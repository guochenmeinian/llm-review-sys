# Learning to Dye in Branch and Bound

Max B. Paulus

ETH Zurich

max.paulus@inf.ethz.ch &Andreas Krause

ETH Zurich

krausea@ethz.ch

###### Abstract

Primal heuristics are important for solving mixed integer linear programs, because they find feasible solutions that facilitate branch and bound search. A prominent group of primal heuristics are diving heuristics. They iteratively modify and resolve linear programs to conduct a depth-first search from any node in the search tree. Existing divers rely on generic decision rules that fail to exploit structural commonality between similar problem instances that often arise in practice. Therefore, we propose _L2Dive_ to learn specific diving heuristics with graph neural networks: We train generative models to predict variable assignments and leverage the duality of linear programs to make diving decisions based on the model's predictions. _L2Dive_ is fully integrated into the open-source solver SCIP. We find that _L2Dive_ outperforms standard divers to find better feasible solutions on a range of combinatorial optimization problems. For real-world applications from server load balancing and neural network verification, _L2Dive_ improves the primal-dual integral by up to 7% (35%) on average over a tuned (default) solver baseline and reduces average solving time by 20% (29%).

## 1 Introduction

Mixed integer linear programming problems are optimization problems in which some decision variables represent indivisible choices and thus must assume integer values. They arise in numerous industrial applications, e.g., workload apportionment to balance server loads. They can be used to solve combinatorial problems or to verify the robustness of neural networks . We write a mixed integer linear program \(M^{}:=(c,P^{})\), with \(A^{m n}\), \(b^{m}\), \(c,x,^{n}\), \(,^{n}_{}\) and \(\{1,,n\}\) indexing the variables restricted to be integrals, as

\[z^{}:=_{x P^{}}c^{}x, P^{}=\{x ^{n} Ax=b,\  x,\ x_{j} \  j\} \]

Typically, mixed integer linear programs are solved with a variant of branch and bound search [29, B&B]. This approach recursively builds a search tree, whose root represents the original problem in (1). Child nodes are created by introducing additional constraints (branching) to partition the set of feasible solutions. B&B uses bounds on the optimal solution to prune the tree and direct the search. To obtain strong upper bounds for \(z^{}\), modern solvers typically rely on an array of primal heuristics. These are methods designed to quickly find good feasible solutions or an optimal solution \(x^{}:=\{x P^{} c^{}x=z^{}\}\). Primal heuristics include problem-specific methods [e.g., 34, 30], variants of large neighborhood search , rounding procedures  or diving heuristics [see e.g., 6, 48].

Diving heuristics are a prominent group of primal heuristics. They are based on the linear program (LP) relaxation \(M^{*}:=(c,P^{*})\) of the problem in (1) given by

\[z^{*}:=_{x P^{*}}c^{}x, P^{*}=\{x^{n} Ax =b,\  x\} \]Diving heuristics attempt to drive the LP solution \(x^{*}^{*}:= c^{}x\;\;\;x P^{*}\) towards integrality. For this purpose, they conduct a depth-first search from any node in the search tree by repeatedly modifying and resolving linear programs. Diving heuristics are popular, because linear programs can typically be solved relatively fast and hence a number of diving heuristics have been proposed. However, standard divers rely on generic rules that fail to exploit problem-specific characteristics. This is particularly severe in applications, where similar problem instances are solved repeatedly and structural commonality exists. In this setting, learning is a promising alternative to design effective divers with the ultimate goal of improving solver performance.

We propose _L2Dive_ to learn such application-specific diving heuristics. _L2Dive_ collects good feasible solutions for some instances of a particular application and trains a generative model to minimize a variational objective on them. The model is a graph neural network that, for a given mixed integer linear program, predicts an assignment of the integer variables. At test time, _L2Dive_ uses the model prediction and leverages the duality of linear programs to select variables for diving and tighten their bounds. We fully integrate _L2Dive_ into the open-source solver SCIP and demonstrate the effectiveness of our approach in two sets of experiments. Our approach is illustrated in First, we compare _L2Dive_ against existing diving heuristics on a common benchmark of combinatorial optimization problems and show that it finds better feasible solutions with the same diving budget. Second, we use _L2Dive_ within branch and bound and test it on two real-world applications where we find that _L2Dive_ improves overall solver performance. For server load balancing, it improves the average primal-dual integral by up to 7% (35%) over a tuned (default) solver baseline and in neural network verification it reduces average solving time by 20% (29%).

## 2 Background

### Diving Heuristics

Diving heuristics conduct a depth-first search in the branch and bound tree to explore a single root-leaf path. They iteratively modify and solve linear programs to find feasible solutions. Algorithm 1 illustrates a generic diving heuristic. A dive can be initiated from any node in the branch and bound tree and will return a (possibly empty) set of feasible solutions \(\) for the original mixed integer linear program in (1). Typically, diving heuristics alternate between tightening the bound of a single candidate variable \(x_{j}\) with \(j\) (line 5) and resolving the modified linear program (line 7), possibly after propagating domain changes . The resultant solution may be integral (\(x_{j}\;,\; j\)) or admit an integral solution via rounding [line 9, 1]. Eventually, the procedure is guaranteed to result in at least one primal-feasible solution (line 10) or an infeasible program (line 6). However, in practice solvers may prematurely abort a dive to curb

Figure 1: Traditional diving heuristics are based on generic manual heuristics and integrated efficiently into the branch and bound solver. In contrast, our approach _L2Dive_ learns application-specific diving heuristics by collecting feasible solutions for a set of training instances to train a generative model. At test time, _L2Dive_ uses the model predictions and leverages the duality of linear programs for diving. Finally, we integrate _L2Dive_ into an open-source branch and bound solver.

for example by imposing a maximal diving depth (line 2), an iteration limit on the LP solver or a bound on the objective value.

```
Input:\(M^{}\) with relaxation \(M^{*}\), maximal depth \(d_{}\) Output:\(\), a (possibly empty) set of feasible solutions Require \(s\), a scoring function to select variables for bound tightening
1\(d=1\)while\(d d_{}\)do
2\(j=_{j}s_{j}\)
3 Either \(_{j} x_{j}^{*}\) or \(_{j} x_{j}^{*}\)
4\(P^{*} P^{*}\{_{j} x_{j}_{j}\}\)
5if\(P^{*}\) is infeasiblethenbreak;
6\(x^{*}=\{c^{T}x x P^{*}\}\)
7if\(x^{*}\) is foundablethen
8\(=(x^{*})\)
9\(\{\}\)
10 end if
11\(d d+1\)
12 Possibly update candidates \(\)
13 end while
```

**Algorithm 1**Generic Diving Heuristic

### Solver Performance and Primal Performance

The most intuitive way to assess the performance of a solver for mixed integer linear programs is by measuring _solving time_, i.e., the average time it takes to solve a set of instances. However, realistic instances are often not solved to completion, because this may be prohibitively expensive or a particular application only requires bounds on the optimal solution, which the solver readily yields. In these cases, it is common to consider the _primal-dual gap1_:

\[_{pd}(,^{*})=-^{*} }{(||,|^{*}|)}&0<^{*}<\\ 1& \]Here, \(:=c^{}\) is the upper (also known as primal) bound given by the feasible solution \(\) and \(^{*}\) is a global lower (also known as dual) bound on the optimal solution \(z^{}\). Performance can be measured by solving instances with a fixed cutoff time \(T\) and then computing the primal-dual gap \(_{pd}(_{T},_{T}^{*})\), where \(_{t}^{*}\) and \(_{t}\) denote the solver's best lower and upper bounds at time \(t\) (if non-existent, then \(-\) and \(+\) respectively).

Primal-dual integralUnfortunately, measuring the primal-dual gap at time \(T\) is susceptible to the particular choice of cutoff time. This is particularly troublesome, because the lower and upper bounds of branch and bound solvers tend to improve in a stepwise fashion. In order to alleviate this issue, it is common to integrate the primal-dual gap over the solving time and measure the primal-dual integral:

\[_{pd}(T)=_{t=0}^{T}_{pd}(_{t},_{t}^{*})dt \]

Primal gapWhen directly comparing diving heuristics with each other, it can be useful to consider primal performance instead of solver performance. Primal performance assesses the quality of the feasible solution \(\) a heuristic may find and can be measured by the _primal gap_:

\[_{p}()=-z^{} \]

Sometimes, the primal gap is normalized by \(|z^{}|\) which can be useful when \(_{p}\) is averaged across disparate instances. We do not normalize \(_{p}\) in this work.

## 3 Learning to Dive

We propose _L2Dive_ to learn application-specific diving heuristics with graph neural networks. _L2Dive_ uses a generative model to predict an assignment for the integer variables of a given mixed integer linear program. This model is learnt from a distribution of good feasible solutions collected initially for a set of training instances of a particular application. The model is a graph neural network closely related to the model in Gasse et al. . It is trained to minimize a variational objective. At test time, _L2Dive_ leverages insights from the duality of linear programs to select variables and tighten their bounds based on the model's predictions. We fully integrate _L2Dive_ into the open-source solver SCIP.

### Learning from feasible solutions

We propose to learn a generative model for good feasible solutions of a given instance \(M^{}\). For this purpose, we first pose a conditional probability distribution over the variables \(x\):

\[ p_{}(x|M^{}):-c^{}x/&x\\ -& \]

The distribution \(p_{}(x|M^{})\) is defined with respect to a set of good feasible solutions \(\) for the given instance. Solutions with a better objective are given larger mass as regulated by the temperature \(\), while solutions that are not known to be feasible or are not good (\(x\)) are given no probability mass. In practice, a model for diving will only need to make predictions on the _divide_ variables \(x_{}\) that are integral, non-fixed and not _slack_ (Section 2). Hence, our model will target the marginal distribution \(p_{}^{}(x_{}|M^{}):=_{ }\{x_{}\}p_{}(x|M^{})\).

Our goal is to learn a generative model \(q_{}\) that closely approximates the distribution \(p_{}^{}\). The model \(q_{}\) will be used to make predictions on unseen test instances for which \(p_{}\) and \(\) are unknown. To learn a good generative model, our objective is to minimize the Kullback-Leibler divergence between \(p_{}^{}\) and \(q_{}\),

\[(p_{}^{}||q_{})= p_{}^{}(x_ {}|M^{})(^{}(x_{ }|M^{})}{q_{}(x_{}|M^{})}) \]

jointly over all training instances. The sum in (7) can be evaluated exactly, because the number of good feasible solutions in \(\) tends to be small. Our model for \(q_{}\) is a variant of the graph neural network described in Gasse et al.  and we give details in Appendix B. This model represents a mixed integer linear program as a bipartite graph of variables and constraints (Figure 3 in Appendix B) and its core are two bi-partite graph convolutions between variables and constraints (Figure 2 in Appendix B). Our variant uses some of the variable and constraint features from Paulus et al.  as well as batch normalization. It makes conditionally independent predictions for each integer variable, such that \(q_{}(x_{}|M^{}):=_{j I}q_{}(x_{j}|M^{ })\). For binary variables, \(q_{}(x_{j}|M^{})\) is a Bernoulli distribution and the model outputs the mean parameter \(\). For general integer variables, \(q_{}(x_{j}|M^{})\) is a sequence of Bernoulli distributions over the bitwise representation of the variable's integer domain and the model outputs a mean for each. Although conditionally independent predictions limit our model to unimodal distributions, this parameterization delivered strong empirical performance in our experiments (Section 5). It is possible to choose more delicate models for \(q_{}\), such as autoregressive models, but those will typically impose a larger cost for evaluations.

Solution augmentationAt train time, we rely on the availability of a set of good feasible solutions \(\) for each instance. This is required to define \(p_{}\) in (6) and evaluate the objective in (7) on all training instances. Several choices for \(\) are possible, and the effectiveness of our approach may depend on them. For example, if \(\) only contains poor feasible solutions, we cannot reasonably hope to learn any good integer variable assignments. The most obvious choice perhaps is to let \(=\{x^{}\}\), where \(x^{}\) is the best solution the solver finds within a given time limit \(T\). However, solvers are typically configured to not only store \(x^{}\), but also a set number of its predecessors. Thus, alternatively some or all of the solutions in store could be used to define \(\) at no additional expense. Lastly, many instances of combinatorial optimization (e.g., set cover, independent set) exhibit strong symmetries and multiple solutions with the same objective value may exist as a result. These can be identified by using a standard solver to enumerate the solutions of an additional auxiliary mixed integer linear program as described in Appendix C. We used this method to augment solutions in \(\) for some of our experiments. This technique may be of independent interest, because the problem of handling symmetries is ubiquitous in machine learning for combinatorial optimization . While it can be expensive to collect feasible solutions for each training instance regardless of the choice of \(\), this cost may be curbed, because we do not require \(\) to contain the optimal solution. Moreover, the cost is incurred only once and ahead of training, such that all solver calls are embarassingly parallelizable across instances. In some cases, a practitioner may be able to draw on previous solver logs and not be required to expend additional budget for data collection. Finally, any training expense will be ultimately amortized in test time service.

### Using a generative model for diving

At test time, we use our generative model \(q_{}\) to predict an assignment for the _divable_ integer variables \(x_{}\) of a given instance. Typically, we will choose \(_{}= q_{}(x_{}|M^{})\) to predict an assignment, but assignments can also be sampled from the model, if multiple dives are attempted in parallel. To use the prediction for diving, we need to decide which variable to select (line 3 in Algorithm 1) and how to tighten its bounds (line 4). Ideally, our decision rules will admit a feasible solution at shallow depths, i.e., only a few bounds must be tightened to result in an integral or roundable solution to the diving linear program. Which variables should we tighten for this purpose and how? Compellingly, the theory of linear programming affords some insight:

**Proposition 1**.: _Let \(\) be a feasible solution for \(M^{}\) as in (1). For the linear program \(M^{*}\), its dual linear program \(M^{*}_{D}\) is defined in (11) in Appendix D. Let \(y^{*}:=(y^{*}_{b},y^{*}_{},y^{*}_{})\) be an optimal solution for \(M^{*}_{D}\). Let \(()\) and \(()\) index the set of variables that violate complementary slackness (12) between \(\) and \(y^{*}\), such that_

\[() :=\{j(_{j}-_{j})\,y^{*}_{_{j}}>0\}\] \[() :=\{j(_{j}-_{j})\,y^{*}_{_{j}}>0\}\]

_and define \(J():=()()\). Let \(M^{*}_{J}:=(c,P^{*}_{J})\) be the linear program, where the bounds of all variables indexed by \(J()\) are tightened, such that_

\[P^{*}_{J}=P^{*}\{x^{n} x_{j}_{j}\  j (),\ x_{j}_{j}\  j( )\}\]

_Then, \(\) is an optimal solution to the linear program \(M^{*}_{J}\), i.e., \(_{x P^{*}_{J}}c^{}x\)._Proof.: \(\) is clearly a feasible solution for \(M^{*}_{J}\). \(y^{*}\) is a feasible solution for the dual linear program of \(M^{*}_{J}\), because it is feasible for \(M^{*}_{D}\). \(\) and \(y^{*}\) satisfy complementary slackness, hence \(\) is optimal. 

This suggests that for a prediction \(_{}\), the bounds of variables in \(J(_{})\) should be tightened to restore complementary slackness. If the integer variable assignment \(_{}\) is feasible and the candidate set includes all integer variables, this will yield a diving linear program for which the assignment is optimal and that may be detected by the LP solver. Unfortunately, this is not guaranteed in the presence of _slack_ variables (where typically \(\)) or if multiple optimal solutions exist (some of which may not be integer feasible). In practice, it may thus be necessary to tighten additional variables in \(\). Inspired by Proposition 1, we propose the following _dual reasoning_ rule to select to select a variable \(j^{*}\) for tightening

\[j^{*}=_{j}s_{j}:=q_{}(_{j})+\{j  J(_{})\} \]

This rule will select any variables in \(J(_{})\) before considering other variables for tightening. The score \(s\) breaks ties by selecting the variable in whose predictions the model is most confident in. Conveniently, the set \(J()\) can be easily computed on the fly from the dual values \(y^{*}\), which standard LP solvers readily emit on every call at no additional expense. We tighten \(_{j}=_{j}\) if \(_{j} x^{*}_{j}\) and we tighten \(_{j}=_{j}\) if \(_{j} x^{*}_{j}\) to replace line 4 in Algorithm 1. We update the candidate set \(\) in line 13 to exclude variables whose value has been fixed, i.e., \(_{j}=_{j}\) as usual. We validate dual reasoning in an ablation study in section 5.1.

### Deployment

We fully integrate _L2Dive_ into the open-source solver SCIP 7.0.2 . This solver exposes a plug-in for diving heuristics that implements an optimized version of Algorithm 1 in the programming language C. We extend the solver's Python interface  to include this plug-in and use it to realize _L2Dive_. This integration facilitates direct comparison to all standard divers implemented in SCIP (Section 5.1) and makes it easy to include _L2Dive_ in SCIP for use in branch and bound (Section 5.2). Importantly, we call our generative model only once at the initiation of a dive to predict a variable assignment. While predictions may potentially improve with additional calls at deeper depths, this limits the in-service overhead of our method. It also simplifies the collection of training data and produced good results in our experiments (Section 5).

## 4 Related Work

Nair et al.  propose a method that learns to tighten a subset of the variable bounds. It spawns a smaller sub-integer program which is then solved with an off-the-shelf branch and bound solver to find feasible solutions for the original program. Sonnerat et al.  improve this approach using imitation learning. Others explore reinforcement learning  or hybrids , but only focus on improving primal performance. All of these methods are variants of large neighborhood search [39; 2; 36], where a neighborhood for local search is not proposed heuristically, but learnt instead. In contrast, our approach _L2Dive_ does not propose a fixed neighborhood and it does not require access to a branch and bound solver to run. Instead, we use our model's predictions to iteratively modify and solve linear programs instead of sub-integer programs. In practice, linear programs tend to solve significantly faster which makes _L2Dive_ more applicable. Khalil et al.  propose a method to learn variable assignments from good feasible solutions, but combine their model predictions with a heuristic rule for node selection, whereas we consider diving.

Overall, there is vivid interest in exploring the use of machine learning for integer programming [5; 52; 31]. With regard to branch and bound, several works learn models for variable selection in branching [25; 3; 17; 19; 42; 51]. Others focus on node selection in the search tree [20; 50] or deal with cutting plane management [35; 22; 43; 9; 45]. Further, related work includes both general [23; 46; 46] and specific [12; 9; 8] attempts of learning to configure the solver. To the best of our knowledge, we are the first to propose _learning to dive_ to improve the performance of branch and bound solvers.

Experiments

The goal of our work is to learn application-specific diving heuristics to improve on existing diving heuristics. We view other primal methods (Section 4) as complementary, and accordingly compare primarily to other diving heuristics. We evaluated the effectiveness of _L2Dive_ in two different experiments and on a total of six datasets. The first set of experiments (Section 5.1) was designed to study the diving performance of _L2Dive_ in isolation and compare it against existing diving heuristics. On a benchmark of four synthetic combinatorial optimization problems from previous work , we performed single dives with each diver and measured the average primal gap. We found that _L2Dive_ outperformed all existing divers on every dataset and produced the best solutions amongst all divers. The second set of experiments (Section 5.2) directly included _L2Dive_ into the branch and bound process of the open-source solver SCIP. The solver called _L2Dive_ in place of existing diving heuristics and our goal was to improve overall performance on real-world mixed integer linear programs. We considered instances from neural network verification  and server load balancing in distributed computing . We measured performance with _L2Dive_ against the default configuration and a highly challenging baseline that tuned the solver's diving ensemble. We found that _L2Dive_ improved the average primal-dual integral by 7% (35%) on load balancing and improved average solving time by 20% (29%) on neural network verification over the tuned (default) solver.

We collected data for training and validation: In all experiments, we extracted a bipartite graph input representation of each instance's root node. On all but two datasets, we chose \(=\{x^{}\}\) where \(x^{}\) is the best solution the solver finds within a given time limit \(T\). For set cover and maximum independent set only, we observed strong symmetries and used the solution augmentation described in Appendix C. We trained separate models for each dataset. We trained each model with ADAM  for 100 epochs in the first set of experiments and for 10 epochs in the second set of experiments. We individually tuned the learning rate from a grid of \([10^{-2},10^{-3},10^{-4}]\). For each dataset, we chose the batch size to exhaust the memory of a single NVIDIA GeForce GTX 1080 Ti device. We validated after every epoch and chose the model that achieved the best validation loss. In all experiments, we use the mode prediction of the generative model and only perform a single dive from a given node. We do not attempt multiple dives in parallel and did not use any accelerators at test time. In all experiments, we only call _L2Dive_'s generative model once at the beginning of a dive to limit the in-service overhead from serving the graph neural network.

### Diving with _L2Dive_

With this first set of experiments, we studied the diving performance of _L2Dive_ and compared it against existing diving heuristics. We used the same benchmark as previous work . This benchmark consists of four different classes of combinatorial optimization problems, including set covering, combinatorial auctions, capacitated facility location and maximum independent sets. For each class, we used 2000 instances in total; we trained on 1000 instances and validated and tested on 500 instances respectively. We presolved all instances before diving, but did not branch and disabled cutting planes and other primal heuristics as our interest is solely in diving. We compared _L2Dive_ against all other standard diving heuristics that are implemented in the open-source solver SCIP and do not require an incumbent solution. This includes _coefficient_, _fractional_, _linesearch_, _pseudocost_, _distributional_, _vectorlength_ and _Farkas_ diving . We briefly describe these baseline divers in Appendix A. In addition, we considered three trivial divers that respectively fix integer variables to their lower (_lower_) or upper limit (_upper_) or either with equal probability (_random_). All divers ran with the same diving budget (\(d_{max}=100\)) and their execution was directly triggered by the user after resolving the root node. We ignore the few test instance that were solved directly at root by SCIP before we could initiate a dive.

_L2Dive_ outperformed all other standard divers (Table 1). It achieved the lowest average test primal gap on each of the four problem classes. The improvements over the _best heuristic_ diver ranged from roughly 15% for combinatorial auctions to more than 70% for independent sets. The trivial divers only found solutions that are significantly worse, which indicates that _L2Dive_ learnt to exploit more subtle patterns in the problem instances to find better feasible solutions. Some baseline divers (e.g., _linesearch_, _distributional_) failed to consistently outperform the trivial divers across all problem classes and _best heuristic_ diver varied (_pseudocost_ diving for combinatorial auctions, _Farkas_ diving for facility location, _vectorlength_ diving for set cover, independent set). This confirms that in practice most diving heuristics tend to be specialized and work particularly well for particular problem classes.

_L2Dive_ is a generic recipe to design effective divers for any specific application. Finally, we found that the mode predictions of our learnt models were rarely feasible (e.g., set cover, combinatorial auctions) or yielded poor solutions (e.g., independent set). This highlights that learning a generative model for diving may be a more promising approach than trying to predict feasible solutions directly.

In order to validate the dual reasoning rule proposed in subsection 3.2, we paired _L2Dive_ with two alternative rules for variable selection in capacitated facility location. The first ablative rule chooses a variable \(j\) uniformly at random, i.e., \(s_{j}^{rand}_{}\). The second ablative rule simply uses model confidence, i.e., \(s_{j}^{conf}=q_{}(_{j})\) and unlike dual reasoning does not treat variables \(j J(_{})\) preferentially. We found that even when variables were selected uniformly at random (where the model prediction is used only for bound tightening), _L2Dive_ outperformed the best standard diver (Table 2). However, selecting variables whose model predictions are more certain significantly improved performance by a large margin, while additionally employing dual reasoning tended to improve performance further for capacitated facility location. The effectiveness of dual reasoning is likely problem-specific, as dual reasoning will collapse to the model confidence rule, if the set \(J\) is empty. To test the generalization performance of _L2Dive_ to larger instances, we performed an additional ablation study and report the results in Appendix E.

### _L2Dive_ in branch and bound

With this second set of experiments, our goal was to use _L2Dive_ within branch and bound to improve solver performance on real-world mixed integer linear programs. To this end, we included _L2Dive_ into the open-source solver SCIP. We disabled all other diving heuristics in SCIP and dive with _L2Dive_ from the root node. We found this to work well, but results for _L2Dive_ may likely improve with a more subtle schedule for _L2Dive_ or by integrating _L2Dive_ into the solver's diving ensemble.

    & Set Cover & Comb. Auction & Fac. Location & Ind. Set \\  _L2Dive_ & **55** (3) & **222** (7) & **160** (10) & **5** (1) \\ _Best heuristic_ & 95 (3) & _256_ (8) & _484_ (7) & _18_ (2) \\ _Coefficient_ & 3,700 (55) & 671 (11) & 762 (9) & 246 (4) \\ _Distributional_ & 3,900 (50) & 1,504 (12) & 760 (9) & 196 (3) \\ _Farkas_ & 105 (3) & 476 (9) & _484_ (7) & - \\ _Fractional_ & 3,726 (57) & 672 (10) & 1,058 (11) & 232 (4) \\ _Linesearch_ & 1,269 (24) & 467 (10) & 1,036 (15) & 77 (1) \\ _Pseudocost_ & 195 (9) & _256_ (8) & 505 (11) & 32 (2) \\ _Vectorlength_ & _95_ (3) & 832 (20) & 840 (19) & _18_ (1) \\  _Random_ & 416 (13) & 704 (12) & 902 (14) & 78 (2) \\ _Lower_ & 2,918 (63) & 1,587 (11) & 623 (8) & 171 (5) \\ _Upper_ & 239 (6) & 611 (11) & 828 (14) & 62 (2) \\   

Table 1: _L2Dive_ finds better feasible solution on all four problem classes than existing diving heuristics. Average primal gap with standard error on test set. Best diver is in **bold** and best heuristic is in _italics_.

    & Fac. Location \\  _L2Dive_ & **160** (10) \\  _L2Dive_ (with \(s_{j}^{conf}\)) & **164** (10) \\ _L2Dive_ (with \(s_{j}^{rand}\)) & **335** (14) \\  _Best heuristic_ & _484_ (7) \\   

Table 2: Dual reasoning in _L2Dive_ tends to improve diving performance on capacitated facility location. Even selecting variables for diving uniformly at random outperforms the best heuristic diver, but using model confidence (and dual reasoning) facilitates significant improvements.

We considered two strongly contrasting applications from previous work. The first application deals with safely balancing workloads across servers in a large-scale distributed compute cluster. This problem is an instance of bin-packing with apportionment and can be formulated as a mixed integer linear program. We used the dataset from Gasse et al.  which contains 9900 instances for training and 100 instances for validation and testing respectively. Solving these instances to optimality is prohibitively hard2 and we therefore set a time limit of \(T_{}=900\) seconds, both for data collection and test time evaluations. The second application deals with verifying the robustness of neural networks. This problem can be formulated as a mixed integer linear program . We considered the instances from Nair et al. , but used the same subset as Paulus et al.  who disregard trivial and numerically unstable instances. This dataset contains 2384 instances for training, 519 instances for validation and 545 instances for testing. These instances are challenging, but can mostly be solved within a reasonable time. We set a limit of \(T_{}=3600\) seconds, both for data collection and test time evaluations.

To assess solver performance, we measure solving time \(T\) for neural network verification and the primal-dual integral \(_{pd}(T_{})\) for server load balancing. Both measures fully account for the entire in-service overhead of _L2Dive_ (e.g., computing the bipartite graph representation from the tree node, forward-propagating the generative model, diving etc.), because the _L2Dive_ diver is directly included into SCIP and called by the solver during the branch and bound process. Our experiments were conducted on a shared distributed compute cluster. To reduce measurement variability, we ran all test time evaluations repeatedly on machines equipped with the same Intel Xeon Gold 5118 CPU 2.3 GHz processors for three different sedings of the solver. We batched evaluations randomly across instances and methods to be processed sequentially on the same machine. We report test set means and standard errors over the three different random seeds.

_L2Dive_ improved solver performance ad-hoc (Table 3, _L2Dive_). On load balancing, _L2Dive_ improved the average primal-dual integral by over 30% from the solver at default settings (Table 3, _Default_). On neural network verification, _L2Dive_ reduced the average solving time from approximately 56 seconds to less than 40 seconds (35%). As a control, we also ran SCIP without any diving and surprisingly found small improvements on both datasets (Table 3, _No diving_). The solver's default setting are calibrated on a general purpose set of mixed integer programs and are typically a challenging baseline to beat. However, our results suggests that SCIP's divers are either ineffective or may be poorly calibrated for these two applications. For this reason, we decided to tune the diving heuristics of the solver to seek an even more challenging baseline for comparison. We leveraged expert knowledge and random search to find strong diving ensembles in the the vicinity of the default configuration. Then, we selected the best tuned solver configuration on a validation set using the same budget of solver calls that _L2Dive_ expended for data collection. Details are in Appendix F. Our tuned solver baseline (Table 3, _Tuned_) significantly improved performance over _Default_, but was still outperformed by _L2Dive_. This highlights that our approach to learn specific divers may be more promising than fitting ensembles of generic diving heuristics to a particular application. Overall, _L2Dive_ achieved the best average performance on 93 (out of 100) test instances for load balancing, and achieved the best

    &  &  \\   & Primal-dual Integral & Wins & Solving Time & Wins \\  SCIP & & & & \\ _Default_ & 4,407 (34) & 0 (0) & 55.8 (2.3) & 54 (5) \\ _No diving_ & 4,221 (21) & 0 (0) & 53.7 (0.6) & 40 (4) \\ _Tuned_ & 3,067 (10) & 7 (3) & 49.9 (2.8) & 164 (3) \\ _L2Dive_ & **2,863 (13)** & **93 (3)** & **39.8 (2.3)** & **287 (5)** \\   

Table 3: _L2Dive_ improves the performance of the branch and bound solver SCIP on real-world applications. When using _L2Dive_ instead of standard divers, the average primal-dual integral for load balancing improves by 7% (35%) and solving time on neural network verification shrinks by 20% (29%) against the tuned (default) solver.

average performance on 287 (out of 545) test instances for neural network verification, more than the three SCIP configurations collectively.

## 6 Conclusions

We presented _L2Dive_ to learn application-specific diving heuristics for branch and bound. Our approach combines ideas from generative modeling and relational learning with a profound understanding of integer programs and their solvers. We tested _L2Dive_ on a range of applications including combinatorial optimization problems, workload apportionment and neural network verification. It found better feasible solutions than existing diving heuristics and facilitated improvements in overall solver performance. We view our work as yet another example that demonstrates the fruitful symbiosis of learning and search to design powerful algorithms.

## Broader Impact and Limitations

This work presents a method to use machine learning for improving the performance of branch and bound solvers. Branch and bound is a powerful general-purpose method for solving mixed integer linear programs which appear frequently across business, science and technology. Therefore, we expect the impact of this work to be overwhelmingly beneficial. However, in cases where integer programming is exploited with ill intentions, our work may potentially have a harmful societal impact.

There are limitations in learning diving heuristics for specific applications. For example, in some cases the set of training instances may be small or collecting feasible solutions could be prohibitively expensive. In such cases, it may be desirable to transfer models from other applications or to utilize self-supervised representations that require fewer labelled examples for training . This is a natural direction to explore in the future, for this and other work at the intersection of machine learning and integer programming. Alternatively, one may attempt to learn a universal diving heuristic using a diverse set of instances from a variety of applications. However, the extent to which machine learning can prove effective in this setting, for diving or other sub-routines, remains an open question.