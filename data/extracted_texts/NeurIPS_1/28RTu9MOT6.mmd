# Improving Graph Matching with Positional Reconstruction Encoder-Decoder Network

Yixiao Zhou

Wangxuan Institute of Computer Technology

Peking University

&Ruiqi Jia

Wangxuan Institute of Computer Technology

Peking University

&Hongxiang Lin

Wangxuan Institute of Computer Technology

Peking University

&Hefeng Quan

School of computer science and engineering

Nanjing University of Technology

&Yumeng Zhao

School of Artificial Intelligence

Beijing University of Posts and Telecommunications

&Xiaoqing Lyu

Wangxuan Institute of Computer Technology, Beijing Institute of Big Data Research

Peking University

Correspondence: lvxiaoqing@pku.edu.cn. Author emails: {chnzyx,jiaruiqi}@pku.edu.cn, linhongxiang@stu.pku.edu.cn, 920106840131@njust.edu.cn, zhaoyumeng_311@bupt.edu.cn, lvxiaoqing@pku.edu.cn

###### Abstract

Deriving from image matching and understanding, semantic keypoint matching aims at establishing correspondence between keypoint sets in images. As graphs are powerful tools to represent points and their complex relationships, graph matching provides an effective way to find desired semantic keypoint correspondences. Recent deep graph matching methods have shown excellent performance, but there is still a lack of exploration and utilization of spatial information of keypoints as nodes in graphs. More specifically, existing methods are insufficient to capture the relative spatial relations through current graph construction approaches from the locations of semantic keypoints. To address these issues, we introduce a positional reconstruction encoder-decoder (PR-EnDec) to model intrinsic graph spatial structure, and present an end-to-end graph matching network PREGM based on PR-EnDec. Our PR-EnDec consists of a positional encoder that learns effective node spatial embedding with the affine transformation invariance, and a spatial relation decoder that further utilizes the high-order spatial information by reconstructing the locational structure of graphs contained in the node coordinates. Extensive experimental results on four public keypoint matching datasets demonstrate the effectiveness of our proposed PREGM.

## 1 Introduction

Image matching is a common and basic matching problem in multimedia and visual applications. The goal of image matching is to find a dense semantic content correspondence between two images, while feature-based matching is a typical strategy to solve the above problems, and in feature matching,the semantic keypoints in images are the most commonly used matching targets. Semantic keypoint matching aims at establishing correspondence between keypoint sets in images, and it has been applied to a wide range of applications, such as object tracking , image retrieval , and pose estimation , etc.

The semantic keypoint data has the properties of non-Euclidean and unstructured for its disorder and discreteness, and graphs are powerful tools to represent some complex objects and their interactions. Specifically, we take each semantic keypoint as a node, and build edges by heuristic methods according to the positions of nodes to construct a corresponding graph. Graph matching is an effective method to solve the correspondence between the semantic keypoints in two images.

As deep learning models are scalable and time-efficient, Graph Neural Networks (GNNs) are increasingly utilized in graph matching tasks, such as GMN , PCA , and BBGM , etc.

However, most graph matching approaches rely on the matching of basic items of graphs, i.e. computing affinities of nodes and edges, lack the mining and utilization of spatial context information hidden in the locations of keypoints as nodes of graphs. Recently, in task scenarios such as point cloud and knowledge graph, which the nodes in graphs have locational information, there are methods such as  utilizing positional encoder to add the spatial information as additional features. However, current methods in graph matching domain lack such spatial positional information supplementation. As the positional information is closer to the intrinsic characteristic of the graph, it is important to integrate spatial descriptions into graph feature embeddings in graph matching.

But utilizing underlying spatial information faces the following challenges: 1) Through taking key points as graph nodes and edges are associated with pairwise distance, such as delaunay triangulation, it is not sufficient to mine hidden relative positional relationship. 2) The description of spatial information from coordinates of keypoints is relatively simple compared with conventional visual features, so it needs more refined network structure to learn location information, in order to facilitate subsequent feature fusion.

To address the two challenges mentioned above, we propose a positional reconstruction encoder-decoder network (PR-EnDec) in our PREGM by integrating more spatial information into semantic features and learning more distinguishable node features. The positional encoder in PR-EnDec aims to learn the encoding of node positional information with spatial invariance, specifically, the affine transformation invariance of node coordinates. The spatial relation decoder in PR-EnDec is designed to recover the locational structure from the learned features of the encoder, and it reconstructs the relative distances and areas among the sampled nodes. To implement the joint learning of PR-EnDec about the intrinsic positional features in graphs, we, consequently, propose a corresponding contrastive loss function and a reconstruction loss function in the encoder and the decoder respectively.

Our main contributions are summarized as follows:

* We propose an end-to-end graph matching network, PREGM, which learns more distinguishable node features, not only captures visual information in images but also models intrinsic spatial structure of keypoints by our designed PR-EnDec.
* Our PR-EnDec consists of a positional encoder that learns effective graph positional encoding with affine transformation invariance, and a spatial relation decoder used to enhance such learning by reconstructing the graph locational information such as relative distances and areas from learned positional encoding. We also design a corresponding contrastive loss function and a reconstruction loss function in the encoder and decoder respectively to help learn effective node positional characteristics.
* We evaluate our PREGM on four public keypoint matching datasets. Our experimental results demonstrate that PREGM outperforms state-of-the-art methods. We also present an ablation study, which shows the effectiveness of each component of PREGM.

Related Work

### Graph Matching

Graph matching is always an effective strategy to find correspondence between semantic keypoints as graphs have sufficient representation ability for points and their complex relationships, and it can then be applied to downstream tasks such as image matching and understanding. As it is famous for being one of the practically most difficult NP-complete problems, researchers often use optimization algorithms to find an acceptable suboptimal solution for the graph matching problem. Traditional graph matching methods [17; 5; 7; 20; 36] generally use heuristic search algorithms to find suboptimal solutions.

Recent graph matching methods begin to combine combinatorial optimization with deep learning models. GMN  proposes an end-to-end graph matching framework, calculates the unary and pairwise affinities of nodes through CNN features, and also uses spectral matching as a differentiable solver to combine deep learning with graph matching. PCA  uses graph neural network (GNN) to learn and aggregate graph structure information into node feature representation, and introduces Sinkhorn network  as the combinatorial solver for finding node correspondence. BBGM  presents an end-to-end trainable architecture that incorporates a state-of-the-art differentiable combinatorial graph matching solver, and introduces a global attention mechanism to improve the matching performance.

Although the research on graph matching has made the above progress, the existing methods lack the distinguishing and informative graph spatial feature descriptions, and adaptive adjustment of node correspondence on graph matching. In this paper, we overcome these limitations by proposing a positional reconstruction encoder-decoder (PR-EnDec) and designing a contrastive learning and positional feature reconstruction procedure to guide the learning of graph matching.

### Positional Encoding on Graphs

Positional Encoding was first proposed in the Transformer  model. In general, positional encoding refers to the process of encoding spatial relationships or topological information of elements as supplementary information in order to augment the representational capacity of a model. The categorization of positional encoding can be further elaborated as follows: spatial positional encoding utilizes point location as input, while topological positional encoding employs the graph structure as input.

For spatial positional encoding, the point location is used as input to obtain a high-dimensional embedding that contains effective locational information. Space2Vec  introduces _theory_ and _grid_ as a 2D multi-scale spatial positional encoder by using sinusoidal functions with different frequencies. PointCNN  designs a point set spatial positional encoder with Point Conv layers consisting of sampling layer, grouping layer, and aggregation layer. DGCNN  considers both global shape structure and local neighborhood information, and proposes spatial positional encoder layers containing dynamic graph neighborhood and edge convolution module. This paper proposes a spatial position encoding on graphs by leveraging the characteristic of node representation containing coordinate information in image keypoint matching.

Topological positional encoding is specific to graph matching, where the graph structure is used as input to obtain the topological embedding of the nodes. Maskey et al.  generalizes Laplacian-based positional encoding by defining the Laplace embedding to more general dissimilarity functions such as p-norm rather than the 2-norm used in the original formulation. INFMCS  designs a permutation-invariant node ordering based on closeness centrality, and effectively enhances the representation of graph structural features.

In recent years, there has also been research on spatial positional encoding in the field of graph matching. GCAN  utilizes SplineCNN  to encode positional information in 2D spatial space, and successfully capture structural information of the graph.

However, there remains the open question of how to further mine intrinsic spatial node information in graphs. In this paper, we propose a positional reconstruction encoder-decoder architecture to obtain effective node spatial positional encoding using 2D point location.

## 3 Problem Formulation of Graph Matching

Given the keypoints in the images, each node is generally associated with a keypoint, and edges are built according to the spatial position relationship between nodes when building an undirected graph. The graph is represented by \(=(,,,)\):

* \(=\{v_{1},...,v_{n}\}\) denotes the node set.
* \(\) denotes the edge.
* \(=\{_{1}|_{1}^{d_{v}},i=1,2,...,| |\}\) denotes the node feature set.
* \(=\{_{1}|_{1}^{d_{v}},i=1,2,...,| |\}\) denotes the edge feature set.

We use the adjacency matrix \(\) to represent the connections of nodes in an undirected graph \(\), that is, \(_{ij}=1\) iff there is an edge \(e_{ij}=(v_{i},v_{j})\).

Given two graphs \(_{1}=(_{1},_{1},_{1},_{1})\) and \(_{2}=(_{2},_{2},_{2},_{2})\), where \(|_{1}|=|_{2}|=n\), the goal of graph matching is to find the correspondence matrix \(\{0,1\}^{n n}\) between nodes \(_{1}\) and \(_{2}\) of the two graphs \(_{1}\) and \(_{2}\), wherein \(_{ij}=1\) iff \(v_{i}_{1}\) corresponds to \(v_{j}_{2}\).

The ultimate goal of the graph matching problem is to find the optimal node correspondence between two graphs \(_{1}\) and \(_{1}\), so the graph matching problem is often considered as a quadratic assignment programming problem (QAP problem):

\[^{*}=_{}^{T} , \]

where \(=()\{0,1\}^{n^{2}}\), \(_{n}=_{n}\), and \(^{T}_{n}=_{n}\). \(^{*}\) denotes the desired node correspondence, and \(_{n}\) denotes a vector of \(n\) ones. \(^{n^{2} nAs an independent stage, we pretrain the abovementioned positional encoder along with the spatial relation decoder module of PR-EnDec (as shown in Figure 2). The pretraining stage enables the positional encoder to learn the high-order spatial information. The PR-EnDec consisting two modules,

**Positional Encoder.** This module takes the coordinates of keypoints as input and learns positional encoding. We first obtain the high-dimensional coordinate embedding vectors by an MLP. The vectors are then fed into self-attention blocks and a normalization layer to learn positional encoding. The attention mechanism provides sequence independence and relative information of nodes. Besides, we propose a contrastive loss for the encoder module. The loss function ensures the affine transformation invariance and learns the relative position information.

**Spatial Relation Decoder.** To reconstruct the spatial structure of graphs, this module generates triangle assignments by distance-based random sampling. In each triangle assignment, the module takes positional encoding corresponding to the three keypoints as the input of self-attention blocks. Next, the processed features are fed into MLPs, and the relative spatial relations of the three points are reconstructed. We adopt a Mean Squared Error (MSE) loss to compare the ground truth relative spatial relations and the decoder's predictions.

### Positional Encoder

The Positional Encoder only takes geometric features of keypoints as inputs,

\(^{g}=\{v_{i}^{g}|v_{i}^{g}^{d^{g}},i=1,...,n\}\) denotes the node geometric feature set.

Specifically, we utilize the 2D Cartesian coordinates of each node \(v_{i}\) as its geometric feature \(v_{i}^{g}=[x_{i},y_{i}]\). The coordinate embedding sub-module embeds the geometric feature \(^{g}\) into latent representations by a two-layer MLP, denoted as \(^{v}\). The updated geometric graph \(^{g}=(,^{v}(^{g}))\) is then fed into the following attention sub-module.

The attention sub-module consists of \(l_{m}\) attention blocks (denoted as \(Attn_{i}^{e}\)) and a normalization layer (denoted as \(Norm\)), which updates latent representations of \(^{g}\). An attention block is composed of a multi-head self-attention layer and a feed-forward layer, which captures the spatial feature of \(^{g}\) by aggregating the latent representations of each node.

\[_{0}^{g}=^{v}(^{g}), \]

\[_{i}^{g}=Attn_{i}^{e}(_{i-1}^{g}),i=1,2,...,l_{m}. \]

The self-attention mechanism is sequence-independent, which is well suited for extracting high-order relative position information between nodes. There is a normalization layer after attention blocks to allow the positional encoding of nodes to be better fused with visual features nodes on the graph matching task. The final positional encoding obtained by the encoder module is denoted as \(F_{pos}\).

\[F_{pos}=Norm(_{l_{m}}^{g}). \]

**Encoder Loss.** For two given graphs \(_{1}=(_{1},_{1},_{1},_{1})\) and \(_{1}=(_{1},_{1},_{1},_{1})\), the positional encoder generates the positional encoding denoted as \(F_{pos}^{1}=\{f_{i}^{1}|i=1,2,...,||\}\) and \(F_{pos}^{2}=\{f_{i}^{2}|i=1,2,...,||\}\) respectively. We expect that for all matched node \(i\) in graph \(_{1}\) and node \(j\) in graph \(_{2}\), the corresponding node positional encoding \(f_{i}^{1}\) and \(f_{j}^{2}\) should be similar. To let the encoder learn the relative position information of the nodes, we perform contrastive learning that

Figure 2: The framework of our PR-EnDec network and the detailed structure of its positional encoder and spatial relation decoder.

perseves the affine invariance of the positional encoding. Specifically, we adopt negative samples to conduct contrastive learning to avoid the encoder module outputs trivial node features that are all similar.

Therefore, we classify \((_{1},_{2})\) as a positive graph pair if \(_{2}^{g}\) is affine transformed by \(_{1}^{g}\) or the keypoints in \(_{1}^{g}\) and \(_{2}^{g}\) are one-by-one matched. On the contrary, \((_{1},_{2})\) is a negative graph pair if the keypoints are not matched.

For each training batch, the positive graph pair set \(_{p}\) and negative graph pair set \(_{n}\) are generated by node permuting or affine transformation. Let \(_{p}\) and \(_{n}\) denote the corresponding positional encoding pair set of \(_{p}\) and \(_{n}\) respectively, we propose a contrastive loss \(_{con}\),

\[S_{p}=_{(F^{1}_{pos},F^{2}_{pos})_{p}}exp(* sim(F^{1}_{pos},F^{2}_{pos})), \]

\[S_{n}=_{(F^{1}_{pos},F^{2}_{pos})_{n}}exp(* sim(F^{1}_{pos},F^{2}_{pos})), \]

\[_{con}=-Log(}{S_{p}+S_{n}}), \]

where \(S_{p}\) and \(S_{n}\) denote the sum of the exponential of positive/negative pairs' similarity, respectively. Additionally, \(\) denotes the temperature constant, and \(sim()\) denotes the cosine similarity.

### Spatial Relation Decoder

To learn the high-order spatial information, we propose \(k\)-th-order geometric reconstruction assignments. Sampling \(k\) points from the node set as an assignment, the corresponding geometric feature set is denoted as \(_{s}^{g}\) and positional encoding set as \(F_{sub} F_{pos}\). If a decoder \(Dec\) takes \(F_{sub}\) as input, we claim the decoder provides \(k\)-th-order relative position information if there exists a non-degenerate geometric function \(\), \((_{s}^{g}) Dec(F_{sub})\). Specifically, we choose \(k=3\) and function \(\) with Euclidean distance and triangle area to learn the third-order relative position information.

The decoder module first samples three keypoints and obtains the corresponding geometric feature set \(_{s}^{g}=\{v_{a}^{g},v_{b}^{g},v_{c}^{g}\}\) and positional encoding set \(F_{sub}=\{f_{a},f_{b},f_{c}\}\). The random sampling method is related to the Euclidean distance from the previous sampled node to learn the relative information better, for the sampling method guarantees that the distances between the sampled nodes are not too far. Next, the sampled feature set \(F_{sub}\) is fed into \(l_{n}\) attention blocks. The intermediate feature is denoted as \(_{sub}=\{_{a},_{b},_{c}\}\). We utilize 2 MLPs, denoted as \(_{d}\) and \(_{a}\), to approximate Euclidean distance and triangle area function, respectively. The reconstructed relative position information of the decoder is represented as:

\[RC=[_{d}(_{a},_{b}),_{d}(_{b},_{c}),_{ d}(_{a},_{c}),_{a}(_{a},_{b},_{c})]. \]

Let \(Dis\) denotes Euclidean distance and \(Area\) denotes triangle area function,\(RC\)'s corresponding geometric function \(\) is obviously

\[(_{s}^{g})=[dis1,dis2,dis3,area], \]

where \(dis1=Dis(v_{a}^{g},v_{b}^{g}),dis2=Dis(v_{b}^{g},v_{c}^{g}),dis3=Dis(v_{a}^{g },v_{c}^{g}),area=Area(v_{a}^{g},v_{b}^{g},v_{c}^{g})\) denote ground-truth third-order relative position information for the decoder to reconstruct.

**Decoder Loss.** Since we calculate the approximated relative position information \(RC\) and the ground-truth \(RC^{gt}=(_{s}^{g})\), we propose the reconstruction loss \(_{rec}\):

\[_{rec}=(RC,RC^{gt}). \]

**PR-EnDec Loss.** Finally, we combine the two losses to guide the training of our PR-EnDec jointly,

\[_{PR-EnDec}=_{con}+_{rec}, \]

where \(\) controls the relative importance of \(_{rec}\).

Through pretraining of PR-EnDec, we obtain an effective encoder for extracting spatial positional encoding for utilization in subsequent PREGM.

### Graph Matching with PR-EnDec

Our training procedure is divided into two stages: In the first stage, we pretrain our PR-EnDec, and in the second stage of graph matching, our positional encoder module of PR-EnDec serves as a sub-module of the base graph matching model, providing learned positional encoding in the first stage.

After the training of PR-EnDec, we freeze all parameters of the encoder module and put it in the training of graph matching tasks. The positional encoding \(F_{pos}\) generated by the positional encoder module is fused with visual features \(F_{vis}\) extracted by a standard CNN:

\[F_{fused}=Linear(F_{pos})+F_{vis}. \]

where \(Linear\) denotes a linear layer.

Next, we feed the fused features into a message-passing module to produce the refined node features, and the message-passing module is implemented by a two-layer SplineCNN . After the message-passing module, node and edge affinities are computed and passed to the differentiable graph matching solver LPMP in . The resulting correspondence matrix X is compared to the ground truth X\(gt\) and the loss function is their Hamming distance:

\[_{GM}=(1-^{gt})+^{gt}(1-). \]

So far, the graph matching problem formulated previously is solved by our PREGM with the two sequential training phases: the PR-EnDec pretrain and the graph matching task.

## 5 Experiments

We conduct experiments on four public keypoint matching datasets and verify the effectiveness of each component of our PREGM by ablation study. We introduce the datasets, baselines, implementation details, and then report the results. The results demonstrate that our PREGM consistently outperforms all other approaches.

### Datasets

We evaluate our PREGM on four public keypoint matching datasets: PascalVOC , Willow ObjectClass , Spar-71k , and IMC-PT-SparseGM .

The PascalVOC dataset includes 20 classes of keypoints with Berkeley annotations  and images with bounding boxes. The PascalVOC dataset is relatively challenging, since the scale, pose and illumination of instances in images are rich and diverse, and the number of annotated keypoints in each image also varies from 6 to 23. When conducting experiments on the PascalVOC dataset, we follow the standard protocol : First, each object is cropped according to its corresponding bounding box and scaled to 256 x 256 px. Second, we use 7,020 images for training and 1,682 for testing.

The Willow ObjectClass dataset contains images of five categories: face, duck, winebottle, car, and motorbike, the first three categories are from the Caltech-256 dataset , and the last two categories are from the PascalVOC 2007 dataset . Each category contains at least 40 different images, and each image is labeled with 10 distinctive keypoints on the target object to be matched. Following the default setting in , we crop the images to the bounding boxes of the objects and rescale to 256 px, 20 images of each class are selected during training, and the rest are for testing.

The SPair-71k dataset is a relatively novel dataset, which was recently published in the paper  about dense image matching. Spar-71k contains 70958 image pairs of 18 categories from PascalVOC 2012 dataset  and Pascal 3D+ dataset . Compared with the other two datasets, SPair71-k has the advantages of higher image quality and richer annotations which includes detailed semantic keypoints, object bounding boxes, viewpoints, scales, truncation, and occlusion differences of image pairs. In addition, compared with PascalVOC dataset, SPair-71k removes two classes with ambiguous and poor annotations: sofa and dining table. Following , we use 53,340 image pairs for training, 5,384 for validation, and 12,234 for testing, and we also scale each image to 256x 256 px.

The IMC-PT-SparseGM dataset contains 16 object categories and 25061 images , which gather from 16 tourist attractions around the world. The IMC-PT-SparseGM benchmark involves matching

[MISSING_PAGE_FAIL:8]

### Performance Evaluation

We conduct experiments on four public datasets: PascalVOC, WillowObject Class, Spain-71k and IMC-PT-SparseGM for the keypoint matching problem, and follow the most common experimental setting, where intersection filtering is applied to generate graphs with the equal size.

Firstly, we report the matching accuracy of the 20 classes and average accuracy on PascalVOC dataset in Table 1, where the best results are shown in bold. The results demonstrate that our model PREGM performs much better than all traditional graph matching methods, and also achieves better performance against state-of-the-art deep graph matching models with matching accuracy 84.1%. And in the 20 classes of PascalVOC dataset, our PREGM has achieved the best results in the other 17 classes except for the boat, bottle and train class. As there are large differences in the scale, pose and illumination of matching objects, PascalVOC is a complex matching dataset, thus the matching accuracy of traditional graph matching methods is not more than 50%, and the performance of deep graph matching methods is relatively better. Our PREGM learns effective node spatial characteristics by PR-EnDec, so as to further improve the graph matching performance.

For the relatively simple WillowObject Class dataset, as shown in Table 2, there are two different training strategies: PT and WT, which PT means matching frameworks are pre-trained on PascalVOC, and WT means learning models are then fine-tuned on WillowObject Class Dataset. In this paper, we adopt two strategies: PT only, both PT and WT, and in both situations, our model achieves the best performance among other state-of-the-art methods with matching accuracy 98.2% and 99.3%. The results again demonstrate the effectiveness of learning positional node features hidden in graphs in our PREGM.

We also conduct experiments on Spain-71k dataset, as shown in Table 3, we compare our PREGM with deep learning methods GMN, PCA, DGMC, BBGM, and DIP-GM. Our PREGM performs best with matching accuracy 81.9%, and shows superiority in total 18 classes, which demonstrates the generalization ability of our model on different objects. SPair-71k dataset, as a relatively new dataset, has the advantages of high image quality, rich annotation, and fixed image pairs for matching, which is a more convincing dataset. Thus our PREGM achieves the best results on the SPair-71k dataset, which further proves the effectiveness of our PREGM.

Additionally, we evaluate our model on the IMC-PT-SparseGM dataset, as shown in Table 4, our model demonstrates outstanding performance on this demanding benchmark. The results outshine the performance of the other methods, GANN-GM  and BBGM, by a significant margin. In terms of the average accuracy across these landmarks, our model excels with an impressive mean accuracy of 90.7%. The IMC-PT-SparseGM dataset is characterized by its substantial number of images, nodes, and high partial rate, making it one of the most comprehensive benchmarks for visual graph matching. Our approach, showcased in these results, demonstrates its ability to handle larger scenes and move closer to real-world applications, such as structure from motion.

  Method & Rechtag & Sacrc\_,cour & St\_,peters\_, square & Avg \\  GANN-GM & 76.0 & 44.2 & 50.5 & 56.9 \\ BBGM & 99.1 & 79.5 & 86.8 & 88.4 \\  Ours & **99.8** & **84.8** & **87.6** & **90.7** \\  

Table 4: Matching accuracy (%) on the IMC-PT-SparseGM.

  Method & aero & bike & boat & bottle & bus & cat & chair & cow & dog & horse & mbike & person & plant & sheep & train & tv & Avg \\  GNN & 30.1 & 40.4 & 62.7 & 46.8 & 60.8 & 56.7 & 57.2 & 62.0 & 40.5 & 51.8 & 49.5 & 36.5 & 35.3 & 76.1 & 44.7 & 61.2 & 57.7 & 35.7 \\ PCA & 58.9 & 42.3 & 72.1 & 54.1 & 61.2 & 73.3 & 66.1 & 65.2 & 50.4 & 64.9 & 56.8 & 55.5 & 64.3 & 53.4 & 86.2 & 49.1 & 75.5 & 61

### Ablation Study and Parameter Analysis

To evaluate the effect of each component in our framework, we conduct comprehensive ablation studies with/without positional encoder, spatial relation decoder, and we also consider the two separate cases of no reconstruction of areas and relative distances in the loss function of spatial relation decoder. Furthermore, we conducted additional ablation experiments by removing visual features to evaluate the effectiveness of the spatial features extracted by our model. The experiments are performed on PascalVOC dataset. As shown in Table 5, compared with the baseline, the results demonstrate that all modules bring substantial performance gains, the reconstruction of relative distance is more important in the decoder, and the spatial relation decoder contributes most to the overall performance. Moreover, with the fact that only taking spatial features as node features can achieve relatively good performance, it further proves the effectiveness of the spatial features learned from our PR-EnDec.

We also conduct parameter analysis to select hyperparameters. As shown in Table 6, PREGM achieves the best performance when learning rate = \(9 10^{-4}\), which is our default setting, and it also shows that adjusting the learning rate causes an accuracy fluctuation of about 1%. For the balance factor \(\) in the loss function, when \(=1/128,1/32\), and \(1/8\), the matching accuracy is 83.7%, 84.1%, and 83.3% respectively. Thus we select \(=1/32\) as our default setting, and the results show that our method is rather sensitive to the choice of \(\), and our designed loss function in positional encoder and spatial relation decoder indeed improves the performance.

## 6 Conclusion

In this paper, we present an end-to-end novel deep graph matching network PREGM that learns more distinguishable node features by modeling spatial positional information in graphs. Our PREGM designs a common encoder-decoder architecture consisting of a positional encoder that learns effective node positional encoding and a spatial relation decoder that reconstructs the positional structure of graphs. Our experiments and ablation studies on four public keypoint matching datasets demonstrate the state-of-the-art performance of our method. The exploration direction of future work includes optimizing the loss function of the positional encoder to extract purer spatial structural information and improve the feature fusion method to obtain better fused feature representation.