# EGonc : Energy-based Open-Set Node Classification with substitute Unknowns

Qin Zhang\({}^{1}\) Zelin Shi\({}^{1}\) Shirui Pan\({}^{2}\) Junyang Chen\({}^{1}\) Huisi Wu\({}^{1}\) Xiaojun Chen\({}^{1}\)

\({}^{1}\)Shenzhen University \({}^{2}\)Griffith University

qinzhang@szu.edu.cn, shizelin2021@email.szu.edu.cn,

s.pan@griffith.edu.cn, {junyangchen,hswu,xjchen}@szu.edu.cn

Corresponding author.

###### Abstract

Open-set Classification (OSC) is a critical requirement for safely deploying machine learning models in the open world, which aims to classify samples from known classes and reject samples from out-of-distribution (OOD). Existing methods exploit the feature space of trained network and attempt at estimating the uncertainty in the predictions. However, softmax-based neural networks are found to be overly confident in their predictions even on data they have never seen before and the immense diversity of the OOD examples also makes such methods fragile. To this end, we follow the idea of estimating the underlying density of the training data to decide whether a given input is close to the in-distribution (IND) data and adopt Energy-based models (EBMs) as density estimators. A novel energy-based generative open-set node classification method, _EGonc_, is proposed to achieve open-set graph learning. Specifically, we generate substitute unknowns to mimic the distribution of real open-set samples firstly, based on the information of graph structures. Then, an additional energy logit representing the virtual OOD class is learned from the residual of the feature against the principal space, and matched with the original logits by a constant scaling. This virtual logit serves as the indicator of OOD-ness. EGonc has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for IND and OOD samples. Comprehensive experimental evaluations of EGonc also demonstrate its superiority.

## 1 Introduction

Learning on graphs, where instance nodes are inter-connected, has become one of the central problems for deep learning, as relational structures are pervasive and induce data inter-dependence which hinders trivial adaptation of existing approaches that assume inputs to be i.i.d. sampled . However, current models mostly focus on improving testing performance of in-distribution (IND) data and largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing samples that may cause negative outcome if the prediction is overconfident on them .

Real-world applications often require machine learning systems to interact with an open world, violating the common assumption that testing and training distributions are identical. This urges the community to devote increasing efforts on how to enhance models' generalization  and reliability _w.r.t._ out-of-distribution data, by classifying samples from known classes and rejecting samples from out-of-distribution.

Existing methods in addressing this task normally are achieved by assuming that a model is more confident in its predictions for closed-set samples than for open-set samples . Based on thisassumption, a threshold is applied to a model's confidence score to separate unknown samples from known ones. Despite its apparent intuitiveness , this method often fails because deep neural networks tend to be over-confident in their predictions, assigning high confidence scores even to unknown inputs [19; 14; 1; 42; 71]. Furthermore, determining an optimal threshold for distinguishing known from unknown classes is a challenging and time-consuming task [38; 12; 22]. Others exploit the feature space of trained network and attempt at estimating the density of in-distribution (IND) features to address OOD detection , such as Gaussian Mixture Models [31; 44], nearest neighbors distribution  and energy logits [34; 8]. However, the immense diversity of the OOD examples makes such methods fragile . For example, GMMs' density explicitly decreases when moving away from training data, making them effective for far-OOD detection, while energy logits benefits from the classifier training to obtain strong results on near-OOD samples [29; 52].

To overcome these limitations, researchers try to make advantages of unrelated samples in the open-set environment . Nevertheless, the methods using real open-set samples to help the training of models often require a substantial amount of data [23; 48; 5], and insouciantly selected data does not really help . Well-designed outlier samples are difficult to obtain and require experts for identification and labeling [6; 25].

In this paper, we follow the idea of estimating the underlying density of the training data to decide whether a given input is close to the IND data and adopt Energy-based models (EBMs) as density estimators. To further improve the OOD detection performance, we try to generate substitute unknown samples carefully under the guidance of graph structure, to mimic the distribution of real open-set classes. Specifically, a novel energy-based generative open-set node classification method, _EGonc_, is proposed to achieve open-set graph learning. Based on the generated substitute unknowns, an additional energy logit representing the virtual OOD class is learned from the residual of the feature against the principal space, and matched with the original logits by a constant scaling. This virtual logit serves as the indicator of OOD-ness. EGonc has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for IND and OOD samples. Comprehensive experimental evaluations of EGonc also demonstrate its superiority. To sum up, the contributions of this paper are summarized as follows:

* A novel method, EGonc, for open-set node classification is proposed by redefining the open-world graph learning paradigm based on the energy model and elaborate unknown-substitute generation;
* EGonc has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for IND and OOD samples. The adopted energy regularization loss has consistent effects with the cross-entropy loss as well as with the tailored complement entropy loss on the known classes, and that they are not mutually exclusive;
* No open-set data (samples of unknown classes or any side information of unknown classes) is required during training and validation. EGonc has an explicit classifier for unknowns and does not require threshold tuning;
* EGonc is agnostic to specific GNN architecture and demonstrates robust generalization capabilities.
* Experiments conducted on benchmark graph datasets illustrate the commendable performance achieved by EGonc.

## 2 Background

### Open-set Node Classification

This paper focuses on the node classification problem for a graph. Consider a graph denoted as \(G=(V,E,X)\), where \(V=\{v_{i}|i=1,,N\}\) is a set of \(N\) nodes in the graph. \(E=\{e_{i,j}|i,j=1,,N.\)\(i j\}\) is a set of edges between pairs of nodes \(v_{i}\) and \(v_{j}\). \(X^{N d}\) denotes the feature matrix of nodes, and \(d\) is the dimension of node features. \(x_{i} X\) indicates the feature vector associated with each node \(v_{i}\). The topological structure of \(G\) is represented as an adjacency matrix \(A^{N N}\), where \(A_{i,j}=1\) if the nodes \(v_{i}\) and \(v_{j}\) are connected, _i.e._, \( e_{i,j} E\), otherwise \(A_{i,j}=0\). \(Y^{N C}\) is the label matrix of \(G\), where \(C\) is the already-known node classes. If node \(v_{i} V\) is associated with a label \(c\), \(y_{i,c}=1\), otherwise, \(y_{i,c}=0\).

For a typical closed-set node classification problem, a GNN encoder \(f_{_{g}}\) takes node features \(X\) and adjacency matrix \(A\) as input, aggregates the neighborhood information and outputs representations. Then, a classifier \(f_{_{c}}\) is used to classify the nodes into \(C\) already-known classes. The GNN encoderand the classifier are optimized to minimize the expected risk  in Eq. (1), with the assumption that test data \(_{}\) and train data \(_{}\) share the same feature space and label space, _i.e._,

\[f^{*}=_{f}_{(x,y)_{}} (y f(_{g},_{c};x,A)) \]

where \(\) is the hypothesis space, \(()\) is the indicator function which outputs 1 if the expression holds and 0 otherwise. Generally, it can be optimized with cross-entropy to discriminate between known classes.

In **open-set node classification problem**, given a graph \(G=(V,E,X)\), \(_{}=(X,Y)\) denotes the train nodes. \(}_{}=(X_{},Y_{})\) is the test nodes, where \(X_{}=S U\), \(Y_{}=\{1,,C,C+1,\}\). \(S\) is the set of nodes that belong to seen classes that already appeared in \(_{}\) and \(U\) is the set of nodes that do not belong to any seen class (_i.e._, unknown class nodes). Open-set node classification aims to learn a \((C+1)\)-\(class\) classifier \(f_{_{c}}\) that \(f(_{g},_{c};X_{},):\{X_{},\}}\), \(}=\{1,,C,unknown\}\), with the minimization of the expected risk :

\[^{*}=_{f}_{(x,y)}_{}}(y f(_{g},_{c};x,)) \]

where \(\) is the adjacency matrix for \(X_{}\). The predicted class \(unknown}\) contains a group of novel categories, which may contain more than one class. Thus, the overall risk aims to classify known classes while also detecting the samples from unseen categories as class \(unknown\).

It is worth mentioning that _open-set node classification problem_ is different with _out-of-distribution (OOD) detection problem_. The objective of OOD detection is to identify a new sample whether from unknown classes or not, which is a binary classification challenge. Thereby, OOD detection techniques are not directly applicable to open-set node classification scenarios. This emphasizes the crucial importance of conducting research on open-set node classification, highlighting the distinct requirements and challenges within this domain.

**From close-set to open-set classifier**, an intuitive way is thresholding . Taking the max output probability as confidence score, i.e., \(conf=max_{c=1,,C}f_{c}(x,A)\), it assumes the model is more confident in closed-set instances than open-set ones. Then we can extend a closed-set classifier by

\[_{i}=_{c=1, C}f_{c}(x_{i},A),\;conf>\\ unknown,\;\;\;\;\;\;\;\;\;\;\;\;otherwise. \]

where \(\) is a threshold. However, due to the overconfidence phenomena of deep neural networks, the output confidence of known and unknown is both high . As a result, tuning a threshold that well separates known from unknown is hard and time-consuming.

Differently, the approach presented in this paper redefines the paradigm of open-set graph learning from the perspective of energy models. well-designed generated unknown substitutes are introduced to aid in training of the energy model performance and elaborate loss function to improve classification performance. There are advantages of adding a class instead of optimizing a threshold as in previous methods [46; 54; 1], since it does not require real open-set samples in validation and also eliminates the difficulty of tuning the threshold.

### Energy-based Models

Energy-based models  use the energy-function \(E_{}\) which defines a density over the data \(x\) as \(p_{}=(x))}{Z()}\), where \(\) are learnable parameters and \(Z()= exp(-E_{})dx\) is the normalizing constant of the EBM. \(Z_{}\) ensures that the induced density function Equation integrates to 1. However, \(Z_{}\) is often hard to compute or even approximate since it is a high-dimensional integral. On the positive side, \(E_{}\) can be any function \(E_{}:^{D}\) placing no restrictions on the transformations compared to Normalizing Flows .

We can directly use the energy for OOD detection. That is, since a data point having high probability is equivalent to having low energy as \(p_{}(x)-E_{}(x)\). This means we are not required to estimate the normalizing constant \(Z()\) in practice by considering a decision threshold \(\) and binary classifier \(G\) for OOD data as

\[G(x,,)=0,\;\;\;-E_{}(x),\\ 1,\;\;\;-E_{}(x)> \]where \(1\) corresponds to IND samples and \(0\) to OOD samples.

We can additionally employ EBMs to \(C\)-category classification problem as discriminative EBMs . Suppose \(f_{}:^{D}^{C}\) is a classifier assigning logits for \(C\) classes for a data point \(x^{D}\). The logits can be interpreted as unnormalized probabilities of the joint distribution \(p_{}(x,y)=\), yielding the marginal distribution over \(x\) as \(p_{}(x)=_{y}p_{}(x,y)\). For training, the factorization can be used, _i.e._,\( p_{}(x,y)= p_{}(x)+ p_{}(y|x)\), and a standard Cross Entropy loss  is usually employed to optimize \(p_{}(y|x)\).

To sum up, the connection between Energy-Based Model and a discriminative neural classifier is established by defining the energy function as the negation of the predicted logit value: \(E(,y)=-h()_{[y]}\). Moreover, the energy function \(E(x)\) can be computed for any given input

\[E()=-_{y^{}}e^{-E(,y^{})} \]

Nevertheless, to the best of our knowledge, existing research on energy-based modeling as well as its application is mostly concentrated on OOD detection, where the primary emphasis is on \(i.i.d.\) inputs while the power of modeling inter-dependent data has remained further exploration. Besides, there have been relatively few attempts to apply energy-based models in open-world scenarios, and this is an endeavor we will also pursue.

## 3 Methodology

We propose a unified open-set node classification framework based on energy scores and generated substitute unknowns. The energy scores mitigate a critical problem of softmax confidence with arbitrarily high values for OOD examples  and the differences of energies between in-distribution and out-of-distribution allow effective differentiation.

Specifically, a GNN encoder \(f_{_{1}}\) takes node features \(X\) and adjacency matrix \(A\) as input, aggregates the neighborhood information and outputs representation \(h_{i}^{k}\) for each node \(v_{i}\) in its \(k\)-th layer, \(k=1,,\), and \(\) is the total number of layers. Thus, in the \(k\)-th layer, for node \(v_{i}\), the GNN encoder aggregates neighbor information from the \(k\)-\(1\) layer into a neighborhood representation:

\[h_{i}^{k}=f^{k}(_{1};h_{i}^{k-1},h_{j}^{k-1},j_{i}) \]

where \(h_{i}^{k}^{d_{k}}\) is the hidden representation at the \(k\)-th layer, \(_{i}\) is the neighborhood of node \(v_{i}\) and \(h^{0}=X\).

Meanwhile, we mimic novel patterns by generating substitute unknown nodes through manifold mixup [51; 17]. Targeted node pairs are selected and mixed up at the middle layer of the GNN, and two kinds of substitutes are created: inter-class unknown substitutes that separate known classes from each other and external unknown substitutes that separate known from unknown. Generated substitutes and original known class nodes are input into the remaining layers together to learn discriminative representations.

Then, a classifier \(f_{_{2}}\) is learned to classify the nodes into \(C+1\) classes according to their energy scores. The energy scores of node \(v_{i}\) is obtained through energy propagation upon the graph topology, _i.e._,

\[E_{i}^{k}=f^{k}(E_{i}^{k-1},E_{j}^{k-1},j_{i}) \]

where \(E_{i}^{0}=-_{y^{}}e^{f_{_{2}}(h_{i}^{k}; y^{ }}\) is the initial energy score of \(v_{i}\).

To conclude, the proposed EGonc method consists of three main modules: 1) a substitute node generation module to create substitute unknown class nodes; 2) a energy propagation module to obtain energy score of each node; and 3) an open-set classifier learning module to guarantee the classification of known classes and the rejection of the unknown class. We introduce them in details.

### Substitute Unknown Generation

As mentioned previously, insouciantly selected unrelated data does not really help  the open-set classification. Thus, we try to generate substitute unknown nodes strategically positioned at class boundaries. These nodes play a crucial role in the learning process by providing supervision and distinguishing between known and unknown nodes. Specifically, we generate two types of substitutes, inter-class unknown substitutes and external unknown substitutes, through manifold mixup [51; 17].

For a well-trained classifier, nodes with common categories tend to have similar characteristics, while those from different classes often have distinct ones. Ideally, well-defined boundaries separate the different classes. Considering that nodes close to these boundaries may have less representative features for their own classes, we chose to generate substitute unknowns using nodes close to these boundaries regions. As a result, samples belonging to different classes, but located in close proximity, become optimal candidates for substitute generation. _i.e._, pairs of nodes in distinct classes connected by an edge. To be specified, given two connected nodes from different categories, denoted as \(\{(x_{i},y_{i}),(x_{j},y_{j})\}\), where \(y_{i} y_{j}\) and \(a_{ij}=1\), their embeddings in the \(k\)-th layer are \(h_{i}^{k}\) and \(h_{j}^{k}\), derived by inputting the graph into the network \(f_{_{1}}^{1 k}\). The inter-class unknown substitute \((_{i},_{i})\) is obtained as follows:

\[_{i}= h_{i}^{k}(_{1};x_{i},A)+(1-)\,h _{j}^{k}(_{1};x_{j},A)\\ _{i}=C+1. \]

Where \(\) is randomly sampled from a Beta distribution, typically centred around \(0.5\). \(_{i}=C+1\) denotes the categories index of \(_{i}\), indicating it belongs to the _unknown_ class. Two edges between \((x_{i},_{i})\) and \((x_{j},_{i})\) are also introduced into the graph. We refer to the set of generated inter-class samples as \(X_{}\). The purpose of \(X_{}\) is to simulate the distribution of unknown classes nodes existing between known classes. The mixed hidden representation \(_{i}\) is then passed to \(f_{_{1}}^{k+1}\) to obtain the final representation \(_{i}^{}=f_{_{1}}^{}(_{i})\).

In addition to the inter-class unknown substitutes, we also generate external unknown substitutes to reflect the unknown distributions at the periphery. We use peripheral nodes of each known category along with their respective class center to generate these external unknown substitutes. The first kind of peripheral nodes are leaf nodes that belong to known classes, denoted as \(x_{i} X_{},\,s.t.\,\,_{j}A_{i,j}=1\). The second kind are nodes with low classification confidence, namely those nodes with the top \(T\) least confident scores within each known classes. In this way, it allows us to identify both structured-based and semantic-based peripheral nodes. We denote the set of peripheral nodes as \(X_{}\). Then, we obtain the embedding of class centers in the \(k\)-th layer based on the ground-truth annotations, _i.e._, \(h_{(c)}^{k}=|}_{x_{i} X^{c}}h_{i}^{k}(_{1};x_{i},A),c=1,,C,\) where \(X^{c}\) represents the nodes labeled with the class \(c\). And we can use the manifold mixup on peripheral nodes and their respective inverted class centers \(\{(x_{i},y_{i}),(x_{(y_{i})},y_{i}),x_{i} X_{},y_{i}\{1,,C\}\}\) to derive the external unknown substitutes in the \(k\)-th layer, i.e.,

\[_{i}= h_{i}^{k}(_{1};x_{i},A)+(-h_{(y_{i })}^{k})\\ _{i}=C+1. \]

where \(>0\) and \(>0\) represent two hyperparameters used to adjust the distance and relative position between the generated samples and the existing known class samples. Furthermore, edges connecting \((x_{i},_{i}),x_{i} X_{}\) are also included in the graph. We denote the set of generated external unknown substitutes as \(X_{}\) and define unknown substitutes as \(X_{}=X_{} X_{}\).

### Energy Propagation

To further capture the diverse distribution of the unknown classes. we introduced an energy-based model. Through formula \(E(,y)=-h()_{|y|}\), we can establish a bridge between the energy function and an open-set classifier.

**Proposition 1**.: The energy score (Eq. (5)) can be an powerful indicator for OOD detection due to its valuable trait: the yielded energy scores for in-distribution data typically exhibit a lower tendency than those of OOD data.

As an energy model on graphs, in order to fully leverage the topological structure information of the graph, we apply energy propagation to the topological structure of the graph.

\[E^{(k)}= E^{(k-1)}+(1-)D^{-1}E^{(k-1)} \]

Here, \(=D^{-1/2}AD^{-1/2}\) is the symmetrically normalized adjacency matrix of \(A\), and \(D\) represents the degree matrix, \(E^{(k)}=[E_{i}^{(k)}],x_{i}_{} X_{}\). With \(0<<1\) as parameter, determine the energy weights for individual nodes with respect to themselves and other connected nodes. The motivation behind topological energy propagation is to incorporate the underlying physical processes involved in data generation by exploiting local interactions between instances. Since similar nodes are often adjacent in the graph, the model can learn relationships between these nodes through energy propagation. This helps to better capture local structures and similarities within the graph.

**Proposition 2**.: For a node \(x_{i}\), if its energy score \(E_{i}^{(k-1)}\) is greater (resp. less) than the average of the energy scores of its one-hop neighbors at the current layer, _i.e._, \(_{ij}E_{i}^{(k-1)}}{_{j}_{ij}}\), then the updated energy score of its own yields \(E_{i}^{(k)}<E_{i}^{(k-1)}\), (resp, \(E_{i}^{(k)}>E_{i}^{(k-1)}\)).

Due to structural homogeneity [60; 28], known classes samples and unknown substitutes often connect within their respective distributions, indicating a correlation. Therefore, by using this energy propagation formula, it could ensure the average energy scores of the known classes samples decrease while the average energy scores of the unknown substitutes increase.

### Open-set Classifier Learning

To address the diverse compositions of known and unknown categories, it is imperative to extract invariant information from both known and unknown classes. Consequently, the backbone GNN network \(f_{_{1}}\) is shared across the \(C+1\) classes, facilitating the learning of class distribution and node representations.

To calibrate the closed-set (known classes) classifier to an open-set classifier, an additional category is introduced in the final classification layer to handle unknown predictions. Suppose the weights of the closed-set classifier are denoted as \(w_{}^{d_{K} C}\) where \(d_{K}\) represents the dimension of the embeddings in the final layer of the GNN, the open-set classifier is formed by combining the closed-set classifier and the substitute classifier, _i.e._, \(_{2}=[w_{},w_{}]^{d_{K}(C+1)}\), where \(w_{}^{d_{K} 1}\) represents the weights associated with the substitute classifier. For simplicity, the bias term is omitted in this context. Then, the integrated classifier is trained using both the original known classes samples and the generated substitute samples, _i.e._, \(}_{}=_{}(X_{}, Y_{})\), \(X_{=X_{} X_{}}\), using the cross entropy loss, _i.e._,

\[l_{1}=_{(x_{i},y_{i})_{}}l_{}(_{i},y_{i})+_{1}_{x_{i} X_{}}l_{}(_{i},C +1) \]

where \(_{i}=s(f_{_{2}}(f_{_{1}}(x_{i})))\) is the output vector of the open-set classifier for the input node \(x_{i}\) through softmax \(s()\). \(l_{}(_{i},y_{i})=-y_{i}_{i}\) is the cross entropy loss.

\(l_{1}\) loss primarily uses information from the ground-truth class to maximize the likelihood, it tends to overlook the influence of complementary classes (_i.e._, incorrect classes) . Therefore, we incorporate the concept of complement entropy  to complement the softmax cross entropy, to neutralize the effects of complementary classes.

Specifically, for the generated unknown substitutes, we minimize their inherent complementary loss, _i.e._, minimize the average of entropy over the \(C\) known classes, considering that the generated substitutes may be adjacent to any of the known classes. Conversely, for nodes belong to known classes, they are predominantly adjacent to the generated substitutes, _i.e._, the \(C+1\) class, we encourage the substitute classifier to assign the second-largest probability to these nodes. In light of these considerations, we introduce a tailored complement entropy loss for EGonc as follows:

\[l_{2}=_{(x_{i},y_{i})_{}}l_{}(_{i}  y_{i},C+1)+_{x_{i} X_{}}l_{}(_{i},y_{i}) \]

where \(_{i} y_{i}\) denotes the prediction logits after excluding the probability of its corresponding ground-truth label. \(l_{CoE}=-_{c=1,c y_{i}}^{C+1}_{i,c}}{l_{-}_{i,y_{i }}}_{i,c}}{l_{-}_{i,y_{i}}},(x_{i},y_{i}) _{}\). The first term of \(l_{2}\) aims to minimize the misclassification of known class nodes into other known classes. By employing \(l_{2}\) loss, the open-world classifier \(f_{_{2}}\) can accurately classify node belonging to known classes into their respective known class, while leveraging the substitute classifier to establish an appropriate boundary for distinguishing between the known and the unknown.

To mitigate the impact of energy attenuation on unknown substitutes during the energy propagation, we further introduce a strict constraints via energy regularization \(l_{3}\) to the model. Drawing inspiration from the Elastic Network [73; 10], we observe a parallel in structure and purpose between regularization terms and their associated error terms. In light of this observation, we adopt a strategy that incorporates both linear loss and quadratic loss terms to penalize errors effectively. The linear error terms facilitate the generation of sparse solutions, thereby enhancing the model's robustness, while the quadratic error terms are adept at accommodating outliers and achieving a better fit to the data. By integrating these two kinds of error terms, we aim to enhance the adaptability and generalization capacity of the model.

\[l_{3}=k_{1}(_{x_{i}_{}}(E_{ }(x_{i}))+_{x_{j} X_{}}(E_{}(x_{j}) ))+k_{2}(_{x_{i}_{}}(E_{}(x_{i}))^ {2}+_{x_{j} X_{}}(E_{}(x_{j}))^{2}) \]

where \(()\) is the LeakyReLU function. \(k_{1},k_{2}\) are the weights for linear and quadratic error terms, respectively. \(t_{},t_{}\) are hyperparameters. \(E_{}(x_{i})=E(x_{i},A;h_{})-t_{in}, x_{i}_{}\) and \(E_{}(x_{j})=t_{}-E(x_{j},A;h_{}), x_{j} X _{}\) represent the energy error terms correspond to the IND data and the OOD data, respectively. Here, \(E(x_{i},A;h_{})\) represents the energy value of sample \(x_{i}\) at the final layer. In this way, the energy scores learned with the constraint of \(l_{3}\) are of benefit to open-set classification, and it also mitigate the excessive attenuation of energy scores for unknown substitutes caused by energy propagation.

**Proposition 3.** For any energy regularization \(l_{3}\) that ensures that the GNN model \(h_{^{*}}\) minimizing \(l_{3}\), where \(t_{}<t_{}\) are two margin parameters, then the corresponding softmax categorical distribution \(p(y|x,_{x};h_{^{*}})\) also minimizes \(l_{1}\), while \(p(C+1|x,_{x};h_{^{*}})\) similarly minimizes \(l_{2}\). This means \(l_{3}\) is optimized in the same direction as \(l_{1}\) and \(l_{2}\) for ind data.

Finally, the total loss of EGonc is a combination of cross entropy, the tailored complement entropy loss, and energy regularization loss, _i.e._,

\[l_{}=l_{1}+_{2}l_{2}+_{3}l_{3} \]

where \(_{2}>0\) and \(_{3}>0\) are the hyperparameters to balance the losses. The algorithm of EGonc and its complexity analysis are provided in Appendix D.

## 4 Experiments

Experiments were carried out to validate the performance of EGonc. These experiments include: open-set node classification comparison, ablation study, parameter study, and generalization analysis. Code are available at _[https://github.com/hiromisyo/EGonc_](https://github.com/hiromisyo/EGonc_).

**Datasets.** Experiments to evaluate the performance for open-set node classification were mainly performed on five benchmark graph datasets [54; 72], namely Cora2, Citeseer3, DBLP4, PubMed5, and Ogbn_arxiv6[24; 45], which are widely used citation network datasets. Statistics are presented in Appendix E.2.

**Metrics.** Accuracy and Macro-F1 are used for performance evaluation.

**Implementation Details.** Generally, EGonc adopt GCN  as the backbone neural network for experimental evaluation unless otherwise specified. Detailed model parameters and platform information are given in Appendix E.3.

**Test settings.** Two kinds of open-set classification evaluations were conducted to consider short or long distances between known classes and unknown classes, _i.e._, near open-set classification and far open-set classification. Specifically, in the near open-set classification experiment, for each dataset, the data of several classes were held out as the unknown classes for testing and the remaining classes were considered as the known classes. \(70\%\) of the known class nodes were sampled for training, \(10\%\) for validation and \(20\%\) for testing. In the far open-set classification experiment, nodes from other datasets were used as unknown class samples for testing, other than the nodes from the dataset used in training.

Besides, a comparison is also provided for different settings in terms of the availability of side information on unknown classes during training or validation, known as the inductive learning setting and the transductive learning setting. In experiments with inductive learning setting, there is not any information about the real unknown class (such as the features \(x_{i}\) or side information of unknown classes) used during training or evaluation, while under the transductive learning setting, the whole graph (including sampled known class nodes and unlabeled unknown class nodes) are input during model training or validation.

**Baselines.** We compare EGonc with ten baselines, which can be classified to four categories.

* 1) Closed-set classification methods: _GCN_soft_ and _GCN_sig_. They are GCNs  with a softmax layer or a multiple 1-vs-rest of sigmoids layer as output layer.
* 2) Open-set classification methods with thresholds: _GCN_soft_\(\)_, _GCN_sig_\(\)_, Openmax , DOC  and OpenWGL . The threshold is chosen from \(\{0.1,0.2,,0.9\}\) or as the description of the original paper, to perform open-set recognition.
* 3) Generative Open-set Classification methods: PROSER  and \(^{2}Pxy\).
* 4) Energy-based methods: GNNSAFE .

A detailed introduction of the baselines can be found in the Appendix E.1.

### Open-set node classification comparison

Since real-world scenarios are complex, where seen and unseen differs in diverse tasks, we evaluate our model in terms of open-set classification from two aspects: near open-set classification, and far open-set classification under inductive and transductive learning setting, respectively, as introduced in test settings.

#### 4.1.1 Near open-set classification

Table 1 presents the accuracy and macro-F1 scores of the methods applied to the near open-set classification task in the inductive learning setting, where the last class of each dataset is designated as the unknown class (_i.e._, u = 1), and the remaining classes are used for model training. It can be observed that EGonc outperforms all the baselines on the five datasets. This shows that EGonc can better differentiate between a known class and an unknown class, though they are similar to each other. Specifically, compared to the second-best method \(^{2}Pxy\), EGonc achieves 2.41% and 2.22% improvements on average in terms of accuracy and F1 on the five datasets,

   &  &  &  &  &  &  \\   & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 \\  GCN\_soft & 70.6 & 67.6 & 44.6 & 38.9 & 63.8 & 59.2 & 28.9 & 29.9 & 49.8 & 17.5 & 51.5 & 42.6 \\ GCN\_sig & 69.2 & 64.7 & 45.3 & 44.5 & 63.5 & 58.7 & 28.9 & 29.8 & 48.8 & 9.5 & 51.1 & 41.4 \\ GCN\_soft\_\(\) & 73.6 & 73.8 & 57.3 & 54.5 & 65.0 & 62.4 & 49.7 & 48.6 & 47.3 & 20.6 & 58.6 & 52.0 \\ GCN\_sig\_\(\) & 79.7 & 80.1 & 62.1 & 54.6 & 69.2 & 68.2 & 45.1 & 46.0 & 46.0 & 8.3 & 60.4 & 51.4 \\ Openmax & 74.6 & 75.1 & 56.2 & 54.5 & 67.2 & 67.2 & 49.1 & 48.7 & 45.5 & 16.3 & 58.5 & 52.4 \\ DOC & 77.8 & 78.1 & 66.0 & 56.7 & 69.9 & 69.2 & 45.6 & 46.2 & 46.7 & 20.7 & 61.2 & 52.2 \\ PROSER & 83.2 & 83.7 & 73.7 & 63.6 & 71.7 & 72.6 & 71.0 & 58.4 & 53.0 & 31.1 & 70.5 & 61.9 \\ OpenWGL & 78.1 & 78.9 & 64.1 & 60.8 & 71.4 & 72.2 & 65.3 & 63.4 & 45.4 & 20.7 & 64.9 & 60.2 \\ GNNSAFE & 79.6 & 81.0 & 69.8 & 60.3 & 72.5 & 74.1 & 70.1 & 66.8 & 51.2 & 24.2 & 68.6 & 61.3 \\ \(^{2}Pxy\) & 84.3 & 84.8 & 75.5 & 71.0 & 77.3 & 79.0 & 73.7 & 70.2 & 62.7 & **33.0** & 74.7 & 67.6 \\ EGonc & **84.5** & **84.9** & **75.8** & **71.5** & **79.1** & **80.8** & **80.2** & **75.5** & **63.0** & **33.0** & **76.5** & **69.1** \\  

Table 1: Near open-set classification on five citation network datasets with one unknown class (u=1) in the inductive learning setting. Numbers reported are all percentage (%).

We illustrate detailed classification accuracy in terms of known classes and unknown classes in Appendix E.4. And the results shows that in order to gain the ability of unknown class detection, there is a slight decrease in the performance of known class classification, i.e. from 79.5% to 76.3% on average, comparing EGonc to closed-set classification method GCN_soft. However, the unknown class detection accuracy is improved from 0% to 76.1% on average, which is remarkable. Besides, we also evaluate the performance of our model in terms of multiple unknown classes. The results are demonstrated in Appendix E.5 and it can be observed that EGonc consistently outperforms the baselines.We further evaluate our model in terms of near open-set classification under transductive learning setting. The results are shown in Appendix E.6. EGonc consistently performs best.

#### 4.1.2 Far open-set classification

For far open-set classification, following the protocol defined in , the models are trained and validated by training and validation instances of the original dataset (IND data). While for testing, instances from another dataset are augmented to the original test set as open-set classes (OOD data). for example, Co_Ci means that Core as IND data and Citeseer as OOD data.

The results for are shown in Table 3. It is found that EGonc can handle far out-of-distribution classes from diverse inputs and achieve noticeable performance improvement compared to other open-set classification methods. Surprisingly, the simple thresholding approach of GCN_soft_\(\) achieves comparable performance with EGonc. This inspires us to combine the generative methods with discriminative methods for far open-set classification in future work.

### Ablation Study

We compare variants of EGonc with respect to loss function and substitute-unknown generation strategy to demonstrate its effect. As shown in Table 2, we firstly verify the effect of each loss we adopted, _i.e._, \((C+1)\)-class cross-entropy loss \(l_{1}\), tailored complement entropy loss \(l_{2}\), and energy regularization loss \(l_{3}\). The results show that these three losses are indispensable to open-set node classification. Then we verify the effect of the substitute unknown samples we generated. Specifically,

   &  &  &  &  &  &  \\  \)} & \(l_{2}\) & \(l_{3}\) & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 \\   ✓ & & & 84.2 & 84.7 & 75.2 & 69.0 & 76.5 & 77.7 & 70.1 & 47.3 & 61.9 & **34.1** & 73.6 & 62.6 \\ ✓ & ✓ & & 84.3 & 84.8 & 75.5 & 71.0 & 77.3 & 79.0 & 73.7 & 70.2 & 62.7 & 33.0 & 74.7 & 67.6 \\ ✓ & ✓ & ✓ & **84.5** & **84.9** & **75.8** & **71.5** & **79.1** & **80.8** & **80.2** & **75.5** & **63.0** & 33.0 & **76.5** & **69.1** \\   \(X_{}\) & \(X_{}\) & \(X_{}\) & \(X_{}\) & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 \\    & & & & 82.7 & 83.2 & 73.5 & 69.6 & 69.5 & 71.3 & 70.4 & 67.2 & 60.1 & 30.0 & 71.2 & 64.3 \\  & & & & 83.7 & 84.0 & 75.5 & 66.9 & 72.3 & 72.7 & 71.8 & 68.5 & 62.3 & 29.3 & 73.1 & 64.3 \\  & ✓ & & & 81.3 & 82.2 & 74.6 & 63.7 & 71.2 & 71.5 & 70.0 & 66.9 & 61.9 & 32.3 & 71.8 & 63.3 \\  & & ✓ & & 84.2 & 84.7 & 75.3 & 70.8 & 75.3 & 76.9 & 73.4 & 68.7 & 62.3 & 31.4 & 74.1 & 66.5 \\  & & & ✓ & 84.1 & 84.6 & 75.4 & 70.9 & 75.5 & 74.8 & 71.4 & 66.9 & 61.5 & 29.5 & 73.6 & 65.3 \\ ✓ & ✓ & & & 84.0 & 84.4 & 75.7 & 71.2 & 72.0 & 71.7 & 73.0 & 69.1 & 61.9 & 32.0 & 73.3 & 65.7 \\  & & ✓ & ✓ & **84.5** & **84.9** & **75.8** & **71.5** & **79.1** & **80.8** & **80.2** & **75.5** & **63.0** & **33.0** & **76.5** & **69.1** \\   

Table 2: Accuracy and macro-F1 scores of EGonc and its variants with respect to different losses and generation strategies.

   &  &  &  &  \\   & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 \\  GCN\_soft & 43.0 & 58.9 & 38.4 & 42.5 & 41.9 & 53.7 & 41.1 & 51.7 \\ GCN\_sig & 41.6 & 57.5 & 36.3 & 42.1 & 41.6 & 45.2 & 39.8 & 48.3 \\ GCN\_soft\(\) & 81.2 & 77.6 & 86.2 & 71.1 & 85.0 & **75.6** & 84.1 & 74.8 \\ GCN\_sig\(\) & 69.4 & 51.8 & 68.7 & 48.0 & 79.8 & 69.1 & 72.6 & 56.3 \\ Openmax & 56.2 & 55.1 & 69.6 & 60.3 & 69.6 & 58.7 & 65.1 & 58.0 \\ DOC & 69.4 & 57.8 & 75.5 & 62.3 & 78.0 & 70.7 & 7we compare the performance of EGonc with respect to different kinds of (substitute) unknown samples: \(X_{}\) which are real far OOD samples, \(X_{}\) which are substitute unknowns generated via \(mixup\) with random parent nodes; \(X_{}\) which are generated inter-class substitute unknowns, and \(X_{}\) which are generated external substitute unknowns. From the results, we can see that EGonc generally achieves higher accuracy with the assistance of auxiliary unknown class samples. However, well-designed unknown substitutes are most beneficial for open-set node classification.

### Generalization Analysis

The proposed model has no specific requirement on the GNN architecture for classification. The unknown-class substitute generation strategy and energy propagation take into account the topological properties of graph data. Therefore, they efficiently achieve the generation of representative unknown class samples and perform in-depth exploration of unkown-class features across different backbones. This design contributes to the model's performance in open-set classification tasks under different backbones. Table 4 illustrates the performance of the proposed EGonc with different GNN architectures, including GCN, GAT and GraphSage. The results confirm the effectiveness and generalization ability of EGonc for open-set node classification.

## 5 Limitation and Conclusion

This paper proposed a novel energy-based generative open-set node classification method, EGonc, by estimating the underlying density of the training data to decide whether a given input is close to the IND data. To obtain better OOD detection capability, we generate substitute unknowns to mimic the distribution of real open-set samples, and use energy logit to represent the indicator of OOD-ness. Under constraint of cross entropy loss, complement entropy loss, and energy regularization loss, EGonc achieves superior effectiveness for unknown class detection and known class classification, which is validated by experiments. EGonc has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for IND and OOD samples. EGonc also has good generalization since it has no specific requirement on the GNN architecture.

   Methods &  &  &  &  &  \\   & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 & Acc & F1 \\  GCN\_soft\_\(\) & 73.6 & 73.8 & 57.3 & 54.5 & 65.0 & 62.4 & 49.7 & 48.6 & 47.3 & 20.6 \\ GCN\_DOC & 77.8 & 78.1 & 66.0 & 56.7 & 69.9 & 69.2 & 45.6 & 46.2 & 46.7 & 20.7 \\ GCN\_Openmax & 74.6 & 75.1 & 56.2 & 54.5 & 67.2 & 67.2 & 49.1 & 48.7 & 45.5 & 16.3 \\ GCN\_\(^{2}Pxy\) & 84.3 & 84.8 & 75.5 & 71.0 & 77.3 & 79.0 & 73.7 & 70.2 & 62.7 & **33.0** \\ GCN\_EGonc & **84.5** & **84.9** & **75.8** & **71.5** & **79.1** & **80.8** & **80.2** & **75.5** & **63.0** & **33.0** \\  GAT\_soft\_\(\) & 71.6 & 69.2 & 58.9 & 51.1 & 65.4 & 66.6 & 43.2 & 43.7 & 49.1 & 16.7 \\ GAT\_DOC & 71.1 & 72.6 & 62.4 & 59.5 & 64.2 & 61.8 & 42.1 & 42.9 & 48.3 & 16.2 \\ GAT\_Openmax & 66.3 & 63.4 & 48.6 & 48.9 & 62.5 & 56.9 & 48.6 & 47.0 & 32.2 & 8.4 \\ GAT\_\(^{2}Pxy\) & 80.4 & 81.0 & 75.2 & 70.9 & 72.9 & 73.7 & 71.7 & 47.0 & 53.7 & 22.6 \\ GAT\_EGonc & **80.8** & **81.3** & **75.3** & **71.0** & **73.1** & **74.0** & **74.3** & **63.6** & **56.1** & **24.5** \\  Graphsage\_soft\_\(\) & 72.7 & 72.9 & 63.5 & 51.2 & 64.3 & 64.0 & 46.6 & 46.9 & 51.5 & 16.0 \\ Graphsage\_DOC & 76.0 & 75.4 & 63.6 & 59.9 & 68.9 & 72.2 & 44.6 & 45.7 & 49.5 & 14.7 \\ Graphsage\_Openmax & 71.1 & 70.6 & 47.9 & 48.7 & 62.3 & 56.9 & 44.4 & 45.1 & 43.2 & 8.0 \\ Graphsage\_\(^{2}Pxy\) & 87.2 & **87.3** & 78.6 & 76.9 & 74.4 & 74.7 & 72.8 & 64.9 & 62.8 & 36.5 \\ Graphsage\_EGonc & **87.3** & **87.3** & **79.5** & **77.4** & **78.0** & **79.6** & **73.0** & **65.0** & **63.4** & **38.4** \\   

Table 4: Accuracy and macro-F1 scores of open-set classification methods with different backbone neural network. Numbers reported are all percentage (%).