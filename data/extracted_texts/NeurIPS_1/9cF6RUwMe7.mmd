# Learning Space-Time Continuous Neural PDEs from Partially Observed States

Valerii Iakovlev Markus Heinonen Harri Lahdesmaki

Department of Computer Science, Aalto University, Finland

{valerii.iakovlev, markus.o.heinonen, harri.lahdesmaki}@aalto.fi

###### Abstract

We introduce a novel grid-independent model for learning partial differential equations (PDEs) from noisy and partial observations on irregular spatiotemporal grids. We propose a space-time continuous latent neural PDE model with an efficient probabilistic framework and a novel encoder design for improved data efficiency and grid independence. The latent state dynamics are governed by a PDE model that combines the collocation method and the method of lines. We employ amortized variational inference for approximate posterior estimation and utilize a multiple shooting technique for enhanced training speed and stability. Our model demonstrates state-of-the-art performance on complex synthetic and real-world datasets, overcoming limitations of previous approaches and effectively handling partially-observed data. The proposed model outperforms recent methods, showing its potential to advance data-driven PDE modeling and enabling robust, grid-independent modeling of complex partially-observed dynamic processes.

## 1 Introduction

Modeling spatiotemporal processes allows to understand and predict the behavior of complex systems that evolve over time and space (Cressie and Wikle, 2011). Partial differential equations (PDEs) are a popular tool for this task as they have a solid mathematical foundation (Evans, 2010) and can describe the dynamics of a wide range of physical, biological, and social phenomena (Murray, 2002; Hirsch, 2007). However, deriving PDEs can be challenging, especially when the system's underlying mechanisms are complex and not well understood. Data-driven methods can bypass these challenges (Brunton and Kutz, 2019). By learning the underlying system dynamics directly from data, we can develop accurate PDE models that capture the essential features of the system. This approach has changed our ability to model complex systems and make predictions about their behavior in a data-driven manner.

While current data-driven PDE models have been successful at modeling complex spatiotemporal phenomena, they often operate under various simplifying assumptions such as regularity of the spatial or temporal grids (Long et al., 2018; Kochkov et al., 2021; Pfaff et al., 2021; Li et al., 2021; Han et al., 2022; Poli et al., 2022), discreteness in space or time (Seo et al., 2020; Pfaff et al., 2021; Lienen and Gunnemann, 2022; Brandstetter et al., 2022), and availability of complete and noiseless observations (Long et al., 2018; Pfaff et al., 2021; Wu et al., 2022). Such assumptions become increasingly limiting in more realistic scenarios with scarce data and irregularly spaced, noisy and partial observations.

We address the limitations of existing methods and propose a space-time continuous and grid-independent model that can learn PDE dynamics from noisy and partial observations made on irregular spatiotemporal grids. Our main contributions include:* Development of an efficient generative modeling framework for learning latent neural PDE models from noisy and partially-observed data;
* the collocation method and the method of lines
- to achieve space-time continuity, grid-independence, and data efficiency;
* Novel encoder design that operates on local spatiotemporal neighborhoods for improved data-efficiency and grid-independence.

Our model demonstrates state-of-the-art performance on complex synthetic and real-world datasets, opening up the possibility for accurate and efficient modeling of complex dynamic processes and promoting further advancements in data-driven PDE modeling.

## 2 Problem Setup

In this work we are concerned with modeling of spatiotemporal processes. For brevity, we present our method for a single observed trajectory, but extension to multiple trajectories is straightforward. We observe a spatiotemporal dynamical system evolving over time on a spatial domain \(\). The observations are made at \(M\) arbitrary consecutive time points \(t_{1:M}:=(t_{1},,t_{M})\) and \(N\) arbitrary observation locations \(_{1:N}:=(_{1},,_{N})\), where \(_{i}\). This generates a sequence of observations \(_{1:M}:=(_{1},,_{M})\), where \(_{i}^{N D}\) contains \(D\)-dimensional observations at the \(N\) observation locations. We define \(_{i}^{j}\) as the observation at time \(t_{i}\) and location \(_{j}\). The number of time points and observation locations may vary between different observed trajectories.

We assume the data is generated by a dynamical system with a latent state \((t,)^{d}\), where \(t\) is time and \(\) is spatial location. The latent state is governed by an unknown PDE and is mapped to the observed state \((t,)^{D}\) by an unknown observation function \(g\) and likelihood model \(p\):

\[(t,x)}{ t}=F((t,),_{}(t,),_{}^{2}(t,),), \]

\[(t,) p(g((t,))), \]

where \(_{}^{}(t,)\) denotes partial derivatives wrt \(\).

In this work we make two assumptions that are highly relevant in real-world scenarios. First, we assume partial observations, that is, the observed state \((t,)\) does not contain all information about the latent state \((t,)\) (e.g., \((t,)\) contains pressure and velocity, but \((t,)\) contains information only about the pressure). Second, we assume out-of-distribution time points and observation locations, that is, their number, positions, and density can change arbitrarily at test time.

## 3 Model

Here we describe the model components (Sec. 3.1) which are then used to construct the generative model (Sec. 3.2).

### Model components

Our model consists of four parts: space-time continuous latent state \((t,)\) and observed state \((t,)\), a dynamics function \(F_{_{}}}\) governing the temporal evolution of the latent state, and an observation function \(g_{_{}}}\) mapping the latent state to the observed state (see Figure 1). Next, we describe these components in detail.

Latent state.To define a space-time continuous latent state \((t,)^{d}\), we introduce \((t):=(^{1}(t),,^{N}(t))^{N d}\), where each \(^{i}(t)^{d}\) corresponds to the observation location \(_{i}\). Then, we define the latent state \((t,)\) as a spatial interpolant of \((t)\):

\[(t,):=((t))(), \]

where \(()\) maps \((t)\) to an interpolant which can be evaluated at any spatial location \(\) (see Figure 2). We do not rely on a particular interpolation method, but in this work we use linear interpolation as it shows good performance and facilitates efficient implementation.

Figure 1: Model sketch. Initial latent state \((t_{1},)\) is evolved via \(F_{_{}}}\) to the following latent states which are then mapped to the observed states by \(g_{_{}}}\).

Latent state dynamics.Given a space-time continuous latent state, one can naturally define its dynamics in terms of a PDE:

\[(t,x)}{ t}=F_{_{}}((t,), _{}(t,),_{}^{2}(t,),), \]

where \(F_{_{}}\) is a dynamics function with parameters \(_{}\). This is a viable approach known as the collocation method (Kansa, 1990; Cheng, 2009), but it has several limitations. It requires us to decide which partial derivatives to include in the dynamics function, and also requires an interpolant which has all the selected partial derivatives (e.g., linear interpolant has only first order derivatives). To avoid these limitations, we combine the collocation method with another PDE solution technique known as the method of lines (Schiesser, 1991; Hamdi et al., 2007), which approximates spatial derivatives \(_{}^{}(t,)\) using only evaluations of \((t,)\), and then let the dynamics function approximate all required derivatives in a data-driven manner. To do that, we define the spatial neighborhood of \(\) as \(_{}()\), which is a set containing \(\) and its spatial neighbors, and also define \((t,_{}())\), which is a set of evaluations of the interpolant \((t,)\) at points in \(_{}()\):

\[_{}():=\{^{}: ^{}=^{}\}, \] \[(t,_{}()):=\{(t,^{ }):^{}_{}()\}, \]

and assume that this information is sufficient to approximate all required spatial derivatives at \(\). This is a reasonable assumption since, e.g., finite differences can approximate derivatives using only function values and locations of the evaluation points. Hence, we define the dynamics of \((t,)\) as

\[(t,)}{ t}=F_{_{}}(_{}(),(t,_{}())), \]

which is defined only in terms of the values of the latent state, but not its spatial derivatives.

One way to define the spatial neighbors for \(\) is in terms of the observation locations \(_{1:N}\) (e.g., use the nearest ones) as was done, for example, in (Long et al., 2018; Pfaff et al., 2021; Lienen and Gunnemann, 2022). Instead, we utilize continuity of the latent state \((t,)\), and define the spatial neighbors in a grid-independent manner as a fixed number of points arranged in a predefined patter around \(\) (see Figure 3). This allows to fix the shape and size of the spatial neighborhoods in advance, making them independent of the observation locations. In this work we use the spatial neighborhood consisting of two concentric circles of radius \(r\) and \(r/2\), each circle contains 8 evaluation points as in Figure 3. In Appendix D we compare neighborhoods of various shapes and sizes.

Equation 7 allows to simulate the temporal evolution of \((t,)\) at any spatial location. However, since \((t,)\) is defined only in terms of a spatial interpolant of \((t)\) (see Eq. 3), with \(^{i}(t)=(t,_{i})\), it is sufficient to simulate the latent state dynamics only at the observation locations \(_{1:N}\). Hence, we can completely characterize the latent state dynamics in terms of a system of \(N\) ODEs:

\[(t)}{dt}:=^{1}(t)}{dt}\\ \\ ^{N}(t)}{dt}=(t,_{1})}{ t}\\ \\ (t,_{N})}{ t}=F_ {_{}}(_{}(_{1}),(t,_{}(_{1})))\\ \\ F_{_{}}(_{}(_{N}),(t,_{}(_{N}))). \]

For convenience, we define \((t;t_{1},_{1},_{}):=(t;t_{1},_ {1},_{})\) as the solution of the ODE system in Equation 8 at time \(t\) with initial state \((t_{1})=_{1}\) and parameters \(_{}\). We also define \((t,;t_{1},_{1},_{})\) as the spatial interpolant of \((t;t_{1},_{1},_{})\) as in Equation 3. We solve the ODEs using off the shelf differentiable ODE solvers from torchdiffeq package (Chen, 2018). Note that we solve for the state \((t)\) only at the observation locations \(_{1:N}\), so to get the neighborhood values \((t,_{}(_{i}))\) we perform interpolation at every step of the ODE solver.

Figure 3: Example of \(_{}(_{i})\). Instead of using the observation locations (dots) to define spatial neighbors, we use spatial locations arranged in a fixed predefined pattern (crosses).

Figure 2: Latent state \((t,)\) defined as an interpolant of \((t):=(^{1}(t),,^{4}(t))\).

Observation function.We define the mapping from the latent space to the observation space as a parametric function \(g_{_{}}\) with parameters \(_{}\):

\[(t,)(g_{_{}}((t,)), _{u}^{2}I_{D}), \]

where \(\) is the Gaussian distribution, \(_{u}^{2}\) is noise variance, and \(I_{D}\) is \(D\)-by-\(D\) identity matrix.

### Generative model

Training models of dynamic systems is often challenging due to long training times and training instabilities Ribeiro et al. (2020); Metz et al. (2021). To alleviate these problems, various heuristics have been proposed, such as progressive lengthening and splitting of the training trajectories Yildiz et al. (2019); Um et al. (2020). We use multiple shooting Bock and Plitt (1984); Voss et al. (2004), a simple and efficient technique which has demonstrated its effectiveness in ODE learning applications Jordana et al. (2021); Hegde et al. (2022). We extent the multiple shooting framework for latent ODE models presented in Iakovlev et al. (2023) to our PDE modeling setup by introducing spatial dimensions in the latent state and designing an encoder adapted specifically to the PDE setting (Section 4.2).

Multiple shooting splits a single trajectory \(\{(t_{i})\}_{i=1,,M}\) with one initial state \(_{1}\) into \(B\) consecutive non-overlapping sub-trajectories \(\{(t_{i})\}_{i_{k}},\ b=1,,B\) with \(B\) initial states \(_{1:B}:=(_{1},,_{B})\) while imposing a continuity penalty between the sub-trajectories (see Figure 4). The index set \(_{b}\) contains time point indices for the \(b\)'th sub-trajectory. We also denote the temporal position of \(_{b}\) as \(t_{[b]}\) and place \(_{b}\) at the first time point preceding the \(b\)'th sub-trajectory (except \(_{1}\) which is placed at \(t_{1}\)). Note that the shooting states \(_{b}\) have the same dimension as the original latent state \((t)\) i.e., \(_{b}^{N d}\). Multiple shooting allows to parallelize the simulation over the sub-trajectories and shortens the simulation intervals thus improving the training speed and stability. In Appendix D we demonstrate the effect of multiple shooting on the model training and prediction accuracy.

We begin by defining the prior over the unknown model parameters and initial states:

\[p(_{1:B},_{},_{})=p(_{1:B}| _{})p(_{})p(_{}), \]

where \(p(_{})\) and \(p(_{})\) are zero-mean diagonal Gaussians, and the continuity inducing prior \(p(_{1:B}|_{})\) is defined as in Iakovlev et al. (2023)

\[p(_{1:B}|_{})=p(_{1})_{b=2}^{B}p(_{b}| _{b-1},_{}). \]

Intuitively, the continuity prior \(p(_{b}|_{b-1},_{})\) takes the initial latent state \(_{b-1}\), simulates it forward from time \(t_{[b-1]}\) to \(t_{[b]}\) to get \(_{[b]}=(t_{[b]};t_{[b-1]},_{b-1},_{})\), and then forces \(_{[b]}\) to approximately match the initial state \(_{b}\) of the next sub-trajectory, thus promoting continuity of the full trajectory. We assume the continuity inducing prior factorizes across the grid points, i.e.,

\[p(_{1:B}|_{}) =[_{j=1}^{N}p(_{1}^{j})][_{b=2}^{ B}_{j=1}^{N}p(_{b}^{j}|_{b-1},_{})], \] \[=[_{j=1}^{N}p(_{1}^{j})][_{b=2} ^{B}_{j=1}^{N}(_{b}^{j}|(t_{[b]},_{j};t_ {[b-1]},_{b-1},_{}),_{c}^{2}I_{d})], \]

where \(p(_{1}^{j})\) is a diagonal Gaussian, and parameter \(_{c}^{2}\) controls the strength of the prior. Note that the term \((t_{[b]},_{j};t_{[b-1]},_{b-1},_{})\) in Equation 13 equals the ODE forward solution \((t_{[b]};t_{[b-1]},_{b-1},_{})\) at grid location \(_{j}\).

Figure 4: Multiple shooting splits a trajectory with one initial state (top) into two sub-trajectories with two initial states (bottom) and tries to minimize the gap between sub-trajectories (orange arrow).

Finally, we define our generative in terms of the following sampling procedure:

\[_{},_{},_{1:B}  p(_{})p(_{})p(_{1:B}| _{}), \] \[(t_{i}) =(t_{i};t_{[b]},_{b},_{}), b\{1,...,B\},\;i_{b},\] (15) \[_{i}^{j}  p(_{i}^{j}|g_{_{}}((t_{i},_{j })), i=1,,M,\;j=1,,N, \]

with the following joint distribution (see Appendix A for details about the model specification.):

\[p(_{1:M},_{1:B},_{},_{})=_{b=1 }^{B}_{i_{b}}_{j=1}^{N}p(_{i}^{j}|_ {b},_{},_{})p(_{1:B}|_{ {dyn}})p(_{})p(_{}). \]

## 4 Parameter Inference, Encoder, and Forecasting

### Amortized variational inference

We approximate the true posterior over the model parameters and initial states \(p(_{1:B},_{},_{}|_{1:M})\) using variational inference (Blei et al., 2017) with the following approximate posterior:

\[q(_{},_{},_{1:B})=q(_{}) q(_{})q(_{1:B})=q_{_{}}(_{})q_{_{}}(_{})_{b=1}^{B}_{j=1}^ {N}q_{_{b}^{j}}(_{b}^{j}), \]

where \(q_{_{}}\), \(q_{_{}}\) and \(q_{_{b}^{j}}\) are diagonal Gaussians, and \(_{}\), \(_{}\) and \(_{b}^{j}\) are variational parameters. To avoid direct optimization over the local variational parameters \(_{b}^{j}\), we use amortized variational inference (Kingma and Welling, 2013) and train an encoder \(h_{_{}}\) with parameters \(_{}\) which maps observations \(_{1:M}\) to \(_{b}^{j}\) (see Section 4.2). For brevity, we sometimes omit the dependence of approximate posteriors on variational parameters and simply write e.g., \(q(_{b}^{j})\).

In variational inference the best approximation of the posterior is obtained by minimizing the Kullback-Leibler divergence: \(q(_{},_{},_{1:B })\|p(_{},_{},_{1:B}|_{1:N})\), which is equivalent to maximizing the evidence lower bound (ELBO), defined for our model as:

\[ =^{B}_{i_{b}}_{j=1} ^{N}_{q(_{b},_{},_{})}[  p(_{i}^{j}|_{b},_{},_{}) ]}_{(i)}-^{N} q(_{j}^{j})\|p(_{1}^{j})}_{(ii)}\] \[-^{B}_{j=1}^{N}_{q(_{ },_{b-1})}q(_{b}^{j})\|p (_{b}^{j}|_{b-1},_{})}_{(iii)}-q(_{})\|p(_{})}_{(iv)}-q(_{})\|p(_{})}_{(v)}.\]

The terms \((ii)\), \((iv)\), and \((v)\) are computed analytically, while terms \((i)\) and \((iii)\) are approximated using Monte Carlo integration for expectations, and numerical ODE solvers for initial value problems. See Appendix A and B approximate posterior details and derivation and computation of the ELBO.

### Encoder

Here we describe our encoder which maps observations \(_{1:M}\) to local variational parameters \(_{b}^{j}\) required to sample the initial latent state of the sub-trajectory \(b\) at time point \(t_{[b]}\) and observation location \(_{j}\). Similarly to our model, the encoder should be data-efficient and grid-independent.

Similarly to our model (Section 3.1), we enable grid-independence by making the encoder operate on spatial interpolants of the observations \(_{1:M}\) (even if they are noisy):

\[_{i}():=(_{i})(), i=1, ,M, \]

where spatial interpolation is done separately for each time point \(i\). We then use the interpolants \(_{i}()\) to define the spatial neighborhoods \(_{}()\) in a grid-independent manner.

To improve data-efficiency, we assume \(_{b}^{j}\) does not depend on the whole observed sequence \(_{1:M}\), but only on some local information in a spatiotemporal neighborhood of \(t_{[b]}\) and \(_{j}\). We define the temporal neighborhood of \(t_{[b]}\) as

\[_{}(t_{[b]})\{k:|t_{k}-t_{[b]}| _{T},\ k=1,,M\}, \]

where \(_{T}\) is a hyperparameter controlling the neighborhood size, and then define the spatiotemporal neighborhood of \(t_{[b]}\) and \(_{j}\) as

\[[t_{[b]},_{j}]:=\{_{k}():k_{}(t_ {[b]}),_{}(_{j})\}. \]

Our encoder operates on such spatiotemporal neighborhoods \([t_{[b]},_{j}]\) and works in three steps (see Figure 5). First, for each time index \(k_{}(t_{[b]})\) it aggregates the spatial information \(\{_{k}()\}_{(_{j})}\) into a vector \(_{k}^{}\). Then, it aggregates the spatial representations \(_{k}^{}\) across time into another vector \(_{[b]}^{}\) which is finally mapped to the variational parameters \(_{b}^{j}\) as follows:

\[_{b}^{j}=h_{_{}}([t_{[b]},_{j}])=h_{}(h_{}(h_{}([t_{[b]},_{j}]))). \]

Spatial aggregation.Since the spatial neighborhoods are fixed and remain identical for all spatial locations (see Figure 5), we implement the spatial aggregation function \(h_{}\) as an MLP which takes elements of the set \(\{_{k}()\}_{_{}(_{j})}\) stacked in a fixed order as the input.

Temporal aggregation.We implement \(h_{}\) as a stack of transformer layers (Vaswani et al., 2017) which allows it to operate on input sets of arbitrary size. We use time-aware attention and continuous relative positional encodings (Iakovlev et al., 2023) which were shown to be effective on data from dynamical systems observed at irregular time intervals. Each transformer layer takes a layer-specific input set \(\{_{k}^{}\}_{k_{}(t_{[b]})}\), where \(_{k}^{}\) is located at \(t_{k}\), and maps it to an output set \(\{_{k}^{}\}_{k_{}(t_{[b]})}\), where each \(_{k}^{}\) is computed using only the input elements within distance \(_{T}\) from \(t_{k}\), thus promoting temporal locality. Furthermore, instead of using absolute positional encodings the model assumes the behavior of the system does not depend on time and uses relative temporal distances to inject positional information. The first layer takes \(\{_{k}^{}\}_{k_{}(t_{[b]})}\) as the input, while the last layer returns a single element at time point \(t_{[b]}\), which represents the temporal aggregation \(_{[b]}^{}\).

Variational parameter readout.Since \(_{i}^{}\) is a fixed-length vector, we implement \(h_{}\) as an MLP.

Figure 5: Spatiotemporal neighborhood of a multiple shooting time point \(t_{[b]}=t_{i}\) and location \(_{j}\), \([t_{[b]},_{j}]\) (denoted by green, blue and orange crosses and the dots inside), is mapped to the variational parameters \(_{b}^{j}\) via the encoder.

### Forecasting

Given initial observations \(}_{1:m}\) at time points \(t_{1:m}\), we predict the future observation \(}_{n}\) at a time point \(t_{n}>t_{m}\) as the expected value of the approximate posterior predictive distribution:

\[p(}_{n}|}_{1:m},_{1:M}) p(}_{n}|}_{m},_{},_{})q(}_{m})q(_{})q(_{})d}_{m}d _{}d_{}. \]

The expected value is estimated via Monte Carlo integration (see Appendix C.4 for details).

## 5 Experiments

We use three challenging datasets: Shallow Water, Navier-Stokes, and Scalar Flow which contain observations of spatiotemporal system at \(N 1100\) grid points evolving over time (see Figure 6). The first two datasets are synthetic and generated using numeric PDE solvers (we use scikit-fdiff (Cellier, 2019) for Shallow Water, and PhiFlow (Holl et al., 2020) for Navier-Stokes), while the third dataset contains real-world observations (camera images) of smoke plumes raising in warm air (Eckert et al., 2019). In all cases the observations are made at irregular spatiotemporal grids and contain only partial information about the true system state. In particular, for Shallow Water we observe only the wave height, for Navier-Stokes we observe only the concentration of the species, and for Scalar Flow only pixel densities are known. All datasets contain 60/20/20 training/validation/testing trajectories. See Appendix C for details.

We train our model for 20k iterations with constant learning rate of 3e-4 and linear warmup. The latent spatiotemporal dynamics are simulated using differentiable ODE solvers from the torchdiffeq package (Chen, 2018) (we use dopri5 with rtol=1e-3, atol=1e-4, no adjoint). Training is done on a single NVIDIA Tesla V100 GPU, with a single run taking 3-4 hours. We use the mean absolute error (MAE) on the test set as the performance measure. Error bars are standard errors over 4 random seeds. For forecasting we use the expected value of the posterior predictive distribution. See Appendix C for all details about the training, validation, and testing setup.

Latent state dimension.Here we show the advantage of using latent-space models on partially observed data. We change the latent state dimension \(d\) from 1 to 5 and measure the test MAE. Note that for \(d=1\) we effectively have a data-space model which models the observations without trying to reconstruct the missing states. Figure 7 shows that in all cases there is improvement in performance as the latent dimension grows. For Shallow Water and Navier-Stokes the true latent dimension is 3. Since Scalar Flow is a real-world process, there is no true latent dimension. As a benchmark, we provide the performance of our model trained on fully-observed versions of the synthetic datasets (we use the same architecture and hyperparameters, but fix \(d\) to 3). Figure 7 also shows examples of model predictions (at the final time point) for different values of \(d\). We see a huge difference between \(d=1\) and \(d=3,5\). Note how apparently small difference in MAE at \(d=1\) and \(d=5\) for Scalar Flow corresponds to a dramatic improvement in the prediction quality.

Figure 6: **Top: Shallow Water dataset contains observations of the wave height in a pool of water. Middle: Navier-Stokes dataset contains observations of the concentration of a species transported in a fluid via buoyancy and velocity field. Bottom: Scalar Flow dataset contains observations of smoke plumes raising in warm air.**Grid independence.In this experiment we demonstrate the grid-independence property of our model by training it on grids with \( 1100\) observation locations, and then testing on a coarser, original, and finer grids. We evaluate the effect of using different interpolation methods by repeating the experiment with linear, k-nearest neighbors, and inverse distance weighting (IDW) interpolants. For Shallow Water and Navier-Stokes the coarser/finer grids contain \(290\)/\(4200\) nodes, while for Scalar Flow we have \(560\)/\(6420\) nodes, respectively. Table 1 shows the model's performance for different spatial grids and interpolation methods. We see that all interpolation methods perform rather similarly on the original grid, but linear interpolation and IDW tend to perform better on finer/coarser grids than k-NN. Performance drop on coarse grids is expected since we get less accurate information about the system's initial state and simulate the dynamics on coarse grids. Figure 8 also shows examples of model predictions (at the final time point) for different grid sizes and linear interpolant.

Comparison to other models.We test our model against recent spatiotemporal models from the literature: Finite Element Networks (FEN) (Lienen and Gunnemann, 2022), Neural Stochastic PDEs (NSPDE) (Salvi et al., 2021), MAgNet (Boussif et al., 2022), and DINO (Yin et al., 2023). We also use Neural ODEs (NODE) (Chen et al., 2018) as the baseline. We use the official implementation for all models and tune their hyperparameters for the best performance (see App. C for details). For Shallow Water and Navier-Stokes we use the first 5 time points to infer the latent state and then predict the next 20 time points, while for Scalar Flow we use the first 10 points for inference and predict the next 10 points. For synthetic data, we consider two settings: one where the data is fully observed (i.e., the complete state is recorded) - a setting for which most models are designed - and one where the data is partially observed (i.e., only part of the full state

   Dataset & Grid & k-NN & Linear & IDW \\   & Courser & \(0.046 0.002\) & \(0.034 0.001\) & \(0.038 0.002\) \\  & Original & \(0.017 0.002\) & \(0.016 0.002\) & \(0.017 0.003\) \\  & Finer & \(0.031 0.003\) & \(0.017 0.003\) & \(0.030 0.002\) \\   & Courser & \(0.087 0.006\) & \(0.069 0.009\) & \(0.066 0.006\) \\  & Original & \(0.048 0.009\) & \(0.041 0.003\) & \(0.045 0.010\) \\  & Finer & \(0.054 0.009\) & \(0.044 0.004\) & \(0.049 0.002\) \\   & Courser & \(0.041 0.021\) & \(0.032 0.009\) & \(0.035 0.012\) \\  & Original & \(0.019 0.001\) & \(0.018 0.000\) & \(0.018 0.001\) \\   & Finer & \(0.040 0.016\) & \(0.026 0.006\) & \(0.028 0.007\) \\   

Table 1: Test MAE for different interpolation methods.

Figure 8: Predictions on spatial grids of different density (linear interpolant, test data).

Figure 7: **Left: Test MAE vs latent state dimension \(d\). Black lines are test MAE on fully-observed versions of the datasets (\(\) standard error). Right: Model predictions for different \(d\).**

is given, as discussed at the beginning of this section). The results are shown in Table 2. We see that some of the baseline models achieve reasonably good results on the fully-observed datasets, but they fail on partially-observed data, while our model maintains strong performance in all cases. Apart from the fully observed Shallow Water dataset where FEN performs slightly better, our method outperforms other methods on all other datasets by a clear margin. See Appendix C for hyperparameter details. In Appendix E we demonstrate our model's capability to learn dynamics from noisy data. In Appendix F we show model predictions on different datasets.

## 6 Related Work

Closest to our work is Ayed et al. (2022), where they considered the problem of learning PDEs from partial observations and proposed a discrete and grid-dependent model that is restricted to regular spatiotemporal grids. Another related work is that of Nguyen et al. (2020), where they proposed a variational inference framework for learning ODEs from noisy and partially-observed data. However, they consider only low-dimensional ODEs and are restricted to regular grids.

Other works considered learning the latent space PDE dynamics using the "encode-process-decode" approach. Pfaff et al. (2021) use GNN-based encoder and dynamics function and map the observations to the same spatial grid in the latent space and learn the latent space dynamics. Sanchez et al. (2020) use a similar approach but with CNNs and map the observations to a coarser latent grid and learn the coarse-scale dynamics. Wu et al. (2022) use CNNs to map observations to a low-dimensional latent vector and learn the latent dynamics. However, all these approaches are grid-dependent, limited to regular spatial/temporal grids, and require fully-observed data.

Interpolation has been used in numerous studies for various applications. Works such as (Alet et al., 2019; Jiang et al., 2020; Han et al., 2022) use interpolation to map latent states on coarse grids to observations on finer grids. Hua et al. (2022) used interpolation as a post-processing step to obtain continuous predictions, while Boussif et al. (2022) used it to recover observations at missing nodes.

Another approach for achieving grid-independence was presented in neural operators (Li et al., 2021; Lu et al., 2021), which learn a mapping between infinite-dimensional function spaces and represent the mapping in a grid-independent manner.

## 7 Conclusion

We proposed a novel space-time continuous, grid-independent model for learning PDE dynamics from noisy and partial observations on irregular spatiotemporal grids. Our contributions include an efficient generative modeling framework, a novel latent PDE model merging collocation and method of lines, and a data-efficient, grid-independent encoder design. The model demonstrates state-of-the-art performance on complex datasets, highlighting its potential for advancing data-driven PDE modeling and enabling accurate predictions of spatiotemporal phenomena in diverse fields. However, our model and encoder operate on every spatial and temporal location which might not be the most efficient approach and hinders scaling to extremely large grids, hence research into more efficient latent state extraction and dynamics modeling methods is needed.

    & Shallow Water & Shallow Water & Navier Stokes & Navier Stokes &  \\  & (Full) & (Partial) & (Full) & (Partial) & \\  NODE & \(0.036 0.000\) & \(0.084 0.001\) & \(0.053 0.001\) & \(0.109 0.001\) & \(0.056 0.001\) \\ FEN & \(\) & \(0.064 0.005\) & \(0.031 0.001\) & \(0.108 0.002\) & \(0.062 0.005\) \\ SNPDE & \(0.019 0.002\) & \(0.033 0.001\) & \(0.042 0.004\) & \(0.075 0.002\) & \(0.059 0.002\) \\ DINO & \(0.027 0.001\) & \(0.063 0.003\) & \(0.047 0.001\) & \(0.113 0.002\) & \(0.059 0.001\) \\ MAgNet & NA & \(0.061 0.001\) & NA & \(0.103 0.003\) & \(0.056 0.003\) \\ Ours & \(0.014 0.002\) & \(\) & \(\) & \(\) & \(\) \\   

Table 2: Test MAE for different models.