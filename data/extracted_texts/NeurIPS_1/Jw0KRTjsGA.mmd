# CODA: Generalizing to Open and Unseen Domains

with Compaction and Disambiguation

 Chaoqi Chen\({}^{1}\)1 Luyao Tang\({}^{2}\)1 Yue Huang\({}^{2}\)2 Xiaoguang Han\({}^{3}\)2 Yizhou Yu\({}^{1}\)2

\({}^{1}\)The University of Hong Kong \({}^{2}\)Xiamen University

\({}^{3}\)The Chinese University of Hong Kong (Shenzhen)

cqchen1994@gmail.com, lytang@stu.xmu.edu.cn, yhuang2010@xmu.edu.cn

hanxiaoguang@cuhk.edu.cn, yizhouy@acm.org

###### Abstract

The generalization capability of machine learning systems degenerates notably when the test distribution drifts from the training distribution. Recently, Domain Generalization (DG) has been gaining momentum in enabling machine learning models to generalize to unseen domains. However, most DG methods assume that training and test data share an identical label space, ignoring the potential unseen categories in many real-world applications. In this paper, we delve into a more general but difficult problem termed Open Test-Time DG (OTDG), where both _domain shift_ and _open class_ may occur on the unseen test data. We propose Compaction and Disambiguation (CODA), a novel two-stage framework for learning compact representations and adapting to open classes in the wild. To meaningfully regularize the model's decision boundary, CODA introduces virtual unknown classes and optimizes a new training objective to insert unknowns into the latent space by compacting the embedding space of source known classes. To adapt target samples to the source model, we then disambiguate the decision boundaries between known and unknown classes with a test-time training objective, mitigating the adaptivity gap and catastrophic forgetting challenges. Experiments reveal that CODA can significantly outperform the previous best method on standard DG datasets and harmonize the classification accuracy between known and unknown classes.

## 1 Introduction

The ability to generalize to unseen environments is considered a key signature of human intelligence . While deep neural networks have achieved great success in many machine learning problems, they are brittle to distribution shifts between training and test domains, which often occur in real-world applications. For example, when deploying object recognition systems in autonomous vehicles, the ever-changing weather conditions (_e.g._ fog, rain, and snow) may deteriorate the performance and raise concerns about their reliability over time. This motivates a challenging scenario named Domain Generalization (DG) , which extrapolates learning machines to related yet previously unseen test domains by identifying the common factors from available source data.

From the perspective of representation learning, the mainstream paradigm for DG includes invariant risk minimization , domain alignment , feature disentanglement , meta-learning , and augmentation-based invariant prediction . In spite of the significant progress in DG, the adaptivity gap  between source and target domains naturally exists and emerges as an inevitable challenge. Therefore, some prior efforts  strive to adaptthe source-trained model through the lens of test-time adaptation , which uses unlabeled target samples in an online manner. While these methods alleviate the adaptivity gap to some extent, there is still no guarantee for any specific domain, especially if the domain divergence is large . Moreover, most existing DG methods are designed with the assumption that the label space in the source and target domain are identical, which is too restrictive to be satisfied in practice.

To enable machine learning systems to be resilient to an open world, we aim at a more practical yet under-explored problem named Open Test-time Domain Generalization (OTDG), where both _domain shift_ and _open class_ occur in the unseen target data. The primary challenge of the proposed problem lies in addressing two critical aspects: (1) _model generalization_ with an incomplete training label space, and (2) _online model adaptation_ with asymmetric test label space.

Motivated by this, we propose a novel framework for OTDG, termed Compaction and Disambiguation (CODA). Our key idea is to enforce constraints on the decision boundaries during training using labeled source data and refine them during test time using unlabeled target data. To regularize the model's decision boundary and make the model expandable, CODA introduces a set of virtual unknown classes and optimizes a novel training objective in conjunction with the standard cross-entropy loss. The response to known- and unknown-class logits will be activated for both real and synthesized samples. This process embeds unknowns into the latent space by compacting the embedding space of known source classes, thereby reserving sufficient latent space for target unknown classes. To disambiguate the decision boundaries between known and unknown classes, we propose a novel prototype-based test-time adaptation pipeline. Specifically, the test-time classification should be subjected to three constraints: (1) consistency between the predicted class distributions and the estimated class conditionals, (2) class-wise sample reliability for ensuring the quality of target pseudo labels, and (3) semantic consistency between source-trained and present model predictions.

The main contributions are summarized as follows:

* We propose CODA, a simple and effective DG framework to mitigate domain shift and identify open classes in unseen test environments.
* We introduce a virtual unknown optimization process to make the model expandable for open classes, and a test-time training objective to match the real test data to corresponding known and unknown class patterns.
* We conduct extensive experiments and demonstrate that CODA outperforms previous methods on a series of DG benchmarks.

## 2 Preliminaries

**Problem setup.** Let us formally define the OTDG problem. We have access to a source domain \(_{s}=\{(_{s}^{i},y_{s}^{i})\}_{i=1}^{n_{s}}\) of \(n_{s}\) labeled data points and multiple unseen target domains \(_{t}=\{(_{t}^{i})\}_{j=1}^{n_{t}}\) of \(n_{t}\) unlabeled data points. Let \(_{s}\) and \(_{t}\) be the source and target class sets, respectively. In OTDG, we have \(_{s}_{t}\) and \(_{t}^{u}=_{t}_{s}\) is referred to as _unknown_ classes. Assume that \(\) is the input space, \(\) is the latent space, and \(\) is the output space. The predictor \(f=h g\) is comprised of a featurizer \(g:\) that learns to extract embedding features, and a classifier \(h:\) that makes predictions based on the extracted features. The goal of OTDG is to find a predictor \(f:\) that generalizes well to all unseen target domains. Although the labeling function \(h_{t}\) is unknown, we assume that we have access to unlabeled instances from \(_{t}\) at test time. In addition, we present the comparison of different problem settings in Table 1.

**Unknown-aware training.** To solve OTDG, a simple baseline is to train a (\(|_{s}|\)+1)-way classifier , where the additional dimension is introduced to identify the unknown. Formally, we define the standard cross-entropy loss as:

\[_{}(f(),y)=-())}{ _{c|_{s}|+1}(f_{c}())}, \]

where \(f()^{|_{s}|+1}\) denotes the network's logit and \(f_{k}()\) is the \(k\)-th element of \(f()\) corresponding to the ground-truth label \(y\). As shown in Figure 1 (a), however, such optimization fails to activate the network's response to unknown classes. In this work, we first introduce a simple yet very effective baseline  for OTDG. Their key idea is to directly activate the unknown's logit by optimizing its likelihood, without affecting the ground-truth classification. For a source sample \((_{s},y_{s})_{s}\), we minimize the negative log-likelihood _w.r.t._ unknown logit to increase the unknown probability,

\[_{}(f(),y)=_{}(f(),y)-())}{_{c_{s}|+1,c y} (f_{c}())}, \]

where \(f_{u}()\) is the unknown's logit. Eq. 2 makes the unknown class probability respond to any input sample, irrespective of its class label. Since the learning process is driven by the cross-entropy loss related to the ground-truth category, Eq. 2 does not hurt the performance of known classes.

## 3 Proposed Method

We propose CODA (Figure 2), a simple two-stage OTDG framework for discovering unknown classes with the help of known ones. The specific implementation of the two stages is described as follows.

### Training-Time Source Compaction

The source compaction stage preserves sufficient space for the upcoming unknown classes without using real target data during training. Since we have no a _priori_ knowledge or assumptions about the characteristics (_e.g.,_ number and attribute) of unknown classes, it is prohibitively difficult to learn meaningful representations beforehand. To begin with, we make a mild assumption that the unknown classes should be far away from all known classes in the embedding space (category shift). In practice, there are two choices for accommodating these unknown classes: (1) low-density region (Figure 1 (b)), and (2) between-class region (Figure 1 (c)). The former is intuitive and could be achieved via Eq. 2, which naturally corresponds to these regions. However, the multi-modal structure of unknown-class data is underspecified, _i.e.,_ different unknown classes should not occupy the same region. By contrast, the latter is able to implicitly separate different unknowns and model the relationships between known and unknown classes. To make the model expandable, our key idea

    &  &  &  \\    & Training Data & & & & & & Testing Loss & Domain shift & Open class & Adaptivity gap \\  Open-Set DA & \(_{s},y_{s},_{t}\) & \((_{s},y_{s})+(_{s},_{t})\) & – & ✓ & ✓ & ✓ & \(\) \\ Source-Free DA & \(_{t}\) & \((_{t})\) & – & ✓ & \(\) & ✓ & \(\) \\ OOD Detection & \(_{s},y_{s}\) & \((_{s},y_{s})\) & – & \(\) & ✓ & \(\) & ✓ \\ Test-Time Adaptation & \(_{s},y_{s}\) & \((_{s},y_{s})\) & \((_{t})\) & ✓ & \(\) & ✓ & ✓ \\ Test-Time DG & \(_{s},y_{s}\) & \((_{s},y_{s})\) & \((_{t})\) & ✓ & \(\) & ✓ & ✓ \\ Open-Set DG & \(_{s},y_{s}\) & \((_{s},y_{s})\) & – & ✓ & ✓ & \(\) & ✓ \\ OTDG (Ours) & \(_{s},y_{s}\) & \((_{s},y_{s})\) & \((_{t})\) & ✓ & ✓ & ✓ & ✓ \\   

Table 1: Comparison of related machine learning problems. DA refers to Domain Adaptation and OOD stands for Out-of-Distribution. ‘One-pass’ indicates that target domain data only passes the network once during the whole process including the training and testing phases.

Figure 1: The decision boundaries learned by different unknown-aware training objectives: **(a)** Eq. 1, **(b)** Eq. 2, and **(c)** Eq. 3 + Eq. 4. These toy examples are generated by scikit-learn toolkit. Yellow, blue, orange, and pink points represent the known-class samples, while black points are unknown-class samples. Different clusters of back points stand for different unknown classes.

is to compact the source embedding space by _(i)_ making real known samples give response to both known and unknown classes, and _(ii)_ inserting virtual unknown samples between known-class pairs.

**Optimization on real known-class samples.** In addition to the original source classes, we introduce a set of virtual classes \(_{v}\) within the source embedding space to mimic the existence of unknown classes. To accommodate the virtual unknown classes, we regularize the embedding space by pushing known-class samples closer to the decision boundaries:

\[_{}(f(),y)=_{}(f(),y)-}())}{_{c[_{s}|+| _{v}|,c y}(f_{c}())}, \]

where \(f_{}()\) is the unknown's logit, having the largest activation among \(_{v}\).

**Optimization on virtual unknown-class samples.** Despite the activation of the network's response to the introduced unknown classes, the "winner-takes-all" nature of softmax-based classification still leaves the unknown category unable to compete effectively with known ones (cf. Figure 2). To mimic test environments, we synthesize virtual unknown samples. Technically, we synthesize unknown samples at the _feature_ level for model regularization, without using external data, _i.e.,_ dashed points in Fig. 1 (c). We introduce manifold mixup  for synthesizing unknowns in the between-class regions, which are less confident for current decision boundaries. For two random samples \(_{i}\) and \(_{j}\) from different classes, we mix their embedding features as: \(}= g(_{i})+(1-) g(_{j})\), where \(\) is the mixing coefficient. The optimization objective for the synthesized unknown \(}\) is defined as:

\[_{}(h(}),)=_{}(h(}),)-}(})) }{_{c[_{s}|+|_{v}|,c}(h_{c}(}))}, \]

where \(\) represents the label of \(\) regarding unknown class, _i.e.,_ having the largest activation among \(_{v}\). \(h_{k^{}}(})\) is the known's logit, having the largest activation among \(_{s}\). The first term in Eq. 4 is a standard self-training loss. Similar to Eq. 3, the second term activates the response of \(}\) to its most related known class. In essence, apart from the standard classification loss (the first term in Eq. 3 and Eq. 4), we activate the response of the real known class towards unknowns (Eq. 3) and the response of the virtual unknown class towards the known ones (Eq. 4).

Figure 2: Overview of the proposed CODA, which consists of two novel components: (1) Training-time source **compaction** to make the model expandable for open classes; (2) Test-time target **disambiguation** to discriminate the decision boundaries with a test-time training objective.

### Test-Time Target Disambiguation

Although we have allocated the embedding space for unknown classes, how to deploy the source-trained model on real test data is yet to be thoroughly studied. In particular, we identify two major challenges: (i) _optimality gap_ between source and target domains, and (ii) _catastrophic forgetting_ in open and dynamic test environments. In OTDG, we define the optimality gap as follows.

**Definition 1** (Optimality Gap): _Let \(\{h|h\,:\,\}\) be the hypothesis class. \(_{S}()\) and \(_{T}()\) denote the expected risk on source and target domains. For any hypothesis \(h\), we have \(_{T}(h^{t})<_{T}(h^{*})\), where \(h^{*}=_{h}_{S}(h)+_{T}(h)\) and \(h^{t}=_{h}_{T}(h)\)._

Definition 1 suggests that it is not feasible to find a _universal_ optimal classifier that applies to both source and target domains. In that sense, the classifier, initially trained on source data, needs additional refinement to adapt effectively to the target patterns. Technically, we resort to TTA  to mitigate the above issues using unlabeled test data in an online manner. Conventional training-based TTA methods  usually need batches of data for self-training (_e.g._ entropy minimization) and/or heuristic self-supervision tasks . On the other hand, training-free methods  require expensive tweaking of the threshold and only bring a marginal performance gain. Moreover, these approaches struggle to handle open-class scenarios, making them susceptible to negative transfer (_i.e._ semantic misalignment). To address these challenges, our proposed target disambiguation stage aligns the unlabeled target samples to their corresponding class patterns through the following process.

We construct a memory bank \(=\{^{1},,^{|_{s}|+|_ {v}|}\}\) for memorizing the embedding \(\) and logits \(f()\) (or \(h()\)) of target samples. We compute a set of class prototypes \(\{_{k}\}_{k=1}^{|_{s}|+|_{v}|}\) based on logits in \(\). Following , the memory bank is initialized with the weights of the linear classifier. Let \(()\) be the Nearest Neighbor (NN) of \(\) in \(\). For each test sample \(^{3}\), we search its NN in \(\) by: \(():=\{|(g(), )_{}\}\), where \(()\) is the cosine similarity and \(_{}\) is a threshold to control the number of NN. The model predictions would be given by the similarity between sample embedding and the class prototype, _i.e._, \(p(y|)_{k},\). Formally, for \(()\), the likelihood of the prototype-based classifier assigning \(\) to the \(k\)-th class can be calculated as follows:

\[p(y=k|)=(h(),_{k})/)}{ _{c}(-(h(),_{c})/)},\ k=1,2,...,| _{s}|+|_{v}|, \]

where \(\) is a temperature scaling parameter. We estimate the class conditionals with \(()\) as:

\[}_{k}=()|}_{ ()}1(*{arg\,max}_{c}p(c|)=k), \]

where \(()\) is an indicator function. Then, we can update the global class prototype computed from the whole \(\) in a moving-average style,

\[_{k}_{k}+(1-)}_{k}, \]

where \(\) is a preset scalar and \(}_{k}\) can be regarded as the local class prototype. Given a batch of test samples \(_{t}\), we use self-training for model updating (\(g\) and \(h\)), _i.e._, minimizing the cross-entropy loss between classifier's prediction \(f()\) and the estimated class prior distribution \(_{k}\):

\[_{}()=_{t}|}_{x _{t}}_{}(_{k},f()), \]

**Semantic consistency.** To resist catastrophic forgetting during the online adaptation process, we enforce semantic consistency between the output of \(f_{0}\) (source-trained model) and \(f_{I}\) (target model) by optimizing the cross-entropy loss between their predictions:

\[_{}()=-(f_{0}())(f_{I} ()), \]

where \(I\) represents the number of iterations and \(f_{0}\) is fixed throughout the testing phase.

**Reliable sample selection.** In the early stage of training, the estimation of target pseudo labels may be unreliable and thus is risky to error accumulation. To improve the quality of pseudo labels andreduce the influence of false class estimations, we introduce an entropy-based weighting strategy to select reliable samples. Specifically, we define the scoring function as follows:

\[S()=(H()<_{0})(_{0}-H( )), \]

where \(H()\) is the Shannon entropy of sample and \(_{0}\) is a pre-defined threshold. In this way, we can allocate larger weights to target samples with lower uncertainties and smaller weights to those with higher uncertainties, effectively prioritizing more confident predictions.

**Test-time training objective.** Formally, the overall optimization objective can be formulated as:

\[_{}()=S()_{}( )+_{}(), \]

where \(\) is a trade-off parameter. The proposed \(_{}\) embraces the complementary strengths of parametric (softmax-based) and non-parametric (prototype-based) classifiers.

## 4 Experiments

### Setup

**Benchmarks.** We conduct extensive experiments on four standard DG benchmarks to verify the effectiveness of CODA. **(1) PACS** has 9,991 images and presents remarkable distinctions in image styles. It is comprised of four domains each with seven classes, _i.e., Photo_, _Art Painting_, _Cartoon_, and _Sketch_. Dog, elephant, giraffe, and guitar are used as \(_{s}\) while the remaining 3 classes are \(_{t}^{u}\). **(2) Office-Home** is gathered from both office and home environments, and its domain shifts originate from variations in viewpoint and image style. It has 15,500 images of 65 classes from four domains, _i.e., Artistic_, _Clipart_, _Product_, and _Real World_. Arranged in alphabetical order, the initial 15 classes are designated as \(_{s}\), and the remaining 50 classes are assigned to \(_{t}^{u}\). **(3) Office-31** encompasses 31 classes harvested from three distinct domains: _Amazon_, _DSLR_, and _Webcam_. The 10 classes shared by Office-31 and Caltech-256  are used as \(_{s}\). In alphabetical order, the final 11 classes, combined with \(_{s}\), constitute \(_{t}\). **(4) Digits**, a dataset varying in background, style, and color, encompasses four domains of handwritten digits, including _MNIST_, _MNIST-M_, _SVHN_, _USPS_, and _SYN_. We utilize _MNIST_ as the source domain, while the other datasets serve as target domains. Numbers from 0 to 4 make up \(_{s}\).

**Evaluation Protocols.** In line with prior works [5; 90; 77], we utilize the H-score (\(hs\))  as our main evaluation criterion. The \(hs\) score balances the significance between known and unknown classes, emphasizing that both groups should have high and equivalent accuracy. Additionally, the \(hs\) score circumvents the trivial solution where a model would predict all samples as known classes. The classification accuracy for both known (\(acc_{k}\)) and unknown (\(acc_{u}\)) classes are also reported.

**Implementation Details.** For PACS, Office-Home, and Office-31, we employ ResNet-18 , pre-trained on ImageNet, as the backbone network. For Digits, we employ the LeNet  with the architecture arranged as _conv-pool-conv-pool-fc-fc-softmax_. The training is performed using SGD with a momentum of 0.9 for 100 epochs, and we set the batch size to 64. Our experiments are built upon Dassl  (a PyTorch toolbox developed for DG), covering aspects of data preparation, model training, and model selection. We report the means over 5 runs with different random seeds.

### Baselines

In experiments, we empirically compare CODA against five types of baselines: **(1) OSDG:** CM  and One Ring-S . **(2) OSDA:** OSBP  and ROS . **(3) OD:** MSP , LogitNorm , and DICE . **(4) SFDA:** SHOT  and AaD . **(5) TTA:** TTT , Tent , MEMO , TAST , and FAU . Since TTA methods are incapable of directly handling unknown-class samples, we adopt the approach from , using the entropy of the softmax output as the final prediction. For ERM , we follow the same strategy for identifying unknowns.

### Results

Our results are summarized in Table 2. For each dataset, CODA outperforms all compared methods by a considerable margin in terms of \(hs\). For instance, in comparison to the previous best-performing OSDG baseline , CODA achieves increases in \(hs\) by 16.8% for PACS, 4.0% for Office-Home,9.7% for Office-31, and 1.0% for Digits. If we focus on the hard generalization tasks, such as PACS, CODA exhibits larger performance gains than on other tasks. Moreover, three trends can be observed: (1) Compared to OSDA and SFDA methods that usually optimize with target data offline, CODA achieves superior performance in an online adaptation manner. (2) The \(acc_{k}\) and \(acc_{u}\) of Tent  and LogitNorm  exhibit significant imbalance as both methods tend to predict all data as known-class samples (_i.e._ shortcut learning). This verifies the benefits of CODA in mitigating shortcut learning. (3) OD methods achieve very competitive results compared to other types of baselines. The rationale is that they usually do not involve test-time adjustment and thus have better stability. (4) The performance of different types of baseline methods varies across benchmarks. For instance, MEMO (TTA) achieves the second-best result in PACS but has relatively inferior performance in Office-Home and Digits. Instead, CODA exhibits consistent improvements on all benchmarks.

In addition, we provide performance comparisons of different methods (_i.e.,_ ERM , MSP , TAST , and our CODA) as testing proceeds on the PACS dataset (trained on domain _Art Painting_). To facilitate a fair comparison, both MSP and TAST will apply to the models that have been trained by our source compaction stage. Figure 3 shows that ERM and TAST substantially increase \(acc_{k}\) and maintain it at a very high level, which severely impedes the improvements of \(hs\). Interestingly, as the number of testing epochs increases, TAST underperforms compared to ERM. By contrast, CODA dynamically harmonizes the relations between \(acc_{k}\) and \(acc_{u}\) (_i.e.,_ suppresses \(acc_{k}\) and hence allows \(acc_{u}\) to grow), which is reflected by the monotonic increase of \(hs\). Figure 4 shows Grad-CAM  visualizations of baseline (ERM) and our method (CODA) on the PACS dataset. We can see that the hot zones activated by CODA are more complete and reasonable, providing a reliable semantic understanding of the foreground object.

    &  &  &  &  &  \\   & & \(acc_{k}\) & \(acc_{u}\) & \(hs\) & \(acc_{k}\) & \(acc_{u}\) & \(hs\) & \(acc_{k}\) & \(acc_{u}\) & \(hs\) & \(acc_{k}\) & \(acc_{u}\) & \(hs\) \\   & OSBP  & 40.6 & 49.5 & 44.6 & 47.1 & 66.9 & 55.3 & 75.8 & 84.3 & 77.7 & 35.6 & 70.6 & 40.5 \\  & ROS  & 35.6 & 66.4 & 46.4 & 50.8 & 77.5 & 60.8 & 71.7 & 80.0 & 75.6 & 20.1 & 48.6 & 34.9 \\   & MSP  & 38.9 & 62.5 & 46.4 & 52.7 & 75.6 & 62.0 & 49.7 & 89.2 & 63.8 & 17.2 & 87.1 & 28.8 \\  & LogitNorm  & 35.1 & 47.6 & 38.3 & 56.3 & 56.5 & 56.1 & 41.0 & 71.2 & 52.1 & 26.8 & 51.2 & 35.2 \\  & DICE  & 44.0 & 53.4 & 49.2 & 61.5 & 58.8 & 59.9 & 72.8 & 61.1 & 66.4 & 35.0 & 47.6 & 40.3 \\   & SHOT  & 51.2 & 34.9 & 40.8 & 52.5 & 32.4 & 44.3 & 84.8 & 60.2 & 70.4 & 27.4 & 20.3 & 23.3 \\  & BaD  & 45.1 & 40.0 & 42.0 & 59.4 & 58.7 & 58.9 & 70.1 & 85.3 & 76.9 & 25.6 & 26.9 & 26.2 \\   & TTT  & 36.9 & 44.6 & 38.9 & 52.0 & 45.9 & 47.2 & 35.4 & 79.6 & 49.0 & 40.1 & 41.1 & 40.6 \\  & Tent  & 25.2 & 43.1 & 31.7 & 33.6 & 45.9 & 38.7 & 56.0 & 85.1 & 67.5 & 27.2 & 41.1 & 32.7 \\  & MEMO  & 37.9 & 52.3 & 44.5 & 49.0 & 55.6 & 52.1 & 59.8 & 72.7 & 65.6 & 21.7 & 56.1 & 31.3 \\   & ADA  & 54.2 & 30.9 & 36.4 & 67.9 & 25.4 & 36.2 & 85.6 & 25.2 & 38.7 & 57.2 & 15.1 & 20.1 \\  & ADA+CM  & 56.4 & 45.6 & 43.0 & 65.0 & 40.4 & 48.5 & 83.0 & 34.5 & 48.5 & 49.2 & 52.1 & 39.9 \\  & MEADA  & 54.1 & 31.4 & 36.2 & 67.6 & 25.7 & 36.4 & 85.8 & 25.1 & 38.6 & 57.6 & 29.8 & 30.4 \\  & MEADA+CM  & 54.3 & 46.6 & 42.7 & 64.9 & 40.5 & 49.6 & 82.8 & 41.1 & 54.7 & 52.3 & 46.1 & 38.7 \\  & One Ring-S  & 43.7 & 49.4 & 41.5 & 56.9 & 69.0 & 62.3 & 67.3 & 77.0 & 71.3 & 33.2 & 51.3 & 40.3 \\   & ERM  & 52.3 & 27.0 & 36.1 & 66.9 & 23.7 & 34.3 & 85.1 & 27.0 & 40.7 & 56.4 & 13.0 & 18.0 \\  & CODA (ours) & 54.3 & 63.8 & **58.3** & 59.7 & 74.6 & **66.3** & 87.5 & 75.4 & **81.0** & 31.5 & 60.1 & **41.3** \\   

Table 2: Accuracy (%) on PACS, Office-Home, Office-31, and Digits datasets.

Figure 4: _Top:_ ERM. _Bottom:_ CODA.

Figure 3: Performance comparisons of different methods as testing proceeds on the PACS dataset.

### Ablation Studies

**Ablations of key components in CODA.** We carry out ablation studies in Table 3, evaluating the effect of source compaction (SC) and target disambiguation (TD) proposed in CODA. When we exclude SC from CODA, model predictions are made based on the entropy of the output in conjunction with a predetermined threshold . From the table, we can observe that adding SC and TD could improve the generalization performance, which verifies their individual contributions for solving domain shifts and open classes. Moreover, our method that integrates both SC and TD achieves the best performance, revealing the synergistic effect between the two components.

**Analysis on target disambiguation.** In Figure 5, we plot the predictions on known- and unknown-class test samples from the models trained with and without target disambiguation. The left image is a battery (known), and the right image is a clipboard (unknown). For the known classes, a model lacking disambiguation often makes uncertain predictions, especially for hard samples that bear high resemblance to other classes. For the unknown class, a model without disambiguation tends to give a high response to an incorrect class and suppress responses to other classes. In contrast, our target disambiguation stage can achieve more accurate predictions by recovering the semantic relationships among classes from unlabeled data, thereby enhancing the model's generalization performance under both domain shift and open classes. In Figure 6 (a)-(b), we investigate the the impact of varying the test batch size on three methods, TAST , FAU , and CODA (ours). As the batch size varies, CODA consistently delivers superior performance compared to TAST and FAU, revealing the advantages of the proposed online adaptation strategy.

**Analysis on unknown-aware training objective.** We empirically compare different unknown-aware training objectives discussed in Section 2 and Section 3.1, _i.e.,_ Eq.(1)-(4) and their combinations. For a fair comparison, we do not involve any TTA strategies including our target disambiguation. The results are reported in Table 4. We can observe that our full source compaction is clearly better than its variants, revealing the superiority of our optimization procedures on both real known-class samples and virtual unknown-class samples.

**Analysis on unknown classes.** In Figure 6 (c)-(d), we study the impact of varying the number of known classes on three methods, ERM , One Ring-S , and CODA (ours). Note that the total number of classes (_i.e._\(|_{s}_{t}|\)) remains unchanged. Even when the number of known classes is small, CODA still exhibits superior performance. This advantage remains consistent as the number of known classes changes. Consequently, CODA is capable of handling extreme scenarios.

**Feature visualization.** We use \(t\)-SNE  to visualize the features of four models on Office-31 dataset, _i.e.,_ ERM, One Ring-S, Source Compaction, and CODA (full). The results are depicted in Figure 7, where various colors, excluding gray, signify different known classes, and gray points represent all unknown classes. It is noteworthy that the embedding features learned by two baselines (ERM and One Ring-S) fail to present a clear separation, resulting in ambiguous boundaries among

   Method & PACS & Office-Home & Office-31 & Digits \\  Eq. 1 & 36.1 & 34.3 & 40.7 & 18.0 \\ Eq. 2 & 41.1 & 58.9 & 63.0 & 39.3 \\ Eq. 3 & 46.8 & 62.4 & 72.6 & 38.6 \\ Eq. 4 & 43.2 & 60.3 & 70.7 & 37.4 \\ Eq. 3 + Eq. 4 & 51.2 & 64.8 & 75.3 & 39.0 \\   

Table 4: Analysis on unknown-aware training objective.

Figure 5: Predictions from models trained with and without target disambiguation.

   SC & TD & PACS & Office-Home & Office-31 & Digits \\  \(\) & \(\) & 36.1 & 34.3 & 40.7 & 18.0 \\ \(\) & \(\) & 51.2 & 64.8 & 75.3 & 39.0 \\ \(\) & \(\) & 49.8 & 61.7 & 72.3 & 37.5 \\ \(\) & \(\) & 58.3 & 66.3 & 81.0 & 41.3 \\   

Table 3: Ablation of CODA on four classification benchmarks. \(hs\) (%) is reported.

different classes particularly between known and unknown ones. Instead, CODA can learn the intrinsic structure ("manifold") of the target samples, providing more discriminable clustering patterns.

## 5 Related Work

**Domain Generalization (DG).** DG is concerned with the training of a model using data from either multiple or a single source domain, with the goal of achieving good generalization to previously unseen target domains. Mainstream approaches usually involve invariant learning and robust learning with elaborate training objectives. Based on the focus of this paper, we classify existing methods into three categories and provide descriptions as follows. **(1) Closed-set DG.** Existing methods can be roughly divided into four categories: feature matching-based [32; 31; 40; 91; 83], decomposition-based [46; 45; 13; 39; 54; 36; 78], augmentation-based [65; 85; 86; 74; 41; 88; 8], and meta-learning-based approaches [29; 33; 30; 37; 7]. **(2) Open-set DG.** It is worth noting that very few works have delved into the exploration of DG in open-set scenarios. A handful of recent studies [53; 90; 77; 9] started to consider the existence of both known and unknown classes in novel DG settings, such as Open-Set DG (OSDG) [90; 77]. For example, Yang _et al._ hold the view that any category other than the ground-truth can be considered as part of the unknown classes. Chen _et al._ first activate the unknown's logit via an unknown-aware training loss and then introduce a test-time adjustment strategy to refine the model prediction. Zhu _et al._ rely on heuristic thresholding mechanisms to distinguish known- and unknown-class samples. **(3) DG by test-time adaptation.** According to Dubey _et al._, a model trained solely on source data will inevitably experience an "adaptivity gap" when it is directly employed on target domains, emphasizing the necessity of on-target adaptation. Grounded on this insight, several recent works [79; 73; 72; 11] resort to TTA for mitigating the adaptivity gap, such as adaptive risk minimization , energy-based sample adaptation , and improved self-supervised learning tasks .

**Test-Time Adaptation (TTA).** TTA  is an emerging paradigm that has demonstrated immense potential in adapting pre-trained models to unlabeled data during the testing phase. A plethora of approaches [35; 58; 67; 23; 43; 10; 80; 69] have been developed to improve the predictions of source-trained models on target domain with online training/adaptation strategies. TTT  introduces self-supervised learning tasks (_e.g._ rotation classification) to both source and target domains. Tent  leverages the batch statistics of the target domain and optimizes the channel-wise affine parameters by entropy minimization. T3A  proposes to use class prototypes for adjusting predictions and introduces a support set to memorize representative and reliable samples. TAST  improves T3A by proposing a nearest neighbor information induced self-training framework.

Figure 6: (a)-(b) The influence of test batch size. (c)-(d) The influence of varying the number of known classes. Figures (a) and (c) are plotted based on the Office-Home dataset, while figures (b) and (d) are derived from the PACS dataset.

Figure 7: t-SNE visualization of the learned features on the Office-31 dataset.

**Out-of-Distribution Detection (OD).** OD , which seeks to identify novel instances that the model has not encountered during training, is close to OTDG setting. Prevailing OD methods center on creating OOD scoring functions, for example, confidence-based techniques , distance-based scores , and energy-based scores . Although promising, the OD approach is limited to binary classification problems and lacks the capability to effectively explore domain shift and open class challenges in the test data.

There are also other topics related to open-world machine learning  that bear certain relevance to our work, including open-set recognition , novel class discovery , zero-shot learning , and class-incremental learning , to name a few. Compared to previous methods, our work addresses two types of open-world situations (_i.e.,_ domain shift and open class), supporting generalization capabilities consistently throughout the training and inference phases.

## 6 Conclusion

In this paper, we solve the problem of OTDG where both domain shift and open classes may concurrently arise on the unseen test data. We introduce a two-stage framework (CODA) for efficiently learning what we don't know in the wild. At the training stage, we compact the embedding of source known classes and thus reserve space for target unknown classes. In the testing phase, we introduce a training objective to mitigate the optimality gap between domains while avoiding catastrophic forgetting. Empirically, CODA achieves superior performance on standard DG benchmarks.