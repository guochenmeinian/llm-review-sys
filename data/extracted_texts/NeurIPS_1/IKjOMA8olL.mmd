# Towards Label Position Bias

in Graph Neural Networks

Haoyu Han\({}^{1}\), Xiaorui Liu\({}^{2}\), Feng Shi\({}^{3}\),

**MohamadAli Torkamani\({}^{4}\), Charu C. Aggarwal\({}^{5}\), Jiliang Tang\({}^{1}\) \({}^{1}\)**Michigan State University \({}^{2}\)North Carolina State University \({}^{3}\)TigerGraph \({}^{4}\) Amazon \({}^{5}\)IBM T.J. Watson Research Center {hanhaoy1,tangjili}@msu.edu, xliu96@ncsu.edu bill.shi@tigergraph.com, alitor@amazon.com, charu@us.ibm.com

This work does not relate to the author's position at Amazon

###### Abstract

Graph Neural Networks (GNNs) have emerged as a powerful tool for semi-supervised node classification tasks. However, recent studies have revealed various biases in GNNs stemming from both node features and graph topology. In this work, we uncover a new bias - label position bias, which indicates that the node closer to the labeled nodes tends to perform better. We introduce a new metric, the Label Proximity Score, to quantify this bias, and find that it is closely related to performance disparities. To address the label position bias, we propose a novel optimization framework for learning a label position unbiased graph structure, which can be applied to existing GNNs. Extensive experiments demonstrate that our proposed method not only outperforms backbone methods but also significantly mitigates the issue of label position bias in GNNs.

## 1 Introduction

Graph is a foundational data structure, denoting pairwise relationships between entities. It finds applications across a range of domains, such as social networks, transportation, and biology. [1; 2] Among these diverse applications, semi-supervised node classification has emerged as a crucial and challenging task, attracting significant attention from researchers. Given the graph structure, node features, and a subset of labels, the semi-supervised node classification task aims to predict the labels of unlabeled nodes. In recent years, Graph Neural Networks (GNNs) have demonstrated remarkable success in addressing this task due to their exceptional ability to model both the graph structure and node features . A typical GNN model usually follows the message-passing scheme , which mainly contains two operators, i.e., feature transformation and feature propagation, to exploit node features, graph structure, and label information.

Despite the great success, recent studies have shown that GNNs could introduce various biases from the perspectives of node features and graph topology. In terms of node features, Jiang et al.  demonstrated that the message-passing scheme could amplify sensitive node attribute bias. A series of studies [6; 7; 8] have endeavored to mitigate this sensitive attribute bias in GNNs and ensure fair classification. In terms of graph topology, Tang et al.  investigated the degree bias in GNNs, signifying that high-degree nodes typically outperform low-degree nodes. This degree bias has also been addressed by several recent studies [10; 11; 12].

In addition to node features and graph topology, the label information, especially the position of labeled nodes, also plays a crucial role in GNNs. However, the potential bias in label information has been largely overlooked. In practice, with an equal number of training nodes, different labeling can result in significant discrepancies in test performance [13; 14; 15]. For instance, Ma et al.  studythe subgroup generalization of GNNs and find that the shortest path distance to labeled nodes can also affect the GNNs' performance, but they haven't provided deep understanding or solutions. The investigation of the influence of labeled nodes' position on unlabeled nodes remains under-explored.

In this work, we discover the presence of a new bias in GNNs, namely the label position bias, which indicates that the nodes "closer" to the labeled nodes tend to receive better prediction accuracy. We propose a novel metric called Label Proximity Score (LPS) to quantify and measure this bias. Our study shows that different node groups with varied LPSs can result in a significant performance gap, which showcases the existence of label position bias. More importantly, this new metric has a much stronger correlation with performance disparity than existing metrics such as degree  and shortest path distance , which suggests that the proposed Label Proximity Score might be a more intrinsic measurement of label position bias.

Addressing the label position bias in GNNs is greatly desired. First, the label position bias would cause the fairness issue to nodes that are distant from the labeled nodes. For instance, in a financial system, label position bias could result in unfair assessments for individuals far from labeled ones, potentially denying them access to financial resources. Second, mitigating this bias has the potential to enhance the performance of GNNs, especially if nodes that are distant can be correctly classified. In this work, we propose a Label Position unbiased Structure Learning method (LPSL) to derive a graph structure that mitigates the label position bias. Specifically, our goal is to learn a new graph structure in which each node exhibits similar Label Proximity Scores. The learned graph structure can then be applied across various GNNs. Extensive experiments demonstrate that our proposed LPSL not only outperforms backbone methods but also significantly mitigates the issue of label position bias in GNNs.

## 2 Label Position Bias

In this section, we provide an insightful preliminary study to reveal the existence of label position bias in GNNs. Before that, we first define the notations used in this paper.

**Notations**. We use bold upper-case letters such as \(\) to denote matrices. \(_{i}\) denotes its \(i\)-th row and \(_{ij}\) indicates the \(i\)-th row and \(j\)-th column element. We use bold lower-case letters such as \(\) to denote vectors. \(_{}^{n 1}\) is all-ones column vector. The Frobenius norm and the trace of a matrix \(\) are defined as \(\|\|_{F}=_{ij}^{2}}\) and \(tr()=_{i}_{ii}\), respectively. Let \(=(,)\) be a graph, where \(\) is the node set and \(\) is the edge set. \(_{i}\) denotes the neighborhood node set for node \(v_{i}\). The graph can be represented by an adjacency matrix \(^{n n}\), where \(_{ij}>0\) indices that there exists an edge between nodes \(v_{i}\) and \(v_{j}\) in \(\), or otherwise \(_{ij}=0\). Let \(=diag(d_{1},d_{2},,d_{n})\) be the degree matrix, where \(d_{i}=_{j}_{ij}\) is the degree of node \(v_{i}\). The graph Laplacian matrix is defined as \(=-\). We define the normalized adjacency matrix as \(}=^{-}^{-}\) and the normalized Laplacian matrix as \(}=-}\). Furthermore, suppose that each node is associated with a \(d\)-dimensional feature \(\) and we use \(=[_{1},,_{n}]^{}^{n  d}\) to denote the feature matrix. In this work, we focus on the node classification task on graphs. Given a graph \(=\{,\}\) and a partial set of labels \(_{L}=\{_{1},,_{l}\}\) for node set \(_{L}=\{v_{1},,v_{l}\}\), where \(_{i}^{c}\) is a one-hot vector with \(c\) classes, our goal is to predict labels of unlabeled nodes. For convenience, we reorder the index of nodes and use a mask matrix \(=_{l}&0\\ 0&0\) to represent the indices of labeled nodes.

**Label Proximity Score.** In this study, we aim to study the bias caused by label positions. When studying prediction bias, we first need to define the sensitive groups based on certain attributes or metrics. Therefore, we propose a novel metric, namely the Label Proximity Score, to quantify the closeness between test nodes and training nodes with label information. Specifically, the proposed Label Proximity Score (LPS) is defined as follows:

\[LPS=_{},\;\;\;\;=(-( 1-)})^{-1}, \]

where \(\) represents the Personalized PageRank matrix, \(\) is the label mask matrix, \(_{}\) is an all-ones column vector, and \((0,1]\) stands for the teleport probability. \(_{ij}\) represents the pairwise node proximity between node \(i\) and node \(j\). For each test node \(i\), its LPS represents the sum of its node proximity values to all labeled nodes, i.e., \((_{n})_{i}=_{i,:}_{n}=_{j_ {L}}_{ij}\).

**Sensitive Groups.** In addition to the proposed LPS, we also explore two existing metrics such as node degree  and shortest path distance to label nodes  for comparison since they could be related to the label position bias. For instance, the node with a high degree is more likely to connect with labeled nodes, and the node with a small shortest path to a labeled node is also likely "closer" to all labeled nodes if the number of labeled nodes is small. According to these metrics, we split test nodes into different sensitive groups. Specifically, for node degree and shortest path distance to label nodes, we use their actual values to split them into seven sensitive groups, as there are only very few nodes whose degrees or shortest path distances are larger than seven. For the proposed LPS, we first calculate its value and subsequently partition the test nodes evenly into seven sensitive groups, each having an identical range of LPS values.

**Experimental Setup**. We conduct the experiments on three representative datasets used in semi-supervised node classification tasks, namely Cora, CiteSeer, and PubMed. We also experiment with three different labeling rates: 5 labels per class, 20 labels per class, and 60% labels per class. The experiments are performed using two representative GNN models, GCN  and APPNP , which cover both coupled and decoupled architectures. We also provide the evaluation on Label Propagation (LP)  to exclude the potential bias caused by node features. For GCN and APPNP, we adopt the same hyperparameter setting with their original papers. The node classification accuracy on different sensitive groups \(\{1,2,3,4,5,6,7\}\) with the labeling rate of 20 labeled nodes per class under APPNP, GCN, and LP models is illustrated in Figure 1, 2, and 3 respectively. Due to the space limitation, we put more details and results of other models, datasets, and labeling rates into Appendix A.

**Observations.** From the results presented in Figure 1, 2, and 3, we can observe the following:

* Label Position bias is prevalent across all GNN models and datasets. The classification accuracy can notably vary between different sensitive groups, and certain trends are discernible. To

Figure 1: APPNP with 20 labeled nodes per class on Cora and CiteSeer datasets.

Figure 3: LP with 20 labeled nodes per class on Cora and CiteSeer datasets.

Figure 2: GCN with 20 labeled nodes per class on Cora and CiteSeer datasets.

ensure fairness and improve performance, addressing this bias is a crucial step in improving GNN models.
* While Degree and Shortest Path Distance (SPD) can somewhat reflect disparate performance, indicating that nodes with higher degrees and shorter SPDs tend to perform better, these trends lack consistency, and they can't fully reflect the Label Position bias. For instance, degree bias is not pronounced in the APPNP model as shown in Figure 1, as APPNP can capture the global structure. Moreover, SPD fails to effectively evaluate relatively low homophily graphs, such as CiteSeer . Consequently, there is a need to identify a more reliable metric.
* The Label Proximity Score (LPS) consistently exhibits a strong correlation with performance disparity across all datasets and models. Typically, nodes with higher LPS scores perform better. In addition, nodes with high degrees and low Shortest Path Distance (SPD) often have higher LPS, as previously analyzed. Therefore, LPS is highly correlated with label position bias.
* The Label Propagation, which solely relies on the graph structure, demonstrates a stronger label position bias compared to GNNs as shown in Figure 3. Moreover, the label position bias becomes less noticeable in all models when the labeling rate is high, as there typically exist labeled nodes within the two-hop neighborhood of each test node (detailed in Appendix A). These observations suggest that the label position bias is predominantly influenced by the graph structure. Consequently, this insight motivates us to address the Label Position bias from the perspective of the graph structure.

In conclusion, label position bias is indeed present in GNN models, and the proposed Label Proximity Score accurately and consistently reflects the performance disparity over different sensitive groups for different models across various datasets. Overall, the label proximity score exhibits more consistent and stronger correlations with performance disparity compared with node degree and shortest path distance, which suggests that LPS serves as a better metric for label position bias. Further, through the analysis of the Label Propagation method and the effects of different labeling rates, we deduce that the label position bias is primarily influenced by the graph structure. This understanding paves us a way to mitigate label position bias.

## 3 The Proposed Framework

The studies in Section 2 suggest that Label Position bias is a prevalent issue in GNNs. In other words, nodes far away from labeled nodes tend to yield subpar performance. Such unfairness could be problematic, especially in real-world applications where decisions based on these predictions can have substantial implications. As a result, mitigating label position bias has the potential to enhance the fairness of GNNs in real-world applications, as well as improve overall model performance. Typically, there are two ways to address this problem, i.e., from a model-centric or a data-centric perspective. In this work, we opt for a data-centric perspective for two primary reasons: (1) The wide variety of GNN models in use in real-world scenarios, each with its unique architecture, makes it challenging to design a universal component that can be seamlessly integrated into all GNNs to mitigate the label position bias. Instead, the graph structure is universal and can be applied to any existing GNNs. (2) Our preliminary studies indicate that the graph structure is the primary factor contributing to the label position bias. Therefore, it is more rational to address the bias by learning a label position unbiased graph structure.

However, there are mainly two challenges: (1) How can we define a label position unbiased graph structure, and how can we learn this structure based on the original graph? (2) Given that existing graphs are typically sparse, how can we ensure that the learned data structure is also sparse to avoid excessive memory consumption? In the following subsections, we aim to address these challenges.

### Label Position Unbiased Graph Structure Learning

Based on our preliminary studies, the Label Proximity Score (LPS) can consistently reflect performance disparity across various GNNs and indicate the label position bias. Therefore, to mitigate the label position bias from the structural perspective, our objective is to learn a new graph structure in which each node exhibits similar LPSs. Meanwhile, this learned unbiased graph structure should maintain certain properties of the original graph. To achieve this goal, we formulate the Label PositionUnbiased Structure Learning (LPSL) problem as follows:

\[*{arg\,min}_{}\|- \|_{F}^{2}+(^{}} )\\ _{n}=c_{n},_{ij}  0 i,j \]

where \(^{n n}\) represents the debiased graph structure matrix. \((^{}})=_{(v_{i},v_{j}) }\|_{i}/}-_{j}/}\|_{2} ^{2}\) measures the smoothness of the new structure based on the original graph structure. The proximity to identity matrix \(^{n n}\) encourages self-loops and avoids trivial over-smoothed structures. \(\) is a hyperparameter that controls the balance between smoothness and self-loop. \(\) is the mask matrix indicating the labeled nodes, \(_{}\) is the all-ones vector, and \(c\) is a hyperparameter serving as the uniform Label Proximity Score for all nodes. Due to the \(\) represents the graph structure, we have the constraint that all elements in \(\) should be non-negative.

Notably, if we ignore the constraint, then the optimal solution for this primary problem is given by \(=(+)^{-1}=(-(1- }))^{-1}\), where \(=\). This solution recovers the Personalized PageRank (PPR) matrix which measures pairwise node proximity. Furthermore, the constraint in Eq. (2) ensures that all nodes have the same Label Proximity Score, denoted as \(c\). The constraint encourages fair label proximity scores for all nodes so that the learned graph structure mitigates the label position bias.

The constrained optimization problem in Eq. (2) is a convex optimization problem, and it can be solved by the Lagrange Multiplier method with the projected gradient descent . The augmented Lagrange function can be written as:

\[L_{}(,)=\|-\|_{F}^{2}+ (^{}})+^{}( _{n}-c_{n})+\|_{n}-c_{n}\|_{2}^{2}, \]

where \(^{n 1}\) is the introduced Lagrange multiplier, and \(>0\) represents the augmented Lagrangian parameter. The gradient of \(L_{}(,)\) to \(\) can be represented as:

\[}{}=2(-)+2 }+(_{n})^{}+(_{n}-c_{n})(_{n})^{}. \]

Then, the problem can be solved by dual ascent algorithm  as follows:

\[^{k+1} =*{arg\,min}_{}L_{}(^{k}, ^{k})\] \[^{k+1}_{ij} =(0,^{k+1}_{ij})\] \[^{k+1} =^{k}+(^{k}_{n}-c_{n }),\]

where \(k\) is the current optimization step, and \(^{k+1}\) can be obtained by multiple steps of gradient descent using the gradient in Eq. (4).

### Understandings

In this subsection, we provide the understanding and interpretation of our proposed LPSL, establishing its connections with the message passing in GNNs.

_Remark 3.1_.: The feature aggregation using the learned graph structure \(\) directly as a propagation matrix, i.e., \(=\), is equivalent to applying the message passing in GNNs using the original graph if \(\) is the approximate or exact solution to the primary problem defined in Eq. 2 without constraints.

The detailed proof can be found in Appendix B. Remark 3.1 suggests that we can directly substitute the propagation matrix in GNNs with the learned structure \(\). The GNNs are trained based on the labeled nodes, and the labeled nodes would influence the prediction of unlabeled nodes because of the message-passing scheme. Following the definition in , the influence of node \(j\) on node \(i\) can be represented by \(I_{i}(j)=sum[_{i}}{_{j}}]\), where \(_{i}\) is the representation of node \(i\), \(_{j}\) is the input feature of node \(j\), and \([_{i}}{_{j}}]\) represents the Jacobian matrix. Afterward, we have the following Proposition based on the influence scores:

**Proposition 3.1**.: _The influence scores from all labeled nodes to any unlabeled node \(i\) will be the equal, i.e., \(_{j_{L}}I_{i}(j)=c\), when using the unbiased graph structure \(\) obtained from the optimization problem in Eq. (2) as the propagation matrix in GNNs._

The proof can be found in Appendix B. Proposition 3.1 suggests that by using the unbiased graph structure for feature propagation, each node can receive an equivalent influence from all the labeled nodes, thereby mitigating the label position bias issue.

### \(_{1}\)-regularized Label Position Unbiased Sparse Structure Learning

One challenge of solving the graph structure learning problem in Eq. (2) is that it could result in a dense structure matrix \(^{n n}\). This is a memory-intensive outcome, especially when the number of nodes \(n\) is large. Furthermore, applying this dense matrix to GNNs can be time-consuming for downstream tasks, which makes it less practical for real-world applications. To make the learned graph structure sparse, we propose the following \(_{1}\)-regularized Label Position Unbiased Sparse Structure Learning optimization problem:

\[&*{arg\,min}_{B}\|- \|_{F}^{2}+(^{})+\| \|_{1}\\ &_{n}=c_ {n},_{ij} 0 i,j, \]

where \(\|\|_{1}\) represents the \(_{1}\) regularization that encourages zero values in \(\). \(>0\) is a hyper-parameter to control the sparsity of \(\). The primary problem in Eq. (5) is proved to have a strong localization property and can guarantee the sparsity [24; 25]. The problem in Eq. (5) can also be solved by the Lagrange Multiplier method. However, when the number of nodes \(n\) is large, solving this problem using conventional gradient descent methods becomes computationally challenging. Therefore, we propose to solve the problem in Eq. (5) efficiently by Block Coordinate Descent (BCD) method  in conjunction with the proximal gradient approach, particularly due to the presence of the \(_{1}\) regularization. Specifically, we split \(\) into column blocks, and \(_{:,j}\) represents the \(j\)-th block. The gradient of \(L_{}\) with respect to \(_{:,j}\) can be written as:

\[}{_{:,j}}=2(_{:,j}-_{:,j})+2}_{:,j}+( _{n})_{j}^{}+(_{n}-c_{n})(_{n})_{j}^{}, \]

where \((_{n})_{j}^{d 1}\) is the corresponding block part with block size \(d\). After updating the current block \(_{:,j}\), we apply a soft thresholding operator \(S_{/}()\) based on the proximal mapping. The full algorithm is detailed in Algorithm 1. Notably, lines 6-8 handle the block updates, line 9 performs the soft thresholding operation, and line 11 updates Lagrange multiplier \(\) through dual ascent update.

```
1:Input: Laplacian matrix \(}\), Label mask matrix \(\), Hyperparamters \(,c,,\), learning rate \(\)
2:Output: Label position unbiased graph structure \(\)
3:Initialization: \(^{0}=\) and \(^{0}=\)
4:while Not converge do
5:for each block \(j\)do
6:for\(i=0\)to update steps \(t\)do
7:\(_{:,j}=_{:,j}-*}{ _{:,j}}\)
8:endfor
9:\(_{:,j}=S_{/}(_{:,j})\)
10:endfor
11:endfor
12:endwhile
13:return\(\)
```

**Algorithm 1** Algorithm of LPSLGNN architectures. For decoupled GNNs such as APPNP, which only propagates once, a large \(\) is necessary to encode the global graph structure with a denser sparsity. In contrast, for coupled GNNs, such as GCN, which apply propagation multiple times, a smaller \(\) can be used to encode a more local structure with a higher sparsity. Our code is available at: [https://github.com/haoyuhan1/LPSL](https://github.com/haoyuhan1/LPSL).

## 4 Experiment

In this section, we conduct comprehensive experiments to verify the effectiveness of the proposed LPSL. In particular, we try to answer the following questions:

* **Q1:** Can the proposed LPSL improve the performance of different GNNs? (Section 4.2)
* **Q2:** Can the proposed LPSL mitigate the label position bias? (Section 4.3)
* **Q3:** How do different hyperparameters affect the proposed LPSL? (Section 4.4)

### Experimental Settings

**Datasets.** We conduct experiments on 8 real-world graph datasets for the semi-supervised node classification task, including three citation datasets, i.e., Cora, Citeseer, and Pubmed , two co-authorship datasets, i.e., Coauthor CS and Coauthor Physics, two co-purchase datasets, i.e., Amazon Computers and Amazon Photo , and one OGB dataset, i.e., ogbn-arxiv . The details about these datasets are shown in Appendix C.

We employ the fixed data split for the ogbn-arxiv dataset, while using ten random data splits for all other datasets to ensure more reliable results . Additionally, for the Cora, CiteSeer, and PubMed datasets, we experiment with various labeling rates: low labeling rates with 5, 10, and 20 labeled nodes per class, and high labeling rates with 60% labeled nodes per class. Each model is run three times for every data split, and we report the average performance along with the standard deviation.

**Baselines.** To the best of our knowledge, there are no previous works that aim to address the label position bias. In this work, we select three GNNs, namely, GCN , GAT , and APPNP , two Non-GNNs, MLP and Label Propagation , as baselines. Furthermore, we also include GRADE , a method designed to mitigate degree bias. Notably, SRGNN  demonstrates that if labeled nodes are gathered locally, it could lead to an issue of feature distribution shift. SRGNN aims to mitigate the feature distribution shift issue and is also included as a baseline.

**Hyperparameters Setting.** We follow the best hyperparameter settings in their original papers for all baselines. For the proposed LPSL GCN, we set the \(\) in range . For LPSL APPNP, we set the \(\) in the range . For both methods, \(c\) is set in the range [0.5, 1.5]. We fix the learning rate 0.01, dropout 0.5 or 0.8, hidden dimension size 64, and weight decay 0.0005, except for the ogbn-arxiv dataset. Adam optimizer  is used in all experiments. More details about the hyperparameters setting for all methods can be found in Appendix D.

### Performance Comparison on Benchmark Datasets

In this subsection, we test the learned unbiased graph structure by the proposed LPSL on both GCN and APPNP models. We then compare these results with seven baseline methods across all eight datasets. The primary results are presented in Table 1. Due to space limitations, we have included the results from other baselines in Appendix E. From these results, we can make several key observations:

* The integration of our proposed LPSL to both GCN and APPNP models consistently improves their performance on almost all datasets. This indicates that a label position unbiased graph structure can significantly aid semi-supervised node classification tasks.
* Concerning the different labeling rates for the first three datasets, our proposed LPSL shows greater performance improvement with a low labeling rate. This aligns with our preliminary study that label position bias is more pronounced when the labeling rate is low.
* SRGNN, designed to address the feature distribution shift issue, does not perform well on most datasets with random splits instead of locally distributed labels. Only when the labeling rate is very low, SRGNN can outperform GCN. Hence, the label position bias cannot be solely solved by addressing the feature distribution shift.
* The GRADE method, aimed at mitigating the degree-bias issue, also fails to improve overall performance with randomly split datasets.

### Evaluating Bias Mitigation Performance

In this subsection, we aim to investigate whether the proposed LPSL can mitigate the label position bias. We employ all three aforementioned bias metrics, namely label proximity score, degree, and shortest path distance, on Cora and CiteSeer datasets. We first group test nodes into different sensitive groups according to the metrics, and then use three representative group bias measurements - Weighted Demographic Parity (WDP), Weighted Standard Deviation (WSD), and Weighted Coefficient of Variation (WCV) - to quantify the bias. These are defined as follows:

\[=^{D}N_{i}|A_{i}-A_{}|}{N_{}},=}}_{i=1}^{D}N_{i}(A_{i}-A_ {})^{2}},=}{A_{}},\]

where \(D\) is the number of groups, \(N_{i}\) is the node number of group \(i\), \(A_{i}\) is the accuracy of group \(i\), \(A_{}\) is the weighted average accuracy of all groups, i.e., the overall accuracy, and \(N_{}\) is the total number of nodes. We choose six representative models, i.e., Label Propagation (LP), GRADE, GCN, APPNP, LPSL\({}_{}\), and LPSL\({}_{}\), in this experiment. The results of the label proximity score, degree, and shortest path on the Cora and Citeseer datasets are shown in Tabel 2, 3, and 4, respectively. It can be observed from the tables:

* The Label Propagation method, which solely utilizes the graph structure information, exhibits the most significant label position bias across all measurements and datasets. This evidence suggests that label position bias primarily stems from the biased graph structure, thereby validating our strategy of learning an unbiased graph structure with LPSL.
* The proposed LPSL not only enhances the classification accuracy of the backbone models, but also alleviates the bias concerning Label Proximity Score, degree, and Shortest distance.
* The GRADE method, designed to mitigate degree bias, does exhibit a lesser degree bias than GCN and APPNP. However, it still falls short when compared to the proposed LPSL. Furthermore, GRADE may inadvertently heighten the bias evaluated by other metrics. For instance, it significantly increases the label proximity score bias on the CiteSeer dataset.

  Dataset & Label Rate & GCN & APPNP & GRADE & SRGNN & LPSL\({}_{}\) & LPSL\({}_{}\) \\   & 5 & \(70.68 2.17\) & \(75.86 2.34\) & \(69.51 6.79\) & \(70.77 1.82\) & \(76.58 2.37\) & \(\) \\  & 10 & \(76.50 1.42\) & \(80.29 1.00\) & \(74.95 2.46\) & \(75.42 1.57\) & \(80.39 1.17\) & \(\) \\  & 20 & \(79.41 1.30\) & \(82.34 0.67\) & \(77.41 1.49\) & \(78.42 1.75\) & \(82.74 1.01\) & \(\) \\  & 60\% & \(88.60 1.19\) & \(88.49 1.28\) & \(86.84 0.99\) & \(87.17 0.95\) & \(\) & \(88.62 1.69\) \\   & 5 & \(61.27 3.85\) & \(63.92 3.39\) & \(63.03 3.61\) & \(64.84 3.41\) & \(65.65 2.47\) & \(\) \\  & 10 & \(66.28 2.14\) & \(67.57 2.05\) & \(64.20 3.23\) & \(67.83 2.19\) & \(67.73 2.57\) &

### Ablation Study

In this subsection, we first explore the impact of different hyperparameters, specifically the smoothing term \(\) and the constraint \(c\), on our model. We conducted experiments on the Cora and CiteSeer datasets using ten random data splits with 20 labels per class. The accuracy of different \(\) values for \(_{}\) and \(_{}\) on the Cora and CiteSeer datasets are illustrated in Figure 4.

From the results, we note that the proposed LPSL is not highly sensitive to the \(\) within the selected regions. Moreover, for the APPNP model, the best \(\) is higher than that for the GCN model, which aligns with our discussion in Section 3 that the decoupled GNNs require a larger \(\) to encode the global graph structure. The results for hyperparameter \(c\) can be found in Appendix F with similar observations.

In addition, we investigate the impact of the sparse graph structure matrix \(\) generated using \(l_{1}\) regularization, as described in Eq. 5, on the performance of different models. For this purpose, we utilize the Cora dataset and select an appropriate \(\) value to produce the sparse graph structure matrix \(\) at sparsity levels of 80%, 90%, and 95%. This means that 80%, 90%, and 95% of the entries in the matrix \(\) are zero, respectively.

The results are presented in Table 5. We observe that the accuracy at 80% and 90% sparsity is closely aligned with that of the dense matrix. However, when sparsity reaches 95%, there is a slight drop in accuracy, mirroring the findings of PPRGo . Notably, fairness appears to be relatively unaffected by the varying levels of sparsity.

  DataSet &  &  \\  Method & WDP \(\) & WSD \(\) & WCV \(\) & WDP \(\) & WSD \(\) & WCV \(\) \\  LP & 0.0562 & 0.0632 & 0.0841 & 0.0508 & 0.0735 & 0.109 \\ GRADE & 0.0292 & 0.0369 & 0.0459 & 0.0282 & 0.0517 & 0.0707 \\ GCN & 0.0237 & 0.0444 & 0.0533 & 0.0296 & 0.0553 & 0.0752 \\ \(_{}\) & **0.0150** & **0.0248** & **0.0289** & **0.0246** & 0.0526 & 0.0714 \\ \(\) & 0.0218 & 0.0316 & 0.0369 & 0.0321 & 0.0495 & 0.0668 \\ \(_{}\) & 0.0166 & 0.0253 & 0.0295 & 0.0265 & **0.0490** & **0.0654** \\  

Table 4: Comparison of Methods in Addressing Shortest Path Distance Bias.

Figure 4: The accuracy of different \(\) for \(_{}\) and \(_{}\) on Cora and CiteSeer datasets.

  Dataset &  &  \\  Method & WDP \(\) & WSD \(\) & WCV \(\) & WDP \(\) & WSD \(\) & WCV \(\) \\  LP & 0.0893 & 0.1019 & 0.1447 & 0.1202 & 0.1367 & 0.2773 \\ GRADE & 0.0386 & 0.0471 & 0.0594 & 0.0342 & 0.0529 & 0.0744 \\ GCN & 0.0503 & 0.0566 & 0.0696 & 0.0466 & 0.0643 & 0.0901 \\ \(_{}\) & 0.0407 & 0.0468 & 0.0554 & 0.0378 & 0.0538 & 0.0742 \\ \(\) & 0.0408 & 0.0442 & 0.0527 & 0.0499 & 0.0688 & 0.0964 \\ \(_{}\) & **0.0349** & **0.0395** & **0.0467** & **0.0316** & **0.0487** & **0.0665** \\  

Table 3: Comparison of Methods in Addressing Degree Bias.

## 5 Related Work

Graph Neural Networks (GNNs) serve as an effective framework for representing graph-structured data, primarily employing two operators: feature transformation and propagation. The ordering of these operators classifies most GNNs into two categories: Coupled and Decoupled GNNs. Coupled GNNs, such as GCN , GraphSAGE , and GAT , entrune feature transformation and propagation within each layer. In contrast, recent models like APPNP  represent Decoupled GNNs [30; 37; 38] that separate transformation and propagation. While Graph Neural Networks (GNNs) have achieved notable success across a range of domains , they often harbor various biases tied to node features and graph topology . For example, GNNs may generate predictions skewed by sensitive node features [8; 6], leading to potential unfairness in diverse tasks such as recommendations  and loan fraud detection . Numerous studies have proposed different methods to address feature bias, including adversarial training [8; 42; 33], and fairness constraints [6; 44; 45]. Structural bias is another significant concern, where low-degree nodes are more likely to be falsely predicted by GNNs . Recently, there are several works aimed to mitigate the degree bias issue [10; 11; 12]. Distinct from these previous studies, our work identifies a new form of bias - label position bias, which is prevalent in GNNs. To address this, we propose a novel method, LPSL, specifically designed to alleviate the label position bias.

## 6 Conclusion and Limitation

In this study, we shed light on a previously unexplored bias in GNNs, the label position bias, which suggests that nodes closer to labeled nodes typically yield superior performance. To quantify this bias, we introduce a new metric, the Label Proximity Score, which proves to be a more intrinsic measure. To combat this prevalent issue, we propose a novel optimization framework, LPSL, to learn an unbiased graph structure. Our extensive experimental evaluation shows that LPSL not only outperforms standard methods but also significantly alleviates the label position bias in GNNs. In our current work, we address the label position bias only from a structure learning perspective. Future research could incorporate feature information, which might lead to improved performance. Besides, we have primarily examined homophily graphs. It would be interesting to investigate how label position bias affects heterophily graphs. We hope this work will stimulate further research and development of methods aimed at enhancing label position fairness in GNNs.

## 7 Acknowledgement

This research is supported by the National Science Foundation (NSF) under grant numbers CNS 2246050, IIS1845081, IIS2212032, IIS2212144, IIS2153326, IIS2212145, IOS2107215, DUE 2234015, DRL 2025244 and IOS2035472, the Army Research Office (ARO) under grant number W911NF-21-1-0198, the Home Depot, Cisco Systems Inc, Amazon Faculty Award, Johnson&Johnson, JP Morgan Faculty Award and SNAP.