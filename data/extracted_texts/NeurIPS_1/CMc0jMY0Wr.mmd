# Optimal Private and Communication Constraint Distributed Goodness-of-Fit Testing for Discrete Distributions in the Large Sample Regime

Optimal Private and Communication Constraint Distributed Goodness-of-Fit Testing for Discrete Distributions in the Large Sample Regime

Lasse Vuursteen

Department of Statistics and Data Science

The Wharton School of the University of Pennsylvania

Philadelphia, PA 19104

lassev@wharton.upenn.edu

###### Abstract

We study distributed goodness-of-fit testing for discrete distribution under bandwidth and differential privacy constraints. Information constraint distributed goodness-of-fit testing is a problem that has received considerable attention recently. The important case of discrete distributions is theoretically well understood in the classical case where all data is available in one "central" location. In a federated setting, however, data is distributed across multiple "locations" (e.g. servers) and cannot readily be shared due to e.g. bandwidth or privacy constraints that each server needs to satisfy. We show how recently derived results for goodness-of-fit testing for the mean of a multivariate Gaussian model extend to the discrete distributions, by leveraging Le Cam's theory of statistical equivalence. In doing so, we derive matching minimax upper- and lower-bounds for the goodness-of-fit testing for discrete distributions under bandwidth or privacy constraints in the regime where number of samples held locally are large.

**Keywords**: distributed inference, goodness-of-fit testing, differential privacy, communication constraint, federated learning, statistical equivalence.

## 1 Introduction

Federated learning is a fundamental problem in statistics and machine learning, where data is distributed across multiple locations (e.g. servers) and cannot readily be shared due to e.g. bandwidth or privacy constraints that each server needs to satisfy. The primary goal in these distributed data settings is to perform a single global inference task, such as hypothesis testing, regression, or classification, by aggregating the local information from each server.

Starting a few decades ago, investigations into distributed settings with bandwidth and other information constraints originated in the electrical engineering community, under the names "decentralized decision theory / the CEO problem" e.g.  or "inference under multiterminal compression" (see  for an overview). These were largely motivated by applications where data is by construction observed and processed locally, such as astronomy, meteorology, seismology, surveillance systems, wireless communication, military radar or air traffic control systems.

Modern federated learning often involves data distributed across siloed data centers (e.g., hospitals) or networks of cellphone users, applied in areas such as word prediction, facial and voice recognition, virtual assistants like Siri or Google Assistant, autonomous vehicles, and earthquake prediction . In these settings, bandwidth often becomes a limited or costly resource .

Similarly, with advances in electronic record keeping, privacy has become a more and more pressing issue. These issues are prominent in tech industry products , including many federated learning applications mentioned earlier, as well as in scientific fields like medical sciences  and social sciences .

Methods that preserve privacy have been around in the statistics community for some time, starting in the 1980's . The current leading formal privacy framework is that of _differential privacy_ (DP), as introduced in . DP is a mathematical guarantee, describing whether results or data sets can be considered "privacy preserving" and hence can be openly published. Whilst many other privacy frameworks exist, this notion of privacy holds a prominent position both theoretically and practically, finding application within industry giants like Google , Microsoft , Apple , as well as governmental entities such as the US Census Bureau .

Quantifying the trade-off between privacy and statistical power means that researchers and data analysts can make an appropriate balance between data privacy and meaningful analysis. Similarly, by quantifying the impact of bandwidth constraints, systems can be designed to work as efficiently as possible within such bandwidth constraints.

The performance of distributed inference under bandwidth or differential privacy is well-studied for various estimation problems. For instance, distributed estimation under differential privacy has been studied for the many-normal-means model, discrete distributions and parametric models in , and density estimation , and nonparametric regression in . Bandwidth constraints have been studied for the many-normal-means and parametric models in e.g. , as well as nonparametric models, including Gaussian white noise , nonparametric regression , density estimation , general, abstract settings  and online learning . Distributed adaptive estimation methods under bandwidth constraints, where adaptation occurs to the unknown regularity of the functional parameter of interest, were derived in . Testing simple hypotheses under bandwidth constraints has been studied by e.g.  and under differential privacy constraints by .

In this paper, we consider goodness-of-fit testing for discrete distributions (i.e. the multinomial model) in scenarios where the number of samples received by each server is large. Specifically, we study testing a simple null versus a composite alternative, in the setting where \(m\) servers receive \(n\) observations each from a distribution on a sample space of cardinality \(d\), where \(n\) is large comparatively to \(m\) and \(d\). Recently, such multinomial distributed data have found many applications in areas that handle very large samples over (possibly also large) discrete domains. For example, in population genetics  and computer science; where it is used for e.g. information retrieval , speech and text and classification , text mining  and large language models . This has sparked recent interest in studying the statistical decision theoretic properties of the multinomial model, see  for an overview.

Deriving minimax rates for goodness-of-fit testing of discrete distributions under bandwidth and differential privacy constraints is particularly challenging when each server holds multiple observations. To date, matching rates have been established only when each machine observes a single observation  (see also our discussion of related work below). The techniques used to derive lower-bounds in the aforementioned paper heavily rely on the fact that each server contains only one observation, see . Moreover, whilst tight lower-bounds for the multiple observations case exist for the Gaussian model, the functional analytic techniques used to derive these results heavily rely on Gaussianity, see  and  for the respective bandwidth constraint and DP lower-bounds. Additionally, lower-bound techniques developed for estimation problems generally do not yield tight impossibility results for goodness-of-fit testing problems (see also the discussion in Section B of the appendix).

We derive matching upper- and lower-bounds for goodness-of-fit testing for discrete distributions under bandwidth and differential privacy constraints in scenarios where the number of samples \(n\) held by each of the servers is large in comparison to \(d\) and \(m\); \(md d/=o(1)\). This is achieved by leveraging the theory of statistical equivalence, as introduced by Le Cam (see e.g.  for an introduction). Leveraging existing results concerning statistical equivalence of multinomial data with a multivariate Gaussian model proven in  allow us to show, roughly speaking, that the distributed goodness-of-fit testing problem for discrete distributions is statistically equivalent a distributed goodness-of-fit testing problem for the mean of a multivariate Gaussian model, and hence the minimax rate for the former problem is the same as the minimax rate for the latter problem, which was established in  and , for bandwidth and differential privacy constraints respectively. Furthermore, we exploit the bandwidth constraint distributed setting in which these two models have different minimax rates to show that, when \(n\) is small compared to \(d\) and \(m\), the multinomial model and multivariate Gaussian model are statistically non-equivalent.

The rest of the paper is organized as follows. After a brief section on related work and notation, the article continues with a precise problem formulation in Section 2. Section 2.1 outlines the distributed framework, for both bandwidth and differential privacy constraints. In Section 2.2, we introduce the problem of distributed goodness-of-fit testing for discrete distributions under bandwidth and differential privacy constraints. In Section 3, the main results concerning the minimax rates are presented. Section 4 briefly outlines the main idea of the proof technique. Section 5 gives further insight into the comparison between discrete distributions and its comparable multivariate Gaussian model. The article ends with a brief discussion of the derived results. In the appendix, the tools of asymptotic equivalence within the distributed framework are presented and the technical proofs are provided.

### Related work

Minimax goodness-of-fit testing knows a rich literature within the statistics and machine learning communities, see [46; 53; 64; 80; 52]. The \(d\)-ary discrete distribution uniformity testing problem bares a close relationship with "classical" nonparametric goodness-of-fit testing in the sense of [14; 79; 33; 96] and other nonparametric testing problems, see Section 1.4 in  and references therein.

For distributed goodness-of-fit testing specifically, much less is known. For multivariate Gaussian models under communication or differential privacy constraints, solutions have been established for the case where each server holds multiple observations. Communication constraints have been studied in [8; 84; 85] and differential privacy constraints in , with the authors deriving matching minimax upper- and lower-bounds for the goodness-of-fit testing for the mean of a multivariate Gaussian model.

For testing in discrete distributions, only the scenario where each server receives just one observation has been fully characterized in terms of the minimax rate in [9; 10; 5]. See also  for an overview. In these aforementioned works, the authors derive minimax rates goodness-of-fit testing for discrete distributions under bandwidth and differential privacy constraints. See [48; 78; 11; 2; 19] for investigations specifically under local DP (i.e. one observation per server with DP constraint). Nonparametric goodness-of-fit density testing for under local DP is considered in [36; 61], where in , the authors consider adaptation as well. For some investigations into the multiple observations per server case, see [34; 47].

For estimation, the bandwidth constraint estimation discrete distributions in the large sample-per-server case has been studied by , who derive matching upper and lower-bounds up to logarithmic factors. However, their technique does not extend to the goodness-of-fit testing problem.

### Notation and notions

Throughout this paper, we shall use the following notation. For two positive sequences \(a_{k}\) and \(b_{k}\), we use \(a_{k} b_{k}\) to mean that \(a_{k} Cb_{k}\) for some universal positive constant \(C\). We write \(a_{k} b_{k}\) if both \(a_{k} b_{k}\) and \(b_{k} a_{k}\), and \(a_{k} b_{k}\) if \(a_{k}/b_{k}=o(1)\).

We denote the maximum of \(a\) and \(b\) by \(a b\) and the minimum by \(a b\). For \(k\), \([k]\) represents the set \(\{1,,k\}\). Universal constants \(c\) and \(C\) may vary between lines. The Euclidean norm of a vector \(v^{d}\) is denoted by \(\|v\|_{2}\). For a matrix \(M^{d d}\), \(\|M\|\) represents the spectral norm, and \((M)\) denotes its trace. \(I_{d}\) is the \(d d\) identity matrix.

A non-negative sequence \(M_{k}\) is said to be of poly-logarithmic order in non-negative sequences \(a_{k},b_{k},c_{k}\) if there exists a constant \(c>0\) such that \(M_{k}((a_{k})(b_{k})(c_{k}))^{c}\).

Given measurable spaces \((,)\) and \((,)\), a _Markov kernel \(K\) (between \((,)\) and target \((,)\))_ is a map \(K K(|):\) with the following two properties: The map \(x K(A|x)\) is measurable for all \(A\), and the map \(A K(A|x)\) is a probability measure on \(\) for every \(x\).

If \(S\) is a random variable on a probability space \((,,)\), we let \(^{S}\) denote its _push-forward measure_, i.e. the measure defined by \(^{S}(B):=(S^{-1}(B))\). We shall use \(\) and \(^{S}\) as the expectation operator corresponding to \(\) and \(^{S}\). Random variables \(X,Y,Z\) form a _Markov chain_\(X Y Z\) whenever their joint distribution \(^{(X,Y,Z)}\) disintegrates as \(d^{(X,Y,Z)}=d^{X}d^{Y|X}d^{Z|Y}\).

## 2 Problem formulation

We begin by formally introducing the general framework of distributed inference.

### The distributed framework

Consider a measurable space \((,)\) with a statistical model \(=\{P_{f}\,:\,f\}\) defined on it. In the distributed framework, we consider \(j=1,,m\) servers, each receiving data \(X^{(j)}\) drawn from a given distribution \(P_{f}\). Each of the servers communicates a transcript \(Y^{(j)}\) based on the data to a central server, which in turn computes its solution to the testing problem \(T(Y)\{0,1\}\) based on the aggregated transcripts \(Y=(Y^{(1)},,Y^{(m)})\). We shall use the convention that \(T(Y)=1\) means rejecting the null hypothesis. The transcript generating mechanisms are then given by Markov kernels \(\{K^{j}\}_{j=1,,m}\), with the Markov kernel (i.e. conditional distribution) of the transcript \(Y^{(j)}\) given the data \(X^{(j)}\) and the randomness \(U\) shared by the servers denoted by \(K^{j}(|X^{(j)},U)\). We formalize this in the following definition.

**Definition 1**.: _A distributed testing protocol for the model \(\) consists of a triplet \(\{T,\{K^{j}\}_{j=1}^{m},(,,^{U})\}\), where \(\{K^{j}\}_{j=1}^{m}\) is a collection of Markov kernels \(K^{j}:(^{j})\) defined on a measurable space \((^{(j)},^{(j)})\), \(T:_{j=1}^{m}^{(j)}\{0,1\}\) is a measurable map and \((,,^{U})\) is probability space._

The probability space \((,,^{U})\) is used to (possibly) generate a source of randomness (independent of the data) that is shared by the servers. The distributed protocol is said to have _no access to shared randomness_ or to be a _local randomness protocol_ if \(^{U}\) is trivial1. In an abuse of notation, we shall often refer to the entire triplet \(\{T,\{K^{j}\}_{j=1,,m},(,,^{U})\}\) using just \(T\).

Given a distributed protocol and i.i.d. data from \(P_{f}\) we shall use \(_{f}\) to denote the joint distribution of \(Y=(Y^{(1)},,Y^{(m)})\), the data \(X\) under \(P_{f}^{m}\) and the shared randomness \(U^{U}\). Writing \(x=(x^{(1)},,x^{(m)})^{m}\), let \(x K(A|x,u)\) denote the Markov kernel \(_{j=1}^{m}K^{j}(|x^{(j)},u)\) (i.e. the product measure). The independence structure of the data yields that \(P_{f}^{m}K=_{j=1}^{m}P_{f}K^{j}\) and the push-forward measure of \(Y\) can be seen to disintegrate as

\[_{f}^{Y}(A)=P_{f}^{m}^{U}K(A)=^{U}P_{f}^{m}K(A) = K(A|x,u)dP_{f}^{m}(x)d^{U}(u),\]

where the second equality follows from the independence of \(U\) with the data drawn from \(P_{f}\). The above disintegration of the push-forward measure of \(Y\) and the product structure of \(K\) can be interpreted as \((X,Y,T(Y))\) forming a Markov chain given \(U\), in the sense of the diagram

\[X^{(1)}@>{}>{}>Y^{(1)}|U@>{}>{}>\\  @V{}>{}>\\ X^{(m)}@>{}>{}>Y^{(m)}|U@>{}>{}>\\  T(Y). \]

The diagram indicates the flow of dependencies. The \(m\) servers each obtain data \(X^{(j)}\) from \(P_{f}\), and generate a transcript \(Y^{(j)}\) based on the data and shared randomness \(U\). The central server then makes a decision \(T(Y)\) based on the aggregated transcripts \(Y\). For a definition of Markov kernels and Markov chains, see Section 1.2.

Allowing transcript-generating mechanisms to access both shared and local randomness is important for our analysis, as shared randomness has been found to yield strictly better performance in distributed goodness-of-fit testing, see e.g. . Shared randomness protocols can be seen as a subset of common interactive procedures, such as sequential and blackboard protocols(see e.g. ). The aforementioned paper shows that for discrete distribution goodness-of-fit testing in the single observation per server case, sequential and blackboard protocols offer no benefit over shared randomness protocols. Similarly, for mean shift problems in the multivariate Gaussian case, no advantage of sequential protocols over shared randomness protocols is known, except in the case of estimation with unknown variance . Since we study goodness-of-fit testing for discrete distributions in the large-number-of-observations case by comparing with a Gaussian model with known variance, we restrict the setting of the main article to local and shared randomness protocols only. Nevertheless, our theoretical framework is general enough to handle interactive protocols, which we discuss in Section A.2 of the appendix.

Next, we introduce the notion of a bandwidth constraint in the distributed setting.

**Definition 2**.: _A distributed protocol is said to satisfy a \(b\)-bit bandwidth constraint if its kernels \(\{K^{j}\}_{j=1,,m}\) are defined on measurable spaces \((^{(j)},^{(j)})\) satisfying \(|^{(j)}| 2^{b}\) for \(j=1,,m\)._

We use \(^{(b)}_{}\) and \(^{(b)}_{}\) to denote the classes of all local randomness and shared randomness distributed testing protocols with communication budget \(b\) per machine, respectively.

Lastly, we introduce the notion of differential privacy in the distributed setting. We will be focusing on the notion of differential privacy as put forward by . Differential privacy provides a mathematical framework that guarantees preservation of privacy in a notion akin to cryptographical guarantees. Formally, a differential privacy constraint on a transcript in our setting is formulated as follows.

**Definition 3**.: _Let \( 0, 0\). The transcript \(Y^{(j)}\) generated from \(K^{j},u\) is said to be \((,)\)-differentially private if_

\[K^{j}(A|x,u) e^{}K^{j}(A|x^{},u)+ \]

_A distributed testing protocol \(\{T,\{K^{j}\}_{j=1}^{m},(,,^{U})\}\), is said be a distributed \((,)\)-differentially private testing protocol if \(\{K^{j}\}_{j=1,,m}\) satisfies (2) \(^{U}\)-a.s._

Small values of \(\) and \(\) ensure that, even when the transcript \(Y^{(j)}\) is publicly available, the sample \(X^{(j)}\) underlying \(Y^{(j)}\) is unidentifiable. We stress that this type of differential privacy guarantee concerns the local data \(X^{(j)}\) in full, even \(X^{(j)}\) consists of multiple observations. This is often referred _local differential privacy_, where the privacy guarantee regards each server as essentially pertaining data to "one indiviual". For a thorough introduction on differential privacy guarantees, we refer the reader to . We also note that the use of shared randomness does not affect the privacy guarantee provided by the protocol, as the guarantee holds even if the outcome of the shared randomness is known.

We use \(^{(,)}_{}\) and \(^{(,)}_{}\) to denote the classes of all local- and shared randomness \((,)\)-differentially private distributed testing protocols, respectively. We note that the machinery developed in Section A.2 allows consideration of both types of constraints simultaneously. In the main text of the article, we shall focus on the bandwidth constraint and differential privacy constraint separately as minimax rates for the joint constraints are not known for the Gaussian model we use for comparison to the multinomial model in the main article.

### Distributed goodness-of-fit testing

We start by giving a formal description of sampling from a discrete distribution in the distributed setting. Consider a set with cardinality \(d\); for simplicity, we take \(}=\{1,,d\}\). Any probability distribution such a set can be characterized by an element of the \(d-1\)-dimensional probability simplex \(^{d}\), defined as

\[\{q=(q_{1},,q_{d})^{d}\,:\,_{i=1}^{d}q_{i}=1\}.\]

In our distributed framework, each server \(j=1,,m\) observes a data \(^{(j)}\) taking values in \(\{1,,d\}^{n}\)

\[^{(j)}=(^{(j)}_{1},,^{(j)}_{n}) Q Q _{n,q},^{(j)}_{i}}{{}}(1,q)\;\;q^{d}. \]That is, each server obtains \(n\) i.i.d. draws from a multinomial distribution with parameter \(q\).

The statistical decision problem of interest shall be that of _goodness-of-fit_ or _uniformity testing_, i.e. distinguishing the hypotheses

\[H_{0}:q=q_{0}\ H_{1}:q\{q:\|q-q_{0} \|_{1}\}=:H_{}, \]

where \(q_{0}=(q_{01},,q_{0d})=(1/d,,1/d)^{d}\) and

\[=\{q^{d}\,:\ q_{i}}{_{i}q_{i}}  R\}, \]

for some fixed constant \(R>0\). The statistical model under consideration shall be denoted by \(=\{Q_{q}^{n}\,:\,q\}\).

We define the testing risk for a distributed testing protocol \(T\), for the hypotheses (4) (and statistical model \(\)) by sum of the type I and worst case type II error over the alternative class;

\[_{}(T,H_{}):=_{q_{0}}^{Y}T(Y)+_{f H _{}}_{f}^{Y}(1-T(Y)).\]

The minimax testing risk over a class of distributed protocols \(\) is then defined as \(_{T}_{}(T,H_{})\).

It is clear that, as \(\) tends to \(0\), the minimax testing risk should increase. We are interested in finding the so called _minimax separation rate_, or detection boundary, which is a sequence \(^{*}\) depending on the model characteristics \(n,d\), \(m\) and \(\) such that the minimax testing risk converges to \(0\) if \(^{*}\) or \(1\) if \(^{*}\).

The minimax separation rate captures how the testing problem becomes easier, or more difficult, for different model characteristics. The minimax rate for the hypothesis above case is \(^{2}}{mn}\) when \(\) consists of the class of all testing protocols, as was established in  and .

When \(\) is taken to be one of the bandwidth or privacy constraint classes of tests, i.e. \(_{}^{(b)}\) and \(_{}^{(b)}\)\(_{}^{(,)}\) and \(_{}^{(,)}\), it is sensible to expect \(^{*}\) to depend on the bandwidth or differential privacy parameters, \(b\) and \((,)\), respectively. In the distributed discrete distribution setupj described above with \(n=1\), such minimax rates have been derived in [9; 10]. We discuss these results in the next section, contrasting them with the minimax separation rate derived in this paper for the case where \(md d/=o(1)\).

## 3 Minimax rates in the large sample regime

We now turn to the main results of this paper, which concern the minimax rates for goodness-of-fit testing for discrete distributions under bandwidth and differential privacy constraints in the large sample regime. We shall show that the minimax rates for the distributed multinomial model under bandwidth and differential privacy constraints are the same as the minimax rates for a \(d\)-dimensional distributed Gaussian model, as derived in  and , respectively.

The first theorem establishes the minimax rate for the distributed multinomial model under bandwidth constraints. A proof can be found in Section D of the appendix.

**Theorem 1**.: _Consider sequences \(m m_{}\), \(b b_{}\), \(d d_{}\), and \(n n_{}\) such that \(md\) whilst_

\[md d/}{{}}0.\]

_Suppose that \(_{}\) is a nonnegative sequence satisfying_

\[^{2}(})(}{}). \]

_Then,_

\[_{T_{}^{(b)}}_{}(T,H_{M_{ }})0\ M_{},\\ 1\ M_{} 0.\]_When considering the class of only local randomness protocols (i.e. replacing \(_{}^{(b)}\) with \(_{}^{(b)}\) in the above display), the minimax separation rate is given by_

\[^{2}(}{(d b)mn})(}{}). \]

The theorem above shows that the minimax rate for the distributed multinomial model under bandwidth constraints is given by (6) in the case of access to shared randomness, and (7) in the case of no access to shared randomness. Both rates are the same as those established for a signal detection problem in a \(d\)-dimensional distributed Gaussian model, as derived in , Theorems 3.1 and 3.2. In Section 4, we shall provide a proof of this result through the notion of statistical equivalence, where we explicitly use that the multinomial model is asymptotically similar to a specific Gaussian model and a corresponding signal detection problem.

The distributed \(b\)-bit bandwidth constraint minimax rate for the hypotheses (4) in the multinomial model with \(n=1\) is established in . Specifically, they find that

\[^{2} d}}&\\ }{m(2^{b} d)}& \]

Several aspects of this minimax rate are intriguing. First, unlike in the "large \(n\) case" for the same model and hypothesis ((6) and (7)), there is no elbow effect. Secondly, the benefit (i.e. "efficiency gain") from an increase in bandwidth is exponential, whereas in the large sample scenario of Theorem 4 it is sub-linear. We shall comment on this "communication super-efficiency" phenomenon further below.

We now turn to the distributed multinomial model under differential privacy constraints. As in the case of the bandwidth constraint uniformity testing problem, we shall show that the minimax rate for the distributed multinomial model under differential privacy constraints is the same as the minimax rate for a \(d\)-dimensional distributed Gaussian model, as derived in .

The following theorem describes that the above rates are the minimax rates for uniformity testing in the distributed multinomial model under differential privacy constraints, for shared randomness and local randomness only protocols, respectively.

**Theorem 2**.: _For any sequences \(m m_{}\), \(d d_{}\) and \(n n_{}\) such that \(md\), \(}}{{}}0\), \(n^{-1/4}_{} 1\), \(_{}(md)^{-p}\) for some \(p>1\). The minimax separation rate in the distributed multinomial model \(\) for testing the hypotheses (4) using locally \((,)\)-differentially private protocols is_

\[^{2}(d,m,n)}& }{},\\ }{}&}< }{} \]

_in the case of having access to shared randomness. In the case of having only access to local randomness, it is given by_

\[^{2}(d,m,n)}{mn }&},\\ }{}&}< }. \]

We provide a proof of the theorem in Section D of the appendix. As with the bandwidth constraint case, the minimax separation rates for the distributed multinomial model under differential privacy constraints are derived by comparing the model and hypothesis test to a signal detection problem for the \(d\)-dimensional distributed Gaussian model. The rates for the latter problem follow from the proofs of Theorems 4 and 5 in , who describe a more general setup which includes signal detection in the \(d\)-dimensional distributed Gaussian model as a special case2.

Also in the case of privacy, there is a difference between the one observation per server case minimax rate (\(n=1\)) and the multiple observations per server with local differential privacy case. The minimax rate in the multinomial model for \(n=1\) is derived in [9; 5];

\[^{2}}\ \\ }{m^{2}}\  \]

Comparing this rate to the rate obtained in Theorem 2, we observe phase transitions in the distributed testing problem for multinomial model under local differential privacy constraints which only occurs if the number of observations locally is large compared to the cardinality of the sample space.

## 4 Deriving the minimax rates through statistical equivalence

The minimax rates for the distributed multinomial model under bandwidth and differential privacy constraints are derived through the notion of statistical equivalence (Le Cam theory), which is a powerful tool for establishing minimax rates in statistical decision theoretic problems. In this section, we shall provide a brief introduction to statistical equivalence, and show how it can be used to derive the minimax rates for the distributed multinomial model under bandwidth and differential privacy constraints. Further details on the statistical equivalence and a detailed proof are deferred Section A of the appendix.

Le Cam theory is a general framework for decision problems. At the core of this theory is the notion of a distance between statistical models, known as Le Cam's deficiency distance. The objective of this distance is to quantify the extent to which a complex statistical model can be approximated by a more simple one. If a model is close to another model in Le Cam's distance, then there is a mapping of solutions to decision theoretic problems from one model to the other. Whenever the risk of the decision problem is bounded, this means that similar performance can be achieved in the two models. Consequently, studying the complex model can be reduced to studying the corresponding simple model. For an extensive introduction to Le Cam theory, see e.g. [62; 81]. For a brief introduction; [63; 66].

Consider a model \(=\{P_{f}:f\}\) (a collection of probability distributions) on a measurable space \((,)\) (the sample space). For this article, we consider only models with Polish sample spaces and corresponding Borel sigma-algebras and dominated models, meaning that there exists a sigma-finite measure \(\) such that \(P_{f}\) for all \(f\). This greatly simplifies the definition of deficiency, given next.

Given another model \(=\{Q_{f}:f\}\) indexed by the same set \(\) and sample space \((},})\), we define the _deficiency of \(\) with respect to \(\)_ as

\[(;)=_{C}_{f}\|P_{f}C-Q _{f}\|_{}. \]

where the infimum is taken over all Markov kernels \(C:}\) and the probability measure \(P_{f}C:}\) is understood as \(P_{f}C(A):=_{x}C(A|x)dP_{f}(x)\). This is equivalent to the more general notion of deficiency of  for dominated models on Polish spaces (see Proposition 9.2 in ).

Le Cam's deficiency distance between \(\) and \(\) is then defined as \((,)=\{(;),(,)\}\). This semi-metric becomes a metric whenever \(\) and \(\) are identified whenever \((;)+(,)=0\). Two sequences of experiments \(_{}\) and \(_{}\) are called _asymptotically equivalent_ if their difference \((_{},_{})\) tends to zero as \(\) approaches infinity. Conversely, such sequences shall be called _asymptotically nonequivalent_ if \((_{},_{})>c\) as \(\) for a fixed constant \(c>0\).

In Section A.2, we prove that models that are close in the Le Cam metric (compared to \(m\)) have similar testing risks in the distributed setup. We leverage this result in combination with the fact that the distributed multinomial model is asymptotically equivalent to a \(d\)-dimensional distributed Gaussian model, which we describe next.

Consider for \(q\) and \(i=1,,d\) the random variables

\[X_{i}^{(j)}=}+}Z_{i}^{(j)} Z^{(j)}=(Z_{1}^{(j)},,Z_{d}^{(j)}) N(0,I_{d}). \]Let \(P_{f} P_{f}^{n}\) denote the distribution of \(X^{(j)}=(X_{1}^{(j)},,X_{d}^{(j)})\). Let \(\) denote the corresponding experiment. It is shown in  that \(\) is close to \(\) in the Le Cam metric when \(d\) is relatively small compared to \(n\). More precisely, it follows from Theorem 1 and Section 7 in  that

\[(,) C_{R}}, \]

where \(C_{R}>0\) is a constant depending only on \(R\). For the testing problem in Gaussian model, with hypotheses (4), the minimax rate can be derived using the results of  in case of bandwidth constraints and  in case of differential privacy constraints. The key tool from which the minimax rates can then be derived for the multinomial model is the following lemma, which allows comparison of the minimax testing risks for the multinomial and Gaussian models in regimes where the Le Cam distance is small. Its proof is given in Section A.2 of the appendix.

**Lemma 1**.: _Suppose \(m(;)\) for \(>0\). Then, it holds that_

\[|_{T()}_{}(T,H_{1})- _{T()}_{}(T,H_{1})|  2,\]

_where \(\) is either \(_{}^{b}\), \(_{LR}^{b}\), \(_{}^{(,)}\) or \(_{LR}^{(,)}\)._

## 5 Statistical non-equivalence of discrete and multivariate Gaussian distributions

Theorem 1 describing uniformity testing in the large sample regime and the result derived for \(n=1\), as displayed in (8), shows a striking difference terms of the role of the communication budget. Specifically, in the \(n=1\) regime, an exponential communication efficiency is observed, whereas in the large sample regime, the benefit is only linear. In this section, we shall provide some explanation for this phenomenon, and shall actually leverage this difference to show that the distributed multinomial model and the distributed Gaussian model are asymptotically non-equivalent: Two models are considered _asymptotically nonequivalent_ if their Le Cam distance remains bounded away from zero, even as the amount of data increases in both models.

The multinomial model is equivalent to a model in which one observes \(N^{(j)}=(N_{1}^{(j)},,N_{d}^{(j)})\) taking values in \(\{1,,n\}^{d}\), where \(N_{k}^{(j)} N_{k}^{(j)}(^{(j)})=|\{i: {X}_{i}^{(j)}=k\}|\). Let \(^{}\) denote the model generated by the observations \(N^{(j)}\). This model is equivalent to \(\), meaning \((,^{})=0\). To see this, note that for \(x=(x_{1},,x_{n})\{1,,d\}^{n}\),

\[Q(^{(j)}=x)=}Q( {X}_{i}^{(j)}=x_{i})=}{}q_{k} ^{|\{i:x_{i}=k\}|}Q,\]

after which the aforementioned equivalence follows by the Neyman-Fisher factorization criterion, e.g. Lemma 2 in the appendix. When \(n\) is large compared to \(d\), one could standardize the count statistics \(N^{(j)}\) to obtain a statistic that tends towards a \(d\)-dimensional Gaussian random vector. When \(d\) and \(m\) are not too large with respect to \(n\), one can obtain transcripts and corresponding test statistics from these approximately Gaussian vectors, that resemble those one would consider in the Gaussian model, and attain the corresponding minimax rates.

Since the observation \(N^{(j)}\) takes values in \(\{1,,n\}^{d}\), the full data can be transmitted whenever there are at least \(d_{2}n\)-bits are available per server. However, recalling that the observation \(^{(j)}\) takes values in the space \(\{1,,d\}^{n}\), which has cardinality bounded above by \(2^{n_{2}d}\), we also obtain that the full data can be transmitted whenever \(n_{2}d\)-bits are available. Consequently, whenever

\[b d_{2}(n+1) n_{2}d,\]

the distributed problem has the same minimax separation rate for the hypothesis in (4) as the unconstrained problem with \(nm\) observations; \(_{}^{2}}{mn}\). For the Gaussian problem, this is only the case whenever \(b d\), as can be seen from Theorem 4. This indicates a kind of "tipping point" occuring whenever \(n\) gets small compared to \(d\), where in a bandwidth constraint distributed setting, the testing problem in for the Gaussian model starts to exhibit very different behavior.

Interestingly, this does not imply that the multinomial model is "easier" from a distributed testing under bandwidth constraints perspective, as there are sub-regimes in which the Gaussian model has a solution whereas the multinomial model does not and vice versa. It indicates that the "communication complexity" of the sample space matters in the respective decision problems. We can leverage this fact to obtain a lower-bound on the Le Cam distance between the multinomial model and the Gaussian model; which is the content of the next theorem.

**Theorem 3**.: _There exists constants \(C>0\) and \(c>0\) such that for any \(n,d\) with_

\[ C n(d), \]

_it holds that_

\[(,) c, \]

_where \(\) is the experiment generated by the observations in (13), \(\) is generated according to (3), both indexed by \(\) as given in (5)._

The proof of the theorem is given in Section D. It leverages that there exist distributed, \(b\)-bit bandwidth constraint settings in which the (distributed) multinomial model allows for consistent goodness-of-fit testing, whereas the (distributed) Gaussian model does not. The result then readily follows from the distributed equivalence results derived in Section A.2. The fact that the separation in the respective (distributed) testing risks occurs for a constant number of servers, yields that the two models are asymptotically nonequivalent whenever \(/^{2}(d) d/n 1\). This reasoning crucially exploits the differing minimax rates that occur under the bandwidth constraint, since without such a constraint, the same goodness-of-fit testing problem of (4) would have similar minimax performance for both of the models.

## 6 Discussion

We have derived minimax separation rates for uniformity testing in the distributed multinomial model under bandwidth and differential privacy constraints, in the large sample regime where \(md d/=o(1)\). When contrasted with existing results for large sample regimes, the minimax rates show that the large sample regime is subject to distinctly different phenomena.

The applicability of our results is somewhat constrained by the requirement that \(md d/=o(1)\), which limits the range of model characteristics we can consider. Consequently, further work is needed to understand the behavior of the distributed multinomial model in other regimes. The non-equivalence result in Theorem 3 indicates that the distributed multinomial model and the distributed Gaussian model are fundamentally different regarding distributed statistical decision problems when the sample size is small. Therefore, direct analysis of the distributed multinomial model might be necessary, requiring new techniques to derive minimax rates. We note, however, that this pertains to the specific Gaussian model formulated in (13), and there might be a different Gaussian model that is equivalent to the distributed multinomial model even in the small \(n\) regime.

The results in this paper are derived through the notion of statistical equivalence, which is a powerful tool for establishing minimax rates in statistical decision theoretic problems. The results and techniques can be applied more generally to other distributed inference problems, and proving more general results concerning statistical equivalence and distributed inference is an interesting avenue for future research.

A downside of leveraging statistical equivalence is that it generally does not provide a direct path to obtain methods that are minimax rate optimal. However, Theorem 1 and Section 7 in  provide a specific transformation that converts the local multinomial sample into a statistic approximately distributed as a Gaussian random vector. Such a transformation, combined with the rate optimal methods given in  and , provide guidance to construct methods that attain the minimax rates described in this article.