# Lubo Wang\({}^{1}\) &Die Zuo\({}^{1}\) &Qing Guo\({}^{4}\) &Feng Zhang\({}^{5}\) &Manyu Wang\({}^{1}\) &Di Lin\({}^{1}\)

Sim2Real-Fire: A Multi-modal Simulation Dataset for Forecast and Backtracking of Real-world Forest Fire

 Yanzhi Li\({}^{1,2}\) &Keqiu Li\({}^{1}\) &Guohui Li\({}^{2}\) &Zumin Wang\({}^{3}\) &Changqing Ji\({}^{3}\)\({}^{1}\)Tianjin University, China

\({}^{2}\)Tianjin Fire Science and Technology Research Institute of MEM, China

\({}^{3}\)Dalian University, China

\({}^{4}\)CFAR and IHPC, Agency for Science, Technology and Research (A*STAR), Singapore

\({}^{5}\)Hebei University, China

wmy22@tju.edu.cn di.lin@tju.edu.cn

Corresponding author.

###### Abstract

The latest research on wildfire forecast and backtracking has adopted AI models, which require a large amount of data from wildfire scenarios to capture fire spread patterns. This paper explores using cost-effective simulated wildfire scenarios to train AI models and apply them to the analysis of real-world wildfire. This solution requires AI models to minimize the Sim2Real gap, a brand-new topic in the fire spread analysis research community. To investigate the possibility of minimizing the Sim2Real gap, we collect the Sim2Real-Fire dataset that contains 1M simulated scenarios with multi-modal environmental information for training AI models. We prepare 1K real-world wildfire scenarios for testing the AI models. We also propose a deep transformer, S2R-FireTr, which excels in considering the multi-modal environmental information for forecasting and backtracking the wildfire. S2R-FireTr surpasses state-of-the-art methods in real-world wildfire scenarios.

## 1 Introduction

The frequency and intensity of extreme weather events, such as high temperatures and droughts, have escalated. This escalation has increased the frequency and scale of forest fires, rendering fire extinguishing a formidable challenge. An accurate and real-time forest fire spread forecast is imperative for organizing evacuations and commanding rescue operations. On the other hand, forest fire backtracking helps identify high-risk ignition areas, assisting people in preventing potential fires.

Extensive studies have been conducted on forest fire spread forecast and backtracking. These studies have given rise to three categories of methods based on the empirical, physical, or artificial intelligence (AI) models. The empirical models [1; 2; 3; 4; 5; 6; 7] only capture the statistical correlation between observed fire data in real-world or the energy conservation, without considering the impact of physical rules like the conductive, convective, and radiative modes of heat transfer on the fire spread. The physical models [8; 9; 10; 11; 12] rely on the approximate physical rules, including the fluid dynamics, combustion, and heat transfer, to forecast the forest fire spread. Furthermore, they also consider the impact of environmental information about vegetation, atmosphere, and topography on fire spread. The research on the empirical and physical models leads to the emergence of an array of simulators of forest fire spread like BehavePlus , FARSITE , FIRETEC , WRF-SFIRE , and WFDS . Given the environmental details and the current fire area, a simulator can predict the spread area at any moment. This is also known as the simulation process. However, the existing simulators fall short of utilizing the historical multi-modal data (e.g., satellite-view images of forest and spreading fire areas) of fire progression to forecast the future areas of fire spreading. These simulators also lack backtracking capability, which traces earlier fire states.

AI models [15; 16; 17; 18; 19; 20; 21; 22; 23; 24; 25; 26; 27; 28; 29; 30] can better leverage the history of fire data to forecast and backtrack the spread of forest fire. Mainly, AI models based on the deep neural networks [20; 24; 25; 28; 29; 30] perform excellently in forest fire forecast and backtracking. These models learn the spreading patterns of forest fire from a large amount of data about the temporal change of the environmental factors and forest fire areas. The environmental data and the wildfire images are usually captured by remote sensing satellites from real-world forests. They form the multi-modal data that requires significant labor costs for data collection and annotation for model training. Moreover, the satellites orbit the Earth rapidly, without continuously observing a particular forest fire area. During the period without observation by any satellite, the environmental and fire data are unavailable, contributing to the difficulty of using real-world data for model training. Though the Gazer satellite can provide temporally complete data, it makes data collection extraordinarily expensive. Therefore, collecting large-scale and temporally complete data at a low cost is critical.

The simulation process based on the empirical and physical models can be done quickly without needing substantial human effort for data collection and annotation. The natural idea is to use the data generated by the simulator, in chronological or reverse order, to train the forecasting or backtracking model primarily based on the data-hungry deep network. Given the multi-modal environmental data of vegetation, atmosphere, and topography, the simulator can generate data on wildfire areas that change over time. This effectively addresses the problem of missing data due to intermittent observation by satellite. Besides, people can let the forest fire start at any possible position in the simulated environment, producing diverse fire-spreading data for model training.

The above manner takes advantage of the empirical, physical, and AI models, using large-scale simulation data to train the AI-based forecast and backtracking models. However, this manner faces two problems relevant to the Sim2Real gap. First, as the simulator employs approximate physical rules to generate simulation data, it introduces simulation errors, resulting in the Sim2Real gap between simulated and real data. Second, different simulators predict fire changes based on empirical or physical models. Even with the same environmental conditions, these simulators may yield vastly different prediction results, further exacerbating the Sim2Real gap. Natural forests' exceptionally complex climate and terrain environments make it infeasible to verify whether the results obtained by different simulators are reliable. This further makes it challenging to eliminate erroneous fire simulation data. The incorrect simulation results introduce significant noise into model training.

We promote research on minimizing the Sim2Real gap and utilizing the simulation data to train AI models for the spread forecast and backtracking of wildfires in real-world forests. We collect the Sim2Real-Fire dataset that contains 1M virtual wildfire scenarios. These scenarios are produced by widely-used simulators, FARSITE , WFDS , and WRF-SFIRE . We prepare the environmental data of vegetation, fuel, topography, weather, and fire areas for each scenario. These data are in the multi-modal format captured from the satellite's view. Sim2Real-Fire provides large-scale data for training the AI-based forecast and backtracking models. We collect 1K worldwide scenarios of wildfire in the natural forest. We select these real scenarios from publicly available satellite data. Compared to the existing datasets [19; 32; 33; 34; 35; 36], Sim2Real-Fire provides more large-scale and challenging data for testing the Sim2Real performances of AI models.

We also contribute a Sim2Real model, S2R-FireTr, based on a deep transformer network inspired by semantic segmentation methods [37; 38], for forest fire spread forecast and backtracking. We train S2R-FireTr on the simulation data. S2R-FireTr comprehensively captures the correlation between multi-modal data to alleviate the Sim2Real gap in network training. Moreover, S2R-FireTr can be trained on temporally incomplete data to enhance its forecast and backtracking capacities during testing on real-world data. We evaluate S2R-FireTr on the new Sim2Real-Fire dataset, surpassing the performances of state-of-the-art methods.

## 2 Sim2Real-Fire Dataset

The Sim2Real-Fire dataset contains wildfire simulation and real-world data. The set includes 1M and 1K wildfire scenarios. Each scenario is associated with five data modalities of environmental information, including topography, vegetation, fuel maps, weather data, and satellite images with the annotated fire regions. We align these modalities spatially and temporally.

### Data Modalities of Environmental Information

Figure 1 shows examples of topography, vegetation, fuel, weather, and satellite data.

Topography MapWe follow the format of LANDFIRE  to make the topography map. Each topography map describes the landscape of a region of the United States, Canada, or Mexico from 2013 to 2023. It can be divided into three channels: landscape aspect, elevation, and slope. Aspect is the azimuth of sloping surfaces across a landscape. The elevation is the land elevation (meters) above mean sea level. The slope is the change in elevation over a specific area.

Vegetation MapWe follow LANDFIRE to collect the vegetation map. Each vegetation map consists of the channels of existing vegetation type (EVT), existing vegetation cover (EVC), existing vegetation height (EVH), and existing vegetation type national vegetation classification(EVTNVC). EVT provides the classification of about 700 types of plants. EVC represents the vertical projection of a region's percent live canopy cover. EVH is the average height of the dominant vegetation. EVTNVC is an existing vegetation-type layer representing the distribution of vegetation groups based on the USNVC classification.

Fuel MapThe fuel map has four channels: surface fuel (SF), canopy fuel (CF), fuel disturbance (FD), and fuel vegetation (FV). SF represents the fuel distribution of sizes and types. CF contains information about forest canopy cover, height, and density. FD integrates the individual disturbance of the burnable vegetation for modeling the fuel transition. FV is an adapted depiction of vegetation for converting continuous vegetation values into the fuel model.

Weather DataThe weather data is tabular, collected from the Remote Automatic Weather Station . Each table of weather data contains the temperature, relative humidity, precipitation, wind speed, wind direction, and cloud cover, which are recorded in the hourly sequence.

Figure 1: Topography, vegetation, fuel, weather, and the satellite data in the Sim2Real-Fire dataset.

Satellite ImagesWe use the satellite image sequences of the fire regions, which are captured by Landsat-8  and Sentinel-2  satellites. Landsat-8 carries the Operational Land Imager and Thermal Infrared Sensor, orbiting the Earth every 99 minutes with a revisit period of 16 days. Sentinel-2 consists of 2A and 2B, with a revisit period of 10 and 5 days, respectively. Each image has the mask annotation of the fire regions.

### Simulation Data

We use the simulation data to train and test the forecast and backtracking models. We prepare 1M virtual wildfire scenarios, each with five data modalities. The satellite image sequence of each scenario contains about 100 frames of fire spread. We divide these simulation data by 80%/20% to form the training and testing sets. Below, we introduce how to use the wildfire simulators (i.e., FARSITE , WFDS , and WRF-SFIRE ) to produce the virtual scenarios.

SimulatorsFARSITE relies on the empirical model to simulate wildfires. The input to FARSITE consists of the topography, vegetation maps, and weather data. Given the above three modalities of environmental information, FARSITE simulates the fire spread represented by a sequence of mask annotations. We fuse the mask annotations of fire regions with the satellite images, thus approximating real-world fire regions with changing boundaries.

WFDS combines numerical methods and physical models to simulate wildfires. It allows tuning the speed and scope of fire spread by controllable parameters. WFDS can produce satellite images with fire regions and smoke, which show realism like real-world images.

Like WFDS, WRF-SFIRE takes input as the simulation process's topography, fuel maps, and weather data. It outputs detailed information on fire dynamics, including the rate of spread, fire intensity, and spatial extent hourly. Unlike FARSITE and WFDS, which assume the weather data are independent of the fire spread, WRF-SFIRE yields weather data that may be significantly affected by the fire spread, thus facilitating the analysis of fire-weather interactions.

Simulated Masks of Fire RegionsThe simulator outputs a sequence of binary masks to represent the change of fire regions in each virtual scenario. To enrich the simulation data, we randomly jitter the initial location of the wildfire and other controllable parameters (e.g., the speed and scope of fire spread). Given an identical set of multi-modality environmental data (i.e., topography, vegetation, fuel maps, weather data, and satellite images), we employ the simulator with the jittered parameters to produce about 200 discrepant sequences of mask annotations.

### Real-world Data

Apart from the masks of fire regions produced by the simulators, we collect 1K real-world wildfire scenarios from the satellite images. We recruit a group of human annotators to identify and label the fire regions. Each real-world scenario also has five modalities of environmental information. Each sequence has 2-10 satellite images. The real-world scenarios are used for model testing.

Data SelectionWe select the satellite images collected by Landsat-8 and Sentinel-2, fuse the images of different wavebands, and eliminate the images without clearly observing the fire regions due to dense clouds or smoke occlusion. We keep the spatial resolution of these fused images to 30 meters to capture landscapes on the Earth. We convert the fused images into tones close to real images through pseudo-colorization.

Data AnnotationWe import the fused satellite images into ArcGIS , allowing human annotators to label the binary masks of the wildfire regions. Each mask is a polygon. Each annotator uses NV5 GEOSPATIAL software  to identify fire areas automatically. We recruit 20 annotators to manage the labeling task. To guarantee the quality of the annotations, we require three annotators to cross-check every binary mask. People need to refine a mask disapproved by three annotators.

### Dataset Statistics and Comparison

We list the basic information of different datasets for wildfire analysis in Table 1. The Sim2Real-Fire dataset contains 1M scenarios of wildfire spreading over the world. It provides five data modalities: topography, vegetation, fuel, weather, and satellite data. We divide these data modalities into two groups. The first group contains the topography, vegetation, fuel maps, and satellite images, which provide the spatial information of the wildfire scenarios. The second group contains sequential weather data and satellite images to capture the temporal dynamic of wildfire scenarios.

Compared to other datasets, Sim2Real-Fire offers richer environmental information across multiple modalities. The satellite images in this dataset have a spatial resolution of less than 30 meters for capturing wildfire scenarios, enabling more precise visualization of surrounding environments and fire areas. A key advantage of our dataset is its multi-modal hybrid data encompassing both simulated and real-life wildfire scenarios. The Sim2Real-Fire dataset is the first public dataset designed to support training forest fire forecast and backtracking models on simulation data and testing them on real-world data. The simulation data in this dataset was generated using various simulators (empirical, numerical, and physical models) to produce diverse fire scenarios, addressing the limitations that relying on a single simulator can introduce biases in model training.

Among the five modalities in the Sim2Real-Fire dataset, the vegetation and fuel maps provide the category-wise data. The topography map and weather data contain numerical data, which can be divided into several ranges. We report the proportions of the vegetation and fuel categories in Figure 2(a-b). The topography and weather data ranges are shown in Figure 2(c-d).

## 3 Architecture of S2R-FireTr

We regard the forecast or backtracking of forest fires as a temporal sequence-to-sequence translation task. Given the source sequence of with \(T\) binary masks of forest fire areas as \(^{H W T}\)

  Name & Scenarios & Countries & Areas & Tasks & Period & Temporal & Size-Recall & Modalities \\    &  &  &  &  &  &  &  &  &  &  \\  Pire Atlas  & 13M & Workside & 149,000,000 & Fire & Backhouse & 200,301-2016 & 500m & Italy & Real Only & 1 \\  Github  & 16M & Workside & 149,000,000 & Fire & Backhouse & 200,301-2016 & 500m & Italy & Real Only & 1 \\  Github  & 16M & Workside & 149,000,000 & Fire & Backhouse & 200,301-2017 & 500m & Italy & Real Only & 1 \\  Wadsen  & 17M & USA & 93,430,000 & Spread & 201,201-2017 & 375m & Italy & Real Only & 4 \\  Sostile Cube  & 20R & Workside & 149,000,000 & Spread & 200,301-2017 & 250m & Italy & Real Only & 4 \\  Next Day Wildlife  & 18K & USA & 93,340,000 & Spread & 201,202-2010 & 18m & Italy & Real Only & 4 \\  Wadsen-SysersHTS  & 607 & USA & 9,334,000 & Spread & 2018-2021 & 375m & Italy & Real Only & 4 \\  } &  &  &  & Spread & Forecast &  &  &  &  \\  & & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & & \\  Mesopress  & 25K & Mediterranean & 9,000,000 & Burned & 2006-2022 & Iran & Italy & Real Only & 4 \\  MODS Thermal Anomaly & 40K & Workside & 149,000,000 & Spars & 2000-2024 & Iran & Italy & Real Only & 3 \\  VIRIS Thermal Anomaly & 40K & Workside & 149,000,000 & Spars & 201,202-2024 & 375m & 12hours & Real Only & 3 \\  NSDAR HIDS & 1K & North America & 24,710,000 & Disp & Forecast & 2018-2024 & 50m & Italy & Real Only & 3 \\  NSDAR HIDS Small & 1K & North America & 24,710,000 & Disp & Forecast & 2018-2024 & 50m & Italy & Real Only & 1 \\  GOES Wildfires & 1K & Western Hemisphere & 61,000,000 & Spars & 2017-2024 & 28m & 50mins & Italy & Real Only & 4 \\  NHC-Waffire Pointcloud & 20K & USA & 9,834,000 & Spread & 2000-2024 & 28m & 50mins & Real Only & 1 \\ 
**Sim2Real-Fire** & **1M** & **Worldside** & **20,000,000** & **Spread Forecast** & **2013-2023** & **30m** & **1hour** & **Sim&Real Only** & 5 \\  

Table 1: Comparison with the related datasets for wildfire analysis.

Figure 2: (a) Distribution of vegetation covers and types. (b) Distribution of fuel types. (c) Distribution topography data. (d) Distribution of weather data.

\(H W\) indicates the spatial resolution of each image. The translation outputs the target sequence with \(T\) binary masks \(^{H W T}\) of forest fire areas. \(\) represents the historical or future changes of the fire areas, temporally, in the forecast or backtracking task. We propose S2R-FireTr to accomplish the above translation. As illustrated in Figure 3, S2R-FireTr consists of the modules of **Environment-guided Area Representation Learning** and **Time-wise Fire Area Regression**.

**Environment-guided Area Representation Learning** The first module of S2R-FireTr (Figure 3(a)) takes input as the source sequence of binary masks \(^{H W T}\), which represents the known areas of forest fire within \(T\) timestamps. We employ the satellite images \(^{H W 3 T}\), the topography, vegetation, fuel maps \(,,^{H W C}\), and the weather \(^{C T}\) to learn the source area representation \(^{H W C T}\) for the source sequence \(\). \(C\) indicates the channels.

We employ the dual cross-attention to learn the source area representation \(\). In Eq. (1), the dual cross-attention considers the correlation between multi-modal data from the spatial and temporal perspectives. We compute the query vector \(^{H W C T}\) based on the source sequence \(\). We compute two sets of key and value vectors, \(^{spatial},^{spatial},^{temporal},^{ temporal}^{H W C T}\), based on the spatial and temporal information of the satellite image sequence \(\), the topography, vegetation, fuel maps \(,,\), and the weather \(\) as:

\[=SwinEnc(),\] \[^{spatial}=SwinEnc([,,, ]),\ \ ^{spatial}=SwinEnc([,,, ]),\] \[^{temporal}=[SwinEnc(),MHA(W)],\ \ ^{ temporal}=[SwinEnc(),MHA(W)],\] \[=softmax(^{spatial}}{ })^{spatial}+softmax( ^{temporal}}{})^{temporal}, \]

where \([]\), \(SwinEnc\), \(MHA\) and \(softmax\) denote the feature concatenation, the encoder of Swin Transformer , multi-head attention, and softmax function.

Figure 3: S2R-FireTr forecasts wildfires by predicting future target fire areas based on source fire areas. (a) During the environment-guided area representation learning, we input the source fire areas and multi-modal environmental information into the transformer to compute the source area presentation \(\). (b) During the time-wise fire area regression, we input the source area presentation \(\) and the target timestamp into the transformer to compute the target area presentation \(\) for predicting the target fire areas. **“Shifted Later”** means that we concatenate the source and target areas to predict later areas. Source and target areas can be interchanged, creating a pipeline for wildfire backtracking.

The above dual cross-attention comprehensively constructs the correlation between fire areas and multi-modal spatial-temporal data. During network training, despite the Sim2Real gap between fire areas of the simulation and real situations, the dual cross-attention can still rely on the correlation between multi-modal data to learn fire area representations that are more consistent with the natural environment. It thereby reduces the negative impact of the Sim2Real gap on network training.

Time-wise Fire Area RegressionBased on the source area representation \(\) of the source sequence \(\), we use the second module of S2R-FireTr (Figure 3(b)) to compute the target area representation \(^{H W C T}\) of the future/history fire areas. Based on the target area representation \(_{*}\) we regress the target sequence \(^{H W T}\) of the forest fire areas in the forecast/backtracking task. We implement the area regression by a cross-attention. This module regards a set of timestamps \([p(1),...,p(T)]\) as the query, the source area representation \(\) as the key and value as:

\[=pos([p(1),...,p(T)]),\ \ =conv(),\ \ = conv(),\ \ =softmax(}{}) , \]

where \(,,^{H W C T}\) represent the query, key, and value vectors. \(pos\) means the positional encoding. We remark that the timestamps \([p(1),...,p(t),...,p(T)]\) in Eq. (2), which are used for computing the query vector \(\), are unnecessarily continuous. \(p(t)\) is the timestamp of the \(t^{th}\) frame. This allows the model to be tested on real-world data, which may be temporally incomplete.

Given the target area representation \(\), we regress the target sequence of binary masks \(}^{H W T}\) as:

\[}=SwinDec(),\ \ =\|- }\|, \]

where \(SwinDec\) means the decoder of Swin Transformer. During the model training phase, we minimize the difference between the regressed sequences \(}\) and the ground-truth sequences \(\).

## 4 Experimental Results

We compare S2R-FireTr with the empirical, physical, and AI models on the Sim2Real spread forecast and backtracking tasks. We train all AI models on the simulation data and evaluate their performances on the simulation and real-world data. These simulators are based on empirical and physical models and work without a training process. They only rely on the multi-modal environmental information to predict the fire spread during the evaluation phase. We evaluate the performances of these models in terms of AUPRC (Area Under the Precision-Recall Curve), Intersection over Union (IOU), and F1-score. We report each metric in percentage (%).

    &  &  \\   &  &  &  &  \\   & AUPRC & F1 & IOU & AUPRC & F1 & IOU & AUPRC & F1 & IOU & AUPRC & F1 & IOU \\   ConvLSTM  & 36.2 & 44.3 & 28.1 & 29.3 & 22.1 & 20.1 & 24.7 & 39.0 & 23.6 & 16.4 & 15.9 & 14.3 \\ Mau  & 59.4 & 67.4 & 50.2 & 43.6 & 49.8 & 41.9 & 54.7 & 60.2 & 35.3 & 40.1 & 45.5 & 32.6 \\ PredRNN-v2  & 75.2 & 71.0 & 55.2 & 66.2 & 58.0 & 49.3 & 59.9 & 62.3 & 46.4 & 50.9 & 51.7 & 40.8 \\ Rainformer  & 79.7 & 78.8 & 69.6 & 67.2 & 65.5 & 52.0 & 73.3 & 71.9 & 57.0 & 54.6 & 52.4 & 42.9 \\ Earthformer  & 77.2 & 73.5 & 59.7

[MISSING_PAGE_FAIL:8]

these components, designed for learning correlation between multiple modalities of environmental information from the temporally incomplete data, remarkably degrade the performances.

In Table 8, we further study the impact of the input and output length of the temporal data (i.e., weather and satellite images) on the performance of S2R-FireTr. Excessively long input and output sequences degrade the performances. It demonstrates that forecasting and backtracking the long-term wildfire areas are highly challenging tasks. On the other hand, we find that the performance of

    &  &  \\  Method & w/o & w/o & w/o & w/o & w/o &  & w/o & w/o & w/o & w/o & w/o &  \\   & Topo. & Veg. & Fuel & Wea. & Sat. & Full & Topo. & Veg. & Fuel & Wea. & Sat. & Full \\   ConvLSTM  & 20.3 & 21.0 & 21.4 & 21.3 & 20.8 & 24.7 & 13.3 & 13.5 & 14.0 & 13.6 & 13.5 & 16.4 \\ Mau  & 50.8 & 51.2 & 51.3 & 50.4 & 50.7 & 54.7 & 35.7 & 35.8 & 36.1 & 35.4 & 35.7 & 40.1 \\ PredRNN-V2  & 54.6 & 54.3 & 55.9 & 55.0 & 54.8 & 59.9 & 45.3 & 45.2 & 46.1 & 45.7 & 45.6 & 50.9 \\ Rainformer  & 70.7 & 71.2 & 71.4 & 71.0 & 70.9 & 73.3 & 50.1 & 50.7 & 51.6 & 50.4 & 50.5 & 54.6 \\ Earthformer  & 66.4 & 67.3 & 67.8 & 66.1 & 67.0 & 71.4 & 48.7 & 49.0 & 49.3 & 47.7 & 47.8 & 53.4 \\ SwinLSTM  & 67.8 & 68.1 & 68.4 & 67.9 & 67.4 & 72.5 & 48.3 & 49.2 & 49.4 & 48.3 & 47.9 & 53.8 \\ Earthfarsser  & 64.5 & 65.0 & 65.4 & 63.3 & 63.7 & 69.3 & 46.8 & 47.0 & 47.2 & 46.8 & 46.0 & 51.6 \\ 
**S2R-FireTr** & **75.7** & **75.8** & **76.1** & **74.9** & **75.0** & **78.6** & **59.8** & **60.0** & **61.3** & **59.4** & **60.7** & **63.9** \\   

Table 6: Impact of modalities on AI backtracking models. We report the results in terms of AUPRC.

Figure 4: Forecast and backtracking results of different methods.

S2R-FireTr within six frames is satisfactory. Given that the sequence length of fire areas in real-world applications is relatively short, we consider the practicability of S2R-FireTr to be solid.

## 5 Conclusion

This paper introduces the Sim2Real-Fire dataset with 1M simulated scenarios and 1K realistic wildfire scenarios for training and testing AI models that forecast and backtrack wildfires in the real world. This dataset is meaningful for the Sim2Real investigation of wildfire forecast and backtracking. Technically, we contribute a deep transformer, S2R-FireTr, trained on the simulated scenarios. S2R-FireTr surpasses state-of-the-art methods, demonstrating the potential of minimizing the Sim2Real gap between the simulated and realistic wildfire scenarios. The sim2Real-Fire dataset is limited as it only includes wildfire scenarios from certain countries and periods due to the limited budget for data acquisition in reality. This closed nature reduces the richness of the training data, limiting the model's ability to generalize to unknown environmental conditions. To address this, we advocate for dynamic data acquisition methods to transform the dataset into an open resource. In the future, we will extend our dataset and method to a broader range of wildfire analysis tasks, where we need to transfer the fire spread patterns learned from the simulated scenarios to the real world. People can access our dataset, a video detailing the dataset creation process, relevant documentation, and model code via [https://github.com/TJU-IDVLab/Sim2Real-Fire](https://github.com/TJU-IDVLab/Sim2Real-Fire).

## 6 Broader Impacts

This paper has several potential positive societal impacts: the proposed Sim2Real-Fire dataset, a multi-modal dataset with temporal data, is designed to facilitate deep learning models on the relevant tasks for wildfire analysis. The proposed S2R-FireTr model provides a comprehensive understanding of the multiple environmental factors influencing forecast and backtracking, thereby enhancing the accuracy of wildfire prediction. This work has inconspicuous negative societal impacts.

## 7 Acknowledgement

The Key Science and Technology Program of the Ministry of Emergency Management of the People's Republic of China (2024EMST010102) fully supported this work.

    &  &  &  \\   & & &  &  &  &  \\   & & AUPRC & F1 & IOU & AUPRC & F1 & IOU & AUPRC & F1 & IOU & AUPRC & F1 & IOU \\  ✗ & ✗ & 70.1 & 74.5 & 59.8 & 60.2 & 64.8 & 45.3 & 58.7 & 63.4 & 46.4 & 42.4 & 50.2 & 33.8 \\ ✗ & ✓ & 79.0 & 82.2 & 70.1 & 63.9 & 65.8 & 47.7 & 75.2 & 71.9 & 56.3 & 58.5 & 54.5 & 37.7 \\ ✓ & ✗ & 83.0 & 82.5 & 70.3 & 70.1 & 66.7 & 50.1 & 76.1 & 72.0 & 56.5 & 59.0 & 57.1 & 39.7 \\  ✓ & ✓ & **87.3** & **83.2** & **71.2** & **72.9** & **69.6** & **56.4** & **78.6** & **73.5** & **58.1** & **63.9** & **60.3** & **46.9** \\   

Table 7: Ablation study of key components on the forecast and backtracking tasks. EARL and TFAR mean environment-guided area representation learning and time-wise fire area regression.

    &  &  \\   &  &  &  &  \\   & AUPRC & F1 & IOU & AUPRC & F1 & IOU & AUPRC & F1 & IOU & AUPRC & F1 & IOU \\ 
1 & 83.3 & 77.4 & 65.1 & 68.4 & 64.7 & 55.4 & 70.2 & 67.3 & 50.6 & 55.9 & 50.2 & 36.6 \\
2 & 85.0 & 80.4 & 67.3 & 70.1 & 67.0 & 55.9 & 75.1 & 69.2 & 52.9 & 59.7 & 55.6 & 38.5 \\
3 & 87.3 & 83.2 & 71.2 & **72.9** &