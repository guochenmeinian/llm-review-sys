# Discretely Beyond \(1/e\): Guided Combinatorial Algorithms for Submodular Maximization

Yixin Chen, Ankur Nath, Chunli Peng, Alan Kuhnle

Department of Computer Science & Engineering

Texas A&M University

College Station, TX

{chen777, anath, chunli.peng, kuhnle}@tamu.edu

###### Abstract

For constrained, not necessarily monotone submodular maximization, all known approximation algorithms with ratio greater than \(1/e\) require continuous ideas, such as queries to the multilinear extension of a submodular function and its gradient, which are typically expensive to simulate with the original set function. For combinatorial algorithms, the best known approximation ratios for both size and matroid constraint are obtained by a simple randomized greedy algorithm of Buchbinder et al. : \(1/e 0.367\) for size constraint and \(0.281\) for the matroid constraint in \((kn)\) queries, where \(k\) is the rank of the matroid. In this work, we develop the first combinatorial algorithms to break the \(1/e\) barrier: we obtain approximation ratio of \(0.385\) in \((kn)\) queries to the submodular set function for size constraint, and \(0.305\) for a general matroid constraint. These are achieved by guiding the randomized greedy algorithm with a fast local search algorithm. Further, we develop deterministic versions of these algorithms, maintaining the same ratio and asymptotic time complexity. Finally, we develop a deterministic, nearly linear time algorithm with ratio \(0.377\).

## 1 Introduction

A nonnegative set function \(f:2^{}^{+}\) is _submodular_ iff for all \(S T\), \(x T\), \(f(S\{x\})-f(S) f(T\{x\})-f(T)\); and \(f\) is monotone iff \(f(S) f(T)\) for all \(S T\). Submodular optimization plays an important role in data science and machine learning , particularly in tasks that involve selecting a representative subset of data or features. Its diminishing returns property makes it ideal for scenarios where the incremental benefit of adding an element to a set decreases as the set grows. Applications include sensor placement for environmental monitoring , where the goal is to maximize coverage with limited sensors, feature selection  in machine learning to improve model performance and reduce overfitting, and data summarization  for creating concise and informative summaries of large datasets. Further, many of these applications employ submodular objective functions that are non-monotone, _e.g._ Mirzasoleiman et al. , Tschiatschek et al. . Formally, we study the optimization problem (SM): \( f(S),\)_s.t._\(S\), where \(f\) is nonnegative, submodular and not necessarily monotone; and \( 2^{}\) is a family of feasible subsets. Specifically, we consider two cases: when \(\) is a size constraint (all sets of size at most \(k\)); and more generally, when \(\) is an arbitrary matroid of rank \(k\).

In this field, algorithms typically assume access to a _value oracle_ for the submodular function \(f\), and the efficiency of an algorithm is measured by the number of queries to the oracle, because evaluation of the submodular function is typically expensive and dominates other parts of the computation. In the general, not necessarily monotone case, the approximability of constrained submodular optimization in the value oracle model is not well understood. For several years, \(1/e 0.367\) was conjecturedto be the best ratio, as this ratio is obtained by the measured continuous greedy  algorithm that also gets the \(1-1/e\) ratio in the monotone setting, which is known to be optimal . However, in several landmark works, the \(1/e\) barrier was broken: first to \(0.371\) by Buchbinder et al.  (for size constraint only) and subsequently to \(0.372\) by Ene and Nguyen , then \(0.385\) by Buchbinder and Feldman . Very recently, the best known approximation factor has been improved to 0.401 . On the other hand, the best hardness result is \(0.478\)[16; 28].

All of the algorithms improving on the \(1/e\) ratio use oracle queries to the _multilinear extension_ of a submodular function and its gradient. The multilinear extension relaxes the submodular set function to allow choosing an element with probability in \(\). Although this is a powerful technique, the multilinear extension must be approximated by polynomially many random samples of the original set function oracle. Unfortunately, this leads to a high query complexity for these algorithms, which we term _continuous algorithms_; typically, the query complexity to the original submodular function is left uncomputed. As an illustration, we compute in Appendix B that the continuous algorithm of Buchbinder and Feldman  achieves ratio of \(0.385\) with query complexity of \((n^{11}(n))\) to the set function oracle. Consequently, these algorithms are of mostly theoretical interest - the time cost of running on tiny instances (say, \(n<100\)) is already prohibitive, as demonstrated by Chen and Kuhnle  where a continuous algorithm required more than \(10^{9}\) queries to the set function on an instance with \(n=87,k=10\).

For size and matroid constraints, the current state-of-the-art approximation ratio for a combinatorial algorithm (_i.e._ not continuous) is obtained by the RandomGreedy algorithm (Algorithm 1) of Buchbinder et al. . RandomGreedy achieves ratio \(1/e 0.367\) for size constraint, and \(0.283-\) ratio for matroid constraint; its query complexity is \((kn)\). Thus, there is no known combinatorial algorithm that breaks the \(1/e\) barrier; and therefore, no such algorithm is available to be used in practice on any of the applications of SM described above.

Moreover, closing the gap between ratios achieved by deterministic and randomized algorithms for SM has been the focus of a number of recent works [5; 17; 11; 8]. In addition to theoretical interest, deterministic algorithms are desirable in practice, as a ratio that holds in expectation may fail on any given run with constant probability. Buchbinder and Feldman  introduced a linear programming method to derandomize the RandomGreedy algorithm (at the expense of additional time complexity), meaning that the best known ratios for deterministic algorithms are again given by RandomGreedy. There is no known method to derandomize continuous

   Constraint & Reference & Query & Ratio & Type \\   & Buchbinder and Feldman  & \((k^{3}n)\) & \(1/e 0.367\) & Det \\  & Buchbinder et al.  & \((kn)\) & \(1/e\) & Cmb \\  & Buchbinder and Feldman  & poly(\(n\)) & \(0.401\) & Cts \\   & Algorithm 2 & \((kn/)\) & \(0.385-\) & Cmb \\  & Algorithm 11 & \((kn()^{-1})\) & \(0.385-\) & Det \\  & Algorithm 14 & \(((k)n()^{}()^{-1})\) & \(0.377-\) & Det \\   & Sun et al.  & \((k^{2}n^{2})\) & \(0.283-(})\) & Det \\  & Buchbinder et al.  & \((kn)\) & \(0.283-\) & Cmb \\  & Buchbinder and Feldman  & poly(\(n\)) & \(0.401\) & Cts \\   & Algorithm 2 & \((kn/)\) & \(0.305-\) & Cmb \\  & Algorithm 11 & \((kn()^{-1})\) & \(0.305-\) & Det \\   

Table 1: The prior state-of-the-art and the ratios achieved in this paper, in each category: deterministic (det), randomized combinatorial (cmb), and continuous (cts).

algorithms, as the only known way to approximate the multilinear extension of a general submodular set function relies on random sampling methods. Ozcan et al. , however, introduced a deterministic estimation via Taylor series approximation, but this approach is limited to a specific class of submodular functions that can be expressed as weighted compositions of analytic and multilinear functions. Therefore, there is no known deterministic algorithm that breaks the \(1/e\) barrier. The best known ratio in each category of continuous, combinatorial, and deterministic algorithms is summarized in Table 1. In this work, we consider the following questions:

_Can combinatorial algorithms, and separately, deterministic algorithms, obtain approximation ratios for SM beyond \(1/e\)? If so, are the resulting algorithms practical and do they yield empirical improvements in objective value over existing algorithms?_

### Contributions

In this work, we improve the best known ratio for a combinatorial algorithm for size-constrained SM to \(0.385- 1/e+0.018\). This is achieved by using the result of a novel local search algorithm to guide the RandomGreedy algorithm. Overall, we obtain query complexity of \((kn/)\), which is at worst quadratic in the size of the ground set, since \(k n\). Thus, this algorithm is practical and can run on moderate instance sizes; the first algorithm with ratio beyond \(1/e\) for which this is possible. Further, we extend this algorithm to the matroid constraint, where it improves the best known ratio of a combinatorial algorithm for a general matroid constraint from \(0.283\) of RandomGreedy to \(0.305-\).

Secondly, we obtain these same approximation ratios with deterministic algorithms. The ideas are similar to the randomized case, except we leverage a recently formulated algorithm InterpolatedGreedy as a replacement for guided RandomGreedy. The analysis of InterpolatedGreedy has similar recurrences (up to low order terms) and the algorithm can be guided in a similar fashion to RandomGreedy, but is amenable to derandomization. The derandomization only adds a constant factor, albeit one that is exponential in \((1/)\).

Next, we seek to lower the query complexity further, while still improving the \(1/e\) ratio. As InterpolatedGreedy can be sped up to \(_{}(n k)\), the bottleneck becomes the local search procedure. Thus, we develop a faster way to produce the guiding set \(Z\) by exploiting a run of (unguided) InterpolatedGreedy and demonstrating that a decent guiding set is produced if the algorithm exhibits nearly worst-case behavior. With this method, we achieve a deterministic algorithm with ratio \(0.377 1/e+0.01\) in \(_{}(n k)\) query complexity, which is nearly linear in the size of the ground set (since \(k=O(n)\)).

Finally, we demonstrate the practical utility of our combinatorial \(0.385\)-approximation algorithm by implementing it and evaluating in the context of two applications of size-constrained SM on moderate instance sizes (up to \(n=10^{4}\)). We evaluate it with parameters set to enforce a ratio \(>1/e\). It outperforms both the standard greedy algorithm and RandomGreedy by a significant margin in terms of objective value; moreover, it uses about twice the queries of RandomGreedy and is orders of magnitude faster than existing local search algorithms.

### Additional Related Work

**Derandomization.** Buchbinder and Feldman  introduced a linear programming (LP) method to derandomize the RandomGreedy algorithm, thereby obtaining ratio \(1/e\) with a deterministic algorithm. Further, Sun et al.  were able to apply this technique to RandomGreedy for matroids. A disadvantage of this approach is an increase in the query complexity over the original randomized algorithm. Moreover, we attempted to use this method to derandomize our guided RandomGreedy algorithm, but were unsuccessful. Instead, we obtained our deterministic algorithms by guiding the InterpolatedGreedy algorithm instead of RandomGreedy; this algorithm is easier to derandomize, notably without increasing the asymptotic query complexity.

**Relationship to Buchbinder and Feldman .** The continuous, \(0.385\)-approximation algorithm of Buchbinder and Feldman  guides the measured continuous greedy algorithm using the output of a continuous local search algorithm, in analogous fashion to how we guide RandomGreedy with the output of a combinatorial local search. However, the analysis of RandomGreedy is much different from that of measured continuous greedy, although the resulting approximation factor is the same.

Specifically, Buchbinder and Feldman  obtain their ratio by optimizing a linear program mixing the continous local search and guided measured continous greedy; in contrast, we use submodularity and the output of our fast local search to formulate new recurrences for guided RandomGreedy, which we then solve.

**Local search algorithms.** Local search is a technique widely used in combinatorial optimization. Nemhauser et al.  introduced a local search algorithm for monotone functions under size constraint; they showed a ratio of \(1/2\), but noted that their algorithm may run in exponential time. Subsequently, local search has been found to be useful, especially for non-monotone functions. Feige et al.  proposed a \(1/3\) approximation algorithm with \((n^{4}/)\) queries for the unconstrained submodular maximization problem utilizing local search. Meanwhile, Lee et al.  proposed a local search algorithm for general SM with matroid constraint, attaining \(1/4-\) approximation ratio with a query complexity of \((k^{5}(k)n/)\). We propose our own FastLS in Section 2.1, yielding a ratio of \(1/2\) for monotone cases and \(1/4\) for non-monotone cases through repeated applications of FastLS, while running in \((kn/)\) queries.

**Fast approximation algorithms.** Buchbinder et al.  developed a faster version of RandomGreedy for size constraint that reduces the query complexity to \(_{}(n)\) with ratio of \(1/e-\). Chen and Kuhnle  proposed LinearCard, the first deterministic, linear-time algorithm with an \(1/11.657\)-approximation ratio for size constraints. Also, Han et al.  introduced TwinGreedy, a \(0.25\)-approximation algorithm with a query complexity of \((kn)\) for matroid constraints. These algorithms are fast enough to be used as building blocks for our FastLS, which requires as an input a constant-factor approximation in \((kn)\) queries.

**Relationship to Tukan et al. .** During the submission of this paper, we noticed an independent and parallel work by Tukan et al. , which proposed a different \(0.385\)-approximation algorithm. Both papers start from a similar idea-guiding the random greedy algorithm with a fast algorithm to find a local optimum. However, Tukan et al.  only considered size constraint and focused on algorithm speedup. They introduced a randomized local search algorithm and used its output to guide the stochastic greedy of Buchbinder et al. , achieving a query complexity of \(_{}(n+k^{2})\). On the other hand, we 1) address a more general constraint-matroid constraint; 2) for size constraint, present an asymptotically faster algorithm that uses a novel way of guiding with partial solutions from random greedy itself, which are not local optima, thereby achieving ratio \(0.377-\) with \(_{}(n(k))\) queries; and 3) derandomize these algorithms.

### Preliminaries

**Notation.** In this section, we establish the notations employed throughout the paper. We denote the marginal gain of adding \(A\) to \(B\) by \((A|B)=f(A B)-f(B)\). For every set \(S\) and an element \(x\), we denote \(S\{x\}\) by \(S+x\), and \(S\{x\}\) by \(S-x\). Given a constraint and its related feasible sets \(\), let \(O_{S}f(S)\); that is, \(O\) is an optimal solution. To simplify the pseudocode and the analysis, we add \(k\)_dummy elements_ into the ground set, where the dummy element serves as a null element with zero marginal gain when added to any set. The symbol \(e_{0}\) is utilized to represent a dummy element.

**Submodularity.** A set function \(f:2^{}^{+}\) is submodular, if \((x|S)(x|T)\) for all \(S T\) and \(x T\), or equivalently, for all \(A,B\), it holds that \(f(A)+f(B) f(A B)+f(A B)\).

**Constraints.** In this paper, our focus lies on two constraints: size constraint and matroid constraint. For size constraint, we define the feasible subsets as \((k)=\{S:|S| k\}\), where \(k\) is an input parameter. The matroid constraint is defined in Appendix A.

**Organization.** Our randomized algorithms are described in Section 2, with two subroutines, FastLS and GuidedRG, in Section 2.1 and 2.2, respectively. Due to space constraints, we provide only a sketch of the analysis for size constraint in the main text. The full pseudocodes and formal proofs for both size and matroid constraint are provided in Appendix C. Then, we briefly sketch the deterministic approximation algorithms in Section 2.3, with full details provided in Appendix D. Next, we introduce the nearly linear-time deterministic algorithm in Section 3, with omitted analysis provided in Appendix E. Our empirical evaluation is summarized in Section 4. In Section 5, we discuss limitations and future directions.

```
1Input: Instance \((f,)\), a constant-factor approximation \(Z_{0}\), switch time \(t\), accuracy \(>0\)
2\(Z(f,,Z_{0},)\) /* find local optimum \(Z\) */
3\(A(f,,Z,t)\) /* guided by local optimum \(Z\) */ return\(\{f(Z)\,,f(A)\}\)
```

**Algorithm 2**Randomized combinatorial approximation algorithm.

A Randomized \((0.385-)\)-approximation in \((kn/)\) Queries

In this section, we present our randomized approximation algorithm (Alg. 2) for both size and matroid constraints. This algorithm improves the state-of-the-art, combinatorial approximation ratio to \(0.385- 1/e+0.018\) for size constraint, and to \(0.305- 0.283+0.022\) for matroid constraint.

**Algorithm Overview.** In overview, Alg. 2 consists of two components, which are detailed below. The first component is a local search algorithm, FastLS (Alg. 4 in Appendix C.1), described in detail in Section 2.1. In brief, the local search algorithm takes an accuracy parameter \(>0\) and a constant-factor, approximate solution \(Z_{0}\) as input, which may be produced by any approximation algorithm with better than \((kn)\) query complexity. The second component is a random greedy algorithm, GuidedRG (Alg. 6 in Appendix C.2), that is guided by the output \(Z\) of the local search, described in detail in Section 2.2. Also, GuidedRG takes a parameter \(t\), which is the switching time (as fraction of the budget or rank \(k\)) from guided to unguided behavior. The candidate with best \(f\) value from the two subroutines is returned.

If \(f(Z)<\)OPT (otherwise, there is nothing to show), then the local search set satisfies our definition of \(((1+),)\)-guidance set (Def. 2.1 below). Under this guidance, we show that GuidedRG produces a superior solution compared to its unguided counterpart. The two components, FastLS and GuidedRG are described in Sections 2.1 and 2.2, respectively. The following theorem is proven in Section 2.2 (size constraint) and Appendix C.2.2 (matroid constraint).

**Theorem 2.1**.: Let \((f,)\) be an instance of SM. Let \(>0\), and \(k 1/\). Algorithm 2 achieves an expected \((0.385-)\)-approximation ratio for size constraint with \(t=0.372\), and an expected \((0.305-)\)-approximation ratio for matroid constraint with \(t=0.559\). The query complexity of the algorithm is \((kn/)\).

### The Fast Local Search Algorithm

In this section, we introduce FastLS (Alg. 4), which is the same for size or matroid constraints. There are several innovations in FastLS that result in \((kn/)\) time complexity, where \(k\) is the maximum size of a feasible set, and \(>0\) is an input accuracy parameter.

In overview, the algorithm maintains a feasible set \(Z\); initially, \(Z=Z_{0}\), where \(Z_{0}\) is an input set which is a constant approximation to OPT. The value of \(Z\) is iteratively improved via swapping, which is done in the following way. For each element \(a\), we compute \((a|Z a)\); if \(a Z\), this is just the gain of \(a\) to \(Z\); this requires \((n)\) queries. Then, if \(a Z\) and \(e Z\) such that \(Z a+e\) is feasible, and \((e|Z)-(a|Z a)f(Z)\), then \(a\) is swapped in favor of \(e\). If no such swap exists, the algorithm terminates.

One can show that, for each swap, the value of \(Z\) increases by at least a multiplicative \((1+/k)\) factor. Since \(f(Z)\) is initialized to a constant fraction of OPT, it follows that we make at most \((k/)\) swaps. Since each swap requires \((n)\) queries, this yields the query complexity of the algorithm: \((kn/)\). In addition, if \(f\) is monotone, FastLS gets ratio of nearly \(1/2\) for FastLS. A second repetition of FastLS yields a ratio of \(1/4\) in the case of general (non-monotone) \(f\), as shown in Appendix C.1.2. Thus, FastLS may be of independent interest, as local search obtains good objective values empirically and is commonly used in applications.

For our purposes, we want to use the output of FastLS to guide RandomGreedy. Since we will also use another algorithm for a similar purpose in Section 3, we abstract the properties needed for such a guidance set. Intuitively, a set \(Z\) is a good guidance set if it has a low \(f\)-value and also ensures that the value of its intersection and union with an optimal solution are poor.

**Definition 2.1**.: A set \(Z\) is a (\(,\))-guidance set, if given constants \(,(0,0.5)\) and optimum solution \(O\), it holds that: 1) \(f(Z)< f(O)\); 2) \(f(O Z) f(O)\); 3) \(f(O Z) f(O)\), or alternatively, 3\({}^{}\)) \(f(O Z)+f(O Z)(+)f(O)\).

Lemma 2.2 (proved in Appendix C.1.1) implies that for the FastLS output \(Z\), if \(f(Z)<\)OPT, then \(Z\) is \(((1+),)\)-guidance set.

**Lemma 2.2**.: Let \(>0\), and let \((f,())\) be an instance of SM. The input set \(Z_{0}\) is an \(_{0}\)-approximate solution to \((f,())\). FastLS (Alg. 4) returns a solution \(Z\) with \((kn(1/_{0})/)\) queries such that \(f(S Z)+f(S Z)<(2+)f(Z)\), where \(S()\).

### Guiding the RandomGreedy Algorithm

In this section, we discuss the guided RandomGreedy algorithm (Alg. 6) using an \(((1+),)\)-guidance set \(Z\) returned by FastLS. Due to space constraints, we only consider the size constraint in the main text. The ideas for the matroid constraint are similar, although the final recurrences obtained differ. The version for matroid constraints is given in Appendix C.2.2.

The algorithm GuidedRG is simple to describe: it maintains a partial solution \(A\), initially empty. It takes as parameters the switching time \(t\) and guidance set \(Z\). While the partial solution satisfies \(|A|<tk\), the algorithm operates as RandomGreedy with ground set \( Z\); after \(|A| tk\), it operates as RandomGreedy with ground set \(\). Pseudocode is provided in Appendix C.2.

**Overview of analysis.** For clarity, we first describe the (unguided) RandomGreedy analysis from Buchbinder et al. . There are two recurrences: the first is the greedy gain:

\[[f(A_{i})-f(A_{i-1})][f(O A_{i-1})-f(A_{i-1})].\]

Intuitively, the gain at iteration \(i\) is at least a \(1/k\) fraction of the difference between \(f(O A)\) and \(A\), in expectation, where \(A\) is the partial solution. If \(f\) were monotone, the right hand side would be at least \((-f(A))/k\). However, in the case that \(f\) is not monotone, the set \(O A\) may have value smaller than OPT.

To handle this case, it can be shown that the expected value of \(f(O A)\) satisfies a second recurrence:

\[[f(O A_{i})](1- )[f(O A_{i-1})]+[f(O A_{i-1} M_{i})](1-)[f(O A_{i-1}) ],\]

where \(M_{i}\) is the set of elements with the top \(k\) marginal gains at iteration \(i\), _(a)_ is from submodularity, and _(b)_ is from nonnegativity. Thus, this expected value, while initially OPT (since \(A_{0}=\)), may degrade but is bounded.

Both of these recurrences are solved together to prove the expected ratio of \(1/e\) for RandomGreedy: the worst-case evolution of the expected values of \(f(A_{i})\), \(f(O A_{i})\), according to this analysis,

Figure 1: **(a)**: The evolution of \([f(O A_{i})]\) and \([f(A_{i})]\) in the worst case of the analysis of RandomGreedy, as the partial solution size increases to \(k\). **(b)**: Illustration of how the degradation of \([f(O A_{i})]\) changes as we introduce an \((0.385+,0.385)\)-guidance set. **(c)**: The updated degradation with a switch point \(tk\), where the algorithm starts with guidance and then switches to running without guidance. The dashed curved lines depict the unguided values from **(a)**.

is illustrated in Fig. 1(a). Observe that \(f(A_{i})\) converges to OPT\(/e\) (as required for the ratio), and _observe that \(f(O A_{i})\) also converges to OPT\(/e\)_. Thus, very little gain is obtained in the later stages of the algorithm, as illustrated in the plot. The overarching idea of the guided version of the algorithm is to obtain a better degradation of \([f(O A_{i})]\), leading to better gains later in the algorithm that improve the worst-case ratio. In the following, we elaborate on this goal, the achievement of which is illustrated in Fig. 1(c).

**Stage 1: Recurrences when avoiding \(Z\).** Suppose \(Z\) is an \((,)\)-guidance set, and that RandomGreedy selects elements as before, but excluding \(Z\) from the ground set. Then, the recurrences change as follows. The recurrence for the gain becomes:

\[[f(A_{i})-f(A_{i-1})][f((O Z) A_{i-1})-f(A_{i- 1})], \]

where \(O Z\) replaces \(O\) since we select elements outside of the set \(Z\). For the second recurrence, we can lower bound the term \([f(O A_{i-1} M_{i})]\) using submodularity and the fact that \(Z A_{i-1}=\):

\[[f(O A_{i})](1- )[f(O A_{i-1})]+[f(O)-f(O Z)]. \]

Finally, a similar recurrence to (2) also holds for \(f((O Z) A_{i})\); both are needed for the analysis. Since \(Z\) is a guidance set, by submodularity, \(f(O Z) f(O)-f(O Z)(1-)\)OPT, which ensures that some gain is available by selection outside of \(Z\). And \(f(O)-f(O Z)(1-)\)OPT, which means that the degradation recurrences are improved.

The blue line in Figure 1(b) depicts this improved degradation with the size of the partial solution. However, this improvement comes at a cost: a smaller increase in \([f(A_{i})]\) is obtained over the unguided version. Therefore, to obtain an improved ratio we switch back to the regular behavior of RandomGreedy - intuitively, this shifts the relatively good, earlier behavior of RandomGreedy to later in the algorithm.

**Stage 2: Switching back to selection from whole ground set.** After the switch, the recurrences revert back to the original ones, but with different starting values. Since \([f(O A_{i})]\) was significantly enhanced in the first stage, in the final analysis we get an overall improvement over the unguided version. The blue line in Figure 1(c) demonstrates the degradation of \([f(O A_{i})]\) over two stages, while the orange line depicts how the approximation ratio converges to a value \(0.385>1/e\).

The above analysis sketch can be formalized and the resulting recurrences solved: the results are stated in the following lemma, which is formally proven in Appendix C.2.1.

**Lemma 2.3**.: With an input size constraint \(\) and a \(((1+),)\)-guidance set \(Z\), GuideDREG returns set \(A_{k}\) with \((kn)\) queries, _s.t._\([f(A_{k})][(2-t- )(1-)e^{t-1}-e^{-1}.\)\(-(1+)((1-)^{2}e^{t-1}-e^{-1} )-((1+})e^{t-1}-(2- )e^{-1})]f(O).\)

From Lemma 2.3, we can directly prove the main result for size constraint.

Proof of Theorem 2.1 under size constraint.: Let \((f,)\) be an instance of SM, with optimal solution set \(O\). If \(f(Z)(0.385-)f(O)\) under size constraint, the approximation ratio holds immediately. Otherwise, by Lemma 2.2, FastLS returns a set \(Z\) which is an \(((1+),)\)-guidance set, where \(=0.385-\). By Lemma 2.3,

\[[f(A_{k})][(2-t- )(1-)e^{t-1}-e^{-1}-(0.385-0.615 )((1-)^{2}e^{t-1}-e^{-1}).\] \[.-(0.385-)((1+)e^{t-1}-(2-)e^{-1})]f(O) ( k)\] \[(0.385-)f(O).\] ( \[t=0.372\] )

### Deterministic approximation algorithms

In this section, we outline the deterministic algorithms, for size and matroid constraints. The main idea is similar, but we replace GuidedRG with a deterministic subroutine. For simplicity, we present a randomized version in Appendix D.2 as Alg. 10, which we then derandomize (Alg. 11 in Appendix D.3). Further discussion is provided in Appendix D.

**Algorithm overview.** Chen and Kuhnle  proposed a randomized algorithm, InterpolatedGreedy, which may be thought of as an interpolation between standard greedy  and RandomGreedy. Instead of picking \(k\) elements, each randomly chosen from the top \(k\) marginal gains, it picks \(=(1/)\) sets randomly from \(()\) candidates. Although it uses only a constant number of rounds, the recurrences for InterpolatedGreedy are similar to the RandomGreedy ones discussed above, so we can guide it similarly.

To select the candidate sets in each iteration, we replace InterlaceGreedy (the subroutine of InterpolatedGreedy proposed in Chen and Kuhnle ) with a guided version: GuidedIG-S (Alg. 9 in Appendix D.1.1) for size constraint, and GuidedIG-M (Alg. 8 in Appendix D.1) for matroid constraint. Since only \(\) random choices are made, each from \(()\) sets, there are at most \((^{()})\) possible solutions, where \(\) is a constant number depending on \(\). Notably, we are still able to obtain the same approximation factors as in Section 2. The proof of Theorem 2.4 is provided in Appendices D.2 and D.3.

**Theorem 2.4**.: Let \((f,k)\) be an instance of SM, with the optimal solution set \(O\). Alg. 11 achieves a deterministic \((0.385-)\) approximation ratio with \(t=0.372\), and a deterministic \((0.305-)\) approximation ratio with \(t=0.559\). The query complexity of the algorithm is \((kn^{2-1})\) where \(=\).

## 3 Deterministic Algorithm with Nearly Linear Query Complexity

In this section, we sketch a deterministic algorithm with \((0.377-)\) approximation ratio and \(_{}(n(k))\) query complexity for the size constraint. A full pseudocode (Alg. 14) and analysis is provided in Appendix E.

**Description of algorithm.** Our goal is to improve the asymptotic \(_{}(kn)\) query complexity. Recall that in Section 2, we described a deterministic algorithm that employed the output of local search to guide the InterpolatedGreedy algorithm, which obeys similar recurrences to RandomGreedy. To produce the \(\) candidate sets for each iteration of InterpolatedGreedy, a greedy algorithm (guided InterlaceGreedy) is used. These algorithms can be sped up using a descending thresholds technique. This results in ThreshGuidedIG (Alg. 12 in Appendix E.1), which achieves \(_{}(n k)\) query complexity for the guided part of our algorithm.

However, the local search FastLS still requires \((kn/)\) queries, so we seek to find a guidance set in a faster way. Recall that, in the definition of guidance set \(Z\), the value \(f(Z)\) needs to dominate both \(f( Z)\) and \(f( Z)\). To achieve this with faster query complexity, we employ a run of unguided InterpolatedGreedy. Consider the recurrences plotted in Fig. 1(a) - if the worst-case degradation occurs, then at some point the value of \(f(A_{i})\) becomes close to \(f(O A_{i})\). On the other hand, if the worst-case degradation does not occur, then the approximation factor of InterpolatedGreedy is improved (see Fig. 2). Moreover, if we ensure that at every stage, \(A_{i}\) contains no elements that contribute a negative gain, then we will also have \(f(A_{i}) f(O A_{i})\).

To execute this idea, we run (derandomized, unguided InterpolatedGreedy, and consider all \((^{})\) intermediate solutions. Each one of these is pruned (by which we mean, any element with negative contribution is discarded until none such remain). Then, the guided part of our algorithm executes with every possible candidate intermediate solution as the guiding set; finally, the feasible set encountered with maximum \(f\) value is returned.

Figure 2: Depiction of how analysis of InterpolatedGreedy changes if there is no \((0.377,0.46)\)-guidance set.

The tradeoff between the first and second parts of the algorithm is optimized with \(=0.377\) and \(=0.46\). That is, if InterpolatedGreedy produces an \((,)\)-guidance set, the guided part of our algorithm achieves ratio \(0.377\); otherwise, InterpolatedGreedy has ratio at least \(0.377\). We have the following theorem. The algorithms and analysis sketched here are formalized in Appendix E.

**Theorem 3.1**.: Let \((f,k)\) be an instance of SM, with the optimal solution set \(\). Algorithm 14 achieves a deterministic \((0.377-)\) approximation ratio with \((n(k){_{1}}^{2_{1}}{_{2}}^{2_{2}-1})\) queries, where \(_{1}=\) and \(_{2}=\).

## 4 Empirical Evaluation

In this section, along with Appendix F, we implement and empirically evaluate our randomized \((0.385-)\)-approximation algorithm (Alg. 2, FastLS+GuidedRG) on two applications of size-constrained SM, and compare to several baselines in terms of objective value of solution and number of queries to \(f\). In summary, our algorithm uses roughly twice the queries as the standard greedy algorithm, but obtains competitive objective values with an expensive local search that uses one to two orders of magnitude more queries. 1

**Baselines.** 1) StandardGreedy: the classical greedy algorithm , which often performs well empirically on non-monotone objectives despite having no theoretical guarantee. 2) RandomGreedy, the current state-of-the-art combinatorial algorithm as discussed extensively above. 3) The local search algorithm of Lee et al. , which is the only prior polynomial-time local search algorithm with a theoretical guarantee: ratio \(1/4-\) in \((k^{5}(k)n/)\) queries. As our emphasis is on theoretical guarantees above \(1/\), we set \(=0.01\) for our algorithm, which yields ratio at least \(0.375\) in this evaluation. For Lee et al. , we set \(=0.1\), which is the standard value of the accuracy parameter in the literature - running their algorithm with \(=0.01\) produced identical results.

**Applications and datasets.** For instances of SM upon which to evaluate, we chose video summarization and maximum cut (MC). For video summarization, our objective is to select a subset of frames from a video to create a summary. As in Banihashem et al. , we use a Determinantal Point Process objective function to select a diverse set of elements . Maximum cut is a classical example of a non-monotone, submodular objective function. We run experiments on unweighted Erdos-Renyi (ER), Barabasi-Albert (BA) and Watts-Strogatz (WS) graphs which have been used to model many real-world networks. The formal definition of problems, details of datasets, and hyperparameters of graph generation can be found in the Appendix F. In video summarization, there are \(n=100\) frames. On all the instances of maximum cut, the number of vertices \(n=10000\). The mean of 20 independent runs is plotted, and the shaded region represents one standard deviation about the mean.

**Results.** As shown in Figure 3 in this section, and Figure 5 and 6 in Appendix F, on both applications, FastLS +GuidedRG produces solutions of higher objective value than StandardGreedy, and also higher than RandomGreedy. The objective values of FastLS +GuidedRG often matches with Lee et al.  which performs the best; this agrees with the intuition that, empirically, local search is nearly optimal. In terms of queries, our algorithm uses roughly twice the number of queries

Figure 3: The objective value (higher is better) and the number of queries (log scale, lower is better) are normalized by those of StandardGreedy. Our algorithm (blue star) outperforms every baseline on at least one of these two metrics.

as StandardGreedy, but we improve on Lee et al.  typically by at least a factor of \(10\) and often by more than a factor of \(100\).

## 5 Discussion and Limitations

Prior to this work, the state-of-the-art combinatorial ratios were \(1/e 0.367\) and \(0.283\) for size constrained and matroid constrained SM, respectively, both achieved by the RandomGreedy algorithm. In this work, we show how to guide RandomGreedy with a fast local search algorithm to achieve ratios \(0.385\) and \(0.305\), respectively, in \((kn/)\) queries. The resulting algorithm is practical and empirically outperforms both RandomGreedy and standard greedy in objective value on several applications of SM. However, if \(k\) is on the order of \(n\), the query complexity is quadratic in \(n\), which is too slow for modern data sizes. Therefore, an interesting question for future work is whether further improvements in the query complexity to achieve these ratios (or better ones) could be made.

In addition, we achieve the same approximation ratios and asymptotic query complexity with deterministic algorithms, achieved by guiding a different algorithm; moreover, we speed up the deterministic algorithm to \(_{}(n k)\) by obtaining the guidance set in another way. This result is a partial answer to the limitation in the previous paragraph, as we achieve a ratio beyond \(1/e\) in nearly linear query complexity. However, for all of our deterministic algorithms, there is an exponential dependence on \(1/\), which makes these algorithms impractical and mostly of theoretical interest.