# LORA-MOO: Learning Ordinal Relations and Angles for Expensive Many-Objective Optimization

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Many-objective optimization (MOO) simultaneously optimizes many conflicting objectives to identify the Pareto front - a set of diverse solutions that represent different optimal balances between conflicting objectives. For expensive MOO problems, due to their costly function evaluations, computationally cheap surrogates have been widely used in MOO to save evaluation budget. However, as the number of objectives increases, the cost of learning and surrogation, as well as the difficulty of maintaining solution diversity, increases rapidly. In this paper, we propose LORA-MOO, a surrogate-assisted MOO algorithm that learns surrogates from spherical coordinates. This includes an ordinal-regression-based surrogate for convergence and \(M-1\) regression-based surrogates for diversity. \(M\) is the number of objectives. Such a surrogate modeling method makes it possible to use a single ordinal surrogate to do the surrogate-assisted search, and the remaining surrogates are used to select solution for expensive evaluations, which enhances the optimization efficiency. The ordinal regression surrogate is developed to predict ordinal relation values as radial coordinates, estimating how desirable the candidate solutions are in terms of convergence. The solution diversity is maintained via angles between solutions, which is a parameter-free. Experimental results show that LORA-MOO significantly outperforms other surrogate-assisted MOO methods on most MOO benchmark problems and real-world applications.

## 1 Introduction

Many-objective optimization problems (MOOPs) are widely exist in many real-world applications, such as production scheduling , traffic signal control , and water resource engineering . These MOOPs have conflicting objectives to optimize, and thus all objectives cannot reach their optimum simultaneously. As a result the optimum of MOOPs is the _Pareto front (PF)_: A set of non-dominated solutions that represent different optimal balance between conflicting objectives. Multi-/many-objective optimization (MOO) 1 aims to find non-dominated solutions that are close to the PF and also well distributed along the PF, indicating that MOO should consider both convergence and diversity.

Various evolutionary optimization algorithms have been proposed to solve MOOPs . These optimization algorithms usually require plenty of solution samplings and evaluations to find converged and diverse non-dominated solutions. However, in many real-world MOOPs, the evaluation of solution performance could be expensive . In these expensive MOOPs, the evaluation budget only allows a limited number of solutions to be evaluated on the expensive objective functions. To address expensive MOOPs, evolutionary optimization algorithms are combined with computationally cheapsurrogates to enhance sampling efficiency and save evaluations, which are known as surrogate-assisted evolutionary algorithms (SAEAs).

Yet, it is a perennial challenge to use surrogates in a more effective and efficient way for SAEAs, especially when optimization problems have many objectives. For example, conventional SAEAs usually use regression-based surrogates to approximate each objective function separately [5; 34]. For MOOPs, many objectives indicate maintaining many surrogates for surrogate-assisted search and selection, which results in a low efficiency of SAEAs. In addition, it is difficult to maintain solution diversity in high-dimensional objective space. Some SAEAs [24; 43; 5] need to investigate proper parametric strategies to generate reference vectors or divide objective space into subspaces. Recently, a family of classification-based SAEAs [31; 17] attempted to use a single surrogate to learn pairwise dominance relations. However, the training with pairwise relations implies an exponential increase in the size of training dataset. Therefore, a natural question is that whether we can reduce the cost of maintaining many surrogates without increasing the cost of training a single surrogate. Furthermore, whether we can use an non-parametric diversity maintenance strategy to handle the objective space of MOOPs, instead of designing complex reference vectors or points?

In this paper, we propose a different way to implement surrogate-assisted evolutionary optimization for expensive MOOPs, named LORA-MOO, where a single surrogate is developed to learn ordinal relations for convergence purpose, and several angular surrogates are generated from spherical coordinates to maintain diversity. Our major contributions are summarized as follows:

* We develop a novel ordinal-regression-based model to approximate the ordinal landscape of expensive MOOPs. Our ordinal surrogate is able to handle many objectives simultaneously and assist MOO algorithms to complete the model-based search. Artificial ordinal relations are generated via a clustering method to improve the learning quality of ordinal relations for many objectives. Unlike the pairwise relations learned through classification, the ordinal relations would not increase the size of training dataset, hence high efficiency.
* We introduce the idea of spherical coordinates approximation into surrogate-assisted evolutionary optimization and proposed LORA-MOO to solve expensive MOOPs. Different from existing SAEAs which learn approximation models from Cartesian coordinates, we fit several regression-based surrogates to approximate angular coordinates, while our ordinal surrogate can be treated as a radial coordinate. An non-parametric approach is developed to select diverse solutions for expensive evaluations via our angular coordinate surrogates.
* Extensive experiments on benchmark and real-world optimization problems are conducted under a range of scales and numbers of objectives. Empirical results show that our LORA-MOO is effective. It is able to obtain a well-distributed solution set that outperforms the state-of-the-arts.

## 2 Related Work

### Multi-/Many-Objective Surrogate-Assisted Evolutionary Algorithms

**Regression-based SAEAs.** Regression-based SAEAs employ regression-based surrogates such as Kriging [36; 39] to approximate either the objective values of solutions or the objective functions of expensive problems . To maintain solution diversity, ParEGO  employs a Kriging model to iteratively approximate an aggregate objective function which aggregates all objectives into one via a set of pre-defined scale vectors. In MOEA/D-EGO , plenty of scale vectors are generated uniformly to decompose the target MOOP into many single-objective subproblems. K-RVEA  also designs a set of scale vectors as reference vectors to maintain solution diversity. Similarity or density estimation is an alternative option for maintaining diversity. For instance, KTA2  estimates the distribution status of non-dominated solutions by defining a similarity or density indicator.

**Classification-based SAEAs.** In model-based optimization, the optimization is guided by the relation between solutions rather than accurate objective values. Therefore, there is a tendency for recently proposed SAEAs to use classification-based surrogates to learn the relation between solutions directly. CSEA  trains a neural network to justify whether candidate solutions can be dominated by given reference points or not. \(\)-DEA-DP  uses two neural networks to predict the Pareto dominance relation and \(\)-dominance relation between two solutions, respectively. REMO  employs a neural network to fit a ternary classifier, which is able to learn the dominance relation between pairs of solutions. Compared with regression-based SAEAs, although classification-based SAEAs take advantage of learning solution relations directly, their drawbacks are also clear: The prediction of solution relations lacks the information of how solutions are distributed in the objective space, making it difficult for classification-based SAEAs to maintain solution diversity. In , a radial projection selection approach is adapted to select diverse reference points. However, its effect on diversity maintenance is limited. In addition, although classification-based SAEAs maintain only one surrogate, the cost of learning pairwise relations from large datasets is inevitably increased.

**SAEAs based on Other Surrogates.** HSMEA  uses an ensemble of multiple surrogates in the optimization. In addition, a new category of surrogates, namely ordinal regression surrogate  or level-based classification surrogate , is proposed recently to combine regression-based surrogates with classification-based surrogates. However, the shortcoming remains the same as these surrogates lack the information of solution distribution, especially when the number of objectives is large.

### Multi-Objective Bayesian Optimization

**MOBO.** Bayesian Optimization (BO)  is also a typical model-based optimization method for expensive optimization, while multi-objective BO (MOBO) methods are designed for expensive MOOPs . Some MOBO generalizes the acquisition functions such as upper confidence bound (UCB) , expected improvement (EI) , Thompson sampling , to solve expensive MOOPs. In addition, entropy search methods have also been employed in MOBO . To maintain solution diversity, the EI of a multi-objective performance indicator, Hypervolume (HV) , was used as the acquisition function in recent MOBO . Based on the Hypervolume improvement (HVI), PSL  proposes a learning method to approximate the whole Pareto set for MOBO, and PDBO  automatically selects the best acquisition function for objective functions in each iteration. However, the time complexity of computing HV increases exponentially with the number of objectives, which may limit the application of MOBO methods on optimization problems with many objectives.

**Connection to SAEAs.** Both SAEAs and MOBO are model-based optimization methods. A SAEA is also a MOBO if it uses probability models as surrogates, and a MOBO is also a SAEA if it searches candidate solutions with evolutionary search algorithms. Therefore, some model-based optimization methods belong to both SAEAs and MOBO .

## 3 LORA-MOO: Optimization via Learning Ordinal Relations and Angles

This section first introduces the LORA-MOO framework, followed by detailed algorithm descriptions.

### LORA-MOO Framework

The pseudocode of LORA-MOO is depicted in Alg. 1, it consists of four phases:

1. Initialization: An initial dataset of size \(11D\) - 1 (As suggested in the literature ) are sampled from the decision space using the Latin hypercube sampling (LHS)  (line 1), where \(D\) is the dimensionality of decision variables. The sampled solutions are evaluated on objective functions \(f\) and then saved in an archive \(S_{A}\) (line 2).
2. Surrogate modeling: For all solutions \( S_{A}\), quantify their ordinal values (line 4) and calculate their angular coordinates (line 9). The set of ordinal values \(S_{o}\) is used to train the ordinal surrogate \(h_{o}\) (line 5). The angular coordinates are used to fit \(M-1\) angular surrogates \(h_{ai}\) separately (line 10).
3. Sampling (Search and Selection): Run an optimizer on surrogate \(h_{o}\) to generate a population of candidate solutions \(P\) (line 6). Select optimal candidate solutions \(_{1}^{*}\), \(_{2}^{*}\) from \(P\) based on surrogates \(h_{o}\), \(h_{ai}\), respectively (lines 7 and 11).
4. Update: Evaluate new optimal candidate solutions \(_{1}^{*}\), \(_{2}^{*}\) on expensive objective functions \(f\), update archive \(S_{A}\) and the number of used function evaluations \(FE\) (lines 8 and 12). The algorithm will go to phase 2 until the evaluation budget \(FE_{max}\) has run out.

### Surrogate Modeling

The ordinal surrogate \(h_{o}\) is mainly trained on dominance-based ordinal relations, additional clustering-based artificial ordinal relations will be introduced for training if the number of objectives \(M\) is large. In addition, for an \(M\)-objective problem, \(M\)-1 angular surrogates \(h_{ai}\) are trained on angular coordinates. These surrogates are used in the selection procedure for solution diversity but are idle in the search procedure.

#### 3.2.1 Learning dominance-based ordinal relations.

In LORA-MOO, the concept of ordinal regression  is adapted to learn dominance-based ordinal relations. Clearly, the dominance-based ordinal relation between a set of reference points \(S_{RP}\) and a given solution \(\) is quantified as a relation value. Such a relation value is a numerical value that used for training the ordinal-regression surrogate \(h_{o}\). The quantification of relation values consists of two steps: The selection of reference points \(S_{RP}\) and the computation of relation values.

**Selection of Reference Points.** We propose the definition of \(\)-dominance relationship to simplify the selection of reference points.

**Definition 1**.: (\(\)-_Dominance Relationship_)__

_A solution \(^{1}\) is said to \(\)-dominate another solution \(^{2}\) (denoted by \(^{1}_{}^{2}\)) if and only if:_

\[g_{}(^{1}) g_{}(^{2}), \]

_where \( 0\) is the dominance coefficient and \(g_{}\) is a smooth objective function defined as:_

\[f_{in}()=()-z_{i}^{*}}{|z_{i}^{nad}-z_{i}^{*}|}, \]

\[g_{,i}()=f_{in}()+ max(f_{jn}()),j\{1, ,M\}, \]

_where \(f_{in}\) denotes a normalized objective function, \(^{*}=\{z_{1}^{*},,z_{M}^{*}\},^{nad}=\{z_{1}^{nad},,z_{ M}^{nad}\}\) are ideal point and nadir point for the current non-dominated solutions, respectively._

More detailed definitions about the background of MOO are available in Appendix A. All non-\(\)-dominated solutions in \(S_{A}\) are selected as reference points \(S_{RP}\). There are two reasons to introduce the definition of \(\)-dominance:

* The \(\)-dominance can smoothen the original PF by excluding dominance resistant solutions (DRSs) [16; 38]. DRSs are solutions that are best or close to best on one or several objectives but extremely poor on at least one of the remaining objectives. Such a solution is apparently not desirable but may be regarded as one of the best solutions since there may not exist any other solutions dominating it in the solution set.

* Second, \(\)-dominance can eliminate some similar non-dominated solutions from the Pareto set, which can be used to adjust the size of Pareto set. When the number of objectives \(M\) is large, it is possible that a majority of past evaluated samples are non-dominated to each other. To balance the number of reference points and remaining samples, we introduce the dominance coefficient \(\) to sightly reduce the ratio of reference points in \(S_{A}\). This alleviates the situation of extreme imbalance of samples in different ordinal levels (see the division of ordinal levels below).

**Computation of Relation Values.** To quantify ordinal relation values, we first calculate extension coefficients \(ec()\) for each \( S_{A}\). \(ec()\) is defined as the minimal coefficient \(ec 1\) to make a solution \(\) non-\(\)-dominated to all solutions \(^{}\) in the extended reference:

\[ec()=_{ec 1}^{} S_{RP}:(^{ }*ec)_{}. \]

Although extension coefficient \(ec()\) quantifies the distance between a solution \(\) and reference \(S_{RP}\), it has not been used to train the ordinal regression-based surrogate directly. To generate a stable ordinal regression-based surrogate, solutions in \(S_{A}\) are divided into \(N_{o}=max(n_{o},|S_{A}|/|S_{RP}|)\) ordinal levels, where \(n_{o}\) is a pre-defined parameter denoting the minimal number of ordinal levels. The solutions in \(S_{RP}\) are classified into the non-dominated ordinal level, thus the relation value \(v_{1}\) = 1.0 is assigned to them. Remaining solutions in \(S_{A}\) are sorted by their extension coefficients \(ec()\) and then divided into \(N_{o}\)-1 ordinal levels uniformly. The relation value \(v_{i}=1--1}\) will be assigned to the solutions \(\) in the \(i^{th}\) ordinal level. Lastly, relation values serve as radial coordinates and a Kriging model is employed to approximate them.

#### 3.2.2 Artificial clustering-based ordinal relations.

When the number of objectives \(M\) is large, most evaluated solutions in archive \(S_{A}\) could be non-dominated solutions, indicating that these solutions will be divided into the same non-dominated ordinal level and thus treated as reference points \(S_{RP}\). This is harmful to the ordinal surrogate modeling due to the extreme imbalance between the numbers of training samples in different ordinal levels. To reduce the ratio of \(S_{RP}\), we use a clustering method to generate \(n\_clusters\) clusters for \(S_{RP}\), where \(n\_clusters\) is the half of the size of \(S_{RP}\). All solutions \( S_{RP}\) are mapped to the closest cluster centers. The solutions with the shortest projection on each cluster center will be selected as the new \(S_{RP}\), while the remaining solutions will be moved to the next ordinal level. Such artificial ordinal relations greatly reduce the ratio of \(S_{RP}\) in \(S_{A}\). In LORA-MOO, we set a ratio threshold \(rp\_ratio\) for \(S_{RP}\), once the ratio of \(S_{RP}\) is larger than \(rp\_ratio\), artificial ordinal relations will be generated for surrogate modeling. Details are available in Appendix C, Alg. 2 and Fig. 5.

#### 3.2.3 Surrogates for Angular Coordinates.

Given a solution \( S_{A}\) with Cartesian coordinates \((f_{1}(),,f_{M}())\), The angular coordinates of solution \(\) are transformed with the following rules:

\[_{i}=arccos()-z_{i}^{*}}{()-z_{i}^{ *})^{2}++(f_{M}()-z_{M}^{*})^{2}}},i=1,,M-1, \]

where \(^{*}\) is the ideal point. The resulting angular coordinates \((_{1},,_{M-1})\) are used to fit \(M-1\) regression-based surrogates separately. In LORA-MOO, we use the Kriging model to approximate angular coordinates. The introduction and usage of Kriging model is given in Appendix B.

### Sampling: Search and Selection

In this subsection, we describe how to use surrogate \(h_{o}\) to search for candidate solutions and how to use surrogates \(h_{o}\) and \(h_{ai}\) to select optimal ones from candidate solutions for expensive evaluations.

#### 3.3.1 Search: Generation of Candidate Solutions.

An advantage of LORA-MOO is that it searches for candidate solutions on ordinal surrogate \(h_{o}\) only, leaving all angular surrogates \(h_{ai}\) idle in this search procedure. This saves a lot of time from predicting with all surrogates. LORA-MOO employs an optimizer (e.g. PSO ) to generate a population of candidate solutions \(P\) (Detailed pseudo-code is available in Appendix C, Alg. 3). The initial population for optimization search consists of two parts. The first half initial solutions are generated randomly from the decision space, while the remaining initial solutions are mutants of current reference points \(S_{RP}\). To ensure the diversity of initial candidate solutions, a KNN clustering method is applied to divide \(S_{RP}\) into several different clusters, from each cluster, an equal number of mutants are generated as initial candidate solutions. The global optimal population \(P\) produced by PSO is the candidate solutions for further environmental selection.

#### 3.3.2 Selection Criteria.

To take both convergence and diversity into consideration, in each iteration, LORA-MOO selects two optimal candidate solutions \(_{1}^{*},_{2}^{*}\) from \(P\) for objective function evaluations. \(_{1}^{*},_{2}^{*}\) are sampled on the basis of convergence and diversity, respectively.

**Convergence Criterion** for environmental selection is the expected improvement (EI)  of ordinal values, which is similar to many MOBO methods . Since the output of our ordinal surrogate \(h_{o}()\) is an 1-D numerical value, the solution with maximal 1-D EI in \(P\) is selected as \(_{1}^{*}\).

**Diversity Criterion** to sample \(_{2}^{*}\) from \(P\) is defined as angles \(d_{ang}\) between candidate solutions and reference points \(S_{RP}\). Firstly, the minimal degree between each candidate solution and \(S_{RP}\) is measured. Among these minimal degrees \(md_{ang}\), the solution with max(\(md_{ang}\)) is selected as \(_{2}^{*}\) (Detailed pseudo-code is available in Appendix C, Alg. 4).

## 4 Experiments

To evaluate the optimization performance of LORA-MOO on expensive MOOPs, we conduct experiments to compare LORA-MOO with other SAEAs on different MOOPs, including a series of scalable multi-/many-objective benchmark optimization problems DTLZ , WFG , and a real-world network architecture search (NAS) problem.

### Experimental Setups

**Optimization Problem Setup.** To ensure a fair comparison, the following optimization problem setup is the same as the setup that has been widely used in the literature . In our experiments, initial datasets of size \(FE_{init}\) = 11 \(D\) - 1 are used to initialize surrogates, while the maximum number of allowed evaluations \(FE_{max}\) is 300. The statistical results are obtained from 30 independent runs. For each run, different comparison algorithms share the same initial dataset.

**Comparison Algorithms.** We compare LORA-MOO with 6 state-of-the-art SAEAs, some of them also known as MOBO methods. These comparison algorithms can be classified into three categories:

* Regression-based MOO methods: ParEGO , K-RVEA , and KTA2 . ParEGO is a classic regression-based SAEA and also a MOBO, which serves as a baseline. K-RVEA is a typical SAEA which uses reference vector to guide the diversity maintenance. KTA2 is a newly proposed algorithm to use an independent archive to keep solution diversity.
* Classification-based MOO methods: CSEA , REMO . CSEA is a classic classification-based SAEA which serves as a baseline. REMO is a newly proposed SAEA which represents the state-of-the-art performance of classification-based SAEAs.
* Ordinal-regression-based MOO method: OREA  is a new category of SAEA that is different from common regression-based and classification-based SAEAs. We compare with it since it is directly related to our radial surrogate.

Note that some classic SAEAs and MOBO methods such as MOEA/D-EGO  and CPS-MOEA  are not compared in our experiments as they failed to outperform other comparison algorithms on any DTLZ problem . Some HV-based MOBO methods are not compared as they are failed to solve many objectives.

**Parameter Setup.** For the surrogate modeling, the Kriging models used in all comparison algorithms are implemented using DACE , just as  suggested. For regression-based Kriging surrogates, the range of hyper-parameter \([10^{-5},100]\). And for the neural networks in CSEA and REMO, the parameters are the same as suggested in the literature. In the sampling strategy, the mutation operator used to initialize candidate solutions is polynomial mutation , the mutation probability \(p_{m}=1/d\)and mutation index \(_{m}=20\), as recommended in [34; 17]. The size of offspring population is 100. The settings of the PSO optimizer are the range of hyper-parameter in the ordinal-regression-based surrogate are the same as suggested in .

For the specific parameters exist in LORA-MOO, such as the dominance coefficient \(\) and the threshold ratio of reference points to introduce clustering-based ordinal relations \(rp\_ratio\). As there is no relevant study in the literature for their setups, we conducted ablation studies to investigate the effect of these parameters on the performance of LORA-MOO. The results are summarized in Section 4.2 and reported in Appendix F. The source code of LORA-MOO 2 will be available online.

**Performance Indicator.** To have a comprehensive estimation of optimization performance, we use three different performance indicators in our experiments: The inverted generational distance (IGD) , the inverted generational distance plus (IGD+) , and the Hypervolume (HV) . IGD and IGD+ use a set of truth Pareto front to measure the quality of a set of non-dominated solutions in terms of convergence and diversity. A smaller IGD or IGD+ value indicates better MOO performance. HV use a reference point to calculate the area covered by a set of non-dominated solutions, a large HV value is preferable to MOO. See Appendix D for details and setups about performance indicators.

### Ablation Studies

We conduct ablation studies on DTLZ and WFG benchmark problems with \(D\) = 10 variables and \(M\)={3, 6, 10} objectives. LHS  is used to sample initial dataset. The effects of four parameters are investigated: They are the minimal number of ordinal levels \(n_{o}\), the dominance coefficient \(\), the ratio threshold of reference points \(rp\_ratio\), and the clustering number for reproduction \(n_{c}\). Three representative results obtained on the WFG5 problem with 3 and 10 objectives are depicted in Fig. 1. Complete results and statistical analysis of ablation studies are reported in Appendix F.

As shown in Fig. 1 (left), when \(M\) = 10, a large \(n_{o}\) results in poor optimization performance. This is because the ratio of non-dominated solutions in the archive tends to be large when \(M\) is large, hence, setting a large \(n_{o}\) will lead to a lack of training samples in each dominated ordinal levels, which is detrimental to the performance of surrogate modeling. As such, \(n_{o}\) in LORA-MOO is set to 4.

The result in Fig. 1 (middle) shows that using \(\)-dominance to sightly modify the original dominance relations is beneficial to the effectiveness of LORA-MOO. When \(=0\), no \(\)-dominance would be used and the corresponding LORA-MOO variant has the worst performance among all the variants. In addition, setting a large \(\) could cause severe damage to the original dominance relations. Therefore, we set \(\) to 0.2.

The effect of introducing artificial ordinal relations via clustering is demonstrated in Fig. 1 (right). When the ratio threshold of reference points \(rp\_ratio\) is 1 and \(M\) = 10, no artificial ordinal relations are introduced to further divide ordinal levels for plenty of non-dominated solutions in the archive. Consequently, the imbalance of sample numbers in different ordinal levels leads to poor optimization performance. However, dominance relations are preferable to artificial ordinal relations when \(M\) = 3 and the size of ordinal levels are well balanced. Hence, we set \(rp\_ratio\) = 0.5.

### Optimization on Benchmark Problems

The optimization performance of LORA-MOO is evaluated on DTLZ and WFG benchmark problems with \(D\) = 10 variables and \(M\)={3, 4, 6, 8, 10} objectives. The IGD values obtained on DTLZ

Figure 1: IGD curves averaged over 15 runs on the WFG5 problem instances for LORA-MOO with different parameter setups (shaded area is \(\) std of the mean).

[MISSING_PAGE_FAIL:8]

### Real-World Network Architecture Search Problem

Further comparison is conducted on a real-world network architecture search (NAS) problem, the best three algorithms listed in Table 1 are compared: LORA-MOO, KTA2, and KRVEA. The NAS problem tested is the NASbench201 implemented in EvoXBench , it has 6 variables and 5 objectives. Details of this NAS problem is provided in Appendix E. Considering NASbench201 is a real-world application and we do not know its exact PF, we use HV to evaluate optimization performance since HV can be calculated without the exact PF. In practice, \(log(HV_{})\) is employed to amplify the visual difference of the obtained HV values:

\[log(HV_{})=log(HV_{}-HV)\]

where \(HV_{}\) is the maximal HV value on this problem that is provided in EvoXBench.

Fig. 3 plots the result. As can be seen in the figure, LORA-MOO outperforms KTA2 and KRVEA on this NAS problem. Although KTA2 and KRVEA have quicker convergence rate than LORA-MOO at the beginning of the optimization, both of them slow down their convergence speed as the number of evaluations increases. Particularly, KTA2 is trapped on local optima and thus fails to reach better results. In comparison, LORA-MOO reaches better NAS results when the evaluation number is larger than 250.

### Runtime Comparison

We compare the runtime on benchmark problems for all the comparison algorithms to investigate the relation between their optimization efficiency and the number of objectives \(M\).

Fig. 4 illustrates how the runtime of each comparison algorithm varies as the \(M\) increases. It can be observed that the runtime of KTA2 increases exactly in the same rate as \(M\) increases. In comparison, the runtime of LORA-MOO increases slightly when \(M\) increases. This demonstrates that using angular surrogates only at the end of environmental selection process is beneficial to the optimization efficiency of LORA-MOO. In addition, the runtimes of ParEGO, CSEA, REMO, and OREA do not increase significantly with \(M\) since they do not maintain specific surrogates to manage the diversity of non-dominated solutions. Consequently, their overall performance reported in Table 1 is not desirable. Overall, LORA-MOO finds a good trade-off between optimization efficiency and optimization results.

## 5 Conclusion

In this paper, we propose an efficient MOO method, LORA-MOO, to solve expensive MOOPs. Different from existing surrogate modeling approaches, our LORA-MOO learns surrogate models from ordinal relations and spherical coordinates. Only one ordinal surrogate is used in the model-based search, which hugely improve the efficiency of optimization. Our empirical studies have demonstrated that our LORA-MOO significantly outperforms other state-of-the-art efficient MOO methods, including SAEAs and MOBO methods.

Figure 4: Comparison of runtime averaged over 30 runs on benchmark problems \(D\) = 10 variables and \(M\) = 3, 4, 6, 8, and 10 objectives for the comparison algorithms. For each algorithm, its runtimes are normalized by the runtime it costed on 3-objective problems.

Figure 3: \(Log(HV_{})\) curves averaged over 30 runs on the NAS problem for the comparison algorithms.