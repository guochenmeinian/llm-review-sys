# Understanding Transformer Reasoning Capabilities

via Graph Algorithms

Clayton Sanford\({}^{1,2}\)1, Bahare Fatemi\({}^{1}\), Ethan Hall\({}^{3}\), Anton Tsitsulin\({}^{1}\),

**Mehran Kazemi\({}^{4}\), Jonathan Halcrow\({}^{1}\), Bryan Perozzi\({}^{1}\), and Vahab Mirrokni\({}^{1}\)\({}^{1}\)Google Research, \({}^{2}\)Columbia University,\({}^{3}\)Google, \({}^{4}\)Google DeepMind**

###### Abstract

Which transformer scaling regimes are able to perfectly solve different classes of algorithmic problems? While tremendous empirical advances have been attained by transformer-based neural networks, a theoretical understanding of their algorithmic reasoning capabilities in realistic parameter regimes is lacking. We investigate this question in terms of the network's depth, width, and number of extra tokens for algorithm execution. Our novel representational hierarchy separates 9 algorithmic reasoning problems into classes solvable by transformers in different realistic parameter scaling regimes. We prove that logarithmic depth is necessary and sufficient for tasks like graph connectivity, while single-layer transformers with small embedding dimensions can solve contextual retrieval tasks. We also support our theoretical analysis with ample empirical evidence using the GraphQA benchmark. These results show that transformers excel at many graph reasoning tasks, even outperforming specialized graph neural networks.

## 1 Introduction

The transformer neural network architecture, which was initially introduced for neural machine translation , quickly became the standard neural network architecture across many fields, powering recent breakthroughs in language modeling , computer vision , and natural sciences . Across fields, transformers have superseded other architectures, surpassing them in downstream performance while maintaining reasonable computational footprint.

How can we analyze reasoning capabilities of neural networks? One approach is to study algorithms executable with their internal representations. Neural algorithmic reasoning  is a field of research dedicated to exploring such capabilities. Algorithmic execution is desirable because models use it to generalize out-of-distribution  and scale to larger problem sizes .

In this work, we focus on classes of transformers solving algorithmic reasoning problems on graphs. Why graph problems in particular? Recent research by Besta et al.  suggests that graphs are an ideal abstraction of complex reasoning with dependencies, including chain-of-thought  and its generalizations . Furthermore, we investigate graph reasoning in order to evaluate transformer capabilities compared to specialized models that explicitly capture the structure of data. Graph neural networks (GNNs)  offer strong baselines for algorithmic reasoning  and comprehensive theoretical frameworks for their capabilities and limitations . The complexity of graph reasoning tasks varies greatly; some are easily solved by non-graph architectures and others require sophistication beyond standard GNNs . This makes graph tasks a compelling testbed for both theoretical and empirical evaluations.

While transformer-based models are commonly optimized for downstream performance , theoretical investigations of transformer capabilities in realistic parameter regimes have been limited.

We analyze the capabilities of standard transformer models to solve graph reasoning tasks by employing a graph tokenization scheme similar to ; see Figure 1 for a graph encoding example. We generalize the insights of --which established that graph connectivity can be computed in a more depth-efficient manner with transformers than GNNs--to broader families of graph reasoning tasks. We also study the representational impacts of _blank tokens_, which can be thought of as a theoretically-tractable version of either chain-of-thought prompting , scratch space , or pause/filler tokens .

We conduct an extensive study of graph reasoning problems with transformers from both theoretical and empirical perspectives. We summarize our principal contributions as follows:

1. We introduce a novel _representational hierarchy_ of graph reasoning tasks that formalizes reasoning capabilities of transformers in several realistic parameter scaling regimes. This includes two graph reasoning task classes--which we refer to as the _parallelizable_ and _search tasks_ and include well-known algorithmic tasks like _connectivity_ and _shortest path_ respectively.
2. We prove that logarithmic-depth transformers are necessary and sufficient to solve parallelizable tasks in a highly parameter-efficient manner; similar constructions for search tasks employ much larger networks. We distinguish both of these classes from an easier family of problems--_retrieval tasks_, such as _node count_ and _edge existence_--by showing that retrieval tasks can be efficiently computed by single-layer transformers, while parallelizable and search tasks cannot.
3. We empirically validate our representational contrast by showing that transformers outperform GNNs on tasks that require the analysis of long-range dependencies, including parallelizable tasks like connectivity. Our experiments suggest that GNNs perform better on simpler tasks that require only local analysis of neighboring nodes in low sample-complexity regimes, benefiting from their well-aligned inductive bias.

## 2 Related work

Fundamental capabilities of transformers.Early representational research  established the universality of transformers by simulating Turing machines step-by-step, albeit in an unrealistic polynomial-depth scaling regime. These universality results were extended to bounded-depth transformers with chain-of-thought tokens , but with a persistent gap between positive and negative results. A more fine-grained theoretical approach established the limitations of bounded-size transformers by relating them to threshold circuits, implying that L-complete tasks like graph connectivity are unsolvable by constant-depth transformers . However, these circuit complexity reductions are not bidirectional and their positive results pertaining to classes of regular languages  reveal little about when tasks like connectivity _can_ be expressed.

Figure 1: The graph encoding scheme employed in our theoretical and empirical analysis that presents a graph reasoning task (e.g. connectivity) as a tokenized input to a standard transformer model.

The closest analytical framework to ours characterizes transformers as distributed computing protocols by quantifying the informational bandwidth of their self-attention units. This line of work sharply separates transformers from other architectures and provides width and depth separations [70; 71]. The ability of transformers to simulate finite-state automata in logarithmic depth provides a further roadmap for how transformers efficiently leverage parallel computation .

Recent work  similarly focuses on understanding the capabilities of transformers to solve graph algorithms, but they focus instead on _looped_ transformers, where a constant-size transformer model is iterated up to a polynomial number of times in the size of the input graph. While their constructions for tasks like graph connectivity are more parameter-efficient than our own, this comes at the cost of a very high depth, which presents both run-time and learnability concerns. Our depth-efficient constructions emerge by simulating parallel graph algorithms, rather than well-known serial algorithms, such as Dijkstra's.

Empirical analysis of transformer reasoning capabilities.Multiple empirical investigations explore the algorithmic capabilities of transformer-based models [91; 47; 46]. Graph reasoning problems have been used to evaluate capabilities of transformer-based LLMs [24; 80; 87; 74; 33] including works with graph-specific GNN adapters [14; 63]. In the empirical part of our study, we use the GraphQA dataset --which was evaluated initially on LLM prompting appraoches and later on GNN-augmented prompts --to validate our complexity hierarchy and compare transformers with GNNs and prompt-based LLMs on a selection of graph reasoning tasks.

Transformers and graph neural networks.GNNs provide a useful benchmark for model expressivity on graph inputs. For instance, the inability of GNNs to efficiently solve "global structure" tasks like subgraph connectivity made evident by a connection to the Congest distributed computing model . A further connection  to the Weisfeiler-Lehman (WL) isomorphism heuristic  captures the inability of feature-less GNNs to distinguish certain graph instances . The feature-less assumption is burdensome and representationally costly; GNNs with randomly initialized node features are known to be universal . See Appendix D for a further discussion of the representational limitations of GNNs.

Graph transformers [22; 68; 58] integrate the transformer architecture with graph-structured data. While GNNs can simulate the WL test , transformers can simulate GNNs and exceed their WL limitations ; they are strictly more expressive than 2-WL . Despite our focus on standard transformers, our empirical results in Section 4 include comparisons to a wide range of GNNs.

## 3 Hardness taxonomy of transformer graph reasoning tasks

We provide our core result: a rigorous quantification of the hardness of graph reasoning tasks for transformer-based models. While graph reasoning tasks, like other algorithmic problems, can be categorized into well-known computational and circuit complexity classes (e.g. \(^{0}\), \(\), \(\), \(\), \(\)), the relationship between membership in these classes and the hardness of solving a task with a parameter-efficient neural network is not immediately obvious. Our hierarchy bridges the gap between these worst-case computational classes and the representational capabilities of bounded-size transformers of different parameter scaling regimes. These regimes include transformers whose depth \(L\) scales with the input sequence length \(N\); this contrasts with most theoretical results, which study on the constant-depth regime.

Our positive and negative theoretical results employ the transformer model of , which is presented in Appendix A.1 and assumes that the embedding dimension \(m\) grows less rapidly than than the sequence length \(N\) and that the multi-layer perceptrons (MLPs) are arbitrary functions. The result is a model of a transformer as a _bounded-capacity communication protocol_. In this model, arbitrary functions of each individual embedding vector can be computed, but the interactions between these vectors are restricted by the low-rank of the attention matrix. The relevance of this model is motivated by the rapid scaling in the context lengths of modern transformers in recent years and the high ratio of MLP parameter count to the embedding dimension each operates on.

This model also permits the inclusion of blank _pause token_ inputs of , which provide additional computational power to the transformer model by extending the computational "tape" without introducing new information about the input.

These results divide the tasks that are we empirically investigate in Section 4 into three difficulty families based on the hardness of solving the task with parallel computation.

1. **Retrieval tasks**--including node count, edge count, edge existence, and node degree--are tasks that can intuitively be solved by a single lookup step or global aggregation. These are the easiest tasks in our framework, and we show in Section 3.3 that these retrieval tasks can be computed by a single-layer transformer with small embedding dimension. (In contrast, all other examined tasks cannot be solved in that regime.)
2. **Parallelizable tasks**--including connectivity, connected nodes, and cycle check from the experimental results and a host of other graph reasoning tasks, such as bipartiteness, planarity, and minimum spanning forest--are non-trivial tasks that can be solved efficiently in a parallel computation setting. Section 3.1 establishes that these tasks can be solved by bounded-size transformers with logarithmic depth.
3. **Search tasks**--including shortest path and other tasks like diameter and directed reachability--comprise a harder family of tasks that are less easily solved by parallel algorithms. In Section 3.2, we prove that these tasks belong in an equivalence class and exhibit large-model scaling regimes where they can be computed.

The representational hardness of these classes is quantified by several results that determine whether transformers that obey different parameter scaling rules can compute them. We define the following scaling regimes for the depth \(L\), embedding dimension \(m\), and number of "pause" tokens \(N^{}\) of a family of transformers as a function of the size of the input graph, \(N=O(|V|+|E|)\).

* Depth1 (D1): Single-layer multi-headed transformers with small embedding dimension \(m=O( N)\) without any pause tokens.
* LogDepth (LD): Transformers with depth \(L=O( N)\), embedding dimension \(m=O(N^{})\) for any fixed \(>0\), and no pause tokens.
* LogDepthPause (LDP): Transformers with the same depth and width constraints as LogDepth, with at most \(N^{}=(N)\) blank "pause" tokens appended to the input sequence.
* LogDepthWide (LDW): Transformers with depth \(L=O( N)\), embedding dimension \(m=O(N^{1/2+})\), and no pause tokens.

Our positive and negative results that relate scaling regimes and graph reasoning tasks are displayed in Figure 2. We present high-level result summaries in the following sections with proofs in Appendix.

The most technically significant results concern LogDepth models and are provided in Appendix B. These bounds are consequences of Theorem 1, an improved analysis of the relationship between

Figure 2: A summary of the theoretical hierarchy of Section 3 that visualizes which type of graph reasoning tasks can be solved in which transformer scaling regime (Depth1 (D1), LogDepth (LD), LogDepthWide (LDW) and LogDepthPause (LDP)).

transformers and the massively parallel computation (MPC) distributed computing model of 2. This connection between MPC and transformers is a sharp improvement of a similar result by .

**Theorem 1** (Simplified version of Theorem 8).: _For constant \(,>0\), any \(R\)-round MPC protocol with \(N\) machines with \(O(N^{})\) bits of local memory each can be simulated by a transformer of depth \(L=O(R)\) and embedding dimension \(m=O(N^{+})\)._

Results pertaining to Depth1 are stated in detail and proved in Appendix C. In addition, we discuss the triangle counting task (and the more general clique counting task) in Section 3.4, where we show a distinct result for much smaller depth (\(L=O( N)\)) that includes pause tokens.

### Parallelizable tasks and LogDepth transformers

We define the family of _parallelizable tasks_ to consist of graph reasoning tasks that are L-complete and are equivalent to graph connectivity in \(O(1)\)-rounds, as proved by . This family includes (but is not limited to): graph connectivity, minimum spanning forest, cycle detection, \(st\)-connectivity, number of connected components, graph bipartiteness, planarity testing, and one-cycle vs two-cycles testing. While graph connectivity and minimum spanning forest were shown to be computable by logarithmic depth transformers with small polynomial width (LogDepth) by previous work , this poses broader questions: Are all parallelizable graph reasoning tasks computable by a transformer of logarithmic depth and small embedding dimension? And do sub-logarithmic-depth transformers exist that solve any parallelizable tasks?

We first show that all parallelizable tasks can be solved in two logarithmic-depth scaling settings.

**Theorem 2**.: _For any parallelizable task, there exists transformers in \(\) and \(\) that solve the task._

Theorem 2 is stated formally as Theorem 18 and proved in Appendix B.2.1. Both components of the theorem are a consequence of a novel relationship between the MPC model and transformers (Theorem 1) and the analysis of MPC protocols for graph reasoning tasks by . The \(\) result is the direct implication of an \(O(1)\)-round MPC equivalence (Theorem 9) between all parallelizable tasks and an MPC protocol that solves the connectivity task (Theorem 11). The \(\) bound is a consequence of Theorem 15, which shows that all languages in \(^{2}\) (including all languages in L and NL) can be evaluated by an MPC protocol with \(O( N)\) rounds and with local memory \(O(N^{1/2+})\).

We further prove the conditional optimality of logarithmic depth.

**Theorem 3**.: _Conditional on Conjecture 13, any transformer that solves some parallelizable task with width \(mH=O(N^{})\) and pause tokens \(N^{}=(N)\) must have depth \(L=( N)\)._

This result (stated formally as Theorem 19 is a combination of the conditional depth lower bound on graph connectivity by  and the \(O(1)\)-round equivalence between all parallel tasks.

### Search tasks

_Search tasks_ are similarly defined to be those that are NL-complete and equivalent to shortest path in \(O(1)\)-rounds of MPC and include shortest path, strong connectivity, \(st\)-reachability, radius, diameter, and median. Like before, the \(O(1)\)-round MPC equivalence translates to an \(O(1)\)-depth equivalence in transformers. We give a similar positive result for \(\) transformers; whether these tasks can be solved by \(\) transformers is unknown.

**Theorem 4**.: _For any search task, there exists a transformer in \(\) that solves the task._

This theorem, which is restated in Appendix B.2.2 as Theorem 21, is also an immediate consequence of Theorem 15.

While the minimum depth of a transformer with small embedding dimension that solves a search task is not identified, we prove that the minimum depth needed to solve some all search task is approximately equivalent in Theorem 22.

### Retrieval tasks and \(\) transformers

Graph tasks whose algorithms consist of a single look-up or aggregation step can be efficiently solved by single-layer transformers. This result assumes that the graph \(G=(V,E)\) is encoded as some input sequence \(X\) of length \(N=O(|V|+|E|)\) that expresses each edge and vertex a single token. This encoding scheme is detailed in Appendix C.

**Theorem 5**.: _For any retrieval task (including node count, edge count, edge existence, and node degree) there exists a transformer in \(\) that solves the task._

We formalize this statement in Theorem 36 and prove it their in Appendix C.1. These rely on proving the existence of a useful input MLP \(\) that precomputes embeddings with useful structure for all retrieval tasks.

In contrast, we show that a collection of parallelizable and search tasks cannot be efficiently solved by transformers in \(\).

**Theorem 6**.: _Any single-layer transformer that solves the graph connectivity, shortest path, or cycle detection task has width satisfying \(mH=(N)\)._

The proof of the formal counterpart of this statement (Theorem 38) appears in Appendix C.2 and is a consequence of a standard communication complexity argument. A more generalized result than Theorem 6 was proved by , which establishes that all problems outside of \(^{1}\)--which include all \(\)-complete and \(\)-complete languages, and hence, all parallelizable and search tasks--cannot be solved by _constant-depth_ transformers with polynomial width because they cannot be computed by \(^{0}\) (constant-depth threshold circuits). We nonetheless include this theorem to demonstrate a clean lower bound that applies to very simple input graph instances.

### Triangle counting

We finally construct depth-efficient transformers for triangle counting due to the MPC algorithms of . Unlike previous positive results, which applied uniformly across all graphs instances of bounded size, the complexity of the corresponding transformers for triangle counting is a function of the arboricity3 of the input graph. When the arboricity grows sub-polynomially with \(N\)--as is the case for bounded-degree graphs--no pause tokens are necessary. Unlike the parallelizable and search classes of problems, strictly sub-logarithmic depth is attainable with pause tokens, even for worst-case graphs.

**Theorem 7**.: _There exists a transformer that computes the number of triangles in any input graph of arboricity \(\) and has embedding dimension \(m=O(N^{})\), depth \(L=O( N)\), and pause tokens_

\[N^{}=O( N^{1-})&)$}\\ 0&\]

This result is a special case of Theorem 23, a more general result about clique counting that appears in Appendix B.2.3.

Theoretical conclusions.These results provide a tight characterization of the the reasoning capabilities of transformers whose depth, width, and input padding conform to different scaling regimes. They strengthen the established connection between transformers and massively parallel computation (MPC)  and generalize the resulting representational bounds to broader categories of graph tasks. We conclude that the logarithmic-depth regime is apt for for considering tasks in \(\) and \(\), which had previous illuminated the limitations of transformers with constant depth and a limited number of chain-of-thought tokens . While expressivity does not imply learnability, these theoretical benchmarks sharply characterize the fundamental limitations of transformers and coincide with experimental results conveyed in the subsequent section.

Our theoretical model of a transformer has certain limitations, namely the universality of the multi-layer perceptron units. When maximally exploited (e.g. by solving NP-hard problems within each MLP), this assumption exaggerates the computational capabilities of transformers. However, thelocal computational complexity of the MPC algorithms employed in this paper tend to be strongly sublinear in the size of the graph input (see, e.g. the connectivity algorithms of Andoni et al. ), which implies the existence of compact ReLU circuits for each of the model's MLPs. Furthermore, the ratio of model parameters that belong to MLPs in state-of-the-art language modelsis known to be high, which suggests that it is reasonable to assume that MLP units in our theoretical model are algorithmically rich. We would be interested in pursuing further theoretical research that combine the computational model  and the communication model of  to assess the capabilities of transformers whose MLPs are represented as bounded-size boolean circuits.

## 4 Empirical graph reasoning capabilities

We further illuminate the reasoning capabilities of transformers by conducting an empirical investigation of the abilities of a variety of neural architecture and training settings to learn graph algorithmic tasks. We use the GraphQA benchmark tasks  for our experiments. We evaluate standard autoregressive transformers--both small models (at most 60M parameters) trained from scratch and fine-tuned (FT) T5-11B model (with 11B parameters) . For the fine-tuned models, we explore task-specific fine-tuning--and contrast those results with graph neural networks (GNNs) and prompting-based methods on pre-trained LLMs.

These experimental results validate key tenets of our theoretical results and demonstrate the utility of transformers' algorithmic reasoning capabilities. Our principal empirical conclusions are as follows:

1. **Transformers excel at global reasoning tasks.** Transformers outperform GNNs on tasks that require efficiently aggregating information about distant nodes in a graph, such as connectivity and shortest path.
2. **GNNs uncover local graph structure with few samples.** While transformers are capable of efficiently expressing all graph learning tasks under investigating, the structural limitations of GNNs provide them with favorable inductive biases for intrinsically local tasks, such as cycle check and node degree, and permit them to outperform transformers in a low-sample regime.
3. **Trained transformers outperform LLM prompting.** Transformers trained to explicitly solve graph reasoning tasks consistently attain greater accuracy across tasks than a variety of prompting strategies applied to more recent larger LMs.

A comprehensive evaluation of each GraphQA task on every training setting appears in Appendix E, in addition details about transformer training, the GraphQA benchmark, and alternative GNN and prompting approaches.

### Transformers excel at global reasoning tasks

As indicated in Section 3, graph reasoning algorithms can be categorized based on the extent to which they entail aggregating "local" information about nodes and their immediate neighbors or modeling "global" connections between nodes separated by a long distances. This section investigates the following question about transformers and long-distance reasoning:

_When do transformers outperform GNNs on tasks that require global reasoning?_

We consider two tasks that require reasoning across long distances in a graph instance: evaluating **connectivity** and computing the **shortest path** between a pair of nodes. Neither of these tasks can be solved by only investigating the neighbors of the source and sink node, which therefore implies that some analysis of global graph structure is necessary.

Figure 2(a) displays the accuracy of a variety of trained transformers and GNNs on the connectivity task contrasting the performance of all such models when trained on 1,000 and 100,000 graph connectivity instances. In the most restricted sample complexity regime, trained GNNs are consistently more accurate than the small transformer; however, increasing the number of training samples yields a far more substantial improvement in the performance of the small transformer, which outperforms all GNNs trained on 100,000 samples. Notably, the pre-trained transformer, fine-tuned on just 1000 training instances, nearly solves the connectivity task. This suggests significant enhancements due to the larger model size and the data-rich fine-tuning phase. Figure 2(b) plots the training and test error of ten small transformers trained on connectivity datasets of increasing size and reveals a sharp and

continual improvement in accuracy. The fine-tuned T5 transformer has similar accuracy to the most sample-rich small transformer and exceeds that of all GNNs.

On the other hand, Table 1 demonstrates that the MPNN GNN models outperform small transformers when trained to compute the shortest path, even on larger training datasets. However, the fine-tuned T5 model has far higher accuracy than all alternatives, even when trained only 1000 samples.

Theoretical interpretation:Because connectivity is the prototypical example of a task in the parallelizable class and can thus be efficiently implemented by LogDepth transformers with very small width (Theorem 2), the fact that small transformers succeed in solving nearly all connectivity instances is illuminating but not surprising. In contrast, message-passing GNNs are unable to solve connectivity in a similarly depth- and width-efficient manner due to fundamental capacity limitations.4

Shortest path belongs to the search class of graph reasoning tasks and is NL-complete. Theorem 4 implies that shortest path is computable by LogDepthWide transformers, which are likely to require very large embedding dimension to be learnable by finite samples. This task can only be computed in a depth- and parameter-efficient manner if a variety of search tasks, including all-pairs shortest-path and diameter, are as well (Theorem 22). The fact that only the pre-trained model has nearly optimal performance on shortest path reinforces the theoretical intuition that solving shortest path requires a very large number of model parameters.

### GNNs uncover local graph structure with few samples

While small transformers outperform GNNs on graph reasoning algorithms that entail analysis of long-range graph structure, their empirical successes are not uniform. Here, we investigate the following question:

_When do GNNs outperform transformers on graph reasoning tasks?_

Figure 2(b) and Table 1 demonstrate that GNNs outperform small transformers in the low-sample regime, despite the sufficient expressivity of transformers. This gap in performance, which is reinforced for the **node degree** and **cycle check** tasks in Table 2, suggests that GNNs have a beneficial

    &  \\ 
**Model** & **1K** & **100K** \\  GCN  & 50.2 & 55.0 \\ MPNN  & 66.8 & 72.6 \\ GIN  & 54.0 & 58.6 \\ 
60M transformer & 57.4 & **97.1** \\
11B transformer (FT) & 92.8 & — \\   

Table 1: Transformers vs GNNs on shortest path: Fine-tuned large transformers outperform other transformers and GNNs, even the alternatives are trained on much larger training sets.

Figure 3: Accuracy of a variety of trained transformers and GNNs on the connectivity task.

inductive bias_ for learning graph reasoning tasks that can be solved by attending exclusively to local heuristics.

Just as the bounded kernel size of convolutional neural networks (CNNs) enables the sample-efficient learning of relevant textures and gradients for image analysis, message-passing GNNs are unable to send messages instantaneously across multiple edges, which simplifies a search of the space of "one-hop" graph algorithms and represents a positive inductive bias. In contrast, the ability of transformers to send information between any pair of input tokens--and the alternative inductive biases suggested by the input positional encoding--likely induces a steeper sample complexity to learn node degree.

Theoretical interpretation:While model expressivity is necessary for learnability, it is not sufficient. The locality constraints of message-passing GNNs likely provides a favorable inductive bias for learning tasks like node degree with an exclusively on local structure that makes learning these tasks possible in a sample-efficient manner. While cycle check is more representationally difficult for GNNs than transformers in the worst case (see Appendix A.2), the random graphs sampled for the GraphQA benchmark have very small cycles (Figure 7) and do not resemble the large-diameter worst-case instance.

### Trained transformers outperform LLM prompting

Large language models (LLMs) are regularly evaluated by their reasoning abilities, and it remains an open research question to determine what kinds of training data best teaches models to solve logical problems. We investigate the extent to which LLMs can already perform graph reasoning tasks without being trained explicitly to do so.

_Do transformers trained explicitly to solve graph reasoning tasks outperform prompt-tuning approaches on much larger LLMs?_

In Table 3, we contrast the capabilities of trained transformer models with several prompt-based approaches to querying LLMs. Task-specific transformers--including the fine-tuned 11B transformers--consistently dominated the prompt-based approaches, despite the vast difference in parameter count and the almost certain presence of graph reasoning in the LLM's corpus.

Theoretical interpretation:While the representational capabilities of LLMs to solve reasoning tasks is much greater than that of small transformers, this performance gap suggests that their effective reasoning capacity is much weaker and that it may be improved by a richer training corpus that includes synthetic tasks.

Finally, we observe that the near-perfect performance of trained transformers on the node count, edge count, and edge existence is consistent with the representational easy of those tasks, as suggested by the existence of efficient Depth1 transformer implementations.

    &  &  \\ 
**Model** & **1K** & **100K** & **1K** & **100K** \\  GCN  & 9.8 & 9.4 & 83.2 & 83.2 \\ MPNN  & 99.4 & **99.8** & 99.0 & **100.0** \\ GIN  & 36.2 & 37.8 & 98.8 & 83.2 \\ 
60M transformer & 31.6 & 91.7 & 97.1 & 98.0 \\
11B transformer (FT) & 68.8 & — & 98.0 & — \\   

Table 2: Transformers vs GNNs on cycle check and node degree: GNNs are favorably biased for local structure.

    &  &  &  &  \\   &  &  &  &  &  &  &  \\    } &  & 21.7 & 12.4 & 44.5 & 14.0 & 84.9 & 76.0 & 11.5 & 1.5 & 1.5 \\  &  & 14.6 & 9.4 & 33.5 & 10.4 & 73.5 & 32.3 & 33.6 & 12.7 \\  &  & 25.3 & 12.0 & 36.8 & 17.4 & 79.4 & 37.4 & 22.7 & 3.0 \\  &  & 27.6 & 12.8 & 42.8 & 29.2 & 45.2 & 88.0 & 38.6 & 8.1 \\  &  & 26.9 & 12.5 & 37.3 & 28.0 & 45.2 & 52.1 & 40.4 & 8.1 \\    } &  & 100.0 & 100.0 & 67.6 & 31.5 & 92.9 & 92.7 & 57.4 & 31.4 \\  &  & **100.0** & **100.0** & **96.1** & **91.7** & **92.0** & **98.0** & 92.2 & **40.5** \\   &  & **100.0** & 45.0 & **100.0** & 68.8 & **98.4** & **98.0** & **92.8** & 26.0 \\   

Table 3: Comparison of GraphQA task accuracies of transformers explicitly trained for graph reasoning and LLMs with a variety of prompting strategies.

Conclusion

This paper provides a comprehensive evaluation of transformer models' graph reasoning capabilities, shedding light on their effectiveness across diverse graph reasoning tasks. By introducing a novel representational hierarchy, the study distinguishes between retrieval, parallelizable, and search reasoning tasks and offers insights into the performance of transformers at varying levels of granularity. The empirical investigation reveals that transformers exhibit strong performance in graph-based reasoning problems, often matching or surpassing specialized graph models. Furthermore, the study highlights transformers' exceptional ability to capture global graph patterns effectively, showcasing their capability in understanding long-range dependencies, a critical factor in solving tasks involving global graph structures. Overall, this work crystallizes precise representational trade-offs that reflect the fundamental reasoning capabilities of transformers and demonstrates that the tasks used to quantify those capabilities are indeed learnable in a sample-efficient and parameter-efficient manner.

While the hierarchy introduced by this work effectively separates graph algorithmic tasks into distinct equivalence classes with significant implications for their computability by transformers, several questions remain for future research. We focused on graph reasoning tasks due to their relevance to the broader context of transformers, GNNs, and parallel algorithms. However, the complexity classes presented here could potentially be extended to a wider range of algorithmic problems. While our assumption of unbounded-size MLPs provides strong lower bounds, further research into whether parallelizable tasks can be represented by transformers with bounded-size MLP units would complement this existing work. Broader experimental results that empirically evaluate the scaling laws would more directly assess the relevance of representational theoretical results to learnability.