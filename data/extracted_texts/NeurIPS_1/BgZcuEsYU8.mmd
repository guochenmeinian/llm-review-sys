# Causal Inference in the Closed-Loop: Marginal Structural Models for Sequential Excursion Effects

Alexander W. Levis

Carnegie Mellon University

alevis@cmu.edu

Authors contributed equally, names alphabetized

Gabriel Loewinger

National Institutes of Health

gloewinger@gmail.com

Francisco Pereira

National Institutes of Health

francisco.pereira@nih.gov

Authors contributed equally, names alphabetized

###### Abstract

Optogenetics is widely used to study the effects of neural circuit manipulation on behavior. However, the paucity of causal inference methodological work on this topic has resulted in analysis conventions that discard information, and constrain the scientific questions that can be posed. To fill this gap, we introduce a nonparametric causal inference framework for analyzing "closed-loop" designs, which use dynamic policies that assign treatment based on covariates. In this setting, standard methods can introduce bias and occlude causal effects. Building on the sequentially randomized experiments literature in causal inference, our approach extends history-restricted marginal structural models for dynamic regimes. In practice, our framework can identify a wide range of causal effects of optogenetics on trial-by-trial behavior, such as, fast/slow-acting, dose-response, additive/antagonistic, and floor/ceiling. Importantly, it does so without requiring negative controls, and can estimate how causal effect magnitudes evolve across time points. From another view, our work extends "excursion effect" methods--popular in the mobile health literature--to enable estimation of causal contrasts for treatment sequences greater than length one, in the presence of positivity violations. We derive rigorous statistical guarantees, enabling hypothesis testing of these causal effects. We demonstrate our approach on data from a recent study of dopaminergic activity on learning, and show how our method reveals relevant effects obscured in standard analyses.

## 1 Introduction

Optogenetics is a neuroscience technique to "turn on/off" neurons _in vivo_ in real-time, with millisecond time resolution. It works by shining lasers on neurons that have been genetically modified through viral infection to express a light-sensitive protein. It is one of the most popular assays with roughly 700 references to it in 2023 alone.2 Optogenetics is often applied to study the causal effect of manipulating specific brain circuits while animals (e.g., mice) perform behavioral tasks to study, for example, learning and decision-making. These tasks are typically composed of a sequence of trials, \(t\{1,2,...,T\}\), each of which involves presentation of stimuli and an opportunity for a behavioral response. For example, a trial might begin with a cue (e.g., a light), which indicates that a lever press will trigger delivery of a food reward. Investigators might want to know, for instance, whether applying optogenetic stimulation on a random subset of trials alters the rate at which mice press the lever. On trial \(t\), an animal's behavioral outcome, \(Y_{t}\), time-varying covariates, \(X_{t}\), and optogenetic (treatment) indicator, \(A_{t}\), are observed. Experiments often include both treatment (\(G=1\)) and negative-control (\(G=0\)) groups, with animals assigned randomly to each. While the laser (i.e., the sequential treatment, \(A_{t}\)) is often applied on a random3 subset of trials inboth groups, only treatment group animals (\(G=1\)) express the protein that enables the laser to trigger the target neural response. The control group thus controls for "off-target" effects such as the laser heating the brain, and the optogenetic insertion surgery. To answer the question above, investigators often estimate the effect of optogenetic manipulation through comparisons such as \(_{t}=[Y_{t} G=1]-[Y_{t} G=0]\). It is common to test whether \(_{t}=0\) at specific timepoints like the end of the study (\(t=T\)), or to conduct inference on summaries (e.g., \(=_{t}_{t}\)). These _between-group_ comparisons assess the intervention impact based on simple long-term, or "macro"/"global" longitudinal effects. When studies randomly deliver treatment at each trial (i.e., with stochastic policies), _within-group_ comparisons between laser and no-laser trials are also common (e.g., \(=_{t}\{[Y_{t} A_{t}=1,\ G=1]-[Y_ {t} A_{t}=0,\ G=1]\}\)).

Importantly, such comparisons do not lend themselves to testing _within-group_ "micro"/"local" longitudinal effects related to specific treatment sequence patterns. For example, one might ask whether there is a dose-dependent relationship between the outcome and the number of stimulations in the last five trials, or whether stimulation on two consecutive trials has a synergistic effect that is greater than if stimulation instead occurred on two non-consecutive trials. Figures 1A-C shows some representative micro longitudinal effects that are identifiable in many optogenetics studies, yet typically are not explored. Critically, such effects may be present even in studies in which one fails to detect the macro effects commonly tested. However, no formal causal inference framework has been applied to these studies, resulting in analysis conventions that limit the scope of questions researchers can ask.

Furthermore, certain experimental designs can complicate the use and interpretation of even standard analysis approaches. In "closed-loop" (referred to as "dynamic regimes" in the causal inference literature) designs, stimulation is applied depending on the behavior of the animal. For example, say a study tests if lever pressing for food, \(Y_{t}\), decreases if optogenetic stimulation (\(A_{t}=1\)) is applied, with positive probability, only when animals approach the lever (\(X_{t}=1\)). Since \(A_{t}\) is randomized conditional on \(X_{t}\), one must incorporate \(X_{t}\) into their analysis, but standard strategies like including \(X_{t}\) as a covariate in a regression can obscure effects and induce bias. This is because 1) \(X_{t}\) influences the probability of _both_ the outcome and treatment, and thus can be cast as a time-varying confounder, and 2) \(X_{t}\)_also_ mediates the effect of prior treatments ; see the illustrative DAG in Figure 1D, though note that we generalize this setting later on to allow treatment to depend on the

Figure 1: **Sequential Excursion Effects.** [A]-[C] The left panels show one setting where a sequence of laser simulations do or do not have the indicated effect on the outcome. The middle panel shows deterministic static policies that could be used to construct a causal contrast to probe the effect. The right panel shows what the anticipated effect size (darker is larger) of the contrast might be if the effect was or was not present. [A] **Blip Effect**: the effect of a single stimulation vs. no treatment on a recent trial. [B] **Effect Dissipation**: Whether the effect of a single stimulation causes an effect that rises and dissipates after a few trials, or persists. [C] **Dose Response**: Do successive simulations increase the response in a dose-dependent fashion? [D] Closed-loop design DAG for two trials. \(U\) is an unmeasured variable. [E] HR-MSM illustration inspired by figure in .

_complete_ history of previously measured variables at each time point. In this case, since treatment also influences both \(Y_{t}\) and \(X_{t}\) on subsequent trials, closed-loop designs induce "treatment-confounder feedback" , which can lead to bias with standard analyses. We include an example in Appendix B to show how, when the treatment has opposing effects on \(Y_{t}\) and \(X_{t}\), treatment and control groups can exhibit _identical_ average (observed) outcome levels even if the laser causes a large immediate effect. Furthermore, standard regression approaches can actually induce collider-bias, and block mediators of the treatment effect . Finally, if treatment policies deterministically rule out treatment (e.g., when \(X_{t}=0\)), certain effects are not identifiable: the positivity violation inherent to these designs precludes estimation of certain counterfactual distributions. Closed-loop designs therefore require specialized algorithms for valid causal inference.

More broadly, there have been a number of high profile calls for more rigorous definitions of causality and causal inference in neuroscience . However, to the best of our knowledge, existing methodological work  focuses on instrumental variable-based approaches to estimate causal effects of optogenetics on neural activity. Unlike our setting, these methods are restricted to datasets that include both measurements of the activity of the neurons stimulated by optogenetics, and the neurons those cells interact with. One can then conceptualize the neural activity of the stimulated neurons as treatment variables, and the optogenetics sequence as instruments. In addition to focusing on behavioral outcomes, we explicitly deal with sequentially randomized (and closed-loop) designs, whereas prior work treats each trial as an exchangeable draw, ignoring the sequential nature of trials.

Our contributions are (1) proposing the first formal counterfactual-based causal framing of these behavioral optogenetics designs, (2) developing an analysis framework based on history-restricted marginal structural models that enables the estimation of "sequential excursion effects" that capture the local causal contrasts described above, (3) expanding excursion effect methodology to account for positivity violations, and to accommodate treatment sequences greater than length one, (4) providing estimators with efficient computational implementations and strong theoretical guarantees under minimal nonparametric conditions (verified in simulations), and (5) applying our methods to data from a high profile _Nature_ paper, and showing how they reveal effects obscured by standard methods.

## 2 Notation and Related Work

In this section, we (i) provide the necessary notation and a brief review of relevant work, and (ii) describe the key methodological gap in the current literature: existing methods cannot estimate causal effects of proximal treatment sequences longer than one timepoint in closed-loop designs.

NotationLet \(_{t}=\{X_{t},A_{t},Y_{t}\}\) be the vector of _observed_ variables for an animal on trial \(t\). We denote \(T\) as the number of trials and \([T]\) as the set \(\{1,2,...,T\}\). A sample of subjects \(i=1,2,...,n\) is collected but, as subjects are exchangeable, we often suppress indices to reduce notational burden. We express _counterfactual_ variables, or _potential outcomes_, with parentheses. For example, \(Y_{t}(_{t})\), represents the potential outcome that would be observed at trial \(t\) if a subject received the treatment sequence, \(_{t}=(a_{1},,a_{t})\). Overbars represent all history up to and including a given trial. For example, \(_{j}=(B_{1},,B_{j})\), for any sequence of variables \(\{B_{t}\}_{t=1}^{T}\), and any \(j[T]\). Finally, we define \(H_{t}=(_{t},_{t-1},_{t-1})\), so \(H_{t}\) includes all information prior to the treatment "decision" at \(t\).

Relevant Literature_Marginal structural models_ (MSMs) are often used to model the mean counterfactuals \([Y_{t}(_{t})]\) in sequentially randomized experiments, though these typically do not perform well  when there are a large number of time points (e.g., as in many optogenetics studies): the variance of the model coefficients can grow prohibitively large. _History-restricted_ MSMs  (HR-MSMs) model \([Y_{t}(_{,t})]\) for some \(_{,t}=(a_{t-+1},,a_{t})\), typically with \( t\). That is, HR-MSMs model the mean counterfactual outcome at time \(t\), under an intervention defined on a proximal (often short) treatment sequence. As \([Y_{t}(_{,t})]=[Y_{t}(_{t-},_{,t})]\), by a consistency assumption, these estimands implicitly marginalize over the observed treatment sequence, \(_{t-}\), prior to the first point of intervention. However, any Markov-like assumptions made by the causal framework follow directly from the experimental design: HR-MSMs (and, by extension, our proposed methods) allow for \(X_{t}\), \(Y_{t}\) to be causally affected by _all_ prior trials (i.e., \(_{j}\) for \(j[t-1]\)). By placing structure on \([Y_{t}(_{,t})]\), the HR-MSM can borrow strength across treatment sequences \(_{,t}\), which can increase power when there are many trials. Figure 1E provides a graphical illustration of HR-MSMs. HR-MSMs are typically fit by using generalized estimating equations (GEE) with inverse probability of treatment weighting (IPW). IPW resolves the dilemma with standard regression techniques in sequentially randomized experiments, outlined above, where failure to condition on time-varying confounders, \(X_{t}\), biases estimates (as treatment is randomized conditional on \(X_{t}\) in closed-loop designs), but conditioning on \(X_{t}\) induces confounding (\(X_{t}\) are colliders on the path between past treatments and subsequent outcomes, through unmeasured confounders, \(U\), as shown in the DAG in Figure 1D)) . HR-MSMs can also incorporate time-varying effect modifiers (e.g., see  and references), to test, for example, whether causal effects vary across trials, or animal-specific covariate levels.

The gaps: Sequential effects and positivity violationsIn designs that assign treatment randomly at each trial, HR-MSMs can be used to estimate the causal effect of specific deterministic treatment sequences \(_{,t}\) that may differ from the observed sequence \(_{t}\) close to trial \(t\), and are compatible with the experimental treatment rule ("policy"). Importantly, this enables estimation of interpretable causal parameters, such as the effect of treatment on the most recent trial, \([Y_{t}(a_{t}=1)-Y_{t}(a_{t}=0)]\). These causal contrasts have grown popular recently in the analysis of mobile health studies , where they are referred to as "excursion effects." However, current methods are restricted to estimating excursion effects for the \(=1\) case in experimental designs like ours, and thus preclude estimation of effects defined only for \(>1\) (e.g., the micro longitudinal effects in Figures 1 and 4). Mobile health studies often include treatment rules with positivity violations: due to ethical or practical constraints, treatment must be withheld in certain cases (e.g., no phone notifications while driving).  use the notation that treatment is withheld when the time-varying "availability" indicator, \(I_{t}\), equals zero. Similarly, in "closed-loop" optogenetics experiments, \(I_{t}=1\) when the conditions are met such that neural manipulation may occur (e.g., when the animal approaches the lever in the example in Section 1). There have been proposals for methods intended to account for such implied positivity violations [19; 5; 26], such as the availability-conditional estimand : \([Y_{t}(a_{t}=1)-Y_{t}(a_{t}=0) I_{t}=1]\). However, estimands proposed for these settings are defined only for \(=1\). Thus, in the presence of these positivity violations, there is currently no methodology to conduct causal inference for longer proximal treatment sequences. We note that machine learning based causal methods including causal transformers , counterfactual recurrent networks , and recurrent marginal structural networks  are comparable to HR-MSMs that condition on all measured variables prior to the first intervention timepoint (\(t-+1\)). These methods target effects of static treatment sequences and require a positivity assumption, and thus cannot be applied in closed-loop designs. They also do not provide tools for statistical inference.

## 3 Methods

To fill the gaps identified above, we propose HR-MSMs for proximal sequences of dynamic treatment regimes, designed to be compatible with treatment availability restrictions in this scientific context. These estimands are defined for any \( 1\), can incorporate time-varying effect modifiers, and can dissect more intricate patterns of treatment over time, compared to standard excursion effects.

### HR-MSMs for Dynamic Treatment Regimes

Adopting the notation from , we define \(I_{t}([A_{t}=1 H_{t}]>0)\) as an "availability indicator", i.e., \(I_{t}=0\) if and only if active treatment (e.g., laser stimulation) is prohibited by design. Define \(_{t}=\{d_{t}:_{t}\{0,1\} d_{t}(H_{t})=0\) if \(I_{t}=0\}\), for any \(t\), to be the class of treatment rules at time \(t\) compatible with \(I_{t}\). In particular, we will consider the deterministic rules \(^{*}_{t}=\{d^{(0)}_{t},d^{(1)}_{t}\}_{t}\), where \(d^{(0)}_{t} 0,\)\(d^{(1)}_{t} I_{t}\). In words, \(d^{(0)}_{t}\) fixes \(A_{t}=0\), and \(d^{(1)}_{t}\) sets \(A_{t}\) equal to \(I_{t}\). The treatment rules \(d^{(0)}_{t},d^{(1)}_{t}_{t}\) represent the two most extreme policies whose effects remain identifiable. We can combine these time-specific rules to construct multiple time-point analogs of excursion effects compatible with availability restrictions: for \(\), we let \(}_{,t}\) be a subset of \(^{*}_{t-+1}^{*}_{t}\), taking \(_{,t}=(d_{t-+1},,d_{t})}_{ ,t}\) to be a sequence of \(\) treatment rules (compatible with availability restrictions) for trials \(j\{t-+1,...,t\}\). The counterfactual outcome under this policy sequence is defined to be

\[Y_{t}(_{,t})=Y_{t}(A_{1},,A_{t-},d_{t-+1}(H_{t- +1}),,d_{t}(H_{t}(_{-1,t-1}))). \]That is, \(Y_{t}(_{,t})\) is the counterfactual outcome under an intervention that leaves the natural value of treatment for the first \(t-\) trials, then sequentially determines treatment by applying \(d_{t-+j}\) to \(H_{t-+j}(_{j-1,t-+j-1})\), for \(j[]\), where \(_{j-1,t-+j-1}=(d_{t-+1},,d_{t-+j-1})\).

Letting \(V_{t} H_{t}\) be a set of effect modifiers at trial \(t\), we seek to estimate \([Y_{t}(_{,t}) V_{t-+1}]\), the counterfactual mean outcome, conditional on effect modifiers that are observed _before_ the treatment decision of trial \(t-+1\). By construction, these estimands are identifiable under standard causal assumptions (see Section 3.2). We discuss their interpretation, and compare with existing proposals in Appendix C.1. When \(>1\) and studies have many trials, there may be many potential treatment rule sequence combinations. We thus propose to estimate effects of these interventions with an MSM on the (conditional) means of the counterfactuals (1): \(m(t,_{,t},V_{t-+1};)[Y_{t}( _{,t}) V_{t-+1}]\), where \(m\) is a fixed known function. We aim to conduct inference on the MSM parameters, \(\), but we do not assume that the model is necessarily well-specified, and thus treat the MSM parameters as projections onto the working model \(m\)[20; 32]:

\[_{0}=_{^{q}}_{t=} ^{T}_{_{,t}_{,t}}(h(t,_{,t},V_{t-+1})\{Y_{t}(_{,t})-m(t,_{,t},V_{t-+1};)\}^{2}), \]

for some fixed non-negative weight function \(h\). This projection approaches lies between a fully parametric strategy, that assumes \(m\) is correctly specified, and a fully nonparametric approach, that places no structure across the target causal quantities. The target \(_{0}\) is defined as the parameter of the best fitting working model \(m\) (i.e., closest in \(L_{2}()\)). In practice, the choice between considering \(m\) as a working model or as a correctly specified model amounts to a trade-off between bias and variance--see the discussions in [13; 12] where analogous projection parameters are proposed.

### Identification and Estimation

In this section, we first describe the causal assumptions under which the effects of interest are identified. We then develop an inverse probability-weighted estimator of the MSM parameters, and derive their asymptotic properties. While we focus on dynamic regime HR-MSMs below, our results also apply to static regime HR-MSMs in the case that there are no availability issues (i.e., \(I_{t} 1\)). There, the treatment rule \(_{,t}\) reduces to a corresponding static sequence \(_{,t}\).

For each \(t\), define the treatment probability function \(_{t}(a;H_{t})[A_{t}=a H_{t}]\). We make the following standard assumptions, which are expected to hold in many optogenetics designs:

**Assumption 3.1**.: _Consistency: \(Y_{t}(_{,t})=Y_{t}\), whenever \(A_{j}=d_{j}(H_{j})\), for all \(j\{t-+1,,t\}\)_

**Assumption 3.2**.: _Positivity: For all \(t\{,,T\}\), and \(d_{t}_{t}^{*}\), \(_{t}(d_{t}(H_{t});H_{t})\), w.p. 1_

**Assumption 3.3**.: _Sequential randomization: \(A_{s}\!\!\! Y_{t}(_{,t}) H_{s}\), for all \(t\{,,T\}\), \(s\{t-+1,,t\}\)_

We provide a detailed discussion of these assumptions in practice in Appendix C.2. The following result says that these three assumptions are sufficient for identification of the counterfactual means \([Y_{t}(_{,t}) V_{t-+1}]\), and of the MSM parameters \(_{0}\).

**Proposition 3.4**.: _Under Assumptions 3.1-3.3, we have_

\[(Y_{t}(_{,t}) V_{t-+1})=_{} (_{j=t-+1}^{t}(A_{j}=d_{j}(H_{j}))}{_{j}(A _{j};H_{j})}Y_{t}|\,V_{t-+1}.).\]

_Recall that \(Z_{i}=\{_{t,i}\}_{t=1}^{T}\) is the totality of data observed on subject \(i\); suppressing subject-specific index for clarity, define \((Z,):^{q}^{q}\) via_

\[(Z,)=_{t=}^{T}\ _{_{,t} }}_{,t}}h(t,_{,t},V_{t-+1})M (t,_{,t},V_{t-+1};)\\ [_{j=t-+1}^{t}(A_{j}=d_{j} (H_{j}))}{_{j}(A_{j};H_{j})}]\{Y_{t}-m(t,_{,t},V_{t- +1};)\},\]

_where \(M(t,_{,t},V_{t-+1};)=_{}\,m(t, _{,t},V_{t-+1};)\). Then, assuming the solution to (2) is unique, and the working model \(m\) is differentiable in \(\), the MSM parameters \(_{0}\) are identified through the estimating equation \(=_{}((Z,_{0}))\)._The result of Proposition 3.4 is a population inverse probability-weighted estimating equation for the target parameters \(_{0}\). This estimating equation motivates a corresponding IPW estimator, \(}\), solving the empirical IPW estimating equation \(_{n}[(Z,})]=\). In the optogenetics applications of interest, the propensity scores \(_{t}\) are known by design, and can be plugged in when estimating \(}\).

We now prove asymptotic normality of the our estimator, \(}\), under mild conditions. We require the following notation: define \(()=[(Z,)(Z,)^{T}]\) and \(()=[_{}\,(Z,)]\).

**Theorem 3.5**.: _Suppose Assumptions 3.1-3.3 and the following conditions hold:_

1. _The minimizer_ \(_{0}\) _in (_2_) is unique;_
2. \(m(t,_{,t},V_{t-+1};)\) _is Donsker in_ \(\)_, continuously differentiable at_ \(_{0}\)_, uniformly in_ \(V_{t-+1}\)_;_
3. _In a neighborhood around_ \(_{0}\)_,_ \(()\) _and_ \(()\) _are finite-valued, and_ \(()\) _is non-singular;_
4. \(}_{0}\)_._

_Then \((}-_{0})}{{ }}(,(_{0}))\), where \(()=()^{-1}()() ^{-1}\)._

Theorem 3.5 gives the asymptotic distribution of the estimator \(}\). The conditions (i)-(iv) are relatively mild; see Appendix C.3 for a discussion. Theorem 3.5 provides a strategy to construct asymptotically valid Wald-based confidence intervals for the MSM parameters \(_{0}\): for any \(\) we can take

\[}()=_{n}[(Z,)(Z,)^{T}],\ }()=_{n}[_{}\, (Z,)],\]

and define \(}=}(})^{-1}}( })}(})^{-1}\), which is consistent for \((_{0})\). Then, for \(j[q]\), an \((1-)\) confidence interval for \(_{j,0}\) is given by \(_{j} z_{1-/2}_{jj}}{n}}\), where \(z_{1-/2}\) is the \((1-/2)\)-quantile of the standard normal distribution, and \(_{jj}\) is the \(j\)-th diagonal element of \(}\). Confidence intervals for any linear combination of the \(\) parameters can be constructed in a similar fashion.

We provide an implementation that builds the necessary dataset (with each observation copied once for every regime in \(_{,t}\)), calculates the corresponding IPW weights, and estimates the HR-MSM parameters \(\) by solving the estimating equation in expression 2 using the rootSolve R package . The process takes about 10 seconds on a standard laptop, for \(>100,000\) total (pre-copy) trials.

## 4 Experiments

### Simulation Studies

Experimental SetupWe sought to assess performance of the proposed estimator, and identify variance estimators that yield nominal coverage in the small \(n\) settings common in optogenetics studies. To evaluate the accuracy of our framework in estimating mean counterfactuals, we designed the simulations such that the target estimands--contrasts of mean counterfactuals--corresponded to regression coefficients from the true HR-MSM. The data were simulated to mimic closed-loop optogenetics designs with positivity violations: we drew i) \(X_{0}(1/2)\); ii) \(A_{t} X_{t}(X_{t})\), for \(t\{0,,T\}\); iii) \(X_{t} A_{t-1}(0.4+0.4A_{t-1})\), for \(t[T]\); and iv) \(Y_{t} X_{t-1},A_{t-1},X_{t},A_{t}(_{1}X_{t-1}+ _{2}A_{t-1}+_{3}X_{t}+_{4}A_{t},_{t}^{2}),\ \ t[T]\), where \((_{1},_{2},_{3},_{4})=(0.25,2,1.75,0.5)\), and \(_{t}^{2}=1\) for all \(t\). These set availability indicator \(I_{t} X_{t}\), for all \(t\), and result in marginal probabilities \([X_{t}=1]=\), \([A_{t}=1]=\), for all \(t\). We obtain a closed form for the parameters of the saturated two time-point dynamic treatment regime HR-MSM: letting \(_{2,t}=(d_{t-1},d_{t})}_{2,t}\) be arbitrary, and defining \(J_{t-1}(d_{t-1} d_{t-1}^{(1)})\), \(J_{t}(d_{t} d_{t}^{(1)})\), we derive in Appendix D.1 that \((Y_{t}(_{2,t}))=_{0}+_{1}J_{t-1}+_{2}J_{t}+ _{3}J_{t-1}J_{t}\), where \(_{0}=0.5_{1}+0.4_{3}\), \(_{1}=0.5_{2}+0.2_{3}\), \(_{2}=0.4_{4}\), and \(_{3}=0.2_{4}\). Aggregating \(=(_{0},_{1},_{2},_{3})\), the HR-MSM given by

\[m(t,_{2,t};)=_{0}+_{1}J_{t-1}+_{2}J_{t}+_{3 }J_{t-1}J_{t} \]

is correctly specified under this data generating process, and we can evaluate the performance of the proposed estimator relative to these true values.

[MISSING_PAGE_FAIL:7]

To define "trials," the authors spliced the time-series of estimated pose classifications into intervals of consecutive timepoints with the same pose classification. If mice exhibited the target pose on trial \(t\), they were considered "available" for optogenetic stimulation, \(I_{t}=1\), and were "unavailable" otherwise, \(I_{t}=0\). The laser was applied (\(A_{t}=1\)) with the dynamic policy, \((A_{t}=1 I_{t})=0.75I_{t}\). Denoting \(Y^{0}_{t}\) and \(Y_{t}\) as a binary indicator that an animal engaged in the target pose on trial \(t\) of the _baseline_ and _treatment_ sessions, respectively, the authors estimated treatment effects of the form \(=([^{1} G=1]-[^{0} G=1] )-([^{1} G=0]-[^{0} G=0])\) where \(^{0}=_{t=1}^{T_{0}}Y^{0}_{t}\), \(^{1}=_{t=1}^{T}Y_{t}\), and \(T,T_{0}\) are the trial numbers in treatment and baseline sessions, respectively.4 There were \(n_{1}=28\) and \(n_{0}=12\) animals in the optogenetics and control groups, respectively. \(T\) ranged across animals/sessions from 1207-4876, with a mean of 3612 and IQR = \(\). The authors reported a (pooled across target poses) positive optogenetics treatment effect estimate akin to \(\), suggesting DA stimulation causes an increase in target pose frequency.

We argue this analysis procedure leaves many scientific questions untested. Conceptualizing optogenetics like a "study drug," we question whether stimulation immediately "taught" the animal the target pose, or whether the treatment effect on learning had a lagged onset. Similarly, did the effect of a single stimulation persist or dissipate across trials? Did more treatments lead to more learning monotonically, or is there an antagonistic effect or non-monotonic dose-response curve in learning?

Application MethodsWe applied our framework to provide a nuanced trial-by-trial characterization of the causal effects of DA stimulation, and formally answer the questions above. Specifically, we tested the causal effect of specific sequences of deterministic dynamic policies, \(_{,t}\) (occurring on trials \(t\{t-+1,,t\}\)), on the mean counterfactual \([Y_{t}(_{,t})]\). We defined the outcome \(_{t}\) as an indicator that the mouse exhibited the target pose on trial \(t+2\), the next trial on which mice could exhibit the target pose if they were available for stimulation on trial \(t\). We fit a set of HR-MSMs illustrating that we can reliably estimate the types of excursion effects in Figure 1. We describe the models we fit below, and relegate code, data and pre-processing details to Appendix Section F.

ResultsOur first question was whether standard methods reveal significant treatment effects when assessed with the estimands commonly tested in optogenetics studies. We applied a GEE with mean model, \(([^{s} G=g,S=s])=_{0}+_{1}g+ _{2}s+_{3}g s\), where \(S\{0,1\}\) indicates baseline and optogenetics sessions, respectively. The estimate \(_{3}\), shown in Figure 3F, thus provides a treatment effect estimate for the _observed_ stochastic dynamic policy in . We adopted a Poisson working model, since  analyzed \(^{1},^{0}\). We tested these (macro longitudinal) effects for each pose individually, rather than pooling over them, as in . The model yielded no significant effects for any individual pose. We show boxplots in Appendix Figure 10 of the subject-level summary \(^{1}-^{0}\) that is compared across groups in this model. Outcome levels are similar across groups for most poses, further highlighting how standard outcome summaries can obscure effects.

To assess an analogous "local" treatment effect using our method, we tested the impact of a single stimulation opportunity. We further evaluated whether the effect had a lagged onset and/or dissipated

    &  &  &  \\  &  &  &  &  &  &  &  &  &  \\  Blip & \(HC\) & \(0.94 0.01\) & \(0.94 0.01\) & \(0.95 0.01\) & \(0.95 0.01\) & \(0.99 0.00\) & \(0.97 0.01\) & \(0.95 0.01\) & \(0.95 0.01\) \\  & \(LS\) & \(0.86 0.01\) & \(0.88 0.01\) & \(0.93 0.01\) & \(0.95 0.01\) & \(0.86 0.01\) & \(0.89 0.01\) & \(0.93 0.01\) & \(0.94 0.01\) \\ Dissip & \(HC\) & \(0.93 0.01\) & \(0.94 0.01\) & \(0.95 0.01\) & \(0.95 0.01\) & \(0.97 0.01\) & \(0.96 0.01\) & \(0.94 0.01\) & \(0.94 0.01\) \\  & \(LS\) & \(0.85 0.01\) & \(0.89 0.01\) & \(0.94 0.01\) &across trials. We included group, \(G\), as an effect modifier, to test whether the causal effect of this treatment opportunity was larger in one of the groups. Setting \(=3\), and restricting the regimes of interest to those with at most one treatment opportunity "dose", \(_{3,t}\{(d_{t-2},d_{t-1},d_{t}):_{j=t-2}^{t}_{j}(d_{j} ) 1\}\), where \(_{j}(d_{j})=(d_{j}=d_{j}^{(1)})\), we fit the HR-MSM

\[([Y_{t}(_{,t}) G=g])= _{0}+_{r=0}^{2}_{r+1}_{t-r}(d_{t-r})+_{4}g+_{r=0}^ {2}_{5+r}g_{t-r}(d_{t-r}). \]

Thus, \(_{r}\) with \(r\) is an estimate of the log odds ratio comparing the mean counterfactual of \(Y_{t}\) under a treatment sequence with a single dose (on \(r=1,2\), or \(3\) trials prior) vs. a treatment sequence with zero dose. This permits assessment of effect dissipation or persistence. Figure 1B illustrates the analogous effect under a static regime. The interaction terms, \(_{r}\) with \(r\{5,6,7\}\), quantify how these causal effects of a recent treatment opportunity differ between the two groups.

The results from our model (4) reveal that stimulation opportunities in the treatment group tend to _reduce_ the odds of the outcome, compared to the control group. As shown in Figure 3C, these effects are significantly negative for at least one lag level in five out of six target poses. In personal communications, the authors of  stated that this result appeared consistent with their finding that animal exploration increased right after stimulation (quantified as higher pose entropy). Figure 3D shows the main effect of group under a treatment sequence of dose zero. In essence, this provides an estimate of the "long-term" effect of DA stimulation: \(_{4}\) is the log odds ratio of treatment group under a regime of dose zero (i.e., a "no recent stimulation" policy). We fit comparable models for sequences as long as \(=7\) and found results were similar across \(\) values.

Next, we fit the analogous model for the availability-conditional estimand  to determine whether current excursion effect methods (i.e., those confined to \(=1\) policies) identify the same treatment effects: \(([Y_{t}(a_{t}) I_{t}=1,G=g])=_{0}+ _{1}a_{t}+_{2}g+_{3}g a_{t}\). Figure 3C shows that the effect estimates, \(_{3}\), are significant in only one pose. These results highlight how our approach can uncover a greater number of significant effects.

Finally, in Appendix Section E, we include analyses showing that the laser exhibits a dose-response curve in both groups: more treatment opportunities (on some poses) in the last \(=5\) trials causes the animal to exhibit the target pose more often. Additionally, there is significant effect modification by baseline responding: the laser has a larger effect in animals who exhibited high baseline pose frequency. Together, these results show we can reliably estimate sequential excursion effects.

## 5 Discussion

We propose the first, to the best of our knowledge, formal causal inference framework for closed-loop optogenetics behavioral studies. We introduce a nonparametric excursion effect framework, an associated IPW estimator (with valid CIs), with a scalable implementation, and proved its consistency

Figure 3: **Optogenetics Analyses.** Plots show coefficient estimates (error bars show 95% CIs). Columns/colors indicate the target pose. [A] Interaction term between \(\) and sequential excursion effect of a single “dose” occuring \(r=1,2,3\) trials prior to the proximal outcome that the “dose” occurred on. The excursion effects are significant for poses 1-5 (at, at least, one lag level). [B] Availability conditional estimate of interaction \(\): laser \(\) group interaction. [C] Main effect of \(\) under a “no-recent-treatment opportunity” policy; this reflects the average causal effect of group among a population that has received no laser opportunities in the last \(=3\) trials. [D] Macro longitudinal analysis, similar to original paper, identifies no significant effects.

and asymptotic normality under mild assumptions. Methodologically, our proposed sequential excursion effects represent an expansion of the conditional estimands proposed in  to longitudinal policies (\( 1\)), in the presence of positivity violations. Our methods also directly apply to "open-loop" (static policies) designs, as they arise as a special case when \(I_{t}=1\) for all \(t[T]\).

HR-MSMs are powerful and useful models, but have their limitations. As has been discussed in the causal inference literature, these estimands marginalize over all treatments for trials \(t[t-]\), and thus depend on the protocol used in the design . Moreover, while contrasts of our estimands are null under the sharp null of no causal effect of treatment (e.g., optogenetic laser stimulation), effects should generally still be interpreted in terms of treatment _opportunities_. Finally, while our implementation is computationally efficient, we anticipate computational challenges for very large \(\).

The model \(m\) and the number of intervention timepoints \(\) represent key choices for practitioners. Our inferential results (i.e., Theorem 3.5) are valid for a large class of working mean models \(m\), and notably do not rely on any distributional assumptions. The "Donsker" requirement (condition (ii) in Theorem 3.5) is satisfied outright by generalized linear models such as those we use in our application , as well as some formulations of random forests  and kernel estimators . In future work, we will study how inference can be obtained for more flexible models that do not satisfy the Donsker assumption. Likewise, the value of \(\) plays a significant role as it determines the nature of the effects being estimated, and should be chosen on the basis of subject matter expertise. That said, we found that 2-3 intervention timepoints are often sufficient to capture a rich set of sequential excursion effects, and in our application that results were relatively stable across a range of \(\) values.

The application highlights the drawbacks of standard optogenetics analysis methods. Our finding that macro longitudinal estimates of individual target poses show almost no effect between groups highlights how "treatment-confounder" feedback can obscure strong treatment effects in closed-loop designs, even when inspecting simple averages of observed outcomes. Our methods account for this by careful causal adjustment with IPW. In personal communications with the authors of , they agreed with our findings and remarked at how these methods reveal a collection of causal effects that are difficult to uncover without sophisticated causal inference methods.

Our analyses reveal immediate _negative_ effects (detectable on the next trial) and _positive_ slower effects of DA stimulation (i.e., in treatment relative to control animals). We also find the control group exhibits positive, off-target effects of the laser. Together the _opposing_ signs of these "fast"/"slow" and on/off-target causal effects may further dilute the magnitude of macro longitudinal effects that summarize the outcome across many trials (e.g., total pose counts). Finally, by enabling estimation of _sequential_ excursion effects (i.e., \(>1\)), we can reveal effect profiles (e.g., dose-response curves) not possible with availability-conditional estimands whose definition is confined to \(=1\) regimes. As we observed, the optogenetics group sometimes exhibits an excursion effect not present in the control group. Thus, by combining different sequential excursion effects, analysts can, for example, disentangle laser on-target from off-target effects. When off-target effects are not a major concern, our framework enables estimation of causal effects _without_ having to collect data in a control group, thereby potentially reducing the number of animals required in a study.

Although we focus on optogenetics here, our proposed methods are relevant for a wide range of mobile health, neuroscience and psychology experiments for which the "local/micro" longitudinal structure is of scientific interest. Indeed, "closed-loop" designs are common in many behavioral studies in human neuroimaging and cognitive sciences (e.g., when stimuli are conditionally randomized). We hope our methods constitute a useful methodological contribution to the causal inference literature, and will help applied researchers exploit the rich information contained in their experiments.