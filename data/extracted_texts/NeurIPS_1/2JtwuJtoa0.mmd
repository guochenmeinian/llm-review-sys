# Unifying Predictions of Deterministic and Stochastic Physics in Mesh-reduced Space with Sequential Flow Generative Model

Unifying Predictions of Deterministic and Stochastic Physics in Mesh-reduced Space with Sequential Flow Generative Model

Luning Sun

Lawrence Livermore National Lab

Livermore, CA 94550

sun42@llnl.gov

Equal contribution.

Xu Han

Tufts University

Medford, MA 02155

xu.han@tufts.edu

Han Gao

Harvard University

Cambridge, MA 02138

hgao1@seas.harvard.edu

&Jian-Xun Wang

University of Notre Dame

Notre Dame, IN 46556

jwang33@nd.edu

&Li-Ping Liu

Tufts University

Medford, MA 02155

liping.liu@tufts.edu

###### Abstract

Accurate prediction of dynamical systems in unstructured meshes has recently shown successes in scientific simulations. Many dynamical systems have a nonnegligible level of stochasticity introduced by various factors (e.g. chaoticity), so there is a need for a unified framework that captures both deterministic and stochastic components in the rollouts of these systems. Inspired by regeneration learning, we propose a new model that combines generative and sequential networks to model dynamical systems. Specifically, we use an autoencoder to learn compact representations of full-space physical variables in a low-dimensional space. We then integrate a transformer with a conditional normalizing flow model to model the temporal sequence of latent representations. We evaluate the new model in both deterministic and stochastic systems. The model outperforms several competitive baseline models and makes more accurate predictions of deterministic systems. Its own prediction error is also reflected in its uncertainty estimations. When predicting stochastic systems, the proposed model generates high-quality rollout samples. The mean and variance of these samples well match the statistics of samples computed from expensive numerical simulations.

## 1 Introduction

Accurate prediction of long-term dynamics of physical systems is of great interest in many science and engineering fields. The classical simulation of a system heavily relies on a spatial/temporal discretization of the space and the numerical solution to a finite-dimensional algebraic system derived from the governing equation . However, due to the multi-scale, stochastic nature of the complex physics and the complexity of the geometry, the simulation of large-scale real-time applications is extremely expensive in computation . In recent years, deep learning models have been applied to predict rollouts of large and complex physical systems thanks to their flexibility and scalability . Moreover, they can handle uncertainties and non-linearity in physical problems  more effectively than traditional methods.

Previous work has studied two types of complex dynamical systems: deterministic ones and stochastic ones. A deterministic system is often considered under a perfectly controlled experiment with exactly known PDE terms and initial conditions (IC) or boundary conditions (BC) [9; 10; 11; 12; 13; 14]. This type of system can be modeled by autoregressive predicting models. A stochastic system such as quantum mechanics  and statistical physics  has a stochastic rollouts. When there are stochastic forcing terms or IC/BC terms in the governing equations, researchers have developed various models for predicting the stochastic state variables, such as turbulence velocity and stock prices [17; 18; 19; 20; 21]. Given that there is not a clear boundary between the two types of systems, it is highly desirable that a unified model can model either a deterministic or a stochastic system automatically. However, such models so far are limited to classical numerical models such as OpenFOAM . There is an urgent need to develop a unified deep-learning model that can model both types of systems.

In this work, we propose a unified framework based on deep generative models to predict deterministic and stochastic systems. The new model is based on graph-structured state representations , which can handle irregular spatial areas commonly seen in dynamical systems. It uses an autoencoder to encode a state representation to a low-dimensional latent vector. Accurate encoding and decoding is critical for recovering the state of the dynamical system. This work makes several innovations to enhance the autoencoder's ability to preserve the information in system states. We provide a new approach to encoding the graph-structured representation with a vector with a fixed length. We also get some inspiration from regeneration learning  and train our autoencoder with self-supervised learning.

To describe stochasticity in the system, we use a sequential probabilistic model for the latent representations. We integrate a transformer and a normalizing flow to construct a step-wise predictive neural network in the latent space. When there is stochasticity, the model will learn the conditional distribution of the next latent state; when there is no stochasticity, it can place probabilities to correct deterministic predictions and still can minimize the predictive error. By including the ability to simulate both deterministic and stochastic systems in a uniform framework, it reduces the effort of developing separate models for different problems.

We evaluate our proposed framework in an extensive empirical study. The results indicate the proposed model outperforms the SOTA baselines on deterministic datasets regarding accuracy. More importantly, for the first time, we introduce several alternative evaluation metrics other than normalized RMSE for stochastic fluid dynamics, which help improve comparisons between different methods in this domain. The proposed framework can produce high-quality samples for stochastic systems in the mesh space.

## 2 Background

### Problem definition

Let's consider a general partial differential equation (PDE) defined on the \(d\)-dimensional space and one-dimensional time domain,

\[}{ t}=j(,,)[0,T_{ end}] \]

where \(^{d}\) is the spatial domain, \(T_{ end}\) is the endpoint of time, \(:[0,T]\) is the random parameter over time for stochastic systems (e.g., boundary conditions), and \(:[0,T]\) is the primary solution variable (e.g., velocity and pressure of fluid flow). Here \(:\) is the global physical system parameter and is time-invariant (e.g., Re number) for a given rollout. \(j:[0,T][0,T]\) is an aggregation of the spatial terms of conservation laws (e.g., source and flux). To numerically solve the conservation law in Equation 1, let \(_{h}\) be a mesh of \(\), that is, \(_{h}=\{C_{i}:i=1,,N\}\) is a collection of non-overlapping cells that cover \(\). We further use \(_{i,t}\) to denote the evaluation of \(\) at the cell center of \(C_{i}\) at time step \(t\).

Using the mesh described above, we apply a finite volume discretization to yield the parametrized, nonlinear dynamical system. Here, the dynamical system can be computationally intensive because a fine-level mesh will lead to discretization with a large degree of freedom. For stability issues, the numerical time step also needs to be very small. Therefore, numerical simulations with traditional methods require extremely expensive computation and storage.

In this paper, we are interested in two different scenarios: _deterministic_ dynamics with invariant parameter \(\) over time (e.g., fixed boundary condition ), and _stochastic_ dynamics with random parameter \(\) over time (e.g., perturbations in boundary conditions of turbulent flow). Both cases will also include the global physical parameters \(\). The scope of our paper is to build a unified data-driven surrogate model for generating/predicting parametric PDE solutions.

### Normalizing flow models

A normalizing flow model constructs a flexible probabilistic distribution by applying a learnable bijective mapping to a simple random variable (e.g. Gaussian distributed). Suppose the mapping is \(=f()\) with \(^{d}\) being the simple input variable, then we have the probability \(p()\) of \(\) as follows:

\[p()=p()())}{( )})^{-1}. \]

Here \())}{()}\) is the Jacobian of \(f\) at \(\). The function \(f\) is usually a neural network with a layered structure, with each layer being a bijective mapping. Then the determinant of \())}{()}\) is the product of determinants of these layers' Jacobian matrices. With a special design of layer structures, their determinants can be efficiently computed. For example, a RealNVP model  is constructed by stacking several _coupling_ layers, each of which has a lower triangular Jacobian matrix. With \(^{d}\) as the input, a coupling layer \(f_{}\) runs the following calculation:

\[f_{}()=([1:d^{}],[(d^{}+1):d] (s([1:d^{}]))+t([1:d^{}])) \]

Here \(\) concatenates its arguments as one vector, and \(d^{}\) is usually about one-half of \(d\). In this calculation, the first half of the vector is directly copied to the output. The second half goes through an entry-wise linear transformation: the operation \(\) is the Hadamard product, the neural network \(s\) provides scaling coefficients, and the neural network \(t\) provides biases. With \(K\) such coupling layers, we have a transformation that defines a flexible distribution \(p()\).

\[p()=p()_{=1}^{K}|( f_{}( ^{-1})/^{-1})|^{-1} \]

Here \(^{0}=\), and \(^{}=f_{}(_{-1})\). At the same time, \(p()\) also has an efficient sampling procedure given by \(f\).

## 3 Methodology

Our new predicting model has three components: an encoder that compresses a graph representation of the state into a fixed-length vector, a sequential model that predicts next-step representations in the latent space, and a decoder that decodes spatial states from graph representations. The encoder is an improved version of the GMR-GMUS encoder . The sequential model is a conditional flow model. The encoder and decoder are trained via self-supervised learning as in regeneration learning.

### Graph representation learning

Following GMR-GMUS, we use a graph \(=(,)\) to encode a snapshot of a deterministic or stochastic dynamical system at time step \(t\). Here each node \(i\) corresponds to the mesh cell \(C_{i}\), and each edge \((i,j) E\) represents a neighboring relationship between two cells. At each step \(t\), the solution \(_{i,t}\) at cell \(i\) becomes the feature vector of the node \(i\) at time \(t\). Because the mesh is pre-defined and fixed, the graph representation \((G,(_{i,t},i V))\) preserves the full information of the mesh \(_{h}\) at time \(t\). Here we use \(_{t}=(_{i,t}:i V)\) to denote a snapshot at time \(t\).

The key task for the encoder is to encode the graph into a low-dimensional vector \(_{t}\). For this task, we use an improved version of the encoder of GMR-GMUS. The GMR-GMUS encoder runs a graph neural network over the graph representation to learn node representations. Then it takes node vectors of a selection of "pivotal" nodes and concatenates them to get \(_{t}\). In our new encoder, we select a set of locations in the spatial space instead of graph nodes to aggregate spatial information: each selected location aggregates vectors of nearby nodes to get its representation. It decouples the graph representation and the aggregation operation so that a select location can encode nodes within an arbitrary distance. To improve the training stability, we also improve the graph neural network'sarchitecture by adding residual connections between its message-passing layers. We call this new encoder Position-based Graph Mesh Reducer (PbGMR). These two modifications clearly improve the encoder's ability to preserve the state information, which will be empirically shown in the experiment section.

The architecture of PbGMR is specified as follows. For notational convenience, we omit the time from the subscript. For each graph node \(i V\), we first extract node and edge features as follows.

\[_{i}^{0}=_{v}(_{i}),_{ij}^{0}=_ {e}((i)-(j)). \]

Here \((i)\) is the spatial location of the cell center of \(C_{i}\). After that, we apply \(L\) message-passing layers.

\[_{ij}^{} =_{ij}^{-1}+(_{}^{e} (_{ij}^{-1},_{i}^{-1},_{j}^{-1})) \] \[_{i}^{} =_{i}^{-1}+(_{} ^{v}(_{i}^{-1},_{j_{i}}_{ij}^{-1} )),=1,,L. \]

Here \(_{i}\) denotes all neighbors of node \(i\), \(_{}^{e}\) and \(_{}^{v}\) are two separate multi-layer perceptrons, and \(\) is the layer-normalization operation. When a perceptron accepts multiple arguments, its arguments are first concatenated into a single vector. Each layer here is similar to a GraphNet block  but with slight differences. The prominent ones are residual connections and layer normalization in the update of node and edge representations: they help to stabilize the training procedure .

After we have learned node representations, we need to aggregate them into a single vector to represent the entire state. We randomly select a small set \(\) of centers in the spatial area. For each center \(c\), we select \(k\) nearest mesh cells \((c)\) based on spatial distance and then compute the position representation \(_{c}\) by interpolation :

\[_{c}=_{j(c)}_{j}^{L}}{_{j (c)}w_{cj}}, w_{cj}=},,c \]

Here \(d(c,j)\) is the spatial distance between cell \(C_{j}\) and the center \(c\). Given that the calculation is scaled by the sum of \(w_{cj}\)-s, the unit of the spatial distance does not change the calculation here. The number \(k\) of neighbors is a hyper-parameter, and we fix it to 10. Finally, we concatenate all representations of centers into a single vector \(=(_{c}:c)\) as the latent for the entire graph. Note that the centers in \(\) are fixed for a problem.

As a comparison, the encoder in GMR-GMUS uses graph nodes as centers and only considers connected neighbors of a center. Then the number of neighbors in the interpolation operation is

Figure 1: The diagram of the proposed model, which first compresses the whole graph into the latent representation \(_{t}\) by PbGMR using selected positions. During the generation process, a transformer encodes physical parameters and previous latent representations into a condition vector \(_{t+1}\), from which a normalizing flow model describes the conditional probability of \(_{t+1}\). Finally, the decoder PbGMUS decodes \(_{t+1}\) through to obtain the next-step prediction \(_{t+1}\).

limited by the graph structure. As a result, each center vector from GMR-GMUS can only represent information in a short range. Our new encoder overcomes this issue by decoupling the neighbors in interpolation and the neighbors in the graph representation and then gives the interpolation operation more freedom to represent a state of the system.

### Decoding and self-supervised training

We devise a decoder PbMUS to recover node features on the graph from latent representation \(\): \(}=()\). Here we also consider the computation at a single time step and omit time indices. We first split \(\) and get vectors at interpolation centers: \((_{}:c)=\) and then compute the initial node representation \(_{i}^{0}\) by spatial interpolation from centers:

\[_{i}^{0}=_{j^{}(i)}_{c}}{ _{c^{}(i)}w_{ic}}, w_{ic}=},,i,c \]

Here \(^{}(i)\) are \(k\) centers that are nearest to the cell center \(i\). Then we apply \(L\) message-passing layers to compute \(}=(G,(_{i}^{0}:i V))\), with \(\) representing the \(L\) network layers. These layers have the same architecture as PbGMR but use different learnable parameters.

Self-supervised training.Without considering the sequential property of the data, we first train the encoder and decoder on single steps with self-supervised training. This training method shares the same spirit of regeneration learning and improves encoder and decoder's abilities to capture spatial patterns in the data. In particular, we use the reconstruction error as the minimization objective to train the encoder-decoder pair.

\[\ \ _{t=0}^{T}||_{t}-((_{t}))|| _{2}^{2} \]

### Attention-based temporal conditioned generative model

Now we consider the sequence of latent representations from the encoder and devise a sequential generative model to model the sequence of latent representations. The low-dimensional latent space reduces the modeling difficulty, and the vector form of latent representations \(_{t}\) avoids the graph structure and allows more model choices. We first decompose the sequence as follows.

\[P(_{1:T}|,_{0})=p(_{1}|,_{0})_{t=2 }^{T}p(_{t}|,_{0},_{1:t-1}). \]

The key is to devise a model for the conditional \(p(_{t}|,_{0},_{1:t-1})\). We take two steps to construct this conditional: we first represent the condition \((,_{0},_{1:t-1})\) with a single vector \(_{t}\) and then adapt RealNVP , a normalizing flow model, to describe the conditional \(p(_{t}|_{t})\).

Calculate the conditional vector with a transformer.Because physical parameters \(\) control the entire system, and the initial condition \(_{0}\) contains information about the initial condition, we consider them special and use them in the prediction of \(_{t}\) for each \(t\). We structure the problem as a "translation" problem and use the transformer  to run the calculation. In our case, the input "sentence" is \((,_{0})\), the first few "tokens" in the target sentence are \((_{1},,_{t-1})\), and the "next token" to be predicted is \(_{t}\).

\[_{t}=((,_{0}),(_{1},, _{t-1})) \]

While the computation is exactly the same as one step in a translation task, the rationale is very different. First, the translation task directly gets the \(_{t}\) from the transformer, but our model needs to send \(_{t}\) to a conditional flow model to get the prediction \(_{t}\). Second, the translation task has an informative input sequence, but our model uses a less informative input and depends on the transformer to get a reasonable output sequence.

Predict \(z_{t}\) with a conditional flow model.Once we have a vector \(_{t}\) representation of the condition, we can construct a conditional flow model from RealMVP. Specifically, we append the condition vector \(_{t}\) to the input of the scaling function \(s\) and the bias function \(t\) in equation 3 in each layer.

\[f_{}()=[[1:d^{}],[d^{}+1:d](s([ 1:d^{}],_{t}))+t([1:d^{}],_{t})] \]

From these layers, we have the flow model \(p(_{t}|_{t})\). By chaining up the transformer and the conditional flow model, we have our sequential model for conditional probability \(p(_{t}|,_{0},_{1:t-1})\).

During training, we train the sequential model on \((_{0},,_{T})\) that are computed from our PbGMR encoder. During inference, we can efficiently sample \(_{t}\) from the sequential model. The whole training and inference processes can be found in Appendix A.2 and Appendix A.3.

## 4 Related Work

Deep learning for physics.For a deterministic system, one-step learning simply takes the current state as the input and outputs the next-step prediction . To further improve the accuracy of long-term forecasts, dimension reduction is applied together with sequence nets, aiming to solve long dynamical systems on a regular domain . Such works often adopt CNNs as encoders so that can not be applied to irregular mesh space. To further work on mesh data directly with dimension reduction, the GNN encoder/decoder was initially introduced by . Various GNN architectures were also proposed to facilitate the learning of physics. . For physical stochastic systems, CNN is mainly used for probabilistic prediction . However, it lacks researches solving stochastic system in the graph space.

Regeneration learning and generative modeling.Regeneration learning is a new learning paradigm for data generation, which first generates a latent representation for the data. Then the generation process happens on the latent space. There are many recently popular generative models for images, videos, speeches, and music  are built on this paradigm. We notice that it should be further investigated for graph generation tasks.

## 5 Experiments

### Deterministic dynamics

We benchmark our proposed model with three datasets from three flows: flows over the cylinder, high-speed flows over the moving edge, and vascular flows . Note that for test cases, we feed the model physical parameters \(\) and the snapshot at the beginning time to generate the whole trajectory. Detailed description can be found in Appendix A.5.

We compare our new method against five SOTA models for fluid dynamics, including two variants of MeshGraphNet and three variants of the GMR-GMUS. We use relative mean square error (RMSE) as the evaluation metric: \(=_{t}^{}-_{t}^{ })^{2}}{(_{t}^{})^{2}}\). More details can be found in the Appendix A.2. For cylinder and vascular flows, we calculate the RMSE with respect to velocity variables \(u\), \(v\), and the pressure variable \(p\). For high-speed flows over the moving edge, we also calculated the RMSE for the temperature \(T\).

The results on prediction errors.Table 2 shows the comparison of different models. Our model outperforms the baseline models in all the scenarios. For the cylinder flow case, our model has improvements of \(22\%\), \(17\%\), and \(47\%\) for \(u\), \(v\), and \(p\). For the sonic flow case, our model has improvements of \(61\%\), \(70\%\) for the \(u\) and \(v\) variables, and improvements of \(82\%\) and \(50\%\) respectively for the \(p\) and \(T\) variables. For the vascular flow case, our model achieves improvements of \(52\%\), \(45\%\), and \(95\%\) for \(u\), \(v\), and \(p\). The ablation

  Dataset & GMR-GMUS & PbGMR-GMUS \\  Cylinder flow & \(14.3\) & \(\) \\  Sonic flow & \(1.11\) & \(\) \\  Vascular flow & \(10\) & \(\) \\  

Table 1: The average relative reconstruction error of three systems, with the unit of \(1 10^{-3}\)study in the Appendix section (Table 9) indicates that both the new encoder and the conditional normalizing flow are essential to improve prediction accuracy.

The error in the time axis is shown in Figure 3. The performance of our model is shown with the solid black line. The model has small initial errors in all three tasks. Then its error accumulates over time, but the accumulation is much slower than that of competing models, so our model consistently has the lowest error in the final time step.

To better understand our model, we have also done an extensive ablation study reported in the appendix. Here we only show a comparison of our model with GMR-GMUS in the encoding-decoding tasks. The results in Table. 1 show that the new model has clearly better encoding and decoding capabilities. In one encoding and decoding case, the reconstruction error of our model is less than one fifth of that of the GMR-GMUS model in the appendix. The ablation study also shows that both residual connections and encoding centers enhance the encoding-decoding accuracy (please see Table 8 in the Appendix section).

Contour analysis.As a probabilistic model, we plotted the contour of the predicted sample and the standard deviation (std) for all three datasets. Figure 2 visualizes the velocity predictions from two datasets. In each subplot, the top row is one prediction (e.g. one sample from our model), and the bottom row visualizes the standard deviation of predictions. To clearly compare different predictions, we use the same color bar within the same dataset. With visual inspection, the sample predictions are reasonable and stable for all three datasets.

The standard deviations also show reasonable spatial-temporal patterns consistent with our expectations. For cylinder flow with \(Re=307\), the standard deviation is larger around the vortex-shedding region, indicating the model is less certain about the fast-changing dynamics. Moreover, the standard deviation tends to grow with time, reflecting the error accumulation behavior for long-time rollouts. Moreover, the standard deviation is smaller when \(Re\) is higher, indicating that the model is more certain about the prediction. The same trends can also be seen in other datasets. Therefore, our proposed model can accurately predict the dynamics for deterministic systems while providing a spatial-temporal uncertainty estimate, potentially improving the interpretability of deep learning systems. More contours can be found in Appendix A.6

### Stochastic dynamics

Dataset.We apply the proposed method to solve a stochastic dynamical system governed by the unsteady-state incompressible Navier-Stokes equations. We also compare our method to the unsteady Reynolds-averaged Navier-Stokes equations (URANS), the most applied method in the industry due to the balance of accuracy and computational efficiency. Let \(\) be the channel with a backward-facing

Figure 2: For each case, the first row is one of our predicted samples for velocity. The second row is the predicted standard deviation for velocity. Our model-predicted sample accurately reflects the physical systems. Meanwhile, the predicted standard deviation also has a physical spatial-temporal pattern.

[MISSING_PAGE_FAIL:8]

the multiscale problem in the time domain can be automatically learned. However, URANS directly calculate an ensemble average over infinite experiments, and it can not capture stochastic behavior. Therefore, the energy (\(E(k)\)) of high-wave-number (\(k\)) signals is underpredicted by URANS while the proposed model has a consistent energy spectrum pattern with the LES simulations. Moreover, the turbulent kinetic energy (TKE) is computed to evaluate the quality of generated samples. Physically, the TKE is characterized by measured root-mean-square velocity fluctuations. By applying the decoder, the point-wise instantaneous flow can be recovered from the latent vector to the physical solution reasonably well. The TKE metric can be defined as a scalar:

\[:=_{[0,T_{}]}[(u-)^{2}+(v- )^{2}]d dt}{_{}_{[0,T_{}]}[(u^{} -^{})^{2}+(v^{}-^{})^{2}]d dt}. \]

It indicates the preservation of the TKE benchmarked by the LES simulations. Our model can generate a flow field preserving \(99\%\) of the energy, whereas URANS can only do less than \(20\%\). As for the temporal mean field, although URANS aims to solve it directly, it is inevitable to introduce the bias from the LES result due to the ergodicity assumption of RANS. Instead, we directly formulate the probabilistic problem to learn the distribution of the spatiotemporal field. We calculate the error of the temporal mean field and find that although URANS leverages the conservation laws, it still obtains a much larger error than our generated samples. Finally, we further propose to measure the quality of predicted rollouts using evaluation metrics of video generation in computer vision. In particular, we consider two metrics: the continuous ranked probability score (CRPS) [48; 49] and Frechet Video Distance (FVD) . We use CRPS to assess the respective accuracy of our probabilistic forecasting and LES models. Since our model considers the distribution of the forecasts as a whole, it outperforms URANS, which only focuses on the mean of the distribution. Our model is also better evaluated in the FVD metric. This indicates the learned distribution by our model is close to the samples from LES.

We have also experimented with two deep learning methods, MeshGraphNet and GMR-GMUS, which are designed for deterministic systems. Their predictions are both far from LES simulations, not to mention that they can only make deterministic predictions. More results can be found in Appendix A.13.

## 6 Conclusion

We propose a new learning model to predict/generate deterministic and stochastic fluid dynamics over unstructured mesh in a uniform way. With an integration of a novel graph auto-encoder, a transformer, and a normalizing flow model, the new model decomposes temporal and spatial correlations in a dynamical system. It outperforms competitive baseline models for deterministic systems while providing a reasonable spatial-temporal pattern of forward uncertainty estimations. The samples

Figure 5: Evaluation lines: Inlet (), Outlet (), Wall (), \(x\)-evaluation lines ( - - ). Quantities from LES (), URANS (), and our model ()

from the model trained on stochastic systems capture the rich physical patterns of expensive LES simulations. The current model still has one limitation: it can not accurately model stochastic variables close to boundary areas, which is shown in Appendix A.12. In future work, we will design new learning architectures to overcome this issue.