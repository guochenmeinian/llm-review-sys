# Sequential Predictive Two-Sample and Independence Testing

Aleksandr Podkopaev

Walmart Global Tech

sasha.podkopaev@walmart.com &Aaditya Ramdas

Carnegie Mellon University

aramdas@cmu.edu

###### Abstract

We study the problems of sequential nonparametric two-sample and independence testing. Sequential tests process data online and allow using observed data to decide whether to stop and reject the null hypothesis or to collect more data, while maintaining type I error control. We build upon the principle of (nonparametric) testing by betting, where a gambler places bets on future observations and their wealth measures evidence against the null hypothesis. While recently developed kernel-based betting strategies often work well on simple distributions, selecting a suitable kernel for high-dimensional or structured data, such as images, is often nontrivial. To address this drawback, we design prediction-based betting strategies that rely on the following fact: if a sequentially updated predictor starts to consistently determine (a) which distribution an instance is drawn from, or (b) whether an instance is drawn from the joint distribution or the product of the marginal distributions (the latter produced by external randomization), it provides evidence against the two-sample or independence nulls respectively. We empirically demonstrate the superiority of our tests over kernel-based approaches under structured settings. Our tests can be applied beyond the case of independent and identically distributed data, remaining valid and powerful even when the data distribution drifts over time.

## 1 Introduction

We consider two closely-related problems of nonparametric two-sample and independence testing. In the former, given observations from two distributions \(P\) and \(Q\), the goal is to test the null hypothesis that the distributions are the same: \(H_{0}:P=Q\), against the alternative that they are not: \(H_{1}:P Q\). In the latter, given observations from some joint distribution \(P_{XY}\), the goal is to test the null hypothesis that the random variables are independent: \(H_{0}:P_{XY}=P_{X} P_{Y}\), against the alternative that they are not: \(H_{1}:P_{XY} P_{X} P_{Y}\). Kernel tests, such as kernel-MMD (Gretton et al., 2012) for two-sample and HSIC (Gretton et al., 2005) for independence testing, are amongst the most popular methods for solving these tasks which work well on data from simple distributions. However, their performance is sensitive to the choice of a kernel and respective parameters, like bandwidth, and applying such tests requires additional effort. Further, selecting kernels for structured data, like images, is a nontrivial task. Lastly, kernel tests suffer from decaying power in high dimensions (Ramdas et al., 2015).

Predictive two-sample and independence tests (2STs and ITs respectively) aim to address such limitations of kernelized approaches. The idea of using classifiers for two-sample testing dates back to Friedman (2004) who proposed using the output scores as a dimension reduction method. More recent works focused on the direct evaluation of a learned model for testing. In an initial arXiv 2016 preprint, Kim et al. (2021) proposed and analyzed predictive 2STs based on sample-splitting, namely testing whether the accuracy of a model trained on the first split of data and estimated on the second split is significantly better than chance. The authors established the consistency of asymptotic and exact tests in high-dimensional settings and provided rates for the case of Gaussiandistributions. Inspired by this work, Lopez-Paz and Oquab (2017) soon after demonstrated that empirically predictive 2STs often outperform state-of-the-art 2STs, such as kernel-MMD. Recently, Hediger et al. (2022) proposed a related test that utilizes out-of-bag predictions for bagging-based classifiers, such as random forests. To incorporate measures of model confidence, many authors have also explored using test statistics that are based on the output scores instead of the binary class predictions (Kim et al., 2019; Liu et al., 2020; Cheng and Cloninger, 2022; Kubler et al., 2022).

The focus of the above works is on _batch_ tests which are calibrated to have a fixed false positive rate (say, \(5\%\)) if the sample size is specified in advance. In contrast, we focus on the setting of sequentially released data. Our tests allow on-the-fly decision-making: an analyst can use observed data to decide whether to stop and reject the null or to collect more data, without inflating the false alarm rate.

**Problem Setup.** First, we define the problems of sequential two-sample and independence testing.

**Definition 1** (Sequential two-sample testing).: Suppose that we observe a stream of i.i.d. observations \(((Z_{t},W_{t}))_{t 1}\), where \(W_{t}(1/2)\), the distribution of \(Z_{t} W_{t}=+1\) is denoted \(P\), and that of \(Z_{t} W_{t}=-1\) is denoted \(Q\). The goal is to design a sequential test for

\[H_{0} :P=Q, \] \[H_{1} :P Q. \]

**Definition 2** (Sequential independence testing).: Suppose that we observe that a stream of observations: \(((X_{t},Y_{t}))_{t 1}\), where \((X_{t},Y_{t}) P_{XY}\) for \(t 1\). The goal is to design a sequential test for

\[H_{0} :(X_{t},Y_{t}) P_{XY}P_{XY}=P_{X} P_{Y}, \] \[H_{1} :(X_{t},Y_{t}) P_{XY}P_{XY} P_{X} P_{Y}. \]

We operate in the framework of "power-one tests" (Darling and Robbins, 1968) and define a level-\(\) sequential test as a mapping \(:_{t=1}^{}^{t}\{0,1\}\) that satisfies: \(_{H_{0}}( t 1:(Z_{1},,Z_{t})=1)\). We refer to such notion of type I error control as _time-uniform_. Here, \(0\) stands for "do not reject the null yet" and \(1\) stands for "reject the null and stop". Defining the stopping time as the first time that the test outputs \(1\): \(:=\{t 1:(Z_{1},,Z_{t})=1\}\), a sequential test must satisfy

\[_{H_{0}}(<). \]

We aim to design _consistent_ tests which are guaranteed to stop if the alternative happens to be true:

\[_{H_{1}}(<)=1. \]

**Related Works.** Our construction follows the principle of testing by betting (Shafer, 2021). The most closely related work is that of "nonparametric 2ST by betting" of Shekhar and Ramdas (2023), which later inspired several follow-up works, including sequential (marginal) kernelized independence tests of Podkopaev et al. (2023), and the sequential conditional independence tests under the model-X assumption of Grunwald et al. (2023) and Shaer et al. (2023). We extend the line of work of Shekhar and Ramdas (2023) and of Podkopaev et al. (2023), studying predictive approaches in detail.

Sequential predictive 2STs were studied by Lheritier and Cazals (2018, 2019), but in practice, those tests were found to be inferior to the ones developed by Shekhar and Ramdas (2023). Recently, Pandeva et al. (2022) proposed a predictive 2ST that handles unknown class proportions using ideas from (Wasserman et al., 2020). In Section 2, we show that our tests are closely related to (Lheritier and Cazals, 2018, 2019; Pandeva et al., 2022), but are consistent under much milder assumptions.

**Sequential Nonparametric Two-Sample and Independence Testing by Betting.** Suppose that one observes a sequence of random variables \((Z_{t})_{t 1}\), where \(Z_{t}\). The principle of testing by betting (Shafer and Vovk, 2019; Shafer, 2021) can be described as follows. A player starts the game with initial capital \(_{0}=1\). At round \(t\), she selects a payoff function \(f_{t}:[-1,)\) that satisfies \(_{Z P_{Z}}[f_{t}(Z)_{t-1}]=0\) for all \(P_{Z} H_{0}\), where \(_{t-1}=(Z_{1},,Z_{t-1})\) denotes the sigma-field generated by \(Z_{1},,Z_{t-1}\) with \(_{0}\) being the trivial sigma-field, and bets a fraction of her wealth \(_{t}_{t-1}\) for an \(_{t-1}\)-measurable \(_{t}\). Once \(Z_{t}\) is revealed, her wealth is updated as

\[_{t}=_{t-1}+_{t}_{t-1}f_{t}(Z_{t})= _{t-1}(1+_{t}f_{t}(Z_{t})). \]

The wealth is used to measure the evidence against \(H_{0}\): if a player can make money in such game, the null is rejected. Formally, for testing \(H_{0}\) at level \((0,1)\), we use the stopping rule:

\[=\{t 1:_{t} 1/\}. \]The validity of the test follows from Ville's inequality (Ville, 1939), a time-uniform generalization of Markov's inequality, since \((_{t})_{t 0}\) is a nonnegative martingale starting at 1 under any \(P_{Z} H_{0}\). To ensure high power, one has to choose \((f_{t})_{t 1}\) and \((_{t})_{t 1}\) to guarantee the growth of the wealth if the alternative is true. In the context of two-sample and independence testing, Shekhar and Ramdas (2023) and Podkopaev et al. (2023) recently proposed effective betting strategies based on kernelized measures of statistical distance and dependence respectively which admit a variational representation. In a nutshell, datapoints observed prior to a given round are used to estimate the _witness_ function -- one that best highlights the discrepancy between \(P\) and \(Q\) for two-sample (or between \(P_{XY}\) and \(P_{X} P_{Y}\) for independence) testing -- and a bet is formed as an estimator of a chosen measure of distance (or dependence). In contrast, our bets are based on evaluating the performance of a sequentially learned predictor that distinguishes between instances from distributions of interest.

_Remark 1_.: In practical settings, an analyst may not be able to continue collecting data forever and may adaptively stop the experiment before the wealth exceeds \(1/\). In such case, one may use a different threshold for rejecting the null at a stopping time \(\), namely \(U/\), where \(U\) is a (stochastically larger than) uniform random variable on \(\) drawn independently from \((_{t})_{t 0}\). This choice strictly improves the power of the test without violating the validity; see (Ramdas and Manole, 2023).

**Contributions.** In Section 2, we develop sequential predictive two-sample and independence tests. We establish sufficient conditions for consistency of our tests and relate those to evaluation metrics of the underlying models. In Section 3, we conduct an extensive empirical study on synthetic and real data, justifying the superiority of our tests over the kernelized ones on structured data.

## 2 Classification-based Two-Sample Testing

We begin with the two-sample testing setting outlined in Definition 5. Let \(:[-1,1]\) denote a class of predictors used to distinguish between instances from \(P\) (labeled as \(+1\)) and \(Q\) (labeled as \(-1\))1. We assume that: (a) if \(g\), then \(-g\), (b) if \(g\) and \(s\), then \(sg\), and (c) predictions are based on \([g()]\), and if \(g(z)=0\), then \(z\) is assigned to the positive class. Two natural evaluation metrics of a predictor \(g\) include the misclassification and the squared risks:

\[R_{}(g):=(W[g(Z )]<0), R_{}(g):=[(g(Z)-W)^{2} ], \]

which give rise to the following measures of distance between \(P\) and \(Q\), namely

\[d_{}(P,Q):=_{g}(-R_{}(g )), d_{}(P,Q):=_{g}(1-R_{}(g)). \]

It is easy to check that \(d_{}(P,Q)[0,1/2]\) and \(d_{}(P,Q)\). The upper bounds hold due to the non-negativity of the risks and the lower bounds follow by considering \(g:g(z)=0, z\). Note that the misclassification risk is invariant to rescaling (\(R_{}(sg)=R_{}(g)\), \( s(0,1]\)), whereas the squared risk is not, and rescaling any \(g\) to optimize the squared risk provides better contrast between \(P\) and \(Q\). In the next result, whose proof is deferred to Appendix D.3, we present an important relationship between the squared risk of a rescaled predictor and its expected margin: \([W g(Z)]\).

**Proposition 1**.: _Fix an arbitrary predictor \(g\). The following claims hold2:_

1. _For the misclassification risk, we have that:_ \[_{s}(-R_{}(sg))=(-R_{}(g)) 0=([W [g(Z)]]) 0.\] (9)
2. _For the squared risk, we have that:_ \[_{s}(1-R_{}(sg))([W  g(Z)] 0)([W g(Z) ]}{[g^{2}(Z)]} 1)\] (10) _Further,_ \(d_{}(P,Q)>0\) _if and only if there exists_ \(g\) _such that_ \([W g(Z)]>0\)Consider an arbitrary predictor \(g\). Note that under the null \(H_{0}\) in (1a), the misclassification risk \(R_{}(g)\) does not depend on \(g\), being equal to 1/2, whereas the squared risk \(R_{}(g)\) does. In contrast, the lower bound (10) no longer depends on \(g\) under the null \(H_{0}\), being equal to 0.

**Oracle Test.** It is a known fact that the minimizer of either the misclassification or the squared risk is \(g^{}(z)=2(z)-1\), where \((z)=(W=+1 Z=z)\). Since \(g^{}\) may not belong to \(\), we consider \(g_{}\), which minimizes either the misclassification or the squared risk over predictors in \(\), and omit superscripts for brevity. To design payoff functions, we follow Proposition 1 and consider

\[f_{}^{}(Z_{t},W_{t}) =W_{t}[g_{}(Z_{t})]\{-1,1\}, \] \[f_{}^{}(Z_{t},W_{t}) =W_{t} g_{}(Z_{t})[-1,1]. \]

Let the _oracle_ wealth processes based on misclassification and squared risks \((_{t}^{,})_{t 0}\) and \((_{t}^{,})_{t 0}\) be defined by using the payoff functions (11a) and (11b) respectively, along with a predictable sequence of betting fractions \((_{t})_{t 1}\) selected via online Newton step (ONS) strategy (Hazan et al., 2007) (Algorithm 1), which has been studied in the context of coin-betting by Cutkosky and Orabona (2018). If a constant betting fraction is used throughout: \(_{t}=, t\), then

\[[_{t}^{i,}]= [(1+ f_{}^{i}(Z,W))], i\{,\}\,. \]

To illustrate the tightness of our results, we consider the optimal constant betting fractions which maximize the log-wealth (12) and are constrained to lie in \([-0.5,0.5]\), like ONS bets:

\[_{}^{i}=*{arg\,max}_{[-0.5,0.5]} [(1+ f_{}^{i}(Z,W))], i\{, \}\,. \]

```
Input: sequence of payoffs \((f_{t})_{t 1}\), \(_{1}^{}=0\), \(a_{0}=1\). for\(t=1,2,\)do  Observe \(f_{t}[-1,1]\);  Set \(z_{t}:=f_{t}/(1+_{t}^{}f_{t})\);  Set \(a_{t}:=a_{t-1}+z_{t}^{}\);  Set \(_{t+1}^{}:=(0(_{t}^{ }+}{a_{t}}))\);
```

**Algorithm 1** Online Newton step (ONS) strategy for selecting betting fractions

Assuming that the 2ST null is false and a predictor with non-trivial prediction risk is used, it is easy to see that the optimal constant betting fraction has to be positive, which is why in Algorithm 1 we truncate \(_{t}^{}\) at \(0\) instead of \(-1/2\) (the latter option is used in (Cutkosky and Orabona, 2018)). We note that this is allowed and does not affect any theoretical claims of the paper. In early simulations, we also did not observe any major differences between the two truncating options. We conclude with the following result for the oracle tests, whose proof is deferred to Appendix D.3.

**Theorem 1**.: _The following claims hold:_

1. _Suppose that_ \(H_{0}\) _in (_1a_) is true. Then the oracle sequential test based on either_ \((_{t}^{,})_{t 0}\) _or_ \((_{t}^{,})_{t 0}\) _ever stops with probability at most_ \(\)_:_ \(_{H_{0}}(<)\)_._
2. _Suppose that_ \(H_{1}\) _in (_1b_) is true. Then:_ 1. _The growth rate of the oracle wealth process_ \((_{t}^{,})_{t 0}\) _satisfies:_ \[_{t}(_{t}^{,} )}}{{}}(-R_{ }(g_{}))^{2}.\] (14) _If_ \(R_{}(g_{})<1/2\)_, then the test based on_ \((_{t}^{,})_{t 0}\) _is consistent:_ \(_{H_{1}}(<)=1\)_. Further, the optimal growth rate achieved by_ \(_{}^{}\) _in (_13_) satisfies:_ \[[(1+_{}^{}f_{}^{}(Z, W))]((-R_{}(g_{ }))^{2}(-R_{}(g_{})) ).\] (15) 2. _The growth rate of the oracle wealth process_ \((_{t}^{,})_{t 0}\) _satisfies:_ \[_{t}(_{t}^{,} )}}{{}} [W g_{}(Z)].\] (16)_If_ \([W g_{}(Z)]>0\)_, then the test based on_ \((_{,}^{})_{t 0}\) _is consistent:_ \(_{H_{1}}(<)=1\)_. Further, the optimal growth rate achieved by_ \(_{}^{}\) _in_ (13) _satisfies:_

\[[(1+_{}^{}f_{}^{}(Z,W) )][W g_{}(Z)]. \]

Theorem 1 precisely characterizes the properties of the oracle wealth processes and relates those to interpretable metrics of predictive performance. Further, the proof of Theorem 1 highlights a direct impact of the variance of the payoffs on the wealth growth rate, and hence the power of the resulting sequential tests (as the null is rejected once the wealth exceeds \(1/\)).

The second moment of the payoffs based on the misclassification risk (11a) is equal to one, resulting in a _slow_ growth: the bound (14) is proportional to _squared_ deviation of the misclassification risk from one half. The bound (15) shows that the growth rate with the ONS strategy matches, up to constants, that of the oracle betting fraction. Note that the second term in (15) characterizes the growth rate if \(R_{}(g_{})<5/16\) (low Bayes risk). In this regime, the growth rate of our test is at least \((3/16)(1/2-R_{}(g_{}))\) which is close to the optimal rate. The second moment of the payoffs based on the squared risk is more insightful. First, we present a result for the case when the oracle predictor \(g_{}\) in (11b) is replaced by an arbitrary \(g\). The proof is deferred to Appendix D.3.

**Corollary 1**.: _Consider an arbitrary \(g\) with nonnegative expected margin: \([W g(Z)] 0\). Then the growth rate of the corresponding wealth process \((_{}^{})_{t 0}\) satisfies:_

\[_{t}(_{t}^{}) }}{{}} _{s}(1-R_{}(sg ))[W g(Z)] \] \[([W g(Z)])^{2}, \]

_and the optimal growth rate achieved by \(_{}^{}\) in (13) satisfies:_

\[[(1+_{}^{}f^{}(Z,W))] (_{s}(1-R_{}(sg )))([W g(Z )]). \]

Corollary 1 states that for an arbitrary \(g\), the growth rate is lower bounded by the minimum of the expected margin and the (optimized) squared risk of such predictor. While the latter term is always smaller for the optimal \(g_{}\), this may not hold for an arbitrary \(g\). The lower bound (18b), which follows from Proposition 1, is always worse than that for \(g_{}\) (the expected margin is squared). The upper bound (19) shows that the growth rate with the ONS strategy matches, up to constants, that of the optimal constant betting fraction. Before presenting a practical sequential 2ST, we provide two important remarks that further contextualize the current work in the literature.

_Remark 2_.: In practice, we learn a predictor sequentially and have to choose a learning algorithm. Note that (18a) suggests that direct margin maximization may hurt the power of the resulting 2ST: the squared risk is sensitive to miscalibrated and overconfident predictors. Kubler et al. (2022) made a similar conjecture in the context of batch two-sample testing. To optimize the power, the authors suggested minimizing the cross-entropy or the squared loss and related such approach to maximizing the signal-to-noise ratio, a heuristic approach that was proposed earlier by Sutherland et al. (2017)3.

_Remark 3_.: Suppose that \(g^{}\) and consider the payoff function based on the squared risk (11b). At round \(t\), the wealth of a player \(_{t-1}\) is multiplied by

\[1+_{t} W_{t} g^{}(Z_{t}) =(1-_{t}) 1+_{t}(1+W_{t} g^{ }(Z_{t})) \] \[=(1-_{t}) 1+_{t}) )^{1\{W_{t}=1\}}(1-(Z_{t}))^{1\{W_{t}=-1 \}}}{()^{1\{W_{t}=1\}}( {2})^{1\{W_{t}=-1\}}},\]

and hence, the betting fractions interpolate between the regimes of not betting and betting using a likelihood ratio. From this standpoint, 2STs of Lheritier and Cazals (2018, 2019), Pandeva et al. (2022) set \(_{t}=1\), \( t\), and use only the second term for updating the wealth despite the fact that the true likelihood ratio is unknown. An argument about the consistency of such test hence requires imposing strong assumptions about a sequence of predictors \((g_{t})_{t 1}\)(Lheritier and Cazals, 2018, 2019). Our test differs in a critical way: we use a sequence of betting fractions, \((_{t})_{t 1}\), which adapts to the quality of the underlying predictors, yielding a consistent test under much weaker assumptions.

**Example 1**.: Consider \(P=(0,1)\) and \(Q=(,1)\) for 20 values of \(\), equally spaced in \([0,0.5]\). For a given \(\), the Bayes-optimal predictor is

\[g^{}(z)=[-1,1], \]

where \((z;,^{2})\) denotes the density of \((,^{2})\) evaluated at \(z\). In Figure 0(a), we compare tests that use (a) the Bayes-optimal predictor, (b) a predictor constructed with the plug-in estimates of the means and variances. While in the former case betting using a likelihood ratio (\(_{t}=1\), \( t\)) is indeed optimal, our test with an adaptive sequence \((_{t})_{t 1}\) is superior when a predictor is learned. The difference becomes even more drastic in Figure 0(b) where a (regularized) \(k\)-NN predictor is used.

**Sequential Classification-based 2ST (Seq-C-2ST).** Let \(_{}:(_{t 1}(\{-1,+1\})^{t}) \) denote a learning algorithm which maps a training dataset of any size and previously used classifier, to an updated predictor. For example, \(_{}\) may apply a single gradient descent step using the most recent observation to update a model. We start with \(_{0}=\) and \(g_{1}:g_{1}(z)=0\), for any \(z\). At round \(t\), we use one of the payoffs:

\[f_{t}^{}(Z_{t},W_{t}) =W_{t}[g_{t}(Z_{t})]\{-1,1\}, \] \[f_{t}^{}(Z_{t},W_{t}) =W_{t} g_{t}(Z_{t})[-1,1]. \]

After \((Z_{t},W_{t})\) is used for betting, we update a training dataset: \(_{t}=_{t-1}\{(Z_{t},W_{t})\}\), and an existing predictor: \(g_{t+1}=_{}(_{t},g_{t})\). We summarize our sequential classification-based 2ST (Seq-C-2ST) in Algorithm 2. We note that using pre-trained models (e.g., for image data) as initialization may definitely improve the performance during the early stages of testing in practice.

```
Input: level \((0,1)\), data stream \(((Z_{t},W_{t}))_{t 1}\), \(g_{1}(z) 0\), \(_{}\), \(_{0}=\), \(_{1}^{}=0\). for\(t=1,2,\)do  Evaluate the payoff \(f_{t}^{}(Z_{t},W_{t})\) as in (22a);  Using \(_{t}^{}\), update the wealth process \(_{t}^{}\) as per (5); if\(_{t}^{} 1/\)then  Reject \(H_{0}\) and stop; else  Update the training dataset: \(_{t}:=_{t-1}\{(Z_{t},W_{t})\}\);  Update predictor: \(g_{t+1}=_{}(_{t},g_{t})\);  Compute \(_{t+1}^{}\) (Algorithm 1) using \(f_{t}^{}(Z_{t},W_{t})\);
```

**Algorithm 2** Sequential classification-based 2ST (Seq-C-2ST)

While we do not need any assumptions to confirm the type I error control, we place some mild assumptions on the learning algorithm \(_{}\) to argue about the consistency.

Figure 1: Comparison between our 2ST with adaptive betting fractions and the likelihood ratio test for Example 1. While the likelihood ratio test is better if the Bayes-optimal predictor is used, our test is superior if a predictor is learned. The results are aggregated over 500 runs for each value of \(\).

**Assumption 1** (\(R_{}\)-learnability).: Suppose that \(H_{1}\) in (1b) is true. An algorithm \(_{}\) is such that the resulting sequence \((g_{t})_{t 1}\) satisfies: \(_{t}_{i=1}^{t}1\{W_{i} [g_{i}(Z_{i})]<0\}}{<}1/2\).

**Assumption 2** (\(R_{}\)-learnability).: Suppose that \(H_{1}\) in (1b) is true. An algorithm \(_{}\) is such that the resulting sequence \((g_{t})_{t 1}\) satisfies: \(_{t}_{i=1}^{t}(g_{i}(Z_{i})-W_{i} )^{2}}{<}1\).

In words, the above assumptions state that a sequence of predictors \((g_{t})_{t 1}\) is better than a chance predictor on average. We conclude with the following result, whose proof is deferred to Appendix D.3.

**Theorem 2**.: _The following claims hold for Seq-C-2ST (Algorithm 2):_

1. _If_ \(H_{0}\) _in (_1a_) is true, the test ever stops with probability at most_ \(\)_:_ \(_{H_{0}}(<)\)_._
2. _Suppose that_ \(H_{1}\) _in (_1b_) is true. Then:_ 1. _Under Assumption_ 1_, the test with the payoff (_22a_) is consistent:_ \(_{H_{1}}(<)=1\)_._ 2. _Under Assumption_ 2_, the test with the payoff (_22b_) is consistent:_ \(_{H_{1}}(<)=1\)_._

_Remark 4_.: Suppose that we perform two-sample testing for \(d\)-dimensional data. At time \(T\), the total accumulated computation for the kernelized test of Shekhar and Ramdas (2023) is \(O(dT^{2})\). For our test, the answer depends on the chosen classifier and learning algorithm. Using logistic regression in combination with gradient descent for updating model parameters results in cheap updates and payoff evaluation (both are \(O(d)\) at each round, and hence the total accumulated computation at time \(T\) is \(O(dT)\)). For \(k\)-NN classifier, no parameters have to be updated, yet evaluating payoffs becomes more expensive with a growing sample size, resulting in the total accumulated computation of \(O(kdT^{2})\) at time \(T\). For more complex models like neural nets, runtime depends on the chosen architecture: the total accumulated computation at time \(T\) is \(O((cB+F)T)\), where \(F\) and \(B\) are the costs of forward-propagation and back-propagation steps respectively and \(c\) is the number of back-propagation steps applied after processing the next point (the exact cost depends on the architecture).

**Sequential Classification-based Independence Test (Seq-C-IT).** Under the setting of Definition 2, a single point from \(P_{XY}\) is revealed at each round. Following (Podkopaev et al., 2023), we bet on two points from \(P_{XY}\) (labeled as \(+1\)) and utilize external randomization to produce instances from \(P_{X} P_{Y}\) (labeled as \(-1\)). Let \(_{}^{}:(_{t 1}(( )\{-1,+1\})^{t})\) denote a learning algorithm which maps a training dataset of any size and previously used classifier, to an updated predictor. We start with \(_{0}=\) and \(g_{1}:g_{1}(x,y)=0\), \((x,y)\). We use derandomized versions of the payoffs (22), e.g., instead of (22b), we use

\[ f_{t}^{}((X_{2t-1},Y_{2t-1}),(X_{2t},Y_{2 t}))&=(g_{t}(X_{2t-1},Y_{2t-1})+g_{t}(X_{2t},Y_{2t}) )\\ &-(g_{t}(X_{2t-1},Y_{2t})+g_{t}(X_{2t},Y_{2t-1}) ). \]

After \((X_{2t-1},Y_{2t-1}),(X_{2t},Y_{2t})\) have been used for betting, we update a training dataset:

\[_{t}=_{t-1}\{((X_{2t-1},Y_{2t-1}),+1),((X_{2t}, Y_{2t}),+1),((X_{2t-1},Y_{2t}),-1),((X_{2t},Y_{2t-1}),-1)\},\]

and an existing predictor: \(g_{t+1}=_{}^{}(_{t},g_{t})\). Seq-C-IT inherits the time-uniform type I error control and the consistency guarantees of Theorem 2, and we omit details for brevity.

## 3 Experiments

**Synthetic Experiments.** In our evaluation, we first consider synthetic datasets where the complexity of the independence testing setup is characterized by a single univariate parameter. We set the monitoring horizon to \(T=5000\) points from \(P_{XY}\), and for each parameter value, we aggregate the results over 200 runs. In particular, we use the following synthetic settings:

1. _Spherical model._ Let \((U_{t})_{t 1}\) be a sequence of random vectors on a unit sphere in \(^{d}\): \(U_{t}}{}(^{d})\), and let \(u_{(i)}\) denote the \(i\)-th coordinate of \(u\). For \(t 1\), we take \[(X_{t},Y_{t})=((U_{t})_{(1)},(U_{t})_{(2)}).\] We consider \(d\{3,,10\}\), where larger \(d\) defines a harder setup.

2. _Hard-to-detect-dependence (HTDD) model._ We sample \(((X_{t},Y_{t}))_{t 1}\) from \[p(x,y)=}(1+(wx)(wy)) 1\{(x,y) [-,]^{2}\}.\] (24) We consider \(w\{0,,6\}\), where \(H_{0}\) is true (random variables are independent) if and only if \(w=0\). For \(w>0\), \((X,Y) 1/w^{2}\), and the setup is harder for larger \(w\).

For the comparison, we use two predictive models to construct Seq-C-ITs:

1. Let \(_{t}(z):=(z,_{t-1},k_{t})\) define the set of \(k_{t}\) closest points in \(_{t-1}\) to a query point \(z:=(x,y)\). We consider a _regularized_\(k\)-NN predictor: \(_{t}(z)=+1}_{(Z,W)_{t}(z)}W\). We select the number of neighbors using the square-root rule: \(k_{t}=_{t-1}|}=\).
2. We use a multilayer perceptron (MLP) with three hidden layers and 128, 64 and 32 neurons respectively and the parameters learned using an incremental training scheme.

We use the HSIC-based sequential kernelized independence test (SKIT) [Podkopaev et al., 2023] as a reference test and defer details, such as MLP training scheme and SKIT hyperparameters, to Appendix E.1. In Figure 2, we observe that SKIT outperforms Seq-C-ITs under the spherical model (with no localized dependence structure), whereas, under the structured HTDD model, Seq-C-ITs, is superior. Further, inspecting Figure 1(b) at \(w=0\) confirms that all tests control the type I error. We refer the reader to Appendix E.2 for additional experiments on synthetic data with localized dependence where Seq-C-ITs are superior. In Appendix E.2, we also provide the results for the average _stopping times_ of our tests: we empirically confirm that our tests are adaptive to the complexity of a problem at hand: they stop earlier on easy tasks and later on harder ones.

**Real Data Experiments.** First, we compare sequential classification-based and kernelized 2STs using Karolinska Directed Emotional Faces dataset (KDEF) [Lundqvist et al., 1998] which contains images of actors and actresses expressing different emotions: afraid (AF), angry (AN), disgusted (DI), happy (HA), neutral (HE), sad (SA), and surprised (SU). Following earlier works [Lopez-Paz and Oquab, 2017, Jitkrittum et al., 2016], we focus on straight profile only and assign HA, NE, SU emotions to the positive class (instances from \(P\)), and AF, AN, DI emotions to the negative class (instances from \(Q\)); see Figure 2(a). We remove corrupted images and obtain a dataset containing 802 images with six different emotions. The original images (\(562 762\) pixels) are cropped to exclude the background, resized to \(64 64\) pixels and converted to grayscale.

For Seq-C-2ST, we use a small CNN as an underlying model and defer details about the architecture and training to Appendix E.1. As a reference kernel-based 2ST, we use the sequential MMD test of Shekhar and Ramdas  and adapt it to the setting where at each round either an observation from \(P\) or that from \(Q\) is revealed; see Appendix E.1 for details. We omit the comparison to Lheritier and Cazals  since their test has been shown to be inferior to the one developed by Shekhar and Ramdas . In Figure 2(b), we illustrate that while both tests achieve perfect power after processing sufficiently many observations, our Seq-C-2ST requires fewer observations to do so.

Figure 2: Power of different sequential independence tests on synthetic data from Section 3. Under the spherical model (no localized dependence), SKIT is better than Seq-C-ITs. Under the (structured) HTDD model, SKIT is inferior to sequential predictive independence tests.

Next, we compare two independence tests using MNIST image dataset (LeCun et al., 1998). To simulate the null setting, we sample pairs of random images from the entire dataset, and to simulate the alternative, we sample pairs of random images depicting the same digit (Figure 3(a)). For Seq-C-IT, we use MLP with the same architecture as for simulations on synthetic data. For SKIT, we use the median heuristic with 20 points from \(P_{XY}\) to compute kernel hyperparameters. In Figure 3(b), we show that while both tests control the type I error under \(H_{0}\), SKIT is inferior to Seq-C-IT under \(H_{1}\), requiring twice as much data to achieve perfect power.

## 4 Conclusion

While kernel methods are state-of-the-art for nonparametric two-sample and independence testing, their performance often deteriorates on complex data, e.g., high-dimensional data with localized dependence. In such settings, prediction-based tests are often much more effective. In this work, we developed sequential predictive two-sample and independence tests following the principle of testing by betting. Our tests control the type I error despite continuously monitoring the data and are consistent under weak and tractable assumptions. Further, our tests provably adapt to the complexity of a problem at hand: they stop earlier on easy tasks and later on harder ones. An additional advantage of our tests is that an analyst may modify the design choices, e.g., model architecture, on-the-fly. Through experiments on synthetic and real data, we confirm that our tests are competitive to kernel-based ones overall and outperform those under structured settings.

Figure 4: (a) Instances from the \(P_{XY}\) (top row) and \(P_{X} P_{Y}\) (bottom row) for MNIST dataset. (b) While both independence tests control the type I error under \(H_{0}\), Seq-C-IT outperforms SKIT under \(H_{1}\), rejecting the null much sooner. The results are aggregated over 200 runs.

Figure 3: (a) Examples of instances from \(P\) (top row) and \(Q\) (bottom row) for KDEF dataset. (b) Rejection rates for our test (Seq-C-2ST) and the sequential kernelized 2ST. While both tests achieve perfect power with enough data, our test is superior to the kernelized approach, requiring fewer observations to do so. The results are averaged over 200 random orderings of the data.

We refer the reader to the Appendix for additional results that were not included in the main paper:

1. In Appendix A, we complement classification-based ITs with a regression-based approach. Regression-based ITs represent an alternative to the classification-based approach in settings where a data stream \(((X_{t},Y_{t}))_{t 1}\) may be processed directly as feature-response pairs.
2. In Section 2, we considered the case of balanced classes, meaning that at each round, an instance from either \(P\) or \(Q\) is observed with equal chance. In Appendix B, we extend the methodology to a more general case of two-sample testing with unknown class proportions.
3. Batch two-sample and independence tests rely on either a cutoff computed using the asymptotic null distribution of a chosen test statistic (when it is tractable) or a permutation p-value, and if the distribution drifts, both approaches fail to provide the type I error control. In contrast, Seq-C-2ST and Seq-C-IT remain valid beyond the i.i.d. setting by construction (analogous to tests developed by Shekhar and Ramdas (2023), Podkopaev et al. (2023)), and we refer the reader to Appendix C for more details.

Acknowledgements.The authors thank Ian Waudby-Smith and Tudor Manole for fruitful discussions. AR acknowledges support from NSF grants IIS-2229881 and DMS-2310718.