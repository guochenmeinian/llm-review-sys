# NVRC: Neural Video Representation Compression

Ho Man Kwan\(\), Ge Gao\(\), Fan Zhang\(\), Andrew Gower\(\), David Bull\(\)

\(\) Visual Information Lab, University of Bristol, UK

\(\) Immersive Content & Comms Research, BT, UK

{hn.kwan, ge1.gao, fan.zhang, dave.bull}@bristol.ac.uk,

andrew.p.gower@bt.com

###### Abstract

Recent advances in implicit neural representation (INR)-based video coding have demonstrated its potential to compete with both conventional and other learning-based approaches. With INR methods, a neural network is trained to overfit a video sequence, with its parameters compressed to obtain a compact representation of the video content. However, although promising results have been achieved, the best INR-based methods are still out-performed by the latest standard codecs, such as VVC VTM, partially due to the simple model compression techniques employed. In this paper, rather than focusing on representation architectures, which is a common focus in many existing works, we propose a novel INR-based video compression framework, Neural Video Representation Compression (NVRC)1, targeting compression of the representation. Based on its novel quantization and entropy coding approaches, NVRC is the first framework capable of optimizing an INR-based video representation in a fully end-to-end manner for the rate-distortion trade-off. To further minimize the additional bitrate overhead introduced by the entropy models, NVRC also compresses all the network, quantization and entropy model parameters hierarchically. Our experiments show that NVRC outperforms many conventional and learning-based benchmark codecs, with a 23% average coding gain over VVC VTM (Random Access) on the UVG dataset, measured in PSNR. As far as we are aware, this is the first time an INR-based video codec achieving such performance.

## 1 Introduction

In recent years, learning-based video compression  has demonstrated its significant potential to compete with conventional video coding standards, with some recent contributions (e.g., DCVC-DC ) reported to outperform the latest MPEG standard codec, VVC VTM . However, learning-based codecs are typically associated with high computational complexity, in particular at the decoder, which therefore limits their practical deployment. To address this, a new type of learned video codec has been proposed, based on implicit neural representation (INR) models , where each INR instance is overfitted and compressed to represent a video sequence (or a video dataset). INR-based codecs enable much faster decoding speed compared to most non-INR learning based coding methods, and do not require offline optimization due to its overfitting nature. Although they have shown promise, INR-based codecs are yet to compete with state-of-the-art conventional and learned video coding methods in terms of rate-distortion performance.

To enhance coding performance, it is noted that most recent INR-based video coding methods  focus on improving network architectures but still perform simply model pruning, quantization and entropy coding to obtain compact representations. Moreover, these methods are not fully end-to-end optimized; for example, NeRV  and HiNeRV  are not trained with a rate-distortionobjective but only perform fine-tuning with pruning and quantization applied. Although COOL-CHIC  and C3  are almost end-to-end optimized, the rate consumed by their entropy model and decoder/synthesis networks does not contribute to the training process. In contrast, state-of-the-art non-INR learning-based codecs [34; 35] are typically end-to-end trained with advanced entropy models, and this contributes to their improved coding performance compared to INR-based methods.

To address this issue, this paper proposes a new framework, referred to as Neural Video Representation Compression (NVRC). Unlike other INR-based video codecs, NVRC is an enhanced framework for compressing neural representations, which, for the first time, enables INR-based coding methods to be fully end-to-end optimized with advanced entropy models. In particular, NVRC groups network parameters and quantizes them with per-group learned quantization parameters. The feature grids are then encoded by a context-based entropy model, where the network layer parameters are compressed by a dual-axis conditional Gaussian model. The quantization and entropy model parameters are further compressed by a lightweight entropy model to reduce their bit rate consumption. The overall rate of the parameters from the INR, quantization, and entropy models is optimized together with the representation quality. NVRC also utilizes a refined training procedure, where the rate and distortion objectives are optimized alternatively to reduce the computational cost. The primary contributions of this work are summarized below.

1. The proposed NVRC is **the first fully end-to-end optimized INR-based framework** for video compression. In NVRC, neural representations, as well as quantization and entropy models, are optimized simultaneously based on a rate-distortion objective.
2. **Enhanced quantization and entropy models** have been applied to encode neural representation parameters, where the context and side information have been utilized to achieve higher coding efficiency.
3. A new **parameter coding method based on a hierarchical structure** has been introduced which allows NVRC to minimize the rate overhead. The parameters from quantization and entropy models for encoding the neural representation, are all quantized and coded with learnable parameters.
4. NVRC features an **enhanced training pipeline**, where the rate and distortion losses are optimized alternatively, to reduce the computational cost of advanced entropy models.

We conducted experiments to compare the proposed approach with state-of-the-art conventional and learning-based video codecs on the UVG , MCL-JCV  and JVET-CTC Class B  datasets. To enable a fair comparison, we use both the RGB444 (like most learned video codecs) and YUV420 (like standard video coding methods) configurations. The results demonstrate the effectiveness of NVRC, which achieved up to 23% and 50% BD-rate savings when compared to the latest MPEG standard codec, H.266/VVC VTM-20.0 (Random Access) , and the state-of-the-art INR-based codec, HiNeRV , respectively. To our best knowledge, NVRC is the **first INR-based video codec outperforming VVC VTM** with such significant coding gains.

## 2 Related work

### Learning-based video compression

Video compression is an important research topic that underpins the development of many video-related applications, such as video streaming, video conferencing, surveillance, and gaming. In

Figure 1: Comparison between the output from HiNeRV  and the proposed NVRC. The image is from UVG dataset (Jockey/ReadySetGo sequence) 

the past three decades, multiple generations of video coding standards [60; 56; 10] have evolved by integrating advanced coding techniques. Recently, learning-based video compression emerged as an popular alternative due to its strong expressive power and the ability to be optimized in a data- and metric-driven manner. Neural networks can be combined with conventional codecs for performance enhancement [42; 64] or used to build end-to-end optimized frameworks. DVC  first proposed to replace all modules in conventional codecs using neural networks. Follow-up innovations include those improving motion estimation [38; 2; 26; 36], applying feature space conditional coding [27; 34], optimizing context modeling in terms of performance and efficiency [23; 22; 68], and adopting novel architectures such as normalizing flows , transformers [61; 44], _etc_. In addition to these architecture modifications, improvements to quantization-involved optimization have also been achieved to handle the non-differentiability caused by hard thresholding operations [29; 3; 19]. Moreover, several studies [17; 51; 28; 41; 39] have validated the effectiveness of adapting a model to an individual image of a video sequence via iterative refinement to reduce the amortization gap [63; 58] and optimize bit allocation over a sequence of frames . Despite demonstrating impressive rate-distortion performance, with some recent advancements reporting outperformance of VVC , neural video codecs are generally too computationally intensive , thus limiting their adoption in practical applications.

### INR-based video compression

Implicit neural representation (INR)  is an emerging paradigm for representing multimedia data, such as audios , images [14; 54], videos , and 3D scenes [46; 49]. This type of method exploits the mapping from the coordinate inputs to a high-dimensional feature space and aims to output the corresponding target data value at that location. Neural representation for videos (NeRV)  has been proposed to model the mapping from frame indices to video frames, showing competitive reconstruction performance with a very high decoding speed. When applied to video compression, the network parameters of these models are compressed through pruning, quantization, and entropy-penalization [20; 16; 18; 65] to achieve high coding efficiency. The following contributions further investigated patch-wise , volume-wise , or spatial-temporal disentangled representations  to improve representational flexibility. There are also methods that explicitly model the volume-wise residual , frame-wise residual , or flow-based motion compensation [66; 32; 21; 33], to enable scalable encoding and representation of longer and more diverse videos. In addition to these _index-based_ approaches, other work has exploited content-specific embeddings/feature grids to provide visual prior for the network. The embeddings may be associated with single  or multiple resolutions [32; 30; 29; 33]. Although they hold promise in terms of low decoding complexity and competitive performance, all these aforementioned INR-based video codecs are still outperformed by state-of-the-art conventional (e.g., VVC VTM ) and autoencoder-based [35; 36] video codecs.

## 3 Method

Figure 2 shows the proposed NVRC framework, which follows a workflow similar to existing INR-based video compression methods, such as [13; 30; 29], but with a more advanced model compression pipeline. It trains a neural representation for a given video(s) and utilizes model compression techniques to obtain the compact representation (with compressed network parameters) of the video(s). Specifically, in NVRC, for a target video sequence \(V^{gt}\) with \(T\) frames, height \(H\), width \(W\), and \(C\) channels, i.e., \(V^{gt}^{T H W C}\), a neural representation \(F\) parameterized by \(\) is trained to map coordinates to pixel intensities such as RGB colors, in a patch-wise manner. This can be represented by:

\[V_{patch}=F_{}(i,j,k), \]

where \(i,j,k\) is the patch coordinates. \(V_{patch}^{T_{patch} H_{patch} W_{patch} C_{patch}}\) is the corresponding video patch, in which \(0 i<}\), \(0 j<}\) and \(0 k<}\). This formulation (the same as in ) generalizes different frameworks: when \((T_{patch},H_{patch},W_{patch})=(1,1,1)\), the neural network maps coordinates to individual pixels ; when \((T_{patch},H_{patch},W_{patch})=(1,H,W)\), the network maps coordinates to video frames .

As mentioned in Section 1, existing INR-based video codecs either split the training of the INR model and model compression [13; 30], or train the model with compression techniques applied, but not entirely in an end-to-end manner [29; 33]. Unlike these works, NVRC employs more advanced entropy models and allows fully end-to-end optimization. Specifically, a neural representation \(F\) contains a set of learnable parameters \(\) including feature grids parameters (\(_{grid}\)) and network layer parameters (\(_{layer}\)). To quantize and encode these parameters, quantization and entropy models are employed with learnable compression parameters \(=\{_{quant},_{em}\}\). \(\) is determined by the distribution of the representation parameters \(\) in a fine-grained manner, e.g., per-group quantization scales, and can be considered as side information in compression . While these parameters do improve overall coding efficiency, the introduced overhead is not negligible, particularly when the compression ratio of the representation parameters is high. Therefore \(\) is also quantized in this work, denoted as \(=\{_{quant},_{em}\}\), and entropy coded. Here the quantization and entropy coding are performed based on another set of learnable parameters \(=\{_{quant},_{em}\}\), which can be simply quantized into full/half precision as \(=\{_{quant},_{em}\}\). This forms a hierarchical coding strategy for encoding these model and compression parameters \(\), \(\) and \(\), as illustrated in Figure 2.

All these parameters are optimized in a fully end-to-end manner based on a rate-distortion objective. Here the distortion metric \(D\), e.g., mean-square-error (MSE), is calculated between a reconstructed video patch, \(V_{patch}=F_{}(i,j,k)\), and the corresponding target video patch \(V_{patch}^{gt}\). The rate \(R\) is based on the number of bits consumed by the three levels of quantized parameters \(\), \(\), \(\).

### Feature grid coding

Although employing feature grids [12; 30; 29; 33; 31] for neural representations improves both convergence rate and reconstruction quality, these typically rely on a large number of parameters,

Figure 2: In NVRC, the parameters are encoded in a hierarchical structure, where (Middle-left) per-block quantization scales and (bottom-left) context-based model are utilized for encoding feature grids, and (Middle-right and bottom-right) per-axis quantization scales and dual-axis Gaussian model are applied for encoding network layer parameters.

which could potentially challenge model compression techniques. To address this issue, related works utilize multi-resolution grids to improve parameter efficiency and/or perform entropy coding for the feature grid compression [12; 32; 30; 29; 33; 31].

To improve feature grid encoding, in NVRC the parameters are first partitioned into small blocks, for which different quantization parameters are applied to improve the encoding efficiency. Context-based entropy models are utilized with parallel coding

**3D block partitioning.** For a feature grid \(z\) in \(_{grid}\), with \(z^{T_{grid} H_{grid} W_{grid} C_{grid}}\), it is divided into blocks with a size of \(T_{blk} H_{blk} W_{blk} C_{grid}\) (padding is applied if the grid size is not divisible) and produced \(}{T_{blk}}}{H_{blk}}}{W_ {blk}}\) blocks. For multi-scale grids [32; 30; 33; 29], the same block size is applied to partition the grids at each scale.

**Quantization.** With the partitioned blocks, a transformation is then applied before quantization. Here, the corresponding per-block quantization scales \(_{grid,blk}\) from \(_{quant}\) are utilized, where \(_{grid,blk}^{}{T_{blk}}} {H_{blk}}}{W_{blk}} C_{grid}}\) is learnable, and all the scales in \(_{grid,blk}\) are shared by features in the same channel and in the same block in \(z\). To achieve this, \(_{grid,blk}\) is first expanded to \(^{grid}\), which has the same shape as \(z\), and such that:

\[_{grid}[t,h,w,c]=_{grid,blk}[}, },},c], \]

where \(0 t<T_{grid}\), \(0 h<H_{grid}\), \(0 w<W_{grid}\) and \(0 c<C_{grid}\). In practice, the logarithm of \(_{grid,blk}\) is learned, instead of \(_{grid,blk}\), which ensures that the scales are non-negative. Following [16; 43; 29; 65; 31], the scaling and quantization can then be computed by:

\[^{s}= z^{s}=}, \]

in which \(z^{s}\) represent the scaled parameters, \(^{s}\) denote the quantized \(z^{s}\).

The corresponding unscaling operation is defined by:

\[=^{s}_{grid}, \]

to obtain the final quantized parameters \(\).

**Context-based entropy model.** Although entropy coding has been used for reducing the bit rate consumed by feature grids, many implementations are only based on simple entropy models and treat the grids as ordinary network parameters [12; 32; 30; 31]. A better solution is to exploit the spatial-temporal redundancy within the feature grids, due to the inter dependent nature of the features. COOL-CHIC  and C3  utilize context-based model and achieve efficient feature grid encoding; however, these methods are not associated with optimal rate distortion performance due to their low complexity constraints, and the use of grid entropy models for INR-based video compression has not been fully explored in the literature.

To enhance the efficiency of feature grid coding, NVRC employs context-based Gaussian models with auto-regressive style encoding and decoding processes  to exploit spatial-temporal redundancy within feature grids. While auto-regressive style coding is sequential, in NVRC, the feature grids at different resolutions are coded independently. Moreover, as mentioned above, each grid is partitioned into many small 3D blocks, which are also coded in parallel. Thus, the context model in NVRC has a high degree of parallelism, which enables fast coding despite of reduced amount of available context. The context-based model employs 3D masked convolution [57; 47], with parameters \(_{context}\) from \(_{em}\), which are applied to all blocks from the same feature grid, but are not shared between grids at different scales. The context model estimates the means \(_{grid}\) and scales \(_{grid}\) for the Gaussian distribution in a per-feature manner and uses a coder such as the arithmetic coder to code the parameters, i.e., \(^{s}\). Here, the estimated means \(_{grid}\) and scales \(_{grid}\) will also be scaled by the corresponding quantization scale \(_{grid}\) before applying for encoding and decoding.

### Network layer parameter coding

Unlike the feature grids in INR models, the network parameters, such as the weights in linear and convolutional layers, are difficult to compress as there is no spatial or temporal correlation between parameters. Existing works typically use simple entropy models for encoding these parameters [13; 30; 16; 43; 33; 65].

**2D block partitioning.** In the proposed NVRC framework, similar to feature grids, network layer parameters are also partitioned into groups prior to quantization and coding. Here we assume that the encoding of the parameters from the same input/output features/channels could benefit from sharing quantization and entropy coding parameters. For example, if an input feature/channel is zero, then the corresponding group of parameters are likely to be zeros as well. In NVRC, the quantization and entropy coding models for network parameters are designed based on this assumption, and aim to share the quantization and entropy models between parameters in the same row/column. Since there are parameters with different numbers of dimensions, e.g., 2D for linear layer weights and 4/5D for convolution weights, all layer parameters in NVRC are first reshaped into 2D tensors, where the parameters in a row correspond to the weight from the same output feature/channel, and the parameters in a column are the weights for the same input feature/channel. While existing works [13; 30] can be directly employed on partitioned parameter tensors by rows or columns, and applied per-row or per-column entropy parameters for coding, this may not be the best solution, because (i) the partitioning axis needs to be decided, (ii) the coding could benefit from sharing quantization and entropy parameters across both rows and columns. Therefore, in NVRC, the tensors are partitioned according to both axes at the same time, and the quantization and entropy parameters are learned in both axes and mixed during coding. We noticed that existing work has utilized quantization parameters on both input and output channels in different contexts . Here, entropy parameters are also utilized, and both the quantization and entropy parameters are further compressed.

**Quantization.** For the weights of a layer, \(_{layer}\), from \(_{layer}\), \(_{layer}^{C_{out} C_{in}}\), the quantization scales \(_{layer}^{C_{out} C_{in}}\), is combined by two vectors of scales \(_{layer,out}^{C_{out}}\) and \(_{layer,in}^{C_{in}}\), such that:

\[_{layer}[i,j]=_{layer,out}[i]_{layer,in}[j], \]

where \(0 i<C_{out}\) and \(0 j<C_{in}\). In practice, only the logarithms of \(_{layer,out}\) and \(_{layer,in}\) are stored, and quantization is performed similarly to the grid parameters (Section 3.1).

**Dual-axis conditional Gaussian model.** In NVRC, a dual-axis conditional Gaussian model is used for coding the network layer parameters. Similar to the quantization parameters mentioned above, the means \(_{layer}\) and the scales \(_{layer}\), are represented in two per-axis parameter vectors, i.e. \(_{layer,out}\), \(_{layer,in}\), \(_{layer,out}\) and \(_{layer,in}\), and they are both from \(_{em}\).

The combined means \(_{layer}\) and scales \(_{layer}\) are obtained by

\[_{layer}[i,j]=_{layer,out}[i]_{layer,in}[j]+_{layer,in}[j], \]

and

\[_{layer}[i,j]=_{layer,out}[i]_{layer,in}[j], \]

where \(0 i<C_{out},0 j<C_{in}\). Like the quantization parameters \(_{layer}\), only the per-axis means \(_{layer,out}\), \(_{layer,in}\), and the logarithms of the per-axis scales \(_{layer,out}\), \(_{layer,in}\) are stored. Finally, the means and scales here will also (as for feature grids) be scaled by \(_{layer}\), before being utilized for coding \(_{layer}\).

### Coding of entropy model parameters

Since our use of more advanced quantization and entropy models will introduce additional bit rate overhead, the quantization parameters \(_{quant}\) and entropy model parameters \(_{em}\) are also quantized into \(_{quant}\) and \(_{em}\) and entropy coded. Here the same (as for feature grids in Section 3.1) scaling and quantization operation is applied, in which a conditional Gaussian model is used, except that the quantization scales and the means/scales for the Gaussian distribution are learned in a per-tensor manner.

### Rate-distortion optimization

**Combined loss for NVRC.** In NVRC, the overall loss function is given below:

\[L=R+ D \]Here \(D\) stands for the distortion calculated between the reconstructed content and the original input. \(R\) is the total bitrate (bits/pixel) consumed by the quantized representation parameters \(\), quantized compression parameters \(\). Specifically

\[R=R_{inr}+R_{em}=(-_{n}^{|^{*}|}log_{ 2}(p_{}(^{*}[n]))-_{n}^{|^{*}|}log_{2}(p_{ }(^{*}[n]))) \]

By jointly optimizing different parameters with the combined rate-distortion loss, the trade-off between the rate and the reconstruction quality can be achieved.

**Alternating optimization.** In existing INR-based video representations and compression methods [13; 30], the distortion loss is minimized iteratively with sampling batches of frames, patches or pixels. To introduce the entropy regularization, this process has been extended [29; 65], where the rate loss is also calculated in each training step, similar to other learning-based video compression methods [40; 34]. However, in the INR-based video compression, the training is the process for over-fitting the network to a video sequence, in which the samples of each steps are from the same sequence, and the code, i.e., the INR model parameters, is the same set of parameters for all steps. Thus, it is not necessary to update the rate term in every step, especially when a significant amount of computation or memory is needed for this due to the use of entropy models. In NVRC, a more efficient training process is used, where the rate \(R\) and distortion \(D\) are optimized alternately. In every \(K+1\) steps, the \(D\) is minimized in the first \(K\) steps, and where \(R\) is minimized at the \(K+1\)-th step. Empirically, the rate loss is also scaled by \(K\) to keep the rate roughly the same. Note that, the quantization step is still applied on each step, and skipping the entropy model is only possible when the quantization parameters are separated from the entropy model.

**Two-stage training.** Similar to some existing works [13; 30; 29], NVRC is also trained in two stages.

In Stage 1, to optimize \(L\), the non-differentiable quantization operation needs to be emulated through a differentiable approximation during training. Recent work  has shown that a soft-rounding operation with an additive Kumaraswamy noise can be used to replace quantization for neural representation training. While in , this is applied only to feature grids, we extend this idea and apply it to both feature grids and network parameters in the first stage of training. Compared to , soft-rounding with higher temperature (0.5 to 0.3) is used in NVRC, as the original, low temperature (e.g. 0.3 to 0.1 in ) for both feature grids and network parameters will lead to training difficulty due to the large variance of the gradients.

In the second stage, instead of using soft-rounding, following [30; 31], Quant-Noise  is used to fine-tune the neural representation, as we empirically found that Quant-Noise remains stable with different hyper-parameter settings and is suitable for high quantization levels.

## 4 Experiment

### Experiment Configuration

**Evaluation database.** To evaluate the performance of the proposed NVRC framework, we conducted experiments on the UVG  and MCL-JCV  dataset. The UVG dataset includes 7 video sequences with 300/600 frames, while the MCL-JCV dataset consists of 30 video clips with 120-150 frames. All sequences are compressed at their original resolution in this experiment. We also provide the result of JVET-CTC dataset Class B  in the _Appendix_.

**Implementation details.** NVRC is a new framework focusing on INR model compression, which can be integrated with any typical INR-based models. To test its effectiveness, we employed one of the latest INR network architectures, HiNeRV , and integrated it into our NVRC framework. This INR model has been reported to provide competitive performance compared to many standard and end-to-end codecs for the video compression task. Minor adjustments have been made on top of HiNeRV in terms of the network structure and the training configuration (see _Appendix_ for details) - rate points are now obtained by both turning the scale of the neural representation and the \(\) value. The model is trained for 360 or 720 epochs in the first stage and 30 or 60 epochs in the second stage, depending on the UVG  and MCL-JCV  datasets, due to the differing lengths of the sequences.

**Benchmark methods.** Conventional codecs, x265  with the _veryslow_ configuration, HM-18.0  and VTM-20.0  with the Random Access configuration, are used for benchmarking, together with two recent learned video codecs, DCVC-HEM , DCVC-DC . Three state-of-the-art INR-based codecs, including the original HiNeRV , C3  and HNeRV-Boost  have also been included in this experiment. All results are produced by the open source implementations.

**Evaluation methods.** The evaluation was performed in the RGB color space (for comparing both conventional codecs and learning-based methods) with the BT.601 color conversion, and in the original YUV420 color space (for comparing both conventional methods and the learning-based methods that support this feature in their public implementations). PSNR (RGB/YUV 6:1:1) and MS-SSIM (RGB/Y) are used here to assess video quality, based on which Bjontegaard Delta Rate figures are calculated against each benchmark codec.

### Results and discussion

Figure 3-4 and Table 1-2 provide the results for the proposed NVRC model and the benchmark methods. It can be observed that when tested in the RGB 4:4:4 color space (as in many learning-based works), NVRC significantly outperforms the original HiNeRV model , with an average coding gain of 50.16%, measured by PSNR. Similar improvement has also been achieved against other INR-based methods including HNeRV-Boost  and C3 . Moreover, NVRC also offers better performance compared to latest MPEG standard codec VVC VTM (Random-Access)  on the UVG dataset , with a 23.4% average coding gain based on PSNR. To the best of our knowledge, it is the first INR-based video codec outperforming VTM. Compared to state-of-the-art learned video coding methods, NVRC also exhibits superior or comparable performance to DCVC-HEM  and

   Color Space & Metric & x265 (_veryslow_) & HM (_kat_) & VTM (_kat_) & DCVC-HEM & DCVC-DC & HNeRV & C3 & HNeRV-Boost \\   & PSNR & -73.74\% & -50.38\% & -23.42\% & -40.57\% & -31.20\% & -50.16\% & -66.86\% & -66.45\% \\  & MS-SSIM & -80.65\% & -67.38\% & -49.75\% & -6.97\% & -11.57\% & -44.27\% & -76.59\% & -78.01\% \\   & PSNR & -66.68\% & -42.50\% & -12.96\% & - & -33.98\% & - & - & - \\  & MS-SSIM & -59.38\% & -38.20\% & -15.04\% & - & -39.12\% & - & - & - \\   

Table 1: BD-rate results on the UVG dataset .

Figure 4: Average rate quality curves of various tested codecs on the MCL-JCV dataset .

Figure 3: Average rate quality curves of various tested codecs on the UVG dataset .

DCVC-DC  on the UVG  and MCL-JCV  datasets, respectively.. When evaluated in the YUV 4:2:0 color space, NVRC still offers superior performance as for RGB 4:4:4 color space, outperforming most benchmarked methods based on PSNR and MS-SSIM. It should be also noted that INR-based video codecs do not require offline training on large-scale datasets, whereas other learning-based methods do. Qualitative results are provided in Figure 1 in terms of visual comparison between the content reconstructed by NVRC and HiNeRV.

### Computational complexity

The complexity figures of NVRC with the UVG dataset  are provided in Table 3. When compared to the original HiNeRV , the proposed method (with HiNeRV as its INR network) is associated with increased computational complexity. However, the MACs figure is still significantly lower than that of other learning-based video codecs (e.g., DCVC-DC ), which allows faster decoding. It should be noted that the complexity figures shown here are obtained based on research source code that has not been optimized for latency. The actual latency of INR and entropy coding can be further reduced by (1) optimizing the implementation of the INR and entropy models, (2) performing lower precision computation, and (3) implementing parallel decoding between different resolution feature grids.

### Ablation study

To evaluate the contribution of the main components in NVRC, an ablation study was performed based on the UVG dataset , using the configurations in Section 4.1, but four rate points for each variant.

**Alternative entropy model settings.** We compared different combinations of entropy models for encoding feature grids \(_{grid}\) and network parameters \(_{layer}\): Context model + dual-axis conditional Gaussian model (Default setting in NRVC), (V1) Context model + per-tensor conditional Gaussian model, (V2) per-tensor conditional Gaussian model + dual-axis conditional Gaussian model, (V3) per-tensor conditional Gaussian model + per-tensor conditional Gaussian model.

**Hierarchical parameters coding.** In NVRC, the quantization parameters \(_{quant}\) and the entropy model parameters \(_{em}\) are also entropy coded. To verify this, we created another variant (V4) with \(_{quant}\) and \(_{em}\) not coded but stored in half-precision.

**Learned quantization steps.** We also compared the use of learned quantization steps \(_{quant}\) and \(_{quant}\) (Default setting in NRVC) and (V5), a new variant with fixed quantization steps for grids, where the log-step size is set to \(-4\).

Table 4 shows the ablation study results, in terms of the BD-rate values against the original NVRC. These figures confirmed the contribution of the tested components in the NVRC framework.

   Metric & NVRC & (V1) & (V2) & (V3) & (V4) & (V5) \\  PSNR & 0.00\% & 13.04\% & 11.06\% & 23.37\% & 30.84\% & 14.42\% \\ MS-SSIM & 0.00\% & 13.84\% & 10.24\% & 23.88\% & 30.07\% & 8.54\% \\   

Table 4: Ablation studies on the UVG dataset . Results are BD-rates.

   Rate point & Frame MACs/Enc FPS/Dec FPS & Model compression MACs/Enc time/Dec time \\ 
1-2 & 359.6G/6.4/21.0 & 25.2G/22.9s/37.0s \\
3-4 & 842.8G/3.6/15.1 & 50.4G/29.6s/44.8s \\
5-6 & 1929.0G/2.2/9.7 & 100.8G/43.4s/53.7s \\   

Table 3: Complexity results of NVRC with the UVG dataset . Encoding and decoding FPS are measured by the number of training steps/evaluation steps per second performed by the INR model with 1080p inputs/outputs. The model compression MACs and encoding/decoding time are measured by the steps for performing quantization and entropy coding. The complexity figures are calculated based on NVIDIA RTX 4090 GPU with FP16.

In addition, we conducted experiments to evaluate the effects of fully end-to-end optimization and alternating optimization on selected challenging sequences from the UVG dataset (Jockey and ReadySetGo) . When removing fully end-to-end optimization, the variant without rate loss in the first stage exhibits up to a 35% BD-rate increase compared to the proposed model. However, this loss diminishes if the number of epochs in the second stage increases. With the proposed alternating optimization, we did not observe any noticeable difference in performance. Nevertheless, without alternating optimization, the training step time can increase by up to 40% under our experimental settings.

## 5 Conclusion

In this paper, we present NVRC, a new INR-based video compression framework with a focus on representation compression. By employing novel entropy coding and quantization models, NVRC significantly improved coding efficiency and allows real end-to-end optimization for the INR model. The experimental results show that NVRC outperforms all the benchmarked conventional and learning-based video codecs, in particular with a 23% bitrate saving against VVC VTM (Random Access)  on the UVG database . This is the first time an INR-based video codec has obtained this achievement.