# Consistency of Neural Causal Partial Identification

Jiyuan Tan

Management Science and Engineering

Stanford University

Stanford, CA 94305

jiyuantan@stanford.edu

&Jose Blanchet

Management Science and Engineering

Stanford University

Stanford, CA 94305

jose.blanchet@stanford.edu

&Vasilis Syrgkanis

Management Science and Engineering

Stanford University

Stanford, CA 94305

vsyrgk@stanford.edu

###### Abstract

Recent progress in Neural Causal Models (NCMs) showcased how identification and partial identification of causal effects can be automatically carried out via training of neural generative models that respect the constraints encoded in a given causal graph . However, formal consistency of these methods has only been proven for the case of discrete variables or only for linear causal models. In this work, we prove the consistency of partial identification via NCMs in a general setting with both continuous and categorical variables. Further, our results highlight the impact of the design of the underlying neural network architecture in terms of depth and connectivity as well as the importance of applying Lipschitz regularization in the training phase. In particular, we provide a counterexample showing that without Lipschitz regularization this method may not be asymptotically consistent. Our results are enabled by new results on the approximability of Structural Causal Models (SCMs) via neural generative models, together with an analysis of the sample complexity of the resulting architectures and how that translates into an error in the constrained optimization problem that defines the partial identification bounds.

## 1 Introduction

Identifying causal quantities from observational data is an important problem in causal inference which has wide applications in economics , social science , health care , and recommendation systems . One common approach is to transform causal quantities into statistical quantities using the ID algorithm  and deploy general purpose methods to estimate the statistical quantity. However, in the presence of unobserved confounding, typically the causal quantity of interest will not be point-identified by observational data, unless special mechanisms are present in the data generating process (e.g. instruments, unconfounded mediators, proxy controls). In the presence of unobserved confounding, the ID algorithm will typically fail to return a statistical quantity and declare the causal quantity as non-identifiable.

One remedy to this problem, which we focus on in this paper, is partial identification, which aims to give informative bounds for causal quantities based on the available data. At a high level, partial identification bounds can be defined as follows: find the maximum and the minimum value that a target causal quantity can take, among all Structural Causal Models (SCMs) that give rise to the same observed data distribution and respect the given causal graph (as well as any other structuralconstraints that one is willing to impose). Note that in the presence of unobserved confounding, there will typically exist many structural mechanisms that could give rise to the same observational distribution but have vastly different counterfactual distributions. Hence, partial identification can be formulated as solving a max and a min optimization problem 

\[_{} _{}(), \] \[P^{}()=P^{^{*}}(), _{}=_{^{*}},\]

where \(()\) is the causal quantity of interest, \(^{*}\) is the true model, \(\) is the set of observed nodes, \(P^{}()\) is the distribution of \(\) in SCM \(\), \(\) is a collection of causal models and \(_{}\) is the causal graph of \(\) (see Section 2 for formal definitions). Two recent lines of work explore the optimization approach to partial identification. The first line deals with discrete Structure Causal Models (SCMs), where all observed variables are finitely supported. In this case, (1) becomes a Linear Programming (LP) or polynomial programming problem and tight bounds can be obtained . The second line of work focuses on continuous models and explores ways of solving (1) in continuous settings using various techniques .

Recently, Xia et al.  formalized the connection between SCMs and generative models (see also  for an earlier version of a special case of this connection). This work showcased that SCMs can be interpreted as neural generative models, namely Neural Causal Models (NCMs), that follow a particular architecture that respects the constraints encoded in a given causal graph. Hence, counterfactual quantities of SCMs can be learned by optimizing over the parameters of the underlying generative models. However, there could be multiple models that lead to the same observed data distribution, albeit have different counterfactual distributions. Xia et al.  first analyze the approximation power of NCMs for discrete SCMs and employ the max/min approach to verify the identifiability of causal quantities, without the need to employ the ID algorithm. Balazadeh et al.  and Hui et al. , extend the method in  and re-purpose it to perform partial identification by solving the min and max problem in the partial identification formulation over neural causal models.

However, for SCMs with general random variables and functional relationships, the approximation error and consistency of this optimization-based approach to partial identification via NCMs has not been established. In particular, two problems remain open. First, given an arbitrary SCM, it is not yet known if we can find an NCM that produces approximately the same intervention distribution as the original one. Although Xia et al. show it is possible to represent any discrete SCM by an NCM, their construction highly relies on the discrete assumption and cannot be directly generalized to the general case. Moreover, Xia et al.  use step functions as the activation function in their construction, which may create difficulties in the training process since step functions are discontinuous with a zero gradient almost everywhere.

Second, since we only have access to \(n\) samples from the true distribution, \(P^{}()\), we need to replace the constraints in (1) with their empirical version that uses the empirical distribution of samples \(P_{n}^{^{*}}()\) in place of the population distribution and looks for NCMs, whose implied distribution lies within a small distance from the empirical distribution. Moreover, even the NCM distribution is typically only accessible through sampling, hence we will need to generate \(m_{n}\) samples from the NCM and use the empirical distribution of the \(m_{n}\) samples from the NCM in place of the true distribution implied by the NCM. Thus, in practice, we will use a constraint of the form \(d(P_{n}^{^{*}}(),P_{m_{n}}^{}()) _{n}\), where \(d\) is some notion of distribution distance and \(_{n}\) accounts for the sampling error. It is not clear that this approach is consistent, converges to the correct partial identification bounds, when the sample size \(n\) grows to infinity. Balazadeh et al.  only show the consistency of this approach for linear SCMs. Consistency results concerning more general SCMs is still lacking in the neural causal literature.

In this paper, we establish representation and consistency results for general SCMs. Our contributions are summarized as follows.

* We show that under suitable regularity assumptions, given any Lipschitz SCM, we can approximate it using an NCM such that the Wasserstein distance between any interventional distribution of the NCM and the original SCM is small. Each random variable of the SCM is allowed to be continuous or categorical. We specify two architectures of the Neural Networks (NNs) that can be trained using common gradient-based optimization algorithms (Theorem 2, Theorem 3 and Corollary 1).

* To construct the NCM approximation, we develop a novel representation theorem of probability measures (Proposition 1) that may be of independent interest. Proposition 1 implies that under certain assumptions, probability distributions supported on the unit cube can be simulated by pushing forward a multivariate uniform distribution.
* We discover the importance of Lipschitz regularization by constructing a counterexample where the neural causal approach is not consistent without regularization (Proposition 2).
* Using Lipschitz regularization, we prove the consistency of the neural causal approach (Theorem 4).

Related WorkThere exists a rich literature on partial identification of average treatment effects (ATE) . Balke and Pearl  first give an algorithm to calculate bounds on the ATE in the Instrumental Variable (IV) setting. They show that regardless of the exact distribution of the latent variables, it is sufficient to consider discrete latent variables as long as all endogenous variables are finitely supported. Moreover, they discover that (1) is an LP problem with a closed-form solution. This LP-based technique was generalized to several special classes of SCMs . For general discrete SCMs,  consider transforming the problem (1) into a polynomial programming problem. Xia et al.  discover the connection between generative models and SCMs. They show that NCMs are expressive enough to approximate discrete SCMs. By setting \(\) in problem (1) to be the collection of NCMs, they apply NCMs for identification and estimation.

For causal models with continuous random variables, the constraints in (1) become integral equations, which makes the problem more difficult. One approach is to discretize the constraints.  uses stochastic process representation of the causal model in the continuous IV setting and transforms the problem into a semi-infinite program.  relaxes the constraints to finite moment equations and solves the problem by the Augmented Lagrangian Method (ALM). The other approach is to use generative models to approximate the observational distribution and use some metric to measure the distance between distributions.  first propose to use GAN to generate images. Later,  uses Wasserstein distance in the constraint and transforms the optimization problem into a min and max problem. Similarly,  solves the optimization problem using Sinkhorn distance to avoid instability during training. They propose to estimate the Average Treatment Derivative (ATD) and use ATD to obtain a bound on the ATE. They also prove the consistency of the proposed estimator for linear SCMs.  uses a linear combination of basis functions to approximate response functions.  uses sieve to solve the resulting optimization problem in the IV setting.  proposes a neural network framework for sensitivity analysis under unobserved confounding.

Organization of this paperIn Section 2, we introduce the notations and some basic concepts used throughout the paper. Next, in Section 3, we demonstrate how to construct an NCM so that they can approximate a given SCM arbitrarily well. Two kinds of architecture are given along with an approximation error analysis. In Section 4, we highlight the importance of Lipschitz regularization by giving a counterexample that is not consistent. Then, leveraging the previous approximation results, we are able to prove the consistency of this approach under regularization. Finally, we compare our method with the traditional polynomial programming method empirically in Section 4.1.

## 2 Preliminary

First, we introduce the definition of an SCM. Throughout the paper, we use bold symbols to represent sets of random variables.

**Definition 1**.: _(Structural Causal Model) A Structural Causal Model (SCM) is a tuple \(=(,,F,P(),_{0})\), where \(=\{V_{i}\}_{i=1}^{n_{V}}\) is the set of observed variables; \(=\{U_{j}\}_{j=1}^{n_{U}}\) is the set of latent variables; \(P()\) is the distribution of latent variables; \(_{0}\) is an acyclic directed graph whose nodes are \(\). The values of each observed variable \(V_{i}\) are generated by_

\[V_{i}=f_{i}((V_{i}),_{V_{i}}),V_{i} (V_{i})_{V_{i}}, \]

_where \(F=(f_{1},,f_{n_{V}})\), \((V)\) is the set of parents of \(V\) in graph \(_{0}\) and \(_{V_{i}}\) is the set of latent variables that affect \(V_{i}\). \(V_{i}\) takes either continuous values \(^{d_{i}}\) or categorical in \([n_{i}]\). We extend graph \(_{0}\) by adding bi-directed arrows between any \(V_{i},V_{j}_{0}\) if there exists a correlated latent variable pair \((U_{k},U_{l}),U_{k}_{V_{i}},U_{l}_{V_{j}}\). We call the extended graph \(_{}\) the causal graph of \(\)._When we write \((V_{i})\), we refer to the parents of \(V_{i}\) in the \(_{0}\). To connect with the literature, the causal graph we define is a kind of Acyclic Directed Mixed Graph (ADMG), which is often used to represent SCMs with unobserved variables . Note that we allow one latent variable to enter several nodes, which differs from the common definition. We use \(n_{U}\) and \(n_{V}\) to denote the number of latent variables and observable variables. Let \(\) be a set of treatment variables. The goal is to estimate causal quantities under a given intervention \(=\). Formally, the structural equations of the intervened model are

\[T_{i}=t_{i}, T_{i},\] \[V_{i}(t)=f_{i}((V_{i}),_{V_{i}}),  V_{i}.\]

We denote \(V_{i}()\) to be the value of \(V_{i}\) under the intervention \(=\) and \(P^{}(())\) to be the distribution of \(()\) in \(\). The notion of a \(C^{2}\) component  is defined as follows.

**Definition 2** (\(C^{2}\)-Component).: _For a causal graph \(\), a subset \(C\) is \(C^{2}\)-component if each pair \(V_{i},V_{j} C\) is connected by a bi-directed arrow in \(\) and \(C\) is maximal._

We provide a concrete example in Appendix A to explain all these notions. We will make the following standard assumption about the independence of latent variables. Note that since we allow latent variables to enter in multiple structural equations, this is more a notational convention and not an actual assumption. Also note that under this convention a bi-directed arrow essentially represents the existence of a common latent parental variable.

**Assumption 1**.: _All the latent variables in \(\) are independent._

To deal with categorical variables, we assume that latent variables that influence categorical variables contain two parts: the shared confounding that influences the propensity functions and the independent noise that generates categorical distributions.

**Assumption 2**.: _The set of latent variables consists of two parts \(=\{U_{1},,U_{n_{U}}\}\{G_{V_{i}}:V_{i}\}\). Precisely, if \(V_{i}\) is a categorical variable, the data generation process of \(V_{i}\) satisfies \(V_{i}=_{k[n_{i}]}\{g_{k}^{V_{i}}+(f_{i}((V_{i}),_{V_{i}}))_{k}\}(f_{i }/\|f_{i}\|_{1})\), where \(G_{V_{i}}=(g_{1}^{V_{i}},,g_{n_{i}}^{V_{i}})\) are i.i.d. standard Gumbel variables, \(_{V_{i}}\{U_{1},,U_{n_{U}}\}\)._

This convention is without loss of generality at this point, but will be useful when introducing Lischitz restrictions on the structural equation functions. The Gumbel variables in the assumption can be replaced by any random variables that can generate categorical variables. It can be proven that all discrete SCMs satisfy this assumption. Note that we implicitly assume that all categorical variables \(V_{i}\) are supported on \([n_{i}]\) for some \(n_{i}\). It is straightforward to generalize all results to any finite support. Next, we introduce Neural Causal Models (NCMs).

**Definition 3**.: _(Neural Causal Model) A Neural Causal Model (NCM) is a special kind of SCM where \(=\{U_{1},,U_{n_{U}}\}\{G_{V_{i}}:V_{i}\}\), all \(U_{i}\) are i.i.d. multivariate uniform variables, \(G_{V_{i}}\) are i.i.d Gumbel variables and functions in (2) are Neural Networks (NNs)._

The definition of NCMs we use is slightly different from that in  because we need to deal with mixed variables in our models. In (1), we usually take \(\) to be the set of all SCMs. However, it is difficult to search over all SCMs since (1) becomes an infinite-dimensional polynomial programming problem. As an alternative, we can search over all NCMs. One quantity of common interest in causal inference is the Average Treatment Effect (ATE).

**Definition 4**.: _(Average Treatment Effect). For SCM \(\), the ATE at \(=\) with respect to \(=_{0}\) is given by \(_{}()=_{ P()}[Y()-Y (_{0})]\)._

Partial identification can be formulated as estimating the solution to the optimization problems (1) . The max and min values \(\) and \(\) define the interval \([,]\) which is the smallest interval we can derive from the observed data without additional assumptions. In particular, if \(=\), then the causal quantity is point-identified.

**Notations.** We use \(\|\|,\|\|_{}\) for the \(1\)-norm and \(\)-norm and \([n]\) for \(\{1,,n\}\). Bold letters represent sets of random variables. We let \(_{L}(K_{1},K_{2})\) be the class of Lipschitz \(L\)-continuous functions \(f:K_{1} K_{2}\). We may omit the domain and use \(_{L}\) when the domain is clear from context. Let \((K_{1},K_{2})\) be the set of homeomorphisms from \(K_{1}\) to \(K_{2}\), i.e., injective and continuous maps in both directions. We define \((_{1},_{2})=_{f_{2}_{2}}_{f_{1} _{1}}\|f_{2}-f_{1}\|\) for function classes \(_{1},_{2}\). We use standard asymptotic notation \(O(),()\). Given a measure \(\) on \(^{d_{1}}\) and a measurable function \(f:^{d_{1}}^{d_{2}}\), the push-forward measure \(f_{\#}\) is defined as \(f_{\#}(B)=(f^{-1}(B))\) for all measurable sets \(B\). We use \(P(X)\) to represent the distribution of random variable \(X\). Let \(_{n}=\{(p_{1},,p_{n}):_{i=1}^{n}p_{i}=1,p_{i} 0\}\) be the probability simplex. We use \((),_{n}\) to represent categorical distribution with event probability \(\). We let \(W(,)\) be the Wasserstein-1 distance and \(S_{}(,)\) be the Sinkhorn distance  with regularization parameter \(>0\).

## 3 Approximation Error of Neural Causal Models

In this section, we study the expressive power of NCMs, which serves as a key ingredient in proving the consistency result. In particular, given an SCM \(^{*}\), we want to construct an NCM \(}\) such that the two causal models produce similar interventional results. Unlike in the discrete case , latent distributions can be extremely complicated in general cases. The main challenge is how to design the structure of NCMs to ensure strong approximation power.

In the following, we first derive an upper bound on the Wasserstein distance between two causal models sharing the same causal graph. Using this result, we decompose the approximation error into two parts: the error caused by approximating structural functions via neural networks and the error of approximating the latent distributions. Then, we design different architectures for these two parts.

Decomposing the Approximation ErrorFirst, we present a canonical representation of an SCM, which essentially states that we only need to consider the case where each latent variable \(U_{i}\) corresponds to a \(C^{2}\) component of \(\).

**Definition 5** (Canonical representation).: _A SCM \(\) with causal graph \(\) has canonical form if_

1. _The set of latent variables consists of two sets,_ \[=\{U_{C}:C$-component of $$} \}\{G_{V_{i}}=(g_{1}^{V_{i}},,g_{n_{i}}^{V_{i}}):V_{i} \},\] _where_ \(U_{C}\) _and_ \(g_{j}^{V_{i}}\) _are independent and_ \(g_{j}^{V_{i}}\) _are standard Gumbel variables._
2. _The structure equations have the form_ \[V_{i}=f_{i}((V_{i}),_{V_{i}}),&$ is continuous},\\ _{k[n_{i}]}\{g_{k}^{V_{i}}+(f_{i}((V_{ i}),_{V_{i}}))_{k}\},&$ is categorical},\|f_{i}\|_{1}=1,\] (3) _where_ \(_{V_{i}}=\{U_{C}:V_{i} C,C$-component of $$}\}\) _and_ \((x)_{k}\) _is the_ \(k\)_-th coordinate of the vector_ \(x\)_. We further assume that_ \(f_{i}\) _are normalized for categorical variables._

_Given a function class \(\), the SCM class \((,,)\) consists of all canonical SCM models with causal graph \(\) such that \(f_{i},i[n_{V}]\)._

Proposition 4 in the appendix shows that any SCM satisfying Assumption 1,2 can be represented in this way and we provide an example in Appendix B.1 to illustrate how to obtain the canonical representation for a given SCM. Therefore, we restrict our attention to the class \((,,)\). For two SCM classes \((,,),(,},})\), we want to study how well we can represent the models in the first class by the second class. The Wasserstein distance between the intervention distributions is used to measure the quality of the approximation. To approximate the functions in the structural equations, we need to make the following regularity assumptions on the functions.

**Assumption 3**.: _If \(V_{i}\) is continuous, \(f_{i}\) in (3) are \(L_{f}\)-Lipschitz continuous. If \(V_{i}\) is categorical, the propensity functions \(f_{i}((V_{i}),_{V_{i}})(V_{i}=j|(V _{i}),_{V_{i}}),j[n_{i}]\) are \(L_{f}\)-Lipschitz continuous. There exists a constant \(K>0\) such that \(_{i[n_{V}],j[n_{U}]}\{\|V_{i}\|_{},\|U_{j}\|_{}\} K\)._

The following theorem summarizes our approximation error decomposition.

**Theorem 1**.: _Given any SCM model \((,_{L},)\), let the treatment variable set be \(=\{T_{k}\}_{k=1}^{n_{k}}\) and suppose that Assumption 1, 2 and 3 hold for \(\) with Lipschitz constant \(L\), constant \(K\).__For any intervention \(=\) and \(}(,},})\), we have_

\[W(P^{}(()),P^{}}(}( ))) C_{}(L,K)(_{i=1}^{n_{V}}\|f_{i}-_{i}\|_{}+W(P^{}(),P^{}}(}))), \]

_where \(C_{}(L,K)\) is a constant that only depends on \(L,K\) and the causal graph \(\) and \(f_{i},_{i}\) are structural functions of \(\) and \(}\) respectively._

Theorem 1 separates the approximation error into two parts, which motivates us to construct the NCM in the following way. First, we approximate the functions \(f_{i}\) in (3) by NNs \(_{i}\). Then, we approximate the distribution of latent variables by pushing forward uniform and Gumbel variables using neural networks, i.e., \(_{C_{j}}=_{j}(Z_{C_{j}})\), where \(\{C_{j}\}\) are \(C^{2}\) components and \(Z_{C_{j}}\) are multi-variate uniform and Gumbel random variables. The structural equations of the resulting approximated model \(}\) are

\[_{i}=_{i}((_{i}),(_{j}( Z_{C_{j}}))_{U_{C_{j}} U_{V_{i}}}),&$ is continuous},\\ _{k[n_{i}]}\{g_{k}+(_{i}(( _{i}),(_{j}(Z_{C_{j}}))_{U_{C_{j}} U_{V_{i}}}))_{k} \},&$ is categorical}, \]

where \(N_{C,j}\) are constants to be specified later.

For the first part, we need to approximate Lipschitz continuous functions. For simplicity, we assume that the domain of the functions are uniform cubes. Similar arguments hold for any bounded cubes. We denote \(_{k_{1},k_{2}}(W,L)\) to be the set of ReLu NNs with input dimension \(k_{1}\), output dimension \(k_{2}\), width \(W\) and depth \(L\). It has been shown that \((_{k_{1},1}(2d_{1}+10,L_{0}),_{L}(^{d_{1} },)) O(L_{0}^{-2/k_{1}})\), where \((,)\) denotes the approximation error defined in Section 2. For a vector valued function, we can use a wider NN to approximate each coordinate and get a similar rate.

For the second part, we approximate each \(U_{i}\) individually by pushing forward i.i.d. multivariate uniform and Gumbel variables \(_{C_{i}}=_{i}(Z_{C_{i}})\) since the latent variables are independent by Assumption 1. To do so, we examine under what assumptions on the measure \(\) over \(^{n}\) we can find a NN \(\) such that \(W(_{\#},)\) is small, where \(()\) is some reference measure.

### Approximating Mixed Distributions by Wide Neural Networks

In this subsection, we will extend the results in  to construct a wide neural network as the push-forward map. It turns out that to get a good approximation of the targeted distribution, the shape of the support is essential.

**Assumption 4** (Mixed Distribution).: _The support of measure \(\) has finite connected components \(C_{1},C_{2} C_{N_{C}}\), i.e., \(()=_{i=1}^{N_{C}}C_{i}\), and each component \(C_{i}\) satisfies \((^{d_{i}^{C}},C_{i})_{L}(^{d_{i}^{C}},C_{i} )\) for some \(d_{i}^{C} 0\). Recall that \((K_{1},K_{2})\) is the set of homeomorphisms from \(K_{1}\) to \(K_{2}\) defined at the end of Section 2._

Assumption 4 encompasses almost all natural distributions. For example, distributions supported on \(^{d}\) and closed balls, finitely supported distributions and mixtures of them all satisfy this assumption. Assumption 4 allows us to transform the support of the targeted distribution into unit cubes and the nice geometric properties of unit cubes facilitate our construction.

Now, we briefly explain the construction of the push-forward maps. An example is provided in Appendix B.1 to illustrate the construction. The NN architecture consists of three parts (see Figure 0(a)). The input dimension is the same as the number of connected components of the support \(N_{C}\). For each component \(C_{i}\), let \(H_{i}(^{d_{i}^{C}},C_{i})_{L}(^{d_{i}^ {C}},C_{i})\), where \(d_{i}^{C}\) is the dimension of component \(C_{i}\) in Assumption 4. By \(=(H_{i})_{\#}(H_{i}^{-1})_{\#}\) on \(C_{i}\), we can approximate \((H_{i}^{-1})_{\#}\) first, which is supported on a unit cube.  constructs a wide NN \(\) of width \(W\) and constant depth such that \(W(_{\#},(H_{i})_{\#}^{-1}) O(W^{-1/d_{i}^{C}})\) where \(\) is the uniform measure on \(\). Then, we approximate the Lipschitz map \(H_{i}\) to \(C_{i}\) to pull the distribution back to \(C_{i}\). These are the first two parts (yellow and blue blocks in Figure 0(a)) of the architecture.

Suppose that the output of \(i\)-th coordinate in the first two parts is \(_{i}\), the Gumbel-softmax layer in the third part (green box) combines different components of the support. In particular, we want to output \(_{i}\) with probability \(p_{i}=(C_{i})\). Let \(V=[_{1},,_{i}]\), this can be achieved by outputting \(VX\), where \(X=(X_{1},,X_{N_{C}})^{T}\) is a one-hot random vector with \((X_{i}=1)=p_{i}\). To use backpropagation in training, we use the Gumbel-Softmax trick  to (approximately) simulate such a random vector, \(_{i}^{}=+G_{i})/}{_{k=1}^{N_{C}}((  p_{k}+G_{k})/)}\), where \(>0\) is the temperature parameter (a hyperparameter) and \(G_{i}(0,1)\) are i.i.d. standard Gumbel variables. As \( 0\), the distribution of \(^{}\) converges almost surely to the categorical distribution [36, Proposition 1]. In particular, when \(=0\), we denote \(_{i}^{0}=_{i=_{j}\{ p_{i}+G_{i}\}}\). The output of the last layer is \(V^{}\). Note that the Gumbel-softmax function is differentiable with respect to parameter \(\{(p_{i})\}_{i=1,,N_{C}}\). Therefore, we can train the network with common gradient-based algorithms. Putting things together, we obtain the following theorem.

**Theorem 2**.: _Given any probability measure \(\) on \(^{d}\) that satisfies Assumption 4, let \(\) be the Lebesgue measure on \(^{N_{C}}\), where \(N_{C}\) is defined in Assumption 4. There exists a neural network \(=_{3}^{}_{2}_{1}\) with the above antichesture (Figure 0(a)) such that_

\[W(_{\#},) O(W_{1}^{-1/_{i}\{d_{i}^ {C}\}}+L_{2}^{-2/_{i}\{d_{i}^{C}\}}+(-)).\]

_Here, \(_{i},i=1,2\) has the separable form \((_{i}^{1}(x_{1}),,_{i}^{N_{C}}(x_{N_{C}}))\) and \(_{1}^{j}_{1,d_{j}^{C}}(W_{1},(d_{j}^{C}))\), \(_{2}^{j}_{d_{j}^{C},d}((d d_{j}^{C}),L_{2}), \ j[N_{C}]\). \(\{d_{j}^{C}\}\) are the dimension of cubes in Assumption 4. \(_{3}^{}\) is the Gumbel-Softmax layer with temperature parameter \(>0\)._

Note that \(_{3}^{}\) (the Gumbel-softmax layer) is actually a random function since the coefficient vector \(^{}\) is a random variable. In this sense, \(_{\#}\) can be viewed as pushing forward uniform and Gumbel variables using a neural net.

### Approximating Mixed Distributions by Deep Neural Networks

In this subsection, we will show that under one additional assumption on the distribution, deep ReLu networks have a stronger approximation power in approximating distributions, which means we can use fewer computational units to achieve the same worst-case theoretical approximation error.

**Assumption 5** (Lower Bound).: _Suppose that \(\) is supported on a compact set \(K^{D}\), there exists a constant \(C_{f}>0\), \(f(^{d},K)_{L}(^{d},K)\), such that for any measurable set \(B^{d}\), \((f(B)) C_{f}(B)\). Besides, if \(d>0\), \(f_{\#}\) vanishes on the boundary \(^{d}\)._

Assumption 5 implies that \(d/d(f_{\#}^{-1})\) exists and is lowered bounded by a constant \(C_{f}\). The next proposition extends the Skorohod representation theorem . It shows that under Assumption 5, itis possible to simulate any distribution on the unit cubes with Holder continuous curves and uniform distribution on \(\).

**Proposition 1**.: _Let \(\) be the Lebesgue measure on \(\). Given any probability measure \(\) that satisfies Assumption 5, there exists a continuous curve \(:()\) such that \(_{\#}=\). Furthermore, if \(d 1\), \(\) is \(1/d\)-Holder continuous._

Results from  show that we can approximate any Holder continuous \(d\)-dimensional function with index \(\) by a deep ReLu network with depth \(L\) and error \(O(L^{-2/d})\). Leveraging this result, we can replace the first part of the architecture in the previous subsection with deep ReLu networks (See Figure 8 in the appendix). The remaining two parts are the same as the construction in Figure 0(a). The following theorem gives a sharper bound on the approximation error compared with Theorem 2.

**Theorem 3**.: _Under the Assumption 4, if in addition, \(\) constrained to each component satisfies Assumption 5, there exists a neural network \(=_{3}^{}_{2}_{1}\) with the above architecture such that_

\[W(_{\#},) O(L_{1}^{-2/_{i}\{d_{i}^ {C}\}}+L_{2}^{-2/_{i}\{d_{i}^{C}\}}+(-)),\]

_where \(d_{i}^{C}\) are the dimensions of the connected components in Assumption 4, \(_{i},i=1,2\) has the form \((_{i}^{1}(x_{1}),,_{i}^{N_{C}}(x_{N_{C}}))\) and \(_{1}^{j}_{1,d_{j}^{C}}((d_{j}^{C}),L_{1})\). \(_{2}^{j},_{3}^{},\) are the same as in Theorem 2._

Let \(N\) be the number of nonzero weights in a neural network, Theorem 3 shows that a deep NN can achieve \(O(N^{-2/d})\) error while by Theorem 2 a wide network can only achieve \(O(N^{-1/d})\) error. Now, we can put things together to construct NCM approximations. For simplicity, we omit the input and output dimensions of the neural network. As we mention in previous sections, our construction (5) consists of two parts, \(_{i}\) approximating the structural functions \(f_{i}\) in (3), and \(_{j}(Z_{j})=_{3,j}^{}_{2,j}_{1,j}(Z_ {j})\) approximating the latent variables \(U_{j}\). Let \(_{}(_{0},_{1},_{2},)\) be a collection of NCMs with structural equation (5) and

\[_{i}_{0},_{1,j}=(_{1,j}^{1},,_ {1,j}^{N_{C,j}}),_{1,j}^{i}_{1},_{2,j}=(_{ 2,j}^{1},,_{2,j}^{N_{C,j}}),_{2,j}^{i}_{2},\]

where \(N_{C,j}\) is the number of connected components for \(U_{j}\) and \(_{i}\) are function classes.

**Corollary 1**.: _Given a causal model \(^{*}(,_{L},)\), suppose that Assumptions 1-3 hold and the distributions of \(U_{C}\) for all \(C^{2}\)-component satisfy the assumptions of Theorem 3. Let \(d_{}^{}\) and \(d_{}^{}\) be the largest input and output dimension of \(f_{i}\) in (3) and \(d_{}^{U}\) be the largest dimension of all latent variables. There exists a neural causal model_

\[}_{}(((d_{}^{ }d_{}^{}),L_{0}),((d_{} ^{U}),L_{1}),(((d_{}^{U})^{2} ),L_{2}),)\]

_with structure equations (5). For any intervention \(=\), \(}\) satisfies_

\[W(P^{^{*}}(()),P^{}}(())) O(L_{0}^{-2/d_{}^{}}+L_{1}^{-2/d_{}^{U}} +L_{2}^{-2/d_{}^{U}}+(-)).\]

Similar approximation results also hold for wide NN approximation, as presented in Section 3.1. The proof can be easily adapted to the wide NNs architecture.

## 4 Consistency of Neural Causal Partial Identification

In this section, we prove the consistency of the max/min optimization approach to partial identification. In the finite sample setting, we consider the following estimator \(F_{n}\) of the optimal values of (1).

\[F_{n}=*{arg\,min}_{}_{ }(_{0,n},_{1,n},_{2,n},_{n})} _{t_{T}}_{}}[F(V_{1}(t),,V_{ n_{V}}(t))], \] \[s.t. S_{_{n}}(P_{m_{n}}^{}}(),P_{n}^{}^{*}}())_{n},\]

where \(P_{n}^{}^{*}},P_{m_{n}}^{}}\) are the empirical distribution of \(P^{}^{*}}\), \(P^{}}\) with sample size \(n,m_{n}\), \(_{T}\) is some given measure and \(_{i,n}\) will be specified later. For example, the counterfactual outcome \([Y(1)]\) is a special case of the objective. Our results can be easily generalized to any linear combination of objective functions of this form. We use the Sinkhorn distance because it can be computed efficiently in practice . We want to study if \(F_{n}\) gives a useful lower bound as \(n\).

[MISSING_PAGE_FAIL:9]

**Proposition 3** (Holder continuity of ATE).: _Given two causal models \(,}(,_{L},)\) satisfying Assumption 1 and Assumption 3, let their observational distributions be \(,\). Suppose the norms of all variables are bounded by \(K>0\). If(1) (Overlap) \(\) is absolutely continuous with respect to one probability measure \(P\) and the density \(p_{}\)\((t|(T)=x)>0\) for x almost surely and \(t[t_{1},t_{2}]\) and (2) (No Confounding) there is no confounding in the causal graph \(\), we have_

\[_{t_{1}}^{t_{2}}(_{}[Y(t)]-_{}}[(t)])^{2}P(dt)}{}W(,)+2(L+1)^{n_{V }}W^{2}(,)(t_{2}-t_{1}),\]

_where \(C_{W}=4(L+1)^{n_{V}}K+2K\{(L+1)^{n_{V}},1\}\)._

**Corollary 2**.: _Let \(F,_{T}\) in Theorem 4 to be \(F()=Y,_{T}([t_{1},t_{2}]),>0\). Suppose that the assumptions in Proposition 3 and Theorem 4 hold, with probability at least \(1-O(n^{-2})\), we have \(|F_{n}-F_{*}| O(})\), where \(F_{n},F_{*},_{n}\) are defined in Theorem 4._

### Experiments

In this section, we examine the performance of our algorithm in two settings. We compare our algorithm with the Autobounds algorithm  in a binary IV example in  and in a continuous IV model 1. Since Autobounds can only deal with discrete models, we discretize the continuous model for comparison purposes. The implementation details are provided in the Appendix D. The setting of the first experiment is taken from [14, Section D.1]. This is a binary IV problem and we can calculate the optimal bound using LP . We find that our bound is close to the optimal bound. The second experiment is a general IV example where the treatment is binary but the rest of the variables are continuous. The program that Autobounds solves after discretization contains \( 2^{14}\) variables. Even with such a fine discretization, the bound obtained by Autobounds is not tighter than our NCM approach. The details of the structural equations and analysis can be found in Appendix D. We also provide an extra experiment on the counterexample of Proposition 5 in the appendix to show the effect of Lipschitz regularization.

ConclusionIn this paper, we provide theoretical justification for using NCMs for partial identification. We show that NCMs can be used to represent SCMs with complex unknown latent distributions under mild assumptions and prove the asymptotic consistency of the max/min estimator for partial identification of causal effects in general settings with both discrete and continuous variables. Our results also provide guidelines on the practical implementation of this method and on what hyperparameters are important, as well as recommendations on values that these hyperparameters should take for the consistency of the method. These practical guidelines were validated with a small set of targeted experiments, which also showcase superior performance of the neural-causal approach as compared to a prior main contender approach from econometrics and statistics, that involves discretization and polynomial programming.

An obvious next step in the theoretical foundation of neural-causal models is providing finite sample guarantees for this method, which requires substantial further theoretical developments in the understanding of the geometry of the optimization program that defines the bounds on the causal effect of interest. We take a first step in that direction for the special case, when there are no unobserved confounders and view the general case as an exciting avenue for future work.

AcknowledgementVasilis Syrgkanis is supported by NSF Award IIS-2337916 and a 2022 Amazon Research Award.

  Setting & Algorithm & Average Bound & Optimal Bound & True Value \\   & NCM (Ours) & [-0.49,0.05] & [-0.45, -0.04] & -0.31 \\   & Autobounds & [-0.45,-0.05] & [-0.45, -0.04] & \\   & NCM (Ours) & [2.49,3.24] & – &  \\   & Autobounds & [1.40, 3.48] & – & \\  

Table 1: Experiment results of 2 IV settings. The sample sizes are taken to be \(5000\) in each experiment. STD is the standard derivation. The experiments are repeated 10 times for binary IV and 50 times for continuous IV. In all experiments, the bounds given by both algorithms all cover the true values.