# Optimized Feature Generation for Tabular Data via LLMs with Decision Tree Reasoning

Jaehyun Nam\({}^{*1}\), Kyuyoung Kim\({}^{*1}\), Seunghyuk Oh\({}^{1}\)

**Jihoon Tack\({}^{1}\), Jaehyung Kim\({}^{2}\), Jinwoo Shin\({}^{1}\) \({}^{1}\)**KAIST, \({}^{2}\)**Yonsei University

{jaehyun.nam,kykim,jinwoos}@kaist.ac.kr

Equal contribution

###### Abstract

In tabular prediction tasks, tree-based models combined with automated feature engineering methods often outperform deep learning approaches that rely on learned representations. While these feature engineering techniques are effective, they typically depend on a pre-defined search space and primarily use validation scores for feature selection, thereby missing valuable insights from previous experiments. To address these limitations, we propose a novel tabular learning framework that utilizes large language models (LLMs), termed _Optimizing Column feature generator with decision Tree reasoning (OCTree)_. Our key idea is to leverage the reasoning capabilities of LLMs to identify effective feature generation rules without manually specifying the search space and provide language-based reasoning information highlighting past experiments as feedback for iterative rule improvements. We use decision trees to convey this reasoning information, as they can be easily represented in natural language, effectively providing knowledge from prior experiments (_i.e._, the impact of the generated features on performance) to the LLMs. Our empirical results demonstrate that OCTree consistently enhances the performance of various prediction models across diverse benchmarks, outperforming competing automated feature engineering methods. Code is available at [https://github.com/jaehyun513/OCTree](https://github.com/jaehyun513/OCTree).

## 1 Introduction

Learning useful representations from raw data is key to the success of deep learning algorithms, and their effectiveness has been demonstrated across multiple domains, _e.g._, vision  and language . However, in the tabular domain, deep learning approaches are often perceived as less effective . For instance, tree-based approaches utilizing raw column features of tabular data  often outperform deep learning models in tabular prediction tasks such as classification and regression . As a result, practitioners commonly resort to using tree-based methods coupled with manual feature engineering, such as computing the product of two column features .

Generating suitable column features, even with domain knowledge, can be challenging and costly. For instance, manual validation to identify useful features is infeasible due to the exponentially many possible combinations to explore . To address this issue, existing feature engineering methods  use additional filtering schemes  to evaluate and select useful features automatically. While these approaches reduce manual effort and improve feature quality, they still present several challenges. First, practitioners often rely on manually defined search spaces to generate candidate features due to the inherent ambiguity of what constitutes informative features . However, this still requires substantial computation for validating candidate features,particularly as the number of features and the complexity of the search space grow. Furthermore, they neglect more effective experimental designs, relying solely on validation scores to select good features, despite the value of past experiment data for improving selection.

Motivated by this, we propose to approach this problem from a novel perspective: optimization to discover effective generation rules, leveraging the language understanding and reasoning capabilities of large language models (LLMs). Recent research has demonstrated that LLMs can optimize various non-differentiable problems using prompts that describe the optimization task in natural language . This suggests the potential for LLMs to automatically generate and iteratively refine feature generators without the need for manually specifying the rule space. For example, the reasoning capabilities of LLMs allow incorporating feedback on their previous outputs into the process for iterative refinement. Moreover, linguistic contexts, such as column names (_e.g._, 'Gender' and 'Age') and categorical values (_e.g._, 'Female' and 'Male'), could be naturally integrated into the optimization , which is difficult, if not impossible, with conventional methods.

**Contributions.** In this work, we leverage LLMs to generate novel column features for tabular prediction tasks, proposing _Optimizing Column feature generator with decision Tree reasoning (OCTree)_, a generic framework for automated feature generation using LLMs. Figure 1 illustrates an overview of our framework. Our approach begins by prompting an LLM to propose a name for a novel column feature based on the task description, such as 'Trading Volume' for stock price prediction. This initial suggestion guides the LLM in exploring and refining the corresponding feature values. Then, we further leverage the reasoning capability of LLMs to produce a _good_ rule that generates values for the newly introduced column feature based on the existing ones. Specifically, starting from an initial rule \(r_{0}\), we let the LLM iteratively improve the current rule \(r_{t}\) by using extracted reasonings \(d_{0},d_{1},,d_{t}\) and validation scores \(s_{0},s_{1},,s_{t}\) attained by the prediction model as feedback. Here, \(d_{t}\) denotes the language description of a decision tree fitted to the entire dataset, including the new feature generated by \(r_{t}\). Specifically, we propose using the _decision tree reasoning_ to provide the LLM with effective knowledge from the past experiments, _i.e._, the prediction model trained with the generated features, providing learned knowledge about the entire dataset. This procedure is iterated for a fixed number of times, after which we select the rule with the highest validation score.

We assess the effectiveness of OCTree on a wide range of real-world datasets (_e.g._, stock price and patient mortality prediction) from various sources, including recent Kaggle competitions. Our

Figure 1: **Overview of OCTree.** (Step 0) Prompt the LLM to propose a name for the new column. (Step 1) Generate a rule by prompting the LLM with feedback on previously generated rules and relevant information for reasoning about the data. (Step 2) Generate a new column feature based on the proposed rule. (Step 3) Train a prediction model on the new data and compute the validation score and tree-based reasoning, provided as feedback for iterative improvements. (Step 4) Repeat steps 1-3 a fixed number of times and select the rule with the best validation score.

experimental results demonstrate that OCTree consistently enhances the performance of various prediction models, including gradient-boosted decision trees  and deep neural networks [31; 32], for both classification and regression tasks. We also assess OCTree on datasets where language descriptions are unavailable, _i.e._, all feature values and column names are anonymized during preprocessing. Even on these datasets, OCTree reduces relative prediction errors by an average of 5.0% compared to the best baseline model, _i.e._, XGBoost on the 19 classification tasks benchmarked by Grinsztajn et al. . Here, we use the Llama 2 7B model fine-tuned on high-quality dialogue data to enhance its ability to understand and generate contextually relevant, coherent rules. We also show that OCTree outperforms recent automatic feature engineering methods, including CAAFE  and OpenFE , often using our 7B LLM, even when these methods are combined with significantly more advanced models like GPT-4. Lastly, we demonstrate that features generated for one type of model (_e.g._, a simpler model like XGBoost) can enhance the performance of other model types (_e.g._, more complex models like neural networks). This illustrates a potential approach to scaling the method for larger, more complex models.

## 2 Related work

**Tabular learning with LLMs.** Recent developments in LLMs have encouraged investigation into their applications to tabular prediction tasks. Dinh et al.  and Hegselmann et al.  fine-tune GPT-3  and T0 , respectively, by serializing tabular data into natural language. Nam et al.  utilizes unlabeled data expressed in natural language for few-shot semi-supervised tabular classification tasks via prompting LLMs. More recently, Yan et al.  introduced a tabular-specific tokenization method to pre-train a single language model capable of performing well across multiple tabular datasets. Instead of using LLMs as prediction models, we explore whether they can effectively generate useful column features for tabular prediction tasks. Specifically, we propose enhancing various prediction models by using LLMs as optimizers to generate novel column features.

**LLMs as optimizers.** Various prompting techniques have demonstrated the use of LLMs for solving optimization problems. This is achieved by describing optimization problems in natural language and instructing LLMs to iteratively generate new solutions based on previously found solutions and their evaluation. In particular, Yang et al.  uses LLMs to optimize linear regression, the traveling salesman problem, and prompt optimization (_i.e._, refining instructions to improve LLM outputs). Building on these insights, we leverage LLMs to optimize feature generators for tabular prediction tasks. Unlike prior work, we incorporate decision tree reasoning as feedback, providing the model with learned knowledge about the dataset in natural language for more effective optimization.

**Automated feature engineering.** Automated feature engineering involves generating features from raw data without human effort to improve the performance on prediction tasks . Various methods have been developed for this purpose [37; 38; 39], including iterative feature subsampling with beam search to select informative features  and feature boosting and pruning algorithms for efficient and accurate filtering . More recently, Hollmann et al.  introduced a context-aware feature engineering approach that leverages LLMs to generate semantically meaningful features based on the description of a given task. Unlike previous approaches, our method leverages the optimization and reasoning capabilities of LLMs to discover effective feature generation rules without the need for manually defining a search space. Furthermore, while methods such as CAAFE  rely on language-based context, our approach is applicable to both context-aware and context-agnostic settings, enabling it to handle a broader range of prediction tasks.

## 3 Optimizing feature generator with decision tree reasoning

In this section, we introduce a framework for automated tabular feature engineering by leveraging the language understanding and reasoning capabilities of LLMs. In a nutshell, our approach utilizes LLMs as optimizers to propose and refine the rules for generating column features. Specifically, we iteratively improve the rules by guiding the LLMs using (1) the validation performance of previously proposed rules and (2) decision tree-based reasoning derived from the training data as inputs, enabling more effective optimization. We begin by framing the feature engineering problem as an optimization of the rules for generating column features (Section 3.1) and then introduce the core framework, termed _Optimizing Column feature generator with decision Tree reasoning_ (OCTree), designed to solve this optimization task (Section 3.2).

**Problem setup.** Formally, the goal of tabular prediction tasks is to train a prediction model \(f:\), where \(\) is the input space and \(\) is an \(M\)-dimensional column feature with corresponding column names \(=\{c_{1},,c_{M}\}\). For example, '\(x_{1}\): Female' and '\(x_{2}\): 36' are values for the columns '\(c_{1}\): Gender' and '\(c_{2}\): Age', respectively. In classification tasks, \(=\{0,1\}^{K}\) represents the label space with \(K\) classes, while in regression tasks, \(\). We denote by \(c_{}\) the name of the column corresponding to the label \(\).

### Tabular feature generation as rule generator optimization

We frame tabular feature engineering as the optimization of feature-generating rules, where the rules define a mapping from the original set of features to a new feature. Our objective is to generate a one-dimensional column feature, \(^{}\), by optimizing the rule \(r:^{}\). Specifically, we aim to create a novel column feature that improves the performance of the prediction model when trained with the new feature, \(f:^{}\). Our optimization problem can be formalized as follows:

\[_{r}_{f^{*}}(_{} r) f^{*}=*{arg\,min}_{f}_{f}(_{ } r), \]

where \(g\) is the rule generator (_i.e._, LLM \(\) in our case), \(r:=g(_{})\) is the rule generated based on the training dataset \(_{}\), and \( r:=\{_{i} r(_{i}),_{i} \}_{i=1}^{N}\) denotes the dataset augmented with the new column feature generated. \(_{f}\) is the objective function for the given prediction task, such as mean absolute error for regression tasks, evaluated using the model \(f\). In summary, we optimize the rule \(r\) to achieve the best validation score measured on \(_{} r\) with the model \(f^{*}\) trained to minimize the loss on \(_{} r\).

However, such bi-level optimization is often non-differentiable or computationally demanding, as it involves computing gradients through the optimization of \(f^{*}\). Moreover, the rule itself may involve non-differentiable operations, such as logical conjunctions between categorical features (_e.g._, 'Is a Smoker = Has Fever \(\) Has Difficulty Breathing' as in Figure 1). One approach to addressing the issue is to use black-box optimization methods, such as evolutionary strategies  or reinforcement learning . However, these methods also have limitations, including the need for a manually defined search space, which is complex, as well as the potentially suboptimal use of valuable feedback from previously proposed solutions that could enhance the optimization process.

To address this issue, we propose leveraging LLMs as optimizers for the tabular feature engineering problem. Our approach involves iteratively proposing and refining rules by prompting LLMs with a trajectory of feedback, which includes the history of previously proposed rules, the validation scores, and the associated reasoning information. Optimization using LLMs  has proven to be an effective tool, particularly for black-box optimization problems, which we show can also be effective in tabular feature engineering. Furthermore, LLMs can leverage the semantics of column and feature values for better optimization and provide the flexibility to operate without a pre-defined search space.

### Generating column features with OCTree

We now present the core algorithm. First, we prompt the LLM to propose a name of a new column, such as 'Smoking Status' in Figure 1, and the corresponding rule based on the task description. We then compute the validation score of the prediction model and extract decision tree reasoning from the training dataset, initializing the optimization trajectory. This trajectory provides feedback to the LLM, with the _decision tree reasoning_ component, which effectively conveys the knowledge of past experiments and captures the quality of previously suggested features. As the optimization process continues, the trajectory is updated, enabling the LLM to refine and enhance the rule iteratively.

**Column name generation.** OCTree begins by generating a name of a new column feature, \(c_{}\), through the LLM \(\). This is done by prompting \(\) with the prompt \(p_{}\) (see Appendix A.1), which asks for a new column name that would be useful for predicting the target: \(c_{}=(p_{}(,c_{ }))\). Leveraging its language understanding capabilities, the LLM is able to generate semantically coherent and relevant column names. For instance, it might suggest using trading volume as a new feature for predicting stock prices.

**Initialize optimization and extract decision tree reasoning.** OCTree then generates an initial rule \(r_{0}\) for deriving a new column feature from the original set of columns \(\). This is done by prompting the LLM \(\) with the prompt \(p_{}\) (see Appendix A.2) to propose a rule for predicting \(c_{}\) with\(c_{1},,c_{M}\): \(r_{0}=(p_{}(,c_{}))\). The score \(s_{0}\) for the initial rule is then evaluated with the prediction model \(f^{*}\): \(s_{0}=_{f^{*}}(_{} r_{0})\). Additionally, decision tree reasoning \(d_{0}\) is extracted using CART  fitted to the training dataset:

\[d_{0}=(_{} r_{0}).\]

CART is a binary decision tree that recursively splits the data based on criteria such as Gini impurity to predict the outcome. We employ CART for two main reasons: (i) tree-based models, often ensembles of simple decision trees like CART, outperform deep learning on many tabular prediction tasks, and (ii) CART is easily interpretable and can be expressed in natural language. For example, as illustrated in Figure 1, CART can be expressed using a simple if-else syntax. Intuitively, the decision tree reasoning extracted by CART provides valuable insights learned from the entire training dataset. It explicitly highlights the columns that are considered more significant (as nodes in the tree) and the corresponding values (as thresholds of the nodes) used for prediction.

**Optimization with decision tree reasoning.** To optimize the rule, we describe the task in natural language and provide the trajectory \(_{t}=\{(s_{i},d_{i},r_{i})\}_{i=0}^{t}\), which includes the history of previously proposed rules, the corresponding scores, and associated reasoning information. We then generate a new rule \(r_{t+1}\) using the LLM \(\) with the prompt \(p_{}\) (see Appendix A.3), which asks \(\) to propose a new rule that is not present in \(_{t}\) and that would improve on the scores from the previous iterations: \(r_{t+1}=(p_{}(_{t},,c_{}))\). The elements in the optimization trajectory are ordered by the scores, as LLMs tend to generate suggestions that appear later in the list [25; 43]. Afterward, we append the new score \(s_{t+1}=_{f^{*}}(_{} r_{t+1})\), the decision tree reasoning \(d_{t+1}=(_{} r_{t+1})\), and the rule \(r_{t+1}\) to the trajectory: \(_{t+1}=_{t}\{(s_{t+1},d_{t+1},r_{t+1})\}\). The optimization proceeds for a fixed number of iterations, with the best rule selected based on the highest validation score.

**Generating multiple features.** The optimization process can be repeated to generate multiple useful features. For example, after generating the column 'Smoking Status', an additional column 'Physical Activity Level' can be generated based on the original features and the newly created 'Smoking Status'. Formally, we first generate a new column \(^{}=r_{}()\), where \(r_{}\) is the optimized rule for generating the new feature \(^{}\). This results in an augmented input space, \(^{}=^{}\). Using the updated dataset \(^{}^{}\), OCTree iteratively generates additional column features. This process continues, introducing new features in sequence until the validation score no longer improves.

## 4 Experiments

In this section, we evaluate the effectiveness of OCTree across a range of tabular classification and regression tasks using diverse datasets. Our findings demonstrate that OCTree consistently improves the performance of various types of prediction models (Section 4.1 and Section 4.2). Furthermore, ablation studies confirm the value of the proposed decision tree reasoning in the optimization and demonstrate that features generated using one type of prediction model can effectively transfer to others, suggesting an approach to scaling the framework to more complex models (Section 4.3).

**Datasets.** First, we select real-world datasets with language descriptions of the column features from diverse sources, including the Disease, Academic, Enefit, and Tesla Stock datasets, recently released on Kaggle, and the Clinical Trial dataset from the US National Library of Medicine. These prediction tasks are highly practical and relevant to domains such as healthcare (_e.g._, diagnostics), academia (_e.g._, student dropout prediction), and finance (_e.g._, stock price forecasting). In addition, to evaluate OCTree on datasets without language descriptions of the columns, we include the 19 classification datasets benchmarked by Grinsztajn et al. . When selecting datasets, it is important to consider the heterogeneous nature of tabular data  and ensure coverage of both categorical and numerical features, as well as both classification and regression tasks. We conduct experiments on this diverse selection of datasets to evaluate OCTree's general applicability across various types of tabular data. Further details on the datasets are provided in Appendix B.

Figure 2: **Generation of multiple features.** The optimization process is repeated to generate multiple column features in sequence.

**Baselines.** To validate our method, we evaluate it across three types of prediction models. We first consider XGBoost , a highly competitive tree-based model known for its effectiveness in the tabular domain. Second, we apply our method to multilayer perceptron (MLP; Gorishniy et al. ), the base architecture for deep learning models. Lastly, we show that OCTree improves the performance of HyperFast , a recently introduced model designed for fast classification of tabular data. Implementation details, including hyperparameter search space, are provided in Appendix C.

**Common setup.** For all datasets, 60% of the data is used for training, 20% for validation, and 20% for testing. Following Gorishniy et al. , we use learned embeddings for categorical features when training MLPs, while HyperFast handles categorical features automatically. For all experiments, we use CART with a maximum depth of 4 to extract decision tree reasoning, provided to the rule generating LLM in the prompt. Unless noted otherwise, we use the Llama 2 model  at the 7B scale, fine-tuned on UltraChat , a dialogue dataset that has been used to develop strong chat models such as UltraLM . Our findings indicate that open models, even at moderate scales, can be highly effective, particularly when equipped with strong chat capabilities. Further comparisons across different types of LLMs are provided in Section 4.2.

### Main results: Context-aware feature engineering

**Datasets with language descriptions.** We first experiment with datasets where language descriptions of the columns and categorical feature values are available. In these cases, the LLM generates a logical rule in _natural language_, which is then converted into Python code for use in our experiments. For this task, we utilize both GPT-4o and our Llama 2 model, as the Llama 2 model can be limited by its relatively short context length on some datasets. See Appendix A.4 for the prompt used.

As shown in Table 1, OCTree consistently enhances the performance of various baseline models. For instance, when generating the column "Trading Volume" for the Tesla Stock dataset using Llama 2 for XGBoost, the relative error is reduced by 15.9%. OCTree is compatible with arbitrary LLMs, allowing more advanced models to enhance the quality of generated features further. Specifically, with GPT-4o, one of the latest LLMs from OpenAI, our method achieves a relative error reduction of 17.1% on the same dataset for XGBoost. We provide results on additional datasets in Table 13.

**Comparison with CAAFE.** CAAFE  also introduces a feature engineering approach that utilizes LLMs to construct features based on the linguistic context. However, it is important to note that CAAFE requires explicit language descriptions of the features, which limits its applicability when such information is unavailable. For example, feature names and values are often obfuscated for confidentiality, a common practice in the financial and medical domains. In contrast, our method can be effectively applied to datasets without linguistic descriptions, as demonstrated in Table 3.

   Method & LLM & Tesla\({}^{}\) & Enetif\({}^{}\) & Disease\({}^{*}\) & Clinical\({}^{*}\) & Academic\({}^{*}\) \\    \\  Baseline & - & 6.61 & 8.00 & 28.09\(\)7.9 & 46.27\(\)5.0 & 14.15\(\)0.6 \\
**OCTree** & Llama 2 & 5.56 (15.9\%) & 8.00 (0.0\%) & 26.19\(\)7.2 (6.8\%) & 45.07\(\)4.1 (2.6\%) & 14.11\(\)0.5 (0.3\%) \\
**OCTree** & GPT-4o & **5.48 (17.1\%)** & **7.82 (2.3\%)** & **25.72\(\)6.8 (8.4\%)** & **43.75\(\)4.4 (5.4\%)** & **13.74\(\)0.1 (2.9\%)** \\    \\  Baseline & - & 7.41 & 33.53 & 38.10\(\)3.6 & 41.77\(\)1.7 & 14.41\(\)0.8 \\
**OCTree** & Llama 2 & 5.23 (29.4\%) & 29.99 (10.6\%) & 32.86\(\)5.7 (13.7\%) & 39.80\(\)23 (4.7\%) & 14.26\(\)0.7 (1.0\%) \\
**OCTree** & GPT-4o & **5.01 (32.4\%)** & **21.68 (35.3\%)** & **30.95\(\)38 (18.8\%)** & **39.25\(\)0.5 (6.0\%)** & **14.22\(\)0.5 (1.3\%)** \\    \\  Baseline & - & N/A & N/A & 28.57\(\)1.00 & 43.64\(\)1.1 & 14.67\(\)0.7 \\
**OCTree** & Llama 2 & N/A & N/A & 28.10\(\)9.2 (1.6\%) & **41.45\(\)1.1 (5.0\%)** & **14.49\(\)0.5 (1.2\%)** \\
**OCTree** & GPT-4o & N/A & N/A & **27.14\(\)3.8 (5.0\%)** & 42.00\(\)1.5 (3.8\%) & **14.49\(\)0.5 (1.2\%)** \\   

Table 1: **Performance improvement by OCTree on datasets with language descriptions. We report test error rates (%) for three classification tasks (\({}^{*}\)) and mean absolute error (\( 10^{-3}\)) for two regression tasks (\({}^{}\)). The lowest errors are highlighted in bold. Values in parentheses indicate the relative error rate reduction from the baseline. We report the mean error and standard deviation across three random splits, except for two regression tasks (time series tabular data), which are split by time index. N/A indicates that the method is not applicable, as HyperFast is a classification model.**Thus, to compare CAAFE with OCTree, we evaluate both methods on datasets with contextual information, particularly all of the six classification datasets used in Tables 1 and 13. The results in Table 2 show that our method significantly outperforms CAAFE with GPT-4o, even when using our custom Llama 2 model fine-tuned on open dialogue data. Also, conventional feature engineering methods, such as OpenFE , often struggle to generate meaningful features, particularly due to the difficulty of applying arithmetic operations to categorical features. A key distinction between CAAFE and OCTree is that our approach generates more semantically meaningful column names, which serve as a basis for creating high-quality features. Leveraging the LLM's reasoning and in-context learning capabilities, we guide the model in effectively navigating the feature space to generate coherent, relevant rules, using a history of feedback on candidate features and decision tree reasoning to enhance its understanding of the data. In contrast, CAAFE primarily relies on language understanding to suggest simple combinations of existing feature. Moreover, CAAFE tends to adopt a greedy approach, evaluating the validation score for a candidate feature only once and discarding it if no improvement is observed. We provide further results with case studies in Appendix E.

### Main result: Context-agnostic feature engineering

**Datasets without language descriptions.** In practice, datasets do not always include clear language descriptions of the prediction task. For example, feature names and values in financial datasets are often obfuscated with arbitrary symbols to protect confidentiality . OCTree adapts easily to such datasets without language descriptions and can generate features using various arithmetic rules. As shown in our ablations in Section 4.3, this is due to the more effective use of LLMs' optimization capabilities with decision tree reasoning that enhances the model's understanding of the data.

To evaluate datasets without language descriptions, we apply ordinal encoding to categorical features and normalize all features using a min-max scaler, transforming the original numeric values. We also use non-descriptive column names, such as \(=\{\)'x1', 'x2',..., 'x5'\(\}\) for a dataset with \(M=5\) columns. To initialize the feedback trajectory, we create an initial rule that is the product of the two columns with the highest importance weights computed using an XGBoost model, _e.g._, \(x_{6}=x_{1} x_{5}\). As shown in Table 3, our framework enhances baseline models even in the absence of language descriptions, achieving an average error reduction of approximately 5.0% for both the XGBoost classifier and MLP. For HyperFast, OCTree also improves the test error on 16 out of 19 datasets.

**Analysis of experiments with various open LLMs.** We evaluate how our method performs with various types of LLMs, we assess the performance of several open LLMs as rule generators. As shown in Table 4, while all models yield improvements over the baseline, we find our own model (_i.e._, Llama 2 fine-tuned on UltraChat) to be particularly effective. This shows that our framework can be effectively implemented even with open models at a moderate scale, especially those with sufficiently strong chat capabilities. We suspect that this improvement stems from the enhanced ability of these models to understand and generate contextually relevant and

   Method & LLM & Size & Avg. Err. \\  XGBoost & - & - & 16.53\(\)0.1 \\
**OCTree** & Llama 2 Chat & 7B & 16.32\(\)0.1 \\
**OCTree** & Code Llama & 7B & 15.83\(\)0.2 \\
**OCTree** & **Ours** & 7B & **15.71\(\)0.4** \\   

Table 4: **OCTree with Llama 2 variants.** We report the average test error rates (%) and standard deviations across three random seeds on the 19 datasets without language descriptions.

    &  &  \\  Method & w/o descriptions & w/ descriptions & LLM & Avg. Err. (\%) \\  Baseline & - & - & - & 25.87\(\)2.2 \\ AutoFeat  & ✓ & ✗ & - & 25.76\(\)2.1 (0.4\%) \\ OpenFE  & ✓ & ✗ & - & 26.44\(\)1.7 ( N/1 ) \\ CAAFE  & ✗ & ✓ & GPT-4o & 25.43\(\)2.2 (1.7\%) \\ 
**OCTree (Ours)** & ✓ & ✓ & 
 Llama 2 \\ GPT-4o \\  & 25.12\(\)1.9 (2.9\%) \\   

Table 2: **Applicability and comparison of automated feature engineering methods.** We report the mean error (%) and standard deviation across the six datasets with language descriptions used in Tables 1 and 13. The lowest error is highlighted in **bold**. Values in parentheses indicate the relative error rate reduction from the baseline model (_i.e._, XGBoost ), while N/I indicates no gain.

[MISSING_PAGE_FAIL:8]

feedback. However, providing the decision tree as feedback to the LLM can lead to even better performance. We believe that decision tree reasoning, which highlights important columns and their threshold values, enables the LLM to understand the data better, resulting in the generation of more contextually relevant and useful rules. Moreover, decision trees can be easily represented in natural language using if-else syntax, effectively conveying the information about the data to the LLM.

**Transferring generated rules to other prediction models.** While we optimize feature generation rules to improve the performance of a specific prediction model, the generated features can also be utilized in other models to achieve similar improvements. For example, it would be more efficient to generate features using XGBoost, which typically trains and evaluates faster than larger deep neural networks, and then apply these features to more complex models. To assess whether such feature transfer is feasible within our framework, we first optimize the column generation rules using XGBoost and then train MLP and HyperFast models with the generated features. As shown in Table 7, these features significantly improve the performance of both models, demonstrating the effectiveness of this approach, especially when only limited computational resources are available.

**Evaluating the validity of generated features.** The rule generator LLM is asked to recommend a new column feature that is not already present in the dataset. Here, we evaluate whether the LLM is capable of generating features that are, in fact, valid and relevant to the target task. We perform this analysis from two perspectives: (i) whether the LLM can identify the most relevant column feature when provided with multiple candidate columns, and (ii) whether using real-world data, when available, for the suggested column leads to improved performance of prediction models.

Our method is based on the assumption that sufficiently capable LLMs can understand the relationship between the target task and column features, enabling them to generate new, relevant features for the task. To evaluate this assumption, we first examine whether the LLMs can identify the features that are more relevant to the prediction task. For this experiment, we begin by removing two existing features from a dataset and then prompt the LLM to rank the two features according to their importance for the target task. Specifically, we remove 'CholesterolLevel' and 'Cough' from the original Disease dataset and then ask the LLM to identify the attribute more relevant to predicting whether a patient has a disease. Both the GPT-40 and Llama 2 models indicate that 'Cough' is more important than 'CholesterolLevel'. As shown in Table 8, XGBoost achieves a lower error rate when trained with the 'Cough' feature compared to when trained with 'CholesterolLevel', which is consistent with the LLMs' assessment that the former is more relevant to the task.

   Gen. Feat. & DT Reasoning & Disease\({}^{*}\) & Clinical\({}^{*}\) & electricity\({}^{}\) & kddCap09\({}^{}\) \\  - & - & 28.09\(\)7.9 & 46.27\(\)5.0 & 8.32\(\)0.0 & 19.86\(\)1.1 \\ ✓ & ✗ & 27.62\(\)8.4 (1.7\%) & 45.61\(\)4.1 (1.4\%) & 6.89\(\)0.6 (17.2\%) & 19.47\(\)1.6 (2.0\%) \\ ✓ & ✓ & **26.19\(\)7.2 (6.8\%)** & **45.07\(\)**4.1 (2.6\%)** & **6.65\(\)**0.1 (20.1\%)** & **19.07\(\)**4 (4.0\%)** \\   

Table 6: **Ablation study of the proposed decision tree reasoning.** We report the mean error (%) and standard deviation across three random splits on two datasets with language descriptions (\({}^{*}\)) and two datasets without language descriptions (\({}^{}\)). The lowest error is highlighted in **bold**. Values in parentheses indicate the relative error rate reduction from the baseline model.

    &  &  \\  Dataset & Baseline & **OCTree\({}_{}\) (Ours)** & Baseline & **OCTree\({}_{}\) (Ours)** \\  Disease\({}^{*}\) & 38.10\(\)3.6 & **35.24\(\)**4.4 (7.5\%)** & 28.57\(\)10.0 & **27.62\(\)**5.8 (5.8\%)** \\ Clinical\({}^{*}\) & **41.77\(\)**1.2 & 42.32\(\)2.3 ( N/I ) & 43.64\(\)1.1 & **42.76\(\)**1.8 (2.0\%)** \\ electricity\({}^{}\) & 15.64\(\)0.3 & **15.03\(\)**0.3 (**3.9\%)** & 15.37\(\)0.4 & **14.88\(\)**0.2 (3.2\%)** \\ kddCap09\({}^{}\) & 24.30\(\)0.3 & **23.47\(\)**0.5 (**3.4\%)** & 25.62\(\)0.7 & **25.22\(\)**0.9 (1.6\%)** \\   

Table 7: **Performance improvement through feature transfer.** We optimize the feature generation rule using XGBoost and transfer the generated features to improve MLP and HyperFast (OCTree\({}_{}\)). We report the test error rates (%) and standard deviation across three random seeds for two datasets with language descriptions (\({}^{*}\)) and two datasets without (\({}^{}\)). The lowest error is in **bold**, with values in parentheses indicating the relative error rate reduction from the baseline model. N/I denotes cases where no improvement was observed.

Building on the LLM's ability to identify important features for the target task, we further assess whether the generated columns can be imputed with real-world data to enhance prediction. In this experiment, we use the Clinical Trial dataset, where the LLM introduced the column 'Age' when prompted to suggest a new column. We then incorporated real-world age data from the US National Library of Medicine to augment the original dataset. As shown in Figure 3, training on this augmented data results in a notable improvement, demonstrating that the LLM-generated columns align well with real-world data. In conclusion, we recommend that practitioners utilize OCTree to either (i) identify additional column features and collect the corresponding real-world data or (ii) optimize feature generation rules in the absence of real-world data.

**Analysis of the rule optimization process.** We analyze how the output rules evolve throughout the optimization rounds on the electricity dataset. Due to space constraints, we show the first and last five output rules in Appendix H. In the early stages of optimization, the LLM generates a diverse range of outputs, indicating an active exploration of potential rules. In contrast, during the later stages, the LLM focuses on refining the solution space around previously identified rules, making only minor adjustments. This again demonstrates that with appropriate guidance through the optimization process, sufficiently capable LLMs can serve as highly effective optimizers.

**Handling hallucinations.** While LLMs may occasionally suggest suboptimal or semantically incoherent rules, our method is designed to address these hallucinations. Specifically, we provide feedback on previously generated rules to guide the LLMs in iteratively improving the rule generation. This feedback loop helps the LLMs avoid hallucinations that might lead to low validation scores in subsequent iterations. Empirically, we find that these issues are more common in the early stages when the LLMs explore the rule space more broadly and in less capable models, _e.g._, those without additional training on dialogue or code generation data.

## 5 Conclusion

In this paper, we propose OCTree, a generic framework that leverages the power of LLMs (_e.g._, reasoning capability) for automatically generating column features for tabular prediction tasks. We evaluate the effectiveness of OCTree across various prediction tasks and demonstrate that our method consistently enhances the performance of diverse prediction models, often significantly more effectively than competing feature engineering methods. As future work, exploring feedback-based alignment methods, such as reinforcement learning from human feedback, to further enhance LLMs as rule generators would be an exciting direction to explore.

**Limitation.** One potential limitation of our work is that evaluating the generated features involves computing the validation scores of the prediction model, which can be time-consuming if the model requires extensive training. However, as demonstrated by the results in Table 7, this issue can be mitigated by first generating features with a simpler prediction model and then transferring those features to the target model, reducing the overall runtime and computational requirements.

   Column feature & Model \\  Cough & Cholesterol & XGBoost \\  ✗ & ✗ & 34.76\(\)0.8 \\ ✗ & ✓ & 33.34\(\)0.8 \\ ✓ & ✗ & 30.00\(\)4.3 \\ ✓ & ✓ & 28.09\(\)7.9 \\   

Table 8: **LLM identifies important features.** We report the mean error (%) and standard deviation across three random splits on the Disease dataset. Both GPT-40 and Llama 2 identify the cough feature as more important, consistent with the accuracy seen in XGBoost models trained with and without these features.

Figure 3: **Imputing features with real data, _i.e._, _Age_. We report the mean accuracy (%) across three random splits on the Clinical dataset using XGBoost.**