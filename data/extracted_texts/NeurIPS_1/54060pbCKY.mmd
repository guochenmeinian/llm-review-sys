# Towards Faster Quantum Circuit Simulation Using Graph Decompositions, GNNs and Reinforcement Learning

Towards Faster Quantum Circuit Simulation Using Graph Decompositions, GNNs and Reinforcement Learning

Alexander Koziell-Pipe1  Richie Yeung1  Matthew Sutcliffe1

Department of Computer Science

University of Oxford

Oxford, UK

[firstname.lastname]@cs.ox.ac.uk

###### Abstract

In this work, we train a graph neural network with reinforcement learning to more efficiently simulate quantum circuits using the ZX-calculus. Our experiments show a marked improvement in simulation efficiency using the trained model over existing methods that do not incorporate AI. In this way, we demonstrate a machine learning model that can reason effectively within a mathematical framework such that it enhances scientific research in the important domain of quantum computing.

In the present-day 'Noisy Intermediate Scale' (NISQ) era of quantum computing , quantum resources are still largely limited. Given this limit on quantum resources, being able to simulate quantum computations efficiently and at scale on classical hardware can accelerate quantum computing research and set a standard for benchmarking quantum computers.

While in general quantum circuit simulation can be #P-hard , a subclass of quantum circuits known as stabiliser circuits can be simulated in polynomial time with respect to size . Hence a technique for simulating quantum circuits is to decompose them into an ensemble of efficiently simulated stabiliser circuits, the aggregation of which simulates the same computation as the original circuit. Decompositions are calculated iteratively, where sub-circuits are decomposed in a sequential manner until the ensemble of stabiliser circuits is achieved. At each step in the decomposition, the choice of sub-circuit to decompose can greatly affect the number of stabiliser circuits that need to be simulated at the end - in the worst case, this is exponential with respect to the number of a certain type of gate, called a \(T\)-gate, in the original circuit.

In this work, we formulate the challenge of choosing good sub-circuit decompositions as a reinforcement learning problem, where an agent learns to make decisions in a combinatorially large action space. To facilitate this, we utilise a mathematical framework known as the ZX-calculus, in which quantum circuits are represented as graphs and reasoning amounts to a set of rules allowing one graph to be transformed into another. Formulating our problem in terms of graphs enables the use of Graph Neural Networks (GNNs), which have seen promising applications in other scientific domains including bioinformatics , social networks , and combinatorial optimisation .

We show that, for classes of quantum circuit known not to be efficiently classically simulated, our GNN agent trained using reinforcement learning achieves significantly more efficient decompositions compared to current methods that do not incorporate AI. Moreover, we show that additional algebraic rules can be added to the decomposition strategy to achieve even further improvements in simulation efficiency. As such, our model demonstrates the ability of an AI-agent to reason about a task that typically requires strong mathematical reasoning skills and a deep understanding of the algebraic structures underlying quantum circuits. Furthermore, it improves our capacity to conduct scientific research in the increasingly important field of quantum computing.

## 1 ZX-Calculus

Quantum algorithms can be expressed graphically in circuit notation, with quantum gates composed together in a time-ordered structure. The ZX-calculus , offers a powerful alternative which has proven effective for reasoning about quantum computing problems such as circuit compilation and optimisation  as well as classical simulation . In our work we use a variation of the ZX-calculus comprised of graphs whose vertices, called _spiders_, are labelled by a real number \([0,2)\) (the _phase_) and two types of edges:

\[}1&0& &0\\ 0&0&&0\\ &&&\\ 0&0&&e^{i}} 1&0\\ 0&1\]

The way spiders are wired together by edges in a ZX-diagram with \(m\) inputs and \(n\) outputs determines a matrix in \(^{2^{n} 2^{m}}\). Furthermore, wiring the inputs of one diagram to the outputs of another amounts to multiplication of their respective matrices, while juxtaposing two diagrams in parallel amounts to taking the Kronecker product. Indeed, for arbitrary \(m,n\) the ZX-calculus is sufficient to express any matrix in \(^{2^{n} 2^{m}}\), hence any quantum circuit acting on qubits. In particular, standard gates in quantum computing may be expressed as ZX-diagrams:

\[}}}}}}}}}}}}}}}}}\]

Note that when no number is present on a spider, the phase is implicitly taken to equal \(0\). Diagrams may be deformed arbitrarily and still represent the same quantum computation, provided the graph topology is conserved. They may also be modified using _rewrite rules_, which express how subdiagrams may be replaced without changing the semantics (the matrix they represent) :

\[}}} }}} }}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}_{5}\) decomposition, introduced by Kissinger et al. :

**Lemma 1**.: _The \(|_{5}\) decomposition :_

_exchanges a set of \(5\) T-spiders for \(3\) partial stabiliser terms._

This decomposition removes \(4\) T-spiders at the cost of replacing a single graph term with \(3\) terms. Efficient decompositions for Clifford+T diagrams remove hard-to-simulate T-spiders while introducing as few new terms as possible in the weighted sum. We quantify this efficiency via the _decomposition efficiency coefficient_\(\), defined as follows:

**Definition 1**.: _The efficiency of a particular decomposition can be measured via:_

\[:=N}{t}\]

_where \(N\) is the number of terms produced and \(t\) is the number of T-spiders removed by the decomposition. The overall efficiency of a sequence of decompositions and diagram rewrites, \(_{}\), can be measured similarly._

A lower \(\) means a more efficient decomposition. For the \(|_{5}\) decomposition of equation (1), the efficiency is \( 0.396\). In practice, the decomposition is applied to a sub-circuit, and after diagram rewrites have been applied to the resulting terms, the number of T-spiders remaining may be reduced even further. This can lead to an \(_{}\) far lower than \(0.396\).

The present state-of-the-art-algorithm  deterministically applies efficient structure-specific decompositions (see appendix A) wherever applicable, relying on the \(|_{5}\) decomposition only when these structures are no longer found. In each case, this algorithm selects the \(5\) T-spiders upon which to apply this decomposition at random. However, we emphasise that this choice of \(5\) T-spiders greatly influences the effective \(\) during a sequence of decompositions and diagram rewrites. As such, selecting spiders that lead to more efficient decompositions, thus yielding fewer stabiliser terms to simulate overall can significantly reduce the computational cost of strong simulation. It is this problem of selecting spiders giving more efficient decompositions that we tackle using AI.

## 3 Experiments

**Data Generation** Training, validation and test data is generated using PyZX: the Python library for quantum circuit rewriting and optimisation using the ZX-calculus . We generate three different types of ZX-diagrams: 1. Clifford+T quantum circuits, 2. grid-like diagrams, and 3. random graphs generated using the \(G(n,m)\) Erdos-Renyi model . Generating random samples from these 3 classes of diagram requires specifying parameters determining the diagram size and phases that appear on the spiders. Specific parameter details used for generating the data can be found in the appendix section C.1.

**GNN Architecture** We use a graph attention network (GAT) -based architecture. For the reinforcement learning algorithm used, the full architecture is divided into a features extractor, policy network and value network. The features extractor processes the input graph. The output of the features extractor is then fed into two separate networks: a policy network, which outputs a probability distribution used to sample vertices for the graph decomposition; and a value network, which assesses the relative value of the current state in the reinforcement learning environment. The value network is only used during training and is not required at inference time.

The features extractor consists of 8 GAT layers each with 4 attention heads and embedding dimension of 64. The policy and value networks follow a transformer-style architecture, consisting of blocks of alternating GAT layers with MLP layers. Residual connections, GELU activations, Graph normalisation layers , and layer normalisation  layers are used. We note the similarity of the policy and value network architectures to a standard transformer architecture , with attention layers replaced with GAT layers, and some layer normalisations replaced with graph normalisation. For further details on the architecture, see appendix section C.2.

**Reinforcement Learning Setup** We train the model using the Proximal Policy Optimisation (PPO) reinforcement learning (RL) algorithm  with an adapted version of generalized advantage estimation . Observations in the RL environment are graphs, actions are vertices to which the \(|_{5}\) decomposition (1) is applied, and rewards are the effective \(\)-efficiencies of applying \(|_{5}\) to these particular vertices. Further details are given in the appendix section C.3. Data is sampled randomly during training, and intra-training performance is assessed on a validation dataset. We save model weights achieving the best performance on the validation set during a random hyperparameter search; hyperparameters for the top performing weights are listed in table 1, appendix section C.4.

**Evaluation & Results** We evaluate the models on an unseen test dataset. The best model obtains a mean effective \(\) of \(0.263\): a marked improvement over selecting the vertices for the decomposition randomly as in Kissinger et al. , which achieves \(0.293\) on the same data. Note that an asymptotic decrease in \(\) leads to an exponential factor speed-up. As an additional investigation, we compare efficiency coefficients when augmenting both methods with an additional set of decompositions, called the \(|_{n}\) decompositions (see appendix A). In both cases, the decompositions are applied according to the algorithm in Kissinger et al.  which is the best, to our knowledge, heuristics-based algorithm using \(|_{n}\) and \(|_{5}\). In this experiment, the model achieves a mean effective \(\) of \(0.232\), versus \(0.235\) for . This improvement in effective \(\) is highlighted by figure 0(a). These results are further summarised appendix D.

Moreover, when looking at the number of stabiliser terms to simulate after decomposition, our model observes better scaling behavior as the number of T-spiders, which comprise the non-stabiliser components of the ZX-diagrams, increases - see figure 0(b). We hypothesise that this is because the message passing performed by the graph neural network permits, within a limited neighborhood, broader contextual information about the diagram to be taken into account when choosing the site of a decomposition, whereas the heuristic method of  does not.

Figure 1: Comparison of our trained model versus Kissinger et al. 

## 4 Discussion

Our experiments have shown that a machine learning model can be perform effective mathematical reasoning, with applications to the domain of quantum computing. This was enabled by an algebraic framework: the ZX-calculus, which allowed the task of simulating quantum circuits to be formulated in terms of graphs, making the problem amenable to graph neural networks. Furthermore, the algebraic nature of the ZX-calculus provided a way of designing a reinforcement learning environment in which to learn the circuit simulation task. The trained model showed a marked improvement in simulation efficiency over existing methods without the use of AI.

These initial results are extremely promising: our methodology could be extended to include a broader set of decompositions into the model's action space. Recent work has shown that heuristics-based applications of decompositions, such as in [2; 3; 34], are remarkably effective for a broad range of quantum circuits. We also note that the ZX-calculus has applications to many other problems in quantum computing beyond circuit simulation. This suggests that similar approaches applying AI to other pertinent areas of quantum computing research, such as circuit optimisation and error correction, could be facilitated by the ZX-calculus in the same manner. Typically, these problems are solved by domain experts due to a solid understanding of the mathematics required. Our work suggests, however, that given a sufficient framework within which to perform reasoning, a machine learning model can learn to solve these mathematics-intensive problems. Indeed, it is clear that the ability of AI to solve problems requiring a high-level mathematical understanding can significantly enhance research and engineering across a broad range of scientific domains.