# Unsupervised Image Denoising with Score Function

Yutong Xie

Peking University

yutongxie_research@163.com &Mingze Yuan

Peking University

mzyuan@pku.edu.cn Bin Dong

Peking University

dongbin@bicmr.pku.edu.cn &Quanzheng Li

Massachusetts General Hospital and Harvard Medical School

li.quanzheng@mgh.harvard.edu

###### Abstract

Though achieving excellent performance in some cases, current unsupervised learning methods for single image denoising usually have constraints in applications. In this paper, we propose a new approach which is more general and applicable to complicated noise models. Utilizing the property of score function, the gradient of logarithmic probability, we define a solving system for denoising. Once the score function of noisy images has been estimated, the denoised result can be obtained through the solving system. Our approach can be applied to multiple noise models, such as the mixture of multiplicative and additive noise combined with structured correlation. Experimental results show that our method is comparable when the noise model is simple, and has good performance in complicated cases where other methods are not applicable or perform poorly.

## 1 Introduction

Image denoising  has been studied for many years. Suppose \(\) is a clean image, \(\) is a noisy image of \(\), and \(p()\) is the noise model. Supervised learning methods try to train a model representing a mapping from \(\) to \(\). Due to the difficulty of collecting paired clean and noisy images in practice, methods in unsupervised learning manner are focus of research. Noise2Noise  is the first to use pairs of two different noisy images constructed from the same clean image to train a denoising model. Strictly speaking, Noise2Noise is not an unsupervised learning method. Collecting noisy pairs is still difficult. Despite all this, many other methods  are inspired from Noise2Noise or borrow the idea behind of it. These methods achieve good performance in some simple noise models.

The main drawback of current methods is the constraint of application. Once the noise model is complicated, they either are not applicable or have poor performance. Noisier2Noise  can only handle additive noise and pepper noise. Recorrupted-to-Recorrupted  is limited to Gaussian noise. Neighbor2Neighbor  requires that the noise model is pixel-wise independent and unbiased (_i.e._\([]=\)). Noise2Score  applies Tweedie's Formula to image denoising and provides a unified framework for those noise models that follow exponential family distributions. However, the practical noise model will be more complicated. It may contain both multiplicative and additive noise, even combining with structural correlation.

In this paper, we propose a new unified approach to handle more noise models. The key of our approach is a theoretical property about score function, \(_{} p()\), which is shown in Proposition 3.1. This property indicates that the score function of \(\) is the average of the score function of \(\) under the posterior distribution \(p()\). Based on it, we define a system that the score function of \(\) equals to the score function of \(\), which turns out to be an equation about \(\) since \(\) is known. Wediscover that the solution of this equation can be regarded as the denoised result of \(\). Implementing our approach practically contains two steps: the first is to estimate the score function of \(\) and the second is to solve the system defined above according to the specific noise model. The overall flow is shown in Figure 1. All the model training is the estimation of score function, which is represented by a neural network. We adapt the amortized residual denoising autoencoder (AR-DAE)  to figure out it. More details can be seen in Section 3.3.

Our approach is so powerful that as long as the score function of \(\) is known and the system is solvable, any kind of noise model is applicable. It means our approach is even able to solve sophisticated noise models such as mixture noise. Another advantage of our approach is that regardless of noise models, the training process of the score function neural network is identical. Therefore, once the assumption of the noise model does not hold or parameters of noise are corrected, we only change the equation system to be solved and resolve it without training the model again. In summary, our main contribution are: (1) We propose a general unsupervised approach for image denoising, which is based on the score function. (2) Experimental results show that our approach is competitive for simple noise models and achieves excellent performance for complicated noise models where other unsupervised methods is invalid.

## 2 Related Works

Here we briefly review the existing deep learning methods for image denoising. When the pairs of clean images and noisy images are available, the supervised training  is to minimize \(_{,}[(,f(;))]\), where \(f(;)\) is a neural network and \((,)\) is a distance metric. Though supervised learning has great performance, the difficult acquisition for training data hampers its application in practice.

To avoid the issues of acquisition for paired clean and noisy images, unsupervised1 approaches are proposed to use noisy image pairs to learn image denoising, which is started from Noise2Noise (N2N) . While N2N can achieve comparable results with supervised methods, collecting noisy image pairs from real world is still intracTable Motivated by N2N, the followed-up works try to learn image denoising with individual noisy images. Mask-based unsupervised approaches  design mask schemes for denoising on individual noisy images and then they train the network to predict the masked pixels according to noisy pixels in the input receptive field. Noise2Void  also proposes the blind-spot network (BSN) to avoid learning the identity function. Noisier2Noise , Noisy-A-Clean  and Recorrupted-to-Recorrupted  require a single noisy realization of each training sample and a statistical model of the noise distribution. Noisier2Noise first generates a synthetic noisy sample from the statistical noise model, adds it to the already noisy image, and asks the network to predict the original noisy image from the doubly noisy image. Besides the blind-spot network design, Self2Self  is proposed on blind denoising to generate paired data from a single noisy image by applying Bernoulli dropout. Recently, Neighbor2Neighbor  proposes to create subsampled paired images based on the pixel-wise independent noise assumption and then a denoising network is trained on generated pairs, with additional regularization loss for better performance. Noise2Score  is another type of unsupervised methods that can deal with any noise model which follows an exponential family distribution. It utilize Tweedie's Formula [21; 6] and the estimation of score function to denoise noisy images.

Figure 1: The overall flow of our approach. The first step is to estimate the score function \(()\) and the second step is to solve an equation.

[MISSING_PAGE_FAIL:3]

**Theorem 3.1**: _Given \(\), suppose the Hessian matrix \((,)\) is bounded, \((,)\) is invertible with respect to \(\), and its inverse function is Lipschitz continuous. Denote \(}\) as the solution of Eq. 7, then,_

\[\|}-_{}[]\|_{2 } C([])+o( ([])), \]

_where \([]\) is the covariance matrix and \(C\) is a constant._

The proof of Theorem 3.1 is in Supplementary Material. Theorem 3.1 shows the lower noise level, the smaller the error between \(}\) and \(_{}[]\), which guarantees the effectiveness of proposed method.

Next, in Section 3.2 we will derive the specific algorithm for solving \(\) in Eq. 7 under different noise models, including additive Gaussian noise in Section 3.2.1, multiplicative noise in Section 3.2.2 and mixture noise in Section 3.2.3. Estimating score function \(()\) will be introduced in Section 3.3.

### Application Examples

#### 3.2.1 Additive Gaussian Noise

Suppose the noise model is \(=+\) where \(\) follows a multi-variable Gaussian distribution with mean of \(\) and covariance matrix of \(\) denoted by \((,)\), _i.e._

\[p()=(-)^{}^{-1}(-)\}}{}||^{}} \]

Then, we derive that \((,)=_{} p( )=-^{-1}(-)\). We consider the following four kinds of \(\): (1) \(=^{2}\); (2) \(=^{2}^{}\); (3) \(=()=(a+b )^{2}\); (4) \(=()=^{}(a +b)^{2}\). In the second and fourth cases, \(\) usually represents a convolution transform which describes the correlation between adjacent pixels.

For the first and second cases, \(\) is a constant matrix. By solving Eq. 7, we have

\[}=()+. \]

While in the third and fourth cases, \(\) is related to \(\) and Eq. 10 is a fixed point equation. Therefore, we use an iterative trick to solve it as shown in Algorithm 2.

```
0: noisy image \(\), \(()\), the parameters of \(()\) and the number of iterations \(n\).
0:\(}\), the solution.
1: Initial value of \(}\) is set as \(\).
2:for\(i=1,...,n\)do
3:\(}(})( )+\).
4:endfor
```

**Algorithm 2** An iterative trick to solve \(=()()+\)

#### 3.2.2 Multiplicative Noise

Firstly, we discuss three types of multiplicative noise model, Gamma, Poisson and Rayleigh noise. Then, we consider the situation where the convolution transform \(\) exists.

**Gamma Noise** is constructed from Gamma distribution, \((,)\): \(p(x;,)=}{()}x^{-1}e ^{- x}\), and is defined as \(=\), where \(_{i}(,)\), \(>1\), and \(\) means component-wise multiplication, _i.e._

\[p()=_{i=1}^{d}}{ ()}(}{x_{i}})^{-1}\{- }{x_{i}}\}}. \]Then, we derive that \((,)=_{} p( )=}-}\). Here, the division is component-wise division. In the residual part of this paper, we neglect such annotation if it is not ambiguous. By solving Eq. 7, we have

\[}=}{-1-()}. \]

**Poisson Noise** is constructed from Poisson distribution, \(()\): \((x=k)=}{k!}e^{-},k=0,1,\), and is defined as \(=\), \(_{i}( x_{i})\), \(>0\), _i.e._

\[()=_{i=1}^{d} )^{_{i}y_{i}}}{( y_{j})!}e^{- x_{i}}. \]

Then, we derive that \((,)=_{}( )=()-(+ )\). By solving Eq. 7, we have

\[}=(+)\{()}{}\}, \]

**Rayleigh Noise** is constructed from Rayleigh distribution, \(()\): \(p(x;)=}\{-}{2^{2}}\}\), and is defined as \(=(+)\), \(_{i}()\), \(>0\), _i.e._

\[p()=_{i=1}^{d}}-x_{i} }{x_{i}^{2}}\{--x_{i})^{2}}{2x_{i}^{2} ^{2}}\}. \]

Then, we derive that \((,)=_{} p( )=-}--}{^{2}^{2}}\). Solving Eq. 7 directly is not easy. Here we provide an iterative algorithm to solve it. It is illustrated in Algorithm 3.

```
1: noisy image \(\), \(()\), the parameter of Rayleigh noise \(\) and the number of iterations \(n\).
2:\(}\), the solution of Eq. 7.
3: Initial value of \(}\) is set as \(\).
4:for\(i=1,...,n\)do
5: Compute \(=^{2}()}\).
6: Compute \(=(-++4^{2}})\).
7:\(}}{+}\).
8:endfor
```

**Algorithm 3** An iterative method to solve Eq. 7 in the case of Rayleigh noise

Now, we consider the situation where the convolution transform \(\) exists. Suppose the noise model is represented by \(=\), \(=N()\), where \(N()\) can be any multiplicative noise model discussed above. Then, we have \(_{} p_{}()=^{-1,} _{} p_{}(^{-1})\). To avoid confusion, we use subscripts to distinguish different distribution. Therefore, we can apply Algorithm 4 to solve Eq. 7, which is shown as follows.

```
1:\(\), \(()\), \(\) and \(}(,)=_{} p_{}( )\).
2:\(}\), the solution of Eq. 7.
3: Computing \(}=^{}()\).
4: Computing \(=^{-1}\).
5: Solve \(}=}(,)\) by the corresponding Algorithm
```

**Algorithm 4** The general framework to solve Eq. 7 for correlated multiplicative noise model

#### 3.2.3 Mixture Noise

In this paper, the mixture noise model is composed of a multiplicative noise and an additive Gaussian noise. We denote it as \(=+,(0,^{2})\), \(=N()\), where \(N()\) is any multiplicative noise model that can be solved by our approach and \(\) is either a convolution transform or identity matrix. It is easy to derive that \(p_{}()= p_{}( )p_{}()\). Generally speaking, \(p_{}()\) has not an explicit analytical form. In this paper, we assume that the additive Gaussian noise is far smaller than the multiplicative noise. Thus, we utilize Taylor expansion to approximate \(p_{}()\). We have the following conclusion:

\[p_{}() p_{}(})+_{}p_{}(} )^{T}(-}), \]

where \(}=[]\). Then, we can further derive that

\[_{} p_{}()_ {} p_{}(}). \]

The full and rigorous derivations of Eq. 16 and Eq. 17 are in Supplementary Material. Applying Eq. 10 in Section 3.2.1, we have \(}=+^{2}()\). Thus, the equation to be solve is \(()=(,})\). The full denoising process is illustrated in Algorithm 5.

```
0:\(\), \(()\).
0:\(}\), the solution of \(()=(,})\).
1: Computing \(}=+^{2}()\).
2: Solve \(()=(,})\) through the corresponding algorithm discussed in Section 3.2.2.
```

**Algorithm 5** The full denoising process for mixture noise \(=+\)

### Estimation of Score Function

So far, we assume that the score function of \(\), \(()\), is known. However, it is usually unknown and should be estimated from the dataset of noisy images \(\{\}\). We use the same method, the amortized residual Denoising Auto Encoder (AR-DAE)  discussed in Noise2Score. Suppose \((;)\) is a neural network used to represent the score function of \(\). The following objective function is used to train the model:

\[L=_{,(,)}\| {u}+_{a}(+_{a};)\|_{2}^{2 }, \]

where \(_{a}\) is a fixed value. Given \(_{a}\), the optimal model \((;^{*})\) that minimizes \(L\) is the score function of perturbed \(\), \(+_{a}\). In other words, we can approximate the score function \(()\) by using a sufficiently small \(_{a}\). Related analysis can also be seen in [8; 23; 1]. During the training process, the value of \(_{a}\) will be decreasing gradually to a very small value. This progressive process is helpful to numerically stabilize the model training. The only model training is to estimate \(()\) by \((;)\), which is served as the first step of our approach. After the score function model is trained, we apply the denoising algorithms given in Section 3.1 to obtain denoised results and no more training is required.

## 4 Experiment

Dataset and Implementation DetailsWe evaluate the proposed method for color images in the three benchmark datasets containing RGB natural images: Kodak dataset, CBSD68  and CSet9. DIV2K  and CBSD500 dataset  are used as training datasets. The synthetic noise images for each noise model are generated and fixed through the training process. For the sake of fair comparison, we use the same modified U-Net  for all methods. When training, we randomly clip the training images to patches with the resolution of \(128 128\). AdamW optimizer  is used to train the network. We train each model for 5000 steps with the batch size of 32. To reduce memory, we utilize the tricks of cumulative gradient and mixed precision training. The learning rate is initialized to \(1 10^{-4}\) for first 4000 steps and it is decreased to \(1 10^{-5}\) for final 1000 steps. All the models are implemented in PyTorch  with NVidia V100. The pixel value range of all clean images is \(\) and the parameters of noise models are built on it. Noisy images will be scaled when fed into the network. When an iterative algorithm is needed to solve Eq. 7, we set the number of iterations as \(10\). The more details of implementation are described in Supplementary Material.

Baseline and Comparison MethodsWe use supervised learning with MSE loss as the baseline model. Noisier2Noise and Neighbor2Neighbor are used as comparison methods. Since our approach is identical to Noise2Score when the noise model follows exponential family distributions, we do not compare to it through metrics. Because Noisier2Noise can only be applied to additive noise, we do not train models by Noisier2Noise for other noise models. Though Neighbor2Neighbor is not suitable for some noise models from the perspective of theoretical analysis, we still train corresponding models and report its results. Table 1 shows the comparison of application range for different methods, including additive Gaussian noise, multiplicative noise and mixture noise. Based on it our experiments are conducted. Only supervised learning and our approach can handle all noise models listed in Table 1.

Parameters of Noise ModelsHere, we emphasize that for all noise models in our experiments, \(\) is set as a \(3 3\) convolution transform with the kernel of

\[0.05&0.1&0.05\\ 0.1&0.4&0.1\\ 0.05&0.1&0.05 \]

if it is used. The additive Gaussian noise in every mixture noise model is set as \((,100)\). Other parameters will be given later. Finally, all parameters are assumed to be known in our experiments.

Additive Gaussian NoiseUsing additive Gaussian noise, we consider four kinds of noise models with different \(\) corresponding from No.1 to No.4 in Table 1. Our method is compared to supervised learning, Noisier2Noise and Neighbor2Neighbor as shown in Table 2. For the first two noise models \(\) is \(25\), and for the rest \(a=0.98\) and \(b=25\). As expected, supervised learning performs best. In the cases without \(\) Neighbor2Neighbor is the best among three other unsupervised learning methods. However, in the cases with \(\) Neighbor2Neighbor performs very poorly. Our approach outperform other unsupervised learning methods in the second noise model and is competitive in the whole.

Multiplicative NoiseWe consider the combination of three various multiplicative noise model (Gamma, Poisson and Rayleigh) and a convolution transform \(\). They are corresponding from No.\(5\) to No.\(10\) in Table 1. Our method is compared to supervised learning and Neighbor2Neighbor and the results are shown in Table 3. Because Noisier2Noise can not address such multiplicative noise models, we neglect it. Though the noise is not pixel-wise independent when the convolution transform exists,

  No. & Noise Model & SL & Nr2N & Nb2Nb & N2S & Ours \\ 
1 & \(=+,(,^{2} )\) & ✓ & ✓ & ✓ & ✓ & ✓ \\
2 & \(=+,(,^{2} ^{})\) & ✓ & ✓ & \(^{*}\) & ✓ & ✓ \\
3 & \(=+,(,(a+b)^{2})\) & ✓ & ✓ & ✓ & \(\) & ✓ \\
4 & \(=+,(,^{ }(a+b)^{2})\) & ✓ & ✓ & \(^{*}\) & \(\) & ✓ \\
5 & \(=,_{i}(,)\) & ✓ & \(\) & ✓ & ✓ & ✓ \\
6 & \(=,_{i}(,)\) & ✓ & \(\) & ✓* & ✓ & ✓ \\
7 & \(=,_{i}( x_{i})\) & ✓ & \(\) & ✓ & ✓ & ✓ \\
8 & \(=,_{i}( x_{i})\) & ✓ & \(\) & ✓* & ✓ & ✓ \\
9 & \(=(+),_{i}( )\) & ✓ & \(\) & \(^{*}\) & \(\) & ✓ \\
10 & \(=(+),_{i}( )\) & ✓ & \(\) & \(^{*}\) & \(\) & ✓ \\
11 & \(=+,_{i}(, ),(0,^{2})\) & ✓ & \(\) & ✓ & \(\) & ✓ \\
12 & \(=+,_{i}( ,),(0,^{2})\) & ✓ & \(\) & \(^{*}\) & \(\) & ✓ \\
13 & \(=+,_{i}(  x_{i}),(0,^{2})\) & ✓ & \(\) & ✓ & \(\) & ✓ \\
14 & \(=+,_{i} ( x_{i}),(0,^{2})\) & ✓ & \(\) & \(^{*}\) & \(\) & ✓ \\
15 & \(=(+),_{i}( ),(0,^{2})\) & ✓ & \(\) & \(^{*}\) & \(\) & ✓ \\
16 & \(=(+),_{i} (),(0,^{2})\) & ✓ & \(\) & \(^{*}\) & \(\) & ✓ \\  

Table 1: The application range of different methods including supervised learning (SL), Noisier2Noise (Nr2N), Neighbor2Neighbor (Nb2Nb), Noise2Score (N2S) and ours. ✓ means applicable and \(\) means not applicable or incapable to perform. For Neighbor2Neighbor, ✓\({}^{*}\) means that direct application is not feasible but indirect application is; \(^{*}\) means that the application is not feasible but model training is executable.

we can execute its inverse transform on \(\) so that the requirement of pixel-wise independence is satisfied for Neighbor2Neighbor. Therefore, tackling noise models with a convolution transform is equivalent to the situations without \(\). That is why we do not provide corresponding metrics result for Neighbor2Neighbor in Table 3. We set \(\) as \(26\) for the Gamma noise, \(\) as \(0.2\) for the Poisson noise, and \(\) as \(0.3\) for the Rayleigh noise. When the noise model is based on Gamma or Poisson noise, it is unbiased, _i.e._\([]=\). In these cases, Neighbor2Neighbor is better than ours. However, when the noise model is based on Rayleigh noise which is biased our approach still has excellent performance while Neighbor2Neighbor is poor.

Mixture NoiseWe also consider the combination of three various multiplicative noise model (Gamma, Poisson and Rayleigh) and a convolution transform \(\). For each one, additive Gaussian noise with \(=100\) is added to construct mixture noise models. They are corresponding from No.\(11\) to No.\(16\) in Table 1. Because of the same reason discussed before, our method is compared to supervised learning and Neighbor2Neighbor, and Noisier2Noise is neglected. The experimental

    & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _32.44/0.887_ & _30.27/0.891_ & _31.32/0.892_ & _34.80/0.928_ & _32.53/0.924_ & _34.08/0.938_ \\ Nr2N & 31.80/0.863 & 29.75/0.878 & 30.84/0.871 & 33.87/**0.914** & 32.02/**0.916** & 33.40/**0.926** \\ Nb2Nb & **31.96/0.875** & **29.90/0.882** & **30.92/0.880** & 27.89/0.673 & 27.88/0.742 & 27.86/0.722 \\ Ours & 31.92/0.870 & 29.86/0.875 & 30.91/0.877 & **33.99/0.914** & **32.16/0.914** & **33.45/0.926** \\    
    & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _30.92/0.856_ & _28.69/0.860_ & _29.68/0.856_ & _33.02/0.904_ & _30.76/0.900_ & _32.11/0.912_ \\ Nr2N & 30.07/0.813 & 28.02/0.834 & 28.99/0.818 & **32.28/0.884** & **29.98/0.886** & **31.55/0.896** \\ Nb2Nb & **30.42/0.840** & **28.22/0.848** & **29.29/0.842** & 25.02/0.557 & 24.44/0.621 & 25.01/0.619 \\ Ours & 29.68/0.797 & 27.58/0.806 & 28.70/0.806 & 31.88/**0.884** & 29.50/0.874 & 31.14/0.895 \\   

Table 2: Quantitative comparison for various parameters of \(\) in additive Gaussian noise using different methods in terms of PNSR (dB)/SSIM. Bold indicates the best result among three unsupervised methods, while underlined indicates the second-best result.

    & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _33.51/0.916_ & _30.72/0.898_ & _32.44/0.922_ & _33.02/0.916_ & _30.41/0.897_ & _32.15/0.921_ \\ Nb2Nb & **32.98/0.908** & **30.33/0.890** & **31.97/0.913** & - & - & - \\ Ours & 32.61/0.894 & 29.89/0.870 & 31.51/0.898 & 31.90/0.877 & 29.26/0.858 & 30.63/0.878 \\        & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _32.90/0.902_ & _30.56/0.894_ & _31.87/0.908_ & _32.55/0.902_ & _30.27/0.894_ & _31.64/0.907_ \\ Nb2Nb & **32.50/0.893** & **30.17/0.886** & **31.48/0.899** & - & - & - \\ Ours & 32.38/0.886 & 29.98/0.874 & 31.31/0.891 & 31.84/0.872 & 29.48/0.864 & 30.56/0.873 \\    
    & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _35.29/0.939_ & _32.44/0.922_ & _34.39/0.947_ & _34.63/0.939_ & _31.97/0.920_ & _33.94/0.946_ \\ Nb2Nb & 16.55/0.865 & 15.16/0.844 & 16.74/0.862 & - & - & - \\ Ours & **34.25/0.915** & **31.45/0.892** & **33.34/0.923** & **32.87/0.894** & **30.30/0.869** & **31.85/0.901** \\   

Table 3: Quantitative comparison for various multiplicative noise models using different methods in terms of PNSR (dB)/SSIM. For Neighbor2Neighbor (Nb2Nb), if the noise model is constructed with \(\), it can be regarded as the one without \(\) through \(^{-1}\). Thus we do not provide the metrics. Bold indicates the better result between two unsupervised methods.

results are shown in Table 4. Due to the additive Gaussian Noise, Neighbor2Neighbor are not able to handle the cases with \(\) through the inverse convolution transform. The correlation of noise hampers the performance of Neigh2bor2Neighbor. Except the first noise model in Table 4, our approach all outperforms Neighbor2Neighbor and achieve excellent performance near to supervised learning.

Robustness EvaluationTo apply our approach, the parameters of noise models have to be known beforehand. Therefore their precision may impact on the performance. We choose No.14 and No.15 noise models in Table 1 as examples to show the robustness to parameters' precision. Suppose \(k\) is one of parameters, we disturb it by \((a+1)k\) where \(a(0,r^{2})\) and \(r\) is called the disturbance rate. The larger \(r\), the less precise the noise model. As \(r\) is increasing, the PSNR of the denoised result is shown in Figure 2. When \(r=0.1\), the PSNR reduces about 1 dB, which displays the robustness.

## 5 Conclusion

In this paper, we propose a new approach for unsupervised image denoising. The key part is Proposition 3.1. Based on it, we construct an equation, Eq. 7 about the clean image \(\) and the noisy image \(\). After the score function of \(\) is estimated, the denoised result can be obtained by solving the equation. Our approach can be applied to many different noise model as long as Eq. 7 is solvable. The denoising performance is competitive for simple noise models and excellent for complicated ones. We hope that this work is helpful to address sophisticated image denoising problems in practice.

    & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _32.86/0.902_ & _30.23/0.889_ & _31.70/0.906_ & _33.02/0.882_ & _29.30/0.875_ & _30.42/0.882_ \\ Nb2Nb & **32.30/0.892** & **29.80/0.880** & **31.21/0.896** & 26.93/0.676 & 25.06/0.663 & 26.33/0.710 \\ Ours & 32.13/0.880 & 29.61/0.861 & 31.08/0.887 & **30.74/0.853** & **28.40/0.841** & **29.58/0.854** \\   & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _32.49/0.892_ & _30.18/0.887_ & _31.40/0.897_ & _31.44/0.877_ & _29.36/0.876_ & _30.32/0.878_ \\ Nb2Nb & 32.03/**0.884** & **29.74/0.880** & 30.98/**0.888** & 26.82/0.646 & 25.48/0.669 & 26.32/0.688 \\ Ours & **32.10/**0.879** & 29.70/0.870 & **31.03/0.883** & **31.11/0.855** & **28.80/0.851** & **29.85/0.856** \\   & \)} & \)} \\  Method & Kodak & CSet9 & CBSD68 & Kodak & CSet9 & CBSD68 \\  SL & _34.38/0.926_ & _31.79/0.913_ & _33.39/0.933_ & _32.83/0.908_ & _30.48/0.898_ & _31.74/0.910_ \\ Nb2Nb & 16.54/0.856 & 15.15/0.838 & 16.71/0.851 & 16.40/0.704 & 15.06/0.738 & 16.56/0.736 \\ Ours & **33.54/0.902** & **30.94/0.883** & **32.68/0.913** & **31.14/0.867** & **28.94/0.847** & **30.23/0.876** \\   

Table 4: Quantitative comparison for various mixture noise models using different methods in terms of PNSR (dB)/SSIM. For each noise model, additive Gaussian noise with \(=100\) is added. Bold indicates the better result between two unsupervised methods.

Figure 2: PSNR V.S. disturbance rate for No.14 and No.15 noise models.

Figure 3: Qualitative Comparison using CBSD68 dataset (cropped to \(256 256\)). From the first row to the last: (1) Gaussian noise, \(=25\) w/o \(\); (2) Gaussian noise, \(=25\) w/ \(\); (3) Rayleigh noise, \(=0.3\) w/ \(\); (5) Poisson noise, \(=0.2\) w/ \(\) added by Gaussian Noise with \(=10\); (6) Rayleigh noise, \(=0.3\) w/o \(\) added by Gaussian Noise with \(=10\). Noisy image, GT: ground-truth image, SL: supervised learning, Nb2Nb: Neighbor2Neighbor, Nr2N: Noisier2Noise.