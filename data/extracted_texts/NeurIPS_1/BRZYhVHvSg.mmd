# Multi-Group Proportional Representation in Retrieval

Alex Oesterling

Harvard University

&Claudio Mayrink Verdun

Harvard University

&Carol Xuan Long

Harvard University

&Alexander Glynn

Harvard University

&Lucas Monteiro Paes

Harvard University

&Sajani Vithana

Harvard University

&Martina Cardone

University of Minnesota

&Flavio P. Calmon

Harvard University

###### Abstract

Image search and retrieval tasks can perpetuate harmful stereotypes, erase cultural identities, and amplify social disparities. Current approaches to mitigate these representational harms balance the number of retrieved items across population groups defined by a small number of (often binary) attributes. However, most existing methods overlook intersectional groups determined by combinations of group attributes, such as gender, race, and ethnicity. We introduce Multi-Group Proportional Representation (MPR), a novel metric that measures representation across intersectional groups. We develop practical methods for estimating MPR, provide theoretical guarantees, and propose optimization algorithms to ensure MPR in retrieval. We demonstrate that existing methods optimizing for equal and proportional representation metrics may fail to promote MPR. Crucially, our work shows that optimizing MPR yields more proportional representation across multiple intersectional groups specified by a rich function class, often with minimal compromise in retrieval accuracy. Code is provided at [https://github.com/alex-oesterling/multigroup-proportional-representation](https://github.com/alex-oesterling/multigroup-proportional-representation).

## 1 Introduction

A recognized objective in fair machine learning (ML) is discovering, reporting, and mitigating _representational harms_. Representational harms arise when systems reinforce and perpetuate the marginalization of population groups based on characteristics such as race, socioeconomic status, cultural background, and gender . These harms often manifest through the biased portrayal or misrepresentation of these groups, stereotype reinforcement, and erasure of cultural identities . Representational harms have been widely documented in ML systems. For instance, many freely available datasets used in ML are not geo-diverse , and generative models can output images that under-represent demographic minorities across gender and racial identities .

We focus on representation in retrieval tasks. Representational harms in retrieval and ranking tasks arise when retrieved items do not accurately reflect the true diversity and proportions present in reality, perpetuating harmful stereotypes and biases . For instance, Kay et al.  demonstrated that, in 2015, only \(10\%\) of the top 100 results for CEO in Google Image Search were women, despite \(28\%\) of CEOs in the US being women, and recent studies  have demonstrated that this bias is still present in modern image search engines. Later, Otterbacher et al.  showed that the search engine Bing usually produced twice as many men as compared to women when queried with the word "person". Finally,  systematically studied gender biases in image representations by auditing the four most important image search engines: Google, Bing, Baidu, and Yandex. In particular, among other findings, this study showed that when a qualifier such as "intelligent" is added to the query "person", the engines still exhibit a significant gender discrepancy; see also [1, Chapter 7]. Whenretrieval is based on a search over vector embeddings of images and text, biases in embedding models can propagate to retrieved results, leading to disparate representation of people by demographic groups such as gender or race , as well as propagating spurious correlations from the dataset more broadly  or distorting results due to stereotypes present in the representation . Though correlations between unrelated semantic concepts do not necessarily constitute representational harms, a wealth of research charts undesirable bias in embedding models, including publicly available vision-language embedding models such as CLIP  used for retrieval. Bias in embeddings can lead to bias in retrieval . In fact, recent work by Srinivasan et al.  argues that many image retrieval systems lack "social diversity" as perceived by humans.

Several interventions aim to control gross statistical deviations in group representations in retrieval. A common approach is ensuring equal representation of pre-defined population groups in retrieved items . An alternative goal is proportional representation (PR) , where the target representation of different groups is proportional to some reference population or statistic. Various interventions have been proposed to achieve equal or proportional representation, including optimizing for diversity in addition to the similarity in retrieval , directly selecting the objects retrieved based on balancing known or predicted sensitive attributes  and, for vector databases, modifying embeddings directly to remove information about group-defining attributes .

Achieving proportional representation across multiple intersectional groups is challenging, as existing fairness interventions typically consider only a small number of pre-defined groups. Ensuring representation across individual groups (e.g., given by gender **or** race) _does not_ guarantee representation across _intersectional_ groups (e.g., given by gender **and** race), as demonstrated in Table 1 (and Table 5 in the Appendix). The study of intersectionality and its consequences is rooted in work in law and the social sciences  and has been a well-discussed problem for several decades. In machine learning systems, lack of intersectional representation can contribute to the invisibility of historically marginalized groups determined by multiple axes of identity , or their mistreatment through "fairness gerrymandering," where interventions on fairness for specific groups may harm fairness on intersectional subgroups . However, as the number of group-denoting attributes increases, the number of intersectional groups grows exponentially, quickly surpassing the number of retrieved items and limiting the achievable proportional representation. In fact, achieving optimal proportional representation across multiple attributes has been shown to be NP-hard .

We propose a metric called _Multi-group Proportional Representation_ (MPR) to quantify the representation of intersectional groups in retrieval tasks. MPR measures the worst-case deviation between the average values of a collection of _representation statistics_ computed over retrieved items relative to a reference population whose representation we aim to match. The set of representation statistics is given by a function class \(\), where each function \(c\) maps a retrieved item \(x\) to a real number. For instance, \(c(x)\{-1,1\}\) may denote binary group membership for an input \(x\). In theory, \(\) can be given by bounded complexity function classes, such as linear functions or shallow decision trees. In practice, \(\) are functions defined over item attributes, such as vector embeddings or group-denoting labels, enabling MPR to measure proportional representation across complex, intersectional subgroups. Compared to naively counting the number of retrieved items across a (potentially exponential) number of pre-defined groups, MPR offers a more flexible, scalable, and theoretically grounded metric for multi-group representation in retrieval.

In addition to **introducing and carefully motivating the MPR metric**, cf. Section 2, we make three contributions. **First**, we show how to compute MPR for several function classes in Section 3. Computing MPR relies on a curated dataset that represents the desired population whose proportional representation we aim to reflect in retrieved items. We derive sample complexity bounds for the size of this curated dataset based on the complexity of the function class \(\). We also prove that MPR can be computed in closed form for certain function classes or with a regression oracle. **Second**, we propose MPR, an algorithm that retrieves items from a vector database to maximize their average similarity to a query embedding while satisfying an MPR constraint relative to the curated dataset (Section 4). MPR achieves this by iteratively calling an oracle that computes MPR violations, yielding both relevant and representative retrieved items. **Third**, we evaluate MPR on retrieval tasks using datasets such as CelebA , the Occupations dataset , Fairface , and UTKFace . In section 5, we show that MPR Pareto-dominates competing approaches in balancing retrieval similarity and MPR.

Related Work.Broadly speaking, existing work on fair and diverse retrieval with pretrained embeddings either: 1) modifies the embedding space to prioritize downstream fairness, or 2) provides retrieval algorithms optimizing for diversity or fairness.

_Mitigating Bias in Embedding Space._ Various approaches have been proposed to produce vector embeddings of text and images that target diversity or mitigate bias. These include modifying loss functions to encourage group fairness , adversarial training , disentangling representations , and in-processing fair sampling methods for gender imbalance . Many popular embedding models are not trained with such approaches, so post-processing methods for fairness have also been developed for multimodal models such as CLIP , including CLIP-clip , CLIP-debias , and FairCLIP . Recent work by Srinivasan et al.  builds upon the pretrained image-text model CoCa and leverages text-guided projections to extract an embedding, called PATHS, that captures complex notions of diversity in people, and then conduct diverse retrieval with a greedy algorithm. However, code for implementing and reproducing PATHS embeddings was not available at the time of publication. In our experiments, we report the MPR achieved by CLIP-clip and CLIP-debias in retrieval tasks and approximate the greedy retrieval algorithm proposed in  with vanilla CLIP embeddings. Unlike the aforementioned methods, MPR is not based on modifying embeddings.

_Retrieval Algorithms with Diversity or Fairness._ Instead of modifying embeddings, several methods aim to promote diversity, given possibly biased embeddings. Given an additional diversity constraint, a popular approach is Maximal Marginal Relevance (MMR) , where items are greedily retrieved in order to maximize a linear combination of similarity and diversity metrics. Celis et al.  and Celis and Keswani  focus on diversity and fairness in image retrieval, using a reweighing method that combines similarity and MMR to select diverse yet relevant images. Alternatively, the Post-Hoc Bias Mitigation  method aims to achieve equal representation over a pre-defined attribute (such as gender) through calls to an oracle classifier and selecting a balanced group of images. **We extend this prior work in two key ways:** (i) we aim to achieve proportional representation across intersectional groups, going beyond the representation of two groups defined by binary attributes; (ii) MPR explicitly balances MPR and retrieval similarity via an optimization that controls for both, offering an efficient alternative to greedy MMR-based methods.

_Diversity Metrics._ A traditional measure of diversity for a set is the pairwise similarity of the retrieved items . However, the general visual (dis)similarity metric is insufficient in optimizing for people-related diversity such as skin tone or gender . When the attribute (e.g., race) along which diversity is optimized is known, or, in other words, we have access to a ground truth attribute label, one can use fairness definition-derived metrics such as proportional representation (see next section and ). For more complex notions of diversity that aim to capture intersectional or subtle sociocultural identities (e.g., cultural backgrounds, lifestyles, nationalities, religions), human annotators can be employed to determine if the selected set of images is more diverse than the baseline (retrieval based on similarity to query only) . MPR complements existing metrics by providing a rigorous approach to measuring representation across complex, intersectional groups defined by a rich class of functions. However, as with any fairness metric, MPR has limitations - see Section 6 - and may not always align with human perceptions of representation. In particular, we underscore the importance of involving stakeholders in defining representation goals and auditing retrieval systems.

_Multi-Group Fairness._ Our work is directly informed by the burgeoning literature on multi-group fairness in classification, particularly the work of Hebert-Johnson et al. , Kim et al.  who proposed rigorous frameworks of multi-group fairness auditing and post-processing to ensure fair predictions across identifiable subgroups. Recent efforts in this field include , which analyze sample complexity aspects of measuring and reporting multi-group representation, and  who develop stronger variants of multi-group fairness notions. Unlike prior work, we focus on multi-group representation in retrieval rather than multi-group fairness in classification and regression.

_Multi-Attribute Proportional Representation._ A recognized challenge in computational social choice research is building committees, groups, or sets of items that ensure proportional representation across several attributes . The work most closely related to ours is by Lang and Skowron , which introduced the problem of multi-attribute proportional representation, where a set of items must be selected to reflect desired distributions over multiple attributes simultaneously. Their work established fundamental computational complexity results, showing that finding optimal proportional representation is NP-hard, and developed approximation algorithms and integer linear programs for promoting proportional representation across attributes. While our work shares similar goals, our MPR metric takes a different approach by measuring the worst-case deviation over computationally-identifiable groups defined by a function class \(\). This formulation connects naturally with statistical learning theory through MMD  and sample complexity bounds (Propositions 1 and 2). Though we use the term _multi-group_ rather than _multi-attribute_ to emphasize connections with the burgeoning literature on multi-group fairness [48; 49], both terms describe related problems of ensuring representation across multiple dimensions. We also highlight that work on multi-attribute representation in computational social choice (including ) strives for proportional representation marginally on each attribute, while our primary goal with this work is to achieve intersectional representation. Finally, while  similarly seeks to match retrieved candidates to a target distribution, we focus on database retrieval rather than social choice applications. The rich history of proportional representation in social choice theory and political sciences provides, however, an important context for our work. We briefly discuss these connections in Appendix E. There, we elaborate on how our approach relates to and differs in terms of representation formulation from .

## 2 A Multi-Group Proportional Representation Metric

Preliminaries.Consider a _retrieval dataset_ of items from which we aim to retrieve relevant entries, denoted by \(_{R}=\{_{1}^{r},...,_{n}^{r}\}\). We assume that \(_{i}^{r}^{d}\), where \(\) is a set of additional labels for each item. For example, items \(_{i}^{r}\) can be \(d\)-dimensional embeddings of images, videos, or textual content, in which case \(=\). Alternatively, \(_{i}^{r}=(_{i},_{i})\), where \(_{i}^{d}\) is an embedding and \(_{i}\) is a vector of labels indicating group membership (e.g., gender, race, ethnicity).

Given a query embedding \(^{d}\), the goal of retrieval is to search and return the top-\(k\) most similar items to \(\) in \(_{R}\). The similarity between an embedding of \(\) and items in \(_{R}\) is measured according to a metric \(:^{d}^{d}\). Throughout the paper, we assume that \(_{R}\) is a vector database and \(\) is cosine similarity between embeddings, though this formulation can be generalized. To retrieve items from \(_{R}\), users prompt a query \(q\) (e.g., "Fortune 500 CEOs") which is then embedded \(^{d}\). Ideally, the user receives \(k\) retrieved items \(()=\{_{1}^{r},...,_{k}^{r}\}_{R}\) such that \((,_{i}^{r})(,)\) for all \(()\) and \(i[k]\).

The simplest setting for measuring representation is to consider only two population groups denoted by a binary variable - a setting commonly found in the fair retrieval and generation literature [18; 19]. In this case, group membership is determined by a _group-denoting function_\(c:^{d}\{-1,1\}\). For an item \(_{i}^{r}\), \(c(_{i}^{r})\) indicates membership to group \(-1\) or \(1\) (e.g., male/female) based on its embedding \(_{i}\) and associated labels \(_{i}\). If the retrieval dataset \(_{R}\) contains annotations for group membership, \(c(_{i}^{r})\) can simply return the relevant feature from \(_{i}\). However, when group labels are not present (i.e., \(=\)), \(c(_{i}^{r})\) can be implemented as a classifier that predicts group membership based on the item's embedding \(_{i}\).

With a group-denoting function \(c(^{r})\) in hand, we can measure the representation of each group in a set of retrieved items \(()\). One popular constraint for representation is _equal representation_[2; 28], which aims to ensure that the number of retrieved items in each group is approximately the same, i.e., \(_{^{r}()}c(^{r}) 0\). An alternative metric is _proportional representation_[61; 20], which quantifies the deviation of group membership from a _reference distribution_\(Q\). Methods that promote proportional representation aim to ensure \(_{^{r}()}c(^{r}) _{Q}[c(X)]\). Here, the measure \(Q\) captures the distribution of a reference population whose representation statistics we aim to match. For example, if \(Q\) were the distribution of individuals in the US, \(_{Q}[c(X)]\) could measure the proportion of men vs. women in the US and be approximated using Census data.

Proportional representation generalizes equal representation since different groups are rarely uniformly distributed over a given population. Naturally, the choice of distribution \(Q\) is application and context-dependent - we revisit the choice of \(Q\) below. Importantly, **if \(Q\) is biased, then biases will be propagated to the retrieved items.**

Multi-Group Proportional Representation.We aim to ensure that retrieved items represent individuals from diverse and intersectional population groups. Instead of measuring proportional representation in terms of the average of a single group-denoting function \(c(^{r})\), we consider a class of \(Q\)-measurable functions, the _representation statistics class_, \(\{c:^{d}\}\). This set \(\) may represent multiple, potentially uncountable overlapping groups. We formally define multi-group proportional representation next.

**Definition 1**.: For a reference _representation distribution_\(Q\), a set of \(Q\)-measurable set of _representation statistics_\(\), and a set of \(k\) retrieved items \(\), we define the _Multi-Group Proportional Representation (MPR)_ metric as

\[(,,Q)_{c} |_{^{r}}c(^{r})-_{Q}[c (X)]|. \]

A set of items \(\) is \((,)\)-multi-group proportional representative of \(Q\) if \((,,Q)\).

The MPR metric quantifies the "representativeness" of a rich class of statistics, denoted by functions in \(\), within a set of retrieved items \(\). This generalization is crucial for capturing intersectional groups. For example, \(\) could contain functions that map items to demographic groups based on race, gender, age, or combinations thereof. Alternatively, when labels in \(\) contain such group-denoting attributes, \(\) can represent decision trees of a given depth over features (e.g., all combinations of pairs of race, gender, and age). The MPR metric compares the empirical average of each \(c\) over the retrieved set \(\) to its expectation under the reference distribution \(Q\). By defining \(Q\) appropriately, we can flexibly specify different statistical representation goals, such as equal representation \((_{Q}[c(X)]=0\) for binary \(c)\) or proportional representation w.r.t. a target population. Measuring representation requires defining what constitutes "fair and proportional representation." While equal representation may suffice for binary groups, proportional representation of more complex intersectional groups requires care. The choice of representation reference statistics (given by the distribution Q in the definition of MPR) should be application-dependent, context-aware, and culturally sensitive.

**Remark 1**.: MPR is equivalent to the maximum mean discrepancy (MMD) of representation statistics in \(\) between the empirical distribution over retrieved items \(\) and the reference distribution \(Q\). MMD-based metrics have a long history  and are used in hypothesis testing for comparing distributions. MMD is a particular case of the Integral Probability Metric (IPM) , allowing us to borrow from the rich literature on IPMs to measure and ensure MPR in practice.

**Remark 2**.: MPR can be viewed as the "representation in retrieval" counterpart of multi-group fairness metrics found in classification, such as multiaccuracy  and multicalibration . Whereas multiaccuracy and multicalibration measure if classification error residuals are correlated with any group represented within a class \(\), MPR captures _proportional representation_ of groups in \(\) within a set of retrieved items - a fundamentally different problem. The idea of representing groups in terms of a "computationally identifiable" class of functions \(\) is directly inspired by the multi-group fairness in classification literature, and we adopt similar notation (i.e., \(c\) and \(\)).

Curated Datasets for Proportional Representation.A key challenge in computing MPR is selecting the reference representation distribution \(Q\) and measuring the expectation of functions in \(\) against this distribution. In the simple case where \(\) consists of a small number of functions indicating membership in individual groups, we could potentially set the proportional representation targets \(_{Q}[c(X)]\) for each group \(c\) manually, e.g., by defining a target fraction of men/women or individuals from different ethnic backgrounds. This quickly becomes infeasible when there are many intersectional groups - and impossible if \(\) is uncountable. Moreover, in most practical settings, \(Q\) will very likely _not_ have a simple closed-form analytical expression.

In practice, i.i.d. samples drawn for \(Q\) may be available. For instance, the retrieval dataset \(_{R}\) itself may be drawn from the target population for which we aim to preserve proportional representation in retrieved items. Alternatively, we may have access to a dataset that was carefully curated to be representative of a diverse population. Examples include the FairFace dataset , which was designed to be balanced across race, gender, and age groups, and the AVFS dataset . More generally, we refer to datasets with samples drawn from the target population \(Q\) as a _curated dataset_.

**Definition 2** (Curated Dataset).: Let \(Q\) be a probability distribution over \(^{d}\) tailored to account for diversity and representation of stakeholders who query the retrieval dataset. The _curated dataset_ with \(m\) samples drawn the distribution \(Q\) is denoted as \(_{C}\{^{c}_{1},...,^{c}_{m}\}\). We denote the MPR of a set of retrieved items \(\) relative to the _empirical distribution_ over \(_{C}\) as \((,,_{C})\).

Constructing a proper \(_{C}\) is critical to properly measuring bias and preventing downstream harms, and the nature of \(_{C}\) is context-dependent and may vary based on the specific application and desired representation goals. We reiterate that if the curated dataset is biased, then these biases will be propagated to downstream usages of MPR. For these reasons, we recommend that curated datasetsused for MPR measurements be developed and verified through participatory design approaches [66; 67] in collaboration with diverse stakeholders. By involving stakeholders in defining representation goals, we can help ensure that the proportional representation in information retrieval systems measured by MPR aligns with the values and needs of the user base these systems serve.

Finally, we note that we can also condition the curated dataset on a given query. Specifically, for a query \(\), we can retrieve relevant samples from both the curated dataset \(_{C}\) and the retrieval dataset \(_{R}\). The samples retrieved from \(_{C}\) can then serve as a "conditional" curated dataset, denoted as \(_{C|}\), which captures the desired representation target specific to the query \(\). This approach allows for a more granular and context-aware proportional representation.

In the next two sections, we introduce theoretical guarantees and algorithms that are agnostic to the specific choice of \(_{C}\). In other words, our proposed methods for measuring and promoting MPR in retrieval are general and can be applied regardless of how the curated dataset is constructed. In our numerical experiments, presented in Section 5, we use FairFace  as the curated dataset.

## 3 Computing Multi-Group Proportional Representation

Computing MPR in Definition 1 requires approximating two quantities: the representation distribution \(Q\) and the supremum \(_{c}\). We first establish generalization bounds for approximating \(Q\) using i.i.d. samples. We then show how to compute \(_{c}\) for several classes of representation statistics \(\).

Error in approximation \(Q\) via a curated dataset.Proposition 1, proved in Appendix C, bounds the deviation between the empirical MPR computed over the curated dataset \(_{C}\) drawn i.i.d. from reference distribution \(Q\) and the true MPR measured over \(Q\).

**Proposition 1** (Generalization Gap of MPR).: _Let \((q)=\{_{i}^{r}\}_{i=1}^{k}\) be a set of \(k\) retrieved samples, \(_{C}=\{_{i}^{c}\}_{i=1}^{m}\) be a curated dataset comprised of \(m\) i.i.d. samples from a target representation distribution \(Q\), and \(>0\). If \(=\{c:^{d}\{-1,1\}\}\) with Rademacher complexity \(_{m}()\) then, with probability at least \(1-\),_

\[|(,,_{C})-(,,Q)|_{m}()+}{8m}}. \]

We can extend Proposition 1 to any set of bounded functions \(\) (see, e.g., bounds on empirical MMD estimates in ). Note that the guarantee in (2) only holds for a single set of retrieved items \(\) in response to a query. Proposition 2 provides a bound on the size \(m\) of an i.i.d. curated dataset \(_{C}\) that ensures an \(\)-accurate estimate of MPR for a set of \(M\) queries.

**Proposition 2** (Query Budget Guarantee).: _Consider any set of \(M\) queries \(=\{_{1},...,_{M}\}\) where \(M\). Let \(()\) denote the VC-dimension of the class \(\) with range in \(\{-1,1\}\). For \(>0\), if \(_{C}\) consists of \(m\) i.i.d. samples drawn from \(Q\) where \(m\) satisfies_

\[m()}{^{2}}+)}}{2^{2}}, \]

_then, with probability at least \(1-\), \(|(,,_{C})-(,,Q)|\)._

The above results provide guidelines on the size of the curated dataset required to accurately estimate MPR relative to a true target representation distribution \(Q\). If the class of representation statistics \(\) is very complex (in the VC-dimension sense), then the size \(m\) of the curated dataset \(_{C}\) must be proportionally large to represent \(Q\) accurately. Hence, the curation dataset should be designed having in mind (i) the number of diverse queries being asked and (ii) the complexity of the function class \(\). While Proposition 2 provides a conservative bound, as generalization bounds are often not tight , these results nevertheless offer insight into the relationship between the complexity of \(\) and the accuracy of MPR estimation.

In the remainder of the paper, we assume that MPR is computed against a fixed curated dataset \(_{C}\) of size \(m\). We consider four specific instantiations of the set of representation statistics \(\): (i) \(\) is closed under scalar multiplication, i.e., if \(c\), then \( c\) for any \(\), (ii) \(\) is a set of functions taking values in \(\{-1,1\}\); (iii) \(\) consists of linear functions; and (iv) \(\) consists of functions in a Reproducing Kernel Hilbert Space (RKHS). Next, we show that for cases (i) and (ii) MPR can be computed using calls to an oracle that performs regression over \(\) and, for linear functions (iii), MPR has a simple closed-form expression. Due to its technical nature, we defer the calculation of MPR for functions in an RKHS to Appendix D.2.

Computing MPR via Mean Square Error (MSE) Minimization.When \(\) is closed under multiplication or consists of binary functions with values \(-1,1\), MPR can be expressed as an MSE minimization. This enables us to compute MPR by leveraging existing black-box oracles that perform regression under quadratic loss, such as regressors implemented in scikit-learn .

The key observation for expressing MPR as an MSE minimization is that MPR can be formulated as a maximum correlation problem. Consider the (row-wise) concatenation of the retrieval dataset \(_{R}\) and the curated dataset \(_{C}\), given by \([_{1}^{r},...,_{n}^{r},_{1}^{c},..., {x}_{m}^{c}]\), where \(_{i}\) is the \(i\)-th entry of \(\). For the remainder of this section, we consider a fixed set of retrieved items \(\). Let \(\{0,1\}^{n}\) be a vector indicating items that are retrieved from \(_{R}\) for a given query, i.e., \(a_{i}=1_{i}^{r}\). Under this notation, where retrieved items are indicated by the vector \(\), MPR can be reformulated as

\[(,,_{C})=_{c} |_{i=1}^{n}a_{i}c(_{i}^{r})-_{i=1}^{ m}c(_{i}^{c})|=_{c}|_{i=1}^{n+m}c(_{i })_{i}|, \]

where \(}^{n+m}\) has \(i\)-th entry given by \(_{i}_{i n}}{k}-_{i >n}\). This reformulation will be useful for explicitly casting MPR-constrained retrieval as an optimization problem.

When \(\) consists of binary functions in range \(\{-1,1\}\), MPR is equivalent to regression over \(\) of \(}\) under quadratic loss, since

\[_{c}_{i=1}^{n+m}(c(_{i})-_{i} )^{2}=n+m+}^{}}+2 _{c}_{i=1}^{n+m}c(_{i})_{i}. \]

The absolute value in (4) can be recovered by regressing \(-}\) instead of \(}\).

Most classes of regression functions in \(\) are closed under scalar multiplication (e.g., multiplying the output of a decision tree regressor by a constant still yields a decision tree regressor). However, in this case, it follows from (4) that MPR is unbounded. Even for bounded \(\), without proper normalization MPR can scale with dataset size, which is undesirable for a representational measure. We constrain \(\) to a set of normalized functions for MPR to be bounded and independent of dataset size. This constraint also allows us to cast MPR as an MSE minimization over \(\). We formally state this result next, proven in Appendix C, which will be applied in Section 4 to develop a cutting-plane-based algorithm for ensuring MPR in retrieval called MOPR.

**Proposition 3**.: _Let \(^{}\{c_{i=1}^{m+n}c(_ {i})^{2}=\}\) where \(\) is closed under scalar multiplication. Let \(c()=[c(}),...,c(})]\). Then \(0(^{},,_{C}) 1,\) and for any_

\[c^{*}*{arg\,inf}_{c}_{i=1}^{n+m}(c(_{i })-_{i})^{2}, \]

_let \(:\) be defined as \(()=}{\|c^{*}()\|_{2}}c^{*}( )\). Then, we have that_

\[*{arg\,sup}_{c^{}}|_{i=1} ^{n+m}c(_{i})_{i}|. \]

Computing MPR for Bounded-Norm Linear Regression.Recall that each item in the retrieval or curated datasets is of the form \(x_{i}=(e_{i},g_{i})\), where \(e_{i}\) is an embedding and \(g_{i}\) are labels. When \(x_{i}^{l}\) (i.e., the labels have numerical values), we can consider \(\) as a linear set of functions over retrieved items. In this case, MPR enjoys a closed-form expression, as stated in the next proposition.

**Proposition 4**.: _Let items in the retrieval and curated datasets be vectors in \(^{l}\) for \(l<m+n\) and \(=\{x w^{}x w^{k}\}.\) Moreover, let \(^{(m+n) l}\) be the matrix formed by concatenating items in the retrieval and curated dataset \(_{R}\) and \(_{C}\), respectively. For \(^{}\) in Proposition 3, we have_

\[(^{},,_{C})=\|_{l}^{}}\|_{2}}\,, \]

**Algorithm 1**Mopr (Multi-group Optimized Proportional Retrieval)

**Input**: \(_{R}\), query \(\), number of iterations \(T\), number of items to retrieve \(k\), MPR constraint \(\), \(()\) that computes solves (4) and returns \(c\) that approximates the sup.

```
1:\(}\), \(s_{i}=(_{i}^{r},q)\)
2:for\(\{1,2,...,T\}\)do
3:\(_{^{n}}^{}\)s subject to \(|_{i=1}^{n}a_{i}c(_{i}^{r})-_{i=1}^{m }c(_{i}^{c})|\) for \(c}\)
4:\((,c)()\)\(\) Solve (4)
5:if\(\)or\(=T\)then
6: return\(\{_{i}^{r}_{R}\) corresponding to \(k\) largest entries of \(a_{i}\}\)
7:else
8:\(}}\{c\}\)
9:endif
10:endfor
```

**Algorithm 2**Mopr (Multi-group Optimized Proportional Retrieval)

Proposition 4 can be directly adapted to linear functions defined only over embeddings or a subset of features of retrieved items. The closed-form expression for MPR in (8) also allows MPR-constrained retrieval to be computed by a quadratic program, as discussed in Appendix D.1.

## 4 Promoting Multi-Group Proportional Representation in Retrieval Tasks

We develop an optimization framework for retrieving the \(k\) most similar items in a vector database to a given query \(\) while satisfying a target MPR threshold of \(\). We formulate the retrieval goal as maximizing the average similarity between a query and retrieved items, given by \(s_{i}=(_{i}^{r},)\) (recall Section 2 for notation), where \((_{i}^{r},)\) is given by cosine similarity in our experiments. The problem of maximizing utility in retrieval while satisfying an MPR constraint (expressed as Eq. (4)) can be formulated as the integer program:

\[_{\{0,1\}^{n}}\ ^{}\ \ \ \ _{c}|_{i=1}^{n}a_{i}c(_{i}^{r})- _{i=1}^{m}c(_{i}^{c})|,_{i=1}^{k}a_{i}=k. \]

When \(\) is given by normalized linear functions as in Proposition 4, the integer constraints can be relaxed to \(^{n}\) and the optimization can be approximated via standard quadratic solvers; see Appendix D.1.

Multi-Group Optimized Proportional Retrieval.We approximate (9) via the Multi-Group Optimized Proportional Retrieval Algorithm (MOPR), described in Algorithm 1. MOPR is essentially a cutting-plane method that aims to find a set of \(k\) items that maximize utility while approximately satisfying an MPR constraint of \(\). The algorithm iterates between (i) a call to an oracle that computes MPR and returns a function \(c\) that achieves the supremum in (4) and (ii) a call to a linear program (LP) solver that approximates the top-\(k\) most similar items to a query subject to linear constraints on the violation measured by \(c\). Each oracle call adds an additional constraint to the LP solver which, in turn, approximates the top-\(k\) items under an increasing set of constraints. The solution of the LP is rounded to satisfy the integer constraint \(\{0,1\}^{n}\). In our implementation, we assume that MPR can be computed via MSE minimization (cf. Section 3) - in which case we consider the normalized class \(^{}\). The oracle call consists of running a black-box quadratic loss minimization over \(\) and normalizing.

Interestingly, we observe that, despite relaxing the integer constraints in each LP call, the solution to the relaxed problem is very sparse and (after rounding) approximates well the solution of the ideal integer program (9) for moderate values of \(\). However, the method can fail to accurately approximate the IP solution when \(\) is small. We present a more detailed analysis of MOPR in Appendix D, which discusses potential convergence issues with the cutting plane method as well as stopping conditions.

## 5 Numerical Experiments

In this section, we show that MOPR is effective in promoting more proportional representation across intersectional groups while preserving similarity between retrieved items and a given query. Notably, MOPR Pareto-dominates competing benchmarks in terms of achieved MPR gap and utility.

Datasets.We conduct retrieval over three image datasets of faces: **CelebA**, which includes labels for gender, age, and various other attributes, **UTKFace**, which contains gender, age, and race attributes, and **Occupations**, which contains gender attributes. We compute MPR for equal representation by constructing a synthetic dataset \(_{C}\) balanced over all attributes and for proportional representation using **FairFace** as the curated dataset \(_{C}\), since it is a carefully designed dataset of faces with subgroup attributes for race, gender, and age. In all cases, each dataset entry consists of an image (CLIP) embedding \(_{i}\) and a set of labels \(_{i}\).

Benchmarks.We compare our method with four baselines. DebiasCLIP  modifies text queries with a prepended learned embedding for debiased retrieval but does not allow for tunable control of the representation-similarity trade-off, so it only results in a single retrieval set over which we compute similarity and MPR. CLIP-Clip  trims features from CLIP embeddings that have high "mutual information" with gender, allowing for control of how many features are clipped from the embedding. PBM  post-processes CLIP embeddings to mitigate bias by predicting gender attributes and subsampling from each gender equally. PBM also allows tuning the representation-similarity tradeoff by controlling the likelihood of sampling at random or in a balanced manner from the retrieval dataset. Finally, the state-of-the-art for fair retrieval first constructs PATHS embeddings , which use a set of adjective-noun keywords to capture a broad set of identity vectors in vision-language models, and then greedily samples using the MMR  algorithm to navigate the representation-similarity tradeoff. However, the authors' method of computing PATHS embeddings is not public, so we used CLIP embeddings to replicate their algorithm. We refer to this method as MMR. For a detailed discussion of these algorithms and their approaches to representation, see Appendix E.

Experimental Setup.We consider three classes of representation statistics \(\): linear regression, decision trees, and MLPs (the last two are presented in Appendix G). In both cases, we compute MPR over \(^{}\), i.e., \(\) normalized over the retrieval and curated datasets (see Prop. 3). We report results over 10 queries for occupations suggested by ChatGPT 3.5 (Appendix H) and an additional 45 occupations for the the Occupations dataset. To accelerate retrieval, we query each of our retrieval datasets for the top 10k items according to the prompt "A photo of a {query}" in terms of raw similarity using FAISS . We similarly retrieve the top 10k items from FairFace as the query-conditioned curated dataset \(_{C}\). One reason we first filter for the top 10k items is the runtime of MMR, which is a greedy algorithm that traverses the full dataset for each retrieval \(k\) (even for 10k entries and \(k=50\) retrieved items, MMR takes hours to run for 10 queries).

In order to evaluate representation over interpretable population groups, we consider that representation statistics \(\) are computed only over labels \(_{i}\) given in FairFace. These labels are not present in all retrieval datasets. Thus, for CelebA and Occupations, we train linear probes on FairFace's CLIP embeddings to predict their race and age attributes, and when using UTKFace, we map from FairFace's race labels to UTKFace's race labels by mapping Southeast Asian and East Asian

Figure 1: Cosine similarity vs MPR for query “A photo of a programmer” with \(k=50\) images retrieved. From left to right: CelebA, UTKFaces, Occupations. Values are normalized so MPR and similarity when retrieving the top-\(k\) items is the point (1,1). MOPR Pareto-dominates baselines and significantly closes the MPR gap.

to Asian and Middle Eastern and Latino_Hispanic to Other. While the fair ML community should engage in broader discussions addressing the ethics of predicting sensitive attributes from CLIP embeddings  (especially given that CLIP itself has been found to be biased) and the issues surrounding the grouping and re-grouping of diverse racial identities, we acknowledge that these are larger-scale issues that our work does not presume to address.

We retrieve \(k=50\) items for each of the above queries. For a given function class and query, we compute the baseline MPR and average cosine similarity given by the top 50 most similar items. Then, we conduct a parameter sweep over \(\) starting from this max-MPR value, inputting each value to MOPR in Algorithm 1. We normalize our results such that the Top-\(k\) MPR and similarity are the point (1,1) on each graph, and each point measures the fraction of Top-\(k\) MPR and similarity.

Results.In Fig. 1 we report results for proportional representation for the query "A photo of a programmer" with respect to FairFace for linear regression models, with additional results for other queries, as well as decision trees and MLPs in Appendix G (Figs. 8-19). We observe that MOPR Pareto-dominates benchmark methods, and is able to preserve similarity while reaching lower levels of MPR. Methods based on directly modifying embeddings or queries for a single group attribute such as CLIP-Clip and DebiasCLIP only partially reduce MPR at a high utility cost. This is because these methods do not modify the retrieval algorithm but use an unbiased embedding and hope by chance that the retrieved items will be representational. The most competitive method to ours is the retrieval algorithm MMR, which is our attempt to replicate PATHS. Though MMR is competitive to ours for large MPR, it fails to achieve small values of MPR relative to MOPR. It is also notable that MOPR can drive MPR to near zero for UTKFace, yet gaps remain in CelebA and Occupations, indicating this gap may be caused by the use of probes to estimate group attribute labels.

In Table 1, we construct a synthetic curation set with an equal number of each group attribute. This allows us to evaluate the performance of MOPR in achieving equal representation. We conduct a similar hyperparameter sweep as above, and take the retrieval set with the minimum MPR averaged over all 10 queries to fairly compare the best possible representation of each method.2 Our results demonstrate that MOPR can exactly achieve our equal representation goals when provided with an equally-balanced curation dataset, whereas prior baselines (see DebiasCLIP, CLIP-Clip, and PBM in Appendix Table 5) underrepresent several intersectional groups.

## 6 Concluding Remarks

In this work, we introduced a novel retrieval metric called Multi-group Proportional Representation (MPR) and developed algorithms to ensure MPR in retrieval tasks. By measuring deviations in a set of representation statistics, MPR provides a scalable approach to quantifying and enforcing proportional representation for complex, intersectional groups. We analyzed the generalization properties and realizable regimes of MPR and, through experiments in image retrieval, demonstrated its favorable utility-fairness trade-off compared to existing fair retrieval algorithms.

  &  &  & Asian & Indian & Others & Sum \\    & Male & \(21.2 11.84\) & \(13.2 7.70\) & \(10.8 7.54\) & \(21.2 20.70\) & \(\) & \(\) \\   & Female & \(17.2 21.04\) & \(6.6 6.14\) & \(\) & \(\) & \(\) & \(\) \\   & Sum & \(\) & \(\) & \(\) & \(\) & \(\) & \\   & Male & \(28.8 8.96\) & \(11.0 4.58\) & \(10.2 4.04\) & \(10.8 2.40\) & \(3.8 1.06\) & \(\) \\   & Female & \(16.2 9.06\) & \(7.6 3.66\) & \(5.0 3.00\) & \(\) & \(2.6 1.56\) & \(\) \\   & Sum & \(\) & \(\) & \(\) & \(\) & \(\) & \\   & Male & \(7.8 3.74\) & \(10.2 2.90\) & \(13.0 2.56\) & \(11.8 2.44\) & \(7.2 3.70\) & \(\) \\   & Female & \(12.2 3.74\) & \(9.8 2.90\) & \(7.0 2.56\) & \(8.2 2.44\) & \(12.8 3.70\) & \(\) \\    & Sum & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \\  

Table 1: Retrieval averaged over 10 queries with 50 retrievals on UTKFace dataset  for MOPR, Top-\(k\), and MMR . Entries indicate average percentage representation in retrieved items. MOPR is able to balance representation across classes, whereas Top-\(k\) and MMR miss intersectional groups (highlighted in red).

Acknowledgements

The authors would like to thank the discussions with Filipe Goulart Cabral. This material is based upon work supported by the National Science Foundation under awards CAREER-1845852, CIF-1900750, CIF-2231707, and CIF-2312667, FAI-2040880, and also by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-2140743. The views expressed here are those of the authors and do not reflect the official policy or position of the funding agencies.