# Creating a Public Repository for Joining Private Data

James Cook

Independent Researcher

falsifian@falsifian.org &Miliind Shyani

Amazon

mshyani@amazon.com &Nina Mishra

Amazon

nmishra@amazon.com

Work done while employed by Amazon.

###### Abstract

How can one publish a dataset with sensitive attributes in a way that both preserves privacy and enables joins with other datasets on those same sensitive attributes? This problem arises in many contexts, e.g., a hospital and an airline may want to jointly determine whether people who take long-haul flights are more likely to catch respiratory infections. If they join their data by a common keyed user identifier such as email address, they can determine the answer, though it breaks privacy. This paper shows how the hospital can generate a private sketch and how the airline can privately join with the hospital's sketch by email address. The proposed solution satisfies pure differential privacy and gives approximate answers to linear queries and optimization problems over those joins. Whereas prior work such as secure function evaluation requires sender/receiver interaction, a distinguishing characteristic of the proposed approach is that it is non-interactive. Consequently, the sketch can be published to a repository for any organization to join with, facilitating data discovery. The accuracy of the method is demonstrated through both theoretical analysis and extensive empirical evidence.

## 1 Introduction

Given a sensitive dataset keyed by individual identities (which must never be revealed), how can we publish a private version of it that can nonetheless be joined by identity to another dataset to produce approximate answers to questions about the join? Can a sender publish this private version to a repository so that receivers can both approximate joint distributions and train ML models, _without any interaction_ between the sender and the receiver?

There are _inter-organizational_ scenarios where answering these questions is valuable. For example, a healthcare provider may have clinical records keyed by patient email address and a private column such as "has cancer". A company wants to determine if employees who work near toxic waste sites have a higher incidence of cancer. We show how two companies can privately join their data in order to build such predictive models. With the rise of data marketplaces, it is more common for organizations to seek to "decorate" their data by adding new columns from other organizations, while preserving privacy. _Intra-organizational_ scenarios also abound. Within a large organization, it is common that data collected in one team is hidden from other teams. With a central repository, not only is data discovery possible, but more private joins can be performed to assess predictive power.

**The Repository Setting.** A stylized view of the problem is shown in Fig. 1. One party, the _sender_ S, holds a dataset \(D_{S}\) with two columns: a unique identifier to join on, and a value from a small finite domain (in this case, has cancer encoded as \( 1\)). S would like to share \(D_{S}\) in a privacy-preserving way with many other organizations without explicitly interacting with each one. To this end, S uploads a private representation of \(D_{S}\) to a public repository. Party R is one of many possible _receivers_, and holds a dataset which has a column with unique identities to join on, and any number of other columns, e.g., latitude and longitude of where their employees work. R's goal is to perform a jointcomputation - red box in Fig. 1. It involves the inner join that would normally include only people in both datasets. But, for privacy, the receiver R does not know about the existence of Alice; and even though David is not in S's data, R still receives a label, which is noise. This paper studies how R can learn functions over the inner join of R and S, e.g., does work location predict cancer positivity.

**Problem statement** Joint computation of linear queries and optimization are described in Subproblems 1.2 and 1.3. The dataset representations should be compatible with both problems simultaneously.

**Problem 1.1**.: _Given a dataset \(D_{S}\) with a unique identity column and one value column with a small finite domain, publish to a repository a single differentially private representation of \(D_{S}\) which can be combined with any other dataset \(D_{R}\) (so long as \(D_{R}\) has a column of unique identities for joining) to solve Subproblems 1.2 and 1.3._

A linear query involves applying some function \(f\) to each element in the join and outputting the sum.

**Subproblem 1.2** (Linear Queries).: _Let \(f\) be a real-valued function. Define_

\[_{D_{R},D_{S}}(f)=_{\,(D_{R})(D_{S})}f(D_{R}[\,],D_{S}[ \,\,])\]

_where \((D)\) is the set of identities that appear in \(D\) and \(D[\,\,]\) is the value associated with \(\,\,\) in \(D\). Given access to \(D_{R}\) and a differentially private representation of \(D_{S}\), find an estimate \(\) so that_

\[[|-_{D_{R},D_{S}}(f)|>]<\]

In an optimization query, the goal is to find a function \(f\) in a class of functions \(\) that approximately minimizes \(_{D_{R},D_{S}}(f)\). Supervised learning with a loss function is a special case.

**Subproblem 1.3** (Optimization Queries).: _Given a class \(\) of real-valued functions, let \(f_{}=_{f}_{D_{R},D_{S}} (f)\). Given access to \(D_{R}\) and a differentially private representation of \(D_{S}\), find a function \(\) such that_

\[[_{D_{R},D_{S}}()-_{D_{R},D _{S}}(f_{})>]<\]

**Contributions.** Problem 1.1 is solved by building upon work on private count sketches. This paper makes the following contributions. (1) **Method.** We show how to apply the private count sketch to enable a sender to share their data privately, enabling a receiver to approximately join it with their own dataset on individual identifiers to estimate linear queries and learn functions.The identities of the individuals in the sender's data are not revealed. A distinguishing characteristic of the method is that the algorithms are non-interactive, and hence are repository ready. (2) **Analysis.** A non-trivial mathematical analysis in the form of theorems bounding the error. For linear queries, Problem 1.2,

Figure 1: A stylized illustration of the Repository Problem. The sender S uploads a private count sketch capturing people who do and do not have cancer. The receiver R uses the sketch to decorate their data (work location) with a noisy version of Sâ€™s cancer column. Two noisy columns are generated: one for cancer (\(+1\)) and another for not (\(-1\)). R can then build an ML model to predict if employees who work near a toxic waste site are more likely to develop cancer.

our main result is Thm. 5.1. For optimization queries, Problem 1.3, our main result is Thm. 6.4, proved using a careful combination of tail bounds. (3) **Experiments.** (a) We conduct three sets of experiments on public data to compare our solutions to exact answers obtained by joining the data directly, with no privacy. With a reasonable privacy parameter (\(=1\)) we achieve over 92% accuracy on the EMNIST dataset, and applying logistic regression on the UCI Adult dataset, we lose less than 1% accuracy compared to training on the original data with no privacy. (b) We compare to related methods. We adapt the protocol of Zhao et al.  to allow for joins and show that our approach is more accurate. We also compare with the LabelDP  method on an already-joined dataset, and show that our method performs competitively despite having the harder task of performing a private non-interactive join.

## 2 Related Work

**Privacy.** Differential privacy [19; 18] is a widely used definition that intuitively guarantees that the outcome of a mechanism is essentially unchanged whether an individual is or is not in the dataset. One of the most commonly studied models of privacy in the literature is the _curator model_ where a trusted centralized repository holds all personal information. The role of the curator is to answer questions about the data in a differentially private way. In the _function release_ problem, the curator must release a single piece of data which can be used to answer an unlimited number of queries [24; 2; 14].

In our case, party S plays the role of curator. The private representation they upload to the public repository can be viewed as an example of function release. It does not depend on the structure of R's dataset or the particular function R aims to compute -- S has no knowledge of the parties R who might later download it. Therefore, we can view the sketch as a function accepting as "query" an entire dataset \(D_{R}\) together with the function to apply to the join.

**Private Sketches.** Sketching is a common technique used to summarize a dataset. The technique most relevant to this paper is the Count Sketch  which we describe in more detail below. Other influential sketching techniques include count min , tug of war , locality sensitive hashing  and AMS . Private variants of sketching have also been considered wherein, for example, the usual sketch is computed and noise is added. Two examples include the private count sketch [6; 39] and the private count min sketch . Count sketch has been used to solve a wide variety of problems, e.g., estimate histograms, frequencies, quantiles or heavy hitters. We add to this list of uses the ability to support data joins. Other examples of private sketch work include the Johnson-Lindenstrauss transform  and the loglog sketch  -- neither require additional noise for privacy. Private locality sensitive hashing  has been considered in the context of private function release.

We are not aware of past work that uses the count sketch to privately join. Nevertheless, it is possible to adapt prior private sketching work to our framework. However, since these solutions were not designed with our application in mind, they do not perform as well - see the experiments in SS7.2.

**Local DP.** describes an approach in the local model, where each individual publishes their own noisy data. If individual identities are discarded it precludes joins. If the central server in the local model records individual identities, the identities cannnot be published without compromising privacy. While our techniques are similar to past work in local differential privacy, there are important differences: we apply them in the _repository setting_ rather than a local DP setting (see Appendix H for a comparison), the frequencies sketched are always \(0\) or \(1\) because unique identifiers are being sketched, and our technique enables joins on those private identifiers. We optimize our use of count sketches for this setting (especially in SS6) and provide a novel experimental and theoretical analysis.

**Vertically Partitioned Data.** study a scenario where a user interactively queries multiple independent databases holding vertical partitions of a dataset. Other results include [30; 31; 33; 36]. Note that in our case, the protocol is non-interactive; each database has an identity column which must be used to join the tables; the identities are private; and some identities may be present in one database and not the other.

**Secure Function Evaluation.** In the cryptography community, there is extensive work showing how two parties \(A,B\) holding data \(x_{A},x_{B}\) can jointly compute \(f(x_{A},x_{B})\) without leaking any information beyond \(f(x_{A},x_{B})\)[37; 23]. For interactive, multi-party computation, cryptographic techniques are a superior solution. However, this paper is on non-interactive solutions for the repository setting. More comparison can be found in Appendix J.

## 3 Preliminaries

Notation\(\), \(\) and \(\) denote the sets of integers, nonnegative integers and reals. We let \(\) be some set of unique identifiers for people -- e.g. strings representing name and address. For datasets \(D,D^{}\), the _join_\(D D^{}\) is defined in Definition 3.1, and \(|D|\) is the number of rows in \(D\).

DatasetsA _dataset_\(D X\) is a set of pairs \((,x X)\); we call \(X\) its _value domain_ and its elements _rows_. In our problem there are two datasets: the sender's (\(D_{S}\)) and the receiver's (\(D_{R}\)). The value domain of \(D_{S}\) will always be \(X=\{1..k\}\) for some small \(k\), but there is no restriction on the value domain of \(D_{R}\): \(X\) could be numbers, text, images, etc. We do not allow any \(\) to appear more than once in the same dataset, so in particular there are no duplicate rows.

JoinsWhen the same identity appears in two datasets, we want to combine the associated values.

**Definition 3.1**.: The _join_ of \(D X\) and \(D^{} Y\) is a dataset \(D D^{} X Y\) defined by

\[(,x,y) D D^{}(,x) D(,y) D^{}\]

This an example of a _natural join_, using the identity column \(D\) and \(D^{}\) have in common. Given a function \(f:X Y\), we define the _sum over the join_:

**Definition 3.2**.: \[_{D,D^{}}(f)=_{(,x,y) D D^{ }}f(x,y)\]

(This is equivalent to the definition in Subproblem 1.2, but written in terms of \(D D^{}\).)

Differential PrivacyLet \(\) and \(\) be positive real numbers and \(M\) be a randomized algorithm. We say that \(M\) is _\((,)\)-differentially private_ if for all \(S(M)\) and for all pairs of datasets \(D_{1}\) and \(D_{2}\) that differ in the addition or removal of one row, \((M(D_{1}) S) e^{}(M(D_{2}) S)+\), where the probability is taken over the coin flips of \(M\). In this work we will always set \(=0\); in this case we say \(M\) is \(\)-differentially private; this is called _pure differential privacy_.

The two-sided geometric distributionThe noise we add to ensure privacy will follow the _two-sided geometric distribution_ (see notes in Appendix B.1):

**Definition 3.3**.: The _two-sided geometric distribution_ with parameter \(\), denoted \(()\), is a distribution over \(\) with probability mass function \([Z=z]=^{|z|}\).

Private Count SketchesWe use a simplified version of the _count sketch_ as a way to encode a dataset \(D\{1..k\}\). It is parameterized by a number of buckets \(b\) and two hash functions \(h:\{1..k\}\{1..b\}\), \(s:\{1..k\}\{-1,+1\}\).

**Definition 3.4**.: Given \(b\), \(h\) and \(s\) as above, the _count sketch_ of a dataset \(D\{1..k\}\) is a vector \(_{b,h,s}(D)=(c_{1},,c_{b})^{b}\), where \(c_{j}=_{(,y) D:h(,y)=j}s(,y)\).

Adding noise makes a count sketch differentially private:

**Definition 3.5**.: Given \(D\), \(b\), \(h\) and \(s\) as in Definition 3.4, and a privacy parameter \(>0\), the _private count sketch_ of \(D\) is a random vector \(_{b,h,s,}(D)=_{b,h,s}(D )+Z_{}^{b}\) where \(Z_{}\) is a vector of \(b\) independent samples from \((e^{-})\) (Definition 3.3).

Since adding or removing a row from \(D\) causes \(_{b,h,s}(D)\) to move a distance of 1 in the \(_{1}\) metric, we have :

**Proposition 3.6**.: \(_{b,h,s,}(D)\) _is \(\)-differentially private._

It is common to repeat the count sketch with multiple independent hash functions to mitigate error caused by hash collisions when there are fewer buckets than items (\(b<n\)). This is important when the goal is to recover frequencies of repeated items while storing the sketch in as few bits as possible. In contrast, our frequences are all \(1\) or \(0\) (present or not), and our goal is to estimate aggregates of many such frequencies. We are not trying to compress a stream, so we take \(b n\), at which pointwe find the error added by \(Z_{}\) dominates the error from hash collisions. We do not repeat the count sketch because it would improve error only slightly (if at all), and because it would complicate our analysis. In SS7.2 we compare to a private sketching method that uses multiple hash functions and Gaussian noise, and find it performs worse than Definition 3.5 for our purposes.

## 4 Method Overview

We begin with intuitive motivation for the method and then a provide an overview of the steps S and R take to solve Problem 1.1. In SSSS5 and 6 we explain R's computation in detail.

### Intuition and alternative approaches

Here is a simplified version of our problem. Suppose parties S and R each have a set of individuals' names \(D_{S},D_{R}=\{..\}^{*}\). R wishes to estimate the number of names in common: \(|D_{S} D_{R}|\). The names are sensitive and cannot be shared directly. Instead, S must publish a differentially private representation \(C=(D_{S})\) without consulting R, and then R must compute their estimate based on \(C\) and \(D_{R}\). This is a special case of Subproblem 1.2. Here are some possible approaches.

**Secure function evaluation.** In cryptography, this problem is called _private set intersection cardinality_[20; 26; 32]. Cryptographic solutions are well-studied, but require multiple rounds of interaction. In our _repository setting_, party S publishes a single value \((D_{S})\) and may not interact further. See Appendix J for a discussion on this comparison.

**Send the hashes.** One might try choosing a secure hash function \(h:\{0,1\}^{*}\) and sending \((D_{S})=\{h(x):x D_{S}\}\). The problem is that R would need to know \(h\) to compute \(|D_{R} D_{S}|\). Knowing \(h\) would let them test individuals' membership in \(D_{S}\), compromising privacy.

**Dot product of noisy vectors.** We can view the sets as vectors \(D_{S},D_{R}\{0,1\}^{}\), with one bit for every possible \(\). Then \(D_{S}^{}D_{R}=|D_{S} D_{R}|\). Party S can make their vector \(\)-differentially private by adding noise: \((D_{S})=D_{S}+Z_{}\), where \(Z_{}^{}\) is a vector of independent samples from \((e^{-})\). Party R can estimate \(|D_{R} D_{S}|(D_{S})^{T}D_{R}\). The problem is that \(\) is too big -- if identities are \(r\)-bit strings, then \((D_{S})\) takes more than \(2^{r}\) bits to store.

**Solution: Private count sketch.** The solution we use is a modification of the previous one: S sends a vector with noise added, but first reduces the dimension using a private count sketch.

### Protocol

Our solution to Problem 1.1 has two steps: (1) S publishes a sketch and some parameters (Algorithm 1; figure in Appendix A); (2) R downloads the sketch and runs Algorithm 2 (Subproblem 1.2, linear queries) or Algorithm 3 (Subproblem 1.3, choosing the optimal function from a class).

Although the elements of \(D_{S}\) are pairs \((,y)\{1..k\}\), we treat them as opaque values for the purpose of computing \(_{b,h,s,}(D_{S})\) -- so the domain of the hash functions \(h,s\) is \(\{1..k\}\). The time complexity of \(\) is \(O(|D_{S}|+b)\), assuming that sampling from \(()\) and computing the hash functions \(h\) and \(s\) all take constant time.

```
1:Let \(\{1..k\}\) be the range of \(D_{S}\)'s value column, i.e. \(D_{S}\{1..k\}\).
2:Choose the privacy budget \(\) and the number of hash buckets \(b\).
3:\(h,s(b)\)
4:\(C_{b,h,s,}(D_{S})\).
5:Publish \(C^{b}\) and the parameters \(k,b,h,s,\) to a repository.
```

**Algorithm 1**Sender

Choosing hash functionsBuilding a sketch requires first choosing hash functions \(h,s\) with an algorithm \((b)\). This choice has no effect on privacy: even if \( x,h(x)=s(x)=1\), the private count sketch is differentially private. However, higher-quality hash functions will give more accurate results. Thm. 6.4 assumes \(h\) and \(s\) are sampled uniformly from the set of all functions; in practice, cryptographically secure hash functions should give the same guarantees.

## 5 Linear queries

R can use Algorithm 2 to estimate \(_{D_{R},D_{S}}(f)\), given access to their own dataset \(D_{R}\) along with \(C=_{b,h,s,e}(D_{S})\) and the associated parameters \(k,b,h,s\) sent by S. Its time complexity is \(O(k|D_{R}|+b)\), assuming \(f(x,y)\) can be computed in constant time. The computation \(Q^{}C\) on lines 2-4 can be explained as follows. For every \((,x) D_{R}\) and \(y\{1..k\}\), R multiplies \(q(,x,y)=s(,y) f(x,y)\) by the entry at index \(h(,y)\) in S's sketch. In expectation this equals \(f(x,y)\) if \((,y) D_{S}\) and 0 otherwise. The sum of these values over \((,x) D_{R},y\{1..k\}\) is \(Q^{}C\), and equals \(_{D_{R},D_{S}}(f)\) in expectation. Here the expectation is taken over the output of ChooseHashFunctions and the \(()\) noise.

```
1:Download \(C=_{b,h,s,e}(D_{S})\) and the parameters \(k,b,h,s\) from the repository.
2:Set \(q(,x,y)^{b}\) to be \(s(,y)f(x,y)\) at entry \(h(,y)\) and 0 everywhere else.
3:Construct \(Q=_{(,x) D_{R}}_{y=1}^{k}q(,x,y)\), the query vector.
4:Return \(Q^{}C\).
```

**Algorithm 2**ReceiverLinearQueries

**Theorem 5.1**.: _For any datasets \(D_{R} X,D_{S}\{1..k\}\), function \(f:X\{1..K\}\), privacy parameter \(>0\), number of hash buckets \(b\), and accuracy parameter \(>0\), if \(h\) and \(s\) are drawn from a mutually 4-way independent hash family, the following holds. Let \(M\) be an upper bound on \(|f(x,y)|\), \(k\) be the range of the value column of \(D_{S}\), \(n=|D_{R} D_{S}|,C=_{b,h,s,e}(D_{S})\). Then_

\[[}C-_{D_{R},D_{S}}(f)|}{n}> ]|D_{R}|(k+1)}{^{2}n^{2}}( }{(1-e^{-})^{2}}+|}{b^{2}})\]

_The probability is taken over \(h,s\) and the noise added to \(_{b,h,s,e}(D_{S})\)._

We defer the proof to Appendix C. According to the theorem, the size of the join should be sufficiently large for it to be useful.

## 6 Optimization

Suppose R's dataset has an \(\) column and several feature columns, and S's has an \(\) column and a label column. In this section we show how R can train a model to predict S's labels from R's features. More generally, if R has a class of functions \(\) which map \(X Y\), we show how R can select \(\) which is close to the optimal function \(f_{}\),

\[f_{}:=*{arg\,min}_{}_{D_{R},D_{S}}(f)=*{arg\,min}_{f}_{( ,x,y) D_{R} D_{S}}f(x,y)\]

in the sense that \(|\,_{D_{R},D_{S}}()-_{D_{R},D _{S}}(f_{})|\) is small.

For example, suppose \(D_{S}\) has labels \(y\{0,1\}\) and \(D_{R}\) has feature vectors \(x^{d}\), and R would like to train a logistic regression model on \(D_{R} D_{S}\). Then R can take \(=\{_{}:^{d}\}\), where \(_{}\) is the logistic loss \(_{}(x,y)=y(1+e^{-^{}x})+(1-y)(1+e^{^{ }x})\).

In SS8.1 and 6.2 we show how to compute the estimate \(\), assuming we already have a non-private optimization algorithm that accepts _weighted inputs_. (For an alternative without weights, see Appendix E.) In SS6.3 we analyze the loss in accuracy due to privacy.

### Evaluating one function

Our optimization method is based on a _score_\(_{D_{R},C}(f)\) for individual functions \(f\), which R computes based on their dataset \(D_{R}\) and the sketch \(C\) sent by S. The score is a proxy for the true objective \(_{D_{R},D_{S}}(f)\). It is less sensitive to noise and hash collisions than the estimate \(Q^{}C\) from SS5. The cost is that \(_{D_{R},C}(f)\) does not actually approximate \(_{D_{R},D_{S}}(f)\).

Instead, the two have a linear relationship: \(_{D_{R},C}(f)_{D_{R},D_{S}}(f)\) for a positive number \(=(D_{R},D_{S},b,)\) which does not depend on \(f\). (We prove this in the appendix in Lemma D.3, as part of the proof of Thm. 6.4.) R does not know \(\), but does not need to: the optimization method described in SS6.2 boils down to computing \(*{arg\,min}_{f}_{D_{R},C}(f)\).

There are two differences between the score \(_{D_{R},C}(f)\) and the linear estimate \(Q^{}C\), developed while proving Theorem 6.4. First, we _clip_ coordinates of the sketch \(C\) to be between \(-1\) and \(1\).

**Definition 6.1**.: For \(x\), \((x)\) is 1 or -1 if \(x 1\) or \(x-1\); otherwise \((x)=x\). The _clipped version_ of a vector \(C^{b}\) is a vector with clipped entries: \((C)_{i}=(C_{i})\).

(Since our sketches have integer coordinates, \((x)\) equals the sign \((x)\{-1,0,1\}\). In SS7.2 we try a sketch with non-integer coordinates.) Second, when \(h\) hashes more than one row \((,x) D_{R}\) to the same coordinate of \(C\), we reweight the terms corresponding to those rows.

**Definition 6.2**.: The _score_ of \(f\) is defined as follows. Let \(N_{R}(a)\) be the number of possible pairs \((,y)\) where \(\) appears in \(D_{R}\), \(y\) is any value in \(\{1..k\}\), and \(h(,y)=a\):

\[_{D_{R},C}(f):=_{(,x) D_{R}}_{y=1}^{k},y)(C)_{h(,y)}f(x,y)}{N_{R}(h( ,y))}\]

### Performing the optimization

Here we show how R can compute the estimate \(\), given their own dataset \(D_{R}\), the parameters \(k,b,h,s,\), and \(C=_{b,h,s,}(D_{S})\) downloaded from the repository. In short, our method is simply to find the function \(f\) that minimizes the score defined in the previous section:

**Definition 6.3**.: The _estimated optimal function in \(\)_ is \(:=*{arg\,min}_{f}_{D_{R},C}(f)\).

If \(\) is a small finite set, this definition directly leads to an algorithm: R computes \(_{D_{R},C}(f)\) for every \(f\) and chooses the \(*{arg\,min}\) directly. For larger \(\)s we will assume R has an algorithm WeightedOpt to find the optimal \(f\) on a _weighted dataset_. A weighted dataset \(\) is a collection of \((w,x,y)\) triples where \(w\) is called the _weight_ and \((x,y)\) is a valid input to functions in \(\). To be precise, WeightedOpt minimizes

\[_{}(f):=_{(w_{,y},x,y) }-14.226378ptw_{,y}f(x,y)\]

Many algorithms for training machine learning models admit a weight associated with each training example; such an algorithm could play the role of WeightedOpt. R can now find the optimal function by implementing Algorithm 3. The time complexity of this algorithm is \(O(k|D_{R}|)+W(k|D_{R}|)\), where \(W(n)\) is the run-time complexity of WeightedOpt on a dataset with \(n\) elements.

By Definitions 6.2 and 6.3, the output of WeightedOpt is identical to the estimated optimal function \(\). The question of whether \(\) is any good is addressed in SS6.3.

```
1:Download \(C=_{b,h,s,}(D_{S})\) and the parameters \(k,b,h,s\).
2:\(w_{,y} s(,y)(C_{h(,y)})/N_{R}(h(,y)\) for \(y=1,,k\)
3:Construct \(=(b,h,s,D_{R},C)\) by creating \((w_{,y},x,y)\) for each element \((,x) D_{R}\) and \(y\{1..k\}\). \(//note:||=k|D_{R}|\)
4:Return WeightedOpt(\(,\))
```

**Algorithm 3**ReceiverOptimize

### Analysis

Here we analyze the accuracy of our method in the context of learning a classifier. We state and prove a more general result in Appendix D, and prove the below results in Appendices D.2 and D.3.

We bound the classification error of a model trained using our method on features from \(D_{R}\) and binary labels from \(D_{S}\) (so \(k=2\)). Let \(\) be a set of classifiers \(f:X\{0,1\}\), and for \(f\) let \(L_{f}\) be the number of classifications errors on \(D_{R} D_{S}\). To apply Algorithm 3, we convert this to an equivalent problem: let \(\) be the set of corresponding error functions \(e_{f}(x,y)=|f(x)-y|\) for \(f\), so \(L_{f}=_{D_{R},D_{S}}(e_{f})\). Then we can ask Algorithm 3 to find the best \(e_{f}\), which corresponds to the best classifier \(f\).

**Theorem 6.4**.: _For any datasets \(D_{R} X,D_{S}\{1..k\}\), function class \(\), privacy parameter \(>0\), number of hash buckets \(b\) and accuracy parameter \(>0\), if \(h\) and \(s\) are drawn uniformly at random from the set of all2 functions \(\{1..k\}\{1..b\}\), the following holds. Let \(f_{}\) be the classifier that minimizes \(L_{f}\), and let \(\) be the classifier corresponding to the function \(e_{f}\) output by Algorithm 3. Let \(d\) be the VC dimension of \(\), \(n=|D_{R} D_{S}|\), and_

\[=|}{n}=|}{n}-1 W_{R}= \{1,|}\} W_{S}=\{, ,|}}\}\]

_Then_

\[[}-L_{f_{}}}{n}>] (-(W_{S}}{+}^{2}n-d n))\]

For reference, we define VC dimension in Appendix B.4. Adding assumptions can simplify the bound. This corollary highlights the dependence on the privacy parameter \(\):

**Corollary 6.5**.: _Assume \(D_{R}\) and \(D_{S}\) have the same set of identities, so the join is "perfect" in the sense that \(|D_{R}|=|D_{S}|=|D_{R} D_{S}|\). Let \(n=|D_{R} D_{S}|\) and let \(d\) be the VC dimension of \(\). Assume also that \(b=(n)\). Let \(f_{}\) be the classifier that minimizes \(L_{f}\), and let \(\) be the classifier corresponding to the function \(e_{}\) output by Algorithm 3. Then for any \(>0\),_

\[[}-L_{f_{}}}{n}>] (-(^{2}n-d n))\]

## 7 Experiments

The goal of the experiments is to evaluate the accuracy of our solutions and quantify the effect of noise and join size on downstream tasks. To simulate parties S and R, for each dataset, we add a unique id to each row, then split its columns into \(D_{R}\) with all of the features and \(D_{S}\) with labels. In SS7.1 we learn a function that, given features \(x\), predicts labels \(y\{1..k\}\) using Algorithm 3 and a private count sketch. In Appendix F we estimate a joint distribution using Algorithm 2. In both cases, we find that the test error drops as we increase \(\) (meaning the privacy requirement is relaxed) or the sketch dimension, or as the join size increases (\(D_{R},D_{S}\) have more ids in common). In SS7.2 we compare our results with the private linear queries protocol of Zhao et al. . We also conduct experiments with multi-way joins and with non-unique identifiers in Appendix I.

**Datasets.** Two datasets are used in the experiments. (1) UC Irvine Adult dataset . We predict if income is greater than 50K based on categorical features such as _age_, _workclass_ and _education_. (2) Extended MNIST, for which we predict labels based on images of handwritten digits.

### Optimization: Prediction Findings

We evaluate our method with two machine learning tasks: logistic regression on the UCI Adult dataset, and a neural net for Extended MNIST. We capped the cross-entropy loss by replacing predicted probabilities \(\) with \(\{,10^{-4}\}\). This is necessary since Algorithm 3 can produce negative weights, which would lead to divergence in the optimization if loss were not bounded.

In each case, we conduct several experiments varying the privacy parameter3\(\) and the sketch dimension \(b\). All accuracy numbers are measured on the test set directly, with no simulated join. The right halves of Figs. 2 and 3 show the results, with different lines for different sketch dimensions \(b\). A dashed line shows the test accuracy of a model trained directly on the training set, without privacy.

Imperfect joins, where \(D_{R}\) has some IDs not present in \(D_{S}\), are simulated by randomly removing most of the rows in the training set, and then adding some back only to \(D_{R}\). The left halves of Figs. 2 and 3 show the results. The performance drops as this fraction increases, which is expected since unmatched rows in \(D_{R}\) are assigned random labels that add noise to the training. In practice, party R would benefit by filtering \(D_{R}\) to contain only identities likely to be in \(D_{S}\), e.g., if \(D_{S}\) contains people in Ohio, R should also filter \(D_{R}\) to Ohio. Note that on the right panel of Fig. 3, when \(=1\), the test accuracy is around 92%, however, on the left panel of Fig. 3, the performance drops to 80% for \(=1\). This is due to the smaller training set size (240K on the right vs 20K on the left).

We also train a neural net on the EMNIST bymerge dataset consisting of 760K images of handwritten digits and uppercase and lowercase letters, with 47 classes. We conduct this experiment to investigate the effects of large label domain sizes, i.e., large \(k\). Fig. 4, shows test accuracy as a function of the number of labels. For each run, we randomly chose out of 47 classes, and applied our method with \(=1\). The figure shows that, as expected, the performance degrades significantly as \(k\) increases, but the method is still viable with \(k=45\). Note that in this experiment, the size of the dataset, and thus the join size, changes as we change \(k\).

Our results are consistent with the dependence of Thm. D.2 on the parameters \(\), \(b\), and \(=|D_{R}|/|D_{R} D_{S}|\): test accuracy improves as \(\) or \(b\) increase, or \(|D_{R}|/|D_{R} D_{S}|\) or \(k\) decrease. Training details can be found in Appendix G.

### Comparison with other methods

To our knowledge, there is no past work on non-interactive private joins in the repository setting. However, one can replace our simplified private count sketch (Definition 3.5) with other private sketches. To this end, we incorporate Zhao et al's  private linear sketches into our method. Party S generates a sketch of \(\) pairs as before, but builds the sketch using Algorithms 1 and 3 from Zhao et al. instead of our Definition 3.5. Then, line 2 of Algorithm 3 is replaced with LinearSketchQuery from Zhao et al.s' Algorithm 2: \(w_{,y}(,y))\).

The EMNIST experiment is run with different combinations of Zhao et al.'s parameters \(,,\). Their protocol satisfies \(\)-zCDP; we use Proposition 1.4 of  to compare our results by equating \(=^{2}\). The number of hash buckets \(b\) is related to \(\) as \(b=1/\) and the number of hash functions (one for us) is given by \((2/)\).

Figure 3: Test accuracy of a deep neural net on the Extended MNIST dataset (Â§7.1).

Figure 2: Test accuracy of logistic regression on the UCI Adult salary prediction task (Â§7.1).

Zhao et al. describe two sketch implementations, Count-Min and CountSketch. Count-Min sketch is a random classifier on EMNIST for \( 10\), possibly because Count-Min is designed to avoid underestimating frequencies, whereas in our case it is more important to be correct on average. CountSketch leads to better results, Fig. 5. For \(=0.3\), there is one hash function, as with our method, and the remaining differences between the two methods is the kind of added noise (Gaussian vs two-sided geometric), and that LinearSketchQuery omits the denominator \(N(h(,y))\) on Line 2 of our Algorithm 3. Our method provides better results, especially for smaller \(\).

The accuracy of the model is roughly proportional to the number of correct vs. incorrect labels reconstructed in the join. For the corresponding values of \(\) and \((,,)\) in the two methods, the number of incorrect labels reconstructed is fewer for the two sided geometric noise than Gaussian. Gaussian noise has thinner tails which is helpful for reducing the probability of large error values but not helpful in our application where queries are in any case clipped to the range \([-1,1]\).

We also compare with LabelDP , which is a Local DP protocol that protects the _labels_. LabelDP is not designed to perform joins, and so we run it without splitting the training set. Results are shown in the right panel of Fig. 5. The definition of "neighbouring datasets" differs in the two settings: we use the "add/remove" definition where a single row is added or removed, but in LabelDP's definition, a single value is changed. To account for this, we double the privacy budget for LabelDP, so for example at \(=1\) on the \(x\)-axis, we actually give LabelDP a privacy budget of \(=2\).

The LabelDP method benefits from not needing to perform a join, and so we expect it to perform better than our method, where the parties must join using a non-interactive protocol. We were surprised to see our method perform better for small \(\), and do not understand why this happens.

**Future Work.** This work focused on when the sender has a single private label column. To broaden applicability, data with multiple columns and data of different types, such as real-valued or text, deserve consideration. New privacy challenges arise in the streaming setting where organizations continuously receive new data and discard outdated data.

Figure 4: Test accuracy as the domain size of the labels, \(k\), increases.

Figure 5: Comparisons with other baselines. The definition of neighboring datasets is different for LabelDP and ours: \(2_{}_{}\), roughly. We have taken this into account in the right panel.

#### Acknowledgments

We would like to thank Joan Feigenbaum, Bill Horne, Yonatan Naamad, Aaron Roth, Doug Terry, Tal Wagner, and the anonymous reviewers for helpful feedback, comments and suggestions that improved this paper.