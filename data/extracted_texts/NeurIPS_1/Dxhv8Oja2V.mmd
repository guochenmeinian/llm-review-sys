# Convergence Analysis of Sequential Federated Learning on Heterogeneous Data

Yipeng Li and Xinchen Lyu

National Engineering Research Center for Mobile Network Technologies

Beijing University of Posts and Telecommunications

Beijing, 100876, China

{liyipeng, lvxinchen}@bupt.edu.cn

Xinchen Lyu is the corresponding author.

###### Abstract

There are two categories of methods in Federated Learning (FL) for joint training across multiple clients: i) parallel FL (PFL), where clients train models in a parallel manner; and ii) sequential FL (SFL), where clients train models in a sequential manner. In contrast to that of PFL, the convergence theory of SFL on heterogeneous data is still lacking. In this paper, we establish the convergence guarantees of SFL for strongly/general/non-convex objectives on heterogeneous data. The convergence guarantees of SFL are better than that of PFL on heterogeneous data with both full and partial client participation. Experimental results validate the counterintuitive analysis result that SFL outperforms PFL on extremely heterogeneous data in cross-device settings.

## 1 Introduction

Federated Learning (FL) (McMahan et al., 2017) is a popular distributed machine learning paradigm, where multiple clients collaborate to train a global model. To preserve data privacy and security, data must be kept in clients locally cannot be shared with others, causing one severe and persistent issue, namely "data heterogeneity". In cross-device FL, where data is generated and kept in massively distributed resource-constrained devices (e.g., IoT devices), the negative impact of data heterogeneity would be further exacerbated (Jhunjhunwala et al., 2023).

There are two categories of methods in FL to enable distributed training across multiple clients (Qu et al., 2022): i) parallel FL (PFL), where models are trained in a parallel manner across clients with synchronization at intervals, e.g., Federated Averaging (FedAvg) (McMahan et al., 2017); and ii) sequential FL (SFL), where models are trained in a sequential manner across clients, e.g., Cyclic Weight Transfer (WT) (Chang et al., 2018). However, both categories of methods suffer from the "client drift" (Karimireddy et al., 2020), i.e., the local updates on heterogeneous clients would drift away from the right direction, resulting in performance degradation.

Motivation.Recently, SFL (more generally, the sequential training manner, see Algorithm 1) has attracted much attention in the FL community (Lee et al., 2020). Specifically, SFL demonstrates advantages on training speed (in terms of training rounds) (Zaccone et al., 2022) and small datasets (Kamp et al., 2023), and both are crucial for cross-device FL. Furthermore, the sequential manner has played a great role in Split learning (SL) (Gupta and Raskar, 2018; Thapa et al., 2022), an emerging distributed learning technology at the edge side (Zhou et al., 2019), where the full model is split into client-side and server-side portions to alleviate the excessive computation overhead for resource-constrained devices. Appendix A will show that the convergence theory in this work is also applicable to SL.

Convergence theory is critical for analyzing the learning performance of algorithms on heterogeneous data in FL. So far, there are numerous works to analyze the convergence of PFL (Li et al., 2019; Khaled et al., 2020; Koloskova et al., 2020) on heterogeneous data. However, the convergence theory of SFL on heterogeneous data, given the complexity of its sequential training manner, has not been well investigated in the literature, with only limited preliminary empirical studies Gao et al. (2020, 2021). This paper aims to establish the convergence guarantees for SFL and compare the convergence results of PFL and SFL.

Setup.In the following, we provide some preliminaries about SFL and PFL.

Problem formulation.The basic FL problem is to minimize a global objective function:

\[_{^{d}}\{F() _{m=1}^{M}(F_{m}()_{_{m}}[ f_{m}(;)])\},\]

where \(F_{m}\), \(f_{m}\) and \(_{m}\) denote the local objective function, the loss function and the local dataset of client \(m\) (\(m[M]\)), respectively. In particular, when \(_{m}\) has finite data samples \(\{_{m}^{i}:i[|_{m}|]\}\), the local objective function can also be written as \(F_{m}()=_{m}|}_{i=1}^{|_{m}|}f_ {m}(;_{m}^{i})\).

Update rule of SFL.At the beginning of each training round, the indices \(_{1},_{2},,_{M}\) are sampled without replacement from \(\{1,2,,M\}\) randomly as the clients' training order. Within a round, each client i) initializes its model with the latest parameters from its previous client; ii) performs \(K\) steps of local updates over its local dataset; and iii) passes the updated parameters to the next client. This process continues until all clients finish their local training. Let \(_{m,k}^{(r)}\) denote the local parameters of the \(m\)-th client (i.e., client \(_{m}\)) after \(k\) local steps in the \(r\)-th round, and \(^{(r)}\) denote the global parameter in the \(r\)-th round. With SGD (Stochastic Gradient Descent) as the local solver, the update rule of SFL is as follows:

\[:_{m,k+1}^{(r)}=_{m,k}^{(r )}-_{_{m},k}^{(r)},_{m,0}^{(r )}=^{(r)}\,,&m=1\\ _{m-1,K}^{(r)}\,,&m>1\] \[:^{(r+1)}=_{M,K}^{(r)}\]

where \(_{_{m},k}^{(r)} f_{_{m}}(_{m,k}^{(r )};)\) denotes the stochastic gradient of \(F_{_{m}}\) regarding parameters \(_{m,k}^{(r)}\) and \(\) denotes the learning rate. See Algorithm 1. Notations are summarized in Appendix C.1.

Update rule of PFL.Within a round, each client i) initializes its model with the global parameters; ii) performs \(K\) steps of local updates; and iii) sends the updated parameters to the central server. The server will aggregate the local parameters to generate the global parameters. See Algorithm 2

In this work, unless otherwise stated, we use SFL and PFL to represent the classes of algorithms that share the same update rule as Algorithm 1 and Algorithm 2, respectively.

```
Output:\(}^{(R)}\): weighted average on \(^{(r)}\)
1fortraining round \(r=0,1,,R-1\)do
2 Sample a permutation \(_{1},_{2},,_{M}\) of \(\{1,2,,M\}\)
3for\(m=1,2,,M\)in sequencedo
4\(_{m,0}^{(r)}=^{(r)}\,,&m=1\\ _{m-1,K}^{(r)}\,,&m>1\)
5forlocal step \(k=0,,K-1\)do
6\(_{m,k+1}^{(r)}=_{m,k}^{(r)}-_{_{m},k}^{(r )}\)
```

**Algorithm 1**Sequential FL

``` Output:\(}^{(R)}\): weighted average on \(^{(r)}\)
1fortraining round \(r=0,1,,R-1\)do
2for\(m=1,2,,M\)in paralleldo
3\(_{m,0}^{(r)}=^{(r)}\)
4forlocal step \(k=0,,K-1\)do
5\(_{m,k+1}^{(r)}=_{m,k}^{(r)}-_{m,k}^{(r )}\)
6 Global model: \(^{(r+1)}=_{m=1}^{M}_{m,K}^{(Contributions

Brief literature review.The most relevant work is the convergence of PFL and Random Reshuffling (SGD-RR). There are a wealth of works that have analyzed the convergence of PFL on data heterogeneity (Li et al., 2019; Khaled et al., 2020; Karimireddy et al., 2020; Koloskova et al., 2020; Woodworth et al., 2020), system heterogeneity (Wang et al., 2020), partial client participation (Li et al., 2019; Yang et al., 2021; Wang and Ji, 2022) and other variants (Karimireddy et al., 2020; Reddi et al., 2021). In this work, we compare the convergence bounds between PFL and SFL (see Subsection 3.3) on heterogeneous data.

SGD-RR (where data samples are sampled without replacement) is deemed to be more practical than SGD (where data samples are sample with replacement), and thus attracts more attention recently. Gurbuzbalaban et al. (2021); Haochen and Sra (2019); Nagaraj et al. (2019); Ahn et al. (2020); Mishchenko et al. (2020) have proved the upper bounds and Safran and Shamir (2020, 2021); Rajput et al. (2020); Cha et al. (2023) have proved the lower bounds of SGD-RR. In particular, the lower bounds in Cha et al. (2023) are shown to match the upper bounds in Mishchenko et al. (2020). In this work, we use the bounds of SGD-RR to exam the tightness of that of SFL (see Subsection 3.2).

Recently, the shuffling-based method has been applied to FL (Mishchenko et al., 2022; Yun et al., 2022; Cho et al., 2023; Malinovsky et al., 2023). The most relevant works are FL with cyclic client participation (Cho et al., 2023) and FL with shuffling client participation (Malinovsky et al., 2023). The detailed comparisons are given in Appendix B.

Challenges.The theory of SGD is applicable to SFL on homogeneous data, where SFL can be reduced to SGD. However, the theory of SGD can be no longer applicable to SFL on heterogeneous data. This is because for any pair of indices \(m\) and \(k\) (except \(m=1\) and \(k=0\)) within a round, the stochastic gradient is not an (conditionally) unbiased estimator of the global objective:

\[[ f_{_{m}}(_{m,k};)]  F(_{m,k})\;.\]

In general, the challenges of establishing convergence guarantees of SFL mainly arise from (i) the sequential training manner across clients and (ii) multiple local steps of SGD at each client.

Sequential training manner across clients (vs. PFL).In PFL, local model parameters are updated in parallel within each round and synchronized at the end of the round. In this case, the local updates across clients are mutually independent when conditional on all the randomness prior to the round. However, in SFL, client's local updates additionally depend on the randomness of all previous clients. This makes bounding the client drift of SFL more complex than that of PFL.

Multiple local steps of SGD at each client (vs. SGD-RR).SGD-RR samples data samples without replacement and then performs one step of gradient descent (GD) on each data sample. Similarly, SFL samples clients without replacement and then performs multiple steps of SGD on each local objective (i.e., at each client). In fact, SGD-RR can be regarded as a special case of SFL. Thus, the derivation of convergence guarantees of SFL is also more complex than that of SGD-RR.

Contributions.The main contributions are as follows:

* We derive convergence guarantees of SFL for strongly convex, general convex and non-convex objectives on heterogeneous data with the standard assumptions in FL in Subsection 3.2.
* We compare the convergence guarantees of PFL and SFL, and find a _counterintuitive_ comparison result that the guarantee of SFL is better than that of PFL (with both full participation and partial participation) in terms of training rounds on heterogeneous data in Subsection 3.3.
* We validate our comparison result with simulations on quadratic functions (Subsection 4.1) and experiments on real datasets (Subsection 4.2). The experimental results exhibit that SFL outperforms PFL on extremely heterogeneous data in cross-device settings.

## 3 Convergence theory

We consider three typical cases for convergence theory, i.e., the strongly convex case, the general convex case and the non-convex case, where all local objectives \(F_{1},F_{2},,F_{M}\) are \(\)-strongly convex, general convex (\(=0\)) and non-convex.

### Assumptions

We assume that (i) \(F\) is lower bounded by \(F^{*}\) for all cases and there exists a minimizer \(^{*}\) such that \(F(^{*})=F^{*}\) for strongly and general convex cases; (ii) each local objective function is \(L\)-smooth (Assumption 1). Furthermore, we need to make assumptions on the diversities: (iii) the assumptions on the stochasticity bounding the diversity of \(\{f_{m}(;_{m}^{i}):i[|_{m}|]\}\) with respect to \(i\) inside each client (Assumption 2); (iv) the assumptions on the heterogeneity bounding the diversity of local objectives \(\{F_{m}:m[M]\}\) with respect to \(m\) across clients (Assumptions 3a, 3b).

**Assumption 1** (\(L\)-Smoothness).: _Each local objective function \(F_{m}\) is \(L\)-smooth, \(m\{1,2,,M\}\), i.e., there exists a constant \(L>0\) such that \(\| F_{m}()- F_{m}()\| L\| -\|\) for all \(,^{d}\)._

_Assumptions on the stochasticity._ Since both Algorithms 1 and 2 use SGD (data samples are chosen with replacement) as the local solver, the stochastic gradient at each client is an (conditionally) unbiased estimate of the gradient of the local objective function: \(_{_{m}}[.f_{m}(;)| ]= F_{m}()\). Then we use Assumption 2 to bound the stochasticity, where \(\) measures the level of stochasticity.

**Assumption 2**.: _The variance of the stochastic gradient at each client is bounded:_

\[_{_{m}}[\| f_{m}(;)-  F_{m}()\|^{2}|]^{2}, \,m\{1,2,,M\} \]

_Assumptions on the heterogeneity._ Now we make assumptions on the diversity of the local objective functions in Assumption 3a and Assumption 3b, also known as the heterogeneity in FL. Assumption 3a is made for non-convex cases, where the constants \(\) and \(\) measure the heterogeneity of the local objective functions, and they equal zero when all the local objective functions are identical to each other. Further, if the local objective functions are strongly and general convex, we use one weaker assumption 3b as Koloskova et al. (2020), which bounds the diversity only at the optima.

**Assumption 3a**.: _There exist constants \(^{2}\) and \(^{2}\) such that_

\[_{m=1}^{M}\| F_{m}()- F() \|^{2}^{2}\| F()\|^{2}+^{2} \]

**Assumption 3b**.: _There exists one constant \(_{*}^{2}\) such that_

\[_{m=1}^{M}\| F_{m}(^{*})\|^{2}= _{*}^{2} \]

_where \(^{*}_{^{d}}F()\) is one global minimizer._

### Convergence analysis of SFL

**Theorem 1**.: _For SFL (Algorithm 1), there exist a constant effective learning rate \( MK\) and weights \(w_{r}\), such that the weighted average of the global parameters \(}^{(R)}}_{r=0}^{R}w_{r}^{ (r)}\) (\(W_{R}=_{r=0}^{R}w_{r}\)) satisfies the following upper bounds:_

_Strongly convex: Under Assumptions 1, 2, 3b, there exist a constant effective learning rate \(\) and weights \(w_{r}=(1-}{2})^{-(r+1)}\), such that it holds that_

\[[F(}^{(R)})-F(^{*})] D^{2}(-R}{2})+^{2}}{MK}+^{2}^{2}}{MK}+^{2}_{*}^{2}}{M} \]

_General convex: Under Assumptions 1, 2, 3b, there exist a constant effective learning rate \(\) and weights \(w_{r}=1\), such that it holds that_

\[[F(}^{(R)})-F(^{*})]}{R}+^{2}}{MK}+ ^{2}^{2}}{MK}+^{2}_{*}^{2}}{M} \]

_Non-convex: Under Assumptions 1, 2, 3a, there exist a constant effective learning rate \(\) and weights \(w_{r}=1\), such that it holds that_

\[_{0 r R}[\| F(^{(r)})\|^ {2}]R}+^{2}}{MK}+ ^{2}^{2}}{8MK}+^{2} ^{2}}{8M} \]

_where \(D\|x^{(0)}-x^{*}\|\) for the convex cases and \(A F(^{(0)})-F^{*}\) for the non-convex case.__The effective learning rate \( MK\) is used in the upper bounds as Karimireddy et al. (2020); Wang et al. (2020) did. All these upper bounds consist of two parts: the optimization part (the first term) and the error part (the last three terms). Setting \(\) larger can make the optimization part vanishes at a higher rate, yet cause the error part to be larger. This implies that we need to choose an appropriate \(\) to achieve a balance between these two parts, which is actually done in Corollary 1. Here we choose the best learning rate with a prior knowledge of the total training rounds \(R\), as done in the previous works (Karimireddy et al., 2020; Reddi et al., 2021)._

**Corollary 1**.: _Applying the results of Theorem 1. By choosing a appropriate learning rate (see the proof of Theorem 1 in Appendix D), we can obtain the convergence bounds for SFL as follows:_

_Strongly convex__: Under Assumptions 1, 2, 3b, there exist a constant effective learning rate \(\) and weights \(w_{r}=(1-}{2})^{-(r+1)}\), such that it holds that_

\[[F(}^{(R)})-F(^{*})]=}(}{ MKR}+}{^{2}MKR^{2 }}+^{2}}{^{2}MR^{2}}+ D^{2}(- )) \]

_General convex__: Under Assumptions 1, 2, 3b, there exist a constant effective learning rate \(\) and weights \(w_{r}=1\), such that it holds that_

\[[F(}^{(R)})-F(^{*})]= (}+D^{4})^{1/3}}{( MK)^{1/3}R^{2/3}}+^{2}D^{4})^{1/3}}{M^{1/3}R^{2/3}}+ }{R}) \]

_Non-convex__: Under Assumptions 1, 2, 3a, there exist a constant effective learning rate \(\) and weights \(w_{r}=1\), such that it holds that_

\[_{0 r R}[\| F(^{(r)})\|^ {2}]=(A)^{1/2}}{ }+^{2}A^{2})^{1/3}}{(MK)^{1/3}R^{2/3}}+^{2}A^{2})^{1/3}}{M^{1/3}R^{2/3}}+) \]

_where \(\) omits absolute constants, \(}\) omits absolute constants and polylogarithmic factors, \(D\|x^{(0)}-x^{*}\|\) for the convex cases and \(A F(^{(0)})-F^{*}\) for the non-convex case._

_Convergence rate._ By Corollary 1, for sufficiently large \(R\), the convergence rate is determined by the first term for all cases, resulting in convergence rates of \(}(1/MKR)\) for strongly convex cases, \((1/)\) for general convex cases and \((1/)\) for non-convex cases.

_SGD-RR vs. SFL._ Recall that SGD-RR can be seen as one special case of SFL, where one step of GD is performed on each local objective \(F_{m}\) (i.e, \(K=1\) and \(=0\)). The bound of SFL turns to \(}(^{2}}{^{2}MR^{2}}+ D^{2} (-))\) when \(K=1\) and \(=0\) for the strongly convex case. Then let us borrow the upper bound from Mishchenko et al. (2020)'s Corollary 1,

\[[\|^{(R)}-^{*}\|^{2}]=}(^{2}}{^{3}MR^ {2}}+D^{2}(-)).\]

As we can see, the bound of SGD-RR only has an advantage on the second term (marked in red), which can be omitted for sufficiently large \(R\). The difference on the constant \(\) is because their bound is for \([\|^{(R)}-^{*}\|^{2}]\) (see Stich (2019)b). Furthermore, our bound also matches the lower bound \((^{2}}{^{2}MR^{2}})\) of SGD-RR suggested by Cha et al. (2023)'s Theorem 3.1 for sufficiently large \(R\). For the general convex and non-convex cases, the bounds of SFL (when \(K=1\) and \(=0\)) also match that of SGD-RR (see Mishchenko et al. (2020)'s Theorems 3, 4). These all suggest our bounds are tight. Yet a specialized lower bound for SFL is still required.

_Effect of local steps._ Two comments are included: i) It can be seen that local updates can help the convergence with proper learning rate choices (small enough) by Corollary 1. Yet this increases the total steps (iterations), leading to a higher computation cost. ii) Excessive local updates do not benefit the dominant term of the convergence rate. Take the strongly convex case as an example. When \(}{ MKR}}{^{2}MR^{2}}\), the latter turns dominant, which is unaffected by \(K\). In other words, when the value of \(K\) exceed \((^{2}/_{*}^{2}/L R)\), increasing local updates will no longer benefit the dominant term of the convergence rate. Note that the maximum value of \(K\) is affected by \(^{2}/_{*}^{2}\), \(/L\) and \(R\). This analysis follows Reddi et al. (2021); Khaled et al. (2020).

### PFL vs. SFL on heterogeneous data

Unless otherwise stated, our comparison is in terms of training rounds, which is also adopted in Gao et al. (2020, 2021). This comparison (running for the same total training rounds \(R\)) is fair considering the same total computation cost for both methods.

_Convergence results of PFL._ We summarize the existing convergence results of PFL for the strongly convex case in Table 1. Here we slightly improve the convergence result for strongly convex cases by combining the works of Karimireddy et al. (2020); Koloskova et al. (2020). Besides, we note that to derive a unified theory of Decentralized SGD, the proofs of Koloskova et al. (2020) are different from other works focusing on PFL. So we reproduce the bounds for general convex and non-convex cases based on Karimireddy et al. (2020). All our results of PFL are in Theorem 2 (see Appendix E).

_The convergence guarantee of SFL is better than PFL on heterogeneous data._ Take the strongly convex case as an example. According to Table 1, the upper bound of SFL is better than that of PFL, with an advantage of \(1/M\) on the second and third terms (marked in red). This benefits from its sequential and shuffling-based training manner. Besides, we can also note that the upper bounds of both PFL and SFL are worse than that of Minibatch SGD.

_Partial client participation._ In the more challenging cross-device settings, only a small fraction of clients participate in each round. Following the works (Li et al., 2019; Yang et al., 2021), we provide the upper bounds of PFL and SFL with partial client participation as follows:

\[}(}{ SKR }+^{2}}{ R}+}{^{2}KR^ {2}}+^{2}}{^{2}R^{2}}+ D^{2}(- )) \] \[}(}{ SKR }+^{2}}{ R}+}{^{2} SKR^{2}}+^{2}}{^{2}SR^{2}}+ D^{2}(- )) \]

where \(S\) clients are selected randomly without replacement. There are additional terms (marked in blue) for both PFL and SFL, which is due to partial client participation and random sampling (Yang et al., 2021). It can be seen that the advantage of \(1/S\) (marked in red) of SFL also exists, similar to the full client participation setup.

   Method & Bound (\(D=\|x^{(0)}-x^{*}\|\)) \\  SGD (Stich, 2019b) & \(}{ MKR}+LD^{2}(-)^{(1)}\) \\  PFL & \\ (Karimireddy et al., 2020) & \(}{ MKR}+}{^{2}KR^{2}}+ }{^{2}R^{2}}+ D^{2}(-)^{(2)}\) \\ (Koloskova et al., 2020) & \(}{ MKR}+}{^{2}KR^{2}}+ ^{2}}{^{2}R^{2}}+LKD^{2}(-)^{(3)}\) \\ Theorem 2 & \(}{ MKR}+}{^{2}KR^{2}}+ ^{2}}{^{2}R^{2}}+ D^{2}(-)\) \\  SFL & \\  & }{ MKR}+}{^{2}MKR^{2}}+ ^{2}}{^{2}MR^{2}}+ D^{2}(-)\)} \\  & & \\   

* SGD with a large mini-batch size. We get the bound in the table by replacing \(^{2}\) in the Stich (2019b)’s result with \(}{MR}\). See Woodworth et al. (2020) for more details about Minibatch SGD.
* Karimireddy et al. (2020) use \(_{m=1}^{M}\| F_{m}()\|^{2} B^{2}\|  F()\|+G^{2}\) to bound the heterogeneity, which is equivalent to Assumption 3a. The global learning rate is not considered in this work.
* Koloskova et al. (2020) use \(_{*}^{2}_{m=1}^{M}[\| f_{m }(^{*};)- F_{m}(^{*})\|^{2}]\) to bound the stochasticity, which is weaker than Assumption 3b.

Table 1: Upper bounds in the strongly convex case with absolute constants and polylogarithmic factors omitted. All results are for heterogeneous settings.

Experiments

We run experiments on quadratic functions (Subsection 4.1) and real datasets (Subsection 4.2) to validate our theory. The main findings are i) in extremely heterogeneous settings, SFL performs better than PFL, ii) while in moderately heterogeneous settings, this may not be the case.

### Experiments on quadratic functions

According to Table 1, SFL outperforms PFL on heterogeneous settings (in the worst case). Here we show that the counterintuitive result (in contrast to Gao et al. (2020, 2021)) can appear even for simple one-dimensional quadratic functions (Karimireddy et al., 2020).

_Results of simulated experiments._ As shown in Table 2, we use four groups of experiments with various degrees of heterogeneity. To further catch the heterogeneity, in addition to Assumption 2(b), we also use bounded Hessian heterogeneity in Karimireddy et al. (2020):

\[_{m}\|^{2}F_{m}()-^{2}F()\| \;.\]

Choosing larger values of \(_{*}\) and \(\) means higher heterogeneity. The experimental results of Table 2 are shown in Figure 1. When \(_{*}=0\) and \(=0\), SFL outperforms PFL (Group 1). When \(_{*}=1\) and \(=0\), the heterogeneity has no bad effect on the performance of PFL while hurts that of SFL significantly (Group 2). When the heterogeneity continues to increase to \(>0\), SFL outperforms PFL with a faster rate and better result (Groups 3 and 4). This in fact tells us that the comparison between PFL and SFL can be associated with the data heterogeneity, and SFL outperforms PFL when meeting high data heterogeneity, which coincides with our theoretical conclusion.

_Limitation and intuitive explanation._ The bounds (see Table 1) above suggest that SFL outperforms PFL regardless of heterogeneity (the value of \(_{*}\)), while the simulated results show that it only holds in extremely heterogeneous settings. This inconsistency is because existing theoretical works (Karimireddy et al., 2020; Koloskova et al., 2020) with Assumptions 2(a), 2(b) may underestimate the capacity of PFL, where the function of global aggregation is omitted. In particular, Wang et al. (2022) have provided rigorous analyses showing that PFL performs much better than the bounds suggest in moderately heterogeneous settings. Hence, the comparison turns vacuous under this condition. Intuitively, PFL updates the global model less frequently with more accurate gradients (with the global aggregation). In contrast, SFL updates the global model more frequently with less accurate gradients. In homogeneous (gradients of both are accurate) and extremely heterogeneous settings (gradients of both are inaccurate), the benefits of frequent updates become dominant, and thus SFL outperforms PFL. In moderately heterogeneous settings, it's the opposite.

    & Group 1 & Group 2 & Group 3 & & Group 4 \\   & \(F_{1}(x)=x^{2}\\ F_{2}(x)=x^{2}\) & \(F_{1}(x)=x^{2}+x\\ F_{2}(x)=x^{2}-x\) & \(F_{1}(x)=x^{2}+x\\ F_{2}(x)=x^{2}-x\) & \(F_{1}(x)=x^{2}+x\\ F_{2}(x)=-x\) \\ \(_{*},\) & \(_{*}=0,=0\) & \(_{*}=1,=0\) & \(_{*}=1,=\) & \(_{*}=1,=1\) \\   

Table 2: Settings of simulated experiments. Each group has two local objectives (i.e., \(M=2\)) and shares the same global objective. The heterogeneity increases from Group 1 to Group 4.

Figure 1: Simulations on quadratic functions. It displays the experimental results from Group 1 to Group 4 in Table 2 from left to right. Shaded areas show the min-max values.

### Experiments on real datasets

Extended Dirichlet strategy.This is to generate arbitrarily heterogeneous data across clients by extending the popular Dirichlet-based data partition strategy (Yurochkin et al., 2019; Hsu et al., 2019). The difference is to add a step of allocating classes (labels) to determine the number of classes per client (denoted by \(C\)) before allocating samples via Dirichlet distribution (with concentrate parameter \(\)). Thus, the extended strategy can be denoted by \((C,)\). The implementation is as follows (with more details deferred to Appendix G.1):

* Allocating classes: We randomly allocate \(C\) different classes to each client. After assigning the classes, we can obtain the prior distribution \(_{c}\) for each class \(c\).
* Allocating samples: For each class \(c\), we draw \(_{c}(_{c})\) and then allocate a \(_{c,m}\) proportion of the samples of class \(c\) to client \(m\). For example, \(_{c}=[1,1,0,0,,]\) means that the samples of class \(c\) are only allocated to the first 2 clients.

Experiments in cross-device settings.We next validate the theory in cross-device settings (Kairouz et al., 2021) with partial client participation on real datasets.

Setup.We consider the common CV tasks training VGGs (Simonyan and Zisserman, 2014) and ResNets (He et al., 2016) on CIFAR-10 (Krizhevsky et al., 2009) and CINIC-10 (Darlow et al., 2018). Specifically, we use the models VGG-9 (Lin et al., 2020) and ResNet-18 (Acar et al., 2021). We partition the training sets of CIFAR-10 into 500 clients / CINIC-10 into 1000 clients by \((1,10.0)\) and \((2,10.0)\); and spare the test sets for computing test accuracy. As both partitions share the same parameter \(=10.0\), we use \(C=1\) (where each client owns samples from one class) and \(C=2\) (where each client owns samples from two classes) to represent them, respectively. Note that these two partitions are not rare in FL (Li et al., 2022). They are called extremely heterogeneous data and moderately heterogeneous data respectively in this paper. We fix the number of participating clients to 10 and the mini-batch size to 20. The local solver is SGD with learning rate being constant, momentent being 0 and weight decay being 1e-4. We apply gradient clipping to both algorithms (Appendix G.2) and tune the learning rate by grid search (Appendix G.3).

The best learning rate of SFL is smaller than that of PFL.We have the following observations from Figure 2: i) the best learning rates of SFL is smaller than that of PFL (by comparing PFL and SFL), and ii) the best learning rate of SFL becomes smaller as data heterogeneity increases (by comparing the top row and bottom row). These observations are critical for hyperparameter selection.

Effect of local steps.Figure 3 is aimed to study the effects of local steps. In both plots, it can be seen that the performance of SFL improves as \(K\) increases from 1 to 5. This validates the theoretical conclusion that local steps can help the convergence of SFL even on heterogeneous data. Then, the performance of SFL deteriorates as \(K\) increases from 5 to 10, whereas the upper bound of SFL always diminishes as long as \(K\) increases. This is because when \(K\) exceeds one threshold, the dominant term of the upper bound will be immune to its change as stated in Subsection 3.2. Then, considering "catastrophic forgetting" (Kirkpatrick et al., 2017; Sheller et al., 2019) problems in SFL, it can be expected to see such phenomenon.

SFL outperforms PFL on extremely heterogeneous data.The test accuracy results for various tasks are collected in Table 3. When \(C=1\) (extremely heterogeneous), the performance of SFL is better than that of PFL across all tried settings. When \(C=2\) (moderately heterogeneous), PFL can achieve the close or even slightly better performance than SFL in some cases (e.g., CIFAR-10/\(C=2\)/\(K=50\)). This is consistent with our observation and analysis in Subsection 4.1. Notably, on the more complicated dataset CINIC-10, SFL shows better for all settings, which may be due to higher heterogeneity.

Figure 3: Effect of local steps.

Figure 2: Test accuracies after training VGG-9 on CIFAR-10 for 1000 training rounds with different learning rates.

## 5 Conclusion

In this paper, we have derived the convergence guarantees of SFL for strongly convex, general convex and non-convex objectives on heterogeneous data. Furthermore, we have compared SFL against PFL, showing that the guarantee of SFL is better than PFL on heterogeneous data. Experimental results validate that SFL outperforms PFL on extremely heterogeneous data in cross-device settings.

Future directions include i) lower bounds for SFL (this work focuses on the upper bounds of SFL), ii) other potential factors that may affect the performance of PFL and SFL (this work focuses on data heterogeneity) and iii) new algorithms to facilitate our findings (no new algorithm in this work).