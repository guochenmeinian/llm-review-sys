# Practical Bayesian Algorithm Execution via

Posterior Sampling

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

We consider the _Bayesian algorithm execution_ framework, where the goal is to select points for evaluating an expensive function to best infer a property of interest. By making the key observation that the property of interest for many tasks is a _target set_ of points defined in terms of the function, we derive a simple yet effective and scalable posterior sampling algorithm, termed PS-BAX. Our approach addresses a broad range of problems, including many optimization variants and level-set estimation. Experiments across a diverse set of tasks show that PS-BAX achieves competitive performance against standard baselines, while being significantly faster, simpler to implement, and easily parallelizable. In addition, we show that PS-BAX is asymptotically consistent under mild regularity conditions. Consequently, our work yields new insights into posterior sampling, broadening its application scope and providing a strong baseline for future exploration.

## 1 Introduction

Many real-world problems can be cast as estimating a property of a black-box function with expensive evaluations. Bayesian optimization  has focused on the case where the property of interest is the function's global optimum. Similarly, level set estimation  deals with the problem of estimating the subset of points above a user-specified threshold.

More generally, it is often of interest to compute a property of the function determined by the output of a _base algorithm_. However, the base algorithm usually requires a large number of function evaluations, often far more than can be performed in practice. As a result, it cannot be used directly, and the evaluation points must instead be carefully selected through other means. Building on the Bayesian optimization and level set estimation frameworks, this is accomplished using two key components: (1) a Bayesian probabilistic model of the function and (2) a sequential sampling policy that uses this model to select new evaluation points. Following , we refer to this framework as Bayesian algorithm execution (BAX).

Existing approaches to BAX use expected information gain (EIG) as a criterion for choosing which points to evaluate , yet maximizing the EIG poses a significant computational challenge. We propose a simple but effective and scalable algorithm based on posterior sampling to address this challenge. Our approach relies on the key observation that many real-world BAX tasks aim to find a _target set_. For example, in Bayesian optimization, the goal is to find the function's global optimum; in level set estimation, the goal is to find the points above the user-specified threshold. Leveraging this observation, we **propose an algorithm termed PS-BAX** where points are chosen according to the posterior probability of being in the target set. **PS-BAX is scalable and orders of magnitude faster than INFO-BAX**, the EIG-based approach proposed by . Finally, we **prove that PS-BAX is asymptotically consistent** under mild regularity conditions.

This work is based on our prior work [citation removed to preserve anonymity]. The present version extends our prior work by including new experiments, a generalization of our algorithm to the batch setting, and an improved discussion of theoretical results.

## 2 Bayesian Algorithm Execution via Posterior Sampling

Problem SettingOur work takes place within the Bayesian algorithm execution (BAX) framework introduced by . The goal is to estimate \(_{}(f)\), the output of a _base algorithm_\(\) applied on a function \(f:\). We assume that \(f\) is expensive to evaluate, which means that employing \(\) directly on \(f\) is infeasible (would require evaluating \(f\) too many times). Instead, we will select the points at which \(f\) is evaluated sequentially, aided by a probabilistic model. As is standard in the literature, we use Gaussian process models in our experiments. More details are provided in Appendix B However, our framework can easily accommodate other models, provided that sampling from the posterior is feasible. We specifically focus on problems where the property of interest can be encoded by a set \(_{}(f)\), which we term the _target set_.

Ps-BaxOur algorithm, termed PS-BAX, is summarized in Algorithm 1. In words, we first draw a sample from the posterior over \(f\), denoted by \(_{n}\) (line 2), and then set the sample target set \(X_{n}=_{}(_{n})\). We then select the point in sampled target set \(X_{n}\) with maximal entropy: \(x_{n}_{x X_{n}}[f(x)|_{n}]\). For a Gaussian posterior, \(x_{n}\) can be equivalently selected as \(x_{n}_{x X_{n}}_{n}(x)\), where \(_{n}(x)\) is the posterior standard deviation of \(f(x)\). Intuitively, PS

Figure 1: Depiction of PS-BAX (Algorithm 1) for a level-set estimation problem. We plot the objective function \(f\) (black line), the available data \(_{n}\) (black points), the threshold (grey dashed line), the posterior distribution \(p(f_{n})\) (blue line and light blue region), a sample from the posterior \(_{n} p(f_{n})\) (green line), the corresponding sampled target set \(X_{n}=_{}(_{n})\) (green region) (this is the set of inputs where the green line is above the threshold), the variance of \(p(f_{n})\) (green line, bottom row), and the next point to evaluate selected by PS-BAX \(x_{n+1} X_{n}\) (input marked by the vertical red line). The key step is computing the target set \(X_{n}\) using the sampled function \(_{n}\), which generalizes posterior sampling for Bayesian optimization.

BAX can be seen as a generalization of posterior sampling in Bayesian optimization. However, in general BAX tasks, the target may be comprised of several points; thus, we select the point with the highest _uncertainty_ among points in \(X_{n}\), a standard strategy in the active learning literature. The batch generalization of PS-BAX is discussed in Appendix F. A comparison between INFO-BAX and PS-BAX is provided in Appendix D.

Asymptotic Consistency of PS-BAXA natural question is under which conditions is PS-BAX able to _find_ the target set given enough evaluations. We provide an answer to this question below. Before formally stating our results, we introduce a definition related to the characterization of problems where PS-BAX is expected to converge.

**Definition 1**.: _A target set estimated by an algorithm \(\) is complement-independent if \(_{}(f)=_{}(f^{})\) for and any pair of functions \(f\) and \(f^{}\) such that \(f(x)=f^{}(x)\) for all \(x_{}(f)_{}(f^{})\)._

Many target sets of interest, such as a function's optimum or level set, are complement-independent. Indeed, the value of \(f\) at points that are not the optimum or that do not lie in the level of interest do not influence these properties. Theorem 1 below shows that PS-BAX enjoys asymptotic posterior consistency, provided the target set of interest is complement-independent. Intuitively, this result means that if \(f\) is drawn from the prior used by our algorithm (i.e., the prior is well-specified), then, with probability one, the posterior will concentrate around the true target set. Corollary 1 gives an asymptotically consistent estimator of the target set. Finally, we also show there are problems where the target set is not complement-independent and PS-BAX is not asymptotically consistent in Theorem 2. The proofs of these results can be found in Appendix C.

**Theorem 1**.: _Suppose that \(\) is finite and that the target set estimated by \(\) is complement-independent. If the sequence of points \(\{x_{n}\}_{n}\) is chosen according to the PS-BAX strategy, then, for each \(X\), \(_{n}_{n}(_{}(f)=X)=\{ _{}(f)=X\}\) almost surely for \(f\) drawn from the prior._

**Corollary 1**.: _Suppose that the assumptions made in Theorem 1 hold and let \(T_{n}_{X}_{n}(_{ }(f)=X)\). Then, \(T_{n}=_{}(f)\) for all \(n\) large enough almost surely for \(f\) drawn from the prior._

**Theorem 2**.: _There exists a problem instance (i.e., \(\), a Bayesian prior over \(f\), and \(\)) such that if the sequence of points \(\{x_{n}\}_{n}\) is chosen according to the PS-BAX strategy, then there is a set \(X\) such that \(_{n}_{n}(_{}(f)=X)=1/2\) almost surely for \(f\) drawn from the prior._

## 3 Numerical Experiments

We demonstrate the performance of PS-BAX on four different problem classes, described below below. We compare the performance of PS-BAX against the INFO-BAX , and uniform random sampling over \(\) (Random); when available, we also include an algorithm from the literature specifically designed for the problem class. The performance of each algorithm is determined by running the algorithm \(\) on \(_{n}\), the posterior mean of \(f\) given \(_{n}\) and subsequently computing a suitable performance metric on \(_{}(_{n})\). Additional details are provided in Appendix E.

1. **Local Optimization** aims to find the optimum of \(f\) using a local optimization method base algorithm (potentially with multiple restarts). In our experiments, we use L-BFGS-B as the base algorithm. The performance metric is the log10 inference regret, given by \(_{10}(f^{*}-f(_{n}^{*}))\), where \(_{n}^{*}\) is obtained by applying \(\) on \(_{n}\). As a baseline, we also include the expected improvement (EI) acquisition function.
2. **Level Set Estimation** aims to find a \(_{}(f):=\{x f(x)>\}\) for a user-specified \(\). The base algorithm \(\) is the algorithm that ranks all the objective values and returns the points at which the function value is greater than the threshold. The performance metric we consider is the F1 score. As an additional baseline specifically designed for this setting, we include the LSE algorithm proposed by .
3. **Top-\(k\) Estimation** aims to find the \(k\) points with the largest values of \(f(x)\) on a finite (but potentially large) set \(\). The base algorithm \(\) is the algorithm that evaluates \(f\) at all points in \(\) and returns the \(k\) best points. We use the Jaccard distance between the estimated output \(S_{n}=_{}(_{n})\) and the ground truth optimal set \(S^{*}\), which is defined as \[d(S_{n},S^{*})=1- S^{*}|}{|S_{n} S^{*}|}.\] (1)* **DiscoBAX** is a problem setting from  where the goal is to find a set of optimal genomic interventions to determine suitable drug targets. Formally, \(_{}\) is the solution of \[_{S:|S|=k}_{}_{x S}f(x)+( x),\] (2) where \(\) is a pool of genetic interventions, \(k\) is the desired interventions set size, \(f(x)\) is an _in vitro_ measurement correlated to the effectiveness of intervention \(x\), and \((x)\) encodes noise and other exogenous factors.

We evaluate the performance of PS-BAX on eight problems across four problem classes (the rest of the experiment results can be. The results for four of the problems (one for each class) are shown in Figure 2. The rest of our experimental results can be found in Appendix E). Overall, we find that PS-BAX is always competitive with and sometimes significantly outperforms INFO-BAX across all of our experiments. Moreover, PS-BAX is one to two orders of magnitude faster in all experiments.

## 4 Conclusion

Many real-world problems can be cast as estimating a property of a black-box function with expensive evaluations. By making the key observation that in many problems, the property of interest is a target set of points defined in terms of the function, we introduce a novel posterior sampling strategy. Our experiments across a broad range of settings show that this strategy is competitive with the approach proposed by  while being much faster to compute. Finally, we showed that our posterior sampling strategy is asymptotically consistent under mild regularity conditions.

Figure 2: Performance of PS-BAX across four test problems and comparisons against different baselines. (a) The log10 inference regret for the local optimization setting on the Ackley 10D test function. Lower is better. (b) The F1 score for the level set estimation setting on Aucklandâ€™s Maunga Whan volcano dataset  with threshold \(=0.55\) of all the function values in the domain. Higher is better. (c) The Jaccard distance for the top-10 problem on an 80-dimensional domain of size 10000 on the GB1 protein dataset with batch size = 5 . (d) Inference regret for DiscoBAX problem using the Achilles dataset , with intervention values from the Interferon \(\) assay . Lower is better.