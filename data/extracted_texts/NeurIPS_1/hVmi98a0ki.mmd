# Optimizing Automatic Differentiation

with Deep Reinforcement Learning

 Jamie Lohoff

Peter Grunberg Institute

Forschungszentrum Julich & RWTH Aachen

ja.lohoff@fz-juelich.de Emre Neftci

Peter Grunberg Institute

Forschungszentrum Julich & RWTH Aachen

e.neftci@fz-juelich.de

###### Abstract

Computing Jacobians with automatic differentiation is ubiquitous in many scientific domains such as machine learning, computational fluid dynamics, robotics, and finance. Even small savings in the number of computations or memory usage in Jacobian computations can already incur massive savings in energy consumption and runtime. While there exist many methods that allow for such savings, they generally trade computational efficiency for approximations of the exact Jacobian. In this paper, we present a novel method to optimize the number of necessary multiplications for Jacobian computation by leveraging deep reinforcement learning (RL) and a concept called cross-country elimination while still computing the exact Jacobian. Cross-country elimination is a framework for automatic differentiation that phrases Jacobian accumulation as ordered elimination of all vertices on the computational graph where every elimination incurs a certain computational cost. We formulate the search for the optimal elimination order that minimizes the number of necessary multiplications as a single player game which is played by an RL agent. We demonstrate that this method achieves up to 33% improvements over state-of-the-art methods on several relevant tasks taken from diverse domains. Furthermore, we show that these theoretical gains translate into actual runtime improvements by providing a cross-country elimination interpreter in JAX that can efficiently execute the obtained elimination orders.

## 1 Introduction

Automatic Differentiation (AD) is widely utilized for computing gradients and Jacobians across diverse domains including machine learning (ML), computational fluid dynamics (CFD), robotics, differential rendering, and finance (Baydin et al., 2018; Margossian, 2018; Forth et al., 2004; Tadjoudine et al., 2002b; Giftthaler et al., 2017; Kato et al., 2020; Schmidt et al., 2022; Capriotti and Giles, 2011; Savine and Andreasen, 2021). To many researchers in the machine learning community, AD is synonymous with the backpropagation algorithm (Linnainmaa, 1976; Schmidhuber, 2014). However, backpropagation is just one particular way of algorithmically computing the Jacobian that is very efficient in terms of computations for "funnel-like" functions, _i.e._ with many inputs and a single scalar output such as in neural networks. In many other domains, we may find functions that do not have this particular property and thus backpropagation might not be optimal for computing the respective Jacobian (Albrecht et al., 2003; Capriotti and Giles, 2011; Naumann, 2020). In fact, there exists a wide variety of AD algorithms, each of them coming with its own advantages and drawbacks regarding computational cost and memory consumption depending on the function they are applied to. Many of these AD algorithms can be viewed as special cases of _cross-country elimination_(Griewank and Walther, 2008). Cross-County Elimination frames AD as an ordered vertex elimination problem on the computational graph with the goal of reducing the required number of multiplications and additions. However, finding the optimal elimination procedure is a NP-complete problem (Naumann,2008). Inspired by recent advances in finding optimal matrix-multiplication and sorting algorithms (Fawzi et al., 2022; Mankowitz et al., 2023), we demonstrate that deep RL successfully finds efficient elimination orders which translate into new automatic differentiation algorithms and practical runtime gains (figure 1). Cross-country elimination is particularly amenable for automatization since it provably yields the exact Jacobian for every elimination order. The solution we seek thus reduces to only finding an optimal elimination order, without the need to evaluate the quality of Jacobian approximations (such as in Neural Architecture Search). An important body of prior work aimed to find more efficient elimination techniques through heuristics, simulated annealing or dynamic programming and minimizing related quantities such as fill-in (Naumann, 1999, 2020). However, none of these works was successful in optimizing with respect to relevant quantities such as number of multiplications or memory consumption. We set up our optimization problem by formulating cross-country elimination as a single player RL game called _VertexGame_. At each step of VertexGame, the agent selects a vertex to eliminate from the computational graph according to a certain scheme called _vertex elimination_. The reward is equal to the negative of the number of multiplications incurred by the particular choice of vertex. VertexGame is played by an AlphaZero-based agent (Silver et al., 2017; Schrittwieser et al., 2019; Danihelka et al., 2022) with policy and value functions modeled with a transformer architecture that processes the graph representation and predicts the next vertex to eliminate, thereby incrementally building the AD algorithm.

Our approach discovers from scratch new vertex elimination orders, _i.e._ new AD algorithms that are tailored to specific functions and improve over the established methods such as minimal Markowitz degree. We further demonstrate the efficacy of the discovered algorithms on real world tasks by including _Graphax_, a novel sparse AD package which builds on JAX (Bradbury et al., 2018) and enables the user to differentiate Python code with cross-country elimination. Our main contributions are summarized as follows:

* We demonstrate that optimizing elimination order can be phrased as a reinforcement learning game by leveraging the graph view of AD,
* We show that a deep RL agent finds new, tailored AD algorithms that improve the state-of-the-art on several relevant tasks,
* We investigate how the discovered novel elimination procedures translate into actual runtime improvements by implementing Graphax, a cross-country elimination interpreter in JAX allowing the efficient execution of newly found elimination orders.

### Related Work

**RL for Algorithm Research:** AlphaTensor and AlphaDev successfully demonstrated that model-based deep RL finds new and improved matrix-multiplication and sorting algorithms (Fawzi et al., 2022; Mankowitz et al., 2023). In particular, AlphaTensor used an extension of the AlphaZero agent to search for new matrix-multiplications algorithms that require fewer multiplication operations by directly using this quantity as a reward. The key insight is that different matrix-multiplication

Figure 1: Summary of the AlphaGrad pipeline. We trained a neural network to produce new Automatic Differentiation (AD) algorithms using Deep RL that can be used in JAX. The resulting algorithms significantly outperform the current state of the art.

algorithms have a common, simple representation through the three-dimensional matrix-multiplication tensor which can be manipulated by taking different actions, resulting in algorithms of varying efficiency. Feeding this tensor into the RL agent, they successfully improved on matrix-multiplication algorithms for 4x4 matrices by beating Strassen's algorithm, the current state-of-the-art, with an improvement from 49 to 47 multiplications.

In a similar vein, AlphaDev improved simple sorting algorithms by representing the sorting algorithm as a series of CPU instructions which then have to be arranged in the correct way to achieve the correct sorting output. Instead of using the number of CPU operations as an optimization target, the agent was trained on actual execution times. Our work follows in these footsteps by tackling the difficult problem of finding new and improved AD algorithms for arbitrary functions and hence we termed our method _AlphaGrad_.

**RL for Compiler Optimization:** A number of works have tackled the complex issue of optimizing the compilation of various computational graphs with deep RL. Knossos (Jinnai et al., 2019) leverages the A\({}^{*}\) algorithm to optimize the compilation of simple neural networks. It employs a model to estimate computational cost and utilizes expression rewriting techniques to enhance performance. While Knossos is hardware agnostic, it needs to be trained from scratch for every new computational graph. GO and REGAL both improve on this shortcoming and generalize to new, unseen graphs at the cost of losing the hardware-agnostic property(Paliwal et al., 2019; Zhou et al., 2020).

REGAL learns a graph neural network-based policy using a REINFORCE-based genetic algorithm to optimize the scheduling of the individual operations of a graph to the set of available devices, thereby successfully reducing peak memory usage for different deep learning workloads. Only GO is directly trained on actual wall time and handles all relevant optimizations jointly, including device placement, operation fusion, and operation scheduling. GO learns a policy based on graph neural networks and recurrent attention using PPO and successfully demonstrates improvements over Tensorflow's default compilation strategy. While our work also makes use of the computational graph, the goal is to find novel AD algorithms instead of optimizing compilation itself, although these problems are related since the new AD algorithm is compiled before execution.

**Optimization of AD** While no prior work directly aims at improving AD with deep RL, several studies aimed at enhancing AD by other methods. This includes Enzyme (Moses and Churavy, 2020), which presents a reverse-mode AD package that operates on the intermediate representation level using LLVM. Enzyme is thus distinct from other AD packages because it can synthesize gradients for many different high-level languages. Another related work is LAGrad (Peng and Dubach, 2023), a source-to-source AD package written in Julia which introduces a set of new static optimizations to accelerate reverse-mode AD. It leverages high-level MLIR information, such as sparsity structure and control flow semantics of the computational graph to produce more efficient differentiated code. While LAGrad can improve the performance of AD workloads by orders of magnitude, it is currently limited to the use of reverse-mode AD which can be suboptimal for certain tasks. In both works, a suboptimal choice of algorithm might nullify the benefits gained from careful engineering. Our work aims to close this gap by additionally providing a novel way of finding the optimal AD algorithm using Deep RL.

The closest related work is (Naumann, 1999) where simulated annealing was applied to reduce the number of multiplications necessary for Jacobian accumulation. The algorithms struggled to significantly outperform state-of-the-art even when it was initialized with a reasonably good elimination order. In a similar manner, (Naumann, 2020) directly optimized the elimination order with dynamic programming albeit with respect to a different optimization target called fill-in on randomly generated graphs that do not necessary represent well-defined, executable functions.t Our work directly optimizes for the number of multiplications required to accumulate the Jacobian on real-world problems. Another approach described in (Chen et al., 2012) utilized integer linear programming to find optimal elimination orders with respect to number of multiplications, but only dealt with very small problems with up to twenty intermediate vertices. Our approach successfully finds new AD algorithms from scratch for complex problems with hundreds of intermediate vertices.

## 2 Automatic Differentiation and Cross-Country Elimination

AD is a systematic approach to computing the derivatives of _dependent variables_\(=f()^{m}\) with respect to the _independent variables_\(^{n}\) utilizing the chain rule. AD enables the precise and efficient calculation of gradients, Jacobians, Hessians, and higher-order derivatives (Linnainmaa, 1976). Unlike methods that rely on finite differences or symbolic differentiation, AD offers a systematic way to compute derivatives up to machine precision, making it an indispensable tool in many numerical scientific problems and machine learning (Baydin et al., 2018; Griewank and Walther, 2008). AD leverages the fact that most computer programs can be broken down into a sequence of simple elemental operations, for example additions, multiplications and trigonometric functions. Partial derivatives of these elemental operations are coded into the AD software and the Jacobian is accumulated by recursively applying the chain rule to the evaluation procedure. Since the partial derivatives are known up to machine precision, AD gives the Jacobian up to machine precision.

### Graph View and Vertex Elimination

We take the graph view of AD where a function is defined through its computational graph \(=(V,E)\) with its vertices \(\) being the elemental operations \(_{j}\) and directed edges \(\) that describe the data dependencies between the operations (figure 1(a)). The relation \(i j\) states that vertex \(i\) has an edge connecting it with vertex \(j\), meaning that the output \(v_{i}\) of \(_{i}\) is an input of \(_{j}\). The partial derivatives of the elemental operations with respect to their dependents are assigned to the connecting edges (figure 1(b)). We can then identify the edges of the graph with their respective partial derivatives \(c_{ji}=}{ v_{i}}\). The cross-country elimination algorithm computes the Jacobian by a procedure called _vertex elimination_.

**Definition 1**(Griewank and Walther, 2008): _For a computational graph \(=(V,E)\) with partial derivatives \(c_{ij}\), vertex elimination of vertex \(j\) is defined as the update_

\[c_{ki}+=c_{kj}c_{ji}\ (i,k)\ \ i j\ \ j k \]

_and then setting \(c_{ji}=c_{kj}=0\) for all involved vertices. The \(+=\) operator creates a new edge if there is no edge \(c_{ki}\) and otherwise adds the new value to the existing value._

Intuitively, vertex elimination can be understood as the _local_ application of the chain rule to a single vertex in the graph since the multiplication \(c_{ij}c_{jk}\) is exactly the result of applying the chain rule to \((_{k}_{j})(v_{i})\). If a vertex has multiple incoming and outgoing edges, all combinations of incoming and outgoing edges are resolved to create new edges. If an edge already exists, we add the result of the product to it, in accordance with the rules for total derivatives. After the new edges are added to the graph, we delete all edges connected to the eliminated vertex since all the derivative information is now contained in the new edges (figure 1(c)). Note that the new graph resulting from a vertex elimination no longer directly represents the data dependencies of the function since the eliminated vertex is now disconnected. Furthermore, the application of vertex elimination as described above

Figure 2: Step-by-step description of cross-country elimination with the simple example function \(f(x_{1},x_{2})=((x_{1}x_{2}),x_{1}x_{2}-(x_{1}x_{2}))^{}\). (a) Initial computational graph. (b) The partial derivatives are added to the edges of the computational graph. The intermediate variables \(v_{1}\) and \(v_{2}\) are defined through \(v_{1}=x_{1}x_{2}\) and \(v_{2}= v_{1}\). (c) Elimination of vertex 2 associated with the \(\) operation. The dotted red lines represent the edges that are deleted. (d) Final bipartite graph after both intermediate vertices have been eliminated. All remaining edges contain entries of the Jacobian.

requires the computational graph to be static and precludes the use of control flow (_if_-statements, _for_-loops) in the differentiated code.

### Cross Country and Elimination Orders

The repeated application of the vertex elimination procedure to a computational graph (_i.e._ cross country elimination) until all intermediate vertices are eliminated will yield a graph where the input vertices and output vertices are directly connected by edges (no intermediate vertices left, see figure 2d). This is called a _bipartite graph_ and the edges of this graph contain the components of the Jacobian of the function \(f\). In particular, as long as all intermediate vertices are eliminated, this Jacobian will always be exact up to machine precision (Griewank and Walther, 2008). There is no restriction on the order in which the vertices are eliminated, but the choice will significantly influence computational cost and memory (Tadjouddine et al., 2006). In the graph view, computational cost is straightforward to measure since every vertex elimination incurs a known number of multiplications that depends on the shapes of the elemental Jacobians which can be used as a proxy for execution time. We can ignore the cost of evaluating the partial derivatives since they have to be performed regardless of the elimination order. Thus, we use the number of multiplications as the optimization target for the remainder of this work. The two most common choices for elimination orders are to either eliminate the vertices in the forward or reverse order. These two modes are called forward-mode AD and reverse-mode AD (backpropagation), respectively.

Forward-mode AD, where vertices are eliminated in the same order as the computational graph is traversed, is particularly efficient for functions where the number of input variables \(n\) is much smaller than the number of output variables \(m\), i.e. \(n m\). In contrast, reverse-mode AD traverses the graph in the opposite direction and is particularly suited for the cases where \(n m\). This is the case in machine learning and neural networks using scalar loss functions, which is why reverse-mode AD is the default choice in such workloads.

### Minimal Markowitz Degree

A more advanced technique is to eliminate vertices with the lowest Markowitz degree first Griewank and Walther (2008). The Markowitz degree of a vertex is defined as the number of incoming vertices times the number of outgoing vertices, _i.e._\((j)=|i j||j k|,\) where \(||\) denotes the cardinality of the sets \(i j\) and \(j k\) for fixed \(j\). Thus the elimination order is constrained by finding the vertex with the lowest Markowitz degree first, eliminating it and then finding the next vertex with minimal Markowitz degree on the resulting graph. This elimination scheme is one of the best known heuristics for finding efficient elimination orders and can incur savings of up to 20% over forward- and reverse-mode AD (Albrecht et al., 2003; Griewank and Walther, 2008). However, for computational graphs that have many inputs and few outputs, it is often outperformed by reverse-mode AD.

### Vector-valued Functions

In most applications, vector-valued functions are used as elemental building blocks of more complex functions. While in most cases, these vectorized operations could be broken down into scalar operations, this would be impractical since it would increase the size of the computational graph representation and action space by orders of magnitude. Thus, it is best to allow vertices of the computational graph to be vector-valued which results in the partial derivatives assigned to the edges becoming Jacobians in their own right. The multiplication operations during vertex elimination are then accordingly replaced with matrix multiplications or higher-order contractions of the elemental Jacobians. For many operations, the Jacobians themselves have a particular internal sparsity structure which can be exploited when performing the eliminations. A simple example is the multiplication of a vector with a matrix followed by the application of a non-linear function \(f(,)=)}\). The input vertices are given by the input \(\) and weights \(\) and the intermediate vertex is matrix multiplication \(a_{i}=_{j}W_{ij}x_{j}\) with the partial derivatives

\[}{ W_{kl}}=x_{l}_{ik}, }{ x_{k}}=W_{ik}. \]The output vertex represents the application of the activation function \(y_{i}= a_{i}\) with the partial derivative

\[}{ a_{j}}=_{ij}(1-^{2}a_{i}). \]

According to the vertex elimination rule, upon elimination of the intermediate vertex the two Jacobians in equation (2) are assigned to the incoming edges are contracted together with the Jacobian from the outgoing edge in equation (3):

\[}{ W_{kl}}= _{j}(1-^{2}a_{i})_{ij}_{jk}x_{l}=_{ik} (1-^{2}a_{i})x_{l}, \] \[}{ x_{k}}= _{j}(1-^{2}a_{i})_{ij}W_{jk}=(1-^{2}a_{i})W_{ ki}. \]

In both cases, instead of a matrix multiplication, one can perform simple element-wise multiplications as shown in figure 2(a). For vectorized cross-country elimination to be efficient, it is paramount to exploit this property. Current state-of-the-art AD frameworks typically lack the ability to perform cross-country elimination and subsequently can not deal with sparse Jacobians. The only exception the authors are aware of is EliAD, an AD interpreter in C++ which is fully capable of processing given elimination orders and create the derivative source code . However, we developed _Graphax_ as a novel AD interpreter that builds on Google's JAX  in order to leverage it's defining features such as JIT compilation, automated batching, device parallelism and a user-friendly Python front-end. Graphax is a fully fledged AD interpreter capable of performing cross-country elimination as described above and outperforms JAX' AD on the relevant tasks by several orders of magnitude (appendix B). Graphax and AlphaGrad are available under and [https://github.com/jamielohoff/graphax](https://github.com/jamielohoff/graphax) and [https://github.com/jamielohoff/alphagrad](https://github.com/jamielohoff/alphagrad).

### Computational Graph Representation and Network Architecture

We describe here how the computational graph is represented for optimization in the RL algorithm, as well as the network architecture that is optimized with AlphaZero. In the scalar case, the computational graph can be represented by its adjacency matrix, meaning that for every pair of vertices \((i,j)\) that share an edge, we set the \(i\)-th row and the \(j\)-th column of the matrix to \(1\). For the vectorized case, we define an extended adjacency tensor by extending the matrix into the third dimension. Along this third dimension, we store 5 values that describe the sparsity pattern and shape of the Jacobian associated with the respective edge. The first value is an integer between -10 and 10 which encodes the sparsity type of the Jacobian. Details about the supported sparsity types can

Figure 3: (a) Graphax implements sparse vertex elimination to benefit from the advantages of cross country elimination. (b) Sketch of the three-dimensional adjacency tensor that represents the computational graph. The colored surfaces represent the five different values encoded in the third dimension. The red and blue surfaces together contain the shape of the Jacobians while the green surface encodes their sparsity. The vertical dotted slices represent the input connectivity of a single vertex. In this work, we compress and feed the vertical slices as tokens into the transformer backbone such that we build a sequence running in direction of the black arrow.

be found in Appendix C. The next four values contain the shape of the Jacobian associated with the respective edge and thus imply that this representation can at most deal with Jacobians of the shape \(}{ x_{kl}}\) where the first two values describe the shape of \(x_{kl}\) and the other two values describe the shape of \(y_{ij}\). This can be expanded to arbitrary tensor sizes of \(x\) and \(y\), but then also requires the definition of new sparsity types to account for the additional dimensions. Figure 2(b) shows the representation of the entire computational graph and a single selected edge with a Jacobian of shape \((4,2,4,2)\) with sparsity type 3. A horizontal or vertical slice of the extended adjacency tensor gives the input or output connectivity of a particular vertex. These slices can be compressed and used as tokens to be fed into a transformer where they are processed simultaneously by the attention mechanism so that the model gets a full view of the graph's connectivity.

In this work, we compress vertical slices into tokens using a convolutional layer with kernel size (3, 5) and use a linear projection to create a 64-dimensional embedding. We found it helpful to apply a positional encoding to the tokens (Vaswani et al., 2017). The output of the transformer is then fed into a policy and a value head. The policy head is a MLP mapped across every token separately, thus creating a probability distribution over the vertices to determine the next one to be eliminated. Already eliminated vertices are masked. Similarly, the value head is also a MLP that predicts a score for every token. These scores are then summed to give the value prediction of the network.

## 3 Reinforcement Learning for Optimal Elimination Orders

Cross-country elimination is typically introduced as a means to reduce the computational cost of computing the Jacobian. We cast the problem of finding an efficient vertex elimination order as a single-player RL game called _VertexGame_. At every step of the game, the agent selects the next vertex to be eliminated by observing the current connectivity of the computational graph. Since it is difficult to directly optimize for execution time, it is common to use the number of multiplications incurred by the elimination order as a proxy value (Tadjouddine et al., 2006, 2002b; Albrecht et al., 2003). Thus, we chose the negative number of multiplications incurred by eliminating the selected vertex as reward. We use action masking to prevent the agent from eliminating the same vertex twice. This also ensures that the accumulated Jacobian is always exact and has a clear terminal condition: when the extended computational graph is bipartite, the game ends.

Between elimination orders, the magnitude of the reward can range across multiple orders of magnitude. To tackle this, we rescale the cumulative reward using a monotonous function. For the functions with scalar inputs as well as _RoeFlux_3d_ and _random function_\(f\), we found the method presented in (Kapturowski et al., 2019) performed well, _i.e._ we scaled with \(s(r)=(r)(-1)+cr\) where \(=10^{-3}\). For _MLP_ and _TransformerEncoder_ tasks, the best performance was achieved with logarithmic scaling \(s(r)= r\)(Hafner et al., 2024). VertexGame is played by an AlphaZero agent, which successfully finds new AD algorithms. To reduce the computational cost of the AlphaZero agent (Silver et al., 2017), we employed Gumbel action sampling Danihelka et al. (2022). Gumbel AlphaZero is a policy improvement algorithm based on sampling actions without replacement which utilizes the Gumbel softmax trick and other augmentations. This algorithm is guaranteed to improve the policy while significantly reducing the number of necessary Monte-Carlo Tree Search (MCTS) simulations. On most tasks, we found that 50 MCTS simulations were sufficient to reach satisfactory performance. Appendix D contains more details about the training of the agent.

## 4 Experiments

To demonstrate the effectiveness of our approach, we devised a set of tasks sampled from different scientific domains where AD is used to compute Jacobians. More details concerning the tasks are listed in appendix A.

**Deep Learning** is a prime example for the success of large-scale AD. We analyze a _two-layer MLP_ with layer norm as described in (Goodfellow et al., 2016) and a small-scale version of the _transformer encoder_(Dosovitskiy et al., 2020).

**Computational Fluid Dynamics** relies on AD for computation of the flux Jacobian on the boundaries of the simulation grid cells. The _RoeFlux_ is particularly relevant and has been studied extensively with vertex elimination in the past (Roe, 1981; Tadjouddine et al., 2002b; Zubair et al., 2023). We test on the 1D and the 3D variants of this problem.

**Differential Kinematics** uses Jacobians to quantify the behavior of a robot or other mechanical system with respect to their controllable parameters (e.g. joints, actuators). There has been a surge in interest of computing the Jacobian using AD[Giftthaler et al., 2017]. We chose the forward kinematics of a _6-DOF robot arm_ as a representative problem and follow [Dikmenli, 2022] for the implementation.

**Non-Linear Equation Solving** requires the computation of large Jacobians to apply state-of-the-art solvers. The MINPACK problem collection provides a set of problems derived from real-life applications of non-linear optimization and designed to be representative of commonly encountered problems. In particular, we analyze the _HumanHeartDiple_ and _PropaneCombustion_ tasks, for which vertex elimination has also been analyzed thoroughly in [Forth et al., 2004b, Averick et al., 1992].

**Computational Finance** makes use of AD for fast computation of the so called "greeks" which measure the sensitivities of the value of an option to the model parameters[Naumann, 2010, Savine and Andreasen, 2021]. Here, we compute the second-order greeks of the _Black-Scholes equation_ using AD by computing the Hessian of the Black-Scholes equation through evaluation of the Jacobian of the Jacobian of the Jacobian Black and Scholes . This way, this task serves a two-fold purpose by also demonstrating how our approach is also useful for finding good AD algorithms for higher-order derivatives.

**Random Functions** are also commonly used to evaluate the performance of new AD algorithms [Albrecht et al., 2003]. We generated two random functions \(f\) and \(g\) with vector-valued and only scalar inputs respectively. The random code generator used to generate these arbitrary functions is included in the accompanying software package.

### Finding Optimal Elimination Orders

Table 1 shows the number of multiplications required by the best elimination order found over 6 runs with different seeds. The model was trained from scratch on each task separately with a batch size of 1 to to keep the rewards as small as possible. The resulting AD algorithms are nonetheless scalable to arbitrary batch sizes. We use forward-mode, reverse-mode and the minimal Markowitz degree method as baselines for comparison. The first six tasks are simple functions with only scalar inputs and simple operations and the cumulative reward stays within the same order of magnitude, making them easier to solve. For all tasks, our approach was able find new elimination orders with improvements ranging from 2% to almost 20%. We found that even for only 5 MCTS simulations, the agent was able to find better than state-of-the-art solutions for the scalar tasks.

On the opposite spectrum, our experiments with 250 MCTS simulations yielded no significant improvement over the results presented in table 1. The four remaining tasks are arguably more difficult since the vector-valued inputs and large variance within possible rewards provide an additional challenge. The _RoeFlux_3d_ and _random function_\(f\) were solved successfully with 50 MCTS simulations and yielded improvements of up to 33%. This is in stark contrast to prior work such as [Naumann, 1999], where algorithms such as simulated annealing or dynamic programming struggled to even beat common heuristics such as minimal Markowitz or reverse-mode AD. With a budget of only 50 MCTS simulations, AlphaGrad failed to find improvements for both deep learning tasks.

   Task & Forward & Reverse & Markowitz & AlphaGrad \\  RoeFlux\_1d & 620 & 364 & 407 & 320 \\ RobotArm\_6DOF & 397 & 301 & 288 & 231 \\ HumanHeartDipole & 240 & 172 & 194 & 149 \\ PropaneCombustion & 151 & 90 & 111 & 88 \\ Random function \(g\) & 632 & 566 & 451 & 417 \\ BlackScholes & 545 & 572 & 350 & 312 \\  RoeFlux\_3d & 1556 & 979 & 938 & 811 \\ Random function \(f\) & 17728 & 9333 & 12083 & 6374 \\
2-layer MLP\({}^{}\) & 10930 & 392 & 4796 & 398 (389) \\ Transformer\({}^{}\) & 135010 & 4688 & 51869 & 4831 (4656) \\   

Table 1: Number of multiplications required by the best discovered elimination order for a batch size of one. Results obtained from VertexGame played by the AlphaZero agent with 50 MCTS simulations and a Gumbel noise scale of 1.0. \(\) marks the experiments where we employed a log-scaling of the cumulative reward instead of the default scaling. The values in parentheses were obtained for 250 MCTS simulations.

The authors conjecture that this is not only due to difficulties presented above, but because reverse-mode AD (backpropagation) is already a very well-suited algorithm for computing Jacobians of "funnel-like" computational graphs with many inputs and a single, scalar output. Despite this, with an increase to 250 MCTS simulations, the agent marginally outperformed backpropagation for both deep learning models. Appendix E contains more information about the experiments, including reward curves, the actual elimination orders and more details about their implementation. Note that the results in table 1 were obtained by separately training on each single function/graph.

We also include joint training runs where the agent was trained on all tasks at once. While the results were inferior to the separate training mode, the agent found new, improved elimination orders for almost all tasks except the _MLP_, _TransformerEncoder_, _RoeFlux_3d_ and _PropaneCombustion_ tasks. For the _random function_\(f\) and _BlackScholes_Jacobian_ task, the multi-task training outperformed the results in table 1 with new best results of 5884 and 307 respectively, thereby showing that the algorithm search might benefit from training on diverse tasks simultaneously. This also hints at the possibility of building a more general statistical model of AD applicable to workloads from many different domains. We also experimented with PPO as an alternative (appendix F).

### Runtime Improvements and the Graphax library

The results in table 1 are mainly of theoretical value. Here, we investigate how these translate into actual runtime improvements. For this purpose, we implemented Graphax, to our knowledge the first Python-based AD interpreter able to leverage cross-country elimination. Graphax builds a second program that computes the Jacobian by leveraging the elimination orders found by AlphaGrad and using the source code of the function as a template by analyzing its _Jaxpression_. The Jaxpression is JAX' own representation of the computational graph of the function in question.

Table 2 shows runtime improvements for the elimination orders found in table 1 for a batch size of 512 with varying levels of improvement. This is due to the fact that the number of multiplications alone was only a proxy to capture the complexity of the entire program. It ignores other relevant quantities such as memory accesses and operation fusion during compilation. Nonetheless, a particularly impressive gain over the state-of-the-art methods can be observed for the _RoeFlux_ tasks and the _RobotArm_6DOF_ task. Remarkably, we also observe a minor improvement for both deep learning tasks when executed on GPUs. Note that the _TransformerEncoder_ task was evaluated on a batch size of 1 because VertexGame only supports two-dimensional input tensors. Figure 4 shows how some of AlphaGrad's algorithms scale with growing batch size. Appendix B provides an in-depth comparison of our work and JAX' own AD modes. In general, the combination of AlphaGrad and Graphax is able to outperform the JAX AD modes in most cases, sometimes by orders of magnitude. While

   Task & Forward & Reverse & Markowitz & AlphaGrad \\  RoeFlux\_1d & \(3.03^{+0.17}_{-0.27}\) & \(3.08^{+0.17}_{-0.23}\) & \(2.87^{+0.22}_{-0.66}\) & \(2.19^{+0.30}_{-0.35}\) \\ RobotArm\_6DOF & \(8.85^{+0.21}_{-0.17}\) & \(8.48^{+0.32}_{-0.20}\) & \(8.55^{+0.38}_{-0.36}\) & \(6.05^{+0.34}_{-0.35}\) \\ HumanHeartDipole & \(16.97^{+1.23}_{-2.39}\) & \(16.87^{+1.45}_{-1.90}\) & \(16.42^{+1.29}_{-2.73}\) & \(15.94^{+1.11}_{-1.10}\) \\ PropaneCombustion & \(36.91^{+1.87}_{-1.50}\) & \(36.47^{+1.45}_{-0.51}\) & \(36.99^{+1.55}_{-1.11}\) & \(36.45^{+2.47}_{-1.31}\) \\ Random function \(g\) & \(82.41^{+2.85}_{-2.97}\) & \(81.64^{+2.82}_{-3.56}\) & \(82.97^{+1.38}_{-1.17}\) & \(80.56^{+1.61}_{-2.30}\) \\ BlackScholes & \(5.04^{+0.23}_{-0.33}\) & \(5.02^{+0.30}_{-0.39}\) & \(5.03^{+0.23}_{-0.29}\) & \(4.77^{+0.23}_{-0.29}\) \\  RoeFlux\_3d & \(72.26^{+3.22}_{-0.62}\) & \(83.98^{+5.69}_{-6.68}\) & \(91.27^{+11.59}_{-16.49}\) & \(63.92^{+4.45}_{-5.76}\) \\ Random function \(f\) & \(12.42^{+0.66}_{-0.25}\) & \(11.54^{+0.15}_{-0.27}\) & \(20.20^{+0.26}_{-0.31}\) & \(91.2^{+0.08}_{-0.06}\) \\
2-layer MLP\({}^{}\) & \(760.63^{+80.01}_{-5.30}\) & \(29.67^{+1.33}_{-4.05}\) & \(317.65^{+33.34}_{-19.34}\) & \(28.73^{+1.32}_{-3.78}\) \\
2-layer MLP\({}^{}\)(GPU) & \(11.04^{+0.31}_{-0.13}\) & \(0.30^{+0.02}_{-0.03}\) & \(1.01^{+0.02}_{-0.05}\) & \(0.29^{+0.02}_{-0.03}\) \\ Transformer\({}^{}\) & \(990.09^{+35.42}_{-31.11}\) & \(39.07^{+4.59}_{-7.67}\) & \(498.94^{+20.34}_{-19.62}\) & \(40.38^{+5.26}_{-3.62}\) \\ Transformer\({}^{}\)(GPU) & \(21.38^{+0.21}_{-0.06}\) & \(0.29^{+0.02}_{-0.03}\) & \(16.17^{+15.04}_{-0.09}\) & \(0.28^{+0.02}_{-0.01}\) \\   

Table 2: Median runtimes for the results obtained in table 1. Results were measured with Graphax for batch size 512 on an AMD EPYC 9684X 2x96-Core processor. Uncertainties are given as 2.5- and 97.5-percentiles over 1000 trials. Execution time is given in milliseconds and default XLA compilation flags were used for all experiments. The size of the networks, i.e. the number of neurons were increased for the MLP and Transformer Encoder by a factor of 16 to create a more realistic sample. GPU experiments were run on a NVIDIA RTX 4090 with JIT compilation.

[Forth et al., 2004b] and [Tadjouddine et al., 2006] present state-of-the-art results for some of the investigated tasks, we were unable to reproduce the experiments given their implementation details.

## 5 Conclusion

In this work we successfully demonstrated that AlphaGrad discovers new AD algorithms that outperform the state-of-the-art. We demonstrated that these theoretical gains translate into measurable runtime improvements with Graphax, a Python-based interpreter we developed that leverages the AD algorithms discovered by AlphaGrad. However, AlphaGrad currently only optimizes for multiplications which cannot capture the entire complexity of the AD algorithm. Future work could explore other optimization targets such as execution time, memory accesses, quantization and different hardware backends using a hardware model for efficient simulation. Another promising research avenue would be the implementation of a much more general framework for vertex elimination. Inspiration could be drawn from Enzyme, which operates on the intermediate representations (IR) using LLVM and is therefore less bound by the choice of programming language. Leveraging the LLVM approach would also open up new directions regarding AD-specific compiler optimizations similar to what was presented in LAGrad.

Two of the main shortcomings of our work are the lack of support for dynamic control flow and dynamically changing functions as well as the need for retraining of the algorithm for every single computational graph. To circumvent the first issue, it would be possible to implement a version of vertex elimination that can deal with dynamic control flow although this would require some significant changes to Graphax. However, as demonstrated by the wide range of benchmark tasks, several applications are already possible without this feature.

The second issue, addressed partially in our work, is the training of the agent on multiple graphs at once. While the best results were still achieved with single-graph training, the multi-graph training still outperformed the other existing methods on most benchmarks. This hints at the possibility to train our agent on a large set of computational graphs at once, thereby effectively building a statistical model of AD. Finally, VertexGame offers a novel way to evaluate existing RL algorithms on a real-world problem that poses diverse challenges such as rewards across multiple scales and large action spaces. Thus, it could complement existing benchmarks such as OpenAI gym and MuJoCo [Todorov et al., 2012, Towers et al., 2023].