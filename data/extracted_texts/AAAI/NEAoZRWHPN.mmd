# Large Language Models for Constrained-Based Causal Discovery

Kai-Hendrik Cohrs\({}^{1}\), Emiliano Diaz\({}^{1}\), Vasileios Sitokonstantinou\({}^{1}\),

Gherardo Varando\({}^{1}\), Gustau Camps-Valls\({}^{1}\)

\({}^{1}\)Image Processing Laboratory (IPL). Universitat de Valencia, Spain. kai.cohrs@uv.es

###### Abstract

Causality is essential for understanding complex systems, such as the economy, the brain, and the climate. Constructing causal graphs often relies on either data-driven or expert-driven approaches, both fraught with challenges. The former methods, like the celebrated PC algorithm, face issues with data requirements and assumptions of causal sufficiency, while the latter demand substantial time and expertise. This work explores the capabilities of Large Language Models (LLMs) as an alternative to domain experts for causal graph generation. We frame conditional independence queries as prompts to LLMs and employ the PC algorithm with the answers. The performances of the LLM-based conditional independence oracle on systems with known causal graphs show a high degree of variability. We improve the performance through a proposed statistical-inspired voting schema that allows control over false-positives and false-negatives rates. Finally, we apply the LLM-based PC algorithm to a complex set of variables around food insecurity in the Horn of Africa and find a plausible graph. Inspecting the chain-of-thought argumentation, we occasionally find causal reasoning to justify its answer to a probabilistic query.

## Introduction

Understanding causality is imperative across various disciplines, as it offers critical insights into the mechanisms of complex systems. For example, in the Earth and climate sciences, uncovering the causal relationship between greenhouse gas emissions and global warming has informed international climate agreements and spurred initiatives for renewable energy adoption, aiding in the mitigation of climate change impacts and promoting environmental sustainability .

Unraveling causality not only enhances our understanding of the underlying processes, but also empowers us to make informed decisions and take proactive measures to address pressing challenges, thus ensuring the well-being and sustainability of our societies and the environment. Investigating causality poses considerable challenges, with constructing causal graphs representing a particularly formidable task. Data-driven causal discovery methods, including prominent techniques like PC  and GES , encounter a range of issues. These methodologies rely heavily on copious amounts of data, necessitating complex conditional independence tests that can be particularly challenging, especially when working with diverse and mixed data types. The assumption of causal sufficiency, which presumes that all relevant variables are observed, can lead to erroneous conclusions, especially when unobserved variables act as potential confounders between system variables. Notably, there exist alternative methods such as LPCMCI , FCI , SVAR-FCI , and GPS  that do not assume causal sufficiency . Nonetheless, missing data and selection bias continue to pose persistent challenges in real-world applications, prompting efforts to develop more resilient causal discovery methods .

In addition to data-driven causal discovery methods, another approach for creating causal graphs involves leveraging domain knowledge. However, this process is inherently challenging and time-consuming, demanding substantial expertise and labor . Experts tasked with constructing causal graphs must possess a deep understanding of the relationships and mechanisms within the system under investigation. This often entails extensive consultations, discussions, and reviews with domain specialists, adding significant time and resource commitments to the process. Furthermore, the complexity of many real-world systems amplifies the difficulty of accurately capturing all relevant causal relationships, leading to potential oversights and inaccuracies in the resulting causal graph. These challenges underscore the necessity for more automated methodologies. In that respect, LLMs could play a key role if they prove to be a reliable source of causal knowledge.

LLMs present a promising knowledge-driven alternative to expert-based graph building or data-driven causal discovery methods. They have shown good performance across a range of language understanding and logical reasoning tasks . This could extend to probabilistic and causal reasoning, including interventional and counterfactual scenarios. Whether or not this is the case is the subject of heated debate . Despite the inherent complexity of directly asking LLMs to providecomplete causal graphs, given the various levels of reasoning involved and the rich context necessary, different strategies exist to elicit causal graphs from LLMs effectively. These strategies include LLMs to predict causal relations , LLMs as priors for data-driven causal discovery methods , and LLMs to aid in downstream causal inference tasks by predicting the causal order of variables .

To marry the traditional and the LLM-based methods, our work proposes _chatPC_ as a hybrid approach. Specifically, this work:

* Frames conditional independence queries as prompts to LLMs and employs the PC algorithm with this oracle for causal graph construction.
* Evaluates the performance of LLMs on conditional independence tests across various problems, showing varied performance.
* Introduces a statistical-based approach for aggregating multiple LLM answers, improving performance.
* Examines the graphs predicted by PC with the LLM oracle, finding them to be reasonable.
* Identifies a general tendency for conservative answers from LLMs compared to experts and finds traces of causal reasoning in the model's answers.
* Suggests that the approach could mitigate limitations of traditional methods, offering a promising avenue for automated causal graph construction.

We argue that relying solely on bivariate causal queries inherently overlooks the presence of mediators, consequently limiting the comprehensive understanding of the full causal graph. Additionally, our research explores the extent to which LLMs' queries can effectively substitute data-driven conditional independence tests, considering that PC represents the current state of the art in causal discovery, and under a perfect oracle, it can consistently retrieve the ideal graph up to the Markov equivalence class .

## Conditional Independence Queries via LLM

We start by describing and evaluating conditional independence (CI) queries with LLMs. Specifically, we are interested in estimating the validity of conditional independence statements of the type:

_Is \(X\) independent of \(Y\) given \(Z=(Z_{1},Z_{2},,Z_{k})\)?_, without having access to observations of the involved variables. Instead, we would like to rely on _available or expert_ knowledge accessible through LLMs.

For an LLM to be able to answer CI queries, it needs to be presented with some context and additional information related to the variables of interest alongside their description. In particular, we assume that for each _problem_, we have access to the following information:

**variables**: names or acronyms plus a short description for each quantity of interest.
**field**: the general subject area or expert field related to the problem.
**context**: a description of the broad context of the variables under consideration, including relevant details that go beyond general knowledge

### Prompting for conditional independence testing

While the approach we propose in this work could be implemented with any LLM trained to follow instructions, we employ gpt-3.5-turbo from OpenAI1. For a CI statement (\(X\!\!\!\!\!\!\! Y|Z\)), we consider a simple prompt that combines the field and context information and a description of the involved variables (\(X,Y\), and eventually \(Z\)) with a general instruction and response template as follows (see the Appendix for a detailed specification of the used prompt):

Persona specification

Instructions

Context

Variables description

CI Statement question

Responset template

The persona is based on the field variable and primes the LLM to produce reasoning appropriate to the area under study. To improve the answers, we apply chain-of-thought prompting following Wei et al. (2023), enabling us to gain insights into the model's reasoning and inspect if it is causally inspired. Further, we ask the model to provide uncertainty about its best guess along the lines of Tian et al. (2023).

### Testing

Various strategies could be envisaged to perform a "Hypothesis test" for a conditional independence statement with LLMs. A naive option consists of asking the LLM a single question with the prompt described in the previous section and decide that a statement is valid (i.e., the variables are indeed independent) if the answer is YES and otherwise, it is NO. The main problem with this approach is that since LLMs are probabilistic, a single answer from an LLM does not need to correspond to its mode (the most likely answer) or could fail to respect the required response template and answer, for instance, UNCERTAIN instead of YES/NO. Instead, we ask for an independent batch (size \(n\)) of answers, parse the obtained answers (YES or NO) together with the reported uncertainties, and finally output either an

Figure 1: Illustration of the introduced scheme for PC with GPT/LLM. Credits: Little robot face by Ant√¥nia Font.

answer based on simple voting or weighted voting where the weights are the reported probabilities.

Alternatively, we implement a "statistical approach" where we actually produce \(p\)-values for the null hypothesis \(p_{no} p_{yes}\) (or alternatively \(p_{no} p_{yes}\)) where \(p_{no},p_{yes}\) are the proportion of NO and YES answers over the total requested batch \(n\). The constructed test is based on the idea that we want to test if the probability of obtaining the answer NO is significantly higher than that of obtaining the answer YES and vice-versa. If we find the difference non-significant in light of the obtained responses, we opt for the null hypothesis. A final decision can then be obtained by setting a significance level \(\) and reject the chosen null hypothesis if the p-value is less or equal to \(\) (we will employ \(=0.05\) in the experiments). This last strategy has the advantage of considering the random variability of the answers and could offer a principled way of controlling the false positive rate. The user could then specify, for a particular problem, which of the two null hypotheses they would like to employ (either \(p_{no} p_{yes}\) or \(p_{yes} p_{no}\)), which in turn implies a different false-positive control (considering either NO or YES as positive).

### Evaluation

We evaluate the performance for CI testing on various problems defined in the BNLearn repository , the spurious correlation website , and a classical problem on reconstructing protein-signaling networks :

* cancer Simple causal graph involving four factors influencing the probability of cancer .
* burglary A modification of the classical earthquake example in 
* asia Causal graph of eight factors linked to respiratory problems .
* sachs: Causal graph among \(11\) phosphorylated proteins and phospholipids in single-cell data .
* spurious: Famous examples of pairs of variables that are spuriously correlated, obtained from the spurious-correlation website .

For the small problems (burglary and cancer) we evaluate all possible CI statements over \(5\) variables with both permutations of \(X\) and \(Y\) (\(160\) statements per problem). For sachs and asia we evaluate all CI statements (with \(X\)-\(Y\) permutations) up to conditioning sets of a certain size (\(0\) and \(1\), respectively) plus \(100\) random valid CI statements. Additionally for sachs, we evaluate also \(100\) randomly chosen statements with a conditioning set of size less or equal to three. Lastly, for spurious we evaluate the marginal independence statements \(X\!\!\! Y\) for all pairs of variables. For all the experiments, we obtain the answer to the CI queries by aggregating, as described previously, \(n=20\) independent batched responses from the LLM.

Permutation consistencyThe result of a conditional independence test should not depend on the order of variables, i.e., it should be commutative in \(X\) and \(Y\) (given \(Z\)). As a first sanity check, we checked the consistency of the responses with respect to the change of order of \(X\) and \(Y\) (see Figure 4 in the Appendix).

In over 80% of the cases, the majority votes resulted in the same response, while roughly 13% of the statements disagreed. In the remaining cases, at least one direction resulted in a tie. Given the variance in the generated responses and the majority vote over merely \(20\) queries, some mismatch is expected. Overall, the LLM seems sufficiently consistent in its responses under change of order. Nevertheless, we propose to aggregate the results of the queries in both directions to obtain results invariant to the order of the two involved variables.

Performance of CITTable 1 summarizes the evaluations of the conditional independence queries over the different problems. We compute the proposed approaches' standard classification metrics (accuracy, precision, recall, and F1 scores). We use the test that always yields NO (meaning NO independence) as a reference point. It reflects the density of the graph (the higher its accuracy, the denser) as it corresponds to assuming a fully connected graph. The results show varying performance over the different causal graphs. In terms of accuracy, all prediction methods underperform with respect to the constant NO baseline due to the density of the graphs. The statistical test (\(H_{0}\): \(\!\!\!\)) approach, which favors dependence, comes closest to this and only loses a few percent points in all cases. For burglary and sachs,

   Dataset & Prediction method & Acc. & Prec. & Rec. & F1 \\   & voting & 0.54 & 0.26 & 0.36 & 0.30 \\  & weighted voting & 0.55 & 0.29 & 0.45 & 0.36 \\  & stat. Test (\(H_{0}\): \(\!\!\!\)) & 0.53 & 0.33 & **0.73** & **0.46** \\  & stat. Test (\(H_{0}\): \(\!\!\!\)) & **0.69** & **0.38** & 0.23 & 0.29 \\  & NO & 0.73 & 0.00 & 0.00 & 0.00 \\   & voting & 0.88 & 0.00 & 0.00 & 0.00 \\  & weighted voting & 0.88 & 0.00 & 0.00 & 0.00 \\  & stat. Test (\(H_{0}\): \(\!\!\!\)) & 0.88 & 0.00 & 0.00 & 0.00 \\  & NO & 0.88 & 0.00 & 0.00 & 0.00 \\   & voting & 0.79 & 0.10 & 0.18 & 0.12 \\  & weighted voting & 0.78 & 0.09 & 0.18 & 0.12 \\  & stat. Test (\(H_{0}\): \(\!\!\!\)) & 0.68 & **0.15** & **0.59** & **0.24** \\  & stat. Test (\(H_{0}\): \(\!\!\!\)) & **0.86** & 0.08 & 0.06 & 0.07 \\  & NO & 0.91 & 0.00 & 0.00 & 0.00 \\   & voting & 0.58 & 0.48 & 0.87 & **0.62** \\  & weighted voting & 0.57 & 0.47 & 0.86 & 0.61 \\   & stat. Test (\(H_{0}\): \(\!\!\!\)) & 0.52 & 0.45 & **0.99** & **0.62** \\   & stat. Test (\(H_{0}\): \(\!\!\!\)) & **0.61** & **0.50** & 0.46 & 0.48 \\   & NO & 0.61 & 0.00 & 0.00 & 0.00 \\   

Table 1: Performance of LLM-based conditional independence tests with different voting procedures and metrics (accuracy, precision, recall, and F1 score.

it has the highest precision. In Recall and F1 score, the other statistical test (\(H_{0}\): \(\!\!\)) partially outperforms the other methods. As independence is usually the underrepresented class, it usually improves in recall and F1 score. Weighted voting usually helps to steer responses that ended in a tie in favour of the one where the models were more certain but did not change the results substantially compared to the normal vote. Statistical-based approaches have a more principled way of working with cases where the vote is not clear enough and allow the deployer to choose how to control for false positive or false negative rates. Even though the LLM did not excel in this task, the responses for the two statistical-based approaches may serve as additional baselines. In the case of the cancer problem, the response of the LLM corresponded to the NO baseline, as it consistently suggested that there could still be some relationship between the variables. As for health data, there are always many confounders; this seems to be a conservative or safe decision.

Inquiring spurious correlationsTo investigate this further, we went to the other extreme and asked for statistical independence between variables taken from the spurious correlation website (see Table 2 in the Appendix). Here, instead, the model almost always chose independence. At the same time, revenue-CS, spending-suicides, and chicken-oil showed the highest disagreement in the responses. For the statistical-based (\(H_{0}\): \(\!\!\)), this even leads to a rejection in the case of revenue-CS. Also, in this case, the model often seems to take the conservative answer: correlation by chance, i.e., YES to independence. On the other side, correlation, according to Reichenbach's principle, implies either direct causation or a common cause. We examined the responses of the LLMs to the queries of the above-mentioned pairs. For the pair spending-suicides, for instance, in some answers, it reasons about factors that influence both variables and gives reasonable examples of confounders such as diverting resources or progress in mental health research (see Appendix Response example A for the full response). The mentioned response shows causal reasoning when the model was not directly requested. And it goes beyond the required reasoning for directing edges as in previous works. We find, however, that the model does not consistently take this path in the answer. In some cases, instead, it reasons about the impacts on probability when fixing the conditioning set and makes false statements about determining conditional independence (see Appendix Response example B for the full response). This shows that more work must be done to steer LLMs towards reliable and coherent causal reasoning.

## 5 Application to Causal Discovery

We propose to couple the conditional independence oracle or testing, introduced in the previous section, with the PC-algorithm  for recovery of the Markov equivalence class of a causal graph. The PC algorithm starts from a fully connected skeleton (undirected graph) among the considered variables and iteratively removes edges between variables \(X\) and \(Y\) when it finds a conditioning set \(Z\) such that \(X\) is independent of \(Y\) given \(Z\). After the so-called skeleton phase, v-structures are identified through specific conditional independence testing, and finally, a set of orientation rules are applied . Hence, to implement chatPC, we plug in the LLM-based conditional independence testing in an available PC implementation .

### Causal graphs from the examples

Since for the cancer problem, all CI statements are considered to be false (see Table 1), chatPC would retrieve a complete skeleton. The graph obtained in the burglary problem (with the stat. \(H_{0}=\!\!\) strategy) is depicted in Figure 2 together with the assumed ground truth, while the estimated graph in the asia and sachs problems are reported in the Appendix.

In all cases, the obtained causal graphs have some similarities with the _ground truth_ graphs. Given the imperfect results in the CI statements, recovering the true causal graph is impossible. Nevertheless, we can observe that some interesting patterns have been uncovered (e.g. the Plcg-PIP2-PIP3 and Raf-Mek-Erk relationships in sachs) and an almost correct skeleton in the burglary problem has been estimated.

### Exploring the uncertain: Food insecurity in Africa

As an exploratory real-world example, we try to extract the causal graph among \(8\) variables related to food security in Somalia using chatPC. The Horn of Africa has seen a troubling increase in food insecurity, impacting 6.5 million people in 2022. Prolonged dry spells, along with factors like hydrological conditions, limited food production, market access issues, inadequate humanitarian aid, conflicts, and displacement, contribute to the complex challenges of households in Somalia .

The output graph obtained leveraging information of CI statements up to conditioning sets of size \(1\) is shown in Figure 3. Firstly, we note that the obtained graph is not fully connected. We observe that all obtained arcs and the estimated causal directions are not inconsistent with domain knowledge and common sense . Specifically, we can see the following causal relationships, which agree with the dynamics of agropastoralist households in drought displacement situations, as reported by the Internal Displacement Monitoring Center (iDMC) (Internal

Figure 2: Assumed true graph (a) and skeleton recovered (b) with the proposed chatPC approach for the burglary problem. Variables: Burglary in progress (B); earthquake (E); radio station announcing earthquake (R); alarm ringing (A); security company calling (C).

Displacement Monitoring Centre (iDMC) 2020); i.e., Violent Conflict (VC) - Drought Displacement (DD), Standardized Precipitation Index (SPI) - Sorghum Yield Production (Y), Local Market Prices (LMP) - Global Acute Malnutrition (GAM).

## Conclusions

Our work contributes to the existing literature by probing an alternative to data-driven PC, leveraging the capabilities of LLMs for PC when data is limited or unavailable. Building a reliable knowledge-based conditional independence _oracle_ could either provide a prior to constrain its data-driven counterpart or even deliver a more reliable substitute for data-driven methods. Our analysis attempts to shed light on where we stand in this endeavor. We found that LLM sometimes conjectures about hidden confounders, showing that they use causal reasoning to tackle this primarily statistical task. This, however, is neither done consistently nor always successfully. The varying performance over different tasks showed that more effort is needed to steer the models to more efficient causal reasoning. We proved that employing an aggregating mechanism framed as a statistical test leads to improved performance and effective control over false positive and negative rates. The causal graphs predicted by the PC algorithm with LLM-based conditional independence tests appear reasonable. While not infallible, the method demonstrates potential in capturing meaningful causal relationships, offering a promising avenue for automated causal graph construction. Finally, we found that LLMs generally tend toward conservative answers, contrasting with the often bolder responses from human experts. Understanding and addressing the cautious nature of LLM reasoning is crucial for refining the accuracy and reliability of the generated causal graphs.

In the future, we will explore the combination of data-driven and language-driven causality, where relying on CIT estimates in PC schemes constitutes a sound framework to improve consistency and robustness.