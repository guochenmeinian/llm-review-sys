# Causal Inference using LLM-Guided Discovery

Aniket Vashishtha1, Abbavaram Gowtham Reddy2, Abhinav Kumar3,

**Saketh Bachu2, Vineeth N Balasubramanian2, Amit Sharma1**

###### Abstract

At the core of causal inference lies the challenge of recovering the underlying causal graphs based on observational data. Recent work aggregates the results of edge-wise prompts to infer the full graph structure using Large Language Models (LLMs). However, graph structure cannot be identified uniquely using such localized prompts for each edge since the existence of an edge depends on which other nodes are included in the node set. Therefore, we propose a simpler property of the causal graph, the _topological order_, that can be estimated reliably using localized LLM prompts. Moreover, for downstream tasks like effect inference, the topological order is sufficient to identify causal effect. Hence we LLMs as virtual domain experts and propose a novel localized prompt based on triplets to infer the causal order. Acknowledging LLMs' limitations, we also study possible techniques to integrate LLMs with established causal discovery algorithms, including constraint-based and score-based methods. Extensive experiments demonstrate that our approach significantly improves causal ordering accuracy as compared to discovery algorithms, and in turn decreases the error of downstream effect estimation algorithms.

1Microsoft Research, India

2IIT Hyderabad, India

3Massachusetts Institute of Technology, USA

{t-aniketva, amshar}@microsoft.com,

{cs19resch11002, vineethnb, saketh.bachu}@cse.iith.ac.in, akumar03@mit.edu

## 1 Introduction

A key question for studies across scientific fields such as epidemiology, economics, and atmospheric sciences is estimating the _causal effects_ of variables on an outcome variable. Inferring causal effects from observational data, however, is a difficult task because the effect estimate depends on the causal graph considered in the analysis. While there has been progress in graph discovery algorithms, especially for specific parametric settings Shimizu et al. (2006); Hoyer et al. (2008); Hyvarinen et al. (2010); Rolland et al. (2022), studies on real-world datasets such as from atmospheric science and healthcare Huang et al. (2021); Tu et al. (2019) show that inferring the causal graph from data remains a challenging problem in practice Reisach et al. (2021). Therefore, causal effect inference studies often rely on a human expert to provide the causal graph.

In this paper, based on the fact that the _topological causal order_ over the graph variables is enough for effect inference (see Proposition 4.1), we leverage LLMs as virtual domain experts to propose an automated method to obtain causal order (and hence causal effect). Moreover, providing the _order_ between variables is the right question to ask experts because it depends only on the variables under question, unlike the existence of a graph _edge_ that depends on which other variables are present (to account for direct and indirect effects). For example, consider the data-generating process, _lung cancer_\(\)_doctor visit_\(\)_positive Xray_. If asked, an expert would affirm a causal edge from _lung cancer_ to _positive Xray_ (indeed, such an edge exists in the BNLearn _Cancer_ dataset Scutari and Denis (2014)). However, if they are told that the set of observed variables additionally includes _doctor visit_, then the correct answer would be to not create a direct edge between lung cancer and positive Xray, but rather create edges mediated through _doctor visit_. Note that the causal order, _lung cancer_\(\)_positive Xray_ remains invariant in both settings.

This observation has implications on using LLMs for inferring graph structure, where existing work prompts the LLM about each causal edge separately Kociman et al. (2023); Long et al. (2022). As we argued above, accuracy of such pairwise prompting is not reliable since it depends critically on which other nodes are included in the node set. The simple solution of constructing a prompt that includes all other nodes may be infeasible, especially for large graphs. As a result, we argue that graph structure may not be a suitable output to expect from LLMs (or any other expert). Instead, our main insight is that a simpler graph property, the causal order, can be inferred locally and is not affected by availability of other nodes. Moreover, for downstream tasks like effect inference, the causal order is sufficient to identify the causal effect; full graph structure is not necessary. Our empirical results on six benchmark datasets show that LLMs like GPT-3.5 and GPT-4 can approximate experts' causal order capabilities. To do so, we propose a novel triplet-based prompting strategy that performs better than pairwise prompts Kociman et al. (2023); Willig et al. (2022); Long et al. (2022) for determining the causal order. The triplet prompt also produces significantly lesser cycles in the output graph.

Still, LLMs can exhibit unknown failure modes. Therefore, we propose two algorithms to combine existing graph discovery algorithms with LLMs: one employs LLM causal order to guide a constraint-based algorithm (e.g., PC) in orienting undirected edges, while the second incorporates LLM causal order as a prior for a score-based algorithm like CaMML. We find that LLM-enhanced algorithms outperform base causal discovery methods in inferring causal order. The methodology is illustrated in Figure 1. Our contributions include,

* We propose prompting strategies for estimating the order using LLMs, which is more reliable than estimating the graph structure using LLMs.
* We propose algorithms for inferring causal order using a novel triplet prompting strategy, using only LLMs and combining them with existing discovery algorithms.

## 2 Related Work

Historically, causal discovery  and causal effect inference  have been studied separately. Instead of using the learned graph for effect inference , demonstrate a simpler combination of approaches: causal order suffices instead of the entire graph.

Our work is related to LLM-based knowledge-driven causal discovery . Unlike causal discovery algorithms that use statistical patterns in the data, LLM-based algorithms use metadata such as variable names. These methods use LLMs to predict causal structure over a set of variables by aggregating the results of an edge-wise prompt for each pair of variables . Instead, we show that the existence of an edge may not be identified if we do not know other existing variables; hence causal order is a more suitable output to elicit from LLMs. We also propose a triplet-based prompt for inferring the causal order, which may be of independent interest in prompting LLMs for causality.

Since LLMs may exhibit errors, a more principled approach may be to combine LLMs with existing discovery algorithms.  use LLM to improve the output of a constraint-based algorithm for full graph discovery and  use LLMs as priors for existing score-based causal discovery methods. We extend this idea to causal order estimation by proposing LLM-adaptations for constraint- and score-based algorithms.

## 3 Background and Problem Formulation

Let \((,)\) be a causal directed acyclic graph (DAG) consisting of a set of variables \(=\{X_{1},,X_{n}\}\) and a set of directed edges \(\) among the variables in \(\). A directed edge \(X_{i} X_{j}\) denotes the _direct_ causal influence of the variable \(X_{i}\) on the variable \(X_{j}\). Let \(pa(X_{i})=\{X_{k}|X_{k} X_{i}\}\), \(de(X_{i})=\{X_{k}|X_{k} X_{i}\}\) denote the set of _parents_ and _descendants_ of \(X_{i}\) respectively. A sequence \(\) of variables \(\) is said to be a topological order iff for each edge \(X_{i} X_{j}\), \(_{i}<_{j}\).

We focus on a downstream application of causal graph discovery called causal effect inference. The average causal effect (ACE) of a variable \(X_{i}\) on a variable \(X_{j}\) is defined as \(ACE_{X_{i}}^{X_{j}}=[X_{j}|do(X_{i}=x_{i})]-[X_{j}|do(X_{i }=x_{i}^{*})]\). Here, \(X_{i}\) is called the _treatment_ variable and \(X_{j}\) is called the _target_ variable. \(do(X_{i}=x_{i})\) denotes an external intervention to the variable \(X_{i}\) with the value \(x_{i}\). The interventional quantity \([X_{j}|do(X_{i}=x_{i})]\) is different from conditional \([X_{j}|X_{i}=x_{i}]\) since it involves setting the value of \(X_{i}\) rather than conditioning on it. To estimate the quantity \([X_{j}|do(X_{i}=x_{i})]\) from observational data, the back-door adjustment formula  is used. Given a DAG \(\), a set of variables \(\) satisfies back-door criterion relative to a pair of treatment and

Figure 1: The _LLM-augmented_ causal inference process based on inferring causal order. We propose a triplet-based prompting technique to infer all three-variable subgraphs and aggregate them using majority voting to produce a causal order. The causal order (optionally combined with discovery algorithms like PC or CaMML) can then be used to identify a valid back-door adjustment set. Ties in causal order are broken using GPT-4.

target variables (\(X_{i},X_{j}\)) if (i) no variable in \(\) is a descendant of \(X_{i}\); and (ii) \(\) blocks every path between \(X_{i}\) and \(X_{j}\) that contains an arrow into \(X_{i}\). Where a _path_ in a causal DAG is a sequence of unique vertices \(X_{i},X_{i+1},,X_{j}\) with a directed edge between each consecutive vertices \(X_{k}\) and \(X_{k+1}\) (either \(X_{k} X_{k+1}\) or \(X_{k+1} X_{k}\)). If a set of variables \(\) satisfies the back-door criterion relative to \((X_{i},X_{j})\), \([X_{j}|do(X_{i}=x_{i})]\) can be computed using the formula: \([X_{j}|do(X_{i}=x_{i})]=_{} [X_{j}|X_{i}=x_{i},=]\) (Theorem 3.3.2 of Pearl (2009)). To ensure causal effect identifiability, we make the no-latent confounding assumption.

## 4 Causal Order Suffices for Effect Estimation

We start with the fact in Proposition 4.1 that the causal order is sufficient to find a valid back-door set and discuss why causal order is easier to elicit from experts than the DAG.

### Causal Order Provides a Valid Back-Door Set

**Proposition 4.1**.: _(Pearl 2009; Cinelli, Forney, and Pearl 2022a) Under the no-latent confounding assumption, given a pair of treatment and target variables \((X_{i},X_{j})\), \(=\{X_{k}|_{k}<_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j})\) for any topological order \(\) of nodes \(X_{i},,X_{n}\)._

Proofs of all propositions are in Appendix SSA. Prop. 4.1 states that all the variables that precede the treatment variable in a topological order \(\) of \(\) constitute a valid adjustment set. Note that the set \(\) may contain variables that are not necessary to adjust for, e.g., ancestors of only treatment or only target variables. For statistical estimation, ancestors of target variable are beneficial for precision whereas ancestors of treatment can be harmful (Cinelli, Forney, and Pearl 2022b). On balance though, causal effect practitioners tend to include all confounders that do not violate the back-door criterion; we are following the same principle. In practice, however, we may not know the true order. To evaluate the goodness of a given causal order, we use the topological divergence metric from (Rolland et al., 2022) (for an example, see Fig. 3). The topological divergence of an estimated topological order \(\) with ground truth adjacency matrix \(A\), denoted by \(D_{top}(,A)\), is defined as \(D_{top}(,A)=_{i=1}^{n}_{j:_{i}>_{j}}A_{ij}\). Where \(A_{ij}=1\) if there is a directed arrow from node \(i\) to \(j\) else \(A_{ij}=0\). \(D_{top}(,A)\) counts the number of edges that cannot be recovered due to the estimated topological order \(\).

### \(}\) Is a Valid Metric for Effect Estimation

Below, we show that \(D_{top}\) is a valid metric to check the correctness of the estimated causal effects. That is \(D_{top}(,A)\) being \(0\) is equivalent to obtaining the correct back-door adjustment set from \(\) (Proposition 4.1).

**Proposition 4.2**.: _For an estimated topological order \(\) and a true topological order \(\) of a causal DAG \(\) with the corresponding adjacency matrix \(A\), \(D_{top}(,A)=0\) iff \(=\{X_{k}|_{k}<_{i}\}\) is a valid adjustment set relative to \((X_{i},X_{j})\), \(_{i}<_{j}\)._

We now compare \(D_{top}\) to structural hamming distance (SHD), a common metric for evaluating graph discovery algorithms. Given a true causal DAG \(\) and an estimated causal DAG \(}\), SHD counts the number of missing, falsely detected, and falsely directed edges in \(}\). We note that SHD can be very high even when \(D_{top}=0\) and a valid back-door set can still be inferred. This result is of significance since most estimated graphs (included those that are LLM-generated (Ban et al., 2023; Long et al., 2023)) are evaluated on SHD.

**Proposition 4.3**.: _In a causal DAG \(\) with \(N\) levels in the level-ordering of variables where the level \(i\) contains \(n_{i}\) variables,\(\,}\) s.t. \(SHD(},)_{i=1}^{N-1}(n_{i} _{j=i+1}^{N}n_{j})-||\) and \(D_{top}(,A)=0\)\(\) of \(}\)._

where a level order refers to a systematic assignment of levels to variables. This assignment begins with the set of variables \(\{X_{i}|(X_{i})=\}\) at level 0. Subsequently, each of the remaining variables is assigned a level \(i\) such that all nodes within a given level \(i\) has a directed path of length \(i\) from one/more nodes in level 0. Figure 2 shows the limitations of SHD empirically. Given a fixed number of nodes, we sample a graph at random as the 'ground-truth' and then consider all graph orientations of the same size (number of nodes) such that \(D_{top}=0\) with respect to ground-truth graph. For this set of graphs, we compute the SHD with respect to the ground-truth graph. Notice that SHD exhibits high variance. For graphs with six nodes, SHD can vary from 0 to 14 even as \(D_{top}=0\) and back-door set validity stays the same. Fig. 3 shows this phenomenon on a real-world BNLearn dataset, _Cancer_. The estimated graph (right panel) has \(D_{top}=0\) with respect to the true graph (left) and yields valid back-door identification sets. However, its SHD is high (6), showing the disconnect between SHD and causal effect identification.

Figure 3: **Left:** Causal graph of Cancer dataset. **Right:** GPT-3.5â€™s estimated causal graph. GPT-3.5 gets causal order correct at the cost of higher SHD score Here \(D_{top}=0\) and \(SHD=6\)

Figure 2: Variability of SHD with consistent \(D_{top}=0\).

[MISSING_PAGE_FAIL:4]

### Prompt Technique Based on Triplets

As we shall see, while pairwise prompts are conceptually simple, they are prone to yielding higher number of cycles in the graph since they decide about each edge separately. Taking inspiration from the PC algorithm that employs constraints over three variables, we now describe a prompting technique based on iterating over all possible triplets given a set of nodes. Once the LLM has provided subgraphs for each triplet, we determine causal order between a pair by aggregating over all triplet LLM answers where the pair was included.

The algorithm has the following steps after generating all possible triplets from a set of nodes. **1)** Generate subgraphs over all triplets through LLMs by prompting them to orient the three causal edges for each triplet. **2)** Merge the resultant structure between any two nodes by aggregating the number of LLM answers for the three orientations: (A \(\) B; B \(\) A; No connection) and choosing the majority answer. If there's a tie in edge orientation, GPT-4 is used with a CoT prompt to make the final decision. Then the causal order is extracted from the graph.

## 6 LLM-Guided Discovery Algorithms

Causal order from LLMs may exhibit unknown failure modes . Hence we now provide algorithms for combining LLMs with causal discovery paradigms.

* **Constraint-based Algorithm**: Given a graph from constraint based algorithm like PC where some edges are not oriented, we use the causal order \(\) from LLM to orient the undirected edges. Iterating over the undirected edges, we first check if the nodes of that edge are occurring in \(\). If yes, we orient the edge according to the causal order. Since there is a possibility that LLM's final graph might have some isolated nodes which won't be in \(\), therefore if either (or both) nodes of the undirected edge are not included in \(\), we query GPT-4 using pairwise CoT prompt (from Sec. 5.1) to finalise a direction between the pair. Refer to Algorithm 1 in Appendix.
* **Score-based Algorithm**: We provide the level order of the causal graph returned by LLM as a prior for a score-based algorithm. Optionally, we can provide prior probability to control the influence of prior on the algorithm. Algorithm 2 in Appendix outlines the steps to combine score based method and the prior level order of variables.

## 7 Experiments and Results

To evaluate the accuracy of LLM-based algorithms on inferring causal order, we perform experiments on the benchmark datasets from Bayesian network repository : Earthquake, Cancer, Survey, Asia, Asia modified (Asia-M), and Child (see AppendixS D for details). We also used a medium sized subset graph from the Neuropathic dataset  used for pain diagnosis.

\(}\)**correlates with effect estimation error:** Before comparing methods on the \(D_{top}\) metric, we first show that \(D_{top}\) has a strong correlation with effect estimation error and hence is the correct metric for effect inference. Specifically, we study how the error in causal effect, \(_{ACE}\), changes as values of the metrics \(SHD,D_{top}\) change. In each graph, we evaluate causal effects of each variable on a specified target variable. We iterate through estimated causal graphs with different values of SHD and \(D_{top}\) and report the mean absolute difference between estimated and true causal effects. As Table 2 shows, when \(D_{top}\) is zero, effect error \(_{ACE}\) is also zero. And as \(D_{top}\) increases (right panel), effect error increases. In contrast, SHD has no correlation with the \(_{ACE}\).

**Triplet prompting is most accurate for causal order:** Comparing prompting techniques (Tab. 3), we observe limitations with pairwise prompts as graph size increases. They often lead to significantly high cycles, making \(D_{top}\) calculation infeasible. Notably, for the 20-node Child dataset, pairwise prompts result in thousands of cycles. Similar trends can be seen for Neuropathic graph as well. Among pairwise prompts, the chain-of-thought prompt achieves the lowest SHD for the small graphs and the fewest cycles for Child and Neuropathic. This highlights the effectiveness of in-context examples and chain-of-thought reasoning in improving causal order accuracy. The triplet prompt yields highly accurate causal order predictions. For all small graphs, number of cycles are 0 and \(D_{top}\) is either 0 or 1. Additionally, the LLM output has lowest SHD. While the number of cycles increases when scaled to larger graphs (Child and Neuropathic), the numer is still significantly much smaller than cycles in pairwise output (all setups included).

Since pairwise orientations yielded substantially more cycles then triplet (see Table 3), we applied a cycle removal algorithm to triplet output only, to use it as prior for discovery algorithms. Our cycle removal algorithm is inspired from . In the original approach, the algorithm minimizes edges to form a weighted DAG. As our noisy expert graphs lack edge weights, we leverage triplet pipeline votes to establish a probability distribution for edge orientations. Using this, we calculate the entropy for eachedge, removing those with higher entropy (lower confidence). To minimize \(D_{top}\), we pruned edges with entropy below the mean of all entropies. However, optimizing the threshold and minimizing edges for a DAG increased connected nodes but also led to a higher \(D_{top}\), diminishing the quality of the prior and causing poor causal discovery performance. Since pruning edges to remove cycles in the pairwise case would have resulted in a non-significant prior, we only apply this on triplet prompting where cycle removal is feasible.

**LLMs improve causal order accuracy of existing discovery algorithms:** We investigate if LLM output enhances causal order inference accuracy in discovery algorithms. We compare against widely used methods: PC (Spirtes, Glymour, and Scheines 2000), SCORE (Rolland et al. 2022), ICA-LiNGAM (Shimizu et al. 2006), Direct-LiNGAM (Shimizu et al. 2011), NOTEARS (Zheng et al. 2018), and CaMML (Wallace, Korb, and Dai 1996) across sample sizes: \(250,500,1000,5000,10000\) (refer Table 1 for full results). We employ the triplet prompt with LLM. Table 1 presents the \(D_{top}\) metric for different algorithms and compares it with PC+LLM and CaMML+LLM. PC and CaMML exhibit superior performance with the lowest \(D_{top}\) among the discovery algorithms.LLM output reduces \(D_{top}\) in both algorithms. PC+LLM exhibits substantial improvements, particularly at lower sample sizes, implying LLM's significance in limited data settings. Transitioning from CaMML to CaMML+LLM also shows significant \(D_{top}\) reductions, with benefits even at higher sample sizes. For instance, at sample size 10000, CaMML+LLM outperforms CaMML by a factor of three for Child and five for Asia. These findings underscore the substantial enhancement LLMs provide to causal discovery algorithms.

## 8 Limitations and Conclusions

We presented causal order as a suitable metric for evaluating quality of causal graphs for downstream effect inference tasks. Using a novel formulation of LLM prompts based on triplets, we showed that LLMs can be useful in the generating accurate causal order, both individually and in combination with existing discovery algorithms. That said, one limitation is that we studied LLMs utility on popular benchmarks which may have been partially memorized. It will be interesting to extend our experiments to more datasets and tasks. Also, we focused on one causal task, viz. effect inference, in this work; identifying suitable metrics for tasks such as causal prediction and counterfactual inference and extending to other tasks in causal inference may be useful directions for future work.