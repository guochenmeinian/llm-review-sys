# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

ing (Zhang et al., 2021; Raedt et al., 2015). Learning the RPM rules becomes a differentiable assignment problem of high-dimensional panel representations in a series of binding and unbinding operations, which can be solved with unconstrained optimization algorithms such as stochastic gradient descent (SGD). ARLC outperformed the SOTA LLM-based approach (Hu et al., 2023) both on in-distribution and OOD, thanks to relying on structured and similarity-preserving representations based on fractional power encoding (FPE) (Plate, 2003). Moreover, ARLC's rules could still be manually programmed and further trained allowing to extend the knowledge of the model, rather than completely erasing it as shown in other settings (Wu, Zhang, and Shu, 2019).

This paper extends on the initial work on ARLC (Camposampiero et al., 2024), by comparing its abstract reasoning capability with two prominent LLMs, GPT-4 (OpenAI et al., 2024) and Llama-3 70B (Dubey et al., 2024) (see Figure 1). Circumventing the perception by providing ground-truth attribute labels to the models allows us to measure their analogical and mathematical reasoning capabilities in isolation when such _compositionally structured_ (i.e., disentangled) representations are provided. Our comprehensive prompting efforts lead to very high accuracy for Llama-3 70B (85.0%) and GPT-4 (93.2%), where the latter notably outperforms previous reports with GPT-3 (Hu et al., 2023) (86.4%) and GPT-4 01-preview (Latif et al., 2024) (18.00%). The LLM's still imperfect accuracy on the isolated task motivated us to further analyze their capability of detecting and executing different rules. In both GPT-4 and Llama-3 70B, we find a notable weakness in performing arithmetic rules that require row-wise additions or subtractions (e.g., see the last prompt in Figure 2). To gain more insight about this behavior, we set up a new RPM dataset (I-RAVEN-X) that increases the grid size from 3\(\)3 to 3\(\)10, additionally allowing for a configurable dynamic range for the arithmetic computations. Also here, we observe a notable weakness in the arithmetic rule that gets even amplified by an increasing dynamic range. On the other hand, ARLC demonstrates high accuracy on larger grid sizes and allows to increase the dynamic range without requiring further retraining, thanks to the the capability of adjusting the underlying structured FPE representations.

## 2 Datasets

### I-RAven

We test the models on the center constellation of I-RAVEN (Hu et al., 2021) (see Figure 1). The test consists of a 3\(\)3 context matrix and eight answer candidate panels. Each panel contains an object, characterized by different attributes (shape, size, and color). The relation between each attribute's value in different panels is governed by a well-defined set of rules: constant, progression, arithmetic, and distribute three. The task is to infer the rule governing each attribute in the context matrix and use it to determine the content of the missing (bottom-right) panel, selecting it within the eight candidate answers. Compared to other RPM benchmarks that have been used to evaluate LLMs (Webb, Holyoak, and Lu, 2023), I-RAVEN tests a more complex range of logical and arithmetic skills. While I-RAVEN provides tests in various constellations with more objects that may intuitively appear more arduous to solve, LLMs are more challenged with the seemingly simple constellations. For instance, GPT-3 achieved a higher accuracy on the 2x2 and 3x3 constellations (78.0% and 86.4%) than on center (77.2%) (Hu et al., 2023). Moreover, high accuracy can be maintained on the 2x2 and 3x3 constellations while only looking at the last row of the context matrix (Hu et al., 2023), effectively showing that no analogical reasoning is required to solve the test in these constellations. Hence, we opted to focus our evaluation on the center constellation only, using 500 samples from I-RAVEN's test

Figure 1: This work compares the abstract reasoning capabilities of large language models (LLMs) and neuro-symbolic ARLC on Raven’s progressive matrices (RPM) tests. **a)** An RPM example taken from the center constellation of I-RAVEN. The task is to find the empty panel at the bottom-right of the context matrix by selecting one of the answer candidates. **b)** Solving RPMs through LLM prompting. Visual attribute values are extracted from the I-RAVEN dataset and assembled to individual per-attribute text-only prompts. LLMs are prompted to predict the attribute of the empty panel. Finally, the attribute predictions are compared with the answer candidates, whereby the best-matching answer is selected as the final answer. **c)** Solving RPMs with neuro-symbolic ARLC that relies on distributed similarity-preserving representations and manipulates them via dimensionality-preserving operations; it learns rule-formulations as a differentiable assignment problem.

set. Inspired by recent works , we simplify RPM from a visual abstract reasoning test to a purely abstract reasoning test. Assuming a perfect perception, we extract the attribute values from I-RAVEN and use them to create the prompts for the model.

### New I-RAVEN-X

To further evaluate the mathematical reasoning capabilities at scale, we introduce an extension of the I-RAVEN's center constellation, called I-RAVEN-X. Our new benchmark maintains I-RAVEN's rules and attributes but allows for a parameterizable number of columns (\(g\)) and a dynamic range of attribute values (\(m\)). Appendix D provides details about the dataset generation, and Figure 1(b) shows example prompts from I-RAVEN-X.

## 3 LLM-based RPM solving

### Models

We focused our evaluations on text-only LLMs. There exist attempts  that leverage vision support of some multi-modal LLMs (e.g., GPT-4V) directly feeding the models with visual RPM data; however, they achieve consistently lower reasoning performance than with text-only prompting. The SOTA LLM-based abstract reasoning approach  relied on reading out GPT-3's (text-davinci-002) token probabilities. However, this model is no longer accessible to users, and its successive iterations did not allow prediction logits to be retrieved at the time of writing. Hence, we considered discrete classification approaches that are based on output strings rather than distribution over tokens. In particular, we investigated two SOTA LLMs: the proprietary GPT-4 (OpenAI et al. 2024)2 (gpt-4-0613) and the open-source Llama-3 70B 3. More recent iterations of these models were not considered in our analysis for different reasons. Meta's attribution requirement in their updated terms regarding naming conventions prevented us from testing Llama-3.1 During initial tests, GPT-4q yielded worse results than GPT-4, hence we focused on GPT-4. Moreover, GPT-4 o1's poor abstract reasoning results on RPM  and its limited availability (only preview version available at time of writing) prevented us from performing statistically significant tests on this chain-of-thought model.

### Prompting and classification

Entangled and disentangled promptsFollowing , we evaluated two different prompting strategies, _entangled_ and _disentangled_ prompting. The entangled prompting provides all the attributes' values in a single prompt (see Appendix A). The disentangled prompting, on the other hand, is a compositionally structured approach that queries the LLM for individual attribute prediction. Disentangled prompting simplifies the task, but increases the number of queries by 3\(\).

Discriminative and predictive classificationSimilarly to , we consider two approaches to solve RPM tests with LLMs. In the _discriminative_ approach, we provide the attribute descriptions of both the context matrix and the answer candidates. The LLM is then asked to return the panel number of the predicted answer. Appendix A provides an example prompt of the discriminative approach. In the _predictive_ approach, we prompt the LLM only with the context matrix without the candidate answers. The LLM has to predict the value of the empty panel (see Figure 2). For selecting the final answer, we compare the predicted values with the answer panels and pick the one with the highest number of overlapping values. While the predictive approach may appear more difficult, it implicitly biases the

Figure 2: Prompting LLMs to predict the missing content (value) of the RPM. Correct outputs are marked green and wrong ones red. **a)** Individual per-attribute text-only prompts to solve RPM tasks from I-RAVEN. **b)** Example prompts with of our novel configurable I-RAVEN-X dataset of size 3\(\)10 with a value range of \(m=1000\). In both the I-RAVEN and I-RAVEN-X examples, the LLM (GPT-4) errs in the arithmetic rules.

LLM to approach the task as humans usually do, i.e., first applying a generative process to abduce rules and execute them to synthesize a possible solution, and then discriminatively selecting the most similar answer from choices . Moreover, the final answer selection is done without the intervention of the LLM, rendering phenomena like hallucinations less likely. Thus, the predictive classification can be seen as a more guided approach that helps LLM to solve the task.

Additional enhancementsFinally, we also employ well-known prompting-enhancing techniques such as self-consistency  and in-context learning  to improve the performances. More details are provided in Appendix A.

## 4 ARLC: learning abductive reasoning using VSA distributed representations

This section presents the Abductive Rule Learner with Context-awareness (ARLC), which performs neuro-symbolic reasoning with distributed VSA representations (see Figure 3). ARLC projects each panel's attribute value (or distributions of values) into a high-dimensional VSA space. The resulting VSA vectors preserve the semantic similarity between attribute values: the dot products between corresponding VSA encoded vectors define a similarity kernel . Moreover, simple component-wise operations on these vectors, binding and unbinding, perform addition and subtraction respectively on the encoded values. For rule learning, ARLC introduces a generic rule template with several terms forming a series of binding and unbinding operations between vectors. The problem of learning the rules from data is reduced to a differentiable assignment problem between the terms of the general rule template and the VSA vectors encoding the contents of the panels, which can be learned with standard SGD. ARLC was initially presented in ; this work mainly compares it to the reasoning capabilities of LLMs on I-RAVEN, and demonstrates its extension to larger grid sizes and dynamic ranges on our novel I-RAVEN-X.

### From visual attributes to distributed VSA representations

ARLC's key concept is to represent attribute values with high-dimensional, distributed VSA vectors that preserve the semantic similarity between the attribute values thanks to an introduced notion of kernel. We start by defining a VSA that equips the space with dimensionality-preserving vector operations (binding \(\), unbinding \(\), and bundling \(\)) as well as a similarity function (\((,)\)). For example, ARLC uses binary generalized sparse block codes (GSBCs)  as a particular VSA instance. In binary GSBCs, the \(D\)-dimensional vectors are divided into \(B\) blocks of equal length, \(L=D/B\), where only one (randomly selected) element per block is set to 1 (\(D=1024\) and \(B=4\)). The algebraic operations of binary GSBCs are defined in Table 1. See Appendix B for a detailed background on VSA.

Next, we define a mapping \(z:^{+}^{D}\) that enables the projection of input RPM attributes into a corresponding high-dimensional, semantically-rich feature space. Note that this work focuses on mapping integer values as the attribute values in I-RAVEN are integer-valued too. However, generalizing this approach to real-valued domain mappings is possible using frequency holographic reduced representations (FHRR) . Leveraging fractional power encoding (FPE) , a value \(v^{+}\) is encoded as \((v)=^{v}=_{n=1}^{v}\), where \(^{D}\) is a random binary GSBC vector. This mapping yields a similarity kernel between neighboring vector representations , as shown in Figure B.7 in Appendix B.

Let us assume two variables with values \(v_{1}\) and \(v_{2}\), which are represented with two VSA vectors (\((v_{1})=^{v_{1}}\) and \((v_{1})=^{v_{2}}\)). Binding the two vectors yields \((v_{1})(v_{2})=^{v_{1}}^{v_{2}}=^{v_{1}+v_{2}}\). Hence, binding in the VSA space is equivalent to the addition in \(\). In other words, the FPE initialization allows to establish a semantic equivalence between high-dimensional vectors and real numbers. This property is consistently exploited in ARLC's framework, as it allows to solve the analogies in the RPM puzzles as simple algebraic operations in the domain of real numbers. For example, by computing the similarity between the bound representation and a third projected variable (\((^{v_{1}+v_{2}},^{v_{3}})\)), we can evaluate if \(v_{1}+v_{2}}{{=}}v_{3}\) representing the arithmetic plus rule in RPM.

One advantage of performing reasoning with distributed VSA representations is its capability to represent perceptual uncertainty in the variable values. Connecting to the previous example, let us assume that the first variable takes value \(v_{1}\) with probability \(p\) and value \(v_{1}^{}\) with probability \(p^{}=1-p\). The distribution can be encoded as the weighted superposition of the two corresponding codewords: \(p^{v_{1}}+p^{}^{v_{1}^{}}\). The similarity computation between the bound representation and a third variable would then yield

\[((p^{v_{1}}+p^{} ^{v_{1}^{}})^{v_{2}},^{v_{3}})=\] \[p(^{v_{1}}^{ v_{2}},^{v_{3}})+p^{}(^{v_{1}^{ }}^{v_{2}},^{v_{3}}),\]

where we use the linearity of the binding operation and the similarity metric. This formulation allows the validation of multiple solutions (in this case two) using only a single binding and similarity computation.

In the RPM application, each panel's label is translated to a probability mass function (PMF) \(_{a}^{(i,j)}\), where \(a\) is the attribute, \(i\) is the row index and \(j\) is the column index of the panel. The panel's PMF is then projected into the VSA space

\[_{a}^{(i,j)}=_{k=1}^{m}_{a}^{(i,j)}[k] ^{k},\]

where \(m\) is the number of possible values that the attribute \(a\) can assume. Overall, this yields eight VSA vectors for each attribute \(a\) (one for each panel of the input RPM matrix). Note that the basis vectors are pre-computed and stored in a dictionary \(=\{^{k}\}_{i=1}^{r}\) containing \(m\) elements.

### Learning RPM rules as an assignment problem

As we have seen in the previous example, RPM rules can be represented using VSA operations. Generalizing the application beyond the arithmetic plus rule, we find that the rules used in RPM can be framed as a series of binding and unbinding operations:

\[r= (_{1}_{2}_{3} _{4}_{5}_{6})\] \[(_{7}_{8}_{9} _{10}_{11}_{12}), \]

where \(_{i}\) can be assigned to a context panel \(_{a}^{(i,j)}\) or the identity \(\). In this setting, learning the rules of RPM can hence be interpreted as an assignment problem between VSA vectors and terms of Equation (1).

Motivated by works in cognitive sciences and psychology that argue for the importance of context in the solution of analogies for humans , ARLC uses a general formulation of the soft-assignment problem which relies on the notion of _context_:

\[_{k}=_{i=1}^{I}w_{k}^{i}_{i}+_{j=1}^{J}u_{k}^ {j}_{j}+v_{k}, \]

where \(,,\) are the learned parameters and they are subject to the following constraints:

\[_{i=0}^{I}w_{k}^{i}+_{j=0}^{J}w_{k}^{j}+v_{k}=1,\] \[0 w_{k}^{i} 1\, i, 0 w_{k}^{j} 1\,  j, 0 v_{k} 1,\, k.\]

Here, \(=\{_{1},,_{I}\}\) is the set of attributes that define the current sample, that is, the description of the problem for which we infer a solution. \(=\{_{1},,_{J}\}\) is the set of attributes that define the context for that sample, that could be interpreted as a working memory from which additional information to infer the answer can be retrieved. For predicting the empty panel in the last row, the context (\(\)) corresponds to the first two rows and the current samples (\(\)) to the last row (see Figure 3(c)). We augment this standard prediction with two more permutations, which aim to predict the last panel of the first and second row (see Figure 3(a) and Figure 3(b)). The knowledge of the right-most panels in the first

   Operation & Binary GSSCs with FPE & Equivalent in \(\) \\  Binding (\(\)) & Block-wise circular convolution & Addition + \\ Unbinding (\(\)) & Block-wise circular correlation & Subtraction -- \\ Bundling (\(\)) & Sum \& normalization & — \\ Similarity (\(\)) & Cosine similarity (\((,)\)) & — \\   

Table 1: VSA operations and their equivalent in \(\).

Figure 4: Visualization of current samples (\(X=\{x_{1},x_{2}\}\), in yellow) and context (\(O=\{o_{1},,o_{5}\}\), in green) panels when predicting the third panel for different rows, namely the first row (left), second row (center) and third row (right). Black objects represent panels that are not used for the computation, while the question mark represents the unknown test panel, which is unavailable during inference.

Figure 3: ARLC architecture. ARLC maps attribute values, or distributions of values, to distributed VSA representations, where the semantic similarity between values is preserved via a notion of kernel. Learnable rules (\(r_{1},...,r_{R}\)) predict the VSA representation of the empty panel (\(}_{a,r}^{(3,3)}\)) together with a confidence value (\(s_{r}\)). The closest answer to the predicted soft-selected prediction (\(}_{a}^{(3,3)}\)) is chosen as the final answer.

two rows allows us to compute a rule confidence by comparing the rule's prediction with the actual panel representation via the cosine similarity.

### Executing and selecting the learned rules

Inference with the learned rule set is a two-step process: an execution step (where all the rules are applied in parallel to the input) and a selection step (where a prediction for the missing panel is generated). The application of each rule \(r\) to an RPM example generates a tuple of three VSA vectors \((}_{a,r}^{(i,3)})_{i=1}^{3}\), which corresponds to the result of the rule execution on the three rows of the RPM matrix, together with a rule confidence value \(s_{r}\). The confidence value is computed as the sum of the cosine similarities between the predicted VSA vectors and their respective ground-truth vector,

\[s_{r}=_{i=1}^{3}(_{a}^{(i,3)},}_{a,r}^{( i,3)}). \]

During inference, the last term of the sum (\(i=3\)) is omitted, as the ground truth for the third row is unknown.

The answer is finally produced by taking a linear combination of the VSA vectors generated by executing all the rules, weighted by their respective confidence scores (normalized to a valid probability distribution using a softmax function). More formally, if we define \(=[s_{1},,s_{R}]\) to be the concatenation of all rules' confidence score and \(}_{a}^{(3,3)}=[}_{a,1}^{(3,3)},,}_{a,R}^{(3,3)}]\) to be the concatenation of all rules' predictions for the missing panel, the final VSA vector predicted by the model for the attribute \(a\) becomes

\[}_{a}^{(3,3)}=()}_{a}^{(3,3)}. \]

The use of the weighted combination can be understood as a _soft-selection_ mechanism between rules and was found to be more effective compared to the _hard-selection_ mechanism provided by sampling .

### Training Loss and other Implementation Aspects

We follow the training recipe provided by Learn-VRF . The model is trained using stochastic gradient descent (SGD) with a learning rate lr \(=0.01\) for 25 epochs. The training loss is defined as the inverse cosine similarity between the three predicted panels and their corresponding ground truth

\[=1-_{i=1}^{3}(_{a}^{(i,3)}, }_{a}^{(i,3)}). \]

As in Learn-VRF, we set the number of rules to \(R=5\). A single set of rules is instantiated and shared between all RPM attributes.

### Applying ARLC on I-RAVEN-X

While ARLC was initially designed for I-RAVEN, it can be seamlessly extended to our I-RAVEN-X with minor modifications. First, the number of binding/unbinding terms in Equation (1) is increased, e.g., from 12 to 22 to support the larger grid size of \(g=10\). Moreover, we increase the number of entries in the dictionary (\(\)) to support the larger dynamic range (\(m\)). Notably, only varying the dynamic range at constant grid size does not require retraining: we can simply replace the dictionary in order to support OOD generalization. Indeed, we could demonstrate that ARLC trained on a dynamic range of \(m=45\) can favorably generalize to a dynamic range of \(m=1000\).

## 5 Results

### Main results on I-RAVEN

Table 2 compares our LLM results with ARLC on the center constellation of I-RAVEN, also considering a range of neuro-symbolic and connectionist baselines. For the LLMs, we show the results with the corresponding best prompting techniques (see the ablation in the next subsection).

Moreover, we present results for two different versions of ARLC: ARLC\({}_{rg}\), where the model's weights are manually programmed with RPM rules (\(R=4\), since constant can be considered as a special case of progression), and ARLC\({}_{}\), where the rules are learned from scratch from data.

Among the LLM approaches, our GPT-4-based approach achieved the highest accuracy (93.2%) notably outperforming previous SOTA LLM-based abstract reasoning approaches on this benchmark (86.4%) . Yet, all LLM approaches fall behind the tailored connectionist and neuro-symbolic solutions. Notably, with only 480 learnable parameters, ARLC achieves a high accuracy of 98.4%.

### Ablation of LLM prompting techniques

Table 3 shows the task accuracy on I-RAVEN using GPT-4 and Llama-3 70B in various prompting configurations. Overall, both models benefit from the additional guidance provided by our prompting techniques. Concretely, using a predictive approach and querying for individual disentangled attributes yielded already high accuracies (91.4% and

   Method & Parameters & Accuracy \\  MLP  & 300 k & 97.6 \\ SCL  & 961 k & \(99.9^{ 0.0}\) \\ PrAE  & n.a. & \(83.8^{ 3.4}\) \\ NVSA  & n.a. & \(99.8^{ 0.2}\) \\ Learn-VRF  & 20 k & \(97.7^{ 4.1}\) \\ GPT-3  & 175 b & 86.4 \\  Llama-3 & 70 b & 85.0 \\ GPT-4 & unk. & 93.2 \\ ARLC\({}_{rg}\) & n.a. & \(100.0^{ 0.0}\) \\ ARLC\({}_{}\) & 480 & \(98.4^{ 1.5}\) \\   

Table 2: Task accuracy (%) on the center constellation of I-RAVEN. Among the baselines, we replicate Learn-VRF ; the other results are taken from . The standard deviations are reported over 10 random seeds. Llama-3 and GPT-4 are queried with the corresponding best prompting technique (see Table 3). Number of parameters for GPT-4 is not publicly available. The reasoning backend of PrAE, NVSA, and our ARLC\({}_{ 1}\) do not have trainable parameters.

83.2% for GPT-4 and Llama-3 70B, respectively). Introducing self-consistency further improves the accuracy for both models. Llama-3 70B's performance can be further pushed (to 85.0%) by using self-consistency and in-context learning. On the contrary, GPT-4 cannot make use of the additional in-context samples, yielding a lower accuracy instead.

### LLMs show weakness in arithmetic rule

Even though both LLMs achieve a reasonable overall task accuracy, they fail in some instances. We shed more light on the reasoning capability of the two models by analyzing the accuracy of predicting the correct value for a given rule. As shown in Table 4, both models perform well on constant, progression, and distribute three rules, whereas the accuracy notably drops for the arithmetic rule. One explanation for the accuracy drop could be the LLM's tendency for (short-sighted) relational reasoning, instead of performing relational mapping that requires the understanding of the first two rows before applying a rule on the last row . We analyze this hypothesis in Appendix C, where we attempt to explain the LLM's wrong predictions by rules that may have been inferred from the last row. For GPT-4, 32 out of 68 errors can be explained by rules that might have been inferred from a partial context matrix, e.g., a constant or progression rule based on the last row.

### Results on our novel I-RAVEN-X

Finally, we conduct experiments on our novel I-RAVEN-X test, which allows us to configure the matrix size and the dynamic range of the attribute values. We fix the grid size to \(3 10\) and vary the dynamic range between 50, 100, and 1000. As shown in Table 5, the performance on the arithmetic rule drops not only due to the larger grid size but also generally degrades with an increasing dynamic range: the arithmetic accuracy falls below 10% for both LLMs at the highest dynamic range (1000). At the same time, our ARLC maintains a high accuracy across the board, while only being trained at dynamic range of 50 and reconfigured for the higher ranges. Appendix D shows that the same trend holds for the overall task accuracy.

## 6 Conclusion

This work revealed LLM's limitations in recognizing and executing arithmetic rules in abstract reasoning tasks, despite being provided disentangled prompts with ground-truth visual attributes and using advanced prompting techniques. We further showed the serious limitation on a larger (3\(\)10) RPM test. As a viable alternative, we presented a neuro-symbolic approach (ARLC) that achieves a high accuracy both on I-RAVEN and our I-RAVEN-X, thanks to learning to reason with distributed VSA representations and operators. We hope that our findings will lead to the development of architectures that aim to improve reasoning capabilities, e.g., by integrating symbolic solvers such as our ARLC into LLMs.

    &  &  &  &  &  \\  & per attribute (3\(\)queries) & & & & \\    & No & 100 & 98.0 & 91.6 & 27.1 \\    & Yes & 100 & 100 & 99.5 & 73.6 \\   & No & 100 & 97.2 & 99.3 & 31.0 \\  & Yes & 100 & 100 & 96.6 & 45.0 \\   

Table 4: Accuracy (%) of predicting the correct attribute value. Results are averaged across attributes.

    &  & Self-consistency &  &  &  \\  & per attribute (3\(\)queries) & & & & \\  Discriminative & & & & 56.0 & 22.8 \\ Discriminative & ✓ & & & 60.0 & 22.4 \\ Predictive & & & & 74.8 & 79.0 \\ Predictive & ✓ & & & 91.4 & 83.2 \\ Predictive & ✓ & ✓ & & **93.2** & 84.8 \\ Predictive & ✓ & & ✓ & 85.4 & 84.8 \\ Predictive & ✓ & ✓ & ✓ & 86.4 & **85.0** \\   

Table 3: Task accuracy (%) on the center constellation of I-RAVEN ablating various LLM prompting techniques.

    &  &  \\  &  &  \\   & 5–10 & 50 & 100 & 1000 \\  Llama-3 70B & 45.0 & 1.5 & 2.6 & 0.4 \\ GPT-4 & 73.6 & 30.4 & 25.1 & 8.4 \\ ARLC\({}_{}\) & 100.0 & 99.8 & 100.0 & 99.5 \\ ARLC\({}_{}\) & 99.5/99.2 & 99.1/95.5 & 98.9/96.3 & 97.9/95.3 \\   

Table 5: Arithmetic accuracy (%) on I-RAVEN and our novel I-RAVEN-X. The LLMs use self-consistency (n=7). For ARLC\({}_{}\) we report max/mean evaluation accuracies over 5 different training seeds.