# Quality and Diversity Both Matters When Merging Models

Anonymous submission

###### Abstract

Generalization to distribution shifts is a primary goal in modern machine learning literature. Ensemble methods, including both output-space ensemble and weight-space ensemble (model merging), are renowned for their robust generalization capabilities over multi-task settings, leveraging the diverse features from source models to improve cross-task transferability. While most studies on model merging focus on constructing diverse pools of task vectors obtained from foundation models trained on different tasks, we also emphasize the quality of each source. In this paper, we introduce a novel method for selectively merging task vectors to achieve superior generalization on target domains. Our approach uniquely considers both the diversity and quality of individual models. Using Determinantal Point Processes (DPP), we propose a probabilistic framework that optimally selects which models to average in a plug-and-play manner, ensuring a balanced consideration of quality and diversity. Theoretical support is provided for our hypothesis that this dual consideration yields a tighter generalization error bound for the unified model. Empirically, we present experiments in an out-of-distribution setting where there is significant violation in identically distributed conditions between the source and target domains.

## Introduction

In the modern era of machine learning, addressing the challenge of distribution shift is crucial, as the assumption of identical distribution between source and target domains may not hold in real-world scenarios. The importance of this issue is magnified in the context of large-scale, foundation models that are typically fine-tuned on diverse sources of datasets. A promising solution to this challenge is merging deep learning models together. Deep ensembles, which are combinations of diverse models, are known for their ability to generalize well on distribution shifts due to diverse features from the source models, enhancing the model's ability to transfer across various tasks. In practical settings, we already possess a variety of fine-tuned models with bless of foundation models and abundance of datasets. Therefore, selectively averaging weights based on quality and diversity in a training-free manner becomes essential.

In this paper, we introduce a novel method for selectively averaging neural networks to achieve solutions with superior generalization on target domains. Unlike existing methods, our approach explicitly considers both the diversity and quality of individual models. We propose a probabilistic framework that optimally selects models to average, ensuring a balanced consideration of both quality and diversity. We provide theoretical support for the hypothesis that considering both quality and diversity yields a tighter generalization error bound for the averaged model.

The contributions of this research are summarized as follows:

* We introduce a novel model merging strategy to exploit both the quality and diversity of source models.
* We provide a generalization error bound for ensemble classifier, supported by theoretical proof.
* Our method demonstrates superior performance in non-i.i.d. settings where the assumption of identical distribution in the source domain is violated.

## Preliminaries and Related Works

### Averaging Model Weights

Averaging the weights of models is a powerful approach in finding good solution in deep learning.  posits that averaging weights leads to wider optima in the loss surface, thereby enhancing generalization ability. By simply averaging multiple checkpoints during the training process, the solution tends to converge to flatter minima compared to the traditional Stochastic Gradient Descent solution. Diverse Weight Averaging for Out-of-Distribution (OOD) Generalization (DiWA)  averages weights obtained from independent training runs that share the same initialization, thereby increasing functional diversity across the averaged models. This work explains the success of weight averaging in OOD scenarios by highlighting the empirical similarity between weight averaging and output ensembling.

Due to the abundance of fine-tuned models and efficiency of foundation models, modern weight averaging methodologies utilize diverse fine-tuned models. Model Soup  averages diverse fine-tuned weights that vary across hyperparameter configurations yielding good generalization ability under distribution shift. Model Rata-toulike  recycles diverse fine-tuned models for OOD generalization. This approach aims to maximize weight diversity by leveraging the diversity in auxiliary tasks. It averages multiple weights fine-tuned from different initializations, each trained on different auxiliary tasks. The rationale for this ensemble's improved generalization in OOD scenarios is that fine-tunings of the same pre-trained foundation model are linearly connected in the loss landscape, despite different initializations, thus allowing successful averaging and yielding a flatter solution.

### Model Merging for Multi-Task Learning (MTL)

Recently, impressed by arithmetic of embedding vectors in language models, weight averaging has been extended to merging task vectors , which are obtained by subtracting pre-trained weight from task-specific fine-tuned weights. Such extension enabled semantic insights on MTL. Several approaches have extended the idea of merging task vectors using various heuristics, such as resolving interference due to redundant parameter values and aligning signs of weights , or preserving the important parameters defined via Fisher Information Matrix .  extended typical 8 computer vision classifications up to 20 tasks, while proposing novel heuristic by eliminating exclusively task-specific weights to improve general performance in MTL. To overcome its limitation in using equal merging coefficients,  introduced test time adaptation and layer-wise merging.  introduced MLP layer of Transformer to flexibly adapt to test tasks and its experiments extensively discussed the generalization and robustness capability of merging models in MTL.

### Determinantal Point Processes

Determinantal Point Processes (DPP) have gained considerable attention in the machine learning community due to their ability to model diversity and provide elegant solutions for subset selection problems. Originally introduced in the context of quantum physics, DPPs have since found applications in a variety of fields including computer vision , information retrieval , and recommendation systems . One of the pioneering works in applying DPPs to machine learning is done by , which provided a comprehensive framework for DPPs and demonstrated their effectiveness in diverse subset selection tasks.

Given a set of data \(=x_{1},,x_{N}\), a point process \(\) is a probability measure over the set of all subsets of \(\). \(\) is a DPP if a random subset \(\) sampled according to \(\) satisfies:

\[_{}(=Y)=_{Y})}{_{Y }(_{Y})}=_{Y})}{( +)}(_{Y})\]

The DPP kernel \(\) is characterized by a similarity matrix \(\), where \(S_{ij}\) defines the similarity between two items \((_{i},_{j})\).

## Methodology

### Notation

Let \(T\) represent the target or test domain and \(S\) represent the source or train domain. The distribution of the source domain is denoted as \(D_{S}=\{(x_{i},y_{i})\} S\). We define \(h\) as a sampled classifier or hypothesis, where \(h:\) and \(h f(x,_{m})\). Here, \(f\) is the labeling function (ground truth) parametrized by \(_{m}\).

The classification performance of \(h\) for a single data point \((x,y)\) is measured by \((h(x),y)\). The expected loss (risk function) over all data points for an arbitrary data distribution \(D\) is defined as \(_{D}(h)=_{(x,y) D}[(h(x),y)]\), assuming that \((h)\) is convex with a range of \(\).

The parameter or weight specifying each classifier \(h\) is denoted by \(\), thus \(h=h(;)\). Finally, \(\) represents the ensemble distribution, or ensemble strategy.

**Problem Setup** Given \(N\) (fine-tuned) models and source data, we aim to choose \(M\) models to generate ensemble that can generalize well on target domain \(T\).

### Generalization Error Bound

We suggest the generalization error bound of selectively merged neural network classifier as follows:

**Proposition 1**.: _Target risk of weight averaged model is bounded by source risk of individual models and diversity of softmax outputs._

\[_{T}(h_{})=_{T}(h_{})+O( ^{2})\] \[_{m=1}^{M}_{S_{m}}(_{m})- ()+d_{1}(D_{S},D_{T})++O(^{2})\]

* \(_{S_{m}}(_{m})\) _is source risk of_ \(m\)_-th model._
* \(()\) _is diversity of the ensemble of selected models._
* \(d_{1}(D_{S},D_{T})\) _is the divergence between source and target domain._
* \(\) _is the difference in labeling functions across the two domains._
* \(O(^{2})\) _is an approximation error between weight-space averaging and output-space averaging._

We start by approximating weight average \(h_{}\) with output ensemble \(h_{}\). Various researches on weight averaging including , , and  have shown the relationship between weight-space averaging and output-space averaging by employing Taylor expansion.

**Lemma 1**.: _Suppose we are given \(\{_{m}\}_{m=1}^{M}\) with \(M\) fine-tuned models. Denoting \(_{_{M}}=_{m}\|_{m}-_{}\|_{2}\), \((x,y)\):_

\[h_{}(x)=h_{}(x)+O(_{_{M}}^{2}),\] \[(h_{}(x),y)=(h_{}(x),y)+O(_{ _{M}}^{2}).\]

Then, according to , we bound target risk with respect to individual source risks and the divergence between two distributions. Here, the divergence and the constant \(\) is irreducible.

**Lemma 2**.: _For a ensemble classifier (hypothesis) \(h_{}\),_

\[_{T}(h_{})_{S}(h_{})+d_{1}(D_{S},D_{T})+,\]

\[=\{_{D_{S}}[|f_{S}(x)-f_{T}(x)|], _{D_{T}}[|f_{S}(x)-f_{T}(x)|]\}\]

[MISSING_PAGE_FAIL:3]

presents two-dimensional embeddings of eight datasets obtained from models fine-tuned on Figure 1(a) GTSRB and Figure 1(b) RESISC45. A notable trend is the similarity in embeddings between RESISC45 (brown) and SUN397 (pink), which largely overlap. The selection of SUN397 but not RESISC45 by DPP indicates that the heuristic effectively samples diverse subsets of tasks for merging.

## Conclusion and Future Works

In this work, we propose a training-free model merging framework that explicitly considers both the diversity and quality of source models. To the best of our knowledge, this is the first approach to incorporate the quality of source models--beyond merely the diversity of ensemble members--and to provide a generalization error bound for the merged solution. The framework is advantageous in its plug-and-play compatibility, enabling seamless application to existing methods.

We validate the effectiveness of our approach both theoretically and empirically. By deriving a generalization error bound and conducting experiments on image classification tasks, we demonstrate that merging diverse fine-tuned models (task vectors) of high quality leads to improved generalization ability. Furthermore, by strategically selecting models for averaging, our method achieves superior performance in generalization and robustness, even under non-i.i.d. settings where the assumption of identically distributed input data does not hold in the test domain.

Looking ahead, we aim to extend this framework to large language models, building upon the foundation laid by existing works in the domain of language foundation models. Additionally, there is potential to enhance diversity further by leveraging larger task pools, as suggested by . Future work will also seek to broaden the theoretical foundation by incorporating more intuitive measures for the generalization error bound, such as the flatness of the loss surface and the diversity of neural network weights, with connections to linear mode connectivity.