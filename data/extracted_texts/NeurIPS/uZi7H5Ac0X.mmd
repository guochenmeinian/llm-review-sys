# A Primal-Dual-Assisted Penalty Approach to Bilevel Optimization with Coupled Constraints

Liuyuan Jiang\({}^{}\), Quan Xiao\({}^{}\), Victor M. Tenorio\({}^{*}\), Fernando Real-Rojas\({}^{*}\)

Antonio G. Marques\({}^{*}\), Tianyi Chen\({}^{}\)

\({}^{}\)Rensselaer Polytechnic Institute, Troy, NY, United States

\({}^{*}\)King Juan Carlos University, Madrid, Spain

{jiang17, xiaoq5, chen18}@rpi.edu

{victor.tenorio, antonio.garcia.marques}@urjc.es; f.real.2018@alumnos.urjc.es

###### Abstract

Interest in bilevel optimization has grown in recent years, partially due to its applications to tackle challenging machine-learning problems. Several exciting recent works have been centered around developing efficient gradient-based algorithms that can solve bilevel optimization problems with provable guarantees. However, the existing literature mainly focuses on bilevel problems either without constraints, or featuring only simple constraints that do not couple variables across the upper and lower-levels, excluding a range of complex applications. Our paper studies this challenging but less explored scenario and develops a (fully) first-order algorithm, which we term **BLOCC**, to tackle **Bi**Level **O**ptimization problems with **C**oupled **C**onstraints. We establish rigorous convergence theory for the proposed algorithm and demonstrate its effectiveness on two well-known real-world applications - hyperparameter selection in support vector machine (SVM) and infrastructure planning in transportation networks using the real data from the city of Seville.

## 1 Introduction

Bilevel optimization (BLO) approaches are pertinent in various machine learning problems, including hyperparameter optimization , meta-learning , and reinforcement learning . Moreover, the ability to handle BLO with constraints is particularly important, as these constraints appear in applications such as pricing , transportation , and kernelized SVM . Although there is extensive research on BLO problems without constraints or with uncoupled constraints , solutions for BLO problems with coupled constraints (CCs) remain limited; see details in Table 1. However, it is of particular interest to investigate BLO with lower-level CCs. Taking infrastructure planning in a transportation network as an example, the lower-level seeks to optimize a utility constrained by the upper-level parameter, network configuration.

Motivated by this, we consider the coupled-constrained BLO problem in the following form

\[_{x}f(x,y_{g}^{*}(x))\] (1a) \[ y_{g}^{*}(x):=_{y(x)}g(x,y) (x):=\{y:g^{c}(x,y) 0\}\] (1b)

where \(f:^{d_{x}}^{d_{y}}\) is the upper-level objective, \(g:^{d_{x}}^{d_{y}}\) is the lower-levelobjective which is strongly convex, \(g^{c}(x,y):^{d_{x}}^{d_{y}}^{d_{c}}\) defines the lower-level CCs, and \(^{d_{x}},^{d_{y}}\) are the domain of \(x\) and \(y\) that are easy to project, such as the Euclidean ball.

The challenge in solving (1) arises from the coupling of the upper and lower-level problems. Prior work addressed this by starting with the unconstrained BLO problem, using implicit gradient descent (IGD) methods  and penalty-based methods . To solve BLO with CCs, AiPOD  and GAM  investigated the IGD method under different constraint settings. However, AiPOD only considered equality constraints, and GAM lacked finite-time convergence guarantees. Leveraging a penalty reformulation,  developed a Hessian-free method with finite-time convergence. However, a key algorithm step in  is a joint projection of the current iterate \((x,y)\) onto the coupled constraint set. This projection, required at each iteration, becomes particularly challenging when \(g^{c}(x,y)\) is not jointly convex and can be computationally expensive for large-scale problems with a high number of variables (\(d_{x},d_{y}\)) or constraints (\(d_{c}\)).

To this end, this paper aims to address the following question

_Can we develop an efficient algorithm that bypasses joint projections on \(g^{c}(x,y)\) and quickly solves the BLO problem with coupled inequality constraints in (1)?_

We address this question affirmatively, focusing on the setting where the lower-level objective, \(g(x,y)\), is strongly convex in \(y\), and the constraints \(g^{c}(x,y)\) are convex in \(y\). To avoid implementing a joint projection, we put forth a novel single-level primal-dual-assisted penalty reformulation that decouples \(x\) and \(y\). Specifically, with \(^{d_{c}}\) denoting the Lagrange multiplier of (1b), we propose solving

\[_{x}\ \ F_{}(x):=_{^{d_{x}}_{+}} _{y}f(x,y)+_{}+ (x,y)}_{}\] (2a) \[ v(x):=_{y(x)}g(x,y)\] (2b)

where the penalty constant \(\) controls the distance between \(y\) and \(y^{*}_{g}(x)\) by penalizing \(g(x,y)\) to its value function \(v(x)\), and the Lagrangian term penalizes the constraint violation of \(g^{c}(x,y)\).

However, recognizing the max-min subproblems involved in (2a), it becomes computationally costly to evaluate the penalty function \(F_{}(x)\) and its gradient. To this end, we pose the following question

_Can we develop efficient algorithms to solve the max-min subproblem and evaluate \( F_{}(x)\)?_

We answer this question by proving that this reformulation exhibits several favorable properties, including smoothness. These properties are critical for designing gradient-based algorithms and characterizing their performance. However, the presence of the CCs renders the calculation of the gradient \( F_{}(x)\) more challenging than for its unconstrained counterpart . Building upon this, we design a primal-dual gradient method with rigorous convergence guarantees for the BLO with general inequality CCs, and provide an improved result for the case of \(g^{c}\) being affine in \(y\).

### Main contributions

In a nutshell, our main contributions are outlined below.

* In Section 2, leveraging the Lagrangian duality theorem, we introduce the function \(F_{}(x)\) in (2a) as a penalty-based reformulation of (1), establish the continuity and smoothness of \(F_{}(x)\), and develop a novel way to compute its gradient.
* In Section 3, we develop BLOCC, a fully first-order algorithm to tackle BLO problems with CCs. With \(\) being the target error for the generalized gradient norm square of \(F_{}(x)\), we establish that the iteration complexity under the generic constraint \(g^{c}(x,y)\) in (1b) is \(}(^{-2.5})\). We establish, for the first time, the linear convergence of a strongly convex-concave max-min problem with linear interaction and a constrained maximization parameter, reducing BLOCC's complexity to \(}(^{-1.5})\) when the constraint \(g^{c}(x,y)\) is affine in \(y\).
* In Section 4, we apply our BLOCC algorithm to two real-world applications: SVM model training and transportation network planning. By comparison with LV-HBA  and GAM , we demonstrate the algorithm's effectiveness and its robustness to large-scale problems.

### Related works

BLO has a long history, dating back to the seminal work of . It has inspired a rich body of literature, e.g., [76; 68; 14; 65]. The recent focus on BLO is centered on developing efficient gradient-based approaches with provable finite-time guarantees.

**Methods for BLO without constraints.** A cluster of BLO gradient-based approaches gravitates around the implicit gradient descent (IGD) method , where the key idea is to approximate the hypergradient by the implicit function theorem. The finite-time convergence of IGD was first established in  for unconstrained strongly-convex lower-level problems. Subsequent works improved the convergence rates and/or relaxed the assumptions under various settings; see [31; 34; 12; 13; 40; 61; 43; 66; 73; 35; 70]. Another cluster of works is based on iterative differentiation (ITD) [49; 23; 53; 60], which estimates the hypergradient by differentiating the entire iterative algorithm used to solve the lower-level problem with respect to the upper-level variables. The finite-time guarantee was first established in [28; 47; 33; 6]. Viewing the lower-level problem as a constraint such as in , penalty-based methods have also emerged as a promising approach for BLO. Dated back to , this line of works [45; 51; 44; 41; 62; 25; 48] reformulated the original BLO as the single-level problems with various penalty terms and leveraged first-order methods to solve them.

**BLO with constraints.** While substantial progress has been made for unconstrained BLO, the analysis for constrained BLO is more limited. Upper-level constraints of the form \(x\) were considered in [31; 12]. For the lower-level uncoupled constraint, SIGD  considered the uncoupled constraint \(Ay b\) and achieved asymptotic convergence, [42; 62] employed penalty reformulation and considered both upper and lower uncoupled constraints. However, the literature on **BLO with CCs** is scarce. BVFSM  conducted a penalty-based method to avoid the calculation of the Hessian, as IGD methods do. However, only asymptotic convergence was achieved. GAM  investigated the IGD method under inequality constraints while failing to provide finite-time convergence results as well. AiPOD  also applied IGD and successfully achieved finite-time convergence, but it only considered equality constraints. LV-HBA  considered inequality constraints and constructed a penalty-based reformulation. However, it employed a joint projection of \((x,y)\) onto \(\{:g^{c}(x,y) 0\}\) which is computationally inefficient when there are many constraints or when \(g^{c}(x,y)\) is not jointly convex. After our initial submission, we found a concurrent work  posted on ArXiv, which used Lagrange duality theory differently from ours, applying it to construct a new smoothed penalty term. However, it does not quantify the relationship between the relaxation of this penalty and the relaxation of lower-level optimality, and it does not guarantee lower-level feasibility. We summarized prior works on BLO with lower-level CCs in Table 1.

## 2 Primal-dual Penalty-based Reformulation

In this section, our goal is to construct a primal-dual-assisted penalty reformulation for our BLOCC problem. The technical challenge comes from finding a suitable penalty function for BLO with CCs.

### The challenges in BLO with coupled constraints

Here, we will elaborate on the two technical challenges of BLO with CCs.

The _first challenge_ associated with the presence of CCs is the difficulty to find the descent direction for \(x\), which involves finding the closed-form expression of the gradient \( v(x)\). The expression without CCs, \( v(x)=_{x}g(x,y_{g}^{*}(x))\) provided in [62; 42; 41; 44], is not applicable.

    & LL constraint & First Order & Complexity \\ 
**BLOCC** & \(g^{c}(x,y) 0\) convex in \(y\) and LICQ holds; & ✓ & \((^{-2.5})\); \\  & Special case: \(g^{c}(x,y)\) affine in \(y\) & & \((^{-1.5})\) \\  LV-HBA & \(g^{c}(x,y) 0\) convex in \(x y\) & ✓ & \((^{-3})\) \\  GAM & \(g^{c}(x,y) 0\) convex in \(x y\) and LICQ holds & ✗ & ✗ \\  BVFSM & \(g^{c}(x,y) 0\) satisfying other requirements & ✓ & ✗ \\  AiPOD & \(g^{c}(x,y)=Ay-b(x)=0\) & ✗ & \((^{-1.5})\) \\   

Table 1: Comparison of our work with LV-HBA , BVFSM , AiPOD , and Gradient Approximation method (GAM) . LL convergence is on metric the squared distance of \(y_{t}\) to its optimal solution, and UL convergence is on squared (generalized) gradient norm.

For example, when \(g(x,y)=(y-2x)^{2}\) and \(g^{c}(x,y)=3x-y\), the optimal lower-level solution is \(y_{g}^{*}(x)=3x\) and thus, \(v(x)=x^{2}\) with \( v(x)=2x\). However, \(_{x}g(x,y_{g}^{*}(x))=-4x v(x)\). The closed form gradient for BLO with CCs should be (8), which considers a Lagrange term that will be illustrated later in this paper. In Figure 1, we present the gradient \( v(x)\) without the Lagrange multiplier in  and ours with the Lagrange term. In this example, the gradient without the Lagrange term leads to the opposite direction to the true gradient.

The _second challenge_ associated with the presence of CCs is the difficulty of performing the joint projection. If we directly extend the penalty reformulation in , we could treat the coupling constraint set \((x)\) as a joint constraint \(\{(x,y):g^{c}(x,y) 0\}\), and employ a joint projection of \((x,y)\) to ensure the feasibility. However, this can be computationally inefficient when the problem is large-scale, i.e. the number of variables or constraints is large. The detailed analysis of computational cost can be seen in Appendix H. Moreover, when \(g^{c}(x,y)\) is complex, the projection may not have a closed form and may not even be well-defined if \(g^{c}(x,y)\) is not jointly convex.

### The Lagrangian duality-based penalty reformulation

Before proceeding, we summarize the assumptions considered as follows.

**Assumption 1** (Lipschitz Continuity).: _Assume that \(f\), \( f\), \( g\), \(g^{c}\) and \( g^{c}\), and are respectively \(l_{f,0}\), \(l_{f,1}\), \(l_{g,1}\), \(l_{g^{c},0}\), and \(l_{g^{c},1}\)-Lipschitz jointly over \((x,y)\), and \(g\) is \(l_{g_{x},0}\)-Lipschitz in \(x\)._

**Assumption 2** (Convexity in \(y\)).: _For any given \(x\), \(g(x,y)\) and \(g^{c}(x,y)\) are \(_{g}\)-strongly convex and convex in \(y\), respectively._

**Assumption 3** (Domain Feasibility).: _Domain \(^{d_{x}}\) and \(^{d_{y}}\) are non-empty, closed, and convex. For any given \(x\), \((x):=\{y:g^{c}(x,y) 0\}\) is non-empty._

**Assumption 4** (Constraint Qualification).: _For any given \(x\), \(g^{c}\) satisfies the Linear Independence Constraint Qualification (LICQ) condition for every \(y\) in a neighborhood of \(y_{g}^{*}(x)\)._

The Lipschitz continuity in Assumption 1 and the strong convexity of \(g\) over \(y\) in Assumption 2 are conventional . Moreover, we only require \(g^{c}(x,y)\) to be convex in \(y\) rather than: i) jointly convex in \((x,y)\) as in , or ii) linear as in . Assumption 3 pertains to the convexity and closeness of the domain, which is also conventional, and Assumption 4 is a standard constraint qualification condition.

To build a penalty reformulation for BLO with lower-level CCs, the first challenge is to find a penalty that regulates \(\|y-y_{g}^{*}(x)\|\). In the following lemma, we show that \(g(x,y)-v(x)\) is a good choice.

**Lemma 1**.: _Suppose that Assumptions 2-4 hold and \(v(x)\) is defined as in (2b). Then, it holds that_

* \(g(x,y)-v(x)^{{}^{}}}{2}\|y-y_{g}^{*}(x)\|^{2}\)_, for some_ \(_{g}^{}>0\)_, for all_ \(y(x)\)_; and_
* \(g(x,y)=v(x)\) _if and only if_ \(y=y_{g}^{*}(x)\)_, for all_ \(y(x)\)_._

The technical challenge of proving this lemma lies in showing the quadratic growth property as in c1) of Lemma 1. For BLO without the CCs, this naturally holds as the lower-level objective \(g(x,y)\) is strongly convex in \(y\). For BLO with CCs, one needs to use the Lagrangian duality theorem. The full proof of Lemma 1 is given in Appendix B.1, where the key challenge is to show the invariance of the modulus of strong convexity in the Lagrangian reformulated lower-level objective.

With \(\) denoting a penalty constant, we consider the following penalty reformulation:

\[_{(x,y)\{:g^{c}(x,y) 0\}}f(x,y)+ (g(x,y)-v(x))\] (3)

where the penalty term confines the squared Euclidean distance from \(y\) to \(y_{g}^{*}(x)\). Furthermore, to avoid projecting \((x,y)\) onto the \(\{:g^{c}(x,y) 0\}\), we propose the primal-dual-assisted penalty

Figure 1: Calculation of \( v(x)\). The blue line is \(v(x)\), the the yellow dashed line is calculated by the formulation given in , while red dashed line is derived by our BLOCC. It can be seen that \( v(x)\) without the Lagrange multiplier is very biased from the true gradient.

reformulation, which was defined in (2). The approximate equivalence of the reformulation (2) to the original BLO problem (1) is established in the following theorem.

**Theorem 1** (Equivalence).: _Suppose that \(f\) is Lipschitz in \(y\) and \( f\) is \(l_{f,1}\)-Lipschitz in \((x,y)\) in Assumption 1 hold, and Assumptions 2-4 hold. Then, solving the \(\)-approximation problem of (1):_

\[_{(x,y)\{:g^{c}(x,y) 0\}}f(x,y) \|y-y_{g}^{*}(x)\|^{2},\] (4)

_is equivalent to solve the primal-dual penalty reformulation in (2) with \(=(^{-0.5})\) and \(>}{_{g}}\)._

The detailed proof is provided in Appendix B.2. By setting \(=(^{-0.5})\), we effectively state the equivalence between the penalty reformulation in (3) and the approximated original problem (4). We can then decouple the joint minimization on \((x,y)\) to a min-min problem on \(x\) and \(g^{c}\) constrained \(y\). For the inner minimization problem in \(y\), we choose \(\) in a way that \(_{g}-l_{f,1}>0\) holds. This ensures the objective in (2a) being strongly convex in \(y\), as \(l_{f,1}\)-smoothness ensures a lower bound for negative curvature of \(f(x,y)\). Furthermore, the convexity of \(g^{c}(x,y)\) in \(y\) validates the strong duality theorem in , thereby enabling the max-min primal-dual reformulation in (2).

### Smoothness of the penalty reformulation

To evaluate \(F_{}(x)\) defined in (2a), we can find the solution to the inner max-min problem:

\[(_{F}^{*}(x),y_{F}^{*}(x)):=_{_{+}^{dx}}_{y }(x,y) }_{=:L_{F}(,y;x)}.\] (5)

The uniqueness of \(y_{F}^{*}(x)\) and \(_{F}^{*}(x)\) is guaranteed under Assumptions 2 and 4 (see Lemma 5 in Appendix A). Therefore, \(F_{}(x)\) in (2a) can be evaluated using the unique optimal solutions by

\[F_{}(x)=L_{F}(_{F}^{*}(x),y_{F}^{*}(x);x).\] (6)

Similarly, we can evaluate \(v(x)=L_{g}(_{g}^{*}(x),y_{g}^{*}(x);x)\), where

\[(_{g}^{*}(x),y_{g}^{*}(x)):=_{_{+}^{dx}}_{y }(x,y)}_{=:L_{g}(,y;x )}.\] (7)

The penalty reformulation \(F_{}(x)\) can hardly be convex, as \(-v(x)\) may be concave, even when \(g(x,y)=g(y)\) and \(g^{c}(x,y)=A^{}y-x\); see Lemma 4.24 in . Instead, in the subsequent lemma, we not only show that \(v(x)\) is differentiable, but also provide a closed-form expression of \( v(x)\).

**Lemma 2** (Danskin-like theorem for \(v(x)\)).: _Suppose that Assumptions 1-4 hold, and let \(B_{g}<\) be a constant such that \(\|_{g}^{*}(x)\|<B_{g}\) for all \(x\). Then, it holds that_

_1. \(y_{g}^{*}(x)\) and \(_{g}^{*}(x)\) defined in (7) are \(L_{g}\)-Lipschitz for some finite constant \(L_{g} 0\)._

_2. \(v(x)\) defined in (2b) is \(l_{v,1}\)-smooth where \(l_{v,1}(l_{g,1}+B_{g}l_{g^{c},1})(1+L_{g})+l_{g^{c},0}L_{g}\) and_

\[ v(x)=_{x}g(x,y_{g}^{*}(x))+_{g}^{*}(x),_{x}g^{c} (x,y_{g}^{*}(x)).\] (8)

The assumption of the existence of the upper bound for the Lagrange multiplier is a consequence of the LICQ condition [69, Theorem 1]. This assumption is mild and traditional . Finding \( v(x)\) is crucial for the design of a gradient-based method to solve \(_{x}F_{}(x)\). Leveraging Lemma 2, the gradient \( F_{}(x)\) can be obtained by the next lemma.

**Lemma 3** (Danskin-like theorem for \(F_{}(x)\)).: _Suppose that the conditions in Lemma 2 hold. Moreover, assume that \(>}{_{g}}\), and there exist \(B_{F}\!<\!\) such that \(\|_{F}^{*}(x)\|\!<\!B_{F},\, x\). Then, it holds that_

_1. \(y_{F}^{*}(x)\) and \(_{F}^{*}(x)\) defined in (5) are \(L_{F}\)-Lipschitz for some constant \(L_{F} 0\)._

_2. \(F_{}(x)\) is \(l_{F,1}\)-smooth with \(l_{F,1}(l_{f,1}+ l_{g,1}+B_{F}l_{g^{c},1})(1+L_{F})+ l_{v,1}+l_{f ^{c},0}L_{F}\), and_

\[ F_{}(x)=_{x}f(x,y_{F}^{*}(x))+(_{x}g(x,y_{F }^{*}(x))- v(x))+_{F}^{*}(x),_{x}g^{c}(x,y_{F}^{*} (x)).\] (9)

The proof of Lemmas 2 and 3 is provided in Appendix C. Similar to , the Danskin-like theorems in Lemmas 2 and 3 rely on the Lipschitzness of the solutions in (5) and (7). Different from BLO without CCs , the results here also hinge on the Lagrange multipliers \(_{g}^{*}(x)\) and \(_{F}^{*}(x)\).

Main Results

We will first introduce an algorithm tailored for **BiL**evel **O**ptimization problems with inequality **C**oupled **C**onstraints, and present its convergence analysis. In Section 3.2, we will propose a primal-dual solver for the inner max-min problems and characterize the overall convergence.

### BLOCC algorithm

As \(F_{}(x)\) features differentiability and smoothness, we can apply a projected gradient descent (PGD)-based method to solve \(_{x}F_{}(x)\). At iteration \(t\), update

\[x_{t+1}=_{}(x_{t}- g_{F,t})\] (10)

with stepsize \(\) and \(g_{F,t}\) as an estimate of \( F_{}(x_{t})\).

In the previous section, we have obtained the closed-form expressions of \( v(x)\) in (8) and \( F_{}(x)\) in (9). Evaluating the closed-form expression requires finding \((y^{*}_{g}(x_{t}),^{*}_{g}(x_{t}))\) and \((y^{*}_{F}(x_{t}),^{*}_{F}(x_{t}))\), the solutions to the max-min problem \(L_{g}(,y;x)\) in (7) and \(L_{F}(,y;x)\) in (5) respectively.

Given \(x_{t}\), we can use some minmax optimization solvers with \(T_{g}\) iterations on (7) and \(T_{F}\) iterations on (5) to find an \(_{g}\)-solution \((y^{T_{g}}_{g,t},^{T_{g}}_{g,t})\) and an \(_{F}\)-solution \((y^{T_{F}}_{F,t},^{T_{F}}_{F,t})\) satisfying

\[\|(y^{T_{g}}_{g,t},^{T_{g}}_{g,t})-(y^{*}_{g}(x_{t}),^{*}_{g}(x_{t}))\|^ {2}=(_{g});\|(y^{T_{F}}_{F,t},^{T_{F}}_{F,t})-(y^{* }_{F}(x_{t}),^{*}_{F}(x_{t}))\|^{2}=(_{F})\] (11)

for target estimation accuracy \(_{g},_{F}>0\). Such an effective minmax optimization solver will be introduced in the following Section 3.2. In this way, \( v(x_{t})\) in (9) can be estimated as

\[g_{v,t}=_{x}g(x_{t},y^{T_{g}}_{g,t})+^{T_{g}}_{g,t},_{x} g^{c}(x_{t},y^{T_{g}}_{g,t}).\] (12)

Leveraging \(g_{v,t}\), the gradient \( F_{}(x)\) can be estimated via (8) as

\[g_{F,t}=_{x}f(x_{t},y^{T_{F}}_{F,t})+(_{x}g(x_{t},y^{T_ {F}}_{F,t})-g_{v,t})+^{T_{F}}_{F},_{x}g^{c}(x,y^{T_{F}}_ {F,t}).\] (13)

We summarize the oracle for finding \( F_{}(x)\) as in Algorithm 1, which we term BLOCC, an algorithm designed for BiLevel Optimization with Coupled Constraints. Notably, our BLOCC algorithm can be seamlessly integrated with any MaxMin Solver (or min-max solver) that converges to the optimal solutions of the max-min subproblems by achieving (11). In the following, we present the convergence result of it allowing estimation error \(_{g},_{F}>0\) from the MaxMin Solver.

```
1:inputs: initial points \(x_{0},y_{g,0},_{g,0},y_{F,0}\), \(_{F,0}\); stepsize \(\), \(_{g}\), \(_{F}\); counters \(T_{g}\), \(T_{F}\).
2:for\(t=0,1,,T\)do
3:\((y^{T_{g}}_{g,t},^{T_{g}}_{g,t})=(T_{g},T^{g}_{g})\)
4:\((y^{T_{F}}_{F,t},^{T_{F}}_{F,t})=(T_{F},T^{F}_{g})\)
5: update \(x_{t+1}\) via (10) \(\) with \(g_{F,t}\) in (13)
6:endfor
7:outputs:\((x_{T},y^{T_{F}}_{F,T})\) ```

**Algorithm 1** Meta algorithm: BLOCC

**Theorem 2**.: _Suppose that the assumptions in Lemma 3 hold. Run Algorithm 1 with some effective inner MaxMin solver to find \((y^{T_{g}}_{g,t},^{T_{g}}_{g,t})\) and \((y^{T_{F}}_{F,t},^{T_{F}}_{F,t})\) respectively \((_{g})\) and \((_{F})\)-optimal in squared distance as in (11). Set \(}\) with some \(l_{F,1}\) defined in Lemma 3. It then holds that_

\[_{t=0}^{T-1}\|G_{}(x_{t})\|^{2}:=}_{t= 0}^{T-1}\|(x_{t+1}-x_{t})\|^{2}= ( T^{-1}+^{2}_{F}+^{2}_{g}).\] (14)

The proof is available in Appendix D.1. Using the projected gradient \(G_{}=^{-1}(x_{t+1}-x_{t})\) as the convergence metric for constrained optimization problems is standard . The term \((^{2}_{F}+^{2}_{g})\) arises from estimation errors using specific MaxMin Solver. Although the inner oracle can be any one that achieves (11), we value the computational effectiveness and therefore present a particular efficient solver Algorithm 2 in the following section.

### MaxMin Solver for the BLO with inequality CCs

In this section, we specify the MaxMin solver in Algorithm 1. By viewing \(L_{g}(,y;x)\) in (7) and \(L_{F}(,y;x)\) in (5) as \(L(,y)\) for fixed given \(x\), we consider the following max-min problem

\[_{^{d_{c}}_{+}}_{y}L(,y)\] (15)which is concave (linear) in \(\) and strongly convex in \(y\). We can evaluate the dual function of \(L(,y)\) defined below by finding \(y_{}^{*}()\).

\[D():= _{y}L(,y)=L(,y_{}^{*}())\] (16) \[ y_{}^{*}():=_{y}L( ,y).\]

According to Danskin's theorem, we have \( D()=_{}L(,y_{}^{*}())\). Taking either \(L_{g}(,y;x)\) or \(L_{F}(,y;x)\) as \(L(,y)\) for given \(x\), \(D()\) defined as (16) exhibits favorable properties namely smoothness and concavity, with details illustrated in Lemma 10 in Appendix D.2. We can, therefore, apply accelerated gradient methods designed for smooth and convex functions such as .

At each iteration \(t\), we first perform a momentum-based update step to update \(_{t+}\) as

\[_{t+}=_{t}+(_{t}-_{t-1}), _{-1}=_{0}.\] (17)

To evaluate \( D(_{t+})=_{}L(_{t+},y_{}^{*}( _{t+})\), with an arbitrary small target accuracy \(>0\), we can run \(T_{y}=((^{-1}))\) PGD steps on \(L(_{t+},y)\) in \(y\) via

\[y_{t,t_{y}+1}=_{}(y_{t,t_{y}}- _{1}_{y}L(_{t+},y_{t,t_{y}})).\] (18)

Defining the output after \(T_{y}\) iterations as \(y_{t+1}\), since strongly convexity of \(L(,)\) ensures that PGD converges linearly [9, Theorem 3.10], it implies that \(\|y_{t+1}-y_{}^{*}(_{t+})\|=()\). We can conduct

\[_{t+1}=_{_{+}^{d_{c}}}(_{t+ }+_{2}_{}L(_{t+},y_{t+1})).\] (19)

We summarize this oracle in Algorithm 2 based on an accelerated method . When we skip the momentum update, i.e. setting \(_{t+}=_{t}\), it is a simple PGD method on \(D()\).

```
1:inputs: initial points \(y_{0}\), \(_{0}\); stepsizes \(_{1},_{2}\); counters \(T,T_{y}\). Blue part is the version with acceleration; and red part is without.
2:for\(t=0,,T-1\)do
3: update \(_{t+}\) via (17) or \(_{t+}=_{t}\)
4:for\(t_{y}=0,,T_{y}-1\)do
5: update \(y_{t,t_{y}+1}\) via (18) \(\) set \(y_{t,0}=y_{t}\)
6:endfor
7: update \(_{t+1}\) via (19) \(\) set \(y_{t+1}=y_{t,T_{y}}\)
8:endfor
9:outputs:\((y_{T},_{T})\) ```

**Algorithm 2** Subroutine on \((T,T_{y})\)

However, for a convex function \(-D()\), the standard results only provide convergence of the function value, i.e. \(_{_{+}^{d_{c}}}D()-D(_{t})}{{}}0\). To establish the convergence of \(\|_{g,t}^{T_{g}}-_{g}^{*}(x_{t})\|\) and \(\|_{F,t}^{T_{F}}-_{F}^{*}(x_{t})\|\), we define the dual functions associated with inner problems (7) and (5) as

\[D_{g}()=_{y}L_{g}(,y;x) D_{F}()=_{y}L_{F}(,y;x)\] (20)

and make the following curvature assumption near the optimum.

**Assumption 5**.: _There exist \(_{g},_{F}>0\) and \(C_{_{g}},C_{_{F}}>0\) such that_

\[- D_{g}()+ D_{g}(_{g}^{*}(x)),-_{g }^{*}(x) C_{_{g}}\|-_{g}^{*}(x)\|^{2}, (_{g}^{*}(x);_{g}),\] (21a) \[- D_{F}()+ D_{F}(_{F}^{*}(x)),-_{F }^{*}(x) C_{_{F}}\|-_{F}^{*}(x)\|^{2}, (_{F}^{*}(x);_{F}).\] (21b)

It is worth noting that \(- D_{g}()+ D_{g}(_{g}^{*}(x)),-_{g}^{*}(x)\) 0 holds for all \(\) due to concavity and in a neighborhood of the optimal, the equality only happens at the optimal due to the uniqueness of \(_{g}^{*}(x)\). The same argument applies to \(D_{F}\) due to the concavity of the dual functions. Therefore, Assumption 5 essentially asserts a positive lower bound on the curvature of the left-hand side term, which is mild as it only applies to the neighborhood of the optima \(_{g}^{*}(x)\) and \(_{F}^{*}(x)\). It is also weaker than the local strong concavity or global restricted secant inequality (RSI) conditions.

By choosing Algorithm 2 with acceleration as the \(\) solver, we provide the convergence analysis of Algorithm 1 next, the proof of which can be found in Appendix D.2.

**Theorem 3**.: _Suppose that Assumptions 1-5 and the conditions in Theorem 2 hold. Let \(>}{_{g}}\), \(_{g}}}{2}_{g}\) and \(_{F}}}{2}_{F}\). If we choose Algorithm 2 with acceleration as the inner loop and input \(T_{g}=(_{g}^{-0.5}),T_{F}=(_{F}^{-0.5})\), and \(T_{y}^{g}=((_{g}^{-1})),T_{y}^{F}=((_{ F}^{-1}))\) with proper constant stepsizes in Remark 3, then the iterates generated by the Algorithm 1 satisfy (11):_

\[\|(y_{g,t}^{T_{g}},_{g,t}^{T_{g}})-(y_{g}^{*}(x_{t}),_{g}^{*}(x_{t}))\|^{2} =(_{g});\ \ \|(y_{F,t}^{T_{p}},_{F,t}^{T_{F}})-(y_{F}^{*}(x_{t}),_{F}^{*}(x_{t}))\|^{2}= (_{F}).\]Theorem 3 concludes the \((_{g}^{-0.5})\) complexity for achieving \(_{g}\)-optimal solutions for the constrained concave-strongly-convex problem \(_{_{+}^{d_{x}}}_{y}L(,y)\), and so as for \(_{F}\). For solving an \(\)-approximation problem of BLO defined in (4), we solve \(_{x}F_{}(x)\) with \(=(^{-0.5})\) according to Theorem 1. In this way, to achieve \(_{t=0}^{T-1}\|G_{}(x_{t})\|^{2}=( T^{-1}+ ^{2}_{F}+^{2}_{g})\) by (14), we need \(_{g},_{F}=(^{2})\), i.e. complexity \(}(^{-1})\) for the MaxMin solver in Algorithm 2, and \(T=(^{-1})=(^{-1.5})\) for the number of iteration in BLOCC (Algorithm 1). Therefore, the overall complexity is \(}(^{-2.5})\), where \(}\) omits the \(\) terms.

Special case of the MaxMin Solver: \(g^{c}(x,y)\) being affine in \(y\) and \(=^{d_{y}}\)

In this section, we investigate a special case of BLO with CCs where Assumption 5 automatically holds. Specifically, we focus on the case where \(g^{c}\) is affine in \(y\) and \(=^{d_{y}}\), i.e.

\[g^{c}(x,y)=g_{1}^{c}(x)^{}y-g_{2}^{c}(x).\] (22)

In this case, fixing \(x\), taking \(L_{g}(,y;x)\) in (7) and \(L_{F}(,y;x)\) as \(L(,y)\), (16) gives

\[D_{g}()= _{y^{d_{y}}}- g_{2}^{c}(x),+  y,g_{1}^{c}(x)+g(x,y)\] (23a) \[D_{F}()= _{y^{d_{y}}}- g_{2}^{c}(x),+  y,g_{1}^{c}(x)+f(x,y)+(g(x,y)-v(x)).\] (23b)

When \(g_{1}^{c}(x)\) is of full column rank, both \(D_{g}()\) and \(D_{F}()\) are strongly concave according to Lemma 13 in Appendix so that Assumption 5 holds globally. Moreover, when applying PGD on \(-D_{g}()\) and \(-D_{F}()\), strongly convexity guarantees linear convergence (Theorem 3.10 in ). Therefore, even without acceleration, Algorithm 2 with \(T_{y}\) sufficiently large performs PGD on \(-D()\) and it converges linearly up to inner loop accuracy. Moreover, PGD on \(L(,y)\) in \(y\) also converges linearly. This motivates us to implement a single-loop version (\(T_{y}=1\)) of Algorithm 2.

When both \(y\) and \(\) are unconstrained, the analysis has been established in . However, as \(\) is constrained to \(_{+}^{d_{e}}\) in the Lagrangian formulation for inequality constraints, the convergence analysis in  is not applicable, and the extension is nontrivial due to the non-differentiability of the projection. We address this technical challenge by treating \(_{+}^{d_{e}}\) as an inequality constraint and reformulating it as an unconstrained problem using Lagrange duality theory. This approach demonstrates that a single-loop \(T_{y}=1\) update in Algorithm 2, without acceleration, achieves linear convergence for the max-min problem (15). The detailed proof is provided in Appendix D.3.

Thus, by selecting the single-loop version (\(T_{y}=1\)) of Algorithm 2 without acceleration as the MaxMin solver in Algorithm 1, we establish the following theorem with proof available in Appendix D.3.

**Theorem 4** (Inner linear convergence).: _Consider BLO with \(=^{d_{y}}\) and \(g^{c}(x,y)\) defined in (22). Suppose Assumptions 1-4 and the conditions in Theorem 2 hold. Suppose for any \(x\), there exist constants \(s_{}\) and \(s_{}\) such that \(0<s_{}_{}(g_{1}^{c}(x))_{}(g_{1}^{c}(x)) s _{}<\). Let \(>}{_{g}}\). If we choose Algorithm 2 without acceleration as the inner loop and input \(T_{g}=(_{g}^{-1}),T_{F}=( _{F}^{-1})\), and \(T_{y}^{g}=T_{y}^{F}=1\) with proper constant stepsizes in Remark 4, then the iterates generated by Algorithm 1 satisfy (11):_

\[\|(y_{g,t}^{T_{g}},_{g,t}^{T_{g}})-(y_{g}^{*}(x_{t}),_{g}^{*}(x_{t}))\|^{ 2}=(_{g});\|(y_{F,t}^{T_{g}},_{F,t}^{T_{F}})-(y_{F} ^{*}(x_{t}),_{F}^{*}(x_{t}))\|^{2}=(_{F}).\]

Theorem 4 establishes, for the first time, the linear convergence of a strongly convex-concave maxim problem with a constrained maximization parameter. Similar to the previous analysis, we choose \(=(^{-0.5})\) to solve the equivalent (2a) to \(\)-approximation problem of BLO (4). To achieve \(_{t=0}^{T-1}\|G_{}(x_{t})\|^{2}\), the number of iteration in BLOCC \(T=(^{-1})=(^{-1.5})\) by (14). As the inner MaxMin solver convergences linearly, the overall complexity is \(}(^{-1.5})\) where \(}\) omits the \(\) terms. We summarized the overall iteration complexity of our BLOCC algorithm in different settings in Table 1.

## 4 Numerical Experiments

This section reports the results of numerical experiments for three different problems: a toy example used to validate our method, an SVM training application, and a network design problem in both synthetic and real-world transportation scenarios. We provide sensitivity analysis and insights for hyper-parameter choices in Appendix G.1. In the two real-world experiments, we compare the proposed algorithm with two baselines, LV-HBA  and GAM . The code is available at https://github.com/Liuyuan999/Penalty_Based_Lagrangian_Bilevel.

### Toy example

Consider the BLO problem with an inequality coupled constraint \((x):=\{y:y-x 0\}\), given by

\[_{x} f(x,y_{g}^{*}(x))=^{*}(x)+2}}{2+(6x)}+ (4x-2)^{2}+1\] \[ y_{g}^{*}(x)_{y(x)}\ g(x,y)=(y-2x)^{2}.\] (24)

Problem (24) satisfies all assumptions for Theorem 2 and Theorem 4. The lower-level problem is strongly convex and \(y_{g}^{*}(x)=x\). Therefore, the BLO problem with inequality constraint in (24) reduces to \(_{x}f(x,y)|_{y=x}\). In Figure 2, we plot the dashed line as the intersected line of the surface \(f(x,y)\) and the plane \(f(x,y_{g}^{*}(x))\), and the red points as the converged points by running BLOCC with \(=5\) and with 200 different initialization values. It can be seen that BLOCC consistently finds the local minima, verifying the effectiveness.

### Hyperparameter optimization for SVM

We test the performance of our algorithm BLOCC with \(=12\) when training a linear SVM model on the diabetes  and four-class datasets . The model is trained via the BLO formulation (1) with inequality CCs; see the details in Appendix E. We compared performance with two baselines, LV-HBA  and GAM , as they are the only existing algorithms addressing coupled constraints and experimentally evaluated on SVM problems in their respective papers.

Table 2 shows that the model trained by our BLOCC algorithm outperforms that of GAM  significantly and is of a similar level as that of LV-HBA . We present some of the performance plots for the diabetes dataset as in Figure 3. Looking into the test accuracy (left), our algorithm achieves more than 0.76 accuracy in the first 2 iterations, which is significantly better than the other ones. For the upper-level objective (middle), in the first few iterations, the loss decreases significantly under all algorithms, in which our BLOCC achieves the lowest results. Moreover, in Figure 3 (right), the lower-level optimum for LV-HBA was not attained until the very end. This indicates that the decrease of upper loss between 0-40 iterations in the middle figure may be due to the suboptimality of lower-level variables. For our BLOCC and GAM, the lower-level minimum is attained as lower-level objective \(g 0\) in this case.

### Transportation network design problem

BLO is particularly relevant in transportation, where network planning must consider different time horizons and actors. Those problems are large-scale with a large number of upper- and lower-level variables and CCs, challenging the use of traditional BLO techniques, which involve expensive calculations of second order information. As a result, our final experiment considers a network design problem, where we act as an operator whose profit is modeled as the upper-level objective that is determined by the passengers' behavior, modeled in the lower-level. We considered three networks:

  Methods & diabetes & fourclass \\  
**BLOCC** & \(\) & \(\) \\ (**Ours**) & \(\) & \(\) \\   & \(0.765 0.039\) & \(0.748 0.060\) \\  & \((2.899 1.378)\) & \((2.404 0.795)\) \\   & \(0.721 0.047\) & \(0.715 0.056\) \\  & \((8.752 4.736)\) & \((13.481 0.970)\) \\   

Table 2: Numerical results on the training outcome of our BLOCC in comparison with LV-HBA  and GAM . The first row represents accuracy mean \(\) standard deviation, and the second row between brackets represents the running time until the upper-level objective’s update is smaller than 1e\({}^{-5}\).

Figure 2: 3-D plot of the upper-level objective \(f(x,y)\) of the toy example, with the line \(f(x,y)|_{y=x}\) shown in dashed red and the convergence points marked as red dots.

two synthetic networks of 3 and 9 nodes, respectively, and a real-world network of 26 nodes in the city of Seville, Spain. Further details about the formulation and the experiment can be found in Appendix F.

In this experiment, we only compare our BLOCC with LV-HBA  as the sole baseline, which is the only existing algorithm that addresses both coupled inequality \(g^{c}(x,y) 0\) and domain constraints \(\). GAM  and BVFSM  cannot handle lower-level domain constraints as they rely on the hypergradient of lower-level and require LL stationarity in an unconstrained space. From Table 3, we can see that LV-HBA failed to work efficiently, especially for large networks. This is mainly because the increased constraints render the projection step impracticable. Our BLOCC, in contrast, is much faster, and it successfully converges even with large real-world networks. We provided computational complexity analysis in Appendix H and we can conclude that our BLOCC is robust to large-scale problems.

## 5 Conclusions and Future Work

This paper proposed a novel primal-dual-assisted penalty reformulation for BLO problems with coupled lower-level constraints, and developed a new first-order method BLOCC to solve the resultant problem. The non-asymptotic convergence rate of our algorithm is \(}(^{-2.5})\), tightening to \(}(^{-1.5})\) when the lower-level constraints are affine in \(y\) without any other constraints. Our method achieves the best-known convergence rate and is projection-free, making it more favorable for large-scale, high-dimensional, constrained BLO problems. Experiments on SVM model training and transportation network planning showcased the effectiveness of our algorithm.

    &  &  &  \\  & NC = 24, NZ = 126 & NC = 678, NZ = 6,222 & NC = 13,336, NZ = 129,256 \\ Methods & Runtime (s) & UL utility & Runtime (s) & UL utility & Runtime (s) & UL utility \\   LV-HBA & \(3.51e2\) & 1.53 & 7 & / & / & / \\ BLOCC (Ours)-\(=2\) & \(2.02e1\) & 1.07 & \(7.27e2\) & 8.09 & \(6.82e4\) & 98.40 \\ BLOCC (Ours)-\(=3\) & \(2.00e1\) & 1.69 & \(8.50e2\) & 10.37 & \(6.42e4\) & 111.39 \\ BLOCC (Ours)-\(=4\) & \(2.01e1\) & 1.71 & \(8.68e2\) & 11.04 & \(6.70e4\) & 138.78 \\   

Table 3: Results of the transportation experiment, both in terms of running time (Runtime) and convergenced upper-level objective value (UL utility, larger there better), with stepsize \(=1.6e-4\). We use ”/” for algorithms that cannot converge within 24 hours of execution. NN (Number of Nodes) is the number of stations in the network. Analogously, NV (Number of Variables), NC (Number of Constraints), and NNZ (Number of non-zero elements) are the number of optimization variables, constraints, and non-zero elements of the constraints matrix, respectively.

Figure 3: Test accuracy (left), upper loss \(f(x,y)\) (middle), and lower loss \(g(x,y)\) (right) for the SVM on the diabetes dataset. The experiments are executed for 50 different random train-validation-test splits, with the bold line representing the mean, and the shaded regions being the standard deviation.