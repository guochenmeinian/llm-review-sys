# Fairness in Social Influence Maximization

via Optimal Transport

 Shubham Chowdhary

ETH Zurich

schowdhary@ethz.ch

Giulia De Pasquale

Eindhoven University of Technology

g.de.pasquale@tue.nl

Nicolas Lanzetti1

ETH Zurich

lnicolas@ethz.ch

Ana-Andreea Stoica

Max Planck Institute, Tubingen

ana-andreea.stoica@tuebingen.mpg.de

Florian Dorfler

ETH Zurich

dorfler@ethz.ch

Authors contributed equally.

###### Abstract

We study fairness in social influence maximization, whereby one seeks to select seeds that spread a given information throughout a network, ensuring balanced outreach among different communities (e.g. demographic groups). In the literature, fairness is often quantified in terms of the expected outreach within individual communities. In this paper, we demonstrate that such fairness metrics can be misleading since they overlook the stochastic nature of information diffusion processes. When information diffusion occurs in a probabilistic manner, multiple outreach scenarios can occur. As such, outcomes such as "In 50% of the cases, no one in group 1 gets the information, while everyone in group 2 does, and in the other 50%, it is the opposite", which _always_ results in largely unfair outcomes, are classified as fair by a variety of fairness metrics in the literature. We tackle this problem by designing a new fairness metric, _mutual fairness_, that captures variability in outreach through optimal transport theory. We propose a new seed-selection algorithm that optimizes both outreach and mutual fairness, and we show its efficacy on several real datasets. We find that our algorithm increases fairness with only a minor decrease (and at times, even an increase) in efficiency.

## 1 Introduction

Problem Description.Social networks play a fundamental role in the spread of information, as in the context of commercial products endorsement , job vacancy advertisements , public health awareness , etc. Information, ideas, or new products can either go viral and potentially bring significant changes in a community or die out quickly. In this context, a fundamental algorithmic problem arises, known as Social Influence Maximization (SIM) . SIM studies how to strategically select a pre-specified small proportion of nodes in the social network - the _early adopters_ or _seeds_ - so that the outreach generated by a diffusion process that starts at these early adopters is maximized. Consider, for example, a product endorsement campaign: the early adopters are strategically selected users who receive the product first to promote it to their friends, who in turn may or may not adopt it. The optimal selection of early adopters is known to be an NP-hard problem . Thus, many heuristic strategies have been proposed, based on iterative processes such as greedy algorithms or on network centrality measures. However, all these algorithms purely rely on the graph topology and are agnostic to users' demographics, which raises significant fairness concerns, especially in contexts of health awareness campaigns, education, and job advertisements, where one wants to ensure anequitable spreading of information. Indeed, real-world social networks are populated by different social groups based on gender, age, race, geography, etc., with different group sizes or connectivity patterns. Ignoring these aspects and focusing only on the outreach maximization process usually leads to the early adopters being the most central nodes. Consequently, low-interconnected minorities are often neglected from the diffusion process, thus causing fundamental inequity in the information propagation and biases exacerbation .

Related Work.The problem of SIM was first introduced in 2003 in Kempe et al. , where the problem of optimally selecting a (limited) set of early adopters was proved to be NP-hard. The study of SIM under fairness guarantees has a more recent history . Several multiple group-level fairness metrics have been proposed over the years . They fall under the notions of _equity_, _equality_, _max-min fairness_, _weffare_, and _diversity_: all of them quantify the fair distribution of influence across groups. In particular, Stoica et al.  propose a new SIM algorithm that operates under the constraint that, in expectation, the same percentage of users in each category is reached. Junaid et al.  optimize outreach under fairness and time constraints, by ensuring that the expected fraction of influenced nodes in each group is the same within a prescribed time deadline. Farnadi et al.  propose a unifying framework that encodes all different definitions of fairness in the SIM process as constraints in a linear program that optimizes outreach. Several other works  adopt a max-min strategy. Specifically, in Fish et al.  fairness is ensured by maximizing the minimum probability of a group receiving the information through modifications of the greedy algorithm. Zhu et al.  ensure that the outreach contains a pre-specified proportion of each group in a population. Finally, Tsang et al.  optimize outreach under the constraint that no group should be better off by leaving the influence maximization process with their proportional allocation of resources done internally. All these definitions involve a marginal expected value of fairness in groups, without considering the correlations - or other higher-order moments - for the joint probability distribution of different groups adopting the information (see Farnadi et al.  for an overview). In contrast, our work introduces a novel formalism for taking into account the actual joint distribution of outreach among groups, thus considering all groups simultaneously, highlighting limitations of various fairness metrics and developing a new seed selection policy that strategically extracts and optimizes our proposed notion of fairness. To conclude, our work is inspired by a recent line of work that draws on optimal transport theory  for fairness guarantees . To our knowledge, this is the first work to develop novel metrics and seeding algorithms that leverage optimal transport for the SIM problem.

Motivation.Many models of diffusion processes in the SIM problem are inherently stochastic, meaning that _who_ gets the information transmitted can vary greatly from one run to another. Consider, as an example, the case in which \(50\%\) of realizations over a diffusion process, no one in group 1 receives the information and everyone in group 2 does, whereas in the other \(50\%\) it is the opposite. This circumstance would be classified as fair in expectation, even though it is commonly not perceived as "fair". We show how this phenomenon is common in real-world data and how our proposed framework can detect such undesired scenarios. This prompts us to study a novel fairness metric.

Contributions.Our main contribution is twofold: first, we propose a new fairness metric based on optimal transport, called _mutual fairness_, and second, we propose a novel seeding algorithm that optimizes for both the group-wise total outreach (termed efficiency) and fairness. Our proposed fairness metric provides stronger fairness guarantees, and it reveals and overcomes known limitations of various other fairness metrics in the literature. Specifically, we leverage optimal transport theory to build _mutual fairness_, a metric that accounts for all groups simultaneously in terms of the distance between an ideal distribution where all groups receive the information in the same proportion. We leverage our proposed mutual fairness metric to provide a unifying framework that classifies the most celebrated information-spreading algorithms both in terms of fairness and efficiency. All algorithms are tested on a variety of real-world datasets. We show how our approach unveils new insights into the role of network topology on fairness; in particular, we observe that selecting group-label blind seeds in networks with moderate levels of homophily induces inequality in information access. In contrast, very integrated or very segregated networks tend to have quite fair and efficient access to information across different groups upon greedy seedset selection. We then extend our mutual fairness metric to also account for efficiency, thus introducing the notion of \(\)-fairness, with \(\) being the tuning parameter for the fairness-efficiency trade-off. Finally, we design a new seedset selection algorithm that optimizes over the proposed \(\)-fairness metric and enhances fairness with either a small trade-offor even improved efficiency. This novel approach provides a comprehensive evaluation and design tool that bridges the gap between fairness and efficiency in SIM problems.

## 2 Preliminaries

**Notation.** Given \(m\), we let \([m]\) denote the interval of integers from \(1\) to \(m\). We denote by \(G\) a network, considered undirected, and by \((C_{i})_{i[m]}\) the \(m\) groups of different sensitive attributes. In this paper, we consider \(m=2\) groups, noting that our framework is easily generalizable to more groups as discussed in Appendix B. We denote by \(_{G}(S)\) the influence function of a seedset \(S\) over a network \(G\), through some diffusion process. In other words, \(_{G}(S)\) determines the set of nodes reached by the seedset under a diffusion process. Then, \(|_{G}(S)|\) is often referred to as the _outreach_, a measure of efficiency for the selection of a seedset \(S\). Under a stochastic diffusion process (e.g., independent cascade, linear threshold model, etc.), \(|_{G}(S)|\) is a random variable, for which we are interested in the expected value and distribution. For a particular outreach, we define the final configuration at the end of a diffusion process as follows.

**Definition 2.1** (Final configuration): _For a network \(G\) with two communities \((C_{i})_{i}\) and a seedset \(S\), we let \(x_{i}\), \(i\), denote the fraction of nodes in each community in the outreach \(_{G}(S)\). The final configuration is the tuple \((x_{1},x_{2})\)._

In many definitions in the literature, fairness is operationalized by measuring the _expected value_ of the final configuration, where the expectation is taken over the diffusion process. In particular, the _equity_ definition introduced by Stoica et al. , Junaid et al.  checks that the expected value of the proportions of each group reached in the outreach is the same for all groups. For a formal definition of equity and other fairness definitions in the literature, see Appendix A. We will show that relying solely on the expected value leads largely unfair outcomes to be classified as fair.

## 3 Mutual Fairness via Optimal Transport

In contrast to the literature, we propose using the _joint_ outreach probability distribution, instead of its marginals, to capture simultaneous outreach between the two groups and therefore address questions like (i) When group 1 receives the information, will group 2 also receive it? (ii) Even if the two groups have the same marginal outreach probability distributions will the final configuration always be fair? We argue that capturing these aspects is crucial for understanding and assessing fairness, as shown in the motivating example below.

Notation.We collect the output of the information-spreading process via a probability distribution \(()\) over all possible final configurations. Informally, \((x_{1},x_{2})\) is the probability that a fraction \(x_{1}\) of group 1 receives the information and a fraction \(x_{2}\) of group 2 receives the information; e.g., \((0.3,0.4)\) represents the probability that 30% of group 1 and 40% of group 2 receive the information. We can marginalize \(\) to obtain the outreach probability distributions associated with each group; i.e., \(_{1}()\) and \(_{2}()\). Informally, we can write \(_{1}(x_{1})=_{x_{2}}(x_{1},x_{2})\). As in the example above, \(_{i}(0.3)\) is the probability that 30% of group \(i\) receives the information.

Motivating Example.Consider the SIM problem with nodes belonging to two groups, \(C_{1}\) and \(C_{2}\), each group having the outreach probability distribution \(_{i}=_{0}+_{1},i\{1,2\}\), with \(_{k}\) representing the delta distribution at \(k\). That is, in \(50\%\) of the cases all members in group \(i\) receive the information (i.e., we get \(x_{i}=1.0\)) and in \(50\%\) of the cases no one in group \(i\) receives the information (i.e., we get \(x_{i}=0.0\)). It is therefore tempting to say that this setting is fair since \(_{1}\) and \(_{2}\) coincide and therefore share the same expected value. We argue that this information does not suffice to claim fairness. Indeed, consider the two following probability distributions over the final configurations:

\[_{a}=0.5_{(0,0)}+0.5_{(1,1)},_{b}=0.25 _{(0,0)}+0.25_{(1,1)}+0.25_{(0,1)}+0.25 _{(1,0)},\]

with \(_{(i,j)}\), representing the delta distribution at \((i,j)^{2}\). Interestingly, both \(_{a}\) and \(_{b}\) are "compatible" with \(_{1}\) and \(_{2}\): If we compute their marginals, we obtain \(_{1}\) and \(_{2}\). However, \(_{a}\) and \(_{b}\) encode two fundamentally different final configurations. In \(_{a}\), the percentage of membersof group 1 who get the information _always_ coincides with the percentage of people of group 2. Conversely, in \(_{b}\), more outcomes are possible; in particular, there is a probability of \(0.25+0.25=0.5\) that all members of one group receive the information and no member of the other group receives it (see Fig. 2). Thus, from a fairness perspective, \(_{a}\) and \(_{b}\) encode very different outcomes. We therefore argue that a fairness metric should be expressed in terms of _joint_ probability distribution \(\), and not solely based on its marginals \(_{1}\) and \(_{2}\), as commonly done in the literature [23; 9].

### A Fairness Metric Based on Optimal Transport

Our motivating example prompts us to reason about fairness in terms of the joint probability measure \(\), instead of its marginal distributions \(_{1}\) and \(_{2}\). Since \(\) is a probability distribution (over all possible final configurations), we can quantify fairness by computing its "distance" from an "ideal" reference distribution \(^{*}\) along the diagonal, capturing the ideal situation in which both groups receive the information in the same proportion. We do so by using tools from optimal transport.

Background in optimal transport.For a given (continuous) transportation cost \(c:()()_{ 0}\), the optimal transport discrepancy between two probability distributions \(_{a}()\) and \(_{b}()\) is defined as

\[W_{c}(_{a},_{b})=_{(_{a},_{b})}_{(x_{1},x_{2}),(y_{1},y_{2})},[c((x_{1},x_{2}),(y_{1},y_{2}))],\] (1)

where \((_{a},_{b})\) is the set of probability distributions over \(()()\) so that the first marginal is \(_{a}\) and the second marginal is \(_{b}\). Intuitively, the optimal transport problem quantifies the minimum transportation cost to morph \(_{a}\) into \(_{b}\) when transporting a unit of mass from \((x_{1},x_{2})\) to \((y_{1},y_{2})\) costs \(c((x_{1},x_{2}),(y_{1},y_{2}))\). The optimization variable \(\) is called transportation plan and \(((x_{1},x_{2}),(y_{1},y_{2}))\) indicates the amount of mass at \((x_{1},x_{2})\) displaced to \((y_{1},y_{2})\). Thus, its first marginal has to be \(_{a}(x_{1},x_{2})\) (that is, \((x_{1},x_{2})\) has to be transported to some \((y_{1},y_{2})\)) and its second marginal must be \(_{b}(y_{1},y_{2})\) (that is, the mass at \((y_{1},y_{2})\) has to arrive from some \((x_{1},x_{2})\)). If the transportation cost \(c\) is chosen to be a \(p 1\) power of a distance \(d\), then \((W_{d^{p}}(,))^{1/p}\) is a distance on the space of probability distributions. When the probability distributions are discrete (or the space \(\) is discretized), the transportation problem (1) is a finite-dimensional linear program and can therefore be solved efficiently .

Our proposed fairness metric.To operationalize the optimal transport problem (1), we therefore need to define (i) a transportation cost and (ii) a reference distribution \(^{*}\). To define the transportation cost, we start with the following two considerations. First, moving mass _along_ the diagonal should have zero cost, as it does not affect fairness but only efficiency (the proportion of population reached in respective groups). Second, moving mass orthogonally towards the diagonal should come at a price, since the difference in group proportion outreach between groups 1 and 2 decreases. We quantify this price as the Euclidean distance. This is illustrated in Fig. 2, which shows how the joint distribution captures unfairness, by depicting the percentage outreach in each group on each axis;thus, the diagonal represents a "fair" line, where the probability of reaching a particular outreach percentage is the same for both groups.

These two insights suggest decomposing the distance between the initial configuration \((x_{1},x_{2})\) (e.g., belonging to \(_{a}\)) and \((y_{1},y_{2})\) (e.g., belonging to \(_{b}\)) into two components: one capturing efficiency and the other one being the fairness component (see Fig. 2). Since the aim of our metric is to measure fairness, we therefore obtain the transportation cost

\[c((x_{1},x_{2}),(y_{1},y_{2}))=\|z(x_{1},x_{2},y_{1},y_{2})-(x_{1},x_{2})\|= }{2}|(x_{2}-x_{1})-(y_{2}-y_{1})|,\] (2)

where \(z(x_{1},x_{2},y_{1},y_{2})\) is the point indicated in green in Fig. 2 and \(\|\|\) is the standard Euclidean norm. Thus, the "fairness distance" between two distributions \(_{a}\) and \(_{b}\) can be readily quantified by \(W_{c}(_{a},_{b})\). Since moving mass along the diagonal is free, we quantify the fairness of a given \(\) as its "fairness distance" from the "ideal" distribution \(^{*}=_{(1,1)}\), which represents the case where all members of both groups receive the information. We can now formally introduce our proposed fairness metric.

**Definition 3.1** (Mutual Fairness): _Given a network with communities \((C_{i})_{i}\), a SIM algorithm is said to be mutually fair if the algorithm propagation is such that it maximizes_

\[() 1-W_{c}(,^{*}),\]

_where \(W_{c}(,^{*})\) is the optimal transport discrepancy, defined with the transportation cost (2), between the probability distribution \(\) and the desired probability distribution \(^{*}\) defined as in (1)._

The mutual fairness from Definition 3.1 can be seen as a normalized expression of \(W_{c}(,^{*})\) to contain its values in \(\). Indeed, its lowest value is 0 and it is achieved with \(=_{(0,1)}\), for which is \(W_{c}(,^{*})=1\); its largest value is 1 and it is achieved with \(=^{*}\), for which \(W_{c}(^{*},^{*})=0\). Since \(^{*}\) is a delta distribution, we can solve the optimal transport problem (1) in closed form to

\[()=1-W_{c}(,^{*})=_{(x_ {1},x_{2})}1-|x_{1}-x_{2}|,\]

which reduces to \(()=1-_{i=1}^{N}|x_{1,i}-x_{2,i}|\) when the distribution \(\) is empirical with \(N\) samples \(\{(x_{1,i},x_{2,i})\}_{i[N]}\). In particular, our fairness metric can also be interpreted in terms of the average distance between the outreach proportions within the two groups.

Discussion.We note that, while we considered two groups in the aforementioned definition, our methodology readily extends the setting with \(m\) groups. We present this extension in Appendix B. Second, since moving mass "diagonally" is free, any distribution \(^{*}\) supported on the diagonal yields the same fairness metric. In practice, it is often not the case that all network members receive the information, and the best one could hope for is to project \(\) onto the diagonal; since moving along the diagonal is free, the fairness cost is the same whether the ideal distribution is that projection or \(^{*}\). Moreover, it is easy to see that the "fairness distance" is symmetric, namely \(W_{c}(_{a},_{b})=W_{c}(_{b},_{a})\). Finally, our definition readily extends to any other distance function besides the standard Euclidean metric.

Back to the motivating example.Armed with a definition of fairness that captures the nature of a diffusion process, we now revisit the motivating example in Fig. 1. To start, we evaluate the "fairness distance" between \(_{a}\) and \(_{b}\):

\[W_{c}(_{a},_{b})=}{2}+ }{2}=}{4},\]

which amounts to the cost of transporting the points \((0,1)\) and \((1,0)\), each with weight \(1/4\), to the diagonal. Notably, in contrast to simply computing the expected outreach of each group, our fairness metric distinguishes the two outcomes. Similarly, we can easily compute the fairness metric: \((_{a})=1\) and \((_{b})=0.5\). In particular, \(_{a}\) achieves the highest fairness score. Indeed, its outcome will always be fair. Instead, \((_{b})\) achieves a lower fairness score, capturing the fact that in 50% of the cases the outcome is perfectly fair, while in the remaining 50% it is largely unfair.

### Mutual Fairness in Practice

We now investigate the use of our newly defined fairness metric across a variety of real-world datasets: Add Health (AH), Antelope Valley variants \(0\) to \(23\) (AV_\(\_0\)-\(23\)) , APS Physics (APS) , Deezer (DZ) , High School Gender (HS) , Indian Villages (IV) , and Instagram (INS) . Each dataset contains a social network with a chosen demographic partitioning the population into two groups (see Appendix C for details). We load the datasets as graphs \(G(V,E)\). We then select a seedset \(S\) of size \(2\)-\(90\) (depending on the dataset) using the following heuristics: two group-agnostic seed selection strategies as our baselines, namely _degree centrality_ (bas_d), and _greedy_ (bas_g), proposed by Kempe et al. . In addition, we implement two fair seed selection heuristics based on the equity metric, namely _degree-central fair heuristic_ (hrt_d), and _greedy fair heuristic_ (hrt_g), proposed by Stoica et al. . To model the information spread, we use the Independent Cascade model (IC) for the diffusion of information  with a probability \(p\) for all edges. This process, being stochastic, is simulated \(R\) times in a Monte Carlo sampling process to achieve \(R\)_final configurations_ (Definition 2.1) plotted together as a _joint outreach distribution_, in Fig. 3. Then we apply our distribution-aware notion of fairness from Section 3.1, mutual fairness. We keep \(R=1,000\) throughout, but explore several values in \(p,|S|\) (mentioned per experiment in the figures below) and exhaustively recorded with other hyperparameters in Appendix D. All details related to computational resources and development environment are available in Appendix G. The code for all our numerical experiments is available at https://github.com/nicolaslanzetti/fairness-sim-ot.

Are the outcomes fair?As a first experiment, we study the _joint_ outreach probability distribution for different datasets. We identify four qualitatively different outcomes, shown in Fig. 3 for a few of the datasets. Additional experiments with different propagation probability and seed selection strategies can be found in Appendix D. Fig. 2(a) is obtained on AH with bas_g selection strategy and \(p=0.5,|S|=10\). We note how the joint outreach distribution is almost _concentrated_ on the top right of the plane, i.e., the outcome is almost _deterministic_ and highly fair and efficient. In turn, this trivializes both the expected value in the equity metric and the cost in the mutual fairness metric in Definition 3.1, which therefore essentially boils down to comparing the almost deterministic outreach fraction within each group. In these cases, our fairness metric does not provide additional insights. Such deterministic outcomes are typical of degree or greedy seedset outreach in dense graphs, such as AH, DZ, INS (refer to Appendix D), with extreme probability of conduction (\(p 0.5\) or \(p 0\)), and cross-group interconnectivity (see Table 1 in Appendix C). For moderate \(p\) (e.g., \(0.1\)), the outreach probability distribution is concentrated along the diagonal (Fig. 2(b)). Thus, both the equity metric and our fairness measure are _maximal_. Nonetheless, our fairness metric provides additional insights: not only does the expected outreach within each group coincide, but also the outreach at _every_ realization coincides (see the example in Section 3). Thus, our fairness metric provides a stronger certificate of fairness. As before, the same applies to AH, DZ, INS (see Appendix D). Intuitively, high cross-group interconnectivity in a dense graph already ensures fairness. Additionally, extreme \(p\) values ensure deterministic outreach (either the information dies out at the seedset, or reaches everyone in the population). When propagation happens with moderate propagation probabilities, \(p\), outreach appears as in Fig. 2(b). Fig. 2(c) represents APS for its hrt_g seedset outreach and \(p=0.3,|S|=6\). Here, we observe a highly stochastic outcome, with many realizations for which almost no member of one group receives the information. Note that the phenomenon observed in Fig. 2(c) is the same as the one captured by our motivating example. We argue such an outcome should _not_ be classified as fair, despite the expected value of the proportions being similar. Finally, Fig. 2(d) shows the AV_0 dataset with \(p=0.3,|S|=4\), and bas_g selection strategy. We observe a more stochastic outreach compared to Fig. 2(b) with variance spread along, but not on the diagonal, with a small bias towards one group. Also in this case, both the equity and mutual fairness metrics characterize this outcome as fair, but mutual fairness is more informative as it requires outcomes to be fair at each realization.

The impact of the conduction probability.As a second experiment, we investigate the difference between mutual fairness and equity (difference in the expected value of the proportions), as a function of the conduction probability \(p\). We consider the IV dataset as a case study and select seeds using bas_g. We show our results in Fig. 4. Our mutual fairness metric in Definition 3.1 shows a fundamentally different trend compared to the equity metric from Definition A.3. Importantly, for \(p(0,0.5)\), both metrics have an opposite trend: equity fairness increases to some extent whereas our metric suggests a significant fall in fairness in this region. For \(p(0.5,0.7)\), there is a decrease in equity fairness, while our fairness evaluation remains relatively constant. We notice similar trendsfor both metrics only for \(p(0.8,1.0)\). The significant difference in the trend of the two metrics confirms our previous finding that mutual fairness is more informative than the equity metric and that the equity metric fails to adequately capture changes in fairness, see Sections 3.1 and 3.2. For more experiments on other datasets, we refer to Appendix D.2.

### Trading off Fairness and Efficiency

To construct our fairness metric, we completely discarded the efficiency of the final configuration. For instance, the "fairness distance" between a configuration whereby no agent receives the information (i.e., \(=_{(0,0)}\)) and the "ideal" configuration whereby everyone receives the information (i.e., \(^{*}\)) is zero, as both probability distributions lay on the diagonal. As such, the fairness score of \(=_{(0,0)}\) is 1 and therefore maximal. Thus, in practice, one seeks a fairness-efficiency _tradeoff_.

In our setting, we can easily introduce the tradeoff in the transportation cost (2). Specifically, we can define the transportation cost as a weighted sum of the "diagonal distance" (measuring the difference in efficiency, dotted segment in Fig. 2) and the "orthogonal distance" (measuring the difference in fairness, solid segment in Fig. 2). Formally, for a given weight \( 0\), the transportation cost reads

\[c_{}((x_{1},x_{2}),(y_{1},y_{2})) =\|z(x_{1},x_{2},y_{1},y_{2})-(x_{1},x_{2})\|+(1-)\|z(x _{1},x_{2},y_{1},y_{2})-(y_{1},y_{2})\|\] \[=}{2}|(x_{2}-x_{1})-(y_{2}-y_{1})|+(1-) }{2}|(x_{1}+x_{2})-(y_{1}+y_{2})|.\] (3)

We refer to Fig. 5 for a heatmap of \(c_{}\). In particular, for \(=1\), we recover the transportation cost (2); for \(=0\) one optimizes for efficiency, and the \(\)-fairness collapses in the classical influence maximization problem. We can then proceed as in Section 3.1. The "\(\)-fairness-efficiency distance" between \(_{a}\) and \(_{b}\) is \(W_{c_{}}(_{a},_{b})\) and the \(\)-fairness metric can be then defined as follows.

**Definition 3.2** (\(\)-Fairness): _Consider a network with groups \(C_{1},C_{2}\), a SIM algorithm is said to be \(\)-fair if the algorithm propagation is such that it maximizes_

\[-() 1-}{\{1,2-2 \}}W_{c_{}}(,^{*}),\] (4)

Figure 4: Mutual fairness (left, red) and equity (right, blue) for the IV dataset as \(p\) varies in \(\).

Figure 3: Joint outreach probability distribution for different datasets, different propagation probabilities \(p\), and seedsets cardinalities \(|S|\).

_with \(W_{c_{}}(,^{*})\) defined as in (1) with transportation cost as in (3) and ideal distribution \(^{*}=_{(1,1)}\)._

The terms \(1\) and \(/\{1,2-2\}\) in (4) ensure that the metric is non-negative and in \(\). Again, the optimal transport problem can be solved in closed form, which yields

\[-()=_{(x_{1},x_{2})}[1- -x_{2}|+(1-)|x_{1}+x_{2}-2|}{\{1,2-2\}}].\]

In particular, for \(=1\), we recover the mutual fairness \(()\) in Definition 3.1 and for \(=0\) we obtain the efficiency metric \(_{(x_{1},x_{2})}[1-+x_{2}-2|}{2}]\).

## 4 Improving Fairness

### Fairness-promoting Seed-selection Algorithm

Armed with a novel fairness metric, \(-\), we now design an _iterative_ seed-selection algorithm, which we call _Stochastic Seedset Selection Descent_ (S3D), that strategically selects seeds taking into account all communities simultaneously. The pseudo-code is summarized in Algorithm 1. For its motivation and details, refer to Appendix E. For a given initial seedset, our algorithm explores new seeds and evaluates them on the efficiency-fairness metric \(-\) as in (4) for a desired value of the fairness-efficiency tradeoff parameter \(\) (S3D_STEP() in Appendix E), to decide if the new seedset becomes a candidate for the optimized seedset. These seeds are searched for by iteratively sampling stochastically reachable nodes, up to a fixed depth, taken as a fraction of the graph diameter, from the current seedset (SEEDSET_REACH() in Appendix E) while making sure they contribute to a non-overlapping outreach (Algorithm 1:e-8). To avoid local minima of the generally non-convex objective, the procedure allows for visiting inferior seedsets on \(-\) or even selecting completely random ones on rare occasions (Algorithm 1:i-18) using _Metropolis Sampling_. Otherwise, a high \(-\) encourages opting for the new seedset with high probability. Finally, we revisit all the seedset candidates collected so far and pick the one with the largest \(-\) as the optimal seedset. For a sparse graph \(G(V,E)\), with \(E=O(V)\), choosing \(|S|\) seeds, averaging over \(R\) realizations to approximate outreach via Monte-Carlo sampling and exploring \(k\) candidates using S3D_STEP suggests a total running time upper bound of \(O(kR|S||V|)\) (see Appendix E for details). In practice, \(k,R=1000\) for \(S\) works well for all datasets.

### Real-world Data

Are the outcomes more fair?We test our algorithm across a variety of datasets (Appendix C) against our baselines (bas_d, bas_g). We initialize the S3D algorithm with the two baseline seedsets and hence include results from two separately optimized seedsets, S3D_d, S3D_g. Our results are shown in Fig. 6. Informally, we observe that our seed-selection mechanism "moves" the probability mass of the joint outreach probability distribution towards the diagonal, which ultimately increases the fairness of the resulting configuration. At the same time, efficiency either increases as well or suffers only a small decrease, as we investigate more in detail in our next experiment. Generally, datasets

Figure 5: Cost of transporting a point \((x_{1},x_{2})\) to the “ideal” point \((1,1)\) (i.e., everyone receives the information) for various values of \(\) (i.e., we plot \((x_{1},x_{2}) c_{}((x_{1},x_{2}),(1,1))\)). Yellow denotes a low transportation cost, whereas dark blue denotes a large cost.

with high cross-group connections (AH, DZ, INS) yield moderately fair outreach with label-blind seed selection. Similarly, for datasets with low cross-group connections (APS) a label-blind strategy, in order to maximize efficiency, selects a diverse population of seeds from which all communities are reached. Therefore, label-blind algorithms work similarly to S3D. In other moderate cases (AV, HS, IV), instead, we observe significant improvements of S3D over label-blind strategies.

Classification of seed-selection algorithms.In our final experiments, we compare several algorithms along with ours in terms of efficiency and mutual fairness across various datasets (see Appendix C). We consider the following algorithms: bas_d, bas_g, their fair heuristic counterparts, hrt_d, hrt_g, against our S3D_d, S3D_g, initialized via greedy and degree centrality baseline seeds, respectively. We show our results in Fig. 7. S3D achieves in almost all cases the highest

Figure 6: Demonstrate S3D (red) improvement over its label-blind baseline counter-part initializations (blue) for several datasets, propagation probabilities \(p\), seed set cardinalities \(|S|\) and fairness-efficiency tradeoffs \(\). Fig. (d)d provides the strongest evidence that, besides improving in fairness, our strategy can also be more efficient, from \(83.1\%\) to \(87.9\%\).

fairness score (\(y\)-axis) and generally a slightly lower efficiency score (\(x\)-axis), compared to others. Thus, our seed-selection mechanism leads to fairer outcomes with only a minor decrease in efficiency.

The impact of the network topology.To conclude, we discuss the impact of the network topology. In particular, when the conduction probability is moderate, network topology starts playing a role, mainly through the number of cross-group edges (CE):

_CE% is small (\(\) 5%, APS):_ Such datasets encode group interaction information in the edges themselves, that is, an edge likely means nodes belong to the same group. In such cases, baseline greedy algorithms (bas_g) already perform well as they rely only on edge connectivity. In such circumstances, S3D does not significantly improve on their selection, both in efficiency and fairness.

_CE% is balanced (40-50%, HS, AH):_ These datasets reflect that groups interact well across each other and so any seedset selection largely ends up in a fair outreach. Since bas_g already has proven near-optimal efficiency guarantees, it is unlikely that S3D performs significantly better than bas_g.

_CE% is moderate (5-30%, AV (datasets 0, 2, 16, 20), IV):_ These are the non-trivial cases not covered above. Here bas_g can not reliably leverage the existence of edges into group information. Hence, S3D usually outperforms the baseline, achieving similar efficiency scores while significantly improving fairness.

_CE% is high (>50%):_ The case where nodes interact more across groups than in their group was never observed. However, as long as the existence of edges does not reliably signal group information, we expect S3D to perform well based on a similar analysis.

_Moderate outreach in dense graphs (\(}\), D2):_ For graphs where \(|E|\) substantially exceeds \(|V|\), the outreach variance across sample sub-graphs is too low to be captured in the discretized space we experimented (\(100 100\) units in \(^{2}\)), even for moderate \(p\). This leads to single-point concentrated joint-distribution plots, all of them leading to the same \(-\)Fairness.

## 5 Conclusions and Limitations

Conclusions.We propose a new fairness metric, called mutual fairness, in the context of SIM. Mutual fairness draws on optimal transport and captures various fairness-related aspects (e.g., when members of group 1 receive the information will members of group 2 receive it?) that are obscure to the fairness metrics in the literature. We also leverage our novel fairness metric to design a new seed selection strategy that tradeoffs fairness and efficiency. Across various real datasets, our algorithm yields superior fairness with a minor decrease (and in some cases even an increase) in efficiency.

Limitations.Our proposed algorithm, S3D, is essentially a random combinatorial search in the graph defining the social network. As such, its performance will generally depend on the quality of the seedset initialization. Moreover, there is no guaranteed bound on the number of iterations needed in S3D to achieve a desired level of fairness. Both aspects can be limiting in real-world applications.

Figure 7: S3D trade-off and improvement against other label-aware and label-blind algorithms for several datasets, propagation probabilities \(p\), seed set cardinalities \(|S|\) and fairness-efficiency tradeoffs \(\). Filled markers refer to greedy-based algorithms: \(=\)bas_g, \(=\)S3D_g, and \(=\)hrt_g. Empty markers refer to degree-based algorithms: \(=\)bas_d, \(\)\(=\)S3D_d, and \(=\)hrt_d. For statistical bounds, we refer to Appendix F.