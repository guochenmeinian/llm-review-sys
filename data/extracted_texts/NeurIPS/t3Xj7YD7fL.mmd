# An NLP Benchmark Dataset for Evaluating the Completeness of ESG Reports

###### Abstract

Environmental, Social, and Governance (ESG) reports serve as a platform for companies to publicly disclose their economic, environmental, and social impacts, as well as their contributions to sustainable development goals. The completeness of ESG reports is considered a crucial criterion for judging their quality and credibility, yet it is often overlooked in existing literature. This paper aims to comprehensively assess the completeness of ESG reports by evaluating their topic coverage and text quality. To achieve this goal, we collect 14,468 ESG reports from Chinese-listed companies. We then segment these reports into sentences and label over 8,000 of them with both topic and text quality tags. Finally, we propose two classification tasks based on the ESG sentences: topic classification and quality classification, to evaluate the ESG completeness. To train the classifiers, we fine-tuned several large language models (LLMs) on this dataset for the two classification tasks. Our findings suggest that the dataset has the potential to fill the gap in academia regarding methods for measuring ESG completeness.

## 1 Introduction

With the increasing awareness of sustainable development in society, how companies balance economic benefits with environmental benefits and social benefits has garnered close public attention. In this context, corporate environmental, social, and governance (ESG) performance has become a rapidly evolving focus [21; 18; 37]. Currently, ESG reports are a crucial means for companies to disclose their ESG performance, providing essential information for investors and stakeholders seeking insights into a company's commitment to these areas [31; 20].

Concerns have been raised regarding the ability of ESG reports to accurately reflect a company's contributions towards sustainable development [25; 27; 32]. Skeptics argue that ESG reports may act as a form of decoupling--a symbolic practice that is disconnected from actual performance, such as selective disclosure [25; 5; 36]. Selective disclosure, as shown in Figure 1, refers to the practice where companies disproportionately highlight favorable or relatively benign performance indicators to obscure their overall less impressive performance, thereby seeking to gain or maintain legitimacy . Authors in  found that decoupling is prevalent in sustainability reports, with 69% of negative events being selectively reported. Numerous non-profit organizations and NGOs, such as the Global Reporting Initiative (GRI), the Sustainability Accounting Standards Board Foundation (SASB), and Bloomberg, introduced specific ESG indicator systems to mitigate this issue. These systems aim to clarify the essential ESG topics that companies should disclose, ensuring the completeness of ESG reports .

Completeness is a crucial criterion for assessing the quality of ESG reports . It requires companies to comprehensively disclose significant economic, environmental, and social impacts related to theiroperations . Scholars emphasized that ESG reports are credible only when they meet completeness requirements . However, the academic community lacks scientific methods for evaluating ESG completeness. Additionally, international regulatory rules, such as the European Union's Corporate Sustainability Reporting Directive (CSRD), mandate that complete ESG reports should include both quantitative and qualitative information . Furthermore, many countries and international stock exchanges encourage issuers to prioritize quantitative information in their ESG reports . Therefore, when studying the completeness of ESG reports, attention should be paid not only to the topics covered but also to the quality of their content.

Due to the diverse categories and extensive content covered by ESG topics , large-scale monitoring and identification of the completeness of ESG reports are extremely challenging, requiring domain experts to analyze company documents. This necessitates the construction of open, high-quality datasets suitable for training and evaluating models in such contexts, which can be alleviated through the rapid text classification processes facilitated by natural language processing (NLP).

However, it is important to note that existing datasets do not support research on the completeness of ESG reports. Although existing works provided datasets in the field of sustainability, they only focus on part of the ESG topics, such as climate and environmental areas . Additionally, many studies utilize unsupervised models like Latent Dirichlet Allocation (LDA)  to learn topic structures, relying on word co-occurrence trends . However, LDA is an unsupervised model with significant uncertainty in the number and criteria of clusters, meaning the topics generated and interpreted by one researcher may not completely align with those of another . Hence, a fine-grained and labeled ESG dataset is essential for evaluating ESG completeness.

To address this need, we introduce a comprehensive dataset representing corporate ESG engagement, compiled from a wide range of company-related documents as illustrated in Figure 1. This dataset facilitates the detection of ESG report completeness, the generation and optimization of ESG reports, the evaluation of stakeholder assessments of corporate sustainability strategies, and the support of ESG fund investment decision-making systems. Initially, we evaluate the completeness of ESG reports based on topic coverage and disclosure quality, establishing an ESG tree and a two-tier classification system for ESG text quality. Utilizing this framework, we collected all ESG reports from Chinese-listed companies spanning the period, sourced from the official website of the Chinese stock exchange. We manually annotated 8,467 text sentences, each assigned two types of labels:

Figure 1: Dataset Collection, Labeling, and ESG Report Completeness Analysis. We collected ESG reports of publicly listed companies from the Internet. Each sentence in these reports is labeled with 36 categories of ESG tags. Using these ESG tags, we performed a quantitative analysis of the completeness of the reports. The completeness panel illustrates two examples: Company A, which exhibits a comprehensive ESG report, and Company B, which selectively discloses information by omitting categories such as “natural capital”, “product responsibility”, and “stakeholder”.

a topic label and a quality label. The topic labels are categorized into 36 classes according to the ESG tree, encompassing various aspects such as climate change, employee health and safety, and community engagement. The quality labels are divided into two categories: quantitative description and qualitative description.

The contributions of this work can be summarized as follows:

* Utilizing a scientific approach to evaluate ESG completeness in terms of both topic coverage and text quality.
* Introduction of a novel, fine-grained ESG dataset for evaluating the completeness of ESG reports and detailed manual annotation of text sentences with both topic and quality labels. This dataset is expected to stimulate research in natural language processing, sustainability, and ESG, guiding more accurate detection of ESG report completeness and evaluating corporate contributions to sustainability.
* We evaluate the performance of pre-trained language models and large language models on this task. Although we obtained promising results, such as an accuracy of approximately 85.66% in evidence page detection, there remains substantial room for improvement in evaluation performance. The code and dataset are available at https://github.com/LCYgogogo/ESG-dataset.

## 2 Background

Selective disclosure issues in ESG reportsESG reports serve as instruments for measuring, disclosing, and communicating information related to corporate social responsibility and sustainability objectives [1; 13; 15]. These reports encompass a range of topics, including specific initiatives, significant risks, and policy goals undertaken by companies across ESG dimensions [1; 13; 15]. However, due to the lack of mandatory ESG reporting frameworks and strong government regulations worldwide, there are significant differences in the quantity, reporting formats, and content of ESG reports disclosed by companies . Additionally, managers often have opportunistic motives for selectively disclosing information . Consequently, the completeness of ESG reports has been questioned . While many companies report substantial ESG information on various topics, the information is often one-sided, lacking disclosure on key ESG issues . Some companies focus excessively on key dimensions related to their business operations while neglecting other CSR topics .

NLP Research Related to the ESG completenessExisting works examined the completeness of ESG reports by analyzing the coverage of ESG topics [26; 16; 22]. In  and , researchers utilize unsupervised models, such as LDA, to learn the topic structure and cluster ESG texts, subsequently analyzing the content and trends of various topics. For instance,  revealed that ESG information disclosed by publicly listed companies in the UK and Europe primarily focuses on employee safety, employee training support, carbon emissions, human rights, efficient electricity, and healthcare products. However, as an unsupervised model, LDA presents significant uncertainty in generating and interpreting text topics . Consequently, these methods are ineffective in evaluating the completeness of ESG report topics or identifying selective disclosure behaviors by listed companies.

## 3 Dataset

Our dataset assesses ESG report completeness from two perspectives: topic coverage and text quality. It offers valuable insights for various research applications. In the field of NLP, it encourages the application of NLP technologies in sustainable development. In the domains of sustainability and finance, models trained on our dataset can evaluate the completeness and credibility of a company's ESG reports, thereby informing investment decisions for ESG funds.

### Dataset Construction

As shown in Figure 1, we evaluate the ESG completeness for each ESG report (document) \(^{i}\) from two perspectives: topics and quality. To achieve this, we segment \(^{i}\) into sentences and labeled each sentence with both topic and quality tags. Suppose report \(^{i}\) contains \(n_{i}\) sentences. Thus, \(^{i}:=\{^{i}_{j}\}_{j=1}^{n_{i}}\), where \(^{i}_{j}\) is the \(j\)-th sentence of report \(i\), with \(j=1,2,,n_{i}\). For each sentence \(\), we assign two kinds of labels: one is the topic label \(\), and the other is the quality label, denoted by \(\).

We believe that both \(\) and \(\) contribute to the completeness of \(^{i}\). The topic label \(\) is a 36-dimensional one-hot vector corresponding to the leaf nodes of the ESG tree shown in Figure 2. Details regarding the 36 topic labels will be discussed in the next section. The quality label \(\) is a 2-dimensional one-hot vector representing "Quantitative description" and "Qualitative description".

We collect ESG reports \(^{i}\) released by Chinese-listed companies from the official website of the China Stock Exchange, resulting in a total of 14,468 documents. Following the definitions of the labels \(\) and \(\), we engage three Ph.D. researchers specializing in the ESG domain to annotate training sets for the 36 topic labels \(\) and the 2 quality labels \(\). This process results in 8,467 manually labeled text sentences. We exclude 483 irrelevant ones, such as tables of contents and acknowledgments, which are unrelated to the ESG topic content. Subsequently, we assign two labels to the remaining 7984 sentences: the topic and quality labels. Consequently, we obtain the dataset \(:=\{_{j},_{j},_{j}\}_{j=1}^{8467}\), as illustrated in Table 1. The average length of these sentences is 80 Chinese characters. By segmenting the unlabeled ESG reports, we obtained over 3.2 million sentences, forming the out-of-distribution sample set.

### Two types of ESG label and ESG completeness

ESG topic labelWe use the ESG tree, as shown in Figure 2, to define the completeness with the topic classification. The topic labels \(\) correspond to the leaf node of ESG tree. We construct the ESG tree according to the standards of internationally recognized third-party organizations, including GRI, SASB, the Carbon Disclosure Project (CDP), Morgan Stanley Capital International (MSCI), Bloomberg, the China Securities Index (CSI), and SynTao Green Finance (SGF).

Figure 2 illustrates the four-layer ESG tree we constructed, a hierarchical framework that dissects corporate sustainability into Environmental, Social, and Governance dimensions, each further divided into related sub-topics. For example, the second-level indicator "_Environment_" includes three third-level indicators: _climate change_, _natural capital_, and _sustainable development management_. Furthermore, for _climate change_, the leaf nodes are _carbon emissions_ and _response to climate change_.

The ESG tree incorporates the disclosure requirements mandated by Chinese regulatory authorities for listed companies' ESG reports. For instance, the China Securities Regulatory Commission encourages listed companies to disclose their contributions to rural revitalization in China. To align with this requirement, we include "Rural Assistance" as a third-level topic. For detailed sources of the ESG tree labels, please refer to Appendix 1.

Text quality labelWe define ESG text quality through two types of labels. Based on our literature analysis, international authoritative ESG rating agencies, national securities regulatory authorities, and international stock exchanges increasingly emphasize that ESG reports should include crucial quantitative data in addition to qualitative descriptions . Furthermore, there is growing encouragement for disclosing quantitative information . Therefore, we examine the quality of ESG text as a crucial component in assessing the completeness of ESG reports. We categorize ESG text quality into two classes: (1) "Quantitative Text", which reflects quantitative information about the

    & Train & Test & ESG Class & Quality Class & Average Len & Out-of-distribution samples \\  sentences & 6,773 & 1,694 & 36 & 2 & 80.54 & 3,216,968 \\   

Table 1: Dataset description.

ESG aspects of the company, and (2) "Qualitative Text", which reflects qualitative information about the ESG aspects of the company.

ESG completeness evaluationThe completeness of ESG reports can be evaluated using a weighted topic distribution derived from the results of topic classification and text quality classification, as illustrated in Figure 4. This approach involves projecting each sentence of an ESG document onto a corresponding topic label and then weighting these labels based on text quality. For instance, we assign scores of 2 to "Quantitative" sentences and 1 to "Qualitative" sentences. Thus, for a specific topic in an ESG report that contains one "Quantitative" sentence and one "Qualitative" sentence, the topic frequency would be calculated as 2 + 1 = 3, rather than simply 2.

## 4 Experiment

In this section, we evaluate our method for assessing ESG completeness on the constructed dataset. We employ several large language models and fine-tune them on this dataset to classify both topic and text quality.

Figure 2: This ESG tree aids in the meticulous and systematic analysis of ESG topics. The topic hierarchical division of the ESG tree is derived from the standards of multiple ESG rating organizations (see subsection 3.2). Its 36 leaf nodes correspond to our 36 categories for sentence topic classification tasks.

### Setups

We adjust the learning rate according to the complexity of the task. Specifically, the learning rate is 2e-5 for the quality classification task and 1e-4 for the text topic classification task. We use Adam  with a weight decay rate of 0.1, and stop training if the test loss does not decrease for 3 consecutive epochs. The batch size is 16. The fine-tuned models train 100 epochs, with a maximum sequence length of 512, the ablation study on the PEFT methods is detailed in Appendix 4. See Appendix 2 for more details on the pre-trained models. We train all models on an A100 GPU.

### Baseline

* BERT : A milestone in the field of NLP, which learns language representation through pre-trained and fine-tuned and utilizes two pre-trained tasks, Masked Language Model (MLM) and Next Sentence Prediction (NSP), it has significantly advanced the performance across a broad spectrum of NLP tasks.
* RoBERTa : A variant of BERT that optimizes the original pre-trained methods, including scaling and complicating the training data, as well as improving the dynamic masking mechanism.
* LERT : A novel pre-trained model that enhances linguistic feature learning by incorporating three types of linguistic features into the traditional masked language model task.
* PERT : A pre-trained model based on an out-of-order language, introduces an auto-encoding mechanism with a Permuted Language Model (PerLM) objective, combining whole word and N-gram masking techniques to enhance performance.
* LLaMA2 [34; 9]: It introduces the Grouped Query Attention (GQA) mechanism during the supervised fine-tuning (SFT) stage, significantly enhancing inference efficiency and scalability in large models. Additionally, in the reinforcement learning phase, LLaMA2 employs the Grouped Attention (GAtt) mechanism to effectively address the issue of context forgetting.

### ESG topic classification results

We present the comprehensive performance of ESG topics on the testing dataset, as detailed in Table 2, which compares the models without fine-tuning against those with fine-tuning. Row 2 of Table 2 presents the performance for the baseline models without fine-tuning. The results indicate that all models perform poorly on the ESG topic classification. For instance, the PERT (base) model has the lowest accuracy at 0.53%, while BERT and RoBERTa (large) achieve 0.65% and 0.54%, respectively. Row 3 displays the metrics for the models after fine-tuning. Fine-tuning significantly enhances performance across the board. For instance, the BERT model's accuracy increases from 0.65% to 81.28%, and the LERT (large) model improves from 1.59% to 84.18%. These improvements underscore the importance of fine-tuning in adapting the models to the specific domain of ESG topics.

Among the fine-tuned models, LLaMA2 exhibits the highest accuracy at 85.66%. The performance suggests that fine-tuning is particularly well-suited for the ESG topic classification task. Additionally, RoBERTa (large) and LERT (large) also show strong performance with accuracies of 84.36% and 84.18%, respectively.

### Prompt results

We investigate the impact of different prompt designs on the performance of the LLaMA2 model in two tasks, topic classification and quality classification. As indicated in Table 3, prompt design significantly affects model performance. Notably, in the topic classification task, the prompt 3 design, substantially improved the model's accuracy. The accuracy for topic classification with prompt 1 is merely 77.27%. Still, with prompt 3, the accuracy rose to 85.66%, which is significantly higher than other prompt designs. It suggests that carefully crafted prompts can greatly enhance the model'sperformance on complex tasks. For the quality classification task, the influence of prompt design is also significant, prompt 5 achieves a significant enhancement, reaching 88.72%.

   Fine-tuned & metrics & BERT &  LERT \\ (base) \\  &  BERT \\ (large) \\  &  LERT \\ (base) \\  &  BERT \\ (large) \\  &  LERT \\ (large) \\  &  BERT \\ (large) \\  &  RoBERTa \\ (base) \\  &  RoBERTa \\ (large) \\  &  LLAMA2 \\  \\   &  Precision \\ Recall \\  } & 0.54\% & 0.43\% & 0.50\% & 0.01\% & 0.02\% & 0.09\% & 0.03\% & 1.11\% \\  & & 2.28\% & 1.82\% & 2.86\% & 2.70\% & 2.70\% & 2.89\% & 2.38\% & 2.75\% \\  & & 1.03\% & 0.42\% & 0.51\% & 0.03\% & 0.03\% & 0.16\% & 0.06\% & 0.68\% \\  &  & 0.65\% & 1.65\% & 1.59\% & 0.53\% & 0.59\% & 0.71\% & 0.54\% & 1.77\% \\   &  Precision \\ Recall \\  } & 
 Precision \\ Recall \\  & 79.25\% & 79.41\% & 83.21\% & 64.62\% & 73.91\% & 81.36\% & 84.99\% & 85.25\% \\  & & 74.09\% & 72.87\% & 75.46\% & 62.22\% & 69.04\% & 77.39\% & 78.69\% & 80.08\% \\  & & 75.08\% & 74.09\% & 78.08\% & 62.00\% & 69.20\% & 78.74\% & 80.87\% & 81.54\% \\  & & 81.28\% & 82.47\% & 84.18\% & 77.92\% & 79.93\% & 83.18\% & _84.36\%_ & **85.66\%** \\   

Table 2: Performance of fine-tuned large language models on ESG topic classification. We evaluate the performance impact of fine-tuning on different language models. Fine-tuning requires additional training on the ESG dataset to improve performance. The best results are highlighted in **boldface** and the second in _italic font_.

Figure 3: The heatmap visualizes the sentence count distribution across various ESG topic in the annual reports of 20 companies for the year 2022, post-elimination of irrelevant content. Identified by their stock codes on the vertical axis and arrayed the ESG topic on the horizontal axis.

[MISSING_PAGE_FAIL:8]

the quality label distribution and topic classification using a sunburst chart, as shown in Appendix 6.1 and 6.2, respectively.

## 5 Conclusion and limitation

ConclusionResearch on utilizing NLP to assess the completeness of ESG reports is still in its early stages. We present a novel NLP dataset specifically designed to evaluate ESG completeness. To facilitate this, we establish topic and quality labels using high-dimensional vectors for classification purposes, and annotate the dataset accordingly. The fine-tuned LLMs exhibit higher precision and robust applicability in evaluating the completeness of ESG reports. We anticipate that our dataset will stimulate further research in both NLP and sustainable development.

LimitationWe manually annotate the themes and narrative quality of ESG sentences. However, due to limited manpower, the number of annotations remains insufficient. Consequently, the accuracy of text theme classification did not exceed 90%, impacting the assessment of ESG completeness. Moving forward, we plan to increase the number of annotations and implement an active learning strategy to enhance their quality. This approach aims to collectively improve the accuracy of text classification and achieve a more precise assessment of ESG completeness.