# Solving a Class of Non-Convex Minimax Optimization

in Federated Learning

 Xidong Wu

Electrical and Computer Engineering

University of Pittsburgh

Pittsburgh, PA 15213

xidong_wu@outlook.com &Jianhui Sun

Computer Science

University of Virginia

Charlottesville, VA 22903

js9gu@virginia.edu &Zhengmian Hu

Computer Science

University of Maryland

College Park, MD 20742

huzhengmian@gmail.com &Aidong Zhang

Computer Science

University of Virginia

Charlottesville, VA 22903

aidong@virginia.edu &Heng Huang

Computer Science

University of Maryland

College Park, MD 20742

henghuanghh@gmail.com

This work was partially supported by NSF CNS 2213700 and CCF 2217071 at UVA.

This work was partially supported by NSF IIS 1838627, 1837956, 1956002, 2211492, CNS 2213701, CCF 2217003, DBI 2225775 at Pitt and UMD.

###### Abstract

The minimax problems arise throughout machine learning applications, ranging from adversarial training and policy evaluation in reinforcement learning to AUROC maximization. To address the large-scale distributed data challenges across multiple clients with communication-efficient distributed training, federated learning (FL) is gaining popularity. Many optimization algorithms for minimax problems have been developed in the centralized setting (_i.e._, single-machine). Nonetheless, the algorithm for minimax problems under FL is still underexplored. In this paper, we study a class of federated nonconvex minimax optimization problems. We propose FL algorithms (FedSGDA+ and FedSGDA-M) and reduce existing complexity results for the most common minimax problems. For nonconvex-concave problems, we propose FedSGDA+ and reduce the communication complexity to \(O(^{-6})\). Under nonconvex-strongly-concave and nonconvex-PL minimax settings, we prove that FedSGDA-M has the best-known sample complexity of \(O(^{3}N^{-1}^{-3})\) and the best-known communication complexity of \(O(^{2}^{-2})\). FedSGDA-M is the first algorithm to match the best sample complexity \(O(^{-3})\) achieved by the single-machine method under the nonconvex-strongly-concave setting. Extensive experimental results on fair classification and AUROC maximization show the efficiency of our algorithms.

## 1 Introduction

The nonconvex minimax optimization has been actively applied to solve enormous machine learning problems, such as adversarial training , generative adversarial networks (GANs) , policy evaluation in reinforcement learning , robust optimization , AUROC (area under the ROC curve) maximization , _etc._ Many single-machine minimax optimization algorithms have been proposed to address these problems.

Machine learning tasks with large-scale distributed datasets call for distributed training  because of its ability to shorten the calculation time and train models with data from various locations. At the same time, communication overhead has emerged as the most restrictive bottleneck of distributed training due to the increasing model and data size. To tackle these issues, federated learning (FL)  has emerged as a promising technique since it makes use of distributed data from different clients, avoids frequent transmission between clients and the central server, and preserves data privacy. In FL, clients train and update their models locally, and the server aggregates and averages the model parameters from all clients periodically. Only models are shared among clients and the training data are stored locally, which provides a certain level of data privacy. In addition, FL also enhances computation power since it utilizes many clients to train models.

Although federated learning has gained popularity, most existing works focus on the standard stochastic minimization problem . Recently, some algorithms for non-minimization optimization in FL are proposed . However, existing FL minimax algorithms have not achieved the complexity level reached by single-machine algorithms. To bridge this gap, we consider the federated nonconvex minimax optimization problem as follows:

\[_{x^{d_{1}}}_{y^{d_{2}}}\{F(x,y)=_{i=1}^{N}f_{i}(x,y)\}\] (1)

where the function \(f_{i}(x,y)=_{_{i}_{i}}[f_{i}(x,y;_{i})]:^{d_{1}}^{d_{2}}\) is the loss function of the \(i^{th}\) client. We restrict our focus to the non-convex minimax problem, where \(f_{i}(x,y)\) is nonconvex over \(x^{d_{1}}\) and concave or nonconcave over \(y^{d_{2}}\). \(N\) is the total number of clients. \(_{i}=(x_{i},y_{i})_{i}\) denotes data point \(_{i}\) is sampled from the local data distribution \(_{i}\) on machine \(i\). In this paper, heterogeneous datasets are considered, namely, \(_{i}\) and \(_{j}\) (\(i j\) ) are not identical.

Some recent works have attempted to solve federated minimax optimization for convex-concave setting . Due to the popularity of deep neural networks, nonconvex minimax has wider applications. More recently, some works  extend single-machine algorithms, such as SGDA, to federated learning settings for nonconvex minimax optimization. However, theoretical understandings of federated minimax optimization remain limited in the literature. In the context of stochastic smooth nonconvex minimax problems, their analysis either relies on strict assumptions  or achieves suboptimal convergence results . For example, single-machine methods  achieve \(O(^{3}^{-3})\) under nonconvex-strongly-concave setting, which is much better than \(O(^{4}^{-4})\) achieved by the best FL minimax algorithm  in existing literature. Therefore, a natural question arises:

**Can we design stochastic gradient decent ascent methods with better sample and communication complexities to match the convergence rate of single-machine counterparts for solving the problem (1)?**

In this paper, we provide an affirmative answer to the aforementioned question and propose a class of algorithms to solve the problem (1) under different settings. In particular, we consider three most common classes of nonconvex minimax optimization problems: 1) NC-C: NonConvex in \(x\), Concave in \(y\); 2) NC-SC: NonConvex in \(x\), Strongly-Concave in \(y\); 3) NC- PL: NonConvex in \(x\), PL-condition in \(y\). For each of these problems, we propose a new algorithm with provably better convergence rate (please see Table 1) and provide a theoretical analysis. Our main contributions are four-fold:

1. NC-C setting. We propose FedSGDA+, and prove it has sample complexity of \(O(N^{-1}^{-8})\) and communication complexity of \(O(^{-6})\). FedSGDA+ takes advantage of the structure of FL by adding the global learning rate at the server and reduces communication complexity to \(O(^{-6})\) from \(O(^{-7})\) in . It also achieves a linear speedup to the number of clients.
2. NC-PL setting. We propose a federated stochastic gradient ascent (FedSGDA-M) algorithm with the momentum-based variance reduction technique. It has the best sample complexity of \(O(^{3}N^{-1}^{-3})\) and the best communication complexity of \(O(^{2}^{-2})\). Compared with existing momentum-based variance reduction algorithms, our result employs a novel theoretical analysis framework that produces a tighter convergence rate (i.e., our rate gets rid of a logarithmic term appearing in existing works).
3. NC-SC setting. FedSGDA-M can be directly applied to the NC-SC setting since the PL condition is weaker than strong-concavity. Our algorithm is the first work to reach sample complexity of \(O(^{-3})\) in federated learning. In addition, FedSGDA-M does not rely on a large batch size to reach optimal sample complexity compared with single-machine minimax algorithms [29; 42].
4. Extensive experimental results on fair classification and AUROC maximization confirm the effectiveness of our proposed algorithm.

## 2 Related Work

### Single-Machine Minimax

**Nonconvex-Concave (NC-C) setting**. [31; 46; 45; 54; 35] proposed various deterministic and stochastic algorithms to solve the NC-C minimax problems. All of these algorithms, however, have a double-loop structure and are thus relatively complicated to implement. They decouple the minimax problem into a minimization problem and a maximization problem and use a nested loop to update variable \(y\) while keeping variable \(x\) constant. Subsequently,  studied the complexity result of the single-loop algorithm (SGDA) for the NC-C minimax problem and proves the stochastic algorithm achieves \(O(^{-8})\) complexity. SGDA is a direct extension of SGD from minimization optimization to minimax optimization problems. Recently,  providing a unified analysis for the convergence of OGDA and EG methods in the nonconvex-strongly-concave (NC-SC) and nonconvex-concave (NC-C) settings.

**Nonconvex-Strongly-Concave (NC-SC) setting**.  analyzed the stochastic gradient descent ascent (SGDA) algorithm and proved that SGDA has \(O(^{3}^{-4})\) stochastic gradient complexity. To reduce the convergence rate,  proposed a stochastic GDA algorithm (i.e. SREDA) with a double-loop structure based on the variance reduction technique of SPIDER  and reduce the complexity to \(O(^{3}^{-3})\).  used momentum-based variance reduction technique of STORM  and proposed Acc-MDA. Acc-MDA is a single-loop algorithm, which gets the same convergence result as SREDA. Furthermore, adaptive minimax algorithms are introduced [28; 30] to solve the nonsmooth nonconvex-strongly-concave minimax problems based on dynamic mirror functions.  used a nested adaptive framework to design parameter-agnostic nonconvex minimax algorithm.  proves that VR-based SAPD+ has the complexity of \(O(^{2}^{-3})\). However, whether the best convergence result of \(O(^{-3})\) in single-machine methods can be achieved in the federated setting is an open question. In addition,  conducts an in-depth investigation of limitations of GDA algorithm (e.g., smaller learning rate, cycling/divergence issue) and gives a systematic analysis of how to improve GDA dynamics.

 
**Type** & **Algorithm** & **Reference** & **Sample** & **Communication** \\  Nonconvex & Local SGDA+ &  & \(O(N^{-1}^{-8})\) & \(O(^{-7})\) \\  concave & FedSGDA+ & Ours & \(O(N^{-1}^{-8})\) & \(O(^{-6})\) \\  Nonconvex & Local SGDA &  & \(O(^{4}N^{-1}^{-4})\) & \(O(^{3}^{-3})\) \\  Strongly & Momentum Local SGDA &  & \(O(^{4}N^{-1}^{-4})\) & \(O(^{3}^{-3})\) \\  Concave & FEDNEST &  & \(O(^{3}^{-4})\)a & \(O(^{2}^{-4})\) \\   & FedSGDA & Ours & \(O(^{3}N^{-1}^{-3})\) & \(O(^{2}^{-2})\) \\   & Local SGDA &  & \(O(^{4}N^{-1}^{-4})\) & \(O(^{3}^{-3})\) \\  Nonconvex & Momentum Local SGDA &  & \(O(^{4}N^{-1}^{-4})\) & \(O(^{3}^{-3})\) \\  PL & SAGDA &  & \(O(N^{-1}^{-4})\) & \(O(^{-2})\)b \\   & FedSGDA & Ours & \(O(^{3}N^{-1}^{-3})\) & \(O(^{2}^{-2})\) \\  

* Their theoretical analysis does not report the dependency on N.
* Their theoretical analysis does not report the dependency on \(\).
* Their theoretical analysis does not report the dependency on \(\).

Table 1: Complexity comparison of existing nonconvex federated minimax algorithms for finding an \(\)-stationary point. Sample complexity is the total number of the First-order Oracle (IFO) to reach an \(\)-stationary point. Communication complexity denotes the total number of back-and-forth communication times between clients and the server. Here, \(N\) is the number of clients, and \(=L_{f}/\) is the condition number.

**Nonconvex-Nonconcave (NC-NC) setting**. There is extensive research on NC-NC problems  and the Nonconvex-PL condition is a special class of functions that interests us the most. Polyak-Lojasiewicz (PL) condition does not require the objective to be concave and recent works show that the PL condition could hold in the training process of overparameterized neural networks with random initialization [1; 5]. Recently, many deterministic methods [45; 64; 14] are proposed for NC-NC problems under the NC-PL setting.  proposed a PDAda method for Nonconvex-PL minimax optimization with the restriction of the concavity condition, and  focuses on the finite-sum Nonconvex-PL minimax optimization. Stochastic alternating GDA and stochastic smoothed GDA proposed in  achieve complexity of \(O(^{4}^{-4})\) and \(O(^{2}^{-4})\), respectively.

### Distributed/Federated Minimax

Distributed training has rapid development in minimax optimization in recent years, driven by the need to train large-scale datasets . Under the serverless decentralized setting, algorithms for nonconvex minimax have been studied extensively in nonconvex-strongly-concave setting [4; 62; 68; 41; 57] and nonconvex-PL setting .

In the FL setting, some works analyzed algorithms for convex-concave problems [11; 37; 26; 52]. However, as nonconvex models (e.g., deep neural networks) being more and more prevalent, there is a growing need for federated nonconvex minimax optimization, such as federated adversarial training , federated deep AUROC maximization  and federated GAN .  and  focus on imbalanced data tasks. They reformulated the AUROC maximization problem as the min-max problem under the FL setting. But their analysis relies on strict assumptions that deep models satisfy the PL condition and only focuses on PL-strong-concave minimax.  converted the robust federated learning into the minimax problem, where only model parameters, namely min variables, are exchanged among clients via the server.  proposed Local SGDA and Local SGDA+. Local SGDA is the local-update version of the SGDA algorithm in FL. Different from local SGDA, in local SGDA+, max variable \(y\) is updated with a constant min variable \(\) and the snapshot \(\) updates every S iteration. Afterward,  improves sample complexity and communication complexity of Local SGDA for NC-SC and NC-PL settings, and Local SGDA+ for NC-C setting.  also proposes a Momentum Local SGDA, which achieves the same theoretical results as Local SGDA for NC-PL and NC-SC settings. In addition,  designs FEDNST with two nested loops. Although FEDNEST is composed of FEDINN (a federated stochastic variance reduction algorithm ), their convergence complexity is not improved over vanilla Local SGDA. Afterward,  proposes SAGDA under NC-PL setting, which yields a better communication complexity (i.e., \(O(^{-2})\)). However, its analysis does not consider the effect of condition number \(\). More recently,  considers federated minimax optimization with Client Heterogeneity in nonconvex concave and nonconvex strongly-concave settings.

**Relation to Existing Works**. We propose FedSGDA+ for NC-C setting and FedSGDA-M for NC-SC and NC-PL settings. In NC-C setting, we discover that the addition of a global step size leads to better communication complexity. Under this circumstance, theoretical analysis is more challenging as we not only need to consider the complicated structure of the minimax problem but also need to handle the local update and global update separately. For FedSGDA-M, we relax the requirement of step size (specifically designed unnatural step size is often required in STORM-like approaches [7; 34]), which requires novel proof techniques to obtain. Thus our result does not contain a logarithmic term and provides a tighter convergence rate (Seen in contributions 1 in ). In addition, with different theoretical frameworks, our better sample complexity doesn't rely on a big batch size, while the single-machine minimax algorithm with variance reduction (Acc-MDA) in  (Table 2) needs a large batch to achieve the same sample complexity.

## 3 Algorithms and Convergence Analysis

Notation: \(\|\|\) denotes the \(_{2}\) norm for vectors. \(a=O(b)\) denotes that \(a Cb\) for some constant \(C>0\). Given the mini-batch samples \(=\{_{j}\}_{j=1}^{b}\), we let \( f_{i}(x,y;)=_{j=1}^{b} f_{i}(x,y;_{ i})\).

**Assumption 3.1**.: (i) Unbiased Gradient. The gradient of each component function \(f_{i}(x,y;)\) computed at each client is unbiased for all \(^{(i)}_{i}\), \(i[N]\):

\[[ f_{i}(x,y;^{(i)})]= f_{i}(x,y),\](ii) Variance Bound. The following inequalities hold for all \(^{(i)}_{i}\), \(i,j[N]\):

\[\| f_{i}(x,y;^{(i)})- f_{i}(x,y)\|^{2} ^{2}\] \[_{i=1}^{N}\| f_{i}(x,y)- F(x,y) \|^{2}^{2}\] (2)

The Assumption 3.1 is a standard assumption in stochastic optimization, which will be used throughout the rest of the paper. In FL algorithms, the Assumption 3.1 (ii) is frequently used to bound the variance and data heterogeneity. The heterogeneity parameter, \(\), denotes the level of data heterogeneity. In the homogeneous data configuration, \(=0\).

### Nonconvex Concave (NC-C) Problems

**Assumption 3.2**.: (Concavity). The nonconvex function \(f(,)\) is concave in \(y\) if for a fixed \(x^{d_{1}}, y,y^{}^{d_{2}}\), we have

\[f(x,y) f(x,y^{})+ f(x,y^{}),y-y^{}\] (3)

To solve the problem (1) under the NC-C setting and reduce the complexity, we propose FedSGDA+ (Seen in algorithm 1). Although local SGDA+  achieves the same sample complexity as the single-machine method (SGDA), its communication complexity is not optimal. This unsatisfactory result is due to the fact that local SGDA+ simply extends the single-machine method into the distributed setting, and does not consider the complicated local-server structure in FL.

In FedSGDA+, Line 5-10 are conducted in the local clients. The updates of variable x are similar to the standard stochastic algorithm for minimization problems, such as FedAvg. We sample data points and update the \(x\) locally with the current variable \(x_{t,q}^{i}\) and \(y_{t,q}^{i}\). However, for the \(y\)-updates, stochastic gradients are calculated with the latest snapshot of \(x(i.e.,_{k})\) and in each local iteration, \(y\) updates with the constant \(_{k}\) as seen in Line 9 in Algorithm 1. The \(_{k}\) is updated every S rounds ( Line 14-16 in Algorithm 1).

In addition, we make use of the advantage of FL and introduce the global step size \(_{x},_{y}\), which provides the flexibility of FL training (Seen in Line 12-13). Local SGDA+ could be regarded as a special case of FedSGDA+. We now provide the convergence analysis of FedSGDA+ and introduce the necessary assumptions. The details of the proofs are provided in the supplementary materials.

**Assumption 3.3**.: (Smoothness). Each local function \(f_{i}(x,y)\) has a \(L_{f}\)-Lipschitz continuous gradients, i.e., \( x_{1},x_{2}\) and \(y_{1},y_{2}\), we have

\[\| f_{i}(x_{1},y_{1})- f_{i}(x_{2},y_{2})\| L_{f}\|(x_{1},y_{1 })-(x_{2},y_{2})\|\] (4)

The Assumption 3.3 on the smoothness is a standard assumption in stochastic optimization .

**Assumption 3.4**.: (Lipschitz continuity in x). For the function \(F\), there exists a constant \(G_{x}\), such that for each \(y^{d_{2}}\), and \( x,x^{}^{d_{1}}\), we have

\[\|F(x,y)-F(x^{},y)\| G_{x}\|x-x^{}\|\]

Under the NC-C setting, the function \(F(,)\) is concave in y. Following , we define \((x)=_{y}F(x,y)\) and the Moreau envelope of \(()\) is defined below:

**Definition 3.5**.: (Moreau Envelope) A function \(_{}()\) is the \(\)-Moreau envelope of \(()\), for \(>0\), if \( x R^{d_{1}}\),

\[_{}(x)=_{z}(z)+\|z-x\|^{2}\]

From , we know that when we have a point \(x\) that is an \(\)-stationary point of \(_{}(x)\), then \(x\) is close to a point \(x^{}\) which is stationary for \((x)\). Hence, we focus on minimizing \(\|_{}(x)\|\) under the NC-C setting.

**Theorem 3.6**.: _Suppose Assumptions 3.1, 3.2, 3.3, 3.4 hold and the sequences \(\{x_{t},y_{t}\}\) are generated by Algorithm 1, \(\{c_{y},c\}}\) and let \(\|_{t}\|^{2} D\) following ,_

\[_{t=0}^{T-1}\|_{1/2L_{f} }(_{t})\|^{2} 8L_{f}_{x}(QG_{x}^{2}+ }{N})+8[_{1/2L_{f}}(x_{0} )]-[_{1/2L_{f}}(_{T})]} {Q_{x}T}\] \[+ 48L_{f}^{2}Q[^{2}+c^{2}](^{2}+6Q^{2})+288L_{f}^ {2}Q^{2}^{2}G_{x}^{2}\] \[+ 576L_{f}^{3}Q^{2}c^{2}[QS}+ ^{2}}{N}+6L_{f}Q^{2}c^{2}(^{2}+6^{2})]\] \[+ 32L_{f}G_{x}_{x}SQ^{2}+}{N }}+D}{c_{y}QS}+(c_{y})^{2}}{N}+96L_{f} ^{2}Q^{2}c^{2}(^{2}+6^{2})]\]

**Corollary 3.7**.: _By setting \(c==QT^{1/3}}\), \(Q=}{N}\), \(_{x}=T}\), \(c_{y}=Q}=T^{1/3}}\), \(S=T^{1/3}\), FedSGDA+ has the following convergence rate:_

\[_{t=0}^{T-1}\|_{1/2L_{f} }(_{t})\|^{2}}{T^{1/3}}+^{2}+^{2})}{5T^{2/3}}++6^{2})}{25T^{2/3}}+ ^{2}}{25T^{2/3}}++6^{2})}{25T^{2/3}}\] \[+}{25T^{2/3}}[D}{T^{1/3}}+}{10L_{f}T^{1/3}}++6^{2})}{50L_{f}T^{2/3}}]+}{5T^{1/3}}^{2}+}{N}}+^{2}D}{T ^{1/3}}+}{5T^{1/3}}\]

_Remark 3.8_.: (Complexity) Based on Corollary 3.7, to make \(_{t=0}^{T-1}\|_{1/2L_{f}}(_{t})\|^{2}^{2}\), communication complexity \(T=O(^{-6})\). We choose \(b=O(1)\), then we have sample complexity \(bQT=N^{-1}^{-8}\). It also denotes that FedSGDA+ has linear speedup with respect to the number of clients.

### Nonconvex-PL (NC-PL) Problems

**Assumption 3.9**.: (Polyak Lojasiewicz (PL) Condition in y). The function \(F(x,y)\) is \(\)-PL condition in \(y(>0)\), if \( x\): 1) \(y^{*}(x)=_{y}F(x,y)\) has a nonempty solution set; 2) \(\|_{y}F(x,y)\|^{2} 2(F(x,y^{*}(x))-F(x,y)), y\).

To solve problem (1) with better convergence complexity under nonconvex-PL, we propose federated stochastic gradient ascent (FedSGDA-M) algorithm with the momentum-based variance reduction technique (Seen in in algorithm 2).

In FedSGDA-M, each client initializes the gradient estimators \(\{u_{1}^{i},v_{1}^{i}\}\) with stochastic gradient as seen in line 2 of Algorithm 2. Following that, each client updates the model variables \(\{x_{t}^{i},y_{t}^{i}\}\) locally as standard stochastic gradient descent ascent method (lines 12-13 of Algorithm 2). Compared with local momentum SGDA , the key difference is that clients utilize variance reduction gradient estimators \(\{u_{t}^{i},v_{t}^{i}\}\), which are constructed in lines 15-17 of Algorithm 2. For the update step of \(\{u_{t},v_{t}\}\), the coefficients should satisfy \(0<<1\) and \(0<<1\). In every \(Q\) iteration, clients transmit model parameters and gradient estimators to the server, which computes \(\{_{t},_{t},_{t},_{t}\}\). Then the server sends averaged model variables and gradient estimators to each client to update the local variables, as shown in lines 5-10 of Algorithm 2.

**Definition 3.10**.: According to Assumption 3.9, there exists at least one solution to the problem \(_{y}F(x,y)\) for any \(x\). Here we define \((x)=F(x,y^{*}(x))=_{y}F(x,y)\). We use \(\)-stationary point of \((x)\), i.e. \(\|(x)\|\) as the convergence metric.

We know \((x)\) is differentiable and \((L+ L)\)-smooth and \(y^{*}()\) is \(\)-Lipschitz from . Given that \(_{y}F(_{t},y^{*}(x_{t}))=0\), we have \((_{t})=_{x}F(_{t},y^{*}(x_{t}) )+_{y}F(_{t},y^{*}(x_{t})) y^{*} (_{t})=_{x}F(_{t},y^{*}(x_{t}))\) which is widely used in the analysis of nonconvex-PL  and nonconvex-strongly-concave minimax optimization . Then we discuss the convergence analysis of FedSGDA-M. The proofs are provided in the supplementary materials.

**Assumption 3.11**.: (Lipschitz Smoothness) Each component function \(f_{i}(x,y;)\) has a \(L_{f}\)-Lipschitz gradient, i.e., \( x_{1},x_{2}\) and \(y_{1},y_{2}\), we have

\[\| f_{i}(x_{1},y_{1};)- f_{i}(x_{2},y_{2};)\| L _{f}\|(x_{1},y_{1})-(x_{2},y_{2})\|\] (5)

\(F(x,y)\) has an \(L_{f}\)-Lipschitz gradient based on the convexity of norm and Assumption 3.11. We have

\[\|_{x}F(x_{1},y_{1})-_{x}F(x_{2},y_{2})\| =\|_{i=1}^{N}_{x}f_{i} (x_{1},y_{1};)-_{x}f_{i}(x_{2},y_{2};)\|\] \[_{i=1}^{N}\|_{x}f_{i}(x_{1},y_ {1};)-_{x}f_{i}(x_{2},y_{2};)\|\] \[ L_{f}\|(x_{1},y_{1})-(x_{2},y_{2})\|\]In optimization analysis, it is standard to use the Assumption 3.11. Several widely used single-machine stochastic algorithms, such as SPIDER  and STORM , make use of this assumption. It is also used by numerous FL algorithms, including MIME  Fed-GLOMO , STEM  and FAFED .

**Theorem 3.12**.: _Suppose that sequence \(\{_{t},_{t}\}_{t=0}^{T}\) is generated from Algorithm 2. Under the above Assumptions (3.1,3.9,3.11), given \(=\), \(=c_{1}^{2},=c_{2}^{2},c_{1}=}{bN^{1-} },c_{2}=}{bN^{2-2}},c=},= }\) where \(\) we have_

\[_{t=0}^{T-1}\|(_{t})\|^{2}_{0})-(_{T})]}{  T}+}{ TBN}+^{2}^{2}}{ ^{2} TBN}+^{2}}{c^{2}T}[(_{0})-F(_ {0},_{t})]\] \[+}{Nb}+L_{f}^{2}}{ Nb^{2}}+[(c_{1}^{2}+c_{2}^{2})}{30bL^{2}}+(c_{ 1}^{2}+c_{2}^{2})}{12L^{2}}]^{2}^{2}\]

**Corollary 3.13**.: _By setting \(b=O(^{})\) for \(,c_{1}=}{bN^{1-}},c_{2}=}{bN ^{2-2}},c=},=},=}{40T_{0}^{2/3}},\)\(=c_{2}^{2}=}{40T_{0}^{2/3}b^{2-2}}\)._

\[_{t=0}^{T-1}\|(_{t})\|^{2}_{0})-^{*}]}{(NT_{0})^{2/3 }}+}{^{3-}(NT_{0})^{2/3}}+}{ ^{2}(NT_{0})^{2/3}}\] \[+}{(NT_{0})^{2/3}}[(_{0})-F(_{0}, _{0})]+}{20b(NT_{0})^{2/3}}+} {5(NT_{0})^{2/3}}+[}{20b}+}{40}] )^{2/3}}\]

_where \(^{*}\) is the optimal._

_Remark 3.14_.: (Complexity) To make the \(_{t=0}^{T-1}\|(_{t}) \|^{2}^{2}\), we get \(T_{0}=O(N^{-1}^{-3})\) and \(T=O(^{3-}N^{-1}^{-3})\). Considering the \(b=^{}\), we have communication complexity \(=^{3-}(NT_{0})^{2/3}=^{3-}^{-2}\) and sample complexity \(bT=O(^{3}N^{-1}^{-3})\). When \(=1,b=\), communication Complexity \(=^{2}^{-2}\) for finding an \(\)-stationary point. Sample complexity \(bT=O(^{3}N^{-1}^{-3})\) matches the complexity result achieved by the single-machine algorithms, such as SREDA and Acc-MDA in [42; 29] but we do not require a large batch size b compared with these algorithms. And \(O(^{3}N^{-1}^{-3})\) also exhibits a linear speed-up compared with the aforementioned single-machine algorithms.

### Nonconvex-Strongly-Concave (NC-SC) Problems

**Assumption 3.15**.: Each local function function \(f_{i}(x,y)\) is \(\)-strongly concave in \(y\), i.e., \( x\) and \(y_{1},y_{2}\), we have

\[\|_{y}f_{i}(x,y_{1})-_{y}f_{i}(x,y_{2})\|\|y_{1}- y_{2}\|\]

When the function \(F(x,y)\) is strongly concave in \(y\), there exists a unique solution to the problem \(_{y}f(x,y)\) for any \(x\). Since PL condition is weaker than strong concavity, the convergence result of FedSGDA-M in Algorithm 2 under NC-PL also apply to NC-SC problem and FedSGDA-M has the sample complexity of \(O(^{3}n^{-1}^{-3})\) and the communication complexity of \(O(^{2}^{-2})\) under nonconvex-strongly-concave setting.

The code is available 1

## 4 Experiments

We conduct experiments on AUROC maximization and fair classification tasks to verify the efficiency of our algorithms under nonconvex-strongly-concave and nonconvex-concave settings. Experiments are completed on the computer cluster with AMD EPYC 7513 Processors and NVIDIA RTX A6000. The code is available 2

**Datasets and Models**: We test the performance of algorithms on three typical datasets: Fashion-MNIST dataset, CIFAR-10 dataset and Tiny-ImageNet. Fashion-MNIST dataset has \(70,000\)\(28 28\) gray images (\(10\) categories, \(60,000\) training images and \(10,000\) testing images). CIFAR-10 dataset consists of \(50,000\) training images and \(10,000\) testing images. Each image is the \(3 32 32\) arrays of color image. Tiny-ImageNet dataset has 200 classes of (\(64 64\)) colored images and each class has 500 training images, 50 validation images, and 50 test images. For Fashion MNIST and Cifar10 data sets, we choose convolutional neural network from  (The details are shown in the supplementary materials). For Tiny-ImageNet, we choose ResNet-18  as the model.

### Fair Classification

First, we follow  and train fair classification networks by minimizing the maximum loss over different categories.

\[_{x}_{y}\ _{i=1}^{N}_{c=1}^{C}y_{c} _{c}^{i}(x)=\{y y_{i} 0,\ _{i=1}^{C}y_{i}=1\}\]

where \(_{c}^{i}\) denotes the cross-entropy loss functions corresponding to the class \(c\) in C different classes and \(x\) denotes the CNN model parameters. Clearly, the problem in (6) is nonConvex in x (deep model parameters), and Concave in y. We compare our algorithm (FedSGDA+) and local SGDA+ with varying model, datasets, local update numbers, step size. Although the constraint is not considered in the theoretical analysis of local SGDA+ and FedSGDA+, FedSGDA+ still shows better performance compared with local SGDA+.

The network has 20 clients. The datasets are partitioned into disjoint sets across all clients and each client holds part of the data from all the classes . We initialize the renset18 with pre-trained weights in PyTorch. In experiments, we run grid search for step size, and choose the step size for primal variable in the set \(\{0.01,0.03,0.05,0.1,0.3\}\) and that for dual variable in the set \(\{0.001,0.01,0.1\}\). We choose the global step size in the set \(\{0.1,0.5,1,1.5,2\}\). The batch-size \(b\) is in 50 and the inner loop number \(Q\) is selected from \(\{20,50,100\}\), The outer loop number \(S\) is selected from \(\{1,5,10\}\) for FedSGDA+ and \(\{1,5,10,Q\}\) for local SGDA+.

Figure 1 shows that FedSGDA+ has a better convergence rate than local SGDA+. This confirms that our algorithm can effectively accelerate SGDA by using the structure of federated learning. Due to the page limititation, the ablation analysis of step size is presented in the supplementary materials.

### AUROC Maximization

 showed the AUROC maximization problem could be reformulated as the non-convex-strongly-concave minimax optimization, as below:

\[_{^{d}\\ (a,b)^{2}}\ _{w}_{i=1}^{N} _{_{i}_{i}}[f_{i}(,a,b,w; )]\] (6)

Figure 1: Test Accuracy vs the number of communication rounds during the training phase.

where

\[f(,a,b,w;)=(1-p)(h( ;)-a)^{2}_{[y=1]}+p(h( ;)-b)^{2}_{[y=-1]}\] \[+2(1+w)[ph(;)_{[y=-1]}- (1-p)h(,)_{[y=1]}]-p(1-p)w^{2}\]

\(_{i}=(,y)_{i}\) denotes a random data point and \(\) represents the data features and \(y=\{-1,+1\}\) is the label. \(h(;)\) denotes the prediction score of the data point \(\) calculated by a model with parameter \(\). \(p=Pr(y=1)=_{y}[_{[y=1]}]\) denotes the prior probability of the positive data.

Following [19; 67], we constructed the imbalanced binary-class versions of datasets as follow: firstly, the first half of the classes (0 - 4) in the original Fashion-MNIST, CIFAR10 and classes (0 - 99) in Tiny-ImageNet datasets are converted into the negative class, and the rest half of classes are considered to be a positive class. 80% of the negative data points are randomly dropped in each dataset. Then the datasets are evenly divided into disjoint sets across 16 clients. In this case, each clients share completely different imbalanced datasets. In the experiment, we use xavier normal initialization to deep models.

We compare our algorithm (i.e., FedSGDA-M) with local SGDA [10; 50], CODA+ [19; 67], Momentum SGDA , CODASCA  and SAGDA  as baselines in AUROC maximization. In experiments, we carefully tune hyperparameters for all methods. We run a grid search for step size, and choose the step size for the primal variable in the set \(\{0.001,0.005,0.01\}\) and that for dual variable in the set \(\{0.0001,0.001,0.01\}\). We choose the global step size from \(\{0.9,1,1.5,2\}\) for CODASCA and SAGDA. We choose the momentum parameter in Local Momentum SGDA in the set \(\{0.1,0.5,0.9\}\). The \(\) and \(\) in FedSGDA-M are chosen from \(\{0.1,0.5,0.9\}\). The batch-size \(b\) is 50 and the inner loop number \(Q\{10,20,50\}\).

As shown in Figure 2, we compare the performance of FedSGDA-M and other baseline methods against the number of communication rounds. Figure 2 shows that our algorithms consistently outperform the other baseline algorithms on testing datasets, which validates the efficacy of our algorithms. Due to space limitation, other test results are provided in the supplementary materials.

**Limitation**. Minimax optimization has many applications and a more comprehensive discussion of our proposed algorithms on these tasks will be a future study because the theoretical analysis is the main contribution of this paper.

## 5 Conclusion

In this paper, we study a class of federated nonconvex minimax optimization problems (1). We consider the three most common settings (NC-SC, NC-PL, NC-C). Under the NC-C setting, we propose FedSGDA+ and prove it has the best communication complexity of \(O(^{-6})\). It also achieves a linear speedup to the number of clients. Under NC-PL and NC-PL settings, we propose FedSGDA-M with variance reduction technique and we prove that our algorithm (FedSGDA-M ) has the best sample complexity (\(O(^{3}n^{-1}^{-3})\)) and the best sample communication complexity (\(O(^{2}^{-2})\)). We prove that FedSGDA also enjoys linear speedup with respect to the number of clients. Therefore, we reduce the existing complexity results for the most common nonconvex minimax optimization problems under the federated learning setting.

Figure 2: AUROC scores on the test datasets vs the number of communication rounds during the training phase.