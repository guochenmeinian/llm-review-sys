# A Unified Framework for Rank-based Loss Minimization

Rufeng Xiao\({}^{*}\)   Yuze Ge\({}^{*}\)   Rujun Jiang\({}^{}\)   Yifan Yan

School of Data Science, Fudan University

{rfxiao21,yze23}@m.fudan.edu.cn

rjjiang@fudan.edu.cn

yanyf21@m.fudan.edu.cn

Equal contribution

###### Abstract

The empirical loss, commonly referred to as the average loss, is extensively utilized for training machine learning models. However, in order to address the diverse performance requirements of machine learning models, the use of the rank-based loss is prevalent, replacing the empirical loss in many cases. The rank-based loss comprises a weighted sum of sorted individual losses, encompassing both convex losses like the spectral risk, which includes the empirical risk and conditional value-at-risk, and nonconvex losses such as the human-aligned risk and the sum of the ranked range loss. In this paper, we introduce a unified framework for the optimization of the rank-based loss through the utilization of a proximal alternating direction method of multipliers. We demonstrate the convergence and convergence rate of the proposed algorithm under mild conditions. Experiments conducted on synthetic and real datasets illustrate the effectiveness and efficiency of the proposed algorithm.

## 1 Introduction

The empirical risk function is the cornerstone of machine learning. By minimizing this function, machine learning models typically achieve commendable average performance. However, as these models find applications across a diverse spectrum of real-world scenarios, the evaluation standards for machine learning performance have evolved to include factors such as risk aversion and fairness . This has led to the empirical loss function often being supplanted by other loss functions, many of which fall under the category of the rank-based loss, which consists of a weighted sum of sorted individual losses. We consider the following optimization problem in this paper, which minimizes the rank-based loss plus a regularizer:

\[_{^{d}}_{i=1}^{n}_{i}_{[i]}(- (X))+g().\] (1)

Here, \(()[l(u_{1}),,l(u_{n})]^{}:^{n}^{n}\) represents a vector-valued mapping where \(l:\) denotes an individual loss function and \(u_{i}\) is the \(i\)-th element of \(\), \(_{}()_{[n]}()\) denotes the order statistics of the empirical loss distribution, \(g:^{d}\) is a regularizer that induces desired structures, \(^{d}\) represents the parameters of the linear model, \(X^{n d}\) is the data matrix, and \(\{ 1\}^{n}\) is the label vector. The subscript \([i]\) denotes the \(i\)-th smallest element, \(_{i}\) is the weight corresponding to the \(i\)-th smallest element, and "\(\)" represents the Hadamard product. Depending on the values of \(_{i}\), the rank-based loss can encompass a significant range of losses oftenused in machine learning and other fields: the L-risk or the spectral risk [1; 2; 35], the trimmed risk or the sum of the ranked-range loss , the human-aligned risk based on the cumulative prospect theory .

**Related work.** When the values of \(_{i}\) are constant and monotonically increase, i.e., \(_{1}_{n}\), the rank-based loss is referred to as the spectral risk . Several methods have been proposed in the literature, including: a derivative-free method proposed by  that utilizes a stochastic smoothing technique; an adaptive sampling algorithm proposed by  for the minimization of conditional value at risk (CVaR), which is a special case of the spectral risk; and a stochastic algorithm developed by  for minimizing the general spectral risk by characterizing the subdifferential of the rank-based loss. In the case of nonconvex rank-based losses,  utilizes the difference of convex algorithm for minimizing the average of ranked-range (AoRR) loss. The nonconvex human-aligned risk was minimized by  by directly computing the gradient of the function, even though the rank-based loss is nondifferentiable, without any convergence guarantee. Despite the increasing applications of the rank-based loss, a unified framework for addressing the rank-based loss minimization remains elusive. Moreover, stochastic methods may encounter bias issues , existing methods for the spectral risk cannot deal with nonconvex rank-based losses, and existing methods for human-aligned risk lack convergence guarantee .

**Our Contributions.** We present a unified framework for the minimization of the rank-based loss to overcome the challenges of existing methods. Specifically, we focus on monotone increasing loss functions, such as the hinge loss and the logistic loss, and use weakly convex regularizers. We leverage the alternating direction multiplier method (ADMM), which is widely used in solving nonsmooth nonconvex composite problems [8; 32; 48]. To utilize the ADMM framework, we introduce an auxiliary variable to represent the product of the data matrix and parameter vector. The two subproblems are either strongly convex (with a proximal term), which can be solved by various existing methods, or can be efficiently solved by the pool adjacent violators algorithm (PAVA) . We demonstrate that our algorithm can find an \(\)-KKT point in at most \(O(1/^{2})\) iterations under mild conditions. To relax the assumptions further, we propose a variant of the ADMM with a smoothing technique when the regularizer is nonsmooth. Notably, when the Moreau envelope is applied to smooth the nonsmooth regularizer, we show that our algorithm can find an \(\)-KKT point within \(O(1/^{4})\) iterations.

Our contributions can be summarized as follows:

1. We propose a unified framework for the rank-based loss minimization for monotonically increasing loss functions. This approach is versatile, effectively dealing with both convex and nonconvex loss functions by allowing different settings of weights \(_{i}\).
2. Furthermore, the regularizer in our problem can be weakly convex functions, extending existing works that only consider convex or smooth regularizers, such as the \(l_{1}\) and \(l_{2}\) penalty.
3. We theoretically demonstrate that our ADMM algorithm converges to an \(\)-approximate KKT point under different assumptions.
4. The experiments in three different aggregate loss function frameworks demonstrate the advantages of the proposed algorithm.

## 2 Preliminaries

In this section, we explore the wide variety of rank-based losses and introduce the Moreau envelope as a smooth approximation of weakly convex functions.

### Rank-Based Loss

Let \(\{(X_{1},y_{1}),,(X_{n},y_{n})\}\) be an i.i.d. sample set from a distribution \(\) over a sample space \((,)\), and \(\) be the individual loss function. Then \(Y=(,X,y)\) is also a random variable, and \(Y_{i}=(,X_{i},y_{i})\) represents the \(i\)-th training loss with respect to the sample \((X_{i},y_{i})\), \(i\{1,,n\}\). Let \(Y_{} Y_{[n]}\) be the order statistics. The rank-based loss function in problem (1) equals

\[_{i=1}^{n}_{i}Y_{[i]}.\] (2)Spectral RiskThe spectral risk, as defined in , is given by:

\[_{}()=_{0}^{1}_{t}()(t)\,dt,\] (3)

where \(_{t}()=\{u:_{}(u) t\}\) denotes the quantile function, and \(F_{}\) represents the cumulative distribution function of \(Y\). The function \(:_{+}\) is a nonnegative, nondecreasing function that integrates to 1, known as the spectrum of the rank-based loss. The discrete form of (3) is consistent with (2), with \(_{i}=_{(i-1)/n}^{i/n}(t)\,dt\). The spectral risk builds upon previous aggregate losses that have been widely used to formulate learning objectives, such as the average risk , the maximum risk , the average top-\(k\) risk  and conditional value-at-risk . By choosing a different spectral \((t)\), such as the superquantile , the extremile , and the exponential spectral risk measure , can be constructed for various spectral risks.

Human-Aligned RiskWith the growing societal deployment of machine learning models for aiding human decision-making, these models must possess qualities such as fairness, in addition to strong average performance. Given the significance of these additional requirements, amendments to risk measures and extra constraints have been introduced . Inspired by the cumulative prospect theory (CPT) , which boasts substantial evidence for its proficiency in modeling human decisions, investigations have been carried out in bandit  and reinforcement learning . Recently,  also utilized the concept of CPT to present a novel notion of the empirical human risk minimization (EHRM) in supervised learning. The weight assigned in (3) is defined as \(_{i}=w_{a,b}()\), where

\[w_{a,b}(t)=-a+1}(3t^{2}-2(a+1)t+a)+1.\]

These weights assign greater significance to extreme individual losses, yielding an S-shaped CPT-weighted cumulative distribution. Moreover, we consider another CPT-weight commonly employed in decision making . Let \(=-(X)\) and \(B\) be a reference point. Unlike previous weight settings, \(_{i}\) is related to the value of \(z_{[i]}\) and is defined as

\[_{i}(z_{[i]})=_{-}()-_{-}(),&z_{[i]} B,\\ _{+}()-_{+}(),&z_{[i]}>B,\] (4)

where

\[_{+}(p)=}{(p^{}+(1-p)^{})^{1/ }},_{-}(p)=}{(p^{}+(1-p)^{} )^{1/}},\] (5)

with \(\) and \(\) as hyperparameters.

Ranked-Range LossThe average of ranked-range aggregate (AoRR) loss follows the same structure as (2), where

\[_{i}=,&i\{m+1,,k\},\\ 0,&,\] (6)

with \(1 m<k n\). The ranked-range loss effectively handles outliers, ensuring the robustness of the model against anomalous observations in the dataset . It is clear that AoRR includes the average loss, the maximum loss, the average top-\(k\) loss, value-at-risk  and the median loss .  utilized the difference-of-convex algorithm (DCA)  to solve the AoRR aggregate loss minimization problem, which can be expressed as the difference of two convex problems.

### Weakly Convex Function and Moreau Envelope

A function \(g:^{d}\) is said to be \(c\)-weakly convex for some \(c>0\) if the function \(g+\|\|^{2}\) is convex. The class of weakly convex functions is extensive, encompassing all convex functions as well as smooth functions with Lipschitz-continuous gradients . In our framework, we consider weakly convex functions as regularizers. It is worth noting that weakly convex functions constitute a rich class of regularizers. Convex \(L^{p}\) norms with \(p 1\) and nonconvex penalties such as the Minimax Concave Penalty (MCP)  and the Smoothly Clipped Absolute Deviation (SCAD)  are examples of weakly convex functions .

Next, we define the Moreau envelope of \(c\)-weakly convex function \(g()\), with proximal parameter \(0<<\):

\[M_{g,}()=_{}\{g()+\|- {w}\|^{2}\}.\] (7)

The proximal operator of \(g\) with parameter \(\) is given by

\[_{g,}()=_{}\{g()+\|-\|^{2}\}.\]

We emphasize that \(_{g,}()\) is a single-valued mapping, and \(M_{g,}()\) is well-defined since the objective function in (7) is strongly convex for \((0,c^{-1})\).

The Moreau envelope is commonly employed to smooth weakly convex functions. From [7, Lemma 3.1-3.2] we have

\[ M_{g,}()=^{-1}(-_{g,}( )) g(_{g,}() ).\] (8)

Here \(\) represents Clarke generalized gradient . For locally Lipschitz continuous function \(f:^{d}\), its Clarke generalized gradient is denoted by \( f()\). We say \(\) is stationary for \(f\) if \( f()\). For convex functions, Clarke generalized gradient coincides with subgradient in the sense of convex analysis. Under assumptions in Section 3.3, both \(():=_{i=1}^{n}_{i}l_{[i]}()\) and \(g()\) are locally Lipschitz continuous . Thus, the Clarke generalized gradients of \(()\) and \(g()\) are well defined, and so is that of \(L_{}(,;)\) defined in Section 3.1.

## 3 Optimization Algorithm

Firstly, we make the basic assumption about the loss function \(l\) and the regularizer \(g\):

**Assumption 1**: _The individual loss function \(l():\) is convex and monotonically increasing, where \(\) is the domain of \(l\). The regularizer \(g():^{d}\{\}\) is proper, lower semicontinuous, and \(c\)-weakly convex. Furthermore, \(l()\) and \(g()\) are lower bounded by 0._

Many interesting and widely used individual loss functions satisfy this assumption, such as logistic loss, hinge loss, and exponential loss. Our algorithm described below can also handle monotonically decreasing loss functions, by simply replacing \(_{i}\) with \(_{n-i+1}\) in (1). We assume \(l\) and \(g\) are lower bounded, and take the infimum to be 0 for convenience. The lower bounded property of \(l\) implies that the \(\) is also lower bounded by 0 since \(_{i} 0\) for all \(i\).

### The ADMM Framework

By Assumption 1, the original problem is equivalent to

\[_{}_{i=1}^{n}_{i}l((D)_{[i]})+ g(),\]

where \(l\) is the individual loss function, \(D=-()X\) and \(()\) denotes the diagonal matrix whose diagonal entries are the vector \(\).

To make use of the philosophy of ADMM, by introducing an auxiliary variable \(=D\), we reformulate the problem as

\[_{,}()+g()=D,\] (9)

where \(()=_{i=1}^{n}_{i}l(z_{[i]}).\)

Note that for human-aligned risk, \(_{i}\) should be written as \(_{i}(z_{[i]})\) since it is a piecewise function with two different values in (4), but for simplicity, we still write it as \(_{i}\).

The augmented Lagrangian function can then be expressed as

\[L_{}(,;)=_{i=1}^{n}()+||-D+}{}||^{2}+g()-||^{2}}{2}.\]The ADMM, summarised in Algorithm 1, cyclically updates \(,\) and \(\), by solving the \(\)- and \(\)-subproblems and adopting a dual ascent step for \(\). In Algorithm 1, we assume the \(\)- subproblem can be solved exactly (for simplicity). When \(g()\) is a smooth function, the \(\)-subproblem is a smooth problem and can be solved by various gradient-based algorithms. Particularly, the \(\)-subproblem is the least squares and admits a closed-form solution if \(g() 0\) or \(g()=||||_{2}^{2}\), where \(>0\) is a regularization parameter. When \(g()\) is nonsmooth, if \(_{g,}()\) is easy to compute, we can adopt the proximal gradient method or its accelerated version . Particularly, if \(g()=||||_{1}\), then the subproblem of \(\) becomes a LASSO problem, solvable by numerous effective methods such as the Coordinate Gradient Descent Algorithm (CGDA) , the Smooth L1 Algorithm (SLA) , and the Fast Iterative Shrinkage-Thresholding Algorithms (FISTA) .

```
0:\(X\), \(\), \(^{0}\), \(^{0}\), \(^{0}\), \(\), \(r\), and \(_{i},i=1,...,n\).
1:for all\(k=0,1,...\)do
2:\(^{k+1}=_{}()+||-D^{ k}+^{k}}{}||^{2}\).
3:\(^{k+1}=_{}||^{k+1}-D+^{k}}{}||^{2}+g()+\|-^{k}\|^{2}\).
4:\(^{k+1}=^{k}+(^{k+1}-D^{k+1})\).
5:endfor ```

**Algorithm 1** ADMM framework

At first glance, the \(\)-subproblem is nonconvex and difficult to solve. However, we can solve an equivalent convex chain-constrained program that relies on sorting and utilize the pool adjacent violators algorithm (PAVA). More specifically, we follow the approach presented in [13, Lemma 3] and introduce the auxiliary variable \(=D^{k}-^{k}}{}\) (we remove the superscript for \(\) for simplicity). This enables us to express the \(\)-subproblem in the equivalent form below

\[_{}_{i=1}^{n}_{i}l(z_{p_{i}})+(z_{p_{i} }-m_{p_{i}})^{2}z_{p_{1}} z_{p_{2}} z_{p_{n}},\]

where \(\{p_{1},p_{2},,p_{n}\}\) is a permutation of \(\{1,,n\}\) such that \(m_{p_{1}} m_{p_{2}} m_{p_{n}}\).

### The Pool Adjacent Violators Algorithm (PAVA)

To introduce our PAVA, for ease of notation and without loss of generality, we consider \(m_{1} m_{2} m_{n}\), i.e., the following problem

\[_{}_{i=1}^{n}_{i}l(z_{i})+(z_{i}-m_{i} )^{2}z_{1} z_{2} z_{n}.\] (10)

The above problem constitutes a convex chain-constrained program. Although it can be solved by existing convex solvers, the PAVA  is often more efficient.

The PAVA is designed to solve the following problem

\[_{}_{i=1}^{n}_{i}(z_{i})z_{1} z_{2} z_{n},\]

where each \(_{i}\) represents a univariate _convex_ function. In our problem, \(_{i}(z_{i})=_{i}l(z_{i})+(z_{i}-m_{i})^{2}\). The PAVA maintains a set \(J\) that partitions the indices \(\{1,2,,n\}\) into consecutive blocks \(\{[s_{1}+1,s_{2}],[s_{2}+1,s_{3}],,[s_{k}+1,s_{k+1}]\}\) with \(s_{1}=0\) and \(s_{k+1}=N\). Here, \([a,b]\) represents the index set \(\{a,a+1,,b\}\) for positive integers \(a<b\), and by convention, we define \([a,a]=a\). A block \([p,q]\) is termed a _single-valued block_ if every \(z_{i}\) in the optimal solution of the following problem has the same value,

\[_{z_{p},,z_{q}}_{i=p}^{q}_{i}(z_{i})z_{p} z_{p+1} z_{q},\]

i.e., \(z_{p}^{*}=z_{p+1}^{*}==z_{q}^{*}\). In line with existing literature, we use \(v_{[p,q]}\) to denote this value. For two consecutive blocks \([p,q]\) and \([q+1,r]\), if \(v_{[p,q]} v_{[q+1,r]}\), the two blocks are _in-order_; otherwise, they are _out-of-order_. Similarly, the consecutive blocks \(\{[s_{k},s_{k+1}]\,,[s_{k+1}+1,s_{k+2}]\,,,[s_{k+t}+1,s_{k+t+1}]\}\) are said to be _in-order_ if \(v_{[s_{k}s_{k+1}]} v_{[s_{k+1}+1,s_{k+2}]} v_{[s_{k+t}+1,s_{k +t+1}]}\); otherwise they are _out-of-order_. Particularly, if \(v_{[s_{k}s_{k+1}]}>v_{[s_{k+1}+1,s_{k+2}]}>>v_{[s_{k+t}+1,s_{k+t+1}]}\), the consecutive blocks are said to be _consecutive out-of-order_. The PAVA initially partitions each integer from 1 to \(n\) into single-valued blocks \([i,i]\) for \(i=1,,n\). When there are consecutive _out-of-order_ single-valued blocks \([p,q]\) and \([q+1,r]\), the PAVA merges these two blocks by replacing them with the larger block \([p,r]\). The PAVA terminates once all the single-valued blocks are in-order.

```
0:\(J=\{,,,[n,n]\}\), \(_{i},i=1,2,,n\).
0:\(\{y_{1}^{*},y_{2}^{*},,y_{N}^{*}\}\)
1:for each \([i,i] J\)do
2: Compute the minimizer \(v_{[i,i]}\) of \(_{i}()\)
3:endfor
4:while exists out-of-order blocks in \(J\)do
5: Find consecutive out-of-order blocks \(C=\{[s_{k},s_{k+1}],[s_{k+1}+1,s_{k+2}],,[s_{k+t}+1,s_{k+t+1}]\}\).
6:\(J J C\{[s_{k},s_{k+t+1}]\}\), compute the minimizer \(v_{[s_{k},s_{k+t+1}]}\) of \(_{i=s_{k}}^{s_{k+t+1}}_{i}()\).
7:endwhile
8:for each \([m,n] J\)do
9:\(y_{i}^{*}=v_{[m,n]},\; i=m,m+1,,n\).
10:endfor ```

**Algorithm 2** A refined pool-adjacent-violators algorithm for solving problem (10)

Traditional PAVA processes the merging of _out-of-order_ blocks one by one, identifying two consecutive _out-of-order_ blocks and then solving a single unconstrained convex minimization problem to merge them. For constant \(_{i}\), our proposed Algorithm 2, however, leverages the unique structure of our problem to improve the PAVA's efficiency. Specifically, we can identify and merge multiple consecutive _out-of-order_ blocks, thereby accelerating computation. This acceleration is facilitated by the inherent properties of our problem. Notably, in case the spectral risk and the rank-ranged loss, the function \(_{i}(z_{i})\) demonstrates strong convexity due to the presence of the quadratic term \((z_{i}-m_{i})^{2}\) and the convex nature of \(l(z_{i})\). This key observation leads us to the following proposition.

**Proposition 1**: _For constant \(_{i}\), suppose \(v_{[m,n]}>v_{[n+1,p]}\), the blocks \([m,n]\) and \([n+1,p]\) are consecutive out-of-order blocks. We merge these two blocks into \([m,p]\). Then the block optimal value, denoted by \(v_{[m,p]}\), satisfies \(v_{[n+1,p]} v_{[m,p]} v_{[m,n]}\)._

Proposition 1 provides a crucial insight: when we encounter consecutive _out-of-order_ blocks with a length greater than 2, we can merge them simultaneously, rather than performing individual block merges. This approach significantly improves the efficiency of the algorithm. To illustrate this concept, consider a scenario where we have a sequence of values arranged as \(v_{}>v_{}>v_{}\). Initially, we merge the blocks \(\) and \(\), resulting in \(v_{} v_{}>v_{}\). However, since \(v_{}\) is still greater than \(v_{}\), we need to merge the blocks \(\) and \(\) as well. Rather than calculating \(v_{}\) separately, we can streamline the process by directly merging the entire sequence into a single block, namely \(\), in a single operation. By leveraging this approach, we eliminate the need for intermediate calculations and reduce the computational burden associated with merging individual blocks. This results in a more efficient version of the PAVA. Further details can be found in Appendix B.3.

It is worth noting that when \(_{i}(z_{i})\) is convex with respect to \(z_{i}\), the PAVA guarantees to find a global minimizer . However, when considering the empirical human risk minimization with CPT-weight in (4), the function \(_{i}(z_{i})\) is nonconvex, which is because \(_{i}\) is a piecewise function with two different values. In such cases, we can still find a point that satisfies the first-order condition [12, Theorem 3]. In summary, we always have

\[_{}L_{}(^{k+1},;^{k}).\] (11)

### Convergence Analysis of Algorithm 1

We now demonstrate that Algorithm 1 is guaranteed to converge to an \(\)-KKT point of problem (9). To this end, we shall make the following assumptions.

**Assumption 2**: _The sequence \(\{^{k}\}\) is bounded and satisfies \(_{k=1}^{}\|^{k}-^{k+1}\|^{2}<.\)_

It is worth noting that Assumption 2 is commonly employed in ADMM approaches .

Next, we present our convergence result based on the aforementioned assumptions. As mentioned in Section 3.2, the PAVA can always find a solution for the \(\)-subproblem that satisfies the first-order condition (11). When \(_{i}\) is constant, which is the case of the spectral risk and the AoRR risk, the subproblems of PAVA are strongly convex, and we can observe the descent property of the \(\)-subproblem:

\[L_{}(^{k},^{k},^{k})-L_{}(^{k+1},^ {k},^{k}) 0.\] (12)

However, if \(_{i}\) has different values for \(\) less than and larger than the reference point \(B\) as in (4), the subproblems of PAVA may lose convexity, and the descent property may not hold. Thus, we assume that (12) holds for simplicity. By noting that the \(w\)-subproblem can be solved exactly as it is strongly convex, we make the following assumption.

**Assumption 3**: _The \(\)-subproblem is solved exactly, and the \(\)-subproblem is solved such that (11) and (12) hold._

**Theorem 1**: _Assume that Assumptions 1, 2 and 3 hold. Then Algorithm 1 can find an \(\)-KKT point \((^{k+1},^{k+1},^{k+1})\) of problem (9) within \(O(1/^{2})\) iterations, i.e.,_

\[(-^{k+1},(^{k+1} )),(D^{}^{k+1},  g(^{k+1})),\|^{k+1}-D ^{k+1}\|,\]

_where \((,A)=\{\|-\|:\; A\}\) defines the distance of a point \(\) to a set \(A\)._

In the absence of Assumption 2, a common assumption for nonconvex ADMM is that \(g()\) possesses a Lipschitz continuous gradient , e.g., \(g()=\|\|^{2}\). Under this assumption, Algorithm 1 guarantees to find an \(\)-KKT point within \(O(1/^{2})\) iterations .

## 4 ADMM for a Smoothed Version of Problem (1)

In Section 3.3, our convergence result is established under Assumption 2 when a nonsmooth regularizer \(g()\) is present. In this section, to remove this assumption, we design a variant of the proximal ADMM by smoothing the regularizer \(g()\). We employ the Moreau envelope to smooth \(g()\) and replace \(g()\) in Algorithm 1 with \(M_{g,}()\). We point out that \(M_{g,}()\) is a \(^{-1}\) weakly convex function if \(0<c\). Thus the \(w\)-subproblem is still strongly convex and can be solved exactly. See Appendix A.1 for proof. We assume that the sequence \(\{^{k}\}\) is bounded, which is much weaker than Assumption 2. We will show that within \(O(1/^{4})\) iterations, \((^{k},}^{k},^{k})\) is an \(\)-KKT point, where \(}^{k}=_{g,}(^{k})\).

To compensate for the absence of Assumption 2, we introduce the following more practical assumptions.

**Assumption 4**: _We assume \(^{k} Im(D)\; k\), where \(Im(D)=\{D:^{d}\}.\)_

A stronger version of Assumption 4 is that \(DD^{}=(()X)(()X)^{}=()XX^{}() 0\). It is worth noting that the full row rank property of the data matrix is often assumed in the high dimensional setting classification (\(m<d\) and each entry of \(\) belongs to \(\{-1,1\}\)). Here we do not impose any assumptions on the rank of data matrix \(X\).

**Assumption 5**: \( M_{g,}()\) _is bounded by \(M>0\), i.e., \(\| M_{g,}()\| M,\;^{n}.\)_

Regarding nonsmooth regularizers, Assumption 5 is satisfied by weakly convex functions that are Lipschitz continuous , due to the fact that Lipschitz continuity implies bounded subgradients and (8). Common regularizers such as \(l_{1}\)-norm, MCP and SCAD are all Lipschitz continuous.

The following proposition establishes the relationship between \(\{(^{k},^{k},^{k})\}\) and \(\{(^{k},}^{k},^{k})\}\).

**Proposition 2**: _Suppose \(g\) is \(c\)-weakly convex and Assumption 3 holds. Suppose the sequence \(\{(^{k},^{k},^{k})\}\) is produced during the iterations of Algorithm 1 with replacing \(g()\) by \(M_{g,}()\) and \(}^{k}=_{g,}(^{k})\). Then we have_

\[(^{k+1})+^{k+1}+ D( ^{k+1}-^{k}), D^{T}^{k+1}+r(^{k}-^{k +1}) g(}^{k+1}).\] (13)

Before presenting our main results, we introduce a Lyapunov function that plays a significant role in our analysis:

\[^{k}=L_{}(^{k},^{k},^{k})+}{}\|^{k}-^{k-1}\|^{2}.\]

The following lemma demonstrates the sufficient decrease property for \(^{k}\).

**Lemma 1**: _Let \(r>^{-1}\). Under Assumptions 1, 3, 4 and 5, if \(0<c\), then we have_

\[^{k}-^{k+1}(}{2}-}{ }-})\|^{k+1}-^{k}\|^{2}+ \|^{k+1}-^{k}\|^{2}.\] (14)

The sufficient decrease property for the Lyapunov function is crucial in the proof of nonconvex ADMM. Using Lemma 1, we can control \(\|^{k+1}-^{k}\|\) and \(\|^{k+1}-^{k}\|\) through the decrease of the Lyapunov function. We are now ready to present the main result of this section.

**Theorem 2**: _Suppose \(\{^{k}\}\) is bounded. Set \(=,\ =}{},\ r=}{}\), where \(C_{1}\) and \(C_{2}\) are constants such that \(C_{2}>1\) and \(C_{1}>^{2}++4}{(2C_{2}-1)}\). Under the same assumptions in Lemma 1, Algorithm 1 with replacing \(g()\) by \(M_{g,}()\) finds an \(\)-KKT point \((^{k+1},}^{k+1},^{k+1})\) within \(O(1/^{4})\) iterations, i.e.,_

\[(-^{k+1},(^{k+1})),(D^{T}^{k+1},  g(}^{k+1})),\| ^{k+1}-D}^{k+1}\|.\]

## 5 Numerical Experiment

In this section, we perform binary classification experiments to illustrate both the robustness and the extensive applicability of our proposed algorithm.

When using the logistic loss or hinge loss as individual loss, the objective function of problem (1) can be rewritten as \(_{i=1}^{n}_{i}(1+(z_{[i]}))+g()\) or \(_{i=1}^{n}_{i}[1+z_{[i]}]_{+}+g(),\) where \(=-(X)\), and \(g()=\|\|_{2}^{2}\) or \(g()=\|\|_{1}\).

We point out some key settings:

1. For the spectral risk measures, we use the logistic loss and hinge loss as individual loss, and use \(_{1}\) and \(_{2}\) regularization with \(\) taken as \(10^{-2}\).
2. For the average of ranked range aggregate loss, we use the logistic loss and hinge loss as individual loss and use \(_{2}\) regularization with \(=10^{-4}\).
3. For the empirical human risk minimization, we use the logistic loss as individual loss, and use \(_{2}\) regularization with \(=10^{-2}\).

As shown in Section 2.1, we can apply our proposed algorithm to a variety of frameworks such as the spectral risk measure (SRM), the average of ranked-range (AoRR) aggregate loss, and the empirical human risk minimization (EHRM). We compare our algorithm with LSVRG, SGD, and DCA: LSVRG(NU) denotes LSVRG without uniformity, and LSVRG(U) denotes LSVRG with uniformity, as detailed in ; SGD denotes the stochastic subgradient method in ; DCA denotes the difference-of-convex algorithm in ; sADMM refers to the smoothed version of ADMM.

The details of our algorithm setting, more experiment settings and detailed information for each dataset are provided in Appendix B. Additional experiments with synthetic datasets are presented in Appendix C.

[MISSING_PAGE_FAIL:9]

Nevertheless, as evidenced in Table 4, our proposed algorithm achieves better objective value in a shorter time for all the instances.

## 6 Conclusion

This paper considers rank-based loss optimization with monotonically increasing loss functions and weakly convex regularizers. We propose a unified ADMM framework for rank-based loss minimization. Notably, one subproblem of the ADMM is solved efficiently by the PAVA. Numerical experiments illustrate the outperformance of our proposed algorithm, with all three practical frameworks delivering satisfactory results. We also point out some limitations of our algorithm. To effectively utilize our algorithm, individual losses must exhibit monotonicity, as this allows us to use the PAVA to solve subproblems. If the sample size is large, the PAVA's computational efficiency may be hindered, potentially limiting its overall effectiveness. Future work may explore a variant using mini-batch samples, potentially improving early-stage optimization performance and overall computational efficiency.