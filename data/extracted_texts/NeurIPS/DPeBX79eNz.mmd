# Transfer Learning with Affine Model Transformation

Shunya Minami

The Institute of Statistical Mathematics

mshunya@ism.ac.jp

&Kenji Fukumizu

The Institute of Statistical Mathematics

fukumizu@ism.ac.jp

&Yoshihiro Hayashi

The Institute of Statistical Mathematics

yhayashi@ism.ac.jp

&Ryo Yoshida

The Institute of Statistical Mathematics

yoshidar@ism.ac.jp

###### Abstract

Supervised transfer learning has received considerable attention due to its potential to boost the predictive power of machine learning in scenarios where data are scarce. Generally, a given set of source models and a dataset from a target domain are used to adapt the pre-trained models to a target domain by statistically learning domain shift and domain-specific factors. While such procedurally and intuitively plausible methods have achieved great success in a wide range of real-world applications, the lack of a theoretical basis hinders further methodological development. This paper presents a general class of transfer learning regression called affine model transfer, following the principle of expected-square loss minimization. It is shown that the affine model transfer broadly encompasses various existing methods, including the most common procedure based on neural feature extractors. Furthermore, the current paper clarifies theoretical properties of the affine model transfer such as generalization error and excess risk. Through several case studies, we demonstrate the practical benefits of modeling and estimating inter-domain commonality and domain-specific factors separately with the affine-type transfer models.

## 1 Introduction

Transfer learning (TL) is a methodology to improve the predictive performance of machine learning in a target domain with limited data by reusing knowledge gained from training in related source domains. Its great potential has been demonstrated in various real-world problems, including computer vision , natural language processing , biology , and materials science . Notably, most of the outstanding successes of TL to date have relied on the feature extraction ability of deep neural networks. For example, a conventional method reuses feature representations encoded in an intermediate layer of a pre-trained model as an input for the target task or uses samples from the target domain to fine-tune the parameters of the pre-trained source model . While such methods are operationally plausible and intuitive, they lack methodological principles and remain theoretically unexplored in terms of their learning capability for limited data. This study develops a principled methodology generally applicable to various kinds of TL.

In this study, we focus on supervised TL settings. In particular, we deal with settings where, given feature representations obtained from training in the source domain, we use samples from the target domain to model and estimate the domain shift to the target. This procedure is called hypothesis transfer learning (HTL); several methods have been proposed, such as using a linear transformation function  and considering a general class of continuous transformation functions . If the transformation function appropriately captures the functional relationship between the source and target domains, only the domain-specific factors need to be additionally learned, which can be done efficiently even with a limited sample size. In other words, the performance of HTL depends stronglyon whether the transformation function appropriately represents the cross-domain shift. However, the general methodology for modeling and estimating such domain shifts has been less studied.

This study derives a theoretically optimal class of supervised TL that minimizes the expected \(_{2}\) loss function of the HTL. The resulting function class takes the form of an affine coupling \(g_{1}(})+g_{2}(}) g_{3}()\) of three functions \(g_{1},g_{2}\) and \(g_{3}\), where the shift from a given source feature \(f_{s}\) to the target domain is represented by the functions \(g_{1}\) and \(g_{2}\), and the domain-specific factors are represented by \(g_{3}()\) for any given input \(\). These functions can be estimated simultaneously using conventional supervised learning algorithms such as kernel methods or deep neural networks. Hereafter, we refer to this framework as the _affine model transfer_. As described later, we can formulate a wide variety of TL algorithms within the affine model transfer, including the widely used neural feature extractors, offset and scale HTLs [10; 11; 12], and Bayesian TL . We clarify theoretical properties of the affine model transfer such as generalization error and excess risk.

To summarize, the contributions of our study are as follows:

* The affine model transfer is proposed to adapt source features to the target domain by separately estimating cross-domain shift and domain-specific factors.
* The affine form is derived theoretically as an optimal class based on the squared loss for the target task.
* The affine model transfer encompasses several existing TL methods, including neural feature extraction. It can work with any type of source model, including non-machine learning models such as physical models as well as multiple source models.
* For each of the three functions \(g_{1}\), \(g_{2}\), and \(g_{3}\), we provide an efficient and stable estimation algorithm when modeled using the kernel method.
* Two theoretical properties of the affine transfer model are shown: the generalization and the excess risk bound.

With several applications, we compare the affine model transfer with other TL algorithms, discuss its strengths, and demonstrate the advantage of being able to estimate cross-domain shifts and domain-specific factors separately.

## 2 Transfer Learning via Transformation Function

### Affine Model Transfer

This study considers regression problems with squared loss. We assume that the output of the target domain \(y\) follows \(y=f_{t}()+\), where \(f_{t}:\) is the true model on the target domain, and the observation noise \(\) has mean zero and variance \(^{2}\). We are given \(n\) samples \(\{(_{i},y_{i})\}_{i=1}^{n}()^{n}\) from the target domain and the feature representation \(}()_{s}\) from one or more source domains. Typically, \(}\) is given as a vector, including the output of the source models, observed data in the source domains, or learned features in a pre-trained model, but it can also be a non-vector feature such as a tensor, graph, or text. Hereafter, \(}\) is referred to as the source features.

In this paper, we focus on transfer learning with variable transformations as proposed in . For an illustration of the concept, consider the case where there exists a relationship between the true functions \(f_{s}^{*}()\) and \(f_{t}^{*}()\) such that \(f_{t}^{*}()=f_{s}^{*}()+^{}^{*}, ^{d}\) with an unknown parameter \(^{*}^{d}\). If \(f_{s}^{*}\) is non-smooth, a large number of training samples is needed to learn \(f_{t}^{*}\) directly. However, since the difference \(f_{t}^{*}-f_{s}^{*}\) is a linear function with respect to the unknown \(^{*}\), it can be learned with fewer samples if prior information about \(f_{s}^{*}\) is available. For example, a target model can be obtained by adding \(f_{s}\) to the model \(g\) trained for the intermediate variable \(z=y-f_{s}()\).

The following is a slight generalization of TL procedure provided in :

1. With the source features, perform a variable transformation of the observed outputs as \(z_{i}=(y_{i},}(_{i}))\), using the data transformation function \(:_{s}\).
2. Train an intermediate model \(()\) using the transformed sample set \(\{(_{i},z_{i})\}_{i=1}^{n}\) to predict the transformed output \(z\) for any given \(\).
3. Obtain a target model \(}()=((),}())\) using the model transformation function \(:_{s}\) that combines \(\) and \(}\) to define a predictor.

In particular,  considers the case where the model transformation function is equal to the inverse of the data transformation function. We consider a more general case that eliminates this constraint.

The objective of step 1 is to identify a transformation \(\) that maps the output variable \(y\) to the intermediate variable \(z\), making the variable suitable for learning. In step 2, a predictive model for \(z\) is constructed. Since the data is limited in many TL setups, a simple model, such as a linear model, should be used as \(g\). Step 3 is to transform the intermediate model \(g\) into a predictive model \(f_{t}\) for the original output \(y\).

This class of TL includes several approaches proposed in previous studies. For example,  proposed a learning algorithm consisting of linear data transformation and linear model transformation: \(\!=\!y\!-\!,}\) and \(\!=\!g()\!+\!,}\) with pre-defined weights \(\). In this case, factors unexplained by the linear combination of source features are learned with \(g\), and the target output is predicted additively with the common factor \(,}\) and the additionally learned \(g\). In , it is shown that a type of Bayesian TL is equivalent to using the following transformation functions; for \(_{s}\), \(\!=\!(y\!-\! f_{s})/(1\!-\!)\) and \(\!=\! g()\!+\!(1\!-\!)f_{s}\) with two varying hyperparameters \(\!<\!1\) and \(0\!\!\!\!1\). This includes TL using density ratio estimation  and neural network-based fine-tuning as special cases when the two hyperparameters belong to specific regions.

The performance of this TL strongly depends on the design of the two transformation functions \(\) and \(\). In the sequel, we theoretically derive the optimal form of transformation functions under the squared loss scenario. For simplicity, we denote the transformation functions as \(_{f,}()\!=\!(,})\) on \(\) and \(_{f_{s}}()\!=\!(,})\) on \(\). To derive the optimal class of \(\) and \(\), note first that the TL procedure described above can be formulated in population as solving two successive least square problems;

\[(i)\;g^{*}:=_{g}_{p_{t}}\|_{f_{s}}(Y)-g( )\|^{2},(ii)\;_{}_{p_{t}}\|Y-_{ f_{s}}(g^{*}())\|^{2}.\]

Since the regression function that minimizes the mean squared error is the conditional mean, the first problem is solved by \(g^{*}_{}()=[_{f_{s}}(Y)|= ]\), which depends on \(\). We can thus consider the optimal transformation functions \(\) and \(\) by the following minimization:

\[_{,}_{p_{t}}\|Y-_{f_{s}}(g^{*}_{} ())\|^{2}.\] (1)

It is easy to see that Eq. (1) is equivalent to the following consistency condition:

\[_{f_{s}}g^{*}_{}()=_{p_{t}}[Y| =].\]

From the above observation, we make three assumptions to derive the optimal form of \(\) and \(\):

**Assumption 2.1** (Differentiability).: The data transformation function \(\) is differentiable with respect to the first argument.

**Assumption 2.2** (Invertibility).: The model transformation function \(\) is invertible with respect to the first argument, i.e., its inverse \(_{f_{s}}^{-1}\) exists.

**Assumption 2.3** (Consistency).: For any distribution on the target domain \(p_{t}(,y)\), and for all \(\),

\[_{f_{s}}(g^{*}())=_{p_{t}}[Y|= ],\]

where \(g^{*}()=_{p_{t}}[_{f_{s}}(Y)|= ]\).

Assumption 2.2 is commonly used in most existing HTL settings, such as  and . It assumes a one-to-one correspondence between the predictive value \(_{t}()\) and the output of the intermediate model \(()\). If this assumption does not hold, then multiple values of \(\) correspond to the same predicted value \(_{t}\), which is unnatural. Note that Assumption 2.3 corresponds to the unbiased condition of .

We now derive the properties that the optimal transformation functions must satisfy.

**Theorem 2.4**.: _Under Assumptions 2.1-2.3, the transformation functions \(\) and \(\) satisfy the following two properties:_

\[(i)\;\;\;_{f_{s}}^{-1}=_{f_{s}}.(ii)\;\;\; _{f_{s}}(g)=g_{1}(})+g_{2}(}) g,\]

_where \(g_{1}\) and \(g_{2}\) are some functions._The proof is given in Section D.1 in Supplementary Material. Despite not initially assuming that the two transformation functions are inverses, Theorem 2.4 implies they must indeed be inverses. Furthermore, the mean squared error is minimized when the data and model transformation functions are given by an affine transformation and its inverse, respectively. In summary, under the expected squared loss minimization with the HTL procedure, the optimal class for HTL model is expressed as follows:

\[= g_{1}(})+g_{2}(})g_{3}( {x}) g_{j}_{j},j=1,2,3},\]

where \(_{1},_{2}\) and \(_{3}\) are the arbitrarily function classes. Here, each of \(g_{1}\) and \(g_{2}\) is modeled as a function of \(}\) that represents common factors across the source and target domains. \(g_{3}\) is modeled as a function of \(\), in order to capture the domain-specific factors unexplainable by the source features.

We have derived the optimal form of the transformation functions when the squared loss is employed. Even for general convex loss functions, (i) of Theorem 2.4 still holds. However, (ii) of Theorem 2.4 does not generally hold because the optimal transformation function depends on the loss function. Extensions to other losses are briefly discussed in Section A.1, but the establishment of a complete theory is a future work.

Here, the affine transformation is found to be optimal in terms of minimizing the mean squared error. We can also derive the same optimal function by minimizing the upper bound of the estimation error in the HTL procedure, as discussed in Section A.2.

One of key principles for the design of \(g_{1}\), \(g_{2}\), and \(g_{3}\) is interpretability. In our model, \(g_{1}\) and \(g_{2}\) primarily facilitate knowledge transfer, while the estimated \(g_{3}\) is used to gain insight on domain-specific factors. For instance, in order to infer cross-domain differences, we could design \(g_{1}\) and \(g_{2}\) by the conventional neural feature extraction, and a simple, highly interpretable model such as a linear model could be used for \(g_{3}\). Thus, observing the estimated regression coefficients in \(g_{3}\), one can statistically infer which features of \(\) are related to inter-domain differences. This advantage of the proposed method is demonstrated in Section 5.2 and Section B.3.

### Relation to Existing Methods

The affine model transfer encompasses some existing TL procedures. For example, by setting \(g_{1}(})=0\) and \(g_{2}(})=1\), the prediction model is estimated without using the source features, which corresponds to an ordinary direct learning, i.e., a learning scheme without transfer. Furthermore, various kinds of HTLs can be formulated by imposing constraints on \(g_{1}\) and \(g_{2}\). In prior work,  employs a two-step procedure where the source features are combined with pre-defined weights, and then the auxiliary model is additionally learned for the residuals unexplainable by the source features. The affine model transfer can represent this HTL as a special case by setting \(g_{2}=1\).  uses the transformed output \(z_{i}=y_{i}/f_{s}\) with the output value \(f_{s}\) of a source model, and this cross-domain shift is then regressed onto \(\) using a target dataset. This HTL corresponds to \(g_{1}=0\) and \(g_{2}=f_{s}\).

When a pre-trained source model is provided as a neural network, TL is usually performed with the intermediate layer as input to the model in the target domain. This is called a feature extractor or frozen featurizer and has been experimentally and theoretically proven to have strong transfer capability as the de facto standard for TL [9; 15]. The affine model transfer encompasses the neural feature extraction as a special subclass, which is equivalent to setting \(g_{2}(})g_{3}()=0\). A performance comparison of the affine model transfer with the neural feature extraction is presented in Section 5 and Section B.2. The relationships between these existing methods and the affine model transfer are illustrated in Figure 1 and Figure S.1

The affine model transfer can also be interpreted as generalizing the feature extraction by adding a product term \(g_{2}(})g_{3}()\). This additional term allows for the inclusion of unknown factors in the transferred model that are unexplainable by source features alone. Furthermore, this encourages the avoidance of a negative transfer, a phenomenon where prior learning experiences interfere with training in a new task. The usual TL based only on \(}\) attempts to explain and predict the data generation process in the target domain using only the source features. However, in the presence of domain-specific factors, a negative transfer can occur owing to a lack of descriptive power. The additional term compensates for this shortcoming. The comparison of behavior for the case with the non-relative source features is described in Section 5.1.

he affine model transfer can be naturally expressed as an architecture of network networks. This architecture, called affine coupling layers, is widely used for invertible neural networks in flow-based generative modeling [16; 17]. Neural networks based on affine coupling layers have been proven to have universal approximation ability . This implies that the affine transfer model has the potential to represent a wide range of function classes, despite its simple architecture based on the affine coupling of three functions.

## 3 Modeling and Estimation

In this section, we focus on using kernel methods for the affine transfer model and provide the estimation algorithm. Let \(_{1},_{2}\) and \(_{3}\) be reproducing kernel Hilbert spaces (RKHSs) with positive-definite kernels \(k_{1},k_{2}\) and \(k_{3}\), which define the feature mappings \(_{1}\!:\!_{s}\!\!_{1}\), \(_{2}\!:\!_{s}\!\!_{2}\) and \(_{3}\!:\!\!\!_{3}\), respectively. Denote \(_{1,i}\!=\!_{1}(}(_{i})),_{2,i}\!=\!_{2}(}(_{i})),_{3,i}\!=\!_{3}(_{i})\). For the proposed model class, the \(_{2}\)-regularized empirical risk with the squared loss is given as follows:

\[F_{,,}=_{i=1}^{n}y_{i}\!-\! ,_{1,i}\!-\!,_{2,i},_ {3,i}}^{2}+_{1}\|\|^{2}_{_{1}}+_ {2}\|\|^{2}_{_{2}}+_{3}\|\|^{2}_{_{3}},\] (2)

where \(_{1}\),\(_{2}\),\(_{3}\!\!0\) are hyperparameters for the regularization. According to the representer theorem, the minimizer of \(F_{,,}\) with respect to the parameters \(_{1}\), \(_{2}\), and \(_{3}\) reduces to \(=_{i=1}^{n}a_{i}_{1,i},=_{i=1}^{n}b_{i}_{2,i}, =_{i=1}^{n}c_{i}_{3,i},\) with the \(n\)-dimensional unknown parameter vectors \(,,^{n}\). Substituting this expression into Eq. (2), we obtain the objective function as

\[F_{,,}=\|y\!-\!K_{1}\!-\!(K_{2}) (K_{3})\|^{2}_{2}\!+\!_{1}^{}K_{1}\!+\!_{2 }^{}K_{2}\!+\!_{3}^{}K_{3}\!=:\!F(, ,).\] (3)

Here, the symbol \(\) denotes the Hadamard product. \(K_{I}\) is the Gram matrix associated with the kernel \(k_{I}\) for \(I\{1,2,3\}\). \(k_{I}^{(i)}=[k_{I}(_{i},_{1}) k_{I}(_{i},_{n})]^ {}\) denotes the \(i\)-th column of the Gram matrix. The \(n n\) matrix \(M^{(i)}\) is given by the tensor product \(M^{(i)}=k_{2}^{(i)} k_{3}^{(i)}\) of \(k_{2}^{(i)}\) and \(k_{3}^{(i)}\).

Because the model is linear with respect to parameter \(a\) and bilinear for \(b\) and \(c\), the optimization of Eq. (3) can be solved using well-established techniques for the low-rank tensor regression. In this study, we use the block relaxation algorithm  as described in Algorithm 1. It updates \(a,b\), and \(c\) by repeatedly fixing two of the three parameters and minimizing the objective function for the remaining one. Fixing two parameters, the resulting subproblem can be solved analytically because the objective function is expressed in a quadratic form for the remaining parameter.

``` Initialize:\(_{0}\), \(_{0}\), \(_{0}\) repeat \(_{t+1}=_{}\,F(,\ _{t},\,_{t})\)\(_{t+1}=_{}\,F(_{t+1},\,,\ _{t})\)\(_{t+1}=_{}\,F(_{t+1},\,_{t+1},\,)\) until convergence ```

**Algorithm 1** Block relaxation algorithm .

Algorithm 1 can be regarded as repeating the HTL procedure introduced in Section 2.1; alternately estimates the parameters \((,)\) of the transformation function and the parameters \(\) of the model for the given transformed data \(\{(_{i},z_{i})\}_{i=1}^{n}\). The function \(F\) in Algorithm 1 is not jointly convex in general. However, when employing methods like kernel methods or generalized linear models, and fixing two parameters, \(F\) exhibits convexity with respect to the remaining parameter. According to , when each sub-minimization problem is convex, Algorithm 1 is guaranteed to converge to a stationary point. Furthermore,  showed that consistency and asymptotic normality hold for the alternating minimization algorithm.

## 4 Theoretical Results

In this section, we present two theoretical properties, the generalization bound and excess risk bound.

Figure 1: Architectures of (a) feature extraction, (b) HTL in , and (c) affine model transfer.

Let \((,P)\) be an arbitrary probability space, and \(\{z_{i}\}_{i=1}^{n}\) be independent random variables with distribution \(P\). For a function \(f\!\!\), let the expectation of \(f\) with respect to \(P\) and its empirical counterpart denote respectively by \(Pf=_{P}f(z),P_{n}f=_{i=1}^{n}f(z_{i})\). We use a non-negative loss \((y,y^{})\) such that it is bounded from above by \(L>0\) and for any fixed \(y^{}\), \(y\!\!(y,y^{})\) is \(_{}\)-Lipschitz for some \(_{}>0\).

Recall that the function class proposed in this work is

\[=x g_{1}(})+g_{2}(})g_{3}()  g_{j},j=1,2,3}.\]

In particular, the following discussion in this section assumes that \(g_{1},g_{2}\), and \(g_{3}\) are represented by linear functions on the RKHSs.

### Generalization Bound

The optimization problem is expressed as follows:

\[_{,,}P_{n}y,\,,_{1}_{ _{1}}+,_{2}_{_{2}}, _{3}_{_{3}}+_{}\|\|_{ _{1}}^{2}+_{}\|\|_{_{2}}^{2}+_{ }\|\|_{_{3}}^{2},\] (4)

where \(_{1}=_{1}(}()),_{2}=_{2}(}())\) and \(_{3}=_{3}()\) denote the feature maps. Without loss of generality, it is assumed that \(\|_{i}\|_{_{i}}^{2} 1\) (\(i=1,2,3\)) and \(_{},_{},_{}>0\). Hereafter, we will omit the suffixes \(_{i}\) in the norms if there is no confusion.

Let \((,,)\) be a solution of Eq. (4), and denote the corresponding function in \(\) as \(\). For any \(\), we have

\[_{}\|\|^{2}\!\!P_{n}(y,,\!_{1}\!+\!,\!_{2}\!,\!_{3})\!+\!_{}\|\|^{2}\!+\! _{}\|\|^{2}\!+\!_{}\|\|^{2}\! \!P_{n}(y,,\!_{1}\!)\!+\!_{}\| \|^{2},\]

where we use the fact that \((,)\) and \(\|\|\) are non-negative, and \((,,)\) is the minimizer of Eq. (4). Denoting \(_{s}=_{}\{P_{n}(y,,_{1})+_ {}\|\|^{2}\}\), we obtain \(\|\|^{2}_{}^{-1}_{s}\). Because the same inequality holds for \(_{}\|\|^{2},_{}\|\|^{2}\) and \(P_{n}(y,)\), we have \(\|\|^{2}_{}^{-1}_{s},\|\|^{2} _{}^{-1}_{s}\) and \(P_{n}(y,)_{s}\). Moreover, we have \(P(y,)=P_{n}(y,)_{s}\). Therefore, it is sufficient to consider the following hypothesis class \(}\) and loss class \(\):

\[}= x\!\!,\!_{1}\!+\! ,\!_{2}\!,\!_{3}}\|^{2}\! \!_{}^{-1}_{s},\,\|\|^{2}\!\!_{}^{- 1}_{s},\,\|\|^{2}\!\!_{}^{-1}_{s},P(y, h)\!\!_{s}},\] \[= (x,y)(y,h)\ \ h}}.\]

Here, we show the generalization bound of the proposed model class. The following theorem is based on , showing that the difference between the generalization error and empirical error can be bounded using the magnitude of the relevance of the domains.

**Theorem 4.1**.: _There exists a constant \(C\) depending only on \(_{},_{},_{}\) and \(L\) such that, for any \(>0\) and \(h}\), with probability at least \(1-e^{-}\),_

\[P(y,\,h)-P_{n}(y,\,h)=\ }{n}}+ ^{2}C^{2}+}{n}C++ +}{n},\]

_where \(R_{s}=_{}\{P(y,,_{1})+_{}\| \|^{2}\}\)._

Because \(_{1}\) is the feature map from the source feature space \(_{s}\) into the RKHS \(_{1}\), \(R_{s}\) corresponds to the true risk of training in the target domain using only the source features \(f_{s}\). If this is sufficiently small, e.g., \(R_{s}=(n^{-1/2})\), the convergence rate indicated by Theorem 4.1 becomes \(n^{-1}\), which is an improvement over the naive convergence rate \(n^{-1/2}\). This means that if the source task yields feature representations strongly related to the target domain, training in the target domain is accelerated. Theorem 4.1 measures this cross-domain relation using the metric \(R_{s}\).

Theorem 4.1 is based on Theorem 11 of  in which the function class \(g_{1}\!+\!g_{3}\) is considered. Our work differs in the following two points: the source features are modeled not only additively but also multiplicatively, i.e., we consider the function class \(g_{1}\!+\!g_{2}\!\!g_{3}\), and we also consider the estimation of the parameters for the source feature combination, i.e., the parameters of the functions \(g_{1}\) and \(g_{2}\). In particular, the latter affects the resulting rate. With fixed the source combination parameters, the resulting rate improves only up to \(n^{-3/4}\). The details are discussed in Section D.2.

### Excess Risk Bound

Here, we analyze the excess risk, which is the difference between the risk of the estimated function and the smallest possible risk within the function class.

Recall that we consider the functions \(g_{1},g_{2}\) and \(g_{3}\) to be elements of the RKHSs \(_{1},_{2}\) and \(_{3}\) with kernels \(k_{1},k_{2}\) and \(k_{3}\), respectively. Define the kernel \(k^{(1)}\!=\!k_{1}\), \(k^{(2)}\!=\!k_{2}\!\!k_{3}\) and \(k\!=\!k^{(1)}+k^{(2)}\). Let \(^{(1)},^{(2)}\) and \(\) be the RKHS with \(k^{(1)},k^{(2)}\) and \(k\) respectively. For \(m\!=\!1,2\), consider the normalized Gram matrix \(K^{(m)}\!=\!(k^{(m)}(_{i},_{j}))_{i,j=1,,n}\) and its eigenvalues \((_{i}^{(m)})_{i=1}^{n}\), arranged in a nonincreasing order.

We make the following additional assumptions:

**Assumption 4.2**.: There exists \(h^{*}\) and \(h^{(m)*}^{(m)}\) (\(m=1,2\)) such that \(P(y-h^{*}())^{2}=_{h}P(y-h())^{2}\) and \(P(y-h^{(m)*}())^{2}=_{h^{(m)}}P(y-h())^{2}\).

**Assumption 4.3**.: For \(m=1,2\), there exist \(a_{m}>0\) and \(s_{m}(0,1)\) such that \(_{j}^{(m)} a_{m}j^{-1/s_{m}}\).

Assumption 4.2 is used in  and is not overly restrictive as it holds for many regularization algorithms and convex, uniformly bounded function classes. In the analysis of kernel methods, Assumption 4.3 is standard , and is known to be equivalent to the classical covering or entropy number assumption . The inverse decay rate \(s_{m}\) measures the complexity of the RKHS, with larger values corresponding to more complex function spaces.

**Theorem 4.4**.: _Let \(\) be any element of \(\) satisfying \(P_{n}(y-())^{2}=_{h}P_{n}(y-h())^{2}\). Under Assumptions 4.2 and 4.3, for any \(>0\), with probability at least \(1-5e^{-}\),_

\[P(y-())^{2}-P(y-h^{*}())^{2}=On^{-,s_{2})}}}.\]

Theorem 4.4 suggests that the convergence rate of the excess risk depends on the decay rates of the eigenvalues of two Gram matrices \(K^{(1)}\) and \(K^{(2)}\). The inverse decay rate \(s_{1}\) of the eigenvalues of \(K^{(1)}\!=\!(k_{1}(}(_{i}),}(_{j})))_{ i,j=1,,n}\) represents the learning efficiency using only the source features, while \(s_{2}\) is the inverse decay rate of the eigenvalues of the Hadamard product of \(K_{2}=(k_{2}(}(_{i}),}(_{j}))_{i,j=1, ,n}\) and \(K_{3}=(k_{3}(_{i},_{j}))_{i,j=1,,n}\), which addresses the effect of combining the source features and original input. While rigorous discussion on the relationship between the spectra of two Gram matrices \(K_{2},K_{3}\) and their Hadamard product \(K_{2}\!\!K_{3}\) seems difficult, intuitively, the smaller the overlap between the space spanned by the source features and by the original input, the smaller the overlap between \(_{2}\) and \(_{3}\). In other words, as the source features and original input have different information, the tensor product \(_{2}\!\!_{3}\) will be more complex, and the decay rate \(1/s_{2}\) is expected to be larger. In Section B.1, we experimentally confirm this speculation.

## 5 Experimental Results

We demonstrate the potential of the affine model transfer through two case studies: (i) the prediction of feed-forward torque at seven joints of the robot arm , and (ii) the prediction of review scores and decisions of scientific papers . The experimental details are presented in Section C. Additionally, two case studies in materials science are presented in Section B. The Python code is available at https://github.com/mshunya/AffineTL.

### Kinematics of the Robot Arm

We experimentally investigated the learning performance of the affine model transfer, compared to several existing methods. The objective of the task is to predict the feed-forward torques, required to follow the desired trajectory, at seven different joints of the SARCOS robot arm . Twenty-one features representing the joint position, velocity, and acceleration were used as the input \(\). The target task is to predict the torque value at one joint. The representations encoded in the intermediate layer of the source neural network for predicting the other six joints were used as the source features \(}^{16}\). The experiments were conducted with seven different tasks (denoted as Torque 1-7) corresponding to the seven joints. For each target task, a training set of size \(n\{5,10,15,20,30,40,50\}\) was randomly constructed 20 times, and the performances were evaluated using the test data.

The following seven methods were compared, including two existing HTL procedures:

* **Direct** Train a model using the target input \(\) with no transfer.
* **Only source** Train a model \(g(})\) using only the source feature \(}\).
* **Augmented** Perform a regression with the augmented input vector concatenating \(\) and \(}\).
* **HTL-offset** Calculate the transformed output \(z_{i}=y_{i}-g_{}(})\) where \(g_{}(})\) is the model pre-trained using **Only source**, and train an additional model with input \(_{i}\) to predict \(z_{i}\).
* **HTL-scale** Calculate the transformed output \(z_{i}=y_{i}/g_{}(})\), and train an additional model with input \(_{i}\) to predict \(z_{i}\).
* **AffineTL-full** Train the model \(g_{1}+g_{2} g_{3}\).
* **AffineTL-const** Train the model \(g_{1}+g_{3}\).

Kernel ridge regression with the Gaussian kernel \((-\|-^{}\|^{2}/2^{2})\) was used for each procedure. The scale parameter \(\) was fixed to the square root of the dimension of the input. The regularization parameter in the kernel ridge regression and \(_{},_{}\), and \(_{}\) in the affine model transfer were selected through 5-fold cross-validation. In addition to the seven feature-based methods, four weight-based TL methods were evaluated: fine-tuning, MAML , \(L^{2}\)-SP , and PAC-Net .

Table 1 summarizes the prediction performance of the seven different procedures for varying numbers of training samples in two representative tasks: Torque 1 and Torque 7. The joint of Torque 1 is located closest to the root of the arm. Therefore, the learning task for Torque 1 is less relevant to those for the other joints, and the transfer from Torque 2-6 to Torque 1 would not work. In fact, as shown in Table 1, no method showed a statistically significant improvement to **Direct**. In particular, **Only source** failed to acquire predictive ability, and **HTL-offset** and **HTL-scale** likewise showed poor prediction performance owing to the negative effect of the failure in the variable transformation. In contrast, the two affine transfer models showed almost the same predictive performance as **Direct**, which is expressed as its submodel, and successfully suppressed the occurrence of negative transfer.

Because Torque 7 was measured at the joint closest to the end of the arm, its value strongly depends on those at the other six joints, and the procedures with the source features were more effective than in the other tasks. In particular, **AffineTL** achieved the best performance among the other feature-based methods. This is consistent with the theoretical result that the transfer capability of the affine model transfer can be further improved when the risk of learning using only the source features is sufficiently small.

    &  &  &  \\   & & 5 & 10 & 15 & 20 & 30 & 40 & 50 \\   & Direct & \(21.3 2.04\) & \(18.9 2.11\) & \(\) & \(15.8 1.70\) & \(13.7 1.26\) & \(12.2 1.61\) & \(10.8 1.23\) \\  & Only source & \(24.0 6.37\) & \(22.3 3.10\) & \(21.0 2.49\) & \(19.7 1.34\) & \(18.5 1.92\) & \(17.6 1.59\) & \(17.3 1.31\) \\  & Augmented & \(21.8 2.88\) & \(19.2 1.37\) & \(17.8 2.30\) & \(\) & \(\) & \(\) & \(\) \\  & HTL-offset & \(23.7 6.50\) & \(21.2 3.85\) & \(19.8 2.33\) & \(17.8 2.85\) & \(12.6 2.31\) & \(15.0 3.16\) & \(15.1 2.76\) \\  & HTL-scale & \(23.3 4.47\) & \(21.2 5.31\) & \(20.4 3.84\) & \(18.5 2.72\) & \(17.6 2.41\) & \(16.9 2.10\) & \(16.7 1.74\) \\  & Affine-full & **21.2\( 2.21\)** & **18.8\( 1.34\)** & \(18.6 2.83\) & \(15.9 1.65\) & \(17.3 1.53\) & \(12.3 1.45\) & \(11.1 1.22\) \\  & AffineTL-const & \(21.2 2.21\) & **18.8\( 1.44\)** & \(17.7 2.44\) & \(15.9 1.58\) & \(13.4 1.15\) & \(12.2 1.54\) & \(10.9 1.02\) \\  & Fine-tune & \(25.0 7.11\) & \(20.5 3.33\) & \(18.6 2.10\) & \(17.6 2.55\) & \(14.1 1.39\) & \(12.6 1.13\) & \(11.1 1.03\) \\  & MAML & \(28.9 1.23\) & \(22.8 3.21\) & \(20.8 2.12\) & \(20.3 3.14\) & \(16.7 2.00\) & \(14.4 1.85\) & \(13.4 1.19\) \\  & \(L^{2}\)-SP & \(24.9 7.03\) & \(20.5 3.30\) & \(18.8 2.04\) & \(18.0 2.45\) & \(14.5 1.36\) & \(13.0 1.13\) & \(11.6 0.933\) \\  & PAC-Net & \(25.2 8.68\) & \(22.5 5.60\) & \(20.7 2.65\) & \(20.1 2.16\) & \(18.5 2.77\) & \(17.6 1.85\) & \(17.1 1.38\) \\   & Direct & \(2.66 0.30\) & \(21.3 0.42\) & \(1.85 0.418\) & \(15.4 0.33\) & \(13.2 0.20\) & \(11.8 0.13\) & \(10.8 0.111\) \\  & Only source & \(23.1 0.618\) & \(17.3 0.50\) & \(14.9 0.513\) & \(12.2 0.269\) & \(1.09 0.232\) & \(0.96 0.144\) & \(0.92 0.170\) \\  & Augmented & \(2.47 0.46\) & \(10.9 0.515\) & \(1.67 0.522\) & \(1.31 0.244\) & \(11.16 0.225\) & \(0.98 0.149\) & \(0.87 0.138\) \\  & HTL-offset & \(2.29 0.621\) & \(\) & \(1.49 0.513\) & \(1.22 0.269\) & \(1.09 0.233\) & \(0.96 0.144\) & \(0.92 0.171\) \\  & HTL-scale & \(2.32 0.599\) & \(1.71 0.515\) & \(1.51 0.513\) & \(1.24 0.217\) & \(1.11 0.234\) & \(0.99 0.175\) & \(0.94 0.172\) \\  & AffineTL-full & \(\) & \(\) was represented by a two-gram bag-of-words vector of the abstract. For the source features \(}\), we utilized text embeddings of the abstract generated by the pre-trained language models; BERT , SciBERT , T5 , and GPT-3 . In the affine model transfer, we employed neural networks with two hidden layers to model \(g_{1}\) and \(g_{2}\), and a linear model for \(g_{3}\). For comparison, we also evaluated the performance of the ordinary feature extraction-based TL using a two-layer neural network with \(}\) as inputs. We used 8,166 training samples and evaluated the performance of the model on 2,043 test samples.

Table 2 shows the root mean square error (RMSE) for the regression task and accuracy for the classification task. In the regression tasks, the RMSEs of the affine model transfer were significantly improved over the ordinary feature extraction for the four types of text feature embedding. We also observed the improvements in accuracy for the classification task even though the affine model transfer was derived on the basis of regression settings. While the pre-trained language models have the remarkable ability to represent text quality and structure, their representation ability to perform prediction tasks for machine learning documents is not sufficient. The affine model transfer effectively bridged this gap by learning the additional target-specific factor via the target task, resulting in improved prediction performance in both regression and classification tasks.

Table 3 provides a list of phrases that were estimated to have a positive or negative effect on the review scores. Because we restricted a network to output positive values for \(g_{2}\), the influence of each phrase could be inferred from the estimated coefficients of the linear model \(g_{3}\). Specifically, phrases such as _"tasks including"_ and _"new state"_ were estimated to have positive influences on the predicted score. These phrases often appear in contexts such as _"demonstrated on a wide range of tasks including"_ or _"establishing a new state-of-the-art result,"_, suggesting that superior experimental results tend to yield higher peer review scores. In addition, the phrase _"theoretical analysis"_ was also identified to have a positive effect on the review score, reflecting the significance of theoretical validation in machine learning research. On the contrary, general phrases with broader meanings such as _"recent advances"_ and _"machine learning,"_ contributed to lower scores. This observation suggests the importance of explicitly stating the novelty and uniqueness of research findings and refraining from using generic terminologies.

As illustrated in this example, integrating modern deep learning techniques and highly interpretable transfer models through the mechanism of the affine model transfer not only enhances prediction performance, but also provides valuable insights into domain-specific factors.

### Case Studies in Materials Science

We conducted two additional case studies, both of which pertain to scientific tasks in the field of materials science. One experiment aims to examine the relationship between qualitative differences in source features and learning behavior of the affine model transfer. In the other experiment, we demonstrate the potential utility of the affine model transfer as a calibration tool bridging computational models and real-world systems. In particular, we highlight the benefits of separately modeling and estimating domain-specific factors through a case study in polymer chemistry. The objective is to predict the specific heat capacity at constant pressure of any given organic polymer with its chemical structure in the polymer's repeating unit. Specifically, we conduct TL to bridge the gap between experimental values and physical properties calculated from molecular dynamics simulations. The details are shown in Section B in Supplementary Material,

## 6 Conclusions

In this study, we introduced a general class of TL based on affine model transformations, and clarified their learning capability and applicability. The proposed affine model transformation was shown to be an optimal class that minimizes the expected squared loss in the HTL procedure. The model is contrasted with widely applied TL methods, such as re-using features from pre-trained models, which lack theoretical foundation. The affine model transfer is model-agnostic; it is easily combined with any machine learning models, features, and physical models. Furthermore, in the model, domain-specific factors are involved in incorporating the source features. From this property, the affine transfer has the ability to handle domain common and unique factors simultaneously and separately.

The advantages of the model were verified theoretically and experimentally in this study. We showed theoretical results on the generalization bound and excess risk bound when the regression tasks are solved by kernel methods. It is shown that if the source feature is strongly related to the target domain, the convergence rate of the generalization bound is improved from naive learning. The excess risk of the proposed TL is evaluated using the eigen-decay of the product kernel, which also illustrates the effect of the overlap between the source and target tasks. In our numerical studies, the affine model transfer generally outperforms in test errors when the target and source tasks have a similarity. We have also seen in the example of NLP that the proposed affine model transfer can identify the (non-)valuable phrases for high-quality papers. This can be done by the affine representation of cross-domain shift and domain-specific factors in our model.

    &  & Classification \\   & FE & 1.3086 \(\) 0.0035 & 0.6250 \(\) 0.0217 \\  & AffineTL & **1.3069 \(\) 0.0042** & **0.6252 \(\) 0.0163** \\   & FE & 1.2856 \(\) 0.0144 & **0.6520 \(\) 0.0106** \\  & AffineTL & **1.2797 \(\) 0.0122** & 0.6507 \(\) 0.0124 \\   & FE & 1.3486 \(\) 0.0175 & 0.6344 \(\) 0.0079 \\  & AffineTL & **1.3442 \(\) 0.0030** & **0.6366 \(\) 0.0065** \\   & FE & 1.3284 \(\) 0.0138 & 0.6279 \(\) 0.0181 \\  & AffineTL & **1.3234 \(\) 0.0140** & **0.6386 \(\) 0.0095** \\   

Table 2: Prediction performance of peer review scores and acceptance/rejection for submitted papers. The mean and standard deviation of the RMSE and accuracy are reported for the affine model transfer (AffineTL) and feature extraction (FE). Definitions of asterisks and boldface letters are the same as in Table 1.

    & Positive & Negative \\ 
1 & tasks including & recent advances \\
2 & new state & novel approach \\
3 & high quality & latent space \\
4 & recently proposed & learning approach \\
5 & latent variable & neural architecture \\
6 & number parameters & machine learning \\
7 & theoretical analysis & attention mechanism \\
8 & policy gradient & reinforcement learning \\
9 & inductive bias & proposed framework \\
10 & image generation & descent sgd \\   

Table 3: Phrases with the top and bottom ten regression coefficients for \(g_{3}\) in the affine transfer model for the regression task with SciBERT.