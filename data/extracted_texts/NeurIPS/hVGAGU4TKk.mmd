# NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction

Yifan Wang\({}^{1,2}\)   Di Huang\({}^{2}\)   Weicai Ye\({}^{2,3,85}\)   Guofeng Zhang\({}^{3}\)   Wanli Ouyang\({}^{2}\)   Tong He\({}^{2,85}\)

\({}^{1}\)Shanghai Jiao Tong University  \({}^{2}\)Shanghai Artificial Intelligence Laboratory

\({}^{3}\)State Key Lab of CAD&CG, Zhejiang University

maikeyeweicai@gmail.com   tonghe90@gmail.com

###### Abstract

Signed Distance Function (SDF)-based volume rendering has demonstrated significant capabilities in surface reconstruction. Although promising, SDF-based methods often fail to capture detailed geometric structures, resulting in visible defects. By comparing SDF-based volume rendering to density-based volume rendering, we identify two main factors within the SDF-based approach that degrade surface quality: _SDF-to-density representation_ and _geometric regularization_. These factors introduce challenges that hinder the optimization of the SDF field. To address these issues, we introduce **NeuRodin**, a novel two-stage neural surface reconstruction framework that not only achieves high-fidelity surface reconstruction but also retains the flexible optimization characteristics of density-based methods. **NeuRodin** incorporates innovative strategies that facilitate transformation of arbitrary topologies and reduce artifacts associated with density bias. Extensive evaluations on the Tanks and Temples and ScanNet++ datasets demonstrate the superiority of **NeuRodin**, showing strong reconstruction capabilities for both indoor and outdoor environments using solely posed RGB captures. Project website: [https://open3dvlab.github.io/NeuRodin/](https://open3dvlab.github.io/NeuRodin/)

Figure 1: We present **NeuRodin**, a novel two-stage framework designed for high-fidelity neural surface reconstruction with intricate structures. Requiring only posed RGB captures as inputs, **NeuRodin** not only recovers large-scale areas but also accurately reconstructs fine-grained details.

## 1 Introduction

3D surface reconstruction [34; 16; 35; 28; 8; 24; 26; 40; 39; 14; 12; 2; 38; 25] is a long-standing research topic in the field of computer vision. This process involves using images to recover the underlying 3D geometry, typically represented as meshes. These reconstructed meshes find diverse applications in various domains, including video games and augmented/virtual reality systems. In this paper, we specifically address the challenge of reconstructing 3D surfaces from posed RGB images.

Inspired by the density-based representation  for task of novel view synthesis, recent works for neural surface reconstruction commonly introduce signed distance functions (SDF) [28; 35] to recover high-quality geometry.

However, incorporating SDF to the density function is nontrivial and often fails to intricate geometric details. We illustrate this by comparing two methods for reconstructing the same scene: _Instant-NGP_, which employs density-based volume rendering, and _Neuralangelo_, which utilizes SDF-based volume rendering. Both methods use a similar multi-resolution hash table representation. The mesh is produced by is by TSDF-fusion  for _Instant-NGP_. As illustrated in Figure 2, _Instant-NGP_ reconstructs surfaces with accurate localization albeit with a certain roughness, while _Neuralangelo_ produces smoother surfaces yet encounters issues in correctly positioning portions of the surface. This disparity underscores the limitations and highlights the need for improved modeling capabilities in SDF-based surface reconstruction methods.

_Why do SDF-based surface reconstruction methods face challenges in accurately capturing intricate geometric details, and how can these methods be improved?_ In this paper, we thoroughly analyze the reconstruction pipeline and identify two primary factors in current SDF-based pipelines that contribute to suboptimal surface reconstruction:

* _SDF-to-density conversion:_ SDF-based volume rendering requires a conversion function to relate the SDF field with the density field. Existing methods use a conversion function that assigns uniform density across the same level sets, which restricts the representation of arbitrary non-negative density values. Additionally, there is no assurance that the geometric representation within a volume rendering framework will align perfectly with the implicit surface. This misalignment often results in accurate visual renderings on incorrect surfaces, due to inherent biases.
* _Geometric regularization:_ Regularization constraints imposed on the implicit surface can limit topological changes during optimization. These constraints often introduce biases, complicating the convergence of the model and hindering its ability to accurately represent complex geometries.

To tackle these challenges, we introduce NeuRodin (Figure 1), a high-fidelity 3D surface reconstruction method that innovatively overcomes the limitations previously outlined. Firstly, we refine the SDF-to-density conversion by transitioning from a global scale parameter to a local adaptive parameter. Unlike previous methods that enforce the same densities for points with identical SDF values, our approach enhances the flexibility and effectiveness of the SDF function by allowing adaptive density values. Secondly, we implement a novel loss function designed to align the maximum probability distance with the zero-level set in volume rendering, improving the alignment of geometric representations. Additionally, We incorporates above innovations within a two-stage optimization framework to tackle the over-regularization imposed by geometric constraints. Initially, we employ a coarse optimization stage in which the SDF field operates similarly to a density field,

Figure 2: **Comparative analysis of SDF-based and density-based volume rendering methods.****(a)** Neuralangelo  experiences difficulties with topological transformations, leading to incorrect surfaces. **(b)** Instant-NGP  approximates the correct surface positioning yet produces a noisy surface. **(c)** Our method achieves high-quality surfaces with fine details.

exhibiting minimal influence from topological transformations. Subsequently, a refinement stage is conducted to achieve a surface with enhanced smoothness. We also introduce the stochastic-step numerical gradient estimation technique to mantain a natural zero level set for the coarse stage. With the design described, our method enables high-fidelity surface reconstruction suited to both large-scale and intricate geometries.

We conducted extensive experiments on the Tanks and Temples dataset  and the ScanNet++ dataset , where our method demonstrated superior performance over the previous state-of-the-art in both indoor and outdoor environments. Notably, recognizing the lack of an established benchmark for ScanNet++, we executed comparative analyses using six baseline methods and established a new benchmark for ScanNet++ reconstruction, significantly enriching the community resources and setting a foundation for future research. In comparative tests, our model outperformed Neuralangelo on the Tanks and Temples training set, delivering superior results with only 1/8 the parameters of the comparative model. Our approach excels in optimizing complex topological structures and preserving intricate details, enabling high-fidelity, fine-grained surface reconstruction.

## 2 Related Work

**Multi-view 3D reconstruction.** In traditional 3D surface reconstruction, methods based on Multi-View Stereo (MVS) have long been prevalent, serving as a foundational approach for mining sparse geometric data from multiple views and generate detailed 3D models by comparing and analyzing the disparities across multiple camera perspectives. The traditional MVS methods , while effective in texture-rich domains, often stumble upon the challenge of processing ambiguous observations. The point clouds produced by traditional MVS methods suffer from noise, undermining the reliability of the surface triangle meshes reconstructed from these point clouds. For learning-based MVS methods [34; 44; 33; 32], the generated point clouds are still plagued by noise, leading to consistently incomplete reconstructions.

**Neural surface reconstruction.** NeRF [16; 37; 10; 17] pioneers the use of neural network to represent neural radiance fields for novel view synthesis and optimizes these scenes through differentiable volume rendering. Following NeRF, subsequent research has combined implicit surfaces with differentiable volume rendering [19; 28; 35]. These methods typically represent implicit surfaces as SDF and use the zero-level set of SDFs to describe geometry, achieving high-quality reconstruction on individual objects. Various improvements have been made based on this foundation, including the incorporation of different positional encoding to enhance representational capabilities [22; 29; 47; 48] and the introduction of additional priors to deal with surfaces that exhibit specular highlights or have low textures [43; 27]. Several studies refine the modeling of SDF-to-density conversion [46; 31] to address bias issues in density. Meanwhile, other works employ patch-match techniques to improve multi-view consistency [5; 7]. Neuralangelo  enhances the network's representational capability by introducing hash encoding. Additionally, it proposes numerical gradients and coarse-to-fine optimization strategies to enhance the quality of surface reconstruction.

## 3 Study on SDF-based Volume Rendering

### Preliminary

Density-based volume renderingDensity-based volume rendering methods model a 3D scene as a volume density field. Given a camera position \(\) and view direction \(\), the ray emitted from \(\) in direction \(\) is denoted as \(\{(t)=+t|t>0\}\). A set of \(n\) points is sampled along this ray. The predicted density \(((t))\) and geometry features \(((t))\) of the point \((t)\) are obtained from a geometry network \(_{}\). the density is parameterized by an activation function, such as ReLU, softplus, or the exp function, prior to being output by the network.

A color network \(_{}\) predicts the color \(((t),)\), taking as inputs the geometry feature \(((t))\), and the viewing direction \(\). The rendered color of this ray can be calculated as:

\[()=_{0}^{+}T(t)((t))( (t)), T(t)=(-_{0}^{t}((u))du). \]The networks are trained to minimize a color loss \(_{}\) that quantifies the difference between the rendered colors and the ground truth colors:

\[_{}=_{}\|( )-C()\|_{1}, \]

with \(\) representing the set of \(m\) rays in each training batch and \(C()\) being the ground-truth color of ray \(\).

SDF-based volume renderingSDF-based volume rendering methods, such as NeuS  and VolSDF , combine volume rendering with an SDF representation. Unlike density-based methods, the geometry is represented as the zero level set of the SDF. The predicted SDF \(f((t))\) and geometry feature \(((t))\) at the point \((t)\) are obtained from the geometry network \(_{}\). Then, the SDF \(f((t))\) is transformed into density \(((t))\) by a predefined function \(\) and a global scale \(s\). For instance, VolSDF defines the density as the scaled cumulative distribution function of the negative SDF:

\[((t))=_{s}(f((t)))= ((t))}{s})&f((t)) 0,\\ (1-((t))}{s}) )&f((t))<0. \]

Moreover, to encourage the SDF to have a unit norm gradient, the Eikonal loss  is often employed:

\[_{}=_{,t}(\| f( (t))\|-1)^{2}. \]

Incorporating this loss not only helps to avoid suboptimal solutions at the zero level set but also promotes smoothness. The networks are trained under the supervision of both the color loss \(_{}\) and the Eikonal loss \(_{}\).

### Challenges in Previous SDF-Based Volume Rendering

State-of-the-art SDF-based volume rendering techniques frequently fail to reconstruct surfaces with accuracy in scenarios where density-based methods manage to renders realistic novel views. This disparity highlights the inherent limitations of SDF-based volume rendering approaches. To further elucidate these issues, we explore the fundamental distinctions between SDF-based and density-based volume rendering. Please refer to the appendix for a more in-depth analysis.

Unsuitable assumption for SDF-to-density conversion.SDF-based volume rendering methods typically employ a predefined function \(\) and a global scale parameter \(s\) to convert SDF values into density, as described by Equation (3). These methods often result in uniform density values for points sharing identical SDF values. Such a global scaling mechanism restricts the representation capability of the density field derived from the SDF field. Intuitively, previous top-performing methods for novel view synthesis can generate arbitrary non-negative density values within \((0,+)\). In contrast, incorporating SDF representation with a global scaling factor for surface reconstruction can only result in density values within \((0,]\).

Bias of the density.When applying an Eikonal constraint or any form of smooth regularization to an SDF, the geometric representation within the rendering framework must align with that of the SDF. Unfortunately, current SDF-based methods often fail to ensure this alignment, particularly at larger-scale parameters \(s\) as explored mathematically in  to analyze this issue. Recent studies  have attempted to tackle this issue, proposing designs for SDF to density conversion that aim to minimize bias. Despite these advancements, these solutions still exhibit inherent biases. Additionally, the introduction of geometric regularization often exacerbates this bias, complicating model convergence and resulting in the creation of inaccurate surfaces. A more detailed analysis of this issue is provided in Section 4.2 and Appendix B to Appendix D.

Over-regularization of Geometry.To maintain a high-quality surface, previous methods often introduce geometric constraints, such as Eikonal loss or smoothness constraints. However, these global constraints result in excessive smoothing across all regions, both flat and intricate, leading to a loss of fine details. Moreover, in the framework of SDF-based volume rendering, the prediction of color typically necessitates being conditioned on normals following IDR , a characteristic that distinctly sets it apart from the density-based volume rendering approach. When optimizing the color conditioned on the normal and explicitly constraining the SDF by geometric regularization, the optimization process restricts the topological structure. Please refer to the Appendix F for the impact on the normal condition.

## 4 Method

### Uniform SDF, Diverse Densities

To deal with the representation limitations of SDF-transformed density, instead of using a global scale \(s\) for the transformation from SDF to density, we have employed a strategy akin to that of , which utilizes a non-linear mapping to obtain the unique scale \(s\) associated with a given point \((t)\). More precisely, it is defined as follows:

\[(f((t)),s((t)),((t)))=_{ }((t)),((t))=_{s((t))}(f( (t))). \]

With this particular design, the density is not identical within the same SDF level set and can achieve any non-negative value through the continuous representation that maps an input coordinate to its corresponding scale.

This approach ensures that densities within the same SDF level set are no longer uniformly identical. Instead, they can vary, achieving any non-negative value through a continuous representation that maps input coordinates to their corresponding scales. This design greatly enhances the flexibility and accuracy of our density modeling, enabling more realistic and detailed reconstructions. More detailed analysis regarding the local scale can be found in Appendix A.

### Explicit Bias Correction

The issue of bias represents a critical concern frequently addressed within SDF-based volume rendering. As demonstrated in Figure 3, it is necessary to align the geometric representation under the volume rendering framework with that of the implicit surface. For the volume rendering framework, the most intuitive way to represent geometry is through the _rendered distance_:

\[_{}()=_{0}^{+}\,T(t)((t))t\,t. \]

We can also consider the position where \(w(t)\) is maximized -- that is, the probability that the light ray arrives and collides is the greatest, or in other words, the location that contributes the most to the color -- as the geometric representation within the volume rendering framework:

\[_{}()=*{arg\,max}_{t(0,+)}w( t)=*{arg\,max}_{t(0,+)}T(t)((t)). \]

We shall refer to \(_{}()\) as the _maximum probability distance_. For an implicit surface, _the zero level set_ offers a direct geometric representation. In an ideal scenario, irrespective of whether convergence has been achieved, the geometric representations of volume rendering (i.e., _rendered distance_ and _maximum probability distance_) and the geometric representation of the implicit surface (i.e., _zero level set_) should be aligned, as illustrated in Figure 3 (a). However, in the practical optimization process, conflicts such as those depicted in Figure 3 (b) may arise, leading to misalignment between the two representations.

Multiple past methods have broached this topic, offering various solutions. For example, in TUVR , an unbiased model is proposed and it is mathematically proven that the zero-crossing point of the SDF is at a local maximum of rendering weight. However, bias still exists. The experimental analysis is presented in Section 5.3. In the work

Figure 3: **Visualization of the bias of the density.****(a)** An ideal scenario where the geometry of the volume rendering scheme (_A: maximum probability distance_ and _B: rendered distance_) aligns precisely with the geometry of the implicit surface (_C: zero level set_). (b) A biased scenario showcasing misalignment.

of , a penalty is imposed on the rendered distance to ensure that its SDF value is equal to zero. However, it is important to note that the rendered distance is subject to significant distortion due to existing biases, particularly in the early stages of convergence as shown in Figure 3 (b). We offer further analysis from Appendix B and Appendix D.

We propose an explicit bias correction in which we opt to deliberately align the maximum probability distance with the zero level set. Specifically, we define

\[_{}=_{}( f((t^{*}+_{})),0), t^{*}=*{ arg\,max}_{t(0,+)}T(t)((t)), \]

where \(_{}\) is a bias correction factor. The loss function is designed to penalize the positive portion of \(f((t^{*}+_{}))\), which encourages the SDF to take on negative values after the maximum probability distance. We have shown in Appendix C that manually scheduling the lower bound of the local scale, coupled with the penalty after the point of maximum probability distance, can effectively alleviate bias issues. During the experiment, we approximate \(t^{*}\) by directly using the sampled point with the largest \(w(t)\), which, despite introducing a certain degree of deviation, does not affect the overall effectiveness. Please refer to Appendix C for details on the design.

### Two-Stage Optimization to Tackle Geometry Over-Regularization

Previous methods often produce incorrect surfaces due to over-regularization of geometry as shown in Figure 2 (a). However, we have discovered that methods based on density are not constrained by changes in topology as shown in Figure 2 (b), prompting us to question whether the SDF field can be first optimized as freely as density field, then refine to a smooth surface by geometry regularization. We now propose a novel two-stage optimization approach. This approach allows the optimization process to initially mimic density-based behavior in the first stage and subsequently refines to a smooth surface in the second stage.

For the first stage, our objective is to tackle the over-regularization issue. An intuitive solution might be to eliminate or downweight any geometric constraints and avoid conditioning the color on the predicted normal, but this approach often results in an unnatural zero level set [9; 28; 35; 36]. We experimentally validated in the Appendix H.6.

We have identified a simple but effective method to preserve the natural level sets of large-scale structures while allowing the formation of complex structures to be unimpeded by geometric regularization. Instead of applying geometric regularization directly to the gradient \( f((t))\), we elect to impose them upon an estimated gradient \(f((t))\), to which we introduce uncertainty through a specific design. Specifically, the \(x\)-component of the estimated gradient is

\[_{x}f((t))=(t)+_{x} )-f((t)-_{x})}{2},_{x}=(,0,0) U(0,_{}). \]

The gradient is calculated through finite differences similar to those described in [13; 21]. However, the step size for gradient estimation at each iteration is stochastically sampled from a uniform distribution in the range of \((0,_{})\).

Using this technique, we observed that estimated larger-scale normals have smaller variance, while fine details exhibit larger variance, as depicted in Figure 4. This introduces uncertainty in geometric regularization, ensuring stability for large features and flexibility for complex details. We provide further explanation in Appendix E.

During the initial stage, our goal is to reconstruct the approximate, coarse structure of the 3D content. This is primarily addressed by tackling the issues of over-regularization and the bias in density estimation that we previously mentioned. We employ the stochastic-step numerical gradient estimation along with the explicit bias correction to address the initial reconstruction of the coarse

Figure 4: The heatmap for the variance of the normal predicted using random step.

  Metric &  \\  Scene & NeuralWarp & COLMAP & Neus & Geo-Neus & NeuS-NSOr & MonoSDF & Neuralangelo\({}^{*}\) & Neuralangelo & Ours \\  Bann & 0.22 & 0.55 & 0.29 & 0.33 & 0.46 & 0.49 & 0.61 & **0.70** & **0.70** \\ Caterpillar & 0.18 & 0.01 & 0.29 & 0.26 & 0.32 & 0.31 & 0.34 & **0.36** & **0.36** \\ Courthouse & 0.08 & 0.11 & 0.17 & 0.12 & 0.08 & 0.12 & 0.13 & **0.28** & 0.21 \\ Ignatius & 0.02 & 0.22 & 0.83 & 0.72 & 0.81 & 0.78 & 0.82 & **0.89** & 0.87 \\ Meetingroom & 0.08 & 0.19 & 0.24 & 0.20 & 0.08 & 0.23 & 0.22 & 0.32 & **0.43** \\ Track & 0.35 & 0.19 & 0.45 & 0.45 & 0.44 & 0.42 & 0.45 & **0.48** & 0.47 \\  Mean & 0.15 & 0.21 & 0.38 & 0.35 & 0.37 & 0.39 & 0.43 & 0.50 & **0.51** \\  

Table 1: **Quantitative evaluation of our method on the Tanks and Temples training subset. The best performance and the second-best outcomes are highlighted for easy reference. Note that the hash grid parameters used in our method is the same as Neuralangelo\({}^{*}\), which possesses \(2^{19}\) hash entries per resolution.**

Figure 5: **Quantitative comparison on the training subset of Tanks and Temples dataset.**

structure of the 3D content. Additionally, we utilize VoIDFâ€™s SDF-to-density conversion, with the local scale modeling delineated in Equation 5, to facilitate this primary formulation. Consequently, the training loss at this stage is formulated as:

\[_{}=_{}+_{} _{}(f)+_{}_{ }. \]

During the refinement stage, we discontinue the use of the estimated gradients given that the fundamental 3D content has been initially restored and the issue of over-regularization no longer presents a concern. In a similar vein, we move past the explicit bias correction, as the significant surface errors induced by bias were initially addressed in the first stage. We incorporate a standard Eikonal loss alongside a smoothness constraint from PermutoSDF  to enforce local smoothness:

\[_{}=_{,t}( ((t))((t)+_{s} ((t)))-1)^{2}, \]

where \(((t))=((t))\) and \(\) is a random unit vector. Furthermore, as the model nears convergence at this stage, we adopt the SDF-to-density conversion method proposed by TUVR , which ensures minimal bias and preserves fine object details. The loss function employed in the second phase is defined as follows:

\[_{}=_{}+_{} _{}( f)+_{}_{}. \]

## 5 Experiments

**Experimental setup.** We carry out experimental evaluations on two benchmark datasets: Tanks and Temples  and ScanNet++ . We include several baselines for comparisons: VoIDSF , NeuralWarp , COLMAP , NeuS , Geo-NeuS , Neuralangelo  and MonoSDF . We extract mesh through marching cube algorithm with a resolution of 2048 applied across all scenes and report the F-score for suface evaluation. More details are provided in the supplementary materials. Please refer to Appendix H for additional experimental results.

### Tanks and Temples

NeuRodin outperforms previous state-of-the-art methods in terms of the average F-score. Owing to our explicit bias correction technique, the barn's roof maintains its structural integrity withoutcollapsing as shown at the top of Figure 5, a marked improvement over other methods which often fail to prevent such collapse. Thanks to our two-stage optimization approach, we effectively mitigate the issue of excessive geometric regularization as shown at the bottom of Figure 5. Consequently, NeuRodin achieves a more detailed surface representation than Neuralangelo with 1/8 fewer parameters.

It is evident that our method outperforms previous work on the Tanks and Temples advance subset as shown in Table 2. In the comparison in Figure 6, we demonstrate enhanced accuracy and completeness when reconstructing large-scale surfaces, alongside capturing more fine-grained details compared to Neuralangelo. Benefiting from our explicit bias correction in the first stage and the TUVR modeling employed in the second stage, fine structures are restored to the zero level set in the initial phase and maintain a sufficiently small bias in the subsequent phase, thus enabling the refinement of high-quality surfaces.

### ScanNet++ Benchmark

Since no public results are available for the ScanNet++ dataset, we randomly selected 8 scenes to construct a benchmark. For more details and results on our ScanNet++ benchmark, please refer to the supplementary materials. Quantitative results are shown in Table 3. We surpassed the methods we compared against in most scenes and achieved comparable results to those with prior knowledge in terms of F-score. We provide more visual result on ScanNet++ dataset in the supplementary.

### Analysis

**Ablation Study.** To validate the efficacy of the proposed techniques, we performed an ablation study on scene _Meetingroom_ from Tanks and Temples dataset. As illustrated in Figure 7 (a), applying a global scale for SDF-to-density conversion results in inaccurate surfaces, primarily due to the

  Method & VolSDF & MonoSDF & Neuralangelo\({}^{*}\) & Neuralangelo & Ours \\  Mean & 6.72 & 20.89 & 22.14 & 26.28 & **28.84** \\  

Table 2: **Quantitative evaluation of our method versus prior work on the Tanks and Temples advance subset.** The **best** performance and the _second_-best outcomes are highlighted for easy reference.

  F-Score \(\) &  &  \\  method & NeuS & VolSDF & Neuralangelo\({}^{*}\) & Neuralangelo & Ours & MonoSDF-MLP & MonoSDF-Grid \\  Mean & 0.455 & 0.391 & 0.507 & 0.564 & 0.638 & 0.439 & **0.642** \\  

Table 3: **Quantitative evaluation of our method versus prior work on the ScanNet++ dataset.** The **best** performance and the _second_-best outcomes are highlighted for easy reference.

Figure 6: **Quantitative evaluation of our method on the Tanks and Temples advance subset.**

assumption of uniform density across the same level sets. This assumption leads to the convergence of surfaces with subtler textures to incorrect locations. Figure 7 (b) demonstrates that the absence of stochastic-step numerical gradient estimation hinders the model's ability to form arbitrary topologies, leading to incorrect surfaces. The incorrect ground collapsing depicted in Figure 7 (c) is due to the bias in density, creating inconsistencies as shown in Figure 3(c). Without the application of our proposed explicit bias correction, this bias issue causes visibly incorrect surfaces. Figure 7 (d) presents the outcomes of optimization conducted in a single phase; under stochastic-step numerical gradient estimation, the Eikonal loss's preference for smoothness is somewhat compromised, resulting in a rougher surface finish. Finally, Figure 7 (e) showcases our full model, which achieves high-fidelity smooth surfaces while preserving most details. We conducted additional ablation experiments in Appendix H.6.

**Analysis on Stochastic-step Numerical Gradient Estimation.** We further demonstrate experimentally the impact of our stochastic-step numerical gradient estimation on the optimization process, as illustrated in Figure 8. The depth maps produced indicate that Model A is severely constrained by geometric regularization, making it difficult to alter its topological structure during optimization. Model B employs a progressive numerical gradient estimation technique that, even after 7500 steps, does not yield an accurate depth map. However, utilizing our stochastic-step numerical gradient estimation, we achieve an approximately accurate scene geometry in as few as 7500 steps.

At this stage, the depth map of Model C is similar to that of Instant-NGP, yet ours displays a more natural and smooth depth profile. This suggests that our approach, similar to instant-NGP, is capable of freely altering topological shapes for optimization, while also maintaining a natural zero-level set surface.

Furthermore, final mesh of Model B still manifests inaccurate floor collapses, whereas mesh of model C, with our stochastic-step numerical gradient estimation, maintains correct and smooth floors. This is attributed to the fact that the floor, being a large scale, allows our stochasticity to continuously apply the Eikonal constraint on large-scale areas. This results in a natural zero level set in these vast regions. However, for progressive steps, once the step size is reduced beyond a certain point, it no longer imposes the Eikonal constraint on large-scale surfaces, resulting in unnatural zero level sets.

**Analysis on Explicit Bias Correction.** To substantiate the versatility and effectiveness of our explicit bias correction approach, we further conducted experiments to verify its potential as a plug-and-play correction method independent of our full model. We implemented this correction technique on our coarse stage and tested it across various renderers, including NeuS, VolSDF, and TUVR. These experiments were designed to evaluate the adaptability and efficacy of our bias correction in diverse SDF-to-density modelings.

As depicted in Figure 9, the ceiling of the room displays a pronounced bias issue that leads to a collapse. However, with the application of our proposed explicit bias correction approach, the issue of ceiling collapse is significantly ameliorated.

Figure 8: **Analysis on stochastic-step numerical gradient estimation.** We visualize the produced depth maps at iteration 7500 of the first stage. Model A: Change stochastic-step numerical gradient estimation to analytical gradient. Model B: Change stochastic-step numerical gradient estimation to progressive numerical gradient estimation from Neuralangelo. Model C: Ours.

Figure 7: **Ablation results.** (a) Without local scale for SDF-to-density conversion. (b) Without stochastic-step numerical gradient estimation. (c) Without explicit bias correction. (d) Without stage-two refinement. (e) Full model.

## 6 Conclusion

This paper proposes NeuRodin, a two-stage framework for high-fidelity neural surface reconstruction with intricate details. It introduces key designs to tackle SDF-based rendering challenges, notably the local scale adjustment for SDF-to-density conversion, which enables any non-negative value to be achieved, facilitating accurate density derivation from SDF. Additionally, an explicit bias correction method is employed to ensure the geometry of the volume rendering scheme coherently aligns with that of the implicit surface, thereby preventing the emergence of incorrect surfaces. Finally, a two-stage optimization strategy effectively resolves the issue of over-regularization imposed by geometric constraints. Comprehensive experiments demonstrate that NeuRodin simultaneously delivers superior quality.