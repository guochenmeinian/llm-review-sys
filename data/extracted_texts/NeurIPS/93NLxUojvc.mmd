# UltraRE: Enhancing RecEraser for Recommendation Unlearning via Error Decomposition

Yuyuan Li

College of Computer Science

Zhejiang University

Hangzhou, China

11821022@zju.edu.cn

&Chaochao Chen

College of Computer Science

Zhejiang University

Hangzhou, China

zjuccc@zju.edu.cn

&Yizhao Zhang

College of Computer Science

Zhejiang University

Hangzhou, China

22221337@zju.edu.cn

&Weiming Liu

College of Computer Science

Zhejiang University

Hangzhou, China

21831010@zju.edu.cn

&Linguan Lyu

Sony AI

Japan

lingjuan.lv@sony.com

&Xiaolin Zheng

College of Computer Science

Zhejiang University

Hangzhou, China

xlzheng@zju.edu.cn

&Dan Meng

OPPO Research Institute

Shenzhen, China

mengdan900163.com

&Jun Wang

OPPO Research Institute

Shenzhen, China

junwang.lu@gmail.com

Corresponding author.

###### Abstract

With growing concerns regarding privacy in machine learning models, regulations have committed to granting individuals the right to be forgotten while mandating companies to develop non-discriminatory machine learning systems, thereby fueling the study of the machine unlearning problem. Our attention is directed toward a practical unlearning scenario, i.e., recommendation unlearning. As the state-of-the-art framework, i.e., RecEraser, naturally achieves full unlearning completeness, our objective is to enhance it in terms of model utility and unlearning efficiency. In this paper, we rethink RecEraser from an ensemble-based perspective and focus on its three potential losses, i.e., redundancy, relevance, and combination. Under the theoretical guidance of the above three losses, we propose a new framework named UltraRE, which simplifies and powers RecEraser for recommendation tasks. Specifically, for redundancy loss, we incorporate transport weights in the clustering algorithm to optimize the equilibrium between collaboration and balance while enhancing efficiency; for relevance loss, we ensure that sub-models reach convergence on their respective group data; for combination loss, we simplify the combination estimator without compromising its efficacy. Extensive experiments on three real-world datasets demonstrate the effectiveness of UltraRE. The source codes are available at https://github.com/ZhangYizhao/UltraRE.

## 1 Introduction

Machine Learning (ML) models have made significant strides in various domains, including natural language processing , image recognition , and recommender systems [18; 27; 28]. However, privacy concerns arise due to individual data involved in training ML models. These concerns aremainly twofold. Firstly, the General Data Protection Regulation (GDPR)  provides individuals with the right to request the removal of their data, including any impact the data may have on the trained models, i.e., the right to be forgotten. Secondly, the Algorithmic Accountability Act  requires companies to evaluate the effect of their ML systems on bias and discrimination.

Machine unlearning is a practical approach that promotes privacy in ML systems by removing previously used data and learned information from ML models. Individuals can remove sensitive information that is learned through their data, while companies can proactively unlearn biased  or inaccurate  data. Unlearning methods can be divided into two approaches based on the level of completeness, namely exact unlearning (full completeness), and approximate unlearning (partial completeness).

In this paper, we concentrate on recommendation unlearning. The personalized recommendation is a typical scenario that urgently requires unlearning because (i) recommender systems rely heavily on individual data, and (ii) the performance of recommendation is highly sensitive to the quality of training data . Existing recommendation unlearning method  follows the Exact Unlearning (EU) approach. As retraining is an algorithmic way to ensure fully complete unlearning, EU approach is mainly developed on the ensemble retraining framework [4; 26; 7; 48]. Similar to the idea of ensemble learning , the ensemble retraining framework involves dividing the dataset into non-overlapping shards, training a sub-model for each shard independently, and ultimately combining all sub-models. The ensemble retraining framework limits retraining overhead to sub-models, thereby avoiding retraining from scratch on the entire dataset.

However, the ensemble retraining framework's non-overlapping division isolates user and item collaboration, which leaves considerable room for performance improvement in recommendation tasks. Guided by the intuition of collaboration preservation, RecEraser groups similar data together and combines sub-models with attention networks. In this paper, we analyze RecEraser as an ensemble system through a theoretical lens, and find that i) existing clustering algorithms exhibit an incongruity between the requirements of collaboration and balance, and ii) the usage of attention networks is not necessary. As shown in Figure 1, the lower bound of error rate \(()\) in an ensemble system can be decomposed into three components, i.e., redundancy, relevance, and combination loss . Each of these components is associated with a particular stage of the ensemble retraining framework. Considering the three loss components as a well-grounded set of metrics, we simplify and power the State-Of-The-Art (SOTA) recommendation unlearning framework, i.e., RecEraser. Specifically, for redundancy loss (stage I), we incorporate transport weights in the clustering algorithm to pursue the optimal trade-off between collaboration and balance; for relevance loss (stage II), we ensure that sub-models reach convergence on their respective shard data; for combination loss (stage III), we simplify the design of the sub-model combiner to reduce complexity without compromising its efficacy. As a result, we propose a novel recommendation unlearning framework named Ultra RecEraser (ULtraRE) that offers greater model utility and efficiency while still achieving full completeness. The main contributions of this paper are summarized as follows:

* We propose a novel ensemble retraining framework (ULtraRE) to address the problem of recommendation unlearning. UltraRE enhances both model utility and unlearning efficiency while achieving unlearning completeness at the algorithmic level.
* During stage I (non-overlapping division), we propose an optimal balanced clustering algorithm that transforms the discrete clustering problem into a continuous optimization process while incorporating a balanced constraint to achieve both balanced clustering and minimal inertia simultaneously.
* During stage III (model combination), we take an empirical investigation into the choice of model combiners, and simplify the complexity of model combiner without compromising model utility.
* We empirically validate and demonstrate the proposed framework through extensive experiments on three real-world datasets in terms of model utility and unlearning efficiency.

## 2 Preliminary

In this section, we first briefly introduce the goals and targets in recommendation unlearning, followed by the error decomposition of an ensemble system.

### Recommendation Unlearning

Unlearning Goals.As introduced in [7; 26], there are mainly three goals for an unlearning task: (G1) Unlearning completeness, which requires completely eliminating the impact of target data from a previously trained model; (G2) Unlearning efficiency, which entails maximizing the efficiency of unlearning while minimizing the need for computationally expensive retraining; and (G3) Model utility, which ensures that the unlearned model can achieve recommendation performance comparable to that of the model retrained from scratch.

As the ensemble-retaining framework belongs to the EU approach, which naturally achieves G1 at an algorithmic level, i.e., the highest level of completeness . In this paper, our objective is to enhance the quality of the ensemble-retraining framework within the recommendation context, with a view to advancing G2 and G3.

Unlearning Targets.The concept of training data holds a multifaceted view, resulting in different unlearning targets. In the context of personalized recommendation, the user-item interaction serves as the training data. Considering ratings as a form of user-item interaction, the unlearning target may differ based on the perspective, either focusing on the user-wise, item-wise, or sample-wise aspects. For instance, user-wise unlearning refers to unlearning all interactions made by the specific target user(s). In this paper, we focus on the ensemble retraining framework, which is versatile and can be applied to any type of unlearning target.

### Ensemble System

Ensemble learning has proven to be successful in various fields of machine learning. An ensemble system involves combing multiple models, such as bagging [5; 23], stacking , and mixture of experts [20; 42]. Early studies have been guided by the intuition that ensemble systems achieve better performance when employing a combination of accurate and diverse models. From a theoretical standpoint, using Fano's inequality of information theory,  decomposes the error rate of an ensemble system into three components, i.e., redundancy (model diversity), relevance (model accuracy), and combination (information lost during model combination) loss. As shown in Figure 1, the aforementioned ensemble retraining framework is basically an ensemble system. We divide the ensemble retraining into three stages, i.e., non-overlapping division, independent training, and model combination. Each stage is associated with one specific error component.

## 3 Related Work

### Machine Unlearning

Machine unlearning is the process of removing the influence of specific training data, i.e., unlearning target, from a learned model . A naive approach to achieve this is by retraining the model from

Figure 1: Decomposition of error rate  in the ensemble retraining framework which is the SOTA framework for model-agnostic exact unlearning and recommendation unlearning.

scratch on the updated dataset that excludes the target. However, this approach can be computationally prohibitive in practice. Based on the degree of unlearning completeness, existing unlearning methods can be classified into the following two approaches.

Exact Unlearning.This approach aims to ensure that unlearning target is fully unlearned, i.e., as complete as retraining from scratch. Cao and Yang  achieved this by transforming training data points into a reduced number of summations to enhance unlearning efficiency. Recently, Bourtoule et al.  proposed an ensemble retraining framework, i.e. SISA, which divides the dataset into non-overlapping subsets, trains a sub-model on each subset, and combines all sub-models in the end. This design reduces the retraining overhead to subsets. Similarly, ARCANE  divides the dataset by class and applies one-class anomaly detection training on each subset. However, ARCANE can only be applied to classification tasks.

Approximate Unlearning.This approach estimates the influence of unlearning target, and removes the influence through direct parameter manipulation [11; 13; 41; 45]. While theoretically more efficient than exact unlearning, this approach faces challenges regarding unlearning completeness, i.e., exactness, due to the inaccurate estimation of influence. In this approach, the influence of unlearning target is estimated by influence function [21; 22], which is found to be fragile in deep learning . Recent studies also point out that the influence of individual training data on deep models is intractable to compute analytically .

### Recommendation Unlearning

RecEraser was proposed to achieve unlearning in recommender systems . Following SISA's ensemble retraining framework, RecEraser groups similar data together, instead of random division. This modification effectively preserves collaborative information necessary for personalized recommendations. In addition, RecEraser uses an attention-based combination to further enhance model utility. Similarly, LASER also groups similar data together . However, instead of training a model on each subset and combining them, LASER trains a model sequentially on each subset using curriculum learning. While this modification significantly enhances model utility, it comes at the cost of reduced efficiency. Theoretically, LASER can only accelerate the unlearning speed two times compared to retraining from scratch, which is generally unsatisfying in practice. Recently, Approximate recommendation unlearning was proposed to enhance efficiency . However, it still suffers from common weaknesses of approximate unlearning and is unable to provide algorithmic unlearning completeness, which exact unlearning achieves.

## 4 Methodology

In this section, we present our UltraRE for addressing the recommendation unlearning problem. Following the design of the ensemble retraining framework, we rethink RecEraser from an ensemble-based perspective. Instructed by the error decomposition theory in ensemble systems (see Figure 1), we associate each loss component with a specific stage in the ensemble retraining framework. Our proposed UltraRE refines the design of each stage to minimize its corresponding loss component. In the following subsections, we describe in detail the modifications we propose for each stage.

### Redundancy Loss (Stage I)

In stage I, the ensemble retraining framework divides the original training data into several non-overlapping shards.

Random Balanced Division.The original framework (SISA , designed for the machine unlearning problem), uses random balanced division. The assumption that there is no prior knowledge regarding the distribution of unlearning requests is widely accepted and practical [4; 7; 26]. In the absence of such knowledge, it is optimal to presume that users submit these requests with equal probability. Therefore, in order to attain optimal unlearning efficiency, the ensemble retaining framework needs to achieve balanced division. The theoretical explanation can be found in Appendix A.

Balanced \(k\)-means.Collecting collaborative information across users and items is essential to the performance of recommendation models. With the intuition of preserving collaboration, RecEraser  uses clustering algorithms to group similar samples together. Additionally, RecEraser needs to achieve balanced division. Thus, the balanced clustering algorithms were proposed [7; 8; 26]. Assume that there are \(N\) input samples \(^{d}\) for clustering. Note that the input samples can consist of user embedding, item embedding, or a combination of both depending on the unlearning target, i.e., user-wise, item-wise, or sample-wise. The core idea of their proposed algorithm is i) limiting the maximum number of samples in one shard, typically \(|S_{i}| N/k\), ii) constructing a priority list for every _sample-centroid_ pair, and iii) assigning each sample to its destination shard by priority value.

#### 4.1.1 Optimal Balanced Clustering

The loss component for stage I is redundancy loss, which directs ensemble systems to enhance the diversity among shards . This theoretical guidance conforms with prior work's intuition of collaboration preservation, which proposes the balanced \(k\)-means algorithm to group similar samples together . However, to achieve a balanced division, balanced \(k\)-means may not always assign samples to their optimal clusters. In practice, as shown in Figure 3, this can result in a significant number of sub-optimally assigned samples, which degrades the clustering performance. To address this incongruity, we propose an Optimal Balanced Clustering (OBC) algorithm that achieves an adaptive equilibrium between **sample similarity** and **shard balance**.

Generally speaking, OBC incorporates a balanced constraint into the optimization process. As illustrated in Figure 3, we obtain the transport weight of assigning an input sample \(\) to a cluster centroid \(\) through the optimization process. The input samples are assigned to the cluster with the largest weight. To start with the derivation of OBC, we first introduce the basic concept of \(k\)-means. The \(k\)-means algorithm minimizes the total distance of each sample-centroid pair, namely inertia \(\). It is formally defined as

\[=_{j=1}^{k}_{i S_{j}}\|_{i}-_{j}\|_{2}^{2}, \ \ _{j}=}_{i}}{|S_{j}|}.\] (1)

Considering \(\) and \(\) as two variables respectively sampled from subsets \(X\) and \(Y\) in the Euclidean space \(^{d}\), the problem of inertia minimization can be framed as the Monge-Kantorovich problem.

**Problem 1** (Monge-Kantorovich Problem).: _Given the transport cost function \(c:X Y\), the objective of the Monge-Kantorovich problem is to find the joint probability measure \(P:X Y\) that minimizes the total transport cost_

\[[c(X,Y)]=_{P}_{X Y}c(,)dP(,).\] (2)

The Monge-Kantorovich problem offers the advantage of accommodating additional constraints to the probability measure. Turning back to the inertia minimization problem, we insert a set of transport

Figure 3: An illustration of different clustering algorithms. The red block located at coordinate (\(_{i}\), \(_{j}\)) represents assigning \(_{i}\) to \(_{j}\). On the left, \(k\)-means groups samples based solely on their similarity, resulting in an imbalanced result. In the middle, balanced \(k\)-means forces a balanced result by considering a similarity-based priority list. On the right, Optimal Balanced Clustering (OBC) incorporates a balanced constraint into the optimization process and assigns samples according to their transport weight values.

Figure 2: An illustration of balanced and imbalanced grouping. We conducted an experiment on a real-world dataset (ML-1M). (a) and (b) are the results of random balanced division and \(k\)-means respectively. Each color block represents one shard. The size of the block varies with the number of samples in the shard, with larger blocks representing more samples.

weights \(\) where their summation equals one into Eq (1) to mimic the function of the joint probability measure \(P\). Then, we can rewrite the objective of \(k\)-means as

\[_{}_{j=1}^{k}_{i=1}^{N}w_{ij}\|_{i}-_{j}\|_{2}^{2},\ \ s.t._{j=1}^{k}_{i=1}^{N}w_{ij}=1,w_{ij}\{0,\},_{i= 1}^{N}w_{ij}=,\] (3)

where \(w_{ij}=1/N\) denotes assigning \(_{i}\) to \(_{j}\), and the constraint \(_{j}w_{ij}=1/k\) ensures each shard is treated equally. By introducing the transport weights \(\), we can transform the discrete clustering problem into a continuous optimization process. This transformation allows us to impose additional constraints on \(\) that facilitate more fine-grained control over the clustering process. Consequently, we add the constraint \(_{j}w_{ij}=1/N\) to ensure a balanced division. Following the Monge-Kantorovich framework [3; 30], we also relax the range of \(\) to \(^{+}\) to guarantee the existence of solution space for the objective. Finally, the shard assignment of \(_{i}\) is determined by \(_{j}w_{ij}\). However, the worst-case complexity of computing the optimum for such a transport objective with additional constraints scales in \(O(N^{3})\). To enhance efficiency, we utilize Sinkhorn divergence to accelerate the optimization process [38; 29]. Specifically, we smooth the objective with an entropic regularization as follows:

\[_{}_{j=1}^{k}_{i=1}^{N}w_{ij}\| _{i}-_{j}\|_{2}^{2}+_{j=1}^{k}_{i=1}^{N}w_{ij} ((w_{ij})-1),\] (4)

where \(=\{\|\|_{1}=1, 0,_{i}w_{ij}=,_{j}w_{ ij}=\}\). The derived new objective can be efficiently solved through Sinkhorn's matrix scaling algorithm with a complexity of \(O(Nk)\)[9; 10]. The optimization details can be found in Appendix B.

### Relevance Loss (Stage II)

In stage II, the ensemble retraining framework trains a sub-model on each shard independently, which means sub-models do not interfere with each other during training. The loss component associated with this stage is relevance loss, which implies that the aim is to enhance the performance of sub-models. However, to ensure unlearning completeness at the algorithmic level, it is crucial that the sub-models fully replicate the original model. This includes replicating not only the model structure, but also hyper-parameters, parameter initialization, and any other relevant elements. Therefore, we do not break the requirement of full replication and also leave stage II unchanged [4; 7; 8]. We assume that the shard data is i.i.d. with the original training data and ensure that all sub-models fully replicate the original model that attains convergence on the original training data. This ensures that sub-models reach convergence on their respective shard data.

### Combination Loss (Stage III)

In stage III, the ensemble retaining framework combines the sub-models to obtain the final model. The original framework, i.e., SISA , uses an average combiner. However, this is a naive solution, since various shards may have different contributions to the final model. Thus, the model-based combiner is proposed by [7; 8]. Specifically, this approach utilizes machine learning models to determine the combination weights by the following objective:

\[_{}_{i=1}^{k}(_{i}_{i },R)+\|\|_{2}^{2},\ \ s.t.\ \|\|_{1}=1, 0,\] (5)

where \(\) is the original loss function for recommendation tasks, \(R\) is the recommendation data, \(_{i}\) denotes the parameters of \(i\)-th sub-models, and \(\) denotes the weights of combination. Note that the parameters of sub-models are fixed during model combination. The \(L_{2}\) regularization parameterized by \(\) on \(\) is applied to prevent over-fitting. This approach is akin to the use of meta-estimators in ensemble systems , where they are employed to alleviate information loss during model combination. As empirically studied by , a simple meta-estimator such as Logistic Regression (LR) proves to be enough on deep models. Building on this insight, we empirically validate the effectiveness of LR on the recommendation tasks in Section 5.2.3. Our results show that LR can perform comparably to attention networks  while substantially reducing model complexity.

### Putting Together

Our proposed UltraRE belongs to the ensemble retraining framework and follows the three-stage structure described in Figure 1. In stage I, we obtain an adaptive equilibrium between sample similarity and shard balance by optimizing Eq (4) In stage II, we do not interfere with sub-model training, meeting the requirement of fully replicating the original model. In stage III, we apply LR to determine the combination weight by optimizing Eq (5).

## 5 Experiments

We conduct experiments on three real-world datasets to evaluate the performance of our proposed UltraRE framework. The evaluation mainly focuses on G2 (unlearning efficiency) and G3 (model utility), as our proposed method (UltraRE) belongs to exact unlearning, which naturally achieves G1 (unlearning completeness). UltraRE can handle all three types of unlearning targets, i.e., user-wise, item-wise, and sample-wise. In this paper, we focus on user-wise unlearning without loss of generality, as it is the most common one in practice. Additionally, we perform an ablation study to further investigate the effectiveness of modification.

### Experimental Settings

#### 5.1.1 Datasets

We conduct experiments on the following three real-world datasets: i) MovieLens 100k (**MI-100K**)2: The MovieLens datasets are among the most extensively used in recommendation researchn [14; 16]. ML-100K contains 100 thousand ratings; ii) MovieLens 1M (**ML-1M**): This is a stable version of the MovieLens dataset, containing 1 million ratings; and iii) Amazon Digital Music (**ADM**)3: The Amazon dataset contains several sub-datasets according to the categories of Amazon products. ADM is the sub-dataset containing digital music reviews. To ensure reliable evaluations, we filter out the users and items that have less than 5 interactions. Specifically, we use 80% of ratings for training, 10% as a validation set for tuning hyper-parameters, and the remainder for testing. Table 1 summarizes the statistics of three datasets.

#### 5.1.2 Compared Models and Methods

Recommendation Models.Our proposed UltraRE is model-agnostic, enabling its application to any recommendation model. In this paper, we select two representative recommendation models: i) a classic model, i.e., Deep Matrix Factorization (DMF) , and ii) the SOTA model, i.e. LightGCN , for testing. Following the original papers, we adopt normalized binary cross entropy loss and Bayesian personalized ranking loss for DMF and LightGCN respectively, and employ Adam optimizer to train the above models. We run all experiments for 10 trials and report the average results. Following , we use WMF  as a pre-training model to generate user and item embedding for the purpose of clustering.

Unlearning Methods.We compare UltraRE with the benchmark and the SOTA methods, including: i) **Retrain**: Retraining the model from scratch on the updated dataset; ii) **SISA**: the SOTA generic exact unlearning method which is based on ensemble retraining framework; and iii) **RecEraser**: the SOTA recommendation unlearning method which modifies SISA to boost performance in recommendation tasks. Following [4; 7], we set the number of shards to 10 for all unlearning methods that involve division, i.e., SISA, RecEraser, and UltraRE.

  Dataset & User \# & Item \# & Rating \# & Sparsity \\  ML-100K & 943 & 1,682 & 100,000 & 93.695\% \\ ML-1M & 6040 & 3,950 & 1,000,209 & 95.814\% \\ ADM & 478,235 & 266,414 & 836,006 & 99.999\% \\  

Table 1: Summary of datasets.

### Results and Discussion

#### 5.2.1 Unlearning Efficiency (G2)

We use running time to evaluate the efficiency of unlearning. To fully exploit the efficiency of the ensemble retraining framework, we run all shards in parallel. Specifically, we measure the running time of each stage during the learning process and report the results in Table 2. As the shard division (stage I) and combination weights (stage III) are determined during learning and remain unchanged during unlearning, their time cost during unlearning is negligible during unlearning compared to retraining (stage II). Since all shards run in parallel, the running time of stage II remains consistent between learning and unlearning. Therefore, by measuring the running time of stage II during learning, we can evaluate the running time of unlearning. We run all experiments on the same Ubuntu 20.04 LTS System server with 48-core CPU, 256GB RAM and NVIDIA GeForce RTX 3090 GPU. From Table 2, we observe that i) compared with Retrain, the ensemble retraining frameworks, i.e., SISA, RecEraser, and UltraRE, significantly enhance unlearning efficiency. Although spending more time in stages I and III, these frameworks decrease the total running time by an average of 85.39%; ii) Using random balanced division and average combiner, SISA enjoys a notably faster speed than other ensemble retraining frameworks. Nevertheless, this simple design also limits SISA's performance regarding model utility (see Section 5.2.2); and iii) Among the comparison of recommendation unlearning frameworks, i.e., RecEraser and UltraRE, our proposed UltraRE decreases the running time of both stages I and III. In stage I, our proposed optimal balanced clustering algorithm can improve the efficiency by 98.11% on average. This improvement is even greater when dealing with larger datasets, i.e., ML-1M and ADM. In stage III, we simplify the choice of the model combiner, resulting in an average efficiency increase of 11.95%.

#### 5.2.2 Model Utility (G3)

We use two common metrics, i.e., Normalized Discounted Cumulative Gain (NDCG) and Hit Ratio (HR), to evaluate the performance of recommender models [17; 47]. For both metrics, we truncate the ranked list at 10, and report NDCG@10 and HR@10 during both the learning and unlearning processes. To simulate user-wise unlearning, we randomly select \(q\)% of users to unlearn, where \(q\) is investigated in {5, 10} across all datasets. From Table 3, we observe that i) Retrain achieves the best performance, suggesting using ensemble retraining frameworks (including SISA, RecEraser, and UltraRE) may come at the cost of slightly increased error rates. This trade-off occurs because these frameworks prioritize unlearning efficiency over preserving model utility; ii) The performance of cluster-based division methods, i.e., RecEraser and UltraRE, surpasses that of the random division method, i.e., SISA. This implies that by clustering similar samples together, redundancy loss can be

    &  &  \\  & Retrain & SISA & RecEraser & UltraRE & Retrain & SISA & RecEraser & UltraRE \\  Stage I & 0.000 & 0.013 & 0.662 & 0.048 & 0.000 & 0.014 & 0.645 & 0.050 \\ Stage II & 1,442.263 & 193.317 & 189.742 & 190.289 & 4,422.531 & 582.659 & 594.714 & 591.638 \\ Stage III & 0.000 & 0.001 & 42.673 & 31.540 & 0.000 & 0.003 & 383.132 & 315.822 \\  Total & 1,442.263 & 193.331 & 233.077 & 221.877 & 4,422.531 & 582.676 & 978.491 & 907.510 \\    &  &  \\  & Retrain & SISA & RecEraser & UltraRE & Retrain & SISA & RecEraser & UltraRE \\  Stage I & 0.000 & 0.046 & 23.904 & 0.429 & 0.000 & 0.058 & 23.950 & 0.467 \\ Stage II & 3,732.366 & 376.237 & 378.475 & 374.999 & 11,372.446 & 1,218.335 & 1,211.275 & 1,218.875 \\ Stage III & 0.000 & 0.003 & 93.519 & 69.327 & 0.000 & 0.004 & 682.182 & 624.349 \\  Total & 3,732.366 & 376.286 & 495.898 & 444.755 & 11,372.446 & 1,218.397 & 1,917.407 & 1,843.691 \\    &  &  \\  & Retrain & SISA & RecEraser & UltraRE & Retrain & SISA & RecEraser & UltraRE \\  Stage I & 0.000 & 0.052 & 20.864 & 0.373 & 0.000 & 0.054 & 20.851 & 0.352 \\ Stage II & 2,012.655 & 207.457 & 201.769 & 206.417 & 6,724.734 & 698.737 & 679.051 & 682.742 \\ Stage III & 0.000 & 0.003 & 57.352 & 48.975 & 0.000 & 0.004 & 404.110 & 374.253 \\  Total & 2,012.655 & 207.512 & 279.985 & 255.765 & 6,724.743 & 698.795 & 1,104.012 & 1,057.347 \\   

Table 2: Running time (s) of the learning process.

significantly reduced. iii) Our proposed UltraRE demonstrates superior performance compared to the SOTA recommendation unlearning framework, i.e., RecEraser. On average, our model achieved an improvement in recommendation metrics of 1.31%, 1.26%, and 1.26%, on ML-100k, ML-1M and ADM respectively. The improved results can be attributed to UltraRE's ability to generate better clustering outcomes while meeting the balance requirement; and iv) Strong performance during the learning process serves as a reliable indicator of strong performance during unlearning.

#### 5.2.3 Ablation Study

To fully understand the effectiveness of our proposed UltraRE, we conduct ablation studies regarding the main modifications during stages I (non-overlapping division) and III (model combination), as well as varying numbers of shards.

Effect of Division.In stage I, we propose a novel division algorithm, named Optimal Balanced Clustering (OBC). We conduct an ablation study to compare OBC with Balanced Random Division (BRD, used in SISA ), Balanced \(k\)-means (BKM, used in RecEraser ) and \(k\)-means (KM). Although KM causes the issue of imbalance in clustering, it can still be a valuable baseline for evaluating division performance. We use inertia in Eq (1) to evaluate division performance. A lower inertia value indicates better division performance. We present the results obtained with \(k=10\) in Figure 4. From it, we observe that i) Among balanced grouping algorithms, our proposed OBC significantly outperforms BKM (by 46.32% on average) and BRD (by 22.01% on average); ii) OBC also achieves comparable inertia to KM, indicating that OBC achieves balanced grouping without compromising sample similarity, and iii) BRD even outperforms BKM. This indicates that the usage of a priority list in BKM leads to a significant degradation in division performance, making it worse than random division.

    &  &  \\  &  &  & RecEraser & UltraRE & Retrain & SISA & RecEraser & UltraRE \\   & NDCG & 0.3956 & 0.3716 & 0.3795 & **0.3847*** & 0.3997 & 0.3684 & 0.3812 & **0.3859*** \\  & HR & 0.4374 & 0.4227 & 0.4273 & **0.4326*** & 0.4395 & 0.4203 & 0.4257 & **0.4312*** \\   & NDCG & 0.3934 & 0.3709 & 0.3762 & **0.3815*** & 0.3976 & 0.3677 & 0.3799 & **0.3841*** \\  & HR & 0.4359 & 0.4222 & 0.4232 & **0.4297*** & 0.4387 & 0.4201 & 0.4233 & **0.4295*** \\   & NDCG & 0.3905 & 0.3702 & 0.3734 & **0.3786*** & 0.3953 & 0.3669 & 0.3793 & **0.3836*** \\  & HR & 0.4353 & 0.4205 & 0.4183 & **0.4245*** & 0.4362 & 0.4186 & 0.4221 & **0.4267*** \\    &  &  \\  & Retrain & SISA & RecEraser & UltraRE & Retrain & SISA & RecEraser & UltraRE \\   & NDCG & 0.4382 & 0.3956 & 0.3973 & **0.4042*** & 0.4437 & 0.3941 & 0.4171 & **0.4241*** \\  & HR & 0.5402 & 0.5141 & 0.5134 & **0.5183*** & 0.5493 & 0.4672 & 0.5160 & **0.5217*** \\   & NDCG & 0.4398 & 0.3937 & 0.3965 & **0.4031*** & 0.4403 & 0.3908 & 0.4138 & **0.4189*** \\  & HR & 0.5411 & 0.5125 & 0.5129 & **0.5179*** & 0.5464 & 0.4543 & 0.5140 & **0.5206*** \\   & NDCG & 0.4391 & 0.3914 & 0.3963 & **0.4013*** & 0.4396 & 0.3912 & 0.4129 & **0.4181*** \\  & HR & 0.5411 & 0.5108 & 0.5127 & **0.5184*** & 0.5421 & 0.4495 & 0.5090 & **0.5146*** \\    &  &  \\  & Retrain & SISA & RecEraser & UltraRE & Retrain & SISA & RecEraser & UltraRE \\   & NDCG & 0.4549 & 0.4063 & 0.4234 & **0.4294*** & 0.4603 & 0.4025 & 0.4281 & **0.4345*** \\  & HR & 0.7914 & 0.7012 & 0.7230 & **0.7311*** & 0.7931 & 0.6912 & 0.7406 & **0.7472*** \\   & NDCG & 0.4551 & 0.4021 & 0.4214 & **0.4273*** & 0.4594 & 0.3963 & 0.4251 & **0.4311*** \\  & HR & 0.7915 & 0.6959 & 0.7202 & **0.7283*** & 0.7945 & 0.6851 & 0.7311 & **0.7403*** \\   & NDCG & 0.4554 & 0.3973 & 0.4198 & **0.4262*** & 0.4595 & 0.4043 & 0.4239 & **0.4306*** \\  & HR & 0.7916 & 0.6772 & 0.7222 & **0.7298*** & 0.7936 & 0.6781 & 0.7192 & **0.7255*** \\   

Table 3: Recommendation performance during learning and unlearning (G3: model utility). The best results except Retrain are highlighted in **bold**. The superscript \(*\) indicates \(p<0.01\) for the t-test of UltraRE against RecEraser.

Figure 4: Effect of division (Stage I)

Effect of Combination.In stage III, we simplify the choice of the model combiner. To validate our choice, we compare our logistic regression (LR) based combiner with Average combiner (AVG which is used in SISA ) and Attention combiner (ATT which is used in RecEraser ). As shown in Figure 5, model-based combiners, i.e., LR and ATT, outperform AVG by a significant margin. On average, AVG's performance is decreased by 3.53% on DMF and 6.51% on LightGCN. Among model-based combiners, LR can achieve comparable performance with ATT while substantially reducing the model complexity.

Effect of Shard Number.To demonstrate the robustness of UltraRE, we empirically study the effect of shard number and compare it with the SOTA recommendation unlearning framework RecEraser. We investigate the number of shards \(S\) in {10, 20, 50}. As shown in Figure 6, UltraRE yields consistent improvements over RecEraser regarding both unlearning efficiency (time) and model utility (NDCG@10). Moreover, as the shard number increases, UltraRE exhibits greater efficiency enhancement over RecEraser. This is because a larger shard number reduces the time taken in stage II, thereby highlighting the efficiency of UltraRE in stages I and III.

## 6 Conclusion

In this paper, we refine the SOTA exact unlearning framework, i.e., ensemble retraining framework, in recommendation tasks. Our proposed UltraRE breaks away from the prior work's intuition on preserving collaboration [7; 8; 26]. Instead, it is guided by the theoretical analysis of error decomposition in ensemble systems. Among the three stages in the ensemble retraining framework, our modifications mainly lie in stages I (non-overlapping division) and III (model combination). In stage I, we proposed an optimal balanced clustering algorithm that can achieve an adaptive equilibrium between sample similarity and shard balance. In stage III, we simplify the complexity of the model combiner without increasing the combination loss. Extensive experiments on three real-world recommendation datasets demonstrate that UltraRE can not only greatly enhance unlearning efficiency, but also outperform the SOTA unlearning models in terms of model utility.

## 7 Broader Impacts and Limitations

Recommendation unlearning can have various implications on society, including addressing issues related to privacy, fairness, bias, and manipulation. UltraRE can also be generalized to other unlearning tasks and is especially adept in association-sensitive tasks, e.g., graph learning. A common limitation of the ensemble retraining framework is the absence of experiments on large-scale datasets with a large shard number [4; 7; 8; 26]. As shown in Section 5.2.1, the major time of unlearning is spent on stage II, which cannot fully demonstrate the efficiency of the ensemble retraining framework. We manage to investigate the effect of large shard number in Section 5.2.3.