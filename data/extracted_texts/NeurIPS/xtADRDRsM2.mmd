# Adversarial Robustness in Graph Neural Networks:

A Hamiltonian Approach

 Kai Zhao

Nanyang Technological University

&Qiyu Kang1

Nanyang Technological University

&Yang Song

C3 AI, Singapore

&Rui She

Nanyang Technological University

&Sijie Wang

Nanyang Technological University

&Wee Peng Tay

Nanyang Technological University

###### Abstract

Graph neural networks (GNNs) are vulnerable to adversarial perturbations, including those that affect both node features and graph topology. This paper investigates GNNs derived from diverse neural flows, concentrating on their connection to various stability notions such as BIBO stability, Lyapunov stability, structural stability, and conservative stability. We argue that Lyapunov stability, despite its common use, does not necessarily ensure adversarial robustness. Inspired by physics principles, we advocate for the use of conservative Hamiltonian neural flows to construct GNNs that are robust to adversarial attacks. The adversarial robustness of different neural flow GNNs is empirically compared on several benchmark datasets under a variety of adversarial attacks. Extensive numerical experiments demonstrate that GNNs leveraging conservative Hamiltonian flows with Lyapunov stability substantially improve robustness against adversarial perturbations. The implementation code of experiments is available at https://github.com/zknus/NeurIPS-2023-HANG-Robustness.

## 1 Introduction

Graph neural networks (GNNs)  have achieved great success in inference tasks involving graph-structured data, including applications from social media networks, molecular chemistry, and mobility networks. However, GNNs are known to be vulnerable to adversarial attacks . To fool a trained GNN, adversaries can either add new nodes to the graph during the inference phase or remove/add edges from/to the graph. The former is called an injection attack , and the latter is called a modification attack . In some works , node feature perturbations are also considered to enable stronger modification attacks.

Neural ordinary differential equation (ODE) networks  have recently gained popularity due to their inherent robustness . Neural ODEs can be considered as a continuous analog of ResNet . Many neural ODE networks have since been proposed, including but not limited to . Using neural ODEs, we can constrain the input and output of a neural network to follow certain physics laws. Injecting physics constraints to black-box neural networks improves neural networks' explainability. More recently, neural ODEs have also been successfully applied to GNNs by modelingthe way nodes exchange information given the adjacency structure of the underlying graph. We call them _graph neural flows_ which enables the interpretation of GNNs as evolutionary dynamical systems. These system equations can be learned by instantiating them using neural ODEs . For instance,  models the message-passing process, i.e., feature exchanges between nodes, as the heat diffusion, while  model the message passing process as the Beltrami diffusion. The reference  models the graph nodes as coupled oscillators with a coupled oscillating ODE guiding the message-passing process.

Although adversarial robustness of GNNs has been investigated in various works, including , robustness study of graph neural flows is still in its fancy. To the best of our knowledge, only the recent paper  has started to formulate theoretical insights into why graph neural diffusion is generally more robust against topology perturbation than conventional GNNs. The concept of Lyapunov stability was used in . However, there are many different notions of stability in the dynamic system literature . In this paper, we focus on the study of different notions of stability for graph neural flows and investigate which notion is most strongly connected to adversarial robustness. We impose an energy conservation constraint on graph neural flows that lead to a Hamiltonian graph neural flow. We find that energy-conservative graph Hamiltonian flows endowed with Lyapunov stability improve the robustness the most as compared to other existing stable graph neural flows.

**Main contributions.** This research is centered on examining various stability notions within the realm of graph neural flows, especially as they relate to adversarial robustness. Our main contributions are summarized as follows:

1. We revisit the definitions of stability from the perspective of dynamical systems as applicable to graph neural flows. We argue that vanilla Lyapunov stability does not necessarily confer adversarial robustness and provide a rationale for this observation.
2. We propose Hamiltonian-inspired graph neural ODEs, noted for their energy-conservative nature. We perform comprehensive numerical experiments to verify their performance on standard benchmark datasets. Crucially, our results demonstrate that Hamiltonian flow GNNs present enhanced robustness against various adversarial perturbations. Moreover, it is found that the effectiveness of Lyapunov stability becomes pronounced when layered on top of Hamiltonian flow GNNs, thereby fortifying their adversarial robustness.

The rest of this paper is organized as follows. We introduce various stability notions from a dynamical system perspective in Section 2. A review of existing graph neural flows is presented in Section 3 with links to the stability notions defined in Section 2. We present a new type of graph neural flow inspired by the Hamiltonian system with energy conservation in Section 4. Two different variants of this model are proposed in Section 5. Section 6 details our extensive experimental outcomes. The supplementary section provides an overview of related studies, an exhaustive outline of the algorithm, further insights into model robustness, supplementary experimental data, and the proofs for the theoretical propositions made throughout the paper.

## 2 Stability in Dynamical Systems

It is well known that a small perturbation at the input of an unstable dynamical system will result in a large distortion in the system's output. In this section, we first introduce various types of stability in dynamical physical systems and then relate them to graph neural flows. We consider the evolution of a dynamical system that is described as the following autonomous nonlinear differential equation:

\[(t)}{t}=f_{}((t)),\] (1)

where \(f_{}:^{n}^{n}\) denotes the system dynamics, which may be non-linear in general, \(\) denotes the system parameters, and \(:[0,)^{n}\) represents the \(n\)-dimensional system state.

We first introduce the stability notions from a dynamical systems perspective that is related to the GNN robustness against _node feature perturbation_.

**Definition 1** (BIBO stability).: _The system is called BIBO (bounded input bounded output) stable if for any bounded input, there exists a constant \(M\) s.t. the output \(\|(t)\|<M,\,t 0\)._

Suppose \(f\) has an equilibrium at \(_{c}\) so that \(f_{}(_{c})=0\). We can define the stability notion for \(_{c}\).

**Definition 2** (Lyapunov stability and asymptotically stable ).: _The equilibrium \(_{e}\) is Lyapunov stable if for every \(>0\), there exists a \(>0\) such that, if \(\|(0)-_{e}\|<\), then for every \(t 0\) we have \(\|(t)-_{e}\|<\). Furthermore, the equilibrium point \(_{e}\) is said to be asymptotically stable if it is Lyapunov stable and there exists a \(^{}>0\) such that if \(\|(0)-_{e}\|<^{}\), then \(_{t}\|(t)-_{e}\|=0\)._

**Remark 1**.: _Lyapunov stability indicates that the solutions whose initial points are near an equilibrium point \(_{e}\) stay near \(_{e}\) forever. For the special linear time-invariant system \(\,(t)/\,t=(t)\) with a constant matrix \(\), it is Lyapunov stable if and only if all eigenvalues of \(\) have non-positive real parts and those with zero real parts are the simple roots of the minimal polynomial of \(\). Asymptotically stable means that not only do trajectories stay near \(_{e}\) for all time (Lyapunov stability), but trajectories also converge to \(_{e}\) as time goes to infinity (asymptotic stability)._

We next introduce the concept of structural stability from dynamical systems theory, which is related to the robustness of GNNs against _graph topological perturbation_. It describes the sensitivity of the qualitative features of a solution to changes in parameters \(\). The definition of structural stability requires the introduction of a topology on the space of \(\) in (1), which we do not however present here rigorously due to space constraints and not to distract the reader with too much mathematical details. Instead, we provide a qualitative description of structural stability to elucidate how it can indicate the robustness of a graph neural flow against topology perturbations.

**Definition 3** (Structural stability).: _Unlike Lyapunov stability, which considers perturbations of initial conditions for a fixed \(f_{}\), structural stability deals with perturbations of the dynamic function \(f_{}\) by perturbing the parameter \(\). The qualitative behavior of the solution is unaffected by small perturbations of \(f_{}\) in the sense that there is a homeomorphism that globally maps the original solution to the solution under perturbation._

**Remark 2**.: _In the graph neural flows to be detailed in Section 3 and Section 4, the parameter \(\) includes the graph topology (i.e., the adjacency matrix) and learnable neural network weights. Unlike adversarial attacks on other deep learning neural networks where the attacker targets only the input \(\), it is worth noting that adversaries for GNNs can also attack the graph topology, which forms part of \(\). If there are different Lyapunov stable equilibrium points, one for each class of nodes, one intuitive example of breaking structural stability in graph neural flows is by perturbing the graph topology in such a way that there are strictly fewer equilibrium points than the number of classes._

In this study, we will propose GNNs drawing inspiration from Hamiltonian mechanics. In a Hamiltonian system, \(=(q,p)^{2n}\) refers to the generalized coordinates, with \(q\) and \(p\) corresponding to the generalized position and momentum, respectively. The dynamical system is characterized by the following nonlinear differential equation:

\[(t)}{\,t}=J H((t)),\] (2)

where \( H()\) is the gradient of a scalar function \(H\) at \(\) and \(J=(0&I\\ -I&0)\) is the \(2n 2n\) skew-symmetric matrix with \(I\) being the \(n n\) identity matrix.

We now turn our attention to the notion of conservative stability in dynamical systems. It is worth noting that a general dynamical system, as characterized in (1), might not consistently resonate with traditional perspectives on energy and conservation, especially when compared to physics-inspired neural networks, like (2).

**Definition 4** (Conservative stability).: _In a dynamical system inspired by physical principles, such as (2), a conserved quantity might be present. This quantity, which frequently embodies the notion of the system's energy, remains invariant along the system's evolution trajectory \((t)\)._

Our focus in this work is on graph neural flows that can be described by either (1) or (2). Chamberlain et al.  postulate that many GNN architectures such as GAT can be construed as discrete versions of (1) via different choices of the function \(f_{}\) and discretization schemes. Therefore, the stability definitions provided above can offer additional insights into many popular GNNs. Most existing graph neural flows only scrutinize the BIBO/Lyapunov stability of their system. For instance, GRAND  proposes BIBO/Lyapunov stability against node feature perturbation over \(\). However, the more fundamental structural stability in graph neural flows, which is related to the robustness against graph topological changes, remains largely unexplored. Some models, such as GraphCON , exhibit conservative stability under certain conditions. We direct the reader to Section 3 and Table 1 for a comprehensive discussion of the stability properties of each model.

## 3 Existing Graph Neural Flows and Stability

Consider an undirected, weighted graph \(=(,)\) where \(\) is a finite set of vertices and \(\) denotes the set of edges. The adjacency matrix of the graph is denoted as \(([u,v])=([v,u])\) for all \([u,v]\). Let \((t)^{|| r}\) represent the features associated with the vertices at time \(t\). The feature vector for the \(i\)-th node in \(\) at time \(t\) can be represented as the \(i\)-th row of \((t)\), indicated by \(_{i}^{}(t)\). In this section, we introduce several graph neural flows on \(\), categorizing them according to the stability concepts outlined in Section 2.

**GRAND:** Inspired by the heat diffusion equation, GRAND  employs the following dynamical system:

\[(t)}{t}=}_{G}( (t))(t)(_{G}((t))- )(t),\] (3)

with the initial condition \((0)\). Within this model, \(_{G}((t))\) is either a time-invariant static matrix, represented as GRAND-l, or a trainable time-variant attention matrix \((a_{G}(_{i}(t),_{j}(t)))\), labeled as GRAND-nl, reflecting the graph's evolutionary features. The function \(a_{G}()\) calculates similarity for pairs of vertices, and \(\) is an identity matrix with dimensions that fit the context. In , \(\) is set to be 1. Let \(\) be the diagonal node degree matrix where \([u,u]=_{v}[u,v]\).

**Theorem 1**.: _We can prove the following stability:_

1. _For GRAND-nl, if the attention matrix_ \(_{G}((t))\) _is set as a doubly stochastic attention_ _[_41_]__, we have BIBO stability and Lyapunov stability for any_ \( 1\)_. When_ \(>1\)_, it reaches global asymptotic stability under any perturbation._
2. _Within the GRAND-l setting, if_ \(_{G}\) _is set as a constant column- or row-stochastic matrix, such as the normalized adjacency matrices_ \(^{-1}\) _or_ \(^{-1}\)_, global asymptotic stability is achieved for_ \(>1\) _under any perturbation. If the graph is additionally assumed to be strongly connected_ _[_42_]__[_Sec.6.3]__, BIBO and Lyapunov stability are realized for_ \(=1\)_._
3. _Furthermore, when_ \(_{G}\) _is specifically a constant column-stochastic matrix like_ \(^{-1}\) _and_ \(=1\)_, GRAND conserves a quantity that can be interpreted as energy. Furthermore, in this setting, asymptotic stability is attained when the graph is aperiodic and strongly connected and the perturbations on_ \((0)\) _ensure unaltered column summations._

**BLEND:**_In comparison to GRAND, BLEND  introduces the use of positional encodings. Following a similar line of reasoning to that used for GRAND, BLEND also exhibits BIBO/Lyapunov stability as stated in Theorem 1. Moreover, it is noteworthy that if positional features_ \((t)\) _are eliminated, for instance by setting them as a constant, BLEND simplifies to the GRAND model._

**GraphCON:** Inspired by oscillator dynamical systems, GraphCON is a graph neural flow proposed in  and defined as

\[\{(t)}{t}=( _{}((t),t))-(t)-(t), \\ (t)}{t}=(t),.\] (4)

where \(_{}()\) is a learnable \(1\)-neighborhood coupling function, \((t)\) is an auxiliary velocity variable, \(\) denotes an activation function, and \(\) and \(\) are tunable parameters.

_As described in [35, Proposition 3.1], under specific settings where \(\) is the identity function and \(_{}((t),t)=(t)\) with \(\) being a constant matrix, GraphCON conserves Dirichlet energy_ (11)_, thereby demonstrating conservative stability._

**GraphBel:** Generalizing the Beltrami flow, mean curvature flow and heat flow, a stable graph neural flow  is designed as

\[(t)}{t}=(_{}((t))_{}((t))-((t)))(t),\] (5)

where \(\) is the element-wise multiplication. \(_{}()\) and \(_{}()\) are learnable attention function and normalized vector map, respectively. \(((t))\) is a diagonal matrix in which \((_{i},_{i})=_{_{j}}( )(_{i},_{j})\).

_Analogous to BLEND, under certain conditions with \(((t))=_{}((t))=\), GraphBel simplifies to the GRAND model. Consequently, it exhibits BIBO/Lyapunov stability in certain scenarios._The incorporation of ODEs via graph neural flows may enhance the stability of graph feature representations. A summarized relationship between model stability and these graph neural flows can be found in Table 1.

### Lyapunov Stability vs. Node Classification Robustness:

At first glance, Lyapunov stability has a strong correlation with node classification robustness against feature perturbations. However, before diving into experimental evidence, we point out an important conclusion: **Lyapunov stability _by itself_ does not necessarily imply adversarial robustness.** Consider a scenario where a graph neural flow has only one equilibrium point \(_{e}\), while the node features are derived from more than one class. In a Lyapunov asymptotically stable graph neural flow, such as GRAND (as shown in Theorem 1), all node features across different classes would inevitably converge to a single point \(_{e}\) due to global contraction. We note that this is why the model in  requires a diversity-promoting layer to ensure that different classes converge to different Lyapunov-stable equilibrium points.

**Example 1**.: _We provide an example to demonstrate our claim. Consider the following Lyapunov stable ODE_

\[}(t)=-1&0\\ 0&-5(t)\] (6)

_with initial condition \((0)=[x_{1}(0),x_{2}(0)]^{}\). The solution to this ODE is given by \((t)=x_{1}(0)e^{-t}^{}+x_{2}(0)e^{-5t}^{}\). For all initial points in \(^{2}\), we have \((t)\) as \(t\). Furthermore, as \(t\), the trajectory \((t)\) for any initial point is approximately parallel to the x-axis. We draw the phase plane in Fig. 0(a)._

_Assume that the points on the upper half y-axis belongs to class 1 while we have a linear classifier that seperates class 1 and class 2 as shown in Fig. 0(a). We observe that for the initial point \(A\) belonging to class 1, the solution from a small perturbed initial point \(A+\) is misclassified as class 2 for a large enough \(t\) for any linear classifier. We see from this example that Lyapunov stability itself does not imply adversarial robustness in graph neural flow models._

_This example indicates that Lyapunov stability does not guarantee node classification robustness. Additionally, for a system exhibiting global contraction to a single equilibrium point, structural stability may also be ensured. For instance, in the case of GRAND, even if the edges are perturbed, the system maintains the same number of equilibrium points with global contraction._ We conclude that even an amalgamation of both Lyapunov stability and structural stability may not help the graph's adversarial robustness for node classification.

In the example shown in Fig. 1, we observe that in the case of GRAND when \(>1\), the node features from different classes tend to become closer to each other as time progresses. This phenomenon can potentially create more vulnerability to adversarial attacks.

Figure 1: (a): We plot the vector field and the system solution trajectories of Example 1. (b) and (c): In GRAND, the node features’ energy tends to converge towards each other. In HANG, we observe the node features’ energy remains relatively stable over time. Two nodes are from different classes.

## 4 Hamiltonian-Inspired Graph Neural Flow

Drawing inspiration from the principles of Hamiltonian classical mechanics, we introduce a novel graph neural flow paradigm, namely HamiltonianAN Graph diffusion (HANG). In Hamiltonian mechanics, the notation \((q,p)\) is traditionally used to represent the properties of nodes (position and momentum). Hence, in this section, we adopt this notation instead of \(\) (as used in Section 3) to denote node features.

### Physics Philosophy Behind HANG

In Hamiltonian mechanics, the state evolution of a multi-object physical system, such as an electromagnetic field, double pendulum, or spring network , adheres to well-established physical laws. For instance, in a system of charged particles, each particle generates an electromagnetic field that influences other particles. The Hamiltonian for such a system includes terms representing the kinetic and potential energy of each particle, along with terms representing the interactions between particles via their electromagnetic fields. In this paper, we propose a novel concept of information propagation between graph nodes, where interactions follow a similar Hamiltonian style.

In a Hamiltonian system, the position \(q\) and momentum \(p\) together constitute the phase space \((q,p)\), which comprehensively characterizes the system's evolution. In our HANG model, we process the raw node features of the graph using a linear input layer, yielding \(2r\)-dimensional vectors. Following the methodologies introduced in the GNN work , we split the \(2r\) dimensions into two equal halves, with the first half serving as the feature (position) vector and the second half as "momentum" vector that guides the system evolution. Concretely, each node \(k\) is associated with an \(r\)-dimensional feature vector \(_{k}(0)=(q_{k}^{1},,q_{k}^{r})\) and an \(r\)-dimensional momentum vector \(_{k}(0)=(p_{k}^{1},,p_{k}^{r})\). Subsequently, \(_{k}(t)\) and \(_{k}(t)\) will evolve along with the propagation of information between graph nodes, with \(_{k}(0)\) and \(_{k}(0)\) serving as the initial conditions.

Following the modeling conventions in physical systems, we concatenate the feature positions of all \(||\) vertices into a single vector, treating it as the system's generalized coordinate within a \(r||\)-dimensional manifold, a process that involves index relabeling3.

\[q(t)=(q^{1}(t), q^{r||}(t))=(_{1}(t ),,_{||}(t)).\] (7)

This \(r||\)-dimensional coordinate representation at each time instance provides a snapshot of the state of the graph system. Similarly, we concatenate all the "momentum" vectors at time \(t\) to construct an \(r||\)-dimensional vector:

\[p(t)=(p_{1}(t), p_{r||}(t))=(_{1}(t ),,_{||}(t)),\] (8)

Figure 2: The model architecture: each node is assigned a learnable “momentum” vector at time \(t=0\) which initializes the evolution of the system together with node features. The graph features evolve on following a _learnable_ law (10) derived from the \(H_{}\). At the time \(t=T\), we use \(q(T)\) as the final node feature. \(H_{}(q(t),p(t))\) is a learnable graph energy function.

which can be interpreted as a generalized momentum vector for the entire graph system.

In physics, the system evolves in accordance with fundamental physical laws, and a conserved quantity function \(H(q,p)\) remains constant along the system's evolution trajectory. This conserved quantity is typically interpreted as the "system energy". In our HANG model, instead of defining an explicit energy function \(H(p,q)\) from a fixed physical law, we utilize a learnable energy function \(H_{}:^{+}\) parameterized by a neural network, referred to as the _Hamiltonian energy function_:

\[H_{}:^{+}\] (9)

We allow the graph features to evolve according to a learnable Hamiltonian law analogous to basic physical laws. More specifically, we model the feature evolution trajectory as the following canonical Hamilton's equations, which is a restatement of (2):

\[(t)=}}{ p},(t)=- }}{ q},\] (10)

with the initial features \((q(0),p(0))^{2r||}\) at time \(t=0\) being the vectors after the raw node features transformation.

The neural ODE given by (10) can be trained and solved through integration to obtain the trajectory \((q(t),p(t))\). At the terminal time point \(t=T\), the system's solution is represented as \((q(T),p(T))\). We then apply the canonical projection map \(\) to extract the nodes' concatenated feature vector \(q(T)\) as follows: \(((q(T),p(T)))=q(T)\). This concatenated feature vector \(q(T)\) is subsequently decompressed into individual node features for utilization in downstream tasks. For this study, we employ backpropagation to minimize the cross-entropy in node classification tasks. The complete model architecture is depicted in Fig. 2, while a comprehensive summary of the full algorithm can be found in the Appendix G.

### Hamiltonian Energy Conservation

Referring to , it is known that the total Hamiltonian energy \(H_{}\) remains constant along the trajectory of its induced Hamiltonian flow. This principle is recognized as the law of energy conservation in a Hamiltonian system.

**Theorem 2**.: _If the graph system evolves in accordance with (10), the total energy \(H_{}(q(t),p(t))\) of the system remains constant. BIBO stability is achieved if \(H_{}\) remains bounded for all bounded inputs and, as \((q,p)\), \(H_{}(q,p)\)._

In light of Theorem 2, if our system evolves following (10), it adheres to the law of energy conservation. As a result, our model guarantees conservative stability. Compared to GraphCON, which conserves Dirichlet energy over time \(t\) under specific conditions, the notion of Hamiltonian energy conservation is broader in scope. Under the settings delineated in Section 3, GraphCON can be considered as a particular instance of HANG when \(H_{}\) is set to represent Dirichlet energy \((q)\):

**Definition 5** (Dirichlet energy ).: _The Dirichlet energy is defined on node features \(q(t)\) at time \(t\) of an undirected graph \(\) as_

\[(q(t))=|}_{i}_{j(i)}\| _{i}(t)-_{j}(t)\|^{2},\] (11)

_where \((i)=\{j:[i,j]\}\) is the set of neighbors adjacent to node \(i\) in the graph._

## 5 Different Hamiltonian Energy Functions

In physical systems, the system is often depicted as a graph where two neighboring vertices with mass are connected by a spring of given stiffness and length . The system's energy is thus related to the graph's topology. Similarly, in our graph system, the energy function \(H_{}\) involves interactions between neighboring nodes, signifying the importance of the graph's topology. There exist multiple ways to learn the energy function, and we present two examples below.

### Vanilla HANG

We define \(H_{}\) as a composition of two graph convolutional layers:

\[H_{}=\|(g_{}} g_{}})(q,p)\|_{2},\] (12)

where \(g_{}}:^{2r||}^{d ||}\) and \(g_{}}:^{d||}^{| |}\) are two GCN  layers with different hidden dimensions. A \(\) activation function is applied between the two GCN layers, and \(\|\|_{2}\) denotes the \(_{2}\) norm. We concatenate \(_{k}\) and \(_{k}\) for each node \(k\) at the input of the above composite function, resulting in an input dimension of \(2r\) per node. From Theorem 2, it follows that HANG exhibits BIBO stability. If \((q(t),p(t))\) were unbounded, the value of \(H_{}\) would also become unbounded, contradicting the energy conservation principle. In subsequent discussions, this invariant is referred to as HANG.

### Quadratic HANG (HANG-quad)

The general vanilla HANG with conservative stability does not possess Lyapunov stability. Other additional conditions may be required for Lyapunov stability. The following Lagrange-Dirichlet Theorem provides a sufficient condition.

**Theorem 3** (Lagrange-Dirichlet Theorem ).: _Let \(_{e}\) be a locally quadratic equilibrium of the natural Hamiltonian (2) with_

\[H=T(q,p)+U(q),\] (13)

_where \(T\) is a positive definite, quadratic function of \(p\). Then \(_{e}\) is Lyapunov stable if the position of it is a strict local minimum of \(U(q)\)._

Theorem 3 implies that we can design an energy function \(H_{}\) such that the induced graph neural flow is both Lyapunov stable and energy conservative. For instance, we can define \(T\) as

\[T(q,p)=_{i}_{i}^{}_{i}+ _{i}^{}_{i},\] (14)

where \(_{i}=_{j(i)}a_{G}(_{i},_{ j})_{j}\) is the aggregation of \(_{j}\) through the attention mechanism \(a_{G}(_{i},_{j})\) calculated based on \(q\) (or we directly use adjacency matrix with \(a_{G}(_{i},_{j})[i,j]\)). The term \(\) is a small positive number included to ensure the positive definiteness. If \(U(q)\) has only a single global minimum, such as \(U(q)=\|q\|\) with an \(_{2}\) norm, this stability may not ensure adversarial robustness as discussed in Section 3.1. An alternative is setting \(U(q)=\|(q)\|\), which fosters Lyapunov stability across multiple local equilibrium points. However, this choice considerably restricts the form that \(U\) can take and may consequently limit the model's capacity. In the implementation, we set the function \(U(q)\) in \(H\) to be a single GAT  layer \(g_{}:^{r||}^{r }\) with a \(\) activation function followed by an \(_{2}\) norm, i.e., \(U(q)=\|g_{}(q)\|_{2}.\) The stability of HANG and HANG-quad is summarized in Table 1.

## 6 Experiments

In this section, we conduct a comprehensive evaluation of our theoretical findings and assess the robustness of two conservative stable models: HANG and HANG-Quad. We compare their performance against various benchmark GNN models, including GAT , GraphSAGE , GCN  and other prevalent graph neural flows. We incorporate different types of graph adversarial attacks as described in Section 6.1 and Section 6.3. These attacks are conducted in a black-box setting, where a surrogate model is trained to generate perturbed graphs or features. For more experiments, we direct readers to Appendix C.

   Graph Neural Flows & BIBO stability & Lyapunov stability & Structural stability & Conservative stability \\  GRAND & \(\) & \(\) & \(\) & \(\) \\ BLEND & \(\) & \(\) & \(\) & \(\) \\ GraphCON & \(\) & \(\) & \(\) & \(\) \\ GraphB & \(\) & \(\) & \(\) & \(\) \\ HANG-quad & \(\) & \(\) & \(\) & \(\) \\   

Table 1: The stability summary for different graph neural flows where the \(\)denotes that stability is affirmed under additional conditions.

[MISSING_PAGE_FAIL:9]

### Performance Results Under GIAs

Upon examining the results in Table 2 and Table 3 pertaining to experiments conducted under GIA conditions, the robustness of our proposed HANG and HANG-quad, is notably prominent across different GIA scenarios. Interestingly, GRAND, despite its Lyapunov stability as analyzed in Theorem 1, does not significantly outperform GAT under certain attacks. In contrast, HANG consistently displays robustness against attacks. Notably, HANG-quad exhibits superior performance to HANG on the Pubmed dataset under GIA perturbations, underscoring the effectiveness of integrating both Lyapunov stability and Hamiltonian mechanics to boost robustness. Although other graph neural flows might demonstrate a range of improved performance compared to conventional GNN models under GIA, the degree of improvement is not consistently distinct. Despite the pronounced association between conservative stability in Hamiltonian systems and adversarial robustness, a clear relationship between adversarial robustness with the other stability of the graph neural flows outlined in Table 1 is not immediately discernible. The performance differential between HANG variants and other graph neural flows further underscores the potential of our proposed Hamiltonian models in enhancing robustness against GIA attacks.

### Graph Modification Attacks

To evaluate the robustness of our proposed conservative models, we conducted graph modification adversarial attacks using the Metattack method . We followed the attack setting described in the Pro-GNN  and utilized the perturbed graph provided by the library  to ensure a fair comparison. The perturbation rate, which indicates the proportion of altered edges, was incrementally varied in 5% increments from 0% to 25%. For comparison, we also considered other defense models for GNNs, namely Pro-GNN , RGCN , and GCN-SVD . We report the results of baseline models from .

### Performance Results Under Modification/Poisoning/Transductive Attacks

In the case of the Polblogs dataset , as shown in Table 4, our proposed HANG-quad model demonstrates superior performance compared to other methods, including existing defense models. This result indicates that incorporating Lyapunov stability indeed enhances HANG's robustness against graph modification and poisoning attacks. For the Pubmed dataset, we note that the impact of Meta-attacks of varying strengths on _all_ graph neural flows, including our proposed ones, is negligible. Conversely, traditional GNN models such as GAT, GCN, and RGCN are marginally affected as the attack strength escalates. This observation underlines the robustness of graph neural flows, including our proposed models, against Meta-attacks on this dataset.

### Combination with other defense mechanisms

It merits noting that our models, HANG and HANG-quad, can be readily integrated with additional defense mechanisms against adversarial attacks. These include Adversarial Training (AT)  and other preprocessing methods such as GNNGUARD . This integration can further bolster the robustness of the HANG model. To validate this enhancement, extensive experiments are conducted, with results detailed in Appendix C.8 and Appendix C.9.

## 7 Conclusion

In this paper, we conducted a comprehensive study on stability notions in the context of graph neural flows and made significant findings. While Lyapunov stability is frequently employed, it alone may not suffice in guaranteeing robustness against adversarial attacks. With a grounding in foundational physics principles, we proposed a shift towards conservative Hamiltonian neural flows for crafting GNNs resilient against adversarial attacks. Our empirical comparisons across diverse neural flow GNNs, as tested on multiple benchmark datasets subjected to a range of adversarial attacks, have further corroborated this proposition. Notably, GNNs that amalgamate conservative Hamiltonian flows with Lyapunov stability exhibited marked enhancement in their robustness metrics. We are optimistic that our work will inspire further research into marrying physics principles with machine learning paradigms for enhanced security.

Acknowledgments and Disclosure of Funding

This research is supported by the Singapore Ministry of Education Academic Research Fund Tier 2 grant MOE-T2EP20220-0002, and the National Research Foundation, Singapore and Infocomm Media Development Authority under its Future Communications Research and Development Programme. To improve the readability, parts of this paper have been grammatically revised using ChatGPT .