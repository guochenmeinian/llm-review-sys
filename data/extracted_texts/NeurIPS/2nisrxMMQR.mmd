# Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning

Fei Zhou\({}^{1}\) Peng Wang\({}^{2}\) Lei Zhang\({}^{1}\)1 Zhenghua Chen\({}^{3}\) Wei Wei\({}^{1}\)

Chen Ding\({}^{4}\) Guosheng Lin\({}^{5}\) Yanning Zhang\({}^{1}\)

\({}^{1}\) School of Computer Science, Northwestern Polytechnical University

\({}^{2}\) School of Computer Science and Engineering, University of Electronic Science and Technology of China

\({}^{3}\) Institute for Infocomm Research, and Centre for Frontier AI Research, A*STAR

\({}^{4}\) School of Computer Science, Xi'an University of Posts & Telecommunications

\({}^{5}\) School of Computer Science and Engineering, Nanyang Technological University

zhoufei@mail.nwpu.edu.cn wangpeng8619@gmail.com chen0832@e.ntu.edu.sg gslin@ntu.edu.sg dingchen@xupt.edu.cn {nwpuzhanglei,weiweiwnpu,ynzhang}@nwpu.edu.cn

###### Abstract

Meta-learning offers a promising avenue for few-shot learning (FSL), enabling models to glean a generalizable feature embedding through episodic training on synthetic FSL tasks in a source domain. Yet, in practical scenarios where the target task diverges from that in the source domain, meta-learning based method is susceptible to over-fitting. To overcome this, we introduce a novel framework, Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning, which is crafted to comprehensively exploit the cross-domain transferable image prior that each image can be decomposed into complementary low-frequency content details and high-frequency robust structural characteristics. Motivated by this insight, we propose to decompose each query image into its high-frequency and low-frequency components, and parallel incorporate them into the feature embedding network to enhance the final category prediction. More importantly, we introduce a feature reconstruction prior and a prediction consistency prior to separately encourage the consistency of the intermediate feature as well as the final category prediction between the original query image and its decomposed frequency components. This allows for collectively guiding the network's meta-learning process with the aim of learning generalizable image feature embeddings, while not introducing any extra computational cost in the inference phase. Our framework establishes new state-of-the-art results on multiple cross-domain few-shot learning benchmarks.

## 1 Introduction

Meta-learning Finn et al. (2017); Lee et al. (2019); Rusu et al. (2019); Zhmoginov et al. (2022); Zhang et al. (2023); Baik et al. (2020) represents a potent paradigm within the domain of FSL Vinyals et al. (2016); Snell et al. (2017); Huang et al. (2022); Zhang and Huang (2022); Chen et al. (2021). This paradigm harnesses a feature embedding network to capture task-agnostic meta-knowledge, facilitating generalization to novel tasks. To this end, meta-learning systematically samples a sequence of FSL episodes in the source domain to supervisedly enforcing learn an effective feature embedding network that assimilating cross-task transferable essentials and generalize well to novel target tasks. Due to its exceptional learning-to-learn capabilities, meta-learning has established itself as the de facto approach for the development of effective few-shot solvers Vinyals et al. (2016); Snell et al.

, Huang et al. , Zhang and Huang , Finn et al. , Lee et al. , Rusu et al. , Zhmoginov et al. , Zhang et al. , Baik et al. .

However, in practical cross-domain scenarios where the target task exhibits a noticeable distribution discrepancy from that in the source domain, meta-learning based methods are susceptible to over-fitting. This phenomenon can be attributed to two main reasons. Firstly, tasks randomly sampled in source domain often come from one or several fixed patterns, and thus the continual switching of episodes training may cause the model to over-fit on some task-specific priors. For instance, in tasks involving the discrimination between tigers and giraffes, meta-learning methods may compel the model to emphasize appearance outlines, while in tasks focused on fine-grained bird identification, models tend to prioritize local discriminative textures. Yet, these task-specific priors prove challenging to transfer across different tasks Lyu et al. , Zhou et al. . Secondly, the iterative episodic training in the source domain can result in the model over-fitting to semantic prior properties specific to that domain. For example, source domains comprised of natural scene images often exhibit obvious semantic priors, whereas specialized target domains like medical image analysis or remote sensing may lack clear semantic concepts. This overall domain bias also hampers the model's cross-domain generalization. For all these challenges, the underlying evil lies in the absence of cross-domain invariant priors to guide meta-learning in the source domain.

To address this challenge, we introduce a novel framework, Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning. Inspired by classical image transform theories (Fourier Nussbaumer and Nussbaumer  or wavelet Zhang and Zhang ), where each image can be decomposed into low-frequency content details and high-frequency structural characteristics, despite which domain it belongs to, we attempt to cast such a cross-domain invariant image property into appropriate frequency priors and utilize them to guide the meta-learning in source domain. Following this idea, we decompose each query image into a high-frequency and a low-frequency parts, and feed each into the feature embedding network for final category prediction, mirroring the process applied to the original query image. These allows for the independent feature learning in both spatial and frequency domains. In addition, the low-frequency and high-frequency branch will separately exploit the complementary image content and structures for feature enhancement, which are often concealed in the spatial domain of original query image. More importantly, we further develop two frequency priors, namely a feature reconstruction prior and a prediction consistency prior, which separately forces the original query image and its decomposed frequency components to produce the consistent intermediate feature representation as well as the final category prediction. In a specific, the feature reconstruction prior requires to reconstruct the feature of original image through fusing the features of both decomposed frequency parts using a deep projection network. The prediction consistency prior aims to minimize the separate Kullback-Leibler divergence between the prediction scores produced by the original query image and its each frequency component. By doing these, meta-learning in the source domain can be appropriately regularized and produce the exceptional cross-domain generalizable feature embeddings. Moreover, such frequency priors only perform in the meta-learning phase without introducing any extra computational cost in inference. Through a series of rigorous experiments, our framework establishes itself as a front-runner, achieving state-of-the-art results across multiple cross domain FSL benchmarks. Additionally, our method exhibits significant efficiency advantages.

The primary contributions of this study can be summarized as follows:

* We present a novel insightful meta-learning framework that exploits cross-domain invariant frequency priors to alleviate the over-fitting problems of classic meta-learning in cross-domain FSL tasks.
* We propose two frequency prior, namely a prediction consistency prior and a feature reconstruction prior, to collectively guide the meta-learning procedure.
* We achieve state-of-the-art results on multiple cross-domain FSL benchmarks.

## 2 Methodology

Problem formulation.Cross-Domain Few-Shot Learning (CD-FSL) aims to transfer the knowledge acquired by a model in the source domain \(_{s}\) to perform few-shot tasks in the target domain \(_{t}\). It is noteworthy that the categories in \(_{t}\) differ from those in the source domain. Each task \(\) involves the random sampling of \(N\) categories, with \(K\) samples and \(M\) samples randomly selected from each category to constitute the support set \(_{S}\) and the query set \(_{Q}\), respectively. The support set \(_{S}\) is employed for constructing a task-specific classifier, while the query set \(_{Q}\) is used to assess the classification accuracy for that specific task. To emulate the meta-testing process, methods based on meta-learning typically sample a series of few-shot tasks from the source domain for training.

Overview.In this study, we introduce a sophisticated meta-learning framework that leverages cross-domain invariant frequency priors to mitigate the over-fitting problems of classic meta-learning in cross-domain FSL tasks. As illustrated in Fig. 1, our method comprises two key components: the Image Decomposition Module (IDM) and the Prior Regularization Meta-Network (PRM-Net). The IDM is designed to explicitly decompose each image within a few-shot task into its low- and high-frequency components using Fast Fourier Transform (FFT) Nussbaumer and Nussbaumer (1982). PRM-Net is a key component responsible for introducing a prediction consistency prior and a feature reconstruction prior. PRM-Net is organized into three branches: the main branch, the low-frequency content branch, and the high-frequency structure branch. In each branch, all images undergo feature extraction through the embedding network. Subsequently, a task-specific classifier is constructed based on the support set to predict the query set. Two frequency priors, namely the prediction consistency prior and the feature reconstruction prior, are proposed to collectively guide the network's meta-learning process with the aim of learning generalizable image feature embeddings. The IDM and PRM-Net work collaboratively to provide a robust meta-learning framework, aiming to enhance cross-domain generalization by explicitly considering image decomposition and introducing effective regularization during the meta-learning process. The subsequent sections will provide a detailed description of each module.

### Image Decomposition Module

In the realm of signal processing, classical image transform theory Nussbaumer and Nussbaumer (1982); Zhang and Zhang (2019) posits that every image can be decomposed into low-frequency content and high-frequency structure, irrespective of its domain. Therefore, within the Image Decom

Figure 1: Framework of the proposed method. In this work, we present an insightful meta-learning framework that exploits cross-domain invariant frequency priors to alleviate the over-fitting problems of classic meta-learning in cross-domain FSL tasks. Our method consists of an Image Decomposition Module (IDM) and a Prior Regularization Meta-Network (PRM-Net). Among them, IDM aim at explicitly decomposing every image in few-shot task into low- and high-frequency components. PRM-Net develops a prediction consistency prior and a feature reconstruction prior to jointly regularize the feature embedding network during meta-learning, aiming to learn generalizable image feature embeddings. Once the model is trained, only the main branch is retained for meta-testing on target domains.

position Module, we adhere to this theory and employ Fast Fourier Transform (FFT) Nussbaumer and Nussbaumer (1982) to explicitly decompose each image from the few-shot task \(\) into a low-frequency content image and a high-frequency structure image. Specifically, for an image \(x\) in \(\), the initial step involves decomposing it into the frequency domain:

\[[f^{xlow},f^{xhigh}]=(x),\] (1)

where \(\) represents FFT, \(f^{xlow}\) and \(f^{xhigh}\) represent the low-frequency and high-frequency components of \(x\) in the frequency domain respectively. Following this decomposition, we transform these components back into the image space using the inverse FFT:

\[ x^{low}=^{-1}(f^{x^{low}}), \\ x^{high}=^{-1}(f^{x^{high}}),\] (2)

where \(^{-1}\) represents inverse transform of FFT, \(x^{low}\) and \(x^{high}\) represent the decomposed low-frequency content image and high-frequency structure image respectively. Similarly, we apply the same decomposition process to each image in \(\) to obtain the corresponding low-frequency content task \(^{low}\) and high-frequency structure task \(^{high}\).

### Prior Regularization Meta-Network

The proposed Prior Regularization Meta-Network is designed to leverage cross-domain invariant frequency priors, addressing meta-learning over-fitting in the source domain. To achieve this objective, we introduce a three-branch meta-learning network, dedicated to processing the raw few-shot task \(\), the low-frequency task \(^{low}\), and the high-frequency task \(^{high}\), respectively. Significantly, we propose a prediction consistency prior and a feature reconstruction prior to jointly regularize the feature embedding network during meta-learning. This approach empowers the learning process, facilitating the acquisition of a cross-domain generalizable feature embedding. Upon completing the meta-training on the source domain, we discard the high-frequency and low-frequency branches, retaining only the main branch for cross-domain validation.

The main branch.As depicted in Fig. 1, the main branch includes a feature embedding network and a task-specific classifier. For a few-shot task \(\), the main branch first feeds each image into the feature embedding network to obtain features, and then utilizes the support set \(_{S}\) to build a prototype classifier Snell et al. (2017):

\[c_{n}=_{k=1}^{K}f_{}(x_{n,k}),\] (3)

where \(c_{n}\) represents the prototype of the \(n\)-th category, \(x_{n,k}\) represents the \(k\)-th support sample of the \(n\)-th category, \(f_{}\) represents the feature embedding network. Finally, we utilize the prototype classifier to make prediction on the query set:

\[_{x_{j}}=(x_{j}),c_{n }))}{_{n^{}}(-d(f_{}(x_{j} ),c_{n^{}}))},n[1,N],\] (4)

where \(x_{j}_{Q}\), \(_{x_{j}}\) represents the prediction scores of \(x_{j}\), \(d()\) represents the Euclidean distance. For the query image \(x_{j}\), the category corresponding to the highest score in \(_{x_{j}}\) is used as the predicted label \(_{x_{j}}\). Subsequently, we calculate the cross-entropy loss between the predicted label \(_{x_{j}}\) and the ground truth \(y_{x_{j}}\) as:

\[_{x_{j}}^{ce}=H(_{x_{j}},y_{x_{j}}),\] (5)

where \(H()\) denotes the cross-entropy loss function.

The high- or low-frequency branch.As illustrated in Fig. 1, both the high-frequency branch and the low-frequency branch maintain consistency with the architecture of the main branch. In practice, we input the decomposed high-frequency task \(^{high}\) and low-frequency task \(^{low}\) into these two branches, respectively, to obtain the corresponding features and prediction scores for the query set. Mathematically, the prediction scores for the query image \(x_{j}\) in the high-frequency branch and the low-frequency branch are denoted as \(_{x_{j}}^{low}\) and \(_{x_{j}}^{high}\), respectively.

Frequency prior regularization.In this work, we posit that the over-fitting problem is the core crux that limits the cross-domain generalization of meta-learning model. To this end, we resort to cross-domain invariant priors to regularize meta-learning in the source domain. Motivated by this perspective, we propose a prediction consistency prior and a feature reconstruction prior to jointly regularize the feature embedding network during meta-learning using high-low frequency information obtained from image decomposition. Specifically, the prediction consistency prior aims to minimize the separate Kullback-Leibler divergence between the prediction scores produced by the original query image and its each frequency component. Formally, for a query image \(x_{j}\), we align its high-frequency prediction distribution \(_{x_{j}}^{high}\) and low-frequency prediction distribution \(_{x_{j}}^{low}\) with the original distribution \(_{x_{j}}\) respectively:

\[_{x_{j}}^{align}=D_{KL}(_{x_{j}}^{low}|| _{x_{j}})+D_{KL}(_{x_{j}}^{high}||_{x_{j}} ),\] (6)

where \(D_{KL}()\) is the Kullback-Leibler divergence loss function. The rationale behind this approach is twofold. Firstly, through explicit decomposition-alignment, we compel the model to attend to both low-frequency content and high-frequency structure. Despite their distinct nature, these two types of features synergistically contribute and complement each other in the challenge of cross-domain generalization. Secondly, establishing prediction consistency between high-low frequency and the original one is domain-invariant. This consistency aids the model in generalizing effectively across different domains.

The feature reconstruction prior aims at reconstructing the original features utilizing low-frequency and high-frequency information in the latent space, which promotes the model to learn comprehensive representations. Specifically, we first project embedding features into the low-dimensional latent space, and then utilize the information retained by high- and low-frequency to reconstruct the original features:

\[z_{x_{i}}=g_{}(f_{}(x_{i})),\] (7)

\[_{x_{i}}=g_{}(f_{}(x_{i}^{low}))+g_{ }(f_{}(x_{i}^{high})),\] (8)

where \(f_{}\) and \(f_{}\) are the feature embedding network of the low-frequency branch and the high-frequency branch respectively, \(g_{}\) is a projector composed of one layer full connected neural network (512\(\)256), \(_{x_{i}}\) is the reconstructed feature. Then, the reconstruction loss is calculated as:

\[_{x_{i}}^{recon}=MSE(_{x_{i}},z_{x_{i}}),\] (9)

where \(MSE()\) represents the mean square error loss function.

Meta-training.Based on the description provided above, for a few-shot task \(\), the total loss can be formulated as:

\[=_{Q}|}_{x_{j}_{Q} }(_{x_{j}}^{ce}+_{x_{j}}^{align})+|}_{x_{i}}_{x_{i}}^{recon}.\] (10)

Following this, we compute the gradient based on the total loss \(\) to update both the main branch \(\) and the projector \(\). While one straightforward approach is to share parameters between the high-low frequency branches and the main branch, this might lead the feature embedding network to primarily focus on common features among the three, potentially causing distinctive features in the high-frequency or low-frequency branches to be overlooked. To address this concern and extract more distinctive features, we opt for an explicit design where three separate feature embedding networks are employed without parameter sharing. However, updating the high-frequency and low-frequency branches through gradient back-propagation can introduce additional computational overhead. As a solution, we update the high-frequency branch \(\) and low-frequency branch \(\) as the Exponential Moving Average (EMA) of the main branch \(\) during meta-training:

\[& m_{1}+(1-m_{1} ),\\ & m_{2}+(1-m_{2}) ,\] (11)

where \(m_{1}\) and \(m_{2}\) are momentum hyper-parameters. We describe the entire meta-training process in detail in Algorithm 1.

Cross-domain evaluation.Once the model is trained, only the main branch \(f_{}\) is retained for meta-testing on target domains. The proposed method is designed to enable the model to learn cross-domain transferable knowledge during the training phase, achieving effective generalization without relying on task-level feature extractor fine-tuning during meta-testing. Specifically, for each meta-testing task in the target domain, the main branch is utilized to extract features. Subsequently, the support set \(_{S}\) is employed to construct a task-specific classifier for inference on the query set \(_{Q}\). It's important to note that the proposed method does not require image decomposition during the meta-testing phase, thereby avoiding additional computational overhead.

## 3 Experimental Analysis

In this section, we begin by providing a detailed description of the experimental configuration, encompassing pre-training, meta-training, and meta-testing. Following that, we analyze the advantages of the proposed method in comparison with state-of-the-art methods. Lastly, we delve into a comprehensive ablation study to further investigate the effectiveness of our approach. Due to space limitations, we put more experiments and analyses in the appendix.

### Experimental details

Source domain and target domains.We focus on the most challenging scenario of single-source domain Cross-Domain Few-Shot Learning (CD-FSL). Following the established setup Guo et al. (2020), Li et al. (2022), Zhou et al. (2023), we employ the base classes of the _mini_-ImageNet Vinyals et al. (2016) as the source domain dataset. Our model is evaluated across multiple target domains, encompassing natural image domains (_CUB_, _Cars_, _Places_, _Plantae_), remote sensing domain (_EuroSAT_), agricultural domain (_CropDisease_), and medical domains (_ChestX_, _ISIC_). These datasets are widely recognized in the field of cross-domain few-shot learning. Additional details about each dataset can be found in Guo et al. (2020), Tseng et al. (2019).

Pre-training and meta-training.In the context of CD-FSL, pre-training is a common technique Li et al. (2022), Zhou et al. (2023), Hu and Ma (2022), Wang and Deng (2021), aiming to provide feature initialization for meta-training. Specifically, it involves supervised classification on the source domain through batch training. Following Li et al. (2022), Zhou et al. (2023), Hu and Ma (2022), we utilize ResNet-10 as the feature embedding network and a one-layer fully connected neural network as the classifier. The total number of pre-training epochs is set to 400. After pre-training, only the feature embedding network is retained as the feature extractor for meta-training. During the meta-training phase, we employ Adam as the optimizer and conduct meta-training for 50 epochs with a learning rate of 0.001. In each epoch, we randomly sample 100 meta-tasks, where each meta-task consists of 5-way 5-shot 15-query. Data augmentation techniques such as "Resize," "ImageJitter," and "RandomHorizontalFlip" are applied during meta-training. We set hyper-parameters \(m_{1}\)=0.997 and \(m_{2}\)=0.999. All experiments were performed on a 4090 GPU. Our experimental platform is a 4090 GPU. Further details and verification of hyper-parameters can be found in the supplementary material.

Meta-testing.Upon completion of meta-training, we directly employ the learned model for meta-testing across all target domains. Specifically, for each target domain, we randomly sample 600 meta-tasks for testing. We consider two challenging meta-tasks: a 5-way 1-shot 15-query task and a 5-way 5-shot 15-query task. In each meta-task, we learn a Logistic Regression classifier using the support set and then conduct inference on the query set.

### Comparison with state-of-the-art methods

Methods.In the realm of single-source domain CD-FSL, the state-of-the-art methods primarily include LDP-net Zhou et al. (2023), StyleAdv Fu et al. (2023), GNN+wave-SAN Fu et al. (2022), RDC Li et al. (2022), AFA Hu and Ma (2022), ATA Wang and Deng (2021), LRP Sun et al. (2021), FWT Tseng et al. (2019), and Fine-tuning Guo et al. (2020). These methods can be categorized into three types: direct inference, using query samples to assist inference (marked with \(\)), and fine-tuning-based inference (marked with \(*\)).

Among these methods, direct inference (e.g., LDP-net, MatchingNet, AFA, ATA) is the most straightforward manifestation of model generalization. It handles each test task without fine-tuning the feature embedding network, meeting practical application requirements. Using query samples to assist inference (e.g., RDC\({}^{}\), LDP-net\({}^{}\), AFA\({}^{}\), ATA\({}^{}\)) is also a common experimental setting. It is noteworthy that GNN+wave-SAN\({}^{}\) and StyleAdv\({}^{}\) also leverage query samples in an unsupervised manner. The main reason is that both GNN+wave-SAN and StyleAdv use Graph Neural Network (GNN)Garcia and Bruna (2018) as a classifier. GNN treats each sample in the few-shot task as a node of the graph, and the associations between different samples as edges for reasoning, akin to label propagationLiu et al. (2019). This approach implicitly leverages unsupervised query samples when the number of query samples in the few-shot task exceeds one. The original GNN paper Garcia and Bruna (2018) tested a single query image for each few-shot task, avoiding this issue. For a fair

  
**Methods** & **Ft** & **CUB** & **Cars** & **Places** & **Platese** & **Chest** & **ISIC** & **EuroSAT** & **CropDisease** & **Ave.** \\  MatchingNet Vinyals et al. (2016) & ✗ & 35.89 & 30.77 & 49.86 & 32.70 & 20.91 & 29.46 & 50.67 & 48.47 & 37.34 \\ RelationNet Sung et al. (2018) & ✗ & 41.27 & 30.09 & 48.16 & 31.23 & 21.95 & 30.53 & 49.08 & 53.58 & 38.24 \\ GNN Garcia and Bruna (2018) & ✗ & 44.40 & 31.72 & 52.42 & 33.60 & 21.94 & 30.14 & 54.61 & 59.19 & 41.00 \\ FWT Tseng et al. (2019) & ✗ & 45.50 & 32.25 & 53.44 & 32.56 & 22.00 & 30.22 & 55.53 & 60.74 & 41.53 \\ LRP Sun et al. (2021) & ✗ & 48.29 & 32.78 & **54.83** & 37.49 & 22.11 & 30.94 & 54.99 & 59.23 & 42.58 \\ ATA Wang and Deng (2021) & ✗ & 45.00 & 33.61 & 53.57 & 34.42 & 22.10 & 33.21 & 61.35 & 67.47 & 43.84 \\ AFA Hu and Ma (2022) & ✗ & 46.86 & 34.25 & 54.04 & 36.76 & 22.92 & 33.21 & 63.12 & 67.61 & 44.85 \\ LDP-net Zhou et al. (2023) & ✗ & 49.82 & 35.51 & 53.82 & 39.84 & **23.01** & 33.97 & **65.11** & 69.64 & 46.34 \\ Ours & ✗ & **51.55** & **37.04** & 52.06 & **41.55** & 22.82 & **33.98** & 64.31 & **71.47** & **46.85** \\  ATA\({}^{}\) Wang and Deng (2021) & ✗ & 50.26 & 34.18 & 57.03 & 39.83 & 21.67 & **34.70** & 65.94 & 77.82 & 47.68 \\ AFA\({}^{}\) Hu and Ma (2022) & ✗ & 50.85 & 38.43 & 60.29 & 40.27 & 21.69 & 34.25 & 66.17 & 72.44 & 48.05 \\ RDC Li et al. (2022) & ✗ & 47.77 & 38.74 & 58.24 & 41.88 & **22.66** & 32.29 & 67.58 & 80.88 & 48.83 \\ GNN+wave-SAN\({}^{}\) Fu et al. (2022) & ✗ & 50.25 & 33.55 & 57.75 & 40.71 & 22.93 & 33.35 & 69.64 & 70.80 & 47.37 \\ LDP-net\({}^{}\) Zhou et al. (2023) & ✗ & 55.94 & 37.74 & 62.21 & 41.04 & 22.21 & 33.44 & **73.25** & 81.24 & 50.85 \\ StyleAdv\({}^{}\) Fu et al. (2023) & ✗ & 48.49 & 34.64 & 58.58 & 41.13 & 22.64 & 33.96 & 70.94 & 74.13 & 48.06 \\ Ours\({}^{}\) & ✗ & **59.48** & **38.86** & **62.90** & **44.06** & 22.48 & 34.28 & 69.56 & **84.01** & **51.95** \\  Fine-tuning Guo et al. (2020) & ✗ & 43.53 & 35.12 & 50.57 & 38.77 & 22.13 & 34.60 & 66.17 & 73.43 & 45.54 \\ ATA\({}^{}\) Wang and Deng (2021) & ✗ & 51.89 & 38.07 & 57.26 & 40.75 & 22.45 & 35.55 & 70.84 & 82.47 & 49.91 \\ RDC\({}^{}\) Li et al. (2022) & ✗ & 50.09 & 39.04 & 61.17 & 41.30 & 22.32 & 36.28 & 70.51 & 85.79 & 50.81 \\   

Table 1: Comparison with state-of-the-art methods on 5-way 1-shot cross-domain FSL. Average classification accuracies (%) are provided. \({}^{}\) stands for exploiting the full data of FSL task. \({}^{*}\) means that the feature embedding network needs to be fine-tuned (Ft) on each target domain tasks. The best results are in bold.

comparison, we also implement a variant that uses query samples to assist inference. Specifically, we train a classifier based on the support set to generate pseudo-labels for the query set, then filter samples from the query set based on these pseudo-labels to expand the support set, and finally retrain the classifier based on the expanded support set for the ultimate prediction on the query set.

Results.Tables 1 and 2 present the experimental results under 5-way 1-shot and 5-way 5-shot settings, respectively. For an easy comparison, the average performance across eight target domains is calculated as the metric. Our method achieves 46.85% (1-shot) and 63.77% (5-shot) under the direct inference setting. Compared to the second-highest method LDP-net Zhou et al. (2023), the proposed method improved by 0.51% and 1.17% on the 1-shot and 5-shot tasks, respectively. In comparison to other methods like AFA Hu and Ma (2022), ATA Wang and Deng (2021), LRP Sun et al. (2021), and FWT Tseng et al. (2019), the proposed method demonstrates greater performance advantages. Moreover, the proposed method achieves the best results on five target domains, showcasing its robust generalization ability across diverse domains. When the proposed method further utilizes query samples to assist inference, the performance is further improved. Under the same comparison, the proposed method (\({}^{}\)) improved by 1.10% (1-shot) and 1.40% (5-shot) compared to the second-best method LDP-net\({}^{}\)Zhou et al. (2023). In contrast to methods based on fine-tuning (e.g., Fine-tuning\({}^{*}\)Guo et al. (2020), RDC\({}^{*\,}\)Li et al. (2022)), the proposed method still achieves certain performance advantages without requiring additional fine-tuning. In summary, the proposed method has demonstrated the best cross-domain few-shot learning performance, indicating its ability to learn generalizable features in the source domain. Additionally, the method's independence from task-level embedding network fine-tuning makes it suitable for potential industrial applications.

### Ablation study

Comparison with baselines.We design two baselines: the "Pre-training baseline" and the "Meta-baseline." For the "Pre-training baseline", we directly use the pre-trained model for meta-testing. The proposed method performs meta-training on the basis of pre-training. When all components are removed from the proposed method, it is equivalent to the "Meta-baseline"Chen et al. (2021). We take the "Meta-baseline" as the baseline of the proposed method. For a fair comparison, during the meta-testing stage, these two baselines also use the same classifier as the proposed method. The

    & **Fi** & **CUB** & **Cars** & **Places** & **Plantae** & **Chest** & **ISC** & **EuroSAT** & **CropDisease** & **Ave.** \\  MatchingNet Vinyals et al. (2016) & ✗ & 51.37 & 38.99 & 63.16 & 46.53 & 22.40 & 36.74 & 64.45 & 66.39 & 48.75 \\ MAML Finn et al. (2017) & ✗ & - & - & - & 23.48 & 40.13 & 71.70 & 78.05 & - \\ RelationNet Sung et al. (2018) & ✗ & 56.77 & 40.46 & 64.25 & 42.71 & 24.07 & 38.60 & 65.56 & 72.86 & 50.66 \\ MetaOptNet Lee et al. (2019) & ✗ & - & - & - & 22.53 & 36.28 & 64.44 & 68.41 & - \\ GNN Garcia and Ruma (2018) & ✗ & 62.87 & 43.70 & 70.91 & 48.51 & 23.87 & 42.54 & 78.69 & 83.12 & 56.77 \\ FWT Tseng et al. (2019) & ✗ & 64.97 & 46.19 & 70.70 & 49.66 & 24.28 & 40.87 & 78.02 & 87.07 & 57.72 \\ LRP Sun et al. (2021) & ✗ & 64.44 & 46.20 & 74.45 & 54.46 & 24.53 & 44.14 & 77.14 & 86.15 & 58.94 \\ ATA Wang and Deng (2021) & ✗ & 66.22 & 49.14 & 75.48 & 52.69 & 24.32 & 44.91 & 83.75 & 90.59 & 60.89 \\ AFA Hu and Ma (2022) & ✗ & 68.25 & 49.28 & **76.21** & 54.26 & 25.02 & 46.01 & **85.58** & 88.06 & 61.58 \\ LDP-net Zhou et al. (2023) & ✗ & 70.39 & 52.84 & 72.90 & 58.49 & **26.67** & 48.06 & 82.01 & 89.40 & 62.60 \\ Ours & ✗ & **73.61** & **54.22** & 73.78 & **61.39** & 26.53 & **48.70** & 81.24 & **90.68** & **63.77** \\  ATA’ Wang and Deng (2021) & ✗ & 65.31 & 46.95 & 72.12 & 55.08 & 23.60 & 45.83 & 79.47 & 88.15 & 59.56 \\ AFA’ Hu and Ma (2022) & ✗ & 65.86 & 47.89 & 72.81 & 55.67 & 23.47 & 46.29 & 80.12 & 85.69 & 59.73 \\ RDC\({}^{}\) Li et al. (2022) & ✗ & 63.39 & 52.75 & 72.83 & 55.30 & 25.10 & 42.10 & 79.12 & 88.03 & 59.83 \\ GNN+wave-SAN\({}^{}\) Fu et al. (2022) & ✗ & 70.31 & 46.11 & 76.88 & 57.72 & 25.63 & 44.93 & 85.22 & 89.70 & 62.06 \\ LDP-net\({}^{}\) Zhou et al. (2023) & ✗ & 73.34 & 53.06 & 75.47 & 59.64 & **26.88** & 48.45 & 91.89 & 64.10 \\ StyleAAJ\({}^{}\) Fu et al. (2023) & ✗ & 68.72 & 50.13 & **77.73** & 61.52 & 26.07 & 45.77 & **86.58** & **93.65** & 63.77 \\ Ours\({}^{}\) & ✗ & **76.68** & **55.44** & 76.98 & **63.08** & 26.45 & **49.07** & 83.22 & 93.09 & **65.50** \\  Fine-tuning\({}^{*}\) Guo et al. (2020) & ✗ & 63.76 & 51.21 & 70.68 & 56.45 & 25.37 & 49.51 & 81.59 & 89.84 & 61.05 \\ NSAE(CE+CE)\({}^{}\) Liang et al. (2021) & ✗ & 68.51 & 54.91 & 71.02 & 59.55 & 27.10 & 54.05 & 83.96 & 93.14 & 64.03 \\ CorefESS\({}^{*}\) Das et al. (2011) & ✗ & - & - & - & 27.09 & 48.85 & 84.65 & 88.88 & - \\ ATA’\({}^{}\) Wang and Deng (2021) & ✗ & 70.14 & 55.23 & 73.87 & 59.02 & 24.74 & 49.83 & 85.47 & 93.56 & 63.98 \\ RDC\({}^{}\) Li et al. (2022) & ✗ & 67.23 & 53.49 & 74.91 & 57.47 & 25.07 & 49.91 & 84.29 & 93.30 & 63.21 \\   

Table 2: Comparison with state-of-the-art methods on 5-way 5-shot cross-domain FSL. Average classification accuracies (%) are provided. \({}^{}\) stands for exploiting the full data of FSL task. \({}^{*}\) means that the feature embedding network needs to be fine-tuned (Fi) on each target domain tasks. The best results are in bold.

comparison results are shown in Table3. Overall, compared with these two baselines, the proposed method has achieved greater performance advantages. Specifically, compared with the "Pre-training baseline", the performance of the proposed method is improved by 2.79% (1-shot) and 3.28% (5-shot) on average. Compared with the "Meta-baseline", the performance of the proposed method is improved by 2.26% (1-shot) and 3.10% (5-shot) on average. These results show that the proposed method can improve the baselines and provide a novel meta-learning framework for CD-FSL.

Effectiveness of the proposed frequency prior.In this work, we propose a prediction consistency prior and a feature reconstruction prior to jointly regularize the embedding network during meta-learning. Among them, the prediction consistency prior encourages to align the predictions produced by the original query image and its each frequency component. The feature reconstruction prior aims at reconstructing the original features utilizing low-frequency and high-frequency information in the latent space, which promotes the model to learn comprehensive representations. We conduct ablation studies to illustrate the contribution of these two components. The results are shown in Table 3. As can be seen, compared to the "Meta-baseline" (meaning not using any components), the proposed method achieves average gains of 1.61% (1-shot) and 2.45% (5-shot). The above experimental results show the proposed prediction consistency prior is effective. We can draw similar conclusions for feature reconstruction prior. In addition, the proposed method improves by nearly 0.65% under both 1-shot and 5-shot tasks when the feature reconstruction module is added. In particular, for the CUB dataset, the proposed method can achieve nearly 1% improvement on the 5-shot task. This indicates that the proposed feature reconstruction prior is beneficial to the entire method.

### Visualization

Feature highlight.we adhere to established practices Zhou et al. (2023), utilizing the model trained on the source domain to extract features from target domain images. Subsequently, these features serve as attention scores to activate the original images. The results are presented in Fig.2. Overall, our proposed method exhibits the capability to capture more nuanced representations compared to the baseline, a critical aspect for effective cross-domain generalization. As an illustrative example, consider image (d) in Fig.2. The baseline tends to concentrate solely on the neck of the bird, neglecting the broader characteristics of its entire shape. In contrast, our method not only hones in on local texture details, such as the head, wings, and claws, but also encapsulates the entirety of the contour shape. This underscores the capacity of our method to learn comprehensive features, avoiding undue emphasis on local textures alone.

Domain gap.The t-SNE Van der Maaten and Hinton (2008) visual results are shown in Fig.3 (a-b). The blue cluster represents the source domain distribution, while the other four colors denote distinct target domain distributions. Notably, the baseline exhibits a substantial gap between target domains and the source domain. In contrast, our method effectively mitigates this domain gap. In addition, we conduct a quantitative assessment of the distribution distance between different target domains and the source domain. Specifically, we compute the first-order statistics based on the sampled samples in each domain, treating it as the statistical characteristic of that domain. Subsequently, we measure the Euclidean distance between the first-order statistics of different target domains and the source domain. The resulting quantitative metrics, comparing the proposed method and the baseline, are visualized in Fig.3 (c). Evidently, the proposed method exhibits a smaller distribution distance between the source domain and the target domains, with particularly notable improvements in the medical domain (ISIC)

    &  &  &  &  &  \\  Method & **1-shot** & **5-shot** & **1-shot** & **5-shot** & **1-shot** & **5-shot** & **1-shot** & **5-shot** & **1-shot** & **5-shot** \\   Pretraining baseline \\ Meta baseline \\ Ours \\  } & 46.90 & 68.05 & 50.24 & 17.43 & 38.47 & 57.08 & 69.89 & 89.80 & 51.37 & 71.59 \\  & 47.05 & 67.99 & 51.09 & 71.74 & 39.26 & 57.82 & 70.22 & 89.54 & 51.30 & 71.77 \\  & **51.55** & **73.61** & **52.06** & **73.78** & **41.55** & **73.74** & **90.68** & **54.16** & **74.87** \\ 
**Alignment** & **Reconstruction** & **1-shot** & **-shot** & **-shot** & **-shot** & **-shot** & **-shot** & **-shot** & **-shot** & **-shot** & **-shot** & **-shot** \\   **✓** \\ \(\)** \\ \(\)** \\  } & **✗** & 50.79 & 72.65 & 51.42 & 73.22 & 41.05 & 60.93 & 70.80 & 90.11 & 53.51 & 74.22 \\  & 50.55 & 71.39 & 51.96 & 72.60 & 41.11 & 60.22 & 70.04 & 89.44 & 53.41 & 73.41 \\  & 51.55 & 73.61 & 52.06 & 73.78 & 41.55 & 61.39 & 71.47 & 90.68 & 54.16 & 74.87 \\   

Table 3: Ablation study. Average classification accuracies (%) are provided. \(\) indicates that this component is used, vice versa. The best results are in bold.

and the remote sensing domain (EuroSAT). This underscores the capability of our method to learn robust representations in the source domain, effectively mitigating domain shifts.

## 4 Conclusions

In this work, we propose an insightful meta-learning framework inspired by the cross-domain invariant frequency priors. Furthermore, we present a prediction consistency prior and a feature reconstruction prior to jointly regularize meta-learning on source domain, enabling learning cross-domain transferable features. This simple yet effective work achieves state-of-the-art experimental results as well as excellent inference efficiency.

Limitations.The limitation of the proposed method lies on its robustness in some extremely challenging cross-domain tasks. For example, on the Chest dataset, the proposed method fails to outperforms all competitors. This indicates that the fixed image decomposition (e.g., Fast Fourier Transform or Wavelet Transform) strategy may be not the optimal solution for all unknown cases in terms of exploit frequency priors. In the future, we will attempt to exploit the learnable image decomposition strategy. In addition, the proposed method requires to decompose the query image before being fed into the network. While the Fast Fourier Transform for signal decomposition is efficient, this does introduce a certain additional training time overhead. Notably, this work does not contain negative social impact.

Acknowledge.This work was supported in part by the National Natural Science Foundation of China under Grand 62372379, Grant 62071387, Grant 62472350, Grant 62472359 and Grant 62101454; in part by the National Key R&D Program of China under Grand 2022ZD0118700; in part by the Xi'an's Key Industrial Chain Core Technology Breakthrough Project: AI Core Technology Breakthrough under Grand 23ZDCYJSGG0003-2023; in part by Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University under Grant CX2024017; in part by National Key Laboratory of Science and Technology on Space-Born Intelligent Information Processing foundation under Grant TJ-04-23-04.

Figure 3: Visual observations in domain gap.

Figure 2: Feature visualization for Baseline and the proposed method.