# UIR-LoRA: Achieving Universal Image Restoration through Multiple Low-Rank Adaptation

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Existing unified methods typically treat multi-degradation image restoration as a multi-task learning problem. Despite performing effectively compared to single degradation restoration methods, they overlook the utilization of commonalities and specificities within multi-task restoration, thereby impeding the model's performance. Inspired by the success of deep generative models and fine-tuning techniques, we proposed a universal image restoration framework based on multiple low-rank adapters (LoRA) from multi-domain transfer learning. Our framework leverages the pre-trained generative model as the shared component for multi-degradation restoration and transfers it to specific degradation image restoration tasks using low-rank adaptation. Additionally, we introduce a LoRA composing strategy based on the degradation similarity, which adaptively combines trained LoRAs and enables our model to be applicable for mixed degradation restoration. Extensive experiments on multiple and mixed degradations demonstrate that the proposed universal image restoration method not only achieves higher fidelity and perceptual image quality but also has better generalization ability than other unified image restoration models.

## 1 Introduction

In the wild, a range of distortions commonly appear in captured images, including noise, blur, low light, and various weather degradations. As a fundamental task in low-level vision, image restoration aims to eliminate these distortions and recover sharp details and original scene information from corrupted images. With the assistance of deep learning, an abundance of restoration approaches  have made significant progress in eliminating single degradation from images. However, these approaches typically require additional training from scratch on specific image pairs in multi-degraded scenarios, which leads to inconvenience in usage and limited generalization ability.

For simplicity and practicality, some existing works consider training a unified model (also called all-in-one model) to handle multiple degradations as multi-task learning. These studies primarily explore how to discern degradation from the image and integrate it into the restoration network. Nevertheless, these methods share all parameters across different degradations, resulting in gradient conflicts  that hinder further improvement of unified models' performance.

Digging deeper, the underlying issue lies in that the similarities among different image restoration tasks and the inherent specificity of each degradation are not well considered and utilized in the training. This limitation drives us to seek solutions for multi-degradation restoration by leveraging both commonalities and specificities.

Inspired by the successes of deep generative models[37; 36; 35] and fine-tuning techniques[11; 10; 4], we propose addressing the aforementioned issue from the perspective of multi-domain transfer learning, as presented in Figure 1. The pre-trained generative model exhibits powerful capabilities, implying rich prior knowledge of clear image distribution \(p(x)\), which is exactly what is needed for image restoration. Since image prior \(p(x)\) is degradation-agnostic and applicable to all types of degraded images, the pre-trained generative model is an excellent candidate for serving as the shared component for multiple degradation restoration. To model the transition from the clean image domain to different degraded image domains, minimal specific parameters are required to fine-tune the pre-trained model for each degradation restoration task. This approach not only isolates conflicts between each degradation task but also ensures efficiency and performance during training.

Following the idea of multi-domain transfer learning, we proposed a universal image restoration framework based on multiple low-rank adaptations, named UIR-LoRA. In our framework, the pre-trained SD-turbo  serves as the shared fundamental model for multiple degradation restoration tasks due to its powerful one-step generation capability and extensive image priors. Subsequently, we incorporate the low-rank adaptation (LoRA) technique  to fine-tune the base model for each specific image restoration task. This involves augmenting low-dimensional parameter matrices on selected layers within the base model, ensuring efficient fine-tuning while maintaining independence between LoRAs for each specific degradation. Additionally, we propose a LoRA composition strategy based on degradation similarity. We calculate the similarity between degradation features extracted from degraded images and existing degradation types, utilizing it as weights for combining different LoRA experts. This strategy enables our method to be applicable for restoring mixed degradation images. Moreover, we conducted extensive experiments and compared our approach with several existing unified image restoration methods. The experimental results demonstrate that our method achieves superior performance in the restoration of various degradations and mixed degradations. Not only does our approach outperform existing methods in terms of distortion and perceptual metrics, but it also exhibits significant improvements in visual quality.

Our contributions can be summarized as follows:

* From the perspective of multi-domain transfer learning, we propose a novel universal image restoration framework based on multiple low-rank adaptations. It leverages the pre-trained generative model as the shared component for multi-degradation restoration and employs distinct LoRAs for multiple degradations to efficiently transfer to specific degradation restoration tasks.
* We introduce a LoRAs composition strategy based on the degradation similarity, which adaptively combines trained LoRAs and enables our model to be applicable for mixed degradation restoration.
* Through extensive experiments on multiple and mixed degradations, we demonstrate that the proposed universal image restoration method not only achieves higher fidelity and perceptual image quality but also has better generalization ability than other unified models.

Figure 1: Motivation of our work. A pre-trained generative model serves as the shared component and minimal parameters are added to model the specificity of each degradation restoration task.

Related Work

### Image Restoration

**Specific Degradation Restoration.** According to degradation type, image restoration tasks are categorized into different groups, including denoising, deblurring, inpainting, draining _etc_. Most existing image restoration methods [2; 53; 16; 56; 5; 14] mainly address the issue with a single degradation. Traditional approaches [27; 28; 7] have proposed image priors. While these priors can be applied to different degraded images, their capability is limited. Due to the remarkable capability of the deep neural network (DNN), numerous DNN-based methods [2; 53; 16] have been proposed to tackle image restoration tasks. While DNN-based methods have made significant progress, they struggle with multiple degradations and mixed degradations, since they typically require retraining from scratch on data with the same degradation.

**Universal degradation restoration.** Increasing attention is currently focused on developing a unified model to process multiple degradations. For example, AirNet explores the degradation representation in latent space for separating them in the restoration network. PromptIR utilizes a prompt block to extract the degradation-related features to improve the performance. Daclip-IR introduces the clip-based encoder to distinguish the type of degradation and extract the semantics information from distorted images and embed them into a diffusion model to generate high-quality images. Despite the advancements, these unified models still have limitations. They also require retraining all parameters when unseen degradations arrive and have limited performance due to the gradient conflict.

### Low-Rank Adaptation

LoRA  is proposed to fine-tune large models by freezing the pre-trained weights and introducing trainable low-rank matrices. This fine-tuning method leverages the property of "intrinsic dimension" within neural networks, lowering the rank of additional matrices and making the re-training process efficient. Concretely, given a weight matrices \(W^{n m}\) in pre-trained model \(_{p}\), two trainable matrices \(B^{n r}\) and \(A^{r m}\) are inserted into the layer to represent the LoRA \( W=BA\), where \(r\) is the rank and satisfy \(r mim(n,m)\), the updated weights \(W^{}\)are calculated by

\[W^{}=W+ W.\] (1)

By applying LoRA in pre-trained models, numerous image generation methods [29; 13], show superior performance in the field of image style and semantics concept transferring. Additionally, fine-tuning methods like ControlNet , T2i-adapter  are also commonly employed in large-scale pre-trained generative models such as Stable Diffusion , SDXL , and Imagen .

### Mixture of Experts

Mixture of Experts (MoE) [41; 49; 48] is an effective approach to scale up neural network capacity to improve performance. Specifically, MoE integrates multiple feed-forward networks into a transformer block, where each feed-forward network is regarded as an expert. A gating function is introduced to model the probability distribution across all experts in the MoE layer. The gating function is trainable and determines the activation of specific experts within the MoE layer based on top-k values. Broadly speaking, our framework aligns with the concept of MoE. However, unlike traditional MoE layers, we employ the more efficient LoRA as experts in selected frozen layers and utilize a degradation-aware router across all selected layers to uniformly activate experts, reducing learning complexity and avoiding conflicts among different image restoration tasks on experts.

## 3 Methodology

### Problem Definition

This paper seeks to develop a novel universal image restoration framework capable of handling diverse forms of image degradation in the wild by fine-tuning the pre-trained generative model. Consider a set of \(T\) image restoration tasks \(D=\{D^{k}\}_{k=1}^{T}\), where \(D^{k}=\{(x_{i},y_{i})\}_{i=1}^{n_{k}}\) is the training dataset containing \(n_{k}\) images pairs of the \(k\)-th image degradation task. Within the set of tasks \(D\)each task \(D^{k}\) only has a specific type of image degradation, with no intersection between any two tasks. Given a pre-trained generative model \(_{p}\) with frozen parameters, our objective is to learn a set of composite \(\{_{k}\}_{k=1}^{T}\) to construct a unified model \(f_{}\) that performs well on multi-degradation restoration and mixed degradation restoration by transferring learning, where \(=_{p}+_{k=1}^{T}s_{k}_{k}\) and \(s_{k}\) represents the composite weight for \(_{k}\). The trainable \(\{_{k}\}_{k=1}^{T}\) can be optimized through minimizing the overall image reconstruction loss:

\[L=E_{(x,y) D}l(f_{}(x),y).\] (2)

We will present how to design and optimize the trainable \(\{_{k}\}_{k=1}^{T}\) and construct the composite weights \(s\) in the next sections.

### Overview of Universal Framework

Inspired by transferring learning, we introduce a novel universal image restoration framework based on multiple low-rank adaptations, named UIR-LoRA. Referring to Figure 2, our framework consists of two main components, namely degradation-aware router and universal image restorer, respectively. The degradation-aware router first extracts the degradation feature from input degraded images and then calculates the similarity probabilities \(s\) with existing degradations in the latent space of CLIP model . For the universal image restorer, it comprises a pre-trained generative model \(_{p}\) and \(T\) trainable LoRAs \(\{_{k}\}_{k=1}^{T}\). This design is primarily motivated by two considerations: firstly, the pre-trained generative model contains extensive image priors that are degradation-agnostic and can be shared across all types of degraded images. Secondly, each LoRA can independently capture specific characteristics of each degradation without gradient conflicts. In practice, the pre-trained SD-turbo  is employed as the frozen base model in our framework and each LoRA \(_{k}\) serves as an expert responsible for transferring the frozen base model to a specific degradation restoration task \(D^{k}\). By adjusting the value of Top-K parameter within the degradation-aware router, different combinations of LoRAs in the universal image restorer can be activated, enabling the removal of a specific degradation and mixed degradation in multi-degraded scenarios.

Figure 2: Overview of UIR-LoRA. UIR-LoRA consists of two components: a degradation-aware router and a universal image restorer. The router calculates degradation similarity in the latent space of CLIP, while the restorer utilizes the similarity provided by the router to combine LoRAs and frozen base model and restore images with multiple or mixed degradations.

### Degradation-Aware Router

The Degradation-Aware Router is designed to provide the restorer with weights for LoRA combination based on degradation confidence. Following Daclip-ir , we utilized the pre-trained image encoder in CLIP  to obtain the degradation vector \(d^{1 z}\) from the input degraded image \(x\), where \(z\) is degradation length in latent space. Differing from Daclip-ir , we use the degradation vector and existing degradations to calculate the similarity, instead of directly embedding the degradation vector into the restoration network in Daclip-ir . The existing degradations refer to the vocabulary bank of diverse degradation types that we introduce in the router, such as "noisy", "blurry" and "shadowed". This vocabulary bank is highly compact and flexible when adding new degradation types. Similarly, by applying the text encoder of CLIP , the vocabulary bank can be encoded into the degradation bank \(B^{z T}\) in the latent space. As presented in Figure 2, the original degradation similarity \(s_{o}^{1 T}\) is calculated by:

\[s_{o}=dB.\] (3)

Building upon the original similarity, we adopt a more flexible and controllable Top-K strategy to modify \(s_{o}\). Specifically, we select the Top-K largest values from the original similarity \(s_{o}\), and normalize them to reallocate the weights for LoRAs. The reallocation process can be formulated as :

\[s= M_{K}}{ s_{o} M_{K}},\] (4)

where \(M_{K}\) represents a binary mask with the same length as \(s_{o}\), where it is 1 when the corresponding value in \(s_{o}\) is among the Top-K, otherwise it is 0. With a smaller value of \(K\), the restorer activates fewer LoRAs, reducing its computational load. For instance, with \(K=1\), only the most similar LoRA is activated and it yields effective results when \(s\) is accurate, but performance noticeably declines with inaccurate \(s\). Conversely, as \(K\) increases, the restorer exhibits higher tolerance to \(s\) and the combination of LoRAs allows it to handle mixed degradation.

### Universal Image Restorer

Our universal image restorer consists of a pre-trained generative model \(_{p}\) and a set of LoRAs \(\{_{k}\}_{k=1}^{T}\). As illustrated in Figure 2, our universal image restorer takes the degraded image \(x\) and similarity \(s\) predicted by the degradation-aware router as inputs. It then activates relevant LoRAs based on \(s\) to recover the degraded image along with the frozen base model. Since one of our objectives is to ensure that each LoRA serves as an expert in processing a specific degradation, the number of LoRAs in the restorer aligns with the number of degradation types, \(T\). In practice, we select multiple layers from the base model, For a selected layer \(W\) of the pre-trained base model, a sequence of trainable matrices \(\{ W_{k}\}_{k=1}^{T}\) are added into this layer, and the parameters of all chosen layers \(L\) form a complete LoRA \(_{k}=\{ W_{k}^{j}\}_{j L}\). As previously explained, each LoRA is a unique expert responsible for a specific degradation. Drawing inspiration from Mixture of Expert (MoE), we aggregate the outputs of each expert rather than directly merging parameters in . Therefore, given the input feature \(x_{in}\) of the current layer and the similarity \(s\), the total output \(x_{out}\) of this modified layer can be expressed as

\[x_{out}=f_{o}(x_{in})+_{i=1}^{K}s_{i}f_{i}(x_{in}),\] (5)

where \(f_{i}(x_{in})\) denotes the result of \(i\)-th trainable matrice \(W_{i}\), particularly \(f_{o}(x_{in})\) is output of the frozen base layer. From the equation 5, it can be observed that the introduced LoRAs interact with the frozen base model at intermediate feature layers in our restorer. This interaction forces the restorer to leverage the image priors of the pre-trained generative model and eliminate degradation with the assistance of LoRAs. In contrast to employing stable diffusion  directly as a post-processing technique, our restorer yields results closer to the true scene without introducing inaccurate structural details. Since each \(W\) is implemented using two low-rank matrices like the formula 1, the total trainable parameters of our framework are much smaller than that of the pre-train generative model.

### Training and Inference Procedure

During the training phase, for the efficient training of the universal image restorer, we ensure that each batch is sampled from the same degradation type \(D^{k}\), and activate the corresponding LoRAfor training. Since the dataset \(D\) is organized by degradation type without overlap and each LoRA is assigned to handle each type of degradation correspondingly, the overall optimization process in equation 2 can be decomposed into independent optimization processes for each degradation. This design and training process circumvent task conflicts among multiple degradations and makes it possible to use suitable loss functions for the specific degradation. Due to the availability of accurate \(s\) during training and the use of pre-trained encoders from CLIP  and Daclip-ir  in our router, the router was not utilized during training.

In the inference phase, the similarity \(s\) is unknown and needs to be estimated from the degraded image. The estimated similarity \(s\) serves as a reference in our framework and can also be manually specified by users. Subsequently, our universal image restorer composite LoRAs and recovers the input image with the guidance of \(s\).

## 4 Experiments

### Experimental Setting

**Datasets.** We validate the effectiveness of our framework in multiple and mixed degradation scenarios. In the case of multiple degradations, we follow Daclip-IR  and construct a dataset using 10 different single degradation datasets. Briefly, the composite dataset comprises a total of 52800 image pairs for training and 2490 image pairs for testing. The degradation types included are commonly encountered in image restoration, such as blur, noise, shadow, JPEG compression, and weather degradations. For mixed degradations, we utilize two degradation datasets, REDS  and LOLBlur . In REDS, the images are distorted by JPEG compression and blur, and those images in LOLBlur have blur and low light. For more details about datasets in our experiments, please refer to **Appendix**.

**Metrics.** The objective of the image restoration task is to output images with enhanced visual quality while maintaining high fidelity to the original scene information. This differs from image generation tasks, which prioritize visual quality. Therefore, to thoroughly evaluate the effectiveness of our method, we utilize reference-based image quality assessment techniques from both distortion and perceptual perspectives, including PSNR, SSIM, and LPIPS, as well as FID.

**Comparison Methods.** In the experiments, we primarily compare with several state-of-the-art methods in image restoration, which fall into two categories: regression model and generative model. Regression models include NAFNet , Restormet , as well as AirNet  and PromptIR  proposed for multiple degradation restoration. DiffBIR , IR-SDE  and Daclip-IR  are generative models built upon the diffusion model .

### Implementation Details

During the training, we adapt an AdamW optimizer to update the weights of trainable parameters in our model. Before training LoRA for specific degradation, we add skip-connections in the VAE of SD-turbo like [29; 44] and train them with multiple degraded images. We set the initialization

    &  &  &  \\   & PSNR\(\) & SSIM \(\) & LPIPS \(\) & FID \(\) & Param /M & Runtime /s \\  SwinIR  & 23.37 & 0.731 & 0.354 & 104.37 & 15.8 & 0.66 \\ NAFNet  & 26.34 & 0.847 & 0.159 & 55.68 & 67.9 & 0.54 \\ Restormer  & 26.43 & 0.850 & 0.157 & 54.03 & 26.1 & 0.14 \\  AirNet  & 25.62 & 0.844 & 0.182 & 64.86 & 7.6 & 1.50 \\ PromptIR  & 27.14 & 0.859 & 0.147 & 48.26 & 35.6 & 1.19 \\ IR-SDE  & 23.64 & 0.754 & 0.167 & 49.18 & 36.2 & 5.07 \\ DiffBIR  & 21.01 & 0.618 & 0.263 & 91.03 & 363.2 & 5.95 \\ Daclip-IR  & 27.01 & 0.794 & 0.127 & 34.89 & 295.2 & 4.09 \\
**UIR-LoRA (Ours)** & **28.08** & **0.864** & **0.104** & **30.58** & 95.2 & 0.44 \\   

Table 1: Comparison of the restoration results over ten different datasets. The best results are marked in boldface.

learning rate to 2e-4 and decrease it with CosineAnnealingLR. We trained every LoRA for 80K iterations with batch size 8 and we keep the same hyper-parameters when training different LoRAs. The default rank of LoRAs in VAE and Unet is 4 and 8, respectively.

### Multiple Image Restoration

For fair comparisons, all methods are trained and tested on the multiple degradation dataset. The results are presented in Table 1. We can find that our model, UIR-LoRA, considerably surpasses all compared image restoration approaches across four metrics. This indicates that our approach can balance generating clear structures and details while ensuring the restored images closely resemble the original information of the scene. The visual comparison results depicted in Figure 7 also confirm this assertion. Regression models such as NAFNet and Restormer , lacking extensive image priors, tend to produce blurred and over-smoothed images, leading to inferior visual outcomes. Conversely, generative models Daclip-IR  excessively prioritize perceptual quality, yielding artifacts and noise that diverge from the actual scene information. Our approach integrates the strengths of both categories of methods, enabling strong performance in both distortion and perceptual aspects

### Mixed Image Restoration

To evaluate the transferability of UIR-LoRA, we conduct some experiments on mixed degradation datasets from REDS and LOLBlur . Each image in these two datasets contains more than one type of degradation, like blur, jpeg compression, noise, and low light. We test the mixed degraded images using models trained on multiple degradations and set \(K\) to 2 in the router. As shown in Table 2, our method achieves superior results in both distortion and perceptual quality, particularly on the LOLBlur dataset. We also provide visual comparison results, as illustrated in Figure 4, our approach effectively enhances the low-light image compared to SOTA methods, highlighting its stronger transferability in the wild. More visual results can be found in **Appendix**.

Figure 3: Qualitative comparison on multiple degraded images.

[MISSING_PAGE_FAIL:8]

similarity achieves better outcomes. This suggests that the transferability between different types of degradation is limited and that specific parameters are needed to address their particularities. Furthermore, the selection of the K value also affects the model's performance. When an image has only one type of degradation, a smaller K value can result in comparable performance with lower inference costs. However, for mixed degradations, a larger K value is required to handle the more complex situation.

**Impact of LoRA's Rank.** Within our framework, LoRA is utilized to facilitate the transfer from the pre-trained generative model to the image restoration task. In order to investigate the impact of LoRA's rank on the performance of image restoration, we conduct experiments using deblurring and denoising tasks chosen from ten distinct degradation categories. We set the initial rank to 2 and incrementally increase the value by a factor of 2. The performance changes are depicted in Figure 5. It is evident that as the rank grows, the restoration results improve in distortion and perceptual quality, and at the same time, the number of trainable parameters also increases. Once the rank value exceeds 4, the performance improvement becomes progressively marginal. Therefore, we set the default rank to 4 in our restorer to balance between performance and complexity.

**Impact of Predicted Degradation.**

The resizing operation on input images in CLIP models [20; 35] may lead to inaccurate predictions of degradation types, especially for blurry images. To reduce its negative impact on performance, we introduce a simple way that uses the degradation vector of the image crop without resizing to correct the potential error in the resized image. Table 4 is the comparison conducted on blurry images from GoPro dataset. It can be observed that our model with modified operation has higher accuracy and better performance for deblurring.

## 5 Conclusion

In this paper, we propose a universal image restoration framework based on multiple low-rank adaptation, named UIR-LoRA, from the perspective of multi-domain transfer learning. UIR-LoRA utilizes a pre-trained generative model as the frozen base model and transfers its abundant image priors to different image restoration tasks using the LoRA technique. Moreover, we introduce a LoRA' composition strategy based on the degradation similarity that allows UIR-LoRA applicable for multiple and mixed degradations in the wild. Extensive experiments on universal image restoration tasks demonstrate the effectiveness and better generalization capability of our proposed UIR-LoRA.

## 6 Limitation and Discussion

Although our UIR-LoRA has achieved remarkable performance in image restoration tasks under both multiple and mixed degradations, it still has limitations and problems for further exploration. For instance, adding new trainable parameters into the network for unseen degradations is unavoidable in image restoration tasks, although UIR-LoRA is already more efficient and flexible compared to other approaches.

    & PSNR\(\) & SSIM \(\) & LPIPS \(\) & FID \(\) & Accuracy \(\) \\  Original & 26.66 & 0.839 & 0.159 & 18.72 & 91.6 \\ Modified & 26.87 & 0.842 & 0.155 & 18.42 & 99.2 \\   

Table 4: The accuracy of predicted degradation type

Figure 5: The impact of LoRAâ€™s rank on deblurring and denoising tasks.