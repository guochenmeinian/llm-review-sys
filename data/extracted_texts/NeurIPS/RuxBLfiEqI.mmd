# Diversified Outlier Exposure for Out-of-Distribution Detection via Informative Extrapolation

Jianing Zhu\({}^{1}\)  Geng Yu\({}^{2}\)  Jiangchao Yao\({}^{2,3}\)  Tongliang Liu\({}^{4}\)

Gang Niu\({}^{5}\)  Masashi Sugiyama\({}^{5,6}\)  Bo Han\({}^{1,5}\)

\({}^{1}\)Hong Kong Baptist University \({}^{2}\)CMIC, Shanghai Jiao Tong University

\({}^{3}\)Shanghai AI Laboratory \({}^{4}\)Sydney AI Centre, The University of Sydney

\({}^{5}\)RIKEN Center for Advanced Intelligence Project \({}^{6}\)The University of Tokyo

{csinzhu, bhanml}@comp.hkbu.edu.hk

{warriors30, sunarker}@sjtu.edu.cn  tongliang.liu@sydney.edu.au

gang.niu.ml@gmail.com  sugi@k.u-tokyo.ac.jp

Correspondence to Bo Han (bhanml@comp.hkbu.edu.hk).

###### Abstract

Out-of-distribution (OOD) detection is important for deploying reliable machine learning models on real-world applications. Recent advances in outlier exposure have shown promising results on OOD detection via fine-tuning model with informatively sampled auxiliary outliers. However, previous methods assume that the collected outliers can be sufficiently large and representative to cover the boundary between ID and OOD data, which might be impractical and challenging. In this work, we propose a novel framework, namely, _Diversified Outlier Exposure (DivoOE)_, for effective OOD detection via informative extrapolation based on the given auxiliary outliers. Specifically, DivOE introduces a new learning objective, which diversifies the auxiliary distribution by explicitly synthesizing more informative outliers for extrapolation during training. It leverages a multi-step optimization method to generate novel outliers beyond the original ones, which is compatible with many variants of outlier exposure. Extensive experiments and analyses have been conducted to characterize and demonstrate the effectiveness of the proposed DivOE. The code is publicly available at: https://github.com/tmlr-group/DivOE.

## 1 Introduction

Out-of-distribution (OOD) detection (Nguyen et al., 2015; Hendrycks and Gimpel, 2017) gains increasing attention in deploying machine learning models into open-world scenarios, as deep learning systems are expected to conduct reliable predictions on in-distribution (ID) data while identifying OOD inputs (Bommasani et al., 2021; Hendrycks et al., 2022). It becomes more critical in safety-critical applications like financial or medical intelligence, where the false prediction for samples out of pre-defined label space can sometimes be a disaster. Extensive explorations (Hendrycks et al., 2019; Liu et al., 2020; Tack et al., 2020; Mohseni et al., 2020; Sehwag et al., 2021; Yang et al., 2021; Yang et al., 2022) in recent years has been contributed to improving the model ability for OOD detection.

Compared with post-hoc methods (Hendrycks and Gimpel, 2017; Liang et al., 2018; Liu et al., 2020; Huang et al., 2021; Sun et al., 2022) which designs different score functions for OOD uncertainty estimation, Outlier Exposure (OE) (Hendrycks et al., 2019) is another kind of method owning better performance improvement on OOD detection (Mohseni et al., 2020; Sehwag et al., 2021; Ming et al., 2022; Katz-Samuels et al., 2022; Wang et al., 2023). The latter engages surrogate OOD data duringtraining and regularizes the model via fine-tuning those auxiliary outliers. The conceptual idea is to learn the knowledge from auxiliary outliers for effectively identifying OOD inputs. Under such a learning framework, there is an intuitive gap between the surrogate OOD data and the unseen OOD inputs (Fang et al., 2022, Ming et al., 2022) as illustrated in Figure 1. It will be a fundamental problem for boosting the model's discriminative capability on the OOD inputs. Given the finite auxiliary outliers, it naturally motivates the following critical research question: _How could we utilize the given outliers for effective OOD detection if the auxiliary outliers are not informative enough?_

Addressing the essential distribution gap between surrogate OOD data and the unseen OOD inputs remains challenging (Hendrycks et al., 2019, Fang et al., 2022, Du et al., 2022, Yang et al., 2021), as it is hard to know the prior knowledge of potential OOD inputs would be encountered at inference stage (Hendrycks et al., 2022), and intentionally collect them. As the unseen OOD inputs in the real-world scenarios are complex (Cimpoi et al., 2014, Yu et al., 2015, Yang et al., 2022), the performance of OE-based methods is heavily affected by the given auxiliary outliers (as empirically presented in Figure 2). Given the finite auxiliary outliers, the surrogate OOD data are expected to have less discrepancy (Hendrycks et al., 2019, Fang et al., 2022) with the unseen OOD inputs, especially for the ones that are close to the decision boundary. Therefore, a potential idea is to expand the given outliers to cover more informative distributions and better generalize to the unseen OOD inputs.

Based on the previous analysis, we propose a new learning framework, i.e., _Divified Outlier Exposure_ (DivOE), to alleviate the pessimism of limited informative auxiliary outliers. At the high level, we aim to diversify the current distribution represented by the surrogate OOD data (e.g., Figure 2). In detail, we introduce a novel learning objective (i.e., Eq. (4)) that conducts informative extrapolation based on the given auxiliary outliers. Through a multi-step optimization target for generating a fraction of more informative outliers, DivOE can adaptively extrapolate and learn beyond the original OOD distribution. It realizes expanding the overall surrogate distribution of OOD data toward a broader coverage by maximizing the difference between the extrapolated one with its original counterpart.

We conduct extensive experiments to characterize and present our proposed methods. We have verified its effectiveness with a series of OOD detection benchmarks mainly on two common ID datasets, i.e., CIFAR-10 and CIFAR-100, and also demonstrated its scalability using the ImageNet dataset with the large-scaled auxiliary outliers sampled from ImageNet21K. Under the various evaluations, our DivOE via informative extrapolation, can obtain the better OOD discriminative capability for the models and consistently achieve the lower averaged FPR95 compared with different baselines. Finally, a range of ablation studies from various aspects of the learning framework and further discussions from different perspectives are provided. Our main contributions are summarized as follows,

* Conceptually, we study a more general and practical research setting in outlier exposure for OOD detection, considering the auxiliary outliers having limited information that can not well represent the whole decision areas for ID and OOD data. (in Section 3.1)
* Technically, we propose a novel learning framework, namely _Diversified Outlier Exposure_ (DivOE), for facilitating fine-tuning with auxiliary outliers, which conducts informative extrapolation to adaptatively diversify outlier exposure. (in Sections 3.2 and 3.3)

Figure 1: Illustration about the research problem on auxiliary outliers studied in our work for OE. Left panel: the general assumption on the auxiliary outliers, in which the surrogate OOD distribution \(_{}^{s}\) can not always be broad enough to well represent the unseen OOD distribution \(_{}\) since it is impractical or even infeasible to accurately pre-define and collect those boundary outliers (especially those close to \(_{}\)); Right panel: an empirical verification on OOD detection performance (evaluated by FPR95, the lower is the better) with the gradually decreased number of given auxiliary outliers. Our proposed DivOE can perform better via extrapolation than previous sampling-based methods, given different numbers of auxiliary outliers. More experimental details are provided in Appendix C.

* Empirically, extensive explorations from different perspectives are conducted to verify the effectiveness of DivOE in improving OOD detection performance, and we perform various ablations or further discussions to provide a thorough understanding. (in Section 4)

## 2 Background

In this section, we briefly introduce the preliminaries and related work in OOD detection.

### Preliminaries

We consider multi-class classification as the original training task (Nguyen et al., 2015), where \(^{d}\) denotes the input space and \(=\{1,,C\}\) denotes the label space. A reliable classifier should be able to figure out the OOD input, which can be considered a binary classification problem. Given \(\), the distribution over \(\), we consider \(_{}\) as the marginal distribution of \(\) for \(\), namely, the distribution of ID data. At test time, the environment can present a distribution \(_{}\) over \(\) of OOD data. In general, the OOD distribution \(_{}\) is defined as an irrelevant distribution of which the label set has no intersection with \(\) and thus should not be predicted by the model \(f()\). A decision model \(g()\) can be made with the threshold \(\):

\[g_{}(x;f)=&S(x;f)\\ &S(x;f)<\] (1)

Building upon the model \(f:^{c}\) trained on ID data with the logit outputs, the goal of decision is to utilize the scoring function \(S:\) to distinguish the inputs of \(_{}\) from that of \(_{}\) by \(S(x;f)\). If the score value is larger than the threshold \(\), the associated input \(x\) is classified as ID and vice versa. We consider several representative scoring functions designed for OOD detection in our exploration, e.g., MSP (Hendrycks and Gimpel, 2017), ODIN (Liang et al., 2018), and Energy (Liu et al., 2020). More detailed definitions are provided in Appendix A.

To mitigate the issue of over-confident predictions for (Hendrycks and Gimpel, 2017; Liu et al., 2020) some OOD data, another line of research directions (Hendrycks et al., 2019; Tack et al., 2020) utilize the auxiliary unlabeled dataset to regularize the model behavior. Among them, one representative baseline is outlier exposure (OE) (Hendrycks et al., 2019). OE can further improve the detection performance by making the model \(f()\) finetuned from a surrogate OOD distribution \(_{}^{s}\), and its corresponding learning objective is defined as follows,

\[_{}=_{_{}}[_{ {CE}}(f(x),y)]+_{_{}^{s}}[ _{}(f(x))],\] (2)

where \(\) is the balancing parameter, \(_{}()\) is the Cross-Entropy (CE) loss, and \(_{}()\) is the Kullback-Leibler divergence to the uniform distribution, which can be written as \(_{}(h())=-_{k}_{k}\ f(x)/C\), where \(_{k}()\) denotes the \(k\)-th element of a softmax output. The OE loss \(_{}()\) is designed for model regularization, encouraging the model to learn knowledge from the surrogate OOD inputs and return low-confident predictions (Hendrycks and Gimpel, 2017).

### Related Work

**OOD Detection.**(Hendrycks and Gimpel, 2017) formally benchmarks the OOD detection problem, proposing to use softmax prediction probability as a conventional baseline method. Subsequent works (Sun et al., 2021) keep focusing on designing post-hoc metrics to distinguish ID samples from OOD samples, among which ODIN (Liang et al., 2018) introduces small perturbations into input images to facilitate the separation of softmax score, Mahalanobis distance-based confidence score (Lee et al., 2018) exploits the feature space by obtaining conditional Gaussian distributions, energy-based score (Liu et al., 2020) aligns better with the probability density. Except directly designing new score functions, some works (Lin et al., 2021; Sun et al., 2022; Djurisic et al., 2023) pay attention to various aspects to enhance the OOD detection such that LogitNorm (Wei et al., 2022) produces confidence scores by training with a constant vector norm on the logits, DICE (Sun and Li, 2022) reduces the variance of the output distribution by leveraging the model sparsification, and ASH (Djurisic et al., 2023) explores the manipulation of feature representation to enhance OOD detection. In addition, Zhu et al. (2023) improves detection performance by investigating the quality of ID data.

**OOD Detection with Auxiliary Outliers.** Another promising direction toward OOD detection involves the auxiliary outliers for model regularization. From the data perspective, some works explore generating virtual outliers such that VOS (Du et al., 2022) and NPOS (Tao et al., 2023) regularize the decision boundary by adaptively sampling virtual outliers from the low-likelihood region. On the other hand, other works exploit information from natural outliers, such that outlier exposure is introduced by (Hendrycks et al., 2019), given that real OOD data are available in enormous quantities. Recently, some works highlight the importance of sampling strategy, such that NTOM (Chen et al., 2021) greedily utilizes informative auxiliary data to tighten the decision boundary for OOD detection, and POEM (Ming et al., 2022) adopts Thompson sampling to contour the decision boundary precisely. The performance of training with outliers is usually superior to that without outliers, as shown in many other works (Fort et al., 2021; Salehi et al., 2021; Sun et al., 2023). From the optimization perspective, Wang et al. (2023) introduces implicit regularization via model perturbation, and Wang et al. (2022); Yang et al. (2023) present early trials to improve OOD performance in terms of the AUROC with tighter generalization bounds and new evaluation metrics.

## 3 Method: Diversified Outlier Exposure

In this section, we introduce our new framework, i.e., _ Diversified Outlier Exposure_ (DivOE), which conducts informative extrapolation during fine-tuning with auxiliary outliers. First, we present and discuss the critical motivation that inspires our method (Section 3.1). Second, we introduce its newly derived learning objective and explain the underlying implications (Section 3.2). Lastly, we present the algorithmic realization of DivOE and discuss its compatibility with other methods (Section 3.3).

### Motivation

First, collecting OOD samples near the boundary still remains challenging as we can hardly know which kind of samples are truly located in the decision boundary between ID and OOD space. Second, as empirically shown in the left-middle panel of Figure 2, if the auxiliary outliers are not sufficiently informative (e.g., less diversified), the performance of outlier exposure will be limited due to the under-represented OOD distributions, which can be reflected by the higher FPR95 score (indicating a higher error on OOD detection). Thus, it naturally arises the following research question,

_How could we utilize the given outliers for effective OOD detection if the auxiliary outliers are not informative enough to represent the unseen OOD distribution?_

Especially for those OOD inputs that are close to the decision boundary, the auxiliary outliers may not well characterize such a broad distributional area (Fang et al., 2022; Wang et al., 2023; Zhang et al., 2023). Therefore, a new mechanism is required to diversify the outlier exposure by exploring more potential OOD distribution for effective OOD detection. As in the right two panels of Figure 2, DivOE realizes this expectation by explicitly extrapolating the OOD data engaged during training.

### DivOE via Informative Extrapolation

As aforementioned, the OE paradigm heavily relies on the auxiliary outliers sampled from the surrogate OOD distribution. Given the auxiliary outliers that are not informative enough to represent the

Figure 2: Empirical demonstration about informative outliers in OE and the diversification effect of the proposed DivOE. In the two left panels, we illustrate auxiliary outliers in different informative levels and divide them into five groups according to the degree of diversity. Empirically, we show that the OOD detection performance of OE can be benefited by the most diversified Group1 among these trials. We leave the experimental details in Appendix C for reference. In the two right panels, we compare the TSNE visualization of the original outliers with our extrapolated outliers in DivOE.

unseen OOD data, the model is expected to learn beyond the current surrogate OOD distribution. One conceptual idea to achieve this goal is to extrapolate based on the current surrogate distribution. Under such a concurrent learning paradigm, the model can be regularized by the original surrogate OOD distribution and simultaneously generalize beyond the given auxiliary outliers for OOD detection. To this intuition, we consider an adaptively evolved version of the surrogate OOD distribution \(^{s}_{}\) under the learning framework of OE as follows,

\[^{*}_{}=_{_{}} [_{}(f(x),y)]+_{^{s}_{ }}[_{}(f())],\] (3)

where \(^{e}_{}\) indicates the extrapolated surrogate distribution during training and \(\) indicates the newly manipulated samples that are different from those in the original objective (i.e., Eq. (2)) of OE. In the above learning objective, the left part is for the original classification task, and the right part is for the newly proposed informative extrapolation in our DivOE. With the conceptual target for diversifying the current surrogate OOD distribution, we consider reformulating the specific objective as,

\[_{^{s}_{}}[_{}(f ())]=(1-)_{}(f;^{s}_{}) +[_{}(f;^{s+ }_{})-_{}(f;^{s}_{})]}_{ },\] (4)

where \(\) indicates a balancing factor for controlling the extrapolation ratio and \(^{s+}_{}\) represents the synthesized distribution with a manipulation \(\). Intuitively, the overall objective defined in Eq. (4) not only learns from the original surrogate OOD distribution but also generalizes to the different OOD distributions via the maximization part. The underlying insight is to expand the surrogate OOD distribution towards a more diversified one. The informative extrapolation is realized by the maximization part that maximizes the differences between the original surrogate OOD distribution and the generated one. Note that, Eq. (4) corresponds to an expectation formulation based on the whole population for diversifying outlier exposure, which is prohibitively expensive in realization. To achieve that more efficiently, we introduce an instance-level version for practical realization, and its optimization target can be formulated as the following hybrid loss,

\[_{}(f())=_{ }(f(x))}_{}+ _{}_{}(f(x+))}_{},\] (5)

where \(n\) indicates the sample number of auxiliary outliers and \(r\) indicates the extrapolation ratio that corresponds to \(\) in Eq. (4). Except for the original loss on learning with the given outliers, the latter part of Eq. (5) defines a surrogate optimization part for realizing the informative extrapolation.

Here we adopt instance-level maximization for manipulating the expected OOD samples based on the original one, in which the specific \(\) is obtained by the following optimization objective,

\[=_{}_{}(f(x+)),\] (6)

Intuitively, DivOE will generate new outliers closer to the decision boundary to expand the coverage area of auxiliary outliers, and simultaneously be more informative to shape the decision area between ID and OOD data. The specific optimization process of \(\) is characterized as,

\[+(_{}_{}(x+ )),(_{}_{}(x+)) (_{}_{}^{S(;f)}(x+)),\] (7)

where sign is the function that extracts the sign of the tensor elements and \(S(;f)\) indicates the general OOD score functions. The optimization process also indicates that our extrapolation framework is general and can adopt different score functions to generate targeted outliers. Here we also provide the theoretical implication of our proposed objective based on previous work .

**Theorem 3.1**.: _Given a simple Gaussian mixture model in binary classification with the hypothesis class \(=(^{T}x),^{d}\). There exists constant \(\), and \(()\) that satisfy,_

\[^{*}_{n_{1},n_{2}}}{||^{*}_{n_{1},n_{2}}||} -^{}||||^{}-( -())}{2}}{2}{n}}(d+)+|| ||^{2}}.\] (8)

From the perspective of sample complexity, we present the effects of our informative extrapolation. As \((^{*}_{n_{1},n_{2}})=erf(^{*}_{n_{1},n_{2}}} {||^{*}_{n_{1},n_{2}}||})\) is monotonically decreasing, the lower bound of \(^{*}_{n_{1},n_{2}}}{||^{*}_{n_{1},n_{2}}||}\) will increase with the constraint of \((-())\) (which corresponds to our DivOE that extrapolates the outlier boundary towards ID data) decrease in our methods, the upper bound of \((^{*}_{n_{1},n_{2}})\) will decrease. The above indicates the benefit of DivOE with the informative extrapolation on shaping boundary decision areas. The completed definition and the analysis can be referred to in Appendix B.

### Realization of DivOE

In this part, we introduce the realization of the whole learning framework of DivOE in detail. Here we formally present the learning objective of DivOE via informative extrapolation as follows,

\[_{}=_{m}_{}(f(x),y)+ (_{n-rn}_{}(f(x))+_{rn}_{ }(f(x+))),\] (9)

where \(m\) and \(n\) indicate the sample numbers of ID data and auxiliary outliers respectively, other notations keep the same meaning as the previous equations. Concretely, the maximization part of DivOE adopts the multi-step optimization (e.g., projected gradient decent (Bottou, 2012; Madry et al., 2018)) to realize the targeted outlier synthetics. The specific process is defined as,

\[(x)^{(t+1)}=_{[x^{(0)};]}x^{(t)}+ (_{x^{(t)}}_{}(f(x^{(t)}))),\] (10)

where \(t\), \(x^{(t)}\) is the extrapolated OOD data at step \(t\), and \(_{[x^{(0)};]}()\) is the projection function that projects the new OOD data back into the \(\)-ball centered at \(x^{(0)}\) if necessary. Different from the conceptual idea of constraining the perturbation (for human-imperceptibility) in the literature on adversarial robustness (Madry et al., 2018; Zhang et al., 2019), the projection operation in DivOE provides a quantification way to study the extrapolated distribution and its diversification. As the generation process starts from the given outliers, the semantical class (belongs to ID or OOD) is hard to change, as empirically shown in the left-most panel of Figure 3 (we adopted a very large \(=0.15\)). More exploration about this perspective will leave to Section 4.3 for further discussion.

Here we summarize the whole procedure of the proposed DivOE in Algorithm 1, which consists of multi-round training iterations. To be specific, on each round of fine-tuning, DivOE first samples a mini-batch with a specific ratio \(r\) from the auxiliary outliers and conduct multi-step optimization following Eq. (10) to generate the new outliers. With the ID training data, the original outliers, and the extrapolated outliers, DivOE then fine-tune the model with the loss defined in Eq. (9).

In practical realization, for the specific extrapolation strength \(\), DivOE can also generate the extrapolation pool with multiple \(\) candidates within the extrapolated sub-batch. The specific definition of extrapolation pool is as follows,

\[()=\{x^{sk_{1}}_{_{1}},,x^{sk_{p}}_{ _{1},,_{p}},\] (11)

where the extrapolation strength with its corresponding sample number can be flexibly decided in the extrapolated sub-batch with a total sample number equal to \(r*n\), which may better facilitate the diversification target. As a primary exploration, we visualize the extrapolated data with its distribution quantified by Energy score (Liu et al., 2020) in the left two panels in Figure 3. Intuitively, even with a large extrapolation strength with human-perceptible pixel noise added in the original outliers, it will not change its classification results in OOD detection. It can represent a more different OOD distribution compared with the given outliers as the distribution shifted gradually to the right.

Figure 3: Empirical exploration of informative extrapolation. Left panel: visualization of extrapolated outliers w.r.t different diversified strength \([0,0.15]\); Left-middle panel: the corresponding density of the energy score distributions on the different extrapolated outliers; Right-middle panel: comparison of ID/OOD distributions based on Energy score of the OE baseline; Right panel: comparison of ID/OOD distributions based on Energy score using the model fine-tuned by the proposed DivOE.

**Input:** given model: \(\), fine-tuning epochs : \(T\), training samples of ID data: \(x^{*}_{}\), training samples of auxiliary outliers: \(x^{*}^{*}_{}\), extrapolated ratio of the original outliers: \(r\), extrapolate epsilon: \(\), optimization step number: \(k\), extrapolation pool: \(()\);

**Output:** fine-tuned model \(^{T}\);

```
1:for epoch \(=1\),..., \(T\)do
2:for mini-batch \(=1\),..., \(M\)do
3: Sample a mini-batch \(\{(x_{i},y_{i})\}_{i=1}^{m}\) from \(_{}\), sample a mini-batch \(\{(x^{*}_{j})\}_{j=1}^{n}\) from \(^{*}_{}\)
4: Sample a sub-batch with ratio \(r\) from the batch of outliers \(\{(x^{*}_{j})\}_{j=1}^{n}\)
5:for\(k=1\),..., \(r*n\) (in parallel)do
6: Obtain the extrapolated outliers \(^{*}_{k}\) by Eq. (10) that following \(_{}(f(^{*}_{k}))\)
7: Aggregate all the extrapolated samples with uniform or different \(\) in \(()\)
8:endfor
9:\(-_{}_{}(f(x),y)+(_{}(f(x^{*}))+ _{}(f(^{*})))}\)
10:endfor
11:endfor ```

**Algorithm 1** Diversified Outlier Exposure (DivOE) via Informative Extrapolation

Comparison and Compatibility.Compared with the conventional OE algorithm (Hendrycks et al., 2019), the critical difference behind DivOE is trying to extrapolate based on the given auxiliary outliers for diversifying outlier exposure. To be specific, it provides a general framework (under the guidance of the learning objective in Eq. (5)) for modeling the informative unknown inputs beyond the original ones. The discriminative feature regularized by our DivOE can be utilized by those advanced post-hoc scoring functions (Sun et al., 2021; Huang et al., 2021; Sun and Li, 2022; Djurisic et al., 2023). For OE-based methods, the informative extrapolation introduced in DivOE is orthogonal to current tuning objectives (Hendrycks and Gimpel, 2017; Wang et al., 2023) and also compatible to those different data augmentation (Zhang et al., 2018; Yun et al., 2019), synthesizing (Kong and Ramanan, 2021; Lee et al., 2018), and also sampling strategies (Chen et al., 2021; Ming et al., 2022) adopted based on either ID data (Du et al., 2022; Tao et al., 2023) or auxiliary outliers.

## 4 Experiments

In this section, we present the comprehensive verification of the proposed DivOE in the OOD detection scenario. First, we provide the experimental setups in detail (in Section 4.1). Second, we provide the performance comparison of our DivOE with a series of post-hoc scoring functions and the OE-based methods with different strategies on the auxiliary outliers (in Section 4.2). Third, we conduct various ablation studies and further discussions to understand our DivOE (in Section 4.3).

### Setups

Here we present several critical parts of experimental setups and leave more details in Appendix C.

Datasets.Following the common benchmarks used in previous work (Liu et al., 2020; Ming et al., 2022), we adopt CIFAR-10, CIFAR-100 (Krizhevsky, 2009) as our ID datasets. We use a series of different image datasets as the OOD datasets, namely Textures(Cimpoi et al., 2014), Places365(Zhou et al., 2017), iSUN(Xu et al., 2015), LSUN_Crop(Yu et al., 2015), and LSUN_Resize(Yu et al., 2015). For the surrogate OOD data used in OE-based methods (Hendrycks et al., 2019; Chen et al., 2021; Ming et al., 2022; Zhang et al., 2023), we adopt Tiny-ImageNet (Le and Yang, 2015). We also conduct the experiments on the ImageNet, where we utilize the large-scaled ImageNet21K (Ridnik et al., 2021) as the surrogate OOD set like previous works (Wang et al., 2023) for OE-based methods.

Evaluation metrics.We employ the following three common metrics to evaluate the performance of OOD detection: (i) Area Under the Receiver Operating Characteristic curve (AUROC) (Davis and Goadrich, 2006) can be interpreted as the probability for a positive sample to have a higher discriminating score than a negative sample (Fawcett, 2006); (ii) Area Under the Precision-Recall curve (AUPR) (Manning and Schutze, 1999) is an ideal metric to adjust the extreme difference

[MISSING_PAGE_FAIL:8]

[MISSING_PAGE_FAIL:9]

different \(\) (with a consistent extrapolation ratio, \(r=0.5\)), which is used to constrain the diversified strength in maximizing the optimization target in Eq. (6). In Figure 4(b), we can observe that an appropriate diversified strength can help OE performs better on OOD detection, while using a large \(\) may empirically return to the original baseline case. One possible reason may be that the extrapolated outliers with a large \(\) may fail to become more informative as previously reflected in Figure 3.

Generality of using different OOD scores.Since DivOE introduces a general learning framework of outlier exposure for model finetuning with auxiliary outliers, the specific realization for informative extrapolation can have multiple choices. For example, different scoring functions can all perform OOD uncertainty estimation, indicating the multiple candidate target for Eq. (6) to optimize. Here we report the performance using different optimization targets (e.g., MSP or Energy score) in Figure 4(c), where they have different performance improvements compared with the original OE baseline.

Comparison with different augmentation-based methods for OE.In Figure 4(d), we perform the comparison of our DivOE with the original OE adopting some representative augmentation methods (e.g., Mixup (Zhang et al., 2018) and CutMix (Yun et al., 2019)) for diversifying the given outliers. The results verify the superiority of DivOE on OOD detection over the direct adaptation of those strategies since they lack a critical diversification guidance. On the other hand, our framework has no strict constraints for the detailed manipulating operations. In other words, DivOE can also utilize those augmentation methods for extrapolation, for which we leave more discussion in Appendix C.

## 5 Conclusion

In this paper, we propose a novel learning framework, i.e., _Diversified Outlier Exposure_ (DivOE), that promotes diversity in outlier exposure with the given auxiliary outliers. To empower the model with more knowledge about the decision boundary between ID and OOD data, DivOE conducts informative extrapolation guided by a newly designed objective. Through the diversification target, our method adaptively synthesizes meaningful outliers during the training process, which helps the model better shape the decision areas for OOD detection. We have conducted extensive experiments to demonstrate the effectiveness of our proposed DivOE and its compatibility with a range of OE-based methods, and also various ablation studies with further explorations to characterize the framework.

#### Acknowledgments

JNZ and BH were supported by the NSFC Young Scientists Fund No. 62006202, NSFC General Program No. 62376235, Guangdong Basic and Applied Basic Research Foundation No. 2022A1515011652, RIKEN Collaborative Research Fund, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04, and HKBU CSD Departmental Incentive Scheme. GY and JCY were supported by the National Key R&D Program of China (No. 2022ZD0160703), 111 plan (No. BP0719010) and National Natural Science Foundation of China (No. 62306178). TLL was partially supported by the following Australian Research Council projects: FT220100318, DP220102121, LP220100527, LP220200949, and IC190100031.

Figure 4: Ablation Study. (a) performance of using different extrapolated ratios of DivOE; (b) exploration of different diversified strength \(\); (c) using different OOD scores as informative extrapolation targets; (d) comparison between DivOE and OE adopting other augmentations for diversification.