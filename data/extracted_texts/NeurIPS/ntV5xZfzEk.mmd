# Constrained Binary Decision Making

Daniel Prusa  Vojtech Franc

Department of Cybernetics

Faculty of Electrical Engineering

Czech Technical University in Prague

{prusapal,xfrancv}@fel.cvut.cz

###### Abstract

Binary statistical decision making involves choosing between two states based on statistical evidence. The optimal decision strategy is typically formulated through a constrained optimization problem, where both the objective and constraints are expressed as integrals involving two Lebesgue measurable functions, one of which represents the strategy being optimized. In this work, we present a comprehensive formulation of the binary decision making problem and provide a detailed characterization of the optimal solution. Our framework encompasses a wide range of well-known and recently proposed decision making problems as specific cases. We demonstrate how our generic approach can be used to derive the optimal decision strategies for these diverse instances. Our results offer a robust mathematical tool that simplifies the process of solving both existing and novel formulations of binary decision making problems which are in the core of many Machine Learning algorithms.

## 1 Introduction

Binary statistical decision making (BDM) involves selecting between two possible states using statistical evidence. This approach is applied across various fields, from classical statistics to machine learning. A notable example is the Neyman-Pearson problem , which establishes the optimal strategy for testing two hypotheses and serves as the foundation for optimal detectors. Beyond classical statistics, BDM problems are used in many machine learning applications, such as detecting out-of-distribution (OOD) samples , designing selective classifiers , and developing selective classification in the presence of OOD data (SCOD)  to name a few.

Instances of BDM determine the best decision-making strategy by solving a constrained optimization problem involving Lebesgue measurable functions in both the objective and constraints. Understanding the structure of this optimal strategy is crucial before deploying efficient methods to find it. The Neyman-Pearson lemma, a well-known example found in many statistics textbooks, states that an optimal detection strategy relies on comparing the likelihood ratio of the underlying distributions with a threshold. Therefore, learning a detector from examples involves effectively approximating the likelihood ratio and then tuning the decision threshold.

However, defining the optimal strategy for various BDM problems is generally challenging, often taking several years to discover. For instance, the Bounded-Improvement and Bounded-Abstention models, serving as formal definitions of optimal selective classifiers, were first introduced in . The optimal strategies for these two BDM problems were initially described in , marking a 14-year period of development. Another recent example is the work of , who developed a method for learning a selective classifier handling inputs contaminated by out-of-distribution data, so called SCOD problem. Although they formulated an optimal SCOD selection strategy to accept input samples as a solution to a novel BDM problem, they did not analyze the optimal strategy directly.

Instead, they proposed a selector strategy named SIRC, combining two detectors using heuristically chosen non-linear functions. In a recently published paper , the authors derived an optimal solution for the SCOD problem, demonstrating that the optimal selective strategy involves a simple linear combination of the two detectors. Empirical evidence confirmed that the optimal linear strategy consistently outperforms the heuristic SIRC, despite its minor change. This example underscores the advantages of understanding the structure of the optimal solution to underlying BDM problems.

In this paper, we present a comprehensive formulation of the BDM problem and thoroughly characterize the optimal strategy. Our framework encompasses various BDM problems as special cases, enabling us to derive optimal decision strategies for these instances. This provides a robust mathematical tool for solving both existing and new BDM problems. The related theorem is highly general, applying to both discrete and continuous instance spaces without requiring the differentiability of decision and loss functions, unlike common proof techniques based on Lagrange duality.

To illustrate the impact of our work, in Section 2, we formulate several practical modifications of existing BDM problems. In Section 4, we demonstrate the derivation of their optimal strategies using our main result, which characterizes the optimal strategies of a generic BDM as presented in Section 3.

## 2 Examples of existing binary decision making problems

In this section, we present various examples of BDM problems, with a focus on the significant application of designing a selective classifier in the presence of out-of-distribution (SCOD) samples [24; 16]. We note that while selective classification itself is not the contribution of this paper, it serves to illustrate the practical importance and diversity of BDM formulations in addressing a recently emerging problem in the machine learning community.

Consider a given classifier \(h\), where \(\) is the instance space and \(\) a finite set of labels. We assume the classifier \(h\) was designed to minimize the prediction loss \(\). Our task is to equip the classifier \(h\) with a binary stochastic decision strategy \(c\). The strategy \(c\) acts as a selector for input samples. The input sample \(x\) is accepted for prediction by \(h\) with probability \(c(x)\) and is rejected otherwise. Thus, the pair \((h,c)\{\}\) forms a reject option classifier :

\[(h,c)(x)=\{h(x)&&c(x)\,,\\ &&1-c(x)\,..\]

We assume the following statistical model of the data. Input samples are generated from a mixture of two distributions: the in-distribution (ID) \(p_{I}_{+}\) and the out-of-distribution (OOD) \(p_{O}_{+}\). Thus, the input sample \(x\) is generated from

\[p(x)=p_{I}(x)\,(1-)+p_{O}(x)\,\,\] (1)

where \(\) represents the portion of OOD samples in the mixture. Furthermore, if the sample \(x\) is generated from the in-distribution, a latent label \(y\) is generated according to the distribution \(p(y x)\).

In the outlined statistical model, prediction uncertainty arises from two main sources: i) inherent data uncertainty (aleatoric uncertainty), stemming from the stochastic relationship between the input \(x\) and the latent label \(y\), and ii) distribution uncertainty, which arises from input samples potentially coming from either in-distribution or out-of-distribution sources. We will explore six different BDM instances to develop a selector \(c\) that admits an input sample \(x\) for classification with \(h\) only when the prediction uncertainty is below an acceptable threshold. Each instance defines an optimal selector in a unique way. In Section 2.1, we described the Neyman-Pearson formulation of the OOD optimal detector , which addresses only distribution uncertainty. Sections 2.2 and 2.3 cover the Bounded-Improvement and Bounded-Abstention models , addressing only data uncertainty. In Section 2.4, we describe the SCOD problem , which defines the optimal selector addressing both distribution and data uncertainty. Additionally, Sections 2.5 and 2.6 give examples of two novel practical variants of the SCOD problem.

The primary contribution of this paper is a framework for solving a broad range of BDM problems. In Section 3, we detail the main theorem that characterizes the optimal solution for a generic BDM problem. In Section 4, we demonstrate how to apply this theorem to find solutions easily for all the BDM instances described here.

### Neyman-Pearson (NP) detector

Assume our goal is to design a selector strategy \(c\) that accepts only in-distribution (ID) samples and rejects out-of-distribution (OOD) samples. In other words, \(c\) functions as a binary classifier to distinguish ID and OOD samples. We will characterize the strategy \(c\) using two metrics. First, using the True Positive Rate (TPR) representing the probability that ID sample \(x\) is correctly accepted by the strategy:

\[(c)=_{}p_{I}(x)\,c(x)\,dx\;.\] (2)

Second, using the False Positive Rate (FPR) representing the probability that OOD sample \(x\) is incorrectly accepted by \(c\):

\[(c)=_{}p_{O}(x)\,c(x)\,dx\;.\] (3)

Given maximal acceptable FPR, \(_{}>0\), the NP task is to find a strategy \(c^{*}\) that solves the following BDM problem :

\[_{c\,X}(c)(c) _{}\;.\] (4)

A well-known solution to the NP task 4 is the strategy:

\[c^{*}(x)=\{1&&g(x)<\,,\\ &&g(x)=\,,\\ 0&&g(x)>\,,.\] (5)

where \(g(x)=(x)}{p_{I}(x)}\) is the likelihood ratio, \(\) is a decision threshold, and \(\) is a probability of acceptance when \(g(x)=\).

Knowing the structure of the optimal strategy simplifies its construction significantly. The key to an optimal decision is accurately modeling the likelihood ratio \(g(x)\). Once the likelihood ratio is known, finding the optimal strategy involves setting the threshold \(\) and the randomization parameter \(\), typically done by tuning these parameters on a validation sample. Moreover, if \(p_{I}(x)\) and \(p_{O}(x)\) are continuous, the randomization parameter \(\) can be arbitrary since the event \(g(x)=\) has zero probability of occurring.

### Selective Classification: Bounded-abstention model

Let us consider the ideal scenario where the input instances \(x\) are solely generated by the in-distribution \(p_{I}(x)\), meaning the out-of-distribution portion in the model (1) is \(=0\). Our aim is devise a selection strategy \(c\,\) that accepts only those input samples \(x\) where the prediction loss \((y,h(x))\) is likely to be small. We will characterize the strategy \(c\) using two metrics. First, we employ the notion of _coverage_:

\[(c)=_{}p_{I}(x)\,c(x)\,dx\] (6)

which reflects the probability of accepting an input sample. Secondly, we introduce the concept of "selective risk":

\[^{}(h,c)=}p_{I}(x,y)\, (y,h(x))\,c(x)\,dx}{(c)}\;.\] (7)

representing the expected prediction loss \(\) on the accepted samples.

Given a minimal acceptable coverage \(>0\), the bounded-abstention model defines the optimal selector strategy as the solution to the following BDM problem :

\[_{h^{*},c^{}}^{}(h,c) (c)\,.\] (8)

The solution to the bounded-abstention model (8) consists of the Bayes predictor

\[h^{*}(x)=*{argmin}_{y^{}}_{y}p_{I}(y x)(y,y^{ })\]and the strategy [8; 9]:

\[c^{*}(x)=\{1&&r(x)<\,,\\ &&r(x)=\,,\\ 0&&r(x)>\,,.\] (9)

where

\[r(x)=_{y}p_{I}(y x)\,(y,h(x))\] (10)

is the conditional risk of the classifier \(h\) for the input \(x\), \(\) is a decision threshold, and \(\) is a probability of acceptance when \(r(x)=0\).

Note that the BDM problem (8) was formulated in , but the optimal solution (9) was not derived until 14 years later in .

The values of \(\) and \(\) depend on \(p_{I}(x,y)\) and \(\), and in practice, they are tuned on validation data once a good model of the conditional risk \(r(x)\) is established. While this process can be challenging and needs be addressed for each problem separately, it is still significantly easier than tuning an unknown function. For example, discretizing the possible values of \(\) and \(\) and conducting an exhaustive search, although not always optimal, has proven effective in practice.

The additivity of the risk \(R^{S}\) allows \(h\) to be optimized independently of \(c\), resulting in the Bayes predictor for all problems discussed in the following sections. Therefore, from this point on, we will focus solely on optimal strategies for \(c\).

### Selective Classification: Bounded-improvement rejection model

A symmetric definition of the optimal selector strategy is provided by the bounded-improvement model. Given a maximum acceptable selective risk \(>0\), the optimal selector is the solution to the following BDM problem:

\[_{h,c}(c)^{}(h,c) \,.\] (11)

The solution to the bounded-improvement model (11) is similar to the strategy (9), differing only in the specific values of the decision threshold \(\) and the randomization parameter \(\).

### Selective Classification in the presence of OOD data (SCOD)

The SCOD problem integrates the objectives of the Neyman-Pearson task and bounded-abstention models. The aim is to design a selector strategy \(c\) that accepts an input sample \(x\) if it is likely to be correctly predicted by \(h\) and unlikely to be generated from the OOD. Formally, the objective is defined using three metrics: True Positive Rate \((c)\), equation (2), False Positive Rate \((c)\), equation (3) and selective risk \(^{}(h,c)\), equation (7). Given the relative cost \(>0\) and the minimum acceptable TPR, \(_{}>0\), the goal is to find a strategy \(c^{*}\) that solves the following BDM problem :

\[_{h^{},c^{}}[(1-) \,^{}(h,c)+\,(c)](c)_{}\,.\] (12)

The solution to the SCOD problem (12) is the strategy [16; 7]:

\[c^{*}(x)=\{1&&s(x)>\,,\\ &&s(x)=\,,\\ 0&&s(x)<. s(x)=r(x)+ _{}}{1-}g(x)\] (13)

for \([0,1)\) and \(s(x)=g(x)\) for \(=1\). Here, \(r(x)\) is the conditional risk (10), \(g(x)=(x)}{p_{I}(x)}\) is the likelihood ratio, \(\) is a decision threshold, and \(\) the acceptance probability for the case \(s(x)=r(x)\).

The BDM problem (12) was formulated in . The optimal solution for continuous distributions was recently derived in , and the solution for the general case was provided in .

### SCOD: bounded TPR-FPR

To demonstrate the versatility of our framework, we will present two novel variants of the SCOD problem in in this section and the next. While the optimal solutions to these new formulations are unknown, they can be easily derived using the framework proposed in this paper, as we will later show.

The original formulation of the SCOD problem (12) relies on the user-defined relative cost \(\). However, this assumes that the prediction loss \(\) and the cost for incorrectly accepting the OOD sample share the same units, which is not always practical. In such cases, it can be useful to remove the FPR from the objective and impose a hard constraint on it instead. Specifically, we can alternatively formulate the SCOD problem as follows. Given \(_{}>0\) and \(_{}>0\), the goal is to find a strategy \(c^{*}\) that solves the following BDM problem:

\[_{h^{X},c^{}}^{ }(h,c)(c)_{ }(c)_{}.\] (14)

In Section 4, we will prove that the optimal solution to the problem (14) is the strategy:

\[c^{*}(x)=\{1&&s(x)<\,,\\ &&s(x)=\,,\\ 0&&s(x)>\,,. s(x)=r(x)+  g(x)\,,\] (15)

with \(\) as the decision threshold, \(\) as the acceptance probability when \(s(x)=\), and \(\) as a constant depending on the problem setup.

### SCOD: bounded Precision-Recall

Assume the portion of OOD samples \(\) is known or can be estimated. In some applications, it is useful to replace FPR with precision, which is the proportion of true ID samples among all accepted inputs. Precision \((c)\) is defined as:

\[(c)=(c)}{(c)\,+(c)\,(1-)}\,.\]

If we want to avoid defining the relative cost, as in (14), we can formulate the SCOD problem as follows. Given \(_{}>0\) and \(_{}>0\), the goal is to find a strategy \(c^{*}\) which solves the following BDM problem:

\[_{h^{},c^{}} ^{}(h,c)(c )_{}(c) _{}\] (16)

In Section 4, we will prove that the optimal solution to the problem (16) is a strategy similar to (15), differing only in the specific values of the decision threshold \(\), the randomization parameter \(\) and the multiplier \(\).

### Summary

In the previous sections, we described six BDM problems, each with a unique optimal selector strategy. The first four are established formulations, while the last two are novel SCOD modifications potentially useful for specific applications. As ML applications grow, new formulations are likely to emerge to address specific setups.

Deriving the optimal strategy for a given BDM problem proved to be the essential first step. Although the statistical model is often unknown in practice, understanding the structure of the optimal strategy is crucial for designing efficient algorithms to learn the selector from examples. This knowledge can narrow the search space or simplify the problem using divide-and-conquer approaches.

For instance, consider constructing a selector strategy for the SCOD problem. Whether using the original cost-based formulation (12) or the two novel variants (14) and (16), takes the form (15), the optimal strategy \(c^{*}\) relies on an uncertainty score \(s(x)=r(x)+ g(x)\). The strategy accepts input \(x\) if \(s(x)\) is below a threshold \(\), and with probability \(\) if \(s(x)=\). This analysis shows that the core problem reduces to approximating the two components: the conditional risk

\[r(x)=_{y}p(y x)(y,h(x))\]and the OOD/ID likelihood ratio \(g(x)=p_{O}(x)/p_{I}(x)\). Extensive literature on OOD detection provides methods to approximate \(g\) (e.g. [11; 14; 6; 5; 15; 10; 2; 21; 20; 22; 23]), and there are methods to construct good proxies for \(r\) (e.g. [13; 12; 4; 8; 9]).

Once \(r\) and \(g\) are known, constructing the selector strategy involves determining the scalars \(\), \(\), and \(\). These parameters can be tuned using held-out data, which is much easier than solving the original problem. Moreover, for continuous distributions, the event \(s(x)=\) has zero probability, making \(\) arbitrary. In the cost-based formulation, the multiplier \(\) has an analytical solution, leaving only \(\) to be determined.

This example shows that deriving an optimal strategy for BDM problems allows us to use existing methods from OOD detection and selective classification to approximate various SCOD problem formulations. Conversely, skipping the optimal strategy derivation and using heuristic rules, such as the SIRC strategy from the original SCOD paper , can lead to sub-optimal performance .

## 3 Main result

In this section, we formulate a generic BDM problem, characterize its optimal solutions, and provide a straightforward instance of the optimal strategy.

For a measurable set \(\) in a measure space, Lebesgue measurable functions \(R,p,q:[0,)\) with finite integrals on \(\), and fixed non-negative real values \(\) and \(\), we define the following optimization problem:

\[_{c:\;}_{}R(x)c(x)dx _{}p(x)c(x)dx_{}q(x)c(x)dx\;.\] (17)

Note that we do not pose any additional requirements on the functions, like continuity or differentiability, neither do we differentiate between discrete and continuous sets \(\); they can be arbitrary.

**Theorem 1**.: _For every optimal solution \(c^{*}:\) to Problem (17), there exist real numbers \(,\) such that_

\[_{^{<}}p(x)c^{*}(x)\,dx =_{^{<}}p(x)\,dx\,,\] (18) \[_{^{>}}p(x)c^{*}(x)\,dx =0\,,\] (19)

_where_

\[^{<} =\{x p(x)>0+ <\}\,,\] (20) \[^{>} =\{x p(x)>0+ >\}\,.\] (21)

Informally, equation (18) states that any optimal \(c^{*}\) attains the value \(1\) on \(^{<}\), except on a subset of measure zero. Similarly, by equation (19), \(c^{*}\) attains the value \(0\) on \(^{>}\), again up to a subset of measure zero. The sets \(^{<}\) and \(^{>}\) contain the points \(x\) for which \(+\) is below and above the threshold \(\), respectively, excluding any insignificant elements where \(p(x)=0\).

Based on these observations, the next lemma suggests a way to construct a single score function that determines an optimal decision strategy.

**Lemma 1**.: _An optimal solution \(c^{*}:\) to Problem (17) can be found among the forms_

\[c^{*}(x)=\{0&s(x)>\,,\\ (x)&s(x)=\,,\\ 1&s(x)<\,,.\]

_where_

\[s(x)=\{+&p(x)>0\,,\\ &.\]_is a score function, \(,\) are suitable real numbers, and \(:\) is a function implicitly defined by the problem parameters._

Proof.: Let \(c:\) be an optimal solution to Problem (17). Consider real numbers \(,\) yielded by Theorem 1 and define

\[c^{*}(x)=\{0&s(x)>\,,\\ c(x)&s(x)=\,,\\ 1&s(x)<\,..\]

To show that \(c^{*}\) is optimal, decompose \(\) into the pairwise disjoint sets \(^{<}\) (see (20)), \(^{>}\) (see (21)), \(^{}=\{x p(x)=0\}\) and \(^{=}=\{x s(x)=\}\). Equalities (18) and (19) ensure that \(c\) and \(c^{*}\) are nearly identical on sets \(^{<}\) and \(^{>}\), respectively, up to subsets of measure zero. By the definition of \(c^{*}\), they are identical on \(^{=}\). Consequently, the criterion and constraints attain the same values for both \(c\) and \(c^{*}\) on \(^{<}^{>}^{=}\). Finally, the first constraint of (17) is independent of \(^{}\), and \(c^{*}(x) c(x)\) for all \(x^{}\) ensures

\[_{^{}}R(x)c^{*}(x)_{^{}}R(x)c(x) \,,_{^{}}q(x)c^{*}(x)_{^{}} q(x)c(x)\,.\]

In conclusion, \(c^{*}\) is an optimal solution. 

Tool to solve the BDM problemsLemma 1 is a key tool for simplifying the BDM problem (17). It shows that the main challenge is approximating the ratios \(\) and \(\). Once these ratios are known, determining the score \(s\) involves finding the multiplier \(\). With the score \(s\), the optimal strategy \(c^{*}\) depends on finding the decision threshold \(\) and the function \((x)\). However, in the cases where \(\) is a continuous space, the boundary set \(\{x s(x)=\}\) typically has measure zero, except in some pathological instances. Consequently, \((x)\) can be chosen arbitrarily and does not play a significant role. Thus, in continuous spaces, one only needs to find the scalars \(\) and \(\), which can be tuned using held-out data, making the process much simpler than solving the original problem from scratch.

The problem feasibilityIn the special case where only one constraint is given, i.e., when either \(p(x)=0\) or \(q(x)=0\), checking feasibility is straightforward. In the general case, to determine the feasibility of Problem (17), we can formulate the task as:

\[_{c:\ }_{}q(x)c(x)dx _{}p(x)c(x)dx\,.\] (22)

We obtain a similar problem but with only one constraint. Problem (17) is feasible if and only if Problem (22) attains a value less than or equal to \(\).

Proof techniqueProblem (17) represents an instance of infinite linear programming, grounded in established theory . Especially, when \(\) is a finite set, it reduces to a standard linear program, allowing the use of Lagrange duality to derive optimality conditions, as characterized in Theorem 1. However, when \(\) is arbitrary and the functions \(R,p,q\) are essentially unrestricted, this approach becomes substantially more complex. In such cases, a more general duality theorem would be required, and even then, deducing the desired results would involve handling significantly more intricate optimality conditions. Given these challenges and drawing inspiration from techniques in related works (e.g.  and other studies on the Neyman-Pearson problem), we instead pursue a direct proof, provided in Appendix A. By introducing forbidden point configurations, this proof shows that each optimal solution is determined by a line separating the images of the sets \(^{<}\) and \(^{>}\) in the plane, mapped by the function \((x)=(,)\).

ExtensionsIt remains an open problem whether our results can be generalized to the extended formulation

\[_{c:\ }_{}R(x)c(x),dx _{}p(x)c(x),dx_{}q_{i}(x)c(x),dx_{i}, i I,\] (23)

where \(I\) is a finite index set, the functions \(q_{i}\) are Lebesgue measurable with finite integrals on \(\), and \(_{i}\) are non-negative bounds. A key question is whether there is a scoring function with \(1+|I|\) parameters (instead of 2) for this case. It is important to note that generalizing the current proof would involve addressing a significantly greater combinatorial complexity in the point configurations.

General tasks

In this section, we introduce several special cases of problem (17), whose forms of solutions directly follow from Theorem 1, as we will show. These cases encompass all the examples in Section 2. Thus, all the mentioned BDM problems can be solved in their general form using the single framework proposed in this paper.

To simplify notation, we represent the Lebesgue measurable functions in (17) as \(p_{i}[0,)\), \(i\{0,1,2\}\). Furthermore, for Lebesgue measurable \(c\), we define the functionals:

\[F_{i}(c)=_{}p_{i}(x)\,c(x)\,dx\,, i\{0,1,2\}\;.\]

The generic BDM problem (17) then requires solving for given non-negative scalars \(\) and \(\):

\[_{c\,}F_{0}(c) F_{1}(c)  F_{2}(c)\;.\] (24)

Note that \(F_{0}\) here does not depend on the classier \(h\), which is consistent with the assumption that \(h\) is the Bayes predictor.

Problem 1:Given \(>0\), the task is to solve:

\[_{c\,}F_{0}(c) F_{1}(c) \;.\] (25)

A special case is the Neyman-Pearson task (4).

We derive this formulation from (24) by setting \(p_{2}(x)=0\) for all \(x\). Lemma 1 implies that if the problem is feasible, it has an optimal solution \(c^{*}\) such that

\[c^{*}(x)=\{0&(x)}{p_{1}(x)}> \;,\\ (x)&(x)}{p_{1}(x)}=\;,\\ 1&(x)}{p_{1}(x)}<\;..\]

Note that here, Lemma 1 does not fully replicate the Neyman-Pearson strategy, in which \(\) is constant.

Problem 2:Given \(>0\), the task is to solve:

\[_{c\,}(c)}{F_{1}(c)}  F_{1}(c)\;.\] (26)

Special cases are the Bounded-Abstention model (8) and the original SCOD problem (12).

This formulation can equivalently be transformed to (25) by showing that there is an optimal solution \(c^{*}\) such that \(F_{1}(c^{*})=\). Indeed, if some optimal \(c:[0,)\) fulfills \(F_{1}(c)>\), then we can define \(c^{*}=(c)}c\), and it holds that \(F_{1}(c^{*})=\) and

\[(c^{*})}{F_{1}(c^{*})}=(c)}F_{0}(c)}{ }=(c)}{F_{1}(c)}\;.\]

Hence, such a \(c^{*}\) is preserved in the set of optimal solutions of the problem

\[_{c\,}(c)}{}  F_{1}(c)\;.\]

Problem 3:Given \(>0\), the task is to solve:

\[_{c\,}F_{1}(c) (c)}{F_{1}(c)}\;.\] (27)

A special case is the Bounded-Improvement model (11).

Let \(c^{*}\) be an optimal solution to (27). Define a problem:

\[_{c:\ }(c)}{F_{1}(c)} F _{1}(c) F_{1}(c^{*})\,.\]

Clearly, \(c^{*}\) is feasible for the new problem, which is of the form (26). Moreover, any optimal solution \(c\) to this problem is also optimal to (27) because it attains the maximum \(F_{1}(c^{*})\) and satisfies the constraint:

\[(c)}{F_{1}(c)}(c^{*})}{F_{1}(c^{*})}\,.\]

Problem 4:Given \(>0\), \(>0\), the task is to solve:

\[_{c:\ }(c)}{F_{1}(c)}  F_{1}(c) F_{2}(c)\,.\] (28)

A special case is the SCOD problem formulation with constraints on FPR and TPR (14).

In this case, we can transform the problem to (24) in the same way as we did it for the formulation (26).

Problem 5:Given \(>0\), \(>0\), the task is to solve:

\[_{c:\ }(c)}{F_{1}(c)}  F_{1}(c)(c)}{F_{1}(c)} \,.\] (29)

A special case is the SCOD problem formulation with the constraints on TPR and Precision (16) because the second constraint in (16) can be rewritten as

\[(c)}{(c)}(^{-1}-1)(_{}^ {-1}-1)\,,\]

which matches the form

\[(c)}{F_{1}(c)}\,.\]

Again, the problem transforms to (24) using the same approach as in the case of the formulation (26).

## 5 Conclusion

In this paper, we presented a comprehensive framework for solving binary decision-making (BDM) problems, which define optimal decision strategies through constrained optimization involving Lebesgue measurable functions. We characterize all optimal strategies for a generic BDM problem and derive a specific class of optimal strategies based on comparing a single score with a decision threshold. Our framework covers a variety of BDM problems, from well-known instances like the Neyman-Pearson problem to recent developments such as the SCOD problem. We demonstrated the versatility and robustness of our framework by deriving optimal solutions for all the BDM problems discussed in our paper. This work provides a foundational approach that can be adapted to future needs in machine learning and statistical decision making, ensuring more effective and theoretically grounded solutions.

## 6 Acknowledgement

This research was supported by the CTU institutional support (future fund).