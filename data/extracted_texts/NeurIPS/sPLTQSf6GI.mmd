# A Measure-Theoretic Axiomatisation of Causality

Junhyung Park

Empirical Inference Department

MPI for Intelligent Systems

72076 Tubingen, Germany

junhyung.park@tuebingen.mpg.de&Simon Buchholz

Empirical Inference Department

MPI for Intelligent Systems

72076 Tubingen, Germany

simon.buchholz@tuebingen.mpg.de&Bernhard Scholkopf

Empirical Inference Department

MPI for Intelligent Systems

72076 Tubingen, Germany

bs@tuebingen.mpg.de&Krikamol Muandet

CISPA

Helmholtz Center for Information Security

66123 Saarbrucken, Germany

muandet@cispa.de

###### Abstract

Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of _what happens when one intervenes on a system,_ and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a _causal space_, consisting of a probability space along with a collection of transition probability kernels, called _causal kernels_, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes.

## 1 Introduction

Causal reasoning has been recognised as a hallmark of human and machine intelligence, and in the recent years, the machine learning community has taken up a rapidly growing interest in the subject , in particular in representation learning  and natural language processing . Causality has also been extensively studied in a wide range of other research domains, including, but not limited to, philosophy , psychology , statistics  including social, biological and medical sciences , mechanics and law .

The field of causality was born from the observation that probability theory and statistics (Figure 0(a)) cannot encode the notion of causality, and so we need additional mathematical tools to support the enhanced view of the world involving causality (Figure 0(b)). Our goal in this paper is to give an axiomatic framework of the forwards direction of Figure 0(b), which currently consists of many competing models (see Related Works). As a starting point, we observe that the forwards direction of Figure 0(a), i.e. _probability theory_, has a set of axioms based on measure theory (Axioms 2.1) that are widely accepted and used1, and hence argue that it is natural to take the primitive objects of this framework as the basic building blocks. Despite the fact that all of the existing mathematical frameworks of causality recognise the crucial role that probability plays / should play in any causaltheory, it is surprising that few of them try to build directly upon the axioms of probability theory, and those that do fall short in different ways (see Related Works).

On the other hand, we place _manipulations_ at the heart of our approach to causality; in other words, we make changes to some parts of a system, and we are interested in what happens to the rest of this system. This manipulative philosophy towards causality is shared by many philosophers , and is the essence behind almost all causal frameworks proposed and adopted in the statistics/machine learning community that we are aware of.

To this end, we propose the notion of _causal spaces_ (Definition 2.2), constructed by adding causal objects, called _causal kernels_, directly to probability spaces. We show that causal spaces strictly generalise (the interventional aspects of) existing frameworks, i.e. given any configuration of, for example, a structural causal model or potential outcomes framework, we can construct a causal space that can carry the same (interventional) information. Further, we show that causal spaces can seamlessly support situations where existing frameworks struggle, for example those with hidden confounders, cyclic causal relationships or continuous-time stochastic processes.

Related WorksWe stress that our paper should _not_ be understood as a criticism of the existing frameworks, or that somehow our goal is to replace them. On the contrary, we foresee that they will continue to thrive in whatever domains they have been used in, and will continue to find novel application areas.

Most prominently, there are the _structural causal models_ (SCMs) , based most often on directed acyclic graphs (DAGs). Here, the theory of causality is built around variables and structural equations, and probability only enters the picture through a distribution on the exogeneous variables . Efforts have been made to axiomatise causality based on this framework , but models based on structural equations or graphs inevitably rely on assumptions even for the definitions themselves, such as being confined to a finite number of variables, the issue of solvability in the case of non-recursive (or cyclic) cases, that all common causes (whether latent or observed) are modeled, or that the variables in the model do not causally affect anything outside the model. Hence, these cannot be said to be an "axiomatic definition" in the strictest sense. In a series of examples in Section 4, we highlight cases for which causal spaces have a natural representation but SCMs do not, including common causes, cycles and continuous-time stochastic processes.

The _potential outcomes framework_ is a competing model, most often used in economics, social sciences or medicine research, in which we have a designated _treatment_ variable, whose causal effect we are interested in, and for each value of the treatment variable, we have a separate, _potential outcome_ variable . There are other, perhaps lesser-known approaches to model causality, such as that based on decision theory , on category theory , on an agent explicitly performing actions that transform the state space , or settable systems .

Perhaps the works that are the most relevant to this paper are those that have already recognised the need for an axiomatisation of causality based on measure-theoretic probability theory. Ortega  uses a particular form of a _tree_ to define a causal space, and in so doing, uses an alternative, Bayesian set-up of probability theory . It has an obvious drawback that it only considers _countable_ sets of "realisations", clearly ruling out many interesting and commonly-occurring cases, and also does not seem to accommodate cycles. Heymann et al.  define the _information dependency model_ based on measurable spaces to encode causal information. We find this to be a highly interesting and relevant approach, but the issue of cycles and solvability arises, and again, only countable sets of outcomes are considered, with the authors admitting that the results are likely not to hold with uncountable sets. Moreover, probabilities and interventions require additional work to be taken care of. Lastly, Cabreros and Storey  attempt to provide a measure-theoretic grounding to the potential

Figure 1: Data generating processes and data.

outcomes framework, but thereby confine attention to the setting of a finite number of variables, and even restrict the random variables to be discrete.

Finally, we mention the distinction between _type_ causality and _actual_ causality. The former is a theory about general causality, involving statements such as "in general, smoking makes lung cancer more likely". Type causality is what we will be concerned with in this paper. Actual causality, on the other hand, is interested in whether a _particular_ event was caused by a _particular_ action, dealing with statements such as "Bob got lung cancer because he smoked for 30 years". It is an extremely interesting area of research that has far-reaching implications for concepts such as responsibility, blame, law, harm , model explanation  and algorithmic recourse . Many definitions of actual causality have been proposed , but the question of how to define actual causality is still not settled . The current definitions of actual causality are all grounded on (variants) of SCMs, and though out of the scope of this paper, it will be an interesting future research direction to consider how actual causality can be incorporated into our proposed framework.

## 2 Causal Spaces and Interventions

Familiarity with measure-theoretic probability theory is necessary, and we succinctly collect the most essential definitions and results in Appendix A. Most important to note is the definition of a _transition probability kernel_ (also given at the end of Appendix A.1): for measurable spaces \((E,)\) and \((F,)\), a mapping \(K:E[0,]\) is called a _transition probability kernel_ from \((E,)\) into \((F,)\) if the mapping \(x K(x,B)\) is measurable for every set \(B\) and the mapping \(B K(x,B)\) is a probability measure on \((F,)\) for every \(x E\). Also worthy of mention is the definition of a _measurable rectangle_: if \((E,)\) and \((F,)\) are measurable spaces and \(A\) and \(B\), then the _measurable rectangle_\(A B\) is the set of all pairs \((x,y)\) with \(x A\) and \(y B\). All proofs are deferred to Appendix F. We start by recalling the axioms of probability theory, which we will use as the starting point of our work.

**Axioms 2.1** (Kolmogorov ).: _A probability space is a triple \((,,)\), where:_

* \(\) _is a set of outcomes;_
* \(\) _is a collection of events forming a_ \(\)_-algebra, i.e. a collection of subsets of_ \(\) _such that_ _(a)_ \(\)_; (b) if_ \(A\)_, then_ \( A\)_; (c) if_ \(A_{1},A_{2},...\)_, then_ \(_{n}A_{n}\)_;_
* \(\) _is a probability measure on_ \((,)\)_, i.e. a function_ \(:\) _satisfying (a)_ \(()=0\)_; (b)_ \((_{n}A_{n})=_{n}(A_{n})\) _for any disjoint sequence_ \((A_{n})\) _in_ \(\) _(c)_ \(()=1\)_._

In the development of probability theory, one starts by assuming the existence of a probability space \((,,)\). However, the actual construction of probability spaces that can carry random variables corresponding to desired random experiments is done through (repeated applications of) two main results - those of Ionescu-Tulcea and Kolmogorov [14, p.160, Chapter IV, Section 4]; the former constructs a probability space that can carry a finite or countably infinite chain of trials, and the latter shows the existence of a probability space that can carry a process with an arbitrary index set. In both cases, the measurable space \((,)\) is constructed as a product space:

* for a finite set of trials, each taking place in some measurable space \((E_{t},_{t}),t=1,...,n\), we have \((,)=_{t=1}^{n}(E_{t},_{t})\);
* for a countably infinite set of trials, each taking place in some measurable space \((E_{t},_{t})\), \(t\), we have \((,)=_{t}(E_{t},_{t})\);
* for a process \(\{X_{t}:t T\}\) with an arbitrary index set \(T\), we assume that all the \(X_{t}\) live in the same standard measurable space \((E,)\), and let \((,)=(E,)^{T}=_{t T}(E,)\).

In the construction of a _causal space_, we will take as our starting point a probability space \((,,)\), where the measure \(\) is defined on a product measurable space \((,)=_{t T}(E_{t},_{t})\) with the \((E_{t},_{t})\) being the same standard measurable space if \(T\) is uncountable. Denote by \((T)\) the power set of \(T\), and for \(S(T)\), we denote by \(_{S}\) the sub-\(\)-algebra of \(=_{t T}_{t}\) generated by measurable rectangles \(_{t T}A_{t}\), where \(A_{t}_{t}\) differs from \(E_{t}\) only for \(t S\). In particular, \(_{}=\{,\}\) is the trivial \(\)-algebra of \(=_{t T}E_{t}\). Also, we denote by \(_{S}\) the subspace \(_{s S}E_{s}\) of \(=_{t T}E_{t}\), and for \(T S U\), we let \(_{SU}\) denote the natural projection from \(_{S}\) onto \(_{U}\).

**Definition 2.2**.: A _causal space_ is defined as the quadruple \((,,,)\), where \((,,)=(_{t T}E_{t},_{t T}E_{t}, )\) is a probability space and \(=\{K_{S}:S(T)\}\), called the _causal mechanism_, is a collection of transition probability kernels \(K_{S}\) from \((,_{S})\) into \((,)\), called the _causal kernel on \(_{S}\)_, that satisfy the following axioms:

1. for all \(A\) and \(\), \[K_{}(,A)=(A);\]
2. for all \(\), \(A_{S}\) and \(B\), \[K_{S}(,A B)=1_{A}()K_{S}(,B)=_{}(A)K_{S}( ,B);\] \[A_{S}K_{S}(,A)=1_{A}()K_{S}(,)=1_{A}()=_{ }(A).\]

Here, the probability measure \(\) should be viewed as the "observational measure", and the causal mechanism \(\), consisting of causal kernels \(K_{S}\) for \(S(T)\), contains the "causal information" of the space, by directly specifying the interventional distributions. We write \(1_{A}()\) when viewed as a function in \(\) for a fixed \(A\), and \(_{}(A)\) when viewed as a measure for a fixed \(\). Note that \(\) cannot be determined "independently" of the probability measure \(\), since, for example, \(K_{}\) is clearly dependent on \(\) by (i).

Before we discuss the meaning of the two axioms, we immediately give the definition of an _intervention_. An intervention is carried out on a sub-\(\)-algebra of the form \(_{U}\) for some \(U(T)\). In the following, for \(S(T)\), we denote \(_{S}=_{TS}()\). Then note that \(=_{S}_{T S}\) and for any \(\), we can decompose it into components as \(=(_{S},_{T S})\). Then \(K_{S}(,A)=K_{S}((_{S},_{T S}),A)\) for any \(A\) only depends on the first \(_{S}\) component of \(=(_{S},_{T S})\). As a slight abuse of notation, we will sometimes write \(K_{S}(_{S},A)\) for conciseness.

**Definition 2.3**.: Let \((,,,)=(_{t T}E_{t},_{t T }E_{t},,)\) be a causal space, and \(U(T)\), \(\) a probability measure on \((,_{U})\) and \(=\{L_{V}:V(U)\}\) a causal mechanism on \((,_{U},)\). An _intervention on \(_{U}\) via \((,)\)_ is a new causal space \((,,^{(U,)},^{(U,,)})\), where the _intervention measure_\(^{(U,)}\) is a probability measure on \((,)\) defined, for \(A\), by

\[^{(U,)}(A)=(d)K_{U}(,A)\] (1)

and \(^{(U,,)}=\{K_{S}^{(U,,)}:S(T)\}\) is the _intervention causal mechanism_ whose _intervention causal kernels_ are

\[K_{S}^{(U,,)}(,A)= L_{S U}(_ {S U},d_{U}^{})K_{S U}((_{S U},_{U}^ {}),A).\] (2)

The intuition behind these definitions is as follows. Starting from the probability space \((,,)\), we choose a "subspace" on which to intervene, namely a sub-\(\)-algebra \(_{U}\) of \(\). The _intervention_ is the process of placing any desired measure \(\) on this "subspace" \((,_{U})\), along with an _internal_ causal mechanism \(\) on this "subspace"2. The causal kernel \(K_{U}\) corresponding to the "subspace" \(_{U}\), which is encoded in the original causal space, determines what the _intervention measure_ on the whole space \(\) will be, via equation (1). For the causal kernels after intervention, the causal effect first takes place within \(_{U}\) via the internal causal mechanism \(\), then propagates to the rest of \(\) via equation (2).

The definition of intervening on a \(\)-algebra of the form \(_{U}\) given in Definition 2.3 sheds light on the two axioms of causal spaces given in Definition 2.2.

**Remark 2.4**.: **Trivial Intervention**: Axiom (i) of causal mechanisms in Definition 2.2 ensures that intervening on the trivial \(\)-algebra (i.e. not intervening at all) leaves the probability measure intact, i.e. writing \(\) for the trivial probability measure on \(\{,\}\), we have \(^{(,)}=\).
**Interventional Determinism**: Axiom (ii) of Definition 2.2 ensures that for any \(A_{U}\), we have \(^{(U,)}(A)=(A)\), which means that if we intervene on the causal space by giving \(_{U}\) a particular probability measure \(\), then \(_{U}\) indeed has that measure with respect to the intervention probability measure.

The following example should serve as further clarification of the concepts.

**Example 2.5**.: _Let \(E_{1}=E_{2}=\), and \(_{1},_{2}\) be Lebesgue \(\)-algebras on \(E_{1}\) and \(E_{2}\). Each \(e_{1} E_{1}\) and \(e_{2} E_{2}\) respectively represent the altitude in metres and temperature in Celsius of a random location. For simplicity, we assume a jointly Gaussian measure \(\) on \((,)=(E_{1} E_{2},_{1}_{2})\), say with mean vector \(1000\\ 1\) and covariance matrix \(300&-15\\ -15&1\). For each \(e_{1} E_{1}\) and \(A_{2}\), we let \(K_{1}(e_{1},A)\) be the conditional measure of \(\) given \(e_{1}\), i.e. Gaussian with mean \(}{20}\) and variance \(\). This represents the fact that, if we intervene by fixing the altitude of a location, then the temperature of that location will be causally affected. However, if we intervene by fixing a temperature of a location, say by manually heating up or cooling down a place, then we expect that this has no causal effect on the altitude of the place. This can be represented by the causal kernel \(K_{2}(e_{2},B)=(B)\) for each \(B_{1}\), i.e. Gaussian measure with mean \(1000\) and variance \(300\), regardless of the value of \(e_{2}\). The corresponding "causal graph" would be Figure 2. If we intervene on \(_{1}\) with measure \(_{1000}\), i.e. we fix the altitude at \(1000\)m, then the intervention measure \(^{(1,_{1000})}\) on \((E_{2},_{2})\) would be Gaussian with mean \(10\) and variance \(\). If we intervene on \(_{2}\) with any measure \(\), the intervention measure \(^{(2,)}\) on \((E_{1},_{1})\) would still be Gaussian with mean \(1000\) and variance \(300\)._

The following theorem proves that the intervention measure and causal mechanism are indeed valid.

**Theorem 2.6**.: _From Definition 2.3, \(^{(U,)}\) is indeed a measure on \((,)\), and \(^{(U,,)}\) is indeed a valid causal mechanism on \((,,^{(U,)})\), i.e. they satisfy the axioms of Definition 2.2._

To end this section, we make a couple of further remarks on the definition of causal spaces.

**Remark 2.7**.:
1. We require causal spaces to be built on top of product probability spaces, as opposed to general probability spaces, and causal kernels are defined on sub-\(\)-algebras of \(\) of the form \(_{}\) for \(S(T)\), as opposed to general sub-\(\)-algebras of \(\). This is because, for two events that are not in separate components of a product space, one can always intervene on one of those events in such a way that the measure on the other event will have to change, meaning the causal kernel cannot be decoupled from the intervention itself. For example, in a dice-roll with outcomes \(\{1,2,3,4,5,6\}\) each with probability \(\), if we intervene to give measure \(1\) to roll \(6\), then the other outcomes are forced to have measure \(0\). Only if we consider separate components of product measurable spaces can we set meaningful causal relationships that are decoupled from the act of intervention itself.
2. We do not distinguish between interventions that are practically possible and those that are not. For example, the "causal effect of sunlight on the moon's temperature" cannot be measured realistically, as it would require covering up the sun, but the information encoded in the causal kernel would still correspond to what would happen when we cover up the sun.

## 3 Comparison with Existing Frameworks

In this section, we show how causal spaces can encode the interventional aspects of the two most widely-used frameworks of causality, i.e. structural causal models and the potential outcomes.

### Structural Causal Models (SCMs)

Consider an SCM in its most basic form, given in the following definition.

**Definition 3.1** ([46, p.83, Definition 6.2]).: A structural causal model \(=(,})\) consists of a collection \(\) of \(d\) (structural) assignments \(X_{j}:=f_{j}(_{j},N_{j}),j=1,...,d\), where \(_{j}\{X_{1},...,X_{d}\}\{X_{j}\}\) are called the _parents of_\(X_{j}\) and \(N_{j}\) are the _noise_ variables; and a distribution \(\) over the noise variables such that they are jointly independent.

The graph \(\) of an SCM is obtained by creating one vertex for each \(X_{j}\) and drawing directed edges from each parent in \(_{j}\) to \(X_{j}\). This graph is assumed to be acyclic.

Below, we show that a unique causal space that corresponds to such an SCM can be constructed.

Figure 2: Altitude and Temperature.

First, we let the variables \(X_{j},j=1,...,d\) take values in measurable spaces \((E_{j},_{j})\) respectively, and let \((,)=_{j=1}^{d}(E_{j},_{j})\). An SCM \(\) entails a unique distribution \(\) over the variables \(=(X_{1},...,X_{d})\) by the propagation of the noise distribution \(}\) through the structural equations \(f_{j}\)[46, p.84, Proposition 6.3], and we take this \(\) as the observational measure of the causal space. More precisely, assuming \(\{1,...,d\}\) is a topological ordering, we have, for \(A_{j}_{j},j=1,...,d\),

\[(A_{1} E_{2}... E_{d})=}(\{n_{1}:f_{1}(n_{1}) A_{1}\})\] \[(A_{1} A_{2} E_{3}... E_{d})= }(\{(n_{1},n_{2}):(f_{1}(n_{1}),f_{2}(f_{1}(n_{1}),n_{2}))  A_{1} A_{2}\})\] \[\] \[(A_{1}... A_{d})=}(\{(n_{ 1},...,n_{d}):(f_{1}(n_{1}),...,f_{d}(f_{1}(n_{1}),...,n_{d})) A_{1}... A_{d}\}).\]

Finally, for each \(S(\{1,...,d\})\) and for each \(\), define \(f_{j}^{S,}=f_{j}\) if \(j S\) and \(f_{j}^{S,}=_{j}\) if \(j S\). Then we have

\[K_{S}(,A_{1}... A_{d})=}(\{(n_{1},...,n_{d }):(f_{1}^{S,}(n_{1}),...,f_{d}^{S,}(f_{1}^{S,}(n_{1}),...,n _{d})) A_{1}... A_{d}\}).\]

This uniquely specifies the causal space \((,,,)\) that corresponds to the SCM \(\). While this shows that causal spaces strictly generalise (interventional aspects of) SCMs, there are fundamental philosophical differences between the two approaches, as highlighted in the following remark.

**Remark 3.2**.:
1. The "system" in an SCM can be viewed as the collection of all variables \(X_{1},...,X_{d}\), and the "subsystems" the individual variables or the groups of variables. Each _structural equation_\(f_{j}\) encodes how the whole system, when intervened on, affects a subsystem \(X_{j}\), i.e. how the collection of all other variables affects the individual variables (even though, in the end, the equations only depend on the parents). This way of encoding causal effects seems somewhat inconsistent with the philosophy laid out in the Introduction, that we are interested in what happens to the "system" when we intervene on a "subsystem". It also seems inconsistent with the actual action taken, which is to intervene on subsystems, not the whole system, or the parents of a particular variable. In contrast, the causal kernels encode exactly what happens to the whole system, i.e. what measure we get on the whole measurable space \((,)\), when we intervene on a "subsystem", i.e. put a desired measure on a sub-\(\)-algebra of \(^{3}\).
2. The primitive objects of SCMs are the variables \(X_{j}\), the structural equations \(f_{j}\) and the distribution \(P_{}\) over the noise variables. The observational distribution, as well as the interventional distributions, are derived from these objects. It turns out that unique existence of observational and interventional distributions are not guaranteed, and can only be shown under the acyclicity assumption or rather stringent and hard-to-verify conditions on the structural equations and the noise distributions . Moreover, it means that the observational and interventional distributions are not decoupled, and rather are linked through the structural equations \(f_{j}\), and as a result, it is not possible to encode the full range of observational and interventional distributions using just the variables of interest (see Example 4.1). In contrast, in causal spaces, the observational distribution \(\), as well as the interventional distributions (via the causal kernels), are the primitive objects. Not only does this automatically guarantee their unique existence, but it also allows the interventional distributions (i.e. the causal information) to be completely decoupled from the observational distribution.
3. Galles and Pearl [21, Section 3] propose three axioms of counterfactuals based on SCMs (called _causal models_ in that paper), namely, composition, effectiveness and reversibility. Even though these three concepts can be carried over to causal spaces, the mathematics through which they are represented needs to be adapted, since the tools that are used in causal spaces are different from those used in causal models of Galles and Pearl . In particular, we work directly with measures as the primitive objects, whereas Galles and Pearl  use the structural equations as the primitive objects, and the probabilities only enter through a measure on the exogenous variables. Thus, the three properties can be phrased in the causal space language as follows:

**Composition**: For \(S,R T\), denote by \(^{}\) the measure on \(_{S R}\) obtained by restricting \(^{(S,)}\). Then \(^{(S,)}=^{(S R,^{ })}\). In words, intervening on \(_{S}\) via the measure \(\) is the same as intervening on \(_{S R}\) via the measure that it would have if we intervened on \(_{S}\) via \(\).

This is not in general true. A counterexample can be demonstrated with a simple SCM, where \(X_{1}\), \(X_{2}\) and \(X_{3}\) causally affect \(Y\), in a way that depends not only on the marginal distributions of \(X_{1}\), \(X_{2}\) and \(X_{3}\) but their joint distribution, and \(X_{1}\), \(X_{2}\) and \(X_{3}\) have no causal relationships among them. Then intervening on \(X_{1}\) with some measure \(\) cannot be the same as intervening on \(X_{1}\) and \(X_{2}\) with \(\), since such an intervention would change the joint distribution of \(X_{1}\), \(X_{2}\) and \(X_{3}\), even if we give them the same marginal distributions.
**Effectiveness**: For \(S R T\), if we intervene on \(_{R}\) via a measure \(\), then \(_{S}\) has measure \(\) restricted to \(_{S}\).

This is indeed guaranteed by interventional determinism (Definition 2.2(ii)), so effectiveness continues to hold in causal spaces.
**Reversibility**: For \(S,R,U T\), let \(\) be some measure on \(_{S}\), and \(_{1}\) and \(_{2}\) be measures on \(_{S R}\) and \(_{S U}\) respectively such that they coincide with \(\) when restricted to \(_{S}\). Then if \(^{(S R,_{1})}(B)=_{2}(B)\) for all \(B_{U}\) and if \(^{(S U,_{2})}(C)=_{1}(C)\) for all \(C_{R}\), then \(^{(S,)}(A)=_{1}(A)\) for all \(A_{R}\).

This does not hold in general in causal spaces; in fact, Example 4.2 is a counterexample of this, with \(S=\).

### Potential Outcomes (PO) Framework

In the PO framework, the treatment and outcome variables of interest are fixed in advance. Although much of the literature begins with individual units, these units are in the end i.i.d. copies of random variables under the stable unit treatment value assumption (SUTVA), and that is how we begin.

Denote by \((,},})\) the underlying probability space. Let \(Z:\) be the "treatment" variable, taking values in a measurable space \((,)\). Then for each value \(z\) of the treatment, there is a separate random variable \(Y_{z}:\), called the "potential outcome given \(Z=z\)" taking values in a measurable space \((,)\); we also have the "observed outcome", which is the potential outcome consistent with the treatment, i.e. \(Y=Y_{Z}\). The researcher is interested in quantities such as the "average treatment effect", \(}[Y_{z_{1}}-Y_{z_{2}}]\), where \(}\) is the expectation with respect to \(}\), to measure the causal effect of the treatment. Often, there are other, "pre-treatment variables" or "covariates", which we denote by \(X:\), taking values in a measurable space \((,)\). Given these, another object of interest is the "conditional average treatment effect", defined as \(}[Y_{z_{1}}-Y_{z_{2}} X]\).

It is relatively straightforward to construct a causal space that can carry this framework. We define \(=\) and \(=)\). We also define \(\), for each \(A\), \(B\) and \(C\), as \((A B C)=}(Z A,Y B,X C)\). As for causal kernels, we are essentially only interested in \(K_{Z}(z,B)\) for \(B\), and we define these to be \(K_{Z}(z,B)=}(Y_{z} B)\).

## 4 Examples

In this section, we give a few more concrete constructions of causal spaces. In particular they are designed to highlight cases which are hard to represent with existing frameworks, but which have natural representations in terms of causal spaces. Comparisons are made particularly with SCMs.

### Confounders

The following example highlights the fact that, with graphical models, there is no way to encode correlation but no causation between two variables, using just the variables of interest.

**Example 4.1**.: _Consider the popular example of monthly ice cream sales and shark attacks in the US (Figure 2(a)), that shows that correlation does not imply causation. This cannot be encoded by an SCM with just two variables as in Figure 2(b), since no causation means no arrows between the variables, which in turn also means no dependence. One needs to add the common causes into themodel (whether observed or latent), the most obvious one being the temperature (high temperatures make people desire ice cream more, as well as to go to the beach more), as seen in Figure 2(c). Now we have a model in which both dependence and no causation are captured. But can we stop here? There are probably other factors that affect both variables, such as the economy (the better the economic situation, the more likely people are to buy ice cream, and to take beach holidays) - see Figure 2(d). Not only is the model starting to lose parsimony, but as soon as we stop adding variables to the model, we are making an assumption that there are no further confounding variables out there in the world4._

_In contrast, causal spaces allow us to model any observational and causal relationships with just the variables that we were interested in, without any restrictions or the need to add more variables. In this particular example, we would take as our causal space \((E_{1} E_{2},_{1}_{2},,)\), where \(E_{1}=E_{2}=\) with values in \(E_{1}\) and \(E_{2}\) corresponding to ice cream sales and shark attacks respectively, and \(_{1}=_{2}\) being Lebesgue \(\)-algebras. Then we can let \(\) be a measure that has a strong dependence between any \(A_{1}\) and \(B_{2}\), but let the causal kernels be \(K_{1}(x,B)=(B)\) for any \(x E_{1}\) and \(B_{2}\), and likewise \(K_{2}(x,A)=(A)\) for any \(x E_{2}\) and \(A_{1}\)._

Nancy Cartwright argued against the completeness of causal Markov condition, using an example of two factories [13, p.108], in which there may not even be any confounders between dependent variables, not even an unobserved one. If we accept her position, then there are situations which SCMs would not be able to represent, whereas causal spaces would have no problems at all.

### Cycles

As mentioned before, cycles in SCMs cause serious problems, namely that observational and interventional distributions that are consistent with the given structural equations and noise distribution may not exist, and when they do, they may not exist uniquely. This is an artefact of the fact that these distributions are derived from the structural equations rather than taken as the primitive objects. In the vast majority of the cases, cycles are excluded from consideration from the beginning and only directed acyclic graphs (DAGs) are considered. Some works study the _solvability_ of cyclic SCMs , where the authors investigate under what conditions on the structural equations and the noise variables there exist random variables and distributions that _solve_ the given structural equations, and if so, when that happens _uniquely_. Other works have allowed cycles to exist, but restricted the definition of an SCM only to those that have a unique solution .

Of course, cyclic causal relationships abound in the real world. In our proposed causal space (Definition 2.2), given two sub-\(\)-algebras \(_{S}\) and \(_{U}\) of \(\), nothing stops both of them from having a causal effect on the other (see Definition B.1 for a precise definition of causal effects), but we are still guaranteed to have a unique causal space, both before intervention and after intervention on either \(_{S}\) or \(_{U}\). The following is an example of a situation with "cyclic" causal relationship.

**Example 4.2**.: _We want to model the relationship between the amount of rice in the market and its price per kg. Take as the probability space \((E_{1} E_{2},_{1}_{2},)\), where \(E_{1}=E_{2}=\) with values in \(E_{1}\) and \(E_{2}\) representing the amount of rice in the market in million tonnes and the price

Figure 3: Correlation but no causation between ice-cream sales and shark attacks. S stands for the number of shark attacks, I for ice cream sales, T for temperature and E for economy.

of rice per kg in KRW respectively, \(_{1},_{2}\) are Lebesgue \(\)-algebras and \(\) is for simplicity taken to be jointly Gaussian. Without any intervention, the higher the yield, the more rice there is in the market and lower the price, as in Figure 3(b). If the government intervenes on the market by buying up extra rice or releasing rice into the market from its stock, with the goal of stabilising supply at 3 million tonnes, then the price will stabilise accordingly, say with Gaussian distribution with mean 4.5 and standard deviation 0.5, as in Figure 3(c). The corresponding causal kernel will be \(K_{1}(3,x)=}e^{-()^{2}}\). On the other hand, if the government fixes the price of rice at a price, say at 6,000 KRW per kg, then the farmers will be incentivised to produce more, say with Gaussian distribution with mean 4 and standard deviation 0.5, as in Figure 3(d). The corresponding causal kernel will be \(K_{2}(6,y)=}e^{-()^{2}}\)._

Causal spaces treat causal effects really as what happens after an intervention takes place, and with this approach, cycles can be rather naturally encoded, as shown above. We do not view cyclic causal relationships as an equilibrium of a dynamical system, or require it to be viewed as an acyclic stochastic process, as done by some authors [46, p.85, Remark 6.5].

### Continuous-time Stochastic Processes, and Parents

A very well established sub-field of probability theory is the field of stochastic processes, in which the index set representing (most often) time can be either discrete or continuous, and in both cases, infinite. However, most causal models start by assuming a finite number of variables, which immediately rules out considering stochastic processes, and efforts to extend to infinite number of variables usually consider only discrete time steps [46, Chapter 10] or dynamical systems . Since probability spaces have proven to accommodate continuous time stochastic processes in a natural way, it is natural to believe that causal spaces, being built up from probability spaces, should be able to enable the incorporation of the concept of causality in the theory of stochastic processes.

Let \(W\) be a totally-ordered set, in particular \(W==\{0,1,...\}\), \(W==\{...,-2,-1,0,1,2,...\}\), \(W=_{+}=[0,)\) or \(W==(-,)\) considered as the time set. Then, we consider causal spaces of the form \((,,,)=(_{t T}E_{t},_{t  T}_{t},,)\), where the index set \(T\) can be written as \(T=W\) for some other index set \(\). The following notion captures the intuition that causation can only go forwards in time.

**Definition 4.3**.: Let \((,,,)=(_{t T}E_{t},_{t  T}_{t},,)\) be a causal space, where the index set \(T\) can be written as \(T=W\), with \(W\) representing time. Then we say that the causal mechanism \(\)_respects time_, or that \(\) is a _time-respecting causal mechanism_, if, for all \(w_{1},w_{2} W\) with \(w_{1}<w_{2}\), we have that \(_{w_{2}}\) has no causal effect (in the sense of Definition B.1) on \(_{w_{1}}\).

In a causal space where the index set \(T\) has a time component, the fact that causal mechanism \(\) respects time means that the past can affect the future, but the future cannot affect the past. This already distinguishes itself from the concept of conditioning - conditioning on the future does have implications for past events. We illustrate this point in the example of a Brownian motion.

**Example 4.4**.: _We consider a 1-dimensional Brownian motion. Take \((_{t_{+}}E_{t},_{t_{+}}_{t },,)\), where, for each \(t_{+}\), \(E_{t}=\) and \(_{t}\) is the Lebesgue \(\)-algebra, and \(\) is the Wiener measure. For \(s<t\), we have causal kernels \(K_{s}(x,y)=}e^{-)}(y-x)^{2}}\) and \(K_{t}(x,y)=}e^{-y^{2}}\)._

_The former says that, if we intervene by setting the value of the process to \(x\) at time \(s\), then the process starts again from \(x\), whereas the latter says that if we intervene at time \(t\), the past values at time \(s\) are not affected. On the left-hand plot of Figure 5, we set the value of the process at time \(1\) to \(0\). The past values of the process are not affected, and there is a discontinuity at time \(1\) where the process starts

Figure 4: Rice in the market in million tonnes and price per kg in KRW.

again from \(0\). Contrast this to the right-hand plot, where we condition on the process having value \(0\) at time \(1\). This does affect past values, and creates a Brownian bridge from time \(0\) to time \(1\)._

_Note, Brownian motion is not differentiable, so no approach based on dynamical systems is applicable._

**Remark 4.5**.: The concept of _parents_ is central in SCMs - the structural equations are defined on the parents of each variable. However, continuous time is dense, so given two distinct points in time, there is always a time point in between. Suppose we have a one-dimensional continuous time Markov process \((X_{t})_{t}\)[14, p.169], and a point \(t_{0}\) in time. Then for any \(t<t_{0}\), \(X_{t}\) has a causal effect on \(X_{t_{0}}\), but there always exists some \(t^{}\) with \(t<t^{}<t_{0}\) such that conditioned on \(X_{t^{}}\), \(X_{t}\) does not have a causal effect on \(X_{t_{0}}\), meaning \(X_{t}\) cannot be a parent of \(X_{t_{0}}\). In such a case, \(X_{t_{0}}\) cannot be said to have any parents, and hence no corresponding SCM can be defined.

## 5 Conclusion

In this work, we discussed the lack of a universally agreed axiomatisation of causality, and some arguments as to why measure-theoretic probability theory can provide a good foundation on which to build such an axiomatisation. We proposed _causal spaces_, by enriching probability spaces with causal kernels that encode information about what happens after an intervention. We showed how the interventional aspects of existing frameworks can be captured by causal spaces, and finally we gave some explicit constructions, highlighting cases in which existing frameworks fall short.

Even if causal spaces prove with time to be the correct approach to axiomatise causality, there is much work to be done - in fact, all the more so in that case. Most conspicuously, we only discussed the _interventional_ aspects of the theory of causality, but the notion of _counterfactuals_ is also seen as a key part of the theory, both _interventional counterfactuals_ as advocated by Pearl's ladder of causation [44, Figure 1.2] and _backtracking counterfactuals_. We provide some discussions and possible first steps towards this goal in Appendix E, but mostly leave it as essential future work. Only then will we be able to provide a full comparison with the counterfactual aspects of SCMs and the potential outcomes. As discussed in Section 1, the notion of _actual causality_ is also important, and it would be interesting to investigate how this notion can be embedded into causal spaces. Many important definitions, including causal effects, conditional causal effects, hard interventions and sources, as well as technical results, were deferred to the appendix purely due to space constraints, but we foresee that there would be many more interesting results to be proved, inspired both from theory and practice. In particular, the theory of _causal abstraction_ should benefit from our proposal, through extensions of homomorphisms of probability spaces to causal spaces5.

As a final note, we stress again that our goal should _not_ be understood as replacing existing frameworks. Indeed, causal spaces cannot compete in terms of interpretability, and in the vast majority of situations in which SCMs, potential outcomes or any of the other existing frameworks are suitable, we expect them to be much more useful. In particular, assumptions are unavoidable for identifiability from observational data, and those assumptions are much better captured by existing frameworks6, However, just as measure-theoretic probability theory has its value despite not being useful for practitioners in applied statistics, we believe that it is a worthy endeavour to formally axiomatise causality.

Figure 5: 1-dimensional Brownian motion, intervened and conditioned to have value \(0\) at time \(1\).