# Speaking Your Language: Spatial Relationships in Interpretable Emergent Communication

Olaf Lipinski\({}^{1}\) Adam J. Sobey\({}^{2,1}\) Federico Cerutti\({}^{3}\) Timothy J. Norman\({}^{1}\)

\({}^{1}\)University of Southampton

\({}^{2}\)The Alan Turing Institute

\({}^{3}\)University of Brescia

{o.lipinski,t.j.norman}@soton.ac.uk

asobey@turing.ac.uk

federico.cerutti@unibs.it

Corresponding author: o.lipinski@soton.ac.uk

###### Abstract

Effective communication requires the ability to refer to specific parts of an observation in relation to others. While emergent communication literature shows success in developing various language properties, no research has shown the emergence of such positional references. This paper demonstrates how agents can communicate about spatial relationships within their observations. The results indicate that agents can develop a language capable of expressing the relationships between parts of their observation, achieving over 90% accuracy when trained in a referential game which requires such communication. Using a collocation measure, we demonstrate how the agents create such references. This analysis suggests that agents use a mixture of non-compositional and compositional messages to convey spatial relationships. We also show that the emergent language is interpretable by humans. The translation accuracy is tested by communicating with the receiver agent, where the receiver achieves over 78% accuracy using parts of this lexicon, confirming that the interpretation of the emergent language was successful.

## 1 Spatial referencing in emergent communication

Emergent communication allows agents to develop bespoke languages for their environment. While there are many successful examples of efficient (Rita et al., 2020) and compositional (Chaabouni et al., 2020) languages, they often lack fundamental aspects seen in human language, such as syntax (Lazaridou and Baroni, 2020) or recursion (Baroni, 2020). It is argued that these aspects of communication are important to improve the efficiency and generalisability of emergent languages (Baroni, 2020; Boldt and Mortensen, 2024; Rita et al., 2024). However, the current architectures, environments, and reward schemes are yet to exhibit such fundamental properties.

One such aspect is the development of _deixis_(Rita et al., 2024), which has been described as a way of pointing through language. Examples of _temporal deixis_ include words such as "yesterday" or "before," and _spatial deixis_ include words such as "here" or "next to" (Lyons, 1977). In emergent communication, Lipinski et al. (2023) investigate how agents may refer to repeating observations, which could also be viewed from the linguistic perspective as investigating _temporal deixis_. However, while there are advocates to investigate how emergent languages can develop key concepts from human language (Rita et al., 2024), no work has demonstrated the emergence of relative references to specific locations _within_ an observation, or _spatial deixis_.

Spatial references would be valuable in establishing shared context between agents, increasing communication efficiency by reducing the need for detailed descriptions, and adaptability, by removing the need for unique references per object. For example, instead of describing a new, previouslyunseen object, such as "a blue vase with intricate motifs on the table," one could simply use spatial relationships and say "the object left of the plate." Spatial referencing streamlines communication by leveraging the shared environment as a reference point. In dynamic environments where objects might change positions, spatial references enable agents to easily track and refer to objects without having to update their descriptions. This enhances communication efficiency and improves interaction and collaboration between agents. These elements may also help the evolved language become human interpretable, allowing the development of trustworthy emergent communication (Lazaridou and Baroni, 2020; Mu and Goodman, 2021).

This paper therefore explores how agents can develop communication with spatial references. While Rita et al. (2024) posit that the emergence of these references might require complex settings, we show that even agents trained in a modified version of the simple referential game (Lazaridou et al., 2018; Lewis, 1969) can develop spatial references.2 This resulting language is segmented and analysed using a collocation measure, Normalised Pointwise Mutual Information (NPMI) adapted from computational linguistics. NPMI allows us to measure the strength of associations between message parts and their context, making it a valuable tool for gaining insights into the underlying structure of the emergent language. Using NPMI, we show how the agents compose such spatial references, providing the first hint of a syntactic structure, and showing that the emergent language can be interpreted by humans.

## 2 Development of a spatial referential game

Current emergent communication environments have not produced languages incorporating spatial references. To address this, we present a referential game (Lazaridou et al., 2018) environment where an effective language requires communication about spatial relationships.

### Referential game environment

In the referential game, there are two agents, a sender and a receiver. The sender observes a vector and transmits its compressed representation through a discrete channel to the receiver. The receiver observes a set of vectors and the sender's message. One of these vectors is the same as the one the sender has observed. The receiver's goal is to correctly identify the vector the sender has described, among other vectors referred to as distractors. The simplicity of the referential games enables the reduction of extraneous factors which could impact the emergence of spatial references, such as transfer learning of the vision network or exploring action spaces in more complex environments.

In this work, the sender's input is an observation in the form of a vector \(=[o_{1},o_{2},o_{3},o_{4},o_{5}]\), where \( o\{-1,0,1 59\}\). The vector \(\) is always composed of \(5\) integers. The observation includes a \(-1\) in only one position, _e.g._, \(_{3}=-1\) for \(=[x,x,-1,x,x]\), to indicate the target integer for the receiver to identify. \(\) represents a window into a longer sequence \(\), which is randomly generated using the integers \(\{0 59\}\) without repetitions. This sequence is visible to the receiver, but **not** to the sender. As the target's position in the sequence is unknown to the sender, it has to rely on the relative positional information present in its observation, necessitating the use of _spatial referencing_.

Due to the window into the sequence being of length \(5\), it is necessary to shift the window when it approaches either extent of the sequence. The window is then shifted to the other side, maintaining the size of \(5\). For example, given a short sequence \(=\), if the selected target is \(1\), since there are no integers to the right of \(1\) the vector \(\) would be \(=[6,9,8,11,-1]\) where it is shifted to the left as it approaches this rightmost extent of the sequence.

Due to the necessity of maintaining the window size, some observations provide additional positional information to the sender agent. Given the same example sequence \(\), we can categorise all observations into \(5\) types. The _begin_ and _begin+1_, where the target integer is either at, or one after, the beginning of the sequence, _i.e._, \(=[-1,5,2,12,10]\) or \(=[7,-1,2,12,10]\). The _end_ and _end-1_, where the target integer is either at, or one before, the end of the sequence, _i.e._, \(=[6,9,8,11,-1]\) or \(=[6,9,8,-1,1]\). The most common case is the _middle_ observation, where the target integer is anywhere in the sequence, excluding the first, second, second, second to last, and last positions, _e.g._, \(=[12,10,-1,3,15]\). Given a window of length \(5\), only \(4\) specific target integer positions per sequence can result in the other observations (_begin+1_, _begin+1_, _end-1_, and _end_). All other target integer positions within the sequence fall into the _middle_ category, as they do not occupy the first, second, second to last, or last positions. Consequently, the majority of the target integer positions result in a _middle_ type observation.

The sender's output is a message defined as a vector \(=[m_{1},m_{2},m_{3}]\), where \(m\{1 26\}\). \(26\) is chosen to allow for a high degree of expressivity, with the agents being able to use over 17k different messages, while also matching the size of the Latin alphabet. Since such a vocabulary size is enough to convey any information in natural languages like English, we consider that this should also apply to the agents. The vector \(\) is always composed of \(3\) integers.

The receiver's input is an observation consisting of three vectors: the sender's message \(\), the sequence \(\), and the set of distractor integers together with the target integer \(\). The distractor integers are randomly generated, without repetitions, given the same range of integers as the original sequence \(\), _i.e._, \(\{0 59\}\), excluding the target object itself. Given an environment with \(3\) distractors, \(\) could be \([d_{1},t,d_{2},d_{3}]\), where \(t\) is the target object and \(d_{1},d_{2},d_{3}\) are distractor objects. The position of the target object in \(\) is randomised.

For example, given the sequence \(=\), and the sender's observation \(=[4,3,-1,16,13]\), the vector \(\) could be \(=\), with \(15\) being the target that the receiver needs to identify. The sender could produce a message \(=\), which would mean that the target integer is one after the integer \(3\). This message would then be passed to the receiver, together with \(\) and \(\). The receiver would then have to correctly understand the message \(\) (_i.e._, that the target is one after \(3\)) and find the integer \(3\) together with the following integer in the sequence \(\). Having identified the target \(15\) given the message \(\) and the sequence \(\), it would output the correct position of this target in the \(\) vector, _i.e._, \(2\), since \(_{2}=15\).

### Spatial reference formalisation

To provide a generalisation of our results, we formalise what we refer to as spatio-temporal references. Let \(O\) represent an abstract observation that an agent perceives from its environment, \(O^{m}\), where \(m\) represents the dimensions of the observation. For a 3D observation, \(m\) could be \(m=j k d\). Such an \(m\) could represent a \(j k\) matrix of \(d=3\) values, which, for example, could be an RGB picture, with \(j k\) pixels and one value for each of the RGB colours (\(d=3\)). The \(m\) dimensions can represent the spatial, temporal, or other positions.

Let \(O_{p}\) and \(O_{t}\) be the coordinates of some elements in \(O\), represented by an \(m\)-tuple of natural numbers \((x_{1},x_{2}...x_{m})\) and \((y_{1},y_{2}...y_{m})\), respectively. \(O_{p}\) represents the reference point and \(O_{t}\) represents a target point.

Then, the relative distance function \(d(O_{p},O_{t})\) returns an \(m\)-tuple of integers \((z_{1},z_{2}...z_{m})\), such that \(z_{i}=x_{i}-y_{i}\). This relative distance function allows for unambiguous identification of the target object \(O_{t}\), given that the position of \(O_{p}\) is known.

We define the spatio-temporally referent expression as a mapping of the value of \(d(O_{p},O_{t})\), the reference point \(O_{p}\), and their context \(O\), to a specific linguistic or symbolic phrase that describes the relationship between \(O_{p}\) and \(O_{t}\). This mapping can be represented as:

\((O,d(O_{p},O_{t}),O_{p})(O,d(O_{p},O_{t}),O_{p})\)

where the resulting expression \((O,d(O_{p},O_{t}),O_{p})\) is a description of the reference point \(O_{p}\) and its relative distances to the target point \(O_{t}\), given the context \(O\).

The version of spatial referencing in our environment is a specific case of the general spatial reference formalisation, where the observation \(O\) is represented as a one-dimensional tensor, and the target point \(O_{t}\) is always indicated by the value \(-1\) within the tensor. The sender's task is to describe the relative position of the target \(O_{t}\) within this sequence, using a message that effectively communicates the spatial relationship between a chosen \(O_{p}\) and the target \(O_{t}\).

## 3 Agent Architecture

The agent architecture follows that of the most commonly used EGG agents (Kharitonov et al., 2019). This architecture is used to maintain consistency with the common approaches in emergent communication research (Chaabouni et al., 2019, 2020; Kharitonov et al., 2019; Lipinski et al., 2023;Ueda and Washio, 2021), increasing the generalization of the results presented in this work. All environmental observations, _i.e._, \(\), \(\), and \(\), are passed in as scalars, as one-hot encoding of the observation vectors leads to agents memorising the dataset.

The sender agent, shown in Figure 0(a), receives a single input, the vector \(\), which is passed through the first GRU of the sender. The resulting hidden state is used as the initial hidden state for the message generation GRU (Cho et al., 2014). The message generation GRU is used to produce the message, character by character, using the Gumbel-Softmax reparametrization trick (Jang et al., 2017; Kharitonov et al., 2019; Mordatch and Abbeel, 2018). The sequence of character probabilities generated from the sender is used to output the message \(\).

\(\) is input to the receiver agent, shown in Figure 0(b), together with the full sequence \(\) and the target and distractors \(\). The message is processed by the first receiver GRU, which produces a hidden state used as the initial hidden state for the GRU processing the sequence \(\). This is the only change from the standard EGG architecture (Kharitonov et al., 2019). This additional GRU allows the receiver agent to process the additional input sequence \(\), using the information contained within the message \(\). The goal of this GRU is to use the information provided by the sender to correctly identify which integer from the sequence \(\) is the target integer. The final hidden state from the additional GRU is multiplied with an embedding of the targets and distractors, to output the receiver's prediction. This prediction is in the form of the index of the target within \(\).

Following the commonly used approach (Kharitonov et al., 2019), agent optimisation is performed using the Gumbel-Softmax reparametrization (Jang et al., 2017; Mordatch and Abbeel, 2018), allowing for direct gradient flow through the discrete channel. The agents' loss is computed by applying the cross entropy loss, using the receiver target prediction and the true target label. The resulting gradients are passed to the Adam optimiser and backpropagated through the network. Detailed training hyperparameters are provided in Appendix A.

## 4 Message interpretability and analysis using NPMI

To analyse spatial references in emergent language, a way to identify their presence is essential. In discrete emergent languages, interpretation is typically done by either using dataset labels in natural language (Dessi et al., 2021), or by qualitative analysis of specific messages (Havrylov and Titov, 2017). However, both of these techniques require message-meaning pairs, and so neither would be able to identify the presence of spatial references, as the labels for spatial relationships that the agents refer to would not necessarily be available. One approach that could overcome this problem is emergent language segmentation using Harris' Articulation Scheme, recently employed by Ueda et al. (2023). Ueda et al. (2023) compute the conditional entropy of each character in the emergent language, segmenting the messages where the conditional entropy increases. However,

Figure 1: The sender and receiver architectures. Adapted from (Lipinski et al., 2023).

even after language segmentation, there is no easy way to interpret the segments, as no method has been proposed to map them to specific meanings.

We present an approach to both segment the emergent language and map the segments to their meanings. We use a collocation measure called Normalised Pointwise Mutual Information (NPMI) (Bouma, 2009), often used in computational linguistics (Lim and Lauw, 2024; Thielmann et al., 2024; Yamaki et al., 2023). It is used to determine which messages are used for which observations and to analyse how the messages are composed, including whether they are trivially compositional (Korbak et al., 2020; Perkins, 2021; Steinert-Threlkeld, 2020). By applying a collocation measure to different parts of each message as well as the whole message, we can address the problems of both segmentation and interpretation of the message segments. This approach allows any part of the message to carry a different meaning. For example, if an emergent message contains segments that frequently appear in contexts involving specific integers, NPMI can help identify these segments and their meanings based on their statistical association with those integers.

NPMI is a normalised version of the Pointwise Mutual Information (PMI) (Church and Hanks, 1989), which is a measure of association between two events. PMI is widely used in computational linguistics, to measure the association between words (Han et al., 2013; Paperno and Baroni, 2016). Normalising the PMI measure results in its codomain being defined between \(-1\) and \(1\), with \(-1\) indicating a purely negative association (_i.e._, events **never** occurring together), \(0\) indicating no association (_i.e._, events being **independent**), and \(1\) indicating a purely positive association (_i.e._, events **always** occurring together). Normalised PMI is used for convenience when defining a threshold at which we consider a message or \(n\)-gram to carry a specific meaning, as the threshold can be between \(0\) and \(1\), instead of unbounded numbers in the case of PMI. 3

To determine which parts of each message are used for a given meaning, two algorithms are proposed.

1. PMI\({}_{nc}\) The algorithm to measure non-compositional monolithic messages, most often used for target positional information (_e.g._, _begin+1_ (Section 2)); and
2. PMI\({}_{c}\) the algorithm to measure trivially compositional messages and their \(n\)-grams, used to refer to different integers in different positions.

A visual representation of the different types of messages that the algorithms can identify is provided in Figure 2. The PMI\({}_{nc}\) algorithm can identify any non-compositional messages, while the PMI\({}_{c}\) algorithm identifies both position variant and invariant compositional messages. The positional variance of the emergent language means that the position of an \(n\)-gram in the message also carries a part of its meaning. In this work, \(n\)-grams refer to a contiguous sequence of n integers from the sender's message. Consequently, in one message there are \(3\) unigrams (\(m_{1}\), \(m_{2}\), \(m_{3}\)), two bigrams ([\(m_{1}\), \(m_{2}\)], [\(m_{2}\), \(m_{3}\)]), and one trigram (_i.e._, the whole message [\(m_{1}\), \(m_{2}\), \(m_{3}\)]).

Figure 2 shows that in the position invariant case, the bigram \(\) always carries the meaning of \(4\). While in the position variant case, the bigram \(\) in position \(1\) of the message means \(4\), but \(\) in position \(2\) of the message means \(8\). This can also be interpreted as the position of the bigram containing additional information, meaning a single "word" could be represented as a tuple of the bigram and its position in the message, as both contribute to its underlying information. Non-compositional messages are monolithic, _i.e._, the whole message carries the entire meaning. For example, message \(\) means the target is in the first position, while \(\) means the target is one to the right of \(9\), even though the two messages share the bigram \(\).

The PMI\({}_{nc}\) algorithmThe PMI\({}_{nc}\) algorithm calculates the NPMI per message by first building a dictionary of all counts of each message being sent, together with an observation that may provide positional information (_e.g._, _begin+1_) or refer to an integer in a given position (_e.g._, 1 left of the target). The counts of that message and the counts of the observation, including the integer position, are also collected. For example, consider the observation \(=[4,-1,15,16,13]\). For the corresponding message \(\), the counts for each integer in each position relative to the target would increase by \(1\) (_i.e._, \(left1+=1\), \(right1+=1\)_etc._). The count for the message signifying _begin+1_ would also be increased. Given these counts, the algorithm then estimates the probabilities of all respective events (messages, positional observations, and integers in given positions) and calculates the NPMI measure.

The PMI\({}_{c}\) algorithmThe PMI\({}_{c}\) algorithm first creates a dictionary of all possible \(n\)-grams, given the message space (\(m\)) and maximum message length (\(3\)). The list of all possible \(n\)-grams is pruned to contain only the \(n\)-grams present in the agents' language, avoiding unnecessary computation in the later parts of the algorithm. Given the pruned list of \(n\)-grams, the algorithm checks the context in which the \(n\)-grams have been used. The occurrence of each \(n\)-gram is counted, together with the \(n\)-gram position in the messages and the context in which it has been sent, or the integers in the observation. The \(n\)-gram position in the message is considered to account for the possible position variance of the compositional messages.

Consider the previous example, with \(=[4,-1,15,16,13]\) and a message \(=\). For all \(n\)-grams (\(,,,\), _etc._) of the message, all integers are counted, irrespective of their positions (_i.e._, \(counts+=1\), \(counts+=1\), _etc._).

Given these counts, the PMI\({}_{c}\) algorithm estimates the NPMI measure for all \(n\)-grams and all integers in the observations. These probabilities are estimated from the dataset using the count of their respective occurrences divided by the number of all observations/messages.

Once the NPMI measure is obtained for the \(n\)-gram-integer pairs, the algorithm calculates the NPMI measure for \(n\)-grams and referent positions or the positions of the integer in the observation the message refers to. For example, given an observation \(=[4,-1,15,16,13]\), if the message contains an \(n\)-gram which has been identified as referring to the integer \(15\), the rest of the message (_i.e._, the unigram or bigram, depending on the length of the integer \(n\)-gram) is counted as a possible reference to that position, in this case, to position \(right1\), or \(1\) to the right of the target. This procedure follows for all messages, building a count for each time an \(n\)-gram was used together with a possible \(n\)-gram for an integer. These counts are used to calculate the NPMI measure for \(n\)-gram and position pairs.

The PMI\({}_{c}\) algorithm also accounts for the possible position invariance of the \(n\)-grams, _i.e._, where in the message the \(n\)-gram appears. This is achieved by calculating the respective probabilities _regardless_ of the position of the \(n\)-gram in the message, by summing the individual counts for each \(n\)-gram position.

PseudocodeWe provide a condensed pseudocode for both algorithms in Algorithm 1. In the case of the PMI\({}_{nc}\), the \(n\)-grams in the pseudocode would be whole messages, _i.e._, trigrams. This base pseudocode would then be duplicated, interpreting the context as either an observation that may provide positional information (_e.g._, _begin+1_) or an integer.

For the PMI\({}_{c}\) algorithm, only the unigrams and bigrams would be evaluated. The base pseudocode would also be duplicated, once for the integer in a given position, and second for the referent position. Each would be used as the context in which to evaluate the NPMI for each \(n\)-gram. A detailed commented pseudocode for both the PMI\({}_{nc}\) and PMI\({}_{c}\) algorithms is available in Algorithm 2 and Algorithm 3 in Appendix D, respectively.

Both algorithms use two hyperparameters: a confidence threshold \(t_{c}\) and top_n \(t_{n}\). The confidence threshold refers to the value of the NPMI measure at which a message or \(n\)-gram can be considered to refer to the given part of the observation unambiguously. To account for polysemy (where one symbol can have multiple meanings), the agents can use a single \(n\)-gram to refer to multiple integers.

Figure 2: Examples of the different types of message compositionality that are possible to identify using the PMI algorithms.

[MISSING_PAGE_FAIL:7]

Together, a message can be composed \(\), which means that the target integer for the receiver to identify is \(2\) to the right of the integer \(18\), _i.e._, \(=[18,X,-1,X,X]\). This allows the sender to identify the target integer exactly, given the sequence \(\).

In Table 1, we summarise the emergence of each type of message across all runs, together with the percentage of the vocabulary that they represent. The entries in the table are composed of average percentages, across all \(t_{n}\) and \(t_{c}\) choices. In the parentheses, we show the maximum and minimum values across all \(t_{n}\) and \(t_{c}\) choices. The average % of emergence represents the absolute % of runs which developed that message type or message feature. For all messages, the average % of messages which are of a given type or exhibit a given feature is only counted for in runs where these features emerged.

### Evaluating interpretation validity and accuracy

To ensure the validity of our message analysis, we present two hypotheses which, if supported by the results, would indicate that the mappings generated by the NPMI measure are correct.

**Hypothesis 1** (H1): If the correlations exist and do not require non-trivial compositionality (Perkins, 2021), and are not highly context-dependent (Nikolaus, 2023), then the evaluation accuracy should be significantly higher than chance, or above \(20\%\), when using the identified mappings.
**Hypothesis 2** (H2): If the positional components of compositional messages are correctly identified and carry the intended meaning, then their inclusion should result in an increase in accuracy.

Given the messages identified by the NPMI method, we test **H1** and **H2** by using a dictionary of all messages successfully identified, given a value of both NPMI hyperparameters \(t_{n}\) and \(t_{c}\). A dataset is generated to contain only targets which can be described with the messages present in the dictionary.

For the non-compositional messages, the dataset is generated by selecting a message from the dictionary at random, and creating an observation that can be described with that message. Given a non-compositional message that corresponds to the target being on the right of the integer \(15\), an observation \(=[1,15,-1,5,36]\) would be created. Analogously, for non-compositional positional messages such as _begin_ an observation \(=[-1,15,8,5,36]\) would be created.

For the compositional messages, we create the observations by randomly selecting a positional component and an integer component from the dictionary. For example, given the unigram \(7\) meaning that X is 2 to the left of the target, we could select the bigram \(\) corresponding to the integer \(30\). The observation created could then be \(=[30,8,-1,36,5]\). The dataset creation process for the compositional messages also checks if the observations can be described given the two \(n\)-grams in their required positions within the message.

To test **H2**, a dataset is created using **only** the integers that can be described by the dictionaries, randomly selecting integer components from the dictionary, and creating the respective observations. This process also accounts for the required positions of the message components so that a message describing the observation can always be created. For example, if the unigram \(9\) described the integer \(11\), and the bigram \(\) described the integer \(6\), a corresponding observation could be \(=[11,6,-1,8,9]\). The positions of the integers in the observations are chosen at random. By generating both compositional datasets using a stochastic process, we do not assume a specific syntax. Rather, the syntax can only be identified by looking at messages understood by the receiver.

   Message Type & Avg. \% Emergence & Avg. \% of Messages \\  Non-Compositional Positional & 99.3\% (100\%-93.75\%) & 1\% (3\%-0\%) \\ Non-Compositional Positional Reserved & 18.75\% (18.75\%-18.75\%) & 1\% (3\%-0\%) \\ Non-Compositional Integer & 45.1\% (100\%-0\%) & 10\% (15\%-0\%) \\ Compositional Integer & 100\% (100\%-100\%) & 34\% (99.7\%-0\%) \\ Compositional Positional & 25\% (27\%-0\%) & 56\% (100\%-0\%) \\   

Table 1: Average emergence and vocabulary coverage of all message types.

These datasets, together with their respective dictionaries, are then used to query the receiver agent, testing if the messages are identified correctly. We run this test for all of our trained agents, with the dictionaries that were identified for each agent pair. We provide the details in Table 2.

Using just the non-compositional positional messages, we observe a significant increase in the performance of the agents, compared to random chance accuracy of **20%**. This proves **H1**, showing that at least some messages do not require complex functions to be composed, or contextual information to be interpreted. As the accuracy for these messages reaches over 90% on average, we argue that the NPMI method has captured almost all the information transmitted using these messages.

As mentioned in **H2**, we examine the impact of the positional components and whether they carry the information the NPMI method has identified. We, therefore, separate the compositional analysis into two parts: Compositional-NP, where the positional components are replaced with \(0\), and Compositional-P, which includes the identified positional components. In the Compositional-NP case, the agents achieve a close to random accuracy, whereas, in the Compositional-P case, agents achieve above random accuracy, with some agent pairs reaching over 75% accuracy. This proves our **H2** correct, showing that the NPMI method has successfully identified the positional information contained in the messages, together with the integer information.

## 6 Discussion

Having successfully verified both **H1** and **H2**, we confirmed the validity of the language analysis.We also verify the generalisation ability of the agents, by evaluating varying training and evaluation sequence lengths, vocabulary sizes, and hidden size in Appendix C.

To provide human interpretability of the emergent language, we use the NPMI method to create a dictionary providing an understanding of both the positional and compositional messages. We present an excerpt from an example dictionary in Table 3. With human interpretability, we can gain a deeper understanding of the principles underlying the agents' communication protocol.

We posit that the emergence of compositional spatial references points to a first emergence of a simple syntactic structure in an emergent language. Both of the \(n\)-grams in our example from Section 5.2, also shown in Table 3, are assigned specific positions in the message by the agents. The unigram \(7\) must always be in the first position of the message, while the bigram \(\) must always be in the second position. The emergence of this structure shows that even though referential games have been considered obsolete in recent research (Chaabouni et al., 2022; Rita et al., 2024), a careful design of the environment may yet elicit more of the fundamental properties of natural language.

We hypothesise that the emergence of non-compositional spatial references tailored to specific observations, such as _begin+1_, is due to observation sparsity. Compositionality would bring no benefit since the observations which they describe are usually rare, representing 1-2% of the dataset and are monolithic, _i.e_., _begin_, _begin_, _begin+1_, _begin+1_, _end-1_, and _end_. We therefore argue that the emergence of non-compositional references in these cases is **advantageous**, since these messages are easily compressible. Since these messages are monolithic, they could be compressed to a single token/character in

  
**Dict Type** & \(t_{n}\) & \(t_{c}\) & **Average Accuracy** & **Maximum Accuracy** \\  Non-Compositional Positional & \(1\) & \(0.9\) & 90\% \(\)3\% & **94\%** \\ Non-Compositional Integer & \(1\) & \(0.5\) & 36\% \(\)0.4\% & 37\% \\ Compositional-NP & \(1\) & \(0.5\) & 22\% \(\) 2\% & 28\% \\ Compositional-P & \(1\) & \(0.5\)3 & 30\% \(\) 21\% & 78\% \\   

Table 2: Accuracy improvements using the NPMI-based dictionary, \(\) denotes the 1-sigma standard deviation. Non-Compositional Positional refers to messages such as _begin_ or _end_, Non-Compositional Integer refers to the non-compositional monolithic messages describing both the position and the integer, Compositional-NP refers to messages only containing the identified integer components, and the Compositional-P which refers to messages containing both the identified integer and positional components.

simple encoding schemes. In contrast, compositional messages require at least two tokens/characters, one for each integer/positional component. With a linguistic parsimony pressure (Chaabouni et al., 2019; Rita et al., 2020) applied, these messages could be more efficient at transmitting the information contained within these observations than compositional ones.

## 7 Limitations

The accuracy for the Non-Compositional Integer, and Compositional-P messages averages about 33%. While still above random, showing that some meaning is captured in non-compositional messages, it points to there being more to be understood about these messages. We hypothesise this may be due to the higher degree of message pragmatism, or context dependence (Nikolaus, 2023). Our method of message generation, using randomly selected parts, may not be able to capture the complexity of the messages. For example, the context in which they are used might be crucial for some \(n\)-grams, requiring the use of a specific n-gram instead of another when referring to certain integers, or when specific integers are present in the observation. Just like in English, certain verbs are only used with certain nouns, such as "pilot a plane" vs "pilot a car". While the word "pilot" in the broad sense refers to operating a vehicle, it is not used with cars specifically. This may also be the case for the emergent language. For compositional messages, an additional issue may be that some messages are non-trivially compositional, using functions apart from simple concatenation to convey compositional meaning (Perkins, 2021), making them impossible to analyse with the NPMI measure. However, these issues may be addressed by scaling the emergent communication experiments as the languages become more general with the increased complexity of their environment (Chaabouni et al., 2022).

## 8 Conclusion

Recent work in the field of emergent communication has advocated for better alignment of emergent languages with natural language (Boldt and Mortensen, 2024; Rita et al., 2024), such as through the investigation of deixis (Rita et al., 2024). Aligned to this approach, we provide a first reported emergent language containing _spatial references_(Lyons, 1977), together with a method to interpret the agents' messages in natural language. We show that agents can learn to communicate about spatial relationships with over 90% accuracy. We identify both compositional and non-compositional spatial referencing, showing that the agents use a mixture of both. We hypothesise why the agents choose non-compositional representations of observation types which are sparse in the dataset, arguing that this behaviour can be used to increase communicative efficiency. We show that, using the NPMI language analysis method, we can create a human interpretable dictionary, of the agents' own language. We confirm that our method of language interpretation is accurate, achieving over 94% accuracy for certain dictionaries.

  
**Message** & **Type** & **Meaning** \\  \(\) & Non-Compositional Positional & _begin_ \\ _ \\ \(\) & Non-Compositional Positional & _begin_ \\ _ \\ \(\) & Non-Compositional Positional & _end-1_ \\ \(\) & Non-Compositional Positional & _end_ \\ \(\) & Non-Compositional Integer & 15 is 1 left of target \\ \([15,m_{2},m_{3}]\) & Compositional Positional &? is 2 left of target \\ \([7,m_{2},m_{3}]\) & Compositional Positional &? is 2 right of target \\ \([m_{1},0,17]\) & Compositional Integer & Integer 1 \\ \([m_{1},0,2]\) & Compositional Integer & Integer 18 \\ \([m_{1},8,14]\) & Compositional Integer & Integer 30 \\   

Table 3: Example dictionary of the agents’ messages and their meanings