# Learning 3D Equivariant Implicit Function with Patch-Level Pose-Invariant Representation

Xin Hu1, Xiaole Tang1, Ruixuan Yu2, Jian Sun()1,3

1Xi'an Jiaotong University, Xi'an, China

2Shandong University, Weihai, China

3Pazhou Laboratory (Huangpu), Guangzhou, China

{huxin7020,tangxl}@stu.xjtu.edu.cn,

yuruixuan@sdu.edu.cn, jiansun@xjtu.edu.cn

###### Abstract

Implicit neural representation gains popularity in modeling the continuous 3D surface for 3D representation and reconstruction. In this work, we are motivated by the fact that the local 3D patches repeatedly appear on 3D shapes/surfaces if the factor of poses is removed. Based on this observation, we propose the 3D patch-level equivariant implicit function (PEIF) based on the 3D patch-level pose-invariant representation, allowing us to reconstruct 3D surfaces by estimating equivariant displacement vector fields for query points. Specifically, our model is based on the pose-normalized query/patch pairs and enhanced by the proposed intrinsic patch geometry representation, modeling the intrinsic 3D patch geometry feature by learnable multi-head memory banks. Extensive experiments show that our model achieves state-of-the-art performance on multiple surface reconstruction datasets, and also exhibits better generalization to cross-dataset shapes and robustness to arbitrary rotations. Our code will be available at https://github.com/mathXin112/PEIF.git.

## 1 Introduction

Surface reconstruction aims at generating continuous surfaces from discrete point clouds. It is a fundamental and challenging task in current robotics and vision applications . Recently, deep learning-based implicit neural representations (INRs) have emerged as a powerful tool for this task, such as signed distance fields (SDFs) , unsigned distance fields (UDFs) , and neural vector fields (NVF) . INRs benefit from its continuity, and the ability to handle complicated topology, showing promising performance on surface reconstruction.

Although current INRs-based methods have achieved promising performance in reconstructing surfaces, they suffer from two main challenges. First, most methods  deal with the distinct local regions as geometry elements to estimate the query point values, e.g., signed/unsigned distance. However, different local regions may exhibit different poses but with similar intrinsic geometry. The extrinsic poses of these 3D patches prevent the models from capturing the intrinsic geometry of 3D shape patches. Second, INRs  without considering equivalence commonly learn the representation of the points using a fixed coordinate frame, implying that if the input points are rotated, the original coordinate mapping may no longer accurately predict the desired output, leading to distortions or inaccuracies. These properties of INRs hinder their applicability to complex 3D scenarios, in particular with regard to their cross-domain generalization ability and robustness to arbitrary transformations like rotations.

To tackle these challenges, we try to eliminate the redundant factor of poses and more focus on the learning of the intrinsic geometric representation of local regions, yielding a patch-level poseinvariant representation (PPIR) of 3D objects. Based on this representation, we develop a patch-level equivariant implicit function (PEIF), allowing us to achieve the equivariance patch-wisely while effectively encoding arbitrary topology. Specifically, in the PEIF framework, the query/patch pairs are first normalized via a unique pose normalization. Then the query/patch features are extracted and processed via learnable multi-head memory banks to acquire the intrinsic patch geometry representation, which is aggregated with the spatial relation representation, resulting in the patch-level pose-invariant representation. PPIR is then utilized for displacement prediction, which can be proven to be equivariant for \(SE(3)\) transformations. These designs enhance the expressive power of INRs with PPIR and enable the PEIF to flexibly adapt to 3D domain gaps as well as arbitrary \(SE(3)\) transformations.

Our contributions can be summarized as follows. _First_, we propose a patch-based equivariant implicit function based on the pose-invariant feature learning, facilitating 3D reconstruction robust to 3D shapes \(SE(3)\) transformations. _Second_, we design an intrinsic patch geometry representation module encoding rich patch-level pose-invariant features leveraging similar geometric patches. _Third_, the effectiveness of PEIF for surface reconstruction is demonstrated on four datasets including two CAD object datasets, a synthetic scene-level dataset, and a real scan dataset. Experiments show that our method outperforms baseline methods and can effectively reconstruct fine geometric structures, particularly performing well in cross-dataset generalization and the robustness to arbitrary rotations.

## 2 Related Work

### Implicit Representation for 3D Shape Reconstruction

Deep learning-based implicit representations have achieved significant advancements, due to their continuity and ability to handle complex geometry structures. Implicit representation for 3D surface reconstruction commonly learns to assign specific values for query points in 3D space. For example, occupancy field (occ) based methods [13; 14; 15; 16; 17; 18] enable the 3D reconstruction as a binary classification problem. The Occupancy Network  introduces predictions of spatial point occupancy, while advancements like ConvONet  and POCO  integrate grid-oriented convolutional or transformer frameworks to enhance performance. Recently, ALTO  iteratively refines features from both points and grids, deploying attention-driven interpolation from adjacent grids to decode occupancy values for query points. GridFormer  introduces transformer architecture to integrate the advantages of both points and grids for the prediction of occupancy.

SDF/UDF provides a continuous value to each spatial point, indicating the corresponding signed or unsigned distance to the surface. UDF with unsigned distance overcomes the limitations of SDF in handling non-watertight geometries. DeepSDF  leverages Multi-Layer Perceptron (MLP) to globally model SDF for entire 3D shape, while DeepLS , Instant-NGP  and NKSR  design more detailed operations to predict the SDF / UDF locally or hierarchically with MLP, kernel function or transformers, etc. GIFS  represents general shapes with multi-layer surfaces based on the spatial relationship between points. CAP-UDF  employs a field consistency constraint to get consistency-aware UDF. GeoUDF  adaptively approximates the UDF and its gradient of a point cloud by leveraging local geometry in a decoupled manner. However, separate learning of UDF values and gradients for points may result in accurate UDF but with the inverted direction problem. To address this issue, NVF  proposes an explicit approach to learning implicit representations based on displacement vectors, which ensures both accuracy and correct directional information. In this paper, we adopt this representation, predicting a displacement vector for each point in 3D space. Compared to NVF , we design our PEIF over the pose-normalized 3D patches and obtain the \(SE(3)\)-equivariant implicit function.

### \(Se(3)\)-Equivariant Network

\(SE(3)\)-equivariance has been extensively studied in both 2D images  and 3D point clouds [24; 25; 26; 27; 28]. Given 3D point cloud \(X\) and transformation \( SE(3)\), a model \(f\) is said to be \(SE(3)\)-equivariant when it satisfies \(f(X)= f(X)\). Various works have been proposed to achieve \(SE(3)\)-equivariance based on PCA [29; 30; 25], spherical harmonics [31; 32; 33], equivariant message passing [34; 35; 36], or Vector Neuron [26; 27; 28]. \(SE(3)\)-equivariant networks are particularly useful for 3D point analysis tasks, such as molecular property or trajectory modeling [34; 35; 36; 37], protein structure prediction [38; 39; 40], 3D shape recognition [26; 27; 28], and robotics [41; 42; 43].

Introducing \(SE(3)\)-equivariance to build an orientation-robust implicit field is one of the motivations of this work. There are few works involving equivariance in the implicit field. EFEM  uses Vector Neuron  to learn equivariant shape representations before shape segmentation. E-GraphONet  utilizes basic Vector Neuron  layers to design graph networks, achieving locally \(SO(3)\)-invariant features for implicit function learning. E-GraphONet  is the most related work to ours, which extends neurons from 1D scalars to 3D vectors for each point. In comparison, our PEIF employs lightweight PCA to achieve pose-invariant patch-level representation and leverages a multi-head memory bank for intrinsic geometry representation, achieving state-of-the-art 3D reconstruction performance.

## 3 Problem Statement for Equivariant Neural Vector Field

In this section, we first introduce the implicit representation, namely the neural vector fields (NVF) , and then introduce the equivariant implicit function of this representation.

Given a sparse point cloud \(X^{N_{x} 3}\) sampled on a shape \(\), and a query set \(Q^{N_{q} 3}\) sampled near the surface of \(\), where \(N_{x}\) and \(N_{q}\) represent the number of input points and query points respectively. A shape \(\) is defined as the zero displacement of the implicit function \(\)

\[=\{x^{3}|(x)=.\},\] (1)

where \(x\) is a point in point cloud \(X\), containing its spatial coordinate. \(\) represents the zero displacement of the point \(x\). For a query point \(q^{3}\), the implicit function \(\) is formulated by

\[(q)= q=-q,=_{x }\|x-q\|,\] (2)

and \(\) is the nearest point of query \(q\) on the \(\).

**Definition 1**: (Equivariant Implicit Function). _Given an abstract group \(G\), the implicit function \(\) based on NVF is equivariant with regard to \(G\), if_

\[( q)=((q))= q,  G,\] (3)

where \(q\) is a query point near or on the surface of shape \(\). In this work, the group \(G\) is \(SE(3)\).

## 4 Equivariant Neural Implicit Function

In this work, we aim to develop an equivariant implicit function model grounded on neural vector field representations. We achieve this goal by firstly learning patch-level pose-invariant representation (PPIR), and then designing shape-level equivariant implicit representation. The overview of our method is introduced in Section 4.1, with the detailed designs presented in Sections 4.2 and 4.3.

### Overview of the Basic Idea

Given point cloud \(X\), implicit representations conventionally involve sampling a set of query points \(Q\) and employing an implicit function \(\) to compute their associated implicit values. Typically, the

Figure 1: Local 3D patches may exhibit geometric similarity, but with different poses. When the pose is removed, these local regions appear repeatedly.

depiction of a query point \(q Q\) depends on its K-nearest neighbors (KNN) in \(X\). As shown in Figure 1, it is observed that some local KNN patches exhibit identical geometric structures if ignoring their pose variations in \(SE(3)\), and the local patches across 3D objects also repeatedly appear. Based on this observation, we design an equivariant implicit function based on patch-level pose-invariant representation, capturing recurring geometric patterns invariant to pose transformation.

Before delving into the specific details of our approach, we present the overall framework as shown in Figure 2. Given query set \(Q=\{q_{i}\}\), the corresponding patch for \(q_{i}\) on point cloud \(X\) is \(P_{i}=\{p_{i,k}\}_{k=0}^{K}\), _i.e._, the KNN of \(q_{i}\) based on Euclidean distance. The point patch \(P_{i}\) and query point \(q_{i}\) are firstly normalized by patch-based pose normalization \(_{i}\), achieving invariant ones under \(SE(3)\) transformation of patch \(P_{i}\). We then feed \(\{_{i}(P_{i}),_{i}(q_{i})\}\) to the displacement predictor \(D\) for \(SE(3)\)-invariant representation learning and displacement prediction. Finally, this predicted displacement is transformed back to the pose of \(P_{i}\) with \(_{i}^{-1}\). The overall displacement prediction can be written as

\[ q_{i}=(q_{i})=_{i}^{-1} D\{_{i}(P_{i}), _{i}(q_{i})\}.\] (4)

This framework is \(SE(3)\)-equivariant for patch \(P_{i}\) and point cloud \(X\). The detailed design of the patch-based pose-normalization \(\) and displacement predictor \(D\) are presented in the following Sections 4.2 and 4.3 respectively. We remove index \(i\) for brevity and denote the query point, point patch, and pose-normalization as \(q^{3}\), \(P^{K 3}\) and \(\) respectively in the following paragraphs.

### Pose Normalization

Geometrically identical patches are expected to maintain consistency across various pose transformations, enabling their representations to complement and reinforce each other. Accordingly, we employ Principal Component Analysis (PCA) to extract the pose-invariant information for patch \(P\).

We first decenter the patch \(P\) by subtracting the points center \(\), then obtain the rotation matrix \(U\) by computing the Singular Value Decomposition (SVD)  over the covariance matrix \((P-)^{}(P-)\). The pose-normalized patch \(\) and query point \(\) are derived as

\[(P)=(P-)U,(q)=(q-)U.\] (5)

The pose-normalized patch \(\) and query point \(\) are invariant under \(SE(3)\) transformation of \(P\), and we take them as input to our displacement predictor \(D\). The prediction \(D\{(P),(q)\}\) is also invariant as proven in following Lemma 1. Note that we uniquely determine \(U\) as  to solve the direction uncertainty problem brought by PCA.

**Lemma 1**: _With \(\) as our pose normalization, and \(D\) as displacement predictor, \(D\{(P),(q)\}\) is invariant under \(SE(3)\) transformation of \(P\)._

Figure 2: Overview of the proposed PEIF. Given query points, the local patches are selected using KNN. The query/patch pairs are normalized by pose transformations \(\). The displacements of query points to the surface are predicted by displacement predictor \(D\). The implicit function is equivariant under the \(SE(3)\) transformations of the input. Finally, the mesh is generated by marching cubes  algorithm.

Please refer to the Appendix for proof. The displacement predictor will be introduced as follows.

### Displacement Predictor Design on Normalized Patches

Taking the pose-normalized patch \(\) and query \(\) as input, the displacement predictor \(D\) is designed to predict the displacement \(\). As shown in Figure 2, predictor \(D\) comprises a pose-invariant feature extractor \(\) and a MLP \(_{_{s}}\). Specifically, the feature extractor \(\) is composed of three modules: the Spatial Relation Module (SRM) for query point feature learning, which models the spatial relative relationship between \(\) and \(\); the Patch Feature Extraction Module (PFEM) for patch feature learning, which extracts patch feature leveraging correlation in feature space; the Intrinsic Patch Geometry Extractor (IPGE), which learns memory-augmented patch representation.

**Spatial Relation Module.** We design SRM to learn query point features based on spatial relation within query \(\) and patch \(=\{_{i}\}_{i=1}^{K}\). Specifically, the point-wise representation \(z_{i}\) of point \(_{i} P\) is firstly computed as

\[z_{i}=_{_{s}}(_{i},_{i}-), i=1,2,,K,\] (6)

\(_{_{s}}()\) is set as MLP. Taking query point position and relative offset as inputs, \(z_{i}\) is expected to directly capture the geometric patterns. Then we aggregate \(z_{i}\) with simple concatenation operator \(\) by

\[h_{}=z_{1} z_{K}.\] (7)

Feature \(h_{}^{K D}\) contains the relative feature of query point \(\) to the patch \(\). We take it as a representation for the query point \(\).

**Patch Feature Extraction Module.** We further design PFEM to learn the patch feature for \(\). Taking the point positions of \(\) and \(=\{_{i}\}_{i=1}^{K}\) as inputs, we first lift them from Euclidean space to feature space via two MLPs \(_{_{p}}()\) and \(_{_{q}}()\) as

\[f_{}=_{_{q}}(), f_{_{i}}=_{ _{p}}(_{i}), i=1,2,,K,\] (8)

where \(f_{},f_{_{i}}^{1 D}\) are the learned point-wise features. Then, a transformer is designed to obtain the patch feature, by encoding the feature attention between point \(_{i}\) and query point \(\) as

\[f_{_{}}_{i=1}^{K}a_{i}(f_{_{i}}W_{V}), \{a_{i}\}_{i=1}^{K}=(\{(f_{}W_{Q})(f_{ _{i}}W_{O})^{}\}),\] (9)

where \(a_{i}\) represents the attention score between query point \(\) and patch points \(_{i}\). The matrices \(W_{Q},W_{O},W_{V}^{D D}\) are learnable parameters. Patch feature \(f_{_{}}\) is aggregated from all the points features in patch \(P\), while different patches may have diverse point distributions. To mitigate the effects of point density in patches, we further design the importance-aware patch feature \(f_{_{}}\) by selecting the top-\(K_{d}\) important points, and aggregating their features as

\[f_{_{s}}_{i=1}^{K_{d}}b_{i}f_{_{i}},\] (10)

where \(\{b_{i}\}_{i=1}^{K_{d}}\) is the selected top-\(K_{d}\) attention scores from \(\{a_{i}\}_{i=1}^{K}\). The final patch feature \(f_{}\) from this PFEM is

\[f_{}=_{1}f_{_{w}}+_{2}f_{_{s}},\] (11)

where \(_{1},_{2}\) are learnable combination coefficients.

**Intrinsic Patch Geometry Extractor.** As discussed in Section 4.1, the normalized point patches can be grouped into different geometric patterns across patches or shapes. To learn the intrinsic features hidden behind those geometric patterns, we propose IPGE to enhance the patch features. Specifically, a learnable multi-head memory bank \(=\{_{i}\}_{i=1}^{N_{M}}\) is constructed, and it is shared across the whole dataset to implicitly model the patch patterns. Then the patch feature \(f_{}\) is enhanced by querying and aggregating each memory item as

\[g_{}=_{i=1}^{N_{M}}w_{i}_{i}, w_{i}=(f_{}_{i}^{}).\] (12)The memory weight \(w_{i}\) is defined as softmax-normalized similarity vectors between query feature \(f_{}\) and the entries of \(_{i}^{C D}\). Figure 3 illustrates the procedures of this module.

**Displacement Prediction.** Based on query point features \(\{h_{},f_{}\}\), point-wise patch feature \(\{f_{_{i}}\}_{i=1}^{K}\), enhanced patch feature \(g_{}\), the patch-level pose-invariant (PPIR) representation is achieved by

\[f_{PPIR}=_{_{a}}(h_{} f_{} \{f_{_{i}}\}) g_{}.\] (13)

Then the displacement for query point \(\) can then be derived by

\[=_{_{d}}(f_{PPIR}).\] (14)

Both \(_{_{d}}\) and \(_{_{a}}\) are set as MLPs. Finally, \(\) is transformed back with pose denormalization, _i.e._, the inverse transformation of \(\), achieving the final \(SE(3)\)-equivariant displacement estimation \( q=^{-1}()\). The \(SE(3)\)-invariance of \(f_{PPIR}\) can be found in Lemma 1, and the \(SE(3)\)-equivariance of learned implicit representation can be found in the following Theorem 1, please refer to Appendix for proof.

**Theorem 1**: _Given query point \(q\) and patch \(P\), implicit function \((q)\) is \(SE(3)\)-equivariant._

### Network Training and Inference

Sections 4.2 and 4.3 illustrate how to obtain the displacement for a query point, where the trained parameters include the parameters \(_{s},_{p},_{q},_{a}\), \(_{d}\) of five MLPs, the multi-head memory bank \(\) and parameters \(_{1}\), \(_{2}\). To optimize the implicit function \(\), we design a joint loss function over the query set \(Q\) to train our method in an end-to-end manner.

**Displacement Optimization Loss.** We compute \(L_{1}\)-loss between the predicted displacement \( q_{i}\) for each query point \(q_{i} Q\) and its ground-truth displacement \(_{i}\) as

\[_{d}=}_{i=1}^{N_{q}}| q_{i}- _{i}|.\] (15)

**Patch Discrimination Loss.** The items in memory should be apart from each other to enhance the representativeness of the memory items. To ensure this, we design the patch discrimination loss as

\[_{m}=_{i=1}^{N_{M}}_{m m^{{}^{}}} ^{N_{M_{i}}}_{i}[m],_{i}[m^{{}^{ }}],0)}{N_{M_{i}}(N_{M_{i}}-1)},\] (16)

which is similar to cosine embedding loss  with a margin set to 0. \(N_{M_{i}}\) is the number of the items in memory bank \(_{i}\). The overall loss function is finally written as \(=_{d}+_{m}\), where \(\) is a hyper-parameter for balancing the two terms.

**3D Reconstruction in Inference Stage.** We employ the Marching Cubes (MC) algorithm proposed by MeshUDF , which can reconstruct surfaces on UDFs. We first discretize the 3D volume into a 3D grid with a resolution of \(N_{R}\), resulting in \(N_{R}^{3}\) grid points as the query set \(Q\). Then, we use the implicit function \(\) to predict the displacement \( q\) of each query point \(q\). Similar to , we get the UDF value and gradient of \(q\) as \(d=\| q\|_{2}\) and \(_{q}=}\). Based on \(d\) and \(_{q}\), the MC in MeshUDF  can reconstruct the surface of the input point cloud as mesh.

## 5 Experiments

**Implementation Details.** We implement our PEIF in Pytorch  using Adam optimizer . The learning rate is \(8 10^{-4}\). For each query point, the size of the neighborhood is set as \(K=32\) for ShapeNet  and ABC  datasets, \(K=54\) for Synthetic Rooms  dataset. We set \(=0.1\) in the training loss and \(N_{m}=4\) for the memory bank. Please refer to the Appendix for details on the structures of involved MLPs, and the effect of different values of \(\). We conducted all experiments on one NVIDIA RTX 4090 GPU.

**Datasets.** We experiment on four datasets including ShapeNet , ABC , Synthetic Rooms , MGN . (1) _ShapeNet_, as pre-processed by , contains watertight meshes of shapes in 13 classes. Following the experimental setting in , we select _cars, chairs, planes, and tables_ as base classes in Table 1, and _speakers, bench, lamps, and watercraft_ as novel classes in Table 1 for category-unseen reconstruction, only for testing. (2) _ABC_ has one million CAD models, mainly mechanical objects. We use the splits from  and select watertight meshes for experiments: 3599/883/98 shapes for training/validation/testing. (3) _Synthetic Rooms_ contains 5k synthetic room scenes composed of random walls, floors, and ShapeNet objects. We adopt the same train/validation/test division in . (4) _MGN_ is a real scanned dataset containing 5 clothing categories. To generate watertight surfaces, we employ the method  for preprocessing. Specifically, we sample 3k points on the surface as input points for ShapeNet and ABC datasets, while 10k input points for Synthetic Rooms. Then 2048 query points are sampled near the surface for ShapeNet, ABC, and Synthetic Rooms. All experiments are tested on 10k points.

**Evaluation Metrics.** We use the Chamfer-L1 distance (CD, \( 10^{-2}\)), Earth Mover Distance (EMD, \( 10^{-2}\)), Normal Consistency (NC), and F-Score (with threshold value 1%) metrics for our evaluation.

**Baselines.** To evaluate the effectiveness of our methods, baselines used for comparison include the equivariant network E-GraphONet , and six non-equivariant networks, including POCO , GIFS , ALTO , NVF , GeoUDF , GridFormer. For fairness, we trained these networks from scratch under the same training/validation/testing dataset splitting.

### Results and Comparisons

**3D Object Datasets Reconstruction.** We first report the results of the 3D object reconstruction on the object datasets: ShapeNet  and ABC . The quantitative results on base and novel classes of ShapeNet  are shown in Table 1, our PEIF achieves better results both in base and novel classes, especially in terms of the CD and F-Score metrics. Qualitative comparisons are provided in Figure 4. Compared with other competitors, our method can capture fine-grained details, and the

    &  &  \\   & CD \(\) & EMD \(\) & NC \(\) & F-Score \(\) & CD \(\) & EMD \(\) & NC \(\) & F-Score \(\) \\  POCO  & 0.395 & 3.937 & 0.929 & 0.970 & 0.520 & 4.941 & 0.906 & 0.954 \\ GIFS  & 0.385 & 3.859 & 0.932 & 0.962 & 0.422 & 4.923 & 0.917 & 0.942 \\ ALTO  & 0.352 & 3.851 & 0.930 & 0.963 & 0.357 & 4.924 & 0.920 & 0.929 \\ NVF  & 0.255 & 3.766 & 0.938 & 0.983 & 0.266 & **4.721** & 0.921 & 0.982 \\ GeoUDF  & 0.225 & 3.761 & **0.957** & 0.997 & 0.219 & 4.735 & 0.934 & **0.997** \\ GridFormer  & 0.284 & 3.768 & 0.942 & 0.984 & 0.289 & 4.725 & 0.928 & 0.985 \\  GraphONet  & 0.389 & 3.868 & 0.921 & 0.932 & 0.461 & 4.733 & 0.917 & 0.952 \\ E-GraphONet  & 0.479 & 3.834 & 0.917 & 0.927 & 0.508 & 4.743 & 0.911 & 0.942 \\ PEIF(Ours) & **0.215** & **3.755** & 0.956 & **0.998** & **0.209** & 4.725 & **0.941** & **0.997** \\   

Table 1: The reconstruction results of ShapeNet . All models are trained on the base classes and evaluated on both the base classes and novel classes. Note that E-GraphONet is the equivariant version of GraphONet.

Figure 4: The qualitative results of ShapeNet  dataset. The object is selected from meshes used for class-unseen reconstruction (novel classes in Table 1).

overall topology of the shape is more consistent. Additional instances are provided in the Appendix (Figure 8). We further evaluate the compared methods on the ABC  dataset. The quantitative results in Table 2 demonstrate that our PEIF achieves competitive performance compared to both equivariant and non-equivariant methods. Visualizations are provided in Figure 9 of the Appendix.

**3D Scene Datasets Reconstruction.** Table 2 shows the quantitative results on the Synthetic Rooms dataset. Our PEIF shows state-of-the-art performance under all quantitative metrics. The competitive competitors such as GridFormer  and POCO  produce smooth but incomplete surfaces. Other methods like GeoUDF  and NVF  produce results with rough surfaces. In contrast, our method reconstructs relatively smooth surfaces with fewer issues of completeness and consistency. Visualizations are provided in Figure 10 of the Appendix.

**Cross-domain Evaluation on Real-world Dataset.** We test and compare our method with the state-of-the-art methods NVF, GoeUDF, and GridFormer on MGN  dataset using the trained models on Synthetic Rooms . Table 3 shows that the compared methods generally exhibit a declined performance in the presence of a synthetic-real domain gap. However, in the presence of such a domain gap, our PEIF still achieves notable performance under all metrics. Figure 5 displays the visual comparison. The competitors either produce a rough surface or suffer from shape incompleteness. As a comparison, our PEIF reconstructs a complete surface with fine-grained details. These results show that our PEIF trained on the synthetic data can be well generalized to real scenarios. The reason might be that the pose-normalized patches are the basic elements for composing different shapes, and our PEIF is based on the pose-invariant patch representations.

    & Methods & CD \(\) & EMD \(\) & NC \(\) & F-Score \(\) \\   & NVF  & 0.245 & 2.685 & 0.963 & 0.997 \\  & GeoUDF  & 0.245 & 2.688 & 0.964 & 0.997 \\ rotations & E-GraphONet  & 0.432 & 2.688 & 0.910 & 0.906 \\  & PEIF (Ours) & 0.241 & 2.672 & 0.969 & 0.998 \\   & NVF  & 0.261 & 2.699 & 0.946 & 0.993 \\ w/ & GeoUDF  & 0.253 & 2.698 & 0.957 & 0.994 \\ rotations & E-GraphONet  & 0.433 & 2.689 & 0.912 & 0.909 \\  & PEIF (Ours) & 0.241 & 2.675 & 0.968 & 0.998 \\   

Table 4: Performance under Arbitrary \(SO(3)\) rotations.

    &  &  \\   & CD \(\) & EMD \(\) & NC \(\) & F-Score \(\) & CD \(\) & EMD \(\) & NC \(\) & F-Score \(\) \\  POCO  & 0.475 & 2.785 & 0.957 & 0.941 & 0.512 & 2.624 & 0.896 & 0.973 \\ GIFS  & 0.339 & 2.765 & 0.950 & 0.985 & 0.425 & 2.658 & 0.913 & 0.984 \\ ALTO  & 0.451 & 2.739 & 0.943 & 0.958 & 0.492 & 2.426 & 0.901 & 0.975 \\ NVF  & 0.245 & 2.685 & 0.963 & 0.996 & 0.504 & 2.052 & **0.925** & 0.979 \\ GeoUDF  & 0.245 & 2.688 & 0.964 & 0.997 & 0.383 & 2.182 & 0.921 & 0.988 \\ GridFormer  & 0.299 & **2.662** & 0.964 & 0.981 & 0.465 & 2.252 & 0.913 & 0.978 \\  E-GraphONet  & 0.432 & 2.688 & 0.910 & 0.906 & 0.485 & 2.534 & 0.903 & 0.980 \\ PEIF (Ours) & **0.241** & 2.672 & **0.969** & **0.998** & **0.314** & **2.045** & **0.925** & **0.994** \\   

Table 2: Comparison of different methods on ABC  and Synthetic Rooms  datasets.

Figure 5: The visual example of cross-domain evaluation on the real scanned dataset MGN , where the model is pre-trained on Synthetic Rooms dataset .

    & Methods & CD \(\) & EMD \(\) & NC \(\) & F-Score \(\) \\   & NVF  & 0.272 & 4.329 & 0.847 & 0.991 \\ GeoUDF  & 0.249 & 4.269 & 0.891 & 0.995 \\ GridFormer  & 0.281 & 4.675 & 0.916 & 0.969 \\ E-GraphONet  & 0.433 & 3.817 & 0.863 & 0.920 \\ PEIF (Ours) & **0.241** & **2.672** & **0.969** & **0.998** \\   

Table 3: The cross-domain evaluation on MNG dataset .

**Robustness to rotations.** We compare the robustness of two equivariant networks (PEIF and E-GraphONet), and two non-equivariant networks (NVF and GeoUDF) to arbitrary rotations. All methods are trained with canonical pose and tested with arbitrary rotations on the ABC  dataset. The quantitative and qualitative results are reported in Table 4 and Figure 5, respectively. In Table 4, "w/ rotation" and "w/o rotation" represent that the testing input point cloud is with and without arbitrary rotation, respectively. The visual results presented in Figure 5 illustrate that our PEIF can retain stable performance under arbitrary rotations, which is consistent with the numerical results presented in Table 4. These results justify the robustness of our PEIF to arbitrary rotations.

### Ablation Study and Model Analysis

We conduct ablation studies and present the model size and inference time on the ABC  dataset.

**Effect of Pose Normalization.** As shown in the 2nd row in Table 5, after removing the patch-level pose normalization, all metrics decline. Particularly, the NC metric is notably affected.

**Effect of the Multi-head Memory Bank.** As demonstrated in Table 5, the performance of our PEIF deteriorates significantly when the multi-head memory bank, _i.e_., the intrinsic patch geometry extractor, is removed. The model performs better with \(N_{M}\) increase from 1 to 4. When \(N_{M}=5\), the performance of the model starts to deteriorate.

**Number of Neighbour Points \(K\).** The size of KNN determines the number of points in each patch. We report the performance of our PEIF with different patch sizes in Table 5. The results show that our method is relatively stable to the size of KNN.

**Model Size and Computational Time.** We compare model size and inference time on the ABC  dataset. In Table 6, our network is comparable to other methods in the number of parameters. The computation time of our approach for 3D reconstruction of one point cloud is lower than the state-of-the-art models NVF, and GeoUDF, but higher than GrridFormer and E-GraphONet. However, our method achieves the best accuracy for 3D reconstruction as shown in experiments.

## 6 Conclusion

In this work, we propose a patch-level equivariant implicit function, based on the patch-level pose invariant feature representation over the pose-normalized query points and corresponding neighboring patches. The proposed representation achieves promising results in 3D reconstruction both quantitatively and qualitatively, and generates shapes with better geometry details and robustness to \(SE(3)\) transforms. Due to the flexibility of the patch-based representation, in the future, we plan to extend this approach to larger-scale 3D reconstruction of real scans. Additionally, our patch-based pose invariant representation can be taken as a foundation network for pre-training, followed by fine-tuning on few-shot examples.

Limitation.As an implicit network, one limitation is that PEIF relies on the query points and estimating the displacement point-wisely. For scaling up to a larger scale, we plan to utilize a multi-scale technique and importance sampling of query points for efficient displacement field estimation.

   Method & \# Para (M) & Time (s) \\  POCO  & 12.19 & 45.10 \\ GIFS  & 3.51 & 16.68 \\ ALTO  & 2.64 & 20.78 \\ NVF  & 10.29 & 73.90 \\ GeoUDF  & 0.74 & 124.73 \\ GridFormer  & 4.11 & 13.32 \\ GraphONet  & 0.06 & 1.72 \\ E-GraphONet  & 0.07 & 1.92 \\ Ours & 7.65 & 40.98 \\   

Table 6: Model size and inference time.

    & Setting & CD \(\) & EMD \(\) & NC \(\) & F-Score \(\) \\  Pose normalization & w/o & 0.261 & 2.677 & 0.933 & 0.993 \\   & \(N_{M}\) = 0.275 & 2.713 & 0.957 & 0.985 \\  & \(N_{M}\) = 1 & 0.244 & 2.705 & 0.962 & 0.997 \\  & \(N_{M}\) = 2 & 0.244 & 2.696 & 0.962 & 0.997 \\  & \(N_{M}\) = 3 & 0.243 & 2.694 & 0.964 & 0.998 \\  & \(N_{M}\) = 5 & 0.244 & 2.691 & 0.961 & 0.997 \\   & \(K=54\) & 0.245 & 2.692 & 0.962 & 0.996 \\  & \(K=20\) & 0.249 & 2.691 & 0.957 & 0.996 \\   &  &  &  &  \\ (\(N_{M}=4\), and \(K=32\)) & & & & & \\   

Table 5: Ablation study on ABC  dataset.

Impact Statement.This work aims to advance the field of equivariant deep learning with applications in 3D surface reconstruction. It may be valuable to the research of equivariant implicit neural representation and geometric modeling of 3D shapes and has no ethical concerns as far as we know.