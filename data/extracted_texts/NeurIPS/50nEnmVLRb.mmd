# Gaussian Process Bandits for Top-k Recommendations

Mohit Yadav

University of Massachusetts Amherst

ymohit@cs.umass.edu &Daniel Sheldon

University of Massachusetts Amherst

sheldon@cs.umass.edu &Cameron Musco

University of Massachusetts Amherst

cmusco@cs.umass.edu

###### Abstract

Algorithms that utilize bandit feedback to optimize top-k recommendations are vital for online marketplaces, search engines, and content platforms. However, the combinatorial nature of this problem poses a significant challenge, as the possible number of ordered top-k recommendations from \(n\) items grows exponentially with \(k\). As a result, previous work often relies on restrictive assumptions about the reward or bandit feedback models, such as assuming that the feedback discloses rewards for each recommended item rather than a single scalar feedback for the entire set of top-k recommendations. We introduce a novel contextual bandit algorithm for top-k recommendations, leveraging a Gaussian process with a Kendall kernel to model the reward function. Our algorithm requires only scalar feedback from the top-k recommendations and does not impose restrictive assumptions on the reward structure. Theoretical analysis confirms that the proposed algorithm achieves sub-linear regret in relation to the number of rounds and arms. Additionally, empirical results using a bandit simulator demonstrate that the proposed algorithm outperforms other baselines across various scenarios.

## 1 Introduction

The top-\(k\) recommendation problem involves providing a ranked list of k items, such as news articles or products, from a pool of \(n\) items . Online algorithms must adapt to dynamic user preferences, making bandit algorithms suitable due to their use of limited feedback . Developing bandit algorithms is challenging due to limited feedback and the need for computational efficiency in real-time recommendation environments. Recent research on user interfaces for recommendations highlights that the overall layout of the recommendation page is crucial for user appeal, as modern UI designs have evolved from simple dropdown lists to complex, visually engaging layouts . Consequently, bandit algorithms must jointly select and display all top-\(k\) items, rather than simply choosing the most relevant \(k\) items and ordering them by decreasing user relevance .

The joint consideration of top-\(k\) items makes the number of arms (possible actions for the bandit algorithm) combinatorially large, i.e., \((n^{k})\). Previous research on bandit algorithms often imposes strict assumptions on feedback models . For instance, _semi-bandit_ feedback provides a scalar reward for each of the top \(k\) items, thus decomposing the combinatorial feedback into item-level feedback. However, this type of feedback is frequently unavailable . Another common feedback model is _cascade_ browsing , which assumes that users examine items in a predetermined order and cease browsing once a desirable item is found, offering item-specific scalar feedback but failing to capture potential non-linear interactions among items . Figure 1 illustrates the limitations of the cascade model in capturing user interactions within modern top-\(k\) recommendation interfaces.

These limitations motivate us to adopt a more general _full-bandit_ feedback setting, where only a single scalar value is provided for the entire top-\(k\) set of recommendations .

Beyond feedback assumptions, the reward structure in bandit algorithms must be decomposable into scalar values for individual items to prevent a combinatorial explosion of arms--something that is not always feasible. For example, modern e-commerce platforms value and track metrics such as diversity and fairness , which cannot be captured by focusing solely on individual items . This necessitates algorithms for full-bandit feedback settings that operate without specific assumptions about the objectives or reward structures .

This work introduces a bandit algorithm that uses Gaussian processes (GPs) to model rewards under full-bandit feedback (i.e., a single scalar value). GPs are selected for their flexibility in accommodating feedback across discrete, continuous, and mixed domains, such as continuous contexts and discrete rankings . Additionally, unlike parametric models that require optimization incorporating accumulated feedback from previous rounds, GP updates are computationally efficient, involving only data updates . Although GP inference may face computational limits, we will develop efficient inference methods tailored to our proposed algorithm. A further challenge in designing GP-based bandit algorithms for top-\(k\) recommendations is constructing expressive positive-definite kernels that capture similarities between top-\(k\) recommendations . This work mitigates these computational and modeling challenges, as illustrated in the following sections.

Broadly speaking, GPs have been previously explored for bandit algorithms [27; 19]. Krause et al.  employed GPs for contextual bandits in continuous domains; we focus on the discrete domain of top-\(k\) recommendations. Vanchinathan et al.  used GPs with a position-based feedback model, and Wang et al.  used GPs with semi-bandit feedback for recommending top-\(k\) items. In contrast, our work does not rely on a specific reward model or feedback assumption, and develops an an efficient GP-based bandit algorithm for top-\(k\) recommendations.

### Contributions

Our primary contribution is the GP-TopK algorithm, a contextual bandit algorithm for recommending top-\(k\) items. This algorithm operates in a full-bandit feedback setting without relying on assumptions on reward, making it broadly applicable compared to prior works. We leverage GPs with variants of the _Kendall_ kernel  to model the reward function and optimize the upper confidence bound (UCB)  acquisition function for selecting the next arm. Additionally, we introduce a novel weighted convolutional Kendall kernel for top-\(k\) recommendations that address pathologies in existing variants of the Kendall kernel when applied to top-\(k\) recommendations.

Our second key contribution is enhancing the scalability of the GP-TopK algorithm for longer time horizons. Initially, the computational cost for top-\(k\) recommendations using the GP-TopK algorithm is \((T^{4})\) for \(T\) rounds. We first reduce this to \((T^{3})\) by leveraging iterative algorithms from numerical linear algebra . Next, we derive sparse feature representations for the novel weighted

   Tasks & _kernel approach_ & _feature approach_ \\  _compute_ & \((})\) & \((c k^{2}})\) \\ _memory_ & \((})\) & \((c k^{2})\) \\ \((K_{X_{t}})\) & \((t^{2})\) & \((c k^{2} t)\) \\ _compute_\(K_{X_{t}}\) & \(((c+k^{2}) t)\) & \((c k^{2})\) \\   

Table 1: Compute and memory analysis for the proposed GP-TopK bandit algorithm. Rows represent different costs: total _compute_ and _memory_ of the GP-TopK algorithm for \(\) rounds, time for matrix-vector multiplication (\(\)) with the kernel matrix \(K_{X_{t}}\) for \(t^{}\) round, and time to update \(K_{X_{t}}\). Columns represent different approaches: the _kernel approach_, which uses full kernel matrices, and our novel _feature approach_, which performs the same operations through feature expansions and scales more efficiently with respect to \(\). The symbols \(c\), \(k\), and \(\) denote the embedding size for contexts, the number of items, and the number of rounds, respectively.

Figure 1: A snapshot from Etsy showcases Fatherâ€™s Day shopping recommendations. The lack of an obvious linear search order challenges the assumptions of the cascade model. Additionally, the proximity and arrangement of items are likely to influence clicks, indicating complex interaction patterns and supporting the need for full-bandit feedback without assumptions about user interactions with recommended items.

convolutional Kendall kernel, further reducing the compute requirements from \((T^{4})\) to \((T^{2})\) and memory requirements from \((T^{2})\) to \((T)\). Table 1 summarizes these improvements in time and memory requirement, including their dependence on other parameters.

We provide a theoretical analysis showing that GP-TopK's regret is sub-linear in \(T\), benefiting from the feature representations of the Kendall kernels introduced in this work. Specifically, we establish an upper bound on regret that is nearly quadratic in \(n\), significantly improving over the naive \((n^{k})\) bound for top-\(k\) recommendations without using feature representations . Finally, we empirically validate GP-TopK's regret on real-world datasets, demonstrating improvement over baseline methods.

### Organization

The remainder of this paper is organized as follows: Section 2 introduces Kendall kernels for full and top-\(k\) rankings, including the novel weighted convolutional Kendall kernel. Section 3 presents faster matrix-vector multiplication algorithms for Kendall kernels, enhancing the efficiency of the proposed bandit algorithm, which is further detailed along with the regret analysis in Section 4. Finally, Sections 5 and 6 present empirical results and concluding discussion, respectively.

## 2 Kendall Kernels for Full and Top-k Rankings

This section introduces Kendall kernels and their extensions for top-\(k\) recommendations, forming the foundation of our approach. We first establish key notations and them present Sections 2.1 and 2.2, which introduce Kendall kernels for full rankings and top-\(k\) rankings, respectively.

Notations:Let \([n]=1,2,,n\), with \(\) representing a top-\(k\) ranking--an ordered tuple of \(k\) distinct elements from \([n]\). For a full ranking (\(k=n\)), we use \(\) and denote the set of all possible top-\(k\) rankings by \(^{k}\), with cardinality \(|^{k}|=(n^{k})\). To capture ranking positions, the vector \(^{}^{n}\) corresponds to a full ranking \(\) with entry \(_{i}^{}\) gives the rank of item \(i\). For top-k rankings, \(^{}^{n}\) is similarly constructed by arbitrarily assigning distinct ranks to items not in the top \(k\). For relative ranks, indicator functions \(_{i<j}^{}\) and \(_{i>j}^{}\) denote whether item \(i\) is ranked before or after item \(j\), respectively in \(\). Also, \(_{i<j}^{}\) and \(_{i>j}^{}\) are similar indicator functions defined for top-k rankings.

### Kendall Kernels for Full Rankings

Jiao et al.  showed that the Kendall tau rank correlation coefficient  is a positive definite (p.d.) kernel for full rankings, which we refer to as the standard Kendall (SK) kernel. The weighted Kendall (WK) kernel generalizes the SK kernel by differentially weighting item pairs . Specifically, the SK and WK kernels for full rankings \(_{1},_{2}\) are defined as:

\[k^{sk}(_{1},_{2}) }_{i<j}_{i,j}(_{1}, _{2})\] (1) \[k^{wk}(_{1},_{2}) }_{i<j}w((_{i}^{ _{1}},_{j}^{_{1}}),(_{i}^{_{2}}, _{j}^{_{2}}))_{i,j}(_{1},_{2}),\] (2)

where \(_{i,j}\) is 1 if the pair \((i,j)\) is _concordant_ (ordered the same in both rankings) and \(-1\) otherwise; concretely, \(_{i,j}(_{1},_{2})_{i<j}^{_{1}} _{i<j}^{_{2}}+_{i>j}^{_{1}}_{i>j}^{_{2}}-_{i<j}^{_{1}}_{i>j}^{ _{2}}-_{i>j}^{_{1}}_{i<j}^{_{2}}\); and \(w((_{i}^{_{1}},_{j}^{_{1}}),(_{i}^ {_{2}},_{j}^{_{2}}))\) is the value of a positive definite weighting kernel \(w(,):[n]^{2}[n]^{2}\) that operates on pairs of ranks. The \(w_{i,j}\) adds flexibility and can assign varying importance to ranks, similar to the discounted cumulative gain (DCG) metric . Note that both SK and WK kernels are p.d. and right-invariant with respect to \(^{n}\). In other words, they compute similarity based only on the relative ranks of pairs, not on the labels of items, as clearly evident from Equations 1 and 2.

### Kendall Kernels for Top-k Rankings

Weighted Kendall and Convolutional Kendall (CK) kernels.To adapt the WK kernel from full rankings to top-\(k\) rankings, Jiao et al.  set the weighting function \(w(i,j,_{1},_{2})\) to zero if either item is not in the top-k of either ranking. While this approach yields a p.d. kernel, it disregardsitems outside the intersection of top-\(k\) rankings. In contrast, the convolutional operation provides an alternative for adapting the standard Kendall kernel to top-\(k\) rankings.

Let \(B_{}\) denote the set of full rankings consistent with the top-k ranking \(\) (i.e., for every item \(i\) in \(\), \( B_{},_{i}^{}=_{i}^{}\)). The convolutional Kendall kernel can be defined as follows:

\[k^{ck}(_{1},_{2})=}||B_{_{2}}|}_{_ {1} B_{_{1}},\ _{2} B_{_{2}}}k^{sk}(_{1},_{2}),\] (3)

where \(k^{sk}\) is the standard Kendall kernel. Since the CK kernel is a convolution of another p.d. kernel, it is also a p.d. kernel . Unlike the WK kernel for top-k rankings, the CK kernel accounts for items not in both top-k rankings. However, computing the CK kernel is expensive, requiring exponentially many evaluations of the kernel \(k^{sk}\) in the double summation. Therefore, Jiao et al.  developed an efficient algorithm to bypass this double summation, reducing compute to \((k k)\) time.

Proposed Weighted Convolutional Kendall (WCK) Kernel.To combine the strengths of the WK and CK kernels for top-k rankings, we propose the weighted convolutional Kendall kernel for top-k rankings \(_{1}\) and \(_{2}^{k}\):

\[k^{wck}(_{1},_{2})}||B_{_{2}}|} _{_{1} B_{_{1}},_{2} B_{_{2}}}k^{wk}(_{1}, _{2}),\] (4)

where \(k^{wk}\) represents the weighted Kendall kernel for full rankings \(_{1},_{2}^{n}\).

The proposed WCK kernel combines the flexibility of differentially weighting ranks among the top-\(k\) items (as in the WK kernel) with the ability to account for items outside the intersection of both top-\(k\) rankings (as in the CK kernel). Additionally, as a convolution of a p.d. kernel, it is also a p.d. kernel. However, computing the WCK kernel remains challenging, as it requires exponentially many evaluation of the \(k^{wk}\) kernel, as given in the RHS of Equation 4. To address this, we focus on a specific form of rank weights of the \(k^{wk}\) kernel, called as _product-symmetric_ rank weights:

\[w_{ps}((i_{1},j_{1}),(i_{2},j_{2})) w_{s}(i_{1},j_{1}) w_{s}(i_{ 2},j_{2}),\] (5)

where, \(w_{s}(i,j):[n][n]\) is a symmetric function, i.e., \(w_{s}(i,j)=w_{s}(j,i)\). Notably, the WCK kernel can be computed efficiently for the case of these weights (see Claim 1 below).

The WCK kernel, even with the relatively simple \(w_{ps}\) weights, exhibits notable properties, as shown in Table 2. In this table, we use \(w_{s}(i,j)=\), inspired by the DCG metric commonly applied in recommendation systems . Notably, the WK kernel ranks two rankings with no overlap (\(_{0}\) and \(_{1}\)) as more similar than two rankings with the same items in reversed order (\(_{0}\) and \(_{2}\)), indicating a clear pathology. Further, the CK kernel fails to distinguish between reversed pairs at different ranks (\(k^{ck}(_{0},_{3})=k^{ck}(_{0},_{4})\)), presenting another limitation if known variants of Kendall kernels for top-k rankings. By using product-symmetric ranking weights, the WCK kernel addresses these shortcomings, providing a more nuanced similarity comparison for top-\(k\) rankings.

**Claim 1**.: _The weighted convolutional Kendall kernel (Equation 4) with product-symmetric rank weights (Equation 5) can be computed in \((k^{2})\) time._

Appendix A provides the proof that leverages the structure of product-symmetric rank weights \(w_{ps}\) to establish the existence of a feature representation for the WCK kernel, as formally stated below in

  Top-k & \(_{1}\) & \(_{2}\) & \(_{3}\) & \(_{4}\) \\ Kernels & \(\) & \(\) & \(\) & \(\) \\  WK & \(0.00\) & \(-1.00\) & \(0.33\) & \(0.33\) \\ CK & \(-0.60\) & \(0.60\) & \(0.87\) & \(0.87\) \\ WCK & \(-0.38\) & \(0.09\) & \(0.46\) & \(0.87\) \\  

Table 2: Comparison of Kendall kernel similarities for top-k rankings. The table shows kernel values \(k(_{0},)\) for the top-k ranking \(_{0}=\) with other rankings (\(_{1}\), \(_{2}\), \(_{3}\), \(_{4}\)) for \(n=7\) and \(k=3\). Rankings are arranged left to right by increasing similarity to \(_{0}\). The similarity values provided by the proposed kernel increase from left to right as expected, demonstrating the desirable behavior of the WCK kernel with DCG rank weights, unlike other variants. All kernels are unit-normalized. See text for further details.

Claim 3 below. We then demonstrate that the inner product of these features, and hence the WCK kernel, can be computed in \((k^{2})\) time (Algorithm 2 in the appendix). Similar to the result of Jiao et al.  for the CK kernel, this approach avoid exponentially many evaluations of \(k^{wk}\) on the RHS of Equation (4) by enabling a direct computation of the WCK kernel.

## 3 Fast Matrix-Vector Multiplication with Kendall Kernel Matrices

In Gaussian processes, inference can be accelerated by using iterative algorithms that take advantage of fast matrix-vector-multiplications (MVMs) with the kernel matrix . This section introduces fast algorithms for kernel MVMs by exploiting the implicit structure of Kendall kernel matrices.

Let \((K_{X_{t}})\) denote the runtime required to multiply the \(t t\) kernel matrix \(K_{X_{t}}=(k(x_{i},x_{j}))_{x_{i},x_{j} X_{t}}\) by any admissible vector. In the naive approach, this runtime is \((KX_{t})=(t^{2})\). However, if \(k(x_{i},x_{j})=^{a}(x_{i})^{T}^{b}(x_{j})\) for any arbitrary \(x_{i}\) and \(x_{j}\), where the vectors \(^{a}(x_{i})\) and \(^{b}(x_{j})\) are sparse and contain only \(z\) non-zero entries, then \((K_{X_{t}})\) reduces to \((z t)\), which is a significant improvement over \((t^{2})\) when \(z t\). When \(^{a}=^{b}\), we refer to \(^{a}\) as the _linear feature vector_ for the kernel \(k\). Before focusing on top-k ranking kernels, we provide a linear feature vector for the WK kernel on full rankings (given earlier in Equation 2).

**Claim 2**.: _Let \(^{wk}():^{n}^{}\) be a vector indexed by unique item pairs \((i,j)\), defined as:_

\[^{wk}_{i,j}()}} w_{s}( ^{}_{i},^{}_{j})(^{ }_{i<j}-^{}_{i>j}),\]

_where \(w_{s}\) is the symmetric weighting function in product-symmetric weights. Then, \(^{wk}\) is a linear feature vector for the weighted Kendall kernel with product-symmetric weights \(w_{ps}\)._

Using Claim 2, the linear feature vector for the WK kernel can be extended to the WK top-\(k\) ranking kernel by utilizing the structure of product-symmetric weights, which allows weights to be set to zero for items outside of the top-\(k\) rankings, as described in Section 2.2. Precisely, such a feature vector for the top-\(k\) ranking kernel is sparse; specifically, the feature vector \(^{wk}()\) contains only \((k^{2})\) non-zero entries due to the WK kernel's focus on item pairs within the top-\(k\). Consequently, the runtime for \((K_{X_{t}})\) in the WK kernel matrix is reduced to \((k^{2} t)\).

Moving forward, we focus on deriving a sparse feature vector for the WCK kernel, enabling fast MVMs with the WCK kernel, which includes the CK kernel as a special case. Notably, any convolutional kernel inherits linear features from its constituent kernel. Specifically, \(_{ B_{s}}^{wk}_{i,j}()\) forms a feature vector for the WCK kernel, which follows from Equation 4 and However, computing this feature vector explicitly is computationally challenging, as it requires summing over all \( B_{}\), which includes an exponential number of terms, i.e., \((n^{k})\).

In response to this challenge, Claim 3 shows that the summation can be computed analytically and provides explicit linear feature vectors for the WCK and CK kernels. It also shows that \(^{wck}\) has only \((k^{2}+2nk)\) non-zero entries among its \((n^{2})\) total entries. Consequently, \((K_{X_{t}})\) for the WCK kernel requires \(((k^{2}+2nk) t)\) operations, which improves from \((t^{2})\) to linear in \(t\). However, this introduces a dependence on \(n\), the number of items, which poses a serious limitation and is beneficial only when \(n t\). In the following theorem, we leverage redundancy in \(^{wck}\) to eliminate this dependence on \(n\), leading to the following main theorem about the \((K_{X_{t}})\).

```
1:For the WCK kernel with product-symmetric weights \(w_{ps}\), the computational complexity of multiplying the kernel matrix \(K_{X_{t}}\) with any admissible vector is \((k^{2}t)\), i.e., \((K_{X_{t}})=(k^{2}t)\), where \(X_{t}\) is any arbitrary set of \(t\) top-k rankings. ```

**Theorem 1**.: _For the WCK kernel with product-symmetric weights \(w_{ps}\), the computational complexity of multiplying the kernel matrix \(K_{X_{t}}\) with any admissible vector is \((k^{2}t)\), i.e., \((K_{X_{t}})=(k^{2}t)\), where \(X_{t}\) is any arbitrary set of \(t\) top-k rankings._

Appendix A provides the proof in two steps. First, we utilize the values of \(^{wck}\) from Claim 3 and categorize \(^{wck}(_{1})^{T}^{wck}(_{2})\) based on item pairs, as summarized in Table 4. Next, we show that only five combinations yield non-zero values, i.e., \(^{wck}(_{1})^{T}^{wck}(_{2})=_{i=1}^{5}s_{i}(_{1},_{2})\). Each term \(s_{i}(_{1},_{2})\) is a dot product of vectors \(^{a_{i}}(_{1})^{T}^{b_{i}}(_{2})\), which contains at most \((k^{2})\) non-zero entries. Thus, for the WCK and CK kernels, \((K_{X_{t}})=(k^{2}t)\), since these vectors across all five terms include only \((k^{2})\) non-zero entries. Consequently, Theorem 1 demonstrates that employing these vector representations for top-k rankings leads to faster MVMs, i.e., \((K_{X_{t}})=(k^{2}t)(t^{2})\).

## 4 Proposed GP-TopK Bandit Algorithm

In this section, we begin by formally defining the top-\(k\) recommendation problem within a bandit framework and introduce a generic contextual bandit algorithm, detailed in Algorithm 1. We then explain how the components of the algorithm are instantiated using the proposed GP approach, followed by an analysis of its computational complexity and cumulative regret.

Let \(T\) denote the number of rounds. Contexts \(\) are represented in a finite \(c\)-dimensional space, i.e., \(^{c}\). In the \(t^{th}\) round, we receive a context \(_{t}\) and select a top-\(k\) ranking \(_{t}^{k}\). Subsequently, a noisy reward \(y_{t}=(_{t},_{t})+_{t}\) is observed, where \(\) is the true reward function and \(_{t}\) is round-independent noise. The regret is defined as \(r_{t}^{{}^{}}^{k}(_{t},^{{}^{ }})-(_{t},_{t})\), with cumulative regret \(R_{T}_{t=1}^{T}r_{t}\). The accumulated data at the \(t^{th}\) round is \(_{t}=(_{i},_{i},y_{i})_{i=1}^{t}\). Below, the Algorithm 1 provides provides a generic schematic of the bandit algorithm.

```
1:Total rounds \(T\), initial reward model \(_{0}\), and acquisition function \(\).
2:for\(t=1,,T\)do
3: Observe a context \(_{t}\) from the context space \(\).
4: Select a top-\(k\) ranking \(_{t}\) that maximizes \((_{t-1}(_{t},))\) for the context \(_{t}\).
5: Obtain the scalar reward \(y_{t}\).
6: Update the reward model \(_{t}\) using the accumulated feedback \(_{t}\).
7:endfor ```

**Algorithm 1** Contextual Bandit Algorithm for Top-k Recommendations

We aim to design the components of above Algorithm 1 with the objectives of minimizing cumulative regret and ensuring computational efficiency. It requires two key components: (a) a reward model \(_{t}\) that estimates the reward for any context and top-\(k\) ranking utilizing the accumulated data \(_{t}\) and (b) an acquisition function \(\) for selecting \(_{t}\) given the reward model \(_{t}\) and observed context \(_{t}\).

Reward model \(\) and acquisition function \(\).The proposed GP-TopK bandit algorithm leverages GP regression to model the reward function over the domain of contexts and top-k rankings. Section B.1 briefs GP regression for the completeness. Essentially, the reward model \(\) maintains a distribution over functions \(f\), i.e., \(f(0,k(,))\), where \(k\) is a product kernel function over both contexts and top-k rankings (\(^{k}\)). Specifically, the kernel function \(k\) is defined as follows:

\[k((_{1},_{1}),(_{2},_{2})) k^{c}(_ _{1},_{2}) k^{r}(_{1},_{2}),\] (6)

where \(k^{c}(_{1},_{2})=_{1}^{T}_{2}\) is the dot-product kernel and \(k^{r}\) is a kernel for top-k rankings. We use variants of the Kendall kernel for \(k^{r}\) from Section 2. Updating the reward model \(_{t}\) at the round involves adding new data points to our GP regression, which is computationally inexpensive compared to the fine-tuning steps required by parametric models to incorporate the latest feedback.

We use the UCB function as the acquisition function, balancing exploration and exploitation by selecting actions that maximize the upper confidence bound of the estimated reward . The UCB acquisition function is \((_{t}(_{t},))_{f} ((_{t},))+^{}._{f}((_{t},))\), where \(_{f}((_{t},))=}(( _{t},),(_{t},))}\) and \(\) controls the trade-off between exploration and exploitation. Here, \(_{f}\) and \(k_{f}\) are the GP posterior mean and covariance functions, as detailed in Section B.1. At the \(t^{}\) round, the algorithm selects the top-k ranking \(^{k}\) that maximizes \((_{t}(_{t},))\), which is performed using local search , as detailed further in Appendix B.

Computational complexity.The GP-TopK bandit algorithm does not require compute for model updates. In other words, updating \(_{t}\), i.e., in the Line 5 of the Algorithm 1 requires only updating the list of accumulated feedback data \(_{t}\). The GP-TopK relies on local search to optimize \(\), so the computational demands stem solely from \(\) evaluations within the local search. As shown in Section B.1, computing the GP variance term for evaluating \(\), i.e, \(_{f}((_{t},))\) involves solving \([K_{X_{t}}+^{2}I]^{-1}\) for a vector \(\), where \(X_{t}=[(_{1},_{1}),,(_{t},_{t})]\). Naively, this operation requires \((t^{3})\) time per round, amounting to total \((T^{4})\) over \(T\) rounds. Iterative algorithms, however, can expedite the process by leveraging fast MVMs with kernel matrices, as discussed in Section 3. Below, Theorem 2 formalizes the computational demands of the GP-TopK algorithm.

**Theorem 2**.: _Assuming a fixed number of iterations required by the iterative algorithms, the total computational time for running the GP-TopK bandit algorithm for \(T\) rounds of top-\(k\) recommendations, using the contextual product kernel (Equation 6), is \((k^{2}c T^{2})\). This applies to WK, CK, and WCK top-k ranking kernels, where \(\) is the number of local search evaluations._

The proof of Theorem 2, provided in Appendix B, demonstrates efficiency gains from combining feature representations with iterative algorithms, reducing computational time from \((T^{4})\) to \((T^{2})\). This is a substantial improvement, as even a single MVM with the matrix \(K_{X_{t}}\) using the full kernel matrix at each round would require \((T^{3})\) compute time. Additionally, the theorem shows that the running time of the GP-TopK algorithm does not explicitly depend on the number of items \(n\).

Regret analysis.The cumulative regret is \(R_{T}=_{t=1}^{T}_{^{{}^{}}^{k}}(_{t},^{{}^{}})-(_{t},_{t})\), where \(_{t}\) is the ranking chosen at round \(t\). Optimizing cumulative regret for top-\(k\) recommendations is challenging, as it requires learning the context-arm relationship and matching the best possible mapping. To bound cumulative regret, regularity assumptions are essential, as noted in prior works . _We consider the following two assumptions, either of which suffices_. Also, \(^{k}\) for below assumptions.

**Assumption 1**.: \(\) _is finite, meaning that only finite contexts are considered (\(||<\)), and the reward function \(\) is sampled from the GP prior with a noise variance of \(^{2}\)._

**Assumption 2**.: \(\) _is arbitrary and the reward function \(\) has a bounded RKHS norm for the kernel \(k\), i.e., \(\|f\|_{k} B\). The reward noises \(_{t}\) form an arbitrary martingale difference sequence (i.e., reward noise does not systematically depend on its past values) and are uniformly bounded by \(\)._

The following theorem proves the regret bound for the GP-TopK algorithm under Assumption 1 or 2.

**Theorem 3**.: _If either Assumptions 1 or 2 hold, setting \(_{t}\) as \(2(|\|^{k}|^{2}^{2}}{6})\) and \(300_{t}^{3}()\) respectively, the cumulative regret \(_{T}\) of the GP-TopK bandit algorithm for top-\(k\) recommendations can, with at least \(1-\) probability, be bounded by \(}(nTc([]+k+(T^{2}^{2}/6 ))})\) under Assumption 1, and \(}(n(2B^{2}c+300n^{2}c^{2}^{3}(T/))T})\) under Assumption 2. Here, \(C_{1}=)}\), and \(}\) excludes logarithmic factors related to \(n\), \(k\), and \(T\)._

Appendix B.4 provides the proof, leveraging the insight that \( I+^{-2} K_{X_{T}}\) for any set \(X_{T}\) can be effectively bounded using the finite-dimensional feature vectors introduced in this work.

Specifically, Proposition 2 utilizes the feature vectors from Section 2. Building on Proposition 2, Theorem 3 establishes that the cumulative regret of the GP-TopK bandit algorithm grows sublinearly in \(T\) with high probability for both assumptions. Furthermore, this result also underscore the importance of using top-k ranking kernels, which improve the asymptotic order in terms of \(n\) by factors of \(n^{k/2-1}\) and \(n^{k-1}\) under Assumptions 1 and 2, respectively, compared to Srinivas et al. (2017). This improvement is substantial even for small values of \(k\), such as \(k=6\), as shown in Table 3.

## 5 Experiments

This section empirically evaluates the proposed GP-TopK bandit algorithms for the top-k recommendations using a simulation based on the MovieLens dataset (Bengio et al., 2010). The reliance on simulation for evaluating bandit algorithms is prevalent in the literature. It stems from the difficulty of conducting online evaluations in real-world bandit scenarios, mainly when there are combinatorial arms (Kirsh and Kirsh, 2017). Next, we provide details of the simulation setup and considered reward settings. Following that, we present results for the empirical regret for small and large numbers of arms below, respectively.

Simulation setup and reward settings.The bandit simulation setup follows the framework outlined by Jeunen et al. (2010), utilizing real-world datasets on user-item interactions. Specifically, we train user and item embeddings using a collaborative filtering approach (Bengio et al., 2010). The user embeddings are accessed by the bandit algorithms as context embeddings, while the item embeddings remain hidden. In the non-contextual setup, the first user from the dataset is chosen as a fixed context throughout the bandit algorithm run, allowing us to use the same reward functions as the contextual bandit algorithm.

For setting up the reward functions, we utilize a similarity function \(s(,)(a(^{T})-b)\) to measure similarity between any user and item embeddings, where \(a\) and \(b\) are similarity score and shift scalars, respectively. The sigmoid function \(\) maps similarity scores to a range between \(0\) and \(1\), enhancing the interpretability of the reward signal (Kirsh and Kirsh, 2017). We set \(a\) and \(b\) to \(6\) and \(0.3\), respectively, to fully utilize the range of the similarity function, as assessed by evaluating its value for many arms.

We set up two preliminary reward functions based on the similarity function \(s\). The first is the DCG metric, \(_{}(,)=_{i=1}^{k}(i+1)}s( ,_{_{i}})\), where \(\) and \(_{_{i}}\) represent the context and item embeddings, respectively. The second is the diversity measure, \(_{}()=}_{i=1}^{k}_{j=1}^{k}_{ _{j}}^{T}_{_{i}}\). These metrics quantify the relevance and diversity of top-k recommendations, respectively.

We use these functions in two contextual reward settings. The first setting focuses on normalized-DCG (n-DCG), \(_{}(,)=_{}(, )}{_{s^{}}_{}(,^{})}\)(Bengio et al., 2010). The second setting combines \(_{}\) and \(_{}\) as \(_{}(,)=_{}( ,)+(1-)_{}()\), evaluating the aggregate effect of relevance and diversity. We set \(=0.75\) to emphasize relevance over diversity.

Evaluation for small arm space.This section presents empirical results for the cumulative regret of bandit algorithms with a limited number of arms. Specifically, with \(n=20\) and \(k=3\), there are \(6,840\) top-k rankings, allowing for an exhaustive search to optimize the acquisition function. All bandit algorithms run in batch mode, updating every five rounds. We consider both reward settings for contextual and non-contextual scenarios, using a subset of five users for the contextual setting.

    \\ 
**Srinivas et al. (2010)** & **Proposed GP-TopK Algorithm** \\  \((n^{}Tc(+k +( 2}{68}))})\) & \((nTc(+k+(  2}{68}))})\) \\   \\ 
**Srinivas et al. (2010)** & **This work** \\  \((n^{}Tc(2B^{2}+300n^{k}c^{3}( ))})\) & \((nTc(2B^{2}+300n^{2}c^{3}())})\) \\   

Table 3: Comparison with Srinivas et al. (2010) on regret bounds for the bandit algorithm under both assumptions. Definitions of notations are provided in the main text.

Several baselines are set to assess the benefits of ranking (Kendall) kernels. Section C details the remaining hyper-parameter configurations and details of other baseline bandit algorithms.

The _Random_ algorithm randomly recommends any k items. The _\(\)-greedy_ algorithm alternates between recommending a random top-k ranking with a probability of \(\) and choosing the top-k ranking with the highest observed mean reward. In contextual settings, _\(\)-greedy_ differentiates arms for each unique context. Similarly, _MAB-UCB_ conceptualizes each ranking as an independent arm, an equivalent of using a direct delta kernel approach for GPs along with UCB \(\). In contextual scenarios, _MAB-UCB_ also treats arms distinctly per context. Each variant of the top-k ranking kernel yields one variation of the proposed GP-TopK algorithm, namely, WK, CK, and WCK. Figure 2 presents empirical values of the cumulative regrets for the above baseline and the proposed GP-TopK algorithms. In all cases, across both reward settings and in both contextual and non-contextual setups, the variants of the proposed GP-TopK algorithm outperform baselines that do not use Kendall kernels, highlighting the significance of top-k ranking kernels for full bandit feedback. Specifically, the CK and WCK kernels significantly outperform the WK kernel regarding the converged values of the regret, with the WCK kernel further improving on the CK kernel variant.

**Evaluation for large arm space.** We evaluate bandit algorithms in a large arm space scenario with \(n=50\) and \(k=3\) and \(k=5\), resulting in \(1.1 10^{5}\) and \(1.1 10^{10}\) possible top-k rankings, respectively. Using local search, we focus on the nDCG reward. The remaining configuration is consistent with the small arm space setup. We use \(10\) restarts and \(5\) steps in each search direction for the local search, starting with \(1000\) initial candidates.

Figure 3 shows that the regret for the GP-TopK variants remains consistently lower even with a large arm space, despite the use of local search. The WCK approach significantly outperforms the CK, especially for \(k=5\), as illustrated in the right plot of Figure 3. Additional empirical results on the effectiveness of local search in a large arm space and other rewards are given in Appendix C.

## 6 Discussion

This work develops a contextual bandit algorithm for top-\(k\) recommendations using Gaussian processes with Kendall kernels in a full-bandit feedback setting, without restrictive assumptions about feedback or reward models. Gaussian processes provide computationally efficient model updates

Figure 3: Comparative evaluation of bandit algorithms for large arm spaces, with \(>1.1 10^{5}\) arms for the left plot and \(>1.1 10^{10}\) arms for the right plot. Cumulative regret with respect to the rounds of the bandit algorithm is depicted. Results are averaged over six trials. In both settings, the WCK approach outperforms other baselines. For more details, see the textual description.

Figure 2: Comparative evaluation of bandit algorithms: The cumulative regret \(R_{T}\) over \(T\) rounds is shown. Lower values indicate better performance. Plots (a) and (b) represent non-contextual settings for nDCG (\(_{}\)) and nDCG + diversity (\(_{}\)) rewards, respectively. Plots (c) and (d) show results for contextual settings for five users using the same rewards. The y-axis for (a) and (b) is on the left, and for (c) and (d) on the right. The GP-TopK algorithm with Kendall kernels, especially the weighted convolutional Kendall (WCK) kernel, outperforms others. Details on other algorithms are in the text. Results are averaged over six trials.

for accumulated feedback data, although inference can be challenging. We address this by deriving features for Kendall kernels tailored to top-\(k\) rankings, resulting in a faster inference algorithm that reduces complexity from \((T^{4})\) to \((T^{2})\). While demonstrated here for the product kernel between contexts and top-\(k\) rankings, these computational improvements extend naturally to other kernel types, such as additive kernels. Additionally, we address limitations of known variants and propose a more expressive Kendall kernel for top-\(k\) recommendations. Finally, we provide both theoretical and empirical results demonstrating the improved performance of the proposed GP-TopK algorithm.

Future Directions and Limitations.This work opens several research avenues. Efficient matrix-vector multiplication with Kendall kernel matrices can enable faster bandit algorithms with various acquisition functions, such as Thompson sampling and expected improvement. Exploring other kernels, like Mallow kernels, for top-k rankings and developing efficient algorithms for them is an intriguing direction, especially since the effectiveness of our algorithm depends on the function space induced by the RKHS of the underlying kernel. Assessing how well these kernels approximate various reward functions for top-k recommendations would provide valuable insights.

Exploring other bandit problem settings, such as stochastic item availability or delayed feedback, would enhance the applicability of this work to more complex scenarios. Extending the finite-dimensional GP framework to other acquisition functions using local search is another promising direction. One limitation of our regret analysis is that it does not account for approximations in the arm selection step due to local search . This limitation is common in continuous domains, where optimizing acquisition functions often involves non-convex optimization .

Impact.This research advances bandit algorithms for top-k item recommendations. By improving recommendation efficiency and accuracy, our algorithms can enhance user experiences across platforms, promoting content relevancy and engagement. However, they may reinforce implicit biases in training data, limiting content diversity and entrenching prejudices. Therefore, monitoring over time is essential when deploying these algorithms in real-world environments.