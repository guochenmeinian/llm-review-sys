# Enhancing Consistency-Based Image Generation via Adversarially-Trained Classification and Energy-Based Discrimination

Enhancing Consistency-Based Image Generation via Adversarially-Trained Classification and Energy-Based Discrimination

 Shelly Golan

Technion

shelly.golan@cs.technion.ac.il

&Roy Ganz

Technion

ganz@campus.technion.ac.il

&Michael Elad

Technion

elad@cs.technion.ac.il

###### Abstract

The recently introduced Consistency models pose an efficient alternative to diffusion algorithms, enabling rapid and good quality image synthesis. These methods overcome the slowness of diffusion models by directly mapping noise to data, while maintaining a (relatively) simpler training. Consistency models enable a fast one- or few-step generation, but they typically fall somewhat short in sample quality when compared to their diffusion origins. In this work we propose a novel and highly effective technique for post-processing Consistency-based generated images, enhancing their perceptual quality. Our approach utilizes a joint classifier-discriminator model, in which both portions are trained adversarially. While the classifier aims to grade an image based on its assignment to a designated class, the discriminator portion of the very same network leverages the softmax values to assess the proximity of the input image to the targeted data manifold, thereby serving as an Energy-based Model. By employing example-specific projected gradient iterations under the guidance of this joint machine, we refine synthesized images and achieve an improved FID scores on the ImageNet 64x64 dataset for both Consistency-Training and Consistency-Distillation techniques.

## 1 Introduction

Diffusion models, also known as score-based generative models, , , , ,  have set new benchmarks in multiple fields, the prime of which is image generation , . A central aspect of these models is the iterative sampling process that gradually eliminates noise from an initial random vector, this way carving fair samples from a prior distribution. By controlling the depth of such processes, these methods offer a flexible balance between computational effort and sample quality. However, compared to single-step generative models like GANs , the iterative generation procedure of diffusion models typically requires 10-2000 times more compute for sample generation , , , causing slow inference and limited real-time applications. Addressing this shortcoming, Consistency models  have been developed to expedite the sampling process, offering a faster alternative with one or two-step data generation. Unfortunately, their reliance on an intricate distillation process tends to limit the ultimate quality of the generated images.

Recent work that aims to remedy this performance gap integrates Consistency Models  with Generative Adversarial Networks, so as to tackle common GAN issues like mode collapse and unstable training process, thereby enhancing the diversity and stability of generated images .

Adversarial Consistency Training (ACT)  further refines this approach by incorporating a discriminator within the Consistency training framework, improving the generative model's quality by fine-tuning the image generation process for more realistic outputs. These methods offer new ways to overcome limitations in image fidelity, but require long and computationally expensive training.

In this work we propose a novel and highly effective technique for post-processing Consistency-based generated images, enhancing their perceptual quality. Our approach is based on a joint classifier-discriminator neural network, in which both functionalities are trained adversarially.

The adversarial approach is critical in our training process, as we will further explain in section 3. We rely on past research that has shown that deep neural networks can be easily deceived by adversarial attacks , , . Therefore, numerous strategies have been developed to make these networks more robust, with adversarial training becoming one of the most favored approaches , . During the analysis of such classifiers, a notable phenomenon was discovered: perceptually aligned gradients , . This trait implies that adjustments to an image, guided by the robust classifier, result in changes that are visually consistent with the intended classification.

Our method utilizes the above phenomenon and iteratively modifies the images created by Consistency-models using a joint robust classifier-discriminator. While the classifier aims to maximize the conditional probability of a target class, the discriminator portion of the very same network uses the softmax values to maximize the energy difference between synthesized and observed data, functioning as an Energy-based Model .

In order to refine synthesized images, we employ example-specific projected gradient iterations under the guidance of this joint machine. The process is controlled by an image-dependent early-stopping mechanism, that allows us to selectively refine images that diverge from the observed data distribution, ensuring that those already close to it remain unaffected. To summarize, our contributions are as follows:

1. We show significant quantitative and qualitative improvements in the perceptual quality of synthesized images for both Consistency-Training and Consistency-distillation, with an FID boost of \(27.48\%\) and \(20.96\%\), respectively.
2. We demonstrate a remarkable capability of adversarial robust classifiers: Serving as a joint classifier-discriminator informed of both synthesized and observed data distributions. This fusion leads to enhanced effectiveness of projected-gradient steps, leading to an additional improvement of \(11.2\%\) in FID results, over a classifier boosting alone .
3. While this work focuses on boosting Consistency based image generation, the proposed approach is general and applicable to any other generative model. While this is beyond the scope of the current work, we do present supporting preliminary such results.

## 2 Background

### Diffusion Models and Consistency

Diffusion models ,  generate data (e.g., images) by starting from a plain random vector and manipulating it progressively by sequential denoising steps and noise perturbations. More specifically, let \(p_{0}(x)\) denote the Probability Density Function (PDF) of true images. Diffusion models introduce a forward path, in which \(p_{0}(x)\) is gradually diffused over the time interval \(0 t T\) to a canonical Gaussian, \(p_{T}(x)=(0,I)\). This is formulated via a Stochastic Differential Equation (SDE) that describes a continuous noise-mixing process,

\[dx_{t}=(x_{t},t)dt+(t)dw_{t}.\] (1)

Here \(T>0\) is a fixed constant, \((,)\) and \(()\) are the drift and diffusion coefficients respectively, and \(\{w_{t}\}_{t[0,T]}\) denotes the standard Brownian motion. We denote the distribution of \(x_{t}\) as \(p_{t}(x)\), where \(p_{t}(x)\) is a \((t)\)-blurred version of \(p_{0}(x)\) due to the additive noise in \(x_{t}\).

Diffusion models are all about designing the reverse process from \(t=T\) to \(t=0\), in which noise is filtered gradually to produce high quality images that serve as fair samples from \(p_{0}(x)\). While the original diffusion techniques  offer an SDE-based reverse path, the more recent and more effective alternatives (e.g. DDIM ) remove the intermediate stochasticity and offer an ODE-basedreverse process of the form

\[dx_{t}=[(x_{t},t)dt-(t)^{2}_{x_{t}}logp_{t}(x_{t}) ]dt.\] (2)

Notice the appearance of the Score-Function \(_{x_{t}}logp_{t}(x_{t})\) in this flow, which is approximated by an image denoiser.

In practice, Diffusion Models are an Euler-Maruyama discretization  of the above equation, resulting with a chain of iterations that starts with a random canonical Gaussian noise \(x_{T}\), and gradually moves \(x_{t}\) towards \(x_{0}\) by steps of denoising that follow the above equation. The resulting \(x_{0}\) can be considered as a fair sample from \(p_{0}(x)\), assuming that the denoiser is well-trained.

Consistency models  are heavily inspired by the theory described above, aiming to preserve the end-to-end behavior that takes us from \(x_{T}\) to \(x_{0}\), but while expediting the process to a single (or a few) step. Given a solution trajectory \(\{x_{t}\}_{t[0,T]}\) of the above reverse equation, the Consistency function is the trained network \(f:(x_{t},t) x_{0}\). This function should have the property of self-consistency: For two temporal points \(t,s[0,T]\) and their corresponding stages in the same trajectory, \(x_{t}\) and \(x_{s}\), the outputs should be the same \(f(x_{t},t)=f(x_{s},s)=x_{0}\), thus explaining the name "Consistency". Such models can be trained in two main ways . The first method (CD) involves distilling knowledge from a pre-trained diffusion model, allowing it to learn the distribution directly from the more computationally intensive yet well-performing diffusion process. The second method (CT) trains the function \(f(,)\) directly via a tailored loss, without the need for a pre-existing diffusion model.

### Boosting Synthesis via Robust Classifier (BIGROC)

Consider a goal of refining generated images, so as to improve their perceptual quality. BIGROC  offers such a post-processing mechanism, by leveraging a robust classifier.

Let \(f_{}:^{d}^{C}\) be a classifier that maps images in \(^{d}\) to scores for \(C\) classes, also known as logits, and denote it's \(c^{}\) output by \(f_{}^{c}(x)\). These logits aim to have a probabilistic interpretation, being related to the estimated posterior probability \(p_{}(c|x)\). Starting with an arbitrary image \(x\) and taking gradient steps \(_{x}f_{}^{c}(x)\) in order to maximize \(f_{}^{c}(x)\), one would expect this process to produce an altered image that better resembles the targeted class \(c\). However, when using a plain classifier, even if it is very well performing, its gradients behave as a perceptually meaningless noise that is unrelated to the image content. This implies that, while the resulting image would tend to be classified to \(c\), its visual appearance would be hardly changed from the original image \(x\). This phenomenon is well-known, giving rise to the wide topic of adversarial attacks on neural networks , .

Past research has shown that, as opposed to the above, robust classifiers produce Perceptually Aligned Gradients (PAG) [31; 15; 1; 8; 7]. These gradients are a trait of adversarially trained models, their content being consistent with the human visual perception , . This implies that when used within the gradient steps mentioned above that aim to pull \(x\) towards class \(c\), robust models are expected to yield meaningful features aligned with the target class, thus modifying \(x\) in a perceptually convincing way.

Harnessing the above knowledge, the BIGROC algorithm  proposes an iterative process for boosting the perceptual quality of synthesized images, assuming that they are classifiable via \(f_{}(x)\). This is obtained by modifying any generated image \(x\) so as to maximize the posterior probability of a given target class \(\), i.e, \(p_{}(|x)\), where \(p_{}\) is modeled by an adversarially trained classifier and \(\) stands for the estimated class the image belongs to. The outcome of this process is a modified version of \(x\) that is more aligned with the class \(\) from a human point of view, thus having a better perceptual quality.

While there are various techniques for generating adversarial examples, the one used in BIGROC is Targeted Projected Gradient Descent  - a deterministic iterative process that operates as described in Algorithm 1, \(_{z}\) in this algorithm stands for the projection operator that ensures that the resulting image is \(\)-close to the starting image, and \(\) is the loss function (e.g., cross-entropy) that defines how the distance between the classifier output and the target label is computed. For simplicity, we can omit the loss and use the gradient of the softmax output of the classifier directly,

\[_{t+1}=_{}(_{t}-_{}f_{}^{} (x+_{t})).\] (3)We would like to draw the readers attention to the fact that BIGROC  is totally unaware of the generated images' distribution, which it aims to improve. This brings us naturally towards the proposed strategy in this paper.

``` Input: * Robust Classifier \(f_{}(x)\), * Input image \(x\), and * Algorithm's parameters: radius \(\), step-size \(\), no. of iterations \(T\), and loss function \(\). Set \(_{0} 0\). Set \(=f_{}(x)\) or get an external assignment for the class. for\(t\) from \(0\) to \(T\)do \(_{t+1}=_{}(_{t}-_{}(f_{ }(x+_{t}),))\). endfor Output:\(x_{adv} x+_{T}\) ```

**Algorithm 1** Targeted Projected Gradient Descent (PGD)

### Energy-Based Models

The core idea behind Energy-Based Models (EBM)  is turning an arbitrary function into a probability distribution. Consider a learned energy function \(E_{}(x):^{d}\), where \(x^{d}\) is an input image, and it's output is a scalar value in the range \((-,+)\). This neural network induces a PDF \(p_{}(x)\) that has a Gibbs form:

\[p_{}(x)=(x))}{Z_{}}.\] (4)

Clearly, this function assigns a probability greater than zero to any input. \(Z_{}\) is known as the Partition Function - a normalization factor that ensures that the density integrates to 1. The negative sign in the exponent implies that low energy values are assigned to highly probable images, while high energy refers to poor looking images.

EBMs are a family of algorithms that aim to learn \(E_{}(x)\) such that the resulting \(p_{}(x)\) aligns with the probability density function of the given training set. Given a learned EBM, image synthesis can be obtained by iteratively climbing the function \(p_{}(x)\) using Stochastic Gradient Langevin Dynamics (SGLD) . PGD, as described above, offers an appealing deterministic alternative to SGLD, by leveraging a loss-function and an additional \(\)-ball constraint in it's computation.

Energy-based models and image classifiers can be shown to have common grounds , as detailed in A. Assuming we have a classifier \(f_{}(x):^{d}^{C}\) that maps images to scores for \(C\) classes, the probability of the \(c^{th}\) label is represented using the Softmax function,

\[p_{}(c|x)=^{}(x))}{_{=1}^{C} exp(f_{}^{}(x))},\] (5)

The normalizing denominator in the above equation can be turned into a candidate energy function for an EBM,

\[E_{}(x)=-log[_{c=1}^{C}exp(f_{}^{c}(x))].\] (6)

In words, the exponent of this energy is the sum of the logits' exponentials. And so, while the classifier's assignment decision, \(p_{}(c|x)\), is independent of the induced energy, \(E_{}(x)\), this value can be interpreted as the entity that defines the PDF \(p_{}(x)\) that aims to match a given image distribution. In this work we leverage this possibility, and modify it, as discussed hereafter.

## 3 Proposed Approach

In this work we propose a method to enhance the perceptual quality of images generated by Consistency-based techniques . Our approach utilizes a robust joint classifier-discriminator to guide synthesized images to better resemble real images. In section 3.1, we explore this method's training objectives and technical details. The post-processing procedure, described in section 3.2, uses the guidance of the joint model in an iterative algorithm to refine the realism and visual appeal of synthesized images. In this process, the synthesized images, originating from the generated distribution \(p_{}\), are modified to align with the real images distribution \(p_{data}\).

### Training a Joint Classifier-Discriminator

Our method aims to leverage the Perceptually Aligned Gradients (PAG) property , and further extend and improve refinement capabilities of models that possess this trait by introducing the model with the distribution of both \(p_{}\) and \(p_{data}\). To this end, we empower the classifier model by incorporating a robust discriminator within it, so as to improve guidance performance significantly with this joint model. This dual-training approach allows the proposed model to better differentiate and understand the unique features of both real and synthetic images.

#### 3.1.1 Proposed Training objective

While Energy-Based Models (EBMs)  may align perfectly with our task of improving image quality by modifying out-of-distribution samples to align with the real data manifold, several challenges impact their practical application. These include the sensitivity of EBM training to the choice of the energy function used, leading often to training instability and poor generalization performance. EBMs necessarily rely on computationally complex sampling techniques (e.g. MCMC), which add to their overall complexity and instability. More on these matters is brought in B.

In this work we propose a joint classifier-discriminator model that overcomes many of the EBM problems mentioned above. Our model aims to guide generated samples to be more realistic and emphasize visual features aligned with the target class. To do so, we propose a revised interpretation of the adversarial training objective and a modified view of the energy that serves the EBM part of our model. More specifically, the loss function proposed contains adversarial variants of both Cross-Entropy and Binary-Cross-Entropy components, each targeting specific aspects of the training as explained further below.

**Discrimination loss:** The Binary-Cross-Entropy (BCE) loss we suggest is formulated as follows:

\[_{BCE}()=_{x p_{data}}[_{BCE}(,c)]+ _{x p_{}}[_{BCE}(,c)],\] (7)

where we define \(_{BCE}(x,c)\) for an image \(x\) from class \(c\) via

\[_{BCE}(x,c)=\{-log((f_{}^{c}(x)))&x  p_{data}\\ -log(1-(f_{}^{c}(x)))&x p_{}..\] (8)

This loss admits values in the range \([0,)\). For real images, the value \(f_{}^{c}(x)\) should tend to be high, while for generated ones it should strive to low values. As such, this ingredient behaves as an energy function that serves our discriminator.

In these equations, \(\) represents the adversarially perturbed version of \(x\), \(\) is the sigmoid function, \(f_{}\) is a classifier and \(c\) is the class to which the sample \(x\) belongs. In this setting, \(\) derived from \(x p_{data}\) serves as an adversarial example designed to deceive the model by pushing it to be "less real". Conversely, \(\) derived from \(x p_{}\) represents a synthetic image that has been created by the Consistency model, and was adjusted to appear more realistic. As we show in our ablation study, these adversarial examples are essential to the training process.

Note that in both attacks, the energy function of the classifier, as given in Equation 6, is _not_ the one used for the PGD computation. Rather, we use only the \(c\) logit magnitude as an energy proxy. Similarly to EBMs, we suggest assigning high probability values to real images and low probability values to fake ones. Further discussion about the relation between the suggested adversarial training and EBMs can be found in C.

**Classification loss:** The commonly used Cross-Entropy loss is formulated as follows:

\[_{CE}()=_{x p_{data}}[_{CE}(,c) ]+_{x p_{}}[_{CE}(,c)],\] (9)

where \(_{CE}(x,c)\) for an image \(x\) from class \(c\) is defined by a soft-max operation,

\[_{CE}(x,c)=-log^{c}(x))}{_{c^{}=1}^{C}exp(f_ {}^{c^{}}(x))},\] (10)which leads to values in the range \([0,)\), \(0\) for high classification probability and large values for indecisive classification. Here, \(\) are the adversarially perturbed samples as described in the paragraph above, in the context of the BCE loss.1 This loss ensures that the classifier can accurately classify real images to their correct classes, despite any potential adversarial modifications, thereby reinforcing the model's resilience to adversarial attacks and maintaining high classification accuracy on real data. Similarly to the BCE loss, this term calculates the CE loss for both the true and the generated images, maintaining the model's ability to classify generated images correctly.

The overall loss is simply an addition of the above two expressions, \(()=_{CE}()+_{BCE}()\). This formulation ensures that the model learns to distinguish effectively between real and generated images, as well as classifying them correctly, enhancing its ability to deal with adversarially altered images and to generalize well across different types of image manipulations. More importantly, due to the adversarial training, the learned model has meaningful gradients (_i.e.,_ PAG , ), which are about to play a vital role in our inference process of pushing Consistency generated images to their improved versions. As our training strategy considers both classification and discrimination losses, these gradients carry both improvements geared by class adjustments and a migration from \(p_{}\) to \(p_{data}\).

In our training process, as described above, we initialize the joint model with a robust RN50 network , while replacing its fully connected head with a randomly initialized one. As a consequence, we expect this network to inherit it's original classification robustness, which proves to be valuable for the overall image improvement obtained hereafter. Our training stands on the shoulders of this classifier, as we update the model parameters with the loss described above using only attacked (real and synthesized) images.

#### 3.1.2 Gradual Adversarial Training

When computing the adversarial attacks for the above losses, we operate differently on real and synthesized images. A real image \(x\) is modified by the PGD algorithm by maximizing the \(_{BCE}(x,c)\) loss, aiming to push it away from \(p_{data}\). This is achieved by ascent directions that require a negative value of \(\) in Algorithm 1. In contrast, attacks on the synthesized images aim to minimize \(_{BCE}(x,c)\) with a positive \(\) in the PGD algorithm.

Referring to the later attacks on the synthesized images, \(x p_{}\), PGD applies \(T\) steps of gradient descent that explore a local area with a small \(\) around the starting point of each input sample. We suggest to modify the activation of the PGD attack to a gradual form, using a large value of \(\), as explained below. In forming the attacks mentioned above, our method aims to traverse the entire spectrum between fake and real samples, systematically eliminating any miss-classifications of fake images as reals ones by the model.

We propose a strategy of gradually increasing the number of attack steps \(T\) throughout the training process. By extending the number of steps and initializing \(\) to be relatively large, the PGD attack can move further from the initial starting points, eliminating closer misleading examples first, and then proceeding to more challenging adversarial examples. Moreover, as the model becomes more adept at countering simpler attacks, incrementally increasing the complexity of the attacks ensure that the training continues to challenge the model effectively.

To further improve our training process and ensure the model does not mistakenly classify high-quality but still fake samples as genuine ones, we implement an early stopping mechanism based on the model's probability outputs. This mechanism halts the PGD process when the model assigns a higher probability to a perturbed fake image being real than it does to a perturbed real image in the same batch. This mechanism prevents the model from believing that fake images are more "real" than the real ones, preserving its' reliability and discriminative power.

### Sampling

As we move to inference, we aim to harness the PAG obtained by the adversarial training of the joint model, in order to boost the perceptual quality of Consistency generated images. We propose an iterative algorithm designed to adjust images \(x p_{}\), by maximizing the probability that \(x\) belongs to class \(c\) and simultaneously minimizing the gap between \(p_{}\) and \(p_{data}\). The choice of the loss function, \(\), is critical in this part, as will be shown in the ablation study. To utilize the gradients of the joint model we start by proposing the following expression that we minimize via the PGD:

\[(x,c)=_{CE}(x,c)-_{BCE}(x,c).\] (11)

Notice the marked difference between the above and the loss used for the training. This function operates only on incoming synthesized images \(x\) and while knowing their designated class \(c\). The rational in this expression has two pieces: A desire to minimize \(_{CE}(x,c)\) so as to align the image with its target class, just as practiced by BIGROC. In addition, \(_{BCE}(x,c)\) should strive for a high value, so as to make the image as realistic as possible, moving \(x\) closer to \(p_{data}\). We remind the reader that \(_{BCE}(x,c)\) here refers to synthesized images (see Equation 7), and thus a high value corresponds to high perceptual quality.

In practice, our tests indicate that the above loss tends to stray unstably, as \(_{BCE}(x,c)\) admits too high values, diverting from good quality outcomes. A remedy to this effect is the following alternative loss:

\[(x,c)=_{CE}(x,c)-(_{BCE}(x,c)-_{0})^{2}.\] (12)

Here we aim to push \(_{BCE}(x,c)\) towards a reference value \(_{0}\), set in the training process to be

\[_{0}=_{x p_{data}}[_{BCE}(x,c)].\] (13)

In words, \(_{0}\) is the mean value of the BCE loss for real images. Minimizing the distance between \(_{BCE}(x,c)\) and \(_{0}\) pushes the modified image to be more "real", while also making sure that it does not admit a value above \(_{0}\), which represents an exaggerated quality.

The overall algorithm for boosting images \(x p_{}\) is described in Algorithm 2.

``` Input:
* Robust Joint Classifier-Discriminator \(f_{}(x)\),
* Input image \(x\) of a target class \(c\), and
* Algorithm's parameters: Radius \(\), Step-size \(\), No. of iterations \(T\), and loss function \(\). Output:\(x_{boosted} TargetedPGD(f_{},,x,c,,,T)\). ```

**Algorithm 2** Boosting Images via PGD Guided by a Joint Classifier-Discriminator

An alternative approach is to sample using Stochastic Gradient Langevin Dynamics, similarly to , as described in Algorithm 3. To further investigate the properties of SGLD, we explored replacing PGD with SGLD during both inference and training. During training, we found that optimizing with SGLD lacks the robustness achieved with PGD and suffers from convergence difficulties. However, during inference, SGLD surpasses PGD, as shown in Table 3. The benefit of using SGLD during inference can be attributed to its ability to better explore multiple modes compared to methods like PGD due to it's stochastic nature.

``` Input:
* Robust Joint Classifier-Discriminator \(f_{}(x)\),
* Input image \(x\) of a target class \(c\), and
* Algorithm's parameters: Step-size \(\), No. of iterations \(T\), noise level \(\). for\(t\) from 1 to \(T\)do \(x_{t}=x_{t-1}-_{x_{t-1}}f_{}(x_{t-1})[c]+ (0,)\). endfor Output:\(x_{T}\). ```

**Algorithm 3** Boosting Images via SGLD Guided by a Joint Classifier-Discriminator

## 4 Experiments

In this section, we present an evaluation of the proposed boosting method. We begin by discussing the results obtained by our method compared to BIGROC . Subsequently, we conduct an ablation study to further analyze various components of the model, as described in Section 3.

### Experimental Settings

During training, we use the pre-trained robust ResNet-50 (RN50) model  as a backbone, with a randomly initialized classification head. We configure the parameters of the Projected Gradient Descent (PGD) attack for fake images with an \(\) of 10.0 and a step size of 0.1, increasing the number of PGD steps every 1,000 training iterations to enhance adversarial robustness over time. For real images, the PGD attack is set with an \(\) of 1.0, a step size of 0.25 and 4 steps. The model is trained on four NVIDIA GeForce RTX 3090 GPUs. The same configuration applies to the training of the Wide-ResNet-50-2 (Wide-RN) model. In the sampling process, we apply the loss function outlined in Equation 12 and the step size is set as \(0.1\). The amount of steps is adjusted according to the generative model we enhance; further technical details can be found in D.

### Experimental Results

We analyze the perceptual-quality boosting performance using Frechet Inception Distance , Inception Score , Precision and Recall. Table 1 summarizes our results on the ImageNet 64x64 dataset . Initially, we present the original FID and IS results as reported in the Consistency Models paper . We then apply our boosting algorithm using both a robust classifier and our joint model. The results demonstrate that our proposed approach offers greater benefits compared to refining with a robust classifier alone (i.e., BIGROC ). Notably, the proposed training of our joint model leads to significantly improved results. This boost in image quality is observed across both Consistency Training (CT) and Consistency Distillation (CD) methods, and when using either one or two generative steps. In terms of efficiency, one PGD step requires only 0.02 seconds, while a single Consistency (CT or CD) inference step takes 0.55 seconds, making 25 PGD steps comparable in cost to a Consistency inference. This suggests that our approach could be interpreted as providing a continuum trade-off between complexity and perceptual quality. For comparison,  used a GAN-based approach to improve CT synthesis with adversarial training, achieving an FID of 10.6, which slightly outperforms BIGROC but falls short of our joint model's performance boost. Note that their training is much more extensive than ours, and much heavier in computational complexity, due to the size of the CT network and the adversarial loss being used.

  Boosting Method & Inference Steps & FID (\(\)) & IS (\(\)) & Precision (\(\)) & Recall (\(\)) \\  
**Consistency Training** & 1 & 13.00 & 28.83 & 0.71 & 0.41 \\ RN50 Robust Classifier & & 10.71 & 36.38 & 0.70 & **0.47** \\ Wide-RN Non-Robust Joint & & 12.30 & 35.62 & 0.64 & 0.46 \\ RN50 Robust Joint & & 9.60 & 50.80 & 0.76 & 0.39 \\ Wide-RN Robust Joint & & **8.83** & **55.67** & **0.73** & 0.45 \\ 
**Consistency Training** & 2 & 11.12 & 27.28 & 0.68 & **0.54** \\ RN50 Robust Classifier & & 9.65 & 33.55 & 0.68 & 0.54 \\ Wide-RN Non-Robust Joint & & 11.28 & 33.16 & 0.63 & 0.54 \\ RN50 Robust Joint & & 8.51 & 39.40 & **0.74** & 0.49 \\ Wide-RN Robust Joint & & **7.98** & **46.33** & 0.71 & 0.52 \\ 
**Consistency Distillation** & 1 & 6.20 & 39.87 & 0.67 & **0.63** \\ RN50 Robust Classifier & & 5.55 & 44.65 & 0.68 & 0.61 \\ Wide-RN Non-Robust Joint & & 6.33 & 45.55 & 0.64 & 0.60 \\ RN50 Robust Joint & & 4.95 & 51.98 & **0.72** & 0.58 \\ Wide-RN Robust Joint & & **4.84** & **58.73** & 0.70 & 0.60 \\ 
**Consistency Distillation** & 2 & 4.69 & 42.28 & 0.68 & **0.63** \\ RN50 Robust Classifier & & 4.20 & 46.78 & 0.69 & 0.63 \\ Wide-RN Non-Robust Joint & & 4.66 & 46.37 & 0.68 & 0.63 \\ RN50 Robust Joint & & 3.84 & 51.12 & **0.72** & 0.60 \\ Wide-RN Robust Joint & & **3.78** & **55.13** & 0.71 & 0.61 \\  

Table 1: Quantitative comparison of image generation performance on ImageNet 64×64 using Consistency Models and our proposed boosting methods with robust classifiers and joint models.

### Ablation Study

As explained in Section 3.2, the choice of the loss function in Algorithm 2 is crucial. The results in Table 2 illustrate that utilizing only Cross-Entropy loss produces results that are similar to those achieved using BIGROC , as expected. The joint model demonstrates substantial discriminative power, which further enhances FID scores when Binary Cross-Entropy loss is applied. In exploring the integration of these two components, we experimented with the loss function proposed in equation 11. Our findings indicate that this approach improves upon Cross-Entropy loss, though it does not consistently surpass Binary Cross-Entropy loss. Consequently, we recommend adopting the loss outlined in Equation 12, which shows an additional improvement in FID by approximately 0.1.

We also compare sampling methods -- Projected Gradient Descent (PGD) and Stochastic Gradient Langevin Dynamics (SGLD) -- as discussed in Section 3.2 and presented in Table 3. Our experiments reveal that SGLD offers advantages over PGD in certain contexts, particularly in terms of sampling diversity and fidelity.

  Method & Inference Steps & Loss Function & FID (\(\)) & IS (\(\)) \\  
**Consistency Training** & 1 & & 13.00 & 28.83 \\  & & \(_{CE}\) & 10.78 & 38.97 \\  & & \(_{BCE}\) & 9.75 & 44.19 \\  & & \(_{CE}-_{BCE}\) & 9.71 & 43.38 \\  & & Our loss & **9.60** & **50.80** \\ 
**Consistency Training** & 2 & & 11.10 & 27.28 \\  & & \(_{CE}\) & 10.26 & 35.89 \\  & & \(_{BCE}\) & 8.59 & 39.38 \\  & & \(_{CE}-_{BCE}\) & 8.62 & 39.02 \\  & & Our loss & **8.51** & **39.40** \\ 
**Consistency Distillation** & 1 & & 6.20 & 39.87 \\  & & \(_{CE}\) & 5.51 & 47.54 \\  & & \(_{BCE}\) & 5.00 & 48.97 \\  & & \(_{CE}-_{BCE}\) & 5.10 & 48.63 \\  & & Our loss & **4.95** & **51.98** \\ 
**Consistency Distillation** & 2 & & 4.69 & 42.28 \\  & & \(_{CE}\) & 4.17 & 47.81 \\  & & \(_{BCE}\) & 3.89 & 48.72 \\  & & \(_{CE}-_{BCE}\) & 4.97 & 48.35 \\  & & Our loss & **3.84** & **51.12** \\  

Table 2: FID and IS results with varying loss functions as described in section 3.2.

  Boosting Method & Inference Steps & FID (\(\)) & IS(\(\)) & Precision (\(\)) & Recall (\(\)) \\  
**Consistency Training** & 1 & 13.00 & 28.83 & 0.71 & 0.41 \\ Wide-RN\(+\)PGD & & 8.83 & 55.67 & 0.73 & 0.45 \\ Wide-RN\(+\)SGLD & & **8.71** & **59.76** & **0.73** & **0.46** \\ 
**Consistency Training** & 2 & 11.12 & 27.28 & 0.68 & **0.54** \\ Wide-RN\(+\)PGD & & 7.98 & 46.33 & 0.71 & 0.52 \\ Wide-RN\(+\)SGLD & & **7.64** & **46.83** & **0.71** & 0.53 \\ 
**Consistency Distillation** & 1 & 6.20 & 39.87 & 0.67 & **0.63** \\ Wide-RN\(+\)PGD & & 4.84 & 58.73 & 0.70 & 0.60 \\ Wide-RN\(+\)SGLD & & **4.65** & **59.00** & **0.71** & 0.60 \\ 
**Consistency Distillation** & 2 & 4.69 & 42.28 & 0.68 & **0.63** \\ Wide-RN\(+\)PGD & & 3.78 & 55.13 & 0.71 & 0.61 \\ Wide-RN\(+\)SGLD & & **3.58** & **56.46** & **0.72** & 0.61 \\  

Table 3: Quantitative comparison of our proposed boosting methods using Wide-ResNet with PGD and SGLD sampling techniques applied to Consistency Models.

To assess the generalization capability of our joint model, we evaluated it on images generated by BigGAN and ADM-G at resolutions of 128x128 and 256x256 pixels (see Table 4). Despite being trained exclusively on images from Consistency Models, our joint model demonstrates strong generalization across different generative models and resolutions. This suggests that our model can enhance images from a variety of generative sources without requiring retraining or fine-tuning for each specific case.

## 5 Conclusion

This work presents a novel technique for leveraging the perceptually aligned gradients phenomenon for refining synthesized images. Our approach enhances the perceptual quality of images generated by Consistency-based techniques using a robust _joint_ classifier-discriminator model. The dual functionality of our model, which serves as both classification and energy-based discrimination, leads to significant improvements in image fidelity.

**Limitations:** In this work we have used the RN50 and Wide-RN 50-2 architectures for the joint model, as commonly employed in robust classification tasks. We note that this architectures are relatively simple and small, compared to the more complex ones proposed in recent years. As a consequence, our study is unavoidably constrained by the capabilities of the chosen models. Another limitation in our work is the reliance of our training on Consistency generated images only. Expanding the training-set to include images from additional generative models could further improve the overall boosting effect that we document in this paper.

  Boosting Method & FID (\(\)) & IS (\(\)) & Precision (\(\)) & Recall (\(\)) \\  
**Adm 64x64** & 2.61 & 46.78 & 0.73 & **0.63** \\ Wide-RN+SGLD & **2.08** & **58.41** & **0.75** & 0.60 \\ 
**BigGAN 64x64** & 4.06 & 44.94 & 0.79 & **0.48** \\ Wide-RN+SGLD & **3.67** & **62.79** & **0.81** & 0.45 \\ 
**Iddpm 64x64** & 2.92 & 45.62 & 0.73 & **0.62** \\ Wide-RN+SGLD & **2.25** & **62.26** & **0.76** & 0.59 \\ 
**Adm-G 128x128** & 2.97 & 141.47 & 0.78 & **0.59** \\ Wide-RN+SGLD & **2.34** & **271.95** & **0.80** & 0.58 \\ 
**BigGAN 128x128** & 6.02 & 145.83 & 0.86 & 0.34 \\ Wide-RN+SGLD & **5.68** & **236.88** & **0.86** & **0.34** \\ 
**Adm-G 256x256** & 4.58 & 186.83 & 0.81 & 0.52 \\ Wide-RN+SGLD & **3.17** & **301.06** & **0.83** & **0.53** \\ 
**BigGAN 256x256** & 7.03 & 202.64 & 0.87 & 0.27 \\ Wide-RN+SGLD & **6.16** & **275.25** & **0.88** & **0.28** \\  

Table 4: Quantitative comparison for various generative models at different resolutions (64×64, 128×128, and 256×256), before and after applying our proposed boosting method using Wide-ResNet with SGLD.