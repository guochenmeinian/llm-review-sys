# Minimum-Risk Recalibration of Classifiers

Zeyu Sun

University of Michigan

zeyusun@umich.edu

&Dogyoon Song

University of Michigan

dogyoons@umich.edu

&Alfred Hero

University of Michigan

hero@eecs.umich.edu

Equal contribution.

###### Abstract

Recalibrating probabilistic classifiers is vital for enhancing the reliability and accuracy of predictive models. Despite the development of numerous recalibration algorithms, there is still a lack of a comprehensive theory that integrates calibration and sharpness (which is essential for maintaining predictive power). In this paper, we introduce the concept of minimum-risk recalibration within the framework of mean-squared-error (MSE) decomposition, offering a principled approach for evaluating and recalibrating probabilistic classifiers. Using this framework, we analyze the uniform-mass binning (UMB) recalibration method and establish a finite-sample risk upper bound of order \((B/n+1/B^{2})\) where \(B\) is the number of bins and \(n\) is the sample size. By balancing calibration and sharpness, we further determine that the optimal number of bins for UMB scales with \(n^{1/3}\), resulting in a risk bound of approximately \(O(n^{-2/3})\). Additionally, we tackle the challenge of label shift by proposing a two-stage approach that adjusts the recalibration function using limited labeled data from the target domain. Our results show that transferring a calibrated classifier requires significantly fewer target samples compared to recalibrating from scratch. We validate our theoretical findings through numerical simulations, which confirm the tightness of the proposed bounds, the optimal number of bins, and the effectiveness of label shift adaptation.

## 1 Introduction

Generating reliable probability estimates alongside accurate class labels is crucial in classification tasks. A probabilistic classifier is considered "well calibrated" when its predicted probabilities closely align with the empirical frequencies of the corresponding labels . Calibration is highly desirable, particularly in high-stakes applications such as meteorological forecasting , econometrics , personalized medicine , and natural language processing . Unfortunately, many machine learning algorithms lack inherent calibration .

To tackle this challenge, various methods have been proposed for designing post hoc recalibration functions. These functions are used to assess calibration error , detect miscalibration , and provide post-hoc recalibration . Despite the rapid development of recalibration algorithms, there is still a lack of a comprehensive theory that encompasses both calibration and sharpness (retaining predictive power) from a principled standpoint. Furthermore, existing methods often rely on diverse calibration metrics , and the selection of hyperparameters is often based on heuristic approaches  without rigorous justifications. This highlights theneed for identifying an optimal metric to evaluate calibration, which can facilitate the development of a unified theory and design principles for recalibration functions.

In addition, the deployment of machine learning models to data distributions that differ from the training phase is increasingly common. These distribution shifts can occur naturally due to factors such as seasonality or other variations, or they can be induced artificially through data manipulation methods such as subsampling or data augmentation. Distribution shifts pose challenges to the generalization of machine learning models. Therefore, it becomes necessary to adapt the trained model to these new settings. One significant category of distribution shifts is label shift, where the marginal probabilities of the classes differ between the training and test sets while the class conditional feature distributions remain the same. With calibrated probabilistic predictions, label shift can be adjusted assuming access to class marginal probabilities . However, miscalibration combined with label shift is common and remains a challenging problem [2; 14; 47; 41].

In this paper, we aim to address these issues in a twofold manner. Firstly, we develop a unified framework for recalibration that incorporates both calibration and sharpness in a principled manner. Secondly, we propose a composite estimator for recalibration in the presence of label shift that converges to the optimal recalibration. Our framework enables the adaptation of a classifier to the label-shifted domain in a sample-efficient manner.

### Related work

Recalibration algorithms.Recalibration methods can be broadly categorized into parametric and nonparametric approaches. Parametric methods model the recalibration function in a parametric form and estimate the parameters using calibration data. Examples of parametric methods include Platt scaling , temperature scaling , Beta calibration , and Dirichlet calibration . However, it has been reported that scaling methods are often less calibrated than supposed, and quantifying the degree of miscalibration can be challenging . In contrast, nonparametric recalibration methods do not assume a specific parametric form for the recalibration function. These methods include histogram binning , isotonic regression , kernel density estimation [52; 42], splines , Gaussian processes , among others. Hybrid approaches, integrating both parametric and nonparametric techniques, have also been proposed. For instance, Kumar et al.  combine nonparametric histogram binning with parametric scaling to reduce variance and improve recalibration performance. Nevertheless, this hybrid approach is biased when its parametric assumptions fail. In this work, we consider a nonparametric histogram binning method called uniform-mass binning (UMB), which is asymptotically unbiased.

Histogram binning method.Histogram binning methods are widely used for recalibration due to their simplicity and adaptability. The binning schemes can be pre-specified (e.g., uniform-width binning ), data-dependent (e.g., uniform-mass binning ), or algorithm-induced . When selecting a binning scheme, it is crucial to consider the trade-off between approximation and estimation. Coarser binning reduces estimation error (variance), leading to improved calibration, but at the expense of increased approximation error (bias), which diminishes sharpness. Thus, determining the optimal binning scheme and hyperparameters, such as the number of bins (\(B\)), remains an active area of research.  proposes a Bayesian binning method, but verifying the priors is often challenging.  suggests choosing the largest \(B\) that preserves monotonicity, which is heuristic and computationally inefficient.  offers a heuristic for choosing the largest \(B\) subject to a calibration constraint, lacking a quantitative characterization of sharpness. Our work builds upon the existing upper bounds for calibration risks of binning methods [29; 20] and derived upper bounds for a complementary risk component known as the sharpness risk. We quantitatively characterize the calibration-sharpness tradeoff, which yields an optimal choice for the number of bins that achieves the minimum risk.

Adaptation to label shift.Label shift presents a challenge in generalizing models trained on one distribution (source) to a different distribution (target). As such, adapting to label shift has received considerable attention in the literature [12; 45; 31; 3; 2; 14]. In practical scenarios, it is common to encounter model miscalibration and label shift simultaneously [47; 41]. Empirical observations have highlighted the crucial role of probability calibration in label shift adaptation [2; 13], which is justified by subsequent theories . However, to the best of our knowledge, there has been no prior work that specifically addresses the recalibration with a limited amount of labeled data from the target distribution. Our theoretical analysis points out that using only target labels achieves risk bounds of the same order as the methods using only target features [31; 3; 14].

### Contributions

This paper contributes to the theory of recalibration across three key dimensions.

Firstly, we develop a comprehensive theory for recalibration in binary classification by adopting the mean-squared-error (MSE) decomposition framework commonly used in meteorology and space weather forecasting [5; 33; 8; 46]. Our approach formulates the probability recalibration problem as the minimization of a specific risk function, which can be orthogonally decomposed into calibration and sharpness components.

Secondly, utilizing the aforementioned framework, we derive a rigorous upper bound on the finite-sample risk for uniform-mass binning (UMB) (Theorem 1). Furthermore, we minimize this risk bound and demonstrate that the optimal number of bins for UMB, balancing calibration and sharpness, scales on the order of \(n^{1/3}\), yielding the risk bound of order \(n^{-2/3}\), where \(n\) denotes the sample size.

Lastly, we address the challenge of recalibrating classifiers for label shift when only a limited labeled sample from the target distribution is available, a challenging situation for a direct recalibration approach. We propose a two-stage approach: first recalibrating the classfier on the abundant source-domain data, and then transfering it to the label-shifted target domain. We provide a finite-sample guarantee for the risk of this composite procedure (Theorem 2). Notably, to control the risk under \(\), our approach requires a much smaller sample size from the target distribution than a direct recalibration on the target sample (\((^{-1})\) vs. \((^{-3/2})\), cf. Remark 4).

### Organization

This paper is organized as follows. In Section 2, we introduce notation and provide an overview of calibration and sharpness. Section 3 introduces the notion of minimum-risk recalibration by defining the recalibration risk that takes into account both calibration and sharpness. In Section 4, we describe the uniform-mass histogram binning method for recalibration and provide a risk upper bound with rate analysis. We extend our approach to handle label shift in Section 5. To validate our theory and framework, we present numerical experiments in Section 6. Finally, in Section 7, we conclude the paper with a discussion and propose future research directions.

## 2 Preliminaries

### Notation

Let \(\) and \(\) denote the set of positive integers and the set of real numbers, respectively. For \(n\), let \([n]:=\{1,,n\}\). For \(x\), let \( x=\{m:m x\}\). For any finite set \(=\{s_{i}:i[n]\}\) and any \(k[n]\), we let \(s_{(k)}\) denote the \(k\)-th order statistic, which is the \(k\)-th smallest element in \(\).

Let \((,,P)\) denote a generic probability space. For an event \(A\), the indicator function \(_{A}:\{0,1\}\) is defined such that \(_{A}(x)=1\) if and only if \(x A\). We write \(A\) happens \(P\)-almost surely if \(P(A)=1\). For a probability measure \(P\), define \(_{P}\) as the expectation, with subscript \(P\) omitted when the underlying probability measure is clear. For a probability measure \(P\) and a random variable \(X:^{d}\), let \(P_{X}:=P X^{-1}\) be the probability measure induced by \(X\).

Letting \(f,g:\), we write \(f(x)=O(g(x))\) as \(x\) if there exist \(M>0\) and \(x_{0}>0\) such that \(|f(x)| Mg(x)\) for all \(x x_{0}\). Likewise, we write \(f(x)=(g(x))\) if \(g(x)=O(f(x))\). We write \(f(x) g(x)\) if \(f(x)=O(g(x))\) and \(g(x)=O(f(x))\). We write \(f(x)=(g(x))\) if there is \(k 1\) such that \(f(x)=O(g(x)^{k}(g(x)))\).

### Calibration and sharpness

Consider the binary classification problem; let \(X\) and \(Y:=\{0,1\}\) denote the feature and label random variables. Letting \(P\) denote a probability measure, we want to construct a function \(f:=\) that estimates the conditional probability, _i.e._,

\[f(X) P[Y=1 X].\] (1)Since estimating the probability conditioned on the high dimensional \(X\) is difficult, the notion of calibration captures the intuition of (1) in a weaker sense [33; 9; 19].

**Definition 1**.: _A function \(f:\) is (perfectly) calibrated with respect to probability measure \(P\), if_

\[f(X)=P[Y=1 f(X)]\]

Calibration itself does not guarantee a useful predictor. For instance, a constant predictor \(f(X)=Y\) is perfectly calibrated, but it does not change with the features. Such a predictor lacks sharpness , also known as resolution , another desired property which measures the variance in the target \(Y\) explained by the probabilistic prediction \(f(X)\).

**Definition 2**.: _The sharpness of a function \(f:\) with respect to probability measure \(P\) refers to the quantity_

\[[Y f(X)]= [Y f(X)]-[Y]^{2}.\]

The following decomposition of the mean squared error (MSE) suggests why it is desirable for a classifier \(f\) to be calibrated and have high sharpness; note that \([]\) is a quantity intrinsic to the problem, unrelated to \(f\).

\[(f):=Y-f(X)^{2} }_{}=[Y]-( Y f(X))}_{}+f(X)-[Y f(X)]^{2}}_{ }\] (2)

## 3 Optimal recalibration

For an arbitrary predictor \(f:\), the aim of recalibration is to identify a post-processing function \(h:\) such that \(h f\) is perfectly calibrated while maintaining the sharpness of \(f\) as much as possible. The calibration and sharpness can be evaluated using the following two notions of risks. We suppress the dependency of risks on \(f\) and \(P\) when it leads to no confusion.

**Definition 3**.: _Let \(f:\) and \(h:\). The calibration risk of \(h\) over \(f\) under \(P\) is defined as_

\[R^{}(h)=R_{P}^{}(h;f):=_{P}[h  f(X)-_{P}[Y h f(X)]^{2}].\] (3)

**Definition 4**.: _Let \(f:\) and \(h:\). The sharpness risk of \(h\) over \(f\) under \(P\) is defined as_

\[R^{}(h)=R_{P}^{}(h;f):=_{P}[ _{P}[Y h f(X)]-_{P}[Y f(X) ]^{2}].\] (4)

Note that the calibration risk \(R^{}(h;f)=0\) if and only if \(h f\) is perfectly calibrated, cf. Definition 1. The sharpness risk \(R^{}(h;f)\) quantifies the decrement in sharpness of \(f\) incurred by applying the recalibration map \(h\), and \(R^{}(h;f)=0\) when \(h\) is injective .

Next we define a comprehensive notion of risk that we will use to evaluate recalibration functions.

**Definition 5**.: _Let \(f:\) and \(h:\). The recalibration risk of \(h\) over \(f\) under \(P\) is defined as_

\[R(h)=R_{P}(h;f):=_{P}[(h f(X)-_{P}[Y f(X)])^ {2}].\] (5)

The following proposition shows that the recalibration risk can be decomposed into calibration risk and sharpness risk. The proof is deferred to Appendix A.

**Proposition 1** (Decomposition of recalibration risk).: _For any \(f:\) and any \(h:\),_

\[R_{P}(h;f)=R_{P}^{}(h;f)+R_{P}^{}(h;f).\] (6)

Note that \(R_{P}(h)=0\) if and only if \(R_{P}^{}(h)=0\) and \(R_{P}^{}(h)=0\). This happens if and only if \(h f\) is calibrated, and the recalibration \(h\) preserves the sharpness of \(f\) in predicting \(Y\).

If \(R(h)=0\), then we call \(h\) an _optimal recalibration function_ (or _minimum-risk recalibration function_) of \(f\) under \(P\). Let \(h_{f,P}^{*}:\) be the function

\[h_{f,P}^{*}(z)=_{P}[Y f(X)=z],&\,P_{f(X)}$},\\ 0,&\,P_{f(X)}$}.\] (7)Then \(R(h^{*}_{f,P})=0\). Indeed, \(h\) is a minimum-risk recalibration function of \(f\) if and only if \(h=h^{*}_{f,P}\)\(P_{Z}\)-almost surely.

**Problem 1** (Recalibration).: _Suppose that we have a measurable function \(f:\) and a dataset \(=\{(x_{i},y_{i}):i[n]\}\) that is an independent and identically distributed (IID) sample drawn from \(P\). The goal of_ recalibration _is to estimate a recalibration function \( h^{*}_{f,P}\) using \(f\) and \(\)._

Problem 1 can be viewed as a regression problem, where we estimate the function form of \([Y Z]\) from data \(\{(z_{i},y_{i}):i[n]\}\), where \(z_{i}=f(x_{i})\), \( i[n]\).

## 4 Recalibration via uniform-mass binning

### Uniform-mass binning algorithm for recalibration

Given a dataset of prediction-label pairs \(\{(z_{i},y_{i}):i[n]\}\), the histogram binning calibration method partitions \(=\) into a set of smaller bins, and estimate \([Y Z]\) by taking the average in each bin. We consider the uniform mass binning, constructed using quantiles of predicted probabilities.

**Definition 6** (Uniform mass binning).: _Let \(S=\{z_{i}:i[n]\}\). A binning scheme \(=\{I_{1},I_{2},,I_{B}\}\) is the \(\) (UMB) scheme induced by \(S\) if_

\[I_{1}=[u_{0},u_{1}], I_{b}=(u_{b-1},u_{b}]\;\; b [B]\{1\},\] (8)

_where \(u_{0}=0\), \(u_{B}=1\), and \(u_{b}=z_{( nb/B)}\) for \(b[B-1]\)._

For our subsequent discussions, we make the following assumptions on the distribution of \(Y\) and \(Z\):

* The cumulative distribution function of \(Z\), denoted by \(F_{Z}\), is absolutely continuous.
* \(h^{*}_{f,P}\), defined in (7), is monotonically non-decreasing on \(P_{Z}\).
* There exists \(K>0\) such that if \(z_{1} z_{2}\), then \(h^{*}_{f,P}(z_{2})-h^{*}_{f,P}(z_{1}) KF_{Z}(z_{2})-F_{Z}(z_{ 1})\).

Assumption (A1) is made for the sake of analytical convenience without loss of generality; see discussions in [20, Appendix C]. An important implication of Assumption (A1) is that all intervals in \(\) are non-empty \(P_{Z}\)-almost surely if \(S=\{Z_{i}:i[n]\}\) are IID under \(P_{Z}\). Assumption (A2) makes sure \(Z\) is informative to preserve the rankings of \(P[Y Z]\). Lastly, Assumption (A3) posits that \(Z\) is sufficiently informative that \(P[Y=1 Z=z]\) does not change to rapidly in any interval \(I\) where \(P_{Z}(I)\) is small. This assumption is mild but not trivial; see Appendix B.2.

Now we describe how to construct a recalibration function \(\) using UMB.

**Algorithm.**

1. Given \(\{(z_{i},y_{i}):i[n]\}\), and \(B\), let \(=\{I_{1},I_{2},,I_{B}\}\) be the UMB scheme of size \(B\) induced by \(\{z_{i}:i[n]\}\).
2. Let \(=_{}:\) be a function such that \[(z)=_{I}_{I}_{I}(z) _{I}:=^{n}y_{i}_{I}(z _{i})}{_{i=1}^{n}_{I}(z_{i})},\;\; I.\] (9)

### Theoretical guarantees

Here we establish a high-probability upper bound on the recalibration risk \(R()\) for the UMB estimator, \(\) defined in (9), which converges to \(0\) as the sample size \(n\) increases to \(\).

**Theorem 1**.: _Let \(P\) be a probability measure and \(f:\) be a measurable function. Suppose that (A1) & (A2) hold. Let \(\) be the UMB scheme induced by an IID sample of \(f(X)\), and let \(=_{}\) be the recalibration function based on \(\), cf. (9). Then there exists a universal constant \(c>0\) such that for any \((0,1)\), if \(n c|||}{}\), then with probability at least \(1-\),_

\[R^{}()(|/ )}{2( n/||-1)}}+ |})^{2}, R^{}() |},\\ }{||^{2}}} holds}.}\]

**Remark 1**.: _We note that the upper bound on \(R^{}()\) in Theorem 1 coincides with the result presented in  up to a constant factor in the failure probability. However, Theorem 1 provides an additional upper bound on \(R^{}()\), thereby effectively managing the overall recalibration risk \(R()\)._

Optimal choice of the number of bins \(||\).Based on Theorem 1, for any fixed sample size \(n\), as the number of bins \(B=||\) increases, the calibration risk bound increases, while the sharpness risk bound decreases. This trade-off suggests we may get an optimal number of bins \(B\) by minimizing the upper bound for the overall risk, \(R()=R^{}()+R^{}()\).

For the simplicity of our analysis, we assume \(n\) is divisible by \(B\), and Assumption (A3) holds. Firstly, observe that \(n/B 2\), and thus, \(n/B-1 n/(2B)\). Also, since \(B 1\) and \(<1\), \(() 1\), it follows that \(()} ()}\). Thus, we obtain a simplified risk bound \(R()(B;n,)\) where \((B;n,):=()+}{B^{2}}\). With \( B\) terms ignored, minimizing \((B;n,)\) over \(B\) yields optimal \(B^{*}\) and resulting risk bounds, respectively:

\[B^{*} n^{1/3}^{-1/3}(1/),\] (10) \[R() R^{}() R^{}()=O({B^{*}}^{-2})=O({n}^{-2/3}^{2/3}(1/ )).\] (11)

Furthermore, the asymptotic risk bound in (11) implies that \(R()\), \(R^{}()\), and \(R^{}()\) are all bounded by \(\) with high probability if the sample size

\[n=(^{-3/2}).\] (12)

Comparison with the hybrid method .Kumar et al.  proposed a hybrid recalibration approach that involves fitting a recalibration function in a parametric family \(\), which is then discretized using UMB. Note that the hypothesis class \(\) may or may not include the optimal recalibration function \(h_{f,P}^{*}\). If \(h_{f,P}^{*}\), using a similar analysis as above, we derive their high probability risk bound as \(O(+})\) under Assumption (A3), which achieves \((n^{-1})\) when \(B^{*}\), exhibiting a faster decay than our \(R()=O(n^{-2/3})\). While the faster rate is anticipated from employing parametric methods, we note that when \(h_{f,P}^{*}\), their method exhibits inherent bias (approximation error) induced by parametric function fitting, whereas our method is asymptotically unbiased. This distinction is corroborated by numerical simulations in Appendix E.2.

Proof sketch of Theorem 1.First, we demonstrate that the uniform-mass binning scheme \(=\{I_{b}\}_{b=1}^{B}\) satisfies two regularity conditions with high probability, when the sample size \(n\) is not too small. Specifically, we show that (i) \(\) is 2-well-balanced  with respect to \(f(X)\), resulting in \(B\) bins having comparable probabilities (Lemma 3); and that (ii) the empirical mean in each bin of \(\) uniformly concentrates to the population conditional mean of \(Y\) conditioned on \(f(X)\) being contained within the bin (Lemma 4). Thereafter, we prove that if \(\) satisfies these two properties, then the calibration risk \(R^{}\) and the sharpness risk \(R^{}\) can be upper bounded as stated in Theorem 1; see Lemmas 5 and 6 (or Lemma 7 when (A3) holds). The detailed proof is in Appendix B.

## 5 Recalibration under label shift

This section extends the results from Section 4 to address label shift. In Section 5.1, we introduce the label shift assumption (Definition 7) and reframe the recalibration problem accordingly. We show that the optimal recalibration function in this context can be expressed as a composition of the optimal recalibration function (cf. Section 3) and a shift correction function. Building on this observation, we propose a two-stage estimator in Section 5.2, where each stage estimates one of the component functions. The composite estimator's overall performance is supported by theoretical guarantees.

### Revisiting the problem formulation

Let \(P\) and \(Q\) denote the probability measures of the source and the target domains, respectively. We assume \(P\) and \(Q\) satisfy the label shift assumption defined below.

**Definition 7** (Label shift).: _Probability measures \(P\) and \(Q\) are said to satisfy the label shift assumption if the following two conditions are satisfied:_

* \(P[X B Y=k]=Q[X B Y=k]\) _for all_ \(k\{0,1\}\) _and all_ \(B()\)_._
* \(P[Y=1](0,1)\) _and_ \(Q[Y=1](0,1)\)_._

According to Condition (B1), the class conditional distributions remain the same, while the marginal distribution of the classes may change. Condition (B2) requires all classes to be present in the source population, which is a standard regularity assumption in the discussion of label shift ; it also posits the presence of every class in the target population.

Optimal recalibration under label shift.Under the label shift assumption between \(P\) and \(Q\), we define the label shift correction function \(g^{*}:\) such that

\[g^{*}(z)=^{*}z}{w_{1}^{*}z+w_{0}^{*}(1-z)} w _{k}^{*}=,\ \  k\{0,1\}.\] (13)

The conditional probabilities under \(P\) and \(Q\) can be related  as follows:

\[Q[Y=1 X B]=g^{*}P[Y=1 X B], B ().\] (14)

Recall that the optimal recalibration function for a predictor \(f:\) under probability measure \(P\) is defined as \(h_{f,P}^{*}(z)=P[Y=1 f(X)=z]\); see (7). In the presence of a label shift between \(P\) and \(Q\), we may write the optimal recalibration function for \(f\) under \(Q\) as

\[h_{f,Q}^{*}=g^{*} h_{f,P}^{*}\] (15)

because \(h_{f,Q}^{*}(z)\ \ Q[Y=1 f(X)=z]\ \ g^{*}(P[Y=1 f(X)=z]\ )\ \ (g^{*} h_{f,P}^{*})(z)\), where (a) and (c) follows from the definition of \(h_{f,P}^{*}\) and (b) is due to (14).

Recalling the definition of the risk \(R_{P}(h;f)\) from (5), we observe that \(R_{Q}(h_{f,Q}^{*};f)=0\), which is consistent with the risk characterization of the optimal recalibration. Our goal is to estimate the optimal recalibration function \(h_{f,Q}^{*}=g^{*} h_{f,P}^{*}\) from data.

**Problem 2** (Recalibration under label shift).: _Suppose that we have a measurable function \(f:\) and two IID datasets \(_{P}=(x_{i},y_{i})_{i=1}^{n_{P}} P\) and \(_{Q}=(x_{i}^{},y_{i}^{})_{i=1}^{n_{Q}} Q\). The goal of_ recalibration under label shift _is to estimate \( h_{f,Q}^{*}\) using \(f\), \(_{P}\) and \(_{Q}\)._

**Remark 2**.: _The source (training) dataset \(_{P}\) may not be accessible due to privacy protections, proprietary data, or practical constraints, as is often the case when recalibrating a pre-trained black box classifier to new data. In these cases, it suffices to have estimates of the recalibration function \(h_{f,P}^{*}\) and the marginal probabilities \(P[Y=k],\ k\{0,1\}\) under \(P\), for our method and analysis._

### Two-stage recalibration under label shift

Method.We propose a composite estimator of \(h_{f,Q}^{*}=g^{*} h_{f,P}^{*}\), which comprises two estimators \( g^{*}\) and \(_{P} h_{f,P}^{*}\). Here we describe a procedure to produce this composite estimator.

1. Use \(_{P}\) to construct \(_{P}:\), the estimated recalibration function (9) (for \(f\) under \(P\)).
2. Use \(_{P}\) and \(_{Q}\) to construct \(:\) such that \[(z)=_{1}z}{_{1}z+_{0}(1-z)} _{k}=[Y=k]}{[Y=k]},\ \  k\{0,1\},\] (16) where \([Y=k]:=_{P}|}_{i=1}^{|_{P}|}[y_{i}=k]\) and \([Y=k]:=_{Q}|}_{i=1}^{|_{Q}|} [y_{i}^{}=k]\) are the empirical estimates of the class marginal probabilities.
3. Let \[_{Q}=_{P}.\] (17)

Note that the recalibration estimator \(_{P}\) (Step 1) remains the same with that in Section 4.1. Furthermore, the shift correction estimator \(\) (Step 2) is a plug-in estimator of the label shift correction function \(g^{*}\) in (14) based on the estimated weights, \(_{1}\) and \(_{0}\).

Theory.We present a recalibration risk upper bound for the proposed two-stage estimator. We let \(p_{k}:=P[Y=k]\), \(q_{k}:=Q[Y=k]\), and \(w^{*}_{k}=}{p_{k}}\) for \(k\{0,1\}\). Moreover, we let \(p_{}:=_{k}p_{k}\), \(q_{}:=_{k}p_{k}\), \(w^{*}_{}:=_{k}w^{*}_{k}\) and \(w^{*}_{}:=_{k}w^{*}_{k}\).

**Theorem 2** (Convergence of \(_{Q}\)).: _Let \(P,Q\) be probability measures and let \(f:\) be a measurable function. Let \(_{P} P\) be an IID sample of size \(n_{P}\) and \(_{Q} Q\) be an IID sample of size \(n_{Q}\). Suppose that Assumptions (B1) & (B2) hold. Let \(\) be the UMB scheme induced by \(_{P}\). Let \(_{P}=_{P,}\) be the recalibration function (9) based on \(\), and let \(\) denote the shift correction function as defined in (16). Then_

\[R_{Q}_{P} 2\{(- _{1}}{_{0}+_{1}})^{2}+_{}}^{3}}{{w^{*}_{ }}^{2}} R_{P}_{P};f\} _{k}:=_{k}}{w^{*}_{k}},\;\;k\{0,1\}.\] (18)

_Furthermore, suppose that (A1), (A2) & (A3) hold. Then there exists a universal constant \(c>0\) such that for any \((0,1)\), if_

\[n_{P}\{c,\;}\}|| (|}{}) n_{Q} }(),\]

_then with probability at least \(1-\),_

\[R_{Q}_{P} 2_{ }}^{3}}{{w^{*}_{}}^{2}}\{(/||-1)}(|}{})}+ /||})^{2}+}{| |^{2}}\}\\ +54\{ n_{P}},\;  n_{Q}}\}().\] (19)

**Remark 3**.: _Note that \(_{k} 1\) as \(n_{P},n_{Q}\), and thus, the upper bound (18) reduces to \(2_{}}^{3}}{{w^{*}_{}}^{2}} R_{P}_{P};f \). Moreover, when \(P=Q\), we have \(w^{*}_{}=w^{*}_{}=1\), and this further simplifies to the recalibration risk without label shift, up to multiplicative constant \(2\)._

**Remark 4** (Target sample complexity).: _Assume that \(n_{P} n_{Q}\) and the number of bins satisfies \(|| n_{P}^{1/3}\). Then (19) implies \(R_{Q}_{P};f=On_{P}^{-2/3}+n_{Q}^{-1} \). This result indicates that the proposed recalibration method using (17) requires a significantly smaller target sample size \(n_{Q}=(^{-1})\) to control the risk, as compared to \(n_{Q}=(^{-3/2})\) in (12)._

**Remark 5** (Comparison with label shift using unlabeled target data).: _When the source sample size \(n_{P}\) is sufficiently large, we achieve a risk of \(R_{Q}(_{P})=O(n_{Q}^{-1})\) with high probability. It is important to note that in this scenario, we only utilize the labels from the target sample to address label shift. Remarkably, the same rate applies when employing the algorithms proposed in , which solely rely on features from the target sample. For a proof sketch, please refer to Appendix D._

## 6 Numerical experiments

In this section, we present the results of our numerical simulations conducted to validate and reinforce the theoretical findings discussed earlier. The simulations are based on a family of recalibration functions called beta calibration : \(_{}=\{h_{}(z;a,b,c):a 0,b 0,c\}\), where \(h_{}(;a,b,c):\) is defined as

\[h_{}(z;a,b,c)=}{(1-z)^{b}} )}.\] (20)

In addition, consider the joint distributions \(()\) of \(X\) and \(Y\), where \(Y()\), \(X Y=0 N(-2,1)\), and \(X Y=1 N(2,1)\), and a pre-trained probabilistic classifier \(f(x)=(x):=1/(1+e^{-x})\). To accommodate the limitations of space, we summarize the results in Figure 1, 2, 3, and Table 1, 2, providing a concise overview. Detailed information about the simulation settings, implementation details, and further experimental results and discussions can be found in Appendix E. Our simulation code is available at https://github.com/ZeyuSun/calibration_label_shift.

Table 1: 90%-quantiles of the risks of Platt scaling , the hybrid method , uniform-width binning (UWB) , and uniform-mass binning (UMB) over 100 random calibration datasets drawn from \(Z\), and **(a)**\(Y Z(h_{}(z;4,4,0))\), or **(b)**\(Y Z(h_{}(z;0.1,4,0))\). While Platt scaling and the hybrid method achieve lower \(R\) under the correct parametric assumption, UWB and UMB may outperform when the parametric assumption fails.

Table 2: Risks under label shift from \((0.5)\) to \((0.1)\), with \(n_{P}=10^{3}\) and \(n_{Q}=10^{2}\). Standard deviations are computed from 10 random realizations. Label-Shift, only applying an injective \(\), achieves \(R^{}=0\) but incurs high \(R^{}\). Source, recalibrated with \(B=n_{P}^{1/3}\) on \(_{P}\), incurs high \(R^{}\). Target, recalibrated with \(B=n_{Q}^{1/3}\) on \(_{Q}\), incurs low \(R^{}\). Our proposed Composite achieves the lowest nonzero \(R^{}\) and lowest \(R^{}\).

Figure 1: Medians (solid lines) and 10-90 percentile ranges (shaded areas) of quadrature estimates of population risks over 10 realizations and theoretical risk upper bounds (\(=0.1\)) (dashed lines) for various \(n\) and \(B\). **(a)-(c)** The empirical rates, \(R^{}=O(n^{-0.99}B^{0.98})\) and \(R^{}=O(B^{-1.83})\), align with theoretically predicted rates, \((B/n)\) and \(O(B^{-2})\), in Thm. 1. **(d)** The empirically observed \(R\) and our upper bound exhibit similar trends as a function of \(B\).

Figure 2: The optimal number of bins \(B\) for different sample sizes \(n\) plotted in linear scale (_left_) and log scale (_middle_), and the population risk for various combinations of \(n\) and \(B\), with the optimal \(B\) marked by black dots (_right_). Note that the risk surface is relatively smooth around its minimum, suggesting the robustness of the optimal \(B\).

## 7 Discussion

This paper presents a comprehensive theory for recalibration, considering both calibration and sharpness within the mean-squared-error (MSE) decomposition framework. We use this framework to quantify the optimal calibration-sharpness balance and establish a rigorous upper bound on the finite-sample risk for uniform-mass binning (UMB). Additionally, we address the challenge of recalibration under label shift with limited access to labeled target data. Our proposed two-stage approach effectively estimates the recalibration function using ample data from the source domain and adjusts for the label shift using target domain data. Importantly, our findings suggest that transferring a calibrated classifier requires a significantly smaller target sample than recalibrating from scratch on the new domain. Numerical simulations confirm the tightness of the finite sample bounds, validate the optimal number of bins, and demonstrate the effectiveness of the label shift adaptation.

In concluding this paper, we identify several promising directions for future research.

Relaxation of the assumptionsIt would be worthwhile to explore whether or not the assumptions made in our analysis could be relaxed. For instance, the widely adopted monotonicity assumption (A2) and its variants  may not hold in real-world settings. Thus, exploring potential relaxations of this assumption is valuable. In addition, a mild but non-trivial smoothness assumption (A3) (c.f. Remark 7 and 8) is introduced to obtain a tight sharpness risk upper bound (c.f. Remark 9); investigating its practical implications and exploring potential relaxations could be interesting future work.

Calibration-sharpness framework analysisApplying our framework to analyze recalibration methods beyond UMB, such as isotonic regression  and kernel density estimation , can offer further insights into their performance and properties, providing guidance to practitioners in selecting suitable algorithms based on specific conditions and requirements.

Multiclass probability recalibrationThe concept of calibration considered in this work extends to multi-class classification settings, known as canonical calibration . Weaker, but more tractable notions of multi-class calibration have also been explored in the literature . While partition-based methods, as multi-class extensions of binning methods, are known to have consistency  and vanishing calibration error , establishing upper bounds for their sharpness risk remains difficult. Additionally, designing a partition scheme in a multidimensional space is a challenging task ; the interplay between calibration and sharpness could potentially guide the development of partition strategies that balance both aspects in multi-class classification.

Applications to real-world dataInvestigating the calibration-sharpness tradeoff in real-world applications, which often involve multiple classes, presents an interesting challenge. It is crucial to develop effective estimators for both calibration risk and sharpness risk in such scenarios. While estimators for calibration risk exist (e.g., binning-based and KDE-based)  and a lower bound for sharpness risk has been established , a direct estimator of sharpness risk is still lacking.

Figure 3: Optimal recalibration function \(h^{*}\) and recalibration function estimates by Platt Scaling , the hybrid method , UWB, and UMB when the parametric assumption is **(a)** correct and **(b)** misspecified. UMB traces the \(h^{*}\) in both cases, whereas the hybrid method traces Platt scaling, exhibiting an intrinsic bias from \(h^{*}\) in **(b)**.