# CryoGEM: Physics-Informed Generative Cryo-Electron Microscopy

Jiakai Zhang\({}^{1,2^{*}}\) Qihe Chen\({}^{1,2^{*}}\) Yan Zeng\({}^{1,2}\) Wenyuan Gao\({}^{1}\)

Xuming He\({}^{1}\) Zhijie Liu\({}^{1,3}\) Jingyi Yu\({}^{1}\)

\({}^{1}\)ShanghaiTech University

\({}^{2}\)Cellverse

\({}^{3}\)Human Institute

{zhangjk,chenqh2024, zengyan2024,gaowy,hexm,liuzhj,yujingyi}@shanghaitech.edu.cn

The authors contributed equally to this work.

###### Abstract

In the past decade, deep conditional generative models have revolutionized the generation of realistic images, extending their application from entertainment to scientific domains. Single-particle cryo-electron microscopy (cryo-EM) is crucial in resolving near-atomic resolution 3D structures of proteins, such as the SARS-COV-2 spike protein. To achieve high-resolution reconstruction, a comprehensive data processing pipeline has been adopted. However, its performance is still limited as it lacks high-quality annotated datasets for training. To address this, we introduce physics-informed generative cryo-electron microscopy (CryoGEM), which for the first time integrates physics-based cryo-EM simulation with a generative unpaired noise translation to generate physically correct synthetic cryo-EM datasets with realistic noises. Initially, CryoGEM simulates the cryo-EM imaging process based on a virtual specimen. To generate realistic noises, we leverage an unpaired noise translation via contrastive learning with a novel mask-guided sampling scheme. Extensive experiments show that CryoGEM is capable of generating authentic cryo-EM images. The generated dataset can be used as training data for particle picking and pose estimation models, eventually improving the reconstruction resolution.

## 1 Introduction

In the past decade, deep generative models like VAEs , GANs , and diffusion models  have achieved significant success in conditional image generation. Recently, Stable Diffusion  can produce high-quality images given simple textual descriptions. Additional controls  can be imposed to produce tailored visual effects, e.g., theatrical lighting  and specific perspectives . In fact, the successes of image generation have gone way beyond visual pleasantness, stimulating significant advances in scientific explorations. Examples include brain magnetic resonance imaging to computational tomography (MRI-to-CT) translation , X-ray image generation , etc. Different from entertainment applications, generation techniques for scientific imaging should faithfully follow the physical process: the generated results would eventually be applied to real-world downstream tasks such as medical image diagnosis. In this work, we extend image generation to a specific biomolecular imaging technique, single-particle cryo-electron microscopy (cryo-EM) to improve the performance of its downstream tasks. Cryo-EM aims to recover the near-atomic resolution 3D structure of proteins, with its latest application in recovering the SARS-COV-2 spike protein  structure for drug development.

As shown in Figure 1, a comprehensive data processing pipeline of single-particle cryo-EM starts with capturing transmission images of flash-frozen purified specimens, termed as _micrographs_, using high-energy electron beams. The complete dataset contains hundreds of thousands of images of target particles with unknown locations, poses, and shapes. The main challenge in cryo-EM is to accurately estimate the locations and orientations of particles in the extremely low signal-to-noise ratio (SNR), mainly caused by detector shot noise in limited dosage conditions and other structural noises such as global ice gradients. Thus, the performance of existing methods for particle picking  and pose estimation  are limited due to the lack of high-quality annotated training datasets, which are labor-intensive for human experts.

In this paper, we present a novel physics-informed generative cryo-electron microscopy (CryoGEM) technique, which is capable of generating authentic annotated synthetic datasets using just 100 unannotated micrographs from a real dataset. To achieve highly controllable generation results, we introduced a simple yet highly controllable physical simulation process. Based on the coarse density volume, we achieve control at both the particle level and the micrograph level. However, this physical simulation still lacks critical authentic noise modeling. We thus adopt unpaired image-to-image translation to generate authentic noises. Existing methods like CycleGAN  assume that the source and target domains are bijective; however, real cryo-EM micrographs have random noises, existing contrastive learning methods, such as contrastive unpaired translation (CUT) , relax these assumptions by using a random sampling strategy for positive and negative samples. However, in cryo-EM, the randomly sampled positives and negatives can be semantically similar since particles are densely located in a micrograph. To address these challenges, we employ a novel contrast noise translation to transform the simulated micrographs into authentic cryo-EM micrographs. Furthermore, we use a particle-background segmentation paired with the simulated result as a guide for positive and negative sample selection. We show that precise guidance on sample selection can significantly improve the quality of image generation.

We validate CryoGEM on five diverse and challenging real cryo-EM datasets. Extensive experiments show that CryoGEM achieves significantly better visual quality compared with state-of-the-art methods. Also, we demonstrate that the performance of existing deep models in downstream tasks, including particle picking and particle pose estimation, can be significantly improved by training on our synthetic dataset. Notably, we achieve 44% picking performance improvements, leading to 22% better resolution of final reconstruction on average.

Figure 1: **CryoGEM improves cryo-EM data analysis.** Cryo-EM captures images of molecules in vitrified ice via electron beams. Data is processed for a high-resolution 3D reconstruction by a comprehensive pipeline. However, some modules like (a) particle picking and (d) ab-initio 3D reconstruction still lack high-quality training datasets. Given a coarse result as an input, CryoGEM can synthesize authentic single-particle micrographs as training dataset augmentation.

Related Works

Our work aims to extend generation methods to the field of cryo-EM. We therefore only discuss the most relevant works in respective fields.

**Cryo-EM Pipeline.** In recent decades, the CryoEM pipeline has rapidly evolved. Popular software such as CryoSPARC , Relion , and Warp  has been widely used for high-resolution 3D reconstruction of macromolecules. Two critical steps are particle picking and pose estimation. To achieve accurate particle picking, recent neural methods [4; 10; 51; 11; 14; 56] have built upon several manually annotated real datasets or incorporated with few-shot learning techniques. However, they still lack generalization capability as the training dataset only covers a small portion of real scenarios. In pose estimation, traditional methods [70; 41] propose a Maximum-A-Posteriori (MAP) optimization by Expectation-Maximization (EM). Recent self-supervised models [28; 27; 67] have been adopted for ab-initio reconstruction, i.e., 3D reconstruction from particle images with unknown poses. However, their performance is still limited without further fine-grained refinement processes. We improve the performance of particle picking and pose estimation by generating high-quality annotated synthetic datasets as training datasets.

**Cryo-EM Simulations.** Theoretical simulation techniques, based on physical priors, combine atomic-level simulations with global projection to accurately compute electron scattering during the imaging process [63; 50; 45; 30; 32; 15]. Traditional simulation methods such as InsilicoTEM  model the interaction between electrons by taking specimens as multi-slices to improve the algorithm's performance. However, they typically require expensive computational resources and may require complex adjustments of parameters to achieve ideal results. Our work also includes an efficient physics-based simulation module to present the structural information of particles. Additionally, we generate realistic noises via a novel unpaired noise translation technique.

**Unpaired Image-to-image Translation.** Deep generative models including GAN-based methods [68; 61; 23; 29; 17] and diffusion models [46; 55] are widely used in unpaired image-to-image translation tasks. CycleGAN  introduces generative adversarial networks to calculate cycle consistency losses, allowing for training on unpaired data [20; 26; 38; 22]. TraVeLGAN , DistanceGAN , and GcGAN  achieve one-way translation while avoiding traditional cycle consistency. Diffusion models [7; 46; 34; 55; 64; 57; 40] have been recently introduced to unpaired image-to-image translation. But they often demonstrate results in low resolution and they often rely on a large-scale training dataset. Recently, Contrastive Unpaired Translation (CUT)  introduces a new generative framework via contrastive learning [21; 52; 65] to propose a more efficient training framework. However, existing methods do not combine the physical process as additional constraints. In contrast, our method includes a physical simulation during authentic cryo-EM micrograph generation.

## 3 Physics-informed Generative Cryo-EM

We propose CryoGEM, the first method to combine a physics-based simulation process with a novel contrastive noise generation technique (Figure 2). Our approach begins with preparing a virtual specimen containing numerous uniformly distributed target protein structures (Section 3.1). We then emulate the cryo-EM imaging process to introduce physical constraints (Section 3.2). To generate authentic cryo-EM noise, we use a novel unpaired noise translation technique via contrastive learning guided by a particle-background mask and detail the final objective during training. (Section 4)

### Virtual Specim Preparation

To simulate the cryo-EM imaging process, we first prepare the virtual specimen \(S(x,y,z)\), a large 3D density volume that contains multiple copies of the target molecule's coarse result with randomly generated locations, orientations, and conformations. To obtain the coarse result, we employ cryoSPARC  for ab-initio reconstruction, followed by cryoDRGN  for a continuous heterogeneous reconstruction to obtain a neural volume

\[V(,):^{3}^{8},\] (1)

where \(=(x,y,z)^{}^{3}\) represents the spatial coordinates, \(^{8}\) denotes a high-dimensional conformational embedding. This neural volume can generate a density volume given a learned conformational embedding following CryoDRGN . Notably, such a coarse result can be easily resolved, but the final result requires further iterative optimizations of selected particles, estimated particle poses, 3D templates, etc.

During the specimen preparation, we sequentially add \(N\) particles \(V(,)\) into an empty virtual specimen. During every addition, we randomly sample orientation matrices \(R_{i}^{3 3}\) from SO(3) space, random conformations \(_{i}\) from the learned conformational space, as well as translations \(_{i}^{3}\) from unoccupied areas of the virtual specimen. Both sampled orientations and locations can be further used as ground-truth annotations. Thus, the virtual specimen can be expressed as:

\[S(x,y,z)=_{i=1}^{N}V(R_{i}+_{i};_{i}),\] (2)

where the number of particles \(N(_{N},_{N}^{2})\), with the mean \(_{N}\) and standard deviation \(_{N}\) derived from the actual distribution of particle count in real micrographs. We ensure that the minimum \(N_{}\) and maximum \(N_{}\) values are within two standard deviations from the mean.

### Emulating the Imaging Process

We emulate the physical imaging process of cryo-EM including electron-specimen interaction, ice gradient, and cryo-EM optical aberration based on virtual specimen. For simplicity, we consider the complex electron-specimen interaction as an orthogonal projection of the specimen by applying the weak phase object approximation  (WPOA). To obtain the true ice gradients, we estimate them on real micrographs by IceBreaker , which can generate a weight map of ice, \(W(x,y)\), whose every pixel represents the attenuation ratio compared to the maximum value of intensity. Also, we model the optical aberrations as a point spread function (PSF) \(g\), which is the Fourier transform of the contrast transfer function (CTF), by off-the-shelf software CTFFIND4 . To sum up, the 2D physics-based result \(I_{}(x,y)\) can be expressed as:

\[I_{}(x,y)=g*[W(x,y)_{}S(x,y,z)z ].\] (3)

During the simulation process, we randomly select a pair of weight maps and PSF estimated from real micrographs.

## 4 Contrastive Noise Generation

Real cryo-EM micrographs contain high-level noises related to specimen-electron interaction and detector . Thus, accurate noise modeling is essential for authentic synthetic cryo-EM micrograph

Figure 2: **Pipeline of CryoGEM.** We begin by creating a virtual specimen containing various initial reconstruction results. We then simulate the imaging process of cryo-EM, incorporating physical priors such as ice gradient and point spread function (PSF) to generate a physical simulation. By adding simple Gaussian noise to the physically simulated results, we introduce randomness within a contrastive learning framework. To enhance training efficiency and performance, we use the particle background mask as a guide for patch sampling. The sampled positive and negative instances are then encoded into multi-scale features for contrastive learning. Additionally, we introduce an adversarial loss to ensure realistic cryo-EM image synthesis.

generation. We model the noise generation as an unpaired image-to-image translation task. The input, \(I_{} X\), learns the actual noise distribution from real cryo-EM images \(I_{} Y\), to generate synthetic cryo-EM images \(I_{}\). The generative model includes a discriminator \(D\), and a generator \(G=G_{} G_{}\), where \(G_{}\) is a encoder and \(G_{}\) is a decoder.

**Non-deterministic noise translation.** Existing contrastive learning methods such as CUT  have shown significant promise for efficient training and generating high-quality natural images. Nonetheless, they do not account for generating random noise in cryo-EM, i.e., they can only generate synthetic micrographs in a deterministic way, against the nature of the random noise generation process, leading to an unstable training process and degraded performance. To address this, we introduce a random process by adding a zero-mean Gaussian random noise \((0,^{2})\) into the physical simulations, where \(^{2}=(I_{phy})/\) (SNR equals to 0.1 in our experiments). We introduce an intermediate result \(I_{inter}=I_{phy}+\), where \(=X+(0,^{2})\). Thus, the synthetic image can be defined as:

\[I_{}=G(I_{inter})\] (4)

This simple strategy significantly improves our noise generation quality by constructing a mapping of a single physical simulation result to infinite synthetic noisy results with varied noise patterns.

**Mask-Guided sampling scheme.** A fundamental assumption of patch-wise contrastive learning is that the randomly chosen negatively sampled patches are semantically different from the positive samples . But in a single cryo-EM micrograph, hundreds of particles are densely distributed against an almost pure yet noisy background, which means that randomly chosen negative and positive patches are likely semantically similar. Taking advantage of our highly controllable physical simulation process, we introduce a mask-guided sampling scheme by generating a binary particle-background mask paired with \(I_{phy}\), denoted as \(M(x,y)\), where \(M(x,y)=1\) indicates a particle. Guided by this mask, our selection process can choose positive and negative samples from locations with contrasting mask labels. This significantly improves the encoder's performance, as shown in Figure 3, our encoder can generate accurate similarity maps given particles or backgrounds as references on real images, but CUT's encoder fails to recognize them.

**Mutual information extraction.** Guided by particle-background mask, we select \(Q\) paired patches in \(I_{}\) and \(I_{}\) as the positive samples and queries on particle region, respectively. We then choose \(K\) patches in \(I_{}\) as negative samples on the background region. The encoder \(G_{}\) maps these to normalized vectors \(=\{_{q}\}_{q=1}^{Q}\), \(^{+}=\{_{q}^{+}\}_{q=1}^{Q}\), and \(^{-}=\{_{k}^{-}\}_{k=1}^{K}\), respectively. Our objective is to maximize the likelihood of selecting a positive sample by minimizing the cross-entropy loss:

\[(,^{+},^{-})=-_{q=1}^{Q}[_ {q}_{q}^{+}/)}{(_{q}_{q}^{+}/)+_{k =1}^{K}(_{q}_{k}^{-}/)}],\] (5)

where \(\) is a temperature factor that scales the distance between the query and samples.

**Mask-guided patch-wise contrastive learning.** We leverages multiple intermediate layers of \(G_{}\) to extract multi-scale features from input patches. Notably, we align the receptive field with particle size by selecting the \(G_{}\)'s first \(L\) layers. Feature map from each layer is then passed through

Figure 3: **Visualization of the learned similarity. Given query patches (red for particle and blue for background) on the input real micrograph, we visualize the learned similarity maps of our and CUT’s encoders \(G_{enc}\) by calculating \((G_{enc}(v) G_{enc}(v^{-})/)\), where \(v\) denotes the query and \(v^{-}\) denotes the patches of real micrograph. The results imply that our encoder can recognize particles and backgrounds in real cryo-EM micrographs. However, CUT fails to learn that without the guidance of particle-background maps during training.**

compact two-layer MLP networks \(H_{l}\) (\(l\{1,2,...,L\}\)) to generate a feature \(_{l}=H_{l}(G_{}^{l}(I_{}))\), where \(G_{}^{l}\) is the \(l\)-th layer. We define those on particles as \(p P\), and those on the background as \(b B\). The feature of \(l\)-th layer at a particle position \(p\) is denoted as \(_{l}^{p}\), and the set represented as \(_{l}^{P}=\{_{l}^{p}\}_{p P}\). Similarly, for background positions, we denote the \(l\)-th layer feature as \(_{l}^{b}\), with the set represented as \(_{l}^{B}=\{_{l}^{b}\}_{b B}\). Features encoded from the output \(I_{}\) are represented as \(}\), where \(}_{l}=H_{l}(G_{}^{l}(I_{}))\). We propose a novel mask-guided Noise Contrastive Estimation (NCE) loss for efficient contrastive learning in cryo-EM:

\[_{}(G,H,)=_{I_{}}_{l=1}^{L}_{p P}(_{l}^{p},}_{l}^{p},}_{l}^{B})+_{b B}(_{l}^ {b},}_{l}^{b},}_{l}^{P}).\] (6)

By minimizing \(_{}\), we effectively differentiate particle and background features (Figure 3).

**Final objective.** We introduce an adversarial loss function, \(_{}\), to encourage the network to produce more realistic simulated cryo-EM images, \(I_{}\), as follows:

\[_{}(G,D,,Y)=_{I_{} Y}[ D(I_{})]+_{I_{}}[ (1-D(G(I_{})))].\]

Combining this with the contrastive learning loss \(_{}\), the overall training loss function is:

\[_{}(G,D,,Y)+_{}(G,H,),\] (7)

we set the hyper-parameter \(\) to \(10.0\) in all our experiments.

## 5 Experiments

Datasets.We evaluate CryoGEM across five challenging cryo-EM datasets. Each includes expert-curated particle-picking annotations for high-resolution reconstruction of target molecules. Note that the particle annotations in the dataset are solely used for validation of downstream tasks and

Figure 4: **Result gallery. The first row showcases the diverse synthetic contents generated by CryoGEM (from left to right for Proteasome, Ribosome, Integrin, PhageMS2, and HumanBAF). The second, third, and fourth rows demonstrate CryoGEM’s ability to control the particle’s pose, conformation, and defocus during the image generation. In every row, the leftmost column is the clean particle image, and the controlled variable is smoothly adjusted from left to right.**

are not utilized during the training phase of our CryoGEM model. 1) T20S **Proteasome** (EMPIAR-10025) ' micrographs exhibit a high density of particles, leading to occlusions. posing significant challenges in particle picking. Also, the 3D structure is D7 symmetric, which brings ambiguities in the pose estimation task. 2) 80S **Ribosome** (EMPIAR-10028)  has a complex 3D structure, making it difficult to estimate the poses of particle images. 3) Asymmetric \(\)V\(\)8 **Integrin** (EMPIAR-10345)  contains molecules with varied conformations, requiring a heterogeneous reconstruction. 4) **PhageMS2** (EMPIAR-10075) 's micrographs contain enormous spherically-shaped virus particles, suitable for testing the generalizability of the particle picking model. 5) Endogenous **HumanBAF** complex (EMPIAR-10590)  has significant ice gradient artifacts. We kindly refer to Appendix B for a more detailed dataset description and illustration.

**Baselines.** We evaluate the performance of CryoGEM compared to several traditional noise baselines and deep generative models. We use **Poisson** noise to simulate the high-level detector shot noises in cryo-EM images, **Gaussian** noise for a general simplified noise modeling in cryo-EM, and Poisson-Gaussian mixed noise (**Pos-Gau**) as traditional baselines. We choose **CycleGAN**, **CUT**, and recent **CycleDiffusion** as deep generative baselines. In Appendix C, we detail their specific settings.

**Implementation details.** All experiments are conducted on a single NVIDIA GeForce RTX 3090 GPU. As a lightweight model, CryoGEM trains 100 epochs on a single dataset within an hour using less than 10 GB of memory. The training dataset (all held out for the evaluation) is comprised of 100 real images alongside 100 physics-based simulated results. We enhance the dataset through

  Metric & _{1}\)} \\ Dataset & Proteasome & Ribosome & Integrin & PageRankS2 & HumanBAF & Avg. \\  Gaussian & 89.87 & 177.01 & 174.94 & 162.81 & 46.48 & 130.22 \\ Poisson & 112.40 & 86.88 & 173.94 & 343.16 & 44.17 & 152.11 \\ Pol-Gau & 93.41 & 73.89 & 173.64 & 311.50 & 45.55 & 139.60 \\ CycleGAN & 89.33 & 27.73 & 54.83 & 422.80 & 137.41 & 146.42 \\ CUT & 46.61 & 44.23 & 49.96 & 85.65 & 74.36 & 60.84 \\ CycleDiffusion & 470.37 & 173.62 & 368.63 & 468.83 & 57.46 & 415.42 \\  Ours & **42.96** & **6.54** & **42.46** & **63.11** & **34.50** & **37.91** \\  

Table 1: **Quantitative comparison of visual quality.** Our approach consistently achieves the best performance in FID metric.

Figure 5: **Qualitative comparison results.** Our approach achieves the most authentic noise generation across all datasets. The traditional noise models succeed in preserving the structural information while lacking realistic noise patterns. CycleGAN, CUT, and CycleDiffusion introduce severe artifacts on generated results.

data augmentation, specifically by rotating the images by 90, 180, and 270 degrees. Please see Appendix B for more details. We choose PatchGAN  as our discriminator and UNet implemented by  as our generator. We fix the image resolution to \(1024 1024\) during training. Guided by the particle-background mask, we evenly sample 256 queries on particles and 256 on the background, ensuring that their corresponding negative samples are located where the labels are opposite.

### Visual Quality

In Figure 4, we demonstrate CryoGEM's ability to generate diverse content through multi-level controls, including adjustments to the ice gradient and defocus values of micrographs, as well as the particles' positions, orientations, and conformations. We then evaluate CryoGEM's visual quality compared to baselines. As illustrated in Figure 5, our approach consistently achieves the best qualitative results across all datasets in terms of overall noise patterns and the preservation of particle structural information. Traditional methods fail to mimic authentic noise distributions. CycleGAN struggles with convergence due to the breakdown of its bijection assumption. CUT can achieve better visual quality but its performance is still limited due to its random sampling scheme. CycleDiffusion cannot learn the the authentic noise patterns. As shown in Table 1, we also employed Frechet Inception Distance (**FID**) which is widely used in generative tasks to measure the similarity between generated and real data. Our results significantly outperform existing baseline methods in all five datasets. For additional conditional generated and zero-shot results, please refer to Figure 10 in the appendix.

### Particle Picking

To evaluate how CryoGEM can enhance downstream particle picking task, we finetune the popular particle picking model **Topaz** using synthetic annotated datasets from different baselines. Our

   & \))} &  \\  Dataset & Photosome & Exposure & Imgen & PrigogNet & HumanRAF & Avg. & Precision & Ristome & Imgen & PrigogNet & HumanRAF & Avg. \\  Gaussian & 0.471 & 0.483 & 0.259 & 0.886 & 0.470 & 0.514 & 2.76 & 3.84 & 7.62 & 7.44 & 10.29 & 6.97 \\ Person & 0.469 & 0.375 & 0.213 & 0.490 & 0.853 & 0.066 & 2.77 & 4.16 & 7.52 & 10.80 & 10.67 & 7.12 \\ Pat-On & 0.455 & 0.681 & 0.210 & 0.760 & 0.381 & 0.474 & 2.30 & 3.87 & 8.13 & 10.90 & 13.18 & 7.77 \\ CycleGAN & 0.200 & 0.388 & 0.444 & 0.895 & 0.228 & 0.490 & 5.30 & 3.93 & 6.03 & 7.51 & 11.83 & 7.28 \\ CUT & 0.442 & 0.224 & 0.353 & 0.592 & 0.513 & 0.421 & 2.77 & 4.78 & 7.16 & 8.91 & 12.22 & 7.30 \\ CycleDiffusion & 0.346 & 0.205 & 0.235 & 0.490 & 0.592 & 0.529 & 3.52 & 4.65 & 6.59 & 5.68 & 6.64 \\  Total & 0.592 & 0.679 & 0.550 & 0.579 & 0.565 & 0.566 & 3.73 & 3.84 & 6.54 & 10.07 & 5.99 & 6.71 \\ Ours & **0.490** & **0.577** & **0.606** & **0.915** & **0.582** & **0.674** & **2.80** & **3.25** & **5.54** & **7.16** & **7.34** & **5.27** \\  

Table 2: **Quantitative comparison of particle picking. Our approach consistently achieves the best in AUPRC and Res(A) metrics.**

Figure 6: **Qualitative comparison results of particle picking. The blue circles indicate matches with manual picking results, while the red circles represent misses or excess picks by the model.**

approach outperforms the original Topaz and other baseline methods in terms of the quality of visual picking results. As illustrated in Figure 6, the fine-tuned Topaz model is employed to select particles across five datasets. The original Topaz often mistakenly picks false particles from contaminants, particle aggregations, and ice patches. Our fine-tuned Topaz significantly improves accuracy by reducing the incidence of false positives and redundant particle picks. Table 2 presents the quantitative particle picking results, where we utilize the Area Under the Precision-Recall Curve (**AUPRC**) metric that is widely used as particle picking metric [4; 51]. For the calculation of the AUPRC score, we retain the original particle-picking results for comparison against the ground truth labels, without any thresholding. The quantitative comparison shows that the finetuned Topaz using our data achieves the best performance across all datasets. We also show that our final reconstruction resolution (**Res(A)**) is significantly improved using cryoSPARC 's default reconstruction pipeline. Finally, we present the coarse volumes used for CryoGEM training, the final resolved structures from CryoGEM picked particles, and the FSC curves from different baselines in Figure 7.

### Pose Estimation

In the cryo-EM reconstruction pipeline, the accuracy of pose estimation is crucial for the resolution of the final reconstruction. Existing cryo-EM ab-initio methods, such as CryoFIRE , leverage a self-supervised learning framework to predict particle poses and reconstruct 3D volume from images simultaneously. Given synthetic datasets generated from different baselines, we directly supervise its pose estimation module by minimizing the quadratic error between the matrix entries in the prediction and ground truth. The details of direct supervision and the evaluation metrics as well as the visualization of improved structures (Figure 14) can be found in Appendix C.3. We evaluate the pose estimation module on real datasets to obtain estimated poses as ground truths. We use a traditional reconstruction algorithm, filter back-projection (FBP), to obtain final reconstruction results. As demonstrated in Table 3, the pre-trained pose estimation module using our data consistently achieves the best performance in terms of pose accuracy (rotation error in radian) and reconstruction resolution (in pixel).

  Metric &  &  \\  Dataset & Proceasome & Ribosome & Integrin & PogogAR & HumanBAT & Avg. & Proceasome & Ribosome & Inception & PogAR52 & HumanBAT & Avg. \\  Gaussian & 2.97 & 4.59 & 7.01 & 5.83 & 6.82 & 5.44 & 0.48 & 0.50 & 1.20 & 0.64 & 1.49 & 0.38 \\ Poisson & 3.02 & 4.912 & 7.01 & 5.98 & 8.03 & 5.79 & 1.20 & 0.90 & 1.19 & 0.69 & 1.47 & 1.10 \\ Pot-Gua & 3.02 & 4.39 & 9.06 & 5.90 & 8.12 & 6.09 & 1.05 & 0.39 & 1.40 & 0.61 & 1.43 & 0.98 \\ CyclGAN & 3.02 & 4.74 & 6.24 & 5.71 & 6.91 & 5.32 & 0.46 & 0.61 & 1.55 & 0.74 & 1.48 & 0.97 \\ CUT & 2.66 & 5.40 & 6.13 & 6.03 & 9.58 & 5.96 & 0.44 & 1.15 & 1.53 & 0.66 & 1.45 & 1.05 \\ CyclDiffusion & 3.61 & 5.79 & 8.5 & 5.91 & 9.33 & 6.62 & 0.44 & 1.42 & 1.55 & 0.58 & 1.53 & 1.10 \\  CryoFIRE & 3.94 & 16.92 & 13.87 & 17.23 & 6.93 & 12.18 & 1.35 & 0.64 & 0.93 & 0.75 & 1.53 & 1.10 \\  Ours & **2.59** & **4.27** & **4.88** & **5.54** & **6.56** & **4.29** & **6.41** & **6.32** & **0.88** & **0.43** & **1.42** & **0.69** \\  

Table 3: **Quantitative comparison of pose estimation.** Our approach achieves the best performance in Res(px) and Rot.(rad) metrics.

Figure 7: **Evaluation of CryoGEM’s picked results on 3D Reconstruction.** We present both the initial coarse inputs from CryoGEM and the final refined structures, with particles selected using CryoGEM’s refined particle picking model. Additionally, we provide a quantitative comparison of the reconstruction results across various baselines. The resolution of each reconstruction is evaluated using the Fourier Shell Correlation (FSC) criterion (threshold=0.143 for real datasets).

### Ablation Study

We validate the effectiveness of our several key designs on the Ribosome dataset.

**Physical priors.** We denote the variation of our model without physical priors as **w/o Physical Priors**. Results imply that the physical priors narrow the domain gap between simulated results and real micrographs.

**Introducing randomness.** We introduce randomness by different kinds of noises, such as introducing feature-level noise in the encoder's third layer (**Third Layer Noise**) and fifth layer (**Fifth Layer Noise**). Additionally, we treat random noise as a second input channel, which may potentially preserve the content of physical simulation better (**Second Channel Noise**). Also, we demonstrate the impact of noise scaling relative to the signal with **SNR=0.01** and **SNR=1.0**. Additionally, we remove the Gaussian noise (**w/o Gaussian Noise**) to validate the effectiveness of this randomness.

**Sampling scheme.** We use a particle background mask to guide sampling in the contrastive learning process. For accurate particle position and shape control, the generator must preserve the input image's content. If we sample positives only in the background, the mutual information between particles can only be optimized indirectly, leading to inaccurate particle positions and shapes (**w/o Particle**). Conversely, sampling positives only in particles results in less realistic noise patterns (**w/o Background**). We also present the results without the mask-guided sampling scheme (**w/o Mask Guide**), which includes only the physics-based module and input domain randomness.

**Training efficiency ablation.** In the right of Figure 8, we validate that our method can generate realistic cryo-EM images with fewer samples compared to baselines in terms of FID. Notably, some high FID outliers indicate that removing the mask-guided sampling scheme or ignoring the physics-based module can decrease training stability.

## 6 Conclusion

**Limitations.** As the first trial to achieve authentic cryo-EM image generation with a novel combination of physics-based simulation and unpaired noise translation via contrastive learning, CryoGEM does have room for further improvements. First, our physics-based simulation relies on a coarse result as an input, which may be hard to obtain in some challenging cases, e.g., when the target molecule is very small or dynamic. The latest AlphaFold 3  can help predict the structure directly. Furthermore, we sacrifice the generalization capability for a lightweight training framework. In the future, we will train a generalized version of CryoGEM to unlock more real applications.

**Conclusion.** We have presented the first generative approach in cryo-EM image synthesis, CryoGEM, that marries physics-based simulation with a contrastive noise generation, to enhance downstream deep models, finally improving cryo-EM reconstruction results. Extensive experiments have shown that CryoGEM's generated dataset with ground-truth annotations can effectively improve particle picking and pose estimation models, eventually improving reconstruction results. We believe that CryoGEM serves as a critical step for high-fidelity cryo-EM data generation using deep generative models, with diverse applications of structure discovery in in cryo-EM.

Figure 8: **Quantitative evaluation of ablation study. Our complete model consistently achieves the best or second performance across all metrics, as shown in the left table. It demonstrates stable and efficient training compared to CycleGAN, CUT, and the ablation without Mask Guide (w/o Mask Guide), as illustrated in the right figure.**Acknowledgement

This work was supported by ShanghaiTech University's HPC Platform. We would like to thank the Cellverse team for their valuable discussions. We also extend our gratitude to Yutong Liu for contributing to the design of Figure 1.