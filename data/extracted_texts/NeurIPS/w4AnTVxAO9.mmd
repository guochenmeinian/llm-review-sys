# Can Language Models Learn to Skip Steps?

Tengxiao Liu\({}^{}\)\({}^{}\)\({}^{}\) & Qipeng Guo\({}^{}\) & Xiangkun Hu\({}^{}\) & Cheng Jiayang\({}^{}\)

Yue Zhang\({}^{}\)\({}^{}\) & Xipeng Qiu\({}^{}\)\({}^{}\) & Zheng Zhang\({}^{}\)

\({}^{}\)Fudan University & UC Santa Barbara & Shanghai AI Laboratory

\({}^{}\)Westlake University & Amazon AWS AI

tengxiao@ucsb.edu zhangyue@westlake.edu.cn xpatiu@fudan.edu.cn zhaz@amazon.com

Work done during internship at AWS Shanghai AI Lab.Corresponding authors.

###### Abstract

Trained on vast corpora of human language, language models demonstrate emergent human-like reasoning abilities. Yet they are still far from true intelligence, which opens up intriguing opportunities to explore the parallels of humans and model behaviors. In this work, we study the ability to skip steps in reasoning--a hallmark of human expertise developed through practice. Unlike humans, who may skip steps to enhance efficiency or to reduce cognitive load, models do not inherently possess such motivations to minimize reasoning steps. To address this, we introduce a controlled framework that stimulates step-skipping behavior by iteratively refining models to generate shorter and accurate reasoning paths. Empirical results indicate that models can develop the step skipping ability under our guidance. Moreover, after fine-tuning on expanded datasets that include both complete and skipped reasoning sequences, the models can not only resolve tasks with increased efficiency without sacrificing accuracy, but also exhibit comparable and even enhanced generalization capabilities in out-of-domain scenarios. Our work presents the first exploration into human-like step-skipping ability and provides fresh perspectives on how such cognitive abilities can benefit AI models.

## 1 Introduction

The pursuit of Artificial General Intelligence (AGI) is profoundly influenced and inspired by human intelligence . Trained extensively on human language, language models not only excel in various tasks, but also begin to exhibit emergent human-like abilities that are not explicitly engineered into them . Among these, reasoning stands out as a core human-like cognitive ability, and has demonstrated great potential in a wide range of problem solving scenarios . Despite their advances in displaying human-like cognitive activities, huge gaps remain in how models and humans actually behave . These differences bring up interesting questions regarding the exploration and development of similar capabilities between models and humans.

We aim to investigate whether the models exhibit any reasoning abilities unique to human experts, and whether they can evolve from beginners to reasoning experts. When humans learn to reason, beginners typically start with detailed, step-by-step solutions to imitate the gradual process of problem solving. As practice makes perfect, human experts not only solve problems more swiftly but also utilize shorter mental pathways, often skipping steps in their reasoning process . This particular ability helps them speed up the reasoning and saves cognitive load for more challenging steps . As demonstrated in Figure 1, the step-skipping behavior illustrated on the right side is commonly adopted by human experts during equation simplification.

In this work, we are curious whether models exhibit mature human-like reasoning ability -- skipping steps, and how such abilities can influence the model's reasoning behaviors. Unlike humans, models do not inherently possess the intrinsic motivation like time limit or skill maturity that naturally drives efficiency in cognitive tasks. To induce the skipping step behavior in models, we introduce a controlled training environment where models are instructed to generate reasoning sequences within a specified number of steps. Our method includes two phases: _initialization_ and _iteration_. We begin with a dataset that contains complete stepwise reasoning processes for the questions. In initialization, models are first trained to solve the tasks comprehensively, adhering to the full sequence of reasoning steps. In Figure 1, the illustration on the left demonstrates how models are trained to follow a specified number of steps. Then in the iteration phase, the models are prompted to produce shorter answers based on the original training data (Figure 1 right). We then select the shorter reasoning paths that still achieve correct answers and mix them with the full-step reasoning paths. This expanded dataset is used to train a new model to have advanced step-skipping capabilities. Each iteration refines the model's ability to identify how steps can be skipped without sacrificing accuracy. Finally, we fine-tune the models using these iteratively generated datasets, including data instances that demonstrate successful step-skipping during each iteration.

We conduct experiments with three different reasoning datasets, each characterized by clear internal reasoning steps, to evaluate model behaviors. Empirical results demonstrate that models exhibit and develop the ability of skipping steps in our framework - not only solving tasks effectively but also actively omitting steps to enhance efficiency. Further analysis of model behaviors indicate that these skipped reasoning paths act as beneficial enhancements rather than mere biased shortcuts, as evidenced by their maintenance or even improvement of out-of-distribution (OOD) performance across various tasks. To the best of our knowledge, this work is the first investigation into the human-like ability of step-skipping in language models, providing empirical evidence that models can indeed skip steps. These preliminary findings provide a fresh perspective on easy-to-hard generalization -- training models on simpler data comprising both comprehensive and skipped reasoning steps can enhance their ability to generalize to more complex scenarios. ++

Footnote ‡: Code and data are publicly available at: https://github.com/tenxiaoliu/LM_skip.

## 2 Related Work

Human-like Abilities in Language ModelsMany of the capabilities widely used in current models are inspired by human intelligence. For instance, in-context learning enables models to address problems by mimicking the patterns demonstrated in examples . In reasoning tasks, models benefit from progressively answer derivations and step-by-step chain-of-thought processes  and their humanlike enhancements, such as planning , task decomposition , and refinement [32; 38]. Another series of studies explore from the perspectives of cognitive science and psychology [10; 2; 12; 9]. Kosinski  reveal that current large language models have demonstrated a certain level of Theory-of-Mind (ToM) abilities by testing their performance to impute another's mental states and perspectives. Further studies  provide preliminary evidence of a correlation between the embeddings in LLMs and human brain neurons during ToM tasks, while Ma et al.  highlights the limitation of current ToM evaluations as they target narrow and inadequate aspects of ToM. Apart from these cognitive abilities, our work draws inspiration from human problem solving [23; 42; 3; 44] and evaluates language models on these unique step skipping behaviors. Additionally, our work aligns with an expanding field exploring the correlation between System 1 and System 2 reasoning

Figure 1: Step skipping in equation simplification. We use the specified number of steps in the input as a stimulation to induce the model to perform skipping by using fewer steps.

mechanisms [14; 15; 49]. Rather than removing all reasoning trajectories, our work explores gradual shortening to provide a smoother transition that mirrors natural cognitive processing.

Compositional Generalization ChallengesTransformers have shown limitations in complex compositional generalization scenarios [17; 39]. Previous work also indicates that models may develop biased shortcut, negatively impacting their OOD performance [27; 25; 16]. A growing body of research focuses on easy-to-hard generalization [4; 7; 19; 41; 48], where models improve their generalization ability by learning from easy tasks, without requiring intensive supervision on harder ones. Following this line, our work encourages the model to learn from self generated skipping paths, which has been empirically shown to maintain and even enhance OOD generalization capabilities.

## 3 Method

Humans develop the ability to skip steps for several reasons. With practice in specific tasks, they evolve from novices to experts, optimizing lengthy thought processes into quicker, more efficient reasoning. Additionally, factors such as time constraints or the desire to conserve cognitive resources can also prompt humans to skip steps . In contrast, models lack an inherent cognitive signal that would drive them to minimize reasoning steps. Rather than attempting to replicate these human-like signals, we design a training approach to directly control the number of steps in their reasoning processes. By restricting the steps in model responses, we can guide the model to self-generate data including skipped steps. Our framework has two phases: initialization and iteration.

### Initialization

We begin with a training dataset \(D_{0}\), which contains detailed full-step reasoning answers to the questions. Our goal is to train a model that can generate answers by following the specified number of steps in the input question. Depending on the characteristics of different tasks, there are two design choices to initialize the framework: cold start and warm start.

Cold startIn the cold start approach, we directly fine-tune the model on the original full-step training data, i.e., \(D_{}=D_{0}\). The trained model is expected to not only learn to solve the problems, but also adhere to the specified number of steps in the input instructions.

Warm startTraining exclusively with full steps does not always guarantee the ability of controlling the number of steps, especially for the challenging tasks. Therefore, we manually create answers that contain skipped steps based on human expertise. Optionally, we can also randomly merge adjacent steps or simply omit random steps within the rationales to create such skipped-step data. In either way, we can expand the original training set with additional data \(D_{}\) that can better help models

Figure 2: Overall framework. The initialization phase aims to equip the model with the ability to reason according to a specified number of steps. During iterations, each cycle produces a mixed dataset \(D_{i}\), which is used to train a standard model to evaluate the model’s step-skipping capabilities.

learn how to solve the problems with fewer steps. Thus, the data for warm start initialization can be describes as \(D_{}=D_{0}+D_{}\).

Using the prepared data, we fine-tune the model to generate the answers with the given number of steps. For each QA pair in \(D_{}\), the question \(q\) is concatenated with the instruction \(I_{n}\) which indicates that the reasoning process \(a^{(n)}\) should be completed in \(n\) steps. Therefore, the resulting model in the initialization phase, \(M_{0}\), is described as:

\[M_{0}=_{(q,a^{(n)}) D_{0}}P(a^{(n)}|q,I_{n}),\] (1)

where the instruction \(I_{n}\) stands for "Solve it in \(n\) steps".

### Iteration

After the initialization, the model is expected to have learned to solve the problems with detailed steps using the specified number of steps in the input. Leveraging this particular ability, we can encourage the model to actively engage in step skipping behavior. At the beginning of each iteration \(k\), the model \(M_{k-1}\) is prompted to solve the same problems in the training set using fewer steps than the full number. Responses that are both correct and meet the reduced step criterion are filtered and composed into a new dataset \(D^{}_{k}\). These reasoning answers are generated solely by the model itself, reflecting its understanding after training on the initialized data and demonstrating its active preferences when reducing steps.

We define the dataset used for current iteration as \(D_{k}=D_{0} D^{}_{k-1}\), where the original training set \(D_{0}\) includes full reasoning steps and the filtered dataset \(D^{}_{k-1}\) contains new responses that successfully utilized fewer steps. This ensures that the model has access to both the original complete reasoning processes and examples of effective step-skipping generated by the model itself. To finalize current iteration, the model \(M_{k}\) is trained on \(D_{k}\): \(M_{k}=_{(q,a^{(n)}) D_{k}}P(a^{(n)}|q,I_{n})\).

The iterative training process described above requires specifying the number of steps in the input, which is impractical in real-world applications because it can be difficult to determine the exact number of steps needed for a given question. To be more applicable, we aim to understand how models learn from the generated skipped data and what benefits they can derive from it. Therefore, for each intermediate resulting dataset \(D_{k}\), we train a new model using a standard QA finetuning setting without specifying the number of steps in the input:

\[M_{k}^{}=_{(q,a^{(n)}) D_{k}}P(a^{(n)}|q).\] (2)

This phase aims to solidify the model's skipping behavior, simulating a more advanced form of cognitive processing akin to human reasoning.

## 4 Experiments

### Datasets

We design three tasks to investigate the model's step skipping behavior (Figure 3). In each task, the intermediate steps needed to solve these problems are explicitly detailed and well-defined, facilitating a clear analysis of the model's predictions. When creating skipped data for warm start, we either omit certain steps or heuristically merge two adjacent steps. Details on data creation can be found in Appendix B.1.

Analog of AlgebraFollowing Blessing and Anderson , we create an analog of algebra by replacing the variables and operators with different symbols. As shown in Figure 3, each variable and standard operator is mapped to a unique, unrelated symbol. The desired result is to isolate the symbol (i.e., \(x\)) on the left side of the symbol \(\) (i.e., \(=\)). This task is entirely new for the model, making it an ideal scenario to understand how models develop problem-solving abilities from scratch. We use a heuristic script to generate the questions along with the stepwise solutions. After generating the QA pairs, we filter the data based on the number of variables involved in the question and the steps required to solve it. The training and in-domain test data contains questions with up to 7 variables and requiring no more than 5 steps. In addition, we create two out-of-domain datasets of varying difficulties to evaluate generalization performance: OOD-easy includes variables unseen during training, with 8 and 9 variables, no limit on steps. OOD-hard is the most challenging setting, including 10 - 14 variables and \(\) 9 steps to solve. Both OOD sets contain unseen variables.

Multi-digit AdditionAs a basic arithmetic task, multi-digit addition naturally involves detailed stepwise reasoning processes, serving as a suitable task for studying model behaviors in compositionality generalization[45; 26; 40]. We utilize step-by-step reasoning processes to perform addition operation digit by digit, as illustrated in Figure 3. For training and in-domain test data, we only consider additions involving numbers with up to 3 digits. We introduce two out-of-domain datasets depending on the number of digits involved in the addition: OOD-easy includes one number with up to 3 digits and another with 4-7 digits. OOD-hard contains two numbers, both with 4-7 digits.

Directional ReasoningWe additionally consider long-form symbolic directional reasoning, which poses a challenge for direct solution and necessitates continuous reasoning steps to arrive at the answer. This task provides an initial direction and a list of turning actions. The desired answer is the final facing direction. For training and in-domain test set, we consider questions that contain \(\) 10 actions. OOD-easy includes questions with 11-20 actions and OOD-hard includes questions with 21-30 actions. The detailed statistics of three datasets can be found in Table 1.

### Experiment Setting

For all our experiments, we use Llama 2 (7B parameters)  and phi-3-mini (3.8B parameters, with context length of 4K)  as our base model. We train the model using a learning rate of 5e-6 for 2 epochs with the AdamW optimizer . During inference, we employ greedy decoding. We run our experiments with three different random seeds and report the average and standard deviation. All experiments are conducted on eight V100 GPUs each with 32GB memory. The total training time required to complete one full cycle of five iterations is under six hours.

## 5 Results

### Can models learn to skip steps?

To make sure our framework can proceed to iterations smoothly, one crucial factor is the initialized model's ability to adhere to the specified number of steps in the input. In the cold start setting, we

  
**Task** & **Train** & **In-domain test** & **OOD-easy** & **OOD-hard** \\  Analog of Algebra & 5,770 & 1,000 & 2,000 & 420 \\ Multi-digit Addition & 2,885 & 1,000 & 1,200 & 1,600 \\ Directional Reasoning & 2,080 & 1,000 & 500 & 500 \\   

Table 1: Dataset statistics.

Figure 3: Illustrations of three different tasks. Each question is accompanied by a comprehensive detailed step-by-step solution.

train the model exclusively using the full step training data. We then run inference on the training set, instructing the model to use \(n-i\) steps to solve the question, where \(n\) denotes the original full step number and \(i\). If \(n-i 0\), we do not ask the model to try skipping on such cases and instruct the model to use \(n\) steps instead.

As shown in Table 2, the results demonstrate that the fine-tuned model exhibits good step-number following ability on the Analog of Algebra -- over 99 % of the answers follow the given number of steps. Additionally, when prompted to generate condensed answers with fewer steps, the model can produce some correct answers in the specified number of steps, achieving accuracies of 8.14% and 2.77% respectively. Despite this relatively low accuracy, these small amount of correct data can still assist the model in gradually developing step skipping ability through iterations. Ultimately, the model manages to produce over 90% of correct skipping data. The trend of the data quantity change can be found in Appendix B.2.

However, this ability varies across different tasks. For the other two tasks, models do not naturally develop the capability for active step skipping, leading to near zero step consistency when required to provide answers in fewer steps. To address this issue, we employ the warm start setting for these tasks. Table 2 presents the results of Multi-digit Addition and Directional Reasoning under the warm start setting, indicating that this approach enhances the models' proficiency with step skipping.

Ideally, we aim for models to be initialized through cold start. The benefits of this approach are obvious -- it allows the model to spontaneously develop step skipping behavior, giving it sufficient freedom to decide and control which steps to skip. However, our experiments have revealed that it can be challenging for models to develop such capability in all scenarios. In contrast, the warm start offers an alternative design choice by providing human-created skipped data. This data includes intuitive and valid skipping steps derived from human expertise, making it more natural and helping models develop human-understandable behaviors. However, it might also introduce human biases that constrain the model's independent exploration of step skipping. This influence can be mitigated in the subsequent iteration phase, where the model is given full freedom to develop and amplify its own step-skipping behavior.

### What do models learn from skipping steps?

Based on this new mixed data including both complete and skipped answers at each iteration, we train the standard models to analyze the change of model's performance -- what models can learn from the behavior of skipping steps.

Models learn to solve problems more effectively with fewer steps.We evaluate the standard models on both in-domain and OOD data, with the results presented in Table 3. Detailed results from each iteration of the evaluation can be found in Appendix B.3. Given the simplicity of the tasks, the model is able to overfit on in-domain data, achieving nearly perfect performance. Further iterations of skipping steps manage to guide the model to use fewer steps while maintaining the performance. In two OOD scenarios, we find that the model trained with mixed data performs comparably to the model trained with complete steps on the OOD test sets, and even exhibits superior generalization abilities. Specifically, in Analog of Algebra, Llama2 models of iteration 5 achieves 4.76% gain on OOD-easy, while phi-3-mini achieves 7.08% gain on OOD-hard set. In the Multi-digit Addition task, the Llama2 model demonstrates a 13.91% improvement in OOD-easy performance

    &  &  &  \\   & \(i=1\) & \(i=2\) & \(i=1\) & \(i=2\) & \(i=1\) & \(i=2\) \\  \# Skipping & 5,308 & 4,159 & 2,844 & 2,175 & 2,071 & 2,049 \\ Step Consistency & 100.00 & 99.19 & 100.00 & 100.00 & 86.24 & 39.19 \\ Answer Accuracy & 8.14 & 2.77 & 98.35 & 82.58 & 85.47 & 29.62 \\ Average Step & 2.33 & 1.81 & 1.90 & 1.38 & 6.14 & 6.66 \\   

Table 2: Step number following ability of the initialized Llama2 models across different tasks. “# Skipping” represents the number of instances where \(n-i>0\). “Step Consistency” quantifies the match between the actual number of steps taken and the number indicated in the input. “Answer Accuracy” calculates the percentage of correct final answers out of the “# Skipping” cases. “Average Step” reflects the mean number of steps across all predictions within the dataset.

and a 4.75% increase in OOD-hard performance. In the OOD-hard dataset for Directional Reasoning, Llama2's performance improvts by 9.2%. These results suggest that not only is the model unaffected by potential shortcut bias from the skipping steps, but it actually benefits from the mixed training data to gain enhanced task solving abilities. The ablation analysis on various data-mixing approaches are provided in Appendix B.5. Furthermore, we observe that the model uses fewer steps, thereby increasing problem-solving efficiency.

### Model Behavior Analysis

#### 5.3.1 Analog of Algebra

Figure 4(a) presents the performance of Llama2 models across various iterations in the Analog of Algebra task, differentiated by the number of steps required in the complete answers. The solid lines represent the accuracy of final answers. We perform uniform evaluation on the union of all in-domain and OOD test sets. Initially, all models maintain high accuracy for in-domain problems with up to five steps, after which a significant drop is observed as the complexity increases. As the model undergoes

  
**Task** & **Iteration** &  &  &  \\  & Acc & Avg steps & Acc & Avg steps & Acc & Avg steps \\   \\  Analog of & Cold start & 99.87 & 3.19 & 85.91 & 4.79 & 7.94 & 11.57 \\ Algebra & Iter 5 & 99.80 & 2.43 & **90.67** & 4.05 & **8.10** & 10.92 \\   & Cold start & 100.0 & 2.86 & 0.06 & 3.25 & 0.00 & 3.69 \\ Addition & Warm start & 99.53 & 2.72 & 0.14 & 3.02 & 0.11 & 3.49 \\  & Iter 5 & 99.17 & 1.46 & **13.97** & 1.49 & **4.75** & 2.06 \\   & Cold start & 100.0 & 7.01 & **90.00** & 15.77 & 42.00 & 19.39 \\  & Warm start & 99.97 & 6.28 & 87.20 & 14.65 & 42.33 & 18.02 \\  & Iter 5 & 100.0 & 6.45 & 89.33 & 14.87 & **51.80** & 19.49 \\   \\  Analog of & Cold start & 99.60 & 3.19 & 98.04 & 6.16 & 4.05 & 10.01 \\ Algebra & Iter 5 & 99.90 & 2.75 & **98.95** & 5.60 & **11.13** & 7.98 \\   & Cold start & 99.92 & 2.86 & 35.93 & 5.03 & 5.39 & 5.44 \\ Warm start & 99.97 & 2.62 & 39.08 & 3.80 & 5.11 & 4.06 \\ Iter 5 & 99.93 & 2.08 & **46.61** & 2.31 & **14.98** & 2.59 \\   & Cold start & 99.83 & 7.01 & 91.47 & 15.46 & 62.67 & 24.85 \\  & Warm start & 99.80 & 6.82 & 93.67 & 15.19 & 71.80 & 24.61 \\  & Iter 5 & 99.70 & 6.12 & **93.73** & 14.44 & **73.87** & 23.77 \\   

Table 3: Performance comparison of models from different phases. Avg steps denotes the average number of steps taken in the prediction. With the skipped step data, models achieve even better generalization performance with fewer steps.

Figure 4: Comparison of models across different phases relative to question length and complexity. Models achieve near perfect performance on in-domain data but diverge on lengthy OOD data.

iterations, there is a noticeable improvement in its ability to handle longer step lengths (green solid line), particularly in the range of 6 to 10 steps where other models show significant weaknesses. The dashed lines illustrate the proportion of data exhibiting step-skipping in model predictions. The blue dashed line indicates models initially adopt step-skipping as problems extend in length. After iterations, the green dashed line indicates the models consistently employ step skipping in shorter questions, thereby improving the reasoning efficiency.

#### 5.3.2 Directional Reasoning

Figure 4 (b) illustrates the comparison of Llama2 model's performance across different question lengths on Directional Reasoning task. We observe that the artificial skipped data has minimal impact on the model, with negligible differences between the cold start and warm start phases. Upon entering the iterative phase, the model's performance notably declines during the first iteration, particularly in handling longer problems. This downturn may reflect the model's adjustment from manually injected skipped data to its own step skipping ability. Subsequent iterations show that the model benefits more significantly from data generated during the iteration process, as evidenced by the results in Iteration 5. The model maintains consistency with the baseline in both in-domain and out-of-domain performances, and exhibits a slight advantage in solving longer problems. Similar to the previous task, the Iteration 5 Ratio curve (dashed green line) also shows a significant increase in step-skipping behavior, suggesting an evolved efficiency in reasoning as the model opts to bypass steps while maintaining or even improving accuracy.

#### 5.3.3 Multi-digit Addition

In Figure 5, we show a finer-grained evaluation of multi-digit addition tasks on Llama2. The horizontal and vertical axes of the matrices represent the number of digits in the two addends for each question in the test set (both in-domain and OOD test data). We utilize the following three metrics: **Question-level accuracy** assesses whether the final answer is correct for additions involving different numbers of digits. **Step-level distribution** illustrates the distribution of the digit lengths used in each individual step of the model's stepwise reasoning process. **Step-level accuracy** measures the accuracy of the single step calculations involving different numbers of digits.

In Figure 5(a), as iterations progress, the model demonstrates improved generalization performance across all test datasets. When initialized with a cold start, the model can only learn from the training data involving single-digit addition steps, resulting in overfitting to in-domain test data (digit \(\) 3). When augmented with manually created skipped data for a warm start, the model begins to incorporate multi-digit additions with skipped steps. However, the inconsistency between the manually injected data and the model's inherent behavior does not significantly enhance the question-level accuracy. As the model is encouraged to explore during the iteration phase, it undertakes broader and bolder attempts--often combining additions across more digits in skipped steps. With the integration of these data, the model trained on this expanded iterative dataset also shows a more pronounced ability to solve OOD problems. As seen in Figure 5(b), the model increasingly employs multi-digit additions in single-step operations. Furthermore, as illustrated in Figure 5(c), there is an improvement in the accuracy of these skipped single-step operations. We believe this may be due to the model-generated data during self-iterations, which are more conducive to enhancing its capability to skip steps, thereby benefiting from this process.

### Accuracy of Step-Skipping Answers

Figure 6 shows the step skipping behavior and accuracy of the standard models at each iteration on the Analog of Algebra task using Llama-2. The Skipping Ratio measures how often the model skips steps in the test set, while Accuracy reflects the correctness of these skipping answers.

We observe that in the beginning models inherently struggle in OOD scenarios, often producing reasoning steps that are incomplete or shorter than the problem complexity requires. In "cold start" settings, where the model is trained solely with complete steps, it performs well with in-domain questions but fails to maintain complete reasoning steps and tends to generate shorter responses on OOD sets. Due to its limited generalizability, these skipping or missing steps negatively impact the performance. However, as the model progressively adapts to step skipping over iterations, the accuracy of the shorter responses improves, suggesting it gradually develops a more reliable ability to skip steps when appropriate. Analysis across all tasks can be found in Appendix B.4.

### Analysis on the Influence of Training Steps

Throughout the iterations, as the model progressively generates more successful step skipping data, the size and the quality of the resulting dataset also gradually increases. This can be considered as a special form of augmentation for answer diversity. To investigate whether the performance improvements are primarily due to the model learning from more training steps, we increase the number of training epochs during the initialization phase to match the data volume after iterations. The comparison results shown in Table 4 reveal that increasing the number of training epochs does not always lead to performance enhancements; instead, it may cause a performance decline due to overfitting. In contrast, mixing skip-step data from the iterative process not only maintains or improves performance in in-domain and OOD-easy tasks but also achieves consistent gains in OOD-hard setting. When the total number of training steps is similar, the integration of skipping data yields better performance.

Figure 5: Model behavior analysis on the test set of multi-digit addition task. Initially constrained to single-digit additions, the model progressively incorporates multi-digit calculations with skipped steps through iterative learning, showing an enhancement in solving out-of-distribution problems and executing more complex calculations with higher accuracy.

Figure 6: Skipping ratio and the accuracy of the skipping responses on Analog of Algebra.

### Extended Iterative Training

In this section, we extend the iterative process to allow the model to skip up to 4 steps, rather than restricting it to less than 2 steps on Analog of Algebra. The process is continued for a total of 9 iterations, and the results are shown in Figure 7. The model continues to benefit from additional iterations beyond Iteration 5, which serves as the default cutoff in our main results. Specifically, the accuracy on the OOD-hard set improves steadily, reaching over 18% by the ninth iteration. This increase suggests that even with a greater allowance for step-skipping, the model's ability to generalize to harder out-of-domain samples is enhanced with continued training.

Simultaneously, the average number of steps taken decreases across all test sets as iterations progress, suggesting that the model is converging towards fewer steps and becoming increasingly efficient. By the ninth iteration, the step count appears to plateau, indicating that the model has likely reached a stable balance between accuracy and efficiency. We hope our work provides a fresh perspective on exploring the connection between System 2 slow reasoning and System 1 fast thinking, and on facilitating their transformation, paving the way for future research in this direction.

## 6 Conclusion

In this work, we explore the human-like ability of step skipping in language models, providing initial empirical evidence that models can skip steps and benefit from such cognitive behaviors. Addressing the absence of intrinsic motivation for step skipping in models, we design an approach that not only enables models to spontaneously develop the ability but also iteratively encourages models to actively adopt and enhance this behavior. Through experiments on three tasks, we demonstrate that models equipped with step-skipping capabilities can solve tasks more efficiently in fewer steps, without sacrificing accuracy. Further empirical results suggest that training on easy data containing both full steps and skipped reasoning steps can potentially help models generalize to harder scenarios. We hope this work offers insights into the relationship and transition between System 1 and System 2 thinking and contributes to advancing easy-to-hard generalization in language model reasoning.

  
**Task** & **Iteration** & **\# steps** & **In-domain** & **OOD-easy** & **OOD-hard** \\   & Cold start - ep4 & 2.9K & 99.9 & 89.7 & 4.5 \\  & Cold start - ep5 & 3.6K & 100 & 84.9 & 2.4 \\  & Iteration 5 - ep2 & 3.3K & 99.8 & 90.5 & 14.3 \\   & Cold start - ep5 & 1.8K & 100 & 0 & 0 \\  & Cold start - ep6 & 2.2K & 100 & 0 & 0 \\  & Warm start - ep2 & 1.4K & 99.9 & 0 & 0.1 \\  & Warm start - ep3 & 2.1K & 100 & 0.1 & 0 \\  & Iteration 5 - ep2 & 2.0K & 99.5 & 13.5 & 5.8 \\   & Cold start - ep3 & 0.8K & 100 & 91.2 & 43.2 \\  & Cold start - ep4 & 1.0K & 100 & 91.0 & 34.8 \\   & Warm start - ep2 & 1.0K & 100 & 90.6 & 43.4 \\   & Warm start - ep3 & 1.5K & 100 & 84.6 & 34.4 \\   & Iteration 5 - ep2 & 1.0K & 100 & 90.4 & 56.2 \\   

Table 4: Performance comparison across different tasks with varying training steps.

Figure 7: Performance of phi-3-mini across 9 iterations with relaxed step-skipping constraints (up to 4 steps) on Analog of Algebra. The figures show the changes in average steps taken (left y-axis) and accuracy (right y-axis). Continuous iteration improves OOD-hard accuracy and reduces the average number of steps, converging towards stability.