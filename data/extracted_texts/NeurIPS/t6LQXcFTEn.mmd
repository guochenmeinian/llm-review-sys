# AudioMarkBench: Benchmarking Robustness of Audio Watermarking

Hongbin Liu\({}^{+}\)\({}^{1}\), Moyang Guo\({}^{*}\)\({}^{1}\), Zhengyuan Jiang\({}^{1}\), Lun Wang\({}^{2}\), Neil Zhenqiang Gong\({}^{1}\)

\({}^{1}\)Duke University, \({}^{2}\)Google

\({}^{1}\){hongbin.liu, moyang.guo, zhengyuan.jiang, neil.gong}@duke.edu, \({}^{2}\)lunwang@google.com

Equal contributions.

###### Abstract

The increasing realism of synthetic speech, driven by advancements in text-to-speech models, raises ethical concerns regarding impersonation and disinformation. Audio watermarking offers a promising solution via embedding human-imperceptible watermarks into AI-generated audios. However, the robustness of audio watermarking against common/adversarial perturbations remains understudied. We present AudioMarkBench, the first systematic benchmark for evaluating the robustness of audio watermarking against _watermark removal_ and _watermark forgery_. AudioMarkBench includes a new dataset created from Common-Voice across languages, biological sexes, and ages, 3 state-of-the-art watermarking methods, and 15 types of perturbations. We benchmark the robustness of these methods against the perturbations in no-box, black-box, and white-box settings. Our findings highlight the vulnerabilities of current watermarking techniques and emphasize the need for more robust and fair audio watermarking solutions. Our dataset and code are publicly available at https://github.com/moyangkuo/AudioMarkBench.

## 1 Introduction

Recent advancements in text-to-speech (TTS) generative models enable generating highly realistic synthetic audios that are indistinguishable from real human voices. However, this capability raises significant concerns, such as malicious impersonation, dissemination of false information, or copyright infringement. For example, a scammer used synthetic audios to impersonate President Biden in illegal robocalls during a New Hampshire primary election, and thus faces a $6 million fine and felony charges .

Audio watermarking  offers a promising approach to mitigate concerns about synthetic audio authenticity. It embeds an imperceptible watermark into a synthetic audio using a watermark encoder, outputting a watermarked audio. During detection, a watermark decoder extracts a watermark from a given audio input. By comparing the extracted watermark with the ground-truth watermark, one can determine the authenticity of the given audio.

Existing audio watermarking methods perform well when there are no perturbations added to watermarked audios . However, real-world audios often undergo various perturbations. Common perturbations include compression using standards like MP3 or Opus  to reduce internet transmission costs. Additionally, attackers may craft adversarial perturbations designed to deceive watermarking methods. However, the robustness of audio watermarking against these perturbations remains under-explored and lacks systematic benchmarking.

**Our work:** In this work, we aim to bridge the gap by introducing **AudioMarkBench** (**Audio Watermarking Benchmark**), the _first_ systematic and comprehensive benchmark for assessing therobustness of audio watermarking. We focus on evaluating robustness against two types of perturbations: _watermark-removal_ perturbations, designed to make watermarked audio undetectable, and _watermark-forgery_ perturbations, which aim to falsely mark unw watermarked audio.

- _Datasets:_ Other than the standard LibriSpeech dataset , we construct a new dataset AudioMark-Data that meticulously sub-samples 20,000 audio samples from the Common Voice dataset , striving to ensure balanced representation of biological sexes, languages, and age groups. Moreover, our datasets provide not only watermarked/unwatermarked audios but also perturbed audios under various perturbations, making it easier for future research to assess the the effectiveness of new watermark-removal/forgery perturbations.

- _Systematic benchmarking:_ We present the _first_ systematic benchmark evaluating the robustness of three state-of-the-art audio watermarking methods against 15 different watermark-removal/forgery perturbations across two datasets. Twelve of these perturbations, termed "no-box" perturbations, require no access to the watermarking method. These perturbations include common audio edits like codec [7; 16; 15] and audio filter, and noise addition such as white noise or background noise. Additionally, We adapt two adversarial example methods [4; 1] in the _black-box_ setting (_i.e._, access to watermark detector API only) and one adversarial example method  in the _white-box_ setting (_i.e._, full access to watermarking model parameters) from image classifiers to audio watermarking.

- _Findings:_ We make intriguing findings in our benchmark study. First, we confirm that all studied audio watermarking methods can distinguish watermarked/AI-generated audios from unwatermarked/non-AI-generated audios precisely when no perturbations are added. Second, existing audio watermarking methods can be vulnerable to watermark removal including certain no-box perturbations (e.g., EnCodeC ), black-box perturbations with sufficient quota for API queries, and white-box perturbations. Third, current audio watermarking techniques are effective at resisting no-box and black-box watermark forgery, but vulnerable to white-box forgery. Fourth, existing audio watermarking methods have robustness gaps among biological sex groups (female vs male) and language groups under certain perturbations, flagging potential fairness issues. However, we do not observe consistently significant robustness gaps across age groups.

## 2 Audio Watermarking Methods

An audio watermarking method consists of four key components: a watermark \(w\), encoder \(\), decoder \(\), and detector \(\). The watermark \(w\{0,1\}^{n}\) is typically an \(n\)-bit bitstring, such as an 16-bit bitstring \(110110110010110\). Given any audio waveform \(s^{T}\) and a watermark \(w\), the encoder \(\) outputs a watermarked audio waveform \(s_{w}=(w,s)^{T}\), where \(T\) denotes the number of time samples in the waveform. For any audio waveform \(s\), whether watermarked or unwatermarked, the decoder \(\) can extract a bitstring watermark \((s)\). When the audio waveform \(s\) is watermarked with \(w\), the extracted watermark \((s)\) should be similar to \(w\). The detector \(\) then uses the decoded watermark \((s)\), together with some additional information, to determine if the given audio waveform \(s\) contains a watermark. In particular, \((s)=1\) (\((s)=0\)) means that \(s\) is detected as watermarked (unwatermarked), respectively. In this study, we examine three state-of-the-art, open-source audio watermarking techniques: AudioSeal/AudioSeal-B ,

Figure 1: Summary of our AudioMarkBench.

Timbre , and WavMark . We utilize the publicly available code and models of these methods for our experimental analysis.

**AudioSeal/AudioSeal-B:** During watermark generation, AudioSeal uses a sequence-to-sequence encoder \(\) to generate the watermarked waveform \(s_{w}\) given any input audio waveform \(s\) and a watermark \(w\). During watermark detection, the decoder \(\) gives two outputs given a suspect waveform \(s\): a global detection probability \(P_{s}\) indicating the likelihood that \(s\) is watermarked, and the decoded watermark \((s)\). With a detection threshold \(\), AudioSeal predicts \((s)=1\) if the detection probability \(P_{s}\) exceeds \(\), and 0 otherwise. AudioSeal-B, a variant of AudioSeal, uses _bitwise accuracy_ (_i.e._ the proportion of matching bits between two bitstrings) for detection instead. Specifically, it predicts \((s)=1\) if the bitwise accuracy between the decoded watermark and the original watermark is at least \(\): \(((s),w)\), and 0 otherwise.

**Timbre:** Given any input audio \(s\), Timbre first transforms it into a spectrogram \(C_{s}=(a_{s},p_{s})\) using Short-Time Fourier Transformation (STFT), where \(a_{s}\) is the amplitude and \(p_{s}\) is the phase. It then embeds the watermark \(w\) into \(a_{s}\) while keeping \(p_{s}\) unchanged, producing the watermarked audio \(s_{w}=((a_{s},w),p_{s})\), where ISTFT is the inverse STFT. For detection, given an audio waveform \(s\), STFT is first applied to obtain its spectrogram \(C_{s}=(a_{s},p_{s})\), and then the decoder \(\) extracts a watermark \((a_{s})\) from the amplitude \(a_{s}\). The detector outputs \((s)=1\) if the bitwise accuracy \(((a_{s}),w)\), otherwise \((s)=0\).

**WavMark:** Similar to Timbre, WavMark operates in the spectrogram domain by first transforming an input waveform \(s\) to its spectrogram \(C_{s}=(a_{s},p_{s})\) via STFT. It then embeds a preset synchronization bitstring \(s_{}\) together with the watermark \(w\) into the whole spectrogram, i.e., producing the watermarked audio \(s_{w}=((C_{s},s_{} w))\) where \(\) denotes bitstring concatenation. For detection, given an audio waveform \(s\), the decoder extracts a bitstring containing both a decoded synchronization bitstring \(((s))_{}\) and watermark \(((s))_{w}\) from its spectrogram. If the decoded synchronization bitstring \(((s))_{}=s_{}\) and the bitwise accuracy \((((s)),w)\), then \((s)=1\), otherwise \((s)=0\).

**Importance of determining a detection threshold \(\):** In real-world deployments, the detector determines whether an audio waveform \(s\) contains a watermark or not by comparing metrics, such bitwise accuracy, with the detection threshold \(\). Thus, \(\) controls a trade-off between _False Positive Rate (FPR)_ and _False Negative Rate (FNR)_, where FPR (or FNR) is the likelihood of incorrectly predicting an unwatermarked (or watermarked) audio as watermarked (or unwatermarked). A higher \(\) reduces FPR but increases FNR. \(\) can vary depending on the specific watermarking method and we will further discuss selecting \(\) in our experiments in Section 5.

## 3 Watermark-removal and Watermark-forgery Perturbations

**Definitions:** Audio watermarking faces two primary threats: _watermark-removal perturbations_, which aim to strip watermarks from watermarked audios, and _watermark-forgery perturbations_, which aim to forge watermarks for unwatermarked audios. Watermark removal allows AI-generated audio to be falsely presented as genuine, potentially fueling disinformation campaigns. Conversely, watermark forgery can mislabel authentic audio as AI-generated, undermining human creators' ability to claim ownership and potentially stifling human creativity.

**-** _Watermark removal:_ Watermark removal aims to add a human-imperceptible perturbation vector \(\) to a watermarked audio \(s_{w}\) such that the detector \(\) outputs 0 for \(s_{w}+\). Formally, finding \(\) can be formulated as the following optimization problem:

\[_{}=_{}(s_{w}+)=0  Q(s_{w}+) Q(s_{w}),\] (1)

where \(Q\) is an audio quality metric. The quality constraint ensures the audio quality to remain high after adding the perturbation. The audio quality metric \(Q\) can be ViSQOL  or SNR.

**-** _Watermark forgery:_ In contrast, watermark forgery attempts to add perturbation \(\) to an unwatermarked audio \(s_{u}\) such that the detector \(\) detects it as watermarked. Formally, finding \(\) in watermark forgery can be formulated as the following optimization problem:

\[_{}=_{}(s_{u}+)=1  Q(s_{u}+) Q(s_{u}).\] (2)Both watermark removal and watermark forgery perturbations can be classified into three groups based on the adversary's knowledge of the watermarking method.

**No-box perturbations:** In no-box setting, the perturbations are crafted without any knowledge of the audio watermarking method, including the architecture, parameters, or even the output of the detector. These no-box perturbations are created blindly or even unintentionally to spoof the watermarking detector for watermark removal/forgery. In our AudioMarkBench, we consider twelve common audio editing operations as no-box perturbations, including Gaussian/background noises and audio codecs like MP3, EnCodeC, SoundStream, Opus, _etc._ More details on these perturbations can be found in Appendix A.2.

**Black-box perturbations:** In black-box setting, perturbations are created by interacting with the watermarking detector \(\) as an oracle. Specifically, the attacker can choose audios to submit to the detector and observe the detection result without any knowledge of how the detector operates internally. We extend existing methods for finding black-box adversarial examples [4; 1] against image classifiers to audio watermarking detectors. In particular, we apply them in waveform and/or spectrogram domains. Next, we briefly describe how we extend them, and Appendix A.3 shows more technical details.

**-** _HopSkipJumpAttack :_ Given an audio \(s\) and access to a watermarking detector \(\)'s output, HopSkipJumpAttack iteratively approximates \(\)'s decision boundary to find a minimal watermark-removal/watermark-forgery perturbation \(\). We implement this attack in both waveform and spectrogram domains. In the waveform domain, perturbations are optimized in a 1-D vector space, while in the spectrogram domain, both phase and amplitude (2-D vectors) are optimized. We conduct 10,000 iterations in each domain, initializing perturbations with Gaussian noise.

**-** _Square attack :_ Given an audio \(s\) and access to a watermarking decoder \(\)'s output, Square attack iteratively finds the watermark-removal/watermark-forgery perturbation \(\) by strategically decreasing either the bitwise accuracy of \(\)'s output or the global detection probability (for AudioSeal). We extend Square attack from image domain to the spectrogram domain by treating a spectrogram as an image. Note that Square attack is only applicable to the spectrogram domain (not the waveform domain) since its input is a 2-D image/spectrogram. We perform Square attack under a \(_{}\)-norm perturbation constraint for 10,000 iterations.

**White-box perturbations:** In white-box setting, the perturbations are crafted with full knowledge of the watermark decoder \(\)'s parameters and the ground-truth watermark \(w\). In particular, the perturbations are found via solving the optimization problems in Equation 1 and 2. The goal of watermark forgery/removal perturbation is to increase/decrease the bitwise accuracy between the decoded watermark \((s)\) and ground-truth watermark \(w\) (for Timbre, WavMark, and AudioSeal-B) or the global detection probability (for AudioSeal). Therefore, for Timbre, WavMark, and AudioSeal-B, we use the cross-entropy loss to minimize/maximize the distance between the decoded watermark \((s+)\) and ground-truth watermark \(w\):

\[L_{ce}=-_{i=1}^{n}w_{i}((s+)_{i})+(1-w_{i})(1- (s+)_{i})\]

, where \(w_{i}\) (or \((s+)_{i}\)) is the \(i^{th}\) bit of \(w\) (or \((s+)\)). For AudioSeal, we adopt the ReLU activation applied between the global detection probability \(P_{s}\) and \(\): \(L_{Re}=(0,P_{s}-)\). We use these loss functions to approximate the objective functions in Equation 1 and 2. Appendix A.4 shows more details on how we solve the optimization problems to find white-box perturbations.

## 4 Datasets

**Unwatermarked audio samples:** Our AudioMarkBench includes two datasets of unwatermarked audio samples, i.e., AudioMarkData and LibriSpeech . AudioMarkData is a dataset we build from the Common Voice dataset . Each audio sample in AudioMarkData is associated with three attributes, which are: _language_ (25 languages), _biological sex_ (male, female) and _age_ (teens, twenties, thirties, fourties). We use these attributes to benchmark whether watermarking methods have different performance/robustness for audio samples with different attributes. For every attribute group (language, biological sex, age), AudioMarkData samples 100 audio samples in 5 seconds with sampling rate at 16kHz from Common Voice, resulting in 20,000 audio samples in total. Table 1summarizes the attributes of AudioMarkData. The LibriSpeech dataset contains over 1,000 hours of read English speech derived from audiobooks in the public domain. We sampled 20,000 audio samples with a maximum length of 5 seconds at the default 16kHz sampling rate. Note that audio samples in LibriSpeech do not have attributes.

**Watermarked audio samples:** We apply each watermarking method (AudioSeal/AudioSeal-B, Timbre, and WavMark) to embed a watermark into each audio sample. Note that AudioSeal/AudioSeal-B use the same encoder and decoder, but different detectors. Specifically, we randomly sample a 16-bit watermark for each watermarking method and embed it into each audio sample. In total, we create 20,000 watermarked audio samples for each watermarking method and each dataset.

**Perturbed audio samples:** We add watermark-removal (or watermark-forgery) perturbations to watermarked (or unwatermarked) audio samples to create perturbed audio samples. These perturbed audio samples will be used to measure the robustness of audio watermarking against watermark removal/forgery. Specifically, we consider 12 categories of common no-box perturbations. For each category of no-box perturbation, we utilize it to perturb the 20,000 unwatermarked audio samples in each dataset and the 20,000 watermarked audio samples in each dataset and watermarking method. Note that each category of no-box perturbations has certain parameter to control the level of perturbation, and we use multiple parameter values (see Appendix A.2). For the black-box and white-box perturbations, due to limits of computation resources, we sample 200 unwatermarked audio samples and 200 watermarked audio samples for each watermarking method in the LibriSpeech dataset; and in AudioMarkData, we sample one unwatermarked audio sample and one watermarked audio sample from each attribute group (language, biological sex, age), leading to 200 unwatermarked audio samples and 200 watermarked audio samples for each watermarking method.

## 5 Benchmark Results

In the following section, we present our primary benchmark results and findings. We conduct our experiments on 18 NVIDIA-RTX-6000 GPUs, each with 24 GB memory. The complete set of experiments requires about 430 GPU-hours to execute.

### Evaluation Metrics

We use FNR and FPR to evaluate the robustness of audio watermarking. Specifically, FNR/FPR is the fraction of watermarked/unwatermarked audios that are incorrectly detected as unwatermarked/watermarked. Lower FNR/FPR indicate better audio watermarking methods. When watermarked audios (or unwatermarked audios) are modified by watermark-removal (or watermark-forgery) perturbations, lower FNR (or FPR) indicates that the watermarking method is more robust against watermark removal (or watermark forgery).

We evaluate the quality of perturbed audios using standard metrics including SNR and ViSQOL . Signal-to-Noise Ratio (SNR) evaluates quality of a perturbed audio by comparing its level of noise with the corresponding clean audio (called _reference audio_), where the reference audio is watermarked (or unwatermarked) in watermark removal (or forgery). Higher SNRs indicate clearer and higher-quality perturbed audios. ViSQOL, ranging from 1 to 5, evaluates audio quality by simulating human perception of audios, where a higher score indicates the perturbed audio better preserves quality of the reference audio. A ViSQOL score no smaller than 3 generally reflects good audio quality. We mainly rely on ViSQOL for measuring audio quality because it is more reliable than SNR .

### Results under No Perturbations

Figure 2 and Figure 9 (in Appendix) show the FPR and FNR of each watermarking method as the detection threshold \(\) varies on AudioMarkData and LibriSpeech datasets, respectively. No

  Attribute & \#Values & Values & \#Samples per Value \\   &  & EU, BE, BN, YUE, CA, ZH-CN, ZH-HK, ZH-TW, & \\  & & EN, EO, FR, KA, DE, HU, IT, IA, LV, MHR, FA, RU, & 800 \\  & & SW, ES, TA, TH, UK & \\  Biological Sex & 2 & Male, Female & 10,000 \\  Age & 4 & Teens, Twenties, Thirties, Forties & 5,000 \\  

Table 1: Attributes of AudioMarkData. Details of languages are shown in Appendix A.1.

perturbations are added to watermarked/unwatermarked audios. We have three key observations. First, FNRs of each watermarking method on both datasets are close to 0 for a wide range of detection threshold \(\), indicating that watermarked audios can be accurately detected as watermarked. Second, FPRs of each watermarking method on both datasets decrease as detection threshold \(\) increases. This is because unwatermarked audios are less likely to be falsely detected as watermarked when \(\) increases. Third, audio watermarking methods are very accurate at distinguishing watermarked and unwatermarked audios when the detection threshold \(\) is properly selected. For instance, when \(=0.15\), both FPR and FNR of AudioSeal are almost 0 on AudioMarkData. For each watermarking method, we choose the smallest detection threshold \(\) that achieves both FNR and FPR lower than 0.01. The selected \(\) for each watermarking method and each dataset is shown in the captions of Figure 2 and Figure 9. In the rest of this paper, we will use these detection threshold \(\) unless otherwise mentioned.

### Robustness against No-box Perturbations

Figure 3 shows the FNR, FPR, SNR, and ViSQOL results of the watermarking methods against EnCodeC perturbations on AudioMarkData and LibriSpeech datasets. Results of the other eleven no-box perturbations can be found in Appendix A.6.

**Overall results:** We have several key observations. First, state-of-the-art audio watermarks are robust against several common no-box watermark-removal perturbations such as time stretch, low-pass, high-pass, and echo. Specifically, while preserving the quality of watermarked audio samples well (i.e., ViSQOL no smaller than 3), those perturbations have small impact on FNRs. This is because these audio watermarking methods use _adversarial training_, which considers various common no-box perturbations, to train the encoders and decoders. Second, current audio watermarking methods are not robust against no-box removal perturbations that are unseen during adversarial training. For instance, when ViSQOL is no smaller than 3, EnCodeC, SoundStream, and Opus achieve very high FNRs, indicating that those perturbations can remove watermarks from watermarked audios while preserving the audio quality. Third, current audio watermarking methods have good robustness against watermark-forgery perturbations. In particular, FPRs of all these watermarking methods are almost always close to 0, except for quantization. Specifically, when bit levels are smaller than 32,

Figure 3: Detection results under EnCodeC perturbations on both datasets (first row: AudioMarkData and second row: LibriSpeech). Results of the other eleven no-box perturbations are in Appendix A.6.

Figure 2: Detection results under no perturbations on AudioMarkData. We set the detection threshold \(\) for each watermarking method as follows: AudioSeal \(=0.15\), AudioSeal-B \(=0.875\), WavMark \(=0.0\), and Timbre \(=0.8125\), to achieve FPR \(<0.01\) and FNR \(<0.01\). Results for LibriSpeech are in Figure 9 in Appendix.

quantization perturbation achieves a FPR larger than 0.2, but the audio quality is also compromised. This is because forging a watermark is harder and may require knowledge of the watermarking model. No-box perturbations do not have such information and therefore cannot forge a watermark. As we will show in the next subsection, forging a watermark remains difficult even in the black-box setting.

**Comparing watermarking methods:** Considering performance against all no-box perturbations, AudioSeal is the most robust against watermark removal and forgery among the evaluated watermarking methods. In contrast, WavMark is the least robust. For instance, watermarks embedded by WavMark can even be removed by Gaussian noise and MP3 compression without compromising the watermarked audios' quality. This stems from two reasons: 1) AudioSeal uses advanced sequence-to-sequence models as encoder and decoder, which can output fine-grained localization of watermarks; and 2) AudioSeal considers more diverse perturbations in adversarial training.

**Comparing biological sex, language, and age groups in AudioMarkData:** Figure 4 and more results in Appendix A.7 show detection differences in biological sexes in terms of FNRs/FPRs. First, watermarked audios with attribute "female" are less robust to watermark-removal Gaussian noise perturbations (i.e., have higher FNRs) than those with attribute "male" for all the evaluated watermarking methods especially AudioSeal-B. These results indicate a fairness gap of robustness against watermark removal among "female" and "male" groups under Gaussian noise perturbations. To rigorously test this gap, we conducte a two-tailed t-test with a null hypothesis positive no difference in FNRs between "female" and "male" groups, at a significance level of \(=0.05\). For Figure 3(a), the calculated \(p\)-value\( 2.4 10^{-6}<=0.05\). Thus, the robustness gap between "female" and "male" groups is statistically significant. Note that we did not observe such gaps for other watermark-removal no-box perturbations except EnCodeC (Figure 18), Opus (Figure 19), Quantization (Figure 20).

Second, unwatermarked audios with attribute "female" are less robust (i.e., have larger FPRs) to watermark-forgery EnCodec perturbations than those with attribute "male" when AudioSeal is used. We did not observe such gaps for other watermarking methods under EnCodec perturbations nor other watermark-forgery no-box perturbations for all watermarking methods since FPRs are generally close to 0 in those scenarios.

Figure 4: FNRs in biological sexes against watermark-removal (a) Gaussian noise perturbations, (b) Square attack perturbations, and (c) white-box perturbations. (d) FPRs in biological sexes against watermark-forgery EnCodeC perturbations. The watermarking method is AudioSeal. The gaps between “female” and “male” are statistically significant in two-tailed t-test with \(p\)-value < \(=0.05\).

Figure 5: Language difference against watermark-removal Gaussian noise perturbations with SNR 20. The watermarking method is AudioSeal.

tions. We also observe that such differences may vary across different watermarking methods. For instance, watermarked audios in Esperanto have smaller FNRs on AudioSeal but larger FNRs on WavMark. We hypothesize that Esperanto, as an artificial language, may have specific characteristics (e.g., phonetic patterns, speech dynamics) that interact differently with the watermarking detectors.

Results in Appendix A.8 show detection differences in age groups in terms of FNRs/FPRs. We observe no consistently significant differences across age groups.

### Robustness against Black-box Perturbations

We find that audio watermarking methods have good robustness against _existing_ black-box watermark-forgery perturbations. In particular, existing black-box watermark-forgery perturbations substantially sacrifice audio quality in order to forge watermarks. However, audio watermarking methods are not robust to _existing_ black-box watermark-removal perturbations when an attacker can query the detector API for many times. In particular, they can remove watermarks from watermarked audios while preserving their audio quality given sufficient number of queries to the detector API. When the number of queries to the detector API is limited, audio watermarking methods have good robustness against _existing_ black-box watermark-removal perturbations. Next, we discuss results for watermark-removal perturbations found by HSJA, and the results for Square attack are in Appendix A.5.

Recall that HSJA guarantees that the found watermark-removal perturbations are successful while iteratively optimizing them. Therefore, we evaluate the quality of the perturbed watermarked audios when increasing the number of iterations/queries to the watermarking detector. We consider adding perturbations to both waveform and spectrogram domains, and the results are shown in Figure 6. First, in the waveform domain, quality of the perturbed audio does not improve with more iterations, indicating that HSJA struggles to optimize perturbations in the waveform domain. This may be attributed to HSJA's design, which is tailored to attack image classifiers, potentially making it less effective on 1-D audio waveform. Second, in the spectrogram domain, although initial audio quality is inferior to those in the waveform domain, the audio quality improves significantly with more iterations. Specifically, for AudioSeal-B, Timbre, and WavMark, while the SNR/ViSQOL scores are slightly inferior to those in waveform domain under 100 iterations, after 10,000 iterations, the audio quality is considerably better, with WavMark achieving SNR/ViSQOL of 40/4.5, and AudioSeal-B and Timbre reaching approximately 30/4. AudioSeal has better robustness in both waveform and spectrogram domains, maintaining SNR/ViSQOL scores below 10/3. Third, like no-box perturbations, we observe that WavMark is least robust while AudioSeal is the most robust.

We also observe that watermarked audios with attribute "female" are less robust to watermark-removal Square attack perturbations (i.e., have higher FNRs) than those with attribute "male" (see Figure 3(b)

Figure 6: HSJA’s audio quality when optimizing watermark-removal perturbations in waveform or spectrogram domain on AudioMarkData. The results on LibriSpeech are in Figure 10 in Appendix.

Figure 7: Detection results under white-box watermark-removal and watermark-forgery perturbations.

and more results in Appendix A.7). Like no-box setting, we did not observe robustness gaps among age groups in both black-box and white-box settings (discussed in the next subsection). Moreover, due to computation resource limit, we sampled 200 audio samples in black-box and white-box settings, leading to only 4 samples per language. Therefore, we did not study robustness across languages due to the small-sample issue.

### Robustness against White-box Perturbations

Figure 7 shows the detection results under white-box perturbations, where the perturbations are constrained by SNR. We evaluate SNRs from 20 to 60, which correspond to ViSQOL scores from above 3 to 5 (see Figure 8). In other words, our white-box perturbations preserve the audio quality. Our key observation is that existing audio watermarking methods are not robust to white-box watermark-removal and watermark-forgery perturbations. For instance, FNRs reach 1 for all watermarking methods when the SNR of the perturbations is 20 (i.e., ViSQOL of 3.2 and 3.9 on the two datasets). Moreover, all watermarking methods have high FPRs under white-box perturbations that preserve audio quality. We also evaluate iterative Fast Gradient Sign Method (I-FGSM)  in Appendix A.11 and get similar conclusion.

We also observe that watermarked audios with attribute "female" are less robust to watermark-removal white-box perturbations (i.e., have higher FNRs) than those with attribute "male" (see Figure 22 and more results in Appendix A.7).

## 6 Discussions

**Limitations:** The major limitation of this work is that AudioMarkData contains 25 languages and 4 age groups due to the fact it's sub-sampled from Common-Voice. We deem the collection of audios with more diverse languages and age groups an important future direction.

**Social impacts:** Our AudioMarkBench evaluates the vulnerability of audio watermarks to removal or forgery and has significant implications for the safe usage of audio generation/watermarking techniques. First, watermark removal enables AI-generated audio to be disguised as authentic, potentially fueling misinformation campaigns. Second, watermark forgery allows for false attribution of AI-generated audio, undermining the ability of human creators to protect their work. By assessing the robustness of audio watermarking techniques, our AudioMarkBench contributes to the development of more secure watermarking systems, helping to mitigate the potential negative impacts of AI-generated audio on society.

## 7 Conclusion

In this work, we introduce AudioMarkBench, the first systematic benchmark for evaluating the robustness of audio watermarking against watermark removal/forgery. Our study, involving 3 state-of-the-art methods and 15 perturbation types across 2 datasets (including our new AudioMarkData), reveals that existing watermarking methods lack robustness under various no-box/black-box and white-box perturbations. Additionally, we identify fairness issues, with robustness varying across biological sex and language groups under certain perturbations. Our benchmark promotes further research to enhance robustness and fairness in audio watermarking.