# Controllable Generation via

Locally Constrained Resampling

Kareem Ahmed, Kai-Wei Chang & Guy Van den Broeck

Department of Computer Science

University of California, Los Angeles

{ahmedk, kwchang, guyvdb}@cs.ucla.edu

###### Abstract

Autoregressive models have demonstrated an unprecedented ability at modeling the intricacies of natural language. However, they continue to struggle with generating complex outputs that adhere to logical constraints. Sampling from a _fully-independent_ distribution subject to a constraint is hard. Sampling from an _autoregressive distribution_ subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. Our approach considers the entire sequence, leading to a more globally optimal constrained generation than current greedy methods. Starting from a model sample, we induce a local, factorized distribution which we can tractably condition on the constraint. To generate samples that satisfy the constraint, we sample from the conditional distribution, correct for biases in the samples and resample. The resulting samples closely approximate the target distribution and are guaranteed to satisfy the constraints. We evaluate our approach on several tasks, including LLM detoxification and solving Sudoku puzzles. We show that by disallowing a list of toxic expressions our approach is able to steer the model's outputs away from toxic generations, outperforming similar approaches to detoxification. We conclude by showing that our approach achieves a perfect accuracy on Sudoku compared to \(<50\%\) for GPT4-o and Gemini 1.5.

## 1 Introduction

The advent of large language models (LLMs) has brought about a paradigm shift towards generating sequences of tokens that jointly constitute the desired output. Such multi-token outputs exhibit an amount of structure to them: in free-form generation, the model is expected to generate coherent paragraphs; in question answering, it is expected to provide answers to the posed questions; and in summarization, it is expected to condense lengthy documents into concise summaries. And while current LLMs are remarkably apt at generating fluent sentences, there is a need for generations that go beyond that, exhibiting more intricate structure (Liu et al., 2024). Such structure includes, e.g., API calls and code snippets (Wang et al., 2023), JSON schemas (OpenAI, 2023), logical puzzles (Mittal et al., 2024; Pan et al., 2023), all of which LLMs struggle with (Sun et al., 2023).

Consequently, several approaches to constraining LLMs were developed, all bolstering a similar underlying idea: at every generation step _greedily_ mask the LLM outputs that could lead to the constraint being violated. That is, the "defacto" recipe (Deutsch et al., 2019; Lundberg et al., 2024; Willard and Louf, 2023; Koo et al., 2024) for applying constraints to LLMs consists of the following:

1. Based on the current state of the constraint, build a mask of valid next tokens.
2. Mask out logits for invalid tokens, normalize, and sample.
3. Based on the sampled token, update the constraint state for the next time step.

The above recipe is limited in a number of ways. First, the masking process is _myopic_(Shih et al., 2023), as the constraint is enforced _greedily_ on a per-token basis rather than jointly across the entire generation. This is as opposed to _Bayesian_ conditioning, where we consider the entire sequence.

Second, the constraint specification language is typically regular expressions, which can be significantly more verbose than their target compilation forms, deterministic finite automata (DFAs) (Gruber and Holzer, 2009, 2014; Koo et al., 2024). Lastly, there exists classes of constraint functions that can only be described by DFAs whose size grows exponentially in the size of their constraint.

In this work we develop an approach that departs from the previously established recipe for constraining LLMs, tackling all the aforementioned shortcomings in the process. Our approach starts with the observation that _an LLM sample induces a local, factorized distribution_\(\). We use a tractable compilation form, _constraint circuits_(Darwiche, 2011), that subsume DFAs on bounded-length strings while being more expressive efficient (Choi et al., 2020). That is, there are classes of functions that we can represent using constraint circuits that we could not otherwise as efficiently represent using DFAs (Bova, 2016). Such constraint circuits can be specified as Boolean python functions, alleviating the need for writing regular expressions or other domain specific languages.We show that we can leverage logical circuits to tractably condition \(\), drawing samples that are biased yet provably satisfy the constraint. Sampling from the LLM subject to a constraint \(\) then entails conditioning \(\) on \(\), drawing biased samples from \(()\), which we debias by reweighing them proportionally to their probability under the LLM and resampling. The returned samples are distributed according to the conditional LLM distribution while also satisfying the constraint.

We start our evaluation by testing our approach on the toy task of predicting shortest paths under an autoregressive model, and observe a significant improvement upon the baseline performance. Next, we evaluate our approach on the task of LLM detoxification where we show that, by virtue of its probabilistic nature, by simply disallowing a list of toxic expressions, our approach is able to steer the model away from toxic generations, outperforming previous approaches to detoxification. Lastly, we show that our approach achieves a perfect accuracy on Sudoku puzzles, compared to an almost \(26\%\) and \(45\%\) accuracy achieved by Gemini 1.5 Flash and GPT4-o models, respectively.

## 2 Background

### Notation and Preliminaries

We write uppercase letters (\(X\), \(Y\)) for Boolean variables and lowercase letters (\(x,y\)) for their instantiation (\(Y=0\) or \(Y=1\)). Sets of variables are written in bold uppercase (\(\), \(\)), and their joint instantiation in bold lowercase (\(\), \(\)). A literal is a variable (\(Y\)) or its negation (\( Y\)). A logical sentence (\(\) or \(\)) is constructed from variables and logical connectives (\(\), \(\), \(\), \(\)), and is also

Figure 1: **An illustration of our proposed approach. (left) An LLM induces a distribution over all possible sentences. Autoregressively sampling from the LLM distribution, we obtain a sentence (\(\)) \(}=\) [He’s, _full, _of, _sh!!t]. This sentence \(}\) violates a constraint \(\) that disallows toxic words, including the word “sh!t”. The subset of sentences that satisfy the constraint \(\) (\(\)) are denoted by \( m_{}\) (center) The sentence \(}\) induces a local, tractable approximation of the true distribution centered around \(}\). (right) We can efficiently condition this tractable approximation on the constraint \(\), trimming away portions of its support that do not satisfy the constraint. Sampling from the LLM distribution subject to the constraint \(\) then corresponds to sampling from the conditional approximate distribution and adjusting the sample weights using importance weighting. This yields a sentence (\(\)) \(=\) [He’s, _full, time, _employed] that satisfies \(\).**

called a (logical) formula or constraint. A state or world \(\) is an instantiation to all variables \(\). A state \(\) satisfies a constraint \(\), denoted \(\), if the sentence evaluates to true in that world. A state \(\) satisfying a constraint \(\) is said to be a model of \(\). We denote by \(m()\) the set of \(\)'s models. Throughout this paper, in reference to DFAs, we limit our discussion to those defined on bounded-length inputs, which are equivalent to ordered binary decision diagrams, or OBDDs (Bryant, 1992).

### A Probability Distribution over Possible Sentences

Let \(\) be a logical constraint defined over Boolean variables \(=\{Y_{11},,Y_{nk}\}\), where \(n\) denotes the number of time steps in the sentence, and \(k\) denotes the size of the vocabulary, i.e., the number of possible tokens at each time step. An autoregressive model induces a probability distribution \(p()\) over all possible sentences \(\). At every time step \(i\), the autoregressive model ensures that exactly one token is predicted; i.e., exactly one Boolean variable \(\{Y_{i1},,Y_{ik}\}\) can be set to true for each time step \(i\). We will write \(_{i}\) to denote that variable \(Y_{ij}\) is set to true in sentence \(\). More precisely, we let \(_{i}\{0,1\}^{k}\) be the one-hot encoding of \(Y_{ij}\) being set to \(1\) among \(\{Y_{i1},,Y_{ik}\}\). The probability assigned by the autoregressive model to a sentence \(\) is then defined as

\[p()=_{i=1}^{n}p(_{i}_{<i}),\] (1)

where \(_{<i}\) denotes the sentence prefix, \(_{1},,_{i-1}\).

### The State of Conditional Autoregressive Sampling

Sampling from an autoregressive distribution conditioned on a logical constraint \(\) constitutes a major challenge: computing the _exact_ conditional distribution \(p()=,)}{p()}\) is intractable even for the simplest constraints (Roth, 1993), e.g., asserting that the word "dog" appears at the end of the sentence. Intuitively, conditioning on \(\) requires that we compute the marginal probability of the constraint \(p()\), in turn requiring that we enumerate all sentences ending with the word "dog".

The defacto approach has therefore been to _greedily_ constrain the distribution, at every time step masking out logits that lead to generations that violate the constraint, followed by re-normalizing the conditional token distribution (Deutsch et al., 2019; Lundberg et al., 2024; Willard and Louf, 2023; Koo et al., 2024). Let the conditioning of the constraint \(\) on the prefix \(_{<i}\), which we write as \(_{|_{<i}}\), be a _subconstraint_ defined on \(_{i:n}\) that results from setting the variables \(_{1:i-1}\) to their values in \(_{<i}\). Semantically, \(_{|_{<i}}\) denotes the set of \(_{i:n}\) that, taken together with the prefix \(_{<i}\), would satisfy the constraint. Moreover, let \(_{i}_{>i}\,_{|_{<i}}\) denote the set of tokens allowed at the \(i\)-th position such that there exists some completion \(_{>i}\) of the sentence that satisfies the constraint \(\), given the current prefix \(_{<i}\). Then we can define the above greedy, or _myopic_, distribution as

\[p^{}()_{i=1}^{n}_{i },_{i}_{<i})}{_{j}p(y_{ij},_{i}_{<i})}= _{i=1}^{n}_{i}_{<i})[_{i}=_{i}]}{_{j}p(y _{ij}_{<i})[y_{ij}_{i}]},\]

Of note here is that since the approximate distribution is modeling the joint probability of the sentence and the constraint, in principle, the logical reasoning is sound, i.e., the constraint is guaranteed to hold. Rather, the shortcoming is in the way the _probabilistic reasoning_ is performed: instead of normalizing the joint distribution by the marginal probability of the constraint, we are performing it token-wise steering us towards sampling sequences that are locally likely rather than globally likely.

The second issue lies with the logical constraint along two different axes. First is the lack of conciseness of the constraint specification language. The most common language for specifying constraints is regular expressions which can be significantly more verbose (Gruber and Holzer, 2009, 2014; Koo et al., 2024) compared to the equivalent logical form. This is due to the inability to reference and reuse sub-expressions without introducing additional features such as lookaround operations which can cause an exponential blowup in the size of the target representations (Mamouras and Chattopadhyay, 2024), or backreferences that allow us to describe non-regular languages at the expense of an exponential runtime due to backtracking. Second is the lack of succinctness of the target representation. All of the current approaches compile the specified regular expressions into DFAs. DFAs represent Boolean functions by recursively performing Shannon-decomposition on the function: disjointing the value of the sub-function with the value of the current variable chosen to be true and false, respectively. Consequently, for many constraints of interest, the size of DFA can grow prohibitively. It turns out there there exists another class of target representation that subsume DFAs on bounded-length strings: at every step in the function decomposition we can branch not only on the value of a single variable, but rather that of an _entire sentence_(Darwiche, 2011). This class of target representations, which we shall henceforth denote as _constraint circuits_ are not only more succinct than DFAs in practice, but are provably exponentially more succinct: there are classes of functions with exponentially-sized DFAs but polynomially-sized constraint circuits (Bova, 2016).

## 3 Locally Constrained Resampling: A Tale of Two Distributions

We depart from the established recipe for conditional autoregressive sampling, providing a treatment of the problem from first principles that tackles all of the shortcomings detailed above. The crux of our approach is the idea that we can approximate the intractable autoregressive distribution \(p()\) using a local, tractable distribution \(()\). The distribution \(()\) is amenable to exact and efficient probabilistic reasoning, allowing us to efficiently condition on the constraint \(\) and draw samples from the distribution \(()\). We can transform the biased samples drawn from \(()\) into samples from \(p()\) by considering the discrepancy between the probability of the sample under the true distribution and the approximate distribution. More formally, we wish to draw samples from

\[p()=,)}{p()},\] (2)

which is intractable. Instead, we design a tractable proposal distribution \(q\) such that \(q()>0\) whenever \(p()>0\). We associate with a _constrained sample_\(\) an _unconstrained sample_\(}\), where \(\) can be understood as a _projection_ of \(}\) onto \(\) s.t. \(\). We define our proposal as

\[q()=_{}}p(}) p_{}}(),\] (3)

where \(p(})\) is the autoregressive distribution, and \(p_{}}()\) is a distribution over projections \(\) of the unconstrained \(}\) given the constraint \(\). The above definition outlines a two-step procedure for sampling a sentence \(\) that satisfies a given constraint \(\). We sample a sentence \(}\) autoregressively from \(p(})\), followed by sampling \(\) from the distribution conditioned on \(}\) and the constraint \(\), \(p_{}}()\). By incorporating the autoregressive distribution \(p(})\), we ensure that we can potentially generate any sentence. \(p_{}}()\) then refines \(}\) by _projecting_ it to satisfy the constraint \(\). It is straightforward to sample from \(p(})\), but what exactly is \(p_{}}()\), and how do we condition it on \(\)? Moreover, a proposal distribution typically implies biased samples; how do we correct for this bias?

### A Sample Induces a Local, Tractable distribution

Our goal is to design a probability distribution \(p_{}}()\) that is first, tractable for conditioning on the constraint \(\) and likelihood evaluation, and second, assigns high probability mass to sentences that are close to the model sample \(y\) and low probability mass to sentences that are far away, thereby providing a sample-efficient approximation of the true distribution (Koller and Friedman, 2009).

As noted earlier, the hardness of computing the conditional probability distribution in Equation (2) is in large part due to the autoregressive nature of the LLM distribution. A logical constraint might have exponentially-many solutions, yet lend itself to reusing of solutions to sub-problems, and therefore a tractable computation of the normalizing constant, the denominator in Equation (2). An example being the \(n\) choose \(k\) constraint (Ahmed et al., 2023b), where the conditional distribution can be computed in quadratic time under the fully-factorized distribution, despite having combinatorially many solutions. Moving away from fully-factorized distribution and towards autoregressive distributions, however, requires that we enumerate all sentences, even for very simple constraints.

To sidestep the hardness of the autoregressive distribution, we attempt to move towards the tractability of fully-factorized distributions, while retaining as much of the contextual information. To that end, we consider the _pseudolikelihood_\(()\) of a sentence \(}\)(Besag, 1975; Ahmed et al., 2023a), i.e.,

\[p(})(})_{i}p(}_{i}}_{-i}),\] (4)where \(}_{-i}\) denotes \(}_{1},,}_{i-1},}_{i+1},, }_{n}\). Unfortunately, Equation (4) above would still not ensure the tractability of Equation (2) since different solutions depend on different sets of conditionals. Instead, we define the pseudolikelihood of a sentence \(\)_in the neighborhood of a sentence \(}\)_

\[p_{}}()_{i}p(_{i}}_{- i})\] (5)

which can be understood as the _contextualized probability_ of a sentence \(\) given the context \(}\). We will next show how, given the structure of the contextualized pseudolikelihood distribution, we are able to efficiently condition it on a constraint \(\). Furthermore, Ahmed et al. (2023) have shown the contextualized pseudolikelihood distribution to be a local, high-fidelity approximation of the LLM distribution. That is, the distribution has low entropy, considering only assignments centered around the model sample, while at the same time having low KL-divergence meaning that our approximation is faithful to the true distribution in the neighborhood of the model sample.

### Constraint Compilation and Tractable Operations

We appeal to knowledge compilation, a class of methods that transform, or _compile_, a logical constraint into a tractable target form which represents functions as parameterized computational graphs, or _circuits_. Knowledge compilers allow us to programmatically specify constraints as Python (Meert, 2017) or PyTorch functions (Ahmed et al., 2022) from which they construct circuits. By enforcing certain structural properties on the compiled circuits we can enable the tractable computation of corresponding classes of probabilistic queries over the encoded functions. As such, circuits provide a language for both constructing and reasoning about tractable representations. An example of a logical constraint specified as a PyTorch function which gets compiled into a constraint circuit is shown in the bottom left of Figure 2 with the corresponding circuit in Figure 2, right.

Formally, a _logical circuit_ is a directed, acyclic computational graph representing a logical formula over variables \(\). Each node \(n\) in the DAG encodes a logical sub-formula, denoted \([n]\). Each inner node in the graph is an AND or an OR gate, and each leaf node encodes a Boolean literal (\(Y\) or \( Y\)). We denote by \((n)\) the set of a node \(n\)'s children. We associate with every node \(n\) a _scope_ function \(()\) such that \((n) X\) evaluates to the subset of variables the subfunction at \(n\) is defined over.

A circuit is _decomposable_ if the inputs of every AND gate depend on disjoint sets of variables i.e. for \(=\), \(()()=\). A circuit is said to be _structured-decomposable_ if every AND gate is decomposable, and any pair of AND gates sharing the same scope decompose in the same way. Intuitively, decomposable AND gates encode local factorizations over variables of the function. We assume that decomposable AND gates always have two inputs, a condition enforceable on any circuit in exchange for a polynomial size increase (Vergari et al., 2015; Peharz et al., 2020).

A second useful property is _smoothness_. A circuit is said to be _smooth_ if the children of every OR gate depend on the same set of variables i.e. for \(=_{i}_{i}\), we have that \((_{i})=(_{j})\  i,j\). Decomposability and smoothness are sufficient and necessary for tractable integration over arbitrary sets of variables in a single pass, as they allow larger integrals to decompose into smaller ones.

Further, a circuit is said to be _deterministic_ if, for any input, at most one child of every OR node has a non-zero output i.e. for \(=_{i}_{i}\), we have that \(_{i}_{j}=\) for all \(i j\). Similar to decomposability, determinism induces a recursive partitioning of the function, but over the support of the function. We consider a stronger form of determinism, _strong determinism_, A circuit is said to be _strongly deterministic_ if, for every OR node, \(=_{i}(_{i}_{i})\), the \(_{i}\)'s are mutually exclusive i.e., \(_{i}_{j}=\) for any \(i j\). Ensuring they are also exhaustive i.e., \(_{i}_{i}=\), along with structured-decomposability, we recover sentential decision diagrams (Darwiche, 2011), or _constraint circuits_.

Given a constraint circuit \(c_{}\) that encodes a logical constraint \(\) we can compute the pseudolikelihood \(()\) by feeding the probability of each literal at the corresponding leaf node and evaluating the circuit upwards, taking sums at OR gates and products at AND gates. This defines a distribution \(p_{}()\). To sample from the distribution, starting from the root node, we trace the circuit top-down, sampling a child at every OR-gate encountered. Figure 2 (center) shows an example of computing such a distribution, and Figure 2 (right) demonstrates the process of sampling from it.

### Intermezo: Constraint Circuits and DFAs

Constraint circuits can implement decisions of the form

\[_{i=1}^{m}_{i}()_{i}(),\] (6)

at OR gates, where \(\) and \(\) are disjoint _sets_ of variables, as opposed to DFAs that are restricted to Binary (or Shannon) decisions and therefore boil down to very special decisions of the form

\[( x_{1}())(x_{2}())\]

where the variable \(X\) is not in the variable set \(\). Therefore, constraint circuits are exponentially-sized DFAs, i.e., there are families of functions can only be represented by a exponentially-sized DFAs, but have a polynomially-sized constraint circuit (Bova, 2016). Barring such families of functions, constraint circuits are also empirically more succinct than DFAs (Xue et al., 2012). In practice, this also allows us to construct shallower (i.e., less layers) and wider (i.e., units per layer) constraint circuits that are more amenable to GPU parallelization (Liu et al., 2024), and can therefore exhibit a much lower vectorized computational complexity (Ahmed et al., 2023).

### Correcting Sample Bias: Importance Sampling\(\) Resampling

We have now sampled \(\) from our proposal distribution \(q()\), where \(\) is a projection of some latent unconstrained sample \(}\), and satisfies the constraint \(\). However, our proposal distribution \(q()\) might not align perfectly with our target distribution \(p()\). We therefore need to account for the mismatch between the two distributions, which we can do by defining importance weights that are a function of the original \(\), and its projection \(}\). We start by defining the true augmented distribution

\[p()_{}}p(,) p_{}(}).\] (7)

This factorization reflects the process of first generating a constrained sentence \(\), and marginalizing over all the unconstrained sentences \(}\) that could have given rise to \(\), and can be therefore be thought of as reversing the proposal distribution. We calculate the self-normalized importance weights

\[w=,) p_{}(})}{p(}) p_{}}( )}\] (8)

These weights quantify the discrepancy between the proposal and target distributions, allowing us to correct for the biased sampling. Note, however, that the importance sampling does not generate samples from the target distribution \(p()\), only a set of weighted particles. Rather, to transform our weighted particles into samples drawn from \(p()\) we need to apply a resampling step according to the importance weights. That is, given particles \(_{i}\) with their corresponding importanceweights \(w_{i}\), if we resample \(_{i}\) with replacement from \(\{_{1},,_{n}\}\) with probabilities proportional to the importance weights i.e.,

\[p^{*}(_{i})=}{_{j=1}^{n}w_{j}}\]

then \(_{i}\) is drawn from the true the distribution in the limit of a large sample size \(n\). Our full algorithm is shown in Algorithm 2, and follows PyTorch syntax (Paszke et al., 2019). One thing to note is the use of the canonize function on line \(6\) in Algorithm 2, where canonize returns the _canonical_ tokenization of an expression (Geh et al., 2024). This ensures that, e.g., in the case of language detoxification, we are banning all the possible ways of generating a given expression.1 We can now prove that Algorithm 2 is guaranteed to return samples that satisfy the constraint \(\). Our algorithm is implemented in log-space to preserve numerical stability while handling very small probabilities.

**Theorem 1**.: Locally Constrained Resampling in Algorithm 2 returns a sample \(\) s.t. \(\).

## 4 Related work

There has been a long line of work tackling constrained generation with LLMs. One of the earlier approaches was to use search-based decoding algorithms, such as NeuroLogic Decoding (Lu et al., 2021, 2022). While these methods explicitly search for high-probability sequences that satisfy the constraint, they face scalability issues due to the exponential growth of the search space as the sequence length increases. Another set of techniques that include GeDi (Krause et al., 2021), FUDGE (Yang and Klein, 2021), and NADO (Meng et al., 2022) employ auxiliary neural classifiers to approximate the intractable conditional distribution, but do not guarantee that the constraint is satisfied and require that a classifier be trained for every new constraint type. Approximate inference methods attempt to approximate the intractable conditional distributions (Qin et al., 2022; Hu et al., 2023; Lew et al., 2023) but suffer from high variance and do not guarantee constraint satisfaction.

Figure 2: **Constructing and sampling the proposal distribution.** (Top left) We start by sampling a sentence \(}\) from the model \(p\). Our goal is to compute the full conditional probability of every word in the vocab i.e., \((_{ij}) p(_{ij}}_{-i})\). We start by expanding the sampled sentence \(}\), including all sentences that are a Hamming distance of \(1\) away from the sample \(\). We proceed by (batch) evaluating the samples through the model, obtaining the joint probability of each sample. We then normalize along each column, obtaining the conditionals \(p(_{ij})\). (Bottom left) We can easily specify a logical constraint that prevents the word “ hate” from appearing as a simple python function that gets compiled in the constraint circuit on the right. (Center) A logical circuit encoding constraint –hates, with a simplified vocab is shown in the figure. To construct the distribution \(p_{}}()\), we feed the computed contextual probabilities at the corresponding literals. We push the probabilities upwards, taking products at AND nodes and sums at OR nodes. This induces a distribution \(p_{}}()\). (Right) To sample a from this distribution, we start at the root of the circuit, sampling a child of every OR gate according to the logits of the distribution, and concatenating at every AND gate. In this case, we sample the sentence “He loves dogs” satisfying the constraint.

Recently Outlines (Willard and Louf, 2023) and Guidance (Lundberg et al., 2024), and along similar lines SGLang (Zheng et al., 2024), were proposed, also guaranteeing that the constraint is satisfied. Outlines employs a precompilation step where constraints specified in regular expressions are compiled into DFAs that are "indexed" to create a token-based overlay. This overlay guides the decoding process, ensuring adherence to the constraints. Koo et al. (2024) recently recast the entire process in an automata-theoretic framework. Similar to Outlines, Guidance utilizes a trie to efficiently store and search through valid token continuations based on the grammar. This allows for dynamic vocabulary matching at each decoding step, offering flexibility potentially at the cost of impacting efficiency. These approaches are considered the "defacto" approaches for constrained generation.

More recently, GeLaTo (Zhang et al., 2023) and subsequently CTRL-G (Zhang et al., 2024) have utilized Hidden Markov Models (HMMs) to guide the generation from LLMs towards constraint satisfaction, but requires training a new HMM for every target model. The very recently proposed ASAp (Park et al., 2024) aims to debias the greedy approach through repeated sampling and discovery of mass assigned to non-grammatical completions, reducing each overapproximation to make it more accurate. While similar in intention, our approach relies on a closed-form tractable approximation of the target distribution to correct for the bias, avoiding the need to oversample the LLM.

Finally, some other approaches no longer predictively mask logits, but instead sample unconstrained continuations and reject invalid ones post-hoc. For example, PICARD (Scholak et al., 2021) converts the top-\(k\) tokens to text and performs various levels of validation. While such approaches are very simple in principle, and in fact perform exact Bayesian conditioning, the number of samples required can be prohibitive, especially when the constraint requires selecting very low probability tokens.

## 5 Experimental Evaluation

We evaluate our approach Gen-C on several tasks spanning a number of domains. We start by evaluating on Warcraft shortest-path finding, where we are given an image of a Warcraft tilemap, and are tasked with _autoregressively_ generating one of the potentially many minimum-cost paths between two end points conditioned on the map, where the cost is determined by the _underlying_ cost of the tiles spanned by the path. We move on to evaluating on the classic, yet challenging, task of solving a \(9 9\) Sudoku puzzle where an LLM is presented with an incomplete Sudoku puzzle and asked to provide the solved puzzle without extraneous text. We also evaluate on the task of LLM detoxification. In this task, we are interested in the generations produced by an LLM when presented with a prompt input by the user. More specifically, we are interested not only in how good these models are at the modeling aspect, but also how _toxic_ their outputs might be, a measure which includes sexual explicitness, identity attacks, and profanity, among others. Our goal in this task is then to shift the model's distribution away from toxic generations, and toward nontoxic ones, all while maintaining its original ability to model text. We believe this to be a timely and important problem due to the prevalence and widespread usage of LLMs coupled with the fact that previous work (Gehman et al., 2020) has found non-negligible amounts of toxic, harmful, and abusive text in the corpora used to train LLMs. Experimental details, hardware specifications, and training details are provided in the appendix. The implementation for our approach and the code to reproduce all of our experiments will be made publicly available.

Warcraft Shortest PathFor this task, we follow the experimental setting set forth by Pogamcic et al. (2020), where our training set consists of \(10,000\) terrain maps curated using Warcraft II tileset. Each map encodes a \(12 12\) grid superimposed on a Warcraft terrain map, where each vertex is weighted according to the cost of the tile, which in turn depends on type of terrain it represents e.g., earth has lower cost than water. These costs are _not_ presented to the network. The task is then to

 Test accuracy \% & Exact & Consistent \\   CNN-LSTM & \(62.00\) & \(76.60\) \\  + oversampling & \(69.10\%\) & \(84.50\%\) \\ + Gen-C (Ours) & \(\%\) & \(\%\) \\  
 Test accuracy \% & Exact & Consistent \\   Gemini 1.5 Flash & \(31.00\% 4.19\) & \(31.00\% 4.19\) \\ GPT-4o mini & \(40.90\% 7.90\) & \(40.90\% 7.90\) \\  Gen-C (Ours) & \(\%\) & \(\%\) \\ 

Table 1: Experimental results on Warcraft.

generate a minimum-cost path from the upper left to the lower right vertices, where the cost of a path is defined as the sum of costs of the vertices visited by the edges along the path, and the minimum-cost path is not unique, i.e., there exists many correct paths with the minimum cost. The minimum cost path between the top left and bottom right vertices is encoded as an indicator matrix.

We use a CNN-LSTM model, where, presented with an image of a terrain map, we use a ResNet18 (He et al., 2016) to obtain a \(128\) image embedding, which is then passed on to an LSTM with a single layer, a hidden dim of size \(512\), and at every time step predicts the next edge in the path conditioned on the image embedding and previous edges. The constraint used in this task is that the predicted edges form a valid simple path from the upper left vertex to the lower right corner of the map.

As has been established in previous work (Xu et al., 2018; Ahmed et al., 2022b;c), the accuracy of predicting individual labels is often a poor indicator of the performance of the neural network in neuro-symbolic settings, where we are rather more interested in the accuracy of our predicted structured object _exactly_ matching the groundtruth label, e.g., _is the prediction a shortest path?_, a metric which we denote "Exact" in our experiments, as well as the accuracy of predicting objects that are _consistent_ with the constraint, e.g., _is the prediction a valid path?_, a metric denoted "Consistent". Our results are shown in Table 1. We compare against two different baselines: the baseline model trained on the task, and _oversampling_, whereby we draw many samples conditioned on the input image, and then resample this distribution, a variant of our approach where the proposal distribution is the autoregressive model itself. We find that our approach improves the exact match from \(62.00\%\) and \(69.10\%\) to \(78.13\%\) while guaranteeing the sampled sequences of edges constitute valid paths, as

SudokuNext, we consider the task of predicting a solution to a given Sudoku puzzle. Here the task is, given a \(9 9\) partially-filled grid of numbers to fill in the remaining cells such that the entries each row, column, and \(3 3\) square are unique i.e., each number from \(1\) to \(9\) appears exactly once. We use the dataset provided by Wang et al. (2019), consisting of 10K Sudoku puzzles, split into 9K training examples, and 1K test samples, all puzzles having 10 missing entries.

Each LLM is prompted with the string "Give me the solution of the following Sudoku without any extra text or quotes" followed by the Sudoku Puzzle. As baselines, we used Gemini 1.5 Flash and GPT-4o mini, and post-process the responses to remove any extraneous text returned by the LLM. We compare the baselines against Llama3-8B constrained using our approach Gen-C, with the constraint that the elements of every row, column and \(3 3\) square are unique. Our results are shown in Table 2. We see that where as Gemini and GPT4o are able solve only \(26\%\) and \(45\%\) of the Sudoku puzzles, our approach consistently manages to recover the correct Sudoku Puzzle solution.

LLM detoxificationLastly, we consider the task of LLM detoxification. That is, we investigate the effectiveness of logical constraints, enforced using Gen-C, at steering the model away from toxic prompted-generations. We choose a _very_ simple constraint to be enforced by Gen-C throughout this task, namely we ban any of a list of "bad words", including profanity, slurs, and swear words' from appearing as part of the model's generations. Similar to previous work (Gehman et al.,

    &  &  & **PPL (\(\))** \\  & **Full** & **Toxic** & **Nontoxic** & **Full** & **Toxic** & **Nontoxic** & **PPL (\(\))** \\  Llama3-8B & \(0.25\) & \(0.43\) & \(0.20\) & \(14.26\%\) & \(38.30\%\) & \(7.60\%\) & \(14.45\) \\  + Word Banning & \(0.24\) & \(0.40\) & \(\) & \(12.47\%\) & \(32.43\%\) & \(6.93\%\) & \(\) \\ + Gen-C _(ours)_ & \(\) & \(\) & \(\) & \(\%\) & \(\%\) & \(\%\) & \(\) \\   

Table 3: Evaluation of LLM toxicity and quality across different detoxification methods on Llama3-8b. Model toxicity is evaluated on the RealToxicityPrompts benchmark through Perspective API. **Full**, **Toxic** and **Nontoxic** refer to the full, toxic and nontoxic subsets of the prompts, respectively. **PPL** refers to the perplexity of Llama3-70B on the model generations using 5 different seeds. In line with Gehman et al. (2020); Wang et al. (2022), we characterize toxicity using two metrics: the **Expected Maximum Toxicity** over \(5\) generations, and the **Toxicity Probability** of a completion at least once over 5 generations.

2020; Wang et al., 2022), we evaluate on the RealToxicityPrompts, a dataset of almost 100k prompts ranging from nontoxic, assigned a toxicity score of \(0\), to very toxic, assigned a toxicity score of \(1\). We focus on Llama3-8B (Radford et al., 2019) as a base model for detoxification. As is customary, (Gehman et al., 2020; Wang et al., 2022), we use Perspective API, an online automated model for toxic language and hate speech detection, to score the toxicity of our predictions. It returns scores in the range \(0\) to \(1.0\), corresponding to nontoxic on the one end, and extremely toxic on the other. The toxicity score can be interpreted as the likelihood of given person perceiving the text as being toxic or offensive. Though not without limitations, studies (Wang et al., 2022; Welbl et al., 2021) have shown that the toxicity scores reported by Perspective API are very strongly correlated with human evaluations.

We compare Llama3-8B against Word Banning, which for this simple constraint functions very similarly to Outlines (Willard and Louf, 2023) and Guidance (Lundberg et al., 2024). It keeps track of the words generated so far, and prevents the banned expression from appearing by setting its probability to \(0\). Word Banning could therefore be seen of as a greedy approximation of what we might hope to achieve using Gen-C: intuitively, it might not be able to recover from generating a sentence associated with a toxic intent as a result of making greedy decision at every step of the generator. We report the _Expected Maximum Toxicity_ and the _Toxicity Probability_. The _Expected Maximum Toxicity_ measures the worst-case toxicity by calculating the maximum toxicity over \(25\) generations under the same prompt with different random seeds, and averaging the maximum toxicity over all prompts. This metric can be seen as a measure of how intensely offensive a generation is. _Toxicity Probability_ estimates the empirical probability of generating toxic language by evaluating the fraction of times a toxic continuation is generated at least once over \(25\) generations with different random seeds for all prompts. This metric can be seen as a measure of how likely the LLM is to be offensive. Both of the above metrics are computed for the full set of prompts, only the toxic subset of the prompts, and only the nontoxic subset of the prompts. To understand the impact of detoxification, we evaluate the quality of the LLM generations by measuring the perplexity of the generations according to Llama3-70B averaged across \(5\) different runs. Our results are seen in Table 3.

We can see that word banning lowers the toxicity of the generations produced by Llama3-8B at a negligible decrease in perplexity. More specifically, we observe that it reduces the average worst-case toxicity as well as the probability of producing a toxic generation when prompted with nontoxic prompts by a modest \(1\%\), but when prompted with nontoxic prompts the reduction in toxicity is much higher at \(3\%\) and almost \(6\%\) for the expected maximum toxicity and toxicity probability, respectively. Moving on to constraining our Llama3-8B with our approach Gen-C attains the same perplexity as using word banning, but greatly reduces the toxicity of Llama3-8B, especially on toxic prompts where it results in almost twice as much the reduction in toxicity affected by word banning, both in terms of the expected maximum toxicity as well as the toxicity probability.

## 6 Conclusion and Future Work

We proposed a new approach for constraining LLMs which we called Gen-C. Given a logical constraint, Gen-C guarantees that an autoregressive model's generations satisfy the constraint. Gen-C is probabilistically sound, while providing a concise constraint specification language as well as an exponentially more succinct compilation form compared to current defacto approaches to controlled generation. We have showed that Gen-C can be applied to autoregressive models such as LSTMs as well as large scale LLMs, outperforming the baselines on the tasks of minimum-cost paths prediction, language as well as solving Sudoku puzzles, where we achieved a perfect accuracy, beating both GPT-4o and Gemini 1.5 by a large margin. We have also shown that by virtue of its probabilistic nature, Gen-C is able to outperform current approaches for constrained generation on LLM detoxification using only a list of toxic expressions as a constraint, relying on probabilistic inference.

Moving forward, we envision extending and building upon Gen-C in a multitude of ways. First, on the systems side since Gen-C extensively uses the language of tractable circuits, we plan on a tight integration with circuits libraries, such as pyjuice (Liu et al., 2024) to greatly improve the efficiency of our approach, as well as open the door for many potentially interesting probabilistic queries. Second, we hope to explore more applications of constrained generation, with one alluring possibility being the use of constraints to improve the factual accuracy of current LLMs.