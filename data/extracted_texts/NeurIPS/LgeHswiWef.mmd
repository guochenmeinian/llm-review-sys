# Enhancing Protein Mutation Effect Prediction through a Retrieval-Augmented Framework

Ruihan Guo\({}^{*1}\), Rui Wang\({}^{*1}\), Ruidong Wu\({}^{*1}\), Zhizhou Ren\({}^{1}\), Jiahan Li\({}^{1}\)

**Shitong Luo\({}^{1}\), Zuofan Wu\({}^{1}\), Qiang Liu\({}^{1,2}\), Jian Peng\({}^{1}\), Jianzhu Ma\({}^{1,3}\)**

\({}^{1}\)Helixon Research, \({}^{2}\)The University of Texas at Austin University

\({}^{3}\)Institute for AI Industry Research, Tsinghua

guoruihan.sansi@gmail.com

majianzhu@tsinghua.edu.cn

###### Abstract

Predicting the effects of protein mutations is crucial for analyzing protein functions and understanding genetic diseases. However, existing models struggle to effectively extract mutation-related local structure motifs from protein databases, which hinders their predictive accuracy and robustness. To tackle this problem, we design a novel retrieval-augmented framework for incorporating similar structure information in known protein structures. We create a vector database consisting of local structure motif embeddings from a pre-trained protein structure encoder, which allows for efficient retrieval of similar local structure motifs during mutation effect prediction. Our findings demonstrate that leveraging this method results in the SOTA performance across multiple protein mutation prediction datasets, and offers a scalable solution for studying mutation effects.

## 1 Introduction

Protein fitness plays significant roles in diverse applications in pharmaceutical industry (Amara, 2013), drug design (De Carvalho, 2011), biofuel production (Huang et al., 2020), and environmental bioremediation (Lu et al., 2022). Deciphering mutation effects on protein fitness is crucial for understanding their functional dynamics and yet remains a central challenge in molecular biology. Most recent breakthroughs on computational predictions of mutation effects are driven by coevolutionary information (Riesselman et al., 2018; Luo et al., 2021; Notin et al., 2022). The mutations on contacting residue pairs would become correlated under the evolutionary pressure to maintain protein stability and optimize functional efficiency within cellular environments. Consequently, conserved patterns within protein sequences and structures typically signify their stability and functionality. The predominant methodology to exploit such coevolutionary patterns is to perform multiple sequence alignments (MSA) (Thompson et al., 1994, 1997) and fit either statistical (Seemayer et al., 2014) or machine learning models (Rao et al., 2021). In addition to sequence-level alignments, performing domain-level structure clustering (Orengo et al., 1997; Dong et al., 2018) is also a promising approach to extract evolutionary information from a protein family.

In this paper, we explore an alternative perspective to retrieve information for mutation effect prediction. In contrast to the global protein representation considered by MSA and domain-level structure alignments, we extract coevolutionary information in the scope of local microenvironments. We focus on the alignment of local structure motifs, _i.e._, a central amino-acid with a few contacting neighbors. Such a local representation of coevolutionary information is specialized to the scenarios of protein engineering, where a common practice involves introducing a few point mutations to enhance a desired function (Shroff et al., 2020). It is widely observed that the effects of point mutations are mainly given by the alteration of local biochemical microenvironments (Kim et al., 2011; Lu et al.,2022]. Given these empirical insights, we propose to retrieve local structure fragments with similar backbone positions as auxiliary information for mutation effect prediction, while withdrawing the constraint on global sequence/structure similarity. This microscopic retrieval mechanism enables us to extract atom-level information from the whole protein universe rather than restricting to molecule-level instances within a certain protein family.

To elucidate the intricate details of local coevolutionary patterns in proteins, we employed a structure-based embedding approach, ESM-IF [Hsu et al., 2022], to encode local structure motifs into latent embeddings, assuming the metric space of such embeddings measures the similarity of motif structures. We preprocess the entire Protein Data Bank (PDB) [Berman et al., 2003] and build a database, we call Structure Motif Embedding Database (SMEDB), to support fast information retrieval by GPU-accelerated \(k\)-nearest neighbors (kNN) search. This retrieval procedure, we call Multiple Structure Motif Alignment (MSMA), is designed to extract coevolutionary information from protein fragments with similar local structure. We rigorously evaluate these extracted embeddings, focusing on their structural similarity and predictive accuracy for mutation effects. Remarkably, the embeddings derived from local coevolutionary patterns demonstrate superior performance compared to those obtained from traditional Multiple Sequence Alignments (MSA). Furthermore, the distribution of these embeddings was found to be complementary to those derived from MSA profiles, indicating that they capture distinct aspects of coevolutionary information, thereby enhancing our understanding of protein structure and function dynamics.

In addition, we introduce a novel model architecture, called Multi-Structure Motif Invariant Point Attention (MSM-IPA), to aggregate the retrieved coevolutionary motif information for predicting the structural fitness of proteins. This model, which effectively incorporates mutational information, has an outstanding capability to generalize across various mutations. It is trained to predict the change in binding free energy (\(\)G) on protein surfaces, an essential element for assessing protein-protein interactions. We extensively evaluate our model on a suite of widely-used protein stability and binding affinity benchmarks, including S669 [Pancotti et al., 2022], cDNA [Tsuboyama et al., 2023], and SKEMPI [Jankauskaite et al., 2019] and demonstrate substantial improvement over baseline methods.

Our contributions are as follows:

* We develop Structure Motif Embedding Database (SMEDB), a comprehensive local structure alignment database encompassing all structures from the Protein Data Bank (PDB), which is organized to accelerate GPU-based kNN search.
* We propose Multiple Structure Motif Alignment (MSMA) to retrieve local coevolutionary motifs based on embeddings of protein structure encoders, which is shown to be complementary to classical sequence-level retrievals.
* Our model, Multi-Structure Motif Invariant Point Attention (MSM-IPA), pretrained on our novel database and retrieval mechanism, demonstrates superior performance in predicting \(\)G, surpassing other models on benchmark datasets, i.e., S669 and SKEMPI.

## 2 Preliminaries

DefinitionsA protein consists of multiple residues, possibly from different chains. For each residue \(i\), we represent the residue as its residue type \(a_{i}\{1,,20\}\) and its positions of backbone heavy atoms with \(_{i,C},_{i,C},_{i,N}^{3}\). A structure motif \(\) is a fragment of the whole protein structure with \(N\) residues. For the raw structure motif \(_{}\), we choose \(N_{}=256\) to match the pretraining settings and keep enough information about raw structure. For the retrieved structure motif (denoted as \(\{_{i}\}_{i=1}^{L}\), where \(L\) is the size of the retrieved motif set), we choose \(N_{}=16\) to ensure sufficient interactions from similar environments are captured.

Our approach uses ESM-IF as a pretrain model and CUHNSW for vector database implementation. Here we make a brief introduction to these two methods.

ESM-IFESM-IF [Hsu et al., 2022] is a model designed for protein sequence prediction using backbone structures. This approach treats inverse folding as a sequence-to-sequence problem with an autoregressive encoder-decoder architecture, allowing the model to recover native sequences from backbone atom coordinates. By incorporating a large number of sequences with predictedstructures as additional training data, ESM-IF effectively learns even when experimental structures are unavailable. The augmented data and backbone-only input make ESM-IF a suitable model to encode the nearby backbone structure of a residue.

CuHnswCUHNSW is a CUDA implementation of Hierarchical NSW (HNSW), a novel approach of vector database that can do approximate K-nearest neighbor (K-NN) search utilizing navigable small world graphs with a controllable hierarchy. Unlike traditional methods, CUHNSW is fully graph-based and eliminates the need for additional search structures. It incrementally builds a multi-layer structure of proximity graphs, with elements randomly assigned to layers using an exponentially decaying probability distribution. This method enhances performance by starting the search from upper layers and leveraging scale separation, resulting in logarithmic complexity scaling. Performance evaluations show that CUHNSW outperforms previous state-of-the-art vector-only approaches and its similarity to the skip list structure allows for straightforward distributed implementation.

## 3 Methodology

### Multiple Structure Motif Alignment

We use per-residue embeddings extracted by ESM-IF model  for each of the protein chains in PDB database and perform local structure search by HNSW. To obtain embeddings for ESM-IF, we utilize the encoder module named GVPTransformerEncoder in ESM-IF to generate a 512-dimensional embedding for each residue. As we exclusively use the encoder module of ESM-IF, the computational cost remains manageable, requiring approximately 3 days on 32 A100 GPUs.

The PDB dataset comprises more than 130 million residues, making it impractical to load the entire dataset into memory for querying. Traditional databases lack the capability to leverage GPU acceleration for efficiently querying the top \(k\) nearest neighbors. To address this, we integrate CUHNSW as a module to obtain the \(k\)-nearest neighbors in the ESM-IF embedding space. The structure motifs are retrieved for their similar local interactions between residues that have similar backbone positions. The interaction between residues occurs only when they are in close proximity. Therefore, when processing the retrieved structure motifs, a large motif size is not necessary. For simplicity, in this paper, we always use \(N_{}=16\). With a highly efficient CUDA implementation  the

Figure 1: Overview of the retrieval augmented framework. (a) Multiple Structure Motif Alignment process. (b) A diagram illustrating MSM-Mut, a model that can predict mutation effect with information get from multiple structure motif alignment.

time consumption querying the top \(10^{5}\) neighbors of a result is about 8 seconds in 8 A100 GPUs and only 0.5 seconds for the top \(10^{3}\) neighbors.

The advantage of using an inverse folding model as a structure encoder, compared to traditional methods that rely on retrieving from a database based on continuous structural fragments, lies in the model's inherent ability to generate embeddings tailored for predicting the surrounding environment based on a given backbone structure. The inverse folding model encodes positions within the spatial context that significantly influence the central amino acid type, rather than merely contiguous positions along the sequence.

Since we use embeddings from a structure encoder (ESM-IF in this case) instead of directly search on structures, we would like to validate the performance of the embedding retrieval method by checking the matched motif size \(N_{}\) of the search result comparing with that of structure search. We first define the _matched_ motif size as

\[N_{}=_{i N_{}}[_{j N_{ }}((R_{,i},R_{,j}))<2.0]\] (1)

The left panel of Figure 2 illustrates the distribution of alignment sizes for the retrieved structures, demonstrating that numerous similar spatial structures can be found centered on each position. The other panel of Figure 2 shows the relationship between local similarity (number of matching amino acids) and overall similarity (TM-score) with different motif size. The figure show that the similar motif may have low TM-score, indicating that our search approach can extract analogous local structures motif from structurally unrelated proteins to aid in prediction.

### Multi Structure Motif Modelling

In this section, we introduce how we utilize the retrieved structure motifs to help predict the effects of mutations. We begin by discussing the filtering of retrieved structure motifs, followed by the superposition of retrieved data, which enables the model to learn information from diverse structures. Finally, we introduce our module, MSM-IPA, which extracts similarity information from the PDB database.

Retrieved Structure Motif FilterAfter extraction, we obtain a large volume of neighbor data (on the order of \(10^{3}\)). For efficiency reasons, we only reserve \(L_{}=16\) data points with most valuable information. This is done in the following manner: Firstly, retrieved structure motifs with central amino acid different from query are discarded. After that, We rank them with a scoring function and retain the top results. The scoring formula can be expressed as follows:

\[_{i N_{}}[_{j N_{}}((R_{,i},R_{,j}))<2.0](-\|p_{i,C }-p_{0,C}\|_{2})\] (2)

Figure 2: CUHNSW combined with embeddings from ESM-IF successfully retrieved motifs with large _matched_ regions, and possibly motifs distant in sequence identity, where matched residues are defined by the indicator function in Eq. (1). Moreover, lower TM-Score is obtained for motifs with high number of locally matched residues, indicating that our search approach can extract analogous local structures motif from structurally unrelated proteins.

where \([]\) is the indicator function and the distance function \((R_{1},R_{2})=\|p_{1,C}-p_{2,C}\|_{2}\). Intuitively, we use the weighted term \((-\|p_{i,C}-p_{0,C}\|_{2})\) to rewrite Eq. (1) to retain as many contacts around the central amino acid as possible.

When dealing with multiple mutations, which involves several central amino acids, we ensure a balanced selection of retrieved structure motif information by using each central amino acid as a query. This approach guarantees an even distribution of the retrieved information across all central amino acids.

In the context of mutation analysis, we conduct separate selection processes for both the pre-mutation (wild type) and post-mutation states. The key distinction between these two processes is the amino acid type in the initial step--one being the wild type and the other the mutated form.

SuperpositionThe choice of superimposition method depends on the nature of the extracted information. We compare two superimposition approaches: alignment based on the central frame and alignment based on the overall structure. Experimental results indicate that the central frame-based alignment method provides better alignment quality for the retrieved structures. Consequently, we select the central frame-based alignment method for subsequent analyses.

For each residue, we can construct the frame from its backbone atom positions \(_{C}\), \(_{C_{}}\), \(_{N}\).

\[_{N,C_{}} =(_{N}-_{C_{}})/\|_{N}-_{C_{}}\|\] \[_{C,C_{}} =(_{C}-_{C_{}})/\|_{C}-_{C_{}}\|\] \[ =[_{N,C_{}},_{C,C_{}},_{N,C_{ }}_{C,C_{}}]\] \[ =_{C_{}},\]

where \(\) is the cross product between two vectors.

Hence with the given raw structure motif \(_{}\) and any other structure motif \(_{}\), we firstly take out the central residue \(_{}^{C}\) and \(_{}^{C}\). Then we can calculate the frame of both the residues, called \((_{C},_{C})\) and \((_{},_{})\) respectively. Then we can define the alignment function as:

\[_{}()=_{C}_{}^{T}( {p}-_{})+_{C}.\]

The alignment procedure involves applying the alignment function to each atom of \(_{}\) to obtain the aligned motif \(_{}^{}\). For simplicity, in the following sections, we will omit the term "aligned" and assume that all motifs are aligned with the raw motif by default.

Msm-IpaTo retrieve information from structure motifs, we propose Multi-Structure Motif Invariant Point Attention (MSM-IPA), which is inspired by and similar to the IPA module in AlphaFold2 (Jumper et al., 2021). The MSM-IPA module takes the raw structure motif \(_{}\) and the processed retrieved structure motifs \(_{1},,_{L}\) as input. For simplicity, we merge the raw motif with the retrieved motifs into a single motif, denoted as \(_{}=\{r_{i}, i\{1,,L\}\} \{r_{}\}\). \(_{}\) is then used as _key_ motifs in the cross attention mechanism. The size of this combined motif is represented as \(N_{}\).

To extract information from the motif, we define two encoders, \(_{s}()\) for single node-wise representations and \(_{z}(_{1},_{2})\) for pair edge-wise representations. The single encoder encodes the residue types and positions of atoms into a single representation, \(\). The pair encoder encodes information such as relative positions in the sequence, spatial relative positions, and amino acid type pairs into a pair representation, \(\).

In MSM-IPA, we extract scalar and vector representations from \(\). The attention weights are updated and aggregated from three sources of information: single, pair, and predicted points. This approach ensures that the model efficiently utilizes the information while maintaining invariance to overall rotation and translation. The updated single representation of the raw structure motif is obtained by concatenating the weighted sums of each data representation. The detailed implementation of this algorithm is shown in Algorithm 1.

MSM-MutThe MSM-Mut model mainly consists of two parts: a series of MSM-IPA to fusion the information and a mutation effect predictor consisted of a series of MLP. For both the wild-type and mutated structures, we retrieve structure motifs independently, merge the information using MSM-IPA, and model it with IPA to obtain the single representations for both structures. These representations are then fed into the mutation effect predictor to get the final impact on the structure.

### Model Training Details

Our model training comprises two phases. In the pretraining phase, we utilize a meticulously curated dataset from the Protein Data Bank-REDO (PDB-REDO) (Joosten et al., 2014) for our pretraining data. The dataset is split into training, validation, and test sets in a ratio of 95%:0.5%:4.5%. The pretraining process involves an initial 200,000 steps without the inclusion of retrieved structure motifs, followed by an additional 30,000 steps incorporating retrieved structure motifs. During training, a random amino acid was selected, and its 256 nearest amino acids are extracted with their amino acid types and backbone atom positions. The type of the central amino acid was masked since the model was tasked with predicting it.

In the finetuning phase, to ensure comparability of our model, we follow the settings of StableOracle and RDE. For the stability mutation effect prediction task, we use the CDNA120K (Tsuboyama et al., 2023) subset of the training set, which was deduplicated against s669 in StableOracle. For the PPI surface mutation effect prediction task, we perform 3-fold cross-validation on the SKEMPI dataset, partitioned by PDBID.

## 4 Results

In this section, we show that our model outperforms other models on a series of tasks with the retrieved MSM information. To begin with, in section 4.1.1, we demonstrate that the retrieved information provides an advantage in predicting mutation effects on protein-protein interfaces. Subsequently, in section 4.1.2, we present a case study on antibody engineering for SARS-CoV-2, illustrating our model's strong performance on real-world targets. In addition, in section 4.2.1, we conducted an experiment to show that our model outperforms others on the protein stability change dataset. To further validate our model's capability in stability prediction, in section 4.2.2, we tested it on a novel enzyme dTM dataset and achieved excellent results.

Baseline modelsThe baselines referenced in this study encompass two main categories: unsupervised models, and semi-supervised/supervised models. The unsupervised models comprise PSSM (position-specific scoring matrix), ESM-1v (Meier et al., 2021), MSA Transformer (Rao et al., 2021), Tranception (Notin et al., 2022), ESM-IF (Hsu et al., 2022), ProteinMPNN (Dauparas et al., 2022), Rosetta (Park et al., 2016; Alford et al., 2017), and FoldX (Delgado et al., 2019). The semi-supervised category includes MIF-Net (Yang et al., 2023), RDE-Net (Luo et al., 2023), and DiffAffinity (Liu et al., 2024), while supervised models encompass DDGPred (Shan et al., 2022) and the End-to-End method.

Evaluation metricsIn this section, we employ six metrics to evaluate our model: Pearson and Spearman correlations to quantify overall trends, per-structure metrics to assess the model's ability to identify beneficial and detrimental mutations within each structure, and RMSE and MAE to measure numerical differences in predicted energy values. Among these, the most critical metric is the per-structure correlation, as practical applications often involve ranking different mutations within the same structure.

### Mutation Effects Prediction on PPI Surface

Following the settings in RDE (Luo et al., 2023), we partitioned the dataset into three folds based on PDB IDs. Two of these folds were further divided into training and validation sets in a 95:5 ratio based on PDB IDs, while the remaining fold was used as the test set. By training in this manner, we obtained three distinct sets of model parameters, each corresponding to the performance measured on the entire dataset used as the test set.

#### 4.1.1 Experimental Results on SKEMPI2.0

This experiment primarily demonstrates two key points. Firstly, we establish a simple baseline that directly utilizes the top 100 retrieved structure motifs obtained from our search to construct a profile, _i.e._, simple statistics of the amino-acid types according to the retrieval results. This baseline, called MSM-profile, achieves significantly better performance compared to MSA, and even surpass the majority of unsupervised language models. Note that MSM-profile is built upon the embeddingsobtained from the ESM-IF model, and we observed that the per-structure Pearson and Spearman correlation coefficients extracted directly are comparable to those predicted by the ESM-IF model. This indicates that our search method effectively retains the information from ESM-IF, allowing us to explicitly extract local structure motifs corresponding to the ESM-IF distribution.

Secondly, the semi-supervised model trained with the enhanced information achieved state-of-the-art performance across almost all metrics. Among the metrics, the per-structure correlation is the most crucial, as it reflects the model's ranking capability for mutations on PPI surfaces. We found that the use of the information we extracted resulted in a significant improvement in the model's prediction correlation, underscoring the value of the retrieved information.

#### 4.1.2 SARS-COV-2 Antibody Optimization

In Shan et al. (2022), five single mutations are identified that enhance the neutralization effectiveness of antibodies against SARS-CoV-2. Within the three CDR regions in the heavy chain, spanning a total of 26 positions, there are 494 possible mutations. Our task is to select these five beneficial mutations from the pool. We compare our results with a subset of the baseline methods that performed well in Section 4.3. Experimental results indicate that our model excels in predicting the ranking of RH103M, while also maintaining high ranks for the other four mutations. This improvement is attributed to our model's ability to extract similar structure motifs from the database.

Case Study: RH103MGiven that this task focuses on antibody optimization, we incorporated a post-processing step in the retrieval process. We prioritize those retrieved data corresponding to an antibody or nanobody and if the relevant position was located in a loop region. At position H103,

    &  &  &  \\  & & Pearson & Spearman & Pearson & Spearman & RMSE & MAE \\   & Rosetta & 0.3284 & 0.2988 & 0.3113 & 0.3468 & 1.6173 & 1.1311 \\  & FoldX & 0.3789 & 0.3693 & 0.3120 & 0.4071 & 1.9080 & 1.3089 \\   & PSSM & 0.0826 & 0.0822 & 0.0159 & 0.0666 & 1.9978 & 1.3895 \\  & **MSM-profile** & 0.1905 & 0.1886 & 0.1653 & 0.2063 & 1.9423 & 1.3784 \\   & ESM-1v & 0.0073 & -0.0118 & 0.1921 & 0.1572 & 1.9609 & 1.3683 \\  & MSA Transf. & 0.1031 & 0.0868 & 0.1173 & 0.1313 & 1.9835 & 1.3816 \\  & Tranception & 0.1348 & 0.1236 & 0.1141 & 0.1402 & 2.0382 & 1.3883 \\  & ESM-IF & 0.2241 & 0.2019 & 0.3194 & 0.2806 & 1.8860 & 1.2857 \\  & ESM2 & 0.0100 & 0.0100 & 0.1700 & 0.1630 & 2.6580 & 2.0210 \\  & EVE & 0.1131 & 0.0898 & 0.1237 & 0.1088 & 2.2622 & 1.4178 \\   & ESM2(Sup) & 0.3330 & 0.3040 & 0.6030 & 0.5290 & 2.1500 & 1.6700 \\  & DDGPred & 0.3750 & 0.3407 & 0.6580 & 0.4687 & 1.4998 & 1.0821 \\  & End-to-End & 0.3873 & 0.3587 & 0.6373 & 0.4882 & 1.6198 & 1.1761 \\   & MIF-Net. & 0.3965 & 0.3509 & 0.6523 & 0.5134 & 1.5932 & 1.1469 \\   Supervised & RDE-Net. & 0.4448 & 0.4010 & 0.6447 & 0.5584 & 1.5799 & 1.1123 \\   & DiffAffinity. & 0.4220 & 0.3970 & 0.6690 & 0.5560 & 1.5350 & 1.0930 \\   & MSM-Mut (w/o retrieval) & 0.4325 & 0.4031 & 0.6233 & 0.4954 & 1.6076 & 1.2155 \\   & **MSM-Mut** & **0.4736** & **0.4354** & **0.6814** & **0.5786** & **1.4703** & **1.0212** \\   

Table 1: Performance comparison to baseline methods on SKEMPI2.0 benchmark.

   Category & Method & TH31W & AH53F & NH57L & RH103M & LH104F \\    & Rosetta & **10.73\%** & 76.72\% & 93.93\% & **11.34\%** & 27.94\% \\  & FoldX & **13.56\%** & **6.88\%** & **5.67\%** & **16.60\%** & 66.19\% \\   & RDE-Net & **5.06\%** & **12.15\%** & 35.47\% & 50.61\% & **9.51\%** \\  & DiffAffinity & **7.28\%** & **3.64\%** & **18.82\%** & 81.78\% & **10.93\%** \\   & MSM-Mut (w/o retrieval) & **9.51\%** & **11.94\%** & 36.44\% & 50.61\% & 23.19\% \\   & MSM-Mut & **6.48\%** & **10.12\%** & **16.19\%** & **19.23\%** & 20.04\% \\   

Table 2: Rankings of the five beneficial mutations on an anti-SARS-CoV-2 antibody.

out of the top 1000 candidates, only 5 structure motifs remained after filtering, with one having the central residue type as methionine (M). Experimental results indicated that including this motif significantly influenced the outcome. Analysis revealed that this structure corresponds to residue 576 of chain T in the 5KOV structure. The aligned structures are depicted in Figure 3.

This demonstrates that our data retrieval method can effectively assist in extracting relevant local structures for antibody design, potentially offering an interpretable approach to the antibody engineering process.

### Stability Change Prediction

Training MSM-Mut(or other model name) for protein engineeringTo train the model's affinity prediction module, we fine-tuned the stability prediction component using the cDNA dataset. To fully utilize the mutation data and reduce bias, ensuring a more balanced representation of mutation types, we followed the settings described in Stability Oracle. Following Diaz et al. (2023), we use Thermodynamic Permutations (TP) to perform data augmentation to balance the mutation type distribution of dataset cDNA120K (Tsuboyama et al., 2023) and train on 2M thermodynamically valid ddG measurements. TP achieves this by exploiting properties of Gibbs free energy and dataset characteristics. Specifically, the original 19 mutations at each position are augmented to cover all 380 (\(19 20\)) pairwise mutations.

#### 4.2.1 Experimental Results on S669

In this study, we utilized a newly curated dataset (S669) (Pancotti et al., 2022) derived from the latest version of ThermoMutDB. This dataset comprises 669 protein variants not found in commonly used training sets, offering a robust basis for evaluating prediction models. Although our model does not match Stability Oracle in predicting stability changes, the integration of retrieved structure motifs enabled our model to surpass the such methods, thereby establishing a new state-of-the-art in this task.

#### 4.2.2 Thermostability Optimization on Novozymes Dataset

To demonstrate our model's robust generalization capability on new data, we tested it on a novel enzyme thermostability dataset provided by Novozymes (Pultz et al., 2022). This dataset includes experimental measurements of melting temperature of point mutations on a novel enzyme sequence that has no high-similarity match in PDB database with sequence identity higher than 30%. An AlphaFold prediction of wild-type protein structure is released with the dataset as the reference to perform structure-based methods. We adopt this predicted structure to retrieve local motifs and feed to MSM-Mut. As the results shown in Table 3b, our method significantly outperforms both classical force fields and machine-learning-based baselines. It suggests that our method can be applied to novel proteins and predicted structures.

Figure 3: A diagram illustrating a set of highly similar local antibody structures obtained through Multiple Structure Motif Alignment. The figure compares the local structures of the T chain 576 from 5KOV and the H chain 103 from 7FAE.

[MISSING_PAGE_EMPTY:9]

Acknowledgements

This work is supported by the National Key RD Program of China No.2021YFF1201600