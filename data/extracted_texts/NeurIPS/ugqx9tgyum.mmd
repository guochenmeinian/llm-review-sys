# Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery

Yongwei Nie\({}^{1}\), Mingxian Fan\({}^{1}\), Chengjiang Long\({}^{2}\), Qing Zhang\({}^{3}\), Jian Zhu\({}^{4}\), Xuemiao Xu\({}^{1}\)

\({}^{1}\)South China University of Technology, China

\({}^{2}\)Meta Reality Labs, USA

\({}^{3}\)Sun Yat-sen University, China

\({}^{4}\)Guangdong University of Technology, China

{nieyongwei, xuemx}@scut.edu.cn, fanmingxian123@gmail.com

cjfykx@gmail.com, zhangq93@mail.sysu.edu.cn, rockeyzhu@163.com

Corresponding author.

###### Abstract

Human Mesh Recovery (HMR) is the task of estimating a parameterized 3D human mesh from an image. There is a kind of methods first training a regression model for this problem, then further optimizing the pretrained regression model for any specific sample individually at test time. However, the pretrained model may not provide an ideal optimization starting point for the test-time optimization. Inspired by meta-learning, we incorporate the test-time optimization into training, performing a step of test-time optimization for each sample in the training batch before really conducting the training optimization over all the training samples. In this way, we obtain a meta-model, the meta-parameter of which is friendly to the test-time optimization. At test time, after several test-time optimization steps starting from the meta-parameter, we obtain much higher HMR accuracy than the test-time optimization starting from the simply pretrained regression model. Furthermore, we find test-time HMR objectives are different from training-time objectives, which reduces the effectiveness of the learning of the meta-model. To solve this problem, we propose a dual-network architecture that unifies the training-time and test-time objectives. Our method, armed with meta-learning and the dual networks, outperforms state-of-the-art regression-based and optimization-based HMR approaches, as validated by the extensive experiments. The codes are available at https://github.com/fmx789/Meta-HMR.

## 1 Introduction

Human mesh recovery (HMR) from a single image is of great importance to human-related applications, such as action capture without MoCap device, action transfer with vision-based system, and VR/AR entertainments, etc. This topic has received extensive research during past years, for which most of previous approaches represent a 3D human mesh by the parametric human model SMPL  with parameters \(=(,)\), where \(\) encodes the pose of the mesh and \(\) describes the body shape. The aim is thus to estimate \(\) of a human in a given image.

Originally, the problem is solved by optimizing a standard human mesh so that its 2D projection matches the 2D joints of the target human (e.g., SMPLify ). Later, works of  propose end-to-end networks trained on large datasets to directly output a 3D SMPL mesh given an input image. In SPIN , the regression-based approach  and optimization-based approach SMPLify  are combined together by interleaved training, where the regression methodprovides an initial solution for optimization and then the optimization method provides supervision for regression. Different from SMPLify  that directly optimizes a 3D mesh, works of EFT  and BOA  finetune a pretrained regression model on each test sample, which indirectly optimize the target human mesh (i.e., the the outcome of the regression models).

In this paper, we are particularly interested in the test-time optimization-based approaches of EFT  and BOA . Since BOA is developed for video leveraging consistency properties between frames, we mainly discuss and compare with EFT that performs HMR for images, like ours. Our observation is that the test-time optimization is analogous to one-shot learning. That is, it finetunes a pretrained model on a specific sample before really applying the model to solve the human mesh recovery task for that sample. However, the pretrained model, which is not specially tailored for the one-shot learning problem, may not be so effective for the test-time adaptation as desired.

Based on the above analysis and inspired by Kim et al. , we incorporate the test-time optimization into the training process, re-formulating the test-time optimization from the perspective of learning to learn, i.e., meta learning . Specifically, given a batch of training samples (or saying a set of tasks), our method first performs test-time optimization on each sample to update the regression network parameters temporally for that sample. Then, based on all pieces of regression parameters after test-time optimizations, we further optimize the training-time objectives over the whole batch of training samples. By performing training-time optimization after test-time optimization, we imagine that the training optimization works as a faithful supervision to correct the wrong optimization directions of the test-time optimizations. After the training, the obtained parameters of the regression network can be viewed as meta-parameters which will be instantiated to parameters actually used for human mesh recovery through several test-time optimization steps.

We find that the test-time objectives for the human mesh recovery task are different from training-time objectives, because we sometimes have ground-truth human meshes at training time but forever not at test time. This may produce an obstacle in the meta-learning process, since the optimization directions of the test-time and training optimizations are not identical. To alleviate this problem, we design a dual-network structure to implement our method, which owns a main regression network and an auxiliary network. The auxiliary network provides the main network with pseudo ground-truth SMPL meshes, by which we unify the training and test-time objectives elegantly.

We demonstrate through extensive experiments that our method equipped with meta-learning and the dual networks greatly outperforms state-of-the art approaches. To summarize, our main contributions are three-fold: (1) We propose a novel dual-network HMR framework with test-time optimization involved into the training procedure, which improves the effectiveness of the test-time optimizations. (2) We ensure the test-time objectives identical to the training objectives, further facilitating the joint-training of the test-time and training-time optimizations. (3) Extensive experiments validate that our results outperform those of previous approaches both quantitatively and qualitatively.

## 2 Related Work

**Regression-based HMR methods** typically employ neural networks to regress the human body mesh representation from images. Methods of [26; 48; 45; 72; 23; 42; 63; 68; 56; 71; 13; 36; 65; 35; 34] choose to regress parametric human body model, i.e., SMPL . HMR  was the first employing CNN  to extract features and MLP layers to output 3D mesh parameters. Later, sophisticated networks were proposed for improving the reasoning accuracy. For example, PyMAF [72; 71] extracted features in a pyramid structure and iteratively aligned 3D vertices with human body in the image. Xue et al.  used a learnable mask to automatically identify the most discriminative features related to 3D mesh recovery. Works of [27; 33; 58; 44] observed that prior works overlooked the importance of camera parameters. Among them, CLIFF  innovatively considered using the cropping bounding boxes as input to reduce the ambiguity of reprojection loss. Zolly  considered the camera distortion produced by perspective projection. Recently, Nie et al.  proposed a RoI-aware feature extraction and fusion network, guided by camera consistency and contrastive loss functions tailored to the multi-RoI setting.

There are also non-parameterized methods directly regressing mesh vertices. For example, METRO  utilized Transformer to model the global relationship between human keypoints and mesh vertices. FastMETRO  separated backbone features from the features corresponding to keypointsand vertices. Recently,  combined pyramid structure in PyMAF [72; 71] with the Transformer-based HMR regression method, further improving the regression accuracy.

The regression model is a key component in our method. In this paper, We test HMR  and CLIFF  as the regression network in our method.

**Optimization-based HMR methods**[5; 47; 30; 16; 18; 74; 3; 22; 52] usually attempt to estimate a 3D body mesh consistent with 2D image cues. Bogo et al.  proposed an approach called SMPLify, which iteratively adjusts SMPL parameters to fit detected 2D keypoints. SPIN  combined regression-based methods with SMPLify in an interleaved training strategy. CycleAdapt  alternately trained a HMR network and a motion denoising network to enhance each other. Unlike SMPLify, EFT  and BOA  fine-tuned a pretrained regression network via 2D reprojection loss or temporal consistency loss at test phase, updating the SMPL parameters indirectly. Some approaches proposed learning stronger 3D priors [29; 47; 12; 43] or utilizing trainable neural networks to update parameters in lieu of gradient updates [69; 9; 53]. Inverse kinematics (IK) has also been explored. These methods address IK problems by decomposing relative rotations , designing networks that integrate forward and inverse kinematics , or incorporating UV position maps . Different from all the above, our method integrates test-time optimization into the training process, obtaining a meta-model and meta-parameters.

**Meta Learning** Our method is most related to the model-agnostic meta-learning (MAML, or more precisely FOMAML) . MAML first samples a number of tasks, then performs local optimization on each task, and finally conducts a global optimization to update the parameters of the original network. Similarly, our method first executes test-time optimization on each training sample and then performs training optimization on a batch of training samples. Although our method is inspired by MAML and its extensions [2; 49; 50], our goal is fundamentally different from theirs. The goal of MAML is usually for few-shot learning or domain adaptation, which assumes there is ground-truth labeled data in the target domain. In contrast, our goal is to adapt the network to a single test sample which is free of ground-truth human mesh. We have noted MAML has been proven effective in various domains, such as talking head generation , SVBRDF recovery [75; 15], image super resolution , etc. As far as we know, the work of Kim et al.  is the first that applies meta learning to HMR. The key difference is that that Kim et al.  used the 2D reprojection loss only (please see Eq. 1 in their paper) in both inner and outer loops of meta learning, while we incorporate the ground-truth 3D SMPLs into the outer loop of meta learning and additionally generate pseudo SMPLs and incorporate them into the inner loop of the metal learning. The utilization of the GT and pseudo SMPLs greatly improves the results of our method upon the method of .

## 3 Our Method

Our goal is to estimate a 3D SMPL human mesh parameterized by \(=(,)\) together with a camera \(\) from a given image \(\) of a person, where \(^{24 3}\) and \(^{10}\) are pose and shape parameters of the SMPL human model , respectively. Let \(\{_{i,j},_{i,j},}_{i,j}\}_{i=1,j=1}^{B,M}\) be a training dataset, where \(_{i,j}\) is a training image, \(_{i,j}\) is the ground-truth (GT) human mesh, \(}_{i,j}\) is the 2D GT joints (or joints detected by such as OpenPose ) of the human in the input image, \(B\) is the number of batches, and \(M\) is the batchsize. End-to-end HMR regression approaches usually train a neural network \(f_{}:_{i,j}(_{i,j},_{i,j})\) by minimizing the following training-time loss function \(_{train}\):

\[_{pre}=*{arg\,min}_{}_{i=1}^{B}_{j=1 }^{M}_{train}(f_{}(_{i,j}),_{i,j},}_{i,j}),\] (1)

where

\[_{train}(f_{}(_{i,j}),_{i,j}, }_{i,j})=_{2D}(f_{}(_{i,j}), }_{i,j})+_{3D}(f_{}(_{i,j}), _{i,j}),\] (2)

with

\[_{2D}(f_{}(_{i,j}),}_{i,j})= \|(_{i,j})-}_{i,j}\|_{2}^{2},\ \ _{3D}(f_{}(_{i,j}),_{i,j})=\|X( _{i,j})-X(_{i,j})\|_{2}^{2}.\] (3)

As seen, \(_{train}\) is composed of a 2D reprojection loss \(_{2D}\) and a 3D loss \(_{3D}\). The 2D loss first projects mesh \(_{i,j}\) to the 2D plane by the camera \(\) and then computes difference between the projected 2D joints and the given 2D joints \(}_{i,j}\). The 3D loss computes difference between 3D meshes, where \(X\) can be an identity transformation or transformations computing 3D human joints or mesh vertices from the mesh parameters.

### Test-time Optimization

Exemplar-Fine-Tuning (EFT)  was the first work proposing test-time optimization for HMR. In particular, the pretrained network \(_{pre}\) is further finetuned by performing the following test-time optimization loss function on a specific test sample \(_{i,j}\):

\[_{i,j}^{*}=*{arg\,min}_{_{i,j}}_{ test}(f_{_{i,j}}(_{i,j}),}_{i,j}),\;\;\;_{i,j}=_{pre},\] (4)

with

\[_{test}(f_{}(_{i,j}),}_{i,j})= _{2D}(f_{}(_{i,j}),}_{i,j}).\] (5)

The test-time optimization starts from the initial solution \(_{pre}\) provided by the pretrained model. It resembles one-shot learning but actually does not, because the pretrained model is obtained using normal supervised learning techniques while not introducing any strategy for guaranteeing the properties of one-shot learning. The parameters of the pretrained model may be not ideal as the starting point for the test-time optimization.

### Incorporating Test-time Optimization into Training

To solve the above problem, we propose to integrate the test-time optimization into the training procedure as shown in Figure 1, inspired by optimization-based meta-learning . Specifically, for each sample in a batch, we first perform test-time optimization on that sample to update the parameters of the regression network temporally corresponding to the sample. After that, we perform training optimization over all \(M\) training samples, based on the \(M\) temporally updated regression

Figure 1: **Overview of the dual-network meta-learning HMR method, composed of a main HMR regression network \(f_{}\) and an auxiliary network \(f_{}\). Both networks have the same architecture but different parameters. Given \(i^{th}\) batch of images, test-time optimization is first executed for each training image \(_{i,j}\) in the batch individually, updating \(f_{}\) to \(f_{_{i,j}^{}}\) by performing a gradient descent step w.r.t. the test-time loss function \(_{test-u}\). Then based on \(\{f_{_{i,j}^{}}|j[1,M]\}\) (\(M\) is the batch size), the training optimization is executed to update the parameters of both main and auxiliary networks by \(_{train}\) with different arguments respectively. \(_{meta}\) and \(_{meta}\) are the finally generated meta-parameters. \(f_{}\) generates “Pseudo SMPLs” that are used in the test-time loss to supervise the learning of the “Estimated SMPL Inner”. GT SMPLs are used in the training loss to supervise the learning of “Estimated SMPL Outer” and the Pseudo SMPLs.**networks. This process is formulated as:

\[_{meta}=*{arg\,min}_{}_{i=1}^{B}_{j=1}^ {M}_{train}(f_{^{}_{ij}}(_{ij}), _{ij},}_{ij}),\] (6)

where,

\[^{}_{ij}=-_{}_{test}( f_{}(_{ij}),}_{ij}).\] (7)

The difference between Eq. 6 and Eq. 1 is in the parameters of \(f\) to be optimized. Instead of directly optimizing the current parameters \(\) of \(f\) using the training objective \(_{train}\), we first perform a step of test-time optimization using Eq. 7 on each sample \(_{ij}\) to obtain network parameters \(^{}_{ij}\) specific to that sample. Then, \(\{^{}_{ij}|j[1,M]\}\) over all training samples in a batch are in turn used in Eq. 6 to evaluate the training objective. In Eq. 7, \(\) is the learning rate of the test-time optimization.

By performing test-time optimization before training optimization in Eq. 6 and 7, we take test-time optimization into consideration in the training procedure. That means, the "test-time optimization" is trained on the training dataset, thus having better generalization ability to test samples. The proposed method resembles the optimization-based meta-learning  and we call the obtained parameters \(_{meta}\) meta-parameters.

### Unifying Training and Test-time Optimization Objectives with Dual Networks

There are ground-truth human meshes at training time while not at test time, causing the difference between \(_{train}\) (see Eq. 2)) and \(_{test}\) (see Eq. 5). Since both the test-time and training optimizations update parameters of the same network, the difference between the two optimization objectives yields different gradient descent directions, causing potential conflicts that reduce the effectiveness of the training (see ablation studies in Section 4.4).

To make the test-time optimization more compatible with the training objective, we propose a method that unifies the training and test-time optimization objectives by introducing an auxiliary regression network \(f_{}\) parameterized by \(\) which is trained together with the main network:

\[_{meta},_{meta}=*{arg\,min}_{, }_{i=1}^{B}_{j=1}^{M}(^{1}_{train}(f_{ ^{}_{i,j}}(_{i,j}),_{i,j},}_{i,j})+ ^{2}_{train}(f_{}(_{i,j}),_{i,j}, }_{i,j})).\] (8)

The above equation is a combination of Eq. 1 and Eq. 6 (superscript 1 and 2 are used to denote the first and second term respectively), with Eq. 1 applied to the auxiliary network \(f_{}\), and Eq. 6 applied to \(f_{}\). We use \(f_{}\) to generate a pseudo GT mesh \(^{u}_{i,j}\) for a training image \(_{i,j}\), i.e., \(^{u}_{i,j}=f_{}(_{i,j})\), and use the pseudo label to supervise the gradient descent in the test-time optimization:

\[^{}_{i,j}=-_{}_{ test-u}(f_{}(_{i,j}),^{u}_{i,j},}_{i,j}).\] (9)

Please compare between Eq. 9 and Eq. 7. The difference is that there is an additional input \(^{u}_{i,j}\) to \(_{test-u}\) in Eq. 9, and note that this new form of \(_{test-u}\) is identical to the form of \(_{train}\).

### Inference with Dual Networks

Both the training and testing pseudo codes of our method are given in Algorithm 1. The training process is fully elaborated in the above sections. Now we introduce how to perform inference at test time. For each test sample \(\), at our hand are two networks \(f_{}\) and \(f_{}\) with \(=_{meta}\) and \(=_{meta}\), respectively. We freeze the parameters of the auxiliary network, and use it to compute the pseudo GT human mesh for the test image \(\). Then, under the supervision of the pseudo mesh, we compute \(_{test-u}\) and use Eq. 9 to iteratively update the parameters \(\) of \(f\) from \(_{meta}\) to \(_{final}\). We run at most \(m=14\) iterations, and automatically stop the iteration if losses of two consecutive iterations are close enough. We finally use \(f_{_{final}}\) to estimate the human mesh for image \(\).

### Implementation Details

We implement the main network \(f_{}\) and auxiliary network \(f_{}\) with the same network architecture but different parameters. Specifically, we use HMR  or CLIFF  as \(f\) due to their simplicity. The two methods and many other approaches [37; 8; 66; 72; 71; 26; 67] adopt ResNet-50  or HRNet-W48  to extract features from the input image, and estimate human mesh based on the features. We provide results of both kinds of backbones.

We implement our method in PyTorch using the Adam optimizer  with \(_{1}=0.9\) and \(_{2}=0.999\). The batchsize for ResNet backbone is 40, and for HRNet backbone is 30. The number of training epochs for ResNet backbone is 65, and for HRNet backbone is 25. The learning rate \(\) used in the test-time optimization is 1e-5, and the learning rate \(\) (see Algorithm 1) for the training optimization is 1e-4. Our method takes about 3 days training on a single NVIDIA RTX3090 GPU.

## 4 Experiments

### Datasets

Following previous work [33; 26; 73], we employ the following datasets in our experiments: (1) **Human3.6M**, an indoor dataset with precise GT human mesh and 2D joints captured through MoCap devices. (2) **MPI-INF-3DHP**, another widely used indoor dataset whose GT human meshes are obtained through multi-view reconstruction. (3) **COCO** and (4) **MPII**, two in-the-wild outdoor datasets with human annotated 2D joints for which we use the pseudo GT mesh provided by . (5) **3DPW**, a challenging in-the-wild dataset providing accurate human mesh fitted from IMU sensor data.

### Training, Testing and Metrics

Following prior arts [37; 66; 8; 4], we first train our method on a mixture of four datasets, including Human3.6M , MPI-INF-3DHP , COCO , and MPII , and then test our method on the test dataset of Human3.6M . After that, we further fine-tune our model for 5 epochs by introducing the training dataset of 3DPW , and then evaluate our method on the test dataset of 3DPW . We use **MPJPE** (Mean Per Joint Position Error), **PA-MPJPE** (Procrustes-aligned MPJPE), **PVE** (Mean Per-vertex Error) as the metrics to evaluate our method.

### Comparison with Previous Approaches

**Quantitative results.** We present accuracy comparison with SOTA methods in Table 1, including regression-based approaches [23; 26; 55; 37; 33; 13; 73; 67; 72; 8; 66] and optimization-based approaches [28; 22; 32; 59; 31; 51; 53; 69]. For all the compared approaches, we report the best results their papers provide. For our method, we adopt CLIFF  as \(f\) and HRNet-W48 as the backbone network. Since our method needs 2D joints for test-time optimization, we report results using joints estimated by OpenPose  (denoted by \(\)) and RSN  (denoted by \(\)).

Please compare "\(_{}\) (HR-W48)" in Table 1 with SOTA approaches that also use HRNet-W48 as backbone. Our method outperforms most of previous approaches. Compared with , we improve it from 69.0 to 62.9 taking MPJPE of 3DPW as an example, which is a large margin. If using RSN joints for the test-time optimization, our method can further improve the metrics.

**Qualitative results.** We show qualitative comparison with CLIFF  and Refit  in Figure 2. Our method estimates faithful human poses and meshes which are better than those of the compared approaches. Comparisons with HybrIK , NIKI , ProPose  and \(_{}\) can be found in the supplementary material.

### Ablation study

**Influence of Regression Model.** The adopted regression model \(f\) influences the effectiveness of our method. In Table 2, we show the results of using HMR  or CLIFF  as the regression model. Since CLIFF is a stronger baseline than HMR, our method based on CLIFF performs better than that based on HMR.

**Influence of Accuracy of 2D Joints.** Since our method needs 2D joints as the supervision at test time, it is interesting to see how the quality of the 2D joints affects the effectiveness of the method. We have already reported results on 2D joints detected by OpenPose  and RSN . In Table 2, we further test GT 2D joints. As seen, our method with GT joints outperforms our method using detected joints by OpenPose and RSN. This indicates our method will become more effective as 2D pose detectors continue to develop.

    &  &  &  \\   & & MPJPE\(\) & PA-MPJPE\(\) & PVE\(\) & MPJPE\(\) & PA-MPJPE\(\) \\    } & HMR ’18 & Res-50 & 130.0 & 81.3 & - & 88.0 & 56.8 \\  & PARE ’21 & HR-W32 & 74.5 & 46.5 & 88.6 & - & - \\  & ROMP ’21 & HR-W32 & 76.7 & 47.3 & 93.4 & - & - \\  & PyMAP ’21 & HR-W48 & 74.2 & 45.3 & 87.0 & 54.2 & 37.2 \\  & METRO ’21 & HR-W64 & 77.1 & 47.9 & 88.2 & 54.0 & 36.7 \\  & Fashioner ’22 & HR-W64 & 73.5 & 44.6 & 84.1 & 52.2 & 33.7 \\  & CLIFF ’22 & HR-W48 & 69.0 & 43.0 & 81.2 & 47.1 & 32.7 \\  & LearnSample ’22 & HR-W32 & 70.5 & 43.3 & 82.7 & 45.9 & 33.5 \\  & ProPose ’23 & HR-W48 & 68.3 & 40.6 & 79.4 & 45.7 & **29.1** \\  & POTTER ’23 & ViT & 75.0 & 44.8 & 87.4 & 56.5 & 35.1 \\  & DeFormer ’23 & HR-W48 & 72.9 & 44.3 & 82.6 & 44.8 & 31.6 \\    } & LearnedGD ’20 & - & - & 55.9 & - & - & 56.4 \\  & HUND ’21 & Res-50 & 81.4 & 57.5 & - & 69.5 & 52.6 \\  & SPIN ’21 & Res-50 & 96.9 & 59.2 & 116.4 & 62.5 & 41.1 \\  & EFT ’21 & Res-50 & 85.1 & 52.2 & 98.7 & 63.2 & 43.8 \\  & Hybridx ’21 & Res-34 & 74.1 & 45.0 & 86.5 & 55.4 & 33.6 \\  & NIKI ’23 & HR-W48 & 71.3 & 40.6 & 86.6 & - & - \\  & ReFit ’23 & HR-W48 & 65.8 & 41.0 & - & 48.4 & 32.2 \\  & PLIKS ’23 & HR-W48 & 66.9 & 42.8 & 82.6 & 49.3 & 34.7 \\    } & OursCliffF \(\) & HR-W48 & 62.9 & 39.7 & 80.1 & 43.9 & 30.3 \\  & OursCliffF \(\) & HR-W48 & **62.4** & **39.5** & **78.1** & **42.0** & **29.1** \\   

Table 1: **Quantitative comparison with state-of-the-art methods on 3DPW  and Human3.6M . “\(\)”: using 2D joints detected by OpenPose , “\(\)”: using 2D joints detected by RSN .**

**Influence of Optimization Steps at Inference Time.** At inference time, we perform at most \(m\) test-time optimization steps. In Figure 3 (a) and (b), we show how the evaluation metrics become as the number of optimization steps increases. As seen, our results consistently become better in terms of both MPJPE and PA-MPJPE. We also show the results of EFT\({}_{}\) and EFT\({}_{}\). With the same regression model, our method is better than EFT . The results of EFT become better at the first few optimization steps, but become worse as more optimization steps execute. This is probably because EFT is only finetuned with 2D reprojection loss and is more sensitive to the errors in the 2D joints. At the first several optimization steps, the estimated 3D SMPL approaches the 2D joints from a relatively distant initialization, therefore the result gets better gradually. With more optimization steps, the SMPL may overfit the 2D joints whose annotation-errors then distort the SMPLs, thus yielding worse evaluation metrics. In contrast, our method is guided by both 3D and 2D

    &  &  &  \\   & & MPJPE\({}_{}\) & PA-MPJPE\({}_{}\) & PVE\({}_{}\) & MPJPE\({}_{}\) & PA-MPJPE\({}_{}\) \\  OurSH\({}_{}\)\(\) & Res-50 & 73.3 & 44.3 & 90.3 & 55.8 & 36.4 \\ OurSHMR\(\) & Res-50 & 68.9 & 39.6 & 85.5 & 53.7 & 33.8 \\ OurSCLIFF\(\) & HR-W48 & 62.9 & 39.7 & 80.1 & 43.9 & 30.3 \\ OurSCLIFF\(\) & HR-W48 & 57.8 & 35.3 & 74.4 & 39.4 & 27.5 \\   

Table 2: **Ablation study on regression model and 2D joints** on 3DPW  and Human3.6M . “\(\)”: using 2D joints detected by OpenPose , “\(\)”: using GT 2D joints.

Figure 3: **Influence of optimization steps during inference.** Our method outperforms EFT when using the same regression model. As optimization proceeds, our results continuously become better, while those of EFT become better at first and then become worse (see (a) and (b)). (c) shows that our method achieves faster convergence compared to EFT.

Figure 2: **Qualitative comparison with SOTA methods.** We show results produced by CLIFF , ReFit , and our method (\(\): OpenPose, \(\): RSN). All the three methods use HRNet-W48 as the backbone. In the novel views, green represents the ground truth, orange represents CLIFF, purple represents ReFit, pink and blue represent the two variants of our method, respectively.

[MISSING_PAGE_EMPTY:9]

in Table 5, our method demonstrates superior performance over EFT\({}_{ CLIFF}\), further validating its effectiveness in OOD scenarios.

Figure 5 shows two examples from the LSP-Extended dataset. The persons in the two images take complex actions. The shadows in the images and the similar color of the black pants and shoes make it difficult even for humans to identify the configuration of the 3D meshes. Our method successfully estimates correct meshes, while the arms in the results of EFT\({}_{ CLIFF}\) exhibit wrong depth orders.

## 5 Conclusion

To conclude, this paper presents a new training paradigm towards better test-time optimization performance at test time. We mainly propose two strategies. First, we integrate the test-time optimization into the training procedure, which performs test-time optimization before running the typical training in each training iteration. Second, we propose a dual-network architecture to implement the proposed novel training paradigm, aiming at unifying the space of the test-time and training optimization problems. Experiments and comparisons prove that the proposed training scheme improves the effectiveness of the test-time optimization during testing, demonstrating that it successfully learns meta-parameters that benefit the test-time optimization for specific samples. Our method can perform even better with stronger regressor baseline or better 2D joints, and can adapt to out-of-domain challenging test cases.