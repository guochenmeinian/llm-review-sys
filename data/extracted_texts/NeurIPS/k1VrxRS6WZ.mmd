# Multi-Label Open Set Recognition

Yi-Bo Wang, Jun-Yi Hang, Min-Ling Zhang

School of Computer Science and Engineering, Southeast University, Nanjing 210096, China

Key Laboratory of Computer Network and Information Integration (Southeast University),

Ministry of Education, China

{wang_yb, hangjy, zhangml}@seu.edu.cn

Corresponding author

###### Abstract

In multi-label learning, each training instance is associated with multiple labels simultaneously. Traditional multi-label learning studies primarily focus on closed set scenario, i.e. the class label set of test data is identical to those used in training phase. Nevertheless, in numerous real-world scenarios, the environment is open and dynamic where unknown labels may emerge gradually during testing. In this paper, the problem of multi-label open set recognition (MLOSR) is investigated, which poses significant challenges in classifying and recognizing instances with unknown labels in multi-label setting. To enable open set multi-label prediction, a novel approach named Slan is proposed by leveraging sub-labeling information enriched by structural information in the feature space. Accordingly, unknown labels are recognized by differentiating the sub-labeling information from holistic supervision. Experimental results on various datasets validate the effectiveness of the proposed approach in dealing with the MLOSR problem.

## 1 Introduction

_Multi-label Learning_ (MLL) deals with the problem where an instance can be associated with multiple labels simultaneously . As a practical machine learning paradigm, multi-label learning has been widely applied in various real-world applications, such as image annotation , text categorization , information retrieval .

Traditional multi-label learning studies focus on closed set scenario. That is, they assume that the class label set of test data is identical to that in the training set . However, in many real-world scenarios, this assumption rarely holds because the environment is open and dynamic . In addition to the extant label knowledge at training phase, the unknown labels may emerge gradually with the data streams during the testing phase. For example, in Figure 1, the test image is annotated with several relevant labels, some of which are unseen in the training set. The classification task becomes much more challenging because the label correlation between known and unknown labels may degrade the performance of the predictive model. Furthermore, due to the presence of unknown labels in the class label set of test data, these test data are hardly employed in subsequent learning processes, such as incremental learning .

Motivated by the potential applications, we formalize a novel framework named _multi-label open set recognition_ (MLOSR), whose goal is to learn a multi-label model that can correctly classify known labels for the unseen instance and recognize unknown labels within its relevant label set. This can be regarded as a special weakly supervised learning. In MLOSR, the most challenging part is to recognize the unknown labels associated with instances. Since we do not have any prior knowledge of unknown labels and they almost always co-occur with some known labels, it is very difficult to separate instances with unknown labels from those with the known labels only.

_Open set recognition_ (OSR) is a paradigm previously proposed in  and is formalized as a risk-minimizing constrained functional optimization problem. OSR describes a scenario where new classes unseen in training occur in testing, thus classifiers must be able to properly identify seen samples while rejecting unseen ones .  proposes a 1-vs-Set machine to minimize open set risk by sculpting a decision space from the marginal distances of binary SVM. OSR problem is further studied via algorithm adaptation [1; 16], statistical extreme value theory (EVT) [25; 32], margin distribution  or hierarchical Dirichlet process . These existing works are based on the fact that each instance owns one ground-truth label for multi-class cases. Thus, they cannot be used to directly solve the MLOSR problem, due to the multiple ground-truth labels in MLL.

To address MLOSR problem, we propose a tailored algorithm named Slan, i.e. _Sub-Labeling informAtion reconstructioN for multi-label open set recognition_. The basic strategy of Slan is to enrich the sub-labeling information in the sub-label space by leveraging the structural information in the feature space and differentiating it from the labeling information from holistic supervision. Specifically, the underlying structure of feature space is characterized by the sparse reconstruction relationships among training instances. After that, the reconstruction information is utilized to guide the enrichment of sub-labeling information. Then, a unified optimization framework is presented to simultaneously facilitate open set recognizer and multi-label classifier induced with alternating optimization. Our empirical study on datasets from diverse domains demonstrates the effectiveness of the proposed approach.

The rest of the paper is organized as follows. We present a brief review of related works. Then we formulate the problem and propose the algorithm. Next, experimental results are reported, followed by the conclusion.

## 2 Related Work

The task of multi-label learning has been extensively studied in recent years [37; 19]. Generally, the major challenge for multi-label learning is its huge output space which is exponential to the number of class labels. Therefore, exploiting _label correlations_ has been adopted as a common strategy to facilitate the learning process. Roughly speaking, extant approaches can be grouped into three categories based on the order of correlations, i.e. _first-order_ approaches, _second-order_ approaches and _high-order_ approaches. First-order approaches tackle multi-label learning problem in a label-by-label manner [2; 33]. Second-order approaches exploit pairwise interactions among class labels [7; 3]. High-order approaches exploit relationships among a subset of or all class labels [22; 14].

OSR is critical for the tasks where incomplete knowledge exists at training time, and unknown classes can be submitted to an algorithm during the testing phase, requiring the classifiers to classify the seen classes and deal with unseen ones. According to , traditional machine learning methods are adapted to OSR scenario. For instance, SVM-based models add extra constraints on the score space in [24; 4]; A collective decision-based model implemented by hierarchical Dirichlet process is proposed in ; and distance-based models [1; 16] are developed by modifying existing classifiers, such as nearest class mean classifier and nearest neighbor classifier. Some other approaches focus

Figure 1: An example. The test image is associated with a variety of relevant labels. Among the set of relevant labels, “cloud”, “car”, “ship”, “building”, “tree” and “sky” are known labels seen in the training set, while “sea”, “mountain” and “treestle bridge” are unknown labels emerging in the testing phase.

on the EVT .  combines the EVT for score calibration with two separated compact abating probability SVMs, where the first SVM is used as a conditioner and the second SVM fitted yields the posterior estimate.  transforms the OSR problem into a set of hypothesis testing problems by modeling the tail part of reconstruction error distribution via EVT.  formulates the extreme value machine with distributional information, which can be interpreted by EVT. There are also some methods trying to incorporate few-shot learning into OSR .

MLOSR can be regarded as a combination of MLL and OSR. Thus, a straightforward approach is to generate a independent recognizer besides the multi-label classifier. However, as unknown labels may co-occur with known labels, it is difficult to separate instances with unknown labels from instances with known labels only, which leads to OSR approaches that could not be applied in MLOSR problems.

Streaming multi-label learning (SMLL)  is similar to our MLOSR problem but differs in the setting of unknown labels. It aims to derive a unified model by taking care of the continually emerging new unknown labels on the training data.  trains a linear classifier for new labels with the linear hypotheses between labels and classifiers.  proposes a novel DNN-based framework to model the emerging new labels depending on high-order representations.  presents probabilistic streaming label tree to incorporate new labels, which capture hierarchical correlations among labels. Compared to SMLL, MLOSR is much more challenging in recognizing unknown labels as the unknown labels only emerge in testing phase. In the next section, the first attempt towards MLOSR is introduced.

## 3 The Slan Approach

### Problem Formulation

Formally, let \(=^{d}\) denote the \(d\)-dimensional input space and \(=\{l_{1},l_{2},,l_{q}\}\) denote the label space including \(q\) class labels. Each multi-label instance can be denoted as \((_{i},Y_{i})\), where \(_{i}\) is its feature vector and \(Y_{i}\) is the set of relevant labels associated with \(_{i}\). Here, a \(q\)-dimensional indicator vector \(_{i}=[y_{i1},y_{i2},...y_{iq}]^{}\) is utilized to denote \(Y_{i}\), where \(y_{ik}=1\) indicates class label \(l_{k} Y\) and \(y_{ik}=-1\) otherwise. By arranging feature vectors and label vectors of \(m\) training instances, we obtain the feature matrix \(=[_{1},,_{m}]\) and label matrix \(=[_{1},,_{m}]\).

Given the multi-label training set \(=\{(_{i},Y_{i}) 1 i m\}\), the goal of MLOSR is to learn a model from \(\) that can correctly classify known labels for the unseen instance and recognize unknown labels within its relevant label set. Conceptually, given the multi-label training set \(\), an open space risk function \(R_{}\) and an empirical risk function \(R_{}\), multi-label open set recognition aims to derive a measurable recognition function \(f\) by minimizing the following **Open Set Risk**:

\[*{argmin}_{f}R_{}(f)+_{r}R_{ }(f())\] (1)

where \(_{r}\) is a regularization constant.

### Structural Information Discovery

To characterize the underlying manifold structure of feature space, a weighted directed graph \(G=(,,)\) is constructed over the set of training instances, where \(=\{_{i} 0 i m\}\) corresponds to the set of vertices and \(=\{(_{i},_{j}) s_{ij} 0,1 i j m\}\) corresponds to the set of edges from \(_{i}\) to \(_{j}\) with nonzero weight.

Furthermore, \(=[s_{ij}]_{m m}\) corresponds to the weight matrix encoding the relationships among all training instances. Conceptually, the weight value \(s_{ij}\) reflects relative importance of \(_{i}\) in reconstructing \(_{j}\). Thus, by implementing global sparse reconstruction, the weight matrix \(\) is instantiated by solving the following optimization problem:

\[_{} ||-||_{}^{2}+_{0}|| ||_{1}\] (2) s.t. \[s_{ii}=0, 1 i m\]

Here, the first term controls the linear reconstruction error via squared Frobenius norm while the second term controls the sparsity of reconstruction via \(_{1}\) norm. The relative importance is balanced by the trade-off parameter \(_{0}\). Then, the constrained optimization problem in Eq.(2) can be solved via a standard ADMM (Alternating Direction Method of Multiplier) procedure .

### Sub-Labeling Information Enrichment

According to the manifold assumption, the structural relationship specified in the feature space should also be preserved in the entire label space to enrich labeling information originally encoding in the indicator vector \(_{i}\)[13; 38]. That is, \(_{i}\) can be transformed into a numerical labeling vector \(_{i}=[z_{i1},z_{i2},,z_{iq}]^{}\) under holistic supervision which encodes richer semantics for predictive model induction.

However, this assumption might be suboptimal in the entire label space. Considering one specific label \(l_{k}\), let \(_{i}^{k}=[f_{i1}^{k},,f_{i,k-1}^{k},f_{i,k+1}^{k},,f_{iq}^{k}]^ {}\) represent the enriched sub-labeling information of \(_{i}\). With the manifold assumption, the structural information would be maintained in the sub-label space \(\{l_{k}\}\). Then, instances with \(l_{k}\) can be reconstructed via the instances without \(l_{k}\) as well as the enriched sub-labeling information. Nevertheless, these reconstructed instances can not be assigned with \(l_{k}\) since there's not enough positive labeling information w.r.t. \(l_{k}\). That is, the sub-labeling information is differentiated from labeling information with holistic supervision. Thus, in open set scenario, if \(l_{k}\) is specified as an unknown class label, such difference can be employed as a criterion for one specific instance to distinguish whether it is associated with an unknown class label.

Let concatenate all \(_{i}^{k}\), denoted by \(_{k}=[_{1}^{k},,_{m}^{k}]^{(q-1) m}\) and all \(_{i}\), denoted by \(=[_{1},,_{m}]^{q m}\). The enriched sub-labeling information is generated via leveraging the structural information encoded in \(\) by solving the following optimization problem:

\[_{,\\ _{1},,_{q}}&_{i=1}^{m}||_{i}-_{i}||_{2}^{2}+ _{k=1}^{q}_{i=1}^{m}||_{i}^{k}-_{j=1}^{m}s_{ji}_{j}^{k}||_ {2}^{2}\\ &+_{k=1}^{q}_{i=1}^{m}||_{i}^{k}( _{i}^{k}-_{k}_{i})||_{2}^{2}\] (3)

Here, \(_{i}^{k}\) is a indicator variable, where \(_{i}^{k}=1\) if \(l_{k}\) is not associated with \(_{i}\); otherwise \(_{i}^{k}=0\). \(_{k}\) is a \((q-1) q\) projection matrix to align \(_{i}\) with \(_{i}^{k}\) without regard to \(l_{k}\), which removes the \(k\)-th row of the identity matrix. The first term supervises the labeling information from the holistic aspect. The second term conveys the manifold structure specified in the feature space to the sub-label space. The third term minimizes the labeling information difference between sub-label space and entire label space to differentiate instances with or without such unknown class label, which implicitly reduces the open space risk.

During the testing phase, for an unseen instance \(_{}\), the reconstruction coefficients w.r.t. \(l_{k}\) is identified by resorting to the ADMM technique over the training set. After that, the enriched sub-labeling information \(_{*}^{k}\) of \(_{}\) is determined via the second term of Eq.(3). Thereafter, whether unknown labels are associated with \(_{*}\) is determined by the following recognizer \(G\) via ensemble majority voting:

\[G(_{*})=,&if\ _{k=1}^{q}g_{k}(_{*})  0,\\ ,&if\ _{k=1}^{q}g_{k}(_{*})>0.\] (4)

where \(g_{k}(_{*})=-1\) if \(||_{*}^{k}-_{k}_{*}||_{2}^{2}>_{k}\); otherwise \(g_{k}(_{*})=1\). \(_{k}\) is the threshold, and can be chosen so that 100\(\)% instances with \(l_{k}\) in training set satisfy \(||_{i}^{k}-_{k}_{i}||_{2}^{2}>_{k}\). The labeling information \(_{*}\) under holistic supervision is generated by the following MLL classifier.

### MLL Classifier Training

Similar to the existing strategy in previous OSR algorithms, instead of training the classifier independently, we perform open set recognizer and multi-label classifier induced simultaneously. Then, the sub-labeling information can be optimized by considering both the manifold assumption and model outputs. Furthermore, considering the label correlation between known and unknown labels, such jointly optimization procedure with recognizer can facilitate the classifier more robust. We denote \(^{q d}\) and \(^{q}\) as a multi-label classifier and adopt the squared Frobenius norm as the regularization term to control the model complexity:

\[_{,}_{i=1}^{m}||_{i}+ -_{i}||_{2}^{2}+}{2}||||_{}^{2}\] (5)

Let \(_{}=[b_{pi}^{k}]_{(q-1) m}\) denote the indicator matrix with \(b_{pi}^{k}=_{i}^{k}\). Then, the objective function of the unified framework is shown as follows:

\[_{,,,}& _{k=1}^{q}(||_{k}-_{k}||_{ }^{2}+||_{k}(_{k}- _{k})||_{}^{2})\\ &+||-(+ _{n}^{})||_{}^{2}+||- ||_{}^{2}\\ &+}{2}||||_{}^{2}\] (6)

Here, The first two terms control the open space risk and remaining terms control the empirical risk.

### Alternative Optimization

**Update Z** With fixed \(_{1},,_{q}\), \(\) and \(\), the optimization problem Eq.(6) can be stated as follows:

\[_{}&||-(+_{n}^{})||_{}^{2}+ ||-||_{}^{2}\\ +&_{k=1}^{q}||_{k} (_{k}-_{k})||_{}^{2}\] (7)

The above optimization problem can be solved by updating \(\) with gradient descent. The gradient of the objective function w.r.t. \(\) is

\[&=(-( +_{n}^{}))+(- )\\ &+_{k=1}^{q}_{k}^{}(_{k}( _{k}-_{k}))\] (8)

**Update \(_{1},,_{q}\)** With \(\), \(\) and \(\) fixed, the optimization problem Eq.(6) can be stated as follows:

\[_{_{k}}||_{k}-_{k} ||_{}^{2}+||_{k}(_{k}-_{k})||_{}^{2}\] (9)

Similarly, gradient descent is employed, and the gradient w.r.t. \(_{k}\) is:

\[_{k}=_{k}+_{k}( _{k}-_{k})\] (10)

where \(=(-_{m m})(-_{m m })^{}\).

**Update W and b** While \(\) and \(_{1},,_{q}\) are fixed, the optimization problem (4) can be stated as follows:

\[_{,}& tr( ^{})+_{1}tr(^{})\\ &=+ _{m}^{}+\] (11)

Here, \(=[_{1},,_{m}]^{q m}\), where \(_{i}=_{i}-(_{i}+)\). To achieve better performance of the predictive model, a kernel extension is further facilitated for the general nonlinear case. Let \(=[(_{1}),,(_{m})]^{h m}\), where \(():^{d}^{h}\) corresponds to the feature mapping that maps the feature space to some higher dimensional Hilbert space with \(h\) dimensions. Then, the Lagrangian function of this problem can be formulated as:

\[(,,, )&=tr(^{})+_{1}tr( ^{})\\ &-tr(^{}(+ _{m}^{}+-))\] (12)where \(=[a_{ki}]^{q m}\) stores the Lagrange multipliers. According to the **KKT** conditions, we can obtain:

\[ =^{-1}_{m}}{_{m}^{ }^{-1}_{m}}\] (13) \[ =(-_{m}^{})^{-1}\]

where \(=}+_{m m}\) and \(=^{}\) with its element \(k_{ij}=(_{i},_{j})=(_{i})^{}(_{j})\) based on the chosen kernel function \((,)\). Then, by incorporating the specified kernel function, the modeling output is denoted by \(}+_{m}^{}\). Furthermore, given an unseen instance \(_{*}\), its relevant label set is predicted as:

\[Y_{*}=\{l_{k}_{i=1}^{m}a_{ki}(_{*},_{i}) 0,0 k  q\}\] (14)

The pseudo-code of Slan is summarized in Algorithm 1. Given the multi-label training set, a weighted graph is constructed to characterize the manifold structure of feature space (Step 1). After that, the alternative optimization strategy is adopted to optimize open set recognizer and multi-label classifier simultaneously (Step 2-9). Finally, the relevant label set of the unseen instance is predicted and the recognition result is generated based on the learned model (Step 10).

## 4 Experiments

### Experimental Setup

Table 1 summarizes the detailed characteristics of each benchmark multi-label data set \(\) employed in the experiments, including the number of instances \(||\), number of features \(dim()\), number of class labels \(L()\), label cardinality \(LCard()\), label density \(LDen()\), number of distinct label sets \(DL()\) and proportion of distinct label sets \(PDL(S)\). To alleviate the influence of extreme

   Dataset & \(||\) & \(dim()\) & \(L()\) & \(LCard()\) & \(LDen()\) & \(DL()\) & \(PDL(S)\) \\  llog & 1208 & 925 & 17 & 0.966 & 0.057 & 96 & 0.079 \\ enron & 1702 & 1001 & 24 & 3.124 & 0.130 & 548 & 0.322 \\ slashdot & 3659 & 1079 & 14 & 1.173 & 0.084 & 119 & 0.033 \\ recreation & 5000 & 606 & 15 & 1.361 & 0.091 & 259 & 0.052 \\ corel5k & 5000 & 499 & 44 & 2.214 & 0.050 & 1037 & 0.207 \\ arts & 5000 & 462 & 14 & 1.512 & 0.108 & 314 & 0.063 \\ education & 5000 & 550 & 11 & 1.374 & 0.125 & 173 & 0.035 \\ rcvsubset2-2 & 6000 & 944 & 39 & 2.170 & 0.056 & 489 & 0.082 \\ bibtex & 7395 & 1835 & 27 & 0.954 & 0.035 & 380 & 0.051 \\   

Table 1: Characteristics of experimental data sets.

imbalance, any class label with rare appearance or with overly-high imbalance ratio is excluded from the label space following previous settings .

For a given dataset, we randomly select 50% labels as known labels and the remaining labels as unknown labels with different label batch sizes. Then, we sample 60% instances without unknown labels to form training set while the remaining instances are treated as test data. The sampling procedure is repeated ten times, and the mean metric value as well as standard deviation for each label batch are reported.

To evaluate the performance of multi-label classifiers, we utilize five widely-used multi-label evaluation metrics , including _Ranking loss_, _One-error_, _Coverage_, _Average precision_ and _Macro-averaging AUC_. In addition, _F-measure_ is employed to evaluate the performance of recognizers.

To validate the effectiveness of the proposed Slan approach in multi-label learning, four multi-label learning approaches are used for comparative studies.

* Lift: A multi-label learning approach, which induces classifiers with the label-specific features generated via conducting clustering analysis for each class label. [parameter configuration: \(r=0.1\)]

   Dataset & \#label & Lift & Muenlplr & Sence & Limic & Slan \\   \\  log \\  } & 0 & 0.339\(\)0.033 & 0.400\(\)0.025\(\) & **0.335\(\)0.039** & 0.350\(\)0.035 & 0.344\(\)0.030 \\  & 3 & 0.358\(\)0.035 & 0.418\(\)0.026\(\) & **0.357\(\)0.041** & 0.367\(\)0.040 & 0.359\(\)0.033 \\  & 5 & 0.365\(\)0.036 & 0.421\(\)0.025\(\) & **0.362\(\)0.037** & 0.373\(\)0.037 & 0.366\(\)0.033 \\  & 7 & 0.368\(\)0.032 & 0.425\(\)0.022\(\) & **0.366\(\)0.033** & 0.376\(\)0.033 & 0.370\(\)0.030 \\  & 9 & 0.368\(\)0.028 & 0.426\(\)0.019\(\) & **0.367\(\)0.029** & 0.377\(\)0.032 & 0.374\(\)0.030 \\   enron \\  } & 0 & 0.174\(\)0.012\(\) & 0.236\(\)0.024 & 0.159\(\)0.018 & 0.199\(\)0.031\(\) & **0.157\(\)0.016** \\  & 6 & 0.179\(\)0.014\(\) & 0.241\(\)0.011\(\) & 0.172\(\)0.009 & 0.194\(\)0.011\(\) & **0.169\(\)0.011** \\  & 9 & 0.179\(\)0.013\(\) & 0.245\(\)0.013\(\) & 0.174\(\)0.008 & 0.193\(\)0.012\(\) & **0.172\(\)0.012** \\  & 12 & 0.180\(\)0.011\(\) & 0.245\(\)0.012\(\) & 0.174\(\)0.005 & 0.193\(\)0.012\(\) & **0.174\(\)0.010** \\   recreation \\  } & 0 & 0.237\(\)0.013\(\) & 0.332\(\)0.018\(\) & **0.214\(\)0.020** & 0.279\(\)0.018\(\) & **0.214\(\)0.020** \\  & 4 & 0.258\(\)0.012\(\) & 0.343\(\)0.015\(\) & **0.242\(\)0.021** & 0.286\(\)0.017\(\) & 0.247\(\)0.019 \\  & 6 & 0.260\(\)0.013 & 0.346\(\)0.015\(\) & **0.247\(\)0.019** & 0.287\(\)0.018\(\) & 0.252\(\)0.016 \\  & 8 & 0.264\(\)0.014 & 0.347\(\)0.015\(\) & **0.251\(\)0.018** & 0.286\(\)0.018\(\) & 0.258\(\)0.014 \\   slashdot \\  } & 0 & 0.312\(\)0.026\(\) & 0.406\(\)0.024\(\) & 0.276\(\)0.026\(\) & 0.324\(\)0.028\(\) & **0.249\(\)0.028** \\  & 3 & 0.324\(\)0.022\(\) & 0.412\(\)0.019\(\) & 0.289\(\)0.020\(\) & 0.337\(\)0.029\(\) & **0.260\(\)0.022** \\  & 5 & 0.335\(\)0.019\(\) & 0.418\(\)0.011\(\) & 0.300\(\)0.015\(\) & 0.350\(\)0.025\(\) & **0.268\(\)0.019** \\  & 7 & 0.335\(\)0.021\(\) & 0.418\(\)0.011\(\) & 0.301\(\)0.021\(\) & 0.351\(\)0.024\(\) & **0.270\(\)0.018** \\   core15k \\  } & 0 & 0.206\(\)0.006\(\) & 0.317\(\)0.011\(\) & **0.195\(\)0.006\(\)** & 0.267\(\)0.045 & 0.240\(\)0.006 \\  & 7 & 0.231\(\)0.020\(\) & 0.332\(\)0.018\(\) & **0.221\(\)0.022\(\)** & 0.287\(\)0.051 & 0.266\(\)0.013 \\  & 12 & 0.239\(\)0.017\(\) & 0.337\(\)0.019\(\) & **0.231\(\)0.019\(\)** & 0.292\(\)0.051 & 0.276\(\)0.012 \\  & 17 & 0.247\(\)0.018\(\) & 0.342\(\)0.016\(\) & **0.238\(\)0.020\(\)** & 0.295\(\)0.051 & 0.283\(\)0.012 \\  & 22 & 0.252\(\)0.018\(\) & 0.345\(\)0.012\(\) & **0.243\(\)0.020\(\)** & 0.299\(\)0.052 & 0.286\(\)0.013 \\   arts \\  } & 0 & 0.220\(\)0.024\(\) & 0.305\(\)0.030\(\) & 0.193\(\)0.023\(\) & 0.297\(\)0.045\(\) & **0.187\(\)0.018** \\  & 3 & 0.324\(\)0.049\(\) & 0.376\(\)0.040\(\) & 0.311\(\)0.051\(\) & 0.397\(\)0.076\(\) & **0.296\(\)0.049** \\  & 5 & 0.348\(\)0.029\(\) & 0.392\(\)0.029\(\) & 0.335\(\)0.033\(\) & 0.421\(\)0.079\(\) & **0.318\(\)0.030* Muenlplr: A SVM-based dynamic multi-label learning approach which trains a set of linear classifiers by minimizing misclassification loss and pairwise ranking loss. [parameter configuration: \(C_{1}=1,C_{2}=1\)]
* Sence: A multi-label learning approach based on label-specific features generated by mixture-based clustering ensemble. [parameter configuration: \(r\)= 0.4].
* Limic: A multi-semantics multi-label metric learning approach coupled with MLlnn which learns one global and multiple label-specific local metrics simultaneously. [parameter configuration: \(_{1}=1,_{2}=100,=2,K=10\)].

With the first attempt towards solving the MLOSR problem, there is no method can be directly applied. Thus, we compare the proposed Slan approach with existing anomaly detection approaches.

* Oc-svm: A SVM-based approach which constructs a hyper-sphere surrounding all instances from known labels.
* iForest: An unsupervised forest-based anomaly detection approach which employs average path length over all trees as the anomaly score.
* Muenlforest: A forest-based dynamic multi-label learning approach which utilizes clustering process in each nodes by considering the feature space and the label patterns. [parameter configuration: \(q=5,=256,g=100,e_{m}=9\)].

For the proposed Slan approach, trade-off parameters are set as \(=0.1,=0.1,=10,_{1}=0.1,=0.8\). \(_{0}\) is fixed to be 0.1. The sensitivity analysis of parameter configurations is conducted in Subsection 4.3. A Linux server equipped with Intel Xeon CPU (48 cores @ 2.67GHz) and 256GB memory is used for supporting the experiments.

    & \#label & Oc-svm & iForest & Muenlforest & Slan \\  } &  &  &  & \\    & 3 & 0.501\(\)0.063\(\) & 0.494\(\)0.062\(\) & 0.340\(\)0.067\(\) & **0.672\(\)0.058** \\  & 5 & 0.440\(\)0.064\(\) & 0.436\(\)0.060\(\) & 0.309\(\)0.067\(\) & **0.576\(\)0.062** \\  & 7 & 0.391\(\)0.049\(\) & 0.387\(\)0.046\(\) & 0.281\(\)0.057\(\) & **0.501\(\)0.050** \\  & 9 & 0.362\(\)0.047\(\) & 0.359\(\)0.043\(\) & 0.267\(\)0.054\(\) & **0.456\(\)0.043** \\   & 6 & 0.352\(\)0.100\(\) & 0.350\(\)0.099\(\) & 0.398\(\)0.116 & **0.406\(\)0.096** \\  & 9 & 0.283\(\)0.109\(\) & 0.282\(\)0.108\(\) & 0.314\(\)0.116 & **0.321\(\)0.095** \\  & 12 & 0.251\(\)0.113\(\) & 0.250\(\)0.112\(\) & 0.276\(\)0.120 & **0.281\(\)0.098** \\   & 4 & 0.346\(\)0.066\(\) & 0.339\(\)0.066\(\) & 0.318\(\)0.054\(\) & **0.376\(\)0.066** \\  & 6 & 0.283\(\)0.052\(\) & 0.279\(\)0.052\(\) & 0.265\(\)0.044\(\) & **0.305\(\)0.055** \\  & 8 & 0.230\(\)0.037\(\) & 0.227\(\)0.035\(\) & 0.218\(\)0.033\(\) & **0.244\(\)0.039** \\   & 3 & 0.411\(\)0.100\(\) & 0.409\(\)0.099\(\) & 0.310\(\)0.088\(\) & **0.528\(\)0.127** \\  & 5 & 0.350\(\)0.094\(\) & 0.349\(\)0.095\(\) & 0.274\(\)0.088\(\) & **0.428\(\)0.105** \\  & 7 & 0.293\(\)0.071\(\) & 0.293\(\)0.072\(\) & 0.235\(\)0.075\(\) & **0.350\(\)0.069** \\   & 7 & 0.496\(\)0.018\(\) & 0.489\(\)0.016\(\) & 0.327\(\)0.013\(\) & **0.653\(\)0.015** \\  & 12 & 0.430\(\)0.022\(\) & 0.424\(\)0.019\(\) & 0.298\(\)0.013\(\) & **0.539\(\)0.017** \\  & 17 & 0.378\(\)0.018\(\) & 0.373\(\)0.018\(\) & 0.272\(\)0.009\(\) & **0.462\(\)0.012** \\  & 22 & 0.344\(\)0.018\(\) & 0.340\(\)0.017\(\) & 0.253\(\)0.009\(\) & **0.414\(\)0.015** \\   & 3 & 0.356\(\)0.074\(\) & 0.354\(\)0.069\(\) & 0.340\(\)0.058\(\) & **0.395\(\)0.105** \\  & 5 & 0.273\(\)0.040\(\) & 0.271\(\)0.037 & 0.264\(\)0.033 & **0.288\(\)0.049** \\  & 7 & 0.230\(\)0.044\(\) & 0.229\(\)0.042 & 0.224\(\)0.038 & **0.235\(\)0.047** \\   & 4 & 0.282\(\)0.086\(\) & **0.282\(\)0.088** & 0.274\(\)0.082 & 0.277\(\)0.059 \\  & 6 & 0.230\(\)0.060\(\) & **0.231\(\)0.060** & 0.226\(\)0.057 & 0.224\(\)0.040 \\   & 8 & 0.479\(\)0.031\(\) & 0.475\(\)0.031\(\) & 0.387\(\)0.017\(\) & **0.616\(\)0.025** \\  & 12 & 0.418\(\)0.034\(\) & 0.414\(\)0.032\(\) & 0.346\(\)0.021\(\) & **0.518\(\)0.027** \\  & 16 & 0.374\(\)0.020\(\) & 0.370\(\)0.020\(\) & 0.315\(\)0.014\(\) & **0.452\(\)0.013** \\  & 20 & 0.341\(\)0.021\(\) & 0.338\(\)0.022\(\) & 0.291\(\)0.015\(\) & **0.404\(\)0.014** \\   & 5 & 0.567\(\)0.021\(\) & 0.564\(\)0.020\(\) & 0.478\(\)0.023\(\) & **0.684\(\)0.025** \\  & 8 & 0.526\(\)0.028\(\) & 0.524\(\)0.026\(\) & 0.450\(

### Experimental Results

The detailed experimental results in terms of _Ranking loss_ and _F-measure_ are reported in Table 2-3. Due to the page limit, the results on other metrics are shown in the Appendix. Meanwhile, pairwise t-test  is conducted to demonstrate whether the performance of Slan is statistically superior/inferior to the comparing approaches on each data set. The resulting win/tie/loss counts are summarized in the supplementary material.

Based on the reported experimental results, the following observations can be made:

* Compared with the performance on close set instances (#label = 0), the performance of all comparing approaches on open set instances degrades. Nonetheless, across all multi-label evaluation metrics, Slan achieves superior or at least comparable performance against the comparing approaches in 91.7% cases. The results clearly indicate the jointly optimization with recognizer serves a more effective way to achieve more robust multi-label classifier in the open environment.
* Comparing with anomaly detection approaches, Slan achieves better performance in 83.3% cases. Possible reasons are that: (a) Oc-svm and iForest are previously designed for multi-class scenario which can not directly solve MLOSR problem. (b) For the construction of Muenlforest, instance is augmented with its predictive values derived from Muenlplr. However, the predictive values might be suboptimal as Muenlplr is trained without considering open space risk.
* In the multi-label setting, instances with unknown labels may share the same dense region of instances with known labels, which makes multi-class anomaly detection approaches tend to reject instances with unknown labels. That is why since Muenlplr is under multi-label setting, it still inferior to iForest and Oc-svm.

### Parameter Sensitivity Analysis

In this section, we study the sensitivity analysis of trade-off parameters \(,,,_{1},\) shown in Algorithm 1. Figure 2 illustrates how the performance of Slan changes with varying parameter configurations on data set enron. As shown in Figure 2, Slan achieves relatively stable performance on multi-label metrics and somewhat sensitive on _F-measure_. In this paper, trade-off parameters are set as \(=0.1,=0.1,=10,_{1}=0.1,=0.8\), which can be employed as the default parameter setting.

## 5 Conclusion

The major contributions of our work are two-fold: 1) We formalize a novel learning framework named multi-label open set recognition (MLOSR), which aims to classify and recognize instances with unknown labels in multi-label setting, suggesting a new direction for multi-label learning. 2) We propose a novel MLOSR approach named Slan which can facilitate open set multi-label classification by utilizing sub-labeling information and recognize the unknown labels by differentiating the sub-labeling information from holistic supervision. Extensive experimental results clearly validate the effectiveness of the proposed Slan approach.

However, Slan enriches #labels+1 sub-labeling information, which could hardly generalize to extreme multi-label data set. Meanwhile, Slan works in the multi-label learning schema where

Figure 2: Performance of Slan with varying value of trade-off parameters on enron.

the feature representations of instances may less informative. In the future, it is interesting to investigate towards extreme multi-label learning to achieve tolerable scalability and design deep MLOSR approaches with discriminative feature representations. Furthermore, it is desirable to extend evaluation metrics for MLOSR.