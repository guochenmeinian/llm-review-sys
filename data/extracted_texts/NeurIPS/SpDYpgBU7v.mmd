# Atomic Layer Deposition Optimization via Targeted Adaptive Design

Marieme Ngom\({}^{1*}\) Carlo Graziani\({}^{1}\) Noah Paulson\({}^{1}\)

\({}^{1}\)Argonne National Laboratory

*mngom@anl.gov

###### Abstract

Atomic Layer Deposition (ALD) is a commonly employed process for producing conformal nanoscale coatings in the microelectronics and energy materials industries. ALD processes are composed of cycles of sequential self-limiting chemical reactions followed by purges with an inert gas to produce atomically thin coatings. At the end of each cycle, the Growth Per Cycle (GPC) which corresponds to net mass or thickness change from the previous ALD cycle is determined. Optimizing ALD processes for stable and uniform GPC for a new combination of reactants is challenging as the optimal combination of gas timings, temperature, and gas partial pressures spans a large multidimensional space and in-situ characterization is typically performed with a limited number of mass sensors. In this work, we use Targeted Adaptive Design (TAD), a Gaussian Process (GP)-based probabilistic machine learning framework that aims at efficiently and autonomously locating control parameters that would yield a desired target within specified tolerance, to optimize simulated ALD processes.

## 1 Introduction

Atomic Layer Deposition (ALD)  is a thin-film deposition technique that employs a cyclical process of alternating precursor exposures and purging steps, enabling self-limiting chemical reactions that deposit one atomic layer per cycle, providing precise control over film thickness and composition. In this work, we consider ALD processes that involve two chemicals, precursor \(1\) and precursor \(2\) that reacts cyclically with the surface of a substrate in a sequential and non-overlapping manner. Each cycle is composed of four sequences: a dose period \(t_{1}\), during which the substrate is exposed to precursor \(1\); a purge period \(t_{2}\), during which there is no precursor exposure; a dose period \(t_{3}\), during which the substrate is exposed to precursor \(2\); and a final purge period \(t_{4}\), during which there is no precursor exposure. At the end of each cycle, the GPC which corresponds to net mass or thickness change from the preceding ALD cycle is determined. In , the authors employed a simple physics model to simulate ALD and proposed three optimization methods- Bayesian Optimization (BO)  with Expected Improvement , Random Optimization (_RO_) and Expert Systems Optimization (_ESO_) leveraging expert knowledge- to find timings \((t_{1},t_{2},t_{3},t_{4})\) that would yield Growth Per Cycle (GPC) saturation in minimum time. In this work, we use Targeted Adaptive Design (TAD) , a Gaussian Process (GP)-based method for efficiently and autonomously locating control parameters that yield a target feature within specified tolerances, to optimize ALD processes. We employ the physics model from  as a simulator and compare the performance of TAD to the methods proposed in that paper.

## 2 Overview of Targeted Adaptive Design

We start by giving a comprehensive overview of TAD which is a recently proposed algorithm for locating control parameters in a \(D\)-dimensional input space \(X^{D}\) that would yield a target feature \(f_{target}\) in a \(E\)-dimensional output space \(Y^{E}\) within specified tolerance, while simultaneouslylearning the unknown mapping \(f:X Y\). The mapping \(f\) is only attainable through noisy measurements \(=f()+\), where \(\{x_{k} X:k=1,,N\}\) and \(\) is a zero-mean Gaussian noise vector. TAD is an iterative method with similarities to BO, optimizing an acquisition function at each iteration to propose new candidate solutions.

### Problem setup

TAD begins by defining three sets which it will update throughout its iterations: a set \(_{1}\) of \(N_{1}\) points in \(X\) with associated noisy observations of \(f\)\(_{1} f(_{1})+_{1}\), a set \(_{2}\) of \(N_{2}\) points in \(X\) associated with latent observations \(_{2} f(_{2})+_{2}\), and a point \(x X\) that corresponds to the initial target candidate solution. Additionally, TAD defines a Targeted Tolerance Region (TTR) \(_{i}[f_{target_{i}}-_{i},f_{target_{i}}+_{i}]\), \(i=1,,E\), where \(f_{target_{i}}\) is the \(i\)th component of the target vector \(f_{target_{i}}\) and \(_{i}\) is a tolerance threshold for \(f_{target_{i}}\). A vector-valued GP prior is assumed on \(f\) i.e \(f((.),C(.,.))\) with \(\) and \(C\) corresponding respectively the mean and covariance vectors of the GP. The GP is trained on the observations \((_{1},_{1})\) and is used to predict the distributions of \(_{2}|_{1}\) and of \(f(x)|_{1},_{2}\). In particular, we have

\[_{2}|_{1} (^{(2|1)},^{(2|1)})\] (1) \[^{(2|1)} _{2}+_{21}(_{11}+_{1} )^{-1}(_{1}-_{1})\] (2) \[^{(2|1)} _{22}+_{2}-_{21}(_{11}+ _{1})^{-1}_{12}.\] (3)

and

\[f(x)|(_{1},_{2}) \{^{(f(x)|1+2)},^{(f(x)|1+2)}\}\] (4) \[p^{(f(x)|1+2)} (x)+[_{x1}_{x2}]_ {11}+_{1}&_{12}\\ _{21}&_{22}+_{2}^{-1}_{1}-_{1}\\ _{2}-_{2}\] (5) \[Q^{(f(x)|1+2)}  K_{xx}-[_{x1}_{x2}]_ {11}+_{1}&_{12}\\ _{21}&_{22}+_{2}^{-1}_{1x}\\ _{2x}.\] (6)

where \(_{1}(_{1})\), \(_{2}(_{2})\), \(K_{xx} C(x,x)\), \(_{x1}=_{1x}^{T} C(x,_{1})\), \(_{x2}=_{2x}^{T} C(x,_{2})\), \(K_{11} C(_{1},_{1})\), \(K_{22} C(_{2},_{2})\), \(K_{12}=K_{21}^{T} C(_{1},_{2})\), \(_{1}\) is the noise covariance matrix associated to \(_{1}\), and \(_{2}\) is the noise covariance matrix associated to \(_{2}\). The acquisition function is then constructed using these distributions.

### Acquisition Function: Expected Log-Probability Density

TAD proposes a new acquisition function that computes the log-predictive probability density (LPPD) of the target design \(f_{target}\) at the point \(x\), conditioned on observations \((_{1},_{2})\). By Equation 4 and the standard formula for multivariate normal probability density, this is

\[_{P}(x,_{1},_{1},_{2},_{2})=-  Q^{(f(x)|1+2)}\\ -(f_{target}-p^{(f(x)|1+2)})^{T}(Q^{(f (x)|1+2)})^{-1}(f_{target}-p^{(f(x)|1+2)}),\] (7)

up to a constant. However, in this expression the mean \(p^{(f(x)|1+2)}\) is dependent on the latent values \(_{2}\) that are yet to be acquired. To obtain the TAD acquisition function, the expectation of the LPPD with respect to the predictive distribution \(_{2}|_{1}\) is calculated to obtain

\[_{TAD}(x,_{1},_{1},_{2}) E_{_{2}| {g}_{1}}\{_{P}(x,_{1},_{1},_{2},_{2}) \}.\] (8)

The TAD acquisition function \(_{TAD}(x,_{1},_{1},_{2})\) of Equation 8 has the following closed form:

\[_{TAD}(x,_{1},_{1},_{2})=- Q^{(f(x)|1+2)}-\\ (f_{T}-p^{(f(x)|1)})^{T}(Q^{(f(x)|1+2)} )^{-1}(f_{T}-p^{(f(x)|1)})\\ -(_{x2}-_{x1} (_{11}+_{1})^{-1}_{12})(^{( 2|1)})^{-1}\\ (_{2x}-_{21}(_{11}+_{1 })^{-1}_{1x})(Q^{(f(x)|1+2)})^{-1}}.\] (9)TAD then defines two stopping rules: _convergence/success_, which occurs when a solution with uncertainties that fit within the TTR is found, and _convergence/failure_, which occurs when the search space is exhausted without finding such a solution (based on information theory). TAD iterates until one of these stopping conditions is met or the computational budget is reached. TAD thus offers an efficient search (with the \(_{2}\) points) at the cost of more function evaluations. A detailed discussion of the properties of this acquisition function, including its incorporation of the exploration/exploitation trade-off, as well as numerical simulations and comparisons with existing methods, can be found in .

## 3 Optimization of Atomic Layer Deposition (ALD):

The authors in  developed a physics-based model surrogate for ALD processes, which they sample with varying levels of noise. They then propose three different optimization methods, Bayesian Optimization with Expected Improvement (_BO/EI_) as an acquisition function, Random Optimization (_RO_) and Expert Systems Optimization (_ESO_) to find dose and purge timings that would yield GPC saturation in minimum time.

Prior to running the BO algorithm, an initial set of \(10\) observations is sampled using a Latin-hypercube design of experiments (LH-DOE)  to provide a representative starting point for the GP surrogate model. The objective function for _BO/EI_ and _RO_ is defined as a combination \(C_{total}\) of four cost functions \(C_{1}\), \(C_{2}\), \(C_{3}\) and \(C_{4}\). \(C_{1}\) focuses on minimizing the sum of the dose and purge timings relative to the sum of the maximum allowed time for each sequence. \(C_{2}\) aims at reducing the divergence of the average GPC over multiple cycles from a reference GPC of a stable ALD process. \(C_{3}\) aims at controlling the difference in GPC between an ALD process and one resulting from perturbed timings while \(C_{4}\) does the same n comparison to the initial GPC. The three different methods were run over \(40\) iterations for \(10\) different initializations of the physics model. We reproduce their experiments for the \(Al_{2}O_{3}\) system at \(200^{o}C\) and a noise value of \(0.1\). Figure 0(a) shows the mean and \(95\%\) confidence intervals of the normalized GPC \(\) across these runs with respect to the number of ALD cycles (each iteration consists of 21 ALD cycles). _BO/EI_ and _RO_ produced timings that would yield desirable GPC but also explored values that led to excessive GPC during optimization. _ESO_, on the other hand, while reliable, suffered from overly conservative precursor dose times. Note that the variability during the first 210 ALD cycles for _BO/EI_ is due to the LH-DOE sampling.

We now add TAD to the optimization strategies. We define the unknown function \(f\) to be \(f(t_{1},t_{2},t_{3},t_{4})=(C_{total},)\), with \(C_{total}\) and \(\) defined above, resulting in a \(2\)-dimensional output space. We then set \(f_{target}=(0.4,1.)\) where \(0.4\) is a conservative value derived from the _ESO_ and \(_{target}=1\) ensures the normalized GPC remains stable around \(1\) during the optimization. We initialize the candidate solution to \((t_{1},t_{2},t_{3},t_{4})=(1,1,1,1)\) and \(_{2}\) is initialized as in . Finally, we set the tolerance for the TTR to be \(10\%\) across both output space dimensions. Since the GPC is dependent from previous ALD cycles, one needs to be conservative about the number \(N_{2}\) of \(_{2}\) points to be acquired at each TAD iteration. Furthermore, the number of ALD cycles per TAD iteration is \(N_{2}\) times more the number of ALD cycles per _BO/EI_ iteration. To avoid having a prohibitive number of ALD cycles, we set \(N_{2}=1\). We also run TAD for 10 different initializations

Figure 1: Comparison between our approach and current GP-based approaches

of the physics model and an observation noise level of \(0.1\). The initial \((_{1},_{1})\) observations for the initial GP fitting are also constructed using the same LH-DOE procedure as before. If TAD reaches _convergence/success_, only the successful candidate solution is acquired after the last iteration. For each initialization, TAD successfully found a solution within the prescribed tolerance in \(14\) to \(21\) iterations (i.e. between \(4\) to \(11\) iterations after the 10 initial LH-DOE steps) corresponding to \(357\) to \(651\) total ALD cycles, as illustrated in Figure 1. Furthermore, the normalized GPC remained stable across the \(10\) different runs. Note that Figure 0(a) shows TAD results for the smallest number of iterations across the \(10\) different initializations while Figure 0(b) shows TAD normalized GPC values for each of the runs over each corresponding number of iterations.

For illustration purposes, we show uptake curves which are commonly used graphical representations of the growth or deposition rate of material as a function of the precursor exposure time or dose. Uptake curves are obtained by varying one timing and fixing all the others at values resulting in saturation. Figure 2 shows uptake curves from one of the TAD runs (solid lines) superposed with reference uptakes curves for a noise level of \(0.1\). TAD saturated slightly above the reference horizontal line \(y=1\) with saturation speed similar to the reference growth.

## 4 Discussion and future work:

We applied TAD, a recently developed batch iterative algorithm for locating control parameters that yield a target design, to the optimization of ALD. We compared TAD to existing optimization methods for ALD, including Bayesian optimization with expected improvement and have shown the effectiveness of our method in terms of the number of ALD cycles required for convergence and the stability of the normalized growth per cycle during optimization. In order to avoid a large number of ALD cycles per TAD iterations, we used a conservative number of points to be acquired at each TAD iteration, and aim to relax this constraint in the future by modifying the objective function and refining the function sampler require fewer ALD cycles per evaluation. Furthermore, we plan to analyze the effect of lower noise levels on TAD. In fact, in the zero-noise limit, the covariance matrices \(Q^{(f(x)|1+2)}\) can become ill-posed especially in the presence of redundant \(_{2}\) points. The authors in  proved that matrix has a finite limit when the noise goes to zero and it would be interesting to diagnose how TAD is affected in this case and compare with the other three methods presented here.

Figure 2: The solid lines correspond to TAD uptake curves while the reference uptake curves for noise level \(0.1\) are represented by the dashed lines.