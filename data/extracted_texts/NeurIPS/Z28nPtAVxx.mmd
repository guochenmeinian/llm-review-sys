# Optimal Extragradient-Based Algorithms for

Stochastic Variational Inequalities with

Separable Structure

 Huizhuo Yuan\({}^{}\) Chris Junchi Li\({}^{}\) Gauthier Gidel\({}^{}\)

Michael I. Jordan\({}^{,}\) Quanquan Gu\({}^{}\) Simon S. Du\({}^{}\)

\({}^{}\) Department of Computer Science, University of California, Los Angeles

{hzyuan, ggu}@cs.ucla.edu

\({}^{}\) Department of Electrical Engineering and Computer Sciences, University of California, Berkeley

{junchili, jordan}@cs.berkeley.edu

\({}^{}\) DIRO, Universite de Montreal and Mila

gauthier.gidel@umontreal.ca

\({}^{}\) Department of Statistics, University of California, Berkeley

\({}^{}\) Paul G. Allen School of Computer Science and Engineering, University of Washington

ssdu@cs.washington.edu

###### Abstract

We consider the problem of solving stochastic monotone variational inequalities with a separable structure using a stochastic first-order oracle. Building on standard extragradient for variational inequalities we propose a novel algorithm--stochastic _accelerated gradient-extragradient_ (AG-EG)--for strongly monotone variational inequalities (VIs). Our approach combines the strengths of extragradient and Nesterov acceleration. By showing that its iterates remain in a bounded domain and applying scheduled restarting, we prove that AG-EG has an optimal convergence rate for strongly monotone VIs. Furthermore, when specializing to the particular case of bilinearly coupled strongly-convex-strongly-concave saddle-point problems, including bilinear games, our algorithm achieves fine-grained convergence rates that match the respective lower bounds, with the stochasticity being characterized by an additive statistical error term that is optimal up to a constant prefactor.

## 1 Introduction

The variational inequality (VI) problem plays a central role in a wide range of optimization problems with convex structure, including convex minimization, saddle-point problems, and games (Facchinei and Pang, 2003; Nemirovski, 2004; Nemirovski et al., 2009; Juditsky et al., 2011; Jordan et al., 2023). A general VI problem aims to find a solution \(^{*}\) that satisfies:

\[(^{*}),^{*}- 0, ,\] (1)

where \(\) is a finite-dimensional closed and convex feasible set and \(()\) is a monotone operator in the following form:

\[()=()+()+J^{}( )_{}[}(;)]+ _{}[}(;)]+J^{}(),\] (2)

where \(\) is continuously differentiable with \(L\)-Lipschitz continuous gradient and is \(\)-strongly convex, \(\) is an \(M\)-Lipschitz monotone operator, \(J^{} J\) is the subgradient of a simple and convex function, \(\) and \(\) are drawn from distributions \(_{}\) and \(_{}\), respectively. This formulation captures a separable structure in which \(\) usually models the competing forces in a system, and \(J\) modelsa nonsmooth factor. In addition, we consider the stochastic setting where we can only access \(\) and \(\) through their unbiased estimators \(}(;)\) and \(}(;)\) respectively.

A notable instance of the VI problem (1) with separable structure (2) is the widely studied _bilinearly coupled strongly-convex-strongly-concave saddle-point problem_:

\[_{^{n}}_{^{m}}\;(,)=F()+H(,)-G()_{}[f( ;)]+_{}[h(,;)]- _{}[g(;)],\] (3)

where \(H(,)^{}-^{}_{ }+_{}^{}\) is the bilinear coupling function with the coupling matrix \(^{n m}\). Note that (3) is a special instance of (1) when taking \(()=F()+G()\), \(()=[_{}H(,);-_{}H(, )]\) and \(J=0\). In addition to a wide range of applications in economics, problems of form (3) are becoming increasingly important in machine learning. For instance, (3) appears in reinforcement learning, differentiable games, regularized empirical risk minimization, and robust optimization formulations. It can also be seen as a local approximation of the nonconvex-nonconcave minimax games--e.g., the generative adversarial network (GAN) (Goodfellow et al., 2020)--around a local Nash equilibrium (Mescheder et al., 2017; Nagarajan and Kolter, 2017).

In this paper, we aim to improve the efficiency of solving (1) by utilizing the structural information of the monotone operator in (2). More specifically, we consider the case when \(\) is strongly monotone, or zero. Although optimal convergence results have been obtained for the monotone VI problem (1) (Chen et al., 2017) as well as the special case of convex-concave saddle-point problem with bilinear coupling (3) (Chen et al., 2014), it remains open how to design an optimal algorithm for the strongly monotone VI problem. Notably, for the special case (3) when \(F\) and/or \(G\) are strongly convex, several concurrent works have independently obtained the optimal convergence rates (Kovalev et al., 2022; Thekumparampil et al., 2022; Jin et al., 2022; Metelev et al., 2022; Li et al., 2022b). On the other hand, when both \(F\) and \(G\) are zero, optimal convergence results have been obtained by Li et al. (2022a) and the accelerated-gradient optimistic gradient approach (Li et al., 2022b). We defer a more complete overview of related work to the appendix.

### Main Contributions

We start with the strongly monotone VI problem in an unbounded feasible set, extending the scope of recent work such as Jin et al. (2022) and going beyond earlier studies that focus on nonstrongly monotone VIs in a bounded feasible set (Juditsky et al., 2011; Chen et al., 2017).1 We propose a class of algorithms named stochastic _accelerated gradient-extragradient_ (AG-EG), which combine Nesterov acceleration with the extragradient method. By employing either a strong-convexity shifting technique or a scheduled restarting scheme, our algorithm achieves convergence rates that match the lower bounds for the general strongly monotone VI problem (1), the special SC-SC saddle-point problem (3), and bilinear games, in both deterministic and stochastic settings, thus providing a unified optimal solution. In sharp contrast to the accelerated mirror-prox (AMP) algorithm proposed by Chen et al. (2017); Jordan et al. (2023), our analysis does not rely on the boundedness of the feasible set \(\), which makes our algorithm projection-free. We also extend our algorithm to VIs with bounded feasible set and/or nondifferentiable convex regularization through proximal mapping. We summarize our contributions as follows:

1. We present a direct approach for separable strongly monotone VIs, where the iteration complexity lower bound due to Zhang et al. (2022) is matched as \((}++}{^{2} ^{2}})()\), which admits a sharp near-unity coefficient (SS2.3, Theorem 2.3). Here \(^{2}\) is the weighted, uniform variance bound on the stochastic gradient and stochastic operator.
2. We also present a stochastic AG-EG algorithm equipped with scheduled restarting, which achieves the sharpest possible iteration complexity of \(((}+)( )+}{^{2}^{2}})\) for finding an \(\)-optimal point. The deterministic part matches the complexity lower bound in Zhang et al. (2022), while the stochastic part matches the optimal statistical error.

When specializing the VI problem to bilinearly coupled SC-SC saddle-point problems, our results have the following implications:

Strongly-convex-strongly-concave (SC-SC) Saddle-Point Problem.For the class of SC-SC saddle-point problems, the stochastic AG-EG descent-ascent Algorithm 1, equipped with scaling reduction, achieves an iteration complexity of

\[((}{_{F}}}{_{G}}}+ (^{})}{_{F}_{G}}} )()+}{_{F}^{2} ^{2}}),\] (4)

where \(F:^{n}\) is \(L_{F}\)-smooth and \(_{F}\)-strongly convex, \(G:^{m}\) is \(L_{G}\)-smooth and \(_{G}\)-strongly convex. When the optimization problem is deterministic, the complexity upper bound matches the lower bound of Zhang et al. (2022)(SS3.1, Corollary 2.8).

Bilinear Games.For bilinear games \(( f(;)=\) and \( g(;)=\) almost surely), Algorithm 1, equipped with scheduled restarting achieves an iteration complexity of

\[\!((^{})}{ _{}(^{})}}((^{})_{}(^{})}}{_{}})+}^{2}}{_{ }(^{})^{2}})\!,\] (5)

where \(_{}^{2}\) is the variance of the stochastic gradient on the bilinear coupling term. When there is no randomness, this complexity result reduces to \(((^{})}{ _{}(^{})}}( ))\) for bilinear games, matching the lower bound of Ibrahim et al. (2020)(SS3.2, Corollary 3.3).2

Organization.The rest of this paper is organized as follows. Section 2 proposes the Accelerated Gradient-Extragradient Descent-Ascent algorithm for strongly monotone VIs, showing that it achieves an accelerated convergence rate, and extending to VIs with bounded domains with proximal operator. Section 3 discusses two specific instances of saddle-point problems, where our proposed AG-EG algorithm has a convergence rate that matches the corresponding lower bounds. Finally, Section 4 summarizes our results and suggests future directions.

Notation.Let \(_{}()\) (resp. \(_{}()\) be the largest (resp. smallest) eigenvalue of a real symmetric matrix \(\). Let \(a b(a,b)\) (resp. \(a b(a,b)\)) denote the maximum (resp. minimum) value of two reals \(a,b\). For two nonnegative real sequences \((a_{n})\) and \((b_{n})\), we write \(a_{n}=(b_{n})\) or \(a_{n} b_{n}\) (resp. \(a_{n}=(b_{n})\) or \(a_{n} b_{n}\)) to denote \(a_{n} Cb_{n}\) (resp. \(a_{n} Cb_{n}\)) for all \(n 1\) for a positive, numerical constant \(C\), and let \(a_{n} b_{n}\) if both \(a_{n} b_{n}\) and \(a_{n} b_{n}\) hold. We also let \(a_{n}=}(b_{n})\) denote \(a_{n} Cb_{n}\) where \(C\) hides a polylogarithmic factor in problem-dependent constants. We let \([;]^{n+m}\) concatenate two vectors \(^{n}\) and \(^{m}\). Finally for two real symmetric matrices \(\) and \(\), we denote \(\) (resp. \(\)) when \(^{}(-) 0\) (resp. \(^{}(-) 0\)) holds for all vectors \(\).

## 2 Accelerated Gradient-Extragradient Descent-Ascent Algorithm

In this section, we focus on accelerating the extragradient algorithm for the strongly monotone VI problem in (1) with separable structure (2). Our algorithm design draws inspiration from the work of Chen et al. (2017) on the stochastic Accelerated MirrorProx (AMP) algorithm for nonstrongly monotone VIs. The AMP algorithm applies Nesterov-type acceleration on top of the mirror-prox method (Korplevich, 1976; Nemirovski, 2004) and attains the optimal iteration complexity of \((}+)\). However, the big-O notation hides the diameter of the feasible set, and the existing theory for the AMP algorithm can only deal with VIs with bounded domain. Our algorithm not only achieves the optimal convergence rates for the strongly monotone VI problem with separable structure but we also remove the dependency on the diameter of the feasible set. Therefore, our algorithm can deal with VIs with unbounded domains.

Throughout SS2, we maintain conceptual simplicity by presenting all our algorithm designs in the deterministic setting, while presenting the convergence results in the more general stochastic setting. These results can be easily reduced to the deterministic setting when the stochastic noise vanishes.

### Setting and Assumptions

In this section, we formally introduce our assumptions. We first state the smoothness and monotonicity assumptions that we impose on \(\) and \(\).

**Assumption 2.1** (Monotonicity, strong convexity and smoothness): _We assume that function \(()\) is continuously differentiable with \(L\)-Lipschitz continuous gradient and is \(\)-strongly convex. That is, for any \(,^{}}\),_

\[\|-^{}\|^{2}()-(^{})-(^{})^{}(-^{ })\|-^{}\|^{2}.\]

_Furthermore, operator \(()\) is monotone and \(M\)-Lipschitz in the sense that for any \(,^{}\),_

\[()-(^{}),-^{ } 0,\|()-(^{})\|  M\|-^{}\|.\]

Second, we impose assumptions on the noise variance.

**Assumption 2.2** (Unbiased gradients and variance bounds): _We assume that \(\), samples \(_{}\) and \(_{}\) are drawn from given distributions such that the following conditions hold: \(_{}[}(;)]=()\), \(_{}[}(;)]=()\), and_

\[_{}[\|}(;)-( )\|^{2}]_{ Str}^{2},_{}[\| }(;)-()\|^{2}]_ { Bil}^{2}.\] (6)

For all results in this work, we suppose that Assumptions 2.1 and 2.2 hold with appropriate parameter settings. Given a desired accuracy \(>0\), our goal is to find an _\(\)-optimal point_ defined as:

**Definition 2.1** (\(\)-Optimal point): _A point \(\) is called an \(\)-optimal point for the VI problem in (1) if \(\|-^{*}\|\)._

### The ExtraGradient (EG) Algorithm

We first consider the case where \(\) is the entire space \(^{n}\) and the objective is smooth (\(J=0\)). The extragradient (EG) algorithm, introduced by Korpelevich (1976), is designed to address cyclic behavior in saddle-point problems by introducing an extrapolated point for gradient evaluation. In the context of VI problems (1), let \(_{t}\) represents the \(t\)-th iterate of the EG algorithm. The update rule of EG is as follows:

\[_{t+1}=_{t}-_{t}-(_{t}),\] (7)

where \(>0\) is the step size. For a \(L\)-smooth and \(\)-strongly monotone operator \(\), Tseng (1995); Mokhtari et al. (2020); Gidel et al. (2019) have shown that the EG algorithm achieves an iteration complexity of \(((1/))\), where \(=L/\) denotes the condition number of the problem.

### Accelerating the ExtraGradient Algorithm, Direct Approach

The convergence rate of the EG algorithm is far from optimal for the strongly monotone VI problem in (1) with separable structure (2). Firstly, the update rule in (7) takes \(\) as a whole without utilizing the separable structure. This prevents us from exploiting the properties of \(\). Secondly, in the case of bilinear games, the established lower bound for EG is \(((1/))\) rather than \(((1/))\). This discrepancy highlights the potential for accelerating the EG algorithm in various directions. We first rewrite the EG update rule in (7) as follows:

\[_{t-} =_{t-1}-(_{t-1})=_{t-1}- (_{t-1})+(_{t-1}),\] \[_{t} =_{t-1}-(_{t-})=_{t-1}- (_{t-})+(_{t- }).\] (8)

To accelerate the process based on \(\), we consider Nesterov's second acceleration scheme on minimizing a single convex function \(\)(Tseng, 2008; Lan and Zhou, 2018; Lin et al., 2020):

\[_{t-1}^{ md}=(1-_{t})_{t-1}^{ sg}+_{t}_{t- 1},_{t}=_{t-1}-}(_{t-1 }^{ md}),_{t}^{ sg}=(1-_{t})_{t-1}^{ sg}+_{t} _{t},\] (9)where \(_{t}\) is the extrapolation step size in the standard three-line Nesterov scheme. Here we adopt the notation \(^{}\) and \(^{}\) to indicate the middle point and the aggregated point (Chen et al., 2017), respectively. Next, to achieve acceleration, we replace the gradient of \(\) evaluated at both \(_{t-1}\) and \(_{t-}\) in (8) by the gradient evaluated at the extrapolated point \(_{t-1}^{}\) in (9). Furthermore, we shift the index of \(^{}\) by \(\) to indicate the use of \(_{t-}\) instead of \(_{t}\) in the \(^{}\) update in (9). In addition, we take into account the \(\)-strong convexity of \(\) and shift the gradient of the strongly convex part \(_{}[\|-_{0}\|^{2}]=(- _{0})\) from \(()\) to \(()\) as \(()=(()-(-_{0}))+( ()+(-_{0}))\), we obtain the following update rule for a direct version of an accelerated EG algorithm (different step size schemes for \(_{t}\) are required for different algorithmic designs):

\[_{t-}^{}=(1-_{t})_{t- {3}{2}}^{}+_{t}_{t-1},\\ _{t-}=_{t-1}-_{t}((_{t-1})+ (_{t-1}^{})-(_{t-1}^{}- {z}_{t-1})),\\ _{t}=_{t-1}-_{t}((_{t-})+ (_{t-1}^{})-(_{t-1}^{}- {z}_{t-})),\\ _{t-}^{}=(1-_{t})_{t-}^{ {ag}}+_{t}_{t-}.\] (10)

We call the algorithm in (10) the _accelerated gradient-extragradient, direct approach_ (AG-EG-Direct), and postpone its full description to Algorithm 2 in SSC.1. The final output of the direct approach is \(_{T}\) after \(T\) iterates. The following theorem records the convergence rate and iteration complexity of AG-EG (direct approach).

**Theorem 2.3** (Convergence of stochastic AG-EG, direct approach): _Suppose Assumptions 2.1 and 2.2 hold. Fix any \(r(0,1)\), \((0,)\), let \(_{}=+}{^{2}}\) and set the step size upper bound \(}}\). For any sequence of step sizes \(_{t}(0,]\) and \(_{t}=}{}\), the iterates of stochastic AG-EG (direct approach) satisfy that for all \(t=1,,T\), we have_

\[\|_{t}-^{}\|^{2}\|_{0}- ^{}\|^{2}(+1)_{s=1}^{t}(1- _{s})+}{^{2}}_{s=1}^{t}_{s}^{2}_{=s+1} ^{t}(1-_{}),\] (11)

_where we define \(=}_{}^{2}+(2+)_{}^{2}}\)._

In the rest of the paper, we use the same definition \(\) as in Theorem 2.3. The proof of Theorem 2.3 is provided in SSD.4. We further note that one possible choice of step size is to let \(_{t}\), such that (11) reduces to

\[\|_{t}-^{}\|^{2}\|_{0}- ^{}\|^{2}(+1)e^{- t}+}{^{2}}.\]

For any given \(T 1\), by choosing the optimal \(=(1+(T}{3^{2}}( {}+1)\|_{0}-^{}\|^{2}))\ \ \), (11) implies

\[\|_{T}-^{}\|^{2}\|_{0}-^{}\|^{2 }(+1)e^{-T}+}{^{2}T} (1+(T}{3^{2}}(+1)\| _{0}-^{}\|^{2})).\]

Prescribing the desired accuracy \(>0\), the iteration complexity to output an \(\)-optimal minimax point is 3

\[((}++}{^ {2}^{2}})((+1)\|_{0}- ^{}\|^{2}/^{2})).\]

We conjecture that the logarithmic factor in the optimal statistical rate \(}{^{2}^{2}}\) is removable using a proper diminishing step size, a possibility that we reserve for future study. In the setting of deterministic optimization, setting \(=0\) and \(r 1^{-}\), \( 0^{+}\) in Theorem 2.3, we obtain the optimal iteration complexity bound as follows:

\[(1++}{^{2}}})(( +1)/^{2}).\] (12)

**Remark 2.4**: _Our complexity bounds fundamentally differs from the previous analysis (Chen et al., 2017; Jordan et al., 2023) for separable smooth (strongly) monotone VIs. The convergence results in previous studies are dependent on the diameter of the domain, whereas our convergence rate is independent of the domain parameters and eliminates the need for projection onto a bounded domain. Moreover, our contributions go beyond those of Chen et al. (2017) by extending the analysis to the strongly monotone case. In comparison with Jordan et al. (2023), we design an algorithm where \(\) is strongly monotone and resolve the open problem of extending the analysis to the stochastic case. Additionally, our complexity bound in (12) indicates a near-unity coefficient on the condition-number exponent, improving the corresponding coefficient in Chen et al. (2017, Theorem 15) by an asymptotic factor of \(4\)._

The direct approach, which reduces to EG when \(=0\) and \(=0\), falls short of attaining optimality within the specific regime of bilinear games. In the next subsection, we will introduce a new algorithm that can overcome this limitation.

### Accelerating the ExtraGradient Algorithm with Scheduled Restarting

In this subsection, we solve problem (1) by further accelerating the stochastic EG algorithm. Rather than directly relying on the strong monotonicity of \(\), the inner updates of our new algorithm are identical to the updates in (10) with \(=0\). Due to the domain-independent nature of our analysis, we can apply the scheduled restarting technique (O'donoghue and Candes, 2015; Roulet and d'Aspremont, 2017; Renegar and Grimmer, 2022) to the outer loop, accelerating the algorithm from sublinear convergence to linear convergence. In addition, the output of our algorithm is the aggregated point \(_{T-}^{}\) after \(T\) iterates. We present the full algorithm in Algorithm 1.

``` Require: Initialization \(_{0}^{}\), total number of epochs \( 1\), total number of per-epoch iterates \((T_{s}:s=1,,)\), stepsizes \((_{t},_{t}:t=1,2,)\). for\(s=1,2,,\)do  Set \(_{-}^{}_{0}^{[s-1]},_{0} _{0}^{[s-1]},_{0}^{}_{0}^{[s-1]}\) for\(t=1,2,,T_{s}\)do  Draw samples \(_{t-}_{}\) from oracle, and also \(_{t-},_{t}_{}\) independently from oracle \(_{t-}_{t-1}-_{t}(}(_{t-1};_{t-})+}(_{t-1}^ {};_{t-}))\) \(_{t-}^{}(1-_{t})_{t-}^{}+_{t}_{t-}\) \(_{t}_{t-1}-_{t}(}(_{t- };_{t})+}(_{t-1}^{}; _{t-}))\) \(_{t}^{}(1-_{t+1})_{t-}^{}+_{t+1}_{t}\) endfor  Set \(_{0}^{[s]}_{T_{s}-}^{}\) {//Warm-start using the output of the previous epoch} endfor Output:\(_{0}^{[]}\) ```

**Algorithm 1** Stochastic AcceleratedGradient-ExtraGradient (AG-EG) Descent-Ascent Algorithm, with Scheduled Restarting

We first present the convergence rate of a single epoch (i.e., the inner loop) of Algorithm 1 in Theorem 2.5. To accommodate more flexibility in the choice of parameters, we introduce three constants \(r,\), and \(C\) in the theorem statement.

**Theorem 2.5** (Convergence of stochastic AG-EG, one epoch): _Suppose Assumptions 2.1 and 2.2 hold. For any fixed epoch length \(T 1\), any constant \(r(0,1)\), \((0,)\), \(C(0,)\), choose step sizes \(_{t}=\) and \(_{t}\) such that_

\[}=L B+}Mt,\] (13)_where \(B=}{C\|_{0}-^{*}\|^ {2}}}\). The output \(_{T-}^{ag}\) of a single epoch of Algorithm 1 satisfies_

\[\|_{T-}^{ag}-^{*}\|^{2} {(T+1)}(+A}M)\| _{0}-^{*}\|^{2}++C)}{} \|_{0}-^{*}\|^{2}},\] (14)

_where the prefactor \(A 1+C^{2}B_{1} 1+C^{2}\) reduces to 1 when \(=0\)._

The proof of Theorem 2.5 is provided in SSD.3. We make a few remarks on Theorem 2.5 as follows:

**Remark 2.6**: _In the setting of deterministic optimization, by taking \(=0\), \(r 1^{-}\), \( 0^{+}\) in our analysis, with step size choice \(_{t}=\), we obtain that_

\[\|_{T-}^{ag}-^{*}\|^{2} +M\|_{0}-^{*}\|^{2},\] (15)

_In this setting, the algorithm is independent of \(B\) and requires no knowledge of \(\|_{0}-^{*}\|^{2}\). In the face of stochasticity, we choose \(C=1\) when the initial distance to the optimal point is known. Alternatively, when only an over-estimate \(_{0}\) of \(\|_{0}-^{*}\|^{2}}\) is available, we can set (large enough) \(C=}{\|_{0}-^{*}\|^{2}}} 1\) to obtain_

\[\|_{T-}^{ag}-^{*}\|^{2}(+2}M)_{0}^{2}+}_{0}.\] (16)

**Remark 2.7**: _When the constants are not a concern, the coarse-grained choices of \(r=\) and \(=1\) would suffice. Nevertheless, to optimize the constants, the tradeoff between the deviation of \(r\) from \(1\) and \(\) from \(0\) is crucial, as it determines a balance between the stochastic gradient noise variance and the convergence rate coefficients._

To prepare for our multi-epoch result with the help of scheduled restarting, we perform an induction based on (16) as follows. Supposing that \(\|_{0}^{[s-1]}-^{*}\|^{2}_{0}^{2}e^{1-s}\) hold, by taking \(r=\) and \(=1\), we have

\[\|_{0}^{[s]}-^{*}\|^{2}^{2}} _{0}^{2}e^{1-s}+}_{0}^{2}e^{1-s}+}}_{0}e^{}.\]

Setting the right-hand side of the above inequality to satisfy \(_{0}^{2}e^{-s}\), and solving for \(T_{s}\), we need the epoch length satisfies \(T_{s}}++}{^{2}_ {0}^{2}e^{1-s}}\). Thus, we can obtain the total iteration complexity as

\[_{s=1}^{S}[}++}{ ^{2}_{0}^{2}e^{1-s}}]=(}+)S+}{^{2}T_{0}^{2}}-1}{e-1},\]

where \(S^{2}}{e^{2}}\). This yields the following multi-epoch iteration complexity bound:

**Corollary 2.8** (Iteration complexity of stochastic AG-EG with scheduled restarting): _Under the same condition of Theorem 2.5, the stochastic AG-EG with scheduled restarting in Algorithm 1 with epoch length \(T_{s}}++}{^{2}_ {0}^{2}e^{1-s}}\) has a total iteration complexity of_

\[((}+)( )+}{^{2}^{2}} ).\] (17)

Note that the hard instance constructed by Zhang et al. (2022) can be modified in a straightforward way to establish a lower bound of \(((}+)( ))\) for our monotone VI (1), demonstrating the optimality of Corollary 2.8 in the deterministic separable setting. An alternative optimality argument proceeds as follows: the first term \(}\) matches the lower bound for the minimization of a strongly convex function \(\)(Nesterov, 2004), and the second term \(\) matches the lower bound for VI for non-strongly monotone operator when \(=0\)(Ouyang and Xu, 2021). This together gives a lower bound for solving monotone VI (1) via a similar argument by Thekumparampil et al. (2022).

It is worth noting that while both complexity bounds in Corollary 2.8 and Theorem 2.3 match the lower bound in Zhang et al. (2022) for strongly monotone VIs with separable structure, the direct approach in SS2.3 reduces to the _last-iterate_ independent-sample stochastic extragradient (SEG) algorithm in _bilinear games_. Consequently, the deterministic part (\(=0\)) fails to match the lower bound in Ibrahim et al. (2020). In the stochastic case with noise variance bounded away from zero, the direct approach in SS2.3 can exhibit _nonconvergence behavior_(Hsieh et al., 2020, SS3). The AG-EG algorithm in SS2.4 resolves this issue by restarting the _average-iterate_ SEG, matching the lower bound results (see SS3.2 for more details). In addition, the complexity bound in (17) also eliminates the \(\) prefactor of the statistical error term \(}{^{2}^{2}}\) compared to Theorem 2.3. The optimality of our algorithm lies in not only the optimization complexity but also the statistical error rate \(}{^{2}^{2}}\). Here the \(\)-optimal point \(\) is defined as \(\|-^{}\|\).4

### Extension of AG-EG to Proximal Algorithms

In previous subsections, we have focused on the case where the feasible set \(\) represents the entire space and the nondifferentiable convex function \(J\) is dropped. We now extend the AG-EG algorithm and its analysis to the more general setting that has a bounded feasible set (via Euclidean projection onto the feasible set) as well as a nondifferentiable convex regularization term (via a proximal operator). These settings are useful in various applications, such as the variational inequality on the Lorentz cone where projection onto \(=\{(,t)^{(n+1)}:\|\| t\}\) is required (Chen et al., 2017), and the two-player game that involves projection onto the probability simplex, among others. To deal with bounded feasible set \(\), we adopt a variant of the EG algorithm, where we project the extrapolated point and the main iterates back onto the feasible set \(\) of \(\):

\[_{t-} =P_{}[_{t-1}-(_{t-1}) ]=_{}-_{t-1}, (_{t-1})+\|-_{t-1} \|^{2},\] \[_{t} =P_{}[_{t-1}-(_{t- })]=_{}-_ {t-1},(_{t-})+\| -_{t-1}\|^{2},\] (18)

where \(P_{}()=_{^{}}\| -^{}\|^{2}\) is the Euclidean projection operator. To handle the nondifferentiable simple convex function \(J\), we replace the projection operator in (18) by the following proximal mapping defined via a Bregman divergence \((,)\):

\[_{}^{J}()*{argmin}_{ },-+(,)+J().\] (19)

In fact, (18) can be seen as a special case of (19) when choosing the Bregman divergence \((,)=\|-\|^{2}\) and \(J()\) as the set indicator function of the feasible set \(\). Therefore, by substituting the prox-mapping (19) into the AG-EG updates introduced in SS2.4, we obtain the more general proximal AG-EG algorithm in Algorithm 3 (See in SSC.2), which reduces to Algorithm 1 when \(J=0\), \((,)=\|-\|^{2}\) and \(=^{n}\). Moreover, we assume that \((,)\) is \(_{}\)-strongly convex. Without loss of generality, in contrast to the previous assumption of \(\)-strong convexity for \(\), we instead assume that \(\) is \(\)-strongly convex with respect to the Bregman divergence \((,)\) (See, for example, Hazan and Kale (2014); Xu et al. (2018)). Similar to Corollary 2.8, we have the following iteration complexity result, whose proof is deferred to SSD.5:

**Corollary 2.9** (Iteration complexity of stochastic proximal AG-EG with scheduled restarting): _Under the same condition of Theorem 2.5, the stochastic proximal AG-EG with scheduled restarting in Algorithm 3, with epoch length \(T_{s}}}}+}} +(_{0},^{})}{^{2}_{}_{0}^{2}^{1-s}}\), has a total iteration complexity of_

\[((}}}+}})()+ (_{0},^{})}{^{2}_{}^{ 2}}).\]

For the deterministic case, proximal AG-EG with scheduled restarting has a total iteration complexity of \(((}}}+}})())\) to output an \(\)-optimal point of (1).

Implications for Specific Instances

In this section, we discuss the implications of our AG-EG algorithm and its convergence rates when applying to two instances of saddle-point problems.

### Strongly-Convex-Strongly-Concave Saddle-Point Problem

For the stochastic bilinearly-coupled SC-SC saddle-point problem (3), we note that the smoothness and strong convexity parameters \(L_{F}\), \(L_{G}\), \(_{F}\), and \(_{G}\) of \(F\) and \(G\) may differ. To accommodate these variations in curvature information, we employ a scaling reduction technique. This technique enables us to convert the SC-SC with equal strong convexity parameters for \(F\) and \(G\) by reparametrizing the objective function. The same argument is also applicable to the direct approach.

In lieu of (3), we consider

\[_{}}_{}}\ }(},})=F(})+(},})-(}),\]

where \(}(},})=(,)\) with the symbolic reparametrization \(}=\), \(}=}{_{F}}}\), \((},})=H(,)\), \((})=G()\) and also their derivatives \(_{}}(},})=} {_{G}}}_{}H(,),(})=}{_{G}}} G(})\) (the stochastic oracles \(,\) follow the same rule). It is straightforward to verify that \(}(},})\) is \(\)-strongly-convex-\(\)-strongly-concave. The essence of our update rules can be summarized by the rescaled updates on \(\):

\[}_{t}=}_{t-1}-_{t}(-_{}}h(}_{t-},}_{t-};_{t})+  g(}_{t-1}^{};_{t-}))\] \[\ _{t}=_{t-1}-_{t}}{ _{G}}(-_{}h(_{t-},_{t-}; _{t})+ g(}_{t-1}^{};_{t-})).\]

Therefore, it suffices to analyze Algorithm 3 for \(}(},})\) and due to this scaling reduction, we only need to prove all results for the case of \(_{F}=_{G}=\). It is also straightforward to justify corresponding scaling changes as: \(L=L_{F}}{_{G}}L_{G}\), \(M=}{_{G}}_{}(^{})}\), and \(=_{F}\). The following corollary is recovered by reverting the scaling reduction from \(}(},})\) to \((,)\).

**Corollary 3.1** (Iteration complexity of stochastic AG-EG on SC-SC saddle-point problem): _For solving (3), Algorithm 1 with an epoch length \(T_{s}}{_{F}}}{_{G}}}+(^{})}{_{F}_{G}}}+}{_{F}^{2}_{G}^{2}e^{1-s}}\) has a total iteration complexity of_

\[((}{_{F}}}{_{G}}} +(^{})}{_{F}_{G}}} )()+}{_{F}^{2}e^{2}} ).\]

In the deterministic case, the iteration complexity in Theorem 2.8 matches the lower bound established by Zhang et al. (2022), i.e., \(((}{_{F}}}{_{G}}}+ (^{})}{_{F}_{G}}} )())\). Moreover, our algorithm achieves the optimal statistical rate of \(}{_{F}^{2}e^{2}}\) up to a constant prefactor.

**Remark 3.2**: _A well-known finding regarding the second scheme of Nesterov acceleration is its connection to the primal-dual method (Lan and Zhou, 2018; Lin et al., 2020c). This finding has been incorporated into the design of the LPD algorithm (Thekumparampil et al., 2022), where a Chambolle-Pock-style primal-dual method is utilized as an approximation of proximal point methods, instead of the extragradient used in this paper. The LPD algorithm (Thekumparampil et al., 2022) also achieves the optimal complexity for the deterministic bilinearly-coupled saddle-point problem._

### Bilinear Games

In this subsection, we consider the particular case of bilinear games. _We assume \(n=m\) such that \(\) is a nonsingular square matrix, \( f(;)=\)_ and \( g(;)=\) a.s., so (3) reduces to

\[_{}_{}\ (,)=_{} [h(,;)]=H(,)=^{} -^{}_{}+_{}^{},\] (20)and Algorithm 3 reduces to the independent-sample extragradient descent-ascent algorithm for (20). The saddle point \([^{*};_{}^{*}]\) in this case is the unique solution to the linear equation

\[&\\ -^{}&^{*}\\ _{}^{*}=_{}\\ _{}, ^{*}\\ _{}^{*}=-(^{})^{-1}_{}\\ ^{-1}_{}.\]

Our results imply the following iteration complexity for solving stochastic bilinear games.

**Corollary 3.3** (Iteration complexity of stochastic AG-EG, bilinear games): _For solving (20), choose the step sizes \(_{t}=\) and \(_{t}(^{})}}\), in which case Algorithm 1 with an epoch length \(T_{s}(^{})}{_{}( ^{})}}\) has the total iteration complexity of_

\[((^{})}{_{ }(^{})}}((^{}) _{}(^{})}}{_{1}})+1}^{2}}{_{}(^{})^{2}}).\] (21)

Note that our choice of the step size is maximal and is independent of the noise. In the deterministic setting, letting \(_{1}(^{}) _{}(^{})}\), the complexity bound in Corollary 3.3 reduces to \(((^{})}{_{ }(^{})}}())\), which matches the lower bound in Ibrahim et al. (2020). Notably, Azizian et al. (2020) proposed an algorithm achieving an upper bound that matches the lower bound in Ibrahim et al. (2020).Li et al. (2022) also proposed a lower-bound matching SEG algorithm that uses a shared sample in both steps under an unbounded noise assumption. In contrast, our algorithm is in the independent-sample setting with bounded noise variance.

**Remark 3.4**: _Standard acceleration techniques do not attain the optimal nonasymptotic convergence rate for bilinear games (Gidel et al., 2019). This limitation applies to various algorithms, including the direct approach (Silma, 2013), as well as several other acceleration techniques (Thekumparampil et al., 2022; Kovalev et al., 2022; Jin et al., 2022), all of which fall short of achieving optimal acceleration for bilinear games. Therefore, matching both lower bounds in a single algorithm in the general stochastic setting has been an open problem. While Li et al. (2022) present an algorithm that achieves both lower bounds in a single algorithm, it relies on the use of optimistic gradients rather than extragradients on the bilinear coupling function. Furthermore, our algorithm and analysis is more general than those in Li et al. (2022) as we can handle the general variational inequality with proximal operators._

## 4 Conclusions

We have presented a stochastic extragradient-based acceleration algorithm, AG-EG, for solving stochastic monotone variational inequalities with separable structure. The iteration complexity of our algorithm matches the lower bound and is independent of the size of the feasible set. When specialized to solving the bilinearly coupled saddle-point problem (3), our AG-EG algorithm simultaneously matches lower bounds due to Zhang et al. (2022) and Ibrahim et al. (2020) for strongly-convex-strongly-concave and bilinear games, respectively. To the best of our knowledge, this is the first time that all three lower bounds have been met by a single algorithm. There are some remaining issues to be addressed, however, including the case of one-sided nonstrong convexity, the setting of unbounded noise variance, and the characterization of the full parameter regime dependency on \(_{}(^{})\). These are left as important directions for future research.