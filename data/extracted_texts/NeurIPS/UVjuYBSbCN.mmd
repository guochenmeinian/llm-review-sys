# Toward a Well-Calibrated Discrimination via Survival Outcome-Aware Contrastive Learning

Dongjoon Lee

Chung-Ang University

dongzza97@cau.ac.kr

&Hyeryn Park1

Chung-Ang University

hyeryn2000@cau.ac.kr

&Changhee Lee

Korea University

changhelee@korea.ac.kr

Equal contribution

###### Abstract

Previous deep learning approaches for survival analysis have primarily relied on ranking losses to improve discrimination performance, which often comes at the expense of calibration performance. To address such an issue, we propose a novel contrastive learning approach specifically designed to enhance discrimination _without_ sacrificing calibration. Our method employs weighted sampling within a contrastive learning framework, assigning lower penalties to samples with similar survival outcomes. This aligns well with the assumption that patients with similar event times share similar clinical statuses. Consequently, when augmented with the commonly used negative log-likelihood loss, our approach significantly improves discrimination performance without directly manipulating the model outputs, thereby achieving better calibration. Experiments on multiple real-world clinical datasets demonstrate that our method outperforms state-of-the-art deep survival models in both discrimination and calibration. Through comprehensive ablation studies, we further validate the effectiveness of our approach through quantitative and qualitative analyses.

## 1 Introduction

Deep learning models have gained significant attention in survival analysis (also known as time-to-event analysis), which focuses on predicting and understanding the occurrence of an adverse event (e.g., death) as a function of time. The utility of survival models is typically evaluated through two key aspects: discrimination and calibration. Discrimination measures a model's ability to differentiate between patients with varying risks, prioritizing those more likely to experience the event. Calibration, on the other hand, assesses how well a model's predictions align with the observed event distribution. In other words, a well-calibrated model offers predictions that closely match actual survival outcomes, offering crucial prognostic value to clinicians.

In an effort to enhance the discriminative power of survival models, ranking loss functions  are frequently employed. These functions aim to maximize a relaxed proxy of the concordance index (C-index), a well-established metric for evaluating the quality of patient rankings based on the risk predictions of survival models . However, a notable improvement in discriminative power often comes at the expense of calibration performance, which can negatively affect the clinical utility of predicted survival outcomes. For example, a poorly calibrated model that overestimates risk may lead to unnecessary treatment or testing for patients. Conversely, underestimating risk may result in patients with adverse conditions not receiving appropriate care.

Contrastive learning  is a framework that aims to learn an embedding space where similar samples are mapped to nearby locations, while dissimilar samples are pushed farther apart. Notably, although commonly used in an unsupervised fashion, this framework shares a fundamental principlewith ranking losses: both focus on the relative ranking of samples for better discrimination. However, unlike ranking losses, which directly modify differences in model outputs, contrastive learning operates on the relative distances of representations in the embedding space. This distinction offers the potential to overcome misalignment issues caused by direct comparisons and modifications of model outputs inherent in the ranking-based approaches. To leverage this potential and further enhance survival models, we propose incorporating informed sampling into the contrastive learning framework. By assigning lower penalties to potential false negative pairs based on the similarity of their survival outcomes, we instill an inductive bias in the model, encouraging it to learn that samples with similar event times likely share similar clinical statuses. This allows us to achieve strong discrimination without directly comparing or manipulating model outputs, thus potentially improving calibration as well.

**Contribution.** In this paper, we propose a novel contrastive learning approach, specifically designed for survival analysis, to enhance both discrimination and calibration performance.2 Motivated by the assumption that patients with similar event times share similar clinical status, we contrast samples in the latent space based on their survival outcomes. However, unlike standard contrastive methods, we leverage the model output solely for maximum likelihood estimation (MLE), thereby promoting better calibration. This is achieved by incorporating importance sampling into our contrastive learning framework, where we assign weights proportional to the differences in survival outcomes. This guides our model to learn appropriate similarity relationships between clinical features relevant to survival analysis. Through experiments on multiple real-world clinical datasets, we demonstrate the superiority of our method in both discrimination and calibration performance, outperforming state-of-the-art deep survival models. We further provide comprehensive quantitative and qualitative analyses through ablation studies to showcase the impact of our novel contrastive learning approach tailored for survival analysis.

## 2 Related Works

### Deep Learning Approaches to Survival Analysis

Deep learning-based survival models have garnered significant attention due to their ability to provide non-parametric estimations of the underlying discrete-time survival distribution, particularly conditional hazard or survival functions. Negative log-likelihood (NLL) has been widely used in survival analysis to estimate various survival quantities, such as conditional hazard functions [9; 10; 11], probability mass functions of event times , or survival functions . MLE, based on NLL, provides unbiased estimates of these quantities under the assumption of ignorable censoring, where the event and censoring are independent given the input features. Building on this foundation, recent deep learning-based survival models often incorporate auxiliary losses alongside the NLL loss to further enhance model performance.

**Ranking Loss.** Ranking loss, often augmented with the NLL loss, has been widely employed in recent deep survival models to enhance the discriminative power of survival predictions [1; 2; 3; 4]. These ranking loss functions, which are differentiable approximations or upper bounds of the negative C-index , are typically based on exponential [1; 2], log-sigmoid [4; 13], or linear  functions. In particular, these approaches directly utilize model outputs, such as conditional hazard or survival functions, to establish pairwise ordering of comparable individual risks for better discrimination. However, since ranking loss primarily focuses on samples with earlier event times (often ignoring censored samples), these models may struggle to capture the full distributional characteristics of time-to-event outcomes. This can adversely affect calibration performance, potentially leading to inaccurate predictions regarding the observed time-to-event outcomes .

**Calibration Loss.** In healthcare applications, while achieving high discriminative power through ranking loss is crucial, well-calibrated predictions are equally important for effective clinical decision-making. Notably, recent approaches [14; 2] have prioritized enhancing calibration by minimizing the rank probability score (RPS), a prediction error metric specifically tailored for survival analysis. Furthermore, the authors in  have introduced a novel approach that transforms D-Calibration  into a differentiable objective, calculating the squared difference between observed and predicted events across multiple time intervals. In contrast to these methods, our proposed approach does not explicitly incorporate a calibration loss function. Nevertheless, it achieves comparable or even superior calibration performance, demonstrating the effectiveness of our contrastive learning framework in implicitly preserving calibration alongside discrimination.

### Contrastive Learning

Contrastive learning [6; 7; 17] is a framework that learns an embedding space that effectively discriminates among samples, by mapping positive pairs (similar samples) closer together, while pushing negative pairs (dissimilar samples) farther apart. While contrastive learning has made significant progress, our review of related work will focus on methods that explore various strategies for injecting inductive bias to enhance representation learning.

Exploiting Continuous Labels.Inspired by the success of incorporating label information into contrastive learning for classification tasks , recent research has extended this concept to regression tasks by exploiting continuous label information for constructing positive and negative pairs. Zha et al.  employ hard thresholding on label differences to generate positive and negative samples, capitalizing on the idea that samples with similar target values should be mapped closer in the latent space. Kerdabadi et al.  apply a similar approach in a dynamic time-to-event setting, defining positive pairs as those within a specific time window and weighting negative pairs proportionally to their time difference. However, this weighting scheme's heavy reliance on absolute time differences can destabilize the contrastive loss during training.

Weighting Negative Samples.Recent works have significantly improved contrastive learning by incorporating inductive bias in the selection of negative samples. This includes focusing more weights on hard negatives that challenge the model for more effective discrimination [20; 21; 22; 23] and avoiding potential false negatives that might mislead the model [24; 25]. Many of these studies address negative sample selection by employing informed sampling techniques to identify informative hard negatives or potential false negatives. Notably, Robinson et al.  leverage importance sampling by proposing a similarity-based distribution that prioritizes hard-to-distinguish negative samples.

## 3 Problem Formulation

### Preliminary: Discrete-Time Survival Analysis

Suppose we are given a discrete-time survival dataset comprising \(N\) patients, denoted as \(=\{(_{i},_{i},_{i})\}_{i=1}^{N}\). Each patient \(i\) is represented by the input feature \(_{i}\) where \(\) is the input space, and the observed survival outcomes, \(_{i}\) and \(_{i}\{0,1\}\). Here, \(_{i}\) and \(_{i}\) indicate the time elapsed until either an event of our interest (e.g., death) or censoring (e.g., lost to follow-up) occurs and whether the event was observed or not (i.e., right-censored), respectively. Throughout, we treat survival time as discrete and the time horizon as finite such that the set of possible survival times is defined as \(=\{0,,T_{}\}\) with a pre-defined maximum time horizon \(T_{}\).

The conditional hazard function, \(:\), is the instantaneous risk of the event at time \(t\) given feature \(\) and is defined as \((t|)=(T=t|T t,)\). Then, we can represent the survival function \(S:\) as follows:

\[S(t|)=(T>t|)=_{t^{} t}(1- (t^{}|))\] (1)

which is a non-increasing function of \(t\), indicating the probability of the event occurring after time \(t\) given feature \(\). Equivalently, we could estimate the risk function, \(R:\), which represents the probability of the event occurring at or before time \(t\) given feature \(\), i.e., \(R(t|)=(T t|)=1-S(t|)\).

Then, we can achieve likelihood-based estimates for the hazard function, \(\), by minimizing the following negative NLL loss:

\[_{}=-_{i=1}^{N}_{i}(_{i}| _{i})+(1-_{i})(_{i}|_{i})\] (2)

where \((t|)=(t|)(t-1|)\) represents the estimate for the probability of an event occurring at time \(t\), i.e., \((T=t|)\). Here, (2) exploits two pieces of information from the survival data: (i)when the event is observed (i.e., \(_{i}=1\)), we know that the event occurred at time \(_{i}\), and (ii) when the event is not observed (i.e., \(_{i}=0\)), we are aware that the event will occur after time \(_{i}\).

### Ranking Loss for Survival Analysis

Ranking loss specifically targets enhancing the discriminative power of survival models, which is crucial for better distinguishing between patients based on their risk. Suppose we are given the risk function, \(R\), that quantifies the risk of a given patient with \(\) at any time \(t\). We aim to penalize instances where the risks assigned to a pair of patients are incorrectly ordered (i.e., assigning a lower risk to patient \(i\) who died before patient \(j\)). This can be achieved by the ranking loss, which is formally given as follows:

\[_{}=_{i j}A_{i,j}R( _{i}|_{i})<R(_{i}|_{j})_{i j }A_{i,j}R(_{i}|_{i}),R(_{i}|_{j}) ,\] (3)

where \(\) is a function that relaxes the non-differentiable indicator function, \(\). Here, \(A_{i,j}=(_{i}=1,_{i}<_{j})\) indicates acceptable pairs whose assigned risks are comparable.

Different deep survival models have employed various types of quantities for implementing the ranking loss. For example, Lee et al.  have applied the risk function, \(R\), and set \((x,y)=(-(x-y)/)\), a convex function that both penalizes the wrongly ordered pairs and encourages the correctly ordered pairs. The same convex function has been employed utilizing the survival function, \(S\). Similarly, Steck et al.  utilizes \((x,y)=(y-x)\), which is a lower bound of the C-index, with the risk function, \(R\). Chi et al.  employ the hazard function \(h\) with a linear ranking function \((x,y)=-(x-y)\).

**Challenges.** While combining NLL with ranking loss shows a notable improvement in discriminative power, it often comes at the expense of calibration performance, potentially harming the clinical utility of predicted survival outcomes. We suspect this is primarily due to how ranking loss directly modifies model outputs to order predicted risks, potentially leading to misalignment with the actual risk distribution. In this paper, we propose a different approach. Our method focuses on increasing discriminative power not by directly utilizing survival outcomes but by exploiting the embedding space through our novel contrastive learning framework. This approach preserves the calibration performance achieved by the NLL loss while enhancing discriminative capabilities.

## 4 Method

To address the challenges described above, we propose a novel **Cont**rastive learning approach to a deep **S**urvival model, which we refer to as **ConSurv**. The proposed method consists of three key components as illustrated in Figure 1:

* _Encoder_ (parameterized by \(\)), \(f_{}:\), takes features \(\) as input and outputs latent representations, i.e., \(=f_{}()\).
* _Projection head_ (parameterized by \(\)), \(g_{}:^{d}\), maps latent representations \(\) to the embedding space where contrastive learning is applied, i.e., \(=g_{}()\).
* _Hazard network_ (parameterized by \(\)), \(f_{}:\), predicts the hazard rate at each time point \(t\) given the input latent representation \(\), i.e., \((t|)=f_{}(,t)=f_{}(f_{}(),t)\).

Motivated by the core concept of contrastive learning frameworks, we aim to differentiate each sample from other _semantically different_ samples based on their _survival outcomes_. This allows us to overcome the limitation of ranking loss, which arises from the direct comparison of model outcomes in the form of risk/survival functions. Instead, we contrast samples in the latent space based on their survival outcomes and utilize the model outcome solely for the NLL loss to encourage better calibration.

### Contrastive Learning for Survival Analysis

Our novel contrastive learning framework imposes lower penalties on potential false negative samples based on the similarities in their survival outcomes. More specifically, given an anchor sample, we define potential false negatives as samples with a small difference in the corresponding time-to-event.

This inherently aligns with our inductive bias that patients with similar survival outcomes should share similar clinical status, which manifests through similar representations.

For each anchor sample \( p_{X}\), the noise-contrastive estimation (NCE) objective aims to learn mapping \(f=g_{} f_{}\) utilizing a positive sample with the same semantic meaning, i.e., \(^{+} p_{+}\), and negative samples with (supposedly) different semantic meanings, i.e., \(^{-} q\), as follows :

\[_{ p_{X}\\ x^{+} p_{X^{+}}}-\ ,^{+})}}{M _{^{-} q}[e^{s(,^{-})}]} \] (4)

where \(M\) is the scaling term which is set to the batch size and \(s:[-1,1]\) is the similarity score between two samples. Here, we use cosine similarity in the embedding space, i.e., \(s(,^{})=^{})^{T}f(^{})}{\|f()\|\|f(^{})\|}\). For notational convenience, we omit the corresponding temperature \(\) and write \(e^{s(,^{+})}\) to denote \(e^{s(,^{+})/}\).

The key aspect in (4) for obtaining embeddings with discriminative power lies in how we select negative samples that the anchor sample should be distinguished from. To reflect the differences in the time-to-events in the embedding space, we design a novel negative distribution, \(q\), by utilizing the available information from survival outcomes.

**Importance Sampling using Survival Outcomes.** To accurately distinguish patients based on their time-to-event outcomes, we fully utilize the time-to-event information for designing \(q\) based on the following inductive bias: similar patients are more likely to experience the event at similar time points than the ones who are not. Hence, given an anchor \((,)\) and a negative sample \((^{-},^{-})\), we define the weight function as follows:

\[w(^{-};)=1-e^{-|-^{-}|\ /\ }\] (5)

where \(>0\) is a temperature coefficient. From this point forward, we will slightly abuse the notation and write \(w(^{-};)\) to denote \(w(^{-};)\) to be consistent with the notation used for the negative distribution. This function is a variant of the Laplacian kernel, where the weight increases as the time difference increases. That is, we assign larger weights for samples with large differences in the time-to-events, and smaller weights for samples with small time differences. Utilizing the weight function in (5), we can define the negative distribution, \(q\), as:

\[q(^{-};)=w(^{-};)p(^{-}),\] (6)

where \(Z\) is the normalizing constant. Then, using the importance sampling technique, we can approximate the expectation of the similarity score of negative samples drawn from the negative distribution in (6) as:

\[_{^{-} q}e^{s(,^{-})} =_{^{-} p}[^{-};)}{p(^{-})} e^{s(,^{-})}]_{j=1}^{M}w(_{j}^{-};) e^{s(, _{j}^{-})}\] (7)

Figure 1: An illustration of the network architecture for ConSurv.

where the normalizing constant for the empirical distribution can be given as \(Z=_{j=1}^{M}w(_{j}^{-};)\). Overall, the survival outcome-aware NCE (SNCE) loss in (8), mitigating the effect of potential false negatives that have similar survival outcomes, can be given as the following:

\[_{}= _{i=1}^{N}-_{i}, _{i}^{+})}}{_{j=1}^{M}w(_{j}^{-};_{i})  e^{s(_{i},_{j}^{-})}}.\] (8)

### Handling Right-Censoring

However, in a survival dataset, there exist samples that are right-censored, offering partial information about the corresponding survival outcomes which indicates that the event will occur sometime after the censoring time. Consequently, not every pair in the survival dataset has comparable survival outcomes. Specifically, there are three different cases of sample pairs to consider:

* **Case 1:** Both samples are uncensored (i.e., have observed events). We can directly compare the two time-to-events of any given pair.
* **Case 2:** One is uncensored and the other is censored. Similar to the acceptable pairs in ranking loss, we can only compare a pair when sample \(i\) experiences an event while sample \(j\) is censored after that event time (implying no event has occurred by that time), i.e., \(_{i}<_{j}\).
* **Case 3:** Both samples are censored. No comparison is possible as we do not know when the actual events have occurred for both samples.

Considering these cases, we redefine the weight function considering the right-censoring as \((_{j};_{i})=I_{i,j} w(_{j};_{i})\) where \(I_{i,j}\) indicates the comparable cases as follows:

\[I_{i,j}= 1&(_{i}=1,_{j}=1)((_{i }=1,_{j}=0)(_{i}<_{j})(|_{i}-_{j}| ))\\ 0&\]

where \(\) is a hyperparameter that represents a margin to ensure a minimum time difference. Please see Appendix C.3 for more details about the effect of \(\).

### Network Description

In this subsection, we provide a detailed network description of ConSurv and outline the learning procedure using a discrete-time survival dataset, \(=\{(_{i},_{i},_{i})\}_{i=1}^{N}\).

**Negative Log-likelihood.** Based on the encoder and the hazard network, we can provide the estimated hazard function given the input feature \(\) at each time point \(t\) as \((t|)=f_{}(f_{}(),t)\). As our hazard estimate is defined as a function of time given an input feature, we can naturally model the time-varying effect of input features (thus, more complex relations) on risk/survival functions. Then, we can compute the NLL loss, \(_{}^{,}\), in (2) by plugging in \(f_{}(f_{}(),t)\) into \(\) and \(\) as follows:

\[(|)=f_{}(f_{}(),)_{t^{ }-1}1-f_{}(f_{}(),t^{}), 14.226378pt(|)=_{t^{}}1 -f_{}(f_{}(),t^{}).\] (9)

**Contrastive Learning.** To train the proposed method using our contrastive loss introduced in (8), we construct augmented samples based on the state-of-the-art contrastive learning framework specifically designed for tabular data . For each sample in a batch of \(M\) samples, we construct a corrupted version of the original sample following the marginal corruption process. So, given \(_{i}\) as an anchor, we set the corrupted sample, i.e., \(}_{i}\), as positive and all the other corrupted samples, i.e., \(}_{j}\) for \(j i\), as negative. By passing the original, positive, and negative samples through \(f=g_{} f_{}\), we can compute our survival outcome-based contrastive learning loss function as defined in (8).

Overall, we can estimate the hazard function by training ConSurv with a loss function that combines the NLL loss and the SNCE loss as the following:

\[_{Total}^{,,}=_{}^{,}+ _{}^{,},\] (10)

where \(\) is a balancing coefficient that trade-offs between the two loss terms; the effect of \(\) is provided in C.3. Please find the pseudo-code of ConSurv in H.

## 5 Experiment

In this section, we evaluate the performance of ConSurv and multiple survival models using several real-world clinical datasets. Further details about all the experiments are available in Appendix D.

### Experiment Setup

**Datasets.** We compare our proposed method and the benchmarks with the following four commonly used real-world clinical datasets: _METABRIC_, _NWTCO_, _GBSG_, _FLCHAIN_, _SUPPORT_, and _SEER_. For detailed descriptions of these datasets, please refer to D.1.

**Benchmarks.** We compare ConSurv with six survival models that were selected based on their respective loss functions, which are critical for understanding trends in survival analysis performance. The evaluated models are based on i) partial log-likelihood including _CoxPH_ and _DeepSurv_, ii) ranking loss including _DeepHit_ and _DRSA_, and iii) calibration loss including _DCS_ and _X-CAL_. Detailed methodological descriptions are provided in Appendix D.3.

**Performance Metric.** We evaluate the discriminative performance of ConSurv and benchmarks using the _integrated time-dependent C-index_ (CI)  across all time points, where higher values indicate better performance. For calibration, we utilize the _integrated Brier score_ (IBS)  and _distributional divergence for calibration_ (DDC) , where lower values indicate better performance. Additionally, _D-Calibration_ (D-CAL)  assesses calibration with results reported based on \(p\)-values; those exceeding 0.05 are noted as statistically significant. Comprehensive details on IBS, DDC, and D-CAL

    &  &  \\
**Method** & CI \(\) & IBS \(\) & DDC \(\) & D-CAL & CI \(\) & IBS \(\) & DDC \(\) & D-CAL \\  CosPH & \(0.662_{ 0.003}\) & \(_{ 0.003}\) & \(0.108_{ 0.009}\) & **10** & \(0.712_{ 0.003}\) & \(0.101_{ 0.003}\) & \(0.567_{ 0.036}\) & **10** \\ DeepSurv & \(0.645_{ 0.014}\) & \(0.188_{ 0.019}\) & \(0.160_{ 0.015}\) & **10** & \(0.654_{ 0.007}\) & **0.090**\( 0.047\) & \(0.624_{ 0.007}\) & 9 \\ DeepHit & \(0.636_{ 0.003}\) & \(0.205_{ 0.007}\) & \(0.289_{ 0.004}\) & 0 & \(0.713_{ 0.009}\) & \(0.140_{ 0.048}\) & \(0.616_{ 0.003}\) & 4 \\ DRSA & \(0.635_{ 0.007}\) & \(0.260_{ 0.006}\) & \(0.199_{ 0.027}\) & 0 & \(0.700_{ 0.037}\) & \(0.272_{ 0.050}\) & \(0.295_{ 0.127}\) & 0 \\ DCS & \(0.598_{ 0.015}\) & \(0.243_{ 0.022}\) & \(0.009_{ 0.030}\) & 0 & \(0.677_{ 0.003}\) & \(0.098_{ 0.015}\) & \(0.173_{ 0.015}\) & 6 \\ X-CAL & \(0.658_{ 0.009}\) & \(0.193_{ 0.018}\) & \(_{ 0.041}\) & 0 & \(0.671_{ 0.003}\) & 0.146_{ 0.022}\) & **0.133**\( ** ** are provided in Appendix D.2. In Appendix C.1, we further provide time-dependent C-index  and time-dependent Brier score  at different time points.

### Quantitative Analysis Results

We report the CI, BS, DDC, and D-CAL of our proposed method and the benchmarks in Table 1. The results in Table 1 demonstrate that our method significantly outperforms all the benchmarks in discriminating among individual risks at the evaluated all time points, consistently across the four real-world clinical datasets. ConSurv achieves such gains in the discriminative performance while providing the best or comparable calibration performance. Notably, as evidenced by the metrics IBS, DDC, and D-CAL, our method yields exceptional calibration performance. Contrarily, ranking loss-based models such as DeepHit and DRSA, which are designed primarily to enhance discriminative power, usually exhibit poor calibration. Even without being specifically designed through the loss function for calibration, our model outperforms benchmarks such as DCS and X-CAL, which incorporate loss functions used to enhance calibration power. This indicates that our approach inherently balances both discriminative and calibration power effectively.

**Ablation Study.** We conduct an ablation study to better understand the contribution of different loss functions within our framework employing the following variants of ConSurv: (i) \(_{NLL}\) only, (ii) \(_{NLL}\) & \(_{NCE}\), (iii) \(_{NLL}\) & \(_{Rank}\), and (iv) ConSurv (i.e., \(_{NLL}\) & \(_{SNCE}\)). Table 1 highlights the performance trade-offs between discrimination and calibration power when different loss functions are utilized in survival models. Using only NLL loss typically leads to lower discriminative performance while maintaining reasonably good calibration. Augmenting a ranking loss to the NLL significantly enhances discriminative performance but decreases calibration. In contrast, our proposed SNCE loss significantly enhances the model's performance compared to (i) using NLL only and (iii) using NLL with ranking loss. This suggests that the SNCE loss not only boosts discriminative power but also preserves or even improves the model's calibration. Additionally, when compared to (ii) using NLL with InfoNCE, which pushes all negative pairs away equally, we confirm that ConSurv, which assigns weights to negative samples based on their time difference until the event, ensures better performance.

Figure 3: Calibration plots for ConSurv in comparison with benchmarks for the METABRIC dataset.

Figure 2: t-SNE visualization for latent representations learned with \(_{NLL}\) only, \(_{SNCE}\) only, and ConSurvfor the METABRIC dataset, colored by event times (for uncensored samples).

### Qualitative Analysis Results

#### 5.3.1 Effect of Contrastive Learning

To further demonstrate how survival outcome-aware contrastive learning promotes discrimination among samples in the latent space, we compare two-dimensional t-SNE visualizations of latent representations trained with \(_{NLL}\) only, \(_{SNCE}\) only and ConSurv (i.e., \(_{NLL}\) & \(_{SNCE}\)) for the METABRIC dataset in Figure 2. Here, we only display uncensored samples with event times for clarity. Figure 2 shows that when trained with \(_{NLL}\) alone, latent representations are mixed regardless of their corresponding event times. However, incorporating \(_{SNCE}\) into the loss function significantly improves the alignment of representations with event time information, enabling the predictor to better discriminate the risks associated with each sample. Notably, even when trained solely with \(_{SNCE}\), latent representations exhibit a clear alignment with event times. This finding strongly suggests that our contrastive learning approach effectively encourages discrimination by capturing and reflecting the underlying event time information. (See Appendix C.2 for more datasets.)

#### 5.3.2 Calibration Plot

Figure 3 shows calibration plots comparing the calibration of ConSurv with the deep learning-based survival models. Here, we evaluate calibration by matching predicted cumulative densities to observed event frequencies at the quantiles of the predicted cumulative density. In these plots, the x=y line represents the ideal state where predicted probabilities perfectly match the observed outcomes. The evaluated survival models show different trends depending on the loss function used for training. The ranking-based models (i.e., DeepHit and DRSA), which directly manipulate the model outputs, experimentally demonstrated the lowest calibration power. Contrarily, the calibration-based models (i.e., X-CAL and DCS), designed to improve calibration power, show relatively better calibration but do not match the calibration performance of DeepSurv, likely due to the assumption of proportional hazards. Compared to these survival models trained based on three different types of loss functions, our proposed method demonstrates calibration performance that is similar or even superior.

#### 5.3.3 Subgroup Analysis

We further validate the calibration performance of the survival models by comparing their survival plots with the Kaplan-Meier (KM) curve, a non-parametric estimate of the survival function at a population level. For this comparison, we examine two binary hormone receptor statuses in the METABRIC dataset: estrogen receptor (ER) and human epidermal growth factor receptor 2 (HER2), which are crucial for determining hormone therapies and can result in significantly different prognoses for breast cancer patients. In Figure 4, we average the survival functions of different survival models based on the subgroups of patients with the corresponding feature values (e.g., ER+ vs ER-). The

    &  &  \\   & + & - & + & - \\  CoxPH & 0.030 & 0.108 & 0.063 & **0.089** \\ DeepSurv & 0.033 & 0.115 & 0.066 & 0.101 \\ DeepHit & 0.063 & 0.082 & 0.146 & 0.156 \\ DRSA & 0.181 & 0.293 & 0.233 & 0.328 \\ DCS & 0.130 & 0.146 & 0.087 & 0.178 \\ X-CAL & 0.136 & 0.165 & 0.105 & 0.180 \\ ConSurv & **0.024** & **0.077** & **0.044** & **0.089** \\   

Table 2: Wasserstein distances from KM curves across various patient subgroups for the METABRIC dataset.

Figure 4: Comparison of the survival curves across various patient subgroups for the METABRIC dataset.

results confirm that our method aligns well with the KM curve compared to other deep learning-based survival models, especially those with ranking loss.

To quantitatively assess calibration performance across different subgroups, we compare the survival predictions of each model with KM curves for each subgroup using the Wasserstein distance. This metric is well-suited for comparing survival curves as it considers both the overall shape and the discrepancies in predicted survival probabilities at each time point. The results in Table 2 demonstrate that our proposed model achieves well-calibrated predictions within each subgroup. (See Appendix C.4.2 for more subgroups.)

## 6 Conclusion

In this paper, we propose ConSurv, a novel contrastive learning approach for deep survival analysis. Our method leverages weighted sampling to incorporate the intuitive assumption that patients with similar event times likely share similar clinical statuses. Unlike most existing deep survival models, ConSurv does not directly manipulate hazard or survival predictions during contrastive learning. This approach allows our method to maintain well-calibrated predictions based on the negative log-likelihood loss. Experiments on multiple real-world datasets demonstrate the superiority of our method over state-of-the-art deep survival models, particularly in achieving superior calibration performance compared to ranking loss-based models.