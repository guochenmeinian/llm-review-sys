# LibMOON: A Gradient-based MultiObjective OptimizatioN Library in PyTorch

Xiaoyuan Zhang, Liang Zhao, Yingying Yu, Xi Lin, Yifan Chen, Han Zhao, Qingfu Zhang

Corresponding to Prof. Qingfu Zhang. Contact: {xzhang2523-c@my.qingfu.zhang@}cityu.edu.hk.

CityUHK, HKBU, UIUC.

###### Abstract

Multiobjective optimization problems (MOPs) are prevalent in machine learning, with applications in multi-task learning, fairness, robustness, and more. Unlike single-objective optimization, which aggregates objectives into a scalar through weighted sums, MOPs focus on generating specific or diverse Pareto solutions and learning the entire Pareto set directly. Existing MOP benchmarks primarily focus on evolutionary algorithms, which are zeroth-order or meta-heuristic methods that fail to leverage higher-order objective information and cannot scale to large models. To address these challenges, we introduce LibMOON, the first multiobjective optimization library supporting state-of-the-art gradient-based methods, offering a fair and comprehensive benchmark, and open-sourced for the community.

## 1 Introduction

Multiobjective Optimization Problems (MOPs) are ubiquitous in machine learning. For instance, trustworthy machine learning (e.g., algorithmic fairness) problems balancing the fairness level and the accuracy level ; in robotics, it is necessary to balance several objectives (e.g., forward speed and energy consumption) ; similarly, recommendation systems face potentially conflicting objectives, such as novelty, accuracy, and diversity . For all the applications above, the underlying optimization problem involves an MOP with \(m\) objectives and can be (informally) defined as:

\[_{}()=(L_{1}(),,L_{m}()), \]

where \(L_{1}(),,L_{m}()\) denote \(m\) (potentially) conflicting objectives and we denote the size of the model parameter as \(n||\). Note that as informally defined above, Equation (1) is a vector optimization problem that does not necessarily admit a total ordering. For a non-trivial MOP, no single solution can attain the minimum of all objectives simultaneously. To compare two solutions for an MOP, we introduce the concepts of _dominance_ and _Pareto optimality_. We say that solution \(^{(a)}\) dominates \(^{(b)}\) when \(^{(a)}\) satisfies \(L_{i}(^{(a)}) L_{i}(^{(b)})\) for all \(1 i m\), with at least one strict inequality. A solution is Pareto optimal if no other solution in the feasible region dominates it. The set of all Pareto optimal solutions is called the Pareto set (PS), and its image set is called the Pareto front (PF).

Over the last few decades, multiobjective evolutionary algorithms (MOEAs) emerged as a widely used methodology for addressing MOPs due to their ability to find diverse and approximate PS. Several popular MOEA libraries have emerged, including PlatEMO (Matlab) , Pagmo (C++) , and Pymoo (Python) . Compared to MOEAs, gradient-based multiobjective optimization (MOO) methods are particularly suitable for large-scale machine learning tasks involving thousands to millions of neural network parameters. In contrast, gradient-based MOO methods can only findPareto _stationary_ solutions--solutions that cannot be _locally_ improved in all objectives, in practice, Pareto stationary solutions well approximate global Pareto solutions for deep learning tasks.

With the growing need for gradient-based MOO methods (e.g., [12; 13; 4; 14]) for large-scale neural networks, there is a pressing need for the development of a standard library to benchmark related algorithms and problems. For this reason, we introduce LibMOON, the first modern gradient-based MOO library supporting over twenty state-of-the-art (SOTA) methods. We summarize our contributions as follows:

1. We introduce the _first_ modern gradient-based MOO library which is implemented in PyTorch  and carefully designed to support GPU acceleration. LibMOON supports MO machine learning problems such as MO classification, MO regression, MO distribution matching, etc, along with their real-world applications.
2. LibMOON supports over twenty state-of-the-art (SOTA) gradient-based MOO methods for constructing the PS and PF, including MOO solvers that use _finite_ solutions to approximate the entire PS/PF [16; 17]; Pareto Set Learning (PSL) solvers [18; 19] that approximate the _entire_ PS/PF with a single neural model; and multi-objective Bayesian Optimization (MOBO) solvers, which are designed to minimize the need for avoiding frequent function evaluations.
3. We have open-ourced LibMOON on Github2 with document at LibMOON Docs3. LibMOON can be installed via "pip install libmoon" as an off-the-shelf gradient-based multiobjective package for easy use. 

Notation.Bold letters represent vector (e.g., \(\) denotes a preference vector). \(^{(k)}\) denotes vector \(\) at \(k\)-th iteration and \(x_{k}\) denotes the \(k\)-th entry of \(\). The preference vector \(\) lies in the \(m\)-dim simplex (\(_{m}\)), satisfying \(_{i=1}^{m}_{i}=1\) and \(_{i} 0\). The decision network parameter \(\) has a size of \(n\). For two \(m\)-D vectors \(^{(a)}\) and \(^{(b)}\), \(^{(a)}^{(b)}\) means \(^{(a)}_{i}^{(b)}_{i}\) for all \(i[m]\); \(^{(b)}\), \(^{(a)}_{}^{(b)}\) means that \(^{(a)}_{i}^{(b)}_{i}\) for all \(i[m]\) and for at least one strict inequality. \(^{(a)}^{(b)}\) means that \(^{(a)}_{i}<^{(b)}_{i}\) for all \(i[m]\). Refer to Table 11 for full notations.

## 2 Related works

### Gradient-based multiobjective optimization

Gradient-based MOO has a rich research literature. The well-known convex optimization book [20; Chap 4] outlines how linear scalarization can transform a MOO problem into a single-objective optimization (SOO) problem. However, for much of the past few decades, gradient-based methods have not been the primary focus for MOO. Instead, MOEAs have gained more attention due to their population-based nature, which is well-suited for approximating the PS and finding diverse solutions. In recent years, however, gradient-based MOO has experienced a resurgence, particularly in (deep) machine learning, where these methods scale better with the number of decision variables. A pivotal contribution in this area is the MODA-UB  method, which introduced MOO techniques into deep learning by casting multi-task learning (MTL) as a MOO problem. Since then, many approaches have followed, including EPO , Pareto Multi-Task Learning (PMTL) , MOO with Stein Variational Gradient Descent (MOO-SVGD) , and some methods for learning the entire PS (Pareto set learning) [19; 18; 21; 22; 23; 24].

### Multiobjective optimization libraries

A number of multiobjective libraries exist in the literature. We summarize the high-level comparison between LibMOON and existing libraries in Table 1 and discuss the detailed differences as follows.

**LibMTL** is a Python-based library for multitask learning. LibMTL aims to find a single network to benefit all tasks, such as finding a benign updating direction or optimizing a network architecture. In contrast, LibMOON addresses inherent trade-offs in machine learning problems, where improving one objective inevitably worsens others, and explores the distribution of Pareto solutions.

**jMetal**, **Pymoo** and **PlatEMO** are Java, python and Matlab frameworks for MOEAs, supporting popular methods such as NSGA-III , MOEA/D , and SMS-EMOA . Pymoo allows flexible algorithm customization with user-defined operators and data visualization. PlatEMO is a MATLAB-based multiobjective optimization tool supporting over 160 MOEAs and a comprehensive test problems, including sparse, high-cost, large-scale, and multimodal. PlatEMO also contains a number of metrics and supporting visualization during the optimization process.

**Pagmo** is a C++ library for parallel multiobjective global optimization, utilizing evolutionary algorithms and gradient-based methods like simplex, SQP, and interior-point techniques. It supports constrained, unconstrained, single- and multi-objective, continuous, integer, stochastic, and deterministic optimization problems.

**EvoTorch** and **EvoX**. EvoTorch accelerates evolutionary algorithms in PyTorch, while EvoX scales them to large, complex problems with GPU-accelerated parallel execution for single and multiobjective tasks, including synthetic problems and reinforcement learning.

## 3 LibMoon: A gradient-based MOO library in PyTorch

This section introduces LibMOON. We introduce its framework in Section 3.1, and briefly introducing its supporting **problems** and **metrics**. Then we introduce supported **solvers** in Sections 3.2 to 3.4.

### Framework

Figure 1 demonstrates the components of LibMOON, including three categories of solvers: MOO solvers aiming to find a finite set of Pareto solutions satisfying certain requirements, Pareto set learning (PSL) solvers aiming to learn whole PS with a single model, and MOBO solvers aiming to solve expensive MO problems. Each solver category is designed in a highly modularized way so that new solvers can be easily incorporated into LibMOON by rewriting only a small portion of code, e.g., the specific algorithm of gradient manipulations4. MOO and PSL solvers support all synthetic, MTL, and real-world (RE) problems, while MOBO solvers support synthetic and RE problems.

**Supported problems.** LibMOON currently supports three categories of methods, synthetic problems, MTL problems, and RE problems.

  
**Name** & **Language** & **Year** & **Key Features** \\ 
**Pymoo** & Python & 2020 & (2) Euro-order methods \\  & & & (3) Diverse problem types \\ 
**JRetail** & Java & 2011 & (1) Single-domain objective optimization \\  & & & (3) Diverse problem types \\ 
**PlatEMO** & **Multi** & 2017 & (1) Over 160 MOEAs \\  & & & (3) Provident size demonstrations \\ 
**Pagmoo** & C++ & 2020 & (1) Global optimization \\  & & & (2) Parallel optimization \\ 
**LIMMTL** & Python & 2023 & (1) Unified codebase \\  & & & (3) Creative solution for new methods \\ 
**EvoTorch** & Python & N/A & (1) Distribution-based search algorithms \\  & & & (3) Participation based search algorithms \\  & & & (3) Multiple CPU, GPU, computers \\ 
**EvoX** & Python & 2024 & (2) Single-multi-objective optimization \\  & & & (3) Neuroscientist/RL tasks \\ 
**LibMOON** & Python & 2024 & (2) Pareto set learners \\  & & & (3) Large-scale (millions \# params.) ML tasks \\   

Table 1: Previous MOO libraries and LibMOON.

Figure 1: **Supported solvers and problems in LibMOON: LibMOON addresses synthetic, real-world and MTL problems with three categories of solvers: MOO, PSL and MOBO solvers.**

**Supported metrics.** LibMOON supports several metrics for evaluation, (1) hypervolume (HV), (2) inverted general distance (IGD), (3) fill distance (FD), (4) minimal distance (l\({}_{}\)), (5) smooth minimal distance (sl\({}_{}\)), (5) Spacing, (6) Span, (7) penalty-based intersection (PBI), (8) inner product (IP), (9) cross angle (\(\)). Full descriptions of these metitres are provided in Appendix A.3.

### MOO solvers

In this paper, MOO solvers refer to solvers that find a set of Pareto solutions. The simplest and most commonly used method is _linear scalarization_, which converts a MOO problem to a single objective optimization problem through some aggregation functions.

Aggregation-based methods.A straightforward way is to use some aggregation functions \(g_{}():^{m}\) to convert a MOP to a single objective optimization problem. The reason that optimizing this converted single objective optimization problem will yield Pareto optimal solutions is due to the following two theorems.

**Theorem 1** (Adapted from Theorem 2.6.2 ).: _If \(g_{}()\) is **strictly decreasing** w.r.t vector \(()\), i.e., \(g_{}((^{(a)}))<g_{}((^{(b)}))\) when \(_{i}(^{(a)})_{}_{i}(^{ (b)})\), then the optimal solution \(^{*}\) of \(g_{}(}())\) serves as a **Pareto optimal** solution for the original MOP._

Proof.: See Mitten's book , Page 22. Similarly, for decreasing aggregation functions, we have the following theorem.

**Theorem 2**.: _If \(g_{}\) is **decreasing** w.r.t. vector \(()\) (i.e., \(g_{}((^{(a)})) g_{}((^{(b)}))\) when \((^{(a)})_{}(^{(b)})\), then the optimal solution \(^{*}\) of \(g_{}(())\) serves as a **weakly Pareto optimal** solution for the original MOP._

Proof.: Similar to the proof of Mitten's book , Page 22.

In Theorem 2, _weakly Pareto optimality_ means that for a solution \(^{(a)}\), no other solutions \(^{}\) can strictly dominate it, i.e., \(_{i}(^{})<_{i}(^{(a)})\) for all \(i[m]\). Some common aggregation functions include the linear scalarization (LS) function, where \(g_{}^{}(())=_{i=1}^{m}_{i}L _{i}()\), the Tchebycheff function, where \(g_{}^{}(())=_{i[m]}_{i }(L_{i}()-z_{i})\) (\(\) is a reference point), Penalty-Based Intersection (PBI) function , and COSMOS function . For expressions and other aggregation functions, please refer to Appendix A.2.

For a preference vector \(\), \(g_{}^{}()\) is a _strictly decreasing function_, hence directly optimizing \(g_{}^{}()\) yields _Pareto optimal solutions_ (by Theorem 1). However, for any \(_{m}\), optimizing \(g_{}^{}()\) only yields weakly _Pareto optimal solutions_ (by Theorem 2). For an improper setting of the weight factor \(\) (see Appendix A.2 item 1 and 6), the optimal solution of \(g_{}^{}()\) or \(g_{}^{}()\) can be non-(weakly) Pareto optimal solutions of the original MOP.

An aggregation function is optimized by gradient descent in LibMOON via backpropagation, i.e, \(^{(k+1)}=^{(k)}-_{k}=^{(k)}- }(())}{}|_{ ^{(k)}}\), where \(^{(k)}\) is called the updating direction at the \(k\)th iteration. The gradient term \(}(())}{}\) can be decomposed into two parts: \(}(())}{}= }(())}{} ()}{}\), assuming that \(()}{}\) exists. If \(g_{}()\) is differentiable, then \(}(())}{()}\) is the standard gradient. In cases where \(g_{}()\) is non-differentiable, \(}(())}{()}\) could be taken as a sub-gradient.

Gradient manipulation-based methods.Besides directly optimizing the aggregation function, several so-called "_gradient manipulation methods"_ solve an updating direction \(^{(k)}\) using gradient information for each iteration for some specific purpose. For example, as listed in Table 3, EPO  aims to find "exact Pareto solutions" (the intersection points of the Pareto front and preference vectors), HVGrad  aims to maximize the hypervolume of a set of solutions, MOO-SVGD 

   Method & \(L_{1}\) & \(L_{2}\) \\  Fairness classification  & BCE & DEO \\ MO classification  & CE - BR & CE - UL \\ MO regression  & MSE & MSE \\ MO distribution matching & \(D(\|)\) & \(D(\|)\) \\  BCE: Binary Cross Entropy; DBO : Difference of Equality of Opportunity; CE: Cross Entropy; BR: Bottom Right; UL: Upper Left; MSE: Mean Square Error. \\   

Table 2: Supported MO machine learning problems. \(L_{1}\): the first objective. \(L_{2}\): the second objective.

aims to find diverse solutions, PMTL  aims to identify sector-constrained Pareto solutions, and ExcessMTL  aims to find a Pareto solution with the same excess risk across all the objectives. Interestingly, until now, all these gradient manipulation methods can be implemented in two steps: 1 calculating a dynamic weight vector \(}\) and then 2 performing backpropagation on a generalized aggregation function \(_{}((^{(k)}))\), where \(_{}((^{(k)}))=_{i=1}^{m}_{i}L_{i}()\). At each iteration, gradient manipulation methods can be equivalently expressed as updating the gradient of its induced generalization aggregation function \(_{}((^{(k)}))\). The weight vector \(}\) are achieved by solving a linear programming (LP) problem (e.g., [16, Eq. 24]) in EPO, a quadratic programming (QP) problem (e.g., [13, Eq. 14]) in PMTL, or other more complex algorithms as used to calculate the hypervolume gradient \(\).

Some MOO solvers accept preference vectors \(\) as input, termed _preference-based_, affecting Pareto solution positions. The others, called _preference-free_, do not accept preferences, such as those maximizing dominated hypervolume. A summary of these solvers is in Table 3.

Zero-order optimization.In the previous discussion, we assume that all the gradients of objective functions \( L_{i}()\) can be easily achieved via backward propagation. However, for some black-box optimization problems, \( L_{i}()\)'s may not easily be achieved. Therefore, LiMDON not only supports first-order optimization, but also supports zero-order optimization methods with estimated gradients \(L_{i}()\) such as evolutionary strategy (ES) .

### Pareto set learning solvers

LibMOON also supports Pareto Set Learning (PSL) solvers, which trains a model with parameter \(\) to approximate the _entire_ PS/PF. A Pareto model is denoted as \(_{}():_{m}^{n}\) with input as a preference vector and output as a Pareto solution.

**PSL Architecture.** Pareto models vary in structure. For synthetic problems, the simplest model is a fully-connected neural network that takes a preference as input and outputs the corresponding Pareto solution. In multitask learning, the input is a pair \((,)\) from dataset \(\), and the decision variable \(\) represents the target network's parameter, with \(\) as the hypernetwork's parameter . The loss vector is calculated as \(()=_{(,)}((_{ }(),))\), where \(\) is a basic loss function like cross-entropy or mean square error. Structures of these two models are illustrated by Figure 2. Besides these two models, LiMDON also supports LoRA (low rank adaptation)-based PSL , which admits a low rank adaptation structure and other structures. PSL structures are decoupled from the training loss and used as plug-ins.

**PSL Training.** Goal of PSL is to find a model with parameter \(\) optimizing the PSL loss \(_{}\),

\[_{}_{}=_{()}_{}((_{}())), ()=_{(,) }((_{}(),)).\]

In the above formulation, \(()\) is a Dirichlet distribution with hyperparameter \(\). \(_{}()\) can either be a generalized aggregation function as introduced in the previous section or a normal aggregation function. The gradient of \(_{}\) can be estimated by the chain rule:

  
**Method** & **Solution Property** & **Complexity** & **Pref.** \\  EPO  & Exact solutions & \(O(m^{2}nK)\) & \(\) \\ HVChap  & Solutions with maximal HV & \(O(m^{2}nK^{2})\) & \(\) \\ MOGA-UB  & Random solutions & \(O(m^{2}nK)\) & \(\) \\ MOO-SOD  & Density by particles repulsion & \(O(m^{2}nK^{2})\) & \(\) \\ PMQCA  & Solutions under specific demands & \(O(m^{2}nK)\) & \(\) \\ PMTL  & Solutions in sectors & \(O(m^{2}nK)\) & \(\) \\ Random  & Random solutions & \(O(m^{2}nK)\) & \(\) \\ Agg-LS  & Conver parts of a PF & \(O(mnK)\) & \(\) \\ Agg-Tob  & Exact solutions & \(O(mnK)\) & \(\) \\ Agg-MLrba  & Exact solutions & \(O(mnK)\) & \(\) \\ ExecMMTL  & Exact solutions & \(O(mnK)\) & \(\) \\ Agg-PH  & Approximate exact solutions & \(O(mnK)\) & \(\) \\ Agg-SmoothSf  & Approximate exact solutions & \(O(mnK)\) & \(\) \\ Agg-SmoothTob  & Approximate exact solutions & \(O(mnK)\) & \(\) \\   

Table 3: MOO solvers, properties, and complexities.

Figure 2: Architecture of Pareto models.

[MISSING_PAGE_FAIL:6]

[MISSING_PAGE_FAIL:7]

**Conclusion.** For synthetic problems, the most recommended method is _Agg-Tche_ since (1) it keeps function convexity, (2) it finds "exact" Pareto solutions under quite mild conditions (3) it does not need to calculate the Jacobian matrix for each iteration.

### Pareto set learning on synthetic problems

In this section, we present PSL results (Figure 4 and table 7) also on VLMOP2. 1. PSL with the COSMOS aggregation function fails to find all marginal Pareto solutions because COSMOS does not guarantee the discovery of the entire PS/PF. PSL with linear scalarization function could not fit the two endpoints of the PF. Those PSL results inherit from their base MOO solvers. 2. PSL with the smooth Tchebycheff function finds diverse but non-exact Pareto solutions. In contrast, PSL with Agg-Tche, EPO, and PMGDA as base solvers discovers the entire PS/PF, as all three methods find exact Pareto solutions. By traversing the preference simplex, the model accurately fits the entire PS.

**Conclusion.** The most recommended method is still _Agg-Tche-based PSL_ since its basic MOO solver Agg-Tche has attractive properties as mentioned in the previous section.

### MOO solvers for MTL problems

We evaluate the performance of finite Pareto solvers on the Adult dataset, a multitask fairness classification problem. The decision variable \(\) represents the parameters of a fully-connected neural network with \(||=28033\). The first objective is cross-entropy loss, and the second is the DEO loss [Eq. 6. 1]. Agg-LS has two drawbacks: (1) it cannot identify the non-convex part of a PF (as previous section mentioned), and (2) the relationship between preference vectors and Pareto objectives is unknown; different preference vectors may yield duplicate solutions. Agg-PBI and Agg-COSMOS only find a small portion of the PF. 2. Agg-Smooth mTche and Agg-mTche perform well on this task, as they can find (approximate) "exact" Pareto solutions. Once the range of PF range is known, diverse solutions can be easily found using uniform preference vectors. The Random and MGDA-UB methods only find a single Pareto solution, since the position of this solution cannot be controlled by these methods. 3. Among the three methods that directly find a set of Pareto solutions (MOO-SVGD, PMTL, and HV-Grad), HV-Grad produces the most diverse solutions with the largest hypervolume. PMTL, being a two-stage method, may fail when solutions fall outside the sector due to stochastic factors. MOO-SVGD optimizes both convergence and diversity but is generally unstable based on our tests.

**Conclusion.** For convex Pareto fronts in MTL problems, _Agg-LS_ is recommended for computational efficiency. However, _PMGDA_ or _EPO_ may offer better convergence and preference-solution correspondence.

   Method & \(I_{}\) & \(I_{}\) & \(I_{}\) & Sparsion & Sparsity & HV & IP & Cross Angle & PBI & Span \\  COSMOS & 0.045 (0.000) & -0.127 (0.000) & 1.560 (0.000) & **0.525 (0.000)** & 0.318 (0.000) & 0.752 (0.000) & 0.950 (0.001) & 0.995 (0.000) & 0.907 (0.000) \\ Agg-LS & 0.000 (0.000) & -0.258 (0.000) & **1.158 (0.000)** & 1.32

[MISSING_PAGE_FAIL:9]

evaluations is set as 200. Our experimental results, illustrated in Figure 4, clearly demonstrate the rapid convergence capabilities of all three methods. DirHV-EGO, PSL-DirHV-EI, and PSL-MOBO not only efficiently navigate the solution space but also quickly reach optimal solutions. This highlights the robustness and effectiveness of our implemented algorithms in handling different types of MOPs.

## 5 Conclusion, limitations, and further works

Conclusion.We introduced the _first_ modern gradient-based MOO framework called LibMOON in PyTorch for the research community's convenience. LibMOON supports more than 20 mainstream gradient-based MOO methods; the modular design of LibMOON further allows the library to address various MOPs via various methods in a plug-and-play manner. LibMOON can thus be leveraged to quickly yet robustly test new MOO ideas.

Limitationsinclude: (1) rapid developments of gradient-based MOO methods makes it hard to incorporate all methods, so some effective methods may be missing; (2) gradient-based solvers may fail for problems with a number of local optimas.

Future Workincludes (1) maintaining a user and development community to address issues and (2) adding newly published methods as quickly as possible.

Figure 6: Training process for generating predicted Pareto solutions using different PSL solvers on MO-MNIST problem.

Figure 7: HV curves on MOBO problem. Results are averaged on five random seeds. Reference point to calculate HV : [1.2, 1.2].

## Acknowledge

The work described in this paper was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China [GRF Project No. CityU 11215622].

## Appendix A Appendix

### Full name and notation tables

This section lists the full names of optimization methods and terms for clarity (Table 10) and provides notation in Table 11.

### Aggregation functions

Aggregation function convert an MOP into a single-objective optimization problem under a specific preference vector \(\). Some popular aggregation functions are:

1. **COSMOS**: \[g_{}^{ cosmos}()=^{}()-^{}()}{\|\|\| ()\|},\] (3) where \(\) is a positive weight factor to align the objective vector \(()\) with the preference vector \(\).
2. **Linear scalarization (LS)**: \[g_{}^{ LS}()=_{i=1}^{m}_{i}L_{i}().\] (4)
3. **Tchebycheff (Tche)**: \[g_{}^{ Tche}()=_{1 i m}\{_{ i}(L_{i}()-z_{i})\},\] (5) where \(\) is a reference point, usually set as the nadir point the minimal value in each objective. Modified Tchebycheff is the same as the original one by simply choosing \(_{i}^{}\) to be \(1/_{i}\), \(g_{}^{ mTche}()=g_{^{}}^{ Tche }()\).
4. **Smooth Tchebycheff (STche)**: \[g_{}^{ STche}()=(_{i=1}^{m} (h_{i}(L_{i}()-z_{i}))).\] (6) The Smooth Tchebycheff function uses a relaxed Smooth \(\) operator. The advantage of this approach is that \(g_{}^{ STche}()\) becomes a smooth function if each objective function \(L_{i}()\) is smooth, unlike the non-Smooth \(g_{}^{ Tche}()\). Smooth functions generally have faster convergence rate compared to non-Smooth ones. Similarly, we can define the Smooth modified Tchebycheff function.
5. **Penalty-Based Intersection (PBI):** \[g_{}^{ PBI}()=\| }_{i=1}^{m}_{i}L_{i}()}_{d_{1}}+()-}{\|\|}\|}_{d_{2}},\] (7) where \(\) is a positive weight factor that encourage a objective to align with a preference vector \(\).
6. \(p\)**-norm**: \[g_{}^{ pmorm}()=\|()-\|_{p}.\] (8) The symbol \(\) denotes the element-wise product between two vectors.

7. **Augmented Achievement Scalarization Function (AASF)**: \[g_{}^{}()=g_{}^{}( )+ g_{}^{}(),\] (9) where \(\) is small positive coefficient, which is usually set as 0.1. Contour curves for this function for a bi-objective case can be found in the LibMOON Doc6. 
### Metrics

Metrics used in LibMOON can be categorized into two groups. The first group evaluates the quality of a _set_ of solutions \(=\{^{(1)},,^{(K)}\}\), with specific metrics such as IGD and FD relying on the known Pareto front for accuracy. The second group of metrics assesses the quality of _individual_ solutions \(\) when a preference vector \(\) is provided.

Group 1: Metrics for a set of solutions.

1. Hypervolume (HV) (\(\)) : This metric evaluates both the convergence to the PF and the diversity of solutions. A low HV value indicates poor convergence, while high HV values

   Short Name & Full name \\   MOP & Multiobjective Optimization Problem \\ SOP & Singleobjective Optimization Problem \\ MOO & MultiObjective Optimization \\ MOEA & MultiObjective Evolutionary Algorithm \\ MOBO & MultiObjective Baysian Optimization \\ PSL & Pareto Set Learning \\ PS & Pareto Set \\ PF & Pareto Front \\ “exact” Pareto solution & The corresponding Pareto objective aligns with a given preference vector \\  ES & Evolutionary strategy \\ BP & Backward propagation \\  PMTL  & Pareto Mults-Task Learning \\ MOO-SVGD  & MultiObjective Optimization Stein Variational Gradient Descent \\ EPO  & Exact Pareto Optimization \\ PMGDA  & Preference based Multiple Gradient Descent Algorithm \\ Agg-LS  & Aggregation function with Linear Scalarization \\ Agg-PBI  & Aggregation function with Penalty Based Intersection \\ Agg-Tche  & Aggregation function with Tchebycheff scalarization \\ Agg-mTche  & Aggregation function with modified Tchebycheff scalarization \\ Agg-COSMOS  & Aggregation function with COSMOS scalarization \\  RE problems & Realworld problems \\   

Table 10: Short name to full name table

   Notation & Meaning \\   \(\) & The decision variable of an MOP. \\ \(\) & The decision variable of a Pareto set model. \\ \(m\) & Number of objectives. \\ \(n\) & Number of decision variables. \\ \(K\) & Number of finite Pareto solutions. \\ \(_{i}\) & Coefficients of objective functions. \\ \(\) & A preference vector. \\   

Table 11: Notations used in this paper imply better performance. The hypervolume is calculated as the volume dominated by at least one solution in the set \(\) with respect to a reference point \(\): \[_{}()=(^{} ,^{}).\]
2. Inverted Generational Distance (IGD) : IGD measures the average distance between points in a reference set \(\) and the nearest solutions in the set \(\): \[()=|}(_{i=1}^{| |}_{^{}}(^{(i)},^{})^{2} )^{1/2}.\]
3. Fill Distance (FD) : This metric calculates the covering radius of a set of solutions \(\), defined as the maximum minimum distance from any point in the reference set \(\) to the nearest solution in \(\): \[()=_{^{}}_{^{ }}(,^{}).\] (10)
4. Minimal Distance (\(l_{}\)): This metric captures the smallest pairwise distance among all objectives: \[l_{}=_{1 i<j K}(^{(i)},^{(j)})\] where \(()\) denotes the Euclidean distance.
5. Smooth Minimal Distance (\(sl_{}\)): This metric is a "smooth-min" version of the minimal distance function, defined as: \[sl_{}=-(_{1 i<j K}(- h(^{(i)},^{(j)}))).\] (11)
6. Spacing: This metric measures the standard deviation of the minimal distances from one solution to others, with lower values indicating a more uniform distribution of objective vectors: \[=_{i=1}^{K}(d_{i}-)^{2},= _{i=1}^{K}d_{i}, d_{i}=_{1 i j K}( {y}^{(i)},^{(j)}).\] (12)
7. Span: This metric evaluates the range (span) of solutions in their minimal dimension, defined as: \[=_{1 i m}_{1 k<l K}|y_{i}^{(k)}-y_{i}^{( l)}|.\] (13)

Group 2: Metrics for individual solutions.

1. Penalty-based Intersection (PBI): This metric is a weighted sum of two distance functions \(d_{1}\) and \(d_{2}\), given by \(=d_{1}+ d_{2}\), where \[d_{1}=-,}{\|\|}, d_{2}=\|-(d_{1}+)\|.\] (14)
2. Inner Product (IP): This metric measures the alignment of the objective vector \(\) with the preference vector \(\): \[=,.\] (15)
3. Cross Angle (\(\)): For bi-objective problems, this metric measures the angular difference between the objective vector and the preference vector: \[=\|(y_{2}/y_{1})-(_{2}/_{1})\|.\] (16)

Those metrics are summarized in Table 12 and also can be found in the LibMOON document.

### GPU acceleration

We evaluate LibMOON performance on Pareto set learning for the MO-MNIST problem across various platforms (CPU, RTX 3080, 4060, 4090). Running times are detailed in Table 13 and visualized in Figure 8. The table and figure show a significant reduction in time (about one-third) when using a personal GPU compared to a CPU. The RTX 4090 further reduces time by approximately 25% compared to the RTX 4060.

### License, usage, and code dependence

The license used for Adult/Compas/Credit follows Creative Commons Attribution 4.0 International (CC BY 4.0), Database Contents License (DbCL) v1.0, and CC0: Public Domain, respectively. For academic use of LibMOON, please cite our paper or GitHub. Commercial use requires author permission.

  
**Platform** & **MO-MNIST** & **MO-Fashion** & **Fashion-MNIST** \\ 
**CPU** & 43.43 & 44.45 & 46.45 \\
**RTX 4060 (8G)** & 14.72 & 13.21 & 12.43 \\
**RTX 3080 (10G)** & 7.88 & 7.16 & 7.17 \\
**RTX 4090 (24G)** & 3.27 & 3.27 & 3.27 \\   

* We run all datasets for 100 epochs using 3M parameters on a 13th Gen Intel(R) Core(TM) i9-13900HX CPU.

Table 12: Supported metrics.

Figure 8: Running time for Pareto set learning on the MO-MNIST problem using different devices using 3M parameters.

Some part codes of LibMOON follows (1) COSMOS 7, (2) PHN 8, and (3) HVGrad 9.