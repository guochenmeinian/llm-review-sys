# Blind Image Restoration via Fast Diffusion Inversion

Hamadi Chihaoui Abdelhak Lemkhenter Paolo Favaro

Computer Vision Group, Institute of Informatics, University of Bern, Switzerland

{hamadi.chihaoui,abdelhak.lemkhenter,paolo.favaro}@unibe.ch

###### Abstract

Image Restoration (IR) methods based on a pre-trained diffusion model have demonstrated state-of-the-art performance. However, they have two fundamental limitations: 1) they often assume that the degradation operator is completely known and 2) they alter the diffusion sampling process, which may result in restored images that do not lie onto the data manifold. To address these issues, we propose Blind Image Restoration via fast Diffusion inversion (BIRD) a blind IR method that jointly optimizes for the degradation model parameters and the restored image. To ensure that the restored images lie onto the data manifold, we propose a novel sampling technique on a pre-trained diffusion model. A key idea in our method is not to modify the reverse sampling, _i.e._, not to alter all the intermediate latents, once an initial noise is sampled. This is ultimately equivalent to casting the IR task as an optimization problem in the space of the input noise. Moreover, to mitigate the computational cost associated with inverting a fully unrolled diffusion model, we leverage the inherent capability of these models to skip ahead in the forward diffusion process using large time steps. We experimentally validate BIRD on several image restoration tasks and show that it achieves state of the art performance. Project page: https://hamadichihaoui.github.io/BIRD.

## 1 Introduction

Recent advances in generative learning due to the development of diffusion models [7; 18] have led to models capable of generating detailed and realistic high-resolution images. In addition to their data generation capabilities, these models also provide an implicit representation of the distribution of the data they train on, which can be used for other applications, such as image restoration (IR). Indeed, several approaches have emerged to solve inverse problems using pre-trained diffusion models [8; 11; 21]. Those approaches start from a random noise vector as the diffusion input and introduce a projection after each diffusion reverse step to enforce the consistency with the corrupted image. As shown by Chung  this procedure alters the original diffusion sampling process, and may cause the generated image to leave the data manifold during the iterative denoising process, which ultimately results in unrealistic image samples. Moreover, most of these methods are non-blind as they assume to have full knowledge of the degradation model, which is not practical in real-world applications.

To overcome all these challenges, we propose a novel blind image restoration method that jointly optimizes the degradation model parameters and the restored image only at test time (and thus separately for each new image). We call this method BIRD, which stands for Blind Image Restoration via fast Diffusion inversion. Since BIRD does not need to pre-train a model for the degradation operator, it can be used immediately on a wide range of IR tasks such as Gaussian deblurring, motion deblurring, super-resolution and denoising (see Figure 2). In this work, we show that having a strong image prior and ensuring that the restored image never leaves the data manifold during the reconstruction process are fundamental properties to generalize to a wide range of image degradation problems. As shown in Figure 1, BIRD (see (f) to (i)) reconstructs realistic images at each iteration, while BlindDPS (see (b) to (e)) may initially reconstruct non realistic images. We observe that eventhough we have a more primitive blur reconstruction procedure (we directly regress the motion blur kernel), the reconstructed image is still more similar to the ground truth one (see column (1)) than the final image estimate from BlindDPS (see (e) top), which uses a quite accurate blur kernel estimate (see (e) bottom). This speaks of the importance of defining a strong image prior first and foremost.

To define the image prior, BIRD uses a pre-trained Denoising Diffusion Implicit Model (DDIM)  and exploits the existing deterministic correspondence between noise and images in DDIMs by casting the inverse restoration problem as a latent estimation problem, _i.e_., where the latent variable is the input noise to the diffusion model. In contrast to prior work, we do not alter the reverse sampling, _i.e_., all the intermediate latents, once an initial noise is sampled. To then apply our image prior, we cast the IR task as an alternating optimization between the unknown restored image and the unknown parameters of the degradation model. However, a direct implementation of the optimization procedure in the case of a diffusion model used as a black box would be computationally demanding and ultimately impractical. To mitigate the substantial computational cost associated with inverting a fully unrolled diffusion model, we leverage, for the first time in IR tasks, the inherent capability of these models to skip ahead in the forward diffusion process using arbitrarily large time steps. We show that our method is able to achieve state of the art performance across a wide range of blind image restoration tasks. Our main contributions can be summarized as follows

1. BIRD is the first to cast an IR task as a latent optimization problem (where only the initial noise is optimized) in the context of diffusion models; our optimization procedure aims at generating images that lie on the data manifold at every iteration;
2. BIRD is computationally efficient; we propose a fast diffusion model inversion in the context of image restoration, without fine-tuning nor retraining;
3. We achieve state of the art results on CelebA and ImageNet for different blind IR tasks, such as Gaussian and motion deblurring, super-resolution, and denoising.

## 2 Related Work

Blind and non-blind image restoration methods.An image restoration task is often cast as an inverse problem, where the degradation model is explicitly known. For example, in image deblurring the degradation model can be described by a convolution with a blur kernel. Methods that explicitly assume the exact knowledge of the blur kernel are called _non-blind_ methods. More general methods that assume only knowledge of the type of degradation (_e.g_., blurring), but not the values of its parameters, are instead called _blind_. Some recent examples of non-blind methods are  and DPS .  points out that relying on an iterative procedure consisting of reverse diffusion steps and a projection-based consistency step runs the risk of stepping outside of the data manifold, a risk they mitigate using an additional correction term. DPS  proposes a more general framework to handle both the non-linear and noisy cases. DDNM  proposes a zero-shot framework for

Figure 1: Blind image deblurring with unknown motion blur. (a): blurry input image. From (b) to (e): The top row shows the predictions of BlindDPS  as the iterations increase; the bottom row shows the corresponding estimated blur kernel. From (f) to (i): Same estimates as in (b) to (e), but obtained from BIRD, our proposed method. (j) is the ground truth sharp image (top) and ground truth blur kernel (bottom). Notice that BlindDPS  trains a score-based model for the kernel estimation, while BIRD does not use any training and can adapt to any new kernel directly at test time. BIRD yields always natural images at every iteration of the reconstruction procedure. Finally, notice that despite recovering a suboptimal blur kernel, the image reconstructed with BIRD is more similar to the ground truth image than with BlindDPS thanks to the robustness of our image generation procedure.

IR tasks based on the range-null space decomposition. The method works by refining only the null-space contents during the reverse diffusion process, to satisfy both data consistency and realness. Some recent examples of blind methods are GDP  and BlindDPS . GDP leverages DDPM and solve inverse problems via hierarchical guidance and a patch-based method. BlindDPS proposes an extension of  to the case of blind deblurring. They train a score-based diffusion model for the blur operator. At test-time, they jointly optimize for both the sharp image and blur operator by running the reverse diffusion process. However, training a model for each new degradation operator can be time-consuming. Fast Diffusion EM  proposes a method for blind image deblurring. It applies the Expectation-Maximization (EM) algorithm after each reverse diffusion step to jointly update the image latent and blur kernel. Gibbsdrm  extends DDRM  to the blind case by adopting a Gibbs sampler to enable efficient sampling from the posterior distribution. In contrast to these works, in BIRD we introduce a blind image restoration method based on a novel diffusion inversion for DDIM. Our method is computationally efficient, as it requires only a few reverse diffusion steps, and generates realistic samples by only estimating the initial noise.

**Methods based on GAN inversion.** Since our proposed method is based on inverting a diffusion process, we also briefly review related work in the literature and discuss how it differs from our approach. Because Generative Adversarial Networks (GANs) were among the best image generation models, a number of methods  inverts pre-trained GANs to solve image restoration problems. DGPGAN  performs the GAN inversion on a single new corrupted image. The authors shows that the inversion is not easily obtainable just with the direct optimization of the latent input to the frozen GANs model. Thus, they propose to also fine-tune the (unfrozen) GAN, while optimizing for the latent vector.  instead train an encoder to invert a pre-trained GANs on a

Figure 2: We demonstrate BIRD on several **blind** image restoration problems (_i.e._, when the values of the degradation model are unknown): Gaussian deblurring, motion deblurring, superresolution (SR) (it includes additional Gaussian blur) and denoising with an unknown noise distribution. BIRD is applicable to a single degraded image and does not require re-training or fine-tuning of the prior model (we use a diffusion model). Although some of the generated degraded images use Gaussian blur, BIRD recovers a generic blur kernel (without making any Gaussianity assumption).

dataset of corrupted images (through masking). At test time they directly apply the trained encoder and the GANs on a new corrupted image without further training. BIRD shares the aim of inverting a generative model with the above prior work. However, as demonstrated in the literature for inverting GANs models, the inversion of generative models is far from a straightforward task. Moreover, the inversion of GANs and diffusion models are fundamentally different in nature. For example, while GANs generate samples in "one forward pass" diffusion models require multiple (denoising) steps. Also, all IR methods based on GAN inversion either optimize the intermediate layers of the generator , train an auxiliary network (_e.g._, an encoder), or fine-tune the pre-trained GAN network. In our method, the diffusion model is not fine-tuned/trained.

## 3 Image Restoration via BIRD

In this section, we introduce the classic Bayesian formulation of inverse problems applied to a single degraded image. An important component in this formulation is the characterization of the image prior, which we do via DDIM diffusion models.

### Problem Formulation

Image restoration (IR) can be cast as a Maximum a Posteriori (MAP) optimization problem 

\[=*{arg\,min}_{x} p(y|x)+ p(x),\] (1)

where \(^{N_{x} M_{x}}\) is the restored image of size \(N_{x} M_{x}\) pixels, \(y^{N_{y} M_{y}}\) is the degraded image of size \(N_{y} M_{y}\) pixels, where \(p(y|x)\) is the so-called _likelihood_ and \(p(x)\) the _prior_ distribution. Inverse problems describe IR tasks with a degradation operator \(H_{}:^{N_{x} M_{x}}^{N_{y} M_ {y}}\) and a noise image \(n^{N_{y} M_{y}}\), such that the observed degraded image \(y\) can be written as

\[y=H_{}(x)+n.\] (2)

\(\) is a vector with all the parameters that define the operator \(H_{}\). IR tasks such as image denoising, deblurring and super-resolution can all be described using specific choices of \(H_{}\). For instance, in the case of image deblurring, the \(H_{}\) operator can be described as a convolution with a blur kernel \(k\) such that \(H_{}(x) k*x\), where \(*\) denotes the convolution operation. In the blind deblurring problem, one assumes that \(H_{}\) takes the form of a convolution, but without knowing its parameters \(\), which, in this case, are the values of the true blur kernel \(k\). Thus, we also need to estimate the parameters \(\) as part of the optimization procedure. Only in the special case of image denoising we do use \(H_{}\) as the identity function. By assuming that the noise \(n\) is zero mean Gaussian in the MAP formulation, one can rewrite eq. (1) as

\[,=*{arg\,min}_{x^{N_{x} M_ {x}},}\|y-H_{}(x)\|^{2}+(x),\] (3)

where \((x)\) is also called a _regularization_ term, and \(>0\) is a coefficient that regulates the interplay between the likelihood and the prior. We define \(_{x}^{N_{x} M_{x}}\) as the (compact) set of degradation-free (realistic) images and we propose employing a formulation that implicitly assumes a uniform

Figure 3: Illustration of our proposed accelerated image sampling of the pre-trained DDIM. (a) initial noise \(x_{T}(0,)\) (\(T=1000\)). (b), (c), (d), (e) and (f) are samples \(x_{0}\) generated using \((x_{T}, t)\) with \( t=100,50,20,1\) respectively. Notice how the generated images are all realistic regardless of the choice of the step size \( t\).

prior \(p(x) p_{U}(x)\) on \(_{x}\). That is, \((x)=-(p_{U}(x))=-(_{_{x}}(x))\), where \(c\) is a normalizing constant and \(_{_{x}}(x)\) is 1 if \(x\) is in the support of \(_{x}\) and 0 otherwise.

This results in the following simplified formulation

\[,=*{arg\,min}_{x_{x},}\|y-H_{}( x)\|^{2}.\] (4)

To ensure that \(x_{x}\), we parameterize \(x\) via the initial noise \(z\) of a pre-trained diffusion model \(g:^{N_{x} M_{x}}^{N_{x} M_{x}}\) trained by mapping noise samples from the high-density region of the standard Normal distribution (that we denote \(_{z}\)) to the domain of degradation-free (realistic) images \(_{x}\). In other words, we assume that \(_{x}=\{g(z)\}_{z_{z}}\). The optimization objective eq. (4) becomes then

\[,=*{arg\,min}_{z_{z},}\|y-H_{} (g(z))\|^{2},\] (5)

with \(=g()\). In high dimensions, \(M_{x}}\|z\|^{2}[zz^{}]=(z)=1\) as \(N_{x}M_{x}\). In fact, most of the density of a high-dimensional Normal random variable is around \(\|z\|^{2}=N_{x}M_{x}\)[12; 20]. Therefore, we propose to approximate the original problem (3) with

\[,=*{arg\,min}_{z:\|z\|^{2}=N_{x}M_{x},}\|y- H_{}(g(z))\|^{2}.\] (6)

### An Efficient Diffusion Inversion

In problem (6), we implement the function \(g\) by adopting a pre-trained diffusion model. We choose the Denoising Diffusion Implicit Model (DDIM)  and set it as a fully deterministic diffusion process. To solve problem (6), we propose an optimization-based iterative procedure. We jointly estimate a realistic image \(x\) (_i.e._, with a high \(p(x)\)) and the forward degradation model \(H_{y}\) such that \(H_{}(x) y\). In order to find \(x\), we explicitly exploit the correspondence between image samples \(x\) and their associated initial latent image \(z\) in DDIMs, in contrast to the mappings used in prior work [8; 11; 21]. Thus, we aim to find the initial noise sample \(z\) that can generate the image \(x\) when applied to DDIM. To keep the notation consistent with the DDIM formalism, we denote images \(x\) with \(x_{0}\) and the samples \(z\) with \(x_{T}\), where \(T\) is the number of iterations in the diffusion model. To make our presentation self-contained, we briefly revise the notation and notions of diffusion models.

#### 3.2.1 Background: Denoising Diffusion Probabilistic and Implicit Models

Denoising Diffusion Probabilistic Models (DDPM)  leverage diffusion processes in order to generate high quality image samples. The aim is to reverse the forward diffusion process that maps images to noise, either by relying on a stochastic iterative denoising process or by learning the explicit dynamics of the reverse process, _e.g._, through an ODE . More precisely the forward diffusion process maps an image \(x_{0} p(x)\) to a zero-mean Gaussian \(x_{T}(0,)\) by generating intermediate images \(x_{t}\) for \(t[1,T]\) which are progressively noisier versions of \(x_{0}\). DDPM  adopts a Markovian diffusion process, where \(x_{t}\) only depends on \(x_{t-1}\). Given a non-increasing sequence \(_{1:T}(0,1]\), the joint and marginal distributions of the forward diffusion process are described by

\[q(x_{1:T}|x_{0})=_{t=1}^{T}q(x_{t}|x_{t-1}),q(x_{t}|x_{t-1})= }x_{t-1},1-_{t},\] (7)

which implies that we can sample \(x_{t}\) simply by conditioning on \(x_{0}\) with \(_{t}=_{s t}_{s}\) via

\[q(x_{t}|x_{0})=_{t}}x_{0},(1- _{t}).\] (8)

To invert the forward process, one can train a model \(_{}\), with parameters \(\), to minimize the objective

\[_{}\ \ _{t(0,1);x_{0} q(x); (0,)}\|-_{}( _{t}}x_{0}+_{t}},t)\|^{2}.\] (9)

Given the initial noise \(x_{T}\), image samples \(x_{0}\) are obtained by iterating for \(t[1,T]\) the denoising update

\[x_{t-1}=}}x_{t}-_{}(x_{t},t) )}{_{t}}}+_{t}z,\] (10)

with \(z(0,)\), and \(_{t}^{2}=_{t-1}}{1-_{t}}(1-_{t})\).

The authors of  point out that the quality of generated images improves as the total number of denoising steps \(T\) increases. Thus, the inference loop using eq. (10) becomes computationally expensive. To reduce the computational cost, they propose to use instead

\[q(x_{1:T}|x_{0})\ =\ q(x_{T}|x_{0})_{t=2}^{T}q(x_{t-1}|x_{t},x_{0}),\] (11)

a Denoising Diffusion Implicit Model (DDIM) , which foregoes the Markovian assumption in favor of a diffusion process where \(q(x_{T}|x_{0})=_{T}}x_{0},(1-_ {T})\) and

\[q(x_{t-1}|x_{t},x_{0})=_{t-1}}x_{0}+ _{t-1}-_{t}^{2}}.-_{t} }x_{0})}{_{t}}},_{t}^{2}.\] (12)

Figure 4: Reconstruction results using BIRD on samples from CelebA and ImageNet validation datasets. The PSNR mean and standard deviation are computed over 10 runs.

When \(_{t}=0\) for all \(t\), the diffusion process is **fully deterministic**. This means that when we start from the same noise sample \(x_{T}\) we obtain the same generated image sample. Given \(x_{t}\), one can first predict the denoised observation \(_{0}\), which is a prediction of \(x_{0}\) given \(x_{t}\)

\[_{0}=-_{t}}_{}(x_{t},t))}{ _{t}}}.\] (13)

Then, we can predict \(x_{t-1}\) from \(x_{t}\) and \(_{0}\) using eq. (12) by setting \(_{t}=0\)

\[x_{t-1}=_{t-1}}_{0}+_{t-1}}\] (14)

with \(=-_{t}}_{0}}{_{t}}}\) a direction pointing to \(x_{t}\).  shows that this formulation allows DDIM to use fewer time steps at inference by directly predicting \(x_{t-}\) with \(>1\), which results in a more computationally efficient process using

\[x_{t-}=_{t-}}_{0}+_{t- }}.\] (15)

#### 3.2.2 Accelerated DDIM Sampling

As previously mentioned, we adopt DDIMs as our pre-trained generative process. Here, we explore the advantage of DDIMs of allowing fewer steps than in other diffusion models during the sampling process, as discussed in section 3.2.1. We start from \(x_{T}(0,)\). Instead of denoising \(x_{T}\) iteratively for all the steps used in the pre-training, we make larger steps by using intermediate estimates of \(_{0|t}\) from \(x_{t}\) using the pre-trained DDIM model \(_{}\) via

\[_{0|t}=-_{t}}_{}(x_{t},t)} {_{t}}}.\] (16)

We define the hyper-parameter \( t\) that controls the number of denoising steps, and we can directly jump to estimate \(x_{t- t}\) from \(_{0|t}\) and \(x_{t}\) using

\[x_{t- t}=_{t- t}}_{0|t}+_{t- t}}.-_{t}}_{0|t}}{_{t}}}.\] (17)

A larger step size \( t\) allows us to favor speed, while a lower one favors precision or fidelity. This iterative procedure, which we summarize in Algorithm 2, results in an estimate of \(x_{0}\) that is differentiable in \(x_{T}\). We denote by \((., t)\) the mapping function between \(x_{T}\) and \(x_{0}\) that is parameterized with the step size \( t\) (this is essentially our choice of \(g\) in problem (6)). Figure 3 shows sampled images \(x_{0}\) using different \( t\) starting from the same initial noise \(x_{T}\) through \((., t)\).

Figure 5: Qualitative comparisons of \(4\) SR on ImageNet. Each column shows two examples. From left to right: input low-resolution images, GDP , BlindDPS , BIRD (our method), and the ground truth (GT) high-resolution and noise-free image.

#### 3.2.3 BIRD: Blind Image Restoration via Fast Diffusion Inversion

BIRD performs an iterative minimization of problem (6) with a running index \(k\), which we append as a superscript to the estimated unknowns. It starts from an initial noise instance \(x_{T}^{0}(0,)\) and a parametric degradation model \(H_{^{0}}\), where \(^{0}\) is randomly initialized. At each iteration \(k\), we first compute our estimate of the clean image \(x_{0}^{k}\) by mapping \(x_{T}^{k}\) through \((., t)\)

\[x_{0}^{k}=(x_{T}^{k}, t).\] (18)

We then compute the restoration loss

\[_{}(x_{0}^{k},H_{})=\|y-H_{}(x_{0}^{k})\|^{2}.\] (19)

Given an initial noise \(x_{T}^{k}\) and \(H_{^{k}}\), the optimization iteration is simply derived through gradient descent with a learning rate \(\)

\[x_{T}^{k+1}=x_{T}^{k}-_{x_{T}}_{}(x_{0}^{k},H_ {^{k}})^{k+1}=^{k}-_{} _{}(x_{0}^{k},H_{^{k}}).\] (20)

To impose the normalization constraint on \(x_{T}\) we set its Euclidean norm to \(\|x_{T}\|=M_{x}}\) via

\[x_{T}^{k+1}=^{k+1}}{\|x_{T}^{k+1}\|}M_{x}}.\] (21)

After \(N\) iterations, or when \(_{}(x_{0}^{N},H_{^{N}})\) becomes small enough, we deem that BIRD has converged. The restored image \(_{0}\) is then generated by \(_{0}=(x_{T}^{N}, t)\), which always ensures that \(_{0}\) is within the manifold of realistic images, as already shown in Figure 3. Moreover, in Figure 4 we show two examples of the reconstruction with \(H_{}(x)=x\) and with \(y\) un-corrupted noise-free images from the validation dataset of ImageNet  and CelebA . We summarize this iterative procedure in Algorithm 1.

## 4 Experiments

### Image Restoration Tasks

We showcase BIRD on four different image restoration tasks: Gaussian and motion deblurring, denoising, and image super-resolution (SR). For Gaussian deblurring, we use an anisotropic Gaussian

Figure 6: Qualitative comparisons of Gaussian deblurring on CelebA. From left to right: input blurry image, GDP , BlindDPS , BIRD (our method), and the ground truth sharp image.

Figure 7: Qualitative comparisons of image denoising on CelebA. From left to right: input noisy image, GDP , BlindDPS , BIRD and the original image (GT).

[MISSING_PAGE_FAIL:9]

shows how BIRD results in a significantly faster execution. Despite being an iterative method, BIRD has a reasonable runtime making it a practical IR method. The reported speed uses \( t=100\).

### Limitations and Broader Impacts

We have evaluated our method on degradation operators with a given explicit parametrized form (albeit with unknown parameters). It would be interesting to further investigate the use of BIRD on problems where an explicit form of the degradation operator is difficult to have, such as in image deraining and dehazing. In terms of broader impacts, BIRD leverages pre-trained denoising diffusion models with both their advantages and pitfalls. It takes advantage of their strong prior, but may also be affected by their data-induced biases.

## 5 Conclusion

We have introduced BIRD, a novel robust, accurate and fast framework for solving general blind image restoration tasks by using pre-trained diffusion generative models as learned priors. Our method exploits the deterministic correspondence between noise and images in DDIM by casting the inverse restoration problem as a latent estimation problem. Our framework does not require training networks on specific task, but can instead be directly applied to new images and new degradation models. We leverage the capability of DDIM to skip ahead in the forward diffusion process and provide an efficient diffusion inversion in the context of image restoration. We demonstrate that BIRD achieves state of the art performance on blind image restoration tasks including Gaussian deblurring, motion deblurring, super-resolution and denoising.

**Acknowledgements.** We acknowledge the support of the SNF project number 200020_200304.