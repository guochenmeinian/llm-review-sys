# Gated Inference Network: Inference and Learning State-Space Models

Hamidreza Hashempoor

Seoul National University

Department of Electrical and Computer Engineering

hamidreza.hashemp@snu.ac.kr

&Wan Choi

Seoul National University

Department of Electrical and Computer Engineering

wanchoi@snu.ac.kr

###### Abstract

This paper advances temporal reasoning within dynamically changing high-dimensional noisy observations, focusing on a latent space that characterizes the nonlinear dynamics of objects in their environment. We introduce the _Gated Inference Network_ (GIN), an efficient approximate Bayesian inference algorithm for state space models (SSMs) with nonlinear state transitions and emissions. GIN disentangles two latent representations: one representing the object derived from a nonlinear mapping model, and another representing the latent state describing its dynamics. This disentanglement enables direct state estimation and missing data imputation as the world evolves. To infer the latent state, we utilize a deep extended Kalman filter (EKF) approach that integrates a novel compact RNN structure to compute both the Kalman Gain (KG) and smoothing gain (SG), completing the data flow. This design results in a computational cost per step that is linearly faster than EKF but introduces issues such as the exploding gradient problem. To mitigate the exploding gradients caused by the compact RNN structure in our model, we propose a specialized learning method that ensures stable training and inference. The model is then trained end-to-end on videos depicting a diverse range of simulated and real-world physical systems, and outperforms its counterparts --RNNs, autoregressive models, and variational approaches-- in state estimation and missing data imputation tasks.

## 1 Introduction

A state-space model is a type of graphical model that effectively represents noise-afflicted data . Typically, the objective is to conduct inference, which involves obtaining accurate estimates of the posterior distribution of latent states or noise-free measurements. In videos, inferring the state space presents a complex challenge owing to the high dimensionality of noisy observations, which only offer partial information about the states. Previous methods have proposed various inference approaches such as sampling , variational inference , or belief propagation . Within the framework of a hidden Markov process, classical methods like the celebrated Kalman filter (KF) and smoother [5; 6], along with their extensions like EKF and UKF, [7; 8] have been employed to address the posterior inference problem. However, the reliance of these methods on accurate knowledge of the underlying dynamics, coupled with computationally intensive matrix inversions, poses challenges in scalability to high-dimensional latent spaces.

To address these issues, this paper distinguishes between the sensory observation and its dynamics by disentangling two representations: a transformed observation \(_{t}\) obtained by mapping the original sensory observation \(_{t}\) through a nonlinear function modeled by neural networks, and the latent state space \(_{t}\) describing the dynamics of \(_{t}\) at time step \(t\). To infer high dimensional state space (dynamics) \(_{t}\), we introduce filtering and smoothing techniques that build upon classical EKF updates but incorporate flexible function estimators without relying on a constrained graphical model. We model temporal dynamics with a linearized Gaussian SSM, which is adapted to accommodate complex dynamics. To address non-linearity and the multiplicity of dynamics, we learn multiple transition and emission matrices, each modeling a unique dynamical scenario. Then, the weight of each matrix during inference is determined by the past state \(_{t-1}\) through a neural network. To prevent mode collapse and ensure the system's ability to capture diverse dynamics, we introduce a loss term proportional to the KL divergence of the transition matrices during training. This design enables our model to handle various state scenarios, similar to approaches found in the switching linear dynamics systems (SLDS) literature . Unlike EKF, which requires precise characterization and modeling of the underlying dynamics, we operate under the assumption that noise statistics and the underlying physical dynamics of SSM are entirely unknown.

The main drawback of the EKF is that it takes \((n^{3})\) time per step, because we need to invert the posterior covariance matrix with size of \(n\). This makes the method slow to use. Moreover, we identify the computation of the KG and SG in the (extended) KF as critical components that rely on noise statistics and domain knowledge. In this paper, we efficiently model KG and SG using GRU cells, bypassing the need for matrix inversion in the KF flow. Consequently, the GIN algorithm achieves a time complexity of \((^{2}n^{2})\) per step, making it linearly faster than EKF. To capitalize on the sparsity of the covariance matrix, we employ a convolutional approach that further reduces the size of \(n\) relative to \(\), where \(0<<1\). However, the nonlinear structure of GRU cells can lead to gradient explosion , a phenomenon that occurs when the dynamics undergo significant changes as GRU parameters traverse bifurcation points  during the learning process. To address this issue, we propose a learning method based on an analysis of GRU cell dynamics. This method aims to prevent parameter values from reaching bifurcation points by stabilizing the dynamics of GRU cells, thereby addressing the issue of gradient explosion.

To summarize, our primary contribution is a novel algorithm designed for the recursive inference of SSMs with arbitrary nonlinear (and possibly non-Gaussian) emission and transition models, with high-dimensional noisy stimuli observation. This algorithm utilizes a linearized Gaussian dynamics approach, with parameter estimation conducted through neural networks. This means that we can apply the recursive Bayesian updates, akin to the Kalman filter and Kalman smoother. We introduce a likelihood for inferring the states (dynamics) and another likelihood for inferring the high-dimensional images (of video). The objective is maximized in a supervised manner, depending on the task. We propose learning schemes for GRU cells to address issues related to gradient explosion and instability. Finally, we introduce a loss term proportional to the KL divergence of the learned transition matrices to prevent the system from becoming stuck in mode collapse.

To substantiate our claims, we conduct five experiments. First, we simulate a nonlinear dynamic system using the pendulum sequence video, a common benchmark in this literature, to demonstrate our model's ability to infer both dynamics and images. Second, we introduce a more challenging experiment of a simulated nonlinear double pendulum, where the video sequence is heavily distorted with noise, showcasing our model's resilience of dynamics estimation and image imputation to noisy observations. Third, we present a switching dynamics irregular bouncing ball experiment to illustrate our model's ability to handle multiple dynamic scenarios. Fourth, we perform visual odometry using the KITTI dataset, demonstrating the practical applicability of our methods in real-world scenarios. Finally, we assess the effectiveness of our proposed gradient explosion handling scheme by evaluating convergence across various simulation seeds.

## 2 Related Works

EKF and UKF represent early extensions of the original Kalman filter, allowing for nonlinear transitions and emissions. These methods, categorized as model-based (MB) algorithms, rely on precise knowledge and modeling of the underlying dynamics within a fully characterized SSM. Consequently, the performance of these MB methods is heavily contingent on the accuracy of domain knowledge and model assumptions. Recent approaches, such as BackpropKF  and SIN , perform EKF in the latent state using deep encoders for feature extraction. However, they face similar limitations as EKF, including computational complexity and scalability. To address these issues, a common approach involves considering a diagonal covariance matrix in the KF flow as in  and . However, we aim to find a richer approximation to the posterior.

A significant body of work, including Variational Auto-Encoders (VAE) , Embed to Control (E2C) , and Importance Weighted VAE (IWVAE) , integrates deep learning with variational inference (VI), but lacks memory cells and recurrent structures for handling imputation tasks. To address this, EM-based VI approaches like Structure VAE (SVAE) , Kalman VAE (KVAE) , Disentangled VAE (DVAE) , Extended KVAE (EKVAE) , Robust VAE , and Markovian VAE (MVAE)  use original KF equations for filtering and smoothing. However, they cannot directly optimize states (dynamics), as noted in RKN  and CRU . Classical memory networks like LSTMs , GRUs , and simple RNNs  infer latent states but fail to provide insights into uncertainties and dynamics.

LatentNet , KalmanNet  and SSI-SSM  utilize GRU in their structures for state updates, similar to the parameterization used in the GIN. However, these models typically necessitate access to complete or partial dynamics information, i.e. they are MB, and their reliance on vanilla GRU cells can cause instability of the SSM. Liu et al.  proposes a disentanglement model for audio data, which shares similarities with the GIN. However, their parameterization and objectives differ from those of the GIN, and they do not utilize compact RNNs in their inference structure.

We cover the most relevant works in this section. A more detailed discussion, including a comprehensive comparison of recent related works like System Identification (SI) with details of EM algorithm, auto-regressive (AR) and SLDS models, is provided in Appendix A.8.3 and Table 7. This builds upon the findings of the RKN with additional complements. We also conduct an empirical complexity analysis in appendix A.8.2, to evaluate the computational efficiency of our method compared to the discussed approaches. This analysis involved measuring the execution time per iteration using a clock on the wall as the benchmark.

## 3 Background

**Linear Gaussian state space models.** Linear Gaussian state space models (LGSSMs) are commonly employed to model vectors of observed time series, denoted as \(=[_{1},...,_{T}]\). LGSSMs excel in filtering and smoothing tasks. They model the first-order Markov process on the state space \(=[_{1},...,_{T}]\), which may also incorporate external control inputs \(=[_{1},...,_{T}]\) under the multivariate normality assumption of the state:

\[p_{_{t}}(_{t}|_{t-1},_{t})=( _{t};_{t}_{t-1}+_{t}_{t}, _{t}), 14.226378ptp_{_{t}}(_{t}|_{t})= (_{t};_{t}_{t},_{t}).\] (1)

\(_{t}\) represents the parameters of the system at time \(t\), encapsulating information from matrices \(_{t},_{t}\), \(_{t}\), \(_{t}\) and \(_{t}\), which correspond to the state transition, control, emission, process noise covariance, and observation noise covariance, respectively. At each time step, the transition and emission procedures are subject to distortion caused by process noise and observation noise, following distributions of \((,_{t})\) and \((,_{t})\), respectively.

**Filtering and smoothing algorithms.** The goal of filtering is to infer the posterior distribution \(p_{_{1:t}}(_{t}|_{1:t},_{1:t})\), while, the smoothing aims to infer the smoothing distribution \(p_{_{1:T}}(_{t}|_{1:T},_{1:T})\) given the whole observations. Without loss of generality, we drop the input variable \(\) in the rest of paper, while one can condition all of the distributions on the input variable in the case of its existence. Considering the prior state parameterization \(p_{_{1:t}}(_{t}|_{1:t-1})=(_{t|t-1}, _{t|t-1})\) and relying on , the filtering and smoothing parameterizations are as:

Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are shown as single images, with color intensity representing the incremental sequence index.

\[p_{_{1:t}}(_{t}|_{1:t})=_{t|t-1}+ _{t}[_{t}-_{t}_{t|t-1}],\ \ \ _{t|t-1}-_{t}_{f}_{t}^{T}= _{t|t},_{t|t}\] (2)

\[p_{_{1:T}}(_{t}|_{1:T})=_{t|t} +_{t}[_{t+1|T}-_{t+1}_{t|t}],\ \ \ _{t|t}+_{t}_{s}_{t}^{T}= (_{t|T},_{t|T})\] (3)

\[_{t}=_{t|t-1}_{t}^{T}._{t }_{t|t-1}_{t}^{T}+_{t}^{-1}\,\ \ \ \ \ _{t}=_{t|t}_{t+1}^{T}_{t+1 |t}^{-1}\] (4)

with \(_{f}=[_{t}_{t|t-1}_{t}^{T}+ _{t}]\) and \(_{s}=_{t+1|T}-_{t+1|t}]\). In (4), \(_{t}\) and \(_{t}\) are KG and SG, respectively. See appendix A.1 for a full derivation of filtering-smoothing distributions.

## 4 Gated Inference Network

The background section defines key elements for the GIN: original observations \(_{1:T}\), task-dependent output which can be either the original denoised-imputed observations \(_{1:T}\) or physical system's states \(_{1:T}\), transferred observations \(_{1:T}^{m T}\), latent states (dynamics) \(_{1:T}^{n T}\), noise covariance of transferred observations \(_{1:T}\) with diagonals \(_{1:T}^{m T}\), noise covariance of states process \(_{1:T}\) with diagonals \(_{1:T}^{n T}\), and the parameters of the SSM \(_{1:T}\). We consider the dimensions of the transferred observation and state at each time step to be \(m\) and \(n\), respectively. The states evolve through transition distribution \(p_{_{1:T}}(_{1:T})=p(_{1})_{t=2}^{T}p_{_{ t}}(_{t}|_{t-1})\). Each \(_{t}\) is assumed to be drawn from noisy emission probability \(p_{_{t}}(_{t}|_{t})\), then the generative process is assumed to factorize as \(p_{_{1:T}}(_{1:T},_{1:T})=p_{_{1:T}}(_{1:T})_{t=1}^{T}p_{_{t}}(_{t}|_{t})\). This factorisation imposes emission conditional independence like \(_{t}(_{-t},_{-t})|_{t}\), where \((_{-t},_{-t})=(_{(1:t-1,t+1:T)},_{(1: t-1,t+1:T)})\). Common models that assume conditional independence include linear dynamical systems, hidden Markov models, but also nonlinear SSMs with higher-order Markov chains in latent space. Graphical model of the GIN is in figure 2, where output (one of colored nodes) is generated, contingent upon the task. In all of our scenarios, the parameters of the SSM, \(_{1:T}\), are completely unknown.

From SI perspective, the GIN operates similarly to a Hammerstein-Wiener (HW) model , employing non-linear transfer functions \(e(.)\) and \(d(.)\) (Figure 3). Leveraging encoder-decoder structures for \(e(.)\) and \(d(.)\), the GIN conducts the transfer between original sensory observations \(_{1:T}\) and lower-dimensional representations \(_{1:T}\) and task dependent output. The transition block in Figure 3 evolves states using the proposed deep EKF approach, efficiently approximating filtering-smoothing distributions while ensuring system stability with the imposed constraint. Further details and formulations are provided in the inference section. The transition block depicted in Figure 4.

## 5 Parameterization and Inference

Given original observations \(_{1:T}\) and transferred observations \(_{1:T}\), our aim is to infer the latent states \(_{1:T}\). To accomplish this, we seek to infer the marginal distributions

Figure 3: The GIN as a HW model for system identification. By appropriate structure selection for \(e(.)\) and \(d(.)\), the GIN can handle high dimensional observations. The relation between the internal variables, \(_{t}\) and \(_{t}\), is simulated by the transition block.

Figure 2: Graphical model. Dashed nodes are task dependent output.

\(p_{_{1:t}}(_{t}|_{1:t})\) for the online inference approach (filtering) and \(p_{_{1:T}}(_{t}|_{1:T})\) for the full inference approach (smoothing). We introduce an advantageous prediction parameterization as \(p_{_{t}}(_{t}|_{t-1},_{1:t-1})=( _{t}_{t-1},_{t})\), where \(_{t-1}\) is sampled from the last filtering distribution, \(p_{_{1:t-1}}(_{t-1}|_{1:t-1})\). Then, we obtain the prior distribution at time \(t\), \(p_{_{1:t}}(_{t}|_{1:t-1})=(_{t} _{t-1|t-1},_{t}_{t-1|t-1}_{t}^{ T}+_{t})=(_{t|t-1},_{t|t-1})\), by marginalizing out \(_{t-1}\) from \( p_{_{t}}(_{t}|_{t-1},_{1:t-1})p_{ _{1:t-1}}(_{t-1}|_{1:t-1})d_{t-1}\) integration. The Gaussianity of \(p_{_{1:t}}(_{t}|_{1:t-1})\) results from the Gaussianity of prediction parameterization. After obtaining \(p_{_{t:t}}(_{t}|_{1:t-1})\) and observing \(_{t}\), it is feasible to derive the filtering parameterization using equation (2). Once all transferred observations \(_{1:T}\) are available, backward induction can be employed to propagate to previous states using the chain rule. This procedure, known as smoothing, is parameterized with (3). These parameterizations provide valuable insights into two key aspects: 1) appropriately modeling \(\) using neural networks, and 2) illustrating a tractable method to parameterize KG and SG and construct distributions approximations. These approximations serve the basis for constructing output.

**Learning \(\).** To handle multiple dynamic scenarios, we learn \(K\) sets of state transition and emission matrices \(}^{k}\) and \(}^{k}\), each representing a distinct dynamic status. These matrices are combined with state-dependent coefficients \(^{k}(_{t-1})\) as :

\[}_{t}=_{k=1}^{K}^{k}(_{t-1}) }^{k},}_{t}=_{k=1}^{K}^{k}(_{t-1}) }^{k}.\] (5)

We model \(^{k}(_{t-1})\) with a \(K\) dimension softmax output neural network called the _Dynamic Net_. It takes the last filtering state \(_{t-1}\) as input, containing the system's history with lower noise distortion than the transferred observations \(_{t-1}\). This choice enhances noise robustness, demonstrated in our experiments with time-correlated noise (See Appendix A.6).

In the graphical model shown in Figure 2, we observe two paths for belief propagation from \(_{t-1}\) to \(_{t}\). The first path, \(_{t-1}_{t}\), linked with \(}_{t}\). The second path involves an intermediate variable \(_{t}(,_{t})\): \(_{t-1}_{t}_{t}\). Since learned \(}_{t}\) transfers information from \(_{t-1}\) to \(_{t}\), we argue that it can capture effects similar to those of \(_{t}\), as both are intended to convey message between \(_{t-1}\) and \(_{t}\). By incorporating \(}_{t}\) from equation (5) into the prior state distribution described earlier as \(p_{_{1:t}}(_{t}|_{1:t-1})=(_{t} _{t-1|t-1},_{t}_{t-1|t-1}_{t}^{ T}+_{t})\), we can neglect the \(_{t}\) term in the covariance, as its influence is accounted for by the learned \(}_{t}\). There are two other meaningful parameterizations for the process noise matrix. First involves direct parameterization by \(_{t-1}\) using a neural network. Second approach is to parameterize it recursively using \(_{t-1}\) and \(_{t-1}\), resulting in a new graphical model with an edge from \(_{t-1}_{t}\) (See Appendix A.2). Both parameterizations are included in our results, presented in the appendix, to show their effectiveness.

Finally, the diagonal elements of the transferred observation noise vector \(_{t}\) are directly mapped from the original observation space using the encoder function \(e(.)\) shown in Figure 3. The mapping employs an activation function, elu+1, to handle the positivity of the diagonal elements.

**Filtering and Smoothing Approximation.** We consider \(GRU^{KG}\) network to approximate KG as:

\[}_{t}=}_{|t-1}}_{t}^{T} _{t}_{t}^{T},_{t}=GRU^{KG}[( }_{t|t-1}),_{t}]\] (6)

Figure 4: Transition block of figure 3 in details. In each time step, the last posterior \(_{t-1}|_{1:t-1}\) is fed to the _Dynamic Net_ to compute \(_{t}\). In the filtering steps, by using the last posterior \(_{t-1}|_{1:t-1}\) and the observation \(_{t}\), the next posterior \(_{t}|_{1:t}\) is obtained. Having posterior \(_{t}|_{1:t}\) and the next smoothing state \(_{t+1}|_{1:T}\), applying smoothing for the current state is feasible so that the smoothing state \(_{t}|_{1:T}\) is obtained.

\[_{t|t}=_{t|t-1}+}_{t}.[_{t}-}_{t}_{t|t-1}], 14.226378pt}_{t|t}=}_{t|t-1}+}_{t}.[}_{t}.}_{t|t-1}.}_{T}^{T}+_{t}].}_{t}^{T}\] (7)

In Equation (6), \((.)\) represents a zero bias convolutional layer with pooling, employed to deal with sparsity of covariance matrix and extract its relevant information while reducing its size. The \([,]\) symbol denotes the concatenation operator. Furthermore, the presence of a positive \(_{t}\) vector and the consideration of the Cholesky factor, \(_{t}_{t}^{T}\) in (6), ensure the resulting covariance matrices maintain positive definiteness. This parameterization construct a new filtering distribution \(q_{_{1:t}}(_{t}|_{1:t})=(_{t|t},}_{t|t})\) that is an approximation of (2). Consequently, we consider the approximated prior distribution as \(q_{_{1:t}}(_{t}|_{1:t-1})=(}_{t}_{t-1|t-1},}_{t}}_{t-1|t-1} }_{t}^{T})=(_{t|t-1},} _{t|t-1})\), where \((_{t|t-1},}_{t|t-1})\) are used in (7).

After obtaining filtering states from \(q_{_{1:t}}(_{t}|_{1:t})\), we use \(GRU^{SG}\) network to approximate SG in a similar way we used \(GRU^{KG}\) in (6) as:

\[}_{t}=}_{t|t}}_{t+1}^{T} _{t}_{t}^{T}, 14.226378pt_{t}=GRU^{SG} (}_{t+1|t})\] (8)

\[_{t|T}=_{t|t}+}_{t}_{t+1|T}- }_{t+1}_{t|t}, 14.226378pt}_{t|T}=}_{t|t}+}_{t}}_{t+1|T}-}_{t+1}}_{t|t} }_{t+1}^{T}}_{t}^{T}\] (9)

where the first smoothing state is set to the last filtering state. The new smoothing distribution \(q_{_{1:T}}(_{t}|_{1:T})=(_{t|T},}_{t|T})\) is an approximation of the exact smoothing distribution in (3). For a GRU cell with an input size of \(i\) and a hidden state size of \(h\), the computational complexity in the forward pass is \((3h(h+i+3))\), which scales linearly with the input size . Considering \(()^{^{2}n^{2}}\) as the input of our GRU cells in (6) and (8) with \(\) as the pooling ratio, the forward pass of GIN for one time step has a time complexity of \((3h^{2}n^{2})\), where \(n h\). Compared with LGSSM matrix inversion time complexity of \((n^{3})\), GIN is faster by a factor of \(}\), which is crucial in high-dimensional regimes.

## 6 Fitting

In the state estimation task, the output from \(d(.)\) in figure 3 equals \(\), the physical system's states. However, in the imputation task, output of \(d(.)\) is same as \(\) since the original observation is reconstructed (see decoder structure for each task in A.8.1). The conditional distributions \(p(_{1:T}|_{1:T})\) and \(q_{_{1:T}}(_{1:T}|_{1:T})\) are modeled using an encoder \(e(.)\) and smoothing parameterization, respectively. Meanwhile, the conditional distributions \(p(_{1:T}|_{1:T},_{1:T},_{1:T})\) and \(p(_{1:T}|_{1:T},_{1:T})\) are represented by the decoder \(d(.)\) for the tasks of state estimation and imputation. These distributions are modeled using multivariate Gaussian and Bernoulli distributions, respectively. Depending on the characteristics of the observations and states, alternative likelihood distributions can also be employed. For instance, the beta likelihood for data in the unit interval, mixtures for multiple marginal distributions, and the negative-binomial likelihood for positive count data (See appendix A.3).

**Likelihood for Inferring States.** The following theorem defines objective for inferring physical system's states. The proof is provided in appendix A.4.1.

**Theorem 1**.: _The lower bounded conditional log likelihood of the physical system's states given original images is determined as:_

\[(_{1:T}|_{1:T})=_{i=1}^{N} {log }p(_{1:T}|_{1:T}^{(i)},_{1:T}^{(i)},_{1 :T})=_{i=1}^{N}_{t=1}^{T}_{t}d_{}(_{t|T}^{(i)}),d_ {c}(}_{t|T}^{(i)})\] (10)

_where the \(d_{}(.)\) and \(d_{c}(.)\) determines those parts of the decoder obtaining the state mean and variance. \(N\) sequences of \((_{1:T}^{(i)},_{1:T}^{(i)}) q_{_{1:T}}( _{1:T},_{1:T}|_{1:T})\) are sampled for Monte Carlo integration estimation._

**Likelihood for Inferring Images.** For the imputation task, consider the ground truth as the sequence of images \(_{1:T}\) with the dimension of \(D_{o}\). The following theorem defines objective for inferring images. See appendix A.4.2 for the proof.

**Theorem 2**.: _The lower bound of log likelihood of the original images is:_

\[(_{1:T})=_{i=1}^{N}p(_{1:T}| _{1:T}^{(i)},_{1:T}^{(i)})=_{i=1}^{N}_{t =1}^{T}_{k=1}^{D_{}}_{t}^{(k)}d_{k}(_{t|T}^{(i)})+1-_{t}^{(k)}(1-d_{k} (_{t|T}^{(i)})\] (11)

_with \(N\) sequences of \((_{1:T}^{(i)},_{1:T}^{(i)}) q_{_{1:T}}(_{1:T},_{1:T}|_{1:T})\) for Monte Carlo integration estimation. \(d_{k}(.)\) defines the corresponding part of the decoder that maps the \(k\)-th pixel of \(_{t}\) image._

We use Wishart distribution as a prior for our covariance matrix of states in (10) and (11), which pushes the covariance toward a scale of identity matrix. Such prior prevents getting high log-likelihood due to the high uncertainty. We shrink this scale toward zero as time passes, as we expect the model to finally perform with very little uncertainty, approaching deterministically.

**Mode collapse handling.** To address the issue of mode collapse, where the model becomes stuck in the same state, we propose a loss term on \((i,j)\) pair of transition matrices as follows:

\[l_{}(i,j)=||}^{i}-(_{i})||_{F}^ {2}-||}^{i}-}^{j}||_{F}^{2}-||}^{i}-(_{j})||_{F}^{2}\] (12)

with \(_{i}\) and \(_{j}\) being distinct hyper parameter vectors, and \(||.||_{F}\) is the Frobenius norm. The term \(-_{i=1}^{K}_{j=1,j i}^{K}l_{}(i,j)\) can be added into (10) and (11). This addition ensures that each \(}^{i}\) captures a unique transition, distinct from others. From a statistical perspective, (12) represents a term proportional to \(-KLp_{i}(})||p_{j}(}).pri_{j}(})+KLp_{i}(})||pri_{i}(})\) (See appendix A.5). \(p_{i}(})_{n n}(}^{i}, ,)\) and \(p_{j}(})_{n n}(}^{j}, ,)\), are matrix normal distributions with priors \(pri_{i}(})_{n n}((_{i}),,)\) and \(pri_{j}(})_{n n}((_{j}),,)\), respectively.

**Gradient explosion handling.** Training (10) and (11) with SGD can be disrupted by a gradient explosion. Specifically, we limit the optimization in (10) and (11) subject to \(_{1}(_{h})<2\), where \(_{i}(.)\) represents the \(i\)-th largest singular value and \(_{h}^{h h}\) denotes the weight matrix of the hidden state \(^{h}\) with \(h\) dimension in the GRU cell (see eq.(5) in  or (53) in appendix A.4.3).

**Theorem 3**.: _When \(_{1}(_{h})<2\), a GRU cell is locally stable at a fix point \(^{*}=\)._

We use Lyapunov stability and two lemmas for the proof of **Theorem 3** in appendix A.4.3. Solving (10) and (11) with SGD gives an updated \(}_{h}\) in each iteration that may not satisfy \(_{1}(}_{h})<2\). We offer two solutions to satisfy the constraint outlined in theorem 3. The first solution relies on the spectral theorem, offering higher accuracy but with increased computational cost. Alternatively, the second solution employs the Gershgorin circle theorem, providing lower accuracy but at a reduced cost. Due to space limitations, we provide the details of the second solution in appendix A.4.5. For the first solution, we modify \(}_{h}\) in three steps: (i) Decompose \(}_{h}\) by singular value decomposition (SVD) such that \(}_{h}=\). (ii) Replace the singular values of diagonal \(\) that are greater than 2 with the threshold \(2-\) and obtain \(}=(min(_{1},2-),...,min(_ {h},2-))\). (iii) Reconstruct \(_{h}}\). Employing SVD approach, the cost of this solution is proportional to \((h^{3})\). In the next theorem we show that constructed \(_{h}\) is the optimum solution. The proof is in appendix A.4.4.

**Theorem 4**.: _The modified weight matrix \(_{h}\) obtained from (iii) step above, is a solution of the following optimization problem: \(min_{_{h}}||}_{h}-_{h}||_{F}^{2}\), s.t. \(_{1}(_{h})<2-\)._

## 7 Evaluation and Experiments

The first two experiments are single pendulum and double pendulum, where the dynamics of the latter one is more complicated. The third experiment is ball bouncing in irregular polygon to demonstrate the ability of the GIN when it faces irregular environments with multiple underlying dynamics. The fourth experiment covers visual odometry task for real world data. The last experiment shows the effectiveness of theorems 3 and 4 for gradient explosion handling. Intuitive python code and training algorithm are in appendix A.11. Detailed explanations regarding hyperparameter optimization, network structure, and empirical solutions aimed at avoiding poor local minima are in appendix A.7.

**Single Pendulum and Double Pendulum.**

In the pendulum experiment, observations are the image sequences comprising 100 time steps, each has the size of \(24 24\) distorted with time correlated noise. We perform the filtering-smoothing by the GIN. In state estimation task, the log-likelihood andsquared error (SE) of the estimated states are given in table 1. With \(n=3m\) (\(n\) and \(m\) representing state and transferred observation dimensions) as shown in Table 1, intuitively states contain information about position, velocity, and acceleration, increasing the likelihood compared to \(n=2m\), where only position and velocity are allocated to states. For the imputation task, we randomly remove half of the images from the generated sequences and perform image imputation by predicting the missing parts. The numerical results are in table 2 and imputed images are in figures 5 and 6. In table 2, the models with informed boolean masks are aware of available and missing images, while uninformed masks use a black image as input for missing images. This encourages the model to accurately infer the dynamics for image generation.

For ablation study, first we compare GIN with simple encoder-decoder without latent parameterization, and

   Model & \(_{1}^{}\) & \(_{2}^{}\) & \(_{3}^{}\) & \(_{4}^{}\) & Log Likelihood & \(_{1}^{}\) & \(_{2}^{}\) & Log Likelihood \\  VAE & 0.212 & 0.275 & 0.192 & 0.285 & 1.953 \(\) 0.306 & 0.211 & 0.247 & 2.191 \(\) 0.451 & 0.769 & 0.762 & 2.094 \(\) 0.392 \\ IW-VAE & 0.203 & 0.251 & 0.201 & 0.266 & 2.113 \(\) 0.301 & 0.231 & 0.197 & 2.328 \(\) 0.394 & 0.777 & 0.764 & 2.117 \(\) 0.475 \\ VAE-RNN (LSTM) & 0.154 & 0.147 & 0.134 & 0.152 & 0.463 \(\) 0.565 & 0.111 & 0.099 & 5.691 \(\) 0.151 & 0.447 & 0.411 & 3.157 \(\) 0.122 \\ VAE-RNN (GRU) & 0.164 & 0.156 & 0.162 & 0.145 & 3.9tr \(\) 0.251 & 0.109 & 0.101 & 5.749 \(\) 0.168 & 0.439 & 0.415 & 3.088 \(\) 0.091 \\ VAE (LDS) & 0.190 & 0.211 & 0.179 & 0.159 & 3.495 \(\) 0.425 & 0.109 & 0.096 & 5.736 \(\) 0.168 & 0.424 & 0.438 & 3.292 \(\) 0.112 \\ KVAE & 0.193 & 0.188 & 0.178 & 0.149 & 3.678 \(\) 0.101 & 0.104 & 0.055 & 5.786 \(\) 0.098 & 0.434 & 0.439 & 3.194 \(\) 0.073 \\ EXVAE & 0.171 & 0.159 & 0.151 & 0.162 & 3.801 \(\) 0.116 & 0.088 & 0.093 & 5.588 \(\) 0.113 & 0.340 & 0.429 & 3.276 \(\) 0.064 \\ MVAE & 0.168 & 0.161 & 0.139 & 0.149 & 3.927 \(\) 0.226 & 0.087 & 0.087 & 5.938 \(\) 0.137 & 0.310 & 0.401 & 3.305 \(\) 0.069 \\  DeepAR & 0.175 & 0.189 & 0.157 & 0.147 & 3.646 \(\) 0.294 & 0.107 & 0.094 & 5.746 \(\) 0.294 & 0.447 & 0.454 & 3.071 \(\) 0.106 \\  RKN & 0.134 & 0.129 & 0.139 & 0.118 & 4.176 \(\) 0.264 & 0.078 & 0.075 & 6.161 \(\) 0.23 & 0.314 & 0.437 & 3.324 \(\) 0.039 \\ CPU & 0.117 & 0.127 & 0.116 & 0.104 & 4.269 \(\) 0.237 & 0.074 & 0.069 & 6.348 \(\) 0.19 & 0.294 & 0.378 & 3.366 \(\) 0.039 \\  Encode-Decoder & 0.291 & 0.284 & 0.342 & 0.317 & 1.877 \(\) 0.427 & 0.248 & 0.191 & 2.271 \(\) 0.215 & 0.569 & 0.914 & 1.994 \(\) 0.384 \\ AE-RNN (LSTM) & 0.163 & 0.171 & 0.148 & 0.167 & 3.901 \(\) 0.076 & 0.089 & 0.687 & 5.751 \(\) 0.215 & 0.349 & 0.319 & 3.331 \(\) 0.124 \\ AE-RNN (ReLU) & 0.189 & 0.183 & 0.179 & 0.177 & 3.886 \(\) 0.369 & 0.091 & 0.085 & 5.798 \(\) 0.205 & 0.351 & 0.429 & 3.267 \(\) 0.089 \\ LGGSMar & 0.125 & 0.119 & 0.121 & 0.107 & 4.192 \(\) 0.127 & 0.077 & 0.073 & 6.211 \(\) 0.265 & 0.448 & 0.312 & 3.171 \(\) 0.365 \\ LGGSMar\_minch & 0.109 & 0.111 & 0.104 & 0.101 & 4.231 \(\) 0.154 & 0.071 & 0.069 & 6.242 \(\) 0.109 & 0.327 & 0.317 & 3.544 \(\) 0.029 \\  GINME(\(n\)=2\(m\)) & 0.105 & 0.099 & 0.109 & 0.099 & 4.524 \(\) 0.105 & 0.063 & 0.06 & 7.192 \(\) 0.239 & 0.203 & 0.208 & 4.125 \(\) 0.146 \\ GINME(\(n\)=2\(m\)) & 0.083 & 0.081 & 0.088 & 0.079 & 4.839 \(\) 0.151 & 0.057 & 0.056 & 7.315 \(\) 0.220 & 0.198 & 0.199 & 4.254 \(\) 0.187 \\ GINME(\(n\)=2\(m\)) & 0.081 & 0.094 & 0.081 & 0.082 & 4.708 \(\) 0.123 & 0.055 & 0.057 & 7.292 \(\) 0.173 & 0.186 & 0.198 & 4.227 \(\) 0.048 \\ GINME(\(n\)=3\(m\)) & **0.069** & **0.073** & **0.075** & **0.067** & **4.977** \(\) **0.168** & **0.049** & **0.047** & **7.445** \(\) **0.165** & **0.154** & **0.147** & **4.342** \(\) **0.051** \\   

Table 1: Double (left) and single pendulum (middle) and polygon (left) state estimation results. \((s_{1},s_{2},s_{3},s_{4})\) are estimated position of the joints of double pendulum. For single pendulum and polygon, \((s_{1},s_{2})\) denotes the estimated single joint and ball position. \(\) is sampled from eq. (10).

   Model & Single Pendulum & Double Pendulum & Imregular Polygon \\  VAE (informed) & -36.751 \(\) 7.227 & -44.264 \(\) 4.232 & -

[MISSING_PAGE_FAIL:9]

Gradient Explosion Experiment.

Table 4 lists the log likelihood and its standard deviation for three experiments: single pendulum, double pendulum, and irregular polygon. These experiments were trained under different settings for gradient explosion handling: the conventional Gradient Clipping (GC), our first solution using Singular Value Decomposition (SVD), and our second solution using the Gershgorin Circle Theorem (GCT). The table empirically demonstrates that our method outperforms conventional gradient clipping. In this table, \(\) represents the threshold for gradient clipping as introduced in , and \(\) is the threshold in our method that keeps the spectral radius less than 2, i.e., \(_{1}(_{h})+=2\). As shown in table 4, gradient clipping failed to train for high \(\), while our approach achieves lower perplexity and higher log likelihood, ensuring stability compared to gradient clipping by constraining the GRU to be stable. We provide a comprehensive discussion on the \(\) variable, including how to tune it in different environments and its impact on model performance, in the appendix A.8.1.

## 8 Conclusion

This paper introduces the GIN for representation learning in high-dimensional SSMs. The data flow is managed by Bayesian filtering-smoothing, and the use of GRU-based KG and SG networks addresses computational issues, resulting in an efficient and numerically stable model. The GIN learns system dynamics end-to-end, making it a high-performance model with strong system identification capabilities. It also provides insightful uncertainty representations for predictions and outperforms various counterparts, including generative models with variational inference, autoregressive models, and other baselines.

## 9 Acknowledgments

We thank Yasin Abbasi-Yadkori for useful discussions and suggestions that contributed to this work.