# Generative Subspace Adversarial Active Learning for Outlier Detection in Multiple Views of High-dimensional Tabular Data

Generative Subspace Adversarial Active Learning for Outlier Detection in Multiple Views of High-dimensional Tabular Data

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Outlier detection in high-dimensional tabular data is an important task in data mining, essential for many downstream tasks and applications. Existing unsupervised outlier detection algorithms face one or more problems, including inlier assumption (IA), curse of dimensionality (CD), and multiple views (MV). To address these issues, we introduce Generative Subspace Adversarial Active Learning (GSAAL), a novel approach that uses a Generative Adversarial Network with multiple adversaries. These adversaries learn the marginal class probability functions over different data subspaces, while a single generator in the full space models the entire distribution of the inlier class. GSAAL is specifically designed to address the MV limitation while also handling the IA and CD, making it the only method to address all three. We provide a mathematical formulation of MV, theoretical guarantees for the training, and scalability analysis for GSAAL. Our extensive experiments demonstrate the effectiveness and scalability of GSAAL, highlighting its superior performance compared to other popular OD methods, especially in MV scenarios.

## 1 Introduction

Outlier detection (OD), a fundamental and widely recognized issue in data mining, involves the identification of anomalous or deviating data points within a dataset. Outliers are typically defined as low-probability occurrences within a population [41; 19]. In the absence of access to the true probability distribution of the data points, OD algorithms rely on constructing a scoring function. Points with higher scores are more likely to be outliers. Existing unsupervised OD algorithms have one or more of the following problems, in high-dimensional tabular data scenarios.

* _The inlier assumption_ (IA): OD algorithms often make assumptions about what constitutes an inlier, which can be challenging to verify and validate .
* _The curse of dimensionality_ (CD): As the dimensionality of data increases, the challenge of identifying outliers intensifies, decreasing the effectiveness of certain OD algorithms 
* _Multiple Views_ (MV): Outliers are often only visible in certain "views" of the data and are hidden in the full space of original features 

We now explain these problems one by one.

_The inlier assumption_ poses a challenge to algorithms that assume a standard profile of the inlier data. For example, angle-based algorithms like ABOD  assume that inliers have other inliers at all angles. Similarly, neighbor-based algorithms like kNN  assume that inliers have other neighboring points nearby. These assumptions influence the scoring as it measures the degree to which a sample deviates from this assumed norm. Consequently, the performance of these algorithmsmay degrade if these assumptions do not hold . This means that a general OD method should not make any inlier assumptions.

_The curse of dimensionality_ refers to the decrease in the relative proximity of data points as the number of dimensions increases. Simply put, with high dimensionality, the distance between any pair of points becomes similar, regardless of whether none, one, or both of the points in a pair are outliers. This is particularly problematic for OD algorithms that rely on distances or on identifying neighbors to detect outliers, such as density- (e.g., LOF ), neighbor- (e.g., kNN ), and cluster-based (e.g., SVDD [1, Chapter 2]) OD algorithms.

_Multiple Views_ refers to the phenomenon that certain complex correlations between features are only observable in some feature subspaces . As detailed in , this occurs when the dataset contains additional irrelevant features, making some outliers only detectable in certain subspaces. In scenarios where multiple subspaces contain different interesting structures, this problem is exacerbated. It then becomes increasingly difficult to explain the variability of a data point based solely on its behavior in a single subspace . This problem can occur regardless of the dimensionality of the dataset if the number of points is insufficient to capture a complex correlation structure.

The following example illustrates the three problems described above

**Example 1** (Effect of MV, IA and CD).: _Consider the random variables \(_{1},_{2}\) and \(_{3}\), where \(_{1}\) and \(_{2}\) are highly correlated and \(_{3}\) is Gaussian noise. Figure 1 plots datasets with 20, 100 and 1000 realizations of \((_{1},_{2},_{3})\). It also contains the classification boundaries from both a locality-based method (green) and a cluster-based method (red) in the subspace. The cluster-based detector fitted in the full 3D space fails to detect the outlier shown in the figure (red cross). However, the outlier is always detected in the 2D subspace, as we can see. Once we increase the number of samples over \(n=1000\), the cluster-based method detects the outlier in the full space (MV). On the contrary, the locality-based method could not detect the outlier in any tested scenario (MV + IA). If we increase the dimensionality by adding more features consisting of noise, no method can detect the outlier in the full space (MV + IA + CD)._

We are interested in tackling outlier detection whenever a population exhibits MV, like  and as showcased in . Particularly, the goal of this paper is to propose the first outlier detection method that explicitly addresses IA, CD, and MV simultaneously.

As we will explain in the next section, we build on Generative Adversarial Active Learning (GAAL) , a widely used approach for outlier detection . It involves training a Generative Adversarial Network (GAN) to mimic the distribution of outlier data, and it enhances the discriminator's performance through active learning , leveraging the GAN's data generation capability. GAAL methods avoid IA  and use the multi-layered structure of the GAN to overcome the curse of dimensionality . However, they often miss important subspaces, leading to MV.

Challenges.Training multiple GAN-based models in individual subspaces is not trivial. (1) The joint training of generators and discriminators in GANs requires careful monitoring to determine the optimal stopping point, a task that becomes daunting for large ensembles. (2) The generation of difficult-to-detect points in a subspace remains hard . (3) While several authors have proposed

Figure 1: Scatterplots of the dataset from example 1.

multi-adversarial architectures for GANs , none of them address adversaries tailored to subspaces composed of feature subsets. Furthermore, these methods may not be suitable for GAAL since they do not have convergence guarantees for detectors, as we will explain.

Contributions.(1) We propose GSAAL (Generative Subspace Adversarial Active Learning), a novel GAAL method that uses multiple adversaries to learn the marginal inlier probability functions in different data subspaces. Each adversary focuses on a single subspace. Simultaneously, we train a single generator in the full space to approximate the entire distribution of the inlier class. All networks are trained end-to-end, avoiding the ensembling problem. (2) To our knowledge, we give the first mathematical formulation of the "multiple views" problem. We used it to show the ability of GSAAL to mitigate the MV problem. (3) We formulate the novel optimization problem for GSAAL and give convergence guarantees of each discriminator to the marginal distribution of its respective subspace. We also analyze the worst-case complexity of the method. (4) In extensive experiments we compare GSAAL with multiple competitors. GSAAL was the only method capable of consistently detecting anomalous data under MV. Furthermore, on 22 popular benchmark datasets for the one-class classification task, GSAAL demonstrated SOTA-level performance and was orders of magnitude faster in inference than its best competitors. (5) Our code is publicly available.1

Paper outline: Section 2 reviews related work, Section 3 contains the theoretical results for our method, Section 4 features our experimental results, and Section 5 concludes and addresses limitations.

## 2 Related Work

This section is a brief overview of popular unsupervised outlier detection methods for tabular data related to our approach. We categorize them based on their ability to address the specific limitations outlined above. Table 1 is a comparative summary. Further comments about OD in other data types can be found in the appendix.

Classical MethodsConventional outlier detection approaches, such as distance-based strategies like LOF and KNN, angle-based techniques like ABOD, and cluster-based methods like SVDD, rely on specific assumptions on the behavior of inlier data. They use a scoring function to measure deviations from this assumed norm. These methods face the _inlier assumption_ limitation by definition. For example, local methods that assume isolated outliers fail when several outlying samples fall together. In addition, many classical methods, which rely on measuring distances, are susceptible to the _curse of dimensionality_. Both limitations impair the effectiveness of these methods .

Subspace MethodsSubspace-based methods  operate in lower-dimensional subspaces formed by subsets of features. They effectively counteract the curse of dimensionality by focusing on identifying so-called "subspace outliers" . These outliers, which are prevalent in high-dimensional datasets with many correlated features, are often elusive to conventional non-subspace methods . However, existing subspace methods inherently operate on specific assumptions on the nature of anomalies in each subspace they explore, and thus face the _inlier assumption_ limitation.

Generative MethodsA common strategy to mitigate the IA and CD limitations is to reframe the task as a classification task using self-supervision. A prevalent self-supervised technique, particularly

   Type & IA & CD & MV \\  Classical & ✗ & ✗ & ✗ \\ Subspace & ✗ & ✓ & ✓ \\ Generative w/ uniform distribution & ✓ & ✗ & ✗ \\ Generative w/ param. distribution & ✗ & ✓ & ✗ \\ Generative w/ subspace behavior & ✗ & ✓ & ✓ \\ GAAL & ✓ & ✓ & ✗ \\
**GSAAL** (Our method) & ✓ & ✓ & ✓ \\   

Table 1: Families of OD methods with the limitations they address.

for tabular data, is the generation of artificial outliers [13; 30]. This method involves distinguishing between actual training data and artificially generated data drawn from a predetermined "reference distribution".  showed that by approximating the class probability of being a real sample, one approximates the probability function of being an inlier. One then uses this approximation as a scoring function . However, it is not easy to find the right reference distribution, and a poor choice can affect OD by much .

A first approach to this challenge proposed the use of naive reference distributions by uniformly generating data in the space. This approach showed promising results in low-dimensional spaces but failed in high dimensions due to the curse of dimensionality . Other approaches, such as assuming parametric distributions for inlier data [1, Chapter 2] or directly generating in subspaces , can avoid CD when the parametric assumptions are met. Methods that generate in the subspaces can model the subspace behavior, additionally tackling the MV limitation. However, these last two approaches do not address the IA limitation, as they make specific assumptions about the behavior of the inlier data.

Generative Adversarial Active LearningAccording to , the closer the reference distribution is to the inlier distribution, the better the final approximation to the inlier probability function will be. Hence, recent developments in generative methods have focused on learning the reference distribution in conjunction with the classifier. A key approach is the use of Generative Adversarial Networks (GANs), where the generator converges to the inlier distribution . The most common approaches for this are GAAL-based methods [30; 17; 39]. These methods differentiate themselves from other GANs for OD by training the detectors using active learning after normal convergence of the GAN [36; 10]. The architecture of GAAL inherently addresses the curse of dimensionality, as GANs can incorporate layers designed to manage high-dimensional data . In practice, GAAL-based methods outperformed all their competitors in their original work. However, they overlook the behavior of the data in subspaces and therefore may be susceptible to MV.

Our method, GSAAL, incorporates several subspace-focused detectors into GAAL. These detectors approximate the marginal inlier probability functions of their subspaces. Thus, GSAAL effectively addresses MV while inheriting GAAL's ability to overcome IA and CD limitations.

## 3 Our Method: GSAAL

We first formalize the notion of data exhibiting multiple views. We then use it to design our outlier detection method, GSAAL, and give convergence guarantees. Finally, we derive the runtime complexity of GSAAL. All the proofs and extra derivations can be found in the technical appendix.

### Multiple Views

Several authors [1; 31; 23; 25; 29] have observed that at times the variability of the data can only be explained from its behavior in some subspaces. Researchers variably call this problem "the subspace problem" [1; 25] or "multiple views of the data" [22; 31]. Previous research has largely focused on practical scenarios, leaving aside the need for a formal definition. In response, we propose a unifying definition of "multiple views" that provides a foundation for developing methods to address this challenge effectively.

The problem "multiple views" of data (MV) arises from two different effects. First, it involves the ability to understand the behavior of a random vector \(\) by examining lower-dimensional subsets of its components \((_{1},,_{d})\). Second, it stems from the challenge of insufficient data to obtain an effective scoring function in the full space of \(\). As Example 1 shows, combining these two effects obscures the behavior of the data in the full space. Hence, methods not considering subspaces when building their scoring function may have issues detecting outliers under MV. The next definition formalizes the first effect.

**Definition 1** (myopic distribution).: _Consider a random vector \(:^{d}\) and \(_{d d}(\{0,1\})\), the set of diagonal binary matrices without the identity. If there exists a random matrix \(:_{d d}(\{0,1\})\), such that_

\[p_{}(x)=p_{}(ux)x\] (1)

_we say that the distribution of \(\) is myopic to the views of \(\). Here, \(x\) and \(ux\) are realizations of \(\) and \(\), and \(p_{}\) and \(p_{}\) are the pdfs of \(\) and \(\)._It is clear that, under MV, using \(p_{}\) to build a scoring function instead of \(p_{}\) mitigates the effects. This comes as the subspaces selected by \(\) are smaller in dimensionality. Hence it should take fewer samples to approximate the pdf of \(\). The difficulty is that it is not yet clear how to approximate \(p_{}\). The following proposition elaborates on a way to do so. It states that by averaging a collection of marginal distributions of \(\) in the subspaces given by realizations of \(\), one can approximate the distribution of \(p_{}\).

**Proposition 1**.: _Let \(\) and \(\) be as before with \(p_{}\) myopic to the views of \(\). Consider a set of independent realizations of \(\): \(\{u_{i}\}_{i=1}^{k}\). Then \(_{i}p_{u_{i}}(u_{i}x)\) is an unbiased statistic for \(p_{}(ux)\)._

MV appears when there is a lack of data, and its distribution is myopic. To improve OD under MV, one can exploit the distribution myopicity to model \(\) in the subspaces, where less data is sufficient. Proposition 1 gives us a way to do so, by approximating \(p_{}\). In this way, under myopicity, this also approximates \(p_{}\), avoiding MV. Our method, GSAAL, exploits these derivations, as we explain next.

### Gsaal

GAAL methods tackle IA by being agnostic to outlier definition and mitigate CD through the use of multilayer neural networks [30; 28; 33]. GAAL methods have two steps:

1. _Training of the GAN._ Train the GAN consisting of one generator \(\) and one detector \(\) using the usual \(\)-\(\) optimization problem as in .
2. _Training of the detector through active learning._ After convergence, \(\) is fixed, and \(\) continues to train. This last step is an active learning procedure with . Following , \((x)\) now approximates the pdf of the training data \(p_{}\).

After Step 2, the detector converges to \(p_{}\). However, our goal is to approximate \(p_{}\) by exploiting a supposed myopicity of the distribution. We extend GAAL methods to also address MV in what follows. The following theorem adapts the objective function of the GAN to the subspace case and gives guarantees that the detectors converge to the marginal pdfs used in Proposition 1:

**Theorem 1**.: _Consider \(\) and \(\) as in the previous definition, with \(x\) a realization of \(\) and \(\{u_{i}\}_{i}\) a set of realizations of \(\). Consider a generator \(:z Z(z)^{d}\) and \(\{_{i}\}\), \(i=1,,k\), a set of detectors such as \(_{i}:u_{i}x S_{i}^{d}_{i} (u_{i}x)\). \(Z\) is an arbitrary noise space where \(\) randomly samples from. Consider the following optimization problem_

\[&_{}_{_{i},\; i }_{i}V(,_{i})=\\ &_{}_{_{i},\; i}_{i} _{u_{i}}_{i}(u_{i}x)+_{z} (1-_{i}(u_{i}(z))),\] (2)

_where each addend \(V(,_{i})\) is the binary cross entropy in each subspace. Under these conditions, the following holds:_

1. _Each detector in optimum is_ \(_{i}^{*}(u_{i}x)=, x\)_. Thus, in optimum_ \(V(,_{i})=-(4), i\)_._
2. _Each individual_ \(_{i}\) _converges to_ \(_{i}^{*}(u_{i}x)=p_{u_{i}x}(u_{i}x)\) _after trained in Step 2 of a GAAL method._
3. \(^{*}(x)=_{i=1}^{k}_{i}^{*}(u_{i})\) _approximates_ \(p_{}(ux)\)_. If_ \(p_{}\) _is myopic,_ \(^{*}(x)\) _also approximates_ \(p_{}(x)\)_._

Using Theorem 1 we can extend the GAAL methods to the subspace case:

1. _Training the GAN._ Train a GAN with one generator \(\) and multiple detectors \(\{_{i}\}\) with Equation (2) as the objective function. The training of each detector stops when the loss reaches its value with the optimum in Statement \((i)\).
2. _Training of the \(k\) detectors by active learning._ Train each \(_{i}\) as in Step 2 of a regular GAAL method using \(\). By Statement \((ii)\) of the Theorem, each \(_{i}\) will approximate \(p_{u_{i}}\). By Statement \((iii)\), \((x)=_{i=1}^{k}_{i}(u_{i})\) will approximate \(p_{}\) under the myopicity of the data.

We call this generalization of GAAL Generative Subspace Adversarial Active Learning (GSAAL). The appendix contains the pseudo-code for GSAAL.

### Complexity

In this section, we focus on studying the theoretical complexity of GSAAL. We study both its usability for training and, more importantly, for inference.

**Theorem 2**.: _Consider our GSAAL method with generator \(\) and detectors \(\{_{i}\}_{i=1}^{k}\), each with four fully connected hidden layers, \(\) nodes in the detectors and \(d\) in the generator. Let \(D\) be the training data for GSAAL, \(n\) data points and \(d\) features. Then the following holds:_

* _Time complexity of training is_ \((E_{D} n(k n+d^{2}))\)_._ \(E_{D}\) _is an unknown complexity variable depicting the unique epochs to convergence for the network in dataset_ \(D\)_._
* _Time complexity of single sample inference is in_ \((k n)\)_, with_ \(k\) _the number of detectors used._

The linear inference times make GSAAL particularly appealing in situations where the model can be trained once for each dataset, like one-class classification. We build on this particular strength in the following section.

## 4 Experiments

This section presents experiments with GSAAL. We will outline the experimental setting, and examine the handling of "multiple views" in GSAAL and other OD methods. We then evaluate GSAAL's performance against various OD methods and investigate its scalability. The appendix includes a study on the sensitivity to the number of detectors, IA experiments, an ablaition study and extra competitors evaluated in the real world datasets. System specifications are included in the appendix.

### Experimental Setting

This section has three parts: First, we describe the synthetic and real data for the outlier detection experiments. Then, we describe the configuration of GSAAL. Finally, we present our competitors.

#### 4.1.1 Datasets

Synthetic.We constructed synthetic datasets, each containing two correlated features, \(_{1}\) and \(_{2}\), along with 58 independent features \(_{j}\), \(j=3,,60\) consisting of Gaussian noise. This approach simulates datasets that exhibit the MV property by adding irrelevant features into a pair of highly correlated variables. We detail the methodology and all correlation patterns in the technical appendix.

Real.We selected 22 real-world tabular datasets for our experiments from . The selection criteria included datasets with less than 10,000 data points, more than 10 outliers, and more than 15 features, focusing on high-dimensional data while keeping the runtime (of competing OD methods) tractable. Table (a)a contains the summary of the datasets. For datasets with multiple versions, we chose the first in alphanumeric order. Details about each dataset are available in the original source .

#### 4.1.2 Network Settings

Structure.Unless stated otherwise, GSAAL uses the following network architecture. It consists of four fully connected layers with ReLu activation functions used in the generator and the detectors. Each layer in \(k=2\) detectors has \(\) nodes, where \(n\) and \(d\) are the number of data points and features in the training set, respectively. This configuration ensures linear inference time. The generator has \(d\) nodes in each layer, a standard in GSAL approaches, which ensures polynomial training times. We assumed \(\) to be distributed uniformly across all subspaces. Therefore, we obtained each subspace for the detectors by drawing uniformly from the set of all subspaces.

Training.Like other GAAL methods , we train the generator \(\) together with all the detectors \(_{i}\) until the loss of \(\) stabilizes. Then we train each detector \(_{i}\) until convergence with \(\) fixed. To automate this process, we introduce an early stopping criterion: Training stops when a detector's loss approaches the theoretical optimum (\(-(4)\)), see statement \((ii)\) of Theorem 1. For consistency across experiments, training parameters remain fixed unless otherwise noted. Specifically,the learning rates of the detectors and the generator are 0.01 and 0.001, respectively. We use minibatch gradient descent  optimization, with a batch size of 500.

#### 4.1.3 Competitors

We selected popular and accessible methods from each category, as summarized in Table 1(b), guided by related work. We excluded generative methods with uniform distributions because they prove ineffective for large datasets . We could not include a generative method with subspace behavior due to operational issues with the most relevant method in this class, , caused by its outdated repository. We used the recommended parameters for all methods, as usual in OD .

We used the pyod library to access all competitors except MO-GAAL. We used MO-GAAL from its original source and implemented our method GSAAL in keras.

### Effect of Multiple Views on Outlier Detection

To demonstrate the effectiveness of GSAAL under MV, we use synthetic datasets. Visualizing the outlier scoring function in a 60-dimensional space is challenging, so we project it into the \(_{1}\)-\(_{2}\) subspace. A method adept at handling MV should have a boundary that accurately reflects the \(_{1}\) and \(_{2}\) dependency structure. We first generate a synthetic dataset \(D^{}\) as described in section 4.1.1 and train the OD model. Using this model, we compute the scores for the points \((x_{1},x_{2},0,,0)\) and visualize the level curves on the \(_{1}\)-\(_{2}\) plane.

Figure 2 shows results for selected datasets and competitors, which are detailed in the Appendix. It shows the level curves and decision boundaries (dashed lines) of the methods. Notably, our model effectively detects correlations in the right subspace. To quantify this, we generated outliers in the subspace of interest and extra inliers. We tested the one-class classification performance of each method in 10 different MV datasets. On average, GSAAL managed to obtain 0.70 AUC, while the second-best performer (IForest) did not surpass a random classifier --0.49 AUC. All results and further details can be found in section B.2 in the appendix.

### One-class Classification

This section evaluates GSAAL on a one-class classification task . First, we study the effectiveness of GSAAL on real data. Then, we investigate the scalability of GSAAL in practical scenarios.

#### 4.3.1 Real-world Performance

We perform the outlier detection experiments on real datasets. Specifically, we take on the task of one-class classification, where the goal is to detect outliers by training only on a collection of inliers . To evaluate the performance of OD methods, we use AUC as it is robust to test data imbalance, a common issue in OD tasks. The procedure is as follows:

Table 2: Real-world datasets and Competitors1. Split the dataset \(D\) into a training set \(D^{}\) containing \(80\%\) of the inliers from \(D\), and a test set \(D^{}\) containing the remaining inliers and all outliers.
2. Train an outlier detection model with \(D^{}\) and evaluate its performance on \(D^{}\) with ROC AUC.

To save space, we moved the detailed AUC results to the appendix; showing that GSAAL obtained the lowest median rank --see Figure 10 in the appendix. Although other subspace methods tend to perform better with irrelevant attributes [29; 25], they did not outperform classical OD methods on average in our experiments. Notably, ABOD, the second-best method in our experiments, performed poorly in the MV tests (Section 4.2).

For statistical comparisons, we use the Conover-Iman post hoc test for pairwise comparisons between multiple populations . It is superior to the Nemenyi test due to its improved type I error boundings . Conover-Iman test requires a preliminary positive result from a multiple population comparison test, for which we employ the Kruskal-Wallis test .

Table 3 shows the test results. In each cell, '+' indicates that the method in the row has a significantly lower median rank than the method in the column, while '--' indicates a significantly higher median rank. One symbol indicates p-values \( 0.15\) and two symbols indicate p-values \( 0.05\). A blank indicates no significant difference. The table shows that GSAAL is superior to most of its competitors. Our method does not significantly outperform the classical methods ABOD and kNN. However, these methods struggle to detect structures in subspaces, showing their inadequacy in dealing with the MV limitation, see Section 4.2.

Overall, the results support GSAAL's superiority in outlier detection tasks involving multiple views. Additionally, they establish our method as the leading GAAAL option for One-class classification

#### 4.3.2 Scalability

In section 3.3, we derived that the inference time of GSAAL scales linearly with the number of training points if the number of detectors \(k\) is fixed, while it does not depend on the number of features \(d\). This is in contrast to other methods, in particular LOF, KNN, and ABOD, which have quadratic runtimes in \(d\)[3; 24]. We now validate this experimentally. The procedure is as follows:

  Method & ABOD & **GSAAL** & GMM & IForest & KNN & LOF & MO GAAL & OCSVM & SOD \\  ABOD & = & & ++ & ++ & & & ++ & ++ & ++ \\
**GSAAL** & & = & ++ & ++ & & + & ++ & ++ & ++ \\ GMM & \(\,--\,\) & \(\,--\,\) & = & ++ & \(\,--\,\) & \(\,--\,\) & & ++ & ++ \\ IForest & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & = & \(\,--\,\) & & ++ & & ++ \\ KNN & & & ++ & ++ & = & & ++ & & ++ \\ LOF & & \(\,-\,\) & ++ & & & = & ++ & + & ++ \\ MO GAAL & \(\,--\,\) & \(\,--\,\) & & \(\,--\,\) & \(\,--\,\) & = & & ++ \\ OCSVM & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & & & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,=\,\) \\ SOD & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,--\,\) & \(\,=\,\) \\  

Table 3: Results of the Conover-Iman test for pairwise comparisons of the rankings.

Figure 2: GSAAL finds classification boundaries for datasets banana and star under MV.

1. Generate datasets \(D_{}\) and \(D_{}\) consisting of random points. \(|D_{}|=10^{6}\).
2. Train an OD method using \(D_{}\) and record the inference time over \(D_{}\).

Following the result of the sensitivity study in our appendix, we fixed \(k=30\). Figure 2(a) plots the inference time of a single data point as a function of the number of features when \(|D_{train}|=500\). Figure 2(b) plots the inference time as a function of the number of points in \(D_{}\), for a fixed number of 100 features. Both figures confirm our complexity derivations and show that GSAAL is particularly well-suited for large datasets.

## 5 Limitations & Conclusions

### Limitations and Future Work

In section 4 we randomly selected subspaces for training the detectors in GSAAL, i.e. we took a uniform distribution of \(\). This was already sufficient to demonstrate the highly competitive performance of our method. In practice, this assumption seemed to perform well for our experiments. However, GSAAL can work with any subspace search strategy to obtain the distribution of \(\), for example, the methods exploiting multiple views [23; 22]. We have not included them in this paper due to the lack of an official implementation. In the future, we plan to benchmark various subspace search methods in GSAAL.

Next, GSAAL is limited to tabular data, since the "multiple views" problem has only been observed for this data type. The mathematical formulation of MV in section 3 does not exclude unstructured data. The difficulty lies in identifying good search strategies for \(\) for non-tabular data, which remains an open question . However, depending on the type of unstructured data, extending GSAAL to work with it is not immediate. Therefore, building a method that exploits the theoretical derivations of GSAAL for structured data is future work.

### Conclusions

Unsupervised outlier detection (OD) methods rely on a scoring function to distinguish inliers from outliers, since the true probability function that generated the dataset is usually unavailable in practice. However, they face one or more of the following problems -- Inlier Assumption (IA), Curse of Dimensionality (CD), or Multiple Views (MV). In this article, we have proposed the first mathematical formulation of MV, which allows for a better understanding of how to solve this occurrence. Using this formulation, we developed GSAAL, which is the first OD approach that solves MV, CD, and IA. In short, GSAAL is a generative adversarial network with a generator and multiple detectors fitted in the subspaces to find outliers not visible in the full space. In our experiments on 27 different datasets, we demonstrated the usefulness of GSAAL, in particular, its ability to deal with MV and its superior performance on OD tasks with real datasets. In addition, we have shown that GSAAL can scale up to deal with high-dimensional data, which is not the case for our most competent competitors. These results confirm GSAAL's ability to deal with data exhibiting MV and its usability in any practical scenario involving large datasets.