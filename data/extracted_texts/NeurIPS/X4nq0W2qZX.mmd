# MmCows: A Multimodal Dataset for Dairy Cattle Monitoring

Hien Vu

Purdue University

hienvu@purdue.edu

&Omkar Prabhune

Purdue University

oprabhun@purdue.edu

&Unmesh Raskar

University of Wisconsin-Madison

uraskar@wisc.edu

&Dimuth Panditharatne

University of Wisconsin-Madison

panditharatn@wisc.edu

&Hanwook Chung

Iowa State University

hwchung@iastate.edu

&Christopher Y. Choi

University of Wisconsin-Madison

cchoi22@wisc.edu

&Younghyun Kim

Purdue University

younghyun@purdue.edu

###### Abstract

Precision livestock farming (PLF) has been transformed by machine learning (ML), enabling more precise and timely interventions that enhance overall farm productivity, animal welfare, and environmental sustainability. However, despite the availability of various sensing technologies, few datasets leverage multiple modalities, which are crucial for developing more accurate and efficient monitoring devices and ML models. To address this gap, we present MmCows, a multimodal dataset for dairy cattle monitoring. This dataset comprises a large amount of synchronized, high-quality measurement data on behavioral, physiological, and environmental factors. It includes two weeks of data collected using wearable and implantable sensors deployed on ten milking Holstein cows, such as ultra-wideband (UWB) sensors, inertial sensors, and body temperature sensors. In addition, it features 4.8 million frames of high-resolution image sequences from four isometric view cameras, as well as temperature and humidity data from environmental sensors. We also gathered milk yield data and outdoor weather conditions. One full day's worth of image data is annotated as ground truth, totaling 20,000 frames with 213,000 bounding boxes of 16 cows, along with their 3D locations and

Figure 1: Sample 3D visualization of the MmCows multimodal sensing and four camera views.

behavior labels. An extensive analysis of MnCows is provided to evaluate the modalities individually and their complementary benefits. The release of MnCows and its benchmarks will facilitate research on multimodal monitoring of dairy cattle, thereby promoting sustainable dairy farming. The dataset and the code for benchmarks are available at https://github.com/neis-lab/mmcows.

## 1 Introduction

The dairy industry around the world is under strong sustainability pressure--environmentally, socially, and economically. Environmentally, massive consumption of clean water and energy and the waste produced by cattle threaten the environmental sustainability of the industry . At the same time, strong social pressure is placed on farmers to raise cattle in a more humane way . However, due to the low economic margin of the dairy industry, dairy farms tend to house more cows in large-scale facilities often with inadequate living conditions , making it even more challenging to carry out environment- and animal-friendly farming. These compounded problems also result in significant production losses which have been estimated at several billions of US dollars annually, along with excessive costs in energy and water usage, that increasingly and negatively affect dairy producers worldwide [4; 5; 6]. In short, the sustainability of the dairy industry depends on the maintenance of larger herds at minimal labor costs with low water and energy consumption, while keeping them healthy and stress-free.

Precision agriculture, or precision livestock farming (PLF) more specifically, has emerged as an effective solution to address these sustainability challenges in dairy farming . Powered by advances in sensing, computing, and communication technologies , PLF enables the monitoring of individual animals' behavior, physiology, and their social interaction in real time to quickly detect health problems and better track their diet, growth, and productivity [8; 5], allowing fine-grained monitoring and control of facilities . More recently, similar to many other application domains, PLF has seen a remarkable transformation with the advent of machine learning (ML) techniques [10; 11]. Combined with various sensing and computer vision techniques, several ML approaches have been proposed to monitor livestock animals. Examples include computer vision-based measurement of cow body weight  and detection of bovine respiratory diseases using wearable inertial measurement units (IMUs) .

With the rapid rise in the popularity of ML approaches and enabled by the increasing availability of low-cost high-quality sensors, a number of datasets of dairy cattle have been introduced. Each modality has different pros and cons in terms of accuracy, cost, animal friendliness, etc., and to determine the optimal modality or complementary modalities for a target application, a high-quality multimodal dataset is crucial. Unfortunately, existing dairy cattle datasets with only one or two sensing modalities do not meet the needs of recent ML research.

In this work, we present the MnCows dataset that leverages the complementary benefits of synchronized data from multiple modalities for accurate and efficient monitoring of dairy cattle. The dataset was collected from Holstein cows, which is the dominant breed of dairy cattle worldwide . MnCows also includes data related to the environment and milk yield, which can be used to provide a comprehensive understanding of behavior and physiological changes of the cattle over time. The contributions and unique aspects of the MnCows dataset are as follows:

* **Multiple sensing modalities:** MnCows is a large-scale fine-grained dataset of dairy cattle collected over a two-week period featuring multiple sensing modalities. The variety of modalities ranges from physiological and behavioral sensing to visual, environmental, and milk yield data. As ground truth, MnCows contains one day's worth of annotated visual data of 16 cows, including 20,000 isometric-view images with IDs and behavior labels.
* **Real-world data:** The data was collected from actual milking cows housed in the Agricultural Research Station at the University of Wisconsin-Madison. The deployment was carefully planned and executed without disrupting the cows' daily routine or negatively affecting their comfort to obtain physiological and behavioral data that is as natural as possible, similar to what can be observed at commercial dairy farms.
* **Comprehensive data and extensive benchmarks:** MnCows not only contains primary measurement data, but also various secondary processed data derived from it. We also present a comprehensive set of benchmarks that utilize both primary and secondary data for various applications of cattle monitoring.

## 2 Related Work

In this section, we discuss advanced sensing technologies that enable the collection of various data required for PLF, and the lack of suitable multimodal datasets required for ML research.

### Health monitoring of dairy cattle

Behavioral and physiological responses in dairy cattle are widely utilized in both research and practice for detecting health issues, and the monitoring of such responses is critical for the timely detection of various health conditions including heat stress, lameness, ketosis, mastitis, estrus, and calving.

Heat stress occurs when a cow's core body temperature exceeds the upper critical threshold of the thermal neutral zone, leading to behavioral changes . Cows experiencing heat stress tend to stand more to increase surface area for better cooling through convection [16; 17; 18]. They also reduce the number of meals per day to lower metabolic heat production [19; 20; 21; 22], and their milk production decreases as a result [23; 24; 25]. Additionally, cows under heat stress drink more frequently but in smaller amounts .

Lameness in dairy cattle is characterized by abnormal gait or movement due to pain or injury in the limbs or feet that significantly impacts well-being and productivity . Lame cows typically exhibit reduced daily feeding time and fewer feeding visits, coupled with an increased feeding rate [28; 29]. Accurate prediction of lameness was achieved by combining data on neck acceleration and milk production .

Ketosis is a metabolic disorder where energy demands exceed intake, that results in a negative energy balance, leading to rapid reductions in daily milk yield, feeding time, and feeding rate in affected cows [28; 31].

Mastitis, an inflammatory condition of the udder, is one of the most economically significant diseases in dairy cattle. Cows with mastitis show decreased feeding and ruminating time, alongside increased idle standing time .

Estrus and calving can be detected early through behavioral monitoring. Indicators of estrus include standing heat, intense physical activity, and mounting behaviors [33; 34]. Before calving, cows typically increase their daily step count and reduce lying and feeding time within the 24 hours leading up to calving [35; 36].

### Behavioral and physiological sensing of dairy cattle

Behavioral and physiological responses of dairy cattle have been widely used to detect health issues in research and practice. For behavior monitoring, the most common methods involve measuring cows' movements and locations. An accelerometer mounted on the neck or ankle provides useful information about a cow's body movements and postures [37; 38; 39; 40]. While this approach allows for accurate behavior inference, wearable devices can be relatively costly to deploy and maintain at scale. Cow location data also offers insights into their activities (such as feeding and drinking) and social interactions, typically using UWB or GPS for localization [41; 42; 43]. UWB provides precise locations but requires an infrastructure of stationary anchor devices, whereas GPS functions without such infrastructure but has relatively low accuracy, especially indoors. High-power consumption and the need for wearable sensors are drawbacks of both localization methods.

An increasingly popular solution for tracking cattle movement and location is ML-based vision processing. Various vision models have been proposed to identify individual cows [44; 45; 46] and to recognize behavior and posture . Vision models can also be applied for localization . The primary advantage of vision-based approaches is that they eliminate the need for wearable devices, which simplifies deployment and improves animal comfort. However, these methods are susceptible to changes in lighting conditions and physical obstructions.

One of the most critical physiological data is core body temperature (CBT) due to its relevance to animal behavior and health conditions, particularly heat stress [17; 49; 8; 50]. CBT can be measured using commercial temperature sensors inserted in the vagina or rectum, which is considered the conventional "gold standard" method [51; 52]. However, the insertion and retrieval process is very costly and stressful for both farmers and cows, and due to the depth of implantation, real-time measurement is not feasible. Ingestible boluses have been used to measure the reticulum temperature , but their measurement results can be affected by water and feed intake, making them unsuitable for precise CBT measurement. More recent studies have shown that subcutaneously injected temperature sensors can be used for real-time CBT measurement [54; 55; 56; 57], though they are not yet commercially available.

### Related datasets

As seen in Section 2.2, each sensing modality has different pros and cons in terms of accuracy, cost, animal friendliness, etc. To develop cattle monitoring devices and ML models that are accurate, cost-effective, and animal-friendly, a careful evaluation of different modalities or combinations of modalities must be performed, which requires an appropriate dataset. Table 1 compares various datasets developed for animal (cattle or swine) and human subjects.

For the monitoring of human subjects, which have been relatively well studied, several datasets are available for multimodal ML, including [58; 59; 60]. In these datasets, RGB images are the most common, and IMUs are also widely used to record joint movements. Other sensing modalities found in human datasets include heart rate, audio, depth, mmWave, etc. [58; 60; 61].

On the other hand, although many animal datasets are available for ML research, none of them were developed mainly for multimodal ML. As shown in Table 1, most datasets consist of RGB images, usually close-up top-view images that are useful for identification of the animals [65; 48; 66; 14; 68; 69; 62; 63; 64]. Other datasets contain IMU data for motion detection and behavior classification [67; 70] or UWB data for localization , but not both. Only one dataset  includes an additional modality, depth images, alongside traditional RGB images; however, both fall into the category of image sensing. As a result, these datasets are only suitable for developing and evaluating ML models for a certain modality and do not provide a way to compare different modalities and their combinations.

    & Datasets & \# of & Main modalities & \# of & \# of & Dura- & \# of & Annotation classes \\  & & modal. & UWB & IMU & RGB & cams. & frames & tion & subj. & ID & Behavior \\    } & Stanford-ECM  & 3 & - & ✓ & ✓ & 1 & - & - & 31h & 10 & - & 24 \\  & ActionSense  & 8 & - & ✓ & ✓ & 7 & 512k & 13h & 10 & - & 20 \\  & mRI  & 4 & - & ✓ & ✓ & 1 & 160k & 0.3h & 20 & - & 12 \\  & SALSA  & 5 & - & - & ✓ & 4 & - & 1h & 18 & - & - \\    } & PBVD-5  & 1 & - & - & ✓ & 1 & - & 8d & 9 & 9 & 5 \\  & Zhang et al.  & 1 & - & - & ✓ & 1 & - & 1.5h & 12 & - & 5 \\  & Bergamini et al.  & 2 & - & - & ✓ & 1 & 3.4M & 23d & 8 & 8 & 5 \\  & FriesianCattle2015  & 1 & - & - & ✓ & 1 & 764 & - & 92 & - & - \\  & FriesianCattle2017  & 1 & - & - & ✓ & 1 & 940 & 2h & 89 & - & - \\  & AerialCattle2017  & 1 & - & - & ✓ & 1 & 16k & 0.2h & 23 & 23 & - \\  & Ter-Sarkisov et al.  & 1 & - & - & ✓ & - & - & 14d & 10 & - & - \\  & DSCOW  & 1 & ✓ & - & - & - & - & 123d & 190 & - & - \\  & Rodriguez et al.  & 1 & - & ✓ & - & - & - & 28d & 20 & - & 7 \\  & OpenCows2020  & 1 & - & - & ✓ & 1 & 3.7k & - & 46 & - & - \\  & Cows2021  & 1 & - & - & ✓ & 1 & 10k & - & 186 & - & - \\  & Koskela et al.  & 1 & - & - & ✓ & 1 & 1.7M & 19h & - & - & 7 \\  & CowScreeningDB  & 1 & - & ✓ & - & - & - & 7h & 43 & - & - \\   & 9 & ✓ & ✓ & ✓ & 4 & 4.8M & 14d & 16 & 16 & 7 \\   

Table 1: Comparison of related datasets.

[MISSING_PAGE_EMPTY:5]

Holstein cows, ten of which are equipped with wearable sensors, described next. The cattle stay in the pen most of the time except for milking twice per day for approximately 30 minutes each time. All procedures were performed with the approval of the Institutional Animal Care and Use Committee (IACUC) of the University of Wisconsin-Madison (Protocol #A006606).

**Neck-mount tag (uwb, immu, pressure).** We designed a wearable neck-mount tag to measure individual cows' locations and behavior. Figure 3 shows the tag's PCB and how it is mounted on the cow. The tag consists of (1) the Qorvo DW3000 UWB module for measuring distances from the tag to eight stationary UWB anchors, which are used to derive 3D neck location of the cow, (2) the TDK ICM-20984 IMMU that measures acceleration and magnetic field, and (3) the Bosch BMP390 air pressure sensor for measuring elevation. To minimize measurement noise, the UWB, the accelerometer inside the IMMU, and the pressure sensor are configured to perform oversampling at rates of 5x, 16x, and 8x, respectively. Refer to Table 2 for the sampling configurations. The tag, along with a 1.9-Ah lithium battery, is enclosed in a water-proof casing with an air-permeable hole for air pressure measurement. As shown in Figure 4, eight UWB anchors are installed at a height of 5 m to enable 3D spatial measurements. Ten of these tags are attached to ten cows (Cow 1 through Cow 10) out of a group of 16. Two additional tags are mounted in stationary positions around the pen to record data as reference points.

**Vaginal temperature sensor (cbt).** Each of the same ten cows is equipped with an Onset HOBO U12-15 temperature logger, inserted in their vagina to measure the vaginal temperature, which is considered the CBT of the cows.

**Ankle sensor (ankle).** As a common approach to detecting lying behavior, we attached an Onset HOBO Pendant G ankle sensor to the left hind leg of the same cows. This sensor measures the direction of gravity, which allows us to infer the orientation of the leg.

**Cameras (rgb).** Four GoPro HERO11 Black cameras are mounted at four corners of the pen, directed toward the center, as shown in Figure 4. The cameras record 4480\(\)2800 (4.5K) videos at 1 fps, providing isometric views of the pen instead of top views, which are more common in many datasets. Detection and identification tasks become much more challenging with isometric-view images, but

Figure 4: Top-view map of the pen with installation locations of the UWB anchors, cameras, and microclimate sensors.

Figure 3: (a) Top and (b) bottom view of the wearable neck-mount tag with UWB, IMMU, and pressure sensor. (c) Water-proof enclosure with a battery. (d) The tag is mounted at the top of the neck using a neck halter.

this setup is more common in commercial barns as it provides wider visibility. We do not add any additional lighting to reduce motion blur, in order to maintain the same barn environment.

**Indoor microclimate (thi) and outdoor weather (weather).** The ambient temperature and relative humidity (RH) are used to infer the Temperature-Humidity Index (THI) , and are measured by six Onset HOBO Pro v2 temperature/RH loggers deployed as shown in Figure 4. The outdoor weather conditions are recorded every 5 minutes by a weather station located 950 m northeast of the experimental site, which includes dew point, precipitation, sunlight intensity, wind speed and direction, etc.

**Milk yield record (milk).** The dataset also contains the daily milk yield in kg and the health checkup records of all 16 cows prior to and after the experiment, which are recorded by the barn staff.

**Secondary data.** We generate secondary data based on the collected primary data. Secondary data in MmCows includes head direction (hd) from IMMU, and lying/non-lying classification (lnl) using the ankle sensor data. The processing pipeline for secondary data generation is illustrated in Figure 5. Note that this pipeline is only an example used in this paper, and the dataset can be used in different processing pipelines for various applications.

**Sensor calibration.** Ten UWB modules in the tags and eight UWB anchors are pairwise calibrated from 0 to 18 m using a linear calibration model. The accelerometer in the IMMU is also separately calibrated using linear offset, and the magnetometer is calibrated for hard and soft iron biases . The MCU stores the calibration parameters and corrects the measurements of the IMMU in real time, while the pressure sensor is programmed to perform self-calibration upon powering on.

**Sensor synchronization.** Each neck tag is equipped with the Analog Devices DS3231 real-time clock to maintain its local time. The local time of all neck-mounted tags is synchronized with Internet time every 30 minutes through a stationary hub using UWB communication. The hub contains a Raspberry Pi 4 connected to the Internet to retrieve and retain the Internet time. In other words, the timestamps of all data collected by different sensors in the tags are synchronized with Internet time. Every 15 seconds, the tags synchronously perform distance measurements one by one in succession to prevent packet collisions when using the same wireless channel.

### Ground truth

#### 3.2.1 Ground truth for cow identification and behavior classification

The ground truth of cow IDs and behaviors is manually created using the vision data. The UWB-synced RGB frames from July 25(tm) are used for the annotation. We manually annotated 20,000 images to produce 213,000 bounding boxes for all 16 cows. When the cows are lying in the stalls, their bodies are often heavily occluded by one another, making identification more challenging. Thus, we separate the bounding box labels of cows into three sets: lying, non-lying, and combined labels. The annotators were trained to follow our comprehensive annotation rules to ensure consistency.

Figure 5: The data processing and benchmarking pipeline of MmCows in this paper. MmCows can be used in different processing pipelines for different applications.

The correctness of cow ID annotation was automatically verified using visual localization, which is elaborated in Section 3.2.2, and was also manually verified during the process of behavior labeling. Details of the annotation rules are provided on the dataset website.

We manually created the behavior ground truth of 16 cows at the granularity of one-second intervals, where each behavior label of the cow is associated with a timestamp. The synchronization of RGB frames from four cameras ensures that for each given timestamp, each cow performs the same behavior in all camera views. We use seven behaviors of individual cows, including walking, standing, feeding head up, feeding head down, licking, drinking, and lying, which are commonly used in various cattle behavior monitoring studies discussed in Section 2.1. Details of behavior definitions and visual examples are available in the supplementary document.

#### 3.2.2 Visual localization and location ground truth

To provide reliable ground truth for cows' locations, we propose a new optimization-based approach to calculate body location using the annotated bounding boxes from multiple views. We first project the bounding box centers of the same cow across multiple views into the world coordinate system as 3D lines that inherently converge in space. We then apply AdaGrad  to find the optimal location that is nearest to the lines, which serves as the cow's location in 3D. This location can be used as ground truth for developing vision-based localization models. More details are provided in the supplementary document.

As an additional step to ensure the correctness of the ID annotation process, for each location, we calculate the distance from that location to its corresponding projection lines. Any line that is irregularly far from the visual location is flagged as an outlier, indicating that the cow's ID has been incorrectly annotated, which is subsequently corrected until all projection lines converge.

## 4 Evaluation and Benchmarks

For the evaluation of MaCows, we conduct a two-stage benchmarking process. In the first stage, to show how the multimodal dataset can be used for system design, we compare different modalities for the behavior classification task. In the second stage, we perform a high-level behavior analysis to show how MaCows can be used for automated dairy barn management. As this section only briefly introduces the results, we discuss them in more detail in the supplementary document.

### Modality comparison for behavior classification

**Setting.** To avoid data leakage, we consider two data split settings: object-wise split (OS) and temporal split (TS). The OS setting evaluates cross-cow generalization, while the TS setting assesses robustness on unseen data. For uwb and immu, data from ten cows with tags is used, and both OS and TS settings are applied. For rgb, data from all 16 cows is used, and only the TS setting is applied since data from all cows is required to train the identification models.

In the OS setting, we use 5-fold cross-validation to train models, with the ratio of cows for training, validation, and testing set to [6:2:2]. The selection of cows is rotated so that each cow appears in the test set exactly once.

In the TS setting, data from each modality is separated into two groups based on the lighting conditions. The first group contains data with artificial light, recorded between 3am-6am and 6pm-12am. The second group contains data with natural light, recorded between 6am-6pm. Each group is divided equally and temporally into five segments, resulting in ten segments. We apply 5-fold cross-validation, where from each group, the ratio of segments for training, validation, and testing is set to [3:1:1]. The two groups are concatenated in the configuration [6:2:2]. Validation is performed until each segment has been tested once.

**Metric.** Cows often spend substantial amounts of time lying, feeding, and standing, but only seldom engaging in walking, drinking, or licking. Since the behavior classes are heavily imbalanced and the minority classes are also important, we use the F1 score to evaluate the results. An average F1 score is reported for each setting.

**Methods.** We perform behavior classification using uwb, immu, rgb, and some combinations of them with hd and ankle. We selected three specific combinations of modalities to demonstrate the benefits

[MISSING_PAGE_FAIL:9]

classification over 13 days with respect to THI (excluding the first and last days that are shorter than 24 hours).

**Metric.** We use the Pearson correlation coefficient (\(r\)), \(p\)-value, and \(R^{2}\) to evaluate the relationship between variables. The \(r\) value helps to identify the strength and direction of the relationship; the \(p\)-value determines the statistical significance, and \(R^{2}\) indicates the proportion of variability explained by the THI.

**Method.** We use UWB+HD+Akl to perform inference on 2-week-long data to extract seven behaviors of ten cows. Feeding head up and head down behaviors are combined as feeding. To obtain an accurate number of bouts for each behavior, we use a custom filter to remove momentary switching between classes.

**Results and discussion.** We confirm significant correlations between the cows' behavior and THI as reported in Table 4. All behaviors are strongly affected by THI, indicated by the very small \(p\)-values and high \(R^{2}\) values. The results agree with previous studies on THI-dependent changes in cattle behavior [16; 17; 18; 76; 77; 78; 79]. The results show the effectiveness of behavior monitoring in assessing cattle health status, such as heat stress.

## 5 Conclusion

MnCows is the first multimodal dataset for dairy cattle monitoring, comprising nine modalities and records. It integrates wearable, implantable, visual, and environmental data collected from 16 milking Holstein cows in a real-world barn over two weeks. This paper describes the creation of this dataset and demonstrates its potential benefits for developing monitoring devices and ML models. The true potential of MnCows lies in the numerous combinations of modalities that have yet to be explored, which can contribute to designing high-accuracy, low-cost, and animal-friendly monitoring systems. We envision MnCows being leveraged for a variety of future endeavors, to promote environmentally, socially, and economically sustainable dairy farming.