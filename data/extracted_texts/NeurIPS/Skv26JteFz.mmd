# Optimal Hypothesis Selection in (Almost) Linear Time

Maryam Aliakbarpour

Department of Computer Science

Rice University

Houston, TX 77005

maryama@rice.edu

&Mark Bun

Department of Computer Science

Boston University

Boston, MA 02215

mbun@bu.edu

&Adam Smith

Department of Computer Science

Boston University

Boston, MA 02215

ads22@bu.edu

###### Abstract

Hypothesis selection, also known as density estimation, is a fundamental problem in statistics and learning theory. Given a sample set from an unknown distribution \(P\) and a finite class of candidate distributions (hypotheses) \( H_{1},H_{2},,H_{n}\), the goal is to design an algorithm that selects a distribution \(\) from \(\) that best describes \(P\). The accuracy of the algorithm is measured by the distance between \(\) and \(P\), compared to the distance between the closest distribution in \(\) and \(P\) (denoted by \(\)). Specifically, we aim for \(\|-P\|_{}\) to be at most \(+\) for some small \(\) and \(\).

While the value of \(\) can be reduced with an increasing number of samples, \(\) is an inherent characteristic of the algorithm. Achieving \(<3\) is impossible, even with only two candidate hypotheses, unless the number of samples is proportional to the domain size of \(P\)[Bousquet, Kane, Moran '19]. Finding a computationally efficient algorithm that achieves the optimal \(\) has been a primary focus of research since the early work of [Devroye, Lugosi '01]. Before our work, the algorithms achieving \(<5\) required time \((n^{2})\). We present the first algorithm that operates in almost linear time (\((n/^{3})\)) and achieves \(=3\). This result improves upon a long line of hypothesis selection research. Previously known algorithms had either worse time complexity, a larger \(\) factor, or additional assumptions about the problem setting. Additionally, we provide another (almost) linear-time algorithm with better dependency on the additive accuracy parameter \(\), albeit with a slightly worse accuracy parameter of \(=4\).

## 1 Introduction

Hypothesis selection, also known as density estimation, is a fundamental problem in statistics and learning theory. This problem involves identifying a density function that accurately represents the distribution of a given dataset. Suppose we are given a dataset of samples drawn from an unknown distribution \(P\) and a finite class of known distributions, representing different hypotheses: \(\{H_{1},H_{2},,H_{n}\}\). The goal is to select a distribution in \(\) that is close to \(P\) in total variation (TV) distance.

Typically, learning a distribution over a domain \(\) with an \(\) error in TV distance requires \((||/^{2})\) samples, which presents a substantial lower bound in sample complexity for distributions over largedomains. Surprisingly, the findings of Yatracos, Devroye, and Lugosi revealed that for hypothesis selection, this sample complexity can be independent of the domain size and only logarithmic in the number of hypotheses . With just \(s( n/^{2})\) samples from \(P\), it is possible to learn \(P\) within error \(+\), where \(\) denotes the distance of the nearest distribution in \(\) to \(P\). Specifically, Devroye and Lugosi introduced two algorithms for this problem: the Scheffe tournament, which operates in \(O(n^{2} s)\) time1 and achieves \(=9\); and the minimum distance estimate, which runs in \(O(n^{3} s)\) time and achieves \(=3\)[15, Chapter 6]. In these results, although \(\) can be decreased as the number of samples increases, \(\) remains an inherent parameter of the algorithm.

Significant effort has been directed towards finding computationally efficient algorithms for this problem while maintaining sample efficiency. The trade-off between the accuracy parameter \(\) and computational efficiency has been a focal point. Mahalanabis and Stefankovic in  enhanced the minimum distance estimate, improving the time complexity to \(O(n^{2} s)\). They also introduced a nearly linear-time algorithm that achieves \(=3\), but requires exponential time in \(n\) for preprocessing the class \(\). Other nearly linear-time algorithms were developed achieving \(=9\) in \(^{+}18\), \(^{+}23\)2 and \(=5\) in . Furthermore, linear-time algorithms have been presented under the assumption that the algorithm receives the value of \(\) (or its upper bound) as input . However, achieving \(<3\) is not possible unless the number of samples becomes \((||)\), as indicated in .

Despite the long-standing history of this problem, the following question remained open:

_Is there an algorithm for hypothesis selection with the optimal number of samples \(s=O((n)/^{2})\) and optimal accuracy parameter \(=3\) that runs in \(O(n s)\) time?_

We present the first almost linear-time algorithm that uses the optimal number of samples and achieves the optimal accuracy parameter \(=3\). Our algorithm runs in \((n s\ /\ )\) time (see Theorem 2). Additionally, we introduce another algorithm with improved dependency on \(\), running in \((n s)\) time while obtaining a slightly higher accuracy parameter, \(=4\) (see Theorem 3). Our results represent a significant step forward, as they are the first in decades to achieve time complexity linear in \(n\) for any \(<5\). See Table 1.

Applications of Hypothesis SelectionThe primary application of hypothesis selection is to identify the best distribution from a set of known models that represent potential underlying data distributions we can effectively manage. For example, this set might include Poisson, gamma, and binomial distributions with various parameters used to model the number of arrivals per time unit. This makes hypothesis selection applicable to tasks like interpretable distribution selection and strategy optimization, where the objective is to choose the most suitable model from available options.

Another key strength of hypothesis selection is its agnostic nature, allowing it to adapt even when the true distribution lies outside the considered class. This robustness makes it effective in noisy data settings, with applications in denoising and anomaly detection. From a theoretical standpoint, hypothesis selection is fundamental in learning structured distributions, particularly when combined with the cover method, as seen in learning mixtures of Gaussians . For additional references, see Section 1.3.

Importance of improving \(\) by a constant factorIn most learning algorithms, the error guarantee decreases polynomially as the number of samples increases, so constant factors may not be as crucial. However, this is not the case in hypothesis selection. The output hypothesis is guaranteed to be \((+)\)-close to \(P\) in total variation distance. While increasing the number of samples can reduce \(\) to negligible levels, it does not improve the term \(\). Hence, \(\) is an inherent property of the algorithm and directly impacts the best achievable error guarantee. Therefore, even a constant improvement in \(\) is significant.

One might argue that, alternatively, \(\) could be reduced by carefully curating the class \(\). However, beyond the practical challenges of finding a better \(\), it is unclear whether this can be achievedwithout significantly increasing the size of the hypothesis class \(\). For example, in the cover method, when aiming to learn a distribution within a class \(\), we set \(\) to be a \(\)-net that serves as a cover for \(\), ensuring that \(<\). While using a finer \(\)-net can reduce \(\), it may also drastically increase the size of \(\), thereby increasing the algorithm's running time, since the size of the net can grow super-polynomially with respect to \(\). For instance, in the case of mixtures of \(k\) Gaussians, the size of the net depends on \(\) as roughly \(O(^{-3 k})\) (see ). Thus, reducing \(\) by a factor of three could exponentially increase the size of \(\) in terms of \(k\), thereby increasing both the running time and sample complexity, ultimately resulting in an inefficient algorithm.

### Problem Setup

Suppose we have an _unknown_ distribution \(P\) over a domain \(\) and a set of \(n\)_known_ distributions \(\{H_{1},H_{2},,H_{n}\}\). Let \(\) denote the distance between \(P\) and the closest distribution to it in \(\)3: \((,P)_{H}\|H-P\| _{}.\) We use the standard access model for this problem as introduced in . The algorithm accesses the distributions through the following types of queries:

1. The algorithm can request a sample from the unknown distribution \(P\).
2. The algorithm can compare the PDF of two known distributions: For every domain element \(x\) and every pair of indices \(i\) and \(j\), it can ask if \(H_{j}(x)<H_{i}(x)\). This is equivalent to asking if \(x\) is in the Scheffe set of \(H_{i}\) and \(H_{j}\) (defined in Equation (2)).
3. The algorithm can query the probability mass of the Scheffe sets according to all the known distributions.

**Remark 1**.: _The last requirement of our model can be relaxed. Only estimates of the probability masses of the Scheffe sets are needed for our algorithms. Thus, one can alternatively assume sample access to \(H_{i}\)'s, and estimate these values via samples._

**Definition 1.1** (Proper learner for hypothesis selection).: _Suppose algorithm \(\) is given parameters \(,(0,1)\), \(_{>0}\) and has access to an unknown distribution \(P\) and a class of \(n\) known distributions \(\) (as described above). We say \(\) is an \((,,)\)-proper learner for the hypothesis selection problem if for every \(P\) and \(\), \(\) outputs \(\) for which, with probability at least \(1-\),_

\[\|-P\|_{}(,P)+\,.\] (1)

  
**Result** & \(\) & **Time Complexity** & **Additional requirement** \\   Min distance estimate  & 3 & \(O(n^{3} s)\) \\  Scheffe tournament  & 9 & \(O(n^{2} s)\) \\  Min distance estimate  & 3 & \(O(n^{2} s)\) \\   AJOS14, AFJ\({}^{+}\)18] & 9 & \((n s)\) \\  ABS23] & 5 & \((n s)\) \\  AAC\({}^{+}\)23] & 9 & \(O(n s/ n)\) \\   MS08] & 3 & \(O(n s)\) & Exponential time preprocessing \\  DK14, ABS23] & \( 3\) & \((n s)\) & Assume knowledge of \(\) \\  Lower bound  & Achieving \(<3\) requires \((||)\) samples \\   This work:Algorithm 1 & 3 & \((n s/\,)\) \\  This work: Algorithm 4 & 4 & \((n s)\) \\   

Table 1: Summary of Past Results in Hypothesis Selection. All algorithms use \(s=( n/^{2})\) samples.

_We refer to \(\) as the accuracy parameter, \(\) as the error (or proximity) parameter, and \(\) as the confidence parameter of the algorithm._

### Main theorems

Below, we provide informal versions of our theorems.

**Theorem 2**.: _For every \(,(0,1)\), Algorithm 1 is an \((=3,,)\)-proper learner for hypothesis selection that uses \(s=O((n/)/^{2})\) samples and time \((n s\ /\ (^{3}))=(n/(^{3} ^{3}))\)._

**Theorem 3**.: _For every \(,(0,1)\), Algorithm 4 is an \((=4,,)\)-proper learner for hypothesis selection that uses \(s=O((n/)/^{2})\) samples and time \((n s(1/))=(n^{2}(1/)/ ^{2}))\)._

For formal statements, see Theorem 5 (Appendix A) and Corollary B.1 (Appendix B).

Our results are the first to achieve time complexity linear in \(n\) for any \(<5\). To achieve this, we introduce novel algorithmic techniques that will hopefully be broadly useful--see Section 3 for an overview. Both algorithms use the optimal number of samples. The first algorithm obtains optimal accuracy parameter \(=3\) with a time complexity of \((n/(^{3}\,) s)\), which is off by an \(O(1/(^{3}\,))\) factor. Our second algorithm achieves the optimal time complexity up to logarithmic factors while achieving a slightly higher \(=4\). Our results leave a fascinating open question: Can one combine the best aspects of both algorithms, maintaining \(=3\), achieving \(O(n s)\) time (or even lower), and sample complexity \(s=O((n/)/^{2})\)?

**Remark 4**.: _Readers may be surprised by the polynomial dependence on \(1/\) in Theorem 2. In many settings, the success probability of a learning algorithm can be amplified from a constant, say 2/3, to at least \(1-\) at a cost of at most \((1/)\) in running time and sample complexity. However, in hypothesis selection, there is no (known) general technique for boosting the confidence parameter while keeping \(\) the same. The issue is that choosing the best output from several runs of a given algorithm requires executing a second hypothesis selection algorithm, which introduces another factor of \(\) in the approximation--leading to a total factor of at least \(9\). As a result, these kinds of two-phase algorithms are not sufficient in the low \(\) regime. Some previous results, such as , also suffer from a polynomial dependency on \(\)._

### Other related work

Hypothesis selection has been studied in various settings including improper setting. In , the authors consider the improper version of the problem where the output hypothesis \(\) may not necessarily be in \(\). They presented an improper learner with accuracy guarantee \(=2\). The sample complexity of their algorithm was improved by , who gave an algorithm with nearly optimal sample complexity and the same accuracy parameter \(=2\). It is worth noting that our algorithms are proper learners and solve this problem with a slightly better sample complexity. In addition, like other proper learners, our algorithms select their output from a predefined set, which can facilitate choosing a distribution with specific structural property (e.g., mixture of Gaussians). In certain applications, this selection ensures consistency with the problem's underlying assumptions, which enhances interpretability and robustness.

The problem of hypothesis selection in _sublinear time_ was studied for distributions on _discrete domains_. Among other results, the authors developed a data structure that upon receiving samples from a unknown distribution \(P\) returns a hypothesis \(\) in \(o(n)\) time. While their algorithm runs in sublinear time, their sample complexity depends on the domain size of the distribution, and their setting allows pre-processing of the class \(\) in polynomial time. Another interesting variation for hypothesis selection is designing differentially private learners for the problem which has received attention over the past few years .

An important application of hypothesis selection arises when there is a structural assumption on the underlying distributions. One approach for learning these classes is to selectively choose a _cover_ for the class. One can then use the learners for the standard hypothesis selection problem (which we study in the paper) and use the cover as the class \(\). Examples of such structural assumptions include Poisson binomial distributions , mixtures of Gaussians , distributions with piecewise polynomial PDFs , and histograms . See Diakonikolas  for a survey of results.

Preliminaries

Notation:We use the following notation throughout this article. We use \([n]\) to indicate the set \(\{1,2,,n\}\). For a distribution \(Q\) over \(\), \(Q(x)\) denotes the PDF of \(Q\) at the domain element \(x\). For any measurable subset of the domain \(S\), \(Q(S)\) indicates the probability mass of the set \(S\) according to \(Q\). We use \(\|Q_{1}-Q_{2}\|_{}_{S}|Q_{1}(S)-Q_ {2}(S)|\) to denote the total variation distance between \(Q_{1}\) and \(Q_{2}\). We say \(Q_{1}\) is \(\)-close to \(Q_{2}\) if \(\|Q_{1}-Q_{2}\|_{}\) is at most \(\). Conversely, we say \(Q_{1}\) is \(\)-far from \(Q_{2}\) if \(\|Q_{1}-Q_{2}\|_{}\) is greater than \(\). We use the standard \(O,,\) notation for asymptotic functions. Additionally, we use \(\), \(\), and \(\) to hide \(\) factors.

Scheffe sets:For every pair of hypotheses \(H_{i}\) and \(H_{j}\) in \(\), we define the Scheffe set of \(H_{i}\) and \(H_{j}\) as follows:

\[_{i,j}\{\{x H_{ i}(x)<H_{j}(x)\}&\\ _{j,i}&.\] (2)

It is known that the Scheffe set maximizes the probability discrepancy between \(H_{i}\) and \(H_{j}\), thus fully characterizing the total variation distance between the two distributions:

\[\|H_{i}-H_{j}\|_{}=_{S}|H_{i}(S)-H_{j}(S) |=|H_{i}(_{i,j})-H_{j}(_{i,j})|\.\] (3)

The optimal hypothesis:Recall that we assume the algorithm is given samples drawn from an unknown distribution \(P\). Let \(H_{i^{*}}\) denote the closest hypothesis in \(\) to \(P\). That is, \(H_{i^{*}}\) is the hypothesis for which \(\|H_{i^{*}}-P\|_{}=\). When there is more than one hypothesis with this property, we pick one arbitrarily as \(H_{i^{*}}\).

Semi-distances:For every pair \(i,j\) in \([n]\), we define \(w_{j}(H_{i})\) to be \(|H_{i}(_{i,j})-P(_{i,j})|\). In words, \(w_{j}(H_{i})\) is the distance of \(H_{i}\) to \(P\) observed on the Scheffe set of \(H_{i}\) and \(H_{j}\). For every pair \(i,j[n]\), we use \(_{j}(H_{i})\) to denote an estimate of \(w_{j}(H_{i})\) based on the observed sample. For the sake of consistency, we define \(w_{i}(H_{i})\) to be zero. In addition, we define the score function \(W(H_{i})_{j[n]}w_{j}(H_{i})\). Similarly, \((H_{i})\) is defined to be \(_{j[n]}_{j}(H_{i})\).

Refined access model:Similar to previous work , we use estimates of the semi-distances. One can easily estimate these quantities, denoted by \(_{j}(H_{i})\), via the access model we have described earlier by letting \(_{j}(H_{i})\) be the empirical ratio of the samples that are in \(_{i,j}\). Throughout this paper, we assume that there are two universal parameters \(^{}=()\) and \(^{}=()\), for which with probability \(1-^{}\) every \(_{j}(H_{i})\) is within \(^{}\) of \(w_{j}(H_{i})\):

\[ i,j[n]:|_{j}(H_{i})-w_{j}(H_{i})|^{}.\]

A simple application of the Hoeffding bound and the union bound shows that one can compute all of the estimates via \(s=O((n/^{})/{^{}}^{2})\) samples, and each estimate can be computed in \(O(s)\) time.

Our algorithms access the distributions in \(\{P\}\) only via querying \(_{j}(H_{i})\). This fact brings the sample complexity of our algorithms to \(s=O((n/^{})/{^{}}^{2})\) samples. The time complexity of our algorithms is determined by the number of queries they make to the \(_{j}(H_{i})\)'s, multiplied by time that we spend on each query, \(O(s)\). Moreover, in the proofs of our theorems, we assume without loss of generality that all the \(_{j}(H_{i})\)'s are accurate. Conditioning on the accuracy will not decrease the probability of correctness of any of our algorithms by more than \(^{}\) due to Fact C.1.

## 3 Overview of our techniques

In this section, we provide a high-level discussion of our algorithm. The important notations and definitions used here are provided in Section 2. For the high-level discussions in this section, we assume we have access to the exact values of the semi-distances \(w_{j}(H_{i})\). In the formal proofs presented in subsequent sections, we will substitute each \(w_{j}(H_{i})\) with an estimated value \(_{j}(H_{i})\)If the error of these estimates is below \(^{}=()\), it can be shown that the overall impact of this substitution on our final distance guarantee (Equation 1) is at most \(()\). See the "Refined access model" in Section 2 for further details.

### Background: Semi-distances and the minimum distance estimate

To solve the hypothesis selection problem, we seek a _certificate_ that ensures we output a hypothesis \(\) such that \(\|-P\|_{}\) is at most \(3\)\(\). Similar to previous work, our algorithms operate based on the probability masses of the _Scheffe sets_ (Equation (2)) of pairs of hypotheses in \(\). The semi-distance \(w_{j}(H_{i})\), defined as \(|H_{i}(_{i,j})-P(_{i,j})|\), captures the "distance" between \(H_{i}\) and \(P\) as measured on this particular set \(_{i,j}\). One suggestion for readers to internalize the semi-distances is to view them as a distance between \(H_{i}\) and \(P\) that is measured from the perspective of \(H_{j}\). By definition, \(w_{j}(H_{i})\) is always a lower bound for \(\|H_{i}-P\|_{}\):

\[w_{j}(H_{i})|H_{i}(_{i,j})-P(_ {i,j})|_{S}|H_{i}(S)-P(S)|=\|H_{i}-P\|_{ }.\]

However, it is possible for \(w_{j}(H_{i})\) to be much lower, making it difficult for an algorithm to estimate the TV distance between \(H_{i}\) and \(P\) just using semi-distances.

Nevertheless, for each hypothesis \(H_{i}\), a specific semi-distance \(w_{i^{*}}(H_{i})\), associated with the optimal hypothesis \(H_{i^{*}}\), determines its quality. As shown in the following proof, if \(w_{i^{*}}(H_{i})\), then \(H_{i}\) is \(3\), \(\)-close to \(P\), with the total variation distance between \(H_{i}\) and \(P\) bounded by \(w_{i^{*}}(H_{i})\) and \(\) via the triangle inequality:

\[\|H_{i}-P\|_{} \|H_{i}-H_{i^{*}}\|_{}+\|H_{i^{*}}-P\|_{}= |H_{i}(_{i,j})-H_{j}(_{i,j})|+ \] (By Eq. 3 ) \[ w_{i^{*}}(H_{i})+w_{i}(H_{i^{*}})+ w_{i^{*}} (H_{i})+2\,.\]

This observation implies that if we assert that \(w_{i^{*}}(H_{i})\) is bounded by \(\), we can output \(H_{i}\) as our final solution to the problem and be done. The challenge is that we neither know \(i^{*}\) nor \(\).

This issue is addressed by the _minimum distance estimate_ presented in  using a score function \(W(H_{i})\), as defined earlier: \(W(H_{i})_{j[n]}w_{j}(H_{i})\). The minimum distance estimate outputs a hypothesis \(\) that minimizes \(W(H_{i})\). We can assert that, for the output of this algorithm, \(\), \(w_{i^{*}}()\) is at most \(\). This approach simultaneously bypasses the issues of not knowing \(i^{*}\) and \(\).

Note that \(W(H_{i})\) serves as a proxy for the quality of \(H_{i}\) since \(W(H_{i})\) is an upper bound for \(w_{i^{*}}(H_{i})\). Using \(W(H_{i})\), we can address the issue of not knowing \(i^{*}\). On the other hand, although \(\) is not known, we have a good lower bound for \(\), which is \(W(H_{i^{*}})\). Putting these observations together, we obtain:

\[\|-P\|_{} w_{i^{*}}()+2\, W()+2\, W(H_{i^{*}})+2\, 3\,.\]

These inequalities are derived using the triangle inequality and the fact that \(\) was chosen to be the \(_{i[n]}W(H_{i})\). See Figure 1 for an illustration of the above inequality.

The primary hurdle with the minimum distance estimate is that it is costly to compute. Computing each \(W(H_{i})\) takes \(O(n s)\) time, bringing the total time complexity of the algorithm to \(O(n^{2} s)\). One might naturally conjecture that sampling may help to compute an estimate of \(W(H_{i})\). Instead of using \(W(H_{i})_{j[n]}w_{j}(H_{i})\), we can use \((H_{i})_{j R}w_{j}(H_{i})\) where \(R\) is a set of random indices in \([n]\). The issue with this approach is that there is no guarantee of \(i^{*}\) being selected in \(R\), making \((H_{i})\) too low while \(H_{i}\) may be far from \(P\). Hence sampling, if used in a trivial manner, is not beneficial.

### The algorithm with \(=3\)

In this section, we present an overview of Algorithm 1 that attains \(=3\). The details of this algorithm and its related theorems are provided in Section A. At a high level, similar to the minimum distance estimate, we work towards finding a hypothesis that minimizes \(W(H_{i})\). To increase efficiency, we work with estimates of \(W(H_{i})\)'s, denoted by \((H_{i})\). The general structure of our algorithm is as follows: Initially, all \((H_{i})\) are set to zero. At every step, we come up with several pairs of hypotheses \(H_{i}\) and \(H_{j}\) and update our estimates by setting \((H_{j})\) to \(((H_{j}),w_{i}(H_{j}))\). Our approach ensures that at every step, \((H_{i})\) is equal to \(_{j R}w_{j}(H_{i})\) for a small, carefully chosen set \(R\). Eventually, we output a hypothesis with roughly the smallest \((H_{i})\).

Focusing on small \(\):Our first idea is to focus on updating the \(\) for hypotheses whose \((H_{i})\) values are around the current minimum \(\). The rationale for this action comes from a simple fact: \((H_{j})\) always underestimates the value of \(W(H_{j})\). Hence, if we observe that \((H_{i})\) is substantially larger than the current minimum, then \(W(H_{i})\) is also substantially larger than the current minimum. This implies that \(H_{i}\) is not a suitable candidate for the minimum at this stage of the algorithm, and it can be ignored for now.

Bucketing hypotheses based on \(\):To implement this idea, we partition the hypotheses into \(k=(1/^{})\) buckets \(\{B_{1},B_{2},,B_{k}\}\) based on \((H_{i})\). The bucket \(\) contains all the hypotheses \(H_{i}\) such that \((H_{i})[(-1)^{},\,^{})\). At every step, we focus on the smallest non-empty bucket \(B_{}\) (the smallest \(\) for which \(|B_{}| 0\)). \(B_{}\) contains all the hypotheses whose \((H_{j})\) is around the minimum \(\). We pick pairs of hypotheses, \(H_{i}\) and \(H_{j} B_{}\), and update \((H_{j})\). Note that our updates may increase \((H_{j})\), and we may remove \(H_{j}\) from \(B_{}\) and put it into a larger bucket (a bucket with a larger index \(\)). Also, observe that we never move a hypothesis into a smaller bucket since \((H_{j})\) never decreases. We continue our updates to reach one of the following outcomes:

* \(B_{}\) becomes empty. That is, our updates made all \((H_{i})\) fall out of the range of these buckets \([0,\,^{})\). Thus, every \((H_{i})\) (and consequently every \(W(H_{i})\)) is at least \(^{}\). Every time that we empty out a bucket, we have increased our threshold for minimum \(W(H_{i})\) by \(^{}\). Hence, we are getting closer to a bucket with the true minimum, which we hope to reach in \(O(1/^{})\) steps.
* \(B_{}\) is not empty, but we can confidently confirm most of the hypotheses in \(B_{}\) are an acceptable output for the algorithm. Although we cannot ensure that \(H_{i^{*}}\) is indeed in \(B_{}\), we can find an acceptable final answer by selecting a random hypothesis in \(B_{}\).

Which pairs to update?Next, we outline our update scheme to implement the above ideas in linear time. To enhance time efficiency, our aim is to optimize the updating process to ensure both _quality_ and _quantity_ in the chosen updates. Quality, in this context, relates to the extent of change in \((H_{j})\) following an update: We consider \(H_{i}\) to have made a _substantial update_ to \(H_{j}\) if \((H_{j})+^{}<_{j}(H_{i})\). Such updates cause a significant shift, increasing the value of \((H_{j})\) by more than \(^{}\) and subsequently moving \(H_{j}\) to a different bucket with a higher index \(\). We refer to this event as \(H_{i}\)_removing_\(H_{j}\) from its bucket. The quantity, on the other hand, relates to the number of \(H_{j}\) instances that a given \(H_{i}\) can remove from \(B_{}\). An ideal \(H_{i}\) eliminates a substantial portion of hypotheses from \(B_{}\) (say a constant fraction). We call such an \(H_{i}\) a _prompting hypothesis_. Now, if for \(O(|B_{}|)\) rounds we find a prompting hypothesis and update all the \((H_{j})\) for \(H_{j} B_{}\), we will empty out the bucket \(B_{}\), and we can move forward.

Finding a prompting hypothesis:To find a prompting hypothesis quickly, we iterate over all \(H_{i}\) in \(\), sample a few \(H_{j}\), and check if \(H_{i}\) substantially updates \((H_{j})\). If \(H_{i}\) substantially improves a large fraction of the sampled hypotheses, then we declare that \(H_{i}\) is a prompting hypothesis. See Section A.1.1 for further details. In addition to that, we provide a more advanced version of this procedure in Section A.1.2 that allows us to shave off an \(O( n)\) factor.

Getting stuck? Here is your way out:What happens when \(B_{}\) is not empty, and we cannot find a prompting hypothesis? We show that if we do not find a prompting hypothesis, then a random hypothesis in \(B_{}\) is an acceptable answer.

The surprising part about this statement is that it holds regardless of the size of the bucket \(B_{}\) due to hypothesis sampling procedure we have to find a prompting hypothesis. In search for a prompting hypothesis, we iterate over all \(H_{i}\) and sample roughly \(O( n/)\) many hypotheses \(H_{j}\)'s in \(B_{}\). We check, if \(H_{i}\) can remove them from the bucket. Note that if \(H_{i}\) was not found to be prompting, it implies that \(H_{i^{*}}\) cannot substantially update most of the hypotheses in \(B_{}\). Thus, We have that with high probability for \(1-\) fraction of the hypotheses in \(B_{}\), \(w_{i}(H_{j})^{}\).

The clever hack here is an observation about \(H_{i^{*}}\). Earlier, we discussed that we are looking for a hypothesis \(H_{i}\) with \(w_{i^{*}}(H_{i})\). We claim that a random hypothesis in the last \(B_{}\) (almost) has this property. On one hand, given that \(H_{i^{*}}\) was not found to be a prompting hypothesis, for \(1-\) fraction of \(H_{i}\) in \(B_{}\), \(w_{i^{*}}(H_{i})\) must be at most \(^{}\). On the other hand, the fact that all the previous buckets, \(B_{1},,B_{-1}\), are empty indicates \(H_{i^{*}}\) has shown a semi-distance of at least \((-1)\,^{}\). Hence, \(\), which is at least as large as all \(H_{i^{*}}\) semi-distances, is at least \((-1)\,^{}\). Therefore, \(w_{i^{*}}(H_{i})^{}+\). Therefore, for \(1-\) fraction of the hypotheses in \(B_{}\), they are \(3\,+()\) close to \(P\). For a formal argument, see Lemma A.1.

Now, assume the search for the prompting hypothesis fails. Recall that during the search, we have checked every single hypothesis in \(\). During the search, at some point, we must have stumbled upon \(H_{i^{*}}\) and did not declare it as a prompting hypothesis. In this case, either our sampling for substantial updates failed (which happens with small probability), or we can infer that there are not too many far hypotheses in \(B_{}\). Either way, we can output a random hypothesis from \(B_{}\) as the final sample without increasing the error probability by too much.

Dependency on \(\):It is worth noting that this last step results in a polynomial dependency on \(\) (as opposed to a more desirable dependency of \((1/)\)). This is mainly due to the fact that to ensure that a random hypothesis in \(B_{}\) is not too far, with a probability of \(1-\) in a single round, we have to try \(O((n)/)\) hypotheses in \(B_{}\) and check if \(H_{i^{*}}\) is prompting them. Hence, relying on this structural property of \(H_{i^{*}}\) makes a polynomial dependency on \(\) inevitable. Improving the dependency on \(\) for this algorithm would require new algorithmic ideas.

### The algorithm with \(=4\)

We introduce another (almost) linear-time algorithm for the hypothesis selection problem, where the time complexity shows improved dependency on \(\). However, this algorithm has a slightly worse accuracy parameter compared to our previous algorithm: \(=4\). This algorithm and the subsequent theorems are provided in Section B.

Algorithm with a guessed upper bound of \(\):As mentioned earlier, unlike previous work, our algorithm does not receive any prior information about the value of \(\). It might be speculated that there exists an easy reduction between our problem and another version of hypothesis selection, where an auxiliary parameter \(\) is provided to the algorithm such that \(\). A learner without the knowledge of \(\) can make a guess about \(\) and run one of the existing algorithms that works with the knowledge of an upper bound of \(\) (e.g., ) and check if it finds a good hypothesis or not. With this procedure in mind, we can run a binary search to find the smallest \(\) for which we find a hypothesis.4 However, a challenge with this approach is that the algorithm might yield a hypothesis even when \(<\), making it difficult for us to _refute_ the hypothesis that is found. Even if the output \(\) satisfies \(W()>\), it does not necessarily invalidate our guessed value \(\).

To overcome this challenge, we design an algorithm, namely \(\), with enhanced accuracy guarantees for the output hypothesis. We provide \(\) with the value \(\). We treat \(\) as a "guess" for which we hope that \(\). We require the algorithm to either refute our guess and declare \(>\), or output a hypothesis \(\) with a reasonable distance to \(P\), irrespective of the relationship between \(\) and \(\). More precisely, the distance of the output hypothesis should be bounded by: \(\|-P\|_{}(,)+\). With these revised guarantees, it is permissible to run a binary search over different values of \(\) in \(\{,2\,,, 1/\;\}\), and output the hypothesis that \(\) returns on the smallest \(\). For the rest of this discussion, we focus on designing \(\) and a provided parameter \(\).

Seeds and finding an acceptable hypothesis via seeds:In this algorithm, we introduce a new concept called a _seed_ for hypotheses. A seed provides us with a structural property that enables us to identify an acceptable hypothesis, regardless of the relationship between \(H_{i^{*}}\) and the seed. More formally, for a hypothesis \(H_{i}\), we define \(_{a,b}(H_{i})\) as the set of hypotheses \(H_{j}\) such that \(w_{j}(H_{i})\) is between \(a\) and \(b\):

\[_{a,b}(H_{i})\{H_{j} a<_{j}(H_{i} ) b\}\;.\]

We may omit the subscript of \(\) when it is clear from the context. We say a hypothesis \(H_{i}\) is a seed if almost all of its \(_{j}(H_{i})\) are low and its \(W(H_{i})\) is not too large. The quality of a seed is determined by three parameters: \(a\), \(b\), and \(m\).

**Definition 3.1** (Seed).: _Given parameters \(a,b_{ 0}\), and a non-negative integer \(m\), we say a hypothesis is an \((a,b,m)\)-seed if the following hold: 1) \((H_{i}) b\), and 2) \(|_{a,b}(H_{i})| m\)._

A seed with a small-sized set \(\) and a small \(b\) exhibits an interesting property: Suppose we have a seed \(H_{i}\) with a constant-sized set \(\). In this case, in \(O(n)\) time, we can compute \(W(H_{j})\) of every hypothesis \(H_{j}\) in \(\). Now, let \(H_{}\) be one of the hypotheses that minimize \(W(H_{j})\): \(H_{}_{H_{j}}W(H_{j})\). We claim either \(H_{i}\) or \(H_{}\) is acceptable output in this case.

When \(H_{i^{*}}\) is in \(\), we can infer that \(w_{i^{*}}(H_{i})\) is at most \(b\) (or, more precisely, \(b+^{}\)). From our earlier discussion, if \(b\) is sufficiently small (compared to \(\)), we can show that \(H_{i}\) is close to \(P\). In cases where \(H_{i^{*}}\) is in \(\), although we do not have strong guarantees for \(H_{i}\) itself, we have a very good answer already: \(H_{}\) is essentially a minimum distance estimate for the set \(\) which includes \(H_{i^{*}}\). Thus, we can conclude: First, \(H_{}\) is an acceptable output because it is \(3\,\)-close; second, \(W(H_{})\) is a lower bound for \(\).

Now, as we described, we have two acceptable outputs for two cases of the problem. For \(H_{i^{*}}\), \(H_{i}\) is an acceptable answer. For \(H_{i^{*}}\), \(H_{}\) is an acceptable answer. The only problem is that we do not know which case we are in. Our strategy is to pick a hypothesis that is still reasonably close to \(P\) even if we are in the other case. Let us fix a threshold value \(T\). We compare \(W(H_{})\) with \(T\): 1) If \(W(H_{}) T\), as we have discussed earlier, \(H_{}\) is \((T+2)\)-close to \(P\). This bound holds regardless of where \(H_{i^{*}}\) is. 2) Next, if \(W(H_{})>T\), we cannot say \(H_{}\) is a good choice for us. However, we can conclude that \(H_{i}\) is a close hypothesis to \(P\) even when \(H_{i^{*}}\) happens to be in \(\). In this case, we know that \( W(H_{})>T\). We take advantage of this knowledge and obtain the following bound:

\[\|H_{i^{*}}-P\|_{}=b\,+2\,(+ 2)\;.\]

Thus, regardless of where \(H_{i^{*}}\) is, \(H_{i}\) is \(((a,b/T)+2)(,)\). Now, the algorithm is fairly straightforward. If \(W(H_{})\) is small, output \(H_{}\); otherwise, output \(H_{i}\). We summarize these four cases in the following table. Depending on \(a\) and \(b\), we set \(T\) to minimize the maximum distance we endure in these cases. It is worth noting that in this argument, we did not rely on any prior knowledge concerning the relationship between \(\) and \(\).

How to find the first seed?Here, we provide an overview of our approach for identifying an initial seed. For a detailed explanation of the algorithm and its performance, refer to Section B.1.

To start, fix two parameters, \(a=\) and \(b=3\). To identify a seed hypothesis, we iterate over all hypotheses \(H_{1},,H_{n}\), checking whether each hypothesis \(H_{i}\) is a strong seed (i.e., a seed with a small \(||\)) by sampling several \(H_{j}\)'s and verifying if \(w_{j}(H_{i})\) is at most \(a\). Roughly speaking, for an integer \(m[n]\), if we sample approximately \((n/m)\)\(H_{j}\)'s and find that no \(w_{j}(H_{i})>a\), we can, with high probability, confirm that the size of \(\) does not exceed \(m\). This approach requires \(O(n^{2}/m)\) time.

There are, however, a few caveats with this method. First, if a seed is identified using the above approach, it may have a large \(W(H_{i})>b\). In this case, we can infer that \(H_{i}\) is likely far from \(P\). Given the time invested in identifying \(H_{i}\), we aim to leverage this information. Broadly, observing that \(w_{j}(H_{i}) a\) implies that many hypotheses are close to \(H_{i}\) (assuming that \(w_{i}(H_{j})\) values are also small). Knowing that \(H_{i}\) is far from \(P\), we can _mark_ all hypotheses close to \(H_{i}\) as also far, allowing us to proceed with the search. While this may seem counterproductive, marking a significant number of hypotheses as "far" constitutes progress for our algorithm. Specifically, if, at some point, all hypotheses are marked, we can declare that \(<\).

The second caveat is more challenging. Ideally, we seek a seed with a constant \(m\), but finding such a seed would require \((n^{2}/m)=(n^{2})\) time. Consequently, for a linear-time algorithm, we can only afford to find seeds where \(m=(n)\). In other words, the quality of the seed we can initially identify is much lower than the quality required for a producing solution. This leads to our next idea: boosting a seed, which is an approach to incrementally improve the seed's quality in roughly \(O( n)\) steps.

Boosting a Seed:In this process, we use an initial seed to iteratively find a stronger seed with a reduced value of \(||\). For a formal argument, see Section B.2. Assume a rate parameter \((0,1)\). As discussed earlier, by spending \(O(n/)\) time, we can identify a seed with \(m n\). Initially, \(m=||\) might be \(O(n)\). Hence, rather than calculating \(W(H_{j})\) exactly for all \(H_{j}\), we compute an approximate maximum semi-distance \((H_{j})\) by sampling \(t\) hypotheses. Specifically, for each \(H_{j}\), we set \((H_{j})_{H_{k}}_{k}(H_{j})\), where \(H_{k}\)'s are sample hypotheses. Using these approximate values \(\), we process the seed as follows. Let \(H_{}\) denote the hypothesis minimizing \((H_{j})\), with the following possible outcomes:

1. High \((H_{})\): If \((H_{})\) is high, all \((H_{j})\) (and thus \(W(H_{j})\)) values are likely large, making \(H_{i}\) an acceptable final solution.
2. Low \((H_{})\): While this does not guarantee a low \(W(H_{})\), it suggests that most \(w_{i}(H_{})\) values are small. Based on the value of \(W(H_{})\), we consider two cases: 1. \(W(H_{})(H_{})\): \(H_{}\) is likely far from \(P\) but has many close hypotheses, allowing us to mark these nearby hypotheses as far. 2. Moderate \(W(H_{})\): In this case, \(H_{}\) can serve as our new seed, as it yields a smaller set \((H_{})\) than \(H_{i}\).

Note that when we select \(H_{}\) as our new seed, \((H_{})\) is roughly \(O(n/t)\). However, we compute \((H_{j})\)'s for only \(|(H_{i})| n\) many hypotheses. Hence, with an increased sample size \(t=O(1/^{2})\), this approach yields a smaller \(|(H_{})|^{2} n\). The step of the process requires \(O(|| t)=m/^{2}=O(n/)\), paralleling the initial search. By repeating, we progressively reduce \(m=||\), and for a constant \(\), \(m\) decreases by a fixed factor until reaching a constant \(m\) seed, as desired.

    & \(H_{i^{*}}\) & \(H_{i^{*}}\) \\  \(W(H_{})>T\) & \(\|H_{i}-P\|_{} a+2\,\) & \(\|H_{i}-P\|_{}(b/T+2)\) \\  \(W(H_{})>T\) & \(\|H_{}-P\|_{} T+2\,\) & \(\|H_{}-P\|_{} T+2\,\) \\   

Table 2: Four cases when we process a good seed.