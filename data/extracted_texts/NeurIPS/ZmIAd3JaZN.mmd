# Truthful High Dimensional Sparse Linear Regression

Liyang Zhu\({}^{1}\), Amina Maneur\({}^{1}\), Meng Ding\({}^{2}\), Jinyan Liu\({}^{3}\), Jinhui Xu\({}^{2}\), Di Wang\({}^{1}\)

\({}^{1}\)PRADA Lab, King Abdullah University of Science and Technology

\({}^{2}\)State University of New York at Buffalo

\({}^{3}\)Beijing Institute of Technology

{liyang.zhu, amina.maneur, di.wang}@kaust.edu.sa

{mengding, jinhu}@buffalo.edu

jjliu@bit.edu.cn

###### Abstract

We study the problem of fitting the high dimensional sparse linear regression model with sub-Gaussian covariates and responses, where the data are provided by strategic or self-interested agents (individuals) who prioritize their privacy of data disclosure. In contrast to the classical setting, our focus is on designing mechanisms that can effectively incentivize most agents to truthfully report their data while preserving the privacy of individual reports. Simultaneously, we seek an estimator which should be close to the underlying parameter. We attempt to solve the problem by deriving a novel private estimator that has a closed-form expression. Based on the estimator, we propose a mechanism which has the following properties via some appropriate design of the computation and payment scheme: (1) the mechanism is \((o(1),O(n^{-(1)}))\)-jointly differentially private, where \(n\) is the number of agents; (2) it is an \(o()\)-approximate Bayes Nash equilibrium for a \((1-o(1))\)-fraction of agents to truthfully report their data; (3) the output could achieve an error of \(o(1)\) to the underlying parameter; (4) it is individually rational for a \((1-o(1))\) fraction of agents in the mechanism; (5) the payment budget required from the analyst to run the mechanism is \(o(1)\). To the best of our knowledge, this is the first study on designing truthful (and privacy-preserving) mechanisms for high dimensional sparse linear regression.

## 1 Introduction

One fundamental learning task is estimating the linear regression model, with a wide array of applications ranging from statistics to experimental sciences like medicine  and sociology . These studies typically assume that analysts have high-quality data, which is essential to the success of the model. However, real-world data, such as medical records and census surveys, often contain sensitive information sourced from strategic, privacy-concerned individuals. In this case, data providers (agents)1 may be disinclined to reveal their data truthfully, potentially jeopardizing the accuracy of model estimation. Therefore, in contrast to conventional statistical settings, it becomes imperative to model the utility functions of individuals and engineer mechanisms that can concurrently yield precise estimators, safeguard the privacy of individual reports, and encourage the majority of individuals to candidly disclose their data to the analyst.

The problem involves two intertwined components: data acquisition and privacy-preserving data analysis. The analyst must strategically compensate agents for potential privacy violations, considering the alignment of their reported data with both the statistical model and their peers' contributions, while minimizing the payment budget. Additionally, the analyst must perform privacy-preserving computations to accurately learn the underlying model. As agents cannot refine their reports after seeing their payment, the interaction is designed to be completed in one round, creating a trade-off between estimator accuracy and the total payment budget needed for participant cooperation.

In recent years, there has been a line of work studying truthful and privacy-preserving linear models such as [2; 37; 14; 38]. However, due to the complex nature of the problem, all of them only consider the low dimension case, where the dimension of the feature vector (covariate) is much lower than the sample size, i.e., they need to assume the dimension is a constant. In practice, we always encounter the high dimensional sparse case where the dimension of the feature vector is far greater than the sample size but the underlying parameter has an additional sparse structure. While the (high dimensional sparse) linear model has been widely studied in statistics and privacy-preserving machine learning [39; 24; 3; 52; 61; 53; 49; 28], to the best of our knowledge, there is no previous study on truthfully and privately estimating high dimensional sparse linear models due to some intrinsic challenges of the problem (see Section C in Appendix for details). Therefore, a natural question to ask is:

_Can we fit the high dimensional sparse linear regression and design mechanism which incentivizes most agents and truthfully report their data and preserves the privacy of the individuals?_

In this paper, we answer the question in the affirmative via providing the first study on the trade-off between privacy, the accuracy of the estimator, and the total payment budget for high dimensional sparse linear models where the dimension \(d\) can be far greater than the sample size \(n\), while the sparsity \(k\) and \( d\) are far less than \(n\) can be considered as constants. Specifically, for the privacy-preserving data analysis part, we adopt the definition of Joint Differential Privacy (JDP)  to protect individuals' data and develop a novel closed-form and JDP estimator for sparse linear regression, which is significantly different from the low dimension case and can be applied to other problems. Moreover, we develop a general DP estimator for the \(_{p}\)-sparse covariance matrix with \(p\) as a by-product, which extends the previous results on the \(_{0}\)-sparse case. Based on our JDP estimator, via the peer prediction method, we then provide a payment mechanism that can incentivize almost all participants to truthfully report their data with a small amount of the total payment budget.

In detail, our mechanism has the following properties. (1) The mechanism preserves privacy for individuals' reported data, i.e., the output of the mechanism is \((o(1),O(n^{-(1)}))\)-JDP, where \(n\) is the number of agents. (2) The private estimator of the mechanism is \(o(1)\)-accurate, i.e., when the number of agents increases, our private estimator will be sufficiently close to the underlying parameter. (3) The mechanism is asymptotically truthful, i.e., it is an \(o()\)-approximate Bayes Nash equilibrium for a \((1-o(1))\)-fraction of agents to truthfully report their data. (4) The mechanism is asymptotically individually rational, i.e., the utilities of a \((1-o(1))\)-fraction of agents are non-negative. (5) The mechanism only requires \(o(1)\) payment budget, i.e., when the number of participants increases, the total payment tends to zero.

## 2 Preliminaries

**Notations.** Given a matrix \(X^{n d}\), let \(x_{i}^{T}\) be its \(i\)-th row and \(x_{ij}\) (or \([X]_{ij}\)) be its \((i,j)\)-th entry (which is also the \(j\)-th element of the vector \(x_{i}\)). For any \(p[1,]\), \(\|X\|_{p}\) is the \(p\)-norm, i.e., \(\|X\|_{p}:=_{y 0}}{\|y\|_{p}}\), and \(\|X\|_{,}=_{i,j}|x_{ij}|\) is the max norm of matrix \(X\). For an event \(A\), we let \(I[A]\) denote the indicator, i.e., \(I[A]=1\) if \(A\) occurs, and \(I[A]=0\) otherwise. The sign function of a real number \(x\) is a piece-wise function which is defined as \((x)=-1\) if \(x<0;(x)=1\) if \(x>0\); and \((x)=0\) if \(x=0\). We also use \(_{}(X)\) to denote the minimal eigenvalue of \(X\). For a sub-Gaussian random variable \(X\), its sub-Gaussian norm \(\|X\|_{_{2}}\) is defined as \(\|X\|_{_{2}}=\{c>0:[(}{c^{2}})] 2\}\) (see Appendix E for more preliminaries).

### Problem Setting

We consider the problem of sparse linear regression in the high dimensional setting where \(d n\). Suppose that we have a data universe \(=^{d}\) and \(n\) agents in the population, where each agent \(i\) has a feature vector \(x_{i}\) and a response variable \(y_{i}\) (we denote \(D_{i}=(x_{i},y_{i})\) and \(D\) as the whole dataset). We assume that \(\{(x_{i},y_{i})\}_{i=1}^{n}\) are i.i.d. sampled from a sparse linear regression model, i.e., each \((x_{i},y_{i})\) is a realization of the sparse linear regression model \(y=^{*},x+\), where the distribution of \(x\) has mean zero, \(\) is some randomized noise that satisfies \([]x=0\), and \(^{*}^{d}\) is the underlying model estimator with sparsity assumption \(\|^{*}\|_{0} k\). In the following, we provide some assumptions related to the model. See Section A in Appendix for a table of notations.

**Assumption 1**.: _We assume \(\|^{*}\|_{2} 1\). Moreover, for the covariance matrix of \(x\), \(\), there exist \(_{}\) and \(_{x}\) such that \(\| w\|_{}_{}\|w\|_{}, w 0\) and \(\|^{-}x\|_{_{2}}_{x}\). 2_

These assumptions have been commonly adopted in some relevant studies such as [52; 14; 3]. Next, we present the assumptions made on the covariate vectors \(x_{i}\) and response variable \(y_{i}\).

**Assumption 2**.: _We assume that the covariates (feature vectors) \(x_{1},x_{2},,x_{n}^{d}\) are i.i.d. (zero-mean) sub-Gaussian random vectors with variance \(}{d}\) with \(=O(1)\). 3 The responses \(y_{i}\) are i.i.d. (zero-mean) sub-Gaussian random variables with variance \(^{2}\) with \(=O(1)\)._

In our setting, the agents are self-interested or strategic. They concerned about their privacy and can misreport their responses \(\{y_{i}\}_{i=1}^{n}\) but not their features \(\{x_{i}\}_{i=1}^{n}\). This means the features are directly observable but the response (e.g., during physical examination) is unverifiable. We denote \(=\{_{i}=(X_{i},_{i})\}_{i=1}^{n}\) the reported dataset where \(_{i}=_{i}(D_{i})\) is the reporting strategy adopted by agent \(i\). Specifically, each agent is characterized by a privacy cost coefficient \(c_{i}_{+}\). Higher \(c_{i}\) indicates the agent \(i\) is concerned more about the privacy violation.

Apart from the agents, there is an analyst who seeks an accurate estimator \(\) of \(^{*}\) based on the reported data and needs to construct a payment rule \(:^{n}^{n}\) that encourages the truthful participation, i.e., reveal their data truthfully to the agent. Misreporting the response \(y_{i}\) will result in a decrease in the payment received \(_{i}\). The analyst will thus design a mechanism \(\) takes the reported dataset \(=\{_{i}=(X_{i},_{i})\}_{i=1}^{n}\) as input and outputs an estimator \(\) of \(^{*}\) and a set of non-negative payments \(\{_{i}\}_{i=1}^{n}\) for each agent. This mechanism will in turn satisfy some privacy guarantee for the reports provided by agents. Moreover, the desired mechanism must constrain the payments to an asymptotically small budget. All of the above discussion depends upon the rationality of each agent.

### Differential Privacy

Due to space limit, we postpone all the relevant definitions of DP to the appendix, readers can refer to Section. A.1. In our case, DP requires that all outputs, including the payments allocated to agents, are insensitive to each agent's input. This requirement is quite strict, as the payment to each agent is not shared publicly or with other agents. Therefore, instead of using the original DP, we consider a relaxation known as _joint differential privacy_ (JDP) .

### Utility of Agents

Based on the definition of JDP, we introduce in this section our model of agent utilities. We assume that each agent \(i\) is characterized by her privacy cost parameter \(c_{i}_{+}\) representing how she is concerned about the privacy violation in the case she truthfully reports \(y_{i}\) to the analyst. We also introduce her privacy cost function \(f_{i}(c_{i},,)\) which measures the cost she incurs when her response \(y_{i}\) is used in an \((,)\)-Joint Differential Private Mechanism. Considering the payment \(_{i}\) of agent \(i\) and her privacy cost function \(f_{i}(c_{i},,)\), we denote by \(u_{i}=_{i}-f_{i}(c_{i},,)\), her utility function that represents the utility she gets when she reports her response \(y_{i}\) truthfully to the analyst. Following the previous works, we assume that all functions \(f_{i}\) are bounded by a function of \(c_{i}\) and \(\), increasing with \(\).

**Assumption 3**.: _The privacy cost function of each agent \(i\) satisfies \(f_{i}(c_{i},,) c_{i}(1+)^{3}\)_

Larger values of \(\) and \(\) imply weaker privacy guarantees, which means the privacy cost of an agent becomes larger. Thus, it is natural to let \(f_{i}\) be bounded by a component-wise increasing function, which can be denoted by \(F(c_{i},,)\). Here \(F(c_{i},,)=c_{i}(1+)^{3}\). In , the authors consider the case where the response is bounded and \(=0\), they assume \(f_{i}(c_{i},,) c_{i}^{2}\), i.e., \(F(c_{i},,)=c_{i}^{2}\). However, since our Assumption 2 on the distribution of the response is more relaxed, we need stronger assumptions regarding the privacy cost function and the distribution of privacy cost coefficients.

We assume that the privacy cost parameters are also random variables, sampled from a distribution \(\). It is intuitive to believe that the privacy cost \(c_{i}\) for each individual does not reflect the privacy costs incurred by other individuals. Also, we allow \(c_{i}\) to be correlated with its corresponding data sample \(D_{i}\). Therefore, we make the following assumption.

**Assumption 4**.: _Given \(D_{i}\), \((D_{-i},c_{-i})\) is conditionally independent of \(c_{i}\), for each \(i[n]\) :_

\[p(D_{-i},c_{-i}|D_{i},c_{i})=p(D_{-i},c_{-i}|D_{i},c_{i}^{})\]_where \(c_{-i}\) represents the set of privacy costs excluding the privacy cost of agent \(i\)._

In addition, we make the same assumption on the tail of \(\) as in  that the probability distribution of \(c_{i}\) has exponential decay. This assumption is essential for providing a bound on the threshold value \(_{,}\) of truthful reporting, which will be explained in the following section.

**Assumption 5**.: _There exists some constant \(>0\) such that the conditional distribution of the privacy cost coefficient satisfies \(_{D_{i}}_{c_{i} p(c_{i}|D_{i})}(c_{i}) 1-e^{- }\)._

### Truthful Mechanism Properties

Following the previous work, we propose to design mechanisms that satisfy the following properties : (1) truthful reporting is an equilibrium; (2) the private estimator output should be accurate; (3) the utilities of almost all agents are ensured to be non-negative; and (4) the total payment budget required from the analyst to run the mechanism is small. These concepts will be measured and evaluated using the framework of a multiagent, one-shot, simultaneous-move symmetric Bayesian game, where the behavior of the agents is modeled. Due to space limit, we provide rigorous definitions of the truthful mechanism properties to the Appendix. Readers can refer to Section A.2 for details.

## 3 Main Results

In this section, we will design truthful and private mechanisms for our problem. Generally speaking, our method consists of two components: a closed-form JDP estimator for high dimensional sparse linear regression and a payment mechanism. In the following, we first introduce our private estimator for the original dataset \(D\).

### Novel Efficient Private Estimator

As mentioned in Section 1, the one-round communication constraint necessitates a closed-form estimator. For this reason, in the low dimension setting, previous methods did not favour LASSO as there is no closed-form solution and thus also cannot be used. [14; 37] are motivated by the closed-form solution of the ordinary least square (OLS) or ridge regression (See Section C for detailed discussion). However, it is well-known that for high dimensional sparse setting these two estimators come with less favorable guarantees when compared to the LASSO. When employed as a regularization term, the \(_{2}\)-norm does not encourage sparsity to the same extent as the \(_{1}\)-norm. Thus, all previous methods for truthful linear regression cannot be applied to our problem.

In the following, we derive a new estimator based on a variant of the classical OLS estimator, tailored for the high dimensional sparse setting. Our aim is twofold: first, to achieve convergence rates similar to the LASSO, and second, to exploit the inherent sparsity of the model.

We initiate our analysis with an initial, albeit unrealistic "scaffolding" assumption that the inverse of the empirical covariance matrix \((_{XX})^{-1}\) exists with \(_{XX}=_{i=1}^{n}x_{i}x_{i}^{T}\), which will be removed in the course of our analysis. Intuitively, our goal is to find a sparse estimator that is close to OLS, i.e., \(_{}\|-_{XX}^{-1}_{XY}\|_{2}^{2}\), s.t. \(\|\|_{0} k\), whose \(_{1}\) convex relaxation of the \(_{0}\) constraint is

\[_{}\|-_{XX}^{-1}_{XY}\|_{2}^{2}+ _{n}\|\|_{1}\] (1)

with some \(_{n}>0\).

Although (1) is very similar to LASSO, fortunately, the above minimizer is just the proximal operator on OLS: \(_{_{n}\|\|_{1}}(_{XX}^{-1}_{ XY})\), which has a closed form expression. Since the proximal operator is separable with respect to both vectors, \(\) and \(_{XX}^{-1}_{XY}\), we have \((_{_{n}\|\|_{1}}(_{XX}^{-1}_ {XY}))_{i}=((_{XX}^{-1}_{XY}))_{i}) \{|(_{XX}^{-1}_{XY}))_{i}|-_{n},0\}\). And the optimal solution \(\) satisfies:

\[=S_{_{n}}(_{XX}^{-1}_{XY}),\] (2)

where for a given thresholding parameter \(\), the element-wise _soft-thresholding_ operator \(S_{}:^{d}^{d}\) for any \(u^{d}\) is defined as the following: the \(i\)-th element of \(S_{}(u)\) is defined as \([S_{}(u)]_{i}=(u_{i})(|u_{i}|-,0)\).

A key insight is that this operation is equivalent to embedding the classical OLS estimator within the sparsity constraint. This secures \(_{2}\)-norm consistency which does not hold for neither the ridge regression nor the original OLS estimator. The \(_{1}\) regularization serves to minimize the structural complexity of the parameter under constraints. Importantly, the estimator above is available in closed-form.

Our next focus centers on the privatization scheme. Prior work on truthful linear regression  employed the output perturbation method, which adds some noise to the closed-form estimator. The noise should be calibrated by the \(_{2}\)-sensitivities of their non-private estimators to ensure DP, which depend on \(()\). This is unacceptable when \(d n\). Should we adopt the same strategy to analyze the sensitivity of \(S_{_{n}}(_{XX}^{-1}_{XY})\), we inevitably encounter the estimation error of \(_{XX}^{-1}\). This error will cause the noise to have an unavoidable dependency on \(()\). Given the previous discussion, we propose to inject Gaussian noise separately to \(_{XX}\) and \(_{XY}\). It is notable that while similar methods have been used in DP statistical estimation , it has not been used in truthful linear regression. This is due to that in our problem, the data is misreported, which makes the utility analysis more difficult. We will discuss it in Section 4.1.

For the term \(_{XX}\), we apply \(_{2}\)-norm clipping so that the sensitivity of clipped version \(_{}\) is irrelevant to \(d\). For the term \(_{XY}\), since the covariate and the response \(y_{i}\) are sub-Gaussian. Therefore, clipping operation becomes necessary. We shrink each coordinate of \(x_{i}\) via parameters \(_{x}\), i.e., for \(j[d]\) and \(_{i}=(x_{i})\{|x_{i}|, _{x}\}\). We also perform the element-wise clipping on the response \(y_{i}\) by \(_{y}\). Then the server aggregates these terms \(_{i}_{i}^{T}\) and \(_{i}_{i}\) and separately add Gaussian noises to \(_{}\) and \(_{}\). The noisy version is denoted by \(_{}\) and \(_{}\).

We now give a second thought to the estimation of the covariance matrix. As mentioned earlier, we used the scaffolding assumption on the invertibility of \(_{XX}\) matrix, which does not hold as the matrix is rank-deficient if \(d n\). To mitigate this issue, we need to impose additional assumptions and here switch to the sparsity assumption introduced below on the structure of the covariance matrix, which has been widely studied previously such as .

**Assumption 6**.: _We assume that \(_{q}(s)\) for some \(0 q<1\), where \(_{q}(s)=\{=(_{xx^{T},ij})_{1 i,j d}:_{i} _{j=1}^{d}|_{xx^{T},ij}|^{q} s, j[d]\}\) is the parameter space of \(s\)-approximately sparse covariance matrices._

It is notable that the sparse covariance assumption is commonly adopted in the previous work on high dimensional estimation . To the best of our knowledge, the only work that considers the private sparse covariance matrix estimation is . Unfortunately,  only considers the case where \(q=0\), which is a special case of Assumption 6 and we cannot trivially apply their method to our setting. Also, as we will discuss in Remark 3, even if the assumption does not hold, all of our theoretical results still hold if the sample size is large enough.

Directly using the perturbed covariance matrix will be insufficient to exploit the sparsity structure. In fact, it can be readily seen that \(\|_{}-\|_{2} O(}{ne})\), which is quite large under the high dimensional setting. To see why \(_{}\) will introduce a large error under Assumption 6, we observe that some of its entries are quite large which makes \(|_{^{T},ij}-_{xx^{T},ij}|\) large for some \(i,j\). Thus, we need to develop a new private estimator for (approximately) sparse covariance matrices as a valuable by-product. By Lemma 24 and 11 in the Appendix, we can get the following, with high probability, for all \(1 i,j d\), \(|_{^{T},ij}-_{xx^{T},ij}| {O}(}}{ne})\). However, under the sparsity assumption, there will be two cases: (1) If \(_{xx^{T},ij}\) is small enough, then maybe the zero entry could have a smaller error than \(_{^{T},ij}\) since the noise is quite large. (2) If \(_{xx^{T},ij}\) is large, then the original \(_{^{T},ij}\) could be better. Motivated by the above observation, we perform a _hard-thresholding_ operation on each \(_{^{T},ij}\). This method takes advantage of this sparsity assumption by first estimating the sample covariance matrix, and then setting all entries with absolute values below a certain threshold _Thres_ to 0. To be more specific, it filters out \(_{^{T},ij}\) smaller than _Thres_ and sets them to 0 while keeping those larger than _Thres_ unchanged. This effectively shrinks the magnitude of the perturbed covariance matrix and thus lowering the error since some small \(_{xx^{T},ij}\) correspond to large \(_{^{T},ij}\). After the hard-thresholding operation, we denote the resulting matrix by \(_{}\) and it is invertible with high probability as shown below.

**Lemma 1**.: _The estimation error of private estimator \(_{}\) satisfies with probability \(1-d^{-(1)}\) that_

\[\|_{}-\|_{}^{2} O (s^{2}(r^{4}}{n^{2}} )^{1-q}+(r^{4}}{n^{2}} ))\]

_where the expectation takes over the randomness of the data records and the algorithm._

_Remark 1_.: When \(q=0\) and \(r=O(1)\), Lemma 1 could achieve an error bound of \(O( d}{n^{2}})\), which matches the optimal rate of locally differentially private sparse covariance matrix estimation .

Our private estimator is of the form \(^{P}(D)=S_{_{n}}(_{}^{-1} _{})\). With some \(r,_{x},\) and \(_{y},\)\(^{P}(D)\), upper bound of \((}{})\) is achievable. See Algorithm 1 for details. Notably, step 8 is the hard thresholding step for the private covariance matrix estimator. Importantly, the threshold only depends on \(n, d\), and the privacy parameters and is independent on the two sparsities \(s\) and \(k\) of our problem. Moreover, since we assume \(\|^{*}\|_{2}_{}\), we can also project \(^{P}(D)\) in Algorithm 1 onto a \(_{2}\)-norm ball: \(^{P}(D)=_{_{}}(^{P}(D)),\) where \(_{_{}}(v)=_{v^{}(_{})}\|v^{ }-v\|_{2}^{2}\) and \((_{})\) is the closed \(_{2}\)-norm ball with radius \(_{}\).

To sum up, high dimensionality gives rise to several consequences: (1) the regularization techniques used by  are not applicable, (2) the invertibility of covariance matrix estimate is not guaranteed, (3) it also precludes the output perturbation method. Our proposed estimator properly overcomes the above challenges. To tackle (1) we embed the OLS estimator within the \(_{1}\) constraint to exploit the sparsity, along with a novel estimator of the covariance matrix to mitigate (2), and privatize it by sufficient perturbation to solve (3), which in turn makes our truthful analysis part much more complicated.

### Payment Rule

We now turn our attention to the payment rule. The analyst wants to pay agents according to the veracity of the data they have provided and needs a reference against which to compare each data item. As mentioned before, the response is unverifiable, hence we lack a ground truth reference to validate the accuracy of the reported values. To circumvent the problem, we adopt the _peer prediction method_ to determine a player's payment. In principle, the higher payment means higher consistency between the agent's reported value \(_{i}\) and the predicted value of \(y_{i}\) estimated using the collective input from their peers \(_{-i}\).

To quantitatively measure the similarity between each agent's report and their peer's reports, we will use the _rescaled Brier score_ rule. Let \(a_{1}\) and \(a_{2}\) be positive parameters to be specified. Consider that \(q\) represents the prediction of agent \(i\)'s response based on her own reports, and \(p\) represents the prediction of agent \(i\)'s response based on her feature vector and her peers' reports. The analyst usesthe following payment rule:

\[B_{a_{1},a_{2}}(p,q)=a_{1}-a_{2}(p-2pq+q^{2}),\] (3)

Observing that \(B_{a_{1},a_{2}}(p,q)\) is a function that exhibits strict concavity with respect to \(q\), we point out that its maximum is attained when \(q\) equals \(p\). This implies a congruence between the prediction of agent \(i\)'s response based on her own information and that derived from her peers' information. For agent \(i\), given \([y_{i}|x_{i},^{*}]= x_{i},^{*}\), it is logical to set \(p=_{i},^{P}(^{b})\) and \(q=_{i},_{ p(|_{i})}[]\). Here, \(^{P}(^{b})\) denotes the private estimator for a dataset \(^{b}\) excluding \(_{i}\), and \(p(|_{i})\) represents the posterior distribution of \(\) post the analyst's receipt of \(_{i}\).

Building upon this analysis, we structure our Algorithm 2. This algorithm utilizes reported data, which may contain manipulated responses, to generate estimators. To maintain data independence, we divide the dataset into two subsets, \(^{0}\) and \(^{1}\). For the purpose of calculating the payment for each agent \(i\) in group \(b\{0,1\}\), the estimator \(^{*}\) is derived using \(^{1-b}\). Finally, the algorithm applies \(^{P}()\) in combination with the specific agent's feature vector \(x_{i}\) to forecast their response.

```
1:Ask all agents to report their data \(_{1},,_{n}\);
2:Randomly partition agents into two groups, with respective data pairs \(^{0},^{1}\)
3:For each dataset \(,^{0}\) and \(^{1}\), compute private estimators \(^{P}()\), \(^{P}(^{b})\) for \(b=0,1\) according to Algorithm 1
4:Compute estimators \(^{P}()=_{_{}}(^{P}())\) and \(^{P}(^{b})=_{_{}}(^{P}(^{b }))\) for \(b=0,1\)
5:Set parameters \(a_{1},a_{2}\), and compute payments to each agent \(i\): if agent \(i\)'s is in group \(1-b\), then he will receive payment \(_{i}=B_{a_{1},a_{2}}(_{i},^{P}(^{b}) ,_{i},_{ p(|_{i})}[ ]).\) ```

**Algorithm 2** General Framework for Truthful and Private High Dimensional Linear Regression

## 4 Theoretical Results and Implementation

### Accuracy and Privacy Analysis

**Theorem 2** (Privacy).: _The output of Algorithm 2 satisfies \((2,3)\)-JDP._

_Remark 2_.: By the selection of \(\) and \(\), our mechanism could achieve an \((o(}),O(n^{-(1)}))\)-JDP, which provides asymptotically the same good privacy guarantee as in  for the low dimension setting with bounded covariates and responses. Specifically,  shows that it is possible to design an \(o(})\)-JDP mechanism, while here we consider the approximate JDP due to the Gaussian noise we add.  considers truthful (low dimensional) linear regression with sub-Gaussian/heavy-tailed covariates and responses, our Theorem 2 is better than theirs. In detail,  can only guarantee Random Joint Differential Privacy (RJDP) where on all but a small proportion of unlikely dataset pairs, pure \(\)-JDP holds, while in this paper we can guarantee approximate JDP, which is more widely used in the DP literature. The main reason is that  used the output perturbation-based method to ensure DP. However, as the data distribution is sub-Gaussian rather than bounded as in , the sensitivity of the closed-form linear regression estimator could be extremely large (with some probability). Thus, the output perturbation-based method can fail with a small probability and can only ensure RJDP. Instead, in our method, we use sufficient statistics perturbation, due to our clipping operator, the sensitivities of \(_{}\) and \(_{}\) are always bounded. One consequence of adopting our sufficient statistics perturbation method is that the utility analysis is harder than that of the output perturbation-based method, as we will discuss in the following.

**Theorem 3** (Accuracy).: _Fix a privacy parameter \(\), a participation goal \(1-\) and a desired confidence parameter \(\) in Definition 6. Then under the symmetric threshold strategy \(_{_{,}}\), when \(n\) is sufficient large such that \(n(r^{4} d}{^{2 }_{}})\), the output \(^{P}()\) of Algorithm 2 satisfies that with probability at least \(1--O(n^{-(1)})\),_

\[[\|^{P}()-^{*}\|_{2}^{2}] O ((^{2}n+)\! d}{^{2}}).\]

_Remark 3_.: The above bound is independent on \((d)\). This outcome is primarily due to the use of sufficient statistics perturbation method, which effectively reduces the size of noise. It is notable that Assumption 6 only ensures that when \(n(r^{4}}{^{2}_{}})\) our private covariance estimator is invertible. Thus, even if the assumption does not hold, we can still get the same upper bound as in Theorem 3 as long as \(n(d)\).

Our framework for analyzing the accuracy differs dramatically from that of the prior ones since our privatization mechanism incurs finer and more delicate analysis on some specific error terms. The work of  and  both used the output perturbation method, as it provides an explicit characterization of the noise. Specifically, their estimator can be represented as \(^{P}()=_{_{}}(^{P}())\), where \(^{P}()=()+v\) with \(()\) as a (non-private) closed-form estimator and \(v\) is the added Gamma noise of scale \(O()\) to the non-private estimator. It can be shown that:

\[[\|^{P}()-^{*}\|_{2}^{2}] \|^{P}()-^{*}\|_{2}^{2} 2 \|^{P}()-(D)\|_{2}^{2}+2 \|(D)-^{*}\|_{2}^{2}\] \[= 2(\|()-(D)\|_{2}^{2}+ \|v\|_{2}^{2}+\|(D)-^{*}\|_{2}^{2})\] (4)

where \(D\) is original data and \(\) is the reported data. Note that the second and the third terms in (4) are easy to upper bound. For the first term, since we know the number of manipulated data in \(\) is bounded by \( n\) with high probability, indicating there are at most \( n\) different samples between \(\) and \(D\). Thus, it can be bounded by directly re-using the sensitivity analysis of \((D)\) as a part of the privacy data analysis. However, as we mentioned previously, the sensitivity of (2) is of scale \(O()\), indicating the previous method cannot be applied in our setting. Hence our tactic is to privatize the terms \(_{}\) and \(_{}\) separately. We shall take another route to estimate the error of the private estimator \(^{P}()\):

\[[\|^{P}()-^{*}\|_{2}^{2}] \|^{P}()-^{*}\|_{2}^{2} 2 \|^{P}()-^{P}(D)\|_{2}^{2}+2\|^{P}(D)-^{*}\|_{2}^{2}.\]

The above framework is now estimating the difference in the private \(^{P}\) (instead of the non-private \(\)). However, this nuance inevitably leads to more complex analysis, i.e. the term \(\|^{P}()-^{P}(D)\|_{2}^{2}\) is much more complicated to deal with than the first term in (4). The bound on \(\|^{P}()-^{P}(D)\|_{2}^{2}\) cannot be obtained by simply applying existing results on the covariance matrix estimation as in  or the assumption of strong convexity of the loss function as in . Specifically, we tackle this issue by combining the analysis for \(s\)-approximately sparse covariance matrices and some technical tools such as the decomposability of the \(_{1}\) norm term in (1) to give a non-trivial bound. The relevant lemma is given below and as mentioned this bound comprises a key component for the proof of Theorem 3.

**Lemma 4**.: _Let \(^{P}()\) and \(^{P}(D)\) be the private estimators on the original dataset \(D\) and the reported dataset \(\) that at most one agent misreports. We set the constraint bound \(_{n}=O(}}{})\), when \(n\) is sufficient large such that \(n(r^{4} d}{^{2}_{ }})\), with probability at least \(1-O(d^{-(1)})\) we have the following error bounds:_

\[\|^{P}()-^{P}(D)\|_{} 4_{n},\| ^{P}()-^{P}(D)\|_{2} 16_{n}.\]

### Analysis for the Properties of Truthful Mechanism

**Theorem 5** (Truthfulness).: _Fix a privacy parameter \(\), a participation goal \(1-\) and a desired confidence parameter \(\) in Definition 6. Then with probability at least \(1--O(n^{-(1)})-nd^{-}\), the symmetric threshold strategy \(_{_{,}}\) is an \(\)-approximate Bayesian Nash equilibrium in Algorithm 2 with_

\[=O(a_{2}r^{4} d(k}{ ^{2}}+})+_{,} ^{3}).\]

We can see with some specified parameters, the above bound could be sufficiently small. For example, when we set \(=O()\) we have \( 0\) as \(n\) since \(=o()\).

**Theorem 6** (Individual rationality).: _With probability at least \(1--O(n^{-(1)})-nd^{-}\), Algorithm 2 is individually rational for all agents with cost coefficients \(c_{i}_{,}\) as long as_

\[a_{1} a_{2}(r_{}+3r^{2}_{}^{2})+_{,}8(1+ 3)^{3}\]

_regardless of the reports from agents with cost coefficients above \(_{,}\), where \(a_{1},a_{2}\) are in (6).__Remark 4_.: Our mechanism may not be individually rational for all agents, since the privacy cost coefficients follow an unbounded distribution with exponential decay. This assumption is made reasonable because for a relatively small subset of agents the privacy costs could be exceptionally high, indicating certain individuals may persistently refrain from reporting truthfully, regardless of the compensation offered to them. The same situation happens in other truthful mechanisms as well.

**Theorem 7** (Budget).: _With probability at least \(1--O(n^{-(1)})-nd^{-}\), the total expected budget \(=_{i=1}^{n}(_{i})\) required by the analyst to run Mechanism 1 under threshold equilibrium strategy \(_{_{,}}\) satisfies_

\[ n(a_{1}+a_{2}(r_{}+r^{2}_{}^{2})).\]

_Remark 5_.: With some appropriate setting of \(\), it is reasonable to expect the overall expected budget to diminish toward zero as the sample size increases. This is because if the sample size is infinite, the ground-truth parameters can always recovered by our estimator, which allows the analyst to pay nothing to incentivize the agents.

### Formal Statement of Main Result

**Corollary 8**.: _For any \((,)\) and \(c>0\), we set \(=n^{-}\), \(=(n^{-(1)})\), \(=(n^{-3})\), \(=(n^{-c})\), \(a_{2}=O(n^{-3})\), \(a_{1}=a_{2}(r_{}+3r^{2}_{}^{2})+_{,}8(1+3 )^{3}\). Then the output of Algorithm 2 satisfies \((O(n^{-}),O(n^{-(1)}))\)-JDP. Moreover, with probability at least \(1-O(n^{-(1)})\), it holds that:_

1. _The symmetric threshold strategy_ \(_{_{,}}\) _is a_ \((n^{--1})\)_-Bayesian Nash equilibrium for a_ \(1-O(n^{-3})\) _fraction of agents to truthfully report their data;_
2. _The private estimator_ \(^{P}()\) _is_ \((n^{2-1})\)_-accurate;_
3. _It is individually rational for a_ \(1-O(n^{-3})\) _fraction of agents to take part in the mechanism;_
4. _The total expected budget required by the analyst is_ \((n^{1-3})\)_._

_Remark 6_.: It is important to highlight the subtle balance between the precision of the estimator and the other attributes of the mechanism. Compromising on accuracy often results in several consequences: (1) a reduction in the total compensation paid to the agents, (2) an increase in the proportion of rational agents, and (3) a closer approximation to the Bayesian Nash Equilibrium. However, we do not observe such a trade-off in 's implementation for linear regression cases. Besides, our results slightly differ from that of  in the sense that they do not have a trade-off between rationality and accuracy. Such discrepancies may be caused by varying willingness to supply higher compensation to the agents, resulting in different settings of parameters.

## 5 Conclusions

In this paper, we fit the high dimensional sparse linear regression privately and we propose a truthful mechanism to incentivize the strategic users. On the one hand, the mechanism is \((o(1),O(n^{-(1)}))\)-jointly differentially private. This is achieved by using the sufficient statistics perturbation method which adds much less noise than the output perturbation method employed by prior work. Leveraging the idea of _soft-thresholding_, we propose a private estimator of \(^{*}\) to exploit the sparsity of the model and it achieves an error of \(o(1)\). On the other hand, via some computation on the consistency between the agent's reported value and the predicted value using peers' reports, we design an appropriate payment scheme for each agent using _rescaled Brier score_ rule. This method ensures that our mechanism reaches an \(o()\)-approximate Bayes Nash equilibrium for a \((1-o(1))\)-fraction of agents to truthfully report their data while a \((1-o(1))\) fraction of agents receive non-negative utilities, thus establishing their individual rationality. Moreover, the total payment budget required from the analyst to run the mechanism is \(o(1)\).