# SeafloorAI: A Large-scale Vision-Language Dataset

for Seafloor Geological Survey

Kien X. Nguyen\({}^{1}\), Fengchun Qiao\({}^{1}\), Arthur Trembanis\({}^{2}\), Xi Peng\({}^{1}\)

\({}^{1}\)Deep-REAL Lab, Department of Computer and Information Sciences, University of Delaware

\({}^{2}\)School of Marine Science and Policy, University of Delaware

{kxnguyen,fengchun,art,xipeng}@udel.edu

###### Abstract

A major obstacle to the advancements of machine learning models in marine science, particularly in sonar imagery analysis, is the scarcity of AI-ready datasets. While there have been efforts to make AI-ready sonar image dataset publicly available, they suffer from limitations in terms of environment setting and scale. To bridge this gap, we introduce SeafloorAI, the first extensive AI-ready datasets for seafloor mapping across 5 geological layers that is curated in collaboration with marine scientists. We further extend the dataset to SeafloorGenAI by incorporating the language component in order to facilitate the development of both _vision_- and _language_-capable machine learning models for sonar imagery. The dataset consists of 62 geo-distributed data surveys spanning 17,300 square kilometers, with 696K sonar images, 827K annotated segmentation masks, 696K detailed language descriptions and approximately 7M question-answer pairs. By making our data processing source code publicly available, we aim to engage the marine science community to enrich the data pool and inspire the machine learning community to develop more robust models. This collaborative approach will enhance the capabilities and applications of our datasets within both fields. Our code repository are available 1 under the CC-BY-4.0 license.

## 1 Introduction

Seafloor mapping stands at the forefront of marine science, utilizing cutting-edge technologies like multibeam echosounders and side-scan sonar to unveil the hidden complexities of the ocean floor . Beyond scientific research, seafloor mapping is instrumental in identifying potential resources, assessing environmental impacts, and supporting sustainable ocean management practices in the context of the blue economy . However, the current analysis techniques in seafloor mapping are predominantly labor-intensive and reliant on manual interpretation by marine scientists, necessitating hundreds of hours spent meticulously examining data surveys to analyze seabed imagery . This hands-on approach is not only time-consuming but also susceptible to user _subjectivity_ and the limitations of individual expertise, thus introducing potential _inconsistencies_ in analysis .

The integration of machine learning (ML) holds the promise of enhancing efficiency and reliability in seafloor mapping by automating the segmentation and classification tasks . However, the lack of public AI-ready datasets poses a significant challenge in leveraging the full potential of AI technologies for this purpose. While there have been efforts to make AI-ready sonar image datasets publicly available, they suffer from limitations in terms of environment setting and scale. For example, the dataset in  was captured in a water tank, which does not accurately represent the ocean's complex conditions. Additionally, other work have only produced small-scale datasetswith limited area coverage [39; 61], not accounting for the generalizability of the ML models in a spatially distributed setting. On the other end, abundant public hydrographic surveys conducted by the U.S. Geological Survey (USGS) and the National Oceanographic and Atmospheric Administration (NOAA)2[17; 48; 49; 47; 50; 2; 5] have yet to be extensively utilized by the ML community.

To bridge this gap, we introduce SeafloorAI, the first extensive AI-ready sonar imagery dataset for seafloor mapping. We compiled 62 public hydrographic surveys to construct a large-scale, geo-distributed and multi-purpose dataset, with the effort to map various geological layers. Furthermore, inconsistencies in the nomenclature of geological attributes across data surveys pose a challenge on the unification and development of an extensive dataset. In collaboration with marine scientists, we have developed a framework that standardizes such nomenclature by adopting the Barnhardt classification  and the Coastal and Marine Ecological Classification Standard (CMECS) . It guarantees uniformity throughout the dataset, enabling the evaluation of robust ML models in a spatially distributed setting. The data pool currently consists of 696K sonar images, 827K segmentation masks for 5 geological layers: Sediment, Physiographic Zone, Habitat, Fault, and Fold.

Finally, we incorporate the language component into our dataset for the development of generative vision-language models (VLMs) in marine science research. VLMs facilitate seamless interactions through textual queries and provide clear, understandable explanations throughout the analysis process [33; 34]. In addition, the ability to automate a report of the survey's findings, such as sediment composition, habitats, _etc._, would reduce the time and effort required for manual preparation. To this end, we present a data curation pipeline that leverages both domain knowledge from marine scientists and language generation capability of GPT-4. Specifically, we employ in-context learning  to generate analysis-driven question-answer pairs for each image, resulting in 7M samples and 696K language descriptions. We name the vision-language dataset SeafloorGenAI.

Figure 1: Overview of the spatially distributed seafloor mapping datasets. The table highlights key dataset statistics. We incorporate 62 public data surveys published by USGS and NOAA from 9 major regions to construct SeafloorAI and SeafloorGenAI datasets. Our dataset contains 9 geological layers, 4 of which are raw signals, _i.e._, Backscatter, Bathymetry, Slope and Ruggosity, and 5 annotated by human experts, _i.e._ Sediment, Physiographic Zone, Habitat, Fault and Fold. SeafloorAI serves as a dataset for standard computer vision tasks, _i.e._ semantic segmentation, whereas SeafloorGenAI constitutes a dataset for generative vision-language tasks, _i.e._, general visual question answering and instruction-following mapping. <SEG> denotes the segmentation mask output by the model.

Our contributions are summarized as follows:

1. We compile 62 public hydrographic data surveys from USGS and NOAA into a large, geo-distributed, multi-purpose and multi-modal dataset for seafloor mapping research.
2. We provide a standardization of naming convention across these surveys, under the _rigorous supervision of marine scientists_, to unify an extensive AI-ready dataset.
3. We present a data curation pipeline that produces detailed descriptions and question-answer pairs for the development of large generative vision-language models in marine science.
4. Our geo-distributed dataset contains 696K sonar images, 827K segmentation masks, 696K language descriptions and 7M question-answer pairs, covering a total area of 17,300 square kilometers.
5. We open-source our data processing code so that marine scientists could efficiently contribute their data surveys to expand the data pool.

## 2 Related Work

**Underwater Imagery Datasets.** Over the years, researchers at USGS and NOAA have carried out frequent hydrographic surveys [17; 48; 49; 47; 50; 2; 5] to collect and provide accurate and reliable information about the physical features of the water bodies and the seafloor. They are instrumental in creating accurate nautical charts to identify underwater hazards, aiding in the planning of marine infrastructure, and providing essential data for scientific research and environmental conservation. Furthermore, the data supports various economic activities, such as fishing, aquaculture, and energy production, by enabling sustainable and efficient operations.

In recent years, substantial efforts have been made to create public AI-ready underwater datasets, including forward-looking sonar (FLS), side-scan sonar (SSS), and RGB imagery. These datasets are utilized to develop machine learning models tailored for domain applications, focusing on classification or detection of geological features [3; 11; 7; 39; 54; 38] and man-made objects [77; 70; 26; 75; 32; 44; 13; 73; 72; 43; 84; 71; 72; 43; 84; 71]. Singh and Valdenegro-Toro  were pioneers with their FLS image dataset aimed at object detection, but their use of a controlled water tank setting may not fully reflect the complex oceanic conditions, limiting the generalizability of their results. Xie et al.  addressed this by extending object detection to data collected in natural water bodies, enhancing its real-world applicability. Sethuraman et al.  developed an SSS dataset for shipw detection, though its small sample size could limit model robustness. Others have also explored RGB underwater imagery for trash detection  and semantic segmentation .

Our research focuses on transforming the USGS and NOAA hydrographic surveys into a comprehensive, multi-scale, multi-purpose and multi-modal SSS imagery dataset. This initiative aims to propel advancements in both marine science and machine learning research, creating a bridge between extensive marine data resources and innovative computational techniques.

    & **Region** & **Image** & **Input** &  &  \\  & **Index** & **Resolution** & **Layers** & Sediment & Physio Zone & Habitat & Fault & Fold & (km\({}^{2}\)) \\   & Region 1 & 2m/pixel & 25,817 & 25,672 & 25,823 &  & 672 \\  & Region 2 & 2m/pixel & 123,774 & & & & & 3,148 \\  & Region 3 & 2m/pixel & 121,270 & 20,861 & 21,253 & & & 564 \\  & Region 4 & 2m/pixel & 42,771 & & & & 25,579 & 42,771 & 42,771 & 1,419 \\   & Region 5 & 10m/pixel & 15,827 & 4,647 & 3,387 &  &  &  &  \\  & Region 6 & 1m/pixel & 122,441 & 122,236 & 118,175 & & & 228 \\  & Region 7 & 1m/pixel & 1,593 & 1,507 & 1,510 & & & 454 \\  Delmarva & Region 8 & 2m/pixel & 329,881 &  &  &  &  &  \\   South Carolina & Region 9 & 4m/pixel & 13,141 & & & & & 808 \\    &  & 696,515 & 174,923 & 170,148 & 149,059 & 166,545 & 166,545 & 17,314 \\   

Table 1: Summary of the seafloor mapping data available for each region. The input layers for sonar images include Backscatter, Bathymetry, Slope and Ruggosity. Due to different mapping objectives of the original data surveys, the availability of segmentation masks is not uniform across mapping layers. Regions with unlabeled data can be utilized to pre-train the model via self-supervised learning .

Why side-scan sonar?Compared to FLS and RGB imagery, SSS offers distinct advantages for underwater imagery analysis. Side-scan sonar provides a wider coverage area, and creates high-resolution images that clearly delineate the seabed texture, which is essential for geological surveys, shipwreck location, and habitat mapping. Unlike FLS, which is primarily used for obstacle avoidance, SSS offers a broad, fan-shaped beam that scans the ocean floor to either side of the twofish or autonomous underwater vehicle, capturing detailed images of the seafloor texture. Moreover, SSS is less affected by water turbidity compared to RGB cameras, which struggle with visibility in murky waters and suffer from significant color loss at depth due to light absorption. This allows SSS to produce consistent and reliable imagery under a variety of underwater conditions, where optical methods would fail. Still, SSS is only a 2D representation of the seabed. We also incorporate 3D information such as water depth to describe the underwater topography. This allows for a broad scope of underwater imagery analysis, providing robust data suitable for in-depth assessments.

Comparison with Existing Datasets.Our dataset is a comprehensive and expansive dataset that serves two primary purposes: (1) to act as a benchmark for various tasks and (2) to train foundation vision or vision-language models with a focus on seafloor morphodynamic analysis. In contrast to existing datasets , which may specialize in single machine learning tasks or offer limited data samples, our dataset provides a diverse array of seafloor mapping tasks sourced from geographically diverse regions. Additionally, we make our data processing source code publicly available, encouraging further expansion of the dataset towards the magnitude of large-scale natural imagery datasets .

Datasets in other Scientific Domains.Following the success of large foundation models in natural imagery , there has been a significant push to develop expansive datasets tailored for training large foundation models for specific domain applications. In remote sensing, initiatives such as RSVQA , RSVQA-BEN , and RSGPT  have been developed to enhance general VQA capabilities, while MUSE  targets more complex reasoning tasks. Similarly, in medical imaging, datasets such as PathVQA , PMC-VQA , XrayGPT , LLaVA-Med , and OmniMedVQA  aim to improve the visual and textual understanding of various body parts through the analysis of MRI, X-rays, _etc._ These datasets comprise hundreds of millions of samples, posing significant acquisition challenges, particularly in marine science where data annotation is notably expensive. To address this, our initiative seeks to develop a large-scale dataset, aiming to significantly expand the resources available for marine science.

## 3 The SeafloorAI Dataset

### Dataset Overview

SeafloorAI is a large, geo-distributed, multi-purpose dataset designed to map various geological layers of the seafloor. It is catered for training computer vision models, _i.e._ CNNs and Vision Transformers that produce semantic segmentation masks. Furthermore, it facilitates the studies of fundamental ML problems such as robust optimization . The dataset also serves as a basis for constructing the generative vision-language variant, SeafloorGenAI, discussed in Sec. 4.

Our dataset is compiled from 62 geological data surveys published on USGS and NOAA repositories, spanning an area of 17,300 square kilometers. This dataset features a broad geographical distribution, covering the nearshore zones of several states, including California , Massachusetts , Delmarva , and South Carolina . These areas are further divided into 9 regions. The data for this dataset were collected over a period spanning from 2004 to 2024, using a variety of single side-scan sonars and multibeam echosounders with different frequencies. These instruments were employed to record the texture (Backscatter) and depth (Bathymetry) of the seafloor.

The surveys have been meticulously annotated by domain experts, focusing on five key geological layers: Sediment, Physiographic Zone, Habitat, Fault, and Fold as detailed in Tab. 1. This expansive and detailed dataset provides a comprehensive view of geological and environmental features across a wide range of coastal environments. In summary, we convert the raw raster data into a large-scale machine learning-ready dataset containing 696,515 input samples, and 827,220 annotated segmentation masks across various layers.

### Data Processing

The input layers, consisting of Backscatter and Bathymetry signals, are provided as raster data in GeoTIFF format. The five mapping layers serve as the ground-truth annotations, defining five tasks for the model training and evaluation. These layers come in shapefile format that stores the location (_i.e._, longitude and latitude), shape (_i.e._, polygons) and attributes of geological features (_i.e._, sediment type). These polygons define the regions of interest on raster images, effectively delineating the boundaries of different categories that we want to segment.

Next, we present the steps for data processing at a high level, and then go further into details with each geological layer. First of all, we reproject all layers from all surveys to the WGS84 (EPSG:4326)3 coordinate reference system. Then, we rasterize the shapefile to GeoTIFF format, effectively converting all the annotations into 2D arrays occupying the same geo-location. Finally, we use a sliding window to split the 2D raster layers into 224\(\)224 patches with a step size of 56 to avoid information loss at the edges. These patches serve as the inputs and outputs for the machine learning algorithms. This process is also referred to as "patchifying".

**Input Layers: Backscatter & Bathymetry.** Backscatter in marine science refers to the amplitude of the echoes of sound waves emitted/received by a transducer that bounce off objects or the seafloor and return to the receiver. By analyzing the time it takes for the sound waves to return and their acoustic intensity, scientists and researchers can create underwater maps of the submerged terrain and identify the composition and characteristics of the seafloor, as well as the presence of underwater objects or marine life. In our dataset, we normalize the backscatter signals to the  range, with 255 representing the nodata value. Regarding Bathymetry, we set the nodata value to be a negative number of significant magnitude, _i.e._, -9999. Additionally, we convert Bathymetry measurements from meters to kilometers, compressing these values into a  range for normalization purposes.

We further calculate two morphologic derivatives from Bathymetry, namely Slope and Ruggosity, to more comprehensively represent the topographical features of the seafloor in the input space. Slope refers to the _steepness_ of the seabed, calculated as the rate of change in elevation over a given distance. It is crucial for understanding sediment transport, habitat diversity, and the stability of underwater structures. We use GDAL implementation of the Zevenbergen & Thorne formula  to estimate the slope. In brevity, the formula computes the differences in elevation between a central pixel and its eight surrounding pixels for a more smoothed and stable slope estimation. Ruggosity, on the other hand, measures the _roughness_ or irregularity of the ocean floor. It quantifies the amount of surface area relative to a flat plane, offering vital clues about the complexity of habitats, which affects biodiversity and ecological interactions.

For each region, we resample Bathymetry, Slope and Ruggosity to the Backscatter's resolution. As a result, our dataset contains a range of resolutions across regions, from 1m to 10m per pixel, enabling both coarse and fine-grained understanding of seafloor morphodynamic analysis. After patchifying the rastered map, we only keep patches where the number of nodata pixels is below 10% the number of total pixels. In the final step, we apply interpolation to fill in the missing pixels, and median filtering to reduce speckle noise. The input contains 6 channels, including these 4 layers and 2 geo-location channels (pixel-wise longitude and latitude), resulting in a dimension of 224\(\)224\(\)6.

**Mapping Layers: Sediment, Physiographic Zone & Habitat.** Our dataset is derived from \(62\) different surveys spanning both the East and West Coasts of the United States. Given the diverse origins of the data, there are inherent inconsistencies in the annotations, such as varying standards or differing vocabularies used to label the same categories. To address this, we have developed a unification process for ground-truth labels, leading to the creation of multi-class segmentation masks for Sediment, Physiographic Zone, and Habitat. This standardization process is meticulously overseen by domain experts to ensure the accuracy and quality of the annotations.

Figure 2: The Barnhardt classification scheme  is based on four end-member units: (R)ock, (G)ravel, (S)and, and (M)ud. The other twelve composite categories represent the combinations of the four units, where the dominant texture (\(>\) 50\(\%\)) is in upper case, and the subordinate (\(<\) 50\(\%\)) in lower.

**(1) Sediment.** Sediments on the seafloor, composed of varied particles from multiple sources, are crucial for creating habitats, indicating geological processes, and aiding in environmental and ecological research. They play a key role in resource exploration by helping to identify potential sites for natural resource extraction and in climate change studies by preserving historical climate data. Detailed seafloor mapping using sediment analysis is vital for accurate marine navigation, scientific research, and effective marine resource management. We define a unified annotation standard for the Sediment layer, following the Barnhardt classification table , which is a classification scheme based on four end-member units: (**R**)ock, (**G**)ravel, (**S**)and, and (**M**)ud. The other twelve composite units represent the combinations of the four units, where the dominant texture (\(>\) 50\(\%\) of the area) is in upper case, and the subordinate (\(<\) 50\(\%\) of the area) is in lower case, illustrated in Fig. 2. Finally, we construct semantic segmentation masks for each input patch where each pixel contains an integer value from 0 to 16, with 0 denoting the pixels without annotations.

**(2) Physiographic Zone.** By definition, a physiographic zone refers to a distinct geographical region characterized by a uniformity in topography and underlying geological structure that sets it apart from adjacent areas. These zones are typically defined based on natural landscape features, such as the configuration of the terrain, rock formations, and soil types. Classifying these zones requires the holistic understanding of multiple geological features, hence the necessity to include the bathymetric derivatives, such as Slope and Ruggosity, as input. Similar to Sediment, we also define a standard for the Physiographic Zone layer. We follow the CMECS unit code for Physiographic Province which belongs in the Geoform Component . There are 21 different categories for Physiographic Zone, as shown in Fig. 3.

**(3) Habitat.** One of the aims of seafloor mapping efforts is to delineate benthic habitats as a high-level outcome. Hall et al.  defined Habitat as "the resources and conditions present in an area that produce occupancy...by a given organism." According to CMECS, a benthic habitat refers to the ecological regions at the lowest level of a body of water, including the sediment surface and sub-surface layers . Benthic habitats are critical areas because they provide living space for a wide range of organisms, both flora and fauna, which are integral to the marine ecosystem. Specifically focusing on abiotic benthic habitats, these are characterized by non-living physical and chemical aspects of the environment that influence the type and abundance of organisms living there. To unify the annotations across surveys, we first gather all 144 descriptions of the polygons from the public data surveys. We then categorize these descriptions into broader groups, ultimately consolidating them into 9 distinct categories for Habitat, depicted in Fig. 4.

**Mapping Layers: Fault & Fold.** Faults and folds are significant geological features on the seafloor that are formed by tectonic movements within the Earth's crust. Faults occur when rock layers break and slide past each other due to tectonic forces, creating distinct disruptions in the seabed. Folds are bends in rock layers that occur when these layers are compressed and folded, resulting in curved or wavy stratifications. Detecting these features is crucial for understanding seismic activity and geological history of the marine environment. In our study, we formulate the binary segmentation task to identify the presence of these geological features within specific image patches, assigning the pixels containing the features a value of 1, and 0 otherwise.

Figure 4: Nine major categories for abiotic habitat defined in SeafloorAI.

Figure 3: Twenty-one physiographic zone categories from CMECS.

[MISSING_PAGE_FAIL:7]

**(3) Spatial distribution.** Spatial distribution complements geological composition, thus giving a more comprehensive description of the image. We convert the segmentation mask of each category to polygons, which can then be fed as language into GPT-4. We first find the contours of the masks using conventional computer vision techniques, then transform them into polygon representation with the format \([x_{1},y_{1},...,x_{n},y_{n}]\), where \(x_{i}\) and \(y_{i}\) are the coordinates of the \(i^{}\) point in \(n\) points.

An example of Spatial Distribution in the Polygonight 2 Zone layer

Continential Shore Complex polygon at [0, 116, 0, 186,..., 1, 117] Shelf Basin polygon at [142, 0, 140, 2,..., 156, 0]

**Instruction-following Mapping.** Besides VQA, we aim to equip the AI assistant with the capability to map various seafloor features across different layers in response to specific instructions. This facilitates a seamless and intuitive interaction between the AI and marine scientists, allowing for easy querying and efficient analysis. We design our dataset to be compatible with state-of-the-art VLM models, such as PixelLM  and LISA  for both single and multi-instance segmentation tasks.

Examples of single and multi-instance instance instance following mapping in Section4.

(1) Q: Please segment [CATEGORY] in [LAYER]. A: Sure, <SEG>. (2) Q: What are present in the image for [LAYER]? Please segment them. A: [CATEGORY_1] <SEG_1>, [CATEGORY_2] <SEG_2>,..., [CATEGORY_N] <SEG_N>. (3) Q: Identify the areas of [CATEGORY_1] from [LAYER_1] and [CATEGORY_2] from [LAYER_2]. A: Sure, [CATEGORY_1] from [LAYER_1] <SEG_1> and [CATEGORY_2] from [LAYER_2] <SEG_2>.

Figure 5: Pipeline for generating question-answer pairs for sonar imagery samples using GPT-4: Marine scientists first identify necessary information, followed by the extraction of _geophysical parameters_, _geological composition_, and _spatial distribution_. They then provide descriptions for a handful of samples from the SeafloorAI dataset. These description are used to design a prompt for GPT-4 to generate high-quality, domain-specific question-answer pairs, via in-context learning .

## 5 Experiments

We report some baseline experiment runs on SeafloorAI for multi-class segmentation. Due to space limit, we move the experiments for binary segmentation to the Supplementary Material.

**Evaluation Metrics.** We use pixel-wise accuracy (Acc), Dice coefficient (Dice) and Jaccard coefficient (mIoU) to evaluate the baseline models.

**Data Split.** We present the data splits for Sediment, Physiographic Zone and Habitat, as well as the motivation for such splits. Due to the availability of the categories in each region, we make sure that the training regions possess the set of categories that cover the testing region(s). We present our data splits for the layers in Tab. 2. For the source data, we randomly split them into \(90\%\) for training and \(10\%\) for validation. The validation set is used to select the best model for testing on the target data.

**Training Details.** We employ the UNet architecture with different backbones as baselines. The UNet architecture  consists of a contracting path (encoder) and an expanding path (decoder), forming a U-shape. We use UNet-Base , UNet-ResNet18  and TransUNet-ViT-B/32 [10; 15] as our baseline models for the multi-class segmentation tasks. We adopt cross-entropy as the loss function. The model was trained using the Adam optimizer . The learning rate was initially set to 0.001 with a cosine annealing schedule. We use a batch size of 64 for 100 epochs, setting the patience to 5 epochs for early stopping. We perform 3 runs with different random seeds and report the model performance in Tab. 3. All runs are conducted on a single NVIDIA RTX A6000 GPU.

**Results.** Tab. 3 reports the results on the geo-distributed setting, which is similar to out-of-distribution generalization [53; 51]. We report the in-distribution (ID; on source data) and out-of-distribution (OOD; on target data) pixel-wise accuracy, Dice coefficient and Jaccard coefficient. Overall, we can see that all baseline models suffer from a signification performance degradation under distribution shift. This might be due to covariate shift (sensor types and configurations) and subpopulation shift (class imbalance). Therefore, ensuring that a model generalizes well to new, unseen distributions is a fundamental challenge. Standard training methods often assume that the training and testing data come from the same distribution, which is rarely the case in real-world applications.

  
**Task** & **Layer** &  & **Target** \\   Multi-class \\ Segmentation \\  } & Sediment & Region 1, Region 5, Region 6, Region 7 & Region 3 \\  & Physio Zone & Region 1, Region 3, Region 5, Region 6 & Region 7 \\  & Habitat & Region 2 & Region 4 \\   

Table 2: Geo-distributed data splits for the SeafloorAI dataset for multi-class segmentation.

Figure 6: An example in the SeafloorGenAI dataset, originated from Region \(5\). It features a GPT-4 generated description and question-answer pairs designed to efficiently assist marine scientists in data analysis. The generated description covers all three key analytical indicators. Noticeably, the last QA pairs focuses on cross-layer understanding (_i.e._, Sediment and Physiographic Zone), which is helpful for unraveling complex ecological dynamics on the seabed.

## 6 Human Evaluation for Language Annotations

Although GPT-4 has shown strong capabilities in data annotations , hallucinations in LLMs are inevitable . To ensure the quality of the language annotations generated by GPT-4, we describe an iterative prompt refinement process that involves human expert evaluation.

To maximize budget efficiency, we designed our procedure with several iterations of feedback and refinement. The idea is to engineer and refine our prompt to GPT-4 on a small subset of data before applying it to the whole dataset. For each iteration, (1) we annotated 1,000 random samples with GPT-4; (2) the marine scientists reviewed the quality of the generated annotations and gave feedback based on the three criteria: (i) _factual consistency_ to the original annotations, (ii) _factual completeness_ with respect to the analytical indicators and (iii) _coherence_ to domain language; (3) we refined our prompts to GPT-4, a.k.a prompt engineering, to achieve higher quality language annotations, (4) we repeated the steps for the next iteration. Finally, when the quality is met, we will populate the entire dataset with language annotations. Due to space limitation, we include more details in the Supplementary Material.

## 7 Limitations and Future Work

Despite the extensiveness of our dataset, there are notable limitations to discuss. Firstly, the availability of layers is not uniform across all regions; for instance, Region \(5\) is missing Habitat, Fault, and Fold layers. This is due to the different mapping objectives when the data surveys were first collected. Additionally, the existing nine Habitat categories are somewhat coarse and exclude biotic classifications. We are actively collaborating with marine scientists to refine and expand the Habitat layer, making it more detailed and comprehensive. The current version of the SeafloorGenAI dataset provides annotations suitable for straightforward analytical queries and lacks the data for deeper reasoning abilities. Moving forward, we plan to enhance the dataset to support the development of reasoning-capable models similar to referring and reasoning segmentation as in [57; 31; 76], offering more profound insights into marine science questions and paving the way for data discovery. Developing this enhanced version of the dataset will require a structured and systematic approach to understanding domain-specific knowledge to accurately annotate the data. In terms of modeling, our plan for future work involves training a generative vision-language model on the SeafloorGenAI dataset, serving as a foundation ML model in marine science research.

    &  \\   & Acc ID & Acc OOD & \(\) Acc & Dice ID & Dice OOD & \(\) Dice & mIoU ID & mIoU OOD & \(\) mIoU \\  UnNet-Base & 77.45 \(\) 0.81 & 21.49 \(\) 0.91 & -55.96 & 97.73 \(\) 0.33 & 21.59 \(\) 0.97 & -58.14 & 66.46 \(\) 1.15 & 12.29 \(\) 0.61 & -54.17 \\ UnNet-ResNet18 & 78.45 \(\) 0.67 & 34.71 \(\) 6.79 & -43.74 & 80.78 \(\) 0.71 & 35.01 \(\) 6.86 & -45.77 & 67.90 \(\) 1.00 & 22.08 \(\) 5.73 & -45.82 \\ TransUNet & 67.90 \(\) 2.18 & 28.32 \(\) 1.04 & -39.58 & 69.94 \(\) 2.27 & 29.16 \(\) 1.05 & -40.16 & 53.98 \(\) 2.65 & 17.41 \(\) 0.71 & -36.57 \\   \\   & Acc ID & Acc OOD & \(\) Acc & Dice ID & Dice OOD & \(\) Dice & mIoU ID & mIoU OOD & \(\) mIoU \\  UnNet-Base & 93.05 \(\) 0.16 & 56.56 \(\) 0.87 & -36.49 & 95.81 \(\) 0.18 & 57.09 \(\) 0.69 & -38.72 & 91.98 \(\) 0.32 & 43.22 \(\) 0.84 & -48.76 \\ UnNet-ResNet18 & 92.87 \(\) 0.10 & 56.74 \(\) 2.53 & -36.13 & 95.63 \(\) 0.09 & 59.86 \(\) 2.54 & -35.77 & 91.66 \(\) 0.17 & 42.97 \(\) 3.00 & -48.69 \\ TransUNet & 90.63 \(\) 0.20 & 56.24 \(\) 1.66 & -34.39 & 93.28 \(\) 0.27 & 57.51 \(\) 1.84 & -35.77 & 87.49 \(\) 0.47 & 43.86 \(\) 2.04 & -43.63 \\   \\   & Acc ID & Acc OOD & \(\) Acc & Dice ID & Dice OOD & \(\) Dice & mIoU ID & mIoU OOD & \(\) mIoU \\  UnNet-Base & 92.02 \(\) 0.18 & 70.54 \(\) 1.72 & -21.48 & 94.82 \(\) 0.20 & 71.04 \(\) 1.54 & -23.78 & 80.19 \(\) 0.37 & 56.75 \(\) 2.01 & -33.44 \\ UnNet-ResNet18 & 92.70 \(\) 0.12 & 76.40 \(\) 1.33 & -16.30 & 95.50 \(\) 0.11 & 76.59 \(\) 1.28 & -18.91 & 91.43 \(\) 0.20 & 65.17 \(\) 1.80 & -26.26 \\ TransUNet & 88.67 \(\) 0.56 & 70.56 \(\) 0.72 & -18.11 & 91.34 \(\) 0.59 & 72.76 \(\) 0.83 & -18.58 & 84.15 \(\) 0.99 & 59.38 \(\) 1.24 & -24.77 \\   

Table 3: Performance of the baselines in the geo-distributed setting for multi-class segmentation.

Figure 7: Accuracy for factual consistency and completeness increases over the iterations thanks to rigorous the prompt refinement procedure. GPT-4 performs worse on factual completeness potentially due to hallucinations.