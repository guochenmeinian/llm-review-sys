# Solving Inverse Problems via Diffusion Optimal Control

Henry Li

Yale University

henry.li@yale.edu

&Marcus Pereira

Bosch Center for Artificial Intelligence

marcus.pereira@us.bosch.com

Work partially completed during an internship at Bosch AI.

###### Abstract

Existing approaches to diffusion-based inverse problem solvers frame the signal recovery task as a probabilistic sampling episode, where the solution is drawn from the desired posterior distribution. This framework suffers from several critical drawbacks, including the intractability of the conditional likelihood function, strict dependence on the score network approximation, and poor \(_{0}\) prediction quality. We demonstrate that these limitations can be sidestepped by reframing the generative process as a discrete optimal control episode. We derive a diffusion-based optimal controller inspired by the iterative Linear Quadratic Regulator (iLQR) algorithm. This framework is fully general and able to handle any differentiable forward measurement operator, including super-resolution, inpainting, Gaussian deblurring, nonlinear deblurring, and even highly nonlinear neural classifiers. Furthermore, we show that the idealized posterior sampling equation can be recovered as a special case of our algorithm. We then evaluate our method against a selection of neural inverse problem solvers, and establish a new baseline in image reconstruction with inverse problems1.

## 1 Introduction

Diffusion models Song and Ermon (2019); Ho et al. (2020) have been shown to be remarkably adept at conditional generation tasks Dhariwal and Nichol (2021); Ho and Salimans (2022), in part due to their iterative sampling algorithm, which allows the dynamics of an uncontrolled prior score function \(_{} p_{t}()\) to be directed towards an arbitrary posterior distribution by introducing an additive guidance term \(\). When this guidance term is the conditional score \(_{} p_{t}(|)\), the resulting sample is provably drawn from the desired conditional distribution \(p(|)\)Song et al. (2020).

A central obstacle to this framework is the general difficulty of obtaining the conditional score function \(_{} p_{t}(|_{t})\) due to its dependence on the _noisy_ diffusion variate \(_{t}\) rather than just the final sample \(_{0}\)Chung et al. (2023). In large-scale conditional generation tasks such as class- or text-conditional sampling the computational overhead of training a time-dependent conditional score function from scratch is deemed acceptable, and is indeed the approach taken by Rombach et al. (2022); Saharia et al. (2022), and many others. However, this solution is not acceptable in inverse problems where the goal is to design a generalized solver that will work in a zero-shot capacity for an arbitrary forward model.

This bottleneck has spawned a flurry of recent research dedicated to approximating the conditional score \(_{} p_{t}(|_{t})\) as a simple function of the _noiseless_ likelihood \( p(|_{0})\)Choi et al. (2021); Chung et al. (2022); Rout et al. (2024); Chung et al. (2023); Kawar et al. (2022); Chung et al. (2023). However, as we will demonstrate in this work, these approximations impose a significant cost to the performance of the resulting algorithm.

To address these issues, we propose a novel framework built from optimal control theory where such approximations are no longer necessary. By framing the reverse diffusion process as an optimal control episode, we are able to detach the inverse problem solver from the strict requirements of the conditional sampling equation given by Song et al. (2020), while still leveraging the exceptionally powerful prior of the unconditional diffusion process. Moreover, we find that the desired score function directly arises as the Jacobian of the value function.

We summarize our contributions as follows:

* We present diffusion optimal control, a framework for solving inverse problems via the lens of optimal control theory, using pretrained unconditional off-the-shelf diffusion models.
* We show that this perspective overcomes many core obstacles present in existing diffusion-based inverse problem solvers. In particular, the idealized posterior sampling score Song et al. (2021) -- approximated by existing methods -- can be recovered exactly as a specific case of our method.
* We showcase the advantages of our model empirically with quantitative experiments and qualitative examples, and demonstrate state-of-the-art performance on the FFHQ \(256 256\) dataset.

## 2 Background

NotationWe use lowercase letters for denoting scalars \(a\), lowercase bold letters for vectors \(^{n}\) and uppercase bold letters for matrices \(^{m n}\). Subscripts indicate Jacobians and Hessians of scalar functions, e.g. \(l_{}^{n}\) and \(l_{}^{n n}\) for \(l():^{n}\), respectively. We overload notation for time-dependent variables, where subscripts imply dependence rather than derivatives w.r.t. time, e.g., \(_{t}=(t)\). Furthermore, \(V(_{t})\) and \(Q(_{t},_{t})\) are scalar functions despite being uppercase, in line with existing optimal control literature Betts (1998).

### Diffusion Models

The diffusion modeling literature uses the following reverse-time Ito SDE to generate samples Song et al. (2021),

\[_{t}=(_{t})-g(t)^{2}_{ _{t}} p_{t}(_{t})t+g(t) _{t},\] (1)

where \(_{t}^{n}\) is the state vector, \(:^{n}^{n}\) and \(g:\) are drift and diffusion terms that can take different functional forms (e.g., Variance-Preserving SDEs (VPSDEs) and Variance-Exploding SDEs (VESDEs) in Song et al. (2021)), \(_{_{t}} p_{t}(_{t})\) is the score-function and \(_{t}^{n}\) is a vector of mutually independent Brownian motions. The above SDE has an associated ODE called the

Figure 1: **Conceptual illustration comparing a probabilistic posterior sampler to our proposed optimal control-based sampler.** In a probabilistic sampler, the model relies on an approximation \(}_{0}_{0}\) to guide each step **(left)**. We are able to compute \(_{0}\)**exactly** on each step, resulting in much higher quality gradients \( p(|}_{0})\) and an improved trajectory update (**right**).

probability-flow (PF) ODE given by

\[_{t}=_{t}+(_{t })-g(t)^{2}_{_{t}} p_{t}(_{t}) t,\] (2)

with the same marginals \(p_{t}(_{t})\) as the SDE, which allow for likelihood computation (Song et al., 2021; Li et al., 2024). All practical implementations of diffusion samplers require a time-discretization of the PF-ODE. One such discretization is the well-known Euler-discretization which gives,

\[_{t-1}=_{t}-[(_{t})-g(t)^{2 }_{} p_{t}(_{t})] t\] (3)

where, \( t\) is the length of the discretization interval and we have reversed the time evolution by changing the sign of the drift. We are not restricted to only using the Euler-discretization and any high-order discretization techniques can also be employed. More concisely, we have,

\[_{t-1}=(_{t}),\ \ \ : ^{n}^{n}\] (4)

which describes the general non-linear dynamics of the corresponding discrete-time diffusion sampler.

### Posterior Sampling for Inverse Problems

Inverse problems are a general class of problems where an unknown signal is reconstructed from observations obtained by a forward measurement process Ongie et al. (2020). The forward process is usually lossy, resulting in an ill-posed signal recovery task where a _unique_ solution does not exist. The forward model can generally be written as

\[y=(_{0})+,\] (5)

where \(:^{n}^{d}\) is the forward operator, \(y^{d}\) the measured signal, \(_{0}^{n}\) the unknown signal to be recovered, and \((0,_{d})\) the noise (with variance \(^{2}\)) in the measurement process.

Given the forward model Eq. (5) and a measurement \(\), sampling from the posterior distribution \(p_{}(|)\) can then be performed by solving the corresponding _conditional_ Ito SDE

\[=[()-g(t)^{2}_{} p _{t}(|)]t+g(t),\] (6)

where, invoking Bayes rule,

\[_{} p_{t}(|)=_{} p _{t}()+_{} p_{t}(|).\] (7)

As with the unconditional dynamics, Eq. (6) has a corresponding ODE

\[=[()-g(t)^{2}_{ } p_{t}(|)]t,\] (8)

which has an approximate solution obtained by the Euler discretization

\[_{t-1}=_{t}+[f(_{t})-g(t)^{2}_{ _{t}} p_{t}(_{t}|)] t.\] (9)

Figure 2: **Predicted \(_{0}\) used in a probabilistic framework (above) compared to ours (below) for a general diffusion trajectory.** The full forward rollout in our proposed framework allows for the predicted \(_{0}\) (and therefore \(_{_{t}} p(|_{0})\)) to be efficiently computed for all \(t=0,,T\).

### Optimal Control

Optimal control is the structured and principled approach to the guidance of dynamical systems over time. Many methods have been developed in the optimal control literature and are popularly referred to as _trajectory optimization_ algorithms Betts (1998). Perhaps the most well-known is the Iterative Linear Quadratic Regulator (iLQR) algorithm which uses a first-order approximation of the dynamics and second-order approximations of the value-function Li and Todorov (2004).

Formally, let us define an arbitrary user-defined global cost function

\[J_{T}=_{t=T}^{1}_{t}(_{t},\,_{t})+_{0}( _{0}),\] (10)

composed of a sum over scalar-valued _running_ and _terminal_ cost functions \(_{t}\) and \(_{0}\). Optimal control theory dictates that the value function \(V(_{t},\,t):=_{\{_{t}\}_{n=1}^{n=1}}J_{t}\) satisfies the following recursive relation also known as _Bellman's Principle of Optimality_

\[V(_{t},\,t)=_{_{t}}_{t}(_{t},\, _{t})+V(_{t-1},\,t-1).\] (11)

The iLQR algorithm centers around approximating the state-action value function,

\[Q(_{t},\,_{t}):=_{t}(_{t},\,_{t}) +V(_{t-1},\,t-1),\] (12)

from which the value function can be recovered as \(V(_{t},\,t)=_{_{t}}Q(_{t},\,_{t})\).

Then given a state transition function \(_{t}=(_{t+1},_{t+1})\) where we crucially note that we have defined time to flow _backwards_ from \(t=T,,0\), the iLQR algorithm has feedforward and feedback gains

\[=-Q_{}^{-1}Q_{} =-Q_{}^{-1}Q_{}\] (13)

The update equations can be written as

\[V_{}=Q_{}-^{T}Q_{} V_{}=Q_{}- ^{T}Q_{}.\] (14)

Given the feedforward and feedback gains \(\{(_{t},_{t})\}_{t=0}^{T}\) and \(}_{0}:=_{0}\), we can recursively obtain the locally optimal control at time \(t\) as a function of the present states \(_{t}\) and controls \(_{t}\) as

\[}_{t} =(}_{t+1},_{t+1}^{*}),\] (15) \[_{t}^{*} =_{t}++(}_{t }-_{t}).\] (16)

For a more detailed treatment of iLQR as well as a derivation of the equations, please see Appendix B.

## 3 Diffusion Optimal Control

We motivate our framework by observing that the reverse diffusion process Eq. (1) is an uncontrolled non-linear dynamical system that evolves from some initial state (at time \(t=T\)) to some terminal state (at time \(t=0\)). By injecting control vectors \(_{t}\) into this system we can influence its behavior and hence its terminal state (i.e., the generated data) to sample from a desired \(p(|)\). There are two obvious ways to inject control into this process:

Figure 3: **Inverse problem solution as a function of total diffusion timesteps \(T\) for the \(4\) super-resolution task.** Compared to DPS (**top row**), our method (**bottom row**) produces solutions that are higher quality, in greater agreement with the inverse problem contraint \(=\), and more stable across \(T\).

1. In **input perturbation control**, we apply the \(_{t}\)_before_ the diffusion step: \[_{t-1}=(_{t}+_{t})-(_{ t}+_{t})-g(t)^{2}_{} p_{t}(_{t}+ _{t}) t.\] (17)
2. In **output perturbation control**, \(_{t}\) is applied _after_ the diffusion step: \[_{t-1}=_{t}-(_{t})-g (t)^{2}_{} p_{t}(_{t}) t+_{t}.\] (18)

Observe that iLQR is formulated for general discrete-time dynamic processes. When applied specifically to the reverse diffusion dynamics of diffusion models, we are able to make several simplifications. First, we assume that we do not have access to any guidance except at time \(t=0\) -- i.e., \(_{t}(_{t},_{t})\) does not depend on \(_{t}\).

In the case of **input perturbation control**, we observe from Eq. (17) that \(_{}=_{}\), whereas **output perturbation control** implies that \(_{}=\), resulting in the left and right equations, respectively:

\[Q_{} =_{}^{T}V_{}^{} Q_{} =_{}^{T}V_{}^{}\] (19) \[Q_{} =_{}+_{}^{T}V_{}^{} Q_{} =_{}+V_{}^{}\] (20) \[Q_{} =_{}^{T}V_{}^{} _{} Q_{} =_{}^{T}V_{}^{}_{}\] (21) \[Q_{} =Q_{} =_{}^{T}V_{}^{} _{} Q_{} =_{}+V_{}^{}.\] (22)

The derivatives of \(V\) can then be backpropagated using the following equations:

\[V_{} =Q_{}-^{T}Q_{} =Q_{}-^{T}Q_{}\] \[=Q_{}+Q_{}^{T}Q_{}^{-1}Q_{}\] (24) \[V_{} =Q_{}-^{T}Q_{} \] \[=Q_{}-Q_{}^{T}Q_{}^{-1}Q_{}.\] (25)

In high dimensional systems such as Eq. 3, matrices may be singular. Therefore, a Tikhonov regularized variant of iLQR is often employed, where matrix inverses are regularized by a diagonal matrix \(\)Tassa et al. (2014).

### High Dimensional Control

Compared to the dynamics in traditional application areas of optimal control, those we consider in Eqs. (17- 18) are much higher dimensional in the state \(\) and control \(\) variates. Therefore, iLQR faces several unique computational bottlenecks when applied to such control problems.

In particular, the Jacobian matrices \(_{},_{}\) and the second-order derivative matrices \(V_{},Q_{},Q_{},Q_ {}\), and \(Q_{}\) are particularly expensive to compute, store, and perform downstream operations against. For example, in a three-channel \(256 256\) image, these matrices naively contain \((256 256 3)^{2} 39B\) parameters.

In Appendix D.1 we propose and analyze three modifications to the standard iLQR algorithm: **randomized low rank approximations**, **matrix-free evaluations**, and action updates via an **adaptive optimizer**, that significantly reduce runtime and memory constraints while introducing minimal deterioration to performance on inverse problem solving tasks.

## 4 Improved Posterior Sampling

We demonstrate that our optimal control-based sampler overcomes several practical obstacles that plague existing diffusion-based methods for inverse problem solvers.

Brittleness to DiscretizationIn a probabilistic framework, solutions to inverse problems incur a discretization error from the numerical solution of Eq. (8) that decays poorly with the total diffusion steps \(T\) of the diffusion process. While much research has been conducted on the acceleration of unconditional diffusion processes Song et al. (2020); Jolicoeur-Martineau et al. (2021); Karras et al. (2022); Meng et al. (2023), sample quality appears to decay much more aggressively in diffusion-based inverse problem solvers (Figure 3).

We theorize that this is due to two reasons: 1) the posterior sampler Eq. (9) is only correct in the limit of infinitely small time steps, and 2) the quality of the approximated conditional score term \(_{} p(|_{t})\) decays quickly with time (Figure 2), and so fewer timesteps lead to fewer chances at low \(t\) to correct errors made at high \(t\). On the other hand, since optimal control directly casts the **discretized** process as an end-to-end control episode, it produces a feasible solution for any number of discretization steps \(T\).

Intractability of \(_{_{t}} p(|_{t})\)When the forward model \(\) is known and \(\) comes from a simple distribution, the conditional likelihood \(p(|_{t})\) can be derived in closed form for \(t=0\). On the other hand, the dependence of \(y\) on \(_{t}\) for \(t>0\) is generally not known without explicitly computing \(_{0}\), which requires sampling from the diffusion process. Ultimately, obtaining the conditional score term \(_{_{t}} p(|_{t})\) is a highly nontrivial task Song et al. (2021).

To sidestep this issue, many works Meng and Kabashima (2022); Song et al. (2022); Chung et al. (2023) factorize this term as the integral

\[p(|_{t})= p(|_{0})p(_{0 }|_{t})d_{0}\] (26)

and then apply a series of approximations to recover a computationally feasible estimate of the conditional score. First, the marginal \(p(_{0}|_{t})\) is replaced by the marginal conditioned on \(_{0}\), i.e.

Figure 4: **Examples from inverse problem tasks on FFHQ \(256 256\). From left to right each column contains ground truth, measurement, Diffusion Posterior Sampling (DPS), and ours.**

\(p(_{0}|_{t},_{0})=(_{0},^ {2})\)Kim and Ye (2021). Next, the \(_{0}\)-centered marginal is replaced by the posterior mean \([_{0}|_{t}]\) given by Tweedie's formula Efron (2011). Finally, the true score is replaced by the learned score network.

While these approximations are necessary in a probabilistic framework, we show that they are not required in our method. Intuitively, this is because the linear quadratic regulator backpropagates the control cost \( p(|)\) through a forward trajectory rollout, which naturally computes the true conditional score at each time \(t\). Moreover, our model always estimates \(_{0}|_{t}\) exactly (up to the discretization error induced by solving Eq. 3), rather than forming an approximation \(}_{0}_{0}\) (Figure 2). We formalize this observation with the following statement.

**Theorem 4.1**.: _Let Eq. 3 be the discretized sampling equation for the diffusion model with **output perturbation mode** control (Eq. 18). Moreover, let the terminal cost_

\[_{0}(_{0})=- p(|_{0})\] (27)

_be twice-differentiable and the running costs_

\[_{t}(_{t},_{t})=0.\] (28)

_Then the iterative linear quadratic regulator with Tikhonov regularizer \(\) produces the control_

\[_{t}=_{_{t}} p(|_{0}).\] (29)

In other words, by framing the inverse problem as an unconditional diffusion process with controls \(_{t}\), our proposed method produces controls that coincide precisely with the desired conditional scores \(_{_{t}} p(|_{0})\).

Let us further assume that \( p(|_{t})= p(|_{0})\), i.e., \(_{t}\) contains no additional information about \(y\) than \(_{0}\). This assumption results in the posterior mean approximation in Chung et al. (2023) under stochastic dynamics (Eq. 1), where we additionally obtain _exact_ computation of \(_{0}\), rather than \(}_{0}_{0}\)via Tweedie's formula Kim and Ye (2021). Under the deterministic ODE dynamics (Eq. 2), we recover the **true posterior sampler** under appropriate choice of Tikhonov regularization constant \(\).

**Lemma 4.2**.: _Under the deterministic sampler with **output perturbation mode** control, \(= t}\) recovers posterior sampling (Eq. 9)._

We demonstrate a similar result with **input mode perturbation**.

**Theorem 4.3**.: _Let Eq. 3 be the discretized sampling equation for the diffusion model with **input perturbation mode** control (Eq. 17). Moreover, let_

\[_{0}(_{0})= p(|_{0}),\] (30)

_and the running costs_

\[_{t}(_{t},_{t})=0.\] (31)

_Then the iterative linear quadratic regulator with Tikhonov regularizer \(= t}\) produces the dynamical sytem_

\[}_{t}=}_{t}+[f( {}_{t})-g(t)^{2}(_{} p_{t}( }_{t})\] \[+_{} p_{t}(|_{t}))] t,\] (32)

_where \(}_{t}:=_{t}+_{t}\)._

Observe that Eq. (32) can be understood as a predictor-corrector sampling method, where the predictor produces an unconditional reverse diffusion update and the corrector produces a conditional correction step on the intermediary variable \(_{t}=}_{t}-_{t}\).

Ultimately, these results demonstrate that our proposed method is able to recover the idealized sampling procedure under mild assumptions on the diffusion optimal control algorithm.

Dependence on the Approximate ScoreWhile our theoretical results require that the learned score function \(s_{}(_{t},t)\) approximates the true data score \( p_{t}(_{t},t)\), we emphasize that the performance of our method does not necessitate this condition. In fact, we find that reconstruction performance is theoretically and empirically robust to the accuracy of the approximated prior score \(s_{}(_{t},t)_{_{t}} p_{t}(_{t})\) or conditional score \(_{_{t}} p_{t}(|_{0})_{ _{t}} p_{t}(|_{t})\) terms. This is because the optimal control-based solution is formulated for the optimization of generalized dynamical systems, and thus agnostic to the diffusion sampling process.

Certainly, improved approximation of the score terms result in a better-informed prior and usually higher sample quality. However, we demonstrate that our sampler produces remarkably reasonable solutions even in the case of randomly initialized diffusion models. Conversely, probabilistic posterior samplers can only sample from \(p(|_{0})\) when the terms composing the posterior sampling equation (Eq. (8)) are well approximated (Figure 6). Modeling errors can occur even in foundation models. For example, this scenario may arise in models trained on regions where there are underrepresented examples in the data. When these arise from existing social or ethical biases, they can further perpetuate or amplify biases to the resulting model if left unaddressedBolukbasi et al. (2016); Birhane et al. (2021); Srivastava et al. (2022).

There exist several methods that seek to alleviate the errors incurred by Tweedie's formula (being a mean approximation of the diffusion process), including Song et al. (2024) which imposes a hard data consistency optimization loop at various points in the diffusion process, and Rout et al. (2023) which includes a stochastic averaging loop in each step of the diffusion process. However, these methods still rely on Tweedie's formula for the error reduction scheme, which assumes access to a ground truth score function. Ultimately, the aforementioned problems in the present section are exacerbated in existing samplers, and relatively less consequential in our solver.

## 5 Related Work

The recent success of diffusion models in image generation Song and Ermon (2019); Ho et al. (2020); Song et al. (2021); Rombach et al. (2022) has spawned a surge of research in deep learning-based solvers to inverse problems. Song et al. (2021) demonstrated a strategy for provably sampling from the solution set \(p(|)\) of a general inverse problem \(=()\) using only an unconditional prior score model \(_{} p_{t}()\) and a forward probabilistic model \( p(|_{t})\). However, a crucial problem arises in the intractability of forward probabilistic model, which depends on the noisy \(_{t}\) rather than the final \(_{0}\). This has resulted in a series of approximation algorithms Choi et al. (2021); Kawar et al. (2022); Chung et al. (2022, 2023, 2022); Kawar et al. (2023) for the true conditional diffusion dynamics.

Topics in control theory have been applied to deep learning Liu et al. (2020); Pereira et al. (2020) as well as diffusion modeling Berner et al. (2022). Optimal control can also be connected to diffusion processes via forward-backward SDEs Chen et al. (2021). However, these ideas have not been applied to guided conditional diffusion processes solely at inference time, nor for guided conditional sampling. Our proposed optimal control-based algorithm is, to our knowledge, the first such framework for deep inverse problem solvers.

    &  &  &  &  &  \\   & FID \(\) & LPIPS \(\) & FID \(\) & LPIPS \(\) & FID \(\) & LPIPS \(\) & FID \(\) & LPIPS \(\) & FID \(\) & LPIPS \(\) \\  Ours (NFE = 2500) & **32.47** & **0.171** & **15.93** & **0.053** & **20.22** & **0.122** & **31.80** & **0.189** & **39.40** & **0.217** \\ Ours (NFE = 1000) & 37.53 & 0.189 & 20.75 & 0.108 & 23.88 & 0.164 & 35.24 & 0.191 & 45.99 & 0.233 \\  PSLD (NFE = 1000) & 34.28 & 201.21 & 3.049 & 0.431 & 0.167 & 41.53 & 0.221 & - & - \\ Flash-Diffusion*(NFE = _varies_) & - & - & 53.95 & 0.195 & - & - & 65.35 & 0.280 & 64.57 & 0.267 \\ DDNM (NFE = 1000) & 68.94 & 0.328 & 105.38 & 0.802 & 72.28 & 0.483 & 126.0 & 0.995 & - & - \\ DPS (NFE = 1000) & 39.35 & 0.214 & 33.12 & 0.168 & 21.19 & 0.212 & 44.05 & 0.257 & 39.92 & 0.242 \\ DDRM (NFE = 1000) & 62.15 & 0.294 & 42.93 & 0.204 & 69.71 & 0.587 & 74.92 & 0.332 & - & - \\ MCG (NFE = 1000) & 87.64 & 0.520 & 40.11 & 0.309 & 29.26 & 0.286 & 101.2 & 0.340 & 310.5 & 0.702 \\ PP-ADMM & 65.52 & 0.353 & 151.9 & 0.406 & 123.6 & 0.692 & 90.42 & 0.441 & 89.08 & 0.405 \\ Score-SDE (NFE = 1000) & 96.72 & 0.563 & 60.06 & 0.331 & 76.54 & 0.612 & 109.0 & 0.403 & 292.2 & 0.657 \\ ADMM-TV & 110.6 & 0.428 & 68.94 & 0.322 & 181.5 & 0.463 & 186.7 & 0.507 & 152.3 & 0.508 \\   

Table 1: Quantitative evaluation (FID, LPIPS) of model performance on inverse problems on the FFHQ \(256\)x\(256\)-1K dataset.

## 6 Experiments

Following previous work Chung et al. (2023); Meng and Kabashima (2022); Kawar et al. (2022), we consider five inverse problems. 1) In \(4\) image super-resolution, we use the bicubic downsampling operator. 2) In randomized inpainting, we uniformly omit 92% of all pixels (across all channels). 3) In box inpainting, we mask out a \(128 128\) block uniformly sampled from a 16 pixel margin from each side of the image, as in Chung et al. (2022). 4) In Gaussian deblurring, we use a kernel of size \(61 61\) and standard deviation \(3.0\). In motion deblurring, we generate images according to a library2 of point spread functions with kernel size \(61 61\) and intensity \(0.5\). Following the experimental design in Chung et al. (2023), we apply Gaussian noise with standard deviation \(0.05\) to all measurements of the forward model.

We compare against a generalized diffusion inverse sampler (Score-SDE) proposed in Song et al. (2021), Diffusion Posterior Sampling (DPS) Chung et al. (2023), Denoising Diffusion Restoration Models Kawar et al. (2022), Manifold Constrained Gradients (MCG) Chung et al. (2022), as well as two recent latent diffusion-based methods Fabian et al. (2023) (Flash-Diffusion3) and Rout et al. (2024) (PSLD). For non-diffusion baselines, we compare against Plug-and-Play Alternating Direction Method of Multipliers (PnP-ADMM) with neural proximal maps Chan et al. (2016); Zhang et al. (2017), and a total-variation based alternating direction method of multipliers (TV-ADMM) baseline proposed in Chung et al. (2023).

We validate our results on the high resolution human face dataset FFHQ \(256 256\)Karras et al. (2019). Several methods are model agnostic (DPS, DDRM, MCG, and thus evaluated with the same pre-trained diffusion models. To fairly compare between all models, all methods use the model weights from Chung et al. (2023), which are trained on 49K FFHQ images, with 1K images left as a held-out set for evaluation. We compare our algorithm against competing frameworks on these last 1K images. We report our results on FFHQ \(256 256\) in Table 1, and demonstrate improvements on all tasks against previous methods. Finally, we demonstrate the performance of our algorithm on the nonlinear inverse problem of class-conditional generation. Namely, let \(()=()\) and \(p(|)\) be its associated probability. We compare our method to DPS on the inverse task of generating an MNIST digit given a label \(\). Compared to images generated by DPS, images from our method exhibit more pronounced class alignment and higher overall sample quality (Figure 5).

## 7 Conclusion

In this paper we presented a novel perspective on tackling inverse problems with diffusion models - framing the discretized reverse diffusion process as a discrete time optimal control episode. We demonstrate that this framework alleviates several core problems in probabilistic solvers: its dependence on the approximation quality of the underlying terms in the diffusion process, its sensitivity to the temporal discretization scheme, its inherent inaccuracy due to the intractability of the conditional score function. We also show that the diffusion posterior sampler can be seen as a specific case of

Figure 5: **Examples from the class-conditional inverse problem.** DPS (left) is compared against ours (right). Each row is a different target MNIST class.

Figure 6: **Robustness to approximation quality of the score function.** We consider the \(4\) super-resolution task with a _randomly initialized_ diffusion model. Since the reverse diffusion process is no longer well approximated, DPS cannot produce a feasible solution, while our method still can.

our optimal control-based sampler. Finally, leveraging the improvements granted by our solver, we validate the performance of our algorithm on several inverse problem tasks across several datasets, and demonstrate highly competitive results.