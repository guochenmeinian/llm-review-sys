# Fast, Precise Thompson Sampling for Bayesian Optimization

David Sweet

Department of Computer Science

Yeshiva University

New York, NY 10174

david.sweet@yu.edu

###### Abstract

Thompson sampling (TS) has optimal regret and excellent empirical performance in multi-armed bandit problems. Yet, in Bayesian optimization, TS underperforms popular acquisition functions (e.g., EI, UCB). TS samples arms according to the probability that they are optimal. A recent algorithm, P-Star Sampler (PSS), performs such a sampling via Hit-and-Run. We present an improved version, Stagger Thompson Sampler (STS). STS more precisely locates the maximizer than does TS using less computation time. We demonstrate that STS outperforms TS, PSS, and other acquisition methods in numerical experiments of optimizations of several test functions across a broad range of dimension. Additionally, since PSS was originally presented not as a standalone acquisition method but as an input to a batching algorithm called Minimal Terminal Variance (MTV), we also demonstrate that STS matches PSS performance when used as the input to MTV.

## 1 Introduction

Bayesian optimization (BO) is applied to many experiment- and simulation-based optimization problems in science and engineering . The aim of BO methods is to minimize the number of measurements needed to find a good system configuration. Measurements are taken in a sequence of batches of one or more _arms_ - where an arm is one system configuration. System performance is measured for each arm in a batch, then a new batch is produced, performance is measured, and so on.

Thompson sampling (TS) samples arms according to the probability that they maximize system performance . Let's denote an arm as \(x_{a}\), its performance as \(f(x_{a})\), and the probability that an arm is best, i.e., that \(x_{a}=*{argmax}_{x}f(x)\), as \(p_{*}(x)\). TS draws an arm as: \(x_{a} p_{*}(x)\). TS has optimal or near-optimal regret  for multi-armed bandits (MAB) and is also used in BO .

Application of TS to BO is not straightforward. Since BO arms are typically continuous - e.g., \(x^{d}\) - sampling from \(p_{*}(x)\) is non-trivial. The usual approach is to first sample many candidate arms uniformly, \(x_{i}(^{d})\), then draw a value, \(y_{i}\), from a model distribution of \(f(x)\) at each \(x_{i}\). The \(x_{i}\) that yields the highest-valued draw, i.e., \(x_{a}=*{argmax}_{x_{i}}y(x_{i})\), is taken as the arm. BO methods usually model \(y(x)\) with a Gaussian process, \(\), i.e. \(y(x)((x),^{2}(x))\). While appealing for its simplicity, TS, implemented as described, tends to underperform popular acquisition functions such as Expected Improvement (EI)  or Upper Confidence bound (UCB)  (see Subsection 3.2).

## 2 Stagger Thompson Sampling

The TS arm candidates, being uniform in \(^{d}\), are unlikely to fall where \(p_{*}(x)\) has high density. If we imagine that the bulk of \(p_{*}(x)\) lies in a hypercube of side \(<1\), then the probability that a randomly-chosen \(x^{d}\) falls in the hypercube is just the hypercube volume, \(v=^{d}\). Note that (i) \(v\) decreases exponentially with dimension, and (ii) \(\), thus \(v\), decreases with each additional measurement added to the model of \(p_{*}(x)\) (see figure 5(c) in appendix A). Effect (ii) is the aim of BO - to localize the maximizer. Effect (i) is the "curse of dimensionality". Thus, the number of candidates required to find the bulk of \(p_{*}(x)\) (i) increases exponentially in dimension, and (ii) increases with each additional measurement (albeit in a non-obvious way).

The P-Star Sampler (PSS)  is a Hit-and-Run  sampler with a Metropolis filter . Our algorithm, Stagger Thompson Sampler (STS), is, also, but differs in several details, discussed below algorithm 1.

```
1:if no measurements yet then
2:return\(x_{i}(^{d})\)\(\)Take \(p_{*}(x)\) prior as uniform in \(x\)
3:\(_{*}=*{argmax}_{x}(x)\)\(\)\((x)\) is mean of a given \(\)
4:\(x_{a}=_{*}\)\(\)Initialize arm
5:forall\(m 1,,M\)do\(\)Refine arm \(M\) times
6:\(x_{t}=(^{d})\)\(\)Perturbation target
7:\(s=e^{-k()}\)\(\)\(A\)"stagger" perturbation length
8:\(x^{}_{a}=x_{a}+s(x_{t}-x_{a})\)\(\)Perturbations
9:\([y,y^{}]([x_{a},x^{}_{a}])\)\(\)Joint sample
10:\(x_{a} x^{}_{a}\)if\(y^{}>y\)\(\)MH acceptance
11:return\(x_{a}\)\(\)A sample from \(p_{*}(x)\) ```

**Algorithm 1** Stagger Thompson Sampler

Algorithm 1 modifies vanilla Hit-and-Run in two ways: (i) Instead of initializing randomly, we initialize an arm candidate, \(x_{a}\), at \(_{*}\). (ii) Instead of perturbing uniformly along some direction - since the scale of \(p_{*}(x)\) is unknown and may be small - we choose the length of the perturbation uniformly in its exponent, i.e. as \( e^{-kU}\), a log-uniform random variable. (\(k\) is a hyperparameter, which we choose to be \(k= 10^{-6}\)). Numerical ablation studies in appendix B show that these modifications improve performance in optimization. We refer to the log-uniform perturbation as a "stagger" proposal, following . Besides being empirically effective, a stagger proposal also obviates the need to adapt the scale of the proposal distribution, as is done in PSS (which uses a Gaussian proposal). We see this as a valuable, practical simplification.

Since a log-uniform distribution is a symmetric proposal we expect the Markov chain generated by algorithm 1 to converge to \(p_{*}(x)\). Appendix A provides some numerical support for this.

Perturbations are made along a line from \(x_{a}\) to a target point, \(x_{t}\), which is chosen uniformly inside the bounding box, \(^{d}\). This ensures that the final perturbation [a convex combination of points in the (convex) bounding box] will lie inside the bounding box. It also simplifies the implementation somewhat, since boundary detection is unnecessary. PSS performs a bisection search to find the boundary of the box along a randomly-oriented line passing through \(x_{a}\).

We accept a perturbation of \(x\), \(x^{}\), with Metropolis acceptance probability \(p_{acc}=\{1,p_{*}(x^{})/p_{*}(x)\}\). As a coarse (and fast) approximation to \(p_{acc}\), we follow PSS and just take a single joint sample from \(\) and accept whichever point, \(x\) or \(x^{}\), has a larger sample value. Note that this is a Thompson sample from the set \(\{x,x^{}\}\), so we might describe STS as iterated Thompson sampling.

Appendix A offers numerical evidence that (i) samples from STS are nearer the true maximizer than are samples from TS, and (ii) STS produces samples more quickly than standard TS while better approximating \(p_{*}(x)\).

Previous work applying MCMC methods to Thompson sampling include random-walk Metropolis algorithms constrained to a trust region  and a sequential Monte Carlo algorithm .

## 3 Numerical Experiments

To evaluate STS, we optimize various test functions, tracking the maximum measured function value at each round and comparing the values to those found by other methods. We use the term _round_ to refer to the generation of one or more arms followed by the measurement of them.

### Ackley-200d

To introduce our comparison methodology, we compare STS to a few other optimization methods, in particular to TuRBO, a trust-region-enhanced Thompson sampling method . In , the authors optimize the Ackley function in 200 dimensions with 100 arms/round on a restricted subspace of parameters. Figure 2 optimizes the same function on the standard parameter space using STS, TuRBO, and other methods. STS finds higher values of \(y\) more quickly than the other methods.

We can summarize each method's performance in Figure 2 with a single number, which we'll call the _score_. At each round, \(i\), find the maximum measured values so far for each method, \(m\): \(y_{i,m}\). Rank these values across \(m\) and scale: \(r_{i,m}=[(y_{i,m})-1]/(M-1)\), where \(M\) is the number of methods. Repeat this for every round, \(i\), then average over all \(R\) rounds to get the score: \(s_{m}=_{i}^{R}r_{i,m}/R\). The scores in figure 2 are \(s_{}=1\), \(s_{}=2/3\), \(s_{}=1/2\), and \(s_{}=0\).

Figure 1: Two iterations of the for loop in algorithm 1. Hash marks indicate the log-uniform (stagger) distribution for \(s\). A Thompson sample – a joint sample, \(([x_{a},x_{a}^{}])\) – determines whether \(x_{a}\) updates to \(x_{a}^{}\).

Figure 2: We maximize the Ackley function in 200 dimensions over 100 rounds of 100 arms/round. The error areas are twice the standard error over 10 runs. STS (sts) finds higher values more quickly than other optimization methods: turbo-1 - TuRBO  with one trust region. cma - CMA-ES , an evolution strategy. random - Choose arms uniformly randomly (serving as a baseline). .

Using an normalized score enables us to average over runs on different functions (which, in general, have different scales for \(y\)). Using a rank-based score prevents a dramatic result, like the one in figure 2, from dominating the average.

In our experiments below we optimize over nine common functions. To add variety to the function set and to avoid an artifact where an optimization method might coincidentally prefer to select points near a function's optimum (e.g., at the center of the parameter space), we randomly distort each function as in , repeating the optimization 30 times with different random distortions.

### One arm per round

We compare STS to other BO methods in dimensions 3 through 300, all generating one arm per round. For each dimension, each method's score is averaged over all test functions. See Figure 3. STS has the highest score in each dimension, and its advantage appears to increase with dimension. Data from dimensions 1, 10, and 100 (unpublished for space) follow the same pattern.

The various optimization methods are: sts - Stagger Thompson Sampling (Algorithm 1), random - Uniformly-random arm, sobol - Uniform, space-filling arms [18, Chapter 5], sr - Simple Regret, \((x)\), ts - Thompson Sampling ,ucb - Upper Confidence Bound , ei - Expected Improvement , gibbon - GIBBON, an entropy-based method , and optuna - an open-source optimizer  employing a tree-structured Parzen estimator . For the methods ei, lei,ucb, sr, gibbon, and turbo-1, we initialize by taking a Sobol' sample for the first round's arm. sts and ts do not require initialization.

STS makes no explicit accommodations for higher-dimensional problems yet performs well on them. Of the methods evaluated, only turbo-1 specifically targets higher-dimensional problems , so it may be valuable for future work to compare STS to other methods specifically designed for such problems. (See references to methods in .)

### Multiple arms per round

Thompson sampling can be extended to batches of more than one arm simply by taking multiple samples from \(p_{*}(x)\), e.g., by running Algorithm 1 multiple times. However, this approach can be inefficient  because some samples - since they are independently generated - may lie very near each other and, thus, provide less information about \(f(x)\) than if they were to lie farther apart. This problem, that of generating effective batches of arms, is not unique to TS but exists for all approaches to acquisition, and there are various methods for dealing with it .

One method, Minimal Terminal Variance (MTV) , minimizes the post-measurement, average variance of the GP, weighted by \(p_{*}(x)\):

\[MTV(x_{a})= dx\;p_{*}(x)^{2}(x|x_{a})\] (1)

approximated by \(_{i}^{2}(x_{i}|x_{a})\), where \(x_{i}\) are drawn from \(x_{i} p_{*}(x)\) with P-Star Sampler (PSS). MTV is interesting, in part, because it can design experiments both when prior measurements are available and _ab initio_ (e.g., at initialization time). It not only outperforms acquisition functions

Figure 3: We optimize for \((30,)\) rounds with num_arms / round over the functions ackley, disornprice, griewank, levy, michalewicz, rastrigin, rosenbrock, sphere, and stybtang  with random distortions (see section 3.1). Error bars are two standard errors over all functions and 30 runs/function. Figure represents a total of 874,800 function evaluations. (We were not able to run pss for num_dim=300 due to long computation times.

(like EI or UCB) but the same formulation also outperforms common initialization methods, such as Sobol' sampling .

We modify MTV to draw \(x_{i} p_{*}(x)\) using STS instead of PSS. Note, also, that the arms, \(x_{a}\), that minimize \(MTV(x_{a})\) are not drawn from the set \(x_{i}\) but are chosen by a continuous minimization algorithm (specifically, scipy.minimize, as implemented in ), such that \(x_{a}=*{argmin}_{x^{}_{a}}_{i}^{2}(x_{i}|x^{ }_{a})\).

Figure 4 compares MTV, with P-Star Sampler replaced by STS (mtv+sts), to other methods using various dimensions (num_dim) and batch sizes (num_arms): mtv - MTV, as in , lei - q-Log EI, an improved EI , and dpp - DPP-TS , a diversified-batching TS. For the methods ei, ucb, sr, gibbon, and dpp, we initialize by taking Sobol' samples for the first round.sts, mtv, and mtv+sts do not require initialization.

Figure 4 roughly reproduces figure 3 of , adding more methods and extending to higher dimensions. Additionally, we include pure PSS and STS sampling, where arms are simply independent draws from \(p_{*}(x)\), to highlight the positive impact of MTV on batch design.

When MTV's input samples come from STS (mtv+sts), performance is similar to the original MTV (mtv).

## 4 Conclusion

We presented Stagger Thompson Sampler, which is novel in several ways:

* It outperforms not only the standard approach to Thompson sampling but, also, popular acquisition functions, a trust region Thompson sampling method, and an evolution strategy.
* It is simpler and more effective at acquisition than an earlier sampler (P-Star Sampler).
* It works on high-dimensional problems without modification.

Additionally, the combination MTV+STS is unique in that it applies to so broad a range of optimization problems: It solves problems with zero or more pre-existing measurements, with one or more arms/batch, and in dimensions ranging from low to high.