# Generator Identification for Linear SDEs with Additive and Multiplicative Noise

Yuanyuan Wang

The University of Melbourne

yuanyuanw2@student.unimelb.edu.au

&Xi Geng

The University of Melbourne

xi.geng@unimelb.edu.au

&Wei Huang

The University of Melbourne

wei.huang@unimelb.edu.au

&Biwei Huang

University of California, San Diego

bih007@ucsd.edu

&Mingming Gong

The University of Melbourne

mingming.gong@unimelb.edu.au

Corresponding author.

###### Abstract

In this paper, we present conditions for identifying the **generator** of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.

## 1 Introduction

Stochastic differential equations (SDEs) are a powerful mathematical tool for modelling dynamic systems subject to random fluctuations. These equations are widely used in various scientific disciplines, including finance , physics , biology  and engineering . In recent years, SDEs have garnered growing interest in the machine learning research community. Specifically, they have been used for tasks such as modelling time series data  and estimating causal effects .

To enhance understanding we first introduce the SDEs of our interest, which are multidimensional linear SDEs with additive and multiplicative noise, respectively. Consider an \(m\)-dimensional standard Brownian motion defined on a filtered probability space \((,,,\{_{t}\})\), denoted by \(W:=\{W_{t}=[W_{1,t},,W_{m,t}]^{}:0 t<\}\). Let \(X_{t}^{d}\) be the state at time \(t\) and let \(x_{0}^{d}\) be a constant vector denoting the initial state of the system, we present the forms of the aforementioned two linear SDEs.

1. Linear SDEs with additive noise. \[dX_{t}=AX_{t}dt+GdW_{t}\,,\;\;\;X_{0}=x_{0}\,,\] (1) where \(0 t<\), \(A^{d d}\) and \(G^{d m}\) are some constant matrices.
2. Linear SDEs with multiplicative noise. \[dX_{t}=AX_{t}dt+_{k=1}^{m}G_{k}X_{t}dW_{k,t}\,,\;\;\;X_{0}=x_{0}\,,\] (2) where \(0 t<\), \(A,G_{k}^{d d}\) for \(k=1,,m\) are some constant matrices.

Linear SDEs are wildly used in financial modeling for tasks like asset pricing, risk assessment, and portfolio optimization [3; 10; 24]. Where they are used to model the evolution of financial variables, such as stock prices and interest rates. Furthermore, linear SDEs are also used in genomic research, for instance, they are used for modeling the gene expression in the yeast microorganism Saccharomyces Cerevisiae . The identifiability analysis of linear SDEs is essential for reliable causal inference of dynamic systems governed by these equations. For example, in the case of Saccharomyces Cerevisiae, one aims to identify the system such that making reliable causal inference when interventions are introduced. Such interventions may involve deliberate knockout of specific genes to achieve optimal growth of an organism. In this regard, identifiability analysis plays a pivotal role in ensuring reliable predictions concerning the impact of interventions on the system.

Previous studies on identifiability analysis of linear SDEs have primarily focused on Gaussian diffusions, as described by the SDE (1) [6; 16; 23; 28; 35; 42]. These studies are typically based on observations located on one trajectory of the system and thus require restrictive identifiability conditions, such as the ergodicity of the diffusion or other restrictive requirements on the eigenvalues of matrix \(A\). However, in practical applications, multiple trajectories of the dynamic system can often be accessed [15; 31; 45; 54]. In particular, these multiple trajectories may start from the same initial state, e.g., in experimental studies where repeated trials or experiments are conducted under the same conditions [9; 12; 26; 29] or when the same experiment is performed on multiple identical units . To this end, this work presents an identifiability analysis for linear SDEs based on the distribution of the observational process with a given fixed initial state. Furthermore, our study is not restricted to Gaussian diffusions (1), but also encompasses linear SDEs with multiplicative noise (2). Importantly, the conditions derived for both types of SDEs are generic, meaning that the set of system parameters that violate the proposed conditions has Lebesgue measure zero.

Traditional identifiability analysis of dynamic systems focuses on deriving conditions under which a unique set of parameters can be obtained from error-free observational data. However, our analysis of dynamic systems that are described by SDEs aims to uncover conditions that would enable a unique generator to be obtained from its observational distribution. Our motivation for identifying generators of SDEs is twofold. Firstly, obtaining a unique set of parameters from the distribution of a stochastic process described by an SDE is generally unfeasible. For example, in the SDE (1), parameter \(G\) cannot be uniquely identified since one can only identify \(GG^{}\) based on the distribution of its solution process [17; 28]. Secondly, the identifiability of an SDE's generator suffices for reliable causal inferences for this system. Note that, in the context of SDEs, the main task of causal analysis is to identify the post-intervention distributions from the observational distribution. As proposed in , for an SDE satisfying specific criteria, the post-intervention distributions are identifiable from the generator of this SDE. Consequently, the intricate task of unraveling causality can be decomposed into two constituent components through the generator. This paper aims to uncover conditions under which the generator of a linear SDE attains identifiability from the observational distribution. By establishing these identifiability conditions, we can effectively address the causality task for linear SDEs.

In this paper, we present a sufficient and necessary identifiability condition for the generator of linear SDEs with additive noise (1), along with a sufficient identifiability condition for the generator of linear SDEs with multiplicative noise (2).

## 2 Background knowledge

In this section, we introduce some background knowledge of linear SDEs. In addition, we provide a concise overview of the causal interpretation of SDEs, which is a critical aspect of understanding the nature and dynamics of these equations. This interpretation also forms a strong basis for the motivation of this research.

### Background knowledge of linear SDEs

The solution to the SDE (1) can be explicitly expressed as (cf. ):

\[X_{t}:=X(t;x_{0},A,G)=e^{At}x_{0}+_{0}^{t}e^{A(t-s)}GdW_{s}\,.\] (3)

Note that in the context of our study, the solution stands for the strong solution, refer to  for its detailed definition.

In general, obtaining an explicit expression for the solution to the SDE (2) is not feasible. In fact, an explicit solution can be obtained when the matrices \(A,G_{1},,G_{k}\) commute, that is when

\[AG_{k}=G_{k}A\ \ \ G_{k}G_{l}=G_{l}G_{k}\] (4)

holds for all \(k,l=1,,m\) (cf. ). However, the conditions described in (4) are too restrictive and impractical. Therefore, this study will focus on the general case of the SDE (2).

We know that both the SDE (1) and the SDE (2) admit unique solutions that manifest as continuous stochastic processes . A \(d\)-dimensional stochastic process is a collection of \(^{d}\)-valued random variables, denoted as \(X=\{X_{t};0 t<\}\) defined on some probability space. When comparing two stochastic processes, \(X\) and \(\), that are defined on the same probability space \((,,)\), various notions of equality may be considered. In this study, we adopt the notion of equality with respect to their distributions, which is a weaker requirement than strict equivalence, see  for relevant notions. We now present the definition of the distribution of a stochastic process.

**Definition 2.1**.: _Let \(X\) be a random variable on a probability space \((,,)\) with values in a measurable space \((S,(S))\), i.e., the function \(X: S\) is \(/(S)\)-measurable. Then, the distribution of the random variable \(X\) is the probability measure \(P^{X}\) on \((S,(S))\) given by_

\[P^{X}(B)=(X B)=\{:X() B\}\,,\ \ B(S)\,.\]

_When \(X:=\{X_{t};0 t<\}\) is a continuous stochastic process on \((,,)\), and \(S=C[0,)\), such an \(X\) can be regarded as a random variable on \((,,)\) with values in \((C[0,),(C[0,)))\), and \(P^{X}\) is called the distribution of \(X\). Here \(C[0,)\) stands for the space of all continuous, real-valued functions on \([0,]\)._

It is noteworthy that the distribution of a continuous process can be uniquely determined by its finite-dimensional distributions. Hence, if two stochastic processes, labelled as \(X\) and \(\), share identical finite-dimensional distributions, they are regarded as equivalent in distribution, denoted by \(X}}{{=}}\). Relevant concepts and theories regarding this property can be found in .

The generator of a stochastic process is typically represented by a differential operator that acts on functions. It provides information about how a function evolves over time in the context of the underlying stochastic process. Mathematically, the generator of a stochastic process \(X_{t}\) can be defined as

\[(f)(x)=_{s 0}[f(X_{t+s})-f(X_{t})|X_{t}=x]}{s},\]

where \(f\) is a suitably regular function.

In the following, we present the generator of the SDEs under consideration. Obviously, both the SDE (1) and the SDE (2) conform to the general form:

\[dX_{t}=b(X_{t})dt+(X_{t})dW_{t}\,,\ \ X_{0}=x_{0}\,.\] (5)

where \(b\) and \(\) are locally Lipschitz continuous in the space variable \(x\). The generator \(\) of the SDE (5) can be explicitly computed by utilizing Ito's formula (cf. ).

**Proposition 2.1**.: _Let \(X\) be a stochastic process defined by the SDE (5). The generator \(\) of \(X\) on \(C_{b}^{2}(^{d})\) is given by_

\[(f)(x):=_{i=1}^{d}b_{i}(x)}+ _{i,j=1}^{d}c_{ij}(x)f(x)}{ x_{i}  x_{j}}\] (6)

_for \(f C_{b}^{2}(^{d})\) and \(x^{d}\), where \(c(x)=(x)(x)^{}\) is a \(d d\) matrix, and \(C_{b}^{2}(^{d})\) denotes the space of continuous functions on \(^{d}\) that have bounded derivatives up to order two._

### Causal interpretation of SDEs

An important motivation for the identification of the generator of an SDE lies in the desire to infer reliable causality within dynamic models described by SDEs. In this subsection, we aim to provide some necessary background knowledge on the causal interpretation of SDEs. Consider the general SDE framework described as:

\[dX_{t}=a(X_{t})dZ_{t}\,, X_{0}=x_{0}\,,\] (7)

where \(Z\) is a \(p\)-dimensional semimartingale and \(a:^{d}^{d p}\) is a continuous mapping. By writing the SDE (7) in integral form

\[X_{t}^{i}=x_{0}^{i}+_{j=1}^{p}_{0}^{t}a_{ij}(X_{s})dZ_{s}^{j}\,, i  d\,.\] (8)

The authors of  proposed a mathematical definition of the SDE resulting from an intervention to the SDE (8). In the following, \(X^{(-l)}\) denotes the \((d-1)\)-dimensional vector that results from the removal of the \(l\)-th coordinate of \(X^{d}\).

**Definition 2.2**.: _[_17_, Definition 2.4.]_ _Consider some \(l d\) and \(:^{d-1}\). The SDE arising from (8) under the intervention \(X_{t}^{l}:=(X_{t}^{(-l)})\) is the \((d-1)\)-dimensional equation_

\[(Y^{(-l)})_{t}^{i}=x_{0}^{i}+_{j=1}^{p}_{0}^{t}b_{ij}(Y_{s}^{(-l)})dZ_ {s}^{j}\,, i l\,,\] (9)

_where \(b:^{d-1}^{(d-1) p}\) is defined by \(b_{ij}(y)=a_{ij}(y_{1},,(y),,y_{d})\) for \(i l\) and \(j p\) and the \((y)\) is on the \(l\)-th coordinate._

Definition 2.2 presents a natural approach to defining how interventions should affect dynamic systems governed by SDEs. We adopt the same notations as used in . Assuming (8) and (9) have unique solutions for all interventions, we refer to (8) as the observational SDE, to its solution as the observational process, to the distribution of its solution as observational distribution, to (9) as the post-intervention SDE, to the solution of (9) as the post-intervention process, and to the distribution of the solution of (9) as the post-intervention distribution. The authors in  related Definition 2.2 to mainstream causal concepts by establishing a mathematical connection between SDEs and structural equation models (SEMs). Specifically, the authors showed that under regularity assumptions, the solution to the post-intervention SDE is equal to the limit of a sequence of interventions in SEMs based on the Euler scheme of the observational SDE. Despite the fact that the parameters of the SDEs are generally not identifiable from the observational distribution, the post-intervention distributions can be identified, thus enabling causal inference of the system. To this end, Sokol and Hansen  derived a condition under which the generator associated with the observational SDE allows for the identification of the post-intervention distributions. We present the corresponding theory as follows.

**Lemma 2.1**.: _[_17_, Theorem 5.3.]_ _Consider the SDEs_

\[dX_{t}=a(X_{t})dZ_{t}\,, X_{0}=x_{0}\,,\] (10)

\[d_{t}=(_{t})d_{t}\,,_{0}= _{0}\,,\] (11)

_where \(Z\) is a \(p\)-dimensional Levy process and \(\) is a \(\)-dimensional Levy process. Assume that (10) and (11) have the same generator, that \(a:^{d}^{d p}\) and \(:^{d-1}\) are Lipschitz and that the initial values have the same distribution. Then the post-intervention distributions of doing \(X^{l}:=(X^{(-l)})\) in (10) and doing \(^{l}:=(^{(-l)})\) in (11) are equal for any choice of \(\) and \(l\)._

A main task in the causality research community is to uncover the conditions under which the post-intervention distributions are identifiable from the observational distribution. In the context of dynamic systems modelled in SDEs, similar conditions need to be derived. Lemma 2.1 establishes that, for SDEs with a Levy process as the driving noise, the post-intervention distributions can be identifiable from the generator. Nevertheless, a gap remains between the observational distribution and the SDE generator's identifiability. This work aims to address this gap by providing conditions under which the generator is identifiable from the observational distribution.

## 3 Main results

In this section, we present some prerequisites first, and then we present the main theoretical results of our study, which include the condition for the identifiability of generator that is associated with the SDE (1) / SDE (2) from the distribution of the corresponding solution process.

### Prerequisites

We first show that both the SDE (1) and the SDE (2) satisfy the conditions stated in Lemma 2.1.

**Lemma 3.1**.: _Both the SDE (1) and the SDE (2) can be expressed as the form of (10), with \(Z\) being a \(p\)-dimensional Levy process, and \(a:^{d}^{d p}\) being Lipschitz._

The proof of Lemma 3.1 can be found in Appendix A.1. This lemma suggests that Lemma 2.1 applies to both the SDE (1) and the SDE (2), given that they meet the specified conditions. Therefore, for either SDE, deriving the conditions that allow for the generator to be identifiable from the observational distribution is sufficient. By applying Lemma 2.1, when the intervention function \(\) is Lipschitz, the post-intervention distributions can be identified from the observational distribution under these conditions.

We then address the identifiability condition of the generator \(\) defined by (6).

**Proposition 3.1**.: _Let \(\) and \(}\) be generators of stochastic processes defined by the form of the SDE (5) on \(C^{2}_{b}(^{d})\), where \(\) is given by (6) and \(}\) is given by the same expression, with \((x)\) and \((x)\) substituted for \(b(x)\) and \(c(x)\). It then holds that the two generators \(=}\) if and only if \(b(x)=(x)\) and \(c(x)=(x)\) for all \(x^{d}\)._

The proof of Proposition 3.1 can be found in Appendix A.2. This proposition states that for stochastic processes defined by the SDE (5), the generator is identifiable from functions associated with its coefficients: \(b(x)\) and \(c(x)=(x)(x)^{}\).

### Conditions for identifying generators of linear SDEs with additive noise

Expressing the SDE (1) in the form given by (5) yields \(b(x)=Ax\) and \(c(x)=GG^{}\). Therefore, based on Proposition 3.1, we define the identifiability of the generator of the SDE (1) as follows.

**Definition 3.1** (\((x_{0},A,G)\)-identifiability).: _For \(x_{0}^{d},A^{d d}\) and \(G^{d m}\), the generator of the SDE (1) is said to be identifiable from \(x_{0}\), if for all \(^{d d}\) and all \(^{d m}\), with \((A,GG^{})(,^{})\), it holds that \(X(;x_{0},A,G)@note{footnote}{$X(;x_{0},A,G)=\{X(t;x_{0},A,G):0  t<\}$}\)._

In the following, we begin by introducing two lemmas that serve as the foundation for deriving our main identifiability theorem.

**Lemma 3.2**.: _For \(x_{0}^{d},A,^{d d}\) and \(G,^{d m}\), let \(X_{t}:=X(t;x_{0},A,G)\), \(_{t}:=X(t;x_{0},,)\), then \(X(;x_{0},A,G)}}{{=}}X(;x_{0}, ,)\) if and only if the mean \([X_{t}]=[_{t}]\) and the covariance \(\{(X_{t+h}-[X_{t+h}])(X_{t}-[X_{t}])^{}\}= \{(_{t+h}-[_{t+h}])(_{t}- [_{t}])^{}\}\) for all \(0 t<\) and \(0 h<\)._

The proof of Lemma 3.2 can be found in Appendix A.3. This lemma states that for stochastic processes modelled by the SDE (1), the equality of the distribution of two processes can be deconstructed as the equality of the mean and covariance of the state variables at all time points. Calculation shows

\[[X_{t}] =e^{At}x_{0}\,,\] (12) \[V(t,t+h) :=\{(X_{t+h}-[X_{t+h}])(X_{t}-[X_{t }])^{}\}\] \[=e^{Ah}V(t)\,,\]

where \(V(t):=V(t,t)\). Please refer to the proof A.5 of Theorem 3.4 for the detailed calculations. It can be easily checked that \([X_{t}]\) follows the linear ordinary differential equation (ODE)

\[(t)=Am(t),\ \ \ m(0)=x_{0}\,,\] (13)

where \((t)\) denotes the first derivative of function \(m(t)\) with respect to time \(t\). Similarly, each column of the covariance \(V(t,t+h)\) also follows the linear ODE (13) but with a different initial state: the corresponding column of \(V(t)\). This observation allows us to leverage not only the characteristics of the SDE (1), but also the established theories  on identifiability analysis for the ODE (13), to derive the identifiability conditions for the generator of the SDE (1).

We adopt the same setting as in , discussing the case where \(A\) has distinct eigenvalues. Because random matrix theory suggests that almost every \(A^{d d}\) has \(d\) distinct eigenvalues with respect to the Lebesgue measure on \(^{d d}\). And the Jordan decomposition of such a matrix \(A\) follows a straightforward form which is helpful for deriving the geometric interpretation of the proposed identifiability condition. The Jordan decomposition can be expressed as \(A=Q Q^{-1}\), where

\[=J_{1}&&\\ &&\\ &&J_{K},\;J_{k}=\{_{k},&\;k=1,,K_{1}\,,\\ a_{k}&-b_{k}\\ b_{k}&a_{k},&\;k=K_{1}+1,,K\,..\]

\[Q=[Q_{1}||Q_{K}]=[v_{1}||v_{d}]\,,\]

\[Q_{k}=\{v_{k},&\\ [v_{2k-K_{1}-1}]v_{2k-K_{1}}],&\;k=K_{1}+1,,K \,,.\]

where \(_{k}\) is a real eigenvalue of \(A\) and \(v_{k}\) is the corresponding eigenvector of \(_{k}\), for \(k=1,,K_{1}\). For \(k=K_{1}+1,,K\), \([v_{2k-K_{1}-1}|v_{2k-K_{1}}]\) are the corresponding "eigenvectors" of complex eigenvalues \(a_{k} b_{k}i\). Inspired by [43, Definition 2.3., Lemma 2.3.], we establish the following Lemma.

**Lemma 3.3**.: _Assuming \(A^{d d}\) has \(d\) distinct eigenvalues, with Jordan decomposition \(A=Q Q^{-1}\). Let \(_{j}^{d}\) and \(_{j}:=Q^{-1}_{j}^{d}\) for all \(j=1,,n\) with \(n 2\). We define_

\[w_{j,k}:=\{_{j,k}^{1},& \;k=1,,K_{1}\,,\\ (_{j,2k-K_{1}-1},_{j,2k-K_{1}})^{}^{2},&\;k=K_{1}+1,,K\,,.\]

_where \(_{j,k}\) denotes the \(k\)-th entry of \(_{j}\). \(([_{1}|A_{1}||A^{d-1}_{1}||_{n }|A_{n}||A^{d-1}_{n}])<d\) if and only if there exists \(k\{1,,K\}\), such that \(|w_{j,k}|=0\) for all \(j=1,,n\), where \(|w_{j,k}|\) is the absolute value of \(w_{j,k}\) for \(k=1,,K_{1}\), and the Euclidean norm of \(w_{j,k}\) for \(k=K_{1}+1,,K\)._

The proof of Lemma 3.3 can be found in Appendix A.4. From a geometric perspective, \(_{j}\) can be decomposed into a linear combination of \(Q_{k}\)'s

\[_{j}=Q_{j}=_{k=1}^{K}Q_{k}w_{j,k}\,.\]

Let \(L_{k}:=(Q_{k})\). According to [43, Theorem 2.2], each \(L_{k}\) is an \(A\)-invariant subspace of \(^{d}\). Recall that a space \(L\) is called \(A\)-invariant, if for all \( L\), \(A L\). We say \(L\) is a proper subspace of \(^{d}\) if \(L^{d}\) and \(L^{d}\). If \(|w_{j,k}|=0\) (i.e., \(w_{j,k}=0\) in \(^{1}\) or \(^{2}\)), then \(_{j}\) does not contain any information from \(L_{k}\). In this case, \(_{j}\) is contained in an \(A\)-invariant proper subspace of \(^{d}\) that excludes \(L_{k}\), denoted as \(L_{-k}\). It is worth emphasizing that \(L_{-k}^{d}\) is indeed a **proper** subspace of \(^{d}\). This further implies that the trajectory of the ODE (13) generated from initial state \(_{j}\) is confined to \(L_{-k}\)[57, Lemma 3.2]. Lemma 3.3 indicates that if \(([_{1}|A_{1}||A^{d-1}_{1}||_{n }|A_{n}||A^{d-1}_{n}])<d\) then all \(_{j}\) for \(j=1,,n\) are confined to an \(A\)-invariant proper subspace of \(^{d}\), denoted as \(L\). Therefore, all trajectories of the ODE (13) generated from initial states \(_{j}\) are also confined to \(L\). Furthermore, based on the identifiability conditions proposed in , the ODE (13) is not identifiable from observational data collected in these trajectories. This lemma provides an approach to interpreting our identifiability conditions from a geometric perspective.

Now we are ready to present our main theorem.

**Theorem 3.4**.: _Let \(x_{0}^{d}\) be fixed. Assuming that the matrix \(A\) in the SDE (1) has \(d\) distinct eigenvalues. The generator of the SDE (1) is identifiable from \(x_{0}\) if and only if_

\[([x_{0}|Ax_{0}||A^{d-1}x_{0}|H_{ 1}|AH_{ 1}||A^{d-1 }H_{ 1}||H_{ d}|AH_{ d}||A^{d-1}H_{ d}])=d\,,\] (14)

_where \(H:=GG^{T}\), and \(H_{ j}\) stands for the \(j\)-th column vector of matrix \(H\), for all \(j=1,,d\)._

The proof of Theorem 3.4 can be found in Appendix A.5. The condition in Theorem 3.4 is both sufficient and necessary when the matrix \(A\) has distinct eigenvalues. It is worth noting that almost every \(A^{d d}\) has \(d\) distinct eigenvalues concerning the Lebesgue measure on \(^{d d}\). Hence, this condition is both sufficient and necessary for almost every \(A\) in \(^{d d}\). However, in cases where \(A\) has repetitive eigenvalues, this condition is solely sufficient and not necessary.

**Remark.** The identifiability condition stated in Theorem 3.4 is generic, that is, let

\[S:=\{(x_{0},A,G)^{d+d^{2}+dm}:) is violated}\}\,,\]

\(S\) has Lebesgue measure zero in \(^{d+d^{2}+dm}\). Refer to Appendix B.2 for the detailed proof.

From the geometric perspective, suppose matrix \(A\) has distinct eigenvalues, the generator of the SDE (1) is identifiable from \(x_{0}\) when not all of the vectors: \(x_{0},H_{.1},,H_{.d}\) are confined to an \(A\)-invariant **proper** subspace of \(^{d}\). A key finding is that when all the vectors \(H_{.j}\), \(j=1,,d\) are confined to an \(A\)-invariant proper subspace \(L\) of \(^{d}\), each column of the covariance matrix \(V(t)\) in Equation (12) is also confined to \(L\), for all \(0 t<\). Thus, the identifiability of the generator of the SDE (1) can be fully determined by \(x_{0}\) and the system parameters \((A,GG^{})\). Further details can be found in the proof A.5 of Theorem 3.4.

By rearranging the matrix in (14), the identifiability condition can also be expressed as

\[([x_{0}|Ax_{0}||A^{d-1}x_{0}|GG^{}|AGG^{}||A^{ d-1}GG^{}])=d\,.\] (15)

Based on the identifiability condition (15), we derive the following corollary.

**Corollary 3.4.1**.: _Let \(x_{0}^{d}\) be fixed. If \(([G|AG||A^{d-1}G])=d\), then the generator of the SDE (1) is identifiable from \(x_{0}\)._

The proof of Corollary 3.4.1 can be found in Appendix A.6. This corollary indicates that the generator of the SDE (1) is identifiable from **any** initial state \(x_{0}^{d}\) when the pair \([A,G]\) is controllable (\(([G|AG||A^{d-1}G])=d\)). Notably, this identifiability condition is stricter than that proposed in Theorem 3.4, as it does not use the information of \(x_{0}\).

### Conditions for identifying generators of linear SDEs with multiplicative noise

Expressing the SDE (2) in the form given by (5) yields \(b(x)=Ax\) and \((x)=[G_{1}x||G_{m}x]^{d m}\), thus, \(c(x)=(x)(x)^{}=_{k=1}^{m}G_{k}xx^{}G_{k}^{}\). Let \(X(t;x_{0},A,\{G_{k}\}_{k=1}^{m})\) denote the solution to the SDE (2), then based on Proposition 3.1, we define the identifiability of the generator of the SDE (2) as follows.

**Definition 3.2** (\((x_{0},A,\{G_{k}\}_{k=1}^{m})\)-identifiability).: _For \(x_{0}^{d},A,G_{k}^{d d}\) for all \(k=1,,m\), the generator of the SDE (2) is said to be identifiable from \(x_{0}\), if for all \(,_{k}^{d d}\), there exists an \(x^{d}\), such that \((A,_{k=1}^{m}G_{k}xx^{}G_{k}^{})(,_{k=1}^{m} _{k}xx^{}_{k}^{})\), it holds that \(X(;x_{0},A,\{G_{k}\}_{k=1}^{m})}{=}X(;x_{0}, ,\{_{k}\}_{k=1}^{m})\)._

Based on Definition 3.2, we present the identifiability condition for the generator of the SDE (2).

**Theorem 3.5**.: _Let \(x_{0}^{d}\) be fixed. The generator of the SDE (2) is identifiable from \(x_{0}\) if the following conditions are satisfied:_

* \(([x_{0}|Ax_{0}||A^{d-1}x_{0}])=d\)_,_
* \(([v|v||^{(d^{2}+d-2)/2}v])=(d^{2}+d)/2\)_,_

_where \(=A A+_{k=1}^{m}G_{k} G_{k}^{d^{2}  d^{2}}\), \(\) denotes Kronecker sum and \(\) denotes Kronecker product, \(v\) is a \(d^{2}\)-dimensional vector defined by \(v:=(x_{0}x_{0}^{})\), where \((M)\) denotes the vectorization of matrix \(M\)._

The proof of Theorem 3.5 can be found in Appendix A.7. This condition is only sufficient but not necessary. Specifically, condition A1 guarantees that matrix \(A\) is identifiable, and once \(A\) is identifiable, condition A2 ensures that the identifiability of \(_{k=1}^{m}G_{k}xx^{}G_{k}^{}\) holds for all \(x^{d}\).

**Remark.** The identifiability condition stated in Theorem 3.5 is generic, that is, let

\[S:=\{(x_{0},A,\{G_{k}\}_{k=1}^{m})^{d+(m+1)d^{2}}:\}\,,\]

\(S\) has Lebesgue measure zero in \(^{d+(m+1)d^{2}}\). This signifies that the conditions are satisfied for most of the combinations of \(x_{0}\), \(A\) and \(G_{k}\)'s, except for those that lie in a set of Lebesgue measure zero. The corresponding proposition and detailed proof can be found in Appendix B.1.

Since obtaining an explicit solution for the SDE (2) is generally infeasible, we resort to utilizing the first- and second-order moments of this SDE to derive the identifiability conditions. Let \(m(t):=[X_{t}]\) and \(P(t):=[X_{t}X_{t}^{}]\), it is known that these moments satisfy ODE systems. Specifically, \(m(t)\) satisfies the ODE (13), while \(P(t)\) satisfies the following ODE (cf. ):

\[(t)=AP(t)+P(t)A^{}+_{k=1}^{m}G_{k}P(t)G_{k}^{}\,,\;\;\;P(0)= x_{0}x_{0}^{}\,.\] (16)

An important trick to deal with the ODE (16) is to vectorize \(P(t)\), then it can be expressed as:

\[((t))=(P(t))\,,\;\;\;(P(0))=v\,,\] (17)

where \(\) and \(v\) are defined in Theorem 3.5. In fact, the ODE (17) follows the same mathematical structure as that of the ODE (13), which is known as homogeneous linear ODEs. Thus, in addition to the inherent properties of the SDE (2), we also employ some existing identifiability theories for homogeneous linear ODEs to establish the identifiability condition for the generator of the SDE (2).

From the geometric perspective, condition A1 indicates that the initial state \(x_{0}\) is not confined to an \(A\)-invariant **proper** subspace of \(^{d}\)[57, Lemma 3.1.]. And condition A2 implies that the vectorization of \(x_{0}x_{0}^{}\) is not confined to an \(\)-invariant **proper** subspace of \(W\), with \(W^{d^{2}}\), and \((W)=(d^{2}+d)/2\), where \((W)\) denotes the dimension of the subspace \(W\), that is the number of vectors in any basis for \(W\). In particular, one can construct a basis for \(W\) as follows:

\[\{(E_{11}),(E_{21}),(E_{22}),,(E_{dd})\},\]

where \(E_{ij}\) denotes a \(d d\) matrix whose \(ij\)-th and \(ji\)-th elements are \(1\), and all other elements are \(0\), for all \(i,j=1,,d\) and \(i j\). Refer to the proof A.7 of Theorem 3.5 for more details.

## 4 Simulations and examples

In order to assess the validity of the identifiability conditions established in Section 3, we present the results of simulations. Specifically, we consider SDEs with system parameters that either satisfy or violate the proposed identifiability conditions. We then apply the maximum likelihood estimation (MLE) method to estimate the system parameters from discrete observations sampled from the corresponding SDE. The accuracy of the resulting parameter estimates serves as an indicator of the validity of the proposed identifiability conditions.

**Simulations.** We conduct five sets of simulations, which include one identifiable case and one unidentifiable case for the SDE (1), and one identifiable case and two unidentifiable cases with either condition A1 or A2 in Theorem 3.5 unsatisfied for the SDE (2). We set both the system dimension, \(d\), and the Brownian motion dimension, \(m\), to 2. Details on the true underlying system parameters for the SDEs can be found in Appendix C. We simulate observations from the true SDEs for each of the five cases under investigation. Specifically, the simulations are carried out for different numbers of trajectories (\(N\)), with 50 equally-spaced observations sampled on each trajectory from the time interval \(\). We employ the Euler-Maruyama (EM) method , a widely used numerical scheme for simulating SDEs, to generate the observations.

**Estimation.** We use MLE [38; 50] to estimate the system parameters. The MLE method requires knowledge of the transition probability density function (pdf) that governs the evolution of the system. For the specific case of the SDE (1), the transition density follows a Gaussian distribution, which can be computed analytically based on the system's drift and diffusion coefficients (cf. ). To compute the covariance, we employ the commonly used matrix fraction decomposition method [4; 49; 50]. However, in general, the transition pdf of the SDE (2) cannot be obtained analytically due to the lack of a closed-form solution. To address this issue, we implement the Euler-Maruyama approach [32; 34], which has been shown to be effective in approximating the transition pdf of SDEs.

**Metric.** We adopt the commonly used metric, mean squared error (MSE), to assess the accuracy of the parameter estimates. To ensure reliable estimation outcomes, we perform 100 independent random replications for each configuration and report the mean and variance of their MSEs.

**Results analysis.** Table 1 and Table 2 present the simulation results for the SDE (1) and the SDE (2), respectively. In Table 1, the simulation results demonstrate that in the identifiable case, as the number of trajectories \(N\) increases, the MSE for both \(A\) and \(GG^{}\) decreases and approaches zero. However, in the unidentifiable case, where the identifiable condition (14) stated in Theorem 3.4 is not satisfied, the MSE for both \(A\) and \(GG^{}\) remains high regardless of the number of trajectories. These findings provide strong empirical evidence supporting the validity of the identifiability condition proposed in Theorem 3.4. The simulation results presented in Table 2 show that in the identifiable case, the MSE for both \(A\) and \(Gsx\) decreases and approaches zero with the increase of the number of trajectories \(N\). Here, \(Gsx:=_{k=1}^{m}G_{k}xx^{}G_{k}^{}\), where \(x\) is a randomly generated vector from \(^{2}\) (in these simulations, \(x=[1.33,0.72]^{}\)). Interestingly, even in unidentifiable case 1, the MSE for both \(A\) and \(Gsx\) decreases with an increasing number of trajectories \(N\), indicating that the generator of the SDE utilized in this particular case is still identifiable, although a larger number of trajectories is required compared to the identifiable case to achieve the same level of accuracy. This result is reasonable, because it aligns with our understanding that condition A1 is only sufficient but not necessary for identifying \(A\), as the lack of an explicit solution for the SDE (2) results in condition A1 not incorporating any information from \(G_{k}\)'s. The identifiability condition derived for the SDE (1) in Theorem 3.4 leverages the information of \(G\), similarly, if information regarding \(G_{k}\)'s is available, a weaker condition for identifying \(A\) could be obtained. For illustration, in Appendix E, we present such a condition assuming the SDE (2) has a closed-form solution. In the case of unidentifiable case 2, the MSE for \(A\) decreases with an increasing number of trajectories \(N\); however, the MSE for \(Gsx\) remains high, indicating that \(A\) is identifiable, while \(Gsx\) is not, albeit requiring more trajectories compared to the identifiable case to achieve the same level of accuracy of \(A\) (since the \(Gsx\) is far away from its true underlying value). This finding is consistent with the derived identifiability condition, as condition A1 is sufficient to identify \(A\), whereas condition A2 governs the identifiability of \(Gsx\). Worth noting that in cases where neither condition A1 nor condition A2 is satisfied, the estimated parameters barely deviate from their initial values, implying poor estimation of both \(A\) and \(Gsx\). These results indicate the validity of the identifiability condition stated in Theorem 3.5.

**Illustrative instances of causal inference for linear SDEs (with interventions).** To illustrate how our proposed identifiability conditions can guarantee reliable causal inference for linear SDEs, we present examples corresponding to both the SDE (1) and the SDE (2). In these examples, we show that under our proposed identifiability conditions, the post-intervention distributions are identifiable from their corresponding observational distributions. Please refer to Appendix D.1 and D.2 for the details of the examples.

## 5 Related work

Most current studies on the identifiability analysis of SDEs are based on the Gaussian diffusion processes that conform to the form described in the SDE (1). In particular, the authors of [27; 28; 42]

   \)} &  &  \\   & MSE-\(A\) & MSE-\(Gsx\) & MSE-\(AG\) & MSE-\(A\) & MSE-\(GG^{}\) \\ 
5 & \(0.0117 0.0115\) & \(5.28\)E-\(05 4.39\)E-\(05\) & \(3.66 0.10\) & \(0.05 0.03\) \\
10 & \(0.0063 0.0061\) & \(2.39\)E-\(05 1.82\)E-\(05\) & \(3.88 0.06\) & \(0.64 0.59\) \\
20 & \(0.0029 0.0027\) & \(1.87\)E-\(05 1.51\)E-\(05\) & \(3.70 0.06\) & \(0.09 0.07\) \\
50 & \(0.0013 0.0010\) & \(8.00\)E-\(06 5.68\)E-\(06\) & \(3.76 0.07\) & \(0.11 0.08\) \\
100 & \(0.0007 0.0004\) & \(4.34\)E-\(06 2.70\)E-\(06\) & \(3.66 0.02\) & \(2.09 1.98\) \\   

Table 1: Simulation results of the SDE (1)

   \)} &  &  \\   &  &  \\   & MSE-\(A\) & MSE-\(Gsx\) & MSE-\(A\) & MSE-\(Gsx\) & MSE-\(A\) & MSE-\(Gsx\) \\ 
10 & \(0.069 0.061\) & \(0.3647 0.3579\) & \(0.509 0.499\) & \(0.194 0.140\) & \(2.562 2.522\) & \(9763 8077\) \\
20 & \(0.047 0.045\) & \(0.1769 0.1694\) & \(0.195 0.180\) & \(0.088 0.058\) & \(0.967 0.904\) & \(8353 6839\) \\
50 & \(0.018 0.018\) & \(0.1703 0.1621\) & \(0.132 0.131\) & \(0.081 0.045\) & \(0.423 0.410\) & \(4779 4032\) \\
100 & \(0.006 0.006\) & \(0.0015 0.0012\) & \(0.065 0.065\) & \(0.068 0.036\) & \(0.207 0.198\) & \(3569 3150\) \\
500 & \(0.001 0.001\) & \(0.0004 0.0001\) & \(0.008 0.008\) & \(0.059 0.004\) & \(0.046 0.046\) & \(4490 3991\) \\   

Table 2: Simulation results of the SDE (2)have conducted research on the identifiability or asymptotic properties of parameter estimators of Gaussian diffusions in view of continuous observations of one trajectory, and have highlighted the need for the diffusion to be ergodic. A considerable amount of effort has also been directed towards the identifiability analysis of Gaussian diffusions, relying on the exact discrete models of the SDEs [6; 16; 23; 35; 41]. Typically, these studies involve transferring the continuous-time system described in the SDE (1) to a discrete-time model such as a vector autoregressive model, based on equally-spaced observations sampled from one trajectory, and then attempting to determine conditions under which \((A,GG^{})\) is identifiable from the parameters of the corresponding exact discrete models. These conditions often have requirements on eigenvalues of \(A\) among other conditions, such as requiring the eigenvalues to have only negative real parts, or the eigenvalues to be strictly real. Due to the limitation of the available observations (continuous or discrete observations located on one trajectory of the SDE system), the identifiability conditions proposed in these works are restrictive.

Causal modelling theories have been well-developed based on directed acyclic graphs (DAGs), which do not explicitly incorporate a time component . In recent years, similar concepts of causality have been developed for dynamic systems operating in both discrete and continuous time. Discrete-time models, such as autoregressive processes, can be readily accommodated within the DAG-based framework [13; 14]. On the other hand, differential equations offer a natural framework for understanding causality in dynamic systems within the context of continuous-time processes [1; 52]. Consequently, considerable effort has been devoted to establishing a theoretical connection between causality and differential equations. In the deterministic case, Mooij et al.  and Rubenstein et al.  have established a mathematical link between ODEs and structural causal models (SCMs). Wang et al.  have proposed a method to infer the causal structure of linear ODEs. Turning to the stochastic case, Boogers and Mooij have built a bridge from random differential equations (RDEs) to SCMs , while Hansen and Sokol have proposed a causal interpretation of SDEs by establishing a connection between SDEs and SEMs .

## 6 Conclusion and discussion

In this paper, we present an investigation into the identifiability of the generators of linear SDEs under additive and multiplicative noise. Specifically, we derive the conditions that are fully built on system parameters and the initial state \(x_{0}\), which enables the identification of a linear SDE's generator from the distribution of its solution process with a given fixed initial state. We establish that, under the proposed conditions, the post-intervention distribution is identifiable from the corresponding observational distribution for any Lipschitz intervention \(\).

The main limitation of our work is that the practical verification of these identifiability conditions poses a challenge, as the true underlying system parameters are typically unavailable in real-world applications. Nevertheless, our study contributes to the understanding of the intrinsic structure of linear SDEs. By offering valuable insights into the identifiability aspects, our findings empower researchers and practitioners to employ models that satisfy the proposed conditions (e.g., through constrained parameter estimation) to learn real-world data while ensuring identifiability. We believe the paramount significance of this work lies in providing a systematic and rigorous causal interpretation of linear SDEs, which facilitates reliable causal inference for dynamic systems governed by such equations. It is worth noting that in our simulations, we employed the MLE method to estimate the system parameters. This necessitates the calculation of the transition pdf from one state to the successive state at each discrete temporal increment. Consequently, as the state dimension and Brownian motion dimension increase, the computational time is inevitably significantly increased, rendering the process quite time-consuming. To expedite parameter estimation for scenarios involving high dimensions, alternative estimation approaches are required. The development of a more efficient parameter estimation approach remains an important task in the realm of SDEs, representing a promising direction for our future research. We claim that this work does not present any foreseeable negative social impact.