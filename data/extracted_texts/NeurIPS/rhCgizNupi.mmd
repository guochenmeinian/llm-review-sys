# Reranking Laws for Language Generation:

A Communication-Theoretic Perspective

 Antonio Farinhas\({}^{1,2}\)   Haau-Sing Li\({}^{2,3}\)   Andre F. T. Martins\({}^{1,2,4,5}\)

\({}^{1}\)Instituto Superior Tecnico, Universidade de Lisboa \({}^{2}\)Instituto de Telecomunicacoes

\({}^{3}\)Ubiquitous Knowledge Processing Lab, TU Darmstadt \({}^{4}\)ELLIS Unit Lisbon \({}^{5}\)Unbabel

{antonio.farinhas,andre.t.martins}@tecnico.ulisboa.pt, hli@ukp.tu-darmstadt.de

###### Abstract

To ensure large language models (LLMs) are used safely, one must reduce their propensity to hallucinate or to generate unacceptable answers. A simple and often used strategy is to first let the LLM generate multiple hypotheses and then employ a reranker to choose the best one. In this paper, we draw a parallel between this strategy and the use of redundancy to decrease the error rate in noisy communication channels. We conceptualize the generator as a sender transmitting multiple descriptions of a message through parallel noisy channels. The receiver decodes the message by ranking the (potentially corrupted) descriptions and selecting the one found to be most reliable. We provide conditions under which this protocol is asymptotically error-free (_i.e._, yields an acceptable answer almost surely) even in scenarios where the reranker is imperfect (governed by Mallows or Zipf-Mandelbrot models) and the channel distributions are statistically dependent. We use our framework to obtain reranking laws which we validate empirically on two real-world tasks using LLMs: text-to-code generation with DeepSeek-Coder 7B and machine translation of medical data with TowerInstruct 13B.

## 1 Introduction

Large language models (LLMs) have shown remarkable performance across many tasks in natural language processing, computer vision, and speech recognition. Despite their capabilities, instances of hallucinations and other critical errors occasionally arise, casting doubt on the reliability of their predictions, without clear indication of when and how badly they might fail (Ji et al., 2023; Guerreiro et al., 2023). This is particularly concerning as these models are increasingly used in high-stakes applications such as those within the medical or legal domains (Hung et al., 2023) or as agents that can perform multiple tasks, including generating and executing code (Wang et al., 2024).

The most common mitigation strategy is to "steer" the LLM with the aid of a reward model or directly from human preferences, either at training time (Stiennon et al., 2020; Yuan et al., 2024; Rafailov et al., 2024) or during decoding (Liu et al., 2024; Huang et al., 2024). A simple and effective decoding-time strategy is first to generate multiple hypotheses and then use a reranker to select the most appropriate one. Several generation techniques used with modern LLMs, including voting procedures (Borgeaud and Emerson, 2020; Wang et al., 2023; Lievin et al., 2024; Shi et al., 2022), minimum Bayes risk decoders (Eikema and Aziz, 2020; Freitag et al., 2022), quality-aware decoders (Fernandes et al., 2022), or other types of hypothesis ensembling/reranking techniques (Farinhas et al., 2023; Ni et al., 2023; Bertsch et al., 2023; Li et al., 2024), embody this idea. An essential aspect of these procedures is that they all add **redundancy** as an intermediate step (by generating multiple hypotheses) to increase the chances of returning an acceptable answer as the final output.

The idea of adding redundancy to decrease the error rate in noisy channels is a cornerstone of **communication theory**, more specifically in forward error correction methods. In its simplestform--repetition codes--a message block is sent multiple times, and the decoder uses some form of majority voting to recover the original message with high probability (MacKay, 2002; Cover and Thomas, 2006). The same idea underlies more sophisticated error-correcting codes (Hamming, 1950; Reed and Solomon, 1960; Gallager, 1962; Berrou et al., 1993).

In this paper, we draw a parallel between these two worlds by regarding generator-reranker LLMs as communication systems (SS2 and Fig. 1, left). We conceptualize the LLM generator \(G\) as a sender transmitting \(N\) message descriptions in parallel through noisy channels, leading to \(N\) potentially corrupted hypotheses. Then, the receiver, which corresponds to the reranker \(R\), decodes the message by ranking the potentially corrupted descriptions and selecting the one found to be most reliable. The goal is for the combined \((G,R)\) system to have lower error rate than \(G\) alone, and for the error rate to decay quickly with \(N\). Our main contributions are as follows:

* We show that when the channel distributions are independent, this simple protocol is asymptotically error-free (_i.e._, it generates an acceptable answer almost surely when \(N\)), even in scenarios where the reranker is imperfect, _e.g._, governed by a Mallows or a Zipf-Mandelbrot model. In the former case, the error probability decays exponentially fast (SS3).
* We show that the protocol is still asymptotically error-free if we assume that the channel distributions are statistically dependent. When they are coupled by a Beta prior, we show that the error probability decays as a power law when the reranker is perfect (SS4).
* We use our framework to obtain "reranking laws", which we validate empirically on text-to-code generation with DeepSeek-Coder 7B (SS5.1), on machine translation of medical data with TowerInstruct 13B (SS5.2), and on mathematical and commonsense reasoning benchmarks (App. B.3).

Notation.We denote \([N]:=\{1,...,N\}\) and we use the shorthand notation \(X_{1:N}:=(X_{1},...,X_{N})\). We use capital letters \((X,Y,...)\) for random variables and represent probability distributions by \((X),(Y)\), etc. We denote expectations of functions \(f\) under \((X)\) by \(_{X}[f(X)]\).

## 2 A Communication-Theoretic Perspective of Generator-Reranker Systems

The focus of our paper is on **generator-reranker systems**: a **generator**\(G\) (such as an LLM) is prompted with a **query**\(q\) (_e.g._, a question to be answered, a source text to be translated, or a textual prompt for code). As a response to this query, \(G\) generates \(N\) candidate answers \(y_{1},...,y_{N}\) (called **hypotheses**). We are agnostic about the internals of \(G\) and the way the hypotheses are generated: they could come from the same system through sampling or beam search, or they could come from an ensemble of different systems. These hypotheses are then processed by a **reranker**\(R\), which ranks them and returns as the final output the one which is found to be the best answer. We are also agnostic about how \(R\) is built--it could be an external system or it could be part of (or share parameters with) the generator. Commonly used rerankers are quality estimators (Fernandes et al., 2022), energy-based models (Bhattacharyya et al., 2021), reward models (Li et al., 2022), and minimum Bayes risk decoders (Kumar and Byrne, 2002; Eikema and Aziz, 2020; Freitag et al., 2022; Shi et al., 2022).

Figure 1: **Left: A generator-reranker system \((G,R)\) depicted as a communication system (§2). Given a query \(q\) with acceptance set \((q)\), the sender sends \(N\) descriptions through noisy channels. The receiver’s goal is to decode an acceptable answer through reranking. Right: Graphical model of the generator \(G\). We consider two different models: a simplified version with \(N\) independent hypotheses, represented in black (§3), and a scenario with exchangeable hypotheses, represented in red (§4).**

Regardless of specific design decisions, the goal of the generator-reranking system \((G,R)\) is to leverage the reranker \(R\) to produce better answers (according to some quality metric) than the ones which would be obtained through \(G\) alone (_e.g._, a single sample). In this paper, we show that the propensity for this combined system to generate unacceptable outputs, such as those containing critical errors or hallucinations, decays quickly enough with \(N\) under mild assumptions on \(G\) and \(R\).

We draw an analogy with communication theory as follows. Let \(\) be an underlying alphabet and \(^{*}:=_{i=0}^{}^{i}\) its Kleene closure, _i.e._, the set of strings from \(\). Given the query \(q\), we denote by \((q)^{*}\) the set of **acceptable answers**.1 We assume the communication system depicted in Fig. 1 (left), a form of **multiple description source coding**(Ozarrow, 1980; Gamal and Cover, 1982; Laneman et al., 2005). In this framework, the sender transmits \(N\) acceptable answers (called **descriptions**) \(x_{1},...,x_{N}(q)^{N}\) in parallel through noisy channels. These descriptions are corrupted according to a distribution \((y_{1},...,y_{N}|x_{1},...,x_{N})\), so that some hypotheses \(y_{i}\) may become unacceptable (\(y_{i}^{*}(q)\)). This "channel noise" is a way to conceptualize the imperfections of the generator \(G\). On the receiver side, a decoder processes the (potentially) corrupted descriptions and estimates \(=g(y_{1},...,y_{N})\) using some decoding function \(g\). The overarching goal is to achieve a low error probability \(P_{}(N;q):=((q) q)\) for any query \(q\). By bounding the maximal probability of error (over all queries), the average error probability is automatically bounded (Cover and Thomas, 2006, SS8). In this paper, we focus on rerankers as the decoding functions, where \(g(y_{1},...,y_{N})\) returns the top ranked answer, _i.e._, \(g(y_{1},...,y_{N})=y_{i}\) for some \(i[N]\).

We formalize this construction by considering different models for \(G\) and \(R\) in the following sections, studying the conditions under which the resulting protocol is **asymptotically error-free**:

**Definition 1**.: _A protocol is asymptotically error-free if, for any query \(q\), the probability of the decoder outputting an unacceptable answer approaches zero as \(N\) tends to infinity, i.e.,_

\[_{N}(g(Y_{1},...,Y_{N})(q ) q)}_{:=P_{}(N;q)}=0.\] (1)

For simplicity, we assume that \(X_{1},...,X_{N}\) are conditionally independent given the query \(q\), _i.e._, that \((x_{1},...,x_{N}|q)=_{i=1}^{N}(x_{i}|q)\).2 We also assume that \(Y_{1:N}\) are independent from \(q\) given \(X_{1:N}\) such that \(q X_{1:N} Y_{1:N}\) forms a Markov chain. Taken together, these two assumptions mean that \((x_{1:N},y_{1:N}|q)=(x_{1:N}|q)(y_{1:N}|x_{1:N})= (_{i=1}^{N}(x_{i}|q))(y_{1:N}|x_{1:N})\).

## 3 Generator-Reranker Systems with Independent Hypotheses

We first consider the case where the corrupted descriptions \(Y_{1:N}\) are conditionally independent and identically distributed (i.i.d.) given \(X_{1:N}\) and where \(Y_{i}\) depends only on \(X_{i}\), that is, \((y_{1:N}|x_{1:N})=_{i=1}^{N}(y_{i}|x_{i})\). Conceptually, this is the scenario where the parallel channels do not interfere, and it corresponds to the graphical model shown in Fig. 1 (right) without the part in red. While this case may not be very realistic in practice--for example, when the hypotheses produced by the generator are all sampled from the same model--it makes the analysis simpler. We will show later in SS4 how the analysis can be extended when this assumption does not hold, reusing the results from this section.

In the sequel, given a query \(q\), we let \(\) denote the probability of a hypothesis being unacceptable, \(:=(Y_{i}(q) X_{i}=x_{i},q)=(Y _{i}(q) X_{i}=x_{i})\).

### Perfect and random rerankers

We start by assuming that \(R\) is a **perfect reranker**, which implies that it produces an acceptable output when presented with a set of \(N\) hypotheses if and only if at least one of them is acceptable. Inthis case, the error probability becomes

\[P_{}(N;q)=(g(Y_{1},...,Y_{N})(q) q) =_{X_{1:N}|q}(g(Y_{1},...,Y_{N}) (q) X_{1:N},q)\] \[=_{X_{1:N}|q}(Y_{i}(q ),\  i[N] X_{1:N})\] \[=_{X_{1:N}|q}_{i=1}^{N}(q) X_{i})}_{=}=^{N}.\] (2)

Thus, \(P_{}(N;q)\) goes to zero exponentially fast with \(N\) for any \([0,1)\), indicating that when the hypotheses are independent and the reranker is perfect, the protocol is error-free.

On the other end of the spectrum, if the reranker is **random**--_i.e._, if it selects one of the \(N\) hypotheses uniformly at random, we obtain

\[P_{}(N;q)=(g(Y_{1},...,Y_{N}) (q) q) =_{X_{1:N}|q}(g(Y_{1},...,Y_{N}) (q) X_{1:N},q)\] \[=_{X_{1:N}|q}_{i}(Y_ {i}(q) X_{1:N},i)=,\] (3)

that is, we obtain the same error probability as the generator alone, as expected.

### Imperfect reranker: Mallows model

We consider now more realistic rerankers. A statistical ranking model widely used in machine learning applications is the **Mallows model**(Klementiev et al., 2008, 2009; Chierichetti et al., 2018; Tang, 2019). Let \(\) denote the set of permutations over \(N\) elements, and let \(d:_{+}\) be a distance function between permutations. In this paper, we use the Kendall-tau distance \(d(,^{})\), which returns the number of adjacent transpositions needed to turn \(\) into \(^{}\). Given a location parameter \(_{0}\) and a scale parameter \(_{+}\), the probability of a ranking \(\) according to the Mallows model is \((;_{0},)=(- d(,_{0}))/Z()\), where \(Z()\) is the partition function.

In our setting, we assume that \(_{0}\) is the ground truth (oracle) ranking3 of the hypotheses \(y_{1},...,y_{N}\) and \(\) is the ranking obtained by the reranker model, so that \((;_{0},)\) expresses how imperfect the reranker might be. Note that the family of Mallows models include both perfect and random rerankers as limit cases, respectively as \(+\) and as \(=0\).4

Let \(_{j}\) denote the marginal probability that the reranker places at the top the \(j^{}\) highest ranked hypothesis according to the oracle, _i.e._, \(_{j}=(_{0}(^{-1}(1))=j)\). When \(K\) out of the \(N\) hypotheses are unacceptable, the reranker will pick an unacceptable hypothesis with probability \(_{j=N-K+1}^{N}_{j}\). Combining this with the fact that the probability of \(G\) generating \(K\) unacceptable hypotheses is a binomial distribution, the error probability becomes

\[P_{}(N;q)=(g(Y_{1},...,Y_{N}) (q) q) =_{X_{1:N}|q}(g(Y_{1},...,Y_{N}) (q) X_{1:N},q)\] \[=_{K=0}^{N}[^{K}(1-)^{N-K} _{j=N-K+1}^{N}_{j}].\] (4)

Note that (4) holds for **any reranker** with top-1 (marginal) probability mass function \(=[_{1},...,_{N}]\), not only Mallows models. Naively determining \(\) would require marginalizing \((;_{0},)\) by summing over all permutations \(\) satisfying \(_{0}(^{-1}(1))=j\), which is intractable due to the factorial number of terms involved. Fortunately, tractable combinatorial expressions exist for Mallows models (Fligner and Verducci, 1986; Lebanon and Mao, 2008): the partition function has the compact expression \(Z()=_{j=1}^{N}(1-e^{- j})/(1-e^{-})\), and we have (Lebanon and Mao, 2008, Prop. 5):

\[_{j}=Z^{-1}()_{:j=_{0}(^{-1}(1))}e^{- d(,_{ 0})}=}{_{r=1}^{N}e^{-(r-1)}}.\] (5)Plugging (5) into (4), invoking the binomial theorem, and simplifying, we obtain

\[P_{}(N;q)=(g(Y_{1},...,Y_{N})(q) q)= \{&=0\\ (1-e)+e|^{N}-e^{- N}}{1-e^{- N}}&..\] (6)

Notably, when \(+\) (perfect reranking), the failure probability becomes \(^{N}\), as expected (see (2)), demonstrating the model's ability to interpolate between scenarios of random reranking (\(=0\)) with a failure probability of \(\) (see (3)), and optimal reranking (\(+\)) with a failure probability of \(^{N}\). A plot is shown in Fig. 2 (left), for several values of \(e^{-}\).

Our next result, proved in App. A.1, shows that, even with an imperfect reranker, an asymptotically error-free protocol is possible:

**Proposition 1**.: _When \(R\) is a Mallows reranker, for any \(>0\), the protocol is asymptotically error-free and the error probability decays exponentially fast, \(P_{}(N;q)=((e^{-}(1-)+)^{N})\)._

This result shows that \(P_{}(N;q)\) converges Q-linearly to zero with rate of convergence \(e^{-}(1-)+>\). Therefore, **Mallows rerankers behave asymptotically as a perfect reranker but where the generator has an increased error probability.

Given this result, one might wonder whether any reranker "slightly better than random" suffices to obtain an asymptotically error-free protocol. This it **not** the case, as the next counter-example shows.

**Example 1**.: _Assume a reranker with probability mass function \(_{j}(N-j+1)\). The resulting protocol is not asymptotically error-free; we have \(P_{}(N;q)=(^{2})\). Therefore, the error is reduced from \(()\) to \((^{2})\) but it is not eliminated. More generally, if \(_{j}(N-j+1)^{r}\) for a fixed positive integer \(r\), we have \(P_{}(N;q)=(^{r+1})\). See App. A.2 for a proof and plots._

Next, we present a class of rerankers weaker than Mallows which still lead to error-free protocols.

### Imperfect reranker: Zipf-Mandelbrot model

For Mallows models (using the Kendall-tau distance), the marginal probabilities (5) can be written as \(=(-)\), where \(=[0,1,...,N-1]^{}\). We now consider transformations that yield distributions with heavier tails, which we will see later in SS5 to be a better empirical fit in several applications. A known extension to softmax is the \(\)**-entmax**(Peters et al., 2019),5 a family of transformations parametrized by \( 0\),

\[():=[1+(-1)(-)]_{+}^{ 1/(-1)},\] (7)

which recovers softmax as a limit case when \( 1\). In (7), \(\) is a constant which ensures that \(()\) is normalized. When \(>1\), \(\)-entmax can return sparse distributions (Blondel et al., 2020). Conversely, when \(<1\), \(\)-entmax leads to heavy-tailed distributions (see App. A.3).

Figure 2: Log of the failure rate (difference with respect to the baseline rate \(\)) as a function of the number of generated independent hypotheses \(N\) for several values of \(e^{-}\) and \(=0.3\). **Left:** Mallows model (§3.2). **Right:** Zipf-Mandelbrot model (§3.3).

Let us now consider \(=(-)\), where \(=[0,1,...,N-1]^{}\), instead of (5). Letting \(p:=1/(1-)\), \(b=/p\), and \(a=-1\) (where \(a\) is seen here as a normalizing constant that replaces \(\)), and assuming \(a>-1\) and \(<1\), we can write the \(\)-entmax model as \(_{j}=b^{-p}(a+j)^{-p}\). Note that \(<1\) is equivalent to \(p>1\). This is called a **Zipf-Mandelbrot model**(Zipf, 1932; Mandelbrot, 1965). This model generalizes the famous Zipf's law, which applies empirically to many practical contexts, such as the frequency table of words in a corpus of natural language (Powers, 1998). The constant \(a\) is determined to satisfy \(_{j=1}^{N}{(a+j)^{-p}}=b^{p}\). When \(N\), the left hand side becomes the Hurwitz zeta function (Hurwitz, 1882), which equals the Riemann's zeta when \(a=0\),

\[(p,a+1):=_{j=1}^{}}=_{ 0}^{}dt}{e^{(a+1)t}(1-e^{-t})}.\] (8)

The following result, proved in App. A.4, shows that Zipf-Mandelbrot rerankers (which are weaker than Mallows rerankers and become the latter when \( 1\)) still ensure error-free protocols. The proof makes use of the integral representation of the Hurwitz zeta function (8) and of the dominated convergence theorem, reusing the result for Mallows models in Proposition 1.

**Proposition 2**.: _When \(R\) is a Zipf-Mandelbrot reranker, for any \(>0\) and \(<1\), the protocol is asymptotically error-free._

Fig. 2 (right) shows how this model differs from the one presented in SS3.2. Since the reranker is weaker, the error curves bend causing the error decrease to be slower, but still convergent to zero.

## 4 Generator-Reranker Systems with Dependent Hypotheses

We assume now a more realistic scenario where the independence assumption of SS3 might not hold. For example, \((X_{1},Y_{1}),...,(X_{N},Y_{N})\) might be only **exchangeable**--this is the case, for example, when the hypotheses are generated from \(G\) by sampling from a given model, conditioned on the query. In communication theory parlance, this assumes the presence of channel "interference" that introduces dependencies between the errors at the various channels, although permuting the messages at each channel does not change the joint distribution. By de Finetti's theorem (Diaconis and Freedman, 1980), exchangeability implies that there is some mixture variable \(h\) such that \((x_{1:N},y_{1:N})=_{}d(h)_{i=1}^{N} (x_{i}|h)(y_{i}|x_{i},h)\).

We assume further that \(h=(q,)\) can be decoupled into the query variable \(q\), which conditions \(x\), and a random variable \(\), which conditions \(y\), such that \((x_{i}|h):=(x_{i}|q)\) and \((y_{i}|x_{i},h):=(y_{i}|x_{i},)\). This corresponds to the graphical model in Fig. 1 (right), including the part in red. We let \(\) be a continuous random variable in \(\) such that \([]==(Y_{i}(q) X_{i})\). A convenient choice is a Beta distribution with parameters \(\) and \(\), \(p(;,):=^{-1}(1-)^{-1}\).

Perfect reranker and Beta coupling.If \(R\) is a perfect reranker, the error probability is

\[P_{}(N;q) =(g(Y_{1},...,Y_{N})(q) q)=_{X_{1:N} q}(g(Y_{1},...,Y_{N})(q)  X_{1:N}\] \[=_{X_{1:N}}_{0}^{1}d\ p()_{i=1} ^{N}(Y_{i}(q) X_{i},)}_{=} =_{}[^{N}].\] (9)

When \((;,)\), the \(N^{}\)-raw moment (9) has a closed form, leading to \(P_{}(N;q)=_{i=1}^{N}\). The next result, proved in App. A.5 using Gautschi's inequality (Gautschi, 1959) and the Stirling's formula, shows that we still obtain an error-free protocol, albeit the error decays slower than in the independent case--no longer exponentially but rather following a power law.

**Proposition 3**.: _When \((;,)\) and with a perfect reranker, the protocol is error-free and the error probability decays as a power law, \(P_{}(N;q)=(N^{-})\). Furthermore, for \(<1\), we have \(P_{}(N;q)(( ++N)^{-},(+ +N-1)^{-})\)._

Imperfect reranker.When \((;,)\), the probability of exactly \(K\) out of \(N\) messages being corrupted is (due to the conjugacy between the Beta prior and the binomial distribution) \(_{0}^{1}d\ p(;,)^{K}(1-)^{N-K}= ^{K}(+i-1)_{i=1}^{N-K}(+i-1)}{ _{i=1}^{N}(++i-1)}\). Therefore, using the reranker marginals \(\) as in (4), we get

\[P_{}(N;q)=_{K=0}^{N}^{K}(+i -1)_{i=1}^{N-K}(+i-1)}{_{i=1}^{N}(++i-1)}_{j=N-K +1}^{N}_{j},\] (10)

which leads to the plot in Fig. 3 for Mallows and Zipf-Mandelbrot models.6

The next result, proved in App. A.6, shows that the dependencies considered in this subsection do not compromise the error-free protocol when it exists for any density \(p()\) which is finite in \((0,1)\) (not necessarily a Beta distribution). The proof invokes the dominated convergence theorem to enable commuting the limit with the integral sign.

**Proposition 4**.: _Let \(G_{}\) be a generator producing independent hypotheses (SS3) where each hypothesis is acceptable with probability \(1-\). Let the reranker \(R\) be such that \((G_{},R)\) has error probability \(P_{}^{}(N;q,) 0\) for every \((0,1)\) (i.e., it is asymptotically error-free). Assume that the function \( P_{}^{}(N;q,)\) is measurable for every \(N\). Then, when \(R\) is used with a generator \(G\) which produces exchangeable hypotheses with arbitrary distribution \(p()\), finite in \((0,1)\), the system \((G,R)\) is still asymptotically error-free._

This result has important implications: it tells us that, to design error-free protocols, it is sufficient to verify if they are error-free in the simpler case where hypotheses are independent.

## 5 Experiments

In this section, we demonstrate the validity of our reranking laws on two different tasks:7 text-to-code generation (SS5.1) and machine translation of medical data (SS5.2). Following existing literature on scaling laws for language modeling, we fit all curves on the development set using least squares (Ghorbani et al., 2022, App. E) and plot them on the _unseen_ test set.8 In all cases, we consider the generalized model presented in SS4 with parameters \(\), \(\), and a Zipf-Mandelbrot reranker with parameters \(\), and \(e^{-}\), which becomes a Mallows reranker when \( 1\). This is done in two steps: first, we fit \(\) and \(\) using the data for the perfect reranker (\(e^{-}=0\)). Then, we fit \(\) and \(e^{-}\) using the already estimated \(\) and \(\) and the data for the imperfect reranker. Our code is available at https://github.com/deep-spin/reranking-laws.

### Code generation

We use a sanitized version of the MBPP dataset (Austin et al., 2021; Liu et al., 2023), a widely used benchmark for evaluating code LLMs, which includes \(400\) programming problems in Python. For each problem, the dataset includes ground-truth programs and three test cases with input and ground-truth output. We split the dataset in two equally sized parts to get development and test splits.

We generate \(200\) hypotheses with DeepSeek-Coder 7B (Guo et al., 2024) using a sampling temperature of \(1\) (see App. B.1 for the prompt template). As in previous work, for simplicity, we use only one test case for each problem (Shi et al., 2022), and select one candidate by taking a **majority vote** over theexecution results, dismissing hypotheses that fail to execute on the test case (Wang et al., 2023). A hypothesis is considered unacceptable if the result of at least one test case (out of three) is different from the ground truth.

Fig. 4 (top) shows the log failure rate on the dev and test sets (left and right, respectively) as a function of \(N\). Even though the oracle fit is not perfect, we get \(=.1\), \(=.309\), \(=.001\), and \(e^{-}=.003\) for the imperfect reranker with majority voting, which fits the data well, as shown by the red curve.

### Machine translation

We use the TICO-19 dataset (Anastasopoulos et al., 2020), which includes 3071 English sentences in the medical domain (_i.e._, COVID-19 related content) translated into \(38\) languages. We use the official splits, which contain \(971\) examples for development and \(2100\) for testing, focusing on translating from English (EN) to Portuguese (PT), Spanish (ES), and Russian (RU).

For each source sentence, we sample \(50\) translation hypotheses with a temperature of \(1\) from TowerInstruct 13B (Alves et al., 2024) using the prompt template in App. B.2.9 Following Farinhas et al. (2023), we consider two reranking strategies: selecting the best candidate with **MBR decoding** using COMET-22 as the utility metric (Eikema and Aziz, 2020; Rei et al., 2022) and **reranking based on quality estimation** using the reference-free CometKiwi (Fernandes et al., 2022; Rei et al., 2022). Since we cannot afford to collect human evaluation scores for each sampled hypothesis, we consider a translation to have a critical mistake (_i.e._, to be unacceptable) if its COMET-22 score is below 0.85, and an **oracle** (perfect) reranker that picks the translation with the highest COMET-22 score.

We follow the described procedure using the data from all language pairs together. Fig. 4 (bottom) shows the log failure rate on the dev and test sets as a function of \(N\). We get \(=0.1\) and \(=0.46\). Additionally, we have \(=0.182\) and \(e^{-}=0.001\) for MBR decoding and \(=0.001\) and \(e^{-}=0.005\) for QE reranking. See App. B.2 for additional plots showing these curves when the data

Figure 4: Log of the failure rate as a function of \(N\). The empirical data is represented with dots (**left:** dev, **right:** test set) and our fitted models with solid and dashed lines (imperfect and perfect reranker, respectively). **Top:** text-to-code generation (§5.1). **Bottom:** machine translation (§5.2).

from each language pair is used to fit a separate model. Again, we see a reasonable fit, especially for the imperfect rerankers, with MBR decoding leading to lower failure rates than reranking with QE.

## 6 Discussion and Related Work

We believe the communication-theoretic perspective introduced in this paper might inspire the design of new protocols for increasing the quality and safety of LLMs. The generator-reranker system studied in this paper bears resemblance with repetition codes, a very naive (and inefficient) class of error-correcting codes. Can more powerful designs (Hamming, 1950; Reed and Solomon, 1960; Gallager, 1962; Berrou et al., 1993) inspire more efficient protocols? In machine translation, other forms of adding redundancy, such as lattice generation (Singhal et al., 2023) and hypothesis recombination (Vernikos and Popescu-Belis, 2024), suggest that more efficient designs are indeed possible.

Recent work also suggests that **LLM-based evaluators** could be used as highly effective rerankers in specific tasks (Kim et al., 2024). While LLMs are not yet ready to fully replace human evaluators across diverse NLP tasks (Bavaresco et al., 2024), in some cases, they can even provide fine-grained assessments in addition to single scores (Kocmi and Federmann, 2023; Fernandes et al., 2023).

Another class of communication systems allow for **feedback**, _e.g._, in "automatic repeat request" protocols (Lin et al., 1984), where the receiver has a backchannel to request the sender to retransmit missing bits of information. This framework can be useful to analyze LLM protocols where the generator generates a varying number of hypotheses interactively, relying on feedback from another module, such as a reward model or a confidence estimator, as in Quach et al. (2023). Communication with feedback was also used recently by Jung et al. (2024) for summarization when the generator error probability \(\) is large--our mild conditions for asymptotically error-free protocols (Propositions 1\(\)4) suggest that "bootstrapping" a correct answer is possible even in scenarios where \(G\) is very weak. Additionally, recent work has shown that LLMs may struggle with planning or self-verification, advocating instead for tighter integration between LLMs and external model-based verifiers (Kambambampati et al., 2024). This supports our view that using external feedback models can improve LLMs by enabling interactive, error-correcting communication.

We provide **reranking laws**, which allow us to predict how many hypotheses are necessary to achieve a desired error probability. This links to a rich body of literature aiming to predict the performance of deep learning models in terms of fundamental parameters, such as the model size or the amount of compute and data used to train them (Hestness et al., 2017, 2019). These so called "neural scaling laws" have been studied in the context of language modeling (Kaplan et al., 2020; Hoffmann et al., 2022) and machine translation (Ghorbani et al., 2022; Fernandes et al., 2023), where we observe a power-law scaling for the performance as a function of each fundamental parameter. Our paper complements this line of work by considering the decoding dimension for generator-reranker systems.

The analysis and theoretical results of this paper focus on binary acceptable/unacceptable decisions; however it is possible to extend our framework to consider also **continuous quality metrics** (such as Comet scores for translation (Rei et al., 2020)) by replacing the notion of "asymptotically error-free" protocol (Definition 1) by a more general concept associated to a quality target. A possible path is to posit a probability _density_ for the continuous quality metric (instead of a Bernoulli error probability) for each hypothesis coming from the generator, such as a Gaussian or uniform distribution with some input-dependent parameters. For a perfect reranker and independent hypotheses, the resulting output after reranking would be distributed according to the corresponding _extreme value distribution_ (this models the distribution of the _highest_ evaluation metric score among the \(N\) hypotheses). Extreme value distributions are an important subject of study in order statistics (David and Nagaraja, 2004) and their densities have closed form expressions in some restricted cases: for example, the Gaussian assumption above yields a Gumbel distribution, and a uniform assumption yields a Beta distribution. The asymptotic case (\(N\)) corresponds to one of Gumbel, Frechet or Weibull families (this is a consequence of the Fisher-Tippett-Gnedenko theorem (David and Nagaraja, 2004)). From the extreme value distribution, we can obtain the _expected_ evaluation metric score or the probability of a quality score being below an acceptable threshold. However, the generalization to imperfect rerankers (such as the Mallows or Zipf-Mandelbrot rerankers described in SS 3.2 and 3.3) seems harder than in the binary case and requires further investigation.

Conclusions

We presented a communication-theoretic perspective of generator-reranker LLMs, where the generator \(G\) is conceptualized as a sender transmitting \(N\) descriptions in parallel through noisy channels, and the reranker \(R\) decodes the message by selecting the most appropriate description. Under mild conditions, the combined system \((G,R)\) yields an acceptable answer almost surely when \(N\). Experiments on text-to-code generation and machine translation with LLMs validate our framework.

## 8 Limitations and Broader Impacts

We regard our paper as a first step connecting communication theory and LLMs, as discussed in SS6. However, it should be noted that our work has several limitations. First, the guarantees of error-free protocol in Propositions 1\(\) are only asymptotic, and in certain cases a large \(N\) may be necessary to achieve a large enough error decrease. We provide convergence rates only for Mallows rerankers (with independent hypotheses and also in the dependent case, when combined with a Beta prior). Second, there is no simple recipe to determine if the Mallows and Zipf-Mandelbrot reranker models are a good empirical fit to concrete rerankers. The same applies to the prior distribution \(p()\) which makes hypotheses dependent. Third, while our experiments in SS5 suggest a reasonable fit in two tasks (code generation and machine translation), the fit is not perfect. A challenge is that, for large \(N\), errors are rare events, and therefore prone to statistical inaccuracies (this is visible in the "steps" observed in the code generation plots). Finally, although our framework focuses on binary acceptable/unacceptable decisions, it can be extended to continuous evaluation metrics, but this would require modifications to some concepts (_e.g._, the notion of asymptotically error-free protocols). Despite these limitations, the binary case remains highly relevant in practice--for example, in code generation, where the output either executes correctly or it does not. We expect future work to overcome some of these limitations.

In considering the broader impact of our work, it is crucial to acknowledge its early stage and predominantly theoretical nature, which lends the discussion a speculative quality. We believe that our research can significantly enhance the reliability of LLMs by facilitating the identification of potential system failures, holding promise in fields such as natural language processing and computer vision, where robustness and error prediction are paramount. While not directly addressing environmental concerns shared across different LLMs (Strubell et al., 2019), our work could indirectly contribute to energy efficiency efforts by quantifying the efficiency of reranking methods, potentially reducing computational requirements while maintaining requisite quality thresholds during inference.