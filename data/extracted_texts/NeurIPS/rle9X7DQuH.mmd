# OwMatch: Conditional Self-Labeling with Consistency

for Open-World Semi-Supervised Learning

 Shengjie Niu\({}^{1}\), Lifan Lin\({}^{2}\), Jian Huang\({}^{1}\), Chao Wang\({}^{2}\)

\({}^{1}\)Hong Kong Polytechnic University, \({}^{2}\)Southern University of Science and Technology

shengjie.niu@connect.polyu.hk, 12012816@mail.sustech.edu.cn,

j.huang@polyu.edu.hk, wangc6@sustech.edu.cn

The first two authors contributed equally to this work.Corresponding author.

###### Abstract

Semi-supervised learning (SSL) offers a robust framework for harnessing the potential of unannotated data. Traditionally, SSL mandates that all classes possess labeled instances. However, the emergence of open-world SSL (OwSSL) introduces a more practical challenge, wherein unlabeled data may encompass samples from unseen classes. This scenario leads to the misclassification of unseen classes as known ones, consequently undermining classification accuracy. To overcome this challenge, this study revisits two methodologies from self-supervised and semi-supervised learning, self-labeling and consistency, tailoring them to address the OwSSL problem. Specifically, we propose an effective framework called _OwMatch_, combining conditional self-labeling and open-world hierarchical thresholding. Theoretically, we analyze the estimation of class distribution on unlabeled data through rigorous statistical analysis, thus demonstrating that OwMatch can ensure the unbiasedness of the self-label assignment estimator with reliability. Comprehensive empirical analyses demonstrate that our method yields substantial performance enhancements across both known and unknown classes in comparison to previous studies. Code is available at https://github.com/niusj03/OwMatch.

## 1 Introduction

Deep learning has made remarkable success in various tasks by leveraging substantial labeled training data . However, the costly and time-consuming labeling process limits their application in practical scenarios. Semi-supervised learning (SSL) significantly reduces the dependency on labeled data by exploring the inherent structure of unlabeled data . Despite promising results, SSL methods assume a closed-world scenario where, though limited, all classes possess labeled instances. This assumption may be violated due to difficulties in data collection, such as in medical diagnostics, where it is common to encounter new symptoms or fail to annotate due to technical constraints. As a result, only a subset of the categories can be precisely labeled during the annotation process. Recently, numerous studies have sought to identify such novel classes effectively. Open-world SSL (OwSSL) is innovative in promoting dual objectives: classifying instances of seen classes and discovering instances of novel classes .

A notable challenge in OwSSL is the _confirmation bias_ of model: model tends to predict instances as seen classes owing to the lack of ground-truth supervision of novel-class instances. To eliminate this bias, existing works utilize unsupervised clustering methods, including contrastive loss and binary cross-entropy (BCE) loss, to group pairs identified by similarity metrics . Among these unsupervised techniques, self-labeling  has shown remarkable success, which involves assigning self-labels to unlabeled data, with the generation of high-quality self-labels being the keyfactor. Previous studies utilize optimal transport to align the self-labels for unlabeled data with a given distribution. However, this self-label generation fully relies on the accurate prior distribution and lack of consideration of the supervision of labeled data. In TRSSL , the unlabeled data are assigned with a soft self-label based on the inaccurate class distribution, which raises a biased estimation. Moreover, the confirmation bias still exists even if we use the ground-truth distribution to align the unlabeled data in the same process. In addition to confirmation bias, a new issue called _clustering misalignment_ arises when self-labeling depends solely on unlabeled data: without proper guidance, the self-labeling process may adopt varying criteria for clustering. For example, it might cluster data based on superficial features like color rather than high-level semantic information. This misalignment can lead to results that deviate from expected outcomes and even contradict the classification criteria established by labeled data.

Consequently, we propose a new self-labeling scheme, conditional self-labeling, designed to address the challenges of OwSSL, particularly targeting issues related to confirmation bias and misalignment. This scheme limits self-labels for each class and incorporates labeled data to generate debiased and informative self-label assignments for all training data, further mitigating the confirmation bias as shown in Figure 0(a). Additionally, as illustrated in Figure 0(b), seen classes typically exhibit higher predictive confidence, while novel clusters demonstrate variability in their internal learning progresses. The disparities in learning paces between seen and novel classes, coupled with their distinct behaviors, necessitate the selection of appropriate thresholds to facilitate cluster learning. To address these challenges and ensure a balanced learning process across classes, we propose a hierarchical thresholding scheme.

We demonstrate our contributions as follows: **1)** We introduce a novel conditional self-labeling method to incorporate labeled data into the clustering process, reducing confirmation bias and misalignment. **2)** We design a hierarchical thresholding strategy that balances learning difficulties across different classes, helping unstable clusters gradually form. **3)** Our theoretical analysis rigorously discusses the unbiasedness and reliability of conditional self-labeling estimator from population-level statistics. To the best of our knowledge, this is the first work proposing the expectation of chi-square statistics (ECS) to evaluate the reliability of self-label assignment estimation. **4)** We conduct extensive experiments on various datasets, demonstrating the effectiveness of our approach, OwMatch, through detailed comparisons. On CIFAR-10, OwMatch significantly outperforms FixMatch  by up to 47.3% in all-class accuracy, while on CIFAR-100, it enhances TRSSL , the state-of-the-art model in OwSSL, by up to 14.6% in novel-class and 7.2% in all-class accuracy.

## 2 Related work

Traditional semi-supervised learning (SSL).Traditional SSL assumes that labeled and unlabeled data share an identical distribution. Extensive researches on SSL have spanned a considerable duration. The commonly employed strategies in SSL consist of entropy minimization [29; 14], consistency regularization [44; 30] and holistic methods [4; 3; 36]. The latest progresses in SSL include adaptive thresholding strategies [42; 45; 47], which enhance model performance by accounting for varying

Figure 1: Experimental results on the OwSSL problem. (a) Self-label assignment of seen classes (1-5) and novel classes (6-10) with or without conditional component in self-labeling. (b) Predictive confidence and hierarchical threshold for each class.

difficulties and learning conditions across classes, alongside other innovative techniques [19; 41; 2] that employ self-SL approaches to facilitate extracting the semantic information from unlabeled data. However, traditional SSL algorithms typically struggle to tackle the open-world problem in the presence of novel-class instances within unlabeled data.

Open-set semi-supervised learning (OSSL).OSSL expands the traditional SSL boundaries by allowing novel-class instances or outliers within unlabeled data. A variety of OSSL approaches have emerged in recent years [46; 16; 35; 8; 23]. A common solution among these methods is the optimization of the SSL objective exclusively for unlabeled samples deemed inliers. For instance, MTC  optimizes the network and estimates the anomaly score of unlabeled data alternately. OpenMatch  and T2T  train one-vs-all (OVA) classifiers for each known class to detect outliers. Subsequently, standard SSL objective  are applied to the remaining training data, excluding detected outliers. Furthermore, DS3L  leverages a bi-level optimization technique to train a weighting function, which mitigates the passive impact of out-of-distribution (OOD) samples. Nonetheless, these approaches are designed for classifying seen classes, thereby failing to learn from the novel class instances.

Open-world semi-supervised learning (OwSSL).OwSSL  has been proposed to address a practical challenge: enabling the model to effectively cluster novel-class instances while maintaining classification robustness on seen classes. One predominant research direction in this under-explored domain is BCE-based methods, including ORCA  and NACH . Additionally, there exist methods to discover novel classes by employing various other clustering techniques: OpenLDN  employs bi-level optimization to train a pairwise similarity prediction network, which provides a supervisory signal to the similarity of all pairs; TRSSL  converts clustering into the self-labeling problem and applies Sinkhorn-Knopp algorithm to optimize self-label assignments. One subsequently proposed Generalized Category Discovery (GCD) setting is similar to the OwSSL [40; 49], with detailed discussion is provided in Section 5.3.

## 3 Methodology

Problem setup.Given training data consisting of labeled data \(_{l}=\{(^{(i)},_{}^{(i)})\}_{i=1}^{N^{l}}\) and unlabeled data \(_{u}=\{^{(i)}\}_{i=N^{l}+1}^{N^{u}}\), where \(N=N^{l}+N^{u}\) and \(N^{u} N^{l}\). Here \(^{(i)}^{d}\) is the \(i\)-th instance with one-hot vector \(_{}^{(i)}\{0,1\}^{K}\) as the corresponding label, where \(K\) is the number of all classes. We denote the set of classes in \(_{l}\) as \(_{l}\) and the set of classes in \(_{u}\) as \(_{u}\). Previous traditional SSL studies assume \(_{l}=_{u}\). Here for OwSSL, we assume \(_{l}_{u}\) and \(_{u}_{l}\). Denote \(_{s}=_{l}_{u}\) as a set of seen classes, \(_{n}=_{u}_{l}\) as a set of novel classes, and \(=_{l}_{u}\) as a set of all considered classes. The desired OwSSL model is required to assign instances to either a previously seen class \(c_{s}\), or a novel class \(c_{n}\).

For labeled dataset \(_{l}\), standard supervised objective is employed as shown in Equation 9. Additionally, OwMatch primarily incorporates two objectives: a) clustering objective, which leverages conditional self-labeling to refine the self-label assignment with the assistance of supervision; b) confidence objective, which applies consistency loss with open-world hierarchical thresholding strategy to enhance predictive confidence and balance the different learning difficulties across all classes. We will elaborate on them respectively in Section 3.1 and 3.2.

Figure 3: Illustration on the hierarchical thresholding scheme.

Figure 2: Overview of the OwMatch framework.

### Conditional self-labeling

To effectively cluster the novel class instances, the self-labeling scheme  has been considered in OwSSL. Formally, consider a deep neural network (encoder) \(f_{}\) mapping input data \(\) to representation \(^{D}\), the representation is followed by a classification head \(h:^{D}^{K}\), usually consisting of a single linear layer, converting the feature vectors into a vector of class scores. Denote \(g_{}= h f_{}\) as a probability function, where \(\) refers to the SoftMax function. Moreover, denote \(^{(i)}^{K}\) as the soft self-label for \(^{(i)}\), and set \(=[^{(1)},^{(2)},,^{(N)}] ^{K N}\) as the self-label assignment for \(\{^{(i)}\}_{i=1}^{N}\). Asano et al.  utilize a constraint of desired partition of \(\) to construct the transportation polytope:

\[_{1}:=\{_{+}^{K N}|_{N}=N},^{T}_{K}=_{N}\},\] (1)

where \(_{v}\) is the \(v\)-dimensional vector of all ones, \(}\) denotes the desired class distribution. On the other hand, we can obtain a probability output through \(^{(i)}=g_{}((^{(i)}))\), where \(()\) refers to a specific weak augmentation, and denote \(=[^{(1)},^{(2)},,^{(N)}]\) as the matrix of probability outputs. This self-label assignment generation can be understood as solving an optimal transport problem . It minimizes the cross-entropy loss and aligns the training data with the desired class distribution:

\[_{_{1}}((^{T})),\] (2)

where \(()\) is the trace of a given matrix. Obviously, clustering through self-labeling primarily relies on the quality of generated self-label assignments. However, optimizing self-label assignments through unsupervised self-labeling is unreliable owing to the lack of supervision. TRSSL  utilizes the above-unsupervised technique to optimize self-label assignment merely on unlabeled data with the uniform class distribution. Despite prominent results, this unconditional self-labeling process  has a notable flaw: it constructs transportation polytope based on an inaccurate class distribution.

Moreover, we consider conducting self-labeling across all training data and constructing a transportation polytope with a precise class distribution. To mitigate the confirmation bias, we propose a conditional self-labeling method to refine the self-label assignment under partial supervision. Specifically, we exploit the ground-truth labels from the labeled dataset and introduce another constraint \(_{2}\):

\[_{2}:=\{_{+}^{K N}|^{(i)}= _{}^{(i)},i=1,,N^{l}\}.\] (3)

Now, the conditional self-label assignment generation with the above two constraints can be formulated as:

\[_{_{1}_{2}}( (^{T}))+ E(),\] (4)

where \(E()\) is the entropy function, \(\) is a hyper-parameter controlling the smoothness of \(\). We adopt fast version  of _Sinkhorn-Knopp algorithm_ to optimize Equation 4 efficiently and denote the optimal solution as \(}=[}^{(1)},}^{(2)},, }^{(N)}]\). Empirically, conditional self-labeling significantly alleviates the confirmation bias, resulting in self-label assignments that are much closer to the expected distribution, as shown in Figure 0(a). Further theoretical analysis regarding estimators from unconditional and conditional self-labeling is provided in Section 4. Then, the clustering objective has the form of: \(_{cls}=_{i=1}^{N}H(}^{(i)},^{(i)})\).

### Open-world hierarchical thresholding

Beyond the clustering objective, prompting the predictive confidence has proven effective for classification. A similar goal arises in traditional SSL, wherein entropy minimization is employed to encourage low entropy (i.e., high confidence) in the prediction. FixMatch  leverages both consistency and pseudo-labeling to achieve exceptional performance with the following regularization: \(_{i=1}^{N}((^{(i)}))H(}^{( i)},g_{}((^{(i)})))\), where \(}^{(i)}:=(^{(i)})\) is predictive one-hot pseudo-label, with the \(^{(i)}\)-th element set to 1. \(\) and \(\) represent weak and strong augmentation respectively. Here, \(\) is a scalar hyperparameter denoting the threshold above which we retain a pseudo-label. The effectiveness of the aforementioned regularization depends on accurate and sufficient pseudo-labels, which are directly influenced by the thresholding scheme. Under the close-word assumption, extensive efforts [47; 45; 42] have been devoted to devising thresholding techniques based on the idea of balancing learning pace across classes with varying learning difficulties. However, these techniques do not fit with the open-world scenario due to a critical challenge: the learningpace of novel classes tends to be much slower . The predictive confidence of these two groups does not share the same behavior, as shown in Figure 0(b).

We introduce an open-world hierarchical thresholding scheme to balance this inconsistent learning pace at the group level, leveraging these well-defined thresholds to retain high-quality and adequate pseudo-labels for learning. As shown in Figure 3, this scheme first estimates the learning conditions of the two groups and then hierarchically modulates the thresholds in a class-specific fashion within each group.

First, we split the dataset into seen (\(_{s}\)) and novel (\(_{n}\)) groups based on the pseudo-label and estimate their overall learning condition by predictive confidence. Motivated by FreeMatch , we define the group-wise learning status for a set of classes \(_{i}=_{s}\) or \(_{n}\) as

\[(_{i})=_{i}}}_{i=1}^{N}(^{(i)})(^{(i)}_{i}),\;_{i}=_{s} _{n},\] (5)

where \(N_{_{i}}=_{i=1}^{N}(^{(i)}_{i})\) denotes the number of samples whose predictive pseudo-labels belong to the group \(_{i}\). Similarly, the class-wise learning conditions can be defined as

\[_{c}=}_{i=1}^{N}(^{(i)})(^{(i)}=c),\;c=1,,K,\] (6)

where \(N_{c}=_{i=1}^{N}(^{(i)}=c)\) denotes the number of samples whose predicted labels belong to the \(c\)-th class. In practice, we utilize the exponential moving average (EMA) to update at each iteration. Then, we merge these two learning statuses and obtain the open-world hierarchical threshold as

\[(c)=}{_{c_{i}}_{c}}( _{i}),\;c=1,,K,\] (7)

where the \(c\)-th class belongs to the set \(_{i}\) (i.e., \(c_{s}\) or \(_{u}\)). The learning condition \(\) distinguishes between seen and novel classes, while the class-wise condition \(\) adjusts for class-wise differences. Ultimately, the confidence objective is:

\[_{conf}=_{i=1}^{N}((^{(i)})> (^{(i)})) H(}^{(i)},g_{}(( ^{(i)}))).\] (8)

Together with the supervised objective \(_{sup}=}_{i=1}^{N^{l}}H(_{gt}^{(i)}, ^{(i)})\), the overall objective for OwMatch is

\[=_{sup}+_{cls}+_{conf}.\] (9)

## 4 Theoretical analysis of conditional self-labeling

To illustrate the superiority of conditional self-labeling over unconditional, we evaluate their estimators of the class distribution on unlabeled data through rigorous statistical analysis. This transformation is justified as both self-labeling methods produce corresponding self-label assignments, each representing their estimation of the class distribution on unlabeled data.

Formulation.Assuming that the class distribution of real-world data conforms to prior information \(}=[p_{1},p_{2},,p_{K}]\). Suppose real-world data is composed of recognized labeled data and unrecognized unlabeled data, conforming to unknown class distribution \(}^{l}=[p_{1}^{l},p_{2}^{l},,p_{K}^{l}]\) and \(}^{u}=[p_{1}^{u},p_{2}^{u},,p_{K}^{u}]\) respectively. We independently sample \(N=N^{l}+N^{u}\) instances from recognized and unrecognized data, respectively. Suppose \(N_{i}=N_{i}^{l}+N_{i}^{u}\) is composed of two random variables that denote the number of recognized and unrecognized samples belonging to the \(i\)-th class. Obviously, we have \(N^{l}=_{i=1}^{K}N_{i}^{l}\) and \(N^{u}=_{i=1}^{K}N_{i}^{u}\).

Objective.We hope to estimate the unknown class distribution \(}^{u}\) with \(}\) based on prior information \(}\) and observations of \(N_{1}^{l},N_{2}^{l},,N_{K}^{l}\), then evaluate \(}\) from unbiasness and ECS. Evaluation on both metrics requires estimating the number of samples in each class, denoted by \(=(A_{1},A_{2},,A_{K})\). Two self-labeling approaches (unconditional and conditional) can optimize self-label assignment, therefore obtaining two approximations of \(\), denoted by \(_{}\) and \(_{}\). Denote the corresponding estimators as \(}_{}\) and \(}_{}\).

**Assumption 4.1**.: Assume that all drawn samples with a static number of samples and class distribution follow the multinomial distribution as follows,

\[N_{1},N_{2},,N_{K} (N,})\] \[N_{1}^{l},N_{2}^{l},,N_{K}^{l} (N^{l},}^{l})\] \[N_{1}^{u},N_{2}^{u},,N_{K}^{u} (N^{u},}^{u}).\]

Given the independency between \(N_{i}^{l}\) and \(N_{j}^{u}\). We basically have:

\[[N_{i}]=[N_{i}^{l}]+[N_{i}^{u}]  i,j\] (10) \[Np_{i}=N^{l}p_{i}^{l}+N^{u}p_{i}^{u}.\]

**Lemma 4.2**.: _Suppose we want to test the null hypothesis (\(H_{0}\)) that categorical data \(N_{1},N_{2},,N_{}\) come from a multinomial distribution with \(K\) classes and class probability of \(}\). A chi-square statistic can be constructed to test the deviation between the observations \(n_{1},,n_{K}\) and expected outcomes for each class._

\[^{2}=_{i=1}^{K}-_{}}[N_{ i}]^{2})}{_{}}[N_{i}]}^{2}_{K-1},\] (11)

_where \(_{}}[]\) denotes the population expectation of random variable. A lower chi-square value suggests that the observed data are consistent with \(H_{0}\). Conversely, an exceedingly high chi-square value implies that either \(H_{0}\) is incorrect or an event of low probability has happened._

Details of the above lemma are presented in Appendix E. Then, we define the following metric to evaluate the goodness of fit of estimation based on chi-square statistics.

**Definition 4.3** (Expectation of chi-square statistics (ECS)).: The expectation of chi-square statistics (ECS) for \(}\) are defined as the population deviation between the estimator of unlabeled class distribution \(}\) and its true distribution \(}^{u}\):

\[(}):=[^{2}()]= [_{i=1}^{K}-_{ }}[N_{i}^{u}])^{2}}{_{}}[N_{i}^{u}]}],\] (12)

where \(\) are estimators based on \(N_{1}^{l},N_{2}^{l},,N_{K}^{l}\), thus are still random variables.

Now, we introduce two main theorems and demonstrate the superiority of our conditional self-labeling.

**Theorem 4.4**.: _Consider two estimators for class distribution on unlabeled data, \(_{}\) and \(_{}\), we have \(_{}\) is a biased estimator and \(_{}\) is an unbiased estimator._

**Theorem 4.5**.: _Suppose \(r_{i}:= p_{i}^{l}}{N}\) denote the ratio of label samples of the \(i\)-th class to the whole samples, \(r:=_{i}r_{i}\) denotes the ratio of labeled samples to the whole samples. For unlabeled sample size \(N^{u}\), if \(}>-r p_{i}^{u}|,r p_{j})}\) for \( i_{l}, j_{u}\), then \((}_{})(}_{})\)._

Following rigorous statistical analysis, the generated self-label assignments from the conditional labeling method are closer to the true class distribution in the following scenarios:

* Estimation based on large unlabeled sample size (\(N^{u}\));
* The difference between prior distribution \(}\) and class distribution of unlabeled data \(}^{u}\) is not negligible.

## 5 Experiments

This section presents a comprehensive evaluation of our approach. It includes experimental results and in-depth analysis, demonstrating the effectiveness of our approach.

### Experimental setup

**Datasets.** We evaluate our approach on CIFAR-10/100 , ImageNet-100  and Tiny ImageNet . A detailed description of these datasets is provided in Appendix A. Specifically, ImageNet-100 dataset contains 100 classes sub-sampled from ImageNet-1k following . On all datasets, we first split all classes into seen and novel classes with a _novel class ratio_. Subsequent experiments will adopt a novel class ratio of 50% unless otherwise specified. Then, we will randomly assign labels to a portion of the data from the seen classes according to the specified _label ratio_, while the remaining data, along with all samples from the novel classes, are assigned to the unlabeled set.

**Implementation details.** For a fair comparison, we apply ResNet-50  as the backbone model for ImageNet-100 and ResNet-18 for other benchmarks. We train the model with a batch size of 256 for Tiny ImageNet and 512 for other benchmarks. Following , experiments across all benchmarks are implemented based on the pre-trained model from SimCLR . We jointly optimize backbone and prototype parameters using the standard Stochastic Gradient Descent (SGD) with momentum. We apply the cosine annealing learning rate schedule for all experiments. Techniques including multi-crop and queue structure  are employed to enhance the clustering objective. Additionally, RandAugment  serves as the strong augmentation for confidence objective. Additional implementation details are available in the Appendix B.

**Evaluation metric.** In assessing the efficacy of OwMatch, we adopt a multifaceted approach to evaluate accuracy following . Evaluation metrics include the standard accuracy for seen classes and the clustering accuracy for novel classes and all classes. Here, we leverage the Hungarian algorithm  to align the predicted class assignment for novel-class instances with their ground-truth labels to obtain clustering accuracy. We also report the joint clustering accuracy across all classes using the Hungarian algorithm.

### Main results

We consider and evaluate two versions of our method, called OwMatch and OwMatch+. OwMatch represents the standard version as illustrated in Figure 2, while OwMatch+ incorporates the multi-crop technique for additional augmentation. Detailed distinctions between the two versions are provided in the Appendix B. We evaluate our method on all benchmarks using a label ratio of 10% and 50% with the comprehensive experiment results provided in Table 1, 12, and 13. Results in Table 1 show that OwSSL approaches significantly outperform current state-of-the-art methods in traditional SSL, OSSL, and NCD by a considerable margin. On the other hand, OwMatch achieves

    &  &  &  \\   & Seen & Novel & All & Seen & Novel & All & Seen & Novel & All \\  FixMatch  & 71.5 & 50.4 & 49.5 & 39.6 & 23.5 & 20.3 & 65.8 & 36.7 & 34.9 \\ DS\({}^{3}\)L  & 77.6 & 45.3 & 40.2 & 55.1 & 23.7 & 24.0 & 71.2 & 32.5 & 30.8 \\ CGDL  & 72.3 & 44.6 & 39.7 & 49.3 & 22.5 & 23.5 & 67.3 & 33.8 & 31.9 \\ DTC  & 53.9 & 39.5 & 38.3 & 31.3 & 22.9 & 18.3 & 25.6 & 20.8 & 21.3 \\ RankStats  & 86.6 & 81.0 & 82.9 & 36.4 & 28.4 & 23.1 & 47.3 & 28.7 & 40.3 \\ SimCLR  & 58.3 & 63.4 & 51.7 & 28.6 & 21.1 & 22.3 & 39.5 & 35.7 & 36.9 \\ UNO  & 91.6 & 69.3 & 80.5 & 68.3 & 36.5 & 51.5 & - & - & - \\ ORCA  & 88.2 & 90.4 & 89.7 & 66.9 & 43.0 & 48.1 & 89.1 & 72.1 & 77.8 \\ NACH  & 89.5 & 92.2 & 91.3 & 68.7 & 47.0 & 52.1 & 91.0 & 75.5 & 79.6 \\ OpenLDN  & 95.7 & 95.1 & 95.4 & 73.5 & 46.8 & 60.1 & 89.6 & 68.6 & 79.1 \\ TRSSL  & **96.8** & 92.8 & 94.8 & 80.0 & 49.3 & 64.7 & - & - & - \\ OpenCon  & 89.3 & 91.1 & 90.4 & 69.1 & 47.8 & 52.7 & 90.6 & 80.8 & 83.8 \\  OwMatch & 93.0 & 95.9 & 94.4 & 74.5 & 55.9 & 65.1 & **91.7** & 72.0 & 81.8 \\ OwMatch+ & 96.5 & **97.1** & **96.8** & **80.1** & **63.9** & **71.9** & 91.5 & 79.6 & **85.5** \\   

Table 1: Average accuracy on the CIFAR-10/100 and ImageNet-100 with both novel class ratio and label ratio of 50%. We compare OwMatch with existing literature on OwSSL. Also compared with other related approaches of traditional SSL, OSSL, and NCD approaches following . Proper modifications are made to make these approaches compatible with OwSSL; the details are in Appendix C. The results are averaged over three independent runs. The baseline figures are sourced from the respective papers.

state-of-the-art across all benchmarks and evaluation metrics. It can not only classify novel classes accurately but also maintain robust performance on seen classes. On CIFAR-10, we observed OwMatch outperforms OpenLDN on novel and all classes by 2.0% and 1.4%, respectively. It is noteworthy that the enhancement brought about by OwMatch is more pronounced on the CIFAR-100 dataset, which presents a greater challenge due to the increasing number of classes. Regarding CIFAR-100, our method surpasses TRSSL by approximately 14.6% on novel classes and 7.2% on all classes. Subsequently, we extend to evaluate ImageNet-100 and observe a similar trend, with OwMatch+ showing significant improvement of **1.7%** on all-class accuracy compared to previous state-of-the-art approaches.

Principle analysis of conditional self-labeling.OwMatch primarily relies on high-quality self-label assignment to alleviate the model's confirmation bias. To clearly illuminate this progress during training, we employ the Manhattan distance \(_{i K}|c_{i}-c_{i}^{gt}|\) as a metric to evaluate the bias between the considered class distribution \(\{c_{i}\}_{i=1}^{K}\) and the ground truth \(\{c_{i}^{gt}\}_{i=1}^{K}\). Table 2 demonstrates the debiasing process: the model's confirmation bias is pronounced in the early epochs, whereas the bias of optimized self-label assignment is relatively minor. As training advances, the self-label assignment continues to guide the model, effectively mitigating the confirmation bias, as reflected in the decreasing \(B_{m}\) and the absolute difference between \(B_{m}\) and \(B_{s}\).

### Ablations, analysis, and real-scenario applications

To investigate the impact of each component, we embark on comprehensive ablation studies with both novel class ratio and label ratio of 50%. The first row in Table 3 showcases the foundational model performance, whose objective consists of only _unconditional_ clustering objective and supervised objective, already achieving impressive performance. We then analyze the effect of integrating a conditional self-labeling framework on CIFAR-100, which boosts novel-class accuracy by 1.0% on average. Additionally, the positive impact of consistency regularization is observed: roughly 0.9% enhancement across all evaluation metrics. Our ablation studies highlight the essential contribution of each component in OwMatch. Individually, each plays a significant part in the intended functionality, and together, these elements coalesce into a cohesive and robust framework. We also ablate other factors, including the number of local views for clustering objectives and iterations for the Sinkhorn-Knopp algorithm, with detailed statements provided in Table 15 and 16.

Comparison study on varying thresholding strategies.We compare our proposed open-world hierarchical thresholding approach with two prominent techniques: static thresholding  and self-adaptive thresholding . As illustrated in Table 4, our proposal achieves superior performance

    & **Epoch 1** & **Epoch 2** & **Epoch 3** & **Epoch 6** & **Epoch 10** & **Epoch 30** & **Epoch 50** \\  \(B_{m}\) & 0.4463 & 0.2939 & 0.2474 & 0.1753 & 0.1505 & 0.0904 & 0.0798 \\ \(B_{s}\) & 0.1004 & 0.0754 & 0.0893 & 0.0613 & 0.0407 & 0.0255 & 0.0219 \\ \(|B_{m}-B_{s}|\) & 0.3459 & 0.2185 & 0.1581 & 0.1140 & 0.1098 & 0.0649 & 0.0579 \\   

Table 2: The Manhattan distance (MD) is used to evaluate the confirmation bias. The first row presents the bias between the model’s predictive class distribution and the ground truth, denoted as \(B_{m}\). The second row reflects the bias between the self-label assignment and the ground truth, denoted as \(B_{s}\). The third row computes the absolute difference between \(B_{m}\) and \(B_{s}\), highlighting the debiasing effect of high-quality self-label assignments.

    &  &  &  \\  ConSL & PLCR & OwHT & Seen & Novel & All & Seen & Novel & All & Seen & Novel & All \\  \(\) & \(\) & \(\) & 96.5 & 90.2 & 93.3 & 78.8 & 56.7 & 67.7 & 66.5 & 38.1 & 52.0 \\ ✓ & \(\) & \(\) & 95.4 & 96.4 & 95.9 & 79.2 & 58.5 & 68.7 & 66.0 & 39.4 & 52.4 \\ ✓ & ✓ & \(\) & 96.3 & 97.3 & 96.8 & 80.1 & 59.4 & 69.6 & 68.6 & 42.0 & 54.2 \\ × & ✓ & ✓ & 97.1 & 90.4 & 93.8 & 80.7 & 59.7 & 69.9 & 69.7 & 41.4 & 54.6 \\ ✓ & ✓ & ✓ & 96.5 & 97.1 & 96.8 & 80.1 & 63.9 & 71.9 & 68.8 & 42.4 & 55.0 \\   

Table 3: Ablation studies on each component with both novel class ratio and label ratio of 50%. Here, **ConSL** refers to conditional self-labeling, **PLCR** refers to pseudo-label consistency regularization, and **OwHT** refers to an open-world hierarchical thresholding scheme.

in both novel- and all-class clustering accuracy across varying thresholding techniques. While self-adaptive has proven effective under closed-world scenarios, it encounters challenges in open-world settings. The pronounced disparity in overall learning conditions between seen and novel classes, as illustrated in Figure 0(b), can lead to unstable global thresholds. The class-wise adaptive approach based on that may exaggerate this issue, resulting in suboptimal performance. We implement a hierarchical structure to mitigate the instability sourcing from distinct learning dynamics of seen and novel classes.

On the comparison between OwSSL and Generalized Category Discovery.The OwSSL setting resembles the subsequently proposed Generalized Category Discovery (GCD) setting , with both assuming the existence of novel classes and that a portion of the data is labeled for seen classes. However, there are notable differences between these two groups of methods: 1) GCD-related methods leverage supervised contrastive learning  on labeled data and self-supervised contrastive learning  on all training data, whereas OwSSL typically employs pairwise similarity-based methods for clustering samples; 2) GCD-related works typically employ a pre-trained ViT-Base/16 backbone, which has significantly more parameters than the ResNet-18 or ResNet-50 models commonly used in OwSSL methods.

It is unfair to compare these two types of methods directly. Here, we still include a comparison with those GCD-related works to demonstrate the effectiveness of our method. Table 5 shows that our method outperforms existing approaches in novel-class and all-class accuracy on ImageNet-100 despite using a simpler model.

Ablation study on supervision components in the overall objective.The overall objective of OwMatch consists of a standard supervised objective, clustering objective, and confidence objective. Both the supervised and clustering objectives involve the use of labeled data, raising concerns about overlap in functionality. To investigate the significance of each component, we conduct an ablation study in which we modify the overall objective in two ways: 1) removing the supervised objective and 2) excluding labeled data from the online clustering process. The results are reported in Table 6.

In the first case, we observe a decrease in seen-class accuracy while maintaining novel-class clustering performance, while the latter case exhibits the opposite tendency: seen-class accuracy remains high, but novel-class clustering accuracy declines. In comparison to the previous cases, our overall objective integrates both components to strike a balance between clustering and confidence. The supervised objective enhances seen-class accuracy through one-hot supervision, while the clustering objective with conditional self-labeling improves novel-class clustering accuracy by incorporating labeled data. This harmonious approach yields the best all-class accuracy while roughly maintaining both seen- and novel-class performance.

The above evaluations are typically conducted under relatively ideal conditions: the datasets are class-balanced, and both the prior class distribution and the number of novel classes are available.

  
**Objective** & Seen & Novel & All \\  w/o supervised objective & 76.8 & 64.4 & 70.6 \\ w/o supervision for clustering & 80.3 & 61.2 & 70.7 \\ overall objective & 80.1 & 63.9 & 71.9 \\   

Table 6: Model performance under varying applications of supervision in the overall objective.

  
**Method** & **Backbone** & Seen & Novel & All \\  GCD  & ViT-B/16 & 91.8 & 63.8 & 72.7 \\ SimGD  & ViT-B/16 & 93.1 & 77.9 & 83.9 \\ InfoSieve  & ViT-B/16 & 84.9 & 78.3 & 80.5 \\ CiPR  & ViT-B/16 & 84.9 & 78.3 & 80.5 \\ PromptCAL  & ViT-B/16 & 92.7 & 78.3 & 83.1 \\  OwMatch+ & ResNet-50 & 91.5 & **79.6** & **85.5** \\   

Table 4: Performance comparison of static, self-adaptive, and our OwHT thresholding techniques on CIFAR-100 with both novel class ratio and label ratio of 50%.

  
**Method** & **Backbone** & Seen & Novel & All \\  GCD  & ViT-B/16 & 91.8 & 63.8 & 72.7 \\ SimGD  & ViT-B/16 & 93.1 & 77.9 & 83.9 \\ InfoSieve  & ViT-B/16 & 84.9 & 78.3 & 80.5 \\ CiPR  & ViT-B/16 & 84.9 & 78.3 & 80.5 \\ PromptCAL  & ViT-B/16 & 92.7 & 78.3 & 83.1 \\  OwMatch+ & ResNet-50 & 91.5 & **79.6** & **85.5** \\   

Table 5: Comparison with GCD-related works: average accuracy on the ImageNet-100 with both novel class ratio and label ratio of 50%.

However, in real-world scenarios, it is crucial to address the dependency on these assumptions. We will elaborate on each of these aspects to demonstrate the practical effectiveness of OwMatch.

Estimating the number of novel classes.OwMatch and other baselines typically assume that the number of novel classes is pre-determined for clarity in evaluation. However, this prior knowledge is often unavailable in practice, necessitating a precise estimation of the number of novel classes in advance. We primarily follow the approaches of GCD  and TRSSL  to estimate the number of classes. Specifically, \(K\)-means clustering is performed on representations of the entire dataset from the pre-trained ViT-B/16 backbone. The optimal value of \(k\) is determined by evaluating the clustering accuracy on the labeled samples calculated by the Hungarian algorithm. This accuracy serves as a scoring function, optimized using Brent's algorithm to find the that maximizes performance on the labeled data. The estimation results across generic benchmarks are shown in Table 7, which illustrates that the estimated class numbers come close to the ground truth. We also evaluate OwMatch's sensitivity to varying extents of class number estimation error, with results reported in Appendix D.

Data imbalance.Most generic benchmarks feature class-balanced, whereas real-world data tend to exhibit long-tailed class distribution. Our approach accommodate to arbitrary class distribution by constraining the optimized self-label assignment to comply with the prior class distribution, thereby naturally mitigating performance degradation caused by data imbalance. We evaluate our approach on imbalanced benchmarks, constructed with varying imbalance factors following TRSSL . Results in Table 8 demonstrate that OwMatch effectively addresses the challenge of data imbalance.

Training without prior.In scenarios where prior class distribution is unavailable, we propose an adaptive estimation scheme to make OwMatch still function _without relying on any prior assumptions_. Specifically, we initially adopt class-balanced prior if no prior information is available; then, the class distribution for conditional self-labeling is estimated and continuously updated based on model prediction. Next, standard training with estimated class distribution and distribution estimation are alternately conducted, with results reported in Table 8. We observe that the reduction in all-class accuracy achieved through the adaptive estimation scheme remains within 3% across almost all benchmarks and imbalance factors. These results reveal that the straightforward estimation technique performs robustly in the absence of prior knowledge.

## 6 Conclusion

This work integrates techniques from self-SL and SSL, refining them to present a new perspective on solving open-world SSL. We demonstrate that conditional self-labeling can achieve an unbiased estimation of the class distribution on unlabeled data with prior information, leading to high-quality self-label assignment with reduced confirmation bias. Our future endeavors will be directed toward developing solutions that are more aligned with realistic scenarios where such prior information might not be readily available or hard to be estimated. This will involve exploring methodologies that can effectively handle uncertainty and variability inherent in real-world data distributions.

    &  &  &  &  \\   & & Seen & Novel & All & Seen & Novel & All & Seen & Novel & All \\   & w/ & 96.5 & 97.1 & 96.8 & 93.7 & 72.1 & 82.5 & 92.9 & 70.1 & 80.9 \\  & w/o & 96.9 & 90.9 & 93.9 & 95.8 & 66.5 & 80.3 & 95.3 & 64.2 & 78.8 \\  & w/ & 80.1 & 63.9 & 71.9 & 76.8 & 42.0 & 57.3 & 76.1 & 35.2 & 51.9 \\  & w/o & 82.5 & 57.9 & 69.2 & 74.6 & 39.7 & 54.1 & 73.9 & 33.9 & 49.2 \\  & w/ & 68.8 & 42.4 & 55.0 & 61.7 & 25.1 & 41.6 & 62.4 & 21.7 & 38.3 \\  & w/o & 69.6 & 40.6 & 54.8 & 61.0 & 24.9 & 40.1 & 61.3 & 20.3 & 36.9 \\   

Table 8: Performance on generic recognition benchmarks with varying imbalance factors (IF), with and without prior class distribution. These benchmarks come with both novel class ratio and label ratio of 50%.