# Overcoming Brittleness in Pareto-Optimal

Learning-Augmented Algorithms

 Alex Elemter

Sorbonne University, CNRS, LIP6

4 place Jussieu

Paris, France 75005

alexelenter@gmail.com &Spyros Angelopoulos

International Laboratory on Learning Systems

Montreal, Canada, and

Sorbonne University, CNRS, LIP6

Paris, France 75005

spyros.angelopoulos@lip6.fr &Christoph Durr

Sorbonne University, CNRS, LIP6

4 place Jussieu

Paris, France 75005

christoph.durr@lip6.fr &Yanni Lefki

Institut Polytechnique de Paris

Rte de Saclay

Palaiseau, 91120, France

yanni.lefki@gmail.com

Research done while at LIP6, Sorboonne University.

###### Abstract

The study of online algorithms with machine-learned predictions has gained considerable prominence in recent years. One of the common objectives in the design and analysis of such algorithms is to attain (Pareto) optimal tradeoffs between the _consistency_ of the algorithm, i.e., its performance assuming perfect predictions, and its _robustness_, i.e., the performance of the algorithm under adversarial predictions. In this work, we demonstrate that this optimization criterion can be extremely brittle, in that the performance of Pareto-optimal algorithms may degrade dramatically even in the presence of imperceptive prediction error. To remedy this drawback, we propose a new framework in which the smoothness in the performance of the algorithm is enforced by means of a _user-specified profile_. This allows us to regulate the performance of the algorithm as a function of the prediction error, while simultaneously maintaining the analytical notion of consistency/robustness tradeoffs, adapted to the profile setting. We apply this new approach to a well-studied online problem, namely the _one-way trading_ problem. For this problem, we further address another limitation of the state-of-the-art Pareto-optimal algorithms, namely the fact that they are tailored to worst-case, and extremely pessimistic inputs. We propose a new Pareto-optimal algorithm that leverages any deviation from the worst-case input to its benefit, and introduce a new metric that allows us to compare any two Pareto-optimal algorithms via a _dominance_ relation.

## 1 Introduction

The field of learning-augmented online algorithms has witnessed remarkable growth in recent years, starting with the seminal works of Lykouris and Vassilvitskii  and Purohit _et al._. The focus, in this field, is on improving the algorithmic performance by leveraging some inherently imperfect _prediction_ on the online input. This is in contrast to the standard framework of _competitive analysis_, in which the algorithm has no access to any information about the future, and the analysis is based on adversarial inputs tailored to the myopic nature of the algorithm.

Learning-augmented online algorithms are typically analyzed with respect to three performance metrics. The first is the _consistency_ of the algorithm, namely its competitive ratio assuming that the prediction is error-free. The second is the _robustness_, that is, the competitive ratio assuming that the prediction is adversarial, and is thus generated by a malicious oracle. A third consideration is the degradation of the competitive ratio as a function of the prediction error; here, the notion of _smoothness_ captures the requirement that the competitive ratio smoothly interpolates between the two extremes, namely the consistency and the robustness.

As expected, not all three objectives can be simultaneously optimized. Many works have thus focused on the trade-off between consistency and robustness. Algorithms with optimal tradeoffs are often called _Pareto-optimal_ since their performance lies on the Pareto front of the two extreme metrics. Examples of problems studied in the Pareto setting include online conversion problems [38; 29], searching for a hidden target , ski rental [39; 6], online covering  metrical task systems , energy-minimization scheduling , scheduling [7; 5] and online state exploration .

Pareto-based analysis is attractive for several reasons. First, it fully characterizes the performance of the algorithm on the extreme scenarios, with respect to the reliability of the prediction. In addition, it provides a mathematically clean formulation of the desired objectives, which is often quite challenging even for seemingly simple online problems. However, as we will discuss, this type of analysis may very well suffer from _brittleness_, in that the performance ratio of any Pareto-optimal algorithm may be as high as its robustness, even if the prediction is near-perfect. This has an important implication for the algorithm designer: namely, in many realistic situations, a Pareto-optimal algorithm may perform even worse than the best competitive algorithm with no predictions.

To illustrate this drawback, as well as our proposed methodology for counteracting it, we will use the well-known _one-way trading_ problem, which is one of the fundamental formulations for online financial transactions. In this problem, a decision maker must convert a unit in a given currency, say USD, to a different currency, say EUR, by performing exchanges over an unknown horizon. Specifically, prior to each transaction, the algorithm is informed about the current exchange rate, and must irrevocably exchange a fraction of its USD budget to EUR, according to the rate in question. This problem has served as a proving ground for the competitive analysis of more involved settings such as two-way trading and portfolio optimization; see Chapter 14 in  and the survey . In addition, it has connections to other problems such as fractional knapsack  and sponsored auctions . Optimal competitive ratios, in the standard framework, were first obtained in . An elegant Pareto-optimal algorithm for maximum-rate prediction was given in , based on the concept of an online _threshold_ function. However,  does not take into consideration the prediction error other than at the two extreme values. In contrast, the interplay between the prediction error across the entire _spectrum_ and the performance of the algorithm is at the heart of our study.

### Contribution

Our first result (Theorem 3.1) establishes the brittleness of all Pareto-optimal algorithms for one-way trading. To remedy this undesirable situation, in Section 3 we introduce the novel concept of a performance _profile_\(F\), chosen by the end user. Informally, \(F\) maps the prediction error to an upper bound on the desired performance ratio of the algorithm. This concept is motivated by practical considerations in everyday applications. E.g., in financial markets, a trader may choose a customized profile based on historical stock exchange data, and how accurate past predictions have proven.

Naturally, not every profile may be _feasible_, in that there may not exist an online algorithm whose performance abides with it. Our next main result is an algorithm that decides whether a given profile is feasible (Theorem 3.2). Note that this is an _offline_ problem, however, our algorithm also yields an online strategy, if \(F\) is indeed feasible. This further allows us to obtain an online algorithm that not only abides with a feasible profile \(F\), but also with the "best" possible profile that has a shape similar to that of \(F\) (Remark 4.1). We formalize this intuitive notion based on the concept of the best vertical translation of \(F\). We thus obtain a generalization of the concept of consistency (which is brittle) to the _consistency according to profile_\(F\), which is inherently non-brittle by virtue of the profile definition.

In Section 5, we address another limitation of the known Pareto-optimal algorithms for one-way trading. Specifically, we note that the algorithm of  is tailored to worst-case inputs in which the exchange rates increase continuously until a certain point, then drop to the lowest rate. Again from a practical standpoint, such a worst-case scenario never arises in real markets. Motivated by the concept of the _lenient adversary_ of  (in the standard, no-prediction setting), we present and analyze an _adaptive_, Pareto-optimal algorithm that leverages any deviation from the worst-case sequence to its benefit. To formally quantify the performance gain, we introduce an additional metric that captures the profit of the algorithm on all exchange rates that are at least as high as the predicted maximum rate, and allows us to compare any two Pareto-optimal algorithms via a _dominance_ relation. Another novelty of our algorithm, in the context of the problem at hand, is that it does not require the prediction to be given ahead of time, instead the prediction can be revealed during its execution (Remark 5.1). This is a clearly desirable algorithmic feature, that has been achieved in other online problems, e.g., .

In Section 6 we give an experimental evaluation of all our algorithms, over both real data (Bitcoin exchange rates) and synthetic data, which validates the theoretical results and quantifies the obtained performance improvements. We emphasize that our framework can be readily applicable to other learning-augmented problems, in particular those which suffer from brittleness. We discuss another well-known application from AI, namely _contract scheduling_ in Section 7.

In terms of techniques, our algorithms and analysis are based on the concept of a _threshold_ function which carefully guides the actions of the algorithm. While online threshold algorithms have been used in previous studies, including one-way trading [41; 40; 38; 29], the settings we study pose novel challenges. For the profile-based setting, the design of the function must take into consideration all the constraints induced by the profile. To this end, we use an iterative approach that considers the constraints incrementally, until they are all satisfied. For the adaptive setting, the threshold function must change dynamically, according to the revealed sequence. This is unlike the standard Pareto setting, in which a static function suffices.

While our framework is directly applicable to single-valued predictions, it can also be applied to more complex settings in which the prediction is a vector of values. This is because the concept of the profile still applies, since the error is defined by a distance norm between the predicted and the actual vector.

### Related Work

There has been a significant body of recent work on online algorithms with predictions, see, e.g., the surveys [34; 33]. Several problems have been studied in learning-augmented settings, e.g., paging [31; 22], metrical task systems [9; 17], rent-or buy problems [36; 6; 20; 39; 3], packing and covering [14; 8; 21], scheduling [26; 28; 11; 32; 18; 25], matching [27; 10; 24], graph optimization [1; 2; 12; 13], and many others. This is only a partial list; for a comprehensive summary of the existing literature, we refer the reader to the online repository . As discussed earlier, many works have focused exclusively on consistency/robustness tradeoffs, without an explicit error-based analysis, e.g. [38; 29; 4; 39; 6; 14; 17; 28; 7; 23; 1]. Incorporating smoothness in regards to the prediction error is a challenging task, both in terms of modeling and analysis. For instance, [13; 1] studied online combinatorial optimization problems in which the performance of the online degrades as a function of a distance measure between the predicted and the actual solution. Our work differs from such studies in that the dependency on the prediction error is _user specific_, and can change according to the application setting, while still maintaining the concepts of consistency and robustness.

## 2 Preliminaries

In the one-way trading problem, the input \(\) is a sequence of _exchange rates_, where \(p_{i}\) denotes the \(i\)-th rate in the sequence. The trader has a starting budget equal to 1. We follow the standard assumption that \(p_{i}[1,M]\), where \(M\) represents an upper bound on the rates that is known in advance. Once \(p_{i}\) is revealed, the trader must decide the amount to be exchanged to the secondary currency, which cannot exceed her current budget. We consider the general setting in which the horizon \(n\) is not known ahead of time. The problem formulation also assumes that the trader is notified once the last rate is revealed, and is thus obliged to exchange all of its remaining fund at rate \(p_{n}\).

An algorithm \(A\) decides the fractional exchanges upon revealing of \(p_{i}\), as a function of the previous \(i-1\) rates, i.e., the sequence \([1,i-1]\). We denote by \(A()\) the _profit_ of \(A\) on \(\), i.e., the total amount that \(A\) has produced after the last exchange. We denote by \(p_{}^{*}=_{i[1,i]}p_{i}\) the _maximum_ rate in \(\) and by \(()\) the profit of the optimal offline strategy, hence \(()=p_{}^{*}\). The competitive ratio of \(A\) is thus defined as \((A)=_{}()}{A()}\). For given \(\), we refer to the ratio \(()/A()\) as the _performance ratio_ of \(A\) on \(\). The optimal competitive ratio, denoted by \(r^{*}\) is \(( M)\), and more precisely, it is equal to the root of the equation \(r^{*}=-1}\).

Given algorithm \(A\), we denote by \(w_{A,i}()\) and \(s_{A,i}()\), the _budget_ used by \(A\) and its accrued _profit_ right before \(p_{i}\) is revealed, respectively. We refer to \(w_{A,i}()\) as the _utilization_ of \(A\). Formally, for every sequence \(\), and every algorithm \(A\), we have \(w_{A,i}=w_{A_{i-1}}+x_{i}\), where \(x_{i}\) is the amount traded on the \(i\)-th rate, that is, \(w_{A,i}\) is the total amount exchanged up to and including the \(i\)-th request. We also have that \(s_{i}=_{j=1}^{i-1}p_{j}(w_{j+1}-w_{j})\), with \(s_{1}=0.\) For simplicity, we may omit the input \(\), or the algorithm \(A\) when it is clear from context. For example, we will denote by \(p^{*}\) the maximum rate in \(\).

The above definitions assume the standard setting in which the algorithm has no information on the input. In regards to learning-augmented settings, we consider the model of  in which the algorithm has an imperfect prediction \(\) on \(p^{*}\). We define formally, the _consistency_ and the robustness of an algorithm \(A\) as \(c(A)=_{:p^{*}_{}=}_{}}{A()}\) and \(r(A)=_{}_{[1,M]}_{}}{A()}\), respectively. An algorithm \(A\) with prediction \(\) is _Pareto-optimal_ if, for any given \(r\), it has robustness at most \(r\), and has the smallest possible consistency, which we will denote by \(c(r)\).

**Remark 2.1**.: It suffices to consider only sequences in which the exchange rates increase up to a certain point, then drop to 1 . Moreover, for any competitively optimal algorithm, the worst-case inputs are such in which the exchange rates increase continuously, i.e., by infinitesimal amounts.

## 3 Brittleness of Pareto-Optimal Algorithms and Performance Profiles

We first define formally the concept of _brittleness_.

**Definition 3.1**.: Let \(\) denote a maximum-rate prediction for \(p^{*}_{}\). We say that \(\) is \(brittle\) if for any Pareto-optimal strategy \(A\) of robustness \(r\) and consistency \(c(r)\), and for every \(>0,\) there exists \(\) with \(|-p^{*}_{}|\), for which \(()}{A()}=r\).

The definition deems a prediction to be brittle if there exist sequences for which the slightest prediction error forces every Pareto-Optimal strategy to have a performance that is equal to its robustness.

**Theorem 3.1** (Appendix A).: The maximum-rate prediction is brittle for one-way trading.

Theorem 3.1 shows that Pareto-optimality is a very "fragile" metric for comparing strategies with max-rate prediction. To remedy this drawback, we introduce the new concept of a _profile_.

**Definition 3.2**.: Let \(\) be a partition of \([1,M]\) to \(l\) intervals, i.e., \(=_{i=1}^{l}[q_{i},q_{i+1})\), with \(q_{1}=1\) and \(q_{l+1}=M\), and let \(\) be a maximum-rate prediction. A _profile_ function \(F:^{+}\) is a step function that maps each interval in \(\) to \(t_{i}^{+}\), and which satisfies the following conditions. There exists \([1,l]\) such that: (i) \(t_{i-1} t_{i}\), for all \(i\) and \(t_{i+1} t_{i}\), for all \(i\), and (ii) \([q_{i},q_{i+1})\).

The profile function allows the end user to impose a requirement on the performance of the algorithm, as expressed in the following definition.

**Definition 3.3**.: We say that an online strategy \(A\)_respects_ a given profile \(F:_{i=1}^{l}[q_{i},q_{i+1})^{+}\) if for all input sequences \(\) for which \(p^{*}_{}[q_{i},q_{i+1})\), it holds that \(()}{A()} F([q_{i},q_{i+1})).\)

Informally, a profile \(F\) reflects a desired worst-case performance of an algorithm, assuming that the _actual_ but unknown maximum rate in the input sequence is in the interval \([q_{i},q_{i+1})\). Thus, the profile represents the desired upper bound on the performance of an algorithm, as a function of the prediction error. Unlike Pareto-optimality, which only cares about performance at extremes, the relation between performance and prediction error becomes now definable across the entire _spectrum_ of error. The definition also reflects the expectation that the algorithm performs best when the prediction is error-free, and its performance degrades monotonically as a function of the error.

We illustrate the above concepts using the profile depicted in Figure 0(a). Here, the profile consists of \(l=6\) intervals, where the first 3 intervals correspond to the _decreasing_ part of the profile and the last 4 to the _increasing_ part of the profile. Note that the interval \([q_{3},q_{4})\) contains the prediction \(\) and belongs in both the decreasing and the increasing parts. Note also that the profile allows to define an asymmetric dependency on the prediction error. This is a very useful property in applications such as one-way trading. For example, a trader may want to be more cautious if the market will perform worse in the future, than better in the future, relative to what has been predicted.

Figure 0(b) depicts a different profile in which the performance ratio must be at most \(t_{1}\), for any error, unless the prediction is error-free, in which case the performance ratio has to be at most \(t_{2}<t_{1}\). Such a profile yields Pareto-optimality, if \(t_{1}=r\) and \(t_{2}=c(r)\).

We are interested in profiles \(F\) that are _feasible_, in the sense there exists an online algorithm that respects \(F\). The following is one of our main results, whose proof will follow from Theorem 4.1 and Corollary 4.1, as we will show in Section 4.

**Theorem 3.2**.: Given a profile \(F\) defined over \(l\) intervals, there exists an algorithm for deciding whether \(F\) is feasible that runs in time \(O(l)\). Furthermore, if \(F\) is feasible, there exists an _online_ algorithm that respects \(F\).

Given our algorithm that decides the feasibility of a profile, we can also answer a more general question. Suppose that \(F\) is infeasible, but we would like, nevertheless, to be able to respect a profile \(F^{}\) that is "similar" to \(F\). Conversely, if \(F\) is feasible, then we know we can likely do even better, for example, we would like to follow a profile \(F^{}\) that is similar to \(F\), but maps some intervals to smaller ratios. The following definition formalizes this intuitive objective.

**Definition 3.4**.: Let \(F:^{+}\) denote a profile. Given \(a^{+}\), we define the _extension_\(G_{a}\) of \(F\) as the vertical transformation of \(F\), in which, for every interval \([q_{i},q_{i+1})\) it holds that \(G_{a}([q_{i},q_{i+1}))=a F([q_{i},q_{i+1}))\).

We can generalize the concepts of consistency and robustness _relative to a profile \(F\)_ as follows, recalling that \([q_{i},q_{i+1})\).

**Definition 3.5**.: Given a profile \(F\) for a prediction \(\), and a robustness \(r\), we say that algorithm \(A\) is \(r\)-robust and \(c\)-consistent _according to \(F\)_, if there exists an extension \(G_{a}\) of \(F\) for which: (i) for every interval, we have \(G_{a}([q_{i},q_{i+1})) r\); (ii) \(G_{a}([q_{i},q_{i+1})) c\); and (iii) \(A\) respects \(G_{a}\).

**Remark 3.1**.: The smoothness of a profile is related to the number of intervals, \(l\). The larger the \(l\), the smoother the performance of an algorithm which respects the profile.

## 4 Profile-Based Algorithms

In this section, we present an algorithm which decides whether a given profile \(F\) is feasible or not. Note that this is an _offline_, decision problem, which we will denote by \((F)\). In addition, if \(F\) is feasible, we also provide an _online_ algorithm that respects \(F\).

Our algorithms are inspired by the class of _threshold_ algorithms (OTA), introduced in . In these algorithms, a threshold function \(\) guides the decision about the amount to be exchanged when a

Figure 1: Illustration of profile functions.

new rate is revealed. Specifically, \(\) maps _utilization_ to _reservation rates_. Here, a utilization value \(w\) represents the fractional amount exchanged so far by the online algorithm, whereas the reservation rate, \(\), is the minimum rate in \([1,M]\) at which the algorithm will make an exchange. At each point a new rate \(p_{i}\) is revealed, the algorithm updates its utilization by setting \(w_{i+1}=^{-1}(p_{i})\), if \(p_{i}>(w_{i})\), otherwise \(w_{i+1}=w_{i}\). In both cases, it exchanges an amount equal to \(w_{i+1}-w_{i}\) at rate \(p_{i}\). The function \(\) must be increasing, and its codomain must include \([1,M]\).

The main challenge posed in our setting is to guarantee the varying performance ratios globally, i.e., for all intervals and not just locally for a given interval. Thus, we need a global approach that takes into account the entirety of the profile, and in particular the transitions between consecutive intervals. We will thus design a function \(\) so as to satisfy \(l\) set of constraints, where each set of constraints applies to a specific interval. Define \(_{i}=_{0}^{w_{i}}(u)du\), with \(_{1}=0\). We seek a function \(\) and values \(0=w_{1} w_{l+1} 1\) such that the following constraints are satisfied for all \(i[1,l]\).

\[[] [w_{i},w_{i+1}):_{i}+ _{w_{i}}^{}(t)\,dt+1-} t_{i}.\]

\[[w_{i+1}] (w_{i+1})=q_{i+1}.\]

\[w_{i} w_{i+1} 1.\]

Constraint \([]\) expresses the requirement on the performance ratio \(F([q_{i},q_{i+1}))\) that is imposed by the profile. Note that here \(_{i}\) is the minimum profit of an OTA at the point it reaches utilization \(w_{i}\). This follows from Remark 2.1. Constraint \([w_{i+1}]\) allows us to obtain the partition of the utilization levels induced by the profile. Moreover, such a constraint is needed for constraint \([]\) to correctly represent the performance ratio indicated by the profile. Constraint \([]\) establishes that the utilization levels defined are increasing and that they do not exceed the unit budget available to the algorithm. The following lemma follows straightforwardly from the above discussion.

**Lemma 4.1**.: \(F\) is feasible if and only if there exist \(\) and \(w_{1},,w_{l+1}\) that satisfy the above sets of constraints, for all \(i[1,l]\).

Algorithm 1, which we call Profile, shows how to obtain the threshold function \(\), along with the utilization values \(w_{1}, w_{l+1}\), assuming that \(F\) is feasible. This is formally stated in Theorem 4.1. We emphasize that the theorem proves an even stronger statement; namely, if \(F\) is not feasible, then Profile correctly outputs its infeasibility. That is, the algorithm fully solves Feasible\((F)\).

**Theorem 4.1** (Appendix B).: A profile \(F\) admits an online strategy which respects \(F\) if and only if Profile terminates with a value \(w_{l+1} 1\).

Furthermore, if \(F\) is feasible, then Profile directly provides an online algorithm that respects \(F\):

**Corollary 4.1**.: If \(F\) is feasible, then the threshold function \(_{l}\) returned by Profile defines an OTA which respects \(F\).

**Remark 4.1**.: For a profile \(F\), we can use binary search in combination with Profile, in order to find the minimum \(a^{+}\), such that \(G_{a}\) extends \(F\) and \(G_{a}\) is feasible, according to Definition 3.4.

We give some intuition about Profile, and how we obtain \(\), and the values \(w_{i}\), for all \(i\). The algorithm computes \(\) incrementally: namely, in iteration \(i\), it obtains a new function \(_{i}\) that aims to satisfy the sets of constraints for the intervals \(_{k=1}^{i}[q_{k},q_{k+1})\), and computes a value for \(w_{i+1}\), as well as an updated value for \(w_{i}\). In each iteration \(i\), the algorithm guarantees that an OTA based on \(_{i}\) respects the profile on all sequences whose maximum rate is in \([1,q_{i+1})\) (provided that this is indeed feasible) and, furthermore, that the utilization at the end of iteration \(i\), namely \(w_{i+1}\) is as small as possible. This is crucial, since it allows us to decide Feasible(\(F\)) based on the final value of \(w_{l+1}\).

The algorithm makes a distinction between two types of updates. The first type occurs in the increasing part of the profile, i.e., when \(t_{i}<t_{i-1}\). This is a relatively simpler case, because the algorithm has already guaranteed a smaller ratio in the previous interval. Hence the algorithm can afford to wait until it sees a rate that exceeds the reservation rate \(_{i}\) (line 5-7). The second type occurs in the decreasing part of the profile (lines 9-14). This is intuitively a harder case, because on every new interval the algorithm must do even better than in the previous intervals. That is, when observing a rate equal to \(q_{i}\), the algorithm now needs to perform at a ratio \(t_{i}<t_{i-1}\), hence it should have made a bigger profit. To this end, we need first to increase \(w_{i}\) (lines 9 and 13) then extend \(_{i-1}\) to account for interval \(i\) (line 12). The precise amount by which we increase \(w_{i}\) is guided by the requirement that the algorithm must have performance ratio \(t_{i}\) for the worst-case sequence of increasing rates up to \(q_{i}\).

## 5 An Adaptive Pareto-Optimal Algorithm

In this section we study another generalization of Pareto-optimality. The starting observation is that the Pareto-optimal OTA of  is tailored to worst-case scenarios. Namely, the threshold function in  is _static_, i.e., determined prior to the execution of the algorithm, and tailored to a sequence of continuously increasing exchange rates that may suddenly drop to 1. However, in practice, such sequences never occur in real markets. We show how to obtain an algorithm that is not only Pareto-optimal, but also leverages deviations from the worst-case sequence to its benefit.

Our setting is further motivated by , who studied the basic setting of standard competitive analysis without predictions. Their solution is based on _threat-based_ policies, i.e., algorithms that exchange at each point in time the minimum required amount so as to guarantee the optimal competitive ratio. In this section, instead, we consider the learning-augmented setting in which the algorithm has access to a max-rate prediction \(\). Our algorithm uses an _adaptive_ threshold policy, in which the threshold function is updated every time a deviation from the worst-case input is observed. We follow this approach since OTAs are typically more versatile than threat-based policies, and can apply to more complex problems and settings, such as several variants of the knapsack problem, e.g., .

In a nutshell, we seek a Pareto-optimal algorithm that is not only optimal over worst-case sequences, but also over all other sequences. To describe this formally, we first define some concepts. Let \(\) be a max-rate prediction for an input \(\) of increasing rates, and define \(\) as the suffix of \(\) comprised of rates at least as high as \(\). (in the event that \(\) is the empty sequence, our problem reduces to standard Pareto optimality). Let \(=_{1},,_{m}\), and \(_{i+1}(A,)\) denote the profit made by an online algorithm \(A\) on \(\) after its exchange over rate \(_{i}\), for any \(i[1,m]\),. Let also \((A,)\) denote the vector \(_{i}(A,):i[1,m]\). We say that algorithm \(A\)_dominates_ another algorithm \(B\) on input \(\), if \((A,)\) is lexicographically no smaller than \((B,)\).

Informally, \((A,)\) is the vector of profits that \(A\) has made so far, for each rate that is at least as high as the predicted maximum rate. The lexicographic ordering assigns priority to profits made at exchange rates close to, but larger than the prediction. We now state our main result.

**Theorem 5.1** (Appendix C).: For any robustness requirement \(r\), Ada-PO is Pareto-optimal and dominates every other Pareto-optimal algorithm, on every possible sequence \(\).

Note that the algorithm of  is dominant only for sequences in which the exchange rates increase continuously up to some \(p^{*}\), then drop to 1. For those and all other sequences, our algorithm dominates that of . Note also that a dominant \(r\)-robust algorithm is a Pareto-optimal algorithm.

``` Input:\(r\), \([1,M]\)
1:\(w 0\), \(s 0\), \(p^{*} 1\)
2:for\(p_{i}\)do
3:if\(p_{i}>p^{*}\)then
4:\(p^{*} p_{i}\)
5:if\(p_{i}\)then
6:\(w_{i+1}-r(s+1-wp_{i})}{r(p_{i}-1)}\)
7:\(s s+p_{i}(w_{i+1}-w)\)
8:\(w w_{i+1}\)
9:else
10:if\(r(s+1-pw+w^{*}) M\)then
11:\(w_{i+1} 1\)
12:else
13:\(w_{i+1} w^{*}\)
14:\(s s+p_{i}(w_{i+1}-w)\)
15:\(w w_{i+1}\) ```

**Algorithm 2** Ada-PO (adaptive Pareto-optimal)

Ada-PO consists of two phases. The first phase (lines 5-9) consists of revealed rates strictly smaller than \(\). In this phase, the algorithm exchanges the minimum amounts so as to guarantee \(r\)-robustness (i.e., it makes threat-based decisions). Here, adaptivity allows the algorithm to reserve its budget for the second phase. The second phase (lines 11-15) consists of revealed rates at least as high as \(\). This is the challenging part, since we need to ensure simultaneously dominance and \(r\)-robustness, but these two objectives are in a trade-off relation. Here, adaptivity allows us to exchange more money at each revealed rate without sacrificing robustness.

Suppose that \(p_{i}\) is revealed in the second phase (i.e., \(p_{i}\)). To achieve simultaneously the robustness and the dominance, we need to find a continuous increasing \(\) whose domain is \([w_{i+1},1]\), along with a value for \(w_{i+1}\). To this end, we solve the optimization problem \(O_{i}\), described below.

Here, constraint [\(\)] is for guaranteeing \(r\)-robustness; and constraint [\(M\)] and [u] guarantee that \(\) is well-defined as a threshold function. Maximizing \(w\) maximizes the amount exchanged at rate \(p_{i}\), which is essential for dominance. In Appendix C we give further details, and we show that \(O_{i}\) has optimal solution \(w^{*}\) equal to the root of the equation \(w^{*}=1-(+1-p_{i}w_{i}+w^{*}(p_{i}-1)-1) }),\) which is used in line 13 of Ada-PO.

\[ w\] ( \[O_{i}\] ) subj. to \[[] [w,1):+p_{i}(w-w_{i}) +_{w}^{}(t)\,dt+1-}=r,\] ( \[M\] ) \[(1) M,\] ( \[] \[w_{i} w 1.\] )

**Remark 5.1**.: Ada-PO, unlike the known static OTAs, does not require a prediction \(\) ahead of time; the prediction can be revealed during its execution instead, since it is only used in the second phase. This can be very useful in practice, e.g., if the trader obtains information "on-the-fly".

## 6 Experimental evaluation

We present experimental results for both the profile-based algorithm Profile (Algorithm 1) and the adaptive Pareto-optimal algorithm Ada-PO (Algorithm 2). We compare our algorithms to the state of the art Pareto-optimal algorithm of , which we denote by PO.

**Profile setting.** We use a profile \(F\) that consists of three intervals \([q_{1}=1,q_{2})\), \([q_{2},q_{3})\) and \([q_{3},q_{4}=M]\), where \(M=100\). The profile is defined in terms of the prediction \(\), by choosing \(q_{2}=0.9\) and \(q_{3}=1.1\). In addition, \(F\) is such that \(F([q_{1},q_{2}))=t_{1}=F([q_{3},q_{4}])=t_{3}=r\), where \(r=4\) (larger than, but close to the optimal competitive ratio \(r^{*}\)). Here, \(F([q_{2},q_{3}))=t_{2}<r\) is the _smallest_ value such that \(F\) is feasible. To find \(t_{2}\), we use binary search in \([1,r]\) in combination with Profile, and note that this depends on \(\). \(F\) is depicted in Figure 1(a). Intuitively, \(r\) corresponds to the robustness, whereas \(t_{2}\) is the performance ratio if the input \(\) is such that \(p^{*}[0.9,1.1)\), i.e. if \(\) is "close" to \(p^{*}\). The length of \([q_{2},q_{3})\), which is equal to \(0.2\), reflects how much the user trusts the prediction.

Figure 1(b) depicts the performance of Profile, and PO with robustness \(r\), on the worst case sequences of maximum rate \(p^{*}\), as a function of \(p^{*}\). Recall that such sequence is of the form \(1,,p^{*},1\), with infinitesimal increments up to \(p^{*}\), simulated using a step equal to 0.01. We denote this sequence by \(^{w}_{p^{*}}\). We choose \(\) u.a.r. in \([1,M]\) (\(=67.8\) in Figure 1(b)). We observe that PO exhibits high brittleeness if \(p^{*}\) is very close, but smaller than \(\), namely has performance ratio of \(r\), which validates Theorem 3.1. In contrast, Profile guarantees a performance ratio equal to \(t_{2}\) in the entire interval \([0,9,1.1]\), as required by \(F\), thus tolerating a prediction error as high as \(10\%\), while remaining \(r\)-robust for all errors. This validates Theorem 4.1. As expected, PO has better ratio if \(p^{*}=\) (from the definition of Pareto optimality).

To further quantify the performance difference between the two algorithms, we evaluated both algorithms on 100 randomly defined worst-case sequences. Each sequence \(^{w}_{p^{*}}\) is obtained by sampling \(\) u.a.r. in \([1,M]\), and for such \(\), by randomly picking \(p^{*}[0.9,1.1]\), the significant prediction error for the user. Figure 1(c) depicts the relative performance difference of the two algorithms for each \(^{w}_{p^{*}}\), as a function of the prediction error. We observe that if \(p^{*}<\), then Profile improves upon PO by 20% to 50%, whereas if \(p^{*}>\), Profile is inferior by only \(10\%\) to \(20\%\). The average improvement we report, taken over the 100 ratios is 22%. We conclude that while both algorithms guarantee robustness \(r\), Profile is not only smooth around the prediction, but also performs better on the average, which supports the benefits from using a profile.

In addition, we performed experiments over sequences obtained from real trading data, using the profile \(F\) as above. We used exchange rates from Bitcoin (BTC) to USD; specifically, we used a list of the last 1000 daily exchange rates (finishing on May 20, 2024), defining as the prediction \(\) the maximum rate in the first 200 rates, and running the algorithm on a sequence consisting of the last 800 rates. Figure 1(d) depicts the performance ratios of Profile and PO, where each point in the plot corresponds to the maximum rate observed so far: these are the only rates at which the algorithms make exchanges. We observe that PO continues to suffer from brittleeness, whereas Profile still exhibits smooth degradation in the interval \([0.9,1.1]\).

In Appendix E we report an additional experiment on the average performance over BTC sequences. The key takeaway from all experiments on both synthetic and real sequences is that Profile performs much better if \(p^{*}<\), and at the same time it is only slightly worse, if \(p^{*}>\). This behavior is due to the smoothness enforced around the prediction, as guaranteed by the profile.

**Adaptive setting.** Since, by definition, PO and Ada-PO perform the same over worst-case sequences, we focus on sequences from BTC rates. Based on a list of the last 1000 daily BTC rates, we obtain a prediction \(\) and the sequence, as in our profile-based experiments above. Figure 1(e) plots the performance ratio as a function of the currently observed maximum rate in the sequence. For every such rate that exceeds \(\), Ada-PO outperforms PO, which validates Theorem 5.1. This comes at an unavoidable increase in brittleeness, as expected, and illustrates the tradeoff between smoothness and dominance. We expect Ada-PO to be the algorithm of choice when the prediction is conservative, or when \(\) is not given to the trader ahead of time, but is rather revealed at some point in the sequence.

## 7 Discussion

Our profile-based framework can apply to many other problems augmented with ML predictions, and is not specific to one-way trading. To illustrate this, in Appendix D we analyze another application in the context of _contract scheduling_, which is a classic problem from resource-bounded reasoning in AI, and which, likewise, suffers from brittleness. Our work is the first towards understanding the power and limitations of imperfect ML predictions in competitive financial optimization beyond extreme values of the prediction error. The techniques introduced will help address problems such as two-way trading and portfolio optimization, which have not yet been studied in learning augmentedsettings. Other potential applications include several well-known variants knapsack problems, where online threshold algorithms are commonly used, especially in learning-augmented settings . Last, it would be interesting to study dynamic settings, in which the predictions are obtained as the sequence is revealed to the algorithm.

## 8 Acknowledgements

This work was funded by the project PREDICTIONS, grant ANR-23-CE48-0010 from the French National Research Agency (ANR). The first author acknowledges the support of AANI (Agencia Nacional de Investigacion e Innovacion).