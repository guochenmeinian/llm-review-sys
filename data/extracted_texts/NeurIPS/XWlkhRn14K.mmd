# Maia-2: A Unified Model for Human-AI Alignment in Chess

Zhenwei Tang

University of Toronto

josephtang@cs.toronto.edu&Difan Jiao

University of Toronto

difanjiao@cs.toronto.edu&Reid McIlroy-Young

Harvard University

reidmcy@seas.harvard.edu&Jon Kleinberg

Cornell University

kleinberg@cornell.edu&Siddhartha Sen

Microsoft Research

sidsen@microsoft.com&Ashton Anderson

University of Toronto

ashton@cs.toronto.edu

###### Abstract

There are an increasing number of domains in which artificial intelligence (AI) systems both surpass human ability and accurately model human behavior. This introduces the possibility of algorithmically-informed teaching in these domains through more relatable AI partners and deeper insights into human decision-making. Critical to achieving this goal, however, is coherently modeling human behavior at various skill levels. Chess is an ideal model system for conducting research into this kind of human-AI alignment, with its rich history as a pivotal testbed for AI research, mature superhuman AI systems like AlphaZero, and precise measurements of skill via chess rating systems. Previous work in modeling human decision-making in chess uses completely independent models to capture human style at different skill levels, meaning they lack coherence in their ability to adapt to the full spectrum of human improvement and are ultimately limited in their effectiveness as AI partners and teaching tools. In this work, we propose a unified modeling approach for human-AI alignment in chess that coherently captures human style across different skill levels and directly captures how people improve. Recognizing the complex, non-linear nature of human learning, we introduce a _skill-aware attention mechanism_ to dynamically integrate players' strengths with encoded chess positions, enabling our model to be sensitive to evolving player skill. Our experimental results demonstrate that this unified framework significantly enhances the alignment between AI and human players across a diverse range of expertise levels, paving the way for deeper insights into human decision-making and AI-guided teaching tools. Our implementation is available here.

## 1 Introduction

There are an increasing number of domains in which artificial intelligence (AI) systems both surpass human ability and accurately model human behavior. This combination of machine mastery over a domain and computational understanding of human behavior in it introduces the possibility of algorithmically-informed teaching and learning. AI-powered aids could guide people along reliable and efficient improvement paths, synthesized from their knowledge of both human trajectories andobjective performance. Reliable AI partners, on the other hand, could learn to act alongside human counterparts in synergistic and complementary ways.

Researchers have begun to tackle this challenge in the model system of chess. Once held to be an ideal testbed for developing artificial intelligence, it is now the perfect domain to pursue human-AI alignment. The AI community finally surpassed all human ability in chess approximately 20 years ago, a milestone achievement and watershed cultural moment. Now, superhuman AI chess engines are ubiquitous and widely used. Despite this transformation, chess has never been more popular, becoming a mainstream activity in many countries during the last few years. There is now both unprecedented demand for chess education, as well as mature superhuman AI that could in principle help meet it.

However, existing models fall short of being effective learning tools and relatable partners. Traditional chess engines such as Stockfish and AlphaZero are unimaginably strong, but they don't play in ways that humans can easily understand or learn from. Comparing one's own decisions with those of traditional engines, it is easy to see how near-perfect AI would have improved upon your play but hard to see how you could realistically do the same. Recent work has resulted in the development of Maia, a suite of models that aim to mimic human behavior in chess at various skill levels by learning to predict actual human moves from a wealth of online gameplay data . While substantially more human-like, these models still cannot power effective algorithmic teaching tools because of several limitations.

First and foremost, Maia models players at different skill levels completely independently; games by players at one skill level and those by an adjacent skill level are fed into separate instances of the same architecture and result in separate models. This has the downside that predictions from one model are independently made of predictions from any other. Viewed as a whole, they are volatile: the Maia models might predict that at one level players will approach a position correctly, then at the next level they will make a horrible mistake, then at the next level they will do fine again, and so on. In a word, they fail to _cohere_. People don't improve along volatile paths, they steadily get better. The unrealistically incoherent predictions made by separate models don't suggest realistic pathways that people can take in order to get better. In order to serve as algorithmic teachers or learning aids, our models of human behavior must be coherent.

Building a coherent model of human skill in chess is difficult, because the breadth of skill in chess is almost incomprehensibly large. Decisions made by beginners bear only the faintest of relations to those made by masters. A difference of 200 points in chess rating systems roughly equates to a 75% win rate for the higher-rated player--typically higher than the best record of any team in the entire National Basketball Association. On the online chess platform we study, there are players who are 2600 rating points apart--or 13 successive steps of 75%-vs.-25% dominance apart from each other. Capturing this breadth of skill in a single model, in a coherent, smooth fashion, is a challenge.

We contribute a unified modeling approach for human-AI alignment in chess that coherently captures human style across different skill levels and directly captures how people improve. Since our model builds directly on original Maia, we call it _Maia_-2. Maia-2 consists of a standard residual network tower that processes chess positions into features, and our novel contribution of a _skill-aware attention module_ with channel-wise patching. This innovation takes the position representation outputted by the residual network tower and simple player skill encodings and learns how player skill levels interact with chess positions to produce the moves humans make. Unlike previous models, Maia-2 only requires the current board position as input (as opposed to six), which dramatically reduces training time and increases flexibility (e.g. for applying the model in non-game contexts where there may be no 6-board history). In addition to policy and value heads like in previous work, we also add an additional auxiliary information head that helps the model learn a deeper understanding of human chess moves.

We evaluate Maia-2 along two key dimensions: move prediction _accuracy_ and _coherence_. Testing it against the original Maia models, Stockfish, and AlphaZero, Maia-2 emerges as the most accurate human move predictor by far, surpassing original Maia by almost 2 full percentage points. Analyzing move prediction accuracy by skill level, Maia-2 matches and surpasses all other models on all skill levels. Furthermore, Maia-2's gains in perplexity are similarly striking, reducing average perplexity from a previous record of 4.67 bits down to 4.07 bits. Maia-2 achieves these accuracy gains while being substantially more coherent than the original Maia models. For example, call a model's treatment of a position _monotonic_ if it assigns a monotonically increasing probability to the correct move as we increase skill. While original Maia treats 1% of a random sample of positions monotonically, Maia-2 treats a remarkable 27% of the same positions monotonically. This is in keeping with our intuitive understanding of how chess players steadily and smoothly improve across the skill range. Finally, we conduct an investigation of the human chess concepts Maia-2 learns and varies with skill via linear probes, and find that skill-dependent concepts like overall board evaluation indeed vary with skill, but skill-independent concepts do not, which also accords with our understanding of how human players make decisions.

## 2 Related Work

**Chess and AI.** This paper draws on the long history of chess at the forefront of AI research [2; 3; 4; 5]. We engage with 3 distinct approaches to building chess AI: heuristic , learned , and textual . _Heuristic search:_ The original approach to computer chess was heuristics-based [4; 9]. This method was famously used by IBM's Deep Blue to defeat Garry Kasparov  and is currently used by Stockfish , one of the strongest chess engines in the world. _Learned search:_ Alpha(Zero) Go [7; 10] is a set of neural networks that learn to play Go with methods that generalized to other games, including chess, with AlphaZero . Chess AI with learned search is also extended to multi-agent systems , where diverse AI systems can outperform a single AI in challenging tasks such as chess. _Chess as text:_ Large language models [12; 13; 14] have recently been found to perform well on tasks where the models were not _explicitly_ trained on , including playing chess without fine-tuning [16; 17; 18]. This has lead to chess knowledge being one of the tested features in BIGBench , a popular LLM evaluation suite. Additionally, fine-tuning a language model can lead to systems that not only play chess, but can also generate comments, describe positions, and create other simple analyses of a game [20; 21; 8].

**Human-AI Alignment in Chess.** Building a chess engine that can defeat any human has been a solved problem for over 20 years. This has led to a new research agenda in extracting useful knowledge from these superhuman systems. A direct way of doing this is to probe an AI chess engine in a human representation space. Without any prior human knowledge or guidance, evidence of human chess concepts learned by AlphaZero is found and measured by linear probes . Going further, AlphaZero also encodes knowledge that extends beyond existing human knowledge but is ultimately learnable by humans .Another direction was the creation of a 'behavioral stylometry' model that can identify chess players from the moves they play . An alternative approach to creating systems that can act as guides to humans is demonstrated by Maia [1; 25], in which a model is trained to predict the next move a human will play, instead of optimizing for winning the game. In addition to predicting human actions the models have been fine-tuned to predict a given player's actions . The prediction accuracy can be improved via a reinforcement learning-style search .

## 3 Methodology

We propose a unified model architecture to capture human decision-making in chess across a broad spectrum of skill levels. Since this model builds upon the previous Maia move-matching models, we call it _Maia-2_. As shown in Figure 1, Maia-2 first encodes active and opponent skill levels and the chess positions, respectively. Then the encoded skill levels and positions are fused using our skill-aware attention with channel-wise patching architecture. The fused representations are then used for move prediction (policy head), auxiliary information prediction (auxiliary head), and game outcome prediction (value head). We now discuss each of these components in detail.

### Skill Level Encoder

Instead of directly incorporating player ratings as numerical inputs, we use categorical skill level embeddings for two reasons. First, player behavior and decision-making in chess are not linearly related to their rating. Categorical embeddings allow for capturing complex, non-linear relationships between player strength and their moves. They can encode nuanced differences in play style and strategy that are not directly proportional to player ratings. Second, Generalization across similar skill levels: Players within a certain skill level may exhibit similar playing styles, strategies, and common mistakes. Categorical embeddings group players into these ranges, helping the model to better generalize across players with similar strengths, as opposed to treating each rating as a numerical input.

Let \(^{|| d_{s}}\) be the matrix of player rating embeddings, where each row corresponds to the embedding of a skill level with dimension \(d_{s}\): \(=[_{(0,1000]},_{(1000,1100]},...,_{(200 0,+)}]^{}\). Given the skill levels \(a\) and \(o\) of an active player (i.e. the player to move) and the opponent player, we look up the embedding matrix \(\) by rows to map the skill levels to active and opponent skill embeddings: \(_{a}=[a],_{o}=[o]\).

Note that previous work [1; 26] uses completely independent models for human-AI alignment at different skill levels--e.g. decisions by 1100-rated chess players are encoded in one model and decisions by 1500-rated players are encoded in a separate model. Further, these models ignore opponent skill level, meaning that predictions cannot vary as a function of opponent strength. However, the active player's decisions may be significantly affected by the opponent's skill level in certain types of situations, or even in general. Players may adjust their strategy based on their perception of the opponent's skill, e.g. a higher-skill opponent might prompt more (or less) cautious play, while against a lower-skill opponent a player may pursue more aggressive tactics. Thus, the interaction between the skill levels of both players is an important component of matching human moves. Unlike existing models that ignore opponent skill level (and actually only consider games in which both players are at the same skill level), we explicitly model not only opponent skill but also the complex interplay between the two players' skill levels, and how it affects human decision-making.

### Position Encoder

**Position representation.** We use a well-established method [10; 1] to represent each chess position as a multi-channel tensor \(P_{}^{C_{} 8 8}\), which includes channels for each type of chess piece, which color is to move, and states of the position that are not derivable from the position alone (castling rights and en passant), where \(C_{}\) denotes the number of channels. One important departure from previous work is that we only use the current chess position, and not the last few chess positions that occurred in the game (models have typically incorporated the six most recent positions in the game). Many games with perfect information, including chess, can be modeled as alternating Markov games [27; 7], where future states are independent of past states given the current game state. Therefore, the current chess position theoretically encapsulates all the information necessary to make future decisions. Although human decision-making in chess may sometimes subtly depend on the historical lead-up to the current position, these effects are anecdotally small. In exchange, we gain two large practical benefits. First, modeling AI-human move matching in a Markovian way vastly improves training _efficiency_ by reducing the computational load via significantly smaller data usage for each decision. Second, it also enhances _flexibility_, enabling our resulting model to make predictions even without historical data, which is particularly advantageous in situations where only the current position is available, like chess training puzzles or any position that didn't necessarily occur in a full game.

**Position encoding.** To process the position representation \(P_{}\), we encode \(P_{}\) with the well-established ResNet-based  backbone architecture for chess position modeling with \(K_{}\) sequentially connected blocks : \(P_{}=_{ K_{}}(P_{}) ^{C_{} 8 8}\), where \(P_{}\) denotes the encoded position representation of \(C_{}\) channels. More details about position representation and the backbone architecture can be found in Appendix Section B.

Figure 1: Overview of the Maia-2 model architecture.

### Bridging Skill Levels and Positions

A central challenge we face is learning how players at different skill levels interact with chess positions differently. How does an expert player evaluate and process a chess position to come up with a move, and how does this differ from a novice? The relationship between positions and skill levels is complicated by the non-linearity in how players of various skill levels interpret and react to chess positions. This complexity presents a significant challenge in human move prediction using a unified model for diverse skill levels. To bridge skill levels and positions--decision-makers and decisions--we propose _skill-aware attention with channel-wise patching_.

**Channel-wise patching.** In contrast to the area-wise patching approach in Vision Transformers (ViTs) , we employ channel-wise patching. Each channel is flattened and linearly transformed, regarding the number of channels in \(P_{}\), i.e., \(C_{}\), as the sequence length: \(P_{}=(P_{})^{C_{} 64}\), \(P=P_{}+^{C_{} d _{}}\), where \(^{64 d_{}}\) and \(^{d_{}}\) denote the parameters of the linear projection from the patching dimension to the hidden dimension of the skill-aware attention blocks \(d_{}\). This is particularly suitable for patching encoded chess positions as inputs to Transformer-like architectures, where channels are essentially feature maps that represent different learned latent concepts. These concepts in feature maps are then interactively selected and aggregated considering skill levels via skill-aware attention.

**Skill-aware Attention.** Given position representations \(P_{}\) and skill level representations \(_{a}\) and \(_{o}\), our proposed skill-aware multi-head self-attention is computed as follows. For each head \(k\), we learn weight matrices \(_{k}^{Q}^{d_{} d_{h}}\), \(_{k}^{K}^{d_{} d_{h}}\), and \(_{k}^{V}^{d_{} d_{h}}\), where \(d_{h}\) denote the dimension of each head. The queries \(Q_{k}\), keys \(K_{k}\), and values \(V_{k}\) for each head are computed as: \(Q_{k}=P_{}_{k}^{Q}\), \(K_{k}=P_{}_{k}^{K}\), \(V_{k}=P_{}_{k}^{V}\). In order to fuse player skill levels and chess positions progressively and interactively set the input skill level embeddings into queries within the multi-head self-attention: \(Q_{k}^{*}=Q_{k}+(_{a}_{o})^{*}\), where \(^{*}^{2d_{s} d_{h}}\) denotes the weight matrix for feature transformation to the query space, and \(\) is the concatenation operator. We choose to incorporate skill levels in queries because queries directly influence how attention is distributed across patched channels. Using skill-aware queries \(Q_{k}^{*}\), the attention mechanism can adjust its focus to reflect the strategic considerations and positional understanding of players at different skill levels. This adjustment allows Maia-2 to adaptively prioritize features of the positions that are more relevant to the skill levels involved, enhancing the model's contextual sensitivity. The skill-aware scaled dot-product attention for each head is thus defined as: \(h_{k}=(^{*}K_{k}^{*}}{}})V_{k}\). The outputs of all heads \(h_{1},h_{2},,h_{h}\) are concatenated and then linearly transformed: \(P_{}=((h_{1} h_{2} h_{h})^{O})\), where \(^{O}^{hd_{h} d_{}}\) denote the weight matrix for multi-head attention and \(()\) denotes the activation function. We apply the vanilla ViT's feed-forward network and add & norm components upon \(P_{}\) to obtain the output of each skill-aware attention block \(P_{}\). In Maia-2, we employ a sequence of skill-aware attention blocks to progressively fuse skill levels and positions. Specifically, the output \(P_{}\) for the previous block is fed into the next block as the input. We denote the final output after \(K_{}\) blocks as \(P\). This procedure enables the model to refine its understanding and interpretation of the positions with each successive block.

### Model Training

**Infusing auxiliary information.** To enhance the model's understanding of the game state, we inject auxiliary information as labels, including _legal moves_ represented by multi-hot vectors and _human move information_: one-hot vectors of which piece is moved, which piece is captured (if any), the move's originating square, the move's destination square, and whether or not the move will deliver a check. These segments are used as labels for classification, serving a dual purpose: 1) It offers a more granular understanding of human moves by providing detailed context beyond just the move indices produced by the policy head labels, enriching the model's insight of player decisions; and 2) It ensures the model also learns about objective (i.e. chess-specific as opposed to behavioral) knowledge in chess, which is essential for developing a comprehensive understanding of both human moves and the fundamental mechanics of the game.

**Data balancing and filtering.** Chess games between players of significantly different skill levels are relatively rare but help us understand how players of lower skill levels approach games against far stronger opponents and vice versa. While previous work has ignored these games completely, they play a central role in our approach. Since games between players of similar skill levels vastly outnumber more uneven matchups, we use a data balancing strategy to effectively train our unified model for aligning players across all skill levels, in which games between players of different skill levels are over-sampled. Online chess platforms feature a variety of game types, including blitz, rapid, and classical, each representing games played at different time controls (amount of time given to each player for the whole game). We focus on Rapid games, which are medium-length games that lie between the fast-paced decisions of "Blitz" games and the slower, more strategic considerations of "Classical" games. In addition, we follow the procedures in  to filter valid positions within each game. More details about data balancing and filtering are available in Appendix B.

**Training objectives.** With the fused skill level and position representation \(P\) as input, we construct the policy head on top to predict human moves, which is optimized using cross-entropy loss with one-hot labels representing the recorded human move. We also build the auxiliary information head to infuse additional knowledge into Maia-2 as introduced in Section 3.4. This head is trained using bit-wise binary cross-entropy loss with multi-hot labels. Finally, following previous work  we include a value head to predict the game outcome as a regression task, where the labels 1, 0, -1 denote winning, drawing, and losing, respectively. The training objectives of these heads are balanced to contribute equally to Maia-2 model optimization. Hyperparameter settings used for Maia-2 training can be found in Appendix Table 5.

## 4 Results

We empirically evaluate Maia-2 along two key dimensions: move prediction _accuracy_, how well it can predict human moves at varying skill levels, and move prediction _coherence_, how aligned its predictions are across skill levels. We train Maia-2 on Lichess games played between Jan 2013 and Nov 2023, with the exception of December 2019, since that is the month used for testing in the original Maia paper (and we also test on this month for consistency) . After game filtering and balancing, we end up with a training set of 169M games (9.1B positions). We also train Maia-2\({}_{}\) with identical model architecture and training configurations as Maia-2, except it only has access to the same training data that Maia had for fair comparisons. Dataset statistics are reported in Appendix Tables 7, 9, and 10. We compare Maia-2 with Stockfish , the strongest chess engine, Leela, an open-source counterpart to AlphaZero . and Maia , the state-of-the-art model for human-like chess play. Maia is actually a set of 9 separate models, each trained on a different set of players at different skill levels from 1100 to 1900. We use the benchmarking _Maia Testset_ for performance comparisons where both players have identical skill levels. We report the results on _Maia Testset_ by grouping players into three categories: _Skilled_ (Rapid rating up to 1600, which slightly exceeds the initial rating of 1500), _Advanced_ (Rapid rating between 1600 and 2000), and _Master_ (Rapid rating over 2000). In addition, we aim to evaluate move prediction across diverse skill combinations with the _Cross-skill Testset_ constructed from Dec 2023 games. Finally, we construct _Grounded Testset_ with 450,000 positions that has recorded Stockfish evaluations, which can serve as grounded facts to measure move quality. Statistics of datasets are summarized in Appendix Table 8.

    &  &  &  &  \\    & 3 & 9 & 15 & 1500 & 2200 & 3200 & 1100 & 1500 & 1900 & \\  Skilled & 36.22 & 36.00 & 36.86 & 40.46 & 39.79 & 39.97 & 51.48 & 50.79 & 48.51 & 51.51 & **51.72** \\ Advanced & 38.25 & 38.78 & 39.83 & 44.45 & 43.97 & 44.29 & 49.13 & 52.61 & 52.26 & 53.54 & **54.15** \\ Master & 40.71 & 43.26 & 44.61 & 48.69 & 47.11 & 47.75 & 45.85 & 50.76 & 53.20 & 53.16 & **53.87** \\ Avg & 38.39 & 39.35 & 40.43 & 44.53 & 43.62 & 44.00 & 48.82 & 51.39 & 51.32 & 52.74 & **53.25** \\   

Table 1: Move prediction accuracy on the _Maia-2 Testset. Skilled_, _Advanced_, and _Master_ are grouped according to Section 4 and _Avg_ denotes macro-averaged results.

### Move Prediction Accuracy

**Maia-2.** In Table 1, we show the top-1 move prediction accuracy of all models across all groups of players on the _Maia-1 Testset_. Maia-2 demonstrates strong and consistent performance across all skill levels, surpassing all baselines. Specifically, despite Maia-1 models being specifically trained to mimic chess moves by players at specific skill levels, Maia-2 emerges as a unified one-for-all model that is consistently effective across the entire spectrum of chess skills. The largest improvement is on _Advanced_ players, where Maia-2 gains 1.5 percentage points over the nearest competitor (Maia 1500). When averaging across skill levels, Maia-2 outperforms all other models by almost 2 full percentage points in overall accuracy. Note that the ceiling accuracy of human move prediction is far below 100% given the randomness and diversity of human decisions--even the _same_ player won't always make the same decision when faced with the same position. Our 2 percentage point gain is substantial considering that the difference between Maia-1 and Leela, the previous state-of-the-art model for this task and a traditional chess engine not trained for this task at all, is only 6 percentage points. Furthermore, Maia-1 is essentially a mixture of 9 experts targeting the specific players' skill level, where each expert has 10.3M parameters. Regarding the routing function to select the best-performing expert as a nonparameterized function, Maia-1 has 92M parameters in total. Maia-2, on the other hand, is a one-for-all model with 23.3M parameters under our default settings. Therefore, Maia-2 achieves better human move prediction accuracy with even much fewer trainable parameters.

**Baseline models.** Both Maia-2 and Maia-1 significantly outperform Stockfish and Leela, typically by 5-15 percentage points. Note that Stockfish and Leela aim to play optimal chess (as most humans do too), and only "predict" human moves when their approximations to optimality happen to overlap with those of human players. However, we compare to these traditional chess engines because besides Maia-1, there are still the default method of creating "human-like" AI agents. The accuracy gap between Maia-1 architectures and traditional chess engines demonstrates the necessity of developing specialized models to mimic human chess moves.

**Maia-2\({}_{}\).** Maia-2 differs from Maia-1 in two main ways: it has a different architecture and it has access to more training data. To control for the difference in training data and isolate the effects of our architecture, we create Maia-2\({}_{}\) which has access to the exact same training data that Maia-1 was developed with. Comparing the two, we see that Maia-2\({}_{}\) matches or outperforms all baselines and alternate models. Recall that Maia-2 and Maia-2\({}_{}\) don't have the recent history passed as input to them, yet still achieve state-of-the-art results. It is important to note that each Maia-1 model is specifically trained for its respective skill level, relying solely on games where the active and opponent skill levels match for its training data. On the contrary, the unified modeling approach with skill-aware attention of Maia-2\({}_{}\) allows it to utilize a broader spectrum of games, featuring a variety of skill-level pairings, for training purposes. Consequently, while both Maia-1 and Maia-2\({}_{}\) draw from the same source dataset, Maia-2\({}_{}\) can leverage a significantly larger portion of this data for its training, improving its learning and predictive capabilities. The improvement from Maia-2\({}_{}\) to Maia-2 underscores the importance of extensive training with vast datasets. A broader range of games provides Maia-2 with access to more comprehensive and nuanced patterns in human chess moves. Using Maia-2\({}_{}\) as a comparison, we can determine the relative contributions of model architecture and training data to Maia-2's 1.9 percentage point gap over its nearest rival (Maia 1500). This calculation suggests that 73% of the increase in performance is due to the architecture improvements and 27% is due to increased training data.

Figure 2: Move prediction accuracy across diverse skill levels. Colors represent performance, with warmer tones indicating higher accuracy.

[MISSING_PAGE_FAIL:8]

models players at different skill levels independently from each other, which results in particularly volatile predictions: the same position might elicit very different predicted behavior from models of adjacent skill levels. This is problematic because we know from personal experience that this type of volatility is rare: players don't change that much as they improve. This limits Maia's ability to perform well in downstream tasks such as serving as a teaching aid, as its understanding of one skill level bears little resemblance to its understanding of the next. In reality, players move from one skill level to another by making small, consistent adjustments. Does Maia-2 reflect this behavioral coherence?

**Prediction smoothness.** We measure the coherence of Maia-2's predictions by testing for smoothness features in its entire set of predictions. Call a model's treatment of a position _monotonic_ if the predicted probability of the correct move increases with skill monotonically. In the _Grounded Testset_ of 100K positions, we find that Maia-1 only treats 1% of them monotonically. In stark contrast, however, Maia-2 treats 27% of them monotonically, clearly demonstrating that Maia-2 is much more coherent. Similarly, call a model's treatment of a position _transitional_ if it predicts a suboptimal move for some prefix of skills and then transitions to an optimal move for all subsequent skill levels. Again, Maia-2 treats substantially more positions transitionally--around 22% of them compared with 17% for Maia.

It's important to note that Maia-2 is deliberately designed to encourage coherence across skill levels without rigidly enforcing it. Our objective is not to impose coherence as a hard constraint, which might obscure legitimate differences in player behavior between skill levels, but to create a model architecture that naturally encourages coherence where the data supports it.

**Move prediction agreement.** As a first test, we measure move prediction coherence as we vary active player skill and opponent player skill in Maia-2. The results shown in Figure 3.(B) reveal several trends. First, increasingly varying either the active or opponent rating results in lower agreement, suggesting that Maia-2 smoothly varies its predictions with skill. Second, comparing the two heatmaps reveals that Maia-2 has clearly learned that varying one's own skill has much larger effects than varying the opponent's--changing one's own skill against a fixed opponent can change the decision up to 22% of the time, but changing the opponent's skill while fixing our own skill will only change the decision up to 6% of the time. This is intuitive, as players must change their decisions in order to play at a higher level, while in theory one's opponent shouldn't affect one's decision. Of course, humans are not optimal agents and sometimes take their opponent's skill level into account when deciding on a move--willfully or not--which is reflected in our results.

**Chess concept understanding.** Human chess players of varying strengths differ in their ability to recognize important features and patterns on the board, e.g., stronger players are adept at discerning

    &  &  \\   & Skilled & Advanced & Master & Skilled & Advanced & Master \\  Maia-1 & 1.61 & 1.42 & 1.14 & 13.34 & 18.14 & 20.48 \\ Maia-2 & 27.61 & 28.51 & 26.38 & 22.59 & 23.39 & 21.72 \\   

Table 4: Percentage of monotonic and transitional positions.

Figure 3: (A). (Top) Joint probability assigned to human moves played by Maia-2 (\(x\)) and Maia 1900 (\(y\)), split by move quality. Blunders (left) reduce the expected win-rate by \(\) 10%, Errors (middle) by 5–10%, and Optimal (right) by \( 0\%\). (Bottom) Log odds ratio of \(p(x,y)\) and \(p(y,x)\) from top. (B). Move prediction agreement as (left) active player and (right) opponent player skill are varied. All cells are evaluated on the same set of positions but with altered skill level configurations.

subtle nuances. We now turn our focus to a critical question: does Maia-2 vary in its ability to capture human chess concepts when given different skill levels? Following the chess concepts probing strategy for AlphaZero , we show how Maia-2's grasp of various concepts varies with skill. The left two plots in Figure 4 show concepts for which Maia-2 clearly distinguishes between skill levels, with higher-skill players paying more attention to them than lower-skill players. These are general board evaluations as given by Stockfish , or aggregate piece values. Note that pre-skill-aware attention is always flat because by construction it cannot vary with skill, since skill-aware attention has not been applied yet. The two plots on the right depict concepts that live closer to fundamental chess rules, and as such are less dependent on player skill. For skill-dependent concepts, the figures reveal an increasing trend in mastery level after skill-aware attention, aligning with the increase in dedicated skill levels. Meanwhile, the model's mastery level decreases after passing through the skill-aware attention modules, potentially adjusting for the imperfections of human players. Conversely, the skill-aware attention blocks are not responsive to skill-independent concepts.

## 5 Discussion

**Human Study.** In addition to human move matching, we also consider engagement, another dimension of human study. In particular, we implement a randomized experiment on Lichess: human players challenge our bots, and we randomize whether players play against Maia-1 or Maia-2. Our result is that our higher move-matching and our vastly improved coherence, across all skill levels, come at no cost to human subject engagement, and in fact slightly increase engagement: players rematch Maia-2 almost 1 percentage point more than Maia-1 (41.2% vs. 40.3%). Although engagement is not our main objective, this is further promising evidence that we have achieved a more human-aligned model that coherently captures human style across different skill levels.

**Ethical Considerations.** We believe Maia-2 poses limited risk while offering large potential benefits. Our data is highly aggregated, with almost 1 billion games being used for training, and chess as a domain is generally low-risk. Meanwhile, helping people improve in chess could lead to increased cognitive skills, confidence boosts, and help with general life satisfaction. Our vision is for Maia-2 to power AI partners and training aids; it cannot currently replace skilled human tutors and coaches.

**Limitation.** Our work has limitations. First, we are excited by the applications that Maia-2 will enable, such as more relatable AI partners and AI-powered learning aids, the development of which is out of scope for the current work. Maia-2 does not yet incorporate search, although previous work has demonstrated that with proper regularization it can help improve move prediction performance . Relatedly, we group the strongest players in a single bucket, although modeling the very best players in the world remains difficult due to the complexity and depth of their moves.

Figure 4: Maia-2’s chess concept recognition as a function of skill level, as measured by linear activation probes right before (blue) and after (orange) skill-aware attention. (a) Stockfish overall board evaluation for middle-game positions. (b) Stockfish evaluation of middle-game bonuses and penalties to pieces for white. (c) Does the active player own two bishops? (d) Can the active player capture the opponent’s queen?