# Boosting Transferability and Discriminability for

Time Series Domain Adaptation

 Mingyang Liu1, Xinyang Chen12, Yang Shu22, Xiucheng Li12, Weili Guan3, Liqiang Nie1

1School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen)
2School of Data Science and Engineering, East China Normal University
3School of Electronics and Information Engineering, Harbin Institute of Technology (Shenzhen)

mingyangliu1024@gmail.com, yshu@daase.ecnu.edu.cn

{chenxinyang,lixiucheng,guanweili,nieliqiang}@hit.edu.cn

###### Abstract

Unsupervised domain adaptation excels in transferring knowledge from a labeled source domain to an unlabeled target domain, playing a critical role in time series applications. Existing time series domain adaptation methods either ignore frequency features or treat temporal and frequency features equally, which makes it challenging to fully exploit the advantages of both types of features. In this paper, we delve into transferability and discriminability, two crucial properties in transferable representation learning. It's insightful to note that frequency features are more discriminative within a specific domain, while temporal features show better transferability across domains. Based on the findings, we propose **A**dversarial **CO**-learning **N**etworks (**ACON**), to enhance transferable representation learning through a collaborative learning manner in three aspects: (1) Considering the multi-periodicity in time series, multi-period frequency feature learning is proposed to enhance the discriminability of frequency features; (2) Temporal-frequency domain mutual learning is proposed to enhance the discriminability of temporal features in the source domain and improve the transferability of frequency features in the target domain; (3) Domain adversarial learning is conducted in the correlation subspaces of temporal-frequency features instead of original feature spaces to further enhance the transferability of both features. Extensive experiments conducted on a wide range of time series datasets and five common applications demonstrate the state-of-the-art performance of ACON. Code is available at https://github.com/mingyangliu1024/ACON.

## 1 Introduction

Time series classification has achieved significant success in the deep learning era by leveraging discriminative features learned from extensive labeled data . However, the presence of distribution shift may arise when deploying the model, potentially impeding the generalization ability of deep models . Unsupervised domain adaptation , offering the potential to transfer knowledge from a labeled source domain to an unlabeled target domain, emerges as a promising solution.

Existing domain adaptation methods tailored for time series primarily focus on learning domain-invariant temporal features , yielding promising results. Recently, the significance of frequency features for enhancing domain-invariant representation has also been recognized . However, frequency features and temporal features are treated equally, and their distinct properties are overlooked, leading to the inability to fully leverage both types of features to boost transfer learning.

In this paper, we analyze the two most important properties of features in transfer learning: transferability and discriminability, to investigate the characteristics of the frequency features and temporalfeatures. We find that under the premise of adopting advanced backbones in state-of-the-art works [31; 16], frequency features are more discriminative within a specific domain, while temporal features show better transferability across domains.

Based on the findings, we propose **A**dversarial **CO**-learning **N**etworks (**ACON**) to maximize the potential of temporal features and frequency features in terms of both transferability and discriminability in a collaborative learning manner. Firstly, to fully leverage the properties of multi-periodicity in time series, we propose multi-period frequency feature learning to further enhance the discriminability of frequency features. Secondly, we propose temporal-frequency domain mutual learning to enhance the discriminability of temporal features in the source domain and improve the transferability of frequency features in the target domain. Specifically, to harness the potent discriminability of frequency features within the domain, we enable the transfer of knowledge from frequency features to temporal features within the source domain via knowledge distillation. To leverage the strong transferability of temporal features across domains, we facilitate the transfer of knowledge from temporal features to frequency features in the target domain through knowledge distillation. Thirdly, we propose to learn transferable representations via domain adversarial learning in temporal-frequency correlation subspace instead of the original temporal feature space. The temporal-frequency correlation subspace not only possesses the properties of the original temporal feature space and original frequency feature space but also incorporates the correlation between the two types of features. Learning transferable representations in the temporal-frequency correlation subspace can further enhance the transferability of features. Our main contributions can be summarized as follows:

* We uncover the characteristics wherein temporal features and frequency features cannot be equally treated in transfer learning. Specifically, we observe that frequency features are more discriminative within a specific domain, while temporal features show better transferability across domains through empirical findings.
* We design ACON, which enhances UDA in three key aspects: a multi-period feature learning module to enhance the discriminability of frequency features, a temporal-frequency domain mutual learning module to enhance the discriminability of temporal features in the source domain and improve the transferability of frequency features in the target domain, and a domain adversarial learning module in temporal-frequency correlation subspace to further enhance transferability of features.
* Experiments conducted on a wide range of time series datasets and five common applications verify the effectiveness of ACON.

## 2 Related Work

General Unsupervised Domain Adaptation MethodsUnsupervised domain adaptation leverages the labeled source domain to predict the labels of a different but related, unlabeled target domain. It finds wide applications in computer vision [46; 15; 8] and natural language processing [40; 39; 44]. Existing UDA methods can be classified into three categories: (1) Methods based on adversarial training aim to learn domain-invariant representations via the game between the feature extractor and the domain discriminator. Widely used methods include DANN , CDAN  and DIRT-T . (2) Methods based on statistical divergence aim to reduce the domain discrepancy by minimizing domain discrepancy in a latent feature space. Widely used methods include DAN , DeepCoral  and HoMM . (3) Methods based on self-training produce pseudo-labels on unlabeled data and use confident pseudo-labels together with the labeled data to train the model. Widely used methods include PFAN, CST  and AdaMatch . However, these methods are generally designed and do not fully leverage the properties of time series. Although these methods can be applied to time series through tailored feature extractors, they often obtain suboptimal performance and UDA algorithm specially designed for time series is needed.

Unsupervised Domain Adaptation for Time SeriesTo date, a few methods have been tailored to unsupervised domain adaptation for time series data. VRADA  is the first UDA method for multivariate time series that uses adversarial learning for reducing domain discrepancy. In VRADA, a variational recurrent neural network (VRNN)  is trained in an adversarial way to learn domain-invariant temporal features. CoDATS  builds upon VRADA but uses a convolutional neural network for the feature extractor, proposing a solution for multi-source domain adaptation in time series classification. SASA  adopts LSTM  as feature extractors to capture the domain-invariant association, and aligns sparse associative structure between source and target domain via the minimization of maximum mean discrepancy (MMD) . AdvSKM  modifies MMD to make it more suitable for time series data. CLUDA  learns contextual representation via contrastive learning, and aligns features between source and target domain via adversarial training. RAINCOAT  is the first to introduce frequency features into domain adaptation, aligning temporal features and frequency features respectively via Sinkhorn divergence.

Research gapIn general, in terms of representation learning, most methods only focus on the temporal domain or assume that the temporal domain and the frequency domain are independent of each other, hindering the full utilization of two types of features. In terms of feature adaptation, existing works only focus on aligning temporal features or adopting simple statistical divergence to align frequency features, ignoring the different properties of the temporal features and frequency features in transfer learning. In terms of evaluation, the existing evaluations are conducted on several datasets of limited scale in a few specific tasks, and more general evaluations are needed.

## 3 Transferability and Discriminability in Time Series

### Problem setup

In this paper, we study the UDA problem for time series classification. In time series classification problem, the model receives a set of \(n\) labeled samples \(\{(_{i},_{i})\}_{i=1}^{n}\), where \(i\)-th sample \(_{i}^{C T}\) contains observation of \(C\) variates over \(T\) time steps. We allow for both univariate and multivariate time series. In UDA setup, we are given \(n_{s}\) labeled samples from a source domain \(=\{(_{i}^{s},_{i}^{s})\}_{i=1}^{n_{s}}\) and \(n_{t}\) unlabeled samples from a target domain \(=\{(_{i}^{t})\}_{i=1}^{n_{t}}\), which are sampled from different distributions \(P\) and \(Q\). Superscripts \(s\) and \(t\) are adopted to distinguish the source domain and the target domain. UDA for time series aims to learn a time series classification model with labeled source data \(\) and unlabeled target data \(\), which can make accurate predictions on the target domain.

In addition to the source domain and target domain in UDA, time series naturally can be represented in the temporal domain and frequency domain. By Fast Fourier Transform (FFT), the raw time series input \(_{i}\) in the temporal domain can be transformed to corresponding frequency input \(_{i}\) in the frequency domain:

\[_{i}=(_{i}),\] (1)

where the complex variable \(_{i}^{C}\) contains observation of \(C\) variates over \(\) different frequencies. Due to the conjugacy of frequency domain, we only consider the frequencies within \(\{1,...,\}\).

### Discriminability of frequency feature

As Figure 1(a) presented, compared to the uniform distribution of temporal data for different classes, the frequency data for different classes shows distinct differences in the dominant frequencies and peaks, which holds more discriminative information. To further investigate the discriminability of

Figure 1: Discriminability of frequency feature: (a) The Electroencephalography (EEG) signal and corresponding frequency data of two classes in the CAP dataset: Wake and Rapid Eye Movement (REM). (b) Classification on the source domain: Temporal domain vs. Frequency domain. (c) Source-only and DANN: Temporal domain vs. Frequency domain.

frequency features, we perform the single data domain classification task in the frequency domain and temporal domain respectively on all five data domains of the CAP [37; 14] dataset.

In order to minimize the impact of specific model structures, we adopt 3-layer 1D-CNN, a generic structure as the temporal feature extractor, and 1-layer linear as the frequency feature extractor, which have both widely validated for their effectiveness in existing time series analysis methods [42; 43; 16; 43]. We only retain the low-frequency data to ensure that the temporal feature extractor and the frequency feature extractor have comparable parameter quantities. For the classifiers, we uniformly use 1-layer linear. As Figure 1(b) shown, with a simple feature extractor, the frequency classification outperforms the temporal classification, demonstrating that the frequency features have better discriminability. More analysis results on different datasets are included in Appendix C.1.

### Transferability of temporal feature

Another key criterion that characterizes the performance of domain adaptation is transferability . Transferability indicates the ability to learn invariant features across domains. Since the frequency features have better discriminability within the source domain, it is natural to raise the question: _Will the frequency features also have better discriminability in the target domain?_

We investigate this problem starting with the comparison of four methods: (1) Source-only-F, a model trained in the frequency domain without UDA. (2) Source-only-T, a model trained in the temporal domain without UDA. (3) DANN-F, a model aligning the source features and the target features in the frequency domain via DANN. (4) DANN-T. a model aligning the source features and the target features in the temporal domain via DANN. Figure 1(c) shows the accuracy in the target domains of four source-target domain pairs from the CAP dataset. Compared with Figure 1(b), the frequency classification, which has better discriminability performance in the source domain, actually slightly underperforms in the target domain. It indicates that better discriminability in the source domain does not necessarily imply better discriminability in the target domain. Compared with Source-only methods, the gap between DANN-F and DANN-T is further exacerbated. This suggests that the temporal feature extractor more easily learns domain-invariant features. More analysis results on different datasets are included in Appendix C.2.

The above analysis reveals two insights for time series domain adaptation: With better discriminability but worse transferability, domain adaptation in the frequency domain obtains suboptimal performance; while with better transferability, domain adaptation in the temporal domain has the potential to achieve superior performance under the guidance of more discriminative information.

## 4 Approach

Based on the above observations, our motivation is to simultaneously leverage the strong discriminability of frequency features and the strong transferability of temporal features to enhance domain adaptation. This inspires us to learn domain-invariant temporal and frequency features in a collaborative learning manner.

Figure 2 illustrates the overall structure of our **A**dversarial **CO**-learning **N**etworks (**ACON**). To avoid confusion, subscripts \(T\) and \(F\) are adopted to distinguish the temporal domain and the frequency domain. Specifically, in the temporal domain, we have a temporal feature extractor with temporal input \(=_{T}()\) and a temporal classifier \(}_{T}=g_{T}()\); while in the frequency domain, we have a frequency feature extractor with frequency input \(=_{F}()\) and a frequency classifier \(}_{F}=g_{F}()\). Additionally, we have a domain discriminator \(g_{D}\), which is trained to distinguish the source feature and the target feature. In the following, we will introduce three main contributions in ACON: multi-period frequency feature learning in Section 4.1, temporal-frequency domain mutual learning in Section 4.2, and domain adversarial learning in temporal-frequency correlation subspace in Section 4.3.

### Multi-period frequency feature learning

The real-world time series usually present multi-periodicity, which is reflected in the frequency domain as the presence of a few dominant frequencies with significantly larger amplitudes. Data from different periods can have different discriminative patterns. Based on this, before performing FFT, we segment the raw time series according to the top-k significant periods, enhancing the discriminability of the frequency domain. Additionally, by period-based segmentation, the noises brought by meaningless high frequencies are effectively filtered out [4; 45].

To capture the overall multi-periodicity, before training, we randomly sample mini-batches from the training set to perform FFT and select the frequencies with the top-k amplitudes \(\{f_{1},,f_{k}\}\). Given the frequency \(f_{j}\), the corresponding period is \(p_{j}=[}]\). For each selected period \(p_{j}\) in \(\{p_{1},,p_{k}\}\) and frequency \(f_{j}\) in the corresponding \(\{f_{1},,f_{k}\}\), we perform the following transform on input \(_{i}\):

\[_{i}^{j} =_{p_{j}}(_{i}), j\{1,,k\},\] (2) \[_{i}^{j} =((_{i}^{j})).\]

where \(_{i}^{j}^{C f_{j} p_{j}}\), \(_{i}^{j}^{C}{2}}\) is averaged from \(f_{j}\) dimensions by \(()\). In other words, we perform FFT on each segment obtained by segmenting \(_{i}\) with period \(p_{j}\), and average the FFT results across segments to obtain the distribution \(_{i}^{j}\) over the frequencies within \(\{1,,}{2}\}\). In this way, we obtain the overall frequency pattern for each period. To keep the discriminative patterns derived from different periods, we concatenate the different \(_{i}^{j}\), obtaining \(_{i}\) as the frequency input corresponding to the temporal input \(_{i}\):

\[_{i}=_{i}^{1}..._{i}^{k}, j \{1,,k\}.\] (3)

We extend the source sample set \(\) and the target sample set \(\) to the frequency domain: \(=\{(_{i}^{s},_{i}^{s},_{i}^{s})\}_{i=1}^ {n_{s}}\) and \(=\{(_{i}^{s},_{i}^{t})\}_{i=1}^{n_{t}}\). To learn features in both real part and imaginary part of complex frequency data, we adopt a complex-valued linear layer as the frequency feature extractor \(_{F}\). Since the phase generally does not provide strong discriminative information, we only retain the amplitudes of each frequency to construct the frequency domain feature \(_{i}\):

\[_{i}=(_{F}(_{i})),\] (4)

where \(()\) denotes the calculation of amplitude values. For multivariate time series, we convert \(_{i}\) into a single-channel vector by concatenating across different variates.

### Temporal-frequency domain mutual learning

Discriminability and transferability are two key criteria that characterize the goodness of feature representations to enable domain adaptation. In Section 3, we reveal that the frequency features are more discriminative within the source domain, while the temporal features are more transferable across domains. Based on this discovery, we propose temporal-frequency domain mutual learning, aiming to leverage the respective advantages of the temporal domain and frequency domain.

The essence of domain mutual learning relies on how to transfer knowledge between the temporal domain and frequency domain. Inspired by model distillation, where the knowledge is transferred by matching the predictions between the teacher and student via the Kullback Leibler (KL) divergence , we focus mutual learning on the alignment between the temporal predictions and the frequency predictions. The KL divergence between two predictions \(p_{1}\) and \(p_{2}\) is formulated as:

\[D_{KL}(p_{1}||p_{2})=_{m=1}^{C}p_{1}^{m}^{m}}{p_{2}^{m }}.\] (5)

Figure 2: The architecture of ACON. ACON models temporal data (blue) and frequency data (green) simultaneously. Left part: Segment raw frequency data by period to capture different discriminative patterns. Middle part: Align distributions in temporal-frequency correlation subspace via adversarial training. Right part: Mutual learning between the temporal domain and frequency domain.

The KL divergence is asymmetric, that is, \(D_{KL}(p_{1}||p_{2})\) emphasizes aligning \(p_{2}\) to \(p_{1}\), while \(D_{KL}(p_{2}||p_{1})\) emphasizes aligning \(p_{1}\) to \(p_{2}\). Based on the asymmetry, we use different alignment strategies in the source domain and target domain. Specifically, in the source domain, the frequency model serves as a more discriminative teacher, helping the temporal model make more accurate predictions; conversely, in the target domain, the temporal model acts as a more transferable teacher, assisting the frequency model in learning domain-invariant representations. We achieve temporal-frequency domain mutual learning by minimizing the KL Divergence. Formally, domain mutual learning is formulated as:

\[_{M_{s}}(_{T},g_{T})& =_{(_{i}^{s},_{i}^{s})}[D _{KL}(}_{F}^{s}||}_{T}^{s})],\\ _{M_{}}(_{F},g_{F})&= _{(_{i}^{t},_{i}^{t})}[D_{KL}(}_ {T}^{t}||}_{F}^{t})],\] (6)

where \(}_{F}^{s}\) and \(}_{T}^{s}\) refer to the frequency prediction and temporal prediction in the source domain respectively; while \(}_{F}^{t}\) and \(}_{T}^{t}\) refer to the frequency prediction and temporal prediction in the target domain respectively. By aligning \(}_{T}^{s}\) to \(}_{F}^{s}\), the training of the temporal feature extractor and classifier is guided with more discriminative information; by aligning \(}_{F}^{t}\) to \(}_{T}^{t}\), the transferable knowledge contained in the temporal features is transferred to frequency domain.

### Domain adversarial learning in temporal-frequency correlation subspace

Domain adversarial learning  is one of the most popular transferable representation learning methods, and it can be employed to learn transferable representation in time series. The key to the effectiveness of the method lies in how to fully utilize two types of features to learn transferable representations. Given time series in temporal domain and frequency domain, domain adversarial learning can be formulated as a minimax optimization problem with three competitive loss terms: (a) \(_{C_{T}}\) on the temporal feature extractor \(_{T}\) and classifier \(g_{T}\), which is minimized to guarantee lower source risk of the temporal classifier; (b) \(_{C_{F}}\) on the frequency feature extractor \(_{F}\) and classifier \(g_{F}\), which is minimized to guarantee lower source risk of the frequency classifier; (c) \(_{D}\) on the temporal feature extractor \(_{T}\), the frequency feature extractor \(_{F}\) and the domain discriminator \(g_{D}\), which is minimized over \(g_{D}\) but maximized over \(_{T}\) and \(_{F}\):

\[_{C_{T}}(_{F},g_{T})& =_{(_{i}^{s},_{i}^{s})}[ (g_{T}(_{T}(_{i}^{s})),_{i}^{s})],\\ _{C_{F}}(_{F},g_{F})&=_{( _{i}^{s},_{i}^{s})}[(g_{F}( _{i}(_{i}^{s})),_{i}^{s})],\\ _{D}(_{T},_{F},g_{D})&=-_{(_{i}^{t},_{i}^{t})}[g_{D}( _{T}(_{i}^{s}),_{F}(_{i}^{s} ))]\\ &-_{(_{i}^{t},_{i}^{t}) }[1-g_{D}(_{T}(_{i}^{t}),_{F} (_{i}^{t}))],\] (7)

where \(\) denotes cross-entropy loss. Different from standard domain adversarial learning, where there is only one type of feature, domain adversarial learning in time series needs to consider the temporal features and frequency features simultaneously. A simple strategy is to concatenate the temporal feature \(\) and the frequency feature \(\). However, with the concatenation strategy, the adversarial game between the domain discriminator and the feature extractors can be viewed as two independent components: the game between \(g_{D}\) and \(_{T}\) and the game between \(g_{D}\) and \(_{F}\). With the worse transferability, \(\) provides \(g_{D}\) with rich domain-label relevant information. In this case, \(g_{D}\) only needs to focus on the game with \(_{F}\), ignoring the domain adversarial learning in the temporal domain.

To achieve co-alignment in the temporal domain and frequency domain, we propose domain adversarial learning in temporal-frequency correlation subspace. The temporal-frequency correlation subspace not only possesses statistical characteristics of the original temporal feature subspace and original frequency feature subspace but also reflects the correlation between temporal features and frequency features. Reducing the discrepancy of the temporal-frequency correlation subspace not only reduces the discrepancy in the cross-domain temporal and frequency features but also decreases the differences in cross-domain temporal-frequency correlations.

Formally, the vectors in temporal-frequency correlation subspace can be calculated as the outer product \(\) between the temporal feature \(\) and the frequency feature \(\):

\[=[[1],\; [2],,[l] ],\] (8)

where \(^{1 l}\). By adjusting the order of dimensions, \(\) is equivalent to \(\). Considering the sparsity of the frequency domain and the modeling of long-length time series, the direct outer product leads to dimension explosion and the sparsity in temporal-frequency feature subspace. We address the problem by performing average pooling over \(\). Average pooling, which calculates the average value for the amplitudes of neighboring frequencies, yields dense frequency features with smaller dimensions. With outer product and average pooling, the adversarial loss \(_{D}\) is formulated as:

\[ h(_{i},_{i})=& _{T}(_{i})(_{F} (_{i})),\\ _{D}(_{T},_{F},g_{D})=-_{(_{i}^{},_{i}^{})}[g_{D}(h (_{i}^{s},_{i}^{s}))]-_{( _{i}^{},_{i}^{})}[1-g_{D} (h(_{i}^{t},_{i}^{t}))],\] (9)

where \(h()\) denotes the mapping from the inputs of the overall model to the inputs of the domain discriminator, and \(()\) denotes the calculation of average pooling.

### Overview

During alignment, our method trains the temporal feature extractor \(_{T}\) and classifier \(g_{T}\) by minimizing the loss \(_{C_{T}}\) and trains the frequency feature extractor \(_{F}\) and classifier \(g_{F}\) by minimizing the loss \(_{C_{F}}\) using the source sample set \(\). Additionally, our method promotes mutual learning between the temporal domain and frequency domain by minimizing the loss \(_{M_{s}}\) on the source domain and the loss \(_{M_{t}}\) on the target domain. Meanwhile, our method aligns distributions of the source domain and target domain in the temporal-frequency correlation subspace. With two gradient reversal layers between the two feature extractors and the domain discriminator, the adversarial training is achieved by minimizing the loss \(_{D}\). To simplify notation, we denote \(_{F}\) as parameters containing \(_{F}\) and \(g_{F}\), and \(_{T}\) is parameters containing \(_{T}\) and \(g_{T}\). The minimax optimization problem is formulated as:

\[&_{_{F},_{T}}_{C_{F}}( _{F})+_{C_{T}}(_{T})+_{M_{s}}(_{T})+ _{M_{t}}(_{F})-_{D}(_{T},_{F},g_{D}),\\ &_{g_{D}}_{D}(_{T},_{F},g_{D}).\] (10)

## 5 Experiments

### Setup

DatasetsWe conduct extensive experiments using a wide range of time series datasets. (1) Experiments using benchmark datasets in sensor-based human activity recognition (HAR) task: UCIHAR , HHAR  and WISDM. For HHAR, we first split domains from the perspective of participants, denoted as HHAR-P [16; 31] dataset. Then, we split domains from the perspective of devices, denoted as HHAR-D  datasets. (2) Experiments using the benchmark dataset in sleep stage classification (SSC) task: CAP [14; 37]. (3) Experiments using EMG [24; 27] dataset in gesture recognition (GR) task. (4) Experiments using PCL [32; 9; 21; 19] dataset in motor imagery classification (MIC) task. (5) Experiments using FD  dataset in machine fault diagnosis (MFD) task. For each dataset, following the existing DA methods on time series [2; 16], we randomly sample 10 source-target domain pairs for evaluation. If the dataset has less than 10 pairs, we evaluate all available domain pairs. Further details, processing and domain splits are included in Appendix A.

Baselines(1) We report the performance of a model without UDA (Source-only) in the temporal domain to show the overall contribution of UDA methods. (2) We implement the following state-of-the-art baselines for UDA of time series data: CODATS, AdvSKM, CLUDA and RAINCOAT. (3) We additionally implement general unsupervised DA methods: CDAN , DeepCoral , AdaMatch , HoMM  and DIRT-T .

EvaluationWe report accuracy and Macro-F1 Score calculated using target test datasets. Accuracy is computed by dividing the number of correctly classified samples by the total number of samples. Macro-F1 Score is calculated using the unweighted mean of all the per-class F1 scores.

ImplementationWe adopt the implementation of AdaTime  as a benchmarking suite for domain adaptation on time series data, using 1D-CNN as the temporal feature extractor and 1-layer complex-valued linear as the frequency feature extractor. We use the same feature extractor across all algorithms, ensuring a fair comparison. In all experiments, we use the prediction of the temporal classifier to calculate accuracy and Macro-F1 Score. More experimental details are provided in Appendix B.

[MISSING_PAGE_FAIL:8]

### Analysis

Ablation StudyWe conduct ablation experiments on three datasets, UCIHAR, HHAR-P and WISDM. For each datasets, we select the same 10 source-target domain pairs as mentioned in Section 5.1. The ablation results (average accuracy of 10 domain pairs) are presented in Table 4. We can observe that all learning modules in the proposed method are effective. Further discussions are included in Appendix C.3.

Sensitivity AnalysisIt's worth noting that our total loss in Equation (10) does not include any hyperparameters. In UDA setup, how to search the optimal trade-offs without access to labeled target samples is still an open problem. Considering that, we choose to set all the trade-offs to 1, as it is the most intuitive choice. Without tuning the trade-offs, our proposed ACON still achieves significant improvements. To further investigate the sensitivity of ACON, we update Equation (10) as:

\[_{_{F},_{T}}_{C_{F}}(_{F})+ _{C_{T}}(_{T})+_{M_{s}}_{M_{s}}(_{T}) +_{M_{t}}_{M_{t}}(_{F})-_{D}_{D}( _{T},_{F},g_{D}),\] (11) \[_{g_{D}}_{D}_{D}(_{T},_{F},g_{D}),\]

where hyperparameters \(_{D}\), \(_{M_{s}}\) and \(_{M_{t}}\) control the contribution of each component. We investigate the sensitivity of the model to the hyperparameters \(_{D}\), \(_{M_{s}}\) and \(_{M_{t}}\). ACON-\(_{D}\) refers that the currently investigated hyperparameter is \(_{D}\), and others are analogous. From Figure 3, we observe that the performance of ACON is quite stable to the hyperparameters in Equation (11). Although setting all the trade-offs to 1 may not achieve the optimal performance, ACON still significantly outperforms the advanced baseline. This implies that ACON can achieve superior performance on a wider range of datasets without the need for careful hyperparameter tuning.

## 6 Conclusion

In this paper, the phenomenon is revealed----that temporal features exhibit better transferability across domains, whereas frequency features tend to be more discriminative within a specific domain. Based on the findings, **A**dversarial **CO**-learning **N**etworks (**ACON**) is proposed to boost the transferability and discriminability in a collaborative learning manner. Specifically, multi-period feature learning is proposed to enhance the discriminability of frequency features; temporal-frequency domain mutual learning is proposed to enhance the discriminability of temporal features in the source domain and improve the transferability of frequency features in the target domain; domain adversarial learning in temporal-frequency correlation subspace is proposed to further enhance transferability of features. ACON achieves state-of-the-art performance on a wide range of time series datasets.

    & \(_{C_{T}}\) & \(_{C_{F}}\) & Period & \(_{M_{s}}\) & \(_{M_{t}}\) & \(_{D}\) & UCIHAR & HHAR-P & WISDM & Average \\  / & ✓ & - & - & - & - & - & 75.12 & 54.25 & 65.78 & 65.05 \\ \(\) & - & ✓ & - & - & - & - & 66.88 & 51.08 & 56.47 & 58.14 \\ / & - & ✓ & ✓ & - & - & - & 73.47 & 53.16 & 59.10 & 61.91 \\ / & ✓ & ✓ & ✓ & - & - & ✓ & 94.05 & 79.49 & 74.19 & 82.58 \\ / & ✓ & ✓ & ✓ & ✓ & ✓ & - & 90.83 & 57.83 & 67.77 & 72.14 \\ / & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & **97.02** & **81.74** & **84.80** & **87.85** \\   

Table 4: Ablation studies: Average Accuracy (%) on UCIHAR, HHAR-P and WISDM.

Figure 3: Sensitivity Analysis on three different datasets: (a) UCIHAR (b) HHAR-P (c) WISDM. RAINCOAT: The advanced baseline that achieves suboptimal performance on the three datasets.