# Byzantine Robustness and Partial Participation Can Be Achieved at Once: Just Clip Gradient Differences

Byzantine Robustness and Partial Participation Can Be Achieved at Once: Just Clip Gradient Differences

 Grigory Malinovsky

KAUST, MBZUAI

Part of the work was done when G. Malinovsky was visiting MBZUAI.

Peter Richtarik

KAUST

Samuel Horvath

MBZUAI

Eduard Gorbunov

MBZUAI

Part of the work was done when G. Malinovsky was visiting MBZUAI.

###### Abstract

Distributed learning has emerged as a leading paradigm for training large machine learning models. However, in real-world scenarios, participants may be unreliable or malicious, posing a significant challenge to the integrity and accuracy of the trained models. Byzantine fault tolerance mechanisms have been proposed to address these issues, but they often assume full participation from all clients, which is not always practical due to the unavailability of some clients or communication constraints. In our work, we propose the first distributed method with client sampling and provable tolerance to Byzantine workers. The key idea behind the developed method is the use of gradient clipping to control stochastic gradient differences in recursive variance reduction. This allows us to bound the potential harm caused by Byzantine workers, even during iterations when all sampled clients are Byzantine. Furthermore, we incorporate communication compression into the method to enhance communication efficiency. Under general assumptions, we prove convergence rates for the proposed method that match the existing state-of-the-art (SOTA) theoretical results. We also propose a heuristic on adjusting any Byzantine-robust method to a partial participation scenario via clipping.

## 1 Introduction

Distributed optimization problems are a cornerstone of modern machine learning research. They naturally arise in scenarios where data is distributed across multiple clients; for instance, this is typical in Federated Learning (FL) (Konecny et al., 2016; Kairouz et al., 2021). Such problems require specialized algorithms adapted to the distributed setup. Additionally, the adoption of distributed optimization methods is motivated by the sheer computational complexity involved in training modern machine learning models. Many models deal with massive datasets and intricate architectures, rendering training infeasible on a single machine (Li, 2020). Distributed methods, by parallelizing computations across multiple machines, offer a pragmatic solution to accelerate training and address these computational challenges, thus pushing the boundaries of machine learning capabilities.

To make distributed training accessible to the broader community, collaborative learning approaches have been actively studied in recent years (Kijsipongse et al., 2018; Ryabinin and Gusev, 2020; Atre et al., 2021; Diskin et al., 2021). In such applications, there is a high risk of the occurrence of so-called _Byzantine workers_(Lamport et al., 1982; Su and Vaidya, 2016)--participants who can violate the prescribed distributed algorithm/protocol either intentionally or simply because they are faulty. In general, such workers may even have access to some private data of certain participants and may collude to increase their impact on the training. Since the ultimate goal is to achieve robustness in the worst case, many papers in the field make no assumptions limiting the power of Byzantine workers. Clearly, in this scenario, standard distributed methods based on the averaging of received information (e.g., stochastic gradients) are not robust, even to a single Byzantine worker. Such a worker can send an arbitrarily large vector that can shift the method arbitrarily far from the solution. This aspect makes it non-trivial to design methods with provable robustness to Byzantines (Baruch et al., 2019; Xie et al., 2020). Despite all the challenges, multiple methods are developed/analyzed in the literature (Alistarh et al., 2018; Allen-Zhu et al., 2021; Wu et al., 2020; Zhu and Ling, 2021; Karimireddy et al., 2021, 2022; Gorbunov et al., 2022, 2023; Allouah et al., 2023).

However, literally, all existing methods with provable Byzantine robustness require _the full (or close to full) participation of clients or rely on extra assumptions_. The requirement of full participation is impractical for modern distributed learning problems since they can have millions of clients (Bonawitz et al., 2017; Niu et al., 2020). In such scenarios, it is more natural to use sampling of clients to speed up the training. Moreover, some clients can be unavailable at certain moments, e.g., due to a poor connection, low battery, or simply because of the need to use the computing power for some other tasks. Although _partial participation of clients_ is a natural attribute of large-scale collaborative training, it is not studied under the presence of Byzantine workers. Moreover, this question is highly non-trivial: the existing methods can fail to converge if combined naively with partial participation since Byzantine can form a majority during particular rounds and, thus, destroy the whole training with just one round of communications. _Therefore, the field requires the development of new distributed methods that are provably robust to Byzantine attacks and can work with partial participation even when Byzantine workers form a majority during some rounds._

Our ContributionsWe develop Byzantine-tolerant Variance-Reduced \(\) with Partial Participation (\(\), Algorithm 1) - the first distributed method having Byzantine robustness and allowing partial participation of clients without strong additional assumptions. Our method uses variance reduction to handle Byzantine workers and clipping of stochastic gradient differences to bound the potential harm of Byzantine workers even when they form a majority during particular rounds of communication. To make the method even more communication efficient, we add communication compression. We prove the convergence of \(\) for general smooth non-convex functions and Polyak-Lojasiewicz functions. In the special case of full participation, our complexity bounds recover the ones for \(\)(Gorbunov et al., 2023) that are the current SOTA convergence results. Moreover, we prove that in some cases, partial participation is theoretically beneficial for \(\). We also propose a simplified version of \(\) with better neighborhood term in the convergence bounds (\(\), Algorithm 3) and a heuristic on how to use clipping to adapt any Byzantine-robust method to the partial participation setup and illustrate its performance in experiments.

### Related Work

Below, we overview closely related works. Additional discussion is deferred to Appendix A.

Byzantine robustness.The primary vulnerability of standard distributed methods to Byzantine attacks lies in the aggregation rule: even one worker can arbitrarily distort the average. Therefore, many papers on Byzantine robustness focus on the application of robust aggregation rules, such as the geometric median (Pillutla et al., 2022), coordinate-wise median, trimmed median (Yin et al., 2018), Krum (Blanchard et al., 2017), and Multi-Krum (Damaskinos et al., 2019). However, simply robustifying the aggregation rule is insufficient to achieve provable Byzantine robustness, as illustrated by Baruch et al. (2019) and Xie et al. (2020), who design special Byzantine attacks that can bypass standard defenses. This implies that more significant algorithmic changes are required to achieve Byzantine robustness, a point also formally proven by Karimireddy et al. (2021), who demonstrate that permutation-invariant algorithms - i.e., algorithms independent of the order of stochastic gradients at each step - cannot provably converge to any predefined accuracy in the presence of Byzantines.

Wu et al. (2020) are the first who exploit variance reduction to tolerate Byzantine attacks. They propose and analyze the method called \(\), which uses \(\)-type (Defazio et al., 2014) gradient estimators on the good workers and geometric median for the aggregation. Gorbunov et al. (2023) develop another variance-reduced method called \(\), which is based on (conditionally biased) \(\)-type (Horvath et al., 2023; Li et al., 2021) gradient estimator and any robust aggregation in the sense of the definition from (Karimireddy et al., 2021,2022), and derive the improved convergence guarantees that are the current SOTA in the literature. There are also many other approaches and we discuss some of them in Appendix A.

**Partial participation and client sampling.** In the context of Byzantine-robust learning, there exists several works that develop and analyze methods with partial participation (Data and Diggavi, 2021; El-Mhamdi et al., 2021; Boubouh et al., 2022; Allouah et al., 2024a). However, these works rely on the restrictive assumption that the number of participating clients at each round is larger than the number of Byzantine workers. In this case, Byzantine cannot form a majority, and standard methods can be applied without any changes. In contrast, our method converges in more challenging scenarios, e.g., \(\) provably converges even when the server samples one client, which can be Byzantine. If the number of participating clients is such that Byzantine clients can form majority, these methods have a certain probability of divergence and this probability grows with each communication round. We provide a more detailed discussion in Appendix A.

## 2 Preliminaries

In this section, we formally introduce the problem, main definition, and assumptions used in the analysis. That is, we consider finite-sum distributed optimization problem5

\[_{x^{d}}\{f(x):=_{i}f_{i} (x)\}, f_{i}(x):=_{j=1}^{m}f_{i,j}(x) i ,\] (1)

where \(\) is a set of regular clients of size \(G:=||\). In the context of distributed learning, \(f_{i}:^{d}\) corresponds to the loss function on the data of client \(i\), and \(f_{i,j}:^{d}\) is the loss computed on the \(j\)-th sample from the dataset of client \(i\). Next, we assume that the set of all clients taking part in the training is \([n]=\{1,2,,n\}\) and \([n]\). The remaining clients \(:=[n]\) are Byzantine ones. We assume that \(B:=||:=_{}n n\), where \(_{}\) is an exact ratio of Byzantine workers and \(\) is a known upper bound for \(_{}\). We also assume that \(0_{}<}{{2}}\) since otherwise Byzantine workers form a majority and problem (1) becomes impossible to solve in general.

**Notation.** We use a standard notation for the literature on distributed stochastic optimization. Everywhere in the text \(\|x\|\) denotes a standard \(_{2}\)-norm of \(x^{d}\), \( a,b\) refers to the standard inner product of vectors \(a,b^{d}\). The clipping operator is defined as follows: \(_{}(x):=\{1,}{{\|x\|}}xx 0_{}(0):=0\) Finally, \(\{A\}\) denotes the probability of event \(A\), \([]\) is the full expectation of random variable \(\), \([ A]\) is the expectation of \(\) conditioned on the event \(A\). We also sometimes use \(_{k}[]\) to denote an expectation of \(\) w.r.t. the randomness coming from step \(k\).

**Robust aggregator.** We follow the definition from (Gorbunov et al., 2023) of \((,c)\)-robust aggregation, which is a generalization of the definitions proposed by Karimireddy et al. (2021, 2022).

**Definition 2.1** (\((,c)\)-Robust Aggregator).: Assume that \(\{x_{1},x_{2},,x_{n}\}\) is such that there exists a subset \([n]\) of size \(||=G(1-)n\) for \(_{}<0.5\) and there exists \( 0\) such that \(_{i,l}[\|x_{i}-x_{l}\|^{2} ]^{2}\) where the expectation is taken w.r.t. the randomness of \(\{x_{i}\}_{i}\). We say that the quantity \(\) is \((,c)\)-Robust Aggregator \((,c)\)-\(\)) and write \(=(x_{1},,x_{n})\) for some \(c>0\), if the following inequality holds:

\[[\|-\|^{2}] c^{2},\] (2)

where \(:=|}_{i}x_{i}\). If additionally \(\) is computed without the knowledge of \(^{2}\), we say that \(\) is \((,c)\)-Agnostic Robust Aggregator \((,c)\)-\(\) and write \(=(x_{1},,x_{n})\).

One can interpret the definition as follows. Ideally, we would like to filter out all Byzantine workers and compute just an average \(\) over the set of good clients. However, this is impossible in general since we do not know apriori who are Byzantine workers. Instead of this, it is natural to expect that the aggregation rule approximates the ideal average up in a certain sense, e.g., in terms of the expected squared distance to \(\). As Karimireddy et al. (2021) formally show, in terms of such criterion (\([\|-\|^{2}]\)), the definition of \((,c)\)-\(\) cannot be improved (up to the numerical constant). Moreover,standard aggregators such as Krum (Blanchard et al., 2017), geometric median, and coordinate-wise median do not satisfy Definition 2.1(Karimireddy et al., 2021), though another popular standard aggregation rule called coordinate-wise trimmed mean (Yin et al., 2018) satisfies Definition 2.1 as shown by Allouah et al. (2023) through the more general definition of robust aggregation. To address this issue, Karimireddy et al. (2021) develop the aggregator called \(\) and prove that it fits the definition of \((,c)\)-\(\). Karimireddy et al. (2022) propose a procedure called \(\) that fixes Krum, geometric median, and coordinate-wise median, i.e., with \(\) Krum, geometric, and coordinate-wise median become \((,c)\)-\(\), which is important for our algorithm since the variance of the vectors received from regular workers changes over time in our method. We notice here that \(\) is a part of the input that should satisfy \(_{}_{}\).

**Compression operators.** In our work, we use standard unbiased compression operators with relatively bounded variance (Khirirat et al., 2018; Horvath et al., 2023).

**Definition 2.2** (Unbiased compression).: Stochastic mapping \(:^{d}^{d}\) is called unbiased compressor/compression operator if there exists \( 0\) such that for any \(x^{d}\)\([(x)]=x,[\|(x)-x\|^{2} ]\|x\|^{2}\). For the given unbiased compressor \((x)\), one can define the expected density6 as \(_{}:=_{x^{d}}[\|( x)\|_{0}]\), where \(\|y\|_{0}\) is the number of non-zero components of \(y^{d}\).

In this definition, parameter \(\) reflects how lossy the compression operator is: the larger \(\) the more lossy the compression. For example, this class of compression operators includes random sparsification (RandK) (Stich et al., 2018) and quantization (Goodall, 1951; Roberts, 1962; Alistarh et al., 2017). For RandK compression \(=-1\), \(_{}=K\) and for \(_{2}\)-quantization \(=-1,_{}=\), see the proofs in (Beznosikov et al., 2020).

**Assumptions.** Up to a couple of assumptions that are specific to our work, we use the same assumptions as in (Gorbunov et al., 2023). We start with two new assumptions.

**Assumption 2.3** (Bounded \(\)).: We assume that the server applies aggregation rule \(\) such that \(\) is \((,c)\)-\(\) and there exists constant \(F_{}>0\) such that for any inputs \(x_{1},,x_{n}^{d}\) the norm of the aggregator is not greater than the maximal norm of the inputs: \(\|(x_{1},,x_{n})\| F_{}_{i[n ]}\|x_{i}\|\).

The above assumption is satisfied for popular \((,c)\)-robust aggregation rules presented in the literature (Karimireddy et al., 2021, 2022). Therefore, this assumption is more a formality than a real limitation: it is needed to exclude some pathological examples of \((,c)\)-robust aggregation rules, e.g., for any \(\) that is \((,c)\)-\(\) one can construct unbounded \((,2c)\)-\(\) as \(}=+X\), where \(X\) is a random sample from the Gaussian distribution \((0,c^{2})\).

Next, for part of our results, we also make the following assumption.

**Assumption 2.4** (Bounded compressor (optional)).: We assume that workers use compression operator \(\) satisfying Definition 2.2 and bounded as follows: \(\|(x)\| D_{Q}\|x\| x^{d}\).

For example, RandK and \(_{2}\)-quantization meet this assumption with \(D_{}=\) and \(D_{}=\) respectively. In general, constant \(D_{}\) can be large (proportional to \(d\)). However, in practice, one can use RandK with \(K=\) and, thus, have moderate \(D_{}=100\). We also have the results without Assumption 2.4, but with worse dependence on some other parameters, see Section 4.

Next, we assume that good workers have \(^{2}\)-heterogeneous local loss functions.

**Assumption 2.5** (\(^{2}\)-heterogeneity).: We assume that good clients have \(^{2}\)-heterogeneous local loss functions for some \( 0\), i.e., \(_{i}\| f_{i}(x)- f(x)\|^{2}^{ 2} x^{d}\).

The above assumption is quite standard for the literature on Byzantine robustness (Wu et al., 2020; Karimireddy et al., 2022; Gorbunov et al., 2023; Allouah et al., 2023). Moreover, some kind of a bound on the heterogeneity of good clients is necessary since otherwise Byzantine robustness cannot be achieved in general. In the appendix, all proofs are given under a more general version of Assumption 2.5, see Assumption D.5. Finally, the case of homogeneous data (\(=0\)) is also quite popular for collaborative learning (Diskin et al., 2021; Kijispongse et al., 2018).

The following assumption is classical for the literature on non-convex optimization.

**Assumption 2.6** (Smoothness (simplified)).: We assume that for all \(i\) and \(j[m]\) there exists \( 0\) such that \(f_{i,j}\) is \(\)-smooth, i.e., for all \(x,y^{d}\)

\[\| f_{i,j}(x)- f_{i,j}(y)\|\|x-y\|.\] (3)

Moreover, we assume that \(f\) is uniformly lower bounded by \(f^{*}\), i.e., \(f^{*}:=_{x^{d}}f(x)\).

For the sake of simplicity, we do not differentiate between various notions of smoothness in the main text. However, our analysis takes into account the differences between smoothness constants, similarity of local functions, and sampling strategy (see Appendix D.1).

Finally, we also consider functions satisfying Polyak-Lojasiewicz (PL) condition (Polyak, 1963; Lojasiewicz, 1963). This assumption belongs to the class of assumptions on the structured non-convexity that allows achieving linear convergence (Necoara et al., 2019).

**Assumption 2.7** (PL condition (optional)).: We assume that function \(f\) satisfies Polyak-Lojasiewicz (PL) condition with parameter \(>0\), i.e., for all \(x^{d}\) there exists \(f^{*}:=_{x^{d}}f(x)\) such that \(\| f(x)\|^{2} 2(f(x)-f^{*}).\)

## 3 New Method: \(\)

We propose a new method called Byzantine-tolerant Variance-Reduced \(\) with Partial Participation (\(\), Algorithm 1). Our method extends \(\)(Gorbunov et al., 2023) to the partial participation case via the proper usage of the clipping operator. To illustrate how \(\) works, we first consider a special case of full participation.

**Special case:**\(\). If all clients participate at each round (\(S_{k}[n]\)) and clipping is turned off (\(_{k}+\)), then \(\) reduces to \(\) that works as follows. Consider the case when no compression is applied (\((x)=x\)) and \(_{i}(x^{k+1},x^{k})= f_{i,j_{k}}(x^{k+1})- f_{i, j_{k}}(x^{k})\), where \(j_{k}\) is sampled uniformly at random from \([m]\), \(i\). Then, regular workers compute \(\) gradient estimator at each step: for \(i\)

\[g_{i}^{k+1}= f_{i}(x^{k+1}),p,\\ g^{k}+ f_{i,j_{k}}(x^{k+1})- f_{i,j_{k}}(x^{k}), \]With small probability \(p\), good workers compute full gradients, and with larger probability \(1-p\) they update their estimator via adding stochastic gradient difference. To balance the oracle cost of these two cases, one can choose \(p}{{m}}\) (for \(b\)-size mini-batched estimator \(-p}{{m}}\)). Such estimators are known to be optimal for finding stationary points in the stochastic first-order optimization (Fang et al., 2018; Arjevani et al., 2023). Next, good workers send \(g_{i}^{k+1}\) or \( f_{i,j_{k}}(x^{k+1})- f_{i,j_{k}}(x^{k})\) to the server who robustly aggregate the received vectors. Since estimators are conditionally biased, i.e., \([g_{i}^{k+1} x^{k+1},x^{k}] f_{i}(x^{k+1})\), the additional bias coming from the aggregation does not cause significant issues in the analysis or practice. Moreover, the variance of \(\{g_{i}^{k+1}\}_{i}\) w.r.t. the sampling of the stochastic gradients is proportional to \(\|x^{k+1}-x^{k}\|^{2} 0\) with probability \(1-p\) (due to Assumption D.3) that progressively limits the effect of Byzantine attacks. For a more detailed explanation of why recursive variance reduction works better than SAGA/SVRG-type variance reduction, we refer to (Gorbunov et al., 2023). Arbitrary sampling allows the improvement of the dependence on the smoothness constants. Unbiased communication compression also naturally fits the framework since it is applied to the stochastic gradient difference, meaning that the variance of \(\{g_{i}^{k+1}\}_{i}\) w.r.t. the sampling of the stochastic gradients and compression remains proportional to \(\|x^{k+1}-x^{k}\|^{2}\) with probability \(1-p\).

**New ingredients: client sampling and clipping.** The algorithmic novelty of Byz-VR-MARINA-PP in comparison to Byz-VR-MARINA is twofold: with (typically large) probability \(1-p\) only \(C\) clients sampled uniformly at random from the set of all clients participate at each round, and clipping is applied to the compressed stochastic gradient differences. With a small probability \(p\), a larger number7 of clients \( n\) takes part in the communication. The main role of clipping is to ensure that the method can withstand the attacks of Byzantines when they form a majority or, more precisely when there are more than \( C\) Byzantine workers among the sampled ones. _Indeed, without clipping (or some other algorithmic changes) such situations are critical for convergence: Byzantine workers can shift the method arbitrarily far from the solution, e.g., they can collectively send some vector with the arbitrarily large norm._ In contrast, Byz-VR-MARINA-PP tolerates any attacks even when all sampled clients are Byzantine workers since the update remains bounded due to the clipping. Via choosing \(_{k+1}\|x^{k+1}-x^{k}\|\) we ensure that the norm of transmitted vectors decreases with the same rate as it does in Byz-VR-MARINA with full client participation. Finally, with probability \(1-p\) regular workers can transmit just compressed vectors and leave the clipping operation to the server since Byzantines can ignore clipping operation.

## 4 Convergence Results

We define \(_{C}^{k}= S_{k}\) and \(G_{C}^{k}=|_{C}^{k}|\) and \(=\) represents the binomial coefficient. We also use the following probabilities:

\[p_{G} :=\{G_{C}^{k}(1-)\,C\}= _{(1-)C t C}}{ },\] \[_{_{C}^{k}} :=\{i_{C}^{k} G_{C}^{k} (1-)\,C\}=}_{(1-)C  t C}}{}.\]

These probabilities naturally appear in the analysis and statements of the theorems. When \(c_{k}=0\), then server samples \(C\) clients, and two situations can appear: either \(G_{C}^{k}\) is at least \((1-)\,C\) meaning that the aggregator can ensure robustness according to Definition 2.1 or \(G_{C}^{k}<(1-)\,C\). Probability \(p_{G}\) is the probability of the first event, and the second event implies that the aggregation can be spoiled by Byzantine workers (but clipping bounds the "harm"). Finally, we use \(_{_{C}^{k}}\) in the computation of some conditional expectations when the first event occurs. The mentioned probabilities can be easily computed for some special cases. For example, if \(C=1\), then \(p_{G}=}{{n}}\) and \(_{_{C}^{k}}=}{{G}}\); if \(C=2\), then \(p_{G}=}{{n(n-1)}}\) and \(_{_{C}^{k}}=}{{G}}\); finally, if \(C=n\), then \(p_{G}=1\) and \(_{_{C}^{k}}=1\).

The next theorem is our main convergence result for general unbiased compression operators.

**Theorem 4.1**.: _Let Assumptions 2.3, 2.5, 2.6 hold, \(_{k+1}=2\|x^{k+1}-x^{k}\|\), and \(\{1,\,_{}n/\}\). Assume that \(0<}{{(1+)}},\) where constant \(A\) is defined as_

\[A = G_{_{C}^{k}}}{p^{2}(1-)C} (30+11)(1+2c)+)(1+4F_{A}^{2})}{p^{2}}.\] (4)

_Then for all \(K 0\) the iterates produced by_ Byz-VR-MARINA-PP _(Algorithm 1) satisfy_

\[[\| f(^{K})\|^{2} ]}{(K+1)}+^{2}}{p},\] (5)

_where \(=_{_{C}^{k}}^{k}}{1-} (+p)+\), where \(=0\) when \(=n\), \(=_{_{C}^{k}}^{k}G}{(1-) }\) when \(=n\), and \(^{K}\) is chosen uniformly at random from \(x^{0},x^{1},,x^{K}\), and \(^{0}=f(x^{0})-f^{*}+\|g^{0}- f (x^{0})\|^{2}\). If, in addition, Assumption 2.7 holds and \(0<}{{(1+)}},\) then for all \(K 0\) the iterates produced by_ Byz-VR-MARINA-PP _(Algorithm 1) with \(=\{,\}\) satisfy_

\[[f(x^{K})-f(x^{*})] (1-)^{K}^{0}+^{2}}{p},\] (6)

_where \(^{0}=f(x^{0})-f^{*}+\|g^{0}- f (x^{0})\|^{2}\)._

The above theorem establishes similar guarantees to the current SOTA ones obtained for Byz-VR-MARINA. That is, in the general non-convex case, we prove \((}{{K}})\) rate, which is optimal (Arjevani et al., 2023), and for PL-functions we derive linear convergence result to the neighborhood depending on the heterogeneity. The size of this neighborhood matches the one derived for Byz-VR-MARINA by Gorbunov et al. (2023). However, since our result is obtained considering the challenging scenario of partial participation of clients, the maximal theoretically allowed stepsize in our analysis of Byz-VR-MARINA-PP is smaller than the one from (Gorbunov et al., 2023).

In particular, the second term in the constant \(A\) appears due to the partial participation, and the whole expression for \(A\) is proportional to \(}{{p^{2}}}\). In contrast, a similar constant \(A\) from the result for Byz-VR-MARINA is proportional to \(}{{p}}\), which can be noticeably smaller than \(}{{p^{2}}}\). Indeed, to make the expected number of clients participating in the communication round equal to \((C)\), to make the expected number of stochastic oracle calls equal to \((b)\), and to make the expected number of transmitted components for each worker taking part in the communication round equal \((_{})\), parameter \(p\) should be chosen as \(p=\{C/n,\,}{{m}},\,}{{_{}}}/d\}\), where the latter term in the minimum often equals to \((}{{(+1)}})\)(Gorbunov et al., 2021). Therefore, in some scenarios, \(p\) can be small.

Next, in the special case of full participation, we have \(C==n\), \(p_{G}=_{_{C}^{k}}=1\), meaning that \(A=(}{{1+}}/}}{{2}})\) for Byz-VR-MARINA-PP. In contrast, the corresponding constant for Byz-VR-MARINA is of the order \((}{{pn}}+}{{p^{2}}})\), which is strictly better than our bound. In this special case, we do not recover the result for Byz-VR-MARINA.

Such a complexity deterioration can be explained as follows: the presence of clipping introduces additional technical difficulties in the analysis, resulting in a reduced step size compared to Byz-VR-MARINA, even when \(C==n\). To achieve a more favorable convergence rate, particularly in scenarios of complete participation, we also establish the results under Assumption 2.4.

**Theorem 4.2**.: _Let Assumptions 2.3, 2.4, 2.5, 2.6 hold, \(_{k+1}=D_{Q}\|x^{k+1}-x^{k}\|\), and \(\{1,\,_{}n/\}\). Assume that \(0<}{{(1+)}},\) where constant \(A\) equals_

\[A = G_{_{C}^{k}}}{p(1-)C}( +)+)(2+F_{A}^{2}D_{Q}^{2})}{p^{2}}.\] (7)

_Then for all \(K 0\) the iterates produced by_ Byz-VR-MARINA-PP _(Algorithm 1) satisfy_

\[[\| f(^{K})\|^{2}] }{(K+1)}+^{2}}{p},\] (8)

_where \(=_{_{C}^{k}}^{k}}{1-} (+p)+\), where \(=0\) when \(=n\), \(=_{_{C}^{k}}^{k}G}{(1-) }\) when \(=n\), and \(^{K}\) is chosen uniformly at random from \(x^{0},x^{1},,x^{K}\), and \(^{0}=f(x^{0})-f^{*}+\|g^{0}- f (x^{0})\|^{2}\).__If, in addition, Assumption 2.7 holds and \(0<}{{}(1+)}\), then for all \(K 0\) the iterates produced by_ Byz-VR-MARINA-PP _(Algorithm 1) satisfy with \(=\{,\}\)_

\[[f(x^{K})-f(x^{*})] (1-)^{K}^{0}+_{}{}^{2} }{p},\] (9)

_where \(^{0}=f(x^{0})-f^{*}+\|g^{0}- f (x^{0})\|^{2}\)._

With Assumption 2.4, vectors \(\{(_{i}(x^{k+1},x^{k}))\}_{i_{C}^{k}}\) can be upper bounded by \(D_{Q}\|x^{k+1}-x^{k}\|\). Using this fact, one can take the clipping level sufficiently large such that it is turned off for the regular workers. This allows us to simplify the proof and remove \(}{{p}}\) factor in front of the terms not proportional to \(\) or to \(1-p_{G}\) in the expression for \(A\) that can make the stepsize larger. However, the second term in (7) can be larger than (4), since it depends on potentially large constant \(D_{Q}\). Therefore, the rates of convergence from Theorems 4.1 and 4.2 cannot be compared directly. We also highlight that the clipping level from Theorem 4.2 is in general larger than the clipping level from Theorem 4.1 and, thus, it is expected that with full participation Theorem 4.2 gives better results than Theorem 4.1: the bias introduced due to the clipping becomes smaller with the increase of the clipping level. However, in the partial participation regime, the price for this is a decrease of the stepsize to compensate for the increased harm from Byzantine clients in situations when they form a majority. Further discussion of the technical challenges we overcame is deferred to Appendix E.3.

Nevertheless, in the case of full participation, we have \(C==n\), \(p_{G}=_{_{C}^{k}}=_{_{ }^{k}}=1\), meaning that \(A=(}{{pn}}+}{{p^{2}}})\) in Theorem 4.2. That is, in this case, we recover the result of Byz-VR-MARINA. More generally, if \(p_{G}=1\), which is equivalent to \(C\{1,}}}{{n}}/{}\}\), then \(_{_{C}^{k}}=\{i_{C}^{k}\}= \{1,}{{G}}\}\), \(_{_{C}^{k}}=\{i_{C}^{k}\}= \{1,}{{G}}\}\) and we have \(A=(}{{p_{G}}}+}{{p^{ 2}}})\). Here, the first term in \(A\) is \(}{{C}}\) worse than the corresponding term for Byz-VR-MARINA. However, the second term in \(A\) matches the corresponding term for Byz-VR-MARINA. Moreover, this term is the main one if \(c}{{C}}\), which is typically the case since parameter \(p\) is often small (\(p=\{}{{G}},}{{m}},}{{ }}/{d}\}\)). In such cases, Byz-VR-MARINA-PP has the same rate of convergence as Byz-VR-MARINA while utilizing, on average, just \((C)\) workers at each step in contrast to Byz-VR-MARINA that uses \(n\) workers at each step. _That is, in some cases, partial participation is provably beneficial for_ Byz-VR-MARINA-PP.

Byz-VR-MARINA+: simplified version of Byz-VR-MARINA.In Appendix F, we propose a simplified version of Byz-VR-MARINA called Byz-VR-MARINA+ (Algorithm 3). The only difference is related to Line 10 of the method: when \(c_{k}=0\), Byz-VR-MARINA+ computes just the average of \(\{}_{_{k+1}}(( _{i}(x^{k+1},x^{k})))\}_{i_{k}}\) instead of robust aggregation, while keeps using ARAgg when \(c_{k}=1\). Of course, when \(c_{k}=0\) and at least one Byzantine worker is sampled, then the step can be useless, but the "harm" of this step is bounded due to the clipping. However, in certain regimes (e.g., when \(C\) is small enough and the number of Byzantine workers is much smaller than the number of regular workers), the probability of sampling only regular workers is larger than sampling at least one Byzantine worker when \(c_{k}=0\), meaning that with high enough probability the resulting estimator has no additional bias coming from the robust aggregation. We formally analyze Byz-VR-MARINA+ and show that such a modification of the method leads to better theoretical results (especially when \(C\) is small). In particular, in the settings of Theorem 4.2, we prove that Byz-VR-MARINA+ exhibits the same \((}{{k}})\) rate but converges to \((}{{p}})\) smaller neighborhood when \(=n\), i.e., the neighborhood term for Byz-VR-MARINA+ is optimal (Karimireddy et al., 2022; Allouah et al., 2024). Moreover, our results for Byz-VR-MARINA+ allow larger stepsizes when \(C\) is small enough. For further details and complete proofs, we refer to Appendix F.

**Extensions without full-batch gradient computations.** The proposed methods - Byz-VR-MARINA and Byz-VR-MARINA+ - have a common limitation related to the full-batch gradient computation with probability \(p\). Although this probability is typically small, even one full-gradient computation can be very expensive for certain problems. To address this issue, we propose the modifications of Byz-VR-MARINA and Byz-VR-MARINA+ without full-batch gradient computations at all (see Algorithms 4 and 5 in Appendix G). That is, these modifications differ from Byz-VR-MARINA and Byz-VR-MARINA+ in Line 8 only: when \(c_{k}=1\), every good worker \(i\) from \(S_{k}\) computes and sends to the server \(b^{}\)-size mini-batched stochastic gradient estimator \(f_{i}(x^{k+1})\) of \( f_{i}(x^{k+1})\)Under the additional assumption that the variance of \(f_{i}(x^{k+1})\) is uniformly bounded by \(}}{{b^{}}}\), which is a standard assumption for variance-reduced methods without full-batch gradient computations (Fang et al., 2018; Cutkosky and Orabona, 2019; Li et al., 2021; Gorbunov et al., 2021), we prove that both methods converge similarly as in the case of the (periodical) full-batch gradient computations but to the neighborhood having an additional term proportional to \((c+_{_{}^{k}}}}{{G}} /{^{2}})}}{{b^{}}}\). For further details and complete proofs, we refer to Appendix G.

Heuristic extension of Byz-Vr-Marina-Pp.In this short remark, we illustrate how the proposed clipping technique can be applied to a general class of Byzantine-robust methods to adapt them to the case of partial participation. Consider the methods having the following update rule: \(x^{k+1}=x^{k}-(\{g_{i}^{k}\}_{i[n]})\), where \(\{g_{i}^{k}\}_{i[n]}\) are the vectors received from workers at iteration \(k\) and Agg is some aggregation rule. A vast majority of existing Byzantine-robust methods fit this scheme. In the case of partial participation of clients, we propose to modify the scheme as follows:

\[x^{k+1}=x^{k}- g^{k},g^{k}:=g^{k-1}+(\{_{_{k}}(g_{i}^{k}-g^{k-1})\}_{i  S_{k}}),\] (10)

where \(S_{k}[n]\) is a subset of clients participating in round \(k\) and \(\{_{k}\}_{k 0}\) is sequence of clipping parameters specified by the server. In particular, Byz-VR-Marina-PP can be seen as an application of scheme (10) to Byz-VR-Marina (up to a minor modification when \(c_{k}=1\) in Byz-VR-Marina) with \(_{k+1}=\|x^{k+1}-x^{k}\|\). We suggest to use \(_{k+1}=\|x^{k+1}-x^{k}\|\) with tunable parameter \(>0\) for other methods as well.

## 5 Numerical Experiments

Firstly, we showcase the benefits of employing clipping to remedy the presence of Byzantine workers and partial participation. For this task, we consider the standard logistic regression model with \(_{2}\)-regularization, i.e., \(f_{i,j}(x)=-y_{i,j}(h(x,a_{i,j}))-(1-y_{i,j})(1-h(x,a_{i,j}))+\|x \|^{2}\), where \(y_{i,j}\{0,1\}\) is the label, \(a_{i,j}^{d}\) represents the feature vector, \(\) is the regularization parameter, and \(h(x,a)=}{{(1+e^{-a^{T}x})}}\). This objective is smooth, and for \(>0\), it is also strongly convex, satisfying the PL-condition. We consider the _a9a_ LIBSVM dataset (Chang and Lin, 2011) and set \(=0.01\). In the experiments, we focus on an important feature of Byz-VR-Marina-PP: it has linear convergence for homogeneous datasets across clients even in the presence of Byzantine workers and partial participation, as shown in Theorems 4.1 and 4.2.

To demonstrate this experimentally, we consider the setup with 15 good workers and 5 Byzantines, _each worker can access the entire dataset_, and the server uses coordinate-wise median with bucketing as the aggregator (see also Appendix C). For the attack, we propose a new attack that we refer to as the _shift-back_ attack, which acts in the following way. If Byzantine workers are in the majority in the current round \(k\), then each Byzantine worker sends \(x^{0}-x^{k}\). Otherwise, they follow protocol and act as benign workers. Further experimental details are deferred to Appendix H.

Figure 1: The optimality gap \(f(x^{k})-f(x^{*})\) for 3 different scenarios. We use coordinate-wise mean with bucketing equal to 2 as an aggregation and shift-back as an attack. We use the a9a dataset, where each worker accesses the full dataset with 15 good and 5 Byzantine workers. We do not use any compression. In each step, we sample 20% of clients uniformly at random to participate in the given round unless we specifically mention that we use full participation. Left: Linear convergence of Byz-VR-Marina-PP with clipping versus non-convergence without clipping. Middle: Full versus partial participation, showing faster convergence with clipping. Right: Clipping multiplier \(\) sensitivity, demonstrating consistent linear convergence across varying \(\) values.

We compare our \(\) with its version without clipping. We note that the setup that we consider is the most favorable in terms of minimized variance in terms of data and gradient heterogeneity. We show that even in this simplest setup, the method without clipping does not converge since there is no method that can withstand the Byzantine majority. Therefore, any more complex scenario would also fall short using our simple attack. On the other hand, we show that once clipping is applied, \(\) is able to converge linearly to the exact solution, complementing our theoretical results.

Figure 1 showcases these observations. On the left, we can see \(\) converges linearly to the optimal solution, while the version without clipping remains stuck at the starting point since \(\) are always able to push the solution back to the origin since they can create the majority in some rounds. In the middle plot, we compare the full participation scenario in which all the clients participate in each round, which does not require clipping since, in each step, we are guaranteed that \(\) are not in the majority, to partial participation with clipping. We can see, when we compare the total number of computations (measured in epochs), \(\) leads to faster convergence even though we need to employ clipping. Finally, in the right plot, we measure the sensitivity of clipping multiplier \(\). We can see that \(\) is not very sensitive to \(\) in terms of convergence, i.e., for all the values of \(\), we still converge linearly. However, the suboptimal choice of \(\) leads to slower convergence.

Furthermore, we also realize that other attacks and more complicated experiments could potentially damage clipping more than methods not using clipping. Therefore, we provide additional experiments with neural networks and different attacks in heterogeneous settings. For our experimental setup, we follow (Karimireddy et al., 2021). However, when working with neural networks, the choice of standard variance reduction is not effective (Defazio and Bottou, 2019). Therefore, we use Byzantine Robust Momentum SGD (Karimireddy et al., 2021) as an underlying optimization method; see (10).

We consider the MNIST dataset (LeCun and Cortes, 1998) with heterogeneous splits with 20 clients, 5 of which are malicious. For the attacks, we consider A Little is Enough (ALIE) (Baruch et al., 2019), Bit Flipping (BF), and aforementioned Shift-Back (SHB). For the aggregations, we consider coordinate median (CM) (Chen et al., 2017) and robust federated averaging (RFA) (Pillutla et al., 2022) with bucketing.

From Figure 2, we can see that clipping does not lead to performance degradation. On the contrary, clipping performs on par or better than its variant without clipping. Furthermore, we can see that no robust aggregator is able to withstand the shift-back attack without clipping.

## 6 Conclusion and Future Work

This work makes an important step in the direction of achieving Byzantine robustness under the partial participation of clients. However, some important questions remain open. First of all, it will be interesting to understand whether the derived bounds can be further improved in terms of the dependence on \(,m\), and \(C\). Next, it would be interesting to rigorously prove that our heuristic works for \(\) with client momentum (Karimireddy et al., 2021, 2022) and other Byzantine-robust methods. Finally, studying other participation patterns (non-uniform sampling/arbitrary client participation) is also a very prominent direction for future research.

Figure 2: Training loss of 2 aggregation rules (CM, RFA) under 2 attacks (BF, SHB) on the MNIST dataset under heterogeneous data split with 20 clients, 5 of which are malicious. Additional experiments on CIFAR10 are provided in Appendix H.