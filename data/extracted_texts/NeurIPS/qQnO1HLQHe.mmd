# Complex Query Answering on Eventuality Knowledge Graph with Implicit Logical Constraints

Jiaxin Bai

Department of CSE

HKUST

jbai@connect.ust.hk

&Xin Liu

Department of CSE

HKUST

xliucr@cse.ust.hk

&Weiqi Wang

Department of CSE

HKUST

wwangbw@cse.ust.hk

&Chen Luo

Amazon.com Inc

cheluo@amazon.com

&Yangqiu Song

Department of CSE

HKUST

yqsong@cse.ust.hk

Prof. Yangqiu Song is a visiting academic scholar at Amazon.

###### Abstract

Querying knowledge graphs (KGs) using deep learning approaches can naturally leverage the reasoning and generalization ability to learn to infer better answers. Traditional neural complex query answering (CQA) approaches mostly work on entity-centric KGs. However, in the real world, we also need to make logical inferences about events, states, and activities (i.e., eventualities or situations) to push learning systems from System I to System II, as proposed by Yoshua Bengio. Querying logically from an EVentuality-centric KG (EVKG) can naturally provide references to such kind of intuitive and logical inference. Thus, in this paper, we propose a new framework to leverage neural methods to answer complex logical queries based on an EVKG, which can satisfy not only traditional first-order logic constraints but also implicit logical constraints over eventualities concerning their occurrences and orders. For instance, if we know that _Food is bad_ happens before _PersonX adds soy sauce_, then _PersonX adds soy sauce_ is unlikely to be the cause of _Food is bad_ due to implicit temporal constraint. To facilitate consistent reasoning on EVKGs, we propose Complex Eventuality Query Answering (CEQA), a more rigorous definition of CQA that considers the implicit logical constraints governing the temporal order and occurrence of eventualities. In this manner, we propose to leverage theorem provers for constructing benchmark datasets to ensure the answers satisfy implicit logical constraints. We also propose a Memory-Enhanced Query Encoding (MEQE) approach to significantly improve the performance of state-of-the-art neural query encoders on the CEQA task.

## 1 Introduction

Querying knowledge graphs (KGs) can support many real applications, such as fact-checking and question-answering. Using deep learning methods to answer logical queries over KGs can naturally leverage the inductive reasoning and generalization ability of learning methods to overcome the sparsity and incompleteness of existing KGs, and thus has attracted much attention recently, which are usually referred to as Complex Query Answering (CQA) . As the computational complexity of answering complex logical queries increases exponentially with the length of the query , brute force search and sub-graph matching algorithms  are unsuitablefor processing complex queries. To overcome these challenges, various techniques, such as query encoding  and query decomposition , have been proposed. These techniques enable effective and scalable reasoning on incomplete KGs and facilitate the processing of complex queries.

Most of the existing work in this field has primarily focused on entity-centric KGs that only describe entities and their relationships. As Yoshua Bengio described in his view2 of moving from System I to System II , we need to equip machine learning systems with logical, sequential reasoning, and other abilities. Particularly, such a system requires the understanding of how actions (including events, activities, or processes) interact with changes in distribution which can be reflected by states. Here we can summarize events, activities, and states as a linguistic term, eventualities (or situations), according to the linguistics literature . As with many other KG querying tasks, querying eventuality-centric knowledge graphs can also support many applications, such as providing references for making logical and rational decisions of intuitive inferences or eventual planning. This requires the CQA models to perform reasoning at the eventuality level. To provide resources for achieving eventuality-level reasoning, recently constructed KGs, such as ATOMIC , Knowlywood , and ASER , tend to use one or more discourse relations to represent the relationships between eventuality instances. For example, _PersonX went to the store_ and _PersonX bought some milk_ are two simple eventuality instances, with the latter being a possible consequence of the former. The construction of these EVentuality-centric Knowledge Graphs (EVKGs) thoroughly maps the relationships between eventualities and enables us to reason about eventuality instances and their relationships using logical queries, thereby facilitating a more comprehensive approach to modeling complex relationships than traditional knowledge graphs.

Aside from the importance of querying EVKGs, reasoning on EVKG also significantly differs from that on an entity-centric KG because eventualities involve considering their occurrences and order. In entity-centric KGs, as shown in Figure 1\(q_{1}\), the vertices represent entities such as _Alzheimer_ or _Mad Cow Disease_, and truth values are assigned to the edges between entities to indicate their relationships. For example, the statement \((Beta-amyloid,Alzheimer)\) is true. In contrast, during the reasoning process on EVKG, the eventualities may or may not occur, and determining their occurrence is a crucial part of the reasoning. For instance, given \((PersonX\,go\,home,PersonX\,buy\,umbrella)\) in Figure 1\(q_{2}\), it implicitly suggests that "PersonX go home" occurs, while "PersonX buy umbrella" does not. Moreover, there are relationships that explicitly or implicitly describe the order of occurrences, such as temporal and causal relations. For example, \((PersonX\,study\,hard,PersonX\,pass\,exam)\) indicates the causality between "PersonX pass the exam" and "PersonX study hard," which also implies that "PersonX pass the exam" occurs after "PersonX study hard." When multiple edges are presented in a given situation, it is essential to ensure that there are no contradictions regarding the occurrence of these eventualities. For example, in Figure 1\(q_{3}\), \((PersonX\,go\,home,PersonX\,buy\,umbrella)(PersonX\,go\,home,PersonX\,buy\,umbrella)\) is contradictory because the former suggests that PersonX did not buy an umbrella, while the latter implies otherwise.

To enable complex reasoning on eventuality knowledge graphs, we formally define the problem of complex eventuality query answering (CEQA). CEQA is a more rigorous definition of CQA on EVKG that consider not only the explicitly given relational constraints, but also the implicit logical constraints on the occurrences and temporal order of eventualities. The implicit constraints are derived from the relational constraints and can be further divided into two types: _occurrence constraints_ and _temporal constraints_. Incorporating these implicit constraints into complex query answers drastically

Figure 1: Complex query examples and corresponding interpretations in natural language. \(q_{1}\) is a query on an entity knowledge graph, while \(q_{2}\) and \(q_{3}\) are queries on an eventuality knowledge graph.

changes the nature of the reasoning process. Unlike conventional CQA, the reasoning process of CEQA is defeasible because when additional knowledge is presented, the original reasoning could be weakened and overturned . For example, we showed in Figure 2, _PersonX adds soy sauce_ is a possible answer to the query _What is the reason for food being bad_. However, if more knowledge is given, like _Food is bad_ is before _PersonX adds soy sauce_, then it cannot be the proper reason anymore due to temporal constraints. However, all the existing methods for CQA cannot incorporate additional knowledge to conduct defeasible reasoning in CEQA.

To address this problem, we propose the method of memory-enhanced query encoding (MEQE). In the MEQE method, we first separate the logic terms in a query into two categories, computational atomics and informational atomics. Computational atomics, like \((Food\ is\ bad,V_{?})\), contains at least one variable in their arguments, and informational atomics, like \((Food\ is\ bad,PersonX\ add\ soy\ sauce)\), does not contain variables. For the computational atomics, following previous work, we construct the corresponding computational graph to recursively compute its query embedding step-by-step. For the informational atomics, we put them into a key-value memory module. For each of the informational atomics, its head argument is used as the memory key, and its relation type and tail arguments are used as memory values. In the query encoding process, after each operation in the computational graph, a relevance score is computed between the query embedding and memory heads. This relevance score is then used to retrieve the corresponding memory values of the corresponding relation and tail. Then these memory values are aggregated, adjusted, and added back to the query embedding. By doing this, the query encoder is able to leverage implicit logical constraints that are given by the informational atomics. We evaluate our proposed MEQE method on the eventuality knowledge graph, ASER, which involves fourteen types of discourse relations between eventualities. Experiment results show that our proposed MEQE is able to consistently improve the performance of four frequently used neural query encoders on the task of CEQA. Code and data are publicly available 3.

## 2 Problem Definition

In this section, we first introduce the definitions of the complex queries on entity-centric and eventuality-centric KGs. Then we give the definition of implicit logical constraints and the informational atomics that specifically provide such constraints to the eventuality queries.

### Complex Queries

Complex query answering is conducted on a KG: \(=(,)\). The \(\) is the set of vertices \(v\), and the \(\) is the set of relation \(r\). The relations are defined in functional forms to describe the logical expressions better. Each relation \(r\) is defined as a function with two arguments representing two vertices, \(v\) and \(v^{}\). The value of function \(r(v,v^{})=1\) if and only if there is a relation between the vertices \(v\) and \(v^{}\).

In this paper, the queries are defined in conjunctive forms. In such a query, there are logical operations such as existential quantifiers \(\) and conjunctions \(\). Meanwhile, there are anchor eventualities \(V_{a}\), existential quantified variables \(V_{1},V_{2},...V_{k}\), and a target variable \(V_{?}\). The query

Figure 2: Complex eventuality queries with their implicit temporal and occurrence constraints

is written to find the answers \(V_{?}\), such that there exist \(V_{1},V_{2},...V_{k}\) satisfying the logical expression:

\[q[V_{?}]=V_{?}. V_{1},...,V_{k}:=e_{1} e_{2}... e_{m}.\] (1)

Each \(e_{i}\) is an atomic expression in any of the following forms: \(e_{i}=r(v_{a},V)\), or \(e_{i}=r(V,V^{})\). Here \(v_{a}\) is an anchor eventuality, and \(V,V^{}\{V_{1},V_{2},...,V_{k},V_{?}\}\) are distinct variables.

### Complex Eventuality Queries

For complex eventuality queries, they can also be written in the form of a conjunctive logical expression as Eq. (1). Differently, each atomic \(e_{i}\) can all be in the form of \(e_{i}=r(v_{i},v_{j})\), where \(v_{i},v_{j} V\) are given eventualities. These atomics, which do not include variables, are called informational atomics, because they only provide implicit constraints.

The relations \(r\) in CEQA are discourse relations, and they exert implicit constraints over the eventualities, and these constraints can be categorized into occurrence constraints and temporal constraints. Suppose the occurrence and temporal constraints derived from the \(i\)-th atomic \(e_{i}\) is denoted as \(o_{i}\) and \(t_{i}\). Then complex eventuality query, including its implicit constraints can be written as

\[q[V_{?}]=V_{?}. V_{1},...,V_{k}:=(e_{1}... e_{m})(o_ {1}... o_{m})(t_{1}... t_{m}).\] (2)

The constraints brought from each type of discourse relations are presented in Table 1. Further justifications of the derivation process are given in the Appendix B.

#### 2.2.1 Occurrence Constraints

The occurrence constraints determine whether certain eventuality occurs or not. For instance, consider Figure 2 (A), where the logical query means that _Instead of buying an umbrella, PersonX goes home. What occurred before PersonX went home?_ If we rely solely on relational constraints, as in the conventional definition of CQA, the answers are only determined by the latter part of the query, _What happened before PersonX went home?_ Consequently, _PersonX buys an umbrella_ could be a solution to this query. However, within the query, there is an information atomic saying, _instead of buying an umbrella, PersonX goes home_, which denies the occurrence of _PersonX buying an umbrella._ To formally express such constraint, we use the function \((V)\). If eventuality \(V\) occurs, then \((V)=\), otherwise it is False. As depicted in Figure 2, the occurrence constraint of this query comprises the terms \((V_{?})(PersonX\;buy\;umbrella)\). In this case, \(V_{?}\) cannot be _PersonX buys an umbrella_ or there is an contradiction.

Most discourse relations assume the occurrence of the argument eventualities, for example, Precedence, Conjunction, and Reason. However, there are also relations that do not imply the occurrence of the arguments, such as Condition and Restatement. Moreover, the Exception and ChosenAlternative relations restrict certain eventualities from happening. For instance, in the

   \))} &  &  \\  & & Occurrence Constraints (\(o_{i}\)) & Temporal Constraints (\(t_{i}\)) \\  Precedence(\(V_{1},V_{2}\)) & \(V_{1}\) occurs before \(V_{2}\) & \((V_{1})(V_{2})\) & \((V_{1})(V_{2})\) \\ Biocausal(\(V_{1},V_{2}\)) & \(V_{1}\) occurs after \(V_{2}\) happens & \((V_{1})(V_{2})\) & \((V_{1})(V_{2})\) \\ Synchronous(\(V_{1},V_{2}\)) & \(V_{1}\) occurs at the same time as \(V_{2}\). & \((V_{1})(V_{2})\) & \((V_{1})(V_{2})\) \\  Reason(\(V_{1},V_{2}\)) & \(V_{1}\) occurs because \(V_{2}\) & \((V_{1})(V_{2})((V_{1})(V_{2}))\) & \((V_{1})(V_{2})\) \\ Result(\(V_{1},V_{2}\)) & \(V_{1}\) occurs as result \(V_{2}\) & \((V_{1})(V_{2})((V_{1})(V_{2}))\) & \((V_{1})(V_{2})\) \\ Condition(\(V_{1},V_{2}\)) & \(V_{1}\) occurs occurs, \(V_{1}\) & \((V_{1})(V_{2})\) & \((V_{1})(V_{2})\) \\  \((V_{1},V_{2})\) & \(V_{2}\) occur, although \(V_{1}\). & \((V_{1})(V_{2})\) &. \\  \((V_{1},V_{2})\) & \(V_{2}\) occurs, but \(V_{1}\). & \((V_{1})(V_{2})\) &. \\  \((V_{1},V_{2})\) & \(V_{1}\) and \(V_{2}\) both occur. & \((V_{1})(V_{2})\) &. \\ \((V_{1},V_{2})\) & \(V_{2}\) is a more detailed description of \(V_{1}\). & \((V_{1})(V_{2})\) &. \\ \((V_{1},V_{2})\) & \(V_{1}\) rotates the semantics of \(V_{2}\). & \((V_{1})(V_{2})\) &. \\ \((V_{1},V_{2})\) & \(V_{1}\) and \(V_{2}\) are alternative windows. & \((V_{1})(V_{2})\) &. \\ \((V_{1},V_{2})\) & \(\) for \(V_{2}\) occurs, \(V_{1}\) & \((V_{1})(V_{2})((V_{2})(V_{1}))\) &. \\  \((V_{1},V_{2})\) & \(V_{1}\): except \(V_{2}\). & \((V_{1})(V_{2})((V_{2})(V_{1}))\) &. \\   

Table 1: The discourse relations and their implicit logical constraints. \((V)\) is True if and only if \(V\) occurs. \((V)\) indicates the happening timestamp of \(V\). Meanwhile, the instance-based temporal logic operator \(,\), or \(=\) means \(V_{1}\) is before, after, or at the same time as \(V_{2}\).

case of \((PersonX\,read\,books,\,PersonX\,play\,games)\), it implies that PersonX reads books: \((PersonX\,read\,books)\), and does not play games: \((PersonX\,play\,games)\). Another example is \((Room\,is\,empty,\,PersonX\,stay\,in\,room)\), which implies that the room is not empty and PersonX is present in the room. Furthermore, if PersonX is not in the room, then the room is empty. This can be formally expressed as \((Room\,is\,empty)(PersonX\,stay\,in\,room)(( PersonX\,stay\,in\,room)\,(Room\,is\,empty))\). For a comprehensive overview of the occurrence constraints, please refer to Table 1.

#### 2.2.2 Temporal Constraints

The temporal constraints reflect the order of occurrence of the eventualities. As shown in Figure 2 (B), the complex query on the eventuality knowledge graph can be interpreted as _Food is bad before PersonX adds soy sauce. What is the reason for food being bad?_ If we only considered the relational constraints, like in the conventional setting of CQA, then _PersonX adds soy sauce_ is a possible answer. However, in the definition of CEQA, the answer _PersonX adds soy sauce_ is incorrect because the food is bad already occurred before _PersonX added soy sauce_, but something that occurs later is impossible to be the reason for something that previously occurred. Formally, we use the expression of temporal logic \(\), \(\), and \(=\) to describe the temporal order between two eventualities . \((A)(B)\) means \(A\) occurs before \(B\), and \((A)=(B)\) means they happen at the same time, and \((A)(B)\) means \(A\) occurs after \(B\). For example in Figure 2 (B), the temporal constraint is represented by \((Food\,is\,bad)(PersonX\,add\,so\,save)(Food\,is\,bad) (V_{})\), which can be interpreted as _Food is bad_ is before _PersonX adds soy sauce_ and \(V_{}\) is before _Food is bad_. Because of this, \(V_{}\) cannot _PersonX adds soy sauce_, otherwise there exists a contradiction.

The temporal relations \((A,B)\), \((A,B)\), and \((A,B)\) naturally describes the temporal constraint. Meanwhile, previous studies also assume that causation implies precedence , With this assumption, the temporal constraints can also be derived from relations like \(\) and \(\). The descriptions of temporal constraints are given in Table 1.

## 3 Memory-Enhanced Query Encoding

In this section, we first introduce the method of query encoding, and then introduce how to use the memory module to represent the informational atomics to conduct reasoning on EVKGs.

Figure 3: An example complex eventuality query with the computational and informational atomics. \(V\) is something that happens before a person complains and leaves the restaurant, according to the KG, the \(V\) could be either _Service is bad_ or _Food is bad_. If \(V_{}\) is the reason of \(V\), then according to the graph, \(V_{}\) could be either _Staff is new_, _PersonY adds ketchup_, _PersonY adds soy sauce_, and _PersonY adds vinegar_. However, in the query we also know that _PersonY adds vinegar_ does not happen, and _PersonY adds soy sauce_ happens after the _Food is bad_, thus cannot be the reason for _Food is bad_. The conflict here is causality implies precedence.

### Computational Graph and Query Encoding

Figure 3 and 4 show that there is a computational graph for each query. This computational graph is a directed acyclic graph (DAG) that consists of nodes and edges representing intermediate encoding states and neural operations, respectively. By recursively encoding the sub-queries following the computational graph, the operations implicitly model the set operations of the intermediate query results. The set operations are defined as follows: (1) _Relational Projection_: Given a set of vertices \(A\) and a relation \(r R\), the relational projection operation returns all eventualities that hold the relation \(r\) with at least one entity \(e A\). This can be expressed as: \(P_{r}(A)=\{v v^{} A,r(v^{},v)=1\}\); (2) _Intersection_: Given sets of eventualities \(A_{1},,A_{n}\), the intersection computes the set that is the subset to all of the sets \(A_{1},,A_{n}\). This can be expressed as \(_{i=1}^{n}A_{i}\).

Various query encoding methods are proposed to recursively encode the computational graph. However, the query embeddings of these methods can be translated into \(d\)-dimensional vectors. As shown in Figure 4, the computations along the computation graph start with the anchor eventualities, such as _PersonX complains_. Suppose the embedding of an anchor \(v\) is denoted as \(e_{v} R^{d}\). Then, the initial query embedding is computed as \(q_{0}=e_{v}\). As for the _relational projection_ operation, suppose the \(e_{rel} R^{d}\) is the embedding vector of the relation \(rel\). The relation projection \(F_{proj}\) is expressed as

\[q_{i+1}=F_{proj}(q_{i},e_{rel}),\] (3)

where the \(q_{i}\) and \(q_{i+1}\) are input and output query embeddings for this relational projection operation.

Meanwhile, for the _Intersection_ operations, suppose there are \(k\) embeddings of sub-queries, \(q_{i}^{(1)},q_{i}^{(2)},...,q_{i}^{(k)}\), as the input for this operation, then the output can be expressed as:

\[q_{i+1}=F_{inter}(q_{i}^{(1)},q_{i}^{(2)},...,q_{i}^{(k)}),\] (4)

where the \(F_{inter}\) is a neural network that is permutation-invariant to the input sub-query embeddings adopted from the backbone models [23; 5; 1; 12].

### Memory-Enhanced Query Encoding

The computational graph is capable of encoding computational atomics presented in the logical expression. However, informational atomics can influence the reasoning outcomes by introducing implicit temporal or occurrence constraints. As depicted in Figure 3, the absence of informational atomics results in two false answers from the knowledge graph. When informational atomics are included, providing implicit constraints, the only two correct answers can be derived.

Based on this observation, we propose using a memory module to encode the constraint information provided by the informational atomics. Suppose that there are \(M\) informational atomics in the query. Their head embeddings, relation embeddings, and tail embeddings are represented as \(c_{h}^{(m)},c_{r}^{(m)}\), and \(c_{t}^{(m)}\) respectively. For each operator output \(q_{i}\) from the computational graph, we compute its relevance score \(s_{i,m}\) towards each head eventuality \(m\),

\[s_{i,m}=<q_{i},c_{h}^{(m)}>.\] (5)

Then we use the \(s_{i,m}\) to access the values from the constraint relation and tails, and then aggregate the memory values according to the relevance scores

\[v_{i}=_{m=1}^{M}s_{i,m}(c_{r}^{(m)}+c_{t}^{(m)}).\] (6)

Figure 4: The example computational graph and the memory-enhanced query encoding process.

Finally, as shown in Figure 4, the constraint values are added back to the query embedding after going through a feed-forward layer FFN, and this process is described by

\[q_{i}=q_{i}+(v_{i}).\] (7)

### Learning Memory-Enhanced Query Encoding

To train the model, we compute the normalized probability of \(v\) being the correct answer to query \(q\) by applying the softmax function to all similarity scores:

\[p(q,v)=>}}{_{v^{} V}e^{<q,e_{v^{}>}}},\] (8)

where \(<,>\) denotes the dot product of two vectors, when \(q\) is the query embedding after the last operation. A cross-entropy loss is used to maximize the log probabilities of all correct answer pairs:

\[=-_{i=1}^{N} p(q^{(i)},v^{(i)}),\] (9)

where \((q^{(i)},v^{(i)})\) denotes one of the positive query-answer pairs, and \(N\) is the total number of them.

## 4 Experiments

To ensure a fair comparison of various methods for the CEQA problem, we generated a dataset by sampling from ASER , the largest eventuality knowledge graph, which encompasses fourteen types of discourse relations. The division of edges within each knowledge graph into training, validation, and testing sets was performed in an 8:1:1 ratio, as illustrated in Table 5. The training graph \(_{train}\), validation graph \(_{val}\), and test graph \(_{test}\) were constructed using the training edges, training+validation edges, and training+validation+testing edges, respectively, following the established configuration outlined in prior research by . Moreover, we conducted evaluations using different reasoning models, consistent with settings in previous studies.

### Query Sampling with Theorem Prover

We employ the sampling algorithm proposed by  with the conjunctive query types outlined in . Specifically, for the training dataset, we sample queries that have a maximum of two anchor nodes, while for the validation and test sets, we select queries containing up to three anchor eventualities. The query types in our framework reflect the structure of the computational graph and are represented using a Lisp-like format [46; 7]. Once the query-answer pairs are sampled, we randomly select up to three edges that share common vertices with the reasoning chain of the query-answer pairs. These selected edges are then used as the informational atomics for the corresponding query. Subsequently, we employ the z3 prover  to filter the queries. We retain only those queries where the informational atomics incorporate effective implicit constraints, ensuring the presence of meaningful constraints in the data. The detailed query types and their numbers of answer with/without contradictions are shown in Table 6, in which the p is for projection, the i is for intersection, and e is for eventuality.

In detail, for each eventuality present on the reasoning path towards an answer in the complex query, we create a corresponding boolean variable in the z3 prover. We then incorporate the relevant

    &  &  &  \\  & & & \#Queries & \#Ans. & \#Contr. Ans. & \#Queries & \#Ans. & \# Contr. Ans. \\  Train & 6 & 124,766 & 5.02 & 1.53 & 35,962 & 5.02 & 1.15 \\ Validation & 15 & 30,272 & 7.68 & 1.75 & 23,905 & 9.17 & 1.44 \\ Test & 15 & 30,243 & 8.40 & 1.81 & 24,226 & 11.40 & 1.50 \\   

Table 2: The dataset details for CEQA. #Ans. reports the number of answers that are proved to be not contradictory by theorem provers. #Contr. Ans. reports the number of answers that can be searched from the ground truth KG, but are contradictory due to the occurrence or temporal constraints.

occurrence constraints based on the relations between these eventualities, as outlined in Table 1, and feed them into the z3 prover. If the result returned by the prover is unsat, it indicates a contradiction in the reasoning process. Regarding temporal constraints, we follow a similar approach. We create corresponding floating variables that represent the timestamps of the occurrence of the eventualities. We then establish constraints on the temporal order by utilizing floating operators such as >, =, or < between the variables. By doing so, for each query, we establish a corresponding linear program. Once again, if the prover outputs unsat, it signifies a contradiction, namely, there is no solution for the timestamps of these events. Queries that have no contradictory answers and queries where all the answers are contradictory are discarded. The remaining queries are then categorized into two types: queries with occurrence constraints and queries with temporal constraints. Table 6 presents the average number of contradictory and non-contradictory answers per query.

### Baselines and Metrics

In this section, we introduce several baseline query encoding models that use different neural network architectures to parameterize the operators in the computational graph and recursively encode the query into various embedding structures: (1) GQE  uses vectors to encode complex queries; (2) Q2P  uses multiple vectors to encode queries; (3) Neural MLP  use MLP as the operators; (4) FuzzQE  uses fuzzy logic to represent logical operators.

To define the evaluation metrics, we use \(q\) to represent a testing query, and \(_{val}\) and \(_{test}\) to represent the validation and testing knowledge graphs, respectively. We use \([q]_{val}\) and \([q]_{test}\) to represent the answers to query \(q\) on \(_{val}\) and \(_{test}\), respectively. Eq. (10) shows how to compute the metrics. When the evaluation metric is Hit@K, \(m(r)\) is defined as \(m(r)=[r K]\), where \(m(r)=1\) if \(r K\), and \(m(r)=0\) otherwise. For mean reciprocal ranking (MRR), \(m(r)\) is defined as \(m(r)=\).

\[(q)=/[q]_{val}}m((v))}{ |[q]_{test}/[q]_{val}|}.\] (10)

During the training process, the testing graph \(_{test}\) is unobserved. In the hyper-parameters selection process, we use the same metrics as Eq. (10), but replace the graphs \(_{test}/_{val}\) with \(_{val}/_{train}\).

### Details

To ensure fair comparisons, we replicate all the models under a unified framework. We use the same number of embedding sizes of three hundred for all models and use grid-search to tune the hyperparameters of the learning rate ranging from \(\{0.002,0.001,0.0005,0.0002,0.0001\}\) and batch size ranging from \(\{128,256,512\}\). All the experiments can be run on NVIDIA RTX3090 GPUs. Experiments are repeated three times, and the averaged results are reported.

    &  &  &  \\  & Hit@1 & Hit@3 & MRR & Hit@1 & Hit@3 & MRR & Hit@1 & Hit@3 & MRR \\  GQE & 8.92 & 14.21 & 13.09 & 9.09 & 14.03 & 12.94 & 9.12 & 14.12 & 13.02 \\ + MEQE & **10.20** & **15.54** & **14.31** & **10.70** & **15.67** & **14.50** & **10.45** & **15.60** & **14.41** \\  Q2P & 14.14 & 19.97 & 18.84 & 14.48 & 19.69 & 18.68 & 14.31 & 19.83 & 18.76 \\ + MEQE & **15.15** & **20.67** & **19.38** & **16.06** & **20.82** & **19.74** & **15.61** & **20.74** & **19.56** \\  Nerual MLP & 13.03 & 19.21 & 17.75 & 13.45 & 19.06 & 17.68 & 13.24 & 19.14 & 17.71 \\ + MEQE & **15.26** & **20.69** & **19.32** & **15.91** & **20.63** & **19.47** & **15.58** & **20.66** & **19.40** \\  FuzzQE & 11.68 & 18.64 & 17.07 & 11.68 & 17.97 & 16.53 & 11.68 & 18.31 & 16.80 \\ + MEQE & **14.76** & **21.12** & **19.45** & **15.31** & **21.01** & **19.49** & **15.03** & **21.06** & **19.47** \\   

Table 3: Experiment results of different query encoding models. In this experiment, we compare the performance of the query encoder with or without the memory-enhanced query encoding method.

### Experiment Results

Table 3 presents the results of the main experiment, which compares different query encoding models with and without MEQE. The table includes the performance metrics of Hit@1, Hit@3, and MRR for both occurrence constraints and temporal constraints, along with the average scores across all categories. The experimental results demonstrate that our proposed memory-enhanced query encoding (MEQE) model consistently improves the performance of existing query encoders in complex eventuality query answering. We conduct experiments on four commonly used query encoders, and the MEQE model, leveraging the memory model depicted in Figure 4, outperforms the baselines. The MEQE models differ structurally from the baseline models by incorporating a memory module that contains informational atomics. By reading this memory module, MEQE effectively incorporates implicit constraints from these atomics, leading to improved performance.

Additionally, we observed that combining MEQE with the Q2P  model yields the best average performance across three metrics: Hit@1, Hit@3, and MRR. Furthermore, on average, MEQE enhances the Hit@1 metric by 17.53% and the Hit@3 metric by 9.53%. The greater improvement in the Hit@1 metric suggests that the model's ability to accurately predict the top-ranked answer has improved more significantly compared to predicting answers within the top three rankings. Moreover, MEQE demonstrates a 13.85% improvement in performance on queries with temporal constraints and an 11.15% improvement on occurrence constraints. This indicates that MEQE is particularly effective in handling temporal constraints compared to occurrence constraints.

Table 4 displays the Hit@3 and MRR results of various types of complex queries. The table demonstrates the superiority of MEQE over the baseline models across different query types. Furthermore, the table indicates that, on average, MEQE achieves an improvement of 8.1% and 11.6% respectively. This suggests that MEQE is particularly adept at handling queries with multiple eventualities.

## 5 Related Work

Complex query answering is a task in deductive knowledge graph reasoning, where a system or model is required to answer a logical query on an incomplete knowledge graph. Query encoding  is a fast and robust method for addressing complex query answering. Various query embedding methods

    &  &  &  &  &  &  \\  & & & Base. & MEQE & Base. & MEQE & Base. & MEQE & Base. & MEQE \\   & (p,(a,p),(p,(c))) & Hit@3 & 12.97 & **13.76** & 17.74 & **18.88** & 15.93 & **17.32** & 15.23 & **18.02** \\  & & MRR & 11.86 & **12.75** & 16.90 & **18.35** & 15.31 & **16.51** & 14.38 & **16.58** \\   & (p,(a,p),(p,(c))) & Hit@3 & 33.52 & **34.84** & **44.65** & 39.54 & 38.49 & **42.09** & **43.71** & 39.77 \\  & & MRR & 30.53 & **32.80** & **39.79** & 34.47 & 35.02 & **35.16** & **36.92** & 36.53 \\   & (p,(a,p),(p,(c))) & Hit@3 & 12.40 & **12.42** & 15.22 & **15.96** & 15.03 & **15.69** & 15.56 & **16.45** \\  & & MRR & **11.46** & 11.38 & 14.36 & **15.25** & 14.21 & **14.74** & 14.82 & **15.36** \\   & (p,(a,p))-(p,(c))) & Hit@3 & 14.16 & **14.87** & 14.79 & **19.86** & 17.06 & **19.87** & 16.58 & **18.65** \\  & (p,(a,p))-(p,(c))) & MRR & 13.16 & **13.19** & 16.48 & **18.89** & 15.49 & **18.27** & 14.69 & **17.22** \\   & (p,(a,p),(p,(c))) & Hit@3 & 14.63 & **18.02** & 25.67 & **26.17** & 23.93 & **24.34** & 18.58 & **26.31** \\  & & MRR & 13.47 & **16.95** & 24.38 & **25.13** & 22.63 & **23.41** & 17.72 & **24.92** \\    & (p,(a,p),(p,(c))) & Hit@3 & 17.20 & **20.63** & 22.52 & **22.92** & 22.32 & **23.39** & 22.67 & **24.33** \\   & (p,(a,p),((a,p),(p,(c)))) & MRR & 15.63 & **19.61** & 21.67 & **21.93** & 21.73 & **22.67** & 21.51 & **23.01** \\    & (p,(a,p),((c)))-(p,(c))) & Hit@3 & 24.66 & **28.11** & **45.10** & 44.12 & 40.28 & **40.62** & 47.14 & **47.56** \\   & (p,(a,p),((c)))-(p,(c))) & MRR & 22.57 & **24.22** & **40.14** & 37.87 & 35.71 & **36.70** & 40.95 & **41.65** \\    & (p,(a,p),((c)))-(p,(c))) & Hit@3 & 13.17 & **13.31** & **17.06** & 16.72 & 18.04 & **15.80** & 16.62 & **18.31** \\    & (p,(a,p))-(p,(c))) & Hit@3 & 11.81 & **12.38** & **17.00** & 16.44 & 16.86 & **17.42** & 15.88 & **17.24** \\    & (p,(a,p))-(p,(c))) & Hit@3 & 16.94 & **16.93** & 22.26 & **22.94** & 21.66 & **23.85** & 19.70 & **22.65** \\    & (p,(a,p),((c)))-(p,(c)))) & MRR & 15.62 & **17.59** & 20.76 & **21.60** & 20.345 & **22.29** & **17.52** & **21.70** \\    & (p,(a,p),((c)))-(p,((c)))) & Hit@3 & 16.23 & **19.75** & 24.45 & **25.59** & 23.39 & **25.45** & 22.33 & **25.63** \\    & (p,(a,p))-(p,((c))))) & MRR & 15.05 & **18.36** & 23.30 & **24.15** & 21.60 & **24.26** & 20.87 & **24.00** \\    & (p,(a,p))-(p,((a)))) & Hit@3 & 20.43 & **23.08** & **34.52** & **36.44** & 36.56 & **24.20** & 35.88 & **41.80** \\    & (p,(a,p))-(p,((a))))) & Hit@3 & 19.26 & **21.74** & 31.91 & **33.45** & 32.46 & **37.41** & 33.74 & **36.65** \\    & (p,(a,p))-(p,((a))))) & Hit@3 & 13.29 & **15.05** & 20.08 & **20.87** & 21.79 & **22.94** & 19.65 & **22.81** \\    & (p,(a,p),((c)))-(p,((c))))) & MRR & 12.34 & **14.04** & 19.31 & **19.81** & 19.57 & **21.65** & 17.85 & **21.37** \\    & (p,(a,p))-(p,((a))))) & Hit@3 & 15.64 & **17.67** & 22.63 & **25.10** & 22.97 & **24.50** & 20.22 & **25.44** \\    & (p,(a,p))-(p,((a))))) & MRR & 14.54 & **16.39** & 21.08 & **23.13** & 20utilize different structures to encode logical KG queries, enabling them to handle different types of logical queries. The GQE method, introduced by Hamilton et al. , represents queries as vector representations to answer conjunctive queries. Ren et al.  employed hyper-rectangles to encode and answer existential positive first-order (EPFO) queries. Simultaneously, Sun et al.  proposed the use of centroid-sketch representations to enhance the faithfulness of the query embedding method for EPFO queries. Both conjunctive queries and EPFO queries are subsets of first-order logic (FOL) queries. The Beta Embedding  is the first query embedding method that supports a comprehensive set of operations in FOL by encoding entities and queries into probabilistic Beta distributions. Moreover, Zhang et al.  utilized cone embeddings to encode FOL queries. Meanwhile, there are also neural-symbolic methods for query encoding. Xu et al.  proposes an entangled neural-symbolic method, ENeSy, for query encoding. Wang et al.  propose using pre-trained knowledge graph embeddings and one-hop message passing to conduct complex query answering. Additionally, Yang et al.  propose using Gamma Embeddings to encode complex logical queries. Finally, Liu et al.  propose pre-training on the knowledge graph with kg-transformer and then fine-tuning on the complex query answering. Recently, Bai et al.  proposes to use sequence encoders to encode the linearized computational graph of complex queries. Galkin et al.  propose to conduct inductive logical reasoning on KG, and Zhu et al.  proposes GNN-QE to conduct reasoning on KG with message passing on the knowledge graph. Meanwhile, Bai et al.  formulate the problem of numerical CQA and propose the corresponding query encoding method of NRN.

Another approach to addressing complex knowledge graph queries is query decomposition . In this research direction, the probabilities of these atomic queries are modeled using link predictors, and then an inference time optimization is used to find the answers. In addition, an alternative to query encoding and query decomposition is proposed by Wang et al. . They employ message passing on one-hop atomic queries to perform complex query answering. A recent neural search-based method called QTO is introduced by Bai et al. , which has shown impressive performance in complex question answering (CQA). Theorem proving is another deductive reasoning task applied to knowledge graphs. Neural theorem proving methods [39; 31; 32] have been proposed to tackle the incompleteness of KGs by using embeddings to conduct inference on missing information.

## 6 Limitation

Although our experiments demonstrate that MEQE improves the performance of existing models on the CEQA task, the evaluation is conducted on specific benchmark datasets constructed with theorem provers from the largest general-domain eventuality graph ASER . The generalizability of the proposed approach to specific or professional fields may require further investigation and evaluation.

## 7 Conclusion

In this paper, we introduced complex eventuality query answering (CEQA) as a more rigorous definition of complex query answering (CQA) for eventuality knowledge graphs (EVKGs). We addressed the issue of implicit logical constraints on the occurrence and temporal order of eventualities, which had not been adequately considered in the existing definition of CQA. To ensure consistent reasoning, we leveraged theorem provers to construct benchmark datasets that enforce implicit logical constraints on the answers. Furthermore, we proposed constraint memory-enhanced query encoding with (MEQE) to enhance the performance of state-of-the-art neural query encoders on the CEQA task. Our experiments showed that MEQE significantly improved the performance of existing models on the CEQA task. Overall, our work provides a more comprehensive and effective solution to the complex query-answering problem on eventuality knowledge graphs.

## 8 Acknowledgments

The authors of this paper were supported by the NSFC Fund (U20B2053) from the NSFC of China, the RIF (R6020-19 and R6021-20) and the GRF (16211520 and 16205322) from RGC of Hong Kong. We also thank the support from the UGC Research Matching Grants (RMGS20EG01-D, RMGS20CR11, RMGS20CR12, RMGS20EG19, RMGS20EG21, RMGS23CR05, RMGS23EG08).