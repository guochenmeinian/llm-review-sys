# Dissecting the Failure of Invariant Learning on Graphs

Qixun Wang\({}^{1}\)  Yifei Wang \({}^{2}\)  Yisen Wang \({}^{1,3}\)1  Xianghua Ying \({}^{1}\)

\({}^{1}\) State Key Laboratory of General Artificial Intelligence,

School of Intelligence Science and Technology, Peking University

\({}^{2}\) CSAIL, MIT

\({}^{3}\) Institute for Artificial Intelligence, Peking University

###### Abstract

Enhancing node-level Out-Of-Distribution (OOD) generalization on graphs remains a crucial area of research. In this paper, we develop a Structural Causal Model (SCM) to theoretically dissect the performance of two prominent invariant learning methods--Invariant Risk Minimization (IRM) and Variance-Risk Extrapolation (VREx)--in node-level OOD settings. Our analysis reveals a critical limitation: due to the lack of class-conditional invariance constraints, these methods may struggle to accurately identify the structure of the predictive invariant ego-graph and consequently rely on spurious features. To address this, we propose Cross-environment Intra-class Alignment (CIA), which explicitly eliminates spurious features by aligning cross-environment representations conditioned on the same class, bypassing the need for explicit knowledge of the causal pattern structure. To adapt CIA to node-level OOD scenarios where environment labels are hard to obtain, we further propose CIA-LRA (Localized Reweighting Alignment) that leverages the distribution of neighboring labels to selectively align node representations, effectively distinguishing and preserving invariant features while removing spurious ones, all without relying on environment labels. We theoretically prove CIA-LRA's effectiveness by deriving an OOD generalization error bound based on PAC-Bayesian analysis. Experiments on graph OOD benchmarks validate the superiority of CIA and CIA-LRA, marking a significant advancement in node-level OOD generalization. The codes are available at https://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs.

## 1 Introduction

Generalizing to unseen testing distributions that differ from the training distributions, known as Out-Of-Distribution (OOD) generalization, is one of the key challenges in machine learning. Invariant learning, which aims to capture predictive features that remain consistent under distributional shifts, is a crucial strategy for addressing OOD generalization. Numerous invariant learning methods have been proposed to tackle OOD problems in computer vision (CV) tasks . While in recent years, enhancing OOD generalization on graph data is an emerging research direction attracting increasing attention. In this work, we focus on the challenge of node-level OOD generalization on graphs.

Straightforwardly adapting the above methods to node-level graph OOD scenarios presents several challenges: 1) the prediction of a node's label depends on its neighbored samples in an ego-subgraph, causing a gap from conventional CV OOD scenarios where samples are independently predicted; and 2) environment labels in node-level tasks are often unavailable .

Liu et al., 2023), rendering invariant learning methods based on environment partitioning infeasible. To illustrate the failure of directly adapting traditional invariant learning to graphs, we evaluate two representative OOD approaches, Invariant Risk Minimization (IRM (Arjovsky et al., 2020)) and Variance-Risk Extrapolation (VREx (Krueger et al., 2021)), in OOD node classification scenarios. We choose IRM and VREx for two reasons: 1) Numerous node-level graph OOD strategies (Zhang et al., 2021; Wu et al., 2021; Liu et al., 2023; Tian et al., 2024) utilize VREx as invariance regularization (details in Appendix A.2). Therefore, analyzing VREx can cover a significant portion of graph-OOD methods; and 2) IRM and VREx are two prominent OOD methods that we can theoretically prove to be effective on non-graph data (Proposition 2.2). By testing their performance on graph data, we can better reveal the differences between graph and non-graph data. We choose real-world graph datasets: Arxiv, Cora, and WebKB; synthetic datasets: CBAS and a toy graph OOD dataset with spurious correlations between node features and labels for evaluation. From Table 1, we observe that IRM and VREx offer marginal or no improvement over ERM on both real-world and synthetic node-level graph OOD datasets. This naturally raises some questions here:

_On graphs, why do traditional invariant learning methods fail? How to make them work again?_

To theoretically analyze their failure modes, we build a Structural Causal Model (SCM) to model the data generation process under two types of distributional shifts: concept shift and covariate shift, and gain a high-level understanding of the challenges in node-level OOD generalization: To correctly predict a node's label, the structure of a predictive invariant neighboring egograph (which we call it a _causal pattern_) and their invariant node features must be learned. However, identifying the correct structure of the causal pattern presents additional optimization requirements (compared to CV scenarios) for Graph Neural Networks (GNNs) since they must adjust the aggregation parameters (such as the attention weights in GAT (Velickovic et al., 2018)) to achieve this. IRM and VREx lack class-conditional invariance constraints, which causes insufficient supervision for regularizing the training of these aggregation parameters, leading to non-unique solutions of GNN parameters and potentially resulting in the learning of spurious features. (detailed analysis is in Section 2). To overcome this, we propose Cross-environment Intra-class Alignment (**CIA**) that further considers class-conditional invariance to identify causal patterns2. We theoretically demonstrate that by aligning node representations of the same class and different environments, CIA can eliminate spurious features and learn the correct causal pattern, as same-class different-environment samples share similar causal patterns while exhibiting different spurious features. Table 1 shows CIA's empirical gains. To leverage the advantage of CIA and adapt it to scenarios without environment labels, we further propose **CIA-LRA** (Localized Reweighting Alignment), utilizing localized label distribution to find node pairs with significant differences in spurious features and small differences in causal ones for alignment, to eliminate the spurious features while alleviating the collapse of the causal ones. Our contributions are summarized as follows:

1. By constructing an SCM, we provide a theoretical analysis revealing that VREx and IRM could rely on spurious features when using a GAT-like GNN (Section 2.2) in node-level OOD scenarios, revealing a key challenge of invariant learning on graphs.
2. We propose CIA and theoretically prove its effectiveness in learning invariant representations on graphs (Section 3.1). To adapt CIA to node-level OOD scenarios where environment labels are unavailable, we further propose CIA-LRA that requires no environment labels or complex environmental partitioning processes to achieve invariant learning (Section 3.2), with theoretical guarantees on its generalization performance (Section 4).
3. We evaluate CIA and CIA-LRA on the Graph OOD benchmark (GOOD) (Gui et al., 2022) on GAT and GCN (Kipf and Welling, 2016). The results demonstrate CIA's superiority over

  Algorithms & Large-Cov. & Large-Con. & Toy \\  ERM & 57.74 & 59.57 & 33.6 \\  IRM & 57.59 & 59.46 & 34.9 \\  VREx & 58.46 & 59.83 & 33.9 \\  CIA (ours) & 59.68 & 60.89 & 37.0 \\  CIA-LRA (ours) & **61.94** & **63.03** & **39.1** \\  

Table 1: _Real-Cov./Con. are average OOD accuracy on the covariate/concept shift of Arxiv, Cora, CBAS, and WebKB. Toy denotes results on our toy synthetic graph OOD dataset._non-graph invariant learning methods, and CIA-LRA achieves state-of-the-art performance (Section 5.2).

We leave comparisons of our method and existing node-level OOD works in Appendix A.3.

## 2 Dissecting Invariant Learning on Graphs

For OOD node classification, we are given a single training graph \(=(A,X,Y)\) containing \(N\) nodes \(=\{v_{i}\}_{i=1}^{N}\) from multiple training environments \(e_{}\). \(A\{0,1\}^{N N}\) is the adjacency matrix, \(A_{i,j}=1\) iff there is an edge between \(v_{i}\) and \(v_{j}\). \(X^{N D}\) are node features. The \(i\)-th row \(X_{i}^{D}\) represents the original node feature of \(v_{i}\). \(Y\{0,1,...,C-1\}^{N}\) are the labels, \(C\) is the number of the classes. Denote the subgraph containing nodes of environment \(e\) as \(^{e}=(A^{e},X^{e},Y^{e})\), which follows the distribution \(p_{e}\). Let \(A^{e}\{0,1\}^{N^{e} N^{e}}\) and \(D^{e}\) be the adjacency matrix and the diagonal degree matrix for nodes from environment \(e\) respectively, where \(D^{e}_{ii}=_{j=1}A^{e}_{ij}\), \(N^{e}\) is the number of samples in \(e\). Denote the normalized adjacency matrix as \(^{e}=(D^{e}+I_{N^{e}})^{-}A^{e}(D^{e}+I_{N^{e}})^{-}\), \(I_{N^{e}}\) is the identity matrix. Let \(^{e}=+(D^{e}+I_{N^{e}})^{-}I_{N^{e}}(D^{e}+I_{N^{e} })^{-}\). Suppose the unseen test environments are \(e^{}_{}\). The test distribution \(p_{e^{}} p_{e} e^{}_{},\; e _{}\). OOD generalization aims to minimize the prediction error over test distributions.

To understand the obstacles in invariant learning on graphs, we start by examining whether IRMv1 (practical implementation of the original challenging IRM objective, proposed by Arjovsky et al. (2020)) and VREx can be successfully transferred to node-level graph OOD tasks. Their objectives are as follows:

\[&\;_{w,}_{e}[ (w(X^{e}),Y^{e})+\|_{w|w=1.0} (w(X^{e}),Y^{e})\|_{2}^{2}],\\ &\;_{w,}_{e}[(w (X^{e}),Y^{e})]+_{e}[(w (X^{e}),Y^{e})],\] (1)

where \(w\) and \(\) denote the classifier and feature extractor, respectively. \(\) is the cross-entropy loss. \(\) is some hyperparameter.

### A Causal Data Model on Graphs

**Data generation process.** We construct an SCM to characterize two kinds of distribution shifts: concept shift (Figure 0(a)) and covariate shift (Figure 0(b)). \(C\) and \(S\) denote unobservable causal/spurious latent variables that affect the generation of the graph \(G\), and dashed \(E\) are environmental variables usually unobservable. We consider a simple case that each node \(v\) in environment \(e\) has a 2-dim feature \([x_{v}^{1},x_{v}^{2}]^{}\), \(x_{v}^{1},\;x_{v}^{2}\). Denote the concatenated node features of all nodes in \(e\) as \(X_{1}^{N^{e} 1}\) and \(X_{2}^{e}^{N^{e} 1}\) corresponding to \(x_{v}^{1}\) and \(x_{v}^{2}\), respectively. For the SCM in Figure 0(a)3, the data generation process of environment \(e\) is

\[Y^{e}=(})^{k}X_{1}+n_{1},\;X_{2}^{e}=(})^{m}Y^{e}+n_{2 }+^{e},\] (2)

where \(k^{+}\) represents the "depth" (number of hops) of the causal pattern, and \(m^{+}\) is the depth of the ego-graph determining the spurious node features. \(n_{1}^{N^{e} 1}\) and \(n_{2}^{N^{e} 1}\) represent random Gaussian noise. \(^{e}\) stands for an environmental variable, causing the spurious correlations between \(X_{2}^{e}\) and \(Y\). A detailed description of the model is in Appendix F.1.

**How the proposed model considers both node feature shifts and structural shifts? \(X_{1}\)** represent invariant node features causing \(Y^{e}\). \(X_{2}^{e}\) denotes spurious node features that vary with environments. As for structural shifts, we consider an environmental \(}\) in Equation (2), which means the structure can vary with environments. For example, there could be a spurious correlation between certain structures and the label; or, the graph connectivity or size may shift (Buffelli et al., 2022; Xia et al.,

Figure 1: Causal graphs of the SCMs considered in our work.

2023]. We model the invariant structural feature as the structure of a node's \(k\)-layer neighboring ego-graph. See Appendix F.2 for more discussions of the structural shifts.

We also have the following assumption about the stability of the causal patterns across environments:

**Assumption 2.1**.: **(Stability of the causal patterns)** The \(k\)-layer causal pattern in Equation (2) is invariant across environments for every class \(c\).

A simple multi-layer GNN.Consider a \(L\)-layer GNN \(f\) parameterized by \(=\{_{1},_{2},{_{1}^{1}}^{(l)},{_{1}^{2}}^{( l)},{_{2}^{1}}^{(l)},{_{2}^{2}}^{(l)}\}\), \(l=1,2,...,L-1\):

\[f_{}(A,X)=H_{1}^{(L)}_{1}+H_{2}^{(L)}_{2},\ \] (3) \[(H_{1}^{(l)} H_{2}^{(l)})=( {I})(^{1}}^{(l-1)}&{_{2}^{1}}^{(l-1 )}\\ {_{1}^{2}}^{(l-1)}&{_{2}^{2}}^{(l-1)})( ^{(l-1)}}&0\\ 0&{H_{2}^{(l-1)}}),\ l=2,...,L,\ H_{1}^{(1)}=X_{1},\ H_{2}^{(1)}= X_{2},\]

where \(_{i}\) and \({_{j}^{i}}^{(l)}\) are scalars for \(i,j\{1,2\}\), \( l\). \(H_{i}^{(l)}^{N D}\) are GNN representations.

**Remark.** In this GNN, we keep only the top-layer weight matrix \([_{1}\ _{2}]^{}\), and let the weight matrix of lower layers \(1,...,L-1\) be an identity matrix. This architecture resembles an SGC . \(_{1}\) and \(_{2}\) are for invariant/spurious features, respectively. \({_{1}^{1}}^{(l)}\), \({_{2}^{1}}^{(l)}\) are weights for aggregating features from neighboring nodes and \({_{1}^{2}}^{(l)}\), \({_{2}^{2}}\) are weights for features of a centered node, this setup can be seen as a GAT. When all lower-layer parameters equal 1, the GNN degenerates to a GCN (see Appendix F.2 for justification of the choice of the GNN).

We consider a regression problem that we aim to minimize the MSE loss over all environments \(_{e}[R(e)]=_{e}[_{n_{1},n_{2}}[\| f_{}(A^{e},X^{e})-Y^{e}\|_{2}^{2}]]\). The optimal invariant parameter set \(^{*}\) is

\[\{_{1}=1\\ _{2}=0 l\{1,...,L-1\}^{1}}^{(l)}={_{2}^{2}}^{(l)}=0\\ _{1}^{1}=1,{_{1}^{2}}^{(l)}=1, l=L-1,...,L-k+1\\ {_{1}^{1}}^{(l)}=0,{_{1}^{2}}^{(l)}=1, l=L-k,L-k-1,...,1 .\.\] (4)

In Equation (4), the GNN parameters for spurious features (line 2) is zero, which means it removes spurious node features. Also, it learns the correct depth \(k\) of the causal pattern \(^{k}X_{1}\) (line 3-4).

### Intriguing Failure of VREx and IRM on Graphs

Now we are ready to present the failure cases in this node-level OOD task: optimizing IRMv1 and VREx induces a model that relies on spurious features \(X_{2}^{e}\) to predict, leading to poor OOD generalization. To illustrate that this failure arises from the graph data, we first prove that IRMv1 and VREx can learn invariant features under the non-graph version of SCM of Equation (2).

**Proposition 2.2**.: _(IRMv1 and VREx can learn invariant features for non-graph tasks, proof is in Appendix G.1.1.) For the non-graph version of the SCM in Equation (2),_

\[Y^{e}=X_{1}+n_{1},\ X_{2}^{e}=Y^{e}+n_{2}+^{e},\] (5)

_VREx and IRMv1 can learn invariant features when using a linear network: \(f(X)=_{1}X_{1}+_{2}X_{2}\)._

Now we will give the main theorem revealing the failure of VREx and IRMv1 on graphs.

**Theorem 2.3**.: _(IRMv1 and VREx will use spurious features on graphs, informal) Under the SCM of Equation (2), the IRMv1 and VREx objectives have non-unique solutions for parameters of the GNN (3), and there exist solutions that use spurious features, i.e. \(_{2} 0\)._

**Intuitive illustration of the failure.** From Theorem 2.3, we find that the main reason for the failure lies in the message-passing mechanism in representation learning. Let's provide some key steps in the proof of the IRMv1 case as an illustration. For the non-graph OOD task Equation (5), we can verify that when IRMv1 objective is solved, i.e. \(_{w}R(e)=0\) for all \(e\), the invariant solution \(_{2}=0\)leads to \((_{1})^{2}X_{1}^{}X_{1}-_{1}X_{1}^{}X_{1}=0\), which can be satisfied when \(=1\). However, in the graph case, \(_{2}=0\) leads to

\[(_{1})^{2}((^{e})^{s}X_{1})^{}(^{e})^{s}X_{1}- _{1}((^{e})^{k}X_{1})^{}(^{e})^{s}X_{1}=0,\; e,\] (6)

where \((^{e})^{s}X_{1}\) is the learned representation of the GNN, \(0<s L\). \(k\) is the depth of the causal pattern. Now we explain why the invariant solution may not hold on graphs. When the depth of the learned aggregation pattern \(s k\), Equation (6) cannot hold for a fixed \(_{1}\) (since \(_{1}\) will depend on \(e\) then). This means that identifying the underlying structure of the causal pattern imposes additional difficulty for invariant learning. Moreover, even if the GNN can learn representations of different depths (e.g. GAT)4, the proof in Appendix G.1.3 shows that IRM failed to provide sufficient supervision to optimize the aggregation parameters \(_{j}^{i}\), \(i,j\{1,2\}\) such that \(s=k\). A similar analysis holds for VREx. In general, successful invariant learning on graphs requires capturing both invariant node features and the structure of the causal pattern, while methods like IRM and VREx that solely enforce a cross-environment invariance at the loss level5 may not be able to achieve these goals. The formal versions and proof are in Appendix G.1.3 (IRM) and G.1.2 (VREx).

## 3 The Proposed Methods

### Cross-environment Intra-class Alignment

Inspired by the examples of VREx and IRMv1, we aim to introduce additional invariance regularization to guide the model in identifying the underlying invariant node features and structures. We propose CIA (Cross-environment Intra-class Alignment), which aligns the representations from the same class across different environments. Intuitively, since such node pairs share similar invariant features and causal pattern structures while differ in spurious features, aligning their representations will help achieve our targets. Denote the representation of node \(i\) as \(_{}(i)\) and the classifier parameterized by \(_{h}\) as \(h_{_{h}}\) CIA's objective is:

\[_{_{h},}\;_{e}[(h_{_{h}} _{}(A^{e},X^{e}),Y^{e})]_{}\; _{}=_{e,e^{}\\ e e^{}}\;_{c,e^{ }\\ (i,j)_{c}^{e,e^{}}}[(_{} (i),_{}(j))]\] (7)

where \(_{c}^{e,e^{}}=\{(i,j)|i j Y_{i}^{e}=Y_{j}^{e^{}}=c  E_{i}=e,\;E_{j}=e^{}\}\) is the set of nodes with same label \(c\) and from two different environments. \(\) is the cross-entropy loss. \(\) is some distance metric and we adopt L-2 distance. Now we prove that CIA can learn invariant representations regardless of the unknown causal patterns:

**Theorem 3.1**.: _Under the SCM of Equation (2) and Assumption 2.1, optimizing the CIA objective will lead to the optimal invariant solution \(^{*}\) in Equation (4) for parameters of the GNN (3)._

The proof is in Appendix G.1.4. By enforcing class-conditional invariance, which is not considered in VREx and IRMv1, CIA overcomes the above obstacles and eliminates spurious features. As long as a GNN has the capacity to adaptively learn the true depth of the causal pattern (such as the one considered in Equation (3)) or a GAT), CIA can identify the invariant causal pattern.

**Remark.** One might note that the objective of CIA is analogous to MatchDG (Mahajan et al., 2021). However, we are the first to adapt such an idea to node-level OOD tasks and theoretically reveal its advantage. In Appendix A.1, we compare our extension and the original MatchDG in detail.

### Localized Reweighting Alignment: an Adaptation to Graphs without Environment Labels

So far, we have theoretically and empirically validated CIA's advantage on graphs, but it still requires environmental labels that are challenging to obtain in most node classification tasks (Wu et al., 2021; Liu et al., 2023; Li et al., 2023a). In this section, we propose CIA-LRA (Localized Reweighting Alignment) that realizes CIA's objective without using environment labels by identifying node pairs with significant/minor differences in spurious/invariant features and then aligning their representations. As illustrated in Figure 2, CIA-LRA mainly incorporates three components:

**Localized alignment.** To avoid learning a collapsed representation of invariant features, it is crucial to align node pairs that share similar invariant features. To achieve this, we align nodes close to each other (about 2 to 6 hops). This is based on two observations. First, we observe that spurious features tend to exhibit larger changes within local graph areas than invariant ones, and nodes from the same class that are too distant may differ more in their invariant features than the closer ones (evidence in Appendix D.4). This is because invariant features are generally more stable than spurious ones, according to Chen et al. (2022), Scholkopf et al. (2021). Second, we empirically find that alignment over an extensive range or too many nodes yields only marginal performance improvements, or even leads to performance degradation (see Appendix D.1), while increasing computational costs. This may also be attributed to the feature collapse caused by excessive alignment of too many node pairs. Formally, the local pairs are defined as \(_{c}(t)=\{(i,j)|i j Y_{i}=Y_{j}=c d(i,j) t\}\), where \(d(i,j)\) represents the the shortest path length from node \(v_{i}\) to \(v_{j}\), \(t^{}\) is a hyperparameter. Also, we propose to assign smaller weights to pairs more distant away from each other.

**Reweighting Alignment.** Since environment labels are unavailable, we need a metric to reflect the distribution of the spurious and invariant representations so that node pairs with significant/small differences in spurious/invariant features can be identified. Since we assume the causal patterns of the same class are similar (Assumption 2.1), the label distribution of homophilic (i.e., same-class) neighbors directly affects the invariant features aggregated to the centered node (empirical evidence in Appendix D.5.2). Therefore, pairs with smaller differences in the ratio of homophilic neighbors should be assigned larger weights for alignment. The ratio discrepancy can be calculated as follows: \(r^{}(c)_{i,j}=|r_{i}^{c}-r_{j}^{c}|\), where \(r_{i}^{c}\) is the ratio of the neighbors of \(v_{i}\) of class \(c\) within \(L\) hops (\(L\) is the number of layers of the GNN). As for spurious features, we utilize _Heterophilic_ (i.e., different-class) _Neighborhood Label Distribution_ (HeteNLD) as a measurement, as it affects the two kinds of main distributional shifts on graphs: 1) environmental node feature shifts, and 2) _Neighborhood Label Distribution_ (NLD) shift (both empirically verified in Appendix D.5.1). HeteNLD determines the first kind of shift when correlations exist between labels and spurious node features, e.g., concept shift. The second kind, NLD shift, which is affected by HeteNLD, can be regarded as a structural shift as the discrepancy in neighborhood distribution will induce a gap in the aggregated representations (Theorem 4.4 shows this shift increases OOD error). Although aligning the representations significantly differing in homophilic neighbor ratio mitigates these two kinds of shifts, it also leads to the collapsed invariant representations and suboptimal performance (Table 4 shows this effect). Therefore we assign larger weights to the pair with a larger discrepancy in HeteNLD when alignment. The discrepancy in HeteNLD is calculated as follows: \(r^{}(c)_{i,j}=_{c^{} c}|r_{i}^{c^{}}-r_{j}^ {c^{}}|\).

Figure 2: The overall framework of our proposed CIA-LRA. The invariant subgraph extractor \(_{_{m}}\) identifies the invariant subgraph for each node. Then the GNN encoder \(_{}\) aggregates information from the estimated invariant subgraphs to output node representations. CIA-LRA mainly contains two strategies: localized alignment and reweighting alignment. Localized alignment: we restrict the alignment to a local range to avoid overalignment that may cause the collapse of invariant features (shown in Appendix D.1). Reweighting alignment: to better eliminate spurious features and preserve invariant features without using environment labels, we assign large weights to node pairs with significant discrepancies in heterophilic Neighborhood Label Distribution (NLD) and minor discrepancies in homophilic NLD. See Section 3.2 for a detailed analysis of CIA-LRA.

**Invariant Subgraph Extractor.** In Section 2.1, the structural invariant features are defined as the \(k\)-hop neighboring ego-graph for ease of analysis. However, in practice, the invariant structure may merely be a subgraph of the neighborhood nodes. To better capture the invariant ego subgraph, we train an invariant subgraph extractor inspired by Li et al. (2023). Concretely, we learn an auxiliary GNN encoder \(_{_{m}}\) (parameterized by \(_{m}\)) to predict an soft edge mask \(M^{N N}\), and then apply it during training and test:

\[M_{i,j}=(_{_{m}}(i)^{}_{_{m}}(j)),\ A_{m}=A  M\,\ \ .\] (8)

Now we are ready to present the formal objective of CIA-LRA:

\[&_{_{h},,_{m}}\ (h_{_{h}}_{}(A_{m},X),Y)\ _{,_{m}}\ _{c}(t)}{i,j}[w_{i,j}(_{}(i),_{}(j))],\\ &\ w_{i,j}=(}(c)_{ i,j}}{d(i,j)r^{}(c)_{i,j}}),().\] (9)

In Equation (9), \(\) is the cross-entropy loss, \(_{c}(t)\), \(r^{}(c)_{i,j}\), \(r^{}(c)_{i,j}\) and \(d(i,j)\) are defined in the above analysis. In practice, we use CIA-LRA as a regularization term added to the cross-entropy loss with a weight \(\) as a hyperparameter. The detailed implementation of CIA-LRA is in Appendix E.

## 4 Theoretical Justification: an OOD Generalization Error Bound

Now will derive an OOD generalization error bound to show that optimizing CIA-LRA can minimize OOD error. To achieve this, we adopt a PAC-Bayesian framework following Ma et al. (2021) and establish a Contextual Stochastic Block Model (CSBM, (Deshpande et al., 2018)) for OOD multi-classification. The proposed CSBM-OOD is as follows (more discussions are in Appendix F.4):

**Definition 4.1**.: **(CSBM-OOD).** For node \(i\) of class \(c\) from environment \(e\), its node feature \(x_{i}^{D}\) consists of two parts, \(x_{i}=[x_{i}^{};x_{}^{}]^{}\), where \(x_{}^{}\) sampled from the Gaussian distribution \((_{c},^{2}I)\) is the invariant feature and \(x_{}^{}\) sampled from the \((_{c}^{e},^{2}I)\) is the spurious feature. 6 Suppose \(\{_{c}\}\) and \(\{_{c}^{e}\}\) for all \(c\) and \(e\) form sets of orthonormal basis. We use \(p_{i}^{}\) to denote the homophilic ratio of node \(i\)'s one-hop neighbors and use \(p_{i}^{}(c^{})\) to denote the heterophilic ratio of node \(i\)'s one-hop neighbors of class \(c^{}\) (\(c c^{}\)). We assume \((y_{i}=c)\) are the same for all classes \(c\).

**The GNN model used for deriving the error bound (following Ma et al. (2021)):** The GNN model has a 1-layer mean aggregation \(g\) that outputs the aggregated feature \(g_{i}^{D}\) for node \(i\). The GNN classifier \(h\) on top of \(g\) is a ReLU-activated \(L\)-layer MLP with \(W_{1},...,W_{L}\) as parameters for each layer. \(h\) is from a function family \(\). The prediction for node \(i\) is \(h_{i}^{C}\) with \(h_{i}[c]\) representing the predicted logit for class \(c\). Denote the largest width of all the hidden layers as \(b\).

**Notations.** Denote nodes of environment \(e\) as \(V_{e}\). We consider the error of generalizing from a mixed training environment \(e^{}\) to any test environment \(e^{}_{}\), where \(V_{e^{}}:=_{e_{}}V_{e}\) represents all training nodes. To guarantee the generalization, we need to characterize the distance between \(V_{e^{}}\) and \(V_{e^{}}\): define \(_{e^{},e^{}}=_{j V_{e^{}}}_{i  V_{e^{}}}\|g_{i}-g_{j}\|_{2}\) as the aggregated feature distance between the training and test subgroup. Define the number of nodes in environment \(e\) as \(N_{e}\). We consider the margin loss of environment \(e\) that is used by Ma et al. (2021); Mao et al. (2023): \(}_{e}^{}(h):=}_{v_{i} V_{e}} [h_{i}[y_{i}]+_{c y_{i}}h_{i}[c]]\).

Now we introduce some assumptions adapted from Ma et al. (2021) that are used in our proof.

**Assumption 4.2**.: (Equal-sized and disjoint near sets, adapted from Assumption 2 of Ma et al. (2021)) For each node \(v_{i} V_{e^{}}\), define \(V_{e^{}}^{(i)}:=\{j V_{e^{}}\ |\ \|g_{i}-g_{j}\|_{2} _{e^{},e^{}}\}\). For any test environment \(e^{}\), assume \(V_{e^{}}^{(i)}\) of each \(v_{i} V_{e^{}}\) are disjoint and have the same size \(N_{e^{}}^{+}\).

**Assumption 4.3**.: (concentrated expected loss difference, adapted from Assumption 3 of Ma et al. (2021)) Let \(P\) be a distribution on \(\), defined by sampling the vectorized MLP parameters from\((0,^{2}I)\) for some \(^{2},e^{}})^{2/L}}{2b ( N_{e^{}}^{-}+ 2bL)}\). For any \(L\) layer GNN classifier \(h\) with model parameters \(W_{1}^{h},,W_{L}^{h}\), define \(T_{h}:=_{l=1,,L}\|W_{l}\|_{2}\). Assume that there exists some \(0<<\) satisfying

\[_{h P}(_{e^{}}^{/4}(h)-_{e^{}}^ {/2}(h)>N_{e^{}}^{-}+HC_{e^{},e^{}}|T_{h}^{L }_{e^{},e^{}}>.) e^{-N_{e^{} }^{2}}\]

Now we present the node-level OOD generalization bound (proof in Appendix G.3):

**Theorem 4.4**.: _(**Subgroup OOD Generalization Bound for GNNs, informal**). Let \(\) be any classifier in a function family \(\) with parameters \(\{_{}\}_{l=1}^{L}\). Under Assumption 4.2 and 4.3, for any \(e^{}_{}, 0\), and large enough \(N_{e^{}}\), there exist \(0<<\) with probability at least \(1-\), we have_

\[_{e^{}}^{0}()}_{e^{}}^{ }()+O(}(_{c=1}^{C}_{c^{ } c}(-_{c^{}})^{};(_{c}^{e^{}}- _{c^{}}^{e^{}})^{}]|})_{e^{},e^{}}}_{}\]

\[+^{C}(C-1)B_{e^{}}|_{c}^{e^{}}-_{c}^{e^{ }}|}_{}+}}}_ {i V_{e^{}}}}}_{j V_{e^{}}^{(i)}}_{c=1 }^{C}_{c^{} c}|p_{j}^{h_{}}(c^{}|c)-p_{i}^{h_{ }}(c^{}|c)|}_{}+const\] (10)

_where \(p_{i}^{h_{}}(c^{}|c)\) is the ratio of heterophilic neighbors of class \(c^{}\) when \(y_{i}=c\), \(B_{e^{}}=_{i V_{e^{}} V_{e^{}}}\|g_{i}\|_{2}\) is the maximum feature norm, \(V_{e^{}}^{(i)}:=\{j V_{e^{}}\|g_{i}-g_{j}\|_{2} _{e^{},e^{}}\}\). \(const\) is a constant depending on \(\), \(\), and \(\)._

The observations from Theorem 4.4 is summarized as follows: Term **(a)** reflects the separability of the original features of different classes \(|[(_{c}-_{c^{}})^{};(_{c}^{e^{}}-_{c^{}}^{e^{ }})^{}]|\) and the distance of the aggregated features between the training and test set \(_{e^{},e^{}}\). The former factor is the nature of the dataset itself. Term **(b)** is the distributional discrepancy between the training and test subgroups, caused by the distribution shifts in spurious features. When there exist correlations between labels and spurious features, CIA-LRA can minimize this term by minimizing the representation distance of node pairs with large discrepancy in the label distribution of heterophilic neighbors7. Term **(c)** measures the shift in HeteNLD between the training and test subgroups, representing the OOD error caused by the shift in the aggregated features of the same class. CIA-LRA minimizes this term by enforcing stronger alignment on pairs with greater HeteNLD differences.

## 5 Experiments

### Experiment Setup

We run experiments using 3-layer GAT and GCN on GOOD [Gui et al., 2022], a graph OOD benchmark. We reported the results on both covariate shift and concept shift. The detailed experimental setup and hyperparameter settings are in Appendix C. We compare our methods with the following algorithms: **ERM [Vapnik, 1999]**; traditional invariant learning methods: **IRM**, **VREx**, **GroupDRO [Sagawa et al., 2019], **Deep Coral [Sun and Saenko, 2016], **IGA**[Koyama and Yamaguchi, 2020]; graph OOD methods: **EERM**, **SRGNN**, **CIT**[Xia et al., 2023], **CaNet**[Wu et al., 2024]; graph data augmentation: **Mixup**[Wang et al., 2021a], **GTrans**[Jin et al., 2022].

### Main Results of OOD Generalization

Table 2 reports the main OOD generalization results. The observations are summarized as follows: 1) CIA-LRA improves the best baseline methods by 2.44% and 3.23% on GAT and GCN, respectively,

achieving state-of-the-art performance. 2) CIA outperforms IRM and VREx on all splits, which validates our theoretical findings in Section 2. Notably, it performs best among the non-graph-specific methods. 3) CIA-LRA improves CIA in most cases. This suggests that our reweighting strategy can enhance generalization on graphs even without environment labels. 4) MatchDG outperforms IRM and VREx on 12 out of 16 splits but underperforms CIA on average (averaged over 16 splits except on Arxiv, CIA: 57.56, MatchDG: 56.73).

### CIA can be Integrated into and Improve other Graph-OOD Methods

We replace VREx with CIA in the loss function of EERM to show that CIA can improve generalization in a plug-and-play manner. Table 3 shows that this improves original EERM by a large margin or has comparable performances, indicating the performance of node-level OOD algorithms can be limited by VREx.

### Empirical Understanding of the Role of CIA-LRA

**A synthetic dataset.** We construct a synthetic dataset (mentioned in Section 1) to validate the role of each module in CIA-LRA in eliminating spurious features and preventing the collapse of invariant representations. We generate a random graph and create a 4-class OOD classification task. Each node has a 4-dim feature, with the first/last two dimensions representing invariant/spurious features (details in Appendix C.3), so we can disentangle the learned invariant and spurious representations.

    &  \\   &  &  &  \\  Domain & Aware &  &  &  &  &  &  &  &  &  \\  Domain & degree & time & degree & word & color & similarity & degree & time & degree & word & color & similarity & \\  EERM & 99.120.14 & 75.100.15 & 56.350.34 & 67.550.34 & 65.750.34 & 65.420.39 & 4.888.17 & 4.576.100.15 & 65.780.19 & 64.900.19 & 75.511.25 & 25.840.39 & 39.57 \\  IRM & 97.120.14 & 75.100.19 & 57.010.39 & 65.750.36 & 56.240.32 & 39.098.63 & 57.970.19 & 66.240.31 & 64.020.34 & 63.310.39 & 75.370.89 & 25.891.99 & 39.8 \\  VREx & 96.100.12 & 71.400.20 & 55.540.16 & 64.100.45 & 64.67(2.92) & 34.130.27 & 52.86 & 65.50(0.02) & 46.100.22 & 64.700.36 & 64.020.22 & 72.530.36 & 27.530.36 & 27.530.34 & 59.33 \\  Graph-OOD & 96.00.16 & 73.900.19 & 65.00.49 & 65.00.49 & 65.020.42 & 37.150.23 & 73.62.62 & 64.900.22 & 64.891.50 & 64.611.30 & 64.020.22 & 73.530.34 & 75.810.32 & 39.526.12 & 98.3 \\  Deep Conf. & 97.120.14 & 75.100.12 & 57.100.15 & 65.00.49 & 65.00.47 & 65.00.47 & 65.470.37 & 33.669.88 & 65.00.47 & 65.00.47 & 65.00.47 & 65.00.47 & 65.00.47 & 65.00.47 & 65.00.47 & 65.00.47 & 65.00.47 & 65.00.47 \\  ICA & 96.00.12 & 77.100.23 & 85.50.12 & 65.00.49 & 65.00.47 & 65.00.49 & 32.980.67 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.43 & 72.950.35 & 28.162.36 & **79.53** \\  MetaIDO & OOD & OOD & 55.00.235 & 65.00.11 & 65.00.11 & 65.00.49 & 32.60.00 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 72.640.39 & 28.760.49 & 28.760.49 & 28.760.49 \\  CI & **96.00.16** & **74.125** & **55.00.13** & **65.00.11** & **65.00.35** & **65.00.10** & **65.00.49** & **65.00.49** & **65.00.49** & **65.00.49** & **65.00.49** & **65.00.49** & **65.00.49** & **65.00.49** & **65.00.49** & 72.640.39 & **65.00.49** & **65.00.49** \\    
   IRM & OOD & OOD & 46.011.75 & 62.750.50 & 56.00.49 & 65.00.49 & 33.110.46 & OOD & OOD & 46.00.49 & 65.00.45 & 53.120.2 & 69.50.58 & 52.794.26 & - \\  MRCNN & 87.190.26 & 71.700.37 & 55.013.23 & 65.400.50 & 65.00.47 & 28.884.15 & 75.97 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.23 & 72.911.22 & 23.751.91 & **75.85.85** \\  Miug & 97.200.11 & 75.100.37 & 56.700.49 & 65.00.49 & 53.700.49 & 28.171.14 & 65.21 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 \\  Ghema & OOD & OOD & 55.100.23 & 65.00.49 & 65.00.49 & 53.00.49 & 28.171.14 & 65.21 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 65.00.49 & 72.730.12 & 28.00.58 & - \\  CTI & OOD & OOD & 55.100.23 & 65.00.49 & 65.00.49 & 65.00.49 & 32.600.47 & 65.00.47 & - & OOD & OOD & 65.00.300.49 & 65.00.49 & 72.60.48 & 24.165.36 & - \\  CNA & OOD & OOD & 55.300.49 & 65.200.49 & 65.00.49 & 32.600.49 & 28.351.10 & 6.00 & OOD & 65.90.00.49 & 65.00.49 & 65.00.49 & 72.60.48 & 24.170.35 & - \\ 
**CL-LRA** & **99.40.10** & **71.30.13** & **57.60.13** & **65.00.30** & **75.60.30** & **75.60.30** & **75.60.30** & **75.60.30** & **75.60.30** & **75.60.30** & **65.00.30** & **65.00.49** & **75.30.35** & 31.301.88 & **63.0** \\    
    &  \\   &  &  &  &  \\  Domain &Figure 3 depicts the OOD accuracy, the variance of the invariant representation, and the norm of the spurious representation across training epochs for CIA and CIA-LRA. The observations are summarized below.

1) Aligning the large discrepancy in HeteNLD helps to eliminate spurious features on concept shift and improves generalization. As evident from the right column, incorporating \(r^{}\) diminishes the norm of spurious features under concept shift. For covariate shift, while \(r^{}\) will not remove environmental spurious features due to their independence from labels, it still helps generalization since it reduces the error caused by shifts in HeteNLD as predicted by Theorem 4.4. 2) CIA-LRA alleviates collapse of causal representation that CIA may suffer when adopting a substantial \(\). When using a large \(\) (\(=0.5\)), the performance of CIA deteriorates to the level of random guessing (25%) after approximately 50 epochs. In contrast, CIA-LRA sustains its accuracy at a high level because it avoids excessive alignment by aligning only local pairs and reweighting (further evidence in Appendix D.2). The mid column shows that the invariant features learned by CIA progressively collapse, even if CIA removes most spurious features (right column). 3) Maintaining the discrepancy in homophilic neighboring label distribution \(r^{}\) helps keep the variance of the invariant representation, slightly improving performance.

**Ablation study.** We also conduct ablation studies on CIA-LRA. Table 4 shows that removing any module causes a significant performance drop, demonstrating the effectiveness of each module.

### Effects of the Hyperparameters of CIA-LRA

This section analyzes the effect of \(\) and \(t\) of CIA-LRA. Figure 4 shows that the test accuracy increases with \(\) when \( 0.5\). Too small \(t\) leads to a sub-optimal performance due to insufficient regularization from aligning only a few pairs. Also, most parameter combinations outperform the baseline methods, indicating that CIA-LRA leads to consistently superior performance. Additional studies of the effects of \(\) and \(t\) are in Appendix D.2 and D.3, respectively.

## 6 Conclusion

In this work, by theoretically dissecting the failure of IRM and VREx in node-level graph OOD tasks, we attribute it to the difficulty in identifying the graph-specific causal pattern structures. To address this, we propose CIA with additional class-conditional invariance constraints and its environment-label-free variant CIA-LRA tailored for graph OOD scenarios. Further theoretical and experimental results validate their efficacy. Notably, CIA can be incorporated in other graph OOD frameworks, serving as a better invariant learning objective than the widely-used VREx on graphs.

  Algorithms & Acc. (\%) \\  IRM & 61.14 \\  VREx & 61.32 \\  no \(r^{}()_{,t}\) & 63.22 \\  no \(r^{}()_{,t}\) & 63.91 \\  no \(r^{}()_{,t}\) & 63.64 \\  no \(r^{}()_{,t}\) in parameter & 62.70 \\  full CIA-LRA & **65.42** \\  

Table 4: Ablation study of CIA-LRA. Results are averaged on the four representation. Right: the norm of the spurious representation. CIA splits of Cora.

Figure 4: Effect of \(\) and the number of hops \(t\) on OOD test accuracy (%).

Figure 3: Left: OOD test accuracy. Mid: the variance of the invariant averaged on the four representation. Right: the norm of the spurious representation. CIA splits of Cora.