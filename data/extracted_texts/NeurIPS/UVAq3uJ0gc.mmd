# Gradient-Free Methods for Nonconvex Nonsmooth Stochastic Compositional Optimization

Zhuanghua Liu

Department of Computer Science, National University of Singapore

CNRS@CREATE LTD, 1 Create Way, #08-01 CREATE Tower, Singapore 138602

liuzhuanghua9@gmail.com

&Luo Luo

School of Data Science, Fudan University

Shanghai Key Laboratory for Contemporary Applied Mathematics

luoluo@fudan.edu.cn

&Bryan Kian Hsiang Low

Department of Computer Science, National University of Singapore

lowkh@comp.nus.edu.sg

The corresponding author

###### Abstract

Stochastic compositional optimization (SCO) problems are popular in many real-world applications, including risk management, reinforcement learning, and meta-learning. However, most of the previous methods for SCO require the smoothness assumption on both the outer and inner functions, which limits their applications to a wider range of problems. In this paper, we study the SCO problem in that both the outer and inner functions are Lipschitz continuous but possibly nonconvex and nonsmooth. In particular, we propose gradient-free stochastic methods for finding the \((,)\)-Goldstein stationary points of such problems with non-asymptotic convergence rates. Our results also lead to an improved convergence rate for the convex nonsmooth SCO problem. Furthermore, we conduct numerical experiments to demonstrate the effectiveness of the proposed methods.

## 1 Introduction

In this paper, we consider the following stochastic compositional optimization (SCO) problem:

\[_{^{d}}() f(g()),\] (1)

where the outer and inner functions \(f^{m}\) and \(g^{d}^{m}\) has the form of

\[f()_{}[F(; {})] g()_{}[G(;)],\]

and the stochastic components \(F(;)\) and \(G(;)\) are Lipschitz continuous but possibly nonconvex and nonsmooth. Random variables \(\) and \(\) are independent. Such formulation is popular in many real-world applications, including risk management , statistical learning , reinforcement learning , and model agnostic meta-learning .

Most of the existing work [2; 5; 6; 7; 8] for nonconvex SCO problem is based on the assumption that both functions \(f()\) and \(g()\) are smooth. Unfortunately, many modern machine learningmodels including deep neural networks do not satisfy the smoothness condition. Ruszczynski  proposed a single time-scale stochastic subgradient method for solving the Problem (1). However, the author only provided asymptotic convergence analysis for the approach. In recent work, Liu and Davanloo Tajbakhsh , Hu et al.  presented the non-asymptotic convergence for the nonconvex nonsmooth SCO problem, while their analysis requires additional assumptions such as the weak-convexity and the relative smoothness condition.

The non-smoothness in the Problem (1) implies the classical gradient-based approaches and the convergence measure in terms of the gradient norm cannot be applied. The Clarke subdifferential  for the Lipshitz continuous functions is a natural extension of gradients for the smooth functions. However, hard instances have shown that no deterministic or randomized algorithms can find an \(\)-stationary point with respect to the Clarke subdifferential of a Lipschitz function in finite time [13; 14]. To address this issue, Zhang et al.  proposed a refined notion of the \((,)\)-Goldstein stationary point in terms of the Goldstein \(\)-subdifferential, which considers the convex hull of the Clarke subdifferential at points in the \(\)-neighbourhood .

In this paper, we propose a zeroth-order stochastic method called gradient-free compositional optimization method (GFCOM) for solving Problem (1) in finite time. In particular, we show that the GFCOM can find a \((,)\)-Goldstein stationary point of the objective function \(()=f(g())\) within the stochastic zeroth-order oracle complexity of \((d^{3.5}^{-3}^{-6})\). Furthermore, we improve the GFCOM by using the variance reduction technique [16; 17; 18; 19] to establish a more efficient first-order oracle estimator, leading to the algorithm GFCOM\({}^{+}\) which achieves a tighter upper complexity bound of \((d^{3.5}^{-3}^{-5})\). In addition, we study convex nonsmooth SCO problems. In this regime, prior methods [2; 20; 21] suffer two major limitations: (i) Their convergence analysis is based on the smoothness condition of the outer function. (ii) Their convergence result is measured by the sub-optimality of the function value gap, while the non-asymptotic convergence rate for finding the stationary point has not been studied. We overcome these issues by involving a warm-start strategy into GFCOM\({}^{+}\), which is guarantee to find a \((,)\)-Goldstein stationary point within \((d^{3}^{-2.4}^{-4}+d^{3.5}^{-2}^{-5})\) stochastic zeroth-order oracle complexity. We summarize the complexity of proposed methods in Table 1.

## 2 Related Work

In this section, we review prior work for stochastic compositional optimization and classical nonconvex nonsmooth optimization.

### Stochastic Compositional Optimization

In a pioneer work, Wang et al.  studied the non-asymptotic convergence of nonconvex smooth stochastic compositional optimization by proposing the stochastic compositional gradient descent (SCGD), which contains two sequences of stepsizes for different time scales to update the variable and track the inner function value, respectively. The authors also heuristically extended their methods to zeroth-order optimization. Wang et al.  proposed an accelerated variant of SCGD using an extrapolation-smoothing scheme, and Ghadimi et al.  proposed a single time-scale approach to accelerate the convergence further. Additionally, Hu et al. , Lin et al. , Yuan et al.  incorporated the variance reduction technique into the first-order iteration, achieving a tight stochastic first-order complexity under the mean-squared smoothness assumption.

   Methods & Problem & Complexity & Reference \\  GFCOM & Nonconvex & \((d^{3.5}^{-3}^{-6})\) & Corollary 4.2 \\ GFCOM\({}^{+}\) & Nonconvex & \((d^{3.5}^{-3}^{-5})\) & Corollary 4.4 \\ WS-GFCOM\({}^{2}\) & Convex & \((d^{3}^{-2.4}^{-4.8}+d^{3.5}^{-2}^{-6})\) & Corollary 5.3 \\ WS-GFCOM\({}^{+}\) & Convex & \((d^{3}^{-2.4}^{-4}+d^{3.5}^{-2}^{-5})\) & Corollary 5.4 \\   

Table 1: We present the stochastic zeroth-order complexity of proposed algorithms for solving nonsmooth stochastic compositional optimization problems.

Compared with the smooth counterpart, the study of nonsmooth compositional optimization is relatively scarce. Ruszczynski  proposed a single time-scale stochastic subgradient method for nonconvex nonsmooth SCO problems, while the theoretical analysis only provided the asymptotic convergence rate. Liu and Davanloo Tajbakhsh  introduced the stochastic composition Bregman gradient method and provided a non-asymptotic convergence analysis under the relative smoothness condition. Vladarean et al.  proposed a Frank-Wolfe algorithm for constrained nonconvex nonsmooth SCO problems. Their analysis assumes that the outer function is convex but possibly non-differentiable, and the inner function is smooth. Very recently, Hu et al.  studied stochastic methods for the finite-sum coupled compositional optimization problem. Their convergence rate is established by assuming both the outer and inner functions are weakly convex, and the outer function is non-decreasing. In addition, Kalogerias and Powell  studied the zeroth-order stochastic optimization for a specific compositional optimization problem in risk-aware learning.

### Non-Asymptotic convergence Analysis of Nonconvex Nonsmooth Optimization

In this subsection, we present a literature review for classical nonconvex nonsmooth optimization. The study of this field has a long history [12; 25], but the non-asymptotic convergence analysis of nonsmooth optimization has only emerged in recent years. Zhang et al.  provided the non-asymptotic complexity analysis of the interpolated normalized gradient descent method to achieve a \((,)\)-Goldstein stationary point of a Lipschitz function with a nonstandard subgradient oracle. Davis et al. , Tian et al.  improved this method by introducing random perturbations in each iteration to remove the assumptions. Recently, Cutkosky et al.  proposed the optimal algorithm via the reduction from nonconvex nonsmooth optimization to online learning.

The development of non-asymptotic convergence analysis of zeroth-order methods for nonsmooth optimization was initiated by Nesterov and Spokoiny . Later, Lin et al.  proposed gradient-free methods for this problem by establishing a relationship between the Goldstein \(\)-subdifferential and randomized smoothing. Chen et al. , Liu et al.  improved their results by leveraging the variance-reduction technique. Kornowski and Shamir  obtained a sharper bound by applying the reduction technique introduced by Cutkosky et al.  to the gradient-free setting. Liu et al. , Grimmer and Jia  further extends the methodology to the constrained setting. However, these methods do not apply to the nonconvex nonsmooth SCO Problem (1).

## 3 Preliminaries

In this section, we first present the notations and assumptions used in this paper, then introduce the convergence criteria for nonsmooth optimization and the randomized smoothing technique.

### Notations and Assumptions

We use \(\|\|\) to denote the Euclidean norm of a vector. We define \(_{}()\{^{d}:\| -\|\}\) as the Euclidean ball centered at \(^{d}\) with a radius \(>0\). We let \((A)\) be the convex hull of the set \(A\). For two given sets \(A\) and \(B\), we define \(A B\) as their Cartesian product. In addition, we denote \(f g\) as the function composition such that \((f g)() f(g())\).

Throughout this paper, we assume the objective function (1) satisfies the following assumptions.

**Assumption 3.1**.: _We assume the stochastic component \(F(,)\) is \(L_{f}()\)-Lipschitz for any given \(\), and the stochastic component \(G(,)\) is \(L_{g}()\)-Lipschitz for any given \(\). That is, it holds_

\[|F(,)-F(,)| L_{f}( )\|-\|\|G(},)-G(},)\| L_{g}()\|}-}\|,\]

_for any \(,^{d}\) and \(},}^{m}\). We also assume the Lipschitz parameters \(L_{f}()\) and \(L_{g}()\) have bounded second-order moments such that \(_{}[L_{f}()^{2}] G_{f}^{2}\) and \(_{}[L_{g}()^{2}] G_{g}^{2}\) for some constants \(G_{f},G_{g}>0\)._

_Remark 3.2_.: We can verify that Assumption 3.1 implies the function \(f()\) is \(G_{f}\)-Lipschitz, and the function \(g()\) is \(G_{g}\)-Lipschitz by Jensen's inequality.

**Assumption 3.3**.: _We assume that there exists a constant \(_{0}\) as the upper bound on the variance of the functions \(G(,)\), such that for any \(^{d}\), we have \(_{}[\|G(,)-g() \|^{2}]_{0}^{2}\)._

**Assumption 3.4**.: _We assume that the composite function \(()(f g)()\) is lower bounded such that \(^{*}_{^{d}}()>-\)._

### Convergence Criteria for Nonsmooth Functions

We introduce the definitions of the Clarke subdifferential and approximate Clarke stationary points.

**Definition 3.5** (Clarke ).: _The Clarke subdifferential of a Lipschitz function \(f\) at a point \(\) is defined as \( f()\{g:g=_{_{k} } f(_{k})\}\). Furthermore, we call a point \(\) an \(\)-Clarke stationary point of \(f\) if it holds that \(\{\|g\|:g f()\}\)._

Zhang et al. , Kornowski and Shamir  showed that no deterministic or randomized algorithm could find an \(\)-Clarke stationary point in finite time. Consequently, Zhang et al.  considered a refined notion of approximate stationary point in terms of the Goldstein \(\)-subdifferential.

**Definition 3.6** (Zhang et al. ).: _Given a Lipschitz function \(f^{d}\) and \(>0\), the Goldstein \(\)-subdifferential of \(f\) at point \(^{d}\) is defined as \(_{}f()(_{ _{}()} f())\), which is the convex hull of the Clarke subdifferential at the points in the \(\)-neighbourhood of \(\). Additionally, a point \(^{d}\) is called a \((,)\)-Goldstein stationary point of \(f()\) if it holds that \(\{\|g\|:g_{}f()\}\)._

Recent work [13; 26; 28] has shown that it is possible to find a \((,)\)-Goldstein stationary point of a nonsmooth problem without a composition structure in finite time. However, these theories are not applicable to nonsmooth SCO. In particular, we can infer from Rademacher's theorem and Assumption 3.1 that the composite function \(()\) is differentiable almost everywhere. Let \(^{d}\) be the set on which \(\) is differentiable, then \(^{d}\) is of measure zero. Recent work assumes they have access to the unbiased stochastic gradient estimator of the objective function for any \(\). In our setting, the unbiased gradient estimator of the composite function \(()\) is \(_{G}(;) F(g(); )\), where \(_{G}\) is the Jacobian matrix of the function \(G(;)\). However, such an estimator is hard to obtain because the function value \(g()\) is an expectation.

### Randomized Smoothing

The randomized smoothing is a popular technique for nonsmooth analysis  and gradient-free optimization . Concretely, given a Lipschitz function \(f\) and a uniform distribution \(\) on a unit ball, we define its smoothed surrogate as \(f_{}()=_{}[f(+ )]\), which has the following properties.

**Lemma 3.7** (Lin et al. [30, Proposition 2.3]).: _Let \(f_{}()=_{}[f(+ )]\) where \(\) is a uniform distribution on a unit ball in \(_{2}\)-norm. Suppose the function \(f\) is \(L\)-Lipschitz, then we have (a) \(|f_{}()-f()| L\); (b) \(f_{}()\) is differentiable everywhere and \(L\)-Lipschitz with \(cL^{-1}\)-Lipschitz gradient, where \(c\) is some positive constant; (c) \( f_{}()_{}f()\) for any \(^{d}\)._

Moreover, we consider the following unbiased gradient estimator of the smoothed surrogate function \(f_{}()\), which can be obtained from two function query oracle calls on points uniformly sampled from a unit sphere .

**Lemma 3.8** (Lin et al. [30, Lemma D.1]).: _Let \(f()=[F(;)]\) be a \(L\)-Lipschitz function. We denote_

\[(;,)(F( +;)-F(-; )),\]

_where \(\) is uniformly sampled from a distribution on a unit sphere in \(^{d}\) space. Then, we have \([(;,)]= f_{}( )\) and \([\|(;,)\|^{2}]  16dL^{2}\)._

## 4 Algorithms for Nonconvex Nonsmooth SCO

In this section, we propose zeroth-order stochastic algorithms for solving the nonconvex nonsmooth SCO problem. We also provide non-asymptotic convergence analysis for the proposed methods.

```
1for\(t=0,1,,T-1\)do
2 Sample \(\{_{t,i},_{t,i}\}_{i=1}^{b_{f}}\) and \(\{_{t,i}\}_{i=1}^{b_{g}}\).
3 Generate \(G(_{t}_{t,j};_{t,i})\) for every \((i,j)[b_{g}][b_{f}]\).
4 Let \(_{t,j}=}_{i[b_{g}]}G(_{t}+ _{t,j};_{t,i})\).
5 Let \(_{t,j}=}_{i[b_{g}]}G(_{t}- _{t,j};_{t,i})\).
6 Let \(_{t}=}_{j[b_{f}]}(F(_ {t,j};_{t,j})-F(_{t,j};_{t,j})) _{t,j}\).
7 Update \(_{t+1}=_{t}-_{t}\).
8
9 end for Return:\(_{R}\) where \(R\) is uniformly sampled from \([T]\). ```

**Algorithm 1**GFCOM(\(_{0},,T,b_{f},b_{g},b_{g}^{}\))

```
1for\(t=0,1,,T-1\)do
2if\(t m=0\)then
3 Sample \(\{_{t,i},_{t,i}\}_{i=1}^{b_{f}}\) and \(\{_{t,i}\}_{i=1}^{b_{g}}\).
4 Generate \(G(_{t}_{t,j};_{t,i})\) for every \((i,j)[b_{g}][b_{f}]\).
5 Let \(_{t,j}=}_{i[b_{g}]}G(_{t}+ _{t,j};_{t,i})\).
6 Let \(_{t,j}=}_{i[b_{g}]}G(_{t}- _{t,j};_{t,i})\).
7 Let \(_{t}=}_{j[b_{f}]}(F( _{t,j};_{t,j})-F(_{t,j};_{t,j})) _{t,j}\).
8
9else
10 Sample \(\{_{t,i},_{t,i}\}_{i=1}^{b_{f}}\) and \(\{_{t,i}\}_{i=1}^{b_{g}^{}}\).
11 Generate \(G(_{t}_{t,j};_{t,i})\) and \(G(_{t-1}_{t,j};_{t,i})\) for every \((i,j)[b_{g}^{}][b_{f}^{}]\).
12 Let \(_{t,j}=^{}}_{i[b_{g}^{}]}G(_{t}+_{t,j};_{t,i})\) for \(k\{t-1,t\}\).
13 Let \(_{k,j}=^{}}_{i[b_{g}^{}]}G(_{k}-_{t,j};_{k,i})\) for \(k\{t-1,t\}\).
14 Let \(_{k}=^{}}_{j[b_{f}^{}]}(F(_{k,j};_{t,j})-F(_{k,j}; _{t,j}))_{t,j}\) for \(k\{t-1,t\}\).
15 Let \(_{t}=_{t}-_{t-1}+_{t-1}\).
16
17 end for
18 Update \(_{t+1}=_{t}-_{t}\).
19
20 end for Return:\(_{R}\) where \(R\) is uniformly sampled from \([T]\). ```

**Algorithm 2**GFCOM(\(_{0},,T,b_{f},b_{g},b_{g}^{},m\))

### The Algorithms

In this subsection, we propose the gradient-free compositional optimization method (GFCOM) and its accelerated variant GFCOM\({}^{+}\). We first introduce the main intuition of the GFCOM. Consider the following hypothetical zeroth-order gradient estimator

\[}_{t}=}_{j[b_{f}]}(F(g( _{t}+_{t,j});_{t,j})-F(g(_{t}-_{t,j});_{t,j}))_{t,j},\] (2)

where \(b_{f}>0\) is the mini-batch size of the gradient estimator. By Lemma 3.8, the vector \(}_{t}\) is an unbiased estimator of \(_{}(_{t})\). Unfortunately, it is intractable to obtain the function values \(g(_{t}_{t,j})\) because \(g()\) is an expectation of stochastic component functions \(G(;)\). To remedy this issue, we introduce auxiliary variables \(_{t,j}\) and \(_{t,j}\) to approximate the inner function values \(g(_{t}+_{t,j})\) and \(g(_{t}-_{t,j})\), respectively. In particular, the vectors \(_{t,j}\) and \(_{t,j}\) are mini-batch function estimators defined as follows

\[_{t,j}=}_{i[b_{g}]}G(_{t}+ _{t,j};_{t,i}),_{t,j}= }_{i[b_{g}]}G(_{t}-_{t,j}; _{t,i}),\] (3)where \(b_{g}>0\) is the mini-batch size of the function estimator. Accordingly, we use these two variables to replace the function calls of \(g()\) in the gradient estimator \(_{t}\) of Eq. (2). The complete procedure of the GFCOM is presented in Algorithm 1.

For the GFCOM\({}^{+}\), we leverage the variance reduction technique to approximate \(_{}(_{t})\). In particular, we consider the following hypothetical recursive gradient estimator

\[}_{t}=}_{t}-}_{t-1}+_{t -1},\] (4)

where \(}_{t}\) and \(}_{t-1}\) are mini-batch gradient estimator defined as follows.

\[}_{k}=^{}}_{j[b_{f}^{}]}(F(g(_{k}+_{t,j});_{t,j})-F(g( _{k}-_{t,j});_{t,j}))_{t, j},\]

where \(b_{f}^{}>0\) is the mini-batch size and \(k\{t-1,t\}\). Compared with the mini-batch gradient estimator (2), the recursive gradient estimator (4) has been shown to achieve a sharper complexity bound in nonconvex optimization literature [17; 18; 31]. However, the gradient estimator is computationally intractable due to the unknown function \(g()\). Similar to the development of Algorithm 1, we define \(_{t}\), \(_{t}\) to estimate the inner function values \(g(_{t}_{t,j})\). We also introduce variables \(_{t-1}\), \(_{t-1}\) to approximate the inner function values \(g(_{t-1}_{t,j})\) at the previous iteration. Then we define stochastic gradient estimators \(_{t}\) and \(_{t-1}\) in terms of \(_{t}\), \(_{t-1}\), \(_{t}\) and \(_{t-1}\).

\[_{k}=^{}}_{j[b_{f}^{}]}(F(_{k,j};_{t,j})-F(_{k,j}; _{t,j}))_{t,j},\]

for \(k\{t-1,t\}\). We replace the minibatch gradient estimator \(}_{t}\) and \(}_{t-1}\) in the recursive gradient estimator \(}_{t}\) of Eq. (4) with the refined gradient estimators \(_{t}\) and \(_{t-1}\). The complete procedure of GFCOM\({}^{+}\) is presented in Algorithm 2.

### Convergence Analysis

In this subsection, we consider the complexity analysis of the proposed algorithms introduced in Section 4.1. We assume that \((x_{0})-^{*} R\), where \(R>0\) is some constant.

The following theorem shows the convergence rate of solving the Problem (1) with the GFCOM method presented in Algorithm 1.

**Theorem 4.1**.: _Under Assumption 3.1, 3.3 and 3.4, running the GFCOM algorithm (Algorithm 1) with \(/(cG_{f}G_{g})\) where \(c>0\) is some constant, then the output \(_{R}\) satisfies_

\[[\|_{}(_{R})\|^{2}]= (G_{g}R}{ T}+^{2}G_{g}^{2} }{T}+^{2}G_{g}^{2}}{b_{f}}+G_{f}^{2}_{0}^ {2}}{^{2}b_{g}}).\] (5)

Using Theorem 4.1 with the parameter setting

\[T=(G_{g}R}{^{2}}+^{2}G _{g}^{2}}{^{2}}), b_{f}=(^{2 }G_{g}^{2}}{^{2}}) b_{g}=(G_{f}^{2}_{0}^{2}}{^{2}^{2}}),\]

we obtain the following oracle complexity result for Algorithm 1.

**Corollary 4.2**.: _Under Assumption 3.1, 3.3 and 3.4, the GFCOM algorithm (Algorithm 1) requires at most \(d^{3.5}G_{f}^{5}G_{g}^{3}_{0}^{2}R^{-3}^ {-6}+d^{3.5}G_{f}^{6}G_{g}^{4}_{0}^{2}^{-2}^{-6}\) stochastic zeroth-order function query calls to obtain a \((,)\)-Goldstein stationary point of \(\)._

After giving the complexity bound of GFCOM in Corollary 4.2, we now consider the convergence analysis of GFCOM\({}^{+}\). We will show that it enjoys a sharper complexity bound due to the utilization of the recursive gradient estimator. The following theorem shows the convergence rate of solving Problem (1) with the GFCOM\({}^{+}\) (Algorithm 2).

**Theorem 4.3**.: _Under Assumption 3.1, 3.3 and 3.4, running the GFCOM\({}^{+}\) algorithm (Algorithm 2) with \(\!=\!/(2cG_{f}G_{g})\), \(b_{f}^{}\!=\!(dG_{f}G_{g}^{-1})\) and \(m\!=\!(G_{f}G_{g}^{-1})\), then the output \(_{R}\) satisfies_

\[[\|_{}(_{R})\|^{2}]= (G_{f}G_{g}R}{ T}+G_{f}^{2}G_ {g}^{2}}{T}+^{2}G_{g}^{2}}{b_{f}}+G_{f}^{2}_{0}^ {2}}{^{2}b_{g}}+G_{f}^{2}_{0}^{2}}{^{2}b_{g}^{ }}).\]Using Theorem 4.3 with the parameter setting

\[T\!=\!\!(\!G_{f}G_{g}R}{^{2}} \!+\!G_{f}^{2}G_{g}^{2}}{^{2}}\!),\ \ b_{f}\!=\!\!(^{2}G_{g}^{2}}{^{2}}\! ),\ \ b_{g}\!=\!b_{g}^{}\!=\!\!(\!G_{f}^{2} _{0}^{2}}{^{2}^{2}}\!)\!,\]

we obtain the following oracle complexity result for Algorithm 2.

**Corollary 4.4**.: _Under Assumption 3.1, 3.3 and 3.4, the GFCOM\({}^{+}\) algorithm (Algorithm 2) requires at most \(\!(d^{3.5}G_{f}^{4}G_{g}^{2}_{0}^{2}B^{-3} ^{-5}+d^{3.5}G_{f}^{5}G_{g}^{3}_{0}^{2}^{-2}^{-5})\) stochastic zeroth-order function query calls to obtain a \((,)\)-Goldstein stationary point of \(\)._

For both Theorem 4.1 and 4.3, we take \(c=1\) according to Lemma 8 of Duchi et al. .

### Discussion

In Algorithm 2, we only apply the variance reduction technique to the outer function \(f()\) to accelerate our algorithm. In contrast, existing methods [2; 7; 22] for nonconvex smooth SCO also apply the technique on the inner function estimator to obtain an improved complexity bound. Here we briefly discuss the cause that leads to such a difference. For smooth optimization, the main intuition of the variance reduction technique is to establish a connection between the bound of the mean-square error term \(\![\,\|_{t}-(_{t})\| ]^{2}\) and the expected distance of iterates at successive iterations \(\![\|_{t}-_{t-1}\|^{2}]\), which diminishes asymptotically. In our algorithm, we exploit the randomized smoothing with perturbed iterates \(_{t}_{t,j}\) to approximate the gradient of the smoothed surrogate function \(_{}(_{t})\). If we apply the variance reduction to the inner function estimator, the mean-square error \(\![\|_{t}-_{}(_{t}) \|]^{2}\) is bounded by the expected distance of the perturbed iterates at successive iterations \(\![\|_{t}-_{t-1}(_{t,j}-_{t-1,j})\|^{2}]\), which does not vanish asymptotically.

```
1 Let \(_{1}=(_{0},_{0},T_{0},1,b_{g,0})\).
2 Option I (WS-GFCOM\({}^{2}\)): \(_{2}=(_{1},,T,b_{f},b_{g})\).
3 Option II (WS-GFCOM\({}^{+}\)): \(_{2}=^{+}(_{1},,T,b_{f},b_{f}^{ },b_{g},b_{g}^{},m)\).
4 Return: \(_{2}\). ```

**Algorithm 3**WS-GFCOM(\(_{0},_{0},T_{0},b_{g,0},,T,b_{f},b_{g},b_{f}^{},b_{g}^{ },m\))

## 5 Extensions to Convex Nonsmooth SCO

In this section, we extend the result in Section 4.1 to study the convex nonsmooth SCO problem. Firstly, we introduce an additional assumption as follows.

**Assumption 5.1**.: _We suppose the function \(f()\) is convex and non-decreasing, \(G(;)\) is convex for any given \(\), and the solution set \(^{*}=*{arg\,min}_{^{d}}( )\) is non-empty._

From this assumption and Section 3.2.4 by Boyd and Vandenberghe , we can deduce that \(()\) is a convex function. We will show that stochastic algorithms obtain an improved convergence rate for the nonsmooth SCO problem with Assumption 5.1. To obtain a \((,)\)-Goldstein stationary point of the problem, we propose a two-phase gradient-free stochastic method called warm-started GFCOM (WS-GFCOM) in Algorithm 3. The intuition is that we use the GFCOM method to get a sufficiently small sub-optimality in the first phase, and then we apply the proposed methods in Section 4.1 to find the stationary point in the second phase. We remark that using the GFCOM method for the first phase is justified by the observation that it can achieve optimal convergence rate in terms of the sub-optimality of function value gap given the access to the exact function value \(g()\).

### Convergence Analysis

In this subsection, we consider the complexity analysis of the proposed WS-GFCOM method. Let \(_{^{*}}\|x-x_{0}\|\). We characterize the convergence rate of the WS-GFCOM method for the convex nonsmooth SCO problem at the first phase with the following theorem.

**Theorem 5.2**.: _Under Assumption 3.1, 3.3 and 5.1, running the WS-GFCOM algorithm (Algorithm 3) with parameters \(_{0}=/(G_{f}G_{g}})\), \(T_{0}=dG_{f}^{2}G_{g}^{2}^{2}^{-2}\), \(b_{g,0}=G_{f}^{2}_{0}^{2}^{-2}\) and \(= G_{f}^{-1}G_{g}^{-1}\), then the output \(_{1}\) satisfies \([(_{1})-^{*}]\). In addition, the total zeroth-order stochastic oracle complexity is at most \(dG_{f}^{4}G_{g}^{2}_{0}^{2}^{2}^{-4}\)._

Theorem 5.2 implies that the initial suboptimality at the beginning of the second phase is bounded by \(\). Consequently, the total complexity of WS-GFCOM2 (Algorithm 3 with Option I) is bounded by \(dG_{f}^{4}G_{g}^{2}_{0}^{2}^{2}^{-4}+d^{3.5 }G_{f}^{3}G_{g}^{3}_{0}^{2}^{-3}^{-6}+d^{3.5}G_{f}^{6 }G_{g}^{4}_{0}^{2}^{-2}^{-6})\). An appropriate choice of \(\) leads to the following oracle complexity of Algorithm 3 with Option I.

**Corollary 5.3**.: _Under Assumption 3.1, 3.3 and 5.1, the WS-GFCOM\({}^{*}\) algorithm (Algorithm 3 with Option I) requires at most \(d^{3}G_{f}^{4.8}G_{g}^{2.8}_{0}^{2}^{0.4} ^{-2.4}^{-4.8}+d^{3.5}G_{f}^{6}G_{g}^{4}_{0}^{2}^{-2 }^{-6}\) stochastic zeroth-order function query calls to obtain a \((,)\)-Goldstein stationary point of \(\)._

With a similar deduction, we can show that using the GFCOM\({}^{*}\) for the second phase can obtain an improved complexity bound. The following theorem shows the oracle complexity of Algorithm 3 with Option II.

**Corollary 5.4**.: _Under Assumption 3.1, 3.3 and 5.1, the WS-GFCOM\({}^{*}\) algorithm (Algorithm 3 with Option II) requires at most \(d^{3}G_{f}^{4}G_{g}^{2.8}_{0}^{2}^{0.4}^ {-2.4}^{-4.8}+d^{3.5}G_{f}^{5}G_{g}^{3}_{0}^{2}^{-2} ^{-5}\) stochastic zeroth-order function query calls to obtain a \((,)\)-Goldstein stationary point of \(\)._

## 6 Experiments

We compare the proposed methods GFCOM and GFCOM\({}^{*}\) with a Kiefer-Wolfowitz style zeroth-order baseline method [2; 40]. In particular, the baseline gradient estimator is defined as

\[_{t}=}_{j[b_{f}]}(F( _{t,j};_{t,j})-F(_{t,j}; _{t,j}^{})),\]

where \(_{t,j}\) and \(_{t,j}\) are function estimators defined in Eq. (3). \(_{t,j}\) and \(_{t,j}^{}\) are independent random variables. We test all the methods on the nonconvex penalized risk-averse portfolio management problem and a reinforcement learning (RL) problem. We set \(=0.1\) for the GFCOM and GFCOM\({}^{*}\) methods.

### Nonconvex Penalized Portfolio Management

We consider the portfolio management problem with capped-\(_{1}\) regularizer . Let \(\) denote the investment quantity corresponding to \(N\) assets and \(_{t}^{N}\) denote the returns of \(N\) assets at timestamp \(t\). We can formulate the portfolio management problem as the following nonsmooth compositional optimization problem

\[_{^{N}}-_{t=1}^{T}_{t},+_{i=1}^{T}(_{t}, -_{s=1}^{T}_{s}, )^{2}+(),\] (6)

where \(()=_{i=1}^{N}\{|x_{i}|,\}\) and \(,>0\) are tunable hyperparameters. Specifically, the inner function \(G(;)\) and outer function \(F(;)\) can be formulated as

\[G(;)=[x_{1},,x_{N}, r_{}, ]^{}\]

and

\[F(;)=-_{},w_{[N]}+(_{},_{[N]}-_{N+1})^{2}+().\]

Both random variables \(\) and \(\) are uniformly sampled from \(\{1,,T\}\). We choose \(=10^{-5}\) and \(=2\) in our experiments. The goal of the Problem (6) is to maximize the return while controlling the variance of the portfolio.

We compare all the methods on 6 different portfolio datasets formed on Size and Operating Profitability2. For all algorithms, we tune the stepsize among \(\{1 10^{-5},3 10^{-5},,1 10^{-3},3 10^{-3}\}\).

We choose the mini-batch size \(b_{f}=b_{g}=1000\). In addition, we set \(b^{}_{f}=100\), \(b^{}_{g}=1000\) and \(m=b_{f}/b^{}_{f}=10\) for the GFCOM\({}^{}\) algorithm. Figure 1 shows that the GFCOM\({}^{}\) algorithm converges much faster than the GFCOM and the baseline method across all datasets.

### Application to Reinforcement Learning

We demonstrate an experiment on RL and verify the effectiveness of the proposed methods on value function evaluation. Let \(V^{}(s)\) be the value function of a state \(s\) under a policy \(\) for all state \(s\) where \(||=n\). Let \(r_{s^{},s}\) be the reward transition from \(s^{}\) to \(s\), and \(>0\) is a discounting factor. Furthermore, we assume that the value of each state can be parameterized as a linear map of some feature map \(_{s}^{d}\) of the state \(s\) such that \(V^{}(s)=_{s},\). Then we formulate the RL problem as a Bellman residual minimization problem

\[_{^{d}}_{s=1}^{n}h(_{s}, -_{s^{}}P_{ss^{}}(r_{s,s^{}}+ _{s^{}},)),\]

where \(P_{ss^{}}\) is the probability transition matrix and \(h(x)=1-(-|x|/)\) is a nonconvex nonsmooth loss which is more robust to adversarial outliers than the squared loss [42; 43]. Specifically, the inner function \(G(;)\) and outer function \(F(;)\) can be formulated as

\[G(;)=[_{1},,r_{1,_{1}}+ _{_{1}},,,_{n}, ,r_{n,_{n}}+_{_{n}}, ]^{}\]

Figure 1: We present the loss vs. complexity on several portfolio management datasets. The plot of GFCOM and the Kiefer-Wolfowitz method are overlapped as their performance are close to each other.

Figure 2: For the RL task, we present the loss vs. complexity on datasets with states of different sizes.

\[F(;)=h(z_{2}-z_{2+1}).\]

In the above formulation, each \(_{i}\) is uniformly sampled from \(\{P_{i1},,P_{in}\}\) and \(\) is uniformly sampled from \(\{1,,T\}\). We follow a similar experiment setup by Yuan et al. . Specifically, we generate a Markov decision process with different numbers of states \(n\{400,600,800\}\) and 10 actions at each state. The transition probability matrix is generated from the uniform distribution from \(\). In addition, the rewards are sampled uniformly from \(\). In terms of hyperparameter setting, we choose \(b_{f}=b_{g}=100\) for all algorithms. In addition, we set \(b^{}_{f}=10\), \(b^{}_{g}=100\) and \(m=b_{f}/b^{}_{f}=10\) for the GFCOM\({}^{}\) algorithm. For other hyperparameters, we use the same setting for the portfolio management problem. The experimental results in Figure 2 show that the GFCOM\({}^{}\) significantly outperforms other methods.

## 7 Conclusion

In this work, we propose novel zeroth-order algorithms for nonconvex nonsmooth stochastic compositional optimization. We present the non-asymptotic convergence rate of the proposed algorithms for obtaining a \((,)\)-Goldstein point of the problem. Furthermore, we extend our methods with a warm-start phase to solve the convex nonsmooth SCO problem with improved convergence guarantees. We conduct numerical experiments on portfolio management and reinforcement learning problems to demonstrate the effectiveness of the proposed algorithms.

In future work, it is interesting to study the lower bound of the zeroth-order algorithms on nonconvex nonsmooth SCO. It is also interesting to investigate whether the complexity bound of zeroth-order algorithms can be further improved.