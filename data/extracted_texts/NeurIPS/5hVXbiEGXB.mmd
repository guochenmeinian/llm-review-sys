# Evolving Standardization for Continual Domain Generalization over Temporal Drift

Mixue Xie\({}^{1}\)  Shuang Li\({}^{1,}\)\({}^{*}\) Longhui Yuan\({}^{1}\)  Chi Harold Liu\({}^{1}\)  Zehui Dai\({}^{2}\)

\({}^{1}\)Beijing Institute of Technology, China \({}^{2}\)Lazada Search & Monetisation Tech, China

{mxxie,shuangli,longhuiyan}@bit.edu.cn, liuchi02@gmail.com

zehui.dzh@alibaba-inc.com

Corresponding author.

###### Abstract

The capability of generalizing to out-of-distribution data is crucial for the deployment of machine learning models in the real world. Existing domain generalization (DG) mainly embarks on offline and discrete scenarios, where multiple source domains are simultaneously accessible and the distribution shift among domains is abrupt and violent. Nevertheless, such setting may not be universally applicable to all real-world applications, as there are cases where the data distribution gradually changes over time due to various factors, e.g., the process of aging. Additionally, as the domain constantly evolves, new domains will continually emerge. Re-training and updating models with both new and previous domains using existing DG methods can be resource-intensive and inefficient. Therefore, in this paper, we present a problem formulation for _Continual Domain Generalization over Temporal Drift_ (CDGTD). CDGTD addresses the challenge of gradually shifting data distributions over time, where domains arrive sequentially and models can only access the data of the current domain. The goal is to generalize to unseen domains that are not too far into the future. To this end, we propose an _Evolving Standardization_ (EvoS) method, which characterizes the evolving pattern of feature distribution and mitigates the distribution shift by standardizing features with generated statistics of corresponding domain. Specifically, inspired by the powerful ability of transformers to model sequence relations, we design a multi-scale attention module (MSAM) to learn the evolving pattern under sliding time windows of different lengths. MSAM can generate statistics of current domain based on the statistics of previous domains and the learned evolving pattern. Experiments on multiple real-world datasets including images and texts validate the efficacy of our EvoS.

## 1 Introduction

In real-world applications, the assumption that training and testing data conform to the same distribution, a prerequisite for the success of contemporary deep learning methods, is seldom valid. A prime example of this can be found in autonomous driving, where a vehicle may traverse environments that switch from daylight to nightfall or from urban to rural. As environmental conditions change, the issue of distribution shift [5; 4; 51; 62] arises. Moreover, directly utilizing a model trained on in-distribution (ID) data in an out-of-distribution (OOD) context often results in catastrophic performance deterioration. Consequently, ensuring that models perform well on OOD data has emerged as a crucial challenge for the widespread deployment of machine learning models in the real world.

To cope with the distribution shift, two dominant paradigms have been systematically explored depending on the availability of target (test) domain. One is domain adaptation (DA), which aims to assist the model learning on an unlabeled or label-scarce target domain by transferring the knowledgefrom a related and label-rich source domain [15; 34; 29; 35]. Yet, target data are not always known or available in advance. The other is domain generalization (DG), the goal of which is to learn a model capable of generalizing to any unseen domain by using date from multiple related but distinct source domains [62; 36; 27; 63; 26]. Though the second paradigm DG has attained some encouraging outcomes, its configuration is limited to offline and discrete scenarios where multiple source domains can be accessed simultaneously, and the distribution shift among domains is sudden and severe. For instance, the prevalent benchmark PACS  in current DG methods comprises four distinct domain styles - "Art", "Cartoon", "Photo" and "Sketch". Nevertheless, this type of configuration may not be suitable for all real-world applications. There are also some cases that the data distribution gradually evolves over time, the distribution shift arising from which is referred to as _temporal drift_.

On one hand, the real-world scenarios often exhibit underlying evolutionary patterns [59; 44]. For example, annual or monthly weather data can be utilized for weather forecasting . The evolutionary patterns can be exploited to enhance generalization capabilities towards future unseen domains that are not too distant. However, current DG methods often fail to consider these patterns, leading to suboptimal performance. On the other hand, since data distribution is constantly evolving, new domains will continue to emerge. Consequently, it is imperative to efficiently utilize these new domains to further enhance the model's performance for practical applications. For instance, in the context of advertisement recommendation, user browsing data for various products continually surfaces. How can we leverage these newly collected data to enable more accurate advertisement recommendations tailored to each user's preferences in the days to come? One simple approach is to store data from previous domains and retrain the model using both the new and previous domains with the existing DG techniques. However, such way may consume huge training resources due to the accumulation of data and is of low efficiency, especially for scenarios with rapid data accumulation.

In this paper, we formulate the aforementioned problems as Continual Domain Generalization over Temporal Drifts (CDGTD), where the data distribution gradually drifts with the passage of time and the domain arrives sequentially. And the goal of CDGTD is to generalize well on future unseen domains that are not too far under the circumstance that only current domain is available at current times point while data from previous domains are inaccessible. Although some temporal / evolving DG methods [44; 59; 3; 41] have been proposed to handle the temporal drift, most of them [59; 44; 41] works in non-incremental setting, i.e., multiple domains can be accessed simultaneously. Instead, we design an Evolving Standardization (EvoS) approach specialized for CDGTD.

For CDGTD, there are two main challenges: how to characterize the evolving pattern in the incremental setting and how to achieve generalization using the learned evolving pattern. For the former, we draw inspiration from the sequence modeling capability of transformers  and design a multi-scale attention module (MSAM) to learn the evolving pattern underlying the feature distribution of domains. Specifically, we store the statistics (i.e., mean and variance of features) of previous domains and use sliding time windows of different lengths over the statistic tokens to obtain multi-scale information. Then multi-scale statistic tokens are fed into MSAM to generate statistics of current domain. MSAM is trained over the whole sequence of domains to learn the evolving pattern. Here, we integrate multi-scale information, with the consideration that some evolving patterns may be better characterized at different time intervals, e.g., seasonal climate and daily weather. For the latter challenge, in order to mitigate the temporal drift, each domain is transformed into a common normal distribution by conducting feature standardization with the generated statistics of corresponding domain. Besides, considering that the feature encoder may suffer from catastrophic forgetting and overfitting to current domain, we constrain it to learn a shared feature space among domains via the adversarial learning.

**Contributions: 1)** We formulate a promising but challenging problem of continual domain generalization over temporal drift (CDGTD), which has seldom been explored, compared with traditional DG. **2)** An evolving standardization (EvoS) approach is specially proposed for CDGTD, which can characterize the evolving pattern and further achieve generalization by conducting the feature standardization. **3)** Experiments on multiple real-world datasets with different models verify the effectiveness of EvoS and the flexibility to be applied on different models.

## 2 Related Work

**Domain Generalization (DG)** aims to learn a model that can generalize well to any unseen target domains by leveraging data from multiple source domains. In recent years, a wide range of DGmethods have been proposed [6; 39; 27; 26; 63; 19; 37]. According to the strategies of improving generalization, existing DG methods roughly fall into the three categories. Representation learning based methods [7; 39; 50; 27; 2; 2; 17; 42] aim to learn domain-invariant or domain-shared representations to enable models to generalize to unseen target domains. Data augmentation/generation based methods [53; 61; 63; 32; 57] focus on manipulating inputs to facilitate learning general representations. Differently, other DG methods instead employ general learning strategies like meta-learning  and ensemble learning  to improve generalization ability. With full access to all source domains, these DG methods have achieved promising performance on unseen domains with abrupt and violent distribution shifts. Unfortunately, without the consideration of the evolutionary pattern of domains over time, existing DG methods are usually less efficient under the scenario of temporal drift.

**Continual Learning (CL)** is a machine learning paradigm, where models learn continuously from a stream of tasks over time and meanwhile try to retain performances on all seen tasks [22; 1; 24; 9; 46; 47]. Existing CL methods can be roughly categorized into replay-based [46; 10; 52], regularization-based [22; 60; 30] and structure-based [45; 14] methods. In addition, the combination of CL and DA has attracted lots of attention [23; 17; 33; 43; 55]. Yet, combining CL and DG remains underdeveloped. In this work, we propose CDGTD which continually trains the model on sequential domains, but the goal is to generalize well on novel domains in the near future. This distinct objective from CL yields different challenges: the modeling of underlying evolutionary patterns of temporal domains and how to utilize these patterns to mitigate the distribution shifts in forthcoming domains.

**Test Time Adaptation (TTA)** focuses on adapting the source-pretrained model during testing phase with test data [40; 49; 20; 54; 58]. For example,  corrects the activation statistics of batch normalization using test data. T3A  uses a back-propagation-free manner to adjust only the weights of the linear classifier during test time. By contrast, CDGTD optimizes the model during training phase with sequential domains and emphasizes on generalization without using test data.

**Evolving / Temporal Domain Generalization** has emerged in recent years, aiming to tackle the problem of generalizing on temporally drifted domains, where the environment evolves dynamically over time [41; 3; 44; 59]. GI  proposes a time-sensitive model architecture to capture the time-varying data distribution and the model is supervised with the first-order Taylor expansion of the learned function to advance the generalization in the near feature. DRAIN  launches a Bayesian framework to model the concept drift and utilizes a recurrent neural network to dynamically generate network parameters to adapt the evolving pattern of domains. LSSAE  incorporates variational inference to explore the evolving patterns of covariate shift and label shift in the latent space. The goal of learning evolutionary patterns from source domains and generalizing to domains in the near future is similar to our EvoS. The main difference is that the model in our EvoS is incrementally trained on sequentially arriving domains, considering the low efficiency of "offline" training with accumulated domains. By contrast, the aforementioned methods [41; 44] require multiple source domains to be simultaneously available. Besides, the Taylor expansion in , variational inference in  and network parameters generation in  make them hard to expand on large models.

## 3 Evolving Standardization for Continual Domain Generalization over Temporal Drift

### Problem Formulation of CDGTD

Here, we take the \(C\)-class classification problem as an example, where \(X\) and \(Y\) denote the data and label space, respectively. Suppose that \(T\) source (training) domains \(\{^{1},^{2},,^{T}\}\) sequentially arrive, which are sampled from distributions at \(T\) different times points \(_{1}<_{2}<<_{T}\). At time point \(_{i}\), \(t\{1,2,,T\}\), only the domain \(^{t}=\{_{i}^{t},y_{i}^{t}\}_{i=1}^{N^{t}}\) is accessible, where \(_{i}^{t} X\), \(y_{i}^{t} Y\) and \(N^{t}\) is the number of training samples in \(^{t}\). Previous and future domains are unavailable. In addition, as previous temporal/evolving DG methods [44; 41; 3], we further assume that the data distribution \(P(X,Y)\) of domains evolves temporally, i.e., the distribution of domains changes along the time following certain patterns. The goal of CDGTD is to enable the model, composed of a feature encoder \(:^{d_{f}}\) (\(d_{f}\) is the dimension of features) and a classifier \(:\{0,1,,C-1\}\), to generalize well on \(K\) unseen target (test) domains in the near future: \(\{^{T+k}\}_{k=1}^{K}\). To this end, two main challenges need to be addressed. One is to characterize the evolving pattern of domains, which we address by designing a multi-scale attention module (MSAM)inspired from the sequence modeling ability of transformers. The other is the generalization, which is realized by transforming domains into a common normal distribution via the feature standardization.

### EvoS: Evolving Standardization

**Single-scale Attention.** Inspired by the capability of the transformer to model the relationships among sequences , we introduce its attention mechanism to model the evolving pattern among sequential domains. Before presenting our multi-scale attention module (MSAM), we first introduce how single-scale attention works. Without loss of much generality, we assume that the feature distribution of domain \(^{t}\) follows the normal distribution, which is characterized by the mean vector \(^{t}^{d_{f}}\) and the standard deviation vector \(^{t}^{d_{f}}\). Now, our goal turns out to be learning the evolving pattern of the feature statistics (i.e., \(^{t}\) and \(^{t}\)). In practice, to ensure that \(^{t}\) is non-negative, we choose to learn \(^{t}\) (the logarithm of \(^{t}\)). In this way, \(^{t}=(^{t})\) is always non-negative. Besides, considering the unavailability of previous domains, we store the learned statistics at time point \(_{t}\) into a memory pool \(\) for future uses once the training procedure finishes on domain \(^{t}\). Having the feature statistics of previous \(t-1\) domains ready, we then utilize the multi-head self-attention module \(\) to generate the statistics of domain \(^{t}\) at time point \(_{t}\).

Concretely, given statistic tokens \(\{^{i}\}_{i=1}^{t-1}\) of previous \(t-1\) domains, where \(^{i}=[^{i},^{i}]^{2d_{f}}\) is the token of concatenated statistics from domain \(^{t}\), the output of \(\) is expressed as

\[}^{t} =(^{t-1})=[_{1}(^{t-1}),_{2}(^{t-1}),,_{n_{h}}(^{t-1})]_{fc}, _{fc}^{(n_{h} d_{h}) 2d_{f}},\] \[=[}^{1},}^{2};;}^{t-1}],\] \[^{t-1} =[^{1};^{2};;^{t-1}],^{t-1} ^{(t-1) 2d_{f}}\] (1)

where \(}^{i}\) is the \(i\)-th output statistic token of \(\), \(n_{h}\) and \(d_{h}\) are the number and feature dimension of heads in the multi-head self-attention module and \(_{fc}\) is the learnable parameters of \(\) to convert feature dimensions. \(_{i}()\) is the self-attention of the \(i\)-th head, which operates as follows:

\[[^{t-1}_{i,q},^{t-1}_{i,k},^{t-1}_{i,v}]=^ {t-1}^{i}_{qkv},^{i}_{qkv}^{2d_{f} 3 d_{h}}\] \[_{i}(^{t-1})=(^{t-1}_{i,q} ^{t-1}_{i,k}{}^{}/})^{t-1}_{i,v},\] (2)

Figure 1: Overview of EvoS. Memory pool \(\) stores previously generated domain statistics (i.e., \(^{i}\) (mean) and \(^{i}\) (logarithm of standard deviation) of features, \(1 i t-1\)). With the \(t\)-th domain \(^{t}\) available, loss \(^{t}_{stan}\) is minimized to train the multi-scale attention module (MSAM) to generate statistics \(}^{t}\) and \(}^{t}\) that approach the real ones via leveraging historical statistics in \(\). Besides, we sample features from historical feature distributions as the proxy of previous domains to conduct adversarial training with current domain, encouraging to learn a shared feature space.

where \(^{i}_{qkv}\) is the learnable parameters of the \(i\)-th head and \(^{t-1}_{i,q},^{t-1}_{i,k},^{t-1}_{i,v}\) are the query, key and value embeddings of \(^{t-1}\). Finally, we use the average of all output statistics tokens of the attention module \(\) as the generated statistic token \(}^{t}\) for time points \(_{t}\):

\[[}^{t},}^{t}]=}^{t}=avg(}^{t})= _{i=1}^{t-1}}^{i}.\] (3)

By continuously generating new statistics from historical ones throughout the whole sequence of domains, the attention module \(\) is expected to learn the evolving pattern of feature distributions. Note that we directly introduce learnable statistic vectors \(}^{1},}^{1}\) and \(}^{2},}^{2}\) for time points \(_{1}\) and \(_{2}\), respectively, since the tokens of historical statistics are not enough for the attention module \(\) to work. That is, the attention module \(\) is only used at time points \(_{t},t 3\).

**Multi-scale Attention Module (MSAM).** The above details how to model the evolving pattern using single-scale attention. However, it is limited to learn the pattern using a sliding time window of length 1 over the statistic tokens. Sometimes, the evolutionary pattern may be better captured by considering longer time intervals. For instance, the data of a season in each time window would be more suitable for capturing the evolving pattern of seasonal climate, rather than data of a single day in each time window. Considering this, we introduce multi-scale attention in Fig. 1, which leverages information from observation windows of different lengths to better model the evolving pattern.

Specifically, for the multi-head self-attention module \(_{w}\) responsible for the time window of length \(w\), we slide the time window with stride 1 over historical \(t-1\) statistics tokens and concatenate the statistic tokens in each window to obtain the input \(}^{t-1}_{w}\) for the attention module \(_{w}\) at time point \(_{t}\):

\[}^{i}_{w} =[^{i},^{i+1},^{i+w-1}],} ^{i}_{w}^{w 2d_{f}},(1 i t-w)(t w+2)\] \[}^{t-1}_{w} =[}^{1}_{w};}^{2}_{w};;}^ {t-w}_{w}],}^{t-1}_{w}^{(t-w)(w 2d_{f})}.\] (4)

And similarly, we use the average output \(}^{t-w+1}_{w}\) of the attention module \(_{w}\) as the generated statistics for the sliding time window at the next time point, the formulation of which is expressed as

\[}^{t}_{w} =_{w}(}^{t-w+1}_{w})=[^{1}_{w};}^{2}_{w};;}^{t-w}_{w}],}^{t}_{w} ^{(t-w)(w 2d_{f})}\] \[}^{t-w+1}_{w} =avg(}^{t}_{w})=_{i=1}^{t-w}}^{i}_{w},}^{t-w+1}_{w}^{w 2d_{f}}.\] (5)

Note that in MSAM, the attention module \(_{w}\) is to predict the statistics in the next sliding time window of length \(w\), instead of one statistic token as in the single-scale attention. This may encourage the attention module to also capture the domain relationships within the window.

Then, we split \(}^{t-w+1}_{w}\) into \(w\) parts: \([}^{t-w+1}_{w},,}^{t-1}_{w},}^{t}_{w} ]=}^{t-w+1}_{w}\), where \(}^{j}_{w}^{2d_{f}}\) can be regarded as the predicted statistic token for time point \(_{j}\) using the attention module \(_{w},j=t-w+1,,t-1,t\). Finally, the generated statistic token \(}^{t}\) for time point \(_{t}\) using MSAM is denoted as the average of predicted statistic tokens for time point \(_{t}\) at different time window lengths:

\[[}^{t},}^{t}]=}^{t}=_{w=1}^ {W}}^{t}_{w},\] (6)

where \(W\) is the maximum length of the sliding time window. Generally, MSAM integrates evolving patterns learned at different scales, contributing better estimation of future feature distributions.

**Feature Standardization.** For CDGTD, the second main challenge is generalization. To this end, we leverage the generated feature statistics by MSAM to transform the distribution of corresponding domain into a standard normal distribution, by which the temporal drift is mitigated. Concretely, for feature \(^{t}_{i}=(^{t}_{i})\), its standardized feature \(^{t}_{i}\) via the feature standardization is formulated as

\[^{t}_{i}=^{t}_{i}-}^{t}}{}^{t}}= ^{t}_{i}-}^{t}}{(}^{t})}.\] (7)

Another benefit of feature standardization is that it allows classifier to be trained on a common feature distribution, thus avoiding the problem of overfitting to current domain and catastrophic forgetting.

### Model Training

This section outlines the four losses \(^{t}_{ce}\), \(^{t}_{stan}\), \(^{t}_{con}\) and \(^{t}_{adv}\) involved in the training stage at time point \(_{t}\). The first one is the essential loss to supervise the model learning for specific tasks, e.g., the following cross-entropy loss \(^{t}_{ce}\) for classification tasks in this paper.

\[_{,}^{t}_{ce}=}_{i=1}^{ N^{t}}(^{t}_{i},y^{t}_{i}),^{t}_{i}= (^{t}_{i}-(}^{t})} {((}^{t}))}),\] (8)

where \((,)\) is the cross-entropy. Here, stopping gradient \(()\) is adopted to stabilize training.

Losses \(^{t}_{stan}\) and \(^{t,w}_{con}\) are responsible for the training of the attention module \(_{w}\) at time point \(_{t}\), \(w=1,2,,W\). The former loss \(^{t}_{stan}\) in Eq. 10 is minimized to ensure that the standardized feature \(^{t}_{i}\) follows a standard normal distribution. Specifically, we first calculate the mean vector and variance vector of the standardized features as

\[mean:}^{t}=}_{i=1}^{N_{t}}( ^{t}_{i})-}^{t}}{(}^{t})}, variance: }^{t}=-1}_{i=1}^{N_{t}} (^{t}_{i})-}^{t}}{(}^{t})}-}^{t }^{2}.\] (9)

Then the loss \(^{t}_{stan}\) at time point \(_{t}\) is expressed as

\[\{ &_{}^{t},}^{t}} ^{t}_{stan}=\|}^{t}-\|_{2}+\|}^{t}- \|_{2}, 1 t 2\\ &_{_{w}}^{t}_{stan}=\|}^{ t}-\|_{2}+\|}^{t}-\|_{2}, t w+2 .,\] (10)

where \(d_{f}\) is the dimension of features and \(w\) is the length of the sliding time window. Here, we just want the learnable/generated \(}^{t},}^{t}\) to approach the statistics of true feature distribution, so stopping gradient operation \(()\) is conducted on \(^{t}_{i}\) to prevent the gradient of \(^{t}_{stan}\) flowing to the feature encoder \(\). Otherwise, the gradient of \(^{t}_{stan}\) may distort the feature distribution. Ideally, if \(^{t}_{stan}\) is minimized, the generated statistics \(}^{t}\) and \((}^{t})\) by our MSAM would be equal to the mean vector and standard deviation vector of the true feature distribution of \(^{t}\). This means that our MSAM can predict future feature distributions based on historical feature statistics.

And the loss \(^{t}_{con}\) is to ensure the consistency between generated statistic tokens in the next sliding time window and real statistic tokens. Specifically, we calculate \(^{t,w}_{con}\) for attention module \(_{w}\) as

\[_{_{w}}^{t,w}_{con}=_{k=1}^{w-1}\| }^{t-w+k}_{w}-^{t-w+k}\|_{2},(t w+2) w 2,\] (11)

where \(}^{j}_{w}\) and \(^{j}_{w}\), \(j=t-w+1,,t-1\) are respectively the predicted statistic token for time point \(_{j}\) using the attention module \(_{w}\) and the real statistic token from memory pool \(\). This loss is expected to also capture the evolutionary pattern within the time window.

The fourth loss \(^{t}_{adv}\) is introduced with this consideration that the feature extractor \(\) may overfit to current domain and lacks generalizability. To avoid this, we additionally conduct adversarial training between the feature encoder \(\) and a discriminator \(\). Nevertheless, historical data are unavailable. So we instead resort to the learned/generated statistics at previous time points. Concretely, we randomly sample a batch of \(B\) samples \(\{}_{1}^{m},,}_{B}^{m}\}\) from each distribution \((^{m},((^{m}))^{2})\), \(m=1,2,,t-1\), via Eq. 12 at each iteration, and use them as the proxy of historical domains.

\[}_{i}^{m}=^{m}+(^{m}), (0,1)-,\] (12)

where \(\) is a truncation hyper-parameter to control the sampling area. Then discriminator \(\) is trained to distinguish \(\{}_{i}\}_{i=1}^{N^{t}}\) from \(\{}_{1}^{m},,}_{B}^{m}\}_{m=1}^{t-1}\) and the feature extractor tries to confuse \(\). Such adversarial process is achieved by the following loss \(^{t}_{adv}\):

\[_{}_{}^{t}_{adv}= _{m=1}^{t-1}_{j=1}^{B}-((}_{j}^{m}))+}_{j=1}^{N^{t}}-(1-(}_{j}^{t})), t 2.\] (13)

In practice, the gradient reverse layer (GRL)  is used to achieve the adversarial training. To sum up, at time point \(_{t}\), the model is trained to minimize the following total loss \(^{t}_{total}\):

\[^{t}_{total}=^{t}_{ce}+^{t}_{stan}+_{w=1}^{ W}^{t,w}_{con}+^{t}_{adv},\] (14)where \(\) is a hyper-parameter to balance the loss tradeoff. Once the training procedure at time point \(_{t}\) is finished, we store the learned/generated statistics of current domain \(^{t}\) into memory pool \(\) by

\[^{t},^{t}}^{t}, }^{t}.\] (15)

In the inference stage, we use MSAM to generate future statistics \(}^{T+k}\) based on the statistics \(\{s^{t}\}_{t=1}^{T+k-1}\) in memory pool \(\) and store it into \(\) as Eq. 15 for the generation at next time point. Due to space limitation, the training and testing procedures are provided in the appendix.

## 4 Experiments

### Experimental Setup

Thanks to the work in , several real-world datasets with distribution shifts over time have been available. And we evaluate EvoS on three image classification datasets (**Yearbook** and **fMoW** from  and **RMNIST**) and two text classification datasets (**Huffpost** and **Arxiv** from ). Yearbook collects data from 1930 to 2013, where we treat every four years as a domain and use the first 16 domains for training (\(T=16\)), the last 5 domains for testing (\(K=5\)). fMoW includes data of 16 years and we set \(T=13,K=3\). RMNIST contains 9 domains with \(T=6,K=3\). Huffpost includes data of 7 years with \(T=4,K=3\). Arxiv collects data of 172 categories for 16 years, with \(T=9,K=7\). For each training domain of all datasets, we randomly select 90% data as training split and 10% data as validation split. Following the backbones in , we use a 4-layer convolutional network  for Yearbook, Densect-121  pretrained on ImageNet for fMoW, pretrained DistilBERT base model  for Huffpost and Arxiv, and the ConvNet in  for RMNIST. For each attention module \(_{w}\) in MSAM, its dimension of head \(d_{h}\) is set to 8 and its number of heads is set to \(w n_{h}\). Specifically, \(n_{h}\) is set to 16 for Yearbook, 32 for RMNIST, 64 for fMoW and 128 for Huffpost and Arxiv. For optimization, we use the Adam optimizer with \(lr=1e-3\) for Yearbook and RMNIST, \(lr=2e-4\) for fMoW and \(lr=2e-5\) for Huffpost and Arxiv. The batch size is set to 64 for all datasets. As for hyper-parameters, we select them via grid search using the validation splits of training domains and finally use \(=2.0\) for RMNIST, \(=1.0\) for others, \(=1.0,W=3\) for all datasets. For all tasks, we report the mean of 3 random trials. Due to space limitations, please refer to appendix for more details. Code is available at https://github.com/BIT-DA/EvoS.

### Main Results

In addition to the incremental training scenario, we also provide results in non-incremental scenario with all source domains simultaneously available, which serves as upper bounds. Among compared baselines, "Offline" denotes merging all source domains into one domain and training the model with the merged domain, while "IncFinetune" represents incrementally training the model in a domain-by-domain fashion. For each dataset, we report the accuracy on the nearest target domain (\(^{T+1}\)),

the average and worst accuracy of future \(K\) domains ("OOD avg.": \(_{k=1}^{K}Acc(^{T+k})\), "OOD worst": \(_{k\{1,2,,K\}}Acc(^{T+k})\)).

**Results on image classification tasks** are provided in Table 5, where we can observe that EvoS consistently achieves superior performance across three reported metrics on Yearbook and RMNIST datasets, compared with the methods in incremental training scenario. Especially, EvoS outperforms DRAIN by over \(1\%\) according the metric "OOD worst" on Yearbook and RMNIST, which means that our EvoS learns more robust evolving patterns. In addition, we notice that conventional DG methods IRM  and CORAL  perform worse than temporal DG method GI  on Yearbook and RMNIST, showing the importance of leveraging evolutionary patterns for generalization over temporal drifts. Though being effective for the small networks used in Yearbook and RMNIST, the advantage of GI disappears on fMoW dataset with backbone DenseNet-121, where its first-order Taylor expansion requires extremely huge computing resources (over 80G). And our available resources cannot afford it. When ablating the Taylor expansion, the performance of GI on fMoW is not the best. So GI is hard to expand on larger models and the similar issue also exists in DRAIN and LSSAE. Finally, we find that for dataset fMoW, not only our method performs unsatisfactorily but also other methods, except for the "offline" method (i.e., merging all source domain into one domain to train the model). We infer this may be due to the temporal drift is not well presented in this dataset.

**Results on text classification tasks** are shown in Table 6, where EvoS consistently achieves the best performances according to the average and worst accuracy of future \(K\) domains under the CDGTD setting. This can be owed to the more robust evolving patterns captured by our multi-scale attention module (MSAM). Similarly, IRM and CORAL show obvious performance drop compared with DRAIN, once again demonstrating the necessity to learn evolving patterns for the problem of CDGTD. And the large performance gap between continual learning methods (i.e., SI and A-GEM) and our method EvoS on dataset Arxiv verifies that our method EvoS fully utilizes the historical knowledge to learn evolutionary patterns, while SI and A-GEM do not consider this.

### Analytical Experiments

**Ablation Study.** Firstly, we study the influence of the stopping gradient \(()\) in the losses \(_{ce}^{t}\) and \(_{stan}^{t}\). The results of variant A and B in Table 3 almost degenerate to random predictions, compared with variant C. This suggests that using \(()\) in loss \(_{stan}^{t}\) is essential. Otherwise, the gradient of \(_{stan}^{t}\) would largely distort the learning of feature encoder, causing training collapse. Meanwhile, the inferior performance of variant C to EvoS also indicates that the gradient of \(_{ce}^{t}\) should not interfere with the learning of MSAM. Secondly, we ablate the losses \(_{adv}^{t}\) and \(_{con}^{t,w}\) to testify their necessity. We can see that the results of

   &  &  &  Access \\ multiple \\  } &  \(^{T+1}\) \\  } &  OOD \\ avg. \\  } &  OOD \\ \(^{T+1}\) \\  } &  OOD \\ avg. \\  } \\   & & & & & & & & & \\  Offline & - & ✗ & ✓ & 72.74 & 71.50 & 66.63 & 57.49 & 52.38 & 49.28 \\ IRM  & arXiv’19 & ✗ & ✓ & 71.04 & 70.31 & 68.97 & 51.11 & 45.89 & 42.86 \\ CORAL  & ECCV Workshops’16 & ✗ & ✓ & 71.34 & 70.08 & 68.68 & 50.98 & 45.77 & 42.71 \\ Mixup  & ICLR’18 & ✗ & ✓ & 73.34 & 71.16 & 69.29 & 57.58 & 52.77 & 49.62 \\ LISA  & ICMI’22 & ✗ & ✓ & 72.19 & 70.24 & 68.60 & 56.53 & 52.41 & 49.67 \\ GI  & NeurIPS’21 & ✗ & ✓ & 68.06 & 66.32 & 64.64 & 53.34 & 49.19 & 46.13 \\  InCintense & ✓ & ✗ & 73.57 & 71.98 & 69.80 & 56.22 & 52.43 & 49.37 \\ Mixup  & ICLR’18 & ✓ & ✗ & 73.07 & 71.52 & 69.44 & **56.64** & 52.95 & 49.97 \\ EWC  & arXiv’16 & ✗ & ✗ & **73.64** & 71.53 & 68.99 & 56.60 & 52.78 & 49.73 \\ SI  & ICMI’17 & ✓ & ✗ & 72.58 & 71.50 & 69.61 & 49.98 & 47.27 & 44.77 \\ A-GEM  & ICLR’19 & ✓ & ✗ & 72.23 & 71.16 & 69.10 & 52.02 & 48.91 & 46.03 \\ DRAN  & ICLR’23 & ✓ & ✗ & 73.42 & 71.75 & 69.69 & 56.04 & 52.07 & 48.97 \\ 
**EvoS** & - & ✓ & ✗ & 73.42 & **72.36** & **70.19** & **56.60** & **53.15** & **50.19** \\   
 For Huffpost and Arxiv, backbone DistilBERT-base is too big to apply the full GI and DRAIN. So we apply DRAIN only to the classifier and apply GI without the fine-tuning stage. \\ 

Table 2: Accuracy (%) on Huffpost and Arxiv. The best and second-best results in CDGTD setup are bolded and underlined. (Huffpost: \(K=3\), Axriv: \(K=7\))

   &  Scale \\ single \\  } &  Loss \\ multiple \\  } &  Loss \\ multiple \\  } &  Using sg(\(\))? \\  } &  Using sg(\(\)?) \\  } &  Using \\ truncation \(\)? \\  } &  OOD \\ avg. \\  } \\  Variant A & - & ✓ & ✓ & ✓ & No & No & Yes & 51.28 \\ Variant B & - & ✓ & ✓ & Yes & No & Yes & 55.37 \\ Variant C & - & ✓ & ✓ & No & Yes & Yes & 93.97 \\  Variant D & - & ✓ & - & - & Yes & Yes & Yes & 93.25 \\ Variant E & - & ✓ & ✓ & - & Yes & Yes & Yes & 94.75 \\ Variant F & - & ✓ & - & ✓ & Yes & Yes & Yes & 94.27 \\  Variant G & - & ✓ & ✓ & ✓ & Yes & Yes & No & 94.46 \\ EvoS & - & ✓ & ✓ & ✓ & Yes & Yes & Yes & **95.53** \\ Variant H & ✓ & - & ✓ & ✓ & Yes & Yes & Yes & 94.09 \\  

Table 3: Ablation study of EvoS on dataset Yearbook.

[MISSING_PAGE_FAIL:9]

**Effect of Memory Pool Length.** In the main experiments, we do not restrict the size of the memory pool \(\), since the datasets used in our paper has a moderate number of domains and the memory cost is small. Nevertheless, a fixed memory pool size is more practical when considering a lifelong process, i.e., \(T\). Thus, we additionally conduct the experiment where the memory pool \(\) is implemented as a FIFO queue with different fixed length \(L\). That is, only the statistics for up to the \(L\) most recent historical domains can be stored. The results on Yearbook in Fig. 4(b) demonstrate that our method generally performs well and a relatively large memory pool length is better.

**t-SNE Visualization of Standardized Features.** To verify our method appropriate for generalization, we visualize the standardized features of all target domains via t-SNE  on RMNIST and Yearbook in Fig. 4(a). It can be observed that the standardized features of target domains are well aligned, suggesting that MASM can capture evolving patterns effectively and feature standardization helps address temporal drift appropriately. These enable EvoS to achieve generalization on future domains.

**Hyper-parameter Sensitivity.**\(\) and \(\) control the truncation range and the tradeoff the adversarial loss \(_{adv}\), respectively. Fig. 4(c) shows the sensitivity of EvoS to them on Yearbook, where \(\{0.1,0.5,1.0,1.5,2.0,2.5,3.0\}\) and \(\{0.1,0.5,1.0,1.5,2.0,5.0,10.0,15.0,20.0\}\). We see that EvoS is more sensitive to \(\) than \(\), and large \(\) values significantly worsen performance. In practice, we suggest selecting \(\) from a range \(\)1. For \(\), its effect is modest and \(=1\) generally works well.

## 5 Conclusion

This paper considers a more challenging problem of continual domain generalization over temporal drift (CDGTD) than conventional DG, where the model is incrementally trained with sequential domains and is required to generalize to unseen domains that are not too far into the future. To this end, we propose an Evolving Standardization (EvoS) method to learn the evolving pattern of sequential domains over the temporal drift and hope to achieve the generalization by transforming the domain distribution into a common normal distribution via feature standardization. Experiments on real-world datasets including images and texts verify the efficacy of EvoS. Since existing DG works focus on conventional setting, we hope this work can encourage more research works on CDGTD.

Figure 4: (a): Visualization of standardized features from each test domain on Yearbook and RMNIST. Different colors denote different domains. (b): Effect of the memory pool length \(L\) on dataset Yearbook. (c):Hyper-parameter sensitivity of \(\) and \(\) on Yearbook

Figure 3: Visualization of decision boundaries for the model at current time point \(_{t}\) on inter-twinning moons 2D problem. Blue line and points are the decision boundary and samples in current domain \(^{t}\), and red line and points are the decision boundary and samples in the next future domain \(^{t+1}\).