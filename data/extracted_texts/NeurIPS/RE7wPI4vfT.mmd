# Your Diffusion Model is Secretly a Noise Classifier and Benefits from Contrastive Training

Yunshu Wu1, Yingtao Luo2, Xianghao Kong1, Evangelos E. Papalexakis1, Greg Ver Steeg1

1University of California Riverside, 2Carnegie Mellon University

{ywu380,xkong016,epapalex,gregoryv}@ucr.edu,yingtaol@andrew.cmu.edu

###### Abstract

Diffusion models learn to denoise data and the trained denoiser is then used to generate new samples from the data distribution. In this paper, we revisit the diffusion sampling process and identify a fundamental cause of sample quality degradation: the denoiser is poorly estimated in regions that are far Outside Of the training Distribution (OOD), and the sampling process inevitably evaluates in these OOD regions. This can become problematic for all sampling methods, especially when we move to _parallel sampling_ which requires us to initialize and update the entire sample trajectory of dynamics in parallel, leading to many OOD evaluations. To address this problem, we introduce a new self-supervised training objective that differentiates the levels of noise added to a sample, leading to improved OOD denoising performance. The approach is based on our observation that diffusion models implicitly define a log-likelihood ratio that distinguishes distributions with different amounts of noise, and this expression depends on denoiser performance outside the standard training distribution. We show by diverse experiments that the proposed contrastive diffusion training is effective for both sequential and parallel settings, and it improves the performance and speed of parallel samplers significantly. 1

## 1 Introduction

Denoising diffusion models  achieve state-of-the-art performance on various unsupervised learning tasks and have intriguing theoretical connections to methods like denoising autoencoders , VAEs , stochastic differential equations , information theory , and score matching . Diffusion models are presented with data samples corrupted by a _forward_ dynamical process that progressively adds more Gaussian noise and trained to _reverse_ this dynamics or denoise the corrupted samples. Samples are then generated by applying the reverse dynamics on images of pure Gaussian noise to produce high-quality samples from the target distribution.

The key to the success of diffusion models is the dynamics that gradually bridges the source and a target distribution, but it suffers from slow sampling, as sequentially simulating these dynamics can take thousands of denoising steps for one sample. Most recent works attempt to expedite the sequential dynamics by taking fewer, larger steps . However, the complexity of these samplers and the need for expensive sampling hyper-parameter grid searches tailored to specific datasets makes them difficult to generalize.

Shih et al. 2024 suggests a different approach by randomly initializing the entire path of the reverse dynamics and then updating all the steps in the path in parallel. The parallel sampling approach promises to drastically reduce wall-clock time at the cost of increased parallel computation. However, it encounters a problem that has largely gone unnoticed in the sequential sampling literature: whilesequential paths sampled during generation are designed carefully to stay as close as possible to the forward paths that add noise to data, the parallel sampler often evaluates in regions far from where the score estimate (the denoiser) is trained, as illustrated in Fig. 1. The shading shows that the error of the score estimate is large in these regions, leading to poor performance for parallel samplers. Discretization errors can lead to similar issues, even for standard sequential samplers.

We propose to improve the training of diffusion models so that the error of the denoiser is reduced in OOD regions, and we hypothesize that this should significantly improve the performance for parallel samplers as they require more OOD evaluations. Our approach starts with an unexpected connection: the optimal MSE denoiser that defines the diffusion dynamics _also defines an optimal noise classifier_ that distinguishes between samples with different amounts of noise. This provides a useful additional signal for training, because optimizing for the noise classification task involves evaluating the denoiser for one noise level on samples from distributions at different noise levels, while standard MSE optimization only evaluates the denoiser on samples from the matching noisy distribution. Accurate denoiser evaluation in regions that are OOD for standard diffusion training is important for robust sampling dynamics.

**Contributions:**

* We use the information-theoretic formulation of diffusion to draw connections between diffusion, log-likelihood ratio estimation, and classification. This reveals that optimal diffusion denoisers are also implicitly optimal classifiers for predicting the amount of noise added to an image.
* We leverage the noise classifier (via density ratio estimation ) interpretation to introduce a novel self-supervised loss function for regularizing diffusion model training, which we call the Contrastive Diffusion Loss (CDL). CDL provides training signal in regions that are OOD for the standard MSE diffusion loss.
* We show that CDL improves the trade-off between generation speed and sample quality, and that this advantage is consistent across different models, hyper-parameters, and sampling schemes. The improvement is especially substantial for parallel diffusion samplers  which rely heavily on OOD denoiser evaluations.

## 2 Diffusion Model Background: Optimal Denoisers are Density Estimators

The defining feature of diffusion models is a sequence of distributions that progressively add noise to the data, from which we then learn to recover the original data. The ("variance preserving" ) channel that mixes the signal \(\) with Gaussian noise is defined as \(_{}}+}\) with \((0,), p()\), where \(\) represents the log of the Signal-to-Noise Ratio (SNR), \(p()\) is the

Figure 1: We plot the error in the score estimate for an 1D two mode Gaussian example where diffusion dynamics bridge between a Gaussian and a mixture (see Appendix A.3). Regions near the standard forward training data paths have lower error magnitude (light), whereas other areas have higher error magnitude (dark). While sequential samplers adhere as closely as possible to low-error regions, parallel samplers initialize and update the entire sample trajectory (blue trajectories), leading to evaluations in high-error regions. When the sampling trajectory is initialized, most are inevitably in the OOD regions and will update to the low-error regions gradually.

unknown data distribution for \(^{d}\), and \(()\) is the sigmoid function. We define the sequence of intermediate distributions drawn according to this channel with a subscript as \(p_{}()\). By definition, we express \(_{}p_{}()=p()\) in this paper. Note that we use a different scaling convention for noise from  and , where the former one takes \(+\) as the forward noising channel and the latter one takes \(}+}\) as the forward noising channel. For further detailed relationships among these scaling conventions, please check App. B.3.

The minimum mean square error (MMSE) estimator \(}\) for recovering \(\) from the noisy channel that mixes \(\) and \(\) can be derived via variational calculus and written as follows.

\[}(_{},)_{  p(|_{})}[]=_{}(,)}_{p()p()}[\|-}(_{},)\|_{2}^{2}].\] (1)

Sampling from the true posterior is typically intractable, but by using a neural network to approximate the solution to the regression optimization problem, we can get an approximation for \(}\). From , we see that log-likelihood can be written _exactly_ in terms of an expression that depends only on the MMSE solution to the Gaussian denoising problem, i.e.

\[- p()=c+}{{2}}_{-}^{}_{p( )}[\|-}(_{},)\| _{2}^{2}]\;d.\] (2)

The constant, \(c=d/2(2 e)-_{0}^{}d\;()\) does not depend on data and will play no role in our approach, as it cancels out in our derivations in Sec. 3.

## 3 What Your Diffusion Model is Hiding: Noise Classifiers

We now introduce our first main result, which shows that diffusion models implicitly define optimal noise classifiers. Eq. (2) expresses the probability density of the data directly in terms of the denoising function. If we apply Eq. (2) to the noisy distributions that bridge the data and a Gaussian, \(p_{}()\), we can see that all mixture densities can be written in terms of the same optimal denoising function, \(}(,)\). The complete derivation is presented in App. A.2.

\[- p_{}() =c+}{{2}}_{-}^{}d\; _{p()}[\|-b}(_{ },)\|_{2}^{2}]\] (3) \[_{} +\] (4) \[ ^{-1}(()()),\;b\] (5)

Intuitively, if we find the optimal denoising function for the data distribution, it may be hypothesized that it can denoise an already _noisy_ version of the data distribution. Using Eq. 2, this directly translates into an expression for density of mixture distributions. Differences in log likelihoods lead to cancellation of constants, and these Log Likelihood Ratios (LLR) are related to the optimal classifiers  as we show below.

To connect LLRs with classification, consider the following generative model. We generate a random binary label \(q(y= 1)=1/2\). Then, conditioned on \(y\), we sample from some distribution \(q(|y)\). Given samples \((,y) q(,y)=q(|y)q(y)\), the Bayes optimal classifier is:

\[q(y|) =|y)q(y)}{q()}=|y)q(y)}{q(|y=1)q(y=1)+q(|y=-1)q(y=-1)}\] \[=1/(1+|-y)}{q(|y)})=1/(1+(y( q(|y=-1)- q(|y=1))))\] \[ q(y|) =-(1+(y|y=-1)}{q(|y=1)}))=- {softplus}(y|y=-1)}{q(|y=1)}))\] (6)

In the second line, because \( y,q(y)=1/2\), these constants cancel out. Then we can just expand definitions and re-arrange to write in terms of log probabilities.

**Contrastive Diffusion Loss (CDL)** Our next contribution is to use the new connection between diffusion denoisers and noise classifiers to define a new training objective. We set the distributions \(q(|y=1)\) and \(q(|y=-1)\) to be two distributions at different noise levels that we can write in terms of the optimal diffusion denoiser from Eq. 3. So we have \(q(|y=1) p()\), the data distribution,and \(q(|y=-1) p_{}()\), for some noise level, \(\). Then given a sample \((,y) q(,y)\) the per-sample cross-entropy loss for the noise classifier, Eq. (6), is as follows.

\[_{CDL}=_{q(,y)}[(y( p_{ }()- p()))]\] (7)

We can estimate both densities directly from our denoising model using Eq. (3), with the constants canceling out in the process. This loss differs significantly from the standard diffusion loss. Intuitively, to distinguish between a sample from the data distribution, \(p()\), versus a noisy version of the data distribution, \(p_{}()\), we need to evaluate denoisers on points from both distributions. In standard diffusion training, denoisers at noise level \(\) are only trained on samples from \(p_{}(x)\).

_Limitations:_ We highlight that CDL is more expensive to compute than the standard diffusion loss, significantly increasing the total cost of diffusion model training. Implementation details appear in App. B.4 and training cost details appear in App. B.5.

**Choice of noise to contrast** Next, let's break the Log-Likelihood Ratio (LLR) term in Eq. (7) down to see how to choose \(\) to maximize the benefit of CDL. Combining Eq. (2) and Eq. (3) we have Eq. (8), where the constant cancels out.

\[= p_{}()- p()=_{- }^{}d\ _{p()}[\|-}(, )\|_{2}^{2}]-_{p()}[\|-b}(,)\|_{2}^{2}]\] (8) \[+\]

Note that the input \(\) to the LLR term may come from two different distributions, which breaks the standard synchronous denoising pair \((_{},)\) into asynchronous. When it's from data distribution \( p()\), \(=_{}\); and when it's from some noisy data distribution \( p_{}()\), \(=_{}\).

From Eq. (8) we see that \(}(,)\) is trained on four pairs: \((_{},)\), \((_{},)\), \((_{},)\) and \((_{},)\), where \(^{-1}(()())<(,)\) (Eq. 5). During standard training, only the first two pairs are trained (Eq. 1). This means that our CDL objective trains the denoiser to perform correctly even for samples from distributions that are noisier or cleaner than the specified noise level (a pair like \((_{},)\) or \((_{},)\)). This can be useful for both sequential and parallel sampling settings. During sequential sampling, extra error noise added due to discretization errors can be corrected by the denoiser trained with CDL. As for parallel sampling, CDL helps with evaluations on asymmetric pairs \((_{},)\) or \((_{},)\) which we refer to OOD regions for standard diffusion loss.

In practice, diffusion training pipelines are highly tuned on popular datasets like CIFAR10 and ImageNet, so the amplitude of discretization errors during sampling is small, meaning that errors won't nudge points too far away from the true trajectory. Therefore, when evaluating CDL objective, we sample some large-valued \(\)s, which corresponds to classifying only small differences in noise levels. Empirically we find that \(\) or \(\) performed equally good.

**Denoising, sampling dynamics, and the score connection** We have focused so far on denoising and density estimation, but we now want to connect this discussion to the primary use case for diffusion models and the focus of Sec. 4, _sampling_. There are many choices in how to implement sampling dynamics , but all of them rely on the _score function_, \(_{x} p_{}()\). The score function points toward regions of space with high likelihood, and by slowly transitioning (or annealing), from the score function of a noisy distribution to one closer to the data distribution, we can build reliable sampling dynamics. To connect denoisers with sampling we must show that a denoising function, \(}\), that is optimal according to Eq. 1 also specifies the score function.

\[_{x} p_{}()=-}(,)}{ }\] (9)

The derivation is straightforward and is given in Appendix A.1.

## 4 Sequential and Parallel Sampling with Diffusion Models

Sampling dynamics are typically presented in terms of a stochastic process \(\{_{t}\}_{t=1}^{T}\) with timestep, \(t\), rather than in terms of log SNR, \(\). We will denote \(_{t}_{(t)},p_{t}() p_{(t)}()\), to connect to our previous notation, with \((t)\) representing a monotonic relationship described in App. B.3. Note that decreasing \(\)-SNR \(\) corresponds to increase timestep \(t\), since smaller \(\)-SNR means there is more noise added to the data.

The general form of sampling dynamics is a process of slowly transitioning from samples of a simple and tractable distribution to the target distribution. Specifically, start with an isotropic Gaussian \(_{T}(0,)\), the sampler steps through a series of intermediate distributions with noise levels \(\{T,T-1,,1\}\) following the score estimates. Many works  interpret diffusion models as stochastic differential equations (SDEs). The forward process is in the form of

\[d_{t}=_{t},t)}_{s}dt+_{ }d_{t},_{0} p()\] (10)

where \(_{t}\) is the standard Wiener process/Brownian motion, \(f\) and \(g\) are drift coefficient and diffusion coefficient of \(_{t}\) separately. The reverse process of Eq. 10 is then used to generate samples

\[d_{t}=_{t},t)-g^{2}(t)_{} p_{ t}())}_{s}dt+_{}d_{t},_{T} p( )\] (11)

Depending on choices for \(f,g\), we can get either a stochastic or ordinary (deterministic) differential equation. Either way, numerical differential equation solvers are used to approximate the true dynamics. The solver introduces discretization errors at each step, causing the trajectory to deviate into the OOD region where the score (or denoiser) is poorly estimated, further compounding the errors. More discretization steps reduce accumulated error and leads to better sample quality, at the expense of more sequential computation. As a result, a significant limitation of diffusion models is that they require many iterations to produce high quality samples.

**Sequential Sampling** The influential diffusion sampler DDPM  iterates over thousands of discretization steps in simulating the dynamics. Recently, many sequential sampling methods have been developed to take fewer and larger steps while introducing less error . Specifically, Karras et al. 2022 studies the curvature shape of SDE/ODE trajectory and suggests a discretization technique where the resulting tangent of the solution trajectory always points towards the denoiser output. However, speeding up the sequential sampling sacrifices generation quality. Furthermore, the SOTA sequential samplers  require hyperparameter tuning and grid search on specific datasets, which poses challenges to the generalization of these samplers to other datasets.

**Parallel Sampling** Shih et al. 2024 explores a parallel sampling scheme, where the entire reverse process path is randomly initialized and then all steps in the path are updated in parallel. Parallel sampling is based on the method of Picard iteration, an old technique for solving ODEs through fixed-point iteration. An ODE is defined by a drift function \(s(,t)\) and initial value \(_{0}\). In the integral form, the value at time \(t\) can be written as

\[_{t}=_{0}+_{0}^{t}s(_{u},u)\,du\]

In other words, the value at time \(t\) must be initial value plus the integral of the derivative along the path of the solution. This formula suggests a natural way of solving the ODE by starting with a guess of the solution \(\{_{t}^{k+1}:0 t 1\}\) at initial iteration \(k=0\), and iteratively refining by updating the value at every time \(t\) until convergence 2

**(Picard Iteration)** \[_{t}^{k+1}=_{0}^{k}+_{0}^{t}s(_{u}^{k},u)\,du\] (12)

To perform Picard iterations numerically, which is shown in Fig. 2, we can write the discretized form of Eq. 12 with step size \(1/T\), for \(t[0,T]\):

\[_{t}^{k+1}=_{0}^{k}+_{i=0}^{t-1}s(_{i}^{k},i/T)\] (13)

Figure 2: The computation graph of Picard iteration for parallel sampling 

We see that the expensive computations \(\{s(_{i}^{k},i/T):i[0,T)\}\) can be performed in parallel. After some number of Picard iterations, the error difference between two iterates \(\|_{t}^{k+1}-_{t}^{k}\|_{2}^{2}\) drops below some convergence threshold. This converged trajectory, \(_{t}^{*}\), should be close to the sequential sampler trajectory. Looking at the example in Fig. 1, we show the trajectories of three iterations \(k=1,2,3\). The trajectories before convergence are consistently appearing in the regions with high score error.

## 5 Experiments

We sample from models fine-tuned on Contrastive Diffusion Loss (CDL) via both parallel and sequential diffusion samplers across a variety of generation tasks, including complex low-dimensional manifold 2D synthetic data and real-world image generation. Our results demonstrate that employing CDL as a regularizer in models trained with standard diffusion loss enhances density estimation and sample quality while also accelerating convergence in parallel sampling. All sampling tests are done on A6000 GPUs. We visualize CDL image generation examples in App. C.

Training configurationOur method is architecture-agnostic. In synthetic experiments, we adopt a simple MLP architecture with positional encoding for timesteps 3, as it is one of the most versatile models in the literature. In real-world experiments, we consider the standard diffusion loss with two training configurations: DDPM by Ho et al. 2020 and EDM by Karras et al. 2022. For more details on model training, data split, and hyper-parameters, please refer to App. B.2.

Generation quality metricsFor real-world data, our intrinsic metric is Frechet Inception Distance (FID) score . The number of images we generated for FID computation follows their baseline models' FID settings, and the FID scores are computed between \(5,0000\) generated images and all available real images.

For synthetic data, to measure how well the generated samples resemble samples from the ground truth distribution, we use the (unbiased) kernel estimator of the squared Maximum Mean Discrepancy (MMD), with Gaussian kernel with bandwidth set empirically as described in App. B.1.

Sampling speed metricsWe adopt the following three metrics: (1) Neural function evaluations (NFE) for all settings, i.e. how many times the denoiser is evaluated to produce a sample; (2) For the parallel setting, we report the number of parallel Picard Iterations; (3) Furthermore for the parallel setting, the wall-clock time is reported. While parallel sampling can use fewer total iterations and less wall-clock time than a sequential sampler, this may come at the cost of an increase in the total number of function evaluations. This gap is called the algorithm inefficiency. In the subsequent section, we use contrastive diffusion loss as a training regularizer for standard diffusion losses and refer to the corresponding models as CDL-regularized models.

### Parallel Sampling

In the parallel setting, we use Parallel DDPM sampler  with 1000-step diffusion sampling. And for synthetic experiment, to reflect sampling speed by only number of Picard iteration and wall-clock time, we don't use the sliding window technique, and the 2D data is small enough to fit the whole sampler trajectory in GPU memory. While for real-world experiment, sliding window is still applied.

Synthetic DatasetWe consider the 2D Dino dataset , characterized by its highly nonlinear density concentrated on a low-dimensional manifold. For baselines, we employ the standard DDPM loss , as all standard diffusion losses similarly minimize a sum of MSE losses between the actual and estimated denoisers. Both CDL-regularized and DDPM-objective-trained models are trained with a MLP where timestep is encoded by positional encoding. We train it for 2000 epochs to ensure convergence and check the training and validation loss curve to avoid overfitting.

In Fig. 4, it is clearly demonstrated that the parallel generated samples from the CDL-regularized model is much better than the model trained only with the standard DDPM loss, especially around the chin, eyes and paws, where the manifolds are close to each other and difficult to distinguish and learn. From the MMD plot, we see that comparing to the baseline curve trained only with standard DDPM loss, the CDL-regularized curve converges faster with smaller number of Picard iterations and better sample quality (lower MMD scores). Table. 1 shows the sampling speed results, from where we see that CDL-regularized model converges faster with lower final MMD and better sample quality.

Real-world DatasetsWe select "DDPM++ cont. (VP)" and "NCSN++ cont. (VE)" models by  trained on CIFAR-10 at \(32 32\), unconditional FFHQ, and unconditional AFHQv2 [15; 10; 3] as baselines, comparing to the corresponding CDL-regularized models. We adopt the pre-trained models from Ho et al. 20204 and Karras et al. 20225. More experimental results can be found in App. B.2. As shown in Tab. 2, CDL-regularized models always outperformed baselines with respect to FID scores.

### Sequential Sampling

While CDL clearly improves parallel sampling quality and convergence speed, we also show that it improves the trade-off between generation speed and sample quality in the sequential setting. As for sequential diffusion sampling choices, we consider the DDPM sampler from Ho et al. 2020, and both the deterministic and stochastic samplers from Karras et al. 2022. To ensure fair comparisons, we adopt the original sampling hyper-parameter settings for all baselines.

Deterministic samplersFor FID test, we follow the exact sampling settings outlined in Karras et al. 2022 for each dataset. FID scores are reported in Tab. 3, for sequential deterministic EDM samplers, CDL objective ensures that the generation quality is consistently similar or better.

In principle, increasing NFE has the potential to decrease the overall discretization errors, consequently leading to improved sample quality. However, in practice we observed an unusual behavior6 with the Karras deterministic sampler - as NFE increases, the FID score deteriorates (Fig. 6). In contrast to EDM models, CDL-regularized models exhibit a more stable FID score. This partially resolves the deterministic sampler sensitivity while improving the quality.

Stochastic samplersIn practice, stochastic samplers often yield superior performance compared to deterministic ones. However this is not true in Karras et al. 2022: stochastic samplers outperform deterministic ones only on challenging datasets, for simpler datasets, the introduction of stochasticity not only fails to enhance performance but exhibits image degradation issues, characterized by a loss of detail. They attribute this phenomenon to L2-trained denoisers excessively removing noise at each step (always remove more than it should), and propose to slightly increase the standard deviation (\(S_{}\)) 7 of newly added noise to 1.007. We argue that this approach may not totally resolve the issue and instead complicates the hyperparameter grid search process by introducing an additional parameter, \(S_{}\). Also, this \(S_{}\) logically serves the same function as another hyperparameter \(_{i}\), where both of them control the amount of noise to add to reach a higher noise level.

In this experiment, we conducted two stochastic sampling configurations for our baseline EDM-trained models. The first configuration, referred to as EDM-opt, operated at the EDM optimal setting with \(S_{}=1.007\). The second, named as EDM-sub-opt, used a setting with \(S_{}=1.00\), effectively disabling \(S_{}\). As for CDL configuration, we exclusively examined the scenario with \(S_{}=1.00\) to determine whether CDL could address the problem of excessive noise removal.

The results, as visualized in Figure 7, indicate that CDL outperforms EDM in both \(S_{}\) configurations. Notably, CDL not only improves upon the EDM-sub-opt configuration (dark blue line) but also surpasses the performance of the EDM-opt configuration (light blue line), even at its optimal setting. This not only demonstrates that CDL robustly provides a better sample quality, but also suggests that CDL can eliminate the need for the hyperparameter \(S_{}\). This reduction enables a more efficient grid search for the optimal EDM sampling settings, potentially enhancing the practicality of using such a sampler for other applications.

## 6 Related Work

The generative modeling trilemma  seeks generative models that produce samples (i) quickly, (ii) with high quality, and (iii) good mode coverage. Diffusion models excel at the latter two but a large amount of research has attempted to address the problem of slow sampling speed. From the inception of diffusion models , dynamics has been at the forefront, so most work has focused on

Figure 6: The FID comparison between our CDL and the baseline EDM in the deterministic sampler experiment.

    &  &  &  \\   & unconditional & conditional & unconditional & unconditional \\  VP & \(2.00 0.02\) & \(1.84 0.02\) & \(2.04 0.00\) & \(2.38 0.01\) \\ CDL-VP & \(\) & \(\) & \(\) & \(\) \\  VE & \(2.01 0.01\) & \(1.81 0.01\) & \(2.17 0.00\) & \(2.56 0.03\) \\ CDL-VE & \(2.01 0.01\) & \(1.81 0.01\) & \(\) & \(\) \\  NFE (EDM/CDL) & 35 & 35 & 79 & 79 \\   

Table 3: Evaluating sequential deterministic EDM samplers generation quality. For reported FID scores, we run three sets of random seeds and reported the average with uncertainty.

the interpretation of the dynamics as a differential equation that can be sped up through accelerated numerical solvers [30; 34; 42; 9; 17]. Our approach is compatible with any of these approaches as we are sampler agnostic, seeking only to improve the input to the sampler, which is the denoiser or score function estimator, through regularization during the diffusion model training. A separate line of work instead attempts to distill a diffusion model into a faster model that achieves similar sampling quality [27; 35; 21; 38; 39]. In principle, these methods could also benefit from distilling based on a more robust base diffusion model trained with CDL.

Diffusion models admit a surprisingly diverse array of mathematical perspectives, like variational perspectives [6; 7; 12], differential equations [34; 20], and nonequilibrium thermodynamics . Our approach is mostly inspired by connections between the information-theoretic perspective [13; 14] and the score matching perspective [31; 33; 32; 8; 37]. In particular, we point out that score function estimates in traditional diffusion training are sub-optimal, and the information-theoretic perspective leads to a new objective (CDL) that can improve the score estimate.

While previous diffusion models focus on log-likelihood estimation, we consider a different approach based on density ratio estimation and noise contrastive estimation [4; 23], which inspired several notable developments in machine learning [1; 25]. A few works have considered contrastive learning inspired modifications to diffusion either to enforce multimodal data relationships [16; 43], for style transfer , or for guidance during generation , but none use the diffusion model as a noise classifier to improve diffusion training as we do. Most similar to our approach are methods that use Density Ratio Estimation (DRE) to estimate a ratio between the data density and some simple noise distribution. The density ratio can be estimated by learning to contrast between data samples and samples from the noisy distribution [4; 36]. Recent work generalized the idea to consider classifying between samples along a sequence of distributions between source and target [26; 2]. Our contribution is to relate this approach to diffusion models by noting that standard diffusion models implicitly already implement the required classifiers for distinguishing distributions on the path from the data distribution to a Gaussian distribution. Concurrent work makes a similar connection but while we focus on improving diffusion models by interpreting them as noise classifiers,  focused on the converse perspective, improving density ratio estimation by interpreting DREs as denoisers.

## 7 Conclusion

In this paper, we introduced a novel connection between diffusion models and optimal noise classifiers. While this relationship has a variety of potential applications that could be explored in future work, we used the connection to propose a new self-supervised loss regularizer for diffusion models, the Contrastive Diffusion Loss (CDL). CDL reduces the error of the learned denoiser in regions that are OOD for the standard loss. We showed that CDL improves the robustness of diffusion models across all types of sampling dynamics, and leads to significant speed-ups for a promising new generation of parallel samplers.

Figure 7: The FID comparison between our CDL and the baselines EDM in the stochastic sampler experiment on CIFAR-10. CDLâ€™s performance is strictly better for all \(S_{}\), outperforming the optimal setting of EDM which inflates the standard deviation \(S_{}\) of the newly added noise.