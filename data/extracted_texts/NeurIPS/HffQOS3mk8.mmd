# Diffusion-Based Probabilistic Uncertainty Estimation

for Active Domain Adaptation

 Zhekai Du, Jingjing Li

School of Computer Science and Engineering

University of Electronic Science and Technology of China

zhekaid@std.uestc.edu.cn, lijin117@yeah.net

Corresponding Author.

###### Abstract

Active Domain Adaptation (ADA) has emerged as an attractive technique for assisting domain adaptation by actively annotating a small subset of target samples. Most ADA methods focus on measuring the target representativeness beyond traditional active learning criteria to handle the domain shift problem, while leaving the uncertainty estimation to be performed by an uncalibrated deterministic model. In this work, we introduce a probabilistic framework that captures both data-level and prediction-level uncertainties beyond a point estimate. Specifically, we use variational inference to approximate the joint posterior distribution of latent representation and model prediction. The variational objective of labeled data can be formulated by a variational autoencoder and a latent diffusion classifier, and the objective of unlabeled data can be implemented in a knowledge distillation framework. We utilize adversarial learning to ensure an invariant latent space. The resulting diffusion classifier enables efficient sampling of all possible predictions for each individual to recover the predictive distribution. We then leverage a t-test-based criterion upon the sampling and select informative unlabeled target samples based on the p-value, which encodes both prediction variability and cross-category ambiguity. Experiments on both ADA and Source-Free ADA settings show that our method provides more calibrated predictions than previous ADA methods and achieves favorable performance on three domain adaptation datasets.

## 1 Introduction

Machine learning algorithms heavily depend on large amounts of labeled data. However, in many real-world scenarios, the distribution of data can change over time or across different domains, which challenges the training of models to perform consistently in all situations. Unsupervised Domain Adaptation (UDA) [1; 2; 3] addresses this problem by transferring knowledge learned from a labeled source domain to an unlabeled target domain. Despite impressive achievements, UDA struggles to bridge the performance gap with fully supervised methods due to the lack of target-supervised information. Recognizing this limitation, a promising alternative is Active Domain Adaptation (ADA) [4; 5; 6], which actively annotates a small subset of target data to greatly benefit the UDA model.

In ADA, the primary concern revolves around designing a criterion for selecting the most informative target samples that can have the maximum impact on performance once annotated. Existing ADA methods have been mainly enlightened by traditional Active Learning (AL) methods [7; 8; 9; 10] and rely on criteria that consider both predictive uncertainty and representativeness of the entire distribution. While they have shown empirical success, they usually handle the distribution shift by further measuring the representativeness of the target domain through various criteria (e.g., the output of a domain discriminator , free energy score , weighted clustering ). However, thesemethods still estimate uncertainty based on metrics like confidence , distinctive margin , and entropy , obtained from a deterministic model. It is worth noting that distribution shift can easily lead to overconfident predictions for deep models , especially deterministic ones [14; 15], which results in poorly calibrated point estimates and unreliable uncertainty estimation in ADA.

In this work, we aim to accurately estimate the posterior distribution of the target variable \(\) given the input \(\) for target domain samples (i.e., \(p(|)\)), by modeling the uncertainty in both data generation and model prediction processes. To achieve this, we utilize diffusion-based generative models [16; 17; 18] to explore the implicit predictive distribution beyond a point estimate for each target domain sample. Specifically, we harness the capabilities of diffusion models for classification , which involve forward and reverse diffusion chains to generate predictions from the conditional predictive distribution, without any assumptions on the parametric form of \(p(|)\). Notably, another work  also tackles the miscalibration issue in ADA by considering the model prediction as a distribution on the probability simplex and introducing a Dirichlet prior over predictive distributions. However, such a constrained parametric form might not be effective if the prior distribution fails to accurately capture the predictive uncertainty . Additionally, their approach only focuses on modeling the probability distribution in the model prediction space, neglecting the inherent uncertainty present in the data representation from a generative perspective.

To approximate the posterior distribution of both latent data representation and model prediction, we use variational inference by optimizing the evidence lower bound (ELBO) corresponding to the log-likelihood of all data points. Concretely, we show that for labeled data, the training objective can be formulated by Variational Autoencoder (VAE)  and a diffusion-based classifier  in the latent space. For unlabeled data, they can also be effective utilized by optimizing the ELBO, which can be implemented in a knowledge distillation framework. With the formulation, we establish a two-stage training procedure where we first learn a guided classifier for mean estimate and then train a diffusion probabilistic model guided by that for predictive distribution recovery. To ensure a shared latent embedding that can be used to solve tasks for both labeled and unlabeled data, we incorporate adversarial learning [1; 22], resulting in a Diffusion-based Adversarial Probabilistic Model (DAPM). With a collection of predictions generated by DAPM for each unlabeled target sample, we conduct t-test  between scores of the two most predicted classes and select the most informative samples based on the p-value, which generally takes into account the sampling scale, prediction variability and the cross-category ambiguity to estimate the prediction uncertainty for active annotation.

**Our contributions:** 1) We formulate ADA in a probabilistic framework for uncertainty estimate, which leverages the abilities of VAE and diffusion-based classification models to capture distributions of both data and prediction. 2) We conduct a two-stage training procedure and use adversarial learning to ensure an invariant latent space. A t-test-based criterion is utilized to estimate informativeness from multiple aspects. 3) We show that our method can naturally handle active learning for both UDA and Source-Free DA (SFDA). Experiments on three datasets show the effectiveness of our method.

## 2 Related Work

**Active Learning**[24; 25] aims to tap the fully supervised performance by only annotating a small subset of training data. The selection of informative samples can be made using a variety of criteria. Committee-based methods [26; 27; 28; 29] leverage diverse classifiers and evaluate the data informativeness based on their disagreement. Representativeness-based methods [30; 31] aim to select samples that are diverse or representative enough of the entire training distribution, typically through clustering  or core-set selection . Uncertainty-based methods resort to various uncertainty heuristics such as entropy , confidence , and best-vs-second-best score , etc, to select the most uncertain instances. However, these AL methods will fail when there is a distribution shift between labeled and unlabeled data, limiting their applications in domain adaptation.

**Active Domain Adaptation.** A series of ADA works have been conducted to select the most informative target samples under domain shift. As an early work, AADA  applies a domain discriminator to evaluate the domainness of target samples and weights it with entropy-based uncertainty. TQS  designs a transferrable query criterion based on a classifier committee and a domain discriminator to handle domain shift. CLUE  performs an entropy-weighted clustering to select both uncertain and diverse samples. SDM  uses a distinctive margin loss for training and selects data lying in the margin. EADA  leverages the free-energy bias and uses an energy-based criterion to evaluate the uncertainty and domainness of target samples. Despite the empirical success, these methods mainly focus on compensating for the domain gap by incorporating target-representativeness into the query function. However, the uncertainty criteria they used are still based on a point estimate from a deterministic model, which can be easily miscalibrated for out-of-distribution data . To remedy this issue, DUC  places a Dirichlet prior on the class probability and evaluates the predictive uncertainty with a probabilistic view. However, they only consider the uncertainty in model outputs. Besides, the true predictive distribution may not be captured by such a restricted distribution form.

**Diffusion-based generative models** have been widely appreciated for their impressive capabilities of generating high quality and diverse samples [17; 16; 39; 18]. While most works focus on high-dimensional generative tasks such as (conditional) image generation [39; 16], super-resolution [40; 41], image inpainting [42; 43], etc., some attempts have been made to apply diffusion models to categorical data  and discrete data , indicating their potential in classification tasks. Recently, Han et al.  utilize diffusion models to recover predictive distributions in regression and classification tasks, verifying their effectiveness for uncertainty estimation. Different from  that focuses on in-distribution scenarios, we consider a more challenging and realistic scenario of capturing predictive distribution in a cross-domain fashion. In addition, we also model the underlying variation of the data in low-dimensional latent space, which can be viewed as a data-level uncertainty and more favorable for downstream tasks compared to original image space .

## 3 Methodology

In ADA, we have a source domain \(=\{(_{i}^{s},y_{i}^{s})\}_{i=1}^{n_{s}}\) with \(n_{s}\) labeled samples, and a target domain \(=\{(_{i}^{t})\}_{i=1}^{n_{t}}\) with \(n_{t}\) unlabeled samples, where \(_{i}^{s}(_{i}^{t})\) is the input instance, and \(y_{i}^{s}\) is the corresponding label. It is assumed that both domains share a common label space \(\) but conform to different data distributions. Domain adaptation aims to train a model \(f_{}:\) parameterized by \(\) that achieves good predictive performance on the target domain. To achieve this goal, the problem of ADA involves selecting a small subset of informative samples \(_{l}\) for annotation with a budget \(\), where \( n_{t}\), such that the model performance on the target domain can be maximally improved. The selection process is typically completed in multiple rounds, where in each round, the model queries \(b\) samples from \(_{u}\) (the remaining unlabeled samples in \(\)) and adds them to \(_{l}\). This process is repeated until the budget is exhausted. In this work, we examine active learning for both UDA and source-free UDA , where, besides using unlabeled target data, we can utilize the raw source data and a source-trained model, respectively, for the purposes of selection and adaptation.

### Preliminary of Classification Diffusion Models for Uncertainty Estimation

In AL, a major concern in sample selection is predictive uncertainty. For a \(K\)-way classification problem, given an input variable \(\), the predictive uncertainty can be expressed as the posterior distribution over the predicted variable \(^{2}\) after observing the training set \(\), i.e., \(p(,)\). Most AL methods merely pay attention to accuracy and adopt a non-Bayesian approach to train the model, e.g., Maximum Likelihood Estimation (MLE) or Maximum A Posteriori (MAP). As frequentist techniques, they are not capable of inferring the variance of predictive distribution \(p()\), but merely provide a mean estimate \([]\) under the assumption of additive noise . Taking a Bayesian view, the predictive uncertainty can be modeled by assuming distributions over network parameters [48; 49], while it involves expensive computation and intractable posterior inference. Some alternative methods include modeling the output of a neural network as a probability distribution over possible outcomes [50; 5] or adding the noise term in the model outputs . As explicit modeling methods, they all assume a specific form in \(p()\) (e.g., Gaussian or Dirichlet distribution).

In this work, we leverage the deep generative models to model the implicit predictive distribution. Specifically, we start with the classification diffusion models . Re-denoted by \(_{0}^{K}\) the one-hot label, the diffusion model first applies a forward diffusion process \(q(_{1:T}_{0},)\) to original data by iteratively perturbing it to latent representations \(_{1:T}\) with Gaussian noises. For each step \(t\),

\[q(_{t}_{t-1},)=(_{t}; }_{t-1}+(1-})f_{}( ),_{t}),\] (1)

where \(_{t}(0,1)\) is the noise variance and fixed as hyperparameter. Here the model output \(f_{}()\) (mean estimate) is injected in the forward process to act as the prior knowledge about the relationship between \(\) and \(_{0}\), so that with a sufficiently large \(T\) and proper schedule \(\{_{t}\}_{t=1}^{T}\), we have

\[p(_{T})=(f_{}(), ).\] (2)

Note that the specific form of the forward diffusion process enables an efficient sampling for arbitrary steps in a closed form:

\[q(_{t}_{0},)=(_{t}; _{t}}_{0}+(1-_{t}})f_{ }(),(1-_{t})),\] (3)

with \(_{t}:=1-_{t}\) and \(_{t}:=_{s=0}^{t}_{s}\). An appreciable feature of diffusion models is that if we know the posterior distribution \(q(_{t-1}_{t},)\), we can sample \(y_{T}(f_{}(),)\) and run the reverse diffusion process to gradually recover the original data from \(p(_{0})\) under the guidance of \(f_{}(x)\). Unfortunately, \(q(_{t-1}_{t},)\) is actually intractable, and a feasible alternative is to use a model \(p_{}(_{t-1}_{t},)\) for approximation, which can be trained with the following ELBO:

\[ p_{}(_{0}) _{q(_{1:T}|_{0},)}[ {p_{}(_{0:T})}{q(_{1:T}_ {0},)}]:=_{ELBO}^{d}(,_{0}):=_{0}+_{t=2}^{T}_{t-1}+_{T},\] (4) \[_{0} :=_{q}[- p_{}(_{0} _{1},)],\] (5) \[_{t-1} :=_{q}[D_{}(q(_{t-1} _{t},_{0},)\|p_{}(_{t-1} _{t},))],\] (6) \[_{T} :=_{q}[D_{}(q(_{T} _{0},)\|p(_{T})) ],\] (7)

where \(D_{KL}\) is the Kullback-Leibler (KL) divergence. It is worth noting that scheduling small \(_{t}\) will make \(q(_{t-1}_{t},_{0},)\) still a Gaussian , which can be explicitly formulated using Bayes theorem. Therefore \(_{t-1}\) can be evaluated in a closed form. \(_{T}\) contains no optimizable parameter and is assumed to be sufficiently small and thus can be ignored. By adopting the appropriate form of \(p_{}(_{t-1}_{t},)\) and reparameterization like DDPM , the model can be trained effectively by being tasked at predicting the forward noise \(\) for sampling \(y_{t}\), with \(_{}(,_{t},f_{}(),t)\).

### Diffusion-Based Adversarial Probabilistic Model for ADA

The above conditional diffusion model admits the sampling of multiple predictions from \(p(,)\) for statistical analysis. However, it assumes that the evaluated sample \(\) and the training set \(\) comes from the same distribution, which is not the case in UDA. Aware of this, we aim to build a model that induces a common latent space \(\), where the source and target samples share the same representations. We first consider the following generative process defined with the joint probability distributions (We omit the subscript \(i\) to represent arbitrary data point in the dataset):

\[p(_{0:T}^{s},^{s},^{s}) =p(^{s})p(^{s}^{s})p (_{0:T}^{s}^{s},^{s}),\] (8) \[p(_{0:T}^{t},^{t},^{t}) =p(^{t})p(^{t}^{t}) p(_{0:T}^{t}^{t},^{t}),\] (9)

where \(^{s}(^{t})\) is the latent representation. To model the inference process of \(^{s}(^{t})\), we employ a shared encoder parameterized by \(\) for both the source and target domains, supposing a domain-shared embedding. And we use two separate decoders with parameters \(\) and \(\) for the source and target reconstructions, respectively, since the generative process requires domain-specific information encoded in the parameter. Due to intractable posterior distributions, we then aim to learn latent variables for both domains using variational inference, with the following variational objectives:

**Objective for Labeled Source Samples.** For a labeled source sample \((^{s},_{0}^{s})\), our goal is to learn both the low-dimensional embedding \(^{s}\) and latent class variable \(y_{1:T}^{s}\), which can be achieved by maximizing the ELBO of the marginal log-likelihood as follows:

\[ p(^{s},_{0}^{s}) = p(^{s},_{0:T}^{s},^{s})d {y}_{1:T}^{s}d^{s}\] \[_{q(_{1:T}^{s},^{s}|^{s},_{0 }^{s})}[_{0:T}^{s},^{s},^{s})}{q (_{1:T}^{s},^{s}^{s},_{0}^{s})}]\] \[=_{q_{}(^{s}|^{s},_{0}^{s})}[ p_{}(^{s}^{s})]-D_{KL}(q_{} (^{s}^{s},_{0}^{s})\|p(^{s}) )}_{}+\] (10) \[_{^{s} q_{}(^{s}|^{s},_{0}^{s})}_{q(_{1:T}^{s}|^{s},_{0}^{s})}[(_{0:T}^{s}^{s})}{q (_{1:T}^{s}_{0}^{s},^{s})}]}_{ _{ELBO}^{s}(^{s},_{0}^{s})}:=_{ELBO}^{s}.\]Eq. (10) implies a standard VAE and a classification diffusion model in the latent space. We provide the detailed derivation in Appendix A.1. To ensure discriminative classification boundaries in \(\), we additionally incorporate a deterministic classifier with parameter \(\) in the training objective. Then the overall objective for the labeled source data can be expressed as:

\[_{s}=-_{ELBO}^{s}+_{(^{t},_{0}^{t}) }_{q_{}(^{s}|^{s})}[- p_{}( _{0}^{s}^{s})].\] (11)

It is worth noting that the parameters of \(f_{}\) have been further decomposed into \(\{,\}\) in our case.

**Objective for Labeled Target Samples.** For target samples with annotation, we treat them the same as source-labeled data in training. The only difference is that we use parameter \(\) for target-specific reconstruction. Limited by space, we give the full expression of the training loss \(_{t}^{l}\) in Appendix A.2.

**Objective for Unlabeled Target Samples.** The training objective for unlabeled target samples can not be carried out in a supervised fashion due to the absence of ground-truth labels. Therefore, we design the following variational lower bound for them by treating \(_{0}^{t}\) and \(^{t}\) as latent variables:

\[ p(^{t})&=  p(^{t},_{0}^{t},^{t})d_{0}^{t}d^{ t}\\ &_{q(_{0}^{t},^{t}|^{t} )}[^{t},_{0}^{t},^{t})}{q (_{0}^{t},^{t}^{t})}]\\ &=_{q_{}(^{t}|^{t})}[ p _{}(^{t}^{t})]-D_{KL}(q_{}(^{t}^{ t})||p(^{t}))}_{}-\\ &_{^{t} q_{}(^{t}|^{t})}[D_{KL}(q(_{0}^{t}^{t})||p_{}(_{0}^{t} ^{t})]}_{_{KD}}:=_{ELBO}^{u}.\] (12)

Intuitively, it encourages to optimize a standard VAE and minimize the KL divergence between \(q(_{0}^{t}^{t})\) and the approximation \(p_{}(_{0}^{t}^{t})\). However, the ground-truth \(q(_{0}^{t}^{t})\) is agnostic in practice. In this work, we implement it in a Knowledge Distillation (KD) framework , where \(q(_{0}^{t}^{t})\) is substituted with the output of a teacher model \(f_{^{}}\) that is optimized by exponential moving average (EMA) from the weights of student model \(f_{^{}}\). We denote the KD loss as \(_{KD}\) and weight it by \(_{kd}\) to absorb the influence of wrong predictions from the teacher model. And only those with confident predictions (larger than a pre-defined threshold \(\)) from the teacher model will be involved in this term. Meanwhile, we hope that the predictions of target samples to be individually confident and holistically diverse, which results in the following loss function:

\[_{t}^{u}=-_{ELBO}^{u}+_{kl}( _{^{t}_{u}}_{q_{}(^{t}| ^{t})}|p_{}(_{0}^{t}^{t})]\|^{K}}{K})- _{^{t}_{u}}_{q_{}(^{t}| {x}^{t})}[D_{KL}(p_{}(_{0}^{t}^{t})||^{K}}{K })]}_{_{KL}}]},\] (13)

where \(_{kl}\) is the weighting coefficient. The derivation of Eq. (12) can be found in Appendix A.3.

**Adversarial Learning between Labeled and Unlabeled data.** The distribution shift between labeled and unlabeled data is a key obstacle to active learning. To extend the applicability of the diffusion model trained on labeled data to unlabeled ones, we apply a discriminator \(D_{}\) parameterized by \(\) and conduct adversarial learning between labeled and unlabeled data, expecting to learn an invariant latent space. Inspired by CDAN , we also leverage the model prediction as the conditioning for joint distribution alignment, which gives the following training loss for the discriminator:

\[_{adv}=-_{(_{l})} _{ q_{}(|)}[D_{}(p_{ }(_{0}),)]-_{ _{u}}_{ q_{}(|)}[1-D_{ }(p_{}(_{0}),)].\]

This minimax process is trained in an end-to-end mode using the gradient reversal layer .

### Two-Stage Training Procedure

The whole model in our framework includes an encoder \(\), two decoders \(,\), a discriminator \(\), a deterministic classifier \(\) and a diffusion-based classifier \(\). As shown in Section 3.1, the diffusion model requires the i.i.d. assumption to hold and injects the mean estimate \(f_{}()\) into both forward and reverse diffusion process. Therefore, we schedule a two-stage training procedure in each active round. Specifically, the first stage is called the **adaptation stage**, which yields the following objective:

\[_{}_{,,,}_{s}+_{t}^{u}+ _{t}^{l}-_{adv}.\] (14)The first stage ensures a well-behaved mean estimator \(f_{}\) and a domain-invariant latent embedding. We then freeze all the trained parameters and train the diffusion model \(_{}(,_{t},f_{}(),t)\) in the second stage, namely the **diffusion stage**, with all labeled data:

\[_{}_{s}+_{t}^{l}.\] (15)

Having the diffusion model, we select target samples according to the strategy in Section 3.4 if there is a remaining budget. We depict the whole framework for ADA in Fig. 1.

**Extension to Source-Free ADA (SFADA).** We naturally extend our method to SFADA  based on the fact that the model \(f_{}:=\{,\}\) in the adaptation stage can be initialized (like in ADA) or source pre-trained. For the latter, we pre-train the source model with \(_{s}\), and disable the source-related losses, i.e., \(_{s}\) and \(_{adv}\) in the adaptation stage. Besides, we use confident unlabeled target data pseudo-labeled by the teacher model to substitute the source samples in \(_{s}\) in the diffusion stage. The detailed procedure of the training process can be found in Appendix. B.

### T-test-Based Selection Strategy

Existing ADA methods generally select both target-representative and uncertain samples. The former characteristic can be naturally absorbed within the adaptation stage, which makes our model operate in a domain-agnostic latent space. Therefore, we mainly focus on selecting samples with high predictive uncertainties. For each \(^{t}_{u}\), we generate \(N\) predictions independently with the diffusion classifier, denoted by \(\{}_{n}^{t}\}_{n=1}^{N}\). Since the raw predictions can be arbitrary real vectors, we then convert them into the probability simplex by a softmax operation following , resulting in a set \(\{}_{n}^{t}\}_{n=1}^{N}\). Based on that, we identify the two most predicted classes among \(N\) votes for each instance, which gathers two groups of predicted scores \(g_{1}=\{}_{n}^{t}[a]\}_{n=1}^{N}\) and \(g_{2}=\{}_{n}^{t}[b]\}_{n=1}^{N}\), where \(a,b\) denote two most voted class labels. We assume independent generation in each dimension and evaluate the uncertainty by conducting an independent two-sample t-test, where the t-value is:

\[t=_{1}-_{2}}{S_{_{1}-_{2}}},S_{_{1}- _{2}}=^{2}+s_{2}^{2}}{N}},\] (16)

here we use \(_{1}(\ _{2})\) and \(s_{1}^{2}(\ s_{2}^{2})\) to denote the mean and variance of the two groups, respectively. Conceptually, the t-value is formulated as the ratio of _mean difference between groups_ to _sampling variability_. Compared to Best-versus-Second-Best (BvSB)  used in deterministic model-based AL methods, the t-test-based criterion can not only allow us to see if two means are different, but also tell us how significant the differences are. As a result, we use the p-value to express the significance of such a difference. Intuitively, uncertain samples are those with small mean differences between groups and high sampling variabilities, which leads to small t-values and high p-values. In practice, we choose unlabeled target samples with top-\(b\) p-values for annotation in each active selection round.

## 4 Experiments

### Experimental Setup

**Datasets and Baselines.** We evaluate our method on three widely used domain adaptation benchmarks, i.e., Office-31 , Office-Home  and VisDA . We construct three groups of baselines

Figure 1: Framework of DAPM. Each active learning round goes through three stages: two stages for training and one stage for selection. Parameters in blue and green backgrounds are trained in the adaptation stage and the diffusion stage, respectively. When the adaptation stage ends, the parameters involved will be frozen. The teacher model \(f_{}^{}}\) is updated by EMA from the student model \(f_{}\).

for comparison. (i) Active learning: Random, Entropy , BvSB , CoreSet , BADGE . (ii) Active Domain Adaptation: AADA , TQS , CLUE , EADA , DUC . (iii) Source-Free ADA: ELPT , and our SFDA baseline with other AL selection methods: Random (DAPM-RD), BvSB (DAPM-BS), Entropy (DAPM-ET), CoreSet (DAPM-CS), BADGE (DAPM-BG). We denote our method with the t-test-based selection criterion by DAPM-TT thereafter. It is worth noting that in the SFADA setting, we retain the abbreviation as DAPM for consistency, however we do not employ the adversarial learning loss.

**Implementation.** We implement our method on Pytorch and MindSporo3. The ResNet-50  pre-trained on ImageNet  is adopted as the backbone, which constitutes the main body of the encoder. The decoder is simply a two-layer MLP. Following previous works [5; 20], we schedule 5 selection rounds, where in each round, the model selects \(b=1\% n_{t}\) samples for annotation, and therefore the total budget \(B=5\% n_{t}\). We use SGD optimizer in the adaptation stage. The learning rate is set as 0.01 except for the VisDA dataset in SFADA, where we use 0.001 for training. The batch size is 32 for ADA and 64 for SFADA. We adopt the same learning rate scheduler as [22; 1]. For hyperparameters, we use \(_{kl}=0.1\), \(_{kd}=0.1\) for ADA and \(_{kl}=1.0\), \(_{kd}=1.0\) for SFADA. For all tasks, the confidence threshold \(\) for knowledge distillation is set to 0.9. We set \(N=100\), i.e., we generate 100 predictions for each individual sample for uncertainty estimation. More implementation details are provided in Appendix. C. Code is available at https://github.com/TL-UESTC/DAPM.

**Evaluation Protocol.** There are two classifiers involved in our method, i.e., a deterministic classifier parameterized by \(\) and a diffusion classifier parameterized by \(\). For evaluating a target sample \(^{t}\) encoded by \(^{t}\), we leverage the predictions generated from the diffusion classifier by calculating the expected class probability based on \(N\) independent votes, i.e., \(_{}(^{t}^{t})=_{n=1}^{N}}_{n}^{t}\). We show in Sec. 4.3 that \(_{}(^{t}^{t})\) provides a more calibrated prediction than the output of the deterministic classifier \(p_{}(^{t}^{t})\). On the other hand, we use the majority vote as the final predicted class.

### Main Results

**Active Domain Adaptation.** We present our results on Office-31 and VisDA in Table 1. Notably, among traditional active selection strategies, those based on uncertainty (e.g., BvSB, Entropy, BADGE) tend to achieve higher performance compared to those based purely on representativeness (e.g., CoreSet). This is because a portion of the target domain is already well-aligned with the source domain, and selecting these easy samples would not provide informative feedback to the model. This highlights the importance of incorporating predictive uncertainty in the selection criterion. However, the accuracies of all traditional AL methods are significantly lower than those of ADA methods due

   &  &  &  \\   & & Synthetic \(\) Real & A \(\) D & A \(\) W & D \(\) A & D \(\) W & W \(\) A & W \(\) D & Avg \\  Source-Only & ResNet  & 4.7 \(\) 0.1 & 81.5 & 75.0 & 63.1 & 95.2 & 65.7 & 99.4 & 80.0 \\   & Random & 78.6 \(\) 0.6 & 87.1 & 84.1 & 75.5 & 98.1 & 75.8 & 99.6 & 86.7 \\  & BVSB  & 81.3 \(\) 0.4 & 89.8 & 87.9 & 78.2 & 99.0 & 78.6 & **100.0** & 88.9 \\  & Entropy  & 82.7 \(\) 0.3 & 91.0 & 89.2 & 76.1 & 99.7 & 77.7 & **100.0** & 88.9 \\  & Correct  & 81.9 \(\) 0.3 & 82.5 & 81.1 & 70.3 & 96.5 & 72.4 & 99.6 & 83.7 \\  & BADGE  & 84.3 \(\) 0.3 & 90.8 & 89.1 & 79.8 & 99.6 & 79.6 & **100.0** & 89.8 \\   & AADA  & 80.8 \(\) 0.4 & 89.2 & 87.3 & 78.2 & 99.5 & 78.7 & **100.0** & 88.8 \\  & TQS  & 83.1 \(\) 0.4 & 92.8 & 92.2 & 80.6 & **100.0** & 80.4 & **100.0** & 91.1 \\  & CLUE  & 85.2 \(\) 0.4 & 92.0 & 87.3 & 79.0 & 99.2 & 79.6 & 99.8 & 89.5 \\  & EADA  & 88.3 \(\) 0.1 & 97.7 & 96.6 & 82.1 & 100.0 & 82.8 & **100.0** & 93.2 \\  & DUC  & 88.9 \(\) 0.2 & 95.8 & 96.4 & 81.9 & 99.6 & 81.4 & **100.0** & 92.5 \\  & DAPM (Baseline) & 80.8 \(\) 0.7 & 94.3 & 93.5 & 72.1 & 97.6 & 72.3 & 99.3 & 88.2 \\   & DAPM-TT & **80.1** & 96.8 & 98.6 & 82.3 & 99.8 & **83.3** & **100.0** & **93.5** \\   & + ELPT  & 83.5 \(\) 0.6 & **98.0** & 97.2 & 81.2 & 99.4 & 80.7 & **100.0** & 92.8 \\  & DAPM (Baseline) & 73.4 \(\) 0.2 & 93.7 & 92.9 & 72.2 & 98.1 & 72.6 & 99.1 & 88.1 \\   & Random & 86.2 \(\) 0.8 & 94.4 & 95.1 & 78.2 & 98.1 & 79.2 & 99.6 & 90.8 \\   & \(\) WvSB  & 86.1 \(\) 0.2 & 96.7 & 96.5 & 81.1 & 99.0 & 81.5 & **100.0** & 92.5 \\   & Entropy  & 87.5 \(\) 0.3 & 96.3 & 95.6 & 80.3 & 98.8 & 80.5 & **100.0** & 91.9 \\   & \(\) Corget  & 87.3 \(\) 0.1 & 94.7 & 96.5 & 80.0 & 97.9 & 79.9 & **100.0** & 91.5 \\   & BADGE  & 87.9 \(\) 0.3 & 96.5 & 97.1 & 79.3 & 98.5 & 80.1 & 99.8 & 91.9 \\   & **DAPM-TT** & 88.4 \(\) 0.3 & 96.8 & 96.4 & **83.5** & 99.7 & 81.7 & **100.0** & 93.0 \\  

* For DUC and ELPT, we report the results on Office-31 and VisDA based on our own runs, respectively, according to the official code.
* For SFADA, we implement several active learning methods upon or SFDA baseline and report the mean results over 3 runs.

Table 1: Accuracy (%) on VisDA and Office-31 datasets under different settings with 5% labeled target samples (ResNet-50).

to the neglect of domain shift. Among ADA methods, our DAPM-TT outperforms other methods and achieves the best accuracies on both Office-31 and VisDA, surpassing the deterministic model EADA  by 0.8% and 0.3% on the two datasets, respectively. Compared to the recent method DUC , our method still achieves better performance, boosting the accuracy by 1.0% on Office-31 and achieving a slightly better performance on VisDA, showing the superiority of our probabilistic framework. The results in Table 2 demonstrate that our method outperforms all deterministic ADA methods on the Office-Home dataset. Although it does not achieve the best accuracy in this case, it remains highly competitive with DUC. Moreover, it is worth noting that our probabilistic modeling is mainly designed to capture predictive uncertainty, rather than to optimize classification accuracy that is largely depended on domain adaptation methods. We will show in Sec. 4.3 that our method induces more calibrated predictions than DUC.

**Source-Free Active Domain Adaptation.** For SFADA, we mainly compare our DAPM-TT with other AL strategies using our SFDA baseline, where we conduct the adaptation stage and adopt some representative AL strategies based on the deterministic classifier. The results in Table 1 and Table 2 show that DAPM-TT consistently achieves the best performance on all datasets. In particular, we find that BvSB , which can be considered as the deterministic counterpart of DAPM-TT, achieves relatively good results on all datasets. However, our DAPM-TT outperforms BvSB by considering the full distribution of the predicted variable, providing a better measure of uncertainty. Compared to the recent SFADA method ELPT , our DAPM-TT is able to surpass it on all datasets, especially the VisDA dataset, where we achieve a 4.9% improvement in mean accuracy.

### Analytical Experiments

**Expected Calibration Error (ECE).** To evaluate the calibration ability of our model, we plot the ECE curves for two tasks on Office-Home in Fig. 1(a). The results demonstrate that, in both tasks, the output of our deterministic classifier is much more uncalibrated compared to that of the diffusion classifier, even though their accuracies remain very close (as shown in the Ablation Study). This confirms the well-known phenomenon that softmax classifiers based on point estimates tend to make overconfident predictions , which can be unsafe when dealing with uncertain estimation. Our DAPM aims to recover the full predictive distribution by modeling the uncertainty in both data

   Category & Method & A\(\)Cl & As\(\)M\(\)M & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl & As\(\)Cl \\  Source-Only & ResNet & 42.1 & 66.3 & 73.3 & 50.7 & 59.0 & 68.6 & 51.9 & 37.9 & 71.2 & 65.2 & 42.6 & 76.6 & 58.3 \\   & ResNet & 52.5 & 74.3 & 77.4 & 56.3 & 69.7 & 68.9 & 57.7 & 50.9 & 57.8 & 59.0 & 54.6 & 81.3 & 68.3 \\  & BvSB  & 56.3 & 78.6 & 79.3 & 58.1 & 74.0 & 70.5 & 59.5 & 52.6 & 77.2 & 71.2 & 56.4 & 45.3 & 68.2 \\  & EAPM  & 58.0 & 78.4 & 79.1 & 60.5 & 73.9 & 72.6 & 60.8 & 54.2 & 77.9 & 73.3 & 58.0 & 83.6 & 69.9 \\  & EAPM  & 51.2 & 76.0 & 75.9 & 61.5 & 70.8 & 72.6 & 60.8 & 54.6 & 75.3 & 70.8 & 59.0 & 68.3 & 68.3 \\  & ADUC  & 59.2 & 78.7 & 79.9 & 61.5 & 74.6 & 72.5 & 61.5 & 56.0 & 73.8 & 71.4 & 60.9 & 84.2 & 69.9 \\   & AADA  & 56.6 & 78.1 & 79.0 & 58.5 & 73.7 & 71.0 & 60.1 & 53.1 & 77.0 & 79.6 & 57.0 & 84.5 & 68.3 \\  & POS  & 88.6 & 81.1 & 81.5 & 61.1 & 76.1 & 73.3 & 61.2 & 54.7 & 79.7 & 73.4 & 59.6 & 86.1 & 73.5 \\  & CLEB  & 58.0 & 79.3 & 80.9 & 68.8 & 77.5 & 76.5 & 65.7 & 57.9 & 81.4 & 75.6 & 60.8 & 86.3 & 72.3 \\  & EARM  & 63.6 & 84.4 & 83.5 & 70.7 & 83.7 & 80.3 & 58.3 & 58.2 & 78.4 & 64.4 & 86.6 & 70.3 \\  & DUC  & **65.5** & 84.9 & 84.3 & **73.0** & 83.4 & 81.1 & **73.9** & **64.6** & 85.4 & **84.1** & **80.2** & 88.8 & **78.6** \\  & DAPM  & 51.9 & 73.1 & **78.4** & 59.6 & 78.3 & 74.9 & 61.2 & 53.8 & 80.2 & 80.2 & 85.3 & 81.3 & 68.2 \\   & DAMP-TT & 64.2 & 84.4 & **85.4** & 69.7 & 69.2 & 84.2 & 85.5 & 69.1 & 63.4 & **86.0** & 72.4 & **86.0** & 77.21 \\  & DAPM  & 65.3 & 84.1 & 84.9 & 72.9 & 84.4 & 82.8 & 69.3 & 63.1 & 86.2 & 66.6 & **89.1** & 77.0 \\  & DAPM  & 50.5 & 76.1 & 80.6 & 66.5 & 74.9 & 77.8 & 63.8 & 49.9 & 80.1 & 72.4 & 53.9 & 83.5 & 69.2 \\  & EAPM  & 59.5 & 82.4 & 82.3 & 68.8 & 81.0 & 60.4 & 60.6 & 60.5 & 82.2 & 76.2 & 64.2 & 85.6 & 74.3 \\  & EAPM  & 59.2 & 83.5 & 53.4 & 72.1 & 84.5 & 53.0 & 70.3 & 50.4 & 85.5 & 75.3 & 63.7 & 87.4 & 70.1 \\  & EAPM  & 59.2 & 82.1 & 84.2 & 66.2 & 82.0 & 82.2 & 66.2 & 85.7 & 84.1 & 75.7 & 63.3 & 81.6 & 74.3 \\  & C Candid3  & 61.2 & 81.3 & 85.0 & 70.7 & 82.5 & 82.6 & 68.9 & 60.3 & 83.5 & 76.3 & 63.8 & 69.7 & 75.4 \\  & BvSB  & 60.2 & 83.9 & 84.9 & 71.8 & 83.7 & 81.6 & 69.1 & 95.8 & 85.1 & 75.9 & 62.8 & 88.1 & 75.6 \\  & DAPM-TT & 64.4 & **85.3** & 55.4 & 72.4 & **84.7** & **84.4** & -20.0 & 63.5 & 85.6 & 77.4 & 68.8 & **84.1** & 77.3 \\   

Table 2: Accuracy (%) on Office-Home dataset under different settings with 5% labeled target samples (ResNet-50). **Markes have the same meaning as in Table 1.**

Figure 2: (a) Visualization of Expected Calibration Error (ECE) for ADA on task Ar \(\) Cl and Cl \(\) Ar. (b) Performance under different choices of \(N\) on Office-Home for ADA and SFADA.

generation and model prediction, thereby effectively mitigating this issue. Compared to DUC , which only models the distribution in output space, our method achieves smaller ECE values in both tasks, demonstrating the benefits of our probabilistic framework.

**Effect of Different Sampling Scales.** We evaluate our model under varying sampling numbers \(N\) and report the performance on Office-Home in Fig. 1(b). Our results demonstrate that the model performance initially improves as \(N\) increases. This is because when \(N\) is too small, the model suffers from sampling bias, which results in a performance degradation to a level similar to that of the point estimate. However, an excessively large number of samples can lead to increased storage and computing resources. We find that when \(N\) is around 100, the performance becomes stable.

**Effect of Different Annotation Budgets.** Fig. 2(a) shows how different budgets affect the model performance. For both ADA and SFADA, our method is able to select the most informative samples at the begining, resulting in superior performance even with a small budget. As the budget increases, the advantage of our method is slightly diluted. However, it is still able to maintain a leading accuracy.

**Evaluation of Active Learning.** We also provide the baseline domain adaptation performance (i.e., DAPM without active learning) in Table 1 and 2. It shows that without active selection and learning, our DAPM only achieves a moderate performance compared to modern methods that are specifically designed for UDA, given that the probabilistic backbone is mainly used for uncertainty modeling rather than accuracy. However, we are encouraged to observe that incorporating AL with our designed selection criterion significantly enhances the domain adaptation performance on all datasets. This outcome demonstrates the effectiveness of our diffusion-based uncertainty estimation, as it identifies informative samples that considerably improve overall performance.

**Performance under Different Selection Strategies.** To explore the superiority of our t-test-based selection strategy, we test our DAPM using other selection strategies for the ADA task. The results are presented in Table 3. In addition to strategies based on the deterministic classifier, we also evaluate three strategies based on the diffusion classifier: DAPM-VT, DAPM-IW and DAPM-AE. DAPM-VT, DAPM-IW select samples with the top-\(B\) highest prediction variance and interval width on the majority voted class, respectively. DAPM-AE averages the entropy across the \(N\) predictions to get the final nonparametric entropy estimate for each data point, and select the ones with highest averaged entropies for annotation. As expected, DAPM achieved the best results. Our findings suggest that the t-test-based criterion is more suitable for the diffusion classifier since it takes into account both sampling variability and cross-category ambiguity.

**T-SNE Visualization of Latent Representations.** We visualize the latent representations of unlabeled target data and selected target data in Fig. 4 using t-SNE . In this visualization experiment, we compared our DAPM-TT with BvSB  that is based on the deterministic classifier. It can be observed that BvSB tends to select samples from relatively ambiguous regions (the center region) since these samples often have ambiguity between different classes. However, many samples selected by BvSB are in areas where the model is able to make predictions accurately. Therefore, it will not help to correct the samples with wrong predictions, resulting in modest improvement on performance.

    &  &  \\   & DAPM-RD & DAPM-BS & DAPM-ET & DAPM-CS & DAPM-BG & DAPM-VT & DAPM-IW & DAPM-AE & DAPM-TT \\  Accuracy (\%) & 92.0 & 92.2 & 92.1 & 91.8 & 92.5 & 93.1 & 92.9 & 92.7 & **93.5** \\   

Table 3: Comparasion between different selection strategies for ADA (5% budget on Office-31).

Figure 3: (a) Accuracy curves as budget goes from 0% to 20%. (b) Model performance varying with parameters \(_{kl},_{kd}\{0.01,0.1,0.2,0.5,1.0\}\) on task D \(\) A (Office-31).

Our DAMP-TT, on the other hand, can select samples from both the regions where there is ambiguity between classes and the regions where a large number of samples are misclassified, which are exaclty the ones we want to select for annotation.

How Does T-test-based Selection Ensure Diversity?While our method mainly focuses on uncertainty estimation, we show that it has properties that help mitigate redundant selections. Firstly, the diffusion process introduces stochasticity by generating varied predictions for the same input. This creates more diversity in the uncertainty estimates across similar instances. In other words, duplicate inputs will not necessarily have identical uncertainty. Secondly, the t-test criterion accounts for both variability across predictions and similarity of top-2 classes. Highly variable samples with closer competing classes will be favored, which is naturally distributed around the classification boundary of every class, thus enabling diversity. In Fig. 4, we observe that our approach naturally selects a diverse range of sample classes, even though we did not explicitly impose a diversity constraint.

Ablation Study.We conduct extensive experiments to investigate the influence of different classifiers and losses in our method. The results are summarized in Table 4, and we observed the following: Firstly, in most cases, the diffusion classifier yields slightly better results than the deterministic one, indicating its superior tolerance for domain shift. Secondly, our approach still achieves much better results than other traditional AL methods without any loss function for domain adaptation, demonstrating the superiority of our selection method. Lastly, all the loss functions have a positive effect on the final result.

Hyperparameter Sensitivity.As shown in Fig. 2(b), our model exhibits low sensitivity to both \(_{kl}\) and \(_{kd}\) in ADA, We conjecture the reason is that the source-available scenario involves more loss terms in the training objective, the additional source domain data and distribution alignment objectives like \(_{adv}\) may make the optimization landscape more complex and susceptible to suboptimal solutions based on weighting hyperparameters. In contrast, in SFADA, the model solely relies on the target data and regularization losses like \(_{KL}\) for alignment, reducing dependence on precise weighting. As SFADA lacks source-supervised information, we recommend using a slightly larger \(_{kl}\) to ensure good adaptation performance.

## 5 Conclusion

In this work, we propose a novel probabilistic framework for ADA that leverages the variability of both latent data representation and model prediction for better uncertainty estimation. Our approach combines a variational autoencoder, a diffusion probabilistic classifier, and an auxiliary deterministic classifier to guide training and ensure an invariant latent space. Our experiments on three domain adaptation benchmarks demonstrate the effectiveness of our approach in improving task performance and effectively handling uncertainty estimation for both ADA and SFADA.

   Classifier &  &  & VisDA-2017 \\   Dif. Det. & \(_{KD}\) & \(_{KL}\) & \(_{adv}\) & ADA SFADA & ADA SFADA & ADA \\   ✓ & & & & 91.4 & 90.8 & 86.3 & 86.7 \\ ✓ & & & & 91.1 & 91.0 & 86.5 & 86.5 \\  ✓ & & ✓ & & 92.2 & 91.9 & 87.1 & 87.6 \\ ✓ & & ✓ & ✓ & 92.9 & - & 87.7 & - \\ ✓ & & ✓ & ✓ & 93.0 & 93.0 & 88.5 & 88.4 \\ ✓ & ✓ & ✓ & & 93.0 & 93.1 & 88.3 & 88.2 \\  ✓ & & ✓ & ✓ & ✓ & **93.5** & - & **89.1** & - \\ ✓ & ✓ & ✓ & ✓ & 93.4 & - & 88.9 & - \\   

Table 4: Ablation study of DAMP-TT on Office-31 and VisDA. Dif. and Det. are short for diffusion classifier and deterministic classifier, respectively.

Figure 4: Visualization of latent representations using t-SNE  on task Ar\(\)Cl (a to b) and Rw\(\)Pr (c to d) of ADA. Darkblue points are unlabeled target samples correctly classified by our model. Lightblue points represent unlabeled target samples misclassified by our model. Red stars are the selected target samples.