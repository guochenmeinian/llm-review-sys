# AutoGuide: Automated Generation and

Selection of Context-Aware Guidelines for

Large Language Model Agents

 Yao Fu Dong-Ki Kim Jaekyeom Kim Sungryull Sohn

Lajanugen Logeswaran Kyunghoon Bae Honglak Lee

\({}^{1}\)University of Michigan LG AI Research

Equal contribution.

###### Abstract

Recent advances in large language models (LLMs) have empowered AI agents capable of performing various sequential decision-making tasks. However, effectively guiding LLMs to perform well in unfamiliar domains like web navigation, where they lack sufficient knowledge, has proven to be difficult with the demonstration-based in-context learning paradigm. In this paper, we introduce a novel framework, called AutoGuide, which addresses this limitation by automatically generating context-aware guidelines from offline experiences. Importantly, each context-aware guideline is expressed in concise natural language and follows a conditional structure, clearly describing the context where it is applicable. As a result, our guidelines facilitate the provision of relevant knowledge for the agent's current decision-making process, overcoming the limitations of the conventional demonstration-based learning paradigm. Our evaluation demonstrates that AutoGuide significantly outperforms competitive baselines in complex benchmark domains, including real-world web navigation.

## 1 Introduction

Recent advances in large language models (LLMs) have empowered AI agents to address various sequential decision-making tasks and applications . The foundation of these successes involves the planning and reasoning capabilities of pre-trained LLMs, enabling agents to execute effective policies . The predominant approach to leveraging these (typically closed source) models for sequential decision making tasks is to provide demonstrations in the form of in-context examples. However, direct application of this learning paradigm can be limited, especially in target domains where the LLM has insufficient prior knowledge such as in web navigation, where LLM agents generally achieve low success rates due to diverse and dynamic contents . Providing all available experiences as demonstrations to an agent can further be unsuccessful due to context length limitations, prompt sensitivity, and difficulty with complex reasoning .

On the other hand, LLMs excel in interpreting concise instructions provided as natural language, an ability that is also reinforced in the instruction-tuning phase of LLMs. Inpired by this, we explore data-driven strategies that leverage offline experiences to extract actionable knowledge to help guide LLM agents. As offline experiences implicitly convey valuable knowledge about desirable and undesirable policies in domains, they promise to serve as a useful resource for improving an LLM agent's decision-making in situations where the pre-trained LLM lacks understanding. Despite this potential benefit, a critical challenge lies in effectively extracting the implicit information embedded in offline data.

To address the challenge of extracting knowledge from offline data, we propose a novel framework, called AutoGuide. Specifically, AutoGuide automatically derives a comprehensive set of context-aware guidelines from offline experiences. Our method applies these context-conditional guidelines to enhance the performance of an LLM agent by retrieving guidelines relevant to the agent's current state and incorporating them into the prompt during testing (see Figure 1). Notably, we generate context-aware guidelines in concise natural language statements, effectively compressing knowledge in offline data. Moreover, context-aware guidelines clearly describe the contexts where they are applicable, so AutoGuide enables an LLM agent to select pertinent guidelines for its current decision-making process. As a result, AutoGuide achieves the highest success rates compared to competitive baselines in complex sequential decision-making benchmark environments.

**Our contribution.** In summary, we present the following main contributions in this paper:

* **Principled method based on context-aware guidelines (Section 3):** We develop two modules to automatically generate context-aware guidelines from offline experiences: the context identification module for identifying the context of a given trajectory, and the guideline extraction module for extracting a desired guideline corresponding to that context. The outcome is a set of domain knowledge in concise natural language that enhances decision-making by providing pertinent information.
* **Comprehensive evaluation of AutoGuide (Section 4.2):** We show AutoGuide's capability in extracting helpful context-aware guidelines in various interactive benchmark domains, including navigating real-world web domains (e.g., GitHub). Our results highlight the effectiveness of AutoGuide, which significantly outperforms baselines without context-aware guidelines.
* **Analyses with important perspectives (Section 4.3):** We study various aspects of AutoGuide, such as the significance of determining the applicability of each guideline based on generated contexts. We also investigate the generalization ability of context-aware guidelines and demonstrate that our guidelines enhance the performance across out-of-domain tasks.

## 2 Related Work

**LLM-based agents.** Language models have recently been shown to possess strong priors for sequential decision-making tasks, which has given rise to LLM-powered agents . Agents

Figure 1: AutoGuide aims to extract the implicit knowledge embedded in offline experiences and help the decision-making process of an LLM agent. Specifically, our method generates a comprehensive set of context-aware guidelines from offline data and explicitly identifies when each guideline is applicable by generating its corresponding context. Our context-aware guidelines enable providing pertinent guidelines at test time by identifying the context of the current trajectory, leading to correct decision-making compared to baselines without context-aware guidelines.

need to possess various skills to be effective in practice including planning [3; 15; 16], reasoning [4; 17], tool manipulation [18; 19; 20; 21], code generation [22; 16], among others. In this work, we focus on building effective agents for web [23; 8] and embodied  environments.

**Self-reflection from past experiences.** An important capability for agents to succeed is the ability to learn from past experiences and update their behavior based on feedback. Self-feedback [25; 26; 27] has emerged as an effective technique where a model inspects its own incorrect predictions, reflects on it to identify what went wrong and attempts to improve its prediction. While self-feedback provides intra-task (i.e., per-episode) knowledge within a task based on immediate feedback, our approach offers an orthogonal and complementary aspect of inter-task knowledge (over multiple tasks) by considering multiple train tasks in offline data. AutoGuide enhances learning efficiency and credit assignment by utilizing detailed feedback from multiple tasks. However, these self-feedback approaches are complementary to AutoGuide and can be used in conjunction with our approach, as shown in our experiments (see Section 4.2).

**Leveraging natural language guidance.** Natural Language can be a rich source of information for agents to learn to act efficiently. Prior work has explored the notion of learning from human-written text manuals, which describe details about the environment [28; 29; 30]. Recent work has explored automatically generating such guidance in the form of chain-of-thought reasoning [4; 23], which emulates a thought process or rationale for agent's predictions. In contrast to approaches which generate such guidance dynamically on the fly by imitating example guidance demonstrations provided by a human, our approach carefully compares trajectories in offline data to generate appropriate guidance and uses these guidelines for predicting better actions. ExpeL  proposed a related approach to derive guidelines. In contrast to ExpeL, where all guidelines are provided to an agent as a prompt, our guideline selection process is contextual, where guidelines relevant to the agent's current state are retrieved and used for prediction. We show that this substantially improves over ExpeL's non-contextual guideline-based approach.

## 3 AutoGuide: Principled Method Based on Context-Aware Guidelines

Our work is motivated by the increasing availability of offline experiences that agents or humans naturally accumulate through their interactions with the environment. AutoGuide aims to leverage this offline data to improve the decision-making of an LLM agent by generating helpful context-aware guidelines. This section details how AutoGuide automatically constructs these guidelines and applies them to guide action generation at test time.

### Problem Statement

Formally, AutoGuide is given offline data \(_{}\!=\!(^{1},...,^{N})\) that consist of \(N\) trajectories from training tasks. Each trajectory \(\!=\!(x_{0},a_{0},r_{0},...,r_{T})\) is a sequence of observations, actions, and rewards following the partially observable Markov decision process . The return of a trajectory is defined as the sum of rewards obtained throughout the trajectory: \(R()\!=\!_{t=0}^{T}r_{t}\). The objective of AutoGuide is to distill knowledge from offline experiences into a useful natural language format, such that the extracted information helps to maximize the expected return \(_{}[R()]\) during test time.

Figure 2: Context-aware guideline generation process based on a pair of contrastive trajectories \(_{+}^{i}\) and \(_{-}^{i}\). In this example, the two trajectories start deviating from each other at \(t\!=\!0\). The context identification module generates a description of the context at \(t\!=\!0\) given \(_{:0}^{i}\), and the guideline extraction module generates the corresponding guideline for that context.

``` Input:Offline data \(_{}\), context identification module \(_{}\), guideline extraction module \(_{}\) Initialize context-aware guideline dictionary \(\) for Each pair \(_{+}^{i},_{-}^{i}_{}\)do # Identify the context from a trajectory  Find the deviating timestep \(t\) from \(_{+}^{i}\) and \(_{-}^{i}\) \(_{}(_{+}^{i})\) # Check if the current context matches any existing contexts if\(\)then \([]=\{\}\) endif # Generate the context-aware guideline guideline \(_{}(_{+}^ {i},_{-}^{i},)\) \([][] \{\}\) endfor Return Context-aware guideline dictionary \(\) ```

**Algorithm 1** Extracting context-aware guidelines from offline data

### Extraction of Context-Aware Guidelines

AutoGuide generates a set of context-aware guidelines by utilizing pairs of contrastive trajectories from offline data. Each context-aware guideline is expressed in concise natural language and follows a conditional structure, clearly describing the context in which the guideline is applicable. Intuitively, contrasting a pair of trajectories with different returns provides important information about when and which actions are effective or ineffective in maximizing expected returns. Building on this insight, we develop two modules for automatically extracting context-aware guidelines (see Figure 2):

**Context identification module.** This module is responsible for abstracting the given partial trajectory into its _context_, a concise natural language description of the agent's state. More specifically, for a timestep \(t\) and the corresponding trajectory \(_{:t}^{i}(x_{0},a_{0},...,x_{t})\), we prompt LLMs to clearly describe the agent's status:

\[_{}(_{:t}^{i}),\] (1)

Our prompt templates for the context identification module are shown in Appendix C.1.

**Guideline extraction module.** This module aims to generate a desired guideline corresponding to a specific context. Let \(_{+}^{i}\) and \(_{-}^{i}\) represent a contrasting pair of trajectories for the same task \(i\) in offline data \(_{}\), where \(R(_{+}^{i})>R(_{-}^{i})\). We want to contrast the pair of trajectories to find desired behaviors at an important timestep. To do this, we compare these two trajectories to find the deviation timestep \(t\) at which they begin to diverge due to different actions. Then we apply the context identification module to summarize the context for the shared part of the trajectory \(_{:t}^{i}\). Eventually, we extract a useful natural language guideline by examining the paired contrastive trajectories \(_{+}^{i}\) and \(_{-}^{i}\) with respect to the context:

\[_{}(_{+}^{i},_{-}^{i},),\] (2)

where we refer to Appendix C.2 for our prompt template. As an example, the paired trajectories in Figure 2 deviate from timestep \(t=0\), for which the context is summarized as _On the Reddit main page_. This module then generates the following context-aware guideline: _When on the Reddit main page, if you want to navigate to a specific forum, you should click on "link 'Forums'" located right above "link 'Wiki'"_.

**Construction of context-aware guidelines.** We collect context-aware guidelines \(\) by iterating through available pairs in the paired offline data and organize the guidelines in a dictionary format, using the context as the key and the corresponding guidelines as the value (see Algorithm 1). In particular, we observe that the context identification module occasionally produces contexts that describe the same situation but are expressed slightly differently. To minimize redundancy, we employ an LLM to determine if the current context corresponds to any previously identified context.

If a match is found, we reuse the existing context; otherwise, we introduce a new context into our dictionary \(\). The specific prompt template for this context-matching procedure is in Appendix C.3.

### Applying Context-Aware Guidelines at Test Time

After extracting a set of context-aware guidelines \(\) from offline experiences, our method employs these guidelines to enhance the decision-making of an LLM agent during testing. At each timestep, AutoGuide identifies the context of the current test trajectory \(\) up to timestep \(t\) (which represents the agent's interactions up to the current time-step) using our context identification module \(_{}\). Our guideline selection module \(_{}\) then selects relevant guidelines for context from \(\). More specifically, the module applies context as the key to fetch a set of possible guidelines \([]\). If there are more than \(k\) guidelines in \([]\), \(_{}\) prompts an LLM to choose top-\(k\) guidelines for the specific \(\):

\[_{}( ,;,k),\] (3)

where Appendix C.4 details the prompt template for this selection procedure. Subsequently, AutoGuide incorporates both the context and relevant guidelines into the agent's action generation prompt. Therefore, the agent selects an action by considering the provided context and guidelines (see Figure 1 for an example). This process iterates until the end of the test trajectory (see Algorithm 2).

**Key benefits of AutoGuide**. First, the extraction of context-aware guidelines in AutoGuide offers the inherent benefit of providing relevant guidelines for the context of interest. This capability is important since neglecting the specific context in which a guideline applies can confuse the agent's decision-making process. The second key benefit is the generation of concise natural language guidelines, which can be seamlessly incorporated into any prompt-based LLM agent. Lastly, AutoGuide generates guidelines at the individual context level rather than at the trajectory level. Given that a single incorrect action can lead to a complete failure, it is essential to provide detailed assistance in each action selection process. With these advantages, we demonstrate in the next section that our approach significantly enhances the performance of LLM agents.

## 4 Evaluation

This section demonstrates the efficacy of AutoGuide by conducting experiments on a diverse suite of sequential decision-making benchmark domains. We also perform important analyses about AutoGuide, such as the ablation study of different AutoGuide components, comparison to

Figure 3: Sequential decision-making benchmark domains considered in our work: ALFWorld , WebShop , WebArena , and multi-modal real-world websites. Graphic credit: [34; 33; 8; 35].

in-context learning, and generalization to out-of-domain tasks. We refer to Appendix B for additional experimental details.

### Evaluation Setup

#### 4.1.1 Sequential Decision-Making Benchmark Domains

We consider the following interactive sequential decision-making benchmarks to study various aspects of AutoGuide (see Figure 3):

\(\)**ALFWorld :** In this embodied benchmark, an LLM agent interacts with an environment to carry out household tasks, such as placing a pan on the dining table. Observations and actions are expressed in natural language statements, and the agent must navigate through the space and manipulate objects to successfully complete the tasks.

\(\)**WebShop :** This interactive web environment simulates the task of online shopping on an e-commerce website. The agent's goal is to understand a text instruction and buy a product that meets specified criteria. This involves querying the website's search engine, understanding the descriptions and details of each item, and selecting necessary options.

\(\)**WebArena :** This web-based benchmark introduces realistic environments by replicating the functionality and data found in popular web domains (e.g., Gitlab, Reddit, Wikipedia). Compared to WebShop, WebArena presents more challenges and difficulties for an LLM agent due to its large observation and action space, along with tasks that involve longer planning horizons. We focus oe the Reddit domain for the main WebArena experiments.

\(\)**Real-world multi-modal websites:** Finally, we consider evaluating AutoGuide on a variety of real-world website tasks. These span from a collaborative software development platform (e.g., GitHub) to a flight search engine (e.g., Google Flights) and an online education platform (e.g., Coursera). Please refer to Appendix B.4 for example tasks. In particular, in comparison to WebShop and WebArena, we design our tasks to be multi-modal such that the agent must consider both visual (e.g., images) and textual information (e.g., HTML) to complete these tasks.

#### 4.1.2 Baselines

We compare AutoGuide against the following baseline approaches to study the effect of context-aware guidelines (refer to Appendix B for more details):

\(\)**ReAct :** This LLM-based planning method integrates reasoning and acting to address sequential decision-making tasks. However, it does not leverage offline experiences and thus suffers from the limited understanding of pre-trained LLMs in downstream domains.

\(\)**Expel :** This method also extracts natural language knowledge from offline data. However, it fails to consider the applicability of guidelines and does not generate context-aware guidelines. Instead, it provides all guidelines to an LLM agent without filtering out irrelevant ones based on the current context. Expel has two contributions, the guideline generation and in-context example selection module. Because the latter is orthogonal to our analysis and can be seamlessly combined with our method, we consider Expel with guidelines in our experiments.

\(\)**Reflexion :** This approach converts environmental feedback into text statements to assist an LLM agent (e.g., ReAct) in the next trial. The baseline generates valuable feedback about solving a specific test task. We demonstrate how context-aware guidelines derived by AutoGuide can be combined with the feedback.

#### 4.1.3 Implementation

We collect offline experiences either by running ReAct and Reflexion, or incorporating human demonstrations. We use ReAct with GPT-3.5-turbo as our base LLM agent for WebShop and ALFWorld and GPT-4-turbo for WebArena. For each benchmark, we apply the same GPT model for action generation, context identification, and guideline selection. We extract context-aware guidelines from offline data with GPT-4-turbo and evaluate their effectiveness by applying them to the test set with non-overlapping tasks. We refer to Appendix B for more details.

### Main Results

**Q1.**_How effective is AutoGuide compared to baselines without context-aware guidelines?_

To answer this question, we compare methods on ALFWorld, WebShop, and WebArena benchmarks. The performance on the test datasets is presented in Table 1. There are three notable observations:

1. **Effectiveness of context-aware guidelines.** Our approach surpasses baseline performance in both ALFWorld and WebShop, achieving the highest test rewards and success rates in Table 1. These results highlight the effectiveness of employing context-aware guidelines in language-based decision-making domains. To further examine the action selection differences among ReAct, ExpeL, and our method, we present their trajectories in Figure 4. We observed that ReAct makes common mistakes such as trying to take soapbar that is not visible, or taking a soapbottle instead of soapbar due to their similar names. Both ExpeL and AutoGuide improve on this by extracting guidelines from similar mistakes in the offline experience. However, ExpeL often erroneously applies incorrect guidelines

    & Offline & Context & ALFWorld  & WebShop  & WebArena  \\   & data? & aware? & Success Rate (SR)\(\) & Reward\(\) & SR\(\) & SR\(\) \\  ReAct  & ✗ & ✗ & 54.5\% & 66.4 & 30\% & 8.0\% \\ ExpeL  & ✓ & ✗ & 59.0\% & 60.9 & 35\% & 21.8\% \\ AutoGuide & ✓ & ✓ & **79.1\%** & **73.4** & **46\%** & **47.1\%** \\  ReAct  & + Reflexion  & ✗ & ✗ & 67.2\% & 77.1 & 51\% & N/A \\ ExpL  & + Reflexion  & ✓ & ✗ & 71.6\% & 71.7 & 42\% & N/A \\ AutoGuide & + Reflexion  & ✓ & ✓ & **88.1\%** & **81.4** & **57\%** & N/A \\   

Table 1: Test reward and success rate on ALFWorld, WebShop, and WebArena. The base agent model for ALFWorld and WebShop is GPT-3.5-turbo and for WebArena is GPT-4-turbo. Reflexion is done by GPT-4-turbo for at most 3 trials. In our experiments, due to token limit of GPT, we did not experiment with Reflexion on WebArena tasks.

Figure 4: Trajectories of ReAct, ExpeL, and AutoGuide from the same test task. ReAct (Left) chose the wrong item, consequently failing the task in the end. ExpeL (middle) was confused by guidelines that were irrelevant to current context, leading to incorrect reasoning and actions. AutoGuide (right) selects relevant guidelines to the agent’s context, enabling the agent to accomplish the task.

due to the availability of all guidelines at each timestep. In Figure 4, ExpeL mistakenly attends to the second guideline _"ensure to specify the item's number and location..."_, leading to wrong reasoning and action. AutoGuide presents relevant guidelines at necessary moments, enabling accurate task completion by avoiding the mistakes seen in ExpeL and ReAct.

2. **Importance of providing pertinent knowledge.** ExpeL approach helps ReAct by extracting knowledge from offline experiences, but its impact is not as significant as AutoGuide. Recall that for ExpeL, the guidelines are neither generated for specific contexts at training time nor selected to only provide context-aware guidelines at test time. As a result, irrelevant guidelines can be introduced to an agent, potentially causing confusion for the agent. Consequently, the result highlights the significance of providing relevant guidelines conditioned on contexts for LLM agents.

3. **Scalability to complex environments.** We conduct experiments on WebArena-Reddit, which features more diverse tasks on realistic and complex websites requiring longer action sequences. This domain has a larger observation space and a more complex action space (e.g., scrolling). Table 1 presents the results, where AutoGuide achieves the highest success rate with a significant margin when compared to ReAct and ExpeL. We observe that ReAct scores low task success rate (8.0%) in WebArena due to the complex observation and action spaces and longer task horizon. In ExpeL, the issue of presenting all guidelines to an agent is exacerbated in the WebArena compared to simpler environments like ALFWorld and WebShop. WebArena's wide variety of tasks across different domains requires a larger number of guidelines to cover the knowledge needed for all tasks and domains. This results in either an overload of irrelevant guidelines that could mislead the agent or a lack of crucial information when the number of guidelines is limited, as suggested in ExpeL . In contrast, AutoGuide achieves a more significant performance enhancement (47.1%) compared to ExpeL (21.8%) by efficiently providing pertinent guidelines and minimizing the burden on context capacity. We refer to Figure 14 for a list of example contexts and guidelines.

**Q2.**_How does AutoGuide perform when combined with test-time self-feedback approaches?_

Our context-aware guidelines effectively provide _inter-task_ knowledge by considering multiple tasks in offline data. Meanwhile, self-feedback methods (e.g., Reflexion) offer _intra-task_ knowledge based on environmental feedback during test time. In this question, we explore the effectiveness of integrating both inter-task and intra-task information. The results presented in Table 1 demonstrate that the combination of AutoGuide with Reflexion achieves the highest performance in the WebShop and ALFWorld benchmarks. Hence, we find that our context-aware guidelines positively complement the intra-task knowledge of Reflexion. Another observation from Table 1 is that, while ExpeL + Reflexion outperforms ExpeL alone, this combination is not as effective as other approaches. This limitation may stem from ExpeL introducing irrelevant knowledge, potentially leading to conflicts with Reflexion's feedback and having an adverse impact on the decision-making process.

**Q3.**_Can AutoGuide generate context-aware guidelines for multi-modal inputs?_

Going beyond text-only inputs is an essential step toward building capable agents for solving real-world environments and tasks. We test AutoGuide in a complex multi-modal setting, where each observation includes image and text information. Specifically, we introduce a set of real-world website navigation tasks in 3 domains: GitHub, Google Flights, and Coursera. For these multi-modal tasks, we employ the Set-of-Marks (SoM) agent  as our base method. The SoM prompting improves the visual grounding capabilities of large multi-modal models such as GPT-4V by adding visually distinguishable marks to image inputs . We apply AutoGuide with GPT-4V to generate natural language context-aware guidelines from collected trajectories with both image and text observations.

    &  \\   & Reward\(\) & SR\(\) \\  ReAct (1-shot) & 66.4 & 30\% \\ ReAct (2-shot) & 66.0 & 35\% \\ ReAct (4-shot) & 70.2 & 37\% \\ ReAct (6-shot) & 71.0 & 38\% \\ AutoGuide & **73.4** & **46\%** \\   

Table 4: Ablation study of AutoGuide using various top-\(k\) values.

Table 2 shows the effectiveness of AutoGuide, demonstrating its generalization ability to complex real-world multi-modal settings. We refer to Figure 15 for example context-aware guidelines.

### Analyses of AutoGuide

**Q4.**_How does AutoGuide compare to ReAct with varying numbers of in-context examples?_

Table 3 shows that, while increasing the number of in-context examples for ReAct gradually improves performance, there is a plateau at a certain number of shots. Additionally, ReAct with more than 6 shots often exceeds the token limit of GPT-3.5-turbo. These results indicate that directly inputting raw trajectories into ReAct for in-context learning is not an effective way to fully leverage offline data. In contrast, AutoGuide extracts knowledge from entire training trajectories by summarizing them into concise context-aware guidelines, making them easy to integrate with prompt-based agents.

**Q5.**_How does altering the number of top-\(k\) guidelines impact the performance of AutoGuide?_

We conducted an ablation study on WebShop using various values of \(k\) in Table 4. We find that employing context-aware guidelines consistently outperforms the no-guideline baseline (\(k=0\); ReAct). The \(k=3\) yields the best performance. The largest \(k\) value of 5 can lead an LLM agent to overthink, potentially resulting in a slight decrease in performance. Conversely, a smaller \(k\), like \(k\!=\!1\), may cause LLM to overlook additional helpful guidelines, leading to slightly worse performance.

**Q6.**_How do AutoGuide's context-aware guidelines generalize to out-of-domain environments?_

We conduct an experiment to further demonstrate AutoGuide's out-of-domain capability across different domains but relevant tasks. We extract context-aware guidelines from WebShop and apply them to WebArena-Shopping, which is a distinct domain with variations in observation/action spaces, task intentions, and episodic horizons. For this domain adaptation case, we additionally incorporate a grounding module to align the context-aware guidelines from WebShop to WebArena's observations based on GPT-4-Turbo. As shown in Table 5, the transferred guidelines bring a notable improvement in success rates compared to the ReAct baseline in WebArena Shopping.

**Q7.**_How does each component of_ AutoGuide _contribute to the final results?_

We evaluate the impact of different components within AutoGuide on its performance in WebShop, as detailed in Table 6. We examine two variants: ReAct+CI and ReAct+GES. The ReAct+CI, which incorporates contexts into observations without guidelines, shows improvement over ReAct. This suggests that contexts enhance decision-making by verifying the current state before action selection. ReAct+GES, which generates guidelines from trajectories without contexts and employs GPT-3.5-turbo for guideline selection, also enhances performance but is less effective than the full AutoGuide. This indicates that choosing relevant guidelines based on the trajectory alone is more challenging than using contexts. Therefore, integrating both context summaries and guidelines is crucial for maximizing the benefits of AutoGuide.

## 5 Conclusion

We present AutoGuide, an effective framework for exploiting important domain knowledge from offline experiences for improving decision-making with pre-trained LLMs. We proposed to generate context-aware guidelines that can be incorporated into prompts for LLM agents. As AutoGuide extracts the guidelines by contrasting trajectories in offline data, the resulting context-aware guidelines carry critical information for preventing failures in the domains. For inference, it provides the guidelines pertinent to each of the different context that LLM agents encounter, which can make

   Algorithm & CI & GES & WebShop SR\(\) \\  ReAct & ✗ & ✗ & 30\% \\ ReAct + CI & ✓ & ✗ & 36\% \\ ReAct + GES & ✗ & ✓ & 37\% \\ AutoGuide & ✓ & ✓ & **46\%** \\   

Table 6: Ablation study of AutoGuide, analyzing each module’s contribution in WebShop. CI denotes our context identification module, and GES denotes the guideline extraction and selection modules.

   Algorithm & WebArena–Shopping \\   & SR\(\) \\  ReAct & 10.2\% \\ AutoGuide & 20.4\% \\   

Table 5: Out-of-distribution generalization of context-aware guidelines from WebShop on the 98 WebArena–Shopping tasks that have a product in the intent template.

pre-trained LLMs strong decision-making agents in the downstream domains. Empirically, we showed that AutoGuide outperforms strong baselines by a large margin and achieves outstanding performance in decision-making benchmarks.

## 6 Acknowledgements

This work was supported in part by LG AI Research.