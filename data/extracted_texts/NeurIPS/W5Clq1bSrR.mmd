# Toward Understanding Generative Data Augmentation

Chenyu Zheng\({}^{1,2}\), Guoqiang Wu\({}^{3}\), Chongxuan Li\({}^{1,2}\)

\({}^{1}\) Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China

\({}^{2}\) Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China

\({}^{3}\) School of Software, Shandong University, Shandong, China

{chenyu.zheng666, guoqiangwu90}@gmail.com; chongxuanli@ruc.edu.cn

Correspondence to Chongxuan Li.

###### Abstract

Generative data augmentation, which scales datasets by obtaining fake labeled examples from a trained conditional generative model, boosts classification performance in various learning tasks including (semi-)supervised learning, few-shot learning, and adversarially robust learning. However, little work has theoretically investigated the effect of generative data augmentation. To fill this gap, we establish a general stability bound in this not independently and identically distributed (non-i.i.d.) setting, where the learned distribution is dependent on the original train set and generally not the same as the true distribution. Our theoretical result includes the divergence between the learned distribution and the true distribution. It shows that _generative data augmentation can enjoy a faster learning rate when the order of divergence term is \(o(((m)_{m},1/))\)_, where \(m\) is the train set size and \(_{m}\) is the corresponding stability constant. We further specify the learning setup to the Gaussian mixture model and generative adversarial nets. We prove that _in both cases, though generative data augmentation does not enjoy a faster learning rate, it can improve the learning guarantees at a constant level when the train set is small, which is significant when the awful overfitting occurs_. Simulation results on the Gaussian mixture model and empirical results on generative adversarial nets support our theoretical conclusions. Our code is available at _https://github.com/ML-GSAI/Understanding-GDA_.

## 1 Introduction

Deep generative models [1; 2; 3; 4] have achieved great success in many fields, including computer vision [5; 6], natural language processing [7; 8; 9], and cross-modal learning [10; 11; 12] in the recent years. A promising usage built upon them is generative data augmentation (GDA) [13; 14; 15], which scales the train set by producing synthetic examples with labels based on advanced conditional generative models. Empirically, it has been observed that GDA can improve classification performance in lots of settings, including supervised learning [16; 17], semi-supervised learning [18; 19; 20], few-shot learning , zero-shot learning , adversarial robust learning [23; 24], etc.

Although promising algorithms and applications of GDA emerge in different learning setups, our experiments in Section 4 show that GDA does not always work, such as in the case with a rich train set or standard augmentation methods (e.g., flip). Besides, the number of augmented data has a significant impact on the performance while is often tuned manually. These phenomena motivate us to study the effect of GDA. Unfortunately, little work has investigated this technique from a theoretical perspective. Therefore, in this paper, we take a first step towards understanding it. Specially, we consider the supervised classification setting, and try to answer the following questions rigorously:

* _Can we establish learning guarantees for GDA and explain when it works precisely?_* _Can we obtain theoretical insights on hyperparameters like the number of augmented data?_

Our first main contribution is to propose a general algorithmic stability bound for GDA in Section 3.1. The main technical challenge is that GDA breaks the primary i.i.d. assumption of the classical results [25; 26] because the distribution learned by the generative model is dependent on the sampled train set and generally not the same as the true distribution. Besides, it is unclear whether the existing general non-i.i.d. stability bounds [27; 28; 29] are suitable to derive meaningful guarantees for GDA. Informally, our result (Theorem 3.1) can be presented as follows:

\[||+,\]

where _Gen-error_ means the generalization error of GDA, and \(a b\) means \(a=O(b)\). The distributions' divergence term on the right hand is caused by the divergence between the distribution learned by the generative model and the true distribution. In addition, the remaining generalization error w.r.t. mixed distribution vanishes as we increase the augmentation size. Comparing this bound to the classical result without GDA (Theorem 2.1), we can obtain an exact condition for GDA to be effective: _GDA can enjoy a faster learning rate when the order of divergence term is \(o(((m)_{m},1/))\)_, where \(m\) is the train set size and \(_{m}\) is the corresponding uniform stability constant. This means the performance of the chosen generative model matters a lot.

Our second main contribution is to particularize the general results to the binary Gaussian mixture model (bGMM) and generative adversarial nets (GANs)  in Section 3.2 and Section 3.3, respectively. Our theoretical results (Theorems 3.2 and 3.3) show that, in both cases, the order of the divergence term in the obtained upper bound is \((((m)_{m},1/))\). Therefore, when the train set size is large enough, it is hopeless to use GDA to boost the classification performance by a large margin. Worse still, GDA may damage the generalization of the learning algorithm. However, _when the train set size is small and awful overfitting happens, GDA can improve the learning guarantee at a constant level, which is significant in this situation_. These theoretical implications show the promise of GDA in real-world problems with limited data.

Finally, experiments presented in Section 4 validate our theoretical findings. In particular, in the bGMM setting, experimental results show that our generalization bound (Theorem 3.2) predicts the order and trend of true generalization error well. Besides, in our empirical study on the real image dataset, we find that GANs can not boost the test performance obviously and even damage the generalization when standard data augmentation methods are used to approximate the case with a large train set. In contrast, GANs improve the performance by a large margin when the train set size is small and terrible overfitting occurs. All these experimental results support our theoretical implications in Section 3. Furthermore, we also conduct experiments with the state-of-the-art diffusion model . Empirical results show the promise of the diffusion model in GDA and suggest it could have a faster learning rate than GAN.

## 2 Preliminaries

### Notations

Let \(^{d}\) be the input space and \(\) be the label space. We denote by \(\) the population distribution over \(=\). The \(L_{p}\) norm of a random variable \(X\) is denoted as \(\|X\|_{p}=(|X|^{p})^{}\). Given a set \(S=\{_{1},_{2},,_{m}\}\), we define \(S^{ i}\) as the set after removing the \(i\)-th data point in the set \(S\), and \(S^{i}\) as the set after replacing the \(i\)-th data point with \(_{i}^{}\) in the set \(S\). Let \([m]=\{1,2,,m\}\), then for every set \(V[n]\), we define \(S_{V}=\{_{i}:i V\}\). In addition, for some function \(f=f(S)\), we denote its conditional \(L_{p}\) norm with respect to \(S_{V}\) by \(\|f\|_{p}(S_{V})=([\|f\|^{p} S_{V}])^{ }\). Besides, we denote the total variation distance by \(_{}\) and KL divergence by \(_{}\), respectively.

We let \(()^{}\) be the set of all measurable functions from \(\) to \(\), \(\) be a learning algorithm and \((S)()^{}\) be the hypothesis learned on the dataset \(S\). Given a learned hypothesis \((S)\) and a loss function \(:()^{}_{+}\), the true error \(_{}((S))\) with respect to the data distribution \(\) is defined as \(_{}[((S),)]\). In addition, the corresponding empirical error \(}_{S}((S))\) is defined as \(_{i=1}^{m}((S),_{i})\).

### Generative data augmentation

In this part, we describe the process of GDA in a mathematical way. Given a training set \(S\) with \(m_{S}\) i.i.d. examples from \(\), we can train a conditional generative model \(G\), and denote the model distribution by \(_{G}(S)\). We note that the randomness from training the generative model is ignored in this paper. In addition, we define the expectation of the model distribution with regard to \(S\) as \(_{G}=_{S}[_{G}(S)]\). Based on the trained generative model, we can then obtain a new dataset \(S_{G}\) with \(m_{G}\) i.i.d. samples from \(_{G}(S)\), where \(m_{G}\) is a hyperparameter. Typically, we consider the case that \(m_{G}=(m_{S})\) if GDA is utilized. We denote the total number of the data points in augmented set \(=S S_{G}\) by \(m_{T}\). Besides, we define the mixed distribution after augmentation as \(}(S)=}{m_{T}}+}{m_{T}} _{G}(S)\). As a result, a hypothesis \(()\) can be learned on the augmented dataset \(\). To understand the effect of GDA, we are interested in the generalization error \(|_{}(())-}_ {}(())|\) with regard to the learned hypothesis \(()\). For convenience, we denote it by _Gen-error_ in the remaining paper. Technically, we establish bounds for _Gen-error_ using the algorithmic stability introduced in the next subsection. As far as we know, this is the first work to investigate the learning guarantees for GDA.

### Generalization via algorithmic stability

Algorithmic stability analysis is a important tool to provide guarantees for the generalization of machine learning models. A key advantage of stability analysis is that it exploits particular properties of the algorithm and provides algorithm-dependent bounds. Different notations of stability have been proposed and used to establish high probability bounds for generalization error [25; 31; 32; 33]. Among them, uniform stability is the most widely used and has been utilized to analyze the generalization of many learning algorithms, including regularized empirical risk minimization (ERM) algorithms  and stochastic gradient descent (SGD) [32; 34; 35]. The uniform stability is defined as the following.

**Definition 2.1** (Uniform stability).: _Algorithm \(\) is uniformly \(_{m}\)-stable with respect to the loss function \(\) if the following holds_

\[ S^{m},, i[m], _{}((S),)-((S^ {i}),)_{m}.\]

Given a \(_{m}\)-stable learning algorithm, the milestone work  provides a high probability generalization bound that converges when \(_{m}=o(1/)\). This condition may fail to hold in some modern machine learning settings , which leads to meaningless guarantees. In recent years, some works [37; 38; 26] improved the classical bound by establishing novel and tighter concentration inequalities. Especially,  proposed a moment bound and obtained a nearly optimal generalization guarantee, which only requires \(_{m}=o(1/ m)\) to converge. It is listed in the next theorem.

**Theorem 2.1** (Corollary 8, ).: _Assume that \(\) is a \(_{m}\)-stable learning algorithm and the loss function \(\) is bounded by \(M\). Given a training set \(S\) with \(m\) i.i.d. examples sampled from the distribution \(\), then for any \((0,1)\), with probability at least \(1-\), it holds that_

\[_{}((S))-}_{S}(A (S))(m)_{m}()+M()}.\] (1)

We note that all generalization bounds mentioned above require a primary condition: data points are drawn i.i.d. according to the population distribution \(\). However, it no longer holds in the setting of GDA. On the one hand, the distribution \(_{G}(S)\) learned by the generative model is generally not the same as the true distribution \(\). On the other hand, the learned \(_{G}(S)\) is heavily dependent on the sampled dataset \(S\). This property brings obstacles to the derivation of the generalization bound for GDA. Furthermore, though there exists some non-i.i.d. stability bounds [27; 28; 29], it is still unclear whether these techniques are suitable in the GDA setting.

## 3 Main theoretical results

In this section, we present our main theoretical results. In Section 3.1, we establish a general generalization bound (Theorem 3.1) for GDA. Built upon the general learning guarantee, we thenparticularize the learning setup to the bGMM introduced in Section 3.2.1 and derive a specified generalization bound (Theorem 3.2). Finally, we discuss our theoretical implications on GANs in real-world problems (Theorem 3.3). Notably, to the best of our knowledge, this is the first work to investigate the generalization guarantee of GDA.

### General generalization bound

To understand GDA, we are interested in studying the generalization error of the hypothesis \(()\) learned on the dataset \(\) after augmentation. Formally, we need to bound \(|_{}(())- }_{}(())|\), which has been defined as _Gen-error_ in Section 2.2. Recall that \(}(S)\) has been defined as the mixed distribution after augmentation, to derive such a bound, we first decomposed _Gen-error_ as

\[||_{}(( ))-_{}(S)}(( ))|}_{}+_{}(S)}(())- }_{}(())|}_{ }.\]

The first term on the right hand can be bounded by the divergence (e.g., \(_{},_{}\)) between the mixed distribution \(}(S)\) and the true distribution \(\). It is heavily dependent on the ability of the chosen generative model. For the second term, we note that classical stability bounds (e.g. Theorem 2.1) can not be used directly, because points in \(\) are drawn non-i.i.d.. We mainly use a core property of \(\), that is, \(S\) satisfies the i.i.d. assumption, and \(S_{G}\) satisfies the conditional i.i.d. assumption when \(S\) is fixed. Inspired by this property, we furthermore decompose this term and utilize sharp moment inequalities [39; 26] to obtain an upper bound. Finally, we conclude with the following result.

**Theorem 3.1** (Generalization bound for GDA, proof in Appendix B.1).: _Assume that \(\) is a \(_{m}\)-stable learning algorithm and the loss function \(\) is bounded by \(M\). Given an set \(\) augmented as described in Section 2.2, then for any \((0,1)\), with probability at least \(1-\), it holds that_

\[|| }{m_{T}}M_{ }(,_{G}(S))}_{}+}+})+m_{S}} _{m_{T}}}{m_{T}})}\] \[+}(m_{S} m_{S}+m_{G} m_{G}) +m_{S} m_{S}M(m_{S},m_{G})}{m_{T}}( ),\]

_where \((m_{S},m_{G})=_{i}_{}(_{ G}^{m_{G}}(S),_{G}^{m_{G}}(S^{i}))\)._

_Remark_.: **Tightness of the proposed upper bound.** Let \(m_{G}=0\), we observe that Theorem 3.1 degenerates to Theorem 2.1. Therefore, our stability bound includes the i.i.d. setting as a special case and benefits from the same nearly optimal guarantee shown by . Further analysis of the tightness of our guarantee when \(m_{G}>0\) is left to future work.

_Remark_.: **Comparison with the existing non-i.i.d. stability bounds.** Detailed introduction for non-i.i.d. stability bounds is placed in Section 5. We note that previous results [27; 28; 29] are proposed for the general non-i.i.d. case. Therefore, they may fail to give awesome guarantees in this special case. In Appendix C, we show that it is hard to derive a better bound than Theorem 3.1 by using the existing non-i.i.d. stability results directly.

_Remark_.: **Stability of the learned distribution \(_{G}(S)\).**\((m_{S},m_{G})\) in Theorem 3.1 reflects the stability of the learned distribution with regard to changing one data point in the training set received by the generative model. Our bound suggests that the more stable the model distribution is, the better performance can be achieved by GDA. As far as we know, though uniformly stability of some generative learning algorithms has been studied , the new notation \((m_{S},m_{G})\) emerging in our bound has not been studied yet.

_Remark_.: **Selection of augmentation size.** We first consider the order of the upper bound with respect to \(m_{S}\). Observing Theorem 3.1, we find that the distributions' divergence term can not be controlled by increasing \(m_{G}\) while the remaining generalization error w.r.t. mixed distribution will vanish. We note that there exists a trade-off between the fast learning rate and augmentation consumption. Typically, the augmentation consumption is caused by additional sampling, training, and storage. When the order of the divergence term is smaller than that of the remains, increasing \(m_{G}\) can induce a faster convergence. Otherwise, increasing \(m_{G}\) can not lead to a faster convergence but a largerconsumption. Therefore, an efficient augmentation size \(m_{G,}^{*}\) with regard to the order of \(m_{S}\) can be defined as follows:

\[m_{G,}^{*}=_{m_{G}}\{\}.\]

Furthermore, without considering the cost, the optimal augmentation number \(m_{G}^{*}\) can be achieved by minimizing the upper bound directly. Unfortunately, it is difficult to calculate an explicit form of \(m_{G,}^{*}\) and \(m_{G}^{*}\) here due to the ignorance of \(_{m_{T}}\) and \((m_{S},m_{G})\). We will discuss them more concretely in the specified cases.

_Remark_.: **Sufficient conditions for GDA with (no) faster learning rate.** We still consider the order of the learning guarantee with respect to \(m_{S}\) here. Let \(m_{G}=m_{G,}^{*}\), it can be found that divergence \(_{}(,_{G}(S))\) plays an important role in deciding whether GDA can enjoy a faster learning rate. Comparing Theorem 3.1 with Theorem 2.1 (without augmentation), we can conclude sufficient conditions as follows.

_Corollary 3.1_.: _Assume that the loss function \(\) is bounded by \(M\), we have_

* _if_ \(_{}(,_{G}(S))=o( ((m)_{m},1/)))\)_, then GDA enjoys a faster learning rate._
* _if_ \(_{}(,_{G}(S))= (((m)_{m},1/)))\)_, then GDA can not enjoy a faster learning rate._

Notably, as we will present in Section 3.2 and 3.3, though GDA can not enjoy a faster learning rate in both special case, it is possible to improve the generalization guarantee at a constant level when \(m_{S}\) is small, which is important when awful overfitting happens.

### Theoretical results on bGMM

The bGMM is a classical but non-trivial setting, which has been widely studied in literature [41; 42; 43]. In this section, we investigated it in the context of GDA. Simulations will be conducted in Section 4.1 to verify these results.

#### 3.2.1 Setting of bGMM

In this part, we introduce the data distribution configuration in the bGMM, as well as the corresponding linear classifier and conditional generative model. Similar setups of distribution and classifier have been adopted by many previous works [44; 45; 46].

**Distribution setting.** We consider a binary task where \(=\{-1,1\}\). Given a vector \(^{d}(\|\|_{2}=1)\) and noise variance \(^{2}>0\), we assume that the distribution satisfies \(y\{-1,1\}\) and \( y(y,^{2}I_{d})\). Besides, similarly to , we assume that the distribution of \(y\) is known, which is satisfied in conditional learning with labels.

**Simple linear classifier.** We consider a linear classifier parameterized by \(^{d}\) in the form of prediction \(=(^{})\). Given \(m\) samples, \(\) is learned by performing ERM with respect to the negative log-likelihood loss function, that is,

\[l(,(,y))=}(-y)^ {}(-y).\]

As a result, this learning algorithm will return \(}=_{i=1}^{m}y_{i}_{i}\), which satisfies \([}]=\).

**Conditional generative model.** We consider a simple generative model parameterized by \(_{y},_{k}^{2}\), where \(y\{-1,1\}\) and \(k[d]\). It learns the parameters of Gaussian mixture distribution directly. Given \(m\) data points, let \(m_{y}\) be the number of samples in class \(y\), it returns

\[}_{y}==y}_{i}}{m_{y}}, {}_{k}^{2}=_{y}}{m}=y}(x_{ik}-_{yk})^{2}}{m_{y}-1},\]

which are unbiased estimators of \(\) and \(^{2}\), respectively. Based on the learned parameters, we can perform GDA by generating new samples from the distribution \(y\{-1,1\}\), \( y(}_{y},)\), where \(=(_{1}^{2},,_{d}^{2})\).

#### 3.2.2 Theoretical results

In this section, we establish the generalization bound for bGMM based on the general bound proposed in Theorem 3.1. To derive such a bound, the main task is to bound terms \(M\), \(_{m_{T}}\), \(_{}(,_{G}(S))\) and \((m_{S},m_{G})\) in Theorem 3.1. For \(M\) (Lemma B.5) and \(_{m_{T}}\) (Lemma B.6), we mainly use the concentration property of the multivariate Gaussian variable (Lemma B.4). In addition, inspired by previous works on naive Bayes , we bound \(_{}(,_{G}(S))\) (Lemma B.7) by discussing the distance between the estimated parameters and the true parameters of bGMM. Besides, the concentration property of \((m_{S},m_{G})\) (Lemma B.9) can be induced by the preceding discussion. Finally, we can obtain the following results.

**Theorem 3.2** (Generalization bound for bGMM, proof in Appendix B.2).: _Consider the setting introduced in Section 3.2.1. Given a set \(S\) with \(m_{S}\) i.i.d. samples from the bGMM distribution \(\) and an augmented set \(S_{G}\) with \(m_{G}\) i.i.d. samples drawn from the learned Gaussian mixture distribution, then with high probability at least \(1-\), it holds that_

\[||)}{}}& {if fix $d$ and $m_{G}=0$,}\\ (m_{S})}{}}&=(m_{S})$,}\\ )}{}}&=m_{G,}^{*}$,}\\ d&$.}\] (2)

_Remark_.: **Explicit upper bound of generalization error.** (19) in Appendix B.2 gives us an explicit form to predict the generalization error in the bGMM setting. In Section 4.1, we will see that (19) predicts the order and trend of true generalization error well, which verifies the correctness of the proposed learning guarantee in the bGMM setting.

_Remark_.: **Negative learning rate of GDA.** Even though we estimate the sufficient statistics of the Gaussian mixture distribution (\(\) and \(^{2}\)) directly in this special case, we can not hope to enjoy a better learning rate. Things could be worse when we model the distribution in reality (e.g., images, texts), which suggests that when original samples are abundant, further performing GDA based on existing generative models can not improve the generalization. Theorem 3.3 supports this viewpoint.

_Remark_.: **Improvement at a constant level matters a lot when overfitting happens.** From (2) we know that when \(m_{S}\) is small and \(d\) is large, the curse of dimensionality happens, which leads to an awful generalization error. In this case, though GDA can only improve it at a constant level by controlling the generalization error w.r.t. mixed distribution, the effect is obvious due to the large scale of \(d\). We note that it is challenging to obtain an explicit form of the constant-level improvement due to the complexity of the generalization bound. Therefore, we clarify this more clearly by comparing the cases where \(m_{G}=0\) (without GDA) and \(m_{G}+\) in Corollary B.1 of Appendix B.2.

### Implications on deep generative models

Nowadays, data augmentation with deep generative models is widely used and received lots of attention. Therefore, benefiting from the recent advances in the generative adversarial network (GAN) [2; 49] and SGD [35; 50], we discuss implications of our theory on real problems, which will be verified by the empirical experiments in Section 4.2.

#### 3.3.1 Learning setup

We consider the general binary classification task in the deep learning era. In this part, we introduce the setup of data distribution, deep neural classifier, learning algorithm, and deep generative model.

**Distribution setting.** We assume that input space satisfies \(^{d}\), and our analysis can be easily extended to any bounded input space. This assumption generally holds in many practical problems, for example, image data satisfies \(^{d}\). Similarly to bGMM, we let \(=\{-1,1\}\) and assume that the distribution of \(y\) is known.

**Deep neural classifier.** We consider a general \(L\)-layer multi-layer perception (MLP) or convolutional neural network (CNN) \(f(,):\), where \(\) denotes its weights and \(_{l}\) denotes the weights in the \(l\)-th layer. Its abstract architecture is consistent with that in , and details can be foundin Appendix A.1. In addition, we suppose the deep neural classifier satisfies smoothness and boundedness assumptions, which are adopted by many previous works [34; 35; 50; 51].

**Assumption 3.1** (Smoothness).: _We assume that \(f(,)\) is \(\)-smooth with respect to \(\), that is, \(| f(_{1},)- f(_{2},)|\| _{1}-_{2}\|_{2}\) for any \(_{1}\) and \(_{2}\)._

**Assumption 3.2** (Boundedness).: _We assume that for all \(l[L]\), there exists a constant \(W_{l}\), which satisfies \(\|_{l}\|_{2} W_{l}\)._

**Learning algorithm for the deep neural classifier.** The setting of the learning algorithm is conformed to the practice. We assume that the loss function is the binary cross-entropy loss \((f,(,y))=(1+(-yf(,)))\) and it is optimized by SGD. For the \(t\)-th step, we set the step size as \(\) for some positive constant \(c\). Besides, we assume that the total iteration number \(T=O(m_{T})\). These configurations are adopted by past works on the stability of SGD [34; 35].

**Deep generative model.** We choose GAN as our deep generative model, which is parameterized by MLP. Its abstract architecture is the same as that in Theorem 19 of , and details are placed in Appendix A.2. Besides, due to the lack of conditional generative model theory, we make a naive approximation here by assuming that each category is learned by a GAN, respectively.

#### 3.3.2 Theoretical results

Similarly to the bGMM setting, we establish a generalization bound for the deep learning setup. To reach this goal, we bound terms \(M\), \(_{m_{T}}\), and \(_{}(,_{G}(S))\) based on the recent results on GAN  and SGD [29; 50]. First, boundedness and Lipschitzness of classifier \(f\) can be induced from Assumption 3.2 (Lemma B.10). Second, the boundedness of \(f\) directly implies the upper bound for \(M\) because the binary cross-entropy loss is 1-Lipschitz with respect to \(f\). Third, by combining the Lipschitzness and smoothness of \(f\), we can bound \(_{m_{T}}\) for SGD (Lemma B.11). Finally, \(_{}(,_{G}(S))\) can be bounded by the result in  (Lemma B.12).

**Theorem 3.3** (Generalization bound for GAN, proof in Appendix B.3).: _Consider the setup introduced in Section 3.3.1. Given a set \(S\) with \(m_{S}\) i.i.d. samples from any distribution \(\) and an augmented set \(S_{G}\) with \(m_{G}\) i.i.d. examples sampled from the distribution \(_{G}(S)\) learned by GANs, then for any fixed \((0,1)\), with probability at least \(1-\), it holds that_

\[||}}& {if fix $W,L,d$, let $m_{G}=0$,}\\ (()}{m_{S}})^{}, m_{S} (m_{S},m_{G}))&=(m_{S})$,}\\ ()}{m_{S}})^{}&=m_{G,}^{*}$,}\\ dL^{2}(_{l=1}^{L}\|W_{l}\|_{2})^{2}&$.}\]

_Remark_.: **Slow learning rate with GDA.** Upper bounds in Theorem 3.3 show that when we perform GDA, the order with regard to \(m_{S}\) strictly becomes worse. Therefore, it implies that when \(m_{S}\) is large enough, it is hopeless to boost the performance obviously by augmenting the train set based on GANs. On the contrary, GDA may make the generalization worse.

_Remark_.: **GDA matters a lot when overfitting happens.** From Theorem 3.3, we know that as the data dimension and model capacity become larger, the deep neural classifier trained with SGD becomes easier to overfit the train set and gain terrible generalization performance. In this case, a constant-level improvement of generalization caused by GDA will be significant. Similarly to the bGMM setting, we clarify the constant-level improvement by comparing the cases where \(m_{G}=0\) (without GDA) and \(m_{G}+\) in Corollary B.2 of Appendix B.3.

## 4 Experiments

In this section, we conduct experiments to verify the results in Section 3, which are two-folded:

* We conduct simulations in the setting of bGMM and validate the results in Theorem 3.2.
* We empirically study the effect of GDA on the real CIFAR-10 dataset , which supports our theoretical implications on GANs.

### Simulations on bGMM

We let \(=(1/,,1/)^{}\) to satisfy \(\|\|_{2}=1\), \(^{2}=0.6^{2}\), and randomly generate 10,000 samples according to the Gaussian mixture distribution as the test set. We approximate the _Gen-error_ by the gap between the training error and the test error. To eliminate randomness, we average over 1,000 random runs and report the mean results. We denote \(=m_{G}/m_{S}\) in this section.

First, we investigate the case that data dimension \(d\) is fixed. To verify the order is near to \(O(1/})\) (\( m_{S}\) can be ignored with respect to \(}\)), we fix \(d=1\), and change \(m_{S}\) from 20 to 500. For each selected \(m_{S}\), we adjust \(\) from 0 to 50 to generate new samples in different levels. The result is presented in Figure 0(a), which shows that the generalization error decreases in a near \(O(1/})\) order. Besides, generalization error without GDA is always (near) optimal, which empirically proves that GDA is ineffective when \(m_{S}\) is large enough.

Second, we conduct simulations in the case that \(m_{S}\) is fixed as a small constant. To verify the order is \(O(d)\), we fix \(m_{S}=10\), and change \(d\) from 2 to 100. For each selected \(d\), we also adjust \(\) from 0 to 50. The result is displayed in Figure 0(d), which shows that the generalization error increases in a \(O(d)\) order. In addition, when \(d\) is large (e.g., 100) and the curse of dimensionality happens, generalization error with larger \(\) is better by a big margin, which suggests that though GDA could only enhance it at a constant level, the effect is significant when overfitting occurs.

Third, we design experiments to validate whether the upper bound in Theorem 3.2 can predict the trend of generalization error well. Similarly to previous theoretical works (e.g. ), we find an approximation of (19) in Appendix B.2 as our prediction by replacing \((a/)\) with \((a)\) if \(a 1\) else 1. We plot the ground truths and predictions in the case that \((d,m_{S})=(1,40)\) and \((50,10)\), respectively. Results in Figure 1 show that our bound predicts the trend of generalization error well. Therefore, an approximation of the optimal augmentation size \(m_{G}^{*}\) can be found by minimizing (19).

### Empirical results on CIFAR-10

In this part, we conduct experiments on the real CIFAR-10 dataset with ResNets  and various deep generative models, including conditional DCGAN (cDCGAN) , StyleGAN2-ADA  and elucidating diffusion model (EDM) . Details of experiments (e.g. motivation, model architecture, training) can be found in Appendix D.

To validate our theoretical implications in Section 3.3, we are supposed to discuss two cases, where one \(m_{S}\) is small and the other \(m_{S}\) is large. The two cases can be approximated by whether performing another data augmentation. We additionally use the standard data augmentation in  to approximate the case with large \(m_{S}\). Then, for each selected ResNet and generative model, we set \(m_{G}\) from 0 to

Figure 1: Simulations results on the bGMM setting. We do not integrate the truths and predictions due to the difference between their y-axis scale.

1M and record the accuracy of the trained classifier on the CIFAR-10 test set. Results are presented in Table 1. We further empirically verify our theory by estimating the generalization error directly. By definition, given a trained neural classifier, the generalization error of Theorem 3.3 can be estimated by the absolute gap between the mean cross-entropy loss on the training set (with generated data) and the mean cross-entropy loss on the test set. We place the results and analysis with this estimator at Table 3 in Appendix D.7. In the following, we interpret our experimental results.

**GANs improve the test performance of classifiers when overfitting occurs.** When standard augmentation is not used, ResNets trained on the train set consistently suffer from overfitting. However, this can be relieved by data augmentation based on GANs, though cDCGAN can not generate high-quality images. This phenomenon supports the implications from Theorem 3.3.

**We can not have an obvious improvement by using GANs when \(m_{S}\) is approximately large.** When standard augmentation is used, deep neural classifiers trained on the CIFAR-10 dataset achieve non-trivial performance. In this case, GDA with cDCGAN always damages the generalization ability. Though we use StyleGAN2-ADA, which achieves state-of-the-art conditional image generation performance on the CIFAR-10 dataset, we can not boost the performance of classifiers obviously, and even consistently obtain worse test accuracy when \(m_{G}\) is 500k or 1M.

**Diffusion probabilistic models are promising for GDA.** As diffusion models show their excellent ability on image generation, a natural question emerges: _are diffusion models more suitable for GDA?_ We choose the EDM that achieves state-of-the-art FID scores as the generator. Table 1 in Appendix D.7 shows that EDM improves the test accuracy obviously, even though the standard augmentation has been utilized. This suggests that diffusion models enjoy \(_{}(,_{G}(S))\) with a faster convergence rate than GANs, and shows the promise of diffusion models in GDA.

    &  &  & \))} \\   & & & 0 & 100k & 300k & 500k & 700k & 1M \\   &  & \(\) & 85.76 & 86.8 & 87.83 & 87.59 & 87.52 & 86.47 \\  & & \(\) & 94.4 & 93.92 & 93.41 & 93.81 & 93.01 & 92.6 \\   & & \(\) & 85 & 86.9 & 87.93 & 87.56 & 87.17 & 86.28 \\  & & \(\) & 94.59 & 94.83 & 94.21 & 93.64 & 93.69 & 93.18 \\   & & \(\) & 82.85 & 87.49 & 88.59 & 86.67 & 86.3 & 85.2 \\  & & \(\) & 94.69 & 94.43 & 93.86 & 93.74 & 93.12 & 92.63 \\   &  & \(\) & 85.76 & 90.22 & 91.33 & 91.37 & 91.25 & 91.38 \\  & & \(\) & 94.4 & 94.68 & 94.46 & 94.4 & 94.11 & 94.12 \\   & & \(\) & 85 & 90.24 & 91.23 & 91.45 & 91.56 & 90.91 \\  & & \(\) & 94.59 & 95.05 & 94.9 & 94.4 & 94.43 & 94.21 \\   & & \(\) & 82.85 & 90.85 & 92.29 & 92.29 & 92.29 & 91.61 \\  & & \(\) & 94.69 & 94.74 & 95.04 & 94.56 & 94.76 & 94.28 \\   &  & \(\) & 85.76 & 92.8 & 94.87 & 95.43 & 96.24 & 96.28 \\  & & \(\) & 94.4 & 96.15 & 96.74 & 97.09 & 97.28 & 97.5 \\    & & \(\) & 85 & 93.42 & 94.93 & 95.59 & 96.14 & 96.44 \\   & & \(\) & 94.59 & 96.47 & 96.96 & 97.36 & 97.53 & 97.51 \\    & & \(\) & 82.85 & 93.29 & 95.29 & 95.95 & 96.1 & 96.64 \\   & & \(\) & 94.69 & 96.09 & 96.87 & 97.28 & 97.6 & 97.74 \\   

Table 1: Accuracy on the CIFAR-10 test set, where S.A. denotes standard augmentation.

Related work

**Data augmentation practice and theory.** Data augmentation [57; 58] is a universal method to improve the generalization ability of deep neural networks in the case of insufficient training data. Classical data augmentation methods include geometric transformations , color space transformations , kernel filters , mixing images , random erasing , feature space augmentation , etc. There are also many theoretical works studying the effect of classical data augmentation methods from different perspectives [64; 65; 66; 67; 68].

With the advance of deep generative models, GDA becomes a novel and promising data augmentation technique. For example,  shows that augmenting the ImageNet training set  with samples from the conditional diffusion models significantly improves the classification accuracy. However, little work has investigated the theory of GDA. Both empirical success and theoretical opening encourage us to study the role of GDA.

**Algorithmic stability theory.** Classical results [25; 26] introduced detailedly in Section 2 has various extensions. Prominent work  focuses on the uniform stability of SGD and derive generalization bounds for it.  improves the results in  and obtains tight guarantees for the stability of SGD, which is used in Theorem 3.3.

Establishing stability bounds under non-i.i.d. settings has also received a surge of interest in recent years. A major line models the dependencies by mixing models [70; 71] and derives stability bounds with mixing coefficients [27; 28; 72]. However, it is usually difficult to estimate the mixing coefficients quantitatively. To avoid this problem, another line qualitatively models the dependencies by graphs. Recently,  derive a general stability bound for dependent settings characterized by forest complexity of the dependency graph. However, it is hard to use these techniques to derive a better bound than Theorem 3.1 for GDA, which is discussed detailedly in Appendix C.

**Convergence of deep generative models.** In addition to the bound for \(_{}(,_{G}(S))\) with respect to GANs  we used in Theorem 3.3, there are attempts to derive such a bound for diffusion models [73; 74; 75; 76]. Informally, they mainly assume that estimation error of score function is bounded, then with an appropriate choice of step size and iteration number, diffusion models output a distribution which is close to the true distribution. However, it is still unclear how to derive learning guarantees with respect to the train set size \(m_{S}\) directly. Once such learning guarantees are established, we can directly analyze the effect of GDA with diffusion models by Theorem 3.1.

## 6 Impacts and limitations

This paper is mainly a theoretical work and a first step towards understanding the GDA, and it can give some insights to the practice. Theorem 3.1 implies that improving the distribution approximation performance of the generative models is important for the GDA, which motivates people to design better generative models. Besides, it shows that stabilizing the training of the generative models can bring benefits to the GDA, which motivates us to improve the stability of the training of generative models (e.g. GAN). Furthermore, it implies that if we can estimate terms in the bound, then the optimal augmentation size can be approximated. With the emergence of more advanced theory, our results can be extended to other settings (e.g., diffusion models, self-supervised learning) and give more guidance to the practice. One limitation is that our results do not enjoy tightness guarantees, though they benefit from the same nearly optimal guarantee shown by  when \(m_{G}=0\). The derivation of lower bounds can be left to future work.

## 7 Conclusion

In this paper, we attempt to understand modern GDA techniques. To realize this goal, we first establish a general algorithmic stability bound in this non-i.i.d. setting. It suggests that GDA enjoys a faster learning rate when the divergence term \(_{}(,_{G}(S))=o( ((m)_{m},1/))\). Second, We specify the learning guarantee to the bGMM and GANs settings. Theoretical results show that, in both cases, though GDA can not enjoy a faster learning rate, it is effective when terrible overfitting happens, which suggests its promise in learning with limited data. Finally, experimental results support our theoretical conclusions and further show the promise of diffusion models in GDA.