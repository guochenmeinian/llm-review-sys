# Dissect Black Box: Interpreting for Rule-Based Explanations in Unsupervised Anomaly Detection

Yu Zhang\({}^{@sectionsign@sectionsign}\), Ruoyu Li\({}^{@sectionsign}\), Nengwu Wu, Qing Li\({}^{@sectionsign}\), Xinhan Lin\({}^{}\), Yang Hu\({}^{@sectionsign@sectionsign\), Tao Li\({}^{}\), Yong Jiang\({}^{}\)

\({}^{}\)Shanghai Artificial Intelligence Laboratory, China; \({}^{}\)Peng Cheng Laboratory, China

\({}^{@paragraphsign}\)College of Computer Science and Software Engineering, Shenzhen University, China

\({}^{@sectionsign@sectionsign\)Tsinghua University, China; \({}^{@sectionsign@sectionsign\)Tsinghua Shenzhen International Graduate School, China;

\({}^{}\)Hunan University of Science and Technology, China

yu-zhang23@mails.tsinghua.edu.cn; liruoyu0401@outlook.com; wnv@mail.hnust.edu.cn liq@pcl.ac.cn;hu_yang@tsinghua.edu.cn; tlee@hnust.edu.cn; linxinhan@pjlab.org.cn; jiangy@sz.tsinghua.edu.cn;

These authors contributed equally to this work.Corresponding author: Qing Li.

###### Abstract

In high-stakes sectors such as network security, IoT security, accurately distinguishing between normal and anomalous data is critical due to the significant implications for operational success and safety in decision-making. The complexity is exacerbated by the presence of unlabeled data and the opaque nature of black-box anomaly detection models, which obscure the rationale behind their predictions. In this paper, we present a novel method to interpret the decision-making processes of these models, which are essential for detecting malicious activities without labeled attack data. We put forward the Segmentation Clustering Decision Tree (SCD-Tree), designed to dissect and understand the structure of normal data distributions. The SCD-Tree integrates predictions from the anomaly detection model into its splitting criteria, enhancing the clustering process with the model's insights into anomalies. To further refine these segments, the Gaussian Boundary Delineation (GBD) algorithm is employed to define boundaries within each segmented distribution, effectively delineating normal from anomalous data points. At this point, this approach addresses the curse of dimensionality by segmenting high-dimensional data and ensures resilience to data variability and perturbations through flexible boundary fitting. We transform the intricate operations of anomaly detection into an interpretable rule's format, constructing a comprehensive set of rules for understanding. Our method's evaluation on diverse datasets and models demonstrates superior explanation accuracy, fidelity, and robustness over existing method, proving its efficacy in environments where interpretability is paramount.

## 1 Introduction

Anomaly detection, particularly in its unsupervised form, holds significant promise by leveraging advanced machine learning to identify outliers or unusual patterns without labeled datasets  in the ML and DL domains. However, this promise is often hindered by the "black-box" nature of many models, which, while adept at detecting anomalies, provide little insight into the "why" behind their judgments . This opacity poses a substantial barrier to trust between AI systems and human experts, fostering uncertainty and potentially leading to delays or errors, thereby undermining the reliability and efficiency these systems are designed to enhance .

To address the trust requirements in high-stakes sectors like cybersecurity [4; 5], rule-based surrogate models [6; 7] have been proposed to provide interpretability for data by approximating their decision-making processes, such as decision trees [8; 9] and linear models , which are effective in simpler scenarios. However, these surrogate models often struggle to imitate the complexity of black-box models, especially with high-dimensional data, leading to oversimplified explanations that may not faithfully represent the original model's behavior.

**Curse of Dimensionality.** The challenge of scalability in the context of high-dimensional data is a critical concern in anomaly detection [11; 12], where the "curse of dimensionality" can significantly obscure meaningful patterns and exacerbate computational demands. In addition, data that appears to belong to a single category might actually embody several underlying distributions, which may cause model misunderstandings. Higher dimensional spaces are inherently sparse, and the volume of the space grows exponentially with dimension, leading to difficulties in clustering, and discretizing the space and processing it in a distribution space is by far the best solution.

**Inresilliance to data variability.** Resilience to data variability and perturbations is a crucial aspect of robust anomaly detection. While some methods [13; 14] often lack the flexibility to adapt data patterns to the flexible distribution of data, and they determine boundaries that are too "hard" to adequately fit the expanded boundaries to predictions of unknown data, which is essential for maintaining the reliability and robustness of anomaly detection systems in dynamic environments.

Our work revolves around extracting rules that can globally explain the model's decisions which is done through two main contributions: distribution decomposition rules via the Segmentation Clustering Decision Tree (SCD-Tree) and the Gaussian Boundary Delineation (GBD) algorithm. The process begins with the creation of SCD-Tree, an unsupervised tree model that uses the block-box model's predictions as criteria for splitting the data into clusters, each representing a segment of the data distribution. This approach helps manage the curse of dimensionality by breaking down the high-dimensional space into more manageable segments. Within these segmented areas, GBD offers a significant advantage by focusing on the most relevant dimensions to model the decision boundary. This allows the GBD algorithm to simulate boundaries effectively, ensuring resilience against data variability and perturbations, and achieving robust interpretation.

In the experimental phase, we meticulously tested the capabilities of our model, focusing on its ability to autonomously extract rules from black-box anomaly detection models and evaluate its accuracy in detecting anomalies. This work focuses on structured, tabular data, which is prevalent in many high-stakes domains such as network and IoT security. To rigorously assess the effectiveness and reliability of our approach, we conducted extensive comparisons against five established baseline anomaly detection models across four diverse datasets from network security, IoT security, and application security, focusing on structured, tabular data prevalent in these high-stakes domains.. The results demonstrate that our method not only excels in extracting interpretable and precise rules from black-box models but also outperforms in terms of fidelity, robustness, and detection rates (true positive and true negative rates). This performance underscores the utility of our model in enhancing trust in automated systems and confirms its suitability for high-stakes environments where high accuracy in anomaly detection is paramount for effective deployment.

## 2 Related Work

**Unsupervised anomaly detection** does not require labeled data, making it highly adaptable and efficient for detecting novel or unknown types of anomalies in environments, which includes methods such as clustering-based approaches  like K-means [16; 17] and DBSCAN [18; 19], which assume normal data points cluster together while anomalies do not. Isolation Forest [20; 21], stands out by isolating anomalies instead of profiling normal data, providing scalability and efficiency. More recently, neural network-based methods, especially autoencoders [22; 23], have gained prominence due to their ability to learn complex, non-linear data representations. However, they are often criticized for their "black-box" nature, which impedes the interpretability of their decisions .

**Model Interpretability.** Enhancing the transparency of anomaly detection models involves techniques ranging from model-agnostic methods like LIME  and SHAP  to model-specific adjustments that incorporate interpretability directly into the model architecture [27; 28; 29], and decision trees or simpler linear models, are trained to approximate the predictions of the original complex models. These explanatory models using local post-hoc techniques [30; 31] attempt to gen eralize across different models by approximating the decision function of the black-box model with inherently interpretable structures. However, the ability of these explanatory models to generalize effectively across different types of black-box models can vary considerably. The complexity of the black-box model's structure and the data it handles can limit the fidelity of such explanations, leading to oversimplifications that fail to capture crucial nuances in decision-making.

In addition, these models often assume linear relationships between features [32; 33], which is rarely the case in complex datasets with non-linear interactions, leading them to potentially oversimplify data complexities and result in incomplete or inaccurate interpretations . They are fundamentally simplifications of the original models, and as such, they may not capture all the nuances of complex decision boundaries effectively, which may lead to a loss of fidelity, where the surrogate model's predictions do not consistently align with those of the black-box model .

**Curse of dimensionality.** The "curse of dimensionality" in high-dimensional data significantly complicates anomaly detection by obscuring meaningful patterns and relationships. Recent research has proposed various strategies to mitigate its effects, including feature selection [36; 37; 38] and extraction  techniques that identify the most informative features of the dataset. In addition, various learning techniques such as t-SNE and UMAP have been used to visualize and understand complex data structures. While these methods are invaluable for simplifying high-dimensional data into more manageable forms, they can sometimes strip away nuances of the original data structure. This oversimplification can result in the loss of information that is critical to accurately identifying anomalies, as certain anomalies may only be detectable in the original high-dimensional space.

**Dynamic Updateability.** Additionally, these surrogate models [13; 40; 14] often assume static data distributions and fail to adapt to the dynamic nature of real-world data, where new anomaly patterns can emerge over time. This assumption limits their effectiveness in continuously evolving environments, where the ability to adapt and update explanations in response to new data is crucial.

In summary, despite black-box models offer significant potential in unsupervised anomaly detection, their application is hindered by a lack of interpretability, reliance on oversimplified surrogate models, and challenges in handling dynamic, high-dimensional data. Addressing these limitations necessitates the development of advanced explanation methodologies that maintain robustness to original models' decisions while providing clear, comprehensive, and adaptable insights into their operational logic.

## 3 Overview

### Problem Definition

**Definition 1** (Unsupervised Anomaly Detection Framework): _Let \(^{d}\) assume unlabeled data sampled from a stationary distribution \(\), representing a \(d\)-dimensional feature space. A vector \(\) represents a feature vector with components \(=(x_{1},,x_{d})\). The detection model is tasked with estimating a density function \(()\), which approximates the true underlying distribution \(p()\). Anomalies are detected based on the density threshold \(\), defined as: \(p()>``Anomaly''\), which can identify data points that deviate significantly from established patterns of 'normality'._

_Threshold \(\)(>0) serves as the critical boundary between normal and abnormal data, deliberately set above zero to account for the inherent false positive rates--often minimized but inevitable in anomaly detection models as discussed in prevailing studies [41; 42; 43]. This setup acknowledges occasional data contamination and errors, ensuring the model's robustness to a small proportion of noisy data without relying on ground truth labels for training._

**Definition 2** (Rule-Based Interpretative Model): _To elucidate the decision-making process of the anomaly detection model, we construct a rule-based interpretative model. This model partitions the data space into a series of interpretable regions using a set of logical rules._

**Rule Construction: _A rule set \(=R_{1},R_{2},,R_{k}\) is formed by a conjunction of linear inequalities where each rule \(R\) captures specific characteristics of the data distribution as understood by surrogate model \(f\). Each rule \(R\) is a logical conjunction of conditions on the feature dimensions, defined as \(R=_{i=1}^{d}(s_{i} x_{i}_{i}_{i})\), where \(_{i},>\) is relational operator, comparing the scaled feature value \(s_{i} x_{i}\) to the threshold \(_{i}\). The rule is satisfied if all inequalities hold true for every dimension._

**Surrogate Model Definition:** To evaluate a data point as anomalous if it does not satisfy any rule within \(\), the surrogate model \(h_{}()\) is constructed from the rule set \(\): \(h_{}()=-_{R}(x R)\). This formulation enables the surrogate model to identify anomalies by their failure to conform to any of the normal profiles described by \(\).

**Our goal:** To ensure that the rule set \(\) extracted from the anomaly detection model accurately mirrors the behavior of the underlying model, with an emphasis on the true positive rate and true negative rate. We refine \(\) to minimize the divergence between the predictions of the anomaly detection model and the classifications made by \(h_{}()\). This is formalized as follows:

\[*{arg\,min}_{}(,, )=*{arg\,min}_{i=1}^{k}_{i|I((x_{i})<)- I(h_{}(x_{i})=^{}Anomaly^{})|}\] (1)

where \(I\) denotes the indicator function, and \(\) measures the mismatch between model predictions and rule-based classifications over the entire data space.

### Methodology Overview

In addressing the intrinsic complexities of unsupervised anomaly detection, especially in handling high-dimensional, multimodal data distributions, our methodology embraces a divide-and-conquer strategy, tailored to dissect and understand these distributions through a robust, structured approach. Leveraging the capabilities of the Segmentation Clustering Decision Tree (Section 4) and Gaussian Boundary Delineation (Section 5), our methodology evolves to refine boundaries.

#### 3.2.1 Multimodal Data and Initial Segmentation

Recognizing the multimodal nature of typical datasets in applications such as network security and healthcare - where data points are derived from various normal operations that inherently form distinct clusters in the feature space, which SCD-Tree achieves the strategic segmentation:

\[_{k=1}^{K}*{arg\,min}_{R_{k}}[_{_{k}}(R_{k},f,)+_{ _{k}}(R_{k},f,)],R_{k}= (R_{k}^{I},R_{k}^{E})\] (2)

Here, \(_{k}\) denotes a hypercube enclosing the \(i^{th}\) modal cluster's data samples, facilitating initial data categorization and minimizing the loss \(_{}(,f,)\) for in-distribution points.

#### 3.2.2 Boundary Delineation

For each \(i\) using GBD based on subspaces to cover maximal normal data while excluding outliers. This step involves dynamically adjusting the decision boundaries within each identified segment using Gaussian Processes to model the decision boundaries accurately. The Gaussian Processes provide a probabilistic framework that not only defines the boundaries but also quantifies the uncertainty in these boundaries, thereby enhancing the model's interpretative power.

Finally, we get a comprehensive rule set [\(=_{i=1}^{m}(H_{i},_{i} )\)] by synthesizing the refined rules from each segment that globally approximates the behavior of the original anomaly detection model across the entire dataset. This synthesized rule set not only ensures high fidelity in anomaly detection but also facilitates a deeper understanding of the model's decision-making process, crucial for trust and transparency in critical applications.

### Anomaly detection pipline

As Figure 1 shows, The initial datasets are transformed through normalization and scaling processes to ensure uniformity and mitigate the influence of outlier values.

**Unsupervised Tree Segmentation:** The SCD-Tree utilizes original detection model outputs to guide its data segmentation process. By integrating anomaly scores (e.g., MSE, Probability) directly into the tree's branching logic, the SCD-Tree adapts its segmentation boundaries dynamically, reflectingsubtle shifts in data patterns and anomaly distributions. This integration allows the SCD-Tree to partition the dataset into clusters that are homogeneously normal, yet distinct from one another based on the learned anomaly characteristics.

**Gaussian Boundary Delineation:** Following the data segmentation by the SCD-Tree, the Gaussian Boundary Delineation is employed to define and refine the decision boundaries between identified clusters. This approach uses Gaussian Processes to achieve a fine-grained mapping of decision boundaries, accommodating the non-linear and complex nature of the data structures encountered.

**Rule Extraction and Interpretation:** Once the boundaries are established, the GBD algorithm translates these complex mathematical models into a set of clear, interpretable rules. Each rule delineates conditions under which data points are considered normal, in the subsequent judgment, we only need to judge whether the data meets the RULE criteria for normal data based on the characteristics of the data, if it meets it is judged to be normal data, otherwise it is considered to be abnormal data. This offers actionable insights into the underlying decision-making process of the anomaly detection model.

**Proposition**.: _Let \(^{d}\) be a dataset sampled from a stationary distribution \(\), and let \(f:\{0,1\}\) be an unsupervised anomaly detection model. There exists a rule-based surrogate model \(h_{}()\) derived from \(f\) such that \(h_{}\) maintains high fidelity to \(f\), achieving high true negative rate (TNR) and true positive rate (TPR)._

## 4 Segmentation Clustering Decision Tree

In the quest to unravel the complex decision-making mechanisms of unsupervised anomaly detection models, our methodology adopts a sophisticated, dual-faceted approach that systematically dissects and models the data distribution \(\). Recognizing the inherent multimodality and high dimensionality of typical datasets in domains like network security, IoT security, we commence with the Segmentation Clustering Decision Tree to partition the feature space into distinct subspaces.

The foundational principle of the SCD-Tree is based on the hypothesis that data points with similar anomaly scores likely share the same operational conditions or states. This hypothesis is formalized

Figure 1: Integrated Anomaly Detection and Interpretation Pipeline Using SCD-Tree and GBD

in the tree's splitting criteria, which aim to minimize within-cluster variance of anomaly scores while maximizing between-cluster differences, thus ensuring each cluster is as homogeneous as possible.

Based on this, SCD-Tree extends the CART decision tree  by integrating black-model-based predictions into its decision-making process. Unlike traditional decision trees which rely on labeled data for node splitting, the SCD-Tree harnesses the original model outputs and threshold to segment data into coherent subsets that reflect underlying distribution patterns.

**Node Splitting.** For each node within SCD-Tree, the splitting process is governed by the distribution of anomaly detection model outputs, \(f()\) across data samples. A node \(\) splits based on the criterion that maximizes the difference in model output distributions between subsets, formalized as:

\[s=*{arg\,max}_{s}H()-_{l}|}{||}H(_ {l})-_{r}|}{||}H(_{r})\] (3)

where \(s=(i,_{i})\) is the splitting condition, \(_{i}\) being the threshold for feature \(i\), and \(H\) represents a homogeneity score based on the output of the anomaly detection model:\(H=2p(1-p)\), with \(p_{k}\) as the proportion of samples in node \(\) that fall into the \(k\)-th output category of the anomaly model.

**Termination Criteria.** Splitting continues recursively until any of the following conditions is met: i) the node \(\) contains only one sample, ii) the variance in anomaly detection scores within a node is less than \(\), or iii) the tree reaches a predetermined maximum depth \(\).

**Distribution Decomposition Rule Extraction.** Upon the completion of the SCD-Tree training, the resulting structure facilitates a granular understanding of the data through its segmented distributions, each represented by a leaf node. The transformation of these segments into a set of operational rules provides a systematic method for categorizing new data points based on the learned segments.

For each leaf node, the sequential decisions from the root compile into a cohesive rule set, outlining the conditions for data points within the corresponding segment:

\[R_{k}=_{h=1}^{}\{x_{f_{h}}_{h}_{h}\}\] (4)

where \(R_{k}\) denotes the rule set corresponding to the \(k\)-th segment. Here, \(\) is the depth of the leaf node, indicating the number of conditions (or splits) from the root to the leaf. The variable \(f_{h}\) identifies the feature upon which the split is made at the \(h\)-th level of the tree, \(_{h}\) is the threshold value for that split, and \(_{h}\) represents the relational operator (either "\(\)" for a left split or '\(>\)' for a right split).

The culmination of the SCD-Tree training results in a multifaceted representation of the data's structure, captured by each leaf node's unique profile, and traversing from the root to a specific leaf encapsulates a precise rule pathway that partitions the feature space into distinct subspaces \(R_{k}\).

## 5 Gaussian Process for Boundary Delineation

Following the creation of these distinct subspaces \(R_{k}\) through the SCD-Tree, we employ _Gaussian Process for Boundary Delineation_ within each subspace to meticulously define and refine the decision boundaries, capturing the subtle variations and dynamics of the data to enhance the precision of anomaly detection.

**Boundary Estimation Process.** Within the Gaussian Process (GP) framework, consider a set of data points \(X_{}\) classified as normal by the SCD-Tree, along with their corresponding scores \(s\). The binary classification outputs \(y\) are determined by comparing these scores to a predefined threshold \(\). Specifically, \(y\) is defined as \(y_{i}=1\) if \(s_{i}\) (indicating normality) and \(y_{i}=0\) if \(s_{i}>\) (indicating anomaly). This classification serves as input to the GP, which provides a predictive distribution for any new point \(^{*}\) based on these inputs:

\[p(f(^{*})|_{},,^{*})=((^{*}),^{2}(^{*}))\] (5)

where \((^{*})\) and \(^{2}(^{*})\) represent the mean and variance of the predictive distribution, respectively, and \(f()(m(),k(, ^{}))\). This probabilistic framework facilitates dynamic assessment of whether new data points conform to the patterns of normality or are indicative of anomalies.

The mean \((^{*})\) and variance \(^{2}(^{*})\) of this distribution are given by:\[(^{*})=^{T}[+_{n}^{2}]^{-1} \] (6)

\[^{2}(^{*})=k(^{*},^{*})-^{T}[ +_{n}^{2}]^{-1}\]

where \(\) is the vector of covariances between \(^{*}\) and each point in \(_{}\), \(\) is the covariance matrix for \(_{}\), which is computed as \(k(x,x^{*})=^{2}exp(-\|^{2}}{2l^{2}})\), and \(_{n}^{2}\) is the noise variance, capturing inherent data uncertainties.

**Defining the Decision Boundaries.** The essential step in boundary delineation is to identify the set \(\) where \(()\) surpasses a predefined threshold \(\) (indicating high confidence in normality) and \(()\) is minimal (indicating low uncertainty). These criteria ensure robust and precise boundary definition:

\[=\{^{d}:()>( )<\}\] (7)

Once \(()\) and \(()\) are obtained, we use the data points \(X_{k}\) within the subspace \(D_{k}\) and the extended set of data points \(X_{k}^{}\) sampled around it to capture boundary variations. The final boundary can be obtained from the following equation:

\[_{k}=[min((X_{k})-^{2}(X_{k})),max((X_{k}^{{}^{}} )+^{2}(X_{k}^{{}^{}}))]\] (8)

**Rule Acquisition and Interpretation.** For each dimension \(j\) of the feature space, a rule is derived based on these boundaries: \(R_{j}:_{,j} x_{j}_{,j}\), where \(_{,j}\) and \(_{,j}\) are the lower and upper bounds of the decision boundary for feature \(j\), computed from the GP outputs. Finally, the rules \(R_{j}\) are then synthesized into a comprehensive rule set \(\), defined as: \(=_{j=1}^{d}R_{j}\), which globally approximates the behavior of the original anomaly detection model across the entire dataset. This rule set classifies a data point \(\) as normal if it satisfies all individual feature rules, thus aligning with the patterns of normality as modeled by the Gaussian Processes within their respective subspaces.

**Rule Refinement.** To ensure that the rules are robust and reflect the subtle nuances of the data, they are continuously refined based on feedback from ongoing anomaly detection operations. This dynamic refinement process utilizes new data to adjust the thresholds \(_{,j}\) and \(_{,j}\), thereby adapting the rule set \(\) to evolving data conditions and anomaly patterns.

## 6 Evaluation

### Experimental Setup

**Datasets.** We employ four distinct datasets to evaluate our method across various security-related domains. These datasets include Malicious and Benign Webpages  for web security, KDDCup  for classic network intrusion scenarios , CIC-IDS  for modern network attacks, and TON-IoT , which integrates IoT and traditional network data.

These tabular format datasets are systematically partitioned into training, validation, and testing segments following an 8:1:1 ratio split. For the calibration of our anomaly detection models' hyperparameters, only normal instances from these datasets are utilized. The performance metrics, specifically the accuracy for each model, are comprehensively documented in Table 1.

**Black Models.** For model comparison, we utilize four established unsupervised models: Autoencoders (AE ) and Variational Autoencoders (VAE ) detect anomalies through reconstruction errors; One-Class SVM (OCSVM ) isolates normal data in feature space; and Isolation Forest (IForest ) efficiently identifies outliers. These models facilitate a robust assessment of our method's effectiveness across diverse data scenarios. In addition to these classical methods, more advanced models such as Variational Recurrent Autoencoder (VRAE ), Deep Autoencoding Gaussian Mixture Model (DAGMM ) are evaluated. These advanced models facilitate a robust

   No. & Dataset & \#Domain & \#Features & \#Normal & \#Attack & AE & VAE & OCSVM & iForest \\ 
1 & Webpages & Web Security & 10 & 98\% & 25 & 0.9909 & 0.9975 & 0.998 & 0.9925 \\
2 & TON-IoT & IoT Security & 30 & 25.71\% & 74.29\% & 0.9839 & 0.9886 & 0.9957 & 0.9943 \\
3 & Kddcw99 & Cybersecurity & 41 & 19.86\% & 80.14\% & 0.9895 & 0.944 & 0.9415 & 0.9905 \\
4 & CIC-IDS & Cybersecurity & 80 & 70.45\% & 29.55\% & 0.9438 & 0.9251 & 0.9706 & 0.9972 \\   

Table 1: The accuracy for four anomaly detection models applied to datasets in security.

assessment of our method's effectiveness across diverse data scenarios, demonstrating its applicability not only to traditional but also state-of-the-art techniques in anomaly detection.

**Baseline Models.** We assess the effectiveness of our approach against several established explanation methods serving as baselines. These include direct rule extraction from unsupervised anomaly detection models (UAD) , knowledge distillation techniques (KD)  that simplify complex models, and global explanation methods such as greedy decision trees (EGDT) , which approximate black-box model decision processes. We also compare with Local Interpretable Model-agnostic Explanations (LIME) , providing local insights aggregated into global interpretations, and Trustee , which synthesizes local explanations into a cohesive global understanding.

**Metrics.** Our evaluation employs a suite of metrics inspired by : Fidelity, Robustness, both True Positive Rate and True Negative Rate. Their meanings and specific calculations are written in appendix B.4.1. These metrics provide a comprehensive framework for comparing the explanatory power and reliability of different approaches, ensuring that our findings are robust and applicable to real-world anomaly detection scenarios.

### Model Interpreting Rationale

To demonstrate the interpretability and effectiveness of our proposed method, we examine rules extracted from a well-trained VAE model applied to different datasets, focusing on Denial of Service (DoS) attacks. As Table 2 indicates, the rule "\(ps\_fwd\_var>101.68\)" with an attack value of 57.33 indicates that normal traffic has higher variance in forward packet sizes compared to DoS traffic, which uses consistent sizes to overwhelm targets. Similarly, "\(0.949<iat\_max 7.278\)" with an attack value of 0.00063 shows very short intervals between packets, characteristic of DoS attacks. These rules encapsulate DoS behaviors, providing a clear rationale for the model's decisions. Such interpretable rules enhance model transparency, enabling security professionals to understand and respond to cyber threats effectively. This interpretability is crucial in high-stakes environments, ensuring trust and facilitating timely, accurate threat detection.

### Precision in Interpretative Output

In our comprehensive assessment, illustrated in Table 1, we employed four established anomaly detection models--Forest, OCSVM, AE, and VAE--as pre-configured "black models" for our SCD-Tree, and rigorously tested them across four distinct datasets from different security domains. The results demonstrate that our model exhibits robust performance and high effectiveness in identifying anomalies across all domains, with nearly all robustness (RB) and fidelity (FD) metrics surpassing 90%. Characterized by strong discriminative power and fidelity, our findings underscore our model's adaptability and confirm its suitability for diverse anomaly detection tasks in various contexts.

In Tables 3, we evaluate our model with five baselines, it consistently outperforms established baseline methods across a variety of metrics: it achieves True Positive Rates (TPR) ranging from 91.5% to 100%, and True Negative Rates (TNR) as high as 99.62%, showcasing its exceptional capability in accurately identifying both normal and anomalous instances. Moreover, the fidelity (FD) and robustness (RB) metrics impressively exceed 90% in most scenarios, with perfect scores (100%) observed in settings involving the KddCup99 and Web datasets, emphasizing the model's reliable interpretative output under varying operational conditions, proving its resilience to data variability and perturbations. This comprehensive performance underscores the SCD-Tree's efficacy and adaptability,

   Attack & Rules of Normality & Attack Value & Feature Meaning & Human Understanding \\   & \(ps\_fwd\_var>101.68\) & 57.33 & Variance in forward packet size & DoS attacks use consistent small packets at high rates. \\  & \(0.949 iat\_max 7.278\) & 0.0605 & Maximum inter-arrival time & They also show minimal intervals between packets \\  & \(fwd\_count>124.371\) & 0.00126 & Forward packet count & and high packet counts to overwhelm the network. \\   & \(count>92.529\) & 12 & IP packet count per connection & MITM attacks often increase packet count and show \\  & \(ps\_var>67248.034\) & 82.0 & Variance of IP packet sizes & high variance in packet sizes due to manipulation. \\   & \(iat\_hard\_max 1.1139\) & 0.1 & Maximum inter-arrival time & Ransomware attacks exhibit irregular \\  & \(iat\_bwd\_min 0.2062\) & 0.37 & Minimum inter-arrival time & traffic patterns and rapid bursts of communication. \\   & \(url\_cluster 1.1038\) & 2.0 & URL grouping & Pishing websites often group similar URLs \\  & \(htps 0.797\) & 1.0 & Uses HTTPS & and one HTTPS to appear score and deceive users. \\   

Table 2: Examples of Explanation for Different Types of Cyber Attacks

[MISSING_PAGE_FAIL:9]

Additionally, GBD uses Gaussian Processes, which have a cubic complexity \(O(k n^{3})\) due to matrix inversion, with \(n\) indicating the data points per segment. Although this complexity might seem high, it's manageable since GP only operates within defined subspaces(\(_{k}\)) post-SCD-Tree segmentation. Post-training, anomaly detection is conducted using a rule set with a fixed complexity of \(O(|C| d)\), where \(|C|\) is the rule count and \(d\) is the feature size, optimizing both speed and resource in practice.

## 7 Conclusion and Future Work

In addressing the global interpretability challenges of unsupervised anomaly detection, this paper integrates a novel Gaussian Boundary Delineation with Segmentation Clustering Decision Tree to refine and explain the decision-making process of black-box models. This model provides a probabilistic assessment of boundary points, enhancing the interpretative fidelity by quantifying the uncertainty in boundary delineation. The culmination of this process synthesizes a comprehensive rule set, offering a granular yet global perspective on the model's decision-making process, thereby enhancing transparency and trust in automated anomaly detection systems.

Building on the foundational work in model interpretability, future research should pivot towards developing adaptive algorithms capable of dynamically refining and correcting decision processes in real-time, which reduce error rates in black-box models by continuously learning from new data. Additionally, integrating interpretable anomaly detection methods into distributed edge systems, promises to decentralize and accelerate decision-making processes. This could be particularly transformative in sectors where timely, accurate decisions are crucial. Exploring the synergy between lightweight, interpretable models and existing infrastructure could also pave the way for more robust and scalable anomaly detection systems that are both efficient and easier to audit.