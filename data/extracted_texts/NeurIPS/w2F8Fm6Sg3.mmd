# Balanced Training for Sparse GANs

Yite Wang\({}^{1}\), Jing Wu\({}^{1}\), Naira Hovakimyan\({}^{1}\), Ruoyu Sun\({}^{2,3}\)

\({}^{1}\)University of Illinois Urbana-Champaign, USA

\({}^{2}\)School of Data Science, The Chinese University of Hong Kong, Shenzhen, China

\({}^{3}\)Shenzhen International Center for Industrial and Applied Mathematics,

Shenzhen Research Institute of Big Data

{yitew2,jingwu6,nhovakim}@illinois.edu, sunruoyu@cuhk.edu.cn

Corresponding author.Equal contribution

###### Abstract

Over the past few years, there has been growing interest in developing larger and deeper neural networks, including deep generative models like generative adversarial networks (GANs). However, GANs typically come with high computational complexity, leading researchers to explore methods for reducing the training and inference costs. One such approach gaining popularity in supervised learning is dynamic sparse training (DST), which maintains good performance while enjoying excellent training efficiency. Despite its potential benefits, applying DST to GANs presents challenges due to the adversarial nature of the training process. In this paper, we propose a novel metric called the balance ratio (BR) to study the balance between the sparse generator and discriminator. We also introduce a new method called balanced dynamic sparse training (ADAPT), which seeks to control the BR during GAN training to achieve a good trade-off between performance and computational cost. Our proposed method shows promising results on multiple datasets, demonstrating its effectiveness. Our code is available at https://github.com/YiteWang/ADAPT.

## 1 Introduction

Generative adversarial networks (GANs)  are a type of generative model that has gained significant attention in recent years due to their impressive performance in image-generation tasks. However, the mainstream models in GANs are known to be computationally intensive, making them challenging to train in resource-constrained settings. Therefore, it is crucial to develop methods that can effectively reduce the computational cost of training GANs while maintaining their performance, making GANs more practical and applicable in real-world scenarios.

Neural network pruning has recently emerged as a powerful tool to reduce the training and inference costs of DNNs for supervised learning. There are mainly three genres of pruning methods, namely pruning-at-initialization, pruning-during-training, and post-hoc pruning methods. Post-hoc pruning  can date back to the 1980s, which was first introduced for reducing inference time and memory requirements for efficient deployment; hence does not align with our purpose of efficient training. Later, pruning-at-initialization  and pruning-during-training methods  were introduced to circumvent the need to fully train the dense networks. However, early pruning-during-training algorithms  do not bring much training efficiency compared to post-hoc pruning, while pruning-at-initialization methods usually suffer from significant performance drop . Recently, advances in dynamic sparse training (DST)  for the first time show that pruning-during-training methods can have comparable training FLOPs as pruning-at-initialization methodswhile having competing performance to post-hoc pruning. Therefore, applying DST on GANs seems to be a promising choice.

Although DST has attained remarkable achievements in supervised learning, the application of DST on GANs is not successful due to newly emerging challenges. One challenge is keeping the generator and the discriminator balanced. In particular, using overly strong discriminators can lead to overfitting, while weaker discriminators may fail to effectively prevent mode collapse [3; 4]. Hence, balancing the sparse generator and the (possibly) sparse discriminator throughout training is even more difficult. To mitigate the unbalance issue, a recent work STU-GAN  proposes to apply DST directly to the generator. However, we find empirically that such an algorithm is likely to fail when the generator is already more powerful than the discriminator. Consequently, it remains unclear how to conduct balanced dynamic sparse training for GANs.

To this end, we propose a metric called balance ratio (BR), which measures the degree of balance of the two components, to study sparse GAN training. We find that BR is useful in (1) understanding the interaction between the discriminator and the generator, (2) identifying the cause of a certain training failure/collapse [7; 8], and (3) helping stabilize sparse GAN training as an indicator. To our best knowledge, this is the first study to quantify the unbalance of sparse GANs and may even provide new insights into dense GAN training.

Furthermore, using BR as an indicator, we propose bAlanced DynAmic sParse Training (ADAPT) to adjust the density and the connections of the discriminator automatically during training.

Our main contributions are summarized below:

* We introduce a novel quantity named balance ratio to study the degree of balance in sparse GAN training.
* We find empirically that the balance ratio is problematic in certain practical training scenarios and that existing methods are inadequate for resolving this issue.
* We propose ADAPT, which makes real-time monitoring of the balance ratio. By dynamically adjusting the discriminator, ADAPT enables effective control of the balance ratio throughout training. Empirically, ADAPT achieves a good trade-off between performance and computational cost on several datasets.

## 2 Related works

### Neural network pruning

In deep learning, efficiency is achieved through several methods. This paper primarily focuses on model training and inference efficiency, which is different from techniques for data efficiency [83; 85; 86]. These include neural architecture search (NAS) [80; 49] to discover optimal network structures, quantization [31; 67] for computational efficacy, knowledge distillation  to leverage the knowledge of larger models for smaller counterparts, and neural network pruning to remove unnecessary connections. Among these, neural network pruning is the focal point of our research. More specifically, we narrow our focus on unstructured pruning [25; 17], where individual weight is the finest resolution. This contracts with structured pruning [56; 59; 57; 30] where entire neurons or channels are pruned.

**Post-hoc pruning.** Post-hoc pruning method prunes weights of a fully-trained neural network. It usually requires high computational costs due to the multiple rounds of the train-prune-retrain procedure [25; 68]. Some use specific criteria [42; 26; 25; 23; 15; 12; 91; 63] to remove weights, while others perform extra optimization iterations . Post-hoc pruning was initially proposed to reduce the inference time, while lottery ticket works [17; 68] aimed to mine trainable sub-networks.

**Pruning-at-initialization methods.** SNIP  is one of the pioneering works that aim to find trainable sub-networks without any training. Some follow-up works [78; 75; 13; 65; 1] aim to propose different metrics to prune networks at initialization. Among them, Synflow , SPP , and FORCE  try to address the problem of layer collapse during pruning. NTT , PHEW , and NTK-SAP  draw inspiration from neural tangent kernel theory.

**Pruning-during-training methods.** Another genre of pruning algorithms prunes or adjusts DNNs throughout training. Early works add explicit \(_{0}\) or \(_{1}\) regularization terms to encourage a sparse solution, hence mitigating performance drop incurred by post-hoc pruning. Later works learn the subnetworks structures through projected gradient descent  or trainable masks [73; 88; 35; 41; 50; 71]. However, these pruning-during-training methods often do not introduce memory sparsity during training. As a remedy, DST methods [5; 62; 64; 14; 16; 51; 52; 54; 21] were introduced to train the neural networks under a given parameter budget while allowing mask change during training.

### Generative adversarial networks

**Generative adversarial networks (GANs).** GANs  have drawn considerable attention and have been widely investigated for years. Deep convolutional GANs  replace fully-connected layers in the generator and the discriminator. Follow-up works [22; 36; 7; 92] employed more advanced methods to improve the fidelity of generated samples. After that, several novel loss functions [69; 60; 2; 22; 74], normalization and regularization methods [61; 76; 87] were proposed to stabilize the adversarial training. Besides the efforts devoted to training GANs, image-to-image translation is also extensively explored [96; 95; 10; 38; 43; 81].

**GAN balance.** Addressing the balance between the generator and discriminator in GAN training has been the focus of various works. However, directly applying existing methods to sparse GAN training poses challenges. For instance, [3; 4] offer theoretical analyses on the issue of imbalance but may have limited practical benefits, e.g., they require training multiple generators and discriminators. Empirically, BEGAN  proposes to use proportional control theory to maintain a hyper-parameter \(\|G(z)-D(G(z))|^{n}\}\), but it is only applicable when the discriminator is an auto-encoder. Unbalanced GAN  pretrains a VAE to initialize the generator, which may only address the unbalance near initialization. GCC  considers the balance during GAN compression, while its criterion requires a trained (dense) GAN, which is not given in the DST setting. Finally, STU-GAN  proposes to use DST to address the unbalance issues but may fail under certain conditions, as demonstrated in our experiments.

**GAN compression and pruning.** One of the promising ways is based on neural architecture search and distillation algorithm [47; 19; 29]. Another part of the work applied pruning-based methods for generator compression [72; 90; 33]. Later, works by  presented a unified framework by combing the methods mentioned above. Nevertheless, they only focus on the pruning of generators, thus potentially posing a negative influence on Nash Equilibrium between generators and discriminators. GCC  compresses both components of GANs by letting the student GANs also learn the losses. Another line of work [34; 9; 8] tries to test the existence of lottery tickets in GANs. To the best of our knowledge, STU-GAN  is the only work that tries to directly train sparse GANs from scratch.

## 3 Preliminary and setups

Generative adversarial networks (GANs) have two fundamental components, a generator \(G(;_{G})\) and a discriminator \(D(;_{D})\). Specifically, the generator maps a sampled noise \(\) from a multivariate normal distribution \(p()\) into a fake image to cheat the discriminator. In contrast, the discriminator distinguishes the generator's output and the real images \(_{r}\) from the distribution \(p_{}(_{r})\).

Formally, the optimization objective of the two-player game defined in GANs can be generally defined as follows:

\[_{D}(_{D},_{G})= _{_{r} p_{}}[f_{1}(D(_{ r};_{D}))]+_{ p}[f_{2}(D(G(;_{G})))]\] (1) \[_{G}(_{G})= _{ p}[g_{1}(D(G(;_{G}))) ].\] (2)

To be more specific, different losses can be used, including the loss in the original JS-GAN  where \(f_{1}(x)=-(x)\), \(f_{2}(x)=-g_{1}(x)=-(1-x)\); Wasserstein loss  where \(f_{1}(x)=-f_{2}(x)=g_{1}(x)=-x\); and hinge loss  where \(f_{1}(x)=(0,1-x)\), \(f_{2}(x)=(0,1+x)\), and \(g_{1}(x)=-x\). The two components are optimized alternately to achieve the Nash equilibrium.

**GAN sparse training.** In this work, we are interested in sparse training for GANs. In particular, the objective of sparse GAN training can be formulated as follows:

\[_{D}^{*} =_{_{D}}_{D}(_{D}_{ D},_{G}_{G})\] \[_{G}^{*} =_{_{G}}_{G}(_{G} _{G})\] \[_{D}\{0,1\}^{|_{D}|}, _{G}\{0,1\}^{|_{G}|},\|_{D}\|_{0}/| _{D}| d_{D},\|_{G}\|_{0}/|_{G}| d_{G},\]

where \(\) is the Hadamard product; \(_{D}^{*}\), \(_{D}\), \(|_{D}|\), \(d_{D}\) are the sparse solution, mask, number of parameters, and target density for the discriminator, respectively. The corresponding variables for the generator are denoted with subscript \(G\). For pruning-at-initialization methods, masks \(\) are determined before training, whereas \(\) are dynamically adjusted for dynamic sparse training (DST) methods.

**Dynamic sparse training (DST).** DST methods [62; 16] usually start with a sparse network parameterized by \(\) with randomly initialized mask \(\). After a constant time interval \( T\), it updates mask \(\) by removing a fraction of connections and activating new ones with a certain criterion. The total number of active parameters \(\|\|_{0}\) is hence kept under a certain threshold \(d||\). Please see Appendix B for more details.

## 4 Motivating observations: The unbalance in sparse GAN training

As discussed in section 1, it is essential to maintain the balance of generator and discriminator during GAN training. As strong discriminators may lead to over-fitting, whereas weak discriminators may be unable to detect mode collapse. When it comes to sparse GAN training, the consequences caused by the unbalance can be further amplified. For example, sparsifying a weak generator while keeping the discriminator unmodified may lead to an even more unbalanced worst-case scenario.

To support our claim, we conduct experiments with SNGAN  on the CIFAR-10 dataset. We consider the following sparse training algorithms:

**Static sparse training (STATIC).** For STATIC, layer-wise sparsity ratio and masks \(_{G},_{D}\) are fixed throughout the training.

**Single dynamic sparse training (SDST).** SDST is a direct application of the DST method on GANs where only the generator dynamically adjusts masks during the training. We name such method SDST as only one component of the GAN, i.e., the generator, is dynamic. Furthermore, we call the variant which grows connections based on gradients magnitude as \(\)SDST-RigL , and randomly as \(\)SDST-SET . Note that STU-GAN  is almost identical to \(\)SDST-RigL with EMA  tailored for DST. We do not consider naively applying DST on both generators and discriminators, as in STU-GAN, it is empirically shown that simply adjusting both components generates worse performance with more severe training instability.2

We test the considered algorithms with \(d_{G}\{10\%,20\%,30\%,50\%\}\) and \(d_{D}\{10\%,20\%,30\%,\)\(50\%,100\%\}\). More experiment details can be found at Appendix A and Appendix B.

Figure 1: FID (\(\)) comparison of SDST against STATIC sparse training for SNGAN on CIFAR-10 with different sparsity ratio combinations. The shaded areas denote the standard deviation.

### Key observations

We report the results in Figure 1 and summarize our critical findings as follows:

**Observation 1: Neither strong nor weak sparse discriminators can provide satisfactory results.** The phenomenon is most noticeable when \(d_{G}=10\%\), where the FID initially decreases but then increases. The reasons may be as follows: (1) Overly weak discriminators may cause training collapse as they cannot provide useful information to the generator, resulting in a sudden increase in FID at the early stage of sparse GAN training. (2) Overly strong discriminators may not yield good FID results because they learn too quickly, not allowing the generator to keep up. Hence, to ensure a balanced training of GAN for sparse training methods, it is crucial to find an appropriate sparsity ratio for the discriminator.

**Observation 2: SDST is unable to give stable performance boost compared to the STATIC baseline.** Another critical observation is that SDST is better than STATIC only when the discriminator is strong enough. More specifically, for all selected discriminator density ratios, SDST method is not better than STATIC when using a small discriminator density (\(d_{D}=10\%\)). On the contrary, for the cases where \(d_{D}>d_{G}\), we generally see a significant performance boost brought by SDST.

## 5 Balance ratio: Towards quantifying the unbalance in sparse GAN training

### Formulation of the balance ratio

To gain a deeper understanding of the phenomenon observed in the previous section, and to better monitor and control the degree of unbalance in sparse GANs, we introduce a novel quantity called the balance ratio (BR). This quantity is defined as follows.

At each training iteration, we draw random noise \(\) from a multivariate normal distribution and real images \(_{r}\) from the training set. We denote the discriminator after gradient descent update as \(D(;_{D})\). We denote generator before and after gradient descent training as \(G^{}(;_{G})\) and

Figure 2: BR comparison of SDST against STATIC sparse training for SNGAN on CIFAR-10 with different sparsity ratio combinations.

\(G^{}(;_{G}^{})\), respectively. Then the balance ratio is defined as:

\[=_{ p}[D(G^{}())-D(G^{ }())]}{_{_{r} p_{}}[D(_{r})]-_{ p}[D(G^{}())]}=.\] (3)

Precisely, BR measures how much improvement the generator can achieve in the scale measured by the discriminator for a specific random noise \(\). When BR is too small (e.g., BR\(<30\%\)), the updated generator is too weak to trick the discriminator, as the generated images are still considered fake. Similarly, for the case where BR is too large (e.g., BR\(>80\%\)), the discriminator is considered too weak hence it may not provide useful information to the generator. We also illustrate BR in Figure 3.

### Understanding observation 1: Analysing GAN balance with the balance ratio

We visualize the BR evolution throughout the training for the experiments in section 4 to show the effectiveness of BR in quantifying the balance of sparse GANs. We show the results in Figure 2.

It illustrates that BR can distinguish the density difference (hence the representation power difference) of the discriminator. Specifically, we can see that for larger discriminator density \(d_{D}\), the BR is much lower throughout the training, indicating strong discriminators. On the contrary, for the cases where the discriminators are too weak compared to the generators, e.g., all cases where \(d_{D}=10\%\), we can observe BR first increases and then oscillates wildly. We believe this oscillatory behavior is related to the training collapse. Empirical results also show that the FID metric experiences a sudden increase after this turning point.

### Dynamic density adjust: A first attempt to utilize the balance ratio

As demonstrated in the previous section, the balance ratio (BR) effectively captures the degree of balance between the generators and discriminators in sparse GANs. Hence, it is natural to leverage BR to dynamically adjust the density of discriminators during sparse GAN training so that a reasonable discriminator density can be found.

To demonstrate the value of BR, we propose a simple yet powerful modification to the STATIC baseline. This method, which we call **dynamic density adjust (DDA)**, is explained below. Specifically, we initialize the initial density of the discriminator \(d_{D}^{}=d_{G}\). After a specific training iteration interval, we adjust the density of the discriminator based on the BR over the last few iterations with a pre-defined density increment \( d\). With a pre-defined BR bounds \([B_{-},B_{+}]\), we decrease \(d_{D}\) by \( d\) when BR is smaller than \(B_{-}\), and vise versa. We show the algorithm in Appendix C Algorithm 1.

**Comparison to ADA .** In this paragraph, we compare ADA and DDA. (1) Notice that DDA algorithm is orthogonal to ADA in a sense that StyleGAN2-ADA adjusts the data augmentation

Figure 4: FID (\(\)) of STATIC sparsely trained SNGAN with and without DDA on CIFAR-10 with different sparsity ratio combinations. The result of DDA is independent of \(d_{D}\) as it is determined automatically. The shaded areas denote the standard deviation.

Figure 3: Illustration of balance ratio.

probability while DDA adjusts the discriminator density. (2) Moreover, the criterion used in DDA, i.e. BR, is very different from the criterion proposed in StyleGAN2-ADA, i.e. \(r_{v}=(D(x_{}))-(D(x_{}))}{ [D(x_{})]-[D(x_{})]}\) and \(r_{t}=[(D(x_{}))]\). In particular, \(r_{v}\) requires a separate validation set, while \(r_{t}\) only quantifies the overfitting of the discriminator to the training set. (3) Another note is that DDA is a flexible framework, where its criterion, i.e. BR, can be potentially replaced by \(r_{v}\), \(r_{t}\), and such.

**Experiment results.** We test DDA with target BR interval \([B_{-},B_{+}]=[0.5,0.65]\). Precisely, DDA tends to find a suitable discriminator where the generator can just trick the discriminator throughout the training. We show the results in Figure 4 with red lines. The experiments show that DDA can identify reasonable discriminator densities to enable balanced training for sparse GANs.

### Understanding observation 2: Analysing the failure of SDST with the balance ratio

By leveraging BR, we can also gain further insights into why some configurations do not benefit from SDST as compared to STATIC.

**Regarding SDST as a way of increasing the generator capacity.** Our findings suggest that SDST can possibly enhance the generator's representation power, as demonstrated by the higher BR values compared to STATIC observed in Figure 2. We attribute this effect to the in-time over-parameterization (ITOP)  induced by dynamic sparse training.

**SDST does not address training collapse.** The increase in generator's representation power resulting from SDST is only beneficial when the discriminator has matching or superior representation power. Therefore, if the training has already collapsed for the static baseline methods (STATIC), meaning that the generator is already stronger than the discriminator, SDST may not be effective in stabilizing sparse GAN training. This is evident from the results shown in Figure 2 first-row column 1, second-row column 1, third-row columns 1-2, and fourth-row columns 1-3.

Despite the superior performance of STU-GAN (or SDST in general) at higher discriminator density ratios \(d_{D}\), there exist some limitations for SDST, which we summarize below:

\(\)SDST requires a pre-defined discriminator density \(d_{D}\) before training. However, it is unclear what is a good choice. In real-world scenarios, it is not practical to manually search for the optimal \(d_{D}\) for each \(d_{G}\). A workaround may be using the maximum allowed density for the discriminator. However, as shown in Figure 1, the best performance is not always obtained with the maximum \(d_{D}=100\%\). Moreover, we are wasting extra computational cost for a worse performance if we use an overly-strong discriminator.

\(\)SDST fails if there is an additional constraint on the density of the discriminator \(d_{D}\). As Figure 1 suggests, for weak discriminators, SDST is unable to show consistent improvement compared to the STATIC baseline.

Hence, STU-GAN (or SDST in general), which directly applies DST to the generator, may only be useful when the corresponding discriminator is strong enough. In this sense, obtaining balanced training automatically is essential in GAN DST to deal with more complicated scenarios.

## 6 Balanced dynamic sparse training for GANs

In this section, we describe our methodology for balanced sparse GAN training.

STU-GAN (or SDST in general) considered in the last section cannot generate stable and satisfying performance. This implies that we should utilize the discriminator in a better way rather than do nothing (like SDST) or directly apply DST to the discriminator (see subsection E.2 for additional experiments). Consequently, DDA (subsection 5.3), which adjusts the discriminator density to stabilize GAN training, is a favorable candidate to address the issue. To this end, we propose **bAlamed DynAmicsparse Training (ADAPT)**, which adjusts the density of the discriminator during training with DDA while the generator performs DST.

We further introduce two variants, namely ADAPT\({}_{}\) and ADAPT\({}_{}\), based on whether we force the discriminator to be sparse. We present them in subsection 6.1 and subsection 6.2. These methods are more flexible and generate more stable performance compared to SDST.

### ADAPT\({}_{}\): Balanced dynamic sparse training in the relaxed setting

In this section, we consider the relaxed setting where a dense discriminator can be used, i.e., \(d_{D} d_{}=100\%\). This relaxed scenario gives the greatest flexibility to the discriminator. However, it does not necessarily enforce the sparsity of the discriminator (hence, no computational savings for the discriminator) because the density of the discriminator can be as high as \(100\%\).

For the relaxed setting, we use the direct combination of SDST with DDA. Precisely, the generator is adjusted using DST as mentioned in section 4 while the density of the discriminator is dynamically adjusted with DDA as mentioned in subsection 5.3. We call such a combination **relaxed balanced dynamic sparse training (ADAPT\({}_{}\))**. Please see Appendix C Algorithm 2 for more details.

**Comparison to STU-GAN (or SDST in general)**. Compared to STU-GAN (or SDST in general), which pre-defines and fixes the discriminator density during training, the difference is that for ADAPT\({}_{}\), the density of the discriminator is adjusted during the training process automatically through real-time monitoring of the balance ratio. Given the initial discriminator density \(d_{D}^{}=d_{G}\), ADAPT\({}_{}\) increases the discriminator density if a stronger discriminator is needed, and vice versa.

### ADAPT\({}_{}\): Balanced dynamic sparse training in the strict setting

Different from subsection 6.1, we now consider a strict setting where there is an additional sparsity constraint on the discriminator density in this section, i.e., \(d_{D} d_{}<100\%\).

ADAPT\({}_{}\) introduced in the previous section does not necessarily enforce sparsity for the discriminator, which provides less memory/training resources saving for larger generator density ratios. Note that the discriminator does not take advantage of DST to explore the structure of the dense network. Hence, we further present **strict balanced dynamic sparse training (ADAPT\({}_{}\))** in this section. This method allows the discriminator to perform DST in a controlled manner, which can lead to a better exploration of the dense network structure while maintaining the balance between the generator and the discriminator. We explain how ADAPT\({}_{}\) differs from ADAPT\({}_{}\) below:

\(\)**Capacity increase of the discriminator.** The essential difference lies when the observed BR is higher than \(B_{+}\), which means we need a stronger discriminator. In this case, if the discriminator density is lower than the constraint, i.e., \(d_{D}<d_{}\), ADAPT\({}_{}\) will perform just like ADAPT\({}_{}\) to increase the discriminator density. However, if the discriminator is already the maximum density, i.e., \(d_{D}=d_{}\), the discriminator will alternatively perform DST as a way of increasing the discriminator capacity (See subsection 5.4 for intuition).

\(\)**Capacity decrease of the discriminator.** Similar to ADAPT\({}_{}\), when the observed BR is lower than \(B_{-}\), we will decrease the discriminator density.

Hence, ADAPT\({}_{}\) makes the discriminator adaptive both in the density level (through density adjustment) and the parameter level (through DST). The algorithm of ADAPT\({}_{}\) is shown in Appendix C Algorithm 3.

### Experiment setting

**Datasets, architectures, and target sparsity ratios.** We conduct experiments on SNGAN with ResNet architectures on the CIFAR-10  and the STL-10  datasets. We have also conducted experiments with BigGAN  on the CIFAR-10 and TinyImageNet dataset (with DiffAug ).

   Dataset &  &  &  &  \\  Generator density & 10\% & 29\% & 30\% & 50\% & 10\% & 20\% & 30\% & 50\% & 10\% & 20\% & 30\% & 50\% & 10\% & 20\% & 30\% & 50\% \\  (Dense Baseline) & & 10.74 & & & 29.71 & & & & 8.11 & & & & & & & & & & & & \\  STAIC-Balance & 26.75 & 19.04 & 15.05 & 12.24 & 48.18 & 44.67 & 41.73 & 37.68 & 16.98 & 12.81 & 10.33 & 8.47 & 28.78 & 21.67 & 18.86 & 17.51 \\  STATIC-Strong & 26.79 & 19.65 & 14.38 & 11.91 & 52.48 & 43.85 & 42.06 & 37.47 & 23.48 & 14.26 & 11.19 & 8.64 & 31.44 & 22.51 & 18.22 & 18.00 \\   \(\) SDST-Balance-SEF & 26.23 & 17.99 & 13.21 & 11.79 & 56.41 & 48.58 & 39.93 & 30.37 & 12.41 & 9.87 & 9.13 & **8.01** & 25.39 & 21.30 & 21.80 & 21.20 \\ \(\) SDST-Strong-SEF & 16.49 & 13.26 & 11.68 & 10.68 & 67.37 & 49.96 & 37.99 & 39.19 & 10.84 & 9.64 & 8.75 & 36.26 & 22.06 & 20.56 & 21.70 & 13.82 \\ \(\) SDST-Balance-Rigid. & 27.06 & 16.36 & 14.00 & 12.28 & 43.08 & 33.90 & 31.83 & 30.30 & 12.45 & 9.42 & 8.86 & 8.03 & 21.60 & 19.33 & 18.57 & 17.45 \\ \(\) SDST-Strong-Rigid. & 17.02 & 13.36 & 12.51 & 11.35 & 35.65 & 33.25 & **31.41** & 20.18 & 10.28 & 9.11 & 8.69 & 8.33 & 21.14 & 18.95 & 17.75 & 16.30 \\   ADAPT\({}_{}\) (Ours) & **14.19** & **13.19** & 12.38 & **10.60** & **35.98** & **33.06** & 31.71 & **29.96** & **10.19** & **8.56** & **8.36** & 8.22 & **19.42** & **17.99** & **17.66** & **14.15** \\   

Table 1: FID (\(\)) of different sparse training methods with **no** constraint on the density of the **discriminator**. Best results are in **bold**; second-best results are underlined.

Target density ratios and two practical strategies.We use STATIC and SDST (section 4) as our Appendix A for more experiment details.

**Baseline methods and two practical strategies.** We use STATIC and SDST (section 4) as our baselines. Note that in real-world application scenarios, it is not practical to perform a grid search for a good \(d_{D}\) as in section 4. Hence, we propose two practical strategies to define the constant discriminator density for these baseline methods: (1) balance strategy, where we set the density of the discriminator \(d_{D}\) the same as the density of the generator \(d_{G}\); (2) strong strategy, where we set the density of the discriminator as large as possible, i.e., \(d_{D}=d_{}\). For SDST methods, we test both \(\)SDST-SET and \(\)SDST-RigL. For a fair comparison, \(d_{}\) is set to be 100% and 50% for the relaxed setting and the strict setting, respectively.

For ADAPT, we use the \(\)RigL version, which grows connections of the generators and discriminators based on gradient magnitude. The gradient information enables two components to react promptly according to the change of each other. Different from the value used in subsection 5.3, we control the balance ratio in the range \([0.45,0.55]\) unless otherwise mentioned to have a slightly stronger discriminator, potentially avoiding training collapse. More details can be found in Appendix B.

### Experiment results

We show the experiment results in Table 1 and Table 2 for the relaxed setting and the strict setting, respectively. We also present the training FLOPs normalized by the dense counterpart for the relaxed setting in Table 3. We defer the results for the strict setting to Appendix F Table 12. We show FID for the CIFAR-10 test set, Inception scores, and comparison with post-hoc pruning baseline in Appendix E. We also show ADAPT BR evolution in Appendix D. We summarize our findings below.

**The strong strategy and the balance strategy for baselines.** Generally, using the strong strategy has some advantages over the balance strategy. Such an observation is most prominent in the CIFAR-10 dataset. For the cases where the balance strategy is better, e.g., SNGAN on the STL-10 dataset, our explanation is that the size difference between generators and discriminators is more significant. Hence, the degree of unbalance is more severe and leads to more detrimental effects.

**Comparison of \(\)RigL and \(\)SET for SDST.** We found that \(\)RigL has an advantage over \(\)SET when dealing with more sparse generators. Our hypothesis is that gradient information can effectively guide the generator to identify the most crucial connections in such cases. However, this advantage is not as apparent for more dense generators.

**ADAPT\({}_{}\) achieves a good trade-off between performance and computational cost.** Experiments show that ADAPT\({}_{}\) shows promising performance by being best for 13 out of 16 cases. The advantage of ADAPT\({}_{}\) is most prominent for the most difficult case, i.e., \(d_{G}=10\%\). Specifically, it

   Dataset &  &  &  &  \\  Generator density & 10\% & 20\% & 30\% & 50\% & 10\% & 20\% & 30\% & 50\% & 10\% & 20\% & 30\% & 50\% & 10\% & 20\% & 30\% & 50\% \\  (Dense Baseline) &  &  &  \\  STATIC-Balance & 26.75 & 10.64 & 15.05 & 12.58 & 48.18 & 44.67 & 41.73 & 37.68 & 16.98 & 12.81 & 10.33 & 8.47 & 28.78 & 21.67 & 18.86 & 17.51 \\ STATIC-Stonge & 21.73 & 16.69 & 13.48 & 12.58 & 50.36 & 44.06 & 40.73 & 37.68 & 18.91 & 13.43 & 10.84 & 8.47 & 33.01 & 25.93 & 17.90 & 17.51 \\   \(\)SDST-Balance-SET & 26.23 & 17.79 & 13.21 & **11.79** & 56.24 & 44.51 & 41.23 & 30.80 & 12.41 & 9.87 & 9.13 & 8.01 & 25.39 & 21.30 & 21.80 & 21.20 \\ \(\)SDST-Stonge-SET & 15.86 & 12.82 & **11.55** & **11.79** & 57.91 & 50.05 & 38.13 & 30.30 & 11.85 & 9.36 & 8.61 & 8.01 & 22.68 & 20.24 & 22.00 & 21.20 \\ \(\)SDST-Balance-RigL & 27.06 & 16.36 & 14.00 & 12.28 & 43.23 & 33.00 & 13.61 & 30.20 & 12.54 & 9.42 & 8.86 & 8.31 & 21.60 & 19.38 & 15.77 & **14.55** \\ \(\)SDST-Stonge-RigL & 15.19 & 12.93 & 12.75 & 12.28 & 53.74 & 37.34 & 31.98 & 30.30 & 10.11 & 9.17 & **8.35** & 8.03 & 21.90 & 20.43 & 18.29 & 17.45 \\   ADAPT\({}_{}\) (Ours) & **14.53** & **12.73** & 12.20 & 12.11 & **41.18** & **31.59** & **31.16** & **29.11** & **9.29** & **8.64** & 8.44 & **7.90** & **18.89** & **17.37** & **16.93** & **16.02** \\   

Table 2: FID (\(\)) of different sparse training methods. **The density of the discriminator is constrained to be lower than 50%**. Best results are in **bold**; second-best results are underlined.

   Dataset &  &  &  &  \\  Generator density & 10\% & 20\% & 30\% & 80\% & 10\% & 20\% & 30\% & 30\% & 10\% & 20\% & 30\% & 80\% & 10\% & 20\% & 30\% & 50\% \\  (Dense Baseline) & 100\% & 2.677 & 10.98 & 26.59 & 47.26 & 27.98 & 47.16 & 93.22 & 73.356 & 9.798 & 10.05 & 26.664 & 40.993 & 23.35 & 44.879 & 60.691 & 93.29 \\ \(\)SDST-Stage-SET & 8.22\% & 40.064 & 46.73shows 2.3 and 7.1 FID improvements over the second-best methods for the SNGAN on the CIFAR-10 and the STL-10, respectively. Moreover, compared to the competitive baseline methods that use the strong strategy, i.e., \(\)SDST-Strong-RigL and \(\)SDST-Strong-SET, ADAPT\({}_{}\) shows great computational cost reduction. For example, it outperforms \(\)SDST-Strong-RigL on BigGAN (CIFAR-10) with much-reduced training FLOPs (10.39% v.s. 83.97%).

**ADAPT\({}_{}\) shows stable and superior performance.** Similar to ADAPT\({}_{}\), we notice that ADAPT\({}_{}\) also delivers promising results compared to baselines, even with a further constraint on the discriminator. More precisely, among all the cases, ADAPT\({}_{}\) ranks top 2 for all cases, with 13 cases being the best. Moreover, ADAPT\({}_{}\) again shows comparable or better performance compared to \(\)SDST-Strong-RigL with reduced computational cost.

A more interesting observation is that ADAPT\({}_{}\) sometimes outperforms ADAPT\({}_{}\). We speculate that this phenomenon occurs because changes in density may result in a larger influence on the GAN balance during training compared to DST. Hence, the strict version, whose discriminator density range is smaller, may offer a more consistent performance.

## 7 Conclusion

In this paper, we investigate the use of DST for GANs and find that solely applying DST to the generator does not necessarily enhance the performance of sparse GANs. To address this, we introduce BR to examine the degree of unbalance between the sparse generators and discriminators. We find that applying DST to the generator only benefits the training when the discriminator is comparatively stronger. Additionally, we propose ADAPT, which can dynamically adjust the discriminator at both the parameter and density levels. Our approach shows promising results, and we hope it can aid researchers in better comprehending the interplay between the two components of GAN training and motivate further exploration of sparse training for GANs. However, we must note that we have not yet evaluated our methods on the latest GAN architectures due to computational constraints.

## 8 Acknowledgement

This work utilizes resources supported by the National Science Foundation's Major Research Instrumentation program, grant No.1725729 , as well as the University of Illinois at Urbana-Champaign. This work is supported in part by Hetao Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone Project (No.HZQSWS-KCCYB-2022046); University Development Fund UDF01001491 from the Chinese University of Hong Kong, Shenzhen; Guangdong Key Lab on the Mathematical Foundation of Artificial Intelligence, Department of Science and Technology of Guangdong Province. Prof. NH is in part supported by Air Force Office of Scientific Research (AFOSR) grant FA9550-21-1-0411.