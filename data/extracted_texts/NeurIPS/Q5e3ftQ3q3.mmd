# Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits

Yunlong Hou

Department of Mathematics

National University of Singapore

yhou@u.nus.edu

&Vincent Y. F. Tan

Department of Mathematics

Department of Electrical and Computer Engineering

National University of Singapore

vtan@nus.edu.sg

&Zixin Zhong

Data Science and Analytics Thrust

Hong Kong University of Science and Technology (Guangzhou)

zixinzhong@hkust-gz.edu.cn

###### Abstract

We propose a _novel_ piecewise stationary linear bandit (PSLB) model, where the environment randomly samples a context from an unknown probability distribution at each changepoint, and the quality of an arm is measured by its return averaged over all contexts. The contexts and their distribution, as well as the changepoints are unknown to the agent. We design _Piecewise-Stationary \(\)-Best Arm Identification\({}^{+}\)_ (PS\(\)BAI\({}^{+}\)), an algorithm that is guaranteed to identify an \(\)-optimal arm with probability \( 1-\) and with a minimal number of samples. PS\(\)BAI\({}^{+}\) consists of two subroutines, PS\(\)BAI and Naive\(\)-BAI (N\(\)BAI), which are executed in parallel. PS\(\)BAI actively detects changepoints and aligns contexts to facilitate the arm identification process. When PS\(\)BAI and N\(\)BAI are utilized judiciously in parallel, PS\(\)BAI\({}^{+}\) is shown to have a finite expected sample complexity. By proving a lower bound, we show the expected sample complexity of PS\(\)BAI\({}^{+}\) is optimal up to a logarithmic factor. We compare PS\(\)BAI\({}^{+}\) to baseline algorithms using numerical experiments which demonstrate its efficiency. Both our analytical and numerical results corroborate that the efficacy of PS\(\)BAI\({}^{+}\) is due to the delicate change detection and context alignment procedures embedded in PS\(\)BAI.

## 1 Introduction

In stochastic _multi-armed bandits_ (MABs), an agent interacts with the environment at each time step. The agent pulls an arm and observes the corresponding return provided by the environment. The classical MAB framework assumes a _stationary_ environment where the expected return of each arm remains unchanged over time. However, we usually face ever-changing environments in real life. For instance, in investment option selection and portfolio management, fund managers want to select a subset of good candidate portfolios. However, the market may be bullish, bearish, or in some other state. The transition between these states can be well-modelled as being stochastic. We wish to select portfolios that yield the best long-term option under such a piecewise stationary environment. Further examples such as one based on agriculture in the face of stochastically changing weather patterns are discussed in detail in Appendix A. These motivate us to formulate and investigate a _piecewise stationary linear bandit_ (PSLB) model.

Our PSLB model is equipped with an _arm set_\(\), a _context set_\(\) and a deterministic but unknown sequence of _changepoints_\(\). At each changepoint, the environment samples a context \(\) from anunknown probability distribution \(P_{}\), and the returns of arms may change when the context changes. The return of each arm under each context is determined by its feature \(x\) and the context \(\). In particular, the expected return of an arm is the weighted sum \(_{x}=_{P_{}}[x^{}]\). While the sequence of changepoints, as well as the distribution and latent vectors of contexts are not known, the agent samples an arm and observes the corresponding return at each time step so that it can identify the best arm \(*{arg\,max}_{x}_{x}\) up to some tolerance \(\) with probability \( 1-\) and with as few samples as possible. The agent's behavior does not affect the sequence of contexts that is drawn from \(P_{}\).

**Main Contributions.** We are the _first_ to study the fixed-confidence _best arm identification_ (BAI) problem in _piecewise stationary bandits_ (PSB). Given \(>0\), we say the arm with the highest expected return \(^{*}\) is the _best_, and an arm is \(\)-optimal if its expected return is at least \(^{*}-\). We seek to design an \((,)\)-PAC algorithm which can identify an \(\)-optimal arm with probability \( 1-\) in as few time steps as possible, i.e., with minimal sample complexity.

Our **first** contribution concerns the formulation of a _novel_ PSLB model, where we measure the quality of an arm \(x\) according to its _expected return_\(_{x}=_{ P_{}}[x^{}]\) for the following reasons. Consider that an arm is measured by its average return across time, which is a generalization of the definition in _stationary bandits_ (SB). A notable feature of PSB models is that the context changes as time evolves, and hence the arm's average return across time also changes, in general. Hence, we aim to identify an arm whose _average return across contexts_ is high, and benefits the agent for interacting with the environment _in the long run_ after the arm identification task. We are thus inspired to introduce the distribution of contexts under the PSLB model, define the expected return \(_{x}\) for each arm, and use this ensemble (non-time varying) statistic as the benchmark for what we seek to learn. The BAI task using this statistic is meaningful but challenging, as the agent needs to reliably estimate the context vectors, changepoints, and context distribution.

**Secondly,** we propose Piecewise-Stationary \(\)-BAI\({}^{+}\) (PS\(\)BAI\({}^{+}\)), an algorithm designed to tackle the BAI problem in our PSLB model. We prove that it is \((,)\)-PAC and bound its sample complexity. PS\(\)BAI\({}^{+}\) samples arms according to a suitably defined G-optimal allocation, and runs two algorithms: Naive\(\)-BAI (N\(\)BAI) and PS\(\)BAI as subroutines in parallel to achieve efficiency and attain a bound on the sample complexity in expectation.

\(\) Being a baseline but naive algorithm, the complexity of N\(\)BAI grows linearly with the maximum length between two changepoints \(L_{}\), motivating us to design a more efficient algorithm, PS\(\)BAI, to reduce the impact of \(L_{}\).

\(\) PS\(\)BAI is equipped with two delicately designed subroutines Linear-Change Detection (LCD) and Linear-Context Alignment (LCA) to actively detect changepoints and align contexts with those observed in the previous time steps respectively. Concretely, **in terms of the design**, PS\(\)BAI determines whether samples from two intervals are under the identical context via a sliding window mechanism, and detects changepoints and aligns contexts accordingly; this facilitates the estimation of context vectors and their distribution. Combining these elements into the design of PS\(\)BAI and analyzing them requires some care. **On the theoretical side**, we prove PS\(\)BAI identifies an \(\)-optimal arm faster than N\(\)BAI with high probability. The success of PS\(\)BAI relies on the LCD and LCA subroutines, while a minor drawback is that they require a non-vanishing failure probability budget which does not allow us to bound the sample complexity of PS\(\)BAI in expectation. To achieve a complete theoretical understanding, we delicately design the PS\(\)BAI\({}^{+}\) algorithm whose efficiency is inherited via the LCD and LCA procedures in PS\(\)BAI as well as the effective utilization of running PS\(\)BAI and N\(\)BAI in parallel.

**Thirdly,** we derive a lower bound on the complexity of any \((,)\)-PAC algorithm in PSLB models. To derive this bound, we first lower bound the complexity of an algorithm when the contextual information (and changepoints) are available, and then quantify the number of arm samples (and realized contexts) required to reliably infer an \(\)-best arm.We compare the upper bound of PS\(\)BAI\({}^{+}\) and this generic lower bound in several instances. The matching (up to logarithmic terms) of bounds illustrate that our PS\(\)BAI\({}^{+}\) algorithm is almost asymptotically optimal.

**Lastly,** we demonstrate the efficiency of PS\(\)BAI\({}^{+}\) with numerical experiments. The first half of our experiment shows that PS\(\)BAI\({}^{+}\) is \((,)\)-PAC and with significantly lower sample complexity compared to N\(\)BAI, corroborating our theoretical findings. In the second half, we compare PS\(\)BAI\({}^{+}\) to N\(\)BAI, and two other benchmarks Distribution \(\)-BAI (D\(\)BAI) and D\(\)BAI\({}_{}\).While contexts and changepoints are not available to PS\(\)BAI\({}^{+}\) and N\(\)BAI, they are observed by D\(\)BAI and D\(\)BAI\({}_{}\). Nevertheless, PS\(\)BAI\({}^{+}\) is still competitive compared to D\(\)BAI and D\(\)BAI\({}_{}\) in our empirical experiments. Hence, both experiments justify the necessity of the change detection and context alignment procedures for boosting the learning of contexts and their distributions, as well as the identification of the best arm. We also show empirically that misspecifications to the knowledge of \(L_{}\) and \(L_{}\) do not affect the performance of our algorithm significantly.

**Related work.**_Best arm identification_ (BAI) and _regret minimization_ (RM) are two fundamental problems in multi-armed bandits. In stationary linear bandits, [1; 2] focus on BAI and [3; 4] aim to solve the RM problem. An efficient algorithm can choose the G-optimal allocation or \(\)-allocation rule to quickly identify a good arm [1; 5]. Besides, [6; 7] focus on \(\)-optimal arm identification, which is a generalization of the standard BAI problem.

The BAI and RM problems are also studied in thr _non-stationary bandits_ (NSB), where in contrast to the SB model, the context varies with time [8; 9; 10]. NSB can be largely divided into two classes: the drifting bandit (DB) model, where the context changes at each step , and PSB, where the context changes less frequently .  provides an extensive discussion on the definition of NSB models.

On one hand, the RM problem have been investigated extensively in DB models [12; 13]. On the other hand, concerning the BAI task in DB models,  investigated BAI with a _fixed-horizon_, where the best arm has the highest average return over this horizon;  assumes the best arm remains unchanged after certain time step and explores the _fixed-confidence_ setting. Besides, when the contextual information in NSB models is available, NSB models are known as _contextual bandit_ (CB) models [16; 17; 18].  showed that the contextual information accelerates the best arm identification process. More discussions on DB and CB models are presented in Appendix C.

Moreover, the context can drift dramatically in a DB model while it remains unvarying in a SB model. Straddling between the DB and SB models, PSB models assume there is an interim stationary interval between each two consecutive changepoints, where the context remains unchanged. The context changes can be characterized in different ways and affect the performance of proposed algorithms in PSB models. For instance, a changepoint signals the return of at least one arm shift as in , and indicates the best arm changes as in .

In PSB models, a large body of works focus on RM. While [10; 20; 21; 22] equip their algorithms with changepoint detection techniques to handle the context changes,  actively checks the quality of each arm. However, there is no existing work on the fixed-confidence BAI problem in a PSB model. To fill this gap in the literature, we design PS\(\)BAI\({}^{+}\) for \(\)-optimal arm identification in our proposed PSLB model. We show PS\(\)BAI\({}^{+}\) is almost asymptotically optimal by comparing its complexity to a generic lower bound of all algorithms, and validate its efficiency through numerical experiments.

## 2 Problem Setup

For \(m\), let \([m]:=\{1,2,,m\}\). For a finite set \(S\), let \(_{S}\) denote the \(|S|\)-dim probability simplex on \(S\). Let \(A():=_{x}q_{x}xx^{}\) be the matrix induced by \(_{}\) with \(^{d}\). An instance of _piecewise stationary linear bandit_ is a tuple \(=(,,P_{},)\). Specifically, \(x^{d}\) is an arm (vector) and the arm set \(^{d}\) is composed of \(||=K\) arms that spans \(^{d}\). The latent vector matrix \(=(_{1}^{*},,_{N}^{*})^{d N}\) contains \(N\) latent column vectors where the \(j^{}\) column \(_{j}^{*}\) is associated with context \(j[N]\). For the sake of normalization, we assume \(|x^{}_{j}^{*}| 1\) for all \(x,j[N]\). Let \(P_{}\) denote the distribution (probability mass function) of the latent vectors and \(p_{j}=P_{}[_{j}^{*}]\). We represent the probabilities of latent vectors as \(=(p_{1},,p_{N})_{N}\). The fixed but unknown sequence of changepoints \(:=(c_{1},c_{2},)\) is an sequence of increasing positive integers \(1=c_{1}<c_{2}<\), characterizing all the changepoints (time steps).

The _return_ of arm \(x\) under latent context \(j\) is a random variable \(Y=x^{}_{j}^{*}+\), where \(\) is a zero-mean random variable (noise) supported on \([-1,1]\), and the _expected return_ of arm \(x\) is \(_{x}:=_{ P_{}}[x^{}]=_{j=1}^{N}P_{ }[_{j}^{*}]x^{}_{j}^{*}\). The _best arm_, which we assume is unique, is denoted as \(x^{*}:=_{x}_{x}\) with mean \(^{*}:=_{x^{*}}\). Given a slackness parameter \(>0\), we define the set of \(\)_-best arms_\(_{}:=\{x:_{x}^{*}-\}\). For each pair of arms \((x,)^{2}\), define the _contextual mean gap_ between \(x\) and \(\) under latent context \(j\) as \(_{j}(x,):=(x-)^{}_{j}^{*}\) and the _mean gap_ between \(x\) and \(\) as \((x,):=_{x}-_{}\).

Given \(l\), the interval \((c_{l},,c_{l+1}-1)\) is known as the \(l^{}\)_stationary segment_ and its length is \(L_{l}:=c_{l+1}-c_{l}\). We assume \(L_{} L_{l} L_{}\). Let \(l_{t}:=\{l:c_{l} t\}\) denote the number of stationary segments up to time step \(t\). At time step \(t[T]\) (see Dynamics 1),

**(i)** If \(t\), the environment samples a latent vector \(^{*}_{t_{i}}\) according to \(P_{}\), that is, it generates a (latent) _context sample_ with \(P_{}\); otherwise the latent vector remains unchanged, i.e., \(^{*}_{j_{t}}=^{*}_{j_{t-1}}\). The contexts \(\{^{*}_{j_{cl}}\}_{l}\) are sampled i.i.d. from \(P_{}\) at each changepoint \(\{c_{t}\}_{l}\).

**(ii)** The agent pulls an arm \(x_{t}\) and observes the stochastic return \(Y_{t,x_{t}}=x_{t}^{}^{*}_{j_{t}}+_{t}\), where \(_{t}\) is drawn independently from a distribution supported on \([-1,1]\).

The agent uses an _online_ algorithm \(:=\{(_{t},_{t},r_{t})\}_{t}\) to actively interact with the instance \(\) and only has access to the arm set \(\), number of latent vectors \(N\), the bounds on the length of each segment \(L_{}\) and \(L_{}\), the slackness parameter \(\), and the confidence parameter \(\).

\(\) sampling rule \(_{t}:^{}_{t}:=((x_{s}^{},Y_{s,x_{s}^{}}))_{ [t-1]}\) samples an arm \(x_{t}^{}\) based on the observation history \(^{}_{t}\) and observe the corresponding random return \(Y_{t,x_{t}^{}}\);

\(\) stopping rule \(_{t}:^{}_{t+1}\{,\}\) decides whether to stop or continue to execute given the observation history \(^{}_{t+1}\). The stopping time under algorithm \(\) is denoted as \(^{}\);

\(\) recommendation rule \(r_{t}:^{}_{+1}\) recommends an arm \(^{}\) based on \(^{}_{+1}\) upon termination.

The stopping time \(^{}\) is the _sample complexity_ of the algorithm \(\) under instance \(\). The _expected sample complexity_ is \([^{}]\), where the expectation is taken w.r.t. the random returns, the realization of the contexts governed by the latent vector distribution \(P_{}\), and the randomness of the algorithm \(\).

An algorithm \(\) is \((,)\)_-PAC_ (Probably Approximately-Correct) if

\[[^{}_{}] 1-.\]

Our overarching goal in this paper is to devise an \((,)\)-PAC algorithm that minimizes \(^{}\) with high probability (w.h.p.) and in expectation.

## 3 Algorithms

### A Naive Baseline: N\(\)BAI

We first devise the Naive \(\)-Best Arm Identification (or N\(\)BAI) algorithm (presented in Algorithm 2). In the design of N\(\)BAI, only the choice of confidence radius \(_{t}\) takes the potential context changes into consideration. Even though N\(\)BAI does not attempt to detect potential changes in the context, it can identify an \(\)-optimal arm w.h.p. and is with a finite expected sample complexity.

**Proposition 3.1**.: _Let \(_{}=_{x x^{*}}(x^{*},x)\),_

\[T_{}^{}=)^{ 2}} T_{}^{}= }{(+_{})^{2}}.\]

_The N\(\)BAI algorithm is \((,)\)-PAC and its expected sample complexity is \((T_{}^{}+T_{}^{})\)._

The upper bound in Proposition 3.1 (also see Appendix F) consists of two main terms. (i) As N\(\)BAI samples arms according to the G-optimal allocation (see Appendix D), the amount of samples needed to estimate the average of latent vectors \(_{s=1}^{t}^{*}_{j_{s}}/t\) contributes to \(T_{}^{}\). (ii) \(T_{}^{}\) quantifies how fast \(_{s=1}^{t}^{*}_{j_{s}}/t\) converges to the expectation of context vectors \(_{j=1}^{t}p_{j}^{*}_{j}\).

The sample complexity of N\(\)BAI grows linearly with \(L_{}\), but we surmise that the sample complexity of a close-to-optimal algorithm should have a _reduced dependence on_\(L_{}\).

### Piecewise-Stationary \(\)-Best Arm Identification

The algorithm Piecewise-Stationary \(\)-Best Arm Identification (or PS\(\)BAI) is presented in Algorithm 1. By using a sliding window mechanism, PS\(\)BAI actively detects the changepoints and aligns the current latent context with contexts observed in the previous time steps via Linear-Change Detection (or LCD) and Linear-Context Alignment (or LCA), which are presented in Algorithms 3 and 4 (see App. D.2.2), respectively. PS\(\)BAI consists of three phases:

(i) _Exploration phase_ (Exp): Estimate latent vectors and their distribution \(P_{}\) (Lines 8 to 11 and 25);

(ii) _Change Detection phase_ (CD): Detect changepoints (Lines 12 to 16);

(iii) _Context Alignment phase_ (CA): Evaluate the current context and align it with the contexts observed in previous time steps (Lines 17 to 21).

At time \(t\), we estimate \(\) and \(\) with \(_{t}=(_{t,1},,_{t,N})\) and \(}_{t}=(_{t,1},,_{t,N})^{}\), respectively.1 We denote the empirical mean gap between \(x\) and \(\) under context \(j\) as \(_{t,j}(x,):=(x-)^{}_{t,j}\).

PS\(\)BAI first computes the G-optimal allocation \(^{*}\) on the arm set \(\) and its maximum possible stopping time \(^{*}\) (Line 2). It initializes \(_{}\) and \(_{}\). \(_{}\) collects samples to detect changepoints and \(_{}\) maintains a dictionary of \([]\) pairs (Line 3);2\(_{}[j]\) is the sequence of CD samples used to _identify_ latent context \(j\). It also initializes \(_{t,j}\), the collection of time indices in \([t]\) in the Exp phases under estimated context \(j\). Define

\[_{t}=_{j[N]}_{t,j}, T_{t}=|_ {t}|, T_{t,j}=|_{t,j}|, j[N].\] (3.1)

```
1:Input: arm set \(\), size of the set of latent vectors \(N\), bounds on the segment lengths \(L_{}\) and \(L_{}\), slackness parameter \(\), confidence parameter \(\), sampling parameter \(\) and window size \(w\), threshold \(b\).
2:Initialize: Compute the G-optimal allocation \(^{*}\) and \(^{*}=}{^{2}}KL_{} }{^{2}}\).
3: Set \(_{}=[\;]\), \(_{}=\{\;\}\). Set \(t_{}=+\).
4: Set \(_{t,j}=\) and initialize \(_{t}\), \(T_{t,j}\), \(T_{t}\) with (3.1) for all \(t^{*}\), \(j[N]\).
5: Sample \(\) arms \(\{x_{s}\}_{s=1}^{}^{*}\) and observe the associated returns \(\{Y_{s,x_{s}}\}_{s=1}^{},t=,t_{}=\).
6:\(_{}=\{1:[(x_{s},Y_{s,x_{s}})]_{s=1}^{}\}\), \(_{t}=1\).
7:while\(t^{*}\)do
8:\(t=t+1\)
9: Sample an arm \(x_{t}^{*}\) and observe return \(Y_{t,x_{t}}\).
10:if\((t-t_{},) 0\)then
11: Update \(_{t}=_{t-1}\), \(_{t,_{t}}=_{t-1,_{t}}\{t\}, _{t,j}=_{t-1,j}\) for \(j_{t}\).
12:else
13:\(_{}=_{}+[(x_{t},Y_{t,x_{t}} )]\). ```

**Algorithm 1** Piecewise-Stationary \(\)-Best \(\) Identification (PS\(\)BAI)

It then collects \(\) samples and stores them in \(_{}\), which is then used to identify the first latent context (Lines 5 to 6).

In the Exp phase, PS\(\)BAI **firstly** samples an arm \(x_{t}\) with \(^{*}\) and observes the return \(Y_{t,x_{t}}=x_{t}^{}^{*}_{_{t}}+_{t}\) (Line 9). It **then** updates the estimated context index and time collectors (Line 11). It also updates the estimates of value and probability of each context \(j\) (Line 25) with

\[_{t,j}=}_{s_{t,j}}A(^{*} )^{-1}x_{s}Y_{s,x_{s}}_{t,j}=}{T_{t}},\] (3.2)where \(_{t,j}=\) if \(T_{t,j}=0\). We define \(_{t}\), \(_{t}\), \(_{t,j}\), and \(\ _{t,j}^{_{2}}(x,)\) in Appendix D.2.1. For each pairs of arms \((x,)\), the confidence radius of \((x,)\) at time step \(t\) is

\[_{t}(x,):=2(_{t}+_{t})+_{j=1}^{N}_{t,j}|_{t,j}^{_{2}}(x,)+_{t}(x,)|;\] (3.3)

PS\(\)BAI actively enters the CD phase every \(\) time steps (Line 12). It **firstly** adds a CD sample to \(}\) (Line 13). **Next**, if there are sufficient CD samples (Line 15), the LCD subroutine (presented in Algorithm 3) is called and utilizes the most recent \(w\) CD samples to check whether a changepoint just occurred (Line 16). PS\(\)BAI steps into the CA phase if a changepoint is detected, and skips the CA phase otherwise, which is illustrated by Figures 1(b) and 1(a) respectively.

In the CA phase, PS\(\)BAI **starts** by resetting \(}\) (Line 17), updating the count of time steps and recording the ending time of this CA phase (Line 18). **Thereafter**, the CA subroutine (presented in Algorithm 4) is invoked, which estimates the current latent context index \(_{t}\) and updates \(}\) (Line 19). If \(_{t}=N+1\), i.e., PS\(\)BAI identifies \(N+1\) latent contexts, which is incorrect under instance \(\), it terminates and fails to identify an \(\)-optimal arm (Line 20). **Lastly**, all empirical statistics are reverted to those from \((w(+1)/2)\) time steps ago, i.e., the most recent \((w/2)\) samples in the Exp phases are abandoned (Line 21).

The stopping rule is described in Lines 26 to 32. **(I)** If the following condition is satisfied (Line 26):

\[_{x:x x_{t}^{}}_{t}(x_{t}^{},x)-_{t}(x_{t}^{ },x)- T_{t}}{9} (}})\] (3.4)

where the empirical mean gap \(_{t}(x_{t}^{},x):=(x_{t}^{}-x)^{}_{t} }_{t}\) and \(x_{t}^{}:=*{arg\,max}_{x}x^{}_ {t}}_{t}\), PS\(\)BAI records the arm with the highest empirical mean as \(_{}\) and the number of CD samples \(t_{}\) (Lines 27 and 28) but does not terminate immediately. Besides, a mild forced arm pull procedure is in the second line of (3.4), which is inspired by Lemma E.1 and to ensure the performance of PS\(\)BAI. **(II)** PS\(\)BAI will execute for another \((w/2)\) time steps in which \(w/2\) CD samples are collected; if no changepoint is detected with these \(w/2\) CD samples, the recorded arm \(_{}\) is recommended and PS\(\)BAI terminates (Lines 29 to 30). Part **(II)** of the stopping rule assures PS\(\)BAI does not terminate when a changepoint has occurred but has not been detected, as PS\(\)BAI may fail to identify an \(\)-optimal arm otherwise.

We remark that even though PS\(\)BAI uses the knowledge of \(L_{}\), our experiments show that the performance of PS\(\)BAI is robust to small misspecifications in \(L_{}\) (see Appendix O.2). Furthermore, the computational complexity of PS\(\)BAI is computed in detail in Appendix D.4. The derived computational complexity indicates the proposed algorithm depends in a natural manner on the problem parameters such as \(d,K,N\), and \(\). Lastly, thanks to the LCD and LCA subroutines, a slightly modified variant of PS\(\)BAI can also solve the "\(\)-Best Arm Tuple identification problem", which aims to identify an \(\)-best arm _under each context_; see Appendix Q for details.

Figure 1: (a) No change alarm is raised during a stationary segment. The active CD samples are the input to the LCD subroutine at current time step \(t\). (b) A changepoint is detected by LCD, followed by a CA phase and a statistics reversion step.

#### 3.2.1 Theoretical guarantee of PS\(\)BAI

To facilitate the analysis of PS\(\)BAI, we propose the following assumptions. Note that our PS\(\)BAI algorithm may still succeed to identify an \(\)-optimal arm w.h.p. when the assumptions do not hold.

**Assumption 1** (Distinguishability Condition).: _The agent can choose \(w\), \(\) and \(b\) such that (1) \(2b_{c}\) where \(_{c}:=_{^{*}_{j}^{*}_{j}}_{x}|x^{ }(^{*}_{j}-^{*}_{j})|\) is the minimum gap between two contexts; and (2) \(3w L_{}\). A possible choice is_

\[b =\!}}\!+\!}}^{2}\!+\!}}}_{}=)^{2}K}.\] (3.5)

This assumption guarantees (i) PS\(\)BAI will not abandon all samples during the reversion procedure (Line 21 of Algorithm 1); (ii) each two latent vectors can be distinguished if the window size \(w\) is sufficiently large (e.g., \(L_{}/6\)). We clarify that this assumption is only for the rigor of theoretical guarantees and it holds provided that each stationary segment is sufficiently long; this is a feature of PSB models and similar assumptions are also present in existing works for their analyses . We demonstrate the robustness of PS\(\)BAI to these parameters using experiments in Section 6.

**Theorem 3.2**.: _Define the context distribution estimation (DE) hardness parameter_

\[_{}(x_{},x):=}{((x^{* },x)+)^{2}}(x_{},x)\]

_where \((x_{},x):=_{j=1}^{N},1/4 \}}|_{j}(x_{},x)+|^{2}\). Under Assumption 1, with probability at least \(1-\), PS\(\)BAI identifies an \(\)-optimal arm and its sample complexity is_

\[_{x_{}_{ }\\ x x_{},x^{*}},x)+)^{2}}}_{T_{}(x)}\!\! +_{}(x_{},x)}_ {T_{}(x_{},x)}+}{(x^{* },x)+}}_{T_{}(x)}.\] (3.6)

The upper bound comprises three terms which serve distinct purposes:

(i) _Latent vector estimation_ (VE): \((T_{}(x))\) quantifies the bulk of samples needed to obtain a good estimate of latent context vectors such that the returns of \(x_{}\) and \(x\) can be distinguished, where \(x_{}\) is an \(\)-best arm and \(x_{}\) is a suboptimal arm. \(T_{}(x)\) recovers the sample complexity in the stationary linear bandits in , indicating that PS\(\)BAI estimates latent vectors efficiently.

(ii) _Context distribution estimation_ (DE): \((T_{}(x_{},x))\) characterizes the bulk of samples needed to learn the distribution of latent context vectors.

(iii) _Residual estimation_ (RE): \((T_{}(x))\) counts the remaining samples needed for VE and DE, in addition to \((T_{}+T_{})\).

Besides, the \(\) operator is applied to exclude all suboptimal arms. We also see that \(T_{}(x)\) and \(T_{}(x_{},x)\) are similar to \(T_{}^{}\) and \(T_{}^{}\) in Proposition 3.1 respectively.

**Firstly,** the bound in (3.6) implies that, in an instance with smaller _relaxed mean gap_\((x^{*},x)+\), PS\(\)BAI terminates after a larger number of time steps; in other words, it is more difficult to identify an \(\)-optimal arm. In difficult instances with small \((x^{*},x)+\), the different orders of this term in \(T_{}(x)\), \(T_{}(x_{},x)\) and \(T_{}(x)\) indicate that, \(T_{}(x)\) is small compared to \(T_{}(x)\) and \(T_{}(x_{},x)\).

**Secondly,** DE solely utilizes context samples generated with \(P_{}\) and they are generated _only_ at changepoints in \(\), while all the observations in Exp phases facilitate VE. From this perspective, there are less samples that can be used for DE than for VE as PS\(\)BAI processes, and hence \(T_{}(x_{},x)\) is supposed to be with larger order than \(T_{}(x)\).

**Moreover,** for the purpose of DE, PS\(\)BAI needs to observe context samples at \((x_{},x)}{((x^{*},x^{*})+ )^{2}}=_{ }(x_{},x)}{L_{}}\) changepoints where \(L_{}\) is the maximum length of a stationary segment, leading us to \(T_{}(x_{},x)\). Close examination of the definition of \((x_{},x)\) reveals that _both_ the vectors and their probabilities influence the number of samples needed for DE. The comparison between \(T_{}(x_{},x)\) and \(T_{}^{}\) in Proposition 3.1 clearly indicates that PS\(\)BAI mitigates the influence of \(L_{}\) by detecting changepoints and aligning the detected context with observed ones, while N\(\)BAI does not do so.

### Ps\(\)Bai\({}^{+}=\) Ps\(\)Bai\(\,\) N\(\)Bai

We have provided a _high-probability_ result for PS\(\)BAI in Theorem 3.2. The design of PS\(\)BAI (Line 7 of Algorithm 1) indicates that PS\(\)BAI will not recommend any arm if it does not terminate at time \(^{*}\). This result is nontrivial, as the high-probability result in Theorem 3.2 depends on the success of change detection (Algorithm 3) and context alignment (Algorithm 4), which requires a non-vanishing failure probability (e.g., \(/2\)). Thus, we cannot derive an upper bound on the expected sample complexity of PS\(\)BAI. We devise a solution by designing the Piecewise-Stationary \(\)-Best \(}\) Identification\({}^{+}\) (PS\(\)BAI\({}^{+}\)) algorithm with a simple but effective trick.

The PS\(\)BAI\({}^{+}\) algorithm samples _one_ arm with the G-optimal allocation \(^{*}\) at each time step, with which Algorithms 1 and 2 are executed in parallel (detailed in Algorithm 5). This is feasible since PS\(\)BAI and N\(\)BAI algorithms have the same sampling rule.

**Theorem 3.3**.: _The PS\(\)BAI\({}^{+}\) algorithm is \((,)\)-PAC and its expected sample complexity is_

\[_{x_{}_{ },x x_{},x^{*}}T_{}(x)+T_{}(x_{ },x)+T_{}(x),\,T_{}^{}+T_{} ^{}}.\]

PS\(\)BAI\({}^{+}\) inherits the superiority of PS\(\)BAI to adapt to the piecewise stationary environment, and employs the stopping rule of N\(\)BAI to maintain a finite expected sample complexity. As a result, the expected complexity of PS\(\)BAI\({}^{+}\) in Theorem 3.3 is of the same order as the high-probability one of PS\(\)BAI in Theorem 3.2 and is not larger than the complexity of N\(\)BAI in Proposition 3.1. We show how our results particularize to the _stationary_ linear bandits BAI problem, as well as additional discussions on the upper bound, in Appendix P.

## 4 Lower Bound on the Sample Complexity

Given \(=(,,P_{},)\), define the alternative instance \(^{}=(,^{},P_{^{}},)\) w.r.t. \(\), where \(^{}=(_{1}^{},,_{n}^{}) ^{d N}\), \(P_{^{}}[_{j}^{}]=P_{}[_{j}^{*}]\), and there exists \(x_{}\), such that \(x_{}^{}_{^{} P_{^{}}}[ ^{}]<x^{}_{^{} P_{^{}}} [^{}]-\) for all \(x_{}_{}\). Let \(_{}()\) be set of all alternative instances (w.r.t. \(\)).

**Theorem 4.1**.: _For all \((,)\)-PAC algorithm \(\), there exists an instance \(=(,,P_{},)\) such that_

\[[_{}]\{T_{}(),\,c_{N_{}}\},\]

_where_

\[T_{}()^{-1}:=_{\{v_{j}\}_{j=1}^{N}^{ }_{}()}_{j,x}p_{j}v_{j,x}( _{j}^{*}-_{j}^{}))^{2}}{2},\] \[N_{}:=_{x x^{*}}p_{j}(_{j}( x^{*},x)+)^{2}}{((x^{*},x)+)^{2}}.\]

Recall that \(c_{N_{}}\) is the \(N_{}\)-th changepoint in the changepoint sequence \(\), which is lower bounded by \(N_{}L_{}\) and is \(N_{}L_{}\) in the worst case. To derive the lower bound in Theorem 4.1, we investigate two environments different from the one defined in Section 2 (and as in Dynamics 1):

\(\) Dynamics 2: the agent observes the index of current context \(j_{t}\) (i.e., contextual linear bandits);

\(\) Dynamics 3: the agent observes the changepoints in \(\) and context vector \(_{j_{t}}^{*}\)'s, and hence she solely needs to estimate the distribution of contexts.

We bound the sample complexity of an \((,)\)-BAI algorithm in Dynamics 2 and 3 respectively, which when combined, yield the lower bound in Theorem 4.1; this is detailed in Appendix M.

Note that \(T_{}()^{-1}\) in the lower bound generalizes  to the setting of linear bandits. In addition, Theorem 4.1 can be reduced to a bound in stationary linear bandits with one latent vector  (see the discussion leading to (M.15)).

## 5 On the Asymptotic Optimality of PS\(\)Bai\({}^{+}\)

To illustrate the efficiency of our PS\(\)BAI\({}^{+}\) algorithm, we compare the upper bound on its expected sample complexity in Theorem 3.3 and the generic lower bound in Theorem 4.1 under specific instances below and in Appendix N. We also gain further insight into our PS\(\)BAI\({}^{+}\) algorithm.

**Example 1**.: _Instance \(=(,,P_{},)\) is with (i) \(2d-1\) arms: \(x_{(1)}=_{1},x_{(i)}=_{i},x_{(d+i-1)}=_{1} +_{i}\) for all \(i\{2,,d\}\) where \([0,/4)\), (ii) \(2d-2\) contexts: \(^{*}_{j}=_{1}_{j+1}\) for all \(j[d-1],\) (iii) Context distribution: \(p_{j}=1/N\) for all \(j[N]\)._

Under the instance defined in Example 1, \(x_{(i)}\) for all \(i 1\) is inferior to \(x_{(1)}\) under all contexts and \(x_{(i+d)}\) for all \(i[d-1]\) is marginally better than \(x_{(1)}\) by \(1-\) only under context \(^{*}_{i+}\) and \((x_{(1)},x_{(i+d)})=-^{2}\). We expect PS\(\)BAI\({}^{+}\) to discover this feature of the instances and quickly identify an \(\)-optimal arm with a course estimation of the context distribution.

**Corollary 5.1**.: _For the instance defined in Example 1, we have \(_{}(x_{},x)=(NL_{})\) for all \((x_{},x)_{}( _{})\). In addition, if \(<()(1-)\), we have_

\[[]^{*}}{(1/)}\ (1 \!+\!f()),x_{(d+1)}}\!+\!)^{2}} ,\] (5.1)

_where \([]^{*}\) is the minimal expected sample complexity over all \((,)\)-PAC algorithms and \(f:\) satisfies \(f() 0\) as \( 0^{+}\). The upper bound in (5.1) is achieved by PS\(\)BAI\({}^{+}\)._

The order of \(_{}\) in Corollary 5.1 indicates that \(T_{}(x_{(1)},x_{(d+1)})=(NL_{}(1/))\) is not dominating the sample complexity of PS\(\)BAI\({}^{+}\), suggesting that a coarse estimation of the context distribution is sufficient when \(\) is small. In other words, PS\(\)BAI\({}^{+}\) exploits the feature of instances and utilize samples mostly for estimate context vectors, which is again expected.

Corollary 5.1 implies that under such instances, the upper and lower bounds on the sample complexity of PS\(\)BAI\({}^{+}\) match up to logarithmic factors, that is, the performance PS\(\)BAI\({}^{+}\) is near optimal. Besides, the bound of N\(\)BAI in Proposition 3.1 is with an extra additive term \(L_{}\) compared to the lower bound in Corollary 5.1, illustrating that N\(\)BAI is suboptimal and again emphasizing the significance of detecting changes and aligning contexts for PS\(\)BAI\({}^{+}\) to reduce the impact of \(L_{}\).

## 6 Numerical Experiments

We now evaluate the empirical performance of PS\(\)BAI\({}^{+}\). We utilize the instance defined in Example 1 with \(d=2\), \(=/8\), We generate a changepoint sequence \(\) such that \(c_{l+1}=c_{l}+L_{l}\) with \(L_{}=3 10^{4}\), \(L_{}=5 10^{4}\), \([L_{l}=L_{}]=0.8\), \([L_{l}=L_{}]=0.2\), and fix it throughout the whole set of experiments. We set the confidence parameter \(=0.05\) and vary the slackness parameter \(\) from \(0.04\) to \(0.6\) (i.e., \(=0.03 1.35^{k}\) for \(k\)). We set \(=6\), the window size \(w=L_{}/(3)\) and compute \(b\) via (3.5) in Assumption 1.3 For each choice of algorithm and instance, we run \(20\) independent trials. All the code to reproduce our experiments can be found at https://github.com/Y-Hou/BAI-in-PSLB.git.

We **first** compare PS\(\)BAI\({}^{+}\) and N\(\)BAI. Both algorithms succeed to identify an \(\)-optimal arm, while empirically, the complexity of PS\(\)BAI\({}^{+}\) is \( 1\%\) of that of N\(\)BAI. The empirical averages and standard deviations of the sample complexities of both algorithms are presented in Figure 2(a).

Figure 2: Experimental resultsFigure 2(a) illustrates that empirically, the termination and arm recommendation of PS\(\)BAI\({}^{+}\) are determined by the execution of PS\(\)BAI as a subroutine, suggesting that in Theorem 3.3, the first term resulting from PS\(\)BAI actually determines the complexity of PS\(\)BAI\({}^{+}\).

**Next,** we test the efficacy of PS\(\)BAI\({}^{+}\) to learn and exploit the latent vectors and the distribution of contexts. Specifically, we run PS\(\)BAI\({}^{+}\) and N\(\)BAI under Dynamics 1 where neither the index nor the vector of current context is visible to the agent. We also run benchmark algorithms: D\(\)BAI and its variant D\(\)BAI\({}_{}\) under Dynamics 3 where context vectors and changepoints are all observed; these two algorithms are detailed and analyzed in Appendix O.4.

As the changepoint sequence \(\) is fixed in a given instance and \(t/L_{} l_{t} t/L_{}\) for all \(t\), we regard the number of context samples \(l_{}\) as a proxy of the sample complexity \(\). We present the number of context samples need by PS\(\)BAI\({}^{+}\), N\(\)BAI, D\(\)BAI and D\(\)BAI\({}_{}\) for arm identification w.r.t. \(1/(_{}+)^{2}\) in Figure 2(b).

Figure 2(b) contains three messages. First, the complexity of PS\(\)BAI\({}^{+}\) scales as \(1/(_{}+)^{2}\), corroborating Theorem 3.3. Second, although PS\(\)BAI\({}^{+}\) has access to neither context vectors nor changepoints, it needs roughly the same number of context samples as D\(\)BAI and D\(\)BAI\({}_{}\), suggesting that it is competitive compared to these algorithms that have oracle information about the environment. Third, D\(\)BAI\({}_{}\) uses the confidence radius in (3.3) and terminates with fewer context samples compared to D\(\)BAI, implying that the confidence radius is well-designed.

**Furthermore,** when \(\) decreases from \(0.03 1.35^{12}\) to \(0.03 1.35^{9}\), the complexity of PS\(\)BAI almost remains unchanged while that of N\(\)BAI increases rapidly as presented in instances \(9\) to \(12\) in Figure 2(a). Meanwhile, the number of context samples need by two algorithms are shown to be with the same pattern in Figure 2(b). This contrast indicates that the cost of distribution estimation (\(T_{}\) in (3.6)) for PS\(\)BAI\({}^{+}\) has been significantly minimized compared to N\(\)BAI.

**To summarize,** we emphasize that the empirical superiority of PS\(\)BAI\({}^{+}\) over N\(\)BAI implies that _the efficacy of_ PS\(\)BAI\({}^{+}\)_is inherited from_ PS\(\)BAI. Our experiments show that actively exploiting the context information, via changepoint detection and context alignment (as in PS\(\)BAI\({}^{+}\) and PS\(\)BAI) facilitates identifying the \(\)-optimal arm efficiently.

Similar to many existing algorithms in piecewise-stationary bandits [21; 10; 22], our algorithm requires Assumption 1 and the knowledge of \(L_{}\). These may not be available in practice. Thus, we conduct more experiments in Appendix O.2 to exhibit the robustness of PS\(\)BAI\({}^{+}\). Specifically, in Appendix O.2, we conduct experiments for the case in which \(L_{}\) is _misspecified_. In Appendix O.3, we alter the change detection frequency \(\) so that \(w\) and \(b\) change accordingly. In both sets of experiments, the overall sample complexity of PS\(\)BAI\({}^{+}\) does not vary significantly and retains its superiority over N\(\)BAI. We conclude that PS\(\)BAI\({}^{+}\) is robust to slight misspecifications in these parameters, as long as Assumption 1 is not severely violated. Please refer to Appendix O for further details and experiments.

## 7 Conclusion and Future Work

We proposed a novel PSLB model and designed the PS\(\)BAI\({}^{+}\) algorithm to identify an \(\)-optimal arm with probability \( 1-\). The efficacy of PS\(\)BAI\({}^{+}\) has been demonstrated both empirically and theoretically. We argued that this is due to the embedded change detection and context alignment procedures. There are several directions for further exploration.

**Firstly,** our PS\(\)BAI\({}^{+}\) algorithm provides a fairly general _framework_ for algorithm design. For instance, in addition to utilization the G-optimal allocation to sample arms as in PS\(\)BAI\({}^{+}\), the \(\)-allocation and adaptive \(\)-allocation  can also be considered. In other words, our PS\(\)BAI\({}^{+}\) algorithm can be generalized to form an entire class of algorithms for BAI in PSLB models. In addition, deriving instance-dependent guarantees is also of great interest.

**Secondly,** most of the literature on piecewise-stationary bandits [21; 10; 22] make assumptions to provide theoretical guarantees. It would be interesting to remove or reduce these assumptions under our \(\)-BAI problem setup, and yet still be able to provide similar theoretical guarantees.

**Finally,** we believe that it is possible to adapt our PS\(\)BAI\({}^{+}\) algorithm to the fixed-budget setting, i.e., to identify an \(\)-optimal arm with high probability in a fixed time horizon in PSLB models.

Acknowledgements:This work is funded by the Singapore Ministry of Education AcRF Tier 2 grant (A-8000423-00-00) and Tier 1 grants (A-8000189-01-00 and A-8000980-00-00).