# Single-Loop Stochastic Algorithms for Difference of Max-Structured Weakly Convex Functions

Quanqi Hu \({}^{1}\) Qi Qi \({}^{2}\) Zhaosong Lu \({}^{3}\) Tianbao Yang \({}^{1}\)

\({}^{1}\) Department of Computer Science & Engineering, Texas A&M University

\({}^{2}\) Department of Computer Science, The University of Iowa

\({}^{3}\) Department of Industrial and Systems Engineering, University of Minnesota

{quanqi-hu, tianbao-yang}@tamu.edu qi-qi@uiowa.edu zhaosong@umn.edu

###### Abstract

In this paper, we study a class of non-smooth non-convex problems in the form of \(_{x}[_{y}(x,y)-_{z}(x,z)]\), where both \((x)=_{y}(x,y)\) and \((x)=_{z}(x,z)\) are weakly convex functions, and \((x,y),(x,z)\) are strongly concave functions in terms of \(y\) and \(z\), respectively. It covers two families of problems that have been studied but are missing single-loop stochastic algorithms, i.e., difference of weakly convex functions and weakly convex strongly-concave min-max problems. We propose a stochastic Moreau envelope approximate gradient method dubbed SMAG, the first single-loop algorithm for solving these problems, and provide a state-of-the-art non-asymptotic convergence rate. The key idea of the design is to compute an approximate gradient of the Moreau envelopes of \(,\) using only one step of stochastic gradient update of the primal and dual variables. Empirically, we conduct experiments on positive-unlabeled (PU) learning and partial area under ROC curve (pAUC) optimization with an adversarial fairness regularizer to validate the effectiveness of our proposed algorithms.

## 1 Introduction

In this paper, we consider a class of non-convex, non-smooth problems in the following form

\[_{x^{d_{x}}}F(x):=_{y}(x,y)- _{z}(x,z)},\] (1)

where the sets \(^{d_{y}}\), \(^{d_{z}}\) are convex and compact, and the two component functions \((x,y)\) and \((x,z)\) are weakly-convex in terms of \(x\) and strongly-concave in the terms of \(y\) and \(z\), respectively. Both component functions are in expectation forms, i.e., \((x,y)=_{_{}}[(x,y;)]\) and \((x,z)=_{_{}}[(x,z;)]\). We refer to this class of problems as the Difference of Max-Structured Weakly Convex Functions (DMax) Optimization. DMax optimization unifies two emerging families of problems in optimization field, difference-of-weakly-convex (DWC) optimization

\[_{x^{d_{x}}}\{F(x):=(x)-(x)\},\] (2)

and weakly-convex-strongly-concave (WCSC) min-max optimization

\[_{x^{d_{x}}}F(x):=_{y}(x,y) }.\] (3)

Thus, DMax optimization has a wide range of applications in machine learning and AI, including applications of DWC optimization (e.g., positive-unlabeled (PU) Learning , non-convexsparsity-promoting regularizers , Boltzmann machines ) and applications of min-max optimization (e.g., adversarial learning [31; 22], distributional robust learning [8; 28], learning with non-decomposable loss ). In recent years, the scale of data and models significantly increased, leading to the demand of more efficient optimization methods. However, all existing stochastic methods for DWC optimization and non-smooth WCSC min-max optimization with state-of-the-art non-asymptotic convergence rate \((^{-4})\) are double-loop. As a result, these methods are complex regarding the implementation and require extensive hyperparameter tuning. To close this gap, we propose a single-loop stochastic algorithm for DMax optimization and provide non-asymptotic convergence analysis to match the state-of-the-art non-asymptotic convergence rate.

The main challenges of designing a single-loop method for DMax optimization are threefold. 1) given the weakly-convex nature of the component functions, their difference \(F(x)\) is not necessarily weakly-convex, resulting in a non-smooth non-convex optimization problem. 2) the component functions \(_{y}(x,y)\) and \(_{z}(x,z)\) require solving maximization subproblems, making unbiased estimations of their subgradients inaccessible. 3) existing work on non-smooth problems with DC or/and min-max structures heavily rely on inner loops to solve subproblems to a certain accuracy.

To address the first challenge, we apply Moreau envelope smoothing technique [24; 3] to the component functions individually and take their difference as a smooth approximation of the original objective. Inspired by existing work [32; 45], we show that solving the original DMax problem can be achieved by solving this smooth approximation. Consequently, the problem is transformed into a smooth problem with two layer of nested optimization structure, the Moreau envelope and the maximization from the min-max structure. In order to avoid inner-loop, we perform only one step of update for each of the nested optimization problems. Our analysis leverages the fast convergence of strongly convex/concave problems, proving that single-step updates are sufficient to achieve a state-of-the-art convergence rate. Although the Moreau envelope smoothing is not new for solving DC and min-max optimization [32; 45; 47; 43], the existing results either require double loops [32; 45] or require smoothness of the objective function [47; 43].

**Contributions.** We summarize the main contribution of this work as following.

* We construct a new framework DMax optimization that unifies the DWC optimization and WCSC min-max optimization. Based on a Moreau envelope smoothing technique, we propose a single-loop stochastic algorithm, namely SMAG, for DMax optimization in non-smooth setting, which achieves \((^{-4})\) convergence rate.
* We show that the proposed method leads to the first single-loop stochastic algorithms for DWC optimization and non-smooth WCSC min-max optimization achieving \((^{-4})\) convergence rate.
* Finally, we present experimental results on applications including Positive-Unlabeled (PU) Learning and partial AUC optimization with an adversarial fairness regularizer to validate the effectiveness of our proposed algorithms.

## 2 Related Work

**Stochastic DC Optimization.** DWC can be converted into Difference-of-convex (DC) programming. DC programming was initially introduced in  and has been extensively studied since then. A comprehensive review on the developments of DC programming can be found in . Despite the

   Method & Smoothness of \(,\) & Complexity & Loops \\  SDCA  & \(\): Smooth & \((^{-4})\) & Double \\ SSDC  & \(\) or \(\): \(\)-Holder continuous gradient & \((^{-4/})\) & Double \\ SBCD\({}^{*}\) & Non-smooth & \((^{-6})\) & Double \\ SMAG (ours) & Non-smooth & \((^{-4})\) & Single \\   

Table 1: Comparison with existing stochastic methods for solving DWC problems with non-asymptotic convergence guarantee. \({}^{*}\) The method SBCD is designed to solve a problem in the form of \(_{x}\{_{y}(x,y)-_{z}(x,z)\}\) with a specific formulation of \(\) and \(\). However, the method and analysis can be generalized to solving non-smooth DWC problems.

rich literature on DC programming, DC in stochastic setting has rarely been mentioned until recently. Most of the existing studies on stochastic DC optimization are based on the classical method, DC Algorithm (DCA) in deterministic DC optimization. The main idea of DCA is to approximate the DC problem by a convex problem by taking the linear approximation of the second component. In other words, DCA solves \(_{x}\{(x)-(x_{k}),x\}\) to update \(x_{k}\) and thus forms a double-loop algorithm.  first proposed stochastic DCA (SDCA) for solving large sum problems of non-convex smooth functions, which was further generalized to solving large sum non-smooth problems in .  is the first work that allows both components in DC problems to be non-smooth. The authors proposed a SDCA scheme in the aggregated update style, where all past information needs to be stored for constructing future subproblems.  improved the efficiency of the SDCA scheme by removing the need of storing historical information. So far, none of the above work provides non-asymptotic convergence guarantee. The first non-asymptotic convergence analysis was established in . The authors proposed a stochastic proximal DC algorithm (SPD), which modifies SDCA by adding an extra quadratic term after linearizing the second component function, and proved that SPD has a convergence rate of \((^{-4})\). The main drawback of their analysis is that they need the smoothness assumption of the first component function. With very similar algorithm design,  managed to partially relax the smoothness assumption. Given at least one of the two component functions having \(\)-Holder continuous gradient, i.e., \(\| f(x)- f(x^{})\|\|x-x^{}\|^{}\) for all \(x,x^{}\), they proved a convergence rate of \((^{-4/})\). In fact, the Holder continuous gradient assumption is still fairly strong as some of the common non-smooth functions do not satisfy, for example the hinge loss function.

Recently, another approach to tackling the non-smoothness in DC problems has been considered. Following the smoothing technique in non-smooth weakly-convex optimization literature  constructed Moreau envelope smoothing approximations for both of the component functions respectively and established non-asymptotic convergence analysis under deterministic setting and the assumption that either one component function is smooth or the proximal-point subproblems can be solved exactly. Following a similar idea,  studied a problem in the form of \(_{x}F(x):=_{y}(x,y)-_{z}(x,z)\), where \(\) and \(\) are in some specific formulations, and proposed a double-loop algorithm with \((^{-6})\) convergence rate. Although the \(\) and \(\) are non-smooth, their analysis heavily relies on the properties in the given formulation, especially the structures in the dual variables \(y,z\), thus is not trivial to generalize.

Note that none of the aforementioned work is able to solve the DMax problem, as they require unbiased stochastic gradient estimations of the two component functions, which are not accessible in DMax due to the presence of the maximization structure.

**Stochastic Non-smooth Weakly-Convex-Strongly-Concave Min-Max Optimization.** Stochastic WCSC min-max optimization has been an emerging topic in recent years. Most of the existing works focuses on the smooth setting, i.e., the objective is smooth  or the stochastic gradient oracles are Lipschitz continuous . To the best of our knowledge,  is the first work that considers non-smooth WCSC min-max problems. They considered a special structure where the maximization over \(y\) given \(x\) can be simply solved and it is solved with \(O(1/^{2})\) times. They proposed a nested method Proximally Guided Stochastic Mirror Descent Method (PG-SMD) that achieves a convergence rate of \((^{-4})\). Later,  further relaxed the assumption by removing the requirement of the special structure, and proved that their nested method Epoch-GDA

   Method & \(f(x,y)\) & \(g(y)\) & \(h(x)\) & Complexity & Loops \\  PG-SMD  & NS, WCC & NSP, SC & NSP, C & \((^{-4})\) & Double \\ SAPD+  & SSC & NSP, C & NSP,C & \((^{-4})\) & Double \\ Epoch-GDA  & NS, WCSC & - & - & \((^{-4})\) & Double \\ StocAGDA  & SSC & NSP, C & NSP, C & \((^{-4})\) & Single \\ SMAG (ours) & NS,WCSC & - & - & \((^{-4})\) & Single \\   

Table 2: Comparison with existing stochastic methods for solving non-convex non-smooth min-max problems. The objective function is in the form of \((x,y)=f(x,y)-g(y)+h(x)\). NS and S stand for non-smooth and smooth respectively, and NSP means non-smooth and its proximal mapping is easily solved. WC, C stand for weakly-convex and convex respectively. WCSC stands for weakly-convex-strongly-concave, SSC stands for smooth and strongly concave and WCC means weakly-convex-concave. Note that Epoch-GDA and SMAG studies the general formulation \((x,y)=f(x,y)\).

has a similar convergence rate of \((^{-4})\). Another line of work studies a special case of the general non-smooth non-convex min-max optimization, where the objective is assumed to be composite, i.e., \((x,y)=f(x,y)-g(y)+h(x)\), so that \(f\) is smooth while \(g,h\) are potentially non-smooth . Both works established \((^{-4})\) convergence rate, and assume \(f\) is smooth and strongly concave, \(g\) and \(h\) are convex but potentially non-smooth and their proximal mappings can be easily solved. However, none of them is applicable to the general non-smooth WCSC min-max optimization.

## 3 Preliminaries

**Notations.** For simplicity, we denote \((x):=_{y}(x,y)\), \((x):=_{z}(x,z)\), \(y^{*}():=_{y}(,y)\), and \(z^{*}():=_{z}(,z)\). We use \(\|\|\) to denote the Euclidean norm of a vector and \(P_{}()\) to denote the Euclidean projection onto a closed set \(\). We use the following definitions of general subgradient and subdifferential .

**Definition 3.1** (subgradient and subdifferential).: Consider a function \(f:^{d}\{\}\) and a point \(x\) with finite \(f(x)\). A vector \(v^{d}\) is a general subgradient of \(f\) at \(x\) if

\[f(y) f(x)+ v,y-x+o(\|y-x\|)y x.\]

The subdifferential \( f(x)\) is the set of subgradients of \(f\) at point \(x\).

For simplicity, we abuse the notation \( f(x)\) to denote one subgradient from the corresponding subdifferential when no confusion could be caused. We use \(f(x)\) and \(f(x)\) to represent an unbiased stochastic estimator of the subgradient \( f(x)\) and the gradient \( f(x)\) respectively. A function \(f:\) is said to be \(L\)-smooth if \(\| f(x)- f(x^{})\| L\|x-x^{}\|\) for all \(x,x^{}\). A function \(f:^{d}\{\}\) is \(\)-weakly convex if \(f()+\|\|^{2}\) is convex. A mapping \(:^{l}\) is said to be \(C\)-Lipschitz continuous if \(\|(x)-(x^{})\| C\|x-x^{}\|\) for all \(x,x^{}\).

Consider solving a non-smooth problem \(_{x}f(x)\). One of the main challenges is that the \(\)-stationary point, i.e., a point \(x\) such that \((0, f(x))\), which is the typical goal for smooth problems, may not exist in the neighborhood of its optimal solution. A classical counter example would be \(f(x)=|x|\), where for \([0,1)\) the only \(\)-stationary point is the optimal solution \(x=0\). A standard solution to this issue in weakly-convex setting is to use a relaxed convergence criteria, that is to find a point no more than \(\) away from an \(\)-stationary point. This is called a nearly \(\)-stationary point, and is widely used in non-smooth weakly-convex optimization literature . In fact, finding a nearly \(\)-stationary point for \(f(x)\) can be achieved by finding an \(\)-stationary point of \(f_{}(x)\), the Moreau envelope of \(f(x)\). Assume function \(f\) is \(\)-weakly-convex, then its Moreau envelope and proximal map are given by

\[f_{}(x):=_{x^{}}f(x^{})+\|x^{ }-x\|^{2}},_{ f}(x):=*{arg\, min}_{x^{}}f(x^{})+\|x^{}-x\|^{2} }.\]

Existing work  has shown that with \((0,^{-1})\) and \(=_{ f}(x)\), we have

\[ f_{}(x)=^{-1}(x-), f() f(x), (0, f())\| f_{}(x)\|.\]

Moreover, \(_{ f}(x)\) is \(}\) - Lipschitz continuous .

Now we consider the DMax problem (1). By Danskin's Theorem, the weak convexity assumption of \((,y)\) and \((,z)\) naturally leads to the weak convexity of \(()\) and \(()\). Since the weak convexity assumption of component functions does not guarantee the weak convexity of their difference function \(F(x)\), one may neither 1) use nearly \(\)-stationary point of \(F(x)\) as the convergence metric, nor 2) directly apply Moreau envelope smoothing technique to \(F(x)\). To tackle the first issue, we follow the existing work  to use the following convergence metric for non-smooth DWC problems.

**Definition 3.2** (Definition 2 in ).: Given \(>0\), we say \(x\) is a **nearly \(\)-critical point** of \(_{x}\{F(x):=(x)-(x)\}\) if there exist \(v,x^{},x^{}\) such that \(v(x^{})-(x^{})\) and \(\{\|v\|,\|x-x^{}\|,\|x-x^{} \|\}\).

To tackle the second issue, we take the Moreau envelope of \(()\) and \(()\) individually and define the smooth approximation of \(F(x)\) as

\[F_{}(x)=_{}(x)-_{}(x).\] (4)

The recent work  has proven that \(F_{}(x)\) is indeed smooth.

**Proposition 3.3** (Proposition EC.1.2 in ).: _Assume \(()\) and \(()\) are \(_{},_{}\)-weakly convex respectively. Then \(F_{}(x)=_{}(x)-_{}(x)\) is \(L_{F}\)-smooth, where \(L_{F}=\{_{},_{}\}}\)._

Moreover, one can show that a good approximate stationary point \(x\) of \(F_{}()\) and a good approximation point \(x^{}\) to the proximal points \(_{}(x)\) and \(_{}(x)\) can guarantee that \(x^{}\) is a nearly \(\)-critical point of \(_{}F()\).

**Lemma 3.4** (Lemma 3 in ).: _Assume \(()\) and \(()\) are \(_{},_{}\)-weakly convex respectively, and \(0<<\{_{}^{-1},_{}^{-1}\}\). If \(x\) is a vector such that \([\| F_{}(x)\|^{2}]\{1,^{-2}\}^{2}/4\), and \(x^{}\) is a vector such that \([\|x^{}-_{}(x)\|^{2}]^{2}/4\) or \([\|x^{}-_{}(x)\|^{2}]^{2}/4\), then \(x^{}\) is a nearly \(\)-critical point of \(_{}F()\)._

## 4 Algorithms and Convergence

Since we aim to minimize the smooth function \(F_{}(x)\), the natural strategy is to perform gradient descent to update the variable \(x\). Following from the properties of Moreau envelope, the gradient of \(F_{}(x)\) is given by

\[ F_{}(x)=\|(x-_ {}(x))\|}{}\,-(x-_{ }(x))\|,\] (5)

where the blue component is the gradient of \(_{}(x)\) and the green component is the gradient of \(_{}(x)\). However, the proximal points \(_{}(x)\) and \(_{}(x)\) are not accessible in general. Indeed, these proximal points are the optimal solutions to \(_{x^{}}\{(x^{})+\|x-x^{}\|^{2}\}\) and \(_{x^{}}\{(x^{})+\|x-x^{}\|^{2}\}\) respectively, and \(()\) and \(()\) are typically not accessible because they are the value functions of possibly sophisticated maximization problems. Thus, we maintain two variables \(x_{}^{t}\) and \(x_{}^{t}\) as the estimators of \(_{}(x_{t})\) and \(_{}(x_{t})\) respectively, and maintain another two variables \(y_{t}\) and \(z_{t}\) as the estimators of \(_{y}(_{}(x_{t}),y)\) and \(_{z}(_{}(x_{t}),z)\) respectively. At each iteration, we update \(x_{}^{t}\) and \(x_{}^{t}\) by one step of stochastic gradient descent, and update \(y_{t}\) and \(z_{t}\) by one step of stochastic gradient ascent. Finally, we compute the gradient estimator \(G_{t+1}=(x_{t}-x_{}^{t+1})-(x_{t}-x_{ }^{t+1})\) of \( F_{}(x_{t})\) and update \(x_{t}\) by one step of gradient descent. The resulting algorithm is presented in Algorithm 1.

```
1:Input Initial points: \(x_{}^{0}\), \(x_{}^{0}\), \(x_{0}\), \(y_{0}\), \(z_{0}\). Hyper-parameters: \(,_{0},_{1}\).
2: Stochastic (sub) gradients: \(_{x}\), \(_{y}\), \(_{x}\), \(_{z}\).
3:for\(t=0,,T-1\)do
4:\(_{}^{t+1}=_{}^{t}-_{1}(_{x}(x_{ }^{t},y_{t})+(x_{}^{t}-x_{}))\)
5:\(y_{t+1}=P_{}y_{t}+_{1}_{y}(x_{}^{t },y_{t})\)
6:\(x_{}^{t+1}=x_{}^{t}-_{1}(_{x}(x_{}^{t},z_{t })+(x_{}^{t}-x_{}))\)
7:\(z_{t+1}=P_{}z_{t}+_{1}_{z}(x_{}^{t },z_{t})\)
8:\(G_{t+1}=(x_{t}-x_{}^{t+1})\,-\, (x_{t}-x_{}^{t+1})\)
9:\(x_{t+1}=x_{t}-_{0}G_{t+1}\)
10:endfor
11:return\(x_{}^{t}\) or \(x_{}^{}\) with \(\) uniformly sampled from \(\{1,,T\}\) ```

**Algorithm 1** Stochastic Moreau Envelope Approximate Gradient Method (SMAG)

**DWC Optimization.** For DWC problem (2), the associated functions \(()=()\) and \(()=()\) are directly accessible. Thus the variables \(y_{t}\) and \(z_{t}\) in SMAG are no longer needed. The simplified SMAG algorithm for DWC optimization is presented in Algorithm 2.

**WSC Min-Max Optimization.** For WSC Min-Max problem (3), the second component function \(=0\) can be ignored, and thus variables \(x_{}^{t}\) and \(z_{t}\) are no longer needed. However, this brings achange to the gradient of \(F_{}(x_{t})\) as it now becomes

\[ F_{}(x_{t})=^{-1}(x_{t}-_{}(x_{t})).\]

The simplified SMAG algorithm for WCSC Min-Max optimization is presented in Algorithm 3.

```
1:for\(t=0,,T-1\)do
2:\(x_{}^{t+1}=x_{}^{t}-_{1}(_{x}(x_{}^{t})+ (x_{}^{t}-x_{t}))\)
3:\(x_{}^{t+1}=x_{}^{t}-_{1}(_{x}(x_{}^{t})+ (x_{}^{t}-x_{t}))\)
4:\(G_{t+1}=(x_{t}^{t+1}-x_{}^{t+1})\)
5:\(x_{t+1}=x_{t}-_{0}G_{t+1}\)
6:endfor
7:return\(x_{}^{}\) or \(x_{}^{}\) with \(\{1,,T\}\) ```

**Algorithm 2** SMAG for DWC Optimization

### Convergence Analysis

In this section, we present convergence results for Algorithms 1-3. To proceed, we make the following assumption for DMax problem (1).

**Assumption 4.1**.: Considering DMax problem (1), we assume that

* \((,y)\) is \(_{}\)-weakly convex, and \((,z)\) is \(_{}\)-weakly convex.
* \((x,)\) is \(_{}\)-strongly concave, and \((x,)\) is \(_{}\)-strongly concave.
* \((x,y)\) and \((x,z)\) are differentiable in terms of \(y\) and \(z\) respectively, \(_{y}(,y)\) is \(L_{,yx}\)-Lipschitz continuous, and \(_{z}(,z)\) is \(L_{,zx}\)-Lipschitz continuous.
* There exists a constant \(F_{}^{*}>-\) such that \(F_{}^{*} F_{}(x)\) for all \(x\).
* There exists a finite constant \(M\) such that \(\|_{x}(x,y)\|^{2} M^{2}\), \(\|_{y}(x,y)\|^{2} M^{2}\), \(\|_{x}(x,z)\|^{2} M^{2}\), \(\|_{z}(x,z)\|^{2} M^{2}\) for all \(x^{d_{x}}\), \(y\) and \(z\).

It shall be noted that Assumption 4.1(iii) only requires partial smoothness of \(\) and \(\), and is to ensure the Lipschitz continuity of \(y^{*}():=_{y}(,y)\) and \(z^{*}():=_{z}(,z)\). This follows from existing results.

**Lemma 4.2** (Lemma 4.3 in ).: _Consider problem \(_{y}}f(x,y)\) for any \(x^{d_{x}}\), where \(}^{d_{y}}\) is a closed convex set. Assume that \(f(x,y)\) is \(\)-strongly concave in \(y\) for each \(x^{d_{x}}\), and \(_{y}f(,y)\) is \(L_{yx}\)-Lipschitz for each \(y}\). Then \(_{y}f(,y)\) is \(}{}\)-Lipschitz continuous._

A Lipschitz smooth function \(f(x,y)\) is guaranteed to have Lipschitz continuous partial gradient \(_{y}f(,y)\), while the reverse statement is not necessarily true. For example, consider a function \(f(x,y)=y^{}h(x)-g(y)\) with non-smooth \(C\)-Lipschitz continuous \(h()\) and strongly convex \(g\). Then \(f(x,y)\) is non-smooth but the partial subgradient \(_{y}f(,y)=h()- g(y)\) is Lipschitz continuous with respect to the first argument. Another example is given by \(f(x,y)=f_{1}(x)+f_{2}(x,y)\), where \(f_{1}\) is weakly convex and \(f_{2}\) is smooth and strongly concave in terms of \(y\). The latter is indeed seen in our considered application for pAUC maximization with adversarial fairness. In fact, one may replace Assumption 4.1(iii) by directly assuming that \(y^{*}()\) and \(z^{*}()\) are Lipschitz continuous. In addition, Assumption 4.1(v) is standard in non-smooth optimization literature [3; 39; 10].

Here we give a brief outline of the convergence analysis. First of all, we present a standard result .

**Lemma 4.3**.: _Suppose that \(F_{}()\) is \(L_{F}\)-smooth and \(x_{t+1}=x_{t}-_{0}G_{t+1}\) with \(0<_{0}}\). Then we have_

\[F_{}(x_{t+1}) F_{}(x_{t})+}{2}\| F_{}( x_{t})-G_{t+1}\|^{2}-}{2}\| F_{}(x_{t})\|^{2}-}{4}\|G_{t+1}\|^{2}.\]This implies that the key to bounding the gradient \(\| F_{}(x_{t})\|^{2}\) is to obtain a recursive bound for the gradient estimation error \(\| F_{}(x_{t})-G_{t+1}\|^{2}\). Following from the true gradient formulation 5, we have

\[\| F_{}(x_{t})-G_{t+1}\|^{2}}(\|x_{ }^{t+1}-_{}(x_{t})\|^{2}+\|x_{}^{t+1}-_ {}(x_{t})\|^{2}).\] (6)

In other words, the error of the gradient estimation \(G_{t+1}\) can be bounded by the estimation errors of \(x_{}^{t+1}\) and \(x_{}^{t+1}\). Thus, we construct recursive bound for the proximal point estimation errors \(\|x_{}^{t+1}-_{}(x_{t})\|^{2}\) and \(\|x_{}^{t+1}-_{}(x_{t})\|^{2}\) individually. In fact, these two errors share almost identical analysis due to similar assumptions and updates. Here we only present the result for function \(\), as the result for \(\) directly follows.

**Lemma 4.4**.: _Suppose that Assumption 4.1 holds, \(0<<1/_{}\), and \(_{1}(1/-_{})}{2}\). Then the sequences \(\{x_{t}\}\), \(\{y_{t}\}\), \(\{x_{}^{t}\}\) and \(\{G_{t}\}\) generated by Algorithm 1 satisfy_

\[\|x_{}^{t+1}-_{}(x_{t})\|^{2}+ _{t}\|y_{t+1}-y^{*}(_{}(x_{t}))\|^{2}\] \[(1-(1/-_{})}{2})\|x_{ }^{t}-_{}(x_{t-1})\|^{2}+(1-_{1}_{}) \|y_{t}-y^{*}(_{}(x_{t-1}))\|^{2}\] \[+(^{2}}{_{1}^{2}(1/- _{})^{3}}+^{2}_{0}^{2}}{_{1}_{}^{3} ^{2}(1/-_{})^{2}})\|G_{t}\|^{2}+12M^{2} _{1}^{2}.\]

Finally, combining Lemma 4.3, inequality (6) and Lemma 4.4 yields the following convergence result for Algorithm 1.

**Theorem 4.5**.: _Suppose that Assumption 4.1 holds, \(0<<\{_{}^{-1},_{}^{-1}\}\), \(_{1}=(^{2})\), and \(_{0}=_{1}\). Then after \(T(^{-4})\) iterations, the sequences \(\{x_{t}\}\), \(\{x_{}^{t}\}\) and \(\{x_{}^{t}\}\) generated by Algorithm 1 satisfy \([\|x_{}^{}-_{}(x_{t-1})\|^{2}+\|x_{ }^{}-_{}(x_{t-1})\|^{2}+\| F_{}(x _{-1})\|^{2}]\{1,^{-2}\}^{2}/4\), and the outputs \(x_{}^{}\) and \(x_{}^{}\) are both nearly \(\)-critical points of problem (1)._

Since DMax optimization is a unified framework covering DWC optimization and WCSC min-max optimization, the convergence results of Algorithms 2 and 3 directly follow from Theorem 4.5. To present them, we first provide a reduced version of Assumption 4.1 for DWC problem (2).

**Assumption 4.6**.: Considering DWC problem (2), we assume that

* \(()\) is \(_{}\)-weakly convex, and \(()\) is \(_{}\)-weakly convex.
* There exists a constant \(F_{}^{*}>-\) such that \(F_{}^{*} F_{}(x)\) for all \(x\).
* There exists a finite constant \(M\) such that \(\|(x)\|^{2} M^{2}\) and \(\|(x)\|^{2} M^{2}\) for all \(x^{d_{x}}\).

By setting \((x,y)=(x)\) and \((x,z)=(x)\), namely independent of \(y\) and \(z\), in DMax problem (1), we obtain the following convergence result for Algorithm 2, which is an immediate consequence of Theorem 4.5.

**Corollary 4.7**.: _Suppose that Assumption 4.6 holds, \(0<<\{_{}^{-1},_{}^{-1}\}\), \(_{1}=(^{2})\), and \(_{0}=_{1}\). Then after \(T(^{-4})\) iterations, the outputs \(x_{}^{}\) and \(x_{}^{}\) of Algorithm 2 are both nearly \(\)-critical points of problem (2)._

For WCSC min-max problem (3), we reduce Assumption 4.1 to the following.

**Assumption 4.8**.: Considering WCSC min-max problem (3), we assume that

* \((,y)\) is \(_{}\)-weakly convex, and \((x,)\) is \(_{}\)-strongly concave.
* \((x,y)\) is differentiable in terms of \(y\), and \(_{y}(,y)\) is \(L_{,yx}\)-Lipschitz continuous.
* There exists a constant \(F_{}^{*}>-\) such that \(F_{}^{*} F_{}(x)\) for all \(x\).
* There exists a finite constant \(M\) such that \(\|_{x}(x,y)\|^{2} M^{2}\) and \(\|_{y}(x,y)\|^{2} M^{2}\) for all \(x^{d_{x}}\) and \(y\).

By setting \((x,z)=0\) in DMax problem (1), we obtain the following convergence result for Algorithm 3, which is an immediate consequence of Theorem 4.5.

**Corollary 4.9**.: _Suppose that Assumption 4.8 holds, \(0<<1/_{}\), \(_{1}=(^{2})\), and \(_{0}=_{1}\). Then after \(T(^{-4})\) iterations, the output \(x_{i}\) of Algorithm 3 is a nearly \(\)-stationary point of problem (3)._

It shall be mentioned that for WCSC min-max problem (3, we use nearly \(\)-stationary point as the convergence metric. This is standard in weakly-convex optimization literature .

## 5 Applications

In this section, we introduce two applications of DMax optimization, PU learning for DWC optimization and partial AUC optimization with adversarial fairness regularization for WCSC min-max optimization. We also show experimental results on both applications.

### Positive-Unlabeled Learning

In binary classification task, the optimization problem is commonly formulated as the minimization of empirical risk, i.e., \(_{^{d}}|}_{_{i} }(;_{i},y_{i})\) where \((;_{i},y_{i})\) is the loss given the model parameter \(\) on a data point \(_{i}\) and its ground truth label \(y_{i}\). Given the scenario where only positive data \(_{+}\) are observed, then the standard approach becomes problematic. One way to address this issue is to utilize unlabeled data \(_{u}\) to construct unbiased risk estimators. To be specific,  formulated the PU learning problem as following

\[_{^{d}}}{n_{+}}_{_{i} _{+}}[(;_{i},+1)-(; _{i},-1)]+}_{_{j}^{} _{u}}(;x_{j}^{u},-1)\] (7)

where \(n_{+}=|_{+}|\), \(n_{u}=|_{u}|\), \(_{p}=Pr(y=1)\) is the prior probability of the positive class. If \((;,y)\) is weakly convex in terms of \(\), then Problem (7) is a DWC problems. In particular, in our experiments we consider linear classification model and hinge loss.

**Baselines.** We implemented five baselines and compared them with our proposed method SMAG for DWC optimization. The first baseline, stochastic gradient descent (SGD), does not have theoretical convergence guarantee for DWC problems. However, since it is the fundamental method for convex optimization, we include it to show its performance. We also implemented existing stochastic methods for solving DC or DWC problems with non-smooth components, including SDCA , SSDC-SPG , SSDC-Adagrad  and SBCD .

**Datasets.** We use four multi-class classification datasets, Fashion-MNIST , MNIST  CIFAR10  and FER2013 . To fit them in binary classification task, we consider the first five classes as negative for Fashion-MNIST, MNIST and CIFAR10, and the first four classes as negative for FER2013. For Fashion-MNIST, MNIST, CIFAR10, we follow the standard train-test split. For FER2013, we take the first \(25709\) samples as the training data, and the rest as for testing.

**Setup.** For all datasets, we use a batch size of \(64\) and set \(_{p}=0.5\). We train \(40\) epochs and decay the learning rate by \(10\) at epoch \(12\) and \(24\). The learning rates of SGD, SDCA, SSDC-SPG and SSDC-Adagrad, the learning rate of the inner loop of SBCD (i.e., \(_{t}/(+_{t})\)), and \(_{1}\) in SMAG are all tuned from \(\{10,1,0.2,0.1,0.01,0.001\}\). The learning rate of the outer loop in SDCA and \(_{0}\) in SMAG are tuned from \(\{0.1,0.5,0.9\}\). The numbers of inner loops for all double-loop methods are tuned from \(\{2,5,10\}\). The \(\) in SBCD, \(1/\) in SSDC-SPG and SSDC-Adagrad, \(\) in SMAG are tuned in \(\{0.05,0.1,0.2,0.5,1,2\}\). We run \(4\) trails for each setting and plot the average curves.

**Results.** We plot the curves of training losses in Figure 1. For all tested datasets, the performance of SMAG surpasses the baselines. Among the baselines, SBDC is the generally the next best choice. However, since SBDC is a double-loop method, it has one more hyperparameter compared to SMAG. We also present the ablation study of SMAG regarding the parameter \(\) in Figure 2 included in the Appendix.

### Partial AUC Maximization with Fairness Regularization

AUC Maximization aims to maximize the area under the curve of true positive rate (TPR) vs false positive rate (FPR). It has been studied extensively  and has shown great success in large-scale real-world tasks, e.g., medical image classification  and molecular properties prediction . One-way partial AUC (OPAUC) is an extension of AUC that has a primary interest in the curve corresponding to low FPR. To be specific, OPAUC restrict the FPR to the region \([0,]\) where \((0,1)\). A recent work  proposed to formulate OPAUC problem into a non-smooth weakly convex optimization problem using conditional-value-at-risk (CVaR) based distributionally robust optimization (DRO). The formulation is given by

\[_{,^{n_{+}}}F_{}(, )=}_{_{i}_{+}}(s_{i} +}_{_{j}_{-}}(L(; _{i},_{j})-s_{i})_{+}),\] (8)

where \(_{+},_{-}\) are the sets of positive and negative samples respectively, \(n_{+}=|_{+}|\), \(n_{-}=|_{-}|\), and \(\) denotes the weights of encoder network and classification layer. The pairwise surrogate loss is defined by \(L(;_{i},_{j})=(h(,_{i}) -h(,_{j}))\) and we use squared hinge loss as the surrogate loss, i.e., \(()=(c-)^{2}\), where \(c>0\) is a parameter.

However, directly solving the above problem may end up with a model that is unfair with respect to some protected groups (e.g., female patients). Hence, we consider a formulation that incorporates an adversarial fairness regularization:

\[_{_{a}}F_{}(,_{a}):=_{ (,a)_{a}}\{(a=1)((,_{a},))+(a=-1)(1-(, _{a},))\},\]

where \((,_{a},)\) denotes a predicted probability that the data has a sensitive attribute \(a=1\) by using a classification head \(_{a}\) on top of the encoded representation of \(\). This adversarial fairness regularization has been demonstrated effective for promoting fairness . As a result, we consider OPAUC problem with a fairness regularization:

\[_{,^{n_{+}}}_{_{a}}F_{ }(,)+ F_{}(, _{a})+}{2}\|_{a}\|_{2}^{2}\] (9)

It is clear that the problem is WCSC.

**Baseline.** We implement our proposed method SMAG for solving OPAUC problem (8) and OPAUC problem with adversarial fairness regularization (9). We refer the former as SMAG\({}^{*}\) and the latter as SMAG. The baseline on OPAUC problem (8) is SOPA, proposed in . The baselines on OPAUC problem with adversarial fairness regularization (9) are SGDA  and Epoch-GDA .

**Dataset.** CelebA contains 200k celebrity face images with 40 binary attributes each, including the gender-sensitive attribute denoted as _Male_. In our experiments, we conduct experiments on three independent attribute prediction tasks: _Attractive, Big Nose, and Bags Under Eyes_, which have high Pearson correlations  with the sensitive attribute _Male_. We divide the dataset into training, validation, and test data with an 80%/10%/10% split.

**Setup.** For all experiments, we adopt ResNet-18 as our backbone model architecture and initialize it with ImageNet pre-trained weights. The batch size is 128. We set the FPR upper bound to be \(=0.3\). We train the model for 3 epochs with cosine decay learning rates for all baselines. The regularizer parameter \(\) is tuned in \(0.1,0.2,0.5\) for SGDA, Epoch-GDA, and SMAG, and the adversarial learning rates are tuned in \(0.001,0.01,0.1\). \(=0\) for SOPA and SMAG\({}^{*}\). The initial learning rates for optimizing \(\) are tuned in \(0.1,0.01,0.001\) for all methods, while the weight interpolation parameters,

Figure 1: Training Curves of PU Learningi.e., \(\) in Epoch-GDA and SMAG, are also tuned in \(0.1,0.01,0.001\). The inner loop step is tuned in \(\{5,10,15\}\) for Epoch-GDA. \(_{1}\) in SMAG are tuned from \(\{10,1,0.2,0.1,0.01,0.001\}\).

**Results.** We report the experimental results on three fairness metrics , equalized odds difference (EOD), equalized opportunity (EOP), and demographic disparity (DP) in Table 3. We observe that SMAG consistently achieves the highest pAUC score and lowest disparities metrics across all tasks compared to all other baseline min-max methods.

## 6 Conclusion

In this study, we have introduced a new framework namely DMax optimization, that unifies DWC optimization and non-smooth WCSC min-max optimization. We proposed a single-loop stochastic method for solving DMax optimization and presented a novel convergence analysis showing that the proposed method achieves a non-asymptotic convergence rate of \((^{-4})\). Experimental results on two applications, PU learning and OPAUC optimization with adversarial fairness regularization demonstrate strong performance of our method. One limitation of this work is the strong convexity assumption on the \((x,)\) and \((x,)\). This strong assumption may limit the applicability of our method. Future work will focus on exploring DMax optimization with weaker assumptions.