# Counterfactual Generation with Identifiability Guarantees

Hanqi Yan\({}^{1,4}\)

Lingjing Kong\({}^{2,*}\)

Lin Gui\({}^{3}\)

Yuejie Chi\({}^{2}\)

Eric Xing\({}^{2,4}\)

Yulan He\({}^{1,3}\)

Kun Zhang\({}^{2,4}\)

\({}^{1}\)University of Warwick,\({}^{2}\) Carnegie Mellon University,

\({}^{3}\)King's College London, \({}^{4}\)Mohamed Bin Zayed University of Artificial Intelligence

###### Abstract

Counterfactual generation lies at the core of various machine learning tasks, including image translation and controllable text generation. This generation process usually requires the identification of the disentangled latent representations, such as content and style, that underlie the observed data. However, it becomes more challenging when faced with a scarcity of paired data and labeling information. Existing disentangled methods crucially rely on oversimplified assumptions, such as assuming independent content and style variables, to identify the latent variables, even though such assumptions may not hold for complex data distributions. For instance, food reviews tend to involve words like "_tasty_", whereas movie reviews commonly contain words such as "_thrilling_" for the same positive sentiment. This problem is exacerbated when data are sampled from multiple domains since the dependence between content and style may vary significantly over domains. In this work, we tackle the domain-varying dependence between the content and the style variables inherent in the counterfactual generation task. We provide identification guarantees for such latent-variable models by leveraging the relative sparsity of the influences from different latent variables. Our theoretical insights enable the development of a do**M**ain **A**dap**T**ive **c**oun**T**erfactual **g**eneration model, called (**MATTE**). Our theoretically grounded framework achieves state-of-the-art performance in unsupervised style transfer tasks, where neither paired data nor style labels are utilized, across four large-scale datasets.

## 1 Introduction

Counterfactual generation serves as a crucial component in various machine learning applications, such as controllable text generation and image translation. These applications aim at producing new data with desirable style attributes (e.g., _sentiment, tense_, or _hair color_) while preserving the other core information (e.g., _topic_ or _identity_) . Consequently, the central challenge in counterfactual generation is to learn the underlying disentangled representations.

To achieve this goal, prior work leverages either paired data that only differ in style components , or utilizes style labeling information . However, collecting paired data or labels can be labour-intensive and even infeasible in many real-world applications . This has prompted recent work  to delve into unsupervised identification of latent variables by tapping into multiple domains. To attain identifiability guarantees, a prevalent assumption made in these works  is that the content and the stylelatent variables are independent of each other. However, this assumption is often violated in practical applications. First, the dependence between content and style variables can be highly pronounced. For example, to express a positive sentiment, words such as "_tasty_" and "_flavor_" are typically used in conjunction with food-related content. In contrast, words like "_thrilling_" are more commonly used with movie-related content [Li et al., 2019, 2022]. Moreover, the dependence between content and style often varies across different distributions. For example, a particular cuisine may be highly favored locally but not well received internationally. This varying dependence between content and style variables poses a significant challenge in obtaining the identifiability guarantee. To the best of our knowledge, this issue has not been addressed in previous studies.

In this paper, we address the identification problem of the latent-variable model that takes into account the varying dependence between content and style (see Fig 1). To this end, we adopt a natural notion of influence sparsity inherent to a range of unstructured data, including natural languages, for which the influences from the content and the style differ in their scopes. Specifically, the influence of the style variable on the text is typically sparser compared to that of the content variable, as it is often localized to a smaller fraction of the words [Li et al., 2018] and plays a secondary role in word selection. For instance, the tense of a sentence is typically reflected in only its verbs which are affected by the sentence content information. Our contributions can be summarised as: 1) We show identification guarantees for both the content and the style components, even when their interdependence varies. This approach removes the necessity for a large number of domains with specific variance properties [Kong et al., 2022, Xie et al., 2023]. 2) Guided by our theoretical findings, we design a do**Main Adap**Tive count**Terfactual g**E**eneration model (**MATTE**). It does not require paired data or style annotations but allows style intervention, even across substantially different domains. 3) We validate our theoretical discoveries by demonstrating state-of-the-art performance on the unsupervised style transfer task, which demands representation disentanglement, an integral aspect of counterfactual generation.

## 2 Related work

**Label-free Style Transfer on variation autoencoders (VAEs).** To perform style transfer, existing methods that use parallel or non-parallel labelled data often rely on style annotations to refine the attribute-bearing representations, although some argue that disentanglement is not necessary for style edit [Sudhakar et al., 2019, Wang et al., 2019, Dai et al., 2019]. In practice, disentangled methods typically employ adversarial objectives to ensure the content encoder remains independent of style information or leverage style discriminators to refine the derived style variables [Hu et al., 2017, Shen et al., 2017, Li et al., 2018, Keskar et al., 2019, John et al., 2019, Sudhakar et al., 2019, Dathathri et al., 2020, Hu et al., 2017, Dathathri et al., 2020, Yang and Klein, 2021, Liu et al., 2022]. Several studies have tackled this task without style labels. Riley et al.  emphasized the implicit style connection between adjacent sentences and used T5 [Raffel et al., 2020] to extract the style vector for conditional generation. CPVAE Xu et al.  split the latent variable into content and style variables and mapped them to a \(k\)-dimensional simplex for \(k\)-way sentiment modeling. Our work aligns more closely with CPVAE and follows VAE-based label-free disentangled learning from data-generation perspective Higgins et al. , Kumar et al. , Mathieu et al. , Xu et al. , Mita et al. , Fan et al. .

**Latent-variable identification.** Representation learning serves as the cornerstone for generative models, where the goal is to create representations that effectively capture underlying factors in the disentangled data-generation process. In the realm of linear generative functions, Independent component analysis (ICA) [Comon, 1994, Bell and Sejnowski, 1995] is a classical approach known for its identifiability. However, when dealing with nonlinear functions, ICA is proven unidentifiable without the inclusion of additional assumptions [Hyvarinen and Pajunen, 1999]. To tackle this problem, recent work incorporated supplementary information [Hyvarinen et al., 2019, Sorrenson et al., 2020, Halva and Hyvarinen, 2020, Khemakhem et al., 2020, Kong et al., 2022], e.g., class/domain labels. However, these approaches require a number of domains/classes that are twice the number of latent components, which can be unfeasible when dealing with high-dimensional representations. Another line of work [Zimmermann et al., 2022, von Kugelgen et al., 2021, Locatello et al., 2020, Gresele et al., 2019, Kong et al., 2023a,b] leverages paired data (e.g., two rotated versions of the same image) to identify the shared latent factor within the pair. The third line of work [Lachapelle et al., 2022, Yang et al., 2022, Zheng et al., 2022] makes sparsity assumptions on the nonlinear generating function. Although their sparsity assumption alleviates some of the explicit requirements in the previous two types of work, it may not hold for complex data distributions. For instance, in the case of generating text, each topic-related latent factor may influence a large number of components. Instead, we adopt a relative sparsity assumption, where we only require the influence of one subspace to be sparser than the other. Unlike prior work (Zheng et al., 2022), each latent variable is allowed to influence a non-sparse set of components, and the influence can overlap arbitrarily within each subspace. Importantly, we necessitate neither many domains/classes nor paired data as prior work mentioned above.

## 3 Disentangled Representation for Counterfactual Generation

In this section, we discuss the connection between counterfactual generation and the identification of the data-generating process shown in Fig 1.

**Disentangled latent representation.** The data-generating process in Figure 1 can be expressed in Equation 1:

\[ p(|),\; p(|,),\;=g(,),\] (1)

where the data (e.g., text) \(\) are generated by latent variables \(:=[,]^{d_{z}}\) through a smooth and invertible generating function \(g():\). The latent space comprises two subspaces: the content variable \(^{d_{z}}\) and the style variable \(^{d_{z}}\). We define \(\) as the description of the main topic, e.g., "We ordered the steak recommended by the waitress," and s comprises supplementary details connected to the primary topic, e.g., the sentiment towards the dish, as exemplified in "it was _delicious_!". Consequently, the counterfactual generation task here is to preserve the content information \(\) while altering the stylistic aspects represented by \(\).

**Content-style dependence.** In many real-world problems, content \(\) can significantly impact style \(\). For instance, when it comes to the positive descriptions of food (content), words like "_delicious_" are more prevalent than terms like "_effective_". Intuitively, the content \(\) acts to constrain the range of vocabulary choices for style \(\). As a result, the counterfactually generated data should preserve the inherent relationship between \(\) and \(\). We directly model this dependence as:

\[:=g_{s}(};,),\] (2)

where \(g_{s}\) characterizes the influence from \(\) to \(\) and the exogenous variable \(}\) accounts for the inherent randomness of \(\). In the running example, \(}\) can be interpreted as the randomness involved in choosing a word from the vocabulary defined by content \(\), encompassing words similar to "_delicious_" such as "_tasty_","_yummy_". In contrast, prior work (Kong et al., 2022; Xie et al., 2023) assumes the independence between \(\) and \(\) thus neglecting this dependence.

**Challenges from multiple domains.** As we outlined in Section 1, the ability to handle domain shift is crucial for unsupervised counterfactual generation. Domain embedding \(\) represents a specific domain and the domain distribution shift influences both the marginal distribution of content \(p(|)\) and the dependence of content on style \(p(|,)\). The change in content distribution \(p(|)\) across different domains \(\) reflects the variability in the subjects of sentences across these domains. For example, it can manifest as a change from discussing food in restaurant reviews to actors in movie reviews. The change in content-style dependence \(p(|,)\) signifies that identical sentence subjects (i.e., content) could be associated with disparate stylistic descriptions in different domains. For instance, the same political question could provoke significantly different sentiments among various demographic groups. Such considerations are absent in prior work (Kong et al., 2022). Here, we learn a shared model \(((|),g_{s}(},,))\) and domain-specific embeddings \(\). This approach enables effective knowledge transfer across domains and manages distribution shifts efficiently. For a target domain \(\), which may have limited available data, we can learn \(^{}\) using a small amount of unlabeled data \(^{}\) while preserving the multi-domain information in the shared model.

In light of the above discussion, the essence of counterfactual generation now revolves around the task of discerning the disentangled representation \((,})\) within the data-generating process (Fig 1) across various domains with unlabeled data \((,)\): if we can successfully identify \((,})\), we could perform counterfactual reasoning by manipulating \(}\) while preserving both the content information and the content-style dependence.

Figure 1: **The data generation process: The grey shading indicates the variable is observed. The observed variable (i.e., text) \(\) is generated from content \(\) and style \(\). Both content \(\) and style \(\) are influenced by the domain variable \(\) and the content also influences the style. \(}\) is the exogenous variable of \(\), representing the independent information of \(\).**

Identifiability of the Latent Variables

In this section, we introduce the identification theory for the content \(\) and the style \(\) sequentially and then discuss their implications for methodological development.

We introduce notations and definitions that we use throughout this work. When working with matrices, we adopt the following indexing notations: for a matrix \(\), the \(i\)-th row is denoted as \(_{i,:}\), the \(j\)-th column is denoted as \(_{:,j}\), and the \((i,j)\) entry is denoted as \([]_{i,j}\). We can also use this notation to refer to specific sets of indices within a matrix. For an index set \(\{1,,m\}\{1,,n\}\), we use \(_{i,:}\) to denote the set of column indices whose row coordinate is \(i\), i.e., \(_{i,:}:=\{j:(i,j)\}\), and analogously \(_{:,j}\) to denote the set of row indices whose column coordinate is \(j\).

In addition, we define a subspace of \(^{n}\) using an index set \(\): \(^{n}_{}=\{^{n}| i ,z_{i}=0\}\), i.e., it consists of all vectors in \(^{n}\) whose entries are zero for all indices not in \(\). Finally, we can define the support of a matrix-valued function \(():^{m n}\) as the set of indices whose corresponding entries are nonzero for some input value \(\), i.e., \(():=\{(i,j):,,\,[()]_{i,j} 0\}\).

### Influence Sparsity for Content Identification

We show that the subspace \(\) can be identified. That is, we can estimate a generative model \((p_{},p_{|},)\)2 following the data-generating process in Equation 1 and the estimated variable \(}\) can capture all the information of \(\) without interference from \(\). In the following, we denote the Jacobian matrices \(_{g}()\)'s and \(_{}()\)'s supports as \(\) and \(}\) respectively. Further, we denote as \(\) a set of matrices with the same support as that of the matrix-valued function \(_{g}^{-1}()_{}(})\).

**Assumption 1** (Content identification).:
1. \(g\) _is smooth and invertible and its inverse_ \(g^{-1}\) _is also smooth._
2. _For all_ \(i\{1,,d_{x}\}\)_, there exist_ \(\{^{()}\}_{=1}^{|_{i,:}|}\) _and_ \(\)_, such that_ \((\{_{g}(^{()})_{i,:}\}_{=1}^{|_{i,:}|})=^{d_{z}}_{_{i,:}}\) _and_ \([_{g}(^{()})]_{i,:}^{d_{z}}_{ _{i,:}}\)_._
3. _For every pair_ \((c_{j_{x}},s_{j_{z}})\) _with_ \(j_{c}[d_{c}]\) _and_ \(j_{s}\{d_{c}+1,,d_{z}\}\)_, the influence of_ \(s_{j_{s}}\) _is sparser than that of_ \(c_{j_{c}}\)_, i.e.,_ \(\|_{j_{c}}\|_{0}>\|_{:,j_{s}}\|_{0}\)_._

**Theorem 1**.: _We assume the data-generating process in Equation 1 with Assumption 1. If for given dimensions \((d_{c},d_{s})\), a generative model \((p_{},p_{|},)\) follows the same generating process and achieves the following objective:_

\[*{arg\,min}_{p_{},p_{},}_{j_{} \{d_{c}+1,,d_{z}\}}\|}_{:,j_{}}\|_{ 0}p_{}()=p_{}(),\; ,\] (3)

_then the estimated variable \(}\) is an one-to-one mapping of the true variable \(\). That is, there exists an invertible function \(h_{c}()\) such that \(}=h_{c}()\)._

A proof can be found in Appendix A.5.

**Interpretation.** Theorem 1 states that by matching the marginal distribution \(p_{}()\) under a sparsity constraint of \(}\) subspace, we can successfully eliminate the influence of \(\) from the estimated \(}\). This warrants that the content information can be fully retained without being entangled with the style information for a successful counterfactual generation. We can further identify \(}\) from that of \(\) when the dependence \(g_{s}\) function is invertible in its argument \(}\)(Kong et al., 2022).

**Discussion on assumptions.** Assumption 1-i. ensures that the information of all latent variables \([,]\) is preserved in the observed variables \(\), which is a necessary condition for latent-variable identification (Hyvarinen et al., 2019; Kong et al., 2022). Assumption 1-ii. ensures that the influence from the latent variable \(\) varies sufficiently over its domain. This excludes degenerate cases where the Jacobian matrix is partially constant, and thus, its support fails to faithfully capture the influence between latent variables and the observed variables. Assumption 1-iii. encodes the observation that the \(\) subspace exerts a relatively sparser influence on the observed data than the subspace \(\) (Fig 2.).

This is reasonable for language, where the main event largely predominant the sentence and the stylistic variable play complementary and local information for particular attributes, e.g., tense, sentiment, and formality (Xu et al., 2019; Wang et al., 2021; Ross et al., 2021). For the language data, \(\) corresponds to a piece of text (e.g., a sentence) with its dimension \(d_{}\) equal to the number of words multiplied by the word embedding dimension, i.e., multiple dimensions of \(\) correspond to a single word. Therefore, even if a word is simultaneously influenced by both \(\) and \(\), the influence from the content \(\) tends to be denser on this word's embedding dimension, as content usually takes precedence in word selection over style.

**Contrast with prior work.**Zheng et al. (2022) impose sparse influence constraints on the generating function \(g\) in an absolute sense - each latent component should have a very sparse influence on the observed data. In contrast, Theorem 1 only calls for relative sparsity between two subspaces where each latent component's influence may not be sparse and unique as in Zheng et al. (2022). We believe this is reasonable for many real-world applications like languages. Kong et al. (2022) assume the independence between the two subspaces and identify the content subspace by resorting to its invariance and sufficient variability of the style subspace over multiple domains. However, as discussed in Section 3, the invariance of the content subspace is often violated, and so is the independence assumption. In contrast, we permit the content subspace to vary over domains and allow for the dependence between the two subspaces.

### Partially Intersecting Influences for Style Identification

In this section, we show the identifiability for the style subspace \(\), under one additional condition: the influences from the two subspaces \(\) and \(\) do not fully overlap.

**Assumption 2** (Partially intersecting influence supports).: _For every pair \((c_{j_{c}},s_{j_{s}})\), the supports of their influences on \(\) do not fully intersect, i.e., \(_{:,j_{c}}_{:,j_{s}}_{0}< \{_{:,j_{c}}_{0},_{:,j_{s}}_{0}\}\)._

**Theorem 2**.: _We follow the data-generating process Equation 1 and Assumption 1 and Assumption 2. We optimize the objective function in Equation 3 together with_

\[_{(j_{c},j_{s})\{1,,d_{c}\}\{d_{c}+1,,d_{z}\}} }_{:,j_{c}}}_{:,j_{s}} _{0}.\] (4)

_The estimated style variable \(}\) is a one-to-one mapping to the true variable \(\). That is, there exists an invertible mapping \(h_{s}()\) between \(\) and \(}\), i.e., \(}=h_{s}()\)._

The proof can be found in Appendix A.6.

**Interpretation.** Theorem 2 states that we can recover the style subspace \(\) if the influences from the two subspaces do not interfere with each other (Fig 2). This condition endows the subspaces distinguishing footprints and thus forbids the content information in \(\) from contaminating the estimated style variable \(}\). The identification of \(\) is crucial to counterfactual generation tasks: if the estimated style variable \(}\) does capture all the true style variable \(\), intervening on \(}\) cannot fully alter the original style that is intended to be changed.

**Discussion on assumptions.** Assumption 2 prescribes that each content component \(c_{j_{c}}\) and each style component \(s_{j_{s}}\) do not fully contain each other's influence support. Together with Theorem 1, this assumption is essential to the identification of \(\), without which \(_{j_{s}}\) may absorb the influence from \(c_{j_{c}}\). Assumption 2 does not demand the supports of the entire subspaces \(\) and \(\) to be partially intersecting or even disjoint, and the latter directly implies Assumption 2. This assumption is plausible for many real-world data distributions, especially for unstructured data like languages and images - certain dimensions in the pixels and word embeddings may reflect the information of either the content or the style.

**Contrast with prior work.**Kong et al. (2022) obtains the identifiability of the style subspace \(\) by exploiting the access to multiple domains over which the marginal distribution of \(\) (i.e., \(p(|)\)) varies substantially over domains \(\). This hinges on the independence between the two subspaces and is not applicable when the marginal distribution of \(\) only varies over the content \(\), i.e., \(p(|,)\).

## 5 A Framework for Unsupervised Counterfactual Generation

In this section, we translate the theoretical insights outlined in Section 4 into an unsupervised counterfactual generation framework. Guided by the theory, we can approximate the underlying data-generating process depicted in Fig 1 and recover the disentangled latent components.

In the following, we will describe each module in our VAE-based estimation framework (Fig 3), the learning objective, and the procedure for counterfactual generation.

### VAE-based Estimation Framework

Given input sentences \(\) from various domains, we use the VAE encoder \(f_{}\) to parameterize the posterior distribution \(q_{f_{}}(|)\) and sample \( q_{f_{}}(|)\). 3 The posterior sample \(\) is then fed into the VAE decoder \(g_{}\) for reconstruction \(_{}=g_{}()\), as in conventional VAE training.

We split \(\) into two components: \(\) and \(\). As shown in Fig 1, both \(\) and \(\) encompass information of a particular domain \(\), and \(\) is also influenced by \(\). We parameterize such influences using flow-based models (Dolatabadi et al., 2020; Durkan et al., 2019)\(r_{c}\) and \(r_{s}\), respectively:

\[}=r_{c}(;),\ }=r_{s}( ;,),\] (5)

where \(}\) and \(}\) are exogenous variables that are independent of each other, and \(\) and \((,)\) act as contextual information for the flow models \(r_{c}(;)\) and \(r_{s}(;,)\). This design promotes parameter sharing across domains, as we only need to learn a domain embedding \(\) (c.f., a separate flow model per domain). As part of the evidence-lower-bound (ELBO) objective in VAE, we regularize the distributions of \(}=[},}]\) to align with the prior \(p(})\) using Kullback-Leibler (KL) divergence. Consequently, the VAE learning objective can be expressed as:

\[_{}:=- p_{f_{},g_{}}(_ {})+(q_{f_{},r_{s}}(}|)|p(})),\] (6)

where the prior \(p(})\) is set to a standard Gaussian distribution, \((,)\), consistent with typical VAE implementations.

### Sparsity Regularization for Identification Guarantees

Guided by the insights from Theorem 1 and Theorem 2, the sparsity constraint on the influence of \(\) (i.e., Equation 3) and the partially intersecting influence constraint (i.e., Equation 4) are crucial to faithfully recover and disentangle the latent representations \(\) and \(\).

**Sparsity of the style influence.** To implement Equation 3, we compute the Jacobian matrix \(_{g_{}}()\) for the decoder function on-the-fly and apply \(_{1}\) regularization to the columns corresponding to the style variable \([_{g_{}}()]_{:,d_{e}+1:d_{e}}\) to control its sparsity. That is, \(_{}=\|[_{g_{}}( )]_{:,d_{e}+1:d_{e}}\|_{1}\).

**Partially intersecting influences.** To encourage sparsity in the intersection of influence between \(\) and \(\) (as defined in Equation 4), we select \(K\) output dimensions \(_{s}\) of \(_{g_{}}()\) that capture the most substantial influence from \(\) and another set of \(K\) output dimensions \(_{c}\) that receive the least influence from \(\). Subsequently, we apply \(_{1}\) regularization to the influence from \(\) on the output dimensions at the intersection \(_{s}_{c}\), i.e., \(_{}=\|[_{g_{}}( )]_{_{s}_{c},:1:d_{e}}\|_{1}\).

**Content variable masking.** In practice, the content dimensionality \(d_{c}\) is a design choice. When \(d_{c}\) is set excessively large, the sparsity regularization term \(_{}\) may cause the style variable \(\) to lose its influence, squeezing the information of \(\) into the content variable \(\). To handle this issue, we apply a trainable soft mask that operates on \(\) to dynamically control its dimensionality.

In sum, the overall training objective is as follows:

\[:=_{}+_{}_{}+_{}_{}+ _{}_{},\] (7)

where \(\)'s are weight parameters to balance various loss terms.

Figure 3: **Our VAE-based framework – MATTE. During training, the input \(\) is fed to the encoder \(f_{}\) to derive the latent variable \(=[,]\), which is then passed to the decoder \(g_{}\) for reconstruction. Flow modules, denoted as \(r_{c}\) and \(r_{s}\), are implemented to model the causal influences on \(\) and \(\) respectively, which yields the creation of exogenous variables \(}\) and \(}\). To generate transferred data \(_{}\), we intervene on the style exogenous variable \(}\) while keeping the original content variable \(\) unchanged (indicated by the green arrows).**

### Style Intervention

As discussed in Section 3, the content-style dependence should be preserved when generating counterfactual text to ensure linguistic consistency. This can be achieved by intervening on the exogenous style variable \(}\) of the original sample. Specifically, we feed the original sample \(\) to the encoder \(f_{}\) to obtain variables \([,]\). Subsequently, we pass the style variable \(\) through the flow models \(r_{s}\) to obtain its exogenous counterpart \(}\), i.e., \(}=r_{s}(;,)\). To carry out style transfer, we set the original variable \(}\) to the desired style value \(}_{}\), which is the average of the exogenous style values of randomly selected samples with the desired style. As the flow model \(r_{s}\) is invertible, we can obtain the transferred style variable \(_{}=r_{s}^{-1}(}_{}; ,)\), which, together with the original content variable \(\), generates the new sample \(_{}=g_{}([,_{}])\). This process is illustrated in Fig 3 using green arrows. We demonstrate the importance of preserving the content-style dependence and provide evidence that our approach can indeed fulfill this purpose (Fig 4).

## 6 Experimental Results

We validate our theoretical findings by conducting experiments on multiple-domain sentiment transfer tasks, which require effective disentanglement of factors, a concept at the core of our identifiability theory.

**Datasets and Evaluation Schema.** The proposed method is trained on four-domain datasets (Tab 1), i.e, movie (Imdb) [Diao et al., 2014], restaurant (Yelp) [Li et al., 2018], e-commerce (Amazon) [Li et al., 2018] and news (Yahoo) [Zhang et al., 2015, Li et al., 2019]. 4 From common practice [Yang et al., 2018, Lample et al., 2019], we evaluate the generated sentences in terms of the four automatic metrics: (1) **Accuracy**. We train a CNN classifier on the original style-labelled dataset, which has over 95.0% accuracy when evaluated on the four separate validation datasets. Subsequently, we employ it to evaluate the transformed sentences, gauging how effectively they convey the intended attributes. (2) **BLEU**[Papineni et al., 2002]. It compares the n-grams in the generated text with those in the original text, measuring how well the original content is retained 5. (3) **G-score**. It represents the geometric mean of the predicted probability for the ground-truth style category and the BLEU score. Due to its comprehensive nature, it is our primary metric. (4) **Fluency**. It is the perplexity score of GPT-2 [Radford et al., 2019] - lower perplexity values indicate a higher levels of fluency. For **human evaluation**, we invited three evaluators proficient in English to rate the sentiment reverse, semantic preservation, fluency and overall transfer quality using a 5-point Likert scale, where higher scores signify better performance. Furthermore, they were asked to rank the generated sentences produced from different models, with the option to include tied items in their ranking.

### Sentiment transfer

**Baselines.** We compare our model with the state-of-the-art text transfer models that do not rely on style labels, along with a supervised model, B-GST [Sudhakar et al., 2019], which is based on GPT2 [Radford et al., 2019] and accomplishes style transfer through a combination of deletion, retrieval, and generation. The other VAE-based baselines can be divided into two groups based on their architecture: those with LSTM backbones and those utilizing pretrained language models (PLM). Within the LSTM group, \(\)-VAE [Higgins et al., 2017] encourages disentanglement by progressively increasing the latent code capacity. JointTrain [Li et al., 2022] uses the GloVe embedding to initialize \(\) and learns \(\) through LSTM. CPVAE [Xu et al., 2020] is the state-of-the-art unsupervised style transfer model, which maps the style variable to a \(k\)-dimensional probability simplex to model different style categories. In the PLM group, we use GPT2 [Radford et al., 2019] as the backbone and introduce an additional variational layer after fine-tuning its embedding layer to generate the latent variable \(\), referred to as GPT2-FT. Also, we consider Optimus [Li et al., 2020], which is one of the most widely-used pretrained VAE models, utilizing BERT [Devlin et al., 2019] as the encoder and GPT2 as the decoder.

  Domains & Train & Dev & Test \\  IMDB & 344,175 & 27,530 & 27,530 \\ Yelp & 444,102 & 63,484 & 1000 \\ Amazon & 554,998 & 2,000 & 1,000 \\ Yahoo & 4,000 & 4,000 & 4,000 \\  

Table 1: Dataset on four domains.

[MISSING_PAGE_FAIL:8]

maintains the original semantics (Src 2, 3), indicating a lack of effective disentanglement between \(\) and \(\). These failure modes demonstrate the importance of a proper disentanglement of content and style and modelling the causal influence between the two across domains. Benefiting from theoretical insights, our approach manages to reflect the content influence across different domains in Src 1 and retain the content information in Src2, 3.

### Ablation Study

Ablation studies in Table 5 are used to verify our theoretical results in SS 47. On top of the backbone, \(\), we incrementally add each component of our method: (1)Indep considers the domain influence on \(\) (i.e., the \(r_{c}\) module in Fig 3), while neglecting the independence between \(\) and \(\). It experiences a large accuracy boost in conjunction with a significant degradation in BLEU, suggesting poor retention of the content information. (2) CausalDep takes into account the dependency between content and style by incorporating the module \(r_{s}\) in Fig 3. This ameliorates the content retention problem and strikes an overall better balance, as reflected by the raised BLEU score and G-score, although causal dependence in CausalDep is not sufficient for identification without proper regularization. (3) After introducing the style sparsity regularization \(_{}\) as specified in Theorem 1, we observe a significant increase of BLEU over CausalDep, verifying Theorem 1 that the style influence sparsity facilitates content identification SS4.1. (4) We further introduce \(_{}\) inspired by Theorem 2, which controls the intersection of content and style influence supports. This improvement in style identification, i.e., the recovery of accuracy over \(_{}\) corroborates Theorem 2. (5) The incorporation of \(_{}\) arrive at our full model, which further improves the style identification, consistent with our motivation in SS 5.3. It also exhibits the best G-score across all the datasets, with the most predominant improvement over CausalDep on the Yahoo dataset, where the G-score increases from 21.39% to 29.01 %.

**The importance of content-style dependence.** We demonstrate the importance of content-style dependence by visualizing the changes in negative log-likelihood (NLL) induced by different ways of style intervention, namely flipping \(}\) as in our method and flipping \(\) which breach the content-style dependence. If the NLL increases after the style transfer, it indicates that the new variables are located in a lower density region (Zheng et al., 2022; Xu et al., 2020). Fig 4 shows the histograms of NLLs for all the Amazon test samples, both before and after a style transfer. We can see that the NLL distribution changes negligibly when we flip \(}\), in contrast with the significant change caused by flipping \(\). This implies that flipping \(}\) enables better preservation of the joint distribution of the

Figure 4: Histograms of negative log-likelihood (NLL) of 1000 Amazon test samples evaluated on the original latent variable and intervened ones. left: flips \(\), right flips \(}\). The table shows the corresponding sentences.

   &  &  \\  Model & Acc(\(\)) & BLEU(\(\)) & G-score(\(\)) & \(()\) & Acc(\(\)) & BLEU(\(\)) & G-score(\(\)) & \(()\) \\  Backbone & 20.15 & 49.82 & 20.01 & 70.18 & 14.50 & 51.47 & 16.84 & 72.81 \\ Indep (Kong et al., 2022) & **45.00\(@math@degree\)** & 30.88 & 19.89 & 61.85\(@math@degree\) & **61.90\(@math@degree\)** & 25.67 & 21.24\(@math@degree\) & 73.78 \\ CausalDep & 28.714 & 39.63 & 21.85\(@math@degree\) & 53.25\(@math@degree\) & 22.10\(@math@degree\) & 48.98\(@math@degree\) & 25.98\(@math@degree\) & 55.14\(@math@degree\) \\  \(/_{}\) & 21.55 & **56.90\(@math@degree\)** & 20.90 & 65.26 & 13.20 & **56.26\(@math@degree\)** & 14.59 & 54.10\(@math@degree\) \\ \(/_{}\) & 30.18\(@math@degree\) & 51.95 & 25.57\(@math@degree\) & 54.66 & 33.70\(@math@degree\) & 49.09 & 25.81\(@math@degree\) & 52.87\(@math@degree\) \\ \(/_{}()\) & **32.43\(@math@degree\)** & 45.10 & **25.92\(@math@degree\)** & **50.80\(@math@degree\)** & 34.30\(@math@degree\) & 50.14 & **26.34\(@math@degree\)** & **51.51\(@math@degree\)** \\  

Table 5: Ablation results on sentiment transfer on two domains. CausalDep incorporates style flow \(r_{s}\) to model dependency of \(\) on \(\), while Indep assumes the independence between the two variables. \(@math@degree\) marks the improvements overBackbone, while \(@math@degree\) over the CausalDep.

original sentence. The generated sentences resulting from flipping \(}\) exhibit a higher level of semantic fidelity to the original sentence, with a clear inverse sentiment.

### Comparison with large language model

As widely recognized, large language models (LLMs) have demonstrated an impressive capability in text generation. However, we consider the principles of counterfactual generation to be complementary to the development of LLMs. We aim to leverage our theoretical insights to further enhance the capabilities of LLMs. We provide examples in Table 6 where LLMs struggle with sentiment transfer, primarily due to their tendency to overlook the broader and implicit sentiments while accurately altering individual sentiment words. Consequently, it is reasonable to anticipate that LLMs could benefit from the principles of representation learning, as developed in our work.

### Visualization of style variable

We further validate our theoretical insights within additional content-style disentanglement scenarios. As tense has a relatively sparse influence on sentences compared to their content, we choose tense (past and present) as another style for illustration. Specifically, we collect 1000 sentences in either past or present tense from the Yelp Dev set and derive their style representations, denoted as \(\), by feeding these sentences into our well-trained model. The projection results of \(\) and \(\) are shown in 5. The distinct separation between the red and blue data points indicates a more discriminative and better disentangled style variabl. However, in the case of \(\), some blue data points are mixed within the lower portion of the red region.

## 7 Conclusion and limitations

Prior work (Kong et al., 2022; Xie et al., 2023) have employed multiple domains to achieve unsupervised representation disentanglement. However, the assumed independence between the content and style variables often does not hold in real-world data distributions, particularly in natural languages. To tackle this challenge, we address the identification problem in latent-variable models by leveraging the sparsity structure in the data-generating process. This approach provides identifiability guarantees for both the content and the style variables. We have implemented a controllable text generation method based on these theoretical guarantees. Our method outperforms existing methods on various large-scale style transfer benchmark datasets, thus validating our theory. It is important to note that while our method shows promising empirical results for natural languages, the sparsity assumption (Assumption 1-iii.) may not hold for certain data distributions like images, where the style component could exert dense influences on pixel values. In such cases, we may explore other forms of inherent sparsity in the given distribution, e.g., sparse dependencies between content and style or sparse changes over multiple domains, to achieve identifiability guarantees and develop empirical approaches accordingly.

  _Scc:_ The buttons to extend the arms worked exactly one time before breaking. \\ _ChaGPT:p1:_ The buttons to extend the arms **failed** to work from the **beginning, never functioning even once**. \\ _ChaGPT:p2:_ The buttons to extend the arms never worked, even once, and **remained** functional until they broke**. \\ _Our:_ The buttons to extend the arms worked exactly **as described**. \\  _Scc:_ I love that it uses natural ingredients but it was ineffective on my skin. \\ _ChaGPT:p1_**: **idlike** that it uses natural ingredients, but it was **highly effective** on my skin. \\ _ChaGPT:p2_**: **idlike** that it uses natural ingredients, but it was **highly effective** on my skin. \\ _Our:_ I like that it uses natural ingredients, and it was **also good**. \\  _Scc:_ This case is one tower this is the only good thing about it. \\ _ChaGPT:p1_ This case is **not** cute; however, it is the only good thing about it. \\ _ChaGPT:p2_ This case is **not** cute at all; however, it is the only **bad** thing about it. \\ _Ours:_This case is **cute** and **overall a valuable product**. \\  

Table 6: A Sentiment transfer example, on which ChatGPT fails to completely reverse the overall sentiment of the sentence, although it successfully negates individual words within text. In contrast, our method achieves the sentiment reversal with minimal changes. _ChatGPT:p1_ and _ChatGPT:p2_ represent results obtained from two different prompts, i.e., p1: “_Flip the sentiment of the following sentences, but keep the content unchanged as much as possible._”; p2: “_Please invert the sentiment while preserving content as much as possible in the following sentence that originates from the original domain._”.

Figure 5: The style variables of sentences in past-tense (blue) and present-tense (red) following a UMAP projection. Left: \(\); Right: \(\).