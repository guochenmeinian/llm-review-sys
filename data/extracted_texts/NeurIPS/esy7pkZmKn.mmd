# Doubly Robust Self-Training

Banghua Zhu

Department of EECS

UC Berkeley

banghua@berkeley.edu

&Mingyu Ding

Department of EECS

UC Berkeley

myding@berkeley.edu

&Philip Jacobson

Department of EECS

UC Berkeley

philip_jacobson@berkeley.edu

&Ming Wu

Department of EECS

UC Berkeley

mingwu@berkeley.edu

&Wei Zhan

Department of EECS

UC Berkeley

wzhan@berkeley.edu

&Michael I. Jordan

Department of EECS

UC Berkeley

jordan@berkeley.edu

&Jiantao Jiao

Department of EECS

UC Berkeley

jiantao@berkeley.edu

###### Abstract

Self-training is an important technique for solving semi-supervised learning problems. It leverages unlabeled data by generating pseudo-labels and combining them with a limited labeled dataset for training. The effectiveness of self-training heavily relies on the accuracy of these pseudo-labels. In this paper, we introduce doubly robust self-training, a novel semi-supervised algorithm that provably balances between two extremes. When the pseudo-labels are entirely incorrect, our method reduces to a training process solely using labeled data. Conversely, when the pseudo-labels are completely accurate, our method transforms into a training process utilizing all pseudo-labeled data and labeled data, thus increasing the effective sample size. Through empirical evaluations on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection, we demonstrate the superiority of the doubly robust loss over the standard self-training baseline.

## 1 Introduction

Semi-supervised learning considers the problem of learning based on a small labeled dataset together with a large unlabeled dataset. This general framework plays an important role in many problems in machine learning, including model fine-tuning, model distillation, self-training, transfer learning and continual learning (Zhu, 2005; Pan and Yang, 2010; Weiss et al., 2016; Gou et al., 2021; De Lange et al., 2021). Many of these problems also involve some form of distribute shift, and accordingly, to best utilize the unlabeled data, an additional assumption is that one has access to a teacher model obtained from prior training. It is important to study the relationships among the datasets and the teacher model. In this paper, we ask the following question:

_Given a teacher model, a large unlabeled dataset and a small labeled dataset, how can we design a principled learning process that ensures consistent and sample-efficient learning of the true model?_Self-training is one widely adopted and popular approach in computer vision and autonomous driving for leveraging information from all three components (Lee, 2013; Berthelot et al., 2019, 2019; Sohn et al., 2020; Xie et al., 2020; Jiang et al., 2022; Qi et al., 2021). This approach involves using a teacher model to generate pseudo-labels for all unlabeled data, and then training a new model on a mixture of both pseudo-labeled and labeled data. However, this method can lead to overreliance on the teacher model and can miss important information provided by the labeled data. As a consequence, the self-training approach becomes highly sensitive to the accuracy of the teacher model. Our study demonstrates that even in the simplest scenario of mean estimation, this method can yield significant failures when the teacher model lacks accuracy.

To overcome this issue, we propose an alternative method that is _doubly robust_--when the covariate distribution of the unlabeled dataset and the labeled dataset matches, the estimator is always consistent no matter whether the teacher model is accurate or not. On the other hand, when the teacher model is an accurate predictor, the estimator makes full use of the pseudo-labeled dataset and greatly increases the effective sample size. The idea is inspired by and directly related to missing-data inference and causal inference (Rubin, 1976; Kang and Schafer, 2007; Birhanu et al., 2011; Ding and Li, 2018), to semiparametric mean estimation (Zhang et al., 2019), and to recent work on prediction-powered inference (Angelopoulos et al., 2023).

### Main results

The proposed algorithm is based on a simple modification of the standard loss for self-training. Assume that we are given a set of unlabeled samples, \(_{1}=\{X_{1},X_{2},,X_{m}\}\), drawn from a fixed distribution \(_{X}\), a set of labeled samples \(_{2}=\{(X_{m+1},Y_{m+1}),(X_{m+2},Y_{m+2}),,(X_{m+n},Y_{m+n})\}\), drawn from some joint distribution \(_{X}_{Y|X}\), and a teacher model \(\). Let \(_{}(x,y)\) be a pre-specified loss function that characterizes the prediction error of the estimator with parameter \(\) on the given sample \((X,Y)\). Traditional self-training aims at minimizing the combined loss for both labeled and unlabeled samples, where the pseudo-labels for unlabeled samples are generated using \(\):

\[^{}_{_{1},_{2}}()= (_{i=1}^{m}_{}(X_{i},(X_{i}))+_{i=m+1}^{m+n} _{}(X_{i},Y_{i})).\]

Note that this can also be viewed as first using \(\) to predict all the data, and then replacing the originally labeled points with the known labels:

\[^{}_{_{1},_{2}}()=_{i=1}^{m+n}_{}(X_{i},(X_{i}))-_{i=m+1} ^{m+n}_{}(X_{i},(X_{i}))+_{i=m+1}^{m+n}_ {}(X_{i},Y_{i}).\]

Our proposed doubly robust loss instead replaces the coefficient \(1/(m+n)\) with \(1/n\) in the last two terms:

\[^{}_{_{1},_{2}}()=_{i=1}^{m+n}_{}(X_{i},(X_{i}))-_{i=m+1}^{ m+n}_{}(X_{i},(X_{i}))+_{i=m+1}^{m+n}_{ }(X_{i},Y_{i}).\]

This seemingly minor change has a major beneficial effect--the estimator becomes consistent and doubly robust.

**Theorem 1** (Informal).: _Let \(^{}\) be defined as the minimizer \(^{}=_{}_{(X,Y)_{X} _{Y|X}}[_{}(X,Y)]\). Under certain regularity conditions, we have_

\[\|_{}^{}_{_{1},_{2}}( ^{})\|_{2}},&Y (X),\\ },&.\]

_On the other hand, there exists instances such that \(\|_{}^{}_{_{1},_{2}}( ^{})\|_{2} C\) always holds true no matter how large \(m,n\) are._

The result shows that the true parameter \(^{}\) is also a local minimum of the doubly robust loss, but not a local minimum of the original self-training loss. We flesh out this comparison for the special example of mean estimation in Section 2.1, and present empirical results on image and driving datasets in Section 3.

### Related work

**Missing-data inference and causal inference.** The general problem of causal inference can be formulated as a missing-data inference problem as follows. For each unit in an experiment, at most one of the potential outcomes--the one corresponding to the treatment to which the unit is exposed--is observed, and the other potential outcomes are viewed as missing (Holland, 1986; Ding and Li, 2018). Two of the standard methods for solving this problem are data imputation Rubin (1979) and propensity score weighting Rosenbaum and Rubin (1983). A doubly robust causal inference estimator combines the virtues of these two methods. The estimator is referred to as "doubly robust" due to the following property: if the model for imputation is correctly specified then it is consistent no matter whether the propensity score model is correctly specified; on the other hand, if the model propensity score model is correctly specified, then it is consistent no matter whether the model for imputation is correctly specified (Scharfstein et al., 1999; Bang and Robins, 2005; Birhanu et al., 2011; Ding and Li, 2018).

We note in passing that double machine learning is another methodology that is inspired by the doubly robust paradigm in causal inference (Semenova et al., 2017; Chernozhukov et al., 2018, 2018; Foster and Syrgkanis, 2019). The problem in double machine learning is related to the classic semiparametric problem of inference for a low-dimensional parameter in the presence of high-dimensional nuisance parameters, which is different goal than the predictive goal characterizing semi-supervised learning.

The recent work of prediction-powered inference (Angelopoulos et al., 2023) focuses on confidence estimation when there are both unlabeled data, labeled data, along with a teacher model. Their focus is the inferential problem of obtaining a confidence set, while ours is the doubly robust property of a point estimator. Since they focus on confidence estimation, an important, strong, yet biased baseline point-estimate algorithm that directly combines the ground-truth labels and pseudo-labels is not considered in their case. In our paper, we show with both theory and experiments that the proposed doubly-robust estimator achieves better performance than the naive combination of ground-truth labels and pseudo-labels.

**Self-training.** Self-training is a popular semi-supervised learning paradigm in which machine-generated pseudo-labels are used for training with unlabeled data (Lee, 2013; Berthelot et al., 2019, 2019; Sohn et al., 2020). To generate these pseudo-labels, a teacher model is pre-trained on a set of labeled data, and its predictions on the unlabeled data are extracted as pseudo-labels. Previous work seeks to address the noisy quality of pseudo-labels in various ways. MixMatch (Berthelot et al., 2019) ensembles pseudo-labels across several augmented views of the input data. ReMixMatch (Berthelot et al., 2019) extends this by weakly augmenting the teacher inputs and strongly augmenting the student inputs. FixMatch (Sohn et al., 2020) uses confidence thresholding to select only high-quality pseudo-labels for student training.

Self-training has been applied in both 2D computer vision problems (Liu et al., 2021; Jeong et al., 2019; Tang et al., 2021; Sohn et al., 2020; Zhou et al., 2022) and 3D problems (Park et al., 2022; Wang et al., 2021; Li et al., 2023; Liu et al., 2023) object detection. STAC (Sohn et al., 2020) enforces consistency between strongly augmented versions of confidence-filtered pseudo-labels. Unbiased teacher (Liu et al., 2021) updates the teacher during training with an exponential moving average (EMA) of the student network weights. Dense Pseudo-Label (Zhou et al., 2022) replaces box pseudo-labels with the raw output features of the detector to allow the student to learn richer context. In the 3D domain, 3DIoUMatch (Wang et al., 2021) thresholds pseudo-labels using a model-predicted Intersection-over-Union (IoU). DetMatch (Park et al., 2022) performs detection in both the 2D and 3D domains and filters pseudo-labels based on 2D-3D correspondence. HSSDA (Liu et al., 2023) extends strong augmentation during training with a patch-based point cloud shuffling augmentation. Offboard3D (Qi et al., 2021) utilizes multiple frames of temporal context to improve pseudo-label quality.

There has been a limited amount of theoretical analysis of these methods, focusing on semi-supervised methods for mean estimation and linear regression (Zhang et al., 2019; Azriel et al., 2022). Our analysis bridges the gap between these analyses and the doubly robust estimators in the causal inference literature.

Doubly Robust Self-Training

We begin with the case where the marginal distributions for the covariates of the labeled and unlabeled datasets are the same. Assume that we are given a set of unlabeled samples, \(_{1}=\{X_{1},X_{2},,X_{m}\}\), drawn from a fixed distribution \(_{X}\) supported on \(\), a set of labeled samples \(_{2}=\{(X_{m+1},Y_{m+1}),(X_{m+2},Y_{m+2}),,(X_{m+n},Y_{m+n})\}\), drawn from some joint distribution \(_{X}_{Y|X}\) supported on \(\), and a pre-trained model, \(:\). Let \(_{}(,):\) be a pre-specified loss function that characterizes the prediction error of the estimator with parameter \(\) on the given sample \((X,Y)\). Our target is to find some \(^{}\) that satisfies

\[^{}*{arg\,min}_{} _{(X,Y)_{X}_{Y|X}}[_{}(X,Y)].\]

For a given loss \(_{}(x,y)\), consider a naive estimator that ignores the predictor \(\) and only trains on the labeled samples:

\[^{}_{_{1},_{2}}( )=_{i=m+1}^{m+n}_{}(X_{i},Y_{i}).\]

Although naive, this is a safe choice since it is an empirical risk minimizer. As \(n\), the loss converges to the population loss. However, it ignores all the information provided in \(\) and the unlabeled dataset, which makes it inefficient when the predictor \(\) is informative.

On the other hand, traditional self-training aims at minimizing the combined loss for both labeled and unlabeled samples, where the pseudo-labels for unlabeled samples are generated using \(\):1

\[^{}_{_{1},_{2}}( ) =(_{i=1}^{m}_{}(X_{i},(X_ {i}))+_{i=m+1}^{m+n}_{}(X_{i},Y_{i}))\] \[=_{i=1}^{m+n}_{}(X_{i},(X_{i}) )-_{i=m+1}^{m+n}_{}(X_{i},(X_{i}))+ {m+n}_{i=m+1}^{m+n}_{}(X_{i},Y_{i}).\]

As is shown by the last equality, the self-training loss can be viewed as first using \(\) to predict all the samples (including the labeled samples) and computing the average loss, then replacing that part of the loss corresponding to the labeled samples with the loss on the original labels. Although the loss uses the information arising from the unlabeled samples and \(\), the performance can be poor when the predictor is not accurate.

We propose an alternative loss, which simply replaces the weight \(1/(m+n)\) in the last two terms with \(1/n\):

\[^{}_{_{1},_{2}}( )=_{i=1}^{m+n}_{}(X_{i},(X_{i}))- {1}{n}_{i=m+1}^{m+n}_{}(X_{i},(X_{i}))+_{ i=m+1}^{m+n}_{}(X_{i},Y_{i}). \]

As we will show later, this is a doubly robust estimator. We provide an intuitive interpretation here:

* In the case when * On the other hand, no matter how bad the given predictor is, the difference between the first two terms vanishes as either of \(m,n\) goes to infinity since the labeled samples \(X_{m+1},,X_{m+n}\) arise from the same distribution as \(X_{1},,X_{m}\). Thus asymptotically the loss minimizes \(_{i=m+1}^{m+n}_{}(X_{i},Y_{i})\), which discards the bad predictor \(\) and focuses only on the labeled dataset. Thus, in this case the loss \(^{}\) is much better than \(^{}\), and comparable to \(^{}\).

This loss is appropriate only when the covariate distributions between labeled and unlabeled samples match. In the case where there is a distribution mismatch, we propose an alternative loss; see Section 2.3.

### Motivating example: Mean estimation

As a concrete example, in the case of one-dimensional mean estimation we take \(_{}(X,Y)=(-Y)^{2}\). Our target is to find some \(^{}\) that satisfies

\[^{}=*{arg\,min}_{}_{(X,Y)_{X}_{Y|X}}[(-Y)^{2}].\]

One can see that \(^{}=[Y]\). In this case, the loss for training only on labeled data becomes

\[^{}_{_{1},_{2}}()= _{i=m+1}^{m+n}(-Y_{i})^{2}.\]

Moreover, the optimal parameter is \(_{}=_{i=m+1}^{m+n}Y_{i}\), which is a simple empirical average over all observed \(Y\)'s.

For a given pre-existing predictor \(\), the loss for self-training becomes

\[^{}_{_{1},_{2}}()=(_{i=1}^{m}(-(X_{i}))^{2}+_{i=m+1}^{m+n}(-Y_{i })^{2}).\]

It is straightforward to see that the minimizer of the loss is the unweighted average between the unlabeled predictors \((X_{i})\)'s and the labeled \(Y_{i}\)'s:

\[^{}_{}=(_{i=1}^{m}(X_{i})+ _{i=m+1}^{m+n}Y_{i}).\]

In the case of \(m n\), the mean estimator is almost the same as the average of all the predicted values on the unlabeled dataset, which can be far from \(^{}\) when the predictor \(\) is inaccurate.

On the other hand, for the proposed doubly robust estimator, we have

\[^{}_{_{1},_{2}}() =_{i=1}^{m+n}(-(X_{i}))^{2}-_{i=m+1}^{m+n}(-(X_{i}))^{2}+_{i=m+1}^{m+n }(-Y_{i})^{2}\] \[=_{i=1}^{m+n}(-(X_{i}))^{2}+_{i=m+1}^{m+n}2((X_{i})-Y_{i})+Y_{i}^{2}-(X_{i}) ^{2}.\]

Note that the loss is still convex, and we have

\[^{}_{}=_{i=1}^{m+n}(X_{i})-_{i=m+1}^{m+n}((X_{i})-Y_{i}).\]

This recovers the estimator in prediction-powered inference (Angelopoulos et al., 2023). Assume that \(\) is independent of the labeled data. We can calculate the mean-squared error of the three estimators as follows.

**Proposition 1**.: _Let \([(X)-Y]=[((X)-Y)^{2}-[((X )-Y)]^{2}]\). We have_

\[[(^{}-_{})^{2}] =[Y],\] \[[(^{}-_{})^{2}] }{(m+n)^{2}}[((X)-Y)]^{2}+}[(X)-Y]+}[Y],\] \[[(^{}-_{})^{2}]  2([Y]+ [(X)],[(X)-Y]+[Y]).\]The proof is deferred to Appendix F. The proposition illustrates the double-robustness of \(_{}\)--no matter how poor the estimator \((X)\) is, the rate is always upper bounded by \(([Y]+[(X)])\). On the other hand, when \((X)\) is an accurate estimator of \(Y\) (i.e., \([(X)-Y]\) is small), the rate can be improved to \([Y]\). In contrast, the self-training loss always has a non-vanishing term, \(}{(m+n)^{2}}[((X)-Y)]^{2}\), when \(m n\), unless the predictor \(\) is accurate.

On the other hand, when \((x)=_{(-1)}^{}x+_{1}\) is a linear predictor trained on the labeled data with \(=_{=[_{1},_{(-1)}]}_{i=m+1}^{ m+n}(_{(-1)}^{}X_{i}+_{1}-Y_{i})^{2}\), our estimator reduces to the semi-supervised mean estimator in Zhang et al. (2019). Let \(=[1,X]\). In this case, we also know that the self-training reduces to training only on labeled data, since \(_{}\) is also the minimizer of the self-training loss. We have the following result that reveals the superiority of the doubly robust estimator compared to the other two options.

**Proposition 2** ((Zhang et al., 2019)).: _We establish the asymptotic behavior of various estimators when \(\) is a linear predictor trained on the labeled data:_

* _Training only on labeled data_ \(_{}\) _is equivalent to self-training_ \(_{}\)_, which gives unbiased estimator but with larger variance:_ \[(_{}-^{})(0,[(Y -^{})^{2}]+_{(-1)}^{}_{(-1)}).\]
* _Doubly Robust_ \(_{}\) _is unbiased with smaller variance:_ \[(_{}-^{})(0,[(Y -^{})^{2}]+_{(-1)}^{}_{(-1) }).\]

_Here \(=_{}[(Y-^{})^{2}]\) and \(=[(X-[X])(X-[X])^{}]\)._

### Guarantee for general loss

In the general case, we show that the doubly robust loss function continues to exhibit desirable properties. In particular, as \(n,m\) goes to infinity, the global minimum of the original loss is also a critical point of the new doubly robust loss, no matter how inaccurate the predictor \(\).

Let \(^{}\) be the minimizer of \(_{_{X,Y}}[_{}(X,Y)]\). Let \(\) be a pre-existing model that does not depend on the datasets \(_{1},_{2}\). We also make the following regularity assumptions.

**Assumption 1**.: _The loss \(_{}(x,y)\) is differentiable at \(^{}\) for any \(x,y\)._

**Assumption 2**.: _The random variables \(_{}_{}(X,(X))\) and \(_{}_{}(X,Y)\) have bounded first and second moments._

Given this assumption, we denote \(_{}^{Y-}=[_{}_{}(X,(X))-_{}_{}(X,Y)]\) and let \(_{}^{}=[_{}_{}(X, (X))]\), \(_{}^{Y}=[_{}_{}(X,Y)]\).

**Theorem 2**.: _Under Assumptions 1 and 2, we have that with probability at least \(1-\),_

\[\|_{}_{_{1},_{2}}^ {}(^{})\|_{2} C\|_{^{}}^{ }\|_{2}}+\|_{^{}}^{Y- }\|_{2}},\] \[\|_{^{}}^{}\|_{2}(}+})+\|_{^{}}^{Y}\|_{2 }},\]

_where \(C\) is a universal constant, and \(_{_{1},_{2}}^{}\) is defined in Equation (1)._

The proof is deferred to Appendix G. From the example of mean estimation we know that one can design instances such that \(\|_{}_{_{1},_{2}}^{}( ^{})\|_{2} C\) for some positive constant \(C\).

When the loss \(_{}_{_{1},_{2}}^{}\) is convex, the global minimum of \(_{}_{_{1},_{2}}^{}\) converges to \(^{}\) as both \(m,n\) go to infinity. When the loss \(_{}_{_{1},_{2}}^{}\) is strongly convex, it also implies that \(\|-^{}\|_{2}\) converges to zero as both \(m,n\) go to infinity, where \(\) is the minimizer of \(_{}_{_{1},_{2}}^{}\).

When \(\) is a perfect predictor with \((X) Y\) (and \(Y|X=x\) is deterministic), one has \(^{}_{_{1},_{2}}(^{})=_{i=1}^{m+n}_{}(X_{i},Y_{i})\). The effective sample size is \(m+n\) instead of \(n\) in \(^{}_{_{1},_{2}}()\).

When \(\) is also trained from the labeled data, one may apply data splitting to achieve the same guarantee up to a constant factor. We provide further discussion in Appendix E.

### The case of distribution mismatch

We also consider the case in which the marginal distributions of the covariates for the labeled and unlabeled datasets are different. Assume in particular that we are given a set of unlabeled samples, \(_{1}=\{X_{1},X_{2},,X_{m}\}\), drawn from a fixed distribution \(_{X}\), a set of labeled samples, \(_{2}=\{(X_{m+1},Y_{m+1}),(X_{m+2},Y_{m+2}),,(X_{m+n},Y_{m+n})\}\), drawn from some joint distribution \(_{X}_{Y|X}\), and a pre-trained model \(\). In the case when the labeled samples do not follow the same distribution as the unlabeled samples, we need to introduce an importance weight \((x)\). This yields the following doubly robust estimator:

\[^{}_{_{1},_{2}}()= _{i=1}^{m}_{}(X_{i},(X_{i}))-_{i=m+1}^{m+n })}_{}(X_{i},(X_{i}))+_{i=m+ 1}^{m+n})}_{}(X_{i},Y_{i}).\]

Note that we not only introduce the importance weight \(\), but we also change the first term from the average of all the \(m+n\) samples to the average of \(n\) samples.

**Proposition 3**.: _We have \([^{}_{_{1},_{2}}()] =_{_{X,Y}}[_{}(X,Y)]\) as long as one of the following two assumptions hold:_

* _For any x,_ \((x)=_{X}(x)}{_{X}(x)}\)_._
* _For any x,_ \(_{}(x,(x))=_{Y_{Y|X=x}}[_{ }(x,Y)]\)_._

The proof is deferred to Appendix H. The proposition implies that as long as either \(\) or \(\) is accurate, the expectation of the loss is the same as that of the target loss. When the distributions for the unlabeled and labeled samples match each other, this reduces to the case in the previous sections. In this case, taking \((x)=1\) guarantees that the expectation of the doubly robust loss is always the same as that of the target loss.

## 3 Experiments

To employ the new doubly robust loss in practical applications, we need to specify an appropriate optimization procedure, in particular one that is based on (mini-batched) stochastic gradient descent so as to exploit modern scalable machine learning methods. In preliminary experiments we observed that directly minimizing the doubly robust loss in Equation (1) with stochastic gradient can lead to instability, and thus, we propose instead to minimize the curriculum-based loss in each epoch:

\[^{,t}_{_{1},_{2}}()=_{i=1}^{m+n}_{}(X_{i},(X_{i}))-_{t}( _{i=m+1}^{m+n}_{}(X_{i},(X_{i}))- _{i=m+1}^{m+n}_{}(X_{i},Y_{i})).\]

As we show in the experiments below, this choice yields a stable algorithm. We set \(_{t}=t/T\), where \(T\) is the total number of epochs. For the object detection experiments, we introduce the labeled samples only in the final epoch, setting \(_{t}=0\) for all epochs before setting \(_{t}=1\) in the final epoch. Intuitively, we start from the training with samples only from the pseudo-labels, and gradually introduce the labeled samples in the doubly robust loss for fine-tuning.

We conduct experiments on both image classification task with ImageNet dataset (Russakovsky et al., 2015) and 3D object detection task with autonomous driving dataset nuScenes (Caesar et al., 2020). The code is available in [https://github.com/dingmyu/Doubly-Robust-Self-Training](https://github.com/dingmyu/Doubly-Robust-Self-Training).

### Image classification

**Datasets and settings.** We evaluate our doubly robust self-training method on the ImageNet100 dataset, which contains a random subset of 100 classes from ImageNet-1k (Russakovsky et al., 2015),with 120K training images (approximately 1,200 samples per class) and 5,000 validation images (50 samples per class). To further test the effectiveness of our algorithm in a low-data scenario, we create a dataset that we refer to as mini-ImageNet100 by randomly sampling 100 images per class from ImageNet100. Two models were evaluated: (1) DaViT-T (Ding et al., 2022), a popular vision transformer architecture with state-of-the-art performance on ImageNet, and (2) ResNet50 (He et al., 2016), a classic convolutional network to verify the generality of our algorithm.

**Baselines.** To provide a comparative evaluation of doubly robust self-training, we establish three baselines: (1) 'Labeled Only' for training on labeled data only (partial training set) with a loss \(^{}\), (2) 'Pseudo Only' for training with pseudo labels generated for all training samples, and (3) 'Labeled + Pseudo' for a mixture of pseudo-labels and labeled data, with the loss \(^{}\). See the Appendix for further implementation details and ablations.

**Results on ImageNet100.** We first conduct experiments on ImageNet100 by training the model for 20 epochs using different fractions of labeled data from 1% to 100%. From the results shown in Fig. 1, we observe that: (1) Our model outperforms all baseline methods on both two networks by large margins. For example, we achieve 5.5% and 5.3% gains (Top-1 Acc) on DaViT over the 'Labeled + Pseudo' method for 20% and 80% labeled data, respectively. (2) The 'Labeled + Pseudo' method consistently beats the 'Labeled Only' baseline. (3) While 'Pseudo Only' works for smaller fractions of the labeled data (less than 30%) on DaViT, it is inferior to 'Labeled Only' on ResNet50.

**Results on mini-ImageNet100.** We also perform comparisons on mini-ImageNet100 to demonstrate the performance when the total data volume is limited. From the results in Table 1, we see our model generally outperforms all baselines. As the dataset size decreases and the number of training epochs increases, the gain of our algorithm becomes smaller. This is expected, as (1) the models are not adequately trained and thus have noise issues, and (2) there are an insufficient number of ground truth labels to compute the last term of our loss function. In extreme cases, there is only one labeled sample (1%) per class.

### 3D object detection

**Doubly robust object detection.** Given a visual representation of a scene, 3D object detection aims to generate a set of 3D bounding box predictions \(\{b_{i}\}_{i[m+n]}\) and a set of corresponding class predictions \(\{c_{i}\}_{i[m+n]}\). Thus, each single ground-truth annotation \(Y_{i} Y\) is a set \(Y_{i}=(b_{i},c_{i})\)

Figure 1: Comparisons on ImageNet100 using two different network architectures. Both Top-1 and Top-5 accuracies are reported. All models are trained for 20 epochs.

containing a box and a class. During training, the object detector is supervised with a sum of the box regression loss \(_{loc}\) and the classification loss \(_{cls}\), i.e. \(_{obj}=_{loc}+_{cls}\).

In the self-training protocol for object detection, pseudo-labels for a given scene \(X_{i}\) are selected from the labeler predictions \(f(X_{i})\) based on some user-defined criteria (typically the model's detection confidence). Unlike in standard classification or regression, \(Y_{i}\) will contain a differing number of labels depending on the number of objects in the scene. Furthermore, the number of extracted pseudo-labels \(f(X_{i})\) will generally not be equal to the number of scene ground-truth labels \(Y_{i}\) due to false positive/negative detections. Therefore it makes sense to express the doubly robust loss function in terms of the individual box labels as opposed to the scene-level labels. We define the doubly robust object detection loss as follows:

\[_{obj}^{}()=}_{i=1}^{M+N_{ps}} _{}(X_{i},f(X_{i}))-}_{i=M+1}^{M+N_{ps}}_{ }(X_{i}^{},f(X_{i}^{}))+_{i=M+1}^{M+N}_{ }(X_{i},Y_{i}),\]

where \(M\) is the total number of pseudo-label boxes from the unlabeled split, \(N\) is the total number of labeled boxes, \(X_{i}^{}\) is the scene with pseudo-label boxes from the _labeled_ split, and \(N_{ps}\) is the total number of pseudo-label boxes from the _labeled_ split. We note that the last two terms now contain summations over a differing number of boxes, a consequence of the discrepancy between the number of manually labeled boxes and pseudo-labeled boxes. Both components of the object detection loss (localization/classification) adopt this form of doubly robust loss.

**Dataset and setting.** To evaluate doubly robust self-training in the autonomous driving setting, we perform experiments on the large-scale 3D detection dataset nuScenes (Caesar et al., 2020). The nuScenes dataset is comprised of 1000 scenes (700 training, 150 validation and 150 test) with each frame containing sensor information from RGB camera, LiDAR, and radar scans. Box annotations are comprised of 10 classes, with the class instance distribution following a long-tailed distribution, allowing us to investigate our self-training approach for both common and rare classes. The main 3D detection metrics for nuScenes are mean Average Precision (mAP) and the nuScenes Detection Score (NDS), a dataset-specific metric consisting of a weighted average of mAP and five other true-positive metrics. For the sake of simplicity, we train object detection models using only LiDAR sensor information.

**Results.** After semi-supervised training, we evaluate our student model performance on the nuScenes _val_ set. We compare three settings: training the student model with only the available labeled data

    &  &  &  &  \\  & top1 & top5 & top1 & top5 & top1 & top5 & top1 & top5 \\ 
1 & 2.72 & 9.18 & **2.81** & 9.57 & 2.73 & 9.55 & 2.75 & **9.73** \\
5 & 3.92 & 13.34 & 4.27 & 13.66 & 4.27 & 14.4 & **4.89** & **16.38** \\
10 & 6.76 & 20.84 & 7.27 & 21.64 & 7.65 &(i.e., equivalent to teacher training), training the student model on the combination of labeled/teacher-labeled data using the naive self-training loss, and training the student model on the combination of labeled/teacher-labeled data using our proposed doubly robust loss. We report results for training with 1/24, 1/16, and 1/4 of the total labels in Table 2. We find that the doubly robust loss improves both mAP and NDS over using only labeled data and the naive baseline in the lower label regime, whereas performance is slightly degraded when more labels are available. Furthermore, we also show a per-class performance breakdown in Table 3. We find that the doubly robust loss consistently improves performance for both common (car, pedestrian) and rare classes. Notably, the doubly robust loss is even able to improve upon the teacher in classes for which pseudo-label training _decreases_ performance when using the naive training (e.g., barriers and traffic cones).

## 4 Conclusions

We have proposed a novel doubly robust loss for self-training. Theoretically, we analyzed the double-robustness property of the proposed loss, demonstrating its statistical efficiency when the pseudo-labels are accurate. Empirically, we showed that large improvements can be obtained in both image classification and 3D object detection.

As a direction for future work, it would be interesting to understand how the doubly robust loss might be applied to other domains that have a missing-data aspect, including model distillation, transfer learning, and continual learning. It is also important to find practical and efficient algorithms when the labeled and unlabeled data do not match in distribution.