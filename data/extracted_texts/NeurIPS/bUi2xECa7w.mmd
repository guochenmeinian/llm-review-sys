# The Fairness-Quality Trade-off in Clustering

Rashida Hakim

Columbia University

&Ana-Andreea Stoica

Max Planck Institute for

Intelligent Systems, Tubingen

Christos H. Papadimitriou

Columbia University

&Mihalis Yannakakis

Columbia University

###### Abstract

Fairness in clustering has been considered extensively in the past; however, the trade-off between the two objectives -- e.g., can we sacrifice just a little in the quality of the clustering to significantly increase fairness, or vice-versa? -- has rarely been addressed. We introduce novel algorithms for tracing the complete trade-off curve, or Pareto front, between quality and fairness in clustering problems; that is, computing all clusterings that are not dominated in both objectives by other clusterings. Unlike previous work that deals with specific objectives for quality and fairness, we deal with all objectives for fairness and quality in two general classes encompassing most of the special cases addressed in previous work. Our algorithm must take exponential time in the worst case as the Pareto front itself can be exponential. Even when the Pareto front is polynomial, our algorithm may take exponential time, and we prove that this is inevitable unless P = NP. However, we also present a new polynomial-time algorithm for computing the entire Pareto front when the cluster centers are fixed, and for a fairness objective that minimizes the sum, over all clusters, of the imbalance between the two groups in each cluster.

## 1 Introduction

Clustering is a fundamental problem in unsupervised learning with many applications, in which data points must be grouped into clusters so that the _quality_ or _cost_ of the clustering is optimized -- where the cost can be \(k\)-median or \(k\)-center, among a long array of different quality objectives treated in the literature. In some of these applications, the data points being clustered are people -- for example, when households are clustered to determine the location of a bus stop or a hospital -- and in those cases considerations such as fairness and equity come into play. In recent work, various frameworks and methods have been proposed for improving the representation of different sensitive groups in clustering, in cases where optimizing for clustering cost alone may be quite unfair. In such works, the fairness criterion is often set as a constraint, for which we must compute the optimal solution. This is generally an intractable computational problem even for the simplest fairness objectives, since clustering on its own is NP-hard. The best one could hope for is an approximate solution based on a vanilla approximation algorithm for clustering that improves fairness; such approaches have indeed been recently proposed, e.g., Esmaeili et al. , see Chhabra et al.  for a survey.

We take a more general approach to fair clustering: We aim to recover the entire _Pareto front_ of clustering cost and fairness, rather than a single point of that front (such as the best-quality clustering under a fairness constraint). Our work aims to enable a practitioner to choose any trade-off point, rather than computing one of them. We give general sufficient conditions for which we can recover the Pareto front, up to an approximation inherited from the clustering problem itself, and encompassing a variety of quality and fairness objectives used in the literature.

### Our Contributions

We present a novel family of algorithms for tracing the Pareto front between a quality/cost objective and a fairness objective, where each objective can belong in a general class that encompasses most of the ones previously proposed in the literature. Our algorithm requires that the fairness objective satisfy an intuitive property: that it is _pattern-based_. Informally, a fairness objective is pattern-based if it is solely a function of the number of nodes of different attributes in each cluster (see Definition 2.1). Many fairness objectives used in the literature are pattern-based, from the well-known balance  to objectives that measure the proportional violation of pre-specified upper and lower bounds for a sensitive attribute within a cluster [10; 40; 2; 9; 26; 32; 22]. For the quality objective, we consider metric-based cost functions. We study the computation of the quality/fairness trade-off in two settings: in the _assignment problem_, the centers of the clusters are given and the cost is the sum of the distances of the data points from their cluster center; whereas in the _clustering problem_, determining the centers is a part of the problem. We show that our algorithm finds the exact Pareto front of the assignment problem, and an approximation of the Pareto front of the clustering problem (Theorems 3.4, 3.5), with an approximation ratio that depends on the baseline approximation ratio (denoted \(\)) for the minimum cost clustering problem without a fairness objective. The running time is \(O(kn^{l(k-1)})\), where \(k\) is the number of clusters, \(l\) is the number of sensitive attribute values, and \(n\) is the size of the dataset.

Our Pareto front algorithms take time exponential in \(\) and \(k\), and this is necessary. One reason is that the Pareto front may be exponential in size. For many fairness objectives the Pareto front is provably polynomial in size, but even in those cases exponential time is still necessary in general because the baseline problem is NP-hard. Importantly, we also present the first nontrivial algorithmic result for the quality/fairness Pareto front problem in clustering: A _polynomial-time algorithm_ for computing the Pareto front for a new fairness objective, namely the one minimizing the sum (or the maximum), over all clusters, of the deviations from parity of the two protected attributes in each cluster (see Theorem 3.6).

We empirically explore faster methods for computing an approximate Pareto front by adapting constraint optimization methods from fair clustering  in Section 4. These experiments explore the trade-off between accuracy and speed for our problem by comparing the tighter approximation obtained through our proposed algorithms with the looser Pareto front approximation obtained using faster methods.

We believe that our work is the first to address and carry out the computation of the entire Pareto front, and also the first to simultaneously cover a large range of quality and fairness criteria. In comparison, extant literature on fair clustering typically optimizes one objective subject to a constraint on the other objective, with an individualized approach for each combination. Our work is particularly applicable in cases where a decision-maker may be willing to be suboptimal in one objective in order to achieve a better value in a second objective, but does not know _a priori_ what bounds to set on either objective. Our algorithms allow them to explore the entire trade-off, from the highest quality clustering all the way down to the fairest clustering. Finally, our polynomial-time algorithm for computing the Pareto front when the fairness objective is the sum or maximum of imbalances (see Theorem 3.6) is another novel contribution to the subject of fair clustering.

### Related Work

Our work is inspired by a plethora of recent studies on fair clustering that propose various metrics for improving the representation of different sensitive attributes within clusters. Unsupervised clustering is known to be NP-hard even in simple settings . A variety of algorithms have been proposed to approximate the best possible clustering, with approximation ratios differing for different cost objectives (e.g., \(k\)-means , \(k\)-median , \(k\)-center ). Fair clustering goals range from maximizing the worst ratio between two groups across clusters , to minimizing the discrepancy between cluster representation and proportional representation of a group in a population [2; 9; 10; 22; 32; 26; 40], and to equalizing the clustering cost for various groups [7; 15; 31; 50; 54; 62]. Many of these works focus on building specialized approaches for each of the fairness objectives defined, and their objective is to find the best quality clustering that satisfies a specified fairness constraint. Optimizing even for simplest fairness objectives can be NP-hard , with approximation guarantees involving a multiplicative and additive factor, which may depend on the particular objective form and data topology. Our work differs in two significant ways: first, we compute the entire trade-off curve rather than a single optimization point on the curve; second, we provide algorithms that are agnosticto the specific objectives used, giving sufficient conditions on the objectives. We note that our conditions favor most group-fairness objectives defined in the literature. We discuss extensions to other definitions of fairness and limitations of our work in Section 5.

Our work takes a different approach, by aiming to compute the entire Pareto front between seemingly opposing objectives. Knowing the entire Pareto front can aid decision-makers when faced with choosing optimal trade-offs. Many real-world applications are faced with such trade-offs: for example, in facility location problems where a central agent decides on the location of facilities (e.g., buses, hospitals, etc.) based on the location of individuals within a certain region. It is well-known that people of lower socio-economic status often travel longer distances  and have fewer health facilities in their region . A decision maker has multiple objectives to balance: minimal travel time for the entire population and equal access to facilities for different populations. The Pareto front allows the decision maker to balance these objectives in the optimal way: how much improvement can a group of people gain by moving a facility slightly away from the solution given by a single objective (e.g., by performing \(k\)-means)? Computing the Pareto front for facility location problems with multiple objectives has a long history motivated by such questions, with real-world case studies in the Singapore road network  and ambulance placement in Barbados . Further applications are found in extensive surveys .

From a theoretical standpoint, computing the entire Pareto front remains a difficult problem. When an underlying single-objective optimization problem is NP-hard, such as in many combinatorial optimization problems, computing an approximation for the Pareto front is the best one could hope for , for example for the multi-objective shortest path problem [11; 36; 44; 64], zero one knapsack problem [25; 42; 63], the multi-objective spanning tree problem [8; 21; 55], among others. To our knowledge, our work is novel in proposing algorithms for solving a bi-objective optimization problem based on clustering and fairness objectives which require only general properties for the fairness objectives to recover an approximate Pareto front with theoretical guarantees.

More generally, multi-objective optimization has seen a variety of methods for computing points close to the Pareto front in various domains, with methods ranging from evolutionary algorithms [20; 56; 61; 65] to gradient-based methods [12; 47; 49; 51], and more recently to hypernetworks [16; 37; 48; 60] (often requiring inputting a preference vector of the objective values that will output a point on the Pareto front). These methods have also been applied to a problem closely related to clustering: that of facility location with multiple objectives [34; 58; 59], considering specific objectives and without theoretical approximation guarantees.

## 2 Preliminaries

We denote by \(\) the set of data points in \(^{d}\). Assume that \(=\{x_{1},,x_{n}\}\), and for \(j n\) define \(_{j}=\{x_{1},,x_{j}\}\). A _clustering map_ is defined as \(: S\), where \(S\) is a set of \(k\) cluster centers in \(^{d}\) and \(k\) is the number of clusters, considered fixed. A cluster \(C_{i}\) is defined as all the data points for which \((x)=s_{i}\), where \(s_{i} S\) is the center for the \(i\)-th cluster. We call a _clustering_\(\) the set of all clusters \(C_{i}\) (so \(||=k\)), and by \(\) the set of all possible clusterings. Finally, we denote by \(:[l]\) the map between data points and a set of sensitive attributes, indexed from \(1\) to \(l\) (which may represent demographic groups, interest groups, etc). We denote by \(C^{}\) the set of data points in a cluster \(C\) with attribute \(a\), and by \(^{}\) the set of data points with attribute \(a\).

Clustering and Assignment Problems.Unsupervised clustering optimizes a clustering cost objective \(c\), often defined as the sum of distances between points and a set of candidate cluster centers. In a general form, the cost of a clustering is \((_{x}d^{p}(x,(x)))^{1/p}\), for metric \(d\) and some value of \(p\). We call such objectives _metric-based_. By varying \(p=1,2,\) we can obtain the \(k\)-median, \(k\)-means, and \(k\)-center objectives, respectively. The _clustering problem_ is thus finding the clustering that has the minimum cost, over all possible sets of centers and maps from \(\) to the set of centers. Since the clustering problem is hard, one often considers, as a stepping stone, the _assignment problem_, where the centers have been fixed. We shall consider both problems in this paper. In the fair clustering problem we have two objectives, the clustering cost objective \(c\), and a fairness objective \(f\), that aims to balance the representation of sensitive attributes in clusters, further detailed below.

Pareto Front.Consider the set of all clusterings \(\) of \(\), and the two objectives \(c\) (the cost objective) and \(f\) (the fairness objective1), each mapping \(\) to \(\). We say that clustering \(\) dominates clustering \(^{}\) if \(c() c(^{})\), \(f() f(^{})\), and one of the inequalities is strict. Intuitively, if a clustering \(^{}\) is dominated, it is unworthy of further consideration, because it lags behind in both objectives of interest. If however a clustering \(\) is _un_dominated, that is, there is no clustering in \(\) that is simultaneously better on both fronts, then it is part of the solution. The _Pareto front_ is the set of all undominated clusterings.

Fairness Objectives.Our main contribution is an algorithm for computing the Pareto front of the clustering and assignment problems for any metric-based quality function, and any fairness objective - always a function to be minimized - that satisfies the following general condition.

**Definition 2.1** (Pattern-based objectives).: For a clustering \(\), \(i[k]\), and \(a[l]\), let its _pattern_\(P^{}[i,a]\) be the number of data points in cluster \(C_{i}\) with attribute value \(a\). A fairness objective \(f\) that maps \(\) to \(\) is called _pattern-based_ if \(f()\) only depends on the values in \(P^{}[i,a]\).

**Definition 2.2** (Mergeable objectives).: Consider two clusterings \(\) and \(^{}\). We say that \(^{}\) is the result of a merging of \(\) (or \(\) is a refinement of \(^{}\)) if every non-empty cluster of \(^{}\) is the union of clusters of \(\). A fairness objective \(f\) that maps \(\) to \(\) is called _mergeable_ if, whenever \(^{}\) is the result of a merging of \(\), \(f(^{}) f()\).

We discuss the pattern-based and mergeability properties in Appendix B, where we give examples of fairness objectives that are not pattern-based or mergeable. Below, we introduce several fairness objectives commonly found in the literature, which we use in our experiments. All of these objectives are pattern-based and mergeable, as proved formally in Appendix B.1.

Balance objective (Definition \(1\) in Chierichetti et al. ): For sensitive attributes that can take two values, indexed \(1\) and \(2\), the balance of a cluster \(C\) is defined as \((C)=(|C^{1}|/|C^{2}|,|C^{2}|/|C^{1}|)\). The balance objective for a clustering \(\) is then defined as

\[()=_{C}(C)\] (1)

The aim is to maximize balance, or equivalently, to minimize the negative balance \(f()=-()\). Balance has been used in fair clustering as a measure of equalizing proportions of different groups across clusters . In practice, optimizing Balance is both difficult and does not measure how far the proportions of sensitive groups in a clustering are from their _true_ proportions in the population. For this reason, objectives based on _proportional violation_ have been proposed, allowing a central decision-maker to input upper and lower bounds for desired proportions of groups in each cluster, and measured the deviation from these bounds .

Proportional violation objectives:As defined in Esmaeili et al. , for every sensitive attribute \(a[l]\), define upper and lower bounds \(_{a}\) and \(_{a}\) with the aim of satisfying \(_{a}|C||C^{a}|_{a}|C|\) for all clusters \(C\). Since this is not always feasible, we define the worst proportional violation of attribute \(a\) in cluster \(C\) as the minimum non-negative value \(_{a}^{C}\) such that

\[(_{a}-_{a}^{C})|C||C^{a}|(_{a}+ _{a}^{C})|C|\] (2)

Then, the proportional violation-based objectives are defined as:

\[=_{a[l]}_{C }_{a}^{C},=_{a[l],C }_{a}^{C},\] (3)

\[=_{a[l],C}_{a}^{C}, =_{a[l]}_{C }_{a}^{C}\] (4)

These objective operationalize utilitarian and egalitarian concepts from social choice , minimizing either the sum of proportional violations or the worst violation across attributes.

_Sum of imbalances objective:_ Finally, for two interest groups in the population (\(l=2\)) the following objective is quite natural:

\[=_{i[k]}|C_{i}^{1}-C_{i}^{2}|,\]that is to say, the sum of the deviations from equality between the two attribute values in the clusters. This objective is most appropriate when datasets contain relatively equal proportions of the two groups. Rather remarkably, the Pareto front for this objective can be computed in polynomial time.

## 3 Algorithms for Computing the Pareto Front

### A Dynamic Programming Algorithm for Recovering the Assignment Pareto Front

We shall now present the main Algorithm. Define an \(\)-pattern \(P\) to be a \(k\)-tuple of \(l\)-tuples of non-negative integers such that \(_{i[k]}P[i,a]=|^{a}|, a[l]\). \(P[i,a]\) specifies the number of data points in cluster \(i\) of attribute \(a\). That is, an \(\)-pattern is a clustering except only the attribute values of the points have been specified.2 Complete proofs to all subsequent results can be found in Appendix A.

```
1:Input: Number of clusters \(k\), a set of \(n\) data points \(\) with \(l\) attribute values, \(k\) centers \(S=\{s_{1},,s_{k}\}\), and metric-based cost objective \(c\) parameterized by \(d,p\).
2:Output: A table \(T_{n}\) containing the solutions of the assignment problem for \(\) for all \(\)-patterns.
3:Method: Dynamic programming. We shall compute \(T_{0},T_{1}, T_{n}\).
4:Initialize \(T_{0}\) to contain the null pattern with cost 0 and the empty clustering.
5:for\(j=1\) to \(n\)do
6: Generate all \(_{j}\)-patterns, where \(_{j}=\{x_{1},,x_{j}\}\).
7: For each \(_{j}\)-pattern \(P\), and for each cluster \(i\) such that \(P[i,a]>0\), where \(a\) is the attribute
8: value of \(x_{j}\), look up in \(T_{j-1}\) the cost of the pattern \(P_{i}\), which is \(P\) with \(x_{j}\) omitted from
9: cluster \(i\), and compute \(T_{j-1}(P_{i})+d^{p}(x_{j},s_{i})\).
10: Let \(i^{*}\) be the cluster index that minimizes \(T_{j-1}(P_{i})+d^{p}(x_{j},s_{i})\).
11: Set \(T_{j}(P) T_{j-1}(P_{i^{*}})+d^{p}(x_{j},s_{i^{*}})\).
12: Store at \(T_{j}(P)\) the clustering from \(T[P_{i^{*}}]\), with \(x_{j}\) added at cluster \(i^{*}\). return\(T_{n}\) ```

**Algorithm 1** Dynamic Programming Algorithm for Computing the Assignment Pareto Front

At the conclusion of the algorithm, the table \(T_{n}\) contains the lowest cost clustering \(\) for each \(\)-pattern \(P\), such that \(P^{}=P\), together with its cost \(c()\). Then, we can find the Pareto front by first sorting these clusterings for all \(\)-patterns \(P\) in increasing \(c\), and then traversing them in order, computing the unfairness of each pattern, remembering the smallest unfairness we have seen so far, and omitting any pattern that has unfairness larger than the smallest seen so far.

_Remark 3.1_.: The above calculation of \(T_{n}\) can be achieved alternatively by a simpler to state but slightly slower algorithm: first generate all \(\)-patterns, and then compute the optimum assignment of each by min-cost flow.

**Theorem 3.2**.: _Algorithm 1 finds the Pareto front of the assignment problem in time \(O(kn^{l(k-1)})\), for any metric-based clustering objective and any pattern-based fairness objective._

**Proof Sketch:** We prove this theorem by finding an invariant of Algorithm 1: \(T_{j}[P]\) stores the lowest cost assignment of \(_{j}\) that maps to pattern \(P\). We maintain this invariant as we build up our table by searching over possible smaller patterns that we can add our next datapoint \(x_{j}\) to and creating the lowest cost assignment that maps to \(P\). Therefore, the assignments stored at \(T_{n}[P]\) are the candidate points for the Pareto front. A simple filtering heuristic, as described above, removes the dominated points from this set of candidates. In terms of running time, the number of possible patterns of total size up to \(n\) is upper bounded by \(n^{l(k-1)}\), since each of the \(lk\) entries of \(P\) takes values between \(0\) and \(n\), and the tuple corresponding to the last cluster \(k\) is fully determined by the other clusters. For each considered pattern, we need to look up at most \(k\) previous entries of the table \(T\).

### Approximating the Pareto Front for the Clustering Problem

As we saw, Algorithm 1 computes the Pareto front of the Assignment problem exactly for any input centers \(S\). We next show that it also provides an approximation for the Pareto front of the clustering problem. For this purpose, we first use a vanilla clustering algorithm \(\) for the single-objectiveproblem of minimizing the cost \(c\), to obtain the set \(S\) of cluster centers, and then apply Algorithm 1 with this set of centers \(S\). Let \(\) be the approximation ratio of algorithm \(\).

**Definition 3.3** (\(\)-approximation of the Pareto Set for clustering).: For parameters \(=(w_{c},w_{f})\), we define the \(\)-approximation of the Pareto set \(X_{P}\) as a set of feasible points \(X^{}_{P}\) such that \( x X_{P}, x^{} X^{}_{P}\) such that \(c(x^{}) w_{c} c(x)\) and \(f(x^{}) w_{f} f(x)\).

This definition is a direct generalization of \(\)-approximate Pareto set defined by Papadimitriou and Yannakakis . One may recover the \(\)-approximate definition by setting \(=(w_{c},w_{f})-1\).

**Theorem 3.4**.: _Algorithm 1 finds a \((2+,1)\)-approximation of the Pareto set of the clustering problem with a metric-based cost objective \(c\) and a pattern-based and mergeable fairness objective \(f\)._

Proof Sketch:We argue that for any clustering map \(^{*}\) with centers \(S^{*}\) in the Pareto set for clustering, there exists an assignment to the centers \(S\) found by an approximate vanilla clustering algorithm that achieves the same or better fairness and at most \((2+)\) times the clustering cost. Then, since Algorithm 1 finds the Pareto set of the assignment problem, we are guaranteed the stated approximation. We construct this assignment using a "routing" argument, first introduced in Bera et al. : we create an assignment \(^{}\) by routing all points in \(^{*}\) with center \(s^{*} S^{*}\) to the center in \(S\) nearest to \(s^{*}\). Given that the clustering cost is metric-based, we use the triangle inequality on the cost objective to argue that the cost of \(^{}\) w.r.t. \(S\) is not more than \((2+)\) times the cost of \(^{*}\) w.r.t. \(S^{*}\). Then, we use the mergeability property of the fairness objective to argue that \(^{}\) has a weakly better fairness than \(^{*}\). We can, in fact, modify Algorithm 1 to include non-mergeable fairness objectives, guaranteeing the same approximation ratio and time complexity:

**Theorem 3.5**.: _We can compute a \((2+,1)\)-approximation of the Pareto set for the clustering problem with a metric-based cost objective \(c\) and a pattern-based fairness objective \(f\) in time \(O(kn^{l(k-1)})\)._

Proof Sketch:The trick here is to transform non-mergeable fairness objectives into mergeable ones, and then apply Algorithm 1. In doing so, we control this transformation through re-assigning the centers of potentially empty clusters (which become an issue in non-mergeable fairness functions). Specifically, for patterns that have empty clusters, we search for the best possible fairness over all ways to reassign the empty clusters' centers to other centers' locations and divide up the points in the non-empty centers. A detailed description and proof for this modified algorithm can be found in Appendix A.

### Intractability

The running time of Algorithm 1 for computing the Pareto front has the parameters \(k,l\) in the exponent of \(n\). What evidence do we have that this computation is necessary?

One reason would be that the sheer size of the Pareto front may be exponential. For some objectives, including the Balance and the Group Egalitarian objectives defined in Section 2, the Pareto front is provably of polynomial size. The reason is that all possible values of these objectives are rational numbers involving integers that are all smaller than \(n\), and there are \(O(n^{2})\) possible different such rational numbers. For other objectives, there may be instances of exponential Pareto fronts, as the objectives that sum over the clusters.

However, a different argument provides a justification of the algorithm's exponential performance: In several papers in recent literature (e.g., see [26; 27]), it is shown that, for a variety of cost functions \(c\) and fairness objectives \(f\) (including all mentioned proportional violation based objectives), it is NP-hard to find the assignment \(\) that has the smallest \(c()\) under the constraint that \(f() F\) (for some bound \(F\)). We conclude that, unless P = NP, there is no polynomial-time algorithm for outputting the Pareto front, for at least some combinations of \(c\) and \(f\). As a footnote to this discussion, the above complexity argument rules out polynomial algorithms, but not exponential algorithms of the form, for example, \(O(2^{k}n^{3})\), which is much more benign than \(O(n^{(k-1)l})\). These would be ruled out, subject to complexity conjectures, if the problem of finding the least costly clustering subject to fairness constraints were shown to be W-complete, a more severe form of complexity that rules out this more benign exponential performance . We leave this as an interesting open question in the theory of the fairness-cost trade-off of clustering.

### A Polynomial Algorithm for the Pareto Front of the Sum of Imbalances

For _specific_ cost and fairness objectives, there is still hope that polynomial-time algorithms exist. As we show below, for a simple objective derived from the Balance objective, such an algorithm is possible. For the Sum of Imbalances fairness objective and a clustering objective defined in Section 2, we want to compute the Pareto front when \(l=2\). Surprisingly, it turns out that this problem can be solved in polynomial time by a reduction to the weighted matching problem.

**Theorem 3.6**.: _If \(l=2\) and the fairness objective \(f\) is the sum of imbalances \(f()=_{i[k]}|C_{i}^{1}-C_{i}^{2}|\), then the Pareto front of the assignment problem can be computed in polynomial time._

**Proof Sketch:** The image of \(f\) is contained in the integer set \(\{1,,n\}\). For each potential value \(j\), we construct a graph \(G_{j}\) that contains \(\) as nodes and another \(j\) 'dummy' nodes. We put an edge \((u,v)\) between every \(u,v\) with different sensitive attribute value with weight equal to the cost \(_{i}(d^{p}(u,i)+d^{p}(v,i))\). Between every data point \(u\) and dummy point \(v\) put an edge \((u,v)\) with cost \(_{i}d^{p}(x,s_{i})\). Finding the minimum cost perfect matching in this graph gives the minimum cost of an assignment with fairness value \(j\). The same result can be shown similarly for the Max Imbalance objective, \(_{i[k]}|C_{i}^{1}-C_{i}^{2}|\) (Theorem A.5).

_Remark 3.7_.: These objectives are quite natural extensions of the Balance objective, as they minimize the sum or max, over the \(k\) clusters, of the deviation from equality between the two groups. It is worth noting that slight modification of these objectives place the problem back in the NP-complete space: A construction of Bercea et al.  (see also Esmaeili et al. , Theorem 5.1) implies that for minimizing the deviations not from equality (\(1:1\)) but from the ratio \(1:3\), it is NP-complete to find even the point of the Pareto front with the best fairness value.

## 4 Experiments

We implement our proposed algorithm (Algorithm 1) for finding the Pareto front on three real-world datasets and five fairness objectives, as detailed below.

Datasets:We use the following real-world datasets for our experiments: the Adult dataset and the Census dataset retrieved from the UCI repository (as the Census1990 version) [43; 46], and the BlueBike trip history dataset.3 The Adult and Census datasets contain numeric attributes such as income, age, education level, often used in applications of fair clustering [6; 19; 26]. The BlueBike dataset contains the starting location, ending location, as well as various user attributes for users of the BlueBike bike sharing system in the Boston area. We use as features the starting and ending longitude and latitude values for all rides during a period of a week in May, 2016. These routes are a proxy for common traffic patterns, for which clustering can inform of high-density areas, with the purpose of deciding on new locations for bike stations or public transportation. Clustering and related framings have long been used in facility location problems, for which fairness is a central question [1; 41; 53; 62]. As the datasets are prohibitively large, we sample from each \(1,000\) data points. Further details about the datasets can be found in Appendix C.

Objectives:We implement the \(k\)-means clustering objective and five different fairness objectives, as defined in Section 2 (Balance, Group Utilitarian, Group Utilitarian-Sum, Group Egalitarian, and Group Egalitarian-Sum).

Experimental details:We first note that our approach for finding the Pareto front is agnostic to the specific vanilla clustering algorithm used. For our datasets, we use the \(k\)-means++ clustering algorithm as the vanilla clustering that has an approximation ratio of \(O(log(k))\). All datasets have numeric attributes, allowing a direct embedding into Euclidean space and using k-means++ directly on the features. We use the self-reported gender (male or female) as the sensitive attribute for all datasets. Each sensitive attribute \(a\) has a proportion \(p_{a}\) in the general population. For the proportional violation objectives, we set upper and lower bounds as a \(\)-deviation from the true proportions \((p_{a})_{a}\): \(_{a}=(1+)p_{a},_{a}=(1-)p_{a}\). We set \([0.005,0.05]\) for all experiments and \(k=2\) clusters. Additional experiments for \(k=3\) are reported in Appendix E, noting qualitatively similar results. All experiments are run on local computers, using Python 3.9, \(k\)-means++ , NetworkX , andCPLEX for the implementation of the FCBC algorithm [52; 26] with \(=2^{-10}\) and \(N=50\) runs. An empirical analysis of the running time for Algorithms 1 and 2 can be found in Section D, Figure 5.4

### Pareto Front on Real-World Data

Figure 1 illustrates the Pareto front recovered by our dynamic programming approach (Algorithm 1) on the real-world datasets: the curves obtained are an exact recovery of the Pareto front for the _assignment_ problem (as we are not re-computing the clusters centers during the implementation), and thus an approximation for the true Pareto front of the _clustering_ problem. We note that the Balance objective and the proportional violation objectives differ: higher balance is considered fairer, whereas lower proportional violation is considered fairer, hence the different shapes of the Pareto fronts. From an evaluation point of view, for each assignment found on the Pareto front, we compute its clustering cost with respect to its _actual_ centers, rather than the initial centers found by \(k\)-means++.

We note that the Pareto front is often, but not always strictly convex or concave, as it simply contains all the undominated points. We note that the proportional violation values will always be worse for the summed objectives than for their min-max equivalents, since the worst proportional violation \(_{a}^{C}\) is always non-negative, \( a[l],C\).

A particular advantage of finding the entire Pareto front is visible for the Balance objective in all datasets: as the clustering cost increases, the gain in the Balance objective becomes negligible; thus, a practitioner wishing to achieve some level of fairness may gain a lot in quality by allowing Balance to decrease by a minimal amount.

### Exploring Faster Pareto Front Approximations

We explore faster algorithms for recovering the Pareto front for the clustering problem. In particular, we leverage a recently proposed linear programming approach that imposes an upper bound on the clustering objective and optimizes a fairness objective, the FCBC algorithm proposed by Esmaeili et al. . For the Group Utilitarian and Group Egalitarian objectives with a clustering

Figure 1: Pareto front recovered by Algorithm 1 for the Adult, Census, and BlueBike datasets (by row), for various fairness objectives (by column), for \(k=2\) clusters.

cost upper bound input \(U\), FCBC presents a polynomial-time approach for finding an approximation of a point \(x\) on the Pareto front that has a clustering cost upper bounded by a quantity \((2+)U\) with a fairness additive approximation of \(\). Here, \(\) is the approximation ratio of a vanilla clustering algorithm for the clustering objective, and \(\) is an additive approximation for the fairness objective. Thus, we can extend the \(\)-approximation of a Pareto set definition (Definition 3.3) to include an additive approximation term: for parameters \(=((w_{c},v_{c}),(w_{f},v_{f}))\), we can define the \((,)\)-approximation of the Pareto set \(X_{P}\) as a set of feasible points \(X_{P}^{}\) such that \( x X_{P}, x^{} X_{P}^{}\) such that \(c(x^{}) w_{c} c(x)+v_{c}\) and \(f(x^{}) w_{f} f(x)+v_{f}\). We note that Algorithm 1 gives only a multiplicative approximation, so \(v_{c}=v_{f}=0\). In contrast, for a point \(x X_{P}\) on the true Pareto front, FCBC recovers a \(((2+,0),(1,))\)-approximation.5

We extend the FCBC algorithm by allowing a sweep over the clustering cost upper bound \(U\), thus, in theory, obtaining an approximation of the Pareto front in polynomial time (for a detailed description, see Algorithm 2 in Appendix D).

Figure 2 shows that repeated FCBC (Algorithm 2) recovers few points on the Pareto front recovered by Algorithm 1: sometimes it recovered the vanilla clustering cost and fairness (the upper most left point in panels b,c,e,f), whereas in other cases it recovers dominated clustering assignments (in panels a-d). We attribute this inaccuracy in recovery to the additive approximation in the fairness objective. Furthermore, whereas both our dynamic programming approach and repeated FCBC have an approximation ratio of \((2+)\) in the clustering objective, dynamic programming often gets a strictly better cost for similar fairness values. In other words, where repeated FCBC gains in running time,6 it loses in recovery accuracy and clustering cost. This is particularly problematic when the only point recovered by FCBC is the vanilla clustering assignment: this means that even when a practitioner may be willing to trade-off significant clustering cost in order to improve fairness, that trade-off is not realizable in practice solely through FCBC.

Furthermore, the FCBC algorithm does not work for objectives summing over the clusters, such as Group Utilitarian-Sum and Group Egalitarian-Sum. For such objectives, there is no polynomial time algorithm that can recover the Pareto front to within an additive approximation of \(O(n^{})\), for \([0,1)\) (see Theorem 7.1 in Esmaeili et al. (2018)). Our approach, however, can also include such objectives, as we show both in theory and in practice.

## 5 Discussion

Overall, our work shows the versatility of our proposed algorithms for a variety of fairness and clustering objectives. We provide simple properties sufficient in theory for the recovery of the Pareto front for the (clustering, fairness)-biobjective optimization problem, with extensive experiments on real-world datasets. We discuss limitations and future directions of our work in this section.

First, while our approach has the advantage of being agnostic to specific objectives, it loses in running time as compared to approaches that optimize for specific fairness objectives. While previous work provides approximation algorithms for optimization clustering under a fairness constraint, none offers a method for computing the Pareto front. On the question 'can we have faster algorithms with worse approximation bounds?', the answer is yes. Our paper provides (the first, to our knowledge) such exploration: We show in Section 4.2 that we can adapt such polynomial-time methods to compute an approximation of the Pareto front; however, what we gain in runtime, we lose in approximation bounds: the repeated FCBC algorithm has an additive approximation on the fairness objective that can get large in practice (we get a different Pareto front, with points quite far away in the objective cost, compared to the dynamic programming approach), and with no theoretical bounds on the additive approximation.

A future direction could study faster algorithms that can recover a similar approximation of the Pareto front. Interesting theoretical open questions emerge: while our analysis ruled out polynomial algorithms for general objectives, are there exponential algorithms (i.e. of the form \(O(2^{k}n^{3})\)), that still provide an improvement from \(O(n^{(k-1)l})\)-type of algorithms? And, are there other objectivesthat admit polynomial-time algorithms for computing an approximate Pareto, aside from Sum/Max of Imbalances? Furthermore, future work could investigate algorithms for recovering the Pareto front for fairness objectives that are not pattern-based, which is a prerequisite for our algorithms. We provide some examples of such objectives in the Appendix.

Our approach is best suited for group fairness definitions. Extending this work to other definitions would be an excellent avenue for future work. We note that for some individual fairness definitions, the notion of a Pareto front does not apply: for example, the socially fair \(k\)-means clustering notion proposed by Ghadiri et al.  defines a single optimization objective that already incorporates fairness (by minimizing the max distance between points in each group and their cluster centers). With this definition, the fairness objective and the clustering objective are not separated in a multi-objective optimization problem, but rather combined in a single objective. Therefore, there is no Pareto front, since this notion applies to a multi-objective optimization problem. For other definitions of individual fairness, such as recent adaptations of individual fairness under bi-criteria optimization problems , one can apply a repeated approximation algorithm under an upper bound on one of the objectives (similar to the repeated-FCBC algorithm). In doing so, one would obtain loose approximation guarantees (see, for example, the approximation guarantee for individual fairness proved by Mahabadi and Vakilian ). Dynamic programming approaches would not directly apply; however, we think this would be an excellent avenue for future work.

Finally, we assumed that the sensitive attributes are disjoint. For overlapping attributes, one could assign a new sensitive attribute to every overlap set and apply our approach, however, with a significant increase in running time. Future work could investigate alternative approaches that optimize running time for overlapping attributes.