# Learning Rate Free Sampling

in Constrained Domains

 Louis Sharrock

Department of Mathematics and Statistics

Lancaster University, UK

l.sharrock@lancaster.ac.uk

&Lester Mackey

Microsoft Research New England

Cambridge, MA

lmackey@microsoft.com

Christopher Nemeth

Department of Mathematics and Statistics

Lancaster University, UK

c.nemeth@lancaster.ac.uk

###### Abstract

We introduce a suite of new particle-based algorithms for sampling in constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.

## 1 Introduction

The problem of sampling from unnormalised probability distributions is of central importance to computational statistics and machine learning. Standard approaches to this problem include Markov chain Monte Carlo (MCMC)  and variational inference (VI) . More recently, there has been growing interest in particle-based variational inference (ParVI) methods, which deterministically evolve a collection of particles towards the target distribution and combine favourable aspects of both MCMC and VI. Perhaps the most well-known of these methods is Stein variational gradient descent (SVGD) , which iteratively updates particles according to a form of gradient descent on the Kullback-Leibler (KL) divergence. This approach has since given rise to several extensions  and found success in a wide range of applications .

While such methods have enjoyed great success in sampling from unconstrained distributions, they typically break down when applied to constrained targets [see, e.g., 60, 82]. This is required for targets that are not integrable over the entire Euclidean space (e.g., the uniform distribution), when the target density is undefined outside a particular domain (e.g., the Dirichlet distribution), or when the target must satisfy certain additional constraints (e.g., fairness constraints in Bayesian inference ). Notable examples include latent Dirichlet allocation , ordinal data models , regularised regression , survival analysis , and post-selection inference . In recent years, there has been increased interest in this topic, with several new methodological and theoretical developments .

One limitation shared by all of these methods is that their performance depends, often significantly, on a suitable choice of learning rate. In principle, convergence rates for existing constrained sampling schemes (e.g., [1, Theorem 1] or [86, Corollary 1]) allow one to compute the optimal learning rate for a given problem. In practice, however, this optimal learning rate is a function of the unknown target and thus cannot be computed. Motivated by this problem, in this paper we introduce a suite of new sampling algorithms for constrained domains which are entirely learning rate free.

**Our contributions** We first propose a unifying perspective of several existing constrained sampling algorithms, based on the viewpoint of sampling in constrained domains as a'mirrored' optimisation problem on the space of probability measures. Based on this perspective, we derive a general class of solutions to the constrained sampling problem via the mirrored Wasserstein gradient flow (MWGF). The MWGF includes, as special cases, several existing constrained sampling methods, e.g., mirrored Langevin dynamics  and mirrored SVGD (MSVGD) . Using this formulation, we also introduce mirrored versions of several other particle-based sampling algorithms which are suitable for sampling in constrained domains, and study their convergence properties in continuous time.

By leveraging this perspective, and extending the coin sampling methodology recently introduced in , we then obtain a suite of learning rate free algorithms suitable for constrained domains. In particular, we introduce mirrored coin sampling, which includes as a special case Coin MSVGD, as well as several other tuning-free constrained sampling algorithms. We also outline an alternative approach which does not rely on a mirror mapping, namely, coin mollified interaction energy descent (Coin MIED). This algorithm can be viewed as the natural coin sampling analogue of the method recently introduced in . Finally, we demonstrate the performance of our methods on a wide range of examples, including sampling on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our empirical results indicate that our methods achieve competitive performance with the optimal performance of existing approaches, with no need to tune a learning rate.

## 2 Preliminaries

**The Wasserstein Space**. We will make use of the following notation. For any \(^{d}\), we write \(_{2}()\) for the set of probability measures \(\) on \(\) with finite \(2^{}\) moment: \(_{}||x||^{2}(x)<\), where \(||||\) denotes the Euclidean norm. For \(_{2}()\), we write \(L^{2}()\) for the set of measurable \(f:\) with finite \(||f||_{L^{2}()}^{2}=_{}||f(x)||^{2}(x)\). For \(f,g L^{2}()\), we also define \( f,g_{L^{2}()}=_{}f(x)^{}g(x)(x)\). Given \(_{2}()\) and \(T L^{2}()\), we write \(T_{\#}\) for the pushforward of \(\) under \(T\), that is, the distribution of \(T(X)\) when \(X\).

Given \(,_{2}()\), the Wasserstein \(2\)-distance between \(\) and \(\) is defined according to \(W_{2}^{2}(,)=_{(,)}_{ }||x-y||^{2}(x,y)\), where \((,)\) denotes the set of couplings between \(\) and \(\). The Wasserstein distance \(W_{2}\) is indeed a distance over \(_{2}()\)[2, Chapter 7.1], with the metric space \((_{2}(),W_{2})\) known as the Wasserstein space. Given a functional \(:()(-,]\), we will write \(_{W_{2}}()\) for the Wasserstein gradient of \(\) at \(\), which exists under appropriate regularity conditions [2, Lemma 10.4.1]. We refer to App. A for further details on calculus in the Wasserstein space.

**Wasserstein Gradient Flows**. Suppose that \(_{2}()\) and that \(\) admits a density \( e^{-V}\) with respect to Lebesgue measure,1 where \(V:\) is a smooth potential function. The problem of sampling from \(\) can be recast as an optimisation problem over \(_{2}()\)[e.g., 99]. In particular, one can view the target \(\) as the solution of

\[=*{arg\,min}_{_{2}()}()\] (1)

where \(:()(-,]\) is a functional uniquely minimised at \(\). In the unconstrained case, \(=^{d}\), a now rather classical method for solving this problem is to identify a continuous process which pushes samples from an initial distribution \(_{0}\) to the target \(\). This corresponds to finding a family of vector fields \((v_{t})_{t 0}\), with \(v_{t} L^{2}(_{t})\), which transports \(_{t}\) to \(\) via the continuity equation

\[}{ t}+(v_{t}_{t})=0.\] (2)A standard choice is \(v_{t}=-_{W_{2}}(_{t})\), in which case the solution \((_{t})_{t 0}\) of (2) is referred to as the Wasserstein gradient flow (WGF) of \(\). In fact, for different choices of \((v_{t})_{t 0}\), one can obtain the continuous-time limit of several popular sampling algorithms [3; 20; 40; 46; 51; 63; 99]. Unfortunately, it is not straightforward to extend these approaches to the case in which \(^{d}\) is a constrained domain. For example, the vector fields \(v_{t}\) may push the random variable \(x_{t}\) outside of its support \(\), thus rendering all future updates undefined.

## 3 Mirrored Wasserstein Gradient Flows

We now outline one way to extend the WGF approach to the constrained case, based on the use of a mirror map. We will first require some basic definitions from convex optimisation [e.g., 77]. Let \(\) be a closed, convex domain in \(^{d}\). Let \(:\{\}\) be a proper, lower semicontinuous, strongly convex function of Legendre type . This implies, in particular, that \(()=^{d}\) and \(:^{d}\) is bijective [77, Theorem 26.5]. Moreover, its inverse \(()^{-1}:^{d}\) satisfies \(()^{-1}=^{*}\), where \(^{*}:^{d}\) denotes the Fenchel conjugate of \(\), defined as \(^{*}(y)=_{x} x,y-(x)\). We will refer to \(:^{d}\) as the mirror map and \(()=^{d}\) as the dual space.

### Constrained Sampling as Optimisation

Using the mirror map \(:^{d}\), we can now reformulate the constrained sampling problem as the solution of a'mirrored' version of the optimisation problem in (1). Let us define \(=()_{\#}\), with \(=(^{*})_{\#}\). We can then view the target \(\) as the solution of

\[=(^{*})_{\#},\ \ =*{arg\,min}_{_{2}(^{d})}(),\] (3)

where now \(:_{2}(^{d})(-,]\) is a functional uniquely minimised by \(=()_{\#}\). The motivation for this formulation is clear. Rather than directly solving a constrained optimisation problem for the target \(_{2}()\) as in (1), we could instead solve an unconstrained optimisation problem for the mirrored target \(_{2}(^{d})\), and then recover the target via \(=(^{*})_{\#}\). This is a rather natural extension of the formulation of sampling as optimisation to the constrained setting.

### Mirrored Wasserstein Gradient Flows

One way to solve the mirrored optimisation problem in (3) is to find a continuous process which transports samples from \(_{0}:=()_{\#}_{0}_{2}(^{d})\) to the mirrored target \(\). According to the mirror map, this process will implicitly also push samples from \(_{0}\) to the target \(\). More precisely, we would like to find \((w_{t})_{t 0}\), where \(w_{t}:^{d}^{d}\), which evolves \(_{t}\) on \(^{d}\) and thus \(_{t}\) on \(\), through

\[}{ t}+(w_{t}_{t})=0\ \ \,\ \ \ _{t}=(^{*})_{\#}_{t}\] (4)

where \((w_{t})_{t 0}\) should ensure convergence of \(_{t}\) to \(\). In the case that \(w_{t}=-_{W_{2}}(_{t})\), we will refer to (4) as the mirrored Wasserstein gradient flow (MWGF) of \(\). The idea of (4) is to simulate the WGF in the (unconstrained) dual space and then map back to the primal (constrained) space using a carefully chosen mirror map. This approach bypasses the inherent difficulties associated with simulating a gradient flow on the constrained space itself.

While a similar approach has previously been used to derive certain mirrored sampling schemes [43; 82; 86], these works focus on specific choices of \(\) and \((w_{t})_{t 0}\), while we consider the general case. Our general perspective provides a unifying framework for these approaches, whilst also allowing us to obtain new constrained sampling algorithms and to study their convergence properties (see App. B). We now consider one such approach in detail.

#### 3.2.1 Mirrored Stein Variational Gradient Descent

MSVGD  is a mirrored version of the popular SVGD algorithm. In , MSVGD is derived using a mirrored Stein operator in a manner analogous to the original SVGD derivation . Here, we take an alternative perspective, which originates in the MWGF. This formulation is more closely aligned with other more recent papers analysing the non-asymptotic convergence of SVGD [51; 78; 85; 86].

We will require the following additional notation. Let \(k:\) denote a positive semi-definite kernel and \(_{k}\) the corresponding reproducing kernel Hilbert space (RKHS) of real-valued functions \(f:\), with inner product \(,_{_{k}}\) and norm \(||||_{_{k}}\). Let \(:=_{k}^{d}\) denote the Cartesian product RKHS, consisting of elements \(f=(f_{1},,f_{d})\) for \(f_{i}_{k}\). We write \(S_{,k}:L^{2}()\) for the operator \(S_{,k}f= k(x,)f(x)(x)\). We assume \( k(x,x)(x)<\) for \(_{2}()\), in which case \( L^{2}()\) for all \(_{2}()\)[52, Sec. 3.1]. We also define the identity embedding \(i: L^{2}()\) with adjoint \(i^{*}=S_{,k}\). Finally, we define \(P_{,k}:L^{2}() L^{2}()\) as \(P_{,k}=iS_{,k}\).

We are now ready to introduce our perspective on MSVGD. We begin by introducing the continuous-time MSVGD dynamics, which are defined by the continuity equation

\[}{ t}-(P_{_{t},k_{}} (}{})_{t})=0,_{t}=( ^{*})_{\#}_{t},\] (5)

where \(k_{}(y,y^{})=k(^{*}(y),^{*}(y^{}))\) for some base kernel \(k:\). Clearly, this is a special case of the MWGF in (4), in which \((w_{t})_{t 0}\) are defined according to \(w_{t}=-P_{_{t},k_{}}_{W_{2}}(_{t})\), with \((_{t})=(_{t}||)\). In particular, \(w_{t}\) can be interpreted as the negative Wasserstein gradient of \((_{t}||)\), the KL divergence of the \(_{t}\) with respect to \(\), under the inner product of \(_{k_{}}\).

The key point here is that, given samples from \(_{t}\), estimating \(P_{_{t},k_{}}(}{})\) is straightforward. In particular, if \(_{||y^{}||}k_{}(y^{},)(y^{ })=0\), then, integrating by parts,

\[P_{_{t},k_{}}(}{})(y)=-_{^{d }}[k_{}(y^{},y)_{y^{}}(y^{})+_{y^{ }}k_{}(y^{},y)]_{t}(y^{}).\] (6)

To obtain an implementable algorithm, we must discretise in time. By applying an explicit Euler discretisation to (5), we arrive at

\[_{t+1}=(- P_{_{t},k_{}}( }{}))_{\#}_{t},_{t+1}=(^{*} )_{\#}_{t+1},\] (7)

where \(>0\) is a step size or learning rate, and \(\) is the identity map. This is the population limit of the MSVGD algorithm in . Now, suppose \(_{0}_{2}()\) admits a density with respect to the Lebesgue measure. In addition, suppose \(x_{0}_{0}\) and \(y_{0}=(x_{0})\). Then, for \(t_{0}\), if we define

\[y_{t+1}=y_{t}- P_{_{t},k_{}}(}{} )(y_{t}), x_{t+1}=^{*}(y_{t+1}),\] (8)

then \((_{t})_{t_{0}}\) and \((_{t})_{t_{0}}\) in (7) are precisely the densities of \((y_{t})_{t_{0}}\) and \((x_{t})_{t_{0}}\) in (8). In practice, these densities are unknown and must be estimated using samples. In particular, to approximate (8), we initialise a collection of particles \(x_{0}^{i}}}{{}}_{0}\) for \(i[N]\), set \(y_{0}^{i}=(x_{0}^{i})\), and then update

\[y_{t+1}^{i}=y_{t}^{i}- P_{_{t},k_{}}(_{t}}{})(y_{t}^{i}), x_{t+1}^{i}=^{*}(y_{t+1} ^{i})\] (9)

where \(_{t}=_{j=1}^{N}_{y_{t}^{j}}\). This is precisely the MSVGD algorithm introduced in  and since also studied in .

#### 3.2.2 Other Algorithms

In App. B, we outline several algorithms which arise as special cases of the MWGF. These include existing algorithms, such as the mirrored Langevin dynamics (MLD)  and MSVGD , and two new algorithms, which correspond to mirrored versions of Laplacian adjusted Wasserstein gradient descent (LAWGD)  and kernel Stein discrepancy descent (KSDD) . We also study the convergence properties of these algorithms in continuous time.

## 4 Mirrored Coin Sampling

By construction, any algorithm derived as a discretisation of the MWGF, including MSVGD, will depend on an appropriate choice of learning rate \(\). In this section, we consider an alternative approach, leading to new algorithms which are entirely learning rate free. Our approach can be viewed as an extension of the coin sampling framework introduced in  to the constrained setting, based on the reformulation of the constrained sampling problem as a mirrored optimisation problem.

### Coin Sampling

We begin by reviewing the general coin betting framework [71; 72; 22]. Consider a gambler with initial wealth \(w_{0}=1\) who makes bets on a series of adversarial coin flips \(c_{t}\{-1,1\}\), where \(+1\) denotes heads and \(-1\) denotes tails. We encode the gambler's bet by \(x_{t}\). In particular, \((x_{t})\{-1,1\}\) denotes whether the bet is on heads or tails, and \(|x_{t}|\) denotes the size of the bet. Thus, in the \(t^{}\) round, the gambler wins \(|x_{t}c_{t}|\) if \((c_{t})=(x_{t})\) and loses \(|x_{t}c_{t}|\) otherwise. Finally, we write \(w_{t}\) for the wealth of the gambler at the end of the \(t^{}\) round. The gambler's wealth thus accumulates as \(w_{t}=1+_{s=1}^{t}c_{s}x_{s}\). We assume that the gambler's bets satisfy \(x_{t}=_{t}w_{t-1}\), for a betting fraction \(_{t}[-1,1]\), which means the gambler does not borrow any money.

In , the authors show how this approach can be used to solve convex optimisation problems on \(^{d}\), that is, problems of the form \(x^{*}=_{x^{d}}f(x)\), for convex \(f:^{d}\). In particular,  consider a betting game with 'outcomes' \(c_{t}=- f(x_{t})\), replacing scalar multiplications \(c_{t}x_{t}\) by scalar products \( c_{t},x_{t}\). In this case, under certain assumptions, they show that \(f(_{t=1}^{T}x_{t})(x^{*})\) at a rate determined by the betting strategy. There are many suitable choices for the betting strategy. Perhaps the simplest of these is \(_{t}=t^{-1}_{s=1}^{t-1}c_{s}\), known as the Krichevsky-Trofimov (KT) betting strategy [53; 71], which yields the sequence of bets \(x_{t}=_{t}w_{t-1}=t^{-1}_{s=1}^{t-1}c_{s}(1+_{s=1}^{t-1} c _{s},x_{s})\). Other choices, however, are also possible [70; 72; 22].

In , this approach was extended to solve optimisation problems on the space of probability measures. In this case, several further modifications are necessary. First, in each round, one now bets \(x_{t}-x_{0}\) rather than \(x_{t}\), where \(x_{0}_{0}\) is distributed according to some \(_{0}_{2}(^{d})\). In this case, viewing \(x_{t}:^{d}^{d}\) as a function that maps \(x_{0} x_{t}(x_{0})\), one can define a sequence of distributions \((_{t})_{t}\) as the push-forwards of \(_{0}\) under the functions \((x_{t})_{t}\). In particular, this means that, if \(x_{0}_{0}\), then \(x_{t}_{t}\).

By using these modifications in the original coin betting framework, and choosing \((c_{t})_{t}:=(c_{_{t}}(x_{t}))_{t}\) appropriately,  show that it is now possible to solve problems of the form \(^{*}=_{_{2}()}()\). This approach is referred to as coin sampling. For example, by considering a betting game with \(c_{t}=-_{W_{2}}(_{t})(x_{t})\),  obtain a 'coin Wasserstein gradient descent' algorithm, which can be viewed as a learning-rate free analogue of Wasserstein gradient descent. Alternatively, setting \(c_{t}=-P_{_{t},k}_{W_{2}}(_{t})(x_{t})\), one can obtain a learning-rate free analogue of the population limit of SVGD, in which the updates are given by

\[x_{t}=x_{0}-^{t-1}_{_{s},k}_{W_{2}} (_{s})(x_{s})}{t}(1-_{s=1}^{t-1}_{ _{s},k}_{W_{2}}(_{s})(x_{s}),x_{s}-x_{0}),\] (10)

where, as described above, \(_{t}=(x_{t})_{\#}_{0}\). In practice, the densities \((_{t})_{t_{0}}\) and thus the outcomes \((c_{t})_{t}\) are almost always intractable, and will be approximated using a set of interacting particles.

### Mirrored Coin Sampling

By leveraging the formulation of constrained sampling as a'mirrored' optimisation problem over the space of probability measures, we can extend the coin sampling approach to constrained domains. In particular, as an alternative to discretising the MWGF to solve this optimisation problem (Sec. 3.2), we propose instead to use a mirrored version of coin sampling (Sec. 4.1). The idea is to use coin sampling to solve the optimisation problem in the dual space, and then map back to the primal space using the mirror map. In particular, this suggests the following scheme. Let \(x_{0}_{0}_{2}()\), and \(y_{0}=(x_{0})^{d}\). Then, for \(t\), update

\[y_{t}=y_{0}+^{t-1}c_{_{s}}(y_{s})}{t}(1+_{s=1}^{t-1 } c_{_{s}}(y_{s}),y_{s}-y_{0})\ \ \,\ \ x_{t}=^{*}(x_{t}),\] (11)where \(_{t}=(y_{t})_{\#}_{0}\) and \(_{t}=(^{*})_{\#}_{t}\), and where \(c_{_{s}}(y_{s})=-_{W_{2}}(_{s})(y_{s})\), or some variant thereof. We will refer to this approach as mirrored coin sampling, or mirrored coin Wasserstein gradient descent. In order to obtain an implementable algorithm, we proceed as follows. First, decide on a suitable functional \(\) and a suitable \((c_{t})_{t}:=(c_{_{t}}(y_{t})_{t}\). For example, \(()=(|)\), and \((c_{t})_{t}=(-_{_{t},k_{}}_{W_{2}} (_{t})(y_{t}))_{t}\). Then, substitute these into (11), and approximate the updates using a set of interacting particles, as in existing ParVIs algorithms.

Following these steps, we obtain a learning rate free analogue of MSVGD , which we will refer to as Coin MSVGD. This is summarised in Alg. 2. For different choices of \((c_{_{t}})_{t}\) in (11), we also obtain learning rate free analogues of two other mirrored ParVI algorithms introduced in App. B, namely mirrored LAWGD (App. B.3), and mirrored KSDD (App. B.4). These algorithms, which we term Coin MLAWGD and Coin MKSDD, are given in Alg. 6 and Alg. 7 in App. D.

``` input: target density \(\), kernel \(k\), mirror function \(\), particles \((x_{0}^{i})_{i=1}^{N}_{0}\). initialise:\(y_{0}^{i}=(x_{0}^{i})\) for \(i[N]\) for\(t=1,,T\)do  For \(i[N]\), \(y_{t}^{i}=y_{0}^{i}-^{t-1}P_{_{s},k_{}} (_{}}{})(y_{s}^{i})}{t}(1-_{s=1}^{t-1 } P_{_{s},k_{}}(_{}}{})(y_{s} ^{i}),y_{s}^{i}-y_{0}^{i})\).  For \(i[N],x_{t}^{i}=^{*}(y_{t}^{i})\). return\((x_{T}^{i})_{i=1}^{N}\). ```

**Algorithm 2** Coin MSVGD

Even in the unconstrained setting, establishing the convergence of coin sampling remains an open problem. In , the authors provide a technical sufficient condition under which it is possible to establish convergence to the target measure in the population limit; however, it is difficult to verify this condition in general. In the interest of completeness, in App. C, we provide an analogous convergence result for mirrored coin sampling, adapted appropriately to the constrained setting.

### Alternative Approaches

In this section, we outline an alternative approach, based on a 'coinification' of the mollified interaction energy descent (MIED) method recently introduced in . MIED is based on minimising a function known as the mollified interaction energy (MIE) \(_{}:(^{d})[0,]\). The idea is that minimising this function balances two forces: a repulsive force which ensures the measure is well spread, and an attractive force which ensures the measure is concentrated around regions of high density. In order to obtain a practical sampling algorithm,  propose to minimise a discrete version of the logarithmic MIE, using, e.g., Adagrad  or Adam . That is, minimising the function

\[ E_{}(^{n}):=}_{i=1}^{n}_{j=1}^{n }_{}(x^{i}-x^{j})((x^{i})(x^{j}))^{-},\] (12)

where \(^{n}=\{x^{1},,x^{n}\}\), and where \((_{})_{>0}\) is a family of mollifiers [60, Definition 3.1]. This approach can be adapted to handle the constrained case, as outlined in . In particular, if there exists a differentiable \(f:^{d}\) such that \( f(^{d})\) has Lebesgue measure zero, then one can reduce the constrained problem to an unconstrained one by minimising \( E_{}(f(w^{n}))\), where \(f(^{n})=\{f(x^{1}),,f(x^{n})\}\). Meanwhile, if \(=\{x^{d}:g(x) 0\}\) for some differentiable \(g:^{d}\), then one can use a variant of the dynamic barrier method introduced in .

Here, as an alternative to the optimisation methods considered in , we instead propose to use a learning-rate free algorithm to minimise (12), based on the coin betting framework described in 4.1. We term the resulting method, summarised in Alg. 3, Coin MIED. In comparison to our mirrored coin sampling algorithm, this approach has the advantage that it only requires a differentiable (not necessarily bijective) map.

## 5 Related Work

**Sampling as Optimisation**. The connection between sampling and optimisation has a long history, dating back to , which established that the evolution of the law of the Langevin diffusion corresponds to the WGF of the KL divergence. In recent years, there has been renewed interest in this perspective . In particular, the viewpoint of existing algorithms such as LMC [23; 24; 33; 34] and SVGD [32; 63] as discretisations of WGFs has proved fruitful in deriving sharp convergence rates [6; 34; 52; 78; 83; 85]. It has also resulted in the rapid development of new sampling algorithms, inspired by ideas from the optimisation literature such as proximal methods , coordinate descent [29; 30], Nesterov acceleration [18; 25; 67], Newton methods [68; 84; 98], and coin betting [80; 81].

**Sampling in Constrained Domains**. Recent interest in constrained sampling has resulted in a range of general-purpose algorithms for this task [e.g., 43; 60; 82; 103; 104]. In cases where it is possible to explicitly parameterise the target domain in a lower dimensional space, one can use variants of classical methods, including LMC , rejection sampling , Hamiltonian Monte Carlo (HMC) , and Riemannian manifold HMC [55; 73]. Several other approaches are based on the use of mirror map. In particular,  proposed mirrored Langevin dynamics and its first-order discretisation. , and an earlier draft of , introduced the closely related mirror Langevin diffusion and the mirror Langevin algorithm, which has since also been studied in [1; 19; 44; 61]. Along the same lines,  introduced two variants of SVGD suitable for constrained domains based on the use of a mirror map, and established convergence of these schemes to the target distribution; see also . In certain cases [e.g., 56; 58] one cannot explicitly parameterise the manifold of interest. In this setting, different approaches are required.  introduced a constrained version of HMC for this case. Meanwhile,  proposed a constrained Metropolis-Hastings algorithm with a reverse projection check to ensure reversibility; this approach has since been extended in [57; 59]. Other, more recent approaches suitable for this setting include MIED  (see Sec. 4.3), and O-SVGD .

## 6 Numerical Results

In this section, we perform an empirical evaluation of Coin MSVGD (Sec. 6.1 - 6.2) and Coin MIED (Sec. 6.3). We consider several simulated and real data experiments, including sampling from targets defined on the simplex (Sec. 6.1), confidence interval construction for post-selection inference (Sec. 6.2), and inference in a fairness Bayesian neural network (Sec. 6.3). We compare our methods to their learning-rate-dependent analogues, namely, MSVGD  and MIED . We also include a comparison with Stein Variational Mirror Descent (SVMD) , and projected versions of Coin SVGD  and SVGD , which include a Euclidean projection step to ensure the iterates remain in the domain. We provide additional experimental details in App. F and additional numerical results in App. G. Code to reproduce all of the numerical results can be found at https://github.com/louissharrock/constrained-coin-sampling.

### Simplex Targets

Following , we first test the performance of our algorithms on two 20-dimensional targets defined on the simplex: the sparse Dirichlet posterior of  and the quadratic simplex target of . We employ the IMQ kernel and the entropic mirror map ; and use \(N=50\) particles, \(T=500\) iterations. In Fig. 1 and Fig. 6 - 7 (App. F.1), we plot the energy distance  to a set of surrogate ground truth samples, either obtained i.i.d. (sparse Dirichlet target) or using the No-U-Turn Sampler (NUTS)  (quadratic target). After \(T=500\) iterations, Coin MSVGD has comparable performance to MSVGD and SVMD with optimal learning rates but significantly outperforms both algorithms for sub-optimal learning rates (Fig. 1). In both cases, the projected methods fail to converge. For the sparse Dirichlet posterior, Coin MSVGD converges more rapidly than MSVGD and SVMD, even for well-chosen values of the learning rate (Fig. 6 in App. F.1). Meanwhile, for the quadratic target, Coin MSVGD generally converges more rapidly than MSVGD but not as fast as SVMD , which takes advantage of the log-concavity of the target in the primal space (Fig. 6 in App. F.1).

### Confidence Intervals for Post Selection Inference

We next consider a constrained sampling problem arising in post-selection inference . Suppose we are given data \((X,y)^{n p}^{n}\). We are interested in obtaining valid confidence intervals (CIs) for regression coefficients obtained via the randomised Lasso , defined as the solution of

\[=*{arg\,min}_{^{p}}[ ||y-X||_{2}^{2}+||||_{1}-^{}+||||_{2}^{2}],\] (13)

where \(,_{+}\) are penalty parameters and \(^{p}\) is an auxiliary random vector. Let \(_{E}^{q}\) represent the non-zero coefficients of \(\) and \(_{E}=(_{E})\) for their signs. If the support \(E\) were known a priori, we could determine CIs for \(_{E}\) using the asymptotic normality of \(_{E}=(X_{E}^{}X_{E})^{-1}X_{E}^{}y\). However, when \(E\) is based on data, these 'classical' CIs will no longer be valid. In this case, one approach is to condition on the result of the initial model selection, i.e., knowledge of \(E\) and \(_{E}\). In practice, this means sampling from the so-called selective distribution, which has support \(=\{(_{E},_{-E}):(_ {E})=_{E}\,,\ ||_{-E}||_{} 1\}\), and density proportional to [e.g., 90, Sec. 4.2]

\[(_{E},_{-E}) g((_{E },0)^{}-X^{}(y-X_{E}_{E})+(_{E},_{-E})^ {}).\] (14)

**Synthetic Example**. We first consider the model setup described in [79, Sec. 5.3]; see App. F.2 for full details. In Fig. 2, we plot the energy distance between samples obtained using Coin MSVGD and projected Coin SVGD, and a set of 1000 samples obtained using NUTS , for a two-dimensional selective distribution. Similar to our previous examples, the performance of MSVGD is very sensitive to the choice of learning rate. If the learning rate is too small, the particle converge rather slowly; on the other hand, if the learning rate is too big, the particles may not even converge. Meanwhile, Coin MSVGD converges rapidly to the true target, with no need to tune a learning rate. Similar to the examples considered in Sec. 6.1, the projected methods once again fail to converge to the true target, highlighting the need for the mirrored approach.

Figure 1: **Results for the simplex targets in  and . Posterior approximation quality for Coin MSVGD, MSVGD, projected Coin SVGD, projected SVGD, and SVMD.**

Figure 2: **Results for a two-dimensional post-selection inference target. Energy distance versus iterations for (a) Coin MSVGD and MSVGD and (b) projected Coin SVGD and projected SVGD, for a selective distribution of the randomised Lasso in which two features are selected.**In Fig. 3, we plot the coverage of the CIs obtained using Coin MSVGD, MSVGD, SVMD, and the norejection MCMC algorithm in selectiveInference, as we vary the nominal coverage or the total number of samples. For MSVGD and SVMD, we use RMSProp to adapt the learning rate, with an initial learning rate of \(=0.1\), following . As the nominal coverage varies, Coin MSVGD achieves similar coverage to MSVGD and SVMD; and significantly higher actual coverage than norejection (Fig. 2(a)). Meanwhile, as the number of samples varies, Coin MSVGD, MSVGD, and SVMD consistently all obtain a higher coverage than the fixed nominal coverage of 90% (Fig. 2(b)). This is important for small sample sizes, where the standard approach undercovers. The performance of MSVGD and SVMD is, of course, highly dependent on an appropriate choice of learning rate. In Fig. 11 (App. G.3), we provide additional plots illustrating how the coverage of the CIs obtained using MSVGD and SVMD can deteriorate when the learning-rate is chosen sub-optimally.

**Real Data Example**. We next consider a post-selection inference problem involving the HIV-1 drug resistance dataset studied in ; see App. F.2 for full details. The goal is to identify statistically significant mutations associated with the response to the drug Lamivudine (3TC). The randomised Lasso selects a subset of mutations, for which we compute 90% CIs using \(5000\) samples and five methods: 'unadjusted' (the unadjusted CIs),'standard' (the method in selectiveInference), MSVGD, SVMD, and Coin MSVGD. Our results (Fig. 4) indicate that the CIs obtained by Coin MSVGD are similar to those obtained via the standard approach, which we view as a benchmark, as well as by MSVGD and SVMD (with a well chosen learning rate). Importantly, they differ from the CIs obtained using the unadjusted approach (see, e.g., mutation P65R or P184V in Fig. 4). Meanwhile, for sub-optimal choices of the learning rate (Fig. 3(b) and Fig. 3(c), Fig. 12 in App. G.3), the CIs obtained using MSVGD and SVMD differ substantially from those obtained using the baseline'standard' approach and by Coin MSVGD, once more highlighting the sensitivity of these methods to the choice of an appropriate learning rate.

Figure 4: **Real data results for post-selection inference. Confidence intervals for the mutations selected by the randomised Lasso as candidates for HIV-1 drug resistance. We report (a) all mutations when MSVGD and SVMD use a well chosen learning rate (\(=0.01\)) and (b) - (c) a subset of mutations when MSVGD and SVMD use a smaller (\(=0.001\)) or larger (\(=1.0\)) learning rate.**

Figure 3: **Coverage results for post-selection inference. Coverage of the post-selection confidence intervals obtained by Coin MSVGD, MSVGD, and SVMD, for 100 repeats of the simulation in [79, Sec. 5.3].**

### Fairness Bayesian Neural Network

Finally, following [60; 64; 65; 69], we train a fairness Bayesian neural network to predict whether an individual's income is greater than $50,000, with gender as a protected characteristic. We use the Adult Income dataset . The dataset is of the form \(=\{x_{i},y_{i},z_{i}\}_{i=1}^{n}\), where \(x_{i}\) denote the feature vectors, \(y_{i}\) denote the labels (i.e., whether the income is greater than $50,000), and \(z_{i}\) denote the protected attribute (i.e., the gender). We train a two-layer Bayesian neural network \((x;w)\) with weights \(w\) and place a standard Gaussian prior on each weight independently. The fairness constraint is given by \(g()=_{(x,y,z)}[z,(x;)]^{2}-t 0\) for some user-specified \(t>0\). In testing, we evaluate each method using a Calder-Verwer (CV) score , a standard measure of disparate impact. We run each method for \(T=2000\) iterations and use \(N=50\) particles.

In Fig. 4(a), we plot the trade-off curve between test accuracy and CV score, for \(t\{10^{-6},10^{-5},10^{-4},10^{-3},2 10^{-3},5 10^{-3},10^{-2}\}\). We compare the results for Coin MIED, MIED, and the methods in , using the default implementations. In this experiment, Coin MIED is clearly preferable to the other methods, achieving a much larger Pareto front. In Fig. 4(b) and Fig. 4(c), we plot the constraint and the MIE versus training iterations for both coin MIED and MIED. Once again, coin MIED tends to outperform MIED, achieving both lower values of the constraint and lower values of the energy.

## 7 Discussion

**Summary**. In this paper, we introduced several new particle-based algorithms for constrained sampling which are entirely learning rate free. Our first approach was based on the coin sampling framework introduced in , and a perspective of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this perspective, we also unified several existing constrained sampling algorithms, and studied their theoretical properties in continuous time. Our second approach can be viewed as the coin sampling analogue of the recently proposed MIED algorithm . Empirically, our algorithms achieved comparable or superior performance to other particle-based constrained sampling algorithms, with no need to tune a learning rate.

**Limitations**. We highlight three limitations. First, like any mirrored sampling algorithm, mirrored coin sampling (e.g., Coin MSVGD), necessarily depends on the availability of a mirror map that can appropriately capture the constraints of the problem at hand. Second, Coin MSVGD has a cost of \(O(N^{2})\) per update. Finally, even in the population limit, establishing the convergence of mirrored coin sampling under standard conditions (e.g., strong log-concavity or a mirrored log-Sobolev inequality) remains an open problem. We leave this as an interesting direction for future work.