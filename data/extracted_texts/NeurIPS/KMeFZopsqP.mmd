# First Order Methods with Markovian Noise: from Acceleration to Variational Inequalities

Aleksandr Beznosikov

Innopolis University, Skoltech, MIPT, Yandex

&Sergey Samsonov

HSE University

&Marina Sheshukova

HSE University

Alexander Gasnikov

MIPT, Skoltech, IITP RAS

&Alexey Naumov

HSE University

&Eric Moulines

Ecole polytechnique

###### Abstract

This paper delves into stochastic optimization problems that involve Markovian noise. We present a unified approach for the theoretical analysis of first-order gradient methods for stochastic optimization and variational inequalities. Our approach covers scenarios for both non-convex and strongly convex minimization problems. To achieve an optimal (linear) dependence on the mixing time of the underlying noise sequence, we use the randomized batching scheme, which is based on the multilevel Monte Carlo method. Moreover, our technique allows us to eliminate the limiting assumptions of previous research on Markov noise, such as the need for a bounded domain and uniformly bounded stochastic gradients. Our extension to variational inequalities under Markovian noise is original. Additionally, we provide lower bounds that match the oracle complexity of our method in the case of strongly convex optimization problems.

## 1 Introduction

Stochastic gradient methods are an essential ingredient for solving various optimization problems, with a wide range of applications in various fields such as machine learning , empirical risk minimization problems , and reinforcement learning . Various stochastic gradient descent methods (SGD) and their accelerated versions  have been extensively studied under different statistical frameworks . The standard assumption for stochastic optimization algorithms is to consider independent and identically distributed noise variables. However, the growing usage of stochastic optimization methods in reinforcement learning  and distributed optimization  has led to increased interest in problems with Markovian noise. Despite this, existing theoretical works that consider Markov noise have significant limitations, and their analysis often results in suboptimal finite-time error bounds.

Our research aims to fill the gap in the existing literature on the first-order Markovian setting. By focusing on uniformly geometrically ergodic Markov chains, we obtain finite-time complexity bounds for achieving \(\)-accurate solutions that scale linearly with the mixing time of the underlying Markov chain. Our approach is based on careful applications of randomized batch size schemes and provides a unified view on both non-convex and strongly convex minimization problems, as well as variational inequalities.

**Our contributions.** Our main contributions are the following:

\(\) **Accelerated SGD.** We provide the first analysis of SGD, including the Nesterov accelerated SGD method, with Markov noise without the assumption of bounded domain and uniformly bounded stochastic gradient estimates. Our results are summarised in Table 1 and Section 2.1 and cover both strongly convex and non-convex scenarios. Our findings for non-convex minimization problems complement the results obtained in .

\(\)**Lower bounds.** In Section 2.2 we give the lower bounds showing that the presence of mixing time in the upper complexity bounds is not an artefact of the proof. This is consistent with the results reported in .

\(\)**Extensions.** In Section 2.4 we provide, as far as we know, the first analysis for variational inequalities with general stochastic Markov oracle, arbitrary optimization set, and arbitrary composite term. Our finite-time performance analysis provides complexity bounds in terms of oracle calls that scale linearly with the mixing time of the underlying chain, which is an improvement over the bounds obtained in  for the Markov setting.

**Related works.** Next, we briefly summarize the related works.

\(\)**Stochastic gradient methods.** Numerous research papers have reported significant improvements achieved by accelerated methods for stochastic optimization with stochastic gradient oracles involving independent and identically distributed (i.i.d.) noise. These methods have been extensively studied in theory  and have shown practical success . The finite-time analysis of first-order methods in i.i.d. noise settings has been extensively studied by many authors, as discussed in  and references therein. In Table 1 we include only some important results because i.i.d. setting is not in the interest of this paper.

While the literature on i.i.d. noise is extensive, existing research on the first-order Markovian setting is relatively sparse. In this study, we focus on Markov chains that are uniformly geometrically ergodic, and we refer the reader to Section 2 for detailed definitions. We note that the complexity bounds which scale linearly with the mixing time of the underlying general Markov chain are currently available only for general convex and non-convex minimization problems. Namely,  has investigated a version of the ergodic mirror descent algorithm that yields optimal convergence rates for Lipschitz, general convex and non-convex problems. Recently,  proposed a random batch size algorithm that adapts to the mixing time of the underlying chain for non-convex optimization with a compact domain. In particular, [21, Theorem 4.3] yields optimal complexity rates in terms of the number of oracle calls required for non-convex problems, which is consistent with the results obtained in . Unlike previous studies, this method is insensitive to the mixing time of the noise sequence.

For the general case of Markovian noise the finite-time analysis of non-accelerated SGD-type algorithms was carried out in  and . However,  heavily relies on the bounded domain assumption and uniformly bounded stochastic gradient oracles, while its bound in [90, Theorem 5] has a suboptimal dependence on the mixing time of the underlying chain, see Table 1. Additionally,  does not cover the strongly convex setting. On the other hand,  covers both non-convex and strongly convex settings, but the bounds of [19, Theorem 1] has terms that are _exponential_ in the mixing time, and a careful examination reveals suboptimal dependence on the initial condition for strongly convex problems when SGD is applied.

In the study of Nesterov-accelerated SGD with Markovian noise, the authors of  considered the use of a batch size of 1 and achieved a rate of forgetting the initial condition that matches that of the i.i.d. noise setting. However, their result is suboptimal in terms of the variance terms in both non-convex and strongly convex settings, as detailed in Table 1. We emphasize that the case of unbounded gradient oracles with Markov noise is not treated in contrast to the i.i.d. setup .

The above papers deal with general Markovian noise optimization. But there are also results that deal with Markovian stochasticity with a finite state space. Here we can highlight the work , where the author gives quite extensive results and achieves linear scaling by mixing time in the non-convex as well as strongly convex cases. Recently, numerous papers have appeared dealing with the special scenario of distributed optimization .  investigates the generalization and stability of Markov SGD with special attention to the excess variance guarantees. We note that first, these algorithms only need to deal with a very special case of Markov gradients, and second, the corresponding dependence on the mixing time of the Markov chain is again quadratic. At the same time, there exist particular results, e.g. , which provide a lower bound for the particular finite sum problems in the Markovian setting.

\(\)**Variational inequalities.** Variational inequalities  have been an active area of research in applied mathematics for more than half a century . VI cover important special cases, e.g., minimization over a convex domain, saddle point or min-max and fixed point problems. computational game theory , robust  and nonsmooth  optimization, supervised  and unsupervised  learning, image denoising . In the last 5 years, variational inequalities and their special cases have attracted much interest in the machine learning community due to new connections to reinforcement learning [79; 50], adversarial training , and GANs [15; 33; 66; 12; 60; 82].

Variational inequalities (VI) and saddle point problems have their own well-established theory and methods. Unlike minimization problems, solving variational inequalities doesn't rely on (accelerated) gradient descent. Instead, the extragradient method , various modified versions [72; 42], or similar techniques  are recommended as the basic and theoretically optimal methods. While deterministic methods have long been used for solving variational inequalities, stochastic methods have gained importance only in the last 15 years, following pioneering works by [49; 52]. We summarise the results on methods for stochastic variational inequalities with the Lipschitz operator and smooth stochastic saddle point problems in Table 2. The number of papers dealing with stochastic VIs and saddle point problems is small compared to those dealing with stochastic optimization, we include in Table 2 papers with the i.i.d. noise (which we do not do for stochastic optimization). The only competing work dealing with Markovian noise in saddle point problems consider the finite sum problem and thus the finite Markov chain , therefore we do not include it in Table 2. Moreover, the results from  has much worse oracle complexity guarantees \((^{2}/^{2})\) in terms of \(\). There are more papers dealing with stochastic finite-sum variational inequalities or saddle point problems, but in the i.i.d. setting [12; 80; 104; 2; 8]. We also do not consider in Table 2 because of the difference in the stochastic oracle structure. It is important to note that, unlike most previous works, we consider the most general formulation of VI itself for an arbitrary optimization set and composite term.

**Notations and definitions.** Let \((,_{})\) be a complete separable metric space endowed with its Borel \(\)-field \(\). Let \((^{},^{})\) be the corresponding canonical process. Consider the Markov kernel \(\) defined on \(\), and denote by \(_{}\) and \(_{}\) the corresponding probability distribution and the expected value with initial distribution \(\). Without loss of generality, we assume that \((Z_{k})_{k}\) is the corresponding canonical process. By construction, for any \(A\), it holds that \(_{}(Z_{k} A|Z_{k-1})=(Z_{k-1},A)\), \(_{}\)-a.s. If \(=_{z}\), \(z\), we write \(_{z}\) and \(_{z}\) instead of \(_{_{z}}\) and \(_{_{z}}\), respectively. For \(x^{1},,x^{k}\) being the iterates of any stochastic first-order method, we denote \(_{k}=(x^{j},j k)\) and write \(_{k}\) as an alias for \([|_{k}]\). We also write \(^{*}:=\{0\}\). For the sequences \((a_{n})_{n}\) and \((b_{n})_{n}\) we write \(a_{n} b_{n}\) if there exists a constant \(c\) such that that \(a_{n} cb_{n}\) for all \(n\).

## 2 Main results

**Assumptions.** In this paper we study the minimization problem

\[_{x^{d}}f(x):=_{Z}[F(x,Z)]\,,\] (1)

where the access to the function \(f\) and its gradient is available only through the (unbiased) noisy oracle \(F(x,Z)\) and \( F(x,Z)\), respectively. In the following presentation we impose at least one of the following regularity constraint on the underlying function \(f\) itself:

   &  &  &  &  &  \\   &  &  &  &  &  &  &  &  \\   & **592 (\(_{k}\), 12)** & ✓ & ✗ & Nx & ✓ & \(((^{})-(^{}) (^{})(^{})(^{}+^{ }))\) & \(((^{})-(^{})( ^{}+^{}))\) \\   & **4891 (\(_{k}\), 17)** & ✓ & ✗ & ✗ & ✓ & \(((^{})-(^{}) (^{}+^{}))\) & \((((^{})(^{}+^{ })))\) \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & \(((^{})-(^{})( ^{}+^{}))\) & \(((^{})(^{}+^{ }))\) \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & \(((^{})-(^{})( ^{}+^{}))\) \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & \(((^{})-(^{})( ^{}+^{}))\) & \(((^{})(^{}+^{} ))\) \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & \(((^{})-(^{})( ^{}+^{}))\) \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & \(((^{})(^{}+^{} ))\) \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\   & **802 (\(_{k}\), 12)** & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & �

**A 1**.: _The function \(f\) is \(L\)-smooth on \(^{d}\) with \(L>0\), i.e., it is differentiable and there is a constant \(L>0\) such that the following inequality holds for all \(x,y^{d}\):_

\[\| f(x)- f(y)\| L\|x-y\|.\]

**A 2**.: _The function \(f\) is \(\)-strongly convex on \(^{d}\), i.e., it is continuously differentiable and there is a constant \(>0\) such that the following inequality holds for all \(x,y^{d}\):_

\[(/2)\|x-y\|^{2} f(x)-f(y)- f(y),x-y.\] (2)

Next we specify our assumptions on the sequence of noise variables \(\{Z_{i}\}_{i=0}^{}\). We consider here the general setting of \(\{Z_{i}\}_{i=0}^{}\) being a time-homogeneous Markov chain. Such problems naturally arise in stochastic optimization. In the empirical risk minimization problems it naturally appears in the context of non-random minibatch choice. Indeed, a random choice of a batch number may lose to a non-random one, see . A wide range of problems dealing with Markovian noise is spawned by the reinforcement learning methods. The usual MDP setting falls naturally inside this paradigm, moreover, the analysis of non-tabular RL problems requires to deal with the general state-space Markov noise. Here the potential range of applications include the policy evaluation methods, such as the temporal difference methods , and policy optimization algorithms, such as policy gradient family, e.g. the celebrated REINFORCE algorithm .

We denote by \(\) the Markov kernel corresponding to the sequence \(\{Z_{i}\}_{i=0}^{}\) and impose the following assumption on the mixing properties of \(\):

**A 3**.: \(\{Z_{i}\}_{i=0}^{}\) _is a stationary Markov chain on \((,)\) with Markov kernel \(\) and unique invariant distribution \(\). Moreover, \(\) is uniformly geometrically ergodic with mixing time \(\), i.e., for every \(k\),_

\[(^{k})=_{z_{z},z^{}}(1/2)\| ^{k}(z,)-^{k}(z^{},)\|_{}( 1/4)^{ k/}\,.\] (3)

The assumption A 3 is classical in the literature on optimization methods with Markovian noise and has been considered in particular in recent works . In particular, this assumption covers finite state-space Markov chains with irreducible and aperiodic transition matrix considered in

   &  &  &  \\   & **Method** & **VI7** & **Any set** & **Composite?** & **Unbounded?** & **Markovian?** & **Oracle complexity** \\   & **SPLE  & ✓ & ✓ & ✗ & ✗ & ✗ & \(}(^{2}+}{^{2}}}{^{2}})^{(1)}\) &  & }(^{2}+}{^{2}}})^{(1)}\)} & }(^{2}+ }{^{2}}}{^{2}})^{(1)}\)} & }(^{2}+}{^{2}}}{^{2}})^{(1)}\)} \\  & **SSQ** & ✓ & ✓ & ✗ & ✗ & ✗ & \(}(^{2}+}{^{2}}}{^{2}})\) & }(^{2}+ }{^{2}}}{^{2}})\)} & }(^{2}+}{^{2}}}{^{2}})\)} & }(^{2}+}{^{2}}}{^{2}})\)} & }(^{2}+ }{^{2}}}{^{2}})\)} & 

. Yet our definition of the mixing time \(\) is more classical in the probability literature , and is slightly different from the one considered e.g. in . Next we specify our assumptions on stochastic gradient:

**A 4**.: _For all \(x^{d}\) it holds that \(_{}[ F(x,Z)]= f(x)\). Moreover, for all \(z\) and \(x^{d}\) it holds that_

\[\| F(x,z)- f(x)\|^{2}^{2}+^{2}\| f(x)\|^{2}\,.\] (4)

The assumption A 4 resembles the strong growth condition , which is classical for the over-parametrized learning setup . The main difference is that A 4 concerns the almost sure bound in (4), which is unavoidable when dealing with uniformly geometrically ergodic Markovian noise A 3. Note that it is possible that the quantity \(^{2}\) in (4) is not instance-independent and scales with the ratio \(L/\) from A 1-A 2 in the particular problems. With the assumptions A 3 and A 4 we can prove the result on the mean spurred error of the stochastic gradient estimate computed over batch size \(n\) under arbitrary initial distribution. This result is summarized below in Lemma 1:

**Lemma 1**.: _Assume A 3 and A 4. Then, for any \(n 1\) and \(x^{d}\), it holds that_

\[_{}[\|n^{-1}_{i=1}^{n} F(x,Z_{i})- f(x)\|^{2}] (^{2}+^{2}\| f(x)\|^{2}).\] (5)

_Moreover, for any initial distribution \(\) on \((,)\), that_

\[_{}[\|n^{-1}_{i=1}^{n} F(x,Z_{i})- f(x)\|^{2}] }{n}(^{2}+^{2}\| f(x)\|^{2}),\] (6)

_where \(C_{1}=16(1+4})\)._

Proof.: We first prove (5). Note that due to [81, Proposition \(3.4\)] the Markov kernel \(\) under A 3 admits a positive pseudospectral gap \(_{ps}>0\) such that \(1/_{ps} 2\). Thus, applying the statement of [81, Theorem \(3.2\)], we get under A 4 that

\[_{}[\|n^{-1}_{i=1}^{n} F(x,Z_{i})- f(x)\|^{2}] _{}[\| F(x,Z_{1})- f(x)\|^{2}]}{n _{ps}}(^{2}+^{2}\| f(x)\|^{2} ).\]

To prove the second part we use the maximal exact coupling construction and follow, e.g., [24, Theorem 1]. The complete proof is given in Appendix B.1. 

The proof of Lemma 1 simplifies the arguments in [21, Lemma 4] and allows us to obtain tighter values for the constants when dealing with the randomized batch size. Note that it is especially important to have the result for MSE under arbitrary initial distribution \(\), since in the proofs of our main results we will inevitably deal with the conditional expectations w.r.t. the previous iterate. We provide more details on the bias and variance of the Markov SGD gradients in the next section.

### Accelerated method

We begin with a version of Nesterov accelerated SGD with randomized batch size, described in Algorithm 1. Due to the unboundedness of the stochastic gradient variance (see A 4), using of the classical Nesterov accelerated method [76, Section 2.2.] does not give the desired result, it is necessary to introduce an additional momentum . We use our own version, but partially similar to . The main feature of Algorithm 1 is that the number of samples used during the \(k\)-th gradient computation scales as \(2^{J_{k}}\), where \(J_{k}\) comes from a truncated geometric distribution. The truncation parameter needs to be adopted (see Theorem 1) in order to control the computational complexity of the algorithm.

Randomized batch size allows for efficient _bias_ reduction in the stochastic gradient estimates and can be seen as a particular case of the so called multilevel MCMC . In the optimization context this approach was successfully used by  for the non-convex problems. Indeed, this bias naturally appears under the Markovian stochastic gradients oracles. It is easy to see that, with the counter \(T^{k}\) defined in Line 9, we have

\[_{k}[ F(x^{k},Z_{T^{k}+i})] f(x^{k})\,.\]

Below we show how the bias of the gradient estimate scales with the truncation parameter \(M\). The statement of Lemma 2 yields that the gradient estimates \(g_{k}\) introduced above have the bias, which decreases _quadratically_ with \(M\).

**Lemma 2**.: _Assume A 3 and A 4. Then for the gradient estimates \(g^{k}\) from Algorithm 1 it holds that \(_{k}[g^{k}]=_{k}[g^{k}_{_{2}M}]\). Moreover,_

\[_{k}[\| f(x^{k})-g^{k}\|^{2}] ( B^{-1}_{2}M+^{2}B^{-2})(^ {2}+^{2}\| f(x^{k})\|^{2})\,,\] \[\| f(x^{k})-_{k}[g^{k}]\|^{2} ^{2}M^{-2}B^{-2}(^{2}+^{2}\| f(x^{ k})\|^{2})\,.\]The proof and the statement with explicit constants are given in Appendix B.2. Note that the Lemma 2 is a natural counterpart of the deterministic bound Lemma 1. Moreover, it gives the idea of the trade-off between the parameters \(B\) and \(M\). Namely, the expected number of oracle calls to compute \(g_{k}\) is \((B_{2}(M))\) with the bias scaling as \(M^{-2}\). Thus the increase of \(M\) drastically reduced the bias with only a logarithmic payment in variance. At the same time, gradient variance scales as \((/B)^{2}\), but the increase of \(B\) is much more expensive for the computational cost of the whole procedure. Taking into account the considerations above, we can prove the following result:

**Theorem 1**.: _Assume A 1 - A 4. Let problem (1) be solved by Algorithm 1. Then for any \(b^{*}\), \((0;]\), and \(,,,p,M,B\) satisfying_

\[p(1+(1+ L)[^{2} b^{-1}+^{2}^{2}b^{-2}])^{-1}, },},\]

\[-1}{ p^{-1}-1}, M\{2; {p^{-1}(1+p/)}\}, B=[b_{2}M],\]

_it holds that_

\[[\|x^{N}-x^{*}\|^{2}+(f(x^{N}_{f})-f (x^{*}))]-N}{3}} \|x^{0}-x^{*}\|^{2}+(f(x^{0})-f(x^{*}))\] \[+}{^{2/2}}(^{2} b^{-1}+ ^{2}^{2}b^{-2}).\] (7)

The proof is provided in Appendix B.3. The result of Theorem 1 can be rewritten as an upper complexity bound under an appropriate choice of the remaining free parameter \(b\):

**Corollary 1**.: _Under the conditions of Theorem 1, choosing \(b=\) and \(\) as_

\[\{; N^{2}}( \{2;N[\|x^{0}-x^{*}\|^{2}+6^{-1}(f(x^{0}_{f})-f(x^{*}))] }{^{2}}\})\},\]

_in order to achieve \(\)-approximate solution (in terms of \([\|x-x^{*}\|^{2}]\)) it takes_

\[}([(1+^{2})} +}{^{2}}]) \,.\] (8)

The results of Corollary 1 are obtained with fixed parameters of the method. In Corollary 1 these parameters are selected a bit artificially, e.g., the stepsize \(\) depends on the iteration horizon \(N\). In Appendix B.4 we show how one can similar results, but with a decreasing stepsize.

**Comparison.** Running the procedure above requires to know the mixing time \(\). Estimating the mixing time from a single trajectory of the running Markov chain is known to be computationally hard problem, see e.g.  and references therein. At the same time, methods, which share the same (optimal) linear scaling of the sample complexity w.r.t. the mixing time also share the same drawback as our method. In particular, it holds true for the EMD algorithm , SGD-DD algorithm , and usual SGD with Markovian data . At the same time, in the non-convex scenario the paper  is truly oblivious to mixing time, allowing to obtain sample complexity rates for non-convex problems, which are homogeneous w.r.t. \(\) with AdaGrad-type learning rate. An interesting direction for the future work to suggest a procedure that would allow to generalize the results of  to accelerated SGD setting.

It is possible that the sample complexity bound (8) is worse than the respective bounds for non-accelerated SGD with Markov data, provided that \(^{2}\) grows quickly with \(L/\). At the same time, this drawback is shared by the classical results on learning under the strong growth condition, see e.g. . As it is shown in , the respective rates can be worse than the ones obtained by usual SGD even under the i.i.d. noise setting, see Appendix F.3 in . Making the analysis of accelerated SGD 'backward compatible' w.r.t. the rates of usual SGD requires to perform analysis in terms of additional problem-specific quantities, see .

The closest equivalent of the result Corollary 1 is given by [20, Theorem 3]. However, the corresponding bound of [20, Theorem 3] is incomplete, since the factor \(^{2}\) is lost in the proof (see equations \((64-66)\)). With this completion, the bound of [20, Theorem 3] yields a variance term of order \(}(^{2}}{^{2}})\), which is suboptimal with respect to \(\). Moreover, the corresponding analysis relies heavily on the assumption of a bounded domain. In , the author considers Markovian noise with a finite number of states and manages to obtain a rather interesting result of the form \(O(+}{^{3} })\). Here the first term does not depend on \(\), and the second consists only \(^{*}\) (stochasticity in \(^{*}\)), but the price for this is an additional factor \(L/\) in the second term and more strict assumption that all realizations \(F(,z)\) are smooth and strongly convex. In the context of overparameterized learning, our results are almost consistent with the bound of [97, Theorem 1] under i.i.d. sampling. The difference is that the term \(^{2}\) in A 4 can be more pessimistic than the expectation bound in .

### Lower bounds

We start with a lower bound for the complexity of Markovian stochastic optimization under the assumptions A 1 -A 4. Below we provide a result that highlights that the bound of Theorem 1 is tight provided that \(\) does not scale with the instance-dependent quantities, e.g., condition number \(L/\).

**Theorem 2**.: _There exists an instance of the optimization problem satisfying assumptions A 1 -A 4 with \(=1\) and arbitrary \( 0,L,>0,^{*}\), such that for any first-order gradient method it takes at least_

\[N=(}+}{^{2}})\]

_oracle calls in order to achieve \([\|x^{N}-x^{*}\|^{2}]\)._

The proof is provided in Appendix B.5. The idea of the constructed lower for deterministic part bound \(}\) goes back to [76, Theorem 2.1.13]. The stochastic part lower bound goes back to the classical statistical reasoning, and is well explained for i.i.d. noise in [59, Chapter 4.1]. Our adaptation for Markovian setting is based on Le Cam's theory, see [1, Theorem 8], and also . For the case of Markov noise this lower bound is, to the best of our knowledge, original. The closest result to ours is the stochastic term lower bound in [28, Proposition 1], but it is valid only for the vanilla stochastic gradient methods. Below we provide another lower bound showing that the dependence of the sample complexity Corollary 1 on \(\) is not an artefact of the proof.

**Proposition 1**.: _There exists an instance of the optimization problem satisfying assumptions A 1 -A 4 with arbitrary \(L,>0,^{*}\), \(=\), and \(=0\), such that for any first-order gradient method it takes at least_

\[N=()\]

_gradient calls in order to achieve \([\|x^{N}-x^{*}\|^{2}]\)._

This lower bound is adapted from the information-theoretic lower bound . The detailed proof can be found in Appendix B.5. Recent studies  have revealed the impossibility of accelerating stochastic gradient descent (SGD) for online linear regression problems with specific noise structures. To address this issue, researchers have proposed various solutions, such as the MaSS algorithm  and the approach presented in . However, these methods rely heavily on the particular structure of the online regression setup. Another question that naturally arises is whether one can get rid of the dependence on \(\) in the deterministic part of (8) if \(=0\). The following counterexample shows that this is not the case in general.

**Proposition 2**.: _There exists an instance of the optimisation problem satisfying assumptions A 1 -A 4 with with arbitrary \(L,>0,^{*}\), \(=1,=0\), such that for any first-order gradient method it takes at least_

\[N=((+}))\]oracle calls in order to achieve \([\|x^{N}-x^{*}\|^{2}]\)._

The proof is provided in Appendix B.5.

### Non-convex problems

Now we proceed with a randomized batch size version of the simple SGD algorithm. It is summarized in Algorithm 2 and can be shown to achieve optimal rates of convergence for smooth non-convex problems. For the case of non-convex problems with Markov noise similar analysis appeared in [21, Theorem 4].

```
1:Parameters: stepsize \(>0\), number of iterations \(K\), bound on batchsize \(B\), mixing time \(\);
2:Initialization: choose \(x^{0}\)
3:for\(k=0,1,2,,N-1\)do
4: Sample \(J_{k}()\)
5:\(g^{k}=g_{0}^{k}+2^{J_{k}}(g_{J_{k}}^{k}-g_{J_{k}-1}^{k} ),&2^{J_{k}} M\\ 0,&\) with \(g_{j}^{k}=2^{-j}B^{-1}_{i=1}^{2^{j}B} f(x^{k},Z_{T^{k}+i})\)
6:\(x^{k+1}=x^{k}- g^{k}\)
7:\(T^{k+1}=T^{k}+2^{J_{k}}B\)
8:endfor ```

**Algorithm 2**Randomized GD

By balancing the values of \(B\) and \(M\) with Lemma 2, we establish the following result:

**Theorem 3**.: _Assume A 1, A 3, A 4. Let problem (1) be solved by Algorithm 2. Let \(f^{*}\) be a global (maybe not unique) minimum of \(f\). Then for any \(b^{*}\), and \(\), \(M\) satisfying_

\[(L[1+^{2} b^{-1}+^{2}^{2}b^{-2}])^{-1}, M \{2;L^{-1}}\}, B= b_{2}M,\]

_it holds that_

\[[_{k=0}^{N-1}\| f(x^{k})\|^{2}] )-f^{*}}{ N}+L[^{2} b^{ -1}+^{2}^{2}b^{-2}].\]

The proof is provided in Appendix B.6. The next corollary immediately follows from the theorem.

**Corollary 2**.: _Under the conditions of Theorem 3, if we choose \(b=\) and \(\) given by_

\[\{)};\;)-f^{ *}}{LN^{2}}}\},\]

_then to achieve \(\)-solution (in terms of \([\| f(x)\|^{2}]^{2}\)) we need_

\[}([)L(f(x^{0})-f^{*} )}{^{2}}+)-f^{*})^{2}}{^{4}} ]).\]

**Comparison.** The respective bound for the non-convex setting provided in [20, Theorem 1] yields the sample complexity of order \(}(L(f(x^{0})-f^{*}))^{2}}{ ^{4}})\). Also we can note the results of [28, Theorem 2] with the following estimate \(O()-f(x^{*}))+^{2})}{^{2}}+)-f(x^{*}))+^{2})^{2}}{^{4}})\).

To achieve linear convergence rates in the non-convex setting we can use the Polyak-Lojasiewicz (PL) condition . The respective result is provided in Appendix B.7.

### Variational inequalities

In this section, we are interested in the following problem:

\[x^{*} F(x^{*}),x-x^{*}+r(x)-r(x^{*})  0x.\] (9)

Here \(F:^{d}^{d}\) an operator, \(\) a convex set, and \(r:^{d}\) is a regularization term (a suitable lower semicontinuous convex function) which is assumed to have a simple structure. As mentioned earlier, this problem is quite general and covers a wide range of possible problem formulations. For example, if the operator \(F\) is the gradient of a convex function \(f\), then the problem (9) is equivalent to the composite minimization problem , i.e., minimization of \(f(x)+r(x)\). In the meantime, (9) is also a reformulation of the min-max problem

\[_{x_{1}_{1}}_{x_{2}_{2}}r_{1}(x_{1})+g(x_{ 1},x_{2})-r_{2}(x_{2}),\] (10)

with convex-concave continuously differentiable \(g\), convex sets \(_{1}\), \(_{2}\) and convex functions \(r_{1}\), \(r_{2}\). Using the first-order optimality conditions, it is easy to verify that (10) is equivalent to (9) with \(x=(x_{1}^{T},x_{2}^{T})^{T}\), \(F(x)=(_{x_{1}}f(x_{1},x_{2})^{T},-_{x_{2}}f(x_{1},x_{2})^{T})^{T}\), and \(r(x)=r_{1}(x_{1})+r_{2}(x_{2})\).

**A 5**.: _The operator \(F\) is \(L\)-Lipschitz continuous on \(\) with \(L>0\), i.e., the following inequality holds for all \(x,y\):_

\[\|F(x)-F(y)\| L\|x-y\|, x,y.\]

**A 6**.: _The operator \(F\) is \(_{F}\)-strongly monotone on \(\), i.e., the following inequality holds for all \(x,y\):_

\[ F(x)-F(y),x-y_{F}\|x-y\|^{2}.\] (11)

_The function \(r\) is \(_{r}\)-strongly convex on \(\), i.e. for all \(x,y\) and any \(r^{}(x) r(x)\) we have_

\[r(y) r(x)+ r^{}(x),y-x+(_{r}/2)\|x-y\|^{2}.\] (12)

These two assumptions are more than standard for the study of variational inequalities and are found in all the papers from Table 2. We consider two cases: strongly monotone/convex with \(_{F}+_{r}>0\) and monotone/convex with \(_{F}+_{r}=0\).

**A 7**.: _For all \(x^{d}\) it holds that \(_{}[F(x,Z)]=F(x)\). Moreover, for all \(z\) and \(x\) it holds that_

\[\|F(x,z)-F(x)\|^{2}^{2}+^{2}\|x-x^{*}\|^{2}\,,\] (13)

_where \(x^{*}\) is some point from the solution set._

A 7 is found in the literature on variational inequalities  and is considered to be analog to A 4 on overparametrized learning.

Just as the Nesterov accelerated method is optimal for smooth convex minimization problems, the ExtraGradient method  is optimal for monotone variational inequalities. Therefore, we take it as a base. On the extrapolation step (Line 4) of Algorithm 3, we simply collect a batch of size \(B\), but on the main step (Line 8) we use the randomization as in Algorithm 1. The next theorem gives the convergence of our method.

**Theorem 4**.: _Assume A 5, A 6 with \(_{F}+_{r}>0\), A 3, A 7. Let problem (9) be solved by Algorithm 3. Then for any \(b^{*}\), and \(\), \(M\) satisfying_

\[\{(_{F}+_{r})^{-1};L^{-1};(_{F}+ _{r})(^{2} b^{-1}+^{2}^{2}b^{-2})^{-1};^{-1}b}\},\] \[M\{2;(_{F}+_{r})^{-1}}\}, B = b_{2}M\,,\]

_it holds that_

\[[\|x^{N}-x^{*}\|^{2}](-+_{r})}{2})\|x^{0}-x^{*}\|^{2}+(^{2}  b^{-1}+^{2}^{2}b^{-2})\,.\]

The proof is postponed to Appendix B.8. One can get an estimate on oracle complexity.

```
1:Parameters: stepsize \(>0\), number of iterations \(N\)
2:Initialization: choose \(x^{0}\)
3:for\(k=0,1,2,,N-1\)do
4:\(x^{k+1/2}=_{ r}x^{k}- B^{-1}_{i=1}^{B}F(x^ {k},Z_{T^{k}+i})\)
5:\(T^{k+1/2}=T^{k}+B\)
6: Sample \(J_{k}()\)
7:\(g^{k}=g_{0}^{k}+2^{J_{k}}(g_{J_{k}}^{k}-g_{J_{k-1}}^{k} ),&2^{J_{k}} M\\ 0,&\) with \(g_{j}^{k}=2^{-j}B^{-1}_{i=1}^{2^{j} B}F(x^{k+1/2},Z_{T^{k+1/2}+i})\)
8:\(x^{k+1}=_{ r}x^{k}- g^{k}\)
9:\(T^{k+1}=T^{k+1/2}+2^{J_{k}}B\)
10:endfor ```

**Algorithm 3**Randomized ExtraGradient

**Corollary 3**.: _Under the conditions of Theorem 4, if we choose \(b=\) and \(\) as follows_

\[\{+_{r}};;+ _{r}}{^{2}};;+_{r})}( \{2;-x^{*}\|^{2}}{^{2}}\})\},\]

_then to achieve \(\)-solution (in terms of \([\|x-x^{*}\|^{2}]\)) we need_

\[}([(1++_{r}}+ +_{r}}+}{(_{F}+_{r})^{2}} )+}{^{2}}] ).\]Note that one provide an (almost) matching lower complexity bounds for variational inequalities via lower bounds for saddle point problems, which are a special case of variational inequalities. The method for obtaining lower bounds for saddle point problems is reduced to obtaining estimates for the strongly convex minimization problem (see  for respective deterministic lower bounds), which we provide in Section 2.2. Similarly, the question of constructing a lower bound which is tight w.r.t. \(\) remains open.

For the monotone case, we use the _gap function_ as a convergence criterion:

\[(x)=_{y}[ F(y),x-y+r(x)-r(y) ]\,.\] (14)

Such a criterion is standard and classical for monotone variational inequalities . An important assumption for the gap function is the boundedness of the set \(\).

**A 8**.: _The set \(\) is bounded and has a diameter \(D\), i.e., for all \(x,y\): \(\|x-y\|^{2} D^{2}\)._

A 8 can be slightly relaxed. We need to use a simple trick from . In particular, we need to consider \(\) - a compact subset of \(\) and change \(\) to \(\) in (14). But such a technique is rather technical and does not change the essence. Finally, the following result holds.

**Theorem 5**.: _Assume A 5, A 6 with \(_{F}+_{r}=0\), A 8, A 3, A 7. Let problem (9) be solved by Algorithm 3. Then for any \(B^{*}\), and \(\), \(M\) satisfying \( L^{-1}\,,\;M=\), it holds that_

\[[(^{N})]}{ N }+( B^{-1}_{2}N+^{2}B^{-2})(^{2}+^{2}D^{2})\;\; \;\;^{N}=_{k=0}^{N-1}x^{k+1/2}\,.\]

The proof is postponed to Appendix B.9. The following corollary holds.

**Corollary 4**.: _Under the conditions of Theorem 5, if we choose \(B=\) and \(\) as follows_

\[\{;}{(^{2}+^{2 }D^{2})N}}\},\]

_then to achieve \(\)-solution (in terms of \([(x)]\)) we need_

\[}([}{}+D^{2}+^{2}D^{4}}{^{2}}]).\]

**Comparison**. These results is the first for variational inequalities with Markovian stochasticity, either in the strongly monotone or monotone cases. The only close work is . The authors work with convex-concave saddle point problems and provide the following estimate on the oracle complexity \((^{2}}{^{2}}+}{ ^{2}})\) (with \(G\) - the uniform bound of the operator), which is worse than ours at least in terms of \(\). Moreover, the authors consider the case of a finite Markov chain, which is a special case of our setup.

## 3 Conclusion

In this paper, we present a unified random batch size framework that achieves optimal finite-time performance for non-convex and strongly convex optimization problems with Markov noise, as well as for variational inequalities. Unlike existing methods, our framework relaxes the assumptions typically imposed on the domain and stochastic gradient oracle. We also provide a variety of lower bounds, which are to the best of our knowledge original in the Markov setting.