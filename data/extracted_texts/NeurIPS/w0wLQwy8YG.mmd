# Plug-and-Play Bayesian Online Change-Point Detection in Gaussian Processes

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

We study the problem of detecting non-stationarity in online time series, when the underlying distribution is assumed to be a piecewise 1d-Gaussian process. Drawing inspiration from Bayesian online change-point detection methods such as that of Adams and MacKay (2007), we construct a restarted variant of that to specifically deal with arbitrary changes both in mean and variance of 1d-Gaussian processes. We evaluate our algorithm on both synthetic datasets of varying task difficulty and on prevalent real-world data across a variety of fields. Our results compare favorably with state-of-the-art, as measured by the detections' F1-Score. Code will be provided to ensure easy reproducibility.

## 1 Introduction

While most statistical models assume that the input data is generated according to some underlying distribution, it is often assumed that the latter does not actively change throughout instances of training or inference. This presents a major setback when tackling real-world problems where the data collection process is often done in a sequential manner and where the parameters of the generating distribution, if assumed parametric, are changing continuously. This applies in various ways across a variety of fields in machine learning and statistics: distribution shifts in deep learning (DL), environment non-stationarity in reinforcement learning (RL), to name a few.

More precisely, we consider the general setting of a sequential decision-making process, during which a series of abrupt changes, commonly referred to as _change-points_ (CP), take place. Change-points are sudden shifts in the underlying parameters of the data generating distribution of a given sequence. Detecting these change-points in real-time is of vital importance for the analysis and forecasting of time series, especially in high volatility scenarios, in consumer decision modeling (Xu and Yun (2020)), service provider adaptation to customers, and pricing (Taylor (2018); Kanoria and Qian (2019); Bimpikis et al. (2019); Gurvich et al. (2019)), wireless communication networks (Zhou and Bambos (2015); Zhou et al. (2016)), epidemic networks and control (Nowzari et al. (2016); Kiss et al. (2017)), inventory management (Agrawal and Jia (2019); Huh and Rusmevichientong (2009)), non-stationary multi armed bandits (Alami et al. (2017); Alami and Azizi (2020); Alami (2023, 2018); Garivier and Moulines (2011), safety-aware bandits: Alami et al. (2023a)), RL (Alami et al., 2023b), and notions of automated quality control (El Mekkaoui et al. (2024)), to name a few.

**Key contributions.** We outline our contributions as follows

* We propose a novel variant of the Restarted Bayesian Online Change-Point Detection algorithm (R-bocpd), that generalizes the modeling scope to the setting where online observation stream is generated from an underlying piecewise stationary 1d-Gaussian process (GP). Our model incorporates changes in either means or variances (or both) of the underlying GP.
* We demonstrate our results experimentally across a wide range of tasks of varying difficulty, on both synthetic and real-world datasets. Our algorithm compares favorably tostate-of-the-art in both online and offline settings, as measured by false-alarm and misdetection rates, detection delay, and finite-time runtime.
* We present concrete promising directions for future work relevant both to theoreticians and practitioners working both on probabilistic modeling under uncertainty and general modeling of time-series data in a variety of fields.

## 2 Main Results

Given the prevalent use of 1d-Gaussian distributions as statistical priors for a wide range of problems across a variety of domains, we choose to model a piecewise stationary GP, where a set of unknown abrupt change-points \(\{c_{}\}_{=1}^{L}\) take place such that

\[x_{t}(_{},_{}) t[c_{},c_{ +1}],[1,L]\] (1)

where \(L\) is the unknown total number of change-points throughout \([1,t]\). We provide Figure 1 for visualization.

**Challenge.** We aim to detect the change-points online and sequentially from data in real-time, without _a-priori_ knowledge on their number, their location, or how often they occur. The latter, indeed, can be used as a plug-and-play prior, as showcased later on in Algorithm 1. In particular, we are interested in designing an algorithm that detects change-points

* _reliably_, with as few misdetections and false-alarms as possible.
* _in real-time_, with as low of a detection delay as possible.
* _incorporating uncertainty_, yielding statistically optimal or near-optimal probabilistic guarantees, allowing for flexibility and control to the decision make.

### Change-point Detection as _Runlength Inference_

We first introduce the notion of _runlength_\(r_{t}\), which is defined as the number of time steps since the last change-point to the process, given an observed data sequence \(_{1:t}\) (up to current time step \(t\)). Adams and MacKay (2007) introduce an efficient Bayesian approach for handling piecewise stationary processes via computing the posterior distribution over the current runlength \(r_{t}\). The exact inference on the runlength distribution is done recursively via message-passing as follows

\[p(r_{t}|_{1:t})_{r_{t-1}}|r_{t-1})}_{}|r_{t-1}, _{1:t-1})}_{}p(r_{t-1}|_{1:t-1})\]

where the _hazard function_ is defined as

\[p(r_{t}|r_{t-1})=H(r_{t-1})&r_{t}=0\\ 1-H(r_{t-1})&r_{t}=r_{t-1}+1\\ 0&\] (2)

where \(H\) is defined as \(H(s)=_{}(s+1)}{_{t=s+1}^{}_{}(t)}\), \(_{}\) denotes the probability distribution over the interval between changepoints, and the _underlying probability model_ (UPM) depends on the probability distribution of \(x_{t}\). We showcase an illustrating example for our reasoning and algorithmic construction in Appendix A.

Figure 1: Piecewise Stationary Gaussian Process. Starting from change-point \(c_{}\), the model is assumed to be Gaussian of parameters \((_{},_{})\).

### Algorithmic Construction of R-bocpd

For an algorithmic construction that adheres to our previously outlined design objectives, we draw inspiration from Alami et al. (2020)'s extension to the seminal _Bayesian Online Change-point Detection_ (Bocpd) work of (Fearnhead and Liu, 2007). Indeed, Alami et al. (2020) introduce a pruned variant of the latter, which they refer to as the _Restarted Bayesian Online Change-point Detection_, particularly designed to model online changes in the means of univariate Bernoulli-distributed data samples. We propose to extend the R-bocpd construction to change-points in an online piecewise stationary GP. In particular, we start by introducing a few definitions in the following

**Definition 2.1** (Predictor).: Given a sequence of observations \(_{s:t}=(x_{s},...,x_{t})\), we define an instance of a predictor as follows

\[(x_{t+1}|_{s:t})=+1}{2})}{(_{s:t}) }}(1+-_{s:t})^{2}}{(_{s:t}+1)}{n_{s:t}}})^{-+1}{2}}\] (4)

where \((x|)=+1}{2 })}{(_{0})}}\) for some chosen \(_{0}>0\) at initialization and incrementing procedure

\[_{s:t+1}=_{s:t}+ n_{s:t+1}=n_{s:t}+1_{s: t+1}=_{s:t}+(x_{t+1}-_{s:t})^{2}}{2 (n_{s:t}+1)}\]

Akin to the our considered construction, instead of dealing with run-length, we introduce the notion of forecaster loss as loss incurred by predictors across time

**Definition 2.2** (Forecaster Loss).: Using the predictor, the instantaneous loss of the forecaster \(s\) at time \(t\) is given by:

\[_{s:t}:=-(x_{t}|_{s:t-1}).\]

Then, let \(_{s:t}:=_{s^{}=s}^{t}_{s^{}:t}\) denotes the cumulative loss incurred by the forecaster \(s\) from time \(s\) until time \(t\) which takes the following form

\[_{s:t}:=_{s^{}=s}^{t}-(x_{t }|_{s^{}:t-1})\] (5)

Thus, the forecaster weights update will remain the same (for some parameter \(h(0,1)\)).

\[_{r,s:t}=(1-h)(-_{s,t})_{r, s:t-1}& s<t,\\ h V_{r:t-1}&s=t V_{r:t-1}:=_{i=r}^{t-1} (-_{i:t})_{r,i:t-1}\] (6)

Finally, we keep the same restart procedure as in Alami et al. (2020), namely

\[(x_{r},...,x_{t})=[\;s(r,t]:_{r, s:t}>_{r,r:t}]\] (7)

where \((.)\) is the indicator function. Finally, we describe our algorithm in full pseudo-code in Algorithm 1.

### Empirical Results

**Measuring Performance.** We design a diverse synthetic task suite and also evaluate on prevalent open-source real-world time-series data (https://github.com/alan-turing-institute/TCPD). We evaluate our algorithm on two key metrics: _F1-Score_ and _detection delay_. We normalize the latter by the length of its corresponding stationary period, i.e for change-point \(c_{}\), delay \(d_{}\) is normalized by \(c_{+1}-c_{}\).

**Runtime.** Given the online nature of our proposed algorithm, we analyze to what extent our algorithm (and others) allow for smooth inference in real-time. We see that our runtime compares favorably with state-of-the-art, which makes it especially useful for modeling long-context sequences.

**Discussion & Future Work.** Our work sheds light on online change-point detection when the underlying distribution of the streaming data is a 1d-Gaussian. Being both quite relevant in practice and theoretically interpretable, this lays the ground for a variety of possible extensions and future work. Among these we list- establishing potential theoretical optimality guarantees, scaling to mixtures of detectors and building hybrid algorithms. We defer a detailed discussion of the latter to Appendix B.

    &  \\   &  &  &  &  \\   & F1-Score \(\) & Delay \(\) & F1-Score \(\) & Delay\(\) & F1-Score \(\) & Delay\(\) & F1-Score \(\) & Delay\(\) \\   Bishop  & 0.87 & — & **1.0** & — & 0.8 & — & 0.6 & — \\ Pelt  & **1.0** & — & **1.0** & — & 0.909 & — & 0.67 & — \\   CSUM & 0.632 & 0.444 & — & — & — & — & — & — \\ GIRT & **1.0** & 0.009 & **1.0** & 0.14 & 0.889 & 0.339 & 0.174 & 0.879 \\  R-bocpd (Ours) & **1.0** & 0.01 & **1.0** & **0.016** & **1.0** & **0.038** & **0.9** & **0.498** \\   

Table 1: Benchmark results for various algorithms across different synthetic datasets of varying difficulty. We report the F1-Score and Delay for each method. Delay is normalized by the size of the stationary periods for each detected change-point for appropriate unified performance assessment across sequences of different lengths. We highlight here that the first family of methods is offline, hence naturally would get much smaller delays. The second group of methods is online, akin to our proposed method. For the interest of comparison within our considered setting, we only measure detection delays for online methods.

   Algorithm &  \\   & Jefk Passengers & Co\({}_{2}\) Canada & Businv & Bitcoin \\   Binese & 1.0 & 0.67 & 0.24 & 0.43 \\ Pelt & 0.5 & 0.67 & 0.20 & 0.43 \\   GIRT & **1.0** & 0.8 & 0.57 & 0.58 \\ R-bocpd & — & — & 0.27 & — \\ Gpts-cp & — & — & 0.62 & — \\ Adaga & — & — & 0.77 & — \\   R-bocpd (Ours) & **1.0** & **1.0** & **0.8** & **0.8** \\   

Table 2: Benchmark results for various algorithms across different real-world datasets belonging to a variety of domains. We mainly compare in terms of F1-Score. We were unable to reproduce R-bocpdms, Gpts-cp and Adaga at the time of submission. Instead, we reproduce their exact setting for the Businv dataset.

   Algorithm & Runtime (ms) \(\) \\  Binese & 2.82666 \\ Pelt & 15.3721 \\  GIRT & 3.0112 \\  R-bocpd(Ours) & **0.7097** \\   

Table 3: Runtime (in milliseconds) per iteration. The first family of methods is offline, while the second one is online, similarly to R-Bocpd.