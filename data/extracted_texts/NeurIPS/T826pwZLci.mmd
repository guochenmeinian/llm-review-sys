# Federated Online Prediction from Experts

with Differential Privacy: Separations

and Regret Speed-ups

 Fengyu Gao, Ruiquan Huang, Jing Yang

School of EECS, The Pennsylvania State University, USA

{fengyugao, rzh5514, yangjing}@psu.edu

###### Abstract

We study the problems of differentially private federated online prediction from experts against both _stochastic adversaries_ and _oblivious adversaries_. We aim to minimize the average regret on \(m\) clients working in parallel over time horizon \(T\) with explicit differential privacy (DP) guarantees. With stochastic adversaries, we propose a **Fed-DP-OPE-Stoch** algorithm that achieves \(\)-fold speed-up of the per-client regret compared to the single-player counterparts under both pure DP and approximate DP constraints, while maintaining logarithmic communication costs. With oblivious adversaries, we establish non-trivial lower bounds indicating that _collaboration among clients does not lead to regret speed-up with general oblivious adversaries_. We then consider a special case of the oblivious adversaries setting, where there exists a low-loss expert. We design a new algorithm **Fed-SVT** and show that it achieves an \(m\)-fold regret speed-up under both pure DP and approximate DP constraints over the single-player counterparts. Our lower bound indicates that Fed-SVT is nearly optimal up to logarithmic factors. Experiments demonstrate the effectiveness of our proposed algorithms. To the best of our knowledge, this is the first work examining the differentially private online prediction from experts in the federated setting.

## 1 Introduction

Federated Learning (FL) (McMahan et al., 2017) is a distributed machine learning framework, where numerous clients collaboratively train a model by exchanging model update through a server. Owing to its advantage in protecting the privacy of local data and reducing communication overheads, FL is gaining increased attention in the research community, particularly in the online learning framework (Mitra et al., 2021; Park et al., 2022; Kwon et al., 2023; Gauthier et al., 2023). Noticeable advancements include various algorithms in federated multi-armed bandits (Shi et al., 2021; Huang et al., 2021; Li and Wang, 2022; Yi and Vojnovic, 2022, 2023), federated online convex optimization (Patel et al., 2023; Kwon et al., 2023; Gauthier et al., 2023), etc.

Meanwhile, differential privacy (DP) has been integrated into online learning, pioneered by Dwork et al. (2010). Recently, Asi et al. (2022) studied different types of adversaries, developing some of the best existing algorithms and establishing lower bounds. Within the federated framework, although differentially private algorithms have been proposed for stochastic bandits (Li et al., 2020; Zhu et al., 2021; Dubey and Pentland, 2022) and linear contextual bandits (Dubey and Pentland, 2020; Li et al., 2022; Zhou and Chowdhury, 2023; Huang et al., 2023), to the best of our knowledge, federated online learning in the adversarial setting with DP considerations remain largely unexplored.

In this work, we focus on federated online prediction from experts (OPE) with rigorous differential privacy (DP) guarantees1. OPE (Arora et al., 2012) is a classical online learning problem under which, a player chooses one out of a set of experts at each time slot and an adversary chooses a loss function. The player incurs a loss based on its choice and observes the loss function. With all previous observations, the player needs to decide which expert to select each time to minimize the cumulative expected loss. We consider two types of adversaries in the context of OPE. The first type, _stochastic adversary_, chooses a distribution over loss functions and samples a loss function independently and identically distributed (IID) from this distribution at each time step. The second type, _oblivious adversary_, chooses a sequence of loss functions in advance. 2

When extending the OPE problem to the federated setting, we assume that the system consists of a central server and \(m\) local clients, where each client chooses from \(d\) experts to face an adversary at each time step over time horizon \(T\). The server coordinates the behavior of the clients by aggregating the clients' updates to form a global update (predicting a new global expert), while the clients use the global expert prediction to update its local expert selection and compute local updates. The local updates will be sent to the server periodically. In the Federated OPE framework, clients face either _stochastic adversaries_, receiving loss functions from the same distribution in an IID fashion, or _oblivious adversaries_, which arbitrarily select loss functions for each client at each time step beforehand (Yi and Vojnovic, 2023). Specifically, we aim to answer the following question:

_Can we design differentially private federated OPE algorithms to achieve regret speed-up against both stochastic and oblivious adversaries?_

In this paper, we give definitive answers to the question. Our contributions are summarized as follows.

* **Speed-up for stochastic adversaries.** We develop a communication-efficient algorithm Fed-DP-OPE-Stoch for stochastic adversaries with DP guarantees. The algorithm features the following elements in its design: 1) _Local loss function gradient estimation for global expert determination._ To reduce communication cost, we propose to estimate the gradient of each client's previous loss functions locally, and only communicate these estimates to the server instead of all previous loss functions. 2) _Local privatization process._ Motivated by the need for private communication in FL, we add noise to client communications (local gradient estimates) adhering to the DP principles, thereby building differentially private algorithms. We show that Fed-DP-OPE-Stoch achieves \(1/\)-fold reduction of the per-client regret compared to the single-player counterparts (Asi et al., 2022b) under both pure DP and approximate DP constraints, while maintaining logarithmic communication costs.
* **Lower bounds for oblivious adversaries.** We establish new lower bounds for federated OPE with oblivious adversaries. Our findings reveal a critical insight: collaboration among clients does not lead to regret speed-up in this context. Moreover, these lower bounds highlight a separation between oblivious adversaries and stochastic adversaries, as the latter is necessary to reap the benefits of collaboration in this framework. Formulating an instance of oblivious adversaries for the corresponding lower bounds is a non-trivial challenge, because it requires envisioning a scenario where the collaborative nature of FL does not lead to the expected improvements in regret minimization. To deal with this challenge, we propose a _policy reduction approach in FL_. By defining an "average policy" among all clients against a uniform loss function generated by an oblivious adversary, we reduce the federated problem to a single-player one, highlighting the equivalence of per-client and single-player regret. Our lower bounds represent the first of their kind for differentially private federated OPE problems.
* **Speed-up for oblivious adversaries under realizability assumption.** We design a new algorithm Fed-SVT that obtains near-optimal regret when there is a low-loss expert. We show that Fed-SVT achieves an \(m\)-fold speed-up in per-client regret when compared to single-player models (Asi et al., 2023). This shows a clear separation from the general setting where collaboration among clients does not yield benefits in regret reduction when facing oblivious adversaries. Furthermore, we establish a new lower bound in the realizable case. This underlines that our upper bound is nearly optimal up to logarithmic factors.

[MISSING_PAGE_FAIL:3]

communication cost. We consider the loss functions \(l_{1,1}(),,l_{m,T}()\) to be convex, \(\)-Lipschitz and \(\)-smooth w.r.t. \(\|\|_{1}\) in this section.

### Intuition behind Algorithm Design

To gain a better understanding of our algorithm design, we first elaborate the difficulties encountered when extending prevalent OPE models to the FL setting under DP constraints. It is worth noting that all current OPE models with stochastic adversaries rely on gradient-based optimization methods. The central task in designing OPE models with stochastic adversaries lies in leveraging past loss functions to guide the generation of expert predictions. Specifically, we focus on the prominent challenges associated with the widely adopted Frank-Wolfe-based methods (Asi et al., 2022b). This algorithm iteratively moves the expert selection \(x_{t}\) towards a point that minimizes the gradient estimate derived from the past loss functions \(l_{1},,l_{t-1}\) over the decision space \(\), where \(=_{d}=\{x^{d}:x_{i} 0,_{i=1}^{d}x_{i}=1\}\), and each \(x\) represents a probability distribution over \(d\) experts. With DP constraints, a tree-based method is used for private aggregation of the gradients of loss functions (Asi et al., 2021b).

In the federated setting, it is infeasible for the central server to have full access to past loss functions due to the high communication cost. To overcome this, we use a design of _local loss function gradient estimation for global expert determination_. Our solution involves locally estimating the gradient of each client's loss functions, and then communicating these estimates to the server, which globally generates a new prediction. This strategy bypasses the need for full access to all loss functions, reducing the communication overhead while maintaining efficient expert selection.

To enhance privacy in the federated system, we implement a _local privatization process_. When communication is triggered, clients send "local estimates" of the gradients of their loss functions to the server. These local estimates include strategically added noise, adhering to DP principles. The privatization method is crucial as it extends beyond privatizing the selection of experts; it ensures the privacy of all information exchanged between the central server and clients within the FL framework.

### Algorithm Design

To address the aforementioned challenges, we propose the Fed-DP-OPE-Stoch algorithm. The Fed-DP-OPE-Stoch algorithm works in phases. In total, it has \(P\) phases, and each phase \(p[P]\) contains \(2^{p-1}\) time indices. Fed-DP-OPE-Stoch contains a client-side subroutine (Algorithm 1) and a server-side subroutine (Algorithm 2). The framework of our algorithm is outlined as follows.

At the initialization phase, the server selects an arbitrary point \(z\) and broadcasts to all clients. Subsequently, each client initializes its expert selection \(x_{i,1}=z\), pays cost \(l_{i,1}(x_{i,1})\) and observes the loss function.

Starting at phase \(p=2\), each client uses loss functions from the last phase to update its local loss function gradient estimation, and then coordinates with the server to update its expert selection. After that, it sticks with its decision throughout the current phase and observes the loss functions. We elaborate this procedure as follows.

**Private Local Loss Function Gradient Estimation.** At the beginning of phase \(p\), each client privately estimates the gradient using local loss functions from the last phase \(_{i,p}=\{l_{i,2^{p-2}},,l_{i,2^{p-1}-1}\}\). We employ the tree mechanism for the private aggregation at each client, as in the DP-FW algorithm from Asi et al. (2021b). Roughly speaking, DP-FW involves constructing binary trees and allocating sets of loss functions to each vertex. The gradient at each vertex is then estimated using the loss functions of that vertex and the gradients along the path to the root. Specifically, we run a DP-FW subroutine at each client \(i\), with sample set \(_{i,p}\), parameter \(T_{1}\) and batch size \(b\). In DP-FW, each vertex \(s\) in the binary tree \(j\) corresponds to a gradient estimate \(v_{i,j,s}\). DP-FW iteratively updates gradient estimates by visiting the vertices of binary trees. The details of DP-FW can be found in Algorithm 3 in Appendix C.1.

Intuitively, in the DP-FW subroutine, reaching a leaf vertex marks the completion of gradient refinement for a specific tree path. At these critical points, we initiate communication between the central server and individual clients. Specifically, as the DP-FW subroutine reaches a leaf vertex \(s\) of tree \(j\), each client sends the server a set of noisy inner products for each decision set vertex \(c_{n}\) with their gradient estimate \(v_{i,j,s}\). In other words, each client communicates with the server by sending \(\{ c_{n},v_{i,j,s}+_{i,n}\}_{n[d]}\), where \(c_{1},,c_{d}\) represents \(d\) vertices of decision set \(=_{d}\), \(_{i,n}(_{i,j,s})\), and \(_{i,j,s}=}{be}\).

**Private Global Expert Prediction.** After receiving \(\{ c_{n},v_{i,j,s}+_{i,n}\}_{n[d]}\) from all clients, the central server privately predicts a new expert:

\[_{j,s}=*{arg\,min}_{c_{n}:1 n d}[ _{i=1}^{m}( c_{n},v_{i,j,s}+_{i,n})].\] (1)

Subsequently, the server broadcasts the "global prediction" \(_{j,s}\) to all clients.

**Local Expert Selection Updating.** Denote the index of the leaf \(s\) of tree \(j\) as \(k\). Then, upon receiving the global expert selection \(_{j,s}\), each client \(i\) updates its expert prediction for leaf \(k+1\), denoted as \(x_{i,p,k+1}\), as follows:

\[x_{i,p,k+1}=(1-_{i,p,k})x_{i,p,k}+_{i,p,k}_{j,s},\] (2)

where \(_{i,p,k}=\).

After updating all leaf vertices of the trees, the client obtains \(x_{i,p,K}\), the final state of the expert prediction in phase \(p\). Then, each client \(i\) sticks with expert selection \(x_{i,p,K}\) throughout phase \(p\) and collects loss functions \(l_{i,2^{p-1}},,l_{i,2^{p-1}}\).

_Remark 1_ (Comparison with Asi et al. (2022b)).: The key difference between Fed-DP-OPE-Stoch and non-federated algorithms (Asi et al., 2022b) lies in our innovative approach to centralized coordination and communication efficiency. Unlike the direct application of DP-FW in each phase in Asi et al. (2022b), our algorithm employs _local loss function gradient estimation_, _global expert prediction_ and _local expert selection updating_. Additionally, our strategic communication protocol, where clients communicate with the server only when DP-FW subroutine reaches leaf vertices, significantly reduces communication costs. Moreover, the integration of DP at the local level in our algorithm distinguishes it from non-federated approaches.

```
1:Input: Phases \(P\), trees \(T_{1}\), decision set \(=_{d}\) with vertices \(\{c_{1},,c_{d}\}\), batch size \(b\).
2:Initialize: Set \(x_{i,1}=z\) and pay cost \(l_{i,1}(x_{i,1})\).
3:for\(p=2\) to \(P\)do
4: Set \(_{i,p}=\{l_{i,2^{p-2}},,l_{i,2^{p-1}-1}\}\)
5: Set \(k=1\) and \(x_{i,p,1}=x_{i,p-1,K}\)
6:\(\{v_{i,j,s}\}_{j[T_{1}],s\{0,1\}^{z}}=(_{i, p},T_{1},b)\)
7:for all leaf vertices \(s\) reached in DP-FW do
8: Communicate to server:\(\{ c_{n},v_{i,j,s}+_{i,n}\}_{n[d]}\), where \(_{i,n}(_{i,j,s})\)
9: Receive from server:\(_{j,s}\)
10: Update \(x_{i,p,k}\) according to Equation (2)
11: Update \(k=k+1\)
12:endfor
13: Final iterate outputs \(x_{i,p,K}\)
14:for\(t=2^{p-1}\) to \(2^{p}-1\)do
15: Receive loss \(l_{i,t}:\) and pay cost \(l_{i,t}(x_{i,p,K})\)
16:endfor
17:endfor ```

**Algorithm 1** Fed-DP-OPE-Stoch: Client \(i\)

### Theoretical Guarantees

Now we are ready to present theoretical guarantees for Fed-DP-OPE-Stoch.

**Theorem 1**.: _Assume that loss function \(l_{i,t}()\) is convex, \(\)-Lipschitz, \(\)-smooth w.r.t. \(\|\|_{1}\). Setting \(_{i,j,s}=}{be}\), \(b=}{(p-1)^{2}}\) and \(T_{1}=(}{ d})\), Fed-DP-OPE-Stoch (i) satisfies \(\)-DP and (ii) achieves the per-client regret of_

\[O(+) T}+ T}}{m^{}}\]_with (iii) a communication cost of \(O(m^{}d})\)._

A similar result characterizing the performance of Fed-DP-OPE-Stoch under \((,)\)-DP constraint is shown in Theorem 6.

Proof sketch of DP guarantees and communication costs.: Given neighboring datasets \(\) and \(^{}\) differing in \(l_{i_{1},t_{1}}\) or \(l^{}_{i_{1},t_{1}}\), we first note that \(l_{i_{1},t_{1}}\) or \(l^{}_{i_{1},t_{1}}\) is used in only one phase, denoted as \(p_{1}\). Furthermore, note that \(l_{i_{1},t_{1}}\) or \(l^{}_{i_{1},t_{1}}\) is used in the gradient computation for at most \(2^{j-|s|}\) iterations, corresponding to descendant leaf nodes. This insight allows us to set noise levels \(_{i,j,s}\) sufficiently large to ensure each of these iterations is \(/2^{j-|s|}\)-DP regarding output \(\{ c_{n},v_{i_{1},j,s}\}_{n[d],j[T_{1}],|s|=j}\). By basic composition and post-processing, we can make sure the final output is \(\)-DP.

The communication cost is obtained by observing that there are \(p\) phases, and within each phase, there are \(O(2^{T_{1}})\) leaf vertices. Thus, the communication frequency scales in \(O(_{p}2^{T_{1}})\) and the communication cost scales in \(O(md_{p}2^{T_{1}})\). 

Proof sketch of regret upper bound.: We first give bounds for the total regret in phase \(p[P]\). We can show that for every \(t\) in phase \(p\), we have

\[L_{t}(x_{i,p,k+1})  L_{t}(x_{i,p,k})+_{i,p,k}[L_{t}(x^{})-L_{t}(x_{i,p,k}) ]+_{i,p,k}\| L_{t}(x_{i,p,k})-_{p,k}\|_{}\] \[+_{i,p,k}(_{p,k},_{p,k}- _{w}_{p,k},w)+ _{i,p,k}{}^{2}.\]

To upper bound the regret, we bound the following two quantities separately.

**Step 1: bound \(\| L_{t}(x_{i,p,k})-_{p,k}\|_{}\) in Lemma 3.** We show that every index of the \(d\)-dimensional vector \( L_{t}(x_{i,p,k})-_{p,k}\) is \(O(+^{2}}{bm})\)-sub-Gaussian by induction on the depth of vertex in Lemma 2. Therefore, \([\| L_{t}(x_{i,p,k})-_{p,k}\|_{}]\) is upper bounded by \(O((+)})\).

**Step 2: bound \(_{p,k},_{p,k}-_{w}_{p,k},w\) in Lemma 5.** We establish that \(_{p,k},_{p,k}-_{w}_{p,k},w\) is upper bounded by \(_{n:1 n d}|_{i=1}^{m}_{i,n}|\). This bound incorporates the maximum absolute sum of \(m\) IID Laplace random variables \(_{i,n}\). To quantify the bound on the sum of \(m\) IID Laplace random variables, we refer to Lemma 4. Consequently, we have \([_{p,k},_{p,k}-_{w}_{p,k},w]\) upper bounded by \(O( d}{})\).

With the two steps above, we can show that for each time step \(t\) in phase \(p\), \([L_{t}(x_{i,p,K})-L_{t}(x^{})]\) is upper bounded by \(O\!((+)m}}+  d}{m^{}}}})\). Summing up all the phases gives us the final upper bound. The full proof of Theorem 1 can be found in Appendix C.2. 

When \(\) is small, Theorem 1 reduces to the following corollary.

**Corollary 1**.: _If \(=O(})\), then, Fed-DP-OPE-Stoch (i) satisfies \(\)-DP and (ii) achieves the per-client regret of_

\[(T,m)=O}+},\]

_with (iii) a communication cost of \(O(md T)\)._

The full proof of Corollary 1 can be found in Appendix C.2.

_Remark 2_.: We note that the regret for the single-player counterpart Asi et al. (2022b) scales in \(O(+)\) when \(=O()\). Compared with this upper bound, Fed-DP-OPE-Stoch achieves \(\)-fold speed-up, with a communication cost of \(O(md T)\). This observation underscores the learning performance acceleration due to collaboration. Furthermore, our approach extends beyond the mere privatization of selected experts; we ensure the privacy of all information exchanged between the central server and clients.

_Remark 3_.: We remark that Fed-DP-OPE-Stoch can be slightly modified into a centrally differentially private algorithm, assuming client-server communication is secure. Specifically, we change the local privatization process to a global privatization process on the server side. This mechanism results in less noise added and thus better utility performance. The detailed design is deferred to Appendix C.4 and the theoretical guarantees are provided in Theorem 7.

## 4 Federated OPE with Oblivious Adversaries: Lower bounds

In this section, we shift our attention to the more challenging oblivious adversaries. We establish new lower bounds for general oblivious adversaries.

To provide a foundational understanding, we start with some intuition behind FL. FL can potentially speed up the learning process by collecting more data at the same time to gain better insights to future predictions. In the stochastic setting, the advantage of collaboration lies in the ability to collect more observations from the same distribution, which leads to variance reduction. However, when facing oblivious adversaries, the problem changes fundamentally. Oblivious adversaries can select loss functions arbitrarily, meaning that having more data does not necessarily help with predicting their future selections.

The following theorem formally establishes the aforementioned intuition.

**Theorem 2**.: _For any federated OPE algorithm against oblivious adversaries, the per-client regret is lower bounded by \(()\). Let \((0,1]\) and \(=o(1/T)\), for any \((,)\)-DP federated OPE algorithm, the per-client regret is lower bounded by \(((,T))\)._

_Remark 4_.: Theorem 2 states that with oblivious adversaries, the per-client regret under any federated OPE is fundamentally independent of the number of clients \(m\), indicating that, the collaborative effort among multiple clients does not yield a reduction in the regret lower bound. This is contrary to typical scenarios where collaboration can lead to shared insights and improve overall performance. The varied and unpredictable nature of oblivious adversaries nullifies the typical advantages of collaboration. Theorem 2 also emphasizes the influence of the DP guarantees. Our lower bounds represent the first non-trivial impossibility results for the federated OPE to the best of our knowledge.

Proof sketch.: We examine the case when _all clients receive the same loss function from the oblivious adversary_ at each time step, i.e. \(l_{i,t}=l_{t}^{}\). Within this framework, we define the _"average policy"_ among all clients, i.e., \(p_{t}^{}(k)=_{i=1}^{m}p_{i,t}(k), k[d]\). This leads us to express the per-client regret as: \((T,m)=_{t=1}^{T}_{k=1}^{d}p_{t}^{}(k) l_{t}^{ }(k)-_{t=1}^{T}l_{t}^{}(x^{*})\). Note that \(p_{t}^{}(k)\) is defined by \(p_{1,t}(k),,p_{m,t}(k)\), which in turn are determined by \(l_{1,1},,l_{m,t-1}\). According to our choice of \(l_{i,t}=l_{t}^{}\), \(p_{t}^{}(k)\) is determined by \(l_{1}^{},l_{2}^{},,l_{t-1}^{}\). Therefore, \(p_{1}^{},p_{2}^{},,p_{t}^{}\) are generated by a legitimate algorithm for online learning with expert advice problems. Through our **policy reduction approach in FL**, we can reduce the federated problem to a single-player setting, showing the equivalence of per-client and single-player regret against the oblivious adversary we construct, thus obtaining the regret lower bound. We believe that this technique will be useful in future analysis of other FL algorithm. Incorporating DP constraints, we refer to Lemma 9, which transforms the DPonline learning problem to a well-examined DP batch model. The full proof of Theorem 2 can be found in Appendix D. 

## 5 Federated OPE with Oblivious Adversaries: Realizable Setting

Given the impossibility results in the general oblivious adversaries setting, one natural question we aim to answer is, _is there any special scenarios where we can still harness the power of federation even in presence of oblivious adversaries?_ Towards this end, in this section, we focus on the (near) realizable setting, formally defined below.

**Definition 2** (Realizability).: A federated OPE problem is _realizable_ if there exists a feasible solution \(x^{}[d]\) such that \(_{t=1}^{T}l_{i,t}(x^{})=0\), \( i[m]\). If the best expert achieves small loss \(L^{} T\), i.e., there exists \(x^{}[d]\) such that \(_{t=1}^{T}l_{i,t}(x^{}) L^{}\), \( i[m]\), the problem is near-realizable.

Intuitively, collaboration is notably advantageous in this context, as all clients share the same goal of reaching the zero-loss solution \(x^{}\). As more clients participate, the shared knowledge pool expands, making the identification of the optimal solution more efficient. In the following, we first provide regret lower bounds to quantify this benefit formally, and then show that a sparse vector based federated algorithm can almost achieve such lower bounds thus is nearly optimal.

### Lower Bound

**Theorem 3**.: _Let \( 1\) and \(/d\). For any \((,)\)-DP federated OPE algorithm against oblivious adversaries in the realizable setting, the per-client regret is lower bounded by \(().\)_

_Remark 5_.: In the single-player setting, the regret bound is \(()\)(Asi et al., 2023). In the federated setting, our results imply that the per-client regret is reduced to \(\) times the single-player regret. This indicates a possible \(m\)-fold speed-up in the federated setting.

Proof sketch.: To begin, we consider a specific oblivious adversary. We introduce two prototype loss functions: \(l^{0}(x)=0\) for all \(x[d]\) and for \(j[d]\)\(l^{j}(x)=0\) if \(x=j\) and otherwise \(l^{j}(x)=1\). An oblivious adversary picks one of the \(d\) sequences \(^{1},,^{d}\) uniformly at random, where \(^{j}=(l^{j}_{1,1},,l^{j}_{m,T})\) such that \(l^{j}_{i,t}=l^{0}\) if \(t=1,,T-k\), otherwise, \(l^{j}_{i,t}=l^{j}\), and \(k=\). Assume there exists an algorithm such that the per-client regret is upper bounded by \(\). This would imply that for at least \(d/2\) of \(^{1},,^{d}\), the per-client regret is upper bounded by \(\). Assume without loss of generality these sequences are \(^{1},,^{d/2}\). We let \(_{j}\) be the set of expert selections that has low regret on \(^{j}\). We can show that \(_{j}\) and \(_{j^{}}\) are disjoint for \(j j^{}\), implying _choosing any expert \(j\) leads to low regret for loss sequence \(^{j}\) but high regret for \(^{j^{}}\)_. By group privacy, we have \(((^{j})_{j^{ }}) e^{-mk}(( ^{j^{}})_{j^{}})-mk\), leading to a contradiction when \(d 32\). The full proof of Theorem 3 can be found in Appendix E.1. 

### Algorithm Design

We develop a new algorithm Fed-SVT. Our algorithm operates as follows:

Periodic communication.We adopt a fixed communication schedule in our federated setting, splitting the time horizon \(T\) into \(T/N\) phases, each with length \(N\). In Fed-SVT, every client selects the same expert, i.e., \(x_{i,t}=x_{t}\) at each time step \(t\). Initially, each client starts with a randomly chosen expert \(x_{1}\). At the beginning of each phase \(n\), each client sends the accumulated loss of the last phase \(_{t^{}=(n-1)N}^{nN-1}l_{i,t^{}}(x)\) to the central server.

Global expert selection.The server, upon receiving \(_{t^{}=(n-1)N}^{nN-1}l_{i,t^{}}(x)\) from all clients, decides whether to continue with the current expert or switch to a new one. This decision is grounded in the Sparse-Vector algorithm (Asi et al., 2023), where the accumulated loss from all clients over a phase is treated as a single loss instance in the Sparse-Vector algorithm. Based on the server's expert decision, clients update their experts accordingly. The full algorithm is provided in Appendix E.2.

### Theoretical Guarantees

**Theorem 4**.: _Let \(l_{i,t}^{d}\) be chosen by an oblivious adversary under near-realizability assumption. Fed-SVT is \(\)-DP, the communication cost scales in \(O(mdT/N)\), and with probability at least \(1-O()\), the pre-client regret is upper bounded by \(O((d)+(}{N_{}}) ()}{mc}+(N+L^{})() ).\) Moreover, Fed-SVT is \((,)\)-DP, the communication cost scales in \(O(mdT/N)\), and with probability at least \(1-O()\), the pre-client regret is upper bounded by \(O(}(d))}+ (}{N_{}})()}{m }+(N+L^{})())\)._

_Remark 6_.: Note that when \(N+L^{}=O()\), then, under Fed-SVT, the per-client regret upper bound scales in \(O(d+ T d}{m})\) for \(\)-DP and \(O(d}{m})\) for \((,)\)-DP.

Compared to the best upper bound \(O(d+ T d}{})\) and \(O(d}{})\) for the single-player scenario (Asi et al., 2023), our results indicate an \(m\)-fold regret speed-up. Note that our lower bound (Theorem 3) scales in \(()\). Our upper bound matches with the lower bound in terms of \(m\) and \(\), and is nearly optimal up to logarithmic factors.

The proof of Theorem 4 is presented in Appendix E.3.

## 6 Numerical Experiments

**Fed-DP-OPE-Stoch.** We conduct experiments in a synthetic environment to validate the theoretical performances of Fed-DP-OPE-Stoch, and compare them with its single-player counterpart Limited Updates (Asi et al., 2022b).

We first generate true class distributions for each client \(i[m]\) and timestep \(t[T]\), which are sampled IID from Gaussian distributions with means and variances sampled uniformly. Following Gaussian sampling, we apply a softmax transformation and normalization to ensure the outputs are valid probability distributions. Then we generate a sequence of IID loss functions \(l_{1,1},,l_{m,T}\) for \(m\) clients over \(T\) timesteps using cross-entropy between true class distributions and predictions. We set \(T_{1}=1\) in Fed-DP-OPE-Stoch, therefore the communication cost scales in \(O(md T)\). We set \(m=10\), \(T=2^{14}\), \(=10\), \(=0\) and \(d=100\). The per-client cumulative regret as a function of \(T\) is plotted in Figure 1. We see that Fed-DP-OPE-Stoch outperforms Limited Updates significantly, indicating the regret speed-up due to collaboration. Results with different seeds are provided in Appendix F.

**Fed-SVT.** We conduct experiments in a synthetic environment, comparing Fed-SVT with the single-player model Sparse-Vector (Asi et al., 2023).

We generate random losses for each expert at every timestep and for each client, ensuring that one expert always has zero loss to simulate an optimal choice. We set \(m=10\), \(T=2^{9}\), \(=10\), \(=0\) and \(d=100\). In Fed-SVT, we experiment with communication intervals \(N=1,30,50\), where communication cost scales in \(O(mdT/N)\). The per-client cumulative regret as a function of \(T\) is plotted in Figure 2. Our results show that Fed-SVT significantly outperforms the Sparse-Vector, highlighting the benefits of collaborative expert selection in regret speed-up, even at lower communication costs (notably in the \(N=50\) case). Results with different seeds are provided in Appendix F. Additionally, we evaluate the performances of Fed-SVT on the MovieLens-1M dataset (Harper and Konstan, 2015) in Appendix G.

## 7 Conclusions

In this paper, we have advanced the state-of-the-art of differentially private federated online prediction from experts, addressing both stochastic and oblivious adversaries. Our Fed-DP-OPE-Stoch algorithm

Figure 1: Per-client regret.

Figure 2: Per-client regret.

showcases a significant \(\)-fold regret speed-up compared to single-player models with stochastic adversaries, while effectively maintaining logarithmic communication costs. For oblivious adversaries, we established non-trivial lower bounds, highlighting the limited benefits of client collaboration. Additionally, our Fed-SVT algorithm demonstrates an \(m\)-fold speed-up, indicating near-optimal performance in settings with low-loss experts. One limitation of this work is the lack of experiments on real-world federated learning scenarios such as recommender systems and healthcare. We leave this exploration to future work.