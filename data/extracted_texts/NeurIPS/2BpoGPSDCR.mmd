# Solving Inverse Physics Problems with Score Matching

Benjamin Holzschuh

Simona Vegetti

Max Planck Institute for Astrophysics, 85748 Garching, Germany

Nils Thuerey

Technical University of Munich, 85748 Garching, Germany

###### Abstract

We propose to solve inverse problems involving the temporal evolution of physics systems by leveraging recent advances from diffusion models. Our method moves the system's current state backward in time step by step by combining an approximate inverse physics simulator and a learned correction function. A central insight of our work is that training the learned correction with a single-step loss is equivalent to a score matching objective, while recursively predicting longer parts of the trajectory during training relates to maximum likelihood training of a corresponding probability flow. We highlight the advantages of our algorithm compared to standard denoising score matching and implicit score matching, as well as fully learned baselines for a wide range of inverse physics problems. The resulting inverse solver has excellent accuracy and temporal stability and, in contrast to other learned inverse solvers, allows for sampling the posterior of the solutions. Code and experiments are available at https://github.com/tum-pbs/SMDP.

## 1 Introduction

Many physical systems are time-reversible on a microscopic scale. For example, a continuous material can be represented by a collection of interacting particles  based on which we can predict future states. We can also compute earlier states, meaning we can evolve the simulation backward in time . When taking a macroscopic perspective, we only know average quantities within specific regions , which constitutes a loss of information, and as a consequence, time is no longer reversible. In the following, we target inverse problems to reconstruct the distribution of initial macroscopic states for a given end state. This problem is genuinely tough , and existing methods lack tractable approaches to represent and sample the distribution of states.

Our method builds on recent advances from the field of diffusion-based approaches : Data samples \(^{D}\) are gradually corrupted into Gaussian white noise via a stochastic differential equation (SDE) \(d=f(,t)dt+g(t)dW\), where the deterministic component of the SDE \(f:^{D}_{ 0}^{D}\) is called _drift_ and the coefficient of the \(D\)-dimensional Brownian motion \(W\) denoted by \(g:_{ 0}_{ 0}\) is called _diffusion_. If the **score**\(_{} p_{t}()\) of the data distribution \(p_{t}()\) of corrupted samples at time \(t\) is known, then the dynamics of the SDE can be reversed in time, allowing for the sampling of data from noise. Diffusion models are trained to approximate the score with a neural network \(s_{}\), which can then be used as a plug-in estimate for the reverse-time SDE.

However, in our physics-based approach, we consider an SDE that describes the physics system as \(d=()dt+g(t)dW\), where \(:^{D}^{D}\) is a physics simulator that replaces the drift term of diffusion models. Instead of transforming the data distribution to noise, we transform a simulation state at \(t=0\) to a simulation state at \(t=T\) with Gaussian noise as a perturbation. Based on a givenend state of the system at \(t=T\), we predict a previous state by taking a small time step backward in time and repeating this multiple times. Similar to the reverse-time SDE of diffusion models, the prediction of the previous state depends on an approximate inverse of the physics simulator, a learned update \(s_{}\), and a small Gaussian perturbation.

The training of \(s_{}\) is similar to learned correction approaches for numerical simulations [10; 11; 12]: The network \(s_{}\) learns corrections to simulation states that evolve over time according to a physics simulator so that the corrected trajectory matches a target trajectory. In our method, we target learning corrections for the "reverse" simulation. Training can either be based on single simulation steps, which only predict a single previous state, or be extended to rollouts for multiple steps. The latter requires the differentiability of the inverse physics step .

Importantly, we show that under mild conditions, learning \(s_{}\) is equivalent to matching the score \(_{} p_{t}()\) of the training data set distribution at time \(t\). Therefore, sampling from the reverse-time SDE of our physical system SDE constitutes a theoretically justified method to sample from the correct posterior.

While the training with single steps directly minimizes a score matching objective, we show that the extension to multiple steps corresponds to maximum likelihood training of a related neural ordinary differential equation (ODE). Considering multiple steps is important for the stability of the produced trajectories. Feedback from physics and neural network interactions at training time leads to more robust results.

In contrast to previous diffusion methods, we include domain knowledge about the physical process in the form of an approximate inverse simulator that replaces the drift term of diffusion models [14; 15]. In practice, the learned component \(s_{}\) corrects any errors that occur due to numerical issues, e.g., the time discretization, and breaks ambiguities due to a loss of information in the simulation over time.

Figure 1 gives an overview of our method. Our central aim is to show that the combination of diffusion-based techniques and differentiable simulations has merit for solving inverse problems and to provide a theoretical foundation for combining PDEs and diffusion modeling. In the following, we refer to methods using this combination as _score matching via differentiable physics_ (SMDP). The main contributions of our work are: (1) We introduce a reverse physics simulation step into diffusion models to develop a probabilistic framework for solving inverse problems. (2) We provide the theoretical foundation that this combination yields learned corrections representing the score of the underlying data distribution. (3) We highlight the effectiveness of SMDP with a set of challenging inverse problems and show the superior performance of SMDP compared to a range of stochastic and deterministic baselines.

## 2 Related Work

Diffusion models and generative modeling with SDEsDiffusion models [16; 17] have been considered for a wide range of generative applications, most notably for image , video [15; 14; 16; 17], audio synthesis , uncertainty quantification [21; 19; 20], and as autoregressive PDE-solvers . However, most approaches either focus on the denoising objective common for tasks involving natural images or the synthesis process of solutions does not directly consider the underlying physics. Models based on Langevin dynamics [10; 18] or discrete Markov chains [16; 17] can be unified in a time-continuous framework using SDEs . Synthesizing data by sampling from neural SDEs has been considered by, e.g., [19; 20]. Contrary to existing approaches, the drift in our method is an actual physics step, and the underlying SDE does not transform a data distribution to noise but models the temporal evolution of a physics system with stochastic perturbations.

Methods for solving inverse problems for (stochastic) PDEsDifferentiable solvers for physics dynamics can be used to optimize solutions of inverse problems with gradient-based methods by backpropagating gradients through the solver steps . Learning-based approaches directly learn solution operators for PDEs and stochastic PDEs, i.e., mappings between spaces of functions, such as Fourier neural operators , DeepONets , or generalizations thereof that include stochastic forcing for stochastic PDEs, e.g., neural stochastic PDEs . Recently, there have been several approaches that leverage the learned scores from diffusion models as data-drivenregularizations for linear inverse problems [Ram+20; Son+22; KVE21; CSY22; Chu+22] and general noisy inverse problems [Chu+23]. Our method can be applied to general non-linear inverse physics problems with temporal evolution, and we do not require to backpropagate gradients through all solver steps during inference. This makes inference significantly faster and more stable.

Learned corrections for numerical errorsNumerical simulations benefit greatly from machine learning models [Tom+17; Mor+18; Pfa+20; Li+21]. By integrating a neural network into differential equation solvers, it is possible to learn to reduce numerical errors [Um+20; Koc+21; BWW22] or guide the simulation towards a desired target state [HTK20; Li+22]. The optimization of \(s_{}\) with the 1-step and multi-step loss we propose in section 3.1 is conceptually similar to learned correction approaches. However, this method has, to our knowledge, not been applied to correcting the "reverse" simulation and solving inverse problems.

Maximum likelihood training and continuous normalizing flowsContinuous normalizing flows (CNFs) are invertible generative models based on neural ODEs [Che+18a; KPB20; Pap+21], which are similar to our proposed physics-based neural ODE. The evolution of the marginal probability density of the SDE underlying the physics system is described by Kolmogorov's forward equation [\(\)ks03], and there is a corresponding probability flow ODE [MRO20; Son+21b]. When the score is represented by \(s_{}\), this constitutes a CNF and can typically be trained with standard methods [Che+18b] and maximum likelihood training [Son+21a]. Huang et al. [HLC21] show that minimizing the score-matching loss is equivalent to maximizing a lower bound of the likelihood obtained by sampling from the reverse-time SDE. A recent variant combines score matching with CNFs [ZC21] and employs joint learning of drift and corresponding score for generative modeling. To the best of our knowledge, training with rollouts of multiple steps and its relation to maximum likelihood training have not been considered so far.

## 3 Method Overview

Problem formulationLet \((,,P)\) be a probability space and \(W(t)=(W_{1}(t),...,W_{D}(t))^{T}\) be a \(D\)-dimensional Brownian motion. Moreover, let \(_{0}\) be a \(_{0}\)-measurable \(^{D}\)-valued random variable that is distributed as \(p_{0}\) and represents the initial simulation state. We consider the time evolution of

Figure 1: Overview of our method. For training, we fit a neural ODE, the probability flow, to the set of perturbed training trajectories (a, top). The probability flow is comprised of a reverse physics simulator \(}^{-1}\) that is an approximate inverse of the forward solver \(\) as well as a correction function \(s_{}\). In many cases, we can obtain \(}^{-1}\) from \(\) by using a negative step size \( t\) or by learning a surrogate model from data. For inference, we simulate the system backward in time from \(_{T}\) to \(_{0}\) by combining \(}^{-1}\), the trained \(s_{}\) and Gaussian noise in each step (a, bottom). For optimizing \(s_{}\), our approach moves a sliding window of size \(S\) along the training trajectories and reconstructs the current window (b). Gradients for \(\) are accumulated and backpropagated through all prediction steps.

the physical system for \(0 t T\) modeled by the stochastic differential equation (SDE)

\[d=()dt+g(t)dW\] (1)

with initial value \(_{0}\) and Borel measurable drift \(:\,^{D}^{D}\) and diffusion \(g:\,[0,T]_{ 0}\). This SDE transforms the marginal distribution \(p_{0}\) of initial states at time \(0\) to the marginal distribution \(p_{T}\) of end states at time \(T\). We include additional assumptions in appendix A.

Moreover, we assume that we have sampled \(N\) trajectories of length \(M\) from the above SDE with a fixed time discretization \(0 t_{0}<t_{1}<...<t_{M} T\) for the interval \([0,T]\) and collected them in a training data set \(\{(_{t_{m}}^{(n)})_{i=0}^{M}\}_{n=0}^{N}\). For simplicity, we assume that all time steps are equally spaced, i.e., \(t_{m+1}-t_{m}:= t\). Moreover, in the following we use the notation \(_{:m}\) for \(0<m M\) to refer to the trajectory \((_{t_{}},_{t_{+1}},...,_{t_{m}})\). We include additional assumptions in appendix A.

Our goal is to infer an initial state \(_{0}\) given a simulation end state \(_{M}\), i.e., we want to sample from the distribution \(p_{0}(\,\,|\,_{M})\), or obtain a maximum likelihood solution.

### Learned Corrections for Reverse Simulation

In the following, we furthermore assume that we have access to a reverse physics simulator \(}^{-1}:^{D}^{D}\), which moves the simulation state backward in time and is an approximate inverse of the forward simulator \(\). In our experiments, we either obtain the reverse physics simulator from the forward simulator by using a negative step size \( t\) or by learning a surrogate model from the training data. We train a neural network \(s_{}(,t)\) parameterized by \(\) such that

\[_{m}_{m+1}+ t[}^{-1}( _{m+1})+s_{}(_{m+1},t_{m+1})].\] (2)

In this equation, the term \(s_{}(_{m+1},t_{m+1})\) corrects approximation errors and resolves uncertainties from the Gaussian perturbation \(g(t)dW\). Below, we explain our proposed 1-step training loss and its multi-step extension before connecting this formulation to diffusion models in the next section.

1-step lossFor a pair of adjacent samples \((_{m},_{m+1})\) on a data trajectory, the 1-step loss for optimizing \(s_{}\) is the L\({}_{2}\) distance between \(_{m}\) and the prediction via (2). For the entire training data set, the loss becomes

\[_{}():=\,_{_{0: M}}[_{m=0}^{M-1}[||_{m}-_{m+1}-  t[}^{-1}(_{m+1})+s_{}(_{m+1},t_{m+1})]||_{2}^{2}]].\] (3)

Computing the expectation can be thought of as moving a window of size two from the beginning of each trajectory until the end and averaging the losses for individual pairs of adjacent points.

Multi-step lossAs each simulation state depends only on its previous state, the 1-step loss should be sufficient for training \(s_{}\). However, in practice, approaches that consider a loss based on predicting longer parts of the trajectories are more successful for training learned corrections . For that purpose, we define a hyperparameter \(S\), called sliding window size, and write \(_{i:i+S}^{S D}\) to denote the trajectory starting at \(_{i}\) that is comprised of \(_{i}\) and the following \(S-1\) states. Then, we define the multi-step loss as

\[_{}():=\,_{_{0:M}} [_{m=0}^{M-S+1}[||_{m:m+S-1}- }_{m:m+S-1}||_{2}^{2}]],\] (4)

where \(}_{i:i+S-1}\) is the predicted trajectory that is defined recursively by

\[}_{i+S}=_{i+S}}_{i+S-1-j} =}_{i+S-j}+ t[}^{-1}(}_{i+S-j})+s_{}(}_{i+S-j},t_{i+S-j})].\] (5)

### Learning the Score

Denoising score matchingGiven a distribution of states \(p_{t}\) for \(0<t<T\), we follow  and consider the score matching objective

\[_{}():=_{0}^{T}_{  p_{t}}[||s_{}(,t)-_{} p _{t}()||_{2}^{2}]dt,\] (6)i.e., the network \(s_{}\) is trained to approximate the score \(_{} p_{t}()\). In denoising score matching , the distributions \(p_{t}\) are implicitly defined by a noising process that is given by the forward SDE \(d=f(,t)dt+g(t)dW\), where \(W\) is the standard Brownian motion. The function \(f:^{D}_{ 0}^{D}\) is called _drift_, and \(g:_{ 0}_{ 0}\) is called _diffusion_. The process transforms the training data distribution \(p_{0}\) to a noise distribution that is approximately Gaussian \(p_{T}\). For affine functions \(f\) and \(g\), the transition probabilities are available analytically, which allows for efficient training of \(s_{}\). It can be shown that under mild conditions, for the forward SDE, there is a corresponding **reverse-time SDE**\(d=[f(,t)-g(t)^{2}_{} p_{t}( )]dt+g(t)d\). In particular, this means that given a marginal distribution of states \(p_{T}\), which is approximately Gaussian, we can sample from \(p_{T}\) and simulate paths of the reverse-time SDE to obtain samples from the data distribution \(p_{0}\).

Score matching, probability flow ODE and 1-step trainingThere is a deterministic ODE , called probability flow ODE, which yields the same transformation of marginal probabilities from \(p_{T}\) to \(p_{0}\) as the reverse-time SDE. For the physics-based SDE (1), it is given by

\[d=[()-g(t)^{2}_{} p_{t}()]dt.\] (7)

For \( t 0\), we can rewrite the update rule (2) of the training as

\[d=[-}^{-1}()-s_{}(,t)]dt.\] (8)

Therefore, we can identify \(}^{-1}()\) with \(-()\) and \(s_{}(,t)\) with \(g(t)_{} p_{t}()\). We show that for the 1-step training and sufficiently small \( t\), we minimize the score matching objective (6).

**Theorem 3.1**.: _Consider a data set with trajectories sampled from SDE (1) and let \(}^{-1}()=-()\). Then the 1-step loss (3) is equivalent to minimizing the score matching objective (6) as \( t 0\)._

Proof.: See appendix A.1 

Maximum likelihood and multi-step trainingExtending the single step training to multiple steps does not directly minimize the score matching objective, but we can still interpret the learned correction in a probabilistic sense. For denoising score matching, it is possible to train \(s_{}\) via maximum likelihood training , which minimizes the KL-divergence between \(p_{0}\) and the distribution obtained by sampling \(_{T}\) from \(p_{T}\) and simulating the probability flow ODE (8) from \(t=T\) to \(t=0\). We derive a similar result for the multi-step loss.

**Theorem 3.2**.: _Consider a data set with trajectories sampled from SDE (1) and let \(}^{-1}()=-()\). Then the multi-step loss (4) maximizes a variational lower bound for maximum likelihood training of the probability flow ODE (7) as \( t 0\)._

Proof.: See appendix A.2 

To conclude, we have formulated a probabilistic multi-step training to solve inverse physics problems and provided a theoretical basis to solve these problems with score matching. Next, we outline additional details for implementing SMDP.

### Training and Inference

We start training \(s_{}\) with the multi-step loss and window size \(S=2\), which is equivalent to the 1-step loss. Then, we gradually increase the window size \(S\) until a maximum \(S_{}\). For \(S>2\), the unrolling of the predicted trajectory includes interactions between \(s_{}\) and the reverse physics simulator \(}^{-1}\). For inference, we consider the neural SDE

\[d=[-}^{-1}()-C\,s_{}( ,t)]dt+g(t)dW,\] (9)

which we solve via the Euler-Maruyama method. For \(C=2\), we obtain the system's reverse-time SDE and sampling from this SDE yields the posterior distribution. Setting \(C=1\) and excluding the noise gives the probability flow ODE (8). We denote the ODE variant by _SMDP ODE_ and the SDE variant by _SMDP SDE_. While the SDE can be used to obtain many samples and to explore the posterior distribution, the ODE variant constitutes a unique and deterministic solution based on maximum likelihood training.

## 4 Experiments

We show the capabilities of the proposed algorithm with a range of experiments. The first experiment in section 4.1 uses a simple 1D process to compare our method to existing score matching baselines. The underlying model has a known posterior distribution which allows for an accurate evaluation of the performance, and we use it to analyze the role of the multi-step loss formulation. Secondly, in section 4.2, we experiment with the stochastic heat equation. This is a particularly interesting test case as the diffusive nature of the equation effectively destroys information over time. In section 4.3, we apply our method to a scenario without stochastic perturbations in the form of a buoyancy-driven Navier-Stokes flow with obstacles. This case highlights the usefulness of the ODE variant. Finally, in section 4.4, we consider the situation where the reverse physics simulator \(}^{-1}\) is not known. Here, we train a surrogate model \(^{-1}\) for isotropic turbulence flows and evaluate how well SMDP works with a learned reverse physics simulator.

### 1D Toy SDE

As a first experiment with a known posterior distribution we consider a simple quadratic SDE of the form: \(dx=-[_{1}(x)x^{2}]dt+_{2}dW\), with \(_{1}=7\) and \(_{2}=0.03\). Throughout this experiment, \(p_{0}\) is a categorical distribution, where we draw either \(1\) or \(-1\) with the same probability. The reverse-time SDE that transforms the distribution \(p_{T}\) of values at \(T=10\) to \(p_{0}\) is given by

\[dx=-[_{1}(x)x^{2}-_{2}^{2} _{x} p_{t}(x)]dt+_{2}dw.\] (10)

In figure 1(a), we show paths from this SDE simulated with the Euler-Maruyama method. The trajectories approach \(0\) as \(t\) increases. Given the trajectory value at \(t=10\), it is no longer possible to infer the origin of the trajectory at \(t=0\).

This experiment allows us to use an analytic reverse simulator: \(}^{-1}(x)=_{1}(x)x^{2}\). This is a challenging problem because the reverse physics step increases quadratically with \(x\), and \(s_{}\) has to control the reverse process accurately to stay within the training domain, or paths will explode to infinity. We evaluate each model based on how well the predicted trajectories \(_{0:T}\) match the posterior distribution. When drawing \(_{T}\) randomly from \([-0.1,0.1]\), we should obtain trajectories with \(_{0}\) being either \(-1\) or \(1\) with the same likelihood. We assign the label \(-1\) or \(1\) if the relative distance of an endpoint is \(<10\)% and denote the percentage in each class by \(_{-1}\) and \(_{1}\). As some trajectories miss the target, typically \(_{-1}+_{1}<1\). Hence, we define the posterior metric \(Q\) as twice the minimum of \(_{-1}\) and \(_{1}\), i.e., \(Q:=2(_{-1},_{1})\) so that values closer to one indicate a better match with the correct posterior distribution.

Figure 2: Overview of our 1D toy SDE. (a) Training with a data set of trajectories and known temporal dynamics given by \(():=-()^{2}\) and \(g 0.1\). We estimate the score \(_{} p_{t}()\) with our proposed method using an MLP network for \(s_{}(,t)\). Negative values (blue) push down the trajectories, and positive ones (red) push them up. Together with the dynamics, this can be used to reverse the system as shown in (b) either with the reverse-time SDE or the probability flow ODE. A successful inversion of the dynamics requires the network \(s_{}\) to be robust and extrapolate well (c). Inference using GRID trained with the 1-step loss causes trajectories to explode, as the network does not extrapolate well. Training GRID with the multi-step loss solves this issue.

TrainingThe training data set consists of \(2500\) simulated trajectories from \(0\) to \(T\) and \( t=0.02\). Therefore each training trajectory has a length of \(M=500\). For the network \(s_{}(x,t)\), we consider a multilayer perceptron (MLP) and, as a special case, a grid-based discretization (GRID). The latter is not feasible for realistic use cases and high-dimensional data but provides means for an in-depth analysis of different training variants. For GRID, we discretize the domain \([0,T][-1.25,1.25]\) to obtain a rectangular grid with \(500 250\) cells and linearly interpolate the solution. The cell centers are initialized with \(0\). We evaluate \(s_{}\) trained via the 1-step and multi-step losses with \(S_{}=10\). Details of hyperparameters and model architectures are given in appendix C.

Better extrapolation and robustness from multi-step lossSee figure 1(c) for an overview of the differences between the learned score from MLP and GRID and the effects of the multi-step loss. For the 1-step training with MLP, we observe a clear and smooth score field with two tubes that merge to one at \(x=0\) as \(t\) increases. As a result, the trajectories of the probability flow ODE and reverse-time SDE converge to the correct value. Training via GRID shows that most cells do not get any gradient updates and remain \(0\). This is caused by a need for more training data in these regions. In addition, the boundary of the trained region is jagged and diffuse. Trajectories traversing these regions can quickly explode. In contrast, the multi-step loss leads to a consistent signal around the center line at \(x=0\), effectively preventing exploding trajectories.

Evaluation and comparison with baselinesAs a baseline for learning the scores, we consider implicit score matching [15, ISM]. Additionally, we consider sliced score matching with variance reduction [14, SSM-VR] as a variant of ISM. We train all methods with the same network architecture using three different data set sizes. As can be seen in table 1, the 1-step loss, which is conceptually similar to denoising score matching, compares favorably against ISM and SSM-VR. All methods perform well for the reverse-time SDE, even for very little training data. Using the multi-step loss consistently gives significant improvements at the cost of a slightly increased training time. Our proposed multi-step training performs best or is on par with the baselines for all data set sizes and inference types. Because the posterior metric Q is very sensitive to the score where the paths from both starting points intersect, evaluations are slightly noisy.

Comparison with analytic scoresWe perform further experiments to empirically verify Theorem 3.1 by comparing the learned scores of our method with analytic scores in appendix C.

  &  &  \\    &  &  \\  & 100\% & 10\% & 1\% & 100\% & 10\% & 1\% \\  multi-step & **0.97** & **0.91** & **0.81** & **0.99** & 0.94 & **0.85** \\
1-step & 0.78 & 0.44 & 0.41 & 0.93 & 0.71 & 0.75 \\ ISM & 0.19 & 0.15 & 0.01 & 0.92 & 0.94 & 0.52 \\ SSM-VR & 0.17 & 0.49 & 0.27 & 0.88 & 0.94 & 0.67 \\  

Table 1: Posterior metric \(Q\) for \(1000\) predicted trajectories averaged over three runs. For standard deviations, see table 3 in the appendix.

Figure 3: Stochastic heat equation overview. While the ODE trajectories provide smooth solutions with the lowest reconstruction MSE, the SDE solutions synthesize high-frequency content, significantly improving spectral error. The ”\(s_{}\) only” version without the reverse physics step exhibits a significantly larger spectral error. Metrics in (b) are averaged over three runs.

### Stochastic Heat Equation

The heat equation \(= u\) plays a fundamental role in many physical systems. For this experiment, we consider the stochastic heat equation, which slightly perturbs the heat diffusion process and includes an additional term \(g(t)\)\(\), where \(\) is space-time white noise, see Pardoux [14, Chapter 3.2]. For our experiments, we fix the diffusivity constant to \(=1\) and sample initial conditions at \(t=0\) from Gaussian random fields with \(n=4\) at resolution \(32 32\). We simulate the heat diffusion with noise from \(t=0\) until \(t=0.2\) using the Euler-Maruyama method and a spectral solver \(_{h}\) with a fixed step size \( t=6.25 10^{-3}\) and \(g 0.1\). Given a simulation end state \(_{T}\), we want to recover a possible initial state \(_{0}\). In this experiment, the forward solver cannot be used to infer \(_{0}\) directly in a single step or without corrections since high frequencies due to noise are amplified, leading to physically implausible solutions. We implement the reverse physics simulator \(^{-1}\) by using the forward step of the solver \(_{h}()\), i.e. \(}^{-1}()-_{h}()\).

Training and BaselinesOur training data set consists of \(2500\) initial conditions with their corresponding trajectories and end states at \(t=0.2\). We consider a small _ResNet_-like architecture based on an encoder and decoder part as representation for the score function \(s_{}(,t)\). The spectral solver is implemented via differentiable programming in _JAX_, see appendix D. As baseline methods, we consider a supervised training of the same _ResNet_-like architecture as \(s_{}(,t)\), a _Bayesian neural network_ (BNN) as well as a _Fourier neural operator_ (FNO) network . We adopt an \(L_{2}\) loss for all these methods, i.e., the training data consists of pairs of initial state \(_{0}\) and end state \(_{T}\).

Additionally, we consider a variant of our proposed method for which we remove the reverse physics step \(}^{-1}\) such that the inversion of the dynamics has to be learned entirely by \(s_{}\), denoted by "\(s_{}\) only". We do not compare to ISM and SSM-VR in the following as the data dimensions are too high for both methods to train properly, and we did not obtain stable trajectories during inference.

Reconstruction accuracy vs. fitting the data manifoldWe evaluate our method and the baselines by considering the _reconstruction MSE_ on a test set of \(500\) initial conditions and end states. For the reconstruction MSE, we simulate the prediction of the network forward in time with the solver \(_{h}\) to obtain a corresponding end state, which we compare to the ground truth via the \(L_{2}\) distance. This metric has the disadvantage that it does not measure how well the prediction matches the training data manifold. I.e., for this case, whether the prediction resembles the properties of the Gaussian random field. For that reason, we additionally compare the power spectral density of the states as the _spectral loss_. An evaluation and visualization of the reconstructions are given in figure 3, which shows that our ODE inference performs best regarding the reconstruction MSE. However, its solutions are smooth and do not contain the necessary small-scale structures. This is reflected in a high spectral error. The SDE variant, on the other hand, performs very well in terms of spectral error and yields visually convincing solutions with only a slight increase in the reconstruction MSE. This highlights the role of noise as a source of entropy in the inference process for SMDP SDE, which is essential for synthesizing small-scale structures. Note that there is a natural tradeoff between both metrics, and the ODE and SDE inference perform best for each of the cases while using an identical set of weights.

Multi-step loss is crucial for good performanceWe performed an ablation study on the maximum window size \(S_{}\) in figure 4 for the reconstruction MSE. For both ODE and SDE inference, increasing \(S_{}\) yields significant improvements at the cost of slightly increased training resources. This also highlights the importance of using a multi-step loss instead of the 1-step loss (\(S_{}=2\)) for inverse problems with poor conditioning.

We perform further experiments regarding test-time distribution shifts when modifying the noise scale and diffusivity, see appendix D, which showcase the robustness of our methods.

Figure 4: Multi-step \(S_{}\) vs. reconstruction MSE averaged over 5 runs.

### Buoyancy-driven Flow with Obstacles

Next, we test our methodology on a more challenging problem. For this purpose, we consider deterministic simulations of buoyancy-driven flow within a fixed domain \(\) and randomly placed obstacles. Each simulation runs from time \(t=0.0\) to \(t=0.65\) with a step size of \( t=0.01\). SMDP is trained with the objective of reconstructing a plausible initial state given an end state of the marker density and velocity fields at time \(t=0.65\), as shown in figure 4(a) and figure 4(b). We place spheres and boxes with varying sizes at different positions within the simulation domain that do not overlap with the marker inflow. For each simulation, we place one to two objects of each category.

Score matching for deterministic systemsDuring training, we add Gaussian noise to each simulation state \(_{t}\) with \(_{t}=\). In this experiment, no stochastic forcing is used to create the data set, i.e., \(g 0\). By adding noise to the simulation states, the 1-step loss still minimizes a score matching objective in this situation, similar to denoising score matching; see appendix A.3 for a derivation. In the situation without stochastic forcing, during inference, our method effectively alternates between the reverse physics step, a small perturbation, and the correction by \(s_{}(,t)\), which projects the perturbed simulation state back to the distribution \(p_{t}\). We find that for the SDE trajectories, \(C=2\) slightly overshoots, and \(C=1\) gives an improved performance. In this setting, the "\(s_{}\) only" version of our method closely resembles a denoiser that learns additional physics dynamics.

Training and comparisonOur training data set consists of 250 simulations with corresponding trajectories generated with _phiflow_. Our neural network architecture for \(s_{}(,t)\) uses dilated convolutions , see appendix E for details. The reverse physics step \(}^{-1}\) is implemented directly in the solver by using a negative step size \(- t\) for time integration. For training, we consider the multi-step formulation with \(S_{}=20\). We additionally compare with solutions from directly optimizing the initial smoke and velocity states at \(t=0.35\) using the differentiable forward simulation and limited-memory BFGS . Moreover, we compare with solutions obtained from diffusion posterior sampling for general noisy inverse problems  with a pretrained diffusion model on simulation states at \(t=0.35\). For the evaluation, we consider a reconstruction MSE analogous to section 4.2 and the perceptual similarity metric LPIPS. The test set contains five simulations. The SDE version yields good results for this experiment but is most likely constrained in performance by the approximate reverse physics step and large step sizes. However, the ODE version outperforms directly inverting the simulation numerically (\(}^{-1}\) only), and when training without the reverse physics step (\(s_{}\) only), as shown in 4(c).

### Navier-Stokes with Unknown Dynamics

As a fourth experiment, we aim to learn the time evolution of isotropic, forced turbulence with a similar setup as Li et al. . The training data set consists of vorticity fields from 1000 simulation trajectories from \(t=0\) until \(T=10\) with \( t=1\), a spatial resolution of \(64 64\) and

Figure 5: Buoyancy flow case. Ground truth shows the marker density and velocity field in the \(x\)-direction at different points of the simulation trajectory from the test set (a, b). We show reconstructions given the simulation end state at \(t=0.65\) and provide an evaluation of the reconstructed trajectories based on perceptual similarity (LPIPS) and the reconstruction MSE for three runs (c).

viscosity fixed at \(=10^{-5}\). As before, our objective is to predict a trajectory \(}_{0 M}\) that reconstructs the true trajectory given an end state \(_{M}\). In this experiment, we pretrain a surrogate for the reverse physics step \(}^{-1}\) by employing the FNO architecture from [Li+21] trained on the reverse simulation. For pretraining \(}^{-1}\) we use our proposed training setup with the multi-step loss and \(S_{}=10\) but freeze the score to \(s_{}(,t) 0\). Then, we train the time-dependent score \(s_{}(,t)\) while freezing the reverse physics step. This approach guarantees that any time-independent physics are captured by \(}^{-1}\) and \(s_{}(,t)\) can focus on learning small improvements to \(}^{-1}\) as well as respond to possibly time-dependent data biases. We give additional training details in appendix F.

Evaluation and training variantsFor evaluation, we consider the MSE and spectral error of the reconstructed initial state \(}_{0}\) compared to the reference \(_{0}\). As baselines, during inference, we employ only the learned surrogate model \(}^{-1}\) without \(s_{}\). In addition to that, we evaluate a variant for which we train both the surrogate model and \(s_{}(,t)\) at the same time. As the two components resemble the drift and score of the reverse-time SDE, this approach is similar to _DiffFlow_[ZC21], which learns both components in the context of generative modeling. We label this approach _simultaneous training_. Results are shown in figure 6. Similar to the stochastic heat equation results in section 4.2, the SDE achieves the best spectral error, while the ODE obtains the best MSE. Our proposed method outperforms both the surrogate model and the simultaneous training of the two components.

## 5 Discussion and Conclusions

We presented a combination of learned corrections training and diffusion models in the context of physical simulations and differentiable physics for solving inverse physics problems. We showed its competitiveness, accuracy, and long-term stability in challenging and versatile experiments and motivated our design choices. We considered two variants with complementary benefits for inference: while the ODE variants achieve the best MSE, the SDE variants allow for sampling the posterior and yield an improved coverage of the target data manifold. Additionally, we provided theoretical insights that the 1-step is mathematically equivalent to optimizing the score matching objective. We showed that its multi-step extension maximizes a variational lower bound for maximum likelihood training.

Despite the promising initial results, our work has limitations that open up exciting directions for future work: Among others, it requires simulating the system backward in time step by step, which can be costly and alleviated by reduced order methods. Additionally, we assume that \( t\) is sufficiently small and the reverse physics simulator is accurate enough. Determining a good balance between accurate solutions with few time steps and diverse solutions with many time steps represents an important area for future research.

AcknowledgementsBH, SV, and NT acknowledge funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (LEDA: grant agreement No 758853, and SpaTe: grant agreement No 863850). SV thanks the Max Planck Society for support through a Max Planck Lise Meitner Group. This research was partly carried out on the High Performance Computing resources of the FREYA cluster at the Max Planck Computing and Data Facility (MPCDF) in Garching operated by the Max Planck Society (MPG).

Figure 6: Turbulence case. Comparison of reconstructed trajectories (a) and evaluation of MSE and spectral error for different training variants (b). Our proposed ODE and SDE inference outperforms the learned surrogate model \(}^{-1}\). Metrics are averaged over three runs.