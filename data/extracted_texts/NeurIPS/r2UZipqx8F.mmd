# Machine Learning Force Fields with Data Cost Aware Training

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Machine learning force fields (MLFF) have been proposed to accelerate molecular dynamics (MD) simulation, which finds widespread applications in chemistry and biomedical research. Even for the most data-efficient MLFFs, reaching chemical accuracy can require hundreds of frames of force and energy labels generated by expensive quantum mechanical algorithms, which may scale as \(O(n^{3})\) to \(O(n^{7})\), with \(n\) proportional to the number of basis functions. To address this issue, we propose a multi-stage computational framework - ASTEROID, which lowers the data cost of MLFFs by leveraging a combination of cheap inaccurate data and expensive accurate data. The motivation behind ASTEROID is that inaccurate data, though incurring large bias, can help capture the sophisticated structures of the underlying force field. Therefore, we first train a MLFF model on a large amount of inaccurate training data, employing a bias-aware loss function to prevent the model from overfitting tahe potential bias of this data. We then fine-tune the obtained model using a small amount of accurate training data, which preserves the knowledge learned from the inaccurate training data while significantly improving the model's accuracy. Moreover, we propose a variant of ASTEROID based on score matching for the setting where the inaccurate training data are unlabeled. Extensive experiments on MD datasets validate the efficacy of ASTEROID.

## 1 Introduction

Molecular dynamics (MD) simulation is a key technology driving scientific discovery in fields such as chemistry, biophysics, and materials science (Alder and Wainwright, 1960; McCammon et al., 1977). By simulating the dynamics of molecules, important macro statistics such as the folding probability of a protein (Tuckerman, 2010) or the density of new materials (Varshney et al., 2008) can be estimated. These macro statistics are an essential part of many important applications such as structure-driven drug design (Hospital et al., 2015) and battery development (Leung and Budzien, 2010). Most MD simulation techniques share a common iterative structure: MD simulations calculate the forces on each atom in the molecule, and use these forces to move the molecule forward to the next state.

The fundamental challenge of MD simulation is how to efficiently calculate the forces at each iteration. An exact calculation requires solving the Schrodinger equation, which is not feasible for many-body systems (Berezin and Shubin, 2012). Instead approximation methods such as the Lennard-Jones potential (Johnson et al., 1993), Density Functional Theory (DFT, Kohn (2019)), or Coupled Cluster Single-Double-Triple (CCSD(T), Scuseria et al. (1988)) are used. CCSD(T) is seen as the gold-standard for force calculation, but is computationally expensive. In particular,CCSD(T) has complexity \((n^{7})\) with respect to the number of basis functions used along with a huge storage requirement (Chen et al., 2020). To accelerate MD simulations while maintaining high accuracy, machine learning based force fields (MLFFs) have been proposed. MLFFs take a molecular configuration as input and then predict the forces on each atom in the molecule, consequently speeding up the force calculation step.

Most recently, deep learning techniques for force fields have been developed, resulting in highly accurate force fields parameterized by large neural networks (Gasteiger et al., 2021; Batzner et al., 2022). Despite their empirical success, these methods suffer from a critical drawback: _in order to train state-of-the-art machine learning force field models, a large amount of costly training data must be generated_. For example, to train a model at the CCSD(T) level of accuracy, at least a thousand CCSD(T) calculations must be done to construct the training set. This is computationally expensive due to the method's \((n^{7})\) cost.

A natural solution to this problem is to train on fewer data points. However, if the number of training points is decreased, the accuracy of the learned force fields quickly deteriorates. In our experiments, we empirically find that the prediction error and the number of training points roughly follow a power law relationship, with prediction error \(()^{-1}\)(Muller et al., 1996; Cortes et al., 1993). This can be seen in Figure 0(a), where prediction error and train set size are observed to have a linear relationship with a slope of \(-1\) when plotted on a log scale.

Another option is to train the force field model on less accurate but computationally cheap reference forces calculated using DFT (Kohn, 2019) or empirical force field methods (Johnson et al., 1993). However, these algorithms introduce undesirable bias into the force labels, meaning that the trained models will have poor performance. This phenomenon can be seen in Figure 0(b), where models trained on large quantities of DFT reference forces are shown to perform poorly relative to force fields trained on moderate quantities of CCSD(T) reference forces. Therefore current methodologies are not sufficient for training force field models in low resource settings, as training on either small amounts of accurate data (i.e. from CCSD(T)) or large amounts of inaccurate data (i.e. from DFT or empirical force fields) will result in inaccurate force fields.

To address this issue, we propose to use both large amounts of inaccurate force field data and small amounts of accurate data to reduce the data generation cost needed to achieve highly accurate force fields. Our motivation is that computationally cheap data, though incurring large bias, can help capture the sophisticated structures of the underlying force field. Moreover, if treated properly, we can further reduce the bias of the obtained model by taking advantage of the accurate data.

Specifically, we propose a multi-stage computational framework - dat**A** cos**ST** awar**E**t**Raining of **f**O**rc**f**I**el**Ds (ASTEROID). In the first stage, small amounts of accurate data are used to identify the

Figure 1: (a) Log-log plot of the number of training points versus the prediction error for deep force fields (b) Prediction error on CCSD labeled molecules for force fields trained on large amounts of DFT reference forces (100,000 configurations) and moderate amounts of CCSD reference forces (1000 configurations). In both cases the model architecture used is GemNet (Gasteiger et al., 2021).

bias of force labels in a large but inaccurate dataset. In the second stage, the model is trained on the large inaccurate dataset with a bias-aware loss function. This loss function generates smaller weights for data points with larger bias, suppressing the effect of label noise on training. The inaccurately trained model serves as a warm start for the third stage, where it is fine-tuned on the small and accurate dataset. Together, these stages allow the model to learn from many molecular configurations while incorporating highly accurate force data, significantly outperforming conventional methods trained with similar data generation budgets.

Beyond using cheap labeled data to boost model performance, we also develop a method for the case where a large amount of unlabeled molecular configurations are cheaply available (Smith et al., 2017; Kohler et al., 2022). Without labels, we cannot adopt the supervised learning approach. Instead, we draw a connection to score matching, which learns the gradient of the log density function with respect to each data point (called the score) (Hyvarinen, 2005). In the context of molecular dynamics, we notice that if the log density function is proportional to the energy of each molecule, then the score function with respect to a molecule's position is equal to the force on the molecule. Based on this insight, we show that the supervised force matching problem can be tackled in an unsupervised manner. This unsupervised approach can then be incorporated into the ASTEROID framework, improving performance when limited data is available.

We demonstrate the effectiveness of our framework with extensive experiments on different force field data sets and downstream simulation tasks. We use two popular model architectures, GemNet (Gasteiger et al., 2021) and EGNN (Satorras et al., 2021), and verify the performance of our method in a variety of settings. These experiments show that ASTEROID can lead to significant gains when either DFT reference forces or empirical force field forces are viewed as inaccurate data and CCSD(T) configurations are used as accurate data. In addition, we show that we can learn accurate forces via the connection to score matching, and that using this objective in the second stage of training can improve performance on both DFT and CCSD(T) datasets.

## 2 Background

\(\) **Machine Learning Force Fields.** Recent years have seen a surge of interest in MLFFs. Much of this work has focused on developing machine learning architectures that have physically correct equivariances, resulting in large graph neural networks that can generate highly accurate force and energy predictions (Gasteiger et al., 2021; Satorras et al., 2021; Batzner et al., 2022). Two popular architectures are EGNN and GemNet. Both models are translation invariant, rotationally equivariant, and permutation equivariant. EGNN is a smaller model and is often used when limited resources are available. The GemNet architecture is significantly larger and more refined than the EGNN architecture, modeling various types of inter-atom interactions. GemNet is therefore more powerful and can achieve state-of-the-art performance, but requires more resources to train.

It has been observed that modern MLFFs often cannot achieve sufficient test accuracy to be reliable for MD simulations (Stocker et al., 2022). Critically, the accuracy of deep force fields such as GemNet and EGNN is highly dependent on the size and quality of the training dataset. With limited training data, MLFFs cannot achieve the required accuracy for usefulness, preventing their application in settings where data is expensive to generate (e.g. large molecules). The amount of resources needed to train is therefore a key bottleneck preventing the widespread use of MLFFs.

\(\) **Data Generation Cost.** The training data for MLFFs can be generated by a variety of force calculation methods. These methods exhibit an accuracy cost tradeoff: accurate reference forces from methods such as CCSD(T) require high computational costs to generate reference forces, while inaccurate reference forces from methods such as DFT and empirical force fields can be generated fairly quickly. Concretely, CCSD(T) is highly accurate but has \((n^{7})\) complexity, DFT is less accurate with complexity \((n^{3})\), and empirical force fields are inaccurate but could have complexity as low as \((n)\)(Lin et al., 2019; Ratcliff et al., 2017). CCSD(T) is typically viewed as the gold standard for calculating reference forces, but its computational costs often make it impractical for MD simulation (it has been estimated that "a nanosecond-long MD trajectory for a single ethanol molecule executed with the CCSD(T) method would take roughly a million CPU years on modern hardware")[Chmiela et al., 2018]. Due to this large expense, MLFF training data is typically generated first with MD simulations driven by DFT or empirical force fields. These simulations generate a large number of molecular configurations, and then CCSD(T) reference forces are computed for a small portion of these configurations. Therefore, a large amount of inaccurately labeled molecular configurations are often available along with the accurate CCSD(T) labeled data.

## 3 Asteroid

To reduce the data generation cost needed to train MLFFs, we propose a multi-stage training framework, ASTEROID, to learn from a combination of both cheaply available inaccurate data and more expensive accurate data.

**Preliminaries.** For a molecule with \(k\) atoms, we denote a configuration (the positions of its atoms in 3D) of this molecule as \(x^{3k}\), its respective energy as \(E(x)\), and its force as \(F(x)^{3k}\). We denote the accurately labeled data as \(_{A}=\{(x_{1}^{n},e_{1}^{a},f_{1}^{n}),...,(x_{N}^{n},e_{N}^{a},f_{ N}^{a})\}\) and the inaccurately labeled data as \(_{I}=\{(x_{1}^{n},e_{1}^{n},f_{1}^{n}),...,(x_{M}^{n},e_{M}^{n},f_{ M}^{n})\}\), where \((x_{i}^{a},e_{i}^{a},f_{i}^{a})\) represents the position, potential energy, and force of the \(i\)th accurately labeled molecule, (similarly \((x_{j}^{n},e_{j}^{n},f_{j}^{n})\) for the \(j\)th inaccurately labeled data). Conventional methods train a force field model \(E(;)\) with parameters \(\) on the accurate data by minimizing the loss

\[_{}(_{A},)=_{i=1 }^{N}\!_{f}(f_{i}^{a},_{x}E(x_{i}^{a};))+_{ i=1}^{N}_{e}(e_{i}^{a},E(x_{i}^{a};)),\] (1)

where \(_{f}\) is the loss function for the force prediction, and \(_{e}\) is the loss function for the energy prediction. Here the force is denoted by \(_{x}E(x;)\), i.e., the gradient of the energy \(E(x;)\) w.r.t. to the input \(x\). In practice, most of the emphasis is placed on the force prediction, e.g. \(=0.001\).

### Bias Identification

The goal of ASTEROID is to leverage cheap MD simulation data to boost MLFF accuracy. However, the approximation algorithms used to generate cheap data \(_{I}\) introduce a large amount of bias into some force labels \(f^{n}\), which may significantly hurt accuracy. Motivated by this phenomenon, we aim to identify the most biased force labels so that we can avoid overfitting the bias during training. To do so, we use small amounts of accurately labeled data \(_{A}\) to identify the levels of bias in the inaccurate dataset \(_{I}\). Specifically, we train a force field model by minimizing \((_{A},)\) (Eq. 1), the loss over the accurate data, to get parameters \(_{0}\). Although the resulting model \(E(;_{0})\) will not necessarily have good prediction performance because of the limited amount of training data, it can still help estimate the bias of the inaccurate data. For every configuration \(x_{j}^{n}\) in the inaccurate dataset \(_{I}\), we suspect it to have a large bias if there is a large discrepancy between its force label \(f_{j}^{n}\) and the force label predicted by the accurately trained model \(_{x}E(x_{j}^{n};_{0})\). We can therefore use this discrepancy as a surrogate for bias, i.e. \(B(x_{j}^{n})=\|_{x}E(x_{j}^{n};_{0})-f_{j}^{n}\|_{1}\).

### Bias-Aware Training with Inaccurate Data

In the second stage of our framework, we train a force field model \(E(;_{})\) from scratch on large amounts of _inaccurately labeled data_\(_{I}\). Although this data can effectively capture the intrinsic

Figure 2: Asteroid workflow diagram.

problem structure, the high levels of bias on some data points may propagate to the final model and harm generalization performance. To avoid over-fitting to the biased force labels, we use a bias-aware loss function that weighs the inaccurate data according to their bias. In particular, we use the weights \(w_{j}=(-B(x_{j}^{n})/)\) for configuration \(x_{j}^{n}\), where \(\) is a hyperparameter to be tuned. In this way, low-bias points are given higher importance and high-bias points are treated more carefully. We then minimize the bias-aware loss function

\[_{}_{w}(_{I},)=(1-)_{i=1}^{M}w_{ i}_{f}(f_{i}^{n},_{x}E(x_{i}^{n};))+_{i=1}^{M}w_{i} _{e}(e_{i}^{n},E(x_{i}^{n};))\] (2)

to get parameters \(_{ init}\), resulting in the initial estimate of the MLFF \(E(;_{ init})\).

### Fine-Tuning over Accurate Data

The model \(E(;_{ init})\) contains information useful to the force prediction problem, but may still contain bias because it is trained on inaccurately labeled data \(_{I}\). Therefore, we further refine it using accurately labeled data \(_{A}\). Specifically, we use \(E(;_{ init})\) as initialization for our final stage, in which we fine-tune the model over the accurate data by minimizing \((_{A},_{ final})\) (Eq. 1). The full ASTEROID framework is illustrated in Figure 2.

## 4 ASTEROID for Unlabeled Data

In several settings, molecular configurations are generated without force labels, either because they are not generated via MD simulation (e.g. normal mode sampling, Smith et al. (2017)) or because the forces are not stored during the simulation (Kohler et al., 2022). Although these unlabeled configurations may be cheaply available, they are not generated for the purpose of learning force fields and have not been used in existing literature. Here, we show that the unlabeled configurations can be used to obtain an initial estimate of the force field, which can then be further fine-tuned on accurate data. More specifically, we consider a molecular system where the number of particles, volume, and temperature are constant (NVT ensemble). Let \(x\) refer to a molecule's configuration and \(E(x)\) refer to the corresponding potential energy. It is known that \(x\) follows a Boltzmann distribution, i.e.

\[p(x)=(-T}E(x)),\]

where \(Z\) is a normalizing constant, \(T\) is the temperature, and \(k_{}\) is the Boltzmann constant. In practice, configurations generated using normal mode sampling (Unke et al., 2021) or via a sufficiently long NVT MD simulation follow a Boltzmann distribution.

Recall that we model the energy \(E(x)\) as \(E(x;),\) and the force can be calculated as \(F(x;)=_{x}E(x;).\) It follows from Hyvarinen (2005) that we can learn the score function of the Boltzmann distribution using score matching, where the score function is defined as the gradient of the log density function \(_{x}p(x)\). In our case, we observe that the force on a configuration \(x\) is proportional to the score function, i.e., \(F(x)_{x}p(x)\). Therefore, we can use score matching to learn the forces by minimizing the unsupervised loss

\[L()=_{p(x)}[[_{x}F(x; )]+||F(x;)||^{2}],\] (3)

where \(=T}\). A derivation can be found in Appendix A.5. Although this objective allows us to solve the force matching problem in an unsupervised manner, the unsupervised loss is difficult to optimize in practice. To reduce the cost of solving Eq. 3, we adopt sliced score matching (Song et al., 2020). Sliced score matching takes advantage of random projections to significantly reduce the cost of solving Eq. 3, allowing us to apply score matching to large neural models such as GemNet.

In our experiments, we find that score matching does not match the accuracy of CCSD(T) force labels. Instead, we can think of score-matching as a form of inaccurate training. We therefore use score matching as an alternative to stages one and two of the ASTEROID framework. That is, we minimize Eq. 3 to get \(_{ init}\), after which the model is fine-tuned on the accurate data.

Experiments

For our main experiments, we evaluate ASTEROID on MLFF datasets and downstream MD simulation tasks. For ASTEROID, we consider three settings: using DFT data to enhance CCSD(T) training, using empirical force field data to enhance CCSD(T) training, and using unlabeled configurations to enhance CCSD(T) training. In each setting, we evaluate the performance of ASTEROID and standard training over a variety of data generation budgets.

### Datasets and Models

For the CCSD(T) data, we use MD17@CCSD, which contains 1,000 configurations labeled at the CCSD(T) and CCSD level of accuracy for five molecules (Chmiela et al., 2017). For DFT data, we use the MD17 dataset, which contains molecular configurations labeled at the DFT level of accuracy (Chmiela et al., 2017). For the empirical force field data, we generate 100,000 configurations for each molecule using the OpenMM empirical force field software (Eastman et al., 2017). For the unlabeled datasets, we use MD17 with the force labels removed.

The MD17 datasets do not release the computational cost of data generation, but when we replicate their experiments, we find that CCSD(T) labels cost roughly 40 times more than DFT labels. However, the difference in cost between CCSD(T) and DFT labels may change drastically depending on the implementation of each method. Therefore we evaluate the performance of ASTEROID when CCSD(T) force labels are 20, 40, and 80 times more expensive than DFT force labels. Note that the cost of empirical force labels is essentially negligible (more than 10,000 times cheaper) compared to CCSD(T) labels (Folmsbee and Hutchison, 2021).

In each setting, we compare standard training with 250, 450, 650, or 850 CCSD(T) training samples with ASTEROID. For ASTEROID, we use either 1000, 2000, or 4000 DFT datapoints (corresponding to cost ratios of 20:1, 40:1, and 80:1 for DFT and CCSD(T) labels), and 200, 400, 600, or 800 CCSD(T) data points. The computational budget of standard training and ASTEROID are therefore equivalent. A validation set of size 50 and a test set of size 500 are used in all experiments.

We implement our method on GemNet and EGNN. For GemNet we use the same model parameters as Gasteiger et al. (2021). For EGNN, we use a 5-layer model and an embedding size of 128. When training with inaccurate data, we train with a batch size of 16 and stop training when the loss stabilizes. In the fine-tuning stage, we use a batch size of 10 and train for a maximum of 2000 epochs. To tune the bias aware loss parameter \(\), we search in the set \(\{0.1,0.5,1.0,2.0\}\) and select the model with the lowest validation loss. Comprehensive experimental details are deferred to Appendix A.6.

### Enhancing Force Fields with DFT

We display the results for using DFT data to enhance CCSD(T) training in Figure 3 for GemNet and Figure 4 for EGNN. From these figures, we can see that ASTEROID can outperform standard training for all amounts of data and cost ratios. Using larger amounts of inaccurate data can significantly reduce prediction error, but the 20:1 cost ratio already has large performance gains over standard training. When applied to GemNet in low resource settings, ASTEROID reduces the average prediction error by 39.4% and improves sample efficiency by a factor of 2. For EGNN, ASTEROID improves prediction error by 56% and increases sample efficiency by more than 3 times. The large performance increase for EGNN may be due to the fact that the EGNN architecture has less inductive bias than GemNet, and therefore may struggle to learn the structures of the underlying force field with only a small amount of data.

### Enhancing Force Fields with Empirical Force Calculation

We present the results for empirical force field in Table 1. Additional results for GemNet can be found in Appendix A.7. Again we find that ASTEROID significantly outperforms the supervised baseline, improving prediction accuracy by 36% for GemNet and by 17% for EGNN. The good performance on empirical force fields indicates that ASTEROID is relatively robust to the label noise on the inaccurate data.

### Enhancing Force Fields with unlabeled Molecules

We first verify that our proposed score matching approach can learn the forces on unlabeled molecules by comparing the prediction accuracy of models trained by score matching with models trained on supervised data (DFT and empirical force fields). We measure prediction accuracy on CCSD(T) datasets and show the results in Figure 7. Surprisingly, we find that the prediction error of score matching is between that of DFT and empirical force fields. This indicates that relatively accurate force predictions can be obtained by only solving the unsupervised loss in Eq. 3.

Next we apply ASTEROID to settings where unlabeled data is available by fine-tuning the model obtained from score matching. We present the results in Table 2, where we find that ASTEROID can improve prediction accuracy by 18% for GemNet and 4% for EGNN. If unsupervised data can be generated cheaply (i.e. through normal mode sampling), then our approach can be used to boost the performance of MLFFs with little additional cost.

## 6 Discussion

**Related Work.** There are several works which we compare ASTEROID with.

\(\)**-ML**[Ramakrishnan et al., 2015, Bogojeski et al., 2020], learns the difference between inaccurate (DFT) and accurate (CCSD(T)) force predictions, therefore speeding up MD simulation while

    & **Aspirin** & **Benzene** & **Malonaldehyde** & **Toluene** & **Ethanol** \\ 
**GemNet** & & & & & \\ Standard Training & \(1.554\) & \(0.083\) & \(0.801\) & \(0.591\) & \(0.348\) \\ ASTEROID & \(\) & \(\) & \(\) & \(\) & \(\) \\ 
**EGNN** & & & & & \\ Standard Training & \(1.897\) & \(0.297\) & \(1.466\) & \(0.777\) & \(0.840\) \\ ASTEROID & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 1: Test MAE of ASTEROID with empirical force field data. The results are measure in kcal/mol/Å, averaged across dimensions and atoms. The training set for the fine-tuning stage contains 200 molecules labeled at the CCSD(T) level. “Malo.” refers to malonaldehyde and “Standard Tr.” refers to standard training.

Figure 4: Main results for EGNN when DFT data is viewed as inaccurate.

Figure 3: Main results for GemNet when DFT data is viewed as inaccurate. The ratio refers to the number of DFT calculations that are equivalent to one CCSD(T) calculation. The results are measure in kcal/mol/Å, averaged across dimensions and atoms.

maintaining high accuracy. However, this approach requires a DFT calculation to be done during inference, greatly increasing inference time compared to ASTEROID or standard MLFFs (Folmsbee and Hutchison, 2021).

\(\)**ANI-1ccx**(Smith et al., 2019; Deringer et al., 2020) train an MLFF on a huge DFT dataset comprised of many molecules, and then finetune on many CCSD(T) labeled molecules with a goal of learning a general MLFF. Notably, the method from Smith et al. (2017) only trains on equilibrium states and may not work well for MD trajectory data. To compare ANI-1ccx with ASTEROID, we evaluate the provided model checkpoint in the zero-shot setting (as in (Smith et al., 2019)) and when finetuned on each MD17 molecule. Note that the data generation cost of ANI-1ccx is much more expensive than ASTEROID, using 2,500 times more CCSD(T) data and 500 times more DFT data.

\(\)**sGDML**(Chmiela et al., 2019) is a kernel-based MLFF method that can perform well when limited training data is available by incorporating relevant physical constraints into the MLFF.

As can be seen in Table 3, ASTEROID trained MLFFs can achieve lower test errors than all of the baselines except \(\)-ML. However, since \(\)-ML requires a DFT calculation during inference, MD simulation with \(\)-ML will take 100 to 1000 times longer than with ASTEROID (Folmsbee and Hutchison, 2021; Gasteiger et al., 2021). Therefore ASTEROID results in the most useful force fields out of all the baselines, while having a smaller or equivalent data generation cost.

**Ablation.** We conduct a detailed ablation study in Appendix A.3, which shows ASTEROID is fairly robust to hyperparameter selection.

**MD Simulation** We show the results of MD simulation results in Appendix A.2, where we observe ASTEROID can result in stable simulation.

**Asteroid with Multiple Molecules.** We try ASTEROID on multiple molecules simultaneously in Appendix A.1. We find mixed results, indicating this could be an exciting direction to explore further.

    & **Aspirin** & **Benzene** & **Malonaldehyde** & **Toluene** & **Ethanol** \\ 
**GemNet** & & & & & \\ Standard Training & \(1.554\) & \(\) & \(0.801\) & \(0.591\) & \(0.348\) \\ ASTEROID & \(\) & \(0.093\) & \(\) & \(\) & \(\) \\ 
**EGNN** & & & & & \\ Standard Training & \(1.897\) & \(\) & \(1.466\) & \(0.777\) & \(0.840\) \\ ASTEROID & \(\) & \(0.305\) & \(\) & \(\) & \(\) \\   

Table 2: Accuracy of ASTEROID with unlabeled molecular configurations. The results are measure in kcal/mol/Å, averaged across dimensions and atoms. The training set for the fine-tuning stage contains 200 CCSD(T) labeled molecules.

    & **Aspirin** & **Benzene** & **Malonaldehyde** & **Toluene** & **Ethanol** \\ 
**ANI-1** & \(1.897\) & \(0.297\) & \(1.466\) & \(0.777\) & \(0.840\) \\
**ANI-1 (FT)** & \(1.314\) & \(0.268\) & \(1.341\) & \(0.664\) & \(0.637\) \\  \(\)**-ML** & \(\) & \(-\) & \(\) & \(0.350\) & \(-\) \\ 
**sGDML** & \(1.727\) & \(0.097\) & \(0.923\) & \(0.478\) & \(0.902\) \\ 
**ASTEROID** & \(0.908\) & \(\) & \(0.338\) & \(\) & \(\) \\   

Table 3: Accuracy of ASTEROID compared with competitive baselines with a data budget of 250 CCSD(T) points. FT refers to fine-tuning ANI-1ccx on MD17@CCSD. The model is GemNet.