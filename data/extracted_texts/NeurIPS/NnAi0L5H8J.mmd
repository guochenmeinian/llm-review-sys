# Multi-Instance Partial-Label Learning with

Margin Adjustment

 Wei Tang\({}^{1,2}\), Yin-Fang Yang\({}^{1,2}\), Zhaofei Wang\({}^{1,2}\), Weijia Zhang\({}^{3}\), Min-Ling Zhang\({}^{1,2}\)

\({}^{1}\)School of Computer Science and Engineering, Southeast University, Nanjing 210096, China

\({}^{2}\)Key Laboratory of Computer Network and Information Integration (Southeast University),

Ministry of Education, China

\({}^{3}\)School of Information and Physical Sciences, The University of Newcastle,

Callaghan, NSW 2308, Australia

tangw@seu.edu.cn, yangyf22@gmail.com, wangzf@seu.edu.cn, weijia.zhang@newcastle.edu.au, zhangml@seu.edu.cn

Corresponding author

###### Abstract

Multi-instance partial-label learning (MIPL) is an emerging learning framework where each training sample is represented as a multi-instance bag associated with a candidate label set. Existing MIPL algorithms often overlook the margins for attention scores and predicted probabilities, leading to suboptimal generalization performance. A critical issue with these algorithms is that the highest prediction probability of the classifier may appear on a non-candidate label. In this paper, we propose an algorithm named MipLMa, i.e., _Multi-Instance Partial-Label learning with Margin Adjustment_, which adjusts the margins for attention scores and predicted probabilities. We introduce a margin-aware attention mechanism to dynamically adjust the margins for attention scores and propose a margin distribution loss to constrain the margins between the predicted probabilities on candidate and non-candidate label sets. Experimental results demonstrate the superior performance of MipLMa over existing MIPL algorithms, as well as other well-established multi-instance learning algorithms and partial-label learning algorithms.

## 1 Introduction

Weakly supervised learning is a powerful strategy for constructing predictive models with limited supervision. Based on the quality and quantity of supervision, Zhou  systematically categorizes weak supervision into three types: inexact, inaccurate, and incomplete supervision. Inexact supervision indicates a coarse alignment between instances and labels, which is a common and challenging issue in real-world tasks. _Multi-instance learning (MIL)_ and _partial-label learning (PLL)_ are two predominant weekly supervised learning frameworks for learning from samples with inexact supervision in the instance space and the label space, respectively.

Recently, _multi-instance partial-label learning (MIPL)_ has been introduced to handle _dual inexact supervision_, where inexact supervision exists in both the instance space and label space. Therefore, MIPL can be seen as a generalized framework of MIL and PLL. In MIPL, a training sample is represented as a multi-instance bag associated with a candidate label set. The candidate label set comprises one true label and the remaining are false positives. The multi-instance bag contains at least one instance corresponding to the true label and does not contain any instance associated with the false positives. Additionally, _positive instances_ refer to the instances that belong to the true label, while _negative instances_ represent the remaining instances in the bag that are notassociated with any label in the label space. During training, the identities of the positive instances and the true label are inaccessible.

Dual inexact supervision widely exists in many tasks. In the classification of histopathological images, an image is frequently partitioned into a multi-instance bag due to its high resolution [17; 18; 19; 6] and employing domain experts for providing ground truth labels are costly. As a result, the utilization of crowd-sourced candidate label sets proves to be a valuable strategy in substantially mitigating labeling expenses . To address colorectal cancer classification under dual inexact supervision, Tang et al.  have introduced the MIPL algorithm named DeMpl. This approach employs an attention mechanism to aggregate all instances within a bag into a bag-level feature representation and a disambiguation strategy to identify the true label. Following DeMpl, EliMpl algorithm has been proposed to exploit the label information from both candidate and non-candidate label sets . Additionally, the early MIPL algorithm M DiplGp predicts a bag-level label by aggregating all instance-level labels within the bag without utilizing attention mechanisms .

However, existing MIPL algorithms fail to consider the dynamics of the margin between attention scores of positive and negative instances, as well as the margin between the candidate and the non-candidate label sets. These oversights could lead to two major issues. First, the attention scores for positive and negative instances can be quite similar, and in some cases, negative instances may even receive higher attention scores than positive ones, as illustrated in Figure 1(a). Second, the classifier may even assign higher predicted probabilities to non-candidate labels than to candidate labels. Figure 1(c) illustrates a scenario where EliMipl assigns predicted probabilities to the candidate labels that are only marginally higher than the non-candidate ones. Furthermore, EliMipl may even output lower predicted probabilities for candidate labels than non-candidate ones, as depicted in Figure 1(d). Such erroneous predictions may have serious consequences in applications. For example, in medical image classification, misclassifying images of severe conditions as mild or disease-free may cause patients to miss the opportunity for timely treatment. In this paper, we term this phenomenon as _margin violations_, where the attention scores of negative instances surpass those of positives, or the predicted probabilities for non-candidate labels exceed those for candidate ones. Margin violations occur in both the instance and label spaces, adversely affecting the model's generalization.

To overcome margin violations, we propose a novel end-to-end MIPL algorithm named M DiplMa, i.e., _Multi-Instance Partial-Label learning with Margin Adjustment_. Specifically, to mitigate margin violations in the instance space, we introduce a margin-aware attention mechanism to consolidate each multi-instance bag into a unified feature representation, incorporating dynamic margin adjustments for attention scores. To address margin violations in the label space, we propose a margin distribution loss that adjusts the margin distribution between the model's highest predicted probability for candidate labels and its highest predicted probability for non-candidate labels. In Figure 1(a), M DiplMa allocates

Figure 1: Margin violations in the instance space and the label space. (a) and (b) depict the attention scores of EliMipl and M DiplMa for the same test bag in the FMNIST-mipl dataset. Orange and blue colors indicate attention scores assigned to positive and negative instances, respectively. (c)–(f) show the highest predicted probabilities for candidate labels (green) and non-candidate labels (blue) by EliMipl or M DiplMa in the CRC-mipl-Row dataset. (c) and (e) correspond to the same training bag, while (d) and (f) refer to another training bag.

higher attention scores to positive instances and enlarges the gap between the attention scores of positive and negative instances. As illustrated in Figure 1(e) and (f), MiplMa significantly enhances the classifier's highest predicted probability on candidate labels while concurrently reducing the model's highest predicted probability on non-candidate labels. Consequently, our margin adjustment strategy effectively reduces supervision inexactness in both the instance space and the label space.

Our contributions can be summarized as follows: First, we identify the phenomenon of margin violations and adjust the margins in both the instance and label spaces to alleviate this issue. Second, our proposed MiplMa outperforms state-of-the-art methods significantly. Third, the introduced margin-aware attention mechanism enhances the performance of MIL algorithms, while the margin distribution loss improves the generalization ability of PLL algorithms.

## 2 The Proposed Approach

Formally, we define a MIPL training dataset as \(=\{(_{i},_{i}) 1 i m\}\), comprising \(m\) multi-instance bags and their corresponding candidate label sets. Specifically, each candidate label set \(_{i}\) includes one true label, and the remaining are false positives. We denote the instance space as \(=^{d}\), and the label space as \(=\{1,2,,k\}\), covering \(k\) class labels. The \(i\)-th bag \(_{i}=\{_{i,1},_{i,2},,_{i,n_{i}}\}\) consists of \(n_{i}\) instances in the \(d\)-dimensional space. Both the candidate label set \(_{i}\) and the non-candidate label set \(}_{i}\) are proper subsets of the label space \(\) and adhere to the conditions \(|_{i}|+|}_{i}|=||=k\), where \(||\) represents the cardinality of a set.

The overall framework of MiplMa is depicted in Figure 2. Initially, we employ a feature extractor \(\) to learn instance-level feature representations \(_{i}\) within the multi-instance bag \(_{i}\). Subsequently, we propose a margin-aware attention mechanism with adjustable margins of attention scores to fuse \(_{i}\) into a unified feature representation \(_{i}\). Lastly, we utilize a classifier to predict the probabilities \(}_{i}\) of the multi-instance bag. To identify the true label from the candidate label set, we introduce the dynamic disambiguation loss \(_{d}\) and the margin distribution loss \(_{m}\).

### Margin Adjustment in the Instance Space

For a given multi-instance bag \(_{i}=\{_{i,1},_{i,2},,_{i,n_{i}}\} ^{d n_{i}}\) comprising \(n_{i}\) instances, we utilize a feature extractor \(\) to learn instance-level feature representations, which is defined as follows:

\[_{i}=(_{i})=\{_{i,1},_{i,2},,_{i,n_{ i}}\}.\] (1)

Here, \(_{i}^{l n_{i}}\) represents the instance-level feature representation of the multi-instance bag \(_{i}\), and \(_{i,j}\) denotes the feature representation of the \(j\)-th instance in the multi-instance bag \(_{i}\).

The subsequent step involves computing attention scores for each instance. In MIPL, attention scores of all instances are closely distributed during the early stages of training. However, as

Figure 2: The MiplMa framework processes an input comprising the multi-instance bag \(_{i}=\{_{i,1},_{i,2},,_{i,9}\}\) and the candidate label set \(_{i}=\{2,3,5,7\}\), where \(_{d}\) and \(_{m}\) represent the dynamic disambiguation loss and the margin distribution loss, respectively.

training progresses, attention scores for positive instances gradually become higher than those for negative instances . Due to dual inexact supervision, the attention mechanism struggles to differentiate between positive and negative instances during the initial training phases and calculate their corresponding attention scores. As training continues, the attention mechanism gradually assigns more distinct attention scores to positive and negative instances.

Motivated by this observation, we introduce a margin-aware attention mechanism that dynamically adjusts the margin of attention scores to achieve a closer alignment with the model's training process. The computation of attention scores is given by:

\[_{i}=(^{}((_{1 }^{}_{i})(_{2}^{}_{i} ))/^{(t)}),\] (2)

where \(^{}\), \(_{1}^{}\), and \(_{2}^{}\) are learnable parameters. \(()\) and \(()\) are the hyperbolic tangent and sigmoid functions, respectively. The operator \(\) denotes element-wise multiplication, and \(^{(t)}\) denotes the _temperature parameter_ of the margin-aware attention mechanism. Specifically, in the early training stages, a larger temperature parameter is employed to smooth the distribution of attention scores, preventing the attention mechanism from assigning high scores to instances that are not unequivocally identified as positive or negative. In the later training stages, a smaller temperature parameter is used to sharpen the distribution of attention scores, thereby widening the gap between attention scores for positive and negative instances. Consequently, throughout the training process, the temperature parameter at the \(t\)-th epoch is dynamically represented as follows:

\[^{(t)}=\{_{m},^{(t-1)}*0.95\},\] (3)

where \(_{m}\) and \(^{(t-1)}\) represent the minimum temperature and the temperature at the \((t-1)\)-th epoch, respectively. Therefore, Eq. (3) describes an annealing process for the temperature parameter \(^{(t)}\).

For multi-instance bags with varying numbers of positive instances, the distribution of attention scores exhibits variations. Consequently, different multi-instance bags require varying temperature parameters. To address this issue, we introduce the following _normalization operations_ for the attention scores:

\[_{i}^{}=_{i}-}_{i}}{^{n_{i} }(a_{i,j}-_{i})^{2}/(n_{i}-1)}},\] (4)

where \(_{i}=}_{j=1}^{n_{i}}a_{i,j}\) is the mean value of the attention score \(_{i}\) and \(}_{i}=[_{i},_{i},,_{i}]^{1  n_{i}}\). Subsequent to obtaining normalized attention scores, we aggregate the instance-level feature representations to compose the bag-level feature representation \(_{i}^{l}\) in the following manner:

\[_{i}=_{i}_{i}^{}.\] (5)

We now discuss the theoretical properties of the proposed margin-aware attention mechanism. Based on the definitions of the permutation and permutation invariance (Appendix A), the margin-aware attention mechanism can be seen as the operator \(\). Then, we have the following theorem:

**Theorem 1**.: _The margin-aware attention mechanism is permutation invariant._

Theorem 1 demonstrates that the margin-aware attention mechanism remains unaffected by the order of instances within multi-instance bags. This property is crucial for algorithms that handle set inputs [23; 4]. The proof is provided in Appendix A.

### Margin Adjustment in the Label Space

With the aggregated bag-level feature representation, we utilize a classifier that synergizes dynamic disambiguation loss and margin distribution loss to identify the true label.

The aim of our _dynamic disambiguation loss_ is to progressively identify the true labels by calculating the classification loss, as illustrated below:

\[_{}=-_{i=1}^{m}_{c_{i}}p_ {i,c}^{(t)}(_{i,c}^{(t)}),\] (6)where \(p_{i,c}^{(t)}\) and \(_{i,c}^{(t)}\) represent the weight and predicted probability, respectively, on the \(c\)-th class at the \(t\)-th iteration. This weight represents the probability that the corresponding candidate label is the true label, which is initialized as follows:

\[p_{i,c}^{(0)}=\{_{i}|}&c _{i},\\ 0&.\] (7)

where \(||\) represents the set cardinality. In the \(t\)-th epoch, we update the weight as:

\[p_{i,c}^{(t)}=\{^{(t)}p_{i,c}^{(t-1)}+(1- ^{(t)})_{i,c}^{(t)}}{_{c^{}_{i}}_ {i,c^{}}^{(t)}}&c_{i},\\ 0&.\] (8)

where \(^{(t)}=(T-t)/T\) is a tuning parameter used to balance the update speed of the weight, and \(T\) is the maximum number of training epochs.

The dynamic disambiguation loss adjusts the classifier's predicted probabilities for the candidate labels, without affecting the probabilities assigned to non-candidate labels. As illustrated in Figure 1(d), this circumstance may result in the classifier assigning its highest predicted probability to a non-candidate label instead of a candidate label, i.e., margin violations. To mitigate potential issues in model generalization, it is crucial to maintain a significant margin between the highest predicted probabilities for the candidate and non-candidate labels. Therefore, we propose the _margin loss_ to maximize the margin between the highest predicted probability on the candidate label set and on the non-candidate label set, as shown below:

\[_{}=_{i=1}^{m}\{1-(_{c_{i }}_{i,c}^{(t)}-_{_{i}}_{i,}^{(t) })\},\] (9)

where \(_{c_{i}}_{i,c}^{(t)}\) and \(_{_{i}}_{i,}^{(t)}\) are the highest predicted probabilities on the candidate label set and the non-candidate label set, respectively. However, only considering the mean margin cannot effectively address margin violations, thus affecting the performance. Some recent studies have shown that the model performance can be enhanced by maximizing the margin mean and minimizing the margin variance simultaneously [24; 25; 26]. Therefore, we employ two statistics of the margins i.e., the margin mean and the margin variance, to adjust the margin distribution. Specifically, we can maximize the margin mean and minimize the margin variance between the highest predicted probability on the candidate label set and on the non-candidate label set simultaneously by minimizing the following _margin distribution loss_:

\[_{}=\{_{1},_{2},,_{m}\} }{1-\{_{1},_{2},,_{m}\}}},\] (10)

where \(_{i}=\{1-(_{c_{i}}_{i,c}^{(t)}-_{ _{i}}_{i,}^{(t)})\}\) refers to the margin loss of the \(i\)-th multi-instance bag. \(\{\}\) and \(\{\}\) are the mean and the variance of the margin loss, respectively.

During training, the full loss is represented as the weighted sum of the dynamic disambiguation loss and the margin distribution loss, as expressed below:

\[=_{}+_{},\] (11)

where \(\) represents a hyperparameter.

## 3 Experiments

### Experimental Configurations

#### 3.1.1 Datasets

Following the experimental setup of DeMipL , we utilize four MIPL benchmark datasets and one real-world dataset. The four benchmark datasets encompass MNIST-mipL, FMNIST-mipL, Birdson-mipL, and SIVAL-mipL, spanning diverse application domains such as image analysis and biology [27; 28; 29; 30]. Additionally, the real-world CRC-mipL dataset is annotated by crowdsourced workers for colorectal cancer classification. The previous works [21; 22] employ four distinct types of multi-instance features and consists of four sub-datasets: CRC-mipt-Row (C-Row), CRC-mipt-SBN (C-SBN), CRC-mipt-KMeansSeg (C-KMeans), and CRC-mipt-SIFT (C-SIFT). These multi-instance features are generated via four image bag generators , i.e., Row, single blob with neighbors (SBN), k-means segmentation (KMeansSeg), and scale-invariant feature transform (SIFT), respectively. Besides these multi-instance features, we are the first to employ the ResNet  to learn the multi-instance features of CRC-mipt dataset. Specifically, we partition each image into \(N\) non-overlapping patches, treating each patch as an instance. Subsequently, the ResNet-34 is employed to acquire feature representations for each patch, resulting in feature representations of dimension \(1000\) for each patch. In our experiments, the \(N\) is \(16\) and \(25\), and the resulting datasets are CRC-mipt-ResNet-34-16 (C-R34-16) and CRC-mipt-ResNet-34-25 (C-R34-25).

The characteristics of the dataset are detailed in Table 1. It provides the number of multi-instance bags and total instances, denoted as _#bag_ and _#ins_, respectively. Furthermore, we employ _max. #ins_, _min. #ins_, and _avg. #ins_ to express the maximum, minimum, and average instance count within all bags. The dimensionality of each instance-level feature representation is indicated by _#dim. #class_ and _avg. #CLs_ denote the length of the label space and the average length of candidate label sets, respectively. For a comprehensive performance assessment, we vary the number of false positive labels on the benchmark datasets, represented as \(r(|_{i}|=r+1)\).

#### 3.1.2 Comparative Algorithms

We conduct a comprehensive comparison of MiptMa with a wide variety of baselines, covering MIPL, PLL, and MIL algorithms. For MIPL algorithms, we compare with MiptSp, DeMipL, and ElMipL. In our evaluation, we incorporate seven PLL algorithms, featuring five deep-learning-based approaches: Proden, Rc, Lws, Cavl, and Pop, one feature-aware disambiguation algorithm, Pl-aggd, and two margin-based algorithms, M3pl and Pl-svm. Furthermore, our comparison encompasses seven MIL algorithms. Three of the MIL algorithms are Gaussian processes-based: Vwsgp, Vgpmil, and Lm-Vgpmil. Additionally, a variational autoencoder-based algorithm, Mivae, and three attention-based algorithms: Atten, Atten-Gate, and Loss-Atten, are included.

The deep-learning-based PLL algorithms [33; 34; 35; 11] can be equipped with either the linear model or multi-layer perceptrons (MLP) as backbone networks. Results obtained from the linear model are presented in the main body of the paper, while additional experiment results are detailed in the Appendix C. Parameters for all compared baselines have been meticulously tuned, drawing from recommendations in the original literature or refined through our pursuit of improved performance.

#### 3.1.3 Implementation

We implement MiptMa using PyTorch  and conduct training with a single NVIDIA Tesla V100 GPU. Employing the stochastic gradient descent (SGD) optimizer, we set the momentum value to \(0.9\) with a weight decay of \(0.0001\). To learn the instance-level features, we employ a two-layer convolutional neural network and a fully connected network for the MNIST-mipt and FMNIST-mipt datasets. Since the features of the Birdsong-mipt, and SIVAL-mipt datasets are preprocessed, we only employ a fully connected network to learn the feature representations. For the CRC-mipt dataset, the feature extractor is one of the four image bag generators or ResNet-34, followed by a fully

   Dataset & \#bag & \#ins & max. \#ins & min. \#ins & avg. \#ins & \#dim & \#class & avg. \#CLs \\  MNIST-mipt & 500 & 20664 & 48 & 35 & 41.33 & 784 & 5 & 2, 3, 4 \\ FMNIST-mipt & 500 & 20810 & 48 & 36 & 41.62 & 784 & 5 & 2, 3, 4 \\ Birdsong-mipt & 1300 & 48425 & 76 & 25 & 37.25 & 38 & 13 & 2, 3, 4 \\ SIVAL-mipt & 1500 & 47414 & 32 & 31 & 31.61 & 30 & 25 & 2, 3, 4 \\  C-Row & 7000 & 56000 & 8 & 8 & 8 & 9 & 7 & 2.08 \\ C-SBN & 7000 & 63000 & 9 & 9 & 9 & 15 & 7 & 2.08 \\ C-KMeans & 7000 & 30178 & 6 & 3 & 4.311 & 6 & 7 & 2.08 \\ C-SIFT & 7000 & 175000 & 25 & 25 & 25 & 128 & 7 & 2.08 \\ C-R34-16 & 7000 & 112000 & 16 & 16 & 16 & 1000 & 7 & 2.08 \\ C-R34-25 & 7000 & 175000 & 25 & 25 & 25 & 1000 & 7 & 2.08 \\   

Table 1: Characteristics of the benchmark and real-world MIPL datasets.

connected network. The initial learning rate is chosen from the set \(\{0.01,0.05\}\) and coupled with a cosine annealing technique. We set the number of epochs to \(100\) for benchmark datasets and \(200\) for the CRC-mipl dataset. The weight of the margin distribution loss is chosen from the set \(\{0.01,0.05,0.1,0.5,1,3,5\}\) for all datasets. For the annealing process of the temperature parameter, the initial temperature parameter \(^{(0)}=5\). Additionally, \(_{m}=0.1\) and \(_{m}=0.5\) are used for benchmark datasets and the CRC-mipl dataset, respectively. The dataset partitioning method aligns with that of DeMipl and EliMipl. We execute ten random train/test splits, maintaining a ratio of \(7:3\). Mean accuracies and standard deviations from these ten runs are reported. The code of MiplMa can be found at https://github.com/tangw-seu/MIPLMA.

### Comparison with MIPL and PLL Algorithms

Since PLL algorithms can not directly handle the multi-instance bags, we utilize two data degradation strategies: the _Mean_ strategy and the _MaxMin_ strategy . The former computes the average feature values across all instances within a bag for producing a bag-level feature representation. The latter identifies both the maximum and minimum feature values for each dimension among instances within a multi-instance bag and concatenates these values to form a bag-level feature representation.

#### 3.2.1 Results on the Benchmark Datasets

Table 2 provides a comprehensive comparison of the results achieved by MiplMa, three MIPL algorithms (EliMipl, DeMipl, and MiplGp), five deep-learning-based PLL algorithms (Proden, Rc, Lws, Cavl, and Pop) with linear model, and the feature-aware disambiguation PLL algorithm (Pl-aggd). The evaluation is conducted on benchmark datasets with varying numbers of false positive labels (\(r\{1,2,3\}\)).

Notably, MiplMa consistently exhibits higher average accuracy than the three MIPL algorithms in \(33\) out of \(36\) cases. For the methods based on the embedding space paradigm, MiplMa demonstrates superior performance compared to EliMipl and DeMipl in \(21\) out of \(24\) cases. Compared to MiplGp that follows the instance space paradigm, MiplMa achieves higher average accuracies than it in all cases. Specifically, on the SIVAL-mipl dataset, the average accuracies of MiplGp consistently

   Algorithm & \(r\) & MNIST-mipl & FMNIST-mipl & Birdong-mipl & SIVAL-mipl \\   & 1 & 985\(\)0.10 & **915\(\)0.106** & **776\(\)0.200** & **703\(\)0.206** \\  & 2 & 979\(\)0.14 & **867\(\)0.28** & **762\(\)0.15** & **468\(\)0.31** \\  & 3 & **749\(\)103** & 654\(\)0.055 & **746\(\)0.13** & **627\(\)0.24** \\   & 1 & **992\(\)0.007** & 903\(\)0.18 & 771\(\)0.18 & 675\(\)0.22 \\  & 2 & **987\(\)0.10** & 845\(\)0.026 & 745\(\)0.15 & 616\(\)0.25 \\  & 3 & 748\(\)1.144 & **702\(\)0.055** & 717\(\)0.17 & 600\(\)0.29 \\   & 1 & 976\(\)0.008 & 881\(\)0.021 & 7.44\(\)0.16 & 633\(\)0.041 \\  & 2 & 943\(\)0.27 & 823\(\)0.28 & 7.01\(\)0.24 & 554\(\)0.51 \\  & 3 & 709\(\)0.088 & 657\(\)0.025 & 696\(\)0.024 & 503\(\)0.018 \\   & 1 & 949\(\)0.16 & 847\(\)0.030 & 7.16\(\)0.26 & 669\(\)0.19 \\  & 2 & 817\(\)0.30 & 791\(\)0.27 & 672\(\)0.15 & 613\(\)0.26 \\  & 3 & 621\(\)0.064 & 670\(\)0.052 & 625\(\)0.15 & 569\(\)0.32 \\   & Mean & MaxMin & Mean & MaxMin & Mean & MaxMin & Mean \\   & 1 & 605\(\)0.23 & 508\(\)0.24 & 697\(\)0.42 & 424\(\)0.045 & 296\(\)0.014 & 387\(\)0.014 & 219\(\)0.014 & 316\(\)0.019 \\  & 2 & 481\(\)0.36 & 400\(\)0.037 & 573\(\)0.266 & 377\(\)0.040 & 272\(\)0.19 & 357\(\)0.012 & 1.84\(\)0.014 & 287\(\)0.024 \\  & 3 & 2.83\(\)0.288 & 345\(\)0.48 & 345\(\)0.270 & 309\(\)0.088 & 211\(\)0.013 & 336\(\)0.012 & 1.66\(\)0.017 & 250\(\)0.018 \\   & 1 & 658\(\)0.031 & 519\(\)0.28 & 753\(\)0.42 & 731\(\)0.027 & 362\(\)0.15 & 390\(\)0.014 & 279\(\)0.011 & 306\(\)0.023 \\  & 2 & 598\(\)0.033 & 469\(\)0.035 & 664\(\)0.028 & 666\(\)0.027 & 335\(\)0.011 & 371\(\)0.013 & 258\(\)0.017 & 2.88\(\)0.021 \\  & 3 & 392\(\)0.033 & 380\(\)0.488 & 401\(\)0.063 & 524\(\)0.034 & 328\(\)0.098 & 363\(\)0.010 & 237\(\)0.020 & 267\(\)0.020exceed those of DeMipl. However, the average accuracies of MiplMa surpass all algorithms on the SIVAL-mipl dataset, thus highlighting the effectiveness of MiplMa.

Additionally, MiplMa significantly outperforms PLL algorithms in all cases. For relatively simple datasets such as MNIST-mipl and FMNIST-mipl, the PLL algorithms demonstrate satisfactory performance. However, with the increasing complexity of datasets, as observed in Birdsong-mipl and SIVAL-mipl, the effectiveness of the PLL algorithms noticeably diminished. On MNIST-mipl and FMNIST-mipl, the Mean strategy generally outperforms the MaxMin strategy. Conversely, on Birdsong-mipl and SIVAL-mipl, the MaxMin strategy tends to yield superior results in most cases compared to the Mean strategy. Hence, the two data degradation strategies do not uniformly outperform each other but have their respective advantages. The selection of the degradation strategy is dependent on the characteristics of the dataset. For simpler datasets, a straightforward Mean strategy may suffice, while for more complex datasets, a sophisticated MaxMin strategy may be preferable.

#### 3.2.2 Results on the Real-World Datasets

Table 3 presents a detailed comparison of results on the CRC-mipl dataset. Our method, MiplMa, demonstrates superior performance in all \(11\) cases when compared to EliMipl, DeMipl, and MiplGp. In terms of the PLL algorithm, MiplMa also achieves superior accuracies in all cases. While the PLL algorithms yield satisfactory results on relatively simple datasets like CRC-mipl-Row and CRC-mipl-sbn, their performances noticeably deteriorate when handling more complex datasets such as CRC-mipl-KMeans and CRC-mipl-sift.

Moreover, both MiplMa and EliMipl demonstrate significantly better performance on the CRC-mipl-kMeans and CRC-mipl-sift datasets compared to the CRC-mipl-Row and CRC-mipl-sbn datasets. However, this trend is reversed for MiplGp and the PLL algorithms. We attribute this discrepancy to the incapacity of these algorithms to effectively model complex features. Particularly, the limitations of the PLL algorithms become more apparent when dealing with complex MIPL data. Therefore, there is an urgent need to devise more effective MIPL algorithms.

#### 3.2.3 Results of the CRC-mipl Dataset with Deep Features

Tang et al.  have introduced the CRC-mipl dataset, extracting multi-instance features using four hand crafted image bag generators . Both DeMipl and EliMipl were evaluated using these multi-instance features in the literature. In this study, we investigate CRC-mipl with neural network generated features and employ ResNet to learn deep multi-instance features from the CRC-mipl dataset. The resulting datasets are referred to as C-R34-16 and C-R34-25.

Table 4 illustrates the classification accuracies of MiplMa, EliMipl, and DeMipl on the CRC-mipl dataset with deep multi-instance features. From the experimental results, two key observations emerge: (a) ResNet-34-based features outperform those generated by image bag generators in terms of classification performance. (b) When learning multi-instance features with ResNet-34, dividing an image into \(25\) instances results in a more discriminative feature representation compared to using \(16\) instances.

   Algorithm & C-R34-16 & C-R34-25 \\  MiplMa & **.631\(\).008** & **.685\(\).011** \\ EliMipl &.628\(\).009 &.663\(\).009 \\ DeMipl &.625\(\).008 &.650\(\).010 \\   

Table 4: The classification accuracies (mean\(\)std) on the CRC-mipl dataset with deep multi-instance features.

   Algorithm &  &  &  &  \\  MiplMa & **.444\(\).010** & **.526\(\).009** & **.557\(\).010** & **.553\(\).009** \\ EliMipl &.433\(\).008 &.509\(\).007 &.546\(\).012 & &.540\(\).010 \\ DeMipl &.408\(\).010 &.486\(\).014 &.521\(\).012 &.532\(\).013 \\ MiplGp &.432\(\).005 &.335\(\).006 &.329\(\).012 & &  \\   & Mean & MaxMin & Mean & MaxMin & Mean & MaxMin & Mean & MaxMin \\  Proden &.365\(\).009 &.401\(\).007 &.392\(\).008 &.447\(\).011 &.233\(\).018 &.265\(\).027 &.334\(\).029 &.291\(\).011 \\ RC &.214\(\).011 &.227\(\).012 &.424\(\).012 &.338\(\).010 &.226\(\).009 &.208\(\).007 &.209\(\).007 &.246\(\).008 \\ Lws &.291\(\).010 &.299\(\).008 &.310\(\).006 &.382\(\).009 &.232\(\).008 &.247\(\).005 &.270\(\).007 &.230\(\).007 \\ Cavl &.312\(\).043 &.368\(\).054 &.364\(\).066 &.503\(\).025 &.286\(\).062 &.311\(\).038 &.329\(\).033 &.274\(\).018 \\ Pop &.383\(\).010 &.393\(\).015 &.439\(\).009 &.438\(\).010 &.385\(\).016 &.279\(\).016 &.326\(\).013 &.278\(\).040 \\ PL-aggd &.412\(\).008 &.460\(\).008 &.480\(\).005 &.524\(\).008 &.355\(\).008 &.434\(\).009 &.363\(\).012 &.285\(\).009 \\   

Table 3: The classification accuracies (mean\(\)std) of MiplMa and comparative algorithms on the real-world datasets. – means unavailable due to computational limitations.

In summary, feature representations learned by the deep feature extractor ResNet-34 exhibit higher discriminative capacity compared to those generated by image bag generators. Our model consistently achieves the highest classification accuracy among these three MIPL algorithms, especially on the C-R34-25 dataset. These observations suggest that our model not only achieves the highest classification accuracy on traditional features but also handles deep features better.

### Effectiveness of the Margin Adjustment

To assess the effectiveness of margin adjustment, we introduce three variants of MiplMa. MiplMais denotes the margin adjustment of attention scores exclusively, with \(\) in Eq. (11) set to \(0\). Mipl-Malab signifies the margin adjustment of predicted probabilities only, where \(^{(t)}\) in Eq. (2) is assigned \(1\) for \(t=1,2,,T\). Mipl-WoMa indicates no margin adjustments of attention scores or predicted probabilities, with \(=0\) and \(^{(t)}=1\) for \(t=1,2,,T\).

Figure 3 demonstrates that MiplMa consistently outperforms its three variants, proving that margin adjustment in the instance and label spaces can significantly enhance model performance. Additionally, adjusting the margin in the label space yields better results than in the instance space, validating the effectiveness of our proposed margin distribution loss. From another perspective, adjusting the margin of predicted probabilities directly impacts classification accuracies, whereas adjusting the margin of attention scores affects the bag-level feature representations, thereby influencing classification accuracies. Consequently, Mipl-MaLab demonstrates superior performance than Mipl-MaIns. By simultaneously adjusting the margins in both the instance and label spaces, i.e., MiplMa, optimal results can be achieved. This underscores the effectiveness of our margin adjustment strategy in dealing with the inexact supervision of MIPL.

### Margin Adjustment for MIL and PLL Algorithms

In MiplMa, the margin adjustments for attention scores and predicted probabilities reduce the supervision inexactness in the instance space and the label space, respectively. MIPL is a generalized framework of MIL and PLL. Therefore, this raises a pertinent question: can margin adjustment enhance the performance of MIL and PLL algorithms?

To answer this question, we propose a MIL algorithm named MaAm that is a simplified variant of MiplMa. We compare MaAm with two classical MIL methods incorporating attention mechanisms, namely Atten and Atten-Gate, on the MNIST-mipL (MIL) and FMNIST-mipL (MIL) datasets. During training, we use only the features of multi-instance bags and their corresponding bag-level true labels. The parameters of MaAm for the two datasets are as follows: learning rates of \(0.005\) for MNIST-mipL and \(0.01\) for FMNIST-mipL. Additionally, \(^{(0)}=5\) and \(_{m}=0.1\) for both datasets. Table 5 presents the classification accuracies over ten runs, indicating that MaAm outperforms both Atten and Atten-Gate, particularly on the FMNIST-mipL dataset. These results demonstrate the effectiveness of MaAm, confirming its superior performance.

   Algorithm & \(q=0.1\) & \(q=0.3\) & \(q=0.5\) & \(q=0.7\) & \(q=0.9\) \\  Proden-Ma & **.932\(\).001** & **.926\(\).002** & **.914\(\).002** & **.892\(\).001** & **.816\(\).008** \\ Proden &.906\(\).002 &.900\(\).001 &.884\(\).005 &.876\(\).010 &.772\(\).017 \\   

Table 6: The classification accuracies (mean\(\)std) of Proden-Ma and Proden on the Kuzushiji-MNIST dataset with varying flipping probability \(q\).

Figure 3: The classification accuracies (mean and std) of MiplMa with the three variants on the SIVAL-mipL dataset (\(r\{1,2,3\}\)).

Moreover, we equip the PLL algorithm Proden with the margin distribution loss, resulting in the variant Proden-Ma. Table 6 presents the classification accuracies of Proden-Ma and Proden on the Kuzushiji-MNIST dataset with varying flipping probability \(q\{0.1,0.3,0.5,0.7,0.9\}\). The only difference between Proden-Ma and Proden lies in that Proden-Ma includes the margin distribution loss with the weight of \(1\). We employ MLP as the backbone network for both Proden-Ma and Proden, and keep all other parameters consistent. Experimental results indicate that Proden-Ma outperforms Proden across all scenarios. Notably, under higher disambiguation difficulty, i.e., \(q=0.9\), the superiority of Proden-Ma is more pronounced.

In summary, adjusting the margins of attention scores improves classification performance for MIL algorithms. Similarly, margin adjustment in the label space enhances the performance of PLL algorithms, particularly in challenging disambiguation scenarios.

## 4 Conclusion

This paper investigates the margin adjustments in both the instance space and the label space for MIPL. We propose MipMa, which incorporates a margin-aware attention mechanism and a margin distribution loss to adjust the margins for attention scores and predicted probabilities, respectively. Experimental results on the benchmark and real-world datasets illustrate the superiority of our proposed MipMa algorithm over a diverse set of baselines, encompassing MIPL, PLL, and MIL algorithms. Specifically, MipMa achieves superior performances compared to baselines in \(96.4\%\) of cases. These results underscore the effectiveness and significance of our margin adjustment strategy.

However, MipMa has several limitations. First, similar to other attention-based MIL and MIPL methods, it cannot process multiple multi-instance bags simultaneously. Second, MipMa demonstrates a slight overfitting problem on the relatively simple MNIST-mipt dataset. Third, MipMa is not suitable for instance-level classification tasks. In the future, we will delve into designing MIPL algorithms capable of instance-level classification and parallel algorithms that can handle multiple multi-instance bags concurrently.