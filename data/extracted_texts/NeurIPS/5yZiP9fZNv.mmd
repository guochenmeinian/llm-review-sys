# Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs

Kevin Course

University of Toronto

kevin.course@mail.utoronto.ca

&Prasanth B. Nair

University of Toronto

prasanth.nair@utoronto.ca

###### Abstract

We consider the problem of inferring latent stochastic differential equations (SDEs) with a time and memory cost that scales independently with the amount of data, the total length of the time series, and the stiffness of the approximate differential equations. This is in stark contrast to typical methods for inferring latent differential equations which, despite their constant memory cost, have a time complexity that is heavily dependent on the stiffness of the approximate differential equation. We achieve this computational advancement by removing the need to solve differential equations when approximating gradients using a novel amortization strategy coupled with a recently derived reparametrization of expectations under linear SDEs. We show that, in practice, this allows us to achieve similar performance to methods based on adjoint sensitivities with more than an order of magnitude fewer evaluations of the model in training.

## 1 Introduction

Recent years have seen the rise of continuous time models for dynamical system modeling . As compared to traditional autoregressive style models , continuous time models are useful because they can deal with non-evenly spaced observations, they enable multilevel/hierarchical and adaptive prediction schemes, and because physics is (mostly) done in continuous time. For example, recent developments in inferring continuous time differential equations from data has been met by a flurry of work in endowing models with physics informed priors .

Despite their advantages, continuous time models remain significantly more computationally challenging to train than their autoregressive counterparts due to their reliance on adjoint methods for estimating gradients. Adjoint methods introduce a significant computational burden in training because they require solving a pair of initial value problems to estimate gradients. Solving such initial value problems as a part of an iterative optimization procedure is computationally demanding for the following reasons:

1. Gradient based updates to models of differential equations can cause them to become extremely stiff. This will have the effect of causing the cost per iteration to explode mid-optimization.
2. With the exception of parareal methods , differential equation solvers are fundamentally _iterative sequential_ methods. This makes them poorly suited to being parallelized on modern parallel computing hardware.

In accordance with such challenges a number of methods have been introduced to speed up training of continuous time models including regularizing dynamics  and replacing ordinary differential equation (ODE) solvers with integration methods where possible . Despite the computational advancements brought about by such innovations, continuous time models remain expensive to train in comparison to discrete time models.

In addition to these computational challenges, it is well-known that adjoint methods suffer from stability issues when approximating gradients of time averaged quantities over long time intervals for chaotic systems .

In the current work, we present a memory and time efficient method for inferring nonlinear, latent stochastic differential equations (SDEs) from high-dimensional time-series datasets. In contrast to standard approaches for inferring latent differential equations that rely on adjoint sensitivities [1; 11; 12], our approach removes the requirement of solving differential equations entirely. We accomplish this advancement by coupling a novel amortization strategy with a recently derived reparametrization for expectations under Markov Gaussian processes . We show that our approach can be used to approximate gradients of the evidence lower bound used to train latent SDEs with a time and memory cost that is independent of the amount of data, the length of the time series, and the stiffness of the approximate differential equations. The asymptotic complexity for our approach is compared to well-known methods from the literature in Table 1. We note that our method has a constant cost that is chosen by the user. Moreover, we will show that our method is embarrassingly parallel (i.e. all evaluations of the model can be performed in parallel over each iteration) whereas, we reiterate, differential equation solvers are iterative sequential methods.

The applications of our method span various standard generative modeling tasks, such as auto-encoding, denoising, inpainting, and super-resolution , particularly tailored for high-dimensional time-series. Crucially, the computational efficiency of our approach not only enables the allocation of more computational resources towards hyperparameter tuning but also democratizes access to state-of-the-art methods by making them feasible to train on lower performance hardware.

In the next section we provide a description of the theory underpinning our work with the main result of a stochastic, unbiased estimate for gradients appearing in Lemma 1. In Section 4 we provide a number of numerical studies including learning latent neural SDEs from video and performance benchmarking on a motion capture dataset. Notably we show that we are able to achieve comparable performance to methods based on adjoints with more than **one order of magnitude** fewer evaluations of the model in training (Section 4.1). We also demonstrate that our approach does not suffer from the numerical instabilities that plague adjoint methods for long time-series with chaotic systems (Section 4.2). Finally, we close with a discussion of the limitations of our approach as well as some suggestions for future work. All code is available at github.com/coursekevin/arlatentsde.

## 2 Method

### Problem description

Consider a time-series dataset \(=\{(x_{i},t_{i})\}_{i=1}^{N}\), where \(t_{i}\) is the time stamp associated with the observation, \(x_{i}^{D}\). For example \(x_{i}\) may be an indirect observation of some underlying dynamical system, a video-frame, or a snapshot of a spatio-temporal field. We assume that each observation was generated via the following process: first a latent trajectory, \(z(t)\), is sampled from a general,

   Method & Time & Memory \\  Deterministic adjoints (Neural ODE)  & \((J)\) & \((1)\) \\ Stochastic adjoints  & \((J J)\) & \((1)\) \\ Backprop through solver  & \((J)\) & \((J)\) \\ Amortized reparametrization (ours) & \((R)\) & \((R)\) \\   

Table 1: Asymptotic complexity comparison for approximating gradients. Units are given by the number of evaluations of the differential equation (gradient field for ODEs or drift and diffusion function for SDEs). Here \(J\) is the number of _sequential_ evaluations and \(R\) is the number of _parallel_ evaluations. \(J\) is adaptively chosen by the differential equation solver and is a function of the stiffness of the differential equation meaning it can change (and possibly explode) while optimizing. In contrast, \(R\) is a fixed constant used to control the variance of gradient approximations. While we could choose \(R=1\) and would still arrive with unbiased approximations for gradients, in practice we found choosing \(R 10^{2}\) worked well for the problems we considered.

nonlinear_ SDE with time-dependent diffusion,

\[dz=f_{}(t,z)dt+L_{}(t)d,\] (1)

with initial condition \(p_{}(z_{0})\) and then each \(x_{i}\) is generated from the conditional distribution \(p_{}(x z(t_{i}))\) where \(z(t_{i})\) is the realization of the latent trajectory at time stamp \(t_{i}\). Here \(f_{}:^{d}^{d}\) is called the drift function, \(L_{}:^{d d}\) is called the dispersion matrix, and \(\) denotes Brownian motion with diffusion matrix \(\). We will model both the drift function of the SDE and the conditional distribution using neural networks in this work. This combination of SDE and conditional distribution define the generative model that we wish to infer.

Like in the standard generative modeling setting, the "true" parameters defining the latent SDE and the conditional likelihood, as well as the specific realization of the latent state, remain unknown. In addition, the posterior over the latent state at a point in time, \(p_{}(z(t))\), is intractable. Our objectives are two-fold, we wish to: (i) infer a likely setting for the parameters, \(\), that is well-aligned with the observed data and (ii) infer a parametric model for the posterior over the latent state at a particular point in time as a function of a small window of the observations, for example \(q_{}(z(t) x_{i},x_{i+1},,x_{i+M}) p_{}(z(t) )\) for \(t[t_{i},t_{i+M}]\) and \(1 M<<N\). This latent variable model is depicted in Figure 1. In this work we will tackle this problem statement using the machinery of stochastic variational inference .

Before proceeding with an explanation of our approach, it is worthwhile taking a moment to consider why assuming the latent state is a realization of a SDE, as opposed to an ordinary differential equation (ODE) with random initial conditions , merits the additional mathematical machinery. First, there is a long history in using SDEs in the physical sciences to model systems (even deterministic systems) that lack predictability due to super-sensitivity to parameters and or initial conditions . One reason for the preference towards this modeling paradigm is that deterministic ODEs with random initial conditions only permit uncertainty to enter in their initial condition. This means that we are assuming that all randomness which may affect the latent trajectory at all future points in time are precisely encoded in the uncertainty in the initial condition. In contrast, SDEs make the less restrictive assumption that uncertainty accumulates over time.

### Evidence lower bound

As is the case with standard latent variable models, training proceeds by specifying approximate posteriors over latent variables (in this case the latent state, \(z(t)\)) and then minimizing the Kullback-Leibler (KL) divergence between the approximate and true posterior. An added complication in our specific case comes from the fact that the latent state is defined by a stochastic process rather than a random-vector as is more typical. While it is possible to choose more general approximate posteriors , in this work we make the choice to approximate the posterior over the latent state as a Markov Gaussian Process (MGP) defined by the linear SDE,

\[dz=(-A_{}(t)z+b_{}(t))dt+L_{}(t)d,\] (2)

with Gaussian initial condition, \(z(t_{0})(m_{0},S_{0})\) where \(m_{0}^{d}\) and \(S_{0}^{d d}\) is a symmetric positive definite. Here \(A_{}:^{d d}\) and \(b_{}:^{d}\) are symmetric matrix and vector-valued functions of time, respectively. Before proceeding, it is worth emphasizing that this choice of approximate posterior is not as restrictive as it may appear since it is only used to approximate the _posterior_ (i.e. the latent state given the observations \(p(z(t))\) for \(t[t_{1},t_{N}]\)). When forecasting

Figure 1: The solid lines indicate the data generating process that depends on the parameters, \(\). The dashed lines indicate the approximate variational posterior that depends on the parameters, \(\).

beyond the data window, we will use the nonlinear SDE in (1). In this way, the approximate posterior primarily serves as a useful intermediary in training the generative model rather than the end-product.

For our purposes, MGPs are useful because the marginal distribution \(q_{}(z(t))=(m_{}(t),S_{}(t))\) (i.e. the distribution of the latent state at time \(t\)) is a Gaussian whose mean and covariance are given by the solution to the following set of ODEs ,

\[_{}(t)&=-A_{}(t)m_{ }(t)+b_{}(t),\\ _{}(t)&=-A_{}(t)S_{}(t)-S_{}( t)A_{}(t)^{T}+L_{}(t) L_{}(t)^{T},\] (3)

where \(m(0)=m_{0}\) and \(S(0)=S_{0}\).

Using the reparametrization trick from , the evidence lower bound (ELBO) can be written as,

\[(,)=&_{i=1}^{ N}_{z(t_{i}) q_{}(z(t))}[ p_{}(x_{i} z(t_{i})) ]\\ &-_{0}^{T}_{z(t) q_{}(z(t))} [||r_{,}(z(t),t)||^{2}_{C_{}(t)}]\,dt,\] (4)

where

\[r_{,}(z(t),t)= B(t)(m_{}(t)-z(t))+_{}(t)-f_{}(z(t),t),\] (5)

\(C_{}(t)=(L_{}(t) L_{}(t)^{T})^{-1}\), \(B(t)=^{-1}((S_{}(t) S_{}(t))^{-1}(C_{ }(t)^{-1}-_{}(t)))\), \(\) indicates the Kronecker sum, \(:^{d d}^{d^{2}}\) maps a matrix into a vector by stacking columns, and \(^{-1}:^{d^{2}}^{d d}\) converts a vector into a matrix such that \(^{-1}((B))=B\  B^{d d}\). See Appendices A and B for a detailed derivation. We note that computing the residual, \(r_{,}\), scales linearly in the dimension of the state so long as \(S_{}(t)\) and \(C_{}(t)\) are diagonal. To ensure our approach remains scalable, we will make this assumption throughout the remainder of this work. In this case, we have

\[B(t)=S_{}(t)^{-1}(C_{}(t)^{-1}-_{}(t)).\] (6)

Often we may wish to place additional priors onto a subset of the generative model parameters, \(\), and infer their posterior using stochastic variational inference as well. In this case we add the KL-divergence between the approximate posterior and prior onto the ELBO, \(KL(q_{}() p())\) and rewrite all expectations with respect to \(q_{}(z(t))\) and \(q_{}()\); details are provided in Appendix C.

Remark 1:Despite having defined the approximate posterior in terms of an SDE with parameters \(A_{}\) and \(b_{}\), the ELBO only depends on the mean and covariance of the process at a particular point in time, \(m_{}\) and \(S_{}\). For this reason we can parametrize \(m_{}\) and \(S_{}\) directly while implicitly optimizing with respect to \(A_{}\) and \(b_{}\). In addition, we can efficiently compute \(_{}\) and \(_{}\) using automatic differentiation.

Remark 2:Despite the fact that the prior and approximate posterior are SDEs, all expectations in the ELBO are taken with respect to _normal distributions_. Moreover, in contrast to the approach in [20; 21] there are no differential equality constraints - instead we have been left with an integral over the window of observations.

Taken together, these observations allow us to infer the parameters of the generative model (a nonlinear, latent SDE with additive diffusion (1)), without the use of a forward solver.

### Amortization strategy

The implicit assumption in the ELBO in (4) is that the state mean and covariance will be approximated over the _entire_ window of observations. This can pose a serious computational bottleneck with long or complicated time-series. In this section we propose a novel amortization strategy that will allow us to effectively eliminate this cost by requiring that we only approximate the posterior over short partitions of total the data time-window at once.

Rather than attempting to compute and store the posterior over the entire latent trajectory, we will instead construct an approximation to the posterior over a small window of observations as a function of those observations. Consider a reindexing of the dataset by splitting it into \(N/M\) non-overlapping partitions where \(1 M<<N\),

\[ [t_{1},\ t_{2},\ ,t_{M},t_{M+1},,t_{N}\ \ \ ]\] \[ [t_{1}^{(1)},t_{2}^{(1)},,t_{M}^{(1)},t_{1}^{(2)},, \ t_{M}^{(N/M)}]\]

In the case that \(N\) is not evenly divisible by \(M\) we allow the final split to contain less elements. We approximate the latent state over each partition using only the \(M\) observations in each partition, \(q_{}(z(t) x_{1}^{(j)},x_{2}^{(j)},,x_{M}^{(j)}) p(z(t) )\) for \(t[t_{1}^{(j)},t_{1}^{(j+1)}]\). This can be interpreted as a probabilistic encoder over the time interval of the partition of observations. Letting \(t_{1}^{N/M+1} t_{M}^{N/M}\), the ELBO can be compactly rewritten as, \((,)=_{j=1}^{N/M}^{(j)}(,),\) where

\[^{(j)}(,)= _{i=1}^{M}_{q_{}(z(t_{1}^{(j)})|x_{1}^{(j)}, ,x_{M}^{(j)})}[ p_{}(x_{i}^{(j)} z(t_{i}^{(j)}))]\] (7) \[-_{t_{1}^{(j)}}^{t_{1}^{(j+1)}}_{q_{ }(z(t)|x_{1}^{(j)},,x_{M}^{(j)})}[||r_{,}(z,t)||_{C_{ }(t)}^{2}]\,dt.\]

An additional advantage of this amortization strategy is that it allows our approach to scale to multiple trajectories without an increase to the overall computational cost. If there are multiple trajectories, we can reindex each trajectory independently and subsequently sum all sub loss functions.

To reiterate, the probabilistic encoder is a function which takes in \(M\) observations from a particular partition along with a time stamp, \(t\), and outputs a mean vector and covariance matrix as an estimate for the latent state at that particular time. In principle, any function which can transform a batch of snapshots and a time stamp into a mean and covariance could be used as an encoder in our work. In our implementation, we use deep neural networks to encode each \(x_{i}^{(j)}\) using \(i\) where \([x_{1}^{(j)},x_{2}^{(j)},,x_{M}^{(j)}]\) contains some temporal neighbours of \(x_{i}\) into a single latent vector. This approach yields a set of latent vectors associated with each observation in the partition \(h_{i}\) for \(i=1,2,,M\). We then interpolate between each latent vector using a deep kernel based architecture to construct the posterior approximation for any time stamp in the partition; see Appendix D for details. We emphasize this is one choice of encoding architecture that we found convenient, it is straightforward to incorporate an autoregressive or transformer based encoder in our methodology 

An important consideration is the selection of the partition parameter, \(M\). In practice, \(M\) should be large enough so that the assumption of a linear SDE for the approximate posterior is appropriate (i.e. we have enough observations in a partition so that the assumption of a Gaussian process over the latent state is reasonable). For example, as we will see in an upcoming numerical study, in the context of inferring latent SDEs from videos, we will need to choose \(M\) to be large enough so that we can reasonably infer both the position and velocity of the object in the video.

### Reparametrization trick

While the previous sections have demonstrated how to eliminate the need for a differential equation solver by replacing the initial value problem with an integral, in this section we show how the reparametrization trick can be combined with the previously described amortization strategy to construct unbiased gradient approximations for the ELBO with a time and memory cost that scales independently with the amount of data, the length of the time series, and the stiffness of the approximation to the differential equations. Consider a reparametrization to the latent state of the form \(z(t)=T(t,,)\) where \( p()\) so that \(z(t) q_{}(z(t) x_{1}^{(j)},x_{2}^{(j)},,x_{M}^{(j)})\). We can rewrite the second term in the evidence lower bound as,

\[_{t_{1}^{(j)}}^{t_{1}^{(j+1)}}_{q_{}(z(t))} [||r_{,}(z(t),t)||_{C_{}(t)}^{2}]\,dt =_{t_{1}^{(j)}}^{t_{1}^{(j+1)}}_{p()} [||r_{,}(T(t,,),t)||_{C_{}(t)}^{2}]\,dt\] (8) \[=(t_{1}^{(j+1)}-t_{1}^{(j)})_{p()p(t)}[||r_ {,}(T(t,,),t)||_{C_{}(t)}^{2}]\]where \(p(t)\) is a uniform distribution, \((t_{1}^{(j)},t_{1}^{(j+1)})\) and \(p()(0,I)\) is a Gaussian. With this rearrangement, we can derive the main result of this work.

**Lemma 1**.: _An unbiased approximation of the gradient of the evidence lower bound, denoted as \(_{,}(,)\), with an \((R)\) time and memory cost can be formulated as follows:_

\[_{,}(,) _{i=1}^{M}_{k=1}^{R}_{,} p _{}(x_{i}^{(j)} T(t_{i}^{(j)},^{(k)},))\] (9) \[-(t_{1}^{(j+1)}-t_{1}^{(j)})_{k=1}^{R}_{ ,}||r_{,}(T(t^{(k)},^{(k)},),t^{(k)})||_{C_{ }(t^{(k)})}^{2}.\]

_where each \(t^{(k)}(t_{1}^{(j)},t_{1}^{(j+1)})\) and each \(^{(k)}(0,I)\)._

The proof follows by applying the standard reparametrization trick  to estimating gradients of the amortized objective in (7).

**Remark 1:** In practice we found choosing \(R 100\) worked well for the problems we considered. Note that in terms of elapsed time, \(100\) evaluations of this objective, which can be computed in parallel, is far cheaper than \(100\) evaluations of the SDE forward model evaluated as a part of an iterative sequential SDE solver. Moreover we found that adaptive stepping schemes required far more evaluations of the SDE forward model than our stochastic approach (see Section 4.1).

**Remark 2:** In the case that evaluations of the SDE drift term were relatively cheap compared to decoder evaluations (for example in the case the dimension of the latent state is much smaller than the dimension of the data), we found it useful to increase the number of samples used to approximate the integral over time without increasing the number of samples from the variational posterior. To do so, we made use of a nested Monte Carlo scheme to approximate the second term in the ELBO,

\[(t_{1}^{(j+1)}-t_{1}^{(j)})_{p(e)p(t)}[||r_{ ,}(T(t,,),t)||_{C_{}(t)}^{2}]\\ ^{(j+1)}-t_{1}^{(j)}}{RS}_{k=1}^{R}_{l=1}^{S}  r_{,}(T(t^{(k,l)},^{(k)},),t^{(k,l)})||_{C_{ }(t^{(k,l)})}^{2},\] (10)

where, again, each \(^{(k)}(0,I)\) and each \(t^{(k,1)},t^{(k,2)},,t^{(k,S)}(t_{1}^{(j)},t_{1}^{(j+1)})\). In addition, because the integral over time is one-dimensional we used stratified sampling to draw from \((t_{1}^{(j)},t_{1}^{(j+1)})\) in order to further reduce the variance in the integral over time. In this case we often found we could choose \(R 10\) and \(S 10\). To be clear, (10) is simply a method for variance reduction that we found to be useful; it is not a necessary component for our approach.

## 3 Limitations & Related Work

Summary of assumptions.In the previous sections we introduced an ELBO which, when maximized, leaves us with a generative model in the form of a nonlinear, latent SDE with time-dependent diffusion and an approximation to the latent state over the time-window of observations in the form of a Gaussian process. To reiterate, we only assume that the approximating posterior, i.e. the distribution over the latent state given a batch of observations, is a Gaussian process; this is an assumption that is commonly made in the context of nonlinear state estimation, for example [23; 24]. When making predictions, we sample from the nonlinear SDE which characterizes the generative model (1).

Stochastic adjoint sensitivities.Li et al.  proposed the stochastic adjoint sensitivity method, enabling the inference of latent SDEs using a wide range of approximate posteriors over the latent state. In our work we choose to approximate the posterior over the latent state using a MGP which enables us to eliminate the requirement of solving any differential equations entirely; as we have discussed extensively this choice enables dramatic computational savings. A limitation of our approach as compared to the stochastic adjoint sensitivities method is that our method should only be used to approximate the posterior over the latent state when it is approximately a MGP. Intuitively, this limitation is akin to the limitations of mean-field stochastic variational inference as comparedto stochastic variational inference with an expressive approximate posterior such as normalizing flows . From our practical experience working on a range of test cases, this has not been a limiting factor. It is worth reiterating that this limitation applies only to the approximate posterior over the time window of observations; the predictive posterior can be a complex distribution defined by a nonlinear SDE with a Gausian initial condition.

In addition, the stochastic adjoint sensitivity method allows for state dependent diffusion processes whereas our approach only allows for a time dependent diffusion process. In cases where a state dependent diffusion process is deemed necessary, our approach could be used to provide a good initial guess for the parameters of the drift function. It remains a topic of future work to determine if this limitation is mitigated by the fact that we are learning latent SDEs rather than SDEs in the original data space. Across the range of test cases we considered, we have not encountered a problem for which the assumption of a time-dependent diffusion matrix was limiting.

Latent neural ODEs.Chen et al. , Rubanova et al. , and Toth et al.  presented latent ordinary differential equations (ODEs) as generative models for high-dimensional temporal data. These approaches have two main limitations: (i) they encode all uncertainty in the ODE's initial condition and (ii) they rely on adjoint sensitivities, necessitating the solution of a sequence of initial value problems during optimization. As was discussed previously, SDEs provide a more natural modeling paradigm for estimating uncertainty, naturally capturing our intuition that uncertainty should accumulate over time . Moreover, to reiterate, our work avoids solving differential equations entirely by relying on unbiased approximations of a one-dimensional integral instead; as we will show, this can result in a dramatic decrease in the number of required function evaluations in training as compared to methods based on adjoints. Moreover, we will show that our approach avoids the numerical instabilities of adjoint methods when they are used to approximate gradients of time averaged quantities over long time intervals for chaotic systems. It is worth mentioning that gradients computed by backpropagation of a forward solver are not consistent with the adjoint ODE in general  so we do not consider comparisons to such approaches here.

Weak form methods.Methods for inferring continuous time models of dynamical systems using the weak form of the differential equations were introduced in the context of learning ODEs with linear dependence on the parameters [27; 28]. More recently these methods were adapted for training neural ODEs more quickly than adjoint methods for time-series prediction problems . These methods share some similarities to the present approach in how they achieve a computational speed-up - both methods transform the problem of solving differential equations into a problem of integration. In contrast to the present approach, these methods only allow for one to learn an ODE in the data coordinates (i.e. they do not allow for one to infer an autoencoder and a set of differential equations simultaneously). Moreover, these methods rely on a biased estimate for the weak form residual which will fail when observations become too widely spaced. In contrast, in the present approach, we rely on unbiased approximations to the evidence lower bound. Finally, these methods require the specification of a carefully designed test-space  - a consideration not required by our approach.

## 4 Numerical Studies

In this section we provide a number of numerical studies to demonstrate the utility of our approach. In the first study, we show that our approach can be used to train neural SDEs using far fewer evaluations of the model than adjoint methods. In the second study, we consider the problem of parameter tuning for a chaotic system over long time intervals. We show that our approach does not suffer from the numerical instabilities which are known to cause issues with adjoint methods on problems such as these. Finally we close this section with two practical test cases: the first demonstrating competitive performance on a motion capture benchmark and the second showing how our approach can be applied to learn neural SDEs from video. An additional numerical study exploring the effect of the nested Monte Carlo parameter, \(S\), is provided in Appendix H. Details on computing resources are provided Appendix F. All code required to reproduce results and figures is provided at github.com/coursekevin/arlatentsde.

### Orders of magnitude fewer function evaluations in training

In this numerical study we consider the task of building a predictive model from noisy observations of a predator-prey system. We simulated the Lotka-Volterra equations for \(50\) seconds collecting data at a frequency of \(10\)Hz. Observations were corrupted by Gaussian noise with a standard deviation of \(0.01\). Validation data was collected over the time inverval \(\) seconds. We then attempt to build a predictive model from the data using a neural ODE (NODE) and our method, amortized reparametrization for continuous time auto-encoding (ARCTA), with the same model for the ODE and drift function respectively. To make comparisons with the NODE fair, we set the decoder to be the identity function. We assume the diffusion matrix is constant and place a log-normal prior on its diagonal elements. We approximate the posterior over these elements using a log-normal variational posterior. Details on the architecture and hyperparameters are provided in Appendix G.1. For this experiment, as well as subsequent experiments, we made use of the Adam optimizer .

We considered three different tolerances on the NODE adaptive stepping scheme. We trained our model as well as the NODEs using 10 different random seeds while recording the validation RMSE and the number of evaluations of the model. Looking to Figure 2, we see that our approach required more than an order of magnitude fewer evaluations of the model to achieve a similar RMSE on the validation set. This remains true even when the tolerance of the ODE solver is reduced such that the validation RMSE is substantially higher than our approach.

### Numerical instabilities of adjoints

It is well-known that adjoint based methods produce prohibitively large gradients for long time averaged quantities of chaotic systems  and accordingly methods, such as least squares shadowing , have been introduced to address such concerns. In this section we reproduce this phenomena on a simple parameter tuning problem and show that our approach does not suffer these same issues.

Given the parametric form of the chaotic Lorenz equations,

\[ =(y-x)\] (11) \[ =x(-z)-y\] (12) \[ =xy- z\] (13)

along with an initial guess for the parameters, \(_{0}\), \(_{0}\), and \(_{0}\), our goal is to tune the value of parameters such that they align with the observed data.

Figure 2: Lotka-Volterra benchmarking result. In the left figure we see our method (ARCTA) requires more than **one order of magnitude** fewer evaluations of the model (NFE) than the standard neural ODE (NODE) to achieve a similar validation accuracy. In the right figure we have plotted a probabilistic prediction on the test set along with three samples from the predictive distribution.

For this experiment we collect data at a frequency of 200Hz and corrupt observations by Gaussian noise with a covariance of \(1\). We generate five independent datasets over the time intervals \(\), \(\), \(\), and \(\). For each dataset we generated an initial guess for the parameters by sampling from a Gaussian whose mean is the true value of the parameters and standard deviation is \(20\)% of the mean. For the adjoint methods we report the \(_{2}\)-norm of the gradient with respect to the parameters at the initial guess. For our method (ARCTA) we optimize for \(2000\) iterations (which tended to be enough iterations to successfully converge to a reasonable solution) and report the average gradient across all iterations. Details on hyperparameters and our architecture design are provided in Appendix G.2. Results are summarized in Figure 3. While adjoints expectedly provide prohibitively large gradients as the length of the time series is increased, our approach remains numerically stable.

### Motion capture benchmark

In this experiment we consider the motion capture dataset from . The dataset consists of 16 training, 3 validation, and 4 independent test sequences of a subject walking. Each sequence consists of \(300\) time-series observations with a dimension of \(50\). We made use of the preprocessed data from . Like previous approaches tackling this dataset, we chose a latent dimension of \(6\). We assume a Gaussian observation likelihood. We place a log-normal prior on the diagonal elements of the diffusion matrix and the noise on the observations. We approximate the posterior of the diffusion matrix and observation noise covariance using a log-normal approximate posterior. Details on our architecture design and hyperparameter selection are provided in Appendix G.3.

For our approach, we train 10 models and report their average performance on the test set due to the extremely limited number (4) of independent test sequences. Looking to Figure 4, we see that our approach provided competitive performance on this challenging dataset. This result, in combination with those presented previously demonstrating we require fewer function evaluations for similar

Figure 4: MOCAP benchmarking results, \({}^{}\) from  and \({}^{*}\) from . Our score is computed by training 10 models with different seeds and averaging on the test set. Looking to the table, we see that our method performs similarly to other state-of-the-art methods. The plot shows the predictive posterior on the test set for some select outputs. Other benchmark results were compiled in . RMSE was computed from MSE by taking the square root of the mean and transforming the error via a first-order Taylor-series approximation.

Figure 3: Stability of gradients in chaotic systems. The log-scale on vertical axis shows our approach remains stable for longer time series, while adjoint-based gradients become unusable at \(50\) and \(100\) seconds.

forecasting accuracy and improved gradient stability for chaotic systems, make clear the utility of the present work. It is possible to achieve state-of-the-art performance at a significantly reduced computational cost as compared to adjoint based methods.

### Neural SDEs from video

In this experiment we attempt to learn a latent SDE from video. We generated \(32 32\) black and white frames of a nonlinear pendulum as it evolves for \(30\) seconds collecting data at a frequency of \(15\)Hz. We transform the \(1024\) dimensional state down to two dimensions using a convolutional architecture. Details on the hyperparameters and architecture are provided in Appendix G.4. This problem is similar to the problem considered in  except the dynamical system we consider is nonlinear. In this prior work, the authors were forced to regularize the latent space so that one set of coordinates resembles a generalized velocity. In the present work, no such regularization is required.

We assume a Bernoulli likelihood on the pixels. Like in previous numerical studies we place a log-normal prior on the diagonals of the diffusion term and approximate the posterior using a log-normal variational distribution. After training we generate a forecast that is visualized in Figure 5. We see that we were successfully able to build a generative model for this simple video. This result demonstrates the broad applicability of the present approach to standard generative modeling tasks.

## 5 Conclusions

Here we have presented a method for constructing unbiased approximations to gradients of the evidence lower bound used to train latent stochastic differential equations with a time and memory cost that scales independently with the amount of data, the length of the time-series, and the stiffness of the model for the latent differential equations. We achieve this result by trading off the numerical precision of adaptive differential equation solvers with Monte-Carlo approximations to expectations using a novel amortization strategy and a recently derived change of variables for expectations under Markov Gaussian processes .

We have demonstrated the efficacy of our approach in learning latent SDEs across a range of test problems. In particular we showed that our approach can reduce the number of function evaluations as compared to adjoint methods by more than one order of magnitude in training while avoiding the numerical instabilities of adjoint methods for long time series generated from chaotic systems. In addition, we showed that our approach can be used for generative modeling of a simple video.

In the immediate future, there is significant room for future work in applying variance reduction schemes to the expectation over time to further reduce the total number of required function evaluations. There are also opportunities to explore the utility of the proposed approach for generative modeling on more realistic problems. Finally, there are opportunities to apply our work in the context of implicit densities .

Figure 5: Neural SDEs from video. Here we used five frames to estimate the intial state and then forecast in the latent space for 30 seconds. The bottom plot shows the latent SDE. The top row shows 10 samples from the predictive posterior overlaid on the data.