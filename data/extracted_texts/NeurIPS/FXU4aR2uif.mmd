# Episodic Multi-Task Learning with

Heterogeneous Neural Processes

 Jiayi Shen\({}^{1}\), Xiantong Zhen\({}^{1,2}\), Qi (Cheems) Wang\({}^{3}\), Marcel Worring\({}^{1}\)

\({}^{1}\)University of Amsterdam, Netherlands, {j.shen, m.worring}@uva.nl

\({}^{2}\) Inception Institute of Artificial Intelligence, Abu Dhabi, UAE, zhenxt@gmail.com

\({}^{3}\) Kaiyuan Mathematical Sciences Institute, Changsha, China, hhq123go@gmail.com

Currently with United Imaging Healthcare, Co., Ltd., China.

###### Abstract

This paper focuses on the data-insufficiency problem in multi-task learning within an episodic training setup. Specifically, we explore the potential of heterogeneous information across tasks and meta-knowledge among episodes to effectively tackle each task with limited data. Existing meta-learning methods often fail to take advantage of crucial heterogeneous information in a single episode, while multi-task learning models neglect reusing experience from earlier episodes. To address the problem of insufficient data, we develop Heterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within the framework of hierarchical Bayes, HNPs effectively capitalize on prior experiences as meta-knowledge and capture task-relatedness among heterogeneous tasks, mitigating data-insufficiency. Meanwhile, transformer-structured inference modules are designed to enable efficient inferences toward meta-knowledge and task-relatedness. In this way, HNPs can learn more powerful functional priors for adapting to novel heterogeneous tasks in each meta-test episode. Experimental results show the superior performance of the proposed HNPs over typical baselines, and ablation studies verify the effectiveness of the designed inference modules.

## 1 Introduction

Deep learning models have made remarkable progress with the help of the exponential increase in the amount of available training data . However, many practical scenarios only have access to limited labeled data . Such data-insufficiency sharply degrades the model's performance . Both meta-learning and multi-task learning have the potential to alleviate the data-insufficiency issue. Meta-learning can extract meta-knowledge from past episodes and thus enables rapid adaptation to new episodes with a few examples only . Meanwhile, multi-task learning exploits the correlation among several tasks and results in more accurate learners for all tasks simultaneously . However, the integration of meta-learning and multi-task learning in overcoming the data-insufficiency problem is rarely investigated.

In episodic training , existing meta-learning methods  in every meta-training or meta-test episode learn a single-task. In this paper, we refer to this conventional setting as _episodic single-task learning_. This setting restricts the potential for these models to explore task-relatedness within each episode, leaving the learning of multiple heterogeneous tasks in a single episode under-explored. We consider multiple tasks in each episode as _episodic multi-task learning_. The crux of episodic multi-task learning is to generalize the ability of exploring task-relatedness from meta-training to meta-test episodes. The differences between episodic single-task learning and episodic multi-task learning are illustrated in Figure 1. To be specific, we restrict the scope of the problemsetup to the case where tasks in each meta-training or meta-test episode are heterogeneous but also relate to each other by sharing the same target space.

The neural process (NP) family [12; 13], as typical meta-learning probabilistic models , efficiently quantifies predictive uncertainty with limited data, making it in principle well-suited for tackling the problem of data-insufficiency. However, in practice, it is challenging for vanilla NPs  with a global latent variable to encode beneficial heterogeneous information in each episode. This issue is also known as the expressiveness bottleneck [15; 16], which weakens the model's capacity to handle insufficient data, especially when faced with diverse heterogeneous tasks.

To better resolve the data-insufficiency problem, we develop Heterogeneous Neural Processes (HNPs) for episodic multi-task learning. As a new member of the NP family, HNPs improve the expressiveness of vanilla NPs by introducing a hierarchical functional space with global and local latent variables. The remainder of this work is structured as follows: We introduce our method in Section (2). Related work is overviewed in Section (3). We report experimental results with analysis in Section (4), after which we conclude with a technical discussion, existing limitations, and future extensions. In detail, our technical contributions are two-fold:

* Built on the hierarchical Bayes framework, our developed HNPs can simultaneously generalize meta-knowledge from past episodes to new episodes and exploit task-relatedness across heterogeneous tasks in every single episode. This mechanism makes HNPs more powerful when encoding complex conditions into functional priors.
* We design transformer-structured inference modules to infer the hierarchical latent variables, capture task-relatedness, and learn a set of tokens as meta-knowledge. The designed modules can fuse the meta-knowledge and heterogeneous information from context samples in a unified manner, boosting the generalization capability of HNPs across tasks and episodes.

Experimental results show that the proposed HNPs together with transformer-structured inference modules, can exhibit superior performance on regression and classification tasks under the episodic multi-task setup.

## 2 Methodology

**Notations**2. We will now formally define episodic multi-task learning. For a single episode \(\), we consider \(M\) heterogeneous but related tasks \(_{}^{1:M}=\{_{}^{m}\}_{m=1}^{M}\). Notably, the subscript denotes an episode, while superscripts are used to distinguish tasks in this episode. In the episodic multi-task setup, tasks in a single episode are heterogeneous since they are sampled from different task distributions \(\{p(^{m})\}_{m=1}^{M}\), but are related at the same time as they share the target space \(_{}\).

Figure 1: **Illustration of episodic multi-task learning. Each row corresponds to a meta-training or meta-test episode. Different colors represent different label spaces among episodes; the same color with different shades represents different categories in the same task. Compared with episodic single-task learning, episodic multi-task learning simultaneously handles several related tasks in a single episode.**

To clearly relate to the modeling of vanilla neural processes , this paper follows its nomenclature to define each task. Note that in vanilla neural processes _context_ and _target_ are often respectively called _support_ and _query_ in conventional meta-learning . Each task \(_{}^{m}\) contains a context set with limited training data \(_{}^{m}=\{_{,i}^{m},_{,i}^{m}\}_{i=1}^{N_{ }}\) and a target set \(_{}^{m}=\{x_{,j}^{m},y_{,j}^{m}\}_{j=1}^{N_{}}\), where \(N_{}\) and \(N_{}\) are the numbers of context samples and target samples, respectively. \(_{,i}^{m}\) and \(x_{,j}^{m}\) represent features of context and target samples; while \(_{,i}^{m},y_{,j}^{m}_{}\) are their corresponding targets, where \(i=1,2,...,N_{};j=1,2,..,N_{};m=1,2,...,M\). For simplicity, we denote the set of target samples and their corresponding ground-truths by \(_{}^{m}=\{x_{,i}^{m}\}_{j=1}^{N_{}}\), \(_{}^{m}=\{y_{,j}^{m}\}_{j=1}^{N_{}}\). For an episode \(\), episodic multi-task learning aims to perform simultaneously well on each corresponding target set \(_{}^{m},m=1,2..,M\), given the collection of context sets \(_{}^{1:M}\).

For classification, this paper follows the protocol of meta models , such as \(O\)-way \(K\)-shot setup, clearly suffering from the data-insufficiency problem. Thus, episodic multi-task classification can be cast as a \(M\)-task \(O\)-way \(K\)-shot supervised learning problem. An episode has \(M\) related classification tasks, and each of them has a context set with \(K\) different instances from each of the \(O\) classes . It is worth mentioning that the target spaces of meta-training episodes do not overlap with any categories in those of meta-test episodes.

### Modeling and Inference of Heterogeneous Neural Processes

We now present the proposed heterogeneous neural process. The proposed model inherits the advantages of multi-task learning and meta-learning, which can exploit task-relatedness among heterogeneous tasks and extract meta-knowledge from previous episodes. Next, we characterize the generative process, clarify the modeling within the hierarchical Bayes framework, and derive the approximate evidence lower bound (ELBO) in optimization.

Generative Processes.To get to our proposed method HNPs, we extend the distribution over a single function \(p(f_{})\) as used in vanilla NPs to a joint distribution of multiple functions \(p(f_{}^{1:M})\) for all heterogeneous tasks in a single episode \(\). In detail, the underlying multi-task function distribution \(p(f_{}^{1:M})\) is inferred from a collection of context sets \(_{}^{1:M}\) and learnable meta-knowledge \(,^{1:M}\). Note that \(\) represents the shared meta-knowledge for all tasks, and \(^{m}\) denotes the task-specific meta-knowledge corresponding to the task distribution \(p(^{m})\). Hence, we can formulate the predictive distribution for every single episode as follows:

\[p(_{}^{1:M}|_{}^{1:M};,^{1:M})= p( _{}^{1:M}|_{}^{1:M},f_{}^{1:M})p(f_{}^{1: M}|_{}^{1:M};,^{1:M})df_{}^{1:M},\] (1)

where \(p(f_{}^{1:M}|_{}^{1:M};,^{m})\) denotes the data-dependent functional prior for multiple tasks of the episode \(\). The functional prior encodes context sets from all heterogeneous tasks and quantifies uncertainty in the functional space. Nevertheless, it is less optimal to characterize multi-task function generative processes with vanilla NPs, since the single latent variable limits the capacity of the latent space to specify the complicated functional priors. This expressiveness bottleneck in vanilla NPs is particularly severe for our episodic multi-task learning since each episode has diverse heterogeneous tasks with insufficient data.

Modeling within the Hierarchical Bayes Framework.To mitigate the expressiveness bottleneck of vanilla NPs, we model HNPs by parameterizing each task-specific function within a hierarchical Bayes framework. As illustrated in Figure 2, HNPs integrate a global latent representation \(_{}^{m}\) and a set of local latent parameters \(_{,1:O}^{m}\) to model each task-specific function \(f_{}^{m}\). Specifically, the latent variables are introduced at different levels: \(_{}^{m}\) encodes task-specific context information from \(_{}^{m}\) and \(^{m}\) in the representation level. \(_{,1:O}^{m}\) encode prediction-aware information for a task-specific decoder from \(_{}^{1:M}\) and \(\) in the parameter level, where \(O\) is the dimension of the decoder. For example, the dimension is the size of the target space when performing classification tasks.

Figure 2: **Graphical model of the proposed HNPs in a single episode.** Filled shapes indicate observations. Probabilistic and deterministic variables are indicated by unfilled circles and diamonds, respectively.

Notably, each local latent parameter is conditioned on the global latent representation, which controls access to all context sets in the episode for the corresponding task. Our method differs from previous hierarchical architectures [16; 18; 19; 20] in the NP family since the local latent parameters of our HNPs are prediction-aware and explicitly constitute a decoder for the subsequent inference processes.

In practice, we assume that distributions of each task-specific function are conditionally independent. Thus, with the introduced hierarchical latent variables for each task in the episode, we can factorize the prior distribution over multiple functions in Eq. (1) into:

\[p(f_{}^{1:M}|_{}^{1:M};,^{1:M})=_{m=1}^{M}p( _{}^{m}|_{}^{m};^{m})p(_{,1:O}^ {m}|_{}^{m},_{}^{1:M};),\] (2)

where \(p(_{}^{m}|_{}^{m};^{m})\) and \(p(_{,1:O}^{m}|_{}^{m},_{}^{1:M};)\) are prior distributions of the global latent representation and the local latent parameters to induce the task-specific function distribution.

By integrating Eq. (2) into Eq. (1), we rewrite the modeling of HNPs in the following form:

\[p(_{}^{1:M}|_{}^{1:M};,^ {1:M}) =_{m=1}^{M} p(_{}^{m}|_{}^{m},_{,1:O}^{m})\] (3) \[p(_{,1:O}^{m}|_{}^{m},_{ }^{1:M};)d_{,1:O}^{m}}p(_{}^{m}| _{}^{m};^{m})d_{}^{m},\]

where \(p(_{}^{m}|_{}^{m},_{,1:O}^{m})\) is the function distribution for the task \(_{}^{m}\) in HNPs. This distribution is obtained by the matrix multiplication of \(_{}^{m}\) and all local latent parameters \(_{,1:O}^{m}\).

Compared with most NP models [12; 16; 18; 19] employing only latent representations, HNPs infer both latent representations and parameters in the hierarchical architecture from multiple heterogeneous context sets and learnable meta-knowledge. Our model specifies a richer and more intricate functional space by leveraging the hierarchical uncertainty inherent in the context sets and meta-knowledge. This theoretically yields more powerful functional priors to induce multi-task function distributions.

Moreover, we claim that the developed model constitutes an _exchangeable stochastic process_ and demonstrate this via Kolmogorov Extension Theorem . Please refer to Appendix B for the proof.

Approximate ELBO.Since both exact functional posteriors and priors are intractable, we apply variational inference to the proposed HNPs in Eq. (3). This results in the approximate ELBO:

\[L_{}(,^{1:M},,)=_{m=1}^{M} _{q_{}(_{}^{m}|_{}^{m}; ^{m})}_{q_{}(_{,1:O}^{m}|_{ }^{m},_{}^{1:M};)}[ p(_{}^{m}| _{}^{m},_{,1:O}^{m})]\]

\[-_{}[q_{}(_{,1:O}^{m}|_{ }^{m},_{}^{1:M};)||p_{}(_{,1:O}^{m}| _{}^{m},_{}^{1:M};)]}-_{ }[q_{}(_{}^{m}|_{}^{m};^{m}) ||p_{}(_{}^{m}|_{}^{m};^{m})]},\] (4)

where \(q_{}(_{}^{m}|_{}^{m};^{m})\) and \(q_{}(_{,1:O}^{m}|_{}^{m},_{}^{1 :M};)\) are variational posteriors of their corresponding latent variables. \(\) and \(\) are parameters of inference modules for \(_{}^{m}\) and \(_{,1:O}^{m}\), respectively. Following the protocol of vanilla NPs , the priors use the same inference modules as variational posteriors for tractable optimization. In this way, the KL-divergence terms in Eq. (4) encourage all latent variables inferred from the context sets to stay close to those inferred from the target sets, enabling effective function generation with few examples. Details on the derivation of the approximate ELBO and its tractable optimization are attached in Appendix C.

### Transformer-Structured Inference Module

In order to infer the prior and variational posterior distributions in Eq. (4), it is essential to develop well-designed approximate inference modules. This is non-trivial and closely related to the performance of HNPs. Here we adopt a transformer structure as the inference module to better exploit task-relatedness from the meta-knowledge and the context sets in the episode. More specifically, the previously mentioned meta-knowledge \(=_{1:O}\) and \(^{1:M}\) are instantiated as learnable tokens to induce the distributions of hierarchical latent variables in the proposed model.

Without loss of generality, in the next, we provide an example of transformer-structured inference modules for prior distributions in classification scenarios. Details of the inference modules in regression scenarios can be found in Appendix D. In Figure 3, a diagram of the transformer-structuredinference modules is displayed under the 3-task 5-way 1-shot setting. In this case, the number of context samples is the same as the size of the target space, and thus we have \(^{m}_{}=\{^{m}_{,o},^{m}_{,o}\}_{o=1}^{O}\), where \(O\) is set as 5. In episodic training, labels in context sets are always available during inference.

Transformer-Structured Inference Module \(\{,^{m}\}\) for \(^{m}_{}\).In the proposed HNPs, each global latent representation encodes task-specific information relevant to the considered task in the episode as \(p_{}(^{m}_{}|^{m}_{};^{m})\). The learnable token \(^{m}\) preserves the meta-knowledge from previous episodes for specific tasks, which are sampled from the corresponding task distribution \(p(^{m})\). The role of \(^{m}\) is to help the model adapt efficiently to such specific tasks in meta-test episodes.

In detail, we set the dimension of the learnable token \(^{m}\) to the same as that of the features \(^{m}_{,1:O}\). Then the transformer-structured inference module \(\) fuses them in a unified manner by taking \([^{m}_{,1:O};^{m}]\) as the input. The module \(\) outputs the mean and variance of the corresponding prior distribution. The inference steps for the global latent representation \(^{m}_{}\) are:

\[[^{m}_{,1:O};^{m}] =(([^{m}_{,1:O};^{m}]))+[ ^{m}_{,1:O};^{m}],\] (5) \[[^{m}_{,1:O};^{m}] =(([^{m}_{,1:O};^{m}]))+[^{m}_{,1:O};^{m}],\] (6) \[p_{}(^{m}_{}|^{m}_{};^{m}) =(^{m}_{};^{m}_{},_{^ {m}_{}}),\] (7)

where \(_{^{m}_{}}=(^{m}),_{ ^{m}_{}}=((^{m}))\). The transformer-structured inference module includes a multi-headed self-attention (MSA) and three multi-layer perceptrons (MLP). The layer normalization (LN) is "pre-norm" as done in . Softplus is the activation function to output the appropriate value as the variance of the prior distribution .

Transformer-Structured Inference Module \(\{,_{1:O}\}\) for \(^{m}_{,1:O}\).Likewise, each learnable token \(_{o}\) corresponds to a local latent parameter \(^{m}_{,o}\). With the learnable tokens \(_{1:O}\), we reformulate the prior distribution of local latent parameters as \(p_{}(^{m}_{,1:O}|^{m}_{},^{1:M}_{ };_{1:O})\). In this way, we learn the shared knowledge, inductive biases across all tasks, and their distribution at a parameter level, which in practical settings can capture epistemic uncertainty.

To be specific, the prior distribution can be factorized as \(_{o=1}^{O}p_{}(^{m}_{,o}|^{m}_{},^{1:M}_{};_{o})\), where all local latent parameters are assumed to be conditionally independent. For each local latent parameter \(^{m}_{,o}\), the transformer-structured inference module \(\) takes \([^{1:M}_{,o},_{o}]\) as input and outputs the corresponding prior distribution, where \(^{1:M}_{,o}\) are deep features from the same class \(o\) in the episode and \(_{o}\) is the corresponding learnable token. Here the inference steps for \(^{m}_{,o}\) are as follows:

\[[^{1:M}_{,o};_{o}] =(([^{1:M}_{,o};_{o}]))+ [^{1:M}_{,o};_{o}],\] (8)

Figure 3: **A diagram of transformer-structured inference modules of HNPs for the first meta-training episode in Figure 1 under the 3-task 5-way 1-shot setting. For clarity, we display the inference process of the local latent parameters specific to the third task in the episode.**

\[[_{,o}^{1:M};_{o}]=([([ _{,o}^{1:M};_{o}]))+[_{,o}^{1 :M};_{o}],\] (9)

\[p_{}(_{,o}^{m}|_{}^{m},_{}^ {1:M};_{o})=(_{,o}^{m};_{_{,o}^ {m}},_{_{,o}^{m}}),\] (10)

where \(_{_{,o}^{m}}=(_{o},_{ }^{m(i)}),_{_{,o}^{m}}=(( _{o},_{}^{m(i)}))\). \(_{}^{m(i)}\) is a Monte Carlo sample from the variational posterior of the corresponding global latent representation during meta-training.

Both transformer-structured inference modules use the refined tokens \(^{m}\) and \(_{o}\) to obtain a global latent representation and a local latent parameter, respectively. The introduced tokens preserve the specific meta-knowledge for each latent variable during inference. Compared with the \(\)-parameterised inference module exploring the intra-task relationships, the \(\)-parameterised inference module enables the exploitation of the inter-task relationships to reason over each local latent parameter. Thus, the introduced tokens can be refined with relevant information from the heterogeneous context sets. By integrating meta-knowledge and heterogeneous context sets, HNPs can reduce the negative transfer of task-specific knowledge among heterogeneous tasks in each episode. Please refer to Appendix E for algorithms.

## 3 Related Work

Multi-Task Learning.Multi-task learning can operate in various settings . Here we roughly separate the settings of MTL into two branches: (1) Single-input multi-output (SIMO) [24; 25; 26; 27; 28; 29; 30], where tasks are defined by different supervision information for the same input. (2) Multi-input multi-output (MIMO) [11; 10; 31; 32; 33; 34], where heterogeneous tasks follow different data distributions. This work considers the MIMO setup of multi-task learning with episodic training.

In terms of modeling methods, from a processing perspective, existing MTL methods can be roughly categorized into two groups: (1) Probabilistic MTL methods [11; 19; 35; 36; 37; 38; 39; 40; 41], which employ the Bayes framework to characterize probabilistic dependencies among tasks. (2) Deep MTL models [10; 32; 24; 25; 26; 42; 43; 44; 45; 46; 47; 48], which directly utilize deep neural networks to discover information-sharing mechanisms across tasks. However, deep MTL models rely on large amounts of training data and tend to overfit when encountering the data-insufficiency problem. Meanwhile, previous probabilistic MTL methods consider a small number of tasks that occur at the same time, limiting their applicability in real-world systems.

Meta-Learning.Meta-learning aims to find strategies to quickly adapt to unseen tasks with a few examples [49; 4; 5; 50]. There exist a couple of branches in meta-learning methods, such as metrics-based methods [6; 51; 52; 53; 54; 55; 56; 57] and optimization-based methods [58; 59; 60; 61; 62; 63; 64; 65; 66; 67; 68]. Our paper focuses on a probabilistic meta-learning method, namely neural processes, that can quantify predictive uncertainty. Models in this family [69; 7; 12; 13; 15; 16; 18; 67; 70; 71; 72; 73] can approximate stochastic processes in neural networks. Vanilla NPs  usually encounter the expressiveness bottleneck because their functional priors are not rich enough to generate complicated functions [15; 16].  introduces deterministic variables to model predictive distributions for meta-learning scenarios directly. Most NP-based methods only focus on a single task during inference [7; 12; 15; 16; 14], which leaves task-relatedness between heterogeneous tasks in a single episode an open problem.

This paper combines multi-task learning and meta-learning paradigms to tackle the data-insufficiency problem. Our work shares the high-level goal of exploiting task-relatedness in an episode with [74; 19; 75]. Concerning the multi-task scenarios, the main differences are: [74; 19; 75] handles multiple attributes and multi-sensor data under the SIMO setting, while our work performs for the MIMO setting where tasks are heterogeneous and distribution shifts exist. Moreover,  theoretically addresses the conclusion that MTL methods are powerful and efficient alternatives to gradient-based meta-learning algorithms. However, our method inherits the advantages of multi-task learning and meta-learning: simultaneously generalizing meta-knowledge from past to new episodes and exploiting task-relatedness across heterogeneous tasks in every single episode. Thus, our method is more suitable for solving the data-insufficiency problem. Intuitive comparisons with related paradigms such as _cross-domain few-shot learning_[77; 78; 79; 80; 81; 82], _multimodal meta-learning_[83; 84; 85; 86; 87] and _cross-modality few-shot learning_[88; 89; 90] are provided in Appendix A.

Experiments

We evaluate the proposed HNPs and baselines on three benchmark datasets under the episodic multi-task setup. Sec. 4.1 and Sec. 4.2 provide experimental results for regression and classification, respectively. Ablation studies are in Sec. 4.3. More comparisons with recent works on extra datasets are provided in Appendix F. Additional results under the convectional MIMO setup without episodic training can be found in Appendix G & H.

### Episodic Multi-Task Regression

Dataset and Settings.To evaluate the benefit of HNPs over typical NP baselines in uncertainty quantification, we conduct experiments in several 1D regression tasks. The baselines include conditional neural processes (CNPs ), vanilla neural processes (NPs ), and attentive neural processes (ANPs ). As a toy example, we construct multiple tasks with different task distributions: each task's input set is defined on separate intervals without overlap.

Given four different tasks in an episode, their input sets are \(_{}^{1;4}\). Each input set contains a few instances, drawn uniformly at random from separate intervals, such as \(_{}^{1}[-4,-2)\), \(_{}^{2}[-2,0)\), \(_{}^{3}[0,2)\), and \(_{}^{1}[2,4)\). All tasks in an episode are related by sharing the same ground truth function. Following [12; 18], function-fitting tasks are generated with Gaussian processes (\(\)). Here a zero mean Gaussian process \(y^{(0)}(0,k(,))\) is used to produce \(_{}^{1;4}\) for the inputs from all tasks \(_{}^{1;4}\). A radial basis kernel \(k(x,x^{})=^{2}(-(x-x^{})^{2})/2l^{2})\), with \(l=0.4\) and \(=1.0\) is used.

Results and Discussions.As shown in Figure 4, CNPs, ANPs, and our HNPs exhibit more reasonable uncertainty than NPs in Figure 4: lower variances are predicted around observed (context) points with higher variances around unobserved points. Furthermore, NPs and ANPs detrimentally impact the smoothness of the predicted curves, whereas HNPs yield smoother predictive curves with reliable uncertainty estimation. These observations suggest that integrating correlation information across related tasks and meta-knowledge in HNPs can improve

To quantify uncertainty we use the average negative log-likelihood (the lower, the better). As shown in Table 1, our HNPs achieve a lower average negative log-likelihood than baselines, demonstrating our method's effectiveness in uncertainty estimation.

### Episodic Multi-task Classification

Datasets and Settings.We use Office-Home and DomainNet as episodic multi-task classification datasets. Office-Home contains images from four domains: Artistic (A), Clipart (C), Product (P) and Real-world (R). Each domain contains images from \(65\) categories collected from office and home environments. Note that all domains share the whole target space. The numbers of meta-training classes and meta-test classes are \(40\) and \(25\), respectively. There are about \(15,500\) images in total. DomainNet has six distinct domains: Clipart, Infograph, Painting, Quickdraw, Real and Sketch. It includes approximately 0.6 million images distributed over \(345\) categories. The

   Methods & CNPs & NPs & ANPs & HNPs \\  Avg. NLL & 0.0935 & 0.8649 & -0.1165 & -0.5207 \\   

Table 1: **Average negative log-likelihoods over target points from all tasks.**

Figure 4: **Performance comparisons on the episodic multi-task \(1\)-D function regression using \(5\) context points (black dots) for each task.** Black curves are ground truth, and blue ones are predicted results. The shadow regions are \( 3\) standard derivations from the mean .**

numbers of meta-training classes and meta-test classes are \(276\) and \(69\), respectively. Here one domain corresponds to a specific task distribution in the episodic multi-task setting.

When it comes to the episodic multi-task classification, we compare HNPs with the following three branches: (1) _Multi-task learning methods_: ERM  directly expands the training set of the current task with samples of related tasks. VMTL  is one of the state-of-the-art under the MIMO setting of multi-task learning. (2) _Meta-learning methods_: MAML , Proto.Net  and DGPs  address each task separately with no mechanism to leverage task-relatedness in a single episode. (3) _Methods from the NP family_: CNPs  and NPs  are established methods in the NP family. TNP-D  is recent NP work in sequential decision-making for a single task in each episode.

Results and Discussions.The experimental results for episodic multi-task classification on Office-Home and DomainNet are reported in Table 2. We use the average accuracy across all task distributions as the evaluation metric. It can be seen that HNPs consistently outperform all baseline methods, demonstrating the effectiveness of HNPs in handling each task with limited data under the episodic multi-task classification setup.

NPs and CNPs do not work well under all episodic multi-task classification cases. This can be attributed to their limited expressiveness of the global representation and the weak capability to extract discriminative information from multiple contexts. In contrast, HNPs explicitly abstract discriminative information for each task in the episode with the help of local latent parameters, enhancing the expressiveness of the functional prior.

We also find that HNPs significantly surpass other baselines on 1-shot Office-Home and DomainNet, both under the 4/6-task 5-way and 4/6-task 20-way settings. This further implies that HNPs can circumvent the effect of the problem of data-insufficiency by simultaneously exploiting task-relatedness across heterogeneous tasks and meta-knowledge among episodes.

### Ablation Studies

Influence of Hierarchical Latent Variables.We first investigate the roles of the global latent representation \(_{}^{m}\) and the local latent parameters \(_{,1:O}^{m}\) by leaving out individual inference modules. These experiments are performed on Office-home under the 4-task 5-way 1-shot setting. We report the detailed performance for tasks sampled from a single task distribution (A/C/P/R) and the average accuracy across all task distributions (Avg.) in Table 3. The variants without specific latent variables are included in the comparison by removing the corresponding inference modules.

As shown in Table 3, both \(_{}^{m}\) and \(_{,1:O}^{m}\) benefit overall performance. Our method with hierarchical latent variables performs \(9.20\%\) better than the variant without both latent variables, \(3.00\%\) better than the variant without \(_{}^{m}\), and \(5.18\%\) better than the variant without \(_{,1:O}^{m}\). This indicates that latent variables of HNPs complement each other in representing con

    &  &  \\   &  &  &  &  \\ Method & 1-shot & 5-shot & 1-shot & 5-shot & 1-shot & 5-shot & 1-shot & 5-shot \\  ERM  & 66.04 \(\)0.051 & 73.62 \(\)0.53 & 39.25 \(\)0.24 & 47.14 \(\)0.18 & 59.95 \(\)0.52 & 58.52 \(\)0.44 & 38.62 \(\)0.22 & 47.85 \(\)0.20 \\ VMTL  & 49.71 \(\)0.48 & 56.75 \(\)0.47 & 27.50 \(\)0.44 & 22.82 \(\)0.13 & 42.24 \(\)0.39 & 57.37 \(\)0.43 & 18.05 \(\)0.11 & 31.38 \(\)0.15 \\  MAML  & 60.58 \(\)0.60 & 75.29 \(\)0.53 & 34.29 \(\)0.19 & 48.39 \(\)0.20 & 53.21 \(\)0.46 & 65.24 \(\)0.47 & 17.10 \(\)0.12 & 20.35 \(\)0.14 \\ Proto. Net.  & 57.19 \(\)0.53 & 74.97 \(\)0.46 & 32.72 \(\)0.18 & 49.75 \(\)0.16 & 53.71 \(\)0.48 & 68.80 \(\)0.42 & 31.90 \(\)0.19 & 47.59 \(\)0.18 \\ DGPs  & 65.89 \(\)0.53 & 79.96 \(\)0.38 & 31.48 \(\)0.18 & 49.46 \(\)0.18 & 50.93 \(\)0.42 & 63.32 \(\)0.38 & 25.46 \(\)0.15 & 38.63 \(\)0.17 \\  CNPs  & 43.33 \(\)0.56 & 55.07 \(\)0.63 & 10.57 \(\)0.10 & 12.02 \(\)0.11 & 37.90 \(\)0.45 & 40.53 \(\)0.44 & 51.21 \(\)0.10 & 5.14 \(\)0.10 \\ NPs  & 33.66 \(\)0.48 & 53.99 \(\)0.06 & 5.25 \(\)0.16 & 11.40 \(\)0.11 & 20.58 \(\)0.51 & 20.53 \(\)0.53 & 5.12 \(\)0.09 & 5.11 \(\)0.09 \\ TNP-D  & 65.49 \(\)0.53 & 78.94 \(\)0.43 & 41.61 \(\)0.22 & 59.19 \(\)0.21 & 49.10 \(\)0.42 & 67.39 \(\)0.40 & 28.83 \(\)0.17 & 47.69 \(\)0.18 \\ HNPs & **76.29** \(\)0.51 & **80.80** \(\)0.42 & **51.82** \(\)0.23 & **59.97** \(\)0.18 & **62.36** \(\)0.53 & **69.38** \(\)0.42 & **39.32** \(\)0.23 & **48.56** \(\)0.19 \\   

Table 2: **Comparative results (95% confidence interval) for episodic multi-task classification on Office-Home and DomainNet. Best results are indicated in bold.**

   \(_{}^{m}\) & \(_{,1:O}^{m}\) & **A** & **C** & **P** & **R** & **Avg.** \\  ✗ & ✗ & 62.64 \(\)0.72 & 56.87 \(\)0.71 & 75.18 \(\)0.79 & 73.68 \(\)0.77 & 67.09 \(\)0.63 \\ ✗ & ✓ & 69.39 \(\)0.63 & 63.10 \(\)0.68 & 80.66 \(\)0.76 & 79.99 \(\)0.62 & 73.29 \(\)0.51 \\ ✗ & ✗ & 67.02 \(\)0.467 & 60.70 \(\)0.69 & 78.26 \(\)0.36 & 78.47 \(\)0.72 & 71.11 \(\)0.59 \\ ✗ & ✓ & **75.33** \(\)0.43 & **64.92** \(\)0.68 & **83.38** \(\)0.46 & **83.54** \(\)0.44 & **76.29** \(\)0.54 \\   

Table 3: **Effectiveness of global latent representations \(_{}^{m}\) and local latent parameters \(_{,1:O}^{m}\) in the model. ✓ and ✗ denote whether the variants of HNPs have the corresponding latent variable or not.**text sets from multiple tasks and meta-knowledge. The variant without \(^{m}_{,1:O}\) underperforms the variant without \(^{m}_{}\) by \(2.18\%\), in terms of the average accuracy. This demonstrates that \(^{m}_{}\) suffers more from the expressiveness bottleneck than \(^{m}_{,1:O}\), weakening the models' discriminative ability. For classification, local latent parameters are more crucial than a global latent representation in revealing the discriminating knowledge from multiple heterogeneous context sets.

Influence of Transformer-Structured Inference Modules.To further understand our transformer-structured inference modules (Trans. w learnable tokens), we examine the performance against two other options: inference modules that solely utilize a multi-layer perceptron (MLP) and the variants that do not incorporate any learnable tokens (Trans. w/o learnable tokens). We also compare the probabilistic and deterministic versions of such inference modules. The deterministic variants consider the deterministic embedding for the hierarchical latent variables.

As shown in Table 4, our inference modules consistently outperform the variants, regardless of whether the inference network is probabilistic or deterministic. When using the probabilistic one, our inference modules respectively achieve \(1.04\%\) and \(2.99\%\) performance gains over Trans. w/o learnable tokens and MLP under the 4-task 5-way 1-shot setting. This implies the importance of learnable tokens and task-relatedness in formulating transformer-structured inference modules, which reduces negative transfer among heterogeneous tasks in each meta-test episode. Moreover, the variants with probabilistic inference modules consistently beat deterministic ones in performance, demonstrating the advantages of considering uncertainty during modeling and inference.

Effects of Different Ways to Generate Local Latent Parameters.We investigate the effects of different ways to generate each \(^{m}_{,o}\) from the shared condition \(^{m}_{}\) and \(^{1:M}_{}\). Given a Monte Carlo sample of global latent variables as \(^{m(i)}_{}\), in Table 5, we compare with two alternatives: 1) Concat directly concatenates each context feature and \(^{m}_{}\), and takes the concatenation as inputs of the transformer-structured inference network \(\). 2) Add sums up each context feature and \(^{m(i)}_{}\) and takes the result as the input. 3) Ours incorporates \(^{m(i)}_{}\) into the transformer-structured inference module by merging it with the refined learnable tokens in Eq. (10). As shown in Table 5, Ours consistently performs the best. This implies that incorporating the conditional variables into the inference module is more effective than the direct combinations of \(^{m(i)}_{}\) and instance features.

Effects of More "Shots" or "Classes".To investigate the effects of more "shots" or "classes" in the episodic multi-task classification setup, we conduct experiments by increasing \(K\) or \(O\) in the defined \(M\)-task \(O\)-way \(K\)-shot setup.

As shown in Table 6, the proposed HNPs have more advantages over the baseline method with the context data points below ten shots. With shots larger than ten, both methods will reach a performance bottleneck.

Moreover, Table 7 shows that our method consistently outperforms the baseline method as the number of classes increases from 20 to 40 in step 5. However, the performance gap between them narrows slightly with more classes. The main reason could be that the setting with more classes suffers from less data insufficiency.

   Methods & 1-shot & 5-shot & 10-shot & 20-shot \\  TNP-D & 65.49 \(\)0.53 & 78.94 \(\)0.43 & 80.81 \(\)0.32 & 81.12 \(\)0.68 \\ HNPs & 76.29 \(\)0.51 & 80.80 \(\)0.42 & 81.28 \(\)0.38 & 81.56 \(\)0.36 \\   

Table 6: **Performance comparisons on Office-Home under the 4-task 5-way K-shot setup.**

    & 1-shot & 5-shot \\   & MLP & 64.93 \(\)0.66 & 72.39 \(\)0.56 \\  & Trans. w/o learnable tokens & 70.22 \(\)0.62 & 76.15 \(\)0.54 \\  & Trans. w learnable tokens & 70.61 \(\)0.56 & 76.70 \(\)0.50 \\   & MLP & 73.30 \(\)0.59 & 77.94 \(\)0.48 \\  & Trans. w/o learnable tokens & 75.25 \(\)0.55 & 80.42 \(\)0.47 \\   & Trans. w learnable tokens & **76.29 \(\)0.51** & **80.80 \(\)0.42** \\   

Table 4: **Performance comparisons between our transformer inference modules (Trans. w learnable tokens) and other alternatives.**

   Methods & **A** & **C** & **P** & **R** & **Avg.** \\  Concat & 65.69 \(\)0.59 & 58.64 \(\)0.54 & 77.54 \(\)0.68 & 77.10 \(\)0.64 & 69.74 \(\)0.51 \\ Add & 69.92 \(\)0.69 & 63.73 \(\)0.71 & 78.81 \(\)0.77 & 79.03 \(\)0.78 & 72.87 \(\)0.61 \\ Ours & **73.31 \(\)0.63** & **64.92 \(\)0.68** & **83.38 \(\)0.64** & **83.54 \(\)0.64** & **76.29 \(\)0.51** \\   

Table 5: **Performance comparisons of different implementations of generating each local latent parameter \(^{m}_{,o}\) from the condition \(^{m}_{}\) and \(^{1:M}_{}\).**Sensitivity to the Number of Monte Carlo Samples.For the hierarchical latent variables in the HNPs, we investigate the model's sensitivity to the number of Monte Carlo samples. Specifically, the sampling number of the global latent representation \(_{}^{m}\) and local latent parameters \(_{,1:O}^{m}\) varies from \(1\) to \(30\). We examine on Office-Home under the 4-task 5-way 1-shot setting. In Figure 5, the runtime per iteration grows rapidly as the number of samples increases. However, there is no clear correlation between the performance and the number of Monte Carlo samples. There are two sweet spots in terms of average accuracy, one of which has favorable computation time. Hence, we set \(N_{z}\) and \(N_{w}\) to \(5\) and \(10\), respectively.

We also investigate the inference time of NP-based models per iteration on Office-Home under the 4task5way1shot setup. As shown in Table 8, our model needs more inference time than other NP-based methods for performance gains. The cost mainly comes from inferring the designed hierarchical latent variables; however, we consider this a worthwhile trade-off for the extra performance.

## 5 Conclusion

Technical Discussion.This work develops heterogeneous neural processes by introducing hierarchical latent variables and transformer-structured inference modules for episodic multi-task learning. With the help of heterogeneous context information and meta-knowledge, the proposed model can exploit task-relatedness, reason about predictive function distributions, and efficiently distill past knowledge to unseen heterogeneous tasks with limited data.

Limitation & Extension.Although the hierarchical probabilistic framework could mitigate the expressiveness bottleneck, the model needs more inference time than other NP-based methods for performance gains. Besides, the proposed method requires the target space to be the same across all tasks in a single episode. This requirement could limit the method's applicability in realistic scenarios where target spaces may differ across tasks. Our work could be extended to the new case without the shared target spaces, where the model should construct higher-order task-relatedness to improve knowledge sharing among tasks. Our code 3 is provided to facilitate such extensions.