# Expert-level protocol translation for self-driving labs

Yu-Zhe Shi\({}^{}\)

Fanxu Meng\({}^{}\)

Haofei Hou\({}^{}\)

Zhangqian Bi

Qiao Xu

Lecheng Ruan\({}^{}\)

Qining Wang\({}^{}\)

Department of Advanced Manufacturing and Robotics,

College of Engineering, Peking University

\({}^{}\)Equal contribution \({}^{}\)ruanlecheng@ucla.edu, qiningwang@pku.edu.cn

###### Abstract

Recent development in Artificial Intelligence (AI) models has propelled their application in scientific discovery, but the validation and exploration of these discoveries require subsequent empirical experimentation. The concept of self-driving laboratories promises to automate and thus boost the experimental process following AI-driven discoveries. However, the transition of experimental protocols, originally crafted for human comprehension, into formats interpretable by machines presents significant challenges, which, within the context of specific expert domain, encompass the necessity for structured as opposed to natural language, the imperative for explicit rather than tacit knowledge, and the preservation of causality and consistency throughout protocol steps. Presently, the task of protocol translation predominantly requires the manual and labor-intensive involvement of domain experts and information technology specialists, rendering the process time-intensive. To address these issues, we propose a framework that automates the protocol translation process through a three-stage workflow, which incrementally constructs Protocol Dependence Graphs (PDGs) that approach structured on the syntax level, completed on the semantics level, and linked on the execution level. Quantitative and qualitative evaluations have demonstrated its performance at par with that of human experts, underscoring its potential to significantly expedite and democratize the process of scientific discovery by elevating the automation capabilities within self-driving laboratories.

## 1 Introduction

The evolution of AI techniques has significantly accelerated the processes inherent to scientific discovery, with a notable impact observed within the domain of experimental sciences (Wang et al., 2023b). This influence is manifested through a variety of avenues: the generation of hypothesis spaces informed by extensive literature analysis (Jablonka et al., 2022; Kim et al., 2024), the interpretation of observational data via the identification of high-dimensional correlations (Jumper et al., 2021; Abramson et al., 2024), the engineering of novel structures that meet predefined specifications (Grisoni et al., 2021; Park et al., 2023), and the implementation of comprehensive simulations to ascertain the characteristics of potential products (Hie et al., 2021; Singh et al., 2023).

However, the findings facilitated by AI-driven research require further validation and exploration via empirical experiments, and may even entail a cyclical process where AI-generated hypotheses are refined based on the outcomes of real-world experiments, which demands the assembly of a sizable cohort of experienced experimenters to carry out these investigations in accordance with established _protocols_(McNutt, 2014). Unfortunately, the formation and sustenance of such a dedicated experimental cadre are fraught with considerable financial demands, and the collaborative engagement between people oriented towards AI methodologies and those grounded in experimental sciences is frequently encumbered by the communication gaps between distinct intellectual paradigms (Baker, 2016; Freedman et al., 2015; Munafo et al., 2017; Baker, 2021; Shi et al., 2023a).

To bridge the aforementioned gap, the paradigm of self-driving laboratories has garnered attention, which automates experimental protocols via robotic systems, potentially revolutionizing the way experiments are conducted (Bedard et al., 2018; Steiner et al., 2019; Mehr et al., 2020; Rohrbach et al., 2022; Burger et al., 2020; Szymanski et al., 2023). Despite the promising outlook, designing such labs relies largely on the translation of protocols, primarily designed for human experimenters, into machine-readable instructions. This translation process necessitates extensive collaboration between domain experts, who possess the requisite scientific knowledge; and information technology specialists, who encode this knowledge into software and hardware systems. The inherently labor-intensive nature of such translation significantly prolongs the development of self-driving laboratories. The primary challenges are rooted in the discrepancies across three critical aspects (see Fig. 1):

SyntaxHuman experimenters can effortlessly **comprehend** protocols articulated in Natural Language (NL), whereas automated systems frequently necessitate dedicated syntax parsers to convert these protocols into a sequence of actionable steps. Consider the protocol: _"Split the mixture equally into 2 separate 50 mL round-bottom flasks for the next steps."_ This example highlights the meticulous control over experimental procedures, explicitly directing the _"split"_ of the mixture into precisely measured volumes -- a crucial factor for achieving uniform outcomes in subsequent reactions. It is imperative at this level to uphold a **structured** representation of the mapping of operation conditions and the control flows of operations.

SemanticsHuman experimenters can **infer** implicit knowledge and context relying on the flexibility and adaptability of human understanding. In contrast, machine instructions necessitate a level of precision and rigidity that human communication does not inherently require. For instance, consider the protocol: _"Stir the mixture at room temperature for 5 minutes."_ While a human expert might inherently understand that _"room temperature"_ denotes a temperature range of 20-25 \({}^{}C\) drawing on their prior knowledge, an automation system necessitates explicit information regarding such implicit details, which therefore need to be **completed** before execution.

ExecutionHuman experimenters can **simulate** possible intermediate states and outcomes by considering the cumulative effects of a sequence of actions. For instance, given the two instructions adjacently: _"Add 35 mL water to the flask"_ and _"Add 25 mL water to the flask"_, an experimenter can deduce that the flask's minimal capacity comes over 60 mL to prevent errors. For an automated system to perform a similar function, the actions need to be **linked** along their execution order.

Great efforts have been made on such translation tasks, among which Chemputer is representative (Mehr et al., 2020). This algorithm parses the NL-based protocol into XDL, a Domain-Specific Language (DSL) specially designed to describe chemical synthesis reactions. The completeness and

Figure 1: **Illustration of the protocol translation problem.** An NL-based protocol is translated to a structured protocol, then to a completed protocol, and finally to a linked protocol that is ready for self-driving laboratories along with a corresponding PDG, after being processed through the syntax, semantics, and execution levels. The three colors of arrows and text/ code highlights indicate the three translation steps respectively.

linkages are constructed with a set of manually-written constraints, with which the correctness of protocols can be further checked. This methodology has gained widespread acceptance in automated chemical synthesis, as a testament to the intensive efforts by domain and IT experts in developing XDL and the corresponding constraints. However, the application of a similar framework in other domains of experimental sciences, such as _Genetics_, _Medicine_, _Ecology_, and _Bioengineering_, would necessitate repeating these labor-intensive tasks on a case-by-case basis, thus underscoring the critical need for a more generally applicable, human-free protocol translator.

In this work, we propose a novel framework of human-free translator, designed to potentially facilitate applications across diverse experimental science domains without requiring extensive manual intervention. This framework decomposes the translation challenge into three hierarchical stages: structured on the syntax level, completed on the semantics level, and linked on the execution level, mirroring the cognitive steps undertaken by human experts in similar translation tasks. In the proposed work, the DSL, its constraints, and linkages are generated automatically, based on protocols tailored for human experimenters, thereby eliminating the need for labor-intensive manual processes.

Our contributions are threefold: (i) We conduct a systematic analysis of the existing discrepancies in protocol translation between human experimenters and automated systems in self-driving laboratories. From this analysis, we derive design principles that emulate human cognitive processes involved in protocol translation (Sec. 2). (ii) We devise an autonomous protocol translator through a tripartite framework that incrementally constructs PDGs, encapsulating the spatial-temporal dynamics of protocol execution across syntax, semantics, and execution levels (Sec. 3). (iii) Through both quantitative and qualitative evaluations in various experimental science domains, we demonstrate that our translator, when integrated as an auxiliary module for Large Language Models (LLMs), approaches the efficacy of skilled human experimenters and substantially surpasses the performance of purely LLMs-based alternatives in protocol translation tasks (Sec. 4).

## 2 Protocol translation for self-driving laboratories

In this section, we explore the translation of protocols for human experimenters to those suitable for self-driving laboratories. We analyze the task requirements across syntax (Sec. 2.1), semantics (Sec. 2.2), and execution (Sec. 2.3) levels. We pinpoint challenges at each level for both humans and machines, delving into systematic methods for addressing these issues. Leveraging expert insights, we delineate fundamental design principles for achieving effective protocol translation (Sec. 2.4).

### Syntax level

Operation-condition mappingIn NL-based protocols, operations and their corresponding parameters such as input reagents and conditions, are entangled with each other. For example, _"Dissolve 10 g of sodium chloride in 100 mL of distilled water at 80\({}^{}C\)"_, the entanglements of actions and conditions highlight the complexity machines face in parsing such protocols. Human experimenters can _recognize_ them without information loss thanks to the _internalized language_ for parsing NL (Chomsky, 1956, 2007). In contrast, protocols for machines must be represented precisely, with proper extraction of keys and values, and matching between them with appropriate data structures.

Operation control flowsIn NL-based protocols, both linear and non-linear control flows are implicitly embedded in the text. While linear control flows, _i.e._, workflows in sequential execution order, can be straightforward, non-linear control flows such as iterative loops and parallel operations can be hard to detect because the signal and the operational domain can be separated. Consider the protocol: _"Repeat the titration until the endpoint is reached, then record the volume of titrant used"_. These steps embody a non-linear control flow, challenging machines to correctly interpret the iterative process involved. Even human experts have to read the protocols carefully to understand the local and global structures to match the signals with operational domains, let alone machines.

### Semantics level

Latent semantics of known unknownsSome assigned values of parameters are regarded as common sense knowledge of domain experts by default, thus the values are omitted for simplicity or referred to via a _proxy name_ following the domains' conventions. For example, the protocol instruction _"Dry the purified product at room temperature"_ relies on the experimenter's understanding of what constitutes _"room temperature"_. However, machines substantially suffer from such latent semantics, implying that every value of parameters should be made explicit.

Latent semantics of unknown unknownsSometimes, even required parameters for a specific operation are omitted from the protocols either or not intentionally, causing _unknown unknowns_ that one may even be not aware of the absence of such information. For instance, the protocol instruction _"Centrifuge the sample after adding the enzyme"_ does not specify the key controlling parameter, speed or duration, for the _"centrifuge"_ operation, before describing its specific value. Both human and machines require every parameter of operations to be grounded.

### Execution level

Capacity of resourcesProtocols often omit explicit specifications of resource capacities, leading to potential execution errors like exceeding a device's maximum capacity. This issue, inherent in the execution sequence, is undetectable by analyzing single operations alone. For example, the instruction _"Transfer the mixture to a beaker"_ requires choosing a beaker with adequate capacity, a decision based on the cumulative volume from previous steps. Humans intuitively manage this through a mental simulation of the experimental process (Gallese and Goldman, 1998). Machines, therefore, need a pre-execution verification mechanism to ensure resource capacities are not exceeded, highlighting the need for an integrated understanding of the experimental sequence.

Safety of operationsIn addition to managing resource capacities, another source of runtime errors stems from operations that, while semantically valid, may lead to adverse or dangerous outcomes in certain execution contexts. Such scenarios necessitate a _dual-constraint_ approach, where experiments are mindful not only of the actions required _what I should do_ but also of potential missteps to avoid _what I must not do_. For instance, the instruction _"Heat the reaction mixture to 70\({}^{}C\)"_ can be appropriate or hazardous, depending on the mixture's composition -- safe with a heat-stable catalyst, but risky with a heat-sensitive component due to potential decomposition. To navigate these complexities, human experts effectively run mental simulations, conducting _"What if?"_ queries and counterfactual reasoning (Hoch, 1985) to anticipate the consequences of their actions. Similarly, machines need a system to draw upon domain-specific knowledge and historical context to assess the safety of each operation, ensuring that all actions are contextually appropriate and safe.

Figure 2: **The design principles and the resulting pipeline of our translator. (Syntax level) Operation dependence synthesis on the syntax level, through the joint optimization of DSL program syntax space and the parsing tree of the NL-based protocols. This process is static and context-free. (Semanties level) Reagent flow analysis on the semantics level, through an automaton scheme maintaining the lifecycles of reagents and intermediate products. This process is static and context-free. (Execution level) Spatial-temporal dynamics analysis on the execution level, through the partial execution trace model based on the spatial-temporal dual constraint representation. This process is dynamic and context-aware.**

### Design principles inspired by human experimenters

Human experts' cognitive capabilities on the translation of protocols serve two key roles: understanding protocols for in-hand experiments and manually developing translators for self-driving laboratories. Inspired by these practices, we outlined design principles for our translator and assessed the strengths and weaknesses of current DSLs for NL-based protocols, such as XDL (Steiner et al., 2019), ULSA (Wang et al., 2022), ORD (Kearnes et al., 2021), Biocoder (Ananthanarayanan and Thies, 2010), Autoprotocol (Strateos, 2023), and the family of DSLs (hereinafter called ADSL) which are automatically designed by the AutoDSL tool driven by domain corpora (Shi et al., 2024).

Operation dependence synthesis for the syntax levelTo precisely comprehend the complicated operation-condition mappings and non-linear control flows, machines should equip with an _externalized language_ in parallel with humans' _internalized language_(Chomsky, 2007). A machine-recognizable language commonly possesses a Context-Free Grammar (CFG) which externally defines the key-value structures on different hierarchies: (i) operation as key, reagents and conditions as values; (ii) condition as key, the corresponding parameters as values; and (iii) signal of control flow as key, the corresponding operational domains as values. If a protocol can be parsed into an Abstract Syntax Tree (AST) with the CFG, it is verified on the syntax level (Hopcroft et al., 1996), resulting in the dependency structures of the operation flow (see Fig. 2 Top). All DSLs mentioned before are context-free languages with CFGs (Fowler, 2010), echoing this design principle.

Reagent flow analysis for the semantics levelDespite the merits of DSLs based on CFGs, the context-free nature hinders verification on the semantics level, which is pivotal in protocols essentially describing procedures, where the preconditions and postconditions between temporally adjacent operations can be end-to-end connected. To be specific, although a CFG defines a structural space with hierarchies of operations, conditions, parameters, and control flows, _i.e._, _"There must be several parameters corresponding to a condition"_, it does not constrain the mappings under the context of domain-specific knowledge, _i.e._, _"There are parameters controlling the Temperature, Duration, and Acidity of the condition"_. If the exact mapping between keys and values cannot be specified, the self-driving laboratories can hardly be aware of the loss of completeness, _i.e._, being aware of the omitted conditions given an operation or the missing value given a parameter, due to the extremely large search space over all symbols given by the corresponding DSLs (Gulwani et al., 2017). The design choices of DSLs diverge on this level, where Autoprotocol only supports verification on the syntax level and does not possess any domain knowledge, ORD and ULSA offer the relations between operations and conditions without more fine-grained parameters, while XDL, Biocoder, and ADSL offer the find-grained key-value relation below the hierarchy of operations without more constraints about the values, _e.g._, suggested values of specific parameters. Hence, we require a mechanism for completing the structures of reagent flow (see Fig. 2 Middle), while the completeness of the fine-grained parameters is guaranteed by the DSLs.

Spatial-temporal dynamics analysis for the execution levelCompletion on the semantics level is conducted statically because the semantics of operations are viewed individually rather than contextualized in the execution sequence. Regrettably, such effort cannot guarantee that the protocols can be executed successfully without any errors in the run time, which is unacceptable by self-driving laboratories (Christensen et al., 2021; Seifrid et al., 2022). One way is to have domain experts write down all of the potential bad cases as constraints and use them for verification. However, run-time errors raised in the dynamic context of operations are heavily long-tail distributed. This makes it extremely hard to predict such errors from statistical _hindsight_(Pearl, 2019), _i.e._, the set of collected post-hoc bad cases. Thus, we leverage the powerful _foresight_ based on simulation, which spans the full probabilistic worlds of each operation by its semantic constraints, both on the _spatial_ dimension, _e.g._, capacity of resources captured by the reagent dependency, and the _temporal_ dimension, _e.g._, safety of operations captured by the operation dependency. The simulation is conducted along the topological order of the corresponding execution flow graph. At each operation unit, both historical operations in the same protocols and similar operations in other protocols are recalled dynamically, checking and refining the dual-constraint spaces accordingly (see Fig. 2 Bottom). Interestingly, none of the DSLs in our discussion take this feature as part of language design and only XDL employs an external compiler with hand-crafted rules for error detection. Such consideration is reasonable because in mainstream DSL design, verification on the execution level is not guaranteed by the DSLs themselves for design simplicity and user convenience (Mernik et al., 2005). Consequently, we require an environment to dynamically check the correctness of execution both spatially and temporally, through synthesizing operation and reagent dependencies.

The framework of protocol translation

In this section, we introduce the three-stage framework for human-free protocol translation, which gradually constructs a structural representation of protocols, called the _Protocol Dependence Graph_ (PDG). The PDG makes explicit both the operation and reagent dependencies for a protocol. Operation dependence echoes the concept of program control flow, which derives the condition of sequential, branch, or loop execution of protocol operations (Sec. 3.1). Reagent flow provides an explicit representation of the reagent instantiate-exploit relationships implicitly in the protocol (Sec. 3.2). Additionally, we simulate the protocol execution process using the PDG, checking and refining operation sequences under the spatial and temporal dynamics of execution (Sec. 3.3).

### Operation dependence synthesis for the syntax level

The operation dependence models the topological order for executing operations in a protocol. The procedure is executed sequentially from the first operation in the protocol to the last, unless the experimenter encounters structures that change the execution flow, such as branches and loops. In practice, we extract the operation dependence by compiling the protocol to DSL programs.

InputThe compilation process is conducted based on the corresponding DSL \(=\{,\}\). The CFG-based syntax \(=(S,V,,R)\) includes (i) the start symbol \(S\); (ii) the variable set \(V=\{V_{},V_{},V_{},V_{}\}\) with placeholders for control flow signals \(V_{}\), operations \(V_{}\), conditions \(V_{}\), and parameters \(V_{}\); (iii) the set of terminals \(\), which are the grounded values of parameters; (iv) the set of production rules \(R\) defining the structural space between the four variable sets. The semantics \(=(T_{},T_{},T_{},T_{}, T_{R})\) constrains the variables and production rules, assigning the placeholders with substantial meanings. To note, according to the design choice discussed in Sec. 2.4, the DSL used here should be one of XDL, Biocoder, and ADSL, _i.e._ the DSLs with the most fine-grained structural representation compared with their counterparts.

Pre-processingGiven an input protocol \(\) for translation, we first parse the NL sentences by an off-the-shelf tool and extract the actions accordingly. Then, the extracted actions are matched with the operations \(o T_{}\) of the DSL, according to both exact match score and semantic similarity. Afterwards, we extract the arrays of entities related to the extracted action \(_{t}\) by an off-the-shelf tool, where we regard the output labels to the entities and relations as _pseudo-labels_ because they can possibly be noisy. Please refer to Appx. C.1 for implementation details.

DSL program synthesisSynthesizing structural representation given unstructured signal is challenging (Billard, 2000, 2006). Specifically, the one-to-many mappings of many DSL operations bring uncertainty into the matching. For example, the operation add possesses distinct patterns: two or three input slots. This further distorts the matching of reagents, conditions, and parameters because off-the-shelf tools can hardly detect the exact categories of these entities deeply rooted in domain-specific knowledge. Since the observation and hypothesis spaces are both noisy, we propose to jointly optimize the patterns of operations and the pseudo-labels. We denote the set of all possible program patterns generated by operation \(o\) as \(o^{}=\{|o^{}\ ,T_{R}^{} , T_{} T_{}^{} T_{ }^{} T_{}^{}\}\). A synthesized DSL program is defined as \(()=(o_{1}),(o_{2}),, (o_{()}|)\), where \((o_{t})\) is the program of an operation assembled with its corresponding conditions and parameters under the selected pattern in \(o^{}\). Let \(s()=_{1},_{2},,_{|s( )|}\) represent the sequence of operation-related entities, the objective of optimization can be

\[_{(o_{t}),_{t}}_{t}_{o _{t}^{}}D()s( ),\] (1)

where \(D(\|)\) is a divergence function with three indicators: (i) the selected pattern examples should be as close as possible to the text span; (ii) the selected pattern should be as similar as possible with the extracted subject-verb-object structure; and (iii) as many labeled entities as possible should be mapped to the parameter space (see Fig. 3B). Though \(|o^{}|\) is not a large value, the whole sequence of operations can yield an exponential complexity. Hence, to make the joint optimization tractable, we separate the search of solution into two steps in the spirit of Expectation Maximization (EM): (i) Expectation: sampling programs from the legal space defined by the corresponding DSL, with a program-size-sensitive prior \(|(o_{t})|^{-1}\); (ii) Maximization: randomly alternating symbols in \(s()\) by matching them with those in \(()\) and greedily select the edits that decrease the objective function.

### Reagent flow analysis for the semantic level

The DSL programs are further contextualized by associating operations with reagent flow. Reagent flow indicates the transfer of reagents among operations, reflecting how one operation impacts the subsequent ones. We define the reagent flow following the _reaching definitions_ schema (Alfred et al., 2007), which is commonly used to capture the life cycle of a variable in compiler design. This schema determines a set of reagents reachable at each point in a protocol, and subsequently tracks the _kills_ and _defines_ of an operation, _i.e._, whether a reachable reagent is consumed, or a new reagent is yielded, in an operation.

InputWe denote the reagents consumed and the intermediate products yielded by each operation \(o\) as \((o)\) and \((o)\) respectively. The objective is to find a set of operation pairs \(\{ o_{i},o_{j}\,|\,(o_{i})(o_{j})\}\) such that \((o_{i})\) is required as input by \((o_{i})\).

The reaching definitions schemaWe determine the availability of a reagent at each step by locating where it is defined in a protocol when execution reaches each operation. A reagent \(r\) reaches an operation \(o\), if there is a path from the point following \(r\) to \(o\), such that \(r\) is not _killed_, _i.e._, consumed, along that path. Any reagent \(r\) that reaches an operation \(o\) might be killed at that point, and \(o\) may yield new intermediate products \(r^{}\) that reach future operations. Notably, according to statistics on corpora of protocols (Vaucher et al., 2020), for about 90% operations of a target DSL, if \(o_{i}<o_{j}\) are two adjacent operations, \((o_{i})(o_{j})\) holds. This implies that the reagent generated by preceding operation is likely to be used and then be killed instantly by the following operation.

Reagent flow analysis via operation flow traversalWe traverse the DSL program in execution order to leverage the reagent locality revealed from statistical results, determining the reachability and life cycle of reagents. A Pushdown Automaton (PDA) with a random access memory is adopted to record reachable reagents as operation context, defining and killing reagents at each operation point along the computation1. A PDA is formally defined as a 7-tuple \(M=(Q,,,,q_{0},Z,F)\), where \(Q T_{}\) indicates the set of states, \(=T_{}\) represents the domain of inputs, \( T_{}\) denotes possible memory elements, \( Q Q^{*}\) is the transition procedure (Transition in Alg. 1), \(q_{0}=o_{1}\) defines the initial state, \(Z=\) is the initial memory element, and \(F\) denotes the set of accepting states. The reagent dependence construction process (Flow in Alg. 1) traverses the DSL program in execution order by leveraging the NextOps utility, which evaluates to subsequent operations. In every transition step with input, the killed reagents are removed from the memory, and the defined reagents are added to the memory. After a reagent is killed, the pair of the operations that defined it and killed it will be added to the set of reagent flow constraints. The accepting state is reached if the memory is empty at the end of execution, _i.e._, all reagents defined in operations are killed by other operations. We employ state-of-the-art LLMs to extract reagent entities from NL-based protocol descriptions for the two utilities Kills and Defines through instruction-following in-context learning (Wei et al., 2021; Brown et al., 2020) (refer to Appx. C.2 for details).

``` procedureTransition(\(M\), \(o\)) \(\)Context Transition \((M(),(M(),o))\) \((M(),(o))\) \(\)State Transition \(M(q)(M(q) o)(o)\) procedureFlow(\(p()\), \(M\)) \(R=\{\ \}\)\(\)Set of reagent dependence \(M(q)\{o_{1}\}\)\(\)Initial State \(M()\)\(\)Initial Memory while\(M(q)\)do  Transition(\(M\), \(M(q)\)) ```

**Algorithm 1** Reagent flow analysis

### Spatial-temporal dynamics for the execution level

While the pre-specified PDG analysis indicates the things _should_ be done to follow operation and reagent flow, we still need to care about the things _must not_ be done by describing the activities that may be performed and the constraints prohibiting undesired execution behavior. Therefore, we introduce a constrained-based execution model to support dynamic protocol simulation, getting grounded in the theories of process modeling and execution (Dourish et al., 1996; Pesic et al., 2007).

A constraint-based protocol execution modelWe extend the DSL program \(()\) by a constraint set \(C=C_{op} C_{reg} C_{s} C_{t}\) to construct a constraint-based execution model \(S=((),C)\). The execution of a program is represented by a trace \(=(o_{1},c_{1}),(o_{2},c_{2}),,(o_{|( )|},c_{|()|})\)where the order of \(o_{i}\) reflects the temporal sequence. The execution context \(c_{i}\) defines the spatial environment in which each operation is performed. Each constraint \(c S(C)\) is a predicate that maps the execution trace \(\) to a binary condition denoting satisfy or not. An execution trace \(\) is said to satisfy the program constraint if and only if \(||=|()|\) and \(c()\) holds for all \(c C\).

Leveraging partial execution trace for spatial and temporal constraintsExplicit constraints, namely operation and reagent flow, are easy to satisfy. Unfortunately, deriving implicit constraints, _e.g._, the capacity of resources and safety of operations, is case-by-case for each protocol, requiring expert efforts. We propose profiling the context through execution to derive implicit spatial and temporal constraints that meet domain-specific requirements. An execution trace is defined as _partially_ satisfying the constraints \(C\) if it follows the operation and reagent flow; that is, for any \( o_{i},o_{j>i}\) in trace \(\), there exists at least a pair of valid operation flow path and reagent flow path from \(o_{i}\) to \(o_{j}\).

## 4 Results

In this section, we compete our framework with human experts on the overall translation task, and assess the utility of each component of the framework by comparing with alternative approaches.

### Experimental setting

MaterialsWe select 75 complicated experiments with 1,166 steps in total as the testing set, from the domains of _Chemical Synthesis_ (235 steps in 10 experiments; 235 in 10 for simplicity; "Synthesis" for abbreviation), _Genetics_ (396 in 34), _Medical and Clinical Research_ (307 in 23, "Medical"), _Bioengineering_ (218 in 17), and _Ecology_ (10 in 1). Please refer to Appx. D for details.

Expert-created protocol translationWe recruited five groups of experienced experimenters, each specializing in a different domain, with seven participants in each group. Every participating experimenter holds at least a Master's degree related to the corresponding domain, has obtained at least six years' experience in manually conducting pre-designed experiments of the domain, has acquired elementary programming skills, and has at least heard of self-driving laboratories. These human experts are asked to translate the original NL-based protocols for their domains into those suitable for self-driving laboratories. Their outputs are subjected to DSL-based representations and complete PDGs to evaluate machines' behaviors, which are clearly demonstrated by a running example and the examples in the DSL documentation. Outputs from experts are carefully cross-validated and the individual divergence between them is minimized through an expert-panel-driven workshop discussion following the established workflow (Reilly et al., 2023). Translation results of human experts and machines are serialized and are compared through ROUGE and BLEU metrics (Lin, 2004; Papineni et al., 2002). Please refer to Appx. B for ethics considerations.

Alternative methodsWe compare our translator with alternative methods on the first two levels, to investigate the effects of early stages on the overall translation result. On the syntax level, we compare the syntactic synthesis method (referred to as Ours-SY) with ConDec-SY (Wang et al., 2023a), which synthesizes DSL programs by LLMs with external DSL grammars as constraint, and a baseline DSL-LLM-SY leveraging the minimal realization used in Shi et al. (2024). On the semantics level, we compare the deductive verification method (referred to as Ours-SE) with NL-RAG-LLM-SE, which retrieves on the embedded vector database of original NL-based protocols, and a baseline NL-LLM-SE implemented by pure prompt-engineering on LLMs. Since the I/Oes of all stages are unified in the pipeline, we implement an overall baseline Best-Baseline that combines the strongest alternative methods within the evaluation of the first two stages.

### Overall assessment on expert-created protocol translation

ResultComparing the overall output of our translator and ideal human experimenters, we find that our translator approaches the level of experts with average performance higher than \(85\%\) across all indicators. Our translator significantly outperforms the alternative pipeline Best-Baseline on the (\(t(148)=-17.71,_{d}<0,p<.0005\); see Fig. 3C).

DiscussionWe find that our translator demonstrates similar performance to human experts in translating protocols with complete parameters and clear descriptions (see Fig. 4A). However, in cases where the linear description of the experimental protocol is lacking, our translator and human experts diverge. Specifically, our translator tends to translate based on the information within the sentence or between adjacent sentences, while human experts tend to consider the overall experimental process comprehensively. Though there are minor gaps, these observations suggest that our translator is approaching the level of performance of experienced human experimenters. Please refer to Appx. E.3 for case studies on the distinctions between the behaviors of experts and machines.

### Comparison between alternative models

ResultOn the syntax level, our Ours-SY significantly outperforms alternative approaches (\(t(148)=-17.07,_{d}<0,p<.0005\) for ConDec-SY; \(t(148)=-15.47,_{d}<0,p<.0005\) for DSL-LLM-SY; see Fig. 3D). On the semantics level, our Ours-SE significantly outperforms alternative approaches (\(t(148)=-2.52,_{d}<0,p<.05\) for NL-RAG-LLM-SE; \(t(148)=-3.07,_{d}<0,p<.005\) for NL-LLM-SE; see Fig. 3E).

DiscussionCompared with alternative methods on the syntax level, our translator excels in ensuring the accuracy of translations across different protocols thanks to the PDG representation, as shown in Fig. 4B. On the semantics level, our translator performs better in translating incomplete protocols with missing information than other baselines, as shown in Fig. 4C. We explain these merits with the properties of structural representation, which defines a representation space with

Figure 3: **Results of experiment.****(A)** Distinctions between various domains regarding domain-specific corpora and the corresponding DSLs. **(B)** Convergence of the three indicators in the objective function for program synthesis. **(C)** Our translator significantly outperforms the best baseline and approaches human-level performance. **(D)** Our translator significantly outperforms alternative methods on the syntax level. **(E)** Our translator significantly outperforms alternative methods on the semantics level.

[MISSING_PAGE_FAIL:10]