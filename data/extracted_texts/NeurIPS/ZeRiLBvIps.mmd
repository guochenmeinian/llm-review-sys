# Local Convergence of Gradient Methods for Min-Max Games: Partial Curvature Generically Suffices

Guillaume Wang

Institute of Mathematics

Ecole polytechnique federale de Lausanne

Station Z, CH-1015 Lausanne

guillaume.wang@epfl.ch

&Lenaic Chizat

Institute of Mathematics

Ecole polytechnique federale de Lausanne

Station Z, CH-1015 Lausanne

lenaic.chizat@epfl.ch

###### Abstract

We study the convergence to local Nash equilibria of gradient methods for two-player zero-sum differentiable games. It is well-known that such dynamics converge locally when \(S 0\) and may diverge when \(S=0\), where \(S 0\) is the symmetric part of the Jacobian at equilibrium that accounts for the "potential" component of the game. We show that these dynamics also converge as soon as \(S\) is nonzero (_partial curvature_) and the eigenvectors of the antisymmetric part \(A\) are in general position with respect to the kernel of \(S\). We then study the convergence rates when \(S A\) and prove that they typically depend on the _average_ of the eigenvalues of \(S\), instead of the minimum as an analogy with minimization problems would suggest. To illustrate our results, we consider the problem of computing mixed Nash equilibria of continuous games. We show that, thanks to partial curvature, conic particle methods - which optimize over both weights and supports of the mixed strategies - generically converge faster than fixed-support methods. For min-max games, it is thus beneficial to add degrees of freedom "with curvature": this can be interpreted as yet another benefit of over-parameterization.

## 1 Introduction

Min-max optimization is notoriously subtler than minimization, even in convex-concave settings. While many of the proof techniques for minimization have a natural equivalent in the min-max world, some common intuitions fail to transfer. The picture is clear for strongly convex-strongly concave (SC-SC) min-max games: all the classical gradient methods converge exponentially (for small enough step-sizes) with worst-case convergence rates dependent on the strong convexity and strong concavity parameters \(_{x}\), \(_{y}\). But, most famously perhaps, for bilinear min-max games the last iterate of simultaneous Gradient Descent-Ascent (GDA) diverges, while the Proximal Point (PP) method converges, and alternating GDA and the continuous-time limit of all of these algorithms - Gradient Flow (GF) - exhibit a cycling behavior.

Based on those two extreme cases, it still seems that part of our intuition from minimization, where the last-iterate convergence rate is indeed determined by the strong convexity parameter, is preserved. In this paper, we argue that this intuition is in fact overly pessimistic, and that gradient methods behave in general more favorably in the min-max setting than in the minimization setting.

Let us first look at a basic example. Consider a bilinear min-max game regularized by a quadratic term _only in one scalar variable_:

\[_{x^{d}}_{y^{d}}x^{}Py+x _{1}^{2}.\]Here there is no strong convexity in either player (so \(_{x}=_{y}=0\)), yet as observed on Fig. 0(a), Fig. 0(b), when \(P^{d d}\) is random with independent standard normal entries, GDA (with a small step-size) typically converges at an exponential rate that scales linearly with \(\).1

As we will see, this phenomenon is a consequence of the existing theory for general smooth min-max games

\[_{x^{n}}_{y^{m}}f(x,y)\] (1.1)

with a local Nash equilibrium (NE), or local saddle point, \(z^{*}=(x^{*},y^{*})\). It is well-known from the dynamical systems literature that GF converges locally to \(z^{*}\) if

\[_{M}_{(M)}()>0, \;\;M=^{2}_{xx}f&^{2}_{xy}f\\ -^{2}_{xy}f^{}&-^{2}_{yy}f(z^{*})^{ (n+m)(n+m)}\]

the Jacobian of the skewed gradient field at \(z^{*}\), and where \(()\) denotes the spectrum, i.e., the set of eigenvalues. For our starting basic example, this quantity2 can be visualized in Fig. 0(c). Moreover, \(_{M}\) also characterizes the convergence behavior of gradient methods in the leading order in the step-size \(\): they all converge to \(z^{*}\) with the rate \(_{M}+O(^{2})\), see the Appendix for a review.3

While the condition \(_{M}>0\) is very general and tight, it is not obvious how to control or interpret it. Our purpose with this paper is to explore what this condition entails and to emphasize some of its surprising consequences.

Figure 1: Convergence of gradient methods on a random bilinear game regularized by \(x_{1}^{2}\) for small step-sizes. The fact that \(_{M}\), and so \(r/\), scale linearly with \(\) (for small \(\)) is explained by Prop. 3.1.

The rest of the paper is organized as follows. In Sec. 2 we show that, generically, \(_{M}>0\) as long as the problem has _partial curvature_, i.e. the diagonal blocks of \(M\) are non-zero. In Sec. 3, we study more precisely the case of games where the "interaction" component dominates the "potential" component, i.e., when \(^{2}_{xx}f(z^{*}),^{2}_{yy}f(z^{*})^{2}_{xy}f(z^{*})\). For such games, in a certain random setting, we show that \(_{M}\) scales as the _average_ of the eigenvalues of the potential part, instead of the minimum as an analogy with minimization problems would suggest. In Sec. 4 we consider the computation of mixed Nash equilibria of continuous games using particle methods, a setting where the convergence under partial curvature has a striking consequence. By optimizing over both the weights and supports of the mixed strategies, one obtains dynamics that generically converge faster than fixed-support methods, even when the latter are using the optimal supports.

For ease of exposition, in most of the paper we focus on the local convergence of GF. We discuss the convergence of discrete time algorithms in Sec. 3.2.

### Related work

Throughout this paper, by "convergence" we mean convergence of the last iterate to a (local) NE, while a different line of work also considers convergence of the averaged iterate , and another considers convergence to any critical point . Also to prevent possible confusion, let us mention a related but distinct line of work  that considers using different step-sizes to update the \(x\) and the \(y\) variables. The resulting two-timescale dynamics can be analyzed globally assuming a min-max analog of the Polyak-Lojasiewicz inequality, using quite different considerations than the ones developed in this paper.

Analysis of GDA and PP for SC-SC, bilinear or convex-SC games.The fact that PP converges for SC-SC and bilinear min-max games is well-established since at least ; for a modern reformulation, see e.g. . The convergence of simultaneous GDA for SC-SC games and its divergence for bilinear games is also a classical fact, see e.g. . The cycling behavior of alternating GDA for bilinear games is proved in [15, Theorem 4].

As shown more recently in [13, Appendix G] and [14, Theorem 6], convexity in \(x\), strong concavity in \(y\) and non-degeneracy of the interaction component are in fact sufficient to ensure \(_{M}>0\), and so local convergence of GDA. The setting of the former work corresponds to \(^{2}_{xx}f(z^{*})=0\), \(-^{2}_{yy}f(z^{*}) 0\) and \(^{2}_{xy}f(z^{*})\) full-row-rank, extended in the latter work to \(^{2}_{xx}f(z^{*}) 0\). Those two works also provide bounds on \(_{M}\) for those specific cases in terms of the least eigenvalues of \(-^{2}_{yy}f(z^{*})\) and of \(^{2}_{xy}f(z^{*})^{2}_{xy}f(z^{*})^{}\).

Spectral analysis-based convergence analyses.Our approach to analyzing min-max algorithms is to directly study the properties of the update operator (e.g., of \(T(z)=z-_{x}f\\ -_{y}f(z)\) for simultaneous GDA). Specifically, by a classical result on discrete-time dynamical systems, the local exponential convergence is characterized by the spectral radius of that operator's Jacobian. This approach is used for example in  to analyze the local convergence behavior of alternating GDA with negative momentum, and in  to derive tight convergence bounds - dependent explicitly on \(\) and \((M)\) - for simultaneous GDA and multi-step Extra-Gradient.

Average-case analysis of the (local) convergence rate.In , the authors analyze the convergence of gradient methods for affine operator problems - i.e., for finding \(z\) such that \(M(z-z^{*})=0\) - when \(M\) is a random normal matrix with a known spectral distribution. They derive average-case optimal methods for this setting. Our analysis in Sec. 3 also has an average-case flavor, but our random model is different: we assume that the symmetric \(S\) and antisymmetric parts \(A\) of \(M\) are independent and that \(S A\). In particular we do not require \(M\) to be normal (i.e., \(S\) and \(A\) do not commute a priori, which is the typical case in min-max optimization).

Hypocoercivity.In the context of partial differential equations (PDEs), the phenomenon that a linear PDE \(_{t}u_{t}=-Lu_{t}\) may exhibit linear convergence to \(0\) even when the generator \(L\) is not coercive, is called hypocoercivity and is studied in detail in . This is precisely the infinite-dimensional analog of the phenomenon studied in the present paper: still denoting by \(S,A\) the symmetric resp. antisymmetric parts of \(M\), coercivity of \(L\) corresponds to \(S 0\), while hypocoercivity corresponds to \(_{M}>0\). Specifically,  shows how to construct Lyapunov functions to establish hypocoercivity and convergence rates of certain PDEs, by exploiting properties of the iterated commutators of \(S\) and \(A\). By contrast our focus is on the finite-dimensional case, where it is easier and more natural to directly study the spectrum of \(M\).

### Notation

For any matrix \(T^{d d}\) or \(^{d d}\), denote by \((T)\) its spectrum, i.e., the set of its eigenvalues, and by \((T)=_{(T)}||\) its spectral radius. Recall that the spectral radius is distinct from the operator norm, which is the largest singular value, although they coincide for Hermitian matrices. Denote eigenspaces as \(E_{}(T)=\{z^{d};\;Tz= z\}\) and let \((T)=_{(T)}E_{}(T)\) the set of all (complex) eigenvectors. \(\|\|\) denotes Euclidean or Hermitian norm. For a collection of square matrices (resp. scalars) \((C_{k})_{k}\), \(((C_{k}))\) denotes the (block-)diagonal matrix with blocks (resp. coefficients) \((C_{k})_{k}\).

## 2 Characterization of local convergence

Consider the general smooth min-max game of Equation (1.1) and assume \(M\) is invertible. We decompose \(M\) into its symmetric and antisymmetric parts as

\[M=_{xx}^{2}f&_{xy}^{2}f\\ -_{xy}^{2}f^{}&-_{yy}^{2}f(z^{*}) Q&P\\ -P^{}&R, SQ&0\\ 0^{}&R, A0&P\\ -P^{}&0.\]

By the second-order optimality condition in the definition of NE, \(Q 0\) and \(R 0\).

Following , \(S\) and \(A\) can be thought of intuitively as the "potential" resp. "interaction" (or Hamiltonian) components of the two-player zero-sum game (1.1). Indeed, consider the quadratic game \(_{x^{n}}_{y^{m}}\{ x\\ y^{}^{2}f(z^{*})x\\ y.=x^{}Qx-y^{}Ry+x^{}Py\}\), which is essentially sufficient to understand the local behavior of GF for (1.1) around \(z^{*}\). Then we can interpret the terms in \(Q\) and \(R\) as quadratic potentials to be optimized independently by each player, with the bilinear term in \(P\) capturing all of the interaction between the players.

Partial curvature generically suffices.Let us recall that \(_{M}=_{(M)}()\) governs the local convergence of GF around the local NE \(z^{*}\). It is a general fact that this quantity is nonnegative (the proof is included below). In the following theorem, we give necessary and sufficient conditions for it to be positive, in terms of geometric conditions on \(Q,R\) and \(P\).

**Theorem 2.1**.: _The following conditions are equivalent:_

* \(_{M}>0\)_._
* \((A)\,S=\{0\}\)_._
* _For any eigenvector_ \(x\) _of_ \(PP^{}\) _(i.e., left-singular vector of_ \(P\)_),_ \(x\,Q\) _or_ \(P^{}x\,R\)_._
* _For any eigenvector_ \(y\) _of_ \(P^{}P\) _(i.e., right-singular vector of_ \(P\)_),_ \(Py\,Q\) _or_ \(y\,R\)_._

As a consequence of Thm. 2.1, the condition \(_{M}>0\) holds generically in the following sense: for any fixed \(S 0\), the set of matrices \(P\) such that \(_{M}>0\) is dense and open in \(^{n m}\). In particular, this property holds with probability \(1\) if \(P\) is drawn from an absolutely continuous distribution and is independent from \(Q\) and \(R\), as in the experiment of Fig. 1.

Proof.: Let \((M)\) and \(z^{n+m}\) non-zero such that \(Mz=(S+A)z= z\). Since \(S\) and \(A\) are real and symmetric resp. antisymmetric,

\[Sz} =z^{}S=(z^{}S)^{}=^{}Sz,\;\;\;\;^{}Sz\] \[\;\;\;Az} =z^{}A=(z^{}A)^{}=-^{ }Az,\;\;\;\;^{}Az i.\]

So by taking the real part in \(^{}(S+A)z=\|z\|^{2}\),

\[()\|z\|^{2}=^{}Sz=(z^{})^{}S (z)+(z)^{}S(z) 0\]since \(S=(Q,R) 0\). This shows that \(_{M} 0\). Now let us show the equivalence of the conditions. \((ii)(i)\): By contraposition, suppose there exists \((M)\) with \(()=0\), and let \(z\) non-zero such that \(Mz= z\). Then \(^{}Sz=()\|z\|^{2}=0\), so \(zS\). So \(Mz=Az= z\), and \(z(E_{}(A)S)\{0\}\). \((i)(ii)\): By contraposition, suppose there exists \((A)\) and a non-zero \(z E_{}(A)S\). Since \(A\) is antisymmetric, then \(()=0\). On the other hand, \(Mz=(S+A)z=Az= z\), i.e., \((M)\). So \(_{M}()=0\). \((i)(iii),(iv)\): By contraposition, suppose there exists an eigenvector \(x\) of \(PP^{}\) such that \(xQ\) and \(P^{}xR\), and denote \(\) such that \(PP^{}x=^{2}x\) (since \(PP^{} 0\)). Then \[Mi\ x\\ P^{}x=Q&P\\ -P^{}&Ri\ x\\ P^{}x=^{2}x\\ -i P^{}x=-ii\ x\\ P^{}x\] and so \(-i(M)\). This shows \((i)(iii)\), and \((i)(iv)\) follows analogously. \((iii),(iv)(ii)\): By contraposition, suppose there exists \(=i(A)\) and a non-zero \(z=(x,y) E_{}(A)S\). Expanding the blocks in \(Az= z\), \[Py=i x\\ -P^{}x=i yP^{}Py= ^{2}y\\ PP^{}x=^{2}x.\] Moreover, this implies that \(x=0 y=0\), and since \(z 0\), then both \(x 0\) and \(y 0\). So \(x\) is an eigenvector of \(PP^{}\) and, since \(Sz=0\), \(xQ\) and \(P^{}x=-i yR\), which contradicts \((iii)\). Likewise, \(y\) is an eigenvector of \(P^{}P\) and \(yR\) and \(Py=i xQ\), which contradicts \((iv)\). \(\)

Geometric interpretation using real vectors.We draw the attention of the reader to the fact that \((ii)\) involves complex eigenvectors. For a rephrasing in terms of real objects, note that if \(z E_{i}(A)\) with \(\), then \(A[(z)(z)]=[(z)(z)] 0&\\ -&0\); geometrically, \(F_{i}(A)=((z),(z))\) is a "rotation plane" of the GF for the bilinear game \(_{x}_{y}x^{}Py\), in the sense that the projection of GF on \(F_{i}(A)\) is a circular motion with constant speed \(\). Condition \((ii)\) expresses that for each such \(F_{i}(A)\), there exists an eigenspace \(E_{}(S)\) of \(S\) (for a \(>0\)) that is not orthogonal to it. This causes the GF for \(_{x}_{y}x^{}Qx-y^{}Ry+x^{}Py\) projected on \(F_{i}(A)\) to spiral down to \(0\) instead of cycling around it.

One may naturally wonder whether a notion of non-orthogonality between the potential (\(S\)) and interaction components (\(A\)) can be used to bound the convergence quantitatively; this is developed in the next section in the particular case \(S A\).

## 3 Convergence rate when interaction dominates (\(S A\))

Let us now discuss the case of games with a small symmetric part, that is, whose Jacobian at optimum is \(M_{}=A+ S\) for some symmetric \(S=Q&0\\ 0^{}&R\), antisymmetric \(A=0&P\\ -P^{}&0\) and some small \(>0\). In this section we assume \(n=m\) (the general case is technically more challenging as Prop. 3.1 requires \(A\) to have distinct eigenvalues, which requires \(|n-m| 1\)).

### Convergence rate of Gradient Flow

As discussed previously, the normalized local exponential convergence rate \(r/\) of gradient methods in the asymptotic regime \( 0\) - or equivalently, the convergence rate of GF - for a game with Jacobian at optimum \(M_{}\) is equal to \(_{M_{}}\). We can estimate this quantity using the standard formula for the asymptotic expansion of the eigenvalues of a perturbed matrix, which takes an interesting form in our context.

**Proposition 3.1**.: _Suppose that \(P\) is full-rank and has distinct singular values, and let \(P=U V^{}=_{j=1}^{n}_{j}u_{j}v_{j}^{}\) be its singular value decomposition. Then it holds_

\[_{M_{}}=_{1 j n}u_{j}^{ }Qu_{j}+v_{j}^{}Rv_{j}+O(^{3}).\]

This expansion explains in particular why the normalized convergence rate \(r/_{M_{}}\) is approximately proportional to \(\) in Fig. 1. Interestingly, the error term is \(O(^{3})\), which suggests that the approximation can be reasonably accurate even for quite large values of \(\), as illustrated in Fig. 1c.

Proof.: Here \(M_{0}=A\) has distinct eigenvalues \(\{is_{j},s\{-1,1\},1 j n\}\), with unit-norm eigenvectors \(A-isu_{j}/\\ v_{j}/=is_{j}-isu_{j}/\\ v_{j}/\). By the calculation of the eigenvalue derivatives from , we obtain the following expansion for \((M_{})\):

\[(M_{})=is_{j}+ (u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j})+^{2 }_{(s^{},j^{})(s,j)}-is^{} _{j^{}}}(ss^{}u_{j^{}}^{}Qu_{j}+v_{j^{ }}^{}Rv_{j})^{2}\\ +O(^{3}),\;\;s\{-1,1\},1 j n}.\] (3.1)

Now the zeroth- and second-order terms are all in \(i\), hence the announced expansion for \(_{M_{}}\). 

Estimate of the leading term under a probabilistic model.Assuming the singular vectors \((u_{1},...,u_{n})\), \((v_{1},...,v_{n})\) of \(P\) are distributed uniformly at random - which is the case for example if \(P\) has i.i.d. Gaussian entries by rotational invariance4 -, the leading term in the expansion of \(_{M_{}}\) can be estimated in expectation as follows. The proof is placed in the Appendix, where we also include a high-probability version of the estimate.

**Proposition 3.2**.: _Suppose \(Q,R\) are fixed and \(U,V\) are independently distributed uniformly on the set of \(n n\) orthonormal matrices. Then_

\[(S)}{n}(1-2}{ (S)})[_{1 j  n}u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j}](S)}{n}\]

_where \(\|\|_{F}\) denotes the Frobenius norm. In particular, provided that \((S)}{\|S\|_{F}} 2(1+c)\) for some fixed \(c>0\), we have \([_{1 j n}u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j} ](S)}{n}\) as \(n\)._

Note that \((S)}{\|S\|_{F}}\), which always lies in the interval \([1,]\), is a measure of the effective sparsity of the spectrum of \(S\) (larger meaning less sparse), so the condition \((S)}{\|S\|_{F}} 2(1+c)\) means the spectrum of \(S\) is well spread-out. So the proposition shows that **the exponential convergence rate depends on the _average_ of the eigenvalues of \(S\),** when \( S A\) and the spectrum of \(S\) is well spread-out. This fact should be contrasted with the case of minimization, where the convergence rate scales as the _minimum_ eigenvalue of the Hessian.

Interestingly, when the spectrum of \(S\) is sparse, the typical behavior of the leading term in the expansion of \(_{M_{}}\), \(_{j}u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j}\), is quite different. In this case, that quantity depends on the geometric mean of the non-zero eigenvalues of \(S\), rather than the arithmetic mean, as formalized in the following proposition. The proof is placed in the Appendix, along with a high-probability version of the estimate.

**Proposition 3.3**.: _Suppose \(Q,R\) are fixed and \(U,V\) are independently distributed uniformly on the set of \(n n\) orthonormal matrices. Let \(s_{1}... s_{r}>0=s_{r+1}=...=s_{2n}\) the eigenvalues of \(S\).__Then_

\[[_{j n}u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j}] _{\{1,,r\}}|}{n}n^{- |}}[_{l}s_{l}]^{|}}.\]

_In particular, \([_{j n}u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j}]  n^{--1}\) when \(n\) and \(r\) and \(s^{r}\) are fixed._

Numerically, the quantity \(_{j n}u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j}\) indeed scales as \(n^{--1}\) under the conditions of the proposition, suggesting that our lower estimate could be tight.

### Convergence rate of discrete-time algorithms

Prop. 3.1 gave an expansion of the normalized convergence rate \(r/\) of gradient methods (for a game with Jacobian at optimum \(M_{}\)), non-asymptotically in \(\) and in the asymptotic limit \( 0\). In this subsection, we give expansions of the convergence rate \(r\) that are non-asymptotic in \(\) and \(\).

The algorithms we will consider can be written in the form \(z^{k+1}=T(z^{k})\) with the update operator \(T\) dependent only on \( f\) and on step-size \(\), and satisfying \(z^{*}=T(z^{*})\). It is well-known that local convergence of such methods is determined by \(( T(z^{*}))\), where \( T\) is the Jacobian of \(T\) and \(()\) denotes spectral radius. Namely, if \(( T(z^{*}))<1\) then the iterates converge locally with \(\|z^{k}-z^{*}\|=O((( T(z^{*}))+ )^{k})\), with \(>0\) an arbitrarily small constant [1, Proposition 4.4.1].

In Table 1 we give an expansion for \(( T(z^{*}))\) for three classical gradient methods: simultaneous GDA (Sim-GDA), alternating GDA (Alt-GDA), and Extra-Gradient (EG). Let us clarify immediately that throughout this paper, statements made about "GDA" without further specification apply to both Sim-GDA and Alt-GDA. In the second column we denoted by \(g(z)=_{x}f\\ -_{y}f(z)\) the skewed gradient field of the game, and in the third column we wrote \(M\) instead of \(M_{}\) for concision. In the fourth column, \( i_{j}\) denotes the eigenvalues of \(A\) assumed distinct and \(w_{j}\) are the associated eigenvectors - equivalently, the singular value decomposition of \(P\) is \(P=_{j=1}^{n}_{j}u_{j}v_{j}^{}\) and for each \(j n\), \(_{j}^{}Sw_{j}=_{j+n}^{}Sw_{j+n}= (u_{j}^{}Qu_{j}+v_{j}^{}Rv_{j})\). We refer to the Appendix for the derivation of this table and for explicit bounds on the "\(O()\)" terms.

Informally, as one can directly see from the fourth column, Sim-GDA requires a very small step-size for the first term in \(\) to overcome the terms \(+^{2}_{j}^{2}\), while for EG those terms actually appear with a favorable sign, and Alt-GDA neither benefits nor suffers from those terms. We also see that Alt-GDA is quite faithful to GF, in that their normalized convergence rates coincide up to terms of order \(^{3}+^{4}\). All of these insights are in line with common intuition in the min-max optimization literature , as well as with our numerical experiments for the next section, Fig. 2.

A symmetrized formulation of Alt-GDA.In order to derive the rate for Alt-GDA, we used the following symmetrized formulation of it: we let \((x^{0},y^{}{{2}}})^{d}^{d}\) and

\[ k,&x^{k+1}=x^{k}-_{x}f(x^{k},y^{ k+}{{2}}})\\  k+}{{2}},&y^{k+1}=y^{k}+_{y}f(x^{ k+}{{2}}},y^{k}) k,&x^{k+}{{2}}}= +x^{k}}{2}\\  k+}{{2}},&y^{k+}{{2}}}=+y^{k}}{2}.\]

That is, \(x\) gets updated with the gradient rule at integer time-steps, \(y\) at half-integer time-steps, and we define \(x^{k}\), \(y^{k}\) at non-updating time-steps as the average of the preceding and following updating time-steps. Assuming \(\|_{xx}^{2}f\|_{}^{-1}\|_{yy}^ {2}f\|_{}^{-1}\), we show in the Appendix that \(z^{k+1}\) is indeed

   Algorithm & \(T(z)\) & \( T(z^{*})\) & \(( T(z^{*}))^{2}=_{j 2n}[]\) \\  & & & \(+\,O(^{3}+^{2}^{2})\) \\  Sim-GDA & \(z- g(z)\) & \(I- M\) & \(1-2(_{j}^{}Sw_{j})+^{2}_{j}^{2}\) \\ Alt-GDA & see text & \(I-(I-A)M+O(^{3})\) & \(1-2(_{j}^{}Sw_{j})+O(^{3})\) \\ EG & \(z- g(z- g(z))\) & \(I-(I- M)M\) & \(1-2(_{j}^{}Sw_{j})-^{2}_{j}^{2}+O( ^{3})\) \\   

Table 1: Expansions of \(( T(z^{*}))\) in \(\) and \(\) for classical gradient methodsentirely determined by \(z^{k}=(x^{k},y^{k})\) for each \(k\), and that the associated update operator \(T\) satisfies

\[T(z)=z- g(z)+}{2}A(z)g(z)+O(^{3}\|g(z)\|)  A(z)=}{2}.\]

For comparison, the usual formulation of Alt-GDA considers as the iterates \((^{k},^{k})=(x^{k},y^{k+}{{2}}})\). We emphasize that \((^{k},^{k})\) and \((x^{k},y^{k})\) have the same convergence rate if they converge exponentially, as one can check directly from the definition.

## 4 Illustration: sparse mixed Nash equilibria of continuous games

In this section we apply the above considerations to a particular class of min-max problems, which is of its own interest in game theory. Namely we consider the classical problem of finding the mixed Nash equilibria (MNE) of two-player zero-sum games, that is, given strategy spaces \(\), \(\) and a payoff function \(f:\), solving the min-max problem

\[_{()}\,_{()} \,\{F(,)=_{x,y}[f(x,y)]\}.\]

Here \(()\) denotes the space of probability measures - representing mixed strategies - over \(\). Let us focus on cases where \(\) and \(\) are continuous sets, say, \(==^{1}\) the one-dimensional Euclidean torus,5 and \(f:^{1}^{1}\) is smooth. The above min-max problem is then infinite-dimensional, and algorithms to solve it explicitly must be based on reparameterized formulations. More specifically, suppose that the MNE \((^{*},^{*})\) is unique and "sparse", i.e., has finite supports: \((^{*})=\{x^{*}_{I},1 I N\}\), \((^{*})=\{y^{*}_{J},1 J M\}\) (this is the case for example if \(f\) is a sum of separable functions ).

In this setting there are two natural parameterizations and associated algorithms:

1. If the optimal support points \(\{x^{*}_{I}\}_{I}\), \(\{y^{*}_{J}\}_{J}\) are known, then we may reparameterize by \(=_{I=1}^{N}a_{I}_{x^{*}_{I}}\), \(=_{J=1}^{M}b_{J}_{y^{*}_{J}}\) and optimize over the \(a_{I},b_{J}\). The problem reduces to a constrained bilinear game \[_{a_{N}}\,_{b_{M}}\{F_{1}(a,b)=_{I=1}^{N} _{J=1}^{M}a_{I}b_{J}\;f(x^{*}_{I},y^{*}_{J})=:a^{}Pb\}\] where \(_{N}\) denotes the standard simplex. A classical approach is then to apply Mirror Prox (MP) with entropy link function  (MP is the Bregman-geometry analog of EG).
2. If only the number of optimal support points is known, then we may reparameterize by \(=_{I=1}^{N}a_{I}_{x_{I}}\), \(=_{J=1}^{M}b_{J}_{y_{J}}\) and optimize over both the weights (\(a_{I},b_{J}\)) and the support points (\(x_{I},y_{J}\)). The problem reduces to \[_{(a,x)_{N}(^{1})^{N}}\;\;_{(b,y)_{ M}(^{1})^{M}}\;\;\{F_{2}(a,x,b,y)=_{I=1}^{N}_{J=1}^{M}a_{I }b_{J}\;f(x_{I},y_{J})\}.\] A possible approach is to iteratively update (simultaneously) the \(a,b\) using MP steps with step-size \(\) and the \(x,y\) using EG steps with step-size \(\), for some parameter \(>0\). This algorithm is called Conic Particle Mirror Prox in , but for concision we will refer to it simply as "EG" in this section. Note that the main challenge in that reference is to deal with the case where \(N\) and \(M\) are unknown, but here we assume they are known for the sake of simplicity.

In Fig. 2, we show the dependency on \(\) and \(\) of the local convergence rate of MP and EG, as well as that of the analogs of Sim-GDA and Alt-GDA and GF for the problem \(_{(a,x)}_{(b,y)}F_{2}(a,x,b,y)\) in order to illustrate the insights from Sec. 3.2. We used a randomly generated payoff function \(f\), and the convergence is measured by the iterates' \(_{2}\) distance to the solution; see the Appendix for details.

MP (the algorithm based on the reparameterization \(F_{1}\)) converges to the MNE for any small enough \(\) with an exponential rate at least proportional to \(^{2}\), and this scaling is tight numerically (green dots in Fig. 1(b)). Its explicit variant (Mirror Descent-Ascent) and its continuous-time flow are known to diverge for any \(\).

EG is known to converge locally to the MNE for any small enough \(\) (and any \(>0\)) with an exponential rate at least proportional to \(^{2}\), despite the non-convexity of \(F_{2}\), under some non-degeneracy assumptions [13, Sec. 3.1]. However numerically the convergence rate of EG typically scales as \(\), not \(^{2}\) (orange dots in Fig. 1(b)) - a fact which we will explain below. The explicit variant of EG and its continuous-time flow have not previously been analyzed; the discussion below will give a characterization of when they converge locally.

Note that, at least for the particular \(f\) and \(\) used for Fig. 1(b), EG converges locally faster than MP for the same \(\) (in number of iterations, the per-iteration costs differing only by a constant factor), even though the former does not use the knowledge of the \(\{x_{I}^{*}\}_{I}\), \(\{y_{J}^{*}\}\)! In other words, even when the optimal support points are known, it is beneficial to use the overparameterized formulation \(F_{2}\) where we also vary the support points.

Overparameterization induces partial curvature.Let us inspect the "Jacobians" at optimum for the two dynamics, MP vs. EG with parameter \(\). Due to the simplex constraints and the non-Euclidean nature of the updates for \(a,b\), the relevant matrices are \(M_{}\) and \(M_{}\) defined below, in the sense that the exponential convergence rate of each algorithm is \(_{M}+O(^{2})\) (see the Appendix). Namely, omitting half of the antisymmetric off-diagonals for readability,

\[M_{}=&_{a}D_{a}PD_{b}_{b}^{}\\ -(*)^{}&\]

where \(D_{a}=(})\) (square roots being taken component-wise) and \(_{a}^{(N-1) N}\) is any matrix such that \(_{a}_{a}^{}=I_{N-1}\) and \(_{a}^{}_{a}=I_{N}-}}^{}\), and likewise for \(D_{b}\) and \(_{b}^{(M-1) M}\); and for EG,

\[M_{}=&&_{a}D_{a}PD_{b}_{b}^{ }&\;_{a}D_{a}[_{y}P]D_{b}\\ &(_{xx}^{2}Pb^{*})&D_{a}[ _{x}P]D_{b}_{b}^{}& D_{a}[_{xy}^{2}P]D_{b}\\ -(*)^{}&-(*)^{}&&\\ -(*)^{}&-(*)^{}&&-(_{yy}^{2}P^{ }a^{*})\]

where \([_{x}P]_{IJ}=_{x}f(x_{I}^{*},y_{J}^{*})\), and likewise for \(_{y}P\), \(_{xx}^{2}P\), \(_{yy}^{2}P\), \(_{xy}^{2}P\).

For MP, it is clear that the equivalent conditions of Thm. 2.1 are violated for any payoff function \(f\), and so \(_{M_{}}=0\). For EG, depending on \(f\) and \(\), they may or may not be violated. For all of the random payoff functions we considered in our experiments, we observed that \(_{M_{}}>0\), suggesting

Figure 2: Observed local convergence rates \(r\) (i.e., \(\|z^{k}-z^{*}\|=((1-r)^{k})\)) for various conic particle methods using step-size \(\) for the weights \((a,b)\) and \(\) for the positions \((x,y)\) and for a fixed random draw of \(f\). (left) Fixing \(=10^{-2}\), we observe a rate for GF (we plot \(_{}\)) scaling as \(^{2}\) as predicted in Prop. 4.1. Interestingly, Alt-GDA has exactly the same behavior, while the behavior of Sim-GDA and EG differ for small \(\), due to the corrective terms shown in Table 1. (right) Fixing \(=10^{-2}\), we observe a rate scaling as \(\) for EG and its variants, and as \(^{2}\) for MP; the convergence of EG is mostly faster than MP.

that the conditions hold generically. They are violated for certain \(f\)'s however, as shown in the Appendix, so that the scaling in \(^{2}\) of the convergence rate proved in  is tight in the worst case.

More precisely as we show in the next proposition, assuming that the blocks of \(M_{}\) are in general position, we expect \(_{M_{}}\) to scale as \(^{2}\), which is indeed observed in the numerical experiment reported in Fig. 1(a). The proof, placed in the Appendix, relies on the same tools as Prop. 3.1, that is, on the asymptotic expansions of the eigenvalues of perturbed matrices.

**Proposition 4.1**.: _Let \(S_{2}\) symmetric and \(A_{0},A_{1},A_{2}\) antisymmetric real matrices of the form_

\[S_{2}=[&\\ &&\\ &*],\,A_{0}=[| []{c}*&\\ &\\ *&&\\ &0],\,A_{1}=[& *\\ &\\ &*\\ &],\,A_{2}=[| &\\ &*\\ &*\\ &*]]\]

_and \(M_{}= S_{2}+A_{0}+A_{1}+ A_{2}\) for all \(>0\). Then \(_{M_{}}=O(^{2})\) as \( 0\)._

## 5 Conclusion

We have investigated the local convergence of gradient methods for min-max games and found that they converge generically under partial curvature. In more specific settings, we have obtained quantitative estimates of the local convergence rate which exhibit the _average_ of the eigenvalues of \(S\) as the driving quantity for typical problems. For the computation of mixed Nash equilibria of continuous games, this leads to a behavior of conic particle gradient methods that is more favorable than that described by the worst-case bounds.

More generally, our analysis leads to the following insights: (i) worst-case bounds might be looser in min-max optimization (compared to minimization) as they fail to capture the interplay between interaction and potential parts; (ii) the addition of new degrees of freedom with curvature typically accelerates the local convergence, as we illustrated in Sec. 4.

We note that the phenomenon described in this paper is fundamentally a consequence of the fact that the skewed gradient field's Jacobian at optimum has a positive-semidefinite symmetric part. This property is satisfied at local Nash equilibria of min-max games, i.e., of two-player zero-sum differentiable games, but is not true for general differentiable games.