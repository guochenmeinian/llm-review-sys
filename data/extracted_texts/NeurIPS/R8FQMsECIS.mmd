# ORDerly: Datasets and benchmarks for chemical reaction data

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Machine learning has the potential to provide tremendous value to the life sciences by providing models that aid in the discovery of new molecules and reduce the time for new products to come to market. Chemical reactions play a significant role in these fields, but there is a lack of high-quality open-source chemical reaction datasets for training ML models. Herein, we present ORDerly, an open-source Python package for customizable and reproducible preparation of reaction data stored in accordance with the increasingly popular Open Reaction Database (ORD) schema. We use ORDerly to clean US patent data stored in ORD and generate datasets for forward prediction, retrosynthesis, as well as the first benchmark for reaction condition prediction. We train neural networks on datasets generated with ORDerly for condition prediction and show that datasets missing key cleaning steps can lead to silently overinflated performance metrics. Additionally, we train transformers for forward and retrosynthesis prediction and demonstrate how non-patent data can be used to evaluate model generalisation. By providing a customizable open-source solution for cleaning and preparing large chemical reaction data, ORDerly is poised to push forward the boundaries of machine learning applications in chemistry.

## 1 Introduction

Advancements in chemistry and material science hinge on the availability of high-quality chemical reaction data, and the advent of machine learning (ML) for science has highlighted the value that data can bring to chemistry. One important application is in the pharmaceutical industry, where figuring out _how_ to make novel molecules remains a significant bottleneck, causing delays in the "make" step of the "design, make, test" cycle . Making a molecule (product) includes predicting the reaction pathway (retrosynthesis) and suitable reaction conditions (e.g. solvents and reagents), and optimising for one or more outcomes such as reaction yield, selectivity, and conversion. ML is well suited to assist with these tasks, with a range of tools being developed for forward reaction prediction [2; 3; 4], retrosynthesis [5; 6; 7; 8; 9], condition prediction [10; 11; 12], yield prediction [13; 14; 15], and closed-loop optimisation [16; 17; 18].

Building reaction prediction tools requires access to large datasets for training. Historically, researchers have accessed proprietary in-house datasets or acquired the data through commercial databases such as Reaxys . The advantage of commercial databases is both the scale of the datasets available (often millions of reactions) and the annotation already completed by the publishers. Yet, these datasets are not freely available to ML practitioners, stymieing advances in reaction condition prediction in both academia and industry.

Recently, efforts have been made to create openly-accessible databases for chemical reaction data. In particular, the Open Reaction Database (ORD)  is promising due to its exhaustive schema for describing chemical reaction data and breadth of data already incorporated. Yet, many of the datasets in ORD require further processing before they can be used in ML pipelines, preventing practical use. This is especially true for the largest dataset in ORD extracted from the US patent literature (the "USPTO dataset" ). In this work, we endeavor to close this gap.

Herein, we present ORDerly, a new framework for extracting and cleaning data from ORD, accompanied by datasets for three reaction related tasks: retrosynthesis, forward, and condition prediction. By offering an open-source and customizable solution for cleaning chemical reaction data, ORDerly aims to contribute to the development of advanced ML models in chemistry and material science.

## 2 Problem formulation

As noted by Meng _et al_. , reaction related tasks operate on molecules. There are numerous machine readable molecular representations , including molecular graphs and strings, and in this work molecules are represented as SMILES strings. Each character \(m_{i}\) in a SMILES string represents an atom or a molecular feature (bond, branch, ring closure): \( m_{1},m_{2},m_{3},,m_{L}\), where \(L\) is the total number of characters in the string. Molecules can take on one of three roles in a reaction: reactant, product, or agent. A reaction \(\) transforms \(N\) reactant molecules (sometimes called educs) \(\{_{i}^{}\}_{i=1}^{N}\) by breaking and forming bonds to form \(M\) new product molecules \(\{_{i}^{}\}_{i=1}^{M}\) using \(K\) agent molecules \(\{_{i}^{}\}_{i=1}^{K}\). Agents are helper molecules that enable the reaction to proceed (e.g., solvents, catalysts).

\[:\{_{i}^{}\}_{i=1}^{N},\{_{i}^{A} \}_{i=1}^{K}\{_{i}^{P}\}_{i=1}^{M},\{_{i}^{A }\}_{i=1}^{K}\] (1)

Given this view of reactions, we define three different reaction related tasks in this work.

**Forward prediction** is the task of predicting the product of a reaction \(^{}\) given its reactants \(\{_{i}^{}\}_{i=1}^{N}\) and, potentially, agents \(\{_{i}^{}\}_{i=1}^{K}\). Probabilistically, the task is to predict the distribution \(p(^{}|\{M_{i}^{}\}_{i=1}^{N})\). While experimental evaluation in a wet lab requires expert chemists and is a time intense task, reaction outcome prediction can help as a tool to evaluate the quality of a predicted retrosynthetic route (i.e., the probability that the reaction predicted by the single-step retrosynthesis model leads to the desired product) .

**Retrosynthesis** is the task of designing a sequence of \(Z\) reactions \(_{1},_{2},_{3},,_{Z}\) that transform a set of readily available reactant molecules \(\{_{i}^{_{1}}\}_{i=1}^{N}\) to a desired product(s) \(\{_{i}^{_{Z}}\}_{i=1}^{M_{Z}}\). Retrosynthesis is done in the reverse direction by starting with the desired product(s) \(\{_{i}^{_{Z}}\}_{i=1}^{M_{Z}}\) and predicting reactants \(\{_{i}^{_{Z}}\}_{i=1}^{N_{Z}}\) that would react to form the desired product(s). The predicted

Figure 1: Overview of ORDerly.

reactants \(\{_{i}^{_{Z}}\}_{i=1}^{N_{Z}}\) then become the products of the next reaction to be predicted \(\{_{i}^{_{Z-1}}\}_{i=1}^{M_{Z-1}}\). This process is repeated until a readily available set of starting reactant molecules are predicted \(\{_{i}^{_{1}}\}_{i=1}^{N}\). Therefore, the key machine learning task, often called single-step retrosynthesis, is predicting the distribution \(p(\{_{i}^{_{j}}\}_{i=1}^{N_{j}})|^{P_{j}})\) or the set of reactants that could lead to a given product(s) \(\{_{i}^{_{j}}\}_{i=1}^{M_{j}}\). Single-step retrosynthesis can be seen as the inverse of forward prediction.

**Condition prediction** is the task of predicting the distribution \(p(\{_{i}^{}\}_{i=1}^{K}|\{M_{i}^{}\}_{i=1}^{N },^{})\) (i.e., the agents for a reaction given reactants and product). In addition to agents, some models can predict continuous variables such as reaction temperature and concentrations of reactants and agents .

## 3 Related work

### Chemical reaction cleaning tools

Existing tools for cleaning reaction data are primarily targeted at retrosynthesis and forward prediction tasks [25; 26; 27; 28] and have somewhat limited extensibility, given that they are built to take as inputs CSV files or the stationary XML files of the US patent (USPTO) dataset  instead of the outputs of continuously updated databases such as ORD . Furthermore, in the original publications, there is little to no discussion of how decisions made during cleaning (e.g. restricting the number of components in a reaction or the minimum frequency of occurrence) impact the datasets being cleaned or performance of models trained on the datasets. We believe that this is in part due to data cleaning historically being viewed as a "low value" task, and therefore not adequately discussed and published on.

USPTO, being the largest open-source chemical reaction dataset, has been cleaned a number of times for different learning tasks. For example, the USPTO-50K [29; 30] and USPTO-MIT datasets  are commonly used for benchmarking single-step retrosynthesis and forward predictions models1, and these benchmarks are available in aggregate benchmarking sets such as the Therapeutics Data Commons (TDC) . However, the code used to process the raw data to generate the aforementioned USPTO benchmarks was not published and, there is no publicly available benchmark for reaction condition prediction extracted from these datasets.

## 4 Dataset generation

ORDerly extracts data directly from ORD . Even though the data in ORD is stored in accordance with a structured schema, we found that further effort is required to transform the labeled data into ML-ready datasets. Therefore, ORDerly is centered around a data extraction script and a data cleaning script, both of which take numerous arguments that customize the operations being performed.

### Extraction and cleaning methodology

The extraction script allows the user to choose whether reaction roles should be assigned using the labeling in ORD or using chemically-informed logic on the atom-mapped reaction string (if available). It also enables specification of data source (e.g., USPTO or non-USPTO), allowing users to train models with data from one source and test the performance with data from another source. Creating test sets from different data sources is a robust way to evaluate generalization performance.

We chose cleaning operations motivated by first-principles understanding of chemistry. Cleaning operations on the chemical reaction data include: (1) Restricting the number of reactants and product, preventing multi-step reactions being included in the datset; (2) Ensuring that all molecules can be sanitized by the cheminformatics package RDKit ; (3) Restricting the maximum number of unique catalysts, solvents, and reagents in a reaction based on commonly used experimental amounts; (4) Frequency filtering to remove outliers; (5) Sanity checking the yield (\(0\% yield 100\%\)), temperature, and pressure; (6) Removing duplicates, and finally; (7) Applying a random split to create training/validation/test sets, carefully ensuring that any inputs present in the train set (i.e. reactants and products for reaction condition prediction) are not also present in the test set.

**Computational details:** All extraction/cleaning operations described in this section were performed using a 2022 Mac Studio with an Apple M1 Max chip and 32GB memory. In ORD there are roughly 1.7 million reactions from US patents (USPTO) and 91k reactions that are not from US patents. For the USPTO dataset extraction and sanitation took roughly 35 minutes, while the cleaning steps took 8 minutes.

### Reaction role assignment

We experimented with two approaches to assigning roles to the molecules found in a reaction (e.g., whether a molecule is a reactant or an agent): trusting the labeling of molecules in ORD (referred to as "labeling") or applying chemical reaction logic to identify the role of different molecules from the reaction string (referred to as "rxn string" or "reaction string"). Our reaction logic identified reactants (molecules that contribute atoms to the product(s)) and spectator molecules (molecules that do not contribute atoms to the product(s)) based on the atom-mapping and their position in the reaction SMILES string. Solvents were identified in the list of spectator molecules by cross checking against a list of solvents compiled from prior research (see Appendix A.1.1), while all other spectator molecules are marked as agents. Catalysts were not separated into their own category since identifying catalysts can be quite subtle (especially with organocatalysis), and few reactions in the reaction string datasets contained transition metals.

### Frequency filtering

Removing rare molecules can increase the signal to noise ratio in a dataset by removing outliers. In this work, we investigated two different strategies for filtering spectator molecules based on their frequency: deleting reactions with rare spectator molecules (rare\(\)delete rxn) or keeping the reactions but mapping the rare molecules to an "other" category (rare\(\)"other") (see Figure 2). We conducted experiments with both the rare\(\)delete rxn and rare\(\)"other" strategies for the task of condition prediction. The frequency threshold was set at 100 in line with previous research , though the sensitivity of dataset size to frequency threshold was still investigated (see Appendix C.2). Deleting reactions with rare molecules may create a more cohesive dataset by removing outliers, while renaming rare molecules "other" allows more reactions to be kept, offering more training data for the model.

Figure 2: We present two different approaches for handling rare molecules. Rare \(\) ”other” is investigated as a strategy to avoid deleting reactions with rare molecules.

### Dataset composition

Datasets generated with ORDerly have the following column groups: Reaction SMILES (string), is_mapped (bool), Reactants & products (SMILES strings), Solvents and agents (rxn string data), or solvents, catalysts, and reagents (labeling data) (SMILES strings), Temperature, reaction time, yield (floats), Procedure details (string), Grant date (datetime), date of experiment (datetime), file name (string).

Three new benchmarks were created from the USPTO dataset: ORDerly-forward for forward prediction, ORDerly-retro for retrosynthesis prediction, and ORDerly-condition for reaction condition prediction. Several additional datasets were created, including datasets from non-USPTO data in ORD and datasets to investigate data labeling and frequency filtering. An overview of the datasets and benchmarks showing how each cleaning step impacted the dataset size can be found in Table 1. The datasets are freely available and can be downloaded immediately from FigShare or regenerated using the code in the ORDerly Github repository.

## 5 Results and discussion

Experimental evaluation of the ORDerly-forward and ORDerly-retro benchmarks was performed using the Molecular Transformer architecture built by Schwaller _et al._. To switch from forward prediction to retrosynthesis prediction no changes to the transformer architecture were necessary, only the data was changed. The ORDerly-condition benchmark was evaluated together with the impact of different approaches to reaction role assignment and frequency filtering using the neural network architecture built by Gao _et al._ with only minor modifications.

### Forward and retrosynthesis prediction with transformers

Transformers were applied to two tasks: forward prediction (predicting products given reactants, solvents, and agents) and retrosynthesis (predicting reactants given a product). For the task of forward reaction prediction two different modes were tested: mixing the reactants, solvents, and agents, or weakly separating the reactants from the solvents and agents with a ">" token. Forward prediction with mixed inputs is a more difficult task, since it is less obvious which atoms (characters) will appear in the product.

For both forward and retrosynthesis prediction the order of the molecules was randomized, and the dataset was augmented by replacing each SMILES string in the reaction with a random equivalent

   Dataset name: & ORDerly- & ORDerly- & ORDerly- & ORDerly- & Non- \\  & condition & condition & forward & retro & USPTO- \\  & (labeling) & (rxn string) & & & forward \\  Full dataset & 1,771,032 & 1,771,032 & 1,771,032 & 1,771,032 & 91,067 \\ Too many reactants & 1,470,060 & 1,631,394 & 1,743,585 & 1,631,394 & 43,845 \\ Too many products & 1,329,399 & 1,593,196 & 1,740,655 & 1,593,196 & 40,770 \\ Too many solvents & 1,222,381 & 1,388,312 & 1,689,445 & NA & 36,522 \\ Too many agents & 1,202,790 & 1,279,833 & 1,550,800 & NA & 31,187 \\ No reactants/products & 1,202,758 & 1,262,333 & 1,533,680 & 1,567,697 & 31,095 \\ No solvents & 870,888 & 950,189 & NA & NA & NA \\ No agents & 135,139 & 690,234 & NA & NA & NA \\ Inconsistent yields & 126,948 & 658,071 & NA & NA & NA \\ Dropping duplicates & 76,634 & 392,996 & 919,231 & 941,566 & 28,496 \\ Frequency filtering & 75,033 & 356,906 & NA & NA & NA \\   

Table 1: Number of reactions left in each dataset after cleaning. A description of each dataset can be found in section 4. Note that the actual number of reactions used for training will differ from the dataset size shown below due to train/test splits and augmentation. Non-USPTO-retro had a final dataset size of 20,830 and was cleaned in the same way as ORDerly-retro.

SMILES string (thus doubling the dataset size), before finally being tokenized . Performance metrics are reported in Table 2, showing that across all tasks only a small percentage of the generated SMILES strings are invalid.

On the forward prediction tasks, the accuracies achieved are similar (albeit slightly lower) to the accuracies reported by by Schwaller et al.  (88-90% top-1 accuracy when trained on the USPTO_MIT  dataset), though the accuracies are not directly comparable since different subsets of USPTO were used. As expected, the performance with separated agents is higher than mixed, since it is an easier task, and it is encouraging to see that the models get stereochemical information correct most of the time. Accuracy with the retrosynthesis model on the held out test set was roughly 50%, which is similar previous work on retrosynthesis . It is interesting that prediction accuracy on the non-USPTO data was similar on the forward prediction tasks, but markedly worse on the retrosynthesis task.

**Computational details:** The transformer models were trained for around 35 hours (roughly 600 epochs) on a T4 cloud GPU instance provided by lightning.ai. Evaluation was done with the final model checkpoint.

### Reaction condition prediction with neural networks

The reaction condition prediction model used in this work predicts five categorical variables: two solvents and three agents. These five molecules form a set (order invariant), though the loss function in the model used to predict the molecules considers them sequentially (with order) since this was found to work better in practice . The metric used to evaluate the accuracy of the model should be order invariant, since the problem is order invariant, and for this reason the accuracy metrics used are top-1 (see appendix B) and top-3 (see Table 3) exact match combination accuracy for each type of component (i.e., solvent, agent). Beam search was used to identify the top-3 highest probability sets of reaction conditions. The top-3 accuracy was compared to the baseline predictive accuracy of simply predicting on the test set the most common molecules found in the train set.

Additionally, we define a metric inspired by Maser _et al._ called the average improvement over baseline (AIB%):

\[AIB\%=-A_{b}}{1-A_{b}}*100\] (2)

where \(A_{m}\) is the exact match combination accuracy of the model and \(A_{b}\) is the exact match combination accuracy of choosing the top 3 most common values of a component in the respective train set.

Table 3 shows the predictive performance on the test set using four different flavours of the ORDerly-condition benchmark. All models show an improvement over the frequency informed baseline.

   Test sets: &  &  \\   & Invalid & Accuracy & Accuracy & Invalid & Accuracy & Accuracy \\ Tasks & SMILES & (with SC) & (w/o SC) & SMILES & (with SC) & (w/o SC) \\  Forward (separated) & 0.46 & 82.18 & 84.31 & 0.31 & 82.61 & 83.62 \\ Forward (mixed) & 0.47 & 80.79 & 82.86 & 0.31 & 82.61 & 83.62 \\ Retrosynthesis & 0.25 & 49.96 & 50.99 & 0.09 & 42.28 & 42.47 \\   

Table 2: Test performance with Molecular Transformer on forward prediction and retrosynthesis (%). The first column shows the percentage of invalid SMILES strings produced by the transformer (lower is better), while the second and third column show the top-1 accuracy with and without consideration of stereochemistry (SC), respectively (higher is better).

The performance of the labeling datasets at first appears to be better than those that use our custom logic to extract reaction components from the reaction string. However, as shown in Figure 5, many of the reactions in datasets where we trust the labeling in ORD have more than three reactants, while most reactions in organic chemistry only have two reactants. Upon manual inspection, we found that many agents were mislabeled as reactants and, therefore, the prediction problem was made significantly easier. This insight is confirmed in Table 4; there are fewer unique solvents and agents and a higher density of null components when using the ORD labeling instead of the reaction string. This discrepancy demonstrates that naive creation of datasets based on ORD can lead to inflated performance metrics. In dealing with rare spectator molecules to avoid sparse OHE (see Table 1) we found that rare \(\) delete rxn strategy performed better in practice. Therefore the ORDerly-condition benchmark uses the reaction string to assign reaction roles with the rare \(\) delete rxn strategy.

For the datasets that extract the components from the reaction string, overall top-3 accuracy is less than 25% across solvents and agents. While not directly comparable, our overall accuracy is lower than what Gao _et al._ achieved with 50.1% top-3 accuracy across catalysts, solvents and agents. However, Gao _et al._ trained on approximately ten million reactions, while we train on less than four percent of that (\(\)350k). As shown in Figure 3, we see consistent increases in AIB (%) with the number of data points for the dataset which uses reaction strings and deletes rare reactions, and this scaling performance indicates that as ORD grows, better performance could be achieved, even with potentially fewer data points than used in the paper by Gao _et al._

**Computational details:** These models were trained on an A10G cloud GPU instance provided by lightning.ai for 100 epochs to minimize cross entropy loss for each reaction component. The best model by validation loss was chosen for evaluation.

## 6 Technical limitations

### Component labeling

Identifying the role of molecules in a reaction provides crucial context to machine learning models, and this identification could be improved with better atom-mapping . However, an atom-mapping algorithm was not integrated into ORDerly to keep ORDerly lightweight. Even with perfect atom-mapping reaction role identification  can be challenging since the role of a molecule depends

    &  &  \\  Reactants & 40,020 & 0 & 25.7\% & 317,184 & 0 & 18.4\% \\ Products & 38,816 & 0 & 0.0\% & 382,850 & 0 & 0.0\% \\ Solvents & 29 & 204 & 40.0\% & 85 & 313 & 28.0\% \\ Agents & 48 & 447 & 56.2\% & 255 & 11,945 & 37.0\% \\   

Table 4: Diversity in the datasets. Frequency filtering was applied for the solvents and agents to create a more dense one-hot encoding. Columns: Number of unique molecules with a frequency above the threshold; number of unique molecules with a frequency below the threshold; percentage of the dataset that is None.

   Datasets: & labeling & labeling & reaction string & reaction string \\  & rare\(\)”other” & rare\(\)delete rxn & rare\(\)”other” & rare\(\)delete rxn \\ Solvents & 47 / 58 / 21\% & 50 / 61 / 22\% & 23 / 42 / 26\% & 24 / 45 / 28\% \\ Agents & 54 / 70 / 35\% & 58 / 72 / 32\% & 19 / 39 / 25\% & 21 / 42 / 27\% \\ Solvents \& Agents & 31 / 44 / 19\% & 33 / 47 / 21\% & 4 / 21 / 18\% & 5 / 24 / 21\% \\   

Table 3: Top-3 metrics on condition prediction with the model architecture of Gao et al. : frequency informed guess accuracy // model prediction accuracy // AIB%.

on the context. Reaction roles can more easily be identified when only considering one reaction class at , since this allows the mechanistic details of the reaction class [36; 37; 38] to be considered. Handling large and diverse datasets inevitably requires generalizations that may result in contradictions upon a more fine-grained inspection.

### Order invariance

Although order of addition may play a role in wet lab chemistry, reaction prediction tasks are often cast as order invariant, where the goal is to predict a set of molecules. However, both of the architectures used for experimental validation of the ORDerly datasets are not agnostic to the ordering of the targets, since the neural networks used predict one molecule at a time in the OHE, and the transformers used predict one token at a time. Incorporating order invariance (and canonicalization) of the molecules into the loss calculation during training may allow for better generalisability of the predictive models, and is an exciting area for further study. It is worth noting that the evaluation metrics used throughout are order invariant.

## 7 Conclusions

In this work, we presented ORDerly, an open-source framework for preparing chemical reaction data stored in the Open Reaction Database (ORD) for machine learning applications. ORDerly was used to generate benchmark datasets for forward prediction (ORDerly-forward), retrosynthesis (ORDerly-retro), and condition prediction (ORDerly-condition) based on US patent data. Transformer models were trained on the forward prediction and retrosynthesis datasets, and they were found to only generate invalid SMILES strings very infrequently, while also achieving similar test accuracy to that found in the literature on a held-out set of US patents. To further investigate model generalisation ORDerly was used to generate test sets from all non-patent data from ORD, and for the forward prediction task the accuracy was comparable, while the accuracy was slightly lower for the retrosynthesis task. The condition prediction task was used to investigate different strategies for assigning reaction roles and frequency filtering of the spectator molecules. When building datasets for condition prediction using the labeling in ORD, we found contamination of the inputs (reactants) with the outputs (agents), resulting in a problem that was unrealistically easy. We therefore chose to use chemically informed logic to better assign reaction roles for the ORDerly-condition benchmark.

All benchmarks and datasets experimented with in this work, as well as the code used to generate them, are freely available online, and we hope the benchmarks will make reaction prediction tasks more accessible. ORDerly presents a fully open-source pipeline to go from raw ORD data to a fully trained condition prediction model, allowing for an avenue to leverage the growing contributions to open source chemistry.

Figure 3: Scaling behaviour of different datasets with respect to overall top-3 AIB (%) for all solvents and agents (third row from Table 3.)