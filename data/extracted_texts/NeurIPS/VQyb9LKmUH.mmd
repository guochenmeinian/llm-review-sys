# A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning

Yuanning Cui\({}^{}\), Zequn Sun\({}^{}\), Wei Hu\({}^{}\)

\({}^{}\)State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China

\({}^{}\)National Institute of Healthcare Data Science, Nanjing University, Nanjing, China

yncui.nju@gmail.com, {sunzq, whu}@nju.edu.cn

Corresponding author

###### Abstract

Extensive knowledge graphs (KGs) have been constructed to facilitate knowledge-driven tasks across various scenarios. However, existing work usually develops separate reasoning models for different KGs, lacking the ability to generalize and transfer knowledge across diverse KGs and reasoning settings. In this paper, we propose a prompt-based KG foundation model via in-context learning, namely **KG-ICL**, to achieve a universal reasoning ability. Specifically, we introduce a prompt graph centered with a query-related example fact as context to understand the query relation. To encode prompt graphs with the generalization ability to unseen entities and relations in queries, we first propose a unified tokenizer that maps entities and relations in prompt graphs to predefined tokens. Then, we propose two message passing neural networks to perform prompt encoding and KG reasoning, respectively. We conduct evaluation on 43 different KGs in both transductive and inductive settings. Results indicate that the proposed KG-ICL outperforms baselines on most datasets, showcasing its outstanding generalization and universal reasoning capabilities. The source code is accessible on GitHub: https://github.com/nju-websoft/KG-ICL.

## 1 Introduction

Reasoning on knowledge graphs (KGs) involves inferring new relational facts from existing ones. Early related work primarily focuses on reasoning over a static KG in the transductive setting, but lacks the generalization ability to handle new entities or relations in the KG. Recent research [1; 2; 3; 4] considers the relational patterns between seen and unseen entities, enabling inductive reasoning. However, these methods still lack the transferability to reason over unseen KGs due to the unshared and unlinked entity and relation vocabularies between the pre-trained KG and unseen KGs.

The primary challenge in generalizing to new entities, relations, and even different KGs lies in how to represent such unseen data. Some methods [1; 2; 3; 4] aggregate query-conditioned relational structures to represent entities. They can conduct inductive reasoning over unseen entities using these relative entity representations without the need of pre-trained entity embeddings. However, these methods cannot reason over unseen relations. To resolve this issue, some recent methods [5; 6] develop relative relation representations. They model relation interactions using a query-conditioned relation graph, where each node represents a relation and an edge indicates that the linked two relations share a subject or object entity in the KG. They conduct message passing on the query-conditioned relation graph to represent relations.

However, the relation graph only describes the connectivity of relations in the KG, with less attention to the local context of the entity and relation in a query. As a result, these methods usually fail togenerate discriminative relation representations. For example, to infer the query relation parentOf, the most relevant relation is coupleOf. While in the KG, since every student has parents and most teachers are parents, the relation graph would also contain edges "parentOf\(\) teach" and "teach\(\) parentOf". The relation teach appears as noise in representing parentOf, which may mislead the model, resulting in prediction failures. This inspires us to capture the local contexts and highlight the important relations relevant to queries, rather than relying on a global relation graph.

In this paper, we propose a novel KG reasoning foundation model with in-context learning, namely KG-ICL. In-context learning is a method that allows pre-trained models to learn tasks based on only a few examples without updating model parameters. The extraordinary success of in-context learning in language modeling  hinges on three crucial fundamentals: prompt design, unified tokenization, as well as contextual understanding and utilization.

The art of prompt design lies in highlighting task-critical information. We construct a prompt graph to model query-related contexts, which starts with an example fact about the query relation, i.e., (subject, query relation, object). We consider two types of contexts as prompts. The first is entity context, which includes the neighboring entities of the example subject and object. The second is relation context, which considers relational paths between the subject and object entities. Thus, the node set of our prompt graph includes the neighbors of the example subject and object, as well as the entities within the paths connecting the subject and object in the KG. We utilize the induced subgraph of these entities as a prompt graph.

Then, we design a unified tokenizer that is applicable to various prompt graphs. The key challenge is that the entities and relations usually vary across different KGs [8; 9], and this issue extends to prompt graphs as well. Conventional KG reasoning models [10; 11; 12; 13; 14] merely learn an individual embedding for each entity or relation, resulting in the inability to reason over unseen KGs. We extend the entity labeling method of GraIL  to relations, proposing a unified tokenizer for various prompt graphs. Given a query relation and its prompt graph, we first group the involved entities based on the lengths of their shortest path to the example subject and object entities. Similarly, we categorize relations into two classes depending on whether they represent query relations. Finally, the entities or relations in the same group will be mapped to the same token. As a result, prompt graphs from different KGs are described in "the same language".

Given the above prompt graph and unified tokenizer, we propose two message passing neural networks as the prompt encoder and KG reasoner, respectively. The input of the prompt encoder is the prompt graph and the learnable token representations. At each layer of prompt encoding, we introduce an entity-centric and a relation-centric aggregation. Notably, in relation-centric aggregation, we treat relations as special nodes and update their representations by aggregating messages from facts containing them. After prompt encoding, we read the relation representations from the prompt graphs to support KG encoding. At the beginning of KG encoding, we initialize the relation representations in the KG as the prompt relation representations. As for entities, we initialize the subject entity as the query relation representation, and other entities are initialized as zero vectors. After performing message passing over the KG, we score all entities based on the output entity representations.

We conduct extensive experiments on 43 datasets to validate the effectiveness of our model. The experimental results indicate that our model not only possesses universal reasoning capabilities across diverse KGs but also outperforms supervised and pre-training models. Moreover, we observe that the proposed model exhibits robustness and high efficiency in utilizing examples.

In summary, our main contributions are listed below:

* Our key contribution is an in-context KG reasoning foundation model. It prompts the pre-trained model to engage in relational reasoning over diverse KGs.
* We propose a prompt graph as context to support in-context learning. It consists of an example fact about the query relation and its relevant subgraphs and paths. We also employ a unified tokenizer to map entities and relations in prompt graphs to predefined tokens.
* Given a prompt graph with token representations, we propose two message passing networks for prompt graph encoding and KG reasoning. The foundation model can be further finetuned on specific KGs to obtain improved performance.
* We conduct extensive experiments on 43 KGs in both transductive and inductive settings to demonstrate the universal reasoning capability of our model.

Related Work

**KG reasoning.** KG reasoning primarily involves three settings: transductive, inductive, and fully-inductive. Early studies [10; 11; 12; 13; 14] focus mainly on the transductive setting, assuming that KGs are static. Real-world KGs are dynamic, inspiring the development of inductive models [1; 2; 3; 4; 15; 16; 17; 18; 19; 20; 21; 22; 23] that allows for emerging entities. In the fully-inductive setting [5; 24; 25; 26], both unseen entities and relations can emerge in the query facts. This setting remains limited to the same KG. In contrast, our in-context learning and KG foundation model seek to break down the barriers imposed by these settings and achieve universal reasoning capabilities.

**Prompt and in-context learning in graph pre-training.** Our work is also related to graph prompt learning and graph in-context learning. Inspired by the success of pre-training models in NLP  and computer vision , some graph pre-training models [29; 30; 31; 32; 33] have been proposed. These models follow the paradigm of "pre-train and finetune", where a model is initially pre-trained and then finetuned for the target task. The work  further develops a KG pre-training model. Consequently, recent work [8; 35; 36; 37; 38; 39; 40; 41; 42; 43; 44; 45] has shifted focus to the "pre-train, prompt, and finetune" paradigm. The relation graph of the KG pre-training model  can also be seen as a special prompt. This paradigm leverages task prompts to enhance the knowledge transfer and generalization abilities of pre-trained models. Inspired by the recent success of large language models like GPT , recent work uses in-context learning to avoid finetuning. It imparts general capabilities to pre-trained models with just a few examples. PRODIGY  introduces an in-context learning-based model to handle various classification tasks on graphs. While it can perform relation classification, it is not suitable for KG reasoning with a massive number of candidate entities.

We discuss more related work in Appendix D.

## 3 Problem Definition

**KG Reasoning.** We define a KG as \(=(,,)\), where \(\), \(\), and \(\) denote the sets of entities, relations, and facts, respectively. A fact \((s,r,o)\) consists of a subject entity \(s\), a relation \(r\), and an object entity \(o\). Given a KG and a query fact in the form of \((s,q,?)\), the reasoning task is to predict the missing entity from \(\). We refer to the relation \(q\) as a query relation.

In practice, we follow the convention  to introduce inverse relations. For each relation \(r\), we add its inverse relation \(r^{-}\) into the relation set and add the reverse fact \((o,r^{-},s)\) into the fact set.

**In-Context KG Reasoning.** In in-context reasoning, a model is pre-trained using a set of source KGs, denoted by \(\{_{1},,_{n}\}\). After pre-training, the model conducts reasoning on emerging KGs based on only a few related examples without updating model parameters. Each pre-training or reasoning query is prompted with some relevant examples as context.

The prompt is crucial for in-context learning. For each query relation \(q\), we first randomly sample some of its facts, e.g., \(c=(u,q,v)\). Next, we extract a subgraph \(_{c}=(_{},_{},_{})\) from the KG for each example fact to construct a prompt graph. In the following, we provide a broad definition of prompt graphs, allowing for a broad design space:

**Prompt Graph.** Given an example fact \(c=(u,q,v)\) in a KG \(=(,,)\), where \(c\), we define its prompt graph \(_{c}=(_{},_{ },_{})\) as a subgraph of \(\), and \(c_{}\).

To encode prompt graphs, we extend the KG-independent entity labeling  to relations and propose a unified tokenizer, which maps entities and relations from different KGs to unified tokens:

**Unified Tokenizer.** The unified tokenizer is a many-to-one mapping function. It maps entities and relations of different prompt graphs to the predefined tokens. Specifically, it maps each entity based on the length of its shortest paths to the subject and object entities of the example fact, i.e., \((e)[(u,e),(v,e)]\), where \(()\) is the length of the shortest path between two entities. It maps each relation to the tokens by whether it is the same as the query relation. That is, \((r)[(r,q)]\), where \((r,q)=1\) if \(r\) is the same as \(q\), otherwise \((r,q)=0\).

In Section 4.2, we assign a learnable representation for each token.

## 4 In-context Reasoning over KGs

The overview of the proposed model is shown in Figure 1. Given a KG and a query, we first generate prompt graphs for the query relation. Then, we use an encoding module to encode the prompt graphs and readout prompts. Finally, we incorporate the prompts into the KG reasoning process.

### Prompt Graph Generation

The prompt graph defined in Section 3 allows for a broad design space. In this section, we introduce a specific method for generating prompt graphs. We primarily address two challenges: (i) How to make the prompt graph general for diverse KGs? (ii) How to provide valuable prompts to enhance reasoning? We propose a prompt graph generation pipeline to address these challenges. It involves two steps: example sampling and prompt graph extraction.

**Example sampling.** For a query relation \(q\), we first randomly sample \(M\) example facts as follows:

\[_{q}=\{c_{i}\}_{i=1}^{M}\,, c_{i}( _{q}),\] (1)

where \(_{q}=\{(u,r,v)\,|\,r=q(u,r,v)\}\) and \(c_{i}=(u,q,v)\) is a \(q\)-specific example fact.

**Prompt graph extraction.** The key point of the prompt graph design is highlighting information crucial for query relation-specific reasoning. The example fact consists of a subject entity, an object entity, and the query relation between them. To depict the example subject and object entities, we draw inspiration from the research on prompt-based graph model [35; 46] to use neighboring nodes centered around the central node to construct prompt graphs. To abstract the semantics of query relation, we include the paths between example subject and entities, considering the success of logical rules in KG reasoning [47; 48; 49; 50]. The body of the rules involves paths between the subject and object entities. Therefore, given an example fact \(c=(u,q,v)_{q}\) and a KG \(=\{,,\}\), we include the neighboring entities of \(u\) and \(v\) and the \(k\)-hop paths between \(u\) and \(v\) in the prompt graph:

\[_{} =x\,|\,(x,r,u)}x\, |\,(x,r,v)}\] (2) \[x\,|\,(x,u)+(x,v) k },\]

where \(k\) is a hyperparameter denoting the maximum value of \((x,u)+(x,v)\). As we have added reverse facts, \(_{}\) includes all 1-hop neighbors. Next, we extract the facts and relations among them, i.e., \(_{}=(s,r,o)\,|\,s_{}  o_{}(s,r,o)}\) and \(_{}=r\,|\,(s,r,o)_{}}\).

Figure 1: Overview of the in-context KG reasoning foundation model. (A) Given the query and KG, we extract prompt graphs as context for the query relation “player in league”. The entities and relations in the prompt graphs are mapped to the unified tokens. (B) We employ a message passing neural network to encode the prompt graph and readout the relation representations as the prompts. (C) Then we use the prompts to initialize the representations of entities and relations in the KG. After KG encoding, we score the candidate entities according to their embeddings in the last layer.

### Prompt Encoding

In this section, we design a message passing neural network for prompt encoding. It comprises three sub-modules: token representation, message passing, and readout. We begin by initializing the token representations of entities and relations in the given prompt graph. Subsequently, a multi-layer message passing neural network is employed to encode the prompt graph. Finally, we introduce a readout sub-module to obtain the prompt representation.

**Token representations.** We assign each token a learnable vector representation. Specifically, according to Equation (2), the tokens for entities satisfy \(i+j k\), \(0 i k-1\) and \(0 j k-1\). Therefore, we set a representation matrix \(^{(-2(k-1)) d}\) for entity tokens, where \(-2(k-1)\) denotes the total number of entity tokens. As for relations, the representation of token \([z]\) is initialized as \(^{} z\), where \(^{}^{1 d}\) is a learnable representation. We denote the input representation matrix of entities and relations for the prompt graph as \(_{}^{(0)}\) and \(_{}^{(0)}\), respectively.

**Message passing for prompt graph.** Then, we employ an \(L\)-layers message passing neural network, which incorporates two types of aggregation: an entity-centric aggregation and a relation-centric aggregation. In each layer, we first update the entity representations as follows:

\[_{}^{(l+1)}*{Aggregation}_{ e _{}, n_{e}} (_{}^{(l)},_{}^{(l)},n,q )},\] (3)

where \(_{e}_{}\) is the set of facts containing the entity \(e\), and \(q\) is the query relation of this prompt graph. Then we update the relation representations using the updated entity representations and the relation representations from the previous layer:

\[_{}^{(l+1)}*{Aggregation}_{ r _{}, n_{r}} (_{}^{(l+1)},_{}^{(l)},n,q )},\] (4)

where \(_{r}_{}\) is the set of facts containing the relation \(r\). Under this message passing framework, we present two specific aggregation and message functions in Appendix A.1.

**Readout.** After \(L\)-layers message passing on the prompt graph \(\), we obtain the prompt as follows:

\[_{}=_{}_{}^{(1)}\,||\,_{}^{(2)}\,||\,\,\,||\,_{}^{(L )},\] (5)

where \(_{}^{d Ld}\) is a learnable weight matrix. Note that the relations in different prompt graphs may vary. We fill in the relations not present in the prompt graph with zero vectors to obtain \(}_{}^{|| d}\), ensuring that the shapes of every representation matrix are the same. Finally, we use mean-pooling to aggregate the information from multiple prompt graphs as follows:

\[}_{}=_{q}|}_{c _{q}}}_{_{c}},\] (6)

where \(}_{}^{|| d}\) is the prompt relation representation matrix, \(_{q}\) is the set of example facts of the query relation \(q\), and \(_{c}\) is the prompt graph corresponding to the example fact \(c\). In practice, we parallel encode these prompt graphs to ensure efficiency.

### In-Context KG Encoding and Reasoning

Based on the prompt encoding, we conduct reasoning on KGs. To achieve a KG-independent encoding, we draw inspiration from the conditional message passing neural network [3; 4; 20; 21; 22] to present a novel KG reasoning module. It separately encodes entities based on the query, rather than mapping them to specific embeddings, offering us an opportunity for knowledge transfer across diverse KGs. It comprises three sub-modules: initialization, KG encoding, and reasoning.

**Initialization.** The input relation representations in the KG are initialized as the prompt relation embeddings, i.e., \(_{}^{(0)}=}_{}\). As for entity representations, given a query fact \((s,q,x)\), the representation of \(s\) is initialized as the representation of the query relation, i.e., \(=\). Other entities are represented by zero vectors. We denote the input representation matrix of entities in KG as \(_{}^{(0)}\).

**Message passing for KG.** Here we employ an \(N\)-layers message passing neural network to aggregate multi-hop information. At each layer, we first update relation representations as follows:

\[_{}^{(l+1)}=_{}^{(l)}+ _{}^{(l)}_{}^{(l)} ,\] (7)

where \(\) denotes the layer normalization operation, and \(_{}^{(l)}^{d d}\) is a learnable weight matrix. Then, we update entity representations based on the updated relation representations. Some studies [3; 20] have shown that the distance-based inductive bias is crucial for KG reasoning. Inspired by this, we introduce a hop-by-hop message passing neural network to update entity representations, starting from the subject entity and expanding one-hop neighbors at each layer:

\[_{}^{(l+1)}*{Aggregation}_{ e ^{(l+1)}, n_{e}}(_{}^{(l)},_{}^{(l+1)},n,q)} ,\] (8)

where \(q\) is the query relation, \(^{(l)}\) is the set of entities in \(l\)-hop neighbors of \(s\), and \(^{(0)}=\{s\}\), \(^{(l+1)}=^{(l)}e\,|\,(x,y,e)  x^{(l)}\,}\). Under this message passing framework, we present a specific message passing neural network for KG encoding in Appendix A.2.

**Reasoning.** Finally, we read the representations of candidate entities and assign scores to them, i.e., \(f(s,q,e)=_{}_{s,q}^{(N)}\),where \(_{s,q}^{(N)}_{}^{(N)}\) is the output representation of the entity \(e\), and \(_{}^{1 d}\) is a weight matrix. Note that the message passing neural network we employ for KG encoding is conditioned on specific queries of the form \((s,q,?)\), meaning the output representations \(_{}^{(N)}\) have taken into account the conditional messages related to both \(s\) and \(q\). In addition, it encodes only the \(N\)-hop neighbor entities of the subject entity. We assign a score of 0 to other entities.

### Pre-training Objective

Given a set of source KGs \(=\{_{0},\,,_{n}\}\), where \(_{i}=(_{i},_{i},_{i})\), we pre-train the model using the multi-class log-loss :

\[_{(_{i},_{i},_{i})}_{( s,q,o)_{i}}-f(s,q,o)+_{e_{i}} f(s,q,e),\] (9)

where \(f\) is the score function mentioned above. Minimizing Equation (9) enlarges scores of positive facts while reducing scores of all negatives that replace the correct object entity with another entity from the KG. We describe our reasoning process in Algorithm 1 of Appendix B.

## 5 Experiments

### Settings

**Datasets and implementations.** We conduct experiments on 43 datasets of various schemata and sizes to evaluate our model. The datasets fall into three groups: (i) 14 inductive datasets, including 12 datasets in GraIL  and 2 datasets in ILPC 2022 , (ii) 13 fully-inductive datasets in , and (iii) 16 transductive datasets, including FB15k-237 , WN18RR , NELL-995, , YAGO3-10 , 3 datasets in CoDEx , 5 datasets in , AristoV4 , DBpedia100k , ConceptNet100k , and Hetiotenet . The statistics of datasets are in Appendix F. We pre-train our model on three datasets, i.e., FB V1  with 180 relations, NELL V1  with 14 relations, and CoDEx-s  with 42 relations, to capture various relational structures in KGs and prompt graphs. The implementation details are in Appendix C. We assess the impact of pre-training KGs in Appendix E.1.

**Baselines.** We compare KG-ICL with two categories of baseline models: (i) Supervised state-of-the-art (abbr. supervised SOTA), which refers to the models achieving the best MRR result on specific target datasets. We list the supervised SOTA model on each dataset in Appendix F. (ii) Pre-training model. ULTRA  is a KG pre-training model, consisting of pre-training and finetuning versions. To investigate the ability of finetuning on target datasets to yield improvement of the proposed model, we also introduce two versions of our model: "KG-ICL pre-train" and "KG-ICL finetune". After pre-training, the finetuning model undergoes finetuning for 5 epochs on the target dataset using the same configuration as the pre-training. The main focus of this work is on in-context learning withoutthe need for finetuning. Therefore, we report the results of both versions of our model in Section 5.2 and Appendix G, and use the pre-training version in further analyses.

**Evaluation protocol.** For each sample \((s,r,o)\) in the test set, we generate two query facts \((s,r,?)\) and \((o,r^{-},?)\), where \(r^{-}\) is the inverse relation of \(r\). As mentioned in Section 3, we add inverse relations and facts before conducting reasoning. The pre-training model considers all entities in the entity set as candidates, scoring and ranking them for each query fact. Following the convention [62; 63; 64], we employ two standard evaluation metrics: mean reciprocal rank (MRR) and Hits@10 (abbr. H@10). Higher scores of both metrics indicate superior performance. We follow the widely-used filtered setting , i.e., wherein all known true entities are removed from the candidate set, except for the target entity. Due to the abundance of datasets, we categorize them and report the scores in terms of the groups, such as the inductive dataset group. This involves calculating scores for each dataset individually and computing the average of all scores within each group.

### Main Results

We divide the datasets into three groups according to their reasoning settings, i.e., inductive, fully-inductive and transductive, and report the average results for each group as well as the overall average results in Table 1. ULTRA employs three different source KGs distinct from ours. For ease of presentation, we incorporate the source KGs into their respective groups rather than listing them separately. We can observe that our "KG-ICL pre-train" outperforms both versions of ULTRA on inductive and fully-inductive datasets, with further enhancements achieved by our "KG-ICL finetune", resulting in the best performance across all groups. We report detailed results of each dataset and more analyses in Figure 2 and Appendix G.

**Inductive datasets.** The inductive setting aims to complete facts involving unseen entities. In each inductive dataset, at least two graphs are included: one for training and the other for evaluation. The evaluation graph incorporates new entities not seen in the training graph. The MRR results are depicted in Figure 2(a). We observe that our "KG-ICL pre-train" outperforms supervised SOTA models on 10 datasets and surpasses the "ULTRA pre-train" model on 11 datasets. The "KG-ICL finetune" achieves further improvements in scores compared to the pre-trained version, achieving the best results on 13 datasets, and yielding the best average results.

    &  &  &  &  \\  &  &  &  &  \\   & MRR & H@10 & MRR & H@10 & MRR & H@10 & MRR & H@10 \\  Supervised SOTA & 0.466 & 0.607 & 0.210 & 0.347 & 0.365 & 0.511 & 0.351 & 0.493 \\ ULTRA pre-train & 0.513 & 0.664 & 0.352 & 0.536 & 0.329 & 0.479 & 0.396 & 0.557 \\ ULTRA finetune & 0.528 & 0.684 & 0.350 & 0.542 & 0.384 & 0.548 & 0.421 & 0.590 \\  KG-ICL pre-train & 0.554 & 0.707 & 0.439 & 0.635 & 0.346 & 0.493 & 0.442 & 0.606 \\ KG-ICL finetune & **0.582** & **0.727** & **0.449** & **0.647** & **0.397** & **0.554** & **0.473** & **0.638** \\   

Table 1: KG reasoning results in various settings.

Figure 2: MRR results on various KGs.

**Fully-inductive datasets.** In fully-inductive datasets, the evaluation graphs not only include new entities unseen during training but also introduce new relations. The MRR results are shown in Figure 2(b). This setting poses a significant challenge with the introduction of unseen relations, leading to relatively lower scores for supervised SOTA models. However, both versions of KG-ICL, aided by prompt graphs, demonstrate the ability to extract valuable information and adaptively perform reasoning for unseen query relations. Consequently, they consistently outperform supervised SOTA models across all 13 datasets and exhibit a notable improvement over the previous pre-training model, ULTRA, on all datasets.

**Transductive datasets.** In the transductive setting, where entities and relations in the test set are encountered during training, the MRR results are presented in Figure 2(c). It is evident that, in comparison to the first two settings, the advantage of the proposed model over the supervised SOTA model is somewhat attenuated. The reason is that the supervised signals on transductive datasets directly target entities and relations in the test set, allowing supervised models to effectively learn representations and achieve high performance. Nonetheless, "KG-ICL pre-train" maintains its superiority over the supervised SOTA models on 7 datasets. "KG-ICL finetune" achieves the best average MRR score. We report detailed results of each dataset and more analyses in Appendix G.

### Further Analyses

In this section, we conduct experiments to devise the impact of each module. In the appendix, we include more experimental analyses about the pre-training datasets (Appendix E.1), complexity analyses of preprocessing (Appendix E.2), and the variant incorporating other message passing layer (Appendix E.3).

**Ablation study.** We hereby conduct an ablation study to evaluate the impact of each module. Specifically, we construct three variants by removing certain modules: "w/o prompt graph", "w/o unified tokenizer", and "w/ GraIL's labeling". "w/o prompt graph" removes the prompt graph generation and encoding module. Its prompt representations are initialized with the Xavier normal initialization. "w/o unified tokenizer" eliminates the unified tokenizer and initializes the input representations of entities and relations in prompt graphs with the Xavier normal initialization. "w/GraIL's labeling" replaces our token representation with GraIL's one-hot labeling . The results are presented in Table 2. We observe a significant performance decline in the "w/o prompt graph" variant compared to the intact model, highlighting the necessity of the prompt graph as a knowledge transfer bridge. The "w/o unified tokenizer" variant also exhibits a performance drop, indicating the importance of the unified tokenizer for in-context learning. The "w/GraIL's labeling" can also achieve promising results, although it still falls behind our intact model, which shows the generalization ability of our model and the effectiveness of the token representation.

**Example efficiency.** The efficiency of utilizing examples is crucial for in-context learning. To determine the optimal number of example prompt graphs needed to support in-context reasoning, we conduct experiments under the settings of 1-shot, 3-shot, 5-shot, 10-shot, and 20-shot. The results are illustrated in Figure 3. Overall, the results remain consistent with a slight fluctuation across the range from 1-shot to 20-shot, which shows that the proposed model is robust to the changes in the num

    &  &  &  &  \\   & MRR & H@10 & MRR & H@10 & MRR & H@10 & MRR & H@10 \\   & 0.554 & 0.707 & 0.439 & 0.635 & 0.346 & 0.493 & 0.442 & 0.606 \\  & 0.219 & 0.420 & 0.105 & 0.228 & 0.076 & 0.143 & 0.132 & 0.259 \\  & 0.511 & 0.660 & 0.419 & 0.617 & 0.296 & 0.453 & 0.403 & 0.570 \\  & 0.531 & 0.704 & 0.434 & 0.634 & 0.343 & 0.492 & 0.431 & 0.604 \\   

Table 2: Ablation study results in various settings.

Figure 3: MRR with different numbers of examples.

ber of prompt graphs. The reason for the slight performance fluctuation is that more examples may also introduce more noise. Besides, multiple examples tend to share popular reasoning patterns, so only one or three prompt graphs can still suffice. For overall performance, we choose \(M=5\) in the main experiment. These results suggest that KG-ICL can unleash universal reasoning capabilities with only a few examples, showcasing high efficiency in example utilization.

**Prompt graph variants.** The core of a prompt graph lies in highlighting essential information for reasoning. In this paper, we propose a prompt graph generation process that combines paths and neighbors of the subject and object entities. To further explore the critical components for reasoning, we introduce several variants, with the proposed model referred to as "neighbor & 3-hop path". We present four variants by altering the entity sampling method: the "neighbor" variant, considering only neighbors of the subject and object entities, and the "\(x\)-hop path" variant, considering \(x\)-hop paths between the entity and object entities, where \(x\{1,2,3\}\). The results in Table 3 demonstrate the impact of the prompt graph on reasoning. We observe that both paths and neighbors of the subject and object entities are crucial for reasoning. The optimal performance is achieved when combining both components. The variants considering only paths within one or two hops exhibit poor performance, indicating insufficient support for effective reasoning.

**Robustness to low-resource relations.** We conduct experiments to assess the robustness of the proposed model to low-resource relations with limited training samples. Specifically, we choose the supervised model RED-GNN  as a baseline and conduct experiments on 12 widely used inductive datasets  and 3 transductive datasets (FB15k-237, WN18RR, and NELL-995). We organize relations within each dataset group into six subgroups based on the number of training samples. Subsequently, we compute the MRR score for each relation and calculate the average score within each subgroup. The results, as illustrated in Figure 4, reveal a gradual decline in the performance of RED-GNN, as the number of training samples decreases. In contrast, our model exhibits robustness across a spectrum of relations. The results suggest that our model maintains effective performance even under resource constraints. This can be attributed to our model of avoiding the representation of each relation independently with specific embeddings. We employ a universal prompt graph and a unified tokenizer for the relation representation, fostering cross-relation knowledge transfer and achieving superior robustness.

    &  &  &  &  \\  &  &  &  &  \\   & MRR & H@10 & MRR & H@10 & MRR & H@10 & MRR & H@10 \\  Neighbor \& 3-hop path & 0.554 & 0.707 & 0.439 & 0.635 & 0.346 & 0.493 & 0.442 & 0.606 \\ Neighbor & 0.552 & 0.702 & 0.429 & 0.628 & 0.311 & 0.459 & 0.425 & 0.590 \\
1-hop path & 0.208 & 0.449 & 0.145 & 0.314 & 0.112 & 0.216 & 0.153 & 0.322 \\
2-hop path & 0.256 & 0.419 & 0.137 & 0.285 & 0.125 & 0.235 & 0.171 & 0.310 \\
3-hop path & 0.544 & 0.697 & 0.409 & 0.601 & 0.294 & 0.464 & 0.410 & 0.582 \\   

Table 3: MRR results on diverse prompt graphs.

Figure 4: Average MRR results of relation subgroups. Relations in the inductive and transductive dataset groups are divided into 6 subgroups based on the number of training samples, and the results represent the average scores for the relations within their respective subgroups. The percentage on the right side of each data bar indicates the proportion of relations in that subgroup to the total number of relations in their respective groups.

**Case study.** We conduct a case study to investigate the reasons behind the proposed model's generalizability across different KGs. Specifically, we select two similar and easily interpretable query relations, "teamSport" and "film/language" from NELL-995 and FB15k-237, respectively. We extract several relation paths from their prompt graphs, forming two similar subgraphs. Subsequently, we execute the model and save the prompt representations for both query relations. Finally, we compute the cosine similarities between relations in the two prompt graphs and visualize the heatmap in Figure 5. We observe that the values along the diagonal of the heatmap are notably high, indicating that different relations with similar roles in the reasoning of the two query relations have correspondingly similar model encodings. This suggests that the prompt representations effectively capture the roles of various relations in reasoning, thereby improving transferability across different KGs.

## 6 Conclusions

This paper introduces a KG foundation model with in-context learning to improve the effectiveness and transferability of KG reasoning. Specifically, we introduce a prompt graph and a unified tokenizer as the bridge to knowledge transfer between different KGs. Following that, we propose a prompt graph generation module, a prompt encoding module, and a KG reasoning module to achieve in-context learning. We evaluate the in-context reasoning ability on 43 different KGs in both transductive and inductive settings. Extensive experimental results validate our model's universal reasoning ability across diverse KGs. In future work, we plan to explore the application of in-context reasoning in more challenging scenarios, such as personal KGs that are dynamic and diverse. This is motivated by the demonstrated robustness of our KG-ICL in Section 5.3. Additionally, investigating how to extend in-context reasoning to more knowledge-driven applications, e.g., recommender systems and question answering, is another promising avenue for future research.