# GeoNLF: Geometry guided Pose-Free

Neural LiDAR Fields

 Weiyi Xue

Tongji University

xwy@tongji.edu.cn

&Zehan Zheng1

Tongji University

zhengzehan@tongji.edu.cn

&Fan Lu

Tongji University

lufan@tongji.edu.cn

&Haiyun Wei

Tongji University

2311399@tongji.edu.cn

&Guang Chen1

Tongji University

guangchen@tongji.edu.cn

&Changjun Jiang

Tongji University

cjjiang@tongji.edu.cn

Equal contribution. \({}^{}\) Corresponding author. Our code is available at https://github.com/ispc-lab/GeoNLF.

###### Abstract

Although recent efforts have extended Neural Radiance Fields (NeRF) into LiDAR point cloud synthesis, the majority of existing works exhibit a strong dependence on precomputed poses. However, point cloud registration methods struggle to achieve precise global pose estimation, whereas previous pose-free NeRFs overlook geometric consistency in global reconstruction. In light of this, we explore the geometric insights of point clouds, which provide explicit registration priors for reconstruction. Based on this, we propose **Geo**metry guided **N**eural LiDAR Fields (GeoNLF), a hybrid framework performing alternately global neural reconstruction and pure geometric pose optimization. Furthermore, NeRFs tend to overfit individual frames and easily get stuck in local minima under sparse-view inputs. To tackle this issue, we develop a selective-reweighting strategy and introduce geometric constraints for robust optimization. Extensive experiments on NuScenes and KITTI-360 datasets demonstrate the superiority of **GeoNLF** in both novel view synthesis and multi-view registration of low-frequency large-scale point clouds.

## 1 Introduction

Neural Radiance Fields (NeRFs)  have achieved tremendous achievements in image novel view synthesis (NVS). Recent studies have extended it to LiDAR point cloud synthesis , mitigating the domain gap to real data and far surpassing traditional methods. Nevertheless, the majority of existing works exhibit a strong dependence on known precise poses. In the domain of images, conventional approaches rely on Structure-from-Motion algorithms like COLMAP  to estimate poses, which are prone to failure with sparse or textureless views. As an alternative, recent works  such as BARF  employ bundle-adjusting techniques to achieve high-quality NVS while simultaneously enhancing the precision of pose estimation.

However, the sparse nature of LiDAR point clouds and their inherent absence of texture information distinguish them significantly from images. Trivial bundle-adjusting techniques from the image domain become less applicable in this context, encountering the following challenges: (1) Outdoor LiDAR point clouds (_e.g._, 2Hz, 32-beam LiDAR keyframes in Nuscenes ) exhibit temporal and spatial sparsity. NeRF easily overfits the input views without addressing the geometric inconsistencies caused by inaccurate poses. Consequently, it fails to propagate sufficient gradients for effective pose optimization. (2) Point clouds lack texture and color information but contain explicit geometric features. However, the photometric-based optimization scheme of NeRFs overlooks these abundant geometric cues within the point cloud, which hinders geometric-based registration.

An alternative to achieving pose-free LiDAR-NeRF is to employ point cloud registration (PCR) methods. Nonetheless, as the frequency of point cloud sequences decreases, the inter-frame motion escalates with a reduction in overlap. As presented in Fig. 1, pairwise and multi-view registration approaches may all trap in local optima and suffer from error accumulation, making it challenging to attain globally accurate poses. Hence, integrating local point cloud geometric features for registration with the global optimization of NeRF would be a better synergistic approach.

Furthermore, as demonstrated in [6; 53], the incorporation of geometric constraints significantly enhances the optimization of both pose and radiance fields. In the image domain, this process involves introducing additional correspondences or depth priors. However, most methods treat them solely as loss terms without fully exploiting them. In contrast, point clouds provide inter-frame correlations (_e.g._, the closest point) for registration and explicit geometric information for reconstruction, presenting substantial advantages over images.

To this end, we propose **GeoNLF**, integrating LiDAR NVS with multi-view PCR for large-scale and low-frequency point clouds. Specifically, to address the suboptimality of global optimization and guide NeRF in the early pose optimization stage to avoid local minima, we regulate NeRF with a pure geometric optimizer. This module constructs a graph for multi-view point clouds and optimizes poses through graph-based loss. To reduce overfitting, we devised a selective-reweighting technique involving filtering out frames with outlier poses, thereby lessening their deleterious impacts throughout the optimization process. Additionally, to fully leverage the geometric attributes of point clouds, we introduced geometric constraints for point cloud modality rather than relying solely on the range map for supervision. Furthermore, our approach has demonstrated excellent performance in large-scale scenarios with sparse point cloud sequences at 2Hz, spanning hundreds of meters. To summarize, our main contributions are as follows:

(1) We propose **GeoNLF**, a novel framework for simultaneous large-scale multi-view PCR and LiDAR NVS. By exploiting geometric clues inside point clouds, **GeoNLF** couples geometric optimizer with neural reconstruction in the pose-free paradigm. (2) We introduce a selective-reweighting method to effectively alleviate overfitting, which presents excellent robustness across various scenarios. (3) Comprehensive experiments demonstrate **GeoNLF** outperforms state-of-the-art methods by a large margin on challenging large-scale and low-frequency point cloud sequences.

## 2 Background and Related Work

**Neural Radiance Fields.** NeRF  and related works have achieved remarkable achievements in NVS. Various neural representations [4; 10; 11; 22; 38], such as hash grids , triplanes [10; 22] and diverse techniques [39; 40; 55; 66] have been proposed to enhance NeRF's performance. Due to the lack of geometric information in images, some methods [16; 46; 59; 64] introduce depth prior or point clouds as auxiliary data to ensure multi-view geometric consistency. However, the geometric information and consistency encapsulated in point clouds are still not fully explored and utilized.

Figure 1: **Registration results. Pairwise algorithms such as GeoTrans  and ICP  suffer from error accumulation and local mismatches. Multi-view methods like SGHR  and MICP  still manifest outlier poses. Previous gradient-based approaches LiDARNeRF-HASH  lack geometric consistency. Our method effectively avoids outlier frames and achieves superior registration accuracy.**

**Novel View Synthesis for LiDAR**. Traditional simulators [17; 27; 49] and explicit reconstruct-then-simulate [20; 28; 35] method exhibit large domain gap compared to real-world data. Very recently, a few studies have pioneered in NVS of LiDAR point clouds based on NeRF, surpassing traditional simulation methods. Among them, NeRF-LiDAR  and UniSim  require both RGB images as inputs. LiDAR-NeRF  and NFL  firstly proposed the differentiable LiDAR NVS framework, and LiDAR4D  further extended to dynamic scenes. However, most of these approaches still require a pre-computed pose of each point cloud frame and lack attention to geometric properties.

**Point Cloud Registration**. ICP  and its variants [45; 47; 43] are the most classic methods for registration, which rely on good initial conditions but are prone to falling into local optima. Learning-based method can be categorized into two schemes, i.e., end-to-end registration [65; 29; 24; 56; 1] and feature matching-based registration such as FCGF . Recently, the specialized outdoor point cloud registration methods HRegNet  and HDMNet  have achieved excellent results. GeoTransformer  has achieved state-of-the-art in both indoor and outdoor point cloud registration. However, learning-based methods are data-driven and limited to specific datasets with ground truth poses, which requires costly pretraining and suffers from poor generalization.

Multiview methods are mostly designed for indoor scenes. Apart from Multiview-ICP [13; 7; 36], modern methods [2; 8; 52; 25] take global cycle consistency to optimize poses starting from an initial set of pairwise maps. Recent developments [19; 54; 3] such as SGHR  employ an iteratively reweighted least-squares (IRLS) scheme to adaptively downweight noisy pairwise estimates. However, their registration accuracy fundamentally depends on pairwise registration. The issues of pairwise methods for NVS still persist.

**Bundle-Adjusting NeRF**. iNeRF  and subsequent works [32; 15] demonstrated the ability of a trained NeRF to estimate novel view image poses through gradient descent. NeRFmm  and SCNeRF  extend the method to intrinsic parameter estimation. BARF  uses a coarse-to-fine reconstruction scheme in gradually learning positional encodings, demonstrating notable efficacy. Subsequent work HASH  adapts this approach on iNGP  through a weighted schedule of different resolution levels, further boosting performance. Besides, some studies have extended BARF to address more challenging scenarios, such as sparse input , dynamic scenes  and generalizable NeRF . And [6; 53] uses monocular depth or correspondences priors for scene constraints, significantly enhancing the optimization of both pose and radiance fields. However, the aforementioned methods cannot be directly applied to point clouds or experience dramatic performance degradation when transferring. In contrast, our work is the first to introduce bundle-adjusting NeRF into LiDAR NVS task and achieve excellent results in challenging outdoor scenarios.

## 3 Methodology

We firstly introduce the pose-free Neural LiDAR Fields and the problem formulation of pose-free LiDAR-NVS. Following this, a detailed description of our proposed **GeoNLF** framework is provided.

**Pose-Free NeRF and Neural LiDAR Fields**. NeRF represents a 3D scene implicitly by encoding the density \(\) and color \(\) of the scene using an implicit neural function \(F_{}(,)\), where \(\) is the 3D coordinates and \(\) is the view direction. When synthesizing novel views, NeRF employs volume rendering techniques to accumulate densities and colors along sampled rays. While NeRF requires precise camera parameters, pose-free NeRF only uses images \(=\{I_{i}|i=0,1...,N-1\}\) and treats camera parameters \(=\{_{s}|s=0,1...N-1\}\) as learnable parameters similar to \(\). Hence, the simultaneous update via gradient descent of \(\) and \(\) can be achieved by minimizing the error \(=_{i=0}^{N}\|_{i}-I_{i}\|_{2}^{2}\) between the rendered and ground truth image \(,I\):

\[^{*},^{*}=_{,}(},})\] (1)

Following [70; 51], we project the LiDAR point clouds into range image, then cast a ray with a direction \(\) determined by the azimuth angle \(\) and elevation angle \(\) under the polar coordinate system: \(=(,\ ,\ )^{T}\). Like pose-free NeRF, our pose-free Neural LiDAR Fields treats LiDAR poses as learnable parameters and applies neural function \(F_{}\) to obtain a radiance depth \(z\) and a volume density value \(\). Subsequently, volume rendering techniques are employed to derive the pixel depth value \(}\):

\[}()=_{i=1}^{N}T_{i}(1-e^{-_{i} _{i}})z_{i}, T_{i}=(-_{j=1}^{i-1}_{j}_{j})\] (2)where \(\) refers to the distance between samples. We predict the intensity \(\) and ray-drop probability \(\) separately in the same way. Besides, our pose-free Neural LiDAR Fields adopted the Hybrid Planar-Grid representation from  for positional encoding \((x,y,z)=_{}_{}\).

\[_{}\!=\!_{i=1}^{3}(, ),^{3\!M\!\!M\!\!C},\ _{}\!=\!(,), ^{M\!\!M\!\!M\!\!C}\] (3)

where \(\) is the 3D point, \(,\) store the grid features with \(M\) spatial resolution and \(C\) feature channels. This encoding method benefits the representation of large-scale scenes.

**Problem Formulation**. In the context of large-scale outdoor driving scenarios, the collected LiDAR point cloud sequence \(=\{_{s}|s=0,1,...,N\!-\!1\}\) serves as inputs with a low sampling frequency. The goal of GeoNLF is to reconstruct this scene as a continuous implicit representation based on neural fields, jointly recovering the LiDAR poses \(=\{_{s}|s=0,1,...,N\!-\!1\}\) which can align all point clouds \(\) globally.

### Overview of GeoNLF Framework

In contrast to prior pose-free NeRF methods, our pipeline employs a hybrid approach to optimize poses. As shown in Fig. 2, the framework can be divided into two alternately executed parts: global optimization of bundle-adjusting neural LiDAR fields (Sec. 3.2) and graph-based pure geometric optimization (Sec. 3.3) with the proposed Geo-optimizer. In the first part, we adopt a coarse-to-fine training strategy  and extend it to the Hybrid Planar-Grid encoding . In the second part, inspired by multi-view point cloud registration, we construct a graph between multiple frame point clouds and propose a graph-based loss. The graph enables us to achieve pure geometric optimization, which encompasses both inter-frame and global optimization. Furthermore, we integrate the selective-reweighting strategy (Sec. 3.4) into the global optimization. This encourages the gradient of outliers to propagate towards pose correction while lowering the magnitude transmitted to the radiance fields, thus mitigating the adverse effects of outliers during reconstruction. To ensure geometry-aware results, we additionally incorporate explicit geometric constraints derived from point clouds in Sec. 3.5.

### Bundle-Adjusting Neural LiDAR Fields for Global Optimization

In the stage of global optimization, we optimize Neural LiDAR Fields while simultaneously back-propagating gradients to the pose of each frame. By optimizing our geometry-constrained loss, which will be detailed in Sec. 3.5, the pose is individually optimized to achieve global alignment.

**LiDAR Pose Representation**. In previous pose-free NeRF methods, poses are often modeled by \(=[] SE(3)\) with a rotation \( SO(3)\) and a translation \(^{3}\). Pose updates are computed in the special Euclidean Lie algebra \((3)=\{=\\ ,^{3},(3)\}\) by

Figure 2: **Overview of our proposed GeoNLF. We alternatively execute global optimization of bundle-adjusting neural LiDAR fields and graph-based pure geometric optimization. By integrating selective-reweighting strategy and explicit geometric constraints derived from point clouds, GeoNLF implements outlier-aware and geometry-aware mechanisms.**

\(^{}=+\), followed by the exponential map to obtain the transformation matrix \(\):

\[=(^{})=_{n=0}^{}(^{} )^{n}=[_{n=0}^{}(^ {})^{n}&_{n=0}^{}(^{ })^{n}\\ ^{T}&1]\] (4)

where \(^{}=[^{}&\\ ^{T}&0]\) and \(^{}\) is the antisymmetric matrix of \(\). Given a rotation vector \((3)\), rotation matrix \(\) can be obtained through the exponential map \(=(^{})=_{n=0}^{}(^{ })^{n}\). Simultaneously, we denote \(_{n=0}^{}(^{})^{n}\) as \(\). Then Eq. (4) can be rewritten as:

\[=[&\\ ^{T}&1]\] (5)

Consequently, due to the coupling between \(=_{n=0}^{}(^{})^{n}\) and \(J=_{n=0}^{}(^{})^{n}\), the translation updates are influenced by rotation. Incorporating momentum may lead to non-intuitive optimization trajectories . Therefore, we omit the coefficient \(\) from the translation term. This approach enables updating the translation of the the center of mass and the rotation around the center of mass independently.

**Coarse-to-Fine Positional Encoding**. BARF/HASH  propose to gradually activate high-frequency/high-resolution components within positional encoding. We further apply this approach to multi-scale planar and hash encoding  and found it also yields benefits in our large-scale scenarios. For the detailed formulation, we direct readers to reference .

### Graph-based Pure Geometric Optimization

ICP  is a classic method for registration based on inter-frame geometric correlations. The essence of ICP lies in searching for the closest point as correspondence in another frame's point at each iteration, followed by using Singular Value Decomposition (SVD) to solve Eq. (6), then iteratively refining the solution. Nonetheless, ICP frequently converges to local optima (Fig. 1). In contrast, NeRF optimizes pose globally through the implicit radiance fields. However, it lacks geometric constraints and overlooks the strong geometric information inherent in the point cloud, leading to poor geometric consistency. As a consequence, both ICP and NeRF acting individually tend to converge to local optima. Our goal is to employ a hybrid method, utilizing NeRF for global pose optimization and integrating geometric information as an auxiliary support.

Drawing inspiration from ICP , we recognize that minimizing the Chamfer Distance (CD) is in line with the optimization objective of each step in ICP algorithm, as demonstrated in Eq. (7):

\[^{*}=_{}_{_{i}}_{ _{i}}\|_{i}-_ {i}\|_{2}^{2}\] (6)

\[_{(P,Q)}=_{_{i}}w_{i}_{_ {i}}\|_{i}-_{i} \|_{2}^{2}+_{_{i}}w_{i}_{_{i} }\|_{i}-_{i}\| _{2}^{2}\] (7)

where \(q,p\) in point cloud \(,\) are homogeneous coordinates. \(_{P},_{Q}\) represent the transformation matrix to the world coordinate system. However, minimizing the original CD does not necessarily indicate improved accuracy due to the non-overlapping regions between point clouds. To alleviate this negative impact, we weight each correspondence based on Eq. (8), whereas \(w_{i}\) in the original CD is normalized by the \(\), N is the number of points.

\[w_{i}=^{i})}{_{i=1}^{N}(t/d_{clipped}^{i})},  t=(t_{0}), d_{clipped}^{i}=(,d_{i})\] (8)

where \(d_{i}\) denotes the distance between a pair of matching nearest neighbor points, \(t\) is the temperature to sharpen the distribution of the \(d_{clipped}^{i}\). The distance \(d_{i}\) is clipped to the size of the downsampled voxel grid. This soft assignment can be considered as an approximately derivable version of weighted averaging. Eq. (7) will degenerate to the original CD when \(t 0\), degrade to considering only correspondences with the minimum distance when \(t\). Considering the distance lacks practical significance in initial optimization, the scheduler is set as a linear or exponential function to vary \(t\) from 0 to 0.5 as the optimization progresses. Building upon the above, as shown in Fig. 3, we approximate the registration objective by optimizing the Graph-based Robust Chamfer distance (G-RCD). Specifically, we construct a graph \((,)\), where each vertex \(\) represents a set of points and each edge \(\) corresponds to proposed RCD via Eq. (7). We connect each frame with its temporally preceding \(n\) frames to mitigate error accumulation in ICP . Then RCD is calculated for all edges as Eq. (9), and \(M\) denotes the number of frames in the sequence. Notably, in Eq. (7), G-RCD is computed using the global transform matrix, enabling direct gradient propagation of the Graph-based loss to the global transformation matrix of each frame.

\[_{graph}=)}_{(i,j)} _{(i,j)},\] (9)

**Discussion**. As illustrated in Fig. 3(b), insufficient geometric guidance leads to certain frame poses being optimized in the wrong direction. Geometric optimizer can address this issue by preventing pose updates strictly following NeRF and correcting wrong optimization directions that do not conform to global geometric consistency. This method involves externally modifying pose parameters and providing effective geometric guidance early in the ill-conditioned optimization process. Consequently, few iterations of graph-based RCD computation suffice to offer ample guidance for NeRF.

### Selective-Reweighting Strategy for Outlier Filtering

In bundle-adjusting optimization, as shown in Fig. 4(a), we observed that frames with outlier poses present significantly higher rendering losses during the early stages of training. However, low

Figure 4: **Impact of selective-reweighting training strategy on pose optimization. (a) Frames with outlier poses exhibit significantly higher losses. With selective-reweighting, outlier frames maintain a relatively higher loss without overfitting. (b) After several training iterations, the pre-trained outlier-aware NeRF can provide globally consistent geometric optimization for outlier frames.**

Figure 3: **Graph-based RCD (left)**. We introduce control factor \(t\) in CD to diminish the weighting of non-overlapping regions between point clouds. **Geo-optimizer and its impact on pose optimization (right)**. Pose errors are reduced after each increase caused by NeRFâ€™s incorrect optimization direction. Comparison of (a) and (b) shows Geo-optimizer prevents incorrect pose optimization of NeRF.

frequency and sparsity of point clouds result in quick overfitting of individual frames including outliers (_cf._ Fig. 4(a)(b)). This leads to minimal pose updates when the overall loss decreases, resulting in incorrect poses and inferior reconstruction. Inspired by the capabilities of NeRF in pose inference , we decrease the learning rate (lr) of neural fields for the top k frames with the highest rendering losses as Eq. (10), while keeping lr of poses unchanged. The strategy facilitates gradient propagation towards outlier poses, while the gradient flow to the radiance fields is concurrently diminished. Consequently, it's analogous to leveraging a pre-trained NeRF for outlier pose correction and lessens the adverse effects caused by outliers during the optimization process.

\[_{outliers}=(w_{0}+l(1-w_{0}))_{inliers}(w_{0}>0)\] (10)

Where \(l\) denotes training progress. Akin to leaky ReLU , we set the reweighting factor \(w_{0}\) to a relatively small value. \(w_{0}\) increases as the process progresses, which ensures the network's ongoing learning from these frames and avoids stagnation.

### Improving Geometry Constraints for NeRF

Point clouds encapsulate rich geometric features. However, solely supervising NeRF training via range images pixel-wise fails to fully exploit their potential, _e.g._, normal information. Furthermore, the Chamfer distance can directly supervise the synthesized point clouds from a 3D perspective. Therefore, in addition to supervising via 2D range map, we propose directly constructing a three-dimensional geometric loss function between the generated point cloud and the ground truth point cloud. Unlike our Geo-optimizer, Eq. (11) imposes constraints between synthetic point clouds \(\) and ground truth point clouds \(P\):

\[_{CD}=}}_{_{i}}_{p_{i}  P}\|_{i}-p_{i}\|_{2}^{2}+}_{p_{i} P}_{ {p}_{i} P}\|p_{i}-_{i}\|_{2}^{2}\] (11)

Based on the point correspondences established between \(\) and \(P\) as derived in Eq. (11), the constraint of normal can be formulated as minimizing:

\[_{normal}=}}_{_{i} P}_{p_{i}  P}\|(_{i})-(p_{i})\|_{1}+ {N_{P}}_{p_{i} P}_{_{i} P}\|(p_{i})- (_{i})\|_{1}\] (12)

Thus, the normal loss is calculated between the synthetic point cloud and the ground truth point cloud to ensure more accurate normal vectors of the point cloud synthesized from NeRF. Moreover, we also employ 2D loss function to supervise NeRF as Eq. (13).

\[_{r}()=_{}_{d}\| ()-D()\|_{1}+_{s}\|}()-()\|_{2}^{2}+_{r}\| }()-()\|_{2}^{2}\] (13)

where \(D\) represents depth and \(,\) represents intensity and ray-drop probabilities. Consequently, the loss for Neural LiDAR fields is weighted combination of the depth, intensity, ray-drop loss and 3D geometry constraints, which can be formalized as \(=_{r}+_{n}_{normal}+_{c} _{CD}\).

## 4 Experiment

### Experimental Setup

**Datasets and Experimental Settings.** We conducted experiments on two public autonomous driving datasets: NuScenes  and KITTI-360  dataset, each with five representative LiDAR point cloud sequences. We selected 36 consecutive frames at 2Hz from keyframes as a single scene for NuScenes, holding out 4 samples at 9-frame intervals for NVS evaluation. KITTI-360 has an acquisition frequency of 10Hz. We used 24 consecutive frames sampled every 5th frame to match scene sizes of Nuscenes, holding out 3 samples at 8-frame intervals for evaluation. We perturbed LiDAR poses with additive noise corresponding to a standard deviation of \(20\) in rotation and \(3m\) in translation.

**Metrics.** We evaluate our method from two perspectives: pose estimation and novel view synthesis. For pose evaluation, we use standard odometry metrics, including Absolute Trajectory Error (\(\)) and Relative Pose Error (\(_{}\) in rotation and \(_{}\) in translation). Following LiDAR4D  for NVS evaluation, we employ CD to assess the 3D geometric error and the F-score with 5cm error threshold. Additionally, we use RMSE and MedAE to compute depth and intensity errors in projected range images, along with LPIPS , SSIM , and PSNR to measure overall variance.

**Implementation Details.** The entire point cloud scene is scaled within the unit cube space. The optimization of GeoNLF is implemented on Pytorch  with Adam  optimizer. All the sequences are trained for 60K iterations. Our Geometry optimizer's lr for translation and rotation is the same as the lr for pose in NeRF with synchronized decay. We use the coarse-to-fine strategy[31; 21], which starts from training progress 0.1 to 0.8. The reweight coefficient for the top-5 frames linearly increases from 0.15 to 1 during training. After every \(m_{1}\) epoch of bundle adjusting global optimization, we proceed with \(m_{2}\) epoch of pure geometric optimization, where \(m_{2}/m_{1}\) decrease from 10 to 1.

### Comparison in LiDAR Nvs

We compare our model with BARF  and HASH , both of which use LiDAR-NeRF as backbone. For PCR-assisted NeRF, we opt to initially estimate pose utilizing pose derived from GeoTrans , which is the most robust and accurate algorithm among other PCR methods in our experiments. And subsequently we leverage LiDAR-NeRF  for reconstruction. For all Pose-free methods, we follow NeRFmm to obtain the pose of test views for rendering. The quantitative and qualitative results are in Tab. 1 and Fig. 5. Our method achieves high-precision registration and high-quality reconstruction across all sequences. However, baseline methods fail completely on certain sequences due to their lack of robustness. Please refer to Fig. 7 for details. Ultimately, our method excels in the reconstruction of depth and intensity, as evidenced by \(7.9\%\) increase in F-score on Nuscenes and \(13.1\%\) on KITTI-360 compared to the second best result.

   &  &  &  \\  &  &  & RMSE & MeMeL & LPIPS & SSIM & PSNR & RMSE & MeMeL & LPIPS & SSIM & PSNR \\  BARF-LN [31; 51] &  & 1.2695 & 0.7589 & 8.2441 & 0.1123 & 0.1432 & 0.6856 & 20.80 & 0.392 & 0.0144 & 0.1023 & 0.6119 & 26.2330 \\ HASH-LN [21; 51] & & 0.3091 & 0.3001 & 7.8353 & 0.0441 & 0.1190 & 0.6543 & 20.6244 & 0.0599 & 0.0135 & 0.0954 & 0.6279 & 268.870 \\ GeoTrans [44; 51] & & 4.1587 & 0.2939 & 1.7699 & 1.2515 & 0.1445 & 0.3671 & 17.5858 & 0.0679 & 0.256 & 0.1149 & 0.3476 & 23.621 \\
**GeNeLf (Ours)** & & **0.2488** & **0.3667** & **0.3288** & **0.2081** & **0.0272** & **0.2746** & **23.047** & **0.0140** & **0.0140** & **0.0174** & **0.2738** & **268.078** \\  BAR-LN [31; 51] &  & 0.6136 & 7.5767 & 2.0583 & 0.5779 & 0.2834 & 22.5759 & 0.2121 & 0.1575 & 0.7121 & 0.1468 & 11.9778 \\ HASH-LN [21; 51] & & 2.6913 & 0.6802 & 6.3005 & 2.1686 & 0.5176 & 0.3752 & 22.6196 & 0.2040 & 0.1850 & 0.6508 & 1.0602 & 12.9286 \\ GeoTrans [44; 51] & & 0.5753 & 0.8116 & 4.4291 & 0.2023 & **0.3896** & 0.5300 & **25.6817** & 0.2070 & 0.1589 & 0.5753 & 0.2753 & 129.7070 \\
**GeNeLf (Ours)** & & **0.2363** & **0.9178** & **4.0293** & **0.1069** & 0.3900 & **0.0222** & 22.758 & **0.405** & 0.1525 & **0.3799** & **0.3456** & **16.5332** \\  

Table 1: **NVS Quantitative Comparison on Nuscenes and KITTI-360.** We compare our method to different types of approaches and color the top results as best and second best. All results are averaged over the 5 sequences.

Figure 5: **Qualitative comparison of NVS.** We compared GeoNLF with other pose-free methods and GeoTrans-assisted NeRF. Especially, GeoTrans fails on Nuscenes due to the inaccurate poses.

[MISSING_PAGE_FAIL:9]

driving scenarios. Additionally, GeoNLF targets point clouds within a sequence, relying on the temporal prior of the point clouds.

## 5 Conclusion

We introduce GeoNLF for multi-view registration and novel view synthesis from a sequence of sparsely sampled point clouds. We demonstrate the challenges encountered by previous pairwise and multi-view registration methods, as well as the difficulties faced by previous pose-free methods. Through the utilization of our Geo-Optimizer, Graph-based Robust CD, selective-reweighting strategy and geometric constraints from 3D perspective, our outlier-aware and geometry-aware GeoNLF demonstrate the promising performance in both multi-view registration and NVS tasks.

## 6 Acknowledgments

This work was supported by the National Key Research and Development Program of China (No.2024YFE0211000), in part by the National Natural Science Foundation of China (No. 62372329), in part by Shanghai Scientific Innovation Foundation (No.23DZ1203400), in part by Tongji-Qomolo Autonomous Driving Commercial Vehicle Joint Lab Project, and in part by Xiaomi Young Talents Program.

Figure 7: **Qualitative registration results of HASH-LN and GeoNLF on Nuscenes and KITTI-360 dataset.** The first row contains original inputs, the second row shows the results of HASH-LN, and the third row displays the results of GeoNLF.