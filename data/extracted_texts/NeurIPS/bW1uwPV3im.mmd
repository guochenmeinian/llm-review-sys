# LoRA: A Logical Reasoning Augmented Dataset for Visual Question Answering

Jingying Gao

School of Computer Science & Engineering

The University of New South Wales

jingying.gao@unsw.edu.au

&Qi Wu

School of Computer & Mathematical Sciences

The University of Adelaide

qi.wu01@adelaide.edu.au

&Alan Blair

School of Computer Science & Engineering

The University of New South Wales

a.blair@unsw.edu.au

&Maurice Pagnucco

School of Computer Science & Engineering

The University of New South Wales

morri@cse.unsw.edu.au

###### Abstract

The capacity to reason logically is a hallmark of human cognition. Humans excel at integrating multimodal information for logical reasoning, as exemplified by the Visual Question Answering (VQA) task, which is a challenging multimodal task. VQA tasks and large vision-and-language models aim to tackle reasoning problems, but the accuracy, consistency and integrity of the generated answers is hard to evaluate in the absence of a VQA dataset that can offer formal, comprehensive and systematic complex logical reasoning questions. To address this gap, we present LoRA, a novel Logical Reasoning Augmented VQA dataset that requires formal and complex description logic reasoning based on a food-and-kitchen knowledge base. Our main objective in creating LoRA is to enhance the complex and formal logical reasoning capabilities of VQA models, which are not adequately measured by existing VQA datasets. We devise strong and flexible programs to automatically generate 200,000 diverse description logic reasoning questions based on the SROIQ Description Logic, along with realistic kitchen scenes and ground truth answers. We fine-tune the latest transformer VQA models and evaluate the zero-shot performance of the state-of-the-art large vision-and-language models on LoRA. The results reveal that LoRA presents a unique challenge in logical reasoning, setting a systematic and comprehensive evaluation standard.12

## 1 Introduction

Logical reasoning is a fundamental hallmark of human cognition that enables us to understand and solve various problems, from everyday life to scientific research. Logical reasoning is the ability to analyze and identify logical relationships and derive conclusions or solutions based on known information or conditions . Humans are adept at integrating multimodal data for logical reasoning, such as visual, linguistic, or auditory information. A challenging task in artificial intelligence that requires such multimodal logical reasoning is Visual Question Answering (VQA). However, existing VQA datasets lack questions with complex logical structure, limiting the ability of these models to perform complex inference and multi-step reasoning. In this work, we introduce a new VQA dataset LoRA (Logical Reasoning Augmented Dataset), to address these challenges andexplore the logical reasoning capabilities of VQA and large vision-and-language models, and how they perform as the logical difficulty increases.

State-of-the-art VQA models have made significant strides in tackling reasoning problems that hinge on visual relationships and basic logical constructs such as 'and', 'or', and 'not'. Nonetheless, they struggle to perform complex inference and multi-step reasoning . Large vision-and-language models can execute complex multi-step reasoning. However, even the most advanced models still often produce logical errors. They exhibit a tendency to fabricate facts when facing uncertain information . It is unclear to what extent they understand the task, are capable of reasoning logically and generalizing, even if they perform well on the benchmark.

This can be largely attributed to the limitations of existing VQA datasets, which primarily offer questions with basic logical connections and not only fail to challenge the models to reason at higher levels of complexity, but also neglect to consider the logical difficulty and the performance of different approaches with increasing complexity. We studied and examined the logical syntactic complexity of the questions in several widely-used VQA datasets from 2016 to 2022  based on various logical categories and confirmed this limitation.

We introduce LoRA, a Logic Reasoning Augmented VQA Dataset, which addresses these issues with a focus on formal, complex, and diverse logical reasoning. The LoRA Dataset comprises 200,000 sophisticated and diverse logical reasoning questions based on the formal Description Logic SROIQ, based on realistic kitchen scenes, with ground truth answers, and logical prompt annotations. We devised multiple strong and flexible tools to automatically generate the LoRA dataset. The logical problems in LoRA span a wide and diverse range of complex logic, divided into three levels of increasing difficulty from simple to complex. This progression provides a more comprehensive evaluation of existing VQA methods, assessing to what extent their logical reasoning abilities have evolved, and highlighting for which logical reasoning tasks their performance is superior.

One example from our LoRA dataset is shown in Figure 1. These questions contain a number of different types of complex logical reasoning relationships, such as conjunction, disjunction, negation and "if... then" rule-based reasoning, etc. In order to answer such questions involving multiple different logical relationships, multi-step logical reasoning is required, based on diverse types of logical inferences.

Our experiments show that current multimodal methods fail to achieve satisfactory performance on the LoRA dataset and their performance decreases with the increasing difficulty level of the questions. The evaluation encompasses end-to-end training, transformer models within a fine-tuning setting, and large vision-and-language models in both zero-shot and few-shot learning settings on LoRA.

In summary, our contributions are three-fold: (1) we present LoRA, a novel VQA dataset that challenges the state-of-the-art models to solve 200,000 multimodal logical reasoning questions of high complexity and diversity; (2) our dataset comes with automated scripts that enable researchers to create and enrich their own logical questions, facilitating the growth and variety of logical reasoning datasets; and, (3) we leverage a formal definition of logical difficulty based on Description Logic to systematically evaluate the logical reasoning abilities of existing VQA and large vision-and-language models across different levels of complexity, revealing important directions for future research.

Figure 1: Sample image and questions from LoRA. Test questions are a combination of logical reasoning including rule-based conditional logic, conjunction, and negation.

[MISSING_PAGE_FAIL:3]

based on the formal Description Logic SROIQ, along with ground truth answers, logical prompt annotations, and 100,000 realistic kitchen scenes.

The LoRA dataset is created automatically via multiple flexible automated scripts. Figure 2 provides an overview of the LoRA generation pipelines. The dataset creation process includes five steps: (1) constructing the ontology, (2) formal description logic definitions, (3) automatically generating questions, (4) dynamically queried answers, (5) automatically generating images.

In constructing the LoRA dataset, we first created a kitchen domain-specific ontology and defined its logic syntax based on Description Logic. We implemented a script to automatically generate complex reasoning questions, enabling arbitrary expansion of question quantity and complexity. Furthermore, we designed a dynamic query algorithm for the automatic retrieval of answers. For realistic visual context, we developed a script that can be executed within the Blender environment to automatically generate realistic kitchen scene images corresponding to the questions. The ground truth answers are intentionally obfuscated by noise distractors to increase the level of difficulty. Last but not least, logical operators to construct the questions are included as logical prompt annotations. It should be emphasized that our dataset creation approach and pipeline are domain-agnostic, allowing adaptation to diverse knowledge areas.

### The Ontology

We used OWLReady2 to create our initial ontology (Knowledge Base, KB), and drew inspiration from public food ontologies such as FoodOn  and FoodKG . This ontology was framed using the industry-standard OWL format. The ontology defines domain knowledge through three elements: concepts (e.g., Food, Fruit), roles that represent atomic relations, (e.g., hasTaste); and individuals (e.g., apple). The ontology is defined as KB = (A, T), where: KB = ABox + TBox.

The **ABox** contains specific instances of the TBox concepts (e.g., apple, banana) and their attributes, covering both visible (e.g., red) and invisible attributes (e.g., sweet). The **TBox** defines concepts (e.g., Food, Fruit, Vegetable, Meal), along with relationships between them(e.g., isSubClassOf, isMadeFrom). Additionally, Semantic Web Rule Language (SWRL) rules are defined in the TBox for conditional logical reasoning.

The ontology provides formal representations and definitions for food and kitchen domain knowledge. The ontology provides three advantages: (1) it provides a rich vocabulary and knowledge base for question generation, (2) it standardizes and maps concepts to objects in images, (3) it enhances reasoning capabilities by enabling inference based on logical rules and knowledge. Our approach and pipeline to create the dataset is generalizable. It can work with any ontology (knowledge base) that adheres to the OWL specifications, which is the standard W3C Web Ontology Language.

### Formal Description Logic Definition

Description Logic (DL) is a family of formalisms for representing and reasoning with ontological knowledge. We use Description Logic syntax to formulate the logical questions in LoRA, as defined in Definition 1. Description Logic provides a standard way to construct the logical components of the questions, enabling diverse and sophisticated logical reasoning.

**Definition 1** (Description Logic Syntax).: _Let C, D be concepts, R is a role (possibly inverse), P is a simple role (possibly inverse), n is a non-negative integer; then C \(\) D, C \(\) D, \(\) C, \(\) R.C, \(\) R.C, \(\) nP.C, \(\) nP.C, are also concepts (Table 2)._

### Automatically Generated Questions

We propose an algorithm that generates complex logical reasoning questions by unrolling the on

   \\  Logic Categories & Syntax \\  atomic concept & C, D \\ atomic role & R \\ transitive role & \(R R^{+}\) \\ conjunction & \(C D\) \\ disjunction & \(C D\) \\ negation & \( C\) \\ concept inclusion & C \( D\) \\ existential restriction & \( R.C\) \\ universal restriction & \( R.C\) \\ number restrictions & \( nP.C\) or \( nP.C\) \\  

Table 2: Description Logic Grammar.

tology into dataframes and populating a matrix with concepts, roles, attributes, logical operators, and formulas. The questions are formed by randomly placing logical operators in the matrix, ensuring diverse reasoning types and difficulty levels. The generated questions exhibit human-like logic, involving both multimodal information and commonsense knowledge as well as symbolic logic.

Logical questions are automatically generated using a five-step procedure: 1) unroll the ontology, 2) generate logical questions with logical operators, 3) generate conditional logical questions with rules, 4) filter rules to avoid repetition, and 5) enrich question diversity using synonymous phrases.

#### 3.3.1 Unroll Ontology

We propose an algorithm that unrolls the ontology into a table format in three steps. First, we recursively extract the class hierarchy, relationship tuples, and object pairs from the ontology. For example, Vegetable is a subclass of Food, which is a subclass of Thing; (hasColor, Vegetable, Color) is a relationship tuple; and (carrot, orange) is an object pair. Second, we collapse the hierarchy into a list of dictionaries recursively, where each dictionary contains the entity and relationship information at each level. Finally, we transform the list of dictionaries into a dataframe with five columns: object classes, attribute classes, entities, attributes, and relationships. This dataframe is the basic building block for generating questions.

Our algorithm can unroll any ontology that is based on or can be converted to owlready2 , not only our customized ontology. This is because the framework we utilized to construct the ontologies is the industry-standard OWL format. It can work with any other domain ontology (knowledge base) that adheres to the OWL specifications, which is the standard W3C Web Ontology Language .

#### 3.3.2 Generate Logical Questions with Logical Operators

We propose an automated script to generate large numbers of logical questions with logical operators based on Description Logic (DL) syntax. We first define nine foundational logical operators based on DL syntax, which include AND, OR, NOT, inclusion, existential restriction, etc., shown in Table 3. These operators form a basic logical library that enables us to construct logical questions following the formal DL syntax.

To generate questions from an unrolled ontology represented as a table, we randomly select concepts, roles and entities to form a matrix of sentence blocks. We then apply logical operators to connect two or three sentence blocks within the matrix, resulting in logical questions with varying levels of complexity. Each row in the table corresponds to a branch of class, relation and entity pairs. By traversing the table, we can randomly combine class, relation and entity elements with diverse logical operators to create intricate questions with two or three layers of logical relationships.

The question template for the three-layer logical relationship is as follows: "\([QuestionTypes]\) Which \(|\) How many \(|\) Are there + \( concepts\) + \(\) sentence block 1 \(\) + logical operator + \(\) sentence block 2\(\) + logical operator + \(\) sentence block 3\(\)?" One such question could be: "\([Which]\)\(\) vegetables \(\) in the picture exhibit \(\) a conical shape \(\), **and**\(\) are rich in nutrient iron \(\), **or**\(\) possess internal seeds \(\)?"

To illustrate, the logical operators used are not confined to [not], [and], [or], but also include formal description logic syntax defined above as a benchmark. Different logic syntax are inserted into the matrix, for instance, using \( nP.C\), we can generate a question like "which vegetables in the picture contain at least two different tastes, and are rich in cellulose?"; C \(\) D: class hierarchy: e.g. "Which foods in the picture are meat but can provide high protein and shaped solids?"; R- inverse role: "Which food in the image can be used to cook a meal for vegetarians?".

#### 3.3.3 Generate Conditional Logical Questions with Rules

We extend our question generation pipeline to produce seven additional complex logical questions based on SWRL rules, illustrated in Table 4. For example, we use the following question template based on a SWRL rule: to cook [attribute] \( concept\), if we do not have \( object\), can we use other \( objects\) in the image instead? Question examples: to cook [spicy] \( noodles\), if we do not have \( pepper\), can we use other items in the image instead?

To generate complex logical questions, we need both the unrolled ontology table and the specific question templates. We design question templates based on SWRL rules and select and replace the 

[MISSING_PAGE_FAIL:6]

[MISSING_PAGE_FAIL:7]

### Question and Answer Types Analysis

**Question Types:** We categorize the question types in the LORA dataset into seven groups shown in Figure 3 based on the head of each question template: What, Which, How many, Is there..., Are there..., If... then, and Why...? The distribution of each question type in the dataset is shown in Figure 3, which also presents the data distribution based on ontology types and the question distribution based on logical reasoning types. The lengths of the logical questions range from eight to thirty words.

**Answer Types:** The answers within the dataset fall into four distinct categories: yes/no responses; individual or multiple objects (e.g., pumpkin, cheese); numerical values; and a small proportion of specialized responses, including answers to 'why' questions that incorporate relations and attributes. Examples of such specialized responses include "because it has juicy taste". or instances where the answer is "None". The length of the answers ranges from two words to a maximum of 23 words, varying based on the answer type.

Supplementary material Section A offers a more comprehensive data analysis, encompassing the analysis of the ontology, question types, and the distribution of question logic in LoRA. Section A.3 of the supplementary material provides examples of question logical complexity and answer inference complexity in LoRA, ranging from 3 to 9 required inference steps.

## 5 Baseline Experiments and Analysis

### Baseline Experiments

The VQA dataset was evaluated and analyzed via different VQA baseline models and large vision-and-language models. The evaluation results are shown in Table 5. In our methodology, we categorize the queries according to their intricacy, on a scale of 1 to 9. A score of 1 signifies a relatively straightforward query, while a score of 9 implies the necessity for more than nine logical deductions to infer the answer. In addition, a study of human performance was conducted, details of which can be found in Supplementary Section E.2.

**Ablation Study.** In order to carry out an ablation study and evaluate the capacity of baseline models to provide accurate answers without image data, question data, or external knowledge, we examined three models: a "deaf" CNN  model, a "blind" LSTM  model, and a CNN+LSTM model that made predictions based on visual and linguistic features, but without a knowledge base. The performance of all three models was found to be unsatisfactory, underscoring the importance of integrating visual, question, and knowledge base information for effective VQA reasoning.

**End-to-End Training Baseline.**

We trained MAC network  end-to-end on the LoRA dataset, inputting both visual and question language features to estimate the accuracy for each type of logical question. The MAC network struggled with rule-based and complex logical questions compared to simple ones, resulting in 64.6% accuracy.

**Fine-tuning Baseline.** Moreover, we trained and fine-tuned the VisualBERT model , based on the transformer architecture, on the LoRA dataset. Visual features were extracted using a pre-trained detectron2 model, while BERT was used for question features. These image and language features were fed into vision-and-language fusion layers to predict final answers. Despite

Figure 3: Dataset Statistics: Ontology types, question types, and logical reasoning types.

the significant improvement in performance brought by the transformer of VisualBERT over other models, it displayed a decrease in its ability to answer complex questions as reasoning complexity increased, from 85.1% to 57.8%.

**Zero-shot Baselines.**

We evaluated the zero-shot performance of cutting-edge large vision-and-language models (VLMs), specifically, MiniGPT4 , Multimodal-GPT , InstructBLIP , and Multimodal Chain-of-Thought (MMCoT)  across three model types: in-context learning, instruct-tuning, and zero-shot CoT, using our LoRA dataset. We used the questions from the LoRA dataset as the prompts, with the accompanying images serving as the input images for these models for zero-shot experiments. Each question in the dataset not only guided the model in the direction of the answer but also implicitly highlighted the logical construct being evaluated. Our results revealed that all four models exhibited basic VQA capabilities, managing to answer questions that do not require much logical reasoning. They could also handle simple negation questions, but inconsistently. However, limitations were evident. The models occasionally ignore the visual information in the image and generate answers solely based on textual knowledge, especially MiniGPT4. Furthermore, they faltered in providing comprehensive responses involving multiple objects, often only listing one or two. Moreover, they are inconsistent and tend to fabricate answers that are often incongruent with the image content. Among the four models, InstructBLIP outperforms the other models with an average accuracy of 41.2%, but it performs poorly on complex logical questions that require more than six inference steps, achieving only 30.5% accuracy. MiniGPT4 struggles with negation questions that involve invisible attributes and complex logical questions involving multimodal inference. MMCoT exhibited suboptimal performance in VQA logical reasoning tasks, producing reasoning chains with logical inconsistencies.

**Few-shot Baseline.**

Furthermore, we evaluated Multimodal Chain of Thought based on the few-shot setting. We provided the logical operator that constructed each question as the prompting context to the model when asking it to answer each question. Using the logical operators of the questions as prompts improved the performance by 5.87% compared to not using them. Further analysis shows that logical prompts can help multimodal models stimulate logical thinking better.

### Error Analysis

The following analysis investigates the different behaviors and performance of VQA models and multimodal LLM models, delving deeper into the underlying reasons behind the observed model behavior, and elucidates the potential factors that contribute to the strengths or weaknesses of a particular model.

#### 5.2.1 MAC and VisualBERT's Challenges in Complex Logical Reasoning

The MAC network and VisualBERT model, despite their groundbreaking advancements in VQA, primarily rely on deep neural networks to derive implicit representations from the provided data. Deep learning models, by their very nature, often lack the inherent capacity to reason in an explicit, step-by-step manner that might be required for intricate logical constructs. Instead, these models tend to predict answers based on the patterns and associations they have learned. While this approach works efficiently for numerous tasks, it may not provide the rigorous, step-by-step logical reasoning required for our dataset, especially when questions increase in complexity.

#### 5.2.2 Multimodal LLMs Baselines' Challenges in Complex Logical Reasoning

Building on our observations from the zero-shot and few-shot experiments, we further analyzed challenges faced by large vision-and-language models (VLMs). We observed that large vision-and-language models demonstrate deficiencies in handling logical constructs, especially with operators like negation and multiple logical operators appearing in a question. For example, when presented with negation-centric queries, these models tend to produce keyword-driven positive responses, overlooking inherent logical relationships. Such tendencies underscore that, despite expansive training data, these models lack genuine "logical understanding".

[MISSING_PAGE_FAIL:10]