# Semantics and Spatiality of Emergent Communication

Rotem Ben Zion\({}^{1}\) Boaz Carmeli\({}^{1}\) Orr Paradise\({}^{2}\) Yonatan Belinkov\({}^{1}\)

\({}^{1}\) Technion - Israel Institute of Technology \({}^{2}\) UC Berkeley

rotm@campus.technion.ac.il boaz.carmeli@campus.technion.ac.il orrp@eecs.berkeley.edu belinkov@technion.ac.il

###### Abstract

When artificial agents are jointly trained to perform collaborative tasks using a communication channel, they develop opaque goal-oriented communication protocols. Good task performance is often considered sufficient evidence that meaningful communication is taking place, but existing empirical results show that communication strategies induced by common objectives can be counterintuitive whilst solving the task nearly perfectly. In this work, we identify a goal-agnostic prerequisite to meaningful communication, which we term _semantic consistency_, based on the idea that messages should have similar meanings across instances. We provide a formal definition for this idea, and use it to compare the two most common objectives in the field of emergent communication: discrimination and reconstruction. We prove, under mild assumptions, that semantically inconsistent communication protocols can be optimal solutions to the discrimination task, but not to reconstruction. We further show that the reconstruction objective encourages a stricter property, _spatial meaningfulness_, which also accounts for the distance between messages. Experiments with emergent communication games validate our theoretical results. These findings demonstrate an inherent advantage of distance-based communication goals, and contextualize previous empirical discoveries.

## 1 Introduction

Humans use language in multi-agent social interactions. Pressures of synchronization and collaboration play a central role in shaping the way we communicate. Motivated by this observation and the goal of creating artificial agents capable of meaningful communication, the field of emergent communication (EC) employs a multi-agent environment jointly trained to accomplish a task that requires active transmission of information. The agents utilize a messaging channel that usually takes the form of a discrete sequence of abstract symbols, resembling the structure of human language. Successful optimization results in synchronized agents operating a newly developed communication protocol tailored to the objective. We study a type of EC setup inspired by Lewis games  where a sender agent describes a given input and a receiver agent makes a prediction based on that description. The game objective is designed to make the receiver demonstrate knowledge of the original input, which in turn compels the sender to encode relevant information in the message. There are two common objectives used in this type of EC setup (illustrated in Figure 1):

**Reconstruction**: In the reconstruction task , the original input is re-generated based solely on the message. We are specifically interested in a reconstruction objective that quantifies distance between prediction and target, forming a discrete version of autoencoding .
**Discrimination**: In the discrimination task , the original input is retrieved from a set of candidates, incentivized by negative log-likelihood.

A central goal in EC, which motivates our work, is understanding how different factors in the environment affect the emergent protocol, and specifically developing agents and objectives that create protocols with similar characteristics to natural language [2; 25; 40; 41; 45]. Tools and experiments have been developed to evaluate the proximity to natural language by testing for properties such as compositionality  or efficiency . Unfortunately, many of these empirical methods show great dissimilarity to human communication. One particularly surprising experiment  revealed that protocols created via the discrimination task can generalize extremely well to random noise data, suggesting that they do not signal human-recognizable (meaningful) properties of the input.

In this paper, we identify a fundamental property of any meaningful communication protocol, and thus a prerequisite for similarity to natural language. We observe that the discrete bottleneck forces EC protocols to be many-to-one mappings, i.e., that messages likely represent more than one input. With this in mind, we claim that inputs mapped to the same message should be _semantically similar_, as is the case with human language. We formalize this idea with a mathematical definition that we term **semantic consistency**. We further develop a stricter version of this definition, **spatial meaningfulness**, which also accounts for distances between messages, and is therefore better suited to indicate similarity to natural language.

Armed with these definitions, we analyze theoretical solutions to the two common EC environments. In the reconstruction setting, under mild assumptions, we prove that **every optimal solution is semantically consistent**. With a different set of assumptions, we also show that reconstruction-induced communication protocols are spatially meaningful. In sharp contrast, we surprisingly find that the discrimination objective **does not guarantee semantic consistency**, i.e., a communication protocol can be optimal in a discrimination environment but still not semantically consistent nor spatially meaningful. In fact, we show that uniformly random messages can lead to a globally optimal discrimination objective value, meaning that the relationship between inputs mapped to the same message is potentially arbitrary despite optimally solving the task. Our results provide theoretical support to previous empirical findings, such as the discrimination generalization to noise. We further analyze several common variations of the discrimination game from the EC literature.

To support our findings, we run experiments on Shapes  and MNIST . The empirical results agree with most of our theoretical findings. However, we observe a gap between theory and practice regarding the level of channel utilization, which we leave for future work to further investigate.

## 2 Background and related work

### Emergent communication with Lewis games

A large portion of EC research, based on Lewis signaling games [28; 32], defines two-agent cooperative tasks where one agent, \(S_{}\) ("sender"), receives an input \(x\) ("target") and generates a message \(m M\), and the second agent, \(R_{}\) ("receiver"), takes that message and outputs a prediction. The two most common such tasks are reconstruction and discrimination.

In the reconstruction task, the receiver tries to predict the target directly from the message. This is a generative method, so it can naturally be modeled with a receiver that outputs a distribution over the input space [7; 41; 42; 44], i.e., \(R_{}:M()\). In this case, the objective is usually negative log-likelihood or accuracy. However, this approach has two major flaws: First, explicitly outputting a distribution is not always feasible, e.g., over images. Thus, this game is mostly implemented on simple synthetic datasets. Second, the incentive of likelihood or accuracy does not measure _how_

Figure 1: Illustration of the reconstruction and discrimination tasks. The discrimination receiver is given the candidates in addition to the message.

_close_ the receiver's output is to \(x\).1 In this work, we assume a different approach to reconstruction, inspired by autoencoders [18; 34], where the receiver outputs an object in the input space rather than a distribution, i.e., \(R_{}:M\). Thus, the loss function in our analysis is straightforwardly the distance between prediction and target.

In the discrimination task, the receiver tries to identify the target within a set of candidates [17; 28; 29; 33; 44]. It can be modeled as \(R_{}:M^{d}\{1,,d\}\). We explore some alternative formulations in Appendix F. This setting introduces two major choices: the number of distractors (candidates other than \(x\)) and how to select them [12; 29]. These parameters have been shown to have a major effect on the resulting protocols [15; 29]. The results in the main body of this paper concern the vanilla version of the discrimination task, where candidates are chosen independently. We analyze other discrimination versions in Appendix A.

### Towards interpretable human-like communication

A central line of study aims to develop EC systems that create protocols with high proximity to natural language. Some have tried aligning the two explicitly, by using pretrained language models [31; 43] or training translation systems [45; 46]. In this work, we focus on properties of the EC protocol itself, as induced by the objective rather than exposure to text. The most studied such characteristic is compositionality, which refers to the ability of agents to assemble complex units (e.g., sentences) from simpler units (e.g., words). Compositionality is hard to measure [1; 5; 6; 24; 37], and while some claim that it is correlated with generalization [2; 40; 42], the opposite has also been argued [8; 11; 13]. In any case, emergent languages are often not compositional , inefficient [7; 41], and generalize to noise , suggesting a mismatch between common EC objectives and the evolution of human language. In this work, we advance the goal of creating human-like communication by interpreting properties of natural language into formal constraints, and analyzing whether the EC objectives create protocols that follow them. A commonly used compositionality measure, topographic similarity (topsim) , is related to the definitions presented in this work. It evaluates the correlation between distances in the input space and the corresponding distances in the messages space. Notably, topsim considers the relationship between every pair of inputs, whereas our definitions only consider pairs that correspond to similar messages. The latter follows an intuitive asymmetry: inputs with similar messages are expected to be similar, but inputs with dissimilar messages do not have to be different (for example, the same image can often be described by several distinct human captions).

### Input information encoded in the message

The game objective dictates the information that needs to be stored in messages. In this work, we focus on spatial information by considering the geometric relationship between inputs mapped to the same message. To the best of our knowledge, no previous work has theoretically analyzed this idea in EC literature. A related concept is the mutual information (MI) between messages and inputs, which has been studied both empirically [1; 15; 23; 35; 45] and theoretically [19; 21; 42]. MI is strongly related to the infoNCE objective  often used in implementations of the discrimination game. MI can be used to measure the complexity of the communication channel [44; 45], and is correlated with task performance [23; 45] and even compositionality . Finally, The mutual information gap  can be used to measure disentanglement [8; 13], which is also related to compositionality. However, Guo et al.  show that MI is not sufficient to indicate transfer-learning generalization, and connect that to pairwise distances of inputs mapped to the same message, effectively testing for semantic consistency. The first part of this work, combined with their findings, would suggest that languages developed by agents in the reconstruction setting should be more expressive and generalize better to different tasks.

On the theoretical side, a relevant work is Rita et al. , where the global discrimination objective is decomposed into two interpretable components, a co-adaptation loss and MI. The latter is equivalent to our Lemma A.1. In this work, we use such equivalent objectives for both the reconstruction and discrimination tasks to investigate the behaviour of optimal solutions, and specifically whether the tasks encourage semantic consistency.

## 3 Notation and task definitions

### General notation

We begin by introducing general notation for the EC setup; see Figure 2 for illustration. The input space is modeled by a real-valued random variable \(X=(,f_{X})\), where \(^{d_{x}}\) is the bounded set of possible inputs (e.g., images), and \(f_{X}:_{+}\) is a prior distribution. Denote by \(M=\{m_{1},m_{2},\}^{d_{M}}\) the finite or countably infinite set of possible messages.2 We assume that the minimal distance between a pair of messages is attained, i.e., that \(_{m_{1} m_{2} M} m_{1}-m_{2}(0,)\).

The _sender_ agent \(S_{} M\), parameterized by \(\), maps each input to a message. Sender \(S_{}\) defines the communication protocol; we compare EC setups based on which optimal sender agents they induce. The _receiver_ agent \(R_{}\), maps the message and optionally additional input to a prediction. It is parameterized by \(\). During EC training, the goal is to learn hypotheses \((,)\) that minimize a _loss_ described by a function \(\), which maps a pair of agents and an input to a real value. To group all of the above notation into a single definition, denote an _EC setup_ as a sextuple \((,f_{X},M,,,)\). An EC setup induces a set of _optimal_ agents by

\[^{*},^{*}*{arg\,min}_{, }*{}_{ X}(,,x).\]

Note that every part of the setup can affect the set of optimal agents. We also define a notion of conditional optimality, where one of the agents is fixed at a potentially sub-optimal hypothesis; sender \(S_{}\) is _synchronized_ with receiver \(R_{}\) if the pair is optimal for the EC setup \((,f_{X},M,,\{\},)\). The same definition applies to the receiver agent respectively. Note that a pair of agents can be synchronized in both directions without being optimal.

### Task definitions

In the reconstruction setting, the receiver agent predicts the original input (the "target") given only the message. In the discrimination setting, the receiver is given the message and a set of candidate inputs containing the target in a random position, and attempts to predict that position based on the message. A visual illustration can be seen in Figure 1. We now present formal definitions of these setups.

Reconstruction.The receiver maps a message \(S_{}(x)\) to a prediction in the input space. The loss is the Euclidean distance between that prediction and the target \(x\).

* \(^{M,}_{}\) is defined as the set of all functions of the form \(R M\).
* \(_{}(,,x):= R_{}(S_{}( x))-x^{2}\).

**Definition 1**.: An EC setup \((,f_{X},M,,,)\) is a _reconstruction game_ if \(^{M,}_{}\) and \(=_{}\). It has an _unrestricted_ receiver hypothesis class if \(=^{M,}_{}\).

Discrimination.In addition to a message \(S_{}(x)\), the receiver sees a set of candidates \(\{x_{1},,x_{d}\}\), which contains the target at a random position \(t\), i.e. \(x_{t}=x\), and the rest are \(d-1\) independently sampled distractors. The receiver outputs a probability distribution over the candidates. The loss is the negative log-likelihood of the correct position \(t\) according to this distribution, averaged over the target position and distractors.

Figure 2: Notation for the emergent communication (EC) setup.

* \(_{}^{M,,d}\) is defined as the set of all functions of the form \(R M^{d}\{1,,d\}\).
* \(_{}^{M,,d}(,,x):=t U\{1,,d\},\ x_{t}=x\\ x_{1},,x_{(t-1)},x_{(t+1)},,x_{d} X^{d-1}}{}- P(R_{}(S_{}(x),x_{1},,x_{d})=t)\).

**Definition 2**.: An EC setup \((,f_{X},M,,,)\) is a \(d\)-_candidates discrimination game_ if \(_{}^{M,,d}\) and \(=_{}^{X,d}\). It has an _unrestricted_ receiver hypothesis class if \(=_{}^{M,,d}\)

In this vanilla version of the discrimination game, the candidates are sampled independently. Several other choice mechanisms have been explored in EC literature. In Appendix A, we define and analyze the most common such variations:

**Global discrimination**: In Appendix A.1, we analyze a version of the discrimination game where the receiver outputs a distribution over the entire data rather than a small set of candidates. We find that optimal communication protocols in this setting maximize mutual information between the inputs and messages, as shown in Rita et al. .
**Supervised discrimination**: Appendix A.2 explores a variant of the discrimination game that incorporates labels by selecting distractors with labels different from the target. We find that optimal communication strategies in this setting are both diverse (the sender is encouraged to output messages uniformly) and pure (labels distribute with low entropy given a message).
**Classification discrimination**: In Appendix A.3, we consider a format of the discrimination game where the target is excluded from the candidate set, requiring the receiver to identify a candidate that matches the target's label. We find that optimal solutions in this setup maximize mutual information between messages and labels.

## 4 Semantic consistency: a prerequisite to meaningful communication

In many EC environments, the message is a latent representation of the input, and is often directly analogous to the corresponding latent vector from continuous training setups (e.g. autoencoding, contrastive learning). That said, the discrete bottleneck in EC offers an additional perspective to the concept of a message; when the message space is smaller than the input space, the communication protocol is forced to be a many-to-one mapping, meaning that each message represents a _set_ of inputs.

We consider inputs mapped to the same message as _equivalent_ with respect to the communication protocol, thus defining a set of equivalence classes that partitions the input space. With this perspective in mind, we wish to understand whether this partition signals meaningful properties of the inputs. In other words, we ask the question: _Is there a meaningful relationship between inputs mapped to the same message?_ This motivation is illustrated in Figure 3.

The semantics of a message can be interpreted as the set of properties shared across all inputs in its equivalence class. We would like to design a theoretical test that evaluates whether meaningful properties are encoded in this way in an emergent communication protocol. We term this notion _semantic consistency_, based on the idea that inputs with shared properties are more semantically similar, as illustrated in Figure 3. We use the same idea to develop a formal definition: We define a communication protocol to be semantically consistent if a random pair of inputs mapped to the

Figure 3: A message describes a set of inputs. Note: the shapes and colors are not part of the input.

same message is, in expectation, more similar than two completely random inputs. Formally, for a communication protocol \(S_{}\), consider the following inequality: 3

\[}_{x_{1},x_{2}}\|x_{1}-x_{2}\|^{2}\ \ S_{}(x_{1})=S_{}(x_{2})<}_{x_ {1},x_{2}}\|x_{1}-x_{2}\|^{2}.\] (1)

Equation (1) is simplified in Appendix C.1 into the following formal definition:

**Definition 3**.: A communication protocol \(S_{}\) is _semantically consistent_ if

\[}_{m S_{}(X)}[[X\ |\ S_{}(X)=m]]<[X].\]

The difference between the two expressions in Definition 3 is the _explained variance_, given by \(_{m S_{}(X)}[}[X\ |\ S_{}(X)=m]]\). Thus, a communication protocol is semantically consistent if it explains some of the variance in \(X\).

_Remark_.: If the message space is larger than the input space, a sender could map each input to a unique message and lose no information. Any such lossless protocol is trivially semantically consistent.

## 5 Are EC systems semantically consistent?

Having defined the two common EC environments in Section 3.2, we now apply Definition 3 to assess whether semantically consistent protocols are induced by reconstruction and discrimination tasks. Formally, we answer the following question for each of the tasks:

_Is every optimal emergent protocol semantically consistent?_

Under the assumption of an unrestricted receiver hypothesis class, we find that:

* In the reconstruction game, the answer is **yes**. We show that equivalent inputs in reconstruction-induced communication protocols are clustered together in input space, matching Figure 2(b).
* In the discrimination game, the answer is **no**. The relationship between equivalent inputs in a discrimination-induced protocol can be arbitrary, matching Figure 2(c).

All proofs are given in Appendix C.

### Reconstruction results

Ideally, we would like to examine a closed-form set of optimal communication protocols. Unfortunately, there is no closed-form solution to the set of optimal agent pairs in a general reconstruction setting. That said, we do have such a solution to the synchronized receiver, i.e., the optimal receiver for a fixed sender \(S\) (the following \(\) set contains a single item):

\[R^{*}(m)=_{r}}_{x X} [\|r-x\|^{2}\ \ S(x)=m]=}[X\ |\ S(X)=m]\]

By assuming that \(\) is unrestricted, we can plug the closed-form synchronized receiver back into the loss function. This yields a transformed objective given in the following lemma.

**Lemma 5.1**.: [proof in page 16] _Let \((,f_{X},M,,,)\) be a reconstruction game. Assuming \(\) is unrestricted, a sender \(S_{}\) is optimal if and only if it minimizes the following objective:_

\[_{m M}P(S_{}(X)=m)[X\ |\ S_{}(X)=m]\] (2)

This equivalent objective clearly shows the connection between inputs mapped to the same message: In every optimal solution, these inputs will have high proximity. (In fact, this is the objective function of k-means clustering , as elaborated in Appendix B.) Moreover, this formula is the unexplained variance, so minimizing it will maximize the explained variance, leading to the following theorem.

**Theorem 5.2**.: [proof in page 17] _Let \((,f_{X},M,,,)\) be a reconstruction game. Assuming \(\) is unrestricted and \(\) contains at least one semantically consistent protocol, every optimal communication protocol is semantically consistent._

### Discrimination results

In a similar fashion to the reconstruction setting, we have a closed form solution to the synchronized discrimination receiver:4

\[R^{*}(m,x_{1},,x_{d})=(t x_{1},,x_{d},m)\]

Explicitly (see Lemma 5.3's proof):

\[P(R^{*}(m,x_{1},,x_{d})=j)=,,x_{d}\}  S^{-1}(m)|}\{S(x_{j})=m\}\]

Applying this receiver, we get the following discrimination loss:5

**Lemma 5.3**.: [proof in page 17] _Let \((,f_{X},M,,,)\) be a \(d\)-candidates discrimination game. Assuming \(\) is unrestricted, a sender \(S_{}\) is optimal if and only if it minimizes the following objective:_

\[_{m M}P(S_{}(X)=m)\ 1+d-1,P(S_{}(X)=m)\] (3)

_And when \(d=2\) (a single-distractor game), this simplifies into: \(_{m M}P(S_{}(X)=m)^{2}\)._

This equivalent objective reveals the interesting disparity between reconstruction and discrimination. Note that this objective is solely a function of the'sizes' of equivalence classes (the probability for each message). Thus, while the above formula incentivizes the sender to distribute the messages uniformly, it does not impose any constraint on their content; the connection between inputs mapped to the same message could be arbitrary. In formal terms, we prove the following corollary:

**Corollary 5.4**.: [proof in page 19] _If the set of possible messages is finite, any sender agent that assigns them such that their distribution is uniform can be paired with some receiver to obtain a globally optimal loss for the discrimination game._

Using this corollary, we prove that optimal solutions can be inconsistent in the discrimination setting:

**Theorem 5.5**.: [proof in page 20] _There exists a discrimination game \((,f_{X},M,,,)\) where \(\) is unrestricted and \(\) contains at least one semantically consistent protocol, in which not all of the optimal communication protocols are semantically consistent._

## 6 A missing dimension: spatiality in the message space

While the notion of semantic consistency successfully differentiates between the two EC frameworks, it has a major shortcoming: is does not take into account distances between messages. Spatiality in the message space is integral to concepts like compositionality  and ease of teaching . A hypothetical communication protocol that maps similar messages to very different meanings may satisfy Definition 3, but is fundamentally different from natural language. We now present a stricter version of semantic consistency, _spatial meaningfulness_, which does consider distances in the message space, and therefore better indicates an inherent similarity to natural language. In addition, we eliminate the assumption that the receiver's hypothesis class is unrestricted, in favor of simplicity and non-degeneracy conditions, which are more realistic in the context of natural language.

To introduce distance between messages, we replace the message equality with similarity in Equation (1). Let \(_{0}\) denote a threshold under which messages are considered similar. To avoid reverting back to Definition 3, we require that \(_{0}\) be greater than or equal to \(_{M}\), defined as the minimal distance between messages: \(_{M}:=_{m_{1} m_{2} M} m_{1}-m_{2}\).6

**Definition 4**.: For \(_{0}_{M}\), a communication protocol \(S_{}\) is \(_{0}\)-_spatially meaningful_ if \( 0<_{0}\)

\[*{}_{x_{1},x_{2}} x_{1}-x_{ 2}^{2}\ \  S_{}(x_{1})-S_{}(x_{2}) <*{}_{x_{1},x_{2}}  x_{1}-x_{2}^{2}\]

A communication protocol \(S_{}\) is _spatially meaningful_ if this definition holds for \(_{0}=_{M}\).

Note that this definition is stricter than semantic consistency. Informally, Definition 4 requires the protocol to be semantically consistent when combining pairs of close messages.

With this new definition, we are able to reach similar results to the original semantic consistency:

* In the reconstruction game, for any receiver that satisfies two conditions, we show that every synchronized sender is spatially meaningful.
* In the discrimination game, given the same conditions, we show that a synchronized sender is not necessarily semantically consistent (and hence nor spatially meaningful).

We now define two conditions on the receiver.

Simplicity constraint.The first condition limits the receiver's complexity, and introduces the effect of distance between messages. We do that by bounding the rate of change in receiver's output, similarly to a Lipschitz constant. The bounding term depends on the variance of the input distribution and the chosen distance threshold. Formally:

**Definition 5**.: Receiver \(R_{}\) is _\((X,M,_{0})\)-simple_ if \( x_{1},x_{2}(R_{})\):

\[\|R_{}(x_{1})-R_{}(x_{2})\| k\|x_{1}-x_{2}\|,  k=-1}{2_{0}}[X]}\]

Non-degeneracy constraint.The second condition prevents the receiver from being too weak. After applying the first condition, we no longer have a closed-form solution for the synchronized receiver. Instead, we take a non-optimal receiver, but add a condition to ensure it is strictly better than any constant function. Formally, let \(^{C}\) be a receiver that always outputs \(C\), and let \(C^{*}=}(,^{C},x)\) be the optimal such constant. (Note the sender does not matter here.)

**Definition 6**.: Receiver \(R_{}\) is _non-degenerate_ if

\[_{x}(^{*},,x) }(,^{C^{*}},x)\]

for every sender \(^{*}\) that is synchronized with \(R_{}\).

### Results

With these definitions, we have the following theorems:

**Theorem 6.1**.: [proof in page 21] _Let \((,f_{X},M,,,)\) be a reconstruction game, let \(_{0}_{M}\) and let \(\) such that \(R_{}\) is \((X,M,_{0})\)-simple and non-degenerate. Every sender that is synchronized with \(R_{}\) is \(_{0}\)-spatially meaningful._

**Theorem 6.2**.: [proof in page 22] _There exists a discrimination game \((,f_{X},M,,,)\), \(_{0}_{M}\) and a receiver \(\) which is \((X,M,_{0})\)-simple and non-degenerate, where a synchronized sender matching \(R_{}\) is not \(\)-spatially meaningful for any \(\)._

## 7 Experiments

To support our theoretical findings, we run experiments on two datasets: (i) the MNIST dataset  contains images of a single hand-written digit; (ii) the Shapes dataset  contains images of an object with random shape, color and position. We train reconstruction and discrimination (40 distractors) agents using a communication channel of vocabulary size 10 and message length 4 (no EOS token), optimized with Gumbel-Softmax [20; 22]. In the MNIST experiments, we use the digit labels to train another set of agents with the supervised discrimination task (40 distractors). Further data and training details are found in Appendix D.1.

### Semantic consistency, compositionality and task performance

To evaluate semantic consistency empirically, we develop the _empirical message variance_ measure (in Appendix D.2) which calculates the empirical variance of each equivalence class and takes a weighted average. We measure task performance using discrimination accuracy over 41 candidates (40 distractors), where the referential prediction of reconstruction-trained agents is defined as the closest candidate to the reconstructed target. We also report Topographic Similarity , the most common compositionality measure from literature. See Appendix E.1 for results with other compositionality measures (PosDis , BosDis  and Speaker-PosDis ). Additional information on each metric is given in Appendix D.2.

Table 1 and Table 2 show results over the Shapes and MNIST validation sets, respectively (showing standard deviation). While all setups achieve good task performance over MNIST, the discrimination game yields higher discrimination accuracy over the more difficult Shapes dataset, As expected. Interestingly, the discrimination-trained agents utilize less of the communication channel's capacity, as shown by the number of unique messages in both tables. This presents a gap from the theoretical analysis, as the discrimination setting should benefit from maximal message diversity (this can be seen in Lemma 5.3). To enable a fair comparison, we establish individual random baselines that maintain the number of inputs mapped to each message but randomize their assignment. Thus, the baseline's message variance shows the level of message diversity induced by the task, whereas the improvement over the baseline indicates semantic consistency. Over both datasets, the reconstruction task induces significantly more semantically consistent protocols both in absolute value and improvement over the baseline, as predicted by our theoretical findings. Furthermore, TopSim strongly favors the reconstruction setting, suggesting a connection between semantic consistency and compositionality. We note that the difference measured by TopSim is more significant over the Shapes dataset, which is itself more compositional, as objects have several attributes. These results, and the correlations reported in Appendix E.1, indicate little to no correlation between the evaluated compositionality and the discrimination objective performance. In fact, within the set of reconstruction runs on Shapes, their correlation is negative (\(-0.24\)). This illustrates the counter-intuitive nature of this objective, which we discuss in Section 5.2.

### Message purity

Since the MNIST dataset has only the digit label, we expect meaningful communication protocols to signal digits in their messages. To evaluate this, we calculate the percentage of images that have the majority digit label of their equivalence class. This can be interpreted as the highest attainable accuracy of a classifier mapping messages to digits. Figure 4 shows the most significant improvement over the baseline in the supervised discrimination game, as expected by Lemma A.2. The reconstruction task induces a nearly perfect digit description protocol as well, despite being unsupervised, providing evidence of its ability to unveil meaningful properties, in agreement with our findings. On the other hand, message purity is much lower in the unsupervised discrimination setting, again showcasing that task success does not guarantee an intuitive communication strategy.

In Appendix E.2, we perform a similar analysis over the Shapes dataset, by evaluating message purity with respect to each attribute individually or to a maximum aggregation. We find similar but weaker results.

    & & & &  \\  EC setup & Unique Msgs & Disc. accuracy \(\) & TopSim \(\) & Trained & Rand \\  Reconstruction & 306.60 \( 28.52\) & 31.64 \( 2.51\) & 0.34 \( 0.02\) & 1334.38 \( 78.05\) & 2554.77 \( 108.19\) \\ Discrimination & 251.60 \( 29.53\) & 61.96 \( 4.78\) & 0.09 \( 0.01\) & 2280.24 \( 157.38\) & 2793.65 \( 115.45\) \\   

Table 1: Empirical results on Shapes, averaged over five randomly initialized training runs.

    & & & &  \\  EC setup & Unique Msgs & Disc. accuracy \(\) & TopSim \(\) & Trained & Rand \\  Reconstruction & 2523.66 \( 30.0\) & 88.00 \( 0.6\) & 0.365 \( 0.042\) & 371.63 \( 2.1\) & 1029.57 \( 13.9\) \\ Discrimination & 402.00 \( 70.4\) & 78.76 \( 10.4\) & 0.360 \( 0.036\) & 1226.14 \( 42.4\) & 1784.59 \( 24.3\) \\ Supervised disc. & 287.33 \( 28.5\) & 87.10 \( 5.4\) & 0.269 \( 0.044\) & 1381.72 \( 41.6\) & 1821.53 \( 12.2\) \\   

Table 2: Empirical results on MNIST, averaged over three randomly initialized training runs.

### Spatial meaningfulness analysis

We develop an evaluation method for spatial meaningfulness, which we term _cluster variance_, based on the message variance measure. While we do not find a decisive result using this method, we suggest several ideas for further investigation; see Appendix E.3 for the full analysis.

## 8 Limitations

Our analysis compares the two frameworks via their optimal solutions, and often assumes unrestricted hypothesis classes. In reality, the complexity of the agents is limited by the chosen architectures. Optimization-error affects the emergent protocol as well, especially when it is discrete, as regular differentiable training is not possible. Future work may further analyze these assumptions from the theoretical side, or evaluate their effect empirically. This limitation is evident in our empirical results (Section 7), where channel utilization in the discrimination game behaves differently than expected.

Our main results regarding the discrimination game deal with a simplistic version, where candidates are chosen independently. While we analyze some common variations in the appendix, many other ideas have been proposed and shown to have significant benefits, including multiple-target games , different-view candidate representations , and multi-modality .

Our results assume, as illustrated in Figure 3, that proximity in the input space entails semantic information, and specifically that Euclidean distance broadly indicates the level of semantic similarity. Future work may investigate other distance metrics or evaluate the validity of this assumption.

## 9 Conclusion

Based on properties of natural language, we have defined notions of semantic consistency and spatial meaningfulness, meant to evaluate meaningfulness in emergent communication protocols. Using these definitions, we found that communication protocols generated to solve the reconstruction objective have messages with inherent meaning, while the discrimination objective can be solved by unintuitive systems. Our findings provide insight into known empirical results in EC, such as the ability of agents in the discrimination game to perform well on unseen random noise. The theoretical tools that we have proposed can be used for future investigation and design of EC environments. As a main takeaway, we conclude that distance-based EC environments have promising potential in the prospect of inducing characteristics of natural language, whereas probability-based objectives must be more carefully designed.

Figure 4: Average message purity, comparing trained models to random baselines.