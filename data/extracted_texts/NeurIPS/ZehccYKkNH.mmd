# Wasserstein convergence of Cech persistence diagrams for samplings of submanifolds

Charles Arnal

Universite Paris-Saclay, Inria

&David Cohen-Steiner

Universite Cote d'Azur, Inria

&Vincent Divol

CREST, ENSAE

Equal contribution

###### Abstract

Cech Persistence diagrams (PDs) are topological descriptors routinely used to capture the geometry of complex datasets. They are commonly compared using the Wasserstein distances \(_{p}\); however, the extent to which PDs are stable with respect to these metrics remains poorly understood. We partially close this gap by focusing on the case where datasets are sampled on an \(m\)-dimensional submanifold of \(^{d}\). Under this manifold hypothesis, we show that convergence with respect to the \(_{p}\) metric happens exactly when \(p>m\). We also provide improvements upon the bottleneck stability theorem in this case and prove new laws of large numbers for the total \(\)-persistence of PDs. Finally, we show how these theoretical findings shed new light on the behavior of the feature maps on the space of PDs that are used in ML-oriented applications of Topological Data Analysis.

## 1 Introduction

Topological Data Analysis (TDA) is a set of tools that aims at extracting relevant topological information from complex datasets, e.g. regarding connected components, loops, cavities, or higher dimensional features. These different notions are made formal through the use of _homology theory_, and in particular the _\(i\)-th homology group_\(H_{i}()\) of a set \(\), which captures the \(i\)-dimensional topological features of \(\) for \(i 0\), see e.g.  or Appendix B. TDA has been successfully applied in a variety of domains, including material science , biology , real algebraic geometry  and neuroscience , to name a few. When used in conjunction with more traditional approaches such as neural networks, TDA-based methods have outperformed state of the arts methods for tasks such as graph classifications .

The most prominent techniques in TDA rely on multiscale approaches, in particular through the use of _persistent homology_. Given a compact set \(\) in \(^{d}\), persistent homology tracks the evolution of the homology groups \(H_{i}(^{t})\) of the \(t\)-offset \(^{t}=_{x}(x,t)\) of \(\) as \(t\) goes from \(0\) to \(+\) (where \((x,t)\) is the closed ball of radius \(t\) centered at \(x\)). The process is summarized by the _Cech persistence diagram (PD) of degree \(i\)_ of the set \(\): the PD \(_{i}()\) is a multiset2 of points in the half-plane \(:=\{(u_{1},u_{2})^{2}:\ u_{1}<u_{2}\}\), where each point \((u_{1},u_{2})\) in the PD corresponds to a \(i\)-dimensional topological feature that appeared in \(^{t}\) at scale \(t=u_{1}\) (its birth time) and disappeared at scale \(t=u_{2}\) (its death time), see Figure 1.3 Points close to thediagonal \(=\{(u_{1},u_{2})^{2}:\ u_{1}=u_{2}\}\) correspond to topological features of small _persistence_\((u)=-u_{1}}{2}\), which have a short lifetime in the filtration \((^{t})_{t 0}\).

A key property of PDs is their robustness to small perturbation in the data, making them suitable for analyzing real-world datasets. This stability property is phrased in terms of the _bottleneck distance_ between PDs . Let \(a\) and \(b\) be two PDs. A _partial matching_ between \(a\) and \(b\) is a bijection of multisets \(:a b\), where each point \((u,u)\) of \(\) has infinite multiplicity. In other words, the points of \(a\) are either paired with a single point of \(b\), or mapped to the diagonal \(\) (and similarly for the points of \(b\)). Let \((a,b)\) be the set of all partial matchings between \(a\) and \(b\). The bottleneck distance is defined as

\[_{}(a,b)=_{(a,b)}_{u }\|u-(u)\|_{}.\] (1)

The Bottleneck Stability Theorem  states that if \(_{1}\) and \(_{2}\) are two compact sets, then for any integer \(i 0\)

\[_{}(_{i}(_{1}),_{i}( _{2})),\] (2)

where \(\) is the Hausdorff distance between the sets \(_{1}\) and \(_{2}\), defined by \(d_{H}(_{1},_{2})=_{x^{d}}|d_{_{ 1}}(x)-d_{_{2}}(x)|\) and where \(d_{}\) is the distance function to a set \(\). An important property of the bottleneck distance is that it is blind to small-persistence topological features: if \(_{}(a,b)=\), then one can arbitrarily modify the PDs \(a\) and \(b\) on a slab of width \(\) above the diagonal (for the \(_{}\)-metric) without changing the bottleneck distance between the two PDs.

Due to this phenomenon, the bottleneck distance turns out to be too weak in many situations of interest, where some topological features of small persistence can be as important as large-scale topological features in the PD (say, with a classification or a regression task in mind). For this reason, finer transport-like distances are often preferred to compare PDs. These distances, which we denote as \(_{p}\), are defined for \(1 p<\) by

\[_{p}(a,b)=_{(a,b)}(_{u a }\|u-(u)\|_{}^{p})^{1/p},\] (3)

with \(_{p}_{p^{}}\) for \(1 p^{} p<\). They can be seen as modified versions of the Wasserstein distances used in optimal transport, with the diagonal \(\) playing the role of a landfill of infinite mass, see e.g. .

The increased sensitivity to small perturbations of the \(_{p}\) distances is of crucial importance in the standard TDA pipeline, which we briefly recall. Starting from a sample of sets \(_{1},,_{n}\), one computes a sample of PDs \(a_{j}=_{i}(_{j})\), \(j=1,,n\). Statistical methods to analyze this sample of PDs are typically awkward to define, due to the nonlinear geometry of the space of PDs . To overcome this issue, the space of PDs is mapped to a vector space through some map \(\) called a feature map. Statistical method are then applied in the feature space on the transformed sample \((a_{1}),,(a_{n})\). Various feature maps have been designed , important examples including persistent images , PersLay , and PLLay ; in the latter two, the feature map is parametrized by a neural network. A good feature map should preserve as much as possible the geometry of the space of PDs ; in particular, Lipschitz (or Holder) continuity of the feature map is a basic requirement. However, due to their (often desirable) sensitivity to small scale

Figure 1: The Čech PD of a point cloud \(\) in \(^{2}\) for \(i=1\) and its \(t\)-offsets. The two points far from the diagonal \(\) in \(_{i}()\) correspond to the two large cycles in the set \(\).

features, most common feature maps are **not** regular with respect to the \(_{}\) distance on the space of diagrams. Instead, they enjoy Lipschitz regularity with respect to either the finer \(_{1}\) distance (see e.g. [33, Proposition 5.2]), or to the \(_{p}\) distances (for \(p>1\)) when restricted to diagrams \(a\) whose \(\)-_total persistence_

\[_{}(a)=_{u a}(u)^{}\] (4)

is bounded for some \(>0\) large enough, see  and . Boundedness assumptions on the \(\)-total persistence also yield a version of the Bottleneck Stability Theorem with respect to the finer \(_{p}\) distance: if \(_{1}\) and \(_{2}\) are such that \(_{}(_{i}(_{k})) M\) (\(k=1,2\)), then, for \(p\),

\[_{p}^{p}(_{i}(_{1}),_{i}(_{2})) M^{p-},\] (5)

where \(=d_{H}(_{1},_{2})\), see . Hence, in addition to having intrinsic theoretical interest, controlling the total persistence and convergence with respect to the \(_{p}\) distance of PDs is crucial to ensure the soundness of most methods commonly used in TDA. This is the subject of this article.

**Contributions.** We provide a deeper understanding of the structure of Cech PDs in the specific case where the underlying set \(\) is a compact subset of am \(m\)-dimensional manifold \(\) in \(^{d}\), focusing in particular on the total persistence of the PDs and their convergence to the PDs of \(\) with respect to the \(_{p}\) distances. The importance of this case is supported by the _manifold hypothesis_, which often serves as a fundamental principle guiding the development of algorithms and models for data analysis . Specifically, our main contributions are the following:

* **Theorem 2.2:** When \(\) is a compact set satisfying \(d_{H}(,)\) for \(\) small enough, we provide a quadratic improvement upon the standard Bottleneck Stability Theorem (2). Namely, we show that there exists an optimal bottleneck matching \(\) such that the distance between a coordinate of a point \(u_{i}()\) and the coordinate of the matched point \((u)_{i}()\) is of order \(O(^{2})\) whenever the coordinate of \(u\) is larger than \(2\).
* **Theorem 3.3:** In the case where the manifold \(\) is generic and the set \(\) is a \(\)-sparse point cloud (i.e. \(_{x y}\|x-y\|\)), we provide a finer analysis by showing that the \(p\)-total persistence \(_{p}(_{i}())\) remains bounded and the distance \(_{p}(_{i}(),_{i}())\) converges to \(0\) for all \(p>m\) whenever the ratio \(/\) is upper bounded.
* **Corollary 4.3:** We then focus on a random context, by assuming that \(=_{n}\) is obtained by sampling \(n\) i.i.d. random variables with positive bounded density \(f\) on a generic manifold \(\). We prove that \(_{p}(_{i}(_{n}),_{i}())\) converges in expectation to \(0\) for \(p>m\). Furthermore, we obtain a law of large numbers for the \(\)-total persistence of \(_{i}(_{n})\): \[_{}(_{i}(_{n}))=_{ }(_{i}())+C_{i}n^{1-/m}+o_{L^{1}}(n^{1- /m})+O_{L^{1}}()^{}\] (6) for all \(>0\), where \(C_{i}\) is a constant that depends explicitly on \(\) and \(f\). In particular, for \(0 i<m\), \(_{}(_{i}(_{n}))\) stays bounded if and only if \( m\).

Our contributions are to be compared to one of the only preexisting results regarding the \(\)-total persistence of a PD: in , the authors proved that for all \(\) strictly greater than the ambient dimension \(d\), the \(\)-total persistence of the Cech PD of a compact set \( B(0,R)^{d}\) satisfies

\[_{}(_{i}()) C_{,d}R^{}\] (7)

for some constant \(C_{,d}\) depending on \(\) and \(d\). In the two scenarios we considered (either \(\)-sparse or random samples), the ambient dimension \(d\) in the constraint \(>d\) for the control of the \(\)-total persistence in (7) has been replaced by the smaller intrinsic dimension \(m\) of the problem: the manifold hypothesis has been successfully exploited.

To summarize, our work sheds light on the behaviour of PDs, provides new guarantees for commonly used ML methods (see e.g. Corollary 4.4), and suggests new heuristics (see Section 5). We also perform various experiments to illustrate the validity of our results and their relevance to the classic TDA pipeline. All proofs are deferred to the Appendix.

**Related work.** This work is part of a long ongoing effort to understand simplicial complexes and PDs in a random context . Closest to our work, Hiraoka, Shiraiand Trinh gave limit laws for Cech PDs for random points in the cube \(^{d}\), while Goel, Trinh and Tsunoda gave similar asymptotics in the case of samples on manifolds . Limit laws for the total persistence have been obtained by Divol and Polonik in the case of random samples in the cube . Among other contributions, this work generalizes this result to submanifolds: unlike the cube, a manifold has a nontrivial topology; a fact which considerably complicates the situation, for we have to take into account the presence of large topological features in the Cech PDs in order to control the total persistence. Note also that tools other than persistent homology exist for studying the geometry of point clouds. For instance, the authors in [77; 52] consider complete isometric invariants for point clouds that are computable in polynomial time.

## 2 Cech persistence diagrams for subsets of submanifolds

Recall that a fundamental result in TDA, the Bottleneck Stability Theorem (2), states that Cech PDs are stable with respect to Hausdorff perturbations. Consider the particular setting where one has access to a set \(\), obtained as an approximation of an unknown shape of interest \(\) through some sampling procedure, with \(\) and \(_{x}d_{}(x)\). The Bottleneck Stability Theorem ensures that \(_{}(_{i}(),_{i}())\) for any \(i 0\), a bound which cannot be improved in general. However, it turns out that a finer understanding of the proximity between \(_{i}()\) and \(_{i}()\) can be obtained if more regularity is assumed on the shape of interest \(\), namely in the situation where \(=\) is a compact submanifold with positive reach.

Let us first set some notation. Let \(\) be an \(m\)-dimensional compact topological submanifold of \(^{d}\); we always assume that the boundary of \(\) is empty. The orthogonal projection \(_{}\) on \(\) is defined for \(x\) close enough to \(\), and we define the _reach_\(()\) as the largest \(r>0\) such that the orthogonal projection \(_{}\) is well (i.e. uniquely) defined for all \(x^{d}\) at distance strictly less than \(r\) from \(\). The reach is a key notion to quantify the regularity of a manifold, see e.g.  and  for more information.

Let \(\) be such that \(d_{H}(,)\) and let \(z^{d}\). By definition of the Hausdorff distance, it holds that \(|d_{}(z)-d_{}(z)|\). However, this naive bound can be quadratically improved as long as \(z\) stays far away from \(\).

**Lemma 2.1**.: _Let \(^{d}\) be a compact submanifold with positive reach and let \(\) be a compact set with \(d_{H}(,)\) for some \(>0\). Let \(z^{d}\). Then, \(|d_{}(z)-d_{}(z)|}{2d_{}(z)}(1+}(z)}{()})\)._

We can build upon this basic remark to obtain a very precise control of the behavior of the Cech PD of the set \(\). Namely, we identify three regions in the upper halfplane \(\) (displayed in Figure 2) which contain all points in the PD \(_{i}()\) (for some integer \(i 0\)). In the first region, corresponding to microscopic topological features disappearing at scales smaller than \(+^{2}/()\), the Bottleneck Stability Theorem cannot be improved. However, there exists an optimal matching (i.e. a matching \(:_{i}()_{i}( )\) that realizes the bottleneck distance (1)) such that at least one of the coordinates of any point in the other two regions is larger than \(()-^{2}/()\), and the proximity between a large coordinate of a point \(u_{i}()\) and the coordinate of the matched point \((u)_{i}()\) is of order \(O(^{2})\). This yields a quadratic improvement upon the Bottleneck Stability Theorem.

**Theorem 2.2** (Improved Bottleneck Stability Theorem).: _Let \(^{d}\) be a compact submanifold with positive reach and let \(\) be a compact set such that \(d_{H}(,)<()/4\). Let \(i 0\) be an integer. Then \(_{i}()\) is the union of three regions \(_{i}^{(1)}():=_{i}()\{u_{1}, u_{2}+}{()}\}\), \(_{i}^{(2)}():=_{i}()\{u_{1} ,u_{2}()-}{()}\}\) and \(_{i}^{(3)}():=_{i}()\{u_{1}, u_{2}()-}{()}\}\)._

Figure 2: PDs of \(\) (red) and of \(\) (black).

_Furthermore, let \(C=)}(1+)}{()})\), where \(R()\) is the radius of the smallest ball that contains \(\). There exists an optimal matching \(:_{i}()_{i}()\) for the bottleneck distance between \(_{i}()\) and \(_{i}()\) such that_

* _Region (1): If_ \(u_{i}^{(1)}()\)_, then_ \((u)\) _and_ \(\|u-(u)\|_{}\)_._
* _Region (2): If_ \(u_{i}^{(2)}()\)_, then_ \((u)\) _is of the form_ \((0,v_{2})\) _and_ \(|u_{2}-v_{2}| C^{2}\)_. The number of such points is finite and depends only on_ \(\)_._
* _Region (3): If_ \(u_{i}^{(3)}()\)_, then_ \(\|u-(u)\|_{} C^{2}\)_._

Note that for any \(i d\), the \(i\)-th PDs of \(\) and \(\) are actually trivial.

## 3 Cech persistence diagrams for subsets of generic submanifolds

The improved Bottleneck Stability Theorem (Theorem 2.2) yields information relative to the location of points in the Cech PD of \(\), but not about their numbers. However, both the \(\)-total persistence of \(_{i}()\) and the distance \(_{p}(_{i}(),_{i}())\) for \(p<\) crucially depend on the number of points in \(_{i}()\) having small persistence.

Unfortunately, no control on, say, the total persistence, can exist without additional assumptions. Indeed, in general, even the \(\)-total persistence of the Cech PD of the submanifold \(\) can be infinite.

**Example 3.1**.: _Let \(f:x 1+x^{4}(1/x)^{2}\). Consider the \(C^{2}\) curve \(\) in \(^{2}\) defined as the union of the graphs of the functions \(f\) and \(-f\) on \([-2,2]\). Being \(C^{2}\), the curve has a positive reach . For \(i=1\), the Cech PD of \(\) contains a sequence of points \((1,_{n})\) for \(n 1\), where \(_{n}=1+(n^{-4})\). In particular, as \(_{n 1}(_{n}-1)^{}=+\) for \(<1/4\), the \(\)-total persistence of \(_{1}()\) is infinite for such a value of \(\). By considering the product \(^{m}^{2m}\), one can also build an \(m\)-dimensional \(C^{2}\) compact submanifold without boundary such that \(_{1}()\) has an infinite \(\)-total persistence for \(<m/4\)._

The existence of such counterexamples is explained by the fact that the distance function \(d_{}\) to a set \(\) is not well-behaved in general, even when the set \(\) is smooth. In contrast to this bleak general case, Song, Yim & Monod (in the case of surfaces in \(^{3}\)) and Arnal, Cohen-Steiner & Divol (in the general case) studied the distance function \(d_{}\) to \(\) when \(\) is a _generic_ submanifold . Their findings indicate that, although counterexamples such as the one presented in Example 3.1 exist, they are extremely uncommon in a sense which can be made precise.

Namely, given an _abstract_ manifold \(M\), Arnal, Cohen-Steiner and Divol show that the set of \(C^{2}\) embeddings \(\) of \(M\) into \(^{d}\) such that \(d_{}\) satisfies some desirable regularity conditions (described in Appendix C) forms an open and dense set in the set of all \(C^{2}\) embeddings equipped with the \(C^{2}\)-Whitney topology [6, Theorem 1.1]. In what follows, we will simply refer to a \(C^{2}\) compact submanifold \(\) such that \(d_{}\) satisfies the regularity condition described in Appendix C as _generic_. See Figure 3 for an example.

**Proposition 3.2** (Cech PDs of generic submanifolds).: _Let \(\) be a generic submanifold of \(^{d}\). Then, for any integer \(i 0\), the PD \(_{i}()\) contains finitely many points. In particular, \(_{}(_{i}())<+\) for all \(>0\)._

When \(\) is a generic submanifold, it becomes a reasonable task to control the number of points in \(_{i}()\) where \(\) is an approximation of \(\) with \(d_{H}(,)\). The Bottleneck Stability Theorem implies that when \(\) is small enough (compared to the smallest persistence of a point in \(_{i}()\)), every point of \(_{i}()\) is mapped to a point in \(_{i}()\) by the optimal bottleneck matching, leaving the points of \(_{i}()\) at \(_{}\)-distance to \(\) less than \(\) unmatched; those will be mapped to the diagonal \(\). The Improved Bottleneck Stability Theorem 2.2 (see Figure 2) shows that these points are of two kinds: those in Region (1), corresponding to small topological features in the set \(\) (of size of order \(O()\)), and those in Region (3), corresponding to large topological features. There are many points in Region (1) (in fact, our proofs show that when \(=_{n}\) is a random

Figure 3: A generic torus.

sample of \(n\) points, the number of points in Region (1) is of order \(O(n)\)). In contrast, the genericity hypothesis allows us to show that the number of points in Region (3) is small under reasonable sampling assumptions.

We say that a point cloud \(\) is _\((,)\)-dense_ in \(\) if \(d_{H}(,)\) and \(_{x y}\|x-y\|\). Such point clouds naturally occur, e.g. as products of the farthest point sampling algorithm .

**Theorem 3.3**.: _Let \(^{d}\) be a generic compact submanifold and \(\) be a \((,)\)-dense set in \(\) for some \(,>0\). Let \(a/\) and let \(i 0\) be an integer. There exist \(_{0}>0\) depending only on \(\) and \(C_{0},C_{1},C_{2},C_{3}\) depending only on \(\) and \(a\) such that if \(_{0}\), then \(_{i}^{(3)}()\) has at most \(C_{0}\) points and for all \(p 1\), \( 0\),_

\[_{p}^{p}(_{i}(),_{i} ()) C_{1}^{p-m}\] (8) \[_{}(_{i}()) C_{2}(C_ {3}^{}+^{-m}).\]

In particular, as long as the ratio \(/\) is larger than some constant \(a>0\), the \(_{p}\) distance between \(_{i}()\) and \(_{i}()\) converges to \(0\) for all \(p>m\) as \( 0\), while the \(p\)-total persistence \(_{p}(_{i}())\) stays bounded.

**Example 3.4**.: _Consider two parallel line segments \(\) in \(^{2}\), and a finite set \(\) consisting of two parallel grids of step \(2\): the set \(\) is \((2,)\)-dense in \(\). Then, there are \(O(^{-1})\) points in \(_{1}()\) with birth coordinates \(u_{1}\) equal to \(1/2\) and persistence of order \(O(^{2})\); they all belong to \(_{1}^{(3)}()\), whose cardinality is thus not bounded by some \(C_{0}=C_{0}()\). This example can be easily modified to make \(\) a compact \(C^{2}\)\(1\)-dimensional manifold. This shows that the first conclusion of Theorem 3.3 cannot hold without a genericity assumption on \(\)._

## 4 Random samplings of submanifolds

We now turn to the case of random samplings of (non-generic and generic) submanifolds. They tend to adopt configurations that are more regular than what can be expected from e.g. a general \(\)-dense sampling, yet their randomness gives rise to new technical difficulties. Let \(P\) be a probability measure having a density \(f\) (with respect to the volume measure) on a compact submanifold \(\) of dimension \(m 1\). Let \(=_{n}=\{X_{1},,X_{n}\}\), where \(X_{1},,X_{n}\) is an i.i.d. sample from distribution \(P\). Let \(i 0\) be an integer; we consider the three regions described in Figure 2 and in the statement of Theorem 2.2, and write again \(_{i}^{(1)}(_{n})\), \(_{i}^{(2)}(_{n})\) and \(_{i}^{(3)}(_{n})\) for the three corresponding PDs. This section is devoted to the study of the probabilistic asymptotic behaviour of these three random PDs, which can be decomposed into two almost independent questions: \(_{i}^{(1)}(_{n})\) only depends on small-scale phenomena and can essentially be reduced to the case of a cube, even if \(\) is non-generic, while \(_{i}^{(2)}(_{n})\) and \(_{i}^{(3)}(_{n})\) are tightly connected to the macroscopic geometry of the submanifold and can be further controlled using genericity assumptions on \(\).

Describing the limit behavior of the random \(\,_{i}^{(1)}(_{n})\) requires extending the metric \(_{p}\) between PDs to more general Radon measures. Indeed, a PD can equivalently be seen as an integer-valued discrete Radon measure on \(\), by identifying a multiset \(a\) with the Radon measure \(_{u a}_{u}\). Let \(\) denote the space of Radon measures on \(\), that is the space of Borel measures on \(\) which give finite mass to every compact set \(K\).4 The space of Radon measures is endowed with the _vague topology_, where a sequence \((_{n})_{n}\) of measures in \(\) is said to converge vaguely to \(\) if \(_{}_{n}_{}\) as \(n\) for all continuous functions \(:\) with compact support.

The \(\)-total persistence is defined for \(\) by \(_{}()=_{}(u)^{}(u)\). For \(p 1\), we let \(^{p}=\{:\,_{p}()<+\}\). The distance \(_{p}\), defined between PDs in (3), can be extended to the set \(^{p}\), see . The distance \(_{p}\) between Radon measures is a variation of the Wasserstein distance, with the important difference that the standard Wasserstein distance is only defined for measures having the same mass, while the distance \(_{p}\) is defined for measures having different (and even infinite) masses. We refer to Appendix F for the precise definition and the main properties of the \(_{p}\) distance on the space \(_{p}\).

For \(q>0\), given a function \(f:\) and a sequence of (nonnecessarily measurable) real maps \((Y_{n})_{n}\) defined on some probabilisitic space, the notation \(Y_{n}=O_{L^{q}}(f(n))\) means that \(^{*}[|Y_{n}|^{q}]=O(f(n)^{q})\), where \(^{*}\) denotes the outer expectation [73, p.6] (and similarly for the little \(o\) notation).

### Region (1)

Consider the rescaled Radon measure \(_{n,i}=_{u_{i}^{(1)}(_{n})} _{n^{1/m}u}\), and note that \(_{n,i}\) is a random measure, owing to the randomness of the set \(_{n}\). Goel, Trinh and Tsunoda studied the vague convergence of the sequence \((_{n,i})_{n}\)[42, Remark 4.2]. Namely, assuming that the density \(f\) satisfies \(_{}f^{j}<\) for all \(j 0\), they show that with probability \(1\) the sequence \((_{n,i})_{n}\) converges vaguely to some (non-random) Radon measure \(_{f,i}\). The limit measure \(_{f,i}\) has support \(\{0\}_{+}\) if \(i=0\) and \(\) if \(0<i<m\); it is the zero measure if \(i m\). We can further describe it as follows: let \(_{,i,m}\) be the limit of the sequence \((_{n,i})\) in the case where the sample \(_{n}\) is uniform on the unit cube \(^{m}\) (see ). Then, for any continuous function \(:\) with compact support,

\[_{}(u)_{f,i}(u)=_{}_{}f(x) (f(x)^{-1/m}u)x_{,i,m}(u).\] (9)

Note that the vague convergence of Radon measures is only defined with respect to compactly supported functions; as such, it is blind to phenomena located increasingly close to the diagonal \(\) as \(n\) goes to infinity. In particular, and except in the case of the uniform distribution on the unit cube \(^{m}\) (see ), it was not known whether \(_{n,i}\) converges to \(_{f,i}\) for the \(_{p}\) distance as well, nor whether the sequences of total persistence \((_{}(_{n,i}))\) converge. We close this gap with the following result.

**Theorem 4.1** (Law of large numbers).: _Assume that \(P\) has a density \(f\) on \(\) bounded away from \(0\) and \(\). Let \(i 0\) be an integer and let \(1 p<\). Then \(_{f,i}_{p}\) and \(}[_{p}^{p}(_{n,i},_{f,i})][ n]{}0\). Furthermore, for all \(>0\), \(_{}(_{i}^{(1)}(_{n}))n^{ -1}=_{}(_{n,i})=_{}(_{f,i})+o_{L^{1}}(1)\)._

### Regions (2)-(3)

It is a well-known fact that the Hausdorff distance \(=d_{H}(_{n},)\) between a random sample and \(\) is of order \(( n/n)^{1/m}\) whenever the underlying density \(f\) is bounded away from zero and \(\) on \(\), see e.g. . Hence the PDs \(_{i}^{(2)}(_{n})\) and \(_{i}^{(3)}(_{n})\) can be described using Theorem 2.2. However, in the case where \(\) is a generic submanifold, one can actually obtain tighter results. We let \(\#E\) denote the cardinality of a multiset \(E\).

**Proposition 4.2**.: _Let \(\) be a generic \(m\)-dimensional submanifold. Assume that \(P\) has a density \(f\) on \(\) bounded away from \(0\) and \(\). Let \(i 0\) be an integer. There exists an optimal matching \(_{n}:_{i}(_{n}) _{i}()\) for the bottleneck distance between \(_{i}(_{n})\) and \(_{i}()\) such that for any \(q 1\):_

* _Region (2): It holds that_ \(_{u_{i}^{(2)}(_{n})}|u_{2}-_{n}(u)_{ 2}|=O_{L^{q}}(n^{-2/m})\)_._
* _Region (3): It holds that_ \(_{u_{i}^{(3)}(_{n})}\|u\,-\,_{n}(u)\|_ {}=O_{L^{q}}(n^{-2/m})\) _and_ \(\#(_{i}^{(3)}(_{n}))=O_{L^{q}}(1)\)_._

We remark that the same bounds can be obtained almost surely (e.g. "a.s. there exists \(C>0\) such that \(_{u_{i}^{(3)}(_{n})}\|u-_{n}(u)\|_{ } Cn^{-2/m}\)"), rather than in expectation, using similar arguments.

Proposition 4.2 yields two distinct improvements upon direct applications of Theorem 2.2 and Theorem 3.3 to the random case. First, we obtain bounds of order \(n^{-2/m}\) instead of bounds of order \(( n/n)^{2/m}\). Second, the random sample \(_{n}\) is in general only \(\)-sparse for \(\) of order \(n^{-2/m}\). Hence, \(_{n}\) is \((,)\)-dense in \(\), but with a diverging ratio \(/\). Therefore, Theorem 3.3 cannot be applied to control the total number of points in \(_{i}(_{n})\) in Region (3).

### Consequences for the Wasserstein convergence of persistence diagrams

As a simple consequence of Theorem 4.1 and Proposition 4.2, we obtain that for \(i<m\), the \(p\)-Wasserstein convergence of \((_{i}(_{n}))\) to \(_{i}()\) holds if and only if \(p>m\), as well as precise asymptotics for the total persistence of \((_{i}(_{n}))\).

**Corollary 4.3**.: _Let \(p 1\) and let \(0 i<d\) be an integer. Under the same assumptions as in Proposition 4.2, the following holds:_

* _If_ \(p>m\)_, then_ \([_{p}^{p}(_{i}(_{n}),_{i }())] 0\) _as_ \(n\)_._
* _If_ \(p=m\)_,_ \([_{p}^{p}(_{i}(_{n}),_{ i}())]_{p}(_{,i,m})()\) _as_ \(n\)_, where_ \(()\) _is the volume of_ \(\)_._
* _If_ \(p<m\) _and_ \(i<m\)_, then_ \([_{p}^{p}(_{i}(_{n}),_{ i}())]+\) _as_ \(n\)_._

_Furthermore, for all \(>0\), \(_{}(_{i}(_{n}))\) is equal to_

\[_{}(_{i}())+n^{1-} _{}(_{,i,m})_{}f(x)^{1-}x+o_{L^{1}}(n^{1-})+O_{L^{1}}( )^{}.\]

As noted earlier, both \(_{i}(_{n})\) and \(_{i}()\) are trivial if \(i d\).

This corollary gives a precise answer to the questions raised in the introduction. First, when \(_{n}\) is a random subset of a \(m\)-dimensional generic manifold in \(^{d}\), the \(\)-total persistence of \(_{i}(_{n})\) is not only bounded for \(>d\) (as was shown by Cohen-Steiner & al. ), but for all \( m\). Moreover, the sequence \(_{i}(_{n})\) converges for the \(_{p}\) distance if \(p>m\). A curious phenomenon can be observed in the case \(p=m\): the sequence does not converge to \(_{i}()\) as one would expect, but its distance to the power \(p\) to \(_{i}()\) converges to some constant-in that case, the cost to the power \(p\) of matching all the points in Region (1) to the diagonal \(\) neither converges to \(0\) nor diverges, but is asymptotically equal to this constant.

Using these bounds on the total persistence, we obtain regularity guarantees for a large family of feature maps, called _linear feature maps_, which includes feature maps introduced in . Let \((V,\|\|)\) be a normed vector space, and let \(: V\) be a continuous bounded map. For \( 0\), the linear feature map \(_{}\) associated to \(\) and defined on the space \(_{f}\) of PDs having a finite number of points is defined for all \(a_{f}\) by \(_{}(a)=_{u a}(u)^{}(u) V\).

**Corollary 4.4**.: _Let \( 1\) and let \(0 i<d\) be an integer. Under the same assumptions as in Proposition 4.2, it holds that \(_{}(_{i}(_{n}))\) converges in probability to \(_{}(_{i}())\) whenever \(>m\)._

Remark that other weighting schemes are possible. For instance,  argued for using linear feature maps of the form \(_{}(a)=_{u a}((u)^{})(u)\). Similar results would hold for such feature maps, as the map \(u((u)^{})(u)/(u)^{}\) is continuous and bounded whenever \(\) is.

## 5 Numerical experiments

We illustrate our results with synthetic experiments, full details are given in Appendix H. We create a generic submanifold of dimension \(m\) by applying a random diffeomorphism \(\) to a given \(m\)-dimensional submanifold \(_{0}\) (e.g. a torus). We then draw a sample of \(n\) i.i.d. observations sampled according to the pushforward \(P\) of the uniform distribution on \(\) by \(\).

Figure 4: Left: the Čech PD \(_{1}(_{n})\) of a sample of \(n=10^{4}\) points sampled on a generic torus, with points in Regions (1), (2) and (3) highlighted in different colors. Right: the persistence images of \(_{1}(_{n})\) with weight \(^{p}\) for different values of \(p\).

**Continuity of feature maps.** As a first experiment, we test the continuity of a feature map, the persistence image . In Figure 4, we plot the persistence image of \(_{1}(_{n})\) where \(_{n}\) is a sample of \(n=10^{4}\) points on a generic torus. We observe that the map is discontinuous for \(p<2\): the two points with large persistence corresponding to the PD of the underlying torus are nonapparent in the image. For \(p>2\), the two points are apparent, and the contribution of points with small persistence (close to the lower edge) has vanished. In the limit situation \(p=2\), we see the contribution of both points with large and small persistence. This phenomenon suggests the following heuristics: **when in presence of multiple datasets on \(m\)-dimensional objects whose global geometries need to be distinguished, feature maps with weights \(^{p}\) with \(p>m\) should be used; when the relevant information is the underlying density of the datasets, the choice \(p<m\) should be preferred.**

**Convergence of total persistences.** We verify the rate of convergence of the total persistence predicted by Theorem 4.1. For values of \(n\) ranging from \(10^{2}\) to \(10^{4}\), we compute \(_{p}(_{i}^{(1)}(_{n}))\) in three scenarios: points sampled on a circle for \(i=0\), and points sampled on a torus for \(i=0\) and \(i=1\). The correct rates of convergence are observed on a log-log plot, see Figure 5. For \(i=1\), we remark that the asymptotic regime starts at larger values of \(n\), above \(n=10^{3}\).

**Convergence of \(_{n,i}\).** We sample \(n\) points on a torus by uniformly sampling the two angles \((,)\) parametrizing the torus. We obtain a (nonnuniform) probability measure, having density \(f\). We then compute, for various values of \(n\), the measure \(_{n,1}\). The measure is approximated by kernel density estimation (see Figure 6). We approximate in a similar manner the measure \(_{,1,2}\) by sampling \(n=10^{5}\) points on a square. We then apply the change of variable formula (9) to compute the theoretical limit \(_{f,1}\). The distance \(_{2}(_{n,1},_{f,1})\) is then computed by approximating the measures on a grid: the distance converges to \(0\) as predicted by Theorem 4.1. See also Figure 6.

Figure 5: Plot in log-log scale of \(_{p}(_{i}^{(1)}(_{n}))\) as a function of \(n\) for points sampled on a circle, \(i=0\) (left), points sampled on a torus, \(i=0\) (center), points sampled on a torus, \(i=1\) (right). Dashed lines have slopes equal to \(1-p/m\).

Conclusion

Under the manifold hypothesis, we have greatly refined earlier work regarding the persistent homology of subsamples of compact sets, with especially strong results when the sampling is either random or well-behaved. In particular, we have precisely described the PDs of such samplings, and provided new convergence guarantees w.r.t. the \(p\)-Wasserstein distances, as well as detailed asymptotics for their total \(\)-persistence. This results in a deeper understanding of these objects, which play an important role in ML techniques applied to TDA. The main limitations of our work were the assumptions that the data is sampled from a submanifold, and without any noise. Relaxing those assumptions, as well as establishing similar guarantees for Vietoris-Rips complexes, could be the subject of future research. We also plan on exploring the consequences of our findings regarding the persistent homology dimension  of submanifolds.