# Temporal Graph Benchmark

for Machine Learning on Temporal Graphs

Shenyang Huang1,2,* Farimah Poursafaei1,2,* Jacob Danovitch1,2 Matthias Fey3

Weihua Hu3 Emanuele Rossi4 Jure Leskovec7 Michael Bronstein8

Guillaume Rabusseau1,5,6 Reihaneh Rabbany1,2,6

###### Abstract

We present the _Temporal Graph Benchmark (TGB)_, a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation of machine learning models on temporal graphs. TGB datasets are of large scale, spanning years in duration, incorporate both node and edge-level prediction tasks and cover a diverse set of domains including social, trade, transaction, and transportation networks. For both tasks, we design evaluation protocols based on realistic use-cases. We extensively benchmark each dataset and find that the performance of common models can vary drastically across datasets. In addition, on dynamic node property prediction tasks, we show that simple methods often achieve superior performance compared to existing temporal graph models. We believe that these findings open up opportunities for future research on temporal graphs. Finally, TGB provides an automated machine learning pipeline for reproducible and accessible temporal graph research, including data loading, experiment setup and performance evaluation. TGB will be maintained and updated on a regular basis and welcomes community feedback. TGB datasets, data loaders, example codes, evaluation setup, and leaderboards are publicly available at https://tgb.complexdatalab.com/.

## 1 Introduction

Many real-world systems such as social networks, transaction networks, and molecular structures can be effectively modeled as graphs, where nodes correspond to entities and edges are relations between entities. Recently, significant advances have been made for machine learning on static graphs, led by the use of _Graph Neural Networks (GNNs)_ and _Graph Transformers_, and accelerated by the availability of public datasets and standardized evaluations protocols, such as the widely adopted _Open Graph Benchmark (OGB)_.

However, most available graph datasets are designed only for _static_ graphs and lack the fine-grained timestamp information often seen in many real-world networks that evolve over time. Examples include social networks , transportation networks , transaction networks  and trade networks . Such networks are formalized as _Temporal Graphs (TGs)_ where the nodes, edges, and their features change _dynamically_.

A variety of machine learning approaches tailored for learning on TGs have been proposed in recent years, often demonstrating promising performance . However, Poursafaei _et al._ recently revealed an important issue: these TG methods often portray an over-optimistic performance-- meaning they appear to perform better than they would in real-world applications -- due to the inherent limitations of commonly used evaluation protocols.

This over-optimism creates serious challenges for researchers. It becomes increasingly difficult to distinguish between the strengths and weaknesses of various methods when their test results suggest similarly high performance. Furthermore, there is a discrepancy between real-world applications of TG methods and the existing evaluation protocols used to assess them. Therefore, there is a pressing need for an open and standardized benchmark that enhance the evaluation process for temporal graph learning, while being aligned with real-world applications.

In this work, we present the _Temporal Graph Benchmark (TGB)_, a collection of challenging and diverse benchmark datasets for realistic, reproducible, and robust evaluation for machine learning on temporal graphs. Figure 2 shows TGB's ML pipeline. Inspired by the success of OGB, TGB automates the process of dataset downloading and processing as well as evaluation protocols, and allows the user to easily compare their model performance with other models on the public leaderboard. TGB improves the evaluation of temporal graph learning in both _dataset selection_ and _evaluation protocol_ and covers both edge and node-level tasks.

**Dataset Selection.** Contrary to real-world networks that typically contain millions of nodes and tens of millions of edges, existing TG benchmark datasets are notably smaller, falling short by several orders of magnitude [33; 40]. Furthermore, these datasets often have limitations in terms of their domain diversity, with a substantial focus on social and interaction networks [35; 24; 25]. This lack of diversity can be problematic as network properties, such as network motifs , the scale-free property , and the modular structure  vary significantly across different domains. Consequently, it is important to benchmark existing methods across a wide variety of domains for a comprehensive evaluation.

To address these limitations, TGB datasets provide diversity in terms of the number of nodes, edges, timestamps, and network domains. As shown in Figure 1, TGB datasets are larger in scale and present statistics that were under-explored in prior literature. For instance, the tgbn-token dataset has around 73 million edges while the tgbl-comment dataset has more than 30 million timestamps. Additionally, TGB introduces four datasets in the novel _node affinity prediction_ task to address the scarcity of large scale datasets for node-level tasks in the current literature.

**Improved Evaluation.** In TGB, we aim to design the evaluation for both edge and node-level tasks on temporal graphs based on real applications. Historically, the standard approach for dynamic link prediction evaluation is to treat it as a binary classification task using one negative edge per positive edge in the test set [9; 40; 25; 33]. This strategy tends to generate negatives that are easy to predict, given the structure and sparsity of real-world networks , leading to inflated model performance estimations . To address this issue, we propose to treat this task as a ranking problem, contrasting each positive sample against multiple negatives and using Mean Reciprocal Rank (MRR) as the metric. Moreover, _historical negatives_ - past edges absent in the current step - are generally more difficult to predict correctly than randomly sampled negatives . Thus, we sample both historical and random negatives in link prediction evaluations.

There is a lack of large-scale datasets for node-level tasks in temporal graphs as acquiring dynamic node labels remains challenging due to privacy concerns. We plan to include additional datasets for node classification in the future. As a starting point, we present the novel _node affinity prediction_ task, which finds its motivation in recommendation systems. The objective is to anticipate the shifts in user preferences for items over time, as expanded in Section 3.2. In this task, node property is considered as the affinity towards different items at a given time. To assess the effectiveness of methods in addressing this task, we adopt the Normalized Discounted Cumulative Gain (NDCG) metric. This

Figure 1: TGB consists of a diverse set of datasets that are one order of magnitude larger than existing datasets in terms of number of nodes, edges, and timestamps.

metric serves to determine whether the methods' predictions for class importance adhere to the same ordering as the ground truth. In Section 5.2, we show that simple heuristics can outperform state-of-the-art TG methods in achieving superior performance for this task.

Overall, our proposed Temporal Graph Benchmark has the following contributions:

* **Large and diverse datasets.** TGB includes datasets coming from a diverse range of domains and spanning both edge and node-level tasks. We contributed seven novel datasets which are orders of magnitude larger than existing ones in terms of number of edges, nodes and timestamps.
* **Improved evaluation.** We propose an improved and standardized evaluation pipeline motivated by real-world applications. For dynamic link property prediction, we sample multiple negative instances per positive edge and ensure a mix of both historical and random negative samples, while using the _MRR_ metric. For the node affinity prediction task, we use the _NDCG_ metric to evaluate the relative importance of classes within the top ranking ones.
* **Empirical findings.** We show that for the dynamic link property prediction task, model performances can vary drastically across datasets. For example, the best performing model on tgbl-wiki encounters a 40% test MRR drop on tgbl-review and the _surprise index_ of a dataset affects model performance. On the node affinity prediction task, we find that simple heuristics can often outperform state-of-the-art TG methods, thus leaving ample room for development of future methods targeting this task.
* **Public leaderboard and reproducible results.** Following the good practice of OGB, TGB also provides an automated and reproducible pipeline for both link and node property prediction tasks. Researchers can submit and compare method performance on the TGB leaderboard.

**Reproducibility:** TGB code, datasets, leaderboards and details are on the TGB website. The code is also publicly available on GitHub with documentations seen here.

## 2 Related Work

**Temporal Graph Datasets and Libraries.** Recently, Poursafaei _et al._ collected six novel datasets for link prediction on continuous-time dynamic graphs while proposing more difficult negative samplings for evaluation. In comparison, we curated seven novel temporal graph datasets spanning both edge and node-level tasks for realistic evaluation of machine learning on temporal graphs. Yu _et al._ presented DyGLib, a platform for reproducible training and evaluation of existing TG models on common benchmark datasets. DyGLib demonstrates the discrepancy of the model performance across different datasets and argues that diverse evaluation protocols of previous works caused an inconsistency in performance reports. Similarly, Skarding _et al._ provided a comprehensive comparative analysis of heuristics, static GNNs, discrete dynamic GNN, and continuous dynamic GNN on dynamic link prediction task. They showed that dynamic models outperforms their static counterparts consistently and heuristic approaches can achieve strong performance. In all of the above benchmarks, the included datasets only contain a few million edges. In comparison, TGB datasets are orders of magnitude larger in scale in terms of number of nodes, edges and timestamps. TGB also includes both node and edge-level tasks. Huang _et al._ collected a novel dynamic

Figure 2: **Overview of the Temporal Graph Benchmark (TGB) pipeline:****(a)** TGB includes large-scale and realistic datasets from five different domains with both dynamic link prediction and node property prediction tasks. **(b)** TGB automatically downloads datasets and processes them into numpy, PyTorch and PyG compatible TemporalData formats. **(c)** Novel TG models can be easily evaluated on TGB datasets via reproducible and realistic evaluation protocols. **(d)** TGB provides public and online leaderboards to track recent developments in temporal graph learning domain. The code is publicly available as a Python library.

graph dataset for anomalous node detection in financial networks and compared the performance of different graph anomaly detection methods. In this work, TGB datasets have more edges and timestamps while covering both edge and node tasks.

**Temporal Graph Methods.** With the growing interest in temporal graph learning, several recent models achieved outstanding performance on existing benchmark datasets. However, due to the limitations of the current evaluation, many methods achieve over-optimistic and similar performance for the dynamic link prediction task [46; 35; 9; 40; 25; 24]. In this work, TGB datasets and evaluation show a clear distinction between SOTA model performance, which helps facilitate future advancement of TG learning methods. Temporal graphs are categorized into discrete-time and continuous-time temporal graphs . In this work, we focus on the continuous-time temporal graphs as it is more general. Continuous-time TG methods can be divided into node or edge representation learning methods. Node-based models such as _TGN_, _DyRep_ and _TCL_ first leverage the node information such as temporal neighborhood or previous node history to generate node embeddings and then aggregate node embeddings from both source and destination node of an edge to predict its existence. In comparison, edge-based methods such as _CAWN_ and _GraphMixer_ aim to directly generate embeddings for the edge of interest and then predict its existence. Lastly, the simple memory-based heuristic _EdgeBank_ without any learning component has shown surprising performance based on existing evaluation. We compare these methods on TGB datasets in Section 5. For more discussion on TG methods see Appendix D.

## 3 Task Evaluation on Temporal Graphs

Temporal graphs are often used to model networks that evolve over time where nodes are entities and temporal edges are relations between entities through time. In this work, we focus on continuous-time temporal graphs and denote them as timestamped edge streams consisting of triplets of source, destination, and timestamp; i.e., \(=\{(s_{0},d_{0},t_{0}),(s_{1},d_{1},t_{1}),,(s_{T},d_{T},t_ {T})\}\) where the timestamps are ordered (\(0 t_{1} t_{2}... t_{T}\)) [33; 21]. Note that temporal graph edges can have different properties namely being weighted, directed, or attributed. We consider \(_{t}\) as the augmented graph of all edges observed in the stream up to the time \(t\) with nodes as \(_{t}\) and edges as \(_{t}\). Optionally, \(_{t}\) can contain node features \(_{t}^{|_{t}| k_{n}}\) where \(k_{n}\) is the size of a node feature vector, and edge features \(_{t}^{|_{t}| k_{m}}\) where \(k_{m}\) is the size of an edge feature vector. We consider a fixed chronological split to form the training, validation, and test set.

**Evaluation Settings.** There are several possible evaluation settings in the temporal graph based on the available information of the test set. We categorize and discuss these settings in detail in Appendix C. In this work, we consider the _streaming setting_ where the deployed models need to adapt to new information at inference time. More specifically, we follow the setting in  where previously observed test edges can be accessed by the model but back-propagation and weight updates with the test information are not permitted.

### Dynamic Link Property Prediction

The goal of _dynamic link property prediction_ is to predict the property (oftentimes the existence) of a link between a node pair at a future timestamp. The timeline is chronologically split at two fixed points resulting in three sets of edges \(E_{}\), \(E_{}\), and \(E_{}\). In TGB, we improve the evaluation setting in the following ways.

**Negative edge sampling.** In current evaluation [24; 48; 35; 45; 40; 51; 6; 53], only one negative edge is sampled uniformly randomly from all possible node pairs to evaluate against each positive edge. In contrast, in real applications where the true edges are not known in advance, the edges with the highest probabilities predicted by a given model are used to decide which connections should be prioritized. With that in mind, we treat the link prediction task as a ranking problem and sample multiple negative edges per each positive edge. In particular, for a given positive edge \(e^{p}:(s,d,t)\), we fix the source node \(s\) and timestamp \(t\), and sample \(q\) different destination nodes. For each dataset, we select the number of negative edges \(q\) based on the trade-off between evaluation completeness and the test set inference time.

We sample the negative edges from both the _historical_ and _random_ negative edges. Historical negatives are sampled from the set of edges that are observed in the training set but are not present at the current timestamp \(t\) (_i.e._\(E_{t} E_{}\)), they are shown to be more difficult for models to predict than random negatives . We sample equally from historical and random negative edges. Note that depending on the dataset and the timestamp \(t\), there might not be enough historical negatives to sample from. In this case, we simply increase the ratio of the random negatives to have the desired number of negative edges per positive ones. For reproducibility, we include a fixed set of negatives sampled for each dataset to ensure consistent comparison amongst models.

**Performance metric.** The commonly used metric for reporting models' performance for the dynamic link prediction task is either Area Under the Receiver Operating Characteristic curve (AUROC) or Average Precision (AP). An appropriate metric should be able to capture the ranking of a positive edge amongst the negative ones, which is not fulfilled by either AUROC or AP. Thus, we devise to use the filtered Mean Reciprocal Rank (MRR) as the evaluation metric for the dynamic link property prediction. The MRR computes the reciprocal rank of the true destination node among the negative or fake destinations. The MRR varies in the range of \((0,1]\) and it is a commonly used metric in recommendation systems  and knowledge graphs [44; 17; 16]. In addition, recent link prediction literature is also shifting towards adopting the MRR metric [5; 16; 50]. It should be noted that when reporting the MRR, we perform collision checks to ensure that no positive edge is sampled as a negative edge.

### Dynamic Node Property Prediction

The goal of _dynamic node property prediction_ is to predict the property of a node at any given timestamp \(t\), i.e., to learn a function \(f:_{t}\), where \(_{t}\) is the set of nodes at time \(t\) and \(\) is some output space (e.g. \(\{-1,+1\}\), \(\), \(^{p}\), etc.). This is a general category for node-level tasks such as node classification and node regression. Here, the property of the node can be a one hot label, a weight vector or an euclidean coordinate. Currently, there is a lack of large-scale temporal graph datasets with node labels in the literature; therefore, we first include the _node affinity prediction_ task (as defined below). In the future, we will add more node-level tasks and datasets into TGB.

**Node affinity prediction.** This task considers the affinity of a subset of nodes (representing, e.g., users) towards other nodes (e.g., items) as its property, and how the affinity naturally changes over time. This task is relevant for example in recommendation systems, where it is important to provide personalized recommendations for a user by modelling their preference towards different items over time. Figure 3 shows the node affinity prediction task in the context of music recommendation systems as seen in the tgbn-genre dataset. In this task, we are given the interaction history of a user with different music genres, and the goal is to predict the frequency at which the user would listen to each genre over the next week.

More formally, given the observed evolution history of a temporal graph \(_{t}\) until current timestamp \(t\), the _node affinity prediction_ task (on a dataset such as tgbn-genre) predicts the interaction frequency vector \(_{t}[u,:]\) for a node \(u\) over a set of candidate nodes \(\) within a fixed future period \([t,t+k]\) where \(k\) is the window size defined by the application. Each entry in \(_{t}[u,:]\) corresponds to a candidate node \(v\) and the groundtruth value is generated as follows:

\[_{t}[u,v]= t+k}w_{(u,v,t_{i})}}{_{z }_{t<t_{i} t+k}w_{(u,z,t_{i})}}\] (1)

where \(w_{(u,v,t_{i})}\) is the weight of the edge \((u,v,t_{i})\) (which we assume to be \(0\) if the edge between \(u\) and \(v\) is not present at time \(t_{i}\)). Observe that, by definition, \(||_{t}[u,:]||_{1}=1\). We use the Normalized Discounted Cumulative Gain (NDCG) metric that takes into account the relative order of elements.

Figure 3: The _node affinity prediction_ task aims to predict how the preference of a user towards items changes over time. In the tgbn-genre example, the task is to predict the frequency at which the user would listen to each genre over the next week given their listening history until today.

NDCG is commonly used in information retrieval and recommendation systems as a measure of ranking quality . In this work, we use NDCG@10 where the relative order of the top 10 ranked items (_i.e.,_ destination nodes) are examined. Specifically in the tgbn-genre dataset, the NDCG@10 compares the ground truth to the relative order of the top-10 music genres that a model predicts.

## 4 Datasets

TGB offers nine temporal graph datasets, seven of which are collected and curated for this work. All datasets are split chronologically into the training, validation, and test sets, respectively containing \(70\%,15\%\), and \(15\%\) of all edges, in line with similar studies such as . The dataset licenses and download links are presented in Appendix B, and the datasets will be permanently maintained via Digital Research Alliance of Canada funded by the Government of Canada. We consider datasets with more than 5 million edges as medium-size and those with more than 25 million edges as large-size datasets.

Table 1 shows the statistics and properties of the temporal graph datasets provided by TGB. Datasets such as tgbl-flight, tgbl-comment, tgbl-coin, and tgbn-reddit are orders of magnitude larger than existing TG benchmark datasets , while their number of nodes and edges span a wide spectrum, ranging from thousands to millions. In addition, TGB dataset domains are highly diverse, coming from five distinct domains including social networks, interaction networks, rating networks, traffic networks, and trade networks. Moreover, the duration of the datasets varies from months to years, and the number of timestamps in TGB datasets ranges from 32 to more than 30 million with diverse ranges of time granularity from UNIX timestamps to annually. The datasets can be weighted, directed, or have edge attributes. We also report the _surprise index_ (i.e., \(} E_{}|}{|E_{}|}\)) as defined in  which computes the ratio of test edges that are not seen during training. Low surprise index implies that memorization-based methods (such as EdgeBank ) can potentially achieve good performance on dynamic link property prediction task. We can observe that the surprise index also varies notably across TGB datasets, further contributing to datasets diversity. We present more dataset statistics in Appendix G. We discuss the details of TGB datasets next.

tgbl-wiki. This dataset stores the co-editing network on Wikipedia pages over one month. The network is a bipartite interaction network where editors and wiki pages are nodes, while one edge represents a given user edits a page at a specific timestamp. Each edge has text features from the page edits. The task for this dataset is to predict with which wiki page a user will interact at a given time.

tgbl-review. This dataset is an Amazon product review network from 1997 to 2018 where users rate different products in the electronics category from a scale of one to five. Therefore, the network is a bipartite weighted network where both users and products are nodes and each edge represents a particular review from a user to a product at a given time. Only users with a minimum of 10 reviews within the aforementioned time interval are kept in the network. The considered task for this dataset is to predict which product a user will review at a given time.

tgbl-coin. This is a cryptocurrency transaction dataset based on the Stablecoin ERC20 transactions dataset . Each node is an address and each edge represents the transfer of funds from one address

    &  &  &  &  &  & ^{@paragraphsign}\)} \\   & tgbl-wiki & interact. & 9,227 & 157,474 & 152,757 & 0.108 & W: ✗, Di: ✓, A: ✓ \\  & tgbl-review & rating & 352,637 & 4,873,540 & 6,865 & 0.987 & W: ✓, Di: ✓, A: ✗ \\  & tgbl-coin & transact. & 638,486 & 22,809,486 & 1,295,720 & 0.120 & W: ✓, Di: ✓, A: ✗ \\  & tgbl-comment & social & 994,790 & 44,314,507 & 30,998,030 & 0.823 & W: ✓, Di: ✓, A: ✓ \\  & tgbl-flight & traffic & 18143 & 67,169,570 & 1,385 & 0.024 & W: ✗, Di: ✓, A: ✓ \\   & tgbn-trade & trade & 255 & 468,245 & 32 & 0.023 & W: ✓, Di: ✓, A: ✗ \\  & tgbn-genre & interact. & 1,505 & 17,858,395 & 133,758 & 0.005 & W: ✓, Di: ✓, A: ✗ \\  & tgbn-reddit & social & 11,766 & 27,174,118 & 21,889,537 & 0.013 & W: ✓, Di: ✓, A: ✗ \\  & tgbn-token & transact. & 61,756 & 72,936,998 & 2,036,524 & 0.014 & W: ✓, Di: ✓, A: ✓ \\   

Table 1: Dataset Statistics. Dataset names are colored based on their scale as small, medium, and large. \({}^{@paragraphsign}\): Edges can be _Weighted_, _Directed_, or _Attributed_.

to another at a time. The network starts from April 1st, 2022, and ends on November 1st, 2022, and contains transaction data of 5 stablecoins and 1 wrapped token. This duration includes the Terra Luna crash where the token lost its fixed price of 1 USD. The considered task for this dataset is to predict with which destination a given address will interact at a given time.

tgbl-comment.This dataset is a directed reply network of Reddit where users reply to each other's threads. Each node is a user and each interaction is a reply from one user to another. The network starts from 2005 and ends at 2010. The considered task for this dataset is to predict if a given user will reply to another one at a given time.

tgbl-flight.This dataset is a crowd sourced international flight network from 2019 to 2022. The airports are modeled as nodes, while the edges are flights between airports at a given day. The node features include the type of the airport, the continent where the airport is located, the ISO region code of the airport as well as its longitude and latitude. The edge feature is the associated flight number. In this dataset, our task is to predict whether a flight will happen between two specific airport on a future date. This is useful for foreseeing potential flight disruptions such as cancellation and delays. For instance, during the COVID-19 pandemic, many flight routes were cancelled to combat the spread of COVID-19. In addition, the prediction of global flight network is also important for studying and forecasting the spread of disease such as COVID-19 to new regions, as shown in .

tgbn-trade.This is the international agriculture trading network between nations of the United Nations (UN) from 1986 to 2016. Each node is a nation and an edge represents the sum trade value of all agriculture products from one nation to another one. As the data is reported annually, the time granularity of the dataset is yearly. The considered task for this dataset is to predict the proportion of agriculture trade values from one nation to other nations during the next year.

tgbn-genre.This is a bipartite and weighted interaction network between users and the music genres of songs they listen to. Both users and music genres are represented as nodes while an interaction specifies a user listens to a music genre at a given time. The edge weights denote the percentage of which a song belongs to a certain genre. The dataset is constructed by cross referencing the songs in the _LastFM-song-listens_ dataset  with that of music genres in the _million-song_ dataset . The _LastFM-song-listens_ dataset has one month of who-listens-to-which-song information for 1000 users and the _million-song_ dataset provides genre weights for all songs in the _LastFM-song-listens_ dataset. We only retain genres with at least 10% weights for each song that are repeated at least a thousand times in the dataset. Genre names are cleaned to remove typos. Here, the task is to predict how frequently each user will interact with music genres over the next week. This is applicable to many music recommendation systems where providing personalized recommendation is important and user preference shifts over time.

tgbn-reddit.This is a users and subreddits interaction network. Both users and subreddits are nodes and each edge indicates that a user posted on a subreddit at a given time. The dataset spans from 2008 to 2010. The task considered for this dataset is to learn the interaction frequency towards the subreddits of a user over the next week.

tgbn-token.This is a user and cryptocurrency token transaction network. Both users and tokens are nodes and each edge indicates the transaction from a user to a token. The edge weights indicate the amount of token transferred and considering the disparity between weights, we normalized the edge weights using logarithm. The goal here is to predict how frequently a user will interact with various types of tokens over the next week. The dataset is extracted and curated from this source.

## 5 Experiments

For dynamic link property prediction, we include DyRep , TGN , CAWN , TCL , GraphMixer , NAT , TGAT  and two deterministic heuristics namely EdgeBank\({}_{}\) and EdgeBank\({}_{}\). For dynamic node property prediction, we include DyRep, TGN, and deterministic heuristics such as persistence forecast  and moving average . Details about the above methods are presented in Appendix D. The computing resources are discussed Appendix E. For the experimental results, we report the average and standard deviation across 5 different runs. We highlight the best results in bold and underline the second place results.

### Dynamic Link Property Prediction

Table (a)a shows the performance of TG methods for dynamic link property prediction on the tgbl-wiki dataset. tgbl-wiki is an existing dataset where many methods achieve over-optimistic performance in the literature [35; 46; 9]. With TGB's evaluation protocol, there is now a clear distinction in model performance and NAT achieves the best result on this dataset. As tgbl-wiki is the smallest dataset in this task, it is computationally feasible to sample all possible destinations of a given source node. Thus, we compare the true destination with all possible negative destinations in this dataset. In Table (b)b, we report the results on tgbl-review where we sample 100 negative edges per positive edge. Here, we observe that many of the best performing methods on tgbl-wiki has a significant drop in performance including NAT, CAWN and Edgebank. More notably, the method rankings also changed significantly with GraphMixer and TGAT being the top two methods. This observation emphasizes the importance of dataset diversity when benchmarking TG methods. In Appendix H, we conduct an ablation study on the effect of number of negative samples on the performance of dynamic link property prediction.

One explanation for the significant performance reduction of some methods on tgbl-review is that it has a higher _surprise index_ compared to tgbl-wiki (see Table 1). The surprise index reflects the ratio of edges in the test set that have not been seen during training. Therefore, a dataset with a high surprise index requires more inductive reasoning, as most of the test edges are unobserved during training. As a heuristic that memorizes past edges, EdgeBank performance is inversely correlated with the surprise index and it achieves higher performance when the suprise index of the dataset is low. An interesting future direction is the investigation of the performance of certain category of methods with the surprise index. For example, the top two methods NAT and CAWN on wikipedia both utilizes features from the joint neighborhood of nodes in the queried edge . On the tgbl-review dataset, the best performing TGAT is designed for inductive representation learning on temporal graph  which fits the inductive nature of tgbl-review which has high surprise index.

    &  \\  & Validation & Test \\  DyRep  & 0.072\(\)0.009 & 0.050\(\)0.017 \\ TGN  & 0.435\(\)0.069 & 0.396\(\)0.060 \\ CAWN  & 0.743\(\)0.004 & 0.711\(\)0.006 \\ TCL  & 0.198\(\)0.016 & 0.207\(\)0.025 \\ GraphMixer  & 0.113\(\)0.003 & 0.118\(\)0.002 \\ TGAT  & 0.131\(\)0.008 & 0.141\(\)0.007 \\ NAT  & **0.773\(\)**0.011 & **0.749\(\)**0.010 \\ EdgeBank\({}_{}\) & 0.600 & 0.571 \\ EdgeBank\({}_{}\) & 0.527 & 0.495 \\   

Table 2: Results for _dynamic link property prediction_ on small datasets.

Figure 4: Test set inference time of TG methods can have up to two orders of magnitude difference.

Figure 3(a) and 3(b) show the inference time of different methods for the test set of tgbl-wiki and tgbl-review, respectively. Similarly, Figure 4(a) and 4(b) show the total training and validation time of TG methods for tgbl-wiki and tgbl-review. Notice that as a heuristic baseline, EdgeBank inference, train, or validation time is generally at least one order of magnitude lower than neural network based methods. We also observe an order of difference in inference time within TG methods. We believe one important future direction is to improve the computational time of these models to be closer to baselines such as EdgeBank, which can better scale to large real-world temporal graphs.

Table 3 shows the performance of TG methods on medium and large TGB datasets. Note that some methods, including CAWN, TCL, and GraphMixer, ran out of memory on GPU for these datasets, thus their performance is not reported. Overall, TGN has the best performance on all of these three datasets. Surprisingly, the EdgeBank heuristic is highly competitive on the tgbl-coin dataset where it even significantly outperforms DyRep. Therefore, it is important to include EdgeBank as a baseline for all datasets. Another observation is that for medium and large TGB datasets, there can be a significant performance change for a single model between the validation and test set. This is because TGB datasets span over a long time (such as tgbl-comment, lasting 5 years) and one can expect that models need to deal with potential distribution shifts between the validation set and the test set. Figure 5(a), 5(b) and 5(c) reports the test time for TG methods on tgbl-coin, tgbl-flight and tgbl-comment, respectively. On both tgbl-coin and tgbl-comment, Edgebank is at least one order of magnitude faster than TGN and DyRep while on the tgbl-flight, due to the large number of temporal edges, DyRep is the fastest method.

### Dynamic Node Property Prediction

Table 4 shows the performance of various methods on the node affinity prediction task in the dynamic node property prediction category. As node-level tasks have received less attention compared to edge-level tasks in the literature, adopting methods that are specially designed for link prediction to this task is non-trivial. As a result, these methods are omitted in this section. Considering Table 4, the key observation is that simple heuristics like persistence forecast and moving average are strong contenders to TG methods such as DyRep and TGN. Notably, persistence forecast is SOTA on tgbm-trade while moving average is the best performing on other datasets. TGN is second place on tgbm-genre dataset. Different from link prediction where the existence of a link is casted as binary classification, the node affinity prediction task compares the likelihood or weight that the model assigns to different target nodes (mostly positive links). These results highlight the need for the future development of TG methods that can acquire flexible node representations capable of learning how user preferences evolve over time.

Figure 5: Total train and validation time of TG methods can have two orders of magnitude difference.

    &  &  &  \\  &  &  &  \\  & Validation & Test & Validation & Test & Validation & Test \\  DyRep  & 0.512\(\)0.014 & 0.452\(\)0.046 & 0.291\(\)0.028 & 0.289\(\)0.033 & 0.573\(\)0.013 & 0.556\(\)0.014 \\ TGN  & **0.607\(\)**0.014 & **0.586\(\)**0.037 & **0.356\(\)**0.019 & **0.379\(\)**0.021 & **0.731\(\)**0.010 & **0.705\(\)**0.020 \\ EdgeBank\({}_{}\) & 0.492 & 0.580 & 0.124 & 0.149 & 0.363 & 0.387 \\ EdgeBank\({}_{}\) & 0.315 & 0.359 & 0.109 & 0.129 & 0.166 & 0.167 \\   

Table 3: Results for _dynamic link property prediction_ task on medium and large datasets.

## 6 Conclusion

To enable realistic, reproducible, and robust evaluation for machine learning on temporal graphs, we present the Temporal Graph Benchmark, a collection of challenging and diverse datasets. TGB datasets are diverse in their dataset properties as well as being orders of magnitude larger than existing ones. TGB includes both _dynamic link property prediction_ and _dynamic node property prediction_ tasks, while providing an automated pipeline for researchers to evaluate novel methods and compare them on the TGB leaderboards. In dynamic link property prediction, we find that model rankings can vary significantly across datasets, thus demonstrating the necessity to evaluate on the diverse range of TGB datasets. Surprisingly for dynamic node property prediction, simple heuristics such as persistence forecast and moving average outperforms SOTA methods such as TGN. This motivates the development of more TG methods for node-level tasks.

**Impact on Temporal Graph Learning.** Significant advancements in machine learning are often accelerated by the availability of public and well-curated datasets such as ImageNet  and OGB . We expect TGB to be a common and standard benchmark for temporal graph learning, helping to facilitate novel methodological changes.

**Potential Negative Impact.** If TGB becomes a widely-used benchmark for temporal graph learning, it is possible that future papers might focus on TGB datasets and tasks, which may limit the use of other TG tasks and datasets for benchmarking. To avoid this issue, we plan to update TGB regularly with community feedback as well as adding additional datasets and tasks.

**Limitations.** Firstly, TGB only considers the most common TG evaluation setting as discussed in Section 3, namely the _streaming_ setting. We also discuss other possible settings in Appendix C. Depending on a specific application, a different setting might be more suitable (such as forbidding test time node updates). Secondly, TGB currently only contains datasets from five domains, while many other domains such as biological networks are not included. We plan to continue adding datasets to TGB to further increase the dataset diversity in TGB.