# ID\({}^{3}\): Identity-Preserving-yet-Diversified Diffusion

Models for Synthetic Face Recognition

Jianqing Xu1,  Shen Li2,

Jiaying Wu2, Miao Xiong2, Ailin Deng2, Jiazhen Ji1,

Yuge Huang\({}^{\#}\)1, Guodong Mu1, Wenjie Feng2, Shouhong Ding1, and Bryan Hooi2

1Tencent Youtu Lab

2National University of Singapore

###### Abstract

Synthetic face recognition (SFR) aims to generate synthetic face datasets that mimic the distribution of real face data, which allows for training face recognition models in a privacy-preserving manner. Despite the remarkable potential of diffusion models in image generation, current diffusion-based SFR models struggle with generalization to real-world faces. To address this limitation, we outline three key objectives for SFR: (1) promoting diversity across identities (inter-class diversity), (2) ensuring diversity within each identity by injecting various facial attributes (intra-class diversity), and (3) maintaining identity consistency within each identity group (intra-class identity preservation). Inspired by these goals, we introduce a diffusion-fueled SFR model termed ID\({}^{3}\). ID\({}^{3}\) employs an ID-preserving loss to generate diverse yet identity-consistent facial appearances. Theoretically, we show that minimizing this loss is equivalent to maximizing the lower bound of an adjusted conditional log-likelihood over ID-preserving data. This equivalence motivates an ID-preserving sampling algorithm, which operates over an adjusted gradient vector field, enabling the generation of fake face recognition datasets that approximate the distribution of real-world faces. Extensive experiments across five challenging benchmarks validate the advantages of ID\({}^{3}\). Code is released at: https://github.com/hitspring2015/ID3-SFR.

## 1 Introduction

With the introduction of various regulations restricting the use of large-scale facial data in recent years, such as GDPR, synthetic-based face recognition (SFR) (Boutros et al., 2023) has received widespread attention from the academic community (Qiu et al., 2021; Wood et al., 2021; Wang et al., 2023). The goal of SFR is to generate synthetic face datasets that mimic the distribution of real face images, and use it to train a face recognition (FR) model such that the model can recognize real face images as effectively as possible.

There exist numerous efforts to address SFR, which can be categorized into _GAN_-based models and _diffusion_ models. GAN-based models utilize adversarial training to learn to generate synthetic data for FR training. Recently, with the empirical advantages of diffusion models over GANs, many works have attempted to use diffusion models to generate synthetic face data in place of authentic data. However, the reported results by these state-of-the-art (SoTA) SFR generative models (Bae et al., 2023; Boutros et al., 2022; Kolf et al., 2023; Qiu et al., 2021; Boutros et al., 2023) showsignificant degradation in the verification accuracy in comparison to FR models trained by authentic data. We deduce the degradation might be due to two reasons. First, while previous works adopt diffusion models, they operate in the original score vector field without injecting the direction with regards to identity information, which makes them unable to guarantee identity-preserving sampling. Second, they fail to consider the structure of face manifold in terms of diversity during sampling.

We thus argue that the crux of SFR is to automatically generate a training dataset that has the following characteristics: (i) _inter-class diversity_: the training dataset covers sufficiently many distinct identities; (ii) _intra-class diversity_: each identity has diverse face samples with various facial attributes such as poses, ages, etc; (iii) _intra-class identity preservation_: samples within each class should be identity-consistent. Also note that, critically, the SFR dataset generation process should be fully automated without manual filtering or introducing auxiliary real face samples.

To this end, in this paper, we propose a novel **ID**entity-preserving-yet-**D**iversified **D**iffusion generative model termed ID\({}^{3}\) and a sampling algorithm for inference. Jointly leveraging identity and face attributes as conditioning signals, ID\({}^{3}\) can synthesize diversified face images that conform to desired attributes while preserving intra-class identity. Specifically, ID\({}^{3}\) generates a new sample based upon two conditioning signals: a target face embedding and a specific set of face attributes. The target face embedding enforces identity preservation while face attributes enrich intra-class diversity. To optimize ID\({}^{3}\), we propose a new loss function that involves an explicit term to preserve identity. Theoretically, we show that with the addition of this term, minimizing the proposed loss function is equivalent to maximizing the lower bound of the likelihood of an adjusted conditional data log-likelihood. Consequently, this theoretical analysis motivates a new ID-preserving sampling algorithm that generates desired synthetic face images. To generate an SFR dataset, we further propose a new dataset-generating algorithm. This algorithm ensures inter-class diversity by solving the Tammes problem (Tammes, 1930), which maximally separates identity embeddings on the face manifold. In the meantime, it encourages intra-class diversity by perturbing identity embeddings randomly within prescribed areas. It works in conjunction with identity embeddings and diverse attributes to ensure inter-/intra-class diversity while preserving identity. Extensive experiments show that ID\({}^{3}\) outperforms other existing methods in multiple challenging benchmarks.

To sum up, our major contributions are listed as follows:

* **Model with Theoretical Guarantees**: We propose ID\({}^{3}\), an identity-preserving-yet-diversified diffusion model for SFR. Theoretically, optimizing ID\({}^{3}\) is equivalent to shifting the original data likelihood to cover ID-preserving data.
* **Algorithm Design**: Motivated by this theoretical equivalence, we design a novel sampling algorithm for face image generation, together with a face dataset-generating algorithm, which effectively generates fake face datasets that approximate real-world faces.
* **Effectiveness**: Compared with SoTA SFR approaches, ID\({}^{3}\) improves SFR performance by \( 2.4\%\) on average across five challenging benchmarks.

## 2 Problem Formulation

The scope of this paper is synthetic-based face recognition (SFR), which focuses on generating high-quality training data (i.e., face images) for FR models. Generally, we aim to address SFR by generating face images that conform to diverse facial attributes while preserving identity within each class, in an automated manner. Technically, we break down this objective into the following two research questions (RQs) to be answered:

* **RQ1**: How can we effectively train a SFR generative model that preserves identity within each class, while boosting inter-class and intra-class diversity?
* **RQ2**: Once the generative model is trained, what sampling strategy can be employed to generate a synthetic face dataset that enables state-of-the-art face recognition models to perform well on real face benchmarks?

The rest of the paper aims to answer these two questions, respectively, in order to improve synthetic face recognition performance.

## 3 Methodology

We propose ID\({}^{3}\), a conditional diffusion model that generates diverse yet identity-preserving face images. ID\({}^{3}\) solves RQ1 by introducing two conditioning signals (identity embeddings and face attributes) into a diffusion model which is trained using a novel loss function. The loss function, together with identity embeddings, ensures intra-class identity preservation, while generation upon various face attributes give rise to intra-/inter-class diversity of face appearances. Our theoretical result regarding this loss function leads to an ID-preserving sampling algorithm and, further, an effective dataset-generating algorithm.

**Notations.** Throughout the rest of the the paper, we let \(\) denote a real face dataset that contains face images \(_{0}^{H W 3}\). Let \(\) denote a desired identity embedding and \(\) be face attributes.

### Diffusion Models

We build up our generative model, ID\({}^{3}\), upon denoising diffusion probabilistic models (diffusion models for short) (Ho et al., 2020; Song et al., 2022; Rombach et al., 2022) as they empirically exhibit SoTA performance in the field of image generation. Diffusion models can be seen as a hierarchical VAE whose optimization objective is to minimize the KL divergence between the true data distribution and the model distribution \(p_{}\), which is equivalent to minimizing the expected negative log-likelihood (NLL), \(_{}[- p_{}()]\). However, directly minimizing the expected NLL is intractable, therefore diffusion models instead maximize its evidence lower bound (ELBO), where the ELBO term can further simply to a denoising task with several model assumptions:

\[ p()&_{q(_{1,T}|_{0})}[_{0 :T})}{q(_{1:T}|_{0})}]}_{}\\ &=_{q(_{1}|_{0})}[-\|_{0}-}_{}(_{1},1) \|_{2}^{2}]-_{t=2}^{T}_{t}\|_{ 0}-}_{}(_{t},t)\|_{2}^{2}\] (1)

where \(_{t}:=^{2}(t)}_{t-1}(1-_ {t})^{2}}{(1-_{t})^{2}},_{t}=_{=1}^{t}_ {}\). Specifically, given a sample \(_{0}\) (or interchangeably, \(\)) from the image distribution, a sequence \(_{1}\), \(_{2}\),..., \(_{T}\) of noisy images is produced by

Figure 1: The forward pass of ID\({}^{3}\) in terms of loss computation. Given an image, its face attributes, and its face embedding, ID\({}^{3}\) obtains the imageâ€™s noised version after \(t\) diffusion steps and employs a denoising network to denoise it. This denoising process is conditioned on the predicted attributes and the ID embedding. Optimization proceeds by minimizing a loss function comprised of a denoising term, a one-step reconstruction term, an inner-product term, and a constant.

progressively adding Gaussian noise according to a variance schedule \(_{1},...,_{T}\). This process is called the forward diffusion process \(q(_{t}|_{t-1})\). At the final time step, \(_{T}\) is assumed to be pure Gaussian noise: \(_{T}(0,I)\). The objective is to train a denoising network \(}_{}\) that is able to predict the original image from the noisy image \(_{t}\) and the time step \(t\). To sample a new image, we sample \(_{T}(0,I)\) and iteratively denoise it, producing a sequence \(_{T}\), \(_{T-1}\),..., \(_{1}\), \(_{0}\). The final image, \(_{0}\), should resemble the training data.

Although the naive diffusion models are powerful in generating images, they do not deliver the promise of generating face images of the same identity (i.e. identity preservation) without direct corresponding information; nor are they aware of diverse desired facial attributes during inference. To achieve _intra-class diversity_ and _intra-class identity preservation_, we would like to gain control of generating desired identities, each of which exhibits various attributes, including poses, ages and background variations. Hence, our aim is to design a diffusion model that conditions on specific identities and attributes throughout the generation of face images.

### ID\({}^{3}\) as Conditional Diffusion Models

We propose a conditional diffusion model, ID\({}^{3}\) (see Figure 1 for details). Specifically, we extend the denoising network by conditioning it on two sources of signals: identity signals \(\) and face attribute signals \(\). The identity signals capture discernible faces in generated images, whereas face attribute signals specify the identity-irrelevant attributes, including poses, ages, etc. We introduce how to obtain these two conditioning signals, respectively, in the next two subsections.

#### 3.2.1 Identity Conditioning Signal

To obtain identity conditioning signals, we assume access to a pretrained face recognition model \(f_{}:^{H W 3}^{d-1}\), which maps the domain of face images to a feature space \(^{d-1}\). This mapping \(f_{}\) is parameterized by the learnable parameter \(\), which is obtained by training the model on a real face dataset in the face recognition task. We follow the latest advancement of face recognition by setting the output space to be a unit hypersphere \(^{d-1}\). Then, given a face image \(_{0}\) drawn from the dataset \(\), we obtain its identity embedding \(^{d-1}\) by feeding it into a face recognition model \(f_{}\): \(=f_{}(_{0})\), which serves as the identity conditioning signals for ID\({}^{3}\).

#### 3.2.2 Face Attribute Conditioning Signal

Face attributes capture identity-irrelevant information about face images, such as age, face poses, etc. To obtain face attribute as conditioning signals, we employ pretrained attribute predictors (Serengil and Ozpinar, 2021) which output these attributes when given a face image as input. The pretrained attribute predictors are a collection of ad-hoc domain experts in age estimation and pose estimation. After obtaining each of these attribute values, \(_{}\), \(_{}[-90^{},90^{}]^{3}\), we concatenate them as the overall attribute \(=[_{},_{}]\) which is then fed into the diffusion model as conditioning signals.

### Optimization Objective

Now the denoising network in Eq. (1) becomes \(}_{}(_{t},t,,)\) that takes as input the noised \(_{t}\), the time step \(t\), and the conditioning signals \(\) and \(\). To optimize ID\({}^{3}\), we construct a training objective upon the ELBO of \( p(|,)\), ensuring that ID\({}^{3}\) generates identity-preserving yet diversified faces:

\[_{}_{(_{0},,) ^{}}_{,}(_{0},,)\] (2)

Here, \(\) is the learnable parameter of the denoising network and the datapoint-wise loss is given by

\[_{,}(_{0},,)\] (3)where \(}_{0}^{(t)}\) is the output of the denoising network that takes as input the conditioning signals \(,\), the time \(t\) and the \(t\)-step noisified image \(_{t}\):

\[}_{0}^{(t)}:=}_{}(_{ t},t,,).\] (4)

Symbolically, \(}_{0}^{(t)}\) denotes the denoised image predicted by the denoising network when given the \(t\)-step noisified \(_{t}\), the time \(t\) and the associated conditioning signals \(,\). The coefficients, \(_{_{0}}\) and \(_{t}\) are scalars depending on \(_{0}\) and \(t\), respectively, and \(C\) is a constant that does not depend on the learnable parameters \(\). The specific value of \(C\) will be elaborated in Appendix A.

To summarize, our proposed loss function consists of four terms: the one-step reconstruction term, the denoising term, the inner-product term, and a constant. Intuitively, the denoising term, along with the one-step reconstruction term, aims to improve the generative quality by denoising the \(t\)-step noisified face images while the inner-product term encourages the face embedding of the denoisified images to get close to the groundtruth identity embedding. To understand this loss function systematically, we theoretically find that minimizing this proposed loss function is equivalent to the maximization of the lower bound of an adjusted conditional log-likelihood over identity-preserving face images, which further leads us to an ID-preserving sampling algorithm.

**Theorem 3.1**.: _Minimizing \(\) with regard to \(\) is equivalent to minimizing the upper bound of an adjusted conditional data negative log-likelihood \(-(|,)\), i.e.:_

\[_{}(_{0},,) -(|,)\] (5)

_where_

\[(|,) p(|, ) p(,|)^{^{T} _{t}}{T-1}}\] (6)

Proof.: The proof can be found in Appendix A. 

**Remark**.: We have just shown that our proposed loss is the upper bound of an adjusted conditional negative data log-likelihood. This adjusted likelihood \((|,)\) can be factorized into the original likelihood \(p(|,)\) and a reversed likelihood \(p(,|)\) with some positive power. We term it as "adjusted" since the original likelihood is discounted by the reversed likelihood. Intuitively, the reversed likelihood shifts the original likelihood such that the adjusted likelihood covers ID-preserving data, which is attributed to the inner-product term we introduce into the loss function in Eq. (2).

```
0: Denoising network \(}_{}\); recognition model \(f_{}\); conditioning signals \(\) and \(\).
0: A generated face \(_{0}\)\(_{T}\) sample from \((0,I)\); for\(t T\)to\(\)do  Compute the score function \((_{t}|,)\) as in Eq. (7);  Draw a Gaussian sample \((0,I)\);  Perform the update: \(_{t-1}_{t}+(_{ t}|,)+\);  end for return\(_{0}\) ```

**Algorithm 2**ID-Preserving Sampling Alg.

### ID-Preserving Sampling

Theorem 3.1 provides insights for designing a novel sampling algorithm in the spirit of Langevin dynamics applied on the adjusted conditional likelihood \((_{t}|,)\). We note that Langevin dynamics can generate new samples from a probability density \(p\) by virtue of its score function (i.e., the gradient of the logarithm of the probability density w.r.t. the sample, \(_{}\! p\)). Motivated by this observation, we aim to find the score function of the adjusted likelihood for sample generation. Specifically, taking the logarithm and the gradient w.r.t. \(\) on both sides of Eq. (6) yields

\[(|,)= p(| ,)+^{T}_{t}}{T-1} p( ,|)\] (7)Then, our ID-preserving sampling algorithm first draws a Gaussian sample \(_{T}(0,I)\). Afterwards, sequentially, the algorithm performs the following update for \(t\) iterating from \(T\) backwards to \(1\):

\[_{t-1}_{t}+(_{ t}|,)+\]

where

\[(_{t}|,)=_{t}|,)}_{}+ ^{T}_{t}}{T-1}, |_{t})}_{}\] (8)

Note that the original likelihood score in Eq. (8) can be evaluated by

\[ p(_{t}|,)=_{ t}}}{_{t}}}(}_{}( _{t},t,,)-_{t}}{_{t}}})\]

and the reversed likelihood score is given by a scaled inner product:

\[ p(,|_{t})=_{_{t} }T^{}f_{}(_{t})\]

See Appendix B for the derivation of the above equations. As such, our ID-preserving sampling algorithm performs sampling by searching a trajectory in the vector field \((_{t}|,)\) that can maximize the adjusted conditional likelihood \((_{t}|,)\). See Algorithm 2 for the specific procedure.

**Remark.** Our proposed adjusted likelihood score differs from the original score by adding an extra scaled reversed likelihood score in Eq. (8). Consequently, as shown in Figure 2, the resulting vector field differs from the original vector field, which leads to different Langevin sampling trajectories and thus different sampling quality.

### Synthetic Dataset Generation

In terms of the second question (**RQ2**): after training ID3, with what sampling strategy is it possible to generate a synthetic face dataset on which SoTA face recognition models can be trained and perform well on challenging benchmarks?

Our proposed dataset-generating algorithm goes as follows: given \(N\) target identities, we generate \(N\) anchor embeddings distributed on the sphere: \(_{1},_{2},...,_{N}^{d-1}\) as uniformly as possible in the sense that each pair of the embeddings are maximally separated on the unit sphere4. For each anchor \(_{i}\), we would like to generate \(m\) identity embeddings perturbed around \(_{i}\) while ensuring

[MISSING_PAGE_EMPTY:7]

models are implemented with PyTorch and trained from scratch using 8 NVIDIA Tesla V100 GPUs. Specifically, we set \(_{t}_{_{t}}=0.5(1-1/(1+))\) for the loss coefficients in Eq. (3), and use \(T=1,000\) for the diffusion model; training batch size is set to \(16\) and the total training steps \(500,000\). We directly use a pre-trained face recognition (FR) model sourced from pSp (Richardson et al., 2021) as the identity feature extractor. Throughout the entire training process, these pre-trained models are frozen. In addition, we set # of identity embeddings \(m=25\) in Eq. (9) for each ID and match their embeddings with randomly selected attributes as conditioning signals for the diffusion model. For face recognition, we use LResNet50-IR (Deng et al., 2019), a variant of ResNet (He et al., 2016), as the backbone framework and follow the original configurations.

### Performance Evaluation

We test the performance of the face recognition model trained on synthetic face data generated by ID\({}^{3}\) and compare against SoTA SFR generative models, including IDiff-Face (Boutros et al., 2023), ID-Net (Kolf et al., 2023), DigiFace (Bae et al., 2023), SFace (Boutros et al., 2022), SynFace (Qiu et al., 2021) and DCFace (Kim et al., 2023).

#### 4.3.1 Qualitative Results

Here, we illustrate a collection of face images generated by ID\({}^{3}\) as qualitative evaluation. Figure 3 shows the results for randomly sampled identities (IDs) under various attribute conditions; Obviously, when comparing different identities (inter-class), the essential intrinsic key information of each identity is still retained and can be easily identified. Also, different samples of each identity (intra-class) exhibit distinct diversity, stemming from variations in similarity scores (\(_{ij}\)'s) and differences in face attributes as conditioning signals. In terms of the effect of our proposed adjusted score and the original score on the sampling algorithm, we observe that the face images generated by our proposed ID\({}^{3}\) exhibits much better quality and identity preservation than those generated by the original score function, as shown in Figure 2.

#### 4.3.2 Quantitative Results

We compare the accuracies of FR models trained on the synthetic face datasets generated by different generative models and demonstrate the results in Table 1.

As shown in Table 1, ID\({}^{3}\) demonstrates consistent superior performance, achieving the highest average accuracy of \(86.50\%\), and outperforms other baselines in all benchmarks, notably scoring \(83.78\%\) in AgeDB and \(85.00\%\) in CFP-FP. This demonstrates the effectiveness of ID\({}^{3}\) in gaining pose and age control. Other methods, while effective to varying degrees, attain average scores below \(86.50\%\) and are inferior to ID\({}^{3}\).

It is worth mentioning that ID\({}^{3}\), apart from using real data during training, does not introduce any real images as auxiliary data during the sampling phase. The synthetic data is directly used in the training of the face recognition model without undergoing any secondary or manual filtering. Additionally, when training the face recognition model using the synthetic data, no real images are introduced as auxiliary data. On the other hand, DCFace, as described and reported in (Kim et al., 2023), introduces real face images as auxiliary data during the training phase for face recognition.

   Method & Training set & LFW & CFP-FP & CP-LFW & AgeDB & CA-LFW & Average \\  ID-Net & FFHQ & 84.83 & 70.43 & 67.35 & 63.58 & 71.50 & 71.53 \\ DigiFace & FFHQ & 88.07 & 70.99 & 66.73 & 60.92 & 69.23 & 71.19 \\ SFace & FFHQ & 91.43 & 73.10 & 73.42 & 69.87 & 76.92 & 76.95 \\ SynFace & FFHQ & 91.93 & 75.03 & 70.43 & 61.63 & 74.73 & 74.75 \\ IDiff-Face & FFHQ & 97.10 & 82.00 & 76.65 & 78.40 & 86.32 & 84.09 \\
**ID\({}^{3}\) (Ours)** & FFHQ & **97.28** & **85.00** & **77.13** & **83.78** & **89.30** & **86.50** \\  DCFace & FFHQ+CASIA & **98.55** & 85.33 & 82.62 & 89.7 & **91.6** & 89.56 \\
**ID\({}^{3}\) (Ours)** & CASIA & 97.68 & **86.84** & **82.77** & **91.00** & 90.73 & **89.80** \\   

Table 1: SoTA Comparison. Face verification accuracy (%) of LResNet50-IR on different benchmarks when trained on synthetic datasets from ID\({}^{3}\) and state-of-the-art SFR generative models. For fairness, all methods generate face datasets of 10K identities each of which has 50 face images.

This helps enhance the diversity of the training data and leads to slightly better results than ID\({}^{3}\) in the two benchmarks.

Ablation study.We further investigate the impact of each contributing component of ID\({}^{3}\) in generating a synthetic face dataset on SFR. This includes three ablation studies shown in Table 2: the effect of the reversed likelihood score in Eq. (8) on ID-preserving sampling algorithm (ID\({}^{3}\) vs. ID\({}^{3}\)-w/o-reversed), the effect of using anchors in ID\({}^{3}\) (ID\({}^{3}\) vs. ID\({}^{3}\)-random), and the effect of lower- and upper-bound of Uniform distribution for sampling \(_{ij}\)'s.

In the first study, we compare ID\({}^{3}\) with ID\({}^{3}\)-w/o-reversed, which removes the reversed likelihood score from Eq. (8) in the proposed ID-preserving sampling algorithm. We observed ID\({}^{3}\) consistently outperforms ID\({}^{3}\)-w/o-reversed with large margins. This suggests the necessity of the inner-product term in the proposed loss function Eq. (3) and the reversed likelihood score in the adjusted likelihood score Eq. (8).

In the second study (cf. Appendix E), an appropriate smaller value of \(lb\), if not exceeding a certain range, can increase the intra-class diversity, resulting in more diverse intra-class face images. This aligns with our objective of increasing intra-class diversity in the generated data to enhance the effectiveness of SFR. As per the constraints of Eq. (9), each generated identity embedding \(_{ij}\) maintains the same identity as the anchor \(_{i}\). This, along with our proposed inner-product term in Eq. (3), ensures consistent intra-class identities while introducing a significant amount of diversity.

In the third study, we demonstrate how effective it is to use maximally-separated anchors in ID\({}^{3}\) as compared to ID\({}^{3}\)-random that randomly sets anchors on the unit hypersphere for sample generation. Clearly, ID\({}^{3}\)-random does not yield as good results as ID\({}^{3}\). This is because the random sampling method only introduces one identity signal per ID, while the model requires a combination of attributes and identity signals. Attribute signals can only control explicit attributes, whereas identity signals control implicit properties. Introducing only one identity signal per identity implies insufficient intra-class diversity. Additionally, ID\({}^{3}\)-random fails to regularize the relationship among different identities, leading to inadequate diversity among classes or aliasing issues with different identity signals. The identity signals obtained using ID\({}^{3}\) resolves the problem of aliasing between identity signals across classes, effectively improving intra-/inter-class diversity.

## 5 Conclusion

We have proposed ID\({}^{3}\), an identity-preserving-yet-diversified diffusion generative model for SFR. Our theoretical analysis regarding the training of ID\({}^{3}\) induces a new ID-preserving sampling algorithm and further, a dataset-generating algorithm that generates identity-preserving face images with inter-/intra-class diversity. Extensive experiments show that ID\({}^{3}\) outperforms existing methods in challenging multiple benchmarks.

**Limitations.** While ID\({}^{3}\), designed for the sake of privacy protection, achieves SoTA performance in SFR, there remains clear margins as compared to the FR performance when training with real-world face datasets such as MS1M. This suggests that the fake face dataset generated by ID\({}^{3}\) does not fully approximate the real-world faces. Future work might include closing this gap.

   Method & LFW & CPP-FP & CP-LFW & AgeDB & CA-LFW & Average \\  ID\({}^{3}\)-w/o-reversed & 78.82 & 62.68 & 61.83 & 58.20 & 63.71 & 65.05 \\ ID\({}^{3}\)-w/o-attribute & 97.12 & 85.57 & 81.70 & 87.50 & 89.48 & 88.27 \\ ID\({}^{3}\)-\([0.7,0.9]\) & 97.28 & 84.26 & 81.48 & 86.25 & 89.63 & 87.78 \\ ID\({}^{3}\)-\([0.5,0.7]\) & 97.38 & 85.00 & 81.10 & 86.63 & 90.13 & 88.05 \\ ID\({}^{3}\)-random & 96.00 & 80.81 & 78.05 & 85.53 & 87.57 & 85.59 \\
**ID\({}^{3}\) (Ours)** & **97.68** & **86.84** & **82.77** & **91.00** & **90.37** & **89.80** \\   

Table 2: Ablation Study. Face verification accuracy (%) of LResNet50-IR when trained on synthetic datasets from ID\({}^{3}\) and other model variants. ID\({}^{3}\)-\([lb,ub]\) represents an ID\({}^{3}\) variant using \(lb\) and \(ub\) as lower- and upper-bound for sampling \(_{ij}\)â€™s. ID\({}^{3}\)-random denotes a model variant that randomly sets anchors on the unit hypersphere for sample generation. ID\({}^{3}\)-w/o-attribute denotes one that does not use attributes as conditioning signals. ID\({}^{3}\)-w/o-reversed denotes one that removes the reversed likelihood score from Eq. (8) in the proposed ID-preserving sampling algorithm.