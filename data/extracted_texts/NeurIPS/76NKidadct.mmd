# Improved Particle Approximation Error for

Mean Field Neural Networks

Atsushi Nitanda

CFAR and IHPC, Agency for Science, Technology and Research (A\(\)STAR), Singapore

College of Computing and Data Science, Nanyang Technological University, Singapore

atsushi_nitanda@cfar.a-star.edu.sg

###### Abstract

Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized nonlinear convex functional defined over the space of probability distributions. MFLD has gained attention due to its connection with noisy gradient descent for mean-field two-layer neural networks. Unlike standard Langevin dynamics, the nonlinearity of the objective functional induces particle interactions, necessitating multiple particles to approximate the dynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzuki et al., 2023b) have demonstrated the _uniform-in-time propagation of chaos_ for MFLD, showing that the gap between the particle system and its mean-field limit uniformly shrinks over time as the number of particles increases. In this work, we improve the dependence on logarithmic Sobolev inequality (LSI) constants in their particle approximation errors which can exponentially deteriorate with the regularization coefficient. Specifically, we establish an LSI-constant-free particle approximation error concerning the objective gap by leveraging the problem structure in risk minimization. As the application, we demonstrate improved convergence of MFLD, sampling guarantee for the mean-field stationary distribution, and uniform-in-time Wasserstein propagation of chaos in terms of particle complexity.

## 1 Introduction

In this work, we consider the following entropy-regularized mean-field optimization problem:

\[()=F()+(),\] (1)

where \(F:_{2}(^{d})\) is a convex functional on the space of probability distributions \(_{2}(^{d})\) and \(()=(x)}{dx}(x)\) is a negative entropy. Especially we focus on the learning problem of mean-field neural networks, that is, \(F()\) is a risk of (infinitely wide) two-layer neural networks \(_{X}[h(X,)]\) where \(h(X,)\) represents a single neuron with parameter \(X\). One advantage of this problem is that the convexity of \(F\) with respect to \(\) can be leveraged to analyze gradient-based methods for a finite-size two-layer neural network: \(_{i=1}^{N}h(x^{i},)\) (\(x^{i}^{d}\)). This is achieved by translating the optimization dynamics of the finite-dimensional parameters \((x^{1},,x^{N})^{dN}\) into the dynamics of \(\) via the mean-field limit: \(_{i=1}^{N}_{x^{i}}(N)\). This connection was pointed out by Nitanda and Suzuki (2017); Mei et al. (2018); Chizat and Bach (2018); Rotskoff and Vanden-Eijnden (2022); Sirignano and Spiliopoulos (2020, 2020) in the case of \(=0\), and used for showing the global convergence of the gradient flow for (1) by Mei et al. (2018); Chizat and Bach (2018).

One may consider adding Gaussian noise to the gradient descent to make the method more stable. Then, we arrive at the following _mean-field Langevin dynamics_ (MFLD) (Hu et al., 2019; Mei et al., 2018) as a continuous-time representation under \(N=\) of this noisy gradient descent.

\[X_{t}=-)}{}(X_{t})t+ W_{t},\ \ \ _{t}=(X_{t}),\] (2)where \(\{W_{t}\}_{t 0}\) is the \(d\)-dimensional standard Brownian motion and \(\) is the Wasserstein gradient that is the gradient of the first-variation of \(F\). Even though several optimization methods (Nitanda et al., 2021; Oko et al., 2022; Chen et al., 2023) that can efficiently solve the above problem with polynomial computational complexity have been proposed, MFLD remains an interesting research subject because of the above connection to the noisy gradient descent. In fact, recent studies showed that MFLD globally converges to the optimal solution (Hu et al., 2019; Mei et al., 2018) thanks to noise perturbation and that its convergence rate is exponential in continuous-time under _uniform log-Sobolev inequality_(Nitanda et al., 2022; Chizat, 2022).

However, despite such remarkable progress, the above studies basically assume the mean-field limit: \(N=\). To analyze an implementable MFLD, we have to deal with discrete-time and finite-particle dynamics, i.e., noisy gradient descent:

\[X_{k+1}^{i}=X_{k}^{i}-_{k}})}{ }(X_{k}^{i})+_{k}^{i},\ \ \ (i\{1,,N\}),\] (3)

where \(_{k}^{i}(0,I_{d})\ (i\{1,,d\})\) are i.i.d. standard normal random variables and \(_{_{k}}=_{i=1}^{N}_{X_{k}^{i}}\) is an empirical measure. On the one hand, the convergence in the discrete-time setting has been proved by Nitanda et al. (2022) using the one-step interpolation argument for Langevin dynamics (Vempala and Wibisono, 2019). On the other hand, approximation error induced by using finite-particle system \(_{k}=(X_{k}^{1},,X_{N}^{N})\) has been studied in the literature of _propagation of chaos_(Sznitman, 1991). As for MFLD, Mei et al. (2018) suggested exponential blow-up of particle approximation error in time, but recent works (Chen et al., 2022; Suzuki et al., 2023) proved _uniform-in-time propagation of chaos_, saying that the gap between \(N\)-particle system and its mean-field limit shrinks uniformly in time as \(N\). Afterward, Suzuki et al. (2023) established truly quantitative convergence guarantees for (3) by integrating the techniques developed in Nitanda et al. (2022); Chen et al. (2022). Furthermore, Kook et al. (2024) proved the sampling guarantee for the mean-field stationary distribution: \(_{*}=_{_{2}(^{d})}()\), building upon the uniform-in-time propagation of chaos.

### Contributions

In this work, we further improve the particle approximation error (Chen et al., 2022; Suzuki et al., 2023) by alleviating the dependence on logarithmic Sobolev inequality (LSI) constants in their bounds. This improvement could exponentially reduce the required number of particles because LSI constant \(\) could exponentially deteriorate with the regularization coefficient, i.e., \((-(1/))\). Specifically, we establish an LSI-constant-free particle approximation error concerning the objective gap by leveraging the problem structure in risk minimization. Additionally, as the application, we demonstrate improved (i) convergence of MFLD, (ii) sampling guarantee for the mean-field stationary distribution \(_{*}\), and (iii) uniform-in-time Wasserstein propagation of chaos in terms of particle complexity. We summarize our contributions below.

* We demonstrate the particle approximation error \(O()\) (Theorem 1) regarding the objective gap. A significant difference from the existing approximation error \(O()\)(Chen et al., 2022; Suzuki et al., 2023) is that our bound is free from the LSI-constant. Therefore, the approximation error uniformly decreases as \(N\) regardless of the value of LSI-constant as well as \(\).
* As applications of Theorem 1, we derive the convergence rates of the finite-particle MFLDs (Theorem 2), sampling guarantee for \(_{*}\) (Corollary 1), and uniform-in-time Wasserstein propagation of chaos (Corollary 2) with the approximation errors inherited from Theorem 1, which improve upon existing errors (Chen et al., 2022; Suzuki et al., 2023; Kook et al., 2024).

Here, we mention the proof strategy of Theorem 1. Langevin dynamics (LD) is a special case of MFLD corresponding to the case where \(F\) is a linear functional. It is well known that even with a single particle, we can simulate LD and the particle converges to the target Gibbs distribution. This means that the particle approximation error is due to the non-linearity of \(F\). Therefore, in our analysis, we carefully treat the non-linearity of \(F\) and obtain an expression for the particle approximation error using the Bregman divergence induced by \(F\). Finally, we relate this divergence to the variance of an \(N\)-particle neural network and show the error of \(O(1/N)\). This proof strategy is quite different from existing ones and is simple. Moreover, it leads to an improved approximation error as mentioned above. We refer the readers to Section 4 for details about the proof.

### Notations

We denote vectors and random variables on \(^{d}\) by lowercase and uppercase letters such as \(x\) and \(X\), respectively, and boldface is used for \(N\)-pairs of them like \(=(x^{1},,x^{N})^{Nd}\) and \(=(X^{1},,X^{N})\). \(\|\|_{2}\) denotes the Euclidean norm. Let \(_{2}(^{d})\) be the set of probability distributions with finite second moment on \(^{d}\). For probability distributions \(,_{2}(^{d})\), we define Kullback-Leibler (KL) divergence (a.k.a. relative entropy) by \((\|)}}{{=}} (x)}{}(x)\). \(\) denotes the negative entropy: \(()=(x)}{x}(x)\). We denote by \(}{x}\) the density function of \(\) with respect to the Lebesgue measure if it exists. We denote \( f,m= f(x)m(x)\) for a (singed) measure \(m\) and integrable function \(f\) on \(^{d}\). Given \(=(x^{1},,x^{N})^{Nd}\), we write an empirical measure supported on \(\) as \(_{}=_{i=1}^{N}_{x^{i}}\).

## 2 Preliminaries

In this section, we explain a problem setting and give a brief overview of the recent progress of the mean-field Langevin dynamics.

### Problem setting

We say the functional \(G:_{2}(^{d})\) is differentiable when there exists a functional (referred to as a _first variation_): \(:\;_{2}(^{d})^ {d}(,x)(x)\) such that for \(,^{}_{2}(^{d})\),

\[.G(+(^{}-))}{} |_{=0}=(x)(^{}-)( x),\]

and say \(G\) is convex when for \(,^{}_{2}(^{d})\),

\[G(^{}) G()+(x)(^{ }-)(x).\] (4)

For a differentiable and convex functional \(F_{0}:_{2}(^{d})\) and coefficients \(,\;^{}>0\) we consider the minimization of an entropy-regularized convex functional (Mei et al., 2018; Hu et al., 2019; Nitanda et al., 2022; Chizat, 2022; Chen et al., 2022; Suzuki et al., 2023; Kook et al., 2024):

\[_{_{2}(^{d})}\{()=F_{0}( )+^{}_{X}[\|X\|_{2}^{2}]+( )\}.\] (5)

We set \(F()=F_{0}()+^{}_{}[\|X\|_{2}^{2}]\). Note both \(F\) and \(\) are convex functionals. In particular, we focus on the empirical risk \(F_{0}\) of the mean-field neural networks, i.e., two-layer neural networks in the mean-field regime. The definition of this model is given in Section 3. Throughout the paper, we assume the existence of the solution \(_{*}_{2}(^{d})\) of the problem (5) and make the following regularity assumption on the objective function, which is inherited from Chizat (2022); Nitanda et al. (2022); Chen et al. (2023).

**Assumption 1**.: _There exists \(M_{1},M_{2}>0\) such that for any \(_{2}(^{d})\), \(x^{d}\), \(|()}{}(x)| M_{1}\) and for any \(,^{}_{2}(^{d})\), \(x,x^{}^{d}\),_

\[\|()}{}(x)-( ^{})}{}(x^{})\|_{2} M_{2}(W_{2}(, ^{})+\|x-x^{}\|_{2}).\]

Then, under Assumption 1, \(_{*}\) uniquely exists and satisfies the optimality condition: \(_{*}(-)}{})\). We refer the readers to Chizat (2022); Hu et al. (2019); Mei et al. (2018) for details.

We introduce the _proximal Gibbs distribution_(Nitanda et al., 2022; Chizat, 2022), which plays a key role in showing the convergence of mean-field optimization methods (Nitanda et al., 2022; Chizat, 2022; Oko et al., 2022; Chen et al., 2023).

**Definition 1** (Proximal Gibbs distribution).: _For \(_{2}(^{d})\), the proximal Gibbs distribution \(\) associated with \(\) is defined as follows:_

\[}{x}(x)= (x))}{Z()},\] (6)

_where \(Z()\) is the normalization constant and \(/x\) is the density function w.r.t. Lebesgue measure._

We remark that \(\) exists, that is \(Z()<\), for any \(_{2}(^{d})\) because of the boundedness of \( F_{0}/\) in Assumption 1 and that the optimality condition for the problem (5) can be simply written using \(\) as follows: \(_{*}=_{*}\). Since the proximal Gibbs distribution \(\) minimizes the linear approximation of \(F\) at \(\): \(F()+()(x)(^{}-)(x) +(^{})\) with respect to \(^{}\), \(\) can be regarded as a surrogate of the solution \(_{*}\). In the case where \(F_{0}()\) is a linear functional: \(F_{0}()=_{}[f]\) (\( f:^{d}\)), the proximal Gibbs distribution \(\) coincides with \(_{*}\).

### Mean-field Langevin dynamics and finite-particle approximation

The mean field Langevin dynamics (MFLD) is one effective method for solving the problem (5). MFLD \(\{X_{t}\}_{t 0}\) is described by the following stochastic differential equation:

\[X_{t}=-(_{t})(X_{t})t+ W_{t},\ \ _{t}=(X_{t}),\] (7)

where \(\{W_{t}\}_{t 0}\) is the \(d\)-dimensional standard Brownian motion with \(W_{0}=0\). We refer the reader to Huang et al. (2021) for the existence of the unique solution of this equation under Assumption 1. Nitanda et al. (2022); Chizat (2022) showed the convergence of MFLD: \((_{t})-(_{*})(-2 t)((_{0})-(_{*}))\) under the _uniform log-Sobolev inequality (LSI)_:

**Assumption 2**.: _There exists a constant \(>0\) such that for any \(_{2}(^{d})\), proximal Gibbs distribution \(\) satisfies log-Sobolev inequality with \(\), that is, for any smooth function \(g:^{d}\),_

\[_{}[g^{2} g^{2}]-_{}[g^{2}] _{}[g^{2}]_{}[\|  g\|_{2}^{2}].\]

Because of the appearance of \(_{t}\) in the drift term, MFLD is a distribution-dependent dynamics referred to as general McKean-Vlasov (McKean Jr, 1966). This dependence makes the difference from the standard Langevin dynamics. Hence, we need multiple particles to approximately simulate MFLD (7) unlike the standard Langevin dynamics. We here introduce the finite-particle approximation of (7) described by the \(N\)-tuple of stochastic differential equation \(\{_{t}\}_{t 0}=\{(X_{t}^{1},,X_{t}^{N})\}_{t 0}\):

\[X_{t}^{i}=-_{t}})}{}(X_ {t}^{i})t+W_{t}^{i},\ \ \ (i\{1,,N\}),\] (8)

where \(_{_{t}}=_{i=1}^{N}_{X_{t}^{i}}\) is an empirical measure supported on \(_{t}\), \(\{W_{t}^{i}\}_{t 0},\ (i\{1,,N\})\) are independent standard Brownian motions, and the gradient in the first term in RHS is taken for the function: \(_{t}})}{}():^{d} \). We often denote \(F()=F(_{})\) when emphasizing \(F\) as a function of \(\). Noticing \(N_{x^{i}}F()=})}{ }(x^{i})\)(Chizat, 2022), we can identify the dynamics (8) as the Langevin dynamics \(_{t}=-N F(_{t})t+ _{t}\), where \(\{_{t}\}_{t 0}\) is the standard Brownian motion on \(^{dN}\), for sampling from the following Gibbs distribution \(_{*}^{(N)}\) on \(^{dN}\)(Chen et al., 2022):

\[_{*}^{(N)}}{}() (-F())=(-F_{0} ()-}{}\|\|_{2}^{2}).\] (9)

In other words, the dynamics (8) minimizes the entropy-regularized linear functional: \(^{(N)}_{2}(^{dN})\),

\[^{(N)}(^{(N)})=N_{^{(N)}}[F()]+(^{(N)}),\] (10)

and \(_{*}^{(N)}\) is the minimizer of \(^{(N)}\). Therefore, two objective functions \(\) and \(^{(N)}\) are tied together through the two aspects of the dynamics (8); one is the finite-particle approximation of the MFLD (7)for \(\) and the other is the optimization methods for \(^{(N)}\). We then expect \(^{(N)}(_{*}^{(N)})/N\) converges to \((_{*})\) as \(N\). Such finite-particle approximation error between \(^{(N)}(_{*}^{(N)})/N\) and \((_{*})\) has been studied in the literature of _propagation of chaos_. Especially, Chen et al. (2022) proved

\[(_{*}^{(N)}\|_{*}^{ N})^{(N)}(_{*}^{(N)})-(_{*})\] (11)

where \(C>0\) is some constant and \(_{*}^{ N}\) is an \(N\)-product measure of \(_{*}\). Suzuki et al. (2023b) further studied MFLD in finite-particle and discrete-time setting defined below: given \(k\)-th iteration \(_{k}=(X_{k}^{1},,X_{k}^{N})\),

\[X_{k+1}^{i}=X_{k}^{i}-_{k}})}{ }(X_{k}^{i})+_{k}^{i},\ \ \ (i\{1,,N\}),\] (12)

where \(_{k}^{i}(0,I_{d})\) (\(i\{1,,N\}\)) are i.i.d. standard normal random variables. By extending the proof techniques developed by Chen et al. (2022), Suzuki et al. (2023b) proved the uniform-in-time propagation of chaos for MFLD (12); there exist constants \(C_{1},C_{2}>0\) such that

\[^{(N)}(_{k}^{(N)})-(_{*})(^{(N)}(_{0}^{(N)})- (_{*}))+)C_{1}}{} +}{ N},\] (13)

where \(_{k}^{(N)}=(_{k})\). The last two terms are due to time-discretization and finite-particle approximation, respectively. The finite-particle approximation error \(O()\) appearing in (11), (13) means the deterioration as \( 0\). Considering typical estimation \((-(1/))\) (e.g., Theorem 1 in Suzuki et al. (2023b)) of LSI-constant using Holley and Stroock argument (Holley and Stroock, 1987) or Miclo's trick (Bardet et al., 2018), these bounds imply that the required number of particles increases exponentially as \( 0\).

## 3 Main results

In this section, we present an LSI-constant free particle approximation error between \(^{(N)}(_{*}^{(N)})\) and \((_{*})\) for mean-field neural networks and apply it to the mean-field Langevin dynamics.

### LSI-constant free particle approximation error for mean-field neural networks

We focus on the empirical risk minimization problem of mean-field neural networks. Let \(h(x,):\) be a function parameterized by \(x^{d}\), where \(\) is the data space. The mean-field model is obtained by integrating \(h(x,)\) with respect to the probability distribution \(_{2}(^{d})\) over the parameter space: \(h_{}()=_{X}[h(X,)]\). Typically, \(h\) is set as \(h(x,z)=(w^{}z)\) or \(h(x,z)=(v(w^{}z))\) where \(\) is an activation function and \(x=w\) or \(x=(v,w)\) is the trainable parameter in each case. Given training examples \(\{(z_{j},y_{j})\}_{j=1}^{n}\) and loss function \((,):\), we consider the empirical risk of the mean-field neural networks:

\[F_{0}()=_{j=1}^{n}(h_{}(z_{j}),y_{j}).\] (14)

For our analysis, we make the following assumption which is satisfied in the common settings.

**Assumption 3**.: \((,y)\) _is convex and L-smooth, and \(h(X,z)\)\((X_{*})\) has a finite-second moment;_

* _There exists_ \(L>0\) _such that for any_ \(a,b,y\)_,_ \((b,y)(a,y)+(b-a)+|b- a|^{2}\)_._
* _There exists_ \(R>0\) _such that for any_ \(z\)_,_ \(_{X_{*}}[|h(X,z)|^{2}] R^{2}\)_._

We can directly verify this assumption for mean-field neural networks using a bounded activation function (Nitanda et al., 2022; Chizat, 2022; Chen et al., 2022; Suzuki et al., 2023b) and standard loss functions such as logistic loss and squared loss. The following is the main theorem that bounds \(^{(N)}(_{*}^{(N)})-(_{*})\). The proof is deferred to Section 4 and Appendix A.1.

**Theorem 1**.: _Under Assumptions 1 and 3, it follows that_

\[(_{*}^{(N)}\|_{*}^{ N})^{(N)}(_{*}^{(N)})-(_{*})}{2N}.\] (15)A significant difference from the previous results (11), (13) with \(k\), and Kook et al. (2024) is that our bound is free from the LSI-constant. Therefore, the approximation error uniformly decreases as \(N\) at the same rate regardless of the value of LSI-constant as well as \(\).

As discussed in Section 4 later, the differences between \(^{(N)}(_{*}^{(N)})\) and \((_{*})\) is due to non-linearity of the loss \(\). In fact, since \(L=0\) for a linear loss function \(\), it follows that \(^{(N)}(_{*}^{(N)})=(_{*})\).

### Application: mean-field Langevin dynamics in the finite-particle setting

As an application of Theorem 1, we present the convergence analysis of the mean-field Langevin dynamics (MFLD) in the finite-particle settings (8) and (12), sampling guarantee for the mean-field stationary distribution \(_{*}_{2}(^{d})\), and uniform-in-time Wasserstein propagation of chaos.

#### 3.2.1 Convergence of the mean-field Langevin dynamics

Our convergence theory assumes the logarithmic Sobolev inequality (LSI) on \(_{*}^{(N)}\).

**Assumption 4**.: _There exists a constant \(>0\) such that \(_{*}^{(N)}\) satisfies log-Sobolev inequality with constant \(\), that is, for any smooth function \(g:^{dN}\), it follows that_

\[_{_{*}^{(N)}}[g^{2} g^{2}]-_{_{*}^{(N)}}[g^{2}] _{_{*}^{(N)}}[g^{2}]}_{ _{*}^{(N)}}[\| g\|_{2}^{2}].\]

By setting \(g=^{(N)}}{_{*}^{(N)}}}\), Assumption 4 leads to \((^{(N)}\|_{*}^{(N)})}_{ ^{(N)}}[\|^{(N)}}{_{*}^ {(N)}}\|_{2}^{2}]\). For instance, using Holley and Stroock argument (Holley and Stroock, 1987) under the boundedness assumption \(|F_{0}()| B\) (\(^{dN}\)), we can verify LSI on \(_{*}^{(N)}\) with a constant \(\) that satisfies: \(}(-}{})\). For the detail, see Appendix B.

The following theorem demonstrates the convergence rates of \(^{(N)}(^{(N)})\) with the finite-particle MFLD in the continuous- and discrete-time settings. The first assertion is a direct consequence of Theorem 1 and the standard argument based on LSI for continuous-time Langevin dynamics. Whereas for the second assertion, we employ the one-step interpolation argument (Vempala and Wibisono, 2019) with some refinement to avoid the dependence on the dimensionality \(dN\) where the dynamics (12) performs. The proof is given in Appendix A.2. We denote \(_{t}^{(N)}=(_{t})\) and \(_{k}^{(N)}=(_{k})\) for continuous- and discrete-time dynamics (8) and (12), respectively.

**Theorem 2**.: _Suppose Assumptions 1, 3, and 4 hold. Then, it follows that_

1. _MFLD (_8_) in finite-particle and continuous-time setting satisfies_ \[^{(N)}(_{t}^{(N)})-(_{*})}{2N}+(-2 t)(^{(N)}(_{ 0}^{(N)})-^{(N)}(_{*}^{(N)})),\]
2. _MFLD (_12_) with_ \(^{}<1/2\) _in finite-particle and discrete-time setting satisfies_ \[^{(N)}(_{k}^{(N)})-(_{*})}{2N}+^{(N)}}{2}+(-  k)(^{(N)}(_{0}^{(N)})- ^{(N)}(_{*}^{(N)})),\] \[_{}^{(N)}=16(M_{2}^{2}+^{ 2})(  M_{1}^{2}+ d)+64^{2}^{ 2}(M_{2}^{2}+^{ 2}) ([\|_{0}\|_{2}^{2}]}{N}+}(^{2}}{4^{}}+ d))\!.\]

The term of \(}{2N}\) is the particle approximation error inherited from Theorem 1. Again our result shows the LSI-constant independence particle approximation error for MFLD unlike existing results (Chen et al., 2022; Suzuki et al., 2023b) where their error bounds \(O()\) scale inversely with LSI-constant \(\) as seen in (11) and (13). Hence, the required number of particles to achieve \(\)-accurate optimization: \(^{(N)}(^{(N)})-(_{*})\) suggested by our result and Chen et al. (2022); Suzuki et al. (2023b) are \(N=O()\) and \(N=O()\), respectively. Whereas the iterations complexity of MFLD (12) is \(O(^{2}})\) which is same as that in Suzuki et al. (2023b) up to a difference in LSI constants \(\) or 

#### 3.2.2 Sampling guarantee for \(_{*}\)

After running the finite-particle MFLD with a sufficient number of particles for a long time, each particle is expected to be distributed approximately according to \(_{*}\). In Corollary 1, we justify this sampling procedure for \(_{*}\) as an application of Theorem 2. We set \(_{0}^{(N)}=^{(N)}(_{0}^{(N)})- ^{(N)}(_{*}^{(N)})\) and write the marginal distribution of \(_{t}^{(N)}/_{k}^{(N)}\) on the first particle \(x^{1}\) as \(_{t,1}^{(N)}/_{k,1}^{(N)}\).

**Corollary 1**.: _Under the same conditions as in Theorem 2, we run MFLDs (8) and (12) with i.i.d. initial particles \(=(X_{0}^{1},,X_{0}^{N})\). Then, it follows that_

1. _MFLD (_8_) in finite-particle and continuous-time setting satisfies_ \[(_{t,1}^{(N)}\|_{*})(_{t,1}^{(N)})- (_{*})}{2N}+(-2 t)_ {0}^{(N)},\]
2. _MFLD (_12_) with_ \(^{}<1/2\) _in finite-particle and discrete-time setting satisfies_ \[(_{k,1}^{(N)}\|_{*})(_{k,1}^{(N)})- (_{*})}{2N}+^{(N)}}{2}+(- k)_{0}^{(N)}.\]

Proof.: For any distribution \(^{(N)}_{2}(^{dN})\) whose marginal \(_{i}^{(N)}\) on \(i\)-th coordinate \(x^{i}\) (\(i\{1,,N\}\)) are identical to each other, it follows that by the convexity of the objective function and the entropy sandwich (Nitanda et al., 2022; Chizat, 2022): \((\|_{*})()-(_{*})\) (\(_{2}(^{d})\)),

\[(_{1}^{(N)}\|_{*})(_{1}^{(N)})- (_{*})^{(N)}(^{(N)})-( _{*}).\] (16)

Because of i.i.d. initialization, the distributions of \(_{t}^{(N)}/_{k}^{(N)}\) satisfies this property. That is, (16) with \(^{(N)}=_{t}^{(N)}/_{k}^{(N)}\) holds. Hence, Theorem 2 concludes the proof. 

Corollary 1 shows the convergence of the objective \(()\) and \(\)-divergence \((\|_{*})\) which attain the minimum value at \(=_{*}\). For instance, we can deduce that the particle and iteration complexities to obtain \((_{k,1}^{(N)}\|_{*})}<\) by MFLD (12) are \(O(})\) and \(O(^{2}^{2}^{2}})\), respectively, whereas Kook et al. (2024) proved the following particle and iteration complexities: \(O(})\) and \(O(^{2}^{2}})\).

#### 3.2.3 Uniform-in-time Wasserstein propagation of chaos

As another application of Theorem 2, we prove the uniform-in-time Wasserstein propagation of chaos for MFLDs (8) and (12), saying that the Wasserstein distance between finite-particle system and its mean-field limit shrinks uniformly in time as \(N\). For the mean-field limit of (8) in the continuous-time setting, we refer to (7). For the discrete-time setting (12), we define its mean-field limit as follows; let \(_{k}=(X_{k})\) be the distribution of the infinite-particle MFLD defined by

\[X_{k+1}=X_{k}-)}{}(X_{k})+_{k},\] (17)

where \(_{k}(0,I_{d})\). Now, the uniform-in-time Wasserstein propagation of chaos for MFLDs is given below. We set \(_{0}^{(N)}=^{(N)}(_{0}^{(N)})- ^{(N)}(_{*}^{(N)})\) and \(_{0}=(_{0})-(_{*})\).

**Corollary 2**.: _Suppose Assumptions 1, 2, 3, and 4 hold. Then, it follows that_

1. _discrepancy between continuous-time MFLDs (_7_) and (_8_) is uniformly bounded in time as follows:_ \[W_{2}^{2}(_{t}^{(N)},_{t}^{ N})(}{2N}+(-2 t)_{0}^{(N)}+ (-2 t)_{0}).\]
2. _discrepancy between discrete-time MFLDs (_17_) and (_12_) is uniformly bounded in time as follows:_ \[W_{2}^{2}(_{k}^{(N)},_{k}^{ N})(}{2N}+^{(N)}}{2 }+}{2}+(- k)_ {0}^{(N)}+(-2 k)_{0}),\] _where_ \(_{}=8(M_{2}^{2}+^{ 2})(2 M_{1}^{2}+2 d)+32^{2} ^{ 2}(M_{2}^{2}+^{ 2})([\|X_{0}\|_{2}^{2}]+ }(^{2}}{4^{}}+ d ))\)_._Proof.: We only prove the first assertion because the second can be proven similarly. We apply the triangle inequality to \(W_{2}\)-distance as follows:

\[W_{2}^{2}(_{t}^{(N)},_{t}^{ N}) 2(W_{2}^{2}(_{t}^{(N)}, _{*}^{ N})+W_{2}^{2}(_{*}^{ N},_{t}^{ N}))\]

Note that \(\) with the same constant is preserved under tensorization: \(_{*}_{*}^{ N}\). Then, by Taragland's inequality (Otto Villani, 2000), Proposition 1 with \(=_{*}\), and the entropy sandwich (Nitanda et al., 2022; Chizat, 2022): \((_{t}\|_{*})(_{t})-(_ {*})\), we get

\[W_{2}^{2}(_{t}^{(N)},_{*}^{ N}) (_{t}^{(N)}\|_{*}^{ N})(^{(N)}(_{t}^{(N)})-N(_{*})),\] \[W_{2}^{2}(_{*}^{ N},_{t}^{ N })=NW_{2}^{2}(_{*},_{t}) N(_{t}\|_ {*})((_{t})-(_{*})).\]

Applying the convergence rates of finite- and infinite-particle MFLDs (Theorem 2 and Nitanda et al. (2022)), we conclude the proof. For completeness, we include the auxiliary results used in the proof in Appendix B. 

Corollary 2 uniformly controls the gap between \(N\)-particle system \(_{t}^{(N)}/_{k}^{(N)}\) and its mean-field limit \(_{t}^{ N}/_{k}^{ N}\). Again this result shows an improved particle approximation error \(O()\) over \(O(N})\)(Chen et al., 2022; Suzuki et al., 2023b). Additionally, the propagation of chaos result in terms of TV-norm can be proven by using Pinsker's inequality instead of Talagrand's inequality in the proof. For the continuous-time MFLDs, we get

\[^{2}(_{t}^{(N)},_{t}^{ N})(}{2N}+(-2 t)_{0}^{(N)} +(-2 t)_{0}),\]

and TV-norm counterpart for the discrete-time can be derived siminary.

## 4 Proof outline and key results

In this section, we provide the proof sketch of Theorem 1. Our analysis carefully treats the non-linearity of \(F_{0}\) because the particle approximation errors, the gap between \(/_{*}\) and \(^{(N)}/_{*}^{(N)}\), come from this non-linearity. In fact if \(F_{0}\) is a linear functional: \(F_{0}()=_{}[f]\) (\( f:^{d}\)), then \(^{(N)}(^{(N)})=_{i=1}^{N}_{X^{i}_{i}^{(N)} }[f(X^{i})+^{}\|X^{i}\|_{2}^{2}]+(^{(N)}) _{i=1}^{N}(_{i}^{(N)})\), where \(_{i}^{(N)}\) are marginal distributions on \(X^{i}\). This results in \(_{*}^{(N)}=_{*}^{ N}\) and \(^{(N)}(_{*}^{(N)})=N(_{*})\), and thus there is no approximation error by using finite-particles as also deduced from Theorem 1 with \(L=0\). Therefore, we should take into account the non-linearity of \(F_{0}\) to tightly evaluate the gap between \(\) and \(^{(N)}\).

To do so, we define Bregman divergence based on \(F\) on \(_{2}(^{d})\) as follows; for any \(,\ ^{}_{2}(^{d})\),

\[B_{F}(,^{})=F()-F(^{})-)}{},-^{}.\] (18)

\(B_{F}\) measures the discrepancy between \(\) and \(^{}\) in light of the strength of the convexity. If \(F\) is linear with respect to the distribution, \(B_{F}=0\) clearly holds. By the convexity \(F\), we see \(B_{F}(,^{}) 0\). Moreover, we see the following relationship between \(_{*}^{(N)}\) and \(\) for any \(_{2}(^{d})\):

\[_{*}^{(N)}}{}() (-F())\] \[=(-(F()+,_{}-+B_{F}(_{ },))\] \[(-B_{F}(_{},) )_{i=1}^{N}(-(x^{i}))\] \[(-B_{F}(_{},) )^{ N}}{}().\] (19)The proximal Gibbs distribution \(\) has been introduced in Nitanda et al. (2022) as a proxy for the solution \(_{*}\) and it coincides with \(_{*}\) when \(F\) is a linear functional. The above equation (19) naturally reflects this property since it bridges the gap between \(_{*}^{(N)}\) and \(^{ N}\) using \(B_{F}\) and leads to \(_{*}^{(N)}=^{ N}\) for the linear functional \(F\).

Next, we provide key propositions whose proofs can be found in Appendix A. The following proposition expresses objective gaps \(^{(N)}(^{(N)})-N()\) and \(^{(N)}(^{(N)})-^{(N)}(^{ N})\) using only divergences.

**Proposition 1**.: _For \(_{2}(^{d})\) and \(^{(N)}_{2}(^{dN})\), we have_

\[^{(N)}(^{(N)})-N()=N_{ ^{(N)}}[B_{F}(_{},)]+ (^{(N)}\|^{ N})- N(\|),\] (20) \[^{(N)}(^{(N)})-^{(N)}(^{ N })=N B_{F}(_{},)(^{(N)}-^{ N})()+(^{(N)}\|^{ N}).\] (21)

The following proposition shows that the \(\)-divergence between \(_{*}^{(N)}\) and \(^{ N}\) can be upper-bounded by the Bregman divergence \(B_{F}\).

**Proposition 2**.: _For any \(_{2}(^{d})\), we have_

\[(_{*}^{(N)}\|^{ N}) B_{F}(_{},)(^{ N}-_{*}^{(N)}) ().\] (22)

By applying Eq. (22) to Eq. (20) with \(=_{*}\) and \(^{(N)}=_{*}^{(N)}\), we obtain an important inequality: \(^{(N)}(_{*}^{(N)})-N(_{*}) N_{ _{*}^{ N}}[B_{F}(_{},_{*})]\). Here, we give a finer result below.

**Theorem 3**.: _For the minimizes \(_{*}\) of \(\) and \(_{*}^{(N)}\) of \(^{(N)}\), it follows that_

\[(_{*}^{(N)}\|_{*}^{ N}) ^{(N)}(_{*}^{(N)})-N(_{*})\] \[^{(N)}(_{*}^{ N})-N(_{*})= N_{_{*}^{ N}}[B_{F}(_{}, _{*})].\]

Proof.: Proposition 1 with \(=_{*}\) and \(^{(N)}=_{*}^{(N)}\) lead to the following equalities:

\[^{(N)}(_{*}^{(N)})-N(_{*})=N_{_{*}^{(N)}}[B_{F}(_{},_{*})]+ (_{*}^{(N)}\|_{*}^{ N}),\] (23) \[^{(N)}(_{*}^{(N)})-^{(N)}(_{*}^{ N })=N B_{F}(_{},_{*})(_{*}^{(N)}-_{*}^{ N})( )+(_{*}^{(N)}\|_{*}^{ N}).\] (24)

The first inequality of the theorem is a direct consequence of Eq. (23) since \(B_{F} 0\). The second inequality results from \(^{(N)}(_{*}^{(N)})^{(N)}(_{*}^{ N})\). The last equality is obtained by subtracting Eq. (24) from Eq. (23). 

Intuitively, \(_{_{*}^{ N}}[B_{F}(_{}, _{*})]\) is small because the empirical distribution \(_{}\) (\(_{*}^{ N}\)) converges to \(_{*}\) by law of large numbers. Indeed, more simply, we can relate this term to the variance of an \(N\)-particle mean-field model \(h_{_{}}(z)\) (\(_{*}^{ N}\)), yielding a bound: \(_{_{*}^{ N}}[B_{F}(_{}, _{*})]}{2N}\) (see the proof of Theorem 1 in Appendix A). Then, we arrive at Theorem 1.

## Conclusion and Discussion

We provided an improved particle approximation error over Chen et al. (2022); Suzuki et al. (2023b) by alleviating the dependence on LSI constants in their bounds. Specifically, we established an LSI-constant-free particle approximation error concerning the objective gap. Additionally, we demonstrated improved convergence of MFLD, sampling guarantee for the mean-field stationary distribution \(_{*}\), and uniform-in-time Wasserstein propagation of chaos in terms of particle complexity.

A limitation of our result is that the iteration complexity still depends exponentially on the LSI constant. This hinders achieving polynomial complexity for MFLD. However, considering the difficulty of general non-convex optimization problems, this dependency may be unavoidable. Improving the iteration complexity for more specific problem settings is an important direction for future research.