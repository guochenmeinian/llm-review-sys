# Identification of Nonlinear Latent Hierarchical Models

Lingjing Kong

Carnegie Mellon University

Biwei Huang

University of California San Diego

Feng Xie

Beijing Technology and Business University

Eric Xing

Yuejie Chi

Carnegie Mellon University

Kun Zhang

###### Abstract

Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of causal structures and latent variables (up to invertible transformations) can be achieved under mild assumptions: on causal structures, we allow for multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we permit general nonlinearity and multi-dimensional continuous variables, alleviating existing work's parametric assumptions. Specifically, we first develop an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model. Leveraging this criterion, we show that _both causal structures and latent variables_ of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure. To the best of our knowledge, our work is the first to establish identifiability guarantees for both causal structures and latent variables in nonlinear latent hierarchical models.

## 1 Introduction

Classical causal structure learning algorithms often assume no latent confounders. However, it is usually impossible to enumerate and measure all task-related variables in real-world scenarios. Neglecting latent confounders may lead to spurious correlations among observed variables. Hence, much effort has been devoted to handling the confounding problem. For instance, Fast Casual Inference and its variants (Spirtes et al., 2000; Pearl, 2000; Colombo et al., 2012; Akbari et al., 2021) leverage conditional independence constraints to locate possible latent confounders and estimate causal structures among observed variables, assuming no causal relationships among latent variables. This line of approaches ends up with an equivalence class, which usually consists of many directed acyclic graphs (DAGs).

Later, several approaches have been proposed to tackle direct causal relations among latent variables with observational data. These approaches are built upon principles such as rank constraints (Silva et al., 2006; Kummerfeld and Ramsey, 2016; Huang et al., 2022), matrix decomposition (Chandrasekaran et al., 2011, 2012; Anandkumar et al., 2013), high-order moments (Shimizu et al., 2009; Cai et al., 2019; Xie et al., 2020; Adams et al., 2021; Chen et al., 2022), copula models (Cui et al., 2018), and mixture oracles (Kivva et al., 2021). Pearl (1988); Zhang (2004); Choi et al. (2011); Drton et al. (2017); Zhou et al. (2020); Huang et al. (2020) extend such approaches to handle tree structureswhere only one path is permitted between any pair of variables. Recently, Huang et al. (2022) propose to use rank-deficiency constraints to identify more general latent hierarchical structures. A common assumption behind these approaches is that either the causal relationships should be linear or the variables should be discrete. However, the linearity and discrete-variable assumptions are rather restrictive in real-world scenarios. Moreover, these approaches only focus on structure learning without identifying the latent variables and corresponding causal models. We defer a detailed literature review to Appendix A.

In this work, we identify the hierarchical graph structure and latent variables simultaneously for general nonlinear latent hierarchical causal models. Specifically, we first develop novel identifiability guarantees on a specific latent variable model which we refer to as the basis model (Figure 2). We then draw connections between the basis-model identifiability and the identification of nonlinear latent hierarchical models. Leveraging this connection, we develop an algorithm to localize and estimate latent variables and simultaneously learn causal structures underlying the entire system. We show the correctness of the proposed algorithm and thus obtain identifiability of both _latent hierarchical causal structures_ and _latent variables_ for nonlinear latent hierarchical models. In sum, our main contributions are as follows.

* Analogous to independence tests in PC algorithm (Spirtes et al., 2000) and rank-deficiency tests in Huang et al. (2022), we develop a novel identifiability theory (Theorem 3.2) as a fundamental criterion for locating and identifying latent variables in general nonlinear causal models.
* We show structure identification guarantees for latent hierarchical models admitting continuous multi-dimensional (c.f., one-dimensional and often discrete (Pearl, 1988; Choi et al., 2011; Huang et al., 2022; Xie et al., 2022)) variables, general nonlinear (c.f., linear (Pearl, 1988; Huang et al., 2022; Xie et al., 2022)) structural functions, and general graph structures (c.f., generalized trees (Pearl, 1988; Choi et al., 2011; Huang et al., 2022)).
* Under the same conditions, we provide identification guarantees for latent variables up to invertible transformations, which, to the best of our knowledge, is the first attempt in cases of nonlinear hierarchical models.
* We accompany our theory with an estimation method that can asymptotically identify the causal structure and latent variables for nonlinear latent hierarchical models and validate it on multiple synthetic and real-world datasets.

## 2 Nonlinear Latent Hierarchical Causal Models

In this section, we introduce notations and formally define the latent hierarchical causal model. We focus on causal models with directed acyclic graph (DAG) structures and denote the graph with \(\), which consists of the latent variable set \(:=\{_{1},,_{m}\}\), the observed variable set 1\(:=\{_{1},,_{n}\}\), and the edge set \(\). Each variable is a random vector comprising potentially multiple dimensions, i.e., \(_{i}^{d_{x_{i}}}\) and \(_{j}^{d_{z_{j}}}\), where \(d_{x_{i}}\) and \(d_{z_{j}}\) stand for the dimensionalities of \(_{i}\) and \(_{j}\), respectively. Both latent variables and observed variables are generated recursively by their latent parents:

\[_{i}=g_{x_{i}}((_{i}),_{ x_{i}})_{j}=g_{z_{j}}((_{j}),_{z_{j}}),\] (1)

Figure 1: **Examples of latent hierarchical graphs satisfying Conditions 2.4**. \(_{i}\) denotes observed variables and \(_{j}\) denotes latent variables. The node size represents the dimensionality of each variable. We note that our graph condition permits multiple paths between two latent variables (e.g., \(_{1}\) and \(_{4}\) in Figure 0(b)), thus more general than tree structures.

where \((_{j})\) represents all the parent variables of \(_{j}\) and \(_{z_{j}}\) represents the exogenous variable generating \(_{j}\). Identical definitions apply to those notations involving \(_{i}\). All exogenous variables \(_{x_{i}}\), \(_{z_{j}}\) are independent of each other and could also comprise multiple dimensions. We now define a general latent hierarchical causal model with a causal graph \(:=(,)\) in Definition 2.1.

**Definition 2.1** (Latent Hierarchical Causal Models).: The variable set \(\) consists of observed variable set \(\) and latent variable set \(\), and each variable is generated by Equation 1.

In light of the given definitions, we formally state the objectives of this work:

1. Structure identification: given observed variables \(\), we would like to recover the edge set \(\).
2. Latent-variable identification: given observed variables \(\), we would like to obtain a set of variables \(}:=\{}_{1},,}_{m}\}\) where for \(i[m]\), \(_{i}\) and \(}_{i}\) are identical up to an invertible mapping, i.e., \(}_{i}=h_{i}(_{i})\), where \(h_{i}\) is an invertible function. 2

Definition 2.1 gives a general class of latent hierarchical causal models. On the functional constraint, the general nonlinear function form (Equation 1) renders it highly challenging to identify either the graph structure or the latent variables. Prior work Pearl (1988); Choi et al. (2011); Xie et al. (2022); Huang et al. (2022) relies on either linear model conditions or discrete variable assumptions. In this work, we remove these constraints to address the general nonlinear case with continuous variables. On the structure constraint, identifying arbitrary causal structures is generally impossible with only observational data. For instance, tree-like structures are assumed in prior work (Pearl, 1988; Choi et al., 2011; Huang et al., 2022) for structural identifiability. In the following, we present relaxed structural conditions under which we show structural identifiability.

**Definition 2.2** (Pure Children).: \(_{i}\) is a pure child of another variable \(_{j}\), if \(_{j}\) is the only parent of \(_{i}\) in the graph, i.e., \((_{i})=\{_{j}\}\).

**Definition 2.3** (Siblings).: Variables \(_{i}\) and \(_{j}\) are siblings if \((_{i})(_{j})\).

**Condition 2.4** (Structural Conditions).:
1. _Each latent variable has at least 2 pure children._
2. _There are no directed paths between any two siblings._

Intuitively, Condition 2.4-i allows each latent variable to leave a footprint sufficient for identification. This excludes some fundamentally unidentifiable structures. For instance, if latent variables \(_{1}\) and \(_{2}\) share the same children \(\), i.e., \(_{1}\) and \(_{2}\), the two latent variables cannot be identified without further assumptions, while pure children would help in this case. The pure child assumption naturally holds in many applications with many directly measured variables, including psychometrics, image analysis, and natural languages. We require fewer pure children than prior work (Silva et al., 2006; Kummerfeld and Ramsey, 2016) and place no constraints on the number of neighboring variables as in prior work (Huang et al., 2022; Xie et al., 2022).

Condition 2.4-ii avoids potential triangle structures in the latent hierarchical model. Triangles present significant obstacles for identification - in a triangle structure formed by \(_{1}_{2}_{3}\) and \(_{1}_{3}\), it is difficult to discern how \(_{1}\) influences \(_{3}\) without functional constraints, as there are two directed paths between them. We defer the discussion of how to use our techniques to handle more general graphs that include triangles to Appendix C.1. Condition 2.4-ii is widely adopted in prior work, especially those on tree structures (Pearl, 1988; Choi et al., 2011; Drton et al., 2017) (which cannot handle multiple undirected paths between variables as we do) and more recent work (Huang et al., 2022). To the best of our knowledge, only Xie et al. (2022) manage to handle triangles in the latent hierarchical structure, which, however, heavily relies on strong assumptions on both the function class (linear functions), distribution (non-Gaussian), and structures (the existence of neighboring variables).

## 3 Identifiability of Nonlinear Latent Hierarchical Causal Models

This section presents the identifiability and identification procedure of causal structures and latent variables in nonlinear latent hierarchical causal models, from only observed variables. First, in Section 3.1, we introduce a latent variable model (i.e., the _basis model_ in Figure 2), whose identifiability

[MISSING_PAGE_FAIL:4]

[MISSING_PAGE_FAIL:5]

**Discussion on assumptions.** Assumption 3.3-ii corresponds to Assumption 3.1-i for the basis model. Intuitively, it states that the information in the system is preserved without unnecessary duplication. As far as we know, the existing literature on causal variable identification for nonlinear models (Hyvarinen et al., 2019; Khemakhem et al., 2020; Kong et al., 2022; Lyu et al., 2022; Yao et al., 2022) universally assumes the invertibility of such a mapping. Without this assumption, we cannot guarantee the identification of latent variables from observed variables in the nonlinear case.

Assumption 3.3-iii is an extension of Assumption 3.1-ii to the hierarchical case, with \(\) and \(_{}\) playing the role of \((_{1},_{2})\) and \(\) respectively.

Assumption 3.3-iv excludes degenerate cases where an edge connects components that do not influence each other. This is equivalent to the causal minimality and generally considered necessary for causal identification with observational data (Peters et al., 2017). For instance, we cannot distinguish \(Y:=f(X)+N_{Y}\) and \(Y:=c+N_{Y}\) if \(f\) is allowed to differ from constant \(c\) only outside \(X\)'s support. Further, when \(_{1}=\) is a pure child of a latent variable \(\), Condition 2.4-i ensures that \(_{2}:=_{}\{_{1}\}\) contains at least one pure child or descendant of \(\) to fulfill Assumption 3.1-iii.

**Implications on measurement causal models.** Despite being an intermediate step towards the global structure identification, Theorem 3.4 can be applied to a class of nonlinear measurement models 4 with arbitrary latent structures and identify all the latent variables. Then, the latent structures in the measurement model can be identified by performing existing causal discovery algorithms, such as the PC algorithm (Spirtes et al., 2001), on the identified latent variables. We leave the detailed presentation of this application as future work.

### Global Identifiability of Latent Hierarchical Causal Models

Equipped with the local identifiability (i.e., Theorem 3.4), the following theorem shows that _all_ causal structures and latent variables are identifiable in the hierarchical model.

**Theorem 3.5**.: _Under assumptions in Theorem 3.4, all latent variables \(\) in the hierarchical model can be identified up to one-to-one mappings, and the causal structure \(\) can also be identified._

**Comparison to prior work.** Theorem 3.5 handles general nonlinear cases, whereas prior work (Pearl, 1988; Choi et al., 2011; Huang et al., 2022; Xie et al., 2022) is limited to linear function or discrete latent variable conditions. Structure-wise, our identifiability results apply to latent structures with V-structures and certain triangle structures (see discussion in Appendix C.1) beyond generalized trees as studied in prior work (Choi et al., 2011; Pearl, 1988; Huang et al., 2022), require fewer pure children and no neighboring variables in comparison with (Xie et al., 2022; Huang et al., 2022), and can determine directions for each edge (c.f., Markov-equivalent classes in Huang et al. (2022)).

**Proof sketch with search procedures.** The proof can be found in Appendix B.3. In particular, we develop a concrete algorithm (i.e., Algorithm 1) and show that it can successfully identify the causal structure and latent variables asymptotically. We give a proof sketch of Theorem 3.4 below by navigating through Algorithm 1 and illustrate it with an example in Figure 3.

_Stage 1: identifying parents with the basis model_ (line 4-line 5). As shown in Theorem 3.4, the basis model can identify the latent parents of leaf-level variables in the hierarchy. In Figure 2(a), we can identify \(_{2}\) when applying the basis model with the assignment \(_{1}:=\{_{1}\}\) and \(_{2}:=_{1}\). Naturally, the basic idea of Algorithm 1 is to iteratively apply the basis model to the most recently

Figure 3: **Evolution of active set \(\) in Algorithm 1. We mark the active set \(\) with shaded gray circles before each iterations of Algorithm 1, with Figure 2(a), Figure 2(b), and Figure 2(c) corresponding to iteration 1, 2, and 3. Before iteration 1, \(\) is set to \(\) by default. At iteration 1, \(_{2}\), \(_{3}\), and \(_{4}\) can be estimated by the basis model; however, only \(_{4}\) can be updated into \(\). Otherwise, directed paths would be introduced by \(_{2}\) and \(_{3}\).**identified latent variables to further identify their parents, which is the purpose of Stage 1 (line 4-line 5). In Algorithm 1, we define as active set \(\) the set of variables to which we apply the basis model. For example, \(\) equals to \(\) in the first round (Figure 2(a)) and becomes \(\{_{1},_{2},_{3},_{4},_{7}, _{8},_{9}\}\) in the second round (Figure 2(b)).

_Stage 2: merging duplicate variables_ (line 6). As multiple variables in \(\) can share a parent, dictionary \(()\) may contain multiple variables that are one-to-one mappings to each other, which would obscure the true causal structure and increase the algorithm's complexity. Stage 2 (Line 6) detects such duplicates and represents them with one variable. In Figure 2(a), setting \(_{1}\) to any of \(_{1}\), \(_{2}\), and \(_{3}\) would yield an equivalent variable of \(_{2}\). We merge the three equivalents by randomly selecting one.

_Stage 3: detecting and merging super-variables_ (line 7 - line 9). Due to the potential existence of V-structures, variables in \(\) may have multiple parents and produce super-variables in \(\). For instance, at the second iteration of Algorithm 1 (i.e., Figure 2(b)), the basis model will be run on \(_{1}=_{4}\) and \(_{2}=\{_{1},_{2},_{3},_{7},_{8},_{9}\}\) and output a variable equivalent to the concatenation \((_{2},_{3})\). Leaving this super-variable untouched will be problematic, as we would generate a false causal structure \(}_{4}\) where \(}\) is the estimated super-variable \((_{2},_{3})\), rather than recognizing \(_{4}\) is the child of two already identified variables \(_{2}\) and \(_{3}\). Line 7 to line 9 detect such super-variables by testing whether each variable \(}\) in \(\) is equivalent to a union of other variables in \(\). If such a union \(}:=\{}_{1},,}_{m}\}\) exists, we will replace \(}\) with \(}\) in all its occurrences. In Figure 2(b), we would split the variable equivalent to \([_{2},_{3}]\) into variables of \(_{2}\) and \(_{3}\) individually. If \(}\) is tested to be a super-variable, i.e., it can perfectly predict another variable \(}^{}\) in \(\) and \(}^{}\) cannot predict \(}\) perfectly, and the equivalent union cannot be found, we will track \(}\) in line 9 to prevent it from being updated into \(\) at line 16.

_Stage 4: detecting and avoiding directed paths in \(\)_ (line 12-line 14). Ideally, we would like to repeat line 4 to line 9 until reaching the root of the hierarchical model. Unfortunately, such an approach can be problematic, as this would cause variables in active set \(\) to have directed edges among them, whereas Theorem 3.4 applies to leaf variable set \(\) which contains no directed edges. In Figure 2(a), \(\) would contain \(\{_{2},_{3},_{4}\}\), as each of these latent variables has pure observed children in \(\). However, due to direct paths within \(\), i.e., \(_{2}_{4}\) and \(_{3}_{4}\), we cannot directly substitute \(\) with \(\{_{2},_{3},_{4}\}\) in \(\). To resolve this dilemma, we proactively detect directed paths emerging with newly estimated variables and defer the local update of such estimated variables to eliminate direct paths. For directed path detection, we introduce a corollary of Theorem 3.4 as Corollary 3.6.

**Corollary 3.6**.: _Under assumptions in Theorem 3.4, for any \(()\) where \(\) is the active set in Algorithm 1, we consider \(_{1}:=\) and \(_{2}:=(())\) where \(()\) is a strict subset of \(\)'s children (i.e., when the active set \(\) contains at least one child of \(\)'s), estimating the basis model yields \(}\) equivalent to \(\) up to a one-to-one mapping._

Corollary 3.6 can be obtained by setting \(_{1}\) as an ancestor of \(_{2}\) and \(_{1}\) as a degenerate variable (i.e., a deterministic quantity) in Theorem 3.4. Leveraging Corollary 3.6, we can detect whether each newly identified latent variable in \(\) would introduce directed paths into \(\) if they were substituted in. If directed paths exist, the variable \(}\) would contain the same information as \(_{1}:=\), which prediction tests can evaluate. In this event, we will suppress the update of the \(\) at this iteration. That is, we still keep its children in \(\). This directed-path detection is conducted in lines 12- 14, after properly grouping variables that share children in lines 10- 11. As shown in Figure 2(b), \(_{2}\) and \(_{3}\) are not placed in \(\), even if they are found in the first iteration. This update only happens when \(_{4}\) has been placed in \(\) at the second iteration.

Generally, a latent variable enters \(\) only if all its children reside in \(\). We can show that \(\) contains all the information of unidentified latent variables - \(\) d-separates the latent variables that have not been placed in \(\) and those were in \(\) once. Equipped with such a procedure, we can identify the hierarchical model iteratively until completion. We discuss Algorithm 1's complexity in Appendix D.

## 4 Experimental Results

In this section, we present experiments to corroborate our theoretical results in Section 3. We start with the problem of recovering the basis model in Section 4.2, which is the foundation of the overall identifiability. In Section 4.3, we present experiments for hierarchical models on a synthetic dataset and two real-world datasets.

### Experimental Setup

**Synthetic data generation.** For the basis model (Figure 2), we sample \((,)\), \(_{1}(,)\), and \(_{2}(+,)\), where the dependence between \(\) and \(_{2}\) is implemented by randomly constructed matrix \(\) and bias \(\). We choose the true mixing function \(\) as a multilayer perceptron (MLP) with Leaky-ReLU activations and well-conditioned weights to facilitate invertibility. We apply element-wise \(\{z,0\}\) to \(\) before inputting \([,_{1}]\) to \(g_{1}\) and element-wise \(\{z,0\}\) to \(\) before inputting \([,_{2}]\) to \(g_{2}\), so that \(_{1}\) is generated by the positive elements of \(\) and \(_{2}\) is generated by the negative elements of \(\). This way, \(g_{1}\) and \(g_{2}\) are jointly invertible but not individually invertible. For latent hierarchical models (Figure 4), we sample each exogenous variable \(\) as \((,)\) and each endogenous variable \(\) is endowed with a distinct generating function \(g_{}\) parameterized by an MLP, i.e., \(=g_{}((),_{})\).

**Real-world datasets.** We adopt two real-world datasets with hierarchical generating processes, namely a personality dataset and a digit dataset. The personality dataset was curated through an interactive online personality test (Project, 2019). Participants were requested to provide a rating for each question on a five-point scale. Each question was designed to be associated with one of the five personality attributes, i.e., agreeableness, openness, conscientiousness, extraversion, and neuroticism. The corresponding answer scores are denoted as \(a_{i}\), \(o_{j}\), etc, as indicated in Figure 5. We use responses (around 19,500 for each question) to six questions for each of the five personality attributes. For the digit dataset, we construct a multi-view digit dataset from MNIST (Deng, 2012). We first randomly crop each image to obtain two intermediate views and then randomly rotate each of the intermediate views independently to obtain four views. This procedure gives rise to a latent structure similar to that in Figure 3(a). We feed images to a pretrained ResNet-44 (He et al., 2016) for dimensionality reduction (\(28 28 64\)) and run our algorithm on the produced features.

**Estimation models.** We implement the estimation model \((_{1},_{2},)\) following Equation 2, where \(\) can be seen as an encoder that transforms \((_{1},_{2})\) to the latent space and \((_{1},_{2})\) act as the decoders

Figure 4: **Evaluated hierarchical models. We denote the estimation \(R^{2}\) scores around corresponding latent variables. We can observe that all latent variables can be identified decently, justifying our theoretic results.**generating \(_{1}\) and \(_{2}\) respectively. We parameterize each module with an MLP with Leaky-ReLU activation. Training configurations can be found in Appendix E.

**Evaluation metrics.** Due to the block-wise nature of our identifiability results, we adopt the coefficient of determination \(R^{2}\) between the estimated variables \(}\) and the true variables \(\), where \(R^{2}=1\) suggests that the estimated variable \(}\) can perfectly capture the variation of the true variable \(\). We apply kernel regression with Gaussian kernel to estimate the nonlinear mapping. Such a protocol is employed in related work von Kugelgen et al. (2021); Kong et al. (2022). We repeat each experiment over at least \(3\) random seeds.

### Basis Model Identification

The results for the basis model are presented in Table 1 and Figure 9. We vary the number of components of each latent partition (\(d_{},d_{_{1}},d_{_{2}}\)). We can observe that the model with individual invertibility (as assumed in prior work (von Kugelgen et al., 2021; Lyu et al., 2022)) can only capture around half of the information in \(\), due to their assumption that both \(g_{1}\) and \(g_{2}\) are invertible, which is violated in this setup. In contrast, our estimation approach can largely recover the information of \(\) across a range of latent component dimensions, verifying our Theorem 3.2. Moreover, prior work (von Kugelgen et al., 2021) assumes \(g_{1}=g_{2}\), and therefore cannot be applicable when the dimensionalities of \(_{1}\) and \(_{2}\) differ (e.g., \(d_{s_{1}}=2\), \(d_{s_{2}}=3\)), hence the "NA" in the table. Figure 9 in Appendix E.2 shows scatter-plots of the true and the estimated components with \(d_{z}=d_{s_{1}}=d_{s_{2}}=2\). We can observe that components of \(\) and those of \(}\) are highly correlated, suggesting that the information of \(\) is indeed restored. In contrast, \(}\) contains very little information of \(_{1}\), consistent with our theory that a desirable disentanglement is attainable. Additional experiments on varying sample sizes can be found in Appendix E.2.

### Hierarchical Model Identification

**Synthetic data.** We present the evaluation of Algorithm 1 on latent hierarchical models in Figure 4, Table 2, and Table 4- 5 in Appendix E.3. In Figure 4, we can observe that all variables can be estimated decently despite a slight recovery loss from a lower to a higher level. Table 2 presents the pair-prediction scores within pairs of estimations while learning the V-structure model in Figure 3(b). We can observe that scores within the sibling pairs \((_{1},_{2})\) and \((_{4},_{5})\) are much higher than non-sibling pairs. Notably, the estimate from \(_{1}=_{3}\) can perform accurate prediction over other estimates, whereas the other estimates fail to capture it faithfully. This is consistent with Theorem 3.4: the basis model with \(_{1}=_{3}\) will output a variable equivalent to the concatenation of \(_{2}\) and \(_{3}\), explaining the asymmetric prediction performances. These results empirically corroborate Theorem 3.5.

**Personality dataset.** From Figure 5, we can observe that our nonlinear model can correctly cluster the variables associated with the same attribute together in the first level, which is consistent with the intentions of these questions. It suggests that conscientiousness, agreeableness, and neuroticism are closely related at the intermediate level, whereas extraversion and neuroticism are remotely related. Some observed variables are not shown in the figure, as they are not clustered with other variables, indicating that they are not closely related to the system. This may provide insights into questionnaire design.

  & \(d_{z}=d_{s_{1}}=d_{s_{2}}=2\) & \(d_{z}=d_{s_{1}}=2\), \(d_{s_{2}}=3\) & \(d_{z}=d_{s_{2}}=d_{s_{2}}=4\) & \(d_{s}=d_{s_{1}}=4\), \(d_{s_{2}}=6\) \\  Joint invertibility (Ours) & \(0.93 0.09\) & \(0.90 0.10\) & \(0.89 0.02\) & \(0.83 0.12\) \\ Individual invertibility & \(0.67 0.06\) & NA & \(0.67 0.09\) & NA \\ 

Table 1: **The basis model identifiability.** We show the identifiability for \(\) under various data dimensionalities \(d_{z}\), \(d_{s_{1}}\), and \(d_{s_{2}}\) for \(\), \(_{1}\), \(_{2}\). We compare our results with prior work that assumes both \(g_{1}\) and \(g_{2}\) are invertible individually. NA indicates that the model is not applicable when the dimensionalities of \(_{1}\) and \(_{2}\) differ. The results are averaged over \(30\) random seeds.

Figure 5: **The causal structure of the personality dataset learned by our method.** The Letter in each variable name indicates the personality attribute. Subscripts correspond to question indices. Some observed variables are not shown in the figure, as they are not clustered with other variables, suggesting their distant relation to the system.

**Digit dataset.** Figure 5(a) and Table 5(b) present the causal structure learned from the multi-view digit dataset. We can observe that we can automatically cluster the two views sharing more latent factors. This showcases that our theory and approach can handle high-dimensional variables, whereas prior causal structure learning work mostly assumes that all variables are one-dimensional.

## 5 Conclusion

In this work, we investigate the identifiability of causal structures and latent variables in nonlinear latent hierarchical models. We provide identifiability theory for both the causal structures and latent variables without assuming linearity/discreteness as in prior work (Pearl, 1988; Choi et al., 2011; Huang et al., 2022; Xie et al., 2022) while admitting structures more general than (generalized) latent trees (Pearl, 1988; Choi et al., 2011; Huang et al., 2022). Together with the theory, we devise an identification algorithm and validate it across multiple synthetic and real-world datasets.

We have shown that our algorithm yields informative results across various datasets. However, it is essential to acknowledge that its primary role is as a theoretical device for our identification proof. It may not be well-suited to large-scale datasets, e.g., ImageNet, due to its nature as a discrete search algorithm. In future research, we aim to integrate our theoretical insights into scalable continuous-optimization-based algorithms (Zheng et al., 2018) and deep learning. We believe that our work facilitates the understanding of the underlying structure of highly complex and high-dimensional datasets, which is the foundation for creating more interpretable, safer, and principled machine learning systems.

**Acknowledgment.** We thank anonymous reviewers for their constructive feedback. The work of LK and YC is supported in part by NSF under the grants CCF-1901199 and DMS-2134080. This project is also partially supported by NSF Grant 2229881, the National Institutes of Health (NIH) under Contract R01HL159805, a grant from Apple Inc., a grant from KDDI Research Inc., and generous gifts from Salesforce Inc., Microsoft Research, and Amazon Research.

   & \(_{1}\) & \(_{2}\) & \(_{3}\) & \(_{4}\) & \(_{5}\) \\  \(_{1}\) & \(\) & \( 0.000\) & \(0.53 0.01\) & \(0.57 0.002\) & \(0.55 0.003\) \\ \(_{2}\) & \( 0.006\) & \(\) & \(0.52 0.002\) & \(0.54 0.001\) & \(0.53 0.000\) \\ \(_{3}\) & \( 0.002\) & \( 0.002\) & \(\) & \( 0.001\) & \( 0.006\) \\ \(_{4}\) & \(0.57 0.001\) & \(0.54 0.002\) & \(0.55 0.003\) & \(\) & \( 0.003\) \\ \(_{5}\) & \(0.55 0.006\) & \(0.56 0.001\) & \(0.55 0.002\) & \( 0.003\) & \(\) \\  

Table 2: **Pairwise predictions among estimated variables in Figure 3(b). Each box \((,)\) shows the \(R^{2}\) score obtained applying the estimated variable produced by treating \(\) as \(_{1}\) to predict that produced by treating \(\) as \(_{1}\). We observe that the prediction scores within sibling pairs are noticeably higher than other pairs, suggesting a decent structure estimation. In particular, the estimate from \(_{1}=_{3}\) can predict other estimates accurately, whereas not the other way round, confirming our theory that \(_{1}=_{3}\) will recover the information of both \(_{2}\) and \(_{3}\). The results are averaged over \(30\) random seeds.**

Figure 6: **Multi-view digit dataset results. Figure 5(a): \((_{1},_{2})\) and \((_{3},_{4})\) form two clusters, as they share the aspect-ratio factor within the cluster while distinct in the rotation-angle factor. Table 5(b): each box \((,)\) shows the \(R^{2}\) score obtained by applying the estimated variable produced by treating one specific view \(\) as \(_{1}\) to predict the estimated variable produced by treating view \(\) as \(_{1}\).**