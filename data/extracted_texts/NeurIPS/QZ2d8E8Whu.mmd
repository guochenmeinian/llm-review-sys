# LLMDFA: Analyzing Dataflow in Code with

Large Language Models

 Chengpeng Wang\({}^{1}\), Wuqi Zhang\({}^{2}\), Zian Su\({}^{1}\), Xiangze Xu\({}^{1}\), Xiaoheng Xie\({}^{3}\), Xiangyu Zhang\({}^{1}\)

\({}^{1}\) Purdue University, \({}^{2}\) Hong Kong University of Science and Technology, \({}^{3}\) Ant Group

{wang6590, su284, xu1415, xyzhang}@purdue.edu

wuqi.zhang@connect.ust.hk, xiexie@antgroup.com

###### Abstract

Dataflow analysis is a fundamental code analysis technique that identifies dependencies between program values. Traditional approaches typically necessitate successful compilation and expert customization, hindering their applicability and usability for analyzing uncomplexing programs with evolving analysis needs in real-world scenarios. This paper presents LLMDFA, an LLM-powered compilation-free and customizable dataflow analysis framework. To address hallucinations for reliable results, we decompose the problem into several subtasks and introduce a series of novel strategies. Specifically, we leverage LLMs to synthesize code that outsources delicate reasoning to external expert tools, such as using a parsing library to extract program values of interest and invoking an automated theorem prover to validate path feasibility. Additionally, we adopt a few-shot chain-of-thought prompting to summarize dataflow facts in individual functions, aligning the LLMs with the program semantics of small code snippets to mitigate hallucinations. We evaluate LLMDFA on synthetic programs to detect three representative types of bugs and on real-world Android applications for customized bug detection. On average, LLMDFA achieves 87.10% precision and 80.77% recall, surpassing existing techniques with F1 score improvements of up to 0.35. We have open-sourced LLMDFA at https://github.com/chengpeng-wang/LLMDFA.

## 1 Introduction

Dataflow analysis is a formal method that identifies the dependence between values in a program . Its primary objective is to determine whether the value of a variable defined at a particular line, referred to as a _source_, affects the value of another variable used at a subsequent line, referred to as a _sink_. This crucial information offers valuable insights into various downstream applications, such as program optimization  and bug detection . In Figure 1, for example, we can regard the variable \(x\) at line 9 as a source and the divisors at lines 4, 11, and 14 as sinks and eventually detect a divide-by-zero (DBZ) bug at line 14. The intuition is that \(x\) at line 9 comes from user input and can be zero. If it can flow to the divisors, DBZ bugs may occur.

Despite decades of effort, current dataflow analysis techniques have drawbacks in terms of applicability and usability. First, many scenarios where dataflow analysis is needed involve incomplete and uncompilable programs, e.g., on-the-fly code flaw analysis in Integrated Development

Figure 1: An example of DBZ bugEnvironments (IDEs). However, current techniques typically rely on intermediate representations (IRs) generated by compiler frontends, such as LLVM IR  produced by the Clang compiler, as shown in Figure 2(a). This reliance limits their applicability in analyzing incomplete programs, leading to the failure of analysis. Second, specific downstream tasks require customizing the analysis to fit specific needs, such as the detection of a specific bug type. In the DBZ detection, for example, the user has to extract variables potentially assigned with zero (sources) and variables used as the divisors (sinks). It is a challenging task for non-experts since they need a deep understanding of program representation (e.g., LLVM IR) for customization. This limitation hinders the usability of classical approaches to address evolving software analysis needs in real-world scenarios .

In the past year, there has been a vast proliferation of software engineering applications built upon large language models (LLMs), from which we observe the exceptional performance of LLMs in comprehending code snippets [7; 8; 9; 10]. Specifically, by treating LLMs as code interpreters and devising appropriate prompts, we can directly obtain semantic properties from source code. For instance, by constructing a prompt like "_Does the value of the variable \(z\) used at line 13 depend on the value of variable \(x\) defined at line 97_", we can ascertain the dataflow fact between the two program values. Likewise, we can leverage LLMs to automate the extraction of specific sources and sinks by describing their characteristics as prompts. This empowers developers to tailor dataflow analysis to their specific requirements. As shown in Figure 2(b), such LLM-powered dataflow analysis gets rid of compilation and avoids complicated customization. In the rest of this paper, our demonstration is consistently within the context of a downstream task, and our references to sources and sinks specifically pertain to that task.

However, instantiating dataflow analysis using LLMs is far from trivial, as their hallucinations [11; 12; 13] threaten the reliability of results. First, the misidentification of sources and sinks leads to dataflow facts that are irrelevant to the user's interest, directly resulting in incorrect results of dataflow analysis. Second, sources and sinks can be distributed across multiple functions, entailing analyzing a large body of code that likely exceeds the input context limit. In addition, incorrect dataflow facts in single functions can accumulate and magnify, thereby impacting the overall performance. Third, the validity of a dataflow fact depends on the feasibility of the program path inducing the dataflow fact. If the path condition is deemed unsatisfiable, no concrete execution will occur along that path . Regrettably, deciding the satisfiability of a logical constraint is a complex reasoning task that LLMs cannot effectively solve . In Figure 1, for example, gpt-3.5-turbo-0125 reports a DBZ bug at line 4 as a false positive because it cannot discover the unsatisfiable branch condition at line 3.

This paper presents LLMDFA, an LLM-powered compilation-free and customizable dataflow analysis. To mitigate hallucination, we decompose the analysis into three sub-problems, namely source/sink extraction, dataflow summarization, and path feasibility validation, which target more manageable tasks or smaller-sized programs. Technically, we introduce two innovative designs to solve the three sub-problems. First, instead of directly prompting LLMs, we leverage LLMs as code synthesizers to delegate the analysis to external expert tools like parsing libraries and SMT solvers , which effectively mitigates the hallucinations in the source/sink extraction and path feasibility validation. Second, we employ a few-shot chain-of-thought (CoT) prompting strategy  to make LLMs aligned with program semantics, which enables LLMDFA to overcome the hallucination in summarizing dataflow facts of single functions. Compared to traditional dataflow analysis, LLMDFA offers distinct advantages in terms of applicability and autonomy. It can be applied to incomplete programs, including those in the development phase. Additionally, it can autonomously create and utilize new tools with minimal human intervention, requiring no particular expertise in customizing dataflow analysis.

We evaluate LLMDFA in the context of bug detection. Specifically, we choose Divide-by-Zero (DBZ), Cross-Site-Scripting (XSS)1, and OS Command Injection (OSCI)2 in Juliet Test Suite 

Figure 2: Two different paradigms of dataflow analysis

for the evaluation. LLMDFA achieves high precision and recall when using different LLMs. For example, equipped with gpt-3.5-turbo-0125, it obtains 73.75%/100.0%/100.0% precision and 92.16%/92.31%/78.38% recall in the DBZ/XSS/OSCI detection. LLMDFA substantially outperforms a classic dataflow analyzer CodeFuseQuery  and an end-to-end solution based on few-shot CoT prompting, improving the average F1 score by 0.23 and 0.36, respectively. Besides, we evaluate LLMDFA upon real-world Android malware applications in TaitBench  and achieve 74.63% precision and 60.24% recall. It surpasses the two baselines with improvements in the F1 score of 0.12 and 0.35, respectively. To the best of our knowledge, LLMDFA is the first trial that leverages LLMs to achieve compilation-free and customizable dataflow analysis. It offers valuable insights into future works in analyzing programs using LLMs, such as program verification [20; 10] and repair .

## 2 Preliminaries and Problem Formulation

**Definition 1**.: (**Control Flow Graph**) The control flow graph (CFG) of a given program \(P\) is a labeled directed graph \(G:=(S,E_{})\). Here, \(s S\) is a statement in the program. For any \((s,s^{}) S S\), \(E_{}(s,s^{})\) is the boolean expression under which that \(s^{}\) is executed just after \(s\).

Figure 3 shows a (partial) CFG of the program in Figure 1. It depicts several important program facts, such as individual branch conditions and caller-collee relation. To simplify formulation, we introduce \(V^{f}_{par}\), \(V^{f}_{ret}\), \(V^{f}_{atg}\), and \(V^{f}_{out}\) that contain parameters (of the function), return values, arguments (passed to invoked functions), and output values in a function \(f\), respectively, which can be easily derived from CFG. Two dashed boxes in Figure 3 show the assignments from arguments to parameters and from the return value to the output value. Based on CFG, we can examine how a program value propagates via _dataflow facts_.

**Definition 2**.: (**Dataflow Fact**) There is a dataflow fact from the variable \(a\) at line \(m\) to the variable \(b\) at \(b\) at line \(n\), denoted by \(a@_{m} b@_{n}\), if the value of \(a\) can affect the value of \(b\).

In Figure 1, the variable \(z\) is assigned with the value of the variable \(x\) at line 12 and used as the second argument at line 13. Hence, we have \(x@_{9} x@_{12}\), \(z@_{12} z@_{13}\), and \(x@_{9} z@_{13}\). Dataflow facts are crucial for many downstream tasks, such as bug detection  and program slicing . Specifically, sensitive information leakage, which may cause XSS bugs , can be detected by identifying dataflow facts from sensitive data to leaked data. For other bug types, additional restrictions may be imposed on dataflow facts. In the DBZ detection, for example, we constrain that a dataflow fact connects two equal values.

The execution of a statement \(s\) can be guarded by a condition. A precise analysis should be _path sensitive_, i.e., validating the feasibility of a fact-inducing path according to the _path condition_.

**Definition 3**.: (**Path Condition**) The path condition of a program path \(p:=s_{i_{1}}s_{i_{2}} s_{i_{n}}\) is \((p)=_{1 j n-1}E_{}(s_{i_{j}},s_{i_{j+1}})\), where \(s_{i_{j}}\) is the statement at line \(i_{j}\) and can be executed just before \(s_{i_{j+1}}\).

We have the dataflow fact \(x@_{9} b@_{4}\) in Figure 1. However, the statement at line 4 is guarded by Math.abs(b) \(>0\). It is evaluated to be false as the parameter \(b\) is passed with 0. Hence, the dataflow fact \(x@_{9} b@_{4}\) cannot occur in any concrete execution. A path-insensitive analysis would introduce a false positive at line 4 in the DBZ detection.

**Our Problem.** In real-world downstream applications, dataflow analysis focuses on the dataflow facts between specific kinds of variables referred to as _sources_ and _sinks_. In the DBZ detection , for example, we need to identify the variables that could potentially yield zero values as sources and set the divisors as sinks. Lastly, we formulate the **dataflow analysis problem** as follows.

Given the source code of a program \(P\) and its CFG \(G\), identify the dataflow facts from user-specified sources \(v_{src} V_{src}\) and sinks \(v_{sink} V_{sink}\) in a path-sensitive manner.

As demonstrated in Section 1, existing dataflow analysis techniques [23; 24; 4] heavily rely on compilation and pose the difficulty of customization, which hinders their applicability and usability . Although several machine learning-based bug detection techniques [25; 26] enable compilation-free analysis, they cannot answer a general dataflow analysis question formulated above and struggle to support the customization for different bug types without a large training dataset. To fill the research

Figure 3: An example of CFG

gap, we aim to propose a new paradigm of dataflow analysis in this work. Specifically, we realize the exceptional performance of LLMs in program comprehension [27; 28], highlighting the potential for identifying dataflow facts. Besides, LLMs demonstrate a strong capability of understanding natural language [29; 30], and thus, can effectively comprehend the developers' intents based on natural language descriptions that specify sources and sinks. Moreover, LLMs posses remarkable program synthesis capabilities that facilitate the synthesis of tools invoking external experts to tackle domain-specific problems. Inspired by these observations, we attempt to instantiate dataflow analysis without laborious compilation steps and intricate customization procedures by harnessing the power of LLMs and domain-specific experts.

## 3 Method

We propose LLMDFA, a compilation-free and customizable dataflow analysis, which takes a program and its CFG as input. To resolve hallucinations, we split the analysis into three phases in Figure 4.

* **Source/Sink Extraction:** For a dataflow analysis application, such as DBZ detection, LLMDFA first extracts sources and sinks, which are the start and end points of dataflow facts of our interests.
* **Dataflow Summarization:** Based on the extracted sources (\(V_{src}^{f}\)) and sinks (\(V_{sink}^{f}\)) of a given function \(f\), LLMDFA identifies the dataflow facts from \(v V_{src}^{f} V_{par}^{f} V_{out}^{f}\) to \(v^{} V_{sink}^{f} V_{arg}^{f} V_{ret}^{f}\) as summaries, which form inter-procedural dataflow paths from sources to sinks.
* **Path feasibility Validation:** For each dataflow path from sources to sinks, LLMDFA collects its path condition and validates path feasibility, eventually reporting bugs induced by feasible paths.

The rest of this section demonstrates the detailed technical designs in the three phases.

### Phase I: Source/Sink Extraction

Extracting sources and sinks is non-trivial with LLMs. First, querying LLMs whether each line contains sources or sinks is expensive. Second, the hallucinations of LLMs may induce incorrect sources and sinks. To tackle these issues, we utilize LLMs to synthesize script programs using parsing libraries as sources/sink extractors. By traversing the abstract syntax tree (AST) of a given program, script programs can identify sources/sinks at a low cost, yielding deterministic and explainable results.

As shown in the left part of Figure 4, the synthesis requires a specification \(\) depicting sources/sinks, example programs \(_{spec}\) with sources/sinks, and their ASTs \(\). Given a phase description \(_{1}\), an extractor \(_{E}:=_{E}^{(t)}\) is generated by the conditional probability \(p_{}\) after a specific number of fixes:

\[_{E}^{(0)} p_{}(_{1},\ ,\ _{spec},\ )\] (1) \[_{E}^{(i)} p_{}(_{1},\ ,\ _{ spec},\ ,\ ^{(i-1)}),\ \ 1 i t\] (2) \[(_{E}^{(i)},\ _{spec})=_{\{t\}}(i),\ \ 0 i t\] (3)

Here \(_{\{t\}}(i)\) checks whether \(i\) is equal to \(t\). \((_{E}^{(i)},_{spec})=1\) if and only if the script synthesized in the \(i\)-th round identifies sources and sinks in \(_{spec}\) with no false positives or negatives. As formulated by Equations (1)\(\)(3), LLMDFA iteratively fixes a script, utilizing the execution result (denoted by \(^{(i-1)}\)) of the script synthesized in the previous round, until the newly synthesized one correctly identifies sources and sinks in the example programs. Notably, our extractor synthesis is a one-time effort. The synthesized extractors can be reused when analyzing different functions. As an example, Figure 12 in Appendix A.2.3 shows an example program with sources/sinks and the synthesized sink extractor for DBZ detection. The code highlighted in grey is generated by LLMs, while the rest is the skeleton provided manually. We also list our prompt template in Figure 9 of Appendix A.2.2.

Figure 4: The workflow of LLMDFA consists of three phases

### Phase II: Dataflow Summarization

We realize that an inter-procedural dataflow fact is the concatenation of multiple intra-procedural dataflow facts from \(v V_{src}^{f} V_{par}^{f} V_{out}^{f}\) to \(v^{} V_{sink}^{f} V_{org}^{f} V_{ret}^{f}\) in single functions \(f\). By identifying intra-procedural dataflow facts as function summaries, we can significantly reduce the prompt length. Besides, a summary can be induced by one or more operations with specific patterns, such as direct uses and assignments. For example, the summary \(x@_{9} z@_{13}\) in Figure 5 is introduced by the assignment at line 12 and the direct use of the variable \(z\) at line 13. Offering few-shot examples with detailed explanations would expose typical patterns of dataflow facts that form function summaries, which can align LLMs with program semantics, prompting their ability in dataflow summarization.

Based on the insight, we introduce a few-shot CoT prompting to facilitate the dataflow summarization, which corresponds to the middle part of Figure 4. Given a phase description \(_{2}\) and a list of examples with explanations \(_{flow}\), the response can be generated by the conditional probability:

\[r p_{}(_{2},\ _{flow},\ v,\ v^{}, \ P)\] (4)

where \(v V_{src}^{f} V_{par}^{f} V_{out}^{f}\), \(v^{} V_{sink}^{f} V_{org}^{f} V_{ret}^{f}\), and \(P\) is the program under the analysis. Based on the response \(r\), we can determine the existence of the dataflow fact between \(v\) and \(v^{}\). Concretely, we construct the prompt according to the template shown in Figure 10 of Appendix A.2.2. Particularly, the examples cover the typical patterns of dataflow facts, and meanwhile, the explanations depict reasoning process in detail. Both designs are pretty crucial for the few-shot CoT prompting. Lastly, we ask LLMs to reason step by step and offer an explanation along with the Yes/No answer.

Consider \(x@_{9}\) and \(z@_{13}\) in Figure 1. As shown in Figure 5, LLMDFA discovers intermediate program values, i.e., \(x@_{12}\) and \(z@_{12}\), and eventually obtains the dataflow fact \(x@_{9} z@_{13}\)step by step. Hence, the strategy of few-shot CoT prompting helps LLMs to better align with program semantics, significantly reducing hallucination in reasoning dataflow facts within single functions.

### Phase III: Path Feasibility Validation

Validating path feasibility is a complicated reasoning task that involves determining the satisfiability of a path condition. Although LLMs cannot achieve adequate performance in complex reasoning tasks , several off-the-shelf domain-specific experts, such as SMT solvers, can be utilized by LLMs. For example, the Python binding of Z3 solver  enables us to solve constraints in Python code. Hence, we propose to synthesize a Python script program that encodes and solves path conditions according to path information. Decoupling constraint solving from path condition collection can substantially mitigate the hallucination in path feasibility validation.

The right part of Figure 4 shows the workflow of the path feasibility validation. Based on the dataflow facts stitched from summaries, LLMDFA first leverages a parser to extract the path information, such as the branches exercised by the program path and the branch conditions. Notably, the parser receives the program lines appearing in the summaries as inputs and does not need to be reimplemented for different forms of sources and sinks. Based on the derived path info \(\) and the phase description \(_{3}\), a script program \(_{V}:=_{V}^{(t)}\) is eventually generated after a specific number of fixes as follows:

\[_{V}^{(0)} p_{}(_{3},\ )\] (5) \[_{V}^{(i)} p_{}(_{3},\ ,\ err^{(i-1)}),\ \ 1 i t\] (6) \[err^{(t)}=,\ err^{(i)},\ 0 i(t-1)\] (7)

Particularly, we utilize the error message of executing the script synthesized in a previous round (\((i-1)\)-th round), denoted by \(err^{(i-1)}\), and feed it to LLMs to conduct the fixing in the \(i\)-th round. Concretely, we design the prompt template shown by Figure 11 in Appendix A.2.2. It should be noted that the synthesis process has to be repeated for each source-sink pair, which is different from the one-time effort paid in the extractor synthesis. Consider \(x@_{9} b@_{4}\) in Figure 1. We offer the branch condition Math.abs(b) > 1 and other path information in a prompt and obtain a script in Figure 6. To ease the synthesis, we offer

Figure 5: A summary discovered via CoT in prompt:

Figure 6: A script invoking Z3 solver

[MISSING_PAGE_FAIL:6]

have to make laborious efforts to examine thousands of program paths. To simplify examination, we choose 37 programs for each bug type to measure the performance of the last two phases, as other programs only differ from the selected ones in terms of sources and sinks.

**Result.** As shown in Table 1, LLMDFA achieves high performance in each phase and the overall detection when it is powered with different LLMs. Equipped with gpt-3.5, for example, it achieves the precision of 73.75%/100%/100%, the recall of 92.16%/92.31%/78.38%, and the F1 score of 0.82/0.96/0.88, in the DBZ/XSS/OSCI detection. Besides, LLMDFA synthesizes all the source/sink extractors successfully for the three bug types. In the DBZ/XSS/OSCI detection, the dataflow summarization achieves 90.95%/86.52%/89.57 precision and 97.57%/96.25%/85.76% recall, and meanwhile, the path feasibility validation achieves 81.58%/100.00%/100.00% precision and 99.20%/100.00%/97.14% recall. When utilizing other LLMs, LLMDFA achieves the precision and recall comparable to those obtained using gpt-3.5. While the precision of the DBZ detection powered by gemini-1.0 is slightly lower at 66.57% than other LLMs, the performance remains satisfactory, exhibiting superiority over the baselines in Section 4.3. LLMDFA successfully synthesizes the extractors and script programs encoding path conditions with only a few iterations, which is demonstrated in Appendix A.3.1 and A.3.2. Lastly, it is found that the average financial costs of the DBZ, XSS, and OSCI detection are 0.14 USD, 0.05 USD, and 0.04 USD, respectively. Such a cost is in line with works of a similar nature, such as , which takes 0.42 USD to repair a bug. Notably, the extractor synthesis is one-time for a given bug type. Hence, the financial cost of the detection in practice is even lower. Overall, the statistics show the generality, effectiveness, and efficiency of LLMDFA in detecting dataflow-related bugs.

### Comparison with Baselines

**Classical Dataflow Analysis.** We choose two industrial static analyzers, namely CodeFuseQuery  and Pinpoint , for comparison. Specifically, CodeFuseQuery does not depend on any compilation process and derives dataflow facts from the ASTs of programs, while Pinpoint requires the compilation and takes as input the LLVM IR generated by a compiler. As shown by Figure 7, CodeFuseQuery achieves 29.41%/92.26%/87.46% precision, 81.08%/79.67%/54.05% recall, and 0.43/0.86/0.67 F1 score in detecting the DBZ/XSS/OSCI bugs. The low precision of the DBZ detection is attributed to its path-insensitive analysis. The low recall of CodeFuseQuery is caused by the lack of the support of analyzing complex program constructs. For example, the inability to analyze global variables causes missing dataflow facts, which causes more false negatives.

Besides, Pinpoint obtains 93.78%/100.00%/100.00% precision, 63.19%/47.49%/31.35% recall, and 0.76/0.64/0.48 F1 score in the detection of DBZ/XSS/OSCI bugs. Due to the lack of comprehensive modeling and customized support for source and sink, Pinpoint misses a large number of buggy dataflow paths, which eventually result in low recall. Although it achieves a high precision of 93.78% in DBZ detection, LLMDFA demonstrates superior capabilities in detecting DBZ bugs, delivering not only satisfactory precision but also significantly higher recall and F1 scores.

**LLM-based End-to-End Analysis.** We adopt few-shot CoT prompting to detect the DBZ, XSS, and OSCI bugs. Specifically, we construct few-shot examples to cover all the forms of sources and sinks, and meanwhile, explain the origin of a bug step by step. Figure 7 shows the performance comparison when using gpt-3.5. LLMDFA exhibits superiority over LLM-based end-to-end analysis in detecting three kinds of bugs. Although the recall of LLMDFA is slightly lower than the baseline in the OSCI detection, the precision of the former is much higher than the latter. We obtain the same findings

Figure 7: The comparison of LLMDFA, CodeFuseQuery, Pinpoint, and LLM-based end-to-end analysis. LLMDFA and LLM-based end-to-end analysis are powered with gpt-3.5

from the results of the analysis powered by the other three LLMs, which are shown by Figure 14 in Appendix A.3.3. In Appendix A.4.1, we offer typical cases where the LLM-based end-to-end analysis identifies wrong dataflow facts due to hallucinations.

### Ablation Studies

**Setup and Metrics.** We introduce three ablations, namely NoSynExt, NoCoT, and NoSynVal  and measure their performance in detecting the DBZ, XSS, and OSCI bugs. Specifically, NoSynExt directly leverages LLMs to extract sources and sinks. NoCoT provides the descriptions of dataflow facts in prompts and summarizes dataflow facts without few-shot CoT prompting.NoSynVal validates path feasibility with LLMs directly without synthesizing programs invoking SMT solvers.

**Result.** Figure 8 shows the comparison results of the ablations using gpt-3.5. First, LLMDFA has an overwhelming superiority over NoSynExt and NoCoT. Although NoCoT achieves 86.8% precision while LLMDFA obtains 73.7% precision in the DBZ detection, LLMDFA has much larger recall and F1 score than NoCoT. The key reason is that NoCoT is unable to identify complex dataflow facts, which causes the low recall of NoCoT. Second, NoSynExt introduces false positives in many cases because of the low precision of source/sink extraction in both the DBZ, XSS, and OSCI detection. Third, it should be noted that LLMDFA does not show significant superiority over NoSynVal in the XSS and OSCI detection because the corresponding benchmark programs do not contain any XSS or OSCI bug-inducing infeasible paths. Also, LLMDFA may encode the path condition incorrectly and accept the infeasible path, eventually causing false positives. As shown by Figure 15 in Appendix A.3.4, We can obtain similar findings when using other three LLMs. Although the precisions vary among different LLMs and bug types, LLMDFA is always superior to the ablations, demonstrating its effectiveness in mitigating the hallucinations in LLM-powered dataflow analysis. We also offer several examples of mitigated hallucinations in Appendix A.4.1.

### Evaluation upon Real-world Programs

Table 2 shows the basic statistics of TantBench Suite . Particularly, there are 53 different forms of source-sink pairs in total and an application contain 7.9 different forms of source-sink pairs on average. The diversity of source-sink pairs necessitates the customization of dataflow analysis. Considering the resource cost of invoking LLMs and the manual cost of comparing detection results with the ground truth, we run LLMDFA with gpt-3.5 for randomly selected source/sink pairs, which constitute 80 out of the 203 dataflow paths in the ground truth. As shown in Table 3, LLMDFA achieves the precision of 75.38% and the recall of 61.25%. The false positives and negatives are mainly caused by the hallucinations in the dataflow summarization. Listing 8 in Appendix A.4.3 shows a false negative example when LLMDFA fails to detect the dataflow path from the return value of the function _query_ to the argument of the function _write_. Specifically, LLMDFA fails to capture the summary of _processResults_, which contains complex program structures, such as a try-catch block and a while statement, ultimately resulting in the failure to report the intended dataflow path. We also present a false positive example by Listing 8 Appendix A.4.3.

We also compare LLMDFA with the end-to-end analysis and CodeFuseQuery. Specifically, we adopt a few-shot CoT prompting strategy to conduct the end-to-end analysis and customize CodeFuseQuery by designing specific queries to capture dataflow paths accordingly. As shown by Table 3, the end-to-end analysis only achieves a precision of 43.48% and a recall of 25.00%. The precision and recall are primarily affected by the incorrect identification of sources and sinks. When dealing

Figure 8: The comparison of LLMDFA and ablations using gpt-3.5

[MISSING_PAGE_FAIL:9]

## 5 Related Work

**Dataflow Analysis.** Current dataflow analysis predominantly relies on IR code generated by semantic analysis during the compilation, such as LLVM IR  and Soot IR . Typically, SVF  and Klee  analyze C/C++ programs based on LLVM IR code. Industrial analyzers like Infer  and Semmelte  also require successful builds to obtain necessary IR code for analysis. Consequently, the reliance on compilation infrastructures restricts the applicability when target programs cannot be compiled. Besides, existing techniques abstract semantics with formal structures, such as graphs  and logical formulas , to compute dataflow facts of interests. However, semantic abstraction differs greatly depending on analysis demands, such as the choices of sources/sinks and the precision setting of the analysis. Hence, the customization of dataflow analysis requires laborious manual effort and expert knowledge, which hinders its widespread adoption in real-world scenarios .

**Machine Learning-based Program Analysis.** The first line of studies derives program properties, such as library specifications [38; 39] and program invariants [40; 41], to augment classical analyzers. For instance, USpec utilizes large codebases to predict aliasing relation . SuSi employs classification models to infer the sources and sinks of sensitive information . While these techniques offer analyzers insightful guidance, they do not have any correctness guarantees due to their inherent limitations. The second line of works targets data-driven bug detection with training models [25; 42; 43]. Typically,  jointly trains an embedding model and a classification model upon a large training dateset. Unlike LLMDFA, it cannot answer general dataflow queries upon two specific program values. Similarly, Hoppity detects JavaScript bugs with the model trained upon a large volume of buggy code . The reliance to training data make these techniques difficult to customize for specific analysis demands in the presence of a sufficient amount of training data.

**LLMs for Program Analysis.** The emergence of LLMs has created exciting opportunities for various analysis tasks, including code completion , repair [9; 45], and comprehension . Considerable research targets the reasoning abilities of LLMs through techniques such as CoT , ToT , and accumulative reasoning . However, only a few studies focus on domain-specific reasoning for programs. Typically, several studies employ the CoT prompting to infer program invariants [10; 48] and rank potential invariants . Also, LLift retrieves function specifications through prompting  to assist classical bug detectors. As far as we know, no previous studies have solely relied on LLMs for program analysis. Our work formulates chain-like structures in dataflow facts and the demonstrates the possibility of synthesizing new tools to avoid hallucinations in program analysis. Our insight into mitigating hallucinations can be generalized to other software engineering problems, such as program repair  and program synthesis [51; 52].

## 6 Conclusion

This paper presents LLMDFA, a LLM-powered compilation-free and customizable dataflow analysis. To mitigate the hallucinations, it decomposes the whole analysis into three manageable sub-problems and solves them with a series of strategies, including tool synthesis, few-shot CoT prompting, and formal method-based validation. Our evaluation shows the remarkable performance of LLMDFA in analyzing both synthetic and real-world programs. Our work demonstrates a promising paradigm for reasoning code semantics, with the potential for generalization to other code-related tasks.