# Learning the Expected Core of

Strictly Convex Stochastic Cooperative Games

 Nam Phuong Tran

Department of Computer Science

University of Warwick

Coventry, United Kingdom

nam.p.tran@warwick.ac.uk

&The Anh Ta

CSIRO's Data61

Marsfield, NSW, Australia

theanh.ta@csiro.au

&Shuqing Shi

Department of Informatics

King's College London

London, United Kingdom

shuqing.shi@kcl.ac.uk

&Debmalya Mandal

Department of Computer Science

University of Warwick

Coventry, United Kingdom

debmalya.mandal@warwick.ac.uk

&Yali Du

Department of Informatics

King's College London

London, United Kingdom

yali.du@kcl.ac.uk

&Long Tran-Thanh

Department of Computer Science

University of Warwick

Coventry, United Kingdom

long.tran-thanh@warwick.ac.uk

###### Abstract

Reward allocation, also known as the credit assignment problem, has been an important topic in economics, engineering, and machine learning. An important concept in reward allocation is the core, which is the set of stable allocations where no agent has the motivation to deviate from the grand coalition. In previous works, computing the core requires either knowledge of the reward function in deterministic games or the reward distribution in stochastic games. However, this is unrealistic, as the reward function or distribution is often only partially known and may be subject to uncertainty. In this paper, we consider the core learning problem in stochastic cooperative games, where the reward distribution is unknown. Our goal is to learn the expected core, that is, the set of allocations that are stable in expectation, given an oracle that returns a stochastic reward for an enquired coalition each round. Within the class of strictly convex games, we present an algorithm named Common-Points-Picking that returns a point in the expected core given a polynomial number of samples, with high probability. To analyse the algorithm, we develop a new extension of the separation hyperplane theorem for multiple convex sets.

## 1 Introduction

The reward allocation problem is a fundamental challenge in cooperative games that seeks reward allocation schemes to motivate agents to collaborate or satisfy certain constraints, and its solution concepts have recently gained popularity within the machine learning literature through its application in explainable AI (XAI)  and cooperative Multi-Agent Reinforcement Learning (MARL) . In the realm of XAI, designers often seek to understand which factors of the model contribute to the outputs. Solution concepts such as the Shapley value  and the core  provide frameworks for assessing the influence that each factor has on the model'sbehavior. In cooperative MARL, these solution concepts offer a framework for distributing team rewards to individual agents, promoting cooperation among players, and preventing the occurrence of lazy learner phenomena [29; 12; 30]. A crucial notion of reward allocation is stability, defined as an allocation scheme wherein no agent has the motivation to deviate from the grand coalition. The set of stable allocations is called _the core of the game_.

In the classical setting, the reward function is deterministic and commonly known among all agents, with no uncertainty within the game. However, assuming perfect knowledge of the game is often unrealistic, as the outcome of the game may contain uncertainty. This led to the study of stochastic cooperative games, dated back to the seminal works of [9; 27], where stability can be satisfied either with high probability, known as the robust core, or in expectation, known as the expected core. However, in these works, the distribution of stochastic rewards is given, allowing agents to calculate the reward before the game starts, which is not practical since the knowledge of the reward distribution may only be partially known to the players. When the distribution of the stochastic reward is unknown, the task of learning the stochastic core by sequentially interacting with the environment appears much more challenging. Early attempts [19; 20] studied robust core and expected core learning under full-information, where full information means that the random rewards of all coalitions are observed at each round. However, full-information feedback is a strong assumption, which does not hold in many real-world situations. Instead, agents typically observe the reward of their own coalition only (e.g., only know the value of their own action - joining a particular coalition in this case), which is typically known as bandit feedback in the online learning literature.

In our work, we focus on learning the expected core, which circumvents the potential emptiness of the robust core in many practical cases. Moreover, instead of full-information feedback, where the stochastic rewards of all coalitions are observed each round, we consider the bandit feedback setting, where only the stochastic reward of the inquired coalition is observed each round. Given the lack of knowledge about the probability distribution of the reward function, learning the expected core using data-driven approaches with bandit feedback is a challenging task.

Against this background, the contribution of this paper is three-fold: **(1)** We focus on expected core learning problem with unknown reward function, and propose a novel algorithm called the Common-Points-Picking algorithm, the first of its kind that is designed to learn the expected core with high probability. Notably, this algorithm is capable of returning a point in an unknown simplex, given access to the stochastic positions of the vertices, which can also be used in other domains, such as convex geometry. **(2)** We establish an analysis for finite sample performance of the Common-Points-Picking algorithm. The key component of the analysis revolves around a novel extension of the celebrated hyperplane separation theorem, accompanied by further results in convex geometry, which can also be of independent interest. **(3)** We show that our algorithm returns a point in expected core with at least \(1-\) probability, using \((n,(^{-1}))\) number of samples.

## 2 Related Work

Stochastic Cooperative Games.The study of stochastic cooperative games can be traced back to at least . The main goal of the allocation scheme is to minimise the probability of objections arising after the realisation of the rewards. [27; 26] later extended and refined the notion of stability in stochastic settings. These seminal works require information about the reward distribution to compute a stable allocation scheme before the game starts. Stochastic cooperative games have also been studied in a Bayesian setting in a series of papers [5; 7; 8; 6]. These works develop a framework for Bayesian stochastic cooperative games, where the distribution of the reward is conditioned on a hidden parameter following a prior distribution. The prior distribution is common knowledge among agents and can be used to define a new concept of stability called Bayesian core. In contrast to previous works, our paper focuses on studying scenarios where the reward distribution or prior knowledge is not disclosed to the principal agent and computing a stable allocation requires a data-driven method.

Learning the Core.The literature on learning the core through sample-based methods can be categorised based on the type of core one seeks to evaluate. Two main concepts of the stochastic core are commonly considered, namely the robust core (i.e. core constraints are satisfied with high probability) [11; 22; 19] and the expected core (i.e. core constraints are satisfied in expectation) [10; 20]. The robust core is defined in a manner that allows the core inequalities to be satisfied with high probability when the reward is realised. However, this definition may lead to the practical issue of an empty robust core, as illustrated in . To mitigate the potential emptiness of the robust core, we investigate the learnability of the expected core.

The work most closely related to ours is , in which the authors introduce an algorithm designed to approximate the expected core using a robust optimization framework. In the context of full information feedback, where rewards for all allocations are revealed each round, the algorithm demonstrates asymptotic convergence to the expected core. Furthermore, the authors provide an finite-samples error bound for the distance to the expected core. However, when dealing with bandit feedback, where the reward of the required coalition is returned each round, naively applying the algorithm of  may result in an exponential number of samples in terms of the number of players. In the bandit feedback setting, as _we later establish in Theorem 7 that, in general cooperative games, no algorithm can learn the expected core with a finite number of samples without additional assumptions._ This highlights the key difference in dealing with bandit feedback compared to full-information feedback. Given this limitation, we narrow our focus to (strictly) convex games, an important class of cooperative games where the expected reward function is (strictly) supermodular. By leveraging strict convexity, we introduce the Common-Points-Picking algorithm, which efficiently returns a point in the expected core with high probability using only a polynomial number of samples. While  proposed a general algorithm applicable to strictly convex games, we argue that it lacks statistical and computational efficiency due to the absence of a mechanism to exploit the supermodular structure of the expected reward function. Further detailed comparison can be found in Appendix E.1.

Learning the Shapley Value.Another relevant line of research is the Shapley approximation, as the Shapley value is the barycenter of the core in convex games. Therefore, the approximation error of the Shapley value is an upper bound on the distance between the approximated Shapley value and the expected core [4; 18; 24]. It is worth noting that, in contrast to the Shapley approximation method, our algorithm ensures the return of a point in the core. In comparison, the Shapley approximation approach can only provide an allocation with a bounded distance from the core.

## 3 Problem Description

### Preliminaries

Notations.For \(k^{+}\), denote \([k]\) as set \(\{1,2,,k\}\). For \(n^{+}\), let \(^{n}\) be the \(n\)-dimensional Euclidean space, and let us denote \(\) as the Euclidean distance in \(^{n}\). Denote \(_{n}\) as the vector \([1,...,1]^{n}\). Denote \(,\) as the dot product. For a set \(C\), we denote \(C x\) as the set resulting from eliminating an element \(x\) in \(C\). For \(C^{n}\), let \((C):=_{x,y C}(x,y)\), and \((C)\) denote the diameter and the convex hull of \(C\), respectively.

Denote \(_{n}:=\{:[n][n]\}\) as the permutation group of \([n]\). For any collection of permutations \(_{n}\), we denote \(_{p},\ p[||],\) as \(p^{}\) permutation order in \(\). Let \(s_{i}:=(i,i+1)\) denote the _adjacent transposition_ between \(i\) and \(i+1\). Given a set \(C\), we denote by \((C)\) the space of all probability distributions on \(C\).

Stochastic Cooperative Games.A _stochastic_ cooperative game is defined as a tuple \((N,)\), where \(N\) is a set containing all agents with number of agents to be \(|N|=n\), and \(=\{_{S}() S N\}\) is the collection of reward distributions with \(_{S}\) to be the reward distribution w.r.t. the coalition \(S\). For any coalition \(S N\), we denote \((S):=_{_{S}}[r]\) as the expected reward of coalition \(S\). For a reward allocation scheme \(x^{n}\), let \(x(S):=_{i S}x_{i}\) as the total reward allocation for players in \(S\). A reward allocation \(x\) is _effective_ if \(x(N)=(N)\). The hyperplane of all effective reward allocations, denoted by \(H_{N}\), is defined as \(H_{N}=\{x^{n} x(N)=(N)\}\). The convex stochastic cooperative game can be defined as follows:

**Definition 1** (**Convex stochastic cooperative game**).: A stochastic cooperative game is convex if the expected reward function is supermodular , that is,

\[(S\{i\})-(S)(C\{i\})-(C) ), i S C C S  N.\] (1)

Next, we define the notion of strict convexity as follows:

**Definition 2** (\(\)**-Strictly convex cooperative game**).: For some constant \(>0\), a cooperative game is \(\)-strictly convex if the expected reward function is \(\)-strictly supermodular , that is, \(\) is supermodular and

\[(S\{i\})-(S)(C\{i\})-(C)+, i  S C C S N.\] (2)Following , we define the expected core as follows:

**Definition 3** (**Expected core**).: The core is defined as

\[:=\{x^{n} x(N)=(N);\ x(S)(S),\  S  N\}.\]

That is, the E-Core is the collection of all effective reward allocation schemes \(x\) (i.e., schemes where the total allocation adds up to the expected reward of the grand coalition \(N\) - see the definition of effective reward allocation above), where if any agents deviate from the grand coalition \(N\) to form a smaller team \(S\), regardless of how they allocate the reward, each individual will not receive more expected reward than if they had stayed in \(N\). Note that, as E-Core \( H_{N}\), its dimension is at most \((n-1)\). We say that E-Core is _full dimensional_ whenever its dimension is \(n-1\).

In convex games, each vertex of the core in the convex game is a marginal vector corresponding to a permutation order . This is a special property of convex games, which plays a crucial role in our algorithm design. For any \(_{n}\), define the marginal vector \(^{}^{n}\) corresponding to \(\), that is, its \(i^{}\) entry is

\[^{}_{i}:=(P^{}(i))-(P^{}(i) i),\] (3)

where \(P^{}_{i}=\{j(j)(i)\}\). It is known from  that if the expected reward function is strictly supermodular, the _E-Core must be full dimensional_.

### Problem Setting

In our setting we assume that there is a principal who does not know the reward distribution \(\). In each round \(t\), the principal queries a coalition \(S_{t} N\). The environment returns a vector \(r_{t}_{S_{t}}\) independently of the past. For simplicity, we assume that the agent knows the expected reward of the grand coalition \((N)\). Additionally, we assume that the convexity of the game, that is, \(\) is supermodular. Our question is how many samples are needed so that with high probability \(1-\), the algorithm returns a point \(x\). More particularly, we ask whether or not there is an algorithm that can output a point in the E-Core, with probability at least \(1-\) and the number of queries

\[T=(n,(^{-1})).\] (4)

As well shall show in Theorem 7, if E-Core is not full-dimensional, no algorithm can output a point in E-Core with finite samples. As such, to guarantee the learnability of the E-Core. From now on in the rest of this paper, we assume that:

**Assumption 4**.: _The game is \(\)-strictly convex._

Note that _strict_ convexity immediately implies full dimensionality , which is not the case with convexity (refer to Section 5). As we shall show in the next sections, strict convexity is a sufficient condition allowing the principal to learn a point in E-Core with polynomial number of samples. Practical examples of strictly convex games can be found in appendix D.

## 4 Learning the Expected Core

In this section, we propose a general-purpose Common-Point-Picking algorithm that is able to return a point of unknown full-dimensional simplex, given an oracle that provides a noisy position of the simplex's verticies. Under the assumption that the game is strictly convex, we show that, when applying Common-Points-Picking algorithm to the \(\)-strictly convex game, it can return a point in E-Core provided the number of samples is \((n,)\).

### Geometric Intuition

Given E-Core polytope of dimension \((n-1)\). In deterministic case when the knowledge of the game is perfect, to compute a point in the core, one can query a marginal vector corresponding to a permutation order \(_{n}\). Given that we have uncertainty in the estimation of E-Core, this approach is no longer applicable. The reason is that for each vertex \(^{}\), we do not precisely compute its position. Instead, we only have information on its confidence set \((^{},)\), a compact \((n-1)\)-dimensional set. The confidence set contains \(^{}\) with probability at least \((1-)\), as we will define shortly in this section.

One approach to overcome the effect of uncertainty is that we can estimate multiple vertices of the E-Core. Let \(_{n}\) be a collection of permutations, and \(Q=\{^{_{p}}_{p}\}\) be the set of vertices corresponding to \(\). For brevity, we denote \(_{p}:=(^{_{p}},),~{}_{p}\). In this section, we assume that the confidence sets contain the true vertices, that is, \(^{_{p}}_{p},~{} p[||]\), which can be guaranteed with high probability. It is clear that \((Q)\), since \(Q\) is a subset of vertices of E-Core. The challenge is that, as the ground truth of the position of the vertex can be any point in the confidence set, we need to ensure that the algorithm outputs a point in the convex hull of any collection of points in the confidence sets. A sufficient condition to achieve this is that, given \(||\) confidence sets \(\{_{p}\}_{p[||]}\), for each \(x^{p}_{p}\),

\[_{x^{p}_{p}\\ p[||]}(\{x^{p}\}_{p[||]}).\] (5)

This condition means that there exists a common point among all the convex hulls formed by choosing any point in confidence sets, \(x^{p}_{p}\). We call the above intersection a set of common points. The reason why it is a sufficient condition is that this set is a subset of a ground-truth simplex, implying that it is in the E-Core. Formally, we have

\[_{x^{p}_{p}\\ p[||]}(\{x^{p}\}_{p[||]})(Q);\] (6)

which means that any common point must be in E-Core. Moreover, the set of common points _is learnable_. As we shall show in the next section, our algorithm can access the set of common points whenever it is nonempty.

We first state a necessary condition for the number of vertices of E-Core need to estimate for (5) can be satisfied:

**Proposition 5**.: _Assume that all the confidence sets are full dimensional, that is, \((_{p})=n-1,~{} p[||]\), and suppose that \(||<n\),_

\[_{x^{p}_{p}\\ p[||]}(\{x^{p}\}_{p[| |]})=.\] (7)

Proposition 5 implies that one needs to estimate at least \(n\) vertices to guarantee the existence of a common point.

### Common-Points-Picking Algorithm

As Proposition 5 suggests, we need to estimate at least \(n\) vertices. As such, from now on, we assume that \(||=n\). Based on the above intuition, we propose Common-Points-Picking, whose pseudo code is described in Algorithm 1.

```
1:Input collection of permutation order \(=\{_{p}\}_{p[n]}\).
2:\(t=0,~{}=0\), \(Q=\)
3:whileStopping-Condition\((Q,b_{})\)do
4:\(+1\);
5:for\(p[n]\)do
6:for\(i[n]\)do
7: Query \(P_{i}^{_{p}}\).
8: Oracle returns \(r_{}(P_{i}^{_{p}}) r_{t}\).
9:\(t t+1\).
10: Computing \(_{i}^{_{p}}()\) as (9).
11:endfor
12:endfor
13: Assign \(Q=\{^{_{p}}()\}_{p[n]}\)
14: Compute \(b_{}\) as (10)
15:endwhile
16: Return \(x^{}=_{}^{}()\). ```

**Algorithm 1** Common Points Picking

The Common-Points-Picking Algorithm can be described as follows. First, let us explain the notation. In epoch \(\), the variable \(r_{}()\) in the algorithm represents the reward value of the enquired coalition; \(^{_{p}}()\) represents the estimated marginal vector w.r.t. \(_{p}\). In each epoch \(\), assuming that the stopping condition is not satisfied, the algorithm estimates the marginal vectors corresponding to the collection of given permutation orders \(Q=\{^{_{p}}()\}_{p[n]}\) (lines 6-10). For each \(p[n]\), the estimation can be done by querying the value of the nested sequence \(P_{1}^{_{p}},~{}P_{2}^{_{p}},~{},~{}P_{n}^{_{p}}\) (line 6-7), then estimating the marginal contribution of each player with respect to the permutation order \(_{p}\) (line 10). Next, it calculates the confidence bonus \(b_{}\) of the confidence sets and checks the stopping condition for the next epoch. The algorithm continues until the stopping condition is satisfied, and then returns the average of the most recent values of the marginal vectors corresponding to \(\).

The termination of the Common-Points-Picking algorithm is based on the Stopping-Condition algorithm (Algorithm 2), which can be described as follows. Consider the case where \(Q\). For each point \(x^{p} Q\), the algorithm attempts to calculate the separating hyperplane \(H_{p}(Q)\), that separates \(x^{p}\) from the rest \(Q x^{p}\) (line 7).

The hyperplane \(H_{p}(Q)\) is defined by two parameters \((v^{p}^{n},c^{p})\), where \(v^{p}\) is one of its unit normal vectors, together with \(c^{p}\), satisfying Eq. (8). Specifically, the second and third equality in (8) implies that \(H_{p}(Q)\) is parallel and at a distance of \(_{}\) (toward \(x^{p}\)) from the hyperplane that passes through all the points in \( x^{p}\). The fourth equality in (8) guarantees that \(H_{p}(Q)\) is a subset of \(H_{N}\) (as the normal vector of \(H_{N}\) is \(_{n}\)). After computing \(H_{p}(Q)\), the algorithm checks whether the distance from the confidence set \(_{p}\) to \(H_{p}(Q)\) is large enough (lines 8-12). The stopping condition checks for all \(p[n]\); if no condition is violated, then the algorithm returns TRUE. An example of the construction of separating hyperplanes in \(H_{N}\), where \(n=3\) is depicted in Figure 1.

Note that the input of algorithm \(\) can be any collection of permutation orders such that \(||=n\). In the next section, we will provide instances of the collection of permutation orders, in which, under Assumption 4, the algorithm can output a point in E-Core with high probability and a polynomial number of samples.

**Remark 6**.: Most of the computational burden lies in computing the separating hyperplane \(H_{p}(Q)\) for each \(p\) (line 7), and calculating the distance between the confidence set \(_{p}\) and \(H_{p}(Q)\) (line 8) in Stopping Condition. Since all tasks can be completed within polynomial time w.r.t. \(n\), our algorithm is polynomial.

There are two challenges regarding the Common-Points-Picking algorithm. First, we need to design confidence sets such that they contain the vertices with high probability, which can be done easily using Hoeffding's inequality. Second, we need to define a stopping condition that can guarantee the non-emptiness of the common set and output a point in the common set with a polynomial number of samples. The second question is _more involved and requires proving new results in convex geometry_, including an extension of the hyperplane separation theorem, as we shall fully explain in Section 5.1.

Confidence SetTo calculate this set we will use the probability concentration inequality to obtain a confidence set: First, let \(r_{}()=0,\ \,>0\), define the empirical marginal vector w.r.t. permutation \(\) as \(^{}^{n}\) at epoch \(\) as

\[^{}_{i}()=}_{s=1}^{ }r_{s}(P^{}_{i})-r_{s}(P^{}_{i}  i).\] (9)

By the Hoeffding's inequality, one has that after \(\) epochs, \(\), for each \(i[n]\), with probability at least \(1-\), \(^{}\) must belong to the following set:

\[(^{},)=\{x H_{N}\|x- ^{}\|_{} b_{}\}; b _{}:=\,^{-1})}{}}.\] (10)

Figure 1: Set of common points constructed by separating hyperplanes. The intersection of half-spaces defined by \(H_{p}(Q),\  p[n],\) creates a subset of common points. The common points are in E-Core, provided that the confidence sets contain the ground-truth vertices.

Main Results

Before proceeding to the analysis of Algorithm 1, let us exclude the case where learning a stable allocation is not possible, thereby emphasizing the need of the strict convexity assumption.

**Theorem 7**.: _Suppose that E-Core has dimension \(k<n-1\), for any \(0.2>>0\) and with finite samples, no algorithm can output a point in E-Core with probability at least \(1-\)._

The proof of Theorem 7 employs an information-theoretic argument. In particular, we construct two game instances with low-dimensional cores, utilising the concept of face games introduced in . The construction of the two games is designed to ensure that, despite the KL distance between their reward distributions being arbitrarily small, their low-dimensional cores are parallel and maintain a positive distance from each other. Consequently, their cores have empty intersections. This implies that, given finite samples, no algorithm can reliably distinguish between the two games. Since these games lack a mutually stable allocation, if an algorithm fails to differentiate between them, it is likely to choose the wrong core with a certain probability.

It is worth noting that convex games may have a low-dimensional core, as demonstrated in the following example.

**Example 8**.: Let \((S)=|S|\) for all \(S N\). It is easy to verify that \(\) is indeed convex. The marginal contribution of any player \(i\) to any set \(S N\) is

\[(S i)-(S)=1,\  S N.\] (11)

Therefore, the only stable allocation is \(_{n}\), which coincides with the Shapley value. Hence, the core is one-point set. According to Theorem 7, since the core has a dimension of \(0\) in this case, it is impossible to learn a stable allocation with a finite number of samples.

Example 8 suggests that convexity alone does not ensure the problem's learnability, emphasizing the requirement for strict convexity.

### On the Stopping Condition

In this subsection, we explain the construction of the stopping condition in Algorithm 2. We will show that the stopping condition can always be satisfied with the number of samples needed polynomially w.r.t the width of the ground truth simplex. Intuitively, the confidence sets need to shrink to be sufficiently small, relative to the width of the simplex, to guarantee the existence of a common point.

To simplify the presentation, we restrict our attention to \(H_{N}\) and consider it as \(^{n-1}\). First, we state a necessary condition for the existence of common points.

**Proposition 9**.: _Suppose there is a \((n-2)\)-dimensional hyperplane that intersect with all the interior of confidence sets \(_{p},\  p[n]\), then common points do not exist._

Proposition 9 suggests that if the ground truth simplex \((Q)\) is not full-dimensional, then the common set is empty. In addition, even if \((Q)\) is full-dimensional, but the confident sets are not sufficiently small, one can also create a hyperplane that intersects with all the confidence sets. For example, when the intersection of the confidence sets is not empty.

On the other hand, when the confidence sets are well-arranged and sufficiently small, that is, there does not exist a hyperplane that intersects with all of them, a nice separating property emerges, as stated in the next theorem. This _new result can be considered as an extension of the classic separating hyperplane theorem_. First, let us recap the notion of separation as follows.

**Definition 10** (Separating hyperplane).: Let \(C\) and \(D\) be two compact and convex subsets of \(^{n-1}\). Let \(H\) be a hyperplane defined by the tuple \((v,c)\), where \(v\) is a unit normal vector and \(c\) is a real number, such that \( x,v=c,\  x H\). We say \(H\) separates \(C\) and \(D\) if \( x,v>c,\  x C;\ \  y,v <c,\  y D\).

**Theorem 11** (Hyperplane separation theorem for multiple convex sets).: _Assume that \(\{_{p}\}_{p[n]}\) are mutually disjoint compact and convex subsets in \(^{n-1}\). Suppose that there does not exist a \((n-2)\)-dimensional hyperplane that intersects with confidence sets \(_{p},\  p[n]\), then for each \(p[n]\), there exists a hyperplane that separates \(_{p}\) from \(_{q p}_{q}\)._

**Remark 12** (**Non-triviality of Theorem 11**).: At a first glance, Theorem 11 may appear as a trivial extension of the classic hyperplane separation theorem due to the following reasoning: Consider the union of all hyperplanes that intersect \(_{q p}_{q}\), which trivially contains \(_{q p}_{q}\). Then, by assuming that these hyperplanes do not intersect \(_{p}\), the separation between \(_{p}\) and \(_{q p}_{q}\) appears to follow from the classic separation hyperplane theorem. However, there is a flaw in the above reasoning: The union of these hyperplanes is _not necessarily convex_. Therefore, the classic separation hyperplane theorem cannot be applied directly. Instead, employing Caratheodory's theorem, we prove in Theorem 11 by contra-position that if the intersection between \(_{p}\) and \((_{q p}_{q})\) is non-empty, then we can construct a low-dimensional hyperplane that intersects with all the set.

When those confidence sets are well-separated, we can provide a sufficient condition for that the common points exist. Let \(H_{p}\) be a separating hyperplane that separate \(_{p}\) from \(_{q p}_{q}\). We define \(H_{p}\) corresponding with tuple \((v^{p},c^{p})\). Now, denote \(E_{p}=\{x^{n-1} v^{p},x<c^{p}\}\) as the half space containing \(_{p}\). We have that:

**Lemma 13**.: _For any \(x^{p}_{p}\), \(p[n]\),_

\[_{p[n]}E_{p}(\{x^{p}\}_ {p[n]}).\] (12)

_Consequently, if \(_{p[n]}E_{p}\) is nonempty, it is the subset of common points._

From Lemma 13, as \(_{p[n]}E_{p}\) is the subset of any simplex defined by a set of points in the confidence sets, \(_{p[n]}E_{p}\) must be either empty or bounded subset of \(^{n-1}\). The _key implication here is that Lemma 13 provides us a method to find a point in the common set_. An example of Lemma 13 in \(^{2}\) is illustrated in Figure 1.

Now, the main question is under what conditions \(_{p[n]}E_{p}\) is nonempty. Next we show that the nonemptiness of \(_{p[n]}E_{p}\) can be guaranteed if the diameter of the confidence sets is sufficiently small. This establishes a condition for the number of samples required by the algorithm.

**Theorem 14**.: _Given a collection of confident set \(\{_{p}\}_{p[n]}\) and let \(Q=\{x^{p}\}_{p[n]}\), for any \(x^{p}_{p}\). For any \(p[n]\), denote \(H_{p}(Q)\) as the \((n-1)\)-dimensional hyperplane with constant \((v^{p},c^{p})\), \(\|v^{p}\|=1\) such that_

\[ v^{p},x=c^{p}+_{q[n] p} {diam}(_{p}), x Q x^{p}.\\  v^{p},x^{p}<c^{p}+_{q[n] p} (_{p}).\] (13)

_For all \(p[n]\), if the following holds_

\[(_{p},H_{p}(Q))>2n(_{q[n] p} (_{q}));\] (14)

_then there exists a common point. In particular, the point \(x^{}=_{p[n]}x^{p}\) is a common point._

Intuitively, Theorem 14 states that if the distance from a confidence set \(_{p}\) to the hyperplane \(H_{p}(Q)\) is relatively large compared to the sum of the diameters of all other confidence sets, then the average of any collection of points in the confidence set must be a common point. As such, Theorem 14 determines the stopping condition for Algorithm 1 and provide us a explicit way to find a common point, which validates the correctness of Algorithm 1. In particular, Algorithm 2 checks if conditions (14) are satisfied for the confidence sets in each round. If the conditions are satisfied, then Algorithm 1 stops sampling and returns \(x^{}\) as the common point.

Note that while the diameters of confidence sets can be controlled by the number of samples regarding the marginal vector, \((_{p},H_{p}(Q))\) is a random variable and needs to be handled with care. We show that there exist choices of \(n\) vertices such that the simplex formed by them has a sufficiently large width, resulting in the stopping condition being satisfied with high probability after \((n,^{-1})\) number of samples.

### Sample Complexity Analysis

Now, we show that, the conditions of Theorem 14 can be satisfied with high probability. The distance \((_{p},H_{p}(Q)),\ p[n]\) can be lower bounded by the width of the ground-truth simplex, which is defined as follows:

**Definition 15** (**Width of simplex)**.: Given \(n\) points \(\{x^{1},...x^{n}\}\) in \(^{n}\), let matrix \(P=[x^{i}]_{i[n]}\), we define the matrix of coordinates of the points in \(P\) w.r.t. \(x^{i}\) as \((P,i):=[(x^{j}-x^{i})]_{j i}^{n(n-1)}\). Denote \(_{k}(M)\) as the \(k^{}\) singular value of matrix \(M\) (with descending order). We define the _width_ of the simplex whose coordinate matrix is \(P\) as follows

\[(P):=_{i[n]}_{n-1}((P,i)).\] (15)

**Lemma 16**.: _Given \(n\) points \(\{x^{1},...,x^{n}\}\) in \(^{n}\), let \(M\) be the matrix corresponding to these points, assume that \(0<M_{ij}<1\) and \((M)\), for some constant \(>0\). Let \(R^{n n}\) be a perturbation matrix, such that its entries \(|R_{ij}|</2,\ (i,j),\) and \(0<<^{2}/3n^{3}\). Let \(h_{}\) be a smallest magnitude of the altitude of the simplex corresponding to the matrix \(M+R\). One has that_

\[h_{}-6n^{3}}.\] (16)

Lemma 16 guarantees that if the width of the ground truth simplex is relatively large compared to the diameter of the confidence set, then the heights of the estimated simplex are also large. We now provide an example of a collection of permutation orders corresponding to a set of vertices as follows.

**Proposition 17**.: _Fix any \(_{n}\), consider the collection of permutation \(=\{, s_{1},, s_{n-1}\}\) and matrix \(M=[^{^{}}]_{^{}}\). The width of the simplex that corresponds to \(M\), is upper bounded as \((M) 0.5 n^{-3/2}\)._

The vertex set in Proposition 17 comprises one vertex and its \((n-1)\) adjacent vertices. Combining Lemma 16, Proposition 17 with the stopping condition provided by Theorem 14, we now can guarantee the sample complexity of our algorithm:

**Theorem 18**.: _With the choice of collection of permutation order \(\) as in Proposition 17, and suppose that Assumption 4 holds. Then, for any \(\), if the number of samples is bounded by_

\[T=O((n^{-1}^{-1})}{^{4}}),\] (17)

_the Common-Points-Picking algorithm returns a point in E-Core with probability at least \(1-\)._

While the choice of vertices in Proposition 17 achieves polynomial sample complexity, the width of the simplex decreases with dimension growth, hindering its sub-optimality. An alternative choice of vertices is those corresponding to cyclic permutation, denoted as \(_{n}_{n}\), which have a larger width in large subsets of strictly convex games (as observed in simulations) but can be difficult to verify in the worst case. We refer readers to Appendix A.4 for the detail simulation and discussion on the choice of set of \(n\) vertices. Based on this observation, we achieve the sample complexity which better dependence on \(n\) as follows.

**Theorem 19**.: _Suppose Assumption 4 holds. Let \(=_{n}\) the collection of cyclic permutations, and denote the coordinate matrix of the corresponding vertices as \(W\). Assume that the width of the simplex \((W)}\) for some \(c_{W}>0\). Then, for any \(\),if number of samples is_

\[T=O(c_{W}^{4}(nc_{W}^{-1}^{-1})}{^ {4}}),\] (18)

_the Common-Points-Picking algorithm returns a point in E-Core with probability at least \(1-\)._

It is worth noting that our algorithm does not require information about the constants of the game \(,\ c_{W}\); instead, the number of samples required automatically scales with these constants. This indicates that our algorithm is highly adaptive and requires fewer samples for benign game instances.

**Remark 20** (**Comment on sample complexity lower bounds)**.: Deriving a lower bound is indeed important, but comes with several significant challenges. E.g., one possible direction is to extend the game instances in Theorem 7. However, there are two key technical issues with this idea: (1) Modifying the face game instance to ensure strict convexity is challenging; (2) It remains unclear how to generalize two face-game instances into \((n)\) game instances such that their cores do not intersect and the statistical distance of the reward can be upper bounded, which is crucial for showing \((n)\) dependencies in the lower bound (we refer the reader to appendix E.2 for further discussions). Given the unresolved challenges, deriving a lower bound remains an open question.

## 6 Experiment

To illustrate the sample complexity of our algorithm in practice and compare it with our theoretical upper bound, we have conducted a simulation as described below. Code is available at: https://github.com/NamTranKekL/ConstantStrictlyConvexGame.git.

**Simulation setting:** We generate convex game of \(n\) players with the expected reward function \(f\) defined recursively as follows: For each \(S N\) s.t. \(i S\),

\[f(S\{i\})=f(S)+|S|+1+0.9.\]

for some \(\) sampled i.i.d. from the uniform distribution \(()\). We then normalize the value of the reward function within the range \(\). It is straightforward to verify that the strict convexity constant is \( 0.1/n\). From the simulation results in Figure 2 (LHS), we can see that the growth pattern nearly matches that of the theoretical bound given in Theorem 19, indicating that our theoretical bound is highly informative.

Moreover, to demonstrate that our algorithm is robust even when the strict convexity assumption is violated, we ran a simulation where the characteristic function is only convex, i.e., the strict convexity constant is arbitrarily small, as follows:

\[f(S\{i\})=f(S)+|S|+1+.\]

We use the cyclic permutations \(_{n}\) as the input for the algorithm. In Figure 2 (RHS), one can see that the number of samples required as \(n\) grows is sub-exponential, indicating that our algorithm is robust when the strict convexity assumption is violated.

## 7 Conclusion and Future Work

In this paper, we address the challenge of learning the expected core of a strictly convex stochastic cooperative game. Under the assumptions of strict convexity and a large interior of the core, we introduce an algorithm named Common-Points-Picking to learn the expected core. Our algorithm guarantees termination after \((n,(^{-1}),^{-1})\) samples and returns a point in the expected core with probability \((1-)\). For future work, we will investigate whether the sample complexity of our algorithm can be further improved by incorporating adaptive sampling techniques into the algorithm, along with developing a lower bound for the class of games.

Figure 2: Simulation with game of \(n\{2,...,10\}\) players, where the strict convexity constant \(\) is \(0.1/n\) in the LHS and \(0\) in the RHS.