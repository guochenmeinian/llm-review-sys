# A Fully Analog Pipeline for Portfolio Optimization

James S. Cummins Natalia G. Berloff

Department of Applied Mathematics and Theoretical Physics

University of Cambridge

Wilberforce Road, Cambridge CB3 0WA, UK

jsc95@cam.ac.uk

###### Abstract

Portfolio optimization is a ubiquitous problem in financial mathematics that relies on accurate estimates of covariance matrices for asset returns. However, estimates of pairwise covariance are notoriously poor and calculating time-sensitive optimal portfolios is energy-intensive for digital computers. We present an energy-efficient, fast, and fully analog pipeline for solving portfolio optimization problems that overcomes these limitations. The analog paradigm leverages the fundamental principles of physics to recover accurate optimal portfolios in a two-step process. Firstly, we utilize equilibrium propagation, an analog alternative to backpropagation, to train linear autoencoder neural networks to calculate low-rank covariance matrices. Then, analog continuous Hopfield networks output the minimum variance portfolio for a given desired expected return. The entire efficient frontier may then be recovered, and an optimal portfolio selected based on risk appetite.

## 1 Introduction

Portfolio optimization involves creating an investment portfolio that balances risk and return. The objective is to allocate assets optimally to maximize expected returns while minimizing risk. Naturally, this problem is of great interest to financial organizations and is pivotal in risk management. However, the problem, formulated by Markowitz's mean-variance model , suffers from problems in practice. Namely, it is well known that estimates of pairwise covariance between assets are notoriously poor . Data samples tend to include significant amounts of noise, distorting the underlying relationships between assets. To overcome this issue, factor models were introduced that vastly reduce the dimensionality . Factor methods produce low-rank covariance matrices that retain only the largest eigenvalues and discard small eigenvalues associated with noise. Despite this development, the computation of optimal portfolios remains energy-intensive as the efficient frontier is mapped out in return-variance space. In high-frequency trading, this becomes a time-sensitive computation as assets are purchased and sold on microsecond timescales , and portfolios must be regularly rebalanced so as not to exceed risk appetites. Much attention has been focused on portfolio optimization in the high-frequency domain [5; 6; 7], including the use of evolutionary algorithms to update efficient frontiers . While algorithmic enhancements provide incremental gains, the exploration of alternative hardware paradigms has the potential to drive significant advancements. By using fundamental principles such as minimizing entropy, energy, and dissipation , or, perhaps, incorporating quantum phenomena like superposition and entanglement , we can advance and surpass classical computations of these problems. At the forefront of this drive to alternate architectures is the integration of analog, physics-based algorithms and hardware, which involve translating complex optimization problems into universal spin Hamiltonians [11; 12; 13]. Indeed, the mean-variance portfolio optimization framework can be encoded into a Hamiltonian's coupling strengths with the physical system recovering the Hamiltonian's ground state, which corresponds to the optimal portfolio solution [14; 15]. Efficient mapping from the original problem description to spin Hamiltonian enables the problem to remain manageable despite increasing complexity .

## 2 Mean-variance optimization

We define \(_{i}\) as the expected return of asset \(i\), and \([]_{ij}=_{ij}=(i,j)\) as the covariance between assets \(i\) and \(j\). The decision variables are \(w_{i}\), the proportion of the total investment in asset \(i\). For a universe of securities with \(n\) assets, the Markowitz mean-variance portfolio optimization problem is

\[_{}&^{}\\ &^{}=R,\\ &^{}=1,\\ & 0 w_{i} 1,\] (1)

for \(i=1,,n\), and the condition \(w_{i} 0\) prohibits shorting . The variance \(^{}\) quantifies the portfolio risk for positive semidefinite matrix \(\), while \(R\) is the desired expected return of the portfolio. \(\) and \(\) are not known a priori and must be estimated from historical data. The efficient frontier is calculated by solving (1) for various \(R\). The efficient frontier is the set of portfolios that minimize the risk for a given \(R\). We illustrate a frontier in Appendix A for a toy model with \(n=2\) assets. It was recently suggested that portfolio optimization problems could be solved on analog spatial-photonic Ising machines for equal-weighted portfolios, that is, \(w_{i}\{0,1/q\}\) for \(q\) selected assets . We go beyond this constraint by utilizing analog Hopfield networks and consider the quadratic continuous optimization problem (1). In Section 3, we aim to recover the optimal asset weights \(\), given known expected returns \(\) and covariance matrix \(\).

## 3 Continuous Hopfield network

A continuous Hopfield network is a type of Hopfield neural network which has continuous states and dynamics . It is an analog computational network for solving optimization problems. For a network of size \(n\), the \(i\)-th network element at time \(t\) is described by a real input \(x_{i}(t)\), and the network dynamics are governed by

\[x_{i}}{t}=-p(t)x_{i}+_{j=1}^{n}J_{ij}v_{j}+m_{i},\] (2)

where \(v_{i}=g(x_{i})\) is a nonlinear activation function, \(p(t)\) is an annealing parameter, \(m_{i}\) are the offset biases, and \(J_{ij}\) are elements of the symmetric coupling matrix \(\). Should \(g(x)\) be a non-decreasing function, then the steady states of the continuous Hopfield network (2) are the minima of the Lyapunov function

\[E=p(t)_{i=1}^{n}_{0}^{v_{i}}g^{-1}(x)x-_{i,j =1}^{n}J_{ij}v_{i}v_{j}-_{i=1}^{n}m_{i}v_{i},\] (3)

We choose the functional form of \(g(x)\), such that when \(p(t) 0\), the minima of \(E\) occur for \(v_{i}\) and correspond to the minima of \(-^{}\). Therefore, by setting \(=-\), we can minimize the variance \(^{}\) of problem (1). To satisfy the constraints in problem (1) we introduce Lagrange multiplier-like scalars \(_{1},_{2}\) and seek to minimize the expression \(H=^{}+_{1}(^{}-R)^{2}+_{2}(^{}- 1)^{2}\). Therefore, after discarding constants, we seek to minimize

\[H=-^{}-^{ },\] (4)

where \(=-2-2_{1}^{ }-2_{2}^{}\), and \(=2R_{1}+2_{2}\). Equation (4) can be directly encoded into the Hopfield network (2), and if required, \(\) can be absorbed into \(\) by introducing an additional auxiliary spin. The non-decreasing monotonic function \(g(x)\) is chosen to be the logistic function \(g(x)=1/[1-(-x)]\) to limit possible values of \(v_{i}\) such that \(0 v_{i} 1\). We illustrate the Hopfield network dynamics in Appendix B for a randomly generated covariance matrix \(\) and expected return vector \(\). The energy minimization properties of Hopfield networks make them particularly suitable for solving combinatorial optimization problems. Further extensions have been proposed to increase convergence to optimal states in challenging optimization problems. For example, the first-order Eq. (2) can be momentum-enhanced and replaced with a second-order equation leading to Microsoft's analog iterative machine  or Toshiba's bifurcation machine .

## 4 Low-rank approximation

We now focus on calculating a low-rank approximation of the covariance matrix, which will be used in (1). If \(_{i}^{n}\) are the \(i\)-th sample of asset returns over \(N\) total samples, and we assume that \([]=\), then the sample covariance matrix is \(=_{i=1}^{N}_{i}_{i}^{}\). When the number of samples \(N\) is of the same magnitude as \(n\), then the sample covariance matrix usually suffers a large estimation error [2; 20]. Many low-rank factor analysis techniques exist to improve the covariance matrix estimate. Here, we consider asset returns \(\) as random variables that follow the model

\[=+,\] (5)

where \(^{n}\) is the observed data, \(^{n r}\) is a factor loading matrix, \(^{r}\) is the vector of latent variables, and \(^{n}\) is uncorrelated random noise, where \(r n\). Here, \(\) represents macroeconomic factors like the growth rate of the GDP, unemployment, inflation etc. Under the assumption that \(\) and \(\) are uncorrelated, the covariance matrix is then \(=[^{}]\). This gives

\[ =[^{}]^{}+[^{}]\] (6) \[=^{}+,\] (7)

where \([^{}]^{r  r}\) has \(() r\), \(() r\), and \(\) is a diagonal matrix containing the variance of noise on its diagonal. Since \(()((), ())\), then \((^{}) r\). Therefore, we have decomposed the covariance matrix \(\) into a positive semidefinite low-rank matrix plus a positive semidefinite diagonal matrix. Defining \(^{}\), low-rank factor analysis concerns the estimation of \(\) and \(\). To calculate \(\) and \(\) we solve the minimization problem

\[_{,}&|| --||_{}^{2}\\ &() r,\\ & 0,\] (8)

where \(||||_{}\) denotes the Frobenius norm . We present a common digital computing method in Appendix (C) for solving problem (8) based on principal component analysis (PCA). The eigendecomposition in PCA becomes computationally expensive as the data size grows. Alternatively, autoencoders - particularly when implemented using stochastic gradient descent - can handle larger datasets and higher-dimensional data more efficiently than PCA . Additionally, when integrating dimensionality reduction as part of a larger neural network framework, an autoencoder can be easily embedded within the pipeline, whereas PCA would need to be applied as a separate pre-processing step .

## 5 Linear autoencoders

A linear autoencoder is a classic neural network model for unsupervised learning that is trained to learn the identity function. The input and output layers have the same number of nodes, while the middle layer has fewer nodes. It aims to approximate the input through learning linear encodings and decodings between input and latent space. The encoder \(^{r n}\) maps input \(=[_{1},,_{N}]^{n N}\) into a low-dimensional latent space \([_{1},,_{N}]\), and the decoder \(^{n r}\) maps \([_{1},,_{N}]\) back to the original representation \(\). We therefore recover the same model as in Eq. (5), and training the linear autoencoder becomes the minimization problem 

\[_{,}||- ||_{}^{2}.\] (9)

We do not explicitly express the learnable biases in the network as these may be absorbed into the encoder \(\) and decoder \(\) by introducing an auxiliary row into \(\) that is permanently clamped to values of \(1\). We illustrate the training of a linear autoencoder in Fig. (1)(a)-(c) with the backpropagation method and compare it to PCA in Fig. (1)(h). A linear autoencoder is related to PCA. Indeed, under mild nondegeneracy conditions, any \(\) at a local minimizer recovers the top rank-\(r\) eigenspace of \(^{}\). However, unlike actual PCA, the coordinates of the output of the middle layer in the network are correlated and are not sorted in descending order of variance . Autoencoder neural networks typically use backpropagation to train the weights. However, backpropagation is energy-intensive and not biologically plausible.

## 6 Equilibrium propagation

On dedicated analog hardware, equilibrium propagation is an energy-efficient alternative to backpropagation . Therefore, in the supervised learning setting studied here, it may be used to train the weights of a linear autoencoder. Equilibrium propagation is an energy-based model because it relies on the concept of energy minimization to learn and make predictions. We consider the continuous Lyapunov function (3) with \(p(t)=1\) and \(m_{i}=0\) for all \(i\), where here the symmetric coupling weights \(J_{ij}\) are to be learned, and nonlinear activation function \(g(x)\) need not be the same as in Section 3. Neurons \(x_{i}\) are split in three sets: the input neurons, which are always clamped, the hidden neurons, and the output neurons. The discrepancy between the desired output \(\) and the realized output \(}\) is measured by the cost function

\[C=||-}||_{2}^{2},\] (10)

which forms part of the total energy function \(F=E+ C\). The clamping factor \( 0\) is a real-valued scalar that allows the output neurons to be weakly clamped . The continuous-time dynamical system evolves according to the differential equation of motion

\[x_{i}}{t}=-}=- { E}{ x_{i}}-},\] (11)

which is formed of two parts. The first is the internal force induced by the internal Hopfield energy, given by Eq. (2) for all \(i\), and the second, the external force, is induced by the cost function \(C\) as

\[-}=(y_{i}-x_{i}), i,\] (12)

for nodes in the output layer \(\). Equilibrium propagation has two modes: the free phase and the weakly clamped phase. In the free phase \(=0\) and only the inputs are clamped. The network then converges to a fixed point \(^{*}\) and the output units are read out. In the weakly clamped phase \(>0\), which induces an external force that acts on the output units as in Eq. (12). This force nudges the outputs from their fixed point values in the direction of the target values \(y_{i}\). This perturbation propagates among the hidden neurons before a new fixed point \(^{*}_{}\) is found. Then, another weakly clamped phase is executed, this time with \(-\) leading to the weakly clamped equilibrium \(^{*}_{-}\). It was shown that the weakly clamped phase implements the propagation of error derivatives with respect to the synaptic weights . In the limit \( 0\), the update rule is

\[ J_{ij}(.}|_{^{*}_{}}-.} |_{^{*}_{-}}),\] (13)

Figure 1: Training a linear autoencoder via (a)-(c) backpropagation (BP), and (d)-(f) with equilibrium propagation (EP). Input and output layers have size \(50\), while the single hidden layer has size \(5\). The networks are trained on \(50\) vectors \(_{1},,_{50}\) of size \(50\) whose elements are randomly sampled from the normal distribution \(N(0,1)\). (a)-(f) illustrate the element-wise absolute difference between the \(50 50\) matrix \(=[_{1},,_{50}]\) and its reconstructed output \(\) at different epochs. (g) An illustrative example of the encoder/decoder Hopfield network structure trained with EP. (h) The overall network loss for BP and EP over epoch time. The black horizontal dashed line corresponds to the loss of the equivalent PCA method described in Appendix C.

which is a second-order approximation to the standard backpropagation derivative . The process is iterated, at each step updating the weights \(J_{ij}\) to minimize the loss function \(C\). We choose activation function

\[g(x)=x&|x| c\\ c(x)&,\] (14)

with constant \(c\), so that under the condition that \(|x_{i}| c\) for all \(i\), Eq. (2) is linear and can thus represent a linear autoencoder. In this case, the output \(}\) of Eq. (2) is then the solution to the linear differential equation \(/t=(-)\), and therefore

\[}=_{t}(t)=_{t}\{( -)t\}(0).\] (15)

The constant \(c\) in Eq. (14) is chosen to be large enough such that after training, all neurons obey \(|x_{i}| c\), and we can associate the Hopfield network as a linear autoencoder. To achieve a steady state in Eq. (15), at least one eigenvalue of \(-\) should be zero, with all others having a negative real part.

**Proposition**. _We state, with proof given in Ref. , that for any fixed \(n r\) matrix \(\), Eq. (9) attains its minimum for \(=(^{})^{-1}^{}\)._

**Lemma**. _The \(n n\) matrix \(-\), where \(=\), has at least one zero eigenvalue, with all others having negative real part._

_Proof_.: \(==(^{}) ^{-1}^{}\), and therefore

\[^{2} =(^{})^{-1}^{ }(^{})^{-1}^{ }\] (16) \[=(^{})^{-1}^{ },\] (17)

which shows that \(\) is idempotent, that is \(^{2}=\). It follows that \(\) is a projection operator on the column space \(C()\) along its null space \(N()\). The \(n\) eigenvalues \(_{i}\) of \(\) are either \(0\) or \(1\): \(_{i}_{i}=_{i}=^{2}_ {i}=_{i}_{i}=_{i}^{2}_{i}\), which implies \(_{i}\{0,1\}\). By construction, \(\) has rank at most \(r\), and therefore there are at least \(n-r\) zero eigenvalues. It follows that there are between \(1\) and \(r\) nonzero eigenvalues of \(\), which must have value \(_{i}=1\). Since \(-\) has eigenvalues \(_{i}=_{i}-1\), then \(_{i}\{-1,0\}\). Therefore, \(-\) has between \(1\) and \(r\) zero eigenvalues, with all others being equal to \(-1\).

The Lemma guarantees that should equilibrium propagation learn the weights that minimize Eq. (9), the corresponding Hopfield network will converge to a steady state. Yet, during training, this will, in general, not be the case, and positive eigenvalues of \(-\) will produce exponential growth in Eq. (15). However, Eq. (15) only holds in the linear regime of the activation function (14). Exponential growth is prevented by the symmetric clipping incorporated into the nonlinear activation function \(g(x)\) for neurons with \(|x_{i}|>c\).

In the linear regime, the overall network dynamics is represented by the square matrix \(_{t}\{(-)t\}\), which for linear autoencoders we seek to decompose into its non-square constituent parts: encoder \(\) and decoder \(\). We achieve this by treating the encoder and decoder as separate Hopfield networks, as shown in Fig. (1)(g), each with their own energy function. The encoder settles into an equilibrium representing the latent vector \(\) without taking into account the decoder. \(\) is then used as a fixed input to the decoder which then settles into its own equilibrium. The decoder then undergoes the weakly clamped phases, and its weights are updated according to Eq. (13). The encoder weights also need to be optimized to lower the reconstruction loss at the decoder output, which is achieved by setting

\[}=_{ 0}(. }|_{^{()}_{} }-.}|_{^{()}_{ -}}), i,\] (18)

in Eq. (11), where \(^{()}_{}\) is the weakly clamped decoder equilibrium state, and Eq. (18) only pertains to neurons in the encoder output layer \(\). Equation (18) follows from the fact that it can be shown that equilibrium propagation also allows for finding the gradient of the loss with respect to the input . We note that \(\), which contains the couplings of the continuous Hopfield network, is now a \((n+r)(n+r)\) matrix on account of the number of nodes in the encoder and decoder networks. Nonetheless, the factor loading matrix \(\) can be recovered as the \(n r\) block corresponding to the nodes of the decoder output layer. The equilibrium propagation training procedure is illustrated in Fig. (1)(d)-(f) and compared to backpropagation and PCA in Fig. (1)(h).

Results

We collect real data samples \(_{i}^{n}\) from stock returns of a selection of \(n=100\) stocks in the S&P 500 index. We restrict ourselves to only \(N=100\) observations such that the sample covariance matrix has a tendency to contain significant noise. Two continuous Hopfield networks, structured as the encoder and decoder parts of a linear autoencoder, are trained using equilibrium propagation. The latent variables \([_{1},,_{N}]\) are calculated as the subset \(\) of steady-state solutions of the encoder network, while the factor loading matrix \(\) is the \(n r\) block of the decoder matrix representation \(_{t}\{(-)t\}\) corresponding to its output layer \(\). In practice, we cannot take the limit to infinity, and instead, we use a suitably large value of \(t\) such that \(\{(-)t\}\) changes minimally from \(t\) to \(t+1\). We depict the full-rank sample covariance matrix and the equilibrium propagation-based low-rank approximation in Figs. (2)(a) and (b) respectively. Figure (2)(c) then illustrates the element-wise absolute difference between these two covariance matrices. The low-rank approximation is plugged into (1) and solved for the portfolio weights \(\) using the continuous Hopfield network of Eq. (2). We minimize the portfolio variance subject to the constraint \(^{}=R\) for incremental values of \(R\). In Fig. (2)(d), we plot the corresponding variances and returns for range \(R=\). The efficient frontier is identified, and an optimal portfolio can be selected based on risk appetite.

Analog Hopfield networks can be implemented as electronic circuits  and photonic neural networks . Photonic systems operate on picosecond to femtosecond timescales as high bandwidth signals flow through a single optical waveguide. Consequently, such implementations can have dense connectivity while maintaining fast convergence times. However, physical analog platforms are subject to noise sensitivity, thermal effects, and non-idealities in circuit components which can degrade performance. In addition, real-world portfolio optimization problems often involve complex constraints such as transaction costs, market liquidity, regulatory requirements, and cardinality constraints. While some of these can be readily incorporated into the objective function (4), for example, an \(^{1}\)-norm can enforce sparsity to satisfy a cardinality constraint, others take more complex forms. To address the limitations, a hybrid approach that combines analog Hopfield networks with digital computing could be explored.

## 8 Conclusions

This paper introduces a fully analog pipeline for portfolio optimization problems. Starting with raw data samples, the proposed pipeline leverages the energy-efficient analog operation of continuous Hopfield networks to calculate optimal portfolio weights. The analog pipeline distinguishes itself from traditional digital methods by its speed and scalability, with applications in time-sensitive domains such as high-frequency trading. At the heart of the pipeline are continuous Hopfield networks, used in two separate applications: autoencoder neural networks and minimum variance portfolios. By shifting to analog architectures, we reduce the reliance on binary logic operations typical of digital systems, paving the way for a more energy-efficient approach to computation. This efficiency can reduce power consumption in data centers and other computing environments, addressing the growing energy demands of digital computing. Specifically, companies can reduce their energy consumption while optimizing large portfolios as part of their risk management processes.

Figure 2: (a) The sample covariance matrix \(\) for \(n=100\) financial stocks selected from the S&P 500 index using \(N=100\) time series samples. (b) The \(r=10\) low-rank approximation \(^{}\) of the covariance matrix, as calculated by training a continuous Hopfield network via equilibrium propagation. (c) The element-wise absolute difference between the sample covariance matrix and its low-rank approximation. (d) The hyperbola in variance-return space for possible optimal portfolios. Each point along the hyperbola is calculated by solving (1) for a specific return value \(R\).