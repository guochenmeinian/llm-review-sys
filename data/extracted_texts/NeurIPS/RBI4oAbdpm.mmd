# Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale Generalization

Fu Luo\({}^{1}\)  Xi Lin\({}^{2}\)  Fei Liu\({}^{2}\)  Qingfu Zhang\({}^{2}\)  Zhenkun Wang\({}^{1}\)

\({}^{1}\) Southern University of Science and Technology

\({}^{2}\) City University of Hong Kong

luof2023@mail.sustech.edu.cn, {xi.lin, fliu36-c}@my.cityu.edu.hk,

qingfu.zhang@cityu.edu.hk, wangzhenkun90@gmail.com

Equal contributorsCorresponding author

###### Abstract

Neural combinatorial optimization (NCO) is a promising learning-based approach for solving challenging combinatorial optimization problems without specialized algorithm design by experts. However, most constructive NCO methods cannot solve problems with large-scale instance sizes, which significantly diminishes their usefulness for real-world applications. In this work, we propose a novel Light Encoder and Heavy Decoder (LEHD) model with a strong generalization ability to address this critical issue. The LEHD model can learn to dynamically capture the relationships between all available nodes of varying sizes, which is beneficial for model generalization to problems of various scales. Moreover, we develop a data-efficient training scheme and a flexible solution construction mechanism for the proposed LEHD model. By training on small-scale problem instances, the LEHD model can generate nearly optimal solutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with up to 1000 nodes, and also generalizes well to solve real-world TSPLib and CVRPLib problems. These results confirm our proposed LEHD model can significantly improve the state-of-the-art performance for constructive NCO. The code is available at https://github.com/CIAM-Group/NCO_code/tree/main/single_objective/LEHD.

## 1 Introduction

Combinatorial optimization (CO) holds significant practical value across various domains, such as vehicle routing , production planning , and drug discovery . Due to the NP-hardness and the presence of numerous complex variants, solving CO problems remains an extremely challenging task . In the past few decades, many powerful algorithms have been proposed to tackle different CO problems, but they mainly suffer from two major limitations. Firstly, solving each new problem requires extensive domain knowledge to design a proper algorithm by experts, which could lead to a significant development cost. In addition, these algorithms usually require an excessively long execution time due to the NP-hardness of CO problems . These limitations make the classical algorithms undesirable and impractical for many real-world applications.

Recently, many learning-based neural combinatorial optimization (NCO) methods have been proposed to solve CO problems without handcrafted algorithm design. These methods build neural network models to generate the solution for given CO problem instances, which can be trained by supervised learning (SL)  or reinforcement learning (RL) . Although these methods can achieve promising performance onsmall-scale problems, they perform poorly on solving large-scale problems. Due to the NP-hardness of large-scale problems, the SL-based methods struggle to obtain enough high-quality solutions as labeled training data. Meanwhile, the RL-based methods could suffer from the critical issues of sparse rewards [47; 15] and device memory limitations for solving large-scale problems. Therefore, it is impractical to directly train the NCO model on large-scale problem instances. One feasible approach is to train the NCO model on small-scale problems and then generalize it to solve large-scale problems. However, the current purely learning-based constructive NCO methods have a very poor generalization ability, which diminishes their usefulness in solving large-scale real-world problems.

The current constructive NCO models typically have a Heavy Encoder and Light Decoder (HELD) structure, which could be an underlying reason for their poor generalization ability. The HELD-based model aims to learn the embeddings of all nodes via a heavy encoder in one shot and then sequentially construct the solution with the static node embeddings via a light decoder. This one-shot embedding learning may incline the model to learn scale-related features to perform well on small-scale instances. When the model generalizes to large-scale problem instances, the learned scale-related features may hinder the model from capturing the necessary relations among a significantly larger number of nodes. This work proposes a constructive NCO model with a novel Light Encoder and Heavy Decoder (LEHD) structure to tackle this issue. Instead of one-shot embedding learning, our proposed LEHD-based model learns to dynamically capture the relationships among the current partial solution and all the available nodes at each construction step via the heavy decoder. As the size of the available nodes varies with construction steps, the model tends to learn scale-independent features. Moreover, the model can iteratively adjust and refine the learned node relationships during the training. Therefore, it could be less sensitive to the instance size and has much better generalization performance on large-scale problem instances.

It becomes impractical to train the proposed LEHD model with RL due to the huge memory and computational cost of the heavy decoder structure. In this paper, we proposed a data-efficient training scheme, called _learn to construct partial solution_, to train the LEHD model in a supervised manner. With this scheme, the model learns to reconstruct partial solutions during the optimization process, which can be treated as a kind of data augmentation for robust model training. Finally, similar to the training process, we propose a flexible solution construction mechanism called _Random Re-Construct (RRC)_ for efficient active improvement at the inference stage, which can significantly improve the solution quality with iterative local reconstructions.

Our contributions can be summarized as follows:

* We propose a novel Light Encoder and Heavy Decoder (LEHD) model for generalizable neural combinatorial optimization. By only training on small-scale problem instances, the proposed LEHD model can achieve robust and promising performance on problems with much larger sizes.
* We develop a data-efficient training scheme and a flexible solution construction mechanism for the proposed LEHD model. The data-efficient training scheme enables LEHD to be trained efficiently via supervised learning, while the solution construction mechanism can continuously improve the solution quality through a customized inference budget.
* Our purely learning-based constructive method can achieve state-of-the-art performance in solving TSP and CVRP at various scales up to size 1000, and also generalizes well to solve real-world TSPLib/CVRPLib problems.

## 2 Related Work

Constructive NCO with Balanced Encoder-DecoderIn their seminal work, Vinyals et al.  propose the Pointer Network as a neural solver to directly construct solutions for combinatorial optimization problems in an autoregressive manner. This model has a balanced encoder-decoder structure where both the encoder and decoder are recurrent neural networks (RNNs) with the same number of layers. The original Pointer Network is trained by supervised learning, while Bello et al.  proposes an efficient reinforcement learning method for NCO model training. Some Pointer Network variants have been proposed to tackle different combinatorial optimization problems . However, these models can only solve small-scale problem instances with sizes up to 100 and have poor generalization performance.

Constructive NCO with Heavy Encoder and Light DecoderKool et al.  and Deudon et al.  leverage the Transformer architecture  to design more powerful NCO models. The Attention Model (AM) proposed by Kool et al.  has a Heavy Encoder and Light Decoder (HELD) structure with three attention layers in the encoder and one layer in the decoder. This model can obtain promising performance on various small-scale problems with no more than 100 nodes. Since then, AM has become a typical model choice, and many AM variants have been proposed for constructive NCO [53; 29; 54; 30; 24]. Among them, POMO proposed by Kwon et al.  is an AM model with a more powerful learning and inference strategy based on multiple optimal policies. The POMO model has a heavy encoder with six attention layers and a light one-layer decoder. It can achieve remarkable performance on small-scale problems with up to 100 nodes.

However, these constructive models with heavy encoder and light decoder structures still have a very poor generalization performance on problem instances with larger sizes, even for those with up to 200 nodes . Directly training these models on the large-scale problem is also very difficult if not infeasible . Different methods have been proposed to enhance the generalization ability for constructive NCO models in the inference stage, such as Efficient Active Search (EAS)  and Simulation-guided Beam Search (SGBS) . While these methods can improve the constructive NCO model's generalization performance on problems with up to size 200, they struggle to solve problems with larger scales.

Very recently, a few approaches have been proposed to use the AM model to tackle large-scale TSP instances. Pan et al.  propose a Lower-Level Model that learns to construct the solution of sub-problems obtained by an Upper-Level Model. Another method proposed by Cheng et al.  uses an AM model to learn to reconstruct segments of a given TSP solution and selects the most improving segment to optimize it. However, these methods heavily rely on specialized designs for TSP by human experts, and cannot be used to solve other problems such as CVRP. In a concurrent work, Drakulic et al.  propose a novel Bisimulation Quotienting (BQ) method for generalizable neural combinatorial optimization by reformulating the Markov Decision Process (MDP) of the solution construction. Our proposed LEHD model has a different motivation and model structure from BQ, and a comprehensive comparison is provided in the experiment section.

Non-Constructive NCO MethodsIn addition to constructive NCO, there are also other learning-based approaches that work closely with search and improvement methods [33; 6; 18; 21]. Joshi et al.  propose a graph convolutional network to predict the heat map of each edge's probability in the optimal solution for a TSP instance. Afterward, approximate solutions can be obtained via the heat map guided beam search , Monte Carlo tree search (MCTS) , dynamic programming , and guided local search . The heatmap-based approach was originally proposed to solve small-scale problems, and some recent works generalize it for solving large-scale TSP instances [13; 42]. However, they heavily rely on the carefully expert-designed MCTS strategy for TSP  and cannot be used to solve other problems.

Learning-augmented methods can also be applied to improve and accelerate heuristic solvers via operation selection [6; 35; 9], guided improvement [17; 5; 55] and problem decomposition [44; 32]. Many improvement-based methods have also been proposed to iteratively improve a feasible initial solution [3; 52; 36]. However, these methods typically rely on human-designed heuristic operators or more advanced solvers [14; 16] for solving different problems. In this work, we mainly focus on the purely learning-based NCO solver without expert knowledge.

## 3 Model Architecture: Light Encoder and Heavy Decoder

In this section, we propose a novel NCO model with the Light Encoder and Heavy Decoder (LEHD) structure to tackle the critical issue regarding large-scale generalization.

### Encoder

For a problem instance \(\) with \(n\) node features \((_{1},,_{n})\) (e.g., the coordinates of \(n\) cities), a constructive model parameterized by \(\) generates the solution in an autoregressive manner, i.e., it constructs the solution by selecting nodes one by one. Our LEHD-based model consists of a light encoder and a heavy decoder, as shown in Figure 1. The light encoder has one attention layer, and the heavy decoder has \(L\) attention layers. Given the problem instance with node features\(=(_{1},,_{n})\), the light encoder transforms each node features \(_{i}\) to its initial embedding \(_{i}^{(0)}\) through a linear projection. The initial embeddings \(\{_{1}^{(0)},,_{n}^{(0)}\}\) are then fed into one attention layer to get the node embedding matrix \(H^{(1)}=(_{1}^{(1)},,_{n}^{(1)})\).

Attention layerThe attention layer comprises two sub-layers: the multi-head attention (MHA) sub-layer and the feed-forward (FF) sub-layer . Different from generic NCO models such as AM , the normalization is removed from our model to enhance generalization performance (see Appendix A). Let \(H^{(l-1)}=(_{1}^{(l-1)},,_{n}^{(l-1)})\) be the input of the \(l\)-th attention layer for \(l=1,,L\), the output of the attention layer in terms of the \(i\)-th node is calculated as:

\[}_{i}^{(l)} =_{i}^{(l-1)}+(_{i}^{(l-1)},H^{(l -1)}),\] (1) \[_{i}^{(l)} =}_{i}^{(l)}+(}_{i}^{(l)}).\]

We denote this embedding process as \(H^{(l)}=(H^{(l-1)})\).

### Decoder

The decoder sequentially constructs the solution in \(n\) steps by selecting node by node. In the \(t\)-th step for \(t\{1,,n\}\), the current partial solution can be written as \((x_{1},,x_{t-1})\), the first selected node's embedding is denoted as \(_{x_{1}}^{(1)}\), the embedding of the node selected in the previous step is denoted as \(_{x_{t-1}}^{(1)}\), and the embeddings of all available nodes is denoted by \(H_{a}=\{_{i}^{(1)} i\{1,,n\}\{x_{1},,x_{ t-1}\}\}\). Since the decoder has \(L\) attention layers, the \(t\)-th construction step of LEHD can be described as:

\[^{(0)} =(W_{1}_{x_{1}}^{(1)},W_{2}_{ x_{t-1}}^{(1)},H_{a}),\] (2) \[^{(1)} =(^{(0)}),\] \[\] \[^{(L)} =(^{(L-1)}),\] \[u_{i} =W_{O}}_{i}^{(L)},&i 1 2\\ -,&,\] \[^{t} =(),\]

where \(W_{1},W_{2},W_{O}\) are learnable matrices. The matrices \(W_{1}\) and \(W_{2}\) are used to re-calculate the embeddings of the starting node (i.e., the node selected in the previous step) and the destination node (i.e., the node selected in the first step), respectively. The matrix \(W_{O}\) is used to transform the relation-denoting embedding matrix \(^{(L)}\) into a vector \(\) for the purpose of calculating the selection probability \(^{t}\). The most suitable node \(x_{t}\) is selected based on \(^{t}\) at each decoding step \(t\). Finally, a complete solution \(=(x_{1},,x_{n})^{}\) is constructed by calling the decoder \(n\) times.

For the HELD model such as AM , the heavy encoder with \(L\) layers outputs the node embedding matrix as \(H^{(L)}=(_{1}^{(L)},,_{n}^{(L)})\). The average of all nodes' embeddings (i.e., \(_{i=1}^{n}_{i}^{(L)}\)), the

Figure 1: The structure of our proposed LEHD model, which has a single-layer light encoder and a heavy decoder with \(L\) attention layers.

starting node's embedding (i.e., \(_{x_{t-1}}^{(L)}\)), the destination node's embedding (i.e., \(_{x_{1}}^{(L)}\)) are contacted to form the context node embedding (i.e., \(_{c}^{(0)}\)). Thereafter, the light decoder takes the context node embedding and the embeddings of all nodes (i.e., \(H^{(L)}\)) as input, and computes the selection probability through an MHA operation, the compatibility calculation, and the softmax function, i.e.,

\[_{c}^{(1)}&=( _{c}^{(0)},H^{(L)}),\\ u_{i}&=10_{c}^{(1)})^{T}W_{E}_{i}^{(L)}}{d},&i x_{1:t-1}\\ -,&,\\ ^{t}&=(),\] (3)

where \(W_{C}\) and \(W_{E}\) are learnable matrices, \(d\) is a parameter determined by the embedding dimension. Since the HELD model's decoder only has a static node embedding matrix \(H^{(L)}\), the relationships among the nodes it captures are not updated throughout the decoding process. In other words, the HELD model's performance relies heavily on the quality of the static node embedding matrix. When the problem size becomes larger, the ability of the static node embedding matrix to represent the relationships among all nodes becomes worse, resulting in the poor generalization performance of the model.

In our LEHD model, the heavy decoder dynamically re-embeds the embeddings of the starting node, destination node, and available nodes via \(L\) attention layers, thus updating the relationships among the nodes at each decoding step. Such a dynamic learning strategy enables the model to adjust and refine its captured relationships between the starting/destination and available nodes. In addition, as the size of the nodes varies during the construction steps, the model tends to learn the scale-independent features. These good properties enable the model to dynamically capture the proper relationships between the nodes, thereby making more informed decisions in the node selection on problem instances of various sizes.

## 4 Learn to Construct Partial Solution

The constructive NCO aims to construct the solution node-by-node using the decoder. The heavy decoder of our LEHD model can result in a higher computational cost than that of the HELD model at each construction step. Whereas the RL training method needs to generate the complete solution before computing the reward, which implies it requires significantly huge memory and computational costs. Furthermore, RL suffers from the challenging issue of sparse reward, especially for problems with large sizes.

According to Yao et al. , data augmentation (DA) can significantly reduce the number of required high-quality solutions (i.e., labels) for SL training, and DA-based SL can even outperform RL regarding solution accuracy and generalization performance. Operations based on the property of multiple optimality  and optimality invariance  are the most commonly used DA methods in NCO. In this work, we develop an efficient DA-based SL training scheme also based on the property of optimality invariance.

For each training data (i.e., a set of nodes), its label is a sequence of all the nodes (i.e., a valid tour). According to the property of optimality invariance, the partial solution of the optimal solution must

Figure 2: Examples of generating partial solution for TSP and CVRP. For the TSP instance, its optimal solution is , and a partial solution is randomly sampled as . For the CVRP instance, its optimal solution is , and a partial solution  is randomly sampled. We impose a restriction for CVRP that the partial solution must end at the depot.

also be optimal. Therefore, we can randomly sample labeled partial solutions with various sizes and different directions from each labeled data, thus greatly enriching our training set. Based on these characteristics, we propose a training scheme called _learning to construct partial solutions_. The model learns to construct optimal partial solutions of various sizes and random directions, thereby resulting in a more efficient and robust training process.

### Generate Partial Solutions during the Training Phase

For a routing problem instance \(\) with \(n\) nodes \((_{1},,_{n})\), its optimal solution can be represented by a specific node sequence \(\) (also called the tour). The partial solution \(_{sub}\) is a consecutive subsequence sampled from \(\) with a random size and direction. In this work, we let each partial solution have a length with \(w\) sampled from the discrete uniform distribution \(([4,|V|])\) where \(|V|\) is the number of nodes for each TSP/CVRP instance, since a problem with size less than \(4\) is trivial to solve. Each partial solution \(_{sub}\) is one augmented data point in our method. Two examples of generating partial solutions for TSP and CVRP are provided in Figure 2.

### Learn to Construct Partial Solutions via Supervised Learning

The model learns to construct the partial solution node by node. The first node of \(_{sub}\) is the starting node, the last node of \(_{sub}\) is the destination node, and the remaining nodes constitute the available nodes to be selected by the model. For the example \(_{sub}=\), node \(6\) is the starting node, node \(1\) is the destination node, and nodes \(3,5,4\) are available nodes.

In each training step, the model provides each available node \(_{i}\) with a probability \(p_{i}\) of being selected. Meanwhile, the label \(_{sub}\) tells whether the node \(_{i}\) should be chosen in the current step (i.e., \(y_{i}=1\) or \(0\)). The cross-entropy loss \(loss=-_{i=1}^{n}y_{i}(p_{i})\) is employed to measure the error made by the current model, where \(u\) is the number of available nodes. Then we can update the model parameters by a gradient-based algorithm (e.g., Adam) with respect to the loss. Throughout the training process, the number of available nodes gradually decreases, and the starting node dynamically shifts to the node selected in the previous step while the destination node remains constant. The training epoch ends when there are no more nodes available. The next epoch starts with new augmented data.

### Generate the Complete Solution during the Inference Phase

During the inference phase, our proposed LEHD model employs a greedy step-by-step approach to construct the whole solution for the given instance \(\). In the beginning, a single node is randomly selected to serve as the destination node and also the initial starting node. The remaining nodes constitute the set of available nodes that the model can select step-by-step. Once a node is selected, it will be treated as the new starting node and removed from the set of available nodes, i.e., the starting node is dynamically shifting while the destination node remains constant. When no more available nodes exist, the whole solution is generated. In this way, LEHD can easily construct solutions for problems of various sizes as well as unseen large-scale problems.

## 5 Random Re-Construct for Further Improvement

The constructive model has an inductive bias, which means it could construct a better solution by following its preferred direction. Similarly, different starting and destination nodes will lead to different solution quality since the model may perform better when starting from some well-learned local patterns. The tour generated via greedy search could be not optimal and contain multiple suboptimal local segments (e.g., partial solutions). Therefore, rectifying these suboptimal segments during the inference phase can effectively enhance the overall solution quality.

Our model stems from learning to construct partial solutions, making it appropriate for iteratively reconstructing partial solutions from different directions and different starting and destination nodes. It naturally leads to our proposed flexible construction mechanism, _Random Re-Construct_(RRC). Specifically, being the same as generating the partial solution during training, RRC randomly samples a partial solution from the initial solution and restructures it to obtain a new partial solution. If the new partial solution is superior, it replaces the old one. This iterative process can enhance the solution quality within a stipulated time budget.

Experiment

In this section, we empirically compare our proposed LEHD model with other learning-based and classical solvers on TSP and CVRP instances with various sizes and distributions.

Problem SettingWe follow the standard data generation procedure of the previous work  to generate TSP and CVRP datasets. The training sets consist of one million instances for TSP100 and CVRP100, respectively. The TSP test set includes 10,000 instances with 100 nodes and 128 instances for each of 200, 500, and 1000 nodes, respectively. Similarly, the CVRP test set is constructed with the same number of instances. We obtain optimal solutions for the TSP training set with the Concorde solver  and obtain optimal solutions for the CVRP training set with HGS . The training and test datasets can be downloaded from Google Drive 3 or Baidu Cloud 4.

Model SettingFor our LEHD model, the embedding dimension is set to 128, and the number of attention layers in the decoder is set to 6. In each attention layer, the head number of MHA is set to 8, and the dimension of the feed-forward layer is set to 512. In all experiments, we train and test our LEHD models using a single NVIDIA GeForce RTX 3090 GPU with 24GB memory.

TrainingBoth the TSP model and CVRP model are trained on one million instances of size 100, respectively. The optimizer is Adam  with an initial learning rate of 1e-4. The value of the learning rate decay is set to 0.97 per epoch for the TSP model and 0.9 per epoch for the CVRP model. With a batch size of 1024, we train the TSP model for 150 epochs and the CVRP model for 40 epochs since it converges much faster.

BaselinesWe compare our method with **(1) Classical Solvers:** Concorde , LKH3 , HGS , and OR-Tools ; **(2) Constructive NCO:** POMO , MDAM , EAS , SGBS , and BQ ; **(3) Heatmap-based Method:** Att-GCN+MCTS .

Metrics and InferenceWe report the optimality gap and inference time for all methods. The optimality gap measures the difference between solutions achieved by different learning and non-learning-based methods and the optimal solutions obtained using Concorde for TSP and LKH3 for CVRP. Since the classical solvers are run on a single CPU, their reported inference times are not directly comparable to those of the learning-based methods executed on GPU.

For MDAM, POMO, SGBS, and EAS, we directly run their source code with default settings on our test set. For Att-GCN+MCTS, we report their original results for the corresponding setting. For BQ, following the settings described in the original paper, we reproduce and train the BQ model by ourselves and report the obtained results on our test set. For our proposed LEHD model, we report both the results for greedy inference as well as for Random Re-Construct (RRC) with various computational budgets.

### Experimental Results

The main experimental results on uniformly distributed TSP and CVRP instances are reported in Table 1. For TSP, our proposed LEHD method can obtain good greedy inference performance with a very fast inference time on instances of all sizes. With only 100 RRC iterations, LEHD can significantly outperform all other learning-based methods with a reasonable inference time. If we have a larger budget of more than 500 RRC iterations, LEHD can achieve very promising performance for all instances, of which the gap is nearly optimal for TSP100 and TSP200, less than \(0.2\%\) for TSP500, and around \(0.8\%\) for TSP1000.

For CVRP, LEHD can also achieve promising greedy inference performance for all instances. With 300 RRC iterations, LEHD can outperform most learning-based methods on all CVRP instances, except for the EAS method on CVRP100, which requires a much longer inference time. The EAS's performance significantly decreases for solving larger instances such as CVRP500, and we fail to obtain a result for EAS on CVRP1000 with a reasonable budget. SGBS struggles with poor generalization and long inference time for solving large-scale instances. LEHD can also outperform 

[MISSING_PAGE_FAIL:8]

LKH3 on CVRP100-CVRP500 with a budget of 500 RRC iterations and can achieve an around \(1\%\) gap to LKH3 on CVRP1000 with \(1000\) RCC iterations. To the best of our knowledge, our method is the first purely learning-based NCO method that can outperform LKH3 on CVRP200 and CVRP500.

Table 2 shows the test results on real-world TSPLib  and CVRPLib  instances with different sizes and distributions. We report the results with greedy inference and 1000 RRC iterations for our proposed LEHD method. It is clear that LEHD has a good greedy inference performance and can significantly outperform POMO and BQ on all instances with 1000 RRC iterations. These results demonstrate the robust generalization ability of LEHD.

### Ablation Study

Heavy Decoder vs. Heavy EncoderWe compare the performance of models with the Heavy Encoder structure (POMO) and the Heavy Decoder structure (LEHD). We also train POMO with SL on TSP100 and report the result in Table 3. According to the results, POMO trained by SL can also reach a good training performance on TSP100 while it still performs poorly on large-scale problems. Therefore, the promising generalization performance of our proposed method does come from the heavy decoder structure rather than the SL training.

Supervised Learning vs. Reinforcement LearningIn Table 4, we conduct a comparison with reinforcement learning and supervised learning for training our proposed LEHD model. Due to the high computational cost, the reinforcement learning method with the POMO strategy cannot converge in a reasonable time. Therefore, we use each method to train a LEHD model separately on TSP50 with the same computational budget. The results in Table 4 confirm that our proposed LEHD model is more suitable to be trained by the supervised learning method.

The Effect of RRCWe also conduct comparisons with POMO with random sampling (POMO-Sample100) as well as POMO with RRC (POMO-RRC100) to clearly present the advantages of LEHD and RRC.

The experimental results are shown in Table 5, and we have the following two main observations:

    & TSP50 & TSP100 & TSP200 & TSP500 & TSP1000 \\  RL & 5.372\% & 7.891\% & 12.581\% & 25.377\% & 46.441\% \\ SL & **0.375\%** & **0.789\%** & **1.545\%** & **3.500\%** & **6.566\%** \\   

Table 4: Effect of reinforcement learning and supervised learning on training the LEHD model with 10K testing instances for TSP50/100 and 128 testing instances for TSP200/500/1000.

    & TSP100 & TSP200 & TSP500 & TSP1000 \\  POMO augx8 SL & **0.571\%** & 3.970\% & 20.418\% & 34.419\% \\ LEHD greedy SL & 0.577\% & **0.859\%** & **1.560\%** & **3.168\%** \\   

Table 3: Comparison of POMO and LEHD with the same SL training method.

    &  &  \\  &  &  &  &  \\  Concorde & 0.000\% & 34m & 0.000\% & 23m & 0.000\% & 4h & 0.000\% & 61h \\  POMO augx8 & 0.134\% & 1m & 1.459\% & 0.6m & 21.948\% & 8m & 40.551\% & 1.1h \\ POMO augx8-sample100 & 0.080\% & 1.7h & 1.609\% & 1.2h & 37.285\% & 16h & 82.015\% & 117h \\ POMO augx8-RRC100 & 0.115\% & 2m & 1.283\% & 1.6m & 11.900\% & 11m & 25.378\% & 1.2h \\ POMO augx8-RRC1000 & 0.075\% & 12m & 0.820\% & 8m & 6.753\% & 29m & 16.261\% & 2.1h \\  LEHD greedy & 0.577\% & 0.4m & 0.849\% & 0.2m & 1.585\% & 2.1m & 3.089\% & 13m \\ LEHD RRC & 100 & 0.0114\% & 13.7m & 0.053\% & 6.5m & 0.357\% & 58m & 1.195\% & 5.3h \\  & 1000 & **0.0016\%** & 2.2h & **0.015\%** & 1h & **0.179\%** & 9.5h & **0.735\%** & 57h \\   

Table 5: Comparison of POMO and LEHD with random sampling and RRC methods.

* **POMO-RRC > POMO-Sample**: The random sampling strategy is inefficient in improving POMO's solution quality, especially for large-scale problems. In contrast, our proposed RRC can efficiently improve POMO's performance at inference time.
* **LEHD-RRC > POMO-RRC**: Our proposed LEHD model structure provides enough model capacity for learning to construct partial solutions for different sizes. It is crucial for the strong generalization ability to large-scale problems.

### Comparison with Search-based/Improvement-based Methods

Recently, Cheng et al.  and Pan et al.  propose two learning-based methods which can tackle large-scale TSP instances. However, these two methods are search-based/improvement-based approaches that require powerful solvers like LKH3 or specifically designed heuristics, and can only tackle TSP but not other VRP variants. In this work, we propose a purely learning-based construction method to tackle the large-scale TSP/VRP instances, and hence mainly compare with other construction-based methods in the original paper.

We conduct a comparison with these methods for a more comprehensive experimental study. The results are reported in Table 6 and Table 7. Our proposed method clearly outperforms those methods in terms of both performance and running time. It highlights the effectiveness of our proposed LEHD+RRC as a purely learning-based method to tackle large-scale problems.

## 7 Conclusion, Limitation, and Future Work

ConclusionIn this work, we propose a novel LEHD model for generalizable constructive neural combinatorial optimization. By leveraging the Light Encoder and Heavy Decoder (LEHD) model structure, the LEHD model achieves a strong and robust generalization ability as a purely learning-based method. We also develop a learn to construct partial solution strategy for efficient model training, and a flexible random solution reconstruction mechanism for online solution improvement with customized computational budgets. Extensive experimental comparisons with other representative methods on both synthetic and real-world instances fully demonstrate the promising generalization ability of our proposed LEHD model. Since the generalization ability is one crucial issue for the current constructive NCO solver, we believe LEHD can provide valuable insights and inspire follow-up works to explore the heavy decoder structure for powerful NCO model design.

Limitation and Future WorkAlthough with a strong generalization performance, the current LEHD model can only be properly trained by supervised learning. It could be interesting to develop an efficient reinforcement learning-based method for LEHD model training. Another promising future work is to design a powerful learning-based method for more efficient partial solution reconstruction.

    &  \\  & TSP200 &  &  \\  Concorde & 0.000\% & 3m & 0.000\% & 32m & 0.000\% & 7.8h \\  SO-mixed & 0.636\% & 21m & 2.401\% & 32m & 2.800\% & 56m \\  LEHD greedy & 0.859\% & 3s & 1.560\% & 0.3m & 3.168\% & 1.6m \\ LEHD RRC100 & 0.0761\% & 1.2m & 0.343\% & 8m & 1.218\% & 43m \\   

Table 6: Comparison with SO-mixed . The results of the SO-mixed method are directly obtained from the original paper.

    & TSP1000 (128 instances) \\  Concorde & 0.000\% & 7.8h \\  H-TSP with LKH-3 & 4.06\% & 7.5m \\  LEHD greedy & 3.168\% & 1.6m \\ LEHD RRC100 & 1.218\% & 43m \\   

Table 7: Comparison with H-TSP . The results of the H-TSP method are directly obtained from the original paper.