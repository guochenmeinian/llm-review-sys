# Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing

Xiangyu Sun

Simon Fraser University

xiangyu_sun@sfu.ca &Oliver Schulte

Simon Fraser University

oschulte@cs.sfu.ca

###### Abstract

A fundamental problem of causal discovery is cause-effect inference, learning the correct causal direction between two random variables. Significant progress has been made through modelling the effect as a function of its cause and a noise term, which allows us to leverage assumptions about the generating function class. The recently introduced heteroscedastic location-scale noise functional models (LSNMs) combine expressive power with identifiability guarantees. LSNM model selection based on maximizing likelihood achieves state-of-the-art accuracy, when the noise distributions are correctly specified. However, through an extensive empirical evaluation, we demonstrate that the accuracy deteriorates sharply when the form of the noise distribution is misspecified by the user. Our analysis shows that the failure occurs mainly when the conditional variance in the anti-causal direction is smaller than that in the causal direction. As an alternative, we find that causal model selection through residual independence testing is much more robust to noise misspecification and misleading conditional variance.

## 1 Introduction

Distinguishing cause and effect is a fundamental problem in many disciplines, such as biology, healthcare and finance [31; 8; 13]. Randomized controlled trials (RCTs) are the gold standard for finding causal relationships. However, it may be unethical, expensive or even impossible to perform RCTs in real-world domains [20; 18]. Causal discovery algorithms aim to find causal relationships given observational data alone. Traditional causal discovery algorithms can only identify causal relationships up to Markov equivalence classes (MECs) [26; 10; 3]. To break the symmetry in a MEC, additional assumptions are needed [20; 22], such as the type of functional dependence of effect on cause. Structural causal models (SCMs) specify a functional class for the causal relations in the data [17; 20]. In this work, we focus on one particular type of SCM called location-scale noise models (LSNMs) [29; 11; 30; 28; 9]:

\[Y:=f(X)+g(X) Z_{Y}\] (1)

where \(X\) is the cause, \(Y\) is the effect, written \(X Y\), and \(Z_{Y}\) is a latent noise variable independent of \(X\) (i.e., \(X\!\!\! Z_{Y}\)). The functions \(f\) and \(g\) are twice-differentiable on the domain of \(X\), and \(g\) is strictly positive on the domain of \(X\). LSNMs generalize the widely studied additive noise models (ANMs), where \(g(x)=1\) for all \(x\). ANMs assume a constant conditional variance \([Y|X]\) for different values of \(X\), which can limit their usefulness when dealing with heteroscedastic noise in real-world data. LSNMs allow for heteroscedasticity, meaning that \([Y|X]\) can vary depending on the value of \(X\). In our experiments on real-world data, methods assuming an LSNM outperform those assuming ANM.

We follow previous work on cause-effect inference and focus on the bivariate setting [29; 11; 30; 9]. There are known methods for leveraging bivariate cause-effect inference in the multivariate setting (see Appendix A). Two major methods for selecting a causal SCM direction in cause-effect inference are maximum likelihood (ML) and independence testing (IT) of residuals vs. the (putative) cause . Both have been recently shown good accuracy with LSNMs [11; 9], especially when the \(f\) and \(g\) functions are estimated by neural networks. Immer et al.  note, however, that ML can be less robust than IT, in the sense that accuracy deteriorates when the noise distribution is not Gaussian.

In this paper we investigate the robustness of ML vs. IT for LSNMs. Our analysis shows that ML cause-effect inference performs poorly when two factors coincide: (1) _Noise Misspecification_: the ML method assumes a different form of the noise distribution from the true one. (2) _Misleading Conditional Variances (CVs)_: \([Y|X]>[X|Y]\) in the data generated by causal direction \(X Y\). For example, in the experiment on synthetic datasets shown in Table 1 below, (i) changing the true noise distribution from Gaussian to uniform and (ii) manipulating \([Y|X]\), while keeping other settings equal, can decrease the rate of identifying the true causal direction from 100% to 10%. In contrast, IT methods maintain a perfect 100% accuracy. The difference occurs with and without data standardization, and with increasing sample sizes.

Both conditions (1) and (2) often hold in practice. For real-world domains, assumptions about the noise distribution can be hard to determine or verify. It is also common to have misleading CVs in real-world datasets. For example, in the Tubingen Cause-Effect Pairs benchmark , about 40% of the real-world datasets exhibit a misleading CV (see Table 7 in the appendix).

We make the following contributions to understanding location-scale noise models (LSNMs):

* Describe experiments and theoretical analysis to show that ML methods succeed when the form of the noise distribution is known. In particular, ML methods are then robust to incorrectly specifying a noise variance parameter.
* Demonstrate empirically that ML methods often fail when the form of the noise distribution is misspecified and CV is misleading, and analyze why.
* Introduce a new IT method based on an affine flow LSNM model.
* Demonstrate, both theoretically and empirically, that our IT method is robust to noise misspecification and misleading CVs.

The paper is structured as follows. We discuss related works and preliminaries in Section 2 and Section 3, respectively. Section 4 examines when and why ML methods fail. Section 5 demonstrates the robustness of the IT method. Experiments with 580 synthetic and 99 real-world datasets are given in Section 7. The code and scripts to reproduce all the results are given online 1.

## 2 Related works

_Causal Discovery._ Causal discovery methods have been widely studied in machine learning [26; 10; 3]. Assuming causal sufficiency and faithfulness, they find causal structure up to a MEC. To identify causal relations within a MEC, additional assumptions are needed [20; 22]. SCMs exploit constraints that result from assumptions about the functional dependency of effects on causes. Functional dependencies are often studied in the fundamental case of two variables \(X\) and \(Y\), the simplest MEC. Mooij et al.  provide an extensive overview and evaluation of different cause-effect methods in the ANM context. We follow this line of work for LSNMs with possibly misspecified models.

_Structural Causal Models._ Assuming a linear non-Gaussian acyclic model (LiNGAM) [24; 25], the causal direction was proved to be identifiable. The key idea in DirectLiNGAM  is that in the true causal direction \(X Y\), the model residuals are independent of \(X\). We refer to methods derived from the DirectLiNGAM approach as _independence testing_ (IT) methods. The more general ANMs [7; 19] allow for nonlinear cause-effect relationships and are generally identifiable, except for some special cases. There are other identifiable SCMs, such as causal additive models (CAM) , post-nonlinear models  and Poisson generalized linear models .

_LSNM Identifiability._ There are several identifiability results for the causal direction in LSNMs. Xu et al.  prove identifiability for LSNMs with linear causal dependencies. Khemakhem et al. show that nonlinear LSNMs are identifiable with Gaussian noise. Strobl and Lasko , Immer et al.  prove LSNMs are identifiable except in some pathological cases (see Appendix C).

_Cause-Effect Inference in LSNMs._ The generic model selection blueprint is to fit two LSNM models for each direction \(X Y\) and \(X Y\) and select the direction with a higher model score. HECI  bins putative cause values and selects a direction based on the Bayesian information criterion. BQCD  uses nonparamatric quantile regression to approximate minimum description length to select the direction. GRCI  finds the direction based on mutual information between the putative cause and the model residuals. LOCI  models the conditional distribution of effect given cause with Gaussian natural parameters. Then, it chooses the direction based on either likelihood (LOCI-M) or independence (LOCI-H). CAREFL-M  fits affine flow models and scores them by likelihood. CAREFL-M is more general than LOCI since LOCI uses a fixed Gaussian prior, whereas CAREFL-M can utilize different prior distributions. DECI  generalizes CAREFL-M to multivariate cases for ANMs. Unlike our work, none of these papers provide a theoretical analysis of noise misspecification and misleading CVs in LSNMs.

_Noise Misspecification._ Schultheiss and Buhlmann  present a theoretical analysis of model misspecification pitfalls when the data are generated by an ANM. Their results focus on model selection with Gaussian likelihood scores, which use Gaussian noise distributions. They suggest that IT-based methods may be more robust to model misspecification in ANMs. The authors also briefly discuss the complication of fitting data generated by a ground-truth ANM model with an LSNM model. Since the backward model of an ANM often takes the form of an LSNM, fitting data generated by a ground-truth ANM with an LSNM model may result in an incorrect causal direction. While their analysis examines ANM data, the ground-truth model in our work is an LSNM. The \(g()\) scale term in Equation (1), which is absent in ANMs, plays a critical role in LSNMs.

_Conditional Variance and Causality._ To the best of our knowledge, the problem of misleading CVs has not been identified nor analyzed in previous work for LSNMs. Prior studies that have focused on CVs were based on ANMs, and stated assumptions about how CVs relate to causal structure, to be leveraged in cause-effect inference [15; 1]. We do not make assumptions about CVs, but analyze them to understand why noise misspecification impairs cause-effect inference in LSNMs.

## 3 Preliminaries

In this section, we define the cause-effect inference problem and review the LSNM data likelihood.

### Problem definition: cause-effect inference

Cause-effect inference takes as input a dataset \(D\) over two random variables \(X,Y\) with \(N\) observational data pairs \((X,Y)=\{(x_{1},y_{1}),(x_{2},y_{2}),,(x_{N},y_{N})\}\) generated by a ground-truth LSNM in Equation (1). The binary output decision indicates whether \(X\) causes \(Y\) (\(X Y\)) or \(Y\) causes \(X\) (\(X Y\)). We assume no latent confounders, selection bias or feedback cycles ([14; 29; 11; 9; 30]).

Figure 1: Summary of the accuracy results for ML methods for LSNMs and ANMs with respect to noise misspecification and misleading CVs.

### Definition of maximum likelihood for LSNMs

An LSNM model for two variables \((X,Y)\) is a pair \((,P_{Z})\). The \(\) represents the direction \(X Y\) with parameter space \(f f_{},g g_{},P_{X} P_{X,}\). The \(\) represents the direction \(X Y\) with parameter space \(h h_{^{}},k k_{^{}},P_{Y} P_{Y,^{ }}\). For notational simplicity, we treat the model functions directly as model parameters and omit reference to their parameterizations. For example, we write \(f f_{}\) for a function \(f\) that is implemented by a neural network with weights \(\). We refer to \(P_{Z}\) as the model prior noise distribution.

A parameterized LSNM model defines a data distribution as follows  (Appendix B):

\[ P_{,P_{Z}}(X,Y;f,g,P_{X})=& P_{X}(X) P_{Z_{Y}}()\\ P_{,P_{Z}}(X,Y;h,k,P_{Y})=& P_{Y}(Y)  P_{Z_{X}}()\] (2)

For conciseness, we use shorter notation \(P_{,P_{Z}}(X,Y)\) and \(P_{,P_{Z}}(X,Y)\) in later sections. The ML method computes the ML parameter estimates and uses them to score the \(\) (or \(\)) model:

\[,,_{X}:=_{f,g,P_{X}} _{i=1}^{N}P_{,P_{Z}}(x_{i},y_{i};f,g,P_{X})\] (3) \[L_{,P_{Z}}(D):=_{i=1}^{N}P_{,P_{Z}}( x_{i},y_{i};,,})\] (4)

## 4 Non-identifiability of LSNMs with noise misspecification

In this section, we show that ML methods fail under noise misspecification and misleading CVs, and analyse why. Figure 1 summarizes the diverse settings considered below.

Existing identifiability results for LSNM ML methods (Appendix C) require knowing the ground-truth noise distribution. We conducted a simple experiment to show that with noise misspecification, ML model selection can fail badly even on large sample sizes. Table 1 shows results for CAREFL-M  and LOCI-M  with model prior distribution \((0,1)\). For the left half of the table, the data

   True Noise & (0,1)\)} & (-1,1)\)} \\  \(\) & 0.1 & 0.5 & 1 & 5 & 10 & 0.1 & 0.5 & 1 & 5 & 10 \\  \(}[Y|X]\) & 0.166 & 0.615 & 0.834 & 0.990 & 0.997 & 0.044 & 0.404 & 0.673 & 0.975 & 0.994 \\  \(}[X|Y]\) & 0.455 & 0.709 & 0.793 & 0.821 & 0.817 & 0.047 & 0.375 & 0.566 & 0.681 & 0.677 \\  Percentage of & & & & & & & & & & \\ Datasets With & 30\% & 50\% & 70\% & 100\% & 100\% & 30\% & 90\% & 100\% & 100\% & 100\% \\ Misleading CVs & & & & & & & & & & \\  CAREFL-M & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 0.7 & 0.6 & 0.7 & 0.1 & 0.1 \\  LOCI-M & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 0.7 & 0.6 & 0.7 & 0.1 & 0.1 \\  CAREFL-H & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 0.9 & 1.0 & 1.0 & 1.0 & 1.0 \\  LOCI-H & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 0.7 & 1.0 & 1.0 & 1.0 & 1.0 \\   

Table 1: **Accuracy** over 10 datasets generated by SCM **LSNM-sine-tanh** (definition in Appendix M) with \(N=10,000\) samples. The task is a binary decision whether \(X\) causes \(Y\) or \(Y\) causes \(X\). \(X\) denotes the ground-truth cause and \(Y\) denotes the ground-truth effect. We rewrite Equation (1) as \(Y=f(X)+ g(X) Z_{Y}\), where \(\) is a scale factor to alter the CVs. CVs are computed by binning the putative cause. We used \((0,1)\) as model prior for both CAREFL and LOCI. The suffix -_M_ denotes a ML method. The suffix -_H_ denotes the corresponding IT method (see Section 5). All the datasets are standardized to have mean 0 and variance 1.

was generated with correctly specified \(Gaussian(0,1)\) noise. In this case, both CAREFL-M and LOCI-M work well, and increasing CV in the causal direction does not affect their accuracy. For the right half of the table, the data was generated with misspecified \(uniform(-1,1)\) noise. With noise misspecification, the accuracy of both CAREFL-M and LOCI-M decreases to \(70\%\). With both noise misspecification and misleading CVs, their accuracy becomes even lower. For example, in the last column when \(}[Y|X]=0.994\) and \(}[X|Y]=0.677\), they give an accuracy of just \(10\%\).

The following results help explain why ML methods fail under noise misspecification and misleading CVs.

**Lemma 4.1**.: _For an LSNM model \(Y:=f(X)+g(X) Z_{Y}\) where \(Z_{Y}\) is the noise with mean \(\) and variance \(^{2} 0\), there exists a likelihood-equivalent LSNM Model \(Y:=f^{}(X)+g^{}(X) Z_{Y}^{}\) such that \(Z_{Y}^{}=-}{}\), \(P_{,P_{Z}}(Y|X;f,g)=P_{,P_{Z^{}}}(Y|X;f^{},g^{})\), and \(_{Z_{Y}}[Y|X]=_{Z_{Y}^{}}[Y|X]\)._

The proof is in Appendix E. Lemma 4.1 shows that for any (non-deterministic) LSNM model there is an equivalent standardized LSNM model with \([Z_{Y}]=1\).

**Theorem 4.2**.: \(}(Y|X)}{[Y|X]}<0\) _for LSNM models._

The proof is in Appendix F. Theorem 4.2 shows that the model likelihood \(P_{,P_{Z}}(Y|X)\) and the conditional variance \([Y|X]\) are negatively related (similarly for \(P_{,P_{Z}}(X|Y)\) and \([X|Y]\)).

**Corollary 4.3**.: _Let \(\) denote the causal model and \(\) denote the anti-causal model. When \([Y|X]\) increases and \([X|Y]\) decreases in the data, the log-likelihood model difference \( P_{,P_{Z}}(X,Y)- P_{,P_{Z}}(X,Y)\) decreases._

The proof is in Appendix G. Under the identifiability assumption [11; 9] that ML is consistent under correct model specification, Lemma 4.1 also implies that ML remains consistent under misspecifying the variance of the noise distribution, as long as the form of the prior distribution matches that of the noise distribution. Table (a)a in the appendix demonstrates this relationship empirically.

The overall relationship between likelihood and CV with respect to noise specification in LSNMs is as follows, illustrated in Figure 2 with actual datasets:

1. (Theorem 4.2) CV and likelihood are negatively related (Figures (a)a and (b)b), with either correctly or incorrectly specified noise distribution form.
2. (Identifiability) When the form of the noise distribution is correctly specified, the causal model always has a higher likelihood (Figure (a)a).
3. (Corollary 4.3) When the form of the noise distribution is misspecified, the anti-causal model can have a higher likelihood under misleading CVs (Figure (b)b).

_ANM vs. LSNM._ The relationship (2) is in general different for ANMs, when the noise variance is misleading (see Figure 1 and Appendix P). Proposition H.1 shows that the standardization lemma Lemma 4.1 does not apply to ANMs (confirmed by empirical results in Table (b)b in the appendix).

## 5 Robustness of independence testing

This section describes IT methods for cause-effect learning in LSNMs, including a new IT method based on affine flows. Theoretical results below explain why IT methods are robust to noise misspecification and misleading CVs in LSNMs.

### The independence testing method

Inspired by the breakthrough DirectLiNGAM approach , independence testing has been used in existing methods for various SCMs [7; 19; 28; 9]. Like ML methods (Equation (4)), IT methods fit the model parameters in both directions, typically maximizing the data likelihood (Equation (3)). The difference is in the model selection step, where IT methods select the direction with the highest degree of independence between the fitted model residuals and the putative cause.

Algorithm 1 is the pseudo-code for our IT method **CAREFL-H**. We fit the functions \(f\) and \(g\) in Equation (1), with the affine flow estimator \(\) from CAREFL-M , implemented using neural networks. For details on CAREFL-M and learning the flow transformation \(\) see Appendix I. This combination of affine flow model with IT appears to be new. Another IT method is to test the independence of both residuals  (Appendix J). We found that this performs similarly to CAREFL-H and therefore report results only for the more common DirectLiNGAM-style method.

As in previous work , we use the Hilbert-Schmidt independence criterion (HSIC)  to measure (in)dependence throughout the paper. HSIC measures the squared distance between the joint probability of the two variables and the product of their marginals embedded in the reproducible kernel Hilbert space. We have \((U,V)=0\) if and only if \(U\!\!\! V\).

### Theoretical comparison between IT and ML under noise misspecification in LSNMs

The intuition for why independence testing works is that if LSNM training is consistent, testing the independence of the putative cause and the residual will indicate the correct causal model. The next theorem provides a formal statement of this intuition.

**Theorem 5.1**.: _For data pairs \((X,Y)\) generated by an LSNM model \(X Y\), let \((X)\) denote the conditional mean estimator and \((X)\) denote the conditional standard deviation estimator. Under the consistency conditions that \((X)=[Y|X]\) and \((X)=[Y|X]\), the reconstructed noise is independent of the cause, i.e. \(_{Y}\!\!\! X\), even under noise misspecification._

Proof.: According to Equation (1),

\((X)=[Y|X]=[f(X)+g(X) Z_{Y}|X]=f(X)+g(X) [Z_{Y}|X]=f(X)+g(X)[Z_{Y}]\)

\((X)=[Y|X]=[f(X)+g(X) Z_{Y}|X]=|g(X)| [Z_{Y}|X]=g(X)[Z_{Y}]\)

Thus, \(_{Y}=(X)}{(X)}=-f(X)-g(X)[Z_{Y}]}{g(X)[Z_{Y}]}= -[Z_{Y}]}{[Z_{Y}]}\), where \([Z_{Y}]\) and \([Z_{Y}]>0\) are constants. Therefore, \(_{Y}\) and \(Z_{Y}\) are identical up to shift and scale. Since \(Z_{Y}\!\!\! X\), therefore, \(_{Y}\!\!\! X\). 

Note that the proof does not involve the specification of the noise prior distribution \(P_{Z_{Y}}\), which shows that under the consistency condition, the conclusion \(_{Y}\!\!\! X\) holds whether the noise prior distribution is misspecified or not.

Figure 2: Visualization of Table 1. First row (2a,2b): ML methods. Second row (2c,2d): IT methods. _Y-axis \(<\) 0.0:_ A ML method returns the _incorrect_ anti-causal direction. _Y-axis \(>\) 0.0:_ An IT method returns the _incorrect_ anti-causal direction. ML methods may fail under misspecification and misleading CVs (2b, when _X-axis \(>\) 1_ ). IT methods are more robust (2d).

In contrast, the likelihood of a causal model depends on the specification of the noise prior distribution \(P_{Z_{Y}}\) (Equation (2)). This explains why IT methods are more robust than ML methods under noise misspecification in LSNMs.

In the context of ANMs, Mooij et al.  provide another sufficient condition for \(_{Y}\!\!\! X\) called suitability. In Appendix K, we show how the suitability concept can be adapted for LSNMs to provide another argument for the robustness of IT methods.

## 6 Limitation of IT-based methods

Limitations of IT-based methods include the following: 1) When the noise prior distribution is correctly specified, ML-based methods can utilize this information to be more sample efficient. Conversely, since IT-based methods are less sensitive to the noise prior distribution, they require a larger sample size to infer causal direction accurately. 2) IT-based methods have higher computational cost, especially with nonlinear independence testing. 3) IT-based methods require high-capacity function estimators to model the unknown functions \(f\) and \(g\) for a good noise reconstruction.

Despite these complications, we advocate the use of IT-based methods over ML-based methods under noise misspecification and misleading CVs in LSNMs, because they are more reliable in such settings.

## 7 Experiments

On synthetic datasets, we find that across different hyperparameter choices the IT method (CAREFL-H) produces much higher accuracy than the ML method (CAREFL-M) in the difficult settings with noise misspecification and misleading CVs, and produces comparable accuracy in the easier settings without noise misspecification or misleading CVs. On real-world data where the ground-truth noise distribution is unknown, the IT method is also more robust across different hyperparameter choices.

For all experiments, we start with the same default hyperparameter values for both CAREFL-M and CAREFL-H and alter one value at a time. The default hyperparameter values are those specified in CAREFL-M  for the Tubingen Cause-Effect Pairs benchmark . Please see Appendix L for more details on default and alternative hyperparameter values. Previous work [14; 9] reported that ML methods perform better with data splitting (split data into training set for model fitting and testing set for model selection) and IT methods perform better with data recycling (the same data is used for both model fitting and selection). Therefore, we use both splitting methods: (i) CAREFL(0.8): \(80\%\) as training and \(20\%\) as testing. (ii) CAREFL(1.0): training = testing = \(100\%\). The training procedure is not supervised: no method accesses the ground-truth direction.

We use a consistent HSIC estimator with Gaussian kernels . A summary of experimental datasets is provided in Appendix Table 7. All the datasets are standardized to have mean 0 and variance 1. The datasets in Section 7.1 are generated by LSNMs and the datasets in Sections 7.2 and 7.3 are not. Consequently, the results demonstrate that the proposed method performs well not only when the ground-truth SCMs are strictly LSNMs, but also when the ground-truth SCMs are unknown or not strictly LSNMs.

### Results on synthetic LSNM data

See Appendix M for the definition of the ground-truth LSNM SCMs and details on how synthetic datasets are generated from them. The sample sizes in each synthetic dataset are 500 or 5,000. As shown in Appendix Table 7, most synthetic datasets generated by such SCMs have misleading CVs. Based on the analysis of Section 4 we formulate the following hypotheses. (i) CAREFL-M should be accurate given a correct specification on the form of noise distribution, with or without misleading CVs. (ii) With noise misspecification and mild misleading CVs, the accuracy of CAREFL-M should be reduced. (iii) With noise misspecification and severe misleading CVs, the accuracy should be very low, often below 50%. Overall, the results from the experiments confirm our hypotheses.

#### 7.1.1 Noise misspecification

We evaluate CAREFL-M and CAREFL-H against data generated with \((-1,1)\), \((1)\), \(Bernoulli(0.9)\) or \((0.5,0.5)\) noise, covered by our identifiability Theorem C.2 (except \((0.5,0.5)\)). Khemakhem et al.  empirically find that CAREFL-M with a Laplace model prior is robust with similar ground-truth noise distributions such as Gaussian and Student's t. We show that it may fail remarkably with a dissimilar distribution.

We summarize findings from the 336 settings here; the detailed results are given in Appendix Figures 6 to 17. In 289 settings (86.01%), both CAREFL-M(0.8) and CAREFL-M(1.0) select the correct causal

Table 2: Accuracy of methods on the SIM and Tübingen Cause-Effect Pairs benchmarks. For methods other than CAREFL-M and CAREFL-H, we use the best results reported in Immer et al. .

Figure 3: **Weighted accuracy** over 99 datasets from **Tübingen Cause-Effect Pairs benchmark**.

direction with less than 50% random accuracy. Furthermore, in 110 settings (32.74%) both CAREFL-M(0.8) and CAREFL-M(1.0) fail catastrophically with an accuracy of 0%. These experiments also show that the accuracy of CAREFL-M often decreases as \(N\) increases. In contrast, CAREFL-H(1.0) achieves better accuracy than CAREFL-M in 333 settings (99.11%). The accuracy of CAREFL-H(1.0) goes below 50% in only 6 settings (1.79%). The results demonstrate the robustness of the IT method under noise misspecification and misleading CVs, across different hyperparameter choices.

Appendix Table 7 and Appendix Figure 17 show that with severe misleading CVs, the accuracy of CAREFL-M is close to 0%. This is much lower than the corresponding cases with mild misleading CVs in Appendix Figures 9 and 13.

#### 7.1.2 Correct specification on the form of the noise distribution

These experiments show that CAREFL-H is comparable with CAREFL-M under correct form of noise specification, with or without misleading CVs, especially on larger datasets, as long as the affine model capacity is sufficient. We evaluate CAREFL-M and CAREFL-H against data generated with \(Gaussian(0,1)\) and \(Laplace(0,1)\) noise. The detailed results are in Appendix Figures 18 to 23. We find that CAREFL-M is more sample efficient than CAREFL-H when the model prior matches the data, which is a general pattern for ML vs. IT methods . Consistent with the suitability results in Appendix K.1, the accuracy of CAREFL-H improves with more data. For example, with \(N=500\), there are 49 out of 84 settings (58.33%) where CAREFL-M outperforms CAREFL-H(1.0). However, with \(N=5,000\), CAREFL-H(1.0) achieves similar accuracy as CAREFL-M on all datasets (except LSNM-sigmoid-sigmoid with \(Laplace(0,1)\) noise.) In addition, CAREFL-H(1.0) may underperform CAREFL-M when the number of hidden neurons, sub-flows or training epochs is low. An IT method requires more model capacity to fit the LSNM functions and produce a good reconstruction of the noise.

### Results on synthetic benchmarks

Similar to Tagasovska et al. , Immer et al. , we compare CAREFL-M and CAREFL-H against the SIM benchmark suite . SIM comprises 4 sub-benchmarks: default (SIM), with one confounder (SIM-c), low noise levels (SIM-ln) and Gaussian noise (SIM-G). In this benchmark, most datasets do not have misleading CVs (Appendix Table 7), which favors ML methods. Each sub-benchmark contains 100 datasets and each dataset has \(N=1000\) data pairs. As shown in Appendix Figure 24, CAREFL-M and CAREFL-H(1.0) achieve similar accuracy on SIM-ln and SIM-G across different hyperparameter choices. For SIM and SIM-c, CAREFL-H, especially CAREFL-H(1.0), outperforms CAREFL-M by 20%-30% in all settings. The accuracy of CAREFL-M is only about random guess (40%-60%) on SIM and SIM-c.

Table 1(a) compares CAREFL-H with SOTA methods. For each CAREFL method, we report the best accuracy obtained in Appendix Figure 24 without further tuning. CAREFL-H achieves the best accuracy on SIM and SIM-c, and achieves competitive accuracy on SIM-ln and SIM-G.

### Results on real-world benchmarks: Tubingen Cause-Effect Pairs

The Tubingen Cause-Effect Pairs benchmark  is commonly used to evaluate cause-effect inference algorithms [11; 30; 9]. To be consistent with previous work [29; 28; 9], we exclude 6 multivariate and 3 discrete datasets (#47, #52-#55, #70, #71, #105, #107) and utilize the remaining 99 bivariate datasets. As recommended by Mooij et al. , we report weighted accuracy. 40% of datasets in the benchmark feature misleading CVs. _CAREFL-H(1.0) outperforms CAREFL-M in all configurations by large margins (7%-30%)_; see Figure 3. We also compare CAREFL-H with SOTA methods (see Appendix N for hyperparameters). Table 1(b) shows that CAREFL-H achieves the SOTA accuracy (82%) and is 9% more accurate than CAREFL-M .

Furthermore, LSNM methods (i.e. LOCI, GRCI, BQCD, HECI, CAREFL) perform better than ANM methods (i.e. CAM, RESTI). The reason is that LSNM is a weaker assumption than ANM and allows for heteroscedastic noise.

Conclusion and future work

We identified a failure mode of maximum-likelihood (ML) methods for cause-effect inference in location-scale noise models (LSNMs). Our analysis shows that the failure occurs when the form of the noise distribution is misspecified and conditional variances are misleading (i.e., higher in the causal direction). Selecting causal models by independence tests (IT) is robust even in this difficult setting. Extensive empirical evaluation compared the ML method and a new IT method based on affine flows, on both synthetic and real-world datasets. The IT flow method achieves better accuracy under noise misspecification and misleading CVs, with robust performance across different hyperparameter choices. Future directions include improving the sample efficiency of IT methods, and improving the robustness of ML methods by learning the noise distribution instead of using a fixed prior.

## 9 Acknowledgments

This research was supported by a Discovery Grant from the Natural Sciences and Engineering Research Council of Canada (NSERC).