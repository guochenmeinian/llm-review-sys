# Looks Too Good To Be True:

**An Information-Theoretic Analysis of Hallucinations**

**in Generative Restoration Models**

**Regev Cohen**

**Idan Kligvasser**

**Ehud Rivlin**

**Daniel Freedman**

**Verily AI (Google Life Sciences), Israel**

regevcohen@google.com

###### Abstract

The pursuit of high perceptual quality in image restoration has driven the development of revolutionary generative models, capable of producing results often visually indistinguishable from real data. However, as their perceptual quality continues to improve, these models also exhibit a growing tendency to generate hallucinations - realistic-looking details that do not exist in the ground truth images. Hallucinations in these models create uncertainty about their reliability, raising major concerns about their practical application. This paper investigates this phenomenon through the lens of information theory, revealing a fundamental tradeoff between uncertainty and perception. We rigorously analyze the relationship between these two factors, proving that the global minimal uncertainty in generative models grows in tandem with perception. In particular, we define the inherent uncertainty of the restoration problem and show that attaining perfect perceptual quality entails at least twice this uncertainty. Additionally, we establish a relation between distortion, uncertainty and perception, through which we prove the aforementioned uncertainly-perception tradeoff induces the well-known perception-distortion tradeoff. We demonstrate our theoretical findings through experiments with super-resolution and inpainting algorithms. This work uncovers fundamental limitations of generative models in achieving both high perceptual quality and reliable predictions for image restoration. Thus, we aim to raise awareness among practitioners about this inherent tradeoff, empowering them to make informed decisions and potentially prioritize safety over perceptual performance.

Figure 1: Illustration of Theorem 3. In restoration tasks, the minimal attainable uncertainty is lower bounded by a function that begins at the inherent uncertainty \(U_{}\) of the problem (Definition 2) and gradually increases up to twice this value as the recovery approaches perfect perceptual quality.

Introduction

Restoration tasks and inverse problems impact many scientific and engineering disciplines, as well as healthcare, education, communication and art. Generative artificial intelligence [80; 38; 10] has transformed the field of inverse problems due to its unprecedented ability to infer missing information and restore corrupted data. In the realm of image restoration, the quest for high perceptual quality has led to a new generation of generative models, capable of producing outputs of remarkable realism, virtually indistinguishable from true images.

While powerful, growing empirical evidence indicates that generative models are susceptible to hallucinations , characterized by the generation of seemingly authentic content that deviates from the original input data, hindering applications where faithfulness is crucial. The root cause of hallucination lies in the ill-posed nature of restoration problems, where multiple possible solutions can explain the observed measurements, leading to uncertainty in the estimation process.

Concerns surrounding hallucinations have prompted the development of uncertainty quantification methods, designed to evaluate the reliability of generated outputs. These approaches offer crucial insights into the model's confidence in its predictions, empowering users to assess potential deviations from the original data and make informed decisions. Despite this progress, the relationship between achieving high perceptual quality and the extent of uncertainty remains an understudied area.

This paper establishes the theoretical relationship between uncertainty and perception, demonstrating through rigorous analysis that the global minimal uncertainty in generative models increases with the level of desired perceptual quality (see illustration in Figure 1). Leveraging information theory, we quantify uncertainty using the entropy of the recovery error , while we measure perceptual quality via conditional divergence between the distributions of the true and recovered images . Our main contribution are as follows:

1. We introduce a definition for the inherent uncertainty \(U_{}\) of an inverse problem, and formulate the uncertainty-perception (UP) function, seeking the minimal attainable uncertainty for a given perceptual index. We prove the UP function is globally lower-bounded by \(U_{}\) (Theorem 1).
2. We prove a fundamental trade-off between uncertainty and perception under any underlying data distribution, restoration problem or model (Theorem 1). Specifically, the entropy power of the recovery error exhibits a lower bound inversely related to the Renyi divergence between the true and recovered image distributions (Theorem 3). This shows that perfect perceptual quality requires at least twice the inherent uncertainty \(U_{}\).
3. We establish a relationship between uncertainty and mean squared error (MSE) distortion, demonstrating that the uncertainty-perception trade-off induces the well-known distortion-perception trade-off  (Theorem 4).
4. We empirically validate all theoretical findings through experiments on image super-resolution and inpainting (Section 5), covering a broad spectrum of recovery algorithms, diverse metrics and data distributions. Our experimental results for image inpainting are illustrated in Figure 2.

Figure 2: Image inpainting results. Algorithms are ordered from low to high perception (left to right). Note the corresponding increased hallucinations and distortion. See Section 5 for details.

We aim to provide practitioners with a deeper understanding of the tradeoff between uncertainty and perceptual quality, allowing them to strategically navigate this balance and prioritize safety when deploying generative models in real-world, sensitive applications.

## 2 Related Work

Recent work in image restoration has made significant strides in both perceptual quality assessment and uncertainty quantification, largely independently. Below, we outline the main trends in research on these topics, laying the foundation for our framework.

**Perception Quantification** Perceptual quality in restoration tasks encompasses how humans perceive the output, considering visual fidelity, similarity to the original, and absence of artifacts. While traditional metrics like PSNR and SSIM  capture basic similarity, they miss finer details and higher-level structures. Learned metrics like LPIPS , VGG-loss , and DISTS  offer improvements but still operate on pixel or patch level, potentially overlooking holistic aspects. Recently, researchers have leveraged image-level embeddings from large vision models like DINO  and CLIP  to capture high-level similarity. Further advancements include HyperIQA  that leverages self-adaptive hyper networks to blindly assess image quality in the wild, while LIQE  and QAlign  utilize large language models to capture high-level semantic similarity and alignment between the restored and original images. Here, we follow previous works [58; 14; 31] and adopt a mathematical notion of perceptual quality defined as the divergence between probability densities.

**Uncertainty Quantification** Uncertainty quantification techniques can be broadly categorized into two main paradigms: Bayesian estimation and frequentist approaches. The Bayesian paradigm defines uncertainty by assuming a distribution over the model parameters and/or activation functions . The most prevalent approach is Bayesian neural networks [52; 78; 34], which are stochastic models trained using Bayesian inference. To improve efficiency, approximation methods have been developed, including Monte Carlo dropout [24; 25], stochastic gradient Markov chain Monte Carlo [67; 18], Laplacian approximations  and variational inference [16; 51; 60]. Alternative Bayesian techniques encompass deep Gaussian processes , deep ensembles [7; 33], and deep Bayesian active learning . In contrast to Bayesian methods, frequentist approaches operate assume fixed model parameters with no underlying distribution. Examples of such distribution-free techniques are model ensembles [44; 59], bootstrap [36; 2], interval regression [59; 37; 83] and quantile regression [27; 64].

An emerging approach in recent years is conformal prediction [3; 70], which leverages a labeled calibration dataset to convert point estimates into prediction regions. Conformal methods require no retraining, computationally efficient, and provide coverage guarantees in finite samples . These works include conformalized quantile regression [64; 69; 6], conformal risk control [5; 8; 4], and semantic uncertainty intervals for generative adversarial networks . The authors of  introduce the notion of conformal prediction masks, interpretable image masks with rigorous statistical guarantees for image restoration, highlighting regions of high uncertainty in the recovered images. Please see  for an extensive survey of distribution-free conformal prediction methods. A recent approach  introduces a principal uncertainty quantification method for image restoration that considers spatial relationships within the image to derive uncertainty intervals that are guaranteed to include the true unseen image with a user-defined confidence probabilities. While the above studies offer a variety of approaches for quantifying uncertainty, a rigours analysis of the relationship between uncertainty and perception remains underexplored in the context of image restoration.

**The Distortion-Perception Tradeoff** The most relevant studies to our research are the work on the distortion-uncertainty tradeoff  and its follow-ups [23; 15; 13]. A key finding in  establishes a convex tradeoff between perceptual quality and distortion in image restoration, applicable to any distortion measure and distribution. Moreover, perfect perceptual quality comes at the expense of no more than 3dB in PSNR. The work in  extends this, providing closed-form expressions for the tradeoff when MSE distortion and Wasserstein-2 distance are considered as distortion and perception measures respectively. In , it is shown that the Lipschitz constant of any deterministic estimator grows to infinity as it approaches perfect perception.

This work uniquely emphasizes _uncertainty_ in image restoration, distinguishing it from distortion. While distortion measures how close a restored image is to the original, uncertainty quantifies the confidence in the restoration itself. This distinction is crucial for decision-making, as high uncertainty can hinder informed choices, complementing existing research on perceptual quality and robustness.

Problem Formulation

We adopt a Bayesian perspective to address inverse problems, wherein we seek to recover a random vector \(X^{d}\) from its observations, represented by another random vector \(Y=(X)^{d^{}}\). Here \(:^{d}^{d^{}}\) is a non-invertible degradation function, implying \(X\) cannot be perfectly recovered from \(Y\). Formally:

**Definition 1**.: _A degradation function \(\) said to be invariable if, the conditional probability \(p_{X|Y}(|y)\) is a Dirac delta function for almost every \(y\) in the support of the distribution \(p_{Y}\) of \(Y\)._

The restoration process involves constructing a estimator \(^{d}\) to estimate \(X\) from \(Y\), inducing conditional probability \(p_{|Y}\). The estimation process forms a Markov chain \(X Y\), implying that \(X\) and \(\) are statistically independent given \(Y\).

In this paper, we analyze estimators \(\) with respect to two performance criteria: perception and uncertainty. To assess perceptual quality, we follow a theoretical approach, similar to previous works [85; 14], and measure perception using conditional divergence1 between \(X\) and \(\) defined as

\[D_{v}(X,Y)_{y p_{Y}}[D_{v}p_ {X|Y=y},p_{|Y=y}],\] (1)

where \(D_{v}\) stands for general divergence function. When an estimator attains a low value of the metric above, we say it exhibits high perceptual quality. When it comes to uncertainty, there are diverse practical methods to quantify it [28; 1]. However, for our analysis, we aim to identify a fundamental understanding of uncertainty. Therefore, we adopt the concept of entropy power from information theory, which assesses the statistical spread of a random variable. For the definition of entropy power and other relevant background, we refer the reader to Appendix B. Utilizing entropy power, we formally define the inherent uncertainty intrinsic to the restoration problem as follows

**Definition 2**.: _The inherent uncertainty in estimating \(X\) from \(Y\) is defined as:_

\[U_{} N(X|Y)=e^{h(X|Y)},\]

_where \(h(X|Y)\) denotes the entropy of \(X\) given \(Y\)._

The inherent uncertainty quantifies the information irrevocably lost during observation, acting as a fundamental limit on the recovery of \(X\) from \(Y\), regardless of the estimation method. Notably, when the degradation process is invertible, this inherent uncertainty becomes zero \(U_{}=0\), reflecting the possibility of perfect recovery of \(X\) with complete confidence.

We now turn our attention to the main focus of this paper, _the uncertainty-perception_ (UP) function:

\[U(P)_{p_{|Y}}N(-X|Y)\ :\ D_{v}(X, Y) P}.\] (2)

In essence, \(U(P)\) represents the minimum uncertainty achievable by an estimator with perception quality of at least \(P\), given the side information within the observation \(Y\). In contrast to the perception-distortion function , the above objective prioritizes the information content of error signals over their mere energy, and its minimization promotes concentrated errors for robust and reliable predictions. The following example offers intuition into the typical behavior of this function.

**Example 1**.: _Consider \(Y=X+W\) where \(X(0,1)\) and \(W(0,^{2})\) are independent. Let the perception measure be the symmetric Kullback-Leibler (KL) divergence \(D_{}\) and assume stochastic estimators of the form \(=[X|Y]+Z\) where \(Z(0,_{z}^{2})\) is independent of \(Y\). As derived in Appendix C, the UP function admits a closed form expression in this case, given by_

\[U(P)=N(X|Y)1+P+1--1}^{2}\,,N(X|Y)=^{2}/(1+^{2}).\]

The above result, illustrated in Appendix C, demonstrates the minimal attainable uncertainty increases as the perception quality improves. Moreover, The above example suggests a structure for uncertainty-perception function \(U(P)\), which fundamentally relies on the inherent uncertainty \(N(X|Y)\). Remarkably, the following section shows that this dependency generalizes beyond the specific example presented here, where its particular form is determined by the underlying distributions, along with the specific perception measure employed.

**Remark** One may consider the following alternative formulation

\[(P)_{_{|Y}}N(-X)\ :\ D_{v}(X,Y) P}.\] (3)

The alternative objective quantifies uncertainty as the entropy power of the error, independent of the side information \(Y\). While potentially insightful, this approach may overestimate uncertainty since \(N(-X|Y) N(-X)\) where equality holds if and only if the error \(=-X\) is independent of \(Y\). Although further investigation is warranted, we hypothesize that the behavior of function (3) mirrors that of the UP function (2), which we examine in detail in the following section.

## 4 The Uncertainty-Perception Tradeoff

Thus far, we have formulated the uncertainty-perception function and elucidated its underlying rationale. We now proceed to derive its key properties, including a detailed analysis for the case where Renyi divergence serves as the measure of perceptual quality. Subsequently, we establish a direct link between the UP function and the well-known distortion-perception tradeoff. Finally, we demonstrate our theoretical findings through experiments on image super-resolution.

### The Uncertainty-Perception Plane

The following theorem establishes general properties of the uncertainty-perception function, \(U(P)\), irrespective of the specific distributions and divergence measures chosen.

**Theorem 1**.: _The uncertainty-perception function \(U(P)\) displays the following properties_

1. _Quasi-linearity (monotonically non-increasing and continuous):_ \[U(P_{1}),U(P_{2}) U P_{1}+(1-)P_{ 2}U(P_{1}),U(P_{2}),\ \]
2. _Boundlessness:_ \[N(X|Y) U(P) 2N(X_{G}|Y),\]

_where \(X_{G}\) is a zero-mean Gaussian random variable with covariance identical to \(X\). The inherent uncertainty is upper bounded by \(N(X_{G}|Y)\), which depends on the deviation of \(X\) from Gaussianity._

The theorem establishes a fundamental tradeoff between perceptual quality and uncertainty in image restoration, regardless of the specific divergence measure, data distributions, or restoration model employed. This tradeoff is fundamentally linked to the inherent uncertainty \(N(X|Y)\) arising from the information loss during the observation process. Notably, the upper bound can be expressed as

\[N(X_{G}|Y)=N(X|Y)e^{D_{KL}(X,X_{G}|Y)}.\] (4)

This shows that as \(X\) approaches Gaussianity, \(N(X|Y)\) approaches \(N(X_{G}|Y)\). However, concurrently, it implies in general higher values of \(N(X|Y)\) due to Lemma 1 of Appendix B. This finding yields a surprising insight: for multivariate Gaussian distributions, perfect perceptual quality comes at the expense of exactly twice the inherent uncertainty of the problem.

Next, we show that for a fixed perceptual index \(P\), the optimal algorithms lie on the boundary of the constraint set. This facilitates the optimization, as it restricts the search space to the boundary points.

**Theorem 2**.: _Assume \(D_{v}(X,Y)\) is convex in its second argument. Then, for any \(P 0\), the minimum is attained on the boundary where \(D_{v}(X,Y)=P\)._

Note that the assumption of the convexity of \(_{v}\) in its second argument is not a restrictive condition. In fact, most widely-used divergence functions, notably all \(f\)-divergences (such as KL divergence, total variation distance, Hellinger distance, and Chi-square divergence), exhibit this property.

While the above theorems describe important characteristics of the uncertainty-perception function, additional assumptions are needed to gain deeper insights. Therefore, we now focus on Renyi divergence as our perception measure. Renyi divergence is a versatile family of divergence functions parameterized by an order \(0 r\), encompassing the well-known KL divergence as a special case when \(r=1\). This divergence plays a critical role in in analyzing Bayesian estimators and numerous information theory calculations . Importantly, it is also closely related to other distance metrics used in probability and statistics, such as the Wasserstein and Hellinger distances. Focusing on the case where \(r=1/2\), we arrive at:

\[U(P)=_{P|Y|}N(-X|Y)\;:\;D_{1/2}(X,Y ) P}.\] (5)

While we set \(r=1/2\) to facilitate our derivations, it is important to note that all orders \(r(0,1)\) are equivalent (see Appendix B). Consequently, given this equivalence and the close relationship between Renyi divergence and other metrics, analyzing the specific formulation provided by (5) may yield valuable insights applicable to a wide range of divergence measures. The following theorem provides lower and upper bounds for the UP function.

**Theorem 3**.: _The uncertainty-perception function is confined to the following region_

\[(P) N(X|Y)\,\,U(P)\,\,(P) N(X_{G}|Y)\]

_where \(1(P) 2\) is a convex function w.r.t the perception index and is given by_

\[(P)=2e^{}-}-1)^{2}-1}.\]

Noteworthy, Theorem 3 holds true regardless of the underlying distributions of \(X\) and \(Y\), thereby providing a universal characterization of the UP function in terms of perception. Furthermore, as depicted in Figure 3, Theorem 3 gives rise to the uncertainty-perception plane, which divides the space into three distinct regions:

1. Impossible region, where no estimator can reach.
2. Optimal region, encompassing all estimators that are optimal according to (5).
3. Suboptimal region of estimators which exhibit overly high uncertainty.

The existence of an impossible region highlights the uncertainty-perception tradeoff, proving no estimator can achieve both high perception and low uncertainty simultaneously. This finding underscores the importance of practitioners being aware of this tradeoff, enabling them to make informed decisions when prioritizing between perceptual quality and uncertainty in their applications. The uncertainty-perception plane could serve as a valuable framework for evaluating estimator performance in this context. While not a comprehensive metric, it may offer insights into areas where improvements can be made, guiding practitioners towards estimators that strike a more desirable balance between perception and uncertainty. For certain estimators residing in the suboptimal region, it may be possible to achieve lower uncertainty without sacrificing perceptual quality. Thus, we believe that our proposed uncertainty-perception plane can serve as a valuable starting point for further research and practical applications, ultimately leading to the development of safer and reliable image restoration algorithms.

Next, we analyze how the dimensionality of the underlying data affects the uncertainty-perception tradeoff. To achieve this, we extend the function \((P)\) to include a dimension parameter \(d\), denoted as \((P;d)\). As shown in Fig. 4, \((P;d)\) exhibits a rapid incline as perception improves and it attain higher values in higher dimensions. This observation suggests that in high-dimensional settings, the uncertainty-perception tradeoff becomes more severe, implying that any marginal improvement in perception for an algorithm is accompanied by a dramatic increase in uncertainty.

Finally, we conjecture that the general form of the tradeoff, given by the inequality in Theorem 3, holds for different divergence measures, with the specific form of \((P)\) capturing the nuances of each chosen measure. For instance, considering the Hellinger distance as our perception measure, we obtain the same inequality as in Theorem 3 but with \((P)\) defined for \(0 P 1\) as2

\[_{}(P)=}-}-1)^{2}-1}.\] (6)

### Revisiting the Distortion-Perception Tradeoff

Having established the uncertainty-perception tradeoff and its characteristics, we now broaden our analysis to estimation distortion, particularly the mean squared-error. A well-known result in estimation theory states that for any random variable \(X\) and for any estimator \(\) based upon side information \(Y\), the following holds true :

\[[||-X||^{2}]e^{2h(X|Y)}.\] (7)

This inequality, related to the uncertainty principle, serves as a fundamental limit to the minimal MSE achieved by any estimator. However, it does not consider the estimation uncertainty of \(\) as the right hand side is independent of \(\). Thus, we extend the above in the following theorem.

**Theorem 4**.: _For any random variable \(X\), observation \(Y\) and unbiased estimator \(\), it holds that_

\[[||-X||^{2}] N(-X Y).\]

Notice that for any estimator \(\) we have \(N(-X|Y) N(X|Y)\), implying

\[[||-X||^{2}] N(X|Y)=e^{h(X|Y)}.\] (8)

Figure 4: Impact of dimensionality, as revealed in Theorem 3, demonstrates that the uncertainty-perception tradeoff intensifies in higher dimensions. This implies that even minor improvements in perceptual quality for an algorithm may come at the cost of a significant increase in uncertainty.

Figure 3: The uncertainty-perception plane (Theorem 3). The impossible region demonstrates the inherent tradeoff between perception and uncertainty, while other regions may guide practitioners toward estimators that better balance the two factors, highlighting potential areas for improvement.

The above result aligns with equation (7), demonstrating that Theorem 4 serves as a generalization of inequality (7), incorporating the uncertainty associated with the estimation. Furthermore, by viewing the estimator \(\) as a function of perception index \(P\), we arrive at the next corollary.

**Corollary 1**.: _Define the following distortion-perception function_

\[D(P)_{P_{|Y}}||-X||^{2}:\;D_{v}(X,Y) P}.\]

_Then, for any perceptual index \(P\), we have \(D(P) U(P)\)._

As uncertainty increases with improving perception, the corollary implies that distortion also increases. Thus, when utilizing MSE as a measure of distortion, the uncertainty-perception tradeoff induces a distortion-perception tradeoff , offering a novel interpretation of this well-known phenomenon.

## 5 Experiments

**Setup.** Our theoretical framework is grounded in empirical observations, leading us to validate our findings through experiments on common benchmark tasks: image super-resolution and inpainting. We analyze performance through the lens of uncertainty, alongside established measures of perceptual quality and distortion. To assess perceptual quality, we employ state-of-the-art metrics including HyperIQA , LIQE  and Q-ALIGN . Distortion is evaluated using traditional measures: MSE, peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM) . Accurately estimating entropy in high-dimensional spaces presents significant challenges ; hence, we utilize an upper bound for uncertainty, \(N(_{G}-X_{G}|Y)\), as detailed in Appendix F. This practical alternative simplifies computation to calculating the geometric mean of the singular values of the error covariance.

For super-resolution, we utilize the BSD100 benchmark dataset , aiming to predict a high-resolution image from its low-resolution counterpart obtained via \(4\) bicubic downsampling. Our evaluation spans a diverse range of recovery algorithms, including EDSR , ESRGAN , SinGAN , SANGAN , DIP , SRResNet/SRGAN variants , EnhanceNet , and Latent Diffusion Models (LDMs) with parameter \(\), where \(=0\) recovers DDIM  and \(=1\) recovers DDPM . In the context of image inpainting, we leverage the SeeTrue dataset , an image-text alignment benchmark known for its diverse collection of real and synthetic text-image pairs. Here, we focus our analysis on diffusion models due to their state-of-the-art performance and growing popularity in the field.

**Results.** Figure 5 presents our super-resolution analysis. As observed in the top row, across various perceptual measures, an unattainable blank region exists in the lower right corner, indicating that no model simultaneously achieves both low uncertainty and high perceptual quality. Furthermore, an anti-correlation emerges near this region, where modest improvements in perceptual quality translate to dramatic increases in uncertainty. This observation suggests the existence of a tradeoff between uncertainty and perception. Additionally, the bottom row showcases a strong relationship between uncertainty and distortion across diverse measures, demonstrating that any increase in uncertainty leads to a significant rise in distortion.3 Figure 6 displays similar trends for image inpainting, consistent with our super-resolution analysis and reinforcing the validity of our findings across diverse restoration tasks and data distributions. This is further visualized in Figure 2, which presents outputs from selected algorithms ordered by perceptual quality. The results clearly demonstrate an increase in hallucination (uncertainty) and distortion with increasing perceptual quality. Finally, Appendix H presents additional results obtained via direct estimation of statistics in high dimensions, further supporting our theoretical analysis.

## 6 Conclusion

This study established the uncertainty-perception tradeoff in generative restoration, demonstrating that high perceptual quality leads to increased hallucination (uncertainty), particularly in high dimensions. We characterized this tradeoff and its fundamental relation to the inherent uncertainty of the problem,introducing the uncertainty-perception plane which may guide practitioners in understanding estimator performance. By extending our analysis to MSE distortion, we showed that the distortion-perception tradeoff emerges as a direct consequence of the uncertainty-perception tradeoff. Experimental results confirmed our theoretical findings, highlighting the importance of this tradeoff in image restoration.

## 7 Limitations

Our analysis is grounded in the theoretical framework of entropy as a measure of uncertainty. Information theory offers a powerful framework for quantifying uncertainty and dependencies in data, handling multivariate and heterogeneous data types, and capturing complex patterns. However, its wider adoption has been limited by the challenge of estimating information-theoretic measures in high dimensions. The curse of dimensionality makes accurate density estimation infeasible [12; 48], leading many to rely on simpler second-order statistics.

The development of practical tools for estimating statistics in high-dimensional data remains an active area of research . While initial approaches assumed exponential family distributions (e.g., Gaussian) for tractable calculations , their performance degrades for long-tailed distributions. Non-parametric methods like binning strategies, including KDE and kNN estimators [61; 40; 29], offer more flexibility but are data-dependent and sensitive to parameter choices. Alternative approaches involve ensemble estimation  or von Mises Expansions , the distributional analog of the Taylor expansion. Rotation-Based Iterative Gaussianization  presents a promising direction by transforming data into a multivariate Gaussian domain, simplifying density estimation. However, its application to images has been limited to small patches due to the computational challenges of learning rotations based on principal or independent component analysis. A recent extension addresses this by utilizing convolutional rotations, enabling efficient processing of entire images .

While accurately estimating high-dimensional entropy remains an active research area, Section 5 utilizes a tractable upper bound. This alternative calls for further investigation into its potential for quantifying uncertainty and analyzing algorithm performance. Moreover, incorporating this bound into the design of new algorithms could enable explicit control over the uncertainty-perception trade-off, potentially leading to more reliable solutions.

Figure 5: Evaluation of SR algorithms. Top: Uncertainty-perception plane showing the tradeoff between perceptual quality and uncertainty (y-axis) for various perceptual measures. Bottom: Uncertainty-distortion plane showing the relationship between uncertainty and various distortion measures. Axis placement differs in the two rows to highlight the distinct roles of uncertainty.

Lastly, we focused our empirical validation on image super-resolution and inpainting, two benchmark problems in image restoration. Our analysis, however, applies to any restoration task with non-invertible degradation. Hence, expanding the experiments to additional image-to-image tasks and domains such as audio, video, and text may reveal broader implications and applications of our work.

## 8 Broader Impact

Our work revealing a fundamental tradeoff between uncertainty and perception in image restoration carries significant societal impact. Developers across various fields, including healthcare and autonomous systems, often integrate cutting-edge models into their applications, prioritizing state-of-the-art performance and perceptual quality. However, our work aims to highlight a crucial factor often overlooked: the inherent tradeoff between uncertainty and perception. By raising awareness of this tradeoff, we empower developers to make informed decisions that prioritize safety and reliability over purely perceptual enhancements. For instance, in healthcare, potential restoration algorithms can be evaluated by plotting them on the uncertainty-perception plane, facilitating the identification of methods that strike the optimal balance for specific clinical needs. Furthermore, by understanding this inherent trade-off, practitioners can consider trading performance for better safety and resilience against potential misuse and misinterpretations.

While primarily theoretical, our analysis yields a practical measure of uncertainty (or entropy), used in our experiments to visually and quantitatively illustrate our findings. This tractable uncertainty measure, or any differentiable alternative, can be incorporated into a loss function during the training of generative models like GANs or as an optimization objective to guide the reverse process in diffusion models. This approach enables the development of algorithms that explicitly optimize for the tradeoff between uncertainty and perception.

Figure 6: Evaluation of LDMs on image inpainting, highlighting the trade-off between uncertainty and perceptual quality (top) and the uncertainty-distortion relationship (bottom). No model achieves both low uncertainty and high perceptual quality, with higher uncertainty generally leading to increased distortion. Differing axis placements emphasize the distinct roles of uncertainty.