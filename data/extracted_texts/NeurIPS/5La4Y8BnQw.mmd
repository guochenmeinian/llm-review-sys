# Fast Bellman Updates for Wasserstein Distributionally Robust MDPs

Zhuodong Yu\({}^{1}\) Ling Dai\({}^{1}\) Shaohang Xu\({}^{1}\) Siyang Gao\({}^{2}\) Chin Pang Ho\({}^{1}\)

\({}^{1}\)School of Data Science, City University of Hong Kong, Hong Kong

\({}^{2}\)Department of Systems Engineering, City University of Hong Kong, Hong Kong

{zhuodonyu2-c, lingdai5-c, shaohanxu2-c}@my.cityu.edu.hk

{siyangao, clint.ho}@cityu.edu.hk

###### Abstract

Markov decision processes (MDPs) often suffer from the sensitivity issue under model ambiguity. In recent years, robust MDPs have emerged as an effective framework to overcome this challenge. Distributionally robust MDPs extend the robust MDP framework by incorporating distributional information of the uncertain model parameters to alleviate the conservative nature of robust MDPs. This paper proposes a computationally efficient solution framework for solving distributionally robust MDPs with Wasserstein ambiguity sets. By exploiting the specific problem structure, the proposed framework decomposes the optimization problems associated with distributionally robust Bellman updates into smaller subproblems, which can be solved efficiently. The overall complexity of the proposed algorithm is quasi-linear in both the numbers of states and actions when the distance metric of the Wasserstein distance is chosen to be \(L_{1}\), \(L_{2}\), or \(L_{}\) norm, and so the computational cost of distributional robustness is substantially reduced. Our numerical experiments demonstrate that the proposed algorithms outperform other state-of-the-art solution methods.

## 1 Introduction

Markov Decision Processes (MDPs) provide a flexible and powerful modeling framework for sequential decision-making problems under uncertainty (Puterman, 2014; Sutton and Barto, 2018). However, the standard MDP model assumes that the exact knowledge of the transition kernel is available, which is not the case for most real-world applications. While these model parameters can be estimated from data, it is well-known that the optimal policy of MDP is sensitive to estimation errors because of the dynamic nature of the problem. In particular, small errors in estimating transition kernels could lead to catastrophic failures in practice (Iyengar, 2005; Nilim and El Ghaoui, 2005; Le Tallec, 2007).

To overcome the aforementioned challenge in model ambiguity, robust MDPs assume that the transition kernels belong to ambiguity sets (Iyengar, 2005; Nilim and El Ghaoui, 2005; Xu and Mannor, 2006). Through optimizing the worst-case performance, robust MDPs compute robust policies to avoid disappointing performance due to the sensitivity issue caused by inaccurate transition kernels. However, robust MDPs are often too conservative because they always adopt the worst possible transition kernels without any consideration of their likelihood. To mitigate this undesirable side effect of robust MDPs, distributionally robust MDPs are proposed to incorporate distributional information of model ambiguity and maximize the expected reward under the most adversarial probability distribution (Xu and Mannor, 2010; Yu and Xu, 2015).

In a distributionally robust MDP, we assume that all the plausible distributions of the transition kernel belong to a prescribed ambiguity set, which could be formalized in different types, such as moment ambiguity sets (Delage and Ye, 2010) and Wasserstein ambiguity sets (Mohajerin Esfahani andKuhn, 2018). In this paper, we focus on the Wasserstein ambiguity sets, which have been a popular choice for distributionally robust data-driven optimization in recent years because of their outstanding empirical performance as well as nice theoretical properties, such as consistency in optimality and finite-sample bounds (Mohajerin Esfahani and Kuhn, 2018; Gao and Kleywegt, 2022). By using Wasserstein distance to formulate the ambiguity set, Yang (2017) shows that there exists an optimal policy that is stationary and Markovian for the corresponding Wasserstein distributionally robust MDP.

While (distributionally) robust MDPs can be solved by extending standard solution methods in classical MDPs to their (distributionally) robust counterparts, these solution methods become much more computationally demanding. For example, each Bellman update for (distributionally) robust MDPs can be formulated as a convex optimization problem. Without making use of any specific problem structure, one would need to use generic convex optimization solvers to compute these Bellman updates, which have to be evaluated numerous times for computing the (distributionally) robust value function. This computational challenge restricted the application of (distributionally) robust MDPs to small or medium size of problems. In recent years, many efficient algorithms are proposed for solving robust MDPs to address this issue (Iyengar, 2005; Nilim and El Ghaoui, 2005; Ho et al., 2018; Behzadian et al., 2021; Grand-Clement and Kroer, 2021b; Ho et al., 2022).

On the other hand, however, distributionally robust MDPs have received limited attention on their computational efficiency. To the best of our knowledge, (Grand-Clement and Kroer, 2021a) is the only pioneer work that proposes a first-order method to efficiently solve Wasserstein distributionally robust MDPs. However, being restricted by the nature of first-order methods, the proposed algorithm in (Grand-Clement and Kroer, 2021a) struggles when high accuracy is needed or when the discount factor is close to one, as it would take unsatisfactorily many numbers of iterations to compute the distributionally robust value function.

In this paper, we take an alternative approach to develop fast algorithms for solving Wasserstein distributionally robust MDPs. In particular, we reformulate the optimization problem of the distributionally robust Bellman update to a structural form, and by exploiting the specific problem structure, we propose decomposition schemes in which the problem of interest can be decomposed into smaller subproblems, which can be solved by our customized algorithms in quasi-linear time. As we will show later, the time complexities of the proposed algorithms are linear in the numbers of actions and kernels and quasi-linear in the number of states, which are significantly better than the state-of-the-art solution methods (Xu and Mannor, 2010; Grand-Clement and Kroer, 2021a).

The rest of this paper is organized as follows. Section 2 introduces the related work, and Section 3 describes the setting of Wasserstein distributionally robust MDPs. In Section 4, we illustrate our decomposition scheme for computing the distributionally robust Bellman updates when the Wasserstein distance in the ambiguity set is chosen to be \(L_{q}\) norm. In Section 5, customized fast algorithms and their time complexities are particularly provided for the three most well-known cases: \(L_{1}\), \(L_{2}\), and \(L_{}\). The numerical experiments in Section 6 verify that our methods outperform other state-of-the-art algorithms.

NotationsWe use boldface lowercase and uppercase letters to denote vectors and matrices, respectively. We denote by \([N]\) the set of natural numbers from \(1\) to \(N\); that is, \([N]=\{1,2,,N\}\). The vector \(\) is denoted as the vector of all ones while the dimension depends on the context. The vector \(_{j}\) represents the vector of all zeros except the \(j\)-th component is one. Probability simplex is denoted as \(_{N}=\{^{N}:^{}=1,\}\). The smallest component of a vector \(\) is denoted by \(\{\}\). Given a set \(\), we call the set of all the Borel probability measures as \(P()\). The general \(L_{q}\) norm for a vector \(^{N}\) is denoted by \(\|\|_{q}=(_{i=1}^{N}|x_{i}|^{q})^{1 /q}\) for \(1 q<\), and the \(L_{}\) norm is \(\|\|_{}=_{i[N]}|x_{i}|\). The Dirac distribution at \(^{N}\) is denoted by \(_{}\). For optimization problems with multiple constraints, we indicate the decision variables on the last line of the constraints.

## 2 Related Work

Research on Markov decision processes under model ambiguity can be traced back to the seventies (Satia and Lave Jr, 1973). In recent years, much progress has been made in the development of robust MDPs. The most fundamental solution scheme to solve robust MDPs is _robust value iteration_, which is the robust counterpart of the standard value iteration and is first developed in (Givan et al., 2000; Iyengar, 2005; Nilim and El Ghaoui, 2005) for robust MDPs with \((s,a)\)-rectangular ambiguity sets. Wiesemann et al. (2013) introduce the \(s\)-rectangular ambiguity sets; the authors reformulate the robust Bellman updates as convex optimization problems and solve them by using off-the-shelf solvers that have polynomial-time complexity. Researchers have been investigating the theoretical properties of robust MDPs, such as the error bound of applying robust MDPs with state aggregation (Petrik and Subramanian, 2014), the relationship between robustness and regularization (Derman et al., 2021), and the geometry of value function in robust MDPs (Wang et al., 2022). Other than the \(s\)- and \((s,a)\)-ambiguity sets, different types of ambiguity sets have been also proposed to mitigate the side effect of conservatism, such as \(k\)-rectangularity (Mannor et al., 2016) and \(r\)-rectangularity (Goyal and Grand-Clement, 2023). Different related models are also proposed to incorporate robustness in different settings, such as robust baseline regret (Ghavamzadeh et al., 2016), imitation learning (Brown et al., 2020), and soft-robust model (Lobo et al., 2020). In terms of algorithmic development, Ho et al. (2018) propose fast algorithms for solving \(s\)-rectangular robust MDPs with weighted \(L_{1}\) norm ambiguity sets and propose to compute robust Bellman updates using the combination of bisection method and homotopy method, and Behzadian et al. (2021) further extend the solution scheme for the unweighted \(L_{}\) norm cases (Delgado et al., 2016). A _first order method_ is introduced in (Grand-Clement and Kroer, 2021b) to approximate robust Bellman updates for robust MDPs with ellipsoidal and Kullback-Leibler (KL) \(s\)-rectangular ambiguity sets. Recently, Ho et al. (2022) propose the \(\)-divergence ambiguity set, which generalizes multiple popular choices of ambiguity sets, and they propose an unified solution scheme to compute robust Bellman updates efficiently. On the other hand, _robust policy iteration_ alternates between robust policy evaluation and policy improvement (Iyengar, 2005) and it has better empirical performance compared to robust value iteration. Kaufman and Schaefer (2013) propose a modified policy iteration for (\(s,a\))-rectangular robust MDPs. Ho et al. (2021) introduce partial policy iteration for \(s\)- and (\(s,a\))-rectangular robust MDPs with \(L_{1}\) norm ambiguity sets. Kumar et al. (2022) study the connection between robust MDPs and regularized MDPs, and propose robust policy iteration for \(s\)-rectangular robust MDPs. Other than robust policy iteration, Li et al. (2022) propose a policy gradient method for solving rectangular robust MDPs. In order to solve large-scale problems, Tamar et al. (2014) apply value function approximation and propose _robust approximate dynamic programming_ for robust MDPs.

While this paper is focused on the model-based setting, recently there is an active line of research focusing on _robust reinforcement learning (RL)_ algorithms (Roy et al., 2017; Badrinath and Kalathil, 2021; Wang and Zou, 2021, 2022; Panaganti and Kalathil, 2022). Liu et al. (2022) propose a robust Q-learning algorithm for \((s,a)\)-rectangular robust MDPs. A function approximation approach is proposed in (Panaganti et al., 2022) for \((s,a)\)-rectangular robust MDPs with offline datasets. The combination of robust RL and deep RL is also studied in (Pinto et al., 2017; Mankowitz et al., 2019; Zhang et al., 2020) although they do not provide theoretical guarantees of the learned policies. We would like to emphasize that both model-based and model-free methods have their own merits: while model-free methods are powerful for applications where data could be generated without much risk and cost, model-based methods are suitable for applications with very limited data or settings where the (time and financial) cost of obtaining new data is high.

For distributionally robust MDPs with the nested-set structured parameter ambiguity sets, Xu and Mannor (2010) propose a Bellman type backward induction to compute the optimal policy, and Yu and Xu (2015) further extend it to a more general state-wise ambiguity set following the unified framework proposed in (Wiesemann et al., 2014). The Wasserstein ambiguity sets are first introduced for distributionally robust MDPs in (Yang, 2017), and a convex formulation is proposed based on Kantorovich duality. Chen et al. (2019) propose a general formulation to combine both moment-based and statistical-distance-based ambiguity sets together for distributionally robust MDPs. Derman and Mannor (2020) study the connection between Wasserstein distributionally robust MDPs and regularization. Abdullah et al. (2019) propose a reinforcement learning framework with distributionally robustness. As mentioned before, however, (Grand-Clement and Kroer, 2021a) is the only work that focuses on the algorithmic development of solving Wasserstein distributionally robust MDPs, which is also the focus of this paper.

Preliminaries

A distributionally robust MDP is a tuple \((,,_{0},,,)\), where \(\) and \(\) are the sets of states and actions, respectively. We assume that the state space \(=\{1,,S\}\) and the action space \(=\{1,,A\}\) are finite. The initial state \(s_{0}\) follows a given initial distribution \(_{0}_{S}\). When the decision maker takes an action \(a\) in state \(s\), the MDP will transit to the next state randomly according to the probability distribution \(_{sa}_{S}\), which is assumed to be unknown; the transition from state \(s\) under action \(a\) to the next state \(s^{}\) will induce the reward \(r_{sas^{}}\). We use the vector \(_{sa}^{S}\) to represent the connection of all rewards given state \(s\) and action \(a\). We denote by \((0,1)\) the discount factor. In distributionally robust MDPs, the transition kernel \(,a}{}_{sa}(_{S} )^{S A}\) is assumed to be uncertain, and it is governed by an unknown probability distribution \(\) which is assumed to reside in a prescribed ambiguity set \(\) that is calibrated from historical data. Note that we also use the notation \(_{s}=}{}_{sa}(_{S} )^{A}\) for the transition kernel given the state \(s\).

The goal of a distributionally robust MDP is to maximize the worst-case expected return; that is,

\[(_{A})^{S}}{}\;}{}\;}{} }{}^{t}r_{s_{t}a_{t}s_{t+ 1}}\;:\;s_{0}_{0}. \]

Here, the decision variable \((_{A})^{S}\) is called a (randomized) policy where for any given \(s\), its sub-vector \(_{s}_{A}\) represents the probability distribution of taking action \(a\) in state \(s\).

It is worth mentioning that the above formulation of distributionally robust MDPs is a generalization of both robust MDPs and standard MDPs. By specifying the ambiguity set \(\) to be \(P()\) where \(\) is the ambiguity set of a robust MDP, the problem (1) is equivalent to the robust MDP with ambiguity set \(\). If the set \(\) is a singleton, then problem (1) with \(=P()\) is equivalent to the standard MDP with transition kernel from the singleton \(\).

Similar to the case of robust MDPs, we consider the common assumption of rectangularity for the sake of tractability, as otherwise problem (1) is NP-hard (Wiesemann et al., 2013). In particular, we consider the following \(s\)-rectangular \(q\)-Wasserstein ambiguity set (Grand-Clement and Kroer, 2021)

\[^{q}= P((_{S})^{S A} )\;:\;=_{s}_{s},\;_{s}_{s }^{q} P((_{S})^{A}),\; s },\]

where \(_{s}^{q}\) is the marginal ambiguity set for the distribution \(_{s}\) that governs the transition kernel at the state \(s\). The superscript \(q\) indicates that \(_{s}^{q}\) is defined by \(q\)-Wasserstein distance; that is,

\[_{s}^{q}=_{s} P((_{S})^{A} )\;:\;W_{q}(_{s},_{s})}\;\; \;\;1 q,\]

where \(_{s}\) is the reference distribution at the center of the Wasserstein ball and

\[W_{q}(_{s},_{s})=_{ P((_{S} )^{A}(_{S})^{A})}\{(}(d_{q}(x,y))^{q})^{1 /q}\;:\;(_{s},_{s})\},\]

for \(1 q<\), where \((_{s},_{s})\) is the set of all the couplings of \(_{s}\) and \(_{s}\) (Ambrosio and Nicola Gigli, 2005), and \(d_{q}\) is induced by the \(q\)-norm \(d_{q}(x,y)=\|x-y\|_{q}\) throughout this work. We define the \(\)-Wasserstein distance \(W_{}(_{s},_{s})\) by taking \(q\).

We adopt the usual setting in distributionally robust data-driven optimization where \(_{s}=_{i=1}^{N}_{}_{s}^{i}}\) is set to be the empirical distribution and estimated by the samples \(\{}_{s}^{i}\}_{i=1}^{N}\) where \(}_{s}^{i}(_{S})^{A}\) for every \(i[N]\). Then, the optimal value function of (1), \(^{}\), satisfies the following distributionally robust Bellman equation (Yu and Xu, 2015; Yang, 2017; Grand-Clement and Kroer, 2021)

\[v_{s}^{}=_{s}_{A}}{}_{_{s} _{s}^{q}}(_{a}_{sa}_{sa}^{}( _{sa}+^{})) s, \]where \(_{s}^{q}\) is the set of expected kernels (Yang, 2017; Bertsimas et al., 2018; Xie, 2020) of the following forms

\[_{s}^{q} = \{_{i=1}^{N}_{s}^{i}\,:\,_{i=1}^{N}\|_{s}^{i}-}_{s}^{i} \|_{q}^{q}^{q},\;_{s}^{i}(_{S})^{A},\;  i[N]\}\;\;\;\;\;\;1 q<,\] \[_{s}^{} = \{_{i=1}^{N}_{s}^{i}\,:\,\| _{s}^{i}-}_{s}^{i}\|_{},\;_{s}^{i}(_{S})^{A}\,,\; i[N]\}.\]

## 4 The Decomposition Algorithm for Distributionally Robust Bellman Update

In this section, we focus on computing the distributionally robust Bellman update, which is the most fundamental operator for solving the distributionally robust Bellman equation (2); we define the distributionally robust Bellman operator \(()\) where for any \(^{S}\),

\[[()]_{s}=_{_{s}_{A}} _{_{s}_{s}^{q}}_{a}_{sa} _{sa}^{}(_{sa}+)\;\;\;\; s. \]

Given the above definition of \(()\), it is well-known that (2) can be solved by iteratively applying \(\), which is a variant of standard value iteration for solving distributionally robust MDPs (Yu and Xu, 2015; Grand-Clement and Kroer, 2021a). For any initial guess \(^{0}^{S}\), we have \(_{t}^{t}^{}\) where \(^{t}=(^{t-1})\) for \(t=1,2,\) and \(^{}\) satisfies (2). Therefore, the efficiency of evaluating \([()]_{s}\) is crucial to the computation of solving distributionally robust MDPs.

However, computing \([()]_{s}\) using generic convex optimization solvers is much more computationally demanding compared to the case of classical MDPs, which only have time complexity \((SA)\) for computing their Bellman updates. In this section, we exploit the specific problem structure in (4) and reformulate the optimization problem to a form that could be decomposed into smaller problems. We first focus on the case of \(q[1,)\) in Section 4.1 and then consider the case of \(q=\) in Section 4.2, where \(q\) indicates the type of Wasserstein distance used in the ambiguity set. As we will show later, combined with the customized fast algorithms in Section 5 for solving the subproblems, one can compute \([()]_{s}\) in time complexity that is quasi-linear in \(S\) and linear in \(A\) and \(N\). All the proofs of propositions and theorems in this section are provided in Appendix A.1.

### Nested bisection method for \(q\)-Wasserstein ambiguity set with \(q[1,)\)

We consider the optimization problem in (4) for the case where \(q[1,)\). By applying the minimax theorem, we obtain the following result.

**Proposition 4.1**.: _Consider the Bellman updates (4) with \(q[1,)\). Then,_

\[[()]_{s}=[ *{minimize}&\\ *{subject\;to}&_{i=1}^{N}( _{sa}+)^{}_{sa}^{i} ,\; a\\ &_{i=1}^{N}_{a}\|_{sa}^{i}- }_{sa}^{i}\|_{q}^{q}^{q}\\ &,\;_{sa}^{i}_{S},\; i[N] \,,\; a.]\;\;\;\; s. \]

The above proposition reformulates the maximin optimization problem in (4) into a convex minimization problem, which can be solved by commercial convex optimization solvers. Moreover, problem (5) can be solved via bisection on \(\); that is, we seek for the lowest possible \(\) such that \(_{i=1}^{N}(_{sa}+)^{} _{sa}^{i}\) for each \(a\) while \(_{sa}^{i}\) satisfies the other constraints in (5), for every \(a\). To this end, we introduce the following subproblem

\[(\{}_{sa}^{i}\}_{i=1}^{N}; _{sa},)=[*{ minimize}&_{i=1}^{N}\|_{sa}^{i}-}_{sa}^{i}\|_{q}^{q}\\ *{subject\;to}&_{i=1}^{N} _{sa}^{}_{sa}^{i}\\ &_{sa}^{i}_{S},\; i[N]]. \]By setting \(_{sa}=_{sa}+\), the above problem \((\{}_{sa}^{i}\}_{i=1}^{N};_{sa},)\) allows us to seek for decision variable \(\{_{sa}^{i}\}_{i=1}^{N}\) that satisfies the first and the last line of constraints in (5) while minimizing the "budget" used in the second line of constraint in (5). In particular, for any fixed \(^{}\), we distinguish among the following two cases:

* If \(_{a}(\{}_{sa}^{i}\}_{i=1}^{N}; {b}_{sa},^{})^{q}\), then \(^{}\) is feasible for (5) and it is an upper bound of the optimal objective value in (5).
* If \(_{a}(\{}_{sa}^{i}\}_{i=1}^{N}; {b}_{sa},^{})>^{q}\), then \(^{}\) must be infeasible for problem (5) and so it is a lower bound of the optimal objective value in (5).

To apply the bisection method, we derive the initial upper and lower bounds of the optimal \(^{}\) in (5).

**Proposition 4.2**.: _Consider the distributionally robust Bellman update (5). The optimal objective value \(^{}\) is bounded by_

\[_{a}\{\{_{sa}\}\}^ {}_{a}\{_{i=1}^{N}_{sa}^{ }}_{sa}^{i}\}. \]

As opposed to (5), the size of problem (6) is independent of \(A\). By using the aforementioned bisection method, the overall time complexity is now only linear in \(A\) since we only need to solve (6) \((A_{1})\) times, where \(_{1}\) is the tolerance for the bisection method.

While one can solve problem (6) using off-the-shelf solvers and enjoy the reduced complexity by using the above bisection method, this subproblem itself turns out to be another structural optimization problem. As we will show in the following proposition, by applying duality on (6), the reformulation could be further decomposed via another bisection method on the dual variable.

**Proposition 4.3**.: _Consider the problem \((\{}_{sa}^{i}\}_{i=1}^{N};_{sa},)\) in (6). If \(>\{_{sa}\}\), then_

\[(\{}_{sa}^{i}\}_{i=1}^{N};_{sa},) =_{0}-+_{i=1}^{N} _{q}(}_{sa}^{i},_{sa},), \]

_where \(=_{i[N]}\|_{j}-}_{sa}^{i}\|_{q }^{q}/(-\{_{sa}\})\) and_

\[_{q}(}_{sa}^{i},_{sa},)=_{_{sa}^ {i}_{S}}\|}_{sa}^{i}-}_{sa}^{i}\|_{q }^{q}+_{sa}^{}_{sa}^{i}, \]

_where \(j*{arg\,min}_{s^{}}\,b_{sa}^{s}\)._

Notice that we focus on the case where \(>\{_{sa}\}\) since \(\{_{sa}\}\) is not larger than the lower bound of \(\) in (7), and the case \(=\{_{sa}\}\) will not occur because \(\) is always taken to be the average of the upper and lower bounds in our bisection method. We refer interested readers to Appendix for more details.

Proposition 4.3 indicates that for any fixed feasible \(\) in (8), the subproblems (9) can be solved separately. Therefore, by applying the bisection method on \(\) in problem (8), one can naturally decompose the problem (8) into \(N\) smaller problems that have \(S\) variables and \(S+1\) constraints. As a consequence, the overall time complexity is linear in the number of kernels \(N\).

By combining both decomposition strategies above, we obtain the proposed nested bisection method, whose pseudocode could be found in Algorithm 1. More details of the algorithm is provided in the Appendix A.1.

**Theorem 4.4**.: _Suppose \(^{}\) is the value returned by Algorithm 1, and \(^{}\) be the optimal value of (5). With the inputs provided in Algorithm 1 and user-specified tolerances \(_{1},_{2}>0\), we have_

\[|^{}-^{}|}{2}+ (_{a}\{_{sa}\}-) (_{a}\{_{sa}\}+)}{ ^{q}}.\]

**Theorem 4.5**.: _Algorithm 1 computes (5) in time \((h_{q}(S)NA_{1}^{-1}_{2}^{-1}+AS)\), where \(h_{q}(S)\) is the time complexity for solving (9)._As shown in the above theorem, the proposed nested bisection method has a time complexity that is linear in both \(A\) and \(N\), but the overall complexity depends on the subproblem (9) where its complexity depends on the choice of \(q\) and the number of states \(S\). In Section 5, we will derive \(h_{1}()\) and \(h_{2}(S)\), which are the two most common cases. The complexities associated with solving equations (5) and (8) using general convex optimization methods are also provided in the Appendix B.

### Decomposition scheme for \(\)-Wasserstein ambiguity set

As opposed to the case where \(q[1,)\), for \(\)-Wasserstein ambiguity set, the corresponding Bellman update can be naturally decomposed without using any bisection method.

**Proposition 4.6**.: _Consider the Bellman update (4) with \(q=\). Then,_

\[[()]_{s}=_{a}_{i=1} ^{N}_{^{i}_{sa}_{S}}\{^{}_{ sa}^{i}_{sa}\ :\ \|^{i}_{sa}-}^{i}_{sa} \|_{}\} s. \]

The above reformulation requires solving \(NA\) inner minimization problems that have \(S\) variables and \(S+2\) constraints. Hence, the time complexity of Bellman update (10) is linear in \(A\) and \(N\). Similar to Section 4.1, we will discuss the complexity of solving the inner minimization in the next section.

## 5 Efficient Algorithms for Subproblems

Section 4 offers decomposition schemes for distributionally robust MDPs with \(q\)-Wasserstein ambiguity set. As shown in Theorem 4.5 and Proposition 4.6, the overall complexity of computing distributionally robust Bellman update is linear in both \(A\) and \(N\) but it depends on complexities of solving the subproblem (9) and the inner minimization problem in (10). In this section, we consider the common cases where \(q\{1,2,\}\) and discuss the time complexity of solving the subproblem in each case.

As we will show below, the overall time complexities of our decomposition algorithms are only \((SA S+NAS_{1}^{-1}_{2}^{-1})\) for \(q=1\), \((NAS S_{1}^{-1}_{2}^{-1})\) for \(q=2\), and \((AS( S+N))\) when \(q=\). These complexities are much lower than \((N^{3.5}A^{3.5}S^{3.5}(^{-1}))\) and \((NA^{2.5}S^{2.5}(S)^{-1.5})\) from the state-of-the-art solution methods in (Xu and Mannor, 2010) and (Grand-Clement and Kroer, 2021), respectively. The proofs of the following propositions, theorems, and corollaries and the details of the proposed algorithms are relegated to Appendix A.2.

### \(1\)-Wasserstein ambiguity set

When \(q=1\), the corresponding subproblem (9) has an equivalent form as follows.

**Proposition 5.1**.: _Suppose \(q=1\). The minimization problem (9) is equivalent to_

\[_{v 0}\{v+_{_{sa}^{i}_{S}}_{ sa}^{}_{sa}^{i}\ :\ \|_{sa}^{i}-}_{sa}^{i}\|_{1 } v\}. \]

While problem (11) does not appear to be trivial at first glance, it has nice mathematical properties which allow us to solve this problem efficiently.

**Theorem 5.2**.: _The objective function in (11) is piecewise-linear in \(v\), and it can be solved in time \((S S)\)._

Therefore, the proposed Algorithm 1 can compute the Bellman update with the time complexity linear in \(A\) and \(N\) and quali-linear in \(S\). We obtain the following result by combining Theorem 4.5 and Theorem 5.2.

**Corollary 5.2.1**.: _The distributionally robust Bellman update with \(1\)-Wasserstein ambiguity set can be computed in time \((SA S+NAS_{1}^{-1}_{2}^{-1})\), where \(_{1}\) and \(_{2}\) are the user-specified tolerances in Algorithm 1._

### \(2\)-Wasserstein ambiguity set

When \(q=2\), the following result shows that (9) could be transformed to an Euclidean projection problem onto the probability simplex.

**Theorem 5.3**.: _Suppose \(q=2\). The minimization problem (9) is equivalent to_

\[-\|_{sa}\|_{2}^{2}}{4}+_{sa}^{ }}_{sa}^{i}+_{_{sa}^{i}_{S}}\|_{ sa}^{i}-}_{sa}^{i}-_{sa}}{2}\|_{2}^{2}, \]

_which can be solved in time \((S S)\)._

Euclidean projection problem onto the probability simplex can be solved via the existing algorithm (Wang and Carreira-Perpinan, 2013). By combining the results in Theorem 4.5 and Theorem 5.3, we obtain the following result.

**Corollary 5.3.1**.: _The distributionally robust Bellman update with \(2\)-Wasserstein ambiguity set can be computed in time \((NAS S_{1}^{-1}_{2}^{-1})\), where \(_{1}\) and \(_{2}\) are the user-specified tolerances in Algorithm 1._

### \(\)-Wasserstein ambiguity set

When \(q=\), the corresponding subproblem

\[_{_{sa}^{i}_{S}}\{_{sa}^{}_{sa}^{i}\ :\ \|_{sa}^{i}-}_{sa}^{i}\|_{}\} \]

can be reformulated to a linear program with box constraints and a linear equality constraint which can be solved efficiently.

**Theorem 5.4**.: _The minimization problem (13) is solved in time \((S S)\)._

Therefore, we obtain the overall complexity as follows.

**Corollary 5.4.1**.: _The distributionally robust Bellman update with \(\)-Wasserstein ambiguity set can be computed in time \((AS( S+N))\)._

## 6 Numerical Results

We experiment on the performance of the proposed algorithms (Fast), Gurobi (Gurobi Optimization, LLC, 2023), and the first-order method (FOM) proposed in (Grand-Clement and Kroer, 2021a) with different sizes of the randomly generated distributionally robust MDPs. Due to page limit, we only report the results of the experiments on a single Bellman update, and we provide additional experimental results in the Appendix C, which also contains the detailed settings of all the experiments.

Figure 1 reports the average computation times of Bellman updates with \(1\)-Wasserstein ambiguity sets. For the first-order method (Grand-Clement and Kroer, 2021a), we report the computation times of the third Bellman iteration, and these computation times increase at every Bellman iteration of the first-order method. One can see that all three algorithms perform similarly when problem size is small. However, as \(S\), \(A\), or \(N\) increases, the runtimes of both Gurobi and first-order method increase rapidly, while the proposed algorithm remains scalable.

The results with \(2\)-Wasserstein ambiguity sets and \(\)-Wasserstein ambiguity sets are shown in Figure 2 and Figure 3, respectively. These results are similar to the case where \(q=1\), which are consistent to our theoretical results on complexities. As expected, the proposed algorithms are several orders of magnitude faster than the existing state-of-the-art solution methods.

Figure 1: Comparisons of all algorithms for \(q=1\), where _(left)_\(N=50\), _(middle)_\(A=70\), \(N=50\), and _(right)_\(S=A=70\).

Figure 3: Comparisons of all algorithms for \(q=\), where _(left)_\(N=50\), _(middle)_\(A=70\), \(N=50\), and _(right)_\(S=A=70\).

Figure 2: Comparisons of all algorithms for \(q=2\), where _(left)_\(N=50\), _(middle)_\(A=70\), \(N=50\), and _(right)_\(S=A=70\).

Conclusion

This paper studies distributionally robust MDPs with Wasserstein ambiguity sets. In particular, we propose fast algorithms to compute distributionally robust Bellman updates. We show that the proposed algorithms outperform other existing methods in both theory and experiments. Future work could address the extensions to approximate dynamic programming for distributionally robust MDPs as well as model-free settings.

## 8 Acknowledgement

We thank the anonymous reviewers for their supportive comments. This work was supported, in part, by the CityU Start-Up Grant (Project No. 9610481), the National Natural Science Foundation of China (Project No. 72032005), and Chow Sang Sang Group Research Fund sponsored by Chow Sang Sang Holdings International Limited (Project No. 9229076).