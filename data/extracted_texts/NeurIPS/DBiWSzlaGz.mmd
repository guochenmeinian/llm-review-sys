# Stoichiometry Representation Learning with

Polymorphic Crystal Structures

 Namkyeong Lee\({}^{1,3}\), Heewoong Noh\({}^{1}\), Gyoung S. Na\({}^{2}\),

**Tianfan Fu\({}^{3}\), Jimeng Sun\({}^{3}\), Chanyoung Park\({}^{1}\)**

\({}^{1}\) KAIST \({}^{2}\) KRICT \({}^{3}\) UIUC

{namkyeong96,heewoongnoh,cy.park}@kaist.ac.kr

ngs0@krict.re.kr, futianfan@gmail.com, jimeng@illinois.edu

Corresponding author. Work done while the author was a visiting Ph.D. student in UIUC.

###### Abstract

Despite the recent success of machine learning (ML) in materials science, its success heavily relies on the structural description of crystal, which is itself computationally demanding and occasionally unattainable. Stoichiometry descriptors can be an alternative approach, which reveals the ratio between elements involved to form a certain compound without any structural information. However, it is not trivial to learn the representations of stoichiometry due to the nature of materials science called _polymorphism_, i.e., _a single stoichiometry can exist in multiple structural forms due to the flexibility of atomic arrangements_, inducing uncertainties in representation. To this end, we propose PolySRL, which learns the probabilistic representation of stoichiometry by utilizing the readily available structural information, whose uncertainty reveals the polymorphic structures of stoichiometry. Extensive experiments on sixteen datasets demonstrate the superiority of PolySRL, and analysis of uncertainties shed light on the applicability of PolySRL in real-world material discovery. The source code for PolySRL is available at https://github.com/Namkyeong/PolySRL_AI4Science.

## 1 Introduction

Recently, ML techniques have found their applications in the field of materials science to analyze the extensive amount of experimental and computational data available . However, the effectiveness of these ML models is not only influenced by the selection of appropriate models but also reliant on the _numerical descriptors_ used to characterize the systems of interest. Although it is still an open problem to construct appropriate descriptions of materials, there is a general agreement on effective descriptors that encompass the following principles : Descriptors should **1**) preserve the similarity or difference between two data points (_preservativity_), **2**) be applicable to the entire materials domain of interest (_versatility_), and **3**) be computationally more feasible to generate compared to computing the target property itself (_computability_).

Among various types of descriptors, there has been a notable surge of interest in using descriptors based on the knowledge of crystal structure in materials science. In particular, as shown in Figure 1(a), one can create graphical descriptions of crystalline systems by considering periodic boundary conditions and defining edges as connections between neighboring atoms within a specific distance . However, these graphical descriptors depend on the structural details of crystals, which are usually obtained through computationally demanding and, in some cases, infeasible Density Functional Theory (DFT) calculations . As a result, graphical descriptors are limited by the same computational bottleneck as DFT calculations, violating the principles of versatility and computability .

An alternative approach to using graphical descriptors is to develop material representations from stoichiometry2 alone, as shown in Figure 1(b), which generates the representation of material solely based on its elemental composition . Despite its simplicity, stoichiometry-based models have been shown to robustly offer a promising set of favorable elemental compositions for exploring new materials with cheap computational cost . However, this approach is inherently limited in that it overlooks the structural information of crystals, leading to inferior performance compared to graphical models  given that structural details strongly influence the crystal properties. This naturally prompts a question: "Is it possible for stoichiometry-based models to also capture the structural information of crystals?"

To answer the question, we propose a novel multi-modal representation learning framework for stoichiometry that incorporates readily available crystal structural information (i.e., stoichiometry and crystal structural information as multi-modal inputs), inspired by the recent success of multi-modal contrastive learning approaches in various domains . For example, in computer vision, CLIP  improves the zero-shot transferability of a vision model by matching captions and images. Moreover, 3D Infomax  improves 2D molecular graph representation in quantum chemistry by maximizing the mutual information with its corresponding 3D molecular representations.

However, naively adopting existing multi-modal contrastive learning approaches to the stoichiometry representation learning task is non-trivial due to the intrinsic characteristics of crystal structures, i.e., one-to-many relationship between stoichiometry and crystal structures stemming from the flexibility of atomic arrangements, which is also known as _polymorphism_. In other words, solely relying on stoichiometry would contradict the principle of _preservativity_, especially for polymorphic materials with the same stoichiometry. More specifically, polymorphism refers to the nature of a certain compound to exist in different crystallographic structures due to different arrangements of atoms, resulting in totally different physical, and chemical properties . An illustrative example of polymorphism is seen in the distinct forms of carbon: diamond and graphite (See Figure 1(c)). Diamond has a tetrahedral lattice structure with each carbon atom bonded to four others, resulting in its exceptional hardness and optical properties . However, graphite has a planar layered structure where carbon atoms are bonded in hexagonal rings, forming sheets that can easily slide past each other, giving graphite its lubricating and conducting properties . Therefore, it is essential not only to obtain qualified stoichiometry representations, but also to account for the uncertainties stemming from polymorphism for real-world material discovery, which has been overlooked in previous studies .

To this end, we propose Polymorphic Stoichiometry Representation Learning (PolySRL), which aims to learn the representation of stoichiometry as a probabilistic distribution of polymorphs instead of a single deterministic representation . In particular, by assuming that polymorphs with an identical stoichiometry follow the same Gaussian distribution, PolySRL models each stoichiometry as a parameterized Gaussian distribution with learnable mean and variance vectors, whose distribution is trained to cover the range of polymorphic structures in representation space. By doing so, we expect the mean of Gaussian distribution serves as the representation of the stoichiometry, and the variance reflects the uncertainty stemming from the existence of various polymorphic structures, enabling PolySRL to assess the degree to which the representation adheres to the principle of _preservativity_. In this work, we make the following contributions:

* Recognizing the advantages and limitations of both structural and stoichiometry descriptors, we propose a multi-modal representation learning framework for stoichiometry, called PolySRL, which incorporates structural information of crystals into stoichiometry representations.

Figure 1: (a) Crystal structure of NaCl. (b), (c) Graphical and stoichiometry description of NaCl, respectively. (d) Diamond and Graphite share a single stoichiometry but have different structures.

* To capture uncertainties of stoichiometry stemming from various _polymorphs_, PolySRL learns a probabilistic representation for each stoichiometry instead of a deterministic representation.
* Extensive experiments on **sixteen datasets** demonstrate the superiority of PolySRL in learning representation of stoichiometry and predicting its physical properties. Moreover, we observe that measured uncertainties reflect various challenges in materials science, highlighting the applicability of PolySRL for real-world material discovery.

To the best of our knowledge, this is the first work that learns generalized representations of stoichiometry by simultaneously considering the crystal structural information and the polymorphism as uncertainty, which is crucial for the process of real-world material discovery.

## 2 Related Works

### Graph Neural Networks for Materials

Among various ML methods, graph neural networks (GNNs) have been rapidly adopted by modeling crystal structures as graphical descriptions inspired by the recent success of GNNs in biochemistry [19; 50; 27; 21; 38; 37]. Specifically, CGCNN  first proposes a message-passing framework based on a multi-edge graph to capture interactions across cell boundaries, resulting in highly accurate prediction for eight distinct material properties. Building upon this multi-edge graph foundation, MEGNet  predicts various crystal properties by incorporating a physically intuitive strategy to unify multiple GNN models. Moreover, ALIGNN  proposes to utilize a line graph, in addition to a multi-edge graph, to model additional structural features such as bond angles and local geometric distortions. Despite the recent success of graph-based approaches, their major restriction is the requirement of atomic positions, which are typically determined through computationally intensive and sometimes infeasible DFT calculations. As a result, their effectiveness is mainly demonstrated in predicting properties for systems that have already undergone significant computational effort, restricting their utility in the materials discovery workflow .

### Stoichiometry Representation Learning

Material representations can be alternatively constructed solely based on stoichiometry, which indicates the concentration of the constituent elements, without any knowledge of the crystal structure . While stoichiometry has historically played a role in effective materials design [6; 45], it has been recently demonstrated that deep neural networks (DNNs) tend to outperform conventional approaches when large datasets are available. Specifically, ElemNet  takes elemental compositions as inputs and trains DNNs with extensive high-throughput OQMD dataset , showing improvements in performance as the network depth increases, up to a point where it reaches 17 layers. Roost  utilizes GNNs for stoichiometry representation learning by creating a fully connected graph in which nodes represent elements, allowing for the modeling of interactions between these elements. Instead of the message-passing scheme, CrabNet  introduces a self-attention mechanism to adaptively learn the representation of individual elements based on their chemical environment. While these methods are trained for a specific task, PolySRL aims to learn generalized stoichiometry representations for various tasks considering 1) the structural information and 2) polymorphism in crystal, both of which have not been explored before.

### Probabilistic Representation Learning

First appearing in 2014 with the introduction of probabilistic word embeddings , probabilistic representations got a surge of interest from ML researchers by offering numerous benefits in modeling uncertainty pertaining to a representation. Specifically, in the computer vision domain, Shi & Jain  proposes to probabilistically represent face images to address feature ambiguity in real-world face recognition. Moreover, Oh et al.  introduces Hedged Instance Embeddings (HIB), which computes a match probability between point estimates but integrates it over the predicted distributions via Monte Carlo estimation. This idea has been successfully extended to cross-modal retrieval , video representation learning , and concept prediction . In this paper, we aim to learn a probabilistic representation of stoichiometry, where the uncertainties account for various polymorphs associated with a single stoichiometry, enhancing the reliability of the material discovery process.

Preliminaries

### Stoichiometry Graph Construction

Given a stoichiometry, we use \(=\{e_{1},,e_{n_{e}}\}\) to denote its unique set of elements, and \(=\{r_{1},,r_{n_{e}}\}\) to denote the compositional ratio of each element in the stoichiometry. We construct a fully connected stoichiometry graph \(^{a}=(,,^{a})\), where \(^{a}\{1\}^{n_{e} n_{e}}\) indicates the adjacency matrix of a fully connected graph . Then, we adopt GNNs as the stoichiometry encoder \(f^{a}\), which aims to learn the stoichiometry representation by capturing complex relationships between elements via the message-passing scheme. Additionally, \(^{a}\) is associated with an elemental feature matrix \(^{a}^{n_{e} F}\) where \(F\) is the number of features.

### Structural Graph Construction

Given a crystal structure \((,)\), suppose the unit cell has \(n_{s}\) atoms, we have \(=[_{1},_{2},,_{n_{s}}]^{} ^{n_{s} 3}\) indicating the atom position matrix and \(=[_{1},_{2},_{3}]^{} ^{3 3}\) representing the lattice parameter describing how a unit cell repeats itself in three directions. Based on the crystal parameters, we construct a multi-edge graph \(^{b}=(,^{b})\) that captures atom interactions across cell boundaries . Specifically, \(v_{i}\) denotes an atom \(i\) and all its duplicates in the infinite 3D space whose positions are included in the set \(\{}_{i}|}_{i}=_{i}+k_{1}_{1} +k_{2}_{2}+k_{3}_{3},k_{1},k_{2},k_{3}\}\), where \(\) denotes the set of all the integers. Moreover, \(^{b}\{0,1\}^{n_{s} n_{s}}\) denotes an adjacency matrix, where \(^{b}_{i,j}=1\) if two atoms \(i\) and \(j\) are within the predefined radius \(r\) and \(^{b}_{ij}=0\) otherwise. Moreover, a single stoichiometry graph \(^{a}\) is associated with a set of polymorphic crystal structural graphs \(^{^{a}}\), i.e., \(^{^{a}}=\{^{b}_{1},,^{b}_{n _{p}}\}\), where \(n_{p}\) is the number of polymorphs for the stoichiometry. Note that each node in \(^{b}\) is associated with a learnable feature \(^{b}^{F}\), which is shared across all crystals, to make sure we utilize only structural information. We provide further details on structural graph construction in Appendix A.

### Task Descriptions

Given the stoichiometry graph \(^{a}\) and the structural graph \(^{b}\) of a single crystal, our objective is to acquire a stoichiometry encoder denoted as \(f^{a}\), alongside mean and variance modules referred to as \(f^{a}_{}\) and \(f^{a}_{}\), which associate structural information of \(^{b}\) into latent representation of stoichiometry \(^{a}\). Then, the modules are applied to a range of downstream tasks, a scenario frequently encountered in real-world material science where _solely stoichiometry of material is accessible_.

## 4 Methodology: PolySRL

In this section, we present Polymorphic Stoichiometry Representation Learning (PolySRL), which learns the representation of stoichiometry regarding polymorphic structures of crystals. Overall model architecture is illustrated in Figure 2.

### Structural Graph Encoder

While structural information plays an important role in determining various properties of crystals, previous studies have overlooked the readily available crystal structures  for stoichiometry representation learning [25; 20; 56]. To this end, we use a GNN encoder to learn the representation of crystal structure, which is expected to provide guidance for learning the representation of stoichiometry. More formally, given the crystal structural graph \(^{b}=(^{b},^{b})\), we obtain a structural representation of a crystal as follows:

\[^{b}=(^{b}),\ \ ^{b}=f^{b}( ^{b},^{b}),\] (1)

where \(^{b}^{n_{s} F}\) is a matrix whose each row indicates the representation of each atom in the crystal structure, \(^{b}\) indicates the latent representation of a crystal structure, and \(f^{b}\) is the GNN-based crystal structural encoder. In this paper, we adopt graph networks  as the encoder, which is a generalized version of various GNNs, and sum pooling is used as the pooling function. We provide further details on the GNNs in Appendix B.1.

### Probabilistic Stoichiometry Encoder

**Deterministic Representation.** After obtaining the structural representation \(^{b}\), we also compute the stoichiometry representation from the stoichiometry graph \(^{a}\) as follows:

\[^{a}=(^{a}),\ \ ^{a}=f^{a}(^{a}, ^{a}),\] (2)

where \(^{a}^{n_{a} F}\) is a matrix whose each row indicates the representation of each element in a stoichiometry, \(^{a}^{F}\) indicates the stoichiometry representation of a crystal, and \(f^{a}\) is a GNN-based stoichiometry encoder. By utilizing GNNs, the stoichiometry encoder effectively learns intricate relationships and chemical environments related to elements, thereby enhancing the stoichiometry representation in a systematic manner . For the stoichiometry encoder \(f^{a}\), we adopt GCNs  with jumping knowledge , and weighted sum pooling with the compositional ratio (i.e., \(\) in Section 3.1) is used as the pooling function.

One straightforward approach for injecting structural information into the stoichiometry representation would be adopting the idea of recent multi-modal contrastive learning approaches, which have been widely known to maximize the mutual information between heterogeneous modality inputs (two modalities in our case: stoichiometry and structure) [46; 49]. However, such a naive adoption fails to capture the polymorphic nature of crystallography: _A single stoichiometry can result in multiple distinct structures due to the diverse atomic arrangements, leading to significantly different physical, and chemical properties_. That is, the relationship between the representations \(^{a}\) and \(^{b}\) constitutes a one-to-many mapping rather than a one-to-one mapping, leading to inherent uncertainties in the stoichiometry representation \(^{a}\).

**Probabilistic Representation.** To this end, we propose to learn a probabilistic representation of stoichiometry \(^{a}\), which naturally exhibits uncertainties of the representation, inspired by the recent Hedge Instance Embeddings (HIB) . The main idea here is to learn the Gaussian representation of stoichiometry, which reveals the distribution of polymorphic structures \(^{a}\) in representation space. Intuitively, the variance of this distribution reflects the range of diversity within these structures, giving us an idea of how well the representation adheres to the principle of _preservativity_. More formally, we model each stoichiometry as a parameterized Gaussian distribution with learnable mean vectors and diagonal covariance matrices as follows:

\[p(}^{a}|^{a},^{a})( ^{a}_{},^{a}_{}),\ \ \ \ \ ^{a}_{}=f^{a}_{}(^{a}),\ \ ^{a}_{}=f^{a}_{}(^{a}).\] (3)

Here, \(^{a}_{},^{a}_{}^{F}\) denote the mean vector and the diagonal entries of the covariance matrix, respectively, and \(f^{a}_{}\) and \(f^{a}_{}\) refer to the modules responsible for calculating the mean and diagonal covariance matrices, respectively. During training, we adopt the re-parameterization trick  to obtain samples from the distribution, i.e., \(}^{a}=diag(^{a}_{}})+ ^{a}_{}\), where \((0,1)\). While mean and variance are obtained from the shared \(^{a}\), we utilize different attention-based set2set pooling functions for \(f^{a}_{}\) and \(f^{a}_{}\), since the attentive aspects involved in calculating the mean and variance should be independent from each other. We provide further details on the probabilistic stoichiometry encoder in Appendix B.2.

### Model Training via Representation Alignment

To incorporate the structural information into the stoichiometry representation, we define a matching probability between the stoichiometry graph \(^{a}\) and its corresponding set of polymorphic crystal

Figure 2: Overall model architecture.

structural graphs \(^{^{a}}\) in the Euclidean space as follows:

\[p(m|^{a},^{^{a}})_{p^{ a}}_{j=1}^{J}-c\|}_{j}^{a}- _{p}^{b}\|_{2}+d,\] (4)

where \(}_{j}^{a}\) is the sampled stoichiometry representation (Section 4.2), \(_{p}^{b}\) is the structural graph representation (Section 4.1), \(c,d>0\) are parameters learned by the model for soft threshold in the Euclidean space, \(J\) is the number of samples sampled from the distribution, and \(()\) is the sigmoid function. Moreover, \(m\) is the indicator function of value \(1\) if \(^{^{a}}\) is the set of polymorphic structures corresponding to \(^{a}\) and 0 otherwise. Then, we apply the soft contrastive loss [43; 14] as:

\[_{}=- p(m|^{a},^{ ^{a^{}}}),&$,}\\ -(1-p(m|^{a},^{^{a^{}}})),&\] (5)

Intuitively, the above loss aims to minimize the distance between a sampled stoichiometry representation and its associated polymorphic structural representations, while maximizing the distance between others. By doing so, PolySRL learns a probabilistic stoichiometry representation that considers the structural information and its associated uncertainties, which tend to increase when multiple structures are associated with a single stoichiometry, i.e., polymorphism.

In addition to the soft contrastive loss, we utilize a KL divergence loss between the learned stoichiometry distributions and the standard normal distribution \((0,1)\), i.e., \(_{}=(p(}^{a}|^{a}, ^{a})(0,1))\), which prevents the learned variances from collapsing to zero. Therefore, our final loss for model training is given as follows:

\[_{}=_{}+_{ },\] (6)

where \(\) is the hyperparameter for controlling the weight of the KL divergence loss. During the inference, we use the mean vector \(_{}^{a}\) as the stoichiometry representation and the geometric mean of diagonal covariance matrices \(_{}^{a}\) as uncertainty .

## 5 Experiments

### Experimental Setup

**Datasets.** For training PolySRL, we collect 80,162 unique stoichiometries and their corresponding 112,183 DFT-calculated crystal structures from **Materials Project (MP)** website 3. However, since DFT-calculated properties often deviate from real-world wet-lab experimental properties , we primarily evaluate PolySRL using wet-lab experimental datasets. Specifically, we use publicly available datasets containing experimental properties of stoichiometry, including **Band Gap**, **Formation Enthalpies**, **Metallic**, and **ESTM**. Moreover, we conduct experiments on seven **Matbench** datasets that are related to DFT-calculated properties. We provide further details on the datasets in Appendix C.

**Baseline Methods.** Since PolySRL is the first work that learns stoichiometry representation without any label information, we construct competitive baseline models from other domains. **Rand init.** refers to a randomly initialized stoichiometry encoder without any training process. **GraphCL** learns the stoichiometry representation based on random augmentations on the stoichiometry graph \(^{a}\), without utilizing structural information. **MP Band G.** and **MP Form. E.** learn the stoichiometry representation by predicting the DFT-calculated properties, which are available in **MP** database 4, i.e., band gap and formation energy per atom, respectively. **3D Infomax** learns stoichiometry representation by maximizing the mutual information between stoichiometry graph \(^{a}\) and structural graph \(^{b}\) with NTXent (Normalized Temperature-scaled Cross Entropy) loss . We provide further details on baseline methods in Appendix D. In addition, we also compare PolySRL with supervised stoichiometry representation learning methods, i.e., **Roost** and **CrabNet** in Appendix F.2.

**Evaluation Protocol.** We first train all models in an unsupervised manner without any use of wet-lab experimental data. Then, we evaluate PolySRL in two evaluation schemes, i.e., representation learning and transfer learning. We further provide the detailed evaluation protocols in Appendix E.

### Empirical Results

**Representation Learning.** In Table 1, we have the following observations: **1)** Comparing the baseline methods that take into account structural information (**Str. \(\)**) with those that do not (**Str. \(\)**), we find out that utilizing structural information generally learns more high-quality stoichiometry representations. This is consistent with the established knowledge in crystallography, which emphasizes that structural details, including crystal structure and symmetry, play a crucial role in determining a wide range of physical, chemical, and mechanical properties . **2)** Moreover, we observe PolySRL outperforms baseline methods that overlook polymorphism in their model design. This highlights the significance of our probabilistic approach, which not only offers insights into polymorphism-related uncertainties but also yields high-quality representations. **3)** On the other hand, we notice that utilizing DFT-calculated values contributes to the model's understanding of a specific target property (see **Prop. \(\)**). For instance, when the model is trained with a DFT-calculated band gap (i.e., MP Band G.), it surpasses all other models when predicting experimental band gap values. This highlights that knowledge acquired from DFT-calculated properties can be applied to wet-lab experimental datasets. However, these representations are highly tailored to a particular target property, which restricts their generalizability for diverse tasks. We also provide empirical results on Matbench datasets that contain DFT-calculated properties in Appendix F.1 and transfer learning scenarios in Appendix F.2.

**Physical Validity of Predicted Properties.** To further verify the physical validity of predicted properties, we theoretically calculate the figure of merit \(Z\)4 of thermoelectrical materials with the predicted properties in ESTM datasets in Table 1. More specifically, given predicted electrical conductivity (E.C.) \(\), thermal conductivity (T.C.) \(\), Seebeck coefficient \(S\), we can compute the figure of merit \(Z\) as follows: \(Z=}{}\), where \(\) indicates a conditioned temperature, i.e., 300 K and 600 K. In Table 1, we have following observations: **1)** Looking at the general model performance on ESTM datasets and \(Z\), we find that performing well on ESTM datasets does not necessarily indicate the predictions are physically valid. **2)** In contrast, models that incorporate structural information tend to produce physically valid predictions in both ESTM datasets, underscoring the importance of the crystal structural information. **3)** Moreover, PolySRL consistently outperforms baseline methods, demonstrating that PolySRL not only learns accurate representations of stoichiometry but also ensures the physical validity of the predictions. We provide further analysis on the predicted \(Z\), and high throughput screening results of thermoelectrical materials in Appendix F.3.

### Uncertainty Analysis

**Number of Structures.** In this section, we examine how uncertainties vary according to the number of possible structures. To do so, we first collect all possible structures of stoichiometry in Band Gap dataset from MP database3 and **Open Quantum Materials Database (OQMD)5**. Subsequently, we compute the average uncertainties for stoichiometry groups with the same number of possible structures. In Figure 3 (a), we have the following observations: **1)** In

    &  &  &  &  \\   & **Prop.** & **Str.** & **Poly.** & **Band G.** & **Form. E.** & **Metallic** & E.C. & T.C. & Seebeck & E.C. & T.C. & Seebeck & 300K & 600K \\  Rand init. & ✗ & ✗ & ✗ & 0.439 & 0.671 & 0.211 & 1.029 & 0.225 & 0.451 & 0.714 & 0.218 & 0.437 & 0.099 & 0.261 \\  & & & & 0.461 & 0.064 & 0.065 & 0.019 & 0.019 & 0.019 & 0.020 & 0.007 & 0.017 & 0.160 \\ GraphCL & ✗ & ✗ & ✗ & ✗ & 0.437 & 0.677 & 0.212 & 0.579 & 0.229 & 0.459 & 0.695 & 0.206 & 0.440 & 0.121 & 0.211 \\  & & & & 0.423 & 0.060 & 0.019 & 0.115 & 0.008 & 0.040 & 0.119 & 0.027 & 0.077 & 0.026 & 0.040 \\ MP Band G. & ✓ & ✗ & ✗ & ✗ & **0.403** & 0.690 & 0.212 & 1.008 & 0.225 & 0.443 & 0.690 & 0.217 & 0.436 & 0.129 & 0.251 \\  & & & & 0.461 & 0.043 & 0.065 & 0.081 & 0.059 & 0.019 & 0.019 & 0.029 & 0.075 & 0.094 & 0.131 \\ MP Form. E. & ✓ & ✗ & ✗ & 0.416 & 0.619 & 0.203 & 1.121 & 0.228 & 0.441 & 0.784 & 0.220 & 0.444 & 0.093 & 0.328 \\  & & & & 0.475 & 0.082 & 0.052 & 0.137 & 0.716 & 0.049 & 0.019 & 0.020 & 0.001 & 0.000 & 0.006 & 0.057 \\
3D Infomax & ✓ & ✓ & ✗ & 0.428 & 0.654 & 0.201 & 0.969 & 0.217 & 0.432 & 0.692 & 0.212 & 0.428 & 0.105 & 0.171 \\  & & & & & 0.455 & 0.015 & 0.010 & 0.010 & 0.010 & 0.010 & 0.010 & 0.010 & 0.013 & 0.013 & 0.019 & 0.000 & 0.013 \\  PolySRL & ✓ & ✓ & ✓ & ✓ & 0.407 & **0.592** & **0.194** & **0.912** & **0.197** & **0.388** & **0.665** & **0.189** & **0.412** & **0.070** & **0.168** \\  & & & & & 0.481 & 0.043 & 0.047 & 0.017 & 0.121 & 0.020 & 0.020 & 0.123 & 0.001 & 0.003 & 0.001 & 0.013 \\   

Table 1: Representation learning performance (MAE) (Prop.: Property / Str.: Structure / Poly.: Polymorphism / Band G.: Band Gap / Form. E.: Formation Entalphies / E.C.: Electrical Conductivity / T.C.: Thermal Conductivity)general, the uncertainty of stoichiometry that has polymorphic structures (\(\#\) possible structures \( 2\)) was higher than that of the stoichiometry with a single structure (\(\#\) possible structures \(=1\)), demonstrating that PolySRL learns uncertainties regarding polymorphic structures.

**2)** On the other hand, an increase in the number of possible structures in OQMD leads to an increase in the uncertainty, demonstrating that PolySRL learns uncertainties related to the diverse polymorphic structures. Note that this trend is mainly shown in the OQMD dataset due to the fact that OQMD encompasses not only realistic but also theoretically possible structures, indicating that PolySRL acquires knowledge of theoretical uncertainties in materials science. **3)** Furthermore, we notice high uncertainties when there are no potential structures available (i.e., when \(\#\) possible structures \(=0\)) in comparison to stoichiometry with a single possible structure, suggesting that uncertainty contains information about the computational feasibility of the structure.

**Impurity of Materials.** Next, we investigate how impurities in materials influence the uncertainty in stoichiometry. Specifically, we compare the average stoichiometry uncertainty between groups of doped or alloyed materials (i.e., Impure) and their counterparts (i.e., Pure) in thermoelectric materials datasets, i.e., ESTM 300K and ESTM 600K, where doping and alloying are commonly employed to enhance their performance. In Figure 3 (b), we notice a substantial increase in the uncertainty within impure materials compared with their pure counterparts. This observation is in line with common knowledge in materials science that doping or alloying can lead to chaotic transformations in a conventional structure [30; 28], demonstrating that PolySRL also captures the complexity of structure as the uncertainty. In conclusion, uncertainty analysis highlights that PolySRL effectively captures the uncertainty related to the presence of polymorphic structures within a single stoichiometry and the computational challenges associated with crystal structures.

**Case Studies.** While our previous analysis on uncertainties generally aligns with our expectations, we do observe some instances where PolySRL exhibits high uncertainty in non-polymorphic stoichiometries and minimal uncertainty in polymorphic stoichiometries. First, we observe the stoichiometry of HgCl and CaS exhibit high uncertainty, even though they only have one possible structure (Figure 4 (a)). We attribute this phenomenon to the limited availability of element combinations in the MP dataset, which occurred due to several factors, including the rarity of certain elements and the difficulty in synthesizing substances with specific combinations of elements [8; 24]. On the other hand, we observe the learned distribution of ScN and AgSO4 collapsed to zero even though each of them has three possible polymorphic structures (Figure 4 (b)). This behavior arises from the structural similarity among the polymorphic structures, where all three polymorphic structures of each stoichiometry fall within the same cubic and monoclinic structural system, respectively. In conclusion, PolySRL acquires detailed insights concerning polymorphic structures beyond mere quantitative counts. Additionally, we include further analysis on the correlation between uncertainty and model performance, along with supplementary case studies that are in line with our anticipated results in Appendix F.5.

## 6 Conclusion

This paper focuses on learning a probabilistic representation of stoichiometry that incorporates polymorphic structural information of crystalline materials. Given stoichiometry and its corresponding polymorphic structures, PolySRL learns parameterized Gaussian distribution for each stoichiometry, whose mean becomes the representation of stoichiometry and variance indicates the level of uncertainty stemming from the polymorphic structures. Extensive empirical studies on sixteen datasets, including wet-lab experimental data and DFT-calculated data, have been conducted to validate the effectiveness of PolySRL in learning stoichiometry representations. Moreover, a comprehensive analysis of uncertainties reveals that the model learns diverse complexities encountered in materials science, highlighting the practicality of PolySRL in real-world material discovery process.

Figure 4: Case studies.

Figure 3: Uncertainty analysis.