# DFRD: Data-Free Robustness Distillation for Heterogeneous Federated Learning

Kangyang Luo\({}^{1}\), Shuai Wang\({}^{1}\), Yexuan Fu\({}^{1}\), Xiang Li\({}^{1}\)1, Yunshi Lan\({}^{1}\), Ming Gao\({}^{1,2}\)

School of Data Science & Engineering\({}^{1}\)

KLATASDS-MOE in School of Statistics\({}^{2}\)

East China Normal University

Shanghai, China

{52205901003, 51215903058,51215903042}@stu.ecnu.edu.cn

{xiangli, yslan, mgao}@dase.ecnu.edu.cn

###### Abstract

Federated Learning (FL) is a privacy-constrained decentralized machine learning paradigm in which clients enable collaborative training without compromising private data. However, how to learn a robust global model in the data-heterogeneous and model-heterogeneous FL scenarios is challenging. To address it, we resort to data-free knowledge distillation to propose a new FL method (namely DFRD). DFRD equips a conditional generator on the server to approximate the training space of the local models uploaded by clients, and systematically investigates its training in terms of _fidelity_, _transferability_ and _diversity_. To overcome the catastrophic forgetting of the global model caused by the distribution shifts of the generator across communication rounds, we maintain an exponential moving average copy of the generator on the server. Additionally, we propose dynamic weighting and label sampling to accurately extract knowledge from local models. Finally, our extensive experiments on various image classification tasks illustrate that DFRD achieves significant performance gains compared to SOTA baselines. Our code is here: [https://anonymous.4open.science/r/DFRD-0C83/](https://anonymous.4open.science/r/DFRD-0C83/).

## 1 Introduction

With the surge of data, deep learning algorithms have made significant progress in both established and emerging fields . However, in many real-world applications (e.g., mobile devices , IoT , and autonomous driving , etc.), data is generally dispersed across different clients (i.e., data silos). Owing to the high cost of data collection and strict privacy protection regulations, the centralized training that integrates data together is prohibited . Driven by this reality, Federated Learning (FL)  has gained considerable attention in industry and academia as a promising distributed learning paradigm that allows multiple clients to participate in the collaborative training of a global model without access to their private data, thereby ensuring the basic privacy.

Despite its remarkable success, the inevitable hurdle that plagues FL research is the vast heterogeneity among real-world clients . Specifically, the distribution of data among clients may be non-IID (identical and independently distributed), resulting in **data heterogeneity**. It has been confirmed that the vanilla FL method FedAvg  suffers from _client drift_ in this case, which leads to severe performance degradation. To ameliorate this issue, a plethora of modifications  for FedAvg focus on regularizing the objectives of the local models to align the global optimization objective. All of the above methods follow the widely accepted assumption of model homogeneity, where local models have to share the same architecture as the global model. Nevertheless,when deploying FL systems, different clients may have distinct hardware and computing resources, and can only train the model architecture matching their own resource budgets , resulting in **model heterogeneity**. In this case, to enable the FL systems with model homogeneity, on the one hand, clients with low resource budgets, which may be critical for enhancing the FL systems, will be discarded at the expense of training bias . On the other hand, keeping a low complexity for the global model to accommodate all clients leads to performance drop due to the limited model capacity . Therefore, the primary challenge of model-heterogeneous FL is how to conduct model aggregation of heterogeneous architectures among clients to enhance the inclusiveness of federated systems. To solve this challenge, existing efforts fall broadly into two categories: knowledge distillation (KD)-based methods  and partial training (PT)-based methods , yet each of them has its own limitations. Concretely, KD-based methods require additional public data to align the logits outputs between the global model (student) and local models (teachers). But the desired public data is not always available in practice and the performance may decrease dramatically if the apparent disparity in distributions exists between public data and clients' private data . PT-based methods send width-based sub-models to clients, which are extracted by the server from a larger global model according to each client's resource budget, and then aggregate these trained sub-models to update the global model. PT-based methods can be considered as an extension of FedAvg to model-heterogeneous scenarios, which means they are implementation-friendly and computationally efficient, but they also suffer from the same adverse effects from data heterogeneity as FedAvg or even more severely. In a word, how to learn a robust global model in FL with both data and model heterogeneity is a highly meaningful and urgent problem.

To this end, we systematically investigate the training of a robust global model in FL with both data and model heterogeneity with the aid of data-free knowledge distillation (DFKD) . See the related work in Appendix A for more DFKD methods. Note that the strategy of integrating DFKD to FL is not unique to us. Recently, FedFTG  leverages DFKD to fine-tune the global model in model-homogeneous FL to overcome data heterogeneity, and DENSE  aggregates knowledge from heterogeneous local models based on DFKD to train a global model for one-shot FL. They all equip the server, which possesses powerful hardware and computing resources, with a generator to approximate the training space of the local models (teachers), and train the generator and the global model (student) in an adversarial manner. However, the local models uploaded per communication round are not only architecturally heterogeneous but also trained on non-IID distributed private data in the situation of both data and model heterogeneity. _In this case, the generator tends to deviate from the real data distribution. Also, its output distribution may undergo large shifts (i.e., distribution shifts) across communication rounds, causing the global model to catastrophically forget useful knowledge learned in previous rounds and suffer from performance degradation._ To confront the mentioned issues, we propose a novel **D**ata-**F**ree **R**obust **D**istillation FL method called DFRD, which utilizes a conditional generator to generate synthetic data and thoroughly studies how to effectively and accurately simulate the local models' training space in terms of _fidelity_, _transferability_ and

Figure 1: The full pipeline for DFRD combined with a PT-based method. DFRD works on the server and contains two phases, _training generator_ and _robust model distillation_, where \(_{tran},_{div},_{fid}\) and \(_{kl},}_{kl}\) are the loss objectives of the conditional generator and the global model, respectively.

_diversity_[48; 49]. To mitigate catastrophic forgetting of the global model, an exponential moving average (EMA) copy of the conditional generator is maintained on the server to store previous knowledge learned from the local models. The EMA generator, along with the current generator, provides training data for updates of the global model. Also, we propose dynamic weighting and label sampling to aggregate the logits outputs of the local models and sample labels respectively, thereby properly exploring the knowledge of the local models. We revisit FedFTG and DENSE, and argue that DFRD as a fine-tuning method (similar to FedFTG) can significantly enhance the global model. So, we readily associate the PT-based methods in model-heterogeneous FL with the ability to rapidly provide a preliminary global model, which will be fine-tuned by DFRD. We illustrate the schematic for DFRD as a fine-tuning method based on a PT-based method in Fig. 1. Although FedFTG and DENSE can also be applied to fine-tune the global model from the PT-based methods after simple extensions, we empirically find that they do not perform as well, and the performance of the global model is even inferior to that of local models tailored to clients' resource budgets.

Our main contributions of this work are summarized as follows. First, we propose a new FL method termed DFRD that enables a robust global model in both data and model heterogeneity settings with the help of DFKD. Second, we systematically study the training of the conditional generator w.r.t. _fidelity_, _transferability_ and _diversity_ to ensure the generation of high-quality synthetic data. Additionally, we maintain an EMA generator on the server to overcome the global model's catastrophic forgetting caused by the distribution shifts of the generator. Third, we propose dynamic weighting and label sampling to accurately extract the knowledge of local models. At last, our extensive experiments on six real-world image classification datasets verify the superiority of DFRD.

## 2 Notations and Preliminaries

**Notations.** In this paper, we focus on the centralized setup that consists of a central server and \(N\) clients owning private labeled datasets \(\{(_{i},_{i})\}_{i=1}^{N}\), where \(_{i}=\{_{i}^{b}\}_{b=1}^{n_{i}}\) follows the data distribution \(_{i}\) over feature space \(_{i}\), i.e., \(_{i}^{b}_{i}\), and \(_{i}=\{y_{i}^{b}\}_{b=1}^{n_{i}}[C]:=\{1,,C\}\) denotes the ground-truth labels of \(_{i}\). And \(C\) refers to the total number of labels. Remarkably, the heterogeneity for FL in our focus includes both data heterogeneity and model heterogeneity. **For the former**, we consider the same feature space, yet the data distribution may be different among clients, that is, label distribution skewness in clients (i.e., \(_{i}=_{j}\) and \(_{i}_{j}, i j,i,j[N]\)). **For the latter**, each client \(i\) holds an on-demand local model \(f_{i}\) parameterized by \(_{i}\). Due to the difference in resource budgets, the model capacity of each client may vary, i.e., \(|_{i}||_{j}|, i j,i,j[N]\). In PT-based methods, we define a confined width capability \(R_{i}(0,1]\) according to the resource budget of client \(i\), which is the proportion of nodes extracted from each layer in the global model \(f\). Note that \(f\) is parameterized by \(\), and \(||\) denotes the number of elements in vector \(\).

**PT-based method** is a solution for model-heterogeneous FL, which strives to extract a matching width-based slimmed-down sub-model from the global model as a local model according to each client's budget. As with FedAvg, it requires the server to periodically communicate with the clients. In each round, there are two phases: local training and server aggregation. In local training, each client trains the sub-model received from the server utilizing the local optimizer. In server aggregation, the server collects the heterogeneous sub-models and aggregates them by straightforward selective averaging to update the global model, as follows [28; 29; 30; 31]:

\[_{[l,k]}^{t}=_{t}}p_{j}}_{i _{t}}p_{i}_{i,[l,k]}^{t}, \]

where \(_{t}\) is a subset sampled from \([N]\) and \(p_{i}\) is the weight of client \(i\), which generally indicates the size of data held by client \(i\). At round \(t\), \(_{[l,k]}^{t}\) denotes the \(k^{th}\) parameter of layer \(l\) of the global model and \(_{i,[l,k]}^{t}\) denotes the parameter \(_{[l,k]}^{t}\) updated by client \(i\). We can clearly see that Eq. (1) independently calculates the average of each parameter for the global model according to how many clients update that parameter in round \(t\). Instead, the parameter remains unchanged if no clients update it. Notably, if \(|_{i}^{t}|=|^{t}|\) for any \(i[N]\), PT-based method becomes FedAvg. The key to PT-based method is to select \(_{i}^{t}\) from the global model \(^{t}\) when given \(R_{i}\). And existing sub-model extraction schemes fall into three categories: _static_[28; 29], _random_ and _rolling_.

Proposed Method

In this section, we detail the proposed method DFRD. We mainly work on considering DFRD as a fine-tuning method to enhance the PT-based methods, thus enabling a robust global model in FL with both data and model heterogeneity. Fig. 1 visualizes the training procedure of DFRD combined with a PT-based method, consisting of four stages on the server side: _training generator_, _robust model distillation_, _sub-model extraction_ and _model aggregation_. Note that _sub-model extraction_ and _model aggregation_ are consistent with that in the PT-based methods, so we detail the other two stages. Moreover, we present pseudocode for DFRD in Appendix C.

### Training Generator

At this stage, we aim to train a well-behaved generator to capture the training space of local models uploaded from active clients. Specifically, we consider a conditional generator \(G()\) parameterized by \(\). It takes as input a random noise \(^{d}\) sampled from standard normal distribution \((,)\), and a random label \(y[C]\) sampled from label distribution \(p(y)\), i.e., the probability of sampling \(y\), thus generating the synthetic data \(=G(=o(,y),)\). Note that \(o(,y)\) represents the merge operator of \(\) and \(y\). To the best of our knowledge, synthetic data generated by a well-trained generator should satisfy several key characteristics: _fidelity_, _transferability_, and _diversity_[48; 49]. Therefore, in this section, we construct the loss objective from the referred aspects to ensure the quality and utility of \(G()\).

**Fidelity.** To commence, we study the fidelity of the synthetic data. Specifically, we expect \(G()\) to simulate the training space of the local models to generate the synthetic dataset with a similar distribution to the original dataset. To put it differently, we want the synthetic data \(\) to approximate the training data with label \(y\) without access to clients' training data. To achieve it, we form the fidelity loss \(_{fid}\) at logits level:

\[_{fid}=CE(_{i_{t}}_{i,y}f_{i}(,_{i}),y), \]

where \(CE\) denotes the cross-entropy function, \(f_{i}(,_{i})\) is the logits output of the local model from client \(i\) when \(\) is given, \(_{i,y}\) dominates the weight of logits from different clients \(\{i|i_{t}\}\) when \(y\) is given. And \(_{fid}\) is the cross-entropy loss between the weighted average logits \(_{i_{t}}_{i,y}f_{i}(,_{i})\) and the label \(y\). By minimizing \(_{fid}\), \(\) is enforced to be classified into label \(y\) with a high probability, thus facilitating the fidelity of \(\).

In reality, the conditional generator \(G()\) easily generates synthetic data with low classification errors (i.e. \(_{fid}\) close to \(0\)) as the training proceeds. This may cause the synthetic data to fall into a space far from the decision boundary of the ensemble model (i.e., \(_{i_{t}}_{i,y}f_{i}(,_{i})\)) if only \(_{fid}\) is optimized, as shown in the synthetic data represented by red circles in Fig. 2 (a). Note that \(d_{S}\) and \(d_{T}\) denote the decision boundaries of the global model (student) and the ensemble model (teacher), respectively. An obvious observation is that the red circles are correctly classified on the same side of the two decision boundaries (i.e., \(d_{S}\) and \(d_{T}\)), making it difficult to transfer teacher's knowledge to student. We next explore how to augment the transferability of the synthetic data to ameliorate this pitfall.

**Transferability** is intended to guide \(G()\) in generating synthetic data that moves the decision boundary of the global model towards that of the ensemble model, such as synthetic data with black circles in Fig. 2 (b). However, during the training of \(d_{S}\) to approach \(d_{T}\), we find that \(G()\) can easily generate two other types of synthetic data, the yellow and purple circles in Fig. 2 (c). Both of them are misclassified by the ensemble model (\(d_{T}\)), while the yellow circles are correctly classified and

Figure 2: The visualization of synthetic data and decision boundaries of global model (student) and ensemble model (teacher). _Left panel_: synthetic data (red circles) are far away from the decision boundary \(d_{T}\). _Middle panel_: synthetic data (black circles) near the decision boundaries \(d_{T}\). _Right panel_: synthetic data (yellow and purple circles) cross over the decision boundary \(d_{T}\).

the purple circles are misclassified by the global model (\(d_{S}\)). For the conditional generator \(G()\) that takes label information as one of the inputs, yellow and purple circles can mislead the generator, thereby leading to \(d_{S}\) approximating \(d_{T}\) with a large deviation, as shown in Fig. 2 (c). Based on the above observation, we reckon that the synthetic data \(=G(=o(,y),)\) is useful if it is classified as \(y\) by the ensemble model but classified not as \(y\) by the global model. To realize it, we maximize the logits discrepancy between the global model and the ensemble model on synthetic data with black circles by leveraging Kullback-Leibler divergence loss, which takes the form:

\[_{tran}=- KL(_{i_{t}}_{i,y}f_ {i}(,_{i}),f(,)), \]

where \(KL\) is Kullback-Leibler divergence function and \(f(,)\) denotes the logits output of the global model on \(\) with label \(y\). Note that \(=1\) if \( f(,) y\) and \(_{i_{t}}_{i,y}f_{i}(,_{i})=y\) hold, otherwise \(=0\). (\(\))

We would like to point out that the existing works  and  are in line with our research perspective on the transferability of generator, which aims to generate more synthetic data with black circles. However, they do not carefully frame learning objective for enhancing the transferability of generator. Concretely,  does not consider the type of synthetic data, i.e., \(=1\) always holds, thus inducing the generation of synthetic data with yellow and purple circles. (\(\))  focuses on synthetic data satisfying \( f(,)_{i_{t}}_{i,y} f_{i}(,_{i})\), but enables the generation of synthetic data with purple circles yet. (\(\)) 2

**Diversity.** Although we enable \(G()\) to generate synthetic data that falls around the real data by optimizing \(_{fid}\) and \(_{tran}\), the diversity of synthetic data is insufficient. Due to the fact that the generator may get stuck in _local equilibria_ as the training proceeds, model collapse occurs . In this case, the generator may produce similar data points for each class with little diversity. Also, the synthetic data points may not differ significantly among classes. This causes the empirical distribution estimated by \(G()\) to cover only a small manifold in the real data space, and thus only partial knowledge of the ensemble model is extracted. To alleviate this issue, we introduce a diversity loss \(_{div}\) with label information to increase the diversity of synthetic data as follows:

\[_{div}=\|_{j}-_{k}\|_{2}*\|_{j}-_{k}\|_{2}/B^{2})}, \]

where \(B\) denotes the batch size and \(_{j/k}=G(_{j/k}=o(_{j/k},y_{j/k}),)\). Intuitively, \(_{div}\) takes \(\|_{j}-_{k}\|_{2}\) as a weight, and then multiplies it by the corresponding \(\|_{j}-_{k}\|_{2}\) in each batch \(B\), thus imposing a larger weight on the synthetic data points pair (\(_{j}\) and \(_{k}\)) at the more distant input pair (\(_{j}\) and \(_{k}\)). Notably, we merge the random noise \(\) with label \(y\) as the input of \(G()\) to overcome spurious solutions . Further, we propose a multiplicative merge operator, i.e., \(o(,y)=(y)\), where \(\) is a trainable embedding and \(\) means vector element-wise product. We find that our merge operator enables synthetic data with more diversity compared to others, possibly because the label information is effectively absorbed into the stochasticity of \(\) by multiplying them when updating \(\). See Section 4.3 for more details and empirical justification.

Combining \(_{fid}\), \(_{tran}\) and \(_{div}\), the overall objective of the generator can be formalized as follows:

\[_{gen}=_{fid}+_{tran}_{tran}+ _{div}_{div}, \]

where \(_{tran}\) and \(_{div}\) are tunable hyper-parameters. Of note, the synthetic data generated by a well-trained generator should be visually distinct from the real data for privacy protection, while it can capture the common knowledge of the local models to ensure similarity to the real data distribution for utility. More privacy protection is discussed in Appendices A and A.

### Robust Model Distillation

Now we update the global model. Normally, the global model attempts to learn as much as possible logits outputs of the ensemble model on the synthetic data generated by the generator based on knowledge distillation . The updated global model and the ensemble model are then served to train \(G()\) with the goal of generating synthetic data that maximizes the mismatch between them in terms of logits outputs (see _transferability_ discussed in the previous section). This adversarial game enables the generator to rapidly explore the training space of the local models to help knowledge transfer from them to the global model. However, it also leads to dramatic shifts in the output distribution of \(G()\) across communication rounds under heterogeneous FL scenario (i.e., distribution shifts), causing the global model to catastrophically forget useful knowledge gained in previous rounds. To tackle the deficiency, we propose to equip the server with a generator \(()\) parameterized by \(}\) that is an exponential moving average (EMA) copy of \(G()\). Its parameters at the \(t^{th}\) communication round are computed by

\[}^{t}=}^{t-1}+(1-) ^{t}, \]

where \((0,1)\) is the momentum. We can easily see that the parameters of \(()\) vary very little compared to those of \(G()\) over communication rounds, if \(\) is close to \(1\). We further utilize synthetic data from \(()\) as additional training data for the global model outside of \(G()\), mitigating the huge exploratory distribution shift induced by the large update of \(G()\) and achieving stable updates of the global model. Particularly, we compute the Kullback-Leibler divergence between logits of the ensemble model and the global model on the synthetic data points \(=G(=o(,y),)\) and \(}=(}=o(}, ),})\) respectively, which is formulated as follows:

\[_{md}=_{kl}+}_{kl}=KL(f( {s},),_{i_{t}}_{i,y}f_{i}(, _{i}))+ KL(f(},),_{i_ {t}}_{i,}f_{i}(},_{i})), \]

where \(\) is a tunable hyper-parameter for balancing different loss items.

**Dynamic Weighting and Label Sampling.** So far, how to determine \(_{i,y}\) and \(p(y)\) is unclear. The appropriate \(_{i,y}\) and \(p(y)\) are essential for effective extraction of knowledge from local models. For clarity, we propose dynamic weighting and label sampling, i.e., \(_{i,y}=n^{y}_{i,t}/n^{y}_{_{t},t}\) and \(p(y)=n^{y}_{_{t},t}/_{y[C]}n^{y}_{_{t},t}\), where \(n^{y}_{_{t},t}=_{j[_{t}]}n^{y}_{j,t}\) and \(n^{y}_{i,t}\) denotes the number of data with label \(y\) involved in training on client \(i\) at round \(t\). Due to space limitations, see Appendix F for their detail study and experimental justification.

## 4 Experiments

### Experimental Settings

**Datasets.** In this paper, we evaluate different methods with six real-world image classification task-related datasets, namely Fashion-MNIST  (FMNIST in short), SVHN , CIFAR-10, CIFAR-100 , Tiny-imageNet3 and Food101 . We detail the six datasets in Appendix B. To simulate data heterogeneity across clients, as in previous works [34; 37; 38], we use Dirichlet process \(Dir()\) to partition the training set for each dataset, thereby allocating local training data for each client. It is worth noting that \(\) is the concentration parameter and smaller \(\) corresponds to stronger data heterogeneity.

**Baselines.** We compare DFRD to FedFTG  and DENSE , which are the most relevant methods to our work. To verify the superiority of DFRD, on the one hand, DFRD, FedFTG and DENSE are directly adopted on the server to transfer the knowledge of the local models to a randomly initialized global model. We call them collectively **data-free methods**. On the other hand, they are utilized as **fine-tuning methods** to improve the global model's performance after computing weighted average per communication round. In this case, in each communication round, the preliminary global model is obtained using FedAvg  in FL with homogeneous models, whereas in FL with heterogeneous models, the PT-based methods, including HeteroFL , Federated Dropout  (FedDp for short) and FedRolex , are employed to get the preliminary global model. 4

**Configurations.** Unless otherwise stated, all experiments are performed on a centralized network with \(N=10\) active clients. We set \(\{0.01,0.1,1.0\}\) to mimic different data heterogeneity scenarios. To simulate model-heterogeneous scenarios, we formulate exponentially distributed budgets for a given \(N\): \(R_{i}=[]^{\{_{i}[]\}}(i[N])\), where \(\) and \(\) are both positive integers. We fix \(=4\)and consider \(\{5,10,40\}\). See Appendix D for more details. Unless otherwise specified, we set \(_{tran}\) and \(_{div}\) both to \(1\) in _training generator_, while in _robust model distillation_, we set \(=0.5\) and \(=0.5\). And all baselines leverage the same setting as ours. Due to space limitations, see Appendix E for the full experimental setup.

**Evaluation Metrics.** We evaluate the performance of different FL methods by local and global test accuracy. To be specific, for local test accuracy (_L.acc_ for short), we randomly and evenly distribute the test set to each client and harness the test set on each client to verify the performance of local models. In terms of global test accuracy (_G.acc_ for short), we employ the global model on the server to evaluate the global performance of different FL methods via utilizing the original test set. Note that _L.acc_ is reported in **round brackets**. To ensure reliability, we report the average for each experiment over \(3\) different random seeds.

### Results Comparison

**Impacts of varying \(\).** We study the performance of different methods at different levels of data heterogeneity on FMNIST, SVHN, CIFAR-10 and CIFAR-100, as shown in Table 1. One can see that the performance of all methods degrades severely as \(\) decreases, with DFRD being the only method that is robust while consistently leading other baselines with an overwhelming margin w.r.t. _G.acc_. Also, Fig. 3 (a)-(b) show that the learning efficiency of DFRD consistently beats other baselines (see Fig. 8-9 in Appendix H for complete curves). Notably, DFRD, FedFTG and DENSE as fine-tuning methods uniformly surpass FedAvg w.r.t. _G.acc_ and _L.acc_. However, their global test accuracies suffer from dramatic deterioration or even substantially worse than that of FedAvg when they act as data-free methods. We conjecture that FedAvg aggregates the knowledge of local models more effectively than data-free methods. Also, when DFRD is used to fine-tune FedAvg, it can significantly enhance the global model, yet improve the performance of local models to a less extent.

**Impacts of different \(\).** We explore the impacts of different model heterogeneity distributions on different methods with SVHN, CIFAR-10, Tiny-ImageNet and FOOD101. A higher \(\) means more clients with \(\)-width capacity w.r.t. the global model. From Table 2, we can clearly see that the performance of all methods improves uniformly with decreasing \(\), where DFRD consistently and overwhelmingly dominates other baselines in terms of \(G.acc\). Specifically, DFRD improves \(G.acc\) by an average of \(11.07\%\) and \(7.54\%\) on SVHN and CIFAR-10 respectively, compared to PT-based methods (including HeteroFL, FedDP and FedRolex). Meanwhile, DFRD uniformly and significantly outstrips FedFTG and DENSE w.r.t. \(G.acc\). The selected learning curve shown in Fig. 3 (c) also verifies the above statement (see Fig. 10-12 in Appendix H for more results). The above empirical results show that DFRD not only is robust to varying \(\), but also has significantly intensified effects on the global model for different PT-based methods. However, the results on Tiny-ImageNet and FOOD101 indicate that PT-based methods suffer from inferior test accuracy. Although DFRD improves their test accuracy, the improvement is slight. Notably, DFRD improves negligibly over PT-based methods when all clients exemplify \(\)-width capability. We thus argue that weak clients performing complex image classification tasks learn little useful local knowledge, resulting in the inability to provide effective information for the global model.

### Ablation Study

In this section, we carefully demonstrate the efficacy and indispensability of core modules and key parameters in our method on SVHN, CIFAR-10 and CIFAR-100. Thereafter, we resort to FedRolex+DFRD to yield all results. For SVHN (CIFAR-10, CIFAR-100), we set \(=0.1\)\((0.1,1.0)\)

    &  &  &  &  \\   & \(\)\(\)\(0.1\) & \(\)\(\)\(0.1\) & \(\)\(\)\(0.01\) & \(\)\(\)\(0.1\) & \(\)\(\)\(0.01\) & \(\)\(\)\(0.01\) & \(\)\(\)\(0.01\) & \(\)\(\)\(0.01\) & \(\)\(\)\(0.01\) & \(\)\(\)\(0.01\) \\   & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) & \(10.99\) \\   & \(\)\(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) & \(\)\(0.1\) \\  & \(\

[MISSING_PAGE_FAIL:8]

**Necessity of each component for DFRD.** We report the test performance of DFRD after divesting some modules and losses in Table 5. Here, EMA indicates the exponential moving average copy of the generator on the server. We can evidently observe that removing the EMA generator leads to a significant drop in \(G.acc\), which implies that it can generate effective synthetic data for the global model. The reason why the EMA generator works is that it avoids catastrophic forgetting of the global model and ensures the stability of the global model trained in heterogeneous FL. We display synthetic data in Appendix I that further corroborates the above claims. Meanwhile, we perform the leave-one-out test to explore the contributions of \(_{tran}\) and \(_{div}\) to DFRD separately, and further report the test results of removing them simultaneously. From Table 5, deleting either \(_{tran}\) or \(_{div}\) adversely affects the performance of DFRD. In addition, their joint absence further exacerbates the degradation of \(G.acc\). This suggests that \(_{tran}\) and \(_{div}\) are vital for the training of the generator. Interestingly, \(_{div}\) benefits more to the global model than \(_{tran}\). We speculate that the diversity of synthetic data is more desired by the global model under the premise of ensuring the fidelity of synthetic data by optimizing \(_{fid}\).

**Varying \(_{tran}\) and \(_{div}\).** We explore the impacts of \(_{tran}\) and \(_{div}\) on SVHN and CIFAR-10. We select \(_{tran}\) and \(_{div}\) from \(\{0.25,0.50,0.75,1.00,1.25,1.50\}\). From Fig. 4, we can see that DFRD maintains stable test performance among all selections of \(_{tran}\) and \(_{div}\) over SVHN. At the same time, \(G.acc\) fluctuates slightly with the increases of \(_{tran}\) and \(_{div}\) on CIFAR-10. Besides, we observe that the worst \(G.acc\) in Fig. 4 outperforms the baseline with the best \(G.acc\) in Table 2. The above results indicate that DFRD is not sensitive to choices of \(_{tran}\) and \(_{div}\) over a wide range.

**Varying \(\) and \(\).** In order to delve into the effect of the EMA generator on DFRD in more details, we perform grid testing on the choices of control parameters \(\) and \(\) over SVHN and CIFAR-10. We set \(\{0.25,0.50,0.75,1.00,1.25,1.50\}\) and \(\{0.1,0.3,0.5,0.7,0.9\}\). It can be observed from Fig. 5 that high global test accuracies on SVHN are mainly located in the region of \(<1.25\) and \(>0.5\), while on CIFAR-10 they are mainly located in the region of \(>0.25\) and \(<0.9\). According to the above results, we deem that the appropriate \(\) and \(\) in a specific task is essential for the utility of the EMA generator. Notably, high local test accuracies mainly sit in regions that are complementary to those of high global test accuracies, suggesting that pursuing high \(G.acc\) and \(L.acc\) simultaneously seems to be a dilemma. How to ensure high \(G.acc\) and \(L.acc\) simultaneously in the field of FL is an attractive topic that is taken as our future work.

## 5 Conclusion

In this paper, we propose a new FL method called DFRD, which aims to learn a robust global model in the data-heterogeneous and model-heterogeneous scenarios with the aid of DFKD. To ensure the utility, DFRD considers a conditional generator and thoroughly studies its training in terms of _fidelity_,

Figure 4: Test accuracy (%) with varying \(_{tran}\) and \(_{div}\).

Figure 5: Test accuracy (%) with varying (\(\),\(\)).

    & SVHN & CIFAR-10 & CIFAR-100 \\  baseline & **34.78\(\)1.49** & **25.57\(\)37.27** & **28.08\(\)9.58** \\  & **(15.99\(\)1.49)** & **(16.74\(\)4.27)** & **(13.03\(\)3.46)** \\  -EMA & 26.97\(\)1.28 & 19.80\(\)2.25 & 24.57\(\)0.50 \\  & (14.17\(\)3.09) & (16.55\(\)0.95) & (12.23\(\)0.07) \\  -\(_{tran}\) & 29.30\(\)2.55 & 22.97\(\)31.71 & 27.28\(\)0.46 \\  & (14.24\(\)1.40) & (16.33\(\)1.16) & (12.79\(\)0.40) \\ -\(_{div}\) & 27.68\(\)9.85 & 22.12\(\)1.08 & 26.94\(\)1.60 \\  & (14.26\(\)3.09) & (16.64\(\)1.15) & (12.81\(\)0.40) \\ -\(_{tran}\) -\(_{div}\) & 20.32\(\)1.03 & 21.97\(\)2.48 & 25.50\(\)0.51 \\  & (13.65\(\)1.13) & (16.52\(\)1.39) & (12.30\(\)0.10) \\   

Table 5: Impact of each component in DFRD.

transferability_ and _diversity_. Additionally, DFRD maintains an EMA generator to augment the global model. Furthermore, we propose dynamic weighting and label sampling to accurately extract the knowledge of local models. At last, we conduct extensive experiments to verify the superiority of DFRD. Due to space constraints, we discuss in detail the **limitations** and **broader impacts** of our work in Appendixes J and K, respectively.

## 6 Acknowledgments

This work has been supported by the National Natural Science Foundation of China under Grant No.U1911203, and the National Natural Science Foundation of China under Grant No.62377012.