# Low Tensor Rank Learning of Neural Dynamics

Arthur Pellegrino

School of Informatics

University of Edinburgh

pellegrino.arthur@ed.ac.uk

N Alex Cayco-Gajic

Departement d'Etudes Cognitives

Ecole Normale Superieure

natasha.cayco.gajic@ens.fr

&Angus Chadwick

School of Informatics

University of Edinburgh

angus.chadwick@ed.ac.uk

These last authors contributed equally.

###### Abstract

Learning relies on coordinated synaptic changes in recurrently connected populations of neurons. Therefore, understanding the collective evolution of synaptic connectivity over learning is a key challenge in neuroscience and machine learning. In particular, recent work has shown that the weight matrices of task-trained RNNs are typically low rank, but how this low rank structure unfolds over learning is unknown. To address this, we investigate the rank of the 3-tensor formed by the weight matrices throughout learning. By fitting RNNs of varying rank to large-scale neural recordings during a motor learning task, we find that the inferred weights are low-tensor-rank and therefore evolve over a fixed low-dimensional subspace throughout the entire course of learning. We next validate the observation of low-tensor-rank learning on an RNN trained to solve the same task. Finally, we present a set of mathematical results bounding the matrix and tensor ranks of gradient descent learning dynamics which show that low-tensor-rank weights emerge naturally in RNNs trained to solve low-dimensional tasks. Taken together, our findings provide insight on the evolution of population connectivity over learning in both biological and artificial neural networks, and enable reverse engineering of learning-induced changes in recurrent dynamics from large-scale neural recordings.

## 1 Introduction

Populations of neurons perform tasks through their dynamics, and these computations can be understood through the lens of recurrent neural networks (RNNs) [1; 2]. Recent work has shown that RNNs trained on idealized versions of behavioural tasks from neuroscience experiments can be reverse-engineered to better understand the dynamical principles by which they perform tasks [3; 4; 5; 6; 7]. RNNs can also be fitted to neural data to infer the latent dynamics that drive neural activity in specific tasks [8; 9; 10; 11]. However, an understanding of task learning in the brain requires methods to understand how these latent dynamics evolve over trials, and to map these computational changes to learning-induced changes in neural connectivity [12; 13]. For example, it has been observed that gradient descent in task-trained RNNs tends to drive low-rank weight updates . Yet the structure of learning dynamics itself remains largely unknown, both in the context of gradient-based optimization of neural networks and biological learning in neural systems.

To address this question, we consider how RNN dynamics evolve as a result of structured changes in connectivity over learning. Specifically, we consider changes in RNN connectivity over multipletrials by assuming that the weight tensor, i.e. the 3-tensor formed by stacking the weight matrix over all trials, has low tensor rank. This allows us to identify how distinct components of the weight matrix vary over trials while simultaneously restricting the parameter complexity and benefiting from the interpretable framework of low (matrix) rank RNNs at each trial . Furthermore, by imposing a constraint on the covariance of the trial factors we are also able to separate smooth changes over learning from condition-specific variability on individual trials. In contrast to classic tensor decomposition methods (such as PARAFAC), which instead constrain the neural activity itself to be low rank, _low-tensor-rank RNNs_ (ltrRNNs) capture high-dimensional neural activity resulting from nonlinear neural dynamics, while preserving the interpretability of these linear methods through having interpretable low-dimensional factors.

**Main contributions.** We first apply this method to neural data during a motor learning task  to show that the resulting neural activity can be captured with surprisingly low-tensor-rank weight updates. Next, we aim to find intuition for the observation that learning can be low tensor rank by turning to gradient-based optimization, which has recently been shown to be able to explain changes in neural activity patterns over motor learning [17; 18]. Towards this end, we show numerically that an RNN that is trained to perform the same task also results in low-tensor-rank learning dynamics. Finally, we provide analytical intuition in the form of upper bounds on both the matrix rank and the tensor rank of gradient-based optimization in RNNs. Ultimately these results provide evidence for low tensor rank learning structure of neural dynamics both in the brain and in RNNs.

## 2 Low tensor rank learning

**The weight tensor.** Learning in recurrent neural networks, both biological and artificial, involves the continual update of a weight matrix \(W^{N N}\), where each element \(W_{ij}\) represents the connectivity from neuron \(j\) to \(i\). Here, we consider a set of \(K\) discrete samples of the weight matrix over learning: \(W^{(k+1)}=W^{(k)}+ W^{(k)}\) for \(k\{0,...,K-1\}\). In neuroscience, \( W^{(k)}\) could represent plasticity-induced changes in connectivity strength following each trial in the experiment (e.g., a perceptual decision or motor action), whereas in machine learning they could represent weight updates arising from the application of a given learning rule to a set of training data. Learning can then be summarised by the _weight tensor_\(^{N N K}\) formed by stacking together the weight matrices \(W^{(k)}\) on all trials1, i.e., \(_{ijk}=W^{(k)}_{ij}\).

Here, we investigate the multilinear structure of the weight tensor \(\) in order to gain insight into the relationship between learning, recurrent weights, and network dynamics (Fig. 1a). In particular, given recent studies suggesting that trained RNNs are typically low (matrix) rank , we ask whether the weight tensor is _low tensor rank_, i.e., if the weight tensor can be written as a sum of \(R\) rank-1 components:

\[ =_{r=1}^{R}_{r}_{r} _{r}\] \[W^{(k)}_{ij} =_{r=1}^{R}_{r}(_{r} _{r})_{ij}}_{=a_{r,i}b_{r,j}c^{(k)}_{r}}\]

where \(_{r},_{r}^{N}\) and \(_{r}^{K}\) for \(r\{1,,R\}\) (Fig. 1b). A consequence of the low tensor rank assumption is that the weights \((W^{(k)})\) must evolve within an \(R\)-dimensional subspace of \(^{N^{2}}\) spanned by the set of rank-1 matrices \(\{(_{r}_{r})\}_{r=1}^{R}\).

Figure 1: **Low tensor rank recurrent neural networks.**

**a.** We consider the 3-tensor formed by stacking the weights over learning. **b.** Constraining the weight tensor to be low rank allows for an interpretable analysis of the evolution of the weights over learning. **c.** LtrRNNs partition neural variability into task condition-specific inputs and learning-related weight changes over trials. **d.** LtrRNNs capture changes in dynamics constrained to a low-dimensional subspace, which reshape neural representations over learning.

**Low tensor rank RNNs.** To investigate the structure of weight tensors formed over learning in recurrent networks, we consider a continuous-time RNN (Fig. 1c). The RNN dynamics on trial \(k\) are given by:

\[}^{(k)}=W^{(k)}(^{(k)})-^{(k)}+B ^{(k)}(t)\]

for \(B^{N N_{}},^{(k)}(t)^{N_ {}}\). If the low tensor rank hypothesis is satisfied, the system can be written as:

\[}^{(k)}=_{r=1}^{R}c_{r}^{(k)}(_{r} _{r})(^{(k)})-^{(k)}+B^{(k)}(t),\]

which reduces to a low-rank RNN on every trial . As a result, \(^{(k)}(t)\) is constrained to an \((R+N_{})\)-dimensional subspace of \(^{N}\) spanned by \(\{_{r}\}_{r=1}^{R}\{B_{i}\}_{i=1}^{N_{}}\), and this subspace is fixed across trials (Fig. 1d).

The weight matrix evolves across trials via a simple rescaling of the rank-1 components by the trial factors \(c_{r}^{(k)}\). This may at first appear to restrict the possible changes in dynamics over trials to simple scalings of the flow field along the directions determined by the corresponding \(_{r}_{r}\) components of the weights. In fact, non-trivial changes in the flow field (e.g., bifurcations) can occur due to the nonlinear activation \(()\) (Fig. 2; Supplementary Material A). Moreover, even in the case of a linear ltrRNN (\(=\)id), a rich repertoire of dynamics is possible. First, the system can switch between different vector fields by allowing the corresponding trial factors to transition to zero (or nonzero) values. More generally, the eigenvalues are non-trivially related to the \(_{r}\)'s. The real eigenvalues can be shown to satisfy the following equality (Supplementary Material A):

\(_{r}=(_{rr}^{}})^{-1} _{r^{}}c_{r^{}}[(_{rr^{}}^{}}+ _{rr^{}}^{}})+(_{rr^{}}^{},}-_{rr^{}}^{,})]\), where \(}_{r}\) and \(_{r}\) are the \(r\)th left and right eigenvectors and \(_{rr^{}}^{},}}\) is the angle between the \(r\)th \(\) and \(r^{}\)th \(\). This non-trivial relationship between the eigendecomposition and tensor rank decomposition endows considerable flexibility in terms of the possible changes in dynamics over trials, depending on the relative orientations of \(\{_{r^{}}\}_{r^{}=1}^{R}\) and \(\{_{r^{}}\}_{r^{}=1}^{R}\) as well as the angle \(_{rr}^{},}\) which quantifies the non-normality of the resulting weight matrix.

**Fitting ltrRNNs to data.** These results suggest that ltrRNNs comprise a highly flexible and expressive class of neural networks for relating the changes in recurrent dynamics to low-dimensional structure of the weight updates. We next considered how ltrRNNs could be fit to a dataset (for example, the activations of an RNN over the course of training, or recordings from a population of neurons as an animal learns to perform a task) in order to elicit a low tensor rank description of the weight updates governing the evolution of the dynamics over trials.

We consider a dataset in the form of a tensor \(^{N_{} T K}\), comprising the activity of \(N_{}\) neurons measured on \(K\) trials, each of duration \(T\) time points, with single trial activations \(^{(k)}(t)\). To fit the ltrRNN to such a tensor, we minimise the loss function \(L(,,,B,M)=_{t,k}^{T,K}\|M(^{(k )}(t))-^{(k)}(t)\|^{2}\), where \(M^{N_{} N}\) is a readout matrix mapping the activation of the ltrRNN units onto the neural data. The loss function is minimised directly via gradient descent with respect to the parameters of a rank \(R\) tensor decomposition of \(\).

Above we considered how the low tensor rank assumption constrains the possible changes in RNN dynamics for the case in which the \(_{r}\) can change arbitrarily across trials. However, here we are interested specifically in understanding how these dynamics change over the course of _learning_ which

Figure 3: **LtrRNN fit to neural data.**

LtrRNNs can be fitted to neural population data (here shown for a single neuron and for three trials), thus capturing smooth changes in activity over learning.

Figure 2: **Bifurcation in the flow field of an ltrRNN.** Here \(==[-1/,1/]^{T}\), so that the weights at any given trial \(k\) are, \(W^{(k)}=}{2}[1&-1\\ -1&1]\). A supercritical pitchfork bifurcation occurs at \(c^{(k)}=1\) when \(=\); for \(=\)id (Sup. Fig. 1) a line attractor emerges at \(c^{(k)}=1\).

typically imposes additional structure on the \(_{r}\)'s. Here, we add an inductive bias that the components determining the weights change smoothly over trials, which we impose by parameterizing the trial factors as \(_{r}=(L+ I)}_{r}\) where \(LL^{T}=A\) is the Cholesky decomposition of the smooth covariance matrix \(A\) (assuming \(}_{r}(0,I)\), see Supplementary Material A). In contrast, we constrain the inputs to the RNN \(^{(k)}(t)\) to depend only on _task condition_ (i.e., the type of trial, such as the stimulus presented or set of instructions given), thus assuming that most of the condition-independent inter-trial variability in the data comes from learning-induced changes in the dynamics of the system rather than changes in its inputs. By partitioning the variability in this way, we ensure that the activations \(^{(k)}(t)\), as well as the weights \((W^{(k)})\), evolve in low-dimensional subspaces of \(^{N}\) and \(^{N^{2}}\), respectively, throughout the course of learning. In the following sections we ask how accurate this low-dimensional view of learning is in the context of both biological and gradient-based learning.

## 3 Related work

LtrRNNs integrate a broad range of concepts in neuroscience and machine learning, including low (matrix) rank RNNs, tensor decompositions, fitting RNNs to neural data, and analytical studies of gradient descent dynamics. Here we review the relationship between ltrRNNs and previous results across these domains.

**Inferring weights from neural activity.** A diverse range of methods have historically been used to infer synaptic connectivity from neural recordings . Our work specifically builds upon a recent line of investigation attempting to infer the recurrently generated dynamics \(}=f(,W)\) of the network from samples of its trajectories .  and  inferred learning-induced changes in population dynamics from neural data, but this approach was limited to pre-post comparisons at two timepoints in learning. Others have developed methods to infer the learning rules governing weight updates from post-learning neural activity , or spike train recordings [24; 25]. However, no previous study has directly inferred the evolution of weights over the course of learning in neural data. Our low-tensor-rank approach enables this inference by constraining the parameter complexity, which allows more efficient application to neural data. Moreover, in contrast to previous approaches [21; 22] our method ensures that the dynamics at different phases of learning remain jointly interpretable due to the existence of a stable latent space in which the network activity unfolds.

**Low rank RNNs.** Previous work has introduced low rank RNNs as a powerful framework to uncover the low-dimensional dynamics underlying task performance [15; 7], and which can be inferred from neural population data . In the context of learning, one could naively fit a separate low rank RNN to data recorded on each trial, but there is no guarantee that the resulting \((NK)\) parameters could be related to each other. By instead assuming the weights have low tensor rank structure, we ensure that smooth changes in the dynamics can be mapped over trials with \((N+K)\) parameters, while benefiting from the low rank RNN framework on each trial.

**The dynamics of learning.** Recent work has investigated the dynamics of learning via gradient descent in artificial neural networks [26; 14].  showed that deep linear networks progressively learn the leading singular values of the input-output covariance matrix, which naturally leads to low rank weight matrices when the input-output mapping is itself low rank.  extended these findings to show that the weight updates of an RNN are low rank. However, the proof assumed an infinite-dimensional linear dynamical system at steady-state and with Gaussian-distributed weights. Using adjoint sensitivity analysis, our work extends this result by deriving bounds on the matrix rank on the weight updates of finite-dimensional nonlinear networks away from steady-state. Furthermore, to investigate the evolution of weights over learning, we provide bounds on the tensor rank of learning.

**Tensor decomposition methods.** Our framework can be used to infer low dimensional latent structure in neural data. An alternative approach is to directly fit a low rank approximation of the _neuron \(\) time \(\) trial_ data tensor [27; 28; 29; 30]. Such linear methods have become increasingly popular because of their interpretability but have two key shortcomings: first, neural representations are generally nonlinearly embedded due to their dynamics and task structure [31; 32; 33]. Second, these methods do not provide insight into the dynamics underlying neural computations. Here, we address both issues by parameterizing the dynamics themselves as being low tensor rank, which allows changes in the dynamics to be mapped directly while also enabling RNN activity over trials to be visualized in a fixed subspace spanned by the weight tensor column factors.

LtrRNN dynamics capture neural activity during motor learning

To test whether neural population dynamics during learning are consistent with a low tensor rank framework, we fit ltrRNNs of varying rank to recordings from the motor and premotor cortex of the macaque during a motor learning task in which the subject must adapt to a force field perturbation in order to reach the target endpoint  (Fig. 4a). Following evidence that motor cortical initial states are set by upstream regions during the preparatory period [16; 34], we parameterize \(u^{(k)}(t)\) with a neural ODE (see Supplementary Material B) with solution \(^{(i)}\) on a trial of condition \(i\) during motor preparation, after which the dynamics evolved autonomously. As preprocessing, we first Gaussian filtered the spiking activity of each neuron (\(=40\) ms) to obtain smooth estimates of the instantaneous firing rates. To compare across models, blocks of consecutive entries in time and trials were held-out for cross validation, and the remaining entries of the data tensor were used to fit the parameters of each ltrRNN model. For comparison we also fit a full tensor RNN (i.e. all \(N^{2}K\) entries of \(\) were fitted), as well as full and low matrix rank RNNs whose weights stayed constant over all trials. We quantified model performance as the unexplained variance on the interiors of the held out blocks while discarding borders to reduce temporal correlations between the train and test set (Fig. 4b inset, Supplementary Material B).

Interestingly, when we compared the performance of the full tensor RNN to a static RNN, we found only a \( 5\%\) difference in the variance explained, indicating that much of the variability in the data is determined by task condition and dynamics, with the difference in performance attributable to learning-induced changes . However, of this remaining variability, a ltrRNN with only 5 components was able to achieve similar performance to the full tensor RNN (Fig. 4b), supporting the hypothesis that learning dynamics are low rank. Using this cross-validation procedure also allowed us to compare the performance of the ltrRNN model with low-rank matrix and tensor decompositions which do not fit the underlying nonlinear neural dynamics. We found that for low ranks, our method outperformed truncated SVD (applied to the trial-concatenated data) and PARAFAC (Fig. 4b). Interestingly, in the case that \(=\)id, the activity of the ltrRNN is constrained to an \(R\)-dimensional subspace, therefore the MSE (without cross-validation) is lower-bounded by that of the rank \(R\) SVD by the Eckart-Young theorem. This suggests that the the higher performance of ltrRNN compared to PCA is due to the nonlinear mapping from the membrane potential space to the firing rate space.

Since after \(t=0\) the network evolved autonomously, all of the information regarding its trajectory was contained in the the recurrent dynamics and initial state. We find that the initial states inferred by the model reflect the topology of the task variables (Fig. 4c.). In comparison, in the perturbation block of trials there was only a small change to the initial states, consistent with the finding that the majority of the variability in the data was due to changes in task condition rather than learning (Fig. 3b, Supplementary Material B).

Since ltrRNNs reduce to a low-rank RNN on any given trial, their membrane potential \((t)\) is constrained to lie in the space spanned by the column vectors \(_{r}\). The membrane potential can therefore be visualized via a projection onto each \(_{r}\) to observe the low-dimensional activity of the network . We find that, compared to applying PCA directly on the neural data, ltrRNNs yield more interpretable visualizations of the condition and learning-related variability in the neural (Fig. 3d,e). Additionally, since ltrRNNs parameterize changes in dynamics, we can visualize the vector field in the subspace spanned by the column vectors. Consistent with our task-trained RNN results, and those of the literature , small changes in the vector field are sufficient to account for learning the perturbation (Fig. 4f). These changes in the dynamics of the network can be easily interpreted through the trial factors. We find that the dynamics along certain directions in the membrane potential space change during learning (Fig. 4g). Furthermore, consistent with the hand kinematics, and recent experimental evidence , some of these changes in the trial factors do not simply revert back to baseline during the washout period (in which the force field perturbation is removed; Fig. 4h,i). Dynamics along some columns capture target variability (Fig. 4j, top 2 components), whereas others capture mainly temporal variability (Fig. 4j, bottom 3 components). Interestingly, the trial factors which revert to baseline during the washout period are those corresponding to target-related dynamics, while those which are persistently changed are the temporal variability factors (Fig. 4i).

Overall, we find that learning-related variability can be accounted for by low-tensor-rank changes in the recurrent dynamics of neural populations. LtrRNN allows uncovering these changes in large-scale neural data and vizualizing their effect in an interpretable fashion.

## 5 Low tensor rank learning in task-trained RNNs

We next decided to test the low-tensor-rank learning hypothesis in a model in which we had direct access to the ground truth weight tensor. Towards this end, we trained an RNN with unconstrained weight structure to perform the same motor task.

**Task-trained RNN model**. At any given trial \(k\), the RNN linearly controls the force applied to the hand:

\[}^{(k)}=D(^{(k)}(t))+^{(k)}(t)\]

where \(^{(k)}(t)^{2}\) is an Ornstein-Uhlenbeck process representing noise in the execution of movement . To create a purely ballistic model, we provide the RNN the target position and a hold cue. For the objective we use the integrated hand to target position so that the RNN simply has to push the hand as fast as possible towards the target (Fig. 5a).

Figure 4: **LtrRNN separates learning- from condition-related variability in motor neural data**. **a.** We apply ltrRNN to recordings of the motor and premotor cortex during learning of a perturbed reach task. (Schematic adapted from ). **b.** We hold out for testing blocks of trials and time points (\(100\) ms by \(50\) trials). This reduces temporal correlations between the train and test sets as compared to holding out individual tensor entries. **c.** State of the ltrRNN (\(R=5\)) \(100\) ms after the go cue. LtrRNN captures the topology of the task. Furthermore, different initial states seem to emerge during the perturbation period. **d.** PCA directly applied to the neural data. **e.** Activity of the ltrRNN projected on the column vectors of the first three components. **f.** Vector field along pairs of column vectors. We constrain the activity to the columns of the tensor such that \(=q_{r}_{r}+q_{r^{}}_{r^{}}\) for \(q_{r},q_{r^{}}[-2,2]\) and we compute the vector field \(_{r}(()_{r})+_{r^{}}( ()_{r^{}})\). **g.** Eigenspectrum of \(W^{(k)}\). Saturation gradient indicates trial. **h**. The trial factors \(_{r}\) can be seen as a latent variable of learning, such that they describe the evolution of the weights in a low-dimensional subspace of the weight space spanned by \(_{r}_{r}\). **i.** Trial factors. The black line is computed using \(=0\). **j.** LtrRNN activity projected onto each column factor (ordered as in **i**). In particular the activity along the top two components seem to be more specific to reach angle.

After first pre-training the RNN to move the hand to the goal position at the go onset, we then probe motor learning following the same protocol as the neural data. Specifically, the RNN first performs 50 trials in the baseline condition, after which we introduce a force perturbation orthogonal and proportional to the velocity of the hand for 100 trials (Fig. 5b):

\[}^{(k)}=D(^{(k)})(t)+cR}^{(k)}(t)+ ^{(k)}(t)\]

where \(R^{2 2}\) is a \(90^{}\) clockwise rotation matrix, and \(c\) is the coefficient of perturbation. Finally, the RNN performs the original unperturbed task for another 100 trials (washout). Throughout the perturbation and washout periods, the weights are updated following SGD.

We next analyzed how the structure of the weight matrix changed over the baseline, perturbation, and washout blocks. The change in weights as a result of the pre-training \(W^{*}-W_{0}\), where \(W_{0}\) is the random initialization, and \(W^{*}\) the weights after pre-training, is of matrix rank \(3\) (Fig. 5c, left). Since the weight updates resulting from learning the perturbation are small (consistent with the literature ), we cannot simply apply PARAFAC on the weights recorded during perturbation learning, as only the \(3\) rank-\(1\) terms from pre-training will be visible. However, running PARAFAC on the updates \(-W^{*}\) (where \(\) is the vector of ones), reveals tensor rank \(2\) updates (Fig. 5c, right). Furthermore, the subspace spanned by the columns (or rows) resulting from pretraining is different than those resulting from perturbation learning (Supplementary Material C).

Figure 5: **Learning-induced weight changes in task-trained RNNs are low tensor rank.****a**. RNN model. **b**. Average MSE between hand and target positions integrated throughout the trial. **c**. Left: Variance explained of the weights resulting from pre-training \(W^{*}\). The original task training results in a rank-3 RNN. Right: Variance explained of the tensor of updates \(-W^{*}\) due to retraining. The retraining procedure results in a rank-2 tensor. We further found that the subspaces spanned by the pre-training columns (resp. rows) and retraining columns (resp. rows) were different, suggesting a tensor of rank at most \(5\). **d**. Hand movements during various periods of learning, where “early” and “late” describe respectively the first and last trial during which the perturbation is introduced or removed. **e**. Using the same cross-validation as in Fig. 4 uncovers the low tensor rank structure. **f**. Eigenspectrum of the weights \(W^{(k)}\) over learning. Top: Ground truth weights of the task-trained RNN. Bottom: Weights of the ltrRNN fit to the task-trained RNN activity. Imaginary eigenvalues emerge to counter the rotational effect of the perturbation, and are uncovered by ltrRNN. **g**. Activity projected on PCs. The rotational activity during perturbed trials is uncovered by ltrRNN. **h**. Example of trial factor uncovered by ltrRNN which correlates with learning at the level of the behaviour.

**LtrRNN application**. We next ask whether ltrRNN can uncover this low-tensor-rank structure in the weights, especially the small changes due to perturbation learning. Using our cross-validation procedure, we find that the variance of the activity of the task-trained RNN that is unexplained by the fitted ltrRNN plateaus at tensor rank \(5\) (Fig. 4(e)), consistent with our analysis of the ground truth weights. Furthermore, the weights of the ltrRNN share similar spectral properties, and a similar evolution over learning, compared to ground truth (Fig. 4(f)). In particular, in both cases, imaginary eigenvalues, corresponding to rotational activity, emerge over learning, consistent with the behaviour being rotational post-learning to counter the force field (5d). The emergence of rotational activity is also visible at the level of the neural activity (Fig. 4(g)).

Therefore, consistent with the results found through ltrRNN fit to neural data, we found that the weight updates in an RNN trained on a perturbed ballistic reach task had low-tensor-rank structure. Furthermore, ltrRNN was able to uncover this structure in the weights of the task-trained RNN, and its evolution over learning.

## 6 Gradient-based learning constrains the tensor rank of weight updates

We have so far observed that learning leads to low-tensor-rank weight changes in both biological data and task-trained RNNs. To gain deeper insight into why this is the case, we next present a set of mathematical results regarding the tensor rank of gradient-based learning in RNNs. Towards this end, we use the method of the adjoint  to derive a dynamical system whose solution is the gradient of a loss functional with respect to the RNN weights .

**The adjoint.** For a dynamical system \(}=f(,)\), the state adjoint of the loss functional \(L:^{n}\) at a particular time point \(t\) is defined as \(_{}(t)=(T))}{d(t)}\) where \(T\) is the time of loss evaluation (but see Supplementary Material E for the case of a loss functional that is integrated over time). From the dynamics of \(\), the state adjoint dynamics can be derived:

\[_{}}(t)=((t))}{d(t )})^{T}_{}(t)\]

However, to understand gradient-based learning, we require the parameter adjoint: \(_{}(t)=(T))}{d(t)}\). This can be accomplished by concatenating the original dynamical system by its parameters \((t)=[(t),(t)]\) (noting that \(}(t)=0\)) to define the the augmented adjoint \(_{}(t)=[_{}(t),_{ {}}(t)]\), whose dynamics can be shown to follow

\[_{}}(t)=[((t))}{(t)})^{T}_{}(t),((t))}{d })^{T}_{}(t)]\]

with terminal condition \(_{}(T)=[(T))}{d(T)},0]\). The gradient of the loss with respect to the parameters can then be found by integrating the parameter adjoint dynamics backwards through time to get \(_{}(0)\). In Supplementary Material E we provide a short derivation of the adjoint adapted from .

**Main results**. While the adjoint method is extensively used as a numerical tool in autodifferentiation packages , it can also provide analytical insight into the gradient dynamics of dynamical systems. Towards this end, we now return to the case of an RNN, with the parameter of interest being the weight matrix. We demonstrate several mathematical results with the aid of the adjoint.

**Lemma 1**.: _Consider the RNN \(}=W()-+B(t),\) where \((t)^{n}\), \((t)^{m}\), \(W^{n n}\), \(B^{n m}\), and \(:^{n}^{n}\) an element-wise nonlinearity, and define a loss functional of the linearly decoded RNN state, \(L(D((T));(T))\) for \(^{d}\). Furthermore, let \(W=_{r}^{R}_{r}_{r}\). The adjoint dynamics are then given by,_

\[_{}}=(_{r}^{R}_{r} (_{r}^{}((t))))^{ T}_{}-_{}, 28.452756pt_{W}}= _{}((t))\]

_with terminal conditions \(_{}(T)=^{}((T))_{r^{}} ^{d}L^{}(D_{r^{}}((T));_{r^{}})D _{r^{}}\) and \(_{W}(T)=0\). 2_

**Theorem 1**.: _Consider an RNN be defined as in Lemma 1. Then the singular values of its gradient can be bounded as:_

\[\{_{n}^{()}_{r}^{_{ }},_{n}^{_{}}_{r}^{()} \}_{r}^{_{W}L}\{_{1}^{()}_{r}^{_{}},_{1}^{_{}} _{r}^{()}\},\]

_where \(_{r}^{}\) denotes the \(r\)th singular value of \(\)._

This theorem demonstrates that there is a natural bound to the numerical rank  of gradient-based learning in RNNs. Numerically, we find that the singular value spectrum of both \(()\) and \(_{}\) tend to decay exponentially, even in the case of a chaotic RNN (Fig. 6). In Supplementary Material E we repeat the same analysis with various activation functions, initial weight variances and ranks: overall, we find that smooth activation functions (such as the most commonly used tanh) tend to lead to the fastest decaying singular value spectrum of the adjoint.

So far, we haven't made any assumption on the architecture of the RNN such as constraints on \(W\) or \(\). Under such constraints, stronger and more explicit bounds on both the matrix and tensor ranks can be obtained.

**Theorem 2**.: _Consider an RNN defined as in Lemma 1 with \(=\)id and \(W^{(0)}\) of rank \(R\). Furthermore suppose \(x^{(k)}(0)\) is constrained to the subspace spanned by the columns of \(W^{(k)}\) and \(B\). Consider the weight tensor \(=[W^{(0)},W^{(1)},...]\) where \(W^{(k+1)}=W^{(0)}+_{j=1}^{k}_{W}L(D^{(j)}(T);^{(j)})\), with \(^{(j)}^{d}\) where \(^{(j)}\) denotes the activity of the RNN after the \(j\)th weight update. Then,_

1. _The rank of the gradient at the first step is at most_ \((_{W}L^{(0)}) R+1\)_._
2. _The rank of the trial slices of the weight tensor is at most_ \((W^{(k)}) 2R+m+d\)_._
3. _The tensor rank of the weight tensor is at most_ \(()(2R+m+d)^{2}\)_._

We note that these bounds are tight, in the sense that there exists networks for which they are equalities; therefore, they cannot be improved upon without restricting the set of architectures considered (e.g. to normal weight matrices). We also point out that they are non-trivial as the current best upper bound on the max rank of a \((^{n})^{ 3}\) tensor is \(n^{2}-n-1\). In particular, in the case of \(W^{(0)}=0\) and \(m=d=1\) considered by , the tensor rank is at most \(4\). For arbitrary weight initializations, the matrix and tensor mathematical ranks can be high. Nevertheless, in most cases the matrix and tensor numerical ranks will fall vastly below these bounds due to Theorem 1.

We illustrate this result with \(R=3,d=2,m=2\) in Fig. 6. We find that the true ranks fall within these bounds - strictly below due to limited machine precision - and that the numerical ranks are extremely low. Intuitively, decoding the firing rate of the RNN into a low-dimensional space produces weight updates that push the RNN and adjoint activity to lie in a low-dimensional subspace of the state space. This, in turn, further pushes weight updates to lie in a low-dimensional subspace of the weight space.

The proofs of Lemma 1 and Theorems 1 and 2 are provided in Supplementary Material E. We also discuss two additional cases, namely that of a loss integrated over some period of time, and the gradient of the loss w.r.t. to other parameters of the RNN. Finally, we show that momentum-based optimization methods such as ADAM have the same property. Together, these analytical results provide insight as to why gradient dynamics bound the matrix rank of the weight updates in generic RNNs, as well as the tensor rank of learning dynamics in the linear case.

## 7 Discussion

**Summary**. In the present work, we explored the tensor rank of learning in artificial and biological neural networks. We showed that learning leads to low-tensor-rank weight updates, which can be exploited to uncover smooth changes in dynamics along with a principled choice of low-dimensional

**Modelling limitations and future work**. Inferring connectivity from neural recordings is in general an ill-posed problem : given any observed pattern of activity, it is always possible that the data could be explained entirely in terms of a external input to a set of unconnected neurons. In our application to neural data, we resolved such ambiguities by assuming that inputs were fixed on each trial of a given condition, forcing the changes in neural activity across trials of the same condition to be captured by (smoothly varying) changes in weights. We note that, in principle, our framework and code could also implement residual trial-to-trial variability in the inputs.

In addition to learning- and condition-specific changes, neural recordings show substantial variability across consecutive trials, which are thought to reflect a combination of i) unmeasured covariates such as behavioural or intrinsic state, ii) stochasticity in the neural system itself, and iii) changes in the initial state at trial onset. Future work could incorporate behavioural covariates, allow for trial-specific initial states, and model the data using a stochastic dynamical system within each trial.

Here, we focused on gradient-based learning, motivated by recent evidence that it is able to explain many features of motor learning in neural data , as well as by more general support for an optimization-based framework to understand neural learning . The tensor rank of learning in RNNs with local synaptic rules (e.g., Hebbian) remains an open question. Towards this end, theoretical work has established links between Hebbian and gradient-based learning , opening the possibility of an extension of our mathematical results to biologically plausible learning rules.

Our analytical results provide intuition for our observation that the rank of learning dynamics is limited by task complexity. This supports previous findings of low (matrix) rank weight changes in RNNs  and in deep networks . Our results on the numerical matrix rank also has interesting ties to work that uses rank compression for more efficient training in deep networks , and for numerical solutions to systems with time-varying dynamics .

**Broader impact**. We introduce a novel framework for understanding learning in the brain and artificial neural networks. Our mathematical results on the rank of RNN gradients have broad relevance to the machine learning community, while our results on motor neural data could drive future applications to brain computer interfaces. Overall, our work makes novel contributions towards understanding the emergence of computations through learning in neural systems.

Figure 6: **The singular value spectrum of the gradient of random RNNs with random objective**. Top: Full rank RNN with tanh activation function in a chaotic regime. Bottom: Low-rank (\(R=3\)) linear RNN. In both cases \(m=d=2\). The networks are trained to map a time-varying input (parameterized as an LDS) to a given target output. Error shade represents the standard deviation over 5 random initialization. **a**. Loss over training. **b**. Example of network activity at one iteration. Inset: activity of two neurons over learning, red is post-learning. **c**. Singular value spectrum of the activity and of the adjoint. **d**. Singular value spectrum of the weights, gradient, and bound we derive. **d**. Tensor rank of the weight tensor minus initial weights. Variance is computed per trial slice.