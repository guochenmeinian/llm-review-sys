# Achievable distributional robustness when the robust risk is only partially identified

Julia Kostin

Department of Computer Science

ETH Zurich

jkostin@ethz.ch

Nicola Gnecco

Gatsby Computational Neuroscience Unit

University College London

nicola.gnecco@gmail.com

Fanny Yang

Department of Computer Science

ETH Zurich

fan.yang@inf.ethz.ch

###### Abstract

In safety-critical applications, machine learning models should generalize well under worst-case distribution shifts, that is, have a small robust risk. Invariance-based algorithms can provably take advantage of structural assumptions on the shifts when the training distributions are heterogeneous enough to identify the robust risk. However, in practice, such identifiability conditions are rarely satisfied - a scenario so far underexplored in the theoretical literature. In this paper, we aim to fill the gap and propose to study the more general setting of _partially identifiable robustness_. In particular, we define a new risk measure, the worst-case robust risk, and its corresponding (population) minimax quantity that is an algorithm-independent measure for the best achievable robustness under partial identifiability. We introduce these concepts broadly, and then study them within the framework of linear structural causal models for concreteness of the presentation. We use the introduced minimax quantity to show how previous approaches provably achieve suboptimal robustness in the partially identifiable case. We confirm our findings through empirical simulations and real-world experiments and demonstrate how the test error of existing robustness methods grows increasingly suboptimal as the proportion of previously unseen test directions increases.

## 1 Introduction

The success of machine learning methods typically relies on the assumption that the training and test data follow the same distribution. However, this assumption is often violated in practice. For instance, this can happen if the test data are collected at a later time or using a different measuring device. Without further assumptions on the test distribution, generalization under distribution shift is impossible. However, practitioners often have partial information about the set of possible "shifts" that may occur during test time, inducing a set of _feasible test distributions_ that the model should generalize to. We refer to the resulting set as the _robustness set_. When a probabilistic model for these possible test distributions is available or estimable, one may aim for good performance on a "typical" held-out distribution using a probabilistic framework. When no extra information is available or estimable, one possibility is to find a model \(\) that has a small risk \((;)\) on the hardest feasible test distribution. More formally, we aim to achieve a small robust risk defined by

\[_{}()_{_{ }(^{*})}(;),\] (1)where \(_{}(^{})\) corresponds to the robustness set which depends on some true parameter \(^{}\). In fact, this worst-case robustness aligns with security and safety-critical applications, where a small robust risk is necessary to confidently guarding against possible malicious attacks.

Causality-oriented robustness  on the other hand is based on the idea that some structural parameters (like a graphical structure of the model) remain invariant across distributions, while others may vary. For a given set of training distributions, certain sets of varying parameters induce robust risks that are identifiable. Similarly, for a given set of varying parameters, heterogeneous enough training distributions may identify the robust risk.

In practice, robustness methods aiming at minimizing a pre-defined robust risk often suffer from ineffectiveness. For adversarial robustness for example, it is known that when the perturbations during training and test time differ, the robust risks resulting from adversarial training and standard training may be comparable (see, e.g. ). Similarly, invariance-based methods are often shown to be less robust than vanilla empirical risk minimization that ignores multi-environment information. Theoretically, besides being effective only for very specific data-generating models , invariance-based methods generally are bound to fail when the heterogeneity of the training data is not enough for a given set of possible test shifts. Even though this issue of non-identifiability has been pointed out previously , prior work so far was primarily satisfied with such a binary statement - whether identifiability is given or not. We believe that the non-identifiable scenario warrants a more detailed discussion. In particular, we aim to formalize how to quantify the best possible robustness for this partially identifiable setting. In particular, we extend the discussion of invariance-based methods to include the partially identifiable setting, where not only the causal parameter, but the robust risk (1) is not determinable using training data either1. Specifically, we aim to discuss the following question:

_What is the optimal worst-case performance any model can have for given structural relationships between test and training data and how do existing methods comparatively perform in such settings?_

When the robust risk is not identifiable from training data, we obtain a whole _set_ of possible objectives that includes the true robust risk. In this case, we are interested in the best achievable robustness for _any algorithm_ that we capture in a quantity called the _worst-case robust risk_:

\[_{}():=_{\\ ^{}}_{ _{}(^{})}(;).\] (2)

Note that \(_{}()\) is well-defined even when the standard robust risk is not identifiable - it takes the supremum over the robust risks induced by all possible true model parameters \(^{}\) that are consistent with the given set of training data distributions. Furthermore, the minimal value of the identifiable robust risk corresponds to the optimal worst-case performance in the partially identifiable setting. Spiritually, this _minimax population quantity_ is reminiscent of the algorithm-independent limits in classical statistical learning theory .2 Even though our partial identifiability framework can be

   Framework accounts for &  bounded \\ shifts \\  &  partial identifiability of \\ model parameters \\  & 
 partial identifiability of \\ robustness set \\  \\  DRO & ✓ & – & ✗ \\  \([7,\,15,\,49,\,32,\,43]\) & & & \\  Infinite robustness & & & \\ \([35,\,17,\,30,\,39,\,6,\,2,\,46,\,54,\,28,\,1]\) & ✗ & ✗ & ✗ \\  Finite robustness & & & \\ \([41,\,23,\,14,\,27,\,45]\) & ✓ & ✓ & ✗ \\  Partially id. robustness & & ✓ & ✓ \\ (this work) & & & \\   

Table 1: Comparison of various distributional robustness frameworks and what kind of assumptions their analysis can account for (with an incomplete list of examples for each framework).

evaluated for arbitrary modeling assumptions on the distribution shift (such as covariate/label shift, DRO, etc.), we present it in a concrete linear setting for clarity of the exposition. Specifically, the setting is motivated by structural causal models (SCMs) with unobserved confounding (cf. Section2), similar to the setting of IV (instrumental variables) and anchor regression [41; 42]. Concurrently with our work,  proposed a framework for partial transportability which is conceptually related to our notion of worst-case robust risk. However, their approach leverages graphical assumptions, i.e., a priori knowledge about the structure of causal models, whereas our focus is a more agnostic multi-environment setting. Additionally, we do not assume a causal data generation process.

The worst-case robust risk (2) not only represents a notion of algorithm-independent optimality for any combination of training and test shifts. In the linear setting in Section2, we also show theoretically and empirically that the ranking and optimality of different robustness methods change drastically in identifiable vs. partially identifiable settings. The same can be observed in experiments on real-world data. Our experimental results strongly indicate that evaluation and benchmarking on partially identifiable settings are important for determining the effectiveness of robustness methods. Finally, while the worst-case robust predictor derived in the paper is only provably optimal for the linear setting, experiments on real-world data in Section4 suggest that our estimator may significantly improve upon other invariance-based methods in more realistic scenarios.

## 2 Setting

In this section, we state the concrete distributional setting on which we introduce our partial identifiability framework. In particular, we consider a data generating process, motivated by structural causal models (SCMs), that allows for hidden confounding, i.e., spurious correlations between the covariates \(X\) and the target \(Y\). We describe the structure of the distribution shifts occurring in the training and test environments, which is reminiscent of interventions in causal models. Finally, we introduce our framework for distributional robustness that allows for partial identifiability and define the _worst-case robust risk_ - for any given model, it corresponds to the maximum robust risk among all possible robust risks induced by the training distributions.

### Data distribution and a model of additive environmental shifts

**Data generating process (DGP).** We first describe the data-generating mechanism that underlies the distributions of all environments \(e\) that may occur during train or test time. For each environment \(e\), we observe the random vector \((X_{e},Y_{e})_{e}^{X,Y}\) consisting of input covariates \(X_{e}^{d}\) and a target variable \(Y_{e}\) which satisfy the following data generating process:

\[ X_{e}&=A_{e}+;\\ Y_{e}&=^{}X_{e}+,\] (3)

where \(A_{e}^{d}\), \((,)^{d+1}\) are random vectors \(A_{e}_{e}^{A}\), \((,)^{,}\) with finite first and second moments and for which \(A_{e}} 2.0mu }{ -2.0mu }{-2.0mu }{-2.0mu }(,)\) for all \(e\).

**Invariant mechanism.** Note how in this setting, apart from \(^{}\), the distribution \(^{,}\) of the noise vector \((,)\) remains constant across environments. Without loss of generality, we assume that the noise \((,)\) has mean zero. Note how this linear setting is, in general, more challenging than the standard linear regression setting where \(} 2.0mu }{ -2.0mu }{-2.0mu }{-2.0mu }\): due to possible dependencies between \(\) and \(\) (induced by, e.g., _hidden confounding/spurious features_), classical estimators, such as the ordinary least squares, are biased away from the true parameter \(^{}\). Denote by \(^{}((,))\) the joint covariance of the noise vector \((,)\), which can be written in block form as \(^{}=^{}_{}&^{}_{, }\\ ^{}_{,}&(^{}_{})^{2}\) and which we assume to be full-rank. We then denote the concatenation of these two invariant parameters by \(^{}(^{},^{}) ^{d}^{(d+1)(d+1)}\) - the parameter that remains invariant across all environments.

**Structure of the distribution shifts.** Note that in the DGP, the distribution shifts between \(_{e}^{X,Y}\) are induced solely by changes in the distribution of the variable \(A_{e}\), whose mean and covariance matrix we denote by \([A_{e}]=_{e}\) and \([A_{e}]=_{e}\), respectively. In general, we allow for degenerate shifts, i.e. the covariance \(_{e}\) can be singular. We remark that although the additive shift structure in Equation3 allows the joint distribution \(_{e}^{X,Y,A}=_{e}^{A}^{X,Y|A}\) to change solely via \(_{e}^{A}\), our distribution shift setting is more general than covariate shift: due to the noise variables \(\) and \(\) being potentially dependent, both the marginal \(_{e}^{X}\) and the conditional distribution \(_{e}^{Y|X}\) can change across environments.

**Training and test-time environments.** Throughout the paper, we assume that we are given the collection of training distributions \(_{^{*},_{}}=\{_{^{*},e}^{X,Y}\}_{e_{}}\), where \(_{}\) denotes the index set of training environments. We omit \(^{*}\) when it is clear from the context. Further, for ease of exposition, we assume that \(_{}\) contains a reference (unshifted) environment \(e=0\) with \(A_{0}=0\) a.s. In Appendix B, we discuss how our results apply if this condition is not met. During test time, we expect to observe a new, previously unseen distribution \(_{}^{X,Y}\) which is induced by the DGP (3) and a shift random variable \(A_{}_{}^{}\), with corresponding finite mean \(_{}\) and covariance \(_{}\).

Even though we do not have access to \(_{}^{X,Y}\) during training, the practitioner might have some information about the possible shift distributions \(_{}^{A}\) that may occur during test time. As an example, we may only have information about the maximum possible magnitude and direction of the test-time mean shift \([A_{}]\). In this work, we assume that we are given an upper bound on the second moment of the shift variable, represented by a positive semidefinite (PSD) matrix \(M_{} 0\) such that

\[[A_{}A_{}.^{}]= _{}+_{}{_{}}^{} M _{}.\] (4)

In practice, there may be different degrees of knowledge of the feasible set of shifts - when no knowledge is available, one can always choose the most "conservative" bound \(M_{}\) with the range equal to \(^{d d}\) and large eigenvalues. The more information is available, the smaller the feasible set of test distributions would become. On the other hand, when the test distribution \(_{}^{X}\) of \(X\) is available during training (as in the _domain adaptation_ setting ), one can directly compute the optimal shift upper bound via \(M_{}=[X^{}X^{}.^{}\)]. In existing literature, \(M_{}\) is often proportional to the pooled first or second moment of the training shifts, for instance \(M_{}=_{e E_{}}w_{e}_{e}_{e}^{}\) in discrete anchor regression  or \(M_{}=_{e E_{}}w_{e}(_{e}_{e}^{ }+_{e})\) in causality-oriented robustness with invariant gradients . Here, \(w_{e}\) are the weights representing the probability of a datapoint being sampled from the environment \(e\). As will become apparent in the next sections, our population-level results are not impacted by the distribution of the environment variable, which we thus omit in the following.

We now provide an example based on structural causal models (SCM) that falls under the aforementioned distrubtion shift setting.

_Example 1_.: Consider the structural causal model and its induced graph in Figure 1. In this model, the variable \(Z\) is a soft intervention on the covariates \(X\). Additionally, the exogenous noise vector \((_{X},_{Y},_{H})\) and the intervention variable \(Z\) are mutually independent. This model is the basis of multiple causality-oriented robustness works, e.g. . Let \(^{} B_{YX}^{}\) and \( B_{YH}H+_{Y}\). Then, from (5), we obtain \(Y=B_{YX}X+(B_{YH}H+_{Y})=X^{}^{}+\). Suppose that \(-\) is invertible and let \((-)^{-1}\)with entries \(C_{XX},C_{XY}\), etc. Define \(A C_{XX}Z\) and \( C_{XX}_{X}+C_{XY}_{Y}+C_{XH}_{H}\). Then, we can write \(X=A+\). Since shifts in distribution of \(Z\) induce shifts in the distribution of \(A\), a collection of interventions \(\{Z_{e}\}_{e_{}}\) translates into a collection of additive shifts \(\{A_{e}\}_{e_{}}\) and gives rise to training distributions varying with the environment \(e\). In summary, our DGP Equation (3) includes the classical setting of causality-oriented robustness as depicted in Figure 1.

### The robust risk

Our goal is to find an estimator using the training data that has a small risk, in this paper exclusively the expected square loss \((;)_{\,}[(Y-^{ }X)^{2}]\), over the robustness set. In our setting, given

Figure 1: (Left) SCM with hidden confounding and (Right) induced graph. The model allows for an arbitrary causal structure of the observed variables \((X,Y)\), as long as \(-\) is invertible, i.e. the underlying graph is acyclic. The shifts across different distributions are captured via shift interventions on \(X\), however, the model does not allow for interventions on the target variable or hidden confounders.

a test shift upper bound \(M_{}\) defined in Equation (4), the robustness set corresponds to

\[_{^{}}(M_{}):=\{_{^{}, }^{X,Y}:\ [A_{}{A_{}}^{}] M_{ }\},\] (6)

yielding the corresponding robust risk that reads

\[_{}(;^{},M_{}) _{_{^{}}(M_{})}(;).\] (7)

We call the minimizer of the robust risk \(_{^{}}^{rob}_{^{d}} _{}(;^{},M_{})\) the _robust predictor_. For the squared loss and linear model, the robust risk can be computed in closed form and _solely_ depends on \(M_{}\) and the invariant parameters \(^{}=(^{},^{})\), and not on other properties of the distributions:

\[_{}(,^{},M_{})=(^{ }-)^{}(^{}_{}+M_{})(^{}- )+2(^{}-)^{}^{}_{,}+(^{} _{})^{2}.\] (8)

This observation motivates us to define an equivalence relation between two data-generating processes that holds whenever they induce the same robust risk for any model \(\) and shift upper bound \(M_{}\). Specifically, observe that \(_{1}\) and \(_{2}\) induce the same robust risks for all \(M_{}\) and \(\) iff \(^{}_{1}=^{}_{2}\) and \(_{1}^{,}_{2}^{,}\), where \(\) denotes the equivalence of distributions based on equality of their first and second moments. Thus, in the following, we treat our data-generating process as uniquely defined by \(^{}\) up to this equivalence relation.

In practice, the model parameters \(^{}\) typically cannot be identified from the training distributions, and the robust risk \(_{}\) can only be computed for specific combinations of training and test shifts, studied, e.g., in . In the next section, we describe concepts that allow us to reason about robustness in the case when the robust risk is only partially identifiable.

### Partially identifiable robustness framework

We start by formally introducing the general notion of partial identifiability for the robust risk. The following notion of _observational equivalence_ of parameters is reminiscent of the corresponding notion in the econometrics literature :

**Definition 1** (Observational equivalence).: _Two model parameter vectors \(_{1}=(_{1},_{1})\) and \(_{2}=(_{2},_{2})\) are **observationally equivalent** with respect to a set of shift distributions \(\{_{}^{A}:e_{}\}\)3 if they induce the same set \(_{,_{}}\) of training distributions over the observed variables \((X_{e},Y_{e})\) as described in Section 2.1, i.e._

\[_{_{1},e}^{X,Y}_{_{2},e}^{X,Y}e_{}.\]

_By observing \(_{^{}},_{}\), we can identify the model parameters \(^{}\) up to the **observationally equivalent set** defined as_

\[_{}:=\{=(,):_{, _{}}_{^{},_{ }}\}.\]

In general, observationally equivalent set is not a singleton, that is, \(^{}\) is not identifiable from the collection of training environments \(_{^{},_{}}\). However, prior work has exclusively considered test shifts \(M_{}\) that still allow identifiability of the robust risk nonetheless, depicted in Figure 1(a) and discussed again in Section 3.2. In this work we argue for analyzing the more general partially identifiable setting, where set-identifiability of the invariant parameter \(^{}\) only allows us to compute a superset of the robustness set

\[_{_{}}(M_{}):=_{ _{}}_{}(M_{})_{^{}}(M_{})\]

and correspondingly, a set of robust risks \(\{_{}(;,M_{}):\, _{}\}\). In this case, we would still like to achieve the "best-possible" robustness, that is the test shift robustness for the "hardest-possible" parameters that could have induced the observed training distributions.

**Definition 2** (Worst-case robust risk and the minimax quantity).: _For the data model in Equation (3), the worst-case robust risk is defined as_

\[_{}(;_{},M_{}):=_{_{}}_{}(; ,M_{}).\] (9)

_The optimal robustness on test shifts bounded by \(M_{}\) given training data \(_{^{},_{}}\) is described by the minimax quantity_

\[(_{},M_{})=_{ ^{d}}_{}(;_{},M_{}).\] (10)

_When the minimizer of Equation (10) exists, we call it the worst-case robust predictor defined by_

\[^{}_{_{}}=*{arg\,min}_{} _{}(;_{},M_{})\] (11)

In the next sections, we explicitly compute these quantities for the linear setting of Section 2. This will allow us to compare the best achievable robustness in the partially identified case with the guarantees of prior methods in this setting.

## 3 Theoretical results for the linear setting

We now compute the worst-case robust risk (9) and derive a lower bound for the minimax quantity (10) in the linear additive shift setting of Section 2. We then compare the worst-case robust risk of some existing robustness methods and ordinary least squares (OLS) with the minimizer of the worst-case robust risk both theoretically and empirically.

### Minimax robustness results for the linear setting

The degree to which the model parameters \(^{}\) in the linear additive shift setting (3) can be identified depends on the number of environments and the total rank of the moments of the additive shifts. For structural causal models, this is well-studied, for instance, in the instrumental variable (IV) regression literature [4; 9]. As we show in Proposition 1, the true parameter \(^{}\) can _only_ be identified along the directions of the training-time mean and variance shifts \(_{e}\) and \(_{e}\). Therefore, if not enough shift directions are observed, \(^{}\) is merely _set-identifiable_, leading to set-identifiability of the robust prediction model (8). More formally, we denote by \(\) the subspace consisting of all _additive shift directions seen during training:_

\[:=\ [_{e_{}} (_{e}+_{e}_{e}^{})],\] (12)

and by \(^{}\) its orthogonal complement. The definition of the space \(\) induces an orthogonal decomposition of the true parameter \(^{}=^{}+^{^{}}\). The _identifiable part_\(^{}\) then uniquely defines a set of _identified model parameters_ that reads

\[^{}:=(^{},^{}_{}, ^{}_{,},(^{}_{})^{2})=(^{},^{}_{},^{}_{,}+^{}_{}^{ },(^{}_{})^{2}+2^{}_{,}, ^{}+^{},^{}_{} ^{})\]

that can be computed from the training distributions. For the following results, we assume a similar decomposition of the test shift upper bound \(M_{}\) which is essentially a decomposition into "seen" and "unseen" directions.

Figure 2: Relationship between identifiability of the model parameters and identifiability of the robust risk. (a) The classical scenario where the test shift upper bound \(M_{}=M_{}\) is contained in the span of training shifts so that the robust risk is point-identified. (b) The more general scenario of this paper, where \(M_{}=M_{}\) contains new shift directions and where only a set can be identified in which the robust risk lies.

**Assumption 3.1** (Structure of \(M_{ test}\)).: _We assume that \(M_{ test}= M_{ seen}+^{}RR^{}\), where \(,^{} 0\), \(M_{ seen}\) is a PSD matrix satisfying \({ range}\ M_{ seen}\) and \(R\) is a semi-orthogonal matrix satisfying \({ range}\ R^{}\)._

In the next proposition, we show that the model parameters and robust predictor can be identified up to a neighborhood around \(^{}\).

**Proposition 1** (Identifiability of model parameters and robust predictor).: _Suppose that the set of training and test distributions is generated according to Section 2.1 and Assumption 3.1 holds. Then,_

1. _the model parameters generating the training distribution (_3_) can be identified up to the following observationally equivalent set :_ \[_{ eq}=\{^{}+,^{}_{}, ^{}_{,}-^{}_{},(^{}_{})^{2}-2^{}^{}_{,}+^{} _{}^{}\}^{};\] (13)
2. _the robust predictor_ \(^{rob}_{}\) _as defined in Equation (_8_) is identified up to the set_ \[^{rob}_{_{ eq}}\{^{}+(M_{ test}+ ^{}_{})^{-1}^{}_{,}+(M_{ test}+ ^{}_{})^{-1}\,\ R\}^{ rob}_{},\] (14)

_where \(^{rob}_{_{ eq}}=\{^{rob}_{}:_{  eq}\}\)._

The proof of Proposition 1 is provided in Appendix F.1. Proposition 1 implies two well-known settings: If we observe a rich enough set \(_{_{ train}}\) of training environments such that \(=^{d}\), the model parameters are uniquely identified, corresponding to the setting of full-rank instruments . From a dual perspective, for a given set of training environments, _the robust predictor is identifiable whenever the test shifts are in the same direction as the training shifts_, i.e. \({ range}\ M_{ test}\) and \(R=0\) - this holds even when the invariant parameters are not identifiable and \(^{d}\). This is the setting considered e.g. in anchor regression  and discussed again in Section 3.2 and Appendix C.

So far, we have described how the identifiability of the robust prediction model depends on the structure of both the training environments (via the space \(\)) and the test environments (via \(M_{ test}\)). We now aim to compute the smallest achievable robust loss for the general partially identifiable setting, which allows for \(R 0\). In particular, we provide a lower bound on the _best-possible achievable distributional robustness_ formalized by the minimax quantity (10). First observe that without further assumptions on the parameter space \(\), the observationally equivalent set is unbounded, and the worst-case robust risk (9) can be infinite. The following boundedness assumption allows us to provide a fine-grained analysis of robustness in a partially identified setting.

**Assumption 3.2** (Boundedness of the causal parameter).: _There exists a constant \(C>0\) such that any parameter \(\) in the DGP (3) is norm-bounded by \(C\), i.e. \(\|\|_{2} C\)._

Furthermore, we define \(C_{ ker}=-\|^{}\|^{2}}\), the maximum norm of the non-identified part of the linear parameter \(^{}\). Finally, recall that the reference distribution \(^{X,Y}_{^{},0}\) is observed and hence identifiable.

**Theorem 3.1**.: _Assume that the training and test data follow the data-generating mechanism in Section 2.1 and \(M_{ test}\) satisfies Assumption 3.1 for some \(M_{ seen},R\) with \({ range}\ M_{ seen}\), \({ range}\ R^{}\). Further, let Assumption 3.2 hold with parameter \(C\). The worst-case robust risk (9) is then given by_

\[_{ rob}(;_{ eq},M_{ test})=^{}(C_{  ker}+\|R^{}\|_{2})^{2}+(^{}-)^{} M_{ seen}(^{}-)+(;^{X,Y}_{ ^{},0}),\] (15)

_The minimax quantity in Equation (10) is lower bounded as follows:_

\[(_{ eq},M_{ test})=^{}C_{ ker }^{2}+_{R^{}=0}_{ rob}(;^{},  M_{ seen}),&^{}^{}_{ th};\\ ^{}C_{ ker}^{2}+_{^{d}}_ { rob}(;^{}, M_{ seen}),&,\] (16)

_where \(^{}_{ th}=_{})+1)\|RR^{} ^{}_{,}\|_{4}}{C_{ ker}}\). Moreover, for small unseen shifts_

\[_{^{} 0}(_{ eq},M_{ test})}{ ^{}}=(C_{ ker}+\|RR^{}^{-1}_{}^{ }_{,}\|)^{2}.\] (17)We prove Theorem 3.1 in Appendix F.2. First, in the case of no new test shifts where \(^{}=0\) (as it appears in prior work [41; 45]) we can plug in the robust risk Equation (7) into Equation (16) to observe the following: as the strength \(\) of the shift grows, the optimal robust risk saturates. On the other hand, if \(^{} 0\), i.e., the test shift contains new directions w.r.t. to the training data, the best achievable robustness \((_{},M_{})\) grows linearly with \(^{}\). Further note that for \(^{}^{}_{}\), we have a tight expression for the minimax quantity and the worst-case robust predictor \(^{}_{_{}}\) can be explicitly computed (cf. Appendix F.2) and is _orthogonal_ to the space \(\ R\) of non-identifiable test shift directions. In other words, for large shifts in non-identified directions, the optimal robust model would "abstain" from prediction in those directions. For smaller \(^{}\), \(^{}_{_{}}\) gradually utilizes less information in the non-identified directions, thus interpolating between maximum predictive power (OLS) and robustness w.r.t. new directions (abstaining). The model \(^{}_{_{}}\) is a population quantity that is identifiable from the collection of training _distributions_. When only finite samples are available, we discuss in Appendix D how we can compute the worst-case robust estimator by minimizing an empirical loss function that can be computed from multi-environment data.

### Theoretical analysis of existing finite robustness methods

We now evaluate existing finite robustness methods in our partial identifiability framework and characterize their (sub)optimality in different scenarios. A spiritually similar systematic comparison of domain adaptation methods is presented in , however, in our setting, the robust risk is not identifiable from data. Concretely, we compare discrete anchor regression  and pooled OLS estimators 5 with the minimax quantity in Theorem 3.1. We consider the same scenario as in discrete anchor regression, which is a the specific case of the setting in Equation (3), where for each environment \(e\), \(A_{e}\) is just a mean shift with variance \(0\). In addition, discrete anchor regression assumes that the environment variable \(E_{}\) follows a probability distribution with \([E=e]=w_{e}\). The discrete anchor setting then corresponds to setting a test shift upper bound \(M_{}= M_{}\) for some \(>0\) (cf. Equation (4)) with \(M_{}=_{e_{}}w_{e}_{e}_{e }^{}\). The (oracle) discrete anchor regression estimator minimizes the robust risk and reads

\[_{}=*{arg\,min}_{^{d}} _{}(;^{}, M_{}),\] (18)

The pooled ordinary least squares (OLS) estimator \(_{}\) corresponds to \(_{}\) with \(=1\). We observe that the test shifts bounded by \( M_{}\) are fully contained in the space of identified directions \(\), since \(=\ _{e_{}}_{e}_{e }^{}=\ M_{}\). Thus, according to Proposition 1, the robust risk and robust predictor \(_{}\) are identifiable for all \(>0\). In the next corollary, we compute worst-case robust risk of both \(_{}\) and \(_{}\) with respect to the more general shifts bounded by \(M_{}:= M_{}+^{}RR^{}\), thus possibly including unseen shifts consisting of additional unseen shifts \(\ R^{}\).

**Corollary 3.2** (Worst-case robust risk of the anchor regression estimator).: _Assume that the test shift upper bound is given by \(M_{}:= M_{}+^{}RR^{}\). Let \(^{X,Y}_{}=_{e}w_{e}^{X,Y}_{e}\) be the pooled training distribution. Then the general worst-case robust risk is given by_

\[_{}(;_{},M_{})= ^{}(C_{}+\|R^{}\|_{2})^{2}+(-1)(^{ }-)^{}M_{}(-^{})+ (,^{X,Y}_{}).\]

_Furthermore, the the anchor and OLS predictor, respectively, it holds that there exists constants \(c_{1},c_{2},c_{3}\) independent of \(,^{}\) such that_

\[_{}(_{};_{ },M_{}) =(C_{}+\|RR^{}(^{}_{}+ M_{ })^{-1}^{}_{,}\|)^{2}^{}+c _{1};\] \[_{}(_{};_{},M_{}) =(C_{}+\|RR^{}(^{}_{}+M_{})^{-1} ^{}_{,}\|)^{2}^{}+c_{2}.\]

_In contrast, the best achievable robustness reads_

\[(_{},M_{}) =C_{}^{2}^{}+c_{3},\ \ ^{}^{}_{};\] \[_{^{} 0}(_{},M_{ })/^{} =(C_{}+\|RR^{}(^{}_{}+ M_{ })^{-1}^{}_{,}\|)^{2}.\]Observe that the worst-case robust risk in the extended anchor regression setting is equal to the anchor regression risk with an additional non-identifiability penalty term \(^{}(C_{}+\|R^{}\|_{2})^{2}\). The anchor regression estimator is optimal in the limit of vanishing unseen shifts but (for any \(\)) significantly deviates6 from the best achievable robustness for larger unseen shifts \(^{}^{}_{}\). Moreover, in case of completely new shifts (\(=0\)), pooled OLS and the anchor estimator achieve the same rate in \(^{}\), showcasing how finite robustness methods can perform similarly to empirical risk minimization if the assumptions on the robustness set are not met. We provide additional performance comparisons for the more general shift in Appendix C and the proof of the corollary in Appendix F.3.

## 4 Experimental results

In this section, we provide empirical evidence of our theoretical conclusions in Sections 3.1 and 3.2. In particular, we compare the prediction performance of multiple existing robustness methods to the (estimated) minimax robustness in identifiable and partially identifiable settings. We observe that both on synthetic and real-world data, in the partially identified setting, empirical risk minimization and invariance-based robustness methods not only have significantly sub-optimal test loss, but also perform more similarly, thereby aligning with our theoretical results in Section 3.2. This stands in contrast to the identifiable setting, where the anchor predictor is optimal up to finite-sample effects. Furthermore, we observe that even though the minimizer of the worst-case robust risk is optimal only for the linear causal setting in Section 2.1, it surprisingly outperforms existing methods in a real-world experiment.

Experiments on synthetic Gaussian dataWe simulate Gaussian covariates according to Equation (3) with multiple environments differing by linearly independent randomly selected mean shifts. For a randomly sampled collection of mean shifts, we evaluate a proxy for the worst-case robust risk by picking the most adversarial \((^{},^{*}_{})\) for the shifts, and then computing its robust risk (7). We describe the full details of the data generation and loss evaluation in Appendix E.1. We consider two shift scenarios: in the identifiable case in (see Figure 1(a)), the test environment is only perturbed by bounded shifts in training directions with increasing strength \(\), as considered in prior work [41; 45]. In the non-identifiable case (see Figure 1(b)), the test environment is perturbed by a mixture of training shifts and shifts in previously unobserved directions, where \(\) is fixed and \(^{}\) varies (cf. Assumption 3.1). We compute the empirical minimizers \(_{},_{}\) and \(_{}^{}\) of the OLS, anchor regression and worst-case robust losses, respectively, and compare their worst-case robust risk (mean squared error) in Figure 3. In the identifiable setting - Figure 3 (left) - the robust risk is asymptotically constant across \(\) for both robust methods, while the error for the OLS, or vanilla ERM, estimator increases linearly. In contrast, in the second, partially identified, setting - Figure 3 (right) - all estimators exhibit linearly increasing test errors; however the slopes of the anchor and OLS estimator are much steeper and lead to larger errors than the empirical minimizer of (15) that closely matches the analytic theoretical lower bound.

Real-world data experimentsWe evaluate the performance of OOD methods using single-cell gene expression data from , consisting of \(d=622\) genes across observational and interventional environments. As in , we focus on 28 genes active in the observational environment. For each gene \(j=1,,28\), we define the target variable \(Y:=X_{j}\) and select the three genes most strongly

Figure 3: Worst-case robust risk of the baseline estimators \(_{},_{}\) (using the ”correct” \(\)), the worst-case robust predictor in (mean-shifted) multi-environment finite-sample experiments and theoretical population lower bound in the classical identified setting with varying shift strength \(\) (left) and the partially identifiable setting with fixed \(\) but varying \(^{}\) (right). The details of the experimental setting can be found in Appendix E.

correlated with \(Y\) as covariates. This yields 28 prediction problems indexed by \(j\), each consisting of data from an observational environment \(\) and three interventional environments \(_{j1}\), \(_{j2}\), \(_{j3}\) representing the gene knockout on a single covariate. For each prediction problem, we consider three training datasets \(D_{j1}\), \(D_{j2}\), \(D_{j3}\), obtained by combining data from \(\) with a single interventional environment \(_{j1}\), \(_{j2}\), \(_{j3}\), respectively. For each training dataset \(D_{jk}\), \(k=1,2,3\), we evaluate the mean-squared error (MSE) at test time using four datasets consisting of varying proportions of unseen shifts (e.g., "\(33\%\) unseen directions" in Figure 4 represents a test dataset with \(67\%\) observations sampled from \(_{jk}\) and \(33\%\) from \(_{j}\) with \( k\)). Hence, for each prediction problem predicting a gene \(j\), we evaluate on 12 configurations (three training and four test datasets).7 Figure 4 illustrates the test MSE of the worst-case robust estimator (Worst-case Rob.) alongside anchor regression, invariant causal prediction (ICP), DRIG, and OLS, as a function of perturbation strength \(s\). 8 For a given proportion of unseen shifts, \(s\) controls the distance of the test data points from the observational mean, acting as a proxy for shift strengths \(\) and \(^{}\). 9 We observe that the performance ranking of the robustness methods significantly varies with the proportion of new test shift directions. As expected, when no new shift directions are present at test time (0%), anchor regression and DRIG are optimal, since they protect against shifts observed at training time. However, as soon as some unseen directions are present, their performance becomes inferior to OLS/ERM and the gap to the worst-case robust predictor (in the linear setting described in Section 2) grows with the proportion of unseen shifts. Further, while the MSE of the previous invariant methods increases significantly with the strength of the test shift \(s\), the test loss of the worst-case robust predictor remains relatively stable.

## 5 Conclusion and future directions

This paper introduces the worst-case robust risk - a quantity that is well-defined even in settings where the usual robust risk is not computable from training distributions, and in identifiable scenarios  reduces to the conventional robust risk. We instantiate our general framework for linear models with additive distribution shifts and compute tight lower bounds for this setting. Further, we demonstrate how i) the benefits of invariance-based robustness methods strongly decrease in the partially identifiable setting; and ii) this suboptimality increases with perturbation strength and proportion of previously unobserved test shifts.

The main limitation of our paper is its reliance on a linear setting to explicitly compute the worst-case robust risk and estimate the minimax quantity. However, we expect that the results and intuition developed in this paper can be extended to linear shifts in a lower-dimensional latent space via a suitable parametric or non-linear map . Important future directions include extending our results to more general shift models, non-linear functional relationships and the classification setting. Further, a potential use of our work is in the field of _active intervention selection_ (e.g, ). By computing the most adversarial model parameter for a given estimator, e.g., OLS, we can obtain an intervention which minimizes the worst-case robust risk of the estimator on the next unseen shift.

Figure 4: The figures show the performance of the _worst-case robust predictor_ (Worst-case Rob.) compared to other methods as a function of perturbation strength \(s\). Different panels correspond to the proportion of unseen shift directions at test time. For each panel and perturbation strength \(s\), each point represents an average over the 28 target genes and three experiments (i.e., training environments).

Acknowledgements

JK was supported by the SNF grant number 204439. NG was supported by the SNF grant number 210976. We thank Kasra Jalaldoust and Yixin Wang for helpful discussions and feedback on the manuscript.