# Acceleration Exists! Optimization Problems When Oracle Can Only Compare Objective Function Values

Aleksandr Lobanov

MIPT, Skoltech, ISP RAS

lobbsasha@mail.ru &Alexander Gasnikov

Innopolis, MIPT, MI RAS

gasnikov@yandex.ru &Andrei Krasnov

MIPT, Innopolis

krasnov.an@phystech.edu

###### Abstract

Frequently, the burgeoning field of black-box optimization encounters challenges due to a limited understanding of the mechanisms of the objective function. To address such problems, in this work we focus on the deterministic concept of Order Oracle, which only utilizes order access between function values (possibly with some bounded noise), but without assuming access to their values. As theoretical results, we propose a new approach to create non-accelerated optimization algorithms (obtained by integrating Order Oracle into existing optimization "tools") in non-convex, convex, and strongly convex settings that are as good as both SOTA coordinate algorithms with first-order oracle and SOTA algorithms with Order Oracle up to logarithm factor. Moreover, using the proposed approach, _we provide the first accelerated optimization algorithm using the Order Oracle_. And also, using an already different approach we provide the asymptotic convergence of _the first algorithm with the stochastic Order Oracle concept_. Finally, our theoretical results demonstrate effectiveness of proposed algorithms through numerical experiments.

## 1 Introduction

The black box problem has garnered extensive attention in diverse scientific and engineering domains, reflecting the challenge of optimizing systems with complex and opaque objective functions, prompting the exploration of innovative solutions Conn et al. (2009); Kimiaei and Neumaier (2022).

This paper focuses on solving a standard general optimization problem in the following form:

\[_{x^{d}}\{f(x):=_{}f_{}(x )\},\] (1)

where \(f:^{d}\) is a possibly non-convex, possibly stochastic function. This problem configuration encompasses a broad range of applications in ML scenarios, e.g. empirical risk minimization,where \(\) denotes distribution across training data points, and \(f_{}(x)\) represents loss of model \(x\) on data point \(\).

When the objective function \(f(x)\) has exclusive access to a zero-order oracle Rosenbrock (1960), problem (1) falls under the classification of a black-box optimization problem. This class of problems is actively studied in various application settings, e.g., deep learning Chen et al. (2017); Gao et al. (2018), federated learning Dai et al. (2020); Alashqar et al. (2023); Patel et al. (2022), reinforcement learning Choromanski et al. (2018); Mania et al. (2018), overparameterized models Lobanov and Gasnikov (2023), online optimization (Agarwal et al., 2010; Bach and Perchet, 2016; Akhavan et al., 2022), multi-armed bandits Shamir (2017); Lattimore and Gyorgy (2021), hyperparameter settings Bergstra and Bengio (2012); Hernandez-Lobato et al. (2014); Nguyen and Balasubramanian (2022), and control system performance optimization Bansal et al. (2017); Xu et al. (2022). It is important to highlight that the zero-order oracle presupposes awareness of the objective function's value \(f(x_{k})\) at a specific point \(x_{k}\) (which may be inexact), enabling the development of effective gradient-free algorithms tailored to various problem scenarios Gasnikov et al. (2022a).

In this paper, we consider concept of zero-order oracle, termed _Order Oracle_, to address problem (1):

\[(x,y)=[f(x)-f(y)+(x,y)],\] (2)

where \(|(x,y)|\) is some bounded noise. The Order Oracle has the capability to compare two functions; however, in contrast to the zero-order oracle, it lacks the ability to calculate or utilize the actual value of the objective function. This concept closely mirrors the challenges encountered in real-world black-box optimization problems. The motivation for the proposed oracle concept becomes more evident when considering the ongoing developments in generative models. Companies like Valio and SberAI have already embraced the active involvement of AI in dessert creation. Notably, Valio, as illustrated in Figure 1*, employed AI to determine the optimal concentration of milk for chocolate bars based on available data. However, envision a scenario where AI creates customized chocolate for an individual by adjusting the concentration of ingredients. In such a case, a flavor comparison procedure, depicted in one iteration, would involve determining the preference _order_. Given that tastes can be closely aligned, introducing bounded noise in oracle (2) mitigates the potential for errors.

To address the initial deterministic problem (1) with the Order Oracle (2), we propose a novel approach to algorithm design that uses class of coordinate descent methods (CD) Bubeck et al. (2015) as an optimization "tool" to integrate our oracle into multidimensional optimization. This approach is good in that we use linear search (where the Order Oracle is directly used) to determine not only the iteration step size, but also the gradient coordinate of the objective function. Thus demonstrating that the proposed algorithms are also adaptive. And for solving the initial stochastic problem (1) with the Order Oracle, we propose an approach based on normalized SGD, providing asymptotic convergence.

### Our contributions

More specifically, our contributions are the following:

* We provide a novel approach to design algorithms for solving deterministic optimization problems (1) with Order Oracle (2) that achieves SOTA convergence results up to logarithm factor in the non-convex, convex, and strongly convex settings (see Table 1 and Algorithm 1).
* By using the approach proposed in this paper to create algorithms for solving deterministic optimization problem (1) with the Order Oracle (2), we have shown, on an example of strongly convex functions, that acceleration in such an oracle concept exists (see Algorithm 2 and Theorem 4.1). Moreover, we have shown how the convergence results of the accelerated algorithm can be improved when the problem is low-dimensional (the algorithm described in Appendix G shows convergence that even the Ellipsoid method cannot).
* We provide the first algorithm for solving a problem (1) with the stochastic Order Oracle concept, where the _order_ between two functions on the same realization is determined.
* Through numerical experiments (see Section 7), we validate our theoretical results by comparing with first-order algorithms, as well as providing practical recommendations for implementing the first accelerated algorithm with the Order Oracle (2) (see Algorithm 2).

Figure 1: Valio’s chocolate

### Main assumptions and notations

Before discussing related works, we present the notation and main assumptions we use in our work.

Notation.We use \( x,y:=_{i=1}^{d}x_{i}y_{i}\) to denote standard inner product of \(x,y^{d}\). We denote Euclidean norm in \(^{d}\) as \(\|x\|:=^{d}x_{i}^{2}}\). In particular, this norm \(\|x\|:=\) is related to the inner product. We use \(_{i}^{d}\) to denote the \(i\)-th unit vector. We define the norms \(\|x\|_{[]}:=^{d}L_{i}^{}x_{i}^{2}}\) and \(\|x\|_{[]}^{*}:=^{d}L_{i}^{}x_{i}^{2}}\). We denote by \( f(x)\) the full gradient of function \(f\) at point \(x^{d}\), and by \(_{i}f(x)\) the \(i\)-th coordinate gradient. The sum of constant \(L_{i}\) denotes as \(S_{}:=_{i}^{d}L_{i}^{}\). We use \(S^{d}(r):=\{x^{d}:\|x\|=r\}\) to denote Euclidean sphere. We use \(()\) to hide the logarithmic coefficients. We denote \(f^{*}:=f(x^{*})\) as the solution to initial problem.

For all our theoretical results, we assume that \(f(x)\) is \(L_{i}\)-smooth with respect to its \(i\)-th coordinate:

**Assumption 1.1** (Smoothness).: A function \(f:^{d}\) is \(L\)-coordinate-Lipschitz for \(L_{1},L_{2},...,L_{d}>0\) if for any \(i[d]\), \(x^{d}\) and \(h\) the following inequality holds:

\[|_{i}f(x+h_{i})-_{i}f(x)| L_{i}|h|.\]

The smoothness assumption of the function is widely used in the optimization literature (e.g. Boyd and Vandenberghe, 2004; Nesterov et al., 2018). However, Assumption 1.1 is specific and frequently utilized in the context of optimization via the CD method Lin et al. (2014); Zhang and Xiao (2017); Mangold et al. (2023). This assumption means that for every input point \(x\), if we alter its \(i\)-th coordinate by at most \(h\), then the corresponding gradient \(_{i}f(x+h_{i})\) differs from \(_{i}f(x)\) by at most \(L_{i}\) times \(|h|\).

Throughout this paper we assume that function \(f(x)\) can be (strongly) convex w.r.t. the norm \(\|\|_{[1-]}\):

**Assumption 1.2**.: A function \(f:^{d}\) is \(_{1-} 0\) strongly convex w.r.t. the norm \(\|\|_{[1-]}\) if for any \(x,y^{d}\) the following inequality holds:

\[f(y) f(x)+ f(x),y-x+}{2}\|y-x \|_{[1-]}^{2}.\]

Many works in convex optimization rely on the (strong) convexity assumption, as evidenced by references such as Duchi (2016); Shi et al. (2019); Asi et al. (2021). Since our work employs norms \(\|\|_{[1-]}\) to derive theoretical estimates, Assumption 1.2 deviates slightly from the standard. However, this assumption of \(_{1-}\) (strong) convexity is extensively used in the following literature: Nesterov (2012); Lee and Sidford (2013); Allen-Zhu et al. (2016). Assumption 1.2 can conform to standard form of \(\) (strong) convexity via Euclidean norm if \(=1\). This assumption is convex provided \(_{1-}=0\).

### Paper organization

Further, this paper has the following structure. In Section 2, we provide a related work discussion. We present and analyze the non-accelerated algorithm in Section 3. Then in Section 4, we discuss the feasibility of accelerating the proposed algorithm in the concept of Order Oracle and provide theoretical guarantees. We provide the first algorithm that utilizes the stochastic concept of the Order Oracle in Section 5. In Section 6, we discuss the current results of this work. Through numerical experiments in Section 7, we validate the theoretical results. While Section 8 concludes the paper.

## 2 Related Works

The literature in the field of optimization is already extensive and continuously expanding, encompassing various problem formulations and assumptions. In this section, we provide an overview of the most relevant contributions to our work. Namely both CD methods and algorithms with Order Oracle.

Algorithms with Order Oracle.In the field of black-box optimization problem, special attention has been paid to algorithms that use only the Order Oracle. For example, Stochastic Three Points Method was proposed in Bergou et al. (2020), which uses an oracle that compares three function values at once and achieves the following oracle complexity in the strongly convex case \((dL/ 1/)\). A little later, the authors of Gorbunov et al. (2019) modified the Stochastic Three Points Method to thecase of importance sampling, improving the oracle complexity estimate in the strongly convex case \((S_{}/ 1/)\). Already in 2021, Saha et al. (2021) provided another algorithm in which the oracle compares two function values only once per iteration. The analysis of this algorithm is based on the Sign SGD and achieves oracle complexity in the strongly convex case \((dL/ 1/)\). The work of Tang et al. (2023) showed that the Order Oracle is also extensively used in _Reinforcement Learning with Human Feedback_, providing only in the non-convex case an estimate on oracle complexity \((d/^{2})\). In this paper, we propose an alternative approach for creating optimization algorithms (via line search method), which achieves SOTA convergence results with logarithm accuracy in a class of non-accelerated algorithms, and provide the first accelerated algorithm with the Order Oracle.

Coordinate descent (CD) methods.In addition to full-gradient algorithms for smooth first-order optimization, coordinate descent algorithms are categorized into accelerated and non-accelerated algorithms. Non-accelerated algorithms typically converge at rates \(1/\) and \(1/\) in convex (\(=0\)) and strongly convex (\(>0\)) cases, respectively, while accelerated algorithms achieve rates \(1/\) and \(1/\) in convex and strongly convex cases, respectively. This classification dates back to 1983 when Nesterov introduced the optimal convergence rates for first-order algorithms Nesterov (1983). However, the fundamental difference between coordinate descent and full-gradient descent lies in the step taken along the \(i\)-th coordinate of the gradient (directional derivative). Monograph Bubeck et al. (2015) has demonstrated that if the direction is chosen uniformly, coordinate descent may require up to \(d\) times more iterations than full-gradient descent. However, authors in Nesterov (2012) have shown that considering smoothness along the direction \(L_{i}\) can improve the number of iterations \((S_{}R_{[1-]}^{2}/)\) and \((S_{}/_{1-})\) in convex and strongly convex cases, respectively, where \(R_{[1-]}=_{x^{d}:f(x) f(x_{0})}\|x-x^{*} \|_{[1-]}\) for \(\). In the same paper Nesterov (2012), the authors demonstrated the potential for acceleration in coordinate descent through the scheme proposed in Nesterov (1983). Subsequently, in Lee and Sidford (2013), they analyzed and presented an accelerated version of coordinate descent (ACDM), along with the corresponding number of required \((R_{[1-]}^{2}/})\) and \((/_{1-}})\) iterations in convex and strongly convex cases, respectively. It is noteworthy that, at that time, this iteration complexity was deemed unimprovable. However, a few years later, both Nesterov and Stich (2017) and Allen-Zhu et al. (2016) independently provided same results, demonstrating that it is indeed possible to enhance the iteration complexity for accelerated coordinate descent methods by modifying the probability of choosing the \(i\)-th coordinate: \(L_{i}^{/2}/S_{/2}\). In this paper, we propose a coordinate descent algorithm with an Order Oracle (2), demonstrating that it achieves the same iteration complexity as first-order algorithms. Furthermore, based on accelerated coordinate descent Nesterov and Stich (2017), we establish on the strongly convex case that even with an Order Oracle, acceleration can be attained, resulting in the most favorable estimates on iteration complexity known to date.

## 3 Non-Accelerated Methods

In this section, we begin to present our main results, by introducing algorithms tailored to address the initial problem (1) utilizing the Order Oracle (2). Given the demand for this oracle concept, we furnish convergence guarantees and conduct comparisons with algorithms employing alternative oracles.

Our approach for developing a new algorithm involves incorporating the Order Oracle into an existing optimization method using linear search. We opt for linear search as the integration tool due to its compatibility with the Order Oracle concept. However, the choice of optimization method to which this linear search can be applied poses a crucial question. After careful consideration, we determined that the _coordinate descent method_ (CDM) is the most suitable candidate. In each iteration, the CDM, given a step size \(_{k}>0\) and starting point \(x_{0}^{d}\), proceeds as follows:

\[x_{k+1}=x_{k}-_{i_{k}}f(x_{k})}_{_{k}}_{i_{k}},\] (3)

where \(i_{k}\) is the coordinate index drawn from \([d]\). Note that the coordinate descent method step (3) requires both a step size \(_{k}\) and a gradient coordinate value \(_{i_{k}}f(x_{k})\), which are scalars. Thus, by employing linear search \(_{k}=*{arg\,min}_{}\{f(x_{k}+_{i_{k}})\}\) at each iteration, we can optimally determine both the direction of steepest descent and the step size to traverse along this direction, resulting in a fully adaptive algorithm. The next consideration is the strategy for coordinate selection at each iteration. Following the trend initiated by Nesterov (2012), we use a more general sampling distribution than the uniform one, obtaining already _random coordinate descent_ (RCD). Specifically, for \(>0\), we assume that a random generator \(_{}(L)\) independently selects \(i_{k}\) from the following distribution:

\[p_{}(i)=L_{i}^{}/S_{}, i[d].\] (4)

We are now ready to introduce a method designed to solve problem (1) utilizing the oracle concept (2).

This algorithm falls under the category of coordinate methods and is named _random coordinate descent with order oracle_ (OrderRCD), see Algorithm 1. It should be noted that the inherent "stochasticity" of problem (1) is artificially induced by randomized procedure used to select the \(i\)-th coordinate (4). Here, \(\) denotes the \(i\)-th coordinate, and \(\) represents distribution \(p_{}(i)\) from (4). The _golden ratio method_ (GRM) serves as the linear search algorithm, which is where the Order Oracle is used. It is known that GRM (which is described in Appendix C.2) requires \(N=( 1/)\) iterations to achieve the desired accuracy \(\) (in terms of function) of the solution to the linear search problem (namely, \(_{k}=_{}\{f(x_{k}+_{i_{k}})\}\)).

Next, we present our theoretical results, demonstrating through convergence analyses that random coordinate descent with order oracle (OrderRCD) exhibits competitive iteration complexity compared to _first-order algorithms_ when applied to _non-convex_, _convex_, or _strongly convex_ functions.

### Non-convex setting

**Theorem 3.1** (non-convex).: _Let function f(x) satisfies Assumption 1.1, \(N\) is the number of iterations, \(F_{0}=f(x_{0})-f(x^{*})\), then Algorithm 1 (OrderRCD) with oracle (2) guarantees an error:_

\[_{k=0}^{N-1}(\| f(x_{k})\|_{[1-]}^ {*})^{2}(F_{0}}{N}+S_{} +S_{}),\]

_where \(\) is the accuracy of solving linear search problem by function and \(=}{2}\) is golden ratio._

The convergence results of Theorem 3.1 imply the existence of a point \(k[N]\) where \((\| f(x_{k})\|_{[1-]}^{*})^{2}( F_{0}}{N})\) holds true. Additionally, Theorem 3.1 indicate that, to achieve the desired accuracy \(\) (according to the gradient norm), Algorithm 1 requires \(N=(S_{}F_{0}/^{2})\) iterations and \(T=}(S_{}F_{0}/^{2})\) calls to the oracle (2). The maximum admissible noise level ensuring the desired accuracy should not exceed \(^{2}\). Notably, the convergence rate of random coordinate descent with the order oracle (OrderRCD), assuming minimal noise (\(^{2}\)), is equal to _first-order method_: random coordinate descent (RCD). It is also characteristic (within the coordinate methods class) to be inferior to _gradient descent_(Ghadimi and Lan, 2013, under \(L\) smoothness assumption). For instance, in the case when \(=1\), the convergence rates \((LF_{0}/N)\) is better because \(L_{i=1}^{d}L_{i}\). Not surprisingly, in terms of oracle complexity, Algorithm (1) is logarithmically inferior to first-order algorithms. This discrepancy reflects the "cost" associated with employing GRM, where the \(()\) to hide the _logarithmic coefficient_ representing the number of oracle calls in the GRM, _contingent upon its accuracy \(\)_. A detailed proof of Theorem 3.1 is given in Appendix D.1.

### Convex setting

We now prove an analogous theorem on the convergence of the algorithm when the function is convex, i.e., additionally assuming that Assumption 1.2 is satisfied with \(_{1-}=0\).

**Theorem 3.2** (convex).: _Let function \(f(x)\) satisfies Assumption 1.1 (\(L\)-Smoothness) and Assumption 1.2 (convexity, \(_{1-}=0\)), then Algorithm 1 (OrderRCD) with oracle (2) guarantees an error:_

\[[f(x_{N})]-f(x^{*})(R _{[1-]}^{2}}{N}+R_{[1-]}^{2}(+ )}{F_{N-1}}),\]

_where \(\) is an inner problem accuracy, \(R_{[1-]}=_{x^{d}:f(x) f(x_{0})}\|x-x^{*} \|_{[1-]}\), and \(=}{2}\)._In comparison to Theorem 3.1 (non-convex setting), the convergence results of Algorithm 1 demonstrate improvement under the assumption of function convexity (Assumption 1.2 with \(_{1-}=0\)). Specifically, according to Theorem 3.2, random coordinate descent with order oracle (OrderRCD) requires \(N=(S_{}R_{[1-]}^{2}/)\) iterations and \(T=}(S_{}R_{[1-]}^{2}/)\) oracle calls to achieve the desired accuracy \(\) (where \([f(x_{N})]-f(x^{*})\)). However, in cases where \(>0\), the condition for maximum noise remains unchanged compared to the non-convex setting. Furthermore, the iteration complexity \(N\) aligns with that of the first-order algorithm, (_random coordinate descent_ (RCD) Nestetrov, 2012). Similarly, akin to Theorem 3.2, the convergence rate of _gradient descent_ (Nesterov et al., 2018, under assuming \(L\) smoothness and convexity) outperforms that of Algorithm 1. Moreover, when \(=0\) (corresponding to a _uniform distribution_ with probability \(p_{}(i)=1/d\)), OrderRCD (like all coordinate methods) necessitates \(d\) times more iterations than gradient descent. Concerning oracle complexity \(T\), a logarithmic coefficient is evident, correlating with the number of oracle calls per iteration of Algorithm 1, line 2. For a comprehensive proof of Theorem 3.2, refer to Appendix D.2.

### Strongly convex setting

In this section we consider case when function is strongly convex (see Assumption 1.2, \(_{1-}>0\)).

**Theorem 3.3** (strongly convex).: _Let function \(f(x)\) satisfies Assumption 1.1 (\(L\)-Smoothness) and Assumption 1.2 (convexity, \(_{1-}>0\)), then Algorithm 1 with oracle (2) has a linear convergence rate:_

\[[f(x_{N})]-f(x^{*})(1-}{S_{ }})^{N}F_{0}+}{_{1-}}+}{_{1-}},\]

_where \(c\) is some constant, \(\) is the GRM accuracy (by function) and \(=}{2}\) is golden ratio._

As depicted in Theorem 3.3 Algorithm 1 exhibits a linear convergence rate, achieving the desired accuracy \(\) in \(N=(S_{}/_{1-})\) iterations and \(T=}(S_{}/_{1-})\) oracle calls. Furthermore, there's an enhancement in the maximum noise level \(\), reaching \(_{1-}\). It's notable that a weaker strong convexity condition was employed in the proof of Theorem 3.3 (see Appendix D.3):

\[\| f(x)\|_{[1-]}^{2} 2_{1-}(f(x)-f(x^{*}) ), x^{d}.\] (5)

This condition (in the case \(=1\)), also known as the Polyak-Lojasiewicz or Gradient-dominated functions condition Polyak (1963); Lojasiewicz (1963); Karimi et al. (2016); Belkin (2021), encompasses a broad class of functions: convex functions, strongly convex functions, sum of squares (e.g. where considering a system of non-linear equations), invex and _non-convex functions_, as well as over-parameterized systems. Also it is shown in Yue et al. (2023) that _non-accelerated algorithms (like Algorithm 1) are optimal for \(L\)-smooth_ problems under the Polyak-Lojasiewicz condition (5).

**High probability deviations bounds.** Given that OrderRCD method in strongly convex setting demonstrates a linear convergence rate and employs a randomization in coordinate selection, we can derive exact estimates of _high deviation probabilities_ using Markov's inequality Anikin et al. (2015):

\[(f(x_{N()})-f^{*}) [f(x_{N()}]-f^{*}}{ }.\]

## 4 Accelerated Method

Random coordinate descent with order oracle (OrderRCD) demonstrates efficiency in the class of coordinate methods. The number of iterations \(N\) required to achieve the desired accuracy \(\) is fully identical to random coordinate descent (RCD), which is the best among the non-accelerated methods in this class, and are also not inferior to existing competitors with Order Oracle. This fact confirms that our proposed approach to developing a novel optimization algorithm is successful. However, Algorithm 1 is still not optimal because it belongs to non-accelerated algorithms. Nevertheless, Section 3 gives hope for the possibility of acceleration among algorithms using the oracle concept (2).

In this section, we demonstrate on the example of the strongly convex (Assumption 1.2 is satisfied with constant \(_{1-}>0\)) problem (1) that _acceleration_ in the class of optimization algorithms using the Order Oracle (2) _exists_! For simplicity, we consider the case when \(=0\).

Our approach to creating an accelerated algorithm closely mirrors the one proposed in Section 3, which involves adapting an existing optimization method (from the class of coordinate algorithms) to the Order Oracle using linear search method (namely, golden ratio method, GRM). Among the accelerated algorithms in the class of coordinate descent, two stand out: (_accelerated coordinate descent method_ (ACDM), Nesterov and Stich, 2017) and (_accelerated coordinate descent method with non-uniform sampling_ (NU-ACDM), Allen-Zhu et al., 2016). These algorithms boost the same convergence rate and are considered among the best available today. Therefore, we select one of them (specifically, ACDM) as the base algorithm to adapt to our oracle concept (2). At each iteration, the ACDM, given parameters such as \(_{k}\), \(_{k}\), \(a_{k+1}\), \(A_{k+1}\), \(B_{k+1}\), Lipschitz coordinate constant \(L_{i}\), strong convexity \(_{1-}\), distribution \(p_{}(i)\), and a starting point \(x_{0}=z_{0}\), proceeds as follows:

\[y_{k}=(1-_{k})x_{k}+_{k}w_{k},\] \[x_{k+1}=y_{k}-(1/L_{i_{k}})_{i_{k}}f(y_{k})_{i_{ k}},\] (6) \[z_{k+1}=w_{k}-}{L_{i_{k}}^{1-}B_{k+1}p_{ }(i)}_{i_{k}}f(y_{k})_{i_{k}},\] (7)

where \(w_{k}=(1-_{k})z_{k}+_{k}y_{k}\). Looking at the \(x_{k+1}\) update (6), it seems that it should not be difficult to determine the step size \(1/L_{i_{k}}\) and the value of the gradient coordinate \(_{i_{k}}f(y_{k})\) using a linear search, as demonstrated in Algorithm 1. However, substituting the same \(_{k}\) instead of \((1/L_{i_{k}})_{i_{k}}f(y_{k})\) into the \(z_{k+1}\) update (7) isn't straightforward. The step with linear search is larger than the original step of \((1/L_{i_{k}})_{i_{k}}f(y_{k})\), potentially leading to a paradoxical situation where the step worsens with linear search. This is because there is no guarantee that the function \(f\) is monotonically decreasing along the sequences \(\{z_{k}\}_{k=0}^{}\) and \(\{x_{k}\}_{k=0}^{}\)Nesterov (1983). Nevertheless, we have successfully addressed this challenge and we are ready to present the first accelerated algorithm utilizing only the Order Oracle: the _accelerated coordinate descent method with order oracle_.

It is evident from Algorithm 2 that the challenge was addressed by incorporating a secondary linear search, ensuring that the update step in \(z_{k+1}\) with linear search is at least as effective as (7). However, unlike Algorithm 1, OrderACDM cannot be deemed fully adaptive as it necessitates knowledge of the strong convexity constant \(_{1-}\) and the Smoothness constant \(L_{i}\) (which disappears in the case where \(=0\)). Despite this, we are ready to present the main advantage of Algorithm: Faster convergence rate of Accelerated Coordinate Descent Method with Order Oracle.

**Theorem 4.1**.: _Let function \(f(x)\) is strongly convex (Assumption 1.2), \(L\)-Smoothness (Assumption 1.1) and \(L_{[1-]}\)-Smoothness+, then Algorithm 2 (OrderACDM) with oracle (2) guarantees an error_

Footnote †: We assume that for any \(x,y^{d}\) it holds: \(f(y) f(x)+ f(x),y-x+}{2}\|y-x \|_{[1-]}^{2}\).

\[[f(x_{N})]-f(x^{*})(1- }}{S_{/2}})^{N}F_{0},\]

_where \(F_{0}=f(x_{0})-f(x^{*})\), \(S_{/2}=_{i=1}^{d}L_{i}^{/2}\)._

Compared to the results of Section 3, the convergence rate demonstrated in Theorem 4.1 is superior, _confirming the potential for acceleration_ in algorithms utilizing the Order Oracle. To achieve the desired accuracy \(\), Algorithm 2 (OrderACDM) requires \(N=(S_{/2}/})\) iterations

[MISSING_PAGE_FAIL:8]

is satisfied, we can perhaps consider that OrderRCD has optimal iteration complexity (see, Yue et al., 2023). However, when the other conditions are satisfied, this is not the case, since Algorithm 1 belongs to non-accelerated algorithms. Therefore, we believe that Section 4 provides a vector for the development of the question of optimality by showing an OrderACDM, which can perhaps be considered optimal in terms of iteration complexity. However, in the case of a _low-dimensional problem_, we can take a "Private communication" approach proposed Yurii Nesterov (for a more detailed description, see Appendix G) to create a more efficient algorithm using only oracle (2).

Before move to the numerical experiments, it's important to note that accelerated Algorithm 2 employs the golden ratio method (GRM) twice per iteration. This might raise concerns about its computational efficiency. However, in practice, we found that OrderACDM converges efficiently, comparable to the first-order algorithm, even when utilizing the golden ratio method only once. For a detailed analysis of the numerical experiments, refer to next Section 7 and Appendix B.

## 7 Numerical Experiments

In this section, we investigate the performance of the proposed algorithms in the corresponding Sections 3 and 4 on a numerical experiment. We compare OrderRCD (see Algorithm 1) and OrderACDM (see Algorithm 2), which utilize deterministic oracle concept (2) with existing first-order state-of-the-art algorithms. The goal is to highlight our theoretical results.

The optimization problem (1) has a standard quadratic form: \(_{x^{d}}f(x):= x,Ax-  b,x+c\), where \(A^{d d}\), \(b^{d}\), and \(c\). We use a uniform distribution (\(=0\)) to choose the active coordinate, then the distribution (4) has the following form: \(p_{0}(i)=1/d\). For such a problem, the assumptions of \(L\)-Coordinate-Lipschitz smoothness (Assumption 1.1) and \(_{1-}\)-strong convexity (Assumption 1.2) are satisfied, where \(L_{i}=A_{ii}\). In all experiments, we employ the golden ratio method (GRM) to solve the linear search problem with a precision of \(=10^{-8}\).

In Figure 2, we compare the convergence _random coordinate descent with order oracle_ (OrderRCD) and _accelerated coordinate descent method with order oracle_ (OrderACDM) with the SOTA non-accelerated algorithms: _random coordinate descent_ (RCD) from Nesterov (2012), as well as _gradient descent_ (GD). Non-accelerated coordinate algorithms, both for first-order oracle (RCD) and for our oracle concept (OrderRCD), are observed to lag behind gradient descent, confirming our theoretical derivations in Section 3. Interestingly, the random coordinate descent with order oracle even _outperforms its first-order counterpart_, despite the limitations associated with oracle usage (only Order Oracle (2) available). This observation can be attributed to the adaptiveness of Algorithm 1, as OrderRCD employs an exact step in the steepest descent direction obtained using the golden ratio method (GRM) at each iteration. Additionally, we can observe perhaps the most significant result demonstrated in Figure 2: _acceleration in our oracle concept_ (2) _exists_! We see that accelerated coordinate descent method with order oracle outpaces the convergence speed of all non-accelerated algorithms, including first-order coordinate (RCD) and full-gradient (GD) methods. In this experiment, OrderACDM was implemented using the method described in Algorithm 2 with \(_{k}=0\) (i.e., with one golden ratio method); RCD and GD used a constant step size, specifically \(1/L_{i}\) and \(1/L\).

## 8 Conclusion

We proposed a new approach to design optimization algorithms using only the deterministic concept of Order Oracle (2) by providing theoretical guarantees (showing SOTA results up to logarithm factor) for non-accelerated algorithms in non-convex, convex and strongly convex settings. We also discussed under which condition the Algorithm 1 is optimal (under the Polyak-Lojasiewicz condition). Using the proposed approach, we have shown that acceleration in the deterministic concept of the Order Oracle exists, thereby opening up a whole range of potential research. Furthermore, we have shown how the evaluation of the accelerated algorithm (so still convex tuning) can be improved by considering low-dimensional problems. Moreover, we provided first-of-its-kind theoretical guarantees for an algorithm utilizing the stochastic concept of Order Oracle (8). Finally, we demonstrated the effectiveness of the proposed algorithms (OrderRCD and OrderACDM) on numerical experiments, thereby validating the theoretical results. We provided practical recommendations for implementation of these algorithms.

Figure 2: Comparison of algorithms proposed with non-accelerated first-order algorithms.

## 9 Authors' Affiliation Clarification

MIPT \(=\)_Moscow Institute of Physics and Technology, Dolgoprudny, Russia_;

Skoltech \(=\)_Skolkovo Institute of Science and Technology, Moscow, Russia_;

ISP RAS \(=\)_Ivannikov Institute for System Programming of the Russian Academy of Sciences, Moscow, Russia_;

\(=\)_Research Center for Artificial Intelligence, Innopolis University, Innopolis, Russia_;

MI RAS \(=\)_Steklov Mathematical Institute of Russian Academy of Sciences, Moscow, Russia_.

## 10 Acknowledgments and Disclosure of Funding

This research has been financially supported by The Analytical Center for the Government of the Russian Federation (Agreement No. 70-2021-00143 01.11.2021, IGK 000000D730324P540002). The authors are grateful to Eduard Gorbunov, Andrey Neznamov, Alexander Vedyakhin.