# GC-Bench: An Open and Unified Benchmark for Graph Condensation

Qingyun Sun\({}^{1}\)

Ziying Chen\({}^{1}\)

Beining Yang\({}^{2}\)

Cheng Ji\({}^{1}\)

Xingcheng Fu\({}^{3}\)

**Sheng Zhou\({}^{4}\)**

Hao Peng\({}^{1}\)

Jianxin Li\({}^{1}\)

Philip S. Yu\({}^{5}\)

\({}^{1}\)Beihang University

\({}^{2}\)University of Edinburgh

\({}^{3}\)Guangxi Normal University

\({}^{4}\)Zhejiang University

\({}^{5}\)University of Illinois

 Chicago

{sunay,chanztuying}@buaa.edu.cn

Equal contribution.

###### Abstract

Graph condensation (GC) has recently garnered considerable attention due to its ability to reduce large-scale graph datasets while preserving their essential properties. The core concept of GC is to create a smaller, more manageable graph that retains the characteristics of the original graph. Despite the proliferation of graph condensation methods developed in recent years, there is no comprehensive evaluation and in-depth analysis, which creates a great obstacle to understanding the progress in this field. To fill this gap, we develop a comprehensive Graph Condensation Benchmark (GC-Bench) to analyze the performance of graph condensation in different scenarios systematically. Specifically, GC-Bench systematically investigates the characteristics of graph condensation in terms of the following dimensions: effectiveness, transferability, and complexity. We comprehensively evaluate 12 state-of-the-art graph condensation algorithms in node-level and graph-level tasks and analyze their performance in 12 diverse graph datasets. Further, we have developed an easy-to-use library for training and evaluating different GC methods to facilitate reproducible research. The GC-Bench library is available at https://github.com/RingBDStack/GC-Bench.

## 1 Introduction

Data are the driving force behind advancements in machine learning, especially with the advancement of large models. However, the rapidly increasing size of datasets presents challenges in management, storage, and transmission. It also makes model training more costly and time-consuming. This issue is particularly pronounced in the graph domain, where larger datasets mean more large-scale structures, making it challenging to train models in environments with limited resources. Compared to graph coarsening, which groups nodes into super nodes, and sparsification, which selects a subset of edges, graph condensation  synthesizes a smaller, informative graph that retains enough data for models to perform comparably to using the full dataset.

**Graph condensation.** Graph condensation aims to learn a new small but informative graph. A general framework of GC are shown in Figure 1. Given a graph dataset \(\), the goal of Graph condensation is to achieve comparable results on synthetic condensed graph dataset \(^{}\) as training on the original \(\). For Node-level condensation, the original dataset \(=\{\}=\{^{N d}, ^{N N}\}\) and the condensed dataset \(^{}=\{^{}\}=\{^{N^{ } d^{}},^{N^{} N^{}}\}\), where \(N^{} N\). For Graph-level condensation, the original dataset \(=\{_{1},_{2},,_{n}\}\) and the condensed dataset \(^{}=\{^{}_{1},^{}_{2},,^{}_{n^{}}\}\), where \(n^{} n\). The condensation ratio \(r\) can be calculated by condensed dataset size / whole dataset size.

**Research Gap.** Although several studies aim to comprehensively discuss existing GC methods [39; 10], they either overlook graph-specific properties or lack systematic experimentation. This discrepancy highlights a significant gap in the literature, partly due to limitations in datasets and evaluation dimensions. A concurrent work  analyzed the performance of node-level GC methods but it included only a subset of representative methods, lacking an analysis of graph-level methods, a deep structural analysis, and an assessment of the generalizability of the methods. To bridge this gap, we introduce GC-Bench, an open and unified benchmark to systematically evaluate existing graph condensation methods focusing on the following aspects: **Effectiveness:** the progress in GC, and the impact of structure and initialization on GC; **Transferability:** the transferability of GC methods across backbone architectures and downstream tasks; **Efficiency:** the time and space efficiency of GC methods. The contributions of GC-Bench are as follows:

* _Comprehensive benchmark._ GC-Bench systematically integrated 12 representative and competitive GC methods on both node-level and graph-level by unified condensation and evaluation, giving multi-dimensional analysis in terms of effectiveness, transferability, and efficiency.
* _Key findings._ (1) Graph-level GC methods is still far from achieving the goal of lossless compression. A large condensation ratio does not necessarily lead to better performance with current methods. (2) GC methods can retain semantic information from the graph structure in a condensed graph, but there is still significant improvement room in preserving complex structural properties. (3) All condensed datasets struggle to perform well outside the specific tasks they were condensed, leading to limited applicability. (4) Backbone-dependent GC methods embed model-specific information in the condensed datasets, and popular graph transformers are not compatible with current GC methods as backbones. (5) The initialization mechanism affects both the performance and convergence according to the characteristics of the dataset and the GC method. (6) Most GC methods coupled with backbones and whole dataset training have poor time and space efficiency, contradicting the initial purpose of using GC for efficient training.
* _Open-sourced benchmark library and future directions._ GC-Bench is open-sourced and easy to extend to new methods and datasets, which can help identify directions for further exploration and facilitate future endeavors.

## 2 Overview of GC-Bench

We introduce **G**raph **C**ondensation **B**enchmark (**GC-Bench**) in terms of datasets (\(\) Section 2.1), algorithms (\(\) Section 2.2), research questions that guide our benchmark design (\(\) Section 2.3) and the comparison with related benchmarks (\(\) Section 2.4). The overview of GC-Bench is shown in Table 1. More details can be found in the Appendix provided in the **Supplementary Material**.

Figure 1: The GC methods can be broadly divided into two categories: The first category depends on the backbone model, refining the condensed graph by aligning it with the backboneâ€™s _gradients_ (\(a\)), _trajectories_ (\(b\)), and output _distributions_ (\(c\)) trained on both original and condensed graphs. The second category, independent of the backbone, optimizes the graph by matching its distribution with that of the original graph data (\(d\)) or by identifying frequently co-occurring computation trees (\(e\)).

### Benchmark Datasets

Regarding evaluation datasets, we adapt the 12 widely-used datasets in the current literature. The node level dataset include 5 homogeneous dataset (_Cora_, _Citeseer_, _ogbn-arxiv_, _Flickr_, _Reddit_) and 2 heterogeneous datasets (_ACM_ and _DBLP_). The graph-level dataset include _NC1I_, _DD_, _ogbg-molbbe_, _ogbg-molbbbp_, _ogbg-molhiv_. We leverage the public train, valid, and test split of these datasets. We report the dataset statistics in Appendix A.1.

### Benchmark Algorithms

We selected 12 representative and competitive GC methods across 6 categories for evaluation. The main ideas of these methods are shown in Figure 1. The evaluated methods include: (1) traditional core-set methods including _Random_, _Herding_, _K-Center_, (2) gradient matching methods including _DosCond_, _Gcond_ and _SGDD_, (3) trajectory matching methods including _SFGC_ and _GEOM_, (4) distribution matching methods including GCDM  and DM [22; 24], (5) Kernel Ridge Regression (KRR) based method _KiDD_, and (6) Computation Tree Compression (CTC) method _Mirage_. The details of evaluated methods are in Appendix A.2.

### Research Questions

We systematically design the GC-Bench to comprehensively evaluate the existing GC algorithms and inspire future research. In particular, we aim to investigate the following research questiones.

**RQ1: How much progress has been made by existing GC methods?**

**Motivation and Experiment Design.** Previous GC methods always adopt different experimental settings, making it difficult to compare them fairly. Given the unified settings of GC-Bench, the first question is to revisit the progress made by existing GC methods and provide potential enhancement directions. A good GC method is expected to perform well consistently under different datasets and different condensation ratios. To answer this question, we evaluate GC methods' performance on 7 node-level datasets and 5 graph-level datasets with a broader range of condensation ratio \(r\) than previous works. The results are shown in Sec. 3.1 and Appendix B.1.

**RQ2: How do the potential flaws of the structure affect the graph condensation performance?**

**Motivation and Experiment Design.** Most of the current GC methods borrow the idea of image condensation and overlook the specific non-IID properties of irregular graph data. The impact of structural properties in GC is still not thoroughly explored. On one hand, the structure itself possesses various characteristics such as homogeneity and heterogeneity, as well as homophily and heterophily. It remains unclear whether these properties should be preserved in GC and how to preserve them. On the other hand, some structure-free GC methods  suggest that the condensed dataset may not

   \\  Traditional core-set methods & _Random_, _Herding_, _K-Center_ \\  Gradient matching & _Gcond_, _DosCond_, _SGDD_ \\  Trajectory matching & _SFGC_, _GEOM_ \\  Distribution matching & _GCDM_, _DM_[24; 22] \\  Kernel Ridge Regression & _KiDD_ \\  Computation Tree Compression & _Mirage_ \\   \\  Homogeneous datasets & _Cora_, _Citeseer_, _ogbn-arxiv_, _Flickr_, _Reddit_ \\  Heterogeneous datasets & _ACM_, _DBLP_ \\  Graph-level datasets & _NC1I_, _DD_, _ogbg-molbbe_, _ogbg-molbbbp_, _ogbg-molhiv_ \\   \\  Node-level task & Node classification, Link prediction, Anomaly detection \\  Graph-level task & Graph classification \\   \\  Effectiveness & Performance under different condensation ratios, Impact of structural properties, Impact of initialization mechanism \\  Transferability & Different downstream tasks, Different backbone model architectures \\  Efficiency & Time and memory consumption \\  

Table 1: An overview of GC-Benchneed to explicitly preserve graph structure, and preserving structural information in the generated samples is sufficient. To answer this question, we evaluated GC methods on both homogeneous and heterogeneous as well as homophilic and heterophilic datasets to further explore the impact of structural properties. The results are shown in Sec. 3.2 and Appendix B.2.

**RQ3: Can the condensed graphs be transferred to different types of tasks?**

**Motivation and Experiment Design.** Most existing GC methods are primarily designed for node classification and graph classification tasks. However, there are numerous downstream tasks on graph data, such as link prediction and anomaly detection, which focus on different aspects of graph data. The transferability of GC across various graph tasks has yet to be thoroughly explored. To answer this question, we perform condensation guided by node classification and use the condensed dataset to train models for 3 classic downstream tasks: _link prediction_, _node clustering_, and _anomaly detection_. The evaluation results are shown in Sec. 3.3 and Appendix B.3.

**RQ4: How does the backbone model architecture used for condensation affect the performance?**

**Motivation and Experiment Design.** The backbone model plays an important role in extracting the critical features of the original dataset and guiding the optimization process of generating the condensed dataset. Most GC methods choose a specific graph neural network (GNN) as the backbone. The impact of the backbone model architecture and its transferability is under-explored. A high-quality condensed dataset is expected to be used for training models with not only the specific one used for condensation but also various architectures. To answer this question, we evaluate the transferability performance for 5 representative GNN models (_SGC_, _GCN_, _GraphSAGE_, _APPNP_, and _ChebyNet_) and 2 non-GNN models (the popular _Graph Transformer_) and simple _MLP_). We also investigated the performance variation of different backbones with the number of training steps. The evaluation results are shown in Sec. 3.4 and Appendix B.4.

**RQ5: How does the initialization mechanism affect the performance of graph condensation?**

**Motivation and Experiment Design.** The initialization mechanism of the condensed dataset is crucial for convergence and performance in image dataset condensation but remains unexplored for irregular graph data. To answer this question, we adopt 5 distinct initialization strategies (_Random Noise_, _Random Sample_, _Center_, _K-Center_, and _K-Means_) to evaluate their impact on condensation performance and converge speed. The results are shown in Sec. 3.5 and Appendix B.5.

**RQ6: How efficient are these GC methods in terms of time and space?**

**Motivation and Experiment Design.** As the GC methods aim to achieve comparable performance on the condensed dataset and the original dataset, they always rely on the training process on the original datasets. The efficiency and scalability of GC methods are overlooked by existing methods, which is crucial in practice since the original intent of GC is to reduce computation and storage costs for large graphs. To answer this question, we evaluate the time and memory consumption of these GC methods. Specifically, we record the overall time when achieving the best result, the peak CPU memory, and the peak GPU memory. The results are shown in Sec. 3.6 and Appendix B.6.

### Discussion on Existing Benchmarks

To the best of our knowledge, GC-Bench is the first comprehensive benchmark for both node-level and graph-level graph condensation. There are a few image dataset condensation benchmark works for image classification task  and condensation adversarial robustness . A recent work GCondenser  evaluates some node-level GC methods for node classification on homogeneous graphs with limited evaluation dimensions in terms of performance and time efficiency. Our GC-Bench analyzes more GC methods on a wider variety of datasets (both homogeneous and heterogeneous) and tasks (node classification, graph classification), encompassing both node-level and graph-level methods. In addition to performance and efficiency analysis, we further explore the transferability across different tasks (link prediction, node clustering, anomaly detection) and backbones. With GC-Bench covering more in-depth investigation over a wider scope, we believe it will provide valuable insights into existing works and future directions. A comprehensive comparison with GCondenser can be found in Appendix A.5.

[MISSING_PAGE_FAIL:5]

poorly with _GCN_. This is because _KiDD_ does not rely on the backbone and depends solely on the structure. Consequently, the stronger the downstream model's expressive ability, the better the results.

From both node-level and graph-level results, we observe that as the condensation ratio increases, traditional core-set methods improve, narrowing the performance gap with deep methods. However, deep GC methods show a saturation point or even a decline in performance beyond a certain threshold, suggesting that larger condensed data may introduce noise and biases that degrade performance.

**Key Takeaways 1:** Current node-level GC methods can achieve nearly lossless condensation performance. However, there is still a significant gap between graph-level GC and whole dataset training, indicating there is substantial room for improvement.

**Key Takeaways 2:** A large condensation ratio does not necessarily lead to better performance with current methods.

### Structure in Graph Condensation (RQ2)

We analyze the impact of structure in terms of heterogeneity and heterophily. Experimental settings and additional results can be found in Appendix B.2.

(1) _Heterogeneity v.s. Homogeneity._ For the heterogeneous datasets _ACM_ and _DBLP_, we convert the heterogeneous graphs into homogeneous ones for evaluation. From the results in Table 2, we observe that GC methods designed for homogeneous graphs preserve most of the semantic information and perform comparably to models training on the whole dataset.

(2) _Heterophily v.s. Homophily._ From the results of the heterophilous dataset _Flickr_ (with homophily ratio \(=0.24\)) in Table 2, we can observe that current GC methods can achieve almost the same accuracy as models training on the whole dataset. However, there is still a significant gap compared to the state-of-the-art results of the model designed for heterophilic graphs.

    &  **Graph** \\ **/Cls** \\  } &  **Ratio(\(r\))** \\  } &  &  &  &  &  \\   & & & **Random** & **Herring K-Center** & **DosCond** & **KiDD** & **Mirage** & **Dataset** \\   _NCI1_ \\ Acc. (\%) \\  } & 1 & 0.06\% & 50.90\({}_{ 0.20}\) & 51.90\({}_{ 1.60}\) & 51.90\({}_{ 1.60}\) & 49.20\({}_{ 1.10}\) & **61.40\({}_{ 0.60}\)** & 50.80\({}_{ 2.20}\) & \)} & \)} \\  & 5 & 0.24\% & 52.10\({}_{ 1.30}\) & 60.50\({}_{ 1.40}\) & 47.00\({}_{ 1.10}\) & 51.10\({}_{ 0.80}\) & **63.20\({}_{ 2.00}\)** & 51.30\({}_{ 1.10}\) \\  & 10 & 0.49\% & 55.60\({}_{ 1.00}\) & 61.80\({}_{ 1.60}\) & 49.40\({}_{ 1.50}\) & 50.30\({}_{ 1.30}\) & **64.20\({}_{ 1.00}\)** & 51.70\({}_{ 1.40}\) & \(80.0_{ 1.8}\) \\  & 20 & 0.97\% & 58.70\({}_{ 1.40}\) & 60.90\({}_{ 1.50}\) & 55.20\({}_{ 1.60}\) & 50.30\({}_{ 1.30}\) & **66.90\({}_{ 0.70}\)** & 52.10\({}_{ 2.20}\) & \\  & 50 & 2.43\% & 61.10\({}_{ 1.20}\) & 50.90\({}_{ 1.50}\) & 62.70\({}_{ 1.50}\) & 50.30\({}_{ 1.30}\) & **65.40\({}_{ 0.60}\)** & 52.40\({}_{ 2.70}\) & \\   _DD_ \\ Acc. (\%) \\  } & 1 & 0.21\% & 49.70\({}_{ 1.30}\) & 58.80\({}_{ 1.60}\) & 58.80\({}_{ 1.60}\) & 46.30\({}_{ 8.50}\) & 71.30\({}_{ 1.70}\) & **74.00\({}_{ 0.00}\)** & \\  & 5 & 1.06\% & 480.80\({}_{ 1.40}\) & 58.70\({}_{ 1.50}\) & 51.30\({}_{ 1.30}\) & 45.70\({}_{ 1.50}\) & - & 70.1\({}_{ 2.2}\) \\  & 10 & 2.12\% & 63.10\({}_{ 1.50}\) & 64.10\({}_{ 1.50}\) & 53.40\({}_{ 1.30}\) & 46.30\({}_{ 8.50}\) & **71.50\({}_{ 0.40}\)** & - & 70.1\({}_{ 2.2}\) \\  & 20 & 4.25\% & 56.40\({}_{ 1.30}\) & 67.00\({}_{ 2.00}\) & 58.50\({}_{ 5.70}\) & **70.00\({}_{ 0.00}\)** & **71.20\({}_{ 0.00}\)** & - & \\  & 50 & 10.62\% & 58.90\({}_{ 1.40}\) & 58.60\({}_{ 1.40}\) & 62.30\({}_{ 1.30}\) & 44.00\({}_{ 0.70}\) & **71.20\({}_{ 0.00}\)** & - & \\   _ogbg-moliance_ \\ ROC-AUC \\  } & 1 & 0.17\% & 0.468\({}_{ 0.45}\) & 0.486\({}_{ 0.03}\) & 0.486\({}_{ 0.03}\) & 0.512\({}_{ 0.02}\) & **0.706\({}_{ 0.00}\)** & 0.590\({}_{ 0.00}\) & \\  & 5 & 0.83\% & 31.21\({}_{ 0.19}\) & 0.470\({}_{ 0.02}\) & 0.553\({}_{ 0.24}\) & 0.555\({}_{ 0.09}\) & **0.562\({}_{ 0.00}\)** & 0.419\({}_{ 0.10}\) & \\  & 10 & 1.65\% & 0.442\({}_{ 0.28}\) & 0.532\({}_{ 0.01}\) & 0.594\({}_{ 0.19}\) & 0.536\({}_{ 0.72}\) & **0.590\({}_{ 0.94}\)** & 0.419\({}_{ 0.10}\) & 0.763\({}_{ 0.20}\) \\  & 20 & 3.31\% & 0.510\({}_{ 0.20}\) & 0.509\({}_{ 0.02}\) & 0.512\({}_{ 0.02}\) & 0.484\({}_{ 0.08}\) & **0.540\({}_{ 0.01}\)** & 0.423\({}_{ 0.01}\) & 0.

**Key Takeaways 3:** Existing GC methods primarily address simple graph data. However, the conversion process to specific data types is non-trivial, leaving significant room for improvement in preserving complex structural properties.

### Transferability on Different Tasks (RQ3)

To evaluate the transferability of GC methods, we condense the dataset by node classification (NC) and use the condensed dataset to train models for link prediction (LP), node clustering (NCIu), and anomaly detection (AD) tasks. The results on _Citeseer_ are shown in Figure 2. Settings and additional results can be found in Appendix B.3.

As shown in Figure 2, performance with condensed datasets was significantly lower compared to original datasets in all transferred tasks. This decline may be due to the task-specific nature of the condensation process, which retains only task-relevant information while ignoring other semantically rich details. For instance, AD task prioritizes high-frequency graph signals more than NC and LP tasks, leading to poor performance when transferring condensed datasets from NC to AD tasks. Among the methods, gradient matching methods (_GCond_, _DosCond_, and _SGD_) demonstrated better transferability in downstream tasks. In contrast, while structure-free methods (_SFGC_ and _GEOM_) perform well in node classification (Section 3.1), they show a significant performance gap in AD tasks compared to gradient matching methods.

**Key Takeaways 4**: All condensed datasets struggle to perform well outside the context of the specific tasks for which they were condensed, leading to limited applicability.

### Transferability of Backbone Model Architectures (RQ4)

We adopt one model (_SGC_ or Graph Transformer) as the backbone for condensation and use the various models in downstream tasks evaluation. Details and additional results are in Appendix B.4.

As shown in Figure 3(a) and 3(b), each column shows the generalization performance of a condensed graph generated by different methods for various downstream models. We can observe that datasets condensed with _SGC_ generally maintain performance when transferred across models. However, datasets condensed with _Graph Transformer_ (_GTrans_) consistently underperform across various methods, and other models also exhibit reduced performance when adapted to _Graph Transformer_. Intuitively, _SGC_'s basic neighbor message-passing strategy may overlook global dependencies critical to more complex models, and similarly, complex models may not perform well when adapted to simpler models. As we can observe, _DosCond_ exhibits generally better transferability compared to other gradient-matching methods. Since it can be regarded as the one-step gradient matching variant of _GCond_, we further test the impact of gradient matching steps on transferability (Figure 3(c)). Increasing the number of matching steps was found to correlate with reduced performance across architectures, indicating that extensive gradient matching may encode model-specific biases.

Figure 2: **Cross-task performance on _Citeseer_. For all downstream tasks, the models are trained solely using data of graphs condensed by node classification. For anomaly detection (c, d), structural and contextual anomalies  are injected into both the condensed graph and the original graph.**

**Key Takeaways 5:** Current GC methods exhibit significant performance variability when transferred to different backbone architectures. Involving the entire training process potentially may lead to encoding backbone-specific details in the condensed datasets.

**Key Takeaways 6:** Despite their strong performance in general graph learning tasks, transformers surprisingly yield suboptimal results in graph condensation.

### Initialization Impact (RQ5)

We evaluate 5 distinct initialization strategies, namely: _Random Noise_, _Random Sample_, _Center_, _K-Center_, and _K-Means_. The results of _Gcond_ on _Cora_ and _ogbn-arxiv_ are shown in Figure 4. Detailed settings and additional results can be found in Appendix B.5.

As shown in Figure 4(a) and Figure 4(b), the choice of the initialization method can significantly influence the efficiency of the condensation process but with little impact on the final accuracy. For instance, using _Center_ on _Cora_ reduces the average time to reach the same accuracy by approximately 25% compared to _Random Sample_ and 71% compared to _Random Noise_. However, this speed advantage diminishes as the scale of the condensed graph increases. Additionally, different datasets have their preferred initialization methods for optimal performance. For example, _Center_ is generally faster for _Cora_ condensed by _Gcond_ while _K-Means_ performs better on _ogbn-arxiv_.

**Key Takeaways 7:** Different datasets have their preferred initialization methods for optimal performance even for the same GC method.

**Key Takeaways 8:** The initialization mechanism primarily affects the convergence speed with little impact on the final performance. The smaller the condensed graph, the greater the influence of different initialization strategies on the convergence speed.

Figure 4: **The impact of initialization** under different condensation ratios (a, b) and the impact across different datasets _Cora_ (a, b) and _ogbn-arxiv_ (c).

Figure 3: **Cross-architecture performance.** Using _SGC_ and Graph Transformer (_GTrans_) to condense _Cora_ with a 2.6% ratio, we then test the accuracy on various downstream architectures (a, b). Furthermore, we evaluate the influence of gradient matching steps on _Gcond_ (c).

### Efficiency and Scalability (RQ6)

In this subsection, we evaluate the condensation time and memory consumption of GC methods. The results on _ogbn-arxiv_ are shown in Figure 5, where the \(x\)-axis denotes the overall condensation time (min) when achieving the best validation performance, the \(y\)-axis denotes the test accuracy (%), the inner size of the marker represents the peak CPU memory usage (MB), while the outer size represents the peak GPU memory usage (MB). As we can observe, the gradient matching methods have higher time and space consumption compared to other types of methods. However, Table 2 shows that current gradient and distribution matching GC methods may trigger OOM (Out of Memory) errors on large datasets with high condensation ratios, making them unsuitable for large-scale scenarios, which contradicts the goal of applying graph condensation to extremely large graphs. More detailed results in Appendix B.6.

**Key Takeaways 9**: GC methods that rely on backbones and full-scale data training have large time and space consumption.

## 4 Future Directions

Notwithstanding the promising results, there are some directions worthy to explore in the future:

**Theory of optimal condensation.** According to our findings, GC methods are striving to achieve better performance with smaller condensed dataset sizes but it's not necessarily true that larger compressed datasets lead to better results. How to trade off between dataset size, information condensation, and information preservation, and whether there exists a theory of Pareto-optimal condensation in the graph condensation process, are future research directions.

**Condensation for more complex graph data.** Current GC methods are predominantly tailored to the simplest types of graphs, overlooking the diversity of graph structures such as heterogeneous graphs, directed graphs, hypergraphs, signed graphs, dynamic graphs, text-rich graphs, etc. There is a pressing need for research on graph condensation methods that cater to more complex graph data.

**Task-Agnostic graph condensation.** Task-agnostic GC methods could greatly enhance flexibility and utilization in graph data analysis, promoting versatility across various domains. Current methods often depend on downstream labels or task-specific training. Future research should focus on developing task-agnostic, unsupervised, or self-supervised GC methods that preserve crucial structural and semantic information independently of specific tasks or datasets.

**Improving the efficiency and scalability of graph condensation methods.** Efficient and scalable GC methods are crucial yet challenging to design. Most current methods combine condensation with full training, making them resource-heavy and less scalable. Decoupling these processes could significantly enhance GC's efficiency and scalability, broadening its use across various domains.

## 5 Conclusion and Future Works

This paper introduces a comprehensive graph condensation benchmark, GC-Bench, by integrating and comparing 12 methods across 12 datasets covering varying types and scopes. We conduct extensive experiments to reveal the performance of GC methods in terms of effectiveness, transferability, and efficiency. We implement an library (https://github.com/RingBDStack/GC-Bench) that incorporates all the aforementioned protocols, baseline methods, datasets, and scripts to reproduce the results in this paper. The GC-Bench library offers a comprehensive and unbiased platform for evaluating current methods and facilitating future research. In this study, we mainly evaluate the performance of GC methods for the node classification and graph classification task, which is widely adopted in the previous literature. In the future, we plan to extend the GC-Bench with broader coverage of datasets and tasks, providing further exploration of the generalization ability of GC methods. We will update the benchmark regularly to reflect the most recent progress in GC methods.