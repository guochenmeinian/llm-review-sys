# Optimal Preconditioning and Fisher Adaptive Langevin Sampling

Michalis K. Titsias

Google DeepMind

mtitsias@google.com

###### Abstract

We define an optimal preconditioning for the Langevin diffusion by analytically optimizing the expected squared jumped distance. This yields as the optimal preconditioning an inverse Fisher information covariance matrix, where the covariance matrix is computed as the outer product of log target gradients averaged under the target. We apply this result to the Metropolis adjusted Langevin algorithm (MALA) and derive a computationally efficient adaptive MCMC scheme that learns the preconditioning from the history of gradients produced as the algorithm runs. We show in several experiments that the proposed algorithm is very robust in high dimensions and significantly outperforms other methods, including a closely related adaptive MALA scheme that learns the preconditioning with standard adaptive MCMC as well as the position-dependent Riemannian manifold MALA sampler.

## 1 Introduction

Markov chain Monte Carlo (MCMC) is a general framework for simulating from arbitrarily complex distributions, and it has shown to be useful for statistical inference in a wide range of problems . The main idea of an MCMC algorithm is quite simple. Given a complex target \((x)\), a Markov chain is constructed using a \(\)-invariant transition kernel that allows to simulate dependent realizations \(x_{1},x_{2},\) that eventually converge to samples from \(\). These samples can be used for Monte Carlo integration by forming ergodic averages. A general way to define \(\)-invariant transition kernels is the Metropolis-Hastings accept-reject mechanism in which the chain moves from state \(x_{n}\) to the next state \(x_{n+1}\) by first generating a candidate state \(y_{n}\) from a proposal distribution \(q(y_{n}|x_{n})\) and then it sets \(x_{n+1}=y_{n}\) with probability \((x_{n},y_{n})\):

\[(x_{n},y_{n})=(1,a_{n}),\;\;a_{n}=)}{(x_{n} )}|y_{n})}{q(y_{n}|x_{n})},\] (1)

or otherwise rejects \(y_{n}\) and sets \(x_{n+1}=x_{n}\). The choice of the proposal distribution \(q(y_{n}|x_{n})\) is crucial because it determines the mixing of the chain, i.e. the dependence of samples across time. For example, a "slowly mixing" chain even after convergence may not be useful for Monte Carlo integration since it will output a highly dependent set of samples producing ergodic estimates of very high variance. Different ways of defining \(q(y_{n}|x_{n})\) lead to common algorithms such as random walk Metropolis (RWM), Metropolis-adjusted Langevin algorithm (MALA)  and Hamiltonian Monte Carlo (HMC) . Within each class of these algorithms adaptation of parameters of the proposal distribution, such as a step size, is also important and this has been widely studied in the literature by producing optimal scaling results , and also by developing adaptive MCMC algorithms . The standard adaptive MCMC procedure in  uses the history of the chain to recursively compute an empirical covariance of the target \(\) and build a multivariate Gaussian proposal distribution. However, this type of covariance adaptation can be too slow and not so robust in high dimensional settings .

In this paper, we derive a fast and very robust adaptive MCMC technique in high dimensions that learns a preconditioning matrix for the MALA method, which is the standard gradient-based MCMC algorithm obtained by a first-order discretization of the continuous-time Langevin diffusion. Our first contribution is to define an optimal preconditioning by analytically optimizing a criterion on the Langevin diffusion. The criterion is the well-known expected squared jumped distance  which at optimum yields as a preconditioner the inverse matrix \(^{-1}\) of the following Fisher information covariance matrix \(=_{(x)}[(x)(x)^{}]\). This contradicts the common belief in adaptive MCMC that the covariance of \(\) is the best preconditioner. While this is a surprising result we show that \(^{-1}\) connects with a certain quantity appearing in optimal scaling of RWM [34; 36].

Having recognized \(^{-1}\) as the optimal preconditioning we derive an easy to implement and computationally efficient adaptive MCMC algorithm that learns from the history of gradients produced as MALA runs. This method sequentially updates an empirical inverse Fisher estimate \(}_{n}^{-1}\) using a recursion having quadratic cost \(O(d^{2})\) (\(d\) is the dimension of \(x\)) per iteration. In practice, since for sampling we need a square root matrix of \(}_{n}^{-1}\) we implement the recursions over a square root matrix by adopting classical results from Kalman filtering [31; 10]. We compare our method against MALA that learns the preconditioning with standard adaptive MCMC , a position-dependent Riemannian manifold MALA  as well as simple MALA (without preconditioning) and HMC. In several experiments we show that the proposed algorithm significantly outperforms all other methods.

## 2 Background

We consider an intractable target distribution \((x)\) with \(x^{d}\), known up to some normalizing constant, and we assume that \((x):=_{x}(x)\) is well defined. A continuous time process with stationary distribution \(\) is the overdamped Langevin diffusion

\[dx_{t}=A(x_{t})dt+dB_{t},\] (2)

where \(B_{t}\) denotes \(d\)-dimensional Brownian motion. This is a stochastic differential equation (SDE) that generates sample paths such that for large \(t\), \(x_{t}\). We also incorporate a _preconditioning matrix_\(A\), which is a symmetric positive definite covariance matrix, while \(\) is such that \(^{}=A\).

Simulating from the SDE in (2) is intractable and the standard approach is to use a first-order Euler-Maruyama discretization combined with a Metropolis-Hastings adjustment. This leads to the so called preconditioned _Metropolis-adjusted Langevin algorithm_ (MALA) where at each iteration given the current state \(x_{n}\) (where \(n=1,2,\)) we sample \(y_{n}\) from the proposal distribution

\[q(y_{n}|x_{n})=(y_{n}|x_{n}+}{2}A(x_ {n}),^{2}A),\] (3)

where the step size \(^{2}>0\) appears due to time discretization. We accept \(y_{n}\) with probability \((x_{n},y_{n})=(1,a_{n})\) where \(a_{n}\) follows the form in (1). The obvious way to compute \(a_{n}\) is

\[a_{n}=)}{(x_{n})}|y_{n})}{q(y_{n}|x_{n})}= )}{(x_{n})}}||x_{n}-y_{n}- }{2}A(y_{n})||_{A^{-1}}^{2}\}}{\{-}||y_{n}-x_{n}-}{2}A(x_{n})||_{A^{-1} }^{2}\}},\]

where \(||z||_{A^{-1}}^{2}=z^{}A^{-1}z\). However, in some cases that involve high dimensional targets, this can be costly since in the ratio of proposal densities both the preconditioning matrix \(A\) and its inverse \(A^{-1}\) appear. In turns out that we can avoid \(A^{-1}\) and simplify the computation as stated below.

**Proposition 1**.: _For preconditioned MALA with proposal density given by (3) the ratio of proposals in the M-H acceptance probability can be written as_

\[|y_{n})}{q(y_{n}|x_{n})}=\{h(x_{n},y_{n})-h(y_{n},x_{n})\}, \;\;\;h(z,v)=(z\!-\!v-\!}{4}A(v) )^{}\!\!(v).\]

This expression does not depend on the inverse \(A^{-1}\), and this leads to computational gains and simplified implementation that we exploit in the adaptive MCMC algorithm presented in Section 4.

The motivation behind the use of preconditioned MALA is that with a suitable preconditioner \(A\) the mixing of the chain can be drastically improved, especially for very anisotropic target distributions.

A very general way to specify \(A\) is by applying an adaptive MCMC algorithm, which learns \(A\) online. To design such an algorithm it is useful to first specify a notion of optimality. A common argument in the literature, that is used for both RWM and MALA, is that a suitable \(A\) is the unknown covariance matrix \(\) of the target \(\). This means that we should learn \(A\) so that to approximate \(\). However, this argument is rather heuristic since it is not based on an optimality criterion. One of our contributions is to specify an optimal \(A^{*}\) based on an optimization procedure, that we describe in Section 3. This \(A^{*}\) will turn out to be not the covariance matrix of the target but an inverse Fisher information matrix.

## 3 Optimal preconditioning using expected squared jumped distance

Preconditioning aims to improve sampling when different directions (or individual variables \(x_{i}\)) in the state space can have different scalings under the target \(\). Here, we develop a method for selecting the preconditioning through the optimization of an objective function. This method uses the observation that an effective preconditioning correlates with large values of the global step size \(^{2}\) in MALA, i.e. \(^{2}\) is allowed to increase when preconditioning becomes effective as shown in the sampling efficiency scores in Table 1 and the corresponding estimated step sizes reported in Appendix E.1.

In our analysis we consider the rejection-free or unadjusted Langevin sampler where we discretize the time continuous Langevin diffusion in (2) with a small finite \(:=^{2}>0\) so that

\[x_{t+}-x_{t}=A(x_{t})+(B_{t+ }-B_{t}),\ \ \ \ B_{t+}-B_{t}(0, I).\] (4)

We will use the expected squared jumped distance \(J(,A)=[||x_{t+}-x_{t}||^{2}]\) computed as follows.

**Proposition 2**.: _If \(x_{t}(x_{t})\) the vector \(x_{t+}-x_{t}\) defined by (4) has zero mean and covariance_

\[[(x_{t+}-x_{t})(x_{t+}-x_{t})^{}]=}{ 4}A_{(x_{t})}[(x_{t})(x_{t})^{ }]A+ A.\] (5)

_Further, \(([(x_{t+}-x_{t})(x_{t+}-x_{t})^{}] )=[((x_{t+}-x_{t})(x_{t+}-x_{t})^{ })]=[||x_{t+}-x_{t}||^{2}]\), which shows that \(J(,A)\) is the trace of the covariance matrix in (5)._

To control discretization error we impose an upper bound constraint \(J(,A)\) for a small \(>0\). A preconditioning that "symmetrizes" the target can be obtained by maximizing the discretization step size \(\) subject to \(J(,A)\). Since \(J(,A)\) monotonically increases with \(\), the maximum \(^{*}\) satisfies \(_{A}J(^{*},A)=\). This means that the _optimal_ preconditioning \(A^{*}\) is obtained by minimizing \(J(,A)\) under some global scale constraint on \(A\), as stated next.

**Proposition 3**.: _Suppose \(A\) is a symmetric positive definite matrix satisfying \((A)=c\), with \(c>0\) a constant. Then the objective \(J(,A)\), for any \(>0\), is minimized for \(A^{*}\) given by_

\[A^{*}=k^{-1},\ \ k=^{d}}},\ \ \ =_{(x)}[(x)(x)^{} ],\] (6)

_where \(_{i}\)s are the eigenvalues of \(\) assumed to satisfy \(0<_{i}<\)._

The positive multiplicative scalar \(k\) in (6) is not important since the specific value \(c>0\) is arbitrary, e.g. if we choose \(c=_{i=1}^{d}}\) then \(k=1\) and \(A^{*}=^{-1}\). In other words, what matters is that the optimal \(A^{*}\) is proportional to the inverse matrix \(^{-1}\), so it follows the curvature of \(^{-1}\). For a multivariate Gaussian \((x)=(x|,)\) it holds \(^{-1}=\), so the optimal preconditioner coincides with the covariance matrix of \(x\). More generally though, for non-Gaussian targets this will not hold.

Connection with classical Fisher information matrix.The matrix \(\) is positive definite since it is the covariance of the gradient \((x):=_{x}(x)\) where \(_{(x)}[(x)]=0\). Also, \(\) is similar to the classical Fisher information matrix. To illustrate some differences suppose that the target \((x)\) is a Bayesian posterior \((|Y) p(Y|)p()=p(Y,)\) where \(Y\) are the observations and \(:=x\) are the random parameters. The classical Fisher information is a _frequentist_ quantity where we fix some parameters \(\) and compute \(G()=_{p(Y|)}[_{} p(Y|)_{ } p(Y|)^{}]\) by averaging over data. In contrast, \(=_{p(|Y)}[_{} p(Y,)_{ } p(Y,)^{}]\) is more like a _Bayesian_ quantity where we fix the data \(Y\) and average over the parameters \(\). Importantly, \(\) is not a function of \(\) while \(G()\) is. Similarly to the classical Fisher information, \(\) also satisfies the following standard property: Given that \((x)\) is twice differentiable and \(_{x}^{2}(x)\) is the Hessian matrix, \(\) from (6) is also written as \(=-_{(x)}[_{x}^{2}(x)]\). Next, we refer to \(\) as the Fisher matrix.

Connection with optimal scaling.The Fisher matrix \(\) connects also with the optimal scaling result for the RWM algorithm [34; 36]. Specifically, for targets of the form \((x)=_{i=1}^{d}f(x_{i})\), the RWM proposal \(q(y_{n}|x_{n})=(y_{n}|x_{n},(^{2}/d)I_{d})\) and as \(d\) the optimal parameter \(^{2}\) is \(^{2}=\) where \(J=_{f(x)}[()^{2}]\) is the (univariate) Fisher information for the univariate density \(f(x)\), and the preconditioning involves as in our case the inverse Fisher \(^{-1}=I_{d}\). This result has been generalized also for heterogeneous targets in  where again the inverse Fisher information matrix (having now a more general diagonal form) appears as the optimal preconditioner.

## 4 Fisher information adaptive MALA

Armed with the previous optimality result, we wish to develop an adaptive MCMC algorithm to optimize the proposal in (3) by learning online the global variance \(^{2}\) and the preconditioner \(A\). For \(^{2}\) we follow the standard practice to tune this parameter in order to reach an average acceptance rate around \(0.574\) as suggested by optimal scaling results [35; 36]. For the matrix \(A\) we want to adapt it so that approximately it becomes proportional to the inverse Fisher \(^{-1}\) from (6). We also incorporate a parametrization that helps the adaptation of \(^{2}\) to be more independent from the one of \(A\). Specifically, we remove the global scale from \(A\) by defining the overall proposal as

\[q(y_{n}|x_{n})=(y_{n}|x_{n}+}{ (A)}A(x_{n}),}{ (A)}A),\] (7)

where \(^{2}\) is normalized by \((A)\), i.e. the average eigenvalue of \(A\). Another way to view this is that the effective preconditioner is \(A/((A))\) which has an average eigenvalue equal to one. The proposal in (7) is invariant to any scaling of \(A\), i.e. if \(A\) is replaced by \(kA\) (with \(k>0\)) the proposal remains the same. Also, note that when \(A\) is the identity matrix \(I_{d}\) (or a multiple of identity) then \((I_{d})=1\) and the above proposal reduces to standard MALA with isotropic step size \(^{2}\).

It is straightforward to adapt \(^{2}\) towards an average acceptance rate \(0.574\); see pseudocode in Algorithm 1. Thus our main focus next is to describe the learning update for \(A\), in fact eventually not for \(A\) itself but for a square root matrix\(\) which is what we need to sample from the proposal in (7).

To start with, let us simplify notation by writing the score function at the \(n\)-th MCMC iteration as \(s_{n}:=_{x_{n}}(x_{n})\). We introduce the \(n\)-sample empirical Fisher estimate

\[}_{n}=_{i=1}^{n}s_{i}s_{i}^{}+ I_{d},\] (8)

where \(>0\) is a fixed damping parameter. Given that certain conditions apply [21; 38] so that the chain converges and ergodic averages converge to exact expected values, \(}_{n}\) is a consistent estimator satisfying \(_{n}}_{n}=\) since as \(n\) the damping part \(I_{d}\) vanishes. Including the damping is very important since it offers a Tikhonov-like regularization, similar to ridge regression, and it ensures that for any finite \(n\) the eigenvalues of \(}_{n}\) are strictly positive. An estimate then for the preconditioner \(A_{n}\) can be set to be proportional to the inverse of the empirical Fisher \(}_{n}\), i.e.

\[A_{n}(_{i=1}^{n}s_{i}s_{i}^{}+ I_{d})^{-1}=n(_{i=1}^{n}s_{i}s_{i}^{}+  I_{d})^{-1}.\] (9)

Since any positive multiplicative scalar in front of \(A_{n}\) plays no role, we can ignore the scalar \(n\) and define \(A_{n}=(_{i=1}^{n}s_{i}s_{i}^{}+ I_{d})^{-1}\). Then, as MCMC iterates we can adapt \(A_{n}\) in \(O(d^{2})\) cost per iteration based on the recursion

\[\;A_{1}=(s_{1}s_{1}^{}+ I_{ d})^{-1}=(I_{d}-s_{1}^{}}{ +s_{1}^{}s_{1}}),\] (10) \[\;A_{n}=(A_{n-1}^{-1}+s_{n}s_{n}^{} )^{-1}=A_{n-1}-s_{n}s_{n}^{}A_{n-1}}{1+s_{n}^{}A_{n- 1}s_{n}},\] (11)

where we applied Woodbury matrix identity. This estimation in the limit can give the optimal preconditioning in the sense that under the ergodicity assumption, \(_{n}}{(A_{n})}=^{-1}}{(^{-1})}\). Inpractice we do not need to compute directly the matrix \(A_{n}\) but a square root matrix \(R_{n}:=}\), such that \(R_{n}R_{n}^{}=A_{n}\), since we need a square root matrix to draw samples from the proposal in (7). To express the corresponding recursion for \(R_{n}\) we will rely on a technique that dates back to the early days of Kalman filtering [31; 10], which applied to our case gives the following result.

**Proposition 4**.: _A square root matrix \(R_{n}\), such that \(R_{n}R_{n}^{}=A_{n}\), can be computed recursively in \(O(d^{2})\) time per iteration as follows:_

\[R_{1}=}(I_{d}-r_{1} s_{1}^{}}{+s_{1}^{}s_{1}}),\ r_{1}=^{}s_{1}}}}\] (12) \[R_{n}=R_{n-1}-r_{n}_{n}) _{n}^{}}{1+_{n}^{}_{n}},\ \ _{n}=R_{n-1}^{}s_{n},\ r_{n}=^{} _{n}}}}.\] (13)

A way to generalize the above recursive estimation of a square root for the inverse Fisher matrix is to consider the stochastic approximation framework . This requires to write an online learning update for the empirical Fisher of the form

\[}_{n}=}_{n-1}+_{n}(s_{n}s_{n}^{}- }_{n-1}),\ \ \ }_{1}=s_{1}s_{1}^{}+ I_{d},\] (14)

where the learning rates \(_{n}\) satisfy the standard conditions \(_{n=1}^{}_{n}=,_{n=1}^{}_{n}^{2}<\). Then, it is straightforward to generalize the recursion for the square root matrix in Proposition 4 to account for this more general case; see Appendix B. The recursion in Proposition 4 is a special case when \(_{n}=\). In our simulations we did not observe significant improvement by using more general learning rate sequences, and therefore in all our experiments in Section 5 we use the _standard_ learning rate \(_{n}=\). Note that this learning rate is also used by other adaptive MCMC methods .

An adaptive algorithm that learns online from the score function vectors \(s_{n}\) can work well in some cases, but still it can be unstable in general. One reason is that \(s_{n}=(x_{n})\) will not have zero expectation when the chain is transient and states \(x_{n}\) are not yet draws from the stationary distribution \(\). To analyze this, note that the learning signal \(s_{n}\) enters in the empirical Fisher estimator \(}_{n}\) through the outer product \(s_{n}s_{n}^{}\) as shown by Eqs. (8) and (14). However, in the transient phase \(s_{n}s_{n}^{}\) will be biased since the expectation \([s_{n}s_{n}^{}]=[(s_{n}-[s_{n}])(s_{n}- [s_{n}])^{}]+[s_{n}][s_{n}]^{} \), where the expectations are taken under the marginal distribution of the chain at time \(n\). In practice the mean vector \([s_{n}]\) can take large absolute values, which can introduce significant bias through the additive term \([s_{n}][s_{n}]^{}\). Thus, to reduce some bias we could track the empirical mean \(_{n}=_{i=1}^{n}s_{i}\) and center the signal \(s_{n}-_{n}\) so that the Fisher matrix is estimated by the empirical covariance \(_{i=1}^{n}(s_{i}-_{n})(s_{i}-_{n})^{}\). The recursive estimation becomes similar to standard adaptive MCMC  where we recursively propagate an online empirical estimate for the mean of \(s_{n}\) and incorporate it into the online empirical estimate of the covariance matrix (in our case the inverse Fisher matrix); see Eq. (17) in Section 5 for the standard adaptive MCMC recursion  and Appendix C for our Fisher method. While this can make learning quite stable we experimentally discovered that there is another scheme, presented next in Section 4.1, that is significantly better and stable especially for very anisotropic high dimensional targets; see detailed results in Appendix E.3.

### Adapting to score function increments

An MCMC algorithm updates at each iteration its state according to \(x_{n+1}=x_{n}+(u_{n}<(x_{n},y_{n}))(y_{n}-x_{n})\) where \((x_{n},y_{n})\) is the M-H probability, \(u_{n} U(0,1)\) is an uniform random number and \(()\) is the indicator function. This sets \(x_{n+1}\) to either the proposal \(y_{n}\) or the previous state \(x_{n}\) based on the binary value \((u_{n}<(x_{n},y_{n}))\). Similarly, we can consider the update of the score function \(s(x)=(x)\) and conveniently re-arrange it as an increment,

\[s_{n}^{}=s(x_{n+1})-s(x_{n})=(u_{n}<(x_{n},y_{n}))(s(y_{n} )-s(x_{n})).\] (15)

While both \(s_{n}\) and \(s_{n}^{}\) have zero expectation when \(x_{n}\) is from stationarity, i.e. \(x_{n}\), the increment \(s_{n}^{}\) (unlike \(s_{n}\)) tends in practice to be more centered and close to zero even when the chain is transient, e.g. note that \(s_{n}^{}\) is zero when \(y_{n}\) is rejected. Further, since the difference \(s_{n}^{}=s(x_{n+1})-s(x_{n})\) conveys information about the covariance of the score function we can use it in the recursion of Proposition 4 to learn the preconditioner \(A\), where we simply replace \(s_{n}\) by \(s_{n}^{}\). As shown in the experiments this leads to a remarkably fast and effective adaptation of the inverse Fisher matrix \(^{-1}\) without observable bias, or at least no observable for Gaussian targets where the true \(^{-1}\) is known. We can further apply Rao-Blackwellization to reduce some variance of \(s_{n}^{}\). Since \(s_{n}^{}\) enters into the estimation of the empirical Fisher, see Eq. (8) or (14), through the outer product \(s_{n}^{}(s_{n}^{})^{}=(u_{n}<(x_{n},y_{n}))(s(y _{n})-s(x_{n}))(s(y_{n})-s(x_{n}))^{}\) we can marginalize out the r.v. \(u_{n}\) which yields \(_{u_{n}}[s_{n}^{}(s_{n}^{})^{}]=(x_{n},y_{n})( s(y_{n})-s(x_{n}))(s(y_{n})-s(x_{n}))^{}\). After this Rao-Blackwellization an alternative vector to use for adaptation is

\[s_{n}^{}=,y_{n})}(s(y_{n})-s(x_{n})),\] (16)

which depends on the square root \(,y_{n})}\) of the M-H probability. As long as \((x_{n},y_{n})>0\), the learning signal in (16) depends on the proposed sample \(y_{n}\) even when it is rejected.

Finally, we can express the full algorithm for Fisher information adaptive MALA as outlined by Algorithm 1, which adapts by using the Rao-Blackwellized score function increments from Eq. (16). Note that, while Algorithm 1 uses \(s_{n}^{}\) from Eq. (16), the initial signal from Eq. (15) works equally well; see Appendix E.3. Also, the algorithm includes an initialization phase where simple MALA runs for few iterations to move away from the initial state, as discussed further in Section 5.

``` Input: Log target \((x)\); gradient \((x)\); \(>0\) (default \(=10\)); \(_{*}=0.574\)  Initialize \(x_{1}\) and \(^{2}\) by running simple MALA (i.e. with \((y|x+(^{2}/2)(x),^{2}I)\)) for \(n_{0}\) (default \(500\)) iterations where \(^{2}\) is adapted towards acceptance rate \(_{*}\)  Initialize square root matrix \(R=I_{d}\) and compute \(((x_{1}),(x_{1}))\)  Initialize \(_{R}^{2}=^{2}\) # placeholder for the normalized step size \(^{2}/(RR^{})\) for\(n=1,2,3,\)do : Propose \(y_{n}=x_{n}+(_{R}^{2}/2)R(R^{}(x_{n}))+_{R}R ,\ \ (0,I_{d})\) : Compute \(((y_{n}),(y_{n}))\) : Compute \((x_{n},y_{n})=(1,e^{(y_{n})+h(x_{n},y_{n})- (x_{n})-h(y_{n},x_{n})})\) by using Proposition 1 : Compute adaptation signal \(s_{n}^{}=,y_{n})}((y_{n})-( x_{n}))\) : Use \(s_{n}^{}\) to adapt \(R\) based on Proposition 4 (if \(n=1\) use (12) and if \(n>1\) use (13)) : Adapt step size \(^{2}^{2}[1+_{n}((x_{n},y_{n})-_{*})]\)# default const learning rate \(_{n}\!=\!0.015\) : Normalize step size \(_{R}^{2}=^{2}/(RR^{})\)#tr\((RR^{})=sum(R R)\) which is \(O(d^{2})\) : Accept/reject \(y_{n}\) with probability \((x_{n},y_{n})\) to obtain \((x_{n+1},(x_{n+1}),(x_{n+1}))\) endfor ```

**Algorithm 1** Fisher adaptive MALA (blue lines are ommitted when not adapting \((R,^{2})\))

## 5 Experiments

### Methods and experimental setup

We apply the Fisher information adaptive MALA algorithm (FisherMALA) to high dimensional problems and we compare it with the following other samplers. **(i)** The simple MALA sampler with proposal \((y_{n}|x_{n}+(^{2}/2)(x_{n}),^{2}I)\), which adapts only a step size \(^{2}\) without having a preconditioner. **(ii)** A preconditioned adaptive MALA (AdaMALA) where the proposal follows exactly the from in (7) but where the preconditioning matrix is learned using standard adaptive MCMC based on the well-known recursion from :

\[_{n}=_{n-1}+x_{n},\ _{n}= _{n-1}+(x_{n}-_{n-1})(x_{n}-_{n-1})^{},\] (17)

where the recursion is initialized at \(_{1}=x_{1}\) and \(_{2}=(x_{2}-_{1})(x_{2}-_{1})^{}+ I\), and \(>0\) is the damping parameter that plays the same role as in FisherMALA. **(iii)** The Riemannian manifold MALA (mMALA)  which uses position-dependent preconditioning matrix \(A(x)\). mMALA in high dimensions runs slower than other schemes since the computation of \(A(x)\) may involve second derivatives and requires matrix decomposition that costs \(O(d^{3})\) per iteration. **(iv)** Finally, we include in the comparison the Hamiltonian Monte Carlo (HMC) sampler with a fixed number of 10 leap frog steps and identity mass matrix. We leave the possibility to learn with our method a preconditioner in HMC for future work since this is more involved; see discussion at Section 7.

For all experiments and samplers we consider \(2 10^{4}\) burn-in iterations and \(2 10^{4}\) iterations for collecting samples. We set \(=10\) in FisherMALA and AdaMALA. Adaptation of the proposal distributions, i.e. the parameter \(^{2}\), the preconditioning or the step size of HMC, occurs only during burn-in and at collection of samples stage the proposal parameters are kept fixed. For all three MALA schemes the global step size \(^{2}\) is adapted to achieve an acceptance rate around \(0.574\) (see Algorithm 1) while the corresponding parameter for HMC is adapted towards \(0.651\) rate . In FisherMALA from the \(2 10^{4}\) burn-in iterations the first \(500\) iterations are used as the initialization phase in Algorithm 1 where samples are generated by just MALA with adaptable \(^{2}\). Thus, only the last \(1.95 10^{4}\) burn-in iterations are used to adapt the preconditioner. For AdaMALA this initialization scheme proved to be unstable and we used a more elaborate scheme, as described in Appendix D.

We compute effective sample size (ESS) scores for each method by using the \(2 10^{4}\) samples from the collection phase. We estimate ESS across each dimension of the state vector \(x\), and we report maximum, median and minimum values, by using the built-in method in TensorFlow Probability Python package. Also, we show visualizations that indicate sampling efficiency or effectiveness in estimating the preconditioner (when the ground truth preconditioner is known).

### Gaussian targets

We consider three examples of multivariate Gaussian targets of the form \((x)=(x|,)\), where the optimal preconditioner (up to any positive scaling) is the covariance matrix \(\) since the inverse Fisher is \(^{-1}=\). For such case the Riemannian manifold sampler mMALA  is the optimal MALA sampler since it uses precisely \(\) as the preconditioning. In contrast to mMALA which somehow has access to the ground-truth oracle, both FisherMALA and AdaMALA use adaptive recursive estimates of the preconditioner that should converge to the optimal \(\), and thus the question is which of them learns faster. To quantify this we compute the Frobenius norm \(||_{n}-||_{F}\) across adaptation iterations \(n\), where \(\) denotes the matrix normalized by the average trace, i.e. \(=B/((B)}{d})\), for either \(A_{n}\) given by FisherMALA or \(A_{n}:=_{n}\) given by AdaMALA and where \(\) is the optimal normalized preconditioner. The faster the Frobenius norm goes to zero the more effective is the corresponding adaptive scheme. For all three Gaussian targets the mean vector \(\) was taken to be the vector of ones and samplers were initialized by drawing from standard normal. The first example is a two-dimensional Gaussian target with covariance matrix \(=[1\ 0.995;0.995\ 1]\). Both FisherMALA and AdaMALA perform almost the same (FisherMALA has faster convergence) in this low dimensional example as shown by Frobenius norm in Figure 1a; see also Figure 5 in the Appendix for visualizations of the adapted preconditioners. The following two examples involve 100-dimensional targets.

Gaussian process correlated target.We consider a Gaussian process to construct a 100-dimensional Gaussian where the covariance matrix is obtained by a non-stationary covariance function comprising the product of linear and squared exponential kernels plus small white noise, i.e. \([]_{i,j}=s_{i}s_{j}\{--s_{j})^{2}}{0.09} \}+0.001_{i,j}\) where the scalar inputs \(s_{i}\) form a regular grid in the range \(\). Figure 1b shows the evolution of the Frobenius norms and panels d,c depict as \(100 100\) images the true covariance matrix and the preconditioner estimated by FisherMALA. For AdaMALA see Figure 6 in the Appendix. Clearly, FisherMALA learns much faster and achieves more accurate estimates of the optimal preconditioner. Further Table 1 shows that FisherMALA achieves significantly better ESS than AdaMALA and reaches the same performance with mMALA.

Inhomogeneous Gaussian target.In the last example we follow [28; 39] and we consider a Gaussian target with diagonal covariance matrix \(=(_{1}^{2},,_{100}^{2})\) where the standard deviation values \(_{i}\) take values in the grid \(\{0.01,0.02,,1\}\). This target is challenging because the different scaling across dimensions means that samplers with a single step size, i.e. without preconditioning, will adapt to the smallest dimension \(x\) of the state while the chain at the higher dimensions, such as \(x_{100}\), will be moving slowly exhibiting high autocorrelation. Note that FisherMALA and AdaMALA run without knowing that the optimal preconditioner is a diagonal matrix, i.e. they learn a full covariance matrix. Figure 2a shows the ESS scores for all 100 dimensions of \(x\) for four samplers (except mMALA which has the same performance with FisherMALA), where we can observe that only FisherMALA is able to achieve high ESS uniformly well across all dimensions. In contrast, MALA and HMC that use a single step size cannot achieve high sampling efficiency and their ESS for dimensions close to \(x_{100}\) drops significantly. The same holds for AdaMALA due to its inability to learn fast the preconditioner, as shown by the Frobenius norm values in Figure 1(c) and the estimated standard deviations in Figure 1(b). AdaMALA can eventually get very close to the optimal precondioner but it requires hundred of thousands of adaptive steps, while FisherMALA learns it with only few thousand steps.

### Bayesian logistic regression

We consider Bayesian logistic regression distributions of the form \((|Y,Z) p(Y|,Z)p()\) with data \((Y,Z)=\{y_{i},z_{i}\}_{i=1}^{m}\), where \(z_{i}^{d}\) is the input vector and \(y_{i}\) the binary label. The likelihood is \(p(Y|,Z)=_{i=1}^{m}(^{}z_{i})^{y_{i}}(1-( ^{}z_{i}))^{1-y_{i}}\), where \(^{d}\) are the random parameters assigned the prior \(p()=(|0,I_{d})\). We consider six binary classification datasets (Australian Credit, Heart, Pima Indian, Ripley, Germma Credit and Caravan) with a number of data ranging from \(n=250\) to \(n=5822\) and dimensionality of the \(\) ranging from \(3\) to \(87\). We also consider a much higher \(785\)-dimensional example on MNIST for classifying the digits \(5\) and \(6\), that has \(11339\) training examples. To make the inference problems more challenging, in the first six examples we do not standardize the inputs \(z_{i}\) which creates very anisotropic posteriors over \(\). For the MNIST data, which initially are grey-scale images in , we simply divide by the maximum pixel value, i.e. 255, to bring the images in \(\). In Table 1 we report the ESS for the low \(7\)-dimensional Pima Indians dataset, the medium \(87\)-dimensional Caravan dataset and the higher \(785\)-dimensional MNIST dataset, while the results for the remaining datasets are shown in Appendix E. Further, Figure 3 shows the evolution of the unnormalized log target density \(\{p(Y|,Z)p()\}\) for the best four samplers in

Figure 1: Panel (a) shows the Frobenius norm across burn-in iterations for the 2-D Gaussian and (b) for the GP target. The exact GP covariance matrix is shown in (c) and the estimated one by FisherMALA in (d).

Figure 3: The evolution of the log-target across iterations for the best four algorithms in Caravan dataset.

Figure 2: Results in the inhomogeneous Gaussian target.

Caravan dataset which visualizes chain autocorrelation. From all these results we can conclude that FisherMALA is better than all other samplers, and remarkably it outperforms significantly the position-dependent mMALA, especially in the high dimensional Caravan and MNIST datasets.

## 6 Related Work

There exist works that use some form of global preconditioning in gradient-based samplers for specialized targets such as latent Gaussian models [13; 44], which make use of the tractable Gaussian prior. Our method differs, since it is more agnostic to the target and learns a preconditioning from the history of gradients, analogously to how traditional adaptive MCMC learns from states [21; 38].

Several research works use position-dependent preconditioning \(A(x)\) within gradient-based samplers, such as MALA. This is for example the idea behind Riemannian manifold MALA  and extensions . Similar to Riemannian manifold methods there are approaches inspired by second order optimization that use the Hessian matrix, or some estimate of the Hessian, for sampling in a MALA-style manner [32; 17; 27]. Recently, such samplers and their time-continuous diffusion limits have been theoretically analyzed by obtaining convergence guarantees [12; 26]. All such methods form a position-dependent preconditioning and not the preconditioning we use in this paper, e.g. note that \(^{-1}\) we consider here requires an expectation under the target and thus it is always a global preconditioner rather than a position-dependent one. Another difference is that our method has quadratic cost, while position-dependent preconditioning methods have cubic cost and they require computationally demanding quantities like the Hessian matrix. Therefore, in order for these methods to run faster some approximation may be needed, e.g. low rank  or quasi-Newton type [46; 24]. Furthermore, the Bayesian logistic results in Table 1 (see also Figure 3) show that the proposed FisherMALA method significantly outperforms manifold MALA  in Caravan and MNIST examples, despite the fact that manifold MALA preconditions with the exact negative inverse Hessian matrix of the log target. This could suggest that position-dependent preconditioning may be less effective in certain type of high-dimensional and log-concave problems.

    & Max ESS & Median ESS & Min ESS \\  _GP target_ (\(d=100\)) & & & \\ MALA & \(15.235 4.246\) & \(6.326 1.934\) & \(3.619 0.956\) \\ AdaMALA & \(845.100 80.472\) & \(662.978 81.127\) & \(552.377 74.441\) \\ HMC & \(17.625 6.706\) & \(6.680 2.205\) & \(4.315 0.889\) \\ mMALA & \(2109.441 101.553\) & \(2007.640 104.867\) & \(1841.978 114.266\) \\ FisherMALA & \(2096.259 94.751\) & \(1923.753 95.820\) & \(1784.962 104.440\) \\  _Pima Indian_ (\(d=7\)) & & & \\ MALA & \(106.668 29.601\) & \(14.723 3.821\) & \(4.061 1.587\) \\ AdaMALA & \(211.948 133.363\) & \(52.277 26.566\) & \(6.401 3.344\) \\ HMC & \(1624.773 544.777\) & \(337.100 212.158\) & \(6.052 2.062\) \\ mMALA & \(6086.948 117.241\) & \(5690.967 118.401\) & \(5297.835 160.084\) \\ FisherMALA & \(6437.419 207.548\) & \(5981.960 156.072\) & \(5628.541 168.425\) \\  _Caravan_ (\(d=87\)) & & & \\ MALA & \(27.247 7.554\) & \(5.890 0.398\) & \(2.906 0.150\) \\ AdaMALA & \(41.522 9.343\) & \(7.144 0.663\) & \(3.144 0.135\) \\ HMC & \(787.901 173.863\) & \(37.303 6.808\) & \(4.238 0.532\) \\ mMALA & \(179.899 61.502\) & \(121.867 41.801\) & \(51.414 24.995\) \\ FisherMALA & \(2257.737 45.289\) & \(1920.903 55.821\) & \( 96.692\) \\  _MNIST_ (\(d=785\)) & & & \\ MALA & \(34.074 4.977\) & \(7.589 0.149\) & \(2.944 0.066\) \\ AdaMALA & \(62.301 9.203\) & \(8.188 0.399\) & \(2.985 0.089\) \\ HMC & \(889.386 118.050\) & \(303.345 10.976\) & \(114.439 20.965\) \\ mMALA & \(51.589 3.447\) & \(20.222 1.259\) & \(5.240 0.492\) \\ FisherMALA & \(1053.455 35.680\) & \(811.522 19.165\) & \( 52.800\) \\   

Table 1: ESS scores are averages after repeating the simulations \(10\) times under different random initializations.

Finally, there is recent work for learning flexible MCMC proposals by using neural networks [42; 25; 23; 41] and by adapting parameters using differentiable objectives [25; 29; 43; 14]. Our method differs, since it does not use objective functions (which have extra cost because they require an optimization to run in parallel with the MCMC chain), but instead it adapts similarly to traditionally MCMC methods by accumulating information from the observed history of the chain.

## 7 Conclusion

We derived an optimal preconditioning for the Langevin diffusion by optimizing the expected squared jumped distance, and subsequently we developed an adaptive MCMC algorithm that approximates the optimal preconditioning by applying an efficient quadratic cost recursion. Some possible topics for future research are: Firstly, it would be useful to investigate whether the score function differences that we use as the adaptation signal introduce any bias in the estimation of the inverse Fisher matrix. Secondly, it would be interesting to extend our method to learn the preconditioning for other gradient-based samplers such as Hamiltonian Monte Carlo (HMC), where such a matrix there is referred to as the inverse mass matrix. For HMC this is more complex since both the mass matrix and its inverse are needed in the iteration. Finally, it could be interesting to investigate adaptive schemes of the inverse Fisher matrix by using multiple parallel and interacting chains, similarly to ensemble covariance matrix estimation for Langevin diffusions .