# Are Uncertainty Quantification Capabilities of

Evidential Deep Learning a Mirage?

 Maohao Shen\({}^{1}\), J. Jon Ryu\({}^{1}\)1, Soumya Ghosh\({}^{2}\),

Yuheng Bu\({}^{3}\), Prasanna Sattigeri\({}^{2}\), Subhro Das\({}^{2}\), Gregory W. Wornell\({}^{1}\)

\({}^{1}\)Department of EECS, MIT, Cambridge, MA 02139

\({}^{2}\)MIT-IBM Watson AI Lab, IBM Research, Cambridge, MA 02142

\({}^{3}\)Department of ECE, University of Florida, Gainesville, FL 32611

{maohao,jongha,gww}@mit.edu,

{ghoshoso,prasanna}@us.ibm.com, subhro.das@ibm.com,

buyuheng@ufl.edu

###### Abstract

This paper questions the effectiveness of a modern predictive uncertainty quantification approach, called _evidential deep learning_ (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their perceived strong empirical performance on downstream tasks, a line of recent studies by Bengs et al. identify limitations of the existing methods to conclude their learned epistemic uncertainties are unreliable, e.g., in that they are non-vanishing even with infinite data. Building on and sharpening such analysis, we 1) provide a sharper understanding of the asymptotic behavior of a wide class of EDL methods by unifying various objective functions; 2) reveal that the EDL methods can be better interpreted as an out-of-distribution detection algorithm based on energy-based-models; and 3) conduct extensive ablation studies to better assess their empirical effectiveness with real-world datasets. Through all these analyses, we conclude that even when EDL methods are empirically effective on downstream tasks, this occurs despite their poor uncertainty quantification capabilities. Our investigation suggests that incorporating model uncertainty can help EDL methods faithfully quantify uncertainties and further improve performance on representative downstream tasks, albeit at the cost of additional computational complexity.2

## 1 Introduction

Accurate estimation of uncertainty in the prediction becomes more crucial to enhance the reliability of a predictive model, especially for high-stake applications such as medical diagnosis . Among several approaches proposed, a class of uncertainty estimation methods under the category of _evidential deep learning_ (EDL) has recently gained attention , due to their claimed advantages over other methods. EDL methods typically learn a single neural network that maps input data to the parameters of a meta distribution, which is a distribution over the predictive distribution. The EDL methods generally claim the following advantages. (1) _Computational efficiency_: they bypass the expensive sampling costs associated with Bayesian or ensemble-based methods by training asingle neural network and estimating uncertainty with a single forward pass. (2) _Promising empirical performance_: they achieve superior results on downstream uncertainty quantification (UQ) tasks, particularly in detecting out-of-distribution (OOD) data. (3) _Ability to quantify different uncertainties_: EDL methods can quantify _distributional uncertainty_ versus _aleatoric uncertainty_, by representing them as the spread and mean of an estimated meta distribution over the prediction, respectively.

Despite the above benefits, a line of recent works has reported theoretical limitations and pitfalls of uncertainties learned by EDL methods, including the issue of non-vanishing distributional uncertainty , a possibility of non-existence of proper scoring rules for meta distributions , and a gap between learned uncertainty and an ideal meta distribution . While these works call for the attention of the UQ community for the raised issues, a comprehensive theoretical understanding of the learned uncertainties from this type of UQ model is still lacking, as the existing analyses focus on a restricted subset of objective functions in the literature. Moreover, they did not explain the empirical success of the EDL methods at downstream tasks, such as OOD detection, despite such issues.

In this paper, we provide a simpler and sharper theoretical characterization of what is being learned by representative EDL methods, and re-examine the empirical success of the EDL methods based on the analysis. More concretely, our contributions are threefold:

1. **Theoretical Analysis**: In Sec. 4, we provide a unifying perspective on several representative EDL methods proposed in the literature, establishing an _exact_ characterization of the _optimal_ meta distribution defined by existing methods. This reveals that existing methods enforce the meta distribution to fit a sample-size-independent target distribution (Theorem 5.1). This analysis covers a wider class of objective functions and modalities, and is sharper than the prior analyses [4; 6].
2. **Empirical Investigation**: In Sec. 5, we further provide empirical evidence to point out the fundamental limitations of the learned uncertainties by EDL methods, and present several findings showing that existing EDL methods are essentially OOD detectors and hence exhibit their pitfalls.
3. **Insights and Solutions**: In Sec. 6, we explain why model uncertainty seems inevitable for faithful UQ and how we can improve the EDL method accordingly. We propose a new model uncertainty based on the idea of bootstrap, and demonstrate that an EDL model can well distill its behavior and achieve superior UQ downstream task performance compared to the existing methods.

## 2 Related Work

We summarize the literature that is closely aligned with the scope of this paper. We refer the reader to Sec. B in Appendix for an overview of classical UQ literature and a recent survey paper  for a comprehensive review of EDL methods.

**EDL Methods.** EDL methods, mainly applied in classification settings, utilize a single neural network to model Dirichlet distributions over label distributions, which can be divided into three categories. (1) _OOD-data-dependent methods_: Earlier works such as Forward Prior Network , and Reverse Prior Network [8; 9], proposed to train a model to output sharp Dirichlet distribution for in-distribution (ID) data and flat Dirichlet distribution for OOD data. (2) _OOD-data-free methods_: Subsequently, several methods without OOD data were proposed with various training objectives, including the MSE loss with reverse Kullback-Leibler (KL) regularizer [10; 11], the "VI" loss [12; 13; 14], and the "UCE" loss . (3) _Distillation based methods_: are motivated by training a single model to mimic the behavior of classical UQ approaches, including END2  that emulates ensemble method, and S2D  that emulates (Gaussian) random dropout method. EDL methods have also been explored for regression problems [18; 19; 20].

**Critiques of EDL Methods.** Recently, several works have raised concerns about the quality of uncertainty learned by EDL methods. Bengs et al.  pointed out the learned distributional uncertainty does not vanish even in the asymptotic limit of infinite training samples. Bengs et al.  provided further theoretical arguments for why a proper scoring rule for learning the meta distribution might not exist. More recently, Jurgens et al.  argues that the learned uncertainty by EDL methods is inconsistent with a reference distribution. In a similar spirit to these critiques, we offer a sharper analysis to characterize the exact behavior of EDL methods. Our analysis can subsume, generalize, and simplify the existing analyses. See Appendix A for a more in-depth review of these works.

## 3 Problem Setting and Preliminaries

In the predictive modeling, we aim to learn the label distribution \(p(y|x)\) over \(\) using data \(=\{(x_{i},y_{i})\}_{i=1}^{N}\) drawn from an underlying data distribution \(p(x)p(y|x)\) over \(\). Here, \(\) is a label set; \(=[C]:=\{1,,C\}\) for classification for some \(C 1\) and \(=\) for regression. \(^{C-1}\) denotes the probability simplex over \([C]\). In addition to accurately learning the conditional distribution \(_{y}(x):=p(y|x)\), we wish to quantify "uncertainty" of the learned prediction. We focus on classification in this paper, but some of our analyses also apply to certain existing EDL methods for regression [19; 20]. For the sake of clarity, we defer all related discussion on regression and beyond to Appendix F.

**Bayesian and Ensemble-based Approaches.** Different UQ methods define predictive uncertainties based on different sources of randomness. The _Bayesian_ approach is arguably the most widely studied UQ approach, in which a parametric classifier \(p(y|x,)\) is trained via the Bayesian principle, and inference is performed with the predictive posterior distribution \(p(y|x,):= p(y|x,)p(|)\,\), where \(p(|)\) is the model posterior distribution, induced by the prior \(p()\) and likelihood \(p(|)\). Ensemble-based methods assume a different distribution \(p(|)\) to generate random models given data, e.g., training neural networks with different random seeds. As alluded to earlier, both Bayesian and ensemble approaches are computationally demanding due to the intractability of \(p(|)\) and the need for computing the integration over \(\). Moreover, \(p(y|x,)\) can capture _aleatoric uncertainty_ (or _data uncertainty_), and the amount of spread over \(p(y|x,)\) induced by the model uncertainty of \(p(|)\) is regarded as _epistemic uncertainty_ (or _knowledge uncertainty_) for its prediction.

**EDL Approach.** The EDL approach further decomposes the predictive posterior distribution as \(p(y|x,)= p(|x,)p(y|)\, {}\), where \(p(|x,)\) is a _meta distribution_ (or called _second-order distribution_[4; 5]) over the prediction at \(x\), and \(p(y|)\) is a fixed likelihood model. For classification, \(^{C-1}\) is a probability vector over \(C\) classes, \(p(y|)=_{y}\) is the categorical likelihood model, and \(p(|x,)\) is a distribution over the simplex \(^{C-1}\). Oftentimes, \(p(|x,)\) is chosen as a conjugate prior of the likelihood model \(p(y|)\), like the Dirichlet distribution for classification [7; 8; 13; 15; 20], but sometimes not [10; 18; 11]. Given the full decomposition, \(p(y|x,)= p(y|)p(|x,)p(| )\,\,\), the uncertainty captured in \(p(y|)\) is called aleatoric uncertainty, in \(p(|x,)\) is called _distributional uncertainty_, a kind of _epistemic uncertainty_. However, EDL methods often assume the best single model \(^{}\) learned with data \(\), without any randomness in \(p(|)\), or formally setting it to be \((-^{})\)[7; 3]. It then aims to train the meta distribution \(p(|x,)\) under certain learning criteria so that it encodes less uncertainty for ID points \(x\) and more for OOD points. While this simplification allows its computational efficiency over the classical methods, as we will argue later, no randomness assumed in the model \(p(|)\) lets all the methods in this framework learn spurious distributional uncertainty. Since a single model \(\) is assumed, we use a frequentist notation \(p_{}(|x)\) instead of \(p(|x,)\) in that context.

## 4 New Taxonomy for EDL Methods

In this section, we propose a new taxonomy to understand different EDL methods (for classification) in a systematic way. Ignoring the choice of base architectures, we identify that the key distinguishing features in EDL methods are (1) the parametric form of the model and (2) the learning criteria. A wide class of EDL methods can be classified with the taxonomy as in Table 1. Several theoretical implications and empirical consequences of the new taxonomy will be investigated in the next section.

   Method (name of loss) & likelihood & \(D(,)\) & prior \(_{0}\) & \(_{}\) & \(_{}(x)\) parameterization \\  FPriorNet (F-KL loss)  & categorical & fwd. KL & \(=_{C}\) & \(>0\) & direct \\ RPriorNet (R-KL loss)  & categorical & rev. KL & \(=_{C}\) & \(>0\) & direct \\ EDL (MSE loss)  & Gaussian & rev. KL & \(=_{C}\) & \(=0\) & direct \\ Belief Matching (VI loss) [12; 13] & categorical & rev. KL & \(_{>0}^{C}\) & \(=0\) & direct \\ PostNet (UCE loss)  & categorical & rev. KL & \(=_{C}\) & \(=0\) & density w/ single flow \\ NatPN (UCE loss)  & categorical & rev. KL & \(=_{C}\) & \(=0\) & density w/ multiple flows \\   

Table 1: **New taxonomy of representative EDL methods.**\(()\) in Eq. (6) subsumes these as special cases.

Criterion 1. Parametric Form of Meta Distribution.For classification, one distinguishing feature is the parametric form of \(_{}(x)\) in Dirichlet distribution \(p_{}(|x)=(;_{}(x))\). Earlier works  typically parameterize \(_{}(x)\) by a direct output of a neural network, e.g., exponentiated logits; we call this _direct parameterization_. Later, Charpentier et al.  brought up a potential issue with the direct parameterization that \(_{}(x)\) can take arbitrary values on the unseen (i.e., OOD) data points. They proposed a more sophisticated parameterization of the form to explicitly resemble the posterior distribution update of the Dirichlet distribution \(_{}(x)_{0}+_{}(x)\), where, for \(y[C]\), \((_{}(x))_{y}:=N(y)p_{_{2}}(f_{_{1}}(x)|y)\), with \((y):=N_{y}/N\), \(N_{y}\) denotes the number of data points with label \(y\), \(N:=_{y[C]}N_{y}\), \(x f_{_{1}}(x)\) a feature extractor, and \(p_{_{2}}(z|y)\) a tractable density model such as normalizing flows  for each \(y[C]\). We call this _density parameterization_. In Sec. 5, we carefully examine the effectiveness of density parameterization.

Criterion 2. Objective Function.The desired behavior of EDL model is to output sharp \(p_{}(|x)\) if it is confident, and fall back to output _prior_ distribution \(p()\) if it is uncertain at an unseen data \(x\). To achieve this, various objectives have been introduced with different jargon and motivations, e.g.:

1. Prior Networks (PriorNet)  aimed to explicitly encourage \(p_{}(|x)\) to be diffused prior \(p()\) for OOD data, and a more concentrated Dirichlet distribution \((;_{0}+_{y})\) for ID data, with \( 1\), \(_{0}=_{C}\) and \(_{y}\) as the one-hot true label, by minimizing \[_{p(x,y)}[D((;_{0}+_{y} ),p_{}(\,|x))+_{}_{p_{}(x )}[D((;_{0}),p_{}(\,|x))]\] (1) for \(D(p,q)=D(p q)\) (forward KL) in , and \(D(p,q)=D(q p)\) (reverse KL) later in . It is known that PriorNet with forward KL requires an additional auxiliary loss \((y|x)}\) to ensure high accuracy, and the reverse-KL version can outperform without such term.
2. The "Evidential Deep Learning" paper  proposed the MSE loss with a reverse KL regularizer: \[_{}(;x,y):=_{p_{}(|x)}[\|- _{y}\|^{2}]+ D(p_{}(\,|x)( ;_{0})).\] (2)
3. Belief Matching  proposed VI loss justified by variational inference framework: \[_{}(;x,y):=_{p_{}(|x)} }+ D(p_{}(\,|x)( ;_{0})).\] (3)
4. Posterior Networks (PostNet  and NatPN ) proposed the uncertainty-aware cross entropy (UCE) loss, motivating it from a general framework for updating belief distributions : \[_{}(;x,y):=_{p_{}(|x)} }- h(p_{}(\,|x)).\] (4)

The hyper-parameter \(>0\) in objectives 2, 3, and 4 balances the first likelihood term which forces \(p_{}(|x)\) to learn the label distribution and the second regularizer term promotes \(p_{}(|x)\) to be close to the prior \(p()\). Below, we reveal that the seemingly different objectives 1, 3, 4 are exactly equivalent, while objective Eq. (2) (different _likelihood_) can also be unified in a single framework.

A Unifying View.We now provide a unifying view of the fairly wide class of representative objective functions. First, for convenience of analysis, we define the _tempered likelihood_: for \(>0\), define

\[p^{()}(\,|y):=(,y)}{ p^{()}(,y )\,},p^{()}(,y):=)p^{}(y|)}{ p()_{y}p^ {}(y|)\,}.\] (5)

Objectives 1, 3, 4 assume the likelihood model is categorical, i.e., \(p(y|)=_{y}\), by the conjugacy of the Dirichlet distribution for the multinomial distribution, it is easy to check that \(p^{()}(|y)=(;_{0}+_{y})\), where \(_{y}^{C}\) is the one-hot vector activated at \(y[C]\). Objective 2 used Gaussian likelihood model \(p(y|)=(_{y};,^{2}I_{C})\), which does not admit a closed form expression for \(p^{()}(|y)\). The prior distribution is usually defined as \(p()=(;_{0})\) with \(_{0}=_{C}\) (all-one vector). Other choices of prior were also proposed to promote some other desired property .

We now introduce a _unified objective function_

\[():=_{p(x,y)}[D(p^{()}(\,|y),p_{}( {}\,|x))]+_{}_{p_{}(x)}[D(p(),p_{}(\,|x))]\] (6)

for some divergence function \(D(,)\), a tempering parameter \(>0\), and an OOD regularization parameter \(_{} 0\) with a distribution \(p_{}\) for OOD samples. The following theorem summarizes how this unified objective subsumes several existing proposals. The proof is deferred to Appendix D.

**Theorem 4.1** (Unifying EDL Objectives for Classification).: _Let \(p()=}(;_{C})\)._

1. _Let_ \(p(y|)=_{y}\) _and let_ \(_{}>0\)_. With_ \(D(p,q)=D(p q)\) _(forward KL) and_ \(D(p,q)=D(q p)\) _(reverse KL),_ \(()\) _is equivalent to the objective (Eq._ (1) _) of forward PriorNet (FPioriNet)_ _[_7_]_ _and that of reverse PriorNet (RPriorNet)_ _[_8_]__, respectively._
2. _Let_ \(p(y|)=(_{y};,^{2}I_{C})\)_, and let_ \(_{}=0\)_,_ \(()\) _is equivalent to the objective_ \(_{}():=_{p(x,y)}[_{}( ;x,y)]\) _(Eq._ (2)_)._
3. _Let_ \(p(y|)=_{y}\)_,_ \(=^{-1}\)_, and let_ \(_{}=0\)_. With_ \(D(p,q)=D(q p)\) _(reverse KL),_ \(()\) _is equivalent to the objective_ \(_{}():=_{p(x,y)}[_{}(;x,y)]\) _(Eq._ (3)_)._
4. _Let_ \(p(y|)=_{y}\)_,_ \(=^{-1}\)_, and let_ \(_{}=0\)_. With_ \(D(p,q)=D(q p)\) _(reverse KL),_ \(()\) _is equivalent to the objective_ \(_{}():=_{p(x,y)}[_{}( ;x,y)]\) _(Eq._ (4)_)._

We first remark that the reverse KL divergence captures most of the cases, except the forward KL PriorNet, which is known to be outperformed by PriorNet with reverse KL. Hence, it suffices to focus on understanding the reverse KL objective. Second, the VI loss in Eq. (3) and UCE loss Eq. (4) turn out to be equivalent to the RPriorNet objective, where the tempering parameter \(\) and the regularization parameter \(\) is related to be reciprocal \(=^{-1}\); see Lemma D.1. Overall, this theorem reveals that different motivations, such as VI or Bayesian updating mechanism of belief distributions, were not very significant, and those objectives turn out to be equivalent to the simple divergence matching in Eq. (6). Given this, distinguishing features that better classify different EDL methods are the choices of (1) likelihood model, (2) prior, (3) use of OOD data, and (4) model parametric form, as shown in Table 1. The recent survey  also offers a unified view of different objective functions with these features. However, the dichotomy between "PriorNet-type methods" [7; 8] and "PostNet-type methods" [12; 13; 15; 20; 14] in  may not effectively contrast different EDL methods compared to our taxonomy.

We acknowledge that there exist other objective functions that might not be covered by this unified view. We defer the discussion on another line of representative work, including the distillation-based methods [16; 17] to Sec. 6. A notable exception that is not subsumed by this unification is FisherEDL , which was recently proposed to use a variant of the MSE loss  by taking into account the Fisher information of \(p_{}(|x)\); see Appendix F for a discussion. Finally, similar reasoning can be naturally extended to unify different EDL objectives for other tasks such as regression and count data analysis, including [19; 20]. We defer a detailed discussion to Appendix F.

## 5 Rethinking the Success of EDL Methods

In this section, we aim to reveal the secrets of EDL methods' empirical success through a combination of theoretical and empirical findings. As alluded to earlier, our empirical investigation focuses on the reverse-KL type EDL methods, i.e., RPriorNet , Belief Matching (BM) , PostNet , and NatPN , which are representative and widely used in the literature.

### What Is the "Optimal" Meta Distribution Characterized By The EDL Objectives?

Based on the unification in Eq. (6), we can provide a sharp mathematical characterization of the optimally learned meta distribution for a wide class of EDL objectives. A direct and important consequence of the divergence minimization view is that we can now characterize the "optimal" behavior of the learned meta distribution of a wide class of EDL objectives, provided that the global minimizer is achieved in the nonparametric and population limit. The following theorem is proved in Appendix E.

**Theorem 5.1**.: _For any prior \(p()\) and likelihood \(p(y|)\), we have_

\[_{}_{p(x,y)}[D(p_{}(|x) p_ {}(|y))]_{}_{p(x)}[D(p_{}(|x)  p^{}(|x))],\] \[p^{}(|x):=)( _{p(y|x)}[ p(y|)])}{ p()(_ {p(y|x)}[ p(y|)])\,}.\] (7)

In words, Theorem 5.1 states that when the model meta distribution \(p_{}(|x)\) is trained with the reverse-KL objective, it is forced to fit a _fixed_ target meta distribution \(p^{}(|x)\).

_Example 5.2_ (Categorical likelihood).: If we consider \(p()=(;_{0})\) and \(p(y|)=_{y}\) (categorical likelihood), we have \(p^{*}(|x)=(;_{0}+(x))\), where \((x):=_{p(y|x)}[_{y}]=[p(1|x),,p(C|x)]\) denotes the true label distribution, Theorem 5.1 implies that

\[_{}_{p(x,y)}[D(p_{}(|x)\|p_{}(|y))] _{}_{p(x)}[D((;_{}(x))\| (;_{0}+(x)))].\] (8)

In particular, with the most common Dirichlet parameterization \(p_{}(|x)=(;_{}(x))\), this shows that \(_{}(x)\) is forced to match the scaled-and-shifted version \(_{0}+(x)\) of the conditional label distribution \((x)\) as the _fixed_ target, under the categorical likelihood model. A similar argument still applies to the Gaussian likelihood model of , but the fixed target distribution \(p^{*}(|x)\) in Eq. (7) does not admit a closed-form expression unlike the categorical likelihood.

An immediate consequence of the Theorem 5.1 is that neither epistemic uncertainty nor aleatoric uncertainty quantified by EDL methods is consistent with their dictionary definition.

**Implication 1: EDL Methods Learn Spurious Epistemic Uncertainty**

First, epistemic uncertainty for ID data, by definition, should monotonically decrease and eventually vanish as the number of observations increases. However, Theorem 5.1 implies that, even with infinite data, the learned "distributional uncertainty" would remain constant for ID data. We also empirically confirm such behavior; see Fig. 1(a). Specifically, we sample data of varying sizes to train the EDL models and evaluate their test accuracy and averaged epistemic uncertainty (mutual information) on a held-out test set. As observed in Fig. 1(a), epistemic uncertainties quantified by EDL methods are almost constant with respect to the sample size and never vanish to 0, regardless of the increasing test accuracy. This suggests that practitioners cannot rely on the learned distributional uncertainty to determine if the model is lacking knowledge. We remark that Benggs et al.  identified a similar issue in the EDL methods specifically for the UCE loss of PostNet , which is the reverse-KL objective for \(=_{C}\) in our view, is not _appropriate_ in a similar spirit.3 Theorem 5.1 can be understood as a more general and sharper mathematical characterization of the behavior of the reverse-KL objective.

**Implication 2: EDL Methods Learn Spurious Aleatoric Uncertainty**

Second, EDL methods quantify aleatoric (data) uncertainty as \(_{p_{}(|x)}[H(p(y|))]\), where \(H\) denotes the Shannon entropy . Eq. (8) reveals the optimal meta distribution as \(p_{^{*}}(|x)=(;_{0}+(x))\).

Figure 1: **Behavior of Uncertainties Learned by EDL methods on Real Data. (a) EDL methods learn spurious epistemic uncertainty, wherein uncertainty does not vanish with an increasing number of observed samples, contrary to the fundamental definition of epistemic uncertainty. (b) Instead of a constant, EDL methods learn model-dependent aleatoric uncertainty that depends on hyper-parameter \(\), contrary to the fundamental definition of aleatoric uncertainty. Similar behavior holds for 2D Gaussian data (see Figure 5 in Appendix H.1).**

[MISSING_PAGE_FAIL:7]

\(_{0}+^{-1}(x)\), so that \(_{C}^{}_{}(x)^{-1} 1\) for ID data, and such behavior seems to benefit the downstream task performance.

**Implication 4: Impact of Specific Objective on UQ Performance is Less Significant**

Given the close resemblance to the OOD detection algorithm, a notable difference is the reverse-KL learning criterion used by the EDL methods. In Appendix H.2, as another ablation study, we investigate if the reverse-KL objective induced by the Dirichlet framework has a significant practical impact, or other Dirichlet-framework-independent objectives which promote the same behavior suffice for the downstream task performance.

### Are EDL Methods Robust for OOD Detection?

Lastly, we investigate the robustness of the auxiliary techniques like density parameterization and OOD regularization of EDL methods for the downstream task performance. Note that in the empirical result with real data presented in Fig. 9 in Appendix, neither OOD regularization (RPriorNet vs. BM) nor density parameterization (PostNet/NatPN vs. BM) demonstrates a clear advantage of deploying such techniques. Thus, we further investigate this counterintuitive phenomenon and discover that the performance of these EDL methods on real data is hindered by certain limitations of the auxiliary techniques they use. Namely, we find that OOD-data-dependent methods  are sensitive to choice of model architectures, and methods [15; 20] using density models may not perform well even for moderate dimensionality. We defer the detailed discussion to Appendix H.3.

## 6 EDL Methods Will Benefit from Incorporating Model Uncertainty

Through the series of analyses in the prior section, we attempted to provide a comprehensive understanding of EDL methods, revealing their key limitations. A reader then may ask an important question: **What is the fundamental issue in these EDL methods that cause all these problems?** As we alluded to in Sec. 3, we identify that the issue arises from that all of the EDL methods discussed in Sec. 4 and Sec. 5 assume _no_ model uncertainty \(p(|)\) in the decomposition of predictive posterior distribution \(p(y|x,)= p(y|)p(|x,)p(|)\,\,\). A proper definition of distributional uncertainty should be based on the induced posterior distribution \(p(|x,):= p(|x,)p(|)\,\) over the prediction \(\) at \(x\), given the dataset \(\). Without the randomness in the model, however, i.e., setting \(p(|)(-^{})\), the induced distribution \(p(|x,)\) becomes degenerate as \(p(|x,^{})\). This simplification is often rationalized for the computational efficiency, but as we reveal, it renders the distributional uncertainty inherently ill-defined in this framework. The existing EDL methods thus have no choice but to train the "UQ" model \(p_{}(|x)\) to fit to an artificial target \((;_{0}+(x))\). Consequently, the learned distributional uncertainty cannot possesses a statistical meaning, and can be better interpreted as free energy in the EBM-based OOD detector.

**Model Uncertainty Can Induce A Proper Distributional Uncertainty.** This strongly suggests that it is inevitable to assume a stochastic procedure \(p(|)\) to properly define the distributional uncertainty \(p(|x,)\). We remark that, to expect the distributional uncertainty \(p(|x,)\) to exhibit a desirable behavior, i.e., getting concentrated for ID data and remaining dispersed for OOD data as \(||\), we implicitly assume that the stochastic algorithm \(p(|)\) would behave as follows: as \(||\), \(p(|)\) will become supported on a subset of models \(\) that agree upon the prediction for ID data while disagreeing on OOD data. Under this assumption, the induced distributional uncertainty will be consistent with the dictionary definition of epistemic uncertainty.

**Revisiting Distillation-Based Methods.** The downside of such an approach is that approximating \(p(|x,)\) can be computationally intractable due to the high-dimensional integration with respect to the stochastic algorithm \(p(|)\), which means that a practitioner needs to generate (or train) and save multiple models to approximately emulate the randomness. In this context, the EDL framework, which aims to quantify uncertainty by a single neural network, can be used to _distill_ the properly defined distributional uncertainty. Indeed, this is what has been explored by another line of EDL literature called _distillation-based methods_[16; 17], which were originally proposed to emulate the behavior the ensemble methods. Our analyses strongly advocate that considering a stochastic algorithm \(p(|)\) and training a single meta distribution trying to fit the induced distributional uncertainty to expedite the inference time complexity is the best practice for the EDLframework to faithfully capture uncertainties. More precisely, we can fit an UQ model \(p_{}(|x)\) to \(p(|x,)\) through the forward-KL objective and Monte Carlo samples, i.e., by minimizing \(_{p(x)}[D(p(|x,) p_{}(|x))] -_{i=1}^{N}_{j=1}^{M} p_{}(_{_{j}} (|x_{i})|x_{i})+\) with respect to \(\), where \(x_{_{j}}(|x)\) is a classifier corresponding to a randomly generated model \(_{j} p(|)\).

**Examples of Stochastic Algorithms \(p(|)\): Old and New.** There are two popular proposals for \(p(|)\) in the literature: (1) EnD\({}^{2}\) considers randomness in random initialization and stochastic optimization, which is called _ensemble_, and (2) S2D  considers a _random dropout_ applied to a single network. We propose yet another algorithm based on the frequentist approach _bootstrap_: given the training dataset \(\), the procedure randomly samples \(M\) different subsets \(\{_{j}\}_{j=1}^{M}\) of size \(N\) without replacement, and train a model \(_{j}\) based on \(_{j}\) for each \(j\). Unlike the previous proposals of \(p(|)\), the bootstrap method aims to leverage the internal consistency among the ID data, beyond the randomness induced by optimization and architectures. We note that this is inspired by a concurrent work of Jurgens et al. , which recently proposed an ideal meta distribution. The proposed bootstrapping can be understood as a practical method for approximating such behavior with finite samples. In the next section, we demonstrate that the new _Bootstrap Distillation_ method performs almost best on both OOD detection and selective classification tasks.

## 7 Comprehensive Empirical Evaluation

In this section, we conduct a comprehensive evaluation of the existing EDL methods, including the new proposed Bootstrap Distillation method, on two UQ downstream tasks: (1) _OOD data detection_: identify the OOD data based on the learned epistemic uncertainty; (2) _Selective classification_: identify the wrongly predicted test samples based on total uncertainty, as wrong prediction can occur from either high epistemic or high data uncertainty, or both. These results corroborate several key findings and insights presented in this paper. The detailed experiment setup are provided in Appendix G, and additional experiment results are included in Appendix H.

Figure 4: **Comparison of Different EDL Methods on Selective Classification.** Distillation based methods, including new proposed Bootstrap-Distill method, demonstrate clear advantage over other classical EDL methods.

Figure 3: **Comparison of Different EDL Methods on OOD Detection.** Distillation based methods, including new proposed Bootstrap-Distill method, demonstrate clear advantage over other classical EDL methods. Similar behavior holds for selective classification task.

* **Baselines.** We include a wide range of EDL methods as baselines: Classical methods: (1) RPriorNet , (2) Belief Matching (BM) , (3) PostNet , (4) NatPN , (5) EDL , and (6) Fisher-EDL . Distillation-based method: (1) EnD\({}^{2}\) and (2) S2D . All baseline results are reproduced using their official implementation, if available, and their recommended hyper-parameters.
* **Benchmark.** We consider two ID datasets: CIFAR10, and CIFAR100. For the OOD detection task, we select four OOD datasets for each ID dataset: we use SVHN, FMNIST, TinyImageNet, and corrupted ID data.
* **Evaluation Metric.** We elaborate metrics for quantifying different types of uncertainties in Section C. We evaluate the UQ downstream performance through the Area Under the ROC Curve (AUROC) and Area Under the Precision-Recall Curve (AUPR), where we treat ID (correctly classified) test samples as the negative class and outlier (misclassified) samples as the positive class.

**Results and Takeaway.** The result is summarized in Fig. 3 and Fig. 4. We present the average AUROC score across four OOD datasets for the OOD detection task, and the AUROC score for the selective classification task. More numerical results can be found in Table 2, 3, and 4 in Appendix H. This set of evaluations corroborates our key findings and insights in the previous sections.

Firstly, the results show that varying the likelihood model does not significantly impact performance (BM vs. EDL and Fisher-EDL), supporting the discussion in Sec. 4. Secondly, classical EDL methods achieve comparable performance regardless of the auxiliary techniques, such as density parameterization (PostNet, NatPN), or leveraging OOD data (RPriorNet); this validates our finding in Sec. 5.3. Thirdly, distillation-based methods, particularly EnD\({}^{2}\) and the new Bootstrap Distillation, demonstrate superior performance over other baselines, especially on CIFAR100, thereby validating the insights provided in Sec. 6. Moreover, our empirical analysis confirms that the Bootstrap Distillation method can faithfully quantify epistemic uncertainty, as illustrated in Fig. 13 in Appendix H, effectively addressing the limitations identified with other EDL methods in Sec. 5.1. Finally, we note that the performance of Bootstrap Distillation comes at a higher computational cost due to training multiple bootstrap models; see Fig. 14 in Appendix H.

## 8 Concluding Remarks

In this work, we revealed that the uncertainty learned by most of the existing EDL methods bear no statistical meaning. The key theoretical insight is based on the unification of representative EDL objectives in Sec. 5.1. Given this, we suggested that EDL methods can be better interpreted as energy-based OOD detection algorithms, which can explain the reported empirical successes of EDL methods from a different perspective. Additionally, we demonstrated that the performance of EDL methods is sensitive to the choice of auxiliary techniques, further raising questions about their robustness. Finally, we identified that the aforementioned issues with EDL arise from ignoring the model uncertainty for computational efficiency, and argued that the distillation-based methods could potentially remedy the issues, at the cost of additional complexity.

Overall, this work calls researchers' attention to carefully reexamine the capabilities and limitations of the EDL approach at large. For practitioners, EDL methods can still be utilized as efficient algorithms for specific applications, such as OOD data detection. However, when considering EDL methods to build reliable machine learning agents based on their UQ capabilities, practitioners should be aware of their limitations, which contrast with the common belief that EDL approaches can accurately learn and distinguish between epistemic and aleatoric uncertainty.

We conclude the paper with a few remarks on the theory of the Bootstrap-Distill method. As we empirically showed, it can resolve the common issues of the EDL methods with improved downstream task performance, and we thus believe that a careful theoretical analysis of its behavior would be a fruitful direction. While it is relatively easy to argue that the epistemic uncertainty would vanish when the sample size grows to infinity with the bootstrap procedure, we believe that a more sophisticated asymptotic analysis for vanishing epistemic uncertainty could be carried out with overparameterized neural networks, adopting a similar setting in . That is, if the trained model's prediction can be shown to be asymptotically normal in the limit of the sample size, one can argue that the uncertainty captured by bootstrap behaves as Gaussian of vanishing variance in the sample limit. This implies a naturally vanishing epistemic uncertainty. We leave this as a future work.