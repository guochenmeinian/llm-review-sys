# Distributionally Robust Skeleton Learning of Discrete Bayesian Networks

Yeshu Li*

Alibaba Group

liyeshu.lys@alibaba-inc.com &Brian D. Ziebart

Department of Computer Science

University of Illinois at Chicago

bziebart@uic.edu

Work done when Yeshu was a PhD student at UIC.

###### Abstract

We consider the problem of learning the exact skeleton of general discrete Bayesian networks from potentially corrupted data. Building on distributionally robust optimization and a regression approach, we propose to optimize the most adverse risk over a family of distributions within bounded Wasserstein distance or KL divergence to the empirical distribution. The worst-case risk accounts for the effect of outliers. The proposed approach applies for general categorical random variables without assuming faithfulness, an ordinal relationship or a specific form of conditional distribution. We present efficient algorithms and show the proposed methods are closely related to the standard regularized regression approach. Under mild assumptions, we derive non-asymptotic guarantees for successful structure learning with logarithmic sample complexities for bounded-degree graphs. Numerical study on synthetic and real datasets validates the effectiveness of our method.

## 1 Introduction

A Bayesian network is a prominent class of probabilistic graphical models that encodes the conditional dependencies among variables with a directed acyclic graph (DAG). It provides a mathematical framework for formally understanding the interaction among variables of interest, together with computationally attractive factorization for modeling multivariate distributions. If we impose causal relationships on the edges between variables, the model becomes a causal Bayesian network that encodes the more informative causation. Without such interpretation, a Bayesian network serves as a dependency graph for factorization of a multivariate distribution. We focus on discrete Bayesian networks with purely categorical random variables that are not ordinal, but will discuss related work on both discrete and continuous Bayesian networks for completeness.

The DAG structure of a Bayesian network is typically unknown in practice (Natori et al., 2017; Kitson et al., 2023). Structure learning is therefore an important task that infers the structure from data. The _score-based_ approach defines a scoring function that measures the goodness-of-fit of each structure and aims to find an optimal DAG that maximizes the score. Unfortunately, the resulting combinatorial optimization problem is known to be NP-hard (Chickering et al., 2004) without distributional assumptions. Representative approaches include those based on heuristic search (Chickering, 2002), dynamic programming (Silander and Myllymaki, 2006), integer linear programming (Jaakkola et al., 2010) or continuous optimization (Zheng et al., 2018), which either yields an approximate solution or an exact solution in worst-case exponential time. The _constraint-based_ approach (Spirtes and Glymour, 1991; Spirtes et al., 1999; Colombo et al., 2014) performs conditional independence tests to determine the existence and directionality of edges. The time complexity is, however, exponential with the maximum in-degree. Furthermore, the independence test results may be unreliable or inconsistent with the true distribution because of finite samples oreven corrupted samples. In general, without interventional data or assumptions on the underlying distribution, we can only identify a Markov equivalence class (MEC) the true DAG belongs to from observational data where DAGs in the MEC are Markov equivalent, that is, encoding the same set of conditional independencies.

A super-structure is an undirected graph that contains the skeleton as a subgraph which removes directionality from the true DAG. It has been shown that a given super-structure possibly reduces the search space or the number of independence tests to be performed. For example, exact structure learning of Bayesian networks may be (fixed-parameter) tractable (Downey and Fellows, 1995) if the super-structure satisfies certain graph-theoretic properties such as bounded tree-width (Korhonen and Parviainen, 2013; Loh and Buhlmann, 2014), bounded maximum degree (Ordyniak and Szeider, 2013) and the feedback edge number (Ganian and Korchemma, 2021). An incomplete super-structure with missing edges also helps improve the learned DAG with a post-processing hill-climbing method (Tsamardinos et al., 2006; Perrier et al., 2008). Furthermore, a combination of a skeleton and a variable ordering determines a unique DAG structure. Learning the exact skeleton rather than a rough super-structure is desirable in Bayesian network structure learning.

Spirtes and Glymour (1991), Tsamardinos et al. (2006) make use of independence tests to estimate the skeleton. Loh and Buhlmann (2014) learn a super-structure called moralized graph via graphical lasso (Friedman et al., 2008). Shojaie and Michailidis (2010) learn the skeleton assuming an ordering of variables. Bank and Honorio (2020) leverage linear regression for skeleton recovery in polynomial time. These methods either rely on independence test results, which are unstable, or a regularized empirical risk minimization problem, where regularization is usually heuristically chosen to combat overfitting. In practice, the observational data is commonly contaminated by sensor failure, transmission error or adversarial perturbation (Lorch et al., 2022; Sankararaman et al., 2022; Kitson et al., 2023). Sometimes only a small amount of data is available for learning. As a result, the existing algorithms are vulnerable to such distributional uncertainty and may produce false or missing edges in the estimated skeleton.

In this paper, we propose a distributionally robust optimization (DRO) method (Rahimian and Mehrotra, 2019) that solves a node-wise multivariate regression problem (Bank and Honorio, 2020) for skeleton learning of general discrete Bayesian networks to overcome the above limitations. We do not assume any specific form of conditional distributions. We take into account the settings with a small sample size and potential perturbations, which makes the true data generating distribution highly uncertain. Our method explicitly models the uncertainty by constructing an ambiguity set of distributions characterized by certain a priori properties of the true distribution. The optimal parameter is learned by minimizing the worst-case expected loss over all the distributions within the ambiguity set so that it performs uniformly well on all the considered distributions. The ambiguity set is usually defined in such a way that it includes all the distributions close to the empirical distribution in terms of some divergence. With an appropriately chosen divergence measure, the set contains the true distribution with high probability. Hence the worst-case risk can be interpreted as an upper confidence bound of the true risk. The fact that a discrete Bayesian network encompasses an exponential number of states may pose a challenge to solve the DRO problem. We develop efficient algorithms for problems with ambiguity sets defined by Wasserstein distances and Kullback-Leibler (KL) divergences. We show that a group regularized regression method is a special case of our approach. We study statistical guarantees of the proposed estimators such as sample complexities. Experimental results on synthetic and real-world datasets contaminated by various perturbations validate the superior performance of the proposed methods.

### Related Work

Bayesian networks have been widely adopted in a number of applications such as gene regulatory networks (Werhli et al., 2006), medical decision making (Kyrimi et al., 2020) and spam filtering (Manjusha and Kumar, 2010).

In addition to the score-based structure learning methods and constraint-based methods discussed in the introduction section, there are a third class of hybrid algorithms leveraging constraint-based methods to restrict the search space of a score-based method (Tsamardinos et al., 2006; Gasse et al., 2014; Nandy et al., 2018). There is also a flurry of work on score-based methods based on neural networks and continuous optimization (Zheng et al., 2018; Wei et al., 2020; Ng et al., 2020; Yu et al., 2021; Ng et al., 2022; Gao et al., 2022), motivated by differentiable characterization of acyclicitywithout rigorous theoretical guarantees. We refer the interested readers to survey papers (Dron and Maathuis, 2017; Heinze-Deml et al., 2018; Constantinou et al., 2021) for a more thorough introduction of DAG structure learning and causal discovery methods.

Recently, there is an emerging line of work proposing polynomial-time algorithms for DAG learning (Park and Raskutti, 2017; Ghoshal and Honorio, 2017, 2018; Chen et al., 2019; Bank and Honorio, 2020; Gao et al., 2020; Rajendran et al., 2021), among which Bank and Honorio (2020) particularly focuses on general discrete Bayesian networks without resorting to independence tests.

Learning a super-structure can be done by independence tests, graphical lasso or regression, as discussed in introduction. Given a super-structure, how to determine the orientation has been studied by Perrier et al. (2008); Ordyniak and Szeider (2013); Korhonen and Parviainen (2013); Loh and Buhlmann (2014); Ng et al. (2021); Ganian and Korchemna (2021).

DRO is a powerful framework emerging from operations research (Delage and Ye, 2010; Blanchet and Murthy, 2019; Shafieezadeh-Abadeh et al., 2019; Duchi and Namkoong, 2019) and has seen effective applications in many graph learning problems such as inverse covariance estimation (Nguyen et al., 2022), graphical lasso learning (Cisneros-Velarde et al., 2020), graph Laplacian learning (Wang et al., 2021), Markov random field (MRF) parameter learning (Fathony et al., 2018), MRF structure learning (Li et al., 2022) and causal inference (Bertsimas et al., 2022).

## 2 Preliminaries

We introduce necessary background and a baseline method for skeleton learning of Bayesian networks.

### Notations

We refer to \([n]\) as the index set \(\{1,2,,n\}\). For a vector \(^{n}\), we use \(x_{i}\) for its \(i\)-th element and \(_{}\) for the subset of elements indexed by \([n]\) with \([n]\{i\}\). For a matrix \(^{n m}\), we use \(A_{ij}\), \(_{i:}\) and \(_{:j}\) to denote its \((i,j)\)-th entry, \(i\)-th row and \(j\)-th column respectively. \(_{}\) represents the submatrix of \(\) with rows restricted to \(\) and columns restricted to \([m]\). We define a row-partitioned block matrix as \([_{1}_{2}_{k}]^{}^{_{i}n_{i} m}\) where \(_{i}^{n_{i} m}\). The \(_{p}\)-norm of a vector \(\) is defined as \(\|\|_{p}(_{i}|x_{i}|^{p})^{1/q}\) with \(||\) being the absolute value function. The \(_{p,q}\) norm of a matrix \(\) is defined as \(\|\|_{p,q}(_{j}\|_{:j}\|_{p}^{q})^{1/q}\). When \(p=q=2\), it becomes the Frobenius norm \(\|\|_{F}\). The operator norm is written as \(\|\|_{p,q}_{\|\|_{p}=1}\|\|_{q}\). The block matrix norm is defined as \(\|\|_{B,p,q}(_{i=1}^{k}\|_{i}\|_{p}^{q})^{1/q}\). The inner product of two matrices is designated by \(,^{} \) where \(^{}\) is the transpose of \(\). Denote by \(\) the tensor product operation. With a slight abuse of notation, \(||\) stands for the cardinality of a set \(\). We denote by \(\) (\(\)) a vector or matrix of all ones (zeros). Given a distribution \(\) on \(\), we denote by \(_{}\) the expectation under \(\). The least \(c\)-Lipschitz constant of a function \(f:\) with a metric \(c:\) is written as \(_{c}(f)_{c}(f)\) where \(_{c}(f)\{>0:_{1},_{2}|f(_{1} )-f(_{2})| c(_{1},_{2})\}\).

### Bayesian Network Skeleton Learning

Let \(\) be a discrete joint probability distribution on \(n\) categorical random variables \(:=\{X_{1},X_{2},,X_{n}\}\). Let \((,_{})\) be a DAG with edge set \(_{}\). We use \(X_{i}\) to represent the \(i\)-th random variable or node interchangeably. We call \((,)\) a Bayesian network if it satisfies the Markov condition, i.e., each variable \(X_{r}\) is independent of any subset of its non-descendants conditioned on its parents \(_{r}\). We denote the children of \(X_{r}\) by \(_{r}\), its neighbors by \(_{r}_{r}_{r}\) and the complement by \(_{r}[n]-_{r}-\{r\}\). The joint probability distribution can thus be factorized in terms of local conditional distributions:

\[()=(X_{1},X_{2},,X_{n})_{i=1}^{ n}(X_{i}|_{i}).\]

Let \(_{}(,_{})\) be the undirected graph that removes directionality from \(\). Given \(m\) samples \(\{^{(i)}\}_{i=1}^{m}\) drawn i.i.d. from \(\), the goal of skeleton learning is to estimate \(_{}\) from the samples.

We do not assume faithfulness (Spirtes et al., 2000) or any specific parametric form for the conditional distributions. The distribution is faithful to a graph if all (conditional) independencies that hold true in the distribution are entailed by the graph, which is commonly violated in practice (Uhler et al., 2013; Mabrouk et al., 2014). The unavailability of a true model entails a substitute model. Bank and Honorio (2020) propose such a model based on encoding schemes and surrogate parameters.

Assume that each variable \(X_{r}\) takes values from a finite set \(_{r}\) with cardinality \(|_{r}|>1\). For an indexing set \([n]\), define \(_{}:=_{i}|_{i}|-1\) and \(_{}^{+}:=_{i}|_{i}|\). The maximum cardinality minus one is defined as \(_{}:=_{i[n]}|_{i}|-1\). Let \(_{r}:=_{i_{_{r}}}\{_{[i-1]}+1, ,_{[i]}\}\) be indices for \(_{_{r}}\) in \(_{[n]}\) and its complement by \(_{r}^{c}:=[_{[n]}]-_{r}-\{_{[r-1]}+1,, _{[r]}\}\). Let \(:_{r}^{_{r}}\) be an encoding mapping with a bounded and countable set \(\). We adopt encoding schemes with \(=\{-1,0,1\}\) such as dummy encoding and unweighted effects encoding2 which satisfy a linear independence condition. With a little abuse of notation, we reuse \(\) for encoding any \(X_{r}\) and denote by \((_{})^{_{}}\) the concatenation of the encoded vectors \(\{(X_{i})\}_{i}\). Consider a linear structural equation model for each \(X_{r}\): \((X_{r})=^{}(_{F})+\), where \(^{}_{1}^{}_{r-1}^{}_{r+1}^{}_{n}^{}^{}^{_{ r}_{r}}\) with \(_{i}^{}^{_{i}_{r}}\) is a surrogate parameter matrix and \(^{_{r}}\) is a vector of errors not necessarily independent of other quantities. A natural choice of a fixed \(^{}\) is the solution to the following problem given knowledge of the true Bayesian network:

\[^{}_{}_{p}\| (X_{r})-^{}(_{})\|_{2}^{2} _{i}= i_{r}.\] (1)

Therefore \(^{}=(_{_{r}}^{};)\) with \(_{_{r}}^{}=_{p}[(_{F})_{ _{r}}(_{})_{_{r}}^{}]^ {-1}_{}[(_{F})_{_{r}}(X_{r})^{}]\) is the optimal solution by the first-order optimality condition assuming that \(_{p}[(_{})_{_{r}}( _{})_{_{r}}^{}]\) is invertible. The expression of \(_{_{r}}^{}\) captures the intuitions that neighbor nodes should be highly related to the current node \(r\) while the interaction among neighbor nodes should be weak for them to be distinguishable. We further assume that the errors are bounded:

**Assumption 1** (Bounded error).: For the error vector, \(\|\|_{}\) and \(\|_{p}[||]\|_{}\).

Note that the true distribution does not have to follow a linear structural equation model. Equation (1) only serves as a surrogate model to find technical conditions for successful skeleton learning, which will be discussed in a moment.

The surrogate model under the true distribution indicates that \(\|_{i}^{}\|_{2,2}>0 X_{i}_{_{r}}\). This suggests a regularized empirical risk minimization (ERM) problem to estimate \(^{}\):

\[}_{}():=_{}_{m}}\|(X_{r})-^{} (_{})\|_{2}^{2}+\|\|_{B,2,1},\] (2)

where \(>0\) is a regularization coefficient, the block \(_{2,1}\) norm is adopted to induce sparsity and \(}_{m}:=_{i=1}^{m}_{^{(i)}}\) stands for the empirical distribution with \(_{^{(i)}}\) being the Dirac point measure at \(^{(i)}\). This approach is expected to succeed as long as only neighbor nodes have a non-trivial impact on the current node, namely, \(\|_{i}^{}\|_{2,2}>0 X_{i}_{_{r}}\).

Define the risk of some \(\) under a distribution \(}\) as

\[R^{}}():=_{}} _{}():=_{}}\| (X_{r})-^{}(_{})\|_{2}^{2},\]

where \(_{}()\) is the squared loss function. The Hessian of the empirical risk \(R^{}_{m}}()\) is a block diagonal matrix \(^{2}R^{}_{m}}()} _{_{r}}^{_{r}_{r}_{r}_{r}}\), where \(}:=_{}_{m}}[(_{}) (_{})^{}]^{_{r}_{ r}}\) and \(_{_{r}}^{_{r}_{r}}\) is the identity matrix of dimension \(_{r}\). Similarly under the true distribution, \(:=_{}[(_{})( _{})(_{})^{}]\). As a result, \(\) is independent of the surrogate parameters \(^{}\) thus conditions on the Hessian translate to conditions on a matrix of cross-moments of encodings, which only depend on the encoding function \(\) and \(\).

In order for this baseline method to work, we make the following assumptions.

**Assumption 2** (Minimum weight).: For each node \(r\), the minimum norm of the true weight matrix \(^{}\) for neighbor nodes is lower bounded: \(_{i_{_{r}}}\|_{i}\|_{}>0\).

**Assumption 3** (Positive definiteness of the Hessian).: For each node \(r\), \(_{_{r},_{r}}>0\), or equivalently, \(_{}(_{_{r},_{r}})>0\) where \(_{}()\) denotes the minimum eigenvalue.

**Assumption 4** (Mutual incoherence).: For each node \(r\), \(\|_{}^{c}_{r}}_{_{r}^{-1} _{r}}^{-1}\|_{B,1,} 1-\) for some \(0< 1\).

Assumption 2 guarantees that the influence of neighbor nodes is significant in terms of a non-zero value bounded away from zero, otherwise they will be indistinguishable from those with zero weight. Assumption 3 ensures that Equation (2) yields a unique solution. Assumption 4 is a widely adopted assumption that controls the impact of non-neighbor nodes on \(r\)(Wainwright, 2009; Ravikumar et al., 2010; Daneshmand et al., 2014). One interpretation is that the rows of \(_{^{c}_{r}}\) should be nearly orthogonal to the rows of \(_{_{r}_{r}}\). Bank and Honorio (2020) show that these assumptions hold for common encoding schemes and finite-sample settings with high probability under mild conditions. They also show that incoherence is more commonly satisfied for the neighbors than the Markov blanket, which justifies the significance of skeleton learning.

Finally, we take the union of all the learned neighbor nodes for each \(r[n]\) by solving Equation (2) to get the estimated skeleton \(}:=(,}_{})\).

## 3 Method

As noted in Bank and Honorio (2020), due to model misspecification, even in the infinite sample setting, there is possible discrepancy between the ERM minimizer \(}\) and the true solution \(^{*}\), resulting in false or missing edges. In the high-dimensional setting (\(m<n\)) or the adversarial setting, this issue becomes more serious due to limited knowledge about the data-generating mechanism \(\).

In this section, we attempt to leverage a DRO framework to incorporate distributional uncertainty into the estimation process. We present efficient algorithms and study the theoretical guarantees of our methods. All technical proofs are deferred to the supplementary materials.

### Basic Formulation

Let \(\) be a measurable space of all states of the Bayesian network \((,)\), i.e., \(\). Let \(()\) be the space of all Borel probability measures on \(\). Denote by \(^{}:=\{():\}\) the space of all the allowed encodings.

Instead of minimizing the empirical risk and relying on regularization, we seek a distributionally robust estimator that optimizes the worst-case risk over an ambiguity set of distributions:

\[}_{}_{} _{}\|(X_{r})-^{}( _{})\|_{2}^{2},\] (3)

where \(()\) is an ambiguity set typically defined by a nominal probability measure \(}\) equipped with a discrepancy measure \((,)\) for two distributions \(_{}^{}(}):=\{ ():(,})\}\), where \(\) is known as the ambiguity radius or size. This way of uncertainty quantification can be interpreted as an adversary that captures out-of-sample effect by making perturbations on samples within some budget \(\). Some common statistical distances satisfy \((,)=0=\). In this case, if \(\) is set to zero, Equation (3) reduces to Equation (2) without regularization. We will show that the DRO estimator \(}\) can be found efficiently and encompasses attractive statistical properties with a judicious choice of \(\).

### Wasserstein DRO

Wasserstein distances or Kantorovich-Rubinstein metric in optimal transport theory can be interpreted as the cost of the optimal transport plan to move the mass from \(\) to \(\) with unit transport cost \(c:_{+}\). Denote by \(_{p}()\) the space of all \(()\) with finite \(p\)-th moments for \(p 1\). Let \((^{2})\) be the set of probability measures on the product space \(\). The \(p\)-Wasserstein distance between two distributions \(,_{p}()\) is defined as \(W_{p}(,):=_{(^{2})} _{^{2}}c^{p}(,^{})(, ^{})^{}:(,)=(),(,^{})= (^{})}.\)

We adopt the Wasserstein distance of order \(p=1\) as the discrepancy measure, the empirical distribution as the nominal distribution, and cost function \(c(,^{})=\|()-(^{})\|\) for some norm\(\|\|\). The primal DRO formulation becomes

\[}_{}_{_{}^{n_{p}}( _{m})}_{}\|(X_{r})-^{ }(_{})\|_{2}^{2}.\] (4)

According to Blanchet and Murthy (2019), the dual problem of Equation (4) can be written as

\[_{, 0}+_{i=1}^{m}_{ }\|(x_{r})-^{} (_{})\|_{2}^{2}-\|()-(^{(i)})\|.\] (5)

Strong duality holds according to Theorem 1 in Gao and Kleywegt (2022). The inner supremum problems can be solved independently for each \(^{(i)}\). Henceforth, we focus on solving it for some \(i[m]\):

\[_{}\|(x_{r})-^{ }(_{})\|_{2}^{2}-\|()- (^{(i)})\|.\] (6)

Equation (6) is a supremum of \(||\) convex functions of \(\), thus convex. Since \(^{}\) is a discrete set consisting of a factorial number of points (\(_{i[n]}_{i}\)), unlike the regression problem with continuous random variables in Chen and Paschalidis (2018), we may not simplify Equation (6) into a regularization form by leveraging convex conjugate functions because \(^{}\) is non-convex and not equal to \(^{_{[n]}}\). Moreover, since changing the value of \(x_{j}\) for some \(j\) is equivalent to changing \(^{}(_{})\) by a vector, unlike Li et al. (2022) where only a set of discrete labels rather than encodings are dealt with, there may not be a greedy algorithm based on sufficient statistics to find the optimal solution to Equation (6). In fact, let the norm be the \(_{1}\) norm, we can rewrite Equation (6) by fixing the values of \(\|()-(^{(i)})\|_{1}\):

\[_{,0 k_{[n]}^{},\|( )-(^{(i)})\|_{1}=k}\|(x_{r})- {W}^{}(_{})\|_{2}^{2}- k.\] (7)

If we fix \(k\), Equation (7) is a generalization of the 0-1 quadratic programming problem, which can be transformed into a maximizing quadratic programming (MAXQP) problem. As a result, Equation (6) is an NP-hard problem with proof presented in Proposition 11 in appendix. Charikar and Wirth (2004) develop an algorithm to find an \((1/ n)\) solution based on semi-definite programming (SDP) and sampling for the MAXQP problem. Instead of adopting a similar SDP algorithm with quadratic constraints, we propose a random and greedy algorithm to approximate the optimal solution, which is illustrated in Algorithm 1 in appendix, whose per-iteration time complexity is \((n^{2}m_{})\). It follows a simple idea that for a random node order \(\), we select a partial optimal solution sequentially from \(_{1}\) to \(_{n}\). We enumerate the possible states of the first node to reduce uncertainty. In practice, we find that this algorithm always finds the exact solution that is NP-hard to find for random data with \(n 12\) and \(_{} 5\) in most cases.

Since \(^{}\) is non-convex and not equal to \(^{_{[n]}}\), using convex conjugate functions will not yield exact equivalence between Equation (5) and a regularized ERM problem. However, we can draw such a connection by imposing constraints on the dual variables as shown by the following proposition:

**Proposition 5** (Regularization Equivalence).: _Let \(}:=[;-_{_{r}}]^{}^{_{[n] }_{r}}\) with \(_{r}=-_{_{r}}\). If \(_{[n]}\|}\|_{F}^{2}\), the Wasserstein DRO problem in Equation (5) is equivalent to_

\[_{}_{}_{m}}\|(X_{r})-^{}(_{})\|_{2}^{2}+_{[n]} \|}\|_{F}^{2},\]

_which subsumes a linear regression approach regularized by the Frobenius norm as a special case._

This suggests that minimizing a regularized empirical risk may not be enough to achieve distributional robustness. Note that exact equivalence between DRO and regularized ERM in Chen and Paschalidis (2018) requires \(^{}=^{d}\).

Now we perform non-asymptotic analysis on the proposed DRO estimator \(}\). First, we would like to show that the solution to the Wasserstein DRO estimator in Equation (4) is unique so that we refer to an estimator unambiguously. Note that Equation (4) is a convex optimization problem but not necessarily strictly convex, and actually never convex in the high-dimensional setting. However, given a sufficient number of samples, the problem becomes strictly convex and yields a unique solution with high probability. Second, we show that the correct skeleton \(_{}\) can be recovered with high probability. This is achieved by showing that, for each node \(X_{r}\), the estimator has zero weights for non-neighbor nodes \(_{r}\) and has non-zero weights for its neighbors \(_{r}\) with high confidence. Before presenting the main results, we note that they are based on several important lemmas.

**Lemma 6**.: _Suppose \(\) is separable Banach space and fix \(_{0}(^{})\) for some \(^{}\). Suppose \(c:_{ 0}\) is closed convex, \(k\)-positively homogeneous. Suppose \(f:\) is a mapping in the Lebesgue space of functions with finite first-order moment under \(_{0}\) and upper semi-continuous with finite Lipschitz constant \(_{c}(f)\). Then for all \( 0\), the following inequality holds with probability \(1\): \(_{_{r}^{W_{p}}(_{0}), (^{})} f(^{})(^{ })_{c}(f)+ f(^{})_{0}( ^{})\)._

Lemma 6 follows directly from Cranko et al. (2021) and allows us to obtain an upper bound between the worst-case risk and empirical risk. It is crucial for the following finite-sample guarantees.

**Lemma 7**.: _If Assumption 3 holds, for any \(_{}^{W_{p}}(}_{m})\), with high probability, \(_{_{r}_{r}}^{}\) is positive definite._

**Lemma 8**.: _If Assumption 3 and Assumption 4 hold, for any \(_{}^{W_{p}}(}_{m})\) and \((0,1]\), with high probability,_

\[\|_{_{r}_{r}}^{}(_{_{r }_{r}}^{})^{-1}\|_{B,1,} 1-.\]

The above two lemmas illustrate that Assumption 3 and Assumption 4 hold in the finite-sample setting. Let the estimated skeleton, neighbor nodes and the complement be \(}(,}_{})\), \(}_{r}\) and \(}_{r}\) respectively. We derive the following guarantees for the proposed Wasserstein DRO estimator.

**Theorem 9**.: _Given a Bayesian network \((,)\) of \(n\) categorical random variables and its skeleton \(_{}(,_{})\). Assume that the condition \(\|^{*}\|_{B,2,1}\) holds for some \(>0\) associated with an optimal Lagrange multiplier \(_{B}^{*}>0\) for \(^{*}\) defined in Equation (1). Suppose that \(}\) is a DRO risk minimizer of Equation (4) with a Wasserstein distance of order \(1\) and an ambiguity radius \(=_{0}/m\) where \(m\) is the number of samples drawn i.i.d. from \(\). Under Assumptions 1, 2, 3, 4, if the number of samples satisfies_

\[m=(++}) ^{2}_{}^{4}_{[n]}^{3}}{(^{2},1)}),\]

_where \(C\) only depends on \(\), \(\), and if the Lagrange multiplier satisfies_

\[}}{}<_{B}^{*}<}}}},\]

_then for any \((0,1]\), \(r[n]\), with probability at least \(1-\), the following properties hold:_

* _The optimal estimator_ \(}\) _is unique._
* _All the non-neighbor nodes are excluded:_ \(_{r}}_{r}\)_._
* _All the neighbor nodes are identified:_ \(_{r}}_{r}\)_._
* _The true skeleton is successfully reconstructed:_ \(_{}=}_{}\)_._

Proof sketch.: The main idea in the proof follows that in the lasso estimator (Wainwright, 2009). Based on a primal-dual witness construction method and Lemma 8, it can be shown that if we control \(_{B}^{*}\), a solution constrained to have zero weight for all the non-neighbor nodes is indeed optimal. Furthermore, Lemma 7 implies that there is a unique solution given information about the true neighbors. The uniqueness of the aforementioned optimal solution without knowing the true skeleton is then verified via convexity and a conjugate formulation of the block \(_{2,1}\) norm. Hereby we have shown that the optimal solution to Equation (4) is unique and excluding all the non-neighbor nodes. Next, we derive conditions on \(_{B}^{*}\) for the estimation bias \(\|}-^{*}\|_{B,2,}</2\) to hold, which allows us to recover all the neighbor nodes. In such manner, applying the union bound over all the nodes \(r[n]\) leads to successful exact skeleton discovery with high probability.

The results in Theorem 9 encompass some intuitive interpretations. Compared to Theorem 1 in Bank and Honorio (2020), we make more explicit the relationship among \(m\), \(_{B}^{*}\) and \(\). On one hand, the lower bound of \(_{B}^{*}\) ensures that a sparse solution excluding non-neighbor nodes is obtained. A large error magnitude expectation \(\) therefore elicits stronger regularization. On the other hand, the upper bound \(_{B}^{*}\) is imposed to guarantee that all the neighbor nodes are identified with less restriction on \(\). There is naturally a trade-off when choosing \(\) in order to learn the exact skeleton. The sample complexity depends on cardinalities \(_{[n]}\), confidence level \(\), the number of nodes \(n\), the ambiguity level \(_{0}\) and assumptions on errors. The dependence on \(\) indicates that higher uncertainty caused by larger error norms demands more samples whereas the dependence on \(^{-2}\) results from the lower bound condition on \(_{B}^{*}\) with respect to \(\). The ambiguity level is set to \(_{0}/m\) based on the observation that obtaining more samples reduces ambiguity of the true distribution. In practice, we find that \(_{0}\) is usually small thus negligible. Note that the sample complexity is polynomial in \(n\). Furthermore, if we assume that the true graph has a bounded degree of \(d\), we find that \(m=(+(n/)+ n+ _{})^{2}_{}^{2}d^{3}}{(^{2},1)})\) is logarithmic with respect to \(n\), consistent with the results in Wainwright (2009).

We introduce constants \(\) and \(_{B}^{*}\) in order to find a condition for the statements in Theorem 9 to hold. If there exists a \(\) incurring a finite loss, we can always find a solution \(}\) and let \(_{}}}_{B,2,1}\) be the maximum norm of all solutions. Imposing \(_{B,2,1}\) is equivalent to the original problem. By Lagrange duality and similar argument for the lasso estimator, there exists a \(_{B}^{*}\) that finds all the solutions with \(}_{B,2,1}=\). Therefore we have a mapping between \(\) and \(_{B}^{*}\).

### Kullback-Leibler DRO

In addition to optimal transport, \(\)-divergence is also widely used to construct an ambiguity set for DRO problems. We consider the following definition of a special \(\)-divergence called the KL divergence: \(D()_{}()}{()}()\), where \(()\) is absolutely continuous with respect to \(()\) and \(()}{()}\) denotes the Radon-Nikodym derivative. A noteworthy property of ambiguity sets based on the KL divergence is absolute continuity of all the candidate distributions with respect to the empirical distribution. It implies that if the true distribution is an absolutely continuous probability distribution, the ambiguity set will never include it. In fact, any other point outside the support of the nominal distribution remains to have zero probability. Unlike the Wasserstein metric, the KL divergence does not measure some closeness between two points, nor does it have some measure concentration results. However, we argue that adopting the KL divergence may bring advantages over the Wasserstein distance since the Bayesian network distribution we study is a discrete distribution over purely categorical random variables. Moreover, as illustrated below, adopting the KL divergence leads to better computational efficiency.

Let \(_{}^{D}(}_{m})\) be the ambiguity set, the dual formulation of Equation (3) follows directly from Theorem 4 in Hu and Hong (2013):

\[_{,>0}_{i[m]}e^{ (x_{r}^{(i)})-^{}(_{r}^{(i)} )_{2}^{2}/}+,\]

which directly minimizes a convex objective. In contrast to the approximate Wasserstein estimator, this KL DRO estimator finds the exact solution to the primal problem by strong duality.

The worst-case risk over a KL divergence ball can be bounded by variance (Lam, 2019), similar to Lipschitz regularization in Lemma 6. Based on this observation, we derive the following results:

**Theorem 10**.: _Suppose that \(}\) is a DRO risk minimizer of Equation (4) with the KL divergence and an ambiguity radius \(=_{0}/m\). Given the same definitions of \((,)\), \(_{}\), \(\), \(_{B}^{*}\), \(m\) in Theorem 9. Under Assumptions 1, 2, 3, 4, if the number of samples satisfies_

\[m=(+(n/)+_{[n]} )^{2}_{}^{4}_{}^{3}}{(^{2},1)}).\]

_where \(C\) depends on \(\), \(\) while independent of \(n\), and if the Lagrange multiplier satisfies the same condition as in Theorem 9, then for any \((0,1]\), \(r[n]\), with probability at least \(1-\), the properties (a)-(d) in Theorem 9 hold._The sample complexities in Theorem 9 and Theorem 10 differ in the constant \(C\) due to the difference between the two probability metrics. Note that \(C\) is independent of \(n\) in both methods. The dependency on \(1/(_{B}^{})^{2}\) is absorbed in the denominator because we require that \(_{B}^{}-16_{}/>0\). The sample complexities provide a perspective of our confidence on upper bounding the true risk in terms of the ambiguity radius. \(_{0}\) serves as our initial guess on distributional uncertainty and increases the sample complexity only slightly because it is usually dominated by other terms in practice: \((n/)\). Even though the samples are drawn from an adversarial distribution with a proportion of noises, the proposed methods may still succeed as long as the true distribution can be made close to an upper confidence bound.

## 4 Experiments

We conduct experiments3 on benchmark datasets (Scutari, 2010) and real-world datasets (Malone et al., 2015) perturbed by the following contamination models:

* **Noisefree model.** This is the baseline model without any noises.
* **Huber's contamination model.** In this model, each sample has a fixed probability of \(\) to be replaced by a sample drawn from an arbitrary distribution.
* **Independent failure model.** Each entry of a sample is independently corrupted with probability \(\).

We conduct all experiments on a laptop with an Intel Core i7 2.7 GHz processor. We adopt the proposed approaches based on Wasserstein DRO and KL DRO, the group norm regularization method (Bank and Honorio, 2020), the MMPC algorithm (Tsamardinos et al., 2006) and the GRaSP algorithm (Lam et al., 2022) for skeleton learning. Based on the learned skeletons, we infer a DAG with the hill-climbing (HC) algorithm (Tsamardinos et al., 2006). For the Wasserstein-based method, we leverage Adam (Kingma and Ba, 2014) to optimize the overall objective with \(_{1}=0.9\), \(_{2}=0.990\), a learning rate of \(1.0\), a batch size of \(500\), a maximum of \(200\) iterations for optimization and \(10\) iterations for approximating the worst-case distribution. For the KL-based and standard regularization methods, we use the L-BFGS-B (Byrd et al., 1995) optimization method with default parameters. We set the cardinality of the maximum conditional set to \(3\) in MMPC. The Bayesian information criterion (BIC) (Neath and Cavanaugh, 2012) score is adopted in the HC algorithm. A random mixture of \(20\) random Bayesian networks serves as the adversarial distribution for both contamination models. All hyper-parameters are chosen based on the best performance on random Bayesian networks with the same size as the input one. Each experimental result is taken as an average over \(10\) independent runs. When dealing with real-world datasets, we randomly split the data into two halves for training and testing.

We use the F1-score, or the Dice coefficient (regarding the label of each edge indicating its presence as a binary random variable and considering all possible edges), to evaluate performance on benchmark datasets and BIC for real-world datasets. The results are reported in Table 1 and more results can be found in Table 2 in appendix. We observe that in most cases the proposed DRO methods are comparable to MMPC and MMHC, which are generally the best-performing methods in Bank and Honorio (2020). We illustrate in Figure 1 the results on earthquake by varying the number of samples, corruption level and ambiguity radius or regularization coefficient. Figure 1 (a) suggests that all the methods perfectly recover the true skeleton given more than \(2,000\) samples. The results in Figure 1 (b-c) indicate that, in highly uncertain settings, Wasserstein DRO as well as KL DRO is superior to other approaches. Meanwhile, Table 1 and Figure 1 (a) suggest that the DRO methods and the regularized ERM approach are comparable to MMPC and GRaSP when clean data is given. The sensitivity analysis (Figure 1 (d)) suggests a trade-off between robustness and target performance (F1-score in our case). All the approaches have similar execution time except that Wasserstein DRO is several times slower due to the combinatorial sub-problem of computing the worst-case distribution.

## 5 Discussion and Conclusion

In this paper, we put forward a distributionally robust optimization method to recover the skeleton of a general discrete Bayesian network. We discussed two specific probability metrics, developed

[MISSING_PAGE_FAIL:10]