# Finding Local Minima Efficiently in Decentralized Optimization

Wenhan Xian

Computer Science

University of Maryland College Park

wxian1@umd.edu

&Heng Huang

Computer Science

University of Maryland College Park

heng@umd.edu

This work was partially supported by NSF IIS 1838627, 1837956, 1956002, 2211492, CNS 2213701, CCF 2217003, DBI 2225775.

###### Abstract

In this paper we study the second-order optimality of decentralized stochastic algorithm that escapes saddle point efficiently for nonconvex optimization problems. We propose a new pure gradient-based decentralized stochastic algorithm PEDESTAL with a novel convergence analysis framework to address the technical challenges unique to the decentralized stochastic setting. Our method is the first decentralized stochastic algorithm to achieve second-order optimality with non-asymptotic analysis. We provide theoretical guarantees with the gradient complexity of \((^{-3})\) to find \(O(,)\)-second-order stationary point, which matches state-of-the-art results of centralized counterparts or decentralized methods to find first-order stationary point. We also conduct two decentralized tasks in our experiments, a matrix sensing task with synthetic data and a matrix factorization task with a real-world dataset to validate the performance of our method.

## 1 Introduction

Decentralized optimization is a class of distributed optimization that trains models in parallel across multiple worker nodes over a decentralized communication network. Decentralized optimization has recently attracted increased attention in machine learning and emerged as a promising framework to solve large-scale tasks because of its capability to reduce communication costs. In the conventional centralized paradigm, all worker nodes need to communicate with the central node, which results in high communication cost on the central node when the number of nodes is large or the transmission between the center and some remote nodes suffers network latency. Conversely, decentralized optimization avoids these issues since each worker node only communicates with its neighbors.

Although decentralized optimization has shown advantageous performance in many previous works (Lian et al. (2017); Tang et al. (2018)), the study of second-order optimality for decentralized stochastic optimization algorithms is still limited. Escaping saddle point and finding local minima is a core problem in nonconvex optimization since saddle point is a category of first-order stationary point that can be reached by many gradient-based optimizers such as gradient descent but it is not the expected point to minimize the objective function.

Perturbed gradient descent (Jin et al. (2017)) and negative curvature descent (Xu et al. (2018); Allen-Zhu and Li (2018)) are two primary pure gradient-based methods (not involving second-order derivatives) to achieve second-order optimality. Typically, perturbed gradient descent method is composed of a descent phase and an escaping phase. If the norm of gradient is large, the algorithm will run the descent phase as normal. Otherwise it will run the escaping phase to discriminate whether the candidate first-order stationary point is a saddle point or local minimum. Negative curvaturedescent method escapes saddle point by computing the direction of negative curvature at the candidate point. If it is categorized as a saddle point then the algorithm will update along the direction of negative curvature. Generally it involves a nested loop to perform the negative curvature subroutine.

Currently, the solution to the second-order optimality of decentralized problem in deterministic setting has been proposed. Perturbed Decentralized Gradient Tracking (PDGT) (Tziotis et al. (2020)) is a decentralized deterministic algorithm adopting the perturbed gradient descent strategy to achieve second-order stationary point. However, it is expensive to compute full gradients for large machine learning models. It is crucial to propose a stochastic algorithm to obtain second-order optimality for decentralized problems. Besides, there are some drawbacks of PDGT to make it less efficient and hard to be generalized to the stochastic setting. These drawbacks are also the key challenges to achieve second-order optimality for decentralized algorithms, which are listed as follows:

(1) PDGT runs fixed numbers of iterations in descent phase and escaping phase such that the phases of all nodes can be changed simultaneously. This strategy works because the descent is easy to be estimated in deterministic setting. Nonetheless, the exact descent of stochastic algorithm over a fixed number of iterations is hard to be bounded because of randomness and noises. If the fixed number is not large enough it is possible that the averaged model parameter is not a first-order stationary point. If the fixed number is as large as the expected number of iterations to achieve first-order stationary point, the algorithm will become less efficient as it is probably stuck at a saddle point for a long time before drawing the perturbation, especially in the second and later descent phase. Specifically, applying fixed number of iterations in each phase results in the complexity of at least \((^{-4.5})\) (see Appendix D), which is higher than \((^{-3})\) of our method. Therefore, we are motivated to propose an algorithm that can change phases _adaptively_ (based on runtime gradient norm) and _independently_ (not required to consider status on other nodes or notify other nodes).

(2) In PDGT the perturbations on all nodes are drawn from the same random seed. Besides, a coordinating protocol involving broadcast and aggregation is used to compute the averaged model parameter and the descent of overall loss function to discriminate the candidate point. These strategies together with the fixed number of iterations act as a hidden coordinator to make PDGT discriminate saddle point in the same way as centralized algorithms. However, when the number of worker nodes is large it is time-consuming to perform broadcast or aggregation over the whole decentralized network. Moreover, when generalized to stochastic setting the changing of phase is not guaranteed to be synchronized. Additionally, we will note in the Supplementary Material that the consensus error \(_{i=1}^{n}\|x_{t}^{(i)}-_{t}\|^{2}\) is another factor to impact the effectiveness of perturbed gradient descent, which is not present in centralized problems. All above issues are theoretical difficulties to study and ensure second-order optimality for decentralized stochastic algorithms.

(Vlaski and Sayed (2020)) proves the theoretical guarantee of second-order optimality for decentralized stochastic algorithm with perturbed gradient descent. However, it does not provide a non-asymptotic analysis to estimate the convergence rate or gradient complexity. The effectiveness of the result relies on a sufficiently small learning rate, and it does not present a specific algorithm. The analysis is based on the assumption that the iteration formula can be approximated by a centralized update scheme when the learning rate is small enough. Nevertheless, in practice it is difficult to maintain an ideally small learning rate, and the iterative update process can be more complex as previously mentioned. To our best knowledge, the second-order optimality issue of decentralized stochastic algorithm with non-asymptotic analysis is still not solved. Therefore, we are motivated to study this important and challenging issue and raise the following questions:

_Can we design a decentralized stochastic optimization algorithm with non-asymptotic analysis to find local minima efficiently? Is the algorithm still effective to discriminate saddle point even if each node can change its phase adaptively and independently without any coordinating protocols?_

The answer is affirmative. In this paper, we propose a novel gradient-based algorithm named PFturbed DEcentralized STORM ALgorithm (PEDESTAL) which is the first decentralized stochastic algorithm to find second-order stationary point. We adopt perturbed gradient descent to ensure the second-order optimality and use STORM (Cutkosky and Orabona (2019)) estimator to accelerate the convergence. We provide completed convergence analysis to guarantee the second-order optimality theoretically. More details about the reason of choosing perturbed gradient descent and technical difficulties are discussed in Section 3.2. Next we will introduce the problem setup in this paper.

We focus on the following decentralized optimization problem:

\[_{x}f(x)=_{i=1}^{n}f_{i}(x),\;f_{i}(x)=_{ D_{ i}}F_{i}(x,)\] (1)

where \(n\) is the number of worker nodes in the decentralized network and \(f_{i}\) is the local loss function on \(i\)-th worker node. Here \(f_{i}\) is supposed to take the form of stochastic expectation over local data distribution \(D_{i}\), which covers a variety of optimization problems including finite-sum problem and online problem. Data distributions on different nodes are allowed to be heterogeneous. The objective function \(f\) is nonconvex such that saddle points probably exist.

The goal of our method is to find \(O(,_{H})\)-second-order stationary point of problem 1, which is defined by the point \(x\) satisfying \(\| f(x)\|\) and \( eig(^{2}f(x))-_{H}\), where \(eig()\) represents the eigenvalues. The classic setting is \(_{H}=\).

We summarize the contributions of this paper as follows:

* We propose a novel algorithm PEDESTAL, which is the first decentralized stochastic gradient-based algorithm to achieve second-order optimality with non-asymptotic analysis.
* We provide a new analysis framework to support changing phases adaptively and independently on each node without any coordinating protocols involving broadcast or aggregation. We also address certain technical difficulties unique to decentralized optimization to justify the effectiveness of perturbed gradient descent in discriminating saddle point.
* We prove that our PEDESTAL achieves the gradient complexity of \((^{-3}+_{H}^{-8}+^{4}_{H}^{-11})\) to find \(O(,_{H})\)-second-order stationary point. Particularly, PEDESTAL achieves the gradient complexity of \((^{-3})\) in the classic setting \(_{H}=\), which matches state-of-the-art results of centralized counterparts or decentralized methods to find first-order stationary point.

## 2 Related Work

In this section we will introduce the background of related works. The comparison of important features is shown in Table 1. Here \(()\) refers to the big \(O\) notation that hides the logarithmic terms.

### Decentralized Algorithms for First-Order Optimality

Decentralized optimization is an efficient framework to solve problem 1 collaboratively by multiple worker nodes. In each iteration a worker node only needs to communicate with its neighbors. One of the best-known decentralized stochastic algorithm is D-PSGD (Lian et al. (2017)), which integrates average consensus with local stochastic gradient descent steps and shows competitive result to centralized SGD. The ability to address Non-IID data is a limitation of D-PSGD and some variants of D-PSGD are studied to tackle the data heterogeneity issue, such as \(D^{2}\)(Tang et al. (2018)) by storing previous status and GT-DSGD (Xin et al. (2021b)) by using gradient tracking (Xu et al. (2015), Lorenzo and Scutari (2016)). D-GET (Sun et al. (2020)) and D-SPIDER-SFO (Pan et al. (2020)) improve the gradient complexity of D-PSGD from \(O(^{-4})\) to \(O(^{-3})\) by utilizing variance reduced gradient estimator SPIDER (Fang et al. (2018)). GT-HSGD also achieves gradient complexity of \(O(^{-3})\) by combining gradient tracking and STORM gradient estimator (Cutkosky and Orabona (2019)). SPIDER requires a large batchsize of \(O(^{-1})\) on average and a mega batchsize of \(O(^{-2})\) periodically. In contrast, STORM only requires a large batch in the first iteration. After that the batchsize can be as small as \(O(1)\), which makes STORM more efficient to be implemented in practice.

### Centralized Algorithms for Second-Order Optimality

Perturbed gradient descent is a simple and effective method to escape saddle points and find local minima. PGD (Jin et al. (2017)) is the representative of this family of algorithms, which achieves second-order optimality in deterministic setting. It draws a perturbation when the gradient norm is small. If this point is a saddle point, the loss function value will decrease by a certain threshold within a specified number of iterations (_i.e._, breaking the escaping phase) with high probability. Otherwise, the candidate point is regarded as a second-order stationary point. In stochastic setting, Perturbed SGD perturbs every iteration and suffers a high gradient complexity of \(O(^{-8})\) to achieve \(O(,)\)-second-order stationary point and the gradient complexity hides a polynomial factor of dimension \(d\). CNC-SGD requires a Correlated Negative Curvature assumption and the gradient complexity of \((^{-5})\) to achieve the classic second-order optimality. SSRGD (Li (2019)) adopts the same two-phase scheme as PGD but uses the moving distance as the criterion to discriminate saddle point in the escaping phase. It also takes advantage of variance reduction to improve the gradient complexity to \((^{-3.5})\). Pullback (Chen et al. (2022)) proposes a pullback step to further enhance the gradient complexity to \((^{-3})\), which matches the best result of reaching first-order stationary point.

### Stochastic Gradient Descent

A branch of study of stochastic gradient descent argues that SGD can avoid saddle point under certain conditions. However, that is completely different from the problem we focus on. In this paper we propose a method that can find local minima effectively for a general problem 1, while escaping saddle point by stochastic gradient itself depends on some additional assumptions. For example, (Mertikopoulos et al. (2020)) requires the noise of gradient should be uniformly excited. According to our experimental result in Section 5, we can see in some cases stochastic gradient descent cannot escape saddle point effectively or efficiently. Besides, the gradient noise in variance reduced methods is reduced in order to accelerate the convergence. Our experimental results indicate that the gradient noise in variance reduced algorithms is not as good as SGD to serve as the perturbation to avoid saddle point. Therefore, it is necessary to study the second-order stationary point for variance reduced algorithms so as to enable both second-order optimality and fast convergence.

## 3 Method

### Algorithm

In this section, we will introduce our PEDESTAL algorithm, which is demonstrated in Algorithm 1. Suppose there are \(n\) worker nodes in the decentralized communication network connected by a weight matrix \(W\). The initial value of model parameters on all nodes are identical and equal to \(x_{0}\). \(x_{t}^{(i)}\), \(v_{t}^{(i)}\) and \(y_{t}^{(i)}\) are the model parameter, gradient estimator and gradient tracker on the \(i\)-th worker node in iteration \(t\). \(z_{t}^{(i)}\) is the temporary model parameter that is awaiting communication. \(_{t}\), \(_{t}\) and \(_{t}\) are corresponding mean values over all nodes. Counter \(esc^{(i)}\) counts the number of iterations in the

   Name & Averaged Batchsize & Gradient Complexity & Classic Setting \\  D-PSGD [(12)] & \(O(1)\) & \(O(^{-4})\) & - \\ GT-DSGD [(22)] & \(O(1)\) & \(O(^{-4})\) & - \\ D-GET [(16)] & \(O(^{-1})\) & \(O(^{-3})\) & - \\ D-SPIDER-SFO [(15)] & \(O(^{-1})\) & \(O(^{-3})\) & - \\ GT-HSGD [(21)] & \(O(1)\) & \(O(^{-3})\) & - \\  SGD+Neon2 [(1)] & \(O(1)\) & \((^{-4}+^{-2}_{H}^{-3}+_{H}^{-5})\) & \((^{-4})\) \\ SCSG+Neon2 [(1)] & \(O(^{-0.5})\) & \((^{-10/3}+^{-2}_{H}^{-3}+_{H}^{-5})\) & \((^{-3.5})\) \\ Natasha2+Neon2 [(1)] & \(O(^{-2})\) & \((^{-3.25}+^{-3}_{H}^{-1}+_{H}^{-5})\) & \((^{-3.5})\) \\ SPIDER-SFO\({}^{+}\)[(5)] & \(O(^{-1})\) & \((^{-3}+^{-2}_{H}^{-2}+_{H}^{-5})\) & \((^{-3})\) \\ Perturbed SGD [(6)] & \(O(1)\) & \(O(^{-4}+_{H}^{-16})\) & \(O(^{-8})\) \\ CNC-SGD [(4)] & \(O(1)\) & \((^{-4}+_{H}^{-10})\) & \((^{-5})\) \\ SSRGD [(11)] & \(O(^{-1})\) & \((^{-3}+^{-2}_{H}^{-3}+^{-1}_{H }^{-4})\) & \((^{-3.5})\) \\ Pullback [(2)] & \(O(^{-1})\) & \((^{-3}+_{H}^{-6})\) & \((^{-3})\) \\  PDGT [(18)] & Full & - & - \\ PEDESTAL-S (ours) & \(O(1)\) & \((^{-3})\), \(_{H}^{0.2}\) & - \\ PEDESTAL (ours) & \(O(^{-3/4})\) & \((^{-3}+_{H}^{-8}+^{4}_{H}^{-11})\) & \((^{-3})\) \\   

Table 1: The comparison of important properties between related algorithms and our PEDESTAL. Column “Averaged Batchsize” is computed when \(_{H}=\). Column “Classic Setting” refers to the gradient complexity under the classic condition \(_{H}=\). The first group of algorithms are decentralized methods achieving first-order optimality. The second group of algorithms are centralized methods achieving second-order optimality. The last group of algorithms are decentralized methods achieving second-order optimality. PEDESTAL-S is a special case of PEDESTAL with \(O(1)\) batchsize. The complexity of PDGT is not shown because it is not stochastic.

current escaping phase on the \(i\)-th worker node, which is also the indicator of current phase. When it runs the descent phase on the \(i\)-th worker node \(esc^{(i)}\) is set to \(-1\); otherwise \(esc^{(i)} 0\).

In the first iteration, the gradient estimator is computed based on a large batch size with \(b_{0}\). Beginning from the second iteration, the gradient estimator \(v_{t}^{(i)}\) is calculated by small mini-batch of samples according to the update rule of STORM, which can be formulated by line 6 in Algorithm 1 where \(\) is a hyperparameter of STORM algorithm. Notation \( F_{i}(x_{t}^{(i)},_{t}^{(i)})\) represents the stochastic gradient obtained from a batch of samples \(_{t}^{(i)}\), which can be written as \( F_{i}(x_{t}^{(i)},_{t}^{(i)})=(1/|_{t}^{(i)}|)_{j_{t}^{ (i)}}F_{i}(x_{t}^{(i)},j)\).

After calculating \(v_{t}^{(i)}\), each worker node communicates with its neighbors and update the gradient tracker \(y_{t}^{(i)}\). Inspired by the framework of Perturbed Gradient Descent, our PEDESTAL method also consists of two phases, the descent phase and the escaping phase. If worker node \(i\) is in the descent phase and the norm \(\|y_{t}^{(i)}\|\) is smaller than the given threshold \(C_{v}\), then it will draw a perturbation \(\) uniformly from \(B_{0}(r)\) and update \(z_{t}^{(i)}=x_{t}^{(i)}+\). The phase is switched to escaping phase and \(esc^{(i)}\) is set to \(0\). Anchor \(^{(i)}=x_{t}^{(i)}\) is saved and will be used to discriminate whether the escaping phase is broken. After this iteration counter \(esc^{(i)}\) will be added by \(1\) in each following iteration until the moving distance from the anchor on \(i\)-th worker node (_i.e._, \(\|x_{t}^{(i)}-^{(i)}\|\)) is larger than threshold \(C_{d}\) for some \(t\), which breaks the escaping phase and turn back to descent phase. If the condition of drawing perturbation is not satisfied, \(z_{t}^{(i)}\) is updated by \(z_{t}^{(i)}=x_{t}^{(i)}- y_{t}^{(i)}\) no matter which phase is running currently.

If the \(i\)-th worker node's counter \(esc^{(i)}\) is larger than the threshold \(C_{T}\), it indicates that \(_{t-C_{T}}\) is a candidate second-order stationary point. When at least \(\) nodes satisfy the condition \(esc^{(i)} C_{T}\), the algorithm is terminated. Notice that the fraction is set to \(\) for convenience in the convergence analysis. Our algorithm also works for other constant fractions. From Algorithm 1 we can see the decision of changing phases on each node only depends on its own status, which is adaptive and independent. Coordinating protocol including broadcast or aggregation is not required.

### Discussion

Here we will discuss the insight of the algorithm design and compare the differences between our method and related works. Some novel improvements are the key to the questions in Section 1.

#### 3.2.1 Perturbed Gradient Descent or Negative Curvature Descent

Perturbed gradient descent and negative curvature descent are two of the most widely used pure first-order methods to find second-order stationary points. In PEDESTAL algorithm, we adopt the strategy of perturbed gradient descent rather than negative curvature descent because of the following reasons. First, negative curvature descent methods such as Neon (Xu et al. (2018)) and Neon2 (Allen-Zhu and Li (2018)) involves a nested loop to execute the negative curvature subroutine to recognize if a first-order stationary point is a local minimum. However, in decentralized setting, it is possible that the gradient norms on some nodes are smaller than the threshold while others are not. Therefore, some nodes will execute the negative curvature subroutine but its neighbors may not. In this case neighbor nodes need to wait for the nodes running negative curvature subroutines and there will be idle time on neighbor nodes. Besides, the analysis of negative curvature descent methods rely on the precision of the negative curvature direction. It is unknown if the theoretical results are still effective when only a fraction of nodes participate in the computation of negative curvature direction while the others use the gradient. In contrast, perturbed gradient descent only requires a simple operation of drawing perturbation, which is more suitable for decentralized algorithms.

#### 3.2.2 Stepsize and Batchsize

In Pullback, a dynamic stepsize \(_{t}=/\|v_{t}\|\) in the descent phase where \(=O()\) and \(v_{t}\) is the gradient estimator. This stepsize is originated from SPIDER (Fang et al. (2018)) which ensures its convergence by bounding the update distance \(\|x_{t+1}-x_{t}\|\). In the escaping phase, Pullback adopts a larger stepsize of \(O(1)\) in the escaping phase and a special pullback stepsize in the last iteration, which is the key to improve the gradient complexity. Different from Pullback, in Algorithm 1 we adopt a consistent stepsize such that it keeps invariant even if phase changes and all nodes always use the same stepsize. If there is no perturbation in iteration \(t\), we have \(_{t+1}=_{t}-_{t}\), which is important to the convergence analysis. We discard the strategy in Pullback for two reasons. First, the gradient normalization will probably cause divergence issues in decentralized optimization because in centralized algorithm the gradient direction is \(v_{t}/\|v_{t}\|\), which is equivalent to \(v_{c}=_{i=1}^{n}v_{t}^{(i)}/\|_{i=1}^{n}v_{t}^{(i)}\|\). However, in decentralized algorithm the average of \(v_{t}^{(i)}\) is not available on local nodes. If the gradient normalization is done locally, we will get \(v_{d}=_{t}^{n}v_{t}^{(i)}/\|v_{t}^{(i)}\|\), which is different to \(v_{c}\) and the error is hard to be estimated. Actually, both D-GET and D-SPIDER-SFO adopt the constant stepsize in SpiderBoost (Wang et al. (2019)) to avoid performing the gradient normalization step. SPIDER needs the gradient normalization because \(\|x_{t+1}-x_{t}\|\) is required to be small in the proof, while SpiderBoost improves the proof to bound \(\|x_{t+1}-x_{t}\|\) by \(\|v_{t}\|\) which is canceled eventually. In our analysis we also adopt the strategy in SpiderBoost. Second, in our algorithm the changing of phase is occurred independently on each node. The phase-wise stepsize and pullback strategy will lead to different stepsizes among all nodes in one iteration, which will also cause potential convergence issues.

In (Chen et al. (2022)), two versions of Pullback are proposed, _i.e.,_ Pullback-SPIDER and Pullback-STORM using SPIDER and STORM as the gradient estimator respectively. As introduced previously, one of the advantages of STORM is avoiding large batchsize. Nonetheless, Pullback-STORM adopt a large batchsize of \(O(^{-1})\) in each iteration, which violates the original intention of STORM. Besides, from Table 1 we can see all algorithms achieving second-order optimality with \((^{-3})\) gradient complexity require a large batchsize of \(O(^{-1})\). Therefore, we propose a small batch version named PEDESTAL-S as a special case of PEDESTAL that only requires an averaged batchsize of \(O(1)\).

#### 3.2.3 Conditions of Termination

As a result of applying gradient tracking, we can bound \(_{i=1}^{n}\|y_{t}^{(i)}-_{t}\|^{2}\) by \(O(^{2})\). Even though we have such an estimation, it is still possible that the norm \(\|y_{t}^{(i)}\|\) is as large as \(O()\) on some nodes when the entire decentralized network has already achieved optimality. Therefore, waiting for all nodes to reach second-order stationary point is not an efficient strategy. This is the reason why we terminate our algorithm when only a fraction of worker nodes satisfy \(esc^{(i)} C_{T}\).

In SSRGD and Pullback, there is an upper bound of iteration numbers in the escaping phase. If the escaping phase is not broken in this number of iterations then the candidate point is regarded as a second-order stationary point. If the escaping phase is broken, then the averaged moving distance is larger than a threshold and the loss function will be reduced by \(O(^{2})\) on average. This strategy guarantees that the algorithm will terminate with a certain gradient complexity. However, in our algorithm worker nodes do not enter escaping phase simultaneously and thus we do not set such an upper bound. In this case the averaged moving distance cannot be lower bounded as \(C_{T}\) has no upper bound. Fortunately, we can complete our analysis by a different novel framework (see the proof outline in the Appendix). An alternative solution is to stop the update on the node that has run certain number of iterations in the escaping phase while the algorithm will continue. But that solution is also challenging since the relation between the first-achieved local optimal solution and the final global optimal solution is unknown and the analysis is non-trivial.

One remaining issue of the current termination strategy is that it involves the global knowledge of how many worker nodes satisfying the termination condition. One solution is to run an additional process to track this global value. The cost of transmitting Boolean values is much less expensive than broadcasting the model. Another solution is to set a maximum iteration in practice. Generally we need to evaluate the model after certain epochs to see if the training process is running smoothly and we can save a checkpoint when we find a better evaluation result. The theoretical analysis ensures that an optimal solution can be visited if the number of iterations is as large as \(O(^{-3})\).

#### 3.2.4 Small Stuck Region

The theoretical guarantee of second-order optimality in SSRGD and Pullback is mainly credit to the lemma of small stuck region, which states that if there are two decoupled sequences \(x_{t}\) and \(x^{}_{t}\) with identical stochastic samples, \(x_{s}=x^{}_{s}\) and \(x_{s+1}-x^{}_{s+1}=r_{0}_{1}\) where \(_{1}\) is the eigenvector corresponding to the smallest eigenvalue, then it satisfies \(\{\|x_{t}-x_{s}\|,\ \|x^{}_{t}-x^{}_{s}\|\} C_{d}\) for some \(s t s+C_{T}\) with high probability. In SSRGD and Pullback, the averaged moving distance \(_{=s+1}^{t}\|x_{+1}-x_{}\|^{2}\) is used as the criterion to discriminate saddle point because the small stuck region lemma can be applied in this way. However, in decentralized algorithm some nodes enter the escaping phase before the candidate point \(_{s}\) is achieved. Suppose node \(i\) enters escaping phase in iteration \(s^{}\), then the averaged moving distance starting from iteration \(s\) on node \(i\) cannot be well estimated because the condition of not breaking escaping phase on node \(i\) only guarantees the bound of averaged moving distance starting from \(s^{}\). Therefore, in our method we use the total moving distance \(\|x^{(i)}_{t}-x^{(i)}_{s}\|\) as the criterion because we can obtain estimation \(\|x^{(i)}_{t}-x^{(i)}_{s}\| 2C_{d}\) given \(\|x^{(i)}_{t}-x^{(i)}_{s^{}}\| C_{d}\) and \(\|x^{(i)}_{s}-x^{(i)}_{s^{}}\| C_{d}\). And we can further complete our analysis by the small stuck region lemma. Actually we do not require more memory because \(\) is the point to return in SSRGD and Pullback (hence should be saved). In practice, we can also return \(^{(i)}\) for any node \(i\) drawing perturbation in iteration \(t-C_{T}\) since \(\|x^{(i)}_{t}-_{t}\|\) can be well bounded. Besides, we discover that the consensus error \(_{i=1}^{n}\|x^{(i)}_{t}-_{t}\|^{2}\) results in an extra term when proving the small stuck region lemma, which becomes another challenge. If the consensus error is not under control, it can drive \(x\) away from \(x_{s}\) or push \(x\) toward \(x_{s}\), no matter what \( f(x)\) is. In this manner, the stuck region cannot be estimated. In this work, we provide the corresponding proof to estimate this new term exclusively occurred in decentralized setting in our convergence analysis.

## 4 Convergence Analysis

### Assumptions

In this section we will provide the main theorem of our convergence analysis. First we will introduce the assumptions used in this paper. All assumptions used in this paper are mild and commonly used in the analysis of related works.

**Assumption 1**.: _(Lower Bound) The objective \(f\) is lower bounded, i.e., \(_{x}f(x)=f^{*}>-\)._

**Assumption 2**.: _(Bounded Variance) The stochastic gradient of each local loss function is an unbiased estimator and has bounded variance, i.e., for any \(i\{1,2,,n\}\) we have_

\[_{} F_{i}(x,)= f_{i}(x),\ _{}\|  F_{i}(x,)- f_{i}(x)\|^{2}^{2}\] (2)

**Assumption 3**.: _(Lipschitz Gradient) For all \(\) and \(i\{1,2,,n\}\), \(F_{i}(x,)\) has Lipschitz gradient, i.e., for any \(x_{1}\) and \(x_{2}\) we have \(\| F_{i}(x_{1},)- F_{i}(x_{2},)\| L\|x_{1}-x_{2}\|\) with a constant \(L\)._

**Assumption 4**.: _(Lipschitz Hessian) For all \(\) and \(i\{1,2,,n\}\), \(F_{i}(x,)\) has Lipschitz hessian, i.e., for any \(x_{1}\) and \(x_{2}\) we have \(\|^{2}F_{i}(x_{1},)-^{2}F_{i}(x_{2},)\|\|x_{1}-x_{2}\|\) with a constant \(\)._

Assumption 1, Assumption 2 and Assumption 3 are common assumptions used in the analysis of stochastic optimization algorithms. Assumption 4 is the standard assumption to find second-order optimality, which is used in all algorithms that achieves second-order stationary point in Table 1.

**Assumption 5**.: _(Spectral Gap) The decentralized network is connected by a doubly-stochastic weight matrix \(W^{n n}\) satisfying \(W_{n}=W^{T}_{n}=_{n}\) and \(:=\|W-J\|[0,1)\)._

Here \(J\) is a \(n n\) matrix with all elements equal to \(\). \(W\) is the weight matrix of the decentralized network where \(w_{ij}>0\) if node \(i\) and node \(j\) are connected, otherwise \(w_{ij}=0\). \(\|\|\) denotes the spectral norm of matrix (_i.e._, largest singular value). Notice that \(\) is a connectivity measurement of the network graph and it is also the second largest singular value of \(W\). We do not assume \(W\) to be symmetric and hence the communication network can be both directed graph and undirected graph. The spectral gap assumption is also used commonly in the analysis of decentralized algorithms.

### Main Theorems

Let \(_{H}=^{}\). When \( 0.5\), we have the following Theorem 1.

**Theorem 1**.: _Assume \( 0.5\) and Assumption 1 to 5 are satisfied. Let \(=\{,1\}\). We set \(=(}{L})\), \(=(^{1+})\), \(b_{0}=(^{-2})\), \(b_{1}=(\{^{2--5},1\})\), \(r=(^{1+})\), \(C_{v}=()\), \(C_{T}=(^{--})\) and \(C_{d}=(^{1-})\). Then our PEDESTAL algorithm will achieve \(O(,_{H})\)-second-order stationary point with \((^{-3})\) gradient complexity._

The specific constants hidden in \(()\) will be shown in Appendix B, where the proof outline and the completed proof of Theorem 1 can also be found. From Theorem 1 we can see our PEDESTAL-S with \(b_{1}=O(1)\) can achieve \(O(,_{H})\)-second-order stationary point with \((^{-3})\) gradient complexity for \(_{H}^{0.2}\). In the classic setting, our PEDESTAL achieves second-order stationary point with \((^{-3})\) gradient complexity. When \(>0.5\), _i.e._, \(_{H}<\), we have the following Theorem 2. Since the parameter settings are different and the \(O(1)\) batchsize is only available in Theorem 1, we separate these two theorems. The proof of Theorem 2 can be found in Appendix D.

**Theorem 2**.: _When \(_{H}<\) (i.e., \(>0.5\)), we set \(=(^{})\), \(=(^{1+})\), \(b_{0}=(^{-1})\), \(b_{1}=(^{-\{4-1-,+\}})\), \(r=(^{1+})\), \(C_{v}=()\), \(C_{T}=(^{--})\) and \(C_{d}=(^{})\) where \(=\{,3-2\}\). Under Assumption 1 to 5, our PEDESTAL algorithm will achieve \(O(,_{H})\)-second-order stationary point with \((_{H}^{-8}+^{4}_{H}^{-11})\) gradient complexity._

## 5 Experiments

In this section we will demonstrate our experimental results to validate the performance of our method. We conduct two tasks in our experiment, a matrix sensing task on synthetic dataset and a matrix factorization task on real-world dataset. Both of these two tasks are non-spurious local minimum problems (Ge et al. (2017, 2016)), which means all local minima are global minima. Thus, we conclude an algorithm is stuck at saddle point if the loss function value does not achieve the global minimum. The source code is available in https://github.com/WH-XIAN/PEDESTAL.

### Matrix Sensing

We follow the experimental setup of (Chen et al. (2022)) to solve a decentralized matrix sensing problem. The goal of this task is to recover a low-rank \(d d\) symmetric matrix \(M^{*}=U^{*}(U^{*})^{T}\) where \(U^{*}^{d r}\) for some small \(r\). We set the number of worker nodes to \(n=20\). We generate a synthetic dataset with \(N\) sensing matrices \(\{A_{i}\}_{i=1}^{N}\) and \(N\) corresponding observations \(b_{i}= A_{i},M^{*}\). Here the inner product \( X,Y\) of two matrices \(X\) and \(Y\) is defined by the trace \(tr(X^{T}Y)\). The decentralized optimization problem can be formulated by

\[_{U^{d r}}_{i=1}^{n}L_{i}(U),L_{i}(U)=_{j=1}^{N_{i}}( A_{ij},UU^{T}-b_{ij})^{2}\,,\] (3)where \(N_{i}\) is the amount of data assigned to worker node \(i\).

The number of rows of matrix \(U\) is set to \(d=50\) and \(d=100\) respectively and the number of columns is set to \(r=3\). The ground truth low-rank matrix \(M^{*}\) equals \(U^{*}(U^{*})^{T}\) where each entry of \(U^{*}\) is generated by Gaussian distribution \((0,1/d)\) independently. We randomly generate \(N=20 n d\) samples of sensing matrices \(\{A_{i}\}_{i=1}^{N}\), \(A_{i}^{d d}\) from standard Gaussian distribution and calculate the corresponding labels \(b_{i}= A_{i},M^{*}\). We consider two different types of data distribution, random distribution and Dirichlet distribution \(Dir_{20}(0.3)\) to assign data to each worker node. We conduct experiments on three different types of network topology, _i.e._, ring topology, toroidal

Figure 1: Experimental results of the decentralized matrix sensing task on different network topology for \(d=50\) and \(d=100\). Data is assigned to worker nodes by random distribution. The y-axis is the loss function value and the x-axis is the number of gradient oracles divided by the number of data \(N\).

Figure 2: Experimental results of the decentralized matrix factorization task on different network topology on MovieLens-100k. The y-axis is the loss function value and the x-axis is the number of gradient oracles divided by the size of matrix \(N l\).

topology (2-dimensional ring) and undirected exponential graph. The initial value of \(U\) is set to \([u_{0},,]\) where \(u_{0}\) is yield from Gaussian distribution and multiplied by a scalar such that it satisfies \(\|u_{0}\| eig(M^{*})\). We compare our PEDESTAL algorithm to decentralized baselines including D-PSGD, GTDSGD, D-GET, D-SPIDER-SFO and GTHSGD. In this experiment, the learning rate is chosen from \((0.01,0.001,0.0001)\). The batchsize is set to \(10\). For PEDESTAL and GTHSGD, parameter \(\) is set to \(0.01\). For D-GET and D-SPIDER-SFO, the period \(q\) is \(100\). For PEDESTAL, threshold \(C_{v}\) is set to \(0.0001\). Perturbation radius \(r\) is set to \(0.001\). The threshold of moving distance \(C_{d}\) is set to \(0.01\). The experimental results are shown in Figure 1. Due to the space limit, we only show the result of random data distribution in the main manuscript and leave the result of Dirichlet distribution to Appendix A.

From the experimental result we can see all baselines are stuck at the saddle point and cannot escape it effectively. In contrast, our PEDESTAL reaches and escapes saddle points and finally find the local minimum. We also calculate the smallest eigenvalue of hessian matrix for each algorithm at the converged optimal point, which is left to the Supplementary Material because of space limit. According to the eigenvalue result, we can see the smallest eigenvalue is much closer to \(0\) than all baselines. Therefore, our experiment verifies that our PEDESTAL achieves the best performance to escape saddle point and find local minimum.

### Matrix Factorization

The second task in our experiment is matrix factorization, which aims to approximate a given matrix \(M^{N l}\) by a low-rank matrix that can be decomposed to the product of two matrices \(U^{N r}\) and \(V^{l r}\) for some small \(r\). The optimization problem can be formulated by

\[_{U^{N r},V^{l r}}\|M-UV^{T}\|_{F}^ {2}:=_{i=1}^{N}_{j=1}^{l}(M_{ij}-(UV^{T})_{ij})^{2}\] (4)

where \(\|\|_{F}\) denotes the Frobenius norm and subscript \(ij\) refers to the element at \(i\)-th row and \(j\)-th column. In our experiment we solve this problem on the MovieLens-100k dataset (Harper and Konstan ). MovieLens-100k contains 100,000 ratings of 1682 movies provided by 943 users. Each rating is in the interval \(\) and scaled to \(\) in the experiment. This task can be regarded as an association task to predict users' potential ratings for unseen movies. In our experiment we set the number of worker node to \(n=50\). Each node is assigned the data from different group of users. Similar to the matrix sensing task, here we also use random distribution and Dirichlet distribution respectively to distribute users to worker nodes. And we also use ring topology, toroidal topology and undirected exponential graph as the communication network. The baselines are also D-PSGD, GTDSGD, D-GET, D-SPIDER-SFO and GTHSGD. In this experiment, the number of worker nodes is \(50\) and the rank of the matrix \(M\) is set to \(25\). The learning rate is chosen from \(\{0.01,0.001,0.0001\}\). The batchsize is set to \(100\). For PEDESTAL and GTHSGD, parameter \(\) is set to \(0.1\). For D-GET and D-SPIDER-SFO, the period \(q\) is \(100\). For PEDESTAL, threshold \(C_{v}\) is set to \(0.002\). Perturbation radius \(r\) is set to \(0.01\). The threshold of moving distance \(C_{d}\) is set to \(0.5\). The experimental results are shown in Figure 2.

From the experimental results we can see our PEDESTAL achieves the best performance to escape saddle point and find second-order stationary point. All baselines cannot escape saddle point effectively or efficiently. Particularly, variance reduced methods D-GET and D-SPIDER-SFO shows worse performance than SGD based algorithms D-PSGD and GTDSGD, which indicates that although reducing gradient noise can accelerate convergence, it also weakens the ability to escape saddle point. Therefore, our contribution is important since we make the fast convergence of variance reduction compatible with the capability to avoid saddle point.

## 6 Conclusion

In this paper we propose a novel algorithm PEDESTAL to find local minima in nonconvex decentralized optimization. PEDESTAL is the first decentralized stochastic algorithm to achieve second-order optimality with non-asymptotic analysis. We improve the drawbacks in previous deterministic counterpart to make phase changed independently on each node and avoid consensus protocols of broadcast or aggregation. We prove that PEDESTAL can achieve \(O(,)\)-second-order stationary point with the gradient complexity of \((^{-3})\), which matches state-of-the-art results of centralized counterpart or decentralized method to find first-order stationary point. We also conduct the matrix sensing and matrix factorization tasks in our experiments to validate the performance of PEDESTAL.