# Putting Gale & Shapley to Work:

Guaranteeing Stability Through Learning

 Hadi Hosseini

Penn State University, USA

hadi@psu.edu

&Sanjukta Roy

University of Leeds, UK

s.roy@leeds.ac.uk

&Duohan Zhang*

Penn State University, USA

dqz5235@psu.edu

Corresponding author

###### Abstract

Two-sided matching markets describe a large class of problems wherein participants from one side of the market must be matched to those from the other side according to their preferences. In many real-world applications (e.g. content matching or online labor markets), the knowledge about preferences may not be readily available and must be learned, i.e., one side of the market (aka agents) may not know their preferences over the other side (aka arms). Recent research on online settings has focused primarily on welfare optimization aspects (i.e. minimizing the overall regret) while paying little attention to the game-theoretic properties such as the stability of the final matching. In this paper, we exploit the structure of stable solutions to devise algorithms that improve the likelihood of finding stable solutions. We initiate the study of the sample complexity of finding a stable matching, and provide theoretical bounds on the number of samples needed to reach a stable matching with high probability. Finally, our empirical results demonstrate intriguing tradeoffs between stability and optimality of the proposed algorithms, further complementing our theoretical findings.

## 1 Introduction

Two-sided markets provide a framework for a large class of problems that deal with matching two disjoint sets (colloquially agents and arms) according to their preferences. These markets have been extensively studied in the past decades and formed the foundation of matching theory--a prominent subfield of economics that deals with designing markets without money. They have had profound impact on numerous practical applications such as school choice , entry-level labor markets , and medical residency . The primary objective is to find a _stable_ matching between the two sets such that no pair prefers each other to their matched partners.

The advent of digital marketplaces and online systems has given rise to novel applications of two-sided markets such as matching riders and drivers , electric vehicle to charging stations , and matching freelancers (or flexworkers) to job requester in a gig economy. In contrast to traditional markets that consider preferences to be readily available (e.g. by direct reporting or elicitation), in these new applications preferences may be uncertain or unavailable due to limited access or simply eliciting may not be feasible. Thus, a recent line of work has utilized _bandit learning_ to learn preferences by modeling matching problems as _multi-arm bandit_ problems where the preferences of agents are unknown while the preferences of arms are known. The goal is to devise learning algorithms such that a matching based on the learned preferences minimize the regret for each agent (see, for example, Liu et al. , Sankararaman et al. , Basu et al. , Maheshwari et al. , Kong et al. , Zhang et al. , Kong and Li , Wang et al. ).

Despite tremendous success in improving the regret bound in this setting, the study of stability of the final matching has not received sufficient attention. The following stylized example illustrates how an optimal matching (with zero regret) across all agents may remain unstable.

**Example 1**.: _Consider three agents \(\{a_{1},a_{2},a_{3}\}\) and three arms \(\{b_{1},b_{2},b_{3}\}\). Let us assume true preferences are given as strict linear orderings1 as follows:_

\[a_{1}:b_{1}^{*}_{2} b_{3} b_{1}:_{2} a_{3} a_{1}^{*}\] \[a_{2}:b_{2}^{*}_{1} b_{3} b_{2}:_{1} a_{3} a_{2}^{*}\] \[a_{3}:b_{1} b_{2}_{3}^{*} b_{3}:a_{1} a_{2}_{3}^{*}\]

_The underlined matching is the only stable solution in this instance. The matching denoted by \({}^{*}\) is a regret minimizing matching: agents \(a_{1}\) and \(a_{2}\) have a negative regret (compared to the stable matching), and \(a_{3}\) has zero regret. However, this matching is not stable because \(a_{3}\) and \(b_{1}\) form a blocking pair. Thus, \(a_{3}\) would deviate from the matching._

Note that stability is a desirable property that eliminates the incentives for agents to participate in secondary markets, and is the essential predictor of the long-term reliability of many real-world matching markets . Though some work (e.g. Liu et al. , Pokharel and Das ) did stability analysis, it is insufficient as we discuss later in Section 3 and Section 4.

Our contributions.We propose bandit-learning algorithms that utilize structural properties of the Deferred Acceptance algorithm (DA)--a seminal algorithm proposed by Gale and Shapley  that has played an essential role in designing stable matching markets. Contrary to previous works , we show that by exploiting an arm-proposing variant of the DA algorithm, the probability of finding a stable matching improves compared to those used in many previous work (an agent-proposing variant, such as Liu et al. , Basu et al. , Kong and Li ). We demonstrate that for a class of profiles (i.e. profiles satisfying \(\)-condition or those with a masterlist), the arm-proposing DA is more likely to produce a stable matching compared to the agent-proposing DA for _any_ sampling method (Corollary 1). For the commonly studied uniform sampling strategy, we show the probability bounds for two variants of DA for general preference profiles (Theorem 2). We initiate the study of sample complexity in the _Probably Approximately Correct_ (PAC) framework. We propose a non-uniform sampling strategy which is based on arm-proposing DA and Action Elimination algorithm (AE) , and show that it has a lower sample complexity as compared to uniform sampling (Theorem 3 and Theorem 5). Lastly, we validate our theoretical findings using empirical simulations (Section 6).

Table 1 shows the main theoretical results for uniform agent-DA algorithm, uniform arm-DA algorithm, and AE arm-DA algorithm. We note that the novel AE arm-DA algorithm achieves smaller sample complexity for finding a stable matching. Our bounds depend on structure of the stable solution \(m\), parameterized by the 'amount' of justified envy \(ES(m)\) (see Definition 4.1).

### Related Works

The two-sided matching problem is one of the most prominent success story of the field of game theory, and in particular, mechanism design, with a profound practical impact in applications ranging from organ exchange and labor market to modern markets involving allocation of compute, server, or content. The framework was formalized by Gale and Shapley 's seminal work, where

    & **Uniform agent-DA** & **Uniform arm-DA** & **AE arm-DA** \\  Prob. instability & \(O(|ES(m)|)\) (Thm. 2) & \(O(|ES(m)|)\) (Thm. 2) & \(O(|ES(m)|(-r_{}}{8}))\) (Thm. 4) \\  Sample complexity & \((}(^{-1}))\) (Thm. 3) & \((}(^{-1}))\) (Thm. 3) & \((}|ES(m)|(^{-1}))\) (Thm. 5) \\   

Table 1: Comparison of bounds on probability of unstable matchings and the sample complexity to find a stable matching. \(=(-T}{8K})\).

they, along with a long list of subsequent works focused primarily on game-theoretical aspects such as stability and incentives (Roth and Sotomayor, 1992; Roth, 1986; Dubins and Freedman, 1981). While the DA algorithm is strategyproof for the proposing side (Gale and Shapley, 1962), no stable mechanism can guarantee that agents from _both_ sides have incentives to report preferences truthfully in a dominant strategy Nash equilibrium (Roth, 1982). A series of works focused on strategic aspects of stable matchings (Huang, 2006; Teo et al., 2001; Vaish and Garg, 2017; Hosseini et al., 2021).

Stable matchings under uncertain linear or pairwise preferences were studied by Aziz et al. (2020, 2022). When preferences are unknown, the problem of learning preferences can be modeled as a multi-agent multi-arm bandit problem. Recent work has shown a variety of learning approaches using Explore-Then-Commit (ETC), Thompson sampling (Kong et al., 2022), in centralized (Liu et al., 2020; Pokharel and Das, 2023) or decentralized (Sankararaman et al., 2021; Kong and Li, 2023) matching markets. Subsequent works focused on domains with restricted preferences (as we also study in this paper) wherein a unique stable matching exists under true preferences (Sankararaman et al., 2021; Basu et al., 2021; Maheshwari et al., 2022; Wang and Li, 2024) or those that generalize to many-to-one markets (Wang et al., 2022; Kong and Li, 2024; Li et al., 2024). An extensive related work with details on upper bounds is provided in Appendix A.

## 2 Preliminary

Let \([k]=\{1,2,,k\}\), and \(()=_{n=1}^{}}\) denotes the Riemann Zeta function, and \(2>()>1\) if \( 2\).

Problem setup.An instance of a two-sided matching market is specified by a set of \(N\) agents, \(=\{a_{1},a_{2},,a_{N}\}\) on one side, and a set of \(K\) arms, \(=\{b_{1},b_{2},,b_{K}\}\), on the other side. The preference of an agent \(a_{i}\), denoted by \(_{a_{i}}\), is a strict total ordering over the arms. Each agent \(a_{i}\) is additionally endowed with a utility \(_{i,j}\) over arm \(b_{j}\). Thus, we say an agent \(a_{i}\) prefers arm \(b_{j}\) to \(b_{k}\), i.e. \(b_{j}_{a_{i}}b_{k}\), if and only if \(_{i,j}>_{i,k}\).2 We use \(\) to indicate the utility profile of all agents, where \(=(_{i,j})_{i[N],j[K]}\). The preferences of arms are denoted by a strict total ordering over the agents, i.e. an arm \(b_{i}\) has preference \(_{b_{i}}\). The _minimum preference gap_ is defined as \(=_{i[N]}_{j,k[K],j k}|_{i,j}-_{i,k}|\). It captures the difficulty of a learning problem in matching markets, i.e., the mechanism needs more samples to estimate the preference profile if \(\) is small.

Stable matching.A matching is a mapping \(m:\{\}\) such that \(m(a_{i})\) for all \(i[N]\), and \(m(b_{j})\{\}\) for all \(j[K]\), \(m(a_{i})=b_{j}\) if and only if \(m(b_{j})=a_{i}\). Additionally, \(m(b_{j})=\) if \(b_{j}\) is not matched. Sometimes we abuse the notation and use \(a_{i}\) to denote \(i\) if agent is clear from context, and similarly use \(b_{j}\) to denote \(j\) if arm is clear from context. Given a matching \(m\), an agent-arm pair \((a_{i},b_{j})\) is called a blocking pair if they prefer each other than their assigned partners, i.e., \(b_{j}_{a_{i}}m(a_{i})\) and \(a_{i}_{b_{j}}m(b_{j})\). Note that for any arm \(b_{j}\), getting matched is always better than being not matched, i.e., \(a_{i}_{b_{j}}\). A matching is stable if there is no blocking pair.

The _Deferred Acceptance (DA) algorithm_(Gale and Shapley, 1962) finds a stable matching in two sided market as follows: the participants from the proposing side make proposals to the other side according to their preferences. The other side tentatively accepts the most favorable proposals and rejects the rest. The process continues until everyone from the proposing side either holds an accepted proposal (i.e., matched to the one who has accepted its proposal), or has already proposed to everyone on its preference list (i.e., remains unmatched). We consider two variants of the DA algorithm, namely, _agent-proposing_ and _arm-proposing_. The matching computed by the DA algorithm is optimal for the proposing side (Gale and Shapley, 1962), i.e. proposing side receives their best match among all stable matchings. It is simultaneously pessimal for the receiving side (McVitie and Wilson, 1971). We denote the agent-optimal (arm-pessimal) stable matching by \(\) and the agent-pessimal (arm-optimal) stable matching by \(\).

Rewards and preferences.Agents receive stochastic rewards by pulling arms. If an agent \(a_{i}\) pulls an arm \(b_{j}\), she gets a stochastic reward drawn from a 1-subgaussian distribution3 with mean value \(_{i,j}\). We denote the sample average of agent \(a_{i}\) over arm \(b_{j}\) as \(_{i,j}\). The _agent-optimal stable regret_ is defined as the difference between the expected reward from the agent's most preferred stable match and the expected reward from the arm that the agent is matched to. Formally, we have \(_{i}(m)=_{i,(a_{i})}-_{i,m(a_{i})}\) for agent \(a_{i}\) and matching \(m\). Similarly, the _arm-optimal stable regret_ as \(_{i}(m)=_{i,(a_{i})}-_{i,m(a_{i})}\).

Preference profiles.Restriction on preferences has been heavily studied by previous papers (see Sankararaman et al. (2021); Basu et al. (2021); Maheshwari et al. (2022)) as they capture natural structures where, for example, riders all rank drivers according to a common _masterlist_, but drivers may have different preferences according to, e.g., distance to riders. If the true preference profiles are known and there exists a unique stable matching, then the agent-proposing DA algorithm and the arm-proposing DA algorithm lead to the same matching, namely \(=\). A natural property of the preference profile that leads to unique stable matching is called uniqueness consistency where not only there exists a unique stable matching, but also any subset of the preference profile that contains the stable partner of each agent/arm in the subset, there exists a unique stable matching. Karpov (2019) provided a necessary and sufficient condition (\(\)-condition) to characterize preference profiles that satisfy uniqueness consistency. A preference profile satisfies the \(\)-condition if and only if there is a stable matching \(m\) and an order of agents and arms such that \( i[N], j>i,m(a_{i})_{a_{i}}b_{j}\), and a possibly different order of agents and arms such that \( j[K], i>j,m(b_{j})_{b_{j}}a_{i}\).

## 3 Unique Stable Matching: Agents vs. Arms

To warm up, we start by analyzing instances of a matching market where a unique stable solution exists. As we discussed in the preliminaries, these markets are common and can be characterized by a property called uniqueness consistency. We show that for _any_ sampling algorithm, the arm-proposing DA algorithm is more likely to generate a stable matching compared to the agent-proposing DA algorithm. All missing proofs and additional results are relegated to the full version Hosseini et al. (2024).

**Theorem 1**.: _Assume that the true preferences satisfy uniqueness consistency condition. For any estimated utility \(\), if the agent-proposing DA algorithm produces a stable matching, then the arm-proposing DA algorithm produces a stable matching._

Theorem 1 states that when preferences satisfy the uniqueness consistency condition, for any estimated utility, the stability of agent-proposing DA matching implies the stability of arm-proposing DA matching. For any fixed sampling algorithm, each estimation occurs with some probability, so we immediately have the following corollary.

**Corollary 1**.: _For any sampling algorithm, the arm-proposing DA algorithm has a higher probability of being stable than the agent-proposing DA algorithm if the true preferences satisfy uniqueness consistency condition._

The following example further shows that the arm-proposing DA could generate a stable matching even if the estimation is incorrect, while the agent-proposing DA generates an unstable matching. In Section 6, we provide empirical evaluations on stability and regret of variants of the DA algorithm.

**Example 2** (The stability of arm vs. agent proposing DA when estimation is wrong.).: _Consider two agents \(\{a_{1},a_{2}\}\) and two arms \(\{b_{1},b_{2}\}\). Assume the true preferences are as follows:_

\[a_{1}:b_{1}^{*} b_{2} b_{1}:a_{1}^{*} a_{2}\] \[a_{2}:b_{1} b_{2}^{*} b_{2}:a_{2}^{*} a_{1}\]

_The matching denoted by \({}^{*}\) is the only stable solution in this instance. Assume that after sampling data, agent \(a_{1}\) has a wrong estimation: \(b_{2} b_{1}\) and agent \(a_{2}\) has the correct estimation. Under the wrong estimation, arm-proposing DA algorithm returns the matching \({}^{*}\) while agent-proposing DA algorithm returns the underlined matching, which is unstable with respect to true preferences. Note that algorithms that rely on agent-proposing DA (e.g. Liu et al. (2021); Kong and Li (2023)) may similarly fail to find a stable matching as they do not exploit the known arms preferences effectively._

## 4 Uniform Sampling DA Algorithms

In this section, we compare the stability performance for two types of DA combined with uniform sampling algorithm when the preferences could be arbitrary. Compared with Section 3, we note that the theory in this section does not constrain preferences. We provide probability bounds for finding an unstable matching in Section 4.1 and analyze sample complexity for reaching a stable matching in Section 4.2.

_Uniform sampling_ is a technique in bandit literature (Garivier et al., 2016) (usually termed as exploration-then-commit algorithm, ETC). Kong and Li (2023) utilized UCB to construct a confidence interval (CI) for each agent-arm pair, where each agent samples arms uniformly. The exploration phase stops when every agent's CIs for each pair of arms have no overlap, i.e. agents are confident that arms are ordered by the estimation correctly. Then, in the commit phase agents form a matching through agent-proposing DA, and keep pulling the same arms.

Agents construct CIs based on the collected data by utilizing the upper confidence bound (UCB) and lower confidence bound (LCB). Given a parameter \(\), if arm \(b_{j}\) is sampled \(t\) times by agent \(a_{i}\), we define the UCB and LCB as follows:

\[UCB_{i,j}=_{i,j}(t)+,\ LCB_{i,j}=_{i, j}(t)-,\] (1)

where \(_{i,j}(t)\) is the average of the collected samples.

**Uniform sampling algorithm (Algorithm 1)** Agents explore the arms uniformly. Suppose that agent \(a_{i}\) has disjoint confidence intervals over all arms, i.e., there exists a permutation \(_{i}:=(_{i}(1),_{i}(2),,_{i}(K))\) over arms such that \(LCB_{i,_{i}(k)}>UCB_{i,_{i}(k+1)}\) for each \(k[K-1]\). Then, agent \(a_{i}\) can reasonably infer the accuracy of the estimated preference profile. The parameter \(\) is used to control the confidence length, where a larger \(\) implies that the agent needs more samples to differentiate the utility for a pair of arms.

After the sampling stage, agents can consider to form a matching either through agent-proposing DA or arm-proposing DA, as is discussed in Section 3. For simplicity, we refer uniform sampling ( Algorithm 1) with agent-proposing DA as uniform agent-DA algorithm, and uniform sampling with arm-proposing DA as uniform arm-DA algorithm.

``` Input :Parameter \(\), sample budget T.
1for\(t=1,2,,T\)do
2for\(i=1,2,,N\)do
3 Agent \(a_{i}\) pulls \(m_{i}(t)=b_{j}\), where \(j=(t+i-1) K+1\);
4 Agent \(a_{i}\) observes a return \(X_{i}(t)\) and updates \(_{i,j}\) ;
5 Compute \(UCB_{i,j}\) and \(LCB_{i,j}\) using \(\);
6if\(\) a permutation \(_{i}\) for all \(i[N]\) such that \(LCB_{i,_{i}(k)}>UCB_{i,_{i}(k+1)}, k[K-1]\)then
7 Break;
8 return\(\{_{i,j} i[N],j[K]\}\). ```

**Algorithm 1**Uniform sampling algorithm

### Probability Bounds for Stability

We provide theoretical analysis on probability bounds for stability for the uniform agent-DA algorithm and the uniform arm-DA algorithm. We show probability bounds of learning a stable matching using the properties of stable solutions and the structure of the profile. We first define the following notions of local and global _emy-sets_.

**Definition 4.1**.: _The local envy-set for agent \(a_{i}\) for a matching \(m\) is defined as_

\[ES_{i}(m)=&:a_{i}_{b_{j}}m(b_{j})\}$ is empty}\\ \{b_{j}:a_{i}_{b_{j}}m(b_{j})\}\{m(a_{i})\}&.\]

_The global envy-set of a matching \(m\) is defined as the union of local envy-sets over all agents:_

\[ES(m)=_{i[N]}\{(a_{i},b_{j}) b_{j} ES_{i}(m))\}.\]By the definition of stability, a matching \(m\) is stable if and only if the global envy-set is justified, i.e., agents truly prefer their current matched arm to the arms in the envy-set \(ES(m)\). Formally, \(_{i,m(a_{i})}_{i,j}\), for all \((a_{i},b_{j}) ES(m)\) if and only if \(m\) is a stable matching. This observation is key in establishing theoretical results.

The following lemma provides a condition for finding a stable matching using the envy-set of the estimated matching. The detailed proof of all the results can be found in the full version Hosseini et al. (2024).

**Lemma 1**.: _Assume \(\) is the sample average, and matching \(\) is stable with respect to \(\). Define a good' event for agent \(a_{i}\) and arm \(b_{j}\) as \(_{i,j}=\{|_{i,j}-_{i,j}|/2\}\), and define the intersection of the good events over envy-set as \((ES())=_{(a_{i},b_{j}) ES()}_{i,j}\). Then if the event \((ES())\) occurs, matching \(\) is guaranteed to be stable (with respect to \(\))._

Now we prove the following bounds for two types of uniform sampling algorithms. The probability bound depends on the size of the envy-set.

**Theorem 2**.: _By uniform sampling (Algorithm 1), each agent samples each arm \(T/K\) times, and \(_{1}\) and \(_{2}\) are matchings generated by agent-proposing DA and arm-proposing DA, respectively. Then,_

1. \(P(_{1})=O(|ES()|(-T}{8K }))\)_,_
2. \(P(_{2})=O(|ES()|(-T}{8K }))\)_,_

_where \(\) is the agent-pessimal stable matching and \(\) is the agent-optimal stable matching._

Proof sketch.: Since \(_{1}\) and \(_{2}\) are produced by DA based on \(\), both matchings are stable with respect to \(\). By Lemma 1, both matchings are guaranteed to be stable with respect to \(\) conditioned on \((ES(_{1}))\) (or \((ES(_{2}))\)). Thus, it follows

\[P(_{1})  1-P((ES(_{1})))\] \[=[_{(a_{i},b_{j}) ES(_{1})}P(|_{i,j} -_{i,j}|/2)] []\] \[[_{(a_{i},b_{j}) ES(_{1})}P(|_{i,j }-_{i,j}|/2)] []\] \[ 2[|ES(_{1})|](-T}{8K}) [}0].\]

To complete the proof for \(_{1}\), we demonstrate an upper bound of \([|ES(_{1})|]\). We show that \(|[|ES(_{1})|]-|ES()| N^{2}K^{3}exp(-T}{4K})\). The difference is negligible when \(T\) is sufficiently large. Thus the first statement follows. The complete proof is deferred to Appendix C. 

In the next lemma, we show the relation between the size of the envy-sets for the agent-optimal and agent-pessimal matchings. Then, combining Theorem 2 and Lemma 2, we prove the next corollary.

**Lemma 2**.: _Given any instance of a matching problem, we have the following relationship between the size of the two envy sets: \(|ES()||ES()|\)._

Proof.: Agent-pessimal stable matching \(\) is the arm-optimal stable matching, and agent-optimal stable matching \(\) is the arm-pessimal stable matching, so we have that \((b_{j})_{b_{j}}(b_{j})\) or \((b_{j})=(b_{j})\) for each arm \(b_{j}\). From the definition of the envy-set, we have \(|ES()||ES()|\). 

**Corollary 2**.: _The uniform arm-DA algorithm has a smaller probability bound of being unstable than the uniform agent-DA algorithm._

**Remark 1**.: _Liu et al. (2020) showed the probability bound of \((-T}{2K})\) for finding an invalid ranking by the ETC algorithm, where a valid ranking is defined as the estimated ranking such that the estimated pairwise comparison is correct for a subset of agent-arm pairs. However, their result did not relate the probability bound with the structure of the instance, whereas the bound in Theorem 2 crucially uses the envy set to improve the probability of finding a stable solution. Liu et al. (2021) provided an upper bound on the sum of the probabilities of being unstable for the Conflict-Avoiding UCB algorithm (CA-UCB). Under CA-UCB algorithm, \(O(^{2}(T))\) out of \(T\) matchings are unstable in expectation._

### Sample Complexity

We turn to analyze the sample complexity to learn a stable matching under the probably approximately correct (PAC) framework. In particular we ask: given a probability budget \(\), how many samples \(T\) are needed to find a stable matching? Formally, an algorithm has sample complexity \(T\) with probability budget \(\) if with probability at least \(1-\), the algorithm guarantees that it would find a stable matching with the total number of samples over all agent-arm pairs upper bounded by \(T\).

**Theorem 3**.: _[Sample complexity for uniform sampling algorithm] With probability at least \(1-\), both the uniform agent-DA and the uniform arm-DA algorithms find a stable matching with the same sample complexity \((}(^{-1}))\)4._

Note that uniform agent-DA algorithm finds the stable matching \(\), and uniform arm-DA algorithm finds the stable matching \(\). Uniform sampling (Algorithm 1) suffers from sub-optimal sample complexity for finding stable matchings since agents sample each arm uniformly. Thus, in the next section we devise an exploration algorithm that exploits the structure of stable matchings by utilizing arms' known preferences.

## 5 An Arm Elimination DA Algorithm

The proposed algorithm (Algorithm 3) combines the arm-proposing DA and Action Elimination (AE) algorithm (Audibert and Bubeck, 2010; Even-Dar et al., 2006; Jamieson and Nowak, 2014). The AE algorithm eliminates an arm (i.e. no longer sampling the arm) when confidence bound indicates that the arm is sub-optimal (i.e. the upper confidence bound is smaller than another arm's lower confidence bound), and outputs the best arm when there is only one arm that hasn't been eliminated. Note that Algorithm 3 differs from the vanilla arm-proposing DA in Line 8, when an agent has been proposed by two arms. Agents utilize the arm elimination algorithm (see Algorithm 2) until the agent eliminates the sub-optimal arm. Note that at every round, each agent chooses an arm with fewer samples thus far (see Line 4 in Algorithm 2). One significant observation is that if Algorithm 2 outputs winners correctly whenever an agent is proposed, Algorithm 3 terminates with the arm-optimal matching \(\).

``` Input : agent \(a\), arms \(b_{1},b_{2}\), sample sizes \(n_{1},n_{2}\), and sample mean \(_{1},_{2}\).
1 Calculate \(LCB_{1},LCB_{2},UCB_{1},UCB_{2}\);
2\(winner\) empty;
3while\((LCB_{1},LCB_{2})<(UCB_{1},UCB_{2})\)do
4\(index\) which.min\((n_{1},n_{2})\);
5 Agent \(a\) publs \(b_{index}\);
6 Agent \(a\) observes a return and updates \(_{index},n_{index}\);
7 Update all \(UCB\) and \(LCB\);
8\(winner\) index of maximum \((_{1},_{2})\);
9return\(winner\). ```

**Algorithm 2**Arm elimination algorithm

### Probability Bounds for Stability

We compute the probability bound for learning an unstable matching for Algorithm 3. Contrary to uniform sampling, here we compute the bound on given sample size.

**Theorem 4**.: _By Algorithm 3, assume that agent \(a_{i}\) samples arm \(b_{j}\) for \(T_{i,j}\) and \(\) is returned by the algorithm. We define \(T_{min}=_{(a_{i},b_{j}) ES()}T_{i,j}\) as the minimum sample size for agent-arm pairs. Then, we have_

\[P() O(|ES()|(-T _{min}}{8})).\]

**Remark 2**.: _Theorem 4 provides stability bound for Algorithm 3 that depends on \(T_{i,j}\), which is unknown apriori. If the total sample budget is \(NT\) and we set \(T_{i,j}=)|}\), the stability boundbecomes \(O(|ES()|exp(-NT}{8|ES()|}))\), which is smaller than uniform arm-DA's stability bound \(O(|ES()|exp(-T}{8K}))\), as stated in Theorem 2. Even though the upper bound could be larger than that of Algorithm 1, simulated experiments show that AE arm-DA significantly improves stability guarantees compared to the uniform sampling variants (Algorithm 1)._

### Sample Complexity

We compute the sample complexity to learn a stable matching for Algorithm 3. Note that agents only sample pairs in the envy-set, while in Algorithm 1 agents explore all arms uniformly. The following analysis shows that Algorithm 3 has smaller sample complexity compared to Algorithm 1.

**Theorem 5**.: _[Sample complexity for AE arm-DA algorithm] With probability at least \(1-\), Algorithm 3 terminates and returns a stable matching, \(\), with sample complexity of_

\[()}{^{2}}(^{-1})).\]

Proof sketch.: We begin by defining a good event \(|_{i,j}(t)-_{i,j}|\) only for agent-arm pairs in the envy-set \(|ES()|\). Conditioned on such events for all time, we demonstrate that the algorithm terminates with true preferences on the envy-set \(ES()\), and thus, the algorithm executes the arm-proposing DA when agents have known preferences and produces \(\).

Then we show the upper bound of sample complexity for each agent-arm pair: \(T=O(}(}))\). We prove it by induction on the number of proposals. The base case is when arms \(b_{j}\) and \(b_{j^{}}\) propose to agent \(a_{i}\) for the first time. Then, we show the number of samples for each pair is bounded by \(T\). In the inductive step, say \(b_{j}\) is the winner in the last round and has sampled \(t_{i,j} T\) times, and \(b_{j^{}}\) proposes to \(a_{i}\) in this round. Then if \(a_{i}\) samples \(b_{j}\) for \(T-t_{i,j}\) more times and \(a_{i}\) samples \(b_{j^{}}\) for \(T\) times, by the same computation as the base case, we have that the number of samples for each pair is bounded by \(T\). Since Algorithm 3 only samples the agent-arm pairs in the envy set \(ES()\), we get that the total sample complexity is \(|ES()|T=O()|)}{^{2}}( }))\). By setting the probability budget \(=)|}{K^{}}\), we have that with probability at least \(1-\), the AE arm-DA algorithm has sample complexity \(()|}{^{2}}(^{-1}))\). The complete proof appears in Appendix D. 

It is worth noting that a large \(\) implies a small \(\), which implies that the algorithm needs more samples to guarantee finding a stable matching. We show bounds on the envy-sets in the next lemma.

**Lemma 3**.: _Considering any true preference \(\), we have the following bounds for envy-set:_

1. _Size of the envy-set for_ \(\)_:_ \((max\{N,K\}-N)N|ES()| NK\)_._
2. _Size of the envy-set for_ \(\)_:_ \((max\{N,K\}-N)N|ES()| NK-N+1\)_._

**Remark 3**.: _By comparing Theorem 5 to Theorem 3, the sample complexity ratio between the AE arm-DA (Algorithm 3) and uniform arm selection (Algorithm 1) is \(}\), which further shows that fewer arms from the envy-set \(ES()\) need to be sampled. Lemma 3 states the best-case and worse-case ratios as \(-N}{K}\) and \(1-<1\). Thus, Algorithm 3 strictly improves the sample complexity of finding a stable matching._

**Remark 4**.: _One can illustrate the magnitude of \(|ES()|\) through the lens of arm-proposing DA algorithm. Observe that \(|ES()|\) is the number of proposals made by arms and rejections made by agents in the arm-proposing DA algorithm. In a highly competitive environment for arms, e.g. when there are much more arms than agents so that many arms are not matched, the magnitude of \(|ES()|\) is large. In a less competitive environment, e.g. when arms put different agents as their top choices, \(|ES()|\) has much smaller magnitude._

## 6 Experimental Results

In this section, we experimentally validate our theoretical results. For this, we consider \(N=K=20\) and randomly generate preferences. In particular, we follow a similar experiment setting in Liu et al. (2021): for each \(i\), the true utilities \(\{_{i,1},_{i,2},,_{i,20}\}\) are randomized permutations of the sequence \(\{1,2,,20\}\) so that the minimum preference gap is fixed (\(=1\)) and algorithm performance exhibits relatively low variability. Arms' preferences are generated the same way. We conduct 200 independent simulations, with each simulation featuring a randomized true preference profile. We compare average stability, i.e., the proportion of stable matchings over \(200\) experiments, average regrets, and maximum regrets over agents between four algorithms: uniform agent-DA5, uniform arm-DA, AE arm-DA, and CA-UCB (Liu et al., 2021).

In terms of stability, our experiments show that the AE arm-DA algorithm significantly enhances the likelihood of achieving stability compared to both types of uniform sampling algorithm and CA-UCB algorithm (Figure 1). On the other hand, the regret gap between uniform agent-DA and other two arm-proposing types of algorithms illustrates the utility difference of agent-optimal matching \(\) and arm-optimal matching \(\). We note that when preferences are restricted to have unique stable matching, AE arm-DA algorithm's regret converges faster to \(0\), compared to uniform algorithms, while still keeping faster stability convergence (Figure 2). Additional experiments with other preference domains (e.g. masterlist) in provided in Appendix E.

At the first glance, Figure 1 (the center and the right plots) seems to suggest that the the uniform arm-DA is outperforming the AE arm-DA algorithm. However, note that the regret here is with respect to the agent-optimal solution (i.e. \(\)); and thus, the AE arm-DA algorithm by design is not optimized to reach that solution. Upon further investigation, however, we see that when comparing the two algorithms using the agent-pessimal regret (\(\)) then the AE arm-DA converges with fewer samples both in terms of average and maximum regrets, as illustrated in Figure 3.

## 7 Conclusion and Future Work

The game-theoretical properties such as stability in two-sided matching problems are critical indicators of success and sustenance of matching markets; without stability agents may'scramble' to participate

Figure 1: \(95\%\) confidence interval of stability and regret for \(200\) randomized general preference profiles.

in secondary markets even when _all_ preferences are known (Kojima et al., 2013). We demonstrated key techniques in learning preferences that rely on the structure of stable solutions. In particular, exploiting the 'known' preferences of arms in the arm-proposing variant of DA and eliminating arms early on, provably reduces the sample complexity of finding stable matchings while experimentally having little impact on optimality (measured by regret). Findings of this paper can have substantial impact in designing new labor markets, school admissions, or healthcare where decisions must be made as preferences are revealed (Rastegari et al., 2014).

We conclude by discussing some limitations and open questions. First, extending this framework to settings with incomplete preferences, ties, or those that go beyond subgaussian utility assumptions are interesting directions for future research. We opted to avoid these nuances, for example ties, as such variations often introduce computational complexity with known preferences. In addition, given that the number of stable solutions could raise exponentially (Knuth, 1976), designing learning algorithms that could converge to stable solutions while satisfying some fairness notions (e.g. egalitarian or regret-minimizing) is an intriguing future direction.