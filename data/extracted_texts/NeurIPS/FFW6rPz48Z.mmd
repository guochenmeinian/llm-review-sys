# Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting

Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting

Romain Ilbert\({}^{ 1,\ 2}\)  Malik Tiomoko\({}^{1}\)  Cosme Louart\({}^{3}\)  Ambroise Odonnat\({}^{1,\ 4}\)

Vasilii Feofanov \({}^{1}\)  Themis Palpanas\({}^{2}\)  Ievgen Redko\({}^{1}\)

\({}^{1}\)Huawei Noah's Ark Lab, Paris, France \({}^{2}\)LIPADE, Paris Descartes University, Paris, France

\({}^{3}\) School of Data Science, The Chinese University of Hong Kong, Shenzhen, China

\({}^{4}\) Inria, Univ. Rennes 2, CNRS, IRISA

Correspondence to: romain.ilbert@hotmail.fr.

###### Abstract

In this paper, we introduce a novel theoretical framework for multi-task regression, applying random matrix theory to provide precise performance estimations, under high-dimensional, non-Gaussian data distributions. We formulate a multi-task optimization problem as a regularization technique to enable single-task models to leverage multi-task learning information. We derive a closed-form solution for multi-task optimization in the context of linear models. Our analysis provides valuable insights by linking the multi-task learning performance to various model statistics such as raw data covariances, signal-generating hyperplanes, noise levels, as well as the size and number of datasets. We finally propose a consistent estimation of training and testing errors, thereby offering a robust foundation for hyperparameter optimization in multi-task regression scenarios. Experimental validations on both synthetic and real-world datasets in regression and multivariate time series forecasting demonstrate improvements on univariate models, incorporating our method into the training loss and thus leveraging multivariate information.

## 1 Introduction

The principle of multi-task learning, which encompasses concepts such as "learning to learn" and "knowledge transfer," offers an efficient paradigm that mirrors human intelligence. Unlike traditional machine learning, which tackles problems on a task-specific basis with tailored algorithms, multi-task learning leverages shared information across various tasks to enhance overall performance. This approach not only improves accuracy but also addresses challenges related to insufficient data and data cleaning. By analyzing diverse and multimodal data and structuring representations multi-task learning can significantly boost general intelligence, similar to how humans integrate skills. This concept is well-established  and has been successfully applied to a wide range of domains, such as computer vision , natural language processing  and biology .

Our Method.We consider the multi-task regression framework  with \(T\) tasks with the input space \(^{(t)}^{d}\) and the output space \(^{(t)}^{q}\) for \(t\{1,,T\}\). For each task \(t\), we assume that we are given \(n_{t}\) training examples organized into the feature matrix \(^{(t)}=[_{1}^{(t)},,_{n_{t}}^{(t)}] ^{d n_{t}}\) and the corresponding response matrix \(^{(t)}=[_{1}^{(t)},,_{n_{t}}^{(t)}] ^{q n_{t}}\), where \(_{i}^{(t)}^{(t)}\) represents the \(i\)-th feature vector of the \(t\)-th task and \(_{i}^{(t)}^{(t)}\) is the associated response. In order to have a more tractable and insightful setup, we follow Romera-Paredes et al.  and consider the linear multi-task regression model. In particular, we study a straightforward linear signal-plus-noise model that evaluates the response \(_{i}^{(t)}\) for the \(i\)-th sample of the \(t\)-th task as follows:

\[^{(t)}=^{(t)}_{t}}{}+^{(t)}, t\{1,,T\},\] (1)

where \(^{(t)}^{n_{t} q}\) is a matrix of noise vectors with each \(_{i}^{(t)}(0,_{N})\), \(_{N}^{q q}\) denoting the covariance matrix. The matrix \(_{t}^{d q}\) denotes the signal-generating hyperplane for task \(t\). We denote the concatenation of all task-specific hyperplanes by \(=[_{1}^{},,_{T}^{}]^{} ^{Td q}\). We assume that \(_{t}\) can be decomposed as a sum of a common matrix \(_{0}^{d q}\), which captures the shared information across all the tasks, and a task-specific matrix \(_{t}^{d q}\), which captures deviations specific to the task \(t\):

\[_{t}=_{0}+_{t}.\] (2)

Given the multitask regression framework and the linear signal-plus-noise model, we now want to retrieve the common and specific hyperplanes, \(_{0}\) and \(_{t}\), respectively. To achieve this, we study the following minimization problem governed by a parameter \(\) that controls the balance between the common and specific components of \(\):

\[_{0}^{*},\{_{t}^{*}\}_{t=1}^{T},^{*}= \|_{0}\|_{F}^{2}+_{t=1}^{T} _{t}\|_{F}^{2}}{_{t}}+_{t=1}^{T}\| ^{(t)}-^{(t)}_{t}}{}\| _{F}^{2}.\] (3)

where \(=[_{1},,_{T}]\) is a vector of task-specific regularization hyperparameters. Each \(_{t}\) controls how much the model overfits (small \(_{t}\)) or underfits (large \(_{t}\)) on task \(t\).

Contributions and Main Results.We seek to provide a rigorous theoretical study of (3) in high dimension, providing practical insights that make the theoretical application implementable in practice. Our contributions can be summarized in four major points:

1. We provide exact train and test risks for the solutions of (3) using random matrix theory. We then decompose the test risk into a signal and noise term responsible for the effectiveness of multi-task learning and the negative transfer, respectively.
2. We show how the signal and noise terms compete with each other depending on \(\) for which we obtain an optimal value optimizing the test risk.
3. In a particular case, we derive a closed-form data-dependent solution for the optimal \(^{*}\), involving raw data covariances, signal-generating hyperplane, noise levels, and the size and number of data sets.
4. We offer empirical estimates of these model variables to develop a ready-to-use method for hyperparameter optimization in multitask regression problems within our framework.

Applications.As an application, we view multivariate time series forecasting (MTSF) as a multi-task problem and show how the proposed regularization method can be used to efficiently employ univariate models in the multivariate case. Firstly, we demonstrate that our method improves PatchTST  and DLinear  compared to the case when these approaches are applied independently to each variable. Secondly, we show that the univariate models enhanced by the proposed regularization achieve performance similar to the current state-of-the-art multivariate forecasting models such as SAMformer and iTransformer.

## 2 Related Work

Usual Bounds in Multi-Task Learning.Since its introduction [1; 5; 26], multi-task learning (MTL) has demonstrated that transfer learning concepts can effectively leverage shared information to solve related tasks simultaneously. Recent research has shifted focus from specific algorithms or minimization problems to deriving the lowest achievable risk given an MTL data model. The benefits of transfer learning are highlighted through risk bounds, using concepts such as contrasts , which study high-dimensional linear regression with auxiliary samples characterized by the sparsity of their contrast vector or transfer distances , which provide lower bounds for target generalization error based on the number of labeled source and target data and their similarities. Additionally, task-correlation matrices  have been used to capture the relationships inherent in the data model.

However, these studies remain largely theoretical, lacking practical algorithms to achieve the proposed bounds. They provide broad estimates and orders of magnitude that, while useful for gauging the feasibility of certain objectives, do not offer precise performance evaluations. Moreover, these estimates do not facilitate the optimal tuning of hyperparameters within the MTL framework, a critical aspect of our study. We demonstrate the importance of precise performance evaluations and effective hyperparameter tuning to enhance the practical application of MTL.

Random Matrix Theory in Multi-Task Learning.In the high-dimensional regime, Random Matrix Theory allows obtaining precise theoretical estimates on functionals (e.g., train or test risk) of data matrices with the number of samples comparable to data dimension [2; 13; 31; 46]. In the multi-task classification case, large-dimensional analysis has been performed for Least Squares SVM  and supervised PCA  showing counterproductivity of tackling tasks independently. We inspire our optimization strategy from  and conduct theoretical analysis for the multi-task regression, which introduces unique theoretical challenges and with a different intuition since we need to consider another data generation model and a regression learning objective. Our data modeling shares similarity with  which theoretically studied conditions of a negative transfer under covariate and model shifts. Our work focuses on the selection of hyperparameters within a general optimization framework, considering both a hyperparameter \(\) to relate all tasks and specific parameters \(_{t}\) to balance overfitting and underfitting within each task, accommodating non-Gaussian distributions and employing recent developments such as deterministic equivalents and concentration inequalities.

High dimensional analysis for regression.Regression is an important problem that has been extensively explored in the context of single-task learning for high-dimensional data, employing tools such as Random Matrix Theory , physical statistics [9; 15], and the Convex Gaussian MinMax Theorem (CGMT) , among others. Typically, authors employ a linear signal plus noise model to calculate the asymptotic test risk as a function of the signal-generating parameter and the covariance of the noise. Our research builds upon these studies, extending them to a multi-task learning framework. In doing so, we derive several insights unique to multi-task learning. However, none of these previous studies offer a practical method for estimating the asymptotic test risk, which is dependent on the ground truth signal-generating parameter. Therefore, our work not only extends previous studies into the multi-task case within a generic data distribution (under the assumption of a concentrated random vector), but also provides a practical method for estimating these quantities.

## 3 Framework

Notation.Throughout this study, matrices are represented by bold uppercase letters (e.g., matrix \(\)), vectors by bold lowercase letters (e.g., vector \(\)), and scalars by regular, non-bold typeface (e.g., scalar \(a\)). The notation \(\) for matrices or vectors \(,\) is the Kronecker product. \(_{}\) or \(()\) stands for a diagonal matrix containing on its diagonal the elements of the vector \(\). The superscripts \(t\) and \(i\) are used to denote the task and the sample number, respectively, e.g., \(_{i}^{(t)}\) writes the \(i\)-th sample of the \(t\)-th task. The canonical vector of \(^{T}\) is denoted by \(_{i}^{[T]}\) with \([e_{i}^{[T]}]_{i}=_{ti}\). Given a matrix \(M^{p n}\), the Frobenius norm of \(\) is denoted \(\|\|_{F}(^{})}\). For our theoretical analysis, we introduce the following notation of training data:

\[=[^{(1)},,^{(T)}]^{q n},=_{t=1}^{T}(_{t}^{[T]}_{t}^{[T] }{}^{})^{(t)}^{Td n}\]

where \(n=_{t=1}^{T}n_{t}\) is the total number of samples in all the tasks.

### Regression Model

We define \(=[_{1}^{},,_{T}^{}]^{} ^{dT q}\) and propose to solve the linear multi-task problem by finding \(}=[}_{1}^{},,}_{T}^{ }]^{}^{dT q}\) which solves the following optimization problem under the assumption of relatedness between the tasks, i.e., \(_{t}=_{0}+}_{t}\) for all tasks \(t\) :

\[_{(_{0},)^{K q}^{ dT q}}(_{0},)\] (4)where

\[(_{0},)\|_{0}\|_{F }^{2}+_{t=1}^{T}_{t}\|_{F}^{2}}{_{t}}+ _{t=1}^{T}\|^{(t)}-^{(t)}}^{ }_{t}}{}\|_{F}^{2}.\]

The objective function consists of three components: a regularization term for \(_{0}\) to mitigate overfitting, a task-specific regularization term that controls deviations \(_{t}\) from the shared weight matrix \(_{0}\), and a loss term quantifying the error between the predicted outputs and the actual responses for each task.

The optimization problem is convex for any positive values of \(,_{1},,_{T}\), and it possesses a unique solution. The details of the calculus are given in Appendix B. The formula for \(}_{t}\) is given as follows:

\[}_{t}=(_{t}^{[T]}^{} _{d})}{ },}_{0}=(_{T}^{} _{d})}{},\]

where with \(=(^{}}{Td}+_ {n})^{-1}^{n n}\), and \(=(_{}+_{T} _{T}^{})_{d}^{Td Td}\).

### Assumptions

In order to use Random Matrix Theory (RMT) tools, we make two assumptions on the data distribution and the asymptotic regime. Following , we adopt a concentration hypothesis on the feature vectors \(_{i}^{(t)}\), which was shown to be highly effective for analyzing machine learning problems [11; 14]. The justification and implications of these assumptions can be found in appendix A.2 and A.3.

**Assumption 1** (Concentrated Random Vector).: _We assume that there exists two constants \(C,c>0\) (independent of dimension \(d\)) such that, for any task \(t\), for any \(1\)-Lipschitz function \(f:^{d}\), any feature vector \(^{(t)}^{(t)}\) verifies:_

\[ t>0:(|f(^{(t)})-[f(^{(t)})]| t)  Ce^{-(t/c)^{2}},\] \[[^{(t)}]=0[ ^{(t)}]=^{(t)}.\]

In particular, we distinguish the following scenarios: \(_{i}^{(t)}^{d}\) are concentrated when they are (i) independent Gaussian random vectors with covariance of bounded norm, (ii) independent random vectors uniformly distributed on the \(^{d}\) sphere of radius \(\), and most importantly (iii) any Lipschitz transformation \((_{i}^{(t)})\) of the above two cases, with bounded Lipschitz norm. Scenario (iii) is especially pertinent for modeling data in realistic settings. Recent research  has demonstrated that images produced by generative adversarial networks (GANs) are inherently qualified as concentrated random vectors.

Next, we present a classical RMT assumption that establishes a commensurable relationship between the number of samples and dimension.

**Assumption 2** (High-dimensional asymptotics).: _As \(d\), \(n_{t}=(d)\) and \(T=(1)\). More specifically, we assume that \(n/dc_{0}<\) with \(n=_{t=1}^{T}n_{t}\)._

Although different from classical asymptotic where the number of samples is implicitly assumed to be exponentially larger than the dimension, the high-dimensional asymptotic finds many applications including telecommunications , finance  and machine learning [11; 14; 48].

## 4 Main Theoretical Results

### Estimation of the Performances

Given the training dataset \(^{n d}\) with the corresponding response variable \(^{n q}\) and for any test dataset \(^{(t)}^{d}\) and the corresponding response variable \(^{(t)}^{q}\), we aim to derive the theoretical training and test risks defined as follows:

\[_{train}^{}=[\|-g( )\|_{2}^{2}],_{test}^{}= _{t=1}^{T}[\|^{(t)}-g(^{(t)})\|_{2}^{2}]\]The output score \(g(^{(t)})^{q}\) for data \(^{(t)}^{d}\) of task \(t\) is given by:

\[g(^{(t)})=}(_{t}^{[T]} ^{(t)})^{}}_{t}=(_{t}^{[T]}^{(t)})^{} \] (5)

In particular, the output for the training score is given by:

\[g()=^{} ,=(^{} }{Td}+_{Td})^{-1}\] (6)

To understand the statistical properties of \(^{}_{train}\) and \(^{}_{test}\) for the linear generative model, we study the statistical behavior of the resolvent matrix \(\) defined in (6). The notion of a deterministic equivalent from random matrix theory  is particularly useful here as it allows us to design a deterministic matrix equivalent to \(\) in the sense of linear forms. Specifically, a deterministic equivalent \(}\) of a random matrix \(\) is a deterministic matrix that satisfies \(u(-}) 0\) almost surely for any bounded linear form \(u:^{d d}\). We denote this as \(}\). This concept is crucial to our analysis because we need to estimate quantities such as \(()\) or \(^{}\), which are bounded linear forms of \(\) with \(,\) and \(\) all having bounded norms. For convenience, we further express some contributions of the performances with the so-called "coresolvent" defined as \(}(^{}^{ }}{Td}+_{Td})^{-1}\).

Using Lemma 1 provided in the Appendix C.1, whose proofs are included in Appendices C.2, C.3 and C.4, we establish the deterministic equivalents that allow us to introduce our Theorems 5 and 1, characterizing the asymptotic behavior of both training and testing risks.

**Theorem 1** (Asymptotic train and test risk).: _Assuming that the training data vectors \(^{(t)}_{i}\) and the test data vectors \(^{(t)}\) are concentrated random vectors, and given the growth rate assumption (Assumption 2), it follows that:_

\[^{}_{test}=(^{ }^{-}}_{2}()^{- })}{Td}}_{}+(_{n}}_{2})}{Td}+( _{n})}_{}.\] (ATR)

_In addition, the asymptotic risk on the training data is given by_

\[^{}_{train}(^ {}^{-1/2}}^{-1/2})}{Tn }-(^{}^{-1/2}}_{ 2}(_{Td})^{-1/2})}{Tn}+ (_{n}}_{2})}{Tn},\]

_where \(}\), \(}_{2}(_{Td})\) and \(}_{2}\) are respectively deterministic equivalents for \(}\), \(}^{2}\) and \(^{2}\)._

We defer the full proof of this theorem to Appendix D and provide an outline of the test risk proof below. Note that derivations of the asymptotic risk for the training data are more complex and involve computing deterministic equivalents (Lemma 1 of Appendix C.1), which is a powerful tool commonly used in Random Matrix Theory. In the derived theorem, we achieve a stronger convergence result compared to the almost surely convergence. Specifically, we prove a concentration result for the training and test risk with an exponential convergence rate for sufficiently large values of \(n\) and \(d\).

\[_{test}^{} =[\|-g()\|_{2}^{2}]\] \[=[\|^{}}{ }+-^{}^{}}{Td}-^{} }{Td}\|_{2}^{2}]\] \[=[(^{ })}{Td}-( ^{}^ {})}{(Td)^{2}}+( ^{})+(^{ }^{} ^{})}{(Td)^{3}}+\] \[=(^{} )}{Td}-2(^{}^{}(_{Td}-})^{- })}{Td}+( ^{})+(^{ })}{Td}\] \[-2(^{} A^{}}A^{-} )}{Td}+^{}^{-} }_{2}()^{-}}{Td}+\, (_{N}}_{2})+O(})\]

### Error Contribution Analysis

To gain theoretical insights, we analyze (ATR) consisting of the signal and the noise components.

**Signal Term.** The signal term can be further approximated, up to some constants as \((^{}(+)^{-2} )\) with \(=_{t=1}^{T}}{d}^{(t)}\). The matrix \((+)^{-2}\) plays a crucial role in amplifying the signal term \((^{})\), which in turn allows the test risk to decrease. The off-diagonal elements of \(+)^{-2}\) amplify the cross terms \(((_{v}^{}_{t})\) for \(t v)\), enhancing the multi-task aspect, while the diagonal elements amplify the independent terms (\(\|_{t}\|_{2}^{2}\)). This structure is significant in determining the effectiveness of multi-task learning.

Furthermore, both terms decrease with an increasing number of samples \(n_{t}\), smaller values of \(_{t}\), and a larger value of \(\). The cross term, which is crucial for multi-task learning, depends on the matrix \(_{t}^{-1}_{v}\). This matrix represents the shift in covariates between tasks. When the features are aligned (i.e., \(_{t}^{-1}_{v}=_{d}\)), the cross term is maximized, enhancing multi-task learning. However, a larger Fisher distance between the covariances of the tasks results in less favorable correlations for multi-task learning.

**Noise term.** Similar to the signal term, the noise term can be approximated, up to some constants, as \((_{N}(^{-1}+)^{-1})\). However, there is a major difference between the way both terms are expressed in the test risk. The noise term does not include any cross terms because the noise across different tasks is independent. In this context, only the diagonal elements of the matrix are significant. This diagonal term increases with the sample size and the value of \(\). It is responsible for what is known as negative transfer. As the diagonal term increases, it negatively affects the transfer of learning from one task to another. This is a critical aspect to consider in multi-task learning scenarios.

### Simplified Model for Clear Insights

In this section, we specialize the theoretical analysis to the simple case of two tasks (\(T=2\)). We assume that the tasks share the same identity covariance and that \(_{1}=_{2}\). Under these conditions, the test risk can be approximated, up to some constants, as

\[_{test}^{}=_{IL}(\|_{1}\|_{2}^{2}+\| _{2}\|_{2}^{2})+_{MTL}_{1}^{} _{2}+_{NT}_{n}\]

where the diagonal term (independent learning) \(_{IL}\), the cross term (multi-task learning) \(_{MTL}\), and the noise term (negative transfer) \(_{NT}\) have closed-form expressions depending on \(\) and \(\):

\[_{IL} =(+)+1)^{2}+c_{0}^{2}^{2}}{(c_{0} (+)+1)^{2}-c_{0}^{2}^{2}},_{MTL}=(c_{0}(+)+1)}{(c_{0}(+)+1)^{2}-c_{0}^{2} ^{2}}\] \[_{NT} =(+)^{2}+(+)-c_{0}^{2 })^{2}+^{2}}{((c_{0}(+)+1)^{2}-c_{0}^{2}^{2} )^{2}}\]We recall that \(c_{0}\) has been defined in the Assumption 2. As previously mentioned, the test risk is primarily composed of two terms: the signal term and the noise term, which are in competition with each other. The more similar the tasks are, the stronger the signal term becomes. In the following plot, we illustrate how this competition can influence the risk. Depending on the value of the parameter \(\) and the sample sizes, the risk can either decrease monotonically, increase monotonically, or exhibit a convex behavior. This competition can lead to an optimal value for \(\), which interestingly has a simple closed-form expression that can be obtained by deriving the \(^{}_{test}\) w.r.t. \(\) as follows (see details in Appendix E.4):

\[^{}=-,\ \ =_{1}\|_{2}^{2}+\|_{2}\|_{2}^{2}}{ _{N}}+_{1}^{}_{2}}{ _{N}}.\]

### Comparison between Empirical and Theoretical Predictions

In this section, we compare the theoretical predictions with the empirical results. Our experiment is based on a two-task setting (\(T=2\)) defined as \(_{1}(0,I_{p})\) with \(_{2}=_{1}+}_{1}^{}\). \(_{1}^{}\) represents any vector orthogonal to \(_{1}\) and \(\). This setting allows us to adjust the similarity between tasks through \(\).

Figure 2 shows a comparison of the theoretical and empirical classification errors for different values of \(\), highlighting the error-minimizing value of \(\). Despite the relatively small values of \(n\) and \(p\), there is a very precise match between the asymptotic theory and the practical experiment. This is particularly evident in the accurate estimation of the optimal value for \(\).

Figure 1: Test loss contributions \(_{IL}\), \(_{MTL}\), \(_{NT}\) across three sample size regimes. Test risk exhibits decreasing, increasing, or convex shapes based on the regime. \(^{}\) from theory are marked.

Figure 2: Empirical and theoretical train and test MSE as functions of the parameter \(\) for different values of \(\). The smooth curves represent the theoretical predictions, while the corresponding curves with the same color show the empirical results, highlighting that the empirical observations indeed match the theoretical predictions.

## 5 Hyperparameter Optimization in Practice

### Empirical Estimation of Task-wise Signal, Cross Signal, and Noise

All the quantities defined in Theorem 1 are known except for the bilinear expressions \((^{})\) and \((_{N})\). These quantities can be consistently estimated under Assumptions 2 as follows (see details in Section F of the Appendix) :

\[(^{})-( )}0,( _{N})- }0\]

where \(()=(}^{}^{-1}( )})-}{Td} }_{2}(^{}^{-1}()^{})\).

We define the estimate of the noise as \(=_{ 0\\ _{t}}^{}_{train}\) and the function \(^{-1}\) is the functional inverse of the mapping \(:^{Td Td}^{q q}\) defined as follows

\[()=-2^{-}} ^{}+^{-}} _{2}(^{}^{})^{ -}-}^{-} ^{-}}_{2}(^{} ^{}).\]

### Application to Multi-task Regression

In our study, we apply the theoretical framework presented in our paper to a real-world regression problem, specifically, the _Appliance Energy dataset_ which aims to predict the total usage of a house. This dataset is a multivariate regression dataset containing \(138\) time series each of dimension \(24\). We select two of these features as 2 tasks to cast the problem as a multi-task learning regression problem.

Figure 3 presents a comparison between the theoretical predictions and empirical outcomes of our proposed linear framework. Despite the assumptions made in the main body of the paper, the theoretical predictions closely align with the experimental results. This demonstrates that our estimates are effective in practice and provide a reliable approximation of the optimal regularization.

In essence, our theoretical framework, when applied to real-world multi-task learning regression problems, yields practical and accurate estimates, thereby validating its effectiveness and applicability.

### Relevance of the theoretical insights beyond the case of linear models

While non-linear models are widely used, establishing their theoretical foundations is challenging. Therefore, we focused on linear models, which, despite their simplicity, provide valuable insights into more complex models.

Figure 3: Theoretical vs Empirical MSE as function of regularization parameter \(\). Close fit between the theoretical and the empirical predictions which underscores the robustness of the theory in light of varying assumptions as well as the accuracy of the suggested estimates. We consider the first two channels as the the two tasks and \(d=144\). \(95\) samples are used for the training and \(42\) samples are used for the test.

Our results show that test risk curves for non-linear models follow patterns predicted by our theory. This is expected because non-linear models in time series forecasting typically use a linear output layer for prediction. Thus, we can apply our theory to the inputs of this final linear layer. This approach is valid due to data concentration and the Lipschitz nature of neural networks, ensuring outputs of the non-linear part don't deviate significantly from the inputs.

Moreover, multivariate time series models often treat channels separately using univariate methods, missing cross-channel information. Our results in Section 5.4 show that our method surpasses univariate baselines by optimally regularizing with \(\) and \(\), supporting our theory's applicability to non-linear models as the final linear layer effectively leverages concentrated inputs.

Finally, our regularization approach differs from traditional cross-task regularizations that use one task per dataset. We consider each prediction as a task and introduce \(_{t}\) parameters alongside \(\). These parameters enforce multivariate regularization and control underfitting or overfitting per task. This method is tractable since it's applied at the model's final layer.

The similarity between curves for non-linear and linear models indicates our findings are robust; non-linear models also exhibit optimal regularization parameters, enhancing performance in multivariate forecasting.

### Application to Multivariate Time Series Forecasting

Our theoretical framework is applied in the context of Multivariate Time Series Forecasting, with related work detailed in Appendix G.1. We previously applied this framework in a linear setting, and now aim to evaluate its empirical validity in the non-linear setting of neural networks. The results presented in this section represent the best test MSE, assuming the ability to find the optimal lambda value, which can be considered as an oracle scenario. A study of these limitations can be found in Appendix H.

Motivation.Our approach is applied to the MTSF setting for several reasons. Firstly, many models currently used are essentially univariate, where predictions for individual series are simply concatenated without exploiting the multivariate information inherent in traditional benchmarks. Given that these benchmarks are designed for multivariate forecasting, leveraging multivariate information should yield better results. Secondly, our theoretical framework can benefit this domain, as most predictive models use a linear layer on top of the model to project historical data of length \(d\) for predicting the output of length \(q\). This characteristic aligns well with our method, making it a promising fit for enhancing forecasting accuracy.

Our approach.We propose a novel method for MTSF by modifying the loss function to incorporate both individual feature transformations \(f_{t}\) and a shared transformation \(f_{0}\). Each univariate-specific transformation \(f_{t}\) is designed to capture the unique dynamics of its respective feature, while \(f_{0}\) serves as a common transformation applied across all features to capture underlying patterns shared among them. We consider a neural network \(f\) with inputs \(=[^{(1)},^{(2)},,^{(T)}]\), where \(T\) is the number of channels and \(^{(t)}^{n d}\). For a univariate model without MTL regularization, we predict \(=[^{(1)},^{(2)},,^{(T)}]=[f_{1} (^{(1)}),,f_{T}(^{(T)})]\) and \(^{(t)}^{n q}\). We compare these models with their corresponding versions that include MTL regularization, formulated as: \(f_{t}^{MTL}(^{(t)})=f_{t}(^{(t)})+f_{0}()\) with \(f_{t}:^{n d}^{n q}\) and \(f_{0}:^{n qT}^{n q}\). We define our regularized loss as follows:

\[(,)=_{t=1}^{T}\|^{(t)}-f_{t}^{ MTL}(^{(t)})\|_{F}^{2}+\|f_{0}()\|_{F}^{2}+_{t=1} ^{T}_{t}\|f_{t}(^{(t)}\|_{F}^{2}, t\{1,,T\}.\]

where \(^{(t)}\) are the true predictions, \(f_{t}\) represents the univariate model for each channel \(t\), and \(\) is our regularization parameter, for which we have established a closed form in the case of linear \(f_{t}\). \(f_{0}\) serves a role equivalent to \(W_{0}\), which was defined in our theoretical study and allows for the regularization of the common part. This component can be added at the top of a univariate model. The parameters \(_{t}\) enable the regularization of the specialized parts \(f_{t}\).

In our setup, \(f_{t}\) is computed in a similar way as in the model without regularization and \(f_{0}\) is computed by first flattening the concatenation of the predictions of \(^{(t)}\), then applying a linear projection leveraging common multivariate information before reshaping. The loss function is specifically designed to balance fitting the multivariate series using \(f_{0}\) and the specific channels using \(f_{t}\). Thisapproach enhances the model's generalization across various forecasting horizons and datasets. More details on our regularized loss function can be found in Appendix G.2

**Results.** We present experimental results on different forecasting horizons, using common benchmark MTSF datasets, the characteristics of which are outlined in the Appendix G.3. Our models include PatchTST, known to be on par with state-of-the-art in MTSF while being a univariate model, a univariate DLinear version called DLinearU compared to its multivariate counterpart DLinearM, and a univariate Transformer with temporal-wise attention compared to the multivariate state-of-the-art models SAMformer and iTransformer. Table 1 provides a detailed comparison of the test mean squared errors (MSE) for different MTSF models, emphasizing the impact of MTL regularization. Models with MTL regularization are compared to their versions without regularization, as well as SAMformer and iTransformer. All the experiments can be found in Appendix G.4.

Adding MTL regularization improves the performance of PatchTST, DLinearU, and Transformer in most cases. When compared to state-of-the-art multivariate models, the MTL-regularized models are often competitive. SAMformer is outperformed by at least one MTL-regularized method per horizon and dataset, except for ETH1 with horizons of 336 and 720. iTransformer is consistently outperformed by at least one MTL-regularized methods regardless of the dataset and horizon.

The best performing methods are PatchTST and DLinearU with MTL regularization. These models not only outperform their non-regularized counterparts, often significantly as shown by Student's t-tests with a p-value of 0.05, but also surpass state-of-the-art multivariate models like SAMformer and Transformer. This superior performance is indicated by the bold values in the table.

Finally, MTL regularization enhances the performance of univariate models, making them often competitive with state-of-the-art multivariate methods like SAMformer and iTransformer. This approach seems to better captures shared dynamics among tasks, leading to more accurate forecasts.

## 6 Conclusions and Future Works

In this article, we have explored linear multi-task learning by deriving a closed-form solution for an optimization problem that capitalizes on the wealth of information available across multiple tasks. Leveraging Random Matrix Theory, we have been able to obtain the asymptotic training and testing risks, and have proposed several insights into high-dimensional multi-task learning regression. Our theoretical analysis, though based on a simplified model, has been effectively applied to multi-task regression and multivariate forecasting, using both synthetic and real-world datasets. We believe that our work lays a solid foundation for future research, paving the way for using random matrix theory with more complex models, such as deep neural networks, within the multi-task learning framework.

    &  &  &  \\   & & PatchTST & DLinearU & Transformer & PatchTST & DLinearU & DLinearU & Transformer & SAMformer\({}^{}\) & iTransformer\({}^{}\) \\   & 96 & 0.385 & **0.367** & 0.368 & 0.387 & 0.397 & 0.386 & 0.370 & 0.381 & 0.386 \\  & 192 & 0.422 & **0.405** & 0.407 & 0.424 & 0.422 & 0.437 & 0.411 & 0.409 & 0.441 \\  & 336 & 0.432* & 0.431 & 0.433 & 0.442 & 0.431 & 0.481 & 0.437 & **0.423** & 0.487 \\  & 720 & 0.430* & 0.454 & 0.455* & 0.451 & 0.428 & 0.519 & 0.470 & **0.427** & 0.503 \\   & 96 & 0.291 & **0.267** & 0.270 & 0.295 & 0.294 & 0.333 & 0.273 & 0.295 & 0.297 \\  & 192 & 0.346* & **0.331** & 0.337 & 0.351 & 0.361 & 0.477 & 0.339 & 0.340 & 0.380 \\  & 336 & **0.332*** & 0.367 & 0.366* & 0.342 & 0.361 & 0.594 & 0.369 & 0.350 & 0.428 \\  & 720 & **0.384*** & 0.412 & 0.405* & 0.393 & 0.395 & 0.831 & 0.428 & 0.391 & 0.427 \\   & 96 & **0.148** & 0.149* & 0.154* & 0.149 & 0.196 & 0.196 & 0.170 & 0.197 & 0.174 \\  & 192 & **0.190** & 0.206* & 0.198* & 0.193 & 0.243 & 0.237 & 0.214 & 0.235 & 0.221 \\   & 336 & **0.242*** & 0.249* & 0.258 & 0.246 & 0.283 & 0.283 & 0.260 & 0.276 & 0.278 \\   & 720 & **0.316*** & 0.326* & 0.331 & 0.322 & 0.339 & 0.345 & 0.326 & 0.334 & 0.358 \\   

Table 1: MTL regularization results. Algorithms marked with \({}^{}\) are state-of-the-art multivariate models and serve as baseline comparisons. All others are univariate. We compared the models with MTL regularization to their corresponding versions without regularization. Each MSE value is derived from 3 different random seeds. MSE values marked with * indicate that the model with MTL regularization performed significantly better than its version without regularization, according to a Studentâ€™s t-test with a p-value of 0.05. MSE values are in **bold** when they are the best in their row, indicating the top-performing models.