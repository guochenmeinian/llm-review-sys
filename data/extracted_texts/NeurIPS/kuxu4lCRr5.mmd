# PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning.

Mingjia Shi\({}^{1}\)1 &Yuhao Zhou\({}^{1}\) &Kai Wang\({}^{2}\) &Huiazheng Zhang

**Shudong Huang\({}^{1}\)** &Qing Ye\({}^{1}\)2 &Jiangcheng Lv\({}^{1}\)3

\({}^{1}\)Sichuan University &National University of Singapore

###### Abstract

Classical federated learning (FL) enables training machine learning models without sharing data for privacy preservation, but heterogeneous data characteristic degrades the performance of the localized model. Personalized FL (PFL) addresses this by synthesizing personalized models from a global model via training on local data. Such a global model may overlook the specific information that the clients have been sampled. In this paper, we propose a novel scheme to inject personalized prior knowledge into the global model in each client, which attempts to mitigate the introduced incomplete information problem in PFL. At the heart of our proposed approach is a framework, the _PFL with Bregman Divergence_ (pFedBreD), decoupling the personalized prior from the local objective function regularized by Bregman divergence for greater adaptability in personalized scenarios. We also relax the mirror descent (RMD) to extract the prior explicitly to provide optional strategies. Additionally, our pFedBreD is backed up by a convergence analysis. Sufficient experiments demonstrate that our method reaches the _state-of-the-art_ performances on 5 datasets and outperforms other methods by up to 3.5% across 8 benchmarks. Extensive analyses verify the robustness and necessity of proposed designs. https://github.com/BDeMo/pFedBreD_public

## 1 Introduction

Federated learning (FL)  has achieved significant success in many fields , which include recommendation systems utilized by e-commerce platforms , prophylactic maintenance for industrial machinery , disease prognosis employed in healthcare . Data heterogeneity is a fundamental characteristic of FL, leading to challenges such as inconsistent training and testing data (data drift) . An efficient solution to these challenges is to fine-tune the global model locally for adaptation on local data . This solution is straightforward and pioneering, but presents a fundamental limitation when dealing with highly heterogeneous data. For examples, heterogeneous data drift may introduce substantial noise  and the resulted model may not generalize well to new sample . Thus, heterogeneous data in FL is still challenging .

Recently, personalized FL (PFL) is proposed to mitigate the aforementioned negative impact of heterogeneous data . To improve the straightforward solution mentioned above, Per-FedAvg  is introduced to train a global model that is easier to fine-tune. Another paper on the similar topic, FedProx , aims to resolve the issue of personalized models drifting too far from the global model during training with a dynamic regularizer in the objective during local training. This issue could occur especially in post-training fine-tuning methods without regularization (_e.g._, Per-FedAvg ). Moreover, pFedMe , another regularization method modeling local problems using Moreauenvelopes, replaces FedProx's personalized model aggregation method with an interpretable approach for aggregating local models . It also accommodates first-order Per-FedAvg .

Although the existing PFL methods have achieved promising results, the prior knowledge from single global model for local training  hinders the development of PFL. Specifically, we analyze the shortcomings of current PFL methods as follows: 1) utilizing the same global model for direct local training could potentially disregard the client's sampling information. As shown in Figure 1, a single global model provides global knowledge directly for local training, which overlooks the client-sampling information when the global knowledge is transferred to specific clients. 2) Explicitly extracting prior knowledge can be a challenging task. Most of the insightful works  propose assumptions for recovering this incomplete information, but these assumptions are implicit, which limits the way to use the information to develop personalized strategies.

To address the former issue above, we propose framework pFedBreD to inject personalized prior knowledge into the one provided by a global model. As shown in Figure 1, it is injected in the \(2^{nd}\) step and the local knowledge is transferred into global model via local models instead of directly aggregating personalized models . To address the latter, we introduce _relaxed mirror descent_ RMD to explicitly extract the prior for exploring personalized strategies.

Our method is backed up with direct theoretical support from Bayesian modeling in Section 4 and a convergence analysis in Section 5, which provides a linear bound \((1/TN)\) with aggregation noise and a quadratic speedup \((1/(TNR)^{2})\) without.3 Meanwhile, the existence and validity of the injection and extraction aforementioned information is verified in Section 6.2. The remarkable performance of the implements of the proposed method is tested on 5 datasets and 8 benchmarks. Consistently, our method reach the _state-of-the-art_. Especially, the improvement of accuracy on task DNN-FEMNIST  is up to 3.5%. Extensive ablation study demonstrate that parts of the hybrid strategy \(\) are complementary to each other. Our contributions can be summarized as follows:

* The problem of overlooking client-sampling information at prior knowledge being transferred is introduced in this paper, and we first investigate the possibility of explicitly expressing the prior knowledge of the information and design personalized strategies on it.
* To express the personalized prior, we model PFL into a Bayesian optimization problem, _Global-MLE and Local-MAP_. A novel framework, pFedBreD, is proposed for computing the modeled problem, and RMD is introduced to explicitly extract prior information.
* Sufficient experiments demonstrate our method surpasses most baselines on public benchmarks, thereby showcasing its robustness to data heterogeneity, particularly in cases involving small aggregation ratios and non-convex local objective settings.

Figure 1: pFedBreD framework: Global-MLE and Local-MAP. The personalized prior knowledge is injected into the global model of the global problem (MLE) in the \(2^{nd}\) step for local training. The local knowledge is extracted from the local problem (MAP) in the \(4^{th}\) step for aggregation.

Related Works

RegularizationResearchers have developed a variety of approaches based on regularization to handle the PFL challenge in recent years (_e.g._, FedU , pFedMe , FedAMP , HeurFedAMP ). All of these approaches' personalized objective functions can be expressed as \(J()+R(;)\) where \(J()\) is the loss function of the local problem and \(R(;)\) is the regularization term used to restrict the deviation between \(\) and \(\) (_e.g._, \(R(;)=\|-\|^{2}\) in pFedMe).

Meta LearningOne of the most representative meta-learning based single-model PFL approach is the well-known Per-FedAvg , aiming to find an initialization that is easy to fine-tune. That is, the global model in the FL setting is regarded as a meta model in MAML [21; 19], where the objective function of the local problem is \(J(- J())\). Researchers also show the connections between FedAvg  and Reptile , another meta learning framework.  shows how to improve personalization of FL via Reptile. Proximal updating is also used in meta-learning based algorithms such as . One of our strategies \(\) is the one motivated by MAML.

Expectation MaximizationTwo EM-based  methods are proposed, _e.g._, FedSparse in  and FedEM in . Both of them focus on communication compression. The latter provides a variance reduce version and assumes complete information (or data) of the global model obeys distribution in X-family. Another FedEM  combines Bayesian modeling, Federated Multi-task learning (FTML) and EM. Our framework pFedBreD is a expectation maximuzatioin and maximum a posteriori estimate (EM-MAP)  algorithm with personalized prior specified.

Bayesian FLIn recent years, studies of PFL with Bayesian learning have been proposed. In related approaches, FLOA  and pFedGP  are proposed with KL divergence regularization in the loss function, which is comparable to applying specific assumption of X-family prior in pFedBreD see Appendix B.2 for details. Our implementation doesn't use a Bayesian neural network (BNN) model as an inferential model as others do (_e.g._, pFedGP uses a Gaussian process tree and pFedBayes  uses BNN). Instead, to eliminate weight sampling cost in Bayesian methods, prior knowledge is introduced through regularization term.

## 3 Preliminary

Overlooked Information in Prior KnowledgeFrom a Bayesian and info. perspective, the global knowledge transferred in conventional method with single global model has no mutual information (MI) with client sampling \(i\), i.e., formally, \(w=_{i}w_{i}=_{i}w_{i}|iI(w;i)=0\), in particular when applying reg. \(R(w^{(t)};...)\) or local init. \(w^{(t)}_{i,0} w\) where \(w_{i}\) is the local model on the \(i^{th}\) client. This makes the specific model on each client have to re-obtain this information from scratch solely from the data during training, especially impacted on hard-to-learn representations and datasets.

Bregman-Moreau EnvelopeBregman divergence  is employed as a general regular term in our local objective that exactly satisfies the computational requirements and prior assumption, and is formally defined in Eq. (1).

\[_{g}(x,y): =g(x)-g(y)- g(y),x-y\] (1)

where \(g\) is a convex function. For convenience, \(g\) is assumed to be strictly convex, proper and differentiable such that Bregman divergence is well-defined. To utilize the computational properties of Bregman Divergence in optimization problems, we introduce the following definition in Eq. (2) [7; 8]: Bregman proximal mapping, Bregman-Moreau envelope, and the relationship between them.

\[_{g,^{-1}}f(x) :=_{}\{f()+_{g}(,x)\},\] (2) \[_{g,^{-1}}f(x) :=_{}\{f()+_{g}(,x)\},\] \[_{g,^{-1}}f(x) =^{2}g(x)[x-_{g,^{-1 }}f(x)],\]

where \(>0\) denotes the regular intensity in general and the variance of the prior in our modeling.

Exponential FamilyThe regular exponential family (X-family) is a relatively large family that facilitates calculations. Therefore, to yield the prior, we employ the X-family defined in Eq. (3).

\[_{ef}(;s,g)=h()\{,s- g(s)\}=h()\{-_{g^{*}}(,)+g^{*}()\},\] (3)

where \(g\) is assumed to be convex, \(_{g}(,)\) is the Bregman divergence, and \(g^{*}\) is the Fenchel Conjugate of \(g\). In Eq. (3), \(s\), \(h()\) and \(g(s)\) are respectively the natural parameter, potential measure and logarithmic normalization factor, where we have the mean parameter \(= g(s)\). Additionally, to highlight the variance, the scaled exponential family (SX-family) is introduced in Eq. (4)

\[_{sef}(;,s,g)=h_{}()\{ [(,s)-g(s)]\}=h_{}()\{- _{g^{*}}(,)+ g^{*}()\},\] (4)

where \( h_{}()\) is the scaled potential measure, and the scale parameter \(\) is employed to highlight the variance. Moreover, \(\) is assumed to be the minimal sufficient statistic of the complete information for local inference, details of which can be found in Section 4.

## 4 Methodology

In this section4, we introduce missing client-sampling information based on classic FL, use EM to reduce the computational cost of the information-introduced FL problem, and propose RMD, a class of prior selection strategies, based on the E-step in EM. The general FL classification problem with KL divergence could be formulated as Eq. (5) [53; 66].

\[_{w}_{i}_{d_{i}}((y_{i}|x_{i} )||}(y_{i}|x_{i},w))=_{w}_{i}_{d_{ i}}_{y_{i}|x_{i}}}(y_{i}|x_{i},w),(x_{i},y_{i})  d_{i},\] (5)

where we rewrite the discriminant model as an maximum likelihood estimation (MLE) problem  of \(y_{i}|x_{i}\) in the right hand side (R.H.S.) of Eq. (5). \((x_{i},y_{i})\) represent the pairs of input and label respectively in dataset \(d_{i}\) on the \(i^{th}\) client, and \(}(y_{i}|x_{i},w)\) is the inferential model parameterized by \(w\). Each local data distribution is presuppose to be unique, so using the global model with local data for inference and training could overlook the fact that the client has been sampled before transmitting the global model, and the prior knowledge transmitted directly via the global model as the local training prior knowledge (_e.g._ via initial points, penalty points in dynamic regular terms, etc.) has no mutual information with the client sampling, _i.e._, the global model \(w=_{i}w_{i}=_{i}w_{i}|i\). Thus, to reduce the potential impact of the overlooked information, the complete information \(_{i}\) on the \(i^{th}\) client is introduced which turns Eq. (5) into Eq. (6).

\[_{w}_{_{i}}}(y_{i}|x_{i}, _{i},w)(_{i}|x_{i},w)d_{i},\] (6)

where \(=_{i}_{d_{i}}_{y_{i}|x_{i}}\) and the direct calculation of this is computationally expensive .

Framework: Leveraging Expectation Maximization for Prior Parameter ExtractionThe integral term in Eq. (6) makes direct computation impossible , so we employ EM to approximate the likelihood with unobserved variables  as shown in Eq. (7), where \((_{i})\) is any probability measure.

\[_{i}}(y_{i}|x_{i},w)_{i}_{( _{i})}[}(y_{i}|x_{i},_{i},w)+_{y_{i}| x_{i},w}(_{i}|d_{i},w)].\] (7)

Assuming that prior \(_{i}|d_{i},w}_{sef}(_{i};,s_{i}(w;d_{i} ),g)\)5 and the local loss function on the \(i^{th}\) client \(f_{i}(_{i},w)\) is \(_{d_{i}}[-(y_{i}|x_{i},_{i},w)]\), we have the left hand side (L.H.S.) of the Eq. (8) from (7). Here is an assumption for simplification that \(_{i}\) contains all the information for local inference, _i.e._\(_{i}=_{i}\) and \((y_{i}|x_{i},_{i},w)=(y_{i}|x_{i},_{i})\). It happens when \(_{i}\) is all the parameters of the personalized model and we only use the personalized model for inference. Thus, \(f_{i}(_{i})=_{d_{i}}[-}(y_{i}|x_{i},_ {i})]\). Thus, we can optimize an upper bound as a bi-level optimization problem as shown in the R.H.S. of the Eq. (8) to solve Eq. (5) approximately, where mean parameter \(_{i}= g s_{i}\)6. And, we can derivate our framework as shown in Section 5.

\[-_{w,\{_{i}\}}_{i}\{-f_{i}(_{i})- _{g^{*}}(_{i},_{i}(w))\}_{w}_{i}\}}}\{f_{i}(_{i})+_{g^{*}}(_{i},_{i}())\}}.\] (8)Strategies: Relaxing Mirror Descent for Prior SelectionTo extract the prior strategies and implement \(_{i}\) E-step of EM in close-form, we propose a method called relaxed mirror descent (RMD), where the mirror descent (MD) is EM in X-family . MD can be generally written as Eq. (9) from the old \(\) to the new one \(^{+}\) in each iteration .

\[^{+}_{}\{f()+ f( {w}),-+_{}(,)\}.\] (9)

According to the Lagrangian dual, we rewrite the problem into a more general variant shown in Eq. (10) with relaxed restrictions and superfluous parameter.

\[_{,}\{(,)+ (),-+_{g^{*}}(,)+(2)^{-1}||-||^{2}\}.\] (10)

We can transform Eq. (10) back into Eq. (9) by setting \(()\) to satisfy \(()= f()\), and defining \((,)\) as a function with \(f()\) and a penalty term to make \(\) and \(\) close as possible (_e.g._, \(_{}(,)\)). This provides us a way to extract \(_{}\) the function to generate mean parameter of the prior, as shown in Eq. (11), which is minimizing an upper bound of the problem in Eq. (10).

\[_{g^{*},^{-1}}( ,w)(_{}(w))&=_{}\{(,w)+ _{g^{*}}(,_{}(w))\}\\ (w)}&=_{}\{ (w),-w+(2)^{-1}||-w||^{2}\}.\] (11)

By optimality condition, we have \(_{}(w)=w-(w)\), which can be specified by \(\). The remaining part is a Bregman-Moreau envelope. Thus, we can optimize the upper bound with an EM-MAP method, alternately computing \(_{}(w)\) and \(_{g^{*},^{-1}}(,w)(_{}(w))\).

## 5 Framework Design

Problem Formulation that Highlights Personalized PriorInspired by the aforementioned motivation, the personalized models \(_{i}\) and mean parameters are respectively the solution of \(_{g^{*},^{-1}}f_{i}(_{i}(w))\) and \(_{i}(w)\) on the \(i^{th}\) client, where \(w\) is the global model. We assume that personalized model contains all the local information required for inference on the \(i^{th}\) client, and satisfies \(_{i}|d_{i},w_{sef}(_{i};,s_{i}(w),g)\). The global problem can be written as Eq. (12).

\[_{w}_{i}\{F_{i}(w):=_{g^{*},^{-1} }f_{i}((w)})\}.\] (12)

The given \(g\) is strictly convex, \(>0\), \(f_{i}\) is the local loss function, \(s_{i}(w)\) is the natural parameter and \(_{i}(w)=_{_{i}|x_{i},w}_{i}= g(s_{i}(w))\) is the mean (or expectation) parameter in Eq. (12).

Framework: pFedBreDTo solve the optimization problem in Eq. (12), we use gradient-based methods to solve the global problem using the gradient of \(F_{i}\):

\[ F_{i}(w)=_{i}(w)^{2}g^{*}(_{i}(w))[_{ i}(w)-_{g^{*},^{-1}}f_{i}(_{i}(w))],\] (13)

where \(\) is the gradient operator of the vector value function, and \(^{2}\) is the Hessian operator.7 The framework is shown as Algorithm 1, where \(\) is the client selecting strategy for global model aggregation; \(w_{init}\) and \(_{init}\) are the initialization strategies on the \(i^{th}\) client; \(_{m}\) is the main problem step-size; \(T\), \(R\), \(N\) are respectively the total number of iterations, local iterations, and clients. \(\) is used in the same trick as . The strategies to derive the initialization points of \(w_{i}\) and \(_{i}\) at each local epoch are \(w_{i,0}^{(t)} w^{(t-1)}\) and \(_{i,0}^{(t)}_{i,R}^{(t-1)}\).

Implementation: Maximum Entropy and Meta-StepPractically, two main parts of the pFedBreD are needed to be implemented:

* \(g\), the function used to derive the logarithmic normalization factor, determines the type of prior to be used;
* \(\{s_{i}\}\) or \(\{_{i}\}\), the functions used to derive the natural parameter and mean parameter for the personalized local prior, determine which particular prior is used.

[MISSING_PAGE_EMPTY:6]

**Theorem 2** (pFedBreD\({}_{ns}\)'s first-order personalization bound).: _Under the same conditions as in Theorem 1, with prior assumption of a spherical Gaussian and first-order approximation, the bound for the gap between the personalized approximate model and global model in the Euclidean space is:_

\[|_{i}(^{T})-w^{*}||^{2}(_{p})+[_{p}_{F}(^{(T)},w^{*})]\]

_where \(_{p}=_{F,}^{2}}([_{F}^{ 2}}{|_{}|}+^{2})+}_{1}^{2 }+}_{F,*}^{2}+^{2}_{}^ {2}\), and \(_{p}=(}_{F}+_{F,}})\)._

**Remark 1**.: _Theorem 1 shows the main factors that affect the convergence of a global model are as follows: random mini-batch size, client drift error, aggregation error, heterogeneous data, dual space selection, local approximation error, and selection strategy for exponential family prior mean and variance. These can be divided into four categories based on their computational complexity. The first and second term shows that the proper fixed \(_{m}\) can linearly reduce the influence of initial error \(^{(0)}\) and the global model converges to a ball near the optimal point. The radius of this ball is determined by the personalized strategy and local errors (including local data randomness and envelope approximation errors). The third term implies that a linear convergence rate \((1/(NT))\) can be obtained w.r.t. the total global epoch \(NT\) in the presence of aggregation noise. Without client sampling \(N=S\), according to the fourth term, the quadratic rate \((1/(TNR)^{2})\) can be obtained with \(=(N)\) or \(=(N)\) (Note that the number of local epoch \(R\) cannot be too large due to client drift, according to \(2^{R}\)). Theorem 2 shows that, with spherical Gaussian prior assumption and first-order methods, the radius of the neighborhood range for the minimum that includes the personalized model on \(i^{th}\) client, \((C_{,F,f,d}+}(_{1}^{2}+_{F,* }^{2}+}{_{F}})+^{2}_{F, }})\), can be trade-off by \(\), and is affected by the prior selection strategies and first-order approximate error besides the elements in Theorem 1. (Note that the Euclidean space is self-dual.)_

## 6 Experiments

### General Settings

**Tricks, Datasets and Models:** our experiments include several tasks: CNN  on CIFAR-10 [18; 39], LSTM  on Sent140  and MCLR/DNN on FEMNIST /FMNIST [65; 67]/MNIST[65; 42]. The details of tricks (FT, AM), data heterogeneity and models are in Appendix C.

**Baselines:** we choose following algorithms as our baselines: FedAvg , Per-FedAvg , pFedMe , FedAMP , pFedBayes  and FedEM . These baselines are respectively classical FL, MAML-based meta learning, regularization based, FTML methods, variational inference PFL and FMTL with EM.

**Global Test and Local Test:** the global and personalized model, represented by **G** and **P**, are evaluated with global and local tests respectively. Global test means all the test data is used in the test. Local test means only the local data is used for the local test and the weight of the sum in local test is the ratio of the number of data. The results of average accuracy per client are shown in Table 1. Each experiment is repeated 5 times. More details are in Appendix C. For readability, we only give the error bar in the main Table 1 and Table 2, and keep one decimal except for the main Table 1.

Hyperparameter SettingsThe step-size of the main problem, \(_{m}\), and the personalized step-size, \(\), for all methods are 0.01. \(\) is 1, and the number of local epochs, \(R\), is 20 for all datasets. \(\) is chosen from 15.0 to 60.0. The batch sizes of Sent140 and the other datasets are 400 and 20, respectively, and the aggregation strategy, \(\), is uniform sampling. The ratios of aggregated clients per global epoch are 40%, 10%, and 20% for Sent140, FEMNIST, and the other datasets, respectively. The numbers of total clients, \(N\), are 10, 198, 20, and 100 for Sent140, FEMNIST, CIFAR-10, and other datasets. The number of proximal iterations is 5 for all settings with proximal mapping. In our implementations, \(_{}\) and \(\) are respectively 0.01 and 0.05.

Summarizing the Effects of Hyper-parametersWe test the hyper-parameter effect of \(\) and \(\) in our implementation pFedBreD\({}_{ns,}\). The details are in Appendix C. From the results, we find that it will degrade the test accuracy if the values of \(\) or \(\) are too large or too small. The test accuracy of personalized model is more sensitive than the ones of global model. The test accuracy of personalizedmodel is more sensitive to \(\) than to \(\). Note that the hyper-parameters are roughly tuned, which shows the insensitivity of \(\), and better tuning could improve the performance in the Table 1.

### Analysis

Comparative Analysis of PerformanceWe compare our methods and the baselines from different perspectives, including convex or non-convex problems, easy or hard tasks, and text tasks. Additionally, we briefly discuss the absence of BNN on hard tasks.

**Convex or non-convex:** on non-convex problems, especially in hard tasks, our method significantly outperforms other methods by at least 3.06% employing some simple tricks. On convex problem, FedAMP outperforms our method somewhat on convex problems with simple data sets. One explanation is that the learning lansecap is simple in shape for these problems and FedAMP converges faster for this case. One possible reason for this is that since FedAMP uses the distance between models as a similarity in the penalty point selection, giving greater weight to the model that is most similar to the local one. In the later stages of training, since there is only one global optimum, this penalty point tends not to change, and thus the method degenerates into a non-dynamic regular term. Compounding intuition, this method will not be as advantageous for non-convex problems and harder convex problems, as penalty point tends to fall into the local optimum and lead to degradation of the dynamic regular term.

**From easy to difficult task:** from the difference between the statistics of Avg and \(\) in Table 1, it can be observed that meta-step methods perform most consistently, with all other methods dropping at least 10%. This is due to the simple and effective local loss design of MAML, with its learning-to-learning design philosophy that enables the method to be more stable in complex situations [19; 20].

**Personalized prior on text:** text tasks, as opposed to image tasks, generally have relatively rugged learning landscape. [55; 16; 13] This understanding is manifested in specific ways, such as parameter sensitivity, slow convergence, and struggling during the process. Thus, the overlooked prior information seems to be more important, which means that each local iteration not only obtains local knowledge from the data, but also the prior itself already contains some local knowledge. Therefore, there is no need to re-obtain this knowledge from scratch solely from the data during training.

**Absence of BNN on hard tasks:** complex BNN is not in Table 1, such as LSTM in pFedBayes, because it is difficult to conduct comparative experiments by fixing elements, _e.g._, inferential models, tricks and optimization methods. In pFedBayes, training often crashes on hard tasks and large datasets, as mentioned in . Our one-step-further research shows that it may be caused by the reparameterization tricks and vanilla Gaussian sampling. If we add tricks on it, the implementation will be very different from the original pFedBayes, and it is beyond this analysis.

Ablation Analysis of Personalized PriorWe conduct ablation experiments by dropping the gradient of the Bregman-Moreau envelope, the local loss function, or both, from the personalized

    &  &  &  &  &  &  \\  &  &  &  &  &  &  &  &  &  &  &  &  &  \\  PolarB  & 54.31\(\)0.5 & 57.04\(\)0.0 & 58.27\(\)50.0 & 80.09\(\)0.0 & 86.56\(\)0.0 & 88.26\(\)0.0 & 89.31\(\)0.6 & 57.51\(\)0.0 & 76.50\(\)0.0 & 76.16\(\)0.0 & 78.45\(\)0.0 & 67.98\(\)0.0 & 7.58 \\ FedAMP-M  & 53.34\(\)0.0 & 59.03\(\)0.0 & 59.03\(\)0.0 & 58.31\(\)0.0 & 58.04\(\)0.0 & 59.31\(\)0.0 & 57.94\(\)0.0 & 57.67\(\)0.0 & 77.63\(\)0.0 & 66.72\(\)0.0 & 71.81\(\)0.0 & 61.42\(\)0.0 & 62.6 & 7.30 \\ FedAMP-M  & 40.75\(\)0.0 & 45.71\(\)0.0 & 59.78\(\)0.0 & 59.42\(\)0.0 & 58.57\(\)0.0 & 58.49\(\)0.0 & 59.49\(\)0.0 & 57.67\(\)0.0 & 66.72\(\)0.0 & 71.88\(\)0.0 & 22.28\(\)0.0 & 56.62 & 10.66 \\ pFedBayes  & 47.96\(\)0.0 & 46.94\(\)0.0 & 59.46\(\)0.0 & 59.46\(\)0.0 & 59.46\(\)0.0 & 59.46\(\)0.0 & 59.46\(\)0.0 & 49.46\(\)0.0 & 49.58\(\)0.0 & 11.80\(\)0.0 & 152.1\(\)0.0 & 71.34 & 5.46 \\ FedAMP-M  & 60.04\(\)0.0 & 66.79\(\)0.0 & **58.63\(\)0.0** & 68.72\(\)0.0 & **59.22\(\)0.0** & 59.31\(\)0.0 & 72.21\(\)0.0 & 67.23\(\)0.0 & 69.53\(\)0.0 & 31.00\(\)0.0 & 17.68\(\)0.0 & 19.65\(\)0.0 & 10.06 \\ pFedBayes-M  & 59.04\(\)0.0 & 15.35\(\)0.0 & 53.21\(\)0.0 & 67.03\(\)0.0 & 58.96\(\)0.0 & 59.41\(\)0.0 & 57.11\(\)0.0 & 67.18\(\)0.0 & 67.28\(\)0.0 & 79.13\(\)0.0 & 16.53\(\)0.0 & 66.61 & 10.96 \\ pFedBayes-M  & 58.55\(\)0.0 & 60.08\(\)0.0 & 60.06\(\)0.0 & 57.75\(\)0.0 & 59.46\( \(\) as shown in Table 2. The relationship among the three strategies mentioned in Eq. (14) is that \(\) consists of \(\) and \(\). Moreover, pFedMe can be regarded in our framework as the one which takes the spherical Gaussian as prior and uses vanilla prior selection strategy \(_{i}=I\) without personalization. Thus, pFedMe and the three implementations of pFedBreD are compared. The results reveal the instability of our implementation \(\) and the introduction of \(\) on difficult tasks is about the same as not introducing it. However, introducing both \(\) and \(\) (i.e., \(\)) together shows remarkable performance. This indicates that \(\) and \(\) complement each other. **To explain these results**, by observing the error bars, in most of the settings, \(\) is significantly more stable compared to methods that do not use personalized priors, while \(\) is relatively less stable. Based on this observation, we have reason to believe that \(\) weakens the influence of potential noise, while \(\) introduces new noise. Therefore, we can infer that while the mean parameters are steadily biased towards the personalized model, the introduction of new noise finds a path that is more likely to escape from local optima or saddle points, based on implicit regularization .

Generalized Coherence Analysis of Information Injection and ExtractionThe generalized coherence estimate (GCE)  of vectors from personalized to local model (_i.e._, the envelope gradients in pFedMe and ours) among clients on each global epoch are shown in Figure 2. The smaller the GCE, the less coherent the envelope gradient between individual nodes and the greater the diversity of information in the global model update. As shown in Figure 2, we can observe that during the convergence phase, using a personalized prior method has significantly greater information diversity than not using a personalized prior method, which proves the success of injecting personalized prior knowledge into the global model and extracting local knowledge from the local training.

Variable-Control Analysis of RobustnessWe analyze the impact of aggregation noise and data heterogeneity  on our method, mainly \(\), by controlling variables. Results are in Table 3 and Table 4. (Details are in Appendix C.8.) We test the performance of global model on different aggregation ratios, where all hyper-parameters except for the aggregation ratios are fixed. Meanwhile, we test the performance of both global and the personalized model on different data heterogeneity settings, where full aggregation (sample client equals total number of clients, \(S=N\)) and one-step local update (local epoch \(R=1\)) are employed to get rid of the effects of aggregation noise and client drift. The experiments demonstrate the instability of the global model in \(\) at small aggregation ratios, which most of the other PFL methods have, by comparing their performances on different aggregation numbers. Comparing to the baselines, the experiments also demonstrate the relative robustness of our method to extreme data heterogeneity.

   &  &  &  &  &  &  \\  & MCL & DNN & MCL & DNN & & MCL & DNN & &  &  &  \\  Non-PP & \(507.8_{ 0.10}\) & \(53.6_{ 0.12}\) & \(97.6_{ 0.03}\) & \(98.6_{ 0.02}\) & \(88.2_{ 0.05}\) & \(90.5_{ 0.04}\) & \(72.2_{ 0.06}\) & \(69.4_{ 0.02}\) & \(77.6\) & \(65.1\) & None \\  \(\) (ours) & \(50.8_{ 0.05}\) & \(49.1_{ 0.33}\) & \(98.9_{ 0.02}\) & \(98.4_{ 0.02}\) & \(88.4_{ 0.01}\) & \(91.9_{ 0.00}\) & \(65.7_{ 0.06}^{}\) & \(60.7_{ 0.1}\) & \(75.3\) & \(58.5\) & Grad \(\) R \\ meg (ours) & \(50.3_{ 0.07}\) & \(53.9_{ 0.06}\) & \(97.8_{ 0.00}\) & \(98.6_{ 0.01}\) & \(88.4_{ 0.01}\) & \(90.6_{ 0.01}\) & \(78.3_{ 0.06}\) & \(69.4_{ 0.02}\) & \(72.9\) & \(65.7\) & Adl. \(\) R \\ m (ours) & \(_{ 0.00}\) & \(_{ 0.00}\) & \(_{ 0.01}\) & \(_{ 0.00}\) & \(_{ 0.02}\) & \(_{ 0.01}\) & \(_{ 0.00}\) & \(\) & \(\) & Both above \\  

Table 2: Average local test accuracy of personalized model (%) in ablation experiments.(\(\)\(\): average accuracy is increased/reduced; AC4PP: Additional cost for personalized prior; Grad. and Add.: cost about calculate gradient and addition; Other notations are the same in Table 1.)Deviation Analysis of Personalization

Deviation represents the difference between an individual and the mean value. We use the deviation of the loss function to reflect the personalization. **On global test**, the lower the deviation, the better the personalized model performance on the corresponding local data. **On local test**, the model is only tested on its own dataset, and because of multiple local iterations, the local test deviation converges to almost the same value, as shown in MNIST-MCLR-L and MNIST-DNN-L in Figure 3. Furthermore, since the local test has a loss of 0 on missing classes, a higher deviation on missing classes reflects a lower mean on these classes. Thus, the lower loss in local testing and better performance are reflected from both of the almost equal deviation in local testing and the higher deviation on missing class. **Summary:** based on Figure 3, we can see that our method has higher deviation on missing classes in local testing and lower deviation in global testing. This means that our method has better personalized performance.

## 7 Conclusion and Discussion

ConclusionTo address the issue of neglecting client-sampling information while providing prior knowledge to local training via direct use of a global model, we propose a general concept: the personalized prior. In this paper, we propose a general framework, pFedBreD, for exploring PFL strategies under the SX-family prior assumption and computation, the RMD to explicitly extract the prior information, and three optional meta-step strategies to personalize the prior. We analyze our proposal both theoretically and empirically. Our strategy **mh** shows remarkable improvement in personalization and robustness to data heterogeneity on non-i.i.d. datasets and the LEAF benchmark  with MCLR / DNN / CNN / LSTM as inferential model, which conduct convex / non-convex problems, and image / language benchmarks.

Limitations and Future WorkAlthough **mh** shows remarkable performance and robustness, there is still instability in the global model with aggregation noise. Furthermore, it should be noted that the superficial reason for the improvement of **mh** seems to be that \(_{}\) and \(\) and (which are similar to each other) are used simultaneously, resulting in a magnitude in **mh** that is twice as large as the ones in the other two implementations and leading to better performance. However, empirically, simply doubling \(_{}\) in **lg** or \(\) in **meg** does not improve performance, and using one more **meg** step used in **lg** significant improvement. Our theoretical analysis cannot explain this phenomenon, and more detailed modeling is needed.

    & small &  & large & Avg \\  FedAvg-**G** & 18.2 & 14.8 & 14.5 & 11.9 & 11.3 & 11.2 & 13.7 \\ pFedMe-**P** & 89.5 & 58.2 & 24.2 & 12.3 & 11.8 & 10.6 & 34.4 \\ pFedMe-**G** & 17.0 & 14.3 & 14.1 & 12.3 & 10.8 & 10.9 & 13.2 \\
**mh**(ours)-**P** & **89.6** & **58.7** & **25.2** & **13.1** & 11.1 & 11.0 & **34.8** \\
**mh**(ours)-**G** & 17.1 & 14.6 & 14.6 & 12.4 & **11.9** & **11.9** & 13.8 \\  

Table 4: The local test accuracy (%) of the personalized model on FMNIST-DNN setting with different data heterogeneity (Non-IID) settings \(\{0.01,0.1,1,10,100,1000\}\)(\(\), Non-IID\(\)) . The **bolded** means the best.

Figure 3: The loss deviation of experiments in Section 6 on the first client, whose major data are on \(0^{th}\) classes. The lower deviation of the available class on global tests and the higher deviation of the unavailable class on local tests demonstrate the superior personalization ability of our methods.

## Acknowledge

This work is supported by the Key Program of National Science Foundation of China (Grant No. 61836006) from College of Computer Science (Sichuan University) and Engineering Research Center of Machine Learning and Industry Intelligence (Ministry of Education), Chengdu 610065, P. R. China. This research is also supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG2-PhD-2021-08-008).