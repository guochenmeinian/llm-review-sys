# Identify Then Recommend:

Towards Unsupervised Group Recommendation

 Yue Liu

Ant Group

National University of Singapore

yueliu1990731@163.com

&Shihao Zhu

Ant Group

Hangzhou, China

&Tianyuan Yang

Ant Group

Hangzhou, China

&Jian Ma

Ant Group

Hangzhou, China

&Wenliang Zhong

Ant Group

Hangzhou, China

Corresponding Author

###### Abstract

Group Recommendation (GR), which aims to recommend items to groups of users, has become a promising and practical direction for recommendation systems. This paper points out two issues of the state-of-the-art GR models. (1) The pre-defined and fixed number of user groups is inadequate for real-time industrial recommendation systems, where the group distribution can shift dynamically. (2) The training schema of existing GR methods is supervised, necessitating expensive user-group and group-item labels, leading to significant annotation costs. To this end, we present a novel unsupervised group recommendation framework named Identify Then Recommend (ITR), where it first identifies the user groups in an unsupervised manner even without the pre-defined number of groups, and then two pre-text tasks are designed to conduct self-supervised group recommendation. Concretely, at the group identification stage, we first estimate the adaptive density of each user point, where areas with higher densities are more likely to be recognized as group centers. Then, a heuristic merge-and-split strategy is designed to discover the user groups and decision boundaries. Subsequently, at the self-supervised learning stage, the pull-and-repulsion pre-text task is proposed to optimize the user-group distribution. Besides, the pseudo group recommendation pre-text task is designed to assist the recommendations. Extensive experiments demonstrate the superiority and effectiveness of ITR on both user recommendation (e.g., 22.22% NDCG@5 \(\)) and group recommendation (e.g., 22.95% NDCG@5 \(\)). Furthermore, we deploy ITR on the industrial recommender and achieve promising results. The codes are available on GitHub2. A collection (papers, codes, datasets) of deep group recommendation/intent learning methods is available on GitHub3.

## 1 Introduction

Online platforms' expansion and information overload make finding pertinent content difficult. Recommendations help by supplying users with items that match their tastes and activities. This paper categorizes recommendations into User Recommendation (UR) and Group Recommendation (GR). UR, the conventional method, delivers personalized content for single users. Differently, GR targets user collectives, striving for a consensus to please most group members.

One essential technique of GR methods is the aggregation of the user groups. The traditional group recommendation methods are based on the heuristic rules [5; 6; 4], limiting the representation capability. To this end, DNN-based methods are proposed and achieve promising performance. Concretely, the learnable aggregate methods [7; 22; 27; 58; 76] are developed based on the attention mechanism . Besides, (hyper-)graph neural networks [64; 32; 75; 23; 70] are built to model the side information and high-order collaborative information in the groups for comprehensive aggregation. Moreover, contrastive learning is utilized to encourage the alignment of different views and distill complementary information [46; 47; 61]. Although verified effective, the above methods rely on in advance given group information. Therefore, on another aspect, researchers [63; 68; 69] aim to develop group discovery capability of GR models by using group annotations.

However, this research highlights two critical problems of recent state-of-the-art methods. Firstly, the promising performance of these methods relies on a pre-defined and fixed number of user groups. Therefore, they can not handle group recommendations without giving the number of user groups, and unfortunately, the number of groups is usually unknown and dynamic in real-time industrial data. Secondly, the supervised training schema of existing GR methods requires extensive human annotations for user-group distribution and group-item interaction, easily leading to significant costs. Therefore, we raise a question that is important for research and practical scenarios. Can group recommendations be handled well without the annotations regarding user group information?

From this motivation, a novel unsupervised group recommendation framework termed Identify Then Recommend (ITR) is proposed by the group identification and the group self-supervised recommendation. Specifically, in the process of group identification, the area and density of each region are determined automatically. In contrast, regions with higher densities are more likely to be recognized as group centers. In comparison, those with lower densities are decision boundaries. Subsequently, a heuristic merge-and-split strategy is developed to consolidate similar user groups and to divide distinct user groups using the explore-and-exploit rule. In this manner, the user groups can be identified without the pre-defined number of groups and the group annotations. Next, at the self-supervised learning stage, we design two pre-text tasks to assist the group identification and recommendations. Besides, the pull-and-repulsion pre-text task is designed to optimize the user-group distribution for group identification. For the group recommendation, we construct the pseudo-group-item labels to guide the self-supervised learning of the GR model. In summary, through the two stages above, we empower the ITR model to handle group discovery and group recommendation even without group annotations, improving the applicability and performance of group recommendation. We conduct comprehensive experiments to demonstrate the superiority of ITR on both user recommendation and group recommendation. Moreover, ITR solves the practical problem in the industry scenario and is successfully deployed on the large-scale recommendation system, achieving promising results. The main contributions of this paper are summarized as follows.

* We propose a novel unsupervised group recommendation framework, ITR, which empowers the model to handle group discovery and group recommendation without annotations of user groups.
* The adaptive density estimation and heuristic merge-and-split strategies are designed to identify user groups automatically. Besides, the pull-and-repulsion pre-text task and pseudo-group recommendation pre-text task are presented to strengthen self-supervised learning.
* Extensive experiments demonstrate the proposed ITR's superiority and effectiveness. ITR has also been deployed on a large-scale industrial recommendation system, achieving promising results.

## 2 Related Work

The related work of this paper mainly contains two domains, including group recommendation and unsupervised clustering. Due to the page limitation of the main text, we provide a detailed introduction to related papers in Appendix 7.1.

## 3 Methodology

This section presents our proposed method. First, we provide the notations and task definitions. Second, we analyze and identify the limitations of existing group recommendations and group discovery. Last, we propose our solutions to address these challenges.

### Basic Notation & Task Definition

In this paper, we denote \(=\{u_{1},u_{2},...,u_{i},...,u_{n}\}\), \(=\{t_{1},t_{2},...,t_{i},...,t_{m}\}\), and \(=\{g_{1},g_{2},...,g_{i},...,g_{k}\}\), as user set, item set, and group set, respectively. \(n=||\), \(m=||\), and \(k=||\) is the number of users, the number of items, and the number of groups, respectively. \(^{n k}\) denotes the user-group distribution, where \(_{ij}=1\) represents that the user \(u_{i}\) participates in the group \(g_{j}\), and \(_{ij}=0\) represents the opposite case. Besides, \(^{n m}\) is the user-item interaction, where \(p_{ij}=1\) denotes the user \(u_{i}\) has the interaction with the item \(t_{j}\), and \(_{ij}=0\) represents the opposite case. Moreover, \(^{g m}\) is the group-item interaction, where \(q_{ij}=1\) denote the group \(g_{i}\) has the interaction with the item \(t_{j}\), and \(q_{ij}=1\) denote the opposite case. The basic notations are summarized in Table 5 of Appendix.

For the conventional group recommendation, the methods aim to recommend items to the user groups. Mathematically, give the user-group distribution \(\), and the training set of user-item interaction \(\), group-item interaction \(\), the method aims to train a group recommendation model \(\). After training, given the test groups, \(\) can provide the potential item recommendation for the groups. Also, \(\) usually has the ability of user recommendation and can provide candidate items for the test users.

### Problem Analysis

By analyzing the above task definition, we notice that the existing group recommendation methods rely on the given user-group distribution \(\). However, we argue that the user-group distribution \(\) is hard to obtain in the real-world recommendation system. First, on the large-scale data of users, we can not know how many groups they will form. Second, it is hard to know which groups the user will join in, and this process should be dynamic. On another aspect, the previous methods are trained based on group-item interaction \(\). It is also a scarce resource. First, as mentioned above, the group information is hard to capture on large-scale data. Second, the interaction between groups and items is also dynamic and costs large human annotations. To this end, we raise an essential question for research and industry. Can group recommendations be handled well without the group annotations (i.e., user-group distribution \(\) and group-item interaction \(\))?

This paper aims to deploy the proposed method in the real-time large-scale industrial recommendation system. On the open benchmarks, we admit that the annotations of users and groups have already existed and in the experiments, we remove them for the unsupervised experimental setting. We also admit that annotating these toy datasets may not be very expensive. However, the group assignments must change dynamically during training, especially at the early stage. However, note that on real-time large-scale data, the annotation costs a lot, and the distribution will shift dynamically. For example, in our scenario, the application contains 130 million page views and 50 million user views per day. The group assignment and annotation will be changed daily since it is a real-time recommendation. In addition, this is a newly launched application. Therefore, the activities of users will shift drastically, e.g., from new users to old users. We believe it will lead to large annotation costs and distribution shifts, and we aim to develop a pure, unsupervised group identification method for the user/group recommendation. In this scenario, performing several runs of clustering methods (the one that needs a pre-defined number of clusters) is not applicable since the search space will become very large, especially since we don't know the cluster number for the daily data. The current methods cannot deal with the data without a given number of clusters. For our proposed method, we just need one pass to determine the cluster number, which can fulfill the requirement of the daily data. The complexity of the multiple trials will be T times than our proposed method, where T denotes the time of trials. The details regarding the application can be found in Section 7.6.

### Identify Then Recommend

From this motivation, we propose a novel unsupervised group recommendation framework termed Identify Then Recommend (ITR), which can automatically identify the user groups and conduct self-supervised group recommendation, even without giving the group number \(k\) and the user-group distribution \(\). It mainly consists of two modules, including the group identification module and the self-supervised group recommendation module as follows.

We briefly introduce the core idea and the primary designs of our proposed method before introducing the method part. Concretely, we aim to develop an unsupervised group recommendation method since we find the promising performance of existing state-of-the-art methods relies on the annotationsof the groups. The experimental evidence can be found in Figure 1. However, in the real-world scenario, the annotations regarding the group-item interactions and the user-group assignments are always not available. Labeling them in the real-time recommendation system is expensive and even impossible. To this end, we develop a pure, unsupervised group recommendation method, which can automatically discover the user groups and provide precise recommendations for them. Therefore, the core ideas of our methods are twofold, including the group identification and the group recommendation. For group identification, our initial solution is to adopt some existing clustering or community detection methods that do not require the number of clusters, e.g., DBSCAN, DeepDPM, etc. However, these methods can not automatically discover the user groups since they need other hyper-parameters, such as the radius and calculation of the density. Therefore, we design an adaptive density estimation method, which can automatically estimate the density of the samples. Then, for the group discovery, we propose a heuristic merge-and-split strategy to merge similar users into the group and split different user groups in the large group. Besides, the group embeddings are set as the learnable neural parameters and can be optimized during the learning process. Moreover, for the group recommendation part, the existing method can not deal with it in the unsupervised setting. We propose two pre-text tasks, including the pseudo group recommendation pre-text task and the pull-and-repulsion pre-text task. The pull-and-repulsion pre-text task aims to optimize the group embeddings by separating the different groups and pushing the samples together to the corresponding groups. Besides, for the pseudo group recommendation pre-text task, it generates the pseudo labels for the group recommendation task and guides the network to conduct group recommendation even without the precise annotations. By these designs, our proposed ITR is able to automatically discover the user groups and then provide precise group recommendations for them. Therefore, it can be applied in the real-time large-scale recommendation system.

#### 3.3.1 Group Identification Module

In this section, we propose a group identification module (GIM) to discover the user groups on the user embeddings in an unsupervised manner. Given the user set \(=\{u_{1},u_{2},...,u_{i},...,u_{n}\}\), the item set \(=\{t_{1},t_{2},...,t_{i},...t_{m}\}\), and their interaction \(^{n m}\), we first encode the user and item into the latent space and obtain the user embedding \(^{n d}\) and the item embedding \(^{m d}\), where \(d\) denotes the dimensions of latent embeddings.

**Adaptive Density Estimation.** Then, we regard the user embeddings as the initial candidate centers of the user groups. We define the identified user groups and their embeddings as \(^{}=\{g^{}_{1},g^{}_{2},...,g^{}_{i},...,g^ {}_{k^{}}\}\) and \(^{}^{k^{} d}\), respectively. Here, \(k^{}\) denotes the number of user groups. Note that \(k^{}\) is initialized as \(n\) and will dynamically change. After initialization, the density of each user group is adaptively estimated. Concretely, take user group \(g^{}_{i}\) as an example, we first calculate the minimal distance \(d^{(i)}_{}=_{j}(i,j)\) and maximal distance \(d^{(i)}_{}=_{j}(i,j)\) from it to all other groups, where \((i,j)\) denote the distance between the \(i\)-th group and the \(j\)-th group. Then, based on the quantile valuable \(q\), we calculate the radius proposal as follows.

\[r_{q}=d_{}+(d^{(i)}_{}-d^{(i)}_{}) q,\] (1)

where \(r_{q}\) denotes the radius proposal with the quantile \(q\). Subsequently, based on \(r_{q}\), we estimate the density of the user group \(g^{}_{i}\) as formulated.

\[_{i}=_{q}((_{j}_{(i,j) r_{q}} )/ r_{q}^{2}),\] (2)

where \(_{(i,j)}\) is an indicator function, which equals \(1\) when \((i,j) r_{q}\), and equals \(0\) when \((i,j)>r_{q}\). Besides, \( r_{q}^{2}\) denotes the area of the user group \(g^{}_{i}\). In equation (2), the group with high density \(\), i.e., containing more users but with less area, is more likely to be recognized as the group center, and the opposite case is more likely to be recognized as the decision boundary.

**Heuristic Merge-and-split Strategy.** After obtaining the estimated density of each group candidate, this section proposes a heuristic merge-and-split strategy to merge similar user groups dynamically and split the distinct user groups. Specifically, we first sort the group candidates based on the density \(\) in descending order, and the group with high density will be processed first. This process can help our model skip some repetitive operations, therefore saving time. Then, we process each group in order based on the idea of the explore-and-exploit rule. Concretely, we design a greedy parameter \(\) to control the exploding rate. For each group, we conduct the exploring strategy with the probability of \((0,1]\), while with the probability of \(1-\), we conduct the exploiting strategy. The greedy parameter \(\) is calculated as follows.

\[=(-s_{}^{2}/(s_{}+1)),\] (3)

where \(s_{}\) and \(s_{}\) denotes the explored step and the overall steps. By this setting, the exploring rate will decrease quickly when the explored steps increase, therefore encouraging the model to explore at the beginning steps and exploit after the beginning steps.

Next, we detail the exploring and exploiting strategies for our group identification task. For the exploring strategy, we aim to discover the new user group candidates based on the existing information. To achieve this target, we utilize the group embedding at this step \(s\), denoted as \(^{(s)}^{1 d}\), and the group embedding at last step \(s-1\), denoted as \(^{(s-1)}\). Subsequently, the new user group is generated as follows.

\[^{}=^{(s)}+(1-) ^{(s-1)},\] (4)

where \((0.5,0.5)\) is the balance parameter. \(\) denotes the Gaussian distribution of the 0.5 mean and 0.5 standard deviation. The equation (4) implies that the closer to the group center at the current step (with the highest density at the current step) or to the group center at the last step (with the highest density at the last step), with the lower possibility that the area contains the new candidate group center. In this manner, we guide the model to explore the new possible group candidate \(g^{}\). In addition, it will be added to the existing group candidate set: \(^{}\{g_{1}^{},g_{2}^{},...,g_{i}^{ },...,g_{k^{}}^{},g^{}\}\), \(k^{} k^{}+1\). Also, the adaptive density of \(g^{}\) will be estimated through equation (1) and (2).

For the exploiting strategy, we aim to conduct a merge or split operation for the current user group. We take the group \(g_{i}^{}\) as an example and denote its radius and corresponding density as \(r_{i}\) and \(_{i}\), respectively. Recall that we have sorted the user groups, so \(g_{i}\) is the unprocessed group center with the highest density. Therefore, we first conduct a merge operation for \(g_{i}\) as follows.

\[_{i}^{}_{(i,j ) r_{i}}}_{k}_{(i,k) r_{i}}_{k},\] (5)

where \(_{(i,j) r_{i}}\) indicate all of the groups within the circle area with \(r_{i}\) radius. In this manner, similar user groups are merged together into the group center with the highest density at the current step. However, we argue that the merged group may contain several isolated density peaks of the user groups. Therefore, in addition to the merge strategy, we conduct the split strategy as formulated.

\[_{i}^{}_{(i, j) r_{i}}(1-_{(i,j)>r_{j}})}_{k}_{(i,k) r_{i}}}_{}_{(i,j)>r_{j}})}_{}_{k},\] (6)

where \(_{(i,j) r_{i}}\) represents that it merges the group candidates within the circle area with \(r_{i}\) radius while \((1-_{(i,j)>r_{j}})\) represents that it splits the group candidates whose circle area with \(r_{j}\) radius can not contain the current user group \(g_{i}\). By these designs, the user groups are first merged and then several isolated user groups are split. This merge-and-split process updates the existing group candidate set as follows.

\[^{}\{g_{1}^{},g_{2}^{},..., {\{g_{i}^{},...\}}_{},...,g_{k^{}}^{} \},k^{} k^{}-_{j}_{(i,j) r _{i}}(1-_{(i,j)>r_{j}})+1.\] (7)

In summary, in the proposed group identification module, we first estimate the adaptive density and the radius of each group candidate. Subsequently, the heuristic merge-and-split strategy dynamically identifies the user groups with the exploring and exploiting. It explores the new groups around the current decision boundary and exploits the current information to merge and split the group candidates. By these designs, our proposed method is empowered to identify groups without the scarce group annotation information. Next, we introduce how to utilize identified groups.

#### 3.3.2 Self-supervised Group Recommendation Module

In this section, a self-supervised group recommendation module (SGRM) is proposed to utilize the discovered user groups and promote the group recommendation. It consists of two pre-text tasks, including the pull-and-repulsion task and the pseudo-group recommendation task.

**Pull-and-repulsion Pre-text Task.** After obtaining the discovered user groups \(^{}\) and corresponding group center embeddings \(^{}^{k^{} d}\), we aim to optimize the group center embeddings along with the user embeddings via the pull-and-repulsion pre-text task as formulated.

\[_{}=}_{i=1}^{n }_{j=1}^{k^{}}\|}_{i}-}_{j}^{ }\|_{2}^{2}}_{}+-1 )k^{}}_{i=1}^{k^{}}_{j=1,j i}^{k^{}}\| }_{i}^{}-}_{j}^{}\|_{2}^{ 2}}_{},\] (8)

where \(}_{i}=_{i}/\|_{i}\|_{2}\) denotes the normalized user embeddings and \(}_{i}^{}=_{j}^{}/\|_{j}^{ }\|_{2}\) denotes the normalized group embeddings. In equation (8), the pull term aims to pull the users to the user groups, while the repulsion term aims to push the distinct groups away. In this manner, the users and the identified groups are optimized in a unified framework during training, achieving better performance for both the user and group recommendations.

**Pseudo Group Recommendation Pre-text Task.** In addition to the pull-and-repulsion pre-text task, we develop a pseudo-group recommendation pre-text task to assist the group recommendation. Concretely, we first calculate the distance \(^{n k^{}}\) between users and groups, and then estimate the user-group distribution \(^{}^{n k^{}}\) as follows.

\[d_{ij}=\|}_{i}-}_{j}^{}\|_{2},\;a_{ij} ^{}=_{d_{ij}<(/nk^{})},\] (9)

where \(}_{i}=_{i}/\|_{i}\|_{2}\) denotes the normalized user embeddings and \(}_{j}^{}=_{j}^{}/\|_{j}^{ }\|_{2}\) denotes the normalized group embeddings. Subsequently, we further estimate the pseudo interactions \(^{}^{k^{} m}\) between the discovered user groups and the items as follows.

\[^{}=(^{})^{},\] (10)

where \(^{n m}\) denotes the user-item interaction and \(^{}^{n k^{}}\) denotes the estimated user-group distribution. Next, we conduct a pseudo group recommendation pre-text task to enhance the performance of the model as follows.

\[_{}=m}(^{ }^{}-^{})^{2},\] (11)

where \(^{m d}\) is the item embedding and \(^{}^{k^{} d}\) denotes the discovered group embedding. In summary, in our proposed self-supervised group recommendation module, we conduct two pre-text tasks to refine the discovered user groups and further promote the group recommendation.

#### 3.3.3 Overall Objective

We integrate the above two modules and provide the overall process of our proposed ITR model. The overall objective \(_{}\) of ITR consists three parts, including the loss of pull-and-repulsion pre-text task \(_{}\), the loss of pseudo group recommendation task \(_{}\), and the loss of user recommendation \(_{}\). \(_{}\) is a binary personalized ranking loss. \(_{}\) is formulated as follows.

\[_{}=a_{}+b_{ }+_{},\] (12)

where \(a\) and \(b\) denote the trade-off parameters. The process of ITR is summarized in Algorithm 1.

BPR loss is a commonly used loss function in the recommendation. In our proposed method, we follow ConsRec for the BPR loss. And \(_{}\) is the same as the \(_{}\) in the ConsRec. It is formulated as \(_{}=-_{u_{s}}_{u_{ s}}|}_{(j,j^{})_{u_{s}}}(_{sj}-_{sj^{ }})\), where \(_{u_{s}}\) is the user-item training set sample for user \(u_{s}\) and the \((j,j^{})\) denotes the user \(u_{s}\) prefers observed item \(i_{j}\) over unobserved item \(i_{j^{}}\). For the sampling of positive and negative sample pairs, we also follow ConsRec, i.e., randomlysampling from missing data as negative instances to pair with each positive instance. For the number of negative samples, ConsRec conducts experiments and analyses in Figure 8 of their original paper. For fairness, we keep the original setting of the ConsRec.

#### 3.3.4 Complexity Analyses

We conduct complexity analyses of our proposed ITR method. First of all, we define the number of users, the number of groups, and the average size of groups as \(n\), \(k^{}\), and \(n/k^{}\), respectively. In the process of the adaptive density estimation, the time complexity and space complexity of calculating radius proposal for one group is \((1)\), \(({k^{}}^{2})\), respectively, and for all groups is \((k^{})\), \(({k^{}}^{2})\), respectively. Then, the time complexity and space complexity of density estimation for all groups are \(k^{} n/k^{}\), \(n k^{}\), respectively. Subsequently, at the heuristic merge-and-split strategy stage, for the explore step, it takes \((k^{})\) time complexity and \((1)\) space complexity, respectively. And for the exploit step, it takes \((k^{} n/k^{})\) time complexity, and \((nk^{})\) space complexity, respectively. Besides, for the proposed pseudo recommendation pre-text task, the time complexity and space complexity are \((n k^{})\), and \((n k^{})\), respectively. In addition, for the proposed pull-and-repulsion pre-text task, the time complexity and space complexity is \((nk^{}+{k^{}}^{2})\), and \((nk^{})\), respectively. Moreover, for the BPR loss, the time complexity and space complexity are \((n)\) and \((n)\), respectively. Overall, the time complexity and space complexity of our proposed ITR method is \((k^{}+k^{} n/k^{}+k^{}+k^{}  n/k^{}+n k^{}+{nk^{}}+{k^{}}^{2}+n) (nk^{}+{k^{}}^{2})\)and \(({k^{}}^{2}+n k^{}+1+nk^{}+n k^{ }+nk^{}+n)(nk^{}+{k^{}}^{2})\), respectively. Therefore, our proposed method will not bring large memory and time costs since the complexity of our method is linear to the number of users.

## 4 Experiment

In this section, we aim to demonstrate the superiority of our proposed ITR model. First, we introduce the experimental setup, including the experimental environment, public benchmarks, and evaluation metrics, and compare baselines and implementation details. Second, we conduct experiments to support our motivation and demonstrate the problems in the existing group recommendation methods. Third, we show the superiority of the ITR model by comparing it with the recent state-of-the-art methods. Subsequently, we conduct ablation studies to demonstrate the effectiveness of the proposed modules in the ITR model. Moreover, we analyze the hyper-parameters and conduct A/B testing in the Appendix.

### Experimental Setup

**Experimental Environment.** Experimental results are obtained from the server with four core Intel(R) Xeon(R) Platinum 8358 CPUs @ 2.60GHZ, one NVIDIA A100 GPU (40G), and the PyTorch platform. During training, we monitored the training process via the Weights & Biases.

**Public Benchmark.** We conduct experiments on two real-world public datasets, Mafengwo and CAMRa2011 . Mafengwo is a tourism website where users can record their traveled venues and create or join group travel. CAMRa2011 is a real-world dataset containing individual users' and households' movie rating records.

**Evaluation Metric.** To evaluate the ITR model, we adopt two groups of metrics, including Hit Ratio(\(\)) (HR@\(x\)) and Normalized Discounted Cumulative Gain@\(x\) (NDCG@\(x\)), where \(x\{5,10\}\).

**Compared Baseline.** We compare ITR with twelve state-of-the-art GR methods including Pop , NCF , AGREE , MAML, GroupIM , HyperGroup , HCR , HHGR , MeLU, CubeRec , ConsRec , and CoHeat . The introduction refers to the Section 7.1.

**Implementation Detail.** For the baseline methods, we use recorded results or adopt their original code to reproduce results. In our ITR model, we set \(b\) as 10. And \(a\) is set to 0.01 for Mafengwo and 10 for CAMRa2011, respectively. The range of \(q\) is set as \(\{0.1,0.2,0.3\}\). The learning rate is set as \(0.001\) for CAMRa2011 and \(0.0001\) for Mafengwo, respectively. All results are obtained from three runs.

### Motivation Experiment

Recall the analyses in Section 3.2, we point out the issue of the existing group recommendation methods, i.e., the promising performance relies on the extensive group annotations, including the user-group distribution and the group-item interaction. To verify our claim and support our motivation, we conduct experiments on user recommendation tasks and group recommendation tasks on two datasets. Concretely, we test the performance of ConsRec  and it without the group annotations. The experimental results are presented in Figure 1, where the first and second rows denote the group recommendation and user recommendation tasks, respectively. From these results, we have the following conclusions. 1) For the group recommendation task, the performance decreases sharply when we remove the group annotations. For example, on the Mafengwo dataset, regarding to HR@5 metric, the performance drops from 0.8844 to 0.0563, leading to the failure of group recommendation. 2) The group annotations have little effect on the user recommendation task. In this multi-task learning process, the group annotations may have a positive effect (since they add information) or a negative effect (since they influence user recommendations we aim to develop a new method that can handle group recommendations even without group annotations.

### Comparison Experiment

We conduct extensive comparison experiments with twelve baselines and our ITR model on two open datasets regarding two recommendation tasks. The experimental results are presented in Table 1 (for group recommendation) and Table 2 (for user recommendation). Based on these results, we find that 1) Firstly, regarding to group recommendation task, our proposed ITR model achieves the best results compared with the state-of-the-art baselines, even without giving the group annotations. For

Figure 1: Motivation experiment on two datasets. “GR” and “UR” denote the group recommendation and the user recommendation, respectively.

example, on the CAMRa2011 dataset, our ITR model achieves 0.2040 NDCG@10 improvement compared to the runner-up. The main reason is that the proposed GIM can precisely discover the potential user groups, and the proposed SGRM can take advantage of the group information to assist the group recommendation. 2) Secondly, for the user recommendation task, benefiting from the supplemental information of discovered user groups, our ITR also achieves significant improvement and the best performance. For example, on the Mafengwo dataset, we achieved 0.0474% NDCG@5 improvement compared to the runner-up. 3) Thirdly, on the CAMRa2011 dataset, for the HR@10 metric, our method can not beat the best methods. This could be due to the fact that GroupIM is unable to effectively capture the order of user preferences. While the items of interest to the user appear in the recommended list, these items are not ranked highly. In summary, this section verifies the superiority of our proposed ITR on both user recommendation and group recommendation. For the performance of our proposed method on the CAMRa2011 dataset, we consider it as a corner case since our proposed method can beat all the baselines with different metrics. And we want to give a reasonable explanation here. For the results, we can observe that our method can beat GroupIM with HR@5 but can not beat it with HR@10. And HR@5 is a more precise metric than HR@10 since it requires the model to rank correctly in the top 5 items. Therefore, we suspect that the ranking ability of GroupIM may not be strong and robust since it can achieve very promising performance when ranking in the top 10 items but can not beat our method when ranking in the top 5 items.

### Ablation Study

In this section, we conduct ablation studies to verify the effectiveness of our proposed modules, including GIM and SGRM. The experimental results are shown in Table 3 (for group recommendation) and Table 4 (for user recommendation). Concretely, "Base", "Base+GIM+PAR", "Base+GIM+PGR", and "ITR" denote the baseline with group annotations, the baseline with GIM and pull-and-repulsive pre-text task, the baseline with GIM and pseudo group recommendation pre-text task, and our proposed method, respectively. From these results, we have the following observations. 1) "Base+GIM+PAR" achieves better performance compared with "Base", demonstrating the effectiveness of our proposed pull-and-repulsive pre-text task. 2) "Base+GIM+PGR" beats "Base", showing the effectiveness of our proposed pseudo group recommendation pre-text task. 3) Due to the GIM being merely a user group identification module, we can not use it to complete the recommendation task. But by combining observations 1) and 2), we find that GIM has contributed to the down-streaming tasks and brings performance improvement. 4) The combination variant "ITR" achieves the best performance.

## 5 Conclusion

This paper finds that the existing group recommendation methods rely on the pre-defined and fixed group number and the expensive user-group and group-item labels. To solve this problem and improve the applicability of group recommendation, we developed a novel unsupervised group recommendation method named ITR. It first identifies the user groups in an unsupervised manner

   &  &  \\  Method & HR@5 & HR@10 & NDCG@5 & NDCG@10 & Avg. & HR@5 & HR@10 & NDCG@5 & NDCG@10 & Avg. \\  Pop\({}^{}\) & 0.3115 & 0.4251 & 0.2169 & 0.2537 & 0.3018 & 0.4324 & 0.5793 & 0.2825 & 0.3302 & 0.4061 \\ NCP\({}^{}\) & 0.4701 & 0.6269 & 0.3657 & 0.4141 & 0.4692 & 0.5803 & 0.7693 & 0.3896 & 0.4448 & 0.5460 \\ AGREE\({}^{}\) & 0.4729 & 0.6321 & 0.3694 & 0.4203 & 0.4737 & 0.5879 & 0.7789 & 0.3933 & 0.4530 & 0.5533 \\ MAML\({}^{}\) & 0.4863 & 0.6484 & 0.3753 & 0.4383 & 0.4871 & 0.5974 & 0.7982 & 0.4123 & 0.4773 & 0.5713 \\ GroupIM\({}^{}\) & 0.7377 & 0.8161 & 0.6078 & 0.6330 & 0.6987 & 0.6552 & **0.8407** & 0.4310 & 0.4914 & 0.6046 \\ HyperGroup\({}^{}\) & 0.5739 & 0.6482 & 0.4777 & 0.5018 & 0.5504 & 0.5890 & 0.7986 & 0.3856 & 0.4538 & 0.5568 \\ ICR\({}^{}\) & 0.7759 & 0.8503 & 0.6611 & 0.6852 & 0.7431 & 0.5883 & 0.7821 & 0.4044 & 0.4670 & 0.5605 \\ S2IHGR\({}^{}\) & 0.7568 & 0.7779 & 0.7322 & 0.7391 & 0.7515 & 0.6062 & 0.7903 & 0.3853 & 0.4535 & 0.5568 \\ MeLU\({}^{}\) & 0.5483 & 0.6626 & 0.4594 & 0.4726 & 0.3557 & 0.5763 & 0.7688 & 0.3827 & 0.4483 & 0.5440 \\ CubeRec\({}^{}\) & 0.8613 & 0.9025 & 0.7574 & 0.7708 & 0.8230 & 0.6400 & 0.8207 & 0.4346 & 0.4935 & 0.5972 \\ ConRec\({}^{}\) & 0.8844 & 0.9156 & 0.7692 & 0.7794 & 0.8372 & 0.6407 & 0.8248 & 0.4358 & 0.4945 & 0.5990 \\ CoIfeat\({}^{}\) & 0.8992 & 0.9202 & 0.7924 & 0.8172 & 0.8573 & 0.6204 & 0.7974 & 0.4284 & 0.4820 & 0.5821 \\  ITR\({}^{}\) & **0.9337** & **0.9377** & **0.8761** & **0.8775** & **0.9062** & **0.6952** & 0.7993 & **0.6653** & **0.6985** & **0.7146** \\ Impro. & 0.0345\({}^{}\) & 0.0175\({}^{}\) & 0.0837\({}^{}\) & 0.0603\({}^{}\) & 0.0490\({}^{}\) & 0.0400\({}^{}\) & 0.0414\({}^{}\) & 0.2295\({}^{}\) & 0.2040\({}^{}\) & 0.1100\({}^{}\) \\  

Table 1: Group recommendation performance. **Bold** and underlined values denote the best and the runner-up. \({}^{}\) denotes the model relies on group annotations. \({}^{}\) denotes the unsupervised model.

and then conducts two pre-text tasks to promote the recommendation. For the group identification, we calculate the adaptive density of groups to determine the group centers and decision boundaries aa and then conduct a heuristic merge-and-split strategy to discover new groups and merge similar user groups. For the self-supervised group recommendation, we design the pull-and-repulsion pre-text task to optimize the users and groups in a unified framework. Besides, a pseudo group recommendation task is designed by estimating user-group distribution and group-item interactions to assist user recommendation and group recommendation. Extensive experiments demonstrate the superiority and effectiveness of our proposed method on both user recommendation tasks and group recommendation tasks. Benefiting the superiority of ITR, it is also deployed on the large-scale industrial recommendation system and achieves promising improvements. However, ITR still relies on the user-item interaction for the user recommendation and group recommendation. In the future, we aim to develop an unsupervised recommendation method or the zero-shot recommendation method to solve the data sparsity problem.

## 6 Acknowledgment

We thank all anonymous reviewers for their constructive and helpful reviews. This work was supported by the National Natural Science Foundation of China (No. 62325604 and 62276271).

   &  &  \\  Method & HR@5 & HR@10 & NDCO@5 & NDCG@10 & Avg. & HR@5 & HR@10 & NDCG@5 & NDCG@10 & Avg. \\ Base & 0.7725 & 0.8404 & 0.6884 & 0.7107 & 0.7503 & 0.6774 & 0.8412 & 0.4568 & 0.5104 & 0.6215 \\ Base+GIM+PAR & 0.7788 & 0.8347 & 0.7125 & 0.7310 & 0.7643 & 0.6970 & 0.8316 & 0.6431 & 0.6866 & 0.7146 \\ Base+GIM+PGR & 0.7959 & 0.8432 & 0.7235 & 0.7392 & 0.7755 & 0.6811 & 0.8253 & 0.5781 & 0.6249 & 0.6774 \\ ITR & 0.8107 & 0.8586 & 0.7569 & 0.7727 & 0.7997 & 0.7106 & 0.8017 & 0.6790 & 0.7083 & 0.7249 \\  

Table 4: Ablation studies of GIM and SGRM on user recommendation task.

   &  &  \\  Method & HR@5 & HR@10 & NDCG@5 & NDCG@10 & Avg. & HR@5 & HR@10 & NDCG@5 & NDCG@10 & Avg. \\  Pop\({}^{}\) & 0.4047 & 0.4971 & 0.2876 & 0.3172 & 0.3767 & 0.4624 & 0.6026 & 0.3104 & 0.3560 & 0.4329 \\ NCP\({}^{}\) & 0.6363 & 0.7417 & 0.5432 & 0.5733 & 0.6236 & 0.6119 & 0.7894 & 0.4018 & 0.4535 & 0.5642 \\ AGREE\({}^{}\) & 0.6357 & 0.7403 & 0.5481 & 0.5738 & 0.6245 & 0.6196 & 0.7897 & 0.4098 & 0.4627 & 0.5705 \\ MAML\({}^{}\) & 0.4528 & 0.5187 & 0.3286 & 0.3579 & 0.4145 & 0.5102 & 0.6309 & 0.3523 & 0.4286 & 0.4805 \\ GroupIM\({}^{}\) & 0.1608 & 0.2497 & 0.1134 & 0.1420 & 0.1665 & 0.6113 & 0.7771 & 0.4064 & 0.4606 & 0.5639 \\ HyperGroup\({}^{}\) & 0.7235 & 0.7759 & 0.6722 & 0.6894 & 0.7153 & 0.5728 & 0.7601 & 0.4410 & 0.5016 & 0.5689 \\ ICR\({}^{}\) & 0.7571 & 0.8290 & 0.6703 & 0.6937 & 0.7375 & 0.6262 & 0.7924 & 0.4195 & 0.4734 & 0.5779 \\ S2HIGR\({}^{}\) & 0.6380 & 0.7520 & 0.4637 & 0.5006 & 0.5886 & 0.6153 & 0.8173 & 0.3978 & 0.4611 & 0.5736 \\ McLU\({}^{}\) & 0.7694 & 0.8358 & 0.7095 & 0.7256 & 0.7601 & 0.6902 & 0.7892 & 0.4376 & 0.4874 & 0.5817 \\ CubeRec\({}^{}\) & 0.1847 & 0.3734 & 0.1099 & 0.1708 & 0.2097 & 0.5754 & 0.7827 & 0.3751 & 0.4428 & 0.5440 \\ ConRec\({}^{}\) & 0.7725 & 0.8404 & 0.6884 & 0.7107 & 0.7530 & 0.6774 & **0.8412** & 0.4568 & 0.5104 & 0.6215 \\ CoIfeat\({}^{}\) & 0.7023 & 0.7621 & 0.6035 & 0.6492 & 0.6793 & 0.6282 & 0.7542 & 0.4015 & 0.4495 & 0.5584 \\  ITR\({}^{}\) & **0.8107** & **0.8586** & **0.7569** & **0.7727** & **0.7997** & **0.7106** & 0.8017 & **0.6790** & **0.7083** & **0.7249** \\ Impro. & 0.03827 & 0.01827 & 0.0474 & 0.0471 & 0.0397 & 0.03327 & 0.03954 & 0.22227 & 0.19797 & 0.1034\({}^{}\) \\  

Table 2: Performance of user recommendation. **Bold** and underlined values denote the best and the runner-up. \({}^{}\) denotes the model relies on group annotations. \({}^{}\) denotes the unsupervised model.

   &  &  \\  Method & HR@5 & HR@10 & NDCO@5 & NDCG@10 & Avg. & HR@5 & HR@10 & NDCG@5 & NDCG@10 & Avg. \\ Base & 0.8844 & 0.9156 & 0.7692 & 0.7794 & 0.8372 & 0.6407 & 0.8248 & 0.4358 & 0.4945 & 0.5990 \\ Base+GIM+PAR & 0.9065 & 0.9156 & 0.8152 & 0.8183 & 0.8639 & 0.6807 & 0.8165 & 0.6345 & 0.6786 & 0.7026 \\ Base+GIM+PGR & 0.8864 & 0.8975 & 0.7934 & 0.7971 & 0.8436 & 0.6497 & 0.8097 & 0.5559 & 0.6082 & 0.6559 \\ ITR & 0.9337 & 0.9377 & 0.8761 & 0.8775 & 0.9062 & 0.6952 & 0.7993 & 0.6653 & 0.6985 & 0.7146 \\  

Table 3: Ablation studies of GIM and SGRM on group recommendation task.