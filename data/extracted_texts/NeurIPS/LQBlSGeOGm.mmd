# How Molecules Impact Cells:

Unlocking Contrastive PhenoMolecular Retrieval

 Philip Fradkin\({}^{1,2,}\), Puria Azadi\({}^{1,3,}\),

**Karush Suri\({}^{1}\)**, Frederik Wenkel\({}^{1}\)**, Ali Bashashi\({}^{3}\)**,

**Maciej Sypetkowski\({}^{1}\)\({}^{1}\)**, Dominique Beain\({}^{1,4,}\)\({}^{1}\)**

\({}^{1}\) Valence Labs, \({}^{2}\) University of Toronto, Vector Institute,

\({}^{3}\) University of British Columbia, \({}^{4}\) Universite de Montreal, Mila- Quebec AI Institute

dominique@valencelabs.com

These two authors contributed equally (ordered alphabetically) and reserve the right to swap their order.Equal advising.

###### Abstract

Predicting molecular impact on cellular function is a core challenge in therapeutic design. Phenomic experiments, designed to capture cellular morphology, utilize microscopy based techniques and demonstrate a high throughput solution for uncovering molecular impact on the cell. In this work, we learn a joint latent space between molecular structures and microscopy phenomena experiments, aligning paired samples with contrastive learning. Specifically, we study the problem of _Contrastive PhenoMolecular Retrieval_, which consists of zero-shot molecular structure identification conditioned on phenomic experiments. We assess challenges in multi-modal learning of phenomics and molecular modalities such as experimental batch effect, inactive molecule perturbations, and encoding perturbation concentration. We demonstrate improved multi-modal learner retrieval through (1) a uni-modal pre-trained phenomics model, (2) a novel inter sample similarity aware loss, and (3) models conditioned on a representation of molecular concentration. Following this recipe, we propose _MoIPhenix_, a molecular _phenomics_ model. MolPhenix leverages a pre-trained phenomics model to demonstrate significant performance gains across perturbation concentrations, molecular scaffolds, and activity thresholds. In particular, we demonstrate an 8.1\(\) improvement in zero shot molecular retrieval of active molecules over the previous state-of-the-art, reaching 77.33% in top-1% accuracy. These results open the door for machine learning to be applied in virtual phenomics screening, which can significantly benefit drug discovery applications.

## 1 Introduction

Quantifying cellular responses elicited by genetic and molecular perturbations represents a core challenge in medicinal research . Out of an approximate \(10^{60}\) druglike molecule designs, a small number are able to alter cellular properties to reverse the course of diseases . In recent years, microscopy-based cell morphology screening techniques, demonstrated potential for quantitative understanding of a molecule's biological effects. Experimental techniques such as cell-painting are used to capture cellular morphology, which correspond to physical and structural properties of the cell . Cells treated with molecular perturbations can change morphology, which is captured by staining and high throughput microscopy techniques. Perturbations with similar cellular impact induce analogous morphological changes, allowing to capture underlying biologicaleffects in phenomic experiments. Identifying such perturbations with similar morphological changes can aid in discovery of novel therapeutic drug candidates [50; 29; 22].

Determining molecular impact on the cell can be formulated as a multi-modal learning problem, allowing us to build on a rich family of methods [43; 62; 53]. Similar to text-image models, paired data is collected from phenomic experiments along with molecules used to perturb the cells. Contrastive objectives have been used as an effective approach in aligning paired samples from different modalities [43; 32]. A model that has learned a cross-modal joint latent space must be able to retrieve a molecular perturbant conditioned on the phenomic experiment. We identify this problem as _contrastive phenomolecular retrieval_ (see Figure 2). Addressing this problem can allow for identification of molecular impact on cellular function, however, this comes with its own set of challenges. [18; 2; 65].

**(1)** Firstly, multi-modal paired phenomics molecular data suffers from lower overall dataset sizes and is subject to batch effects. Challenges with uniform processing and prohibitive costs associated with acquisition of paired data, leads to an order of magnitude fewer data points compared to text-image datasets [49; 11]. Furthermore, data is subject to random batch effects that capture non-biologically meaningful variation [33; 55]. **(2)** Paired phenomic-molecular data contains inactive perturbations that do not have a biological effect or do not perturb cellular morphology. It is difficult to infer a priori whether a molecule has a cellular effect, leading to the collection of paired molecular structures with unperturbed cells. These data-points are challenging to filter out without an effective phenomic embedding, as morphological effects are rarely discernible. These samples can be interpreted as misannotated, under the assumption of all collected pairs having biologically meaningful interactions. **(3)** Finally, a complete solution for capturing molecular effects on cells must capture molecular concentration. The same molecule can have drastically different effects along its dose response curve, thus making concentration an essential component for learning molecular impact.

In this work, we explore the problem of contrastive phenomolecular retrieval by addressing the above challenges circumvented in prior works. Our key contributions are as follows:

* We demonstrate significantly higher phenomolecular retrieval rates by utilizing a pretrained unimodal phenomic encoder. Thus alleviating the data availability challenge, reducing the impact of batch effects, and identifying molecular activity levels.
* We propose a novel soft-weighted sigmoid locked loss (S2L) that addresses the effects of inactive molecules. This is done by leveraging distances computed in the phenomic embedding space to learn inter-sample similarities.
* We explore _explicit_ and _implicit_ methods to encode molecular concentration, assessing the model's ability to perform retrieval in an inter-concentration setting and generalize to unseen concentrations.

Figure 1: Illustration of proposed guidelines when incorporated in our _MolPhenix_ contrastive phenomolecular retrieval framework. We address challenges by utilizing uni-modal pretrained MAE & MPNN models, inter-sample weighting with a dosage aware S2L loss, undersampling inactive molecules, and encoding molecular concentration.

[MISSING_PAGE_EMPTY:3]

(such as molecules) which are obtained at a specific dosage concentration \(_{i}\), while \(\) denotes molecular activity threshold.

Figure 2 describes the problem of contrastive phenomolecular retrieval, where for a single image \(_{i}\), the challenge consists of identifying the matching perturbation, \(_{i}\), and concentration, \(_{i}\), used to induce morphological effects. This can be accomplished in a zero-shot way by generating embeddings for \((_{1},_{1}),...(_{j},_{j})\) and \(_{i}\) using functions \(f_{_{m}}(,)\), \(f_{_{x}}()\) which map samples into \(^{d}\). Then, by defining a similarity metric between generated embeddings \(_{x_{i}}\) and \(_{m_{i}}\), \(f_{sim}\), we can rank \((_{1},_{1})...(_{j},_{j})\) based on computed similarities. An effective solution to the contrastive phenomolecular retrieval problem would learn \(f_{_{m}}(,)\) and \(f_{_{x}}()\) that results in consistently high retrieval rates of \((_{i},_{i})\) used to perturb \(_{i}\).

In practice, the image embeddings are generated using a phenomics microscopy foundation MAE model [28; 20]. We use phenomic embeddings to marginalize batch effects, infer inter-sample similarities, and undersample inactive molecules. Activity is determined using consistency of replicate measurements for a given perturbation. For each sample, a \(p\) value cutoff \(\) is used to quantify molecular activity. Only molecules below the \(p\) value cutoff \(\) are considered active.

Prior methods in multi-modal contrastive learning utilize the InfoNCE loss, and variants thereof  to maximize the joint likelihood of \(_{i}\) and \(_{i}\). Given a set of \(N N\) random samples \((_{1},_{1},_{1}),,(_{N}, _{N},_{N})\) containing \(N\) positive samples at \(k^{}\) index and \((N-1) N\) negative samples, optimizing Equation 1 maximizes the likelihood of positive pairs while minimizing the likelihood of negative pairs:

\[_{}=-_{i=1}^{N}[_{x_{i}},_{m_{i}}/. }{_{k=1}^{N}(_{x_{i}},_{ m_{k}}/)}+_{x_{i}}, _{m_{i}}/.}{_{k=1}^{N}( _{m_{i}},_{x_{k}}/)}].\] (1)

Where \(_{x}\), \(_{m}\) correspond to phenomics and molecular embeddings respectively, \(\) is softmax temperature, and \(\) corresponds to cosine similarity.

#### Challenge 1: Phenomic Pretraining and Generalization

We find that using a phenomics foundation model to embed microscopy images allows for mitigation of batch effects, reduces the required number of paired data points, and improves generalization in the process. While CLIP, a hallmark model in the field of text-image multi-modality, was trained on 400 million curated paired data points, there is an order of magnitude fewer paired molecular-phenomic molecule samples . Cost and systematic pre-processing of data make large scale data generation efforts challenging, and resulting data is affected by experimental batch effects. **Batch effects** induce noise in the latent space as a result of random perturbations in the experimental process, while biologically meaningful variation remains unchanged [39; 52]. Limited dataset sizes and batch effects make it challenging for contrastive learners to capture molecular features affecting cell morphology, yielding low retrieval rates .

We address data availability and generalization challenges by utilizing representations from a large **unimodal pre-trained phenomic model**, \(_{}\), trained to capture representations of cellular morphology. \(_{}\) is pretrained on microscopy images using a Fourier modified MAE objective, utilizing the ViT-L/8 architecture with methodology similar to Kraus et al. (2024) [20; 14; 28]. For simplicity in future sections, we refer to this model as _Phenom1_. This pretrained model allows a drastic

Figure 2: Illustration of the contrastive phenomolecular retrieval challenge. Image \(_{i}\) and a set of molecules and corresponding concentrations \((_{k},_{k})\) get mapped into a \(^{d}\) latent space. Their similarities get computed with \(f_{sim}\) and ranked to evaluate whether the paired perturbation appears in the top K%.

reduction in the required number of paired multi-modal samples . In addition, using phenomic representations alleviates the challenge of batch effects by averaging samples, \(_{x}\), generated with the same perturbation \(_{i}\) over multiple lab experiments \(_{i}\). Averaging model representations \(_{i N}^{1}_{x_{i}}\) allows marginalizing batch effect induced by individual experiments.

**Guideline 1**: _Utilizing pre-trained uni-modal encoder, \(_{}\), can be used to reduce the number of paired data-points compared to training \(\) without prior optimization. In addition, averaging phenomic embeddings \(_{x}\) from matched perturbations can alleviate batch effects._

To reason over molecular structures, we make use of features learned from GNNs trained on molecular property prediction . We utilize a pretrained MPNN foundational model up to the order of 1B parameters for extracting molecular representations following a similar procedure to Sypetkowski et al. (2024) . We refer to this model as _MolGPS_.

**Challenge 2: Inactive Molecular Perturbations**

The phenomics-molecular data collection process can result in pairing of molecular structures with unperturbed cells in cases where the molecule has no effect on cell morphology (Figure 3)

Since the morphological effects observed in cell \(_{i}\) is conditioned on the perturbation, in the absence of a molecular effect \(P(_{i}|_{i}^{0},_{i},_{i}) P( _{i}|_{i}^{0})\). In these samples, phenomic data will be independent, from paired molecular data, which results in misannotation under the assumption of data-pairs having an underlying biological relationship. We demonstrate how utilizing Phenom1 to undersample inactive molecules and learn continuous similarities between samples can alleviate this challenge.

To **undersample inactive molecules**, we extract the embeddings from Phenom1 and calculate the relative activity of each perturbation \((_{i},_{i})(,)\). This is done using the rank of cosine similarities between technical replicates produced for a molecular perturbation against a null distribution. The null distribution is established by calculating cosine similarities from random pairs of Phenom1 embeddings generated with perturbation \((_{j},_{j}),(_{k},_{k})\). Hence, we can compute a p-value and filter out samples likely to belong to the null distribution with an arbitrary threshold \(\).

In addition, by utilizing an inter-sample aware S2L **training objective**, the model can learn similarities between inactive molecules. S2L is grounded in previous work which demonstrates improved robustness to label noise (SigLip) and learnable inter-sample associations (CWCL) . Continuous Weighted Contrastive Loss (CWCL) provides better multi-modal alignment using a uni-modal pretrained model to suggest sample distances, relaxing the negative equidistant assumption present in InfoNCE :

\[_{}=- _{i=1}^{N}[^{N}_{i,j}^{}} _{j=1}^{N}_{i,j}^{}_{x_{i}},_{m_{j}}/)}{_{k=1}^{N} (_{x_{i}},_{m_{k}}/ )}].\] (2)

CWCL weights logits with a continuous measure of similarity \(^{}\), resulting in better alignment of embeddings \(_{_{i}}\) and \(_{_{j}}\) across modalities. In equation 2, \(^{}\) is computed using a within modality similarity function such as \(_{i,j}^{}= z_{_{i}},z_{_{ j}}/2+0.5\). Note, the above formula is used only for mapping samples from modality \(\) to \(\) for which a pre-trained model \(_{}\)is available.

Another work, SigLIP, demonstrates robustness to label noise and reduces computational requirements during contrastive training . It does so by avoiding computation of a softmax over the entire set of in-batch samples, instead relying on element-wise sigmoid operation:

\[_{}=-_{i=1}^{N}_{j=1}^{N}[ _{i,j}(-_{_{i}},_{_{j}}+b))}].\] (3)

Figure 3: Data generation process of a phenomic experiment on cells \(}\) with molecular perturbations \(}\) and concentrations \(}\).

In equation 3, \(\) and \(b\) are learned, calibrating the model confidence conditioned on the ratio of positive to negative pairs. \(_{i,j}\) is set to 1 if \(i=j\) and -1 otherwise.

Inspired by prior works, we introduce S2L for molecular representation learning, which leverages inter-sample similarities and robustness to label noise to mitigate weak or inactive perturbations.

\[_{}=-_{i=1}^{N}_{j=1}^{N}[ _{i,j}^{}}{1+(-_{ _{i}},_{_{j}}+b))}+_{i,j}^{})}{1+(_{_{i}},_{_{j}}+b)}].\] (4)

In the equation above, \(_{_{i}}\) and \(_{_{j}}\) correspond to latent representations of images and molecules, respectively. \(\) and \(b\) correspond to learnable temperature and bias parameters for the calibrated sigmoid function. \(_{ij}^{}\) is an inter-sample similarity function computed from images using the pretrained model \(_{_{}}\). To compute \(_{i,j}^{}\), we use the arctangent of L2 distance instead of cosine similarity, as was the case for Equation 2 (more details in Appendix D.3). Intuitively, S2L can be thought of as shifting from a multi-class classification to a soft multi-label problem. In our problem setting, the labels are continuous and determined by sample similarity in the phenomics space.

```
1:# mol_emb : molecule model embedding [n, dim]
2:# phn_emb : phenomics model embedding [n, dim]
3:# t_prime, b : learnable temperature and bias
4:# n : mini-batch size
5:# \(\) : custom similarity function
6:# \(,\) : similarity dampening parameters
7:
8:t = exp(t_prime)
9:zmol = 12_normalize(mol_emb)
10:zphn = 12_normalize(phn_emb)
11:logits = dot(zmol, zphn.T) * t + b
12:sim_matrix = \(\)zphn, zphn.T\(\) # [n, n] sample similarity matrix
13:pos = log_sigmoid(logits)
14:neg = log_sigmoid(- logits)
15:l = sim_matrix * pos + (\(\) - \(\) sim_matrix) * neg
16:l = - sum(l) / n ```

**Algorithm 1** S2L loss pseudo-implementation.

#### Challenge 3: Variable Concentrations

Perturbation effect on a cell is determined by both molecular structure and corresponding concentration . A model capturing molecular impact on cell morphology must be able to generalize across different doses, since variable concentrations can correspond to different data distributions.

We note that providing concentrations \(_{i}\) as input to the model would benefit performance, as this would indicate the magnitude of molecular impact. However, we find that simply concatenating concentrations does not result in effective training due to its compressed dynamic range. To that end, we add concentration information in two separate ways: _implicit_ and _explicit_ formulations.

We add **implicit concentration** as molecular perturbation classes by using the S2L loss (Equation 4) to treat perturbation \(_{i}\) with concentrations \(_{i}\) and \(_{j}\) as distinct classes. This pushes samples apart in the latent space proportionally to similarities between phenomic experiments.

We add **explicit concentration**\(c_{i}\) by passing it to the molecular encoder. We explore different formulation for dosage concentrations, \(^{}(c_{i})\), where \(^{}\) maps \(}\). Encoded representations \(^{}(c_{i})\)are concatenated at the initial layer of the model. We find simple functional encodings \(^{}\) (such as one-hot and logarithm) to work well in practice.

**Guideline 3**: _When training a molecular-phenomic model, conditioning on an (implicit and explicit) representation of concentration \(^{}(_{i})\) aids in capturing molecular impacts on cell morphology and improves generalization to previously unseen molecules and concentrations._

## 4 Experimental Setup

In this section, we describe evaluation datasets used, and descriptions of the underlying data modalities. To assess phenomolecular retrieval, we use 1% recall metric unless stated otherwise, as it allows direct comparison between datasets with different number of samples. Additional implementation and evaluation details can be found in Appendix D.

Datasets:Our training dataset consists of fluorescent microscopy images paired with molecular structures and concentrations, which are used as perturbants. We assess models' phenomolecular retrieval capabilities on three datasets of escalating generalization complexity. First dataset, consisting of unseen microscopy images and molecules present in the training dataset. Second, a dataset consisting of previously unseen phenomics experiments and molecules split by the corresponding molecular scaffold. Finally, we evaluate on an open source dataset with a different data generating distribution . In the case of the latter two datasets, the model is required to perform zero-shot classification, as it has no access to those molecules in the training data. This requires the model to reason over molecular graphs to identify structures inducing corresponding cellular morphology changes. Using methodology described in guideline 2 we report retrieval results for all molecules as well as on an active subset. Finally, all datasets are comprised of molecular structures at multiple concentrations (\(.01,.1,1.0,10\), etc.) Additional details regarding the datasets can be found in Appendix C.

Modality Representations:In our evaluations, we consider different representations for molecular perturbations and phenomic experiments and quantitatively evaluate their impact.

* Images: Image encoders utilize 6-channel fluorescent microscopy images of cells representing phenomic experiments. Images are 2048 \(\) 2048 pixels, capturing cellular morphology changes post molecular perturbation. We downscale each image to 256 \(\) 256 using block mean downsampling.
* Phenom1: We characterize phenomic experiments by embedding high resolution microscopy images in the latent space of a phenomics model \(_{Ph}\) as described in guideline 1.
* Fingerprints: Molecular fingerprints utilize RDKIT , MACCS  and MORGAN3  bit coding, which represent binary presence of molecular substructures. Additional information such as atomic identity, atomic radius and torsional angles are included in the fingerprint representations.
* MolGPS: We generate molecular representations from a large pretrained GNN. Specifically, we obtain molecular embeddings from a 1B parameter MPNN .

    & &  &  \\  Method & & & Unseen & Unseen & Unseen & Unseen & Unseen & Unseen \\  & & Im. & Im. + Mol. & Dataset & Im. & Im. + Mol. & Dataset \\  CLOOME & Images \& Multi-FPS & \(0.756 0.042\) & \(0.787 0.005\) & \(0.528 0.0057\) & \(0.547 0.0028\) & \(0.0661 0.0020\) & \(0.2223 0.0014\) \\ CLOOME & Phenom1 \& Multi-FPS & \(4.659 0.042\) & \(5057 0.0014\) & \(2065 0.146\) & \(3009 0.0053\) & \(2.474 0.013\) & \(1.337 0.0045\) \\ MolPhenix & Phenom1 \& Multi-FPS & \(\) & \(6.365 0.004\) & \(3.354 0.0097\) & \(\) & \(\) & \(2163 0.0021\) \\ MolPhenix & Phenom1 \& MolGPS & \(7.646 0.0014\) & \(\) & \(\) & \(5.0012 0.0002\) & \(3511 0.0041\) & \(\) \\  MolPhenix* & Phenom1 \& MolGPS & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 1: Impact of pre-trained Phenom1 and MolGPS on CLOOME and MolPhenix for a matched number of seen samples (Top), where we observe an \(\) improvement of MolPhenix over the CLOOME baseline for active unseen molecules. SOTA results trained with a higher number of steps by utilizing the best hyperparameters (Bottom *). We note that MolPhenix’s main components such as S2L and embedding averaging relies on having a pre-trained uni-modal phenomics model.

[MISSING_PAGE_EMPTY:8]

retrieval performance gap, throughout training, with a **1.26**\(\) final improvement (Figure 4, Table 1). Compared to CLOOME  trained directly on images, MolPhenix achieves an average improvement of \(\) on active molecules on the unseen dataset. These results verify the effectiveness of Guideline 1 in accelerating training, and the importance of Guidelines 2 and 3 in recall improvements over CLOOME.

We evaluate the impact of different loss objectives on the proposed MolPhenix training framework. Table 2 presents top-1% retrieval accuracy across different contrastive losses utilized to train molecular-phenomics encoders on cumulative concentrations. Compared to prior methods, the proposed S2L loss demonstrates improved retrieval rates in cumulative concentration setting. Label noise and inter-sample similarity aware losses such as CWCL and SigLip also demonstrate improved performance. The effectiveness of S2L can be attributed to smoothed inter-sample similarities and implicit concentration information.

Finally, in Table 3, we observe recall improvements when considering both molecular structures and concentration. We note the importance of the addition of implicit concentration, further confirming the importance of considering molecular effects at different concentrations as different classes. Explicitly encoding molecular concentration with one-hot, logarithm and sigmoid yields improved recall performance, where one-hot performs the best in a cumulative concentration setting. These findings verify the efficacy of implicit and explicit concentration encoding outlined in Guideline 3.

Results are averaged across experiments for each dropped concentration, and across three seeds. Recall is reported for active molecules, while the results for all molecules can be found in Table 13.

### Evaluation on held-out concentrations:

Next, we evaluate recall on held-out concentrations to obtain a measure of generalization performance. This evaluation allows us to capture the utility of our models for prediction of unseen concentrations, hence resembling _in-silico_ testing. We omit concentrations from the training set and evaluate recall at the excluded data, where we observe a drop in retrieval performance for unseen concentrations. Similar to cumulative concentration results, we find that using S2L improves recall over other losses and outperforms CLOOME by up to 126% (Table 4). While one-hot encoding exhibits significant improvements in cumulative concentrations, its expressivity on unseen concentrations is limited (Table 5) and sigmoid encoding provides a sufficient representation of concentration.

### Ablation Studies

We assess the importance of our design decisions by conducting an ablation study over our proposed guidelines. Figure 5 presents the variation of top-1% recall accuracy across key components such as cutoff \(p\) value, fingerprint type, and embedding averaging. We observe that employing a lower cutoff \(p\) value yields improved generalization for unseen dataset, while employing a higher cutoff appears to be optimal for unseen images + unseen molecules. For molecular structure representations, we find that using embeddings from the large pretrained MPNN graph based model (e.g., MolGPS) surpasses traditional fingerprints. Finally, utilization of embedding averaging demonstrates improved recall.

   Loss &  Unseen \\ Im. \\  &  Unseen \\ Im. + Mol. \\  &  Unseen \\ Dataset \\  \\   CLIP \\ Hopfield-CLIP \\ InfoLOOB \\  &.2122 &.2496 &.1519 \\  CLOOME \\  &.2164 &.2461 &.1479 \\  PCL \\  &.4717 &.4027 &.2841 \\  CVCL \\ SigLip \\  &.5731 &.4403 &.3232 \\ 
 S2L (ours) \\  & **.8334** & **.4615** & **.3792** \\   

Table 4: Top-1% recall accuracy of different loss objectives while using the proposed MolPhenix guidelines, such as Phenom1 and embedding averaging.

    &  Unseen \\ Im. \\  &  Unseen \\ Im. + Mol. \\  &  Unseen \\ Dataset \\  \\   CLIP \\ Hopfield-CLIP \\ InfoLOOB \\  &.2122 &.2496 &.1501 \\  CLOOME \\  &.2164 &.2461 &.1479 \\  PCL \\  &.4717 &.4027 &.2841 \\  CVCL \\ SigLip \\  &.5731 &.4403 &.3232 \\  SigLip \\  &.5718 &.4217 &.3021 \\ 
 S2L (ours) \\  & **.8334** & **.4615** & **.3792** \\   

Table 5: Top-1% recall accuracy across different concentration encoding choices while using the proposed MolPhenix guidelines, such as Phenom1 and embedding averaging.

## 6 Conclusion

In this work, we investigate the problem of _contrastive phenomolecular retrieval_ by constructing a joint multi-modal embedding of phenomic experiments and molecular structures. We identify a set of challenges afflicting molecular-phenomic training and proposed a set of guidelines for improving retrieval and generalization. Empirically, we observed that contrastive learners demonstrate higher retrieval rates when using representations from a high-capacity uni-modal pretrained model. Use of inter-sample similarities with a label noise resistant loss such as S2L allows us to tackle the challenge of inactive molecules. Finally, adding implicit and explicit concentrations allows models to generalize to previously unseen concentrations. MolPhenix demonstrates an **8.1\(\)** improvement in zero shot retrieval of active molecules over the previous state-of-the-art, reaching 77.33% in top-1% accuracy. In addition, we conduct a preliminary investigation on MolPhenix's ability to uncover biologically meaningful properties (activity prediction, zero-shot biological perturbation matching, and molecular property prediction in Appendix E.1, E.2, and E.3, respectively.). We expect a wide range of applications for MolPhenix, particularly in drug discovery. While there's a remote chance of misuse for developing chemical weapons, such harm is unlikely, with our primary focus remaining on healthcare improvement.

**Limitations and Future Work:** While our study covers challenges in phenomolecular recall, we leave three research directions for future work. (1) Future investigations could consider studying additional modalities such as text, genetic perturbations and chemical multi-compound interventions. (2) While we propose and evaluate our guidelines on previously conducted phenomic experiments, we note that a rigorous evaluation would evaluate model predictions in a wet-lab setting. (3) In addition, our work makes the assumption that the initial unperturbed cell state \(x_{i}^{0}\) can be marginalized by utilizing a single cell line with an unperturbed genetic background. Future works can relax this assumption, aiming to capture innate intercellular variation.