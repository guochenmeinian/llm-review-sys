# Neural Concept Binder

Wolfgang Stammer\({}^{1,2,}\) &Antonia Wust\({}^{1,}\)&David Steinmann\({}^{1,2,}\)

&Kristian Kersting\({}^{1,2,3,4}\)

\({}^{1}\)Computer Science Department, TU Darmstadt; \({}^{2}\)Hessian Center for AI (hessian.AI);

\({}^{3}\)German Research Center for AI (DFKI); \({}^{4}\)Centre for Cognitive Science, TU Darmstadt

These authors share equal contribution.Correspondence to: Wolfgang Stammer <wolfgang.stammer@cs.tu-darmstadt.de>.

###### Abstract

The challenge in object-based visual reasoning lies in generating concept representations that are both descriptive and distinct. Achieving this in an unsupervised manner requires human users to understand the model's learned concepts and, if necessary, revise incorrect ones. To address this challenge, we introduce the _Neural Concept Binder_ (NCB), a novel framework for deriving both discrete and continuous concept representations, which we refer to as "concept-slot encodings". NCB employs two types of binding: "soft binding", which leverages the recent SysBinder mechanism to obtain object-factor encodings, and subsequent "hard binding", achieved through hierarchical clustering and retrieval-based inference. This enables obtaining expressive, discrete representations from unlabeled images. Moreover, the structured nature of NCB's concept representations allows for intuitive inspection and the straightforward integration of external knowledge, such as human input or insights from other AI models like GPT-4. Additionally, we demonstrate that incorporating the hard binding mechanism preserves model performance while enabling seamless integration into both neural and symbolic modules for complex reasoning tasks. We validate the effectiveness of NCB through evaluations on our newly introduced CLEVR-Sudoku dataset. Code and data at: project page.

## 1 Introduction

An essential aspect of visual reasoning is obtaining a proper _conceptual_ understanding of the world by learning visual concepts and processing these into a suitable representation (_cf._ Fig. 1). The majority of current machine learning (ML) approaches that focus on visual concept-based processing utilize forms of supervised , weakly-supervised  or text-guided  learning of concepts. These approaches all require some form of additional (prior) knowledge about the relevant domain. An attractive alternative, though much more challenging, is to learn concepts in an unsupervised fashion. This comes with several challenges: (i) learning an expressive concept representation without concept supervision is intrinsically difficult , and (ii) there is no guarantee that learned concepts align with general domain knowledge  and (iii) can therefore be utilized for complex downstream tasks. Moreover, (iv) to trust that the learned concept representations are reliable for high stakes scenarios , it is necessary to make the model's concept representations human-_inspectable_ and -_revisable_ (_cf._ Fig. 1 (left)).

These challenges raise questions about the nature of the unsupervised learned concept representations. Continuous encodings  are easier to learn and more expressive. However, they are difficult to interpret and suffer from problems related to poor generalization  and information leakage . On the other hand, discrete encodings  are hard to learn , but are easier to understand and thus align, _e.g._, to a task at hand.

This work proposes the **Neural Concept Binder** (NCB) framework to learn expressive, yet inspectable and revisable, concepts from unlabeled data. NCB combines continuous encodings, obtained via block-slot-based _soft-binding_, with discrete concept representations, derived through retrieval-based _hard-binding_. NCB's soft binding leverages the object-factor disentanglement capabilities of the recent SysBinder mechanism . Subsequently, NCB's hard binding mechanism utilizes HDBSCAN [12; 13] to cluster the continuous block-slot encodings, distilling a structured corpus of discrete concepts from these clusters. This corpus enables the retrieval of discrete concept representations during inference by matching the continuous encoding with the closest entries in the corpus. Thus, to address the challenges of unsupervised concept learning, NCB integrates the strengths of both continuous _and_ discrete concept representations. Moreover, NCB enables straightforward concept inspection and facilitates easy revision procedures, allowing alignment of the learned concepts with prior knowledge. In our evaluations, we demonstrate that NCB's discrete _concept-slot_ encodings retain the expressiveness of their continuous counterparts. Moreover, they can be seamlessly integrated into downstream applications via symbolic _and_ interpretable neural computations (_cf._ Fig. 1 (right)). In this context, we introduce our novel _CLEVR-Sudoku_ dataset, which presents a challenging visual puzzle that requires both perception and reasoning capabilities (_cf._ Fig. 4).

In summary, our contributions are the following: **(i)** we introduce the Neural Concept Binder framework (NCB) for unsupervised concept learning, **(ii)** we show the possibilities to integrate NCB with symbolic and subsymbolic modules in challenging downstream tasks, achieving performance on par with supervised trained models, **(iii)** we highlight the possibilities of easy concept inspection and revision via NCB, and **(iv)** we introduce the novel CLEVR-Sudoku dataset, which combines challenging visual perception and symbolic reasoning.

## 2 Related Work

**Unsupervised visual concept learning** focuses on obtaining concept-level representations from unlabeled images . Some works have tackled this only for specific domains, such as extracting "teachable" concepts for chess  or learning manipulation concepts from videos of task demonstrations . Others rely on object-level concept guidance through initial image segmentations  or "natural supervision" . In contrast, Vedantam et al.  and Wust et al.  focus on learning higher-level relational concepts, _i.e._, assuming that basic-level concepts have already been provided. Several approaches learn concepts from the training signal of an image classification task [78; 1; 14; 38], often focusing on image-region-based concepts . More recently, several works have explored leveraging the knowledge stored in large pretrained models, such as combining large language models with CLIP embeddings [82; 52] or using weakly-supervised queries to a vision-language model . These approaches still rely on some form of supervision, whether through text, class labels, or prompts. In contrast, this work focuses on learning unsupervised concepts at both the object and factor levels, ensuring that these concepts remain inherently inspectable and revisable.

The motivation for **inherently inspectable and revisable concept representations** is to allow human stakeholders to investigate and potentially revise a model's internal concepts. Most research in this area focuses on post-hoc approaches that distill concept knowledge from pretrained models [83; 21; 57;

Figure 1: **Unsupervised learning of concepts for visual reasoning. (left) Models that learn concepts from unlabeled data require inspectable and revisable concept representations. (right) Concepts obtained from the Neural Concept Binder (NCB) can be utilized both in (interpretable) neural and symbolic computations.**

18, 23]. In contrast, Lage and Doshi-Velez  explore learning inspectable concept representations through human feedback, focusing on tabular data and higher-level concepts. Similarly, Stammer et al.  develop inherently inspectable visual concepts using weak supervision and a prototype-based binding mechanism. However, no existing work addresses the development of inherently inspectable and revisable concept representations in the context of unsupervised visual learning.

The properties of **discrete vs. continuous encodings** are a vibrant research topic that is highly relevant to learning suitable concept representations. Continuous encodings allow for easier and more flexible optimization and information binding . However, discrete representations are considered essential for understanding AI models , mitigating shortcut learning , and solving complex visual reasoning tasks . Despite their advantages, learning discrete representations through neural modules remains a challenging problem . While some works have focused on categorical-distribution-based discretization , others have explored retrieval-based discretization of continuous encodings using various forms of inherent "codebooks" . Only a few studies have explicitly addressed how to bind semantic visual information to specific discrete representations . Whereas previous works typically emphasize one of the two representation types, we see great potential in the recent trend of explicitly integrating both discrete and continuous representations .

## 3 Neural Concept Binder (NCB): Extracting Hard from Soft Concepts

In this work, we refer to a concept as "the label of a set of things that have something in common" . This definition can be applied on different scales of a visual scene: on an image level (_e.g._, an image of a _park_), an object level (_e.g._, a _tree_ vs. a _bird_) or an object-factor level (_e.g._, the _color_ of a bird). Our proposed Neural Concept Binder (NCB) framework tackles the challenge of learning inspectable and revisable object-factor level concepts from unlabeled images by combining two key elements: (i) continuous representations via SysBinder's block-slot-attention  with (ii) discrete representations via retrieval-based inference. Fig. 2 provides an overview of NCB's inference, training, concept inspection, and revision processes. Let us formally introduce these processes.

Overall, we consider a set of _unlabeled_ images \(X:=(x_{1},,x_{N})^{N D}\) with \(x_{i}^{D}\), \(N\) and \(D\) (for simplicity, we drop the image index notation in the following). Briefly, given an image, x, NCB infers latent block-slot encodings, z, and performs a retrieval-based discretization step on z to infer concept-slot encodings, c. These express the concepts of the objects in the image, i.e., object-factor level concepts. We begin by introducing the inference procedure of NCB. We hereby assume that NCB's components have already been trained and will introduce details of the training procedure subsequently.

Figure 2: The **Neural Concept Binder** (NCB) combines continuous, block-slot encodings via slot-attention based image processing with discrete, concept-slot encodings via retrieval-based inference. The structured retrieval corpus (distilled from the block-slot encodings) allows for easy concept inspection and revision by human stakeholders. Moreover, the resulting concept-slot encodings can be easily integrated into complex downstream tasks.

### Inferring Concept-Slot Representations

**Obtaining _Continuous Block-Slot-Encodings.** Consider an image \(x X\). The first component of NCB, the _soft binder_, is based on the systematic binding mechanism  and is represented by a block-slot encoder (_cf._ Fig. 2 (i)), \(g_{}:x z^{N_{S} N_{B} D_{B}}\), where \(g\) is parameterized by \(\) (for simplicity, this notation is omitted in the following). The soft binder transforms an input image into a latent, continuous _block-slot_ representation, where \(N_{S}\) represents the number of slots, \(N_{B}\) the number of blocks per slot, and \(D_{B}\) the dimension of each block. The soft binder employs two key types of _binding_ mechanisms: spatial and factor binding. Spatial binding ensures spatial modularity across the entire scene and is achieved through slot attention , allowing each object in the image to be represented in a specific slot, \(z_{i}\). Factor binding, introduced by Singh et al. , ensures that different object _factors_ (_e.g._, attributes like color) are encoded in separate blocks of a slot, _i.e._, \(z_{i}^{j}\). These two binding mechanisms work together to perform object- and factor-based image processing. We refer to Suppl. A.1 for additional details on both systematic (factor) binding and slot attention. Overall, the resulting block-slot encodings represent continuous, object-centric representations of the input image, with objects encoded in slots and object factors encoded within the blocks of those slots.

**Obtaining _Discrete_ Concept-Slot-Encodings.** The role of NCB's second processing component, the _hard binder_, is to transform the continuous block-slot encodings into expressive, yet _discrete_ concept-slot encodings. Specifically, the hard binder is represented by a retrieval encoder, \(f\) (_cf._ Fig. 2 (v)), which processes the block-slot encodings, \(z\), into a set of discrete concept-slot encodings, \(c\). In detail, \(f\) defines a function \(f_{}:z c^{N_{S} N_{B}}\), parameterized by a retrieval corpus \(\) (_cf._ Fig. 2 (iv)). This retrieval corpus consists of a tuple of sets \(:=[^{1},,^{N_{B}}]\), where each set \(^{j}:=\{(^{j}_{l},v_{l}):l\{1,...,|^{j}|\}\}\) contains tuples of block encodings, \(^{j}_{l}^{D_{B}}\), and corresponding discrete values, \(v_{l}\{1,,N_{C}\}\). Importantly, \(^{j}_{l}\) is a representative block encoding of a specific _concept_ cluster, determined during NCB's training phase (_cf._ Fig. 2 (iii), detailed below). \(v_{l}\) serves as the _symbol_ identifier for the concept cluster associated with \(^{j}_{l}\). Each block can contain up to \(N_{C}\) different concepts. To infer the concept symbol for a sample's block-slot encoding, NCB compares \(z_{i}^{j}\) with the encodings in the corresponding block's retrieval corpus, \(^{j}\), and selects the most fitting concept. Specifically, given a distance metric \(d(,)\) and the block-slot encoding \(z_{i}^{j}\), the selection function \(s_{}:z_{i}^{j} l\) (Fig. 2 (v)) finds the index \(l\) of the closest encoding in the retrieval corpus: \(s_{}(z_{i}^{j})=*{argmin}_{l}d(^{j}_{l},z_ {i}^{j})\) such that \((^{j}_{l},v_{l})^{j}\). This results in the concept representation for slot \(i\) and block \(j\), denoted as \(c_{i}^{j}:=v_{s_{}(z_{i}^{j})}\). For slot \(i\), the full concept representation is denoted as \(c_{i}:=[c_{i}^{1},,c_{i}^{N_{B}}]\) and the final concept-slot encoding as \(c:=f_{}(z)=[c_{1},,c_{N_{S}}]\). We refer to Suppl. A.2 for details on an alternative _top-k_ selection function. We further note that NCB's flexibility, in principle, allows also to utilize the continuous encodings of its soft binder (Fig. 2 dashed arrow) in case a downstream task requires it. Let us now move on to NCB's training procedure.

### Unsupervised Concept Learning via NCB

The training procedure of the Neural Concept Binder is separated into two subsequent steps where we provide an overview here and details in Suppl. A.3. We formally describe these steps using the pseudo-code in Alg. 1. The first step consists of optimizing the encoder, \(g\), to provide _object-factorised_ block-slot encodings. It is optimized for unsupervised image reconstruction based on the decoder model, \(g^{}_{^{}}:z^{D}\) (Fig. 2 (ii)) and utilizing a mean squared error loss: \(L=L_{}(x,g^{}(g(x)))\). The goal of NCB's second training step is to obtain the retrieval corpus, \(\). This procedure is based on obtaining an optimal clustering of block encodings via an unsupervised clustering model, \(h\), and distilling the resulting information from \(h\) into explicit representations in the retrieval corpus. For each block \(j\) a clustering model \(h_{^{j}}\) (Fig. 2 (iii)) is fit to identify a potentially overparameterised set of clusters within a set of block encodings (based on an unsupervised criterion, _e.g._, a density-based score ), resulting in \(N_{C}\) clusters. Next, for each cluster, \(v\{1,,N_{C}\}\), representative block encodings, \(^{j}\), are extracted from \(h\). Such an encoding represents either an averaged _prototype_ or instance-based _exemplar_ encoding. The corresponding tuples \((^{j},v)\) are explicitly stored in the retrieval corpus \(^{j}\) (Fig. 2 (iv)) where we use the index \(l\) to identify specific encodings in \(^{j}\), leading to \(^{j}:=\{(^{j}_{l},v_{l}):l\{1,...,|^{j}|\}\}\). Thus, \(^{j}_{l}\) represents one block encoding of \(^{j}\) that has been assigned to cluster \(v_{l}\). Finally, \(=[^{1},,^{N_{B}}]\) represents the final retrievalcorpus, _i.e._, the set of corpora for each block. Through this training procedure, NCB learns to unsupervisedly categorize the object-factor information from the latent encoding space of the soft binder and stores this information in a structured, symbolic, and accessible way in the hard binder's retrieval corpus. We refer to the resulting clusters of each block as NCB's _concepts_ and denote concepts with a capital letter for the block and a natural number for the category id, _e.g._, \(A3\). We note that in practice, it is further possible to finetune the block-slot encoder, \(g\), through supervision from the hard binder (_cf._ gray arrow in Fig. 2), _e.g._, once initial categories have been identified, and can be achieved via a standard supervised approach. Ultimately, this allows for _dynamically_ finetuning NCB's concept representations. Let us now introduce how human stakeholders can inspect and revise NCB's learned concepts.

### Inspecting and Revising NCB's Concepts

**Inspection.** NCB inherently enables: (i) _implicit_, (ii) _comparative_, (iii) _interventional_ and (iv) _similarity_-based inspection (_cf._ Fig. 3). Where the first three aim at investigating NCB's explicit, _symbolic_ concept space (stored in \(\)), the last one aims at investigating its latent, continuous concept space (stored in \(\)). **(i) Implicit inspection** queries the model to provide a set of examples for a specific concept. Essentially, this answers the question _"What are examples of this concept?"_. NCB answers this question in two ways: by providing samples from the retrieval corpus corresponding to _exemplars_ of the concept or by identifying additional data samples belonging to the concept at hand. **(ii) Comparative inspection**, on the other hand, allows comparing two specifically different concepts, _e.g._, _"Why does this object depict concept H5 and not concept H1?"_. NCB hereby provides examples for both concepts for the user to compare and potentially identify dissimilar properties. Ultimately, this form of inspection allows to answer questions of the form "Why _not_...?" and represents a valuable tool for in-depth and targeted concept inspection. **(iii) Interventional inspection** allows to answer questions such as _"What if this object would have concept H1?"_ To answer this question, NCB utilizes its decoder \(g^{}\). Specifically, by swapping the block \(z_{i}^{j}\) of a data sample's block-slot encoding with that of a representative sample, \((_{l}^{j},v_{l})^{j}\), NCB can provide an _interventional_ image reconstruction, from which the effect of the swapped concept can be observed. Ultimately, this form of inspection allows to answer important questions of the form "What if...?". Finally, **(iv) Similarity inspection** allows inspecting NCB's _continuous_ encoding space on a more global level (in comparison to the more symbolic, sample-based inspection above), _e.g._, _"What are similar concepts to this concept?"_. Specifically, NCB's distance metric \(d\) directly provides information about the similarity between concepts in the continuous representation. Inspecting the block-slot encoding space thus allows to identify a suboptimal soft binding, _e.g._, when block encodings are similar according to \(g\) but not according to the human stakeholder. Overall, these inspection mechanisms allow a human stakeholder to ask a diverse set of questions concerning a model's learned concepts (_cf._ Fig. 15, Fig. 16 and Fig. 17 for additional examples of the inspection types).

**Revise.** Let us now describe how a human stakeholder can revise NCB's concept space. Below, we provide details on the three main actions for _symbolic_ revision (_i.e._, revision on the representations in \(\)): (i) _merging_, (ii) _deleting_, or (iii) _adding_ information. These actions can be performed on a single encoding or on a concept level and essentially represent a form of "reorganization" of information

Figure 3: **NCB’s concept space is inherently inspectable.** A human stakeholder can easily inspect the concept space by asking a diverse set of questions. For example, NCB answers interventional questions (iii) via generating images with selectively modified concepts.

stored in \(\). Furthermore, we provide details on how to (iv) _revise the continuous latent space_, which essentially requires finetuning of \(g\)'s parameters. **(i) Merge Concepts:** In the case that \(\) contains multiple concepts that, according to additional knowledge (_e.g._, from a human or other model), represent a joint underlying concept (_e.g._, two concepts for purple in Fig. 3 (right)) it is easy to update the model's internal representations by replacing the concept symbols of one concept with those of the second concept. Specifically, for block \(j\) if concept \(m\) should be merged with concept \(b\) where \(m,b\{1,,N_{C}\}\), then for all corpus tuples, \((_{l}^{j},v_{l})^{j}\), we replace \(v_{l}\) with \(b\) if \(v_{l}=m\). **(ii) Delete Encodings or Concepts:** If \(^{j}\) contains an encoding, \(_{l}^{j}\), for a specific concept, \(m\), that does not match the other encodings of that concept (_e.g._, a misplaced exemplar) this encoding can simply be deleted from the corpus. Accordingly, if an entire concept, \(m\), is identified as suboptimal, one can simply delete all corresponding encodings of that concept. _I.e._, for all corpus tuples, \((_{l}^{j},v_{l})^{j}\), we remove the tuple if \(v_{l}=m\). **(iii) Add Encodings or Concepts:** If a specific concept is not sufficiently well captured via the existing encodings in \(^{j}\), one can simply add a new encoding, \(_{l+1}^{j}\), for the concept, \(m\), to the corpus. This leads to an additional entry in the corpus, \((_{l+1}^{j},m)\). Accordingly, it is also possible to add encodings for an entire concept. Hereby, one gathers block encodings of objects that represent that novel concept and adds these to the corpus as \((_{l+1}^{j},b)\) with \(b=N_{C}+1\). **(iv) Revise the (Continuous) Latent Space:** Lastly, if the soft binder provides suboptimal object- and factor-level block-slot encodings, it is further possible to integrate revisory feedback on the soft binder's continuous latent space. This can be achieved via additional finetuning of the soft binder's parameters, \(\), _e.g._, via standard forms of weak supervision  or interactive learning .

In summary, our novel Neural Concept Binder framework fulfills several important desiderata for concept learning (_cf._ Tab. 1). Specifically, NCB learns concepts in an unsupervised fashion that are structured on both an object and factor-level. Furthermore, next to standard continuous encodings, NCB also provides discrete concept representations, which are crucial for interpretability and integration into symbolic computations. Lastly, NCB's concept space is inspectable and revisable, essential for unsupervised learned concept representations.

## 4 Experimental Evaluations

In our evaluations, we investigate the potential of NCB's soft and hard binding mechanisms in unsupervised concept learning and its integration into downstream tasks. Notably, NCB encompasses concept processing between both of its components (soft binder and hard binder) whereby the direction "soft binder \(\) hard binder" (_cf._ Fig. 2) represents a standard approach (_i.e._, supervised learning of the soft binder's encoding space via symbolic concept labels, _e.g._, ). Therefore, we focus our evaluations on NCB's more novel processing direction, "soft binder \(\) hard binder". We aim to answer the following research questions: **(Q1)** Does NCB provide **expressive** and **distinct** encodings? **(Q2)** Can NCB be combined with **symbolic** methods to solve complex downstream tasks? **(Q3)** Can NCB's learned concepts be **revised** to improve suboptimal behaviour? **(Q4)** Can NCB be combined with **subsymbolic** methods to _transparently_ solve complex downstream tasks?

  Method & Unsupervised & Obj. level & Factor level & Cont. ens & Disc. ens & Inspectable & Revisable \\   CBM  & ✗ & ✗ & ✓ & ✗ & ✓ & ✓ & ✓ \\  NegyCL  & ✗ & ✓ & ✓ & ✗ & ✓ & ✓ & ✓ \\  Glaneckus  & ✗ & ✗ & ✓ & ✓ & ✓ & ✓ & ✓ \\ VAE  & ✓ & ✗ & ✓ & ✓ & ✗ & ✗ & ✗ \\  VQ-VAE  & ✓ & ✗ & ✗ & ✓ & ✓ & ✗ & ✗ \\ SA  & ✓ & ✓ & ✗ & ✓ & ✗ & (✓) & ✗ \\  Sysbinder  & ✓ & ✓ & ✓ & ✓ & ✗ & (✓) & ✗ \\  
**Neural Concept Binder** & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ \\  

Table 1: **Comparison of different approaches for concept learning. Hereby, we differentiate based on the following categories: whether a method (1) is learned in an unsupervised fashion, (2) provides object-level concepts (_i.e._, can explicitly process multiple objects), (3) provides factor-level concepts (_e.g._, the color green), (4) provides continuous concept encodings, (5) provides discrete concept encodings, (6) provides inherently inspectable and (7) revisable concept representations.**

**Data.** We focus our evaluations on different variations of the popular CLEVR dataset. Specifically, we investigate (Q1 & Q3) in the context of the CLEVR  and CLEVR-Easy  datasets. For investigating the integration of NCB into symbolic modules (Q2), we utilize our novel CLEVR-Sudoku puzzles introduced in the following. Finally, to evaluate the integration of NCB into subsymbolic modules (Q4), we evaluate on confounded and non-confounded variants of the CLEVR-Hans3 dataset . We provide further details on these datasets in the supplements (_cf._ Suppl. C).

**CLEVR-Sudoku.** To investigate the potential of integrating NCB's discrete concept representations into symbolic downstream tasks, we introduce the novel CLEVR-Sudoku dataset. This dataset presents a challenging visual puzzle that requires both visual object perception and reasoning capabilities. Each sample in the dataset (_cf._ Fig. 4 for an example puzzle) consists of a Sudoku puzzle (partially filled) with CLEVR-based images  and additional example images depicting the mapping of relevant object properties to digits. Specifically, each digit in the Sudoku is replaced by an image of an object. All objects representing the same digit share a set of common properties, _e.g._, in Fig. 4, all objects replacing "1"s are yellow spheres.

We introduce two variants of CLEVR-Sudoku: _Sudoku CLEVR-Easy_ and _Sudoku CLEVR_. In the first variant, shape and color are distinguishing properties for the digits. In _Sudoku CLEVR_, additional object attributes -- size and material -- are relevant for the digit identification. Moreover, up to 10 example images are provided per digit mapping; the fewer examples provided, the more difficult it becomes to learn the mapping. The initial state and digit-attribute mappings vary across samples. One specific intricacy of CLEVR-Sudoku is that the puzzle can only be solved if all subcell images are correctly mapped to their corresponding digits. Even a single mistake can render the Sudoku unsolvable. Thus, compared to standard Sudoku puzzles, which primarily require deductive reasoning, solving CLEVR-Sudoku also demands complex object recognition and the ability to map visual concept perceptions to the _task concepts_ (_i.e._, the 9 digits of Sudoku). For further details, we refer to Suppl. B.

**Models.** For our evaluations, we instantiate Neural Concept Binder based on the SysBinder model  for the soft binder encoder, \(g\), and HDBSCAN  for the clustering model, \(h\). Further details about the instantiation can be found in Suppl. A.4. In the context of **Q1**, we compare NCB's results to four variations of the SysBinder model , as well as the recent Neural Language of Thought Model (NLOTM) . We refer to the original SysBinder configuration as _SysBinder (cont.)_, which provides continuous block-slot encodings. In _SysBinder_, SysBinder's continuous encodings are discretized at inference time via an \(*{argmin}\) operation over its internal codebooks. _SysBinder (hard)_ is trained from the beginning to produce discrete encodings using a low codebook softmax temperature. _SysBinder (step)_ is trained with a step-wise decrease in temperature (_cf._ Suppl. D for details). For evaluations on CLEVR-Sudoku (**Q2** and **Q3**), we first infer NCB's discrete concept-slot encodings from the puzzle's candidate examples. These encodings, along with their corresponding digit labels, are then passed to a symbolic classifier, which is trained to predict digits from the encodings. The classifier subsequently infers the digits for each subcell in the puzzle's initial state. These predictions are used by a constraint propagation and search-based algorithm  to solve the puzzle (_cf._ Suppl. E.2 for details). We refer to the combination of the symbolic classifier and constraint solver as the _solver_. We compare the solver's performance when provided with ground-truth (GT) object-property labels (_GT concepts_), encodings from a supervised slot attention encoder  (_SA (supervised)_), and the discrete encodings from _SysBinder_ (denoted as _SysBinder (unsupervised)_). For classification evaluations (**Q4**), we evaluate a configuration in which a set transformer classifier  is provided with NCB's concept encodings (_NCB + NN_) to make final class predictions (_cf._ Suppl. E.4). We compare this to _SA + NN_, where a supervised slot attention encoder  provides object-property predictions.

**Metrics.** We evaluate all models based on their accuracies on held-out test splits, each with 3 seeded runs. We provide average accuracies and standard deviations over these. When assessing the expressiveness of NCB's concept-slot encodings (Q1), we evaluate the accuracy for object-property

Figure 4: **Example from CLEVR-Sudoku. Each digit is represented by CLEVR objects with the same attribute combination. The objective is to solve the Sudoku only based on the initial grid of CLEVR images and the digit mapping of candidate examples.**

[MISSING_PAGE_FAIL:8]

**Easily revising NCB's concepts (Q3).** In our next evaluations, we illustrate the potential of NCB's revision procedures. Since revising the continuous latent space of NCB's soft binder is analogous to existing approaches (_e.g._, ), we focus on the novel, NCB-specific forms of _symbolic_ revision, _i.e._, revisions within the hard binder's concept space. We demonstrate two forms of symbolic revision (_removing_ and _merging_ concept information) using feedback from two sources: a pretrained vision-language model (here via GPT-4 ) and simulated human feedback. In both cases, we ask the revisory agent to identify which concepts in each block should be removed or merged based on exemplar images of each concept, _i.e._, implicit concept inspection (_cf._ Suppl. E.3 for details). In Fig. 5, we show CLEVR-Sudoku performance when NCB's retrieval corpus is updated by different revisory agents (_i.e._, _NCB revised (GPT-4)_ and _NCB revised (human)_). Interestingly, while GPT-4's revisions improve performance in settings with few examples, they have a negative impact when more digit examples are present. This is due to GPT-4's suboptimal consistency in object descriptions, leading to the removal or merging of too much concept information. This highlights the potential issue of "ill-informed" feedback (_cf._ Suppl. F.5). In contrast, human revisions provide a substantial boost in Sudoku performance, particularly in puzzle configurations with fewer candidate examples. Moreover, using NCB's similarity inspection mechanism (_cf._ Sec. 3.3), a human stakeholder can easily identify models that suffer from suboptimal soft binding processing. In such cases, these models can be excluded from further downstream evaluations (_cf. NCB revised (human)*_) and refined by finetuning \(g\)'s parameters (_e.g._, via approaches from ). In Suppl. F.6, we further explore concept revision by _adding_ new information. Overall, our results demonstrate the potential and ease of revising NCB's concept space, allowing us to answer **Q3** positively.

**Utilizing unsupervised concepts for understanding neural computations (Q4).** In our final evaluations, we investigate whether NCB's discrete concept encodings can make _subsymbolic_ compu

Figure 5: **NCB’s unsupervised concepts allow solving symbolic puzzles. Accuracy of solved Sudokus via different discrete concept encodings on Sudoku CLEVR-Easy and Sudoku CLEVR (left sides). Additional revision on NCB’s concepts leads to improved performances (right sides).**

   GT Class Rule & NN Expl. & Human Inspection &  \\   Large, gray cube & C4 \(\) H5 \(\) K5 & (Gray1) \(\) (**Red**\(\) Gray2) \(\) (Large) \(\) & “A large gray object” \\  & \(\) O13 \(\) P6 & (Gray3) \(\) (Gray4) & \\  Small, metal cube & B4 \(\) D4 \(\) H1 & (**Cube**) \(\) (Small1) \(\) (Small2) \(\) (Small3) & “A small cube” \\  & \(\) I1 \(\) K1 & \(\) (Small4) & \\  Large, blue sphere & B1 \(\) C7 \(\) H4 & (Sphere) \(\) (Blue1) \(\) (Blue2) \(\) (Small \(\) & “A blue sphere” \\  & \(\) O1 \(\) P2 & Blue3) \(\) (Blue4 \(\) Green \(\) Purple) & \\   

Table 3: **NCB’s unsupervised concept representations facilitate interpretable neural computations. Explanations of a NN classifier trained on the unsupervised concepts of NCB. Via NCB’s inherent inspection procedures a human stakeholder can identify which concepts the classifier focuses on to make its predictions and thus interpret the NN’s underlying decision rule.**tations more transparent. We focus on the task of image classification using concept-bottleneck-like approaches [68; 34] on variations of the benchmark CLEVR-Hans3 dataset . While the concept encodings in _NCB + NN_ are trained _unsupervised_, they perform on par with the supervised approach of  (_cf._ Suppl. F.7). More importantly, integrating NCB's inherently inspectable concept representations into neural computations leads to more transparent decision processes. We illustrate this in Tab. 3, where we provide class-level explanations of the classifier in _NCB + NN_ (_cf._ Suppl. E.4 for details). Using NCB's inspection mechanisms, human stakeholders can easily identify the classifier's internal decision rules for a class (_e.g._, "a large gray object"). This is a critical feature for deploying trustworthy AI models in real-world scenarios. The key result is that this transparency is achieved even with _unsupervised_ concept encodings. In Fig. 6, we further investigate whether a NCB-based neural classifier can be revised to mitigate confounders in the CLEVR-Hans3 dataset (_cf._ Suppl. E.4 and Suppl. F.8 for details). The confounding factor in the training set is the color _gray_, and we present the non-confounded test set accuracy in Fig. 6. We observe that standard loss-based feedback via explanatory interactive learning (XIL)  on the NN classifier's explanations (_+ XIL on NN_) significantly reduces the effect of the confounder. Alternatively, by simply zeroing the activations of the undesired concept _gray_ (_+ XIL on concepts_), we achieve even better confounding mitigation results without the typical issues of joint optimization. Our results highlight the potential of integrating NCB's unsupervised concept representations for eliciting transparent and trustworthy subsymbolic computations. We thus answer **Q4** affirmatively.

**Limitations.** NCB largely benefits from high-quality initial block-slot encodings. If these encodings are suboptimal, the resulting concept-slot encodings also degrade in quality. An important next step to handle more complex visual inputs, such as video data, is the integration of recent approaches (_e.g._, [16; 19]). Additionally, due to NCB's unsupervised training nature, further alignment of NCB's concepts is inevitable for effective deployment in downstream tasks . Further, to build trust in NCB's concept knowledge, human inspection is essential. Lastly, revisions are a critical aspect of NCB. However, they rely on humans to provide accurate feedback; a malicious user could manipulate NCB's concepts. Fortunately, by inspecting the concept space, it is possible to track and mitigate such manipulation effectively.

## 5 Conclusions

In this work, we introduce the Neural Concept Binder framework for learning visual object-factor concepts in an unsupervised manner. Our evaluations suggest that NCB's specific binding mechanisms facilitate the learning of expressive yet discrete concept representations. Furthermore, our results highlight the potential of integrating NCB's inherently inspectable and revisable concept-slot encodings into both symbolic _and_ neural modules. Promising directions for future research include exploring the benefits of NCB's representations in continual learning settings , high-level concept learning , and probabilistic logic programming approaches [66; 67], as well as investigating connections to object-centric causal representation learning . Lastly, incorporating downstream learning signals may be valuable (if present) for improving the quality of NCB's initial concept encodings, _e.g._, through classification [5; 6] or differentiable clustering .

#### Acknowledgments

The authors thank Gautam Singh for help with SysBinder and Cyprien Dzialo for preliminary results and insights. This work was supported by the Priority Program (SPP) 2422 in the subproject "Optimization of active surface design of high-speed progressive tools using machine and deep learning algorithms" funded by the German Research Foundation (DFG), the "ML2MT" project from the Volkswagen Stiftung and the "The Adaptive Mind" project from the Hessian Ministry of Science and Arts (HMWK). It has further benefited from the HMWK projects "The Third Wave of Artificial Intelligence - 3AI", and Hessian.AI, as well as the Hessian research priority program LOEWE within the project WhiteBox, and the EU-funded "TANGO" project (EU Horizon 2023, GA No 57100431).

Figure 6: **NCB’s unsupervised concept representations facilitate shortcut mitigation.** Test accuracy for classification via NN predictor when trained on _confounded_ images.