# Measuring Progress in Dictionary Learning

for Language Model Interpretability

with Board Game Models

 Adam Karvonen

Independent

Benjamin Wright1

MIT

Can Rager

Independent

Rico Angell

UMass, Amherst

Jannik Brinkmann

University of Mannheim

Logan Smith

Independent

Claudio Mayrink Verdun

Harvard University

David Bau

Northeastern University

&Samael Marks

Northeastern University

Equal contribution. Correspondence to: Adam Karvonen <adam.karvonen@gmail.com>.

###### Abstract

What latent features are encoded in language model (LM) representations? Recent work on training sparse autoencoders (SAEs) to disentangle interpretable features in LM representations has shown significant promise. However, evaluating the quality of these SAEs is difficult because we lack a ground-truth collection of interpretable features that we expect good SAEs to recover. We thus propose to measure progress in interpretable dictionary learning by working in the setting of LMs trained on chess and Othello transcripts. These settings carry natural collections of interpretable features--for example, "there is a knight on F3"--which we leverage into _supervised_ metrics for SAE quality. To guide progress in interpretable dictionary learning, we introduce a new SAE training technique, _\(p\)-annealing_, which improves performance on prior unsupervised metrics as well as our new metrics.2

## 1 Introduction

Mechanistic interpretability aims to reverse engineer neural networks into human-understandable components. What, however, should these components be? Recent work has applied Sparse Autoencoders (SAEs) [9; 16], a scalable unsupervised learning method inspired by sparse dictionary learning to find a disentangled representation of language model (LM) internals. However, measuring progress in training SAEs is challenging because we do not know what a gold-standard dictionary would look like, as it is difficult to anticipate which ground-truth features underlie model cognition. Prior work has either attempted to measure SAE quality in toy synthetic settings  or relied on various proxies such as sparsity, fidelity of the reconstruction, and LM-assisted autointerpretability .

In this work, we explore a setting that lies between toy synthetic data (where all ground-truth features are known; cf. Elhage et al. ) and natural language: LMs trained on board game transcripts. This setting allows us to formally specify natural categories of interpretable features, e.g., "there is a knight on e3" or "the bishop on f5 is pinned." We leverage this to introduce two novel metrics for how much of a model's knowledge an SAEs has captured:* **Board reconstruction.** Can we reconstruct the state of the game board by interpreting each feature as a classifier for some board configuration?
* **Coverage.** Out of a catalog of researcher-specified candidate features, how many of these candidate features actually appear in the SAE?

These metrics carry the limitation that they are sensitive to researcher preconceptions. Nevertheless, we show that they provide a useful new signal of SAE quality.

Additionally, we introduce \(p\)_-annealing_, a novel technique for training SAEs. When training an SAE with \(p\)-annealing, we use an \(L_{p}\)-norm-based sparsity penalty with \(p\) ranging from \(p=1\) at the beginning of training (corresponding to a convex minimization problem) to some \(p<1\) (a non-convex objective) by the end of training. We demonstrate that p-annealing improves over prior methods, giving performance on par with the more compute-intensive Gated SAEs from Rajamanoharan et al. , as measured both by prior metrics and our new metrics.

Overall, our main contributions are as follows:

1. We train and open-source over 500 SAEs trained on chess and Othello models each.
2. We introduce two new metrics for measuring the quality of SAEs.
3. We introduce \(p\)-annealing, a novel technique for training SAEs that improves on prior techniques.

## 2 Background

### Language models for Othello and chess

In this work, we make use of LMs trained to autoregressively predict transcripts of chess and Othello games. We emphasize that these transcripts only give lists of moves in a standard notation and do not directly expose the board state. Based on behavioral evidence (the high accuracy of the LMs for predicting legal moves) and prior studies of LM representations [36; 47; 33] we infer that the LMs internally model the board state, making them a good testbed setting for studying LM representations.

Othello.Othello is a two-player strategy board game played on an 8x8 grid, with players using black and white discs. Players take turns placing discs on the board, capturing their opponent's discs by bracketing them between their own, causing the captured discs to turn their color. The goal is to have more discs turned to display your color at the end of the game. The game ends if every square on the board is covered or either player cannot make a move.

In our experiments, we use an 8-layer GPT model with 8 attention heads and a \(n=512\) dimensional hidden space, as provided by Li et al. . This model had no prior knowledge of the game or its rules and was trained from scratch on 20 million game transcripts, where each token in the corpus represents a tile on which players place their discs. The game transcripts were synthetically generated by uniformly sampling from the Othello game tree. Thus, the data distribution captures valid move sequences rather than strategic depth. For this model, Li et al.  demonstrated the emergence of a world model--an internal representation of the correct board state allowing it to predict the next move--that can be extracted from the model activations using a non-linear probe. Nanda et al.  extended this finding, showing that a similar internal representation could be extracted using linear probes, supporting the linear representation hypothesis .

Chess.Othello makes a natural testbed for studying emergent internal representations since the game tree is far too large to memorize. However, the rules and state are not particularly complex. Therefore, we also consider a language model trained on chess game transcripts with identical architecture, provided by Karvonen . The model again had no prior knowledge of chess and was trained from scratch on 16 million human games from the Lichess chess game database . The input to the model is a string in the Portable Game Notation (PGN) format (e.g., "1. e4 e5 2. Nf3 \(\)"). The model predicts a legal move in 99.8 % of cases and, similar to Othello, it has an internal representation of the board state that can be extracted from the internal activations using a linear probe .

### Sparse autoencoders

Given a dataset \(\) of vectors \(^{d}\), a sparse autoencoder (SAE) is trained to produce an approximation

\[_{i}^{d_{}}f_{i}()_{i}+ \] (1)

as a sparse linear combination of _features_. Here, the _feature vectors_\(_{i}^{d}\) are unit vectors, the _feature activations_\(f_{i}() 0\) are a sparse set of coefficients, and \(^{d}\) is a bias term. Concretely, an SAE is a neural network with an encoder-decoder architecture, where the encoder maps \(\) to the vector \(=[f_{1}() f_{d_{}}()]\) of feature activations, and the decoder maps \(\) to an approximate reconstruction of \(\).

In this paper, we train SAEs on datasets consisting of activations extracted from the residual stream after the sixth layer for both the chess and Othello models. At these layers, linear probes trained with logistic regression were accurate for classifying a variety of properties of the game board [33; 47]. For training SAEs, we employ a variety of SAE architectures and training algorithms, as detailed in Section 4.

## 3 Measuring autoencoder quality for chess and Othello models

Many of the features learned by our SAEs reflect uninteresting, surface-level properties of the input, such as the presence of certain tokens. However, upon inspection, we additionally find many SAE features which seem to reflect a latent model of the board state, e.g., features that reflect the presence of certain pieces on particular squares, squares that are legal to play on, and strategy-relevant properties like the presence of a pin in chess (Figures 1 and 6).

Fortunately, in the setting of board games, we can formally specify certain classes of these interesting features, allowing us to more rigorously detect them and use them to understand our SAEs. In Section 3.1, we specify certain classes of interesting game board properties. Then, in Section 3.2, we leverage these classes into two metrics of SAE quality.

### Board state properties in chess and Othello models

We formalize a _board state property_ (BSP) to be a function \(g:\{\}\{0,1\}\). In this work, we will consider the following interpretable classes of BSPs:

* \(_{}\) contains BSPs which classify the presence of a piece at a specific board square, where the board consists of \(8 8\) squares in both games. For chess, we consider the full board for the twelve

Figure 1: We find SAE features that detect interpretable board state properties (BSP) with high precision (i.e., above 0.95). This figure illustrates three distinct chessboard states, each an example of a BSP associated with a high activation of a particular SAE feature. Left: A **board state detector** identifies a knight on square f3, owned by the player to move. Middle: A **rook threat detector** indicates an immediate threat posed by a rook to a queen regardless of location and piece threatened. Right: A **pin detector** recognizes moves that resolve a check on a diagonal by creating a pin, again, regardless of location and piece pinned.

distinct piece types (white king, white queen,..., black king), giving a total of \(8 8 12\) BSPs. For Othello, we consider the full board for the two distinct piece types (black and white), yielding \(8 8 2\) BSPs.
* \(_{}\) consists of BSPs relevant for predicting legal moves and playing strategically in chess, such as a pin detector. They were selected by the authors based on domain knowledge and prior interpretability work on the chess model AlphaZero . We provide a full list of strategy BSPs in Table 3 in the Appendix. Because our Othello model was trained to play random legal moves, we do not consider strategy BSPs for Othello.

### Measuring SAE quality with board state properties

In this section, we introduce two metrics of SAE quality: coverage and board reconstruction.

Coverage.Given a collection \(\) of BSPs, our coverage metric quantifies the extent to which an SAE has identified features that coincide with the BSPs in \(\). In more detail, suppose that \(f_{i}\) is an SAE feature and \(t\) is a threshold, we define the function

\[_{f_{i},t}()=[f_{i}()>t f_{i}^{ }]\] (2)

where \(f_{i}^{}\) is (an empirical estimate of) \(_{}f_{i}()\), the maximum value that \(f_{i}\) takes over the dataset \(\) of activations extracted from our model, and \(\) is the indicator function. We interpret \(_{f_{i},t}\) as a binary classifier; intuitively, it corresponds to binarizing the activations of \(f_{i}\) into "on" vs. "off" at some fraction \(t\) of the maximum value of \(f_{i}\) on \(\). Given some BSP \(g\), let \(F_{1}(_{f_{i},t};g)\) denote the F1-score for \(_{f_{i},t}\) classifying \(g\). Then we define the _coverage_ of an SAE with features \(\{f_{i}\}\) relative to a set of BSPs \(\) to be

\[(\{f_{i}\},):=|}_{g}_{t}_{f_{i}}F_{1}(_{f_{i},t};g).\] (3)

In other words, we take, for each \(g\), the \(F_{1}\)-score of the feature that best serves as a classifier for \(g\), and then take the mean of these maximal \(F_{1}\)-scores. An SAE receives a coverage score of \(1\) if, for each BSP \(g\), it has some feature that is a perfect classifier for \(g\). Since Cov depends on the choice of threshold \(t\), we sweep over \(t\{0,0.1,0.2,,0.9\}\) and take the best coverage score; typically this best \(t\) is in \(\{0,0.1,0.2\}\).

Board reconstruction.Again, let \(\) be a set of BSPs. Intuitively, the idea of our board reconstruction metric is that, for a sufficiently good SAE, there should be a simple, human-interpretable way to recover the state of the board from the profile of feature activations \(\{f_{i}()\}\) on an activation \(^{d}\). Here, the activation \(\) was extracted after the post-MLP residual connection in layer 6.

We will base our board reconstruction metric around the following human-interpretable way of recovering a board state from a feature activation profile; we emphasize that different ways of recovering boards from feature activations may lead to qualitatively different results. This recovery rule is based on the assumption that interpretable SAE features tend to be _high precision_ for some subset of BSPs, in line with Templeton et al. . For example, features that classify common configurations of pieces are high precision (but not necessarily high recall) for multiple BSPs. We use a consistent dataset of 1000 games as our training set \(_{}\) for identifying high-precision features across all Board State Properties (BSPs). An additional, separate set of 1000 games serves as our test set \(_{}\). Using the training set \(_{}\), we identify, for each SAE feature \(f_{i}\), all of the BSPs \(g\) for which \(_{f_{i},t}\) is a _high precision_ (of at least \(0.95\)) classifier. Then for each \(g\) our prediction rule is

\[_{g}(\{f_{i}()\})=1,&,t}( )=1$ for any $f_{i}$ which}\\ &_{}$}\\ 0,&\] (4)

Let \(F_{1}(}(\{f_{i}()\});)\) denote the \(F_{1}\)-score for a given board state \(\), where \(}(\{f_{i}()\})=\{_{g}(\{f_{i}( )\})\}_{g}\) represents the full predicted board (containing predictions for all 64 squares) obtained from the SAE activations.3Then, the average \(F_{1}\)-score over all board states in the test dataset \(_{}\) can be calculated as

\[(\{x_{i}\},_{})=_{}|}_{_{}}_{t}F_{1}(}(\{f_{i}()\});).\] (5)

## 4 Training methodologies for SAEs

In our experiments, we investigate four methods for training SAEs, as explained in this section. These are given by two autoencoder architectures and two training methodologies--one with \(p\)-annealing and one without \(p\)-annealing--for each architecture. Our SAEs are available at https://huggingface.co/adamkarvonen/chess_saes/tree/main (chess) and https://huggingface.co/adamkarvonen/othello_saes/tree/main (Othello).

### Standard SAEs

Let \(n\) be the dimension of the model's residual stream activations that are input to the autoencoder, \(m\) the autoencoder hidden dimension, and \(s\) the dataset size. Our baseline "standard" SAE architecture, as introduced in Bricken et al.  is defined by encoder weights \(W_{e}^{m n}\), decoder weights \(W_{d}^{n m}\) with columns constrained to have a \(L_{2}\)-norm of 1, and biases \(b_{e}^{m}\), \(b_{d}^{n}\). Given an input \(^{n}\), the SAE computes

\[() =(W_{e}(-_{d})+_{e})\] (6) \[} =W_{d}\,()+_{d}\] (7)

where \(()\) is the vector of feature activations, and \(}\) is the reconstruction. For a standard SAE, our baseline training method is as implemented in the open-source dictionary_learning repository , optimizing the loss

\[_{}=_{_{}}\|-}\|_{2}+\|( )\|_{1}.\] (8)

for some hyperparameter \(>0\) controlling sparsity.

### Gated SAEs

The \(L_{1}\) penalty used in the original training method encourages feature activations to be smaller than they would be for optimal reconstruction . To address this, Rajamanoharan et al.  introduced a modification to the original SAE architecture that separates the selection of dictionary elements to use in a reconstruction and estimating the coefficients of these dictionary elements. This results in the following gated architecture:

\[_{}():=W_{}(-_{d})+ _{}\] (9)

\[}():=[_{}() >0](W_{}(-_{d})+_{})\] (10)

\[(}())=W_{d}}()+ _{d}\] (11)

where \([:>0]\) is the Heaviside step function and \(\) denotes elementwise multiplication. Then, the loss function uses \(_{}\), a frozen copy of the decoder:

\[_{}:=_{_{ }} \|-(}())\|_{2}^{2}\] (12) \[+\|(_{}())\|_{1}\] \[+\|-_{}((_{}()))\|_{2}^{2}.\]

### \(p\)-Annealing

Fundamentally, an \(L_{1}\) penalty has been used to induce sparsity in SAE features because it serves as a convex relaxation of the true sparsity measure, the \(L_{0}\)-norm. The \(L_{1}\)-norm is the convex hull of the \(L_{0}\)-norm, making it a tractable alternative for promoting sparsity . However, the proxy loss function is not the same as directly optimizing for sparsity, leading to issues such as feature _shrinkage_ and potentially less sparse learned features. Unfortunately, the \(L_{0}\)-norm is non-differentiable and directly minimizing it is an NP-hard problem [48; 18], rendering it impractical for training.

In this work, we propose the use of nonconvex \(L_{p}^{p}\)-minimization, with \(p<1\), as an alternative to the standard \(L_{1}\) minimization in sparse autoencoders (SAEs). This approach has been successfully employed in compressive sensing and sparse recovery to achieve even sparser representations . To perform this optimization, we introduce a method called \(p\)_-annealing_ for training SAEs, based on the compressive sensing technique called \(p\)-continuation . The key idea is to start with convex \(L_{1}\)-minimization through setting \(p=1\) and progressively decrease the value of \(p\) during training, resulting in closer approximations of the true sparsity measure, \(L_{0}\), as \(p\) approaches \(0\). We define the sparsity penalty for each batch \(x\) as a function of the current training step \(s\):

\[_{}(,s)=_{s}\|()\|_{p_{s}}^{p_{s}}=_{s}_{i}f_{i}()^{p_{s}}\] (13)

In other words, the sparsity penalty will be a scaled \(L_{p}^{p}\) norm of the SAE feature activations, with \(p\) decreasing over time. At \(p=1\), the \(L_{p}^{p}\) norm is equal to the \(L_{1}\) norm, and as \(p 0\), the \(L_{p}^{p}\) norm limits to the \(L_{0}\)-norm, as \(_{p 0}_{i}f_{i}()^{p}=_{i}f_{i}()^{0}\).

The purpose of annealing \(p\) from \(1 0\) instead of starting from a fixed, low value for \(p\) is that the lower the \(p\), the more concave (non-convex) the \(L_{p}^{p}\) norm is, increasing the likelihood of the training process getting stuck in local optima, which we have observed in initial experiments. Therefore, we aim to first arrive at a region of an optimum using the easier-to-train \(L_{1}\) penalty and then gradually shift the loss function. This manifests as keeping \(p=1\) for a certain number of steps and then starting decreasing \(p\) linearly down to \(p_{}>0\) at the end of training. We set \(p_{}=0.2\).

Coefficient Annealing.Changing the value of \(p\) changes the scale of the \(L_{p}^{p}\) norm. Without also adapting the coefficient \(\), the strength of the sparsity penalty would vary too wildly across training. Empirically, we found that keeping a constant \(\) would lead to far too weak of a sparsity penalty for

Figure 2: Comparison of the coverage and board reconstruction metrics for chess SAE quality on \(_{}\). The coverage score reports the mean F1 scores over BSPs. The top row corresponds to coverage, and the bottom row corresponds to board reconstruction. The left column contains a scatterplot of loss recovered vs. \(L_{0}\), with the scheme color corresponding to the coverage score and each point representing different hyperparameters. We differentiate between SAE training methods with shapes.

the larger \(p\)'s at the start of training, making the process worse than simply training with a constant \(p\) from the beginning. Consequently, we aim to adapt the coefficient \(\) such that the strength of the sparsity penalty is not changed significantly due to \(p\) updates. Formally, the update step is:

\[_{s+1}_{s}^{s}_{i}f_{i}(})^{p_{s}}}{_{j=s-q+1}^{s}_{i}f_{i}(})^{p_{s+1}}}.\] (14)

We keep a queue of the most recent \(q\) batches of feature activations mid-training and use them to calibrate the \(_{s}\) updates. Therefore, the strength of the sparsity penalty is kept _locally_ constant.

Combining \(p\)-annealing with other SAEs.Since the \(p\)-annealing method only modifies the \(L_{1}\) terms in the loss function without affecting the SAE architecture, it is simple to combine \(p\)-annealing with other SAE modifications. This allows us to create the Gated-Annealed SAE method by combining the Gated SAE architecture and \(p\)-annealing. Concretely, we modify \(_{}\) (Equation 12) by replacing the sparsity term \(\|(_{}())\|_{1}\) in with \(_{s}\|(_{}())\|_{P_{s}}^{p_{s}}\). Our experiments showed that the optimum values for coefficients \(\) and \(_{s}\) differ.

## 5 Results

In this section, we explore the performance of SAEs applied to language models trained on Othello and chess. Consistent with Nanda et al. , we find that interpretable SAE features typically track properties relative to the player whose turn it is (e.g. "my king is pinned" rather than "the white king

Figure 3: Comparison of the coverage and board reconstruction metrics for chess SAE quality on \(_{}\). The metrics represent the average coverage and board reconstruction obtained across all BSPs in \(_{}\). The coverage score reports the mean of maximal F1 scores over BSPs. The absolute coverage scores vary significantly between strategy BSPs, as discussed in Appendix D. The top row corresponds to coverage, and the bottom row corresponds to board reconstruction. The left column contains a scatterplot of loss recovered vs. \(L_{0}\), with the color scheme corresponding to the coverage score and each point representing different hyperparameters. We differentiate between SAE training methods with shapes.

[MISSING_PAGE_FAIL:8]

Coverage and board reconstruction are consistent with existing metrics.Figures 2, 4, and 3 demonstrate that both coverage and board reconstruction metrics are optimal in the elbow region of the Pareto frontier. This region, where SAEs reconstruct internal activations efficiently with minimal features, also yielded the most coherent interpretations during our manual inspections. This provides precise, empirical validation to the common wisdom that SAEs in this region of the Pareto frontier are the best.

## 6 Limitations

The proposed metrics for board reconstruction and coverage provide a more objective evaluation of SAE quality than previous subjective methods. Nevertheless, these metrics exhibit several limitations. Primarily, their applicability is confined to the chess and Othello domains, raising concerns about their generalizability to other domains or different models. Additionally, the set of BSPs that underpin these metrics is determined by researchers based on their domain knowledge. This approach may not encompass all pertinent features or strategic concepts, thus potentially overlooking essential aspects of model evaluation. Developing comparable objective metrics for other domains, such as natural language processing, remains a significant challenge. Moreover, our current focus is on evaluating the quality of SAEs in terms of their ability to capture internal representations of the model. However, this does not directly address how these learned features could be utilized for downstream interpretability tasks.

Figure 4: Comparison of the coverage and board reconstruction metrics for Othello SAE quality on \(_{}\). The coverage score reports the mean of maximal F1 scores over BSPs. The top row corresponds to coverage, and the bottom row corresponds to board reconstruction. The left column contains a scatterplot of loss recovered vs. \(L_{0}\), with the color scheme corresponding to the coverage score and each point representing different hyperparameters. We differentiate between SAE training methods with shapes.

Related work

Sparse dictionary learning.Since the nineties, dictionary learning [22; 20], sparse regression , and later, sparse autoencoders  have been extensively studied in the machine learning and signal processing literature. The seminal work of Olshausen and Field  introduced the concept of sparse coding in neuroscience (see also , building upon the earlier concept of sparse representations  and matching pursuit . Subsequently, a series of works established the theoretical and algorithmic foundations of sparse dictionary learning [23; 30; 21; 1; 65; 32; 59; 2; 5; 7; 10]. Notably, Gregor and LeCun  introduced LISTA, an unrolled version of ISTA  that learns the dictionary instead of having it fixed.

In parallel, autoencoders were introduced in machine learning to automatically learn data features and perform dimensionality reduction [29; 37]. Inspired by sparse dictionary learning, sparse autoencoders [49; 14; 13; 41; 35] were proposed as an unsupervised learning model to build deep sparse hierarchical models of data, assuming a certain degree of sparsity in the hidden layer activations. Later, Luo et al.  generalized sparse autoencoders (SAEs) to convolutional SAEs. Although the theory for SAEs is less developed than that of dictionary learning with a fixed dictionary, some progress has been made in quantifying whether autoencoders can, indeed, do sparse coding, e.g., Arpit et al. , Rangamani et al. , Nguyen et al. .

Feature disentanglement using sparse autoencoders.The individual computational units of neural networks are often polysemantic, i.e., they respond to multiple seemingly unrelated inputs . Elhage et al.  investigated this phenomenon and suggested that neural networks represent features in linear superposition, which allows them to represent more features than they have dimensions. Thus, in an internal representation of dimension \(n\), a model can encode \(m n\) concepts as linear directions , such that only a sparse subset of concepts are active across all inputs - a concept deeply related to the coherence of vectors  and to frame theory in general . To identify these concepts, Sharkey et al.  used SAEs to perform dictionary learning on a one-layer transformer, identifying a large (overcomplete) basis of features. Cunningham et al.  applied SAEs to language models and demonstrated that dictionary features can be used to localize and edit model behavior. Marks et al.  proposed a scalable method to discover sparse feature circuits, as opposed to circuits consisting of polysemantic model components, and demonstrated that a human could change the generalization of a classifier by editing its feature circuit. Recently, Kissane et al.  explored autoencoders for attention layer outputs. These works have benefited from a variety of open-source libraries for training SAEs for LLM interpretability [43; 8; 15].

## 8 Conclusion

Most SAE research has relied on proxy metrics such as loss recovered and \(L_{0}\), or subjective manual evaluation of interpretability by examining top activations. However, proxy measures only serve as an estimate of interpretability, monosemantic nature, and comprehensiveness of the learned features, while manual evaluations depend on the researcher's domain knowledge and tend to be inconsistent.

Our work provides a new, more objective paradigm for evaluating the quality of an SAE methodology; coverage serves as a quantifiable measure of monosemanticity and quality of feature extraction, while board reconstruction serves as a quantifiable measure of the extent to which an SAE is exhaustively representing the information contained within the language model. Therefore, the optimal SAE methodology can be judged by whether it yields both high coverage and high board reconstruction.

Finally, we propose the \(p\)-annealing method, a modification to the SAE training paradigm that can be combined with other SAE methodologies and results in an improvement in both coverage and board reconstruction over the Standard SAE architecture.

## Author Contributions

A.K. built and maintained our infrastructure for working with board-game models. A.K., S.M., C.R., J.B., and L.S. designed the proposed metrics. B.W. performed initial experiments demonstrating the benefits of training SAEs with \(p<1\). B.W., C.M.V., and S.M. then proposed \(p\)-annealing, with B.W. leading the implementation and developing coefficient annealing. The basic framework for our dictionary learning work was built and maintained by S.M. and C.R. The training algorithms studied were implemented by S.M., C.R., B.W., R.A., and J.B. R.A. trained the SAEs used in our experiments. A.K., C.R., and J.B. selected and implemented the BSPs. A.K. and J.B. trained the linear probes. Many of the authors (including L.S., J.B., R.A.) did experiments applying traditional dictionary learning methods and exploring both toy problems and natural language settings, which helped build valuable intuition. The manuscript was primarily drafted by A.K., B.W., C.R., R.A., J.B., C.M.V., and S.M., with extensive feedback and editing from all authors. D.B. suggested the original project idea.