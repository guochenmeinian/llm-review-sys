# Semi-Supervised Sparse Gaussian Classification: Provable Benefits of Unlabeled Data

Eyar Azar

Weizmann Institute of Science

eyar.azar@weizmann.ac.il

&Boaz Nadler

Weizmann Institute of Science

boaz.nadler@weizmann.ac.il

###### Abstract

The premise of semi-supervised learning (SSL) is that combining labeled and unlabeled data yields significantly more accurate models. Despite empirical successes, the theoretical understanding of SSL is still far from complete. In this work, we study SSL for high dimensional sparse Gaussian classification. To construct an accurate classifier a key task is feature selection, detecting the few variables that separate the two classes. For this SSL setting, we analyze information theoretic lower bounds for accurate feature selection as well as computational lower bounds, assuming the low-degree likelihood hardness conjecture. Our key contribution is the identification of a regime in the problem parameters (dimension, sparsity, number of labeled and unlabeled samples) where SSL is guaranteed to be advantageous for classification. Specifically, there is a regime where it is possible to construct in polynomial time an accurate SSL classifier. However, any computationally efficient supervised or unsupervised learning schemes, that separately use only the labeled or unlabeled data would fail. Our work highlights the provable benefits of combining labeled and unlabeled data for classification and feature selection in high dimensions. We present simulations that complement our theoretical analysis.

## 1 Introduction

The presumption underlying Semi-Supervised Learning (SSL) is that more accurate predictors may be learned by leveraging both labeled and unlabeled data. Over the past 20 years, many SSL methods have been proposed and studied (Chapelle et al., 2006; Zhu & Goldberg, 2009). Indeed, on many datasets SSL yields significant improvements over supervised learning (SL) and over unsupervised learning (UL). However, there are also cases where unlabeled data does not seem to help. A fundamental theoretical issue in SSL is thus to understand under which settings can unlabeled data help to construct more accurate predictors and under which its benefit, if any, is negligible.

To address this issue, SSL was studied theoretically under various models. Several works proved that under a cluster or a manifold assumption, with sufficient unlabeled data, SSL significantly outperforms SL (Rigollet, 2007; Singh et al., 2008). In some cases, however, SSL performs similarly to UL (i.e., clustering, up to a label permutation ambiguity). In addition, Ben-David et al. (2008) described a family of distributions where SSL achieves the same error rate as SL.

In the context of the cluster assumption, a popular model for theoretical analysis is Gaussian classification, in particular binary classification for a mixture of two spherical Gaussians. In this case, the label \(Y\{ 1\}\) has probabilities \((Y=y)=_{y}\) and conditional on a label value \(y\), the vector \(^{p}\) follows a Gaussian distribution,

\[|y(_{y},_{p})\] (1)

where \(_{1},_{-1}^{p}\) are both unknown. This model and related ones were studied theoretically in supervised, unsupervised and semi-supervised settings, see for example Li et al. (2017); Tifrea et al.

(2023); Wu and Zhou (2021), and references therein. Without assuming structure on the vectors \(_{y}\) or on their difference (such as sparsity), there are computationally efficient SL and UL algorithms that achieve the corresponding minimax rates. Moreover, Tifrea et al. (2023) proved that for the model (1), no SSL algorithm simultaneously improves upon the minimax-optimal error rates of SL and UL. In simple words, there do not seem to be major benefits for SSL under the model (1).

In this paper we consider a mixture of two Gaussians in a _sparse_ high dimensional setting. Specifically, we study balanced binary classification with a sparse difference in the class means, which is a specific instance of (1). Here, the joint distribution of a labeled sample \((,y)\) is given by

\[y\{ 1\},\ \ |y(_{y},_{ p}).\] (2)

The class means \(_{1},_{-1}^{p}\) are unknown, but their difference \(=_{1}-_{-1}\) is assumed to be \(k\)-sparse, with \(k p\). In a supervised setting, model (2) is closely related to the sparse normal means problem, for which both minimax rates and computationally efficient (thresholding based) algorithms have been developed and analyzed, see e.g. Johnstone (1994, 2002). In an unsupervised setting, inference on the model (2) is closely related to clustering and learning mixtures of Gaussians (Azizyan et al., 2013; Jin and Wang, 2016). A key finding is that in an unsupervised setting with a sparsity assumption, there is a statistical-computational gap (Fan et al., 2018; Loffler et al., 2022). Specifically, from an information viewpoint a number of unlabeled samples \(n\) proportional to \(k\) suffices to accurately cluster and to detect the support of \(\). However, under under various hardness conjectures, unless \(n k^{2}\), no polynomial time algorithm is able to even detect if the data came from one or from two Gaussians (namely, distinguish between \(=\) and \(\|\|=O(1)\)).

In this work we study the model (2) in a SSL setting, given \(L\) labeled samples and \(n\) unlabeled samples, all i.i.d. from (2). Despite extensive works on the SL and UL settings for the model (2), the corresponding SSL setting has received relatively little attention so far. This gives rise to several questions: On the theoretical front, what is the information lower bound for accurate classification and for recovering the support of \(\)? On the computational side, is there a computational-statistical gap in SSL? In addition, are there values of \(L\) and \(n\) for which SSL is provably beneficial as compared to SL and UL separately?

Our Contributions.(i) We derive information theoretic lower bounds for exact support recovery in the SSL setting. As described in Section 2.2, our lower bounds characterize sets of values for the number of labeled and unlabeled samples, where any estimator based on both types of data is unable to recover the support. To derive these bounds, we view SSL as a data fusion problem involving the merging of samples that come from two measurement modalities: the labeled set and the unlabeled set. In Theorem 2.3 we present a general non-asymptotic information-theoretic result for recovering a discrete parameter in this setting. This general result is applicable to other data fusion problems and may thus be of independent interest.

(ii) We present SSL computational lower bounds. These are based on the low-degree likelihood ratio hardness conjecture (Hopkins and Steurer, 2017; Kunisky et al., 2022), in an asymptotic setting where dimension \(p\) and a suitable scaling of the sparsity \(k\), and of the number of labeled and unlabeled samples. Our main result is that there is a region of the number of labeled and unlabeled samples, whereby in a SSL setting, accurate classification and feature selection are computationally hard. Our analysis extends to the SSL case previous computational lower bounds that were derived only in UL settings. In particular, if the number of the labeled samples is too small then the statistical-computational gap still remains. To the best of our knowledge, our work is the first to extend this framework to a SSL setting.

(iii) Building upon (i) and (ii), our key contribution is the identification of a region where SSL is provably computationally advantageous for classification and feature selection. Specifically, in Section 3 we develop a polynomial time SSL algorithm, denoted LSPCA, to recover the support of \(\) and consequently construct a linear classifier. We then prove that in a suitable region for the number of labeled and unlabeled samples, LSPCA succeeds in both feature selection and accurate classification. In contrast, under the low degree ratio hardness conjecture, any computationally efficient SL or UL schemes, that use only the labeled or unlabeled data separately, would fail. In Section 4 we show via simulations the superiority of LSPCA, in both support recovery and classification error, in comparison to several SL and UL methods, a self-training SSL scheme and the SSL method of Zhao et al. (2008).

Figure 1 summarizes the picture emerging from our work in combination with previous papers that analyzed the UL and SL settings of (2), namely, the \(x\)-axis and \(y\)-axis in Figure 1. As in prior

works we consider a fixed separation \(=\|\|_{2}^{2}/4=O(1)\), where \(\) is \(k\)-sparse. The asymptotic setting is that \((k,L,n,p)\) all tend to infinity with the following scaling, which arises naturally for this problem (see Section 2): the number of labeled samples is \(L= 2k(p)/\), the number of unlabeled samples scales as \(n k^{}/^{2}\), and the sparsity scales as \(k p^{}\) for some \((0,1/2)\). The figure shows different regions in the \((,)\) plane, namely as a function of the number of unlabeled and labeled samples, where classification and feature selection are either impossible, hard or computationally easy. We say that classification is impossible if for any classifier there is a \(k\)-sparse vector \(\) whose corresponding accuracy is no better than random. Similarly, we say that feature selection is impossible if for any estimator \(\) of size \(k\) there is a \(k\)-sparse \(\) with support \(S\) such that \(| S|/k 0\) as \(p\). Feature selection is easy if it is possible to construct in polynomial time a set \(\) of size \(k\) such that \(| S|/k 1\). This implies that the corresponding classifier has an excess risk that asymptotically tends to zero. The green region \( 2\) follows from Deshpande & Montanari (2014), since in this case support estimation is computationally feasible using only the unlabeled data. The region depicted in red is where classification and support recovery are impossible. The impossibility of support recovery follows from Ingster (1997); Donoho & Jin (2004), who proved that support recovery is feasible if and only if \(>1-\). The same condition holds for classification as well, as described in the supplement. The orange and blue regions in Figure 1 follow from novel results of this paper. In the orange region, defined as \(<1-\) and \(1<<2\), our computational lower bound in Theorem 2.6 suggests that any polynomial-time scheme will not succeed in accurate classification. In the blue region, characterized by \((1-,1-)\) and \(1<<2\), our proposed polynomial time SSL method is guaranteed to construct an accurate classifier. This is proven in Theorem 3.2. In addition, note that in this regime, the availability of unlabeled data allows to decrease the number of labeled samples by a factor of \(\). Under the low degree hardness conjecture, in this blue region no computationally efficient SL or UL method that separately analyze the labeled or unlabeled samples, respectively, would succeed. We conjecture that in the remaining white region, no polynomial-time algorithm exists that is able to recover the support or able to construct an accurate classifier. In summary, our work highlights the provable computational benefits of combining labeled and unlabeled data for classification and feature selection in a high dimensional sparse setting.

NotationFor an integer \(p\), we write \([p]=\{1,...,p\}\). The cardinality of a set \(B\) is \(|B|\). For a vector \(^{p}\), we denote its restriction to a subset \(T[p]\) by \(|_{T}\). For vectors \(,\), their inner product is \(,\), and \(\|\|\) denotes the \(_{2}\) norm. We say that \(f(p)=(g(p))\) if for any \(c>0\), there exists \(p_{0} 1\) such that \(f(p)>cg(p)\) for every \(p p_{0}\).

Figure 1: Semi-supervised classification and support recovery regions. The red and green regions follow from previous works. Contributions of our work include identification of the orange and the blue regions.

Theoretical Results

In this section we present our first two contributions, namely an information-theoretic lower bound for exact support recovery of \(\), and a computational lower bound for classification and support recovery, in a SSL setting. To this end, in Section 2.1 we first review lower bounds for SL and UL settings. As we were not able to find these precise results in the literature, for completeness we present their proofs, based on Fano's inequality, in the supplementary. Our main contribution here, described in Section 2.2, is a SSL lower bound. To derive it, we view SSL as a data fusion problem with two types of data (the labeled set and the unlabeled set). The SSL lower bound then follows by a combination of the lower bounds for SL and UL.

To derive lower bounds, it suffices to consider a specific instance of (2), where the two Gaussian means are symmetric around the origin, with \(_{1}=-_{-1}=\). Hence,

\[y\{ 1\},\ \ |y(y,_{p}).\] (3)

Here, \(^{p}\) is an unknown \(k\)-sparse vector with \(_{2}\) norm of \(\). We denote its support by \(S=()=\{i|_{i} 0\}\), and by \(\) the set of all \(()\) possible \(k\)-sparse support sets.We denote by \(_{L}=\{(_{i},y_{i})\}_{i=1}^{L}\) and \(_{n}=\{_{i}\}_{i=L+1}^{L+n}\) the i.i.d. labeled and the unlabeled datasets, respectively.

To derive information and computational lower bounds for support recovery, it is necessary to impose a lower bound on \(_{i S}|_{i}|\). As in Amini & Wainwright (2009); Krauthgamer et al. (2015), it suffices to study the set of most difficult \(k\)-sparse vectors with such a lower bound on their entries. In our case this translates to the nonzero entries of \(\) belonging to \(\{\}\). Clearly, if some signal coordinates had magnitudes larger that \(\), then the problem of detecting them and constructing an accurate classifier would both be easier. Throughout our analysis, we assume \(\) is of this form and the sparsity \(k\) is known. All proofs appear in the supplementary.

### Information Lower Bounds (Supervised and Unsupervised)

The next theorem states a non-asymptotic result for exact support recovery in the SL case.

**Theorem 2.1**.: _Fix \((0,1)\). For any \((L,p,k)\) such that_

\[L<(p-k+1),\] (4)

_and for any support estimator \(\) based on \(_{L}\), it follows that \(_{S}( S)>-\)._

Donoho & Jin (2004) proved a similar result in an asymptotic regime. Specifically, they proved that for \(k=p^{}\) and \(L= p\), approximate support recovery is possible if and only if \(>1-\). Theorem 2.1 states a stronger non-asymptotic result for exact support recovery. It implies that even if \(>1-\), it is still impossible to recover the exact support with probability tending to one if \(<1\).

Next we present an information lower bound for exact support recovery in UL. Here we observe \(n\) vectors \(_{i}\) from (3) but not their labels \(y_{i}\).

**Theorem 2.2**.: _Fix \((0,1)\). For any \((n,p,k)\) with \( 0\) and_

\[n<}(p-k+1)\{1, \},\] (5)

_for any support estimator \(\) based on \(_{n}\), as \(p\), then \(_{S}( S)\)._

The scaling in Eq. (5) appeared in several prior works on related problems. Azizyan et al. (2013) showed that for \(<1\), with number of samples \(n<}(p/k)\), no clustering method can achieve accuracy better than random. Verzelen & Arias-Castro (2017) studied hypothesis testing whether the data came from a single Gaussian or from a mixture of two Gaussians. In Proposition 3 of their paper, they proved that for \(n}()\{1,\}\), any testing procedure is asymptotically powerless. Note that for \(k=p^{}\) with \(<1\), the lower bound derived in Verzelen & Arias-Castro (2017) has a similar form to (5) with a factor of \(1-\), which is slightly smaller. Thus the bound in (5) is sharper.

### Semi-Supervised Setting

In the SSL case, the observed data consists of two subsets, one with \(L\) labeled samples and the other with \(n\) unlabeled ones. We now develop information-theoretic and computational lower bounds for this setting. The information lower bound is based on the results in Section 2.1 for SL and UL settings. The computational lower bound relies on the low-degree likelihood hardness conjecture. Over the past 10 years, several authors studied statistical-computational gaps for various high dimensional problems. For the sparse Gaussian mixture (3) both Fan et al. (2018) and Loffler et al. (2022) derived such gaps in an UL setting. To the best of our knowledge, our work is amongst the first to explore computational-statistical gaps in a SSL setting. Our analysis, described below, shows that with relatively few labeled samples, the computational statistical gap continues to hold. In contrast, as we describe in Section 3, with a sufficiently large number of labeled samples, but not enough so solve the problem using only the labeled set, the computational-statistical gap is resolved. In particular, we present a polynomial time SSL algorithm that bridges this gap.

Information Lower Bounds.Before presenting results for the mixture model (3), we analyze a more general case. We study the recovery of a latent variable \(S\) that belongs to a large finite set \(\), given measurements from two different modalities. Formally, the problem is to recover \(S\) from two independent sets of samples \(\{_{i}\}_{i=1}^{N}\) and \(\{_{j}\}_{j=1}^{M}\) of the following form,

\[\{_{i}\}_{i=1}^{N} f_{x}(|S),\{_{j}\}_{j=1}^{M}  g_{z}(|S).\] (6)

Here, \(f_{x}(|S)\) and \(g_{z}(|S)\) are known probability density functions. These functions encode information on \(S\) from the two types of measurements. In our SSL setting, \(\) represents an unlabeled sample, whereas \(=(,y)\) a labeled one, and \(S\) is the unknown support of \(\).

Our goal is to derive information lower bounds for this problem. To this end, we assume that \(S\) is a random variable uniformly distributed over a finite set \(\), and denote by \(I_{x}=I(;S)\) and \(I_{z}=I(;S)\) the mutual information of \(\) with \(S\) and of \(\) with \(S\), respectively. Further, recall a classical result in information theory that to recover \(S\) from \(N\) i.i.d. samples of \(\), \(N\) must scale at least linearly with \(|}{I_{x}}\). A similar argument applies to \(\). For further details, see Scarlett & Cevher (2021). The following theorem states a general non-asymptotic information-theoretic result for recovering \(S\) from the above two sets of samples. Hence, it is applicable to other problems involving data fusion from multiple sources and may thus be of independent interest.

**Theorem 2.3**.: _Fix \((0,1)\). Let \(N,M\) be integers that satisfy \(\{N I_{x},\,M I_{z}\}<(1-)||\). Let \(N_{q}= qN\) and \(M_{q}=(1-q)M\), for \(q\). Then, any estimator \(\) based on \(\{_{i}\}_{i=1}^{N_{q}}\) and \(\{_{j}\}_{j=1}^{M_{q}}\) satisfies_

\[( S)>-|}.\]

This theorem implies that with any convex combination of samples from the two modalities, \(qN\) from the first and \((1-q)M\) from the second, accurate recovery of \(S\) is not possible if \(N\) and \(M\) are both too small. Essentially this follows from the additivity of mutual information.

Combining Theorem 2.3 with the proofs of Theorems 2.1 and 2.2 yields the following information lower bound for the semi-supervised case.

**Corollary 2.4**.: _Let \(_{L}\) and \(_{n}\) be sets of \(L\) and \(n\) i.i.d. labeled and unlabeled samples from the mixture model (3). Fix \((0,1)\). Let \((L_{0},n_{0},p,k)\), with \( 0\), be such that_

\[L_{0}<(p-k+1),\,n_{0}<}(p-k+1)\{1,\}.\]

_Suppose the number of labeled and unlabeled samples satisfy \(L= qL_{0}\) and \(n=(1-q)n_{0}\) for some \(q\). Then, for any estimator \(\) based on \(_{L}_{n}\), as \(p\)_

\[_{S}( S).\]Computational Lower Bounds.Our SSL computational lower bound is based on the low-degree framework, and its associated hardness conjecture (Hopkins and Steurer, 2017; Kunisky et al., 2022). This framework was used to derive computational lower bounds for various unsupervised high dimensional problems including sparse-PCA and sparse Gaussian mixture models (Loffler et al., 2022; Schramm and Wein, 2022; Ding et al., 2023). To the best of our knowledge, our work is the first to adapt this framework to a SSL setting.

For our paper to be self-contained, we first briefly describe this framework and its hardness conjecture. We then present its adaptation to our SSL setting. The low degree likelihood framework focuses on unsupervised _detection_ problems, specifically the ability to distinguish between two distributions \(\) and \(\), given \(n\) i.i.d. samples. Specifically, denote the null distribution of \(n\) samples by \(_{n}\), whereby all \(_{i}\), and denote by \(_{n}\) the alternative distribution, with all \(_{i}\).

Under the low-degree framework, one analyzes how well can the distributions \(_{n}\) and \(_{n}\) be distinguished by a low-degree multivariate polynomial \(f:^{p n}\). The idea is to construct a polynomial \(f\) which attains large values for data from \(_{n}\) and small values for data from \(_{n}\). Specifically, the following metric plays a key role in this framework,

\[\|_{n}^{ D}\|:=_{(f) D}_{X _{n}}[f(X)]}{_{X_{n}} [f(X)]}},\] (7)

where the maximum is over polynomials \(f\) of degree at most \(D\). The value \(\|_{n}^{ D}\|\) characterizes how well degree-\(D\) polynomials can distinguish \(_{n}\) from \(_{n}\). If \(\|_{n}^{ D}\|=O(1)\), then \(_{n}\) and \(_{n}\) cannot be distinguished via a degree-\(D\) polynomial. Computational hardness results that use the low-degree framework are based on the following conjecture, which we here state informally, and refer the reader to Loffler et al. (2022) for its precise statement.

_Conjecture 2.5_ (Informal).: Let \(_{n}\) and \(_{n}\) be two distinct distributions. Suppose that there exists \(D=((pn))\) for which \(\|_{n}^{ D}\|\) remains bounded as \(p\). Then, there is no polynomial-time test \(T:^{p n}\{0,1\}\) that satisfies

\[_{X_{n}}[T(X)]+_{X _{n}}[1-T(X)]=o(1).\]

In simple words, Conjecture 2.5 states that if \(\|_{n}^{ D}\|=O(1)\) as \(p\), then it is not possible to distinguish between \(_{n}\) and \(_{n}\) using a polynomial-time algorithm, as no test has both a low false alarm as well as a low mis-detection rate (the two terms in the equation above).

We now show how to extend this framework, focused on unsupervised detection, to our SSL setting. To this end, consider \(L+n\) samples, distributed according to either a null distribution \(_{L+n}\) or an alternative distribution \(_{L+n}\). In our case, the null distribution is

\[_{L+n}:_{i}=_{i}(0,_{p }),\ i[L+n],\] (8)

whereas the alternative belongs to the following set of distributions,

\[_{L+n}:_{i}=^{S}+_{i}, i [L],\\ _{i}=y_{i}^{S}+_{i},\ L<i L+n.\] (9)

Here, \(S\) is uniformly distributed over \(\), \(^{S}(j)=}\{j S\}\), and \(y_{i}\) are unobserved Rademacher random variables.

The next theorem presents a low-degree bound for our SSL testing problem. The scalings of \(L,n\) and \(k\) with \(p\) and \(\) are motivated by those appearing in Theorems 2.1 and 2.2.

**Theorem 2.6**.: _Let \(k= c_{1}^{},L=(p-k)\), \(n= c_{2}}{^{2}}\) and \(D=( p)^{2}\), for some \(,,,c_{1},c_{2}_{+}\) and \((0,)\). With the null and alternative distributions defined in (8) and (9), if \(<-\) and \(<2\), then as \(p\)_

\[\|_{L+n}^{ D}\|^{2}=O(1).\]

Theorem 2.6 together with the hardness conjecture 2.5 extends to the SSL case previous computational lower bounds that were derived only in UL settings (\(=0\)) (Fan et al., 2018; Loffler et al., 2022). Next, we make several remarks regarding the theorem.

**SSL statistical-computational gap.** In the rectangular region \(<-\) and \(1<<2\), depicted in orange in Figure 1, under the hardness conjecture 2.5, distinguishing between \(\) and \(\) is computationally hard. Since testing is easier than variable selection and classification (Verzelen & Arias-Castro, 2017; Fan et al., 2018), in this region these tasks are computationally hard as well.

**Tightness of condition \(<2\) in Theorem 2.6.** This condition is sharp, since for \( 2\), namely \(n}{^{2}}\), the support can be recovered by a polynomial-time algorithm, such as thresholding the covariance matrix followed by PCA, see Deshpande & Montanari (2014) and Krauthgamer et al. (2015).

**Tightness of condition \(<-\).** This condition is tight for detection, though not necessarily for feature selection or classification. The reason is that for \(>-\), it is possible to distinguish between \(\) and \(\), using only the labeled data (Ingster, 1997; Donoho & Jin, 2004).

Combining Theorems 2.1-2.6 leaves a rectangular region \(1<<2\) and \(-<<1-\) where SSL support recovery is feasible from an information view, but we do not know if it possible in a computationally efficient manner. In the next section we present a polynomial time SSL method that in part of this rectangle, depicted in blue in Figure 1, is guaranteed to recover \(S\) and construct an accurate classifier. We conclude with the following conjecture regarding the remaining white region:

_Conjecture 2.7_.: Let \(_{L},_{n}\) be sets of \(L\) and \(n\) i.i.d. labeled and unlabeled samples from the model (3). Assume, as in Theorem 2.6 that \(k p^{},L=(p-k)\) and \(n}{^{2}}\). Then in the white region depicted in Figure 1, no polynomial-time algorithm is able to recover the support \(S\) or to construct an accurate classifier.

## 3 Semi-Supervised Learning Scheme

We present a SSL scheme, denoted LSPCA, for the model (2), that is simple and has polynomial runtime. In subsection 3.2 we prove that in the blue region of Figure 1 it recovers the support, and thus constructs an accurate classifier. In this region, under the hardness conjecture 2.5, computationally efficient algorithms that rely solely on either labeled or unlabeled data would fail.

Preliminaries.To motivate the derivation of LSPCA, we first briefly review some properties of the sparse model (2). First, note that the covariance matrix of \(\) is \(_{x}=^{}+_{p}\). This is a rank-one spiked covariance model, whose leading eigenvector is \(\), up to a \(\) sign. Hence, with enough unlabeled data, \(\) can be estimated by vanilla PCA on the sample covariance or by some sparse-PCA procedure taking advantage of the sparsity of \(\). Unfortunately, in high dimensions with a limited number of samples, these procedures may output quite inaccurate estimates, see for example Nadler (2008); Birnbaum et al. (2013). The main idea of our approach is to run these procedures after an initial variable screening step that uses the labeled data to reduce the dimension.

### The LSPCA Scheme

Our SSL scheme, denoted LSPCA, stands for Label Screening PCA. As described in Algorithm 1, LSPCA has two input parameters: the sparsity \(k\) and a variable screening factor \(<1\). The scheme consists of two main steps: (i) removal of noise variables using the labeled samples; (ii) support estimation from the remaining variables using the unlabeled samples via PCA. Finally, a linear classifier is constructed via the leading eigenvector of the covariance matrix on the estimated support.

The first stage screens variables using only the labeled samples. While our setting is different, this stage is similar in spirit to Sure Independence Screening (SIS), which was developed for high-dimensional regression (Fan & Lv, 2008). To this end, our scheme first constructs the vector,

\[_{L}=}_{i:y_{i}=1}_{i}-}_{i:y_ {i}=-1}_{i},\] (10)

where \(L_{+}=|\{i[L]:y_{i}=1\}|\) and \(L_{-}=L-L_{+}\). With a balanced mixture \((Y= 1)=\), it follows that \(_{L}+}N(,_{p})\). Hence, \(_{L}\) can be viewed as a noisy estimate of \(\). If the number of labeled samples were large enough, then the top \(k\) coordinates of \(_{L}\) would coincide with the support of \(\). With few labeled samples, while not necessarily the top-\(k\), the entries of \(_{L}\) atthe support indices still have relative large magnitudes. Given the input parameter \(>0\), the scheme retains the indices that correspond to the largest \(p^{1-}\) entries in absolute value of \(_{L}\). We denote this set by \(S_{L}\). Note that for any \(>0\), this step significantly reduces the dimension (as \(>0\) then \(p^{1-} p\)). In addition, as analyzed theoretically in the next section, for some parameter regimes, this step retains in \(S_{L}\) (nearly all of) the \(k\) support indices. These two properties are essential for the success of the second stage, which we now describe.

The second step estimates the support \(S\) using the unlabeled data. Specifically, LSPCA constructs the sample covariance matrix restricted to the set \(S_{L}\),

\[|_{S_{L}}=_{i=L+1}^{n+L}(_{i}- })|_{S_{L}}(_{i}-})|_{S_{L}}^{},\] (11)

where \(}=_{i=L+1}^{n+L}_{i}\) is the empirical mean of the unlabeled data. Next, it computes the leading eigenvector \(}_{}\) of \(|_{S_{L}}\). The output support set \(\) consists of the \(k\) indices of \(}_{}\) with largest magnitude. Finally, the vector \(\) is (up to scaling) estimated by the leading eigenvector of \(\) restricted to \(\), with its sign determined by the labeled data.

_Remark 3.1_.: After the removal of variables in the first step, the input dimension to the second step is much lower, \(=p^{1-}\). Despite this reduction in dimension, as long as the vector \(\) is sufficiently sparse with \(k\), or equivalently \(<1-\), then in the second step our goal is still to find a sparse eigenvector. Hence, instead of vanilla PCA, we may replace the second step by any suitable (polynomial time) sparse-PCA procedure. We refer to this approach as LS\({}^{2}\)PCA (Labeled Screening Sparse-PCA). As illustrated in the simulations, for finite sample sizes, this can lead to improved support recovery and lower classification errors.

### Support Recovery and Classification Guarantees for LSPCA

Before presenting our main result, we first recall two standard evaluation metrics. The classification error of a classifier \(C:^{p}\{ 1\}\) is defined as \((C)=(C() y)\). Its excess risk is defined as

\[(C)=(C)-^{*}=(C)- _{C^{}}(C^{}).\] (12)

As in Verzelen & Arias-Castro (2017), the accuracy of a support estimate \(\) is defined by its normalized overlap with the true support, namely \(| S|/k\). To simplify the analysis, we focus on the symmetric setting where \(_{1}=-_{-1}=\). The next theorem presents theoretical guarantees for LSPCA, in terms of support recovery and the excess risk of the corresponding classifier.

**Theorem 3.2**.: _Let \(_{L},_{n}\) be labeled and unlabeled sets of \(L\) and \(n\) i.i.d. samples from (3) with a \(k\)-sparse \(\) whose non-zero entries are \(\). Suppose that \(k= c_{1}p^{},L=(p-k) ,n= c_{2}}{^{2}}\), for some fixed \(0<<1/2,0<<1-,>1\) and \(,c_{1},c_{2}_{+}\). Let \(,}\) be the output of Algorithm 1 with input \(k\) and screening factor \(\). If \(>1-\) and \((1-,)\), then_

\[_{p}(|}{k} 1- )=1,>0,\] (13)_and the excess risk of the corresponding classifier \(C()=}},\), satisfies_

\[_{p}(C)=0.\] (14)

The interesting region where Theorem 3.2 provides a non-trivial recovery guarantee is the triangle depicted in blue in Figure 1. Indeed, in this region, LSPCA recovers the support and constructs an accurate classifier. In contrast, any SL algorithm would fail, and under the low degree hardness conjecture, any computationally efficient UL scheme would fail as well. To the best of our knowledge, our work is the first to rigorously prove the computational benefits of SSL, in bridging the computational-statistical gap in high dimensions. As mentioned above, we conjecture that in the remaining white region in Figure 1, it is not possible to construct in polynomial time an accurate SSL classifier. The intuition underlying this conjecture is based on the work of Donoho & Jin (2004), where in the fully supervised (SL) setting, the authors show that there is a detection-recovery gap. Namely for a range of number of labeled samples, it is possible to detect that a sparse signal is present, but it is not possible to reliably recover its support. Intuitively, adding a few unlabeled samples should not resolve this gap.

## 4 Simulation Results

We illustrate via several simulations some of our theoretical findings. Specifically, we compare LSPCA and LS2PCA to various SL, UL and SSL schemes, in terms of both accuracy of support recovery and classification error. The sparse PCA method used in LS2PCA was iteratively proxy update (IPU) (Tian et al., 2020). We generate \(L+n\) labeled and unlabeled samples according to the model (3) with a \(k\)-sparse \(\) whose non-zero entries are \(\). The quality of a support estimate \(\) is measured by its normalized accuracy \(| S|/k\). For all methods compared we assume the sparsity \(k\) is known. Hence, each method outputs a \(k-\)sparse unit norm vector \(}}\), so its corresponding linear classifier is \(},\). Given the model (3), its generalization error is \(^{c}(},)\). We run our SSL schemes with \(=-(-(1-))/4\) which satisfies the requirements of Theorem 3.2. We present experiments with \(p=10^{5},k=p^{0.4}=100\) and \(=3\), though the behavior is similar for other settings as well. The error of the Bayes classifier is \(^{c}() 0.042\). We report the average (with \( 1\) standard deviation) of the support recovery accuracy and the classification error over \(M=50\) random realizations. All experiments were run on a Intel i7 CPU 2.10 GHz.

We empirically evaluate the benefit of \(L=200\) labeled samples in addition to \(n\) unlabeled ones. We compare our SSL schemes LSPCA and LS2PCA to the following UL methods, taking all \(L+n\) samples as unlabeled: ASPCA (Birnbaum et al., 2013), and IPU (Tian et al., 2020). The SSL methods that we compare are LSDF (Zhao et al., 2008), and self-training (self-train). The self-training algorithm is similar to the approach in Oymak & Gulcu (2021), but explicitly accounts for the known sparsity \(k\): (i) compute \(_{L}\) of (10) using the labeled samples, and keep its \(k\) largest entries, denote the result by \(_{L}^{(k)}\); (ii) compute the dot products \(c_{i}=_{L}^{(k)},_{i}\) and the pseudo labels \(_{i}=(c_{i})\); (iii) let \(n_{}\) be the cardinality of the set \(\{i:|c_{i}|>\}\), for some threshold value \( 0\); (iv) estimate the support by the top-\(k\) coordinates in absolute value of the following vector:

\[_{}=}}(_{i=1}^{L}y_{i}_{i}+_{i=L+1}^{L+n}\{|c_{i}|>\}_{i}_{i})\]

In the experiments we used \(=0.8\), which gave the best performance. Also, we implemented the SL scheme Top-K Labeled that selects the indices of the top-\(k\) entries of \(|_{L}|\) of (10). As shown in the supplementary, this is the maximum-likelihood estimator for \(S\) based on the labeled data.

Figure 2 illustrates our key theoretical result - that in certain cases SSL can yield accurate classification and feature selection where SL and UL simultaneously fail. The left panel of Figure 2 shows the average accuracies of support estimation for the different schemes as a function of number of unlabeled samples \(n\). Except at small values of \(n\), LS2PCA achieved the best accuracy out of all methods compared. The right panel shows the classification errors of the different methods. The black horizontal line is the error of the Bayes optimal (Oracle) classifier. As seen in the figure, our SSL schemes come close to the Bayes error while SL and UL schemes have much higher errors.

We present further experiments that empirically illustrate the benefit of using a fixed number of \(n=1000\) unlabeled samples while varying the number of labeled samples \(L\). Specifically, we compare our SSL algorithms LSPCA and LS\({}^{2}\)PCA to the SSL methods self-train and LSDF, as well as to the SL scheme Top-K Labeled, which uses only the \(L\) labeled samples. Figure 3 illustrates the support recovery accuracies and the classification error as a function of the number of labeled samples \(L\). As seen in the figure, adding \(n=1000\) unlabeled samples significantly improves the classification and support recovery accuracies.

## 5 Summary and Discussion

In this work, we analyzed classification of a mixture of two Gaussians in a sparse high dimensional setting. Our analysis highlighted provable computational benefits of SSL. Two notable limitations of our work are that we studied a mixture of only two components, both of which are spherical Gaussians. It is thus of interest to extend our analysis to more components and to other distributions.

From a broader perspective, many SSL methods for feature selection have been proposed and shown empirically to be beneficial, see for example the review by (Sheikhpour et al., 2017). An interesting open problem is to theoretically prove their benefits, over purely SL or UL. In particular it would be interesting to find cases where SSL improves over both SL and UL in its error rates, not only computationally.

Figure 3: Empirical simulation results. (Left) Support recovery, (Right) Classification error.

Figure 2: Empirical simulation results. (Left) Support recovery, (Right) Classification error.