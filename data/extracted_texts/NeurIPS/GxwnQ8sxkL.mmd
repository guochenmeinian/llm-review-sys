# Learning from Snapshots of Discrete and Continuous Data Streams

Pramith Devulapalli

Department of Computer Science

Purdue University

pdevulap@purdue.edu

&Steve Hanneke

Department of Computer Science

Purdue University

steve.hanneke@gmail.com

###### Abstract

Imagine a smart camera trap selectively clicking pictures to understand animal movement patterns within a particular habitat. These "snapshots", or pieces of data captured from a data stream at adaptively chosen times, provide a glimpse of different animal movements unfolding through time. Learning a continuous-time process through snapshots, such as smart camera traps, is a central theme governing a wide array of online learning situations. In this paper, we adopt a learning-theoretic perspective in understanding the fundamental nature of learning different classes of functions from both discrete data streams and continuous data streams. In our first framework, the _update-and-deploy_ setting, a learning algorithm discretely queries from a process to update a predictor designed to make predictions given as input the data stream. We construct a uniform sampling algorithm that can learn with bounded error any concept class with finite Littlestone dimension. Our second framework, known as the _blind-prediction_ setting, consists of a learning algorithm generating predictions independently of observing the process, only engaging with the process when it chooses to make queries. Interestingly, we show a stark contrast in learnability where non-trivial concept classes are unlearnable. However, we show that adaptive learning algorithms are necessary to learn sets of time-dependent and data-dependent functions, called pattern classes, in either framework. Finally, we develop a theory of pattern classes under discrete data streams for the blind-prediction setting.

## 1 Introduction

### Two Motivating Examples

Pretend you're a farmer by day and businessperson by night. As a farmer, you oversee a 10,000 arc plot of land equipped with a smart irrigation system. To feed data to your irrigation system, you rely on hyperspectral imaging taken from a satellite to gauge soil moisture conditions. Ideally, you would like to constantly feed your irrigation system with hyperspectral data; however, the steep financial cost of processing hyperspectral data prevents you from doing so. As a result, you need to devise a strategy to sparingly use satellite data; at all other times, you rely on the smart irrigation system to accurately extrapolate the soil moisture conditions as time passes by.

At night, you become a businessperson. You employ a translator on your work laptop during your virtual meetings to automatically convert your voice into the preferred language of your client. This translator is fine-tuned by a speech-to-text translation system that takes in voice data and updates the translator's model on the correct language translation. But, there's a caveat. Each request costs money. And each transmission dominates a sizable portion of the available Internet bandwidth. Your task is to come up with the optimal strategy of balancing requests to the cloud versus trusting the fidelity of the translator.

### A New Learning Paradigm

While these settings may seem rather creative in nature, both of these scenarios represent plausible real-world instances of learning from continuous data streams with temporal dependencies. What type of learning-theoretic framework should one construct when framing the question of online learning under continuous data streams? How can we best capture the notion of temporal dependencies and patterns that naturally arise when analyzing such data sources? While these questions are highly pertinent, the answers aren't clear due to a vast majority of the learning theory literature focusing on online learnability from discrete data streams modeled as round-by-round processes. In the two examples showcased at the beginning, it's clear that establishing a theoretical understanding of these settings can be an important step in tackling online learnability under continuous data streams.

In our paper, we present a streamlined approach in tackling these rather fundamental challenges by first establishing two closely related, but separate, frameworks.

Blind-Prediction SettingThe first framework is called _blind-prediction_ which is highlighted by the smart irrigation system using satellite imagery data. The irrigation system receives feedback only when hyperspectral data is requested; at all other times, the system must predict on its own with no input from the environment. This framework is designed such that a learning algorithm must make a prediction based only on the current timestamp and previous queries. The learner's predictions are independent of the current values generated by the data stream hence the name _blind-prediction_.

Update-and-Deploy SettingThe second framework, called _update-and-deploy_, is highlighted by the speech-to-text translation system. The speech-to-text translation system, a learning algorithm, and the translator, called the predictor, are considered as two separate entities where the algorithm retrieves snapshots of the data stream to update the predictor. We describe this behavior as a learning algorithm activating different modes at different times. A learning algorithm performs _updates_ to a predictor when it queries and _deploys_ the predictor to make predictions as the process rolls by.

Pattern ClassesA significant portion of this work is dedicated to studying these frameworks under _pattern classes_, sets of sequences encoding data-dependent and time-dependent characteristics. First introduced by Moran et al. , these classes consist of a set of patterns; each pattern is a sequence of instance-label pairs marked with the appropriate timestamp. For example, if we let \(\) and \(\) represent the instance space and label space respectively, then \(Z^{}=()^{}\) represents the set of all countably infinite patterns. A discrete pattern class \(\) is defined as \( Z^{}\) where any \(P\) is understood as \(P=(Z_{t})_{t=1}^{}=(X_{t},Y_{t})_{t=1}^{}\).

Pattern classes can also be viewed as natural generalizations of concept classes. Given a concept class \(H\) consisting of classifiers mapping instances from \(\) to labels in \(\), we can derive a pattern class that encapsulates all sequences that could be realized by any single \(h H\). Formally speaking, the induced pattern class \((H)\) is defined as \((H)=\{(Z_{t})_{t=1}^{} Z^{}: h H, t ,h(X_{t})=Y_{t}\}\)

Now that the stage has been developed for pattern classes, we turn to a set of questions that naturally arise under continuous data streams. What pattern classes are online learnable? Is there a natural dimension that characterizes online learnability of pattern classes under the different querying-based models? How does learning pattern classes and concept classes differ under continuous data streams? We tackle these important questions in our paper using our learning frameworks.

### Our Contributions

We detail the primary contributions of this work below.

1. **Non-Adaptive Learners in the Update-and-Deploy Setting.** First, we extend the current theory on concept classes to include online learning under continuous data streams for the update-and-deploy setting. A non-adaptive learner is a learning algorithm that queries independent of the process itself. For the _update-and-deploy_ setting, we show that the non-adaptive learner, \(_{}\), that uniformly samples its queries from a fixed uniform distribution, achieves a bounded expected error with a linear querying strategy.
2. **Theorem 1.1** (Informal Version).: _Given an instance space \(\) and a label space \(\), let \(H^{}\) be a concept class where \(LD(H)\) represents the Littlestone dimension of \(H\). Forany \(H\) that has \(LD(H)<\), \(_{}\) achieves an expected error bound \(MB_{(H)}(_{}) LD(H)\) with a linear querying strategy \(Q_{_{}}(t)=O(t)\) where \(\) is an input parameter._
2. **Concept Class Learnability in the Blind-Prediction Setting.** Second, we show that non-trivial concept classes aren't learnable within the blind-prediction setting. Letting \(H\) be any concept class that contains a classifier that labels two points differently, then any learning algorithm, adaptive or non-adaptive, is not learnable in the blind-prediction setting. **Theorem 1.2** (Informal Version).: _For any \(H\) and two points \(x_{1},x_{2}\) such that \( h H\) where \(h(x_{1}) h(x_{2})\), then for any learning algorithm \(\), the expected mistake-bound \(MB_{(H)}()=\)._
3. **Adaptive Learners for Pattern Classes.** As our third result, we investigate what types of learning algorithms are required to learn pattern classes under continuous data streams. In Section 4.3, we design a continuous pattern class \(\), where each pattern \(P\) is a continuous sequence of point-label pairs \((X_{t},Y_{t})_{t 0}\), that is not learnable by any random sampling algorithm such as \(_{}\). Additionally, we construct an adaptive learning algorithm that successfully learns \(\) with zero expected error. This important example signifies a learnability gap between concept classes and pattern classes.
4. **Discrete Data Streams.** Fourth, we develop a theory for realizable learning of pattern classes under discrete data streams in the blind-prediction setting for deterministic learning algorithms. We characterize a combinatorial quantity called the _query-learning distance_ or \(QLD\) for discrete pattern classes \(\) with a query budget \(Q\{0\}\). We show that the optimal mistake-bound given \(Q\) queries, \(M_{Q}()\), is lower bounded by \(QLD(,Q)\). Then, we construct a deterministic learning algorithm whose optimal mistake-bound is upper bounded by \(QLD(,Q)\). **Theorem 1.3** (Informal Version).: _For a discrete pattern class \(\) and number of queries \(Q\), the optimal mistake-bound \(M_{Q}()=QLD(,Q)\)._

### Related Work

An extensively studied area in online learning theory closely related to our work is the round-by-round learning of concept classes from discrete data streams in the realizable setting. Littestone  successfully characterized the types of concept classes \(H\) that are learnable under an adversarial online setting which is now famously known as the Littestone dimension or \(LD(H)\). Later, Daniely et al.  extended this result to the multi-class setting, showing that \(LD(H)\) also characterizes multi-class learnability. A recently explored setting called self-directed online learning shares an important trait with our learning frameworks which is adaptivity in selecting points where Devulapalli and Hanneke  constructed a dimension, \(SDdim(H)\), characterizing learnable concept classes.

While traditional approaches assume that the learner receives the true label after each round, our study diverges by focusing on frameworks where feedback is only provided when actively queried by the learner. Our work is conceptually aligned with the area of partial monitoring, which investigates how various feedback constraints influence a learner's ability to minimize regret. A series of studies have established optimal regret bounds across different online learning scenarios, structured as discrete data streams with diverse feedback mechanisms [5; 6; 7; 8; 9; 10; 11].

A core principle within our learning frameworks is the ability of a learning algorithm to selectively query at different time-steps within a data-stream which is shared by stream-based active learning approaches. Several works within the field have explored theoretical guarantees of active learning in different variations of the stream-based setting [12; 13; 14; 15]. However, a crucial difference between stream-based active learning and learning models in this work is the decision to query at a particular time is carried out before the current instance is observed.

## 2 Learning Frameworks

### Basic Definitions

Let \(\) and \(\) be arbitrary, non-empty sets where \(\) is referred to as the instance space and \(\) is the label space. A concept class \(H^{}\) consists of functions \(f:\). Depending on the context,we will specify if we are considering a multi-class setting where \(|| 2\) or a binary classification setting where \(=\{0,1\}\).

To define a continuous data stream, we use the notation \((Z_{t})_{t 0}=(X_{t},Y_{t})_{t 0}\) to define a point and label pair \(Z_{t}=(X_{t},Y_{t})\) for each \(t_{ 0}\). A continuous pattern class \(\) is defined as \(((X_{t},Y_{t})_{t 0})\) where \(((X_{t},Y_{t})_{t 0})\) represents the collection of all measurable continuous-time processes on the space \(\). Each pattern \(P\) is then a continuous-time process \((Z_{t})_{t 0}\).

We now proceed to define discrete pattern classes and subsequently, discrete data streams. Let \(=\) where \(z\) and \(z=(x,y)\). Define \(Z^{}=()^{}\) which is the set of all countably infinite patterns. Then the discrete pattern class \( Z^{}\). Both continuous and discrete pattern classes are referred to as \(\) so it will be clear from context which type of pattern class we are referring to. It then follows that a discrete data stream \((Z_{t})_{t=1}^{}=(X_{t},Y_{t})_{t=1}^{}\) lives in the space \(^{}\).

### Update-and-Deploy Setting

In this learning framework, we aim to describe the online learning game that occurs between a learner and an oblivious adversary. An oblivious adversary is an adversary impervious to any of the learner's actions; in other words, the adversary does not adapt its strategy based on the learner's actions. As a result, the oblivious adversary fixes the entire data stream in advance of the learning process.

Denote by \(\) a class of predictor functions \(\). With \(\) representing the timestamps of the data stream, either discrete or continuous, then \(:\) is designed to make a prediction at every timestamp \(t\). In the update-and-deploy setting, we consider the learning algorithm \(\) and the predictor \(\) to be separate entities. Denote by \(Q_{}(t)=\{(X_{t_{1}},Y_{t_{1}}),(X_{t_{2}},Y_{t_{2}}),...\}\) the set of queries made by learning algorithm \(\) before time \(t\). Intuitively, a learning algorithm is a mapping \(:()^{*}\) where \(()^{*}\) corresponds to the set \(Q_{}(t)\). Formally, \(((X_{t_{1}},Y_{t_{1}}),...,(X_{Q_{}(t)},Y_{Q_{}(t)}))\) outputs a predictor \(\) given the history of previous queries \(Q_{}(t)\). It's important to note that we only consider learning algorithms \(\) that have a linear querying strategy or \(Q_{}(t)=O(t)\).

Assume the adversary has selected a data stream \((Z_{t})_{t D}\). For each \(t D\), the predictor \(\) produces predictions \(_{t}=(X_{t},t)\) given \(X_{t}\) and \(t\). On timestamps \(t\) that the learning algorithm \(\) decides to query, the following procedure occurs:

1. The learner \(\) makes a decision to query and receives the true point-label pair \((X_{t},Y_{t})\).
2. \(\) updates the predictor \(\) with \((X_{t},Y_{t})\).
3. \(\) is redeployed as the new predictor.

It's important to note that the data stream selected by the adversary is constrained to be realizable. If the realizability is with respect to a concept class \(H\), then \( h H, t D,h(X_{t})=Y_{t}\). If the setting is studied under a discrete pattern class \(\), then the pattern is considered realizable if \((X_{t},Y_{t})_{t 1}^{}\). If \(\) represents a continuous data stream and \(\) a continuous pattern class, then the pattern \((X_{t},Y_{t})_{t 0}\) implies realizability.

### Blind-Prediction Setting

For our second learning framework, we describe the online learning game between the learner and an oblivious adversary. As similarly described in Section 2.2. an oblivious adversary acts independently of the learner's actions and fixes the entire data stream beforehand.

Let \(\) be any learning algorithm and let \(Q_{}(t)\) be the set of queries made by a learning algorithm \(\) before time \(t\). As mentioned in Section 2.2, we consider algorithms with a linear querying strategy where \(Q_{}(t)=O(t)\). Letting \(\) be the timestamps of the data stream, \(\) is described as a mapping \(:()^{*} \) where \(()^{*}\) corresponds to the set \(Q_{}(t)\). At any time \(t\), \(\) only observes the current timestamp \(t\) and the history of queries \(Q_{}(t)\) when making a prediction \(_{t}\). If it decides to query, then \(\) witnesses the true instance-label pair \((X_{t},Y_{t})\).

Assume that the adversary has selected a data stream \((Z_{t})_{t D}\). For each \(t\):

1. The learner \(\) selects a prediction \(_{t}\).

2. If the learner decided to query, then the pair \((X_{t},Y_{t})\) is revealed to the learner.

It's important to note that the data stream selected by the adversary is constrained to be realizable. Refer to Section 2.2 for realizability regarding concept classes and pattern classes.

### Integral Mistake-Bounds

To capture the optimal behavior of learning algorithms under continuous data streams, we formalize the notion of integral mistake-bounds. Since we consider two separate settings, we construct a general mistake-bound and then differentiate from context which setting the mistake-bound operates under.

Due to their nature, pattern classes subsume concept classes so we define all the mistake-bounds with respect to pattern classes. Let \(=_{ 0}\) which denotes the timestamps of a continuous stream. The pattern class representation of a concept class \(H\), or \((H)\), is defined in the following way: \((H)=\{(X_{t},Y_{t})_{t 0}: h H, t ,h(X_{t})=Y_{t}\}\). It is important to note that we assume that each pattern \(P\) for any continuous pattern class \(\) is measurable.

Given a continuous pattern class \(\), a learning algorithm \(\), and some realizable continuous data stream \((Z_{t})_{t 0}\), the quantity \(MB_{}(,(Z_{t})_{t 0})\) represents the expected error \(\) makes on the data stream \((Z_{t})_{t 0}\) given \(\). Formally,

\[MB_{}(,(Z_{t})_{t 0})=_{T} [_{0}^{T}[(X_{t}) Y_{t}]\,dt].\]

To define the optimal mistake-bound for \(\), we take the supremum over all patterns in the class:

\[MB_{}()=_{(Z_{t})_{t 0}=P}MB_{ }(,(Z_{t})_{t 0}).\]

Finally, we obtain the optimal mistake-bound for the pattern class \(\) by taking the infimum over all learning algorithms corresponding to the learning setting (blind-prediction or update-and-deploy):

\[MB_{}=_{}MB_{}().\]

## 3 Update-and-Deploy Setting: Learning Concept Classes from Continuous Data Streams

### Littlestone Classes are Learnable

In this section, we are interested in multi-class concept classes \(H\) that are learnable in the update-and-deploy setting with learning algorithms deploying a linear querying strategy. Below, we give a definition of the learnability of a concept class \(H\) which allows us to frame our first important question.

**Definition 3.1**.: _A concept class \(H\) is learnable if the following condition is satisfied: there exists an algorithm \(\) such that \(MB_{(H)}()<\) and \(Q_{}(t)=O(t)\)._

**Question:**: What is the dimension that characterizes the learnability of a concept class \(H\) where finiteness implies learnability and an infinite value implies non-learnability?

Once we have defined learnability of a concept class \(H\), our interest immediately swings towards the performance of different learning algorithms with linear querying strategies. Naturally, we want to understand if there exists optimal learning algorithms whose expected error is finite if the concept class \(H\) is learnable. This then leads us to our second important question.

**Question:**: Does there exist a learning algorithm \(\) employing a linear querying strategy such that for every \(H\) that is learnable, does \(MB_{(H)}()<\)? If so, does the learning algorithm employ an adaptive strategy?

The Littlestone dimension  is a key measure that defines the learnability across various online learning frameworks. Extending this concept, we investigate whether the Littlestone dimension can similarly influence learnability in the context of continuous data streams. We propose that \(LD(H)\)could be a valuable combinatorial tool for designing learning algorithms in the continuous setting. To explore this, we introduce Algorithm 1, or \(_{}\), which is designed to learn any concept class with a finite Littlestone dimension, \(LD(H)<\), by using a linear querying approach.

The idea behind \(_{}\) is to randomize the timestamp of the query so that the adversary has to "guess" which point in the data stream the learner will decide to target. If the timestamp of the query is not randomized, then the adversary can select a data stream designed with this knowledge. A potential strategy an adversary could employ against a deterministic learning algorithm would be to present the same point again and again to the learner for every query. Since the learner has only received information about one point, the adversary can present other points in the data stream at times the learner doesn't query forcing errors to occur. As a result, the adversary has a strategy to force an infinite mistake-bound to a learning algorithm that employs a deterministic querying strategy regardless if it's adaptive or non-adaptive.

To avoid this issue, we fitted \(_{}\) with a randomized querying strategy. As shown in Algorithm 1, \(_{}\) samples the next timestamp of the query, \(t_{q}\), from a uniform distribution over an interval of fixed width \(\).

```
0:\(H\)
0:\(>0\)
1:\(V=H,t=\) time, starts at \(t=0\), \(t_{q}[t,t+]\)
2: Deploy \((x_{t},t)=_{r\{0,1\}}LD(V_{(x_{t},r)})\)
3:while\(\)do
4:if\(t=t_{q}\)then
5: Query at time \(t_{q}\) and receive point-label pair \((x_{t_{q}},y_{t_{q}})\)
6: Update \(V=V_{(x_{t_{q}},y_{t_{q}})}\)
7: Redeploy \((x_{t},t)=_{r\{0,1\}}LD(V_{(x_{t},r)})\)
8:\(t_{q}[t,t+]\)
9:endif
10:endwhile ```

**Algorithm 1** Uniform Sampler(\(H,\))

In Algorithm 1, notice that the predictor function \(\) follows that of the Standard Optimal Algorithm, or SOA, defined by Littlestone . Since the \(LD(H)<\), and if the prediction differs from the true label on a query point, then the Littlestone dimension of the subsequent version space is reduced by at least \(1\). This property follows immediately from the analysis of the SOA, so the learner knows that it needs only \(LD(H)\) successful queries to fully learn \(H\) from the continuous data stream.

Additionally, note that while Algorithm 1 decides the next \(t_{q}\) after the previous query finishes, this is done non-adaptively. The timestamp \(t_{q}\) is not dependent on the true label witnessed by the previous queries; it's simply sampled from a uniform distribution. As a result, the set of query timestamps are produced in a non-adaptive fashion by sampling the next query from an interval of width \(\).

**Theorem 3.2**.: _Let \(_{}\) be Algorithm 1. For any \(H\) that has \(LD(H)<\), \(MB_{(H)}(_{}) LD(H)\) where \(\) is an input parameter from Algorithm 1. Since \(Q_{_{}}(t)=O(t)\), then \(H\) is learnable._

Proof.: For a given \(H\) with \(LD(H)<\), we show that the expected mistake-bound of algorithm \(_{}\) is bounded proportionally to the size of \(LD(H)\) using a linear querying strategy. Since \(_{}\) deploys the SOA as its predictor, then the mistake-bound of \(_{}\) is inherently tied to \(LD(H)\). In other words, if \(_{}\) makes \(LD(H)\) successful queries, where success implies that the SOA's prediction is incorrect on the query point, then the version space has Littlestone dimension of \(0\) implying that any consistent classifier subsequently makes zero error onwards. Our analysis first focuses on bounding the maximum expected error \(_{}\) makes until its first successful query. We repeat this analysis \(LD(H)-1\) times to show that \(MB_{(H)}(_{}) LD(H)\) with a linear querying strategy.

As a starting point, we define all the necessary quantities in order to begin the analysis. Since our learning model assumes an oblivious adversary, it selects a continuous data stream \((Z_{t})_{t 0}\) realizable with respect to some target concept \(f^{*} H\) before the learning process begins. Let the random variable \(B_{k}\) be an indicator random variable representing the success of the \(k^{th}\) query on the process \((Z_{t})_{t 0}\). More specifically,

\[B_{k}=1&$ query is successful}\\ 0&\]

takes a value of \(1\) if the \(k^{th}\) query succeeds. Then, we define \(P(B_{k}=1|B_{k-1}=0,B_{k-2}=0,...,B_{1}=0)=_{k}\) which is the probability that the learner has a successful query on the \(k^{th}\) try given that the previous \(k-1\) attempts failed. \(_{k}\) can be equivalently viewed as the probability of the learner making an error on the \(k^{th}\) interval because a successful query results in receiving a mistake-point, or a point the predictor incorrectly predicts. Since \(_{}\) selects its \(k^{th}\) query \(t_{q}^{k}\) from a \(\)-sized interval, then \(_{k}\) represents the total potential error the learner makes on the \(k^{th}\) interval.

Our primary interest is calculating the expected error \(_{}\) makes until it reaches \(LD(H)\) successful queries. Since the learner \(_{}\) deploys an SOA predictor, \(LD(H)\) successful queries where the predictor is incorrect guarantees the learner to narrow down on the right set of consistent classifiers.

We approach this by first computing the expected error that the learning algorithm makes until its first successful query. It's important to note that \(_{}\) does not alter its querying strategy regardless of the number of successful queries it has received; it constantly chooses its queries from intervals of size \(\). As a result, after the learner receives its first successful query, the same process repeats again until \(_{}\) finds it second successful query. So, we focus on bounding the maximum expected error \(_{}\) will encounter until its next successful query for the data stream \((Z_{t})_{t 0}\).

Let \(A\) be a function that represents the maximum error the learner receives until its first successful query given the values of the random variables \(B_{1},B_{2},...\) Formally speaking, let \(A=A(B_{1},B_{2},...)=(_{1}+_{2}(1-B_{1})+_{3}(1- B_{1})(1-B_{2})+)=_{k=1}^{}_{k}_{i=1}^{k-1}(1-B_ {i})\). Each \(_{k}\) represents the error region in the \(k^{th}\) interval given that the previous \(k-1\) queries failed or each \(B_{i}=0\) for all \(i k-1\). It's important to observe that \(A\) is the maximum error the learner receives until the first successful query. As an example, let \(B_{n}=1\) for some \(n\) and \(B_{j}=0\) for all \(j<n\). Then \(A\) includes the cumulative error from the first \(n-1\) intervals and the entire potential error on the \(n^{th}\) interval (represented as \(_{n}\)) even though the \(n^{th}\) query, which is successful, can lie anywhere within the \(_{n}\) error region located inside the \(n^{th}\) interval. Now, we compute the expectation of \(A\).

\[[A] =[_{i=1}^{}_{k}_{i=1}^{ k-1}(1-B_{i})]=_{k=1}^{}_{k}[_{i=1}^ {k-1}(1-B_{i})]\] \[=_{k=1}^{}_{k}P(B_{1}=0,...,B_{k-1}=0)= _{k=1}^{}_{k}_{i=1}^{k-1}(1-_{i})\]

Since we are interested in the maximum expected error the learner \(_{}\) encounters until its first successful query, we want to bound the term \(_{k=1}^{}(k)_{i=1}^{k-1}(1-_{i})\) by selecting the optimal values for \(_{1},_{2},...\) Notice that the expression is recursive in the sense that if we pulled out the first \(k\) terms, the structure of the sum doesn't change. We then exploit this fact to bound the total value of the sum. Let \(U^{*}=_{^{}}_{k=1}^{}(k)_{i=1}^{k-1}(1-(i))\) where \((1)=_{1},(2)=_{2}\), and so on and so forth. Then,

\[U^{*} =_{^{}}_{k=1}^{} (k)_{i=1}^{k-1}(1-(i))=_{[ 0,1]^{}}(1)+(1-(1))_{k=2}^{ }(k)_{i=2}^{k-1}(1-(i))\] \[_{p} p+(1-p)(_{[ 0,1]^{}}_{k=1}^{}(k)_{i=1}^{k-1}(1- {}(i)))_{p} p+(1-p)U^{*}\] \[_{p}=.\]

Therefore, we show that \(E[A]\).

At the beginning of this analysis, we assumed some adversarially chosen data stream and target concept, so the result \(E[A]\) holds for any choice of \((Z_{t})_{t 0}\) realizable with respect to \(H\)Now, we repeat this analysis \(LD(H)-1\) times. Therefore, \(MB_{(H)}(_{}) LD(H)\) where \(Q_{_{}}(t)=O(t)\). 

In Theorem 3.2, we establish that if \(LD(H)\) is finite, then \(H\) is learnable in the update-and-deploy setting. This leads to our second result, which demonstrates that \(LD(H)\) serves as the defining dimension for the learnability of a concept class \(H\) in this context.

**Theorem 3.3**.: _If \(LD(H)=\), then for any learning algorithm \(\) with a linear querying strategy \(Q_{}(t)\), \(MB_{(H)}()=\) implying that \(H\) is not learnable._

For the formal proof of Theorem 3.3, refer to Appendix A.1. While the results hold for \(O(t)\) querying strategies, an open direction is to investigate algorithms with a broader range of querying strategies.

## 4 Blind-Prediction Setting: Learning from Discrete and Continuous Data Streams

### It's Impossible to Learn Non-Trivial Concept Classes from Continuous Data Streams

In this section, we discover what constitutes learnability of multi-class concept classes in the blind-prediction setting. We borrow Definition 3.1 to describe the learnability of a concept class \(H\).

Since the blind-prediction setting is a harder variant of the update-and-deploy setting, we frame a similar question asking if the Littlestone dimension is the right characterization of learnability.

**Question:** What characterizes the learnability of concept classes \(H\) in the blind-prediction setting? Does \(LD(H)\) play a pertinent role?

To answer this question, we come up with a simple concept class \(H\) that proves to be unlearnable in the blind-prediction setting. This result comes in stark contrast to the results found in Section 3.1. Below, we detail Theorem 4.1 and Corollary 4.2.

**Theorem 4.1**.: _Let \(H=\{h\}\) and \(=\{x_{1},x_{2}\}\) with \(h(x_{1})=0\) and \(h(x_{2})=1\). Then, for any learning algorithm \(\) with a linear querying strategy, \(MB_{(H)}()=\) so \(H\) is not learnable under the blind-prediction setting._

For the formal proof of Theorem 4.1, refer to Appendix A.2.

**Corollary 4.2**.: _If \(H\) is a concept class such that \( h H\) and \( x_{1},x_{2}\) such that \(h(x_{1}) h(x_{2})\), then \(H\) is unlearnable in the blind-prediction setting._

Proof.: Let \(H^{}=h\) and \(^{}=\{x_{1},x_{2}\}\). From Theorem 4.1, it was shown that \(MB_{(H^{})}()=\) for any learning algorithm \(\) with a linear querying strategy so \(H^{}\) is unlearnable. Since \(H^{} H\) and \(x_{1},x_{2}\), it follows that \(MB_{(H)}=\) so \(H\) is unlearnable. 

### Are Adaptive Learners Required for Pattern Classes?

In this section, we demonstrate the necessity of adaptive learning algorithms for effectively learning pattern classes. Since concept classes represent a set of functions, and functions can be thought as established input-output pairs, different permutations of these pairs don't result in different functions being realizable on the sequence. As a result, non-adaptive learning algorithms are sufficient in learning concept classes but adaptive learning strategies may be required for pattern classes. Below, we construct an example of a continuous pattern class \(\) that is only learnable by any adaptive sampling algorithm.

Pattern Class ExampleLet \(H\) be a multi-class concept class with \(LD(H)=\). For \(t_{1},t_{2}\) with \(t_{2}>t_{1}\), define \(}(H,t_{1},t_{2})=\{(X_{t},Y_{t})_{t(t_{1},t_{2})}: h  H, t(t_{1},t_{2}),h(X_{t})=Y_{t}\}\). Then, \((H,t_{1},t_{2})=\{(X_{t},Y_{t})_{t[t_{1},t_{2})}: P (H,t_{1},t_{2})\ \ (X_{t_{1}},Y_{t_{1}})=(P,t_{2})\ \ (X_{t},Y_{t})_{t(t_{1},t_{2})}=P\}\). \(}(H,t_{1},t_{2})\) corresponds to the set of realizable data streams between \(t_{1}\) and \(t_{2}\) and \(}(H,t_{1},t_{2})\) ensures that at time \(t_{1}\) the data stream encodes the entire pattern from \(t_{1}\) to \(t_{2}\) in \(X_{t_{1}}\). Let \(=\{\{0\}^{}: i,(i+1)>(i)\}\) and \(=\{\{0\}_{>0}^{}: , i,(i)<(i+1)<(i+1)\}\). Then, we define the continuous pattern class \(\) in the following way: \(=_{}(_{i=1}^{} (H,(i),(i+1)))\) where \(_{i=1}^{}(H,(i),(i+1))\) represents an infinite Cartesian product among the valid patterns in each interval dictated by \(\).

**Lemma 4.3**.: _For the update-and-deploy setting, any random sampling algorithm \(\) with a linear querying strategy \(Q_{}(t)\) has \(MB_{}()=\)._

Proof.: Let \(\) be a random sampling algorithm with a linear querying strategy \(Q_{}(t)\). We will now construct a continuous data stream \((Z_{t})_{t 0}\) that is realizable with respect to \(\) in a randomized fashion and prove a bound on the minimum expected error. Randomly select a vector \(\).

To construct such a continuous process \((Z_{t})_{t 0}\), we first decompose \(_{ 0}=_{n=1}^{}[2(n),2(n+1))\). The idea behind this decomposition is to construct a pattern on each interval that corresponds to a randomly chosen \(h H\). To do this, we take each interval \([2(n),2(n+1))\), letting \(_{}(2(n+1))=k\) for some \(k\), and break it further down such that \([2(n),2(n+1))=_{j=1}^{2k}[(n+1) -(n))}{k}(j-1)+2(n),(n+1)-(n)) }{k}j+2(n)]\). By doing this, we can take an arbitrary root-to-leaf path from a Littestone tree of depth \(2k\), and then paint each sub-interval with an instance-label pair on this path. Since the number of sub-intervals is greater than the number of queries made by the algorithm \(\), on some set of sub-intervals the algorithm \(\) is forced to guess the true label.

As described above, assume the interval \([2(n),2(n+1))\) for some \(n\), letting \(_{}(2(n+1))=k\) for some \(k\). Since \(LD(H)=\), there must exist a Littlestone tree \(T\) where the minimum root-to-leaf depth is at least \(2k\). Then, let \(=\{(X_{1},Y_{1}),...,(X_{2k},Y_{2k})\}\) correspond to a randomly chosen root-to-leaf path. For each \(j\{1,...,2k\}\), populate the interval \([(n+1)-(n))}{k}(j-1)+2(n),(n+1)-(n))}{k}j+2(n))\) with the pair \((X_{j},Y_{j})\). For simplicity, let \(I_{j}=[(n+1)-(n))}{k}(j-1)+2(n), (n+1)-(n))}{k}j+2(n))\). For the process at time \(t=2(n)\), let \(Z_{t}=(P,2(n+1))\) where \(P=(X_{1},Y_{1})_{t I_{1} 2(n)}_{j=2}^{2k}[X_{j},Y_{j})_{t  I_{j}}\).

It's important to note that the constructed continuous process on the interval \([2(n),2(n+1))\) lies in \((H,2(n),2(n+1))\). The first point in the interval corresponds to the point \((P,2(n+1))\) and \(P(H,2(n),2(n+1))\) since it was generated from a root-to-leaf path in \(T\) which is realizable by some \(h H\).

Now, we show that on the sub-intervals \(\) does not query in the interval \([2(n),2(n+1))\), \(\), the minimum expected error is equal to \((n+1)-(n))}{k}\). The analysis closely mirrors that of in Theorem 3.3. Let the \(j^{th}\) sub-interval be a sub-interval, where \(1 j 2k\), where \(\) does not query. Let \(E_{1}=\{t I_{j}:(X_{t}) Y_{j}\}\) and \(E_{0}=\{t I_{j}:(X_{t}) Y_{j}^{}\}\) where \(Y_{j}^{}\) is the other label in tree \(T\) for the point \(X_{j}\). Then, \([_{I_{j}}[(X_{t}) Y_{t}]\,dt ]=[(E_{1})[Y_{t}=Y_{j}]+(E_{0})[Y_{t}=Y_{j}^{}]]=[(E_{1})][1[Y_{t}=Y_{j }]]+[(E_{0})][1[Y_{t}=Y_{j}^{}]]\) where \(\) is the Lebesgue measure. Since a random branch was chosen within the tree \(T\), there was an equal chance of selecting \(Y_{t}=Y_{j}\) or \(Y_{t}=Y_{j}^{}\), then \([(E_{1})][1[Y_{t}=Y_{j}]]+[(E_{0})][1[Y_{t}=Y_{j}^{}]]=[(E_{0})]/2+[(E_{1})]/2= [(E_{0})+(E_{1})]/2(n+1)-(n))}{k}\). Therefore, the learner \(\) accumulates an expected error of \((n+1)-(n))}{k}\) on each interval it doesn't query. Since the learner has only \(k\) queries, it can only query in at most \(k\) of the \(2k\) intervals. At minimum there will exist \(k\) intervals that haven't been queried by the learner. Let \(I_{1},...,I_{k}\) represent \(k\) of these intervals algorithm \(\) does not query. It follows that \([_{2(n)}^{2(n+1)}[(X _{t}) Y_{t}]\,dt]_{i=1}^{k}[_{I_{i}} [(X_{t}) Y_{t}]\,dt]=(n+1)-(n)\).

Since \(n\) was chosen arbitrarily, then it holds for all intervals \([2(n),2(n+1))\). As a result,

\[_{T}[_{0}^{T}[ (X_{t}) Y_{t}]\,dt] _{T}_{i=1}^{\{n N:T 2(n+1) \}}[_{2(i)}^{2(i+1)}[ (X_{t}) Y_{t}]\,dt]\] \[=_{T}_{i=1}^{\{n N:T 2(n+1)\}} (i+1)-(i)=.\]Since we constructed the process \((Z_{t})_{t 0}\) by randomly selecting branches from Littlestone trees for each interval, we appeal to the probabilistic method to show that there exists a fixed choice of a continuous-process \((Z_{t})_{t 0}\) such that \(MB_{}(,(Z_{t})_{t 0})=\). Therefore, \(MB_{}()=\). 

**Remark 4.4**.: _It can be shown that the results of Lemma 4.3 directly extend for the blind-prediction setting._

Now, we turn to an adaptive sampling learning algorithm, specifically Algorithm 2, that achieves \(MB_{}(2)=0\). Specifically, we show this result in the blind-prediction setting. As will be proven in the analysis of Lemma 4.5, Algorithm 2 specifically queries at the timestamps where a portion of the future continuous data stream is revealed. As a result, Algorithm 2 makes at most a countable number of mistakes because only a countable number of such points exist in any continuous data stream realizable by \(\) so it has an expected error of \(0\) with a linear querying strategy.

```
1:\(t=\) time {starts at \(t=0\)}, \(t_{q}=0\), initialize \(\) to be some function \(:_{ 0}\)
2:while\(\)do
3: Predict \((t)\)
4:if\(t=t_{q}\)then
5: Query and receive point-label pair \((X_{t},Y_{t})=(P,n)\)
6: Update \((t)=Y_{t}\) for all \((X_{t},Y_{t}) P\)
7:\(t_{q} n\)
8:endif
9:endwhile ```

**Algorithm 2** Adaptive Sampler(\(\))

**Lemma 4.5**.: _Let \(\) be the adaptive sampler in Algorithm 2. Then, the querying strategy \(Q_{}(t) t\) and \(MB_{}()=0\) in the blind-prediction setting._

Proof (Sketch).: Let \(\) represent Algorithm 2 and \((Z_{t})_{t 0}=P\) be any adversarially chosen data stream. Since each \(\) has \((1)=0\), then for any \(P\), it must be the case that \(Z_{0}=(X_{0},Y_{0})\) where \(X_{0}\) reveals the full sequence until time \(Y_{0}\). Algorithm 2 has its first query at time \(t=0\) and fits the predictor \(\) to output the labels of sequence \(X_{0}\) for all time \(t(0,Y_{0})\). Since \((Z_{t})_{t>0}\) follows the exact sequence described by \(X_{0}\) until time \(t=Y_{0}\), then \(_{0}^{Y_{0}}[(X_{t}) Y_{t}]\,dt=0\) implying that \([_{0}^{Y_{0}}[(X_{t}) Y_{t}]\,dt]=0\). At time \(t=Y_{0}\), \(\) queries at exactly the right time to gain information about a future portion of the data stream \((Z_{t})_{t 0}\) with the same analysis repeating continuously. As a result, \(MB_{}(,(Z_{t})_{t 0})=0\) and since \((Z_{t})_{t 0}\) was arbitrarily chosen, then \(MB_{}()=0\) with \(Q_{}(t) t\). 

**Remark 4.6**.: _The results of Lemma 4.5 can also be extended to the update-and-deploy setting._

### Learning Pattern Classes from Discrete Data Streams

As witnessed in the example from Section 4.2, one can construct a rather complex pattern class to model almost any sort of structure. While the power of pattern classes is inherent in their ability to express complicated relationships, directly analyzing their behavior under continuous data streams without a foundational understanding can prove to be an intractable problem.

As a result, we initiate a study of pattern classes under discrete data streams to provides a foundational understanding of how learning algorithms handle data arriving in distinct, separate chunks. This framework simplifies the complexity by allowing us to focus on key principles of sequential decision-making such as incremental learning. By developing a theory in a discrete context, we can potentially employ these insights that can prove to be crucial for tackling the more complex scenarios of learning under continuous data streams. In Appendix B, we develop a complete theory on realizable learning of pattern classes in the blind-prediction setting under discrete streams.