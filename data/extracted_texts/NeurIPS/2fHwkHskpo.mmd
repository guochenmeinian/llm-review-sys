# Bayesian Optimization of High-dimensional Outputs

with Human Feedback

 Qing Feng

Meta

San Francisco, CA

qingfeng@meta.com

&Zhiyuan Jerry Lin

Meta

USA

zylin@meta.com

&Yujia Zhang

Cubist Systematic Strategies

USA

yz685@cornell.edu

Benjamin Letham

Meta

USA

bletham@meta.com

&Jelena Markovic-Voronov

Meta

USA

jmarkovic@meta.com

&Ryan-Rhys Griffiths

FutureHouse

USA

ryanrhys@meta.com

&Peter I. Frazier

Cornell University

Ithaca, NY

pf98@cornell.edu

&Eytan Bakshy

Meta

USA

ebakshy@meta.com

###### Abstract

We consider optimizing the inputs to a black-box function that produces high-dimensional outputs such as natural language, images, or robot trajectories. A human decision maker (DM) has a utility function over these outputs. We may learn about the DM's utility by presenting a small set of outputs and asking which one they prefer. We may learn about the black-box function by evaluating it at adaptively chosen inputs. Given a limited number of such learning opportunities, our goal is to find the input to the black box that maximizes the DM's utility for the output generated. Previously proposed methods for this and related tasks either do not scale to high dimensional outputs or are statistically inefficient because they ignore information in the outputs. Our proposed approach overcomes these challenges using Bayesian optimization and a novel embedding of high-dimensional outputs into a low-dimensional latent space customized for this task. This embedding is designed to both minimize error when reconstructing high-dimensional outputs and support accurate prediction of human judgments. We demonstrate that this approach significantly improves over baseline methods.

## 1 Introduction

Bayesian optimization (bo) is an efficient method for black-box optimization with applications across machine learning, materials science, engineering, chemistry, and A/B testing. In new grey-box Bayesian optimization approaches, "opening the black box" by modeling intermediate outputs arising during objective function evaluation improves objective function prediction and optimization performance when solving challenging black-box optimization problems [2; 3]. For example, when designing a new material, its properties may depend on the precursors used to synthesize the material and parameters describing the synthesis [25; 57; 19]. In physical simulations, including telecommunications, optical design, and fluid dynamics, directly modeling a simulator's spatiotemporal outputs can dramatically improve performance . In personalized policy optimization for internetapplications, overall experience quality can be decomposed into parameters that primarily affect certain subgroups, and their corresponding outputs .

This work aims to open the black box for _Bayesian optimization with human feedback (BOHF)_--a new class of problems where a human decision-maker (DM) judges an object's quality based on its attributes \(^{k}\) according to an unknown utility function \(g()\), and the object's attributes \(=f()\) depend on the inputs \(^{d}\) used to construct the object through an unknown and time-consuming-to-evaluate black-box function \(f:\). In BOHF, we can interrogate \(f\) by evaluating it at \(\) of our choice and we can interrogate \(g\) by asking the DM which of two attribute vectors \(\), \(^{}\) they prefer, giving a signal on whether \(g(f())>g(f(^{}))\) or vice versa. The \(,^{}\) presented can either be equal to \(f()\) at previously-evaluated \(\) or, if the application allows it, constructed _de novo_. We refer to these ways of learning about \(f\) and \(g\) as "experiments" and "queries" respectively. Understanding that DM time is valuable and \(f\) is slow to evaluate, we wish to efficiently allocate a limited number of experiments and queries to solve:

\[^{*}*{arg\,max}_{}g(f( )).\] (1)

For example, an engineer configuring cell phone towers may choose a tower configuration \(\) and use a time-consuming simulation to compute the resulting pattern of signal power over space \(=f()\). The engineer judges the quality of this pattern using their latent utility function \(g()\). To help the engineer find the cell phone tower configuration with the highest utility, a BOHF algorithm can run the simulation to model the mapping from tower configurations \(\) to signal power patterns \(=f()\), and can query the engineer's preferences \(g()\) by asking which they prefer among pairs of signal power patterns. Later, we will illustrate our method using this example in Fig 1.

BOHF includes two previously-considered problems as special cases: (1) BO with preference exploration (BOPE)  assumes that \(f()\) is evaluated only when it will be used within a query to the DM while BOHF allows evaluating \(f()\) solely to learn about \(f\). The additional flexibility offered by BOHF is important when DM time is more limited than evaluation of \(f\). Additionally, as we explain below, past BOPE methods are limited to low-dimensional \(\). (2) In preferential Bayesian optimization (PBO) , an algorithm iteratively chooses sets of \(\) to evaluate. For each set, attribute vectors \(f()\) are evaluated for each \(\) in the set and the DM is asked which attribute vector they prefer. While it is computed, the algorithm does not use the information in \(f()\).

Past success in grey-box Bayesian optimization suggests it _should_ be possible to use observations of \(f()\) (e.g., the signal power pattern) to improve our model of the DM's utility beyond what is possible using the inputs alone (the tower configurations that generated the signal pattern). This however, poses a substantial challenge: the intermediate output \(f()\) is often high-dimensional, especially for complex objects like images, text, or movies. Such complex objects are common in PBO applications. As a result, PBO has ignored the intermediate output, effectively treating the composition \(g f\) in (1) as one black-box function. While BOPE models intermediate outputs, computational limits have

Figure 1: The framework of HDP-GP used for BOHF. Inputs \(\) are evaluated by the black-box function \(f\), producing high-dimensional outputs \(\) (e.g., images). The outputs \(\) are embedded into a lower-dimensional embedding \(\), producing a representation \(()\). The human decision maker evaluates pairs of the intermediate outputs and reveals a preference. These elicited preferences are used to jointly learn the embedding and a utility function over the latent space \(\) (posterior for utility function shown at right). Utility optimization is then performed in the latent space.

driven past work to focus on applications where \(f()\) is low-dimensional: typically 10 dimensions or fewer. While applying a standard dimensionality-reduction method to \(f()\) might seem appealing, the resulting low-dimensional representation will ignore preference feedback and thus risks losing key information needed to accurately predict \(g(f())\). The low-dimensional representation of \(f\) needs to capture the aspects of \(f\) that influence \(g\) and are most germane to the DM's choice.

Here, we develop the high-dimensional preferential Gaussian process (HDP-GP) model, which uses human feedback to jointly learn a low-dimensional representation of \(f\) and a utility model \(g\). This joint learning and a tailored architecture for embedding \(f\) ensure that the representation stays aligned with the DM's utility, in contrast to simply minimizing reconstruction error of \(f\). This avoids losing information needed to represent the DM's utility at the expense of structure that is only needed for reconstruction. For example, when recording a movie of a robot performing a task, the background may be needed for accurate reconstruction while fine details of how the robot grasps an object may be orders of magnitude more important for the DM's utility.

Fig 1 illustrates HDP-GP for BOHF using data and a real embedding from the Cell Tower problem (Sec 3). The DM is given a pair of images and identifies the better of the two, according to the coverage uniformity and interference patterns. In HDP-GP, these image outputs and DM feedback jointly train an embedding into a latent low-dimensional space. We summarize our contributions as:

1. Motivated by real-world decision making processes, we formulate Bayesian optimization with _human_ feedback as a grey-box optimization problem with respect to high-dimensional outputs.
2. We propose HDP-GP, a novel model architecture for efficiently modeling latent preferences over high-dimensional outputs whose loss function is tailored toward representing features of the output space relevant to the DM's utility function.
3. We demonstrate empirically that HDP-GP achieves substantially better optimization performance for PBO and BOPE tasks in high-dimensional settings.

## 2 Framework for BO with Human Feedback over High-dimensional Outputs

The HDP-GP is a framework for BO with human feedback about high-dimensional objects. It leverages and aligns high-dimensional outputs with the DM's utilities and can be applied to both PBO and BOPE setups. See App A for details on PBO and BOPE and App B for related work.

HDP-GP consists of: (1) an embedding layer that maps high-dimensional outputs \(\) to a low-dimensional latent space \(\); (2) a latent output model that maps from input space \(\) to \(\); (3) a utility model that maps from the latent space \(\) to the DM's utility; (4) human feedback that is used to jointly train both of those components, end-to-end, which facilitates output dimensionality reduction through the embedding layer, with supervision from the utility function. Specifically, binary comparisons \(\{(^{}_{j},^{}_{j},r(^{ }_{j},^{}_{j}))\}_{j=1}^{n}\) are considered here, where \((^{}_{j},^{}_{j})\) is the pair presented to the DM and \(r(^{}_{j},^{}_{j})\{0,1\}\) indicates the output that the DM prefers.

Embedding layerAt the core of the HDP-GP is a transformation, denoted \(:^{k}^{p}\), from the output space to a low-dimensional latent output space \(=(Y)\). This transformation serves the crucial role of distilling effective information for modeling utility. This \(\) is a versatile transformation encompassing a spectrum of dimensionality reduction methods. The decoder \(:^{p}^{k}\) maps points back to the original high-dimensional space. The reconstruction error is the \(L_{2}\) loss, \(\|Y-((Y))\|_{2}^{2}\). We leverage autoencoders (AEs)  due to their flexibility and extensibility, making them adept at handling complex structured outputs, such as images, graphs, and sequences.

Latent output and Utility modelWe utilize a multi-output \((_{0}^{z},K_{0}^{z})\) on the latent output space \(\). We fit the latent output model on the encoded dataset \(\{(_{i},_{i})\}_{i=1}^{n}\), yielding a posterior mean function \(_{n}^{z}\) and posterior covariance function \(K_{n}^{z}\). For computational tractability, we model all \(p\) latent outputs independently so that the fitting cost is linear in \(p\). The utility model on the embedding \(\) is then a gp with a probit likelihood for the DM's response distribution. We compute an approximate gp posterior with mean \(_{m}^{g}\) and covariance function \(K_{m}^{g}\) using the Laplace approximation . The primary advantage of HDP-GP lies in its focused learning of the output subspace relevant to the utility function. For instance, when a DM selects between two robot trajectories, only a specific segment of the route may influence the decision; thus, modeling the entire output space would not yield significant utility-related information. Moreover, the scalability of latent outputs makes HDP-GP more adept at handling high-dimensional outputs compared to the potential scalability issues encountered by the mogp as the output dimension increases.

Joint End-to-End TrainingWe perform joint end-to-end training for the AE, latent output model, and utility model. This ensures that the representation of the outputs remains aligned with the target task: the learning of the decision maker's utilities with respect to the high-dimensional outputs. The training procedure alternates between refining the latent output model, and updating the AE and utility model. Detailed training workflow is outlined in Algorithm 1.

## 3 Experiments

We evaluate HDP-GP's performance in both PBO and BOPE settings compared to the state-of-the-art BOHF methods  that do not take advantage of the compositional structure of high-dimensional attributes \(\) ("Non-compositional BO").

In PBO settings, we evaluate 80 design points using 16 quasi-random initial points and 32 pairwise comparisons. Non-compositional BO in PBO settings is performed as described by Section A.2 using analytic EUBO as the acquisition function . In BOPE settings, we interleave 8 stages of PE and experimentation, starting with 16 quasi-random points, followed by 16 pairwise comparisons and one batch of 8 candidates per experimentation stage. Non-compositional BO in BOPE settings uses qNEIUU for experimentation and analytic EUBO for preference exploration . Moreover, we ablate against HDP-GP without joint training, where unsupervised dimensionality reduction is performed and the AE and utility model are trained separately.

Image Generation.Our objective is to generate a rectangle within a \(20 20\) blank square panel and achieve a square of specific size positioned at the center of the panel. The input space is defined to be \(^{4}\). We let \((x_{1},x_{2})\) and \((x_{3},x_{4})\) each specify a vertex, constructing a rectangle with these vertices serving as diagonally opposite corners. Each output is a 400-d binary array representing the resulting image. The utility function is designed to promote the resemblance of the generated image to the desired square at the center of the panel.

Contextual 10-D Hartmann FunctionsWe consider an input space \(^{10}\) and 100-d output space building on the 5D Hartmann test function in , which computes the average of the Hartmann function assuming the sixth dimension follows U. We apply the 5D Hartmann function on inputs 1-5 and 6-10 respectively to construct two basis outputs, then project the basis outputs to 100 dimensions by repeating the first and second basis output 50 times each. The utility function is a classification model trained on synthetic datasets. In this setup, we craft a scenario where each output is sparse with respect to the input space, depending solely on 5 parameters.

Cell-Rower CoverageWe optimize the transmission power and down-tilt angle for each of 15 cell towers (\(30\)-d input space) based on . The simulator generates two 50\(\)50 intensity maps (\(k=5000\)) representing signal power and interference respectively. The utility function is a equally weighted quality metric that prefers high total coverage and low total interference.

ResultsFig 2 shows the PBO setting. HDP-GP with joint training outperforms all baselines for image generation. Without joint training, the output subspace captures the variation across all pixels, while the utility function focuses on a specific region in the center, causing misalignment. In the contextual 10-D Hartmann functions, the utility function leverages all outputs and is not sparse.

Figure 2: Results of three test problems in the PBO setting.

Standard Bayesian preferential optimization, which does not utilize the composite structure, performs poorly. In the cell-tower problem, the high-dimensional output space poses computational challenges, highlighting HDP-GP's superior performance. Fig 3 shows the BOPE setting, where HDP-GP outperforms both non-compositional and random search across all three cases.

The results demonstrate that HDP-GP with joint training consistently outperforms non-compositional BO methods. While HDP-GP without joint training can sometimes perform similarly to HDP-GP with joint training, in tasks such as image generation, joint training of the embedding layer can specifically guide the representation in the latent space, leading to better optimization results. This underscores the efficacy of HDP-GP in distilling pertinent information from high-dimensional outputs for the optimization of utility. Additional test problems and details can be found in the Appendix D.

## 4 Limitations and conclusion

A great number of real-world problems involve optimization of many competing objectives and complex structured data, yet it is often difficult for a human decision maker to articulate their true utility over such outputs. We introduce the HDP-GP model which captures high-dimensional data underlying decision-maker's choices. We show that this method improves the performance of Bayesian optimization with Human Feedback, including preferential Bayesian optimization and Bayesian optimization with preference exploration.

Our approach unlocks the ability to effectively perform BOHF over high-dimensional outcomes--a problem with numerous applications in science and engineering. In this work, we show substantial improvements over BOPE and PBO using a simple one-layer auto-encoder architecture, but there is a large design space of improvements to the autoencoder (e.g., multiple layers, the use of regularization and/or denoising autoencoders), and similar more SoTA methods such as diffusion models. Alternative dimensionality reduction techniques could also be considered, such as encoder-only architectures, diffusion models, and pre-trained modules. This could enable HDP-GP to be applied to output spaces of structured objects such as graphs and sequence data in applications such as human-in-the-loop drug discovery  and human feedback on generative AI models such as LLMs and image generation .