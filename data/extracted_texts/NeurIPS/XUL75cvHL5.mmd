# The Collusion of Memory and Nonlinearity in

Stochastic Approximation With Constant Stepsize

 Dongyan Lucy Huo\({}^{1}\) Yixuan Zhang\({}^{2}\) Yudong Chen\({}^{2}\) Qiaomin Xie\({}^{2}\)

\({}^{1}\)Cornell University \({}^{2}\)University of Wisconsin-Madison

dh622@cornell.edu

{yzhang2554,yudong.chen,qiaomin.xie}@wisc.edu

###### Abstract

In this work, we investigate stochastic approximation (SA) with Markovian data and nonlinear updates under constant stepsize \(>0\). Existing work has primarily focused on either i.i.d. data or linear update rules. We take a new perspective and carefully examine the simultaneous presence of Markovian dependency of data and nonlinear update rules, delineating how the interplay between these two structures leads to complications that are not captured by prior techniques. By leveraging the smoothness and recurrence properties of the SA updates, we develop a fine-grained analysis of the correlation between the SA iterates \(_{k}\) and Markovian data \(x_{k}\). This enables us to overcome the obstacles in existing analysis and establish for the first time the weak convergence of the joint process \((x_{k},_{k})_{k 0}\). Furthermore, we present a precise characterization of the asymptotic bias of the SA iterates, given by \([_{}]-^{*}=(b_{}+b_{}+b_{ })+(^{3/2})\). Here, \(b_{}\) is associated with the Markovian noise, \(b_{}\) is tied to the nonlinearity of the SA operator, and notably, \(b_{}\) represents a multiplicative interaction between the Markovian noise and the nonlinearity of the operator, which is absent in previous works. As a by-product of our analysis, we derive finite-time bounds on higher moment \([||_{k}-^{*}||^{2p}]\) and present non-asymptotic geometric convergence rates for the iterates, along with a Central Limit Theorem.

## 1 Introduction

Stochastic Approximation (SA) is an iterative scheme for solving fixed-point equations using noisy observations. Its application spans various domains including stochastic control [9; 40], reinforcement learning (RL) [4; 62] and stochastic optimization . A typical SA algorithm takes the form \(_{k+1}=_{k}+ g(_{k},x_{k})\), where \((x_{k})_{k 0}\) represents the underlying noisy data sequence and \(>0\) is a constant stepsize. The goal of SA is to approximate the target solution \(^{*}\) that solves \(_{x}[g(^{*},x)]=0\), with \(\) being the stationary distribution of the stochastic process \((x_{k})_{k 0}\).

SA subsumes many important algorithms. A prime example is stochastic gradient descent (SGD) for minimizing a function \(J()\) given noisy estimates \(g(,x)\) of its gradient. Linear SA schemes include SGD for quadratic objective functions, as well as various RL algorithms such as linear TD-Learning (in which \(g\) is not the gradient of any function and standard SGD results do not apply).

Of particular interest to us are SA updates given by a _nonlinear_ function \(g(,x)\) of \(\). One motivating example is learning a Generalized Linear Model (GLM) \(y(z^{})\) with a nonlinear mean function \(:\). A power approach, developed in [19; 36; 37; 64], uses a surrogate loss function, where the corresponding SGD update takes the form \(_{k+1}=_{k}+((w_{k}^{}_{k})-y_{k})w_{k}\), where \(x_{k}=(w_{k},y_{k})\) is the observed covariate-response pair. Common choices of \(\) include the identity map for linear regression, the sigmoid function for logistic regression, as well as Rectified Linear Unit (ReLU) and its various smoothed versions (e.g., ELU and SoftPlus) for ReLU regression [7; 18; 19; 30; 36].

Furthermore, we are interested in the setting where the data sequence \((x_{k})_{k 0}\) forms a _Markov chain_, going beyond the common i.i.d. data setting. The Markovian model captures a wide range of SA problems in machine learning where stochastic data exhibit serial dependence .

Classical work on SA focuses on diminishing stepsizes . Constant stepsize schemes have recently gained popularity due to easy parameter tuning, fast initial convergence, and robust empirical performance. Non-asymptotic error bounds have been obtained for constant stepsize SA . Recent work further provides fine-grained characterization of the distributional and steady-state behaviors of the iterates . Two recurring themes in these results are weak convergence of the distribution of \(_{t}\) and the presence of an asymptotic bias \([_{}]-^{*}\), both having important implications for iterate averaging, bias reduction and statistical inference .

Note that most previous work studied the nonlinear update setting and Markovian data setting _separately_--e.g., in  for nonlinear SGD with i.i.d. data, and in  for Markovian linear SA. The linearity or i.i.d. assumptions imposed in these prior works are restrictive, especially in the face of modern machine/reinforcement learning paradigms where nonlinear models are the norm and dependent data is common. Moreover, the absence of prior work dealing with Markovian nonlinear SA is not merely an overlook--as argued below, this setting is significantly more challenging.

Our ContributionsIn this work, we study constant-stepsize SA with _both_ Markovian data and nonlinear update. In Section 3, we elucidate the new challenges that arise from the simultaneous presence of these two structures, which break key steps in previous analyses of the i.i.d. or linear setting. Due to the interaction between these two structures, establishing weak convergence is far from obvious, and the asymptotic bias exhibits new behaviors. Consequently, analyzing the nonlinear Markovian setting requires more than simply combining previous techniques.

To address the above confounding complication, we exploit the smoothness and recurrence structures of the SA update, thereby developing a fine-grained analysis of the correlation of the parameter \(_{k}\) and data \(x_{k}\). This allows us to establish for the first time the weak convergence of the joint process \((x_{k},_{k})_{k 0}\) to a unique invariant distribution, represented by the limiting random variable \((x_{},_{})\). As a by-product of our analysis, we derive finite-time bounds on \([\|_{k}-^{*}\|^{2p}]\), the \(2p\)-th moments of the errors, generalizing the results in  to higher moments and to the nonlinear Markovian setting. In addition, we prove a Central Limit Theorem (CLT) for averaged iterates.

Moreover, we show that nonlinearity and Markovian structure contribute in a _multiplicative_ way to the asymptotic bias of the SA iterates. We obtain the following bias characterization: \([_{}^{()}]-^{*}=(b_{}+b_{ }+b_{})+((_{})^{3/2}).\) We provide explicit expressions for the vectors \(b_{},b_{},b_{}\), which are independent of \(\). \(b_{}\) represents the bias component due to Markovian data (quantified by the mixing property of \(x_{k}\)), and \(b_{}\) the bias due to the nonlinearity of \(g\) (quantified by the second derivative \(g^{}\)). Importantly, we identify the compound term \(b_{}\), which is absent in both nonlinear SA with i.i.d. data and linear SA with Markovian data. We explore the algorithmic implications of the above results on Polyak-Ruppert (PR) averaging  and Richardson-Romberg (RR) extrapolation . We show that PR averaging reduces the variance but not the bias, whereas RR extrapolation eliminates the leading bias term \((b_{}+b_{}+b_{})\), reducing the asymptotic bias to a higher order of \(\).

Related WorkPostponing a detailed literature review to Section 6, here we remark on the recent works most relevant to ours , all studying Markovian nonlinear SA. The authors of  present an _upper bound_ for the PR-averaged iterates and, similar to our results, demonstrate the effectiveness of RR-extrapolation in reducing bias, but lack weak convergence result for last iterates. In , the authors suggest adopting the ordinary differential equation framework to prove weak convergence of iterates and derive an _upper bound_ for the asymptotic bias, which contrasts with our equality characterization with a closed-form solution for the leading-order bias. In , the authors prove weak convergence of \((x_{t},_{t})\) using coupling, but only in the linear setting, _not_ for nonlinear SA. In the latter setting, their weak convergence analysis is thwarted by challenges similar to what we elucidate in Section 3, the interplay between nonlinearity and Markovian data leading to "double recursions." The coupling technique differs as well: we couple two processes by sharing data \(x_{t}=x_{t}^{}\), while in , they initialize two processes with different \(x_{0}\) and \(x_{0}^{}\), and analyze the stopping time \(\) when \(_{}=_{}^{}\). Moreover, they only present an _upper bound_ for asymptotic bias, while ours presents a fine-grained characterization in Theorem 4.6_necessary_ for justifying RR-extrapolation. Lastly, the paper  discusses stepsize selection and its impact on the asymptotic statistics of PR-averaged SA with both constant and diminishing stepsizes.

NotationsThe Euclidean norm is denoted by \(\|\|\). The notation "\(u v\)" represents the tensor product between vectors \(u\) and \(v\), and "\(u^{ k*}\) denotes the \(k\)-th tensor power of vector \(u\). The ball with radius \(\) is \(B():=\{^{d}:\|\|\}\). \((z)\) denotes the distribution of a random vector \(z\) and \((z)\) its covariance matrix. Let \(_{2}(^{d})\) be the space of square-integrable distributions on \(^{d}\) and \(_{2}(^{d})\) be the space of distributions \(\) on \(^{d}\) with square-integrable second marginal on \(^{d}\). The Wasserstein-2 between two probability measures \(\) and \(\) in \(_{2}(^{d})\) is defined as \(W_{2}(,)=_{(,)}([\|- ^{}\|^{2}])^{}:()=,(^{})=},\) where \((,)\) is the set of all couplings between \(\) and \(\). Extending to \(^{d}\), we define the metric \((x,),(x^{},^{}):=\{x x^{}\}+\|-^{}\|^{2}},\) and denote by \(_{2}\) the extended Wasserstein-2 distance w.r.t. \(\).

The lowercase letter \(c\) and its derivatives \(c^{},c_{0}\), etc. denote universal numerical constants, whose value may change from line to line. We use \(s s(_{0},^{*},,L,R)\) and its derivatives to denote quantities (scalars, vectors, or matrices) that are independent of the stepsize \(\) and the iteration index \(k\), but may depend on the initialization \(_{0}\), SA primitives \(^{*}\), \(\) and \(L\), and the coefficient \(R\) for the geometric mixing rate of \((x_{k})\) in Assumption 1. As we are primarily interested in dependence on \(\) and \(k\), we adopt the following big-O notation: \(\|f\|=(h(,k))\) if it holds that \(\|f\| s\|h(,k)\|\).

## 2 Problem Setup and Preliminaries

Let \((x_{k})_{k 0}\) be a Markov chain on a general state space \(\). Consider the following projected stochastic approximation (SA) iteration:

\[_{k+1}^{()}=_{B()}_{k}^{()}+ g(_{k}^{()},x_{k})+_{k+1}(_{k}^{()}) ,\] (2.1)

where \(g:^{d}^{d}\) is a deterministic function, \(\{_{k}\}_{k 1}\) are i.i.d. zero-mean random fields, \(>0\) is a constant stepsize, and \(_{B()}():=_{z:\|z\|}\|z-\|\) is the projection operator. We shall omit the superscript \({}^{()}\) in \(_{k}\) when the dependence on \(\) is clear from the context. In this work, we also consider the projection-free variant of the iteration (2.1) with \(=\).

We denote by \(\) the stationary distribution of the Markov chain \((x_{k})_{k 1}\) and define the shorthand \(():=_{}[g(,x)],\) where \(_{}[]\) denotes the expectation with respect to \(x\). The algorithm (2.1) computes an estimation of the target vector \(^{*}\) that solves the steady-state equation \(_{}[g(,x)]=0\). Our general goal is to characterize the relationship between the iterate \(_{k}\) and the target solution \(^{*}\).

In the following, we state the assumptions needed for our main results. For a more detailed discussion of the assumptions, we refer readers to Appendix B.

**Assumption 1** (Uniform Ergodicity).: \((x_{k})_{k 0}\) _is a uniformly ergodic Markov chain on a countable state space \((,())\) with transition kernel \(P\) and a unique stationary distribution \(\). That is, there exist constants \(r[0,1)\) and \(R>0\) such that \(\|P^{k}(x,)-\|_{} Rr^{k}, x\)._

The countable state space ensures separability under the \(\{x x^{}\}\) metric, necessary for constructing a valid coupling in the invariance proof and establishing a well-defined \(P^{*}\) for bias characterization. We keep the notation general to allow future extensions to general state space and broader applicability of our results. All irreducible, aperiodic, and finite state space Markov chains are uniformly ergodic. The uniform ergodicity assumption is common in prior work on SA with Markovian noise . Relaxing this uniform ergodicity assumption, in the style of  is possible but orthogonal to our focus, and thus we do not pursue this direction in this work.

We allow the chain \((x_{k})_{k 0}\) to be arbitrarily initialized rather than from the stationary distribution \(\). An important quantity is the mixing time of the Markov chain, defined as follows.

**Definition 2.1**.: _For \((0,1)\), the \(\)-mixing time of \((x_{k})_{k 0}\), denoted by \(_{} 1\), is defined as \(_{}:=k 1:_{x X}\|P^{k}(x,)-\|_{ }}.\)_

Under Assumption 1, the \(\)-mixing time satisfies \(_{} K\) for all \((0,1)\), where \(K 1\) is independent of \(\). In the sequel, unless otherwise specified, we always choose \(=\) and let \(_{}\).

The following assumptions on the nonlinear function \(g\) in (2.1) is standard in the literature . A wide family of \(g\) functions satisfies these assumptions, with the \(L_{2}\)-regularized logistic regression of GLM being a standard example.

**Assumption 2** (Differentiability and Linear Growth).: _For each \(x\), the function \(g(,x)\) is three times continuously differentiable in \(\) with uniformly bounded first to third derivatives, i.e., \(_{^{d}}\|g^{(i)}(,x)\|<+\) for \(i=1,2,3\), \(x\). Moreover, there exists a constant \(L_{1}>0\) such that (1)\(\|g^{(i)}(,x)-g^{(i)}(^{},x)\| L_{1},\) for all \(,^{}^{d}\), \(i=0,1,2\) and \(x\), and (2) \(\|g(0,x)\| L_{1}\) for all \(x\)._

The linear growth condition in Assumption 2 implies that \(g(,x)\) is \(L_{1}\)-Lipschitz w.r.t. \(\) uniformly in \(x\). When \(g\) is a linear function, i.e., \(g(,x)=A(x)+b(x)\), this assumption is satisfied with \(_{x}\|A(x)\|<\) and \(_{x}\|b(x)\|<\), which are commonly assumed for linear SA. The above assumption immediately implies that the growth rate of \(\|g\|\) and \(\|\|\) will be at most linear in \(\), i.e., \(\|g(,x)\| L_{1}(\|-^{*}\|+1)\) and \(\|()\| L_{1}(\|-^{*}\|+1)\).

**Assumption 3** (Strong Monotonicity).: _There exists \(>0\) such that \(-^{},()-(^{}) -\|-^{}\|^{2},\,,^{} ^{d}\). Consequently, the target equation \(()=0\) has a unique solution \(^{*}\)._

When \(g\) is a gradient field, Assumption 3 is equivalent to strong convexity. For notational simplicity, we assume the strong monotonicity parameter satisfies \( 1-r\), where \(r\) is the convergence factor in Assumption 1. For general \(\), our results remain valid with \(\) replaced by \(\{,1-r\}\).

We next consider the noise. Denote by \(_{k}\) the filtration generated by \(\{x_{t},_{t},_{t+1}\}_{t=0}^{k-1}\{x_{k},_{k}\}\).

**Assumption 4** (Noise Sequence).: _Let \(p_{+}\) be given. The noise sequence \((_{k})_{k 1}\) is a collection of i.i.d. random fields satisfying the following conditions with \(L_{2,p}>0\):_

\[[_{k+1}()|_{k}]=0 ^{1/(2p)}[\|_{1}()\|^{2p}] L_{2,p}(\|-^{*}\|+1), ^{d}.\] (2.2)

_Define \(C()=[_{1}()^{ 2}]\) and assume that \(C()\) is at least twice differentiable. There also exist \(M_{},k_{} 0\) such that for \(^{d}\), we have \(_{i=1,2}\|C^{(i)}()\| M_{}\{1+\|- ^{*}\|^{k_{}}\}\)._

In the sequel, we set \(L:=L_{1}+L_{2}\), and without loss of generality, we assume \(L 1\).

When \(p=1\), the second inequality in (2.2) only requires linear growth _in expectation_, which relaxes the almost sure linear growth condition in . The constraint on the covariance matrix \(C()\) is lenient and satisfied in most regular enough settings, as shown in .

## 3 Analytical Challenges and Techniques

In this section, we elaborate on the challenges and techniques in proving the above results.

Previous work has established weak convergence of \((x_{k},_{k})\) separately for nonlinear SA with i.i.d. data, and for Markovian linear SA. The high-level approaches used in two representative prior works can be summarized as follows. The work  on nonlinear SGD leverages _local linearization_ of \(g\) through Taylor expansion. The work  on Markovian linear SA exploits the mixing property of the Markovian noise to regain approximate independence, particularly between \(x_{k}\) and \(_{k-}\) for sufficiently large \(\). It is tempting to expect that nonlinear SA can be analyzed by combining these two approaches. Perhaps surprisingly, such a simple combination would not work due to the interplay between nonlinearity and Markovian structures.

To demonstrate this challenge, let us seek to establish weak convergence in the Wasserstein distance \(W_{2}\) via forward coupling , an approach employed by both  as well as others . Specifically, we consider two SA iterate sequences \((_{k}^{})_{k 0}\) and \((_{k}^{})_{k 0}\) from different initializations \(_{0}^{}\) and \(_{0}^{}\) coupled by sharing the data sequence \((x_{k})_{k 0}\): \(_{k+1}^{}=_{k}^{}+ g(_{k}^{},x_{k})\) and \(_{k+1}^{}=_{k}^{}+ g(_{k}^{},x_{k})\). To establish convergence in \(W_{2}\), we consider the difference sequence

\[w_{k+1}:=_{k+1}^{}-_{k+1}^{}=w_{k}+g(_{k}^ {},x_{k})-g(_{k}^{},x_{k}),\] (3.1)

and it suffices to prove \(w_{k}\) converges to \(0\) in mean square: \([\|w_{k+1}\|^{2}]^{k}[\|w_{0}\|^{2}]\) for \(<1\).

With this goal in mind and following the idea from , one may first linearize the right-hand side of the difference dynamic (3.1) and obtain the approximation

\[w_{k+1} w_{k}+ g^{}(_{k}^{},x_{k})w_{k}.\] (3.2)Next, to analyze the drift of the Lyapunov function \([\|w_{k}\|^{2}]\) and handle the Markovian noise \((x_{k}),\) we use the conditioning technique from . We condition on the information of \(\) steps before, denoted by \(_{k-}:=((_{t}^{},_{t}^{},x_{t}):t k-).\) Ignoring higher-order terms and assuming a one-dimensional problem for simplicity, we obtain that

\[[\|w_{k+1}\|^{2}] \|w_{k}\|^{2}1+2  g^{}(_{k}^{},x_{k})_{k-} \] \[\|w_{k-}\|^{2}1+2 g^{}(_{k}^{},x_{k})_{k-} ,\] (3.3)

where we use \(w_{k} w_{k-}\) for small \(\) (this argument, which is made precise in , essentially exploits the fact that \(x_{k}\) evolves faster than \(_{k}\)).

To prove dynamic (3.3) converges, it boils down to showing the "gain matrix" \(g^{}(_{k}^{},x_{k})_{k-} \) is negative/Hurwitz. To further simplify, we assume \(k\) is large so that the chain \((x_{k})\) is distributed per its stationary distribution \(,\) in which case the gain matrix simplifies to \(_{x_{}}[g^{}(_{}^{},x_{})].\)

Analyzing this gain matrix is where our analysis diverges from previous work. If the SA update were _linear_, i.e., \(g(,x)=A(x),\) then the gain \([g^{}(_{}^{},x_{})]=_{}[A(x _{})]\) would be independent of \(_{}^{},\) and its Hurwitz property is a standard and necessary condition for proving convergence of linear SA. If the data sequence \((x_{k})\) were _i.i.d._, then \(_{k}\) would be _independent_ of \(x_{k}\) and hence the gain becomes \([g^{}(_{}^{},x_{})]=[[g^{}(_{}^{},x_{})|_{}^{}]]= [^{}(_{}^{})]\) with \(():=_{x}[g(,x)],\) where the Hurwitz property again follows from standard assumptions on \(.\)

However, both arguments fail for the _Markovian nonlinear_ setting. Common assumptions for nonlinear SA only ensure Hurwitz \(_{x}[g^{}(,x)|]\) given \(.\) This does not imply the desired Hurwitz \([g^{}(_{}^{},x_{})],\) precisely owing to the simultaneous presence of (i) the _dependence_ of \(g^{}\) on both \(_{}\) and \(x_{}\) (due to nonlinearity) and (ii) the _correlation_ between \(_{}\) and \(x_{}\) (due to Markovian).

Our ApproachWe overcome this challenge by carefully analyzing the properties of the above dependence and correlation. Therefore, for sufficiently large \(,\) we further decompose (3.3) as

\[[\|w_{k+1}\|^{2}]\|w_{k-}\|^ {2}1+2g^{}(_{k}^{},x_{k}) _{k-}\] \[=\|w_{k-}\|^{2}1+2g^{}(_{k-}^{},x_{k})_{k- }}_{[g^{}(_{k-}^{},x_{}) _{k-}]}\ \] \[[\|w_{k-}\|^{2}]+ ,g(_{k}^{},x_{k})-g( _{k}^{},x_{k})-g(_{k-}^{},x_{k})+g(_{k-}^{ },x_{k})}_{}_{k-},\]

where we approximate \(w_{k} w_{k-},\)\(w_{k}g^{}(_{t}^{},x_{k})(g(_{t}^{},x_{k})-g( _{k}^{},x_{k}))\) for \(t=k,k-\) and obtain the second term in the last inequality. Next, we propose employing two different Taylor expansions to prove that \(\) is of higher orders of \(\). We first apply the Taylor expansion to \(g(_{k}^{},x_{k})-g(_{k}^{},x_{k})\) and \(g(_{k-}^{},x_{k})-g(_{k-}^{},x_{k})\). However, this only achieves \(\|w_{k}\|^{2}\|w_{k}\|+ T_{1},\) where \(T_{1}=(\|_{k}^{}\|,\|_{k}^{}\|,\|_{k-}^{}\|, \|_{k-}^{}\|)+1.\) When \(_{k}^{}\) and \(_{k}^{}\) are not close to each order, i.e., when \(\|w_{k}\|\) is large, \(\) is not necessarily of higher order. Therefore, we consider a second type of Taylor expansion on \(g(_{k}^{},x_{k})-g(_{k-}^{},x_{k})\) and \(g(_{k}^{},x_{k})-g(_{k-}^{},x_{k})\). The intuition for the second type of Taylor expansion is to analyze and bound \(\) by the small distance between \(_{k}^{[j]}\) and \(_{k-}^{[j]}\) for \(j\{1,2\},\) even when \(\|w_{k}\|\) is large. This achieves \(\|w_{k}\| T_{1}\|w_{k}\|+ T_{1}.\) Simultaneously applying the two Taylor expansions will yield \(\|w_{k}\|^{2}T_{1}\). Finally, we overcome this challenge by carefully analyzing the boundness of \(T_{1};\) see Theorem 4.1 and its proof.

In parallel to the above coupling approach, we also explore an alternative approach by verifying the joint Markov chain \((x_{k},_{k})\) satisfies certain irreducibility and Lyapunov drift conditions, which in turn imply the chain is ergodic. To apply this approach, we exploit additional properties of the SA noise, namely minorization, which is satisfied in many applications where additional randomness is injected to the SA update. While the high level strategy of this approach is well developed ,carrying out the analysis of each step is technically involved. In particular, we need to translate the minorization property of the noise to the irreducibility of the joint chain \((x_{k},_{k})\), which is nontrivial in the presence of Markovian noise and nonlinearity.

## 4 Main Results

### Weak Convergence of Projected SA

Our first main result proves the ergodicity of the joint process \((x_{k},_{k})_{k 0}\) of the projected SA (2.1).

**Theorem 4.1** (Ergodicity of Projected SA).: _Suppose that Assumption 1-4\((p=1)\) hold. The projected SA (2.1) is applied with radius parameter \(2\|^{*}\|<\). For stepsize \(>0\) that satisfies the constraint \(_{}}\), the Markov chain \((x_{k},_{k})_{k 0}\) converges to a unique stationary distribution \(_{}_{2}(^{d})\). Let \(_{}:=(_{})\) be the second marginal of \(_{}\). For \(k 2_{}\), it holds that_

\[W_{2}((_{k}),_{})_{2}((x_{k},_{k}),_{})(1-)^{k/2} s(_{0}, ^{*},,L,R).\]

Theorem 4.1 generalizes prior weak convergence results for constant stepsize SA/SGD either under i.i.d. noise [20; 67] or linear update [33; 45]. Our stepsize condition \(_{}/L^{2}\) coincides with [33; 60] on linear SA, a special case of our setting.

The proof of Theorem 4.1 highlights the stabilizing effect of the projection operation in (2.1). This effect, together with the smoothness of update function \(g\), controls how the Markovian correlation propagates through the nonlinear update, allowing us to overcome the challenges discussed in Section 3. It is unclear whether our proof, which is based on Markov chain coupling, can be fully generalized to SA without projection. Nevertheless, we show that such a generalization is possible for a sub-family of nonlinear SA where \(g\) possesses the additional structure termed "asymptotic linearity", which is satisfied by, e.g., SGD applied to certain settings of logistic regression. For a formal statement of this result and proof, we refer the readers to Appendix E.

As a by-product of our analysis, we establish the following non-asymptotic \(2p\)-th moment bound on the error \(_{k}-^{*}\). Let \(_{t+1/2}:=_{t}+(g(_{t},x_{t})+_{t+1}(_{t}))\) denote the pre-projection iterate.

**Proposition 4.2**.: _Consider \((_{k})_{k 0}\) of iteration (2.1) with \([2\|^{*}\|,]\). Let Assumption 1-4\((2p)\) hold. If stepsize \(\) satisfies \(_{}L^{2} c_{p}\), with \(c_{p} 1\), the following holds for all \(k_{}\),_

\[[\|_{k+1}-^{*}\|^{2p}][\|_{k+1/2}- ^{*}\|^{2p}] c_{p,1}(1-)^{k+1}[\|_{0}- ^{*}\|^{2p}]+c_{p,2}(_{})^{p} s(_{0},^ {*},L,).\]

Proposition 4.2 implies that \([\|_{k}-^{*}\|^{2p}]()^{p}\) for sufficiently large \(k\), generalizing the results of [17; 20; 60] to higher moments and the nonlinear Markovian setting. Notably, this result holds even without the projection operation in the SA update (2.1), i.e., \(=\). Furthermore, Proposition 4.2 can be used to derive high-probability tail bounds using the Markov inequality.

### Weak Convergence without Projection

Parallel to the coupling approach, we consider an alternative approach for establishing weak convergence via verifying irreducibility, positive Harris recurrence, and \(V\)-uniform ergodicity  of the Markov chain \((x_{k},_{k})\). This approach applies to nonlinear SA even without projection. To verify irreducibility, we exploit the following additional noise structure.

**Assumption 5** (Noise Minorization).: _For each \(^{d}\), the distribution of the random variable \(_{1}()\), denoted by \(_{}\), can be decomposed as \(_{}=_{1,}+_{2,}\), where the measure \(_{1,}\) has a density, denoted by \(p_{}\), which satisfies \(_{ C}p_{}(t)>0\) for any bounded set \(C\) and any \(t^{d}\)._

A similar assumption is considered in [5; 67]. This assumption is mild and satisfied by any continuous random field supported on \(^{d}\). Introducing such (small) continuous noise is often part of the algorithm design for inducing privacy [2; 22] or exploration [28; 55]. Without Assumption 5, the chain may fail to be irreducible even when the other assumptions are satisfied; see  for a counterexample.

Under Assumption 5, we obtain the following ergodicity result paralleling Theorem 4.1.

**Theorem 4.3** (Ergodicity of SA - Minorization).: _Suppose that Assumption 1-3, Assumption 4\((p=1)\), and Assumption 5 hold. For stepsize \(>0\) that satisfies the constraint \(_{}L^{2}<c_{2}\), the Markov chain \((x_{k},_{k})_{k 0}\) of (2.1) with \(=\) is \(V\)-uniformly ergodic with Lyapunov function \(V(x,)=\|-^{*}\|^{2}+1\) and a unique stationary distribution \(_{}_{2}(^{d})\). Moreover, defining the \(V\)-norm \(\|\|_{V}:=|(x)|V(x)\), we have_

\[(x_{k},_{k})-_{}_{V} ^{k},(x_{0},_{0})^{d},  k 0,\] (4.1)

_where the constants \((0,1)\) and \((0,)\) may depend on \(\)._

### Non-Asymptotic Convergence Rate and Central Limit Theorem

In the sequel, let \((x_{},_{}^{()})\) denote the random vector whose law is the stationary distribution \(_{}\) given in Theorem 4.1. As a corollary, we have geometric convergence for the first 2 moments of \(_{k}\).

**Corollary 4.4** (Non-Asymptotic Convergence Rate).: _Under the setting of Theorem 4.1, for any initialization of \(_{0}^{d}\), we have_

\[[_{k}]-[_{}^{( )}](1-)^{k/2} s^{}(_{0},^{*},,L, R),\] \[[_{k}_{k}^{}]-[ _{}^{()}(_{}^{()})^{}](1- )^{k/2} s^{}(_{0},^{*},,L,R).\]

Moreover, the convergence rate established in Theorem 4.1 is fast enough that we can use it to prove a Central Limit Theorem for the average iterates.

**Corollary 4.5** (Central Limit Theorem).: _Under the setting of Theorem 4.1, as \(k\) we have \(}_{t=0}^{k-1}_{t}-[_{ }](0,^{(a)})\), where \(^{()}:=_{k}_{ t=0}^{k-1}_{t}-[_{}^{()}] ^{ 2}\)._

Establishing the CLT sets the stage for using the SA iterates for statistical inference tasks such as confidence interval estimation. We discuss this in greater detail in Section 4.4 after characterizing the asymptotic bias, another important ingredient for using SA for inference.

### Bias Characterization

In this subsection, we characterize the asymptotic bias \([_{}^{()}]-^{*}\). Understanding the bias structure has important algorithmic implications for bias reduction, which we explore in Section 4.5, as well as for more efficient statistical inference and confidence interval estimation .

**Theorem 4.6** (Bias Characterization).: _Suppose Assumptions 1-4\((p=3)\) hold. For each stepsize \(>0\) satisfying \(_{}L^{2}<c_{3}\), the following holds for some vector \(b\) independent of \(:\)_

\[[_{}^{()}]-^{*}= b+( _{})^{3/2}.\] (4.2)

_More specifically, the leading bias can be decomposed as \(b=b_{}+b_{}+b_{}\), where_

\[b_{} =-(^{}(^{*}))^{-1}[g^{}( ^{*},x_{})h(^{*},x_{})],\] (4.3) \[b_{} =(^{}(^{*})^{-1}^{ }(^{*})A[g(^{*},x_{})^{ 2}]+ [(_{1}(^{*}))^{ 2}],\] (4.4) \[b_{} =(^{}(^{*})^{-1}^{ }(^{*})A[g(^{*},x_{}) h(^ {*},x_{})]+[h(^{*},x_{}) g(^{*},x_{ })],\] (4.5)

_with \(A=(^{}(^{*}) I+I^{}(^{*}) )^{-1}\) and \(h(^{*},x)=_{}(I-P^{*}+)^{-1}(P^{*}-)(x,x^{ })g(^{*},x^{})\), with the kernel \(P^{*}\) being a regular conditional probability on \(\) that satisfies \(_{B}(x)P(x,C)=_{C}(y)P^{*}(y,B)\), for all \(B,C()\)._

We defer the detailed proof to Appendix I. A few remarks are in order. First, we emphasize that (4.2) is essentially an equality, indicating a non-zero bias of order \(\) whenever \(b 0\) (up to higher order terms). Notably, the Polyak-Ruppert averaging of the iterates cannot eliminate this bias. Note that the bias expansion in (4.2) applies to both weakly converged projected and non-projected SA. Our analysis shows that compared with the non-projected SA, the projection operator induces an extra bias term of the order \((^{2}_{}^{3})\), which is negligible relative to the main terms in in (4.2).

More importantly, Theorem 4.6 provides an explicit expression of the leading bias, which decomposes into three components: the Markovian part, the nonlinearity contribution, and a _compound_ term,which is unique in nonlinear Markovian SA. Specifically, \(b_{}\) in (4.3) is associated with the Markovian multiplicative noise, where the matrix \(P^{*}-\) in the \(h\) function determines the mixing time of the data sequence \((x_{k})_{k>}\). The term \(b_{}\) in (4.4) is linked to nonlinearity, as reflected by the Hessian term \(^{}(^{*})=[g^{}(^{* },x_{})]\), which quantifies the nonlinearity of \(g\) and is equal to zero in the case of a linear \(g\). Lastly, \(b_{}\) in (4.5) is the _compound_ term, due to its dependence on both the Markov noise (\(h\) function) and the nonlinearity measure \(^{}\). In particular, we note the following two special cases: (1) When \(g\) is a linear function, \(^{}(^{*})=0\). Hence, \(b_{}=b_{}=0\), and \(b_{}\) recovers the result in ; (2) When \((x_{k})_{k 0}\) is i.i.d. sampled from the stationary distribution \(\), we have \(h(^{*},x) 0\)\( x\), for \(P=P^{*}=\). As such, \(b_{}=b_{}=0\), recovering the result in . The presence of the compound term \(b_{}\) suggests that as the SA structure becomes more nonlinear and the underlying Markov chain mixes more slowly, the impact on the bias is _multiplicative_ rather than simply additive, a surprising phenomenon not unveiled in previous studies. It is possible to improve the residual order from \((^{3/2})\) to \((^{2})\) with a more refined characterization of the asymptotic second moment \([(_{}-^{*})^{ 2}]\) by following a similar strategy as our current approach. We leave this refinement out of the scope of the current paper.

### Algorithmic Implications

We examine the practical implications of our weak convergence and bias characterization results, particularly for Polyak-Ruppert (PR) tail averaging and Richardson-Romberg (RR) extrapolation. In this subsection, we focus on the dependence on the stepsize \(\) and iteration index \(k\), and make use of the big-O notation from Section 1. Recall that \(b\) is the bias vector defined in Theorem 4.6.

PR averaging [56; 59] is a classical approach for reducing the variance and accelerating the convergence of SA. Here we consider the tail-averaging variant of PR averaging, defined as \(_{k_{0},k}:=}_{t=k_{0}}^{k-1}_{t},\) for \(k k_{0}\), with a user-specified burn-in period \(k_{0} 0\) (a common choice is \(k_{0}=k/2\)). The following corollary, proved in Appendix J, provides a non-asymptotic bound on the mean squared error (MSE) for the averaged iterates \(_{k_{0},k}\).

**Corollary 4.7** (Tail Averaging).: _Under the setting of Theorem 4.6, the tail-averaged iterates satisfy the following bounds for all \(k>k_{0}+2_{}\) and \(k_{0}_{}+}\),_

\[\|_{k_{0},k}-^{*}\|^{2}= {^{2}\|b\|^{2}+()^{} }_{T_{1}:}+ }{k-k_{0}}}_{T_{2}:}+/2}}{(k-k_{0})^ {2}}}_{T_{3}:}.\]

Corollary 4.7 shows that the MSE can be decomposed into three terms and elucidates how these terms depend on \(,k\), and other problem parameters. In particular, the term \(T_{1}\) corresponds to the asymptotic squared bias \(\|[_{}^{()}-^{*}]\|^{2}\), which is not affected by averaging. The term \(T_{2}\) is associated with the variance \((_{k_{0},k})\), which decays at rate \(1/k\) due to averaging. Lastly, the term \(T_{3}\) represents the optimization error \(\|_{k_{0},k}-_{}\|^{2}\), which decays geometrically in \(k_{0}\) thanks to the use of a constant stepsize \(\) and the tail-averaging procedure.

Note that averaging does not affect the bias of order \(\). With the precise bias characterization in Theorem 4.6, we can order-wise reduce the bias to \((^{3/2})\) by employing the RR extrapolation technique . Let \(_{k_{0},k}^{()}\) and \(_{k_{0},k}^{(2)}\) denote the tail-averaged iterates using two stepsizes \(\) and \(2\) with the same data \((x_{k})_{k 0}\). The RR extrapolated iterates are defined as \(_{k_{0},k}^{()}=2_{k_{0},k}^{()}- _{k_{0},k}^{(2)}\).

**Corollary 4.8** (RR-Extrapolation).: _Under the setting of Theorem 4.6, the RR-extrapolated iterates satisfy the following bounds for all \(k>k_{0}+2_{}\) and \(k_{0}_{}+}\),_

\[\|_{k_{0},k}-^{*}\|^{2}= (_{})^{3}+}{k-k_{0}}+/ 2}}{(k-k_{0})^{2}}.\]

Backed by the CLT in Corollary 4.5, the iterates of constant-stepsize SA can be used to construct confidence intervals of \(^{*}\). For i.i.d. data or linear SA, this approach has been explored in [34; 67; 66; 47] along with an appropriate variance estimator [26; 66]. In our Markovian nonlinear setting, where the iterates are biased, it is crucial to use RR extrapolation for bias reduction. Once the bias is accounted for, the power of using constant stepsizes reveals itself as it leads to rapid mixing and low correlation of the iterates. Together, they lead to efficient confidence interval estimation schemes using nonlinear Markovian SA; see the empirical results in  showing its efficacy. In contrast, the classical diminishing stepsize paradigm often suffers from high correlation  and in turn inaccurate variance estimation, resulting in unsatisfactory coverage probability with finite data .

### Implications for Learning GLM

Generalized linear models (GLM) extend linear regression to the model \([Y|W]=(W^{}^{*})\), where \(W\) is the covariate, \(Y\) the response variable, and \(\) is called the _mean function_. For any monotone (and potentially nonlinear) \(\), the powerful framework developed in [19; 36; 37; 64] allows one to formulate the estimation of \(^{*}\) as minimizing an appropriate _convex_ (surrogate) loss function. Applying SGD to this loss leads to a nonlinear SA update, to which our results are applicable. Below we discuss their applications in two concrete examples of GLMs.

Logistic RegressionLogistic regression uses a sigmoid mean function \((x)=\). Suppose the covariate \(w_{k}\) is sequentially sampled from a uniformly ergodic Markov chain with a bounded state space \(^{d}\), and conditioned on \(w_{k}\) the response \(y_{k}\) is Bernoulli distributed with parameter \((1+(-w_{k}^{}^{*}))^{-1}\). SGD applied to the \(L_{2}\)-regularized negative log-likelihood function takes the form of the SA update \(_{k+1}=_{k}+ g(_{k},x_{k})\), where \(x_{k}=(w_{k},y_{k})\{0,1\}\) and \(g(_{k},x_{k})=-w_{k}(-w_{k}^{}_{k})-y_{k} -_{k}\). For simplicity, we do not consider \(\)-perturbation, i.e., \(_{k+1}(_{k}) 0\). It is easy to verify that this \(g\) is strongly monotone and sufficiently smooth with at most linear growth in \(||\), hence satisfying Assumption 1-3. Therefore, all the results in Sections 4.1-4.5 apply to logistic regression with constant stepsizes and Markovian data.

Smooth ReLU RegressionThe mean function \(\) can be interpreted as playing a similar role as the activation function in neural networks. Widely adopted is ReLU activation \((x)=(0,x)\) as well as its various smooth approximations [7; 30]. The problem of learning \(^{*}\) in this setting, sometimes called ReLU Regression, has been studied in the last decade and recently regained attention [19; 36; 37; 64]. Unlike linear or logistic regression, the least squares and maximum likelihood formulation associated with such nonlinear mean functions \(\) is non-convex. Nevertheless, the convex surrogate loss framework in [19; 64] still applies. As an example, we focus on the SoftPlus activation \((x)=(1+( x))/\) with a temperature parameter \(>0\). With \(L_{2}\)-regularization the resulting SGD iteration is \(_{k+1}=_{k}-w_{k}(1+(  w_{k}^{}_{k}))-y_{k}+_{k},\) where the covariate-response pair \((_{k},x_{k})\) is as before. This problem can again be cast as nonlinear SA with a strongly monotone and smooth \(g\), satisfying Assumptions 1-3. All results in Sections 4.1-4.5 apply.

## 5 Numerical Experiments

In this section, we provide numerical experiment results to verify our theoretical results. We run SGD on \(L_{2}\)-regularized logistic regression with Markovian data and constant stepsizes, where the covariate \(x_{t}\) is sequentially sampled from an autoregressive (AR) model of order 1; specifically, \(x_{t+1}=0.9x_{t}+_{t+1}\) with \(_{t}\) i.i.d. following \(N(0,1)\), and the stationary distribution is \(x_{} N(0,1/(1-0.9^{2}))\). The binary dependent variable \(y_{t}\) is sampled from Bernoulli\((1/(1+(-w^{*}x_{t}))\) with \(w^{*}=1\). The regularized parameter is set to \(=0.0001\).1

To examine the asymptotic bias, we run the experiment for an episode length of \(10^{7}\), with Markovian data as well as i.i.d. data sampled from \(N(0,1/(1-0.9^{2}))\). We plot the errors (distance to \(^{*}\)) of the PR averaged iterates and the RR extrapolated iterates, for different stepsizes \(\). Figure 1(a) verifies the presence of an asymptotic bias approximately proportional to the stepsize \(\), and illustrates the effectiveness of RR extrapolation in reducing this bias. In Figure 1(b), we compare the bias under Markovian data (\(x_{t+1} P(|x_{t})\)) and i.i.d. data (\(x_{t} x_{}\)). Interestingly, Figure 1(b) reveals that Markovian data does not necessarily lead to a larger bias than i.i.d. data. This is consistent with our theory, as the three bias terms \(b_{m},b_{n},b_{c}\) may have opposite signs leading to cancellation. This result suggests that in the presence of nonlinearity, one should not avoid Markovian data simply for the sake of reducing bias. Rather, RR extrapolation may be more effective for bias reduction.

To verify the CLT in Corollary 4.5, we repeat the experiment 1000 times with an episode length of \(10^{6}\) and stepsize \(=0.8\). We compute the PR averaged iterates and plot the histogram and the quantile-quantile (QQ) plot in Figure 2 in Appendix C. The close alignment between the histogram and the normal curve in Figure 2(a) and the linearity of the points along the 45-degree reference line in the QQ plot in Figure 2(b) confirm that the empirical distribution follows a normal distribution.

## 6 Related Work

**General SA and SGD.** SA and SGD can be traced back to the seminal work of . Classical work assumes a diminishing stepsize sequence, and has shown almost sure asymptotic convergence to \(^{*}\)[58; 8]. Subsequent works propose the iterate averaging technique, now known as Polyak-Ruppert (PR) averaging, to reduce variance and accelerate convergence [56; 59], and also establish a Central Limit Theorem for the asymptotic normality of the averaged iterates . The asymptotic convergence theory of SA and SGD is well developed and extensively addressed in many exemplary textbooks, see [3; 40; 65]. There are also recent works studying the non-asymptotic convergence with diminishing stepsizes [14; 12]. The recent work  establishes the high probability bound on the estimation error of contractive SA with diminishing stepsize.

**SA and SGD with Constant Stepsizes.** There has been an increasing interest in studying SA with constant stepsize. Many works in this line provide non-asymptotic upper bounds on mean squared error (MSE) \([\|_{t}-^{*}\|^{2}]\). Works in [25; 42; 51] study linear SA (LSA) under i.i.d. data. Recent works extend the analysis of the MSE to LSA with Markovian data, such as [24; 52; 60]. There are also works providing upper bounds of MSE for general contractive SA with Markovian noise [14; 17].

In addition to non-asymptotic guarantees, some works focus on the asymptotic behavior of SA iterates. Recent works have shown that when using constant stepsize, one loses the almost sure convergence guarantee in the diminishing stepsize sequence regime, and at best can achieve distributional convergence, as demonstrated in [16; 20; 25; 33; 66; 67; 69]. The presence of asymptotic bias is also a recurring theme in recent literature, with precise characterization given in  for strongly-convex SGD with i.i.d. data and in  for LSA with Markovian data. Works in [34; 51; 66; 67; 69] also establish Central Limit Theorems for averaged SA iterates with constant stepsizes.

## 7 Conclusion

We provide the first weak convergence and steady-state analysis for constant-stepsize SA with both nonlinear update and Markovian data. Our analysis elucidates the compound effect of nonlinearity and memory, which leads to new analytical challenges and behaviors. A limitation of our results is the use of a projection step or the noise minorization assumption. Whether they can be removed is worth investigating. Other future directions include refining the dimension dependence in our results, as well as a theoretical investigation of statistical inference.

Figure 1: Experiment results to illustrate the properties of asymptotic bias.

AcknowledgementY. Chen is partially supported by National Science Foundation (NSF) grants CCF-1704828 and NSF CCF-2233152. Y. Zhang and Q. Xie are supported in part by NSF grants CNS-1955997, EPCN-2339794 and EPCN-2432546. Y. Zhang is also supported in part by NSF Award DMS-2023239.