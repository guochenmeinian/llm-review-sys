# Transfer Learning for Diffusion Models

Yidong Ouyang\({}^{1}\), Liyan Xie\({}^{2}\), Hongyuan Zha\({}^{3}\), Guang Cheng\({}^{1}\)

\({}^{1}\)Department of Statistics and Data Science, University of California, Los Angeles

\({}^{2}\)Department of Industrial and Systems Engineering, University of Minnesota Twin Cities

\({}^{3}\)School of Data Science, Chinese University of Hong Kong, Shenzhen

yidongouyang@g.ucla.edu; liyanxie@umn.edu; zhahy@cuhk.edu.cn; guangcheng@ucla.edu

Correspondence to: Liyan Xie, liyanxie@umn.edu.

###### Abstract

Diffusion models, a specific type of generative model, have achieved unprecedented performance in recent years and consistently produce high-quality synthetic samples. A critical prerequisite for their notable success lies in the presence of a substantial number of training samples, which can be impractical in real-world applications due to high collection costs or associated risks. Consequently, various finetuning and regularization approaches have been proposed to transfer knowledge from existing pre-trained models to specific target domains with limited data. This paper introduces the Transfer Guided Diffusion Process (TGDP), a novel approach distinct from conventional finetuning and regularization methods. We prove that the optimal diffusion model for the target domain integrates pre-trained diffusion models on the source domain with additional guidance from a domain classifier. We further extend TGDP to a conditional version for modeling the joint distribution of data and its corresponding labels, together with two additional regularization terms to enhance the model performance. We validate the effectiveness of TGDP on both simulated and real-world datasets.

## 1 Introduction

Diffusion models have achieved remarkable success in modeling data distributions and generating various types of synthetic data, such as images [13; 36; 17], videos , vision language [32; 33; 30], and time series . However, their success heavily relies on the availability of a large number of training samples. In real-world applications, acquiring ample samples for specific tasks can be challenging due to the high costs associated with data collection or labeling, or the potential risks involved. Therefore, an important research question is how to effectively transfer knowledge from a pre-trained generative model in the source domain (using existing large-scale datasets) to a target domain (for specific tasks) where data is limited.

Training a generative model directly or finetuning a pre-trained generative model on limited data from the target domain often results in significant performance degradation due to overfitting and memorization. To address these issues, numerous studies have proposed methods in generative domain adaptation, including the GAN-based models [46; 45; 49; 1; 51; 28; 48; 9; 15; 43; 22; 50], diffusion-based model [25; 52; 44], etc. Specifically, approaches using diffusion models can be divided into two categories: finetuning lightweight adapters [25; 44] and finetuning with regularization . Approaches involving finetuning lightweight adapters focus on adjusting only a subset of parameters in a pre-trained model. The primary challenge here is identifying which parameters to finetune. This process is typically heuristic and requires preliminary experiments to identify the most efficient parameters for adjustment. Additionally, the specific parameters to be finetuned can vary acrossdifferent neural network architectures. On the other hand, the challenge in incorporating regularization during the finetuning process is the heuristic design of the regularization term, which can significantly alter the optimization landscape. We refer to Appendix A for a more detailed discussion of existing literature.

In this work, we introduce a new approach, termed Transfer Guided Diffusion Process (TGDP), to transfer knowledge in the source domain generative model to the target domain with limited samples. Unlike finetuning-based methods that primarily use the pre-trained model as an initialization point, TGDP leverages the pre-trained model as a plug-and-play prior. We show that the score function for the diffusion model on the target domain is the score function on the source domain (which can be pre-trained) with additional guidance as shown by Theorem 3.1 and Theorem 3.3. The guidance network is related to the density ratio of the target and source domain data distributions. Consequently, we convert the original optimization problem for a diffusion model on the target domain into estimating the density ratio.

We utilize a domain classifier (binary classifier) along with samples from both domains to efficiently estimate the density ratio. Furthermore, we introduce two additional regularization terms for better training and calibration of the guidance network. These regularization terms are equivalent forms that the optimal guidance network should satisfy, ensuring they do not alter the original optimization problem. We validate the effectiveness of our approach through experiments on Gaussian mixture simulations and real electrocardiogram (ECG) data. Under both fidelity and utility evaluation criteria, TGDP consistently outperforms finetuning-based methods.

Our contributions can be summarized as follows.

* We introduce a new framework, the Transfer Guided Diffusion Process (TGDP), for transferring a pre-trained diffusion model from the source domain to the target domain.
* We extend TGDP to a conditional version for modeling the joint distribution of data and its corresponding labels, along with two additional regularization terms, which are important for practical applications and downstream tasks.
* TGDP demonstrates superior performance over finetuning-based methods on Gaussian mixture simulations and on benchmark electrocardiogram (ECG) data.

The rest of the paper is organized as follows. Section 2 reviews the setup of generative domain adaptation and the diffusion model. Section 3 introduces the proposed method and theoretically characterizes its effectiveness. Numerical results are given in Section 4. We conclude the paper in Section 5. All proofs and additional numerical experiments are deferred to the Appendix.

## 2 Problem Formulation and Preliminaries

### Transfer Learning Problem Setup

Let \(\) denote the data space and \(\) the label space. A domain corresponds to a joint distribution over \(\) and \(\), denoted as \(p_{XY}\) for the _source_ domain and \(q_{XY}\) for the _target_ domain. The marginal distribution of data in the source and target domains are \(p_{X}\) and \(q_{X}\), respectively. Suppose we have access to \(m\) (labeled) samples from the source domain \(=\{(_{i},y_{i})\}_{i=1}^{m} p_{XY}\) and \(n\) (labeled) samples from the target domain \(=\{(^{}_{i},y^{}_{i})\}_{i=1}^{n } q_{XY}\). Typically, the source domain contains significantly more samples than the target domain, i.e., \(n m\). This setup reflects the common scenario where there is limited data available for specific tasks in the target domain, while abundant data is readily accessible and stored in the source domain.

The problem of interest is as follows. Given a pre-trained generative model \(p_{}\) for the data distribution \(p_{X}\) in the source domain, and a relatively small number of samples from the target domain, generative domain adaptation approaches aim to obtain a generative model that can generate synthetic samples following the target data distribution \(q_{X}\). We will focus on diffusion generative models, given their great success in synthetic data generation. We first present the key idea of a carefully designed guidance network for the generation of \(\) values only. Then, we extend the method to facilitate conditional generations so that we can generate paired samples with labels, \((,y)\), and can incorporate downstream classification tasks on the target domain.

### Preliminaries of Diffusion Model

Diffusion models are characterized by their forward and backward processes. For illustrative purposes, we discuss the diffusion model trained on the source domain. The forward process involves perturbing the data distribution \(p_{X}()\) by injecting Gaussian noise, as described by the following continuous-time equation :

\[_{t}=(_{t},t)t+g(t) ,\ t[0,T],\] (1)

where \(\) is the standard Brownian motion, \((,t):^{d}^{d}\) is a drift coefficient, and \(g():\) is a diffusion coefficient. The marginal distribution of \(_{t}\) at time \(t\) is denoted as \(p_{t}(_{t})\), and \(p_{0}\) is the distribution of the initial value \(_{0}\), which equals the true data distribution \(p_{X}()\). For notational simplicity and provided it does not cause further confusion, we will refer to this diffusion process as \(p\) in the following, and we define \(p(_{t}|_{s})\), \( s,t\), as the conditional distribution of \(_{t}\) given the value \(_{s}\). Similarly, for initial value \(\) following the target domain distribution, we denote the corresponding probability measure induced by the above diffusion process (1) as \(q\).

Then, we can reverse the forward process (1) for generation, defined as:

\[_{t}=[(_{t},t)-g(t)^{2}_{ } p_{t}()]t+g(t)},\] (2)

where \(}\) is a standard Brownian motion when time flows backwards from \(T\) to 0, and \(t\) is an infinitesimal negative time step. The key of the backward process is to estimate the score function of each marginal distribution, \(_{} p_{t}()\), then the generation can be performed by discretizations of (2) [13; 36]. Score Matching [16; 40; 35] are proposed to train a neural network \(_{}(_{t},t)\) (parameterized by \(\)) to estimate the score:

\[^{*}=*{arg\,min}_{}_{ t}\{(t)_{p_{t}(_{t})}[\|_{ }(_{t},t)-_{_{t}} p_{t}( _{t})\|_{2}^{2}]\},\] (3)

where \((t):[0,T]_{>0}\) is a positive weighting function, \(t\) is uniformly sampled over \([0,T]\). One commonly adopted forward process is choosing an affine \((,t)=-(t)\) and \(g(t)=\), which yields the Gaussian transition distribution \(p(_{t}|_{s})=(_{t}; _{s},(t))\), \(t>s\), with \((t):[0,T](0,1)\) as a variance schedule. This is the Variance Preserving Stochastic Differential Equation (VP SDE) that we use in the numerical Section 4.

Several works on image generation [4; 5] and inverse problem  extends Score Matching to Conditional Score Matching, i.e.,

\[^{*}=*{arg\,min}_{}_{ t}\{(t)_{p_{t}(_{t},y)}[\|_{ }(_{t},y,t)-_{_{t}} p_{t}( _{t}|y)\|_{2}^{2}]\},\] (4)

where \(p_{t}(_{t}|y)\) is the conditional distribution of perturbed data \(_{t}\) given corresponding label \(y\).

## 3 Transfer Guided Diffusion Process

In this section, we introduce the proposed Transfer Guided Diffusion Process (TGDP) that leverages a pre-trained diffusion model - trained on the source domain data - to generate data in the target domain. The proposed approach is orthogonal to and different from the existing fine-tuning type methods. We introduce the additional guidance in Section 3.1. The methods for calculating the guidance are provided in Section 3.2. We extend our framework to the conditional diffusion model in Section 3.3 and we propose two regularization terms for enhancing the performance of our method in Section 3.4. All proofs are deferred to Appendix C.

### Methodology Formulation

This subsection outlines the process of transferring knowledge from a diffusion generative model pre-trained using the source domain data \(\) for generating samples that match the underlying distribution of target domain sample \(\). The simplest non-transfer type approach involves directly training a diffusion model on samples \(\) from the target domain by denoising Score Matching as described by Eq (3) or Eq (4). However, since we assume only a limited amount of data is accessible on the target domain, directly learning from the target domain is unlikely to yield an effective generative model.

Several studies propose to finetune the pre-trained diffusion model to alleviate the challenges caused by limited data and make use of acquired knowledge [25; 42; 53]. These methods typically design different strategies, such as adapters, to avoid finetuning all weights in a pre-trained model. However, these approaches generally use the pre-trained diffusion model from the source domain only as initial weights. Our method offers a different way for better utilization of the acquired knowledge.

Our proposed method is inspired by the key observation detailed in the following Theorem 3.1. Intuitively, the score function \(_{_{t}} q_{t}(_{t})\) for the target domain differs from the score function \(_{_{t}} p_{t}(_{t})\) of the source domain by a term related to the density ratio function \(q_{X}/p_{X}\). We refer to this differing term as a guidance term in the following Theorem.

**Theorem 3.1**.: _Consider two diffusion models on the source and target domain, denoted as \(p\) and \(q\), respectively. Let the forward process on the target domain be identical to that on the source domain, \(q(_{t}|_{0})=p(_{t}|_{0})\), and \(_{^{*}}(_{t},t)\) is the score estimator in the target domain:_

\[^{*}=*{arg\,min}_{}_ {t}\{(t)_{q_{t}(_{t})}[|_ {}(_{t},t)-_{_{t}} q_{t}( _{t})|_{2}^{2}]\},\] (5)

_then we have_

\[_{^{*}}(_{t},t)=_{t}} p_{t}(_{t})}_{}+_{t}}_{p( _{0}|_{t})}[_{0})}{p(_{0} )}]}_{}.\] (6)

Based on Eq (6), instead of solving \(_{^{*}}\) from the limited training samples on the target domain, we construct \(_{^{*}}\) by combing the pre-training score estimator and the guidance based on a binary classifier of source and target domain samples (detailed in Section 3.2). We comment on some potential advantages of this simple yet effective idea. First of all, we do not need to fine-tune the pre-trained diffusion model on the source domain, with the corresponding computation shifted to training the guidance network which is essentially a classifier. Second, the guidance network can be effectively estimated by a domain classifier using data from both the source and target domains. There is also great flexibility in constructing this guidance network due to the extensive literature on classification problems and density ratio estimation approaches. Additionally, the sample complexity for training a generative model could be much larger than a discriminative model, since the generative model needs to recover the full spectrum of target data distribution, while a domain classifier only needs to distinguish whether the sample is from the source or target distribution.

### Learning Guidance Network

We calculate the guidance for the diffusion model on the target domain as defined in the second term of Eq (6) via two steps. In the first step, we estimate the density ratio \(q(_{0})/p(_{0})\) by training a classifier \(c_{}():\) to distinguish samples from the source and target domains. We adopt the typical logistic loss as follows:

\[^{*}=*{arg\,min}_{}\{- _{_{i} p} c_{}(_{i})-_{_{i}^{} q}(1-c_{}(_{i}^{}))\}.\] (7)

Then, the density ratio \(q(_{0})/p(_{0})\) can be estimated as \((1-c_{^{*}}(_{0}))/c_{^{*}}( _{0})\), and it can be shown that the optimal solution to the population counterpart of Eq (7) is exactly the true likelihood ratio . It is worthwhile mentioning that we may only use a subset of source domain samples to learn the classifier \(c_{}\) to alleviate the unbalanced sample sizes, and we could also adopt modern density ratio estimators to improve the accuracy . After learning the density ratio \(q(_{0})/p(_{0})\), the second step is to calculate the expectation \(_{p(_{0}|_{t})}[q(_{0})/p(_{ 0})]\) using Monte Carlo simulation. Since it is hard to sample from \(q(_{0}|_{t})\), we use the following equivalent formulation to get the value instead. This trick has also been used in previous work such as the Appendix H in .

**Lemma 3.2**.: _For a neural network \(h_{}(_{t},t)\) parameterized by \(\), define the objective_

\[_{}():=_{p(_{0},_{t})}[\|h_{}(,t) -_{0})}{p(_{0})}\|_{2}^{2}],\] (8)

_then its minimizer \(^{*}=*{arg\,min}_{}_ {}()\) satisfies:_

\[h_{^{*}}(_{t},t)=_{p( _{0}|_{t})}[q(_{0})/p(_{0})].\]By Lemma 3.2, we estimate the value \(_{p(_{0}|_{t})}[q(_{0})/p( _{0})]\) using the guidance network \(h_{^{*}}\) solved by minimizing the objective function \(_{}()\), which can be approximated by easy sampling from the joint distribution \(p(_{0},_{t})\). Combine the above steps together, the estimated score function for the diffusion generative model on target domain \(q_{X}\) can be calculated as follows:

\[_{^{*}}(_{t},t)=_{ t}} p(_{t})}_{}+_{t}} h_{^{*}}( _{t},t)}_{}.\] (9)

### Extension to the Conditional Version

The approach outlined above is for generating the sample \(\) in the target domain. In this section, we extend the idea to the conditional generation task. Such extension is essential when the label sets in the source and target domain are different since, in such cases, we usually rely on the conditional diffusion model for sampling [18; 21]. We first present the following theorem, which is an analog to Theorem 3.1 within the context of conditional score matching.

**Theorem 3.3**.: _Assume \(_{t}\) and \(y\) are conditional independent given \(_{0}\) in the forward process, i.e., \(p(_{t}|_{0},y)=p(_{t}|_{0})\), \( t[0,T]\), and let the forward process on the target domain be identical to that on the source domain \(q(_{t}|_{0})=p(_{t}|_{0})\), and \(^{*}\) is the optimal solution for the conditional diffusion model trained on target domain \(q(_{0},y)\), i.e.,_

\[^{*}=*{arg\,min}_{}_{t}\{ (t)_{q_{t}(_{t},y)}[\|_{}( _{t},y,t)-_{_{t}} q_{t}(_{t}|y)\|_{2}^ {2}]\},\] (10)

_then_

\[_{^{*}}(_{t},y,t)=_{t}} p_{t}(_{t}|y)}_{}+_{t}}_{p(_{0}| _{t},y)}[_{0},y)}{p(_{0},y)}] }_{}.\] (11)

The key difference is we need to estimate the joint density ratio between the source and target domain. We can extend the density ratio estimator in Section 3.2 for estimating joint density ratio, i.e., also feed the label \(y\) into the classifier \(c_{}(,y)\). The corresponding Lemma and its proof for the conditional version of Lemma 3.2 can be found in Appendix C.3. We further provide a detailed discussion about how to extend this conditional guidance to text-to-image generation tasks and when the source and target domain contain different class labels in Appendix B.

### Additional Regularizations in Practical Implementations

In this subsection, we provide two additional regularization terms in our final objective function, to enhance the performance of the proposed scheme.

Cycle RegularizationIn the approaches described above, after obtaining the classifier network \(c_{^{*}}\), calculation of the additional guidance \(_{_{t}}_{p(_{0}|_{t})}[q( _{0})/p(_{0})]\)(or \(_{_{t}}_{p(_{0}|_{t},y)}[q (_{0},y)/p(_{0},y)]\) for conditional generation) _only_ utilizes the data from source domain. In this section, we provide an enhancement in which the limited data from the target domain can also be utilized to improve the training of the guidance network \(h_{}\).

Notice that (with detailed derivation given in Appendix C.5)

\[_{p(_{0}|_{t})}[_{0})}{ p(_{0})}]=_{q(_{0}|_{t})}[ (_{t})}{p_{t}(_{t})}],\] (12)

where recall \(p_{t}(_{t})\) and \(q_{t}(_{t})\) are the marginal distribution at time \(t\) for source and target distributions, respectively. A similar idea to Theorem 3.2 implies that we can learn the guidance network by solving the following optimization problem as well:

\[^{*}=*{arg\,min}_{}_{}:= _{q(_{0},_{t})}[\|h_{}( _{t},t)-(_{t})}{p_{t}(_{t})} \|_{2}^{2}].\] (13)

Moreover, in order to estimate the density ratio for marginal distributions at time \(t\) between the target and source data distribution, we train a time-dependent classifier \(c_{}(,t)\) to distinguish samples from 

[MISSING_PAGE_FAIL:6]

Implementation details and BaselinesWe adopt the default Variance Preserving (VP) SDE in  with a linear schedule, i.e., \(q(_{t}|_{0})=p(_{t}|_{0})= (_{t}|_{t}_{0},_{t}^{2})\) with \(_{t}\) and \(_{t}\) being:

\[_{t}=--_{0}}{4}t^{2}-}{2}t, _{t}=^{2}},\]

with \(_{0}=0.1,_{1}=20\). We adopt 5-layer MLP with hidden sizes of \(\) and SiLU activation function as the diffusion model. We train the diffusion model on data from the source domain for 100 epochs using the Adam optimizer with a learning rate of \(1^{-4}\) and batch size of 4096. The guidance network is a 4-layer MLP with 512 hidden units and SiLU activation function. We train the guidance network 20 epochs for our TGDP and train a vanilla diffusion model or finetune the diffusion model target domain 50 epochs. For generation, we adopt DPM-Solver  with a second-order sampler and a diffusion step of 25. We compare TGDP with the following baseline methods: 1) Vanilla Diffusion: directly training from target domain; 2) Finetune Diffusion: finetuning all weights of a pre-trained diffusion model on target distribution 2.

Experimental resultsWe first demonstrate the effectiveness of guidance in Figure 1 under the above setup. Figure 1 (a) plots the source samples, while Figure 1 (b) shows the target samples under different sample sizes \(n=10\), \(100\), \(1000\). Figure 1 (c-e) illustrates the generated target samples via different methods, respectively. It can be seen that the samples generated via the proposed TGDP approach share similar patterns with the target distribution and two mixture components are more obvious as compared with other baseline methods. Furthermore, since the true data distribution of the target domain is known, we calculate the average likelihood of samples generated by each method as demonstrated in Table 1 for quantitative evaluation and comparison.

    &  \\  & n=10 & n=100 & n=1000 \\  Vanilla Diffusion & 0.145 & 0.253 & 0.328 \\ Finetune & 0.290 & 0.329 & 0.335 \\ TGDP & **0.417** & **0.627** & **0.673** \\   

Table 1: Quantitative evaluation of TGDP on simulations. Training on 10K samples from the source domain and \(n=10,100,1000\) numbers on the target domain, respectively. TGDP achieves the highest average likelihood under target distribution.

Figure 1: An illustration of the effectiveness of TGDP on simulations with 10/100/1000 target samples, respectively.

As a sanity check, we also look at the sensitivity of the learned density ratio estimator (through the classifier network (7)) regarding different sizes of target samples. As shown in Figure 2, even with only 10 samples from the target domain (and 10 samples from the source domain for class balance sampling), we can accurately estimate the landscape of density ratio (although the magnitude of the estimated ratio is not entirely accurate when the number of target samples equal 10).

### ECG Data

In this section, we demonstrate the effectiveness of the proposed guidance on the benchmark of electrocardiogram (ECG) data. We first provide the standard synthetic quality and diversity evaluation in Section 4.2.1. Then, we utilize downstream classification tasks to further evaluate the effectiveness of TGDP in Section 4.2.2. We follow the setup of existing benchmarks on biomedical signal processing  that regard PTB-XL dataset  as the source domain and ICBEB2018 dataset  as the target domain. PTB-XL dataset contains 21,837 clinical 12-lead ECG recordings of 10 seconds length from 18,885 unique patients. A 12-lead ECG refers to the 12 different perspectives of the heart's electrical activity that are recorded. Moreover, the PTB-XL dataset is a multi-label dataset with 71 different statements (label). ICBEB2018 dataset  comprises 6877 12-lead ECGs lasting between 6 and 60 seconds. Each ECG record is categorized into one of nine classes, which is a subset of labels in the PTB-XL dataset. We randomly select 10% samples as limited target distribution by stratified sampling preserving the overall label distribution in each fold following . We use the data from PTB-XL dataset and ICBEB2018 dataset at a sampling frequency of 100 Hz, which means 100 samples per second. We include more implementation details in Appendix D.3.

#### 4.2.1 Synthetic Quality and Diversity Evaluation

Baseline methodWe compare TGDP with the following baseline methods to demonstrate the effectiveness of TGDP. 1) Learn a generative model directly _(Vanilla Diffusion)_: The vanilla way is to learn a generative model directly on limited samples from the target domain. 2) Leveraging the pre-trained generative model from source domain _(Finetune Generator)_: Since the label set of the target domain is a subset of that in the source domain, a preliminary solution is to utilize the pre-trained diffusion model to generate samples with labels in the target domain.

Experimental resultsIn Table 2, we compare the generation performance on the target domain using two metrics. The first criterion is the widely used Frechet Inception Distance (FID)  to evaluate the quality of synthetic data, which calculates the Wasserstein-2 distance between the real data and the synthetic data on the feature space. We use the pre-trained classifier on the target domain as the feature extractor, i.e., xresnet1d50 . The second metric is the coverage  that evaluates the diversity of the synthetic data. It is defined as the ratio of real records that have at least one fake (synthetic) record in its sphere. The higher the coverage is, the more diverse the synthetic data are.

From Table 2, we see that TGDP achieves better performance than baseline methods on two criteria, which demonstrates the effectiveness of TGDP on generative transfer learning in scenarios with limited data. Moreover, TGDP has fewer parameters to be trained and less training time. We also demonstrate the T-SNE of the generated ECG data in Figure 3.

#### 4.2.2 TGDP for Downstream Task

In Section 4.2.1, we illustrate that TGDP is capable of generating samples that adhere to the joint distribution of data and labels in the target domain and is diverse enough. In this subsection, we

Figure 2: An ablation study of the sensitivity of density ratio estimator.

further investigate whether utilizing TGDP to acquire a generative model for the target domain yields superior performance compared to existing transfer learning pipelines.

Baseline methodFirst of all, we can utilize the generative model learned in Section 4.2.1 to generate sufficient samples. Incorporated with the original limited sample from the target domain, we can train the classifier, which we still denoted as _Vanilla Diffusion_, _Finetune Generator_, and TGDP, respectively. Moreover, we have the following baseline methods. Directly train a classifier on target domain _(Vanilla Classifier)_: Utilizing the limited data from the target domain, a vanilla classifier can be obtained. Finetune pre-trained classifier _(Finetune Classifier)_: Instead of training a classifier from scratch on the target domain, the parameters of the classifier trained on the source domain are adjusted by using the limited data from the target domain. To verify the effectiveness of the generative model, we demonstrate that it improves the performance of the learned classifier in the following.

Experimental resultsWe adopt the same evaluation criteria as ECG benchmark , i.e., Macro-averaged area under the receiver operating characteristic curve (AUC), Macro-averaged \(F_{}\)-score (\(=2\)), where \(F_{}=)}{(1+^{2} )+^{2}+}\), and Macro-averaged \(G_{}\)-score with \(=2\), where \(G_{}=}{++}\). In Table 3, TGDP outperforms baseline methods across three evaluation criteria, showcasing its effectiveness in transfer for diffusion model with limited data.

## 5 Conclusion

In this work, we propose a novel framework, Transfer Guided Diffusion Process (TGDP), for transferring a source-domain diffusion model to the target domain which consists of limited data. Instead of reducing the finetuning parameters or adding regularization for finetuning, TGDP proves the optimal diffusion model on the target domain is the pre-trained diffusion model on the source domain with additional guidance. TGDP outperforms existing methods on Gaussian mixture simulations and electrocardiogram (ECG) data benchmarks.

   Method & Diversity (\(\)) & FID (\(\)) & Number of Parameters & Training Time \\  Vanilla Diffusion & 0.37 & 11.01 & 50.2M & 1h \\ Finetune Generator & 0.47 & 12.26 & 50.2M & 40min \\ TGDP & **0.53** & **10.46** & **2.8M** & 30min \\   

Table 2: The effectiveness of TGDP on ECG benchmark under synthetic quality and diversity criteria.

Figure 3: T-SNE of the generated ECG data.

   Method & AUC & \(F_{=2}\) & \(G_{=2}\) \\  Vanilla Classifier & 0.906(03) & 0.674(06) & 0.433(06) \\ Finetune Classifier & 0.941(05) & 0.747(08) & 0.521(10) \\  Vanilla Diffusion & 0.932(05) & 0.718(09) & 0.464(09) \\ Finetune Generator & 0.941(04) & 0.761(10) & 0.528(12) \\ TGDP & **0.953**(05) & **0.773**(11) & **0.534**(11) \\   

Table 3: The effectiveness of TGDP on ECG benchmark for downstream task. We provide 95% confidence intervals via empirical bootstrapping used by . 0.906(03) stands for 0.906 Â± 0.003.

Limitations and broader impactOverall, this research presents a promising direction for leveraging pre-trained diffusion models to tackle new tasks. The proposed method, TGDP, has potential applications in a wide range of tasks where domain shift exists. A limitation of this study is the lack of empirical validation regarding TGDP's performance on language vision tasks, which we have earmarked for future exploration. Since we propose a generic algorithm for transferring knowledge to new tasks, this technique could enable people to train Deepfakes for disinformation better. Our approach hinges on the efficacy of detection methods in mitigating negative societal consequences.

## 6 Acknowledgement

Hongyuan Zha was supported in part by the Shenzhen Key Lab of Crowd Intelligence Empowered Low-Carbon Energy Network (No. ZDSYS20220606100601002). Guang Cheng was partially sponsored by NSF - SCALE MoDL (2134209), NSF - CNS (2247795), Office of Naval Research (ONR N00014-22-1-2680) and CISCO and Optum AI Research Grants.