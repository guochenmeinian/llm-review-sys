# A Unified Solution for Privacy and Communication Efficiency in Vertical Federated Learning

Ganyu Wang

Western University

gwang382@uwo.ca

Bin Gu

Jilin University and MBZUAI

jsgubin@gmail.com

Qingsong Zhang

Xidian University

qszhang1995@gmail.com

Xiang Li

Western University

lixiang41@126.com

&Boyu Wang

Western University

bwang@csd.uwo.ca

Charles X. Ling

Western University

charles.ling@uwo.ca

Co-corresponding authors

###### Abstract

Vertical Federated Learning (VFL) is a collaborative machine learning paradigm that enables multiple participants to jointly train a model on their private data without sharing it. To make VFL practical, privacy security and communication efficiency should both be satisfied. Recent research has shown that Zero-Order Optimization (ZOO) in VFL can effectively conceal the internal information of the model without adding costly privacy protective add-ons, making it a promising approach for privacy and efficiency. However, there are still two key problems that have yet to be resolved. First, the convergence rate of ZOO-based VFL is significantly slower compared to gradient-based VFL, resulting in low efficiency in model training and more communication round, which hinders its application on large neural networks. Second, although ZOO-based VFL has demonstrated resistance to state-of-the-art (SOTA) attacks, its privacy guarantee lacks a theoretical explanation. To address these challenges, we propose a novel cascaded hybrid optimization approach that employs a zeroth-order (ZO) gradient on the most critical output layer of the clients, with other parts utilizing the first-order (FO) gradient. This approach preserves the privacy protection of ZOO while significantly enhancing convergence. Moreover, we theoretically prove that applying ZOO to the VFL is equivalent to adding Gaussian Mechanism to the gradient information, which offers an implicit differential privacy guarantee. Experimental results demonstrate that our proposed framework achieves similar utility as the Gaussian mechanism under the same privacy budget, while also having significantly lower communication costs compared with SOTA communication-efficient VFL frameworks.

## 1 Introduction

Federated Learning  is an emerging technique that has raised wide attention recently. It has become one of the most important distributed learning frameworks for enabling multiple data holders to train a model collaboratively without sharing their local privacy data explicitly.

Our research focuses on VFL, where each client possesses all the data points, but only a non-intersecting subset of the features (vertically distributed). In VFL, all participants collaborate to train a single global model. The client trains a feature extraction model that maps its local data sample to embeddings, and the server collects the embeddings from all clients to make a prediction [21; 34; 6; 39; 16; 37; 14; 42; 43; 13].

Ensuring both privacy and computation-communication efficiency is crucial for practical VFL implementations. One common approach to achieve this is starting with a basic VFL [5; 6; 28] and subsequently applying privacy protection techniques, such as Secure Multiparty Computation (SMC) , Differential Privacy (DP) [32; 36], and Homomorphic Encryption (HE) [36; 32] to protect privacy. However, the addition of these protection techniques often increases computation-communication costs. To avoid these costly protective add-ons, research attention has turned to Zero-Order Optimization (ZOO). Literature reports that ZOO-based VFL is able to conceal the internal information of the model (gradient/model parameter) making the SOTA privacy inference attack ineffective . This finding highlights the potential of ZOO for efficient and secure VFL.

However, two critical problems remained. First, the convergence rate of ZOO-based VFL is significantly slower  compared to VFL frameworks optimized with gradient, resulting in a high number of communication rounds and increased communication costs. Furthermore, the convergence rate is negatively correlated to the size of the parameters optimized using ZOO [41; 27; 12], which hinders the application of ZOO-based VFL on large neural networks. Second, although ZO-based VFL has demonstrated resistance to SOTA attacks, its privacy guarantee has not been theoretically explained.

To solve the first problem, we reevaluate the advantages and disadvantages of applying first-order (FO) or zero-order (ZO) gradient methods for each component of the VFL, and find an optimal balance between efficiency and privacy protection. This analysis leads to a novel cascaded hybrid optimization framework that efficiently solves the convergence problems while fully preserving privacy protection. Specifically, our proposed framework (VFL-CZOFO) utilizes the ZO gradient for optimizing the most critical output layer of the clients, while other parts are optimized with the FO gradient2. To address the second problem, we theoretically prove that applying ZOO on VFL is equivalent to adding Gaussian Mechanism  to the gradient information and can provide a corresponding intrinsic (\(,\))-DP guarantee.

For a clear illustration, a schematic diagram of our proposed framework is presented in Figure 1-(c). The advantage of our framework is two-fold. First, it greatly alleviates the slow convergence problem of ZOO-based VFL (Figure 1-b), where our framework's convergence is solely limited by the output size of the clients, rather than the parameter size of the entire model. Second, compared with the FOO-based VFL (Figure 1-a), the connection layer of our framework used ZOO, allowing the backward messages to be solely losses, thus inheriting the privacy protection of the ZOO-based VFL.

The primary innovations of our paper are as follows: 1) Our framework employs a novel cascaded hybrid optimization method, in which different optimization methods are applied to different layers of the global model in each iteration, which significantly improves the convergence rate of ZOO-based VFL while preserving privacy. To the best of our knowledge, no prior research in VFL has proposed a similar method that cascaded a hybrid optimization and exploits its advantages. 2) We provide

Figure 1: Comparing the Asyn-VFL Frameworks

a theoretical explanation of the intrinsic privacy guarantee of ZOO, based on \((,)\)-DP, which is fundamentally different from the common DP mechanism, where noise is added to items afterward.

In summary, the contributions of our paper are:

* We propose the cascade hybrid optimization method in VFL, where ZOO is applied to the most essential part of the VFL, which provides intrinsic privacy protection and significantly improves the convergence rate compared with the ZOO-based VFL.
* Theoretically analysis shows: 1) the intrinsic \((,)\)-differential privacy guarantee provided by ZOO within our framework, 2) the convergence of our framework and its superiority compared with the ZOO-based VFL, 3) the compatibility of communication compression for both forward and backward messages within our framework.
* Extensive experiments show: 1) with the same \((,)\)-differential privacy guarantee, our method can achieve a similar utility as the Gaussian Mechanism, 2) Our method significantly reduces the communication cost compared with the SOTA communication-efficient VFL.

## 2 A Detailed Comparison with SOTA VFL Frameworks

Table 1 presents a comparison of our VFL framework with other SOTA VFL frameworks, including "split-learning" , "compressed-VFL" , "Syn-ZOO-VFL"3, "VAFL" , "ZOO-VFL" . In the table, Asyn/Syn are abbreviations for asynchronous and synchronous. The \(T\) is the iteration of the model. \(d\) and \(d_{h}\) represent the size of the entire global model's parameter and the size of the client's output embeddings, respectively. The "communication size per iteration" column summarizes the number of elements in the original messages before any post-processing, such as compression. \(B\) is the batch size. \(q\) is the sampling times for multiple point estimation of ZOO .

Compared to the FOO-based VFL  our framework has two distinct advantages. First, our framework leverages the intrinsic privacy protection of ZOO, which is a result of its stochastic characteristics and the concealment of internal information. Second, we leverage the advantage of ZOO to reduce the communication cost from the server to the client where the backward message consists of merely \(q\) elements, which is typically significantly smaller than the FO-based VFL with \(d_{h}B\) elements. The key difference between our framework and the FOO-based framework is that our approach reduces communication costs while simultaneously ensuring privacy protection. In contrast, FOO-based VFL typically shares internal information (parameters/gradient)  and then applies for extra privacy protection mechanism .

Compared with the ZOO-based VFL , this framework and ours both leverage the privacy protection of ZOO in VFL. However, ZOO-based VFL suffers from a slow convergence rate of \((d/)\) which is constrained by the global model parameter size \(d\). This hinders its effectiveness when dealing with "larger" networks containing millions of parameters, causing higher communication costs due to increased communication rounds. To address this issue, we applied ZOO to the crucial connection layer between the server and the client. By doing so, we maintained the privacy protection offered by ZOO while significantly mitigating the slow convergence problem, reducing the constraint from the entire global model size \(d\) to merely the output size of the clients \(d_{h}\).

   Framework & Privacy & Asyn/Syn & Optimization & Convergence \(()\) & Comm. Size per Iter. \\  & & & & & (Forward + Backward) \\  Split learning  & ✗ & Syn & FO & \(1/\) & \(d_{h}B\) + \(d_{h}B\) \\ Compressed-VFL  & ✗ & Syn & FO & \(1/\) & \(d_{h}B\) + \(d_{h}B\) \\ VAFL  & ✗ & Asyn & FO & \(1/\) & \(d_{h}B\) + \(d_{h}B\) \\ Syn-ZOO-VFL & ✓ & Syn & ZO & \(d/\) & \(2d_{h}B\) + 1 \\ ZOO-VFL  & ✓ & Asyn & ZO & \(d/\) & \(2d_{h}B\) + 1 \\ VFL-CZOFO (Ours) & ✓ & Asyn & ZO\&FO \(d_{h}/\) & \(d_{h}B\) + \(q\) \\   

Table 1: Compare with Different VFL Algorithm

## 3 Method

Problem DefinitionIn the VFL framework, there is one server and \(M\) clients4. The server holds the label \(y_{i}\) for each sample \(i[n]\), \(([n]\{1,2 n\})\), while each client holds a non-intersecting feature set for all the samples. Specifically, the features for sample \(i\) on client \(m\) are denoted as \(x_{m,i}\). Client \(m\)'s model, \(h_{m}(w_{m};x_{m,i})\), is parameterized by \(w_{m}\) and takes local feature \(x_{m,i}\) as input, outputting the embedding. The server inputs the embeddings from all clients into its own model, which is parameterized by \(w_{0}\), and then calculates the losses for updating the parameters. The VFL framework can be viewed as solving a finite-sum problem in composite form:

\[f(w_{0},;X,Y)=_{i=1}^{n}(w_{0 },h_{1,i},,h_{M,i};y_{i})]}_{f_{i}(w_{0},h_{1,i},,h_{M,i})}\ \ \ \ h_{m,i}=h_{m}(w_{m};x_{m,i})\ \ \  m[M]\] (1)

where \(=[w_{1}, w_{M}]\) denotes the parameter for all clients, \(X\) denotes the entire feature set across all clients, and \(y\) denotes the labels for all samples. For notation brevity, we define the outputs from all clients as \(_{i}()=[h_{1}(w_{1};x_{1,i}),,h_{M}(w_{M};x_{M,i})]=[h_{1, i},,h_{M,i}]\). Therefore, the loss for the \(i\)-th sample5 can be represented as \(f_{i}(w_{0},)\). \((\ \ ;y_{true})\) is the loss function.

Cascaded and Minimal Application of ZOO on the Connection LayerApplying ZOO on VFL resolves the privacy leakage issue from the gradient , but simply applying ZOO to the entire VFL has a slow convergence problem, leading to a high number of communication rounds. Specifically, the major problem of ZOO is that with more dimensions on the gradient that need to be estimated, more variance will be introduced in the estimation of the gradient [27; 3]. This is especially problematic for machine learning scenarios where even relatively small models may have millions of parameters. To address the slow convergence problem of ZOO-based VFL, we precisely apply ZOO to the client's output layer, while the rest of the model utilizes the FO gradient. This approach significantly improves the convergence of the ZOO-based VFL, since only a small portion of the entire model uses ZOO.

ZOO  estimates the gradient of a function by sampling a random perturbation within the function's domain of definition and evaluating its shift on the value domain. To estimate the partial derivative with respect to the output layer of the client's model, we apply the average random gradient estimation (Avg-RandGradEst) [27; 25] which utilizes \(q\) i.i.d. samples \(\{u^{j}_{m,i}\}_{j=1}^{q}\) on the objective function:

\[_{h_{m,i}}f_{i}(w_{0},h_{1,i},,h_{M,i})=})}{q_{m}}_{j=1}^{q}[(h_{m,i}+_{m}u^{j }_{m,i})-f_{i}(h_{m,i})}_{^{}_{m,i}}]u^{j}_{m,i}\] (2)

where \(f_{i}(h_{m,i}+_{m}u_{m,i})\) is the abbreviation for \(f_{i}(w_{0},h_{1,i}, h_{m,i}+_{m}u_{m,i},h_{M,i})\), \(d_{h_{m}}\) is the size of the output layer of client \(m\). \((d_{h_{m}})\) is a dimension-dependent factor  related to the choice of the distribution \(p\) of the random vector \(u^{j}_{m,i}\). If \(p\) is the multivariate uniform distribution \(((,1))\) on a unit sphere centered at \(\) with radius \(1\), then \((d_{h_{m}})=d_{h_{m}}\). If \(p\) is the multivariate normal distribution \((,)\), then \((d_{h_{m}})=1\). \(q\) is the sampling times. The clients cannot calculate \(^{j}_{m,i}\) by themselves because the loss function \(f_{i}()\) is held by the server, therefore the server has to send the \(^{j}_{m,i}\) back to the clients6. To implement multiple-point estimation, the server must transmit multiple distinct values of \(^{j}_{m,i}\) to the client, with the number of values sent equaling the number of sampling points \(q\) used in the Avg-RandGradEst.

The theoretical difficulty in analyzing our framework is that different optimization methods are cascaded within a single model. Unlike most VFL research [34; 5; 28; 6; 41] which updates the global model with a unified optimization method, e.g. \( f_{i}(w_{m})\) (VAFL ) or the \(f_{i}(w_{m})\) (ZOO-VFL ), we apply a cascaded hybrid gradient via chain rule, i.e. \(_{h_{m}}f_{i}(h_{m,i})_{w_{m}}h_{m,i}\), where \(_{h_{m}}f_{i}(h_{m,i})\) is the stochastic gradient estimator of the partial derivative w.r.t. the output layer of the client, and \(_{w_{m}}h_{m}(w_{m})\) is the local gradient of the client.

Compress the CommunicationFurthermore, we demonstrate that compression is compatible with our approach, and can be applied to all communications in the framework, including the forward message  and the backward message . We define the compressor of the client as \(_{m}()\), and the compressor of the server as \(_{0}()\). In each communication round, the client \(m\) sends compressed embeddings instead of the raw message to the server, and the server replies with the compressed messages. We apply the uniform scale compressor  in the experiment. However, other compression schemes such as Top-K , sign-SGD , and lattice quantization  can also be applied to the different parts of our framework to further reduce the message size.

The theoretical challenge in proving the convergence with compression lies in that two errors (forward and backward) are introduced in the analysis. The first error affects the embeddings sent from the client to the server, where the error influences the server's model input, creating uncertainty in the loss value and gradients for updating the parameter. We bound this error by imposing assumptions on the curvature of the loss function, i.e. an upper bound for the norm of the Hessian matrix. The second error affects the message sent from the server to the clients, which then updates using the hybrid gradient with compression error. As a result, there are three different sources of uncertainty in the clients' parameter update: the two mentioned above, as well as the error caused by ZOO.

AlgorithmIn this section, we propose our asynchronous VFL7 with ZOO on the connection layer and compression on the communication messages. Starting with the client, which randomly selects a sample \(i\) and sends its local model output to the server. Receiving the forward message from the client \(m\), the server calculates the \(_{m,i}^{j}\) with Avg-RandGradEst (Eq. 2) and group \(_{m,i}^{j}\) with \(j=1,2,,q\) into a vector \(_{m,i}\). The server compresses \(_{m,i}\) and sends it back to the client. Then the server and client update their local model with the "gradient".

```
0: Learning rate \(_{m}\), smoothing parameter \(_{m}\), compressor \(_{m}\) for \(m\{0,1,...M\}\).
0: Parameter \(w_{m}\) for \(m\{0,1,...M\}\).
0: Initialize model parameter \(w_{m}\) for all participants \(m\{0,1,...M\}\)
1:while not convergent do
2:when a client \(m\) is activated, do:
3: Randomly select a sample \(x_{m,i}\)
4: Compute and send \(_{m}(h_{m}(w_{m};x_{m,i}))\) to server
5: Receive \(_{0}(_{m,i})\) from the server (in a listen manner)
6: Compute \(_{h_{m,i}}_{i}(w_{0},_{i})\) via Avg-RandGradEst (Eq. 2)
7: Compute \(_{w_{m}}h_{m}(w_{m};x_{m,i})\) via backpropagation.
8: Compute \(v_{m}=_{h_{m,i}}_{i}(w_{0},_{i}) _{w_{m}}h_{m,i}\)
9: Update \(w_{m} w_{m}-_{m}v_{m}\)
10:when server receives from client \(m\), do:
11: Compute \(_{m,i}^{l}\) and group into \(_{m,i}\)
12: Send \(_{0}(_{m,i})\) to the client \(m\)
13: Compute \(v_{0}=_{w_{0}}f_{i}(w_{0},_{i})\), (FOO)
14: Update \(w_{0} w_{0}-_{0}v_{0}\)
15:endwhile ```

**Algorithm 1** VFL-CZOFO

## 4 Security Analysis

Threat ModelWe discuss privacy under two scenarios: "honest-but-curious" and "honest-but-colluded". In both scenarios, all participants are assumed to follow the protocol and perform their assigned tasks. Under the "honest-but-curious" scenario, a curious client attempts to obtain private information from other participants using the information they have received. In the "honest-but-colluded" scenario, some participants collude to obtain private information from other participants. The attacker in this scenario can access all information and messages from the colluding participants. In the "honest-but-colluded" scenario, the attacker's capability is either equal to or stronger than in the "honest-but-curious" scenario. This is because the attacker can acquire more information from other participants when colluding, therefore increasing their ability to infer sensitive data.

**Theorem 4.1**.: **Differential Privacy Guarantee of Sharing the ZO Gradient:** Under the "honest-but-colluded" threat model where the attacker can access all information of all clients through the entire training process, including the client's dataset, model, and the ZO gradient received from the server. Under algorithm 1, with \(q\) being sufficiently large, \(\) being the maximum \(l_{2}\)-norm of the partial gradient w.r.t. any client's output through the entire training. If the following condition holds:

\[_{m_{t},s}=T}_{t=0}^{T-1}(_{m_{t}} ^{t})}>}{N}\] (3)

we can derive that sharing the stochastic gradient estimation from the server ensures \((,)\)-DP for all \(,,^{}>0\), where \(=)}+T(e^{} -1)\), \(=T+^{}\).

_Proof sketch:_ The proof can be found in Appendix C.1. Firstly, we establish that each client's update can be modeled with an ideal sequence, where the unbiased parameter is updated with the gradient of the smoothed loss function \(f_{,i}(w_{0}^{t},_{i})=_{}[f_{i} (w_{0},())+]\). Since Avg-RandGradEst in Eq. 2 is an average of \(q\) independently and identically distributed samples from \(f_{i}()\), applying the central limit theorem, the estimated gradient is normally distributed for sufficiently large \(q\). We can then apply the differential privacy guarantee for the Gaussian Mechanism to the estimated gradient. Finally, the accumulated privacy guarantee is derived from the advanced composition theorem.

_Remark 4.2_.: This theorem tells that under the worse case where a strong attacker has obtained all of the ZO information \(_{m,i}\) from all client \(m[M]\), of all sample \(i[N]\), during the entire training process \(t[T]\), the attacker cannot differ a single data point in the dataset, with \((,)\)-DP guarantee.

_Remark 4.3_.: Since the ZO gradient is shared from the server to clients, this theorem mainly provides a privacy guarantee for the label on the server.

_Remark 4.4_.: For a weaker attacker, where the attacker can only access the information from fewer clients ("honest-but-colluded"), or only one client ("honest-but-curious"), the privacy guarantee either remains the same or is strengthened.

Additionally, in Appendix C.2, we provided a detailed discussion of the privacy protection of our approach at the framework level, plus a discussion on the SOTA inference attacks under "honest-but-curious"  and "honest-but-colluded" threat model.

## 5 Convergence Analysis

**Assumption 5.1**.: The formal definition and detailed discussion of the assumptions are in Appendix B. We assume that there is a feasible optimal solution for \(f()\), \( f_{i}()\) is \(L\)-Lipschitz continuous, \(f_{i}()\) has an unbiased gradient, bounded Hessian \(H_{m}\) and bounded block-coordinate gradient \(_{m}\). The activation of the clients is independent, and the client has a uniformly bounded delay \(\).

**Theorem 5.2**.: _Under assumption 5.1, to solve the problem 1 with algorithm 1, the following inequality holds._

\[\!_{t=0}^{T-1}\!\| f(w_{0 }^{t},^{t})\|^{2} (f^{0}-f^{*})}{T}+2 p _{}L_{*}(4d_{}_{*}^{4}+_{*}^{2}L_{*}^{2}d_{*}^{2} _{*}^{2}+2_{0}^{2})\] \[+7^{2}p_{}_{*}^{2}(4d_{} _{*}^{2}+_{*}^{2}L_{*}^{4}d_{*}^{2}+2L_{*}^{2})\] \[+_{*}^{2}p_{}L_{*}^{2}d_{*}^{2}_{*}^{2}+ p_{}H_{*}^{2}(6+16_{*}^{2})+17 p_{ }_{*}^{2}\]

_where \(L_{*}=_{m}\{L,L_{0},L_{m}\}\), \(_{0}=_{m}=\), \(}=_{m}p_{m}\), \(_{*}=_{m}\{_{m}\}\), \(d_{*}=_{m}\{d_{h_{m}}\}\), \(_{*}=_{m}\{_{0},_{m}\}\), \(H_{*}=_{m}\{H_{0},H_{m}\}\), \(\) and \(\) are the upper bound for the square of the norm of the forward and backward compression error respectively. \(T\) is the total number of iterations (communication rounds)._

_Remark 5.3_.: If we choose \(=}\) and \(_{*}=}\). Design the compression to make \(=(})\) and \(=(})\) we can derive:

\[\!_{t=0}^{T-1}\!\| f(w_{0}^{t}, ^{t})\|^{2}=(}{})\]where \(d_{h}=_{m}\{d_{h_{m}}\}\) is the maximum output layer size of the clients.

_Remark 5.4_.: This theorem proves that we significantly relieve the slow convergence problem of ZOO-based VFL  from \((})\) to \((}{})\).

## 6 Experiment

We conducted a systematic experiment on the SOTA and baseline VFL and our proposed framework. The primary objective of our study was to empirically validate the security measures of our approach and demonstrate its capability in reducing communication overhead. Furthermore, we conducted an ablation study to quantify the contributions of each component toward improving communication efficiency. Due to space limitations, extra experiment details, the CIFAR-10 experiments, extra experiments on less common datasets, and extra experiments on other aspects of our framework have been placed in appendix E. The source code for this project is available at the following URL: https://github.com/GanyuWang/VFL-CZOFO.

### Experiment Setups

DatasetsThe datasets were vertically partitioned among all participants in our experiments. Each client held a portion of the features of each sample, while the server held the corresponding labels. Both the server and the client kept the sample IDs during training. We utilized two datasets in our main experiments: MNIST  and CIFAR-10 . For both datasets, we employed two clients in our experiments, with each client being responsible for half of the images8 in the respective dataset. Therefore, we denoted these datasets as dist-MNIST and dist-CIFAR-10.

ModelsIn our dist-MNIST experiment, we implemented a multilayer perception (MLP). Each client utilized a one-layer Fully Connected Layer (FCL), with an input size equal to the flattened local data input size, and an output size of 64. The server employed a two-layer FCL. The first layer concatenated all the outputs from all clients and produced embeddings with 128 neurons. The second layer outputs 10 neurons for prediction. ReLU  was used as the activation function for the server and clients. Practically, the server kept a table of the outputs from all clients for all of the samples, i.e. \(_{i}^{t}=[h_{1}(w_{1}^{t-_{1,i}^{t}};x_{1,i}),,w_{M}^{t- _{M,i}^{t}}]\) was maintained by the server. The server updated the corresponding value in the table when it received \(h_{m}(w_{m}^{t-_{m,i}^{t}};x_{m,i})\) from client \(m\) during each communication round. The clients' outputs from the table were then used for prediction. Regarding the dist-CIFAR-10 dataset, each client padded its half-image to full size and trained a ResNet-18 . The server then summed the outputs from all the clients.

Frameworks for ComparisonWe compare our framework with other SOTA VFL frameworks including "split-learning" , "compressed-VFL" , "Syn-VFL-ZO"9, "VAFL" , "ZOOVFL" . All frameworks utilized identical base models and training procedures. While some frameworks also introduced alternative VFL settings, e.g. server and clients both processing the labels, we only focus on the VFL setting where the server stores the labels and multiple clients possess non-intersecting features.

Training ProceduresFor the experiment applying the split MLP model on dist-MNIST, a batch size of 64 was utilized, and the model was trained for 100 epochs. For the experiment applying the ResNet-18 on dist-CIFAR-10, a batch size of 128 was used, and the model was trained for 50 epochs. The learning rate \(\) was chosen from \([0.1,0.01,0.001,]\), and \(\) for ZOO was chosen from \([1,0.1,0.001,0.0001,]\). We use a uniform scale compressor  on the forward and backward messages with different compression bits \(\). The number of sampling \(q\) used for Avg-RandGradEst in the dist-MNIST experiment was set to \(\), while in the dist-CIFAR-10 experiment, it was set to either \(\). The sampling distribution is \(((,1))\). We used a vanilla SGD with a fixed learning rate for all VFL frameworks to ensure a fair comparison. The reported test accuracy values in the tables have been obtained from five independent runs.

### Evaluation on the Privacy Protection

In this part, we evaluate the privacy protection of our method and Gaussian Mechanism. The major difference between the ZOO and Gaussian Mechanism in DP is that the variance of the stochastic gradient estimation (ZOO) is intrinsically controlled by the hyper-parameter of the ZOO and the characteristic of the objective function, while in the Gaussian Mechanism, the variance is a parameter that directly controls the magnitude of the noise added.

We obtain the DP guarantee w.r.t. the sampling times of ZOO in the dist-MNIST experiment and report the result in Table 2. We estimate \(^{2}\) by freezing the model and repeatedly applying Eq.2 \(100\) times, then calculating the variance of the estimated gradients. We obtain the maximum gradient norm \(\) by recording the norm throughout the entire training process10. We set \(=10^{-6}\) and calculate \(\) based on the given sampling times \(q\). The iteration \(T\) was set to the total iteration of 50 epochs, which is \(93800\).

In the second part, we compared the utility of our framework with the VAFL using the Gaussian Mechanism and gradient clipping  on the partial derivative w.r.t. the client's output with the corresponding \((,)\)-DP. We set the gradient norm clipping bound to \(0.1\) And we plotted the training accuracy for each epoch in Figure 2. As illustrated in the figure, our scheme exhibits comparable utility to VAFL with the same privacy guarantee.

### Evaluation of Training Efficiency and Communication Cost

In this part, we compare our framework with SOTA VFL in the effectiveness of training and communication efficiency. We apply the best tuning for all other frameworks with respect to test accuracy and communication efficiency. (The experiment for dist-CIFAR-10 is in Appendix E.3)

Figure 3-(a) demonstrates that our VFL-CZOFO framework has the fastest convergence rate comparable to VAFL, demonstrating the superiority of our cascade hybrid optimization method. It is worth noting that the pure-ZOO-based VFL suffers from a slower convergence compared to other frameworks, even with an MLP model. Figure 3-(b) plots the total communication cost against the training accuracy, where the crosses indicate the point where the curve reaches 95% training accuracy for MNIST. It shows that our VFL-CZOFO framework achieves the same level of convergence with much lower communication costs.

Table 3 report the important statistic about the training. As shown in the table, our framework significantly outperforms other communication-efficient frameworks in terms of communication cost.

   \(q\) & \(^{2}\) & \(\) & \(\) & \(\) & \(^{}\) & \(\) & \(\) \\ 
10 & 1.61 & 20.1 & \(10^{-6}\) & \(2.8 10^{-3}\) & \(10^{-6}\) & 85.9 & \(9.4 10^{-2}\) \\
100 & 0.15 & 7.3 & \(10^{-6}\) & \(3.3 10^{-3}\) & \(10^{-6}\) & 93.6 & \(9.4 10^{-2}\) \\   

Table 2: Sampling Times of Avg-RandGradEst and the Corresponding Differential Privacy Guarantee

Figure 3: Compare with other VFL Frameworks

Figure 2: The Utility Comparing with the VAFL with Gaussian Mechanism

[MISSING_PAGE_EMPTY:9]

## 7 Limitation

While the utilization of ZOO improves communication efficiency and security, it comes at the expense of increased computational costs for the server. Specifically, the server needs to perform \(q\) extra forward propagations on its local model compared to other FOO-based VFL methods. A more comprehensive analysis and supplementary experiments can be found in Appendix E.2. However, it is important to note that the server typically has higher computational capabilities, which makes the associated costs manageable and acceptable.

## 8 Conclusion

We propose a solution in VFL that improves communication efficiency and privacy simultaneously. Our method has been theoretically proven to outperform ZOO-based VFL in terms of convergence, while also providing proof of the intrinsic differential privacy guarantees. Through our experiments, we demonstrate that our method substantially reduces the communication cost of VFL in comparison to the state-of-the-art communication-efficient VFL. Furthermore, our method achieves comparable utility to VFL models that offer the same level of privacy guarantee.