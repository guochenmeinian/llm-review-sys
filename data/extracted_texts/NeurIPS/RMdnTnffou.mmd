# Coarse-to-Fine Concept Bottleneck Models

Konstantinos P. Panousis\({}^{1,2,5}\)1 Dino Ienco\({}^{1,2,3,4}\)1 Diego Marcos\({}^{1,2}\)1

\({}^{1}\)Inria

University of Montpellier

Inrae

UMR TETIS

Department of Statistics, AUEB panousis@aueb.gr

diego.marcos@inria.fr

dino.ienco@inrae.fr

###### Abstract

Deep learning algorithms have recently gained significant attention due to their impressive performance. However, their high complexity and un-interpretable mode of operation hinders their confident deployment in real-world safety-critical tasks. This work targets _ante hoc_ interpretability, and specifically Concept Bottleneck Models (CBMs). Our goal is to design a framework that admits a highly interpretable decision making process with respect to human understandable concepts, on _two levels of granularity_. To this end, we propose a novel two-level concept discovery formulation leveraging: (i) recent advances in vision-language models, and (ii) an innovative formulation for _coarse-to-fine concept selection_ via data-driven and sparsity-inducing Bayesian arguments. Within this framework, concept information does not solely rely on the similarity between the _whole_ image and general unstructured concepts; instead, we introduce the notion of _concept hierarchy_ to uncover and exploit more granular concept information residing in patch-specific regions of the image scene. As we experimentally show, the proposed construction not only outperforms recent CBM approaches, but also yields a principled framework towards interpretability.

## 1 Introduction

The recent advent of foundation models has greatly popularized the deployment of deep learning approaches to a variety of tasks and applications. However, in most cases, deep architectures are treated in an alarming _black-box_ manner: given an input, they produce a particular prediction, with their mode of operation and complexity preventing any potential investigation of their decision-making process. This property not only raises serious questions concerning their deployment in safety-critical applications, but at the same time, it could actively preclude their adoption in settings that could otherwise benefit societal advances, e.g., medical applications.

This conspicuous _shortcoming_ of modern architectures has fortunately gained a lot of attention from the research community in recent years, expediting the design of novel frameworks towards deep learning interpretability. Within this frame of reference, there exist two core approaches: _ante_ and _post_ hoc. The latter aims to provide _explanations_ to conventional pretrained models, e.g., Network Dissection , while the former aims to devise _inherently_ interpretable models. In this context, Concept Bottleneck Models (CBMs) constitute one of the best-known approaches ; these comprise: (i) an intermediate Concept Bottleneck Layer (CBL), a layer whose neurons are tied to human understandable _concepts_, e.g., textual descriptions, followed by (ii) a linear decision layer. Thus, the final decision constitutes a linear combination of the CBL's concepts, leading to a more interpretable decision mechanism. However, typical CBM approaches are accompanied by four significant drawbacks: (i) they commonly require hand-annotated concepts, (ii) they usually exhibitlower performance compared to their non-interpretable counterparts, (iii) their interpretability is substantially impaired due to the sheer amount of concepts that need to be analysed during inference, and (iv) they are not suited for tasks that require greater granularity.

The first drawback has been recently addressed by incorporating vision-language models in the CBM pipeline; instead of relying on a fixed concept set, images and text can be projected in the common embedding space and compared therein. Mechanisms to restore performance have also been proposed, e.g., residual fitting . The remaining two limitations however, still pose a significant challenge.

Indeed, CBMs commonly rely on a large amount of concepts, usually proportional to the number of classes of the given task; with more complex datasets, thousands of concepts may be considered. Evidently, this renders the investigation of the decision making task an _arduous_ and _unintuitive_ process. In this context, some works aim to reduce the amount of used concepts by imposing sparsity constraints upon concept activation. Commonly, post-hoc class-wise sparsity methods are considered [22; 13]; however, these tend to restrict the number of concepts on a _per-class_ basis, enforcing _ad hoc_ application-specific sparsity/performance thresholds, greatly limiting the flexibility of concept activation for each example. Recently, a data-driven per-example discovery mechanism has been proposed in ; this leverages binary indicators that explicitly denote the relevance of each concept towards the downstream task on a per-example basis, thus allowing for greater flexibility.

Even though these approaches aim to address the problem of concept over-abundance, they do not consider ways to emphasize finer concept information that may be present in a given image; they still exclusively target similarity between concepts and the _whole image_. In this setting, localized, low-level concepts (e.g., shape or texture), are predicted from a representation of the whole image, potentially leading to the undesirable use of top-down relations. For instance, the model detects some high-level concept (e.g., elephant), resulting in associated lower-level concept activations (e.g., tasks, wrinkled skin) that may not even be actually be visible. This can further lead to significant concept omission, i.e., information potentially crucial for tasks that require greater granularity, e.g., fine-grained part discovery, or even cases where the input is susceptible to multiple interpretations.

Drawing inspiration from this inadequacy of CBM formulations, we introduce a novel coarse-to-fine paradigm that allows for discovering and capturing both _high_ and _low_ level concept information. We achieve this objective by devising an end-to-end trainable hierarchical construction; in this setting, we exploit both the whole image, as well as information residing in individual isolated regions of the image, i.e., specific patches, to achieve the downstream task. These levels are linked together by intuitive and principled arguments, allowing for information and context sharing between them, paving the way towards more interpretable models. We dub our approach _Coarse-to-Fine Concept Bottleneck Models_ (CF-CBMs); in principle, our framework allows for arbitrarily deep hierarchies using different representations, e.g., super-pixels. Here, we focus on the two-level setting, as a proof of concept for the potency of the proposed framework. Our contributions can be summarized as:

* We introduce a novel interpretable hierarchical model that allows for coarse-to-fine concept discovery, exploiting finer details residing in patch-specific regions of an image.
* We propose a novel way of assessing the interpretation capacity of our model based on the Jaccard index between ground truth concepts and learned data-driven binary indicators.
* We experimentally show that CF-CBMs outperform other SOTA approaches classification-wise, while substantially improving interpretation capacity.

## 2 Related Work

**Concept Bottleneck Models.** Let us denote by \(=\{_{n},}_{n}\}_{n=1}^{N}\), a dataset comprising \(N\) image/label pairs, where \(_{n}^{I_{H} I_{W} c}\) and \(}_{n}\{0,1\}^{C}\). Within the context of CBMs, a _concept set_\(A=\{a_{1},,a_{H}\}\), comprising \(H\) concepts, e.g., textual descriptions, is also considered; the main objective is to re-formulate the prediction process, constructing a _bottleneck_ that relies upon the considered concepts, in an attempt to design inherently interpretable models. In this context, early works on concept-based models [11; 9], were severely limited by requiring an extensive hand-annotated dataset comprising all the used concepts. To enhance the reliability of predictions of diverse visual contexts, probabilistic approaches, such as ProbCBM , introduce the concept of _ambiguity_, allowing for capturing the uncertainty both in concept and class prediction. The appearance of vision-language models, chiefly CLIP , has mitigated the need for hand-annotated data, allowing to easily make use of thousands of concepts, followed by a linear operator on the concept similarity to solve the downstream task [13; 24]. However, this generally means that all concepts may simultaneously contribute to a given prediction, rendering the analysis of concept contribution an arduous and counter-intuitive task, severely undermining the sought-after interpetability. This has led to methods that seek a sparse concept representation, either by design  or data-driven  perspectives.

**Concept-based Classification.** To discover the relations between images and attributes, vision-language models, e.g., CLIP , are typically considered. These comprise an image and a text encoder, denoted by \(E_{V}()\) and \(E_{T}()\) respectively, trained in a contrastive manner [20; 2] to learn a common embedding space. After training, we can then project any image and text in this common space and compute the similarity between their (\(_{2}\)-normalized) embeddings. Assuming a concept set \(A\), with \(|A|=H\), the most commonly considered measure is the cosine similarity \(\):

\[ E_{V}()E_{T}(A)^{T}^{N H}\] (1)

This _similarity-based characterization_ yields a unique representation for each image and has recently been exploited to design models with interpretable decision processes such as CBM-variants [25; 13] and Network Dissection approaches[14; 15]. Within this context, let us consider a \(C\)-class classification setting; by introducing a linear layer \(_{c}^{C H}\), we can perform classification via the similarity representation \(\). The output of such a network yields:

\[=_{c}^{T}^{N C}\] (2)

The image/text encoders are typically kept frozen; training only pertains to the weight matrix \(_{c}\).

However, this formulation comes with a key deficit: it is by-design limited to the granularity of the concepts that it can potentially discover in any particular image. Indeed, VLMs are commonly trained to match concepts to the _whole image_; this can lead to a _loss of granularity_, that is, important details may be either omitted or considered irrelevant. Yet, in complex tasks such as fine-grained classification or in cases where the decision is ambiguous, this can potentially hinder both the downstream task, but also interpretability. In these settings, it is likely that any low-level information present is not exploited, hindering any potential low-level investigation on the network's process. Moreover, this approach considers the _entire concept set_ to describe an input; this not only greatly limits the flexibility of the considered framework, but also renders the interpretation analyses questionable due to the sheer amount of concepts that need to be analysed during inference . In this work, we take a step beyond the classical definition of CBMs and consider the setting of _coarse-to-fine_ concept-based classification based on similarities between images, patches and concepts.

## 3 Coarse-to-fine CBM

To construct our proposed CF-CBM framework, we first introduce two distinct modeling _levels_: _High (H)_ and _Low (L)_. The _High_ level aims to model the whole image, while the _Low_ level investigates and aggregates information stemming from localized regions. At the outset, we define these levels as separate modules that can be individually used towards a downstream task using some _independent_ concepts sets \(A_{H}\) and \(A_{L}\); intuitively, the former should comprise descriptions that characterize the main scenes/objects in the considered dataset, e.g., an ImageNet class name, such as _Arctic Fox_, while the latter, descriptions that are inferrable from localized regions of the image, e.g., characteristics of parts of the animal or the background.

Then, we present the notion of _hierarchy_ of concepts. Specifically, we introduce _interdependence_ between the sets to capture information in a coarse-to-fine-grained manner; in this setting, the concepts \(A_{H}\) encapsulate concepts that characterize each image, in turn determining the _allowed subset_ of concepts from the low-level concept pool \(A_{L}\). Essentially, the concepts in \(A_{H}\) capture a holistic representation of the image, while the low-level, their sub-characteristics, delving deeper into patch-specific regions, aiming to uncover finer-grained information. Each level aims to achieve the given downstream task, while information sharing takes place between them as we describe next.

### High Level Concept Discovery Module

For the formulation of the _High Level_ view of our CF-CBM model, we consider: (i) the whole image, (ii) a set of \(H\) concepts \(A_{H}\), and exploit the definitions of concept-based classification, i.e., Eqs. (1)(2). To this end, we introduce a single linear layer with weights \(_{}^{C H}\), yielding:

\[_{}  E_{V}()E_{T}(A_{})^{T}^{N  H},\] (3) \[_{} =_{}_{}^{T}^{N C}\] (4)

Evidently, this formulation, fails to take into account the relevance of each concept towards the downstream task or any information redundancy, since all the considered concepts are potentially used; this also limits its emerging interpretation capacity due to the large amount of concepts that need to be analysed during inference. To bypass this drawback, we consider a novel, data-driven mechanism for concept discovery based on auxiliary _binary_ latent variables.

**Concept Discovery.** To discover the subset of high-level concepts present in each example, we introduce the auxiliary binary latent variables \(_{}\{0,1\}^{N H}\); these operate in an "on-off" fashion, indicating, for each example, if a given concept needs to be considered to achieve the downstream task, i.e., \([_{}]_{n,h}=1\) if concept \(h\) is _active_ for example \(n\), and \(0\) otherwise. The output of the network is now given by the inner product between the classification matrix \(_{}\) and the _discovered concepts_ as dictated by the binary indicators \(_{}\):

\[_{}=(_{}_{})_{ }^{T}^{N C}\] (5)

A naive definition of these indicators would require computing and storing one indicator per example. To avoid the computational complexity and generalization limitations of such a formulation, we consider an _amortized_ approach similar to . To this end, we introduce a data-driven random sampling procedure for \(_{}\), and postulate that the latent variables are drawn from appropriate Bernoulli distributions; specifically, their probabilities are proportional to a separate linear computation between the _embedding of the image_ and an _auxiliary linear layer_ with weights \(_{}^{H K}\), where \(K\) is the dimensionality of the embedding, yielding:

\[q([_{}]_{n})=([_{}]_{n} |(E_{V}(_{n})_{}{}^{T} ))\] (6)

where \([]_{n}\) denotes the \(n\)-th row of the matrix, i.e., the indicators for the \(n\)-th image. This formulation exploits an _additional source of information_ emerging solely from the image embedding; this allows for an _explicit_ mechanism for inferring concept activation in the context of the considered task, instead of exclusively relying on the _implicit_ VLM similarity. The described process is encapsulated in what we call a Concept Discovery Block (CBD); this is illustrated in Fig.1 (Left and Upper Right).

### Low Level Concept Discovery Module

Here, we present a variant of the described architecture that aims to individually exploit finer information potentially present in the image. In this setting, re-using the whole image may hinder concept discovery since fine-grained details may be ignored; prominent objects may dominate the discovery task, especially in complex scenes, while omitting other significant attributes present in different regions of the image.

To facilitate the discovery of low-level information, avoiding conflicting information in the context of whole image, we split each image \(n\) into a set of \(P\)_non-overlapping_ patches: \(_{n}=\{_{n}^{1},,_{n}^{P}\}\), where \(_{n}^{p}^{P_{} P_{} c}\) and \(P_{H},P_{W}\) denote the height and width of each patch respectively, and \(c\) is the number of channels. In this context, each patch is now treated as a standalone image. To this end, we first compute their similarities with respect to a set of low-level concepts \(A_{L}\). For each image \(n\) split into \(P\) patches, the patches-concepts similarity computation reads:

\[[_{L}]_{n} E_{V}(_{n})E_{T}(A_{L})^{T}^{P  L}, n\] (7)

We define a single classification layer with weights \(_{}^{C L}\), while for obtaining a single representation vector for each image, we introduce an _aggregation_ operation to combine the information from all the patches. This can be performed before or after the linear layer. Here, we consider the latter, using a maximum rationale. Thus, for each image \(n\), the output \([_{L}]_{n}^{C}\), reads:

\[[_{L}]_{n}=_{p}[[_{L}]_{n}_{}^{T} ]_{p}^{C}, n\] (8)

where \([]_{p}\) denotes the \(p\)-th row of the matrix. Similar to the high-level, we define the corresponding concept discovery mechanism for the low level to address information redundancy; then, we introduce an information linkage between the different levels towards context sharing between them.

**Concept Discovery.** For each patch \(p\) of image \(n\), we consider latent variables \([_{L}]_{n,p}\{0,1\}^{L}\), operating in an "on"-"off" fashion as before. Specifically, we introduce an amortization matrix \(W_{Ls}^{L K}\), \(K\) being the dimensionality of the embeddings. In this setting, \([_{L}]_{n,p}\) are drawn from Bernoulli distributions driven from the patch embeddings, s.t.:

\[q([_{L}]_{n,p})=([_{L}]_{n,p}|(E_{V}([]_{n,p})_{Ls}{}^{T}))\] (9)

The output is now given by the inner product between the _discovered low level concepts_ as dictated by \(_{L}\) and the weight matrix \(_{Lc}\), yielding:

\[[_{L}]_{n}=_{p}[([_{L}]_{n}[_{L}]_{n} )_{Lc}{}^{T}]_{p}^{C},\; n\] (10)

The formulation of the low-level, patch-focused variant is now concluded. This module can be used as a standalone network to uncover information residing in patch-specific regions of an image and investigate the network's decision making process as shown in Fig.1 (Lower Right). However, by slightly altering its definition, we can straightforwardly introduce a linkage between the two described levels, allowing the flow of information between them.

### Linking the two levels

For formulating a finer concept discovery mechanism, we introduce the notion of _concept hierarchy_. In this setting, we do not assume individual concepts sets, but instead posit that _each_ high-level concept in \(A_{H}\) is characterized by \(L\) low-level attributes, such that \(|A_{L}|=H L\). For tying the two different levels together, we augment the dimension of the low level module to account for this modification, and exploit the resulting latent variables \(_{H}\) and \(_{L}\) to devise a novel way of deciding which low-level attributes should be considered according to the active high level concepts dictated by \(Z_{H}\); this allows for context exchange between the two levels and end-to-end training.

The underlying principle is that we can now _mask_ the low-level concepts, i.e., _zero-out_ the ones that are irrelevant, following a top-down rationale. During training, we learn which high-level concepts are active, and subsequently discover the essential low-level attributes, while the probabilistic nature of our construction allows for the consideration of different configurations of high and low level concepts. This leads to a rich information exchange between the levels of the network towards achieving the downstream task.

To formalize this linkage, we first consider which high-level concepts are active via \(_{H}\) to uncover which low-level attributes should be considered; then, we use the augmented indicators \(_{L}\) to further

Figure 1: (Left) The Concept Discovery Block (CDB). Given a set of concepts and an image, we compute their similarity via a VLM; we consider a data-driven mechanism for concept discovery, sampling from an amortized Bernoulli posterior. (Right) A schematic of the envisioned CF-CBMs. We consider a set of high level concepts, each described by a number of attributes; this forms the _pool_ of low-level concepts. Our objective is to discover concepts that describe the whole image, while exploiting information residing in, in this case \(P=9\), patch-specific regions by matching low-level concepts to each patch and aggregate the information to obtain a single representation. Each level comprises CDBs, while the levels are linked together via the binary indicators \(_{H}\) and \(_{L}\).

mask the remaining low-level attributes according to the values therein. This yields:

\[[Z]_{n,p}_{h}[Z_{H}]_{n,h}[Z_{L}]_{n,p,h,:}\{0,1\}^{L}\] (11)

Thus, by replacing the indicators \(_{L}\) in Eq. (10) with \(\), the two levels are linked together and can be trained in an end-to-end fashion. A graphical illustration of this linkage and the proposed Coarse-to-Fine CBM (CF-CBM) is depicted on Fig. 1 (Middle Right) and (Right) respectively. The introduced framework can easily accommodate more than two levels of hierarchy, while allowing for the usage of different input representations, e.g., super-pixels.

### Training & Inference

**Training.** Considering a dataset \(=\{(_{n},}_{n})\}_{n=1}^{N}\), we employ the standard cross-entropy loss, denoted by \(}_{n},f(_{n},)\), where \(f(_{n},)=([]_{n})\) are the class probabilities. For the simple concept-based model, i.e., without any discovery mechanism, the logits \([]_{n}\) correspond to either \([_{H}]_{n}\) (Eq.(4)), or \([_{L}]_{n}\) (Eq.(8)), depending on the considered level. In this context, the only trainable parameters are the classification matrices for each level, i.e., \(_{Hc}\) or \(_{Lc}\).

For the full model, the presence of the indicator variables, i.e., \(_{H}\) and/or \(_{L}\), necessitates a different treatment of the objective. To this end, and in line with recent literature [16; 17], we turn to the Variational Bayesian (VB) framework, and specifically to Stochastic Gradient Variational Bayes (SGVB) . We impose appropriate prior distributions on the latent indicators \(_{H}\) and \(_{L}\), s.t.:

\[_{H}(_{H}),_{L}(_{L})\] (12)

where \(_{H}\) and \(_{L}\) are non-negative constants. When the levels are linked together, the model comprises two outputs, and thus, the loss function consists of two distinct CE terms: (i) one for the high, and (ii) one for the low level. The objective function takes the form of an Evidence Lower Bound (ELBO) provided in the Appendix. Obtaining the objective for a single level is trivial; one only needs to remove the other level's terms. For training, we turn to Monte Carlo (MC) sampling using a single reparameterized sample for each latent variable. Since, the Bernoulli is not amenable to the reparameterization trick , we turn to its continuous relaxation, i.e., the Gumbel-Softmax trick [10; 6]; we present the exact sampling procedure in the appendix.

**Inference.** After training, we can directly draw samples from the learned posteriors and perform inference. However, the stochastic nature of the indicators could potentially lead to multiple interpretations for the same input when drawing different samples. Commonly, there are two approaches to address this issue in the VB community: (i) draw multiple samples and average the results, or (ii) directly use the mean as an approximation to the aforementioned process; here, we opt for the latter. In our framework, the binary indicators are modeled via a Bernoulli distribution; thus, the mean corresponds to the probability of a concept being active for a particular example. Within this context, we can further introduce an interpretable threshold \(\); if the probability of a particular concept is greater than \(\), we consider it to be active, i.e., its indicator has a value of one, and zero otherwise. We use this formulation during inference, obtaining a single sparse interpretable representation for each image.

## 4 Experimental Evaluation

**Experimental Setup.** We consider three benchmark datasets for evaluating the proposed framework, namely, CUB, SUN, and ImageNet-1k. These constitute highly diverse datasets varying in both number of examples and applicability: ImageNet is a \(1000\)-class object recognition benchmark, SUN comprises \(717\) classes with a limited number of examples for each, while CUB is used for fine-grained bird species identification spanning \(200\) classes. For the VLM, we turn to CLIP  and select a common backbone, i.e., ViT-B/16. To avoid having to calculate the embeddings of both images/patches and text at each iteration, we pre-compute them with the chosen backbone. Then, during training, we load them and compute the necessary quantities. For the high level concepts, we consider the class names for each dataset. For the low-level concepts, for Imagenet, we randomly select \(20\) concepts for each class from the concept set described in  while for SUN and CUB, we exploit a per-class summary of the included attributes comprising \(102\) and \(312\) descriptions respectively. Since these are shared among classes and the number of active attributes differ for each class, we devise an efficient alternative linkage formulation to accommodate this setting; this is provided in the Appendix. These distinct sets enables us to assess the efficacy of the proposed framework in highly diverse configurations. We use \(P=16\) patches and set \(=0.05\); this translates to a concept being active for the input only if it has probability of being active greater than 5%. We observed no significant variation when using smaller values. Larger values translate to fewer concepts being active, despite having significant activation probability before thresholding. We consider both classification accuracy, as well as the capacity of the proposed framework towards interpretability.

**Accuracy.** We begin our experimental analysis by assessing both the classification capacity of the proposed framework, but also its _concept sparsification_ ability. To this end, we consider: (i) a baseline non-interpretable backbone, (ii) the recently proposed SOTA Label-Free CBMs , (iii) classification using only the clip embeddings either of the whole image (CLIP Embeddings\({}^{}\)) or the image's patches (CLIP Embeddings\({}^{}\)), (iv) classification based on the similarity between images and the _whole_ concept set (CDM\({}^{}\)\(\)discovery), and (v) the approach of  that considers a data-driven concept discovery mechanism only on the whole image (CDM\({}^{}\)\(\) discovery). We also consider the proposed patch-specific variant of CDMs defined in Sec. 3.2, denoted by CDM\({}^{}\). The baseline results and the Label-Free CBMs are taken directly from . We denote our framework as CF-CBM.

In this setting, CLIP\({}^{}\) and CDM\({}^{}\) consider the concept set \(A_{H}\), while patch-focused models, i.e., CLIP\({}^{}\) and CDM\({}^{}\), solely consider the low-level set \(A_{L}\). Here, it is worth noting that the CDM\({}^{}\)-setting corresponds to a variant of the full CF-CBM model, where all the high level concepts are active; thus, all attributes are considered in the low-level with no masking involved. In this case, since the binary indicators \(_{H}\) are not used, there is no information exchange taking place between the levels; this serves as an ablation setting of the impact of the information linkage. The obtained comparative results are depicted in Table 1. Therein, we observe that the proposed framework exhibits highly improved performance compared to Label-Free CBMs, while on par or even improved classification performance compared to the concept discovery-based CDMs on the high-level. On the low level, our approach improves performance up to \( 20\%\) compared to CDM\({}^{}\).

At this point, it is important to highlight the effect of the hierarchical construction and the linkage of the levels to the overall behavior of the network. In all the considered settings, we observe: (i) a drastic improvement of the classification accuracy of the low-level module, and (ii) a significant change in the patterns of concept discovery on both levels. We posit that the information exchange that takes place between the levels, conveys a _context_ of the relevant attributes that should be considered. This is reflected both to the capacity to improve the low-level classification rate compared to solely using the CLIP\({}^{}\) or CDM\({}^{}\), but also on the drastic change of the concept retention rate of the low level. At the same time, the patch-specific information discovered on the low-level alters the discovery patterns of the high-level, since potentially more concepts should be activated in order to successfully achieve the downstream task. This behavior is extremely highlighted in the ImageNet case: our approach not only exhibits significant gains compared to the alternative concept-based CDM on the high-level, but also the low-level accuracy of our approach _outperforms_ it by a large margin. These first investigations hint at the capacity of the proposed framework to exploit patch-specific information for improving performance on the considered downstream task.

**Attribute Matching.** Even though classification performance constitutes an important indicator of the overall capacity of a given architecture, it is not an appropriate metric for quantifying its behavior within the context of interpretability. To this end, and contrary to recent approaches that

   &  &  &  &  \\   & & & &  &  &  \\   & Baseline (Images) & ✗ & ✗ & \(76.70\) & \(42.90\) & \(76.13\) \\ Non-Interpretable & CLIP Embeddings\({}^{}\) & ✗ & ✗ & \(81.90\) & \(65.80\) & \(79.40\) \\  & CLIP Embeddings\({}^{}\) & ✗ & ✗ & \(47.80\) & \(46.00\) & \(62.85\) \\    & Label-Free CBMs (Ours) & ✓ & ✓ & \(74.59\) & \(-\) & \(71.98\) \\  & CDM\({}^{}\) & ✓ & ✗ & \(80.30\) & \(66.25\) & \(75.22\) \\  & CDM\({}^{}\) & ✓ & ✓ & \(78.09||19.00\) & \(64.55||13.00\) & \(76.55||14.00\) \\  & CF-CBM\({}^{}\) (Ours) & ✓ & ✓ & \(79.50||50.00\) & \(64.00||47.58\) & \(||27.20\) \\   ^{}\) (Ours)} & ✓ & ✗ & \(39.05\) & \(37.00\) & \(49.20\) \\  & CDM\({}^{}\) & ✓ & ✓ & \(59.62||58.00\) & \(42.30||67.00\) & \(58.20||25.60\) \\   & CDM\({}^{}\) & ✓ & ✓ & \(|29.80\) & \(|28.33\) & \(||15.00\) \\  

Table 1: Classification Accuracy and Average Percentage of Activated Concepts (Sparsity). By **bold** blue/red, we denote the best-performing high/low level _sparsity_-inducing concept-based model.

[MISSING_PAGE_FAIL:8]

examples' indicators. We observe that CF-CBM is able to retain highly relevant concepts from the original set, while discovering equally relevant concepts from other classes such as _australian terrier_, _soft-coated wheaten terrier_ and _collie_.

In Fig.3, we focus on the example-wise behavior of the proposed framework. To this end, and for a random image from the ImageNet-1k validation set, we illustrate: (i) the original low-level set of attributes describing its class (_Black Swan_), and (ii) some of the low-level attributes discovered by our CF-CBM. We observe that the original concept set pertaining to the class cannot adequately represent the considered example. Indeed, most concepts therein would make the interpretation task difficult even for a human annotator. In stark contrast, the proposed framework allows for a more interpretable set of concepts, capturing finer information residing in the patches; this can in turn facilitate a more thorough examination of the network's decision making process.

In this context, and since we have access to all the concepts/attributes discovered on the image and patch level, we can examine and visualize the discovered concepts for each patch and assess their validity. We provide such a visualization in Fig. 4, where for the _Black Swan_ image of Fig.3, we present five of the most contributing discovered attributes on the patch-wise level, i.e., attributes that are inferred to be active for this example, encoded in the binary masks \(\), and that have a large contribution to the classification decision. Therein, we observe that our approach is able to exploit the information residing in localized regions of the image, granting significant insights towards the decision-making process of the proposed framework.

Additional qualitative investigations with respect to the inferred concept patterns are provided in the Appendix.

  \(P\) & Acc. & \(|\) Sparse. High (\%) & Acc. & \(|\) Sparse. Low (\%) & Example-wise Jaccard (\%) & Class-wise Jaccard (\%) \\  \(4\) & 79.05 & 55.00 & 73.70 & 35.27 & 16.60 & 27.20 \\ \(9\) & 79.20 & 47.80 & 72.00 & 27.00 & 16.10 & 27.20 \\ \(16\) & 79.50 & 50.00 & 73.20 & 29.80 & 17.60 & **32.50** \\ \(64\) & 79.00 & 47.60 & 73.40 & 29.00 & **18.00** & 31.50 \\ \(256\) & 79.15 & 47.60 & 73.40 & 25.00 & 16.70 & 27.40 \\  

Table 3: An ablation study on the effect of the number of patches used on the low-level on the CUB dataset for both classification and interpretation capacity of the CF-CBM framework.

Figure 2: Original and additional discovered concepts for the _Sussex Spanier_ ImageNet class. By green, we denote the concepts retained from the original low-level set pertaining to the class, by maroon, concepts removed via the binary indicators \(\), and by purple, the newly discovered concepts.

## 5 Limitations & Conclusions

A potential limitation of the CF-CBM framework is the dependence on the vision-language backbone. The final performance and interpretation capacity is tied to its suitability with respect to the task at hand. If the embeddings cannot adequately capture the relation (in terms of similarity) between images/patches-concepts, there is currently no mechanism to mitigate this issue. However, our construction easily accommodates adapting the backbone. Concerning the complexity of the proposed CF-CBM framework, by precomputing all the required embeddings, the resulting complexity is orders of magnitude lower than training a conventional backbone. A more thorough discussion on the limitations and complexity of our approach is presented in the Appendix.

In this work, we proposed an innovative framework in the context of ante-hoc interpretability based on a novel hierarchical construction. We introduced the notion of _concept hierarchy_, in which, high-level concepts are characterized by a number of lower-level attributes. In this context, we leveraged recent advances in CBMs and Bayesian arguments to construct an end-to-end coarse-to-fine network that can exploit these distinct concept representations, by considering both the whole image, as well as its individual patches; this facilitated the discovery and exploitation of finer information residing in patch-specific regions of the image. We validated our paradigm both in terms of classification performance, while considering a new metric for evaluating the network's capacity towards interpretability. As we experimentally showed, we yielded networks that retain or even improve classification accuracy, while allowing for a more fine-grained investigation of their decision process.