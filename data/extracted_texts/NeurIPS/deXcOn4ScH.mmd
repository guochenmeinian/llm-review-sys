# Hi-fi functional priors by learning activations

Marcin Sendera \({}^{1,2,3}\) +
Footnote â€ : denotes equal contribution

 Amin Sorkhei  Tomasz Kusmierczyk \({}^{1}\)

\({}^{1}\) Jagiellonian University \({}^{2}\) Mila \({}^{3}\) Universite de Montreal

###### Abstract

Function-space priors in Bayesian Neural Networks (BNNs) provide a more intuitive approach to embedding beliefs directly into the model's output, thereby enhancing regularization, uncertainty quantification, and risk-aware decision-making. However, imposing function-space priors on BNNs is challenging. We address this task through optimization techniques that explore how trainable activations can accommodate higher-complexity priors and match intricate target function distributions. We investigate flexible activation models, including Pade functions and piecewise linear functions, and discuss the learning challenges related to identifiability, loss construction, and symmetries. Our empirical findings indicate that even BNNs with a single wide hidden layer when equipped with flexible trainable activation, can effectively achieve desired function-space priors.

## 1 Introduction

Models trained in a function-space rather than in the space of weights and biases (parameters space) exhibit flatter minima, better generalization, and improved robustness to overfitting (Qiu et al., 2024). Better properties achieved by focusing directly on the output space are particularly advantageous in scenarios where the relationship between parameters and function behavior is not straightforward, especially for Bayesian Neural Networks (BNNs). Moreover, function-space priors offer a direct method of specifying beliefs about the functions being modeled by BNNs, rather than just the parameters, leading to intuitive and often more meaningful representation of prior knowledge (Tran et al., 2022).

Finding accurate posteriors for deep and complex models such as BNNs is notoriously challenging due to their high-dimensional parameter spaces and complex likelihood surfaces. On the other hand, for single-hidden-layer wide BNNs, it has been recently shown that posterior sampling via Markov Chain Monte Carlo (MCMC) can be performed efficiently (Hron et al., 2022). Moreover, research has demonstrated that the exact posterior of a wide BNN weakly converges to the posterior corresponding to the Gaussian Process (GP) that matches the BNN's prior (Hron et al., 2020). This allows BNNs to inherit GP-like properties while preserving their advantages. For example, BNNs scale better to large datasets as they can also leverage deep learning methods, reducing computational burden compared to GPs. The relation between NNs and BNNs has been a topic of significant research interest, which we briefly discuss in Section A.

A classic result by Neal (1996); Williams (1996), later extended to deep NNs by Lee et al. (2017); Matthews et al. (2018), shows that infinitely wide layers in NNs behave _a priori_ like GPs by identifying the kernel of a GP that matches covariance of a (B)NN. The past studies were conducted for better understanding of NNs. We are interested in a similar setting, but our objective is the opposite: we aim to implement the function-space priors (in particular, GP-like behavior) in BNNs, by matching _both_ their priors on parameters and activations. GP prior specification generally offers greater interpretability compared to the prior applied to the weights of a BNN. This is because the kernelclearly governs key characteristics of the prior functions, such as shape, variability, and smoothness. We provide an extended reasoning on BNNs mitigating GPs behaviour in Appendix B.

Finding BNNs that exhibit the behavior of GPs is a notoriously difficult problem, with analytical solutions existing for only a few GP kernels. For example, Meronen et al. (2020) found a solution (a BNN's activation function) for the popular Matern kernel. To address the challenge of imposing function-space _a priori behavior_ to BNNs, Flam-Shepherd et al. (2017), Flam-Shepherd et al. (2018), and especially Tran et al. (2022), attempted to find both parameters and priors on parameters by using gradient-based optimization. Their approach, which requires deep networks equipped with complex priors, presents an additional undisclosed challenge in learning posteriors. Instead, we demonstrate that by learning also activations, we can achieve faithful function-space priors using just a shallow, wide BNN. In this work, we establish a practical and straightforward alternative to finding closed-form solutions (activations) to impose function-space priors on BNNs.

Results in the paper are supplemented in the Appendix, which covers Related Work (Section A), a discussion on the relationship between BNNs and GPs (Section B), challenges in optimization (e.g., identifiability; Section C), and details of the Experimental Setting followed by Additional Results.

## 2 Finding weights and activations to match function-space priors

The covariance between two inputs \(x\) and \(x^{}\) of a (single-hidden layer wide) BNN is

\[(f^{l}(x),f^{l}(x^{}))=_{f}^{l}(x,x^{})={_{b }^{l}}^{2}+{_{w}^{l}}^{2}_{f_{j}^{l-1}}[(f_{j}^{l-1}( x))(f_{j}^{l-1}(x^{}))]\] (1)

where \(l\) reads here as _last_ (or output) and \(l-1\) as _input_ layer. The BNN matches, a priori, a GP with an appropriate kernel \(\) realised by the covariance cov. In this work, we focus on zero-centered i.i.d. priors for weights and biases, e.g., \([w]=0\) and \([b]=0\). To ensure that the asymptotic variance neither vanishes nor explodes, marginal variances are assumed to be inversely proportional to layer width, i.e., \([w_{ij}^{l}]=^{l}}^{2}}{B_{l}}\). For the full discussion, please see Section B.

We consider the inverse problem of imposing behavior akin to a GP\((0,)\) on a BNN. The task is to identify hyperparameters in Eq. 1, i.e., priors on \(w\), \(b\) (where \(f^{l-1}\) is also expressed via \(w^{l-1}\) and \(b^{l-1}\)) and activation \(\), to align them with the desired GP, such that on an input subspace (=_index set_) \(\), the covariance would match the kernel. Ideally, \(f^{l}(0,)_{[]}\), i.e., \(p_{nn}(f^{l}(X))=p_{gp}(f^{l}_{i}(X))\) for any \(X\). However, in practice we strive for the approximate similarity: \(p_{nn}(f^{l}_{i}(X)) p_{gp}(f^{l}_{i}(X))\). The matching is performed on an input subspace denoted here by the functional-space measurement set \(X\) (=\(N\) input points of dimensionality \(F\), which can generally be defined in multiple ways (Sun et al., 2019)) and is posed as an optimization task: \(p^{*}_{nn}=_{p_{nn}}_{X p_{X}}D(p_{nn}(f^{l}_ {i}(X)),p_{gp}(f^{l}_{i}(X))\), where \(D\) is an _arbitrary_ (but in our case differentiable) divergence measure, and we average over \(S\) samples from the input space. While \(p_{gp}\) can be both sampled and evaluated (for fixed inputs \(X\), the GP reduces to a Gaussian distribution), \(p_{nn}\) is known only implicitly, which means that we can sample from it but its density cannot be evaluated directly.

We proceed by reparameterizing the prior distributions on model weights and biases. In particular, we use the basic zero-centered factorized Gaussians with learned variances, e.g., \(p(w|_{w}^{2})\), \(p(b|_{b}^{2})\). However, we assume additionally, parametric and differentiable activations \((|)\). Thus, \(p_{nn}\) is fully specified by \(=\{,\}\), leading to the final optimization objective:

\[^{*}=_{}_{X p_{X}}D(p_{nn}(f^{l} (X)|),p_{gp}(f^{l}(X)))\] (2)

which we address through gradient-based optimization with respect to \(\). This formulation involves deciding on the loss function \(D\) and the model for \(\).

The problem of learning activations for NNs involves designing functions that enable networks to capture complex and non-linear relationships effectively. In principle, any function \(:\) can serve as an activation, but the choice significantly impacts the network's expressiveness and training dynamics. We explore several models for \(\), including Rational (Pade) (Molina et al., 2019), Piece-wise linear (PWL)1, and activations realized by a NN with a single narrow hidden layer and ReLU/SiLU own activations. These functions are efficient to compute and introduce desirable non-linear properties, striking a balance between efficiency and the capacity to model intricate patterns.

The loss \(D\) measures the divergence between two distributions over functions. Due to the implicit nature of \(p_{nn}\), it must be specified between sets of samples \(\{f_{i}\}\) (we used 512 samples from each distribution) and approximated using Monte Carlo. We discovered that the standard losses, including KL-divergence, fail for this task. For example, in KL, estimating the empirical entropy term presents a challenge. Consequently, we followed Tran et al. (2022) and relied on the Wasserstein distance:

\[D=(_{(p_{nn},p_{gp})}_{ }d(f,f^{})^{p}(f,f^{})dfdf^{})^ {1/p}\] \[=_{||_{L} 1}_{p_{nn}}[(f)]-_{p_{gp }}[(f)]\] (3)

Unlike Tran et al. (2022), we used the 2-Wasserstein metric, which for Multivariate Gaussians (applicable in the case of GPs and wide BNNs, at least approximately) has a closed-form solution (Mallasto and Feragen, 2017):

\[D=||_{1}-_{2}||_{2}^{2}+(_{1}+_{2}-2}_{2}}}),\]

where \(_{1/2}\), \(_{1/2}\) are respectively expectations and covariance matrices estimated for \(p_{nn}\) and \(p_{gp}\) from samples \(\{f^{l}(X)\}\) obtained at finite input sets \(X\). Not only we avoid the internal optimisation due to \(_{||}\), but additionally \(D\) can be efficiently computed based on results by Buzuti and Thomaz (2023). For experiments, we report numerical values of \(D\) normalized by number of elements in \(X\). If the assumptions cannot be fulfilled, we can always revert back to the nested optimization for \(||_{L}\) in Eq. 3.

## 3 Learning activations enables more accurate function-space priors.

To map GP function-space priors to a BNN, we can: train its priors on parameters, train both priors and activation, or learn just the activation function. We empirically show that learning also activations provides better solutions to the inverse problem of imposing function-space priors on BNNs. Figure 1 illustrates the results of an extensive study where we compare the quality of the GP prior fit for various models of parameters' priors and activations. The target was \(GP(0,(=5/2,l=1))\). For each configuration, we conducted several training iterations and measured the final (converged) loss value multiple times. Generally, learning activations alone is not sufficient for good fits, but when combined with learning priors, it significantly improves the solutions.

Figure 1: Quality of matching BNNs to the prior of a GP with a Matern kernel (\(=5/2\), _length scale_=1.0) for 1D inputs (left) and 16D inputs (right). We evaluate models with trained parameter priors (denoted by \(w\)), activations (denoted by \(a\)), and both (denoted by \(a\)+\(w\)). Each label specifies whether a fixed activation (e.g., ReLU) or a specific activation model (e.g., Rational) was employed. Gaussian parameter priors were used by default. If not trained, we set variances to \(1\)., and for the hidden layer, we normalized the variance by its width. The label \(w\): _Matern_ refers to a BNN with the closed-form (fixed) activation as derived by Meronen et al. (2020).

Do expressive function-space priors require networks to be deep?

Tran et al. (2022) takes a practical approach to learning function-space priors. Instead of considering BNNs with wide layers, they _postulate_ that a deep network as a whole can model a functional prior. They then tune its parameters to reflect this functional prior. This involves modeling complex priors on all weights considered jointly, for example, using Normalizing Flows (Rezende and Mohamed, 2015) to ensure sufficient fidelity. This approach reveals a challenge in finding posteriors for deep networks. While MCMC (Chen et al., 2014; Del Moral et al., 2006) algorithms are computationally expensive, approximate posteriors (Hoffman et al., 2013; Ritter et al., 2018) do not possess sufficient expressiveness to adapt to such complex priors. We demonstrate that a BNN with a single wide hidden layer, basic Gaussian priors, and learned activation can match or even outperform the results of Tran et al. (2022), both in terms of priors and posteriors quality. For the description of the experimental setting, see Appendix D. We present the results in Fig. 2 and in Tab. 1 (in Appendix).

## 5 Can learned activations match performance of the closed-form ones?

Complexity of deriving suitable neural activations makes matching BNNs to GPs a formidable challenge. We instead propose a gradient-based learning method that adapts both activations and parameters priors. This approach departs from the traditional methods that rely on fixed, analytically derived activations, offering instead a flexible alternative that empirically can match or even surpass the performance of the more conventional approaches.

The empirical evaluation we performed for a problem of 2D data classification following Meronen et al. (2020), with a GP, where the authors derived analytical activation to match the Matern kernel exactly. For our method, we used a BNN with Gaussian priors with trained variances, where the activation function was modeled by a NN with a single hidden layer consisting of 5 neurons using SiLU activation. Posterior distributions were generally obtained using a HMC sampler. For the comprehensive description of the setting, please see Appendix D.

Tab. 2 and Fig. 3 demonstrate that our method enhances the match between the posteriors of a BNN and the desired target GP. Note that Meronen et al. (2020) originally used MC Dropout to obtain the posteriors, achieving much worse results than those obtained with HMC. For fairness in comparison, we tested both MC Dropout and HMC.In terms of performance, our model not only captures class probabilities accurately but also adeptly handles the total variance in class predictions and the epistemic uncertainty component, which are crucial for robust decision-making under uncertainty.

Figure 2: Prior (**(a)**) and posterior (**(b)**) predictive distributions for a BNN with trained parameters priors and activations (ours; 4th column), and for Tran et al. (2022) approach with different prior realizations (Gaussian - 3rd column and Normalizing Flow - 2nd). The first column illustrates the ground truth (GP). Numerical results complementing the figures we provide in Tab. 1 in Appendix.

## 6 Conclusion

In this paper, we addressed the problem of transferring functional priors for wide Bayesian Neural Networks to replicate desired a priori properties of Gaussian Processes. Previous approaches typically focused on learning distributions over weights and biases, often requiring deep BNNs for sufficient flexibility. We proposed an alternative approach by also learning activations, providing greater adaptability even for shallow models and eradicating the need for task-specific architectural designs. To the best of our knowledge, we are the first to explore learning activations in this context.

Figure 3: Posterior predictive distributions for a BNN with trained parameters priors and activations (ours; 2nd row), and for a BNN with analytically derived activations with posteriors determined using MC Dropout (3rd row) and HMC (4th row). The first column illustrates class probabilities, the second column shows the total variance in class predictions, and the last column depicts the epistemic uncertainty component of the total uncertainty. Numerical results complementing the figures we provide in Tab. 2 in Appendix.

[MISSING_PAGE_FAIL:6]

Meronen, L., Irwanto, C., and Solin, A. (2020). Stationary activations for uncertainty calibration in deep learning. _Advances in Neural Information Processing Systems_, 33:2338-2350.
* Meronen et al. (2021) Meronen, L., Trapp, M., and Solin, A. (2021). Periodic activation functions induce stationarity. _Advances in Neural Information Processing Systems_, 34:1673-1685.
* Molina et al. (2019) Molina, A., Schramowski, P., and Kersting, K. (2019). Pade activation units: End-to-end learning of flexible activation functions in deep networks. cite arxiv:1907.06732Comment: 12 Pages, 6 Figures.
* Neal (1996) Neal, R. M. (1996). _Bayesian Learning for Neural Networks, Vol. 118 of Lecture Notes in Statistics_.
* Pearce et al. (2020) Pearce, T., Tsuchida, R., Zaki, M., Brintrup, A., and Neely, A. (2020). Expressive priors in bayesian neural networks: Kernel combinations and periodic functions. In _Uncertainty in artificial intelligence_, pages 134-144. PMLR.
* Qiu et al. (2024) Qiu, S., Rudner, T. G. J., Kapoor, S., and Wilson, A. G. (2024). Should we learn most likely functions or parameters? In _Proceedings of the 37th International Conference on Neural Information Processing Systems_, NIPS '23, Red Hook, NY, USA. Curran Associates Inc.
* Rasmussen and Williams (2005) Rasmussen, C. E. and Williams, C. K. I. (2005). _Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)_. The MIT Press.
* Rezende and Mohamed (2015) Rezende, D. and Mohamed, S. (2015). Variational inference with normalizing flows. _International Conference on Machine Learning (ICML)_.
* Ritter et al. (2018) Ritter, H., Botev, A., and Barber, D. (2018). A scalable laplace approximation for neural networks. In _6th international conference on learning representations, ICLR 2018-conference track proceedings_, volume 6. International Conference on Representation Learning.
* Sun et al. (2019) Sun, S., Zhang, G., Shi, J., and Grosse, R. (2019). Functional variational bayesian neural networks. In _International Conference on Learning Representations_.
* Tran et al. (2022) Tran, B.-H., Rossi, S., Milios, D., and Filippone, M. (2022). All you need is a good functional prior for bayesian deep learning. _Journal of Machine Learning Research_, 23(74):1-56.
* Tsuchida et al. (2019) Tsuchida, R., Roosta, F., and Gallagher, M. (2019). Richer priors for infinitely wide multi-layer perceptrons. _arXiv preprint arXiv:1911.12927_.
* Williams (1996) Williams, C. (1996). Computing with infinite networks. In Mozer, M., Jordan, M., and Petsche, T., editors, _Advances in Neural Information Processing Systems_, volume 9. MIT Press.

Related work

The relation between NNs/BNNs has been a topic of significant research interest. For example, Meronen et al. (2021) explored periodic activation functions in BNNs to connect network weight priors with translation-invariant GP priors. Pearce et al. (2020) derived BNN architectures to mirror GP kernel combinations, showcasing how BNNs can produce periodic kernels. Furthermore, Karaletsos and Bui (2020) introduced a hierarchical model using GP for weights to encode correlated weight structures and input-dependent weight priors, aimed at regularizing the function space. Matsubara et al. (2021) proposed using ridgelet transforms to approximate GP function-space distributions with BNN weight-space distributions, providing a non-asymptotic analysis with finite sample-size error bounds. Finally, Tsuchida et al. (2019) extended the convergence of NN function distributions to GPs under broader conditions, including partially exchangeable priors. For a more detailed discussion of related topics see for example, Sections 2.3 and 4.2 in Fortuin (2021). Here, we included just a brief review of the selected works.

## Appendix B On BNNs imitating GPs

Behavior akin to GPs has been _observed_ or _postulated_ within neural networks. In particular, let's consider a Multilayer Perceptron:

\[f_{i}^{0}(x)=_{j}^{I}w_{ij}^{0}x_{j}+b_{i}^{0},\ \ i=1 H_{0};\ \ f_{i}^{l}(x)=_{j}^{H_{l}}w_{ij}^{l}(f_{j}^{l-1}(x))+b_{i}^{l},\ \ i=1 H_{l}\] (4)

where \(x\) denotes \(I\)-dimensional input, and \(f^{L}\) denotes \(O\)-dimensional output. In BNNs, \(z_{ij}(x)=w_{ij}^{l}(f_{j}^{l-1}(x))\) is a r.v. and assuming common prior distributions for \(w\) and \(b\), \(f_{i}^{l}(x)\) becomes a sum of i.i.d r.v.-s. Then, from Central Limit Theorem follows \(p(f_{i}^{l}(x))}((x), ^{2}(x))\). For two different inputs \(x\), \(x^{}\) we can write \(p(f^{l}(x),f^{l}(x^{}))} (_{f}^{l}[x,x^{}],_{f}^{l}[x,x^{}])\) where we use \([]\) to denote that we limit the mean and covariance potentially specified on a bigger space to these two inputs. In particular, by Kolmogorov extension theorem, the prior distribution of functions induced in the \(l\)-th layer, weakly converges to a GP as \(p(f^{l})}(_{f}^{l},_{ f}^{l})\).

We focus on zero-centered i.i.d. priors for weights and biases, e.g., \([w_{ij}^{l}]=0\) and \([b^{l}]=0\). Furthermore, to ensure that asymptotic variance neither vanishes nor explodes, marginal variances are assumed to be inversely proportional to layer width, i.e., \([w_{ij}^{l}]=^{l^{2}}}{H_{l}}\). Then, following from the definition, the covariance for two inputs \(x\) and \(x^{}\) can be obtained as (we repeat here Eq. 1)

\[(f^{l}(x),f^{l}(x^{}))=_{f}^{l}(x,x^{})={_{ b}^{l}}^{2}+{_{w}^{l}}^{2}_{f_{j}^{l-1}}[(f_{j}^{l-1}(x ))(f_{j}^{l-1}(x^{}))]\]

The expectation is taken over realisations of the r.v. \(f_{i}^{l-1}\). We write \(_{f_{j}^{l-1}}\) meaning \(_{p(f_{j}^{l-1}(x)),p(f_{j}^{l-1}(x^{}))}\) to signify r.v.-s which are integrated out.

MLPs consisting of several (wide) hidden layers were considered by Lee et al. (2017) and Matthews et al. (2018). Such the network can be considered a compound GP, where outputs of each layer are modeled by a GP. Then, \(f_{i}^{l-1}(0,^{l-1})\) and subsequent (\(l\)-th) layer pre-activations \((f_{j}^{l},f_{k}^{l})^{T}(0,^{l}_{jk})\) where \(^{l}=_{f}^{l}(x,x^{})={_{b}^{l}}^{2}+{_{w}^{l}} ^{2}_{f_{i}^{l-1}(0,^{l-1})}[(f_{i}^{l- 1}(x))(f_{i}^{l-1}(x^{}))]\). For an even more basic network with only one hidden layer, as considered by Neal (1996); Williams (1996), the behavior converges to that of a single individual GP, inheriting its capacity for _arbitrary function approximation_(Rasmussen and Williams, 2005). The approximation capability will depend on the chosen activation function, the nature and scale of the prior distributions on the weights and biases, and the width of the layer. For this case, the r.v.-s \(f_{i}^{0}\) are expressed with \(w^{0}\) and \(b^{0}\) and the expectation in Eq.(1) is taken over these variables as \(_{f_{i}^{0}}[]=_{w^{0} p_{w}^{0},b_{i}^{0} p _{b}^{0}}[]\).

## Appendix C Selected challenges in optimizing BNNs with learnable activations

Models with a larger number of hyperparameters and a higher degree of freedom allow for achieving more complex distributions and potentially better solutions to Eq.(2). On the other hand, overparameterization and complication of shape of the optimization manifold, may create identifiability problems or increase the risk of getting stuck in a local optimum for the steepest-gradient optimization.

To alleviate this, the optimization task in Eq.2 can be slightly simplified by appropriately fixing parameters in Eq.(1). In particular, bias \(b_{i}^{l}\) can be removed (set to \(0\)) and variance of weights between layer \(l-1\) and \(l\) can be set to \([w_{ij}^{l}]=}\) effectively simplifying Eq.(1) to

\[(f^{l}(x),f^{l}(x^{}))=^{l}(x,x^{})=_{f _{i}^{l-1}}[(f_{i}^{l-1}(x))(f_{i}^{l-1}(x^{}))]\] (5)

We cannot fix the weights as we propose to do for biases as this would mean that \(f_{i}^{l}(x)=f_{j}^{l}(x)\) effectively reducing such the layer to a single output.

On the other hand, the problem of finding BNNs behaving like GPs (e.g. inverting covariance equation) in unidentifiable. There exist multiple solutions assuring similar quality of the final match. In particular, activations \(\) solving Eq.(2) are not unique, regardless if \(p_{nn}\) is given by Eq.(1) or Eq.(5) (below). For example:

* The solutions are symmetric w.r.t activity values (y-axis), i.e., for \(^{}(f)=-(f)\), values of covariance given by Eq.(1) or Eq.(5) are not changed, simply because \((-1)^{2}=1\).
* For \(p(f_{i}^{l-1}(x))\) symmetric around \(0\) (for example, Gaussians), activations with flipped arguments \(^{}(f)=(-f)\) result in the same covariances.
* Scaling activations \(^{}(f)=(f)\) leads to the same covariances as scaling variances of the output weights as \((_{w}^{l})^{}=_{w}^{l}\)

Given a sufficiently flexible model (like a neural network itself), one can learn to approximate any target activation function to an arbitrary degree of accuracy on a compact domain. This is in line with the universal approximation theorem. However, in practice there are multiple limitations and challenges. A model may require an impractically large number of parameters to approximate certain complex functions to a desired level of accuracy. More complex models may be harder to fit and may require more training data. Some functions might require high numerical precision to be approximated effectively, and even if a model can fit a target activation function on a compact set, it might not generalize well outside the training domain. Overall, one needs to consider factors like the gradient behavior (for backpropagation), computational efficiency, and numerical stability. These factors can limit the practicality of using certain models of activations.

## Appendix D Experimental setting

### 1-dimensional regression - comparison with Tran et al. (2022)

In order to show the abilities of our approach on a standard regression task and for a fair comparison with another method optimizing Wasserstein distance, we follow the exact experimental setting presented in Tran et al. (2022). We used a GP with RBF kernel (_length scale_=0.6, _amplitude_=1.0 and _noise variance_=0.1) as the ground truth.

For a baseline, we used a method from Tran et al. (2022) consisting of a BNN (3 layers with 50 neurons each) with TanH activation function. We consider all three priors realizations presented in that work: simple Gaussian prior, hierarchical prior and prior given by a Normalizing Flow. On the other hand, our model configuration consists of a BNN with Gaussian priors centered in \(\) with trained variances, where the activation function was modeled by a NN with a single hidden layer consisting of 5 neurons using SiLU activation. Posterior distributions were obtained using a HMC sampler.

We find that our approach allows for achieving the same or better results than Tran et al. (2022) baseline both by visual and numerical comparisons. In general, we obtain better results in terms of distributional metrics as presented in Tab. 1 and getting better (visually) posterior distributions (see Fig.2) without utilizing any specific activation function or computationally heavy prior realization (like, e.g., Normalizing Flow).

### Classification - comparison with Meronen et al. (2020)

For the comparison against Meronen et al. (2020), we followed their experimental setting and used a GP with Matern kernel (\(=5/2\), _length scale_=1) as the ground truth. For a baseline we utilized

[MISSING_PAGE_FAIL:10]

 Setting & & & & & & & & & & & & \\ Default with ReLU & 39 & 39 & 667 & 0.23 & 0.26 & 0.067 & 0.3 & 0.33 & 0.11 & 4518 & 0.16 \\ Default with TanH & 38 & 38 & 595 & 0.22 & 0.24 & 0.058 & 0.3 & 0.32 & 0.11 & 4181 & 0.15 \\ Normal with ReLU & 31 & 32 & 603 & 0.21 & 0.25 & 0.061 & 0.22 & 0.26 & 0.069 & 3093 & 0.47 \\ Normal with TanH & 25 & 25 & 314 & 0.14 & 0.18 & 0.031 & 0.15 & 0.18 & 0.034 & 1721 & 0.55 \\  (Meronen et al., 2020) & 36 & 36 & 777 & 0.24 & 0.28 & 0.078 & 0.28 & 0.32 & 0.1 & 7311 & 0.24 \\ Normal + HMC & 21 & 21 & 72 & 0.07 & 0.09 & 0.007 & 0.071 & 0.094 & 0.009 & 435 & 0.24 \\ Default + HMC & 42 & 42 & 284 & 0.14 & 0.16 & 0.026 & 0.32 & 0.34 & 0.12 & 1867 & 0.11 \\   & 25 & 25 & 73 & 0.06 & 0.09 & 0.008 & 0.076 & 0.1 & 0.011 & 771 & 0.07 \\  & 23 & 23 & 6 & 0.03 & 0.03 & 0.001 & 0.029 & 0.035 & 0.001 & 45 & 0.03 \\  & 23 & 23 & 13 & 0.03 & 0.03 & 0.001 & 0.028 & 0.035 & 0.001 & 74 & 0.02 \\ 

Table 2: Similarity of the posterior predictive distributions of BNNs with a single wide hidden layer to the posterior of a GP, considered as ground truth. Calculations were performed for a test grid that includes regions both with and without training data to account for overconfidence far from data. The posteriors were obtained using the HMC sampler in all cases, except for (Meronen et al., 2020), where the original code was used (however, results for this model with a HMC-derived posterior are also included below). The lower, the better. For our method, we present results using weights and priors pretrained for 1D inputs, as well as those trained on functional priors for 1D/2D inputs matched to the task on \(\) (see Fig. 3).