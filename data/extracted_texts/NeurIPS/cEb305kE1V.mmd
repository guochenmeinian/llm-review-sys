# Deep Implicit Optimization for Robust and Flexible Image Registration

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Deep Learning in Image Registration (DLIR) methods have been tremendously successful in image registration due to their speed and ability to incorporate weak label supervision at training time. However, DLIR methods forego many of the benefits of classical optimization-based methods. The functional nature of deep networks do not guarantee that the predicted transformation is a local minima of the registration objective, the representation of the transformation (displacement/velocity field/affine) is fixed, and the networks are not robust to domain shift. Our method aims to bridge this gap between classical and learning methods by incorporating optimization as a layer in a deep network. A deep network is trained to predict multi-scale dense feature images that are registered using a black box iterative optimization solver. This optimal warp is then used to minimize image and label alignment errors. By _implicitly_ differentiating end-to-end through an iterative optimization solver, our learned features are registration and label-aware, and the warp functions are guaranteed to be local minima of the registration objective in the feature space. Our framework shows excellent performance on in-domain datasets, and is agnostic to domain shift such as anisotropy and varying intensity profiles. For the first time, our method allows switching between arbitrary transformation representations (free-form to diffeomorphic) at test time with zero retraining. End-to-end feature learning also facilitates interpretability of features, and out-of-the-box promptability using additional label-fidelity terms at inference.

## 1 Introduction

Deformable Image Registration (DIR) refers to the local, non-linear alignment of images by estimating a dense displacement field. Many workflows in medical image analysis require images to be in a common coordinate system for comparison, analysis, and visualization, including comparing inter-subject data in neuroimaging [53; 104; 97; 89; 89; 94], biomechanics and dynamics of anatomical structures including myocardial motions, airflow and pulmonary function in lung imaging, organ motion tracking in radiation therapy [78; 77; 11; 70; 29; 105; 50; 18; 71; 84], and life sciences research [112; 104; 99; 80; 72; 17].

Classical DIR methods are based on solving a variational optimization problem, where a similarity metric is optimized to find the best transformation that aligns the images. However, these methods are typically slow, and cannot leverage learning to incorporate a training set containing weak supervision such as anatomical landmarks or expert annotations. The quality of the registration is therefore limited by the fidelity of the intensity image. Deep Learning for Image Registration (DLIR) is an interesting paradigm to overcome these challenges. DLIR methods take a pair of images as input to a neural network and output a warp field that aligns the images, and their associated anatomical landmarks. The neural network parameters are trained to minimize the alignment loss over image pairs and landmarks in a training set. A benefit of this method is the ability to incorporate weaksupervision like anatomical landmarks or expert annotations during training, which performs better landmark alignment without access to landmarks at inference time.

**Motivation.** However, DLIR methods face several limitations. First, the prediction paradigm of deep learning implies the feature learning and amortized optimization steps are fused; transformations predicted at test-time may not even be a local minima of the alignment loss between the fixed and moving image. The end-to-end prediction also implies that the representation of the transformation is fixed (as a design choice of the network), and the model cannot switch between different representations like free-form, stationary velocity, geodesic, LDDMM, B-Splines, or affine at test time without additional finetuning, in sharp contrast to the flexibility of classical methods. Typical registration workflows require a practitioner to try different parameterizations of the transformation (free-form, stationary velocity, geodesic, LDDMM, B-Splines, affine) to determine the representation most suitable for their application and additional retraining becomes expensive. Moreover, design decisions like sparse keypoint learning for affine registration [103; 16; 69; 40] do not facilitate dense deformable registration. Furthermore, DLIR methods do not allow interactive registration using additional landmarks or label maps at test time, which is crucial for clinical applications. Hyper-parameter tuning for regularization is also expensive for DLIR methods. Although recent methods propose conditional registration [44; 67] to amortize over the hyperparameter search during training, the family of regularization is fixed in such cases, and space of hyperparameters becomes exponential in the number of hyperparameter families considered. Lastly, current DLIR methods are not robust to minor domain shifts like varying anisotropy and voxel resolutions, different image acquisition and preprocessing protocols [62; 53; 70; 43]. Robustness to domain shift is imperative to biomedical and clinical imaging where volumes are acquired with different scanners, protocols, and resolutions, where the applicability of DLIR methods is limited to the training domain.

**Contributions.** We introduce _DIO_, a generic _differentiable implicit optimization_ layer to a learnable feature network for image registration. By decoupling feature learning and optimization, our framework **incorporates weak supervision like anatomical landmarks into the learned features** during training, which improves the fidelity of the feature images for registration. Feature learning also leads to _dense_ feature images, which smoothens the optimization landscape compared to intensity-based registration due to homogeneity present in most medical imaging modalities. Since optimization frameworks are agnostic to spatial resolutions and feature distortions, DIO is extremely robust to domain shifts like varying anisotropy, difference in sizes of fixed and moving images, and different image acquisition and preprocessing protocols, even when compared to models trained on contrast-agnostic synthetic data . Moreover, our framework allows _zero-cost plug-and-play_ of arbitrary transformation representations (free-form, geodesics, B-Spline, affine, etc.) and regularization at test time without additional training and loss of accuracy. This also paves the way for practitioners to perform **quick and interactive registration**, and use **additional arbitrary 'prompts'** such as new landmarks or label maps out-of-the-box at test time, as part of the optimization layer.

## 2 Related Work

Deep Learning for Image RegistrationDIR refers to the alignment of a fixed image \(I_{f}\) with a moving image \(I_{m}\) using a transformation \( T\) where \(T\) is a family of transformations. Classical methods formulate a variational optimization problem to find the optimal \(\) that aligns the images [15; 4; 7; 5; 6; 2; 15; 25; 24; 23; 27; 39; 63; 102; 101; 100; 46; 60; 61; 76; 33; 32; 12]. In contrast, earliest DLIR methods used supervised learning [19; 55; 82; 88] to predict the transformation \(\). Voxelmorph  was the first unsupervised method utilizing a UNet  for unsupervised registration on brain MRI data. Recent works considered different architectural designs [21; 56; 48; 66], cascade-based architectures and loss functions [116; 115; 49; 26; 68; 114; 79; 20], and symmetric or inverse consistency-based formulations [65; 51; 52; 92; 116]. [67; 44] inject the hyperparameter as input and perform amortized optimization over different values of the hyperparameter. Domain randomization and finetuning [43; 96; 73; 30] are also proposed to improve robustness of registration to domain shift, that is a core necessity in medical imaging since different institutions follow varying acquisition and preprocessing pipelines. Foundational models are also proposed to improve registration accuracy [57; 93]. Another line of work propose to use the implicit priors of deep learning  within an optimization framework [110; 106; 49; 45]. We refer the reader to [36; 41; 28] for other detailed reviews.

Iterative methods for DLIROwing to the success of iterative optimization methods, few DLIR methods propose emulating the iterative optimization within a network. [115; 116] use a cascade of networks to iteratively predict a warp field, and use the warped moving image as the input to the next layer in the cascade. TransMorph-TVF  uses a recurrent network to predict a time-dependent velocity field.  use a shared weights encoder to output feature images at multiple scales, and a deformation field estimator utilizing a correlation layer. RAFT  similarly builds a 4D correlation volume from two 2D feature maps, and updates the optical flow field using a recurrent unit that performs lookup on the correlation volume. However, such recursive formulations have a large memory footprint due to explicit backpropagation through the entire cascade , and are not adaptive or optimal with respect to the inputs. In contrast, DIO uses optimization as a layer - guaranteeing convergence to a local minima, and _implicit differentiation_ avoids storing the entire computation graph making the framework both memory and time efficient.

Feature Learning for Image Registration [103; 16; 69; 40] learn keypoints from images which is then used to compute the optimal affine transform using a closed form solution. However, these methods are restricted to transformations that can be represented by differentiable _closed-form_ analytical solutions, making backpropagation trivial. These sparse keypoints cannot be reused for dense deformable registration either. On the other hand, dense deformable registration (diffeomorphic or otherwise) is almost universally solved using iterative optimization methods. This motivates the need to perform _implicit differentiation_ through an iterative optimization solver to perform feature learning for registration. Other approaches learn image features to perform registration [108; 59; 107; 81], but do not perform feature learning and registration end-to-end, i.e., the features obtained are not task-aware and may not be optimal for registration, especially for anatomical landmarks. Learned features are either fed into a functional form to compute the transformation end-to-end, or are learned using unsupervised learning in a stagewise manner. In contrast, by implicitly differentiating through a black-box iterative solver, and minimizing the image and label alignment losses end-to-end, DIO learns features that are _registration-aware_, _label-aware_, and _dense_. The optimization routine also guarantees that the transformation is a local minima of the alignment of high-fidelity feature images.

Deep Equilibrium modelsDeep Equilibrium (DEQ) models [9; 34] have emerged as an interesting alternative to recurrent architectures. DEQ layers solve a fixed-point equation of a layer to find its equilibrium state without unrolling the entire computation graph. This leads to high expressiveness without the need for memory-intensive backpropagation through time [10; 8; 31; 75; 37; 111]. PIRATE  uses DEQ to finetune the PnP denoiser network for registration, but unlike our work, the data-fidelity term comes from the intensity images. However, these methods use DEQ to emulate an infinite-layer network, which typically consists of learnable parameters within the recurrent layer.

Conceptually, our work does not aim to simply emulate such an infinite cascade, but rather use DEQ to _decouple_ feature learning and optimization in an end-to-end registration framework. This inherits all the robustness and agnosticity of optimization-based methods, while retaining the fidelity of learned features. DEQ allows us to avoid the layer-stacking paradigm for cascades, and use optimization as a black box layer without storing the entire computation graph, leading to constant memory footprint and faster convergence. This allows learnable features to be registration-aware since gradients are backpropagated to the feature images through the optimization itself.

## 3 Methods

The registration problem is formulated as a variational optimization problem:

\[^{*}=_{}L(I_{f},I_{m})+R()=_{ }C(,I_{f},I_{m})\] (1)

where \(I_{f}\) and \(I_{m}\) are fixed and moving images respectively, \(L\) is a loss function that measures the dissimilarity between the fixed image and the transformed moving image, and \(R\) is a suitable regularizer that enforces desirable properties of the transformation \(\). We call this the _image matching_ objective. If the images \(I_{f}\) and \(I_{m}\) are supplemented with anatomical label maps \(L_{f}\) and \(L_{m}\), we call this the _label matching_ objective. Classical methods perform image matching on the intensity images, but the label matching performance is bottlenecked by the fidelity of image gradients with respect to the label matching objective, and dynamics of the optimization algorithm. Deep learning methods mitigate this by injecting label matching objectives (for example, Dice score) into the objective Eq. (1) and using a deep network with parameters \(\) to predict \(\) for every image pair as input. In essence, learning-based problems solve the following objective:

\[^{*}=_{}_{f,m}L(I_{f},I_{m}_{})+D(S_{f },S_{m}_{})+R(_{})=_{}_{f,m}T( _{},I_{f},I_{m},S_{f},S_{m})\] (2)where \(_{}(I_{f},I_{m})\) is abbreviated to \(_{}\). This leads to learned transformations \(_{}\) that perform both good image and label matching. However, the feature learning and optimization are coupled, and the learned features are optimized only for a specific training domain. This limitation primarily marks the difference between DIO and existing DLIR methods.

Fig. 1 shows the overview of our method. Our goal is to learn feature images such that **registration in this feature space corresponds to both image and label matching performance**, by disentangling feature learning and optimization. We do this by using a feature network to extract dense features from the intensity image, that are used to solve Eq. (1) using a black-box optimization solver, and obtain an optimal transform \(^{*}\). Once \(^{*}\) is obtained, this is plugged into Eq. (2) to obtain gradients with respect to \(^{*}\). Since \(^{*}\) is a function of the feature images, we _implicitly differentiate_ through the optimization to backpropagate gradients to the feature images and to the deep network. We discuss the details of our method in the following sections.

### Feature Extractor Network

The first component of our framework is a feature network that extracts dense features from the intensity images. This network is parameterized by \(\), and takes an image \(I^{H W D C_{in}}\) as input and outputs a feature map \(F^{H W D C}\), where \(C\) is the number of feature channels, i.e. \(F=g_{}(I)\). Unlike existing DLIR methods where moving and fixed images are concatenated and passed to the network, our feature network processes the images _independently_. This allows the fixed and moving images to be of different voxel sizes. The feature network can also output multi-feature feature maps \(=g_{}(I)=[F^{0},F^{1},,F^{N}]\), where \(F^{k}^{H/2^{k} W/2^{k} D/2^{k} C_{k}}\), which can be used by multi-scale optimization solvers. The feature network is agnostic to architecture choice, and we ablate on different architectures in the experiments.

### Implicit Differentiation through Optimization

Given the feature maps \(F_{f}\) and \(F_{m}\) extracted from the fixed and moving images, an optimization solver optimizes Eq. (1) to obtain the transformation \(^{*}\). This can be written by modifying Eq. (1) to use the feature maps \(F\); i.e. \(^{*}=_{}C(F_{f},F_{m})\). A local minima of this equation satisfies:

\[(^{*},F_{f},F_{m})=_{ ^{*}}=0\] (3)

This \(^{*}\) is used to compute the loss Eq. (2) to minimize image and label matching objective. To propagate derivatives from \(^{*}\) to the feature images \(F_{f},F_{m}\), we invoke the Implicit Function Theorem :

Figure 1: **Overview of our framework.****(a)** A neural network extracts multi-scale features from the input images. **(b)**These features are used to optimize warp fields using a multi-scale differentiable optimization solver. **(c)** The optimized transform is used to warp the moving image and labels. **(d)** The warped image/label are compared with the fixed image/label using a similarity metric.

**Theorem 1**: _For a function \(:^{n}^{m_{1}+m_{2}}^{n}\) that is continuously differentiable, if \((^{*},F_{f},F_{m})=0\) and \(||_{^{*}} 0\), then there exist open sets \(U,V_{f},V_{m}\) containing \(^{*},F_{f},F_{m}\), and a function \(^{*}(F_{f},F_{m})\) defined on these open sets such that \((^{*}(F_{f},F_{m}),F_{f},F_{m})=0\)._

Given the Implicit Function Theorem, we write \((^{*}(F_{f},F_{m}),F_{f},F_{m})=0\) and differentiate with respect to \(F_{f}\) to obtain:

\[}=}+}=0 }=-()^{-1}\,}\] (4)

The gradients of \(\) come from Eq. (2) (i.e. \(\)), and the gradients of \(F_{f}\) w.r.t. Eq. (2) are obtained as \(}=-( )^{-1}}\). The gradients of \(F_{m}\) are obtained similarly.

This design ensures that optimal registration in the feature space corresponds to optimal registration _both_ in the image and label spaces. Furthermore, the optimization layer ensures that the \(^{*}\) is a local minima of this high-fidelity feature matching objective, i.e., the features obtained by the network.

Jacobian-Free BackpropIn practice, the Jacobian \(\) is expensive to compute, given the high dimensionality of \(\) and \(\). Following , we substitute the Jacobian to identity, and compute \(}- }\). This leads to much less memory and stable training dynamics compared to other estimates of Jacobian like phantom gradients, damped unrolling, or Neumann series [35; 34].

### Multi-scale optimization

Optimization based methods typically use a multi-scale approach to improve convergence and avoid local minima with the image matching objective [7; 5; 3; 15]. However, the downsampling of intensity images leads to indiscriminate blurring and loss of details at the coarser scales. We adopt a multi-scale approach by using pyramidal features from the network, which are naturally built into many convolutional architectures. We perform optimization at the coarsest scale, and use the result as initialization for the next finer scale (Algorithm 2). This is similar to optimization methods, but our multi-scale features obtained from different layers in the network correspond to different semantic content, in contrast to classical methods where the multi-scale features are simply downsampled versions of the original images. This allows the multi-scale registration to align different anatomical regions at different scales, which may be hard to align at other finer or coarser scales.

## 4 Experiments

### DIO learns dense features from sparse images

A key strength of DIO is the ability to learn interpretable dense features from sparse intensity images for accurate and robust image matching. This is especially relevant for medical image registration, which typically contain a lot of homogenity in the intensity images, making registration difficult. We design a toy task to isolate and demonstrate this behavior. The fixed and moving images are generated by placing a square of size \(32{}32\) pixels on an image of \(128{}128\) pixels. The squares in

Figure 2: **Dense feature learning leads to flatter loss landscapes.**_Top row_ shows the intensity image with the corresponding multi-scale features predicted by the deep network, where the \(L^{}\) level denotes a feature of size \(H/2^{k}{}W/2^{k}{}C_{k}\). _Bottom row_ shows the loss landscape as a function of the relative translation between the squares in the fixed and moving image. Note the flat maxima which occurs when there is no overlap between the fixed and moving image, making optimization impossible if there is no overlap of the squares. On the contrary, the loss landscape for learned features is smooth, even at the finest scale, leading to much faster convergence even when there is no overlap between the intensity images.

the fixed and moving images overlap with a 50% chance. The task is to find an affine transformation to align the two images. However, classical optimization methods will fail this task 50% of the time, because when the squares do not overlap, there is no gradient of the loss function, illustrated by the flat loss landscape in Fig. 2. However, deep networks discover features that significantly flatten this loss landscape in the feature matching space. To show this, we train a network to output multi-scale feature maps that is used to optimize Eq. (1) to recover an affine transform. We choose a 2D UNet architecture, and the multi-scale feature maps are recovered from different layers of the decoder path of the UNet. Since the features are trained to maximize label matching, the loss landscape is much flatter, and the network is able to recover the affine transform with \(>99\%\) overlap (Appendix A.4). End-to-end learning enables learning of features that are most conducive to registration, unlike existing work  that may not contain discriminative registration-aware features about anatomical labels due to lack of task-awareness.

### Results on brain MRI registration

**Setup**: We evaluated our method on inter-subject registration on the OASIS dataset . The OASIS dataset contains 414 T1-weighted MRI scans of the brain with label maps containing 35 subcortical structures extracted from automatic segmentation with FreeSurfer and SAMSEG. We use the preprocessed version from the Learn2Reg challenge  where all the volumes are skull-stripped, intensity-corrected and center-cropped to \(160 192 224\). We use the same training and validation sets as provided in the Learn2Reg challenge to enable fair comparison with other methods.

**Architectures**: We consider four architectures for the task, representing different inductive biases in the network. We use a 3D UNet architecture (denoted as _UNet_ in experiments), and a large-kernel UNet (denoted as _LKU_) . To extract multi-scale features from the networks, we attach single convolutional layers to the feature of the desired scales from the decoder path. For each of these architectures, we also consider "Encoder-Only" versions by discarding the decoder path, and creating independent encoders for each scale Fig. 9, denoted as _UNet-E_ and _LKU-E_. We choose Encoder-Only versions to ablate the performance using shared features from the decoder path versus independent feature extraction at each scale.

**Results**: We compare our method with existing methods on the Learn2Reg OASIS challenge (Table 1). We compare with state-of-the-art classical methods , and deep networks . DIO is highly competitive with existing methods, especially with TransMorph which uses up to two orders of magnitude more trainable parameters than DIO to achieve a similar performance. We note that the Large Kernel UNet architecture performs better than the standard UNet architecture, which is consistent with the findings in , even for dense feature extraction. This is due to the larger receptive field of LKUNet, which is able to capture more context in the image. Moreover, the Encoder-Only versions of the network perform slightly worse than the full networks, showing that sharing features across scales is beneficial for the task.

### Optimization-in-the-loop introduces robustness to domain shift

A key requirement of registration algorithms is to generalize over a spectrum of acquisition and preprocessing protocols, since medical images are rarely acquired with the same configuration. Existing DLIR methods are extremely sensitive to domain shift, and catastrophically fail on other brain datasets. On the contrary, DIO inherits the domain agnosticism of the optimization solver, and is robust under feature distortions introduced by domain shift.

We evaluate the robustness of the trained models on three brain datasets: LPBA40, IBSR18, and CUMC12 datasets . Contrary to the OASIS dataset, these datasets were obtained on

   \\ 
**Method** & **Dice** & **HD95** \\  ANTs  & \(0.786 0.033\) & \(2.209 0.534\) \\ NiftyReg  & \(0.775 0.029\) & \(2.382 0.723\) \\ LogDemans  & \(0.804 0.022\) & \(2.068 0.448\) \\ FireANTs  & \(0.791 0.028\) & \(2.793 0.602\) \\  Progressive C2F  & \(0.827 0.013\) & \(1.722 0.318\) \\ Little learning & \(0.846 0.016\) & \(1.500 0.304\) \\ CLapIRN  & \(0.861 0.015\) & \(1.514 0.337\) \\ Voxelmorph-huge  & \(0.847 0.014\) & \(1.546 0.306\) \\ TransMorph  & \(0.858 0.014\) & \(1.494 0.288\) \\ TransMorph-Large  & \(0.862 0.014\) & \(1.431 0.282\) \\  Ours (UNet-E) & \(0.845 0.018\) & \(1.790 0.433\) \\ Ours (LKU-E) & \(0.849 0.018\) & \(1.733 0.401\) \\ Ours (UNet) & \(0.853 0.018\) & \(1.675 0.379\) \\ Ours (LKU) & \(0.862 0.017\) & \(1.584 0.351\) \\  

Table 1: **Performance on OASIS validation set. DIO is highly competitive with state-of-the-art DLIR methods in the in-distribution setting. Our feature learning incorporates label-aware features, which is evident from the superior performance compared to four SOTA optimization-based classical methods.**different scanners, aligned to different atlases (MNI305, Talairach) with varying algorithms used for skull-stripping, bias correction (BrainSuite, autoseg), and different manual labelling protocols of different anatomical regions (as opposed to automatically generated Freesurfer labels in OASIS). Unlike the OASIS dataset, these datasets have different volume sizes, and IBSR18 and CUMC12 datasets are not 1mm isotropic. More details about the datasets are provided in Appendix A.6.

**Results**. We evaluate across a variety of configurations - (i) preserving the anisotropy of the volumes or resampling to 1mm isotropic (denoted as _anisotropic_ or _isotropic_), and (ii) center-cropping the volumes to match the size of the OASIS dataset (denoted as _Crop_ and _No Crop_). The results for all three datasets are shown in Fig. 3 sorted by mean Dice score; quantitative comparison is also shown in Appendix Table 4. Note that TransMorph, VoxelMorph, and SynthMorph do not work for sizes that are different than the OASIS dataset, therefore they only work in the _Crop_ setting. The IBSR18 dataset also has volumes with different spatial sampling, and resampling to 1mm isotropic leads to different voxel sizes. These volumes cannot be concatenated along the channel dimension, consequently very DLIR method cannot run under this configuration (Fig. 3(a)). Since our method takes as input only a single volume, and the convolutional architecture preserves the volume size, the fixed and moving images can have different voxel sizes, i.e. feature extraction is not contingent on the voxel sizes of the moving and fixed images being equal. The optimization solver can also handle different voxel sizes for the fixed and moving volumes - which is useful in applications like multimodal registration (in-vivo to ex-vivo, histology to 3D, MRI to microscopy). This unprecedented flexibility brings forth

Figure 3: **Boxplots of Dice scores for three out-of-distribution datasets.** DIO performs significantly better across three datasets without additional finetuning. Contrary to other baselines that output warp fields considering 1mm isotropic data, leading to a performance drop with anisotropic volumes, DIO performs better with anisotropic data due to the optimization’s resolution-agnostic nature.

a new operational paradigm in deep learning for registration that was unavailable before, widening the scope of applications for registration with deep features.

We compare our method with a variety of DLIR baselines, trained with and without label supervision (the former denoted as '_w/ Dice sup._' in Fig. 3). Our method performs substantially better than all the baselines with a significantly narrower interquartile range on the IBSR18 and CUMC12 datasets. The differences are significant - on IBSR18 and CUMC12, our median performance is higher than the third quartile of almost all baselines. The sturdy performance against domain shift provides a strong motivation for using optimization-in-the-loop for learnable registration.

### Robust feature learning enables zero-shot performance by switching optimizers at test-time

Another major advantage of our framework is that we can switch the optimizer _at test time_ without any retraining. This is useful when the registration constraints change over time (i.e. initially diffeomorphic transforms were required but now non-diffeomorphic transforms are acceptable), or when the registration is used in a pipeline where different parameterizations (freeform, diffeomorphic, geodesic, B-spline) may be compared. Since our framework decouples the feature learning from the optimization, we can switch the optimizer arbitrarily at test time, at no additional cost. A crucial requirement is that learned features should not be too sensitive to the training optimizer.

To demonstrate this functionality, we use the validation set of the OASIS dataset and the four networks trained in Section 4.2. The networks were initially trained on the SGD optimizer without any additional constraints on the warp field. At test time, we switch the optimizer to the FireANTs optimizer , that uses a Riemannian Adam optimizer for multi-scale diffeomorphisms. Results in Table 2 compare the Dice score, 95th percentile of the Haussdorf distance (denoted as _HD95_) and percentage of volume with negative Jacobians (denoted as \(\%(||J||<0)\)) for the two optimizers. The SGD optimizer introduces anywhere from \(0.79\%\) to \(1.1\%\) of singularities in the registration, while the FireANTs optimizer does not introduce any singularities. A slight drop in performance can be attributed to the additional constraints imposed by diffeomorphic transforms. However, the high-fidelity features lead to a much better label overlap than FireANTs run with image features (Table 1). Our framework introduces an unprecedented amount of flexibility at test time that is an indispensible feature in deep learning for registration, and can be useful in a variety of applications where the registration requirements change over time, without expensive retraining.

 
**Optimizer** &  &  \\
**Architecture** & **DSC** & **HD95** & \(\%(||||<)\) & **DSC** & **HD95** & \(\%(||||<)\) \\  UNet Encoder & 0.845 \(\) 0.018 & 1.790 \(\) 0.433 & 0.7866 \(\) 0.1371 & 0.834 \(\) 0.018 & 1.847 \(\) 0.410 & 0.0000 \(\) 0.0000 \\ LKU Encoder & 0.849 \(\) 0.018 & 1.733 \(\) 0.041 & 0.8079 \(\) 0.1308 & 0.838 \(\) 0.018 & 1.806 \(\) 0.373 & 0.0000 \(\) 0.0000 \\ UNet & 0.853 \(\) 0.018 & 1.675 \(\) 0.379 & 1.0718 \(\) 0.1662 & 0.842 \(\) 0.018 & 1.748 \(\) 0.397 & 0.0000 \(\) 0.0000 \\ LKU & 0.862 \(\) 0.017 & 1.584 \(\) 0.351 & 0.8646 \(\) 0.1429 & 0.849 \(\) 0.017 & 1.740 \(\) 0.345 & 0.0000 \(\) 0.0000 \\  

Table 2: **Zero shot performance by switching optimizers at test-time. Our method is trained on the OASIS dataset with the SGD optimizer to obtain the warp field. At inference time, we use an SGD optimizer for no constraint on the warp field, and the FireANTs optimizer to ensure diffeomorphic warps. Across all architectures, the Dice Score remains robust, with only a slight dip attributed to the constraints introduced by diffeomorphic mappings. The SGD optimization introduces \(\)1% singularities, while FireANTs shows no singularities.**

Figure 4: Examples of multi-scale features learned by the feature extractor. Scale-space features (_bottom row_) obtained by downsampling the image downsample all image features indiscriminately. Our features (_top row_) preserve necessary anatomical information at all scales, and introduce inhomogenity in the feature space for better optimization (watershed effect and enhanced contrast near gyri and a halo around the outer surface to delineate background from gray matter).

### Interpretability of features

Decoupling of feature learning and optimization allows us to examine the feature images obtained at each scale to understand what feature help in the registration task. Classical methods use scale-space images (smoothened and downsampled versions of the original image) to avoid local minima, but lose discriminative image features at lower resolutions. Moreover, intensity images may not provide sufficient details to perform label-aware registration. Since our method learns dense features to minimize label matching losses, we can observe which features are necessary to enable label-aware registration. Fig. 4 highlights differences between scale-space images and features learned by our network. At all scales, the features introduces heterogeneity using a watershed effect and enhanced contrast to improve label matching performance.

### Inference time

DLIR methods have been very popular due to their fast inference time by performing amortized optimization . Classical methods generally focus on robustness and reproducibility, and do have GPU implementations for fast inference. However, modern optimization toolkits  utilize massively parallel GPU computing to register images in seconds, and scale very well to ultrahigh resolution imaging. A concern with optimization-in-the-loop methods is the inference time. Table Table 3 shows the inference time for our method for all four architectures. These inference times are fast for a lot of applications, and the plug-and-play nature of our framework makes DIO amenable to rapid experimentation and hyperparameter tuning.

## 5 Conclusion and Limitations

ConclusionDLIR methods provide several benefits such as amortized optimization, integration of weak supervision, and the ability to learn from large (labeled) datasets. However, coupling of the feature learning and optimization steps in DLIR methods limits the flexibility and robustness of the deep networks. In this paper, we we introduce a novel paradigm that incorporates optimization-as-a-layer for learning-based frameworks. This paradigm retains all the flexibility and robustness of classical multi-scale methods while leveraging large scale weak supervision such as anatomical landmarks into _high-fidelity, registration_-a-posterioration, where additional supervision such as labelmaps or landmarks can be added to the optimization loss at test time. Our fast implementation allows for implementation of optimization-as-a-layer in deep learning, which was previously thought to be infeasible, due to existing optimization frameworks being prohibitively slow. Densification of features from our method also leads to better optimization landscapes, and our method is robust to unseen anisotropy and domain shift. To our knowledge, our method is the first to switch between transformation representations (free-form to diffeomorphic) at _test time_ without any retraining. This comes with fast inference runtimes, and interpretability of the features used for optimization. Potential future work can explore multimodal registration, online hyperparameter tuning and few-shot learning.

LimitationsThe first limitation is unlike existing DLIR methods that concatenate the fixed and moving images to feed into the network, DIO processes the images independently. The features extracted from an image are therefore trained to marginalize the label matching performance over all possible moving images, and cannot adapt to the moving image. This leads to slightly asymptotically lower in-domain performance than methods like . The second limitation is the implicit bias of the optimization algorithm. Implicit bias in SGD restricts the space of solutions for optimization problems that are overparameterized, such as deep networks . In deformable registration, the implicit bias of SGD restricts the direction of the gradient of the particle at \((x)\), which is _always parallel_ to \( F_{m}((x))\), independent of the fixed image and dissimilarity function. This limits the degrees of freedom of the optimization by \(N\)-fold for \(N\)-D images. This is unlike DLIR methods where the warp is not constrained to move along \( F_{m}((x))\). This behavior is explored in more detail in Appendix A.1. Future work aims to mitigate this implicit bias for better performance.

  
**Architecture** & **Neural net** & **Optimization** \\  UNet & 0.444 & 1.693 \\ UNet-E & 0.433 & 1.555 \\ LKU & 0.795 & 1.463 \\ LKU-E & 2.281 & 1.457 \\   

Table 3: **Inference time for various architectures. A multi-scale optimization takes only \( 1.5\) seconds to run all iterations (no early stopping) making it suitable for most applications. This is compared to the time for neural network’s feature extraction which is architecture dependent.**