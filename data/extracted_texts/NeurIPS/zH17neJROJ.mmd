# Integration-free kernels for equivariant Gaussian fields with application in dipole moment prediction

Integration-free kernels for equivariant Gaussian fields with application in dipole moment prediction

 Tim Steinert

University of Bern

tim.steinert@unibe.ch &David Ginsbourger

University of Bern

david.ginsbourger@unibe.ch &August Lykke-Moller

University of Aarhus

alm@chem.au.dk &Ove Christiansen

University of Aarhus

ove@chem.au.dk &Henry Moss

University of Cambridge

& Lancaster University

hm493@cam.ac.uk

###### Abstract

We develop a Gaussian Process model for accurate prediction of the dipole moments of water molecules by incorporating their equivariance under rotations. While kernels guaranteeing such equivariances have been investigated in previous work, their evaluation is often computationaly prohibitive due to required integrations over the involved groups. In this work, we propose an alternative integration-free construction for equivariant kernels, relying on fundamental domain ideas previously explored in the scalar-valued invariant case, establishing a data-efficient and computationally lightweight GP model for dipole moments.

## 1 Motivation

The incorporation of structural knowledge such as physical laws into statistical machine learning models has gained significant attention for improving predictive accuracy and realism. In Gaussian process (GP) modelling, various invariances and equivariances can be encoded through tailored covariance kernels (Ginsbourger et al., 2012; Scheuerer and Schlather, 2012; Ginsbourger et al., 2016; van der Wilk et al., 2018; Holderrieth et al., 2021; Henderson, 2023). GPs offer closed-form posterior distributions that facilitate uncertainty quantification and active learning for scientific tasks (Rankovic et al., 2024). However, constructing covariance functions that account for equivariance is computationally challenging, e.g. evaluating equivariant matrix-valued kernels (Reisert and Burkhardt, 2007) may require nested integrations.

Across molecular chemistry, invariances and equivariances are ubiquitous -- applying simultaneous rigid motions on underlying atoms often results in unchanged scalar properties and in vectorial properties also invariant or affected by analogous motions (i.e. equivariance). While quantum chemical methods typically guarantee exact invariance and equivariance due to their theoretical foundations, ensuring these properties in computationally efficient models is less straightforward. Accordingly, we study how GP models trained on such properties can produce invariant and equivariant predictions for improved accuracy and efficiency.

The electric dipole moment, a vector indicating the imbalance in a molecule's electron distribution, is key to understanding intermolecular interactions (Israelachvili, 2011; Stone, 2013) and predicting IR spectra intensities (Califano, 1976). Estimating the dipole moment across a molecular surface is computationally intensive, often requiring recalculations for numerous configurations, which can take days even for small molecules. Therefore, accurate statistical models are crucial, as they reduce the number of required calculations while still effectively describing the dipole surface, thereby making it feasible to predict IR spectra and manage computational costs for larger molecules.

Our main contributions are: (1) a novel class of computationally efficient integration-free equivariant kernels (2) a demonstration of this kernel class over \((2)\)- and \((3)\)- equivariance, and (3) an empirical validation on predicting dipole moments in quantum chemistry.

## 2 Background

PreliminariesFor a detailed summary of the necessary background on the interplay between matrix-valued kernels and group theory, we refer the reader to Reisert and Burkhardt (2007). In this work, we interchangeably denote multivariate Gaussian random fields as Gaussian Processes (GP).

Dipole momentsThe electric dipole moment of a molecule is here modelled as a vector function \(: D^{3 s} ()^{3}\), where \(=[_{1},,_{s}]\) encodes the position vectors in Euclidean space of the \(s\) atoms (\(_{i}\), \(i=1,...,s\)) within the considered molecule. From physical principles, \(\) is known to be translation-invariant and rotation-equivariant, i.e. for all \( D\),

\[(t_{1})=( )& t^{3},\\ (g_{2})=_{g}( )& g(3),\] (1)

where \(_{1}\) denotes the action of translations (encoded by elements of \(^{3}\)) on \(^{3}\), \(_{2}\) denotes the usual action of \((3)\) on \(^{3}\), and \(_{g}^{3 3}\) is the rotation matrix (representation) canonically associated with \(g(3)\). The actions are extended to \(D\) with the conventions:

\[t_{1}=[t_{1}_{1},,t_{1} _{s}]\,, g_{2}=[g_{2}_{1},,g_{2}_{s}]\,.\]

In the considered case of water molecules where \(s=3\) and \(_{2},_{3}\) both stand for hydrogen atoms, there is also permutation-invariance with respect to these two columns. Specifically, for all \( D\),

\[(_{3})=() /2,\] (2)

where \(_{3}\) stands for the action of \(/2\) that swaps (for \(=\)) the second and third atoms.

## 3 Equivariant random field modeling

Due to the spatial dependence of dipole moments on the molecular configuration \(\), we model their distribution as a \(^{3}\)-valued centred Gaussian random field \(Z=(_{})_{ D}\,,\) where \(D^{3 s}\) represents the configuration space, and \(_{}\) denotes the random dipole moment vector at configuration \(\). \(Z\) is characterized by a covariance kernel matrix function \(K:D D^{3 3}\), which encodes the covariance structure of the dipole moments across different configurations.

Equivariant KernelsTo encode our structural knowledge, \(Z\) must satisfy the invariance and equivariance conditions given in (1) and (2). Specifically, we can establish that, for a group \(G\) represented on \(^{p p}\) by \(_{}:G^{p p}\) and some action \(\) of \(G\) on \(D\), second-order centred \(^{p}\)-valued random fields have equivariant paths (up to a modification), if their matrix-valued kernel \(K:D D^{p p}\), \(D^{d}\) satisfies the following condition (Reisert and Burkhardt, 2007):

\[,} D,\;g,h G, K(g ,h})=_{g}K(, })_{h}^{T}.\] (3)

For a linear, compact and unimodular group \(G\), where the representation \(g_{g}\) is continuous if \(G\) is continuous, such an equivariant matrix-valued kernel function can be constructed by Haar integration of a base kernel matrix function \(K_{o}\) over \(G\):

\[K_{f}(,})=_{G^{2}}_{g}^{T}K_{o}(g ,h})_{h}\,dg\,dh.\] (4)

However, the absence of an analytical form for the integrations in (4) necessitates expensive quadrature methods, which have so far made the incorporation of equivariances in GP models computationally infeasible and unstable. This challenge was previously addressed by Glielmo et al. (2017), who aimed to model interatomic force fields using equivariant multivariate GP regression. Restricting to atoms of a single chemical species allowed them to represent molecule configurations as a scalar-valued linear combination of Gaussian functions (via kernel embedding), yielding analytical forms for the resulting kernels between configurations. We are not aware of extensions of this elegant approach to systems involving several chemical species.

Integration Free Equivariant KernelsWe now introduce a new class of equivariant matrix-valued kernels that overcomes the problems of computational inefficiency and instability with existing equivariant kernels by combining a fundamental domain approach with a base matrix-valued kernel. The following proposition formalises the construction of this efficient kernel, and we then provide a first example for the case \(G=(2)\) demonstrating its significant computational advantages.

**Proposition 3.1**.: _Let \(G\) be a linear group acting on \(D\) via \(\) and possessing a unitary group representation \(_{}:G^{p p}\). Let \(A D\) be a fundamental domain of \(\) and \(:D A\) be mapping any \( D\) to its representer in \(A\). Let furthermore \(=\{ D:|_{}()|=1\}\) and \(s_{}:D G\) be a map such that for any \( D\), \(()=s_{}()\). Then, for any matrix-valued kernel \(K_{A}\) on \(A\), \(K_{}\) below defines an equivariant (w.r.t \(\) and \(\)) matrix-valued kernel on \(\):_

\[K_{}(,^{})=_{s_{}()}^{T}K _{A}((),(^{}))_{s_{ }(^{})}.\] (5)

**Remark 3.2**.: _While there are several ways to define \(s_{}\) on points possessing a stabilizer with cardinality \( 2\), \(s_{}()\) is uniquely defined on \(\). We refer to any such \(s_{}\) as a section._

**Example 3.3**.: _Assume \(D=^{2}\), \(p=2\), and \(G=(2)\) (with \(g\) being plainly defined as \(\) rotated by \(g\)). A fundamental domain is then given by \(A=\{(x,0),x 0\}\) and its projector is defined by \(()=(r(),0),\) where \(r()=\|\|_{2}.\) Here, for \((0,0),\)\(s_{}()\) is represented by the unique rotation matrix sending \(\) to \(()\). For \(=(0,0)\), any rotation matrix would do; we conventionally set \(s_{}((0,0))\) equal to the identity matrix. In Figure (1) we compare the total computational times of the covariance matrices of the posterior distribution of the GPs \(GP(0,K_{})\) and \(GP(0,K_{f})\) on \([-1,1]^{2},\) for different training and test set sizes. Here, \(K_{f}\) is computed by adaptive integration with the adaptIntegrate function in \(\) on a maximum of \(1000\) function evaluations. The base kernel \(K_{o}\) is chosen to be the simple diagonal RBF kernel matrix function \(K_{o}=(--^{}\|_{2}^{2}}{2}, \;i\{1,2\}).\) The time difference for moderate training and test sizes of \(100\) and \(500\) are substantial; while the posterior distribution of \(GP(0K_{})\) requires a total of 55 seconds to compute, \(GP(0,K_{f})\) requires 33 hours._

## 4 Water molecule dipole moment prediction

We now provide an explicit example of how to apply our Eq. (5) to a quantum chemistry problem. In particular, we consider the case of water molecules, where \( D^{3 3}\) now represents the position vectors of an oxygen and two hydrogen atoms. As baseline kernel, we take diagonal squared exponential matrix-valued kernels:

\[K(;) D D^{p p},\ \ (,^{})(_{i}^{2}--^{}\|_{2}^{2}}{2_{i}^{2}},\;i\{1,2,3\}),\]

where \(=(_{1},_{1}^{2},,_{3},_{3}^{2})\) denotes the vector containing the tunable kernel lengthscale and variance hyperparameters. For ease of notation we write \(K=K(;)\).

Figure 1: Comparison of the log computational time for the equivariant kernels.

Constructing a tailored matrix-valued kernelTo construct matrix-valued kernels that lead to computationally efficient GP models honoring invariances and equivariances from Equations (1) and (2), we construct an integration-free rotation-equivariant (as well as translation and hydrogen swap invariant) kernel matrix function \(K_{}\). Our construction requires a fundamental domain endowed with a matrix-valued kernel \(K_{A}\), as well as a suitably defined projection mapping \( D A\), also expressible via an associated section \(s_{} D(3)\) (such that for \( D\), \(()=s_{}()_{2} \)).

For the translation-invariance of (1), we arrange the configurations relative to the position of the oxygen atom and consider only \(}=(-_{})_{1}= -_{}\). To honor (2), we ensure (by swapping columns when necessary) that \(_{1}=\|}_{1}\|_{2}\|}_{2}\|_ {2}=_{2}\). We then build a rotation matrix \(()^{3 3}\) based on three elementary rotations, such that for some \(a,b\), \(()}_{1}=(0,_{1},0)\) and \(()}_{2}=(a,b,0)\). We eventually obtain \(K_{}\) by taking

\[K_{}(,^{})=( )^{}K_{A}((),( ^{}))(^{}),\]

where \(()\) is parametrised by \((_{1},a,b)\) only. Notice that \(\) is invariant under \(_{1},_{2},_{3}\). Let us remark that choices of \(A\), \(\) and \(s_{}\) are not unique. Here, \(K_{A}\) is chosen of the same form as \(K(;)\) (yet with inputs in \(^{3}\)).

Experimental ResultsWe utilise a dataset of dipole moments \(\) obtained from 850 water molecule configurations \(\), which were computed using quantum chemical methods. For details on the dataset generation process, see Appendix B. To enhance the dataset's diversity and representativeness, we applied random rotations to the data points. See Appendix B for a visualisation of this augmented dataset. We compare the predictive accuracy of GP models for the dipole moments of water molecules using the baseline kernel \(K\) and the proposed kernel \(K_{}\).

For additional comparison, we include invariances separately with the following kernels:

1. **Translation-invariance:** \[K_{2}(,^{})=K(},}^{})\]
2. **Permutation-invariance:** \[K_{4}(,^{})=K(_{_{3}}( ),_{_{3}}(^{})),\] \[_{_{3}}()=[_{1}, _{3},_{2}],&_{1}<_{2},\\ ,&\]
3. **Permutation and translation-invariance:** \[K_{3}(,^{})=K(_{_{1,3}}( ),_{_{1,3}}(^{})),\] \[_{_{1,3}}()=(-_{1})_{1} _{_{3}}().\]

We train the GPs using Adam optimisation over 1000 iterations, with all kernel hyperparameters initialised to 1, maximising the training likelihood. In Figure (2), we see that the proposed integration-free equivariant GP consistently outperforms the base GP across all training set sizes, the small order of magnitudes of thet RMSE suggest that our proposed model is accurate enough for use in quantum chemistry.

Figure 2: Predictive scores (mean \(\) sd over \(10^{3}\) reps) of GP models versus training set size.

Conclusion and perspectives

We have introduced an integration-free method to construct a class of equivariant GP models. By leveraging fundamental domains, we eliminate the need for cumbersome integration over groups, significantly reducing the computational burden whilst leveraging prior knowledge of invariances and equivariances, enabling accurate predictions in small training data regimes. Our approach significantly enhances the modelling of dipole moments of water molecules by incorporating physical principles directly into the Gaussian process framework. The obtained numerical results are in fact very promising and open avenues of research on the short and longer term. Ongoing work include testing different scenarios on \(K_{A}\) and its hyperparameters, looking into equivariances with respect to reflections, comparing \(K_{}\) to \(K_{f}\) in feasible settings in terms of both accuracy and computational cost, and also analysing more precisely how the benefits are split among the account of the different invariances and equivariances. Investigating potential synergies with recent developments pertaining to kernels on graphs, Lie groups, and other structures is also of interest (See, e.g., Azangulov et al. (2024)). Future work include implementing resulting kernels into open source software toward GP prediction of molecular properties and active learning (see for instance (Moss and Griffiths, 2020; Griffiths et al., 2024)) and extend our approach to other molecular systems and tensor properties like polarisability volume, broadening the applicability of equivariant GP modeling in scientific research. Furthermore, future work may include comparisons between the fundamental domain approach and extensions of Glielmo et al. (2017) in dipole moment estimation and potentially in further contexts. On the theoretical side, further studying the proposed class of kernels and their properties calls for in-depth investigations on fundamental domains (potentially calling for variations in associated definitions and assumptions).