# Better Private Linear Regression Through

Better Private Feature Selection

Travis Dick

tdick@google.com, Google Research

Jennifer Gillenwater

jgillenw@gmail.com, work done while at Google Research

Matthew Joseph

mtjoseph@google.com, Google Research

###### Abstract

Existing work on differentially private linear regression typically assumes that end users can precisely set data bounds or algorithmic hyperparameters. End users often struggle to meet these requirements without directly examining the data (and violating privacy). Recent work has attempted to develop solutions that shift these burdens from users to algorithms, but they struggle to provide utility as the feature dimension grows. This work extends these algorithms to higher-dimensional problems by introducing a differentially private feature selection method based on Kendall rank correlation. We prove a utility guarantee for the setting where features are normally distributed and conduct experiments across 25 datasets. We find that adding this private feature selection step before regression significantly broadens the applicability of "plug-and-play" private linear regression algorithms at little additional cost to privacy, computation, or decision-making by the end user.

## 1 Introduction

Differentially private  algorithms employ carefully calibrated randomness to obscure the effect of any single data point. Doing so typically requires an end user to provide bounds on input data to ensure the correct scale of noise. However, end users often struggle to provide such bounds without looking at the data itself , thus nullifying the intended privacy guarantee. This has motivated the development of differentially private algorithms that do not require these choices from users.

To the best of our knowledge, two existing differentially private linear regression algorithms satisfy this "plug-and-play" requirement: 1) the Tukey mechanism , which combines propose-test-release with an exponential mechanism based on Tukey depth, and 2) Boosted AdaSSP , which applies gradient boosting to the AdaSSP algorithm introduced by Wang . We refer to these methods as, respectively, Tukey and BAS. Neither algorithm requires data bounds, and both feature essentially one chosen parameter (the number of models \(m\) for Tukey, and the number of boosting rounds \(T\) for BAS) which admits simple heuristics without tuning. In contrast, AdaSSP requires a user to provide bounds on the data's feature and label norms, and DPSGD requires a user to configure hyperparameters including learning rate, clipping norms, batch size, and number of epochs. Both algorithms produce much weaker utility when these parameters are even moderately misconfigured .

Tukey obtains strong empirical results when the number of data points \(n\) greatly exceeds the feature dimension \(d\), while BAS obtains somewhat weaker utility on a larger class of datasets . Nonetheless, neither algorithm provides generally strong performance on its own. Evaluated over a collection of 25 linear regression datasets taken from Tang et al. , Tukey and BAS obtain coefficient of determination \(R^{2}>0\) on only four (see Section 4); for context, a baseline of \(R^{2}=0\) is achieved by the trivial constant predictor, which simply outputs the mean label. These results suggest room for improvement for practical private linear regression.

### Our Contributions

We extend existing work on private linear regression by adding a preprocessing step that applies private feature selection. At a high level, this strategy circumvents the challenges of large feature dimension \(d\) by restricting attention to \(k d\) carefully selected features. We initiate the study of private feature selection in the context of "plug-and-play" private linear regression and make two concrete contributions:

1. We introduce a practical algorithm, \(\), for differentially private feature selection (Section 3). \(\) uses Kendall rank correlation  and only requires the user to choose the number \(k\) of features to select. It satisfies \(\)-DP and, given \(n\) samples with \(d\)-dimensional features, runs in time \(O(dkn(n))\) (Theorem 3.4). We also provide a utility guarantee when the features are normally distributed (Theorem 3.8).
2. We conduct experiments across 25 datasets (Section 4), with \(k\) fixed at \(5\) and \(10\). These compare \(\) and \(\) without feature selection, with \(\) feature selection , and with \(\) feature selection. Using \(((3),10^{-5})\)-DP to cover both private feature selection and private regression, we find at \(k=5\) that adding \(\) yields \(R^{2}>0\) on 56% of the datasets. Replacing \(\) with \(\) drops the rate to 40% of datasets, and omitting feature selection entirely drops it further to 16%.

In summary, we suggest that \(\) significantly expands the applicability and utility of practical private linear regression.

### Related Work

The focus of this work is practical private feature selection applied to private linear regression. We therefore refer readers interested in a more general overview of the private linear regression literature to the discussions of Amin et al.  and Tang et al. .

Several works have studied private sparse linear regression [21; 31; 17; 29]. However, Jain and Thakurta  and Talwar et al.  require an \(_{}\) bound on the input data, and the stability test that powers the feature selection algorithm of Thakurta and Smith  requires the end user to provide granular details about the optimal Lasso model. These requirements are significant practical obstacles. An exception is the work of Kifer et al. . Their algorithm first performs feature selection using subsampling and aggregation of non-private Lasso models. This feature selection method, which we call \(\), only requires the end user to select the number of features \(k\). To the selected features, Kifer et al.  then apply objective perturbation to privately optimize the Lasso objective. As objective perturbation requires the end user to choose parameter ranges and provides a somewhat brittle privacy guarantee contingent on the convergence of the optimization, we do not consider it here. Instead, our experiments combine \(\) feature selection with the \(\) and \(\) private regression algorithms. An expanded description of \(\) appears in Section 4.2.

We now turn to the general problem of private feature selection. There is a significant literature studying private analogues of the general technique of principal component analysis (PCA) [25; 15; 8; 19; 11]. Unfortunately, all of these algorithms assume some variant of a bound on the row norm of the input data. Stoddard et al.  studied private feature selection in the setting where features and labels are binary, but it is not clear how to extend their methods to the non-binary setting that we consider in this work. \(\) is therefore the primary comparison private feature selection method in this paper. We are not aware of existing work that studies private feature selection in the specific context of "plug-and-play" private linear regression.

Finally, private rank correlation has previously been studied by Kusner et al. . They derived a different, normalized sensitivity bound appropriate for their "swap" privacy setting and applied it to privately determine the causal relationship between two random variables.

## 2 Preliminaries

Throughout this paper, a database \(D\) is a collection of labelled points \((x,y)\) where \(x^{d}\), \(y\), and each user contributes a single point. We use the "add-remove" form of differential privacy.

**Definition 2.1** ().: _Databases \(D,D^{}\) from data domain \(\) are neighbors\(D D^{}\) if they differ in the presence or absence of a single record. A randomized mechanism \(:\) is \((,)\)-differentially private (DP) if for all \(D D^{}\) and any \(S\)_

\[_{}[(D) S] e^{} _{}[(D^{}) S]+.\]

We use basic composition to reason about the privacy guarantee obtained from repeated application of a private algorithm. More sophisticated notions of composition exist, but for our setting of relatively few compositions, basic composition is simpler and suffers negligible utility loss.

**Lemma 2.2** ().: _Suppose that for \(j[k]\), algorithm \(_{j}\) is \((_{j},_{j})\)-DP. Then running all \(k\) algorithms is \((_{j=1}^{k}_{j},_{j=1}^{k}_{j})\)-DP._

Both SubLasso and DPKendall use a private subroutine for identifying the highest count item(s) from a collection, known as private top-\(k\). Several algorithms for this problem exist . We use the pure DP "peeling mechanism" based on Gumbel noise , as its analysis is relatively simple, and its performance is essentially identical to other variants for the relatively small \(k\) used in this paper.

**Definition 2.3** ().: _A Gumbel distribution with parameter \(b\) is defined over \(x\) by \([x;b]=(--e^{-x/b})\). Given \(c=(c_{1},,c_{d})^{d}\), \(k\), and privacy parameter \(\), \((c,k,_{},)\) adds independent \((}{})\) noise to each count \(c_{j}\) and outputs the ordered sequence of indices with the largest noisy counts._

**Lemma 2.4** ().: _Given \(c=(c_{1},,c_{d})^{d}\) with \(_{}\) sensitivity \(_{}\), \((c,k,_{},)\) is \(\)-DP._

The primary advantage of Peel over generic noise addition is that, although users may contribute to \(d\) counts, the added noise only scales with \(k\). We note that while Peel requires an \(_{}\) bound, neither DPKendall nor SubLasso needs user input to set it: regardless of the dataset, DPKendall's use of Peel has \(_{}=3\) and SubLasso's use has \(_{}=1\) (see Algorithms 1 and 2).

## 3 Feature Selection Algorithm

This section describes our feature selection algorithm, DPKendall, and formally analyzes its utility. Section 3.1 introduces and discusses Kendall rank correlation, Section 3.2 describes the full algorithm, and the utility result appears in Section 3.3.

### Kendall Rank Correlation

The core statistic behind our algorithm is Kendall rank correlation. Informally, Kendall rank correlation measures the strength of a monotonic relationship between two variables.

**Definition 3.1** ().: _Given a collection of data points \((X,Y)=\{(X_{1},Y_{1}),,(X_{n},Y_{n})\}\) and \(i<i^{}\), a pair of observations \((X_{i},Y_{i}),(X_{i^{}},Y_{i^{}})\) is discordant if \((X_{i}-X_{i^{}})(Y_{i}-Y_{i^{}})<0\). Given data \((X,Y)\), let \(d_{X,Y}\) denote the number of discordant pairs. Then the empirical Kendall rank correlation is_

\[(X,Y)-}{n-1}.\]

_For real random variables \(X\) and \(Y\), we can also define the population Kendall rank correlation by_

\[(X,Y)=[(X-X^{})(Y-Y^{})>0]- [(X-X^{})(Y-Y^{})<0].\]

Kendall rank correlation is therefore high when an increase in \(X\) or \(Y\) typically accompanies an increase in the other, low when an increase in one typically accompanies a decrease in the other, and close to 0 when a change in one implies little about the other. We typically focus on empirical Kendall rank correlation, but the population definition will be useful in the proof of our utility result.

Before discussing Kendall rank correlation in the context of privacy, we note two straightforward properties. First, for simplicity, we use a version of Kendall rank correlation that does not account for ties. We ensure this in practice by perturbing data by a small amount of continuous random noise. Second, \(\) has range \([-1,1]\), but (this paper's version of) \(\) has range \([-n/2,n/2]\). This scaling does not affect the qualitative interpretation and ensures that \(\) has low sensitivity4.

**Lemma 3.2**.: \(()=3/2\)_._

Proof.: At a high level, the proof verifies that the addition or removal of a user changes the first term of \(\) by at most 1/2, and the second term by at most 1.

In more detail, consider two neighboring databases \((X,Y)\) and \((X^{},Y^{})\). Without loss of generality, we may assume that \((X,)=\{(X_{1},Y_{1}),,(X_{n},Y_{n})\}\) and \((X^{},Y^{})=\{(X^{}_{1},Y^{}_{1}),,(X^{}_ {n+1},Y^{}_{n+1})\}\) where for all \(i[n]\) we have that \(X^{}_{i}=X_{i}\) and \(Y^{}_{i}=Y_{i}\). First, we argue that the number of discordant pairs in \((X^{},Y^{})\) cannot be much larger than in \((X,Y)\). By definition, we have that \(d_{X^{},Y^{}}-d_{X,Y}=_{j=1}^{n}_{(X_{j}-X^{ }_{n+1})(Y_{j}-Y^{}_{n+1})<0}\). In particular, this implies that \(d_{X^{},Y^{}}-d_{X,Y}[0,n]\).

We can rewrite the difference in Kendall correlation between \((X,Y)\) and \((X^{},Y^{})\) as follows:

\[(X,Y)-(X^{},Y^{}) =-}{n-1}-+,Y^{}}}{n}\] \[=2(,Y^{}}}{n}-}{n-1} )-\] \[=2(,Y^{}}-d_{X,Y}}{n}+ }{n}-}{n-1})-\] \[=2,Y^{}}-d_{X,Y}}{n}+2d_{X,Y}( -)-\] \[=2,Y^{}}-d_{X,Y}}{n}-}{ }-,\]

where the final equality follows from the fact that \(2(-)=-1/\). Using our previous calculation, the first term is in the range \(\) and, since \(d_{X,Y}[0,]\), the second term is in the range \([-1,0]\). It follows that

\[-=0-1-(X,Y)-(X^{},Y^{ }) 2-0-=,\]

and therefore \(|(X,Y)-(X^{},Y^{})| 3/2\).

To show that the sensitivity is not smaller than \(3/2\), consider neighboring databases \((X,Y)\) and \((X^{},Y^{})\) such that \(d_{X,Y}=0\) and \((X^{},Y^{})\) contains a new point that is discordant with all points in \((X,Y)\). Then \(d_{X^{},Y^{}}=n\) while \(d_{X,Y}=0\). Then \((X,Y)-(X^{},Y^{})=2-0-1/2=3/2\). 

Turning to privacy, Kendall rank correlation has two notable strengths. First, because it is computed entirely from information about the relative ordering of data, it does not require an end user to provide data bounds. This makes it a natural complement to private regression methods that also operate without user-provided data bounds. Second, Kendall rank correlation's sensitivity is constant, but its range scales linearly with \(n\). This makes it easy to compute privately. A contrasting example is Pearson correlation, which requires data bounds to compute covariances and has sensitivity identical to its range. An extended discussion of alternative notions of correlation appears in Section 6.

Finally, Kendall rank correlation can be computed relatively quickly using a variant of merge sort.

**Lemma 3.3** ().: _Given collection of data points \((X,Y)=\{(X_{1},Y_{1}),,(X_{n},Y_{n})\}\), \((X,Y)\) can be computed in time \(O(n(n))\)._

### DPKendall

Having defined Kendall rank correlation, we now describe our private feature selection algorithm, DPKendall. Informally, DPKendall balances two desiderata: 1) selecting features that correlate with the label, and 2) selecting features that do not correlate with previously selected features. Prioritizing only the former selects for redundant copies of a single informative feature, while prioritizing only the latter selects for features that are pure noise.

In more detail, DPKendall consists of \(k\) applications of Peel to select a feature that is correlated with the label and relatively uncorrelated with the features already chosen. Thus, letting \(S_{t}\) denote the setof \(t-1\) features already chosen in round \(t\), each round attempts to compute

\[_{j S_{t}}(|(X_{j},Y)|-_{j^{}  S_{t}}|(X_{j},X_{j^{}})|).\] (1)

The \(\) scaling ensures that the sensitivity of the overall quantity remains fixed at \(\) in the first round and 3 in the remaining rounds. Note that in the first round we take second term to be 0, and only label correlation is considered.

```
1:Input: Examples \(D=\{(X_{i},Y_{i})\}_{i=1}^{n}\), number of selected features \(k\), privacy parameter \(\)
2:for\(j=1,,d\)do
3: Compute \(_{j}^{Y}=|(X_{j},Y)|\)
4: Initialize \(S=\)
5: Initialize \(=^{Y}^{d}\)
6: Initialize \(^{X}=0^{d}\)
7:for\(t=1,,k\)do
8: Set \(_{}=+_{t>1}\)
9: Set \(s_{t}=(^{Y}+^{X}}{t-1},1,_{ },)\)
10: Expand \(S=S s_{t}\)
11: Update \(_{j^{}}^{Y}=-\)
12:for\(j S\)do
13: Update \(_{j}^{X}=_{j}^{X}-|(X_{j},X_{s_{t}})|\)
14: Return \(S\) ```

**Algorithm 1**\((D,k,)\)

Pseudocode for \(\) appears in Algorithm 1. Its runtime and privacy are easy to verify.

**Theorem 3.4**.: \(\) _runs in time \(O(dkn(n))\) and satisfies \(\)-DP._

Proof.: By Lemma 3.3, each computation of Kendall rank correlation takes time \(O(n(n))\), so Line 2's loop takes time \(O(dn(n))\), as does each execution of Line 12's loop. Each call to Peel requires \(O(d)\) samples of Gumbel noise and thus contributes \(O(dk)\) time overall. The loop in Line 7 therefore takes time \(O(dkn(n))\). The privacy guarantee follows from Lemmas 2.4 and 3.2. 

For comparison, standard OLS on \(n\) samples of data with \(d\) features requires time \(O(d^{2}n)\); \(\) is asymptotically no slower as long as \(n O(2^{d/k})\). Since we typically take \(k d\), \(\) is computationally "free" in many realistic data settings.

### Utility Guarantee

The proof of \(\)'s utility guarantee combines results about population Kendall rank correlation (Lemma 3.5), empirical Kendall rank correlation concentration (Lemma 3.6), and the accuracy of Peel (Lemma 3.7). The final guarantee (Theorem 3.8) demonstrates that \(\) selects useful features even in the presence of redundant features.

We start with the population Kendall rank correlation guarantee. Its proof, and all proofs for uncited results in this section, appears in Section 7 in the Appendix.

**Lemma 3.5**.: _Suppose that \(X_{1},,X_{k}\) are independent random variables where \(X_{j} N(_{j},_{j}^{2})\). Let \( N(0,_{e}^{2})\) be independent noise. Then if the label is generated by \(Y=_{j=1}^{k}_{j}X_{j}+\), for any \(j^{*}[k]\),_

\[(X_{j^{*}},Y)=}_{j^{*}}} {}_{j}^{2}_{j}^{2}+_{e}^{2}}}.\]

To interpret this result, recall that \([-1,1]\) and \(\) has domain \(\), is odd, and has \(_{x} x=/2\). Lemma 3.5 thus says that if we fix the other \(_{j}\) and \(_{e}\) and take \(_{j^{*}}\), \((X_{j^{*}},Y)(_{j^{*}})\) as expected. The next step is to verify that \(\) concentrates around \(\).

**Lemma 3.6** (Lemma 1 ).: _Given \(n\) observations each of random variables \(X\) and \(Y\), with probability \(1-\),_

\[|(X,Y)-(X,Y)|.\]

Finally, we state a basic accuracy result for the Gumbel noise employed by Peel.

**Lemma 3.7**.: _Given i.i.d. random variables \(X_{1},,X_{d}\;(b)\), with probability \(1-\),_

\[_{j[d]}|X_{j}| b().\]

We now have the tools necessary for the final result.

**Theorem 3.8**.: _Suppose that \(X_{1},,X_{k}\) are independent random variables where each \(X_{j} N(_{j},_{j}^{2})\). Suppose additionally that of the remaining \(d-k\) random variables, for each \(j[k]\), \(n_{j}\) are copies of \(X_{j}\), where \(_{j=1}^{k}n_{j} d-k\). For each \(j[k]\), let \(S_{j}\) denote the set of indices consisting of \(j\) and the indices of its copies. Then if the label is generated by \(Y=_{j=1}^{k}_{j}X_{j}+\) where \( N(0,_{e}^{2})\) is independent random noise, if_

\[n=([k]} \{|}_{j^{*}}}{} _{j}^{2}_{j}^{2}+_{e}^{2}}}|\}}),\]

_then with probability \(1-O()\), \(\) correctly selects exactly one index from each of \(S_{1},,S_{k}\)._

Proof.: The proof reduces to applying the preceding lemmas with appropriate union bounds. Dropping the constant scaling of \(\) for neatness, with probability \(1-O()\):

**1.** Feature-label correlations are large for informative features and small for uninformative features: by Lemma 3.5 and Lemma 3.6, each feature in \(j^{*}_{j[k]}S_{j}\) has

\[(X_{j^{*}},Y)} _{j^{*}}}{}_{j}^{2}_{j}^{2}+_{e }^{2}}}-)\]

and any \(j^{*}_{j[k]}S_{j}\) has \((X_{j^{*}},Y)\).

**2.** Feature-feature correlations are large between copies of a feature and small between independent features: by Lemma 3.5 and Lemma 3.6, for any \(j[k]\) and \(j_{1},j_{2} S_{j}\),

\[(X_{j_{1}},X_{j_{2}})-\]

and for any \(j_{1},j_{2}\) such that there exists no \(S_{j}\) containing both, \((X_{j_{1}},X_{j_{2}})\).

**3.** The at most \(dk\) draws of Gumbel noise have absolute value bounded by \(()\).

Combining these results, to ensure that \(\)'s \(k\) calls to Peel produce exactly one index from each of \(S_{1},,S_{k}\), it suffices to have

\[n_{j^{*}[k]}\{|}_{j^{*}}}{ }_{j}^{2}_{j}^{2}+_{e}^{2}}}| \}=([+]())\]

which rearranges to yield the claim. 

## 4 Experiments

This section collects experimental evaluations of \(\) and other methods on 25 of the 33 datasets5. Descriptions of the relevant algorithms appear in Section 4.1 and Section 4.2. Section 4.3 discusses the results. Experiment code may be found on Github .

### Feature Selection Baseline

Our experiments use SubLasso  as a baseline "plug-and-play" private feature selection method. At a high level, the algorithm randomly partitions its data into \(m\) subsets, computes a non-private Lasso regression model on each, and then privately aggregates these models to select \(k\) significant features. The private aggregation process is simple; for each subset's learned model, choose the \(k\) features with largest absolute coefficient, then apply private top-\(k\) to compute the \(k\) features most selected by the \(m\) models. Kifer et al.  introduced and analyzed SubLasso; we collect its relevant properties in Lemma 4.1. Pseudocode appears in Algorithm 2.

```
1:Input: Examples \(D=\{(X_{i},Y_{i})\}_{i=1}^{n}\), number of selected features \(k\), number of models \(m\), privacy parameter \(\)
2:Randomly partition \(D\) into \(m\) equal-size subsets \(S_{1},,S_{m}\)
3:for\(i=1,,m\)do
4: Compute Lasso model \(_{i}\) on \(S_{i}\)
5: Compute set \(C_{i}\) of the \(k\) indices of \(_{i}\) with largest absolute value
6: Compute binary vector \(v_{i}\{0,1\}^{d}\) where \(v_{i,j}=_{j C_{i}}\)
7: Compute \(V^{d}=_{i=1}^{n}v_{i}\)
8: Return Peel\((V,k,1,)\) ```

**Algorithm 2**\((D,k,m,)\)

**Lemma 4.1**.: SubLasso _is \(\)-DP and runs in time \(O(d^{2}n)\)._

Proof.: The privacy guarantee is immediate from that of Peel (Lemma 2.4). Solving Lasso on \(n/m\) data points with \(d\)-dimensional features takes time \(O(n}{m})\). Multiplying through by \(m\) produces the final result, since Peel only takes time \(O(dk)\). 

Finally, we briefly discuss the role of the intercept feature in SubLasso. As with all algorithms in our experiments, we add an intercept feature (with a constant value of 1) to each vector of features. Each Lasso model is trained on data with this intercept. However, the intercept is removed before the private voting step, \(k\) features are chosen from the remaining features, and the intercept is added back afterward. This ensures that privacy is not wasted on the intercept feature, which we always include.

### Comparison Algorithms

We evaluate seven algorithms:

1. \(\) is a non-private baseline running generic ordinary least-squares regression.
2. BAS runs Boosted AdaSSP  without feature selection. We imitate the parameter settings used by Tang et al.  and set feature and gradient clipping norms to 1 and the number of boosting rounds to 100 throughout.
3. Tukey runs the Tukey mechanism  without feature selection. We introduce and use a tighter version of the propose-test-release (PTR) check given by Amin et al. . This reduces the number of models needed for PTR to pass. The proof appears in Section 9 in the Appendix and may be of independent interest. To privately choose the number of models \(m\) used by the Tukey mechanism, we first privately estimate a \(1-\) probability lower bound on the number of points \(n\) using the Laplace CDF, \(=n+(})-}\), and then set the number of models to \(m=/d\). Tukey spends 5% of its \(\) privacy budget estimating \(m\) and the remainder on the Tukey mechanism.
4. L-BAS runs spends 5% of its \(\) privacy budget choosing \(m=/k\) for SubLasso, 5% of \(\) running SubLasso, and then spends the remainder to run BAS on the selected features.
5. L-Tukey spends 5% of its \(\) privacy budget choosing \(m=/k\) for SubLasso, 5% running SubLasso, and the remainder running Tukey on the selected features using the same \(m\).
6. K-BAS spends 5% of its \(\) privacy budget running DPKendall and then spends the remainder running BAS on the selected features.
7. K-Tukey spends 5% of its \(\) privacy budget choosing \(m=/k\), 5% running DPKendall, and then spends the remainder running the Tukey mechanism on the selected features.

### Results

All experiments use \(((3),10^{-5})\)-DP. Where applicable, 5% of the privacy budget is spent on private feature selection, 5% on choosing the number of models, and the remainder is spent on private regression. Throughout, we use \(=10^{-4}\) as the failure probability for the lower bound used to choose the number of models. For each algorithm and dataset, we run 10 trials using random 90-10 train-test splits and record the resulting test \(R^{2}\) values. Tables of the results at \(k=5\) and \(k=10\) appear in Section 10 in the Appendix. A condensed presentation appears below. At a high level, we summarize the results in terms of _relative_ and _absolute_ performance.

#### 4.3.1 Relative Performance

First, for each dataset and method, we compute the median \(R^{2}\) of the final model across the 10 trials and then rank the methods, with the best method receiving a rank of 1. Figure 1 plots the number of times each method is ranked first or second.

At \(k=5\) (left), \(\)-Tukey performs best by a significant margin: it ranks first on 48% of datasets, twice the fraction of any other method. It also ranks first or second on the largest fraction of datasets (68%). In some contrast, \(\)-BAS obtains the top ranking on 24% of datasets, whereas \(\)-BAS only does so on 8%; nonetheless, the two have nearly the same number of total first or second rankings. At \(k=10\) (right), no clear winner emerges among the feature selecting methods, as \(\)-BAS, \(\)-BAS, and \(\)-Tukey are all first or second on around half the datasets6, though the methods using Sub.lasso have a higher share of datasets ranked first.

Figure 1: Plots of rank data for each private method.

Figure 2: Plots of the number of datasets with positive \(R^{2}\) for each private method.

#### 4.3.2 Absolute Performance

Second, we count the number of datasets on which the method achieves a positive median \(R^{2}\) (Figure 2), recalling that \(R^{2}=0\) is achieved by the trivial model that always predicts the mean label. The \(k=5\) (left) setting again demonstrates clear trends: K-Tukey attains \(R^{2}>0\) on 56% of datasets, L-Tukey does so on 40%, K-BAS does so on 28%, and L-BAS on 20%. DPKendall therefore consistently demonstrates stronger performance than SubLasso. As in the rank data, at \(k=10\) the picture is less clear. However, K-Tukey is still best by some margin, with the remaining feature selecting methods all performing roughly equally well.

### Discussion

A few trends are apparent from Section 4.3. First, DPKendall generally achieves stronger final utility than SubLasso, particularly for the Tukey mechanism; the effect is similar but smaller for \(k=10\); and feature selection generally improves the performance of private linear regression.

**Comparing Feature Selection Algorithms**. A possible reason for DPKendall's improvement over SubLasso is that, while SubLasso takes advantage of the stability properties that Lasso exhibits in certain data regimes , this stability does not always hold in practice. Another possible explanation is that the feature coefficients passed to Peel scale with \(O(n)\) for DPKendall and \(m=O()\) or \(m=O()\) for SubLasso. Both algorithm's invocations of Peel add noise scaling with \(O()\), so DPKendall's larger scale makes it more robust to privacy-preserving noise. Finally, we emphasize that DPKendall achieves this even though its \(O(dkn(n))\) runtime is asymptotically smaller than the \(O(d^{2}n)\) runtime of SubLasso in most settings.

**Choosing \(\)**. Next, we examine the decrease in performance from \(k=5\) to \(k=10\). Conceptually, past a certain point adding marginally less informative features to a private model may worsen utility due to the privacy cost of considering these features. Moving from \(k=5\) to \(k=10\) may cross this threshold for many of our datasets; note from Figure 4 and Figure 5 in the Appendix that, of the 21 datasets used for \(k=10\), 86% witness their highest private \(R^{2}\) in the \(k=5\) setting7. Moreover, from \(k=5\) to \(k=10\) the total number of positive \(R^{2}\) datasets across methods declines by more than 50%, from 41 to 19, with all methods achieving positive \(R^{2}\) less frequently at \(k=10\) than \(k=5\). We therefore suggest \(k=5\) as the more relevant setting, and a good choice in practice.

**The Effect of Private Feature Selection**. Much work aims to circumvent generic lower bounds for privately answering queries by taking advantage of instance-specific structure [6; 16; 33; 5]. Similar works exist for private optimization, either by explicitly incorporating problem information [35; 18] or showing that problem-agnostic algorithms can, under certain conditions, take advantage of problem structure organically . We suggest that this paper makes a similar contribution: feature selection reduces the need for algorithms like Boosted AdaSSP and the Tukey mechanism to "waste" privacy on computations over irrelevant features. This enables them to apply less obscuring noise to the signal contained in the selected features. The result is the significant increase in utility shown here.

## 5 Conclusion

We briefly discuss DPKendall's limitations. First, it requires an end user to choose the number of features \(k\) to select; we suggest \(k=5\) as a reasonable first cut. Second, DPKendall's use of Kendall rank correlation may struggle when ties are intrinsic to the data's structure, e.g., when the data is categorical, as a monotonic relationship between feature and label becomes less applicable. Finally, Kendall rank correlation may fail to distinguish between linear and nonlinear monotonic feature-label relationships, even though the former is more likely to be useful for linear regression. Unfortunately, it is not obvious how to incorporate relationships more sophisticated than simple monotonicity without sacrificing rank correlation's low sensitivity. Answering these questions may be an interesting avenue for future work.

Nonetheless, the results of this paper demonstrate that DPKendall expands the applicability of plug-and-play private linear regression algorithms while providing more utility in less time than the current state of the art. We therefore suggest that DPKendall presents a step forward for practical private linear regression.