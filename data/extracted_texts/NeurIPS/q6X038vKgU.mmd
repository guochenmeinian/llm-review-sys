# Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting

Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting

Marcel Kollovieh\({}^{2}\)\({}^{}\) Abdul Fatir Ansari\({}^{1}\) Michael Bohlke-Schneider\({}^{1}\)

Jasper Zschiegner\({}^{1}\) Hao Wang\({}^{1}\) Yuyang Wang\({}^{1}\)

\({}^{1}\)AWS AI Labs \({}^{2}\)Technical University of Munich

Correspondence to: ansarnd@amazon.de

Equal contribution.Work conducted during an internship at Amazon.

###### Abstract

Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally-trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (_predict_). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the predictions of base forecasters with reduced computational overhead over reverse diffusion (_refine_). Notably, the generative performance of the model remains intact -- downstream forecasters trained on synthetic samples from TSDiff outperform forecasters that are trained on samples from other state-of-the-art generative time series models, occasionally even outperforming models trained on real data (_synthesize_).

## 1 Introduction

Time series forecasting informs key business decisions , for example in finance , renewable energy , and healthcare . Recently, deep learning-based models have been successfully applied to the problem of time series forecasting . Instantiations of these methods use, among other techniques, autoregressive modeling , sequence-to-sequence modeling , and normalizing flows . These techniques view forecasting as the problem of conditional generative modeling: generate the future, conditioned on the past.

Diffusion models  have shown outstanding performance on generative tasks across various domains  and have quickly become the framework of choice for generative modeling. Recent studies used conditional diffusion models for time series forecasting and imputation tasks . However, these models are task specific, i.e., their applicability is limited to the specific imputation or forecasting task they have been trained on. Consequently, they also forego the desirable _unconditional_ generative capabilities of diffusion models.

This raises a natural research question: _Can we address multiple (even conditional) downstream tasks with an unconditional diffusion model?_ Specifically, we investigate the usability of task-agnostic unconditional diffusion models for forecasting tasks. We introduce TSDiff, an unconditional diffusion model for time series, and propose two inference schemes to utilize the model for forecasting. Building upon recent work on guided diffusion models [10; 19], we propose a self-guidance mechanism that enables conditioning the model during inference, without requiring auxiliary networks. This makes the unconditional model amenable to arbitrary forecasting (and imputation) tasks that are conditional in nature3. We conducted comprehensive experiments demonstrating that our self-guidance approach is competitive against task-specific models on several datasets and across multiple forecasting scenarios, without requiring conditional training. Additionally, we propose a method to iteratively refine predictions of base forecasters with reduced computational overhead compared to reverse diffusion by interpreting the implicit probability density learned by TSDiff as an energy-based prior. Finally, we show that the generative capabilities of TSDiff remain intact. We train multiple downstream forecasters on synthetic samples from TSDiff and show that forecasters trained on samples from TSDiff outperform those trained on samples from variational autoencoders  and generative adversarial networks , sometimes even outperforming models trained on real samples. To quantify the generative performance, we introduce the _Linear Predictive Score (LPS)_ which we define as the test forecast performance of a linear ridge regression model trained on synthetic samples. TSDiff significantly outperforms competing generative models in terms of the LPS on several benchmark datasets. Fig. 1 highlights the three use cases of TSDiff: predict, refine, and synthesize.

In summary, our key contributions are:

* TSDiff, an unconditionally trained diffusion model for time series and a mechanism to condition TSDiff during inference for arbitrary forecasting tasks (observation self-guidance);
* An iterative scheme to refine predictions from base forecasters by leveraging the implicit probability density learned by TSDiff;
* Experiments on multiple benchmark datasets and forecasting scenarios demonstrating that observation self-guidance is competitive against task-specific conditional baselines;
* Linear Predictive Score, a metric to evaluate the predictive quality of synthetic samples, and experiments demonstrating that TSDiff generates realistic samples that outperform competing generative models in terms of their predictive quality.

The rest of the paper is organized as follows. Sec. 2 introduces the relevant background on denoising diffusion probabilistic models (DDPMs) and diffusion guidance. In Sec. 3, we present TSDiff, an unconditional diffusion model for time series, and propose two inference schemes to utilize the model for forecasting tasks. Sec. 5 discusses the related work on diffusion models for time series and diffusion guidance. Our empirical results are presented in Sec. 4. We conclude with a summary of our findings, the limitations of our proposals, and their potential resolutions in Sec. 6.

Figure 1: An overview of TSDiffâ€™s use cases. **Predict**: By utilizing observation self-guidance, TSDiff can be conditioned during inference to perform predictive tasks such as forecasting (see Sec. 3.1). **Refine**: Predictions of base forecasters can be improved by leveraging the implicit probability density of TSDiff (see Sec. 3.2). **Synthesize**: Realistic samples generated by TSDiff can be used to train downstream forecasters achieving good performance on real test data (see Sec. 4.3).

## 2 Background

### Denoising Diffusion Probabilistic Models

Diffusion models [48; 20] provide a framework for modeling the data generative process as a discrete-time diffusion process. They are latent variable models of the form \(p_{}()= p_{}(,^{1:T})d^{ 1:T}\), where \( q()\) is the true underlying distribution. The latent variables \(\{^{1},,^{T}\}\) are generated by a fixed Markov process with Gaussian transitions, often referred to as the _forward process_,

\[q(^{1},,^{T}|^{0}=)=_{t=1}^ {T}q(^{t}|^{t-1}) q(^{t}| ^{t-1}):=(}_{t-1},_{t} ),\] (1)

where \(_{t}\) is the variance of the additive noise, \(\) is the observed datapoint, and \(q(^{T})(,)\). The fixed Gaussian forward process allows direct sampling from \(q(^{t}|)\),

\[^{t}=_{t}}+_{t}) },\] (2)

where \(_{t}=1-_{t}\), \(_{t}=_{i=1}^{t}_{i}\), and \((,)\). On the other hand, the reverse diffusion (generative) process is formulated as,

\[p_{}(^{0}=,,^{T})=p(^{T}) _{t=1}^{T}p_{}(^{t-1}|^{t}) p _{}(^{t-1}|^{t}):=(_{}(^{t},t),_{t}),\] (3)

where \(p(^{T})(,)\) and \(_{t}=_{t-1}}{1-_{t}}_{t}\). The model is trained to approximate the true reverse process \(q(^{t-1}|^{t})\) by maximizing an approximation of the evidence lower bound (ELBO) of the log-likelihood. Specifically, \(_{}\) is parameterized using a denoising network, \(_{}\),

\[_{}(^{t},t)=}}(^{ t}-}{_{t}}}_{}( ^{t},t)),\] (4)

which is trained to predict the sampled noise (\(\) in Eq. 2) using the simplified objective function ,

\[_{,,t}[\|_{ }(^{t},t)-\|^{2}].\] (5)

By suitably adjusting the denoising neural network to incorporate the conditioning input, this objective can be employed to train both unconditional and conditional models.

### Diffusion Guidance

Classifier guidance repurposes unconditionally-trained image diffusion models for class-conditional image generation . The key idea constitutes decomposing the class-conditional score function using the Bayes rule,

\[_{^{t}} p(^{t}|c)=_{^{t}} p (^{t})+_{^{t}} p(c|^{t}),\] (6)

and employing an auxiliary classifier to estimate \(_{^{t}} p(c|^{t})\). Specifically, the following modified reverse diffusion process (Eq. 3) allows sampling from the class-conditional distribution,

\[p_{}(^{t-1}|^{t},c)=(^{t-1}; _{}(^{t},t)+s_{t}^{2}_{^{t}} p( c|^{t}),_{t}^{2}),\] (7)

where \(s\) is a scale parameter controlling the strength of the guidance.

## 3 TSDiff: an Unconditional Diffusion Model for Time Series

In this section, we present our main contributions: TSDiff, an _unconditional_ diffusion model designed for time series, along with two inference schemes that leverage the model for downstream forecasting tasks. We begin by outlining the problem setup and providing a concise overview of our network architecture. Subsequently, we delve into our first scheme -- observation self-guidance -- which enables conditioning reverse diffusion on arbitrary observed timesteps _during inference_. Secondly, we present a technique to iteratively refine predictions of arbitrary base forecasters by utilizing the implicit probability density learned by TSDiff as a prior.

Problem Statement.Let \(^{L}\) be a time series of length \(L\). Denote \(\{1,,L\}\) as the set of observed timesteps and \(\) as its complement set of target timesteps. Our goal is to recover the complete time series \(\), given the observed subsequence \(_{}\) which may or may not be contiguous. Formally, this involves modeling the conditional distribution \(p_{}(_{}|_{})\). This general setup subsumes forecasting tasks, with or without missing values, as special cases. We seek to train a single unconditional generative model, \(p_{}()\), and condition it during inference to draw samples from arbitrary distributions of interest, \(p_{}(_{}|_{})\).

Generative Model Architecture.We begin with modeling the marginal probability, \(p_{}()\), via a diffusion model, referred to as TSDiff, parameterized by \(\). The architecture of TSDiff is depicted in Fig. 2 and is based on SSSD  which is a modification of DiffWave  employing S4 layers . TSDiff is designed to handle _univariate_ sequences of length \(L\). To incorporate historical information beyond \(L\) timesteps without increasing \(L\), we append lagged time series along the channel dimension. This results in a noisy input \(^{t}^{L C}\) (see Eq. 2) to the diffusion model, where \(C-1\) is the number of lags. The S4 layers operate on the time dimension whereas the Conv1x1 layers operate on the channel dimension, facilitating information flow along both dimensions. As typical for unconditional diffusion models, the output dimensions of TSDiff match the input dimensions. Note that while we focus on univariate time series in this work, TSDiff can be modified to handle multivariate time series by incorporating additional layers, e.g., a transformer layer, operating across the feature dimensions after the S4 layer.

In the following, we discuss two approaches to condition the generative model, \(p_{}()\), during inference, enabling us to draw samples from \(p_{}(_{}|_{})\).

### Observation Self-Guidance

Let \(t 0\) be an arbitrary diffusion step. Applying Bayes' rule, we have,

\[p_{}(^{t}|_{}) p_{}( _{}|^{t})p_{}(^{t}),\] (8)

which yields the following relation between the conditional and marginal score functions,

\[_{^{t}} p_{}(^{t}|_{})=_{^{t}} p_{}(_{}|^{t})+_{^{t}} p_{}(^{t}).\] (9)

Given access to the guidance distribution, \(p_{}(_{}|^{t})\), we can draw samples from \(p_{}(_{}|_{})\) using guided reverse diffusion, akin to Eq. (7),

\[p_{}(^{t-1}|^{t},_{})=(^{t-1};_{}(^{t},t)+s_{t}^{2}_{ ^{t}} p_{}(_{}|^{t}), _{t}^{2}).\] (10)

The scale parameter \(s\) controls how strongly the observations, \(_{}\), and the corresponding timesteps in the diffused time series, \(\), align. Unlike Dhariwal and Nichol , we do not have access to auxiliary guidance networks. In the following, we propose two variants of a _self-guidance_ mechanism that utilizes the same diffusion model to parameterize the guidance distribution. The main intuition behind self-guidance is that a model designed for complete sequences should reasonably approximate partial sequences. A pseudo-code of the observation self-guidance is given in App. A.2.

Mean Square Self-Guidance.We model \(p_{}(_{}|^{t})\) as a multivariate Gaussian distribution,

\[p_{}(_{}|^{t})=(_{ }|f_{}(^{t},t),),\] (11)

Figure 2: An overview of observation self-guidance. The predicted noise, \(_{}(^{t},t)\), first denoises \(^{t}\) unconditionally as \(}^{t-1}\) and approximates \(\) as \(}\). The reverse diffusion step then guides \(}^{t-1}\) via the log-likelihood of the observation \(_{}\) under a distribution parameterized by \(}\).

where \(f_{}\) is a function approximating \(\), given the noisy time series \(^{t}\). We can reuse the denoising network \(_{}\) to estimate \(\) as

\[}=f_{}(^{t},t)=^{t}-_{t})}_{}(^{t},t)}{ _{t}}},\] (12)

which follows by rearranging Eq. (2) with \(=_{}(^{t},t)\), as shown by Song et al. . This one-step denoising serves as a cost-effective approximation of the model for the observed time series and provides the requisite guidance term in the form of the score function, \(_{^{t}} p_{}(_{}|^{ t})\), which can be computed by automatic differentiation. Consequently, our self-guidance approach requires no auxiliary networks or changes to the training procedure. Applying the logarithm to Eq. (11) and dropping constant terms yields the mean squared error (MSE) loss on the observed part of the time series, hence we named this technique mean square self-guidance.

Quantile Self-Guidance.Probabilistic forecasts are often evaluated using quantile-based metrics such as the continuous ranked probability score (CRPS) . While the MSE only quantifies the average quadratic deviation from the mean, the CRPS takes all quantiles of the distribution into account by integrating the quantile loss (also known as the pinball loss) from 0 to 1. This motivated us to substitute the Gaussian distribution with the asymmetric Laplace distribution that has been studied in the context of Bayesian quantile regression . The probability density function of the asymmetric Laplace distribution is given by,

\[p_{}(_{}|^{t})= (-(_{}-f_{ }(^{t},t)),(-1)(_{}-f_{}( ^{t},t))}),\] (13)

where \(Z\) is a normalization constant, \(b>0\) a scale parameter, and \((0,1)\) an asymmetry parameter. Setting \(b=1\), the log density yields the quantile loss with the score function,

\[_{^{t}} p_{}(_{}|^ {t})=_{^{t}}\{(_{}-f_{ }(^{t},t)),(-1)(_{}-f_{ }(^{t},t))\},\] (14)

with \(\) specifying the quantile level. By plugging Eq. (14) into Eq. (9), the reverse diffusion can be guided towards a specific quantile level \(\). In practice, we use multiple evenly spaced quantile levels in \((0,1)\), based on the number of samples in the forecast. Intuitively, we expect quantile self-guidance to generate more diverse predictions by better representing the cumulative distribution function.

### Prediction Refinement

In the previous section, we discussed a technique enabling the unconditional model to generate predictions by employing diffusion guidance. In this section, we will discuss another approach repurposing the model to refine predictions of base forecasters. Our approach is completely agnostic to the type of base forecaster and only assumes access to forecasts generated by them. The initial forecasts are iteratively refined using the implicit density learned by the diffusion model which serves as a prior. Unlike reverse diffusion which requires sequential sampling of all latent variables, refinement is performed directly in the data space. This provides a trade-off between quality and computational overhead, making it an economical alternative when the number of refinement iterations is less than the number of diffusion steps. Furthermore, in certain industrial forecasting scenarios, one has access to a complex production forecasting system of black-box nature. In these cases, refinement presents a cost-effective solution that enhances forecast accuracy post hoc, without modifying the core forecasting process -- a change that could potentially be a lengthy procedure.

In the following, we present two interpretations of refinement as (a) sampling from an energy function, and (b) maximizing the likelihood to find the most likely sequence.

Energy-Based Sampling.Recall that our goal is to draw samples from the distribution \(p(_{}|_{})\). Let \(g\) be an arbitrary base forecaster and \(g(_{})\) be a sample forecast from \(g\) which serves as an initial guess of a sample from \(p(_{}|_{})\). To improve this initial guess, we formulate refinement as the problem of sampling from the regularized energy-based model (EBM),

\[E_{}(;})=- p_{}()+ (,}),\] (15)

where \(}\) is the time series obtained upon combining \(_{}\) and \(g(_{})\), and \(\) is a regularizer such as the MSE loss or the quantile loss. We designed the energy function such that low energy is assigned to samples that are likely under the diffusion model, \(p_{}()\), and also close to \(}\), ensured by the diffusion log-likelihood and the regularizer in the energy function, respectively. The Lagrangemultiplier, \(\), may be tuned to control the strength of regularization; however, we set it to \(1\) in our experiments for simplicity.

We use _overdamped_ Langevin Monte Carlo (LMC)  to sample from this EBM. \(_{(0)}\) is initialized to \(}\) and iteratively refined as,

\[_{(i+1)}=_{(i)}-_{_{(i)}}E_{}( _{(i)};})+_{i} _{i}(,),\] (16)

where \(\) and \(\) are the step size and noise scale, respectively.

Note that in contrast to observation self-guidance, we directly refine the time series in the data space and require an initial forecast from a base forecaster. However, similar to observation self-guidance, this approach does not require any modifications to the training procedure and can be applied to any trained diffusion model. A pseudo-code of the energy-based refinement is provided in App. A.2.

Maximizing the Likelihood.The decomposition in Eq. (15) can also be interpreted as a regularized optimization problem with the goal of finding the most likely time series that satisfies certain constraints on the observed timesteps. Concretely, it translates into,

\[*{arg\,min}_{}\;[- p_{}()+ (,})],\] (17)

which can be optimized using gradient descent and is a special case of Eq. (16) with \(=0\). Given the non-convex nature of this objective, convergence to the global optimum is not guaranteed. Therefore, we expect the initial value, \(_{(0)}\), to influence the resulting time series, which can also be observed in the experiment results (see Table 3).

Approximation of \( p_{}()\).To approximate the log-likelihood \( p_{}()\) we can utilize the objective used to train diffusion models,

\[ p_{}()-_{,t}[ \|_{}(^{t},t)-\|^{ 2}],\] (18)

which is a simplification of the ELBO . However, a good approximation requires sampling several diffusion steps (\(t\)) incurring computational overhead and slowing down inference. To speed up inference, we propose to approximate Eq. (18) using only a single diffusion step. Instead of randomly sampling \(t\), we use the _representative step_, \(\), which improved refinement stability in our experiments. The representative step corresponds to the diffusion step that best approximates Eq. (18), i.e.,

\[=*{arg\,min}_{}(_{,t,}[\|_{}(^{t},t)-\|^{2}]-_{, }[\|_{}(^{t},)- \|^{2}])^{2}.\] (19)

The representative step is computed only once per dataset. It can be efficiently computed post training by computing the loss at every diffusion step on a randomly-sampled batch of training datapoints and then finding the diffusion step closest to the average loss. Alternatively, we can keep a running average loss for each \(t\) and compute the representative step using these running averages. This can be done efficiently because the loss used to obtain \(\) is the same as the training loss for the diffusion model.

## 4 Experiments

In this section, we present empirical results on several real-world datasets. Our goal is to investigate whether unconditional time series diffusion models can be employed for downstream tasks that typically require conditional models. Concretely, we tested if (a) the self-guidance mechanism in TSDiff can generate probabilistic forecasts (also in the presence of missing values), (b) the implicit probability density learned by TSDiff can be leveraged to refine the predictions of base forecasters, and (c) the synthetic samples generated by TSDiff are adequate for training downstream forecasters.4

Datasets and Evaluation.We conducted experiments on eight _univariate_ time series datasets from different domains, available in GluonTS  -- Solar , Electricity , Traffic , Exchange , M4-Hourly , UberTLC-Hourly , KDDCup , and Wikipedia . We evaluated the quality of probabilistic forecasts using the _continuous ranked probability score_ (CRPS) . We approximated the CRPS by the normalized average quantile loss using 100 sample paths, and report means and standard deviations over three independent runs (see App. B for details on the datasets and evaluation metric).

### Forecasting using Observation Self-Guidance

We tested the forecasting performance of the two proposed variants of observation self-guidance, mean square guidance (TSDiff-MS) and quantile guidance (TSDiff-Q), against several forecasting baselines. We included Seasonal Naive, ARIMA, ETS, and a Linear (ridge) regression model from the statistical literature . Additionally, we compared against deep learning models that represent various architectural paradigms such as the RNN-based DeepAR , the CNN-based MQ-CNN , the state space model-based DeepState , and the self-attention-based Transformer  and TFT  models. We also compared against two conditional diffusion models, CSDI  and TSDiff-Cond, a conditional version of TSDiff closely related to SSSD  (see App. B.4 for a more in-depth discussion on the baselines). Note that we did not seek to obtain state-of-the-art forecasting results on the datasets studied but to demonstrate the efficacy of unconditional diffusion models against task-specific conditional models.

Table 1 shows that TSDiff-Q is competitive with state-of-the-art conditional models, but does not require task-specific training, achieving the lowest or second-lowest CRPS on 5/8 datasets. We also observe that the choice of guidance distribution is critical. While Gaussian (TSDiff-MS) yields reasonable results, using the asymmetric Laplace distribution (TSDiff-Q) lowers the CRPS further. We hypothesize that taking the different quantile levels into account during guidance improves the results on the quantile-based evaluation metric (CRPS). Fig. 3 shows example forecasts from TSDiff-Q. Note that as self-guidance only imposes a soft-constraint on the observed timesteps, the resultant diffused values are not guaranteed to match the observations for these timesteps. The alignment between predictions and observations can be controlled via the scale parameter, \(s\) (see Eq. 9). In practice we observed that the diffused values were close to the observations for our selected values of \(s\), as shown in Fig. 5 (Appendix).

Forecasting with Missing Values.We evaluated the forecasting performance with missing values in the historical context during inference to demonstrate the flexibility of self-guidance. Specifically, we tested three scenarios: (a) random missing (RM), (b) blackout missing (i.e., a window with consecutive missing values) at the beginning of the context window (BM-B), and (c) blackout missing at the end of the context window (BM-E). We removed a segment equal to the context window from the end of the training time series to ensure that the model is not trained on this section. During inference, we masked 50% of the timesteps from this held-out context window for each scenario

  
**Method** & **Solar** & **Electricity** & **Traffic** & **Echange** & **M-Rourly** & **Inert-IC-Rourly** & **NODep** & **N\&**Light-A** \\  Seasonal Naive & 0.52\(\)0.000 & 0.009\(\)0.000 & 0.221\(\)0.000 & 0.011\(\)0.000 & 0.08\(\)0.000 & 0.299\(\)0.000 & 0.561\(\)0.000 & 0.410\(\)0.000 \\ ARIMA & 0.545\(\)0.006 & - & 0.008\(\)0.000 & 0.044\(\)0.001 & 0.284\(\)0.001 & 0.547\(\)0.000 & 0.547\(\)0.000 \\ ETS & 0.611\(\)0.004 & 0.072\(\)0.004 & 0.433\(\)0.050 & 0.080\(\)0.000 & 0.042\(\)0.001 & 0.422\(\)0.001 & 0.753\(\)0.000 & 0.715\(\)0.002 \\ Linear & 0.569\(\)0.0021 & 0.088\(\)0.008 & 0.179\(\)0.003 & 0.011\(\)0.001 & 0.095\(\)0.001 & 0.360\(\)0.023 & 0.531\(\)0.011 & 1.624\(\)1.114 \\  DeepAR & 0.389\(\)0.001 & 0.054\(\)0.000 & 0.009\(\)0.001 & 0.011\(\)0.003 & 0.052\(\)0.006 & **0.161\(\)0.002** & 0.414\(\)0.027 & 0.231\(\)0.008 \\ MR-CNN & 0.700\(\)0.003 & 0.007\(\)0.001 & 0.019\(\)0.005 & 0.046\(\)0.003 & 0.436\(\)0.020 & 0.516\(\)0.012 & 0.230\(\)0.001 \\ DeepState & 0.379\(\)0.002 & 0.075\(\)0.004 & 0.146\(\)0.018 & 0.011\(\)0.001 & 0.011\(\)0.002 & 0.238\(\)0.087 & - & 0.318\(\)0.019 \\ Transformer & 0.419\(\)0.008 & 0.076\(\)0.018 & 0.102\(\)0.002 & 0.010\(\)0.000 & 0.040\(\)0.014 & 0.192\(\)0.004 & 0.411\(\)0.012 & **0.214\(\)0.001** \\ TFT & 0.417\(\)0.023 & 0.086\(\)0.008 & 0.134\(\)0.007 & **0.067\(\)0.000** & 0.092\(\)0.001 & 0.193\(\)0.006 & 0.581\(\)0.053 & 0.279\(\)0.006 \\  CSBI & 0.352\(\)0

[MISSING_PAGE_FAIL:8]

because the additive noise in LMC incentivizes exploration of the energy landscape which improves the "spread" of the initial point forecast. In contrast, ML-Q refinement outperforms energy-based refinement on probabilistic base models suggesting that sampling might not be necessary for these models due to the probabilistic nature of the initial forecasts.

Refinement provides a trade-off; while it has a lower computational overhead than self-guidance, its performance strongly depends on the chosen base forecaster. It substantially improves the performance of simple point forecasters (e.g., Seasonal Naive) and yields improvements on stronger probabilistic forecasters (e.g., Transformer) as well.

### Training Downstream Models using Synthetic Data

Finally, we evaluated the quality of generated samples through the forecasting performance of downstream models trained on these synthetic samples. Several metrics have previously been proposed to evaluate the quality of synthetic samples [12; 57; 26; 23]. Of these, we primarily focused on _predictive_ metrics that involve training a downstream model on synthetic samples and evaluating its performance on real data (i.e., the _train on synthetic-test on real_ setup). In the absence of a standard downstream model (such as the Inception network  in the case of images), prior works have proposed different network architectures for the downstream model. This makes the results sensitive to architecture choice, random initialization, and even the choice of deep learning library. Furthermore, training a downstream model introduces additional overhead per metric computation. We propose the Linear Predictive Score (LPS) to address these issues. We define the LPS as the test CRPS of a linear (ridge) regression model trained on the synthetic samples. The ridge regression model is a simple, standard model available in standard machine learning libraries (e.g., scikit-learn) that can effectively gauge the predictive quality of synthetic samples. Moreover, a ridge regression model is cheap to fit -- it can be solved in closed-form, eliminating variance introduced by initialization and training.

We compared samples generated by TSDiff against those from TimeGAN  and TimeVAE , two time series generative models from alternative frameworks. In addition to the linear model, we trained two strong downstream forecasters (DeepAR and Transformer) on synthetic samples from each generative model. The test CRPS of these forecasters is presented in Table 4. TSDiff's samples significantly outperform TimeVAE and TimeGAN in terms of the LPS showcasing their excellent predictive quality with respect to a simple (linear) forecaster. On the stronger DeepAR and Transformer forecasters, TSDiff outperforms the baselines on most of the datasets. Moreover, the scores obtained by TSDiff are reasonable when compared to those attained by downstream forecasters trained on real samples. Notably, these forecasters trained on real data had the advantage of accessing time features and lags that extend far beyond the sequence length modeled by TSDiff. These results serve as evidence that TSDiff effectively captures crucial patterns within time series datasets and generates realistic samples (see App. C for a qualitative comparison between real time series and those generated by TSDiff).

    &  &  &  &  &  &  &  &  &  \\   & Real & 0.569\(\)0.021 & 0.088\(\)0.008 & 0.179\(\)0.003 & 0.011\(\)0.001 & 0.039\(\)0.001 & 0.360\(\)0.023 & 0.513\(\)0.001 & 1.624\(\)1.114 \\   & TimeVAE & 0.933\(\)0.147 & 0.128\(\)0.005 & 0.226\(\)0.010 & 0.024\(\)0.004 & 0.074\(\)0.003 & 0.354\(\)0.020 & 1.020\(\)0.179 & 0.643\(\)0.008 \\  & TimeScale & 1.140\(\)0.583 & 0.234\(\)0.046 & 0.398\(\)0.029 & **0.011\(\)0.000** & 0.140\(\)0.053 & 0.665\(\)0.104 & 0.713\(\)0.009 & 0.421\(\)0.023 \\  & TSDiff & **0.581\(\)0.032** & **0.065\(\)0.002** & **0.164\(\)0.002** & 0.012\(\)0.001 & **0.045\(\)0.007** & **0.291\(\)0.004** & **0.648\(\)0.013** & **0.329\(\)0.013** \\   & Real & 0.389\(\)0.001 & 0.055\(\)0.000 & 0.009\(\)0.001 & 0.010\(\)0.003 & 0.052\(\)0.006 & 0.161\(\)0.002 & 0.414\(\)0.007 & 0.211\(\)0.008 \\  & TimeVAE & 0.493\(\)0.012 & 0.060\(\)0.001 & 0.155\(\)0.006 & 0.009\(\)0.000 & **0.039\(\)0.010** & 0.278\(\)0.009 & 0.621\(\)0.003 & 0.440\(\)0.012 \\  & TimeScale & 0.976\(\)0.739 & 0.183\(\)0.006 & 0.491\(\)0.122 & **0.008\(\)0.001** & 0.121\(\)0.005 & 0.940\(\)0.125 & 0.690\(\)0.001 & 0.322\(\)0.0048 \\  & TSDiff & **0.478\(\)0.007** & **0.485\(\)0.001** & **0.129\(\)0.003** & 0.017\(Related Work

Diffusion Models.Diffusion models were originally proposed for image synthesis [48; 20; 10], but have since been applied to other domains such as audio synthesis , protein modeling , and graph modeling . Prior works have also studied image inpainting using diffusion models [35; 45; 25] which is a problem related to time series imputation. Similar to the maximum likelihood variant of our refinement approach, Graikos et al.  showed the utility of diffusion models as plug-and-play priors. The architecture of our proposed model, TSDiff, is based on a modification  of DiffWave  which was originally developed for audio synthesis.

Diffusion Models for Time Series.Conditional diffusion models have been applied to time series tasks such as imputation and forecasting. The first work is due to Rasul et al. , who proposed TimeGrad for multivariate time series forecasting featuring a conditional diffusion head. Bilos et al.  extended TimeGrad to continuous functions and made modifications to the architecture enabling simultaneous multi-horizon forecasts. CDSI  is a conditional diffusion model for imputation and forecasting which is trained by masking the observed time series with different strategies. SSSD  is a modification of CDSI that uses S4 layers  as the fundamental building block instead of transformers. The models discussed above [44; 52; 1] are all conditional models, i.e., they are trained on specific imputation or forecasting tasks. In contrast, TSDiff is trained unconditionally and conditioned during inference using diffusion guidance, making it applicable to various downstream tasks.

Diffusion Guidance.Dhariwal and Nichol  proposed classifier guidance to repurpose pretrained unconditional diffusion models for conditional image generation using auxiliary image classifiers. Ho and Salimans  eliminated the need for an additional classifier by jointly training a conditional and an unconditional diffusion model and combining their score functions for conditional generation. Diffusion guidance has also been employed for text-guided image generation and editing [39; 4] using CLIP embeddings . In contrast to prior work, our proposed observation self-guidance does not require auxiliary networks or modifications to the training procedure. Furthermore, we apply diffusion guidance to the time series domain while previous works primarily focus on images.

## 6 Conclusion

In this work, we proposed TSDiff, an unconditional diffusion model for time series, and a self-guidance mechanism that enables conditioning TSDiff for probabilistic forecasting tasks during inference, without requiring auxiliary guidance networks or modifications to the training procedure. We demonstrated that our task-agnostic TSDiff, in combination with self-guidance, is competitive with strong task-specific baselines on multiple forecasting tasks. Additionally, we presented a refinement scheme to improve predictions of base forecasters by leveraging the implicit probability density learned by TSDiff. Finally, we validated its generative modeling capabilities by training multiple downstream forecasters on synthetic samples generated by TSDiff. Samples from TSDiff outperform alternative generative models in terms of their predictive quality. Our results indicate that TSDiff learns important characteristics of time series datasets, enabling conditioning during inference and high-quality sample generation, offering an attractive alternative to task-specific conditional models.

Limitations and Future Work.While observation self-guidance provides an alternative approach for state-of-the-art probabilistic time series forecasting, its key limitation is the high computational cost of the iterative denoising process. Faster diffusion solvers [49; 33] would provide a trade-off between predictive performance and computational overhead without altering the training procedure. Furthermore, solvers developed specifically for accelerated guided diffusion [34; 55] could be deployed to speed up sampling without sacrificing predictive performance. Forecast refinement could be further improved by better approximations of the probability density and the utilization of momentum-based MCMC techniques such as Hamiltonian Monte Carlo  and underdamped Langevin Monte Carlo . In this work, we evaluated TSDiff in the context of probabilistic forecasting, however, it is neither limited nor tailored to it. It can be easily applied to any imputation task similar to our forecasting with missing values experiment where we only evaluated the forecasting performance. Moreover, the core idea behind observation self-guidance is not limited to time series and may be applicable to other domains. Tailoring the guidance distribution appropriately, enables the use of self-guidance to a variety of inverse problems.