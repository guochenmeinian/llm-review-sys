# Multi-Layer Perceptron (MLP), Layer Normalization, and Residual Connection:

Mobility-LLM: Learning Visiting Intentions and Travel Preferences from Human Mobility Data with Large Language Models

 Letian Gong\({}^{1,2}\), Yan Lin\({}^{3}\), Xinyue Zhang\({}^{1,2}\), Yiwen Lu\({}^{1}\), Xuedi Han\({}^{1}\)

**Yichen Liu\({}^{1,2}\)**, **Shengnan Guo\({}^{1,2}\), Youfang Lin\({}^{1,2}\), Huaiyu Wan\({}^{1,2}\)

\({}^{1}\)School of Computer Science and Technology, Beijing Jiaotong University, China

\({}^{2}\)Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing, China

\({}^{3}\)Department of Computer Science, Aalborg University, Denmark

{gonglt, zhangxinyue, luyiwen, hankuedi, liuyichen, guoshn, yflin, hywan}@bjtu.edu.cn, lyan@cs.aau.dk

Both authors contributed equally to this research.Corresponding author.

###### Abstract

Location-based services (LBS) have accumulated extensive human mobility data on diverse behaviors through check-in sequences. These sequences offer valuable insights into users' intentions and preferences. Yet, existing models analyzing check-in sequences fail to consider the semantics contained in these sequences, which closely reflect human visiting intentions and travel preferences, leading to an incomplete comprehension. Drawing inspiration from the exceptional semantic understanding and contextual information processing capabilities of large language models (LLMs) across various domains, we present Mobility-LLM, a novel framework that leverages LLMs to analyze check-in sequences for multiple tasks. Since LLMs cannot directly interpret check-ins, we reprogram these sequences to help LLMs comprehensively understand the semantics of human visiting intentions and travel preferences. Specifically, we introduce a visiting intention memory network (VIMN) to capture the visiting intentions at each record, along with a shared pool of human travel preference prompts (HTPP) to guide the LLM in understanding users' travel preferences. These components enhance the model's ability to extract and leverage semantic information from human mobility data effectively. Extensive experiments on four benchmark datasets and three downstream tasks demonstrate that our approach significantly outperforms existing models, underscoring the effectiveness of Mobility-LLM in advancing our understanding of human mobility data within LBS contexts.

## 1 Introduction

Location-based services (LBS) such as Gowalla, Weeplace, and Foursquare enable users to share and discover location information and nearby services. This results in the collection of extensive human mobility data, often presented in the form of check-in sequences. These sequences record users' visits to different points of interest (POIs) like restaurants and hospitals at various times, reflecting significant semantics about their intentions and preferences. Analyzing these check-in sequences is crucial as it offers valuable information on human mobility data, which can positively impact individuals, businesses, and urban management.

The key to effectively mining check-in sequences lies in understanding their rich semantics. Existing methods primarily focus on specific tasks, such as location prediction [10; 59; 52; 26], time prediction [40; 45], and trajectory user linking [34; 13; 62], rather than delving into the semantics of human behaviors. This narrow focus often results in limited optimization goals and a shallow understanding of the semantics contained in check-in sequences. Recently, large language models (LLMs) have demonstrated impressive capabilities in semantic understanding and contextual information processing, demonstrating successful adaptability across different domains. LLMs trained on extensive corpora surpass task-specific models in their potential to understand semantic information. Inspired by this, we aim to utilize pre-trained LLMs as powerful check-in sequence learners.

Nevertheless, LLMs encounter a significant obstacle in their inability to directly interpret check-in sequences. As typical sequential data, check-in sequences contain a wealth of semantic information that reflects various near-term regularities and inherent characteristics. The future intention of an individual is prone to be dictated by near-term regularities that are close to recent visits, termed _visiting intentions_. Furthermore, an individual's inherent characteristics tend to persist over time and determine their _travel preferences_, which is necessary to analyze them across multiple domains for a comprehensive understanding. Hence, our main challenge is to enable LLMs to effectively extract semantics from check-in sequences and comprehensively understand human visiting intentions and travel preferences.

To address this challenge, we present a novel unified framework called **Mobility-LLM** for various check-in sequence analysis tasks. It leverages pre-trained LLMs for general check-in sequence analysis. Our contributions can be summarized as follows:

* We propose a unified framework called **Mobility-LLM** that uses a pre-trained LLM to achieve a SOTA or comparable performance across various check-in analysis tasks including location prediction, trajectory user link, and time prediction. We extract the semantics of check-in sequences to enable LLMs to gain a comprehensive understanding of human visiting intentions and travel preferences.
* A visiting intention memory network (VIMN) is proposed for capturing users' visiting intentions of users at each check-in record by prioritizing relevant check-in records.
* A shared pool of human travel preference prompts (HTPP) in different domains is introduced, which enables a comprehensive understanding of human travel preferences and matches appropriate prompts from multiple domains.
* Our model's exceptional performance is validated through extensive experiments on four benchmark datasets involving three tasks. Our robust outcomes in cross-domain pre-training exhibit an average enhancement of 17.8% and an average of 23.6% to 38.3% on the few-shot scenario.

## 2 Related Works

In this section, we provide short reviews of literature in the areas of mobility data mining and cross-domain applications of LLMs. We postpone the detailed discussion of works to the Appendix A, due to limited space.

**Mobility Data Mining** has emerged as a promising research area due to the proliferation of location-based services. This has led to the development of three significant tasks that enhance service quality: next location prediction (LP), next time prediction (TP), and trajectory user link (TUL). The LP task aims to anticipate a user's future location based on their historical movement. Several notable models have emerged as leading approaches in LP [10; 59; 51; 48; 5; 23; 58]. The TUL task focuses on establishing connections between different trajectories and users, facilitating the analysis of user movement patterns and uncovering valuable insights into their behavior [13; 7; 60; 16]. The TP task focuses on estimating the time at which a user is likely to visit their next location. Various models have been developed to model the intensity function representing the rate or density of event occurrences, effectively making accurate time predictions [57; 17; 53].

**Cross-domain Application of LLMs** has gained attention in recent studies, which adopt large language models to address the challenge of limited training data. In the field of time series analysis, LLM4TS  is a pioneering method that aligns pre-trained large language models with temporal characteristics, introducing a two-level aggregation method to effectively incorporate multi-scale temporal data into pre-trained LLMs. One-Fits-All  is a unified framework that leverages a frozen pre-trained language model to attain state-of-the-art or comparable performance across various major types of time series analysis tasks. AutoTimes  facilitates the tokenization of time series into the embedding space of LLMs and intelligently utilizes the inherent token transitions to effectively predict time series in an autoregressive manner. In the field of computer vision, LM4VE  incorporates a frozen transformer block from an LLM as a general-purpose visual encoder layer. To tackle graph-related tasks, TAPE  utilizes semantic knowledge generated by LLMs to enhance the quality of initial node embeddings in GNNs. MoleculeSTM  aligns GNNs and LLMs within a shared vector space, integrating textual knowledge into graphs to enhance reasoning capabilities.

## 3 Preliminaries

**POI Visiting Record** In the check-in datasets, a user's visit to a certain place is represented by a POI visiting record \(R=(L_{p},t)\) generated by the user \(u\). \(L_{p}\) indicates the visited POI at time \(t\). \(L_{p}\) is represented by \((L_{id},L_{lon},L_{lat},L_{category})\), comprising \(L_{id}\) as a POI index, and accurate longitude \(L_{lon}\) and latitude \(L_{lat}\). \(L_{category}\) denotes the category of the visited POI (e.g., hospital, restaurant).

**Check-in Sequence** A user's movement during a specific period can be represented by sequential POI visiting records, which we refer to as a check-in sequence. We denote a check-in sequence as \(=<R_{1},R_{2},,R_{n}>\), where the POI visit records are ordered by their visited time, and \(n\) is the length of the sequence.

**Problem Statement** Given a check-in sequence \(\), our objective is to encode this sequence into a meaningful representation. This representation can be used for various tasks. In this paper, we choose three typical check-in prediction tasks: 1) Identifying the user \(\) who generated the check-in sequence (TUL task). 2) Predicting the next location \(_{n+1}\) the user will arrive at (LP task). 3) Predicting the arrival time \(_{n+1}\) at this location (TP task).

## 4 Methodology

We introduce a novel unified framework, **Mobility-LLM**, designed to address a variety of check-in sequence tasks. The overall structure of this framework is illustrated in Fig. 1. 1) Initially, to embed POIs by incorporating category semantics, we introduce the POI Point-wise Embedding Layer (PPEL) to generate the embedding of POIs in the current check-in record (referred to as PPE). 2) Subsequently, we feed the PPEs and timestamps of a check-in sequence into the Visiting Intention Memory Network (VIMN) to capture the visiting intentions of users at each check-in record. 3) A Human Travel Preference Prompt (HTPP) pool is introduced to extract users' preferences from check-in sequences, which act as cues to assist the LLM in comprehending users' travel preferences more effectively. 4) Finally, we use the different parts outputs of LLM (corresponding to VIMN, HTTP), each with its own projection head, to forecast the user's next location, the estimated arrival time, and the user who generates the check-in sequence.

**POI Point-wise Embedding Layer (PPEL)** is designed to generate the semantic information embedding for each POI in a check-in record. This is especially important since POI categories contain a wealth of semantic information. It has been observed that the category descriptions of POIs in the original check-in datasets are often vague or unidentified. When we refer to "vague," we are indicating that the descriptions are too broad or contain abbreviations, making it challenging to determine the specific POI categories accurately. To address this issue, we have developed a category word pool (see Appendix I for the whole categories list) that allows each POI to match with the most appropriate categories automatically. We reindex the POI IDs and word IDs in each dataset, making it convenient for subsequent encoding of these IDs. As shown in Fig. 0(a), we use the learnable embedding \(E_{L_{id}}\) of each POI ID as the query, the learnable embedding \(E_{C_{id}}\) of the category word ID as the key, and the corresponding category word token \(E_{C_{token}}\) from the LLM tokenizer as the value. A Point-wise attention mechanism is used to calculate the \(i\)-th PPE \(_{i}\) of POIs:

\[_{i}=((E_{L_{id}})(E_{C_{id }})^{T}}{})(E_{C_{token}})+(L_{lon},L_{ lat}),\] (1)

where \(()\), \(()\), and \(()\) denote linear projections, \(d\) is the dimension of \(E_{C_{token}}\), \((,)\) encodes geographic coordinates (latitude and longitude) into an embedding vector (see Appendix H for details). We omit the MLP Layer and Layer Normalizations in Transformer layers to simplify the representation in Eq. 1.

**Visiting Intention Memory Network (VIMN)** is proposed to capture the visiting intentions of users at each check-in record by prioritizing relevant check-in records. As shown in Fig. 1b, we feed the timestamp of each check-in record and the time interval between the adjacent records into the Imminent GRU layer. We adopt a dual encoding approach for time representation: 1) Periodic encoding for timestamps \(t\) as \(T(t)=[(_{1}t),(_{1}t),,(_{k}t),(_ {k}t)]\), where \(\{_{k}\}\) are frequencies determined to capture periodicity across various temporal scales. 2) Logarithmic encoding for time intervals \( t\) represented as \( T=(1+ t)\), which adjusts the GRU's forget gate based on the time interval \( t\). This adjusted factor, denoted as \( T\), affects the forget gate of the GRU unit through \(G_{}( T)=(W_{f} T+b_{f})\). The other components like \(G_{}\) remain unchanged from the original GRU configuration. The Imminent GRU layer can be depicted as:

\[z_{i}=(W_{in}T(t_{i})+G_{}(_{i-1}) G_{ }( T)),\] (2)

where \(z_{i}\) represents the output of the Imminent GRU at time step \(t_{i}\), and \(_{i-1}\) denotes the hidden state at time step \(i-1\). This setup allows for filtering out less relevant, temporally distant data. Subsequently, the outputs \([z_{i-r+1},,z_{i-1},z_{i}]\) from the most recent \(r\) cycles of the Imminent GRU, along with the latest \(r\) PPEs, are forwarded to the feed-forward layer  (further elaborated in Appendix G) to refine the representation of the user's visiting intentions \(_{i}\).

**Human Travel Preference Prompt (HTPP).** This paragraph introduces a method for extracting users' travel preferences to help the LLM enable a comprehensive understanding of human travel preferences and match appropriate prompts from multiple domains. Prompting strategies have demonstrated encouraging outcomes in various applications that aid model predictions . Previous works primarily focus on utilizing a fixed prompt to boost the pre-trained models' performance through fine-tuning  or learnable prompts lacking reality semantic meaning [41; 3]. User behavior is diverse and cannot be accurately summarized as a single fixed prompt to describe the user's travel

Figure 1: The overall of our Mobility-LLM framework. a) POI Point-wise Embedding Layer (**PPEL**). b) Visiting Intention Memory Network (**VIMN**). c) Human Travel Preference Prompt (**HTPP**). d) \(\) denotes the output of the LLM corresponding to VIMN (i.e. first \(n\) output of the LLM), while the remaining outputs are denoted as \(\).

Figure 2: The architecture of HTTP.

preferences. Adopting a prompt-based approach with meaningless learnable prompt vectors can only handle sequences with simple semantics, such as time series . However, it lacks the capability to adequately extract human travel preferences. To address this limitation, we introduce a shared pool of travel preference prompt words across \(D=3\) domains (e.g., occupation, activity type, lifestyle) as illustrated in Fig. 2. Each domain includes a selection of \(m=16\) prompt words. For every prompt word, we create a key-value pair where the value represents the word token obtained from the LLM tokenizer, and the key is derived from the word token through a trainable linear transformation. Specifically, these key-value pairs are defined as follows:

\[P=\{(_{1}^{D},V_{1}^{D}),(_{2}^{D},V_{2}^{D}),,(_{m}^{ D},V_{m}^{D})\},D\{1,2,3\},\] (3)

where \(_{m}^{D},V_{m}^{D}^{L_{E}}\) is a key-value pair, and we maintained it at the same embedding size \(L_{E}\) as visiting intentions \(_{i}\). We then employ a scoring function \((_{i},_{m}^{D})=_{i}_{m}^{D}/\|_{i}\| \|_{m}^{D}\|\) to determine the significance score of each \(_{i}\), where \(:^{L_{E}}^{L_{E}}\). The significant score of each \(_{i}\) indicates the relevance of the current visiting intention to each word in the travel preference prompts pool. Subsequently, we aggregate the significant scores of each \(_{i}\) to identify the top-\(\) most significant pairs in a domain. By defining \(\{m_{j}\}_{j=1}^{}\) as a subset of indices for the selected top-\(\) prompt words in each domain, we obtain the output \([V_{m_{1}}^{D};;V_{m_{}}^{D}]\) of HTTP as prompts (illustrated in Fig. 1c) to more accurately recognize and comprehensively understand user's travel preferences at the level of individual check-in sequences.

**Training Task** In Fig. 1d, the input to the LLMs consists of the output of VIMN \(H=[_{1},_{2},,_{n}]\), HTTP, and the user embedding \(U_{i}\), denoted as \(_{input}\):

\[_{input}=[H,U_{i},V_{m_{1}}^{D};;V_{m_{}}^{D} ],D\{1,2,3\}\] (4)

We concatenate all the tokens along the check-in length dimension. As shown in Fig. 1e, \(\) denotes the output of the LLM corresponding to VIMN (i.e., the first \(n\) output of the LLM), while the remaining outputs are denoted as \(\), where \(n\) is the length of this check-in sequence. Various projection heads are used to predict the next location \(_{n+1}\) the user will arrive at and its arrival time \(_{n+1}\) with the \(\). We use the \(\) and \(\) with a mean pooling projection head to predict the user \(\) who generates this check-in sequence.

## 5 Experiments

To evaluate the performance of our proposed model, we carry out extensive experiments on four real-world check-in sequence datasets, targeting three different types of downstream tasks: Next Location Prediction (LP), Trajectory User Link (TUL), and Time Prediction (TP). We use TinyLlama-1B  as the default backbone unless stated otherwise. The code of Mobility-LLM is released at _https://github.com/LetianGong/Mobility-LLM_.

**Baselines:** For the LP task, we cover five state-of-the-art LP models to demonstrate the superiority of our model: DeepMove , LightMove , PLSPL , HMT-LSTM , LSTPM . For the TUL task, we select four end-to-end models for comparison: TULER , TULVAE , MoveSim , S2TUL . For time prediction methods, we select four SOTA models for comparison: IFLTPP , THP , NSTPP , DSTPP . NSTPP and DSTPP can also be applied to the LP task. For sequence representation methods ReMVC , VaSCL , SML , CACSR , we apply them to learn the representation of the check-in sequence and serve different downstream tasks. More details are in Appendix D.

**Datasets:** In our experiments, we use four real-world datasets derived from Gowalla 3, WeePlace , Brightkite 4, and FourSquare . To ensure data consistency, we set a maximum historical time limit of 120 days and filter out users with fewer than 10 records and places visited fewer than 10 times. Appendix C provides statistical information for each processed dataset. We shuffle all the samples and then split the datasets into training, validation, and test sets in a 6:2:2 ratio based on the number of samples.

[MISSING_PAGE_FAIL:6]

[MISSING_PAGE_FAIL:7]

Processes (TPP) struggle to achieve excellent results across all datasets. However, our model outperforms all baselines in most cases and does so significantly for most of them.

### Few-shot Forecasting

**Setups:** LLMs have recently demonstrated remarkable few-shot learning capabilities . This section assesses whether our reprogrammed LLM retains this ability in different tasks. In our experiments, we maintain consistent splits for training, validation, and test sets in both standard learning (where the full training set is used) and few-shot learning. For few-shot scenarios, we intentionally limit the training data percentage of sample number (i.e., using first 20%, 5%, 1% samples of the training dataset).

**Results:** Our 5% few-shot learning results are in Tab. 4 remarkably excel over all baseline methods, and we attribute this to the successful knowledge activation in our reprogrammed LLM. Interestingly, our approach on both LP and TUL tasks consistently surpasses other competitive baselines, further underscoring the potential prowess of language models as proficient human behavior analysis machines. Concerning recent SOTA models such as NSTPP, DSTPP, S2TUL, ReMVC, and CACSR, our average enhancements surpass **21.4%**, **21.7%**, **86.6%**, **46.2%**, and **45.2%** w.r.t. average on all the metrics. Even with only 5% of the training dataset, our model achieves results comparable to other models using 100% of the training dataset. This is particularly significant for privacy-protected and typically smaller Check-in datasets, as our model can effectively understand the distribution patterns of human behaviors with minimal data.

### Model Analysis

**Language Model Variants.** We compare eight representative backbones with varying capacities (**A.1-8** in Tab. 5). We find that the TinyLlama (**A.1** in Tab. 5) backbone model performed the best overall for our task, while its Chat version (**A.2**) is relatively less suitable for reprogramming. Our results indicate that the scaling law is not strictly retained after the LLM reprogramming. Even

    Tasks \\ Variant \\  }} &  &  &  \\   & Acc@1 & Acc@5 & Acc@20 & MRR & Acc@1 & Acc@5 & Acc@20 & MRR & MAE & RMSE \\ 
**A.1**TinyLlama (Default) & 11.87 & 25.14 & 36.38 & 18.29 & 50.31 & 86.29 & 88.56 & 88.18 & 383.89 & 509.55 \\
**A.2** TinyLlama-Chat & 11.59 & 24.33 & 35.76 & 17.88 & 71.83 & 79.37 & 83.38 & 75.38 & 356.34 & 513.76 \\
**A.3** LieLlama & 11.56 & 25.39 & 35.78 & 18.41 & 80.53 & 85.11 & 86.12 & 81.11 & 354.71 & 496.36 \\
**A.4** phi-2 & 11.22 & 24.29 & 35.97 & 17.62 & 2.33 & 79.53 & 83.55 & 75.77 & 358.67 & 512.28 \\
**A.5** phi-3/0M & 11.03 & 24.86 & 35.74 & 17.91 & 79.47 & 85.51 & 86.18 & 81.69 & 356.71 & 513.15 \\
**A.6** phi-1B & 11.19 & 24.84 & 35.82 & 18.01 & 78.83 & 84.91 & 88.46 & 80.92 & 354.21 & 511.04 \\
**A.7** phi-2-3B & 11.76 & 25.14 & 36.11 & 18.02 & 79.63 & 84.32 & 87.24 & 80.95 & 354.57 & 512.59 \\
**A.8** GPT-2 & 11.33 & 23.67 & 34.49 & 17.28 & 77.01 & 83.33 & 84.35 & 78.98 & 351.85 & 510.01 \\ 
**B.1** w@ HYP & 11.35 & 24.29 & 33.62 & 17.38 & 72.02 & 79.64 & 80.45 & 75.71 & 361.08 & 517.35 \\
**B.2** w/ VINN & 11.01 & 23.27 & 34.03 & 16.83 & 75.88 & 81.79 & 83.72 & 78.06 & 355.65 & 517.26 \\
**B.3** w/o P PELL & 11.32 & 23.74 & 35.31 & 17.61 & 76.11 & 81.85 & 82.96 & 78.37 & 356.01 & 513.12 \\
**B.4** w/o LLM & 10.06 & 20.82 & 31.52 & 15.62 & 70.79 & 76.32 & 78.32 & 73.75 & 366.84 & 526.73 \\   

Table 5: Ablations on Gowalla dataset in all tasks. Red: the best, Blue: the second best. Our full results can be found in Appendix E.3.1. The setting of **A.1-8** can be found in Appendix E.1, and the settings of **B.1-4** can be found in Appendix E.2.

Figure 3: Showcases of the HTTP and VIMN.

the Pythia-70M (**A.5** in Tab. 5) backbone model, which has fewer parameters, can demonstrate advantages in certain datasets and tasks. Therefore, it can be inferred that the suitability of backbone models for different tasks is significantly related to the training strategy of the backbone model, and not just to the number of parameters. For example, in time prediction tasks, GPT-2 (**A.8**) performs better than the 2.7B+ parameter backbone model (**A.4,7**).

**Ablation Study.** As shown in Tab. 5, we find that the removal of (**B.1**) stands as a pivotal element in harnessing the efficiency for the TUL task. We observe a notable average performance degradation of **5.16%** on the TUL task. The inherent habits of human activities can effectively reflect a user's behavioral characteristics, which strongly validates the importance of (**B.1**) in capturing the inherent habits of people's activities. Ablation of this component (**B.2**) results in over **4.09%** degradation on LP task, as people's actions are largely influenced by visiting intentions. Additionally, (**B.3**) allows for more accurate embedding of POI types and semantics, providing a foundation for subsequent modules and tasks. In the w/o LLM setting (**B.4**), we replace the large language model with a standard transformer. (**B.4**) also shows that even without using an LLM as the base model, our reprogramming still achieves excellent results, even surpassing many baselines.

**Reprogramming Interpretation.** We provide three case studies to visualize the improvements brought by HTPP and VIMN. In Fig. 2(a), we visualize the significance of different prompt words in three domain pools within the HTPP model. Orange indicates high significance, and **Purple** indicates low significance. It can be observed that as training progresses, the prompt words for this sample in each domain concentrate on a few words. This also indicates that user behavior is diverse and personalized. To more intuitively see the effect of HTPP, we select 10 different users, each with several samples. We visualize the output of LLM with t-SNE  corresponding to the samples generated by these 10 users in Fig. 2(b) and Fig. 2(c). It can be seen that with the addition of HTPP, the model can more comprehensively capture user behavior patterns and better recognize the behavioral characteristics of each user. Similarly, to better visualize the effect of VIMN, we select a continuous sequence of five user behavior points. Fig. 2(d)-f show the Pearson correlation coefficients between the five outputs \(\) without using the VIMN, without considering Delta Time as input, and when using VIMN, respectively. Fig. 2(g) shows the time intervals among these five points. It can be observed that with the use of the VIMN, the closer the time, the greater the influence on the current state, which aligns with human behavior patterns. Since plans cannot keep up with changes, people's decisions are mostly influenced by recent behaviors. Therefore, our model uses Delta Time as a constraint for correlation, effectively mimicking human activity patterns and achieving better prediction results.

**Hyperparameter Analysis.** There is a significant difference in user behavior patterns across different datasets. As shown in Fig. 3(a), in larger datasets like Foursquare, user behavior is more diverse, and larger K values yield better results. In Fig. 3(b), it can also be seen that the number of nearby cycles in VIMN is highly correlated with the distribution of time intervals in the dataset.

**Reprogramming Efficiency.** Tab. 6 provides an overall efficiency analysis with and without the backbone LLM. Our proposed reprogramming network itself is lightweight in activating the LLM's ability for different tasks (i.e., fewer than 10 million trainable parameters; only around **3.4%** of the total parameters in TinyLlama), and the leveraged backbones actually cap the overall efficiency. This is favorable even compared to the parameter-efficient fine-tuning methods (e.g., QLoRA )

Figure 4: Effects of hyper-parameters validated on different datasets.

in balancing task performance and efficiency. In terms of runtime, the total training time with the advanced fine-tuning framework is acceptable compared to not using LLMs.

## 6 Conclusion

In conclusion, our work presents **Mobility-LLM**, a unified framework leveraging large language models (LLMs) to analyze check-in sequences and understand human mobility behaviors. By incorporating the visiting intention memory network (VIMN) and the human travel preference prompts (HTPP), our model excels in various tasks. Moreover, our model exhibits robust few-shot learning capabilities, outperforming existing methods by an average of 23.6% to 38.3%. Our work paves the way for a more comprehensive and accurate analysis of human mobility, benefiting individuals, businesses, and urban management.

**Limitations** The sets of POIs in different datasets (which usually cover different regions) are unique. Therefore, our proposed model is trained on one dataset, its learned information about the set of POIs is not easily transferable to another dataset. Different sets of POIs have different functionalities and usually have a different number of POIs, making many modules (such as embedding and predictor) technically untransferable in a zero-shot setting. Future work will focus on developing universal user and POI embeddings to enhance cross-dataset migration and improve model versatility.

**Acknowledgment.** This work was supported by the National Natural Science Foundation of China (No. 62372031) and the Beijing Natural Science Foundation (Grant No. 4242029).