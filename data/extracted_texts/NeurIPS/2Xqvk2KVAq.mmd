# Clip-OGD: An Experimental Design for Adaptive Neyman Allocation in Sequential Experiments

Jessica Dai

UC Berkeley

jessicadai@berkeley.edu &Paula Gradu

UC Berkeley

pgradu@berkeley.edu &Christopher Harshaw

MIT

charshaw@mit.edu

###### Abstract

From clinical development of cancer therapies to investigations into partisan bias, adaptive sequential designs have become increasingly popular method for causal inference, as they offer the possibility of improved precision over their non-adaptive counterparts. However, even in simple settings (e.g. two treatments) the extent to which adaptive designs can improve precision is not sufficiently well understood. In this work, we study the problem of Adaptive Neyman Allocation in a design-based potential outcomes framework, where the experimenter seeks to construct an adaptive design which is nearly as efficient as the optimal (but infeasible) non-adaptive Neyman design, which has access to all potential outcomes. Motivated by connections to online optimization, we propose Neyman Ratio and Neyman Regret as two (equivalent) performance measures of adaptive designs for this problem. We present Clip-OGD, an adaptive design which achieves \(}()\) expected Neyman regret and thereby recovers the optimal Neyman variance in large samples. Finally, we construct a conservative variance estimator which facilitates the development of asymptotically valid confidence intervals. To complement our theoretical results, we conduct simulations using data from a microeconomic experiment.

## 1 Introduction

From medicine and public health to economics and public policy, randomized control trials are used in a variety of disciplines to investigate causal effects. Typically, treatment is assigned in a non-adaptive manner, where assignments are determined before any outcomes are observed. A sequential experimental approach, which adaptively assigns treatment based on previously observed outcomes, offers the possibility of more precise or high powered estimates of relevant causal effects. Adaptive experiments are run to develop clinical therapies for breast cancer , evaluate incentives to reduce partisan bias , and evaluate customer acquisition via online advertising , to name a few.

In this paper, we study the problem of Adaptive Neyman Allocation, which we informally define as follows. An optimal non-adaptive experimental design which minimizes variance of an estimator will depend on the unknown potential outcomes, rendering it infeasible to run. However, by adaptively choosing treatment assignments in a sequential manner based on observed outcomes, we can hope to guarantee that the variance of the estimator under the adaptive design converges to the optimal non-adaptive variance. The problem of Adaptive Neyman Allocation is to construct such an adaptive design which guarantees the variance converges to the (infeasible) optimal non-adaptive design.

An experimental design which sufficiently addresses the Adaptive Neyman Allocation problem offers the advantage of higher statistical power, relative to a broad class of fixed experimental designs. Practically speaking, this means that either smaller confidence intervals are obtained for a given number of experimental units, or that fewer units are required to achieve confidence intervals of a given length. In practice, this means that investigating causal effects can be cheaper--in terms of time, money, and other valuable resources--when adaptive experiments are run. Although several experimental designs have been proposed for this purpose (Hahn et al., 2011; Blackwell et al., 2022), none have provided formal guarantees that the optimal non-adaptive variance can be achieved and the effectiveness of such designs has recently been called into question Cai and Rafi (2022).

The main contributions of this work are as follows:

1. **Neyman Ratio and Regret**: We propose two (equivalent) performance measures of experimental designs for the problem of Adaptive Neyman Allocation: Neyman Ratio and Neyman Regret. We show that guarantees on the rates of these performance measures directly translate to guarantees on the convergence of variance to the Neyman variance.
2. **Clip-OGD**: We propose the adaptive design Clip-OGD, a variant of online stochastic projected gradient descent for which the Neyman regret is \(}()\). This guarantees that the variance of the sequential effect estimator approaches the Neyman variance.
3. **Confidence Intervals**: By constructing a conservative variance estimator, we provide confidence intervals which guarantee asymptotic coverage of the average treatment effect.

In Section 7, we support these theoretical results with simulations using data from a microeconomic experiment. Our results rely on viewing the Adaptive Neyman Allocation problem through the lens of online convex optimization. However, as discussed in Section 4.2, due to the subtleties arising in the problem, we do not know of an existing online algorithm which directly obtains these results.

### Related Work

We work within the potential outcomes framework for causal inference Neyman (1923); Rubin (1980); Imbens and Rubin (2015). The idea of optimal treatment allocation dates back to Neyman (1934), where he demonstrates that sampling from treatments proportional to the within-treatment outcome variance will minimize the variance of standard estimators. Unfortunately, this type of design is not practically feasible when little is known about the statistics of outcomes from each treatment. Robbins (1952) highlights adaptive sampling as one of the more pressing open statistical problems at the time. In Chapter 5, Solomon and Zacks (1970) presents a survey of adaptive designs for survey sampling, but from a Bayesian perspective. More recently, Hahn et al. (2011) proposed a two stage design in a super-population setting, where data is uniformly collected from both arms in the first stage, statistics of the treatment arm are estimated, and a fixed probability derived from estimated statistics is used in the second stage. They derive the limiting distribution of the effect estimator under the two-stage design, which has a variance that is similar to, but asymptotically bounded away from the optimal Neyman variance. In a design-based setting, Blackwell et al. (2022) propose a similar two-stage approach and, through simulations, provide practical guidance on how to choose the length of the first stage. Although both of these works are motivated by achieving the Neyman variance, neither formally show that this is possible under the two-stage design.

While the goal in this paper is to increase the precision of treatment effect estimates, a variety of response-adaptive designs have been developed for various objectives, including reducing mean total sample size (Hayre and Turnbull, 1981) and reduction of harm reduction in null hypothesis testing (Rosenberger et al., 2001). Eisele (1994) proposes the Doubly Adaptive Coin Based Design, which is a meta-algorithm for targeting various allocation proportions when outcomes are drawn i.i.d. from an exponential family. Hu and Rosenberger (2003) critiques many response-adaptive designs as being "myopic strategies" which have "adverse effects on power", providing an asymptotic framework by which to judge adaptive design when the outcomes are i.i.d. and binary. This asymptotic evaluation framework was extended to continuous outcomes by Zhang and Rosenberger (2006). An additional line of work has developed adaptive Bayesian methods for subgroup identification (Xu et al., 2014).

Causal inference under adaptively collected data has seen a variety of recent developments which are adjacent to, but distinct from, the problem of Adaptive Neyman Allocation. One line of research has been to construct estimators via re-weighting which ensure consistency and normality when data is collected via bandit algorithms (Hadad et al., 2021; Zhang et al., 2020, 2021). A second line of research has been to provide inferential methods which are valid under data-dependent stopping times (Wald, 1945; Howard et al., 2021; Ham et al., 2022). Finally, Offer-Westort et al. (2021) propose an adaptive experimental design for improved selective inference, when only the effect of the best performing treatment is to be inferred.

## 2 Preliminaries

The sequential experiment takes place over \(T\) rounds, where we assume that \(T\) is fixed and known to the experimenter. At each iteration \(t[T]\), a new experimental unit (e.g. clinical participant), enters into the experiment, so that there are \(T\) units in total. In an abuse of notation, we identify units with their respective round \(t[T]\). The experimenter assigns a (random) treatment \(Z_{t}\{0,1\}\) (e.g. drug or placebo) to the experimental unit. The unit has two real-valued potential outcomes \(y_{t}(1),y_{t}(0)\) which are unknown to the experimenter and represent the unit's measured response to the treatment assignments (e.g. measured heart rate). The term "potential" is used here because while only one treatment is assigned and thus only one outcome is observed, both outcomes have the potential to be observed. At the end of the round, the experimenter sees the observed outcome \(Y_{t}=[Z_{t}=1]y_{t}(1)+[Z_{t}=0]y_{t}(0)\).

### Potential Outcomes Framework

In this paper, we adopt a _design-based framework_ where the sequence of potential outcomes \(\{y_{t}(1),y_{t}(0)\}_{t=1}^{T}\) is deterministic and the only source of randomness is treatment assignment itself. In particular, we place no assumption on the homogeneity of the outcomes: they are not necessarily related to each other in any systematic way. Although the potential outcomes are deterministic, we introduce finite population analogues of various statistics. Define the finite population second moments \(S(1)\) and \(S(0)\) and correlation of the treatment and control outcomes \(\) to be

\[S(1)^{2}=_{t=1}^{T}y_{t}(1)^{2}, S(0)^{2}= {T}_{t=1}^{T}y_{t}(0)^{2},=_{t=1}^{T}y_{t}(1)y_{t}(0)}{S(1)S(0)}.\]

Observe that the correlation between treatment and control outcomes is bounded \([-1,1]\). Although we refer to \(\) as the correlation, it also known as the cosine similarity and is generally not equal to the Pearson correlation coefficient. We remark that although the potential outcomes \(y_{t}(1)\) and \(y_{t}(0)\) are deterministic, the observed outcome \(Y_{t}\) is random, as it depends on random treatment assignment. The natural filtration according to these rounds is denoted as \(_{1}_{T}\), so that \(_{t}\) captures all randomness before the sampling of \(Z_{t}\), i.e. the treatments assigned and outcomes observed in previous rounds.

In this sequential setting, the mechanism for random treatment assignment can incorporate observed outcomes from previous experimental rounds. This treatment mechanism, referred to as the _experimental design_, is selected by and thus known to the experimenter. Formally, the experimental design is a sequence of functions \(\{_{t}\}_{t=1}^{T}\) with signature \(_{t}:(\{0,1\})^{t-1}\) such that treatment is assigned as \((Z_{t}=1_{t})=_{t}(Z_{1},Y_{1}, Z_{t-1},Y_{t-1})\). We denote \(P_{t}=(Z_{t}=1_{t})\) as the (random) probability of treatment assignment at iteration \(t\), given previously observed treatment assignments and outcomes.

The causal estimand of interest is the _average treatment effect_, defined as

\[=_{t=1}^{T}y_{t}(1)-y_{t}(0).\]

The average treatment effect captures the average counterfactual contrast between a unit's outcomes under the two treatment assignments. For example, this could be the average contrast of a clinical participant's heart rate under the drug or placebo. Individual treatment effects are defined as \(_{t}=y_{t}(1)-y_{t}(0)\), but they cannot be estimated without strong additional assumptions, as only one outcome is observed.

A standard estimator of the average treatment effect is the Horvitz-Thompson estimator, which weights observed outcome by the probability of their observation (Narain, 1951; Horvitz and Thompson, 1952). For adaptive designs, the standard Horvitz-Thompson estimator is infeasible because the marginal probability of treatment assignment \((Z_{t}=1)\) depends on the unknown potential outcomes. For this reason, we investigate the _adaptive Horvitz-Thompson estimator_, which uses the random (observed) treatment probabilities used at each iteration.

\[_{t=1}^{T}Y_{t}[Z_{t} =1]}{P_{t}}-[Z_{t}=0]}{1-P_{t}},\]

where we recall that \(P_{t}=_{t}(Z_{1},Y_{1}, Z_{t-1},Y_{t-1})\) is the treatment probability under the experimental design given the observed data. When treatment assignments are non-adaptive and independent, then the adaptive Horvitz-Thompson estimator is the equivalent to the standard Horvitz-Thompson estimator. Such adaptively weighted estimators have been proposed previously in the literature, e.g. (Bowden and Trippa, 2015; Hadad et al., 2021). Below, we provide positivity conditions under which the adaptive estimator is unbiased, and derive its variance.

**Proposition 2.1**.: _If \(\{P_{t},1-P_{t}\}>0\) almost surely for all \(t[T]\) then the adaptive Horvitz-Thompson estimator is unbiased: \([]=\)._

**Proposition 2.2**.: _The variance of the adaptive Horvitz-Thompson estimator is_

\[T()=_{t=1}^{T}y_{t}(1)^{2}\, }+y_{t}(0)^{2}\, }-_{t=1}^{T}_{t}^{2}.\]

### Asymptotic Framework and Assumptions

Following the convention of design-based inference, we analyze statistical methods within an asymptotic framework (see e.g., Freedman, 2008; Lin, 2013; Savje et al., 2021). This provides a formal basis for reasoning about the performance of statistical methods as the sample size increases, giving meaning to conventional notions such as consistency and limiting distribution. Formally speaking, the asymptotic sequence of potential outcomes is a triangular array \(\{\{y_{t,T}(1),y_{t,T}(0)\}_{t=1}^{T}\}_{T=1}^{}\), which yields a sequence of estimands \(\{_{T}\}_{T=1}^{}\) and, together with an appropriately specified sequence of experimental design, a sequence of estimators \(\{_{T}\}_{T=1}^{}\). Analysis which applies to a fixed \(T\) is said to be finite-sample (e.g. \([_{T}]=_{T}\)) whereas analysis which applies to the entire sequence is said to be asymptotic (e.g. \(_{T}-_{T}0\)). Although we use an asymptotic framework, we emphasize that the majority of our results are derived from finite-sample analysis and are merely interpreted through the lens of the asymptotic framework. We drop the subscript \(T\) for notational clarity.

The main regularity conditions we place on the sequence of potential outcomes is below.

**Assumption 1**.: There exist constants \(0<c C\) with \(c<1\) such that for all \(T\) in the sequence:

1. **Bounded Moments**: \(c_{t=1}^{T}y_{t}(k)^{2}^{1/2} _{t=1}^{T}y_{t}(k)^{4}^{1/4} C \;\;k\{0,1\}\).
2. **Bounded Correlation**: \(-(1-c)\).

The upper moment bound in Assumption 1 stipulates that the potential outcomes cannot grow too large with the sample size, while the lower moment bound is a type of non-degeneracy condition that prevents an increasingly large fraction of the outcomes going to zero. These assumptions are analogous to finite fourth moment and positive second moment assumptions in an i.i.d. setting. The bounded correlation assumption stipulates that the treatment and control outcomes are not exactly negatively correlated. In this paper, we do not assume that these constants \(C\) and \(c\) are known to the experimenter; however, if the experimenter can correctly specify such bounds (perhaps knowing a priori the scaling of the outcomes) then some of the constant factors in our analysis can be improved. We emphasize here that Assumption 1 places no assumption on the order in which units arrive in the experiment. In this sense, Assumption 1 allows for arbitrary "non-stationarity" or "drift" in the potential outcomes over the experimental rounds. In the next section, these regularity assumptions will ensure that the Neyman variance converges to zero at the parametric rate.

## 3 Neyman Design: The Infeasible Non-Adaptive Ideal

The problem of Adaptive Neyman Allocation is to construct an adaptive experimental design that achieves nearly the same variance as an optimal non-adaptive experimental design, chosen with knowledge of all potential outcomes. The optimal non-adaptive design, referred to as the Neyman Design, is infeasible to implement because it depends on all potential outcomes, which are unknown to the experimenter at the design stage. The goal is that an adaptive experimental design--which can select treatment assignment based on observed outcomes--can gather enough information to perform as well as the infeasible Neyman design.

In order to define the optimal non-adaptive design, we begin by defining the class of Bernoulli designs. Informally, the class of Bernoulli designs consists of non-adaptive designs where each unit receives treatment \(Z_{t}=1\) with probability \(p\), independently of past treatment assignments and observations. Formally, this class is parameterized by a non-adaptive sampling probability \(p\) such that for all \(t[T]\), the treatment policy \(_{t}\) is a constant function whose value is \(p\). Using Proposition 2.2, we can derive the variance of the Bernoulli design with parameter \(p\) to be

\[T V_{p}=S(1)^{2}-1+S(0)^{2}- 1+2 S(1)S(0).\]

From the above, we can see that in order to minimize the variance of the Horvitz-Thompson estimator under the Bernoulli design, we should set the sampling probability \(p\) so as to balance the square of the second moments of treatment and control outcomes. The Neyman Design is the Bernoulli design which minimizes the variance of the Horvitz-Thompson estimator. The corresponding optimal probability \(p\)* and variance \(V_{}\) are referred to as the Neyman probability and Neyman variance, respectively. The following proposition derives these quantities in terms of the potential outcomes.

**Proposition 3.1**.: _The Neyman variance is \(T V_{N}=2(1+)S(1)S(0)\), which is achieved by the Neyman probability \(p^{*}=(1+S(0)/S(1))^{-1}\)._

In order to quantify the reduction in variance achieved by the Neyman design, define the _relative Neyman efficiency with respect to \(p\)_ to be \(V_{}/V_{p}\). Intuitively, this ratio is a scale-free measure which captures the percent reduction in variance of the sequential Horvitz-Thompson estimator under the Neyman design. Formally, the equation for the relative Neyman efficiency is given below:

\[}}{V_{p}}=2(1+) {p}++^{-1}.\]

Consider the setting where outcomes are uncorrelated, and treatment outcomes are larger than control outcomes, e.g. \(=0\), \(S(1)=4 S(0)\). In this case, the Neyman design is able to achieve less than half the variance of the uniform Bernoulli design (with \(p=1/2\)): we can plug in to 3 to see that in this setting, we have \(V_{N}/V_{p}=0.47\). The improvement is larger if the experimenter makes erroneous assumptions about the relative magnitudes of the treatment and control outcomes and attempts to set \(p\) accordingly: for example, if the experimenter had set \(p=1/4\), incorrectly believing that \(S(1) S(0)\), then the Neyman allocation results in a sixfold improvement in variance. Blackwell et al. (2022) derives qualitatively similar analysis of Neyman efficiency for stratified designs.

While the relative Neyman efficiency is helpful in determining the variance reduction afforded by the (infeasible) optimal Bernoulli design, it does not address the main question: which adaptive experimental designs can guarantee similar variance reduction? In the next section, we propose a performance metric which better addresses this question.

## 4 Adaptive Neyman Allocation: An Online Optimization Approach

### Neyman Ratio and Neyman Regret: New Performance Measures

Let \(V\) be the variance of the adaptive experimental design. We introduce our first performance measure of a sequential experimental design for Adaptive Neyman Allocation.

**Definition 1**.: The _Neyman ratio_ of a sequential experimental design is \(_{T}=(V-V_{})/V_{}\).

The subscript \(T\) in \(_{T}\) in included the reflect dependence of the number of rounds \(T\). The Neyman ratio is motivated by the following relationship between the adaptive variance and the optimal Neyman variance:

\[V=}} V_{}=1+_{T}  V_{}. \]Equation (1) shows that the adaptive design can recover the Neyman variance if and only if the Neyman ratio \(_{T}\) can be made arbitrarily small. For this reason, we propose the Neyman ratio as a performance measure of a sequential experimental design.

A natural question then becomes: how small can the Neyman ratio \(_{T}\) be made as the number of rounds \(T\) increases? To answer this question, we view the problem of minimizing the Neyman ratio through the lens of online optimization. To this end, we must re-express the variance of the sequential experimental design. For each round \(t[T]\), define the cost function \(f_{t}:\) as \(f_{t}(p)=y_{t}(1)^{2}/p+y_{t}(0)^{2}/(1-p)\). Observe that by Proposition 2.2, the variance is given by \(T()=[_{t=1}^{T}f_{t} (P_{t})]\). This reformulation of variance does not allow us to minimize variance directly, for the usual reason that the outcomes, and thus the cost functions \(f_{t}\), are not fully observed. On the other hand, our goal is only to show that the variance of the adaptive design is comparable to the Neyman variance.

**Definition 2**.: The _Neyman regret_ of a sequential experimental design is

\[_{T}=_{t=1}^{T}f_{t}(P_{t})-_{p}_{t=1}^{T}f_{t} (p).\]

Recall that \(P_{t}\) is the random treatment probability at round \(t\). The Neyman regret compares the accumulated costs \(f_{t}(P_{t})\) incurred by the adaptive design to the accumulated costs incurred by the optimal Bernoulli design which has access to all potential outcomes. The Neyman regret is random because the sequence \(P_{1}, P_{T}\) is random. The following theorem connects the expected Neyman regret to the Neyman ratio.

**Theorem 4.1**.: _Under Assumption 1, the Neyman ratio is within a constant factor of the \(1/T\)-scaled expected Neyman regret: \(_{T}=(}[_{T}])\)._

Theorem 4.1 demonstrates that the Neyman ratio can be made small by minimizing the expected Neyman regret in an online fashion. In particular, any sublinear bound on the expected Neyman regret ensures that the Neyman ratio goes to zero so that, in large samples, the adaptive design achieves the variance reduction of the optimal Neyman design. Any adaptive design which aims to achieve Neyman variance must, to some extent, minimize expected Neyman regret.

Fortunately, online optimization is a well-studied area with a rich source of techniques from which we may draw inspiration. However, to the best of our knowledge, existing regret minimization algorithms are not well-suited to minimizing the Neyman regret. For example, the multi-arm bandit literature typically defines regret in terms of a finite number of actions that can be taken (Lattimore and Szepesvari, 2020) while Adaptive Neyman Allocation consists of a continuum of actions as \(P_{t}\). This means that algorithms like UCB (Auer et al., 2002a) and EXP3 (Auer et al., 2002b) are not appropriate for Adaptive Neyman Allocation. Our cost objectives \(f_{t}\) and action space \(\) are both convex, so the problem of Adaptive Neyman Allocation is an instance of Online Convex Optimization (OCO) (Hazan, 2016). Even so, the problem of minimizing Neyman regret is not immediately amenable to existing algorithms, which typically requires assumptions on the cost functions such as bounded gradients or known Lipschitz parameters. In this setting, the cost functions have gradients which blow up at the boundary and Lipschitz parameters cannot be guaranteed as they rely on the unknown heterogeneous potential outcomes. For these reasons, we must design a new algorithm specifically tailored to Adaptive Neyman Allocation.

### Clip-OGD: A Variant of Online Stochastic Projected Gradient Descent

We present Clip-OGD, which aims to minimize the Neyman regret and thus recover the Neyman variance in large samples. The algorithm is based on the online stochastic projected gradient descent principle, but with a twist: the projection set continuously grows over the rounds. At each round \(t\), a new treatment probability \(P_{t}\) is chosen by updating the previous sampling probability \(P_{t-1}\) in the negative (estimated) gradient direction of the previous cost, and then projecting to an interval \([_{t},1-_{t}]\). Initially, this projection interval contains only the point \(1/2\) and it grows as the rounds increase, allowing for larger amounts of exploitation in later rounds.

The gradient estimator \(G_{t}\) is obtained in the following way: the gradient of \(f_{t}\) at \(P_{t}\) is given as \(f^{}(P_{t})=-(1)^{2}}{P_{t}^{2}}+(0)^{2}}{(1-P_{t} )^{2}}\). Only one outcome is observed, so we used the adaptive HorvitzThompson principle using the conditional probability \(P_{t}\) to unbiasedly estimate the outcomes. Clip-OGD is formally presented below as Algorithm 1, where the projection operator is defined as \(_{c}(x)=\{c,\{x,1-c\}\}\).

```
Input: Step size \(\) and decay parameter \(\)  Initialize \(P_{0} 1/2\) and \(G_{0} 0\) for\(t=1 T\)do  Set projection parameter \(_{t}=(1/2) t^{-1/}\)  Compute new treatment probability \(P_{t}_{_{t}}(P_{t-1}- G_{t-1})\)  Sample treatment assignment \(Z_{t}\) as \(1\) with probability \(P_{t}\) and \(0\) with probability \(1-P_{t}\)  Observe outcome \(Y_{t}=[Z_{t}=1]y_{t}(1)+[Z_{t}=0]y_{t}(0)\)  Construct gradient estimator \(G_{t}=Y_{t}^{2}-=1]}{P_{t}^{2}}+=0]}{(1-P_{t} )^{3}}\)  end for
```

**Algorithm 1**Clip-OGD

Unlike the two-stage design of (Hahn et al., 2011; Blackwell et al., 2022), Clip-OGD does not feature explicit explore-exploit stages, but rather performs both of these simultaneously. The trade-off is implicitly controlled through parameters \(\) and \(\): smaller values of \(\) limit the amount of that sampling probabilities can update and, likewise, larger values of \(\) prevent extreme probabilities in earlier stages. Because the gradient of the cost functions are inversely proportional to the treatment probabilities, limiting the extremeness of the treatment probabilities in this way ensures that the gradient estimates do not increase at a fast rate. By appropriately setting input parameters, Clip-OGD achieves \(}()\) expected Neyman regret, where the \(}()\) notation hides sub-polynomial factors.

**Theorem 4.2**.: _Under Assumption 1 the parameter values \(=\) and \(=\) ensure the expected Neyman regret of Clip-OGD is asymptotically bounded: \(_{T}} {T}\)._

Theorem 4.2 answers, in the affirmative, that it is possible to construct an adaptive experimental design whose variance recovers that of the Neyman variance, in large samples. Note that the amount of exploration (as given by the parameters \(\) and \(\)) should be increasing with \(T\) in order to recover these regret bounds. In Appendix C, we show that Clip-OGD is somewhat robust to different values of the decay parameter, i.e. for any value \(>5\), the expected regret will be sublinear. We also show that if the experimenter presumes to have correctly specified bounds \(C\) and \(c\) appearing in Assumption 1, then the step size can be modified to improve the constant factors in the Neyman regret bound, which may lead to improved performance in moderate sample sizes. We conjecture that the minimax rate for expected Neyman regret is \(()\), but proving this is beyond the scope of the current paper--we only remark that we do not know it to immediately follow from any existing regret lower bounds for OCO.

## 5 Inference in Large Samples

The proposed Clip-OGD was constructed to ensure that the variance of the adaptive Horvitz-Thompson estimator quickly approaches the Neyman variance. In this section, we provide confidence intervals for the average treatment effect which also enjoy reduced width compared to non-adaptive counterparts.

A necessary condition for variance estimation is that the variance itself cannot be going to zero too quickly. In design-based inference, it is common to directly posit a so-called "non-superefficient" assumption that \(()=(1/T)\)(Aronow and Samii, 2017; Leung, 2022; Harshaw et al., 2022). The non-superefficiency assumption may be seen as an additional regularity assumption on the outcomes, e.g. preventing \(y_{t}(1)=y_{t}(0)=0\) for all \(t[T]\). In this work, a similar lower bound on the rate of the adaptive variance is obtained through a different, perhaps more transparent, assumption on the expected Neyman regret.

**Assumption 2**.: The outcome sequence is not overly-fit to Clip-OGD: \(-[_{T}]=o(T)\).

While we have shown that \([_{T}]}()\), the Neyman regret could in principle be negative if the adaptive design achieves variance which is strictly smaller than the best Bernoulli design. While this seems unlikely to happen for "typical" outcomes, it is not impossible. Assumption 2 rules out these edge-case settings. We suspect that Assumption 2 would not be necessary in an i.i.d. setting, but proving this seems beyond the scope of the current paper. As shown in the appendix, Assumptions 1 and 2 imply that the adaptive variance achieves the parametric rate: \(()=(1/T)\).

### Variance Estimation

In this section, we provide a variance estimator and show its stability in large samples. Rather than estimating the adaptive variance (which has no simple closed form), our approach is to estimate the Neyman variance directly. For an adaptive design achieving sublinear expected Neyman regret, these two quantities are asymptotically equivalent. In this way, our variance estimator may be appropriate not only for Clip-OGD, but for any adaptive design achieving sublinear expected Neyman regret.

Recall that the Neyman variance is given by \(T V_{}=2(1+)S_{1}S_{0}\), where \(\) is the outcome correlation, \(S_{1}\) is the second moment of treatment outcomes and \(S_{0}\) is the second moment of control outcomes. Unfortunately, the outcome correlation term is generally not estimable without strong assumptions in a design-based framework. Indeed, the difficulty is that terms like \(y_{t}(1)y_{t}(0)\) are unobservable due to the fundamental problem of causal inference (Imbens and Rubin, 2015). A common solution to the problem is to opt for a conservative estimate of the variance, which will ensure validity of resulting confidence intervals.

We propose estimating the following upper bound on the variance: \(T=4S_{0}S_{1}\). This upper bound on the Neyman variance is tight (i.e. \(=V_{}\)) when outcome correlation satisfies \(=1\). For example, this occurs when all individual treatment effects are zero, i.e. \(y_{t}(1)=y_{t}(0)\) for all \(t[T]\). Conversely, the upper bound will become looser for smaller values of the outcome correlation. In this sense, our bound resembles both the Neyman bound and the Aronow-Samii bound (Neyman, 1923; Aronow and Samii, 2013). It may be possible to use the recent insights of Harshaw et al. (2021) in order to construct variance bounds which are tight in other scenarios, but that is beyond the scope of the current paper. Our variance estimator is defined as

\[T} 4_{t=1}^{T}y_{t }^{2}[z_{t}=1]}{p_{t}})(_{t=1}^ {T}y_{t}^{2}[z_{t}=0]}{1-p_{t}})},\]

which is essentially a plug-in Horvitz-Thompson estimator for the second moments. Theorem 5.1 shows the error of the normalized variance estimator converges at a parametric rate.

**Theorem 5.1**.: _Under Assumptions 1 and 2, and the parameters stated in Theorem 4.2, the error of the normalized variance estimator under Clip-OGD is \(T}-T=}_{p}(T^{-1/2})\)._

### Confidence Intervals

The variance estimator may be used to construct confidence intervals for the average treatment effect. This offers experimenters standard uncertainty quantification techniques when running Clip-OGD. The following corollary shows that the resulting Chebyshev-type intervals are asymptotically valid.

**Corollary 5.1**.: _Under Assumptions 1 and 2, and parameters stated in Theorem 4.2, Chebyshev-type intervals are asymptotically valid: for all \((0,1]\), \(_{T}(^{-1/2}}}) 1-\)._

While these confidence intervals are asymptotically valid under our regularity assumptions, they may be overly conservative in general. In particular, they will over cover when the Chebyshev tail bound is loose. We conjecture that the adaptive Horvitz-Thompson estimator under Clip-OGD satisfies a Central Limit Theorem, which would imply asymptotic validity of the narrower Wald-type intervals where \(^{-1/2}\) scaling is replaced with the corresponding normal quantile, \(^{-1}(1-/2)\). As discussed in Section 7, the adaptive estimator appears approximately normal in simulations. Until this is formally shown, we recommend experimenters exhibit caution when using Wald-type confidence intervals for the adaptive Horvitz-Thompson estimator under Clip-OGD.

## 6 Considering Alternative Designs

Explore-Then-CommitTwo-stage adaptive designs have been proposed for the purpose of variance reduction (Hahn et al., 2011; Blackwell et al., 2022). Due to its similarities to algorithms in the banditsliterature, we call these types of designs Explore-Then-Commit (ETC) (Lattimore and Szepesvari, 2020). At a high level, an Explore-then-Commit design runs the Bernoulli design with \(p=1/2\) for \(T_{0} T\) iterations, uses the collected data to estimate \(p^{*}\) by \(^{*}\), and then runs the Bernoulli design with \(p=^{*}\) for the remaining \(T_{1}=T-T_{0}\) iterations. These ETC designs are conceptually simpler than Clip-OGD, and may be reasonable to apply in more restricted settings where changing the treatment probabilities is difficult or costly. However, we provide the following negative result which shows that they can suffer linear Neyman regret.

**Proposition 6.1**.: _For all explore phase lengths \(T_{0}\) satisfying \(T_{0}=(T^{*})\) for some \(>0\), there exist a class of potential outcomes sequences satisfying Assumption 1 such that the Neyman regret under Explore-then-Commit is linear: \(_{T}=_{p}(T)\)._

The specific class of potential outcomes referenced in Proposition 6.1 is constructed explicitly in Appendix E.1. ETC designs suffer larger variance when the estimated \(^{*}\) may be far from the true optimal probability \(p^{*}\). In a design-based setting, this happens when the units in the explore phase are not representative of the entire sequence. Formulating conditions under which Explore-then-Commit designs achieve low Neyman regret is beyond the scope of this paper, but the proof of Proposition 6.1 shows that additional regularity conditions on the order of the units will be required.

Multi Arm Bandit AlgorithmsMulti Arm Bandit (MAB) algorithms are often used for adaptive decision making settings, from online advertising to product development. The goal of MAB algorithms is to minimize the outcome regret, which measures the contrast between the overall value obtained from the actions relative to the value of the best action. The outcome regret is conventionally defined as \(_{T}^{}=_{k\{0,1\}}_{t=1}^{T}y_{t}(k)- _{t=1}^{T}Y_{t}\). In certain contexts, minimizing outcome regret may be a more desirable goal than estimating a treatment effect to high precision. However, the following proposition illustrates that these two objectives are generally incompatible.

**Proposition 6.2**.: _Let \(\) be an adaptive treatment algorithm achieving sublinear outcome regret, i.e. there exists \(q(0,1)\) such that \([_{T}^{}] O(T^{q})\) for all outcome sequences satisfying Assumption 1. Then, there exists a class of outcome sequences satisfying Assumption 1 on which \(\) suffers super-linear Neyman regret, i.e. \([_{T}](T^{2-q})\)._

Proposition 6.2 demonstrates that the outcome regret and the Neyman regret cannot generally be simultaneously minimized. In particular, sublinear outcome regret implies that the variance of the estimator must converge slower than the \((1/T)\) parametric rate. This result contributes to a growing body of work which highlights trade-offs between various possible objectives in sequential decision making (Burtini et al., 2015). It is beyond the scope of the current paper to determine how such trade-offs ought to be resolved, though Appendix F discusses ethical considerations.

## 7 Numerical Simulations

We evaluate the performance of Clip-OGD and Explore-then-Commit (ETC) for the purpose of Adaptive Neyman Allocation on the field experiment of Groh and McKenzie (2016), which investigates the effect of macro-insurance on micro-enterprises in post-revolution Egypt2. The experimental units are 2,961 clients of Egypt's largest microfinance organization and the treatment was a novel insurance product. Several outcomes were recorded including whether the clients took on loans, introduced a new product or service, and the amount invested in machinery or equipment following treatment. To allocate treatment, Groh and McKenzie (2016) use a non-adaptive matched pair experimental design. Our goal here is not to provide a new analysis of this study, but rather to construct a plausible experimental setting under which to evaluate adaptive experimental designs.

In our simulations, we focus on the numerical outcome "invested in machinery or equipment". The experimental data contains only observed outcomes, so we must impute the missing potential outcomes in order to simulate the experiment. We impute outcomes using the model \(y_{t}(1)-y_{t}(0)=+_{t}\), where \(=90,000\) and \(_{1}_{T}(0,^{2})\) are independent with \(=5,000\). This randomness is invoked only to impute potential outcomes, i.e. not re-sampled during each run of the experiment. In order to increase the sample size, we create a larger population by repeating this processes \(5\) times, which yields a total of \(14,445\) units after those with missing entries are removed. Units are shuffled to appear in an arbitrary order and outcomes are normalized to be in the range\(\)Figure 1 presents two plots illustrating how the variance of the adaptive HT estimator varies with different designs. The \(x\) axis contains the number of rounds \(T\) and the \(y\) axis contains the normalized variance \(T()\) under the designs. For each value of \(T\), we take the population to be the first \(T\) units in the sequence. Clip-OGD is run with the parameters recommended in Theorem 4.2 and ETC is run with \(T_{0}=T^{1/3}\) so that the exploration phase grows with \(T\). The variance under Clip-OGD and ETC is estimated empirically from 50,000 runs of the experiment, while the variance under the Bernoulli and Neyman designs is computed exactly.

In Figure 0(a), we observe that Clip-OGD requires about \(T=4,000\) samples to achieve variance equal to Bernoulli, but eventually converges to the Neyman variance. As discussed in Section 4.2, it may be possible to improve the convergence rate by incorporating knowledge of the outcome moments in the design parameters. On the other hand, ETC remains comparable with Bernoulli even for small values of \(\), but remains far away from the Neyman design for large samples. In Figure 0(b), a similar simulation is run, except that the potential outcomes of the first 100 units are swapped, so that the first units have negative individual treatment effects. While this produces little effect on the performance of Clip-OGD, it substantially worsens the performance of ETC, which relies on the early outcomes to estimate an optimal treatment probability. In particular, ETC performs worse than Bernoulli under this minor modification--even in large samples--corroborating Proposition 6.1.

In the appendix, we evaluate the proposed confidence intervals, showing that Clip-OGD enjoys intervals of reduced width. We show that normal based intervals cover at the nominal level and provide further evidence that the estimator is asymptotically normal under Clip-OGD. We run additional simulations to investigate the sensitivity of the step size, and to demonstrate that additional baselines which were not designed for Neyman allocation indeed perform poorly.

## 8 Conclusion

In this paper, we have proposed the Neyman ratio and Neyman regret as a performance measure of experimental designs for the Adaptive Neyman Allocation problem. To this end, we proposed Clip-OGD which achieves \(}()\) expected Neyman regret under mild regularity conditions on the outcomes. This formally establishes--for the first time--the existence of adaptive experimental designs under which the variance of the effect estimator quickly approaches the Neyman variance. Finally, we have provided a variance estimator which provides experimenters with uncertainty quantification methods when using Clip-OGD. The main drawback of our analysis is that it is most relevant for moderate and large sample sizes; in particular, our work does not properly address whether adaptive designs are always beneficial in small samples.

There are several research directions which can improve relevance of this methodology to practice. First, establishing conditions under which a central limit theorem holds for Clip-OGD will yield smaller and thus more desirable Wald-type confidence intervals. Second, investigations into batched treatment allocations and delayed observations of outcomes would allow practitioners more flexibility in their designs. Finally, investigating variants of Adaptive Neyman Allocation in the presence of interference (Aronow and Samii, 2017; Harshaw et al., 2022) would allow for more realistic inference in complex settings, e.g. social network experiments and marketplace experiments.

Figure 1: Normalized Variance of Adaptive Estimator under Experimental Designs