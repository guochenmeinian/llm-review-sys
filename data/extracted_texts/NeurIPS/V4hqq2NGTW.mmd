# Perceptual Kalman Filters: Online State Estimation

under a Perfect Perceptual-Quality Constraint

 Dror Freirich

Technion - Israel

Institute of Technology

drorfrc@gmail.com &Tomer Michaeli

Technion - Israel

Institute of Technology

tomer.m@ee.technion.ac.il &Ron Meir

Technion - Israel

Institute of Technology

rmeir@ee.technion.ac.il

###### Abstract

Many practical settings call for the reconstruction of temporal signals from corrupted or missing data. Classic examples include decoding, tracking, signal enhancement and denoising. Since the reconstructed signals are ultimately viewed by humans, it is desirable to achieve reconstructions that are pleasing to human perception. Mathematically, perfect perceptual-quality is achieved when the distribution of restored signals is the same as that of natural signals, a requirement which has been heavily researched in static estimation settings (i.e. when a whole signal is processed at once). Here, we study the problem of optimal _causal_ filtering under a perfect perceptual-quality constraint, which is a task of fundamentally different nature. Specifically, we analyze a Gaussian Markov signal observed through a linear noisy transformation. In the absence of perceptual constraints, the Kalman filter is known to be optimal in the MSE sense for this setting. Here, we show that adding the perfect perceptual quality constraint (i.e. the requirement of temporal consistency), introduces a fundamental dilemma whereby the filter may have to "knowingly" ignore new information revealed by the observations in order to conform to its past decisions. This often comes at the cost of a significant increase in the MSE (beyond that encountered in static settings). Our analysis goes beyond the classic innovation process of the Kalman filter, and introduces the novel concept of an unutilized information process. Using this tool, we present a recursive formula for perceptual filters, and demonstrate the qualitative effects of perfect perceptual-quality estimation on a video reconstruction problem.

## 1 Introduction

In many settings, it is desired to reconstruct a temporal signal from corrupted or missing data. Examples include decoding of transmitted communications, tracking targets based on noisy measurements, enhancing audio signals, and denoising videos. Traditionally, restoration quality has been assessed by distortion measures such as MSE. As a result, numerous methods targeted the minimization of such measures, including the seminal work of Kalman . However, in applications involving human perception, one may favor reconstructions that cannot be told apart from valid signals. Mathematically, such _perfect perceptual quality_ can be achieved only if the distribution of restored signals is the same as that of "natural" signals.

Interestingly, it has been shown that good perceptual quality generally comes at the price of poor distortion and vice versa. This phenomenon, known as the _perception-distortion tradeoff_, was first studied in , and was later fully characterized in  for the particular setting where distortion is measured by MSE and perception is measured by the Wasserstein-\(2\) distance between the distribution of estimated signals and the distribution of real signals. However, to date, all existing works addressed the static (non-temporal) setting, in which the entire corrupted signal is available for processing all atonce. This setting is fundamentally different from situations involving temporal signals, in which the corrupted signal is processed causally over time, such that each sample is reconstructed only based on observations up to the current time.

To illustrate the inherent difficulty in causal estimation, consider video restoration tasks like denoising, super-resolution, or frame completion (see Fig. 1). Achieving high perceptual quality in those tasks requires generating restored videos whose spatio-temporal distribution matches that of natural videos. Particularly, an incorrect temporal distribution may lead to flickering artifacts  or to unnaturally slow dynamics . To comply with this requirement, the restoration method needs to 'hallucinate' motion whenever the dynamics cannot be accurately determined from the measurements. For example, it may be impossible to determine whether a car is standing still or moving slowly from just a few noisy frames, yet the restoration method must generate _some_ (nearly) constant velocity in order to comply with the statistics of natural videos. However, as more measurements become available, the uncertainty may be reduced, and it may become evident that the hallucinated dynamics were in fact incorrect. When this happens, the method cannot suddenly change the motion in the output video, because such an abrupt change would deviate from natural video statistics. Thus, although the method "becomes aware" of its mistake, it may have to stick to its past decisions for a while. A natural question is, therefore:

_What is the precise cost of temporal consistency in online restoration?_

In this paper, we study this question in the setting where the signal to be restored, \(x_{t}\), is a discrete-time Gaussian Markov process, and the measurements \(y_{t}\) are noisy linear transformations of the signal's state. We address the problem of designing a _causal filter_ for estimating \(x_{t}\) from \(y_{t}\), where the distribution law of the filter's output, \(_{t}\), is constrained to be the same as that of \(x_{t}\) (perfect perceptual quality). We show that this temporal consistency constraint indeed comes at the cost of increased MSE compared to filters that only enforce the correct distribution per time step, but not joint distributions across time steps. To derive a recursive form for linear perceptual filters, we introduce the novel concept of an _unutilized information_ process, which is the portion of accumulated information that does not depend on past estimates. We provide a closed-form expression for the MSE of such filters and show how to design their coefficients to minimize different objectives. We further establish a special class of perceptual filters, based on the classic _innovation_ process, which has an explicit solution. We analyze the evolution of MSE over time for perceptual filters and for non-perceptual ones in several numerical setups. Finally, we demonstrate the qualitative effects of perfect perceptual-quality estimation on a simplified video reconstruction problem.

Related workMany works proposed practical algorithms for achieving high (spatio-temporal) perceptual quality in video restoration tasks. Bhattacharjee and Das  improved temporal coherence by using a loss that penalizes discontinuities between sequential frames. Perez-Pellitero et al.  suggested a recurrent generator architecture whose inputs include the low-resolution current frame (at time \(t\)), the high-resolution reconstruction of the previous one (at time \(t-1\)), and a low-resolution version of the previous frame, aligned to the current one. The model is trained using losses that encourage it to conserve the joint statistics between consecutive frames. Chu et al.  introduced a temporally coherent GAN architecture (TecoGAN). Their generator's input includes again a warped version of the previously generated frame, where each discriminator input consists of 3 consecutive frames, either generated or ground-truth. They also introduced a bi-directional loss that encourages long-term consistency by avoiding temporal accumulation of artifacts, and another loss which measures the similarity between motions. More recent progress in generating temporally coherent videos includes _Make-a-video_ that expands a text-to image model with spatio-temporal convolutional and attention layers, and Video-Diffusion Models  that use a

Figure 1: **The temporal consistency dilemma.** Estimation cannot suddenly change the motion in the output video, because such an abrupt change would deviate from natural video statistics. Thus, although the method is aware of its mistake, it may have to stick to its past decisions.

diffusion model with a network architecture adapted to video. In the context of online restoration, we mention the work of Kim et al.  which presented a GAN architecture for real-time video deblurring, where restoration is done sequentially. They introduce a network layer for dynamically (at test-time) blending features between consecutive frames. This mechanism enables generated features to propagate into future frames, thus improving consistency. We note, however, that our work is the first to provide a theoretical/mathematical framework, and a closed-form solution for a special case.

## 2 Preliminaries: The distortion-perception tradeoff

Let \(x,y\) be random vectors taking values in \(^{n_{x}}\) and \(^{n_{y}}\), respectively, with joint probability \(p_{xy}\). Suppose we want to estimate \(x\) based on \(y\), such that the estimator \(\) satisfies two requirements: (i) It has a low distortion \([d(x,)]\), where \(d(,)\) is some measure of discrepancy between signals; (ii) It has a good perceptual quality, _i.e._ it achieves a low value of \(d_{p}(p_{x},p_{})\), where \(d_{p}(,)\) is a divergence between probability measures. Blau and Michaeli  studied the best possible distortion that can be achieved under a given level of perceptual quality, by introducing the _distortion-perception_ function

\[D(P)=_{p_{|y}}\{[d(x,)]\ :\ d_{p}(p_{x},p_{})  P\}.\] (1)

Freirich et al.  provided a complete characterization of \(D(P)\) for the case where \(d\) is the squared-error and \(d_{p}\) is the Wasserstein-\(2\) distance. Particularly, in the Gaussian case, they developed a closed-form expression for the optimal estimator.

In this paper we discuss estimation with perfect perceptual quality, namely \(P=0\). In this case, [8, Thm. 4] implies that if \(x\) and \(y\) are zero-mean, jointly-Gaussian with covariances \(_{x},_{y} 0\), and \(x^{*}=[x|y]\), then a MSE-optimal perfect perceptual-quality estimator is obtained by

\[=^{*}x^{*}+w,^{*}_{x}^{ }(_{x}^{}_{x^{*}}_{x}^{}) ^{}_{x}^{-}_{x}^{},\] (2)

where \(w\) is a zero-mean Gaussian noise with covariance \(_{w}=_{x}-^{*}_{x}^{*}^{*}\), independent of \(y\) and \(x\), and \(_{x^{*}}^{}\) is the Moore-Penrose inverse of \(_{x^{*}}\). For the more general case where \(_{x} 0\), a similar result can be obtained by using Theorem F.2 in the Appendix.

## 3 Problem formulation

We consider a state \(x_{k}^{n_{x}}\) with linear dynamics driven by Gaussian noise, and observations \(y_{k}^{n_{y}}\) that are linear transformations of \(x_{k}\) perturbed by Gaussian noise,

\[x_{k} =A_{k}x_{k-1}+q_{k}, k=1,...,T,\] (3) \[y_{k} =C_{k}x_{k}+r_{k}, k=0,...,T.\] (4)

Here, the noise vectors \(q_{k}(0,Q_{k})\) and \(r_{k}(0,R_{k})\) are independent white Gaussian processes, and \(x_{0}(0,P_{0})\) is independent of \(q_{1},r_{0}\). For convenience, we will sometimes refer to \(P_{0}\) as \(Q_{0}\). The matrices \(A_{k}\), \(C_{k}\), \(Q_{k}\), \(R_{k}\) and \(P_{0}\) are deterministic system parameters with appropriate dimensions, and assumed to be known.

Our goal is to construct an estimated sequence \(_{0}^{T}=(_{0},,_{T})\) based on the measurements \(Y_{0}^{T}=(y_{0},,y_{T})\), which minimizes the cost

\[(_{0},,_{T})=_{k=0}^{T}_{k} [\|x_{k}-_{k}\|^{2}],\] (5)

for some given weights \(_{k} 0\). Importantly, we want to do so under the following two constraints.

\[: _{k} p_{_{k}}(|y_{0},,y_{k}, _{0},,_{k-1}),\] (6) \[: p_{_{0}^{T}}=p_{X_{0}^{T}}.\] (7)

Condition (6) states that each prediction should depend only on past and present observations and on the past predictions. Note that Condition (7) requires not only that every estimated sample have the same distribution as the original one, but also that the _joint_ distribution of every subset of reconstructed samples be identical to that of the corresponding subset of samples in the original sequence. In the context of video processing, this means that not only does every recovered frame have to look natural, but also that motion must look natural. This perfect perceptual quality constraint is what sets our problem apart from the classical Kalman filtering problem, which considers only the causality constraint. Since we will make use of the Kalman filter, let us briefly summarize it.

The Kalman filter (no perceptual quality constraint)Let \(^{*}_{k|s}[x_{k}|y_{0},,y_{s}]\) denote the estimator of \(x_{k}\) based on all observations up to time \(s\), which minimizes the MSE. The celebrated Kalman filter  is an efficient method for calculating the _Kalman optimal state_\(^{*}_{k}^{*}_{k|k}\) recursively without having to store all observations up to time \(k\). It is given by the recurrence

\[^{*}_{k}=A_{k}^{*}_{k-1}+K_{k}_{k},\] (8)

where \(K_{k}\) is the _optimal Kalman gain_, whose recursive calculation is given in Algo. 2 in the Appendix. The vector \(_{k}\) is the _innovation_ process,

\[_{k}=y_{k}-C_{k}^{*}_{k|k-1},\] (9)

describing the new information carried by the observation \(y_{k}\) over the optimal prediction based on the observations up to time \(k-1\), which is given by \(^{*}_{k|k-1}=A_{k}^{*}_{k-1}\). The innovation \(_{k}\) is uncorrelated with all observations up to time \(k-1\), which guaranties the MSE optimality of the estimation. The calculation of the Kalman state is also summarized in Alg. 2. Pay attention to the innovation process \(_{k}\), its covariance \(S_{k}\) and gain \(K_{k}\), which we will build upon. Our notations are summarized in Table 2 in the Appendix. Note that since the Kalman filter minimizes the MSE at each timestep, it also minimizes (5) regardless of the choice of \(_{k}\), but it generally fails to fulfill (7). As we will see later, when taking (7) into consideration, the choice of \(_{k}\) does affect the optimal filter.

Temporally-inconsistent perceptual filterA naive way to try to improve the perceptual quality of the Kalman filter would be to require that each \(_{k}\) be distributed like \(x_{k}\) (but without constraining the joint distribution of samples). In the context of video processing, each frame generated by such a filter would look natural, but motion would not necessarily look natural. This problem can be solved using the result (2), which gives the optimal "temporally-inconsistent" perceptual estimator

\[^{}_{k}=^{*}_{k}^{*}_{k}+w_{k}=^ {*}_{k}(A_{k}^{*}_{k-1}+K_{k}_{k})+w_{k},\] (10)

with \(^{*}_{k}\) and \(w_{k}\) from (2). These quantities depend only on the covariances of \(x_{k},^{*}_{k}\), which can be computed recursively using the Kalman method. The MSE of this estimator is given by (see )

\[[\|x_{k}-_{k}\|^{2}]=d^{*}_{k}+ \{_{x_{k}}+_{^{*}_{k}}-2(^{}_{ _{k}}_{^{*}_{k}}^{}_{_{k}}) ^{}\},\] (11)

where \(d^{*}_{k}\) is the MSE of the Kalman filter, which can also be computed recursively.

Our setting (with the perceptual quality constraint)Going back to our setting, one may readily recognize that perceptually reconstructing the signal \(X^{T}_{0}\) from the full measurement sequence \(Y^{T}_{0}\) is also a special case of the Gaussian perceptual restoration problem discussed in Section 2, only applied to the entire sequence of states and measurements. Generally, this estimate already achieves a higher MSE than the estimate that minimizes the MSE without the perceptual constraint. However, in our setting we have the additional causality constraint (6). Requiring both constraints (7) and (6) might incur an additional cost, as illustrated by the following example, where applying each one of them does not restrict the optimal solution, but together they result in a higher MSE.

_Example 3.1_.: Let \(T=1\) and consider the process \((x_{0},x_{1})=(q_{0},q_{0})\), where \(q_{0}(0,1)\), with observations \((y_{0},y_{1})=(0,x_{1})\). Assume we want to minimize the error at time \(k=1\) (namely \((_{0},_{1})=(0,1)\) in (5)). Then, considering only the causality constraint (6), the estimator \((_{0},_{1})=(y_{0},y_{1})\) is optimal. Indeed, it is causal and it achieves zero MSE. Similarly, considering only the perceptual quality constraint (7), the estimator \((_{0},_{1})=(y_{1},y_{1})\) is optimal. Indeed, it is distributed like \((x_{0},x_{1})\) and it also achieves zero MSE. However, when demanding both conditions, \(_{0}\) must be based on no information to obey (6) (as \(y_{0}=0\)), and it must be drawn from the prior distribution \((0,1)\) in order to be distributed like \(x_{0}\) and obey (7). Furthermore, to satisfy (7), we must also have \(_{1}=_{0}\). Therefore, the optimal estimator in this case is \((_{0},_{1})=(_{0},_{0})\), where \(_{0}(0,1)\) is independent of \(q_{0}\). The MSE achieved by this estimator is \(2\).

## 4 Perfect perceptual-quality filters

The perceptual constraint (7) dictates that the estimator must be of the form

\[_{k}=A_{k}_{k-1}+J_{k},_{0}=J_{0},\] (12)where \(J_{k}=_{k}-A_{k}_{k-1}\) is distributed as \((0,Q_{k})\) and is independent of \(_{0}^{k-1}\). Note the similarity between (12) and the MSE-optimal state (8), in which \(J_{k}=K_{k}_{k}\). Here, however, this choice is not valid due to the constraint on the output distribution. In terms of temporal consistency, an estimator of the form (12) guarantees that previously presented features obey the natural dynamics of the domain, while newly generated estimates do not contradict the previous ones. In order to maintain causality (6), \(J_{k}\) must be of the form

\[J_{k} p_{J_{k}}(|y_{0},,y_{k},_{0},,_{k-1}),\] (13)

_i.e._, \(J_{k}\) is independent of future observations \(Y_{k+1}^{T}\) given \(Y_{0}^{k}\). As a consequence, \(J_{k}\) is uncorrelated with \(_{k+n}\) for all \(n 1\).

We now discuss linear estimators, where \(Y_{0}^{T}\) and \(J_{0}^{T}\) (hence \(_{0}^{T}\)) are jointly Gaussian. Our first result is as follows (see proof in App. B).

**Theorem 4.1**.: _Under the cost (5), there exists a linear optimal estimator of the form_

\[J_{k}=_{k}_{k}+_{k}_{k}+w_{k},\] (14)

\(_{k}^{n_{x} n_{y}}\) _and \(_{k}^{n_{x}(kn_{y})}\) are the filter's coefficients, \(w_{k}\) is an independent Gaussian noise with covariance \(_{w_{k}}=Q_{k}-_{k}S_{k}_{k}^{}-_{k}_{_{k}} _{k}^{} 0\), \(_{k}\) is the process of unutilized information_

\[_{k}_{0}^{k-1}-[_{0}^{ k-1}|_{0}^{k-1}],\,_{0}^{k-1}= \{_{0},,_{k-1}\},_{0}=0.\] (15)

Note that with this form for \(J_{k}\), the state \(_{k}\) is indeed a function of the observations \(Y_{0}^{k}\) and the previous states \(_{0}^{k-1}\). Intuitively, \(_{k}\) is the part of the information in the observations, which has no correlation with the information used to construct the past estimates \(_{0}^{k-1}\). Thus, from the standpoint of the filter's output, this information has not yet been introduced. As opposed to the innovation \(_{k}\), the process \(_{k}\) is not white, and it is affected by the choices of \(_{t}\) and \(_{t}\) up to time \(k-1\). However, \(_{k}\) is always independent of \(_{k}\), since \(_{k}\) is independent of \(_{0}^{k-1}\) and \(J_{0}^{k-1}\), which constitute \(_{k}\).

The filter of Theorem 4.1 is causal but not recursive. Specifically, although it is possible to obtain \(_{k+1},_{_{k+1}}\) given the coefficients \(\{_{t},_{t}\}_{t=0}^{k}\) (see App. E), the dimension of \(_{k}\) grows with time (it is \(kn_{y}\)), thus increasing the cost of computing \(_{k}_{k}\). Furthermore, determining the coefficients \(\{_{k},_{k}\}_{k=0}^{T}\) that minimize the objective (5) (which is done a-priori in an offline manner) requires solving a large optimization problem, as the total size of all coefficients is \((n_{x}n_{y}T^{2})\). To efficiently optimize these coefficients, we next suggest two simplified versions of this form, which may generally be sub-optimal but easier to optimize.

_Remark 4.2_.: A remark is in place regarding objectives beyond the squared-error. While (14) forms an optimal filter under the cost (5), it can be considered as a representation for linear filters in general. The constraints on the coefficients (\(Q_{k}-_{k}S_{k}_{k}^{}-_{k}_{_{k}}_{k}^{}  0\)) are necessary and sufficient for perfect perception, regardless of the cost objective. It is therefore possible to optimize coefficients for objectives other than MSE under these constraints to obtain optimal perceptual _linear_ filters. Optimization may be performed numerically (when the cost is tractable) or in an online fashion, assuming access to ground-truth samples. Note, however, that under general distortion measures, optimal filters might be non-linear.

Figure 2: **Recursive perceptual filtering (Sec. 4.1).** The state estimator \(_{k}\) consists of the previous state \(_{k-1}\), and the innovation and unutilized information processes. The unutilized information state \(_{k+1}\) is updated using the previously unutilized information \(_{k}\) and the newly-arriving information \(_{k}\). The currently utilized information, arriving from \(J_{k}\), is then subtracted from \(_{k+1}\).

### Recursive-form filters

The optimal Kalman state \(_{k}^{*}\) achieves the minimal possible MSE, given by \(d_{k}^{*}=[\|_{k}^{*}-x_{k}\|^{2}]=\{P _{k|k}\}\), where \(P_{k|k}\) is the error covariance, given explicitly in Alg. 2. By the orthogonality principle (see _e.g._[8, Lemma 2]), any other estimator \(_{k}\) based on the observations \(Y_{0}^{k}\), satisfies

\[[\|x_{k}-_{k}\|^{2}]=d_{k}^{*}+[\| _{k}-_{k}^{*}\|^{2}].\] (16)

Now, consider an estimator \(_{k}\) of the form (12), and let \(D_{k}[(_{k}^{*}-_{k})(_{k}^{*}-_{k})^{}]\). Since we choose \(J_{k}\) to be normally distributed and independent of \(_{k-1}\), it is easy to see that \(D_{k}\) obeys the _Lyapunov difference equation_

\[D_{k}= A_{k}D_{k-1}A_{k}^{}+K_{k}S_{k}K_{k}^{}+Q_{k}\] \[-[J_{k}_{k}^{}]K_{k}^{}-K_{k} [_{k}J_{k}^{}]-A_{k}[_{k-1}^{*}J_{k }^{}]-[J_{k}_{k-1}^{*}]A_{k}^{}.\] (17)

As we see, the choice of \(J_{k}\) affects current (and future) errors by its correlation with the two independent components, \((A_{k}_{k-1}^{*},K_{k}_{k})\). Let us now consider filters of the form

\[J_{k}=_{k}A_{k}_{k}+_{k}K_{k}_{k}+w_{k}, w_{k} (0,_{w_{k}}),\] (18)

where here, by slight abuse of notation, we define the process of unutilized information as

\[_{k}_{k-1}^{*}-[_{k-1}^{*}| _{0},,_{k-1}],_{0}=0.\] (19)

The matrices \(_{k},_{k}^{n_{x} n_{x}}\) are coefficients such that

\[_{w_{k}}=Q_{k}-_{k}A_{k}_{_{k}}A_{k}^{}_{k}^{ }-_{k}M_{k}_{k}^{} 0,\] (20)

where we denote the Kalman update covariance by \(M_{k} K_{k}S_{k}K_{k}^{}\). This guarantees that \(J_{k}{}N(0,Q_{k})\), as desired. Importantly, as opposed to \(v_{k}\), the dimension of \(_{k}\) is _fixed_, namely it does not grow with time \(k\). Note that since \(_{k-1}^{*}\) is a linear combination of \((_{0},,_{k-1})\), (18) is a special choice of \(_{k}\) and \(_{k}\) in (14) where coefficient size does not grow with \(k\) as well. \(_{k}\) and its covariance \(_{_{k}}\) are given via a recursive form, illustrated in Fig. 2 (and derived in App. E):

\[_{k+1}=A_{k}_{k}+K_{k}_{k}-_{k}Q_{k }^{}J_{k},\,_{_{k+1}}=A_{k}_{_{k}}A_{k}^{ }+M_{k}-_{k}Q_{k}^{}_{k}^{},\] (21) \[_{k} M_{k}_{k}^{}+A_{k}_{_{k}}A_{k}^{ }_{k}^{}.\] (22)

Note again that unlike the innovation \(_{k}\), \(_{k}\) might not be a white process, but we have that \(_{k}\) is independent of the filter's output \(_{0}^{k-1}\) and \(_{k}\). Equation (17) now takes the form

\[D_{k}= A_{k}D_{k-1}A_{k}^{}+Q_{k}+M_{k}-_{k}M_{k}-M_{k}_{k}^{}-A _{k}_{_{k}}A_{k}^{}_{k}^{}-_{k}A_{k}_{ _{k}}A_{k}^{},\] (23)

where we observe that \(_{_{k}}\) may depend on the choice of \(\{_{t},_{t}\}_{t=0}^{k-1}\). In order to retrieve an optimal filter, one should perform optimization of the desired objective over \(\{_{t},_{t}\}_{t=0}^{T}\), under the constraints given in (20). From (16), minimizing the cost (5) boils down to minimizing \(_{k=0}^{T}_{k}\{D_{k}\}\) subject to the constraints in (20), which is an optimization problem over only \((n_{x}^{2}T)\) parameters.

### An Exactly solvable reduction: Perceptual Kalman Filter

We now consider an additional reduction, which allows to obtain a closed form solution for the filter's coefficients. Specifically, a reduced-size filter can be obtained by using the form (12) and (18) with the sub-optimal choice \(_{k} 0\), namely

\[J_{k}=_{k}K_{k}_{k}+w_{k}.\] (24)

The meaning of this choice is that only newly-observed information is used for updating estimation at each stage, while non-utilized information from previous time steps is discarded. We note that such a simplification should be used with discretion; while requiring only half of the computations, rejecting the unutilized information might lead to enhanced errors in some settings (_e.g._ when an observation is missing). However, in many cases where observations are informative and different timesteps are weakly correlated, past unutilized information rapidly becomes irrelevant and can be safely ignored. We demonstrate the utility of this reduction in Sec. 5. Here, \(_{k}\) is a \(n_{x} n_{x}\) coefficient matrix, and\(w_{k}(0,Q_{k}-_{k}M_{k}_{k}^{})\) is a Gaussian noise, uncorrelated with all other states, observations and noises in the system up to time \(k\). Again, note that \(_{k}\) is independent of the measurements up to time \(k-1\), hence this choice makes \(J_{k}\) independent of \(_{0}^{k-1}\). These innovation-based corrections resemble the mechanism exploited in (8), hence we will refer to optimal filters of the form (24) as _perceptual_ Kalman filters (PKF).

Now, by a straightforward substitution, (17) becomes

\[D_{k}=A_{k}D_{k-1}A_{k}^{}+Q_{k}+M_{k}-_{k}M_{k}-M_{k}_{k}^{},  k=0,,T,\] (25)

where we consider \(Q_{0}=P_{0}\), \(M_{0}=_{_{0}^{*}}\) and \(D_{-1}=0\). As before, minimizing (5) boils down to minimizing \(_{k=0}^{T}_{k}\{D_{k}\}\), and in order for (24) to be well-defined, we should enforce the constraints \(Q_{k}-_{k}M_{k}_{k}^{} 0\), \(k=0,,T\). For simplicity, we consider the time-invariant case where \(A_{k} A\), so that the optimization objective becomes

\[_{\{_{k}\}_{k=0}^{T}}&_{k=0}^{T}_{k} \{D_{k}\}\\ &D_{k}=_{k=0}^{k}A^{k-t}[_{t}-_{t}M_{t}-M _{t}_{t}^{}](A^{})^{k-t}, k=0,,T,\\ &Q_{k}-_{k}M_{k}_{k}^{} 0, k=0,,T,\] (26)

where we denoted \(_{k}=Q_{k}+M_{k}\). Substituting \(D_{k}\), we can rewrite the objective as

\[_{k=0}^{T}\{_{t=k}^{T}_{t}A^{t-k}[_{k}-2_{k}M_{k}](A^{})^{t-k}\}.\] (27)

As we can see, optimization over a particular coefficient \(_{k}\) does not affect other summands of the external sum. Therefore, each \(_{k}\) can be optimized separately. Minimizing the cost at the \(k\)-th step is equivalent to

\[_{_{k}}\{_{k}M_{k}_{t=k}^{T}_{t}(A^{t-k}) ^{}A^{t-k}\} Q_{k}-_{k}M_{k}_{k}^{ } 0.\] (28)

Let us denote \(B_{k}_{t=k}^{T}_{t}(A^{t-k})^{}A^{t-k}=_{k}I+A^ {}B_{k+1}A\). As we now show, this optimization problem possesses a closed-form solution under a mild assumption (which is satisfied e.g. when \(Q_{k} 0\)). The proof is given in Appendix F.

**Theorem 4.3**.: _Assume that \(\{B_{k}M_{k}B_{k}\}\{Q_{k} \}\) for every \(k\). Let \(M_{B} B_{k}M_{k}B_{k}\) and denote \(=\{_{k}:Q_{k}-_{k}M_{k}_{k}^{} 0\}\). Then the optimal value in (28) is given by_

\[_{_{k}}\{_{k}M_{k}B_{k}\}=\{(M_{B}^{1/2}Q_{k}M_{B}^{1/2})^{}\},\] (29)

_and is achieved by the optimal coefficient (which is generally not unique)_

\[_{k}^{*}=Q_{k}M_{B}^{1/2}(M_{B}^{1/2}Q_{k}M_{B}^{1/2})^{1/2!}M_{ B}^{1/1/2}B_{k}.\] (30)

For a closed form solution under the alternative assumption that \(\{M_{k}\}\{Q_{k}\}\), as well as a discussion of stationary filters, please see the Appendix. The Perceptual Kalman filter (PKF) obtained from Thm. 4.3 is summarized in Alg. 1.

Numerical demonstrations 1

We now revisit our main question: _what is the cost of temporal consistency in online restoration?_ In addition, as we have seen in Sec. 4.2, the relaxation \(_{k}=0\), yielding the Perceptual Kalman filters, reduces the complexity of computation, possibly at the cost of higher errors. It is natural, then, to ask what is the cost of this simplification. In the following experiments, we compare the performance of several filters; \(^{*}_{}\) and \(_{}\) correspond to the Kalman filter and the temporally-inconsistent filter (10) (which does not possess perfect-perceptual quality). The estimate \(_{}\) is a perfect-perception filter obtained by numerically optimizing the coefficients in (18), where the cost is the MSE at termination time, \(_{}=[\|_{T}-x_{T}\|^{2}]\). \(_{}\) is a perfect-perception filter obtained by the optimization approach discussed in Appendix C, where we consider again the terminal cost. The estimates \(_{},_{}\) correspond to PKF outputs (Alg. 1) minimizing the _total cost_ (area under curve) \(_{}=_{k=0}^{T}[\|_{k}-x_{k}\|^{2}]\) and the _terminal cost_\(C_{T}\), respectively. The filters are summarized in Table 1. Full details and additional experimental results are given in App. I.

### Harmonic oscillator

We start with a simple \(2\)-D example. Specifically, we consider a harmonic oscillator, where the state \(x_{k}^{2}\) corresponds to position and velocity, and the observation at time \(t\) is a noisy versions of the position at time \(t-_{t}\), where \(_{t}\) is the sampling period (see App. I for details). Figure 3 shows the MSE for \(_{}\) and the sub-optimal PKF outputs \(_{},_{}\). The estimates \(^{*}_{}\) and \(_{}\) achieve lower MSE than \(_{}\), however they do not possess perfect-perceptual quality. _The difference in MSE between the filters \(_{}\) and \(_{}\) is the cost of temporal consistency in online estimation for this setting_.

In Figure 3, we also observe that the PKF estimations are indeed not MSE optimal at time \(T=255\). However, their RMSE is only about \(30\%\) higher than that of \(_{}\) and they have the advantage that they can be solved analytically and require computing only half of the coefficients (\(_{k}\)). The penalty related to this reduction may vary, depending on the exact setup. In Fig. 4 we demonstrate the relations between gaps due to temporal consistency (gap between \(_{}\) and \(_{}\)) and due to the reduction \(_{k}=0\) (gap between \(_{}\) and \(_{}\)), in various settings based on the Harmonic Oscillator example. On the _left_ pane, dynamics are driven by \(x_{k}= Ax_{k-1}+q_{k}\), where \(A\) is a fixed marginally-stable matrix, and \(\) is a scalar controlling the strength of correlation between timesteps. On the _right_ pane, \(=1\) and observations are given only up to time \(\) (\(y_{k}\) is only noise for \(k\)). We observe that for systems where timesteps are strongly correlated, or in the absence of current information, discarding \(_{k}\) leads

  & **description** & **def.** &  \\  & & per-sample & temporal \\  \(_{}\) & Kalman filter & Alg.2 & ✗ & ✗ \\ \(_{}\) & Per-sample quality & (10) & ✓ & ✗ \\ \(_{}\) & Optimized filter & (18) & ✓ & ✓ \\ \(_{}\) & Directly optimized & App. C & ✓ & ✓ \\ \(_{}\) &  PKF \\ (total cost) \\  & Alg. 1 & ✓ & ✓ \\ \(_{}\) & 
 PKF \\ (terminal cost) \\  & Alg.1 & ✓ & ✓ \\  

Table 1: List of demonstrated filters.

Figure 3: **MSE on Harmonic oscillator.** We observe \((i)\) the difference in distortion between the perfect-perceptual state \(_{}\), optimized according to (18), and \(_{}\). This additional cost is due to the perceptual constraint on the joint distribution. Also note the gap \((ii)\) between MSE of the optimized estimator and \(_{}\) which is due to the sub-optimal choice of coefficients, \(_{k}=0\).

to significantly higher errors. Whenever states are less correlated and more observations are given, unutilized information can be ignored with lower cost.

### Dynamic texture

We now illustrate the qualitative effects of perceptual estimation in a simplified video restoration setting. Specifically, we consider a video of a "dynamic texture" of waves in a lake. Such dynamic textures are accurately modeled by linear dynamics of a Gaussian latent representation , whose parameters we learn from a real video. Here, frames are generated from a latent \(128\)-dimensional state \(x_{k}^{FA}\) which corresponds to their _Factor-Analysis_ (FA) decomposition (see _e.g._[2, Sec. 12.2.4] for more details). Thus, \(512 512 3\) frames in the video domain are created through an affine transformation of \(x_{k}^{FA}\). Linear observations \(y_{k}^{32 32}\) are given in the frame (pixel) domain, by \(16\) downsampling the \(Y\)-channel of the generated ground-truth frames, and adding white Gaussian noise. All filtering is done in the latent domain, and then transformed to the pixel domain. MSE is also calculated in the FA domain. The exact settings can be found in App. I.

In the first experiment, measurements are supplied up to frame \(k=127\) and then stop (Fig. 5), letting the different filters predict the next, unobserved, frames of the sequence. We can see that until frame \(k=127\), all filters reconstruct the reference frames well. Starting from time \(k=128\), when measurements stop, the Kalman filter slowly fades into a static, blurry output which is the average frame value in this setting. This is a non- realistic' video; Neither the individual frames nor the temporal (static) behavior are natural to the domain. Our perfect-perceptual filter, \(_{ auc}\), keeps generating a 'natural' video, both spatially and temporally. This makes its MSE grow faster2.

We now perform a second experiment, where measurements are set to zero until frame \(k=512\). At times \(k>512\) they are given again by the noisy, downsampled frames as described above. In Fig. 6 we present the outcomes of the different filters. We first note that up to frame \(k=512\), there is no observed information, hence outputs are actually being generated according to priors. The Kalman filter outputs a static, average frame. The filter \(_{ tic}\) randomizes each frame independently, leading to unnatural random movement with flickering features. At frame \(k=513\), when observations become available, \(_{ kal}^{*}\) and \(_{ tic}\) get updated immediately, creating an inconsistent, non-smooth motion between frames \(512\) and \(513\). The PKF output \(_{ auc}\), on the other hand, maintains a smooth motion. Since the outputs of inconsistent filters rapidly becomes similar to the ground-truth, their errors drop. The perfect-perceptual filter, \(_{ auc}\), remains consistent with its previously generated frames and the natural dynamics of the model, hence its error decays more slowly.

Figure 4: **Different dynamics yield different MSE gaps. Here we use different dynamics, based on the Harmonic oscillator (matrices \(A,C,Q,R\) are given in Sec. I.1) to demonstrate behavior of gaps due to temporal consistency (gap between \(_{ direct}\) and \(_{ tic}\)) and due to the reduction \(_{k}=0\) (gap between \(_{ direct}\) and \(_{ minT}\)). We present analytical errors at time \(T=255\), normalized by the ground-truth state \(x_{T}\) variance. (Left) dynamics are driven by the stabilized matrix \( A\) for different scalar values of \(\). Observe that when timesteps are more correlated (higher \(\)), both consistency and unutilized information play a major role, hence MSE gaps between filters grow. (Right) Here, \(=1\), and observations are given only up to time \(\) (\(y_{k}=\) noise, for \(k\)).**

ConclusionWe studied the problem of causal filtering of time sequences from corrupted or missing observations, where the the filter's output process is constrained to possess perfect (spatio-temporal) perceptual-quality in the sense of being distributed like the original signal. Our theoretical derivations focused on Gauss-Markov state-space processes. We introduced the novel concept of an unutilized information process and established a special class of perceptual filters, coined Perceptual Kalman Filters (PKF), that are based on the innovation process alone. We demonstrated the qualitative effects of perfect perceptual quality estimation on a video reconstruction problem. To the best of our knowledge, this is the first work addressing the distortion-perception tradeoff in online restoration settings. This work paves the way toward understanding perceptual online filtering, and the cost of temporal consistency in sequential estimation problems.

Figure 5: **Frame prediction on a dynamic texture domain.** In this experiment, measurements are supplied only up to frame \(k=127\) and the filter’s task is to predict the unobserved future frames. Observe that \(_{}^{*}\) fades into a blurred average frame, while the perceptual filter \(_{}\) generates a natural video, both spatially and temporally. This makes its MSE grow faster.

Figure 6: **Frame generation on a dynamic texture domain.** In the first half of the demo (\(k 512\)), there are no observations, hence the reference signal is restored according to prior distribution. The filters with no perfect-perceptual quality constraint in the temporal domain generate non-realistic frames (Kalman filter output \(_{}^{*}\)) or unnatural motion (\(_{}\)). Perceptual filter \(_{}\) is constrained by previously generated frames and the natural dynamics of the domain, hence its MSE decays slower.

AcknowledgementsThe work of RM was partially supported by the Israel Science Foundation grant 1693/22 and by the Skillman chair in biomedical sciences. The work of TM was partially supported by the Israel Science Foundation grant 2318/22 and by a gift from KLA. RM and TM were supported by the Ollendorff Minerva Center, ECE Faculty, Technion.