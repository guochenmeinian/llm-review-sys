# Diversify, Contextualize, and Adapt:

Efficient Entropy Modeling for Neural Image Codec

Jun-Hyuk Kim1  Seungeon Kim  Won-Hee Lee  Dokwan Oh

Samsung Advanced Institute of Technology

{jh131.kim, se2.kim, why_wh.lee, dokwan.oh}@samsung.com

###### Abstract

Designing a fast and effective entropy model is challenging but essential for practical application of neural codecs. Beyond spatial autoregressive entropy models, more efficient backward adaptation-based entropy models have been recently developed. They not only reduce decoding time by using smaller number of modeling steps but also maintain or even improve rate-distortion performance by leveraging more diverse contexts for backward adaptation. Despite their significant progress, we argue that their performance has been limited by the simple adoption of the design convention for forward adaptation: using only a single type of hyper latent representation, which does not provide sufficient contextual information, especially in the first modeling step. In this paper, we propose a simple yet effective entropy modeling framework that leverages sufficient contexts for forward adaptation without compromising on bit-rate. Specifically, we introduce a strategy of diversifying hyper latent representations for forward adaptation, i.e., using two additional types of contexts along with the existing single type of context. In addition, we present a method to effectively use the diverse contexts for contextualizing the current elements to be encoded/decoded. By addressing the limitation of the previous approach, our proposed framework leads to significant performance improvements. Experimental results on popular datasets show that our proposed framework consistently improves rate-distortion performance across various bit-rate regions, e.g., 3.73% BD-rate gain over the state-of-the-art baseline on the Kodak dataset.

## 1 Introduction

Most neural image codecs [8; 9; 11; 15; 17; 18] first transform an image into a quantized latent representation. It is then encoded into a bitstream via an entropy coding algorithm, which relies on a learned probability model known as the entropy model. According to the Shannon's source coding theorem, the minimum expected length of a bitstream is equal to the entropy of the source. Thus, accurately modeling entropy of the quantized latent representation is crucial.

Entropy models estimate a joint probability distribution over the elements of the quantized latent representation. Generally, it is assumed that all elements follow conditionally independent probability distributions. To satisfy this, the probability distributions are modeled in context-adaptive manners, which is key to accurate entropy modeling . Recent methods are based on the joint backward and forward adaptation where the probability distributions adapt by leveraging contexts in two different ways: directly using previously encoded/decoded elements (i.e., backward adaptation), and extracting and utilizing an additional hyper latent representation (i.e., forward adaptation). Here, the type of contexts leveraged can be diverse depending on the spatial range they cover. First, each element has dependencies with other elements in the same spatial location along the channel dimension. Since the channel-wise dependencies correspond to the local image area (e.g., a \(16 16\) patch), we denotethem as the "local" context. Second, dependencies exist among spatially adjacent elements, and we refer to them as the "regional" context. Lastly, long-range spatial dependencies span the entire image area, referred to as the "global" context.

For the backward adaptation, the modeling order, i.e., which elements are modeled first, is an important factor, and the key lies in how effectively we can utilize diverse contexts in the modeling process. Early studies employ spatial autoregressive (AR) models that access regional context including the most spatially adjacent elements. However, they suffer from significantly slow decoding times due to the inevitably large number of modeling steps, which is equal to the spatial dimensions . To enhance efficiency in entropy modeling, several attempts reduce the number of modeling steps while leveraging diverse contexts: a 10-step channel-wise AR model , a 2-step spatial non-AR model with a checkerboard pattern , and a 4-step non-AR model that operates across spatial and channel dimensions using a quadtree partition .

Entropy models based on the efficient backward adaptation methods have led to significant improvements. However, they are still limited in fully leveraging contexts for forward adaptation. Since they use multiple neural layers with downsampling and upsampling for modeling hyper latent representation, they can only access the regional context. This limits the performance improvement due to the insufficient contexts (Figure 0(a)). In particular, this limitation is exacerbated at the first step where only forward adaptation is utilized due to the absence of previous elements (Figure 6). Therefore, it is necessary to develop effective forward adaptation in synergy with the efficient backward adaptation.

In this paper, we propose a simple yet effective entropy modeling framework, called **DCA** (Diversify, Contextualize, and Adapt), leveraging sufficient contexts for forward adaptation without compromising on bit-rate (Figure 0(b)). Building on the quadtree partition-based backward adaptation , we introduce a strategy of diversification, i.e., extracting local, regional, and global hyper latent representations unlike only a single regional one in the previous approach. Note that simply using more contexts for forward adaptation does not guarantee performance improvements because forward adaptation requires additional bit allocation unlike backward adaptation. Then, we propose how to effectively utilize the diverse contexts along with the previously modeled elements for contextualizing the current elements to be encoded/decoded. To consider step-wise different situations, e.g., increased number of previous elements over steps, our contextualization method is designed to utilize each hyper latent representation separately in a step-adaptive manner. Additionally, our contextualization method proceeds in the sequence of regional, global, and local hyper latent representations. Similarly to backward adaptation, we empirically observe that modeling order also matters in forward adaptation.

Our main contributions are summarized as follows:

* We propose a strategy of diversifying contexts for forward adaptation by extracting three different hyper latent representations, i.e., local, regional, and global ones. This strategy can provide sufficient contexts for forward adaptation without compromising on bit-rate.
* We introduce how to effectively leverage the diverse contexts, i.e., previously modeled elements and the three hyper latent representations. We empirically show that the modeling order of three types of contexts affects the performance.
* Through the diversification and contextualization methods, our DCA effectively adapts, resulting in significant performance improvements. For example, DCA achieves 3.73% BD-rate gain over the state-of-the-art method  on the Kodak dataset.

Figure 1: **DCA** diversifies the hyper latent representations and contextualizes the current elements by leveraging the diverse hyper latent representations along with the previous elements. As a result, the probability distributions adapt effectively, leading to accurate entropy modeling.

Related work

Joint backward and forward adaptation.Balle et al.  propose a scale hyperprior for forward adaptation. A hyper latent representation is extracted and utilized for inferring local scale parameters of the parameterized entropy model. Minnen et al.  extend the hyperprior model by using an additional mean hyperprior, and introduce joint backward and forward adaptation by combining the extended hyperprior model with a spatial autoregressive (AR) model. A patch matching-based non-local referring model  and a multi-head attention-based global hyperprior  are proposed to enrich contexts for backward and forward adaptation, respectively.

Efficient backward adaptation.To address the slow decoding times of spatial AR-based entropy models, several studies have proposed group-wise backward adaptation methods. They first divide the quantized latent representation into multiple groups and then process them in a group-wise manner, resulting in improved efficiency. He et al.  propose dividing the quantized latent representation into two groups using the checkerboard pattern, which is further improved by incorporating Transformer-based modules . While they apply a group-wise modeling in spatial dimension, Minnen and Singh  introduce a channel-wise AR model that divides the quantized latent representation into ten groups along channel dimension. Some studies [22; 23] improve this model by applying Swin Transformer . Based on the channel-wise AR model, He et al.  optimize the channel division and combine it with the checkerboard-based model. Recently, Li et al.  propose a quadtree partition-based backward adaptation that divides the quantized latent representation into four groups considering both channel and spatial dimensions.

In this paper, we propose a novel fast and effective entropy model that achieves better rate-distortion performance by diversifying not only the quantized latent representation but also the hyper latent representations for backward and forward adaptation, respectively.

## 3 Methods

We provide an overview of the proposed methods in Figure 2. The analysis transform \(f_{a}()\) and the synthesis transform \(f_{s}()\) (the gray blocks in Figure 2) are learned to find an effective mapping between an input image \(\) and a quantized latent representation \(}\), i.e., \(}= f_{a}()\) and \(}=f_{s}(})\), where \(\) is a round operation and \(}\) is the decoded image. For the analysis and synthesis transforms, we adopt the same model structure as in the ELIC-sm model  due to its efficiency.

All other components are learned to model a prior probability distribution on the quantized latent representation \(}\), i.e., the entropy model \(p_{}}\). The learned entropy model is utilized in the process of entropy coding, for which we employ the asymmetric numeral systems . Here, our goal is to design a fast and effective learned entropy model.

Quadtree partition.We build our entropy model on the joint forward and backward adaptation where the quadtree partition is used, which is formulated as follows :

\[p(})=p(}) p(}|})=p(})_{i=1}^{4}p(}^{i}|}^{<i},})\]

where \(}\) is the quantized latent representation, \(}\) is the quantized regional hyper latent representation, \(}^{i}\) is the elements to be modeled at the \(i\)-th step, and \(}^{<i}\) is all the previous modeled elements before the \(i\)-th step. At each step, one-fourth of the total elements are modeled. The method partitions the quantized latent representation into four groups along the channel dimension, and then divides each group into non-overlapping 2\(\)2 patches along the spatial dimension. The entropy modeling proceeds over

Figure 3: Example of the quadtree partition-based backward adaptation for \(}^{4 4 320}\). For simplicity, channel dimensions are represented via different colors. \(}^{i}\) means the elements to be encoded/decoded at the \(i\)-th step. For modeling the current elements \(}^{i}\), all the previous modeled elements \(}^{<i}\) are used. For example, the elements corresponding to the red arrow leverage diverse contexts including elements across different channels at the same spatial location (local context denoted as L) and spatially adjacent four elements of the same channel (regional context denoted as R).

four steps, with each step modeling different elements as shown in Figure 3. This quadtree partition-based method uses diverse contexts for backward adaptation, capturing dependencies from both spatial and channel dimensions.

Motivation.Recent studies to efficient modeling of backward adaptation have made significant advancements in terms of optimizing the rate-distortion-computation trade-off; however, there is still a gap between their assumptions in the probability modeling and actual data, leaving room for further performance enhancement. The assumptions are as follows: 1) All elements of \(}\) are independent; 2) All elements of \(}^{i}\) are conditionally independent given \(}^{<i}\) and \(}\). Here, the more the actual data deviates from the assumptions, the lower the accuracy of the entropy modeling. At the first modeling step, the elements are modeled conditioned only on the quantized hyper latent representation, i.e., \(p(}^{1}|})\), resulting in a hyperprior model known for deviating from to the second assumption . This can be more problematic because the state-of-the-art methods process a relatively large number of elements at the first step in order to complete the overall modeling with a minimal number of steps. We also empirically show that this problem actually occurs in Figure 6.

One straightforward solution is to increase the number of steps so that fewer elements are modeled in the first step. However, this leads to slower modeling speeds, which conflict with the goal of our paper, i.e., developing a fast and effective entropy model. Another simple approach is to provide more quantized regional hyper latent representation \(}\) when modeling the quantized latent representation \(}^{1}\). However, paradoxically, this approach can introduce another issue due to the first assumption. Since all elements of hyper latent representation are the same type of information (i.e., regional context), there is a relatively high likelihood of dependencies among the elements. Therefore, to meet both assumptions, the newly added hyper latent representation is required to be independent from the existing regional hyper latent representation. This is why our proposed diversification method using

Figure 2: Overview of the neural image codec with the proposed entropy model, referred to as DCA. DCA can be employed by any analysis and synthesis transforms \(f_{a}()\) and \(f_{s}()\). DCA is an adaptive entropy model consisting of two main stages: \(\) (Section 3.1) and \(\) (Section 3.2). First, given the latent representation \(\), DCA extracts diverse hyper latent representations \(}_{l}\), \(}_{r}\), and \(}_{g}\), and then encodes them into the bitstreams using learned factorized entropy models, which are omitted in this figure for simplicity. Second, contextualization proceeds over four steps. By using the three features \(_{l}\), \(_{r}\), and \(_{g}\) (from the three hyper latent representations, respectively) and all the previously encoded/decoded elements before the \(i\)-th step, i.e., \(}^{<i}\), DCA contextualizes the current elements to be encoded/decoded, i.e., \(}^{i}\), and finally obtains adaptive distribution parameters \(^{i}\) and \(^{i}\) for probability modeling. Using the learned adaptive probability model, the quantized latent representation \(}\) are encoded into a bitstream.

local, regional, and global hyper latent representations is needed. In this paper, we propose a fast and effective entropy model, called DCA, which consists of three main stages: diversifying the hyper latent representations, contextualizing the elements targeted for probability modeling, and ultimately adapting the probability distribution of the elements to the given contexts.

### Diversify

The proposed DCA aims to diversify the information that the hyper latent representations contain. Specifically, given the latent representation \(^{H W C}\), where \(H\), \(W\), and \(C\) are the height, width, and the number of channels, respectively, DCA extracts three different types of hyper latent representations depending on the range they cover: a local hyper latent representation \(}_{l}^{H W C_{l}}\), a regional hyper latent representation \(}_{r}^{ C_{r}}\), and a global hyper latent representation \(}_{g}^{N}\). The whole process is illustrated in the orange blocks of Figure 2.

Local context.To model remaining dependencies along channel dimension at each spatial location, which correspond to a \(16 16\) local patch in the image domain, we introduce local hyper analysis and synthesis transforms, \(l_{a}()\) and \(l_{s}()\), based on Swin Transformer (SwinT) . The local hyper analysis transform \(l_{a}()\) analyzes local information in the latent representation, followed by the quantization operation to obtain a local hyper latent representation \(}_{l}\). The local synthesis transform \(l_{s}()\) synthesizes the local features \(_{l}^{H W 2C}\) for contextualization from the local hyper latent representation \(}_{l}\).

Each transform proceeds in the order of a Patch Split block, a SwinT block, and a Patch Merge block. The Patch Split block serves the function of shifting all channel-wise elements at each spatial location to a \(2 2\) spatial resolution, consisting of the depth-to-space, layer normalization, and linear layers in sequence. The SwinT block then captures dependencies between elements within each non-overlapping window of the input, producing an output of the same size as the input. By setting the window size to \(2 2\) in conjunction with the use of the Split block, we enforce the local hyper transforms to focus only on the local image area. The Patch Merge block performs the opposite function of the Patch Split block, containing the layer normalization, linear, and space-to-depth layers in sequence.

Regional context.While the receptive field of the local hyper transforms is limited to the local image area (i.e., \(16 16\) patches), regional hyper analysis transform \(r_{a}()\) and regional hyper synthesis transform \(r_{s}()\) model remaining dependencies between elements distributed across a relatively wide image area. The regional hyper analysis transform \(r_{a}()\) analyzes regional information in the latent representation and yields a regional hyper latent representation \(}_{r}\) after quantization. From the extracted regional hyper latent representation \(}_{r}\), the regional synthesis transform \(r_{s}()\) generates the regional features \(_{r}^{H W 2C}\) for contextualization.

To do this, we stack multiple layers with the downsampling and upsampling operations for the regional hyper analysis and synthesis transforms, respectively. We adopt the same structure as the previous work , which is based on SwinT. Specifically, the regional hyper analysis transform \(r_{a}()\) conducts a Patch Merge block, five SwinT blocks, a Patch Merge block, and a SwinT block. The regional hyper synthesis transform \(r_{s}()\) is constructed in the opposite order of the hyper analysis transform \(r_{a}()\), using the Patch Split block instead of the Patch Merge block.

Global context.Lastly, to capture remaining dependencies between elements across the whole image area, we construct global hyper analysis and synthesis transforms \(g_{a}()\) and \(g_{s}()\) by adopting model structure of the global hyperprior model of Informer . The global hyper analysis transform \(g_{a}()\) extracts globally abstracted information from the latent representation using a Transformer block with cross-attention and a \(1 1\) convolutional layer. After quantization, it obtains a global hyper latent representation \(}_{g}\). Using a \(1 1\) convolutional layer, the global synthesis transform \(g_{s}()\) infers the global features \(_{g}^{N 2C}\) for contextualization.

### Contextualize

Diverse contexts, i.e., previously modeled elements (i.e., \(}^{<i}\)) and hyper latent representations (i.e., \(}_{l}\), \(}_{r}\), and \(}_{g}\)) can be used for adapting probability distributions. Here, an important research question emerges: How can we effectively leverage the diverse contexts? First, to consider step-wise varied situations, e.g., increased previously encoded/decoded elements over modeling steps, we propose a step-adaptive utilization of the three hyper latent representations. In other words, instead of applying a combined set of the three hyper latent representations, each hyper latent representation is adaptively leveraged at each step. In addition, we use regional, global, and local information sequentially. We argue that modeling order is crucial for forward adaptation, which is already known to be a key factor for backward adaptation.

The green part of Figure 2 illustrates our proposed contextualization model \(c()\) at the \(i\)-th step. First, the previously modeled \(}^{<i}\) and the regional feature \(_{r}\) are combined based on the same structure as in the previous approach , consisting of concatenation, a \(1 1\) convolutional layer, and three DepthConv Blocks. The DepthConv Block employs depth-wise separable convolutional layers for more efficient implementation. Second, the global feature \(_{g}\) is combined with the output of the last DepthConv Block using the Transformer block with cross-attention . Finally, we combine the output of the Transformer block with the local feature \(_{l}\) using concatenation followed by three \(1 1\) convolutional layers, yielding the distribution parameters \(^{i}\) and \(^{i}\). To make our contextualization model \(c()\) more efficient in terms of the number of parameters, all layers share weights across the four steps except for the initial \(1 1\) convolutional layer.

Discussion on modeling order.According to the study on theoretical understanding of masked autoencoder via hierarchical latent variable models, the semantic level of the learned representation varies with the masking ratio . Specifically, extremely large or small masking ratios lead to low-level detailed information such as texture, while non-extreme masking ratios result in high-level semantic information. Inspired by this, we can infer that the local and global hyper latent representations correspond to relatively low-level information because they are extracted via limited utilization of the latent representation. The receptive field of the local hyper latent representation is limited by 1\(\)1 convolutional layers. While the receptive field of the global hyper latent representation is whole image area, its attention mechanism selectively use the latent representation. Through the same reasoning, we can infer that regional hyper latent representation corresponds to relatively high-level information. Since different type of contexts has different characteristics, we argue that the modeling order is important for effective entropy modeling. In Figure 11, we empirically confirm that modeling higher-level information (i.e., regional context) first and lower-level information (i.e., local and global contexts) later is more effective than the opposite. In addition, the order between global and local is shown to be not influential.

### Adapt

We design an adaptive entropy model on the quantized latent representation \(}\) where each element is assumed to follow the Gaussian distribution, and each distribution parameters are obtained from the previous diversification and contextualization stages. Following the previous works [3; 18], we formulate our entropy model as follows:

\[p_{}}(})=_{i}_{i}, _{i}^{2}*-, (_{i}),\] (1)

where \(_{i}\) and \(_{i}\) are the mean and scale of the Gaussian distribution for each element \(_{i}\), respectively.

The transforms and entropy model are jointly trained in an end-to-end manner by minimizing the expected length of the bitstream (rate) and the expected distortion between the original image and the decoded image, \(d(,)\). When a learned entropy model precisely matches the actual probability distribution, the entropy coding algorithm achieves the minimum rate. Therefore, we minimize the cross-entropy between the two distributions. We use mean squared error (MSE) for measuring image distortion. The objective function for our method is as follows:

\[=_{ p_{}}-_{2}p_{ }}(})-_{2}p_{}_{i}}(}_{l})-_{2}p_{ }_{r}}(}_{r})-_{2}p_{}_{g}}(} _{g})+ d(,}),\] (2)

where \(p_{}\) is the distribution of the training dataset, the entropy models \(p_{}_{i}}\), \(p_{}_{r}}\), and \(p_{}_{g}}\) are the non-parametric fully factorized entropy models , and \(\) is the Lagrange multiplier that determines weighting between rate and distortion. As the value increases, a model is trained in a direction that reduces information loss, and consequently leads to a higher bit-rate.

## 4 Experiments

We use a PyTorch  based open-source library and evaluation platform, CompressAI , which has been widely used for developing and evaluating neural image codecs.

Training.We set our model parameters as follows: \(C=320\), \(C_{l}=10\), \(C_{r}=192\), and \(N=8\). We train our models corresponding six different bit-rates. We use 300,000 images randomly sampled from the OpenImages  dataset. We construct a batch size of 16 with 256\(\)256 patches randomly cropped from different training images. All models are trained for 100 epochs using the Adam optimizer. The learning rate is set to \(10^{-4}\) up to 90 epoch, and then decreases to \(10^{-5}\). We use PyTorch v1.9.0, CUDA v11.1, CuDNN v8.0.5, and all experiments are conducted using a single NVIDIA A100 GPU.

Evaluation.We evaluate our method on the two popular datasets: Kodak  and Tecnick . The Kodak dataset consists of 24 images with a resolution of either 768\(\)512 or 512\(\)768 pixels. The Tecnick dataset is composed of 100 images with a resolution of 1200\(\)1200 pixels. We evaluate our method in terms of rate-distortion performance. For this, we calculate the bits per pixel (bpp) after the encoding phase, and measure distortion between the decoded image and the original image using the peak signal-to-noise ratio (PSNR).

### Comparison with state-of-the-art methods

We compare the proposed entropy model, DCA, with state-of-the-art entropy models. DCA can be combined with any transforms; in this paper, DCA is implemented with transforms that have the same structure as in ELIC-sm . For the comparison, we further train image compression methods with four different entropy models [11; 14; 17; 18]. For a fair comparison, they are also implemented with transforms that have the same structure as in ELIC-sm .

Rate-Distortion.Figures 3(a) and 3(b) show the rate-distortion performance on the Kodak and Tecnick datasets, respectively. The proposed DCA consistently achieves the best rate-distortion performance across all bit-rate regions and two benchmark datasets. Specifically, DCA achieves 11.96% average rate savings over VTM-12.1 on the Kodak dataset, while the second (Lie et al. 2023)  and third best (Minnen and Singh, 2020)  methods obtain 8.55% and 4.86%, respectively.

Complexity.We also evaluate DCA in terms of efficiency. To this end, we provide the decoding time, the number of model parameters, and Bjontegaard delta rate (BD-rate)  in Figure 5. Decoding time is measured on the Kodak dataset using a single NVIDIA V100 GPU.

Figure 4: Performance comparison with latest entropy models on the two benchmark datasets: (a) Kodak and (b) Tecnick. For clear comparisons, we denote each method as follows. B and F mean backward and forward adaptation, respectively, and the corresponding methods are written in parentheses. For backward adaptation, AR, ChARM, and Quadtree represent spatial autoregressive model, channel-wise autoregressive model, and quadtree partition-based model, respectively. For forward adaptation, L, R, G mean local, regional, and global hyper latent representations, respectively.

BD-rate means the average bit-rate savings compared to a baseline while maintaining the same quality of decoded images. We set VTM-12.1 as the baseline, calculate BD-rate for each image in the Kodak dataset, and average them. As shown in Figure 5, our DCA achieves better rate-distortion-computation trade-off than the AR models  and the ChARM model . Even compared to the quadtree-based entropy model , DCA improves performance significantly, i.e., 3.73% BD-rate gain, without compromising efficiency as much as possible.

Using the same structure of transforms, we additionally compare DCA with two state-of-the-art entropy models (Table 1), which shows that DCA improves performance most efficiently. It is worth noting that performance improvements are significantly difficult to achieve when there are constraints on compute and memory usage, and this is the achievement of our DCA.

Probability modeling.To further show the role of the proposed DCA, we measure the normalized latent representation for each step, i.e., \(}^{i}=(^{i}-^{i})/^{i}\). It provides a standardized measure of how far the latent representation deviates from the predicted mean in terms of estimated standard deviations. Smaller values indicate that a learned entropy model estimates the true probability distribution more accurately. In Figure 6, we compare the result with that of the baseline model , which does not leverage diverse contexts for forward adaptation. Here, we have an interesting observation: While the existing work shows significantly high values at the first modeling step, DCA demonstrates consistent modeling performance across four steps. At the first step, since only forward adaptation is possible, the previous approach can utilize only a limited amount of context. On the other hand, DCA enables sufficient contextualization through diverse hyper latent representations, addressing the limitation of previous approach, which has difficulty effectively adapting to various situations.

   Methods & BD-rate (\(\%\)) \(\) & Decoding time (ms) \(\) & \# Parameters (M) \(\) \\  Baseline (CVPR’23)  & 0.00 & 67.05 & 32.64 \\ LIC-TCM (CVPR’23)  & \(-\)0.72 & 139.04 & 55.19 \\ MLIC++ (ICMLW’23)  & 5.76 & 242.61 & 107.80 \\ 
**DCA (Ours)** & \(-\)3.73 & 82.05 & 37.89 \\   

Table 1: Performance comparison with state-of-the-art entropy models on Kodak.

Figure 5: Performance comparison with latest entropy models on the Kodak dataset in terms of decoding time, BD-rate, and model size. Decoding time is measured on a NVIDIA V100 GPU. BD-rate means average rate savings over VTM-12.1. The size of the circle is determined proportionally to the number of model parameters, and the specific numbers are written to the left of the circles.

Figure 6: Illustration of normalized latent representations \(}^{i}\) across four steps using both the baseline and proposed DCA. Each sub-figure includes the minimum and maximum values of normalized latent representations. Notably, the baseline exhibits a broader range of values at the first modeling step, resulting in a higher bit-rate. More examples are provided in the appendix.

Qualitative results.We provide visual results in Figure 9, showing the decoded image from DCA has better visual quality and a higher PSNR value than that of VTM-12.1, under the same bit-rate.

### Model analysis

We conduct detailed analyses of DCA. To do this, we train different variants of DCA depending on various aspects for analysis. All results are shown in two different bit-rate regions (Figures 9 to 12).

Analysis of diversification.To validate the effectiveness of diversifying contexts for forward adaptation, we compare three different methods depending on the context diversity (Figure 9): one using regional context ("R"), one using both regional and global contexts ("R + G"), and one using regional, global, and local contexts altogether ("R + G + L"). We use two additional models: one using a larger regional context ("Large R") and the other using both global and local contexts ("G + L"). The comparison among the first three methods show diversifying forward contexts is effective in both bit-rate regions. Through the results showing that the "Large R" method does not contribute to performance improvement, we once again demonstrate the effectiveness of our diversification. The last one is decomposing regional context into global and local ones rather than diversifying, which is equal to simply adopting the forward adaptation of Informer . The result shows the decomposing approach significantly decreases compression efficiency, and diversifying is more effective.

In addition, while our focus lies on diversifying forward context, someone might be curious about whether the context utilized for the quadtree-based backward adaptation is diverse enough. To verify this, we conduct experiments additionally extracting global information from the backward context. Figure 9 demonstrates that there is no distinguishable advantage between two: one simply using the quadtree-based method  for backward adaptation ("B (LR) + F (LRG)") and the other using additional global information for backward adaptation ("B (LRG) + F (LRG)"). This implies that backward adaptation is favorable when focusing on local and regional contexts.

Analysis of contextualization.To show the effectiveness of our contextualization approach, we first compare two different methods in Figure 10. "R + G (Step-independent)" combines regional and global information in advance and utilizes the combined one regardless of the step. The other adaptively utilizes regional and global information separately for each step, "R + G (Step-adaptive)".

As a reference, we use the model utilizing only regional context, i.e., "R". The result shows that both are effective and our step-adaptive approach is more beneficial for boosting performance.

In addition, we analyze the effectiveness of our modeling order for contextualization in Figure 11. Four different ordering methods and one reference method are used for the comparison. Our ordering approach ("R\(\)G\(\)L") achieves the best rate-distortion performance, and the methods are categorized into two groups based on the performance in both bit-rate regions. Models that prioritize the regional context ("R\(\)G\(\)L" and "R\(\)L\(\)G") show better performance compared to those that do not prioritize it ("G\(\)L\(\)R" and "L\(\)G\(\)R"). We observe that the method using the opposite modeling order of the proposed sequence ("L\(\)G\(\)R") even exhibits a performance decline compared to the baseline ("R") in a lower bit-rate region.

Analysis of architecture.Applying attention mechanisms on various tasks is one of the most actively researched topics. We analyze the effect of the architecture combination for forward and backward adaptation in DCA. Figure 12 compares three different methods: one without attention ("B (CNN) + F (CNN)"), another applying attention only to forward adaptation ("B (CNN) + F (Attention)"), and the last applying attention for both ("B (Attention) + F (Attention)"). The results show that CNN and attention are effective for forward and backward adaptation, respectively. We infer that focusing on local and regional information is preferable in backward adaptation; thus, a CNN with a locality inductive bias may be more effective.

## 5 Conclusion

In this paper, we proposed a fast and effective entropy modeling framework, DCA, which diversifies forward contexts by extracting local, regional, and global information, and contextualizes current elements with the diverse forward and backward contexts. We demonstrated that our DCA improves rate-distortion performance significantly compared to previous approach without compromising efficiency as much as possible. Furthermore, we provided diverse insights into entropy modeling by conducting a comprehensive and in-depth analysis of the design aspects of DCA.

Limitation and future works.To address the limitation of the state-of-the-art entropy models, we focused on paving a novel framework with diverse contexts rather than designing neural architectures. Therefore, DCA can be limited by the architectural designs that are inspired by the existing works [11; 14; 22]. In the future, we expect that it would be further improved by neural architectures especially designed for the diverse contexts. In addition, it is worth exploring alternative criteria for diversification beyond the spatial range the contexts covers (i.e., local, regional, and global contexts).

Figure 11: Analysis of contextualization order. R, G, L denote the regional, global, and local forward contexts, respectively. \(\) means the order. For example. the “R\(\)G\(\)L” method utilizes R, G, and L sequentially.

Figure 12: Analysis of model architecture for backward and forward adaptation. B and F mean backward and forward adaptation, respectively.

Figure 10: Analysis of how to contextualize. R and G denote the regional and global contexts, respectively. “Step-independent” first combines R and G and then utilizes them for all steps, while “Step-adaptive” does not pre-combine them and utilizes each separately for all steps.