# HASSOD: Hierarchical Adaptive Self-Supervised

Object Detection

 Shengcao Cao\({}^{1}\) Dhiraj Joshi\({}^{2}\) Liang-Yan Gui\({}^{1}\) Yu-Xiong Wang\({}^{1}\)

\({}^{1}\)University of Illinois at Urbana-Champaign \({}^{2}\)IBM Research

\({}^{1}\){cao44,lgui,yxw}@illinois.edu \({}^{2}\)djoshi@us.ibm.com

###### Abstract

The human visual perception system demonstrates exceptional capabilities in learning without explicit supervision and understanding the part-to-whole composition of objects. Drawing inspiration from these two abilities, we propose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a novel approach that learns to detect objects and understand their compositions without human supervision. HASSOD employs a hierarchical adaptive clustering strategy to group regions into object masks based on self-supervised visual representations, adaptively determining the number of objects per image. Furthermore, HASSOD identifies the hierarchical levels of objects in terms of composition, by analyzing coverage relations between masks and constructing tree structures. This additional self-supervised learning task leads to improved detection performance and enhanced interpretability. Lastly, we abandon the inefficient multi-round self-training process utilized in prior methods and instead adapt the Mean Teacher framework from semi-supervised learning, which leads to a smoother and more efficient training process. Through extensive experiments on prevalent image datasets, we demonstrate the superiority of HASSOD over existing methods, thereby advancing the state of the art in self-supervised object detection. Notably, we improve Mask AR from 20.2 to **22.5** on LVIS, and from 17.0 to **26.0** on SA-1B. Project page: https://HASSOD-NeurIPS23.github.io.

## 1 Introduction

The development of human visual perception is remarkable for two key abilities: 1) Humans begin learning to perceive objects in their environment through observation alone , without needing to learn the names of these objects from external supervision. 2) Moreover, human perception operates in a hierarchical manner, enabling individuals to recognize the part-to-whole composition of objects . These characteristic capabilities offer valuable insights into the learning processes of object detectors, which still heavily rely on the availability and quality of fine-grained training data. For example, the state-of-the-art detection/segmentation model, Segment Anything Model (SAM) , is developed on a dataset of 11 million images and 1 billion object masks. It remains an open question how to effectively learn to detect objects and recognize their compositions from even larger-scale datasets (_e.g._, LAION-5B ) without such object-level annotations.

In prior work on self-supervised object detection , a two-stage _discover-and-learn_ paradigm is adopted: 1) Self-supervised visual representations  are obtained, and a saliency-based method is employed to extract the most prominent one or few objects. 2) Subsequently, an object detector is trained based on these pseudo-labels, sometimes involving multiple rounds of self-training for refinement. However, despite such attempts to eliminate the need for external supervision, several weaknesses persist in these approaches: 1) **Narrow coverage of objects.** The focus on only one or few objects per image in previous methods undermines their ability to fully exploit the learning signals innatural scene images containing dozens of objects, such as those in the MS-COCO dataset . This narrow focus also restricts the capability of these methods to accurately detect and segment multiple objects within an image. 2) **Lack of composition.** Prior work often overlooks the composition of objects, neglecting the identification of hierarchical levels for whole objects, part objects, and subpart objects (_e.g._, considering an image of a bicycle; the bicycle is a whole object, its wheels and handles are parts, and the spokes and tires are subparts). This oversight not only limits the interpretability of learned object detectors, but also hinders the model's ability to tackle the intrinsic ambiguity in the task of segmentation. 3) **Infefficiency.** The reliance on multi-round self-training in earlier methods can result in inefficient and non-smooth training processes, which further constrains the potential of self-supervised object detection and comprehension of object composition.

Inspired by the unsupervised, hierarchical human visual perception system, we propose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), _aiming to address these limitations_ mentioned above and better harness the potential of self-supervised object detection, as depicted in Figure 1. First, unlike previous methods that limit their focus to one or few prominent objects per image, HASSOD employs a hierarchical adaptive clustering strategy to group regions into object masks, based on self-supervised visual representations. By adjusting the threshold for terminating the clustering process, HASSOD is capable of effectively determining the appropriate number of objects per image, thus better leveraging the learning signals in images with multiple objects.

The second key component of HASSOD is its ability to identify hierarchical levels of objects in terms of composition. By analyzing the coverage relations between masks and building tree structures, our approach successfully classifies objects as _whole_ objects, _part_ objects, or _subpart_ objects. This novel self-supervised learning task not only improves detection performance, but also enhances the interpretability and controllability of the learned object detector, a property that prior self-supervised detectors lack. Therefore, HASSOD users can comprehend how the detected whole objects are assembled from smaller constituent parts. Simultaneously, they can control HASSOD to perform detection at their preferred hierarchical level, thereby catering more effectively to their needs.

Finally, HASSOD abandons the multi-round self-training used in previous methods which lacks efficiency and smoothness. Instead, we take inspiration from the Mean Teacher [22; 31] framework in semi-supervised learning, employing a teacher model and a student model that mutually learn from each other. This innovative adaptation facilitates a smoother and more efficient training process, resulting in a more effective self-supervised object detection approach.

In summary, the key contributions of HASSOD include:

Figure 1: Fully self-supervised object detection and instance segmentation on prevalent image datasets. Our approach, HASSOD, demonstrates a significant improvement over the previous state-of-the-art method, CutLER , by discovering a more comprehensive range of objects. Moreover, HASSOD understands the part-to-whole object composition like humans do, while previous methods cannot.

* A hierarchical adaptive clustering strategy that groups regions into object masks based on self-supervised visual representations, adaptively determining the number of objects per image and effectively discover more objects from natural scenes.
* The ability to identify hierarchical levels of objects in terms of composition (whole/part/subpart) by analyzing coverage relations between masks and building tree structures, leading to improved detection performance and enhanced interpretability.
* A novel adaptation of the Mean Teacher framework from semi-supervised learning, which replaces the multi-round self-training in prior methods, leading to smoother and more efficient training.
* State-of-the-art performance in self-supervised object detection, enhancing Mask AR from 20.2 to **22.5** on LVIS , and from 17.0 to **26.0** on SA-1B . Remarkably, these results are achieved through training with only \(\) of the images and \(\) of the iterations required by prior work.

## 2 Related Work

**Unsupervised object detection/discovery.** Identifying and locating objects in images without using any human annotations is a challenging task, as it requires learning the concept of objects from image data without any external supervision. OSD  formulates this task as an optimization problem on a graph, where the nodes are object proposals generated by selective search, and the edges are constructed based on visual similarities. rOSD  improves the scalability of OSD with a saliency-based region proposal algorithm and a two-stage strategy. LOD  formulates unsupervised object discovery as a ranking optimization problem for improved computation efficiency. Following the observation that DINO , a self-supervised pre-training method, can segment the most prominent object in each image, LOST , FOUND , and FreeSOLO  train object detectors using saliency-based pseudo-labels. TokenCut  and CutLER  also use self-supervised representations, but generate pseudo-labels by extending Normalized Cuts . Saliency-based region proposal and Normalized Cuts are both focused on the prominent objects in each image, and usually only propose one or few objects per image. Different from these approaches, HASSOD produces initial pseudo-labels using a hierarchical adaptive clustering strategy, which can adaptively determine the number of objects depending on the image contents.

**Object detection by parts.** Detecting objects by identifying their composing parts has been widely studied in computer vision. Deformable Parts Model (DPM)  is a seminal approach that utilizes discriminatively trained part-based models for object detection, which effectively models complex object structures and improves over monolithic detectors. A following method  not only detects the objects, but also simultaneously represents them using body parts, highlighting the importance of both holistic models and part-based representations. This idea is extended by leveraging both whole object and part detections to infer human actions and attributes , suggesting the advantage of a combined approach. In this work, we revisit this classic idea of representing and detecting whole objects as well as their parts in the context of self-supervised learning.

## 3 Approach

In this section, we introduce the learning process in our proposed approach, Hierarchical Adaptive Self-Supervised Object Detection (HASSOD). Following prior work on unsupervised object detection [39; 37; 29; 30; 38], HASSOD adopts a two-stage _discover-and-learn_ process to learn a self-supervised object detector, as illustrated in Figure 2. In the first stage, we discover objects from unlabeled images using self-supervised representations, and generate a set of initial pseudo-labels. Then in the second stage, we learn an object detector based on the initial pseudo-labels, and smoothly refine the model by self-training. The first stage is based on pre-trained, fixed visual features, and the second stage learns an object detector to improve over the fixed visual features and pseudo-labels. In the following subsections, we describe the three core components of HASSOD in detail.

### Hierarchical Adaptive Clustering

In the first stage, HASSOD creates a set of pseudo-labels as the initial self-supervision source. We propose a hierarchical adaptive clustering strategy to discover object masks as pseudo-labels, using only unlabeled images and a frozen self-supervised visual backbone. Figure 3 provides an overview of this procedure. Our hierarchical adaptive clustering algorithm extends agglomerative clustering , grouping adjacent image patches into semantically coherent masks based on the similarity of self-supervised visual representations. More specifically, we use a _frozen_ ViT-B/8 model  pre-trained on unlabeled ImageNet  by DINO , a self-supervised representation learning method, to extract visual features. For each image, we take the feature map generated by this model at its final Transformer layer . Each spatial element in the feature map corresponds to a \(8 8\) patch in the original image.

To initiate the hierarchical adaptive clustering process, we treat each patch as an individual region. We then compute the pairwise cosine similarity between the features of adjacent regions to measure their closeness in the semantic feature space. The regions are gradually merged into masks that represent objects by iteratively performing the following steps: 1) Identify the pair of adjacent regions with the highest feature similarity. 2) If the similarity is smaller than the pre-set threshold \(^{}\), stop the merging process. 3) Merge the two regions, and compute the feature of the merged region by averaging all the patch-level features within it. 4) Update the pairwise similarity between this newly merged region and its neighbors. This merging process is visualized in Figure 3, columns 1-3.

Once the merging process is complete, we perform a series of automated post-processing steps to refine and select the masks, including Conditional Random Field (CRF)  and filtering out masks that are smaller than 100 pixels or contain more than two corners of the image. These steps are based on standard practices in previous work  and require no manual intervention. Our hierarchical adaptive clustering strategy effectively groups regions into object masks based on self-supervised visual representations, adaptively determining the appropriate number of objects per image. In

Figure 3: Hierarchical adaptive clustering and hierarchical levels of objects. The procedure of creating initial pseudo-labels for training the object detector without any human annotations includes the following steps: (Initialize) Visual features are extracted from the given image by a ViT pre-trained with DINO , and each \(8 8\) patch is initialized as one individual region. (Merge) Adjacent regions with the highest feature similarities are progressively merged into object masks, until the pre-set thresholds \(_{i}^{}\) are reached. (Post-Process) Object masks are selected and refined using simple post-processing techniques. (Ensemble) Results from multiple thresholds \(\{_{i}^{}\}_{i=1}^{3}\) are combined to ensure better coverage of potential objects. (Split) Analysis of coverage relations divides objects into three hierarchical levels: whole, part, and subpart. The example on the right illustrates the tree structure of object composition: The whole aircraft is composed of an upper and a lower part. The upper part further consists of a left wing, a right wing, and a person standing on it.

Figure 2: Two-stage discover-and-learn process in HASSOD. Stage 1 uses a frozen, self-supervised DINO  ViT backbone to discover initial pseudo-labels from unlabeled images. Stage 2 learns an object detector to improve over the pre-trained features and initial pseudo-labels.

images containing multiple objects with heterogeneous semantic features, the merging process stops earlier, resulting in a larger number of regions corresponding to different objects. Conversely, in highly homogeneous images, more regions are merged, leading to fewer object masks. This adaptive approach enables HASSOD to cover more objects for self-supervised learning, rather than being limited by one or a few prominent objects in each image in prior work [38; 39].

In practice, we are not restricted to one single fixed threshold \(^{}\) to determine the stopping criterion for the clustering process. Instead, we find it beneficial to ensemble results from multiple (_e.g._, 3) pre-set thresholds \(\{^{}_{i}\}_{i=1}^{3}\). When the currently highest feature similarity reaches one of these thresholds, we record the derived object masks from the merged regions at that step. Utilizing multiple thresholds allows us to capture objects of various sizes and at different hierarchical levels of composition, enabling a more comprehensive coverage of objects in scene images. The post-processing and ensemble are visualized in Figure 3, columns 4-5.

### Hierarchical Level Prediction

In the following second stage, HASSOD learns an object detection and instance segmentation model, _e.g._, Cascade Mask R-CNN , using the initial pseudo-labels generated in the first stage. By training on such pseudo-labels, the model learns to recognize common objects across different training images, and thus achieves _enhanced generalization_ to images which the model has not seen during training.

In addition to the standard object detection objective, we aim to equip our detector with the ability to understand the hierarchical structure among objects and their constituent parts. In HASSOD, we incorporate the concept of _hierarchical levels_ into object masks by leveraging the _coverage relations_ between them. Formally, we say mask A is covered by mask B when three conditions are satisfied (with respect to a pre-set coverage threshold \(^{}\%\)): 1) More than \(^{}\%\) of pixels in mask A are also in mask B. 2) Less than \(^{}\%\) of pixels in mask B are in mask A. 3) Mask B is the smallest among all masks satisfying the previous two conditions. Intuitively, if mask B covers mask A, it suggests that A is a part of B and B is at a higher level than A. If we consider A and B as tree nodes, A should be a child of B. Using all such coverage relations, we can construct a _forest of trees_ that contain all masks in an image. Ultimately, the roots of all trees in this image are considered as "whole" objects, their direct children are "part" objects, and all the remaining descendants are "subpart" objects. An example is shown on the right side of Figure 3.

After identifying the hierarchical levels of object masks in the pseudo-labels, we attach a new classification head to the object detector for level prediction, which classifies each predicted object as a whole object, a part object, or a subpart object. This new component enables HASSOD to model object composition effectively, resulting in improved object detection performance and enhanced interpretability compared with previous self-supervised object detection methods. The hierarchical level prediction head is added alongside the existing foreground/background classification head, box regression head, and mask prediction head. Subsequently, we train the object detector using the initial set of object mask pseudo-labels obtained from the hierarchical adaptive clustering process, as well as the additional level prediction task.

### Mean Teacher Training with Adaptive Targets

Notably, the initial pseudo-labels derived in the first stage contain noise and are not perfectly aligned with real objects. To improve over such noisy pseudo-labels, prior work [37; 38] usually employs multi-round self-training to refine the model, _i.e._, using a well-trained detector to re-generate pseudo-labels and re-train a new detector. _For the first time_, HASSOD refines the object detector efficiently and smoothly by adapting the Mean Teacher learning paradigm [22; 31] from semi-supervised learning to the fully self-supervised setting.

Before introducing our innovative adaptation of Mean Teacher in the self-supervised setting, we first briefly summarize the mutual-learning process in Mean Teacher (see Figure 4). Mean Teacher employs two models, a teacher and a student, which learn from each other. The teacher takes weakly-augmented, unlabeled images as input and provides detection outputs as training targets for the student. The student's weights are updated to minimize the discrepancy between its predictions and the targets given by the teacher on the same unlabeled images but with strong augmentation. In the semi-supervised setting, the student receives supervision from two sources simultaneously. One source is the "teacher-to-student" branch mentioned above, and the other is the "label-to-student" branch where the student learns from images with ground-truth labels. Both branches compute standard detection losses (_e.g._, bounding box classification and regression), and the student is optimized to minimize the total loss. The teacher's weights are an exponential moving average of the student's weights, ensuring smooth and stable training targets.

In HASSOD, we do not have any labeled images from human supervision but instead utilize two sources of self-supervision. One source is the initial pseudo-labels obtained from our hierarchical adaptive clustering, which functions similarly to the labels-to-student branch in the semi-supervised setting. The other source is the detection predictions made by the teacher model, which corresponds to the teacher-to-student branch in Mean Teacher. Different from standard Mean Teacher, our method employs adaptive training targets, as we gradually adjust the loss weights for the two branches. This is because the initial pseudo-labels may not effectively cover all possible objects, while the teacher model will progressively improve as a better source of supervision. Consequently, during Mean Teacher self-training, we continuously decrease the loss weight \(_{}\) for the branch that uses the initial pseudo-labels and increase the loss weight \(_{}\) for the branch based on the teacher's predictions, following a cosine schedule.

## 4 Experiments

In this section, we conduct extensive experiments to evaluate HASSOD in comparison with previous methods. We first describe the training details and efficiency in Section 4.1. Section 4.2 introduces the datasets and metrics used for evaluation. Section 4.3 presents our main results of self-supervised object detection and instance segmentation. Section 4.4 provides some qualitative results and analysis. Section 4.5 conducts further experiments to verify the effects of each component in HASSOD. Additional quantitative and qualitative results are included in the appendix.

### Data-Efficient and Computation-Efficient Training

We train a Cascade Mask R-CNN  with a ResNet-50  backbone on MS-COCO  images. The backbone is initialized from DINO  self-supervised pre-training. We use both the train and unlabeled splits of MS-COCO, totaling to about 0.24 million images. Notably, this amount of images is only \(/\) of ImageNet used by prior work CutLER . Compared with ImageNet-like  iconic images, images in MS-COCO are mostly captured in complex scenes containing multiple objects with diverse layouts and compositions. Therefore, each image offers richer learning resources for object detectors, _enabling effective detector training with significantly fewer images_. The whole

Figure 4: Mean Teacher self-training with adaptive targets in HASSOD. Two detectors of the same architecture, the teacher and the student, learn from each other to improve over the initial pseudo-labels. The teacher is updated as the exponential moving average (EMA) of the student. The student receives supervision from two branches: The teacher-to-student branch (**top**) encourages the student to mimic the teacher’s predictions; the label-to-student branch (**bottom**) minimizes the discrepancy between the student’s predictions and the initial pseudo-labels. During training, our proposed adaptive target strategy increases the weight for the teacher-to-student branch, \(_{}\), and decreases the weight for the label-to-student branch, \(_{}\), since the teacher becomes a more and more reliable self-supervision source compared with the initial pseudo-labels.

training process spans 40,000 iterations, taking about 20 hours on 4 NVIDIA A100 GPUs. The efficiency and smoothness introduced by the Mean Teacher self-training approach reduces the training iterations to \(\) of that required by CutLER , highlighting the computation efficiency of our training strategy. Implementation details are included in Appendix J.

### Evaluation Datasets and Metrics

We mainly conduct our experiments in a _zero-shot_ manner on the validation sets of three benchmark datasets, namely Objects365 , LVIS , and SA-1B . Given that self-supervised object detection methods, including HASSOD, do not utilize class labels as a form of supervision, we follow prior work [37; 38; 39] and evaluate these models as _class-agnostic_ detectors, comparing them only against the bounding boxes and masks provided in the dataset annotations.

* Objects365  is a large-scale object detection dataset containing 365 object categories. The combined validation sets of Objects365 v1 and v2 include 80,000 images in total.
* LVIS  is a dataset that features a wide variety of over 1,200 object classes, using the same images as MS-COCO . LVIS v1.0 validation set has 19,809 images, each annotated with object masks for instance segmentation.
* SA-1B  is a recent dataset that includes 11 million images and 1 billion fine-grained, model-generated object masks. SA-1B provides a more comprehensive coverage of all potential objects, facilitating a more robust evaluation of self-supervised object detectors. As SA-1B does not provide a validation split, we utilize a random subset of 50,000 images for our assessment.

In terms of evaluation metrics, we focus primarily on average recall (AR) rather than average precision (AP). The choice of AR over AP is motivated by the nature of the self-supervised task. In a dataset with a fixed number of classes, objects not labeled by humans - simply because they do not fall under the designated classes - may still be detected by a self-supervised detection model. Standard AP calculation would penalize such predictions as false positives, despite them being valid detections. In contrast, AR does not suffer from this issue, making it a more appropriate metric for our context. By prioritizing recall, we can more accurately assess the ability of our model to identify all relevant objects in an image, which aligns with the goal of the self-supervised object detection task. We evaluate AR based on both bounding boxes for object detection ("Box AR") and masks for instance segmentation ("Mask AR"). Appendix A discusses the evaluation metrics in detail.

### Self-Supervised Detection and Segmentation

After we use HASSOD to train the object detection and instance segmentation model, Cascade Mask R-CNN, on MS-COCO images, we evaluate our model on Objects365, LVIS, and SA-1B datasets in a zero-shot manner, _i.e_., no further training on these three datasets. The whole training and evaluation process is repeated for three times, and we report the mean performance for conciseness. The _standard deviation of AR is less than \(0.6\)_ on all three datasets. Complete evaluation results are included in Appendix H.

We compare HASSOD with prior state-of-the-art self-supervised object detection methods, including FreeSOLO  and CutLER . We also include results from SAM , the latest _supervised_ class-agnostic detection/segmentation model, to gain understanding of the gap between self-supervised and supervised models, and how HASSOD is effectively closing this gap. To be consistent with other models, we provide SAM with only the raw images but no bounding boxes or points as prompts. For prior methods FreeSOLO, CutLER, and SAM, we directly evaluate the publicly available model checkpoints on the given datasets. Considering that the number of ground-truth labels per image may be greater than 100, we allow all models to output up to 1,000 predictions per image.

As shown in the main results summarized in Table 1, HASSOD significantly improves the detection and segmentation performance over previous self-supervised models FreeSOLO and CutLER. On Objects365, we improve the Box AR by 3.2; on LVIS, we improve Box AR by 3.3, and Mask AR by 2.3. The most remarkable performance gain is observed on **SA-1B**. **We improve Box AR from 18.8 to 29.0 (relatively +54%) and improve Mask AR from 17.0 to 26.0 (relatively +53%).**

We gain improved recalls for objects of all scales, but _small and medium-sized objects relatively benefit more than large objects_. For instance, our AR\({}_{S}\) is 2.6\(\) as CutLER's AR\({}_{S}\) on SA-1B. It is worth noting that detecting small objects is intrinsically harder than large objects - even though the labels in SA-1B are produced by the same SAM model, when the bounding box prompts are no longer available, SAM can only reach a 20.0 Mask AR for small objects. Meanwhile, **we halve the performance gap between self-supervised CutLER and supervised SAM from 15.1 Mask AR\({}_{S}\) to 7.1 Mask AR\({}_{S}\).** By learning from hierarchical levels of object compositions, HASSOD more effectively captures small objects which are part of whole objects.

### Qualitative Results

In this section, we analyze some qualitative results on images from LVIS. The visualization is shown in Figure 5. Qualitative results on other datasets are included in Appendix K.

As shown in the examples, our proposed HASSOD exhibits a more comprehensive coverage of all objects in complex scenes, compared with the previous state-of-the-art self-supervised object detection method CutLER . This advantage originates from the pseudo-labels generated by our hierarchical adaptive clustering, which includes a proper number of candidate objects per image according to the image contents, rather than only focusing on a fixed number of objects. Furthermore, HASSOD can predict the hierarchical level of each detected object. Being a _fully self-supervised_ model, HASSOD has surprisingly gained the _human-like ability_ to comprehend the composition of objects. This ability leads to better interpretability and controllability: Users of HASSOD can understand the composition of each object detected by the model. Meanwhile, users can also control the segmentation granularity by selecting the predictions at the desired hierarchical level.

The qualitative results also show some limitations of HASSOD. By comparing the last two columns, it can be observed that HASSOD produces relatively fewer predictions for "subpart" objects. This is due to the distribution imbalance in the initial pseudo-labels, in which only about 10% objects are subparts. Also, the hierarchical levels learned by HASSOD are sometimes inconsistent with human perception. For example, instead of recognizing the person as a whole object in the last example image, HASSOD detects the upper and lower parts of the body as whole objects. Due to the lack of human supervision, the hierarchical prediction of HASSOD is not always aligned with humans. We further analyze this limitation in Appendix I.

    &  &  \\ Method & AR & AR\({}_{S}\) & AR\({}_{M}\) & AR\({}_{L}\) & AP & AR & AR\({}_{S}\) & AR\({}_{M}\) & AR\({}_{L}\) & AP \\   \\ SAM & 54.9 & 32.1 & 60.5 & 67.6 & 11.9 & & & & \\ FreeSOLO  & 10.2 & 0.2 & 5.8 & 23.4 & 3.4 & & No ground-truth mask & \\ CutLER  & 35.8 & 17.6 & 36.1 & 50.5 & **11.5** & & & annotations in Objects365 & \\ HASSOD (Ours) & **39.0** & **21.4** & **40.4** & **52.1** & 11.0 & & & & \\   \\ SAM & 42.7 & 27.7 & 66.3 & 75.5 & 6.1 & 46.1 & 31.1 & 71.3 & 74.6 & 6.7 \\ FreeSOLO  & 6.4 & 0.3 & 9.7 & 34.6 & 1.9 & 5.9 & 0.2 & 9.2 & 31.7 & 1.9 \\ CutLER  & 23.6 & 13.1 & 36.2 & 55.6 & 4.5 & 20.2 & 11.3 & 31.1 & 46.2 & 3.6 \\ HASSOD (Ours) & **26.9** & **15.6** & **42.2** & **56.9** & **4.9** & **22.5** & **12.7** & **36.1** & **47.8** & **4.2** \\   \\ SAM & 60.5 & 19.8 & 59.8 & 81.5 & 38.2 & 60.8 & 20.0 & 59.9 & 82.2 & 38.9 \\ FreeSOLO  & 2.4 & 0.0 & 0.1 & 7.4 & 1.5 & 2.2 & 0.0 & 0.2 & 6.9 & 1.5 \\ CutLER  & 18.8 & 5.1 & 14.6 & 32.8 & 9.0 & 17.0 & 4.9 & 13.9 & 28.5 & 7.8 \\ HASSOD (Ours) & **29.0** & **13.3** & **25.1** & **43.8** & **15.5** & **26.0** & **12.9** & **22.8** & **38.3** & **13.8** \\   

Table 1: Comparison of self-supervised object detection and instance segmentation methods on prevalent image datasets. We consider the average recall (AR) instead of average precision (AP) as the main metric, because valid detection of objects outside the categories defined by human annotations is penalized by AP. HASSOD significantly outperforms the previously best methods FreeSOLO  and CutLER  in terms of AR at all object scales (**S**mall, Medium, and Large). To understand the extent of improvements, we also include results from state-of-the-art _supervised_ model SAM . HASSOD leads to a reduced gap between _fully self-supervised_ models and _supervised_ SAM. Notably, HASSOD only uses \(1/5\) of training images and \(1/12\) of training iterations as CutLER.

### Ablation Study

In this section, we conduct an ablation study to understand the effects of each component in HASSOD. To evaluate the performance more robustly against a larger set of human-annotated object-level labels, we combine the annotations of MS-COCO  and LVIS  on the val2017 split, because they are complementary to each other: LVIS uses the same images as MS-COCO, but labels more object classes. However, LVIS annotations are not as exhaustive as MS-COCO, meaning that objects within LVIS categories may not be labeled on all images. After combining the two sets of annotations and removing duplicates, there are around 20 object-level labels per image. We use this combined dataset for evaluation in all the ablation study experiments, unless otherwise specified.

**Quality of initial pseudo-labels.** We first examine how the design choices in our hierarchical adaptive clustering influence the quality of initial pseudo-labels. The results are summarized in Table 2. Each threshold \(_{}^{}\{0.1,0.2,0.4\}\) leads to a different trade-off between the number of labels per image and the recall. A higher threshold stops the merging process earlier, and thus results in more pseudo-labels. With post-processing, we can improve pseudo-label quality by removing about half of the labels, and increase AP significantly without losing much AR. Finally, the ensemble of multiple merging thresholds \(_{}^{}\{0.1,0.2,0.4\}\) brings the best overall pseudo-label quality. Appendices D, E, and F present more details regarding the choice of \(^{}\), computation costs, and ViT backbones in this stage.

**Effects of hierarchical level prediction and Mean Teacher.** After generating the initial pseudo-labels with hierarchical adaptive clustering, we train the object detector with several techniques, including hierarchical level prediction, Mean Teacher self-training, and adaptively adjusting learning targets. The contribution of each technique is summarized in Table 3. Each component brings an additional 0.3 - 0.5 Mask AR improvement, and when they function together, the best overall performance can be achieved.

Figure 5: Qualitative results on LVIS images. Overall, our HASSOD successfully detects more objects compared with CutLER . CutLER tends to detect only one or few prominent objects in the image, while HASSOD captures other objects as well (_e.g._, bread in row 1, and traffic sign in row 3). Moreover, HASSOD learns the composition of objects (_e.g._, cat-face-eye in row 2, and vehicle-wheel-tire in row 4), which is similar to human perception.

**Improvement over initial pseudo-labels.** Although the initial pseudo-labels are produced by a frozen DINO backbone and they tend to be noisy and coarse, HASSOD is _not upper-bounded by_ the quality of the fixed initial pseudo-labels or the pre-trained backbone. This is because of the following reasons: 1) While the initially discovered pseudo-labels are noisy, in the learning stage we train a detection model to learn common objects and their hierarchical relations for _enhanced generalization_ to unseen images. By learning this detector, we boost the detection AR and AP from 8.9 and 1.7 (the last row in Table 2) to 20.6 and 6.1 (the second row in Table 3), respectively. Meanwhile, the pre-trained backbone features are adapted for the detection task in an end-to-end manner. 2) We further leverage Mean Teacher for continual self-enhancement, and gradually _minimize the negative impact of noisy initial pseudo-labels_. The evolving teacher detector and its features provide improved pseudo-labels to the student. Notably, we can directly _read out_ the predictions from the teacher as the refined hierarchical pseudo-labels, instead of inefficiently running the clustering algorithm using the enhanced backbone. Consequently, we further improve the detection AR and AP to 22.4 and 6.3 (the last row in Table 3), respectively.

## 5 Conclusion

We present Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), an approach inspired by human visual perception that learns to detect objects and understand object composition in a self-supervised manner. HASSOD uses a hierarchical adaptive clustering strategy to propose a varying number of objects per image, and learns hierarchical levels of objects by analyzing geometric relations between objects. Mean Teacher self-training with adaptive targets facilitates the detector training process with smooth learning objectives and improved training efficiency. Empirical evaluation on recent large-scale image datasets Objects365, LVIS, and SA-1B demonstrates our significant improvement over prior self-supervised detectors. We detail the limitations and broader impacts of HASSOD in Appendix I.

    &  &  &  \\  & }\)} &  &  &  & _{S}\)} & _{M}\)} & _{L}\)} &  \\  MaskCut  & – & ✓ & 1.85 & 3.5 & 0.0 & 2.0 & 20.0 & 1.5 \\   & 0.1 & & 5.33 & 4.4 & 0.8 & 5.1 & 16.6 & 1.2 \\  & 0.1 & ✓ & 2.58 & 4.1 & 0.6 & 5.1 & 15.6 & **1.8** \\ Hierarchical & 0.2 & & 8.36 & 5.5 & 1.2 & 7.0 & 18.9 & 1.3 \\ adaptive & 0.2 & ✓ & 4.20 & 5.3 & 0.9 & 7.0 & 18.4 & **1.8** \\ clustering & 0.4 & & 23.33 & 7.9 & **2.1** & 12.0 & 21.7 & 0.7 \\ (Ours) & 0.4 & ✓ & 11.61 & 7.8 & 1.7 & 12.1 & 22.1 & 1.3 \\  & ensemble & ✓ & 12.69 & **8.9** & 1.7 & **12.4** & **29.1** & 1.7 \\   

Table 2: Ablation study on factors influencing the quality of initial pseudo-labels. The threshold \(^{}\) controls the stopping criterion of the merging process, and affects AR and the number of pseudo-labels. Applying post-processing can remove low-quality pseudo-labels without decreasing AR by a large margin. Ensemble of multiple pseudo-label sources leads to the best overall quality.

   Level & Mean & Adaptive & & & Mask & \\ Prediction & Teacher & Targets & AR & AR\({}_{S}\) & AR\({}_{M}\) & AR\({}_{L}\) & AP \\   & & & 20.2 & 9.2 & 30.4 & 42.5 & 5.7 \\ ✓ & & & 20.6 & 9.7 & 30.1 & 43.9 & 6.1 \\ ✓ & ✓ & & 22.1 & 10.9 & **32.9** & 44.5 & 5.5 \\ ✓ & ✓ & ✓ & **22.4** & **11.3** & **32.9** & **45.0** & **6.3** \\   

Table 3: Ablation study on factors influencing the training of the object detector. Hierarchical level prediction is introduced as an auxiliary task for self-supervision. Mean Teacher self-training replaces the vanilla multi-round self-training and brings a smoother and more efficient training process. The weights of two learning targets, initial pseudo-labels and teacher predictions, are adaptively adjusted to build a more effective curriculum. All the three key designs are combined for the best overall performance of HASSOD.