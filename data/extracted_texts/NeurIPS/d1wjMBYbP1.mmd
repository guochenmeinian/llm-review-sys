# Zero-Shot Anomaly Detection via Batch Normalization

Aodong Li

UC Irvine

&Chen Qiu

Bosch Center for AI

&Marius Kloft

TU Kaiserslautern

&Padhraic Smyth

UC Irvine

&Maja Rudolph

Bosch Center for AI

&Stephan Mandt

UC Irvine

Equal contribution Joint supervision. Correspondence to: aodongl1@uci.edu

###### Abstract

Anomaly detection (AD) plays a crucial role in many safety-critical application domains. The challenge of adapting an anomaly detector to drift in the normal data distribution, especially when no training data is available for the "new normal", has led to the development of zero-shot AD techniques. In this paper, we propose a simple yet effective method called Adaptive Centered Representations (ACR) for zero-shot batch-level AD. Our approach trains off-the-shelf deep anomaly detectors (such as deep SVDD) to adapt to a set of inter-related training data distributions in combination with batch normalization, enabling automatic zero-shot generalization for unseen AD tasks. This simple recipe, batch normalization plus meta-training, is a highly effective and versatile tool. Our theoretical results guarantee the zero-shot generalization for unseen AD tasks; our empirical results demonstrate the first zero-shot AD results for tabular data and outperform existing methods in zero-shot anomaly detection and segmentation on image data from specialized domains. Code is at https://github.com/aodongli/zero-shot-ad-via-batch-norm

## 1 Introduction

Anomaly detection (AD)--the task of identifying data instances deviating from the norm --plays a significant role in numerous application domains, such as fake review identification, bot detection in social networks, tumor recognition, and industrial fault detection. AD is particularly crucial in safety-critical applications where failing to recognize anomalies, for example, in a chemical plant or a self-driving car, can risk lives.

Consider a medical setting where an anomaly detector encounters a batch of medical images from different patients. The medical images have been recorded with a new imaging technology different from the training data, or the patients are from a demographic the anomaly detector has not been trained on. Our goal is to develop an anomaly detector that can still process such data using batches, assigning low scores to normal images and high scores to anomalies (i.e., images that differ systematically) without retraining. To achieve this zero-shot adaptation, we exploit the fact that anomalies are rare. Given a new batch of test data, a zero-shot AD method [18; 36; 51; 71] has to detect which features are typical of the majority of normal samples and which features are atypical.

We propose Adaptive Centered Representations (ACR), a lightweight zero-shot AD method that combines two simple ideas: batch normalization and meta-training. Assuming an overall majority of "normal" samples, a randomly-sampled batch will typically have more normal samples than anomalies. The effect of batch normalization is then to draw these normal samples closer to the center (in its recentering and scaling operation), while anomalies will end up further away from the center. Notably, this scaling and centering is robust to a distribution shift in the input, allowing aself-supervised anomaly detector to generalize to distributions never encountered during training. We propose a meta-training scheme to unlock the power of batch normalization layers for zero-shot AD. During training, the anomaly detector will see many different anomaly detection tasks, mixed from different choices for normal and abnormal examples. Through this variability in the training tasks, the anomaly detector will learn to rely as much as possible on the batch normalization operations in its architecture.

Advantages of ACR include that it is theoretically grounded, simple, domain-independent, and compatible with various backbone models commonly used in deep AD [56; 63]. Contrary to recent approaches based on foundation models , applicable only to images, ACR can be employed on data from any domain, such as time series, tabular data, or graphs.

We begin by presenting our assumptions and method in Sec. 2. Next, with the main idea in mind, we describe the related work in Sec. 3. We demonstrate the effectiveness of our method with experiments in Sec. 4. Finally, we conclude our work and state the limitations and societal impacts.

Our contributions can be summarized as follows:

* **An effective new method.** Our results for the first time show that training off-the-shelf deep anomaly detectors on a meta-training set, using batch normalization layers, gives automatic zero-shot generalization for AD. For which we derive a generalization bound on anomaly scores.
* **Zero-shot AD on tabular data.** We provide the first empirical study of zero-shot AD on tabular data, where our adaptation approach retains high accuracy.
* **Competitive results for images.** Our results demonstrate not only a substantial improvement in zero-shot AD performance for non-natural images, including medical imaging but also establish a new state-of-the-art in anomaly segmentation on the MVTec AD benchmark .

## 2 Method

We begin with the problem statement in Sec. 2.1 and then state the assumptions in Sec. 2.2. Finally we present our proposed solution in Sec. 2.3. The training procedure is outlined in Alg. 1 in Supp. C.

### Problem Statement and Method Overview

We consider the problem of learning an anomaly detector that is required to immediately adapt (without any further training) when deployed in a new environment. The main idea is to use batch normalization as a mechanism for _adaptive batch-level_ AD. For any batch of data containing mostly "normal" samples, each batch normalization shifts its inputs to the origin, thereby (1) enabling the discrimination between normal data and outliers/anomalies, and (2) bringing data from different distributions into a common frame of reference. (Notably, we propose applying batch norm in multiple layers for different anomaly scorers.) For the algorithm to generalize to unseen distributions,

Figure 1: **a)** Demonstrations of concrete examples of a meta-training set and a testing distribution. It is not necessary for the meta-training set to include the exact types of samples encountered during testing. For instance, when detecting lions within geese, the training data does not need to include lions or geese. **b)** Illustration of zero-shot batch-level AD with ACR using a one-class classifier . The approach encounters three tasks (\(P_{1:3}^{}\), Eq. (6)) during training (black arrows) and learns to map each taskâ€™s majority of samples (i.e., the normal samples) to a shared learned center in embedding space. At test time (blue arrow), the learned model maps the normal (majority) samples to the same center and the distance from the center serves as AD score.

we train our model on multiple data sets of "normal" data simultaneously, making sure each training batch contains a majority of related data points (from the same distribution) at a time.

Fig. 1 illustrates this idea, where all distributions are exemplified based on the example of homogeneous groups of animals (only dogs, only robins, etc.) The goal is to detect a lion among geese, where neither geese nor lions have been encountered before. Fig. 1 illustrates the scheme based on the popular example of deep support vector data description (DSVDD) , where samples are mapped to a pre-specified point in an embedding space and scored based on their distance to this point. All training distributions are mapped to the same point, as enabled through batch normalization.

### Notation and Assumptions

To formalize the notion of a meta-training set, we consider a distribution of interrelated data distributions (previously referred to as groups) as commonly studied in meta-learning and zero-shot learning . This inter-relatedness can be expressed by assuming that \(K\) training distributions \(P_{1},,P_{K}\) and a test distribution \(P_{*}\) are sampled from a meta-distribution \(\):

\[P_{1},,P_{K},P_{*}}}{{}} .\] (1)

We assume that the distributions in \(\) share some common structure, such that training a model on one distribution has the potential to aid in deploying the model on another distribution. For example, the data \(\) could be radiology images from patients, and each \(P_{j}\) or \(P_{*}\) could be a distribution of images from a specific hospital. These distributions share similarities but differ systematically because of differences in radiology equipment, calibration, and patient demographics2. Each of the distributions \(P\) defines a different anomaly detection task. For each task, we have to obtain an anomaly scoring function \(S_{}\) that assigns low scores to normal samples \( P\) and high scores to anomalies.

We now consider a batch \(\) of size \(B\), taken from an underlying data set \( P\) of size \(N\). The batch can be characterized by indexing data points from \(\):

\[(i_{1},...,i_{B})(\{1,...,N\}).\] (2)

We denote the anomaly scores on a _batch_ level by defining a vector-valued anomaly score

\[_{}(}})=(S_{}^{i_{1}}(}}),,S_{}^{i_{B}}(}})),\] (3)

indicating the anomaly score for every datum in a batch. By thresholding the anomaly scores \(S_{}^{i}(}})\), we obtain binary predictions of whether data point \(_{i}\) is anomalous in _the context of batch_\(}}\).

By conditioning on a batch of samples, our approach obtains distributional information beyond a single sample. For example, an image of a cat may be normal in the context of a batch of cat images, but it may be anomalous in the context of a batch of otherwise dog images. This is different from current deep anomaly detection schemes that evaluate anomaly scores without referring to a context.

Before presenting a learning scheme of how to combine batch-level information in conjunction with established anomaly detection approaches, we discuss the assumptions that our approach makes. (The empirical or theoretical justifications as well as possibilities of removing or mitigating the assumptions can be found in Supp. A.)

**A1**_Availability of a meta-training set._ As discussed above, we assume the availability of a set of interrelated distributions. The meta-set is used to learn a model that can adapt without re-training.

**A2**_Batch-level anomaly detection._ As mentioned above, we assume we perform batch-level predictions at test time, allowing us to detect anomalies based on reference data in the batch.

**A3**_Majority of normal data._ We assume that normal data points take the majority in every i.i.d. sampled test batch.

Due to the absence of anomaly labels (or text descriptions) at test-time, we cannot infer the correct anomaly labels without assumptions **A2** and **A3**. Together, they instruct us that given a batch of test examples, the majority of the samples in the batch constitute normal samples.

### Adaptively Centered Representations

Batch Normalization as Adaptation Modules.An important component of our method is batch normalization, which shifts and re-scales any data batch \(_{}\) to have a sample mean zero and variance one. Batch normalization also provides a naive parameter-free zero-shot batch-level anomaly detector:

\[S_{}^{i}(_{})=\|(_{i}-_{ _{}})/_{_{}}\|_{2}^{2},\] (4)

where \(\) and \(^{2}\) are the coordinate-wise sample mean and sample variance. \(\) is dominated by the majority of the batch, which by assumption A3, is the normal data. If the \(_{i}\) lie in an informative feature space, anomalies will have a higher-than-usual distance to the mean, making the approach a simple, _adaptive_ AD method, illustrated in Fig. 2 in Supp. D.

While the example provides a proof of concept, in practice, the normal samples typically do not concentrate around their mean in the raw data space. Next, we integrate this idea into neural networks and develop an approach that learns adaptively centered representations for zero-shot AD.

Deep Models with Batch Normalization Layers as Scalable Zero-shot Anomaly Detectors.In deep neural networks, the adaptation ability is obtained for _free_ with batch normalization layers . Batch normalization has become a standard and necessary component to facilitate optimization convergence in training neural networks. In common neural network architectures [27; 33; 60], batch normalization layers are used after each non-linear transformation layer, making a zero-shot adaptation with respect to its input batch. The entire neural network, stacking up many non-linear transformation and normalization layers, has powerful potential in scalable zero-shot adaptation and learning adaptation-needed feature representations for complex data forms.

Training Objective.As discussed above, we can instantiate \(S_{}\) as a deep neural network with batch normalization layers and optimize the neural network weights \(\). We first provide our objective function and then the rationality. Our approach is compatible with a wide range of deep anomaly detection objectives; therefore we consider a generic loss function \(L[_{}(_{})]\) that is a function of the anomaly score. For example, in many cases, the loss function to be minimized is the anomaly score itself (averaged over the batch).

The availability of a meta-data set (**A1**) gives rise to the following minimization problem:

\[^{*}=*{arg\,min}_{}_{j=1}^{K}_{_{}-P_{j}}L[_{}(_{})].\] (5)

Typical choices for \(L[_{}(_{})]\) include DSVDD  and neural transformation learning (NTL) . Details and modifications of this objective will follow.

Why does it work? Batch normalization helps re-calibrate the data batches of different distributions into similar forms: normal data will center around the origin. Such calibration happens from granular features (lower layers) to high-level features (higher layers), resulting in powerful feature learning and adaptation ability3. We visualize the calibration in Fig. 3 in Supp. I.2. Therefore, optimizing Eq. (5) are able to learn a (locally) optimal \(_{^{*}}\) that is adaptive to all \(K\)_different_ training distributions. Such learned adaptation ability will be guaranteed to generalize to unseen related distributions \(P_{*}\). See Sec. 2.4 below and Supp. B for more details.

Meta Outlier Exposure.While Eq. (5) can be a viable objective, we can significantly improve over it while avoiding trivial solutions4. The approach builds on treating samples from other distributions as anomalies during training. The idea is that the synthetic anomalies can be used to guide learning a tighter decision boundary around the normal data . Drawing on the notation from Eq. 1, we thus simulate a mixture distribution by contaminating each \(P_{j}\) by admixing a fraction \((1-) 1\) of data from other available training distributions. The resulting corrupted distribution \(P_{j}^{}\) is thereby

\[P_{j}^{}:= P_{j}+(1-)_{j},_{j}:= _{i j}P_{i}\] (6)

This notation captures the case where the training distribution is free of anomalies (\(=1\)).

Next, we discuss constructing an additional loss for the admixed anomalies, whose identity is known at training time. As discussed in [30; 58], many anomaly scores \(_{}(_{})\) allow for easily constructing a score \(_{}(_{})\) that behaves inversely. That means, we expect \(_{}(_{})\) to be _large_ when evaluated on normal samples, and small for anomalies. Importantly, both scores share the same parameters. In the context of DSVDD, we define \(_{}(_{})=1/_{}(_{})\), but other definitions are possible for alternative losses [58; 63; 64]. Using the inverse score, we can construct a supervised AD loss on the meta training set as follows.

We define a binary indicator variable \(y^{i}_{j}\), indicating whether data point \(i\) is normal or anomalous in the context of distribution \(P_{j}\) (i.e., \(y^{i}_{j}=0\) iff \(^{i}_{} P_{j}\)). We later refer to it as _anomaly label_. A natural choice for the loss in Eq. (5) is therefore

\[L[_{}(_{})]=_{i }\{(1-y^{i})^{i}_{}(_{})+y^{ i}^{i}_{}(_{})\}.\] (7)

The loss function resembles the outlier exposure loss , but as opposed to using synthetically generated samples (typically only available for images), we use samples from the complement \(_{j}\) at training time to synthesize outliers. The training pseudo-code is in Alg. 1 of Supp. C.

In addition to DSVDD, we also study backbone models such as binary classifiers and NTL . For NTL, we adopt the \(_{}\) and \(_{}\) used by Qiu et al. . For binary classifiers, we set \(_{}()=-(1-(f_{}()))\) and \(_{}()=-(f_{}())\).

Batch-level Prediction.After training, we deploy the model in an unseen production environment to detect anomalies in a zero-shot adaptive fashion. Similar to the training set, the distribution will be a mixture of new normal samples \(P_{*}\) and an admixture of anomalies from a distribution never encountered before. For the method to work, we still assume that the majority of samples be normal (Assumption A3). Anomaly scores are assigned based on batches, as during training. For prediction, the anomaly scores are thresholded at a user-specified value.

Time complexity for prediction depends on the network complexity and is constant \(O(1)\) relative to batch size, because the predictions can be trivially parallelized via modern deep learning libraries.

### Theoretical Results

Having described our method, we now establish a theoretical basis for ACR by deriving a bounded generalization error on an unseen test distribution \(P_{*}\). We define the generalization error in terms of training and testing losses, i.e., we are interested in whether the expected loss generalizes from the meta-training distributions \(P_{1},,P_{K}\) to an unseen distribution \(P_{*}\).

To prepare the notations, we split \(S_{}()\) into two parts: a feature extractor \(=f_{}()\) that spans from the input layer to the last batch norm layer and that performs batch normalization, and an anomaly score \(S()\) that covers all the remaining layers. We use \(P^{z}_{j}\) to denote the data distribution \(P_{j}\) transformed by the feature extractor \(f_{}\). We assume that \(P^{z}_{j}\) satisfies \(_{ P^{z}_{j}}[]=0\) and \(_{ P^{z}_{j}}[]=1\) for \(j=1,,K,*\) because \(f_{}\) ends up with a batch norm layer.

**Theorem 2.1**.: _Assume the mini-batches are large enough such that, for batches from each given distribution \(P_{j}\), the mini-batch means and variances are approximately constant across batches. Furthermore, assume the loss function \(L[S()]\) is bounded by \(C\) for any \(\). Let \(\|\|_{TV}\) denote the total variation. Then, the generalization error is upper bounded by_

\[|_{_{} P_{*}}[_{i=1 }^{B}L[S^{i}_{}(_{})]]-_{j=1}^ {K}_{_{} P_{j}}[_{i=1}^ {B}L[S^{i}_{}(_{})]]| C\|P^{z}_ {*}-_{j=1}^{K}P^{z}_{j}\|_{TV}.\]

The proof is shown in Supp. B. Note that Thm. 2.1 still holds if \(P_{j}\) or \(P_{*}\) are contaminated distributions \(P^{}_{j}\) or \(P^{}_{*}\).

Remark.Thm. 2.1 suggests that the generalization error of the expected loss function is bounded by the total variation distance between \(P^{z}_{*}\) and \(_{j=1}^{K}P^{z}_{j}\). While we leave a formal bound of the TV distance to future studies, the following intuition holds: since \(f_{}\) contains batch norm layers, the empirical distributions \(_{j=1}^{K}P^{z}_{j}\) and \(P^{z}_{*}\) will share the same (zero) mean and (unit) variance. If both distributions are dominated by their first two moments, we can expect the total variation distance to be small, providing an explanation for the approach's favorable generalization performance.

Related Work

Deep AD.Many recent advances in AD are built on deep learning methods  and early strategies used autoencoder [9; 55; 85] or density-based [13; 66] models. Another pioneering stream of research combined one-class classification  with deep learning [57; 63]. Many other approaches to deep AD are self-supervised, employing a self-supervised loss function to train the detector and score anomalies [4; 23; 31; 44; 56; 68; 72; 75].

All of these approaches assume that the data distribution will not change too much at test time. However, in many practical scenarios, there will be significant shifts in the abnormal distribution and even the normal distribution. For example, Dragoi et al.  observed that existing AD methods fail in detecting anomalies when distribution shifts occur in network intrusion detection. Another line of work in this context requires test-time modeling for the entire test set, e.g., COPOD , ECOD , and robust autoencoder , preventing real-time deployment.

Few-shot AD.Several recent works have studied adapting an anomaly detector to shifts by fine-tuning a few test samples. One stream of research applies model-agnostic meta learning (MAML)  to various deep AD models, including one-class classification , generative adversarial networks , autoencoder , graph deviation networks , and supervised classifiers [20; 84]. Some approaches extend prototypical networks to few-shot AD [8; 40]. Kozerawski and Turk  learn a linear SVM with a few samples on top of a frozen pre-trained feature extractor, while Sheynin et al.  learn a hierarchical generative model from a few normal samples for image AD. Wang et al.  learn an energy model for AD. The anomalies are scored by the error of reconstructing their embeddings from a set of normal features that are adapted with a few test samples. Huang et al.  learn a category-agnostic model with multiple training categories (a meta set). At test time, a few normal samples from a novel category are used to establish an anomaly detector in the feature space. Huang et al.  does not exploit the presence of a meta-set to learn a stronger anomaly detector through synthetic outlier exposure. While meta-training for object-level anomaly detection (e.g., ) is generally simpler (it is easy to find anomaly examples, i.e., other objects different from the normal one), meta-training for anomaly segmentation (e.g., ) poses a harder task since image defects may differ from object to object (e.g., defects in transistors may not easily generalize to subtle defects in wood textures). Our experiments found that using images from different distributions as example anomalies during training is helpful for anomaly segmentation on MVTec-AD (see Supp. I.5).

In contrast to all of the existing few-shot AD methods, we propose a zero-shot AD method and demonstrate that the learned AD model can adapt itself to new tasks without any support samples.

Zero-shot AD.Foundation models pre-trained on massive training samples have achieved remarkable results on zero-shot tasks on images [37; 59; 82; 83]. For example, contrastive language-image pre-training (CLIP)  is a pre-trained language-vision model learned by aligning images and their paired text descriptions. One can achieve zero-shot image classification with CLIP by searching for the best-aligned text description of the test images. Esmaeilpour et al.  extend CLIP with a learnable text description generator for out-of-distribution detection. Liznerski et al.  apply CLIP for zero-shot AD and score the anomalies by comparing the alignment of test images with the correct text description of normal samples. In terms of anomaly segmentation, Trans-MM  is an interpretation method for Transformer-based architectures. Trans-MM uses the attention map to generate pixel-level masks of input images, which can be applied to CLIP. MaskCLIP  directly exploits CLIP's Transformer layer potential in semantic segmentation to generate pixel-level predictions given class descriptions. MAEDAY  uses the reconstruction error of a pre-trained masked autoencoder  to generate anomaly segmentation masks. WinCLIP , again using CLIP, slides a window over an image and inspects each patch to detect local defects defined by text descriptions.

However, foundation models have two constraints that do not exist in ACR. First, foundation models are not available for all data types. Foundation models do not exist for example for tabular data, which occurs widely in practice, for example in applications such as network security and industrial fault detection. Also, existing adaptations of foundation models for AD (e.g., CLIP) may generalize poorly to specific domains that have not been covered in their massive training samples. For example, Liznerski et al.  observed that CLIP performs poorly on non-natural images, such as MNIST digits. In contrast, ACR does not rely on a powerful pre-trained foundation model, enabling zero-shot AD on various data types. Second, human involvement is required for foundation models. While previous pre-trained CLIP-based zero-shot AD methods adapt to new tasks through informative prompts given by human experts, our method enriches the zero-shot AD toolbox with a new adaptation strategy without human involvement. Our approach allows the anomaly detector to infer the new task/distribution based on a mini-batch of samples.

Connections to Other Areas.Our problem setup and assumptions share similarities with other research areas but differences are also pronounced. Those areas include _test-time adaptation_[10; 49; 53; 67; 76], _unsupervised domain adaptation_, _zero-shot classification_, _meta-learning_, and _contextual AD_. Supp. H details the connections, similarities, and differences.

## 4 Experiments

We evaluate the proposed method ACR on both image (detection/segmentation) and tabular data, where distribution shifts occur at test time. We compare ACR with established baselines based on deep AD, zero-shot AD, and few-shot AD methods. The experiments show that our method is suitable for different data types, applicable to diverse AD models, robust to various anomaly ratios, and significantly outperforms existing baselines. We report results on image and tabular data in Sec. 4.1 and Sec. 4.2, and ablation studies in Sec. 4.3. Results on more datasets are in Supps. I.3 to I.6.

### Experiments on Images

Visual AD consists of two major tasks: (image-level) anomaly detection and (pixel-level) anomaly segmentation. The former aims to accurately detect images of abnormal objects, e.g., detecting non-dog images; the latter focuses on detecting pixel-level local defects in an image, e.g., marking board wormholes. We test our method on both tasks and compare it to existing SOTA methods.

#### 4.1.1 Anomaly Detection

We evaluate ACR on images when applied to two simple backbone models: DSVDD  and a binary classifier. Our method is trained from scratch. The evaluation demonstrates that ACR achieves superior AD results on corrupted natural images, medical images, and other non-natural images.

**Datasets.** We study four image datasets: CIFAR100-C , OrganA  (and MNIST , and Omniglot  in Supp. I.4). We consider CIFAR100-C is the noise-corrupted version of CIFAR100's test data, thus considered as distributionally shifted data. We train using all training images from original CIFAR100 and test all models on CIFAR100-C. OrganA is a medical image dataset with 11 classes (for various body organs). We leave two successive classes out for testing and use the other classes for training. We repeat the evaluation on all combinations of two consecutive classes. Across all experiments, we apply the "one-vs-rest" setting at test time, i.e., one class is treated as normal, and all the other classes are abnormal . We report the results averaged over all combinations.

**Baselines.** We compare our proposed method with a SOTA stationary deep anomaly detector (anomaly detection with an inductive bias (ADIB) ), a pre-trained classifier used for batch-level zero-shot AD (ResNet152 ), a SOTA zero-shot AD baseline (CLIP-AD ), and a few-shot AD baseline (one-class model-agnostic meta learning (OC-MAML) ). ResNet152-I and ResNet152-II differ in the which statistics they use in batch normalization: ResNet152-I uses the statistics from training and ResNet152-II uses the input batch's statistics. See Supp. E for more details.

**Implementation Details.** We set \(=0.8\) in Eq. (6) to apply Meta Outlier Exposure. For each approach, we train a single model and test it on different anomaly ratios. Two backbone models are implemented: DSVDD  (ACR-DSVDD) and a binary classifier with cross entropy loss (ACR-BCE). More details are given in Supp. F.

**Results.** We report the results in terms of the AUROC averaged over five independent test runs with standard deviation. We apply the model to tasks with different anomaly ratios to study the robustness of ACR to the anomaly ratio at test time. Our method ACR significantly outperforms all baselines on Gaussian noise-corrupted CIFAR100-C and OrganA in Tab. 1. In Tabs. 8 and 9 in Supp. I, we systematically evaluate all methods on all 19 corrupted versions of CIFAR100 and on non-nature images (MNIST, Omniglot). The results show that on _non-natural_ images (OrganA, MNIST, Omniglot) ACR performs the best among all compared methods, including the large pre-trained CLIP-AD baseline; on corrupted _natural_ images (CIFAR-100C), ACR achieves results competitive with CLIP-AD and significantly outperforms other baselines. ACR is also robust on various anomaly ratios: without any (hyper)parameter tuning, the results are consistent and don't vary over 3%. The deep AD baseline, ADIB, doesn't have adaptation ability and thus fails to perform the testing tasks, leading to random guess results. Pre-trained ResNet152 armed with batch normalization layers can adapt but with limited ability, which is in contrast with our method that directly learns to adapt. Few-shot OC-MAML suffers because it requires a large support set at test time to achieve adaptation effectively. CLIP-AD has a strong performance on corrupted natural images but struggles with non-natural images, presumably because it is trained on massive natural images from the internet.

#### 4.1.2 Anomaly Segmentation

We benchmark our method ACR on the MVTec AD dataset  in a zero-shot setup. Experiments show that ACR achieves new state-of-the-art anomaly segmentation performance.

**Datasets.** MVTec AD comprises 15 classes of images for industrial inspection. The goal is to detect the local defects accurately. To implement our method for zero-shot anomaly segmentation tasks, we train on the training sets of all classes except the target one and test on the test set of the target class. For example, when segmenting wormholes on wood boards, we train a model on the other 14 classes' training data except for wood and later test on wood test set. This satisfies the zero-shot definition as the model doesn't see any wood data during training. We apply this procedure for all classes.

**Baselines.** We compare our method to four zero-shot anomaly segmentation baselines: Trans-MM , MaskCLIP , MAEDAY , and WinCLIP . The details are described in Sec. 3. We report their results listed in Jeong et al. , Schwartz et al. .

**Implementation Details.** We first extract informative texture features using a sliding window, which corresponds to 2D convolutions. The convolution kernel is instantiated with the ones in a pre-trained ResNet. We follow the same data pre-processing steps of Cohen and Hoshen , Defard et al. , Rippel et al.  to extract the features (the third layer's output in our case) of WideResNet-50-2 pre-trained on ImageNet. Second, we detect anomalies in the extracted features in each window position with our ACR method. Specifically, each window position corresponds to one image patch. We stack into a batch the patches taken from a set of images that all share the same spatial position. For example, we may stack the top-left patch of all testing wood images into a batch and use ACR to detect anomalies in that batch. Finally, the window-wise anomaly scores are bilinearly interpolated to the original image size to get the pixel-level anomaly scores. In implementing meta outlier exposure, we tried two sources of outliers: one is noise-corrupted images, and the other is images of other classes. We report results of the former in the main paper and the latter in Supp. I.5. More implementation details are given in Supp. F.

**Results.** Similar to common practice, we report both the pixel-level and image-level results in Tab. 2. We use the largest pixel-level anomaly score as the image-level score. All methods are evaluated with

    &  &  \\   & 1\% & 5\% & 10\% & 20\% & 1\% & 5\% & 10\% \\  ADIB  & 50.9\(\)2.4 & 50.5\(\)0.9 & 50.6\(\)0.9 & 50.2\(\)0.5 & 49.9\(\)6.3 & 50.3\(\)2.4 & 50.2\(\)1.3 \\ ResNet152-1  & 75.6\(\)2.3 & 73.2\(\)1.3 & 73.2\(\)0.8 & 69.9\(\)0.6 & 54.2\(\)1.1 & 53.9\(\)0.5 & 53.2\(\)0.6 \\ ResNet152-II  & 62.5\(\)3.1 & 61.8\(\)1.7 & 61.2\(\)0.6 & 60.2\(\)0.4 & 54.2\(\)1.7 & 53.5\(\)0.8 & 52.9\(\)0.3 \\ OC-MAML  & 53.0\(\)3.6 & 54.1\(\)1.9 & 55.8\(\)0.6 & 57.1\(\)1.0 & 73.7\(\)4.7 & 72.2\(\)2.6 & 74.2\(\)2.4 \\ CLIP-AD  & 82.3\(\)1.1 & 82.6\(\)0.9 & 82.3\(\)0.9 & 82.6\(\)0.1 & 52.6\(\)0.8 & 51.9\(\)0.6 & 51.5\(\)0.2 \\  ACR-DSVD (ours) & **87.7\(\)1.4** & **86.3\(\)0.9** & **85.9\(\)0.4** & **85.6\(\)0.4** & 79.0\(\)1.0 & 77.7\(\)0.4 & 76.3\(\)0.3 \\ ACR-BCE (ours) & **84.3\(\)**2.2 & **86.0\(\)0.3** & **86.0\(\)0.2** & **85.7\(\)0.4** & **81.1\(\)0.8** & **79.5\(\)0.4** & **78.3\(\)0.3** \\   

Table 1: AUC (\(\%\)) with standard deviation for anomaly detection on CIFAR100-C with Gaussian noise  and medical image dataset, OrganA. ACR with both backbone models perform best.

    & MAEDAY  & CLIP  & Trans-MM  & MaskCLIP  & WinCLIP  & ACR (ours) \\  pixel-level & 69.4 & - & 57.5\(\)0.0 & 63.7\(\)0.0 & 85.1\(\)0.0 & **92.5\(\)0.2** \\ image-level & 74.5 & 74.0\(\)0.0 & - & - & **91.8\(\)0.0** & 85.8\(\)0.6 \\   

Table 2: Pixel-level and image-level AUC (\(\%\)) on MVTec AD. On average, our method outperforms the strongest baseline WinCLIP by 7.4% AUC in pixel-level anomaly segmentation.

the AUROC metric. It shows that 1) our method is competitive to the SOTA method in image-level detection tasks, and 2) it surpasses the best baseline WinCLIP by a large margin (7.4% AUC on average) in anomaly segmentation tasks, achieving a new SOTA performance and testifying the potential of our method. We report class-wise results in Supp. I.5.

### Experiments on Tabular Data

Tabular data is an important data format in many real-world AD applications, e.g, network intrusion detection and malware detection. Distribution shifts in such data occur naturally over time (e.g., as new malware emerges) and grow over time. Existing zero-shot AD approaches [36; 51] are not applicable to tabular data. We evaluate ACR on tabular AD when applied to DSVDD and NTL. ACR achieves a new SOTA of zero-shot AD performance on tabular data with temporal distribution shifts.

**Datasets.** We evaluate all methods on two real-world tabular AD datasets Anoshift  and Malware  where data shifts over time. Anoshift is a data traffic dataset for network intrusion detection collected over ten years (2006-2015). We follow the preprocessing procedure and train/test split suggested in Dragoi et al. . We train the model on normal data collected from 2006 to 2010 5, and test on a mixture of normal and abnormal samples (with anomaly ratios varying from \(1\%\) to \(20\%\)) collected from 2011 to 2015. We also apply similar protocols on Malware , a dataset for detecting malicious computer programs, and provide details in Supp. I.6.

**Baselines.** We compare with state-of-the art deep and shallow detectors for tabular AD [2; 17; 26] and study their performance under test distribution shifts. The shallow AD baselines include OCSVM , IForest , LOF , and KNN . The deep AD baselines include DSVDD , Autoencoder (AE) , LUNAR , internal contrastive learning (ICL) , NTL , and BERT-AD . We adopt the implementations from PyOD  or their official repositories.

**Implementation Details.** To formulate meta-training sets, we bin the data against their timestamps (year for Anoshift and month for Malware) so each bin corresponds to one training distribution \(P_{j}\). The training tasks are mixed with normality ratio \(=0.8\). To create more training tasks, we augment the data using attribute permutations, resulting in additional training distributions. These attribute permutations increase the variability of training tasks and encourage the model to learn permutation-invariant features. At test time, the attributes are not permuted. Details are in Supp. F.

**Results.** In Tab. 3, we report the results on Anoshift split into AVG (data from 2011 to 2015) and FAR (data from 2014 and 2015). The two splits show how the performance degrades from average (AVG) to when strong distribution shifts happen after a long time interval (FAR). The results of Malware with varying ratios are in Tab. 12 and Supp. I.6. We report average AUC with standard deviation over five independent test runs. The results on Anoshift and Malware show that ACR outperforms all baselines on all distribution-shifted settings. Remarkably, ACR is the only method

    &  &  &  &  \\   & FAR & AVG & FAR & AVG & FAR & AVG & FAR & AVG \\  OC-SVM  & 49.6\(\)0.2 & 62.6\(\)0.1 & 49.6\(\)0.2 & 62.6\(\)0.1 & 49.5\(\)0.1 & 62.7\(\)0.1 & 49.5\(\)0.1 & 62.6\(\)0.1 \\ IForest  & 25.8\(\)0.4 & 54.6\(\)0.2 & 26.1\(\)0.1 & 54.7\(\)0.1 & 26.0\(\)0.1 & 54.6\(\)0.1 & 26.0\(\)0.1 & 54.7\(\)0.1 \\ LOF  & 37.3\(\)0.5 & 59.6\(\)0.3 & 37.0\(\)0.1 & 59.5\(\)0.1 & 37.0\(\)0.1 & 59.5\(\)0.1 & 37.1\(\)0.1 & 59.5\(\)0.1 \\ KNN  & 45.0\(\)0.3 & 70.8\(\)0.1 & 45.3\(\)0.2 & 70.9\(\)0.1 & 45.1\(\)0.1 & 70.8\(\)0.1 & 45.2\(\)0.1 & 70.8\(\)0.1 \\  DSVDD  & 34.6\(\)0.3 & 62.3\(\)0.2 & 34.7\(\)0.1 & 62.5\(\)0.1 & 34.7\(\)0.2 & 62.5\(\)0.1 & 34.7\(\)0.1 & 62.5\(\)0.1 \\ AE  & 18.6\(\)0.2 & 25.3\(\)0.1 & 18.7\(\)0.2 & 25.5\(\)0.1 & 18.7\(\)0.1 & 25.5\(\)0.1 & 18.7\(\)0.1 & 25.5\(\)0.1 \\ LUNAR  & 24.5\(\)0.4 & 38.3\(\)0.4 & 24.6\(\)0.1 & 38.6\(\)0.2 & 24.7\(\)0.1 & 38.7\(\)0.1 & 24.6\(\)0.1 & 38.6\(\)0.1 \\ ICL  & 20.6\(\)0.3 & 50.5\(\)0.2 & 20.7\(\)0.2 & 50.4\(\)0.1 & 20.7\(\)0.1 & 50.4\(\)0.1 & 20.8\(\)0.1 & 50.4\(\)0.1 \\ NTL  & 40.7\(\)0.3 & 57.0\(\)0.1 & 40.9\(\)0.2 & 57.1\(\)0.1 & 41.0\(\)0.1 & 57.1\(\)0.1 & 41.0\(\)0.1 & 57.1\(\)0.1 \\ BERT-AD & 28.6\(\)0.3 & 64.6\(\)0.2 & 28.7\(\)0.1 & 64.6\(\)0.1 & 28.7\(\)0.1 & 64.6\(\)0.1 & 28.7\(\)0.1 & 64.7\(\)0.1 \\  ACR-DSVDD (ours) & 62.0\(\)0.5 & **74.0\(\)0.2** & 61.3\(\)0.1 & **73.3\(\)0.1** & 60.4\(\)0.1 & 72.5\(\)0.1 & 59.1\(\)0.1 & 71.2\(\)0.1 \\ ACR-NTL (ours) & **62.5\(\)0.2** & 73.4\(\)0.1 & **62.2\(\)0.1** & **73.2\(\)0.1** & **62.3\(\)0.1** & **73.1\(\)0.1** & **62.0\(\)0.1** & **72.7\(\)0.1** \\   

Table 3: AUC (\(\%\)) with standard deviation for anomaly detection on Anoshift with different anomaly contamination rations (1% - 20%) and on different splitting strategies AVG and FAR . ACR with either backbone model outperforms all baselines. Especially, under the distribution shift occuring in the FAR split, ACR is the only method that is significantly better than random guessing.

that clearly outperforms random guessing on shifted datasets (the FAR split in Anoshift and the test split in Malware). All baselines perform worse than random on shifted test sets even though they achieve strong results when there are no distribution shifts (see results in Alvarez et al. , Dragoi et al. , Han et al. ). This worse-than-random phenomenon is also verified in the benchmark paper AnoShift . The reason is that in cyber-security applications (e.g., Anoshift and Malware), the attacks evolve adversarially. The anomalies (cyber attacks) are intentionally updated to be as similar to the normal data to spoof the firewalls. That's why static AD methods like KNN flip their predictions during test time and achieve worse than random performance. In terms of robustness, although ACR-DSVDD's performance degrades a little (within 3%) when the anomaly ratio increases, ACR-NTL is fairly robust to high anomaly ratios. The degradation is attributed to the fact that the majority of normal samples get blurred as the anomaly ratio increase, leading to noisy batch statistics.

### Ablation Studies

We perform several ablation studies in Supp. I.1, including 1) demonstrating the benefit of the Meta Outlier Exposure loss, 2) studying the effect of batch normalization, and 3) analyzing the effects of the batch sizes and the number of meta-training classes. To show that Meta Outlier Exposure is a favorable option, we compare it against the one-class classification loss and a fine-tuned version of ResNet152 on domain-specific training data. Tab. 4 shows that our approach outperforms the two alternatives on two image datasets. To analyze the effect of batch normalization, we adjust batch normalization usage during training and testing listed in Tab. 5. More details and the studies on the batch size, the number of meta-training classes, other normalization techniques (LayerNorm, InstanceNorm, and GroupNorm), effects of batch norm position, and robustness of the mixing hyperparameter \(\) can be found in Supp. I.1.

## 5 Conclusion

We studied the problem of adapting a learned AD method to a new data distribution, where the concept of "normality" changed. Our method is a zero-shot approach and requires no training or fine-tuning to a new data set. We developed a new meta-training approach, where we trained an off-the-shelf deep AD method on a (meta-) set of interrelated datasets, adopting batch normalization in every layer, and used samples from the meta set as either normal samples and anomalies, depending on the context. We showed that the approach robustly generalized to new, unseen anomalies.

Our experiments on image and tabular data demonstrated superior zero-shot adaptation performance when no foundation model was available. We stress that this is an important result since many, if not most AD applications in the real world rely on specialized datasets: medical images, data from industrial assembly lines, malware data, network intrusion data etc. Existing foundation models often do not capture these data, as we showed. Ultimately, our analysis shows that relatively small modifications to model training (meta-learning, batch normalization, and providing artificial anomalies from the meta-set) will enable the deployment of existing models in zero-shot AD tasks.

Limitations & Societal ImpactsOur method depends on the three assumptions listed in Sec. 2. If those assumptions are broken, zero-shot adaptation cannot be assured.

Anomaly detectors are trained to detect atypical/under-represented data in a data set. Therefore, deploying an anomaly detector, e.g., in video surveillance, may ultimately discriminate against under-represented groups. Anomaly detection methods should therefore be critically reviewed when deployed on human data.