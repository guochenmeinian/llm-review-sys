# Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics Alignment with Diffusion Models

Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics Alignment with Diffusion Models

Yule Wang

Georgia Institute of Technology

Atlanta, GA, 30332 USA

yulewang@gatech.edu

&Zijing Wu

Georgia Institute of Technology

Atlanta, GA, 30332 USA

zwu381@gatech.edu

&Chengrui Li

Georgia Institute of Technology

Atlanta, GA, 30332 USA

cnlichengrui@gatech.edu

&Anqi Wu

Georgia Institute of Technology

Atlanta, GA, 30332 USA

anqiwu@gatech.edu

###### Abstract

In the field of behavior-related brain computation, it is necessary to align raw neural signals against the drastic domain shift among them. A foundational framework within neuroscience research posits that trial-based neural population activities rely on low-dimensional latent dynamics, thus focusing on the latter greatly facilitates the alignment procedure. Despite this field's progress, existing methods ignore the intrinsic spatio-temporal structure during the alignment phase. Hence, their solutions usually lead to poor quality in latent dynamics structures and overall performance. To tackle this problem, we propose an alignment method ERDiff, which leverages the expressivity of the diffusion model to preserve the spatio-temporal structure of latent dynamics. Specifically, the latent dynamics structures of the source domain are first extracted by a diffusion model. Then, under the guidance of this diffusion model, such structures are well-recovered through a maximum likelihood alignment procedure in the target domain. We first demonstrate the effectiveness of our proposed method on a synthetic dataset. Then, when applied to neural recordings from the non-human primate motor cortex, under both cross-day and inter-subject settings, our method consistently manifests its capability of preserving the spatio-temporal structure of latent dynamics and outperforms existing approaches in alignment goodness-of-fit and neural decoding performance. Codes are available at: [https://github.com/alexwangNTL/ERDiff](https://github.com/alexwangNTL/ERDiff).

## 1 Introduction

A key challenge severely impeding the scalability of behavior-related neural computational applications is their robustness to the distribution shift of neural recordings over time and subjects . Given a behavior model trained on previous neural recordings (e.g., velocity predictor for human with paralysis ), it usually suffers performance degradation when applied to new neural recordings due to the neural distribution shift . Thus, for long-term usability and stable performance of the trained neural decoding model, high-quality alignment between the neural recordings used for training (i.e., source domain) and new recordings for testing (i.e., target domain) is of vital importance.

Distribution alignment is an important task at the heart of unsupervised transfer learning . The goal is to align the target domain to the source domain so that the trained model in the source domain can be applied to the target domain after eliminating the distribution shift. However, due to issues such as instabilities and low signal-to-noise ratio , raw neural spiking activities are noisy and ambiguous , causing difficulties in aligning the distributions of these high-dimensional signals directly.

One promising research direction  points out that the trial-based neural activities can always be understood in terms of low-dimensional latent dynamics [11; 12; 13]. Such latent dynamics manifest coordinated patterns of evolution constrained to certain "neural manifolds" [14; 15]. Hence, early studies focusing on the alignment of latent dynamics reach comparably satisfactory results [16; 17]. Generally, most previous methods [16; 18; 19] are based on a pre-defined metric for optimization during latent dynamics alignment, i.e., minimizing the difference evaluated by the metric, between source and target domains within the low-dimensional latent space. However, those metrics are usually non-parametric and handcrafted, which are not guaranteed to suit specific neural recordings or problems well. Methods based on adversarial-learning [20; 21] thus have been introduced since they can implicitly find an adapted metric . However, they suffer from mode collapse and instability issues in practice .

Moreover, during the alignment process, we note that the above-mentioned works lack the necessary awareness of the latent dynamics structure, especially when aligning non-linear and lengthy trials. Through an empirical study on the motor cortex of non-human primate (NHP)  (shown in Figure 1), we can observe that: a state-of-the-art alignment method JSDM  (minimizing the symmetric Jensen-Shannon divergence between distributions) fails to recover the latent dynamics structures of the source domain since JSDM neglects those structures during alignment. From another perspective, in the alignment phase, existing methods fail to effectively model and leverage the information-rich correlations between each time bin and each latent dimension within latent dynamics.

In this paper, we focus on preserving the _temporal evolution_ of each individual latent dimension and the _spatial covariation_ between latent dimensions of the source domain during alignment. The main idea is that we first extract the spatio-temporal structure of latent dynamics from the source domain; and then, we align the target domain by recovering the source domain's underlying structure. However, such a workflow is non-trivial since the underlying spatio-temporal structure is both implicit and complex.

To tackle this problem, we propose a novel alignment method that is capable of _E_xtracting and _R_ecovering the latent dynamics structure with _Diff_ vision model (ERDiff). Firstly, given the source-domain neural observations, we use a diffusion model (DM) [25; 26] to extract the spatio-temporal structure of latent dynamics. Then, in the alignment phase, we propose a maximum likelihood alignment procedure through the guidance of DM, by which the spatio-temporal structure of source-domain latent dynamics can be recovered well in the target domain. The proposed extract-and-recover method nicely encodes and preserves the spatio-temporal structure of latent dynamics, which are significant inductive biases for neural latent dynamics alignment. Furthermore, from the perspective of core machine learning, ERDiff introduces an approach of extracting structure knowledge from one distribution and imposing it as the prior to constrain the alignment of another distribution. Note that although we have been emphasizing extraction and recovery of the source-domain structure, ERDiff is not performing a copy-and-paste of the source domain distribution to the target domain. As ERDiff preserves the dynamics structure of the source domain, it also maintains the original characteristics of the target domain. We present experimental results to support this argument. Finally, we conduct extensive experiments to verify the effectiveness of ERDiff on a synthetic dataset and two real-world neural datasets [8; 27]. Visualization of latent dynamics also demonstrates that ERDiff is capable of preserving the spatio-temporal structure consistently during the alignment phase.

## 2 Preliminary

**Distribution alignment.** We denote the source-domain observations of single-trial neural population activities as \(^{(s)}=[^{(s)}_{1},,^{(s)}_{l}] ^{}^{l n}\), where \(l\) is the trial length (_i.e._, number of time bins), and \(n\) is the number of observed neurons. We denote its low-dimensional latent dynamics as \(^{(s)}=[^{(s)}_{1},,^{(s)}_{l}] ^{}^{l d}\), where \(d\) is the latent dimension size. Generally, we build a variational autoencoder (VAE) to estimate the latent \(^{(s)}\) given the observations \(^{(s)}\). The VAE

Figure 1: **Empirical study**. Latent dynamics (3D visualization) of the source domain and the aligned target domain by JSDM on a primary motor cortex dataset.

consists of a probabilistic encoder \(q(^{(s)}^{(s)};_{s})\) and a probabilistic decoder \(p(^{(s)}|^{(s)},_{s})\). \(_{s}\) and \(_{s}\) are the parameters of the encoder and decoder. The encoder also serves as an approximated posterior distribution to the intractable true posterior \(p(^{(s)}^{(s)})\). Then in the target domain, given the neural population activities \(^{(t)}=[^{(t)}_{1},,^{(t)}_{l}] ^{}^{l n}\), we perform distribution alignment by linear probing the probabilistic encoder \(q(;)\). This alignment phase is conducted by minimizing certain probability divergence \(()\) between the two posterior distributions:

\[_{_{t}}(q(^{(s)}^{(s)};_{s} ))\|q(^{(t)}^{(t)};_{t})). \]

**Diffusion (probabilistic) model (DM).** Given \(l d\)-dimensional i.i.d. samples \(\) from an unknown data distribution, a DM  aims to approximate such distribution by fitting the parameters of a neural network \(p_{}()\). DM is composed of a _forward process_ followed by a _reverse process_. In the _forward process_, isotropic Gaussian noise is added to diffuse the original data, which can be defined in a linear stochastic differential equation (SDE) form:

\[=(,t)t+g(t), \]

where \(():^{l d}^{l d}\) is the drift coefficient, \(g():\) is the diffusion coefficient, and \(\) is the standard Wiener process. The solution of the SDE is a diffusion process \(\{_{t}\}_{t[0,T]}\), in which \([0,T]\) is a fixed time zone. In this paper, we implement them with VP-SDE . \(\{_{t}\}_{t[0,T]}\) approaches the standard normal prior distribution \(()\) when \(t=T\). Under mild conditions on drift and diffusion coefficients , the denoising _reverse process_ can be solved in the following closed-form SDE:

\[=[(,t)-g(t)^{2}_{}  p_{t}()]t+g(t)}, \]

where \(_{} p_{t}()\) is the score function, and \(}\) is a reverse-time Wiener process. We train a parameterized network \((,t;)\) to fit the score function \(_{} p_{t}()\). However, \(_{} p_{t}()\) is not directly accessible and we resort to the denoising score matching (DSM)  for optimization:

\[_{}()=_{t[0,T]} _{_{0} p,p_{0t}(_{t}|_{0})}[ (t)^{2}\|_{_{t}} p_{0t}(_{t} _{0})-(_{t},t;)\|_{2}^{2}], \]

where \(\) represents the uniform distribution and \((t)\) is the weighting function. Under VP-SDE, the transition probability \(p_{0t}(_{t}_{0})\) also follows a Gaussian distribution \((_{t}_{0},_{t})\), in which \(_{t},_{t}^{l d}\). On the other hand, according to , we can define a noise estimator with the score function as \((_{t},t;)=-_{t}^{-T}(_ {t},t;)\), in which \(_{t}_{t}^{T}=_{t}\). Invoking these expressions, we can thus reformulate the form of DSM loss based on the Fisher Divergence between noise terms:

\[_{}()=_{t[0,T]} _{_{0} p,(0,_{l  d})}[w(t)^{2}\|-(_{t},t; )\|_{2}^{2}], \]

in which \(w(t)=_{t}(t)\) and \(_{t}=_{t}_{0}+_{t}\).

## 3 Methodology

In this section, we introduce our proposed latent dynamics alignment method ERDiff in detail.

### Maximum likelihood alignment

Given the source-domain neural activities \(^{(s)}\), we infer their latent dynamics \(^{(s)}\) by building a VAE. We use variational inference to find the probabilistic encoder \(q(^{(s)}^{(s)};_{s})\) and probabilistic decoder \(p(^{(s)}^{(s)};_{s})\) through maximization of the evidence lower bound (ELBO) :

\[_{s},_{s}=*{argmax}_{,}[ _{q(^{(s)}^{(s)};)}[ p( ^{(s)}^{(s)};)]-_{} (q(^{(s)}^{(s)};)\|(^{ (s)}))], \]

in which \((^{(s)})\) is the normal prior. Note that we introduce ERDiff with this basic VAE architecture. But ERDiff can be combined with many variants of latent variable models (LVM) [31; 32]. The essence of ERDiff is to tune the parameter set \(\) of the probabilistic encoder, regardless of the model architecture of the encoder and decoder.

Practically, alignment methods that directly match the discrete samples from the source and target domains in a pair-wise fashion may lead to sub-optimal solutions , especially when the collected samples from the target domain are limited. Thus given the target-domain neural activity \(^{(t)}\), we propose to perform neural distribution alignment via maximum likelihood estimation (MLE):

\[*{argmax}_{}_{ p(^{(t) })}[ p_{s}(h(;))]=*{ argmax}_{}_{ q(|^{(t)};)}[ p_{s}()], \]

in which \(p_{s}()\) represents the ground-truth probabilistic density of latent dynamics in the source domain and \(h()\) refers to the non-linear transformation from \(\) to \(\) underlying the probabilistic encoder \(q(;)\). The objective in Eq. 7 implies that, instead of minimizing a distance metric between source observations and target observations, we aim at maximizing the likelihood where the density comes from the source domain and the data comes from the target domain. The left-hand-side (LHS) is the MLE for observation \(\) and the right-hand-side (RHS) is the MLE for latent \(\). We will focus on the RHS in the following sections. We note that the RHS objective implies that we will optimize the encoder parameter \(\) during alignment so that the latent encoder will map \(^{(t)}\) to a proper latent \(^{(t)}\) who fits the source density \(p_{s}()\) well.

### Spatio-temporal structure extraction and source domain learning

In order to calculate the objective function in Eq. 7, we need to know two density functions: \(q(;)\) is defined in the original VAE model with the learnable parameter \(\); \(p_{s}()\) is the density of latent \(\) for the source domain. The latter is inaccessible by building a VAE alone. Therefore, the first step is to learn \(p_{s}()\) given only \(^{(s)}\). We propose to learn \(p_{s}()\) through training a DM.

To fully capture \(p_{s}()\), the DM should consider the overall spatio-temporal structure of latent dynamics. To extract such a structure, the DM can not treat each latent state or time bin within latent dynamics as mutually independent and feed them into the model sequentially. We thus take the entire trial of latent dynamics \(_{0}^{(s)} q(^{(s)};_{s})\) as input to the DM for training. Specifically, the DM fits \(p_{s}()\) through the training of a denoiser \((,t;_{s}):(^{l d} )^{l d}\).

Next, we describe the architecture of \((,t;_{s})\), which is refined for extracting the global spatio-temporal structure of latent dynamics. Traditional architecture based on 2D-Convolution Layers  focuses on capturing the local features within latent dynamics, which can hardly extract its global spatio-temporal dependency or structure. Thus, we adopt an architecture mainly derived from Diffusion Transformer (DiT) . Specifically, we propose to use _S_patio-_T_emporal Transformer _Block_ (STBlock), shown in Figure 2(A). Each STBlock is composed of a Spatio Transformer layer followed by a Temporal Transformer layer, which are 1-layer encoders based on multi-head self-attention. The Spatio Transformer layer takes latent states of each time bin as inputs to extract spatial structure, whereas the Temporal Transformer layer takes the entire latent trajectory of each latent space dimension as inputs to extract temporal structure. (see Appendix A for details of the architecture of DM).

Figure 2: **A schematic overview of spatio-temporal structure extraction and recovery in ERDiff. (A) The architecture of DM for spatio-temporal structure extraction. (B) A descriptive diagram of structure recovery schematic. The left presents the extracted spatio-temporal structure of the source-domain latent dynamics; the right illustrates the structure-aware maximum likelihood alignment guidance in ERDiff.**

For the training objective of \((;_{s})\), we sample noisy targets \(_{t}^{(s)}\) and minimize the following DSM loss function:

\[_{s}=*{argmin}_{}_{t [0,T]}_{_{0}^{(s)} q(|^{(s)};_ {s}),(,_{ d})} [w(t)^{2}\|-(_{t}^{(s)},t;)\|_{2}^{2}]. \]

We note that \(_{0}^{(s)}\) here are actually latent dynamics inferred via VAE in Eq. 6. To enrich the input samples and adequately estimate the source density \(p_{s}()\) as motivated earlier, we propose to learn the VAE objective (Eq. 6) and the diffusion objective (Eq. 8) simultaneously. In each training iteration, conditioning on the current value of \(_{s}\) and \(_{s}\), we obtain a set of \(_{0}=h(^{(s)};_{s})\) and use it as \(_{0}^{(s)}\) to optimize Eq. 8. We can also optimize VAE first, obtain an optimal \(_{s}\), and use it to optimize Eq. 8. Experimental results show that the former approach achieves higher density estimation performance compared to the latter (see Appendix A for details).

### Spatio-temporal structure recovery and distribution alignment

Given the trained denoiser \((,t;_{s})\), we go through the reverse process from \(t=T\) to \(t=0\) in Eq.(3) and obtain the marginal distribution \(p_{0}(;_{s})\). We use \(p_{0}(;_{s})\) to approximate \(p_{s}()\) in Eq. (7). The maximum likelihood estimation can thus be written as

\[*{argmax}_{}_{ q(| ^{(t)};)}[ p_{0}(;_{s})]. \]

We perform alignment by tuning the parameter set \(\) of the probabilistic encoder while keeping the DM \(p_{0}(;_{s})\) fixed. Note that we have already optimized the VAE objective to obtain an optimal \(_{s}\) using source data. During alignment, we first set \(\) as \(_{s}\) and then linear probe \(\) (e.g., neural observation read-in layer). Consequently, we not only initialize the model with a good encoder but also make optimization during alignment much faster and more efficient.

In the reverse process, the computation of \( p_{0}(;_{s})\) is tractable through the probability flow ODE  whose marginal distribution at each time step \(t\) matches that of our VP-SDE. However, the direct computation of \( p_{0}(;_{s})\) will require invoking the ODE solver in each intermediate time step [38; 39]. Such complexity is prohibitively costly for online neural applications. To circumvent this issue, we can reform Eq. (9) as follows:

\[-_{ q(|^{(t)};)}[  p_{0}(;_{s})]=_{}(q (^{(t)};)\|p_{0}(;_{s}) )+(q(^{(t)};)), \]

where the first term is the KL divergence from the DM marginal distribution \(p_{0}(;_{s})\) to the probabilistic encoder distribution \(q(^{(t)};)\), and the second term \(()\) denotes the differential entropy. For the \(_{}()\) term in Eq. (10), via the Girsanov theorem [40; 41], we have

\[_{}(q(^{(t)};)\|p_ {0}(;_{s}))_{} (,_{s})+_{}(p_{T}( ;_{s})\|()), \]

where \(_{}\) is the denoising score matching loss in Eq. (5), and \(p_{T}()\) is the distribution at final time step \(T\) of Eq. (2). Consequently, we could obtain an upper bound of the maximum likelihood objective, as follows (we provide detailed derivation in Appendix B):

\[-_{ q(|^{(t)};)}[  p_{0}(;_{s})]_ {}(p_{T}(;_{s})\|())}_ {} \]

Since \(()\) is a fixed prior distribution, it does not depend on parameter \(\). Thus, our optimization objective will include only the latter two terms, which are more computationally tractable. The first objective simplifies to a weighted noise residual for the parameter set \(\) and the second divergence objective can be approximated using the Hutchinson-Skilling trace estimator . We note that the recovery of spatio-temporal structure is primarily conducted by the weighted noise residual part, in which the probabilistic encoder obtains alignment guidance in awareness of the spatio-temporal structure from \((,t;_{s})\). This procedure is illustrated in Figure 2(B).

In distribution alignment, it is a common practice to directly leverage the ground-truth data samples by introducing a regularizer term in the optimization function. To encourage the diversity of latent dynamics after alignment, here we further compute and penalize the Sinkhorn Divergence  between the latent dynamics samples of source domain \(^{(s)} q(^{(s)};_{s})\) and that of target domain \(^{(t)} q(^{(t)};)\):

\[_{},_{F}+ (), \]

where each value \([i][j]=\|_{i}^{(s)}-_{j}^{(t)}\|_{2}^{2}\) in matrix \(\) denotes the squared Euclidean cost to move a probability mass from \(_{i}^{(s)}\) to \(_{j}^{(t)}\), and \(()\) computes the entropy of transport plan \(\). The total loss for distribution alignment is composed of the term in (13) and the latter two terms on the right side of (12). We note that the total loss is minimized only with respect to the probabilistic encoder parameter set \(\). (see Appendix C for the total loss formula and the detailed algorithm of ERDiff.)

## 4 Experiments

**Datasets.** We first train and evaluate ERDiff with a synthetic dataset. Then we apply ERDiff to a non-human primate (NHP) dataset with neural recordings from the primary motor cortex (M1), in which the primates are performing a center-out reaching task in 8 different directions. The NHP dataset contains rich cross-day and inter-subject settings that provide us with an ideal test bed.

**Baselines for comparison.** We compare ERDiff against the following two strong baselines proposed for the neural distribution alignment task:

\(\) **JSDM**: a metric-based method that leverages discrete samples from both the source and target domains. The alignment is performed through the symmetric Jensen-Shannon divergence .

\(\) **Cycle-GAN**: a state-of-the-art GAN-based method that uses cycle-consistent adversarial networks to align the distributions of latent dynamics.

Considering the neural observations and latent dynamics are in the format of multi-variate time series, we also compare ERDiff with the following methods aiming at distribution alignment for general time series data:

\(\) **SASA**: a metric-based distribution alignment method for time series data regression task through the extraction of domain-invariant representation.

\(\) **DANN**: an adversarial learning framework in which a domain classifier is followed by a feature extractor through a gradient reversal layer. This layer adjusts the gradient by multiplying it with a predefined negative constant during the training process.

\(\) **RDA-MMD**: a distribution alignment method via minimizing MMD Loss between the latent dynamics extracted from LSTM.

\(\) **DAF**: an adversarial learning framework that uses a transformer-based shared module with a domain discriminator. During the adaptation step, the domain-invariant features are invariant (\(\), \(\) of self-attention); the domain-specific features (\(\) of self-attention) keep tuning.

### Synthetic dataset

**Data synthesis and evaluation metrics.** We first generate a simulated latent dynamics dataset to illustrate the effect of our ERDiff method on spatio-temporal structure-preserving and distribution alignment performance. In this setting, we consider modeling the nonlinear latent dynamics to follow conditionally Continuous Bernoulli (CB)  distribution. For each single-trial latent dynamics, we generate \(2\)-dimensional latent variables \(=\{_{1:L}\}\) and their \(32\)-dimensional observations \(=\{_{1:L}\}\), where \(L=32\). We use the following synthesis process and parameter settings to generate samples for the source and target domains, respectively:

\[p(_{l+1}^{(s)}_{l}^{(s)}) =_{d}(_{l+1,d}^{(s)} ^{(s)}(_{l,d}^{(s)})), p( _{l}^{(s)}_{l}^{(s)})=(_{l}^{(s)}^{(s)}_{l}^{(s)},), \] \[p(_{l+1}^{(t)}_{l}^{(t)}) =_{d}(_{l+1,d}^{(t)} ^{(t)}(_{l,d}^{(t)})), p(_{l}^{(t)}_{l}^{(t)})=(_{l}^{(t)} ^{(t)}_{l}^{(t)},),\]

where \(l\{1,,L\}\), and \(\{^{(s)},^{(s)}\}\), \(\{^{(t)},^{(t)}\}\) are the specific parameter sets of the source and target domains. To compare and evaluate the latent dynamics alignment performance, we estimate the trial-average log density of the aligned latent dynamics evaluated at the optimal generatiodistribution: \(1/L_{l=0}^{L-1} q^{*}(_{l}^{(t)})\), and the trial-averaged KL Divergence to the optimal latent dynamics distribution: \(1/L_{l=0}^{L-1}_{}(p_{^{*}}(_{l +1}^{(t)}_{l}^{(t)})\|p_{^{(t)}}(_{l+1}^{(t)} _{l}^{(t)}))\).

Results on synthetic dataset.We repeat the simulation experiment five times and report the mean and standard deviation of each method in the above two quantitative evaluation metrics, shown in Figure 3(A). We observe that ERDiff achieves higher alignment performance on both two evaluation metrics compared to baseline methods. For further analysis, we plot the phase portrait of the true source domain and those inferred by ERDiff and JSDM in Figure 3(B). Compared to JSDM, ERDiff can extract and recover the spatio-temporal structure of the synthetic latent dynamics more precisely and be much closer to the ground truth. These results mainly due to the fact that ERDiff obtains structure-aware alignment signals from the DM while JSDM neglects this structural information.

### Neural datasets

We conduct extensive experiments on two real-world neural datasets: the non-human-primate (NHP) primary motor cortex (M1)  and Rat hippocampal CA1 . Experiments on these two datasets use a nearly identical setup. Here we primarily discuss the experimental approach and results related to the NHP motor cortex dataset. (See Appendix D for the detailed results on the rat hippocampal CA1 dataset.)

Motor cortex dataset description.We conduct experiments with datasets collected from the primary motor cortex (M1) of two non-human primates ('C' & 'M') . The primates have been trained to reach one of eight targets at different angles (Figure 4A). Neural recordings from these two primates have been widely studied [20; 50]. During such a process, their neural spike activities (signals) in the primary motor cortex (M1) along with the reaching behavior velocity were recorded. They performed the center-out reaching task multiple times in each direction and only successful trials were saved. For our experimental evaluation purpose, we select the trials from three recording sessions for each primate per day. In total, we have 3 days for each primate. We will perform **cross-day** (recordings of the same primate performing the task on different days) and **inter-subject** (recordings of different primates) experiments.

Data processing and evaluation metrics.The neural recordings of each day and each primate consist of about 180-220 trials across 3 sessions. For each trial, about 200 neurons are recorded and the number of time bins is 39 with 20ms intervals. We also bin the velocity of the primate's behavior into 39 bins. Therefore, we have time-aligned neural data and behavioral data. When training with the source data, we optimize the VAE model together with the DM. One thing we need to emphasize here is that we also include a velocity-decoding loss to the VAE loss. The decoder maps the neural latent to the velocity values, which is a ridge regression model. Therefore, the inferred latent contains a rich amount of velocity information. During testing, we align the test neural data to the training neural data so that we can directly apply the velocity decoder to the latent in the test data without performance degradation. In the training session, the ratio of training and validation set is split as 80%:20% through 5-fold cross-validation. The post-processed dataset of primate 'C' contains 586 trials in total while that of primate 'M' contains 632 trials. For the evaluation protocol, since

Figure 3: **Experimental results on the synthetic dataset.****(A)** Performance comparison on trial-average negative log-likelihood (NLL) and KL Divergence (KLD). \(\) means the lower the better. ERDiff achieves the second-lowest NLL and the lowest KLD. **(B)** True continuous Bernoulli dynamics in the source domain compared to the latent dynamics aligned by ERDiff and JSDM in the target domain (blue dots denote the fixed points). ERDiff preserves the spatio-temporal structure of latent dynamics much better.

the ground-truth source domain distribution of latent dynamics is inaccessible, we use the behavior decoding performance to evaluate the performance of latent dynamics alignment. Here we compare the true behavior velocity with the decoded one in the test data using coefficient of determination values (\(R^{2}\), in %) and root-mean-square error (_RMSE_). To verify the generalization of each method in latent dynamics alignment, we make full use of the dataset collected in chronological order. We perform \(6\) sets of cross-day experiments and \(10\) sets of inter-subject experiments, all repeated over \(5\) different random seeds.

**Experimental setup.** The VAE is based on a sequential architecture , in which recurrent units are applied in both the probabilistic encoder and decoder. We also add domain knowledge of our alignment task into the model structure: a behavior regression decoder is cooperatively trained from the latent dynamics so that the behavior semantics information is complementarily provided during the neural manifold learning. Poisson negative log-likelihood loss is used for firing rate reconstruction and mean squared error is used for behavior regression. We use the Adam Optimizer  for optimization and the learning rate is chosen among \(\{0.005,0.01\}\). The batch size is uniformly set as 64. Despite the varying size of the input dimension (due to the varying number of recorded neurons in different sessions), the latent space dimension size is set as \(8\) for all the methods for a fair comparison. We use the dropout technique  and the ELU activation function  between layers in our probabilistic encoder and decoder architectures. During latent dynamics alignment, we perform linear probing only on the read-in layer of the probabilistic encoder while keeping the remaining layers fixed.

**Neural manifold analysis.** Considering the interpretability  and strong latent semantics contained in neural manifold , we conduct a case study based on the visualization of neural manifolds to verify the spatio-temporal structure preserving capability and alignment performance of ERDiff. In Figure 4(B), we plot the averaged latent dynamics of each direction in the source domain, which is based on one recording on primate 'C' using demixed Principle Component Analysis (dPCA) . The parameters of dPCA fit with the source-domain latent dynamics while being fixed when applied to perform the transformation in the target domain. In Figure 4(C), we plot the averaged latent dynamics of each direction aligned by ERDiff and two representative baseline methods (DAF and JSDM) under both cross-day and inter-subject settings.

Under both experimental settings, the overall observation is that the spatio-temporal structure of the aligned results of ERDiff is much more coherent with that of the source domain. The results of DAF and JSDM roughly recover the direction of dynamics but fail to preserve the spatio-temporal

Figure 4: **Motor cortex dataset and experimental results.****(A)** Illustration of the center-out reaching task of non-human primates. **(B)** The 3D visualization of trial-averaged latent dynamics corresponding to each reaching direction in the source domain. **(C)** The 3D visualization of trial-averaged latent dynamics corresponding to each reaching direction aligned by ERDiff, DAF, and JSDM given the target distribution from cross-day and inter-subject settings. We observe that ERDiff preserves the spatio-temporal structure of latent dynamics well.

structure tightly. That is because JSDM neglects the spatio-temporal structure during alignment and it is difficult for adversarial networks to capture such structure implicitly in DAF. Additionally, the averaged latent dynamics of each direction are much more clearly separated through ERDiff. We owe this outcome to the fact that providing extra guidance on the spatio-temporal structure would also facilitate the model to align directions properly. Additionally, without any mean offset alignment, the starting points (from the bottom center) and ending points of latent dynamics are also aligned well with the source domain, further verifying the structure recovering ability of ERDiff.

**Decoding performance comparison.** Table 1 shows a comparison of the r-squared value (\(R^{2}\)) and average RMSE on both the cross-day and inter-subject settings. While Figure 5(A) depicted the decoded velocity trajectories of a subset of trials on the cross-day setting given the method. We have the following observations: (1) Compared to traditional alignment methods specially designed for neural data, deep learning-based methods additionally model the sequential information of the latent dynamics, thus achieving better alignment results, which reflects the importance of spatio-temporal structure modeling. In most cases, ERDiff achieves the highest decoding accuracy and alignment performance among all methods. (2) From the ablation study shown at the bottom of Table 1, we find that both the Spatial Transformer layer and Temporal Transformer layer are key components in ERDiff, verifying the effectiveness of spatio-temporal structure modeling. (3) As shown in Figure 5(A), the spatio-temporal structure of the latent dynamics is well-preserved in the result of ERDiff. Compared to baselines, the smoothness and continuity of the trajectory decoded by ERDiff are also more satisfying.

**Impact of sampling density in the target domain.** We verify the consistent performance of ERDiff in few-shot target-sample circumstances. In Figure 5(B), we analyze the impact of the sampling density of the target domain on decoding performance. The setting is that we sample a portion

    &  &  \\   & \(R^{2}(\%)\) & RMSE\(\) & \(R^{2}(\%)\) & RMSE\(\) \\  Cycle-GAN & -24.83 (\( 3.91\)) & 11.28 (\( 0.44\)) & -25.47 (\( 3.87\)) & 12.23 (\( 0.46\)) \\ JSDM & -17.36 (\( 2.57\)) & 9.01 (\( 0.38\)) & -19.59 (\( 2.77\)) & 11.55 (\( 0.52\)) \\ SASA & -12.66 (\( 2.40\)) & 8.36 (\( 0.32\)) & -14.33 (\( 3.05\)) & 10.62 (\( 0.40\)) \\ DANN & -12.57 (\( 3.28\)) & 8.28 (\( 0.32\)) & -18.37 (\( 3.24\)) & 10.66 (\( 0.57\)) \\ RDA-MMD & -9.96 (\( 2.63\)) & 8.51 (\( 0.31\)) & -6.31 (\( 2.19\)) & 10.29 (\( 0.42\)) \\ DAF & -6.37 (\( 3.72\)) & 8.17 (\( 0.48\)) & -11.26 (\( 3.64\)) & \(( 0.58)\) \\  ERDiff w/o S & -12.69 (\( 2.64\)) & 8.57 (\( 0.50\)) & -14.60 (\( 2.88\)) & 10.85 (\( 0.57\)) \\ ERDiff w/o T & -14.61 (\( 2.33\)) & 8.93 (\( 0.50\)) & -17.10 (\( 3.23\)) & 10.94 (\( 0.59\)) \\
**ERDiff (Ours)** & \(( 2.24\)) & \(( 0.43)\) & \(( 2.86)\) & \(9.78( 0.50)\) \\   

Table 1: The R-squared values (\(R^{2}\), in %) and RMSE of the methods on the motor cortex dataset. ERDiff w/o S is short for a variant of our proposed method that removes the spatial transformer layer in the DM. ERDiff w/o T is short for a variant of our proposed method that removes the temporal transformer layer in the DM. The boldface denotes the highest score. Each experiment condition is repeated with 5 runs, and their mean and standard deviation are listed.

Figure 5: **(A) True source-domain trial velocities and behavior decoding trajectories inferred from a ridge regression model given the latent dynamics aligned by ERDiff and JSDM, respectively. We can observe that ERDiff not only preserves the spatio-temporal structure but also decodes the direction more accurately. (B) We compare the decoding performance of ERDiff, DAF, and JSDM with a decrease in the sampling density of trials on the target domain. We can observe that ERDiff maintains a relatively high accuracy under low sampling densities.**

of target-domain data to learn the alignment and apply the alignment to the entire target domain. Despite the sampling density drops from \(50\%\) to \(10\%\), our results demonstrate that ERDiff continues to produce fairly consistent decoding accuracy with a small drop. This result validates our argument that ERDiff both preserves the dynamics structure underlying neural activities and maintains the characteristics of the target domain. In comparison, the performance of baseline methods shrinks drastically because they lack prior knowledge of the spatio-temporal structure.

We can conclude that the DM in ERDiff is capable of extracting the spatio-temporal structure in the source domain latent dynamics, providing a valuable inductive bias in recovering such structure during distribution alignment.

## 5 Discussion

In this work, we propose a new method named ERDiff, for solving the neural distribution alignment issue in real-world neuroscience applications (e.g., brain-computer interfaces). Firstly, with the source domain, we propose to use a diffusion model to extract the spatio-temporal structure within the latent dynamics of trials. Next, in the alignment phase with the target domain, the spatio-temporal structure of latent dynamics is recovered through the maximum likelihood alignment based on the diffusion model. Experimental results on synthetic and real-world motor cortex datasets verify the effectiveness of ERDiff in the enhancement of long-term robustness and behavior decoding performance from neural latent dynamics.

To be in line with the conventions of previous studies on neural distribution alignment [4; 16], the behavioral (velocity) signals of the source domain are present during the VAE training. These signals do help in learning a more interpretable neural latent space. However, we emphasize that ERDiff does not incorporate any behavioral signals of the target domain during the distribution alignment phase. Hence, ERDiff is entirely an _unsupervised_ neural distribution alignment (i.e., test-time adaptation) method. As for the computational cost analysis, In the source domain training phase, the additional computation cost of ERDiff primarily comes from the diffusion model (DM) training. We note that the DM is trained in the latent space \(\), which is significantly lower in dimensionality than the raw neural spiking signal space \(\). Therefore, the computational overhead of this one-time training phase is acceptable, especially given that it can be conducted offline in real-world BCI applications. In the alignment phase, we would like to emphasize that ERDiff maintains a comparable computational cost with baseline methods. Please refer to Appendix E for a comprehensive analysis of ERDiff's computational cost and time complexity.

**Limitation and future work.** (1) Currently, ERDiff can align well with a single source domain neural latent distribution. An intriguing direction for future work would be learning a unified latent space across multiple source domains using the diffusion model. Thus the method would be applicable to domain generalization problems. (2) Generalization on alternative latent variable models (LVM). In this paper, ERDiff identifies the latent variables of raw neural spiking signals with a canonical version of VAE. However, the architecture of the LVM within ERDiff is actually disentangled from the diffusion model training or MLA procedure. Future work includes validating ERDiff given more advanced implementations of LVM, e.g., LFADS , STNDT .

**Broader impact.** Not confined to practical applications in systems neuroscience, the maximum likelihood alignment (MLA) with diffusion model algorithm proposed in ERDiff has great potential to apply to broader domain adaptation tasks across general time-series datasets (e.g., weather forecasting, and seismology). We also expect that our method can be applied or extended to other real-world scenarios and the broader field of neuroscience/AI.