# Model-Based Control with Sparse Neural Dynamics

Ziang Liu\({}^{1,2}\)  Gengengeng Zhou\({}^{2}\) Jeff He\({}^{2}\) Tobia Marcucci\({}^{3}\)

Li Fei-Fei\({}^{2}\) Jiajun Wu\({}^{2}\) Yunzhu Li\({}^{2,4}\)

\({}^{1}\)Cornell University \({}^{2}\)Stanford University

\({}^{3}\)Massachusetts Institute of Technology

\({}^{4}\)University of Illinois Urbana-Champaign

ziangliu@cs.cornell.edu

{g9zhou,jeff2024}@stanford.edu

tobiam@mit.edu

{feifeili,jiajunwu}@cs.stanford.edu

yunzhuli@illinois.edu

denotes equal contributionPlease see our website at robopil.github.io/Sparse-Dynamics/ for additional visualizations.

###### Abstract

Learning predictive models from observations using deep neural networks (DNNs) is a promising new approach to many real-world planning and control problems. However, common DNNs are too unstructured for effective planning, and current control methods typically rely on extensive sampling or local gradient descent. In this paper, we propose a new framework for integrated model learning and predictive control that is amenable to efficient optimization algorithms. Specifically, we start with a ReLU neural model of the system dynamics and, with minimal losses in prediction accuracy, we gradually sparsify it by removing redundant neurons. This discrete sparsification process is approximated as a continuous problem, enabling an end-to-end optimization of both the model architecture and the weight parameters. The sparsified model is subsequently used by a mixed-integer predictive controller, which represents the neuron activations as binary variables and employs efficient branch-and-bound algorithms. Our framework is applicable to a wide variety of DNNs, from simple multilayer perceptrons to complex graph neural dynamics. It can efficiently handle tasks involving complicated contact dynamics, such as object pushing, compositional object sorting, and manipulation of deformable objects. Numerical and hardware experiments show that, despite the aggressive sparsification, our framework can deliver better closed-loop performance than existing state-of-the-art methods. +

Footnote â€ : Please see our website at robopil.github.io/Sparse-Dynamics/ for additional visualizations.

## 1 Introduction

Our mental model of the physical environment enables us to easily carry out a broad spectrum of complex control tasks, many of which lie far beyond the capabilities of present-day robots . It is, therefore, desirable to build predictive models of the environment from observations and develop optimization algorithms to help the robots understand the impact of their actions and make effective plans to achieve a given goal. Physics-based models  have excellent generalization ability but typically require full-state information of the environment, which is hard and sometimes impossible to obtain in complicated robotic (manipulation) tasks. Learning-based dynamics modeling circumvents the problem by learning a predictive model directly from raw sensory observations, and recent successes are rooted in the use of deep neural networks (DNNs) as the functional class . Despite their improved prediction accuracy, DNNs are highly nonlinear,making model-based planning with neural dynamics models very challenging. Existing methods often rely on extensive sampling or local gradient descent to compute control signals, and can be ineffective for complicated and long-horizon planning tasks.

Compared to DNNs, simpler models like linear models are amenable to optimization tools with better guarantees, but often struggle to accurately fit observation data. An important question arises: how precise do these models need to be when employed within a feedback control loop? The cognitive science community offers substantial evidence suggesting that humans do not maintain highly accurate mental models; nevertheless, these less precise models can be effectively used with environmental feedback [30; 10]. This notion is also key in control-oriented system identification [25; 44] and model order reduction [55; 61]. The framework from Li et al.  trades model expressiveness and precision for more efficient and effective optimization-based planning through the learning of compositional Koopman operators. However, their approach is limited by the linearity of the representation in the Koopman embedding space and struggles with more complex dynamics.

In this paper, we propose a framework for integrated model learning and control that trades off prediction accuracy for the use of principled optimization tools. Drawing inspiration from the neural network pruning and neural architecture search communities [22; 54; 16; 5; 41], we start from a neural network with ReLU activation functions and gradually reduce the nonlinearity of the model by removing ReLU units or replacing them with identity mappings (Figure 1a). This yields a highly sparsified neural dynamics model, that is amenable to model-based control using state-of-the-art solvers for mixed-integer programming (MIP) (Figure 1b).

We present examples where the proposed sparsification pipeline can determine region partition and uncover the underlying system for simple piecewise affine systems. Moreover, it can maintain high prediction accuracy for more complex manipulation tasks, using a considerably smaller portion of the original nonlinearities. Importantly, our approach allows the joint optimization of the network architecture and weight parameters. This yields a spectrum of models with varying degrees of sparsification. Within this spectrum, we can identify the simplest model that is adequate to meet the requirements of the downstream closed-loop control task.

Our contributions can be summarized as follows: (i) We propose a novel formulation for identifying the dynamics model from observation data. For this step, we introduce a continuous approximation of the sparsification problem, enabling end-to-end gradient-based optimization for both the model class and the model parameters (Figure 1a). (ii) By having significantly fewer ReLU units than

Figure 1: **Model-based control with sparse neural dynamics.** (a) Our framework sparsifies the neural dynamics models by either removing neurons or replacing ReLU activation functions with identity mappings (ID). (b) The sparsified models enable the use of efficient MIP methods for planning, which can achieve better closed-loop performance than sampling-based alternatives commonly used in model-based RL. (c) We evaluate our framework on various dynamical systems that involve complex contact dynamics, including tasks like object pushing and sorting, and manipulating a deformable rope.

the full model, the sparsified dynamics model allows us to solve the predictive-control problems using efficient MIP solvers (Figure 0(b)). This can lead to better closed-loop performance compared to both model-free and model-based reinforcement learning (RL) baselines. (iii) Our framework can be applied to many types of neural dynamics, from vanilla multilayer perceptrons (MLPs) to complex graph neural networks (GNNs). We show its effectiveness in a variety of simulated and real-world manipulation tasks with complex contact dynamics, such as object pushing and sorting, and manipulation of deformable objects (Figure 0(c)).

## 2 Related Work

**Model learning for planning and control.** Model-based RL agents learn predictive models of their environment from observations, which are subsequently used to plan their actions [9; 53]. Recent successes in this domain often heavily rely on DNNs, exhibiting remarkable planning and control results in challenging simulated tasks , as well as complex real-world locomotion and manipulation tasks [34; 56]. Many of these studies draw inspiration from advancements in computer vision, learning dynamics models directly in pixel-space [15; 11; 12; 71; 62], keypoint representation [31; 47; 39], particle/mesh representation [36; 60; 27], or low-dimensional latent space [65; 1; 21; 20; 58; 69]. While previous works typically assume that the model class is given and fixed during the optimization process, our work puts emphasis on finding the desired model class via an aggressive network sparsification, to support optimization tools with better guarantees. We are willing to sacrifice the prediction accuracy for better closed-loop performance using more principled optimization techniques.

**Network sparsification.** The concept of neural network sparsification is not new and traces back to the 1990s . Since then, extensive research has been conducted, falling broadly into two categories: network pruning [23; 22; 66; 54; 35; 24; 3; 43; 16; 42; 5; 72] and neural architecture search [74; 8; 40; 13; 64]. Many of these studies have demonstrated that fitting an overparameterized model before pruning yields better results than directly fitting a smaller model. Our formulation is closely related to DARTS  and FBNet , which both seek a continuous approximation of the discrete search process. However, unlike typical structured network compression methods, which try to remove as many units as possible, our goal here is to minimize the model nonlinearity. To this end, our method also permits the substitution of ReLU activations with identity mappings. This leaves the number of units unchanged but makes the downstream optimization problem much simpler.

**Mixed-integer modeling of neural networks.** The input-output map of a neural network with ReLU activations is a piecewise affine function that can be modeled exactly through a set of mixed-integer linear inequalities. This allows us to use highly-effective MIP solvers for the solution of the model-based control problem. The same observation has been leveraged before for robustness analysis of DNNs in [63; 70], while the efficiency of these mixed-integer models has been thoroughly studied in .

## 3 Method

In this section, we describe our methods for learning a dynamics model using environmental observations and for sparsifying DNNs through a continuous approximation of the discrete pruning process. Then we discuss how the sparsified model can be used by an MIP solver for trajectory optimization and closed-loop control.

### Learning a dynamics model over the observation space

Assume we have a dataset \(=\{(y_{t}^{m},u_{t}^{m}) t=1,,T,m=1,,M\}\) collected via interactions with the environment, where \(y_{t}^{m}\) and \(u_{t}^{m}\) denote the observation and action obtained at time \(t\) in trajectory \(m\). Our goal is to learn an autoregressive model \(_{}\), parameterized by \(\), as a proxy of the real dynamics that takes a small sequence of observations and actions from time \(t^{}\) to the current time \(t\), and predicts the next observation at time \(t+1\):

\[_{t+1}^{m}=_{}(y_{t^{}:t}^{m},u_{t^{}:t}^{m}).\] (1)We optimize the parameter \(\) to minimize the simulation error that describes the long-term discrepancy between the prediction and the actual observation:

\[()=_{m=1}^{M}_{t}\|y_{t+1}^{m}-_{}(_ {t^{}:t}^{m},u_{t^{}:t}^{m})\|_{2}^{2}.\] (2)

### Neural network sparsification by removing or replacing ReLU activations

We instantiate the transition function \(_{}\) as a ReLU neural network with \(N\) hidden layers. Let us denote the number of neurons in the \(i^{}\) layer as \(N_{i}\). When given an input \(x=(y_{ t:t}^{m},u_{ t:t}^{m})\), we denote the value of the \(j^{}\) neuron in layer \(i\) before the ReLU activation as \(x_{ij}\). Regular ReLU neural networks apply the rectifier function to every \(x_{ij}\) and obtain the activation value using \(x_{ij}^{+}=h_{ij}(x_{ij})(x_{ij})(0,x_{ij})\). The nonlinearity introduced by the ReLU function allows the neural networks to fit the dataset but makes the downstream planning and control tasks more challenging. As suggested by many prior works in the field of neural network compression [22; 16], a lot of these ReLUs are redundant and can be removed with minimal effects on the prediction accuracy. In this work, we reduce the number of ReLU functions by replacing the function \(h_{ij}\) with either an identity mapping \((x_{ij}) x_{ij}\) or a zero function \((x_{ij}) 0\), where the latter is equivalent to removing the neuron (Figure 0(a)).

We divide the parameters in \(_{}\) into two vectors, \(=(,)\). The vector \(\) collects the weight matrices and the bias terms. The vector \(\) consists of a set of integer variables that parameterize the architecture of the neural network: \(=\{_{ij}\{1,2,3\} i=1,,N,j=1,,N_{i}\}\), such that

\[h_{ij}(x_{ij})=(x_{ij})&_{ij}=1\\ (x_{ij})&_{ij}=2\\ (x_{ij})&_{ij}=3.\] (3)

The sparsification problem can then be formulated as the following MIP:

\[_{=(,)}() _{i=1}^{N}_{j=1}^{N_{i}}(_{ij}=1),\] (4)

where \(\) is the indicator function, and the value of \(\) decides the number of regular ReLU functions that are allowed to remain in the neural network.

### Reparameterizing the categorical distribution using Gumbel-Softmax

Solving the optimization problem in Equation 4 is hard, as the number of integer variables in \(\) equals the number of ReLU neurons in the neural network, which is typically very large. Therefore, we relax the problem by introducing a random variable \(_{ij}\) indicating the categorical distribution of \(_{ij}\) assigning to one of the three categories, where \(_{ij}^{k} p(_{ij}=k)\) for \(k=1,2,3\). We can then reformulate the problem as:

\[_{,}[()] _{i=1}^{N}_{j=1}^{N_{i}}_{ij}^{1},_{ij} _{ij},\] (5)

where \(\{_{ij} i=1,,N,j=1,,N_{i}\}\).

In Equation 5, the sampling procedure \(_{ij}_{ij}\) is not differentiable. In order to make end-to-end gradient-based optimization possible, we employ the Gumbel-Softmax [28; 46] technique to obtain a continuous approximation of the discrete distribution.

Specifically, for a 3-class categorical distribution \(_{ij}\), where the class probabilities are denoted as \(_{ij}^{1},_{ij}^{2},_{ij}^{3}\), Gumbel-Max  allows us to draw 3-dimensional one-hot categorical samples \(_{ij}\) from the distribution via:

\[_{ij}=(*{arg\,max}_{k}(_{ij}^{k}+g^{k })),\] (6)where \(g^{k}\) are i.i.d. samples drawn from \((0,1)\), which is obtained by sampling \(u^{k}(0,1)\) and computing \(g^{k}=-(-(u^{k}))\). We can then use the softmax function as a continuous, differentiable approximation of the \(\) function:

\[z_{ij}^{k}=^{k}+g^{k})/)}}{_{k^{}}^{k^{}}+g^{k^{}})/)}}.\] (7)

We denote this operation as \(z_{ij}(_{ij},)\), where \(\) is a temperature parameter controlling how close the softmax approximation is to the discrete distribution. As the temperature \(\) approaches zero, samples from the Gumbel-Softmax distribution become one-hot and identical to the original categorical distribution.

After obtaining \(z_{ij}\), we can calculate the activation value \(x_{ij}^{+}\) as a weighted sum of different functional choices:

\[x_{ij}^{+}=_{ij}(x_{ij}) z_{ij}^{1}(x_{ij})+ z_{ij}^{2}(x_{ij})+z_{ij}^{3}(x_{ij}),\] (8)

and then use gradient descent to optimize both the weight parameters \(\) and the architecture distribution parameters \(\).

During training, we can also constrain \(z_{ij}\) to be one-hot vectors by using \(\), but use the continuous approximation in the backward pass by approximating \(_{}_{ij}_{}z_{ij}\). This is denoted as "Straight-Through" Gumbel Estimator in .

### Optimization algorithm

Instead of limiting the number of regular ReLUs from the very beginning of the training process, we start with a randomly initialized neural network and use gradient descent to optimize \(\) and \(\) by minimizing the following objective function until convergence:

\[[()]+ R(),\] (9)

where the regularization term \(R()_{i=1}^{N}_{j=1}^{N_{i}}_{ij}^{1}\) aims to explicitly reduce the use of the regular ReLU function. One could also consider adjusting it to \(R()_{i=1}^{N}_{j=1}^{N_{i}}(_{ij}^{1}+_{ {ID}}_{ij}^{2})\) with a small \(_{}\) to discourage the use of identity mappings at the same time.

We then take an iterative approach by starting with a relatively large \(_{1}\) and gradually decrease its value for \(K\) iterations with \(_{1}>_{2}>>_{K}=\). Within each optimization iteration using \(_{k}\), we first rank the neurons according to \((_{ij}^{2},_{ij}^{3})\) in descending order, and assign the activation function for the top-ranked neurons as ID if \(_{ij}^{2}_{ij}^{3}\), or Zero otherwise, while keeping the bottom \(_{k}\) neurons intact using Gumbel-Softmax as described in Section 3.3. Subsequently, we continue optimizing \(\) and \(\) using gradient descent to minimize Equation 9. The sparsification process generates a range of models at various sparsification levels for subsequent investigations.

### Closed-loop feedback control using the sparsified models

After we have obtained the sparsified dynamics models, we fix the model architecture and formulate the model-based planning task as the following trajectory optimization problem:

\[_{u}_{t}c(y_{t},u_{t}) y_{t+1}=_{ }(y_{t^{}:t},u_{t^{}:t}),\] (10)

where \(c\) is the cost function. When the transition function \(_{}\) is a highly nonlinear neural network, solving the optimization problem is not easy. Previous methods [71; 11; 56; 14; 47] typically regard the transition function as a black box and rely on sampling-based algorithms like the cross-entropy method (CEM)  and model-predictive path integral (MPPI)  for online planning. Others have also tried applying gradient descent to derive the action signals [36; 37]. However, the number of required samples grows exponentially with the number of inputs and trajectory length. Gradient descent can also be stuck in local optima, and it is also hard to assess the optimality or robustness of the derived action sequence using these methods.

#### 3.5.1 Mixed-integer formulation of ReLU neural dynamics

The sparsified neural dynamics models open up the possibility of dissecting the model and solving the problem using more principled optimization tools. Specifically, given that a ReLU neural network is a piecewise affine function, we can formulate Equation 10 as MIP. We assign to each ReLU a binary variable \(a=(x 0)\) to indicate whether the pre-activation value is larger or smaller than zero. Given lower and upper bounds on the input \(l x u\) (which we calculate by passing the offline dataset through the sparsified neural networks), the equality \(x^{+}=(x)(0,x)\) can be modeled through the following set of mixed-integer linear constraints:

\[x^{+} x-l(1-a), x^{+} x, x^{+} ua, x^{+} 0,  a\{0,1\}.\] (11)

If only a few ReLUs are left in the model, Equation 10 can be efficiently solved to global optimality.

The formulation in Equation 11 is the simplest mixed-integer encoding of a ReLU network, and a variety of strategies are available in the literature to accelerate the solution of our MIPs. For large-scale models, it is possible to _warm start_ the optimization process using sampling-based methods or gradient descent, and subsequently refine the solution using MIP solvers . There also exist more advanced techniques to formulate the MIP , these can lead to tighter convex relaxations of our problem and allow us to identify high-quality solutions of Equation 10 earlier in the branch-and-bound process. The ability to find globally-optimal solutions is attractive but requires the model to exhibit a reasonable global performance. The sparsification step helps us also in this direction, since we typically expect a smaller simulation error from a sparsified (simpler) model than its unsparsified (very complicated) counterpart when moving away from the training distribution. In addition, we could also explicitly counteract this issue with the addition of trust-region constraints that prevent the optimizer from exploiting model inaccuracies in the areas of the input space that are not well-supported by the training data .

#### 3.5.2 Tradeoff between model accuracy and closed-loop control performance

Models with fewer ReLUs are generally less accurate but permit the use of more advanced optimization tools, like efficient branch-and-bound algorithms implemented in state-of-the-art solvers. Within a model-predictive control (MPC) framework, the controller can leverage the environmental feedback to counteract prediction errors via online modifications of the action sequence. The iterative optimization procedure in Section 3.4 yields a series of models at different sparsification levels. By comparing their performances and investigating the trade-off between prediction accuracy and closed-loop control performance, we can select the model with the most desirable capacity.

## 4 Experiments

In our experiments, we seek to address three central questions: (1) How does the varying number of ReLUs affect the prediction accuracy? (2) How does the varying number of ReLUs affect open-loop planning? (3) Can the sparsified model, when combined with more principled optimization methods, deliver better closed-loop control results?

**Environments, tasks, and model classes.** We evaluate our framework on four environments specified in different observation spaces, including state, keypoints, and object-centric representations.

Figure 2: **Recover the ground truth piecewise affine functions from data. We evaluate our sparsification pipeline on two hand-designed piecewise affine functions composed of four linear pieces. Our pipeline successfully generates sparsified models with 2 ReLUs that accurately fit the data, determine the region partition, and recover the underlying ground truth system.**These evaluation environments make use of different modeling classes, including vanilla MLPs and complex GNNs. For closed-loop control evaluation, we additionally present the performance of our framework on two standardized benchmark environments from OpenAI Gym , CartPole-v1 and Reacher-v4.

* **Piecewise affine function.** We consider manually designed two-dimensional piecewise affine functions consisting of four linear pieces (Figure 2), and the goal is to recover the ground-truth system from data through the sparsification process starting from an overparameterized MLP. To train the model, we collect 1,600 transition pairs from the ground truth functions uniformly distributed over the 2D input space.
* **Object pushing.** A fully-actuated pusher interacts with an object moving on a 2D plane, as depicted in Figure 3(a). The goal is to manipulate the object to reach a randomly generated target pose. We generated 50,000 transition pairs using the Pymunk simulator . The observation \(y_{t}\) is defined by the position of four selected keypoints on the object, and the dynamics model is also instantiated as an MLP.
* **Object sorting.** In Figure 3(c), a pusher is used to sort a cluster of objects that lie on a table into corresponding target regions. In this environment, we generate a dataset consisting of 150,000 transition pairs with two objects using Pymunk. Following the success of previous graph-based dynamics models [4; 37; 36], we use GNNs as the model class. The model takes the object positions as input and allows compositional generalization to extrapolate settings containing more objects, supporting up to 8 objects as tested in our benchmark.
* **Rope manipulation.** Figure 3(b) shows the task of manipulating a deformable rope into a target shape. We generate a dataset of 60,000 transition pairs through random interactions using Nvidia FleX . We use an MLP to model the dynamics, and the observation \(y_{t}\) is the position of four selected keypoints on the rope.

### How does the varying number of ReLUs affect the prediction accuracy?

**Recover the ground truth piecewise affine system from data.** The sparsification procedure starts with the full model with four hidden layers and 576 ReLU units. It then undergoes seven iterations of sparsification, with the number of remaining ReLUs, represented as \(_{k}\), diminishing from 25 down to 2. As illustrated in Figure 2, the sparsified model, which retains only two ReLUs, accurately identifies the region partition and achieves a nearly zero distance from the ground truth. This enables

Figure 3: **Quantitative analysis of the sparsified models for open-loop prediction and planning. (a) Long-term future prediction error, with the shaded area representing the region between the 25\({}^{}\) and 75\({}^{}\) percentiles. The significant overlap between the curves suggests that reducing the number of ReLUs only leads to a minimal decrease in prediction accuracy. (b) Results of the trajectory optimization problem from Equation 10. We compare two optimization formulations: mixed-integer programming (MIP) and model-predictive path integral (MPPI), using models with varying levels of sparsification. The figure clearly indicates that MIP consistently outperforms its sampling-based counterpart, MPPI.**

the model to recover the underlying ground truth system and demonstrates the effectiveness of the sparsification procedure.

**Future prediction using sparsified models at different sparsification levels.** Existing literature provides comprehensive studies indicating that neural networks are overparameterized . Still, we are interested in understanding how the proposed sparsification process affects the model prediction accuracy. We evaluate our framework on three benchmark environments, object pushing, sorting, and rope manipulation. Starting with the full model, we gradually sparsify it using decreasing values of \(_{k}\). During training, we focus solely on the accuracy of one-step prediction but evaluate the models for their long-horizon predictive capability.

Figure (a)a illustrates the prediction accuracy for models with varying numbers of ReLUs. "Object Sorting-2" denotes the task of sorting objects into two piles, while "Object Sorting-3" represents sorting into three piles. The blue curve shows the full-model performance, and the shaded area denotes the region between the 25\({}^{}\) and 75\({}^{}\) percentiles over 100 trials. The figure suggests that, even with significantly fewer ReLUs, the model still achieves a reasonable future prediction performance, with the confidence region significantly overlapping with that of the full model. It is worth

Figure 4: **Qualitative results on closed-loop feedback control. (a) In object pushing, the objective is to manipulate the object to reach a randomly generated target pose, depicted as transparent in the first column. The second column illustrates how the planner, using the sparsified model, can leverage feedback from the environment to compensate for the modeling errors and accurately achieve the target. (b) The framework is also applicable to rope manipulation. Our sparsified model, in conjunction with the MIP formulation, facilitates closed-loop feedback control to manipulate the rope into desired configurations. (c) Our framework also consistently succeeds in object sorting tasks that involve complex contact events. Using the same model with the MIP formulation, the system can manipulate up to eight objects, sorting them into their respective regions.**

noting that our framework is adaptable to both vanilla MLPs (utilized in object pushing and rope manipulation) and GNNs (employed for object sorting), thereby showcasing the broad applicability of our proposed method. Later in Section 4.2 and 4.3, we will demonstrate that the sparsified models, although slightly less accurate than the full model, can yield superior open-loop and closed-loop optimization results when paired with more effective optimization tools.

### How does the varying number of ReLUs affect open-loop planning?

Having obtained the sparsified models and examined their prediction accuracy, we next assess how these models can be applied to solve the trajectory optimization problem in Equation 10. The sparsified model contains significantly fewer ReLUs, making it feasible to use formulations with better optimality guarantees, as discussed in Section 3.5. Specifically, we formulate the optimization problem using MIP (Equation 11) and solve the problem using a commercial optimization solver, Gurobi . We compare our method with MPPI, a commonly-used sampling-based alternative from the model-based RL community. As illustrated in Figure 3b, the MIP formulation permits the use of advanced branch-and-bound optimization procedures. With a sufficiently small number of ReLU units remaining in the neural dynamics models, we can solve the problem optimally. This consistently outperforms MPPI by a significant margin.

### Can the sparsified model deliver better closed-loop control results?

The results in Section 4.2 only tell us how good different optimization procedures are as measured by the learned dynamics model. However, what we really care about is the performance when executing optimized plans in the original simulator or the real world. Therefore, it is crucial to evaluate the effectiveness of these models within a closed-loop control framework. Here we employ an MPC

Figure 5: **Quantitative analysis of model sparsification vs. closed-loop control performance. The horizontal axis represents the number of ReLUs remaining in the model, and the vertical axis indicates the closed-loop control performance. As shown in the figure, there exists a nice trade-off between the levels of model sparsification and the performance of closed-loop control. Models with fewer ReLUs are typically less accurate than the full model but make the MIP formulation tractable to solve. Across the spectrum of models, there exists a sweet spot, where a model, although only reasonably accurate, benefits from more powerful optimization tools and can lead to superior closed-loop control results. Moreover, our method consistently outperforms commonly used RL techniques such as PPO and SAC.2**

framework that, taking into account the feedback from the environment, allows the agent to make online adjustments to the action sequence.

Figure 4 visualizes multiple execution trials of object pushing, sorting, and rope manipulation in the real world using our method. Our framework reliably pushes the object to its target pose, deforms the rope into the desired shape, and sorts the many objects into the corresponding piles. We then present the quantitative results for object pushing, sorting, and rope manipulation, along with two tasks from OpenAI Gym , CartPole-v1 and Reacher-v4, measured in simulation, in Figure 5. Across various tasks, we observe a similar trade-off between the levels of model sparsification and closed-loop control performance. As the number of ReLUs decreases, there is typically a slight decrease in prediction accuracy, but as illustrated in Figure 5, this allows us to formulate the trajectory optimization problem as an MIP and solve it using efficient branch-and-bound algorithms. Consequently, within the spectrum of sparsified models, there exists an optimal point where a model, albeit only reasonably accurate, benefits from the more effective optimization tools and can result in better closed-loop control performance. Our iterative sparsification process, discussed in Section 3.4, enables us to easily identify such model. Furthermore, our method consistently outperforms commonly used RL techniques such as PPO  and SAC  when using the same number of interactions with the underlying environments.

## 5 Discussion

**Conclusion.** In this work, we propose to sparsify neural dynamics models for more effective closed-loop, model-based planning and control. Our formulation allows an end-to-end optimization of both the model class and the weight parameters. The sparsified models enable the use of efficient branch-and-bound algorithms and can deliver better performance in closed-loop control. Our framework applies to various dynamical systems and multiple neural network architectures, including vanilla MLPs and complicated GNNs. We also demonstrate the effectiveness and applicability of our method through its application to simple piecewise affine systems and manipulation tasks involving complex contact dynamics and deformable objects.

Our work draws inspiration and merges techniques from both the learning and control communities, which we hope can spur future investigations in this interdisciplinary direction to take advantage and make novel use of the powerful tools from both communities.

**Limitations and future work.** Our method relies on sparsifying neural dynamics models to fewer ReLU units to make the control optimization process solvable in a reasonable time due to the worst-case exponential run time of MIP solvers. Although our experiments showed that this already enabled us to complete a wide variety of tasks, our approach may struggle when facing a much larger neural dynamics model.

Our experiments also demonstrated superior closed-loop control performance using sparsified dynamics models with only reasonably good prediction accuracy as a result of benefiting from stronger optimization tools, but our approach may suffer if the sparsified dynamics model becomes significantly worse and incapable of providing useful forward predictions.

Acknowledgments.This work is in part supported by ONR MURI N00014-22-1-2740. Ziang Liu is supported by the Siebel Scholars program.