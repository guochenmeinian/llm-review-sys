# Concept Algebra for (Score-Based) Text-Controlled Generative Models

Zihao Wang\({}^{1}\)

Lin Gui\({}^{1}\)

Jeffrey Negrea\({}^{2}\)

Victor Veitch\({}^{1,2,3}\)

\({}^{1}\)_Department of Statistics, University of Chicago_

\({}^{2}\)_Data Science Institute, University of Chicago_

\({}^{3}\)_Google Research_

###### Abstract

This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. A key property of such models is that they can compose disparate concepts in a 'disentangled' manner. This suggests these models have internal representations that encode concepts in a 'disentangled' manner. Here, we focus on the idea that concepts are encoded as subspaces of some representation space. We formalize what this means, show there's a natural choice for the representation, and develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples using Stable Diffusion.

## 1 Introduction

Large-scale text-controlled generative models are now dominant in many parts of modern machine learning and artificial intelligence [e.g., 1, 2, 1, 11]. In these models, the user provides a prompt in natural language and the model generates samples based on this prompt--e.g., in large language models the sample is a natural language response, and in text-to-image models the sample is an image. These models have a remarkable ability to compose disparate concepts to generate coherent samples that were not seen during training.This suggests that these models have some internal representation of high-level concepts that can be manipulated in a 'disentangled' manner. Broadly, the goal of this paper is to shed light on how this concept representation works, and how it can be manipulated. We focus on text-to-image diffusion models, though many of the ideas are generally applicable.

Our starting point is the following commonly observed structure of representations:

1. Each data point \(x\) is mapped to some representation vector \((x)^{p}\).
2. High-level concepts correspond to subspaces (directions) of the representation space.

Perhaps the best known example of this structure is in word embeddings, where semantic relationships such as Rep("king")--Rep("queen") \(\) Rep("man")--Rep("woman") suggest that high-level concepts (here, sex) are encoded as directions in the representation space . This kind of encoding of concepts has been argued to occur in many contexts, including in the latent space of variational autoencoders  and in the latent space of language models . We'll call representations of this kind _arithmetically composable_, because composition corresponds to arithmetic operations on the representation vectors. The goal of this paper is to develop arithmetically composable representations of text for score-based text to image models.

There are two main motivations. First, understanding the structure of the representation space is important for foundational progress on understanding the emergent behavior of text-controlled generative models. It is particularly interesting to study this question in the text-to-image settingbecause the multi-modality of the data makes it straightforward to distinguish concepts from inputs, and because it is not clear a priori that the models themselves build in any inductive bias towards arithmetic structure. The secondary motivation is that having such a representation would allow us to manipulate the concepts expressed by the model through linear-algebraic manipulations of representation of the input text; fig. 1 illustrates this idea.

The development of the paper is as follows:

1. We develop a mathematical formalism for describing the connection between representation structures and concepts for text-controlled generative models.
2. Using this formalism, we show that the Stein score of the text-conditional distribution is an arithmetically composable representation of the input text.
3. Then, we develop _concept algebra_ as a method for manipulating the concepts expressed by the model through algebraic manipulation of this representation. We illustrate the approach with examples manipulating a variety of concepts.

## 2 A Mathematical Framework for Concepts as Subspaces

The first task is to develop a precise mathematical formalism for connecting the structure of representations and high-level concepts. This is necessary for understanding when such representations are possible, how to construct them, and when they may fail. We must make precise what is a concept, how concepts relate to inputs \(x\), and what it means to represent concepts.

ConceptsThe real-world process that generated the training data has the following structure. First, images \(Y\) are generated according to some real-world, physical process. Then, some human looks at each image and writes a caption describing it. Inverting this process, each text \(x\) induces some probability density \(p(y x)\) over images \(Y\) based on how compatible they are with \(x\) as a caption. The (implicit) goal of the generative model is to learn this distribution.

To write the caption, the human first maps the image to a set of high-level variables summarizing the image's content, then uses these latent variables to generate the text \(X\). Let \(C\) be the latent variable that captures all the information about the image that is relevant for a human writing a caption. So,

\[p(y X=x)= p(y C=c)p(C=c X=x)c.\] (1)

Figure 1: We show that high-level concepts such as sex and artistic_style are encoded as subspaces of a suitably chosen representation space. This allows us to manipulate the concepts expressed by a prompt through algebraic operations on the representation of that prompt. Namely, we edit the representation projected on to the subspace corresponding to a concept. Note images are paired by random seed.

The random variable \(C\) captures the information that is jointly relevant for both the image and caption. Variables in \(C\) include attributes such as has_mathematician or is_man, but not pixel_14_is_red. We define concepts in terms of the latent \(C\).

**Definition 2.1**.: A _concept variable_\(Z\) is a \(C\)-measurable random variable. The _concept_\(\) associated to \(Z\) is the sample space of \(Z\).

Now, the full set of all possible concepts is unwieldy. Generally, we are concerned only with the concepts elicited by a particular prompt \(x\).

**Definition 2.2**.: A set of concepts \(_{1},,_{k}\) is _sufficient for \(x\)_ if \(p(c X=x,Z_{1:k}=z_{1:k})=p(c Z_{1:k}=z_{1:k})\) for all \(z_{1},,z_{k}_{1}_{k}\).

For example, the concept profession would be sufficient for the prompt "A nurse". This prompt induces a distribution on many concepts (e.g., background is likely to be a hospital) but these other concepts are independent of the caption given profession \(=\) nurse. Then,

\[p(y x)=_{z_{1:k}}p(y z_{1:k})p(z_{1:k} x).\] (2)

Concept DistributionsFollowing eq.2, we can view each text \(x\) as specifying a distribution \(p(z_{1:k} x)\) over latent concepts \(_{1},,_{k}\). This observation lets us make the relationship between text and concepts precise.

**Definition 2.3**.: A _concept distribution_\(Q\) is a distribution over concepts. Each text \(x\) specifies a concept distribution as \(Q_{x}=p(z_{1:k} x)\).

That is, we move from viewing text as expressing specific concept values (is_mathematician \(=1\)) to expressing probability distributions over concepts (\(Q_{x}\)(is_mathematician \(=1\)) \(=0.99\)). The probabilistic view is more general--deterministically expressed concepts can be represented as degenerate distributions. This extra generality is necessary: for example, the prompt "a person" induces a non-degenerate distribution over the sex concept.

Concept RepresentationsA text-controlled generative model takes in prompt text \(x\) and produces a random output \(Y\). Implicitly, such models are maps from text strings \(x\) to the space of probability densities over \(Y\). We'll define a representation \((x)\) of \(x\) as any function of \(x\) that suffices to specify the output distribution. We define \(f_{r}()\) as the density defined by \(r\), and assume that the model learn's the true data distribution of \(Y|X=x\):

\[f_{(x)}(y)=p(y x).\] (3)

The key idea for connecting representations and concepts is to move from considering representations of prompts to representations of concept distributions.

**Definition 2.4**.: A _concept representation_\(\) is a function that maps a concept distribution \(Q\) to a representation \((Q)\), where \(\) is a vector space. The _representation of a prompt \(x\)_ is the representation of the associated concept distribution, \((x):=(Q_{x})\).

There are two reasons why this view is desirable. First, defining the representation in terms of the concept distribution makes the role of concepts explicit--this will allow us to explain how representation structure relates to concept structure.

The second reason is that it allows us to reason about representations that do not correspond to any prompt. Every prompt defines a concept distribution, but not every concept distribution can be defined by a prompt. This matters because we ultimately want to reason about the conceptual meaning of representation vectors created by algebraic operations on representations of prompts. Such vectors need not correspond to any prompt.

Arithmetic CompositionalityWe now have the tools to define what it means for a representation to be arithmetically composable. We define composability for a pair of concepts \(\) and \(\). In the subsequent development, our aim will be to manipulate \(\) while leaving \(\) fixed.

**Definition 2.5**.: A representation \(\) is _arithmetically composable_ with respect to concepts \(,\) if there are vector spaces \(_{Z}\) and \(_{W}\) such that for all concept distributions of the form \(Q(z,w)=Q_{Z}(z)Q_{W}(w)\),

\[(Q_{Z}Q_{W})=_{Z}(Q_{Z})+_{W}(Q_{W}),\] (4)where \(_{Z}(Q_{Z})_{Z}\) and \(_{W}(Q_{W})_{W}\).

In words: we restrict to product distributions to capture the requirement that the concepts \(\) and \(\) can be manipulated freely of each other (the typical case is that one or both of \(Q_{Z}\) and \(Q_{W}\) are degenerate, putting all their mass on a single point). Then, the definition requires that there are fixed subspaces corresponding to each concept in the sense that, e.g., changing only \(Q_{Z}\) induces a change only in \(_{Z}\).

## 3 The Score Representation

We now have an abstract definition of arithmetically composable representation. The next step is to find a specific representation function that satisfies the definition.

We will study the following choice.

**Definition 3.1**.: The _score representation_\(s[Q]\) of a concept distribution \(Q\) is defined by:

\[s[Q](y)_{y} p(y z,w)Q(z,w)zw.\]

The _centered score representation_\([Q]\) is defined by \([Q] s[Q] s[Q_{0}]\).

Here, \(s[Q]\) is itself a function of \(y\) and the representation space \(\) is a vector space of functions. This is a departure from the typical view of representations as elements of \(^{p}\). The score representation can be thought of as a kind of non-parametric representation vector. The centered score representation just subtracts off the representation of some baseline distribution \(Q_{0}\).1

The main motivation for studying the score representation is that

\[s[x](y) s[Q_{x}](y)=_{y} p(y x).\]

The importance of this observation is that \(_{y} p(y x)\) is learnable from data. In fact, this score function is ultimately the basis of many controlled generation models [e.g., 1, 2, 2], because it characterizes the conditional while avoiding the need to compute the normalizing constant . Accordingly, we can readily compute the score representation of prompts in many generative models, without any extra model training.

Causal SeparabilityThe score representation does not have arithmetically composable structure with respect to every pair of concepts. The crux of the issue is that concepts are reflected in the representation based on their effect on \(Y\). If the way they affect \(Y\) depends fundamentally on some interaction between two concepts, the representation cannot hope to disentangle them. Thus, we must rule out this case.

**Definition 3.2**.: We say that \(Y\) is _causally separable_ with respect to \(,\) if there exist unique \(Y\)-measurable variables \(Y_{}\), \(Y_{}\), and \(\) such that

1. \(Y=g(Y_{},Y_{},)\) for some invertible and differentiable function \(g\), and
2. \(p(Y_{},Y_{}, z,w)=p()p(Y_{} z)p( Y_{} w)\)

Informally, the requirement is that we can separately generate \(Y_{}\) and \(Y_{}\) as the part of the output affected by \(\) and \(\)(and \(\) as the part of the image unrelated to \(Z\) and \(W\)), then combine these parts to form the final image. That is, generating the visual features associated to a concept \(\) can't require us to know the value of another concept \(\). As an example where causal separability fails, consider the concepts of species \(=\{,\}\) and \(\ =\{,\}\). It seems reasonable that there is a \(Y\)-measurable \(Y_{}\) that is the species part of the image--e.g., the presence of fur vs skin, snouts vs noses, and so forth. However, there is no part of \(Y\) that corresponds to a sex concept in a manner that's free of species. The reason is that the visual characteristics of sex are fundamentally different across species--e.g., male deer have antlers, but humans usually do not. In fig. 8 we test this example, finding that concept algebra fails in the absence of causal separability.

It turns out it suffices to rule out this case (all proofs in appendix):

**Proposition 3.1**.: _If \(Y\) is causally separable with respect to \(\) and \(\), then the centered score representation is arithmetically composable with respect to \(\) and \(\)._

That is: the (centered) score representation is structured such that concepts correspond to subspaces of the representation space.

## 4 Concept Algebra

We have established that concepts correspond to subspaces of the representation space. We now consider how to manipulate concepts through algebraic operations on representations.

To modify a particular concept \(\) we want to modify the representation only on the subspace \(_{Z}\) corresponding to \(\). For example, consider changing the style concept to Fauvism. Intuitively, we want an operation of the form:

\[s_{}(-_{})s[]+_{}s[],\] (5)

where \(_{}\) is the projection onto the subspace corresponding to the style concept. The idea is that the representation of the original prompt \(x_{}\) is unchanged except on the style subspace. On the style subspace, the representation takes on the value elicited by the new prompt \(x_{}=\).

There are two main challenges for putting this intuition into practice. First, because we are working with an infinite dimensional representation, it is unclear how to do the projection. Second, although we know that some \(_{Z}\) exists, we still need a way to determine it explicitly.

### Concept Manipulation through Projection

Following proposition 3.1, we have that

\[[Q_{Z} Q_{W}]=_{Z}[Q_{Z}]+_{W}[Q_{W}],\] (6)

for some representation functions \(_{Z}\) and \(_{W}\) with range in \(_{Z}\) and \(_{W}\) respectively. We have that the \(Z\)-representation space is

\[_{Z}=(\{_{Z}[Q_{Z}]:Q_{Z}\}).\] (7)

Our goal is to find a projection onto \(_{Z}\).

The first obstacle is that \(_{Z}\) is a function space, making algebraic operations difficult to define. The resolution is straightforward. In practice, score-based models generate samples by running a discretized (stochastic) differential equation forward in time. These algorithms only require the score function evaluated at the finite set of points. At each \(y\), we have that \((y)^{m}\). Accordingly, by restricting attention to a single value of \(y\) at a time, we can use ordinary linear algebra to define the manipulations:

**Definition 4.1**.: The \(Z\)_subspace at \(y\)_ is

\[_{Z}(y):=(\{_{Z}[Q_{Z}](y):Q_{Z}\})\] (8)

and the \(Z\)_-projection at \(y\)_, denoted \(_{Z}(y)\) is the projection onto this subspace.

If we can compute \(_{Z}(y)\) then we can just edit the representation at each point \(y\). That is, we transform the score function at each point:

\[_{}(y)(-_{Z}(y))[x_{ }](y)+_{Z}(y)[x_{}](y).\] (9)

We then draw samples from the stochastic differential equation defined by \(_{}\).

### Identifying the Concept Subspace

The remaining obstacle is that we need to explicitly identify \(_{Z}(y)\), so that we can compute \(_{Z}(y)\). The problem is that the function \(_{Z}\) in eq. (6) is unknown, so we cannot compute \(_{Z}(y)\) directly. Our strategy for estimating the space is based on the following proposition.

**Proposition 4.1**.: _Let \(Q_{W}\) be any fixed distribution over the \(W\) concept and \(Q_{Z}^{0}\) be any reference distribution over \(Z\). Then, assuming causal separability for \(,\),_

\[_{Z}(y)=span(\{s[Q_{Z}Q_{W}](y)-s[Q_{Z}^{0}Q_{W}](y):Q_{Z}\}).\] (10)The importance of this expression is that it does not require the unknown \(s_{Z}\).

We'll use eq.10 to identify \(_{Z}(y)\). The idea is to find a basis for the subspace using prompts \(x_{0}, x_{k}\) that elicit distributions of the form \(Q_{x}=Q_{Z}Q_{W}\). For example, to identify the sex concept we use the prompts \(x_{0}=\) "a man" and \(x_{1}=\) "a woman", with the idea that

\[Q_{x_{0}}=_{} Q_{W} Q_{x_{1}}=_{ } Q_{W},\] (11)

with the same marginal distribution \(Q_{W}\). We then use the prompts to define the estimated subspace as

\[}_{Z}(y):=\{\{s[x_{i}](y)-s[x_{0}](y):i=1,,k\}\}.\] (12)

That is, we write \(k+1\) prompts \(x_{0}, x_{k}\) designed so that each elicits a different distribution over \(Z\), but the same distribution on \(W\). Then, the estimated subspace is given by eq.12.

### Concept Algebra

Summarizing, our approach to algebraically manipulating concepts is:

1. Find prompts \(x_{0},,x_{k}\) such that each elicits a different distribution on \(Z\), but the same distribution on \(W\). That is, \(Q_{x_{j}}=Q_{Z}^{j}Q_{W}\) for each \(j\).
2. Construct the estimated representation space \(}_{Z}(y)\) following eq.12, and define \(_{Z}(y)\) as the projection onto this space.
3. Sample from the discretized SDE defined by the manipulated score representation2 
\[s_{}(y)(-_{Z}(y))s[x_{ }](y)+_{Z}(y)s[x_{}](y).\] (13)

Implementation of eq.13 with the diffusion model is described in appendixA.

## 5 Validity of Concept Subspace Identification

The procedure described in the previous section relies on finding spanning prompts \(x_{0},,x_{k}\) for the target concept subspace. These prompts must satisfy \(Q_{x_{j}}=Q_{Z}^{j}Q_{W}\) for some common \(Q_{W}\), and we must have sufficient prompts to span the subspace. The first condition is a question of prompt design, and is often not too hard in practice. However, it is natural to wonder when it's possible to actually recover \(_{Z}\) using only a practical number of prompts. We give some results showing that the dimension of \(_{Z}(y)\) is often small, and thus can be spanned with a small number of prompts. Note that these results rely on the special structure of the score representation, and may not hold for other representations.

First, the case where \(\) is categorical with few categories:

**Proposition 5.1**.: _Assuming causal separability holds for \(,\). If \(\) is categorical with \(L\) possible values (\(L 2\)), then \(dim(_{Z}(y)) L-1\)._

This result covers concepts such as sex, which can be spanned with only two prompts.

The next result extends this to certain categorical concepts with large cardinality, such as style. The idea is that if a concept is composed of finer grained categorical concepts, each with small cardinality, then the representation space of the concept is also low-dimensional. For example, style may be composed of lower-level concepts such as color, stroke, textures, etc.

**Proposition 5.2**.: _Suppose \(\) is composed of categorical concepts \(\{_{k}\}_{k=1}^{K}\) each with the number of categories \(L_{k}\), in the sense that \(=_{1}_{k}\). Assume \(Y\) satisfies causal separability with respect to \(,\), with \(Y_{}\) the corresponding \(Y\)-measurable variable for \(\). Further assume that there exists \(Y_{}\)-measurable variables \(Y_{_{k}}\) such that \(p(y_{} z)=_{k=1}^{K}p(y_{_{k}} z_{k})\). Then_

\[dim(_{Z}(y))_{k=1}^{K}(L_{k}-1)\] (14)Following this result, we might take the spanning prompts for style to be \(x_{0}=\) "a mathematician in Art Deco style", \(x_{1}=\) "a mathematician in Impressionist style", etc. Each of these prompts elicit a fixed distribution \(Q_{W}\) over the content, but varies the distribution \(Q_{Z}\) over style. If style is composed of finer-grained attributes, a relatively small set of such of prompts will suffice.

## 6 Experiments

We have formalized what it means for concepts to correspond to subspaces of the representation space, and derived a procedure for identifying and editing the subspaces corresponding to particular concepts in the score representation. We now work through some examples testing if this subspace structure does indeed exist, and whether it enables manipulation of concepts.

Many concepts are represented as subspacesFirst, we check whether the subspace structure does indeed exist. To this end, we generate randomly selected prompts--e.g., "a black dog sitting on the beach"--and attempt to change binary concepts expressed in the prompt. For example, we change the subject to be a cat by manipulating the concept dog--vs--cat with concept algebra. This, and other examples, are shown in fig. 2. It is clear that we are able to manipulate the target concept--providing evidence that these concepts are represented as subspaces.

Concept Algebra can disentangle hard-to-separate conceptsWe stress-test concept algebra by using it to sample images expressing combinations of concepts that occur rarely in the training data. Specifically, we look at unlikely subject/style combinations--e.g., "A nuclear power plant in Baroque painting". We accomplish this by taking a base prompt that generates a high-quality image, but with the wrong style (e.g., "A nuclear power plant"). Then we use concept algebra to edit the style. We compare this with directly prompting the model, and with concept composition [e.g., Du+21; Liu+21]. The later is a method that adds on a score representation of the style to the base prompt (without projecting on to a target subspace).

We used each of the three methods to sample images expressing to 49 anti-correlated content/style pairs. Human raters were then presented with the outcomes alongside reference images, and asked to rank them based on adherence to the desired style and content. This evaluation was replicated across 10 different raters. Refer to fig. 3 for illustrative examples. Raters consistently favored images produced by concept algebra, as highlighted in table 1. This aligns with our theory, suggesting concept algebra's adeptness in retaining content while altering style. See appendix C for further details.

Figure 2: Binary concepts (e.g. dog--vs--cat, smiling--vs--gloomy) correspond to subspaces, and can be easily manipulated with concept algebra.

Mixture concept distributionsNext, our theory predicts that we can use concept algebra to sample from mixture (non-degenerate) distributions over concept values. Consider sex. Figure 0(a) shows that \(x=}(-_{})s[x]+_{ }s[],\] (15)

and observe that we indeed get a mixture distribution (induced by "person") over sex.

Non-prompted edits to the subspace edit the conceptConcept algebra uses reference prompts (e.g., "woman" or "person") to set the target concept distribution. It's natural to ask what happens if we make an edit to a concept subspace that does not correspond to a reference prompt. In fig. 4, we sample from

\[s_{}(-_{})s[x]+_ {}(s[]+s[]).\] (16)

    & Direct Prompting & Concept Composition & Concept Algebra & All Bad \\  Average Proportion & 0.162 & 0.164 & **0.476** & 0.198 \\ Standard Error & 0.017 & 0.017 & 0.023 & 0.018 \\   

Table 1: Raters find concept algebra is more faithful to content and style than direct prompting or concept composition

Figure 3: Concept algebra is considered more faithful than other methods. Raters are shown rows of images and rank method outputs by how well they produce target style while preserving content. Each row has style-reference (leftmost), a content-reference (2nd from left), and left-to-right (here, but randomly permuted in the survey) images generated from concept-algebra, composition and direct prompting. Quantative results are in table 1.

The representation vector \(s[]+s[]\) need not correspond to any English prompt. We observe that modifications on the subspace still affect just the sex concept though--the samples are andrognous figures!

Mask as a ConceptFinally, we consider a more abstract kind of concept motivated by the following problem. Suppose we have several photographs of a particular toy, and we want to generate an image of this toy in front of the Eiffel Tower. In principle, we can do this by fine-tuning the model (e.g., with dreambooth) to associate a new token (e.g., "sks toy") with the toy. Then, we can generate the image by conditioning on the prompt "a sks toy in front of the Eiffel Tower". In practice, however, this can be difficult because the fine-tuning ends up conflating the toy with the background in the demonstration images. E.g., the prompt "a sks toy in front of the Eiffel Tower" tends to generate images featuring carpet; see fig. 4(b).

Intuitively, we might hope to fix this problem by finding a concept subspace that excludes background information. Given such a "subject subspace", we could mask the subject out of the image, generate the background, and then edit the subject back in. In appendix C.1 we explain how to construct such a subspace using the prompts \(x_{0}=\) and \(x_{1}=\). Figure 5 shows the sampled output.

## 7 Discussion and Related Work

We introduced a framework illustrating that concepts align with subspaces of a representation space. Through this, we validated the structure of the score representation and derived a method to identify the subspace for a concept. We then demonstrated concept manipulation in a diffusion model's score representation.

Concepts as SubspacesThere has been significant interest in whether and how neural representations encode high-level concepts. A substantial body of work suggests that concepts correspond to subspaces of a representation space [e.g., Mik+13; MYZ13; PSM14; GL14; Aro+15; GAM17; AH19]. Often, this work focuses on a specific representation learning approach and is either empirical or offers domain-tied theoretical analysis. For instance, in word embeddings, theories explaining observed structures depend on the unique nature of language [e.g., Aro+15; AH19]. In contrast, our paper's mathematical development is broad--we merely stipulate that the data have two views separated by a semantically meaningful space. We argue that the concepts-as-subspaces structure stems from the structure of probability theory, independent of any specific architecture or algorithm.

Our work also relates to studies that assume training data arises from a specific latent variable model and demonstrate that learned representations (partially) uncover these latent variables [e.g., HM16; HM17; HST19; Khe+20; VK+21; Eas+22; Hig+18; Zim+21]. This literature often aims for "disentangled" representations where each latent space dimension matches a single latent factor. Unlike these, we don't presuppose a finite set of latent factors driving the data.

Figure 4: Elements of the \(_{2}\) may not correspond to any prompt.

Instead, our representations define probability distributions over latent concepts, not merely recovering them. This non-determinism, as observed, is generally necessary.

Controlling Diffusion ModelsTo demonstrate the concept-as-subspace structure, we developed a method for identifying the subspace corresponding to a given concept and showed how to manipulate concepts in the score representation of a diffusion model. We emphasize that our contribution here is not the manipulation procedure itself, but rather the mathematical framework that makes this procedure possible. In particular, the requirement to manipulate entire score functions is somewhat burdensome computationally. However, the ability to precisely manipulate individual concepts is clearly a useful tool, and it is an intriguing direction for future work to develop more efficient procedures for doing so. We conclude by surveying connections to existing work on controlling diffusion models.

One idea has been to take the bottleneck layer of UNet as a representation space and control the model by manipulating this space . This work does not consider text controlled models. It would be intriguing to understand the connection to the score-representation view, as moving from manipulation of the score to manipulation of the bottleneck layer would be a large computational saving.

Concept algebra can be seen as providing a unifying mathematical view on several methods that manipulate the score function [e.g., 15, 16, 17, 18]. Du et al.  and Liu et al.  manipulate concepts via adding and subtracting scores. Negative prompting is a widely-used engineering trick that'subtracts off' a prompt expressing unwanted concepts. In section 6 and appendix D we compared against these heuristics and show that concept algebra is more effective at manipulating concepts in isolation. Couairon et al.  use score differences to identify objects' locations in images; this inspired our approach in section 6 and appendix C.1. In each case, we have seen that this kind of manipulation may be viewed as editing the subspace corresponding to some concept.

Figure 5: We can manipulate abstract concepts such as ‘subject’ of the image