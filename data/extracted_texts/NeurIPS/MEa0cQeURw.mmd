# NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics

**Anwar Said**

Vanderbilt University

anwar.said@vanderbilt.edu

&Roza G. Bayrak

Vanderbilt University

roza.g.bayrak@vanderbilt.edu

&Tyler Derr

Vanderbilt University

tyler.derr@vanderbilt.edu

&Mudassir Shabbir

Vanderbilt University

Information Technology University

mudassir.shabbir@itu.edu.pk

&Daniel Moyer

Vanderbilt University

daniel.moyer@vanderbilt.edu

&Catie Chang

Vanderbilt University

catie.chang@vanderbilt.edu

&Xenofon Koutsoukos

Vanderbilt University

xenofon.koutsoukos@vanderbilt.edu

###### Abstract

Machine learning provides a valuable tool for analyzing high-dimensional functional neuroimaging data, and is proving effective in predicting various neurological conditions, psychiatric disorders, and cognitive patterns. In functional magnetic resonance imaging (MRI) research, interactions between brain regions are commonly modeled using graph-based representations. The potency of graph machine learning methods has been established across myriad domains, marking a transformative step in data interpretation and predictive modeling. Yet, despite their promise, the transposition of these techniques to the neuroimaging domain has been challenging due to the expansive number of potential preprocessing pipelines and the large parameter search space for graph-based dataset construction. In this paper, we introduce NeuroGraph1, a collection of graph-based neuroimaging datasets, and demonstrated its utility for predicting multiple categories of behavioral and cognitive traits. We delve deeply into the dataset generation search space by crafting 35 datasets that encompass static and dynamic brain connectivity, running in excess of 15 baseline methods for benchmarking. Additionally, we provide generic frameworks for learning on both static and dynamic graphs. Our extensive experiments lead to several key observations. Notably, using correlation vectors as node features, incorporating larger number of regions of interest, and employing sparser graphs lead to improved performance. To foster further advancements in graph-based data driven neuroimaging analysis, we offer a comprehensive open-source Python package that includes the benchmark datasets, baseline implementations, model training, and standard evaluation.

## 1 Introduction

Graph Neural Networks (GNNs) have demonstrated remarkable efficacy in a variety of domains including recommendations, forecasting, and biomedical data analysis [1; 2; 3]. In human neuroimaging research, GNNs have proven valuable in capturing the complex connectivity patterns within brain functional networks but also enhance the modeling and analysis with other relevant informative features [4; 3]. For instance, examining synchronized fluctuations of functional magnetic resonance imaging (fMRI) signals provides a useful means of measuring functional network connectivity .

Neuroimaging and Graph Machine Learning (GML) are two rapidly evolving fields with immense potential for mutual collaboration. However, a significant challenge lies in bridging the gap between these domains and enabling seamless integration of neuroimaging data into state-of-the-art GML approaches . This gap is primarily attributed to the expansive number of potential fMRI data preprocessing workflows, the absence of an intuitive tool to generate fMRI graph representations for graph-based learning approaches, and the knowledge gap between the fields of neuroimaging and advanced graph machine learning . To address these challenges, the main objectives of this study are, first, a careful exploration of graph-based dataset generation with the goal of formulating a roadmap for graph-based representations of fMRI data. Second, we conduct a rigorous evaluation of graph machine learning methodologies, with a special emphasis on GNNs, examining their efficacy when applied to diverse fMRI data configurations.

The human brain, a complex network of interconnected regions, can be represented as a graph, wherein nodes correspond to contiguous segments known as Regions of Interest (ROIs), and edges represent their relationships [7; 8]. Features of the functional connectome, such as correlations between the BOLD (Blood Oxygen Level Dependent) signals between different brain regions, typically employed for downstream machine learning tasks [6; 9], can be re-envisioned as node features within attributed graph representations. These representations pave the way for a rich assortment of graph-based data representations, wherein GNNs are exceptionally well-suited . Yet, the vast potential offered by the intersection of fMRI datasets and GNNs remains untapped, due primarily to the expansive search space for data generation and the multifaceted nature of hyperparameters. In this study, we pioneer a rigorous exploration and benchmarking for GNNs, with the following primary contributions:

* We introduce NeuroGraph, a collection of static and dynamic brain connectome datasets tailored for benchmarking GNNs in classification and regression tasks including gender, age, task classification, and prediction of fluid intelligence and working memory scores. This enables an extensive exploration of brain connectivity and its associations with various cognitive, behavioral, and demographic variables. Details of the proposed datasets are provided in Table 1.
* We perform an extensive exploratory study in search of optimal graph-based data representations for neuroimaging data, implementing 15 baseline models on 35 different datasets. Additionally, we provide detailed benchmarking for the datasets we propose.

By offering NeuroGraph, we create an essential bridge between the neuroimaging and graph machine learning communities. Researchers in the neuroimaging field can more readily tap into the power of cutting-edge GNNs. Specifically, our datasets generation pipeline may guide researchers toward effectively transforming neuroimaging data into a unified graph representation suitable for graph machine learning. This integration facilitates the adoption of state-of-the-art graph-based techniques, unlocking new insights and accelerating discoveries in the neuroimaging field.

   &  &  &  \\   & \(|G|\) & \(|N|_{avg}\) & \(|E|_{avg}\) & \(d_{max}\) & \(d_{avg}\) & \(K_{avg}\) & **(dms)** & **Prediction Task** \\   & RCF-Task & 7443 & 400 & 7029.18 & 153 & 17.572 & 0.410 & 400 & 7 & Graph Classification \\   & RCF-Order & 1078 & 1000 & 45578.61 & 413 & 45.579 & 0.466 & 1000 & 2 & Graph Classification \\   & RCF-Age & 1065 & 1000 & 45588.40 & 413 & 45.588 & 0.466 & 1000 & 3 & Graph Classification \\   & RCF-F & 1071 & 1000 & 45573.67 & 413 & 45.574 & 0.466 & 1000 & - & Graph Regression \\   & RCF-WM & 1078 & 1000 & 45578.61 & 413 & 45.579 & 0.466 & 1000 & - & Graph Regression \\    & DynRF-Task & 7443 & 100 & 843.04 & 57 & 8.430 & 0.427 & 100 & 7 & Graph Classification \\   & DynRF-Gender & 1080 & 100 & 874.88 & 53 & 8.749 & 0.439 & 100 & 2 & Graph Classification \\   & DynRF-Age & 1067 & 100 & 875.42 & 53 & 8.754 & 0.439 & 100 & 3 & Graph Classification \\   & DynRF-FI & 1073 & 100 & 874.82 & 53 & 8.748 & 0.438 & 100 & - & Graph Regression \\   & DynRF-WM & 1080 & 100 & 874.88 & 53 & 8.749 & 0.439 & 100 & - & Graph Regression \\  

Table 1: Dataset statistics. \(|G|\) denotes the number of graphs, \(|N|_{avg}\) and \(|E|_{avg}\) denote the average number of nodes and edges, \(d\) indicates the degree, and \(K\) signifies the global clustering coefficient.

Related Work

While functional brain connectomes have long been recognized as a rich source of information in neuroscience and neuroinformatics [11; 12], their value has become increasingly evident in recent years . Propelled by growth in data availability and methodological breakthroughs, ML has shown remarkable efficacy on tasks such as decoding of cognitive processes [14; 15] and diagnosing mental health disorders [16; 17]. Simultaneously, there has been increased utilization of static and dynamic graph representation learning methods for brain analytics, which we briefly summarize in this section.

**Static graph representations:** GNNs have significantly evolved as a major field of exploration, offering an intuitive approach in learning from graph-structured data [18; 19; 20; 21; 22]. In a static setting, where individual data points are represented by single graphs, a variety of methods have been introduced [23; 21; 24; 22; 25; 26]. Recent studies have demonstrated the effectiveness of various approaches when applied to functional connectome data, which can be represented as different types of graphs, including weighted graphs [3; 27; 28], and attributed graphs [2; 29], among others. In benchmarking setup, BrainGB  stands out as a notable advancement, offering a unified framework for brain network analysis utilizing GNNs. Likewise, BrainGNN  introduces a specialized GNN architecture tailored for the discovery of neurological biomarkers from fMRI data. By leveraging the structured nature of the data and incorporating local information, GNNs not only enable learning from the functional connectivity patterns but also enhance modeling and analysis with other relevant informative features [9; 30; 22; 1; 31].

**Dynamic graph representations:** The field of learning dynamic graph representations in a graph machine learning setting remains relatively unexplored, especially in the realm of brain imaging . In neuroimaging, dynamic graphs are constructed to capture the time-varying interactions and connectivity patterns in the brain [2; 33; 34]. While GML methods have not been commonly employed in this domain, recent years have seen the introduction of methods that yield impressive results on dynamic brain graphs[2; 35; 36; 37; 38]. Specifically, Kim et al.  have made significant strides by introducing dynamic GNNs tailored specifically for brain graphs. These methods have showcased the potential of effectively capturing and analyzing the dynamic nature of brain connectivity, opening up new avenues for advancements in our understanding of brain function and neurological processes.

## 3 NeuroGraph

The design space for graph construction from functional connectome is vast, since a variety of methods can be employed to generate various forms of graphs, such as simple undirected graphs , weighted graphs, attributed graphs , and minimum spanning trees [39; 40], among others. Thoroughly navigating this extensive design space and evaluating all potential parameter combinations is a challenging task. While recent efforts have been undertaken to leverage GNNs for predictive modeling on neuroimaging data, a consensus has yet to be reached regarding the preprocessing pipeline and hyper-parameter configurations best suited for generating expressive graph-based neuroimaging datasets [2; 3; 41; 28; 42]. In addition, although there are a multitude of GNNs models, no benchmark datasets have been created to evaluate GML approaches on brain connectome data. To fill this gap and provide a common ground between neuroimaging and GML communities, we use publicly available datasets and only minimally preprocess the data using standard fMRI preprocessing steps. We provide an illustration of the overall NeuroGraph preprocessing pipeline in Figure 1.

### From fMRI to Graph Representations

fMRI data is typically represented in four dimensions, where the blood-oxygen level-dependent (BOLD) signal is captured over time in a series of 3-dimensional volumes. These volumes display the intensity of the BOLD signal for different spatial locations in the brain. However, since brain activity tends to exhibit strong spatial correlations, the BOLD signal is often summarized into a collection of special functional units, _brain parcels_. These units represent _regions of interest_ (ROIs) whose constituent "voxels" (a smallest three dimensional resolution) exhibit temporally correlated activity.

The Human Connectome Project (HCP)  is a publicly available rich neuroimaging dataset containing not only imaging data but also a battery of behavioral and cognitive data. We select this dataset for benchmarking and utilize the established group level Schaefer  atlases to represent the measured BOLD signal. These atlases provide a parcellation of the cerebral cortex into hierarchically organized regions at multiple granularities (resolutions).

We use resting-state and seven task fMRI paradigms from the HCP \(1200\) dataset. All fMRI scans underwent the HCP minimal preprocessing pipeline . We further regressed out six rigid-body head motion parameters and their derivatives, as well as the low-order trends, from the minimally preprocessed data. The mean fMRI time series was extracted from all voxels within each ROI for different parcellation schemes. Individual (subject-wise) ROI time-series signals were temporally normalized to zero mean and unit variance. In summary, our proposed fMRI preprocessing pipeline encompasses five steps: a) brain parcellation, removal of b) scanner drifts and motion artifacts, c) subject-level signal normalization, d) calculation of correlation matrices and finally, e) construction of static and dynamic brain graphs. For further in-depth details, we refer the reader to Appendix B.3.

Our study of these datasets encompasses two distinct modes of analysis: _static_ and _dynamic_ graph construction. We apply different GNNs to both types and perform benchmarking in five unique tasks. In the static graph construction, we investigate multiple parameters to build the graphs from the raw data, taking into consideration variations in node features, the number of nodes or regions of interest (ROIs), and the density of the graph. For node features, we take into account correlations, time-series signals, or a blend of both. For the number of nodes provided by  (i.e., ROIs), we examine three different resolutions: \(100,400\), and \(1000\) nodes. As for graph density, we consider sparse, medium, and dense configurations. For the sparse setup, we choose the top 5% of values from the correlation matrix for edge selection, whereas for the medium and dense setups, we select the top 10% and 20% of values, respectively. We note that constructing brain graphs involves a number of parameters including the choice of parcellation methods, where various brain atlases can be employed to segment the brain into regions of interest. Equally crucial is defining the number of ROIs, as it yields a significant influence on exploring brain functions. The selection of ROIs count permits the creation of brain graphs of varying sizes, allowing the opportunity to focus on both the global and granular levels of the brain. We have opted for those more likely to yield superior performance . Additional details about the complexity of the search space in benchmark dataset construction and the rationale behind these parameters are presented in Appendix B.4. We performed extensive experiments in the exploratory analysis to find the suitable combination of parameters and use a total of 15 baseline methods for benchmarking. The baselines include 10 GNNs, 3 conventional machine learning methods and 2 new architectures. Using the optimal combination of parameters in the static setting, we generate benchmark datasets for corresponding tasks in the dynamic setting. In the subsequent sections, we first describe the generation of graph-based datasets, followed by the description of each task.

### Graph Representation

The landscape of constructing brain graphs encompasses a variety of approaches. Previous research in this domain has explored various methodologies for constructing brain graphs and subsequent downstream tasks. For instance, in , distinct measures such as mean activation, node index as coordinates, spatial one-hot encoding, and correlations have been employed as node features

Figure 1: An illustration of the preprocessing pipeline, demonstrating the transition from fMRI data to the construction of both static and dynamic graphs.

with brain graphs. Additionally, a diverse range of measures including partial correlation, Pearson correlation, and geometric distances, among others, have found wide application in defining edges within brain graphs . Our static graph representation encompasses the conventional methodology of generating a static functional connectome graph from an fMRI scan, see Appendix, B.3 for additional details. We define a connectome graph as \(G=(,,X)\), wherein the node set \(=\{v_{1},v_{2},,v_{n}\}\) represents ROIs, while the edge set \(\) represents positive correlations between pairs of ROIs, determined via a defined threshold. The feature matrix is denoted by \(X^{n d}\), where \(n\) signifies the total number of ROIs and \(d\) refers to the feature vector's dimension. In our benchmarking setup, we define correlation vectors as node features. Subsequently, we define a representation vector \(_{G}\) for the graph \(G\), obtained via a GNN with an objective to perform the desired downstream machine learning task.

fMRI data comprise numerous timepoints within a scan, permitting the construction of dynamic graphs and thereby emphasizing the temporal information encapsulated within the data. This strategy has been evidenced to be notably effective within the literature . Within the dynamic context, we define a sequence of brain graphs over \(T\) timepoints, denoted as \(=\{G_{1},G_{2}, G_{T}\}\), wherein each graph \(G_{t}\) captured at index \(t\) to \(t+\) from the fMRI scan. Here, \(\) signifies the window length, set to \(50\) with a stride of \(3\) in our experiments. This setup allows us to capture functional connectivity within 36 seconds every 2.16 seconds, adhering to a common protocol for sliding-window analyses as outlined in . Following the approach in , we opt to randomly crop the ROI-timeseries data to a length of 150 timepoints. This procedure results in a total of 34 frames per subject, mitigating the computational and memory overhead in training complex models.

The procedure for constructing a graph at each time-point similar to the one applied to the static graph. The initial preprocessing, including parcellation, noise removal, and addressing head motions, remains consistent in order to construct the timeseries object. For each window, individual normalization has been performed, and then correlation matrices and corresponding graphs are constructed. Subsequently, \(\) can be utilized to generate a dynamic graph representation \(h_{dyn}\) to execute the desired downstream ML task. We refer the reader to the Appendix B.3 for further details.

### Benchmark Datasets

The benchmark datasets are primarily divided into three main categories: those constructed for classification of demographics and task states, and those constructed for estimation of cognitive traits. Each category encapsulates distinct aspects of the collected data and serves unique analytical purposes. A brief description is provided below for each of these categories with some basic statistics presented in Table 1.

**Predicting Demographics:** The category of demographic estimation in our dataset is comprised of gender and age estimation . The gender attribute facilitates a binary classification with the categories being male and female. Age is categorized into three distinct groups as in : 22-25, 26-30, and 31-35 years. A fourth category for ages 36 and above was eliminated as it contained only 14 subjects (0.09%), to maintain a reasonably balanced dataset. We introduce four datasets named: HCP-Gender, HCP-Age, DynHCP-Gender, and DynHCP-Age under this category. The first two are static graph datasets while the last two are the corresponding dynamic graph datasets.

**Predicting Task States:** The task-decoding involves seven tasks: Emotion Processing, Gambling, Language, Motor, Relational Processing, Social Cognition, and Working Memory. Each task is designed to help delineate a core set of functions relevant to different facets of the relation between human brain, cognition and behavior . Under this category, we present two datasets: HCP-Task, a static representation, and DynHCP-Task, its dynamic counterpart.

**Estimating Cognitive Traits:** The cognitive traits category of our dataset comprises two significant traits: working memory (evaluated with List Sorting)  and fluid intelligence (evaluated with PMAT24) . Working memory refers to an individual's capacity to temporarily hold and manipulate information, a crucial aspect that influences higher cognitive functions such as reasoning, comprehension, and learning . Fluid intelligence represents the ability to solve novel problems, independent of any knowledge from the past. It demonstrates the capacity to analyze complex relationships, identify patterns, and derive solutions in dynamic situations [20; 30]. The prediction of both these traits, quantified as continuous variables in our dataset, are treated as regression problem. We aim to predict the performance or scores related to these cognitive traits based on the functional connectome graphs. We generate four datasets under cognitive traits: HCP Fluid Intelligence (HCP-FI), HCP Working Memory (HCP-WM), DynHCP-FI and DynHCP-WM.

### Learning models

The functional connectome, which effectively captures the network structure of brain activity, has proven to be a valuable representation of fMRI data for machine learning, as demonstrated in numerous previous studies and our own experiments [4; 9]. Recognizing its significance in the learning process, we sought a suitable GNN framework that could effectively leverage the comprehensive functional connectome data through a combination of message passing and neural network. After thorough exploration, we implemented a GNN architecture, denoted as GNN\({}^{*}\) illustrated in Figure 2 (b), that incorporates residual connections and concatenates hidden representations obtained from message passing at each layer. To further enhance the model's performance, we employ batch normalization and a multi-layer perceptron (MLP) to effectively utilize the combined representations during training. While adaptive residual connections have been extensively explored in GNNs, we present this simple and unique architecture for brain graphs that effectively learns the representations for brain graphs .

Recently, a number of dynamic graph representation approaches in conjunction with recurrent neural networks (RNNs) such as GRU, LSTM, and transformers, have been introduced [33; 54]. However, assessing the effectiveness of GNN models in a unified dynamic setting using the existing approaches presents a significant challenge. Therefore, we implement a simple and generalized architecture tailored to process dynamic graphs for the graph classification problem, as illustrated in Figure 2 (a). Our architecture comprises two distinct modules. The first is a GNN-based learning module, responsible for deriving graph-level representations from each of the derived graph snapshot. Following this, a transformer module takes over, applying attention to the learned representations from the GNNs. Finally, the outputs are averaged into a single dynamic graph representation vector, \(_{dyn}\). This design offers a universally applicable method for evaluating multiple GNN methods within a dynamic graph setting for the downstream ML classification and regression problem.

## 4 Benchmarking Setup

In order to thoroughly evaluate the performance of brain graphs generated through different hyperparameters, we propose a series of questions, defined as hyperparameter probe. These questions seek to identify the optimal hyperparameter setting for our graph-based neuroimaging analysis and ultimately enhance the performance of the predictive models derived from it.

**Question 4.1**: _What are the optimal node feature configurations?_

The first question aims to identify the best configurations for node features. This involves an exploration and comparison of various feature representations to discern their effectiveness on the performance of the derived predictive models. In assessing node feature configurations, our analysis encompasses the correlation matrix, the time-series BOLD signals, as well as their combination. The

Figure 2: (a). Illustration of the architecture for learning dynamic graph representations. (b). Visualization of the GNN\({}^{*}\) architecture featuring residual connections and concatenated features.

correlation matrix is generated by calculating the correlation values amongst all ROIs. On the other hand, the BOLD signals are derived post the preprocessing of the input fMRI image, adhering to the preprocessing pipeline outlined in Section 3.1.

**Question 4.2**: _To what extent does the number of ROIs impact the performance of predictive modeling on graphs?_

The second question delves into the influence of varying the number of ROIs on the performance of predictive modeling. The objective is to assess how the granularity of ROIs affects the quality and the performance of the predictive models. We evaluate the use of \(100,400\) and \(1000\) ROIs.

**Question 4.3**: _To what degree does sparsifying brain functional connectome graphs impact the performance of predictive modeling? What threshold yields optimal performance?_

Our third question investigates the impact of sparsifying brain functional connectome graphs on the performance of the predictive models. It aims to establish a threshold that leads to optimal model performance in graph machine learning setting. In our exploration, we consider the top 20%, 10%, and 5% percentile values from the correlation matrices to construct the graph edges.

**Question 4.4**: _Which graph convolution approaches are preferable for the predictive modeling on brain graphs?_

Our fourth and final question delves into the exploration of various graph convolution methods, assessing their suitability for predictive modeling on brain graphs. The aim here is not only to identify, but also to recommend the most effective techniques, considering the specific features and intricacies of neuroimaging data. In this endeavor, we have put to test over \(12\) GNNs, which include two of our own implemented frameworks, to gauge their comparative performance.

By addressing these questions, we aim to set a robust benchmarking framework for graph-based machine learning methods in neuroimaging, providing invaluable insights into their optimal application.

## 5 Benchmarking Results

In this section, we introduce the baseline models, describe our experimental setup, and present the results from our preliminary exploration study. Following this, we lay out our approach to benchmarking.

### Baselines and Experimental Setup

This section outlines the specifics of our unique, generalized experimental setup designed to evaluate a range of GNN models. We consider 10 well-established GNN models: \(k-\)GNN , GCN , GraphSAGE , Unified Message Passing (UniMP), Residual GCN (ResGCN) , Graph Isomorphism Network (GIN), Chebyshev Convolution (Cheb) , Graph Attention Network (GAT) , Simplified GCN (SGC) , and General Convolution (General) 2. We also consider 3-layered Neural Network (NN), 2D Convolutional Neural Network (CNN) and Random Forest (RF) for the comparison.

In our experimental setup, we devise a graph classification architecture comprising three layers of GNNs, followed by a sort pooling aggregator . Sort pooling sorts the node features based on the last channel, selecting only the first \(k\) representations. Subsequently, sort pooling is advanced through two one-dimensional convolution layers, which are then succeeded by a two-layer Multi-Layer Perceptron (MLP). This architecture has been consistently utilized across all GNNs throughout the entire experimental setup. For the dynamic datasets, we utilize our baseline method with five different GNNs. For NN, we utilized 512, 256, and 128 hidden units in each layer, respectively. For the CNN, we utilized a four-layer model with a stride of 2, 64 kernels of size 5, and padding set to 2. This was complemented by three fully connected layers . For the Random Forest (RF) , we opted for 100 estimators, leaving the remaining parameters at their Scikit-learn defaults. All of our experiments were carried out on a system equipped with an Intel(R) Xeon(R) Gold 6238R CPU operating at 2.20GHz with 112 cores, 512 GB of RAM, and an NVIDIA A40 GPU with 48GB of memory.

Models training: We have carefully carried out the training and evaluation of each dataset in our study. Each dataset was partitioned randomly with 70% training, 20% testing, and 10% for validation. To ensure reproducibility and balance across the datasets, we employed a fixed seed, 123, for the split in a stratified setting. This stratified approach facilitated an equitable distribution of classes in each partition. Each model underwent training for 100 epochs with a learning rate of \(1e^{-5}\) for classification, and for 50 epochs with a learning rate of \(1e^{-3}\) for regression problem. Across all experiments, we set dropout to 0.5, weight decay to \(5e^{-4}\), and designated 64 hidden dimensions for both the GNN convolution and MLP layers. Furthermore, for loss functions, we utilized cross entropy for classification and mean absolute error for regression problems. All benchmarks and their source codes can be accessed on GitHub3. The static benchmark datasets are also available at PyG4.

### Exploratory Experiments and Results

Here we address the questions outlined earlier by conducting a series of experiments including the evaluation of different node feature configurations, the influence of varying numbers of ROIs, the implications of sparsity in brain graphs, and the effectiveness of diverse graph convolution approaches. Each experiment aligns with a question, thereby paving the way for comprehensive analysis and definitive conclusions.

**Performance enhancement with correlations as node features:** Our first step involves evaluating the interplay between the number of ROIs and the configuration of node features, with an aim to streamline the overall search space. For this purpose, we engage in the gender classification problem using 10 different GNNs. The results of these experiments are presented in Table 2. It is clear that employing correlations as node features consistently enhances the performance across all evaluated numbers of ROIs. However, what caught our attention was the significant variance in the results obtained through correlations and BOLD signals and the number of ROIs. The performance notably declines when correlations and BOLD signals are combined, and the number of ROIs are reduced. This motivates further investigation on how to leverage BOLD signal or perhaps obtain features from the BOLD signals to be used for learning. Furthermore, the performance of different GNNs baselines does not consistently correlate with the number of ROIs or node features.

**Performance enhancement through large ROIs and sparse brain graphs:** Our analysis extended to evaluating the efficacy of 10 GNNs on gender classification, using a varying number of ROIs and different graph densities. In addition to gender classification, we further incorporated task-state classification problem to strengthen our observations under different settings. For all the experiments, we opted for correlations as node features, a decision driven by the consistent boost they offer in performance from the last experiment. The results are presented in Table 3. An important observation from our findings reveals that larger numbers of ROIs, (1000) demonstrate superior performance in gender classification. Similarly, a significant number of GNNs exhibit improved results with the use of 1000 ROIs for the task-state classification problem. An analysis of the graph densities reveals an

   &  & **GCN** & **SAGE** & **UnMP** & **RetGCN** & **GIN** & **Cbb** & **GAT** & **SGC** & **General** & **Avg** \\   & CORR & 65.65 & 68.98 & 68.70 & 68.33 & 66.06 & 68.24 & 63.94 & 69.49 & 68.43 & 64.95 & **67.30** \\   & BOLD & 49.83 & 50.97 & 51.67 & 51.30 & 51.34 & 56.09 & 53.19 & 49.95 & 51.90 & 51.11 & 51.11 \\   & CORR+BOLD & 52.78 & 51.02 & 50.28 & 50.79 & 50.60 & 54.91 & 49.44 & 50.37 & 51.57 & 51.30 & 51.36 \\    & CORR & 72.21 & 74.10 & 61.66 & 68.57 & 70.09 & 71.89 & 58.94 & 69.35 & **75.99** & **73.69** & **69.34** \\   & BOLD & 51.16 & 51.62 & 53.94 & 51.59 & 52.31 & 55.09 & 49.07 & 50.46 & 53.24 & 53.94 & 52.22 \\   & CORR+BOLD & 51.53 & 51.90 & 52.56 & 51.57 & 52.36 & 55.56 & 50.63 & 52.13 & 52.08 & 52.61 & 53.33 \\    & CORR & **78.80** & **75.19** & **71.71** & **75.14** & **76.75** & **77.21** & **64.77** & **71.34** & 73.75 & 63.13 & **72.98** \\   & BOLD & 48.15 & 46.99 & 49.31 & 50.93 & 47.92 & 56.48 & 47.22 & 50.93 & 49.31 & 51.62 & 49.89 \\    & CORR+BOLD & 51.30 & 51.81 & 51.25 & 51.11 & 49.86 & 54.35 & 49.66 & 51.22 & 51.34 & 51.37 & 51.33 \\  

Table 2: Results of the gender classification using three distinct node feature configurations across three settings, evaluated on 10 GNNs. The configurations include CORRELATIONS (CORR), BOLD signals, and a combination of BOLD + CORRELATIONS, evaluated across 100ROIs, 400ROIs, and 1000ROIs. Avg. column indicates the average results across the row and numbers under ROIs indicates average results across each ROI. The blue notation highlights the overall best results for each GNN and red indicates average best performance across each ROI. Average best results are obtained through 1000 ROIs with sparser graphs.

intriguing trend. For instance, based on the results from Table 3, the ratio of sparse:medium:dense on the gender classification dataset is \(6:0:4\), while on the task dataset, it stands at \(4:2:4\) for 1000 number of ROIs. Furthermore, the differences in results, especially in cases where sparse graphs exhibit lower performance, are generally small. Recognizing the increased complexities stemming from memory usage, training demands, and the possibility of oversmoothing, we have chosen sparse graphs with the combination of large ROIs, and correlation features in our benchmarking setup.

### Benchmarking with Optimal Settings

Considering the optimal setting obtained through exploring search space presented in the previous section, here we present the experimental setup and benchmarking results on the proposed 10 datasets.

The classification accuracy of all baseline models is detailed in Table 4. It is evident from the results that the GNN\({}^{*}\) stands out as the leading performer. However, the Neural Network's performance is also notably impressive. Similarly, the results pertaining to the regression problems have been outlined in Table 5. The leading performer on the regression problems is again GNN\({}^{*}\). These results distinctly demonstrate that _residual connections_ coupled with message passing play a pivotal role in enhancing performance in brain networks. This synergy arises from the capacity of message passing to glean meaningful representations from highly correlated features. Simultaneously, the inclusion of residual connections empowers the utilization of the input features with the learned representations obtained through message passing. This also underscores the effectiveness of correlation features in influencing the model's performance on brain graphs.

In Table 6, we lay out the classification and regression results obtained on the dynamic datasets. Given the consideration of a basic dynamic baseline and the construction of dynamic datasets using limited dynamic lengths and number of ROIs, the performance does not quite match up to the static datasets. Nonetheless, it's worth noting that UniMP, despite the constraints, consistently demonstrates competitive performance.

## 6 Conclusion and Future Works

In this work, we introduce novel brain connectome benchmark datasets specifically tailored for graph machine learning, representing a promising avenue for addressing various challenges in neuroimaging. The inherent symmetries and complex higher-level patterns found in brain graphs make them well

 
**Dataset** & **NN** & **CNN** & **RF** & \(\)**-**CNN** & **CNN** & **MAE** & **UnMP** & **ReCoK** & **GAN** & **Chab** & **CAT** & **SCC** & **General** & **CNN\({}^{*}\)** \\ 
**HCP-Task** & \(97.75\) & 95.58 & 88.98 & 93.23 & 94.21 & 94.78 & 94.22 & 94.61 & 89.79 & 94.45 & 95.2 & 94.17 & 95.24 & **95.20** \\ 
**HCP-Encoder** & \(86.67\) & \(16.59\) & \(09.9\) & \(25.13\) & \(75.46\) & \(77.99\) & \(86.77\) & \(78.33\) & \(75.56\) & \(59.07\) & \(16.29\) & \(18.48\) & \(78.89\) & **89.07** \\ 
**HCP-Age** & \(44.23\) & \(43.38\) & \(40.84\) & \(42.72\) & \(45.68\) & \(40.94\) & \(43.85\) & \(40.00\) & \(44.98\) & \(41.97\) & \(42.25\) & \(43.47\) & \(41.03\) & \(80.23\) \\  

Table 4: Classification results in terms of accuracy on benchmark static datasets constructed with optimal setting. Blue indicates overall best results.

   &  & **GCN** & **SAGE** & **UnMP** & **ReCoK** & **GAN** & **Chab** & **CAT** & **SCC** & **General** \\   &  & Sparse & 63.33 & 72.96 & 69.35 & 67.72 & 68.06 & 69.72 & 63.70 & 70.28 & 20.37 & 67.22 \\   & & Medium & 65.65 & 66.98 & 68.70 & 68.33 & 66.06 & 68.34 & 63.94 & 69.49 & 68.43 & 64.95 \\   & & Dense & 64.44 & 68.52 & 65.00 & 68.06 & 63.70 & 66.39 & 64.26 & 69.72 & 68.43 & 61.76 \\   & &  & Sparse & 69.95 & 77.41 & 69.86 & 67.56 & 71.43 & 69.44 & 66.53 & 77.72 & **78.25** & 67.13 \\   & &  & Medium & 65.65 & 68.98 & 68.70 & 68.33 & 66.06 & 68.24 & 63.94 & 69.69 & 68.43 & 64.95 \\   & &  & Dense & 71.61 & 76.13 & 62.83 & 61.20 & 67.77 & 73.27 & 61.84 & 67.33 & 74.19 & 72.44 \\   & &  & Sparse & **82.12** & 75.46 & 77.69 & **76.67** & 78.33 & 75.56 & 59.07 & **76.2** & 76.68 & **78.09** \\   & &  & Sparse & **82.13** & 75.46 & 77.99 & **76.67** & 78.33 & 75.56 & 59.07 & **76.2** & 76.68 & **78.09** \\   & &  & Medium & 78.80 & 75.19 & 71.71 & 73.14 & 78.75 & 77.21 & 71.43 & 71.34 & 77.35 & 65.13 \\   & &  & Dense & 61.57 & 73.80 & **78.86** & 72.50 & **78.39** & **78.70** & **76.47** & 16.76 & 75.25 & 72.69 \\   & &  & Sparse & 91.50 & 91.56 & 91.43 & 92.73 & 92.14 & 88.31 & 92.55 & 92.91 & 91.40 & 91.52 \\   & &  & Medium & 90.91 & 90.80 & 91.81 & 92.75 & 92.85 & 80.01 & 93.06 & 91.51 & 91.40 & 91.22 \\   & &  & Dense & 90.50 & 91.75 & 91.55 & 91.52 & 92.92 & 87.12 & 93.18 & 93.08 & 90.49 & 94.7 \\   & &  & Sparse & 93.23 & **94.21** & 94.78 & 94.72 & 94.61 & **80.79** & 94.45 & 95.2 & **94.17** & 93.62 \\   & &  & Medium & 92.92 & 93.93 & 93.89 & 95.02 & 94.33 & 89.44 & 97.03 & 94.67 & 93.99 & 95.88 \\   & &  & Sparse & 90.64 & 93.56 & **95.76** & 94.88 & **94.64** & 88.22 & 87.24 & 94.78 & 93.18 & 90.84 \\   & &  & Sparse & 93.50 & 93.30 & 94.09 & 93.59 & 94.23 & 85.14 & 93.22 & 94.66 & 93.2 & **94.17** \\   & &  & Medium & 92.65 & 90.87 & 94.39 & **95.79** & 92.04 & 85.40 & **94.28** & 94.00 & 91.37 & 91.87 \\    & &  & Dense & **93.77** & 93.12 & 94.12 & 94.54 & 93.59 & 81.59 & 92.92 & **95.8** & 95.76 & 95.76 \\  

Table 3: Performance comparison in termssuited for graph machine learning techniques. To advance this vision, we present NeuroGraph, a comprehensive suite encompassing benchmark datasets and computational tools.

In our comprehensive exploratory study encompassing 35 datasets, we conducted a thorough analysis by running multiple machine learning models. Our key observations are as follows: (1) increasing the number of ROIs or employing large-scale brain graphs leads to improved performance compared to datasets with fewer ROIs, (2) employing a sparser graph setting enhances model performance and (3) while not intuitive, utilizing correlation as node features has significant potential to enhance model performance. Through a range of experiments across various learning objectives, we further highlight that GNNs exhibit superior performance compared to traditional NNs and 2D CNNs. These findings underscore the significant potential of GNNs in achieving improved performance across diverse tasks and underscore their suitability for graph-based Neuroimaging data analysis. Based on these insightful observations, we have developed NeuroGraph, a comprehensive benchmarks specifically designed for graph-based neuroimaging. Additionally, we provide computational tools to explore the design space of graph representation coming from Neuroimaging data, to facilitate the transformation of fMRI data into graph representations and showcase the potential of GNNs in this context. NeuroGraph serves as a valuable resource, offering a road map for researchers interested in leveraging graph-based approaches for fMRI analysis and demonstrating the effective utilization of GNNs in this domain.