# Proving Theorems Recursively

Haiming Wang\({}^{1}\)1 Huajian Xin\({}^{1}\)1 Zhengying Liu\({}^{2}\)2 Wenda Li\({}^{3}\)

Yinya Huang\({}^{4}\) Jianqiao Lu\({}^{5}\) Zhicheng Yang\({}^{6}\) Jing Tang\({}^{6,7}\) Jian Yin\({}^{1}\)2

Zhenguo Li\({}^{2}\) Xiaodan Liang\({}^{1,8}\)2

\({}^{1}\)Sun Yat-sen University \({}^{2}\)Huawei Noahs Ark Lab \({}^{3}\)University of Edinburgh

\({}^{4}\)CityU \({}^{5}\)HKU \({}^{6}\)HKUST (Guangzhou) \({}^{7}\)HKUST \({}^{8}\)Pengcheng Laboratory

{wanghm39, xinhj, issyjin}@mail2.sysu.edu.cn, wli8@ed.ac.uk, jqlu@cs.hku.hk

{liuzhengying2, Li.Zhenguo}@huawei.com, yinya.huang@hotmail.com

jingtang@ust.hk {yangzhch6, xdilang328}@gmail.com

###### Abstract

Recent advances in automated theorem proving leverages language models to explore expanded search spaces by step-by-step proof generation. However, such approaches are usually based on short-sighted heuristics (e.g., log probability or value function scores) that potentially lead to suboptimal or even distracting subgoals, preventing us from finding longer proofs. To address this challenge, we propose POETRY (PrOVE Theorems RecursivelyY), which proves theorems in a recursive, level-by-level manner in the Isabelle theorem prover. Unlike previous step-by-step methods, POETRY searches for a verifiable sketch of the proof at each level and focuses on solving the current level's theorem or conjecture. Detailed proofs of intermediate conjectures within the sketch are temporarily replaced by a placeholder tactic called _sorry_, deferring their proofs to subsequent levels. This approach allows the theorem to be tackled incrementally by outlining the overall theorem at the first level and then solving the intermediate conjectures at deeper levels. Experiments are conducted on the miniF2F and PISA datasets and significant performance gains are observed in our POETRY approach over state-of-the-art methods. POETRY on miniF2F achieves an average proving success rate improvement of \(5.1\%\). Moreover, we observe a substantial increase in the maximum proof length found by POETRY, from \(10\) to \(26\).3

## 1 Introduction

Neural theorem proving has made significant strides in recent years (Pulu and Sutskever, 2020; Han et al., 2022; Polu et al., 2022; Wang et al., 2023; Jiang et al., 2022, 2021; Wang et al., 2023; Huang et al., 2024; Thakur et al., 2024; Liu et al., 2023; Xiong et al., 2023), particularly with the integration of language models and search algorithms (Pulu and Sutskever, 2020; Han et al., 2022; Jiang et al., 2022; Yang et al., 2023; Lample et al., 2022). The combination of language models, which excel at understanding and generating human-like text, and search algorithms, which systematically explore potential solutions, has proven to be a powerful approach to discovering proofs for intricate theorems (Pulu and Sutskever, 2020; Lample et al., 2022; Jiang et al., 2022).

As shown in Figure 1(a), search-based neural theorem proving methods begin with a theorem statement to prove. A formal mathematic environment like Isabelle will first process the theorem statement and provide the initial proof state. Starting with the initial proof state, the proving process alternates between sampling new proof steps from the language model and obtaining new statesby executing the generated proof steps within the formal mathematic environment. Additionally, a search algorithm, such as best-first search or Monte Carlo Tree Search (MCTS), is employed to find a complete path of proof steps. The search algorithm selects the next state to explore based on heuristics such as the log-probability of the proof step (Polu and Sutskever, 2020; Jiang et al., 2022; Yang et al., 2023), value function scores of the proof state (Han et al., 2022; Polu et al., 2022) (in best-first search), or a PUCT score that combines both (Wang et al., 2023; Lample et al., 2022) (in MCTS). These heuristics assess the plausibility or potential value of a given step, helping to prioritize the most promising actions. However, these scores are approximate, do not ensure the correctness of the proof direction, and can lead to exploring sub-optimal or distracting subgoals. Even if the language model is capable enough to produce correct proof steps, the search algorithm, guided by short-sighted heuristics, often gets trapped exploring a detailed proof of a meaningless intermediate conjecture. This wastes time and may even cause the algorithm to fail in finding the correct proof path due to a search timeout. Moreover, as the length of the proof increases in more challenging problems, the search space expands exponentially. Consequently, the need for an accurate heuristic to guide the search becomes critical, as a myopic step-by-step approach can easily get lost in the vast expanse of the intermediate proving steps.

To address the aforementioned drawbacks, we propose POETRY, a novel approach that proves the theorem recursively, level by level. As shown in Figure 1(b), POETRY first searches for a _proof sketch_, which is defined to be a verifiable proof outline with the detailed proof of the middle conjecture replaced by a placeholder tactic, _sorry_. The _sorry_ tactic signals the formal environment to temporarily ignore the proof of the middle conjecture, assuming it as resolved. Once a validated proof sketch is established, POETRY then endeavors to prove the intermediate conjectures that remain unresolved, also in a recursive, level-by-level manner. This procedure persists until every _sorry_ keyword is substituted with a valid proof. Notably, the verified sketch at each level may still contain errors. Since POETRY uses the _sorry_ tactic to skip the proof of intermediate conjectures, these conjectures might represent false statements and be unprovable. However, they still serve as correct conjectures to prove the target theorem or conjecture at the current level, resulting in an incorrect proof sketch. For example, to prove the theorem of the commutative property of addition, \(a+b=b+a\), a false conjecture such as \(a=b\) might be used. However, when actually attempting to prove \(a=b\), we would never be able to find a valid proof at the next level. If a false proof sketch is generated and POETRY fails to find the proof for the middle conjecture, it will continue its search to identify a new proof sketch. Nevertheless, Empirical evidence indicates that verifying and ensuring the correctness of the proof sketch at each level before delving into deeper proofs significantly enhances performance. Additionally, we observe a substantial increase in the length of the proofs being able to be generated by POETRY compared with step-by-step approaches. This recursive methodology is inspired by human problem-solving techniques, where complex problems are decomposed into manageable sub-problems, each addressed using a similar recursive strategy.

Figure 1: **Comparison between the step-by-step proof and the recursive proof. (a) A step-by-step proving approach ignores the hierarchical structure inherent in the proof, treating it merely as a sequence of proof steps. The proof cannot be verified as valid until it is fully complete. (b) The recursive proving method decomposes the structured proof into different levels of verifiable proof sketches. Each proof sketch attempts to prove the target theorem or conjecture by outlining the primary steps at the current level and postponing the proof of intermediate conjectures to the next level.**

By adopting this approach, POETRY not only improves the efficiency of its search process but also increases the overall success rate in discovering valid proofs.

We conduct extensive experiments on the theorem proving datasets miniF2F (Zheng et al., 2021) and PISA (Jiang et al., 2021) to validate the effectiveness of our proposed approach. POETRY significantly outperforms previous approaches, achieving a pass rate of \(42.2\%\) on both the miniF2F valid and test datasets, respectively. With a \(5.1\%\) absolute improvement on average over the previous state-of-the-art. Additionally, our ablation study shows that with recursive theorem proving, we obtain a \(3.9\%\) absolute improvement on average compared with step-by-step baselines. Our case study also reveals that POETRY can find proofs substantially longer compared with sequential step-by-step proving methods, the maximum proof length increases from \(10\) to \(26\) compared to the step-by-step baseline in the PISA dataset.

## 2 Preliminary

### Formal Mathematic Environments

We choose Isabelle (Paulson, 1994) as our formal environment. It is widely used for formal verification purposes in academia and industry (Gesellensetter et al., 2008; Klein et al., 2009; Zhang et al., 2024). It employs a structured proof language called Isar (Wenzel et al., 2004), which facilitates the creation of human-readable proofs and bridges the gap between formal verification and human understanding. As illustrated in Figure 1(a), Isabelle processes each proof step (or tactic) and provides feedback. If the proof step fails to apply, an error message is returned. Otherwise, Isabelle returns a proof state along with a special variable, proof level, indicating the current level after applying the step. In the Isabelle theorem prover, the proof level indicates the depth within a structured proof. This level increases with commands like _have_, _obtain_, and _show_, which introduce new subgoals or conjectures in the proof. Conversely, it decreases with commands like _by_, _qed_ and _done_, which conclude a proof block or subgoal.

Isabelle is well-suited for POETRY to accomplish recursive theorem proving. The Isar language is elegantly structured in a level-by-level format, and it contains proof level that can be easily used to identify each level. However, the recursive proving technique proposed by POETRY is not specific to Isabelle; the same framework can be extended to other formal mathematical environments like Lean (de Moura et al., 2015), Coq (Barras et al., 1997), and HOL (Harrison, 2009), with additional engineering effort to accommodate the proving strategies. These environments also provide mechanisms to temporarily skip parts of proofs, similar to Isabelle's _sorry_ tactic, such as Lean's _sorry_, and Coq's _Admitted_. We will leave the extension of POETRY to other formal environments for future work.

### Search-Based Neural Theorem Proving

Search-based neural theorem proving mostly employs the approach introduced by GPT-f (Polu and Sutskever, 2020). In this method, a pre-trained causal language model predicts the next proof step based on the current proof state and optional context. The language model is trained using data formatted as follows:

INPUT: CONTEXT $(context) GOAL $(proof state) STEP  OUTPUT: $(proof step)

where \(\$()\) represents the substitution operation, and context denotes the preceding proof steps leading to the current proof state. At test time, GPT-f employs a best-first search strategy to identify a sequence of proof steps that solve the problem. Specifically, The proof search algorithm constructs a tree-like search structure, where each node represents a proof state and each edge represents a proof step. Starting from the root node, the proof search continuously selects the unexplored node with the highest score and performs an expansion. The score for each node is the cumulative log probability of the proof steps that led to the node. During expansion, the language model receives the node's proof state and preceding context, then samples \(e\) new proof steps. Isabelle subsequently processes these proof steps, generating new proof states or error messages. The search continues until a proof is found or the computational budget is exhausted.

## 3 Methodology

```
1:functionExtractProofSketch(\(\), \(\))
2:\(\)\(\): a list of pairs of the format "(proofStep, proofLevel)"
3:\(\)\(\): the starting index in \(\) for processing
4:\(\), \(\) empty list, empty list
5:\(\_,[]\)\(\) Obtain the current proof level being extracted
6:\(\)
7:while\(\)do\(\) Extraction ends after the proof level drops below the current proof level
8:\(,[ ]\)
9:\(\_,[+1]\)
10:if\(=\)then
11:\(.()\)
12:\(+1\)
13:elseif\(>\)then
14:\(.(+\)"\(\)"\(\) Replace the next level proof with \(\)
15:\(,\) ExtractProofSketch(\(,+1\))
16:\(.()\)
17:endif
18:endwhile
19:\(.()\)
20:return\(,\)
21:endfunction ```

**Algorithm 1** Core data curation process

### Recursive Data Construction

**Proof sketch extraction.** As illustrated in Figure 1(b), to prepare recursive proving data, we need to split theorems into blocks of proof sketches. Each proof sketch focuses solely on the target theorem, conjectures, or subgoals, with the detailed proof of intermediate conjectures or subgoals replaced by the \(\) tactic. Algorithm 1 presents the pseudocode for the sketch data extraction process. POETRY initially inputs the complete theorem text into Isabelle, which parses it into a sequence of proof lines, containing proof steps and corresponding proof levels. Subsequently, the list of proof lines is passed to the ExtractProofSketch function with the index set to 0, initiating the extraction of all proof sketches. The sketch proof extraction process starts by identifying the current proof level, which is determined by the level of the proof step at the initial index (Line 5). Proof steps that are on the same level as the target theorem, conjectures, or subgoals are those that directly focus on proving the target. Our goal is to retain proof steps with a proof level equal to the current proof level (Lines 10-12) and replace higher-level proof steps with the \(\) tactic (Lines 13-16). We defer the extraction of higher-level proofs to the recursive call of ExtractProofSketch in Line 15. Finally, the function will return a list of extracted proof sketches, each containing only the current level of proof, as illustrated in Figure 1(b).

**Training data construction.** Following the extraction of proof sketches, POETRY follows Jiang et al. [2022a] and uses PISA, an interactive environment built on top of Isabelle, to extract proof states for each proof step. Subsequently, the proof states and proof steps are reformatted into lines in Equation 1 and used as training examples to fine-tune the language model. Notably, although \(\) is an independent tactic in Isabelle, POETRY integrates the \(\) tactic into the preceding proof step (Line 14 in Algorithm 1). This enables the language model to predict the intermediate conjectures and the \(\) tactic simultaneously. For example, a proof step with the \(\) keyword would appear as \(\)\(+=\). Merging the \(\) tactic is crucial to ensure that the language model generates proof steps at the current level and postpones higher-level proofs using the \(\) tactic. Without this merge, the model must determine the use of \(\) solely based on the context and proof state, which offers no guarantee that the model will generate the necessary \(\) after stating a conjecture or subgoal. This approach ensures that deep-level proofs are deferred correctly.

### Recursive Best-First Search

To prove theorems recursively, POETRY introduces a novel recursive best-first search (recursive BFS) algorithm to conduct a level-by-level proof search. Figure 2 illustrates a complete walkthrough. In general, recursive BFS employs the best-first search technique to search for proof sketches at each level. When a proof sketch is found at a certain level, the algorithm pauses the search at this current level and then proceeds to the next level to solve the skipped middle conjectures by this current level. Once all sketches are found and middle conjectures or subgoals are resolved, a complete proof is achieved. Recursive BFS enhances the generic best-first search to handle multi-level proofs and ensures that the search can pause and continue across different proof levels, adapting BFS to dynamically shift between current and subsequent proof layers based on the progress and outcomes of proof sketches. Below, we will introduce the core elements in the recursive BFS: the sorry edge and the node status. For the complete updating rules of nodes status and proof search terminate conditions, please refer to Appendix A.1.

**Sorry edge and node status.** As shown in Figure 2(a), each node in the proof tree is a proof state, and each edge is a proof step. In a proof state, once a tactic contains a "sorry" keyword (usually after a conjecture or subgoal), we use a special sorry edge to connect the parent node and the child node. Then the sorry edge attaches the root node of the next proof level with an unproved conjecture or subgoal. Such root nodes have a score of 0 and will not be selected in the current-level proof search. Moreover, we attach each node in the search tree with one of the status labels: OPEN (the node is open, and no proof has been found so far), FAILID (the node is failed when all potential subproofs or child nodes stemming from it are unable to establish a valid proo), PROVED (the node is proven and part of the successful proof), and HALF-PROVED. A HALF-PROVED node means it belongs to the trajectory that has successfully found a complete proof sketch but contains special sorry edges with unsolved next-level subgoal or mid-conjecture. Only after all the mid-conjectures or subgoals in the sorry edges from the HALF-PROVED node to the PROVED node are proved will the node be switched to a PROVED node, as illustrated in Figure 2(f).

Using recursive best-first search, POETRY can generate a verifiable proof sketch at each proving level before proceeding to prove the middle conjectures or subgoals at the next level. In essence, POETRY breaks down a lengthy proof into manageable, shorter proof sketches, preventing the

Figure 2: **A walkthrough example of recursive BFS. Each node in the proof tree is a proof state and each edge is a proof step. (a) The proof search begins by finding the proof sketch at the first level using BFS. The search is paused upon identifying a successful proof path, marked with P and HP nodes. This proof path contains a sorry edge, indicating that it includes skipped conjectures or subgoals that must be addressed in the next level. (b) Recursive BFS enters the next level of proof search to attempt to prove the skipped subgoal from the first level. Unfortunately, the proof search for this subgoal fails due to a lack of valid nodes to explore, and the search returns to the first level. (c) After the failed attempt to prove the subgoal, the previously established proof path at the first level becomes invalid. Consequently, we backpropagate the failure from the second level’s root node up to the first-level root node, updating all the HP nodes to an O node. (d) At the first level, with the status set to open for searching proofs, we continued to explore new proof paths. Fortunately, we discovered another proof path. However, this path also contained a sorry edge with a skipped conjecture that needs to be proved at the next level. (e) Similar to (b), the recursive BFS proceeds to the next level to search for a proof for the previously skipped conjecture. It successfully finds a proof path without any “sorry” edges (denoted as P nodes), indicating that the conjecture has been proven successfully without any skipped intermediate conjectures or subgoals in the proof path. (f) After finding the sub-level proof, the recursive BFS returns to the first level and backpropagates the PROVED message to the root, completing the proof.**search space from expanding exponentially as the proof length increases. This approach allows search-based methods to find more challenging and longer proofs without necessitating a highly performant value function model to guide the proof search procedure.

## 4 Experiments

### Experimental Setup

This section presents our experimental setup, detailing the baselines and evaluation metrics. The implementation details are covered in Appendix A.2.

**Baseline methods.** To fairly compare POETRY with classic step-by-step baselines like GPT-f , we implement an Isabelle version of GPT-f, denoted as _GPT-f Baseline_. This baseline model is trained on the same dataset as POETRY, with the only modification being the removal of all _sorry_ keywords in the proof steps. All hyperparameters and setups for training and the BFS search are identical to POETRY to ensure a fair comparison.

Notably, the GPT-f Baseline is similar to Thor , except for three main differences. Firstly, GPT-f Baseline does not use Sledgehammer , nor replace the _smt_, _metis_ tactic with <hammer> in the proof step for training. Secondly, GPT-f Baseline fine-tunes a 1.3B parameter proofGPT , whereas Thor uses a 700M model pre-trained on The Pile . GPT-f Baseline also uses a newer version of Isabelle which contains more state action pairs for training (detailed in Section A.3). Thirdly, during the proof search, the GPT-f Baseline utilizes the beam-search decoding method instead of sampling to generate proof steps for each proof state.

Aside from the GPT-f Baseline, we also include state-of-the-art search-based neural theorem-proving methods. PACT , FMSCL , Leandojo , and COPRA  are works focusing on the Lean formal environment.3 Conversely, Thor , Thor with expert iteration on auto-formalized data  and Thor + Magnushammer  are works done in Isabelle. Moreover, for methods with LLMs, COPRA is an in-context learning agent that uses GPT-4  to generate proof steps and prove the theorem step by step.

We do NOT compare our methods with LLM-based proving approaches like DSP , Lyra , or LEGO-Prover . These approaches employ general-purpose large language models (LLMs), such as ChatGPT or GPT-4, which feature several orders of magnitude more parameters than the models considered in our study. Moreover, these methods typically utilize proofs in natural language to guide the generation of formal code without searching and attempting to solve each problem 100 times. In contrast, POETRY provides a performance evaluation at pass@1, attempting to prove the theorem once for each problem.

**Evaluation datasets and metrics.** For evaluation, we use two datasets, the miniF2F dataset , and the PISA . The miniF2F dataset comprises 488 problems with varying levels of difficulty, ranging from basic algebra and number theory, originating from the MATH dataset , to more challenging problems found in the AIME4 and IMO . The problems are divided into valid and test sets, with 244 problems each. The miniF2F dataset only contains problem statements and we only evaluate our method on this dataset, without any training. The other dataset we adopt is the PISA test set, which comprises theorems from the Archive of Formal Proofs  and the Isabelle standard library . To better understand how POETRY performs in complex problems with multiple levels, we subdivided the test set into two subsets: single-level and multi-level. The PISA single-level subset contains problems with only one level in the ground truth human-written proofs, whereas the PISA multi-level subset includes problems with multiple proof levels. A more comprehensive analysis of the PISA dataset is shown in Appendix A.3. For evaluation metrics, we follow Jiang et al. , Yang et al.  and use pass@1 as the evaluation metric, where each theorem in the dataset is proved once by POETRY. Then we calculate the proportion of the theorems being successfully proven.

### Main Results

**Comparison with language model-only baselines.** As shown in Table 5, we compare POETRY with baselines that only utilize language models to search for proofs. Thor w/o sledgehammer is the language model-only version of Thor (Jiang et al., 2022). It does not call the sledgehammer during the proof search. Our reproduced GPT-f Baselines outperform Thor w/o sledgehammer by \(13.7\%\) in miniF2F and \(10.6\%\) in the PISA test set. This performance boost is mostly due to using the beam-search decoding strategy during the proof search, as we observe the performance of the GPT-f Baseline with sampling drops by \(6.8\%\) compared with the beam-search version. This is because the beam-search decoding method is guaranteed to produce \(e\) different proof steps for each proof state, whereas the sampling will produce duplicate proof steps, making the actual number of proof steps generated per expansion smaller than \(e\). The remaining performance improvements are mostly contributed by larger model sizes and better pertaining.

Compared with the GPT-f Baseline, we can observe the benefit of the recursive theorem proving. POETRY outperforms GPT-f Baselines by \(3.9\%\) in the miniF2F dataset on average, and \(0.7\%\) in the PISA test set. The modest performance gain observed in the PISA test set is primarily attributed to the skewed distribution of problem complexity, with the majority of problems containing only a single proof level (see Table 3). POETRY executes nearly identically to the GPT-f Baseline when encountering proofs with only one level, resulting in similar performance within the single-level subset. In contrast, POETRY achieves a \(2.5\%\) improvement on the multi-level subset. Furthermore, POETRY solves a very distinct set of theorems compared with GPT-f Baseline in PISA, with \(99\) out of \(1109\) theorem solved by POETRY can not be proved by GPT-f Baseline, taking up \(4.4\%\) in total. This outcome well supports the effectiveness of our proposed recursive proving method. Moreover, the gap between step-by-step approaches and POETRY does not end here. The effectiveness of POETRY will become even more pronounced as the language models are continuously improved and solve more complex proofs, where the bottleneck caused by searching comes to the fore yet POETRY is demonstrated effective for searching.

   Success rate & miniF2F-valid & miniF2F-test & PISA & single-level & multi-level \\  Thor w/o sledgehammer & \(25.0\%\) & \(24.2\%\) & \(39.0\%\) & - & - \\ GPT-f Baseline & \(39.3\%\) & \(37.3\%\) & \(49.0\%\) & **65.5\%** & \(11.1\%\) \\ \(-\) with sampling decoding & \(30.3\%\) & \(31.5\%\) & \(43.2\%\) & \(57.8\%\) & \(9.8\%\) \\  POETRY & **42.2\%** & **42.2\%** & **49.7\%** & \(65.4\%\) & **13.6\%** \\   

Table 1: **Comparing with baseline.** The table displays the pass@1 success rates of the baselines and POETRY, The highest success rates for each set are highlighted in bold.

   Success rate & environment & miniF2F-valid & miniF2F-test \\  _Baselines_ & & & \\  PACT (Han et al., 2022) & Lean & \(23.9\%\) & \(24.6\%\) \\ Leandojo (Yang et al., 2023) & Lean & - & \(26.5\%\) \\ FMSCL (Pou et al., 2022) & Lean & \(33.6\%\) & \(29.6\%\) \\ COPRA (Thakur et al., 2024) & Lean & - & \(30.7\%\) \\  Thor (Jiang et al., 2022) & Isabelle & \(28.3\%\) & \(29.9\%\) \\ Thor + expert iteration (Wu et al., 2022) & Isabelle & \(37.3\%\) & \(35.2\%\) \\ Thor + Magnushammer (Mikula et al., 2023) & Isabelle & \(36.9\%\) & \(37.3\%\) \\  _Ours_ & & & \\  POETRY & Isabelle & **42.2\%** & **42.2\%** \\   

Table 2: **Comparing with state-of-the-art search-based methods on the miniF2F dataset.** The table displays the pass@1 success rates of previous works and POETRY, The highest success rates for each set are highlighted in bold. 6

**Comparison with state-of-the-art methods.** In Table 2, we illustrate the proportion of successful proofs found on the miniF2F dataset. Due to the larger amount of formal data, as well as the help of hands in ATP like the sledgehammer, the approaches using Isabelle tend to achieve a higher pass rate compared with approaches using Lean environments. Our proposed POETRY significantly outperforms all such approaches. POETRY outperforms Thor+Magnushammer by \(5.1\%\) on average, the highest performance on the miniF2F dataset with the search-based method at pass@1.

Notably, the recursive proving method is orthogonal to these baseline approaches. It can be further improved with the use of Sledgehammer or Magnushammer (Jiang et al., 2022; Mikula et al., 2023), running expert iteration on the training set (Polu et al., 2022; Wu et al., 2022), using retrieval augmented proof step generation techniques (Yang et al., 2023), or even better search algorithm in each level (Wang et al., 2023; Lample et al., 2022). As these are not the focus of the current paper, we leave the integration for future work.

### Analysis

**Can POETRY find longer proof?** Figure 3 (a) and (b) compares the proof length of proofs discovered by the GPT-f Baseline and POETRY in both the miniF2F dataset and the PISA test set. It can be observed that the proof lengths found by POETRY are longer than those found by the GPT-f Baseline. The average proof length increases from \(1.47\) to \(2.13\) in the miniF2F dataset and \(1.62\) to \(2.09\) in the PISA test set. Prominently, the maximum proof length increases from \(3\) to \(18\) compared with the GPT-f Baselines in the miniF2F dataset, and from \(10\) to \(26\) in the PISA test set. This proof length is unattainable without a recursive proving method. By comparison, the maximum proof length found by Leandolo in the miniF2F test set is \(4\), with an average proof length of \(1.35\). Therefore, it's evident that POETRY expands the possibility of discovering longer proofs and addressing more challenging problems.

**Can POETRY find harder proof?** The ability to find longer proofs does not necessarily imply the ability to find harder proofs. We analyze this issue from two perspectives. First, POETRY does not generally produce longer proofs than the GPT-f Baseline for problems both approaches successfully solve. Algorithmically, POETRY operates almost identically to the GPT-f Baseline,

Figure 3: **(a)&(b) Proof length comparison between POETRY and GPT-f Baseline.** The y-axis is shown in the log scale. (a) Proof length’s histogram of found proof in miniF2F dataset. most of the proof found is within 3 steps long, especially for GPT-f Baselines, but POETRY managed to find longer proof up to 18 proof steps in one proof. (b) Proof length’s histogram of found proof in the PISA dataset. POETRY discovers a lot more proofs with longer proof lengths. **(c), (d) and (e) Number of problems solved by GPT-f Baseline and POETRY based on the length of the ground truth proofs. (a) The distribution in the entire PISA dataset. POETRY has a clear tendency to solve problems with longer ground truth proofs. (b) The distribution in the single-level subset. In this subset, POETRY and GPT-f Baseline should behave nearly identically; therefore, there are not many differences as expected. (c) The distribution in the multi-level subset. POETRY has a distinctive advantage over GPT-f Baseline. This is the subset where all the complex theorems exist.

only progressing to deeper levels when it identifies a complete proof sketch. Therefore, we expect similar proof lengths for problems solved by both methods. Statistically, 82.3% of the problems solved by both methods have identical proof lengths, and 96.0% have proof length differences of less than 3 steps, attributable to algorithmic randomness. Occasionally, POETRY generates longer proofs with redundant steps, as shown in Figure 6 in the Appendix. This is due to POETRYs greedy exploration mechanism, which sometimes explores dummy sketches. These cases are rare (2.4% of solved problems where POETRYs proof is 3 steps longer than GPT-f Baselines). We believe this issue can be addressed by implementing a value function to prioritize informative sketches over redundant ones in future work.

Secondly, we included histograms displaying the number of problems categorized by the lengths of the ground truth proofs (Figure 3 (c), (d), and (e)). From these figures, it is evident that POETRY shows a marked tendency to solve harder problems (i.e., those with longer ground truth proofs) and consistently outperforms the GPT-f Baseline across various levels of problem difficulty within the multi-level subset. Therefore, we conclude that POETRY demonstrates a distinct advantage over the GPT-f Baseline, showcasing its ability to solve more complex problems.

**Case study.** As illustrated in Figure 4, we compare the proof found by the POETRY with the failed attempts by the GPT-f Baseline. The theorem n_mult_closed states that if a polynomial \(f\) belongs to the carrier set of polynomials \(P\), then the operation n_mult applied to \(f\) results in a polynomial that also belongs to \(P\). As shown in Figure 4(a), the proof found by the POETRY contains two levels, marked with different shades of blue. The first level is completed by first showing two main properties: (i) Zero polynomial condition (the first show statement in Line 2): For any integer \(n\) greater than the degree of \(f\), n_mult\(fn\) must be zero. (ii) Closure under carrier (the second show statement in Line 7): For any integer \(n\), the result n_mult\(fn\) must be within the carrier set \(R\). When proving the first level, the detailed proof of these two properties will be skipped with the sorry tactic. After the first level of the proof has been found, POETRY searches for the proof of these properties one by one in the next level. In contrast, the GPT-f Baseline failed to find valid proof for this problem, resulting in a search timeout after reaching 600 seconds of time limit. Two failure search trajectories are selected and shown in Figure 4(b). For proof path 1, the proof searches astray and tries to utilize a more complex way to prove the first property, resulting in a timeout. The GPT-f Baseline also identified the first two steps in POETRY's proof. However, this proof path never had the chance to be further explored before the timeout occurred. From this case, we can see that by recursively proving the theorem, the proof with \(11\) steps is broken down into \(3\) proof sketches with a maximum length of \(4\). Therefore, POETRY effectively prevents the proof search from wasting too much time on searching for useless mid-step conjectures. These are typical successful cases for POETRY; additional failure cases can be found in Section A.4 of the Appendix.

## 5 Related Works

**Search-based neural theorem proving.** Our work is closely related to prior work on step-by-step search-based nerual theorem proving. GPT-f  is the first to apply transformer-based language models to generate single-step action for theorem proving in Metamath. With the ability to generate arbitrary proof text, modern ATPs advance drastically and are capable of proving theorems in complex ITPs like Lean  or Isabelle .

Figure 4: **Case comparison between POETRY and GPT-f Baseline. (a) Recursive proof found by POETRY in 71.2 seconds, the proof contains two proof levels. (b) Failure-proof paths found by the GPT-f Baseline. GPT-f Baseline failed to find proof due to timeout after 600 seconds. We select two different failure proof paths found by GPT-f Baseline.**

1994). The follow-up work PACT Han et al. (2022) proposes auxiliary pre-training tasks for action-generating language models. Polu et al. (2022) uses expert iteration and syntactic data to bootstrap the language model's performance. Most recently, HTPS Lample et al. (2022) plugs in Monte-Carlo Tree Search Silver et al. (2016) in this framework and applies an online version of expert iteration. DT-Solver Wang et al. (2023) improves HTPS by enabling backtracking during proof search, increasing the robustness. LeanDjo Yang et al. (2023) retrieve possible premise to assist the generation of a single proof step. Lisa and Thor Jiang et al. (2021, 2022) tackle theorem proving in Isabelle, which combines traditional ATPs and language models to suggest proof steps, in a neuro-symbolic way. All theorem-proving method introduced above proves theorems step-by-step, with short-sighted heuristics guiding the search to find a correct proof path.

**Nerual theorem proving with a large language model.** Another popular paradigm for automated theorem proving resorts to large pre-trained language models for proof context generation in an in-context-learning manner, without finetuning on formal mathematic datasets. DSP Jiang et al. (2022) uses OpenAI Codex LLM Chen et al. (2021) to generate the entire proofs guided by informal proof. It suffers from hallucination problems with LLM and requires multiple attempts for each problem to ensure correctness. Lyra Zheng et al. (2023) improves on DSP and uses GPT-4's auto-correction ability to correct previous error attempts. Baldur First et al. (2023) also uses Minerva Lewkowycz et al. (2022) for whole proof generation using the initial theorem statement. To prevent hallucination, Baldur finetunes a small model that uses error messages to correct the generated faulty proof. MUSTARD Huang et al. (2024) generates the problem and the solution simultaneously with ChatGPT and uses Lean as a verifier to check the correctness of the generated content.

**Subgoal-based AI agents.** Another domain that is closely related to our paper is subgoal-based AI agents Wang et al. (2023, 2023); Wei et al. (2023). These agents decompose the major tasks into small sub-objectives and tackle them one by one. However, most AI agents do not focus on formal mathematic problems, which require compiling the rules of formal environments. LEGO-Prover Wang et al. (2023) approaches the theorem-proving problem by decomposing the target into subgoal lemmas and building the proof block by block. However, not all the subgoals can be easily decomposed into lemmas. Many mid-conjectures or subgoals are specific to the current problem and involve shared variables defined in the previous proving process, making them unsuitable for extraction as lemmas, or sometimes impossible to extract as lemmas. kSubS Czechowski et al. (2024) utilizes a subgoal generation model to produce mid-step proof states and employs a policy model to generate paths in between. However, the generated proof must adhere to the generated proof states, thus the method cannot be applied to more complex real-world datasets like miniF2F. Moreover, the proposed subgoal generator constrains the ability of the policy model to explore freely and find solutions beyond predefined subgoals.

## 6 Limitations

The proposed method proves theorems recursively by producing a verifiable proof sketch at each level. Although this leads to consistent performance improvements, there is no theoretical guarantee that it will avoid the problem of infinite action space for each proof step generation and the problem of exponential search space with respect to the depth of the search tree. Furthermore, applying the framework of POETRY to other formal languages such as Lean or Coq is straightforward but would require a non-neglectable amount of engineering efforts on some language-specific aspects.

## 7 Conclusion

In this work, we introduce a novel theorem-proving method, POETRY, which recursively proves the theorem in a level-by-level manner. POETRY searches for a verifiable proof sketch in each level, focusing on proving the target theorem, conjecture, or subgoals in the current level, and utilizes a special _sorry_ tactic to defer detailed proofs of mid-conjectures or subgoals. POETRY introduces a fundamentally different theorem-proving paradigm to the community, preventing short-sighted proof searches that easily go astray. The recursive dataset decomposes long proofs into short proof sketches within a tractable search space. Extensive experiments show that POETRY can indeed improve the pass rates on the miniF2F dataset and PISA test set, and can find longer proofs compared to step-by-step approaches.