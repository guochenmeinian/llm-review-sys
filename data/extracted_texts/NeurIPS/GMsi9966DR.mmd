# DeepITE: Designing Variational Graph Autoencoders for Intervention Target Estimation

Hongyuan Tao

Ant Group

Hangzhou, China

thy.qy@antgroup.com

Equal contribution.

Hang Yu

Ant Group

Hangzhou, China

hyu.hugo@antgroup.com

&Jianguo Li

Ant Group

Hangzhou, China

lijg.zero@antgroup.com

Equal contribution.

Equal contribution.Corresponding author.

###### Abstract

Intervention Target Estimation (ITE) is vital for both understanding and decision-making in complex systems, yet it remains underexplored. Current ITE methods are hampered by their inability to learn from distinct intervention instances collaboratively and to incorporate rich insights from labeled data, which leads to inefficiencies such as the need for re-estimation of intervention targets with minor data changes or alterations in causal graphs. In this paper, we propose DeepITE, an innovative deep learning framework designed around a variational graph autoencoder. DeepITE can concurrently learn from both unlabeled and labeled data with different intervention targets and causal graphs, harnessing correlated information in a self or semi-supervised manner. The model's inference capabilities allow for the immediate identification of intervention targets on unseen samples and novel causal graphs, circumventing the need for retraining. Our extensive testing confirms that DeepITE not only surpasses 13 baseline methods in the Recall@k metric but also demonstrates expeditious inference times, particularly on large graphs. Moreover, incorporating a modest fraction of labeled data (5-10%) substantially enhances DeepITE's performance, further solidifying its practical applicability. Our source code is available at [https://github.com/alipay/DeepITE](https://github.com/alipay/DeepITE).

## 1 Introduction

Causal analysis in complex systems encompasses a series of steps beginning with causal discovery , which aims to delineate the causal structure, followed by the identification and estimation of causal effects . Within this framework, a critical yet often overlooked component is Intervention Target Estimation (ITE) , alternatively known as Intervention Recognition . ITE is the process of pinpointing which variables in a system have been subject to intervention, particularly when such interventions are opaque or not directly manipulable. This process not only fosters a deeper understanding of the causal mechanisms driving specific outcomes, which resonates with the principles of explainable AI (XAI), but also plays a pivotal role in recognizing variables that can be strategically altered to produce desired effects, aligning with the concept of algorithmic recourse .

To illustrate, consider the application of ITE in root cause analysis (RCA) within a microservices system. These systems consist of a network of services working in concert to deliver software functionality. When a service failure occurs, such as a system outage or performance degradation, it becomes imperative to identify the root cause. ITE is the key that unlocks definitive insight into the RCA process. It methodically pinpoints the specific services whose malfunctions--stemming from network issues, hardware failures, or security breaches--lead to the anomalies in question. ITE notonly equips operators with a clear and logical explanation for the system's alerts, enhancing their comprehension of the issues at hand, but it also empowers them to implement immediate and effective countermeasures and fortify the system against future incidents. Beyond RCA in microservice systems, ITE's applicability extends to a multitude of domains, from unraveling the genetic factors involved in diseases within biomedicine, to tracing the determinants of user behavior for marketing.

Unfortunately, the field of ITE has not been thoroughly explored, often resulting in intervention targets being relegated to secondary outputs from causal discovery rather than being a dedicated field of inquiry. Only recently, Varici _et al._ pioneered the exclusive study of learning intervention targets in linear SCMs. In parallel, Li _et al._ approached the problem from the perspective of RCA, coining it intervention recognition. Finally, Yang _et al._ extended ITE to non-linear SCMs. This handful of methods can only identify the targets for an intervention instance3 with a large sample size, relying on an accompanying dataset of known observational data, all within the confines of a fixed causal graph. The drawbacks of these strategies are twofold: **From the learning perspective,** they independently map data to intervention targets for each intervention instance, disregarding the potential correlations among distinct instances. In RCA scenarios, for example, various incidents could stem from the same underlying service problem. A collaborative learning approach, which considers all instances collectively, could more effectively elucidate the data-intervention target relationships. Moreover, these methods often neglect the labeled data that are often available, such as those obtained from controlled chaos engineering exercises that identify specific services as failure root causes. Consequently, opportunities to refine and expedite future similar analyses are lost. **From the inference standpoint**, slight changes in the data or in the graph structure necessitate a burdensome and complete re-estimation of intervention targets. In RCA contexts, this means that despite shared causality between distinct incidents, we still require piecemeal analyses for each new occurrence, leading to extended system downtime and delayed resolutions. Additionally, the premise that a large volume of data pertains to a uniform set of intervention targets is restrictive. Such data are challenging to obtain, which further complicates the assurance of these methods' performance.

Addressing these shortcomings, we introduce DeepITE, an innovative deep-learning solution that disentangles the learning and inference processes. In particular, **we design a variational graph autoencoder (VGAE) that can concurrently learn across diverse causal graphs and sets of intervention targets in a self-supervised or semi-supervised mode, thus, effectively harnesses correlated information to unravel the intricate relationship between input data and intervention targets. Once the VGAE is trained, its inference model can instantly identify intervention targets for new, unseen samples with different interventions and causal graphs, all without the need to retrain or refer to observational data.** Specifically, leveraging the principle that interventions entail the removal of all incoming edges to intervention targets, our VGAE framework is designed to estimate the probability of edge removal for each node, thereby identifying the intervention targets. The generative model within the VGAE employs a non-linear Graph Neural Network (GNN), an extension of linear SCMs that adheres to causal factorization and meets the criteria for causal interventions, across causal graphs of various structures and sizes. This theoretical foundation ensures robust ITE capabilities. The generative model accepts exogenous noise variables \(\), the adjacency matrix of the observational causal graph \(\), a Bernoulli-distributed intervention indicator \(\) characterizing edge removal probability, and outputs the distribution of endogenous variables \(\). Conversely, the inference model interprets a given sample of endogenous variables \(\) to infer distributions of exogenous variables \(\) and the intervention indicator \(\), all of which rely on the causal graph \(\). We employ graph attention networks (GAT) as the backbone due to their flexibility and scalability. This VGAE--comprising both the generative and inference models--can be trained in a self-supervised manner by maximizing the evidence lower bound (ELBO) or can leverage labeled intervention targets when available for semi-supervised learning.

Our contributions can be summarized as follows:

* We propose a novel VGAE architecture tailored for ITE, termed DeepITE. It excels in collaborative learning from varying causal structures and interventions, negating the need for retraining with each new instance.
* We establish self-supervised and semi-supervised training approaches for DeepITE, allowing it to autonomously discern intervention targets and enhance accuracy through the integration of labeled data from controlled experiments.

* Extensive experiments show that DeepITE surpasses 13 baseline methods by a large margin on average in terms of _Recall@k_ with competitive inference time, especially for large graphs.

## 2 Related Works

In this section, we briefly review the literature on ITE. Moreover, we notice that the realm of ITE is interconnected with causal explanations and RCA. These three concepts demonstrate a considerable degree of overlap (cf. [8; 4; 9]), suggesting that methods from each domain can not only inform and enhance one another but also be utilized in a complementary fashion. We therefore refer the readers to Appendix B for further discussion on causal explanations and RCA.

The limited literature on ITE approaches bifurcates, with one camp focusing on incidental estimation of intervention targets via causal discovery and the other dedicated solely to identifying intervention targets within a given causal framework. The former includes methods such as UT-IGSP , which seeks to recover an interventional Markov equivalence class (I-MEC) through permutation searches but is hampered by sample inefficiency and limited scalability. Ghassami _et al._ explore linear structural causal models (SCMs) yet may struggle with complexity in diverse data settings. For causal insufficient systems, Jaber _et al._ propose \(\)-FCI for matching interventional distributions to causal graphs and intervention target pairs, contending with exponential growth in complexity as the number of variables increases. Mooij _et al._ alternatively propose a method leveraging context variables for integrating interventional datasets, but this method suffers from scalability issues with large graphs. To overcome this problem, RCD  further adapts the \(\)-FCI algorithm in  to the \(\)-PC algorithm to expedite the process in causally sufficient systems. The second approach, exemplified by CITE  and PreDITEr , zeros in on ITE by contrasting precision matrices from observational and interventional data, achieving scalability at the cost of being initially restricted to linear Gaussian SCMs. LIT  explores non-linear SCMs through non-linear ICA, still carrying quadratic complexity. Alternatively, CI-RCA  conducts ITE by detecting shifts in probability distributions of a variable conditioned on a variable's parents via hypothesis testing. Both groups of methods share critical disadvantages: they are vulnerable to even minor changes in data or causal graphs during both learning and inference, and they underutilize labeled data from controlled experiments.

## 3 Preliminaries

This section lays the groundwork for our study by introducing SCMs and Pearl's Causal Hierarchy.

**Structural Causal Models (SCMs)**: Given a set of variables \(=[_{1},,_{d}]\), SCMs present a formal mechanism to represent causal relations among them. An SCM is composed of two primary components: a set of structural equations and a causal graph. The structural equations take the form:

\[_{i}:=f_{i}((_{i}),_{i}), i=1,2, ,m, \]

where \(f_{i}\) is a deterministic function, \((_{i})\) denotes parent variables that exert direct causal influence on \(_{i}\), and \(_{i}\) signifies unobserved exogenous variables capturing influences not represented by other variables in \(\). We typically invoke causal sufficiency, assuming the \(_{i}\) are jointly independent, thereby ruling out hidden confounders. The use of the assignment symbol ":=" instead of an equality sign underscores the asymmetry of the causal relationship. The corresponding causal graph \(\) (see Figure 1(a) for an example) induced by the SCM is typically a directed acyclic graph (DAG) with vertex set \(\) and directed edges from each variable on the right hand side (RHS) of a structural equation (1) to the variable on the left hand side, thus delineating the causal dependencies.

**Pearl's Causal Hierarchy (PCH)**: Under the SCMs framework, PCH categorizes causal inference into a three-tiered structure reflective of the cognitive processes of "seeing" (observational), "doing" (interventional), and "imagining" (counterfactual). The initial tier addresses observational queries using SCMs as conventional probabilistic models to describe statistical associations.

Progressing to the second tier of PCH, SCMs distinguish themselves from standard probabilistic models by enabling the assessment of outcomes resulting from active interventions or manipulations, captured by the notions of _do-operator_ and _graph surgery_. Here, the do-operator \((_{i}=x_{i})\) represents an intervention that sets the variable \(_{i}\) to value \(x_{i}\), while graph surgery alters the corresponding causal graph by removing all incoming edges to the intervened-upon variable \(_{i}\). Interventional queries are then addressed by performing probabilistic inference in the modified graph, which often reveals new conditional independencies due to the excision of edges. For example, the interventional distribution \(p(_{3}|(_{2}=x_{2}))\) for the SCM in Figure 1(b) is obtained via probabilistic inference with regard to (w.r.t.) the intervention graph:

\[p(_{3}|(_{2}=x_{2}))=_{_{1}} p(_{1})p(_{3}|_{1},_{2}=x_{2}), \]

contrasting with the conditional distribution in the original graph (i.e., Figure 1(a)):

\[p(_{3}|_{2}=x_{2})=_{_{1}}p(_{1}| _{2}=x_{2})p(_{3}|_{1},_{2}=x_{2}). \]

The key distinction is the marginal \(p(_{1})\) in (2) versus the conditional \(p(_{1}|_{2}=x_{2})\) in (3), reflecting that the causal relationship between \(_{1}\) and \(_{2}\) is broken by the intervention \((_{2}=x_{2})\).

Finally, there are _counterfactual_ queries about what would or could have been, given that something else was in fact observed. We refer the readers to  as this topic is beyond the scope of our paper.

## 4 Problem Formulation

As discussed in the introduction, intervention target estimation (a.k.a. intervention recognition) is a pivotal component within the landscape of causal analysis, addressing the question of which nodes within a given causal system should be subjected to intervention in order to best explain the given interventional data. This inquiry draws upon the framework established by SCMs and operationalizes the principles enshrined in the second tier of Pearl's Causal Hierarchy. More formally,

**Definition 1**.: _Given a causal graph \(\) with variables \(\), the observational data, and the interventional data corresponding to a certain intervention on a subset of variables \(_{}\), the task of intervention target estimation is to identify \(_{}\)._

Here, we maintain the assumptions of causal sufficiency and the acyclicity of the causal graph. Note that while the DAG structure (i.e., the adjacency matrix \(A\)) is assumed to be known, the explicit forms of the structural equations remain unspecified. In comparison with the interventional queries mentioned in Section 3, which presuppose knowledge of where interventions have occurred and seek to determine their effects, ITE is the inverse process: it starts with the consequences of interventions and works backward to identify the sources of these perturbations. Essentially, we are solving for the _origin_ of the observed interventional data, rather than predicting their _impact_.

In this paper, we innovatively solve the problem of intervention target estimation from the perspective of graph surgery. Recognizing that the interventional data align best with the intervention graph (see Figure 1(b)), our objective is to discover the subset of nodes \(_{}\) such that, upon hypothetically removing the incoming edges to these nodes, the modified interventional model most accurately reflects the presented interventional data. Furthermore, We aim to create a singular model capable of pinpointing distinct sets of intervention targets for individual samples, each associated with its unique causal graph, while eliminating the need for observational data during inference. This represents

Figure 1: **Left Panel: Illustration of the do operator and the corresponding graph surgery: (a) The observation graph \(\); (b) The intervention graph \(_{}\) for \((_{2}=x_{2})\). Right Panel (c): The DeepITE architecture has an inference and a generative model. The inference model uses a three-branch GAT to link endogenous variables \(\) to posterior distributions of intervention indicators \(_{i}\), exogenous variables \(_{i}\), and observation noise precision \(\). The generative model then synthesizes \(\) given these latent variables following Eq. (7) plus observation noise \(\).**

a significant shift from conventional ITE methods that independently identify shared intervention targets for each intervention instance based on both observational and interventional data within the context of a fixed causal graph. Additionally, we seek to enhance model performance by incorporating labeling information during the training phase, which is a step forward in refining ITE processes.

## 5 DeepITE

To move forward to the above objectives, we present DeepITE, a VGAE that can estimate the probability of edge presence within the latent space. The architecture of DeepITE is showcased in Figure 1(c). We will first introduce the generative and inference models within the VGAE. Subsequently, we will explicate the self and semi-supervised methods to train the inference model.

### Generative Model

The chief aim of the generative model is to recreate the observed variables \(\) given the exogenous noise variables \(\), the adjacency matrix \(\) of the causal DAG, and a set of nodes \(\) that have been intervened upon. Notably, when \(\) is an empty set, the model is capable of recovering the observational distribution.

Specifically, when the structural equations are linear, they can be succinctly written as \(=^{T}+\). Therefore, given \(\) and \(\), we can derive \(\) through a linear decoder:

\[=(-^{T})^{-1}. \]

Drawing inspiration from DAG-GNN , we extend this formulation to non-linear scenarios with:

\[=f_{2}(-^{T})^{-1}f_{1}(), \]

where \(f_{1}\) and \(f_{2}\) are non-linear, component-wise learnable functions. In practice, these functions are executed by MLPs, which serve as universal approximators. Assuming \(f_{2}\) is invertible, the aforementioned decoder corresponds to a conglomerate of non-linear structural equations :

\[f_{2}^{-1}()=^{T}f_{2}^{-1}()+f_{1}(). \]

This setup implies that when \(f_{1}\) and \(f_{2}^{-1}\) are suitably expressive, they can transform \(\) and \(\) into a space where their causal interrelations are aptly described by linear structural equations. The decoder, as specified in Eq. (5), exhibits inductiveness, enabling generalization to new nodes, edges, or graph schemas by only modifying the adjacency matrix \(\) while preserving the learned functions \(f_{1}\) and \(f_{2}\). This decoder displays a particular characteristic, ratified by the following proposition:

**Proposition 1**.: _For a GNN layer as defined in Eq. (5), and denoting \((i)\) as the ancestor nodes of node \(i\) with the extension \(^{*}(i)=(i) i\), each output feature \(_{i}\) exclusively acquires information from its own and all ancestor input features \(_{^{*}(i)}\)._

Proof.: See Appendix C. 

Owing to this property, this decoder (5) satisfies causal factorization and captures causal intervention, as proven below.

**Proposition 2**.: _(causal factorization) The decoder defined in Eq. (5) conforms to causal factorization \(p(|,)=_{i}p(_{i}|_{ ^{*}(i)})\), that is, each endogenous variable \(_{i}\) can be expressed as a function of its exogenous variable \(_{i}\) and those of its causal ancestors._

**Proposition 3**.: _(causal intervention) The decoder defined in Eq. (5) captures causal interventions \((_{}=x_{})\) by replacing the original adjacency matrix \(\) in Eq. (5) with the one corresponding to the post-intervention graph after graph surgery._

Proof.: See Appendices D and E. 

As established in Section 4, ITE resides within the second tier of PCH. Within this framework, any model purporting to tackle the ITE challenge must adeptly manage both observational and interventional data. The above propositions bridge this requirement, affirming DeepITE's competency in fulfilling the ITE task. Specifically, these propositions serve as the key to unlocking the model's ability to honor the causal structure inherent in the data and to emulate the effects of interventions.

In light of Proposition 3, to manipulate the intervened nodes \(\) in the decoder (5), we introduce a Bernoulli distributed variable \(_{i}\) for each node \(_{i}\): \(_{i}=0\) means \(_{i}\) is intervened, and thus, all incoming edges of \(_{i}\) is removed during the graph surgery. The variable \(_{i}\) is henceforth referred to as the intervention indicator. The corresponding intervened adjacency matrix is given by \(_{}=(^{T})\), where \(\) is a column vector of all ones and \(\) denotes Hadamard product. As a result, the decoder, inclusive of interventions, is delineated as:

\[=(,,)=f_{2} -A_{}^{T}^{-1}f_{1}(). \]When \(_{i}=1\) for all \(i\), there is no intervention (i.e., \(_{}=\)) and the above decoder can describe the observational distribution.

To facilitate the reparameterization trick in VAE, we assume the exogenous variables \(\) are standard normal distributions: \(_{i}(0,1)\). Finally, since we do not have access to the true structural equations, we introduce the observation noise \((0,^{-1})\) to (7), so as to account for the model uncertainty associated with the above decoder (7). Here, \(\) denotes the inverse variance of the noise, and we impose a non-informative Jeffrey's prior on \(\), that is, \(p() 1/\).

Collectively, the overall generative model can be factorized as:

\[p(,,,|)=p(|,,,)p()_{i=1}^{m}p(_{i})p(_{i}), \]

where

\[p(_{i})=(0,1), p(_{i})=()  i,\]

\[p() 1/, p(|,,, )=(,,),^{ -1}. \]

Here, \(\) denotes the probability of taking 1 in a Bernoulli distribution and \(\) is the identity matrix.

**Discussion on Hard versus Soft Interventions**: Hard interventions, characterized by the removal of incoming edges as part of graph surgery, contrast with soft interventions, which modify the causal mechanism without complete elimination. For instance, for an intervened node \(_{i}\), a soft intervention would replace the original structural equation \(_{i}:=f_{i}((_{i}),_{i})\) with an updated version \(_{i}:=f^{}_{i}((_{i}),_{i})\), where \(f_{i} f^{}_{i}\), thereby altering the generative process while maintaining the graph's structure. In our generative model, the intervention indicator \(_{i}\) is a Bernoulli variable, allowing the learning of edge removal probability from data \(\). A probability of \(_{i}=0\) being one indicates a hard intervention, whereas any other value suggests a soft intervention. This nuanced approach allows DeepITE to offer a spectrum between hard and soft interventions based on given data.

### Inference Model

The pinnacle goal of the inference model within DeepITE is to determine the probability that a node \(i\) has undergone an intervention based on the observed data, succinctly expressed as \(p(_{i}=1|)\). To achieve this, we aim to compute the exact posterior \(p(,,|,)\). However, the intricate nature of this posterior necessitates approximation through a tractable inference model \(q(,,|,)\)[16; 17]. Specifically, the inference model can be factorized in a manner akin to the generative model as:

\[q(,,|,)=q(|,) _{i=1}^{m}q(_{i}|,)q(_{i}|,). \]

The variational distributions on RHS are parametrized by:

\[q(_{i}|,) =_{i}(,),_{i}^{2}( ,), \] \[q(_{i}|,) =\,_{i}(,),\] (12) \[q(|,) =\,_{}(,), _{}^{2}(,), \]

where the Bernoulli distribution (26) can be well approximated using the Gumbel-Softmax reparameterization trick [18; 19]. The parameters of the variational \(q\) distributions in (25)-(27) are derived from a network based on Graph Attention Networks (GAT). While any inductive spatial GNN can be used as the inference network in DeepITE, we choose GAT since it provides the flexibility and scalability necessary for our model. This flexibility stems from GAT's ability to dynamically weigh the importance of different nodes, thus allowing the variational distribution given by the inference network better approximate the exact posterior distribution. This advantage is further demonstrated in Appendix G.6, where we replace the GAT encoder with the encoder of DAG-GNN.

The architecture features an initial dual-layer GAT for feature extraction, followed by three specialized branches dedicated to the parameters of \(\), \(\), and \(\). Note that the parameters of \(\) and \(\) can be regarded as node-level features, while those of \(\) as graph-level features. As such, the final \(\) branch includes a pooling layer to yield the graph-level features. The complete inference network is depicted in Figure 1(c).

It is pertinent to mention that the graph associated with the GATs is undirected, in contrast to the directed nature of the causal graph. This design choice is motivated by the need for the variational update of a variable to account for all elements within its Markov blanket, which includes the parents,children, and co-parents of the node . An undirected graph facilitates the message passing process within this Markov blanket by removing the constraints imposed by edge directionality. Moreover, the use of GAT ensures that the resulting model is inductive, enabling its application to new nodes within the graph and even entirely new graph structures.

**Relation to DAG-GNN **: DAG-GNN's objective is to infer the structure of a DAG (i.e., the zero pattern of \(\)) from the provided data, a process known as causal discovery. The architecture of DAG-GNN employs a generative model expressed as \(=f_{2}((-^{T})^{-1}f_{1}())\) and an inference model as \(=f_{4}((-^{T})f_{3}())\), both of which are differentiable with respect to \(\). This differentiability is crucial as it enables the learning of \(\) through gradient descent. On the other hand, DeepITE enhances the generative model by integrating an intervention indicator, which facilitates the adaptation of the model to account for interventions via graph surgery. Furthermore, DeepITE's inference model seeks to closely approximate the true posterior \(p(,,|,)\). Unlike DAG-GNN, which may only collect messages from the parents of a node, DeepITE's model is designed to aggregate messages from all nodes within the Markov blanket of a given node \(i\). This comprehensive approach ensures that DeepITE's inference model is not as restrictive as DAG-GNN's and is better suited for ITE tasks.

**Relation to VACA **: VACA sets out to perform causal queries utilizing observational data within the framework of the VGAE. It hinges on Message Passing Neural Networks (MPNNs) for both the generative and inference models. A prerequisite for VACA to perform observational and interventional queries is that the generative model's number of MPNN layers must at least be \(-1\) given that \(\) is the graph diameter.4 This criterion ensures that the information propagated within the graph can reach from one end to the other, thereby reflecting the global structure necessary for accurate causal inference. DeepITE aligns with this requirement for effectively performing ITE. However, DeepITE distinguishes itself by employing the generative model, specified in Eq. (7). It keeps the number of GNN layers to be one regardless of graph diameter, while satisfying causal factorization and intervention conditions (cf. Proposition 2-3). DeepITE thereby overcomes the limitations imposed by VACA's dependence on graph diameter, offering a substantial benefit for collective learning on graphs with different sizes.

### Self and Semi-Supervised Learning

DeepITE's learning strategies encompass self-supervised learning, which automates the identification of intervention targets from unlabeled data, and semi-supervised learning, which refines the model's performance by integrating labeled data. The training process is summarized in Algorithm 1.

**Self-Supervised Learning**: Given the generative and inference model, we can learn their parameters jointly by maximizing the evidence lower bound (ELBO) of the log-likelihood of the given data \(\):

\[=_{q}[ p(,,,|)]+_{q} p(|), \]

where \(_{q}\) denotes expectation over the \(q\) distribution in (10) and \(_{q}\) denotes the entropy of the \(q\) distribution. The derivation of the ELBO can be found in Appendix F. Note that \(\) can be maximized via stochastic gradient ascent after using the reparameterization trick for normal and Bernoulli distributions .

**Semi-Supervised Learning**: Information regarding intervention targets may often be available in practice. For instance, in the case of RCA in cloud-native systems, the ground truth of intervention targets can be derived from resolved incidents and chaos engineering exercises. This ground truth data can be utilized to train the inference network, enabling it to more accurately identify intervention targets. In particular, the term \(q(_{i}|,)\) is replaced by the ground truth \(_{i}^{*}\) when computing the ELBO \(\), and an additional term is introduced to maximize the log-likelihood \( q(_{i}^{*}|,)\). By taking advantage of both labeled and unlabeled data, we can effectively train the inference model.

Once trained, the inference model of DeepITE becomes equipped to evaluate individual new samples against different causal graphs, directly deducing the intervention targets and thus circumventing the necessity of retraining for each new scenario. It can also distinguish between observational and interventional data directly as the former equates to the absence of intervention targets. Another significant feature of DeepITE is its independence from observational data during the testing phase; it relies solely on the interventional data input into the inference network. This is a distinct advantage over existing ITE methods, which consistently require observational data for ITE. In practice, we are primarily concerned with the intervention indicators \(\). Hence, during inference, we only need to process \(\) through the relevant branch of \(\), as highlighted by the red dashed box in Figure 1(c), disregarding the other branches to optimize inference efficiency.

## 6 Experimental Results

In this section, we demonstrate the usefulness of DeepITE on three datasets, comprising one synthetically generated dataset, which provides a controlled environment to test the robustness and scalability of the framework, and two real-world datasets that introduce the complexity of genuine causal systems. We position DeepITE against 13 state-of-the-art (SOTA) methods, spanning three areas of relevance: Intervention Target Estimation (ITE), Explainable AI (XAI), and Root Cause Analysis (RCA), due to their intertwined nature (see more discussions in Section 2 and Appendix B).

* **ITE:** We select 3 methods: UT-IGSP , which learns intervention targets as a byproduct of causal discovery; CITE  and PreDITEr , both of which are dedicated to ITE.
* **XAI**: We opt for TreeExplainer , ASV , ShapleyFlow , and PWSHAP , 4 methods based on Shapley values. TreeExplainer only considers associations, whereas ASV, ShapleyFlow, and PWSHAP incorporate causation, accounting for the DAG structure.
* **RCA**: We pick 6 methods: CausInfer , MicroHECL , MicroRCA , CausalRCA , CI-RCA , and RCD . The last two aim to find intervention targets in a causal graph.

To facilitate a fair comparison, all methods are provided with the same ground truth causal graph, eschewing the need for graph construction from data for some RCA methods. More implementation details can be found in Appendix G.1. The performance is quantified using the _Recall@k_ metric. _Recall@k_ measures the proportion of true intervention targets (ITs) that are successfully captured within the top k ranked candidates proposed by each method. This metric is widely adopted in the literature [4; 9; 29]. When \(k=1\), our goal is to pinpoint the intervention targets based on the highest-ranked candidate. We prioritize _Recall@k_ because, in practice, false positives can be eliminated through further analysis, while false negatives are irrecoverable as they get lost among the numerous true negatives. All experiments report average results over 10 trials, with error bars representing a standard deviation (\( 1\)) from the mean.

**Synthetic Data**: The synthetic data is generated following the method outlined in CI-RCA  and in Appendix G.2. We assess causal graphs with nodes ranging from 50 to 500 and corresponding edges from 100 to 5000, exhibiting different levels of complexity. In particular, DeepITE is evaluated in two configurations: DeepITE (sep), where separate models are trained for each graph size, and DeepITE (mix), where a single model is trained across all graph sizes and structures.

Analysis of the results in Table 1 reveals 5 key insights: (i) **Traditional ITE Methods Fall Short**: Such methods underperform with larger graphs with fewer samples due to their design for small, dense datasets (typically involving tens of nodes but with tens of thousands of samples) and lack of cross-instance learning, treating each intervention instance in isolation. As shown in Appendix G.3, they perform much better for small graphs with large sample size. (ii) **XAI Methods Face Challenges**: TreeExplainer lacks consideration for causal relationships in graphs. ASV and Shapley Flow, although

  
**DATASET** &  &  &  \\
**METRICS** & Recall@1 & Recall@5 & Recall@5 & Recall@1 & Recall@5 \\  UT-IGSP & \(0.224 0.015\) & \(0.318 0.019\) & \(0.079 0.007\) & \(0.185 0.010\) & \(0.016^{*} 0.002\) & \(0.020^{*} 0.004\) \\ CITE & \(0.098 0.009\) & \(0.124 0.013\) & \(0.044 0.003\) & \(0.063 0.006\) & \(0.007 0.001\) & \(0.008 0.001\) \\ PreDITEr & \(0.104 0.009\) & \(0.122 0.012\) & \(0.049 0.004\) & \(0.066 0.006\) & \(0.008 0.001\) & \(0.008 0.001\) \\  TreeExplainer & \(0.381 0.022\) & \(0.510 0.017\) & \(0.298 0.016\) & \(0.448 0.009\) & \(0.102 0.008\) & \(0.152 0.002\) \\ ASV & \(0.296 0.021\) & \(0.390 0.022\) & \(0.261 0.014\) & \(0.323 0.017\) & \(0.081 0.003\) & \(0.140 0.005\) \\ ShapleyFlow & \(0.552 0.017\) & \(0.690 0.009\) & \(0.378 0.009\) & \(0.485 0.007\) & \(0.124 0.005\) & \(0.148 0.002\) \\ PWSHAP & \(0.468 0.014\) & \(0.610 0.012\) & \(0.339 0.009\) & \(0.454 0.008\) & \(0.117 0.003\) & \(0.195 0.003\) \\  CausInfer & \(0.561 0.002\) & \(0.765 0.003\) & \(0.554 0.002\) & \(0.786 0.02\) & \(0.559 0.003\) & \(0.769 0.004\) \\ MicroHECL & \(0.462 0.010\) & \(0.587 0.009\) & \(0.341 0.004\) & \(0.400 0.004\) & \(0.199 0.003\) & \(0.241 0.004\) \\ MicroRCA & \(0.647 0.004\) & \(0.899 0.003\) & \(0.623 0.004\) & \(0.875 0.004\) & \(0.436 0.003\) & \(0.676 0.003\) \\ CausalRCA & \(0.633 0.004\) & \(0.894 0.004\) & \(0.622 0.004\) & \(0.863 0.004\) & \(0.418 0.004\) & \(0.630 0.004\) \\ CI-RCA & \(0.615 0.002\) & \(0.952 0.001\) & \(0.631 0.002\) & \(0.930 0.003\) & \(0.623 0.004\) & \(0.823 0.003\) \\ RCD & \(0.495 0.003\) & \(0.706 0.004\) & \(0.440 0.004\) & \(0.521 0.005\) & \(0.325 0.002\) & \(0.364 0.003\) \\  DeepITE (sep) & \( 0.002\) & \( 0.003\) & \(0.685 0.004\) & \( 0.002\) & \( 0.003\) & \( 0.004\) \\ DeepITE (mix) & \(0.718 0.003\) & \(0.945 0.005\) & \( 0.004\) & \(0.923 0.003\) & \(0.627 0.003\) & \(0.875 0.004\) \\   

Table 1: Recall@k of different algorithms for detecting the intervened nodes from the Synthetic dataset. Graph-\(m\) means DAGs with \(m\) nodes.

aware of the causal structure, struggle with scalability similar to traditional ITE methods, as these methods demonstrate optimal performance on comparatively smaller graphs (around 10-20 nodes) (cf. [25; 26]). (iii) **RCA Methods Show Promise but Have Limitations**: RCA methods generally perform better than ITE and XAI approaches, with CI-RCA aligning exactly with the ITE task. However, these methods also face challenges in integrating multiple intervention instances effectively. (iv) **DeepITE Models Excel**: Both DeepITE (sep) and DeepITE (mix) outperform all benchmarked methods on Recall@1 and Recall@5 metrics, attributing success to a flexible model that fosters collaborative instance learning, independent of graph characteristics, enabling precise alignment of data with intervention targets. (v) **Competitive Performance within DeepITE Models**: The two DeepITE models (sep&mix) demonstrate competitive results, indicating that the model's inductive strength and its adaptability to various graph structures and sizes.

**Protein Signaling Dataset**: The description of the dataset is presented in Appendix G.4. The results, shown in the second column of Table 2, focus on the Recall@1 metric due to the graph's limited size. It is evident that DeepITE outshines competing methods, attributable to its capacity for collaborative learning across the entire dataset and its inherent adaptability. Traditional ITE and XAI methods trail closely behind, with their methodologies being particularly suited to smaller graphs that nevertheless have a substantial number of samples. In contrast, RCA methods exhibit weaker performance as techniques such as PageRank, DFS, BFS, or rank walk struggle to distinguish between nodes in such a compact network. Unlike these approaches, DeepITE demonstrates versatility in handling both small and large graphs, affirming its utility across a wide range of practical scenarios.

**ICASSP-SPGC 2022**: The details of this dataset can be found in Appendix G.4. Note that the absence of purely observational data in this dataset precludes the application of the ITE methods including UT-IGSP, CITE, and PreDITE. For our evaluation, we continue to employ Recall@1 and Recall@5 metrics and additionally consider accuracy and the root-cause score, the latter two being an official recommendation. The root-cause score is calculated by subtracting the number of false positives from the number of true positives and then dividing by the total number of true intervention targets. The results of this multifaceted assessment are presented in the last four columns of Table 2. Once more, in comparison with the SOTA methods, DeepITE stands out by a large margin of above 20% in Recall@1, underscoring its applicability to real-world RCA challenges. Notably, CI-RCA and Shapley Flow emerge as close second-best performers, likely because both methods leverage causal rather than just correlational information, which appears to be advantageous in this context.

### Ablation Study

Due to the page limit, we only present an overview of the major findings here. More details can be found in Appendix G.5- G.7. (i) **Impact of Label Proportions**: Incorporating even a modest amount (5-10%) of labeled data significantly enhances DeepITE's performance across various datasets, with recall improvements ranging from 4-20%. This approach provides substantial benefits in practical settings, unlike other baseline methods in the study that cannot utilize labeled data at all. (ii) **Replacement of Encoder and Decoder**: Modifying DeepITE's encoder to DAG-GNN's and its decoder to VACA's in two ablation designs shows that DeepITE-with its flexible generative and inference models-outperforms both modified versions and the original VACA  and DAG-GNN . These observations, especially under conditions of increasing graph complexity, highlight

  
**DATASET** & **Protein Signaling** &  \\
**METRICS** & Recall@1 & Recall@1 & Recall@5 & RootAcc & Score \\  UT-IGSP & 0.579 \(\) 0.018 & - & - & - & - \\ CITE & 0.588 \(\) 0.011 & - & - & - & - \\ PreDITE & 0.586 \(\) 0.010 & - & - & - & - \\  TreeExplainer & 0.434 \(\) 0.020 & 0.367 \(\) 0.013 & 0.687 \(\) 0.010 & 0.7401 \(\) 0.0153 & 0.3534 \(\) 0.0298 \\ ASV & 0.441 \(\) 0.017 & 0.449 \(\) 0.010 & 0.720 \(\) 0.008 & 0.7933 \(\) 0.0117 & 0.3820 \(\) 0.0230 \\ ShapleyFlow & 0.615 \(\) 0.021 & 0.677 \(\) 0.013 & 0.825 \(\) 0.015 & 0.9176 \(\) 0.0131 & 0.5312 \(\) 0.0252 \\ PWSHAP & 0.603 \(\) 0.016 & 0.488 \(\) 0.009 & 0.741 \(\) 0.010 & 0.8551 \(\) 0.0109 & 0.4233 \(\) 0.0211 \\  Causelnfer & 0.076 \(\) 0.002 & 0.278 \(\) 0.003 & 0.490 \(\) 0.001 & 0.5808 \(\) 0.0084 & 0.1139 \(\) 0.0180 \\ MicroHECL & 0.081 \(\) 0.004 & 0.323 \(\) 0.010 & 0.661 \(\) 0.011 & 0.7339 \(\) 0.0134 & 0.3697 \(\) 0.0283 \\ MicroRCA & 0.127 \(\) 0.003 & 0.246 \(\) 0.004 & 0.463 \(\) 0.002 & 0.5662 \(\) 0.0089 & 0.0721 \(\) 0.0204 \\ CausalkCA & 0.113 \(\) 0.001 & 0.308 \(\) 0.004 & 0.447 \(\) 0.003 & 0.5353 \(\) 0.0078 & 0.0617 \(\) 0.0161 \\ CI-RCA & 0.090 \(\) 0.001 & 0.559 \(\) 0.002 & 0.828 \(\) 0.001 & 0.9284 \(\) 0.0055 & 0.6560 \(\) 0.0105 \\ RCD & 0.214 \(\) 0.002 & 0.481 \(\) 0.008 & 0.757 \(\) 0.005 & 0.8768 \(\) 0.0112 & 0.4542 \(\) 0.0216 \\  DeepITE & **0.652**\(\) 0.002 & **0.881**\(\) 0.002 & **0.984**\(\) 0.000 & **0.9794**\(\) 0.0023 & **0.9085**\(\) 0.0040 \\   

Table 2: Results of the Protein Signaling Data and the ICASSP-SPGC Data.

DeepITE's robustness and the limitations of DAG-GNN's rigid design and VACA's requirement of minimal decoder layers in estimating ITE. (iii) **Scalability**: Figure 2(a-b) revealed the performance of DeepITE as a function of the graph size and the number of interventions respectively. Our findings indicate that while performance in terms of Recall@1 declines as the graph size increases, Recall@5 remains stable even for graphs with 1000 nodes--a size that is already considered quite large for causal analysis. (iv) **Hard&Soft Intervention**: We examined DeepITE under varying ratios of hard and soft interventions, where soft interventions were modeled by modifying the linear structural equations of the intervention targets to quadratic forms. Figure 2(c) shows DeepITE's adaptability to these mixtures, confirming its effectiveness in handling both types of interventions with only minimal performance loss. (v) **Samples**: Figure 2(d) illustrates the performance of DeepITE with variations in sample size. Our results show that DeepITE exhibits robustness with performance generally improving as the sample size increases. In contrast, traditional ITE methods [3; 6; 10] typically require thousands of samples for a single graph and intervention set to perform well. This resilience can be attributed to the collaborative learning framework of DeepITE and the relatively few parameters in the GNN-based encoder and decoder. (vi) **Amortization**: The performance of DeepITE as more graphs with different sizes are trained together, is detailed in Figure 2(e). Our findings indicate a minimal gradual degradation in the performance of DeepITE (mix) as we incorporate more graphs of varying sizes, attributed to the amortization error. Moreover, Table 1 shows that DeepITE (mix) even outperforms DeepITE (sep) training exclusively on 100-node graphs in terms of Recall@1. Based on this evidence, we maintain that the amortization process across graphs does not significantly hinder the performance.

### Runtime Analysis

We conducted a runtime analysis using four distinct datasets, with variable counts \(m\) ranging from 5 to 500, specifically \(m=\). For each value of \(m\), we executed 10 trials on a set of 1000 samples and reported the average runtime. To ensure a fair comparison, we focused exclusively on the code pertinent to intervention identification. Timing commenced the moment the algorithm received the dataset and accompanying causal graph, if applicable, and ceased immediately upon delivery of the final results. This process ensured that our analysis exclusively measured the performance of the algorithm's core intervention-targeting functionality.

The runtime performance of the various methods, relative to graph size, is depicted in Appendix Figure 3. From the analysis, we note that DeepITE's runtime curve, represented in black, has the gentlest slope, implying that it boasts the lowest time complexity among all the methods. Notably, DeepITE secures the shortest runtime for graphs with more than 100 nodes. This heightened efficiency is attributable to DeepITE's inference process, which necessitates only a single pass through one branch of the inference network. In contrast, UT-IGSP exhibits the highest time complexity as it engages in an exponentially growing number of hypothesis tests to identify intervention targets. For instance, when handling graphs with \(m=500\) nodes, UT-IGSP requires nearly an hour to complete a single run.

## 7 Conclusion

In this paper, we presented DeepITE, a novel VGAE for ITE. By carefully design the VGAE based on GNNs, DeepITE allows collaborative learning and amortized inference across data with a range of intervention targets and causal graphs. The model adeptly supports both self-supervised and semi-supervised learning modalities, effectively harnessing labeled data to refine ITE. Our comprehensive results demonstrate that DeepITE can be seamlessly adapted to a multitude of domains, accommodating diverse causal graph configurations while exhibiting superior performance in terms of both Recall@k metrics and computational efficiency.

Figure 2: The performance of DeepITE as a function of (a) graph sizes, (b) interventions, (c) the mixture proportion of soft and hard interventions, (d) sample size for each graph, (e) the number of mixed graphs.