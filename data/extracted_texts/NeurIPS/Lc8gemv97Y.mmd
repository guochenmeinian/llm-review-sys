# Dealing with Synthetic Data Contamination in Online Continual Learning

Maorong Wang\({}^{1}\) Nicolas Michel\({}^{1,2}\) Jiafeng Mao\({}^{1}\) Toshihiko Yamasaki\({}^{1}\)

\({}^{1}\)The University of Tokyo \({}^{2}\)Univ Gustave Eiffel, CNRS, LIGM

{ma_wang, yamasaki}@cvm.t.u-tokyo.ac.jp

nicolas.michel@univ-eiffel.fr

mao@hal.t.u-tokyo.ac.jp

###### Abstract

Image generation has shown remarkable results in generating high-fidelity realistic images, in particular with the advancement of diffusion-based models. However, the prevalence of AI-generated images may have side effects for the machine learning community that are not clearly identified. Meanwhile, the success of deep learning in computer vision is driven by the massive dataset collected on the Internet. The extensive quantity of synthetic data being added to the Internet would become an obstacle for future researchers to collect "clean" datasets without AI-generated content. Prior research has shown that using datasets contaminated by synthetic images may result in performance degradation when used for training. In this paper, we investigate the potential impact of contaminated datasets on Online Continual Learning (CL) research. We experimentally show that contaminated datasets might hinder the training of existing online CL methods. Also, we propose **E**ntropy **S**election with Real-synthetic similarity **M**aximization (ESRM), a method to alleviate the performance deterioration caused by synthetic images when training online CL models. Experiments show that our method can significantly alleviate performance deterioration, especially when the contamination is severe. For reproducibility, the source code of our work is available at https://github.com/maorong-wang/ESRM.

## 1 Introduction

Continual Learning (CL)  solves the problem of learning from a sequence of ever-emerging machine-learning tasks without forgetting previously learned knowledge. Defined by learning manners, CL can be classified into two categories : _offline_ CL and _online_ CL. In offline CL (_i.e._ conventional CL), the learners can access the training dataset on **current** task multiple times before proceeding to the next task. In online CL, the training data also comes in a continual data stream, and the continual learner only sees the training data once. Besides learning manners, there are also three typical CL settings : Task-Incremental Learning (TIL), Domain-Incremental Learning (DIL), and Class-Incremental Learning (CIL). In this paper, we investigate the more challenging CIL setting in the online CL manner.

Image generation with deep generative models has shown remarkable success. Thanks to denoising diffusion models , Internet users are capable of generating high-fidelity and realistic images within several seconds. Despite the astonishing quality of those images to human eyes, research has shown that AI-generated content may be harmful when used to train machine learning models, leading to potential performance deterioration , bias amplification , loss of diversity , etc.

Recently, it has become a trend for researchers to collect datasets from the Internet, and synthetic data contamination would become a potential threat to the CL community. Moreover, the online CL is particularly affected as assessing the soundness of data in the online scenario is impractical. In this work, we first aim to investigate how this new form of dataset contamination might affect the existing Online CL methods. Then, we empirically observe the characteristics of synthetic data when used to train online CL models and form four observations of synthetic data properties in online CL, which might be of interest to the community. Moreover, we investigate synthetic data properties and exhibit specific differences in terms of entropy and representations when compared to real data. Guided by these properties, we propose **E**ntropy **S**election with **R**eal-synthetic similarity **M**aximization (ESRM), a method to alleviate the performance degradation caused by the synthetic contamination. As a replay-based method, ESRM consists of two key components: Entropy Selection (ES) and Real-synthetic similarity Maximization (RM). ES selects more realistic samples in the memory buffer to alleviate catastrophic forgetting. RM is a contrastive learning based optimization strategy, that aims to alleviate the performance artifact caused by synthetic data contamination.

The major contribution of this paper can be summarized as follows:

* We investigate the potential impact of synthetic data contamination on existing online CL methods and outline four observations regarding the properties of synthetic data in continual scenarios.
* We propose ESRM, a method to alleviate the performance deterioration caused by synthetic data contamination.
* Comprehensive experiments show that ESRM can successfully mitigate the performance deterioration caused by synthetic contamination, especially when the contamination is severe.

## 2 Related Work

Synthetic data contamination.Recently, diffusion models [19; 34] have achieved high-fidelity image generation and surpassed GANs in terms of image quality and diversity. Likewise, text-to-image generation based on diffusion models can generate astonishing images that faithfully follow the users' text instructions. Furthermore, these generative models demonstrate excellent extrapolation capabilities (_i.e._, meaningfully combining concepts that would be nearly impossible to combine in reality), such as "a photo of an astronaut riding a house". Various generative models are open-sourced to the public, and users can use these models to generate realistic images in seconds. However, while people are appreciating the new format of art and flooding the Internet with fabulous images, such synthetic images are difficult to differentiate from the real ones. Therefore, these generated images are becoming a potential source of contamination for the future datasets collected from the Internet. Research has proven that synthetic data contamination may lead to a significant performance drop when supervising machine learning models in non-continual scenarios [18; 28]. Also, training deep models with such a contaminated dataset may give rise to bias amplification  and loss of diversity . To tackle the issue caused by the synthetic contamination, researchers have proposed different strategies to detect the synthetic data with deep learning based detectors [30; 27]. However, the challenge brought by synthetic data contamination to the CL community is exclusive, and it is even more problematic in the online scenario since it is almost impossible to assess the quality of the training data, due to the unique challenge brought by the online setting.

Continual Learning.The mainstream CL strategies can be classified into four categories: regularization-based, parameter-isolation-based, prompt-based, and replay-based. Regularization-based methods [7; 26; 1; 23; 46] design and apply extra regularization terms to balance the learning and forgetting of CL learners. Parameter-isolation-based methods [14; 36; 37; 35; 3] tackle the CL problem by allocating task-specific parameters. Prompt-based methods [44; 43] take the idea of prompt learning and use prompt pools against catastrophic forgetting. Replay-based methods [33; 5; 6; 16; 17; 45] store a small portion of historical data with a memory buffer. Among all of the strategies, replay-based methods have prevailed in Online CL with better performance and simplicity. Early work  proposed **Experience Replay (ER)**, suggesting using a random replay buffer to alleviate catastrophic forgetting. **Dark Experience Replay (DER++)** proposes to store the logits in the memory buffer and leverage the stored logits as dark knowledge to extend ER. **ER-ACE** is a variant of ER with asymmetric cross-entropy loss. **OCM** alleviates catastrophic forgetting by maximizing the mutual information between current and past representations. **GSA** addresses the cross-task class discrimination problem with gradient self-adaption. **OnPro** solves the shortcut learning problem with online prototype learning. In this paper, these methods are used as baselines to assess the impact of synthetic data contamination.

## 3 Preliminary

### Synthetic dataset generation

To simulate a dataset contaminated with synthetic data, we employed five diffusion-based models to generate synthetic counterparts of the original datasets. These twin datasets contain the same number of images and the same classes, while all images are synthetic. The models used in generation include Stable Diffusion XL , Stable Diffusion v1.4, Stable Diffusion v2.1, VQDM , and GLIDE . The synthetic data contamination was simulated across four benchmark datasets used in online CL, including CIFAR-10 , CIFAR-100 , TinyImageNet , and ImageNet-100 [13; 20].

The generation of synthetic twin datasets is guided by the category names of the original dataset. For each class, we devised a simple yet effective prompt. For instance, for the class "helicopter", we employed the prompt "an image of a helicopter". After the generation by the diffusion model, we adjusted the image size to match that of the original dataset.

In the experiments, we design two different settings: **a)** all the synthetic twin datasets are generated from Stable Diffusion XL, one of the state-of-the-art generative models; and **b)** Synthetic images are generated with the aforementioned five diffusion models, with each model contributing 20% to the synthetic dataset.

For setting **a)**, we denote the generated dataset as SDXL-C10, SDXL-C100, SDXL-Tiny, and SDXL-In100, respectively, while for setting **b)**, we denote the generated dataset as Mix-C10, Mix-C100, and Mix-Tiny. Some examples of generated images and more detailed information about the synthetic twin dataset generation can be found in Appendix D.2. Notably, the generation results in Fig. 10 reveal the lack of diversity for synthetic data compared with the real data.

### Simulation of synthetic data contamination

To simulate the contamination by the synthetic data, we substitute a portion \(P\) of the original dataset with its synthetic twin, where \(P\) is the contamination ratio. We designate these contaminated datasets using specific notations. For example, we denote the CIFAR-100 contaminated by SDXL-C100 as C100/SDXL. More details about the simulation of contamination are included in Appendix D.3. In

Figure 1: Overview of proposed ESRM framework for online CL. The proposed ESRM framework has two main components: Entropy Selection (ES) and Real-synthetic similarity Maximization (RM). Motivated by Obs. 2 and Obs. 3, ES is a buffer management strategy designed to use entropy as a criterion to select more real samples in the memory buffer, thereby alleviating catastrophic forgetting and performance degradation caused by the contamination. RM aims to bridge the embedding gap between synthetic and real data, as noted in Obs. 4, using a contrastive learning technique.

the following sections, we will investigate the effect of synthetic contamination with these simulated datasets.

## 4 Synthetic Data Contamination in Online CL

In this section, we explore the potential impact of synthetic data contamination on the existing online CL methods and exhibit specific properties of synthetic data.

### Contamination as a cause of performance degradation

When dealing with synthetic data contamination, it is crucial to measure the impact of such contamination on existing methods. In that sense, we train ResNet-18 models in the online continual setting on the contaminated dataset C10/SDXL, C100/SDXL, Tiny/SDXL, and In-100/SDXL with representative online CL methods. We observed that as the contamination ratio \(P\) increases, the performance of all existing methods drops significantly, as shown in Table 2. Detailed information about the experiment settings can be found in Sec. 6. With such experiments, we can form the following observation:

**Observation 1**: _As a source of potential contamination, synthetic data is harmful to the performance of existing online CL methods. Performance degradation increases as contamination becomes more severe._

### Detecting synthetic data matters

Replay-based methods are characterized by the existence of a replay buffer, which helps alleviate forgetting and implicitly improves network plasticity . The quality of data in the replay buffer intuitively influences network performance. Motivated by Obs. 1, we hypothesize that the presence of synthetic data in the replay buffer might degrade performance. We trained ER on the C100/SDXL dataset, with extra information on the samples' synthetic status (_i.e._, whether the image is real or synthetic). We employed two memory strategies: storing only real data in the replay buffer and storing only synthetic data. The results showed in Table 2 indicate that knowing the synthetic status and storing only real data in the replay buffer can achieve performance on par with the no-contamination scenario, even at high contamination ratios. For instance, at a contamination ratio of \(P=80\%\), ER achieves an accuracy of 38.13% on C100/SDXL when only real images are stored in the replay buffer. This result is comparable to the accuracy achieved when training on the clean CIFAR-100 dataset (38.70%), which contains four times more real data. These findings also demonstrate the potential of synthetic models to enhance performance through data generation and augmentation in an online continual learning scenario.

**Observation 2**: _The memory buffer plays a key role in replay-based methods, and storing real samples in the memory buffer is effective against performance degradation caused by contamination._

### Synthetic data properties

**Lower entropy distribution.** One noteworthy characteristic of synthetic data is its lower entropy distribution compared to real data, as observed from the perspective of continual learners. Fig. 2 shows the entropy distribution produced by a representative method ER and a state-of-the-art method OnPro when trained on the contaminated dataset. The values in the histogram are calculated at the end of the training on the whole training dataset (In-100/SDXL, \(P=50\%\)). From the figure, we can spot a salient distribution difference between synthetic data and real data. Moreover, the synthetic samples have a peak in entropy distribution close to 0. Extra entropy histogram with other baselines can be found in Appendix C.1. Thus, we conclude with another finding:

**Observation 3**: _Compared with real data, synthetic data entropy tends to be lower._

**Feature gap in the embedding space.** We find another intriguing property of synthetic data in the feature embeddings. Fig. 3 shows the t-SNE  visualization of the memory data produced by ER and OnPro on the In-100/SDXL dataset. For clarity, we only visualize the embeddings of the first 10 classes. With the synthetic data contamination, the features of the synthetic samples are better clustered than the real data. The pattern of the clustering of synthetic data indicates the ease of classification, which is on par with the limited diversity of synthetic data (cf. Fig. 10), and the low entropy distribution (cf. Obs. 3). Moreover, the embeddings of real data are inferior and fail to align with the superior embeddings of synthetic samples, which explains the performance degradation of inference on real test datasets. Extra visualization produced by other baselines is illustrated in Appendix C.2.

**Observation 4**: _With the limited diversity of synthetic data, the synthetic data are better clustered than the real data, leading to a misalignment in the embedding space between synthetic samples and real samples. Such misalignment likely contributes to performance deterioration._

## 5 Proposed Method

Fig. 1 presents the main framework of our proposed ESRM to alleviate the performance degradation caused by synthetic data contamination. In this section, we introduce the two components of ESRM: Entropy Selection (ES) and Real-synthetic similarity Maximization (RM). Then, we explain the whole ESRM framework.

### Entropy selection

The introduced ES aims to select more representative samples in the memory buffer. For replay-based methods, having high-quality samples in the memory buffer helps alleviate forgetting and achieve better overall performance. As per Obs. 2, selecting real images into the memory buffer can provide more representative and reliable features and therefore lead to better performance. Motivated by this, we propose ES, a memory management strategy. Guided by Obs. 3 (synthetic data has lower entropy distributions), the core idea of ES is to select more real samples in the memory buffer based on the entropy distribution of the current batch.

At the beginning of the training, ES initializes an empty buffer. When a new batch comes, ES drops 50% of the batch samples with lower entropy, and stores the remaining samples, along with their entropy of the prediction. Once the buffer is full, as shown in Fig. 4, ES takes four steps to replace the elements in the buffer. Firstly, ES drops 50% of low entropy samples in the incoming batch. Then, ES uses Reservoir Sampling [21; 40] to decide whether to keep or discard the remaining incoming samples. If Reservoir Sampling decides to keep the incoming sample, it will nominate a buffer sample. After that, ES checks the class of the nominated sample and chooses a sample of the same class with the lowest

Figure 4: Overview of the proposed Entropy Selection strategy. The color of the samples indicates the class, and the number in the samples represents the entropy predicted by the learner.

entropy in the memory buffer. And finally, ES replaces the chosen memory sample with the incoming sample, along with its entropy. Moreover, all entropy values in the memory buffer are updated by the current model's prediction at the end of each task. The pseudo-code of ES is given in Appendix B.

### Real-synthetic similarity maximization

Prior to introducing the loss function of RM, we present the network structures of our ESRM. As shown in Fig. 1, the continual learner consists of three components: a feature extractor \(f\), a projection head \(g\), and a classifier \(\). The output dimension of the projection head \(g\) is set to 128. For each sample \(x\) from incoming data stream \(X^{new}\), the projected embedding \(z\) can be formulated as:

\[z=g(f(x)).\] (1)

As per Obs. 4, the gap in the embedding space might be a cause for the performance degradation in the contamination setting. To tackle this issue, we propose RM. The main idea of RM is to maximize the cosine similarity between the features of real and synthetic data. Motivated by the seminal supervised contrastive loss , we propose our variant RM loss.

RM aims to maximize the similarity between two groups of data \(X_{1}\) and \(X_{2}\). We define the loss to match the similarity of samples in group \(X_{1}\) to group \(X_{2}\) as:

\[_{M}(X_{1},X_{2})=_{i I_{1}}_{p P(i )}log z_{p}/)}{_{d I_{2}}exp(z_{i} z_{d}/ )},\] (2)

where \(I_{1}=\{i:x_{i} X_{1}\},I_{2}=\{d:x_{d} X_{2}\}\) are the set of the indices of \(X_{1},X_{2}\), respectively. And \(P(i)=\{p X_{2}:y_{p}=y_{i}\}\) is the set of the indices of positive samples in group \(X_{2}\), which share the same class with \(x_{i}\). \(\) is the temperature hyperparameter which is set to 0.07. Since \(_{M}(X_{1},X_{2})\) only optimize samples in the group \(X_{1}\), in the optimization, it is used together with \(_{M}(X_{2},X_{1})\). Due to RM aims to maximize the inter-group similarity between the \(X_{1}\) group and the \(X_{2}\) group, we do not need to perform augmentations as shown in similar work, such as SimCLR  and SupCon . Intuitively, the way to handle the similarity matrix is illustrated in Fig.1.

For an incoming batch \(X^{new}\), we use entropy criteria to split it into two groups \(X^{new}_{+}\) and \(X^{new}_{-}\) of the same size. Group \(X^{new}_{+}\) includes 50% of the samples with the highest entropy, and as per Obs. 3, tend to contain more real images. On the contrary, group \(X^{new}_{-}\) contains low entropy samples which tend to be synthetic. To alleviate the gap in feature embeddings mentioned in Obs. 4, we maximize the inter-group similarity between \(X^{new}_{+}\) and \(X^{new}_{-}\) with \(_{M}(X^{new}_{+},X^{new}_{-})\) and \(_{M}(X^{new}_{-},X^{new}_{+})\). Moreover, to align the holistic feature embeddings between the stream data \(X^{new}\) and memory data \(X^{mem}\), we also applied \(_{M}(X^{new},X^{mem})\) and \(_{M}(X^{mem},X^{new})\) in the loss function.

Thus, the proposed RM to alleviate the feature gap in Obs. 4 can be achieved by employing \(_{RM}\):

\[_{RM}=_{M}(X^{new}_{+},X^{new}_{-})+_{M}(X^{ new}_{-},X^{new}_{+})+_{M}(X^{new},X^{mem})+_{M}(X^{ mem},X^{new}).\] (3)

### Overall framework of ESRM

The overall framework of ESRM is shown in Fig. 1. Besides ES and RM, following , ESRM employs a self-distillation technique to alleviate the overconfidence problem of the replay-based methods. For the combined batch \(X=(X^{new},X^{mem})\), we apply the self-distillation as:

\[_{SDC}=D_{KL}((f(X))/t,)/t),\] (4)

where \(D_{KL}()\) is the Kullback-Leibler divergence, \(t\) is another temperature hyperparameter which is set to 4, \(\) is the fixed copy of \((f(aug(X)))\), without gradient propagation, and \(aug()\) is the data augmentation used in the training process, with detailed information in Appendix D.5.

Thus, the total loss of ESRM can be formulated as:

\[_{ESRM}=_{CE}+_{1}_{SDC}+_{2} _{RM},\] (5)

where \(_{CE}=CE((f(X)),y)+CE((f(aug(X))),y)\) is the cross-entropy loss, and \(_{1},_{2}\) are the balancing hyperparamteres. We set \(_{1}=1\) and \(_{2}=0.5\) after a small hyperparameter search as illustrated in the Appendix D.6.

## 6 Experiments

### Experiment setup

**Datasets.** In the experiments, we used four benchmark datasets in evaluation, including CIFAR-10/100, TinyImageNet, and ImageNet-100. All of the datasets are split into tasks containing non-overlapping classes. The details about the task split are available in Appendix D.1.

**Baselines.** We evaluate the effectiveness of ESRM against six representative and state-of-the-art baselines, including ER , DER++ , ERACE , OCM , GSA , and OnPro .

**Implementation details.** We use full-width ResNet-18 (not pre-trained) as the backbone for all experiments. For a fair comparison, we conduct a hyperparameter search on CIFAR-100 (Memory Size = 5K) and apply the same hyperparameter to all settings. Stream batch size is set to 10 and memory batch size is set to 64. We do not use multiple updates trick for incoming batches as detailed in . Detailed information about task allocation, hyperparameter search protocol, and data augmentation can be found in Appendix D.

**Buffer size.** For CIFAR-10 and CIFAR-100 experiments, the buffer size is set to 1,000 and 5,000, respectively. For the harder TinyImageNet experiments, the buffer size is set to 10,000. The buffer size of ImageNet-100 is set to 5,000. Appendix C.5 demonstrates more experiments with different memory buffer sizes.

   Dataset & CIFAR10 &  \\  Ratio \(P\) & 0\% & 50\% & 70\% & 80\% & 90\% & 95\% \\  ER & 63.93\({}_{24.0}\) & 60.40\({}_{15.41}\)(-3.53) & 57.07\({}_{3.64}\)(-6.86) & 54.18\({}_{3.42}\)(-9.75) & 56.09\({}_{3.50}\)(-13.24) & 47.39\({}_{2.74}\)(-16.54) \\ DER++ & 64.31\({}_{2.63}\)(-6.02) & 60.24\({}_{2.42}\)(-4.07) & 56.11\({}_{2.199}\)(-8.20) & 51.62\({}_{2.43}\)(-21.69) & 44.43\({}_{3.00}\)(-19.88) & 40.46\({}_{2.92}\)(-23.85) \\ ERACE & 60.19\({}_{15.51}\)(-5.04) & 56.17\({}_{2.08}\)(-4.02) & 50.70\({}_{2.69}\)(-4.99) & 46.86\({}_{3.61}\)(-13.33) & 41.86\({}_{2.06}\)(-18.33) & 37.56\({}_{2.64}\)(-22.63) \\ OCM & 72.61\({}_{61.61}\)(-6.97)(-13.29) & 66.68\({}_{1.68}\)(-5.98) & 63.79\({}_{2.59}\)(-8.87) & 60.41\({}_{1.43}\)(-12.25) & 57.07\({}_{2.41}\)(-15.59) \\ GSA & 66.91\({}_{11.57}\)(-6.37) & 63.47\({}_{1.189}\)(-3.44) & 59.44\({}_{2.33}\)(-7.47) & 56.60\({}_{2.62}\)(-10.31) & 49.93\({}_{2.79}\)(-16.98) & 45.77\({}_{2.60}\)(-21.14) \\ OnPro & **74.87\({}_{1.58}\)(-7.18)** & **72.46\({}_{1.36}\)(-2.41)** & **68.79\({}_{2.17}\)(-6.08)** & 66.07\({}_{2.71}\)(-8.80) & 62.37\({}_{1.10}\)(-12.50) & 56.41\({}_{2.95}\)(-18.46) \\ ESRM & 67.53\({}_{2.51}\)(-6.79) & 67.47\({}_{1.41}\)(**0.12**) & **66.81\({}_{1.18}\)(-9.54)** & **64.59\({}_{1.58}\)(-9.76)** & **60.04\({}_{2.97}\)(-7.31)** \\  Dataset & CIFAR100 &  \\  Ratio \(P\) & 0\% & 50\% & 70\% & 80\% & 90\% & 95\% \\  ER & 38.70\({}_{14.55}\) & 36.37\({}_{1.39}\)(-2.33) & 32.82\({}_{2.62}\)(-5.88) & 31.33\({}_{31.31}\)(-7.37) & 27.09\({}_{1.92}\)(-11.61) & 25.56\({}_{1.22}\)(-13.14) \\ DER++ & 37.62\({}_{2.30}\) & 32.35\({}_{2.74}\)(-5.27) & 28.32\({}_{2.42}\)(-9.30) & 25.57\({}_{2.44}\)(-12.05) & 19.56\({}_{1.88}\)(-18.06) & 16.00\({}_{1.60}\)(-21.62) \\ ERACE & 39.82\({}_{1.37}\)(-31.51) & 34.51\({}_{2.53}\)(-6.57) & 28.16\({}_{1.19}\)(-11.66) & 25.13\({}_{1.14}\)(-14.69) & 19.37\({}_{1.94}\)(-20.45) & 16.14\({}_{2.52}\)(-23.68) \\ OCM & 42.10\({}_{2.11}\)(-1.80) & 37.24\({}_{1.11}\)(-1.80) & 37.54\({}_{1.34}\)(-4.47) & 34.78\({}_{2.73}\)(-23.31) & 34.11\({}_{2.01}\)(-16.01) & 28.84\({}_{1.12}\)(-13.17) \\ GSA & 42.27\({}_{1.53}\) & 39.21\({}_{1.11}\)(-3.06) & 35.21\({}_{1.62}\)(-7.06) & 33.62\({}_{1.61}\)(-9.63) & 27.62\({}_{1.15}\)(-14.65) & 23.88\({}_{1.61}\)(-18.39) \\ OnPro & 41.47\({}_{1.41}\)(-1.09) & 39.26\({}_{2.07}\)(-2.21) & 35.64\({}_{1.60}\)(-5.83) & 33.20\({}_{1.07}\)(-8.27) & 30.20\({}_{1.08}\)(-11.27) & 26.77\({}_{1.19}\)(-14.70) \\ ESRM & **47.72\({}_{2.48}\)(-6.75)** & **46.57\({}_{1.08}\)(-1.15)** & **45.92\({}_{0.42}\)(-1.80)** & **44.48\({}_{4.44}\)(-3.24)** & **40.99\({}_{1.41}\)(-3.20)** & **40.99\({}_{1.41}\)(-3.10)** & **37.45\({}_{1.60}\)(-10.27)** \\  Dataset & TinyDXL &  \\  Ratio \(P\) & 0\% & 50\% & 70\% & 80\% & 90\% & 95\% \\  ER & 25.06\({}_{1.81}\) & 18.03\({}_{1.69}\)(-7.03) & 13.59\({}_{1.58}\)(-11.47) & 11.29\({}_{1.44}\)(-13.77) & 6.38\({}_{4.08}\)(-18.68) & 3.88\({}_{4.06}\)(-21.18) \\ DER++ & 19.40\({}_{13.71}\) & 12.55\({}_{2.22}\)(-6.85) & 9.71\({}_{1.14}\)(-9.69) & 4.76\({}_{1.41}\)(-11.94) & 4.49\({}_{4.03}\)(-14.91) & 2.81\({}_{1.04}\)(-**16.59)** \\ ERACE & 26.38\({}_{1.81}\)(-1.03) & 17.04\({}_{0.08}\)(-9.34) & 11.23\({}_{1.09}\)(-15.15) & 7.83\({}_{3.14}\)(-18.55) & 4.09\({}_{0.08}\)(-22.29) & 2.54\({}_{0.83}\

### Results and analysis

**Final Average Accuracy.** Table 2 shows the final average accuracy of learners trained with four datasets, including C10/SDXL, C100/SDXL, Tiny/SDXL, and In-100/SDXL, with different contamination ratios \(P\). More results on C10/Mix, C100/Mix, and Tiny/Mix are given in Appendix C.3. For the six baselines, we can notice a significant performance drop when synthetic data contamination appears. Notably, when the contamination is severe (contamination ratio \(P 70\%\)), the performance degradation is significant. Also, it can be observed that ESRM is less impacted by synthetic data contamination. For most datasets and contamination ratio \(P\), the ESRM performance drop is the lowest of the compared methods. This is remarkably true for large values of \(P\).

Apart from the robustness against synthetic data contamination, the absolute performance of ESRM is also attractive. In most cases, ESRM outperforms the baseline methods by a large margin. More interestingly, for some datasets, such as CIFAR-100 and ImageNet-100, even with an extreme contamination ratio, ESRM can still achieve a substantial performance, while the performance of most baseline methods is unsatisfactory.

**Plasticity and Stability Metrics.** We measure the model's plasticity and stability with Learning Accuracy (LA)  and Relative Forgetting (RF) , respectively. As shown in Table 3 and 4, for baseline methods, both plasticity and stability performance are hindered by synthetic data contamination. From the model plasticity perspective, ESRM alleviates the problem with a larger plasticity. For the model stability, ESRM solves the problem of stability degradation with the presence of contamination. It is notable that with RM loss and self-distillation loss, ESRM implicitly trades off some model stability in favor of plasticity. Plasticity and stability performance on other datasets are available in Appendix C.4.

**Domain-Incremental Learning Results.** While Class-Incremental Learning (CIL) setting is the standard evaluation protocol in online CL, we also evaluated the performance of ESRM in Domain-Incremental Learning (DIL) scenarios. We conducted the experiment with the 20 coarse labels of the

    & \(P=70\%\) & \(P=80\%\) \\  & Acc. \(\) & Acc. \(\) \\  Baseline & 42.61\(\)0.84 & 41.22\(\)0.65 \\ w/o \(_{SDC}\) & 44.30\(\)0.78 & 42.59\(\)0.69 \\ w/o \(_{RM}\) & 44.03\(\)0.73 & 42.32\(\)0.52 \\ ESRM & 45.92\(\)0.42 & 44.48\(\)0.41 \\   

Table 6: Ablation of loss functions on C100/SDXL dataset, with different contamination ratio \(P\). “Baseline” indicates ES+\(_{CE}\).

   Dataset & In-100 &  \\  Ratio \(P\) & 0\% & 50\% & 70\% & 80\% & 90\% & 95\% \\  ER & 53.87\(\)1.27 & 52.12\(\)1.03 & 48.38\(\)0.79 & 45.21\(\)1.24 & 39.24\(\)1.58 & 35.27\(\)0.93 \\ DER++ & 61.14\(\)2.38 & 56.99\(\)1.85 & 53.56\(\)2.86 & 50.26\(\)2.66 & 44.08\(\)1.89 & 37.92\(\)1.9 \\ ERACE & 49.25\(\)1.94 & 43.83\(\)0.76 & 37.92\(\)0.94 & 35.11\(\)0.85 & 26.78\(\)1.14 & 22.70\(\)0.75 \\ COAT & 22.71\(\)1.82 & 19.17\(\)0.28 & 19.18\(\)0.85 & 19.43\(\)4.77 & 20.44\(\)0.25 & 18.98\(\)1.44 \\ GSA & 61.83\(\)1.72 & 58.15\(\)1.99 & 53.63\(\)0.46 & 49.55\(\)1.25 & 42.35\(\)0.38 & 36.16\(\)0.90 \\ OnPro & 39.28\(\)0.84 & 38.98\(\)1.16 & 40.07\(\)1.72 & 38.45\(\)2.80 & 36.45\(\)1.51 & 32.94\(\)1.33 \\ ESRM & **74.85\(\)0.61** & **71.25\(\)0.74** & **65.14\(\)0.39** & **62.16\(\)0.39** & **55.30\(\)0.50** & **50.41\(\)0.97** \\   

Table 3: Learning Accuracy (%; higher is better) on In-100/SDXL with various contamination ratio \(P\).

   Dataset & In-100 &  \\  Ratio \(P\) & 0\% & 50\% & 70\% & 80\% & 90\% & 95\% \\  ER & 53.87\(\)1.27 & 52.12\(\)1.03 & 48.38\(\)0.79 & 45.21\(\)1.24 & 39.24\(\)1.58 & 35.27\(\)0.93 \\ DER++ & 61.14\(\)2.38 & 56.99\(\)1.85 & 53.56\(\)2.86 & 50.26\(\)2.66 & 44.08\(\)1.89 & 37.92\(\)1.9 \\ ERACE & 49.25\(\)1.94 & 43.83\(\)0.76 & 37.92\(\)0.94 & 35.11\(\)0.85 & 26.78\(\)1.14 & 22.70\(\)0.75 \\ COAT & 22.71\(\)1.82 & 19.17\(\)0.28 & 19.18\(\)0.85 & 19.43\(\)4.77 & 20.44\(\)0.25 & 18.98\(\)1.44 \\ GSA & 61.83\(\)1.72 & 58.15\(\)1.99 & 53.63\(\)0.46 & 49.55\(\)1.25 & 42.35\(\)0.38 & 36.16\(\)0.90 \\ OnPro & 39.28\(\)0.84 & 38.98\(\)1.16 & 40.07\(\)1.72 & 38.45\(\)2.80 & 36.45\(\)1.51 & 32.94\(\)1.33 \\ ESRM & **74.85\(\)0.61** & **71.25\(\)0.74** & **66.51\(\)0.39** & **62.16\(\)0.39** & **55.30\(\)0.50** & **50.41\(\)0.97** \\   

Table 5: Comparison of different memory strategies on C100/SDXL dataset, with different contamination ratio \(P\).

CIFAR-100 dataset. Since the 100 classes in CIFAR-100 are grouped into 20 superclasses with 5 fine-grained classes for each superclass, we split the CIFAR-100 dataset with 5 domain increment steps. For each step, we feed the model with the training data of a fine-grained class from each superclass. Because the model only classifies 20 coarse labels, we refer to this dataset as DIL-CIFAR20. Similar to the simulated CIFAR100/SDXL dataset, we replace the images in the DIL-CIFAR20 dataset with its Stable Diffusion XL generated counterpart with a contamination ratio P, as per the protocol in Sec. 3.2.

Table 7 shows the final average accuracy with different contamination ratios. Notably, we adapted the CIL-specifically designed components in OnPro and GSA to the DIL scenario, and the performance suffered a decent loss. We did not report ERACE results because its Asymmetric Cross Entropy (ACE) loss converges to standard cross-entropy loss in the DIL scenario, making it equivalent to vanilla ER. The experimental results show that ESRM can yield robust performance against domain shift in the DIL setting, under different synthetic contamination situations, which validates the efficiency of ESRM under DIL settings.

### Ablation studies

**Effect of ES.** To evaluate the effect of ES, we substitute ES with three different memory strategies: random sampling, storing real data only, and storing synthetic data only. Note that storing real or synthetic data requires knowing the ground truth of an image's synthetic status, which is not practical in realistic settings. Additionally, storing only real data is an idealized case for memory management, while storing only synthetic data represents the worst-case scenario. As shown in Table 5, both ES and random reservoir sampling  outperform the worst-case scenario by a large margin. Moreover, ES outperforms the random sampling significantly.

**Effects of loss terms.** We also conduct experiments to verify the effects of loss terms in Eq. 5. As shown in Table 6, Both \(_{SDC}\) and \(_{RM}\) can benefit the final average accuracy of the classification. Furthermore, the combination of the two loss terms can further improve the final accuracy, validating that both terms complement each other.

   Dataset & DIL-CIFAR20 &  \\  Ratio \(P\) & 0\% & 50\% & 70\% & 80\% \\  ER & 53.56\(\)1.42 & 51.91\(\)1.63(-1.65) & 49.61\(\)4.06(-3.95) & 47.25\(\)40.73(-6.31) \\ DER++ & 56.43\(\)0.65 & 52.46\(\)1.19(-3.97) & 48.73\(\)5.0(-7.70) & 44.60\(\)1.79(-11.83) \\ OCM & 56.02\(\)1.17 & 53.87\(\)5.0(-2.15) & 52.69\(\)4.93(-3.33) & 50.57\(\)4.08(-5.45) \\ GSA & 53.67\(\)2.60 & 51.54\(\)1.76(-2.13) & 47.16\(\)1.76(-6.51) & 45.55\(\)1.17(-8.12) \\ OnPro & 31.81\(\)1.21 & 30.43\(\)0.72(-1.38) & 29.19\(\)40.82(-2.62) & 27.79\(\)40.86**(-4.02)** \\ Ours & **64.27\(\)0.46** & **63.35a.70**(-**0.92)** & **61.86a.54**(-2.41)** & **59.94a.71**(-4.33) \\   

Table 7: Final Average Accuracy (%; higher is better) on DIL-C20/SDXL dataset. Numbers in parentheses indicate the performance degradation due to synthetic contamination compared to the clean setting. The average and deviation over 10 runs are reported.

## 7 Discussions

**The alleviation of feature misalignment.** As mentioned in Obs. 4, baseline methods suffer performance degradation due to the misalignment between the inferior feature embedding of real images and the superior feature embedding of synthetic samples. Fig. 5 presents the t-SNE visualization of memory data at the end of training of ESRM on the In-100/SDXL dataset. Similar to Fig. 3, only the first 10 classes are visualized for clarity. Compared to ER and OnPro, the embeddings of synthetic and real samples in ESRM are better aligned, facilitated by the RM.

**Training dynamics of memory buffer.** To intuitively demonstrate the effect of ES, we visualized the percentage of synthetic data in the memory buffer throughout the whole training process. Fig. 6 displays the curve of the percentage of synthetic data in the memory buffer when the model is trained with ESRM on In-100/SDXL with different contamination ratios \(P\). To generate this curve, we checked the memory buffer every 10 iterations. As shown in the figure, the percentage of synthetic data is close to the contamination ratio \(P\) in the early stages of training. As training progresses, the amount of synthetic data decreases. This trend intuitively illustrates the effect of ES in selecting real samples. Furthermore, we take a model trained with ESRM at the end of training and use the model's entropy as the criterion to categorize the synthetic status of samples in the training dataset and generate an ROC curve, as shown in Fig. 7. We regard real data as positive and use models trained with ESRM on In-100/SDXL (\(P=50\%\)) to categorize the samples in the training set. The AUC of the ROC curve is 0.7098, showing the effect of the entropy criterion in discriminating real and synthetic samples.

## 8 Conclusion

With the widespread availability of advanced generative models, the prevalence of AI-generated images appears inevitable, posing a potential challenge for researchers attempting to collect datasets devoid of AI-generated content from the Internet. In this paper, we examine the potential side effects of AI-powered image generation on the continual learning community. First, we experimentally demonstrate that synthetic data has become a potential source of data pollution. We spot a catastrophic performance loss when the contaminated datasets are used to train continual learning models. Based on our experiments, we identify and summarize four typical characteristics of synthetic data when involved in the training of continual learners. Additionally, we propose ESRM, a method designed to alleviate performance deterioration, maintaining satisfactory performance even with highly contaminated datasets. Lastly, we hope our work highlights the need for improved regulation and systematic control over generated data, such as watermarking AI-generated content before publication. Internet data is a valuable resource accumulated over decades. We believe ensuring the integrity of Internet data is crucial for the future soundness of AI development.