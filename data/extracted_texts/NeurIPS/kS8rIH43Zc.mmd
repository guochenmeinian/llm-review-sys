# Bayesian Active Causal Discovery with

Multi-Fidelity Experiments

 Zeyu Zhang

Gaoling School of Artificial Intelligence

Renmin University of China

zeyuzhang@ruc.edu.cn

&Chaozhuo Li

Microsoft Research Asia

cli@microsoft.com

&Xu Chen

Gaoling School of Artificial Intelligence

Renmin University of China

xu.chen@ruc.edu.cn

Co-first authors.

Xing Xie

Microsoft Research Asia

xingx@microsoft.com

Co-first authors.

Corresponding author.

###### Abstract

This paper studies the problem of active causal discovery when the experiments can be done based on multi-fidelity oracles, where higher fidelity experiments are more precise and expensive, while the lower ones are cheaper but less accurate. In this paper, we formally define the task of multi-fidelity active causal discovery, and design a probabilistic model for solving this problem. In specific, we first introduce a mutual-information based acquisition function to determine which variable should be intervened at which fidelity, and then a cascading model is proposed to capture the correlations between different fidelity oracles. Beyond the above basic framework, we also extend it to the batch intervention scenario. We find that the theoretical foundations behind the widely used and efficient greedy method do not hold in our problem. To solve this problem, we introduce a new concept called \(\)-submodular, and design a constraint based fidelity model to theoretically validate the greedy method. We conduct extensive experiments to demonstrate the effectiveness of our model.

## 1 Introduction

Causal discovery aims to learn the causal structure of a set of variables, which is fundamental for many real-world applications, including health caring , education  drug discovery  and protein synthesis . In general, causal structure learning is an NP-hard problem , and purely based on the observational datasets, one cannot identify the unique causal structure, where the best result is discovering its Markov equivalence class .

To more accurately identify the unique causal structure, a promising direction is active causal discovery (ACD), where the model is allowed to actively intervene the causal structure to query key information for orienting the causal relations between different variables. For example, to study the causal relations between the drugs and diseases, one can conduct clinical tests via selectively administering the medicines to the patients. The key of active causal discovery is how to design effective experiments when the total cost (_e.g._, the number of experiments) is limited. To achieve this goal, recent years have witnessed many promising models. For example, Agrawal et al.  proposes to intervene on the variables which can orient as many as possible undirected edges. Tigas et al. designs a mutual information based method to determine the variables and values to be intervened, and study both single and batch intervention scenarios.

While the above models have achieved remarkable successes, they only allow to query a single oracle (_e.g._, the real causal structure) for the experiments3. However, in many real-world applications, the experiments can be done via different methods. For example, to investigate the drug-disease causal relations, in addition to the clinical tests, one can also build simulators to obtain the medicine effects on the patients . Usually, each experimental method corresponds to a unique oracle, and different oracles have various fidelites. Higher-fidelity experiments are more accurate but expensive, for example, administering drugs to the real patients. Lower-fidelity experiments are cheaper but inaccurate, for example, using patient simulators. These different fidelity oracles may offer better cost-benefit trade-offs, which, however, cannot be handled by existing active causal discovery models.

To bridge the above gap, in this paper, we formally define the task of active causal discovery with multi-fidelity oracles, where the model has to actively select which variables and values to intervene at which fidelities. This task is non-trivial due to the following reasons: to begin with, because of the introduction of multi-fidelity oracles, the model has to strategically choose the lower-cost and informative enough experiments to uncover the real causal structure, which needs our special designs. Then, given the experiment results with different fidelities, how to infer the real causal structure is also not easy, since the experiment results can be not produced from the oracle corresponding to the real causal structure. In addition, in practice, an efficient experiment should allow simultaneously intervening multiple variables . However, how to extend our model to the batch intervention scenario is still not clear.

To overcome the above challenges, we design a Bayesian active causal discovery model, which is composed of two components. The first one is a mutual information (MI) based acquisition function. It aims to select the interventional variables, values and fidelities which are more informative for the real causal structure. The second one is a cascading fidelity model. In specific, we first regard the highest fidelity oracle as the real causal structure, and then a cascading model is built to correlate different fidelity oracles, so that the experiment results at one fidelity can be leveraged to infer the oracle at another fidelity. To achieve more efficient experiments, we also extend our model to the batch intervention scenario. Previously, the greedy method is demonstrated to be an efficient and effective strategy for batch intervention . However, we found that, by allowing multi-fidelity oracles, the theoretical foundations behind the greedy method do not hold. For alleviating this problem, we introduce a new concept called \(\)-submodular, and design a constraint-based fidelity model to theoretically validate the greedy method.

The main contributions of this paper are summarized as follows: (1) we formally define the task of active causal discovery with multi-fidelity oracles, which, to our knowledge, is the first time in the field of causal discovery. (2) To solve the above task, we propose a Bayesian framework, which is composed of a mutual information based acquisition function and a cascading fidelity model. (3) To extend our framework to the batch intervention scenario, we introduce a constraint-based fidelity model, which provides theoretical guarantees for the efficient greedy method. (4) We conduct extensive experiments to demonstrate the effectiveness of our model.

## 2 Preliminaries

### Structure Causal Model

Structure causal model (SCM) is an effective language for describing and learning the causal relations between different random variables . Usually, SCM is composed of a causal graph and a set of structure equation models (SEM).

For the causal graph, we denote it by \(G= V,\), where \(V\) is the node set, and \(\) is the adjacency matrix. Each node in \(V\) corresponds to a variable. Suppose there are \(d\) variables in our studied problem, then we use \(X_{V}=[X_{1},X_{2},,X_{d}]\) to denote the variable set. The adjacency matrix \(\{0,1\}^{d d}\) describes the causal relations between different variables. \(_{ij}=1\) means that \(X_{i}\) is a parent of \(X_{j}\), and there exists an edge from \(X_{i}\) to \(X_{j}\), while \(_{ij}=0\) indicates that there is no edge between \(X_{i}\) and \(X_{j}\).

For the structure equation models, we denote them by \(=\{g_{1},g_{2},...,g_{d}\}\), where each \(g_{i}\) quantitatively describes the relation between \(X_{i}\) and its parents. Formally, we implement \(F\) with the commonly used additive noise models (ANM) , that is:

\[X_{i}=g_{i}(pa(i);_{i})+_{i},_{i}(0, _{i}^{2}),\] (1)

where \(_{i}\) is the parameter set of \(g_{i}\), and the noise term \(_{i}\) follows the Gaussian distribution with \(_{i}^{2}\) as the variance. We denote the complete parameter set of \(\) as \(=\{,\}\), where \(=\{_{1},_{2},,_{d}\}\) and \(=\{_{1},_{2},,_{d}\}\). Note that, given the above equation, we can easily derive the distribution of \(X_{V}\), that is, \(p(X_{V})=_{i=1}^{d}(g_{i}(pa(i);_{i}),_{i}^{2})\).

Based on the above formulation, given an observational dataset \(D=\{_{k}\}_{k=1}^{N} p(X_{V})\), causal discovery aims to learn the adjacency matrix \(\), or more generally, simultaneously identify \(\) and the SEM parameter \(\). In this paper, we focus on the general case, and denote \(=(,)\).

### Active Causal Discovery

Previous work has demonstrated that, purely based on the observational dataset, the real causal graph can only be identifiable to its Markov equivalence class. Active causal discovery holds the promise of identifying more accurate causal graph via designing interventional experiments.

Formally, an interventional experiment is represented by \(=\{(j,v)\}\), which means cutting all the causal relations pointing to \(X_{j}\), and fixing the value of \(X_{j}\) as \(v\). In causal learning, the experiment \(\) can also be represented by \((X_{j}=v)\). Obviously, the distribution of \(X_{V}\) is changed after the experiment \(\), and we denote the experiment-induced distribution by \(p(X_{V}|(X_{j}=v))\). In practice, we cannot access the implementation of \(p\), but can only observe the experiment result sampled from \(p(X_{V}|(X_{j}=v))\). The key of active causal discovery is to design a series of experiments within limited budgets, such that the results can be better leveraged to identify \(\).

### Multi-Fidelity Active Causal Discovery

Existing ACD models mostly obtain the experiment results via interacting with the real SCM. However, in practice, the experiments can be done in different ways (_e.g._, real clinical tests or patient simulators). Each type of experiment corresponds to an underlying oracle, which produces the results of the experiments. Different oracles may provide better cost-benefit trade-offs for the experiment designs, which are failed to be considered by the previous work.

Formally, suppose we have \(M\) oracles, and the parameters of the \(i\)th oracle is denoted by \(_{i}\). Let the experiment cost of the \(i\)th oracle be \(_{i}\), and without loss of generality, we assume \(_{1}_{2}_{M}\). Intuitively, if an oracle is more accurate (_i.e._, has higher fidelity), then it should be more expensive4. We regard the real SCM as the most accurate oracle, thus we set \(_{M}=\). We denote all the oracle parameters and costs as \(=\{_{1},_{2},...,_{M}\}\) and \(=\{_{1},_{2},...,_{M}\}\), respectively.

Due to the introduction of multi-fidelity oracles, the experiment in traditional active causal discovery is extended to be a triplet \(=\{(j,v),m\}\), where in addition to the intervention pair \((j,v)\), the fidelity \(m\) should also be considered in the experiment design. We define the dataset for model training as \(D=\{_{t},_{t}\}_{t=1}^{T}\), where \(_{t}=\{(j,v),m\}\) indicates the distribution for generating \(_{t}\). In general, \(\{(j,v),m\}\) means that \(_{t}\) is generated from \(p_{m}(X_{V}|(X_{j}=v))\), which is induced by \(_{m}\) and the intervention \((j,v)\). If \((j,v)=\), then \(_{t}\) is an observational data, which is sampled from \(_{m}\) without any intervention. Finally, we define the task of multi-fidelity active causal discovery as follows:

**Definition 1** (Multi-Fidelity Active Causal Discovery (MFACD)).: Given \(M\) oracles with different costs \(\), we need to design a model \(f\), which can strategically determine the intervention pair \((j,v)\) and fidelity \(m\) to achieve better cost-benefit trade-off in terms of identifying the real SCM \(_{M}\).

The Licence Model

For solving the task of MFACD, we design a Bayesian framework called Licence (Multi-fidelity active learning for causal discovery), which is composed of two components. The first one is an acquisition function based on mutual information, which is responsible for designing the experiments. The second one is a cascaded fidelity model, which is designed to capture the correlation between different \(_{i}\)'s. The experiment results obtained from the first component are leveraged to update the fidelity model, and \(_{M}\) in the fidelity model is the finally predicted result. At last, we introduce how to extend our model to the batch intervention scenario.

### MI-based Acquisition Function

Intuitively, a better experiment should leverage little cost to reveal as much as possible information about the real SCM \(_{M}\). Thus, we design the following acquisition function:

\[f(j,v,m)=;_{M}|,D)}{_{m}},\]

where \(=\{(j,v),m\}\) is the experiment to be designed. \(D\) is the dataset already collected, which will be enlarged after each experiment. \(I(;_{M}|,D)\) is the mutual information, which indicates that if we conduct experiment \(\), then how much information the experiment result may share with the target parameter \(_{M}\). Obviously, we should select \(\) which can lead to larger \(I(;_{M}|,D)\). \(_{m}\) is the cost of \(\). By dividing \(I(;_{M}|,D)\) with \(_{m}\), we trade-off the experiment informativeness and cost. To determine \((j,v,m)\), we derive an estimator for \(f(j,v,m)\) following the idea of Bayesian Active Learning by Disagreement (BALD) , that is:

\[& f(j,v,m)=|,D)-H(|_{M},,D)}{_{m}}\\ =&_{p(|,D)}[ _{p(_{m}|,D)}[p(|,_{m})]] +_{p(_{M}|D)}[_{p(|,_{ M})}[ p(|,_{M})]]}{_{m}},\] (2)

where \(p(|,D)\) and \(p(_{m}|,D)\) correspond to the distributions of \(\) and \(_{m}\) after observing \(D\) under the intervention \((j,v)\). \(p(_{M}|D)\) is the posterior of \(_{M}\) after observing \(D\). \(p(|,_{m})\) is the probability of \(\) based on \(_{m}\) intervened by \((j,v)\). We approximate the expectation operator based Monte Carlo sampling. The detailed derivation process can be seen in the appendix.

Obviously, determining the best \((j,v,m)\) equals to solving the following problem:

\[\{j^{*},v^{*},m^{*}\}=_{\{j,v,m\}}f(j,v,m).\] (3)

In our task, the intervention value \(v\) is continuous. Following the previous work, we firstly learn the optimal \(v\) for each \((j,m)\) pair based on Bayesian optimization (BO). Then, we compare all the results, and select the solution which can lead to the largest \(f(j,v,m)\). We present the detailed Bayesian optimization process in the appendix. It should be noted that one can also leverage more advanced BO methods for jointly learning \((j,v,m)\). However, we do not find significant performance improvements by these models.

### Cascaded Fidelity Model

Intuitively, the experiment results from different oracles may share common information. The samples at one fidelity may help to infer the oracles at other fidelities. To capture the correlations between different oracles, we build a cascaded probabilistic model (see Figure 1), where the oracles with different fidelities are successively connected, and the observed samples are only determined by their corresponding oracles.

Formally, to achieve more robust optimization, we first regard the discrete adjacency matrix \(\) as the samples from Bernoulli distribution. In specific, we let \(_{ij}((_{i}^{T}_{ j }))\), where \(,^{K d}\) (\(K d\)) are two continuous matrices. \(_{ i}\) and \(_{ j}\) are the \(i\)th and \(j\)th columns of \(\) and \(\), respectively. By replacing \(\) with \(\) and \(\), we revise the parameter set \(\) as \((,,)\).

For each fidelity \(m\), we assign a prior distribution of \(_{m}\) given \(_{m-1}\) as follows:

\[ p(_{1})& e^{-  f(_{1},_{1})}(,),\\ p(_{m}|_{m-1})& e^{-  f(_{m},_{m})}(_{m-1 }+,^{2}), m 2,\] (4)where we add subscript \(m\) to indicate different fidelities. \(f(_{m},_{m})=_{p(|_{m},_{m})}[_{1}\{(e^{})-d\}+_{2 }||||_{1}]\) is a regularizer to encourage \(\) to be a sparse and directed acyclic graph . \(_{1}\), \(_{2}\), \(\), \(\) and \(^{2}\) are hyper-parameters.

Since the real SCM is \(_{M}\), we need to infer the posterior \(p(_{M}|D)\), where \(D\) is the initially observational dataset or experiment results. Directly computing \(p(_{M}|D)\) is not easy, since the dataset \(D\) may contain samples from different fidelity oracles. To solve this problem, we first obtain the joint distribution \(p(|D)\), where \(=\{_{1},_{2},...,_{M}\}\) is the collection of all the oracle parameters. Then we derive \(p(_{M}|D)\) by marginalizing out \(\{_{1},_{2},...,_{M-1}\}\).

To efficiently compute and sample from \(p(|D)\), we introduce a variational approximator \(q()\), which is specified as follows:

\[ q(_{1})&( ,),\\ q_{_{m}}(_{m}|_{m-1})& (_{m}_{m-1}+_{m},_{m}^{2}),  m 2,\\ q()&=q(_{1})_{m=2}^{M}q( _{m}|_{m-1}),\] (5)

where \(_{m}=\{_{m},_{m},_{m}\}\) is the set of learnable parameters, and we denote \(=\{_{m}\}_{m=2}^{M}\). According to the theory of variational inference , we maximize the following evidence lower bound (ELBO)  to learn \(\):

\[=&_{  q()}[ p(D|)-(q()||p())],\\ =&_{ q()}[ p (D|)- q()+ p()],\] (6)

where the likelihood \(p(D|)\) can be easily obtained based on equation (1). More detailed derivation on the ELBO can be seen in the appendix. Once we have learned \(\), the posterior \(p(|D)\) is approximated by \(q()\), and further, we have the following theory:

**Theorem 1**.: _If \(p(|D) q()\), then for any variable sets \(A,B\), \(p(A|B,D) q(A|B)\). As a special case \(p(_{M}|D) q(_{M})\)._

The proof of this theory is immediate, since

\[ p(A|B,D)&== _{-A-B}}p(|D)_{-A-B}}{_{ _{-B}}p(|D)_{-B}}_{-A-B}}q()_{-A-B}}{_{_{-B}}q( {})_{-B}}\\ &==q(A|B)\]

Let \(A=_{M}\) and \(B=\), we have \(p(_{M}|D) q(_{M})\). Based on this theory, we leverage \(q\) to replace \(p\) in (2) for easy sampling.

_Remark_.: According to the specification of \(q_{_{m}}(_{m}|_{m-1})\), we can easily demonstrate that \(q()\) follows Gaussian distribution. Such property enables us to use the reparameterization trick  to relate \(\) with \(\). Different from traditional variational models, in our objective, the adjacency matrix

Figure 1: The cascaded probabilistic model is shown above. Different fidelity oracles are successively connected, and the observed samples are only determined by their corresponding oracles.

\(\) in \(f(_{m},_{m})\) is sampled from a discrete distribution, which cuts down the back-propagation signal. To solve this problem, we leverage gumbel-softmax to further associate \(\) with \((_{m},_{m})\). Since \(\) can be further represented by \(\), all the variables in (6) can be reparameterized by \(\), which enables us to optimize it in an end to end manner. We present the detailed derivation process and the complete learning algorithm in the appendix.

### Extension to Batch Intervention

In practice, simultaneously intervening multiple variables can be more efficient due to the lower frequency on interacting with the oracles. However, under the setting of batch intervention, the candidate intervention space exponentially increases with respect to the number of targets. Suppose we need to select \(c\) out of \(d\) variables for intervention, then the size of the candidate space is \(d^{c}\). Previous work found that the greedy strategy is a both efficient and effective method for the batch intervention scenario . From the efficiency perspective, the greedy method only need to search in a \(cd\)-sized candidate space. From the effectiveness perspective, people demonstrate that the mutual information obtained by the greedy strategy is not worse than that of the optimal solution multiplied by \((1-)\). In the following, we introduce how to extend our model to the batch intervention scenario, and leverage the greedy strategy to solve our task.

**Objective for batch intervention in MFACD**. We use the following objective for batch intervention scenario:

\[*{arg\,max}_{\{_{i}\}_{i=1}^{n}}I (\{_{i}\}_{i=1}^{n};_{M}|\{_{i}\}_{i=1}^{n},D),\\ &_{i=1}^{n}_{i} C,\] (7)

where \(_{i}=\{(j_{i},v_{i}),m_{i}\}\) is an experiment, \(_{i}\) is the observed sample from the experiment \(_{i}\), that is, \(_{i} p_{m_{i}}(X_{V}|do(X_{j_{i}}=v_{i}))\). \(_{i}\) is the cost of experiment \(_{i}\). This objective aims to design a series of experiments with budget C, which can reveal the information about \(_{M}\) as much as possible. The number of intervention targets \(n\) is not a fixed value, which is constrained by the total budget.

**The greedy method for MFACD**. The greedy method designs each experiment independently, and at each step, it selects the experiment which can maximize the average information gain. Following , the \(k\)th experiment is determined based on the following objective:

\[*{arg\,max}_{_{k}}& _{i}\}_{i=1}^{k-1}_{k};_{M}|\{_{i} \}_{i=1}^{k-1}_{k},D)-I(\{_{i}\}_{i=1}^{k-1};_{M}|\{ _{i}\}_{i=1}^{k-1},D))}{_{m}}\\ & s.t._{m=1}^{k-1}_{m}+_{k} C,\] (8)

where \(\{_{i}\}_{i=1}^{k-1}\) is the previously designed experiments, and is fixed when learning \(_{k}\).

**What's wrong with the greedy method.** The theoretical foundations of the greedy method is demonstrated by the previous work  as follows:

**Theorem 2**.: _If \(I(;_{M}|,D)\) is (1) submodular and (2) non-decreasing, then_

\[I(\{_{i}^{g}\}_{i=1}^{n};_{M}|\{_{i}^{g}\}_{i=1}^{n},D) (1-)I(\{_{i}^{*}\}_{i=1}^{n};_{M}|\{_{i}^{* }\}_{i=1}^{n},D),\] (9)

_where \(\{_{i}^{g}\}_{i=1}^{n}\) is the solution obtained from the greedy method, and \(\{_{i}^{*}\}_{i=1}^{n}\) is the optimal solution._

However, due to the introduction of multi-fidelity, in our model, \(I(;_{M}|,D)\) is actually not submodular. More specifically, in the proof of submodular, two samples \(_{s}\) and \(_{t}\) has to be independent given \(_{M}\) (_e.g._, see B.4 in ). In the single-fidelity setting, this requirement naturally holds, since \(_{M}\) is exactly the parameter used to sample \(_{s}\) and \(_{t}\). However, when we introduce multi-fidelity, \(_{s}\) and \(_{t}\) may not independent given \(_{M}\), since they are only directly influenced by their own oracles (see Figure 1).

**An improved greedy method tailored to MFACD**. To alleviate the above problem, in this section we design an improved greedy method tailored to our task. In specific, we first define several new concepts, and then build theories based on these concepts to inspire our model designs.

**Definition 2** (\(\)-independent).: For random variables \(A,B\) and \(C\), if their mutual information satisfy \(I(A;B|C)\), then we say \(A\) and \(B\) are \(\)-independent given \(C\).

**Definition 3** (\(\)-submodular).: Suppose \(f()\) is a set function on \(\). If for any \(A,B\), \(A B\) and \(x B\), \(f(A\{x\})-f(A) f(B\{x\})-f(B)-\), then we say \(f\) is \(\)-submodular on \(\).

Based on the above two definitions, we have:

**Theorem 3**.: _For any two experiments \(_{s}\) and \(_{t}\), if the corresponding samples \(_{s}\) and \(_{t}\) are \(\)-independent given \(_{M},\{_{s},_{t}\}\) and \(D\), then \(I(;_{M}|,D)\) is \(\)-submodular._

**Theorem 4**.: _If \(I(;_{M}|,D)\) is \(\)-submodular on \(X\) and non-decrease, for any \(i,j\), \(}{_{j}} B_{}\), then_

\[I(\{_{i}^{g}\}_{i=1}^{n};_{M}|\{_{t}^{g}\}_{i=1}^{n},D) (1-e^{-}})I(\{_{i}^{*}\}_{i=1}^{n};_{M} |\{_{i}^{*}\}_{i=1}^{n},D)-B,\]

_where \(B=}_{i=1}^{n}(1-n})^{ i-1}\)._

Following this theory, we improve objective (6) to a consitant-based ELBO as follows to capture the degree of independence between different experiment results:

\[ \ _{ q()}[ p(D|) - q()+ p()],\] (10) s.t. \[_{\{_{s},_{t}\}}I(_{s};_{t}|_{M},\{_{s},_{t}\},D).\]

The proofs of the above theories are presented in the appendix, and similar to objective (2), we use Monte Carlo method to approximate the mutual information in objective (10).

## 4 Related Works

**Bayesian Active Causal Discovery.** Causal discovery [20; 21; 22] refers to recovering causality in a set of variables, especially trying to find a directed acyclic graph (DAG) that can represent the relationship between variables in a system. Active causal discovery was first proposed in [23; 24] with the assumption that the data is discrete-valued. In active causal discovery, the experimenter attempts to intervene on the variables in the system at each step, utilizes the interventional data to recover causal relation, and finally identifies the entire causal structure with minimal cost . Many methods have been discussed in different settings over the past decades, including continuous linear Bayesian networks [26; 27], non-linear causal models , and large-scale causal models .

**Multi-fidelity Settings.** The fidelity commonly refers to how accurate the model or environment can be when providing information. Higher-fidelity models are more accuracy but cost much, while lower ones are less accurate but cheaper. In order to combine the strength of each model, multi-fidelity models are proposed to achieve an accurate model with lower costs. Multi-fidelity models can be divided into two main categories : Multi-fidelity Surrogate Models (MFSM) [30; 31; 32] and Multi-fidelity Hierarchical Models (MFHM) [33; 34; 35]. In addition to optimization, multi-fidelity models can also be used for uncertainty propagation  and statistical inference . Recent works also start to study the multi-fidelity settings when conducting Bayesian experiments [38; 39; 40], and adopt deep learning frameworks to solve corresponding problems.

Our paper makes a first step towards multi-fidelity active causal discovery, and solve the non-trivial challenges when combining the above two fields, which, to the best of our knowledge, is the first time in the causal inference domain.

## 5 Experiments

In this section, we conduct experiments to demonstrate the effectiveness of our model, where we focus on the following problems: (1) whether our model can achieve better performance than the previous ACD methods? (2) Whether the constraint in objective (10) in necessary? (3) How the DAG regularization coefficient influence the model performance? In the following, we first introduce the experiment setup, and then present and analyze the results.

### Experimental Setup

We experiment with three commonly used causal discovery datasets, including Erdos-Renyi graph (**ER**) , Scale-Free graph (**SF**)  and DREAM . To demonstrate the effectiveness of our model, we compare it with AIT  and CBED , which are the recent state-of-the-art models in this field. Since they cannot select different fidelities, we design two variants for each of the baseline, that is, **X-REAL** and **X-RANDOM**, which means that the model always interacts with the ground truth oracle \(_{M}\) or randomly select the oracles. Here "X" is AIT or CBED. For the evaluation metrics, we use SHD , AUPRC  and RMSE to evaluate different models. The first two metrics aim to evaluate the accuracy of the learned topological structure, and the last one measures the performance of functional relations. For single intervention, we first generate several observational samples to initialize the model. Then, we indicate a total intervention budget, and let the model interact with the causal graph with different fidelities until the budget runs out. For each interaction, the model will provide an intervention, and correspondingly obtain a sample from the oracles, which is used to update the model. Finally, the model outputs the estimated causal graph, which is leveraged to evaluate the performance. For batch intervention, we indicate the total budget for each intervention step, and the model determines \(n\) interventions simultaneously, which are delivered to the oracles to obtain the samples. We present more detailed settings in the appendix.

### Overall Performance

In this experiment, we evaluate the models under different total budgets, and we present the results on ER and SF datasets with 10 graph nodes. The experiments on DREAM and more nodes are presented in the appendix. From the results shown in Figure 2, we can see: as the total budget becomes larger, the performances of all the models tend to increase on both datasets. This is not surprising, since more experiment budgets enable us to conduct more interventions or query more accurate oracles, which can reveal more information about the ground truth and facilitate more accurate causal discovery. In most cases, our model can perform better than the baselines across different datasets, evaluation metrics and intervention budgets. These results demonstrate the effectiveness of our model. In specific, on the metrics of SHD, AUPRC and RMSE, our model can on average improve performance of the best baseline by about 27.74%, 82.35% and 22.74% on ER, and 17.69%, 60.27% and 21.62%

Figure 2: Results of the overall performance on different datasets and budgets. Lower SHD, RMSE or larger AUPRC indicate better performances. We conduct each experiment for ten times, and report the average performances and error bars.

on SF, respectively. If we look more carefully, we find that, for both AIT and CBED, randomly querying the oracles can sometimes perform better than always interacting with the ground truth oracles. This result suggests that lower fidelity oracles can be helpful to trade-off the performance and cost. However, the random method is still suboptimal, and designing more principled and tailored strategies to select the fidelities is necessary, which is evidenced by the lowered performance of "X-RANDOM" than our model.

### Necessity of the Mutual Information Constraint in Objective (10)

In our model, the mutual information constraint in objective (10) aims to make the greedy method validate. In this section, we study whether it is necessary by experiments. To achieve this goal, we introduce a variant of our model **Licence (w/o reg)**, where we remove the mutual information constraint. We evaluate the models based on the dataset of ER with 10 graph nodes, and the total budget is set as 30. The results are presented in Figure 3(a). We can see, in some cases, "X-RANDOM" performs better than "X-REAL", which is consistent with the above experiments, and demonstrates that always querying the ground truth oracle may not lead to better performance under limited budget. By comparing our model with the variant Licence (w/o reg), we find that our model can consistently achieve better performances on all the evaluation metrics. In specific, Licence can improve the performance of Licence (w/o reg) by about 2.05%, 16.57% and 14.92% on SHD, AUPRC and RMSE respectively. These results demonstrate that the mutual information constraint is necessary in our model, which empirically verifies the theories proposed in section 3.3.

### Influence of the DAG regularization coefficient

In this section, we analysis the influence of the DAG regulation coefficient \(\) in equation (4). The results are reported based on AUPRC. The coefficient \(\) reflects the importance of DAG regulation when updating the model. As \(\) increases, the DAGness is more emphasized for the causal graph. In this subsection, we conduct experiments for various \(\), ranging from \(0.0\) to \(1.0\), and the results are shown in Figure 3(b). We can see as \(\) increases, the performance of AUPRC improves as well, and peaks at \(=0.8\). That is probably because lower \(\) will decrease the acyclic property of causal graphs, which is incompatible with the prior knowledge of true causal graphs. However, higher coefficient may also impact the optimization process, which leads to sub-optimal results. We think a trade-off between mild constraint for easy optimization and solid constraint for DAG property is supposed to take into consider for different tasks and settings.

## 6 Conclusion

This paper formally defines the task of active causal discovery with multi-fidelity oracles, which, to our knowledge, is the first time in the causal discovery domain. To solve this task, we propose a Bayesian framework, which is composed of a mutual information based acquisition function and a cascading fidelity model. We also extend our framework to the batch intervention scenario, and propose a constraint-based fidelity model to validate the efficient greedy method.

Figure 3: (a) The results of experiments on ER graph with 10 graph nodes under the batch intervention scenario. The average performance and error bars are provided. (b) The results of Licence model with different DAG regulation coefficient \(\)â€™s. The experiment is conducted based on ER graph with 10 graph nodes.

This paper actually makes an initial step toward considering different oracles in active causal discovery. There is much room left for improvement. To begin with, one can design more advanced batch intervention strategies, which can bypass the greedy method and does not need to introduce the mutual information constraint in the fidelity model. In addition, since the experiments in active causal discovery are conducted sequentially, and the former experiment results may influence the latter ones, it is interesting to consider the experiment designs as a Markov decision process, and leverage reinforcement learning to optimize the total information gains of all the experiments in a more principled manner.