# Efficient Federated Learning against Heterogeneous

and Non-stationary Client Unavailability

 Ming Xiang\({}^{1}\)  Stratis Ioannidis\({}^{1}\)  Edmund Yeh\({}^{1}\)  Carlee Joe-Wong\({}^{2}\)  Lili Su\({}^{1}\)

\({}^{1}\)Northeastern University, Boston, MA \({}^{2}\)Carnegie Mellon University, Pittsburgh, PA

{xiang.mi,l.su}@northeastern.edu

{ioannidis,eyeh}@ece.neu.edu

cjoewong@andrew.cmu.edu

###### Abstract

Addressing intermittent client availability is critical for the real-world deployment of federated learning algorithms. Most prior work either overlooks the potential non-stationarity in the dynamics of client unavailability or requires substantial memory/computation overhead. We study federated learning in the presence of heterogeneous and non-stationary client availability, which may occur when the deployment environments are uncertain, or the clients are mobile. The impacts of heterogeneity and non-stationarity on client unavailability can be significant, as we illustrate using FedAvg, the most widely adopted federated learning algorithm. We propose FedAWE, which includes novel algorithmic structures that (i) compensate for missed computations due to unavailability with only \(O(1)\) additional memory and computation with respect to standard FedAvg, and (ii) evenly diffuse local updates within the federated learning system through implicit gossiping, despite being agnostic to non-stationary dynamics. We show that FedAWE converges to a stationary point of even non-convex objectives while achieving the desired linear speedup property. We corroborate our analysis with numerical experiments over diversified client unavailability dynamics on real-world data sets.

## 1 Introduction

Federated learning is a distributed machine learning approach that enables training global models without disclosing raw local data [32; 21]. It has been adopted in commercial applications such as autonomous vehicles [6; 70; 41], the Internet of things , and natural language processing [63; 43].

Heterogeneous data and massive client populations are two of the defining characteristics of cross-device federated learning systems [32; 21]. Despite intensive efforts [32; 29; 68; 45; 21], several key challenges that arise from the involvement of large-scale client populations are often overlooked in the existing literature . One of the primary hurdles is the issue of client unavailability. Intuitively, more active clients drive the global model to their local optima by overfitting their local data, which biases the training. In addition, the higher the uncertainty in client unavailability, the larger the performance degradation. Concrete examples that confirm these intuitions in the context of FedAvg - the most widely adopted federated learning algorithm - can be found in Section 4. Client unavailability issues can arise from internal factors such as different working schedules and heterogeneous hardware/software constraints. External factors, such as poor network coverage and frequent handovers of base stations due to fast movements, only exacerbate these problems [50; 57; 64; 3; 21]. The intricate interplay of internal and external factors results in the _non-stationarity_ and _heterogeneity_ of client unavailability.

Most prior work either assumes exact knowledge of the clients' available dynamics or requires their dynamics to be benignly stationary [32; 27; 42; 54; 55; 11]. A related line of work studies asynchronous federated learning wherein clients are vulnerable to delays in message transmission and the reported model updates may be stale [59; 38; 49; 25]. The proposed methods therein assume the availability of all clients or uniformly sampled clients, making them inapplicable to our settings. A few recent works [44; 58] study non-stationary dynamics. Ribero et al.  consider the settings where the available probabilities follow a homogeneous Markov chain. Xiang et al.  require that clients be capable of continuous local optimization regardless of communication failures. A handful of other works [14; 60] memorize the old gradients of the unavailable clients to compensate for their unavailability. However, the added memory burdens the federated learning system with substantial memory proportional to the product of the number of clients and the model dimension.

**Contributions**. In this work, we focus on stochastic client unavailability, where client \(i\) is available for federated learning model training with probability \(p_{i}^{t}\) at any time \(t\). An illustration can be found in Fig. 1. Our contributions are four-fold:

* In Section 4, via constructing concrete examples, we demonstrate that both heterogeneity and non-stationarity of \(p_{i}^{t}\) will result in bias and thus significant performance degradation of FedAvg.
* In Section 5, we propose an algorithm named FedAVE, which features computational and memory efficiency: only \(O(1)\) additional computation and memory per client will be used when compared with FedAvg. The design of FedAWE introduces two novel algorithmic structures: _adaptive innovation echoing_ and _implicit gossiping_. At a high level, these novel algorithmic structures (i) help clients catch up on the missed computation, and (ii) simultaneously enable a balanced information mixture through implicit client-client gossip, which ultimately corrects the remaining bias. Notably, no direct neighbor information exchanges are used, and the client unavailability dynamics remains unknown to all clients and the parameter server.
* In Section 6, we show that FedAWE converges to a stationary point of even non-convex global objective and achieves the linear speedup property without conditions on second-order partial derivatives of the loss function in analysis.
* In Section 7, we validate our analysis with numerical experiments over diversified client unavailability dynamics on real-world data sets.

## 2 Related Work

**Dynamical client availability.** There is a recent surge of efforts to study time-varying client availability [45; 44; 7; 54; 44; 42; 58; 11], which can be roughly classified into two categories depending on whether the parameter server can unilaterally determine the participating clients.

(i) _Controllable participation._ Earlier research [32; 29] presumes that, in each round, the parameter server could select a small set of clients either uniformly at random or in proportion to the volume of local data held by clients. More recently, Cho et al.  design adaptive and non-uniform client sampling to accelerate learning convergence, albeit at the cost of introducing a non-zero residual error. In another work, Cho et al.  study the convergence of FedAvg with cyclic client participation. Yet, the set of available clients is sampled uniformly at random per cyclic round and is decided unilaterally by the parameter server. Perazzone et al.  consider heterogeneous and time-varying response rates \(p_{i}^{t}\) under the assumptions that \(p_{i}^{t}\) is known a priori and that the stochastic gradients are bounded in expectation. Furthermore, the dynamics of \(p_{i}^{t}\) are determined by the parameter server by solving a stochastic optimization problem. Chen et al.  propose a client sampling scheme wherein only the clients with the most "important" updates communicate back to the parameter server. This sampling method can achieve performance comparable to that of full client participation, provided that \(p_{i}^{t}\) is globally known to both the parameter server and the clients. Departing from this line of literature, our setup neither assumes any side information or prior knowledge of the response rates \(p_{i}^{t}\) nor assumes that the parameter server has any influence on \(p_{i}^{t}\).

(ii) _Uncontrollable participation._ There is a handful of work on building resilience against arbitrary client availability [44; 54; 60; 14; 62; 55]. Ribero et al.  consider random client availability whose underlying response rates are also heterogeneous and time-varying with unknown dynamics.

Figure 1: Client \(i\)’s available probabilities \(p_{i}^{t}\)’s are heterogeneous and are subject to _non-stationary_ dynamics.

However, the underlying dynamics of \(p_{i}^{t}\) in  are assumed to follow a homogeneous Markov chain. Wang and Ji  propose a generalized FedAvg that amplifies parameter updates every \(P\) rounds for some carefully tuned \(P\). Despite its elegant and unified analysis and potential to accommodate non-independent unavailability dynamics, to reach a stationary point, \(p_{i}^{t}\) needs to satisfy some assumptions to ensure roughly equal availability of all clients over every \(P\) round. Sharing a similar spirit, Crawshaw and Liu  propose a SCAFFOLD variant that amplifies global parameter and local gradient updates every \(P\) round. In spite of its communication efficiency and resilience to data heterogeneity, the rolling average of \(p_{i}^{t}\) over every \(P\) round is assumed to be the same constant for all clients. Yang et al.  analyze a setting where clients participate in the training at their will. Yet, their convergence is shown to be up to a non-zero residual error. The algorithms proposed in  share the same idea of using the memorized latest updates from unavailable clients for global aggregation. Despite superior numerical performance, both algorithms demand a substantial amount of additional memory . For non-convex objectives, both  and  require an absolute bounded inactive period, and share similar technical assumptions such as almost surely bounded stochastic gradients  or Lipschitz Hessian . Though bounded inactive periods are relevant for applications wherein the sensors wake up on a periodic schedule, this assumption is not satisfied even for the simple stochastic setting when clients are selected uniformly at random. Wang and Ji consider unknown heterogeneous \(p_{i}\)' in a concurrent work ; however, \(p_{i}\)'s are assumed to be fixed over time.

**Asynchronous federated learning.** Another related line of work is asynchronous federated learning. To the best of our knowledge, Xie et al.  initialize the study of asynchronous federated learning, wherein the parameter server revises the global model every time it receives an update from a client. Convergence is shown under some technical assumptions such as weakly-convex global objectives, bounded delay, and bounded stochastic gradients. Zakerinia et al.  propose QuAFL which is shown to be resilient to computation asynchronicity and quantized communication yet under the bounded and stationary delay assumption. Nguyen et al.  propose FedBuff, which uses additional memory to buffer asynchronous aggregation to achieve scalability and privacy. Convergence is shown under bounded gradients and bounded staleness assumptions. In fact, most convergence guarantees in the asynchronous federated learning literature rely on bounded staleness , or bounded gradients . Recently, arbitrary delay is considered in the context of distributed SGD with bounded stochastic gradients and \((0,)\)-bounded inter-client heterogeneity  (see Assumption 4 for the definition). The convergence suffers from a non-zero residual term \(O(^{2})\). In contrast, our convergence guarantee is free from non-zero residual terms and does not require gradients to be bounded.

## 3 Problem Formulation

A federated learning system consists of a parameter server and \(m\) clients that collaboratively minimize

\[_{^{d}}F()_{i=1}^{m}F_{ i}(),\] (1)

where \(F_{i}()_{_{i}_{i}}[_{i}( ;_{i})]\) is the local objective and can be non-convex, \(_{i}\) is the local distribution, \(_{i}\) is a stochastic sample that client \(i\) has access to, \(_{i}\) is the local loss function, and \(d\) is the model dimension.

We use Assumption 1 to capture the uncertain _non-stationary_ dynamics and heterogeneity. Let \(^{t}\) denote the set of active clients, \(_{\{\}}\) an indicator function, \(T\) the number of total training rounds.

**Assumption 1**.: There exists a \((0,1]\) such that \(p_{i}^{t}[_{\{i^{t}\}}]\), where the events \(\{i^{t}\}\) are independent across clients \(i\) and across rounds \(t[T]\).

Assumption 1 subsumes uniform availability  and stationary availability considered in . Independent client unavailability is widely adopted by federated learning research . Analyzing non-independent unavailability, together with uncertain and non-stationary dynamics in Assumption 1, is in general challenging. Specifically, the involved entanglement of stochastic gradient and availability statistics fundamentally complicates the theoretical analysis. However, we conjecture that independence and strictly positive probabilities are only necessary for the technical convenience of our analysis. Our experiments in Section 7 suggest that our algorithm offers notable improvement even in the presence of non-independent and occasionally zero-valued probabilities.

Future work will investigate how to provably accommodate correlated or zero-valued probabilities of arbitrary probabilistic trajectories.

## 4 Heterogeneity and Non-stationarity May Lead to Significant Bias

In this section, we illustrate the impacts of heterogeneity and non-stationarity of client availability under the classic FedAvg. We use two examples to showcase the significant bias incurred.

**Example 1** (Heterogeneity).: Suppose that \(m=2\) and \(p_{i}^{t}=p_{i}\) for \(i\). Let \(F_{i}(x)\|x-u_{i}\|_{2}^{2}/2\), where \(x,u_{i}\). The global objective (1) is

\[F(x)=(\|x-u_{1}\|_{2}^{2}+\|x-u_{2} \|_{2}^{2}),\] (2)

with unique minimizer \(x^{}=(u_{1}+u_{2})/2\). Let \(u_{1}=0\) and \(u_{2}=100\). Fig. 2 illustrates how the heterogeneity in \(p_{i}\) affects the expected output of FedAvg.

Example 1 matches [55, Theorem 1], which shows that FedAvg leads to a biased global objective (3) under heterogeneous \(p_{i}\)'s, and that (3) may be significantly away from (1) depending on \(p_{i}\)'s.

\[()_{i=1}^{m}}{_{j=1}^{m}p_{j} }F_{i}().\] (3)

When the probabilistic dynamics of \(p_{i}^{t}\)'s is non-stationary, obtaining an exact biased objective similar to (3) in a neat analytical form becomes challenging, if not impossible, due to the unstructured non-stationary dynamics. Fortunately, Example 2 helps us confirm that the complex interplay between \(p_{i}^{t}\)'s across rounds and clients will inevitably further degrade the performance of FedAvg algorithm.

**Example 2** (Non-stationarity).: In Fig. 3, a total of \(m=100\) clients perform an image classification task on the SVHN dataset  under the FedAvg algorithm, whose local dataset distribution follows \((0.1)\). Clients become available with probability \(p_{i}^{t}=p[(0.1 t)+(1-)],\  i[m]\). The hyperparameter details are deferred to Appendix J. Observations can be found in the caption.

## 5 Federated Agile Weight Re-Equalization (FedAWE)

To minimize (1), one natural idea is to have the entire client population performs the same number of local updates and mixes these updates carefully to ensure they are weighted equally. Unfortunately, when clients are available only intermittently, they will miss some rounds. A naive approach to equalizing the number of local updates is to have clients catch up by performing their missed local computations immediately when they become available. However, this approach requires a daunting

Figure 3: Train and test accuracy results in percentage (%). In particular, the parameter \(\) signifies the degree of non-stationary. Notice that, as the client availability becomes more non-stationary (a larger \(\)), FedAvg experiences a significant drop in accuracy. For example, both the train and test accuracies drop by over \(10\%\) when \(p=0.1\), and \(\) increases from \(0.1\) to \(0.5\).

amount of resources and may not be possible due to hardware/software constraints. Formally, recall that \(^{t}\) is the set of available clients at time \(t\). Let \(_{i}(t)\{t^{}:\ t^{}<ti^{t^{}}\}\) denote the most recent (with respect to time \(t\)) round that client \(i\) is available. Compared with standard FedAvg, the naive "catch-up" procedure will consume \((t-_{i}(t)-1) s\) local stochastic gradient descent updates and \((t-_{i}(t)-1)\) additional stochastic samples, where \(s\) is the number of local updates per round when a client is available in standard FedAvg.

In this work, we target computation-light algorithms that, compared with FedAvg, only take \(O(1)\) additional computation without additional stochastic samples. We propose **Fed**erated **A**gile **W**eight **R**e-**E**qualization (FedAWE), which is formally described in Algorithm 1. It involves two novel algorithmic structures: _adaptive innovation echoing_ and _implicit gossiping_. At a high level, these novel algorithmic structures (i) help clients catch up on the missed computation, and (ii) simultaneously enable a balanced information mixture through implicit client-client gossip, which ultimately corrects the remaining bias.

In Algorithm 1, each client keeps two local variables \(_{i}\) and \(_{i}\), along with a few auxiliary variables used in updating \(_{i}\) and \(_{i}\). The algorithm inputs are rather standard: total training rounds \(T\), local and global learning rates \(_{l}\) and \(_{g}\), the number of local updates per round \(s\), and the initial model \(^{0}\). In each round \(t\), similar to FedAvg, an available client \(i^{t}\) performs \(s\) steps of stochastic gradient descent on its local model \(_{i}^{t}\) (lines 5-8), where \(_{i}(;_{i}^{(t,k)})\) is the stochastic gradient of sample \(_{i}^{(t,k)}\). Next, we describe the two novel algorithmic structures used in FedAWE.

```
1Inputs:\(T\), \(s\), \(_{l}\), \(_{g}\), \(^{0}\).
2for\(i[m]\)do\(_{i}^{0}^{0}\) and \(_{i}(0)-1\) ;
3for\(t=0,,T-1\)do
4for\(i^{t}\)do
5\(_{i}^{(t,0)}_{i}^{t}\);
6for\(k=0,,s-1\)do
7\(_{i}^{(t,k+1)}_{i}^{(t,k)}-_{l}_{i}(_{i}^{(t,k)};_{i}^{(t,k)})\);
8
9 end for
10\(_{i}^{t}_{i}^{t}-_{i}^{(t,s)}\);
11\(_{i}^{t}_{i}^{(t,0)}-_{g}(t-_{i}(t)) _{i}^{t}\);
12\(_{i}(t+1) t\);
13
14 Report \(_{i}^{t}\) to the parameter server;
15
16 end for
17
18 end for ```

**Algorithm 1**FedAWE

**Adaptive innovation echoing.** Departing from FedAvg wherein the local estimate \(_{i}^{t}\) is updated as \(_{i}^{t}_{i}^{(t,0)}-_{g}_{i}^{t}\). In FedAWE (lines 10-11), we "echo" the local innovation \(_{i}^{t}\) by multiplying it by \((t-_{i}(t))\). Intuitively, this simple echoing helps us approximately equalize the number of local improvements, as formally stated in Proposition 1. It says that the total numbers of innovations echoing are the same for all active clients for any given round and allows the unavailable clients to catch up to the missed computations when they become available.

**Proposition 1**.: _If \(_{\{i^{R-1}\}}=1\), it holds that \(_{t=0}^{R-1}_{\{i^{t}\}}(t-_{i}(t)) =R,\ \ R 1\)._

**Implicit gossiping.** In FedAWE, the parameter server does not send the most recent global model to the active clients at the beginning of a round. Instead, the parameter server aggregates the locally updated models \(_{i}^{t}\) and sends the new global model \(_{i}^{t+1}\) to all active clients \(^{t}\) (lines 14-15). By postponing multicasting the shared global model, the active clients in \(^{t}\)_implicitly gossip_ their updated local models with each other through the parameter server . Though the postponed multi-cast brings in staleness, a simple coupling argument shows that the staleness is bounded (Lemma 2). In addition, our empirical results (Table 8 in Appendix J) suggest that there is no significant slowdown when compared to vanilla FedAvg. Gossip-type algorithms were originally proposed for peer-to-peer networks and are well-known for their agility to communication failures and asynchronous information exchange in achieving average consensus [13; 4; 24; 16; 31; 36]. Intuitively, the clients' local estimates are eventually equally weighted in the final algorithm output. Note that, departing from the standard gossiping protocols therein [24; 46], information exchange in FedAvg does not involve client-client communication. The information mixing matrix under FedAvg is defined in (4), which is doubly stochastic. Let \(M^{(t)}[(W^{(t)})^{2}]\), \((t)_{2}(M^{(t)})\), \(=^{}/m\), and \(_{t}(t)\), where \(_{2}()\) denotes the second largest eigenvalue. We next characterize the information mixing error, i.e., consensus error in Lemma 1.

**Lemma 1** ([35; 34; 51]).: _For any matrix \(B^{d m}\), it holds that \(_{W}[\|B(_{r=1}^{t}W^{(r)}-)\|_{F}^{2}] ^{t}\|B\|_{}^{2}\), where the expectation is taken with respect to randomness in \(W\) matrices._

## 6 Convergence Analysis

In this section, we analyze the convergence of FedAvg. All missing proofs and intermediate results are deferred to the Appendix. Details can be found in Table of Contents.

### Assumptions

We start by stating regulatory assumptions that are common in federated learning analysis [27; 52; 23].

**Assumption 2**.: Each local objective function \( F_{i}()\) is \(L\)-Lipschitz, i.e.,

\[\| F_{i}(_{1})- F_{i}(_{2})\|_{2} L \|_{1}-_{2}\|_{2},\;_{1},\;_{2},\; \;\;i[m].\]

**Assumption 3**.: Stochastic gradients \(_{i}(;)\) are unbiased with bounded variance, i.e.,

\[[_{i}(;)]= F_{i}( {x})\;\;[\|_{i}(;)- F_{ i}()\|_{2}^{2}]^{2},\;\;i[m].\]

**Assumption 4**.: The divergence between local and global gradients is bounded for \(,\; 0\) such that

\[_{i=1}^{m}\| F_{i}()- F()\|_ {2}^{2}^{2}\| F()\|_{2}^{2}+^{2}.\] (5)

When the local data sets are homogeneous, \( F_{i}()= F()\) holds for any client \(i[m]\), resulting in \(==0\). Assumption 4 and its variants in Table 1 are often referred to as bounded gradient dissimilarity assumption to account for data heterogeneity across clients. It can be easily checked that our Assumption 4 is more relaxed or equivalent to the variants therein.

### Auxiliary/Imaginary update sequence construction.

Directly analyzing the evolution of \(^{t}\) and \(^{t}_{i}\) is challenging due to the fact that different clients update at different rounds, and that different active clients echo their local innovation \(^{t}_{i}\) (line 9 in Algorithm 1) with different strength \((t-_{i})\). As such, we construct an auxiliary/imaginary update sequence \(^{t}_{i}\) for client \(i[m]\), whose evolution is closely coupled with \(^{t}\) and \(^{t}_{i}\) but is easier to analyze. Note that the auxiliary/imaginary update sequence is never actually computed by clients but acts as a necessary tool in building up the analysis.

**Definition 1**.: _The auxiliary sequence \(\{^{t}_{i}\}\) of client \(i[m]\) is defined as_

\[^{t}_{i}\;\;^{t}_{i}-_{l}_{g}s(t-_{i}(t)-1)  F_{i}(^{_{i}(t)+1}_{i}),\;\;i[m].\] (6)

 
**Bounded Gradient Dissimilarity** & **References** \\  \(_{}\| F_{i}()\|_{2}^{2}^{2},\; \;i[m]\) & [29; 66; 9; 10; 60] \\  \(_{i=1}^{m}\| F_{i}()\|_{2}^{2}^{2 }\| F()\|_{2}^{2}\) & [27; 28] \\  \(_{i=1}^{m}\| F_{i}()- F()\|_{2 }^{2}^{2}\) & [53; 65; 18; 56; 1; 22; 54; 62] \\  \(_{i=1}^{m}\| F_{i}()\|_{2}^{2}^{2 }\| F()\|_{2}^{2}+^{2}\) & [23; 68; 52; 51; 14] \\  

Table 1: Popular variant assumptions on gradient dissimilarity.

Recall that \(_{i}(0)=-1\). Thus, by definition, \(_{i}^{0}=_{i}^{0}\) according to (6). For general \(t\), when client \(i^{t-1}\), we simply have \(_{i}(t)=t-1\) and thus \(t-1-_{i}(t)=t-1-(t-1)=0\). That is, the auxiliary model \(_{i}^{t}\) and the real model \(_{i}^{t}\) are _identical_ whenever the client \(i\) becomes available in the previous round.

* When \(i^{t-1}\), the iterate of \(_{i}\) is a bit more involved: \[_{i}^{t})}}{{=}}_{i}^{t} )}}{{=}}^{t-1}} (_{j}^{t-1}+(_{j}^{t-1}-_{j}^{t-1}}_{()})-_{l}_{g}(t-1-_{j}(t-1))_{j}^{t-1}),\] (7) where \(()\) holds because of Definition 1 and \(i^{t-1}\), \(()\) because of line 10 in Algorithm 1, addition and subtraction. \(()\) can be expanded by (6). We defer the simplified form of (7) to (18) in Appendix C for a tidy presentation.
* When \(i^{t-1}\), \(_{i}^{t}\) has a simple iterative relation: \[_{i}^{t}\;=\;_{i}^{t-1}-_{l}_{g}s F_{i}(_{i}^{ _{i}(t-1)+1}).\] (8) At a high level, the sequence \(_{i}^{t}\) approximately mimics the ideal descent evolution at a client as if the client performs local optimizations on its local model \(_{i}\) per round regardless of its availability. Mathematically, the idea is that, if the progress per iteration of the auxiliary sequence \(_{i}^{t}\) is bounded, we can show the convergence of \(_{i}^{t}\) when \(_{i}^{t}\) and \(_{i}^{t}\) are close to each other.

It is worth noting that auxiliary sequences are used in peer-to-peer distributed learning literature [47; 2; 30; 67; 48; 34]. Yet, existing constructions are not applicable to our problem due to (1) the non-convexity of the global objectives, (2) multiple local updates per round, (3) possibly unbounded gradients, and (4) the general form of bounded gradient dissimilarity. Departing from the use of staled stochastic gradients for auxiliary updates therein, we adopt the true gradient \( F_{i}()\) to avoid the complications from the involved interplay between randomness in stochastic samples and randomness in \(_{i}(t)\). On the technical front, it follows from Definition 1 that \(\|_{i}^{t}-_{i}^{t}\|_{2}^{2}_{l}^{2}_{g}^{2}s^{2}(t- _{i}(t)-1)^{2}\| F_{i}(_{i}^{_{i}(t)+1})\|_{2}^{2}\), whose bound appears to be quite challenging to derive due to the coupling of different realizations of \(_{i}(t)\) and gradients. As such, we bound the average of \(\|_{i}^{t}-_{i}^{t}\|^{2}\) across clients and rounds in Proposition 2.

**Lemma 2** (Unavailability statistics).: _Under Assumption 1 and \(\) defined therein. It holds for \(t 0\) that \([t-_{i}(t)] 1/\) and \([(t-_{i}(t))^{2}] 2/^{2}\)._

Lemma 2 yields an upper bound on the first and second moments of a client \(i\)'s unavailable duration despite the unstructured nature of clients' non-stationary and heterogeneous unavailability. In the special case where we have clients available with the same probability \(\), the duration simply follows a homogeneous geometric distribution. It can be easily checked that our bounds trivially hold. However, the duration becomes a more challenging _non-homogeneous_ geometric random variable under our non-stationary unavailability dynamics. Lemma 2 can be derived by using a simple coupling argument and by using tools from probability theory .

### Main results.

Let \(}_{t}_{i=1}^{m}_{i}^{t}\), \(F^{}_{}F()\), and \(_{}_{i[m],t[T]}p_{i}^{t}\).

**Lemma 3** (Descent Lemma).: _Let \(^{t}\) define the sigma algebra generated by randomness up to round \(t\). Suppose Assumptions 2, 3 hold and \(_{l}_{g} 9/(100sL)\), it holds that_

\[[F(}^{t+1})-F(}^{t}) ^{t}] -_{g}s}{4}\| F(}^{t}) \|_{2}^{2}\] \[+_{g}sL^{2}(_{l}_{g} _{}+4.5m_{l}^{2}sL)}{m^{2}}_{i=1}^{m}(t-_{i}(t))^{2}\] \[+_{l}^{3}s^{3}L^{2}}{m}_{i=1}^{m}(t- _{i}(t))^{2}\| F_{i}(_{i}^{_{i}(t)+1})\|_{2}^{2}\] \[+_{g}sL^{2}}{m}_{i=1}^{m} {\|_{i}^{t}-_{i}^{t}\|_{2}^{2}}_{}+_{g}sL^{2}}{2m}_{i=1}^{m} _{i}^{t}-}^{t}\|_{2}^{2}}_{}.\]

[MISSING_PAGE_FAIL:8]

Moreover, from (12), (14) and (15), it can be seen that (16) holds.

\[_{t=0}^{T-1}_{i=1}^{m}[\|_{i}^{t}- }^{t}\|_{2}^{2}]_{t=0}^{T-1}[\| F(}^{t})\|_{2}^{2}] _{t=0}^{T-1}[\| F(}^{t})\|_{2}^{ 2}].\] (16)

Combining (12), (13), (14) and (15), we are ready for Corollary 1.

**Corollary 1** (Convergence rate of \(_{i}^{t}\)).: _Suppose that Assumptions 1, 2, 3 and 4 hold. Choose learning rates as \(_{l}=}\), \(_{g}=\) such that the conditions in (11) are met for \(T 1\), it holds that_

\[_{t=0}^{T-1}[\| F(}^{t}) \|_{2}^{2}]}^{0})-F^{} )}{}+}{^{}}^{2}+(+^{2}}{(1- )^{2}}).\] (17)

Corollary 1 establishes the full convergence rate for FedAWE algorithm. It can be seen that the first and second terms dominate when \(T\) is sufficiently large, which relate to initial suboptimality gap and stochastic gradient noise \(^{2}\), respectively. The non-stationary client unavailability results in the third term, which relates to gradient divergence \(^{2}\) and also to \(^{2}\). The proof of Corollary 1 follows from (15) by plugging in Proposition 2 and Theorem 1. In the special case where \(k\) clients participate uniformly at random, we simply have \(_{}==k/m\). Our convergence bound attains the rate of \(O(1/)\). In other words, we achieve the desired linear speedup property with respect to the number of local steps \(s\) and the number of active clients \(k\), matching the established literature . The linear speedup property enables a large cross-device federated learning system to take advantage of a massive scale of parallelism. Notice that the consensus error (16) and the convergence rate (17) have the same asymptotic order with respect to the parameters therein. Hence, the consensus error also enjoys the desired linear speedup property when \(T\) is sufficiently large.

## 7 Numerical Experiments

**Overview.** In this section, we evaluate FedAWE on real-world data sets to corroborate our analysis and compare it with the other state-of-the-art algorithms. The missing specifications and additional results can be found in Appendix J. Specifically, we consider a federated learning system of one parameter server and \(m=100\) clients, wherein clients become available intermittently. The image classification tasks use CNNs and are based on SVHN , CIFAR-10  and CINIC-10  data sets. All of them include \(10\) classes of images of different categories. To emulate a highly heterogeneous local data distribution, the image class distribution \(_{i}(=0.1)\) at client \(i\).

**Non-stationary client unavailability.** A total of four unavailable dynamics are evaluated in Table 2, including stationary and _non_-stationary with staircase, sine and interleaved sine trajectories, with their visualizations available in the same table. The classification tasks become more challenging as the list progresses due to the growing complexity in the non-stationary dynamics. Furthermore, our choices of the non-stationary dynamics are motivated by real-world federated learning participation statistics, for example, sine trajectory , and by generalizing the existing participation patterns such as cyclic participation . In particular, the interleaved sine dynamics is more challenging than the vanilla cyclic availability dynamics since clients become available during each active period with probability that is less than 1 and non-stationary simultaneously. Formally, client \(i\)'s dynamics is defined as \(p_{i}^{t}=p_{i} f_{i}(t)\), where \(f_{i}(t)\) is a time-dependent function under non-stationary dynamics but \(f_{i}(t)=1\) when stationary, and \(p_{i}=_{i},\). \(\) characterizes the unbalanced contribution of different image classes to the generated probabilities. Each element of \([]_{c}\) is drawn from \((0,_{c})\), where a smaller \(_{c}\) leads to a less significant contribution of that image class.

Correlating the local data distribution and the probability of client availability is a common practice in the prior literature. For example, Gu et al. in  experiment with a formula for \(p_{i}\) so that clients that hold images of smaller digits participate less frequently. Wang and Ji in  construct \(p_{i}\) as an inner product of the clients' local data distribution \(_{i}\) and an external distribution \(^{}\). It is immediately clear that the coupling of local data distribution \((_{i}(=0.1))\) and class contribution \(\) leads to _non-independent_\(p_{i}\)'s. In addition, Assumption 1 will not hold in the case of interleaved sine non-stationary dynamics since \(p_{i}^{t}\)'s occasionally reach 0. Although being agnostic to the challenging client unavailability dynamics not covered by our analysis, we observe that FedAWE retains its outperformance. Comparisons will be specified next.

**Benchmark algorithms and discussions.** We compare FedAWE with six baseline algorithms, including FedAvg over active clients , FedAvg over all clients, FedAU , F3AST , FedAvg with known \(p_{i}^{*}\), MIFA  and FedVARP . The details of the algorithm and the additional results are deferred to Appendix J. It is observed that FedAWE consistently outperforms the algorithms not aided by memory or known statistics. Surprisingly, FedAWE occasionally beats MIFA and FedVARP, which are memory-heavy. We attribute it to reuse of stored gradients from the unavailable clients. Although FedAWE brings in stalens due to implicit gossiping, our results (Table 8 in Appendix J) indicate that there is no significant slowdown for FedAWE when compared to vanilla FedAvg, where we study the first round to achieve a targeted accuracy by different algorithms. In addition, FedAWE attains competitive or even better performance than FedAvg with known probability, yet unknown to the underlying dynamics in client unavailability.

## 8 Conclusion

In this paper, we have shown that the impacts of heterogeneous and non-stationary client unavailability can be significant through concrete examples on FedAvg. To address this, we have proposed an algorithm FedAWE, which provably converges by adaptively echoing clients' local improvement and by evenly diffusing local updates through implicit gossiping. Theoretically, it achieves the desired linear speedup property. Experiments have validated the superiority of FedAWE over state-of-the-art algorithms under diversified non-stationary dynamics. Future work will investigate how to extend our analysis to broader unavailability dynamics such as non-independent and non-stationary unavailability and how to incorporate our findings into federated learning algorithms of different local optimization methods.

    &  &  &  &  \\   &  &  &  &  &  &  &  \\   Stationary \\  } & FedAWE (ours) & **86.5**\(\) 0.7 \(\) & **86.1**\(\) 0.7 \(\) & **68.1**\(\) 1.4 \(\) & **66.3**\(\) 1.1 \(\) & **47.9**\(\) 2.1 \(\) & **47.3**\(\) 2.0 \(\) \\  & FedAvg over active & 82.6 \(\) 1.0\(\) & 82.4 \(\) 1.1 \(\%\) & 64.1 \(\) 1.9 \(\%\) & 62.9 \(\) 1.4 \(\%\) & 43.6 \(\) 2.4 \(\%\) & 43.1 \(\) 2.4 \(\%\) \\  & FedAvg over all & 76.1 \(\) 1.2 \(\%\) & 76.1 \(\) 2.4 \(\%\) & 58.2 \(\) 1.2 \(\%\) & 55.4 \(\) 1.8 \(\%\) & 38.4 \(\) 2.1 \(\%\) & 38.0 \(\) 2.1 \(\%\) \\  & FedAWE & 83.4 \(\) 1.0 \(\%\) & 83.2 \(\) 1.0 \(\%\) & 65.4 \(\) 1.4 \(\%\) & 54.1 \(\) 1.0 \(\%\) & 45.6 \(\) 1.5 \(\%\) & 45.5 \(\) 1.5 \(\%\) \\   _F3AST_ \\  } & F3AST & 83.2 \(\) 0.7 \(\%\) & 83.2 \(\) 0.7 \(\%\) & 64.4 \(\) 1.1 \(\%\) & 63.3 \(\) 0.9 \(\%\) & 45.3 \(\) 1.2 \(\%\) & 44.8 \(\) 1.2 \(\%\) \\   & FedAWE with known \(p_{i}\)’s & 86.1 \(\) 0.5 \(\%\) & 85.6 \(\) 0.5 \(\%\) & 63.4 \(\) 1.0 \(\%\) & 63.1 \(\) 0.9 \(\%\) & 45.0 \(\) 1.2 \(\%\) & 44.6 \(\) 1.1 \(\%\) \\  & & HTA (memory) added & 84.2 \(\) 0.5 \(\%\) & 84.1 \(\) 0.6 \(\%\) & 66.6 \(\) 0.5 \(\%\) & 63.5 \(\) 0.5 \(\%\) & 47.5 \(\) 0.5 \(\%\) & 46.9 \(\) 0.5 \(\%\) \\  & FedVARP (memory) added & 84.6 \(\) 0.2 \(\%\) & 84.3 \(\) 0.1 \(\%\) & 67.5 \(\) 0.2 \(\%\) & 66.3 \(\) 0.3 \(\%\) & 47.8 \(\) 0.2 \(\%\) & 47.2 \(\) 0.2 \(\%\) \\   **Non-stationary** \\ **(Sine)** \\  } & FedAWE (ours) & **85.9**\(\) 0.8 \(\) & **85.6**\(\) 1.0 \(\%\) & **67.7**\(\) 1.3 \(\%\) & **66.0**\(\) 1.2 \(\%\) & **47.5**\(\) 2.0 \(\%\) & **46.9**\(\) 2.0 \(\%\) \\  & FedAvg over active & 82.5 \(\) 1.0 \(\%\) & 82.4 \(\) 0.9 \(\%\) & 64.2 \(\) 1.8 \(\%\) & 63.0 \(\) 1.4 \(\%\) & 43.7 \(\) 2.0 \(\%\) & 42.9 \(\) 2.2 \(\%\) \\  & FedAvg over all & 75.9 \(\) 1.4 \(\%\) & 75.9 \(\) 2.3 \(\%\) & 55.7 \(\) 1.2 \(\%\) & 55.4 \(\) 1.8 \(\%\) & 38.4 \(\) 2.0 \(\%\) & 37.9 \(\) 2.0 \(\%\) \\  & FedAWE & 83.6 \(\) 0.8 \(\%\) & 33.4 \(\) 0.8 \(\%\) & 65.2 \(\) 1.7 \(\%\) & 63.2 \(\) 1.5 \(\%\) & 45.7 \(\) 1.5 \(\%\) & 45.1 \(\%\) \\  & F3AST & 83.1 \(\) 0.6 \(\%\) & 83.1 \(\) 0.6 \(\%\) & 64.3 \(\) 1.1 \(\%\)