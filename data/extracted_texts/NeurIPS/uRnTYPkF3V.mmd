# For \(t=1,2,...,T\)do

Sequential Probability Assignment with Contexts: Minimax Regret, Contextual Shtarkov Sums, and Contextual Normalized Maximum Likelihood

 Ziyi Liu

University of Toronto & Vector Institute

kevind.liu@mail.utoronto.ca &Idan Attias

Ben-Gurion University & Vector Institute

idanatti@post.bgu.ac.il &Daniel M. Roy

University of Toronto & Vector Institute

daniel.roy@utoronto.ca

###### Abstract

We study the fundamental problem of sequential probability assignment, also known as online learning with logarithmic loss, with respect to an arbitrary, possibly nonparametric hypothesis class. Our goal is to obtain a complexity measure for the hypothesis class that characterizes the minimax regret and to determine a general, minimax optimal algorithm. Notably, the sequential \(_{}\) entropy, extensively studied in the literature (Rakhlin and Sridharan, 2015, Bilodeau et al., 2020, Wu et al., 2023), was shown to not characterize minimax regret in general. Inspired by the seminal work of Shtarkov (1987) and Rakhlin, Sridharan, and Tewari (2010), we introduce a novel complexity measure, the _contextual Shtarkov sum_, corresponding to the Shtarkov sum after projection onto a multiary context tree, and show that the worst case log contextual Shtarkov sum equals the minimax regret. Using the contextual Shtarkov sum, we derive the minimax optimal strategy, dubbed _contextual Normalized Maximum Likelihood_ (cNML). Our results hold for sequential experts, beyond binary labels, which are settings rarely considered in prior work. To illustrate the utility of this characterization, we provide a short proof of a new regret upper bound in terms of sequential \(_{}\) entropy, unifying and sharpening state-of-the-art bounds by Bilodeau et al. (2020) and Wu et al. (2023).

## 1 Introduction

Sequential probability assignment is a fundamental problem with connections to information theory (Ris84; MF98; XB00), machine learning (CL06; Vov95; RST15; FKLMS18; Sha20), and portfolio optimization (Ke15; Cov74; Cov91; CO96; Fed91). In the original non-contextual setup, the learner aims to assign probabilities to a series of labels, which are revealed sequentially. The goal is to offer probabilistic forecasts over the label set such that the probability assigned to any observed sequence is comparable to that assigned by the best model in any fixed class of models.

The celebrated work of Shtarkov (Sht87) characterized minimax regret for context-free sequential probability assignment in terms of what is now known as the _Shtarkov sum_, and subsequently described the minimax algorithm, _Normalized Maximum Likelihood_ (NML). NML represents the ideal probabilistic forecast in the sense of minimax regret, providing a benchmark for universal coding and prediction strategies. While often not used directly due to its computational complexity, NML has guided the design of practical algorithms and informed the development of efficient approxima

[MISSING_PAGE_FAIL:2]

A long line of work has focused on controlling minimax regret for rich classes in terms of covering numbers.  upper bounded the regret in terms of the (non-sequential) uniform covering number of the class. However, this complexity measure proved to be insufficient for obtaining optimal rates.  improved regret upper bounds by proposing a sequential covering measure. Thereafter, by utilizing the self-concordance property and the curvature of the log loss,  further improved the upper bound in terms of the sequential covering number for nonparametric Lipschitz classes, through a non-constructive proof.  proposed a Bayesian algorithmic approach in order to upper bound the regret using a global notion of sequential covering. Notably, both the global and local sequential covering numbers do not fully characterize the regret, and the algorithm in  is not minimax optimal. By relaxing the worst-case analysis,  studied this problem within the smoothed analysis framework, where nature is not fully adversarial but constrained.

Online learning with respect to arbitrary hypothesis classes and the zero-one loss, in the realizable case, is known to be characterized by the Littestone dimension . The agnostic case was addressed by . Understanding sequential complexities in online learning with Lipschitz losses was extensively studied by . Note that the logarithmic loss is neither Lipschitz nor bounded. Recently,  characterized online regression in the realizable case, for any approximate pseudo-metric, such as the \(_{p}\) loss.

## 2 Preliminaries

Notation.For a positive integer \(K\), let \([K]:=\{1,2,,K\}\). For a finite set \(\) with \(||=K\), we use \(()\) to denote the set of all distributions on \(\). We may identify \(\) with \([K]\) (under arbitrary enumeration of elements in \(\)) and treat elements of \(()\) as vectors in \(^{K}\). For a vector \(p^{K}\) and \(i[K]\), let \(p(i)\) be the \(i\)-th coordinate of \(p\). Let \(^{+}()=\{p():p(k)>0, k\}\). For a general finite sequence \((a_{i})_{i=1}^{N}\), we will use \(a_{n:m}\) to denote the sub-sequence \((a_{n},,a_{m})\) for any \(n m\) and the empty sequence for \(n>m\). For any set \(\), let \(^{*}=_{k 0}^{k}\) be the set of all finite length sequences over \(\).

Sequential probability assignment and minimax regret.Let \(\) be the context space and \(\) be the finite label space. In each round \(t[T]\) during the game of sequential probability assignment, the learner receives a context \(x_{t}\) from nature and assigns a probability distribution \(_{t}()\) to the possible labels. Then nature reveals the true label \(y_{t}\) and the learner incurs a loss \((_{t},y_{t})=-(_{t}(y_{t}))\). Throughout, the learner is required to predict nearly as well as the best expert from an expert class, which is modeled as an arbitrary hypothesis class \(\{()^{*} ()\}\). More formally, the goal of the learner is make their _regret_ with respect to \(\),

\[_{T}(;_{1:T},x_{1:T},y_{1:T})=_{t=1}^{T} (_{t},y_{t})-_{f}_{t=1}^{T}(f(x_{1:t},y_{1:t- 1}),y_{t}),\]

as small as possible for all sequences \(\) and \(\) generated by nature, possibly in an adversarial manner. Here \(f(x_{1:t},y_{1:t-1})()\) can be understood as the prediction made by expert \(f\) at round \(t\) using past observations \((x_{1:t-1},y_{1:t-1})\) as well as the fresh context \(x_{t}\). The main focus is to study the _minimax regret_\(_{T}()\), which can be written as the following extensive form

\[_{T}()=_{x_{t}}_{_{1}}_{y_{1}} _{x_{T}}_{_{T}}_{y_{T}}_{T}(; _{1:T},x_{1:T},y_{1:T}),\]

where \(x_{t},_{t}()\) and \(y_{t}, t[T]\). In light of this formulation, we can see that the minimax regret concerns both the learner and the nature to be _adaptive_, meaning that their actions can rely on the revealed history so far.

**Remark 2.1** (Sequential vs non-sequential experts): Experts \(f\) as mappings from \(()^{*}\) to \(()\) are sometimes called _fully sequential_ experts  due to their ability to predict based on the past history. However, the literature (e.g. ) often considers the more limited notion of _non-sequential_ experts, modeled as \(\{()\}\), reflecting the fact that prediction made by each expert \(f\) is simply \(f(x_{t})\) in each round \(t\). In contrast, our results are more general as our novel techniques can be applied to the more flexible sequential experts.

Multiary trees.The complexity of online learning problems stems from the sequential and adaptive nature of the adversary, which we can capture with _multiary trees_. Formally, for a general space \(\) and a finite set \(\), an \(\)-valued \(\)-ary tree \(\) of depth \(d\) is a sequence of mappings \(_{t}:^{t-1}\) for \(t[d]\). A _path_ in a depth-\(d\) tree is a sequence \(=(_{1},,_{d})^{d}\). We use the notation \(_{t}()\) to denote \(_{t}(_{1},,_{t-1})\) for \(t[d]\) and the boldface notation \(()\) to denote \((_{1}(),,_{d}( {}))^{d}\). Throughout we will only consider \(\)-ary trees valued in either \(\) or \(()\), where the paths are denoted by the boldface \(\). We refer to \(\)-valued trees as _context trees_ and \(()\)-valued trees as _probabilistic trees_.

Time-varying context sets.So far we consider the context set \(\) to be constant over time. But all of our results can be extended easily to allow for time-varying context spaces. Details of this generalization can be found in Appendix C.

### Prior work: the Shtarkov sum in context-free and fixed designs

Before introducing our complexity measure that characterizes \(_{T}()\), we review some prior settings where the minimax regret can be characterized by the well-studied _Shtarkov sum_. First we introduce the notion of likelihood of a hypothesis \(f\) with respect to a context and label sequence, which plays a key role in defining complexity measures and optimal algorithms.

**Definition 2.2** (Likelihood): For \(f:()^{*}()\) and length\(-d\) sequences \(x_{1:d}^{d},y_{1:d}^{d}\), the likelihood \(P_{f}(y_{1:d}|x_{1:d})\) is defined as

\[P_{f}(y_{1:d}|x_{1:d})=_{t=1}^{d}f(x_{1:t},y_{1:t-1})(y_{t}),\]

where we use the compact notation \(f(x_{1:t},y_{1:t-1})\) for \(f(x_{1},y_{1},,x_{t-1},y_{t-1},x_{t})\).

In the classical context-free setting where \(\) can be thought of as a singleton, any sequential expert \(f\) degenerates to a joint distribution over label sequences. Indeed, given any label sequence \(y_{1:t-1}\), \(f(y_{1:t-1})()\) can be interpreted as the conditional distribution \(f\) assigns to the next label \(y_{t}\). We use \(P_{f}(y_{1:d})=_{t=1}^{d}f(y_{1:t-1})(y_{t})\) to denote this distribution. Similarly, the learner's strategy is also specified by a joint distribution that is decomposed to a sequence of conditional distributions \(_{t}=_{t}(|y_{1:t-1})()\). In this setup the minimax regret \(_{T}()\) is characterized by the Shtarkov sum .

**Proposition 2.3** (): _In the context-free setting, for any hypothesis class \(\) and horizon \(T\), the Shtarkov sum \(S_{T}()\) is defined as_

\[S_{T}()=_{y_{1:T}^{T}}_{f}P_{f} (y_{1:T}).\]

_Moreover, the minimax regret is given by \(_{T}()= S_{T}()\), and the unique minimax optimal strategy is the normalized maximum likelihood (NML) distribution given by_

\[p_{nml}(y_{1:T})=}P_{f}(y_{1:T})}{_{y^{}_{ 1:T}^{T}}_{f}P_{f}(y^{}_{1:T})},  y_{1:T}^{T}.\]

To go beyond this classical context-agnostic setting and incorporate contextual information, prior work (e.g. ) also considered an easier problem than the aforementioned sequential probability assignment, by forcing nature to reveal the context sequence \(x_{1:T}\) to the learner at the start of the game. This is known as the _fixed design_ setting or _transductive online learning_, where the goal is to characterize the so-called _fixed design maximal_ minimax regret

\[_{T}^{}():=_{x_{1:T}^{T}} _{_{1}}_{y_{1}}_{_{T}}_{y_{T}}_ {T}(;_{1:T},x_{1:T},y_{1:T}).\]

It is straightforward to see that after projecting on \(x_{1:T}\), the hypothesis class \(\) again collapses to a set of joint distributions over \(^{T}\) specified by the likelihood function in Definition 2.2. Moreover, this set of distributions can be accessed by the learner from the start, so the fixed design setting can be essentially reduced to the context-free setting. To be more specific, for any \(f\), it induces an expert in the context-free setting after being projected on \(x_{1:T}\), which is denoted by \(f|_{x_{1:T}}\) and

\[f|_{x_{1:T}}(y_{1:t-1}):=f(x_{1:t},y_{1:t-1})(), t [T],y_{1:t-1}^{t-1},\]

and let \(|_{x_{1:T}}:=\{f|_{x_{1:T}}:f\}\). Then given any predetermined \(x_{1:T}\), the learner is equivalently competing with \(|_{x_{1:T}}\) in the context-free setting. With the following natural variant of the Shtarkov sum, we can easily characterize \(_{T}^{}()\).

**Definition 2.4** (Conditional Shtarkov sum): Given a context sequence \(x_{1:T}^{T}\), the Shtarkov sum of \(\) conditioned on \(x_{1:T}\) is

\[S_{T}(|x_{1:T}):=_{y_{1:T}^{T}}_{f }P_{f}(y_{1:T}|x_{1:T}).\]

In fact, \(S_{T}(|x_{1:T})\) is just the Shtarkov sum of the projected class \(|_{x_{1:T}}\) in the context-free setting. The following result characterizes the fixed-design setting:

**Proposition 2.5** (Minimax regret, fixed design ): _In the fixed design setting, for any hypothesis class \(\) and horizon \(T\), the fixed design maximal minimax regret is_

\[_{T}^{}()=_{x_{1:T}^{T}}  S_{T}(|x_{1:T}),\]

_and, given any context sequence \(x_{1:T}\), the minimax optimal response is NML with respect to \(|_{x_{1:T}}\)._

## 3 Minimax regret via contextual Shtarkov sum

Now we state one of our main results about the characterization of the minimax regret of sequential probability assignment. First we introduce the key concept of _contextual Shtarkov sum_, which is a natural generalization of Shtarkov sum in the context-free setting.

**Definition 3.1** (Contextual Shtarkov sum): The _contextual Shtarkov sum_\(S_{T}(|)\) of a hypothesis class \(\) on a given context tree \(\) of depth \(T\) is defined as

\[S_{T}(|):=_{^{T}}_{f }P_{f}(|()).\]

Just like the conditional Shtarkov sum, the contextual Shtarkov sum \(S_{T}(|)\) can be interpreted as the Shtarkov sum of the projected class \(|_{}:=\{f|_{}:f\}\) where \(f|_{}\) is the induced context-free expert specified by

\[f|_{}(y_{1:t-1}):=f((y_{1:t-1}),y_{1:t-1})( ), t[T],y_{1:t-1}^{t-1},\]

where we have slightly abused the notation to use \((y_{1:t-1})\) to denote the length-\(t\) context sequence obtained by tracing tree \(\) through the (partial) path \(y_{1:t-1}\). Next we show that the minimax regret \(_{T}()\) is characterized by the worst-case contextual Shtarkov sum:

**Theorem 3.2** (Main result: minimax regret): _For any hypothesis class \(\{()^{*} ()\}\) and horizon \(T\),_

\[_{T}()=_{} S_{T}(|),\]

_where the supremum is taken over all \(\)-valued context trees \(\) of depth \(T\)._

Since any context sequence \(x_{1:T}\) can be thought as a special context tree \(\) that is constant in each level \(t[T]\) (i.e., \(_{t}()=x_{t},\)), we can find that the supremum over context trees in Theorem 3.2 strictly subsumes the supremum over context sequences in Proposition 2.5. Thus we can see the separation between \(_{T}()\) and \(_{T}^{}()\) is clearly exhibited.

The full proof of Theorem 3.2 as well as an overview are provided in Appendix A.

### Applications: an improved regret upper bound in terms of sequential entropy

To illustrate the utility of our characterization in Theorem 3.2, we walk through some examples where we are able to recover and _sharpen_ existing regret upper bounds with relatively short proofs via contextual Shtarkov sum. As a start, we provide a short proof in Appendix A.6 of the classical regret bound for a finite hypothesis class.

**Proposition 3.3** (Finite classes): _For any \(^{}\) and horizon \(T\), \(_{T}()||\)._

Let us go back to the binary label setting with non-sequential experts, that is, \(=\{0,1\}\) and \(^{}\), and \(f(x)\) is interpreted as the probability assigned to label \(1\) by this expert \(f\). We will show a regret bound that _outperforms_ the state-of-the-art ones in  with a surprisingly simple proof. To proceed, we need the following notation. Given a context tree \(\) of depth \(T\), let \(=\{f:f\}\), where \(f\) is the \(\)-valued tree such that

\[(f)_{t}()=f(_{t}()), ^{T}.\]

Next we introduce the definitions of sequential \(_{}\) covers and entropy.

**Definition 3.4** (Sequential \(_{}\) cover and entropy): Given a hypothesis class \(^{}\) and a context tree \(\) of depth \(T\), we say a collection of \(\)-valued trees \(V_{,}\) is a sequential cover of \(\) at scale \(>0\) if for any \(f,^{T}\), there exists some \(v V_{,}\) such that

\[|f(_{t}())-v_{t}()|, t[T].\]

Let the sequential \(_{}\) covering number \(_{}(,,T)\) be the size of the smallest such cover. The sequential \(_{}\) entropy of \(\) at scale \(\) and depth \(T\) is defined as the logarithm of the worst-case sequential covering number: \(_{}(,,T):=_{}_ {}(,,T)\).

**Definition 3.5** (Global sequential \(_{}\) cover and entropy): Given a hypothesis class \(^{}\), we say a collection of mappings \(_{}^{_{*}}\) is a _global_ sequential cover of \(\) at scale \(>0\) and depth \(T\) if for any \(f,x_{1:T}^{T}\), there exists some \(g_{}\) such that

\[|f(x_{t})-g(x_{1:t})|, t[T].\]

Let the _global_ sequential \(_{}\) covering number \(_{G}(,,T)\) be the size of the smallest such cover. The _global_ sequential \(_{}\) entropy of \(\) at scale \(\) and depth \(T\) is defined as

\[_{G}(,,T):=_{G}(,, T).\]

**Proposition 3.6** (): _For any \(^{}\) and horizon \(T\),_

\[_{T}()\{4T +c_{}(,,T)\}}_{]}}},\{T(1+2)+ _{G}(,,T)\}}_{ {WHG82}{}{}]}}}},\]

_where \(c=(3,4)\)._

It is easy to show that \(_{}(,,T)_{G}(, ,T)\), but, in general, the two bounds in Proposition 3.6 are incomparable due to constants and different dependence on \(\) (more discussions on these bounds are deferred to Appendix C). Starting from the contextual Shtarkov sum, we are able to derive a bound that combines the best of these two bounds:

**Theorem 3.7** (Main result: sequential entropy bound): _For any \(^{}\) and horizon \(T\),_

\[_{T}()_{>0}T(1+2)+ _{}(,,T)}.\]Proof.: For any scale \(>0\) and depth-\(T\) context tree \(\), let \(V_{,}\) be a sequential cover of \(\) at scale \(\) with size \(_{}(,,T)\). We can always assume \(V_{,}\) to be \(\)-valued without loss of generality because otherwise we can just truncate it without violating its coverage guarantee. Define the smoothed covering set \(_{,}=\{: t[T],_{t}( )=()+}{1+2},v V_{,}\}\), inspired by . Then for any \(f,^{T}\), there exists some \(v V_{,}\) such that \(|f(_{t}())-v_{t}()|, t[T]\) and hence \(\) satisfies

\[_{t}())}{_{t}()} 1+2, _{t}())}{1-_{t}()} 1 +2.\]

Hence

\[P_{f}(|())=_{t=1}^{T}f(_{t}( ))^{y_{t}}(1-f(_{t}()))^{1-y_{t}}(1+2) ^{T}_{t=1}^{T}_{t}()^{y_{t}}(1-_{t}())^{1-y_{t}},\]

and

\[_{}_{f}P_{f}(|()) (1+2)^{T}_{}_{_ {,}}_{t=1}^{T}_{t}()^{y_{t}}(1-_{t}())^{1-y_{t}}\] \[(1+2)^{T}_{_{, }}_{}_{t=1}^{T}_{t}()^{y_{t}}(1-_{t}())^{1-y_{t}}=(1+2)^{T}|_{,}|,\]

where the last equality follows from Lemma D.1, treating \(\) as sequential experts. Finally,

\[_{T}() =_{}_{}_{f }P_{f}(|())\] \[_{}(1+2)^{T}|_{ ,}|=T(1+2)+_{}(, ,T).\]

Since our choice of \(\) is arbitrary, the result follows. 

### The inadequacy of sequential \(_{}\) covering number

We conclude this section with a discussion on the suboptimality of regret bounds based on sequential covering numbers as in Proposition 3.6 and Theorem 3.7. Let us consider the binary label setting and the following hypothesis classes over the unit Hilbert ball \(=_{2}\):

\[^{}:=\{x:w _{2}\},^{}:=\{x | w,x|:w_{2}\}.\] (1)

We can see that the sequential \(_{}\) covering numbers of \(^{}\) and \(^{}\) are of the same order for all scales, thus the aforementioned results will yield the same regret bound for these two classes. However, we have \(_{T}(^{})=()\) while \(_{T}(^{})=(T^{2/3})\), which implies that the sequential \(_{}\) covering number, in its current form within the regret bound, cannot characterize the minimax regret.

It is worth mentioning that an \(()\) lower bound on \(_{T}(^{})\) is achievable, via an \((1/^{2})\) lower bound on the sequential fat-shattering dimension \(_{}(^{})\) combined with Proposition 2 in . The same lower bound also holds in the finite-dimensional case, where \(_{2}\) is a unit \(d\)-dimensional Euclidean ball with \(d\). Our proof (Appendix A.7) of the next result works in both the infinite and finite dimensional (with \(d T\)) cases.

**Lemma 3.8** (\(()\)**lover bound for the linear class \(^{}\)): _For \(^{}\) defined as in Eq. (1) with \(_{2}\) being the unit Hilbert ball or the unit \(d\)-dimensional Euclidean ball with \(d T\), then_

\[_{T}(^{})_{T}^{}( ^{})/4.\]

The proof of Lemma 3.8 is based on lower bounding the conditional Shtarkov sums (and hence the contextual Shtarkov sums) of \(^{}\). From Theorem 3.2 we know that the \(()\) upper bound holds for the log of contextual Shtarkov sums as well but we do not have a direct proof of this fact so far.

**Input:** Hypothesis class \(\), horizon \(T\)1. Observe context \(x_{t}\)
2. If \(_{f}P_{f}(y_{1:t-1}|x_{1:t-1})>0\), predict \(_{t}()\) with \[_{t}(y)=}S_{T}^{x_{1:t},(y_{1:t-1},y)}(|)}{_{y^{}}_{}S_{T}^{x_{1:t},(y_{1: t-1},y^{})}(|)}, y,\] (2) and otherwise set \(_{t}\) to be an arbitrary member of \(^{+}()\)
3. Receive label \(y_{t}\)

**End for**

**Algorithm 1** Contextual Normalized Maximum Likelihood (cNML)

## 4 Contextual NML, the minimax optimal algorithm

So far we have settled the minimax regret of sequential probability assignment in a nonconstructive way. Now we switch to the algorithmic lens to study the optimal strategy that achieves the minimax regret. Remarkably, we show that the minimax optimal algorithm can be described by a data-dependent variant of the contextual Shtarkov sum, which is named contextual Shtarkov sum _with prefix_.

**Definition 4.1** (Contextual Shtarkov sum with prefix): Given sequences \(x_{1:t}^{t},y_{1:t}^{t},t[T]\) and a context tree \(\) of depth \(T-t\), the contextual Shtarkov sum \(S_{T}^{x_{1:t},y_{1:t}}(|)\) of \(\) on \(\) with prefix \(x_{1:t},y_{1:t}\) is defined as

\[S_{T}^{x_{1:t},y_{1:t}}(|)=_{^{T-t}}_{f}P_{f}(y_{1:t},|x_{1:t},( )).\]

Now we present our prediction strategy, _contextual normalized maximum likelihood_ (cNML), which is summarized in Algorithm 1. In each round \(t\), with \(x_{1:t},y_{1:t-1}\) as past observations, the learner first checks whether \(_{f}P_{f}(y_{1:t-1}|x_{1:t-1})>0\) since if that is not the case and \(_{f}P_{f}(y_{1:t-1}|x_{1:t-1})=0\), the cumulative losses of all experts in \(\) have already blown up to \(+\) and the learner only needs to predict any \(^{+}()\) in all remaining rounds. On the other hand, if \(_{f}P_{f}(y_{1:t-1}|x_{1:t-1})>0\), then

\[_{y}_{}S_{T}^{x_{1:t},(y_{1:t-1},y)}(|)>0\]

and the \(_{t}\) given by Eq. (2) is indeed a valid member of \(()\) (shown in Appendix B) and is used as the learner's prediction. The following theorem shows that cNML is the minimax optimal algorithm, with proof deferred to Appendix B.

**Theorem 4.2** (Main result: optimal algorithm): _The contextual normalized maximum likelihood strategy (Algorithm 1) is minimax optimal._

To see that cNML is reduced to NML in the context-free setting, it suffices to consider the case where \(_{f}P_{f}(y_{1:T})>0\) since otherwise NML will simply assign \(0\) probability on this sequence \(y_{1:T}\) and during the actual round-wise implementation of NML, it also predicts an arbitrary element from \(^{+}()\) in those rounds \(t\) where \(_{f}P_{f}(y_{1:t-1})=0\). Now for any \(y_{1:T}\) such that \(_{f}P_{f}(y_{1:T})>0\), the prediction by cNML in each round \(t\) is

\[_{t}(y)=^{T-t}}_{f}P_{f}(y_{1:t-1},y,)}{_{^{}^{T-t+1}} _{f}P_{f}(y_{1:t-1},^{})}, y \]

which can be summarized into a joint density over \(y_{1:T}\) by

\[(y_{1:T})=}P_{f}(y_{1:T})}{_{^{ }_{1:T}^{T}}_{f}P_{f}(y^{}_{1:T})}.\]

Recall that this is exactly the NML prediction \(p_{nml}(y_{1:T})\).

**Remark 4.3** (Relaxations and efficient algorithms): One may wonder if more efficient algorithms are available when it is not easy to compute contextual Shtarkov sums with prefix. One solution is to apply the framework of admissible relaxation in , which provides a systematic way of constructing efficient algorithms at the cost of worse regret guarantees. Notice that the worst-case log contextual Shtarkov sums with prefix constitute a trivially "admissible relaxation" since they are the exact conditional game values.

## 5 Perspectives on contextual Shtarkov sums

In this section, we provide further insight into contextual Shtarkov sums, defined in Sections 3 and 4.

### Contextual Shtarkov sums through martingales

We can relate our characterization of the minimax regret to the more extensively studied _sequential Rademacher complexity_, which arises in online learning problems with hypothesis class \(^{}\) and bounded convex losses like absolute loss. Specifically, the (conditional) sequential Rademacher complexity  is defined by

\[_{T}(;):=_{}_{f}_{t=1}^{T}_{t}f(_{t}( )),\]

where \(\) is a depth-\(T\) binary context tree and \(=(_{1},,_{T})\{ 1 \}^{T}\) is a sequence of i.i.d. Rademacher random variables. A notable feature of \(_{T}(;)\) is that it is the expected supremum of the sum of a martingale differences, i.e., for any \(f,[_{t}f(_{t}())| _{1},,_{t-1}]=0\). Likewise, \(S_{T}(|)\) also admits a martingale interpretation. To see this, let \(\{()^{*} ()\}\) and rewrite \(S_{T}(|)\) for any context tree \(\):

\[S_{T}(|)=_{^{T}}_{f }P_{f}(|())=_{} _{f}_{t=1}^{T}|| f( _{1:t}(),y_{1:t-1})(y_{t}),\]

where \(=(y_{1},,y_{T})\) is a sequence of i.i.d. variables following the uniform distribution over \(\). It is easy to check that \([|| f(_{1:t}(),y_{1:t-1})(y_{t} )|y_{1},,y_{t-1}]=1\), and thus

\[_{s=1}^{t}|| f(_{1:s}(),y_{1:s-1})(y_{s})}_{t[T]}\]

is a martingale with respect to filtration \(_{t}=(y_{1},,y_{t}),t[T]\). It would be of independent interest to study the contextual Shtarkov sums more quantitatively by developing new tools for such product-type martingales.

### General Shtarkov sums

We can also interpret contextual Shtarkov sums as an instance of _general Shtarkov sums_, which are defined over sub-probability measures.

**Definition 5.1** (Sub-probability measure): A set \(=\{p:\}\) is a class of sub-probability measures over a finite set \(\) if

\[_{k}p(k) 1, p.\]

Due to Lemma D.1, it is easy to see that for any hypothesis class \(\{()^{*} ()\}\) and depth-\(T\) context tree \(\), they induce a class

\[_{|}:=\{P_{f}(|()):f \}\]

that is a class of sub-probability measures over \(^{T}\). Moreover, for any \(\), depth-\((T-t)\) context tree \(\) and sequences \(x_{1:t}^{t},y_{1:t}^{t}\), the induced

\[_{^{x_{1:t},y_{1:t}}|}:=\{P_{f}(y_{1:t},|x_ {1:t},()):f\}\]is a class of sub-probability measure over \(^{T-t}\) since

\[_{^{T-t}}P_{f}(y_{1:t},|x_{1:t},())=P_{f}(y_{1:t}|x_{1:t}) 1.\]

Next we introduce the notion of general Shtarkov sum over classes of sub-probability measures.

**Definition 5.2** (General Shtarkov sum): Given any class \(\) of sub-probability measures over \(\), the general Shtarkov sum of \(\) is defined as

\[S()=_{k}_{p}p(k).\]

With the notion of general Shtarkov sum, it is not hard to verify that the contextual Shtarkov sums with & without prefix can be interpreted as instances of general Shtarkov sums:

**Proposition 5.3**: _For any horizon \(T,t[T]\), data sequence \(x_{1:t}^{t},y_{1:t}^{t}\), and context trees \(,^{}\) of depth \(T,T-t\) respectively, we have_

\[S_{T}(|)=S(_{|}), S _{T}^{x_{1:t},y_{1:t}}(|^{})=S(_{ ^{x_{1:t},y_{1:t}}|^{}}).\]

It would be interesting to find out other instances of general Shtarkov sums that capture the complexities of other online learning problems with log loss.

## 6 Discussions

In this paper, we characterize the minimax regret and the optimal prediction strategy for sequential probability assignment, generalizing the classical results in the context-free setting. Moreover, our results are general enough to subsume the setting of multiary labels and sequential hypothesis classes, which has not been sufficiently explored before. Remarkably, our characterization holds for arbitrary hypothesis classes that may not admit the regularity assumptions implicitly required by prior works (e.g. ).

For future works, it would be interesting to study the minimax regret of specific classes more quantitatively using our contextual Shtarkov sums. It is also intriguing to consider the setting of infinite labels. Although most of our arguments would go through under sufficient regularity conditions, a more systematic study is needed. On the practical side, it is important to develop algorithms that are more computationally efficient than cNML and with provable guarantees.