# Probabilistic size-and-shape functional mixed models

Fangyi Wang

Department of Statistics

The Ohio State University

Columbus, OH, 43210

wang.15022@osu.edu &Karthik Bharath

School of Mathematical Sciences

University of Nottingham

Nottingham, UK, NG7 2RD

Karthik.Bharath@nottingham.ac.uk &Oksana Chkrebtii

Department of Statistics

The Ohio State University

Columbus, OH, 43210

oksana@stat.osu.edu &Sebastian Kurtek

Department of Statistics

The Ohio State University

Columbus, OH, 43210

kurtek.1@stat.osu.edu

###### Abstract

The reliable recovery and uncertainty quantification of a fixed effect function \(\) in a functional mixed model, for modelling population- and object-level variability in noisily observed functional data, is a notoriously challenging task: variations along the \(x\) and \(y\) axes are confounded with additive measurement error, and cannot in general be disentangled. The question then as to what properties of \(\) may be reliably recovered becomes important. We demonstrate that it is possible to recover the size-and-shape of a square-integrable \(\) under a Bayesian functional mixed model. The size-and-shape of \(\) is a geometric property invariant to a family of space-time unitary transformations, viewed as rotations of the Hilbert space, that jointly transform the \(x\) and \(y\) axes. A random object-level unitary transformation then captures size-and-shape _preserving_ deviations of \(\) from an individual function, while a random linear term and measurement error capture size-and-shape _altering_ deviations. The model is regularized by appropriate priors on the unitary transformations, posterior summaries of which may then be suitably interpreted as optimal data-driven rotations of a fixed orthonormal basis for the Hilbert space. Our numerical experiments demonstrate utility of the proposed model, and superiority over the current state-of-the-art.

## 1 Introduction

Consider a sample of functions from the much-studied Berkeley growth data in Figure 1(a), where growth rate curves from measurements on heights in centimeters of 54 girls and 39 boys from age 1 to 18 are plotted on a rescaled time axis. It appears that individuals experience different numbers of small and large growth spurts that differ in magnitude and timing. Any reasonable generative model for inference on distributional aspects of the functions will need to account for the fact that the sample size (\(n=93\)) is smaller than the dimension of each observation, and it is thus common to consider tractable parametric probabilistic models. A popular choice is a functional mixed model

\[f_{i}=+v_{i}+_{i}, i=1,,n,\] (1)

comprising three component real-valued functions on \(\): (i) fixed population-level function that represents an average, or representative, change in growth rate; (ii) an individual- or object-levelrandom function \(v_{i}\) that represents deviations from \(\); and, (iii) a zero-mean random measurement error process \(_{i}\). The growth rate function \(f_{i}(t)\) of individual \(i\) at time \(t\) differs pointwise from an average \((t)\) via a smooth random translation \(v_{i}(t)\) observed with additive error \(_{i}(t)\).

A function with any number of peaks representing spurts may be generated under the model, and as such exact recovery of \(\) is not possible without further constraints on \(v_{i}\) and \(_{i}\). The issue is exacerbated when \(f_{i}\) in (1) is changed to \(f_{i}_{i}\) by incorporating phase variability, or \(x\)-axis variability, via a time dilation/contraction object-level increasing function \(_{i}:\), which models variability in timings of the spurts. Even for the simpler model, \(f_{i}_{i}=+_{i}\), for a fixed scalar \(>0\), recovery of \(\) is possible only when the measurement error process \(_{i}\) has a rank one covariance operator (Kurtek et al., 2011; Chakraborty and Panaretos, 2021).

The crux of the problem in reliable recovery of the population-level function \(\) lies in the fact that its topological features such as number of critical points and their nature (non-degenerate or otherwise), while preserved by \(_{i}\), may be altered due to addition of \(v_{i}\) and \(_{i}\). Consequently, a growth spurt (peak) in the average \(\) at time \(t\) (or \(_{i}(t)\)) may either be preserved or destroyed. From a modeling perspective, uncertainty quantification of \(\) in (1) within a Bayesian framework is unreliable in the presence of phase \(_{i}\), regardless of how informative the prior distributions on \(v_{i}\) and \(_{i}\) are. Figure 1(d)&(e) show an additional motivating dataset of PQRST complexes segmented from an electrocardiogram (ECG) signal and a typical PQRST pattern, respectively.

Summarily, under the functional mixed model (1), the topological shape of \(\) may be irrevocably altered, and thus ordinate values of \(\) may not be reliably inferred through probabilistic modeling. The goal of the paper is to investigate if the situation may be salvaged by considering a complementary geometric property of \(\), its size-and-shape, characterized by a joint transformation of its range and domain by the phase function \(\).

**Contributions.** We focus on sampling from and summarizing the posterior distribution of a fixed effect function \(\) in a functional mixed model with random object-level phase and amplitude components, without a finite-rank covariance assumption on the error process. We do not make any claims on efficiency of the computational algorithms, but emphasize that the goal is to thoroughly investigate the novel size-and-shape perspective in inference on \(\). Thus, our contributions are as follows.

1. We propose a mixed model in a functional Hilbert space for the size-and-shape of a square-integrable fixed effect \(\) by considering an isometric action of the infinite-dimensional group of phase functions \(\). The geometric property of \(\) thus preserved is referred to as its size-and-shape (Section 2), which we demonstrate may be reliably inferred under the model. To our knowledge, this is the first paper to consider a Bayesian functional mixed effects model with an _unrestricted_ form of phase variation, and employ the novel perspective of inferring the size-and-shape of \(\).
2. Informative priors on the phase functions \(\) regularize the posterior of \(\), and sampling is assisted by exploiting the group structure of the phase functions while exploring the parameter space (Section 3 and Appendix D).
3. Isometric action of \(\) engenders a unitary transformation of the Hilbert space; the class of unitary transformations indexed by \(\) constitutes rotations of coordinates of the Hilbert space. Upon expressing \(\) and \(v_{i}\) in a suitable orthonormal basis of the Hilbert space, inference for \(_{i}\) translates to an automatic identification of a data-optimal rotation of the chosen basis that best captures population- and object-level variations, and performs better when compared to an empirical functional principal component analysis (FPCA) basis (Appendices B and G).

Figure 1: (a) Berkeley growth rate curves. (b) Convex phase function \(\). (c) One example function \(f\) from (a) (blue) transformed by value-preserving action \(f\) (red) and norm-preserving action \((f)\) (yellow). Here, \(f\) has the same classical notion of shape as \(f\), whereas \((f)\) has the same size-and-shape as \(f\) as described in Section 2. (d) PQRST complexes. (e) PQRST pattern: P wave (first max), QRS complex (sharp min-max-min) and T wave (last max) (Pham et al., 2023).

4. We carry out extensive numerical experiments to investigate utility of the proposed model, and demonstrate that the posterior mean of \(\) under our model better captures the properties of \(\) than the estimate given by current state-of-the-art (Claeskens et al., 2021)(Section 4 and Appendix I).

**Related work.** In absence of phase functions as part of the random effect, approaches have broadly focused on two types of dimension reduction techniques for estimating the fixed effect: (i) empirical orthonormal basis from FPCA (e.g., Yao et al., 2005), and (ii) pre-specified basis functions (e.g., Rice and Wu, 2001; Guo, 2002; Chen and Wang, 2011; Zhu et al., 2011; Morris and Carroll, 2006; Huo et al., 2023). Some recent works have extended methodology to multivariate functional mixed effect models (Volkmann et al., 2023), scalar on function regression (Liu et al., 2017), spatial-temporal variation (Zhu et al., 2019), and generalized functional mixed effect models (St. Ville et al., 2022).

In the presence of phase functions, the notable works are by Claeskens et al. (2021) and Raket et al. (2014), where the former provides sufficient conditions for exact recovery of the fixed effect when the error process is not assumed to have phase variation; in our numerical experiments, we compare our results to the estimator proposed by Claeskens et al. (2021), which represents the state-of-the-art.

We are unaware of work in literature on Bayesian approaches to functional mixed models with unrestricted, nonparametric phase functions to _jointly_ model amplitude and phase variations, and not sequentially following pre-processing via registration. Of relevance, however, is the work by Schiratti et al. (2017), where manifold-valued curves with reparameterization variation are considered.

## 2 Phase functions and size-and-shape-preserving transformations

Without loss of generality, we assume that all functions are observed on a fixed domain \(\). Let \(^{2}(,)=\{f:|_{0}^{1}|f(t)|^{2} t<\}\) (henceforth simply referred to as \(^{2}\)) denote the representation space of interest, i.e., the space of real-valued square-integrable functions on \(\). The space \(^{2}\) when endowed with the norm \(\|f\|:=[_{0}^{1}|f(t)|^{2}t]^{1/2}\) coming from the inner product \( f,g:=_{0}^{1}f(t)g(t)t\) is a Hilbert space. Additionally, let \(=\{:|(0)=0,(1)=1,>0\}\) denote the group of orientation-preserving diffeomorphisms (\(\) is the time derivative of \(\)) of \(\). In the functional data analysis literature, \(\) is used to model phase variability in functional observations. Thus, elements of \(\) will henceforth be referred to as phase functions. Note that \(\) is a Lie group with composition \((_{1},_{2})_{1}_{2}\) as the group operation, where \(\) is function composition. This implies that (i) \(\) is an infinite-dimensional smooth manifold, (ii) \((_{1}_{2})_{3}=_{1}(_{2} _{3})\) for any \(_{1},\;_{2},\;_{3}\), (iii) it contains the identity element \(_{id}(t)=t\) such that \(_{id}=\) for any \(\), and (iv) for any \(\) there exists \(^{-1}\) such that \(^{-1}=_{id}\). The group structure of \(\) plays a pivotal role when defining prior and proposal distributions for phase functions; this is further elucidated in Section 3.2 and Appendix D. Importantly, the group \(\) can act on the function space \(^{2}\) from the right, engendering maps \(^{2}^{2}\), in different ways, thus resulting in different notions of phase variation in functional data.

1. **Value-preserving action.** The value-preserving mapping is defined via composition: \(f,\;f^{2},\;\). This action is referred to as the time warping of a function since \(f\) and \(f\) traverse the same exact \(y\) axis values, but at different times (\(x\) axis values). It is commonly used for alignment or registration of prominent features in functional data, e.g., local extrema, a process traditionally referred to as amplitude-phase separation.
2. **Area-preserving action.** The area-preserving mapping is defined as \((f),\;f^{2},\;\). This action is commonly used for statistical analysis of probability density functions.
3. **Norm-preserving action.** The norm-preserving mapping is defined as \((f,):=(f)},\;f^{2},\;\). An important property of this action is that it preserves the \(^{2}\) norm of a function: \(\|f\|=\|(f,)\|\). The action has been profitably used in the problem of function alignment/registration, wherein a desideratum is a cost function invariant to a simultaneous action of the group \(\), or time warping (Srivastava and Klassen, 2016; Chapter 4).

The operator \(D_{}:^{2}^{2},\;f D_{}(f):=(f )}\) arising from the norm-preserving action for a fixed \(\) is a surjective isometry, and hence unitary. Thus, \(D_{}\), for a fixed \(\), is an infinite-dimensional rotation in the Hilbert space \(^{2}\), and the group \(:=\{D_{},\;\}\) of rotations of \(^{2}\) plays a prominent role in classical white noise calculus (Hida, 2015).

A general space-time diffeomorphism \((t,x)(_{1}(t,x),_{2}(t,x))\) preserves the topology of the graph \(\{(t,f(t))\}\) of \(f\) viewed as a subset of \(\). The operator \(D_{}\) is associated with a special space-time diffeomorphism with \(_{1}(t,x)=(t)\) and \(_{2}(t,x)=x(t)}\). In this sense, the size and shape of \(f\), as it relates to its norm and its graph, is preserved by operators in \(\).

To better understand how \(D_{}\) transforms \(f\), consider Figure 1(b)&(c). As seen with the red curve in (c), the value-preserving action of \(\) preserves the image of \(t f(t)\), where ordinate values of \(f\) are relabeled in an order-preserving way and no new values are created/destroyed. A more classical notion of the shape of \(f\) is thus preserved under the value-preserving action in that the topology of the level sets of \(f\) is unaltered. In contrast, the norm-preserving action shown with the yellow curve in (c) alters the image of \(t f(t)\), and may create new critical points, but in a way such that its size-and-shape in the sense alluded to above is preserved. As such, the norm-preserving action is size-and-shape preserving, i.e., \(f\) and \(D_{}(f)\) for any \(\) are equivalent in their size-and-shape.

Use of the operator \(D_{}\) is particularly useful for modeling phase variation in model (1):

1. Dimension reduction of the fixed and random effects is implemented via an orthonormal basis system, and operators in \(\) allow us to rotate these basis systems to better align with observed data (see Appendix B). This provides modeling flexibility that is often needed due to the use of a finite, and potentially small, number of basis functions to represent these model components.
2. The norm preserving action can be viewed as a combination of value-preserving warping and an associated local scaling of function values, i.e., when \((t)>1\) (\((t)<1\)) the function value \(f((t))\) is warped to the right (left) relative to \(f(t)\) and additionally rescaled by a factor of \((t)}\).
3. The equivalence class of functions having the same size-and-shape under the norm-preserving action is 'larger' than the one under the value-preserving action in the following sense. The map \(:^{2}^{2}/\) takes a function to its equivalence class determined by equivalence relation \(\). It can be shown that the measure of an equivalence class, under the pushforward of a non-degenerate measure with support in \(^{2}\) under \(\), is larger when \(\) pertains to norm-preserving action as opposed to value-preserving one (see Example 6.5.2 in Bogachev  for an example that illustrates this idea). In practice, the larger equivalence class under the norm-preserving action helps with reliable recovery of the size-and-shape of the fixed effect \(\), in contrast to the more traditional notion of shape of \(\) under the value-preserving action, wherein the additive linear term \(v_{i}+_{i}\) more easily alters the shape of \(\).

## 3 Bayesian size-and-shape functional mixed model

The operator \(D_{}\) related to the norm-preserving action of \(\) is an isometry of \(^{2}\). The use of Euclidean isometries arising from translations and rotations as size-and-shape preserving has a long history in statistical shape analysis of landmark configurations [e.g., Dryden and Mardia, 2016]. To elaborate, let \(X_{i}^{K 2}\) denote a set of \(K\) landmarks, i.e., \(X_{i}\) is a matrix that contains the coordinates of \(K\) points in \(^{2}\), and \(SO(2)=\{R^{2 2}|R^{T}R=RR^{T}=I,\;(R)=1\}\) denote the rotation group with matrix multiplication as the group operation. Consider the following perturbation (generative) model for the size-and-shape of an object represented via a landmark configuration \(X_{i}\):

\[X_{i}=(M+E_{i})R_{i}+t_{i}^{T},\] (2)

where \(t_{i}^{2}\) is a random translation, \(^{K}\) is a vector of \(1\)s, \(R_{i} SO(2)\) is a random rotation, \(M^{K 2}\) is a fixed template, and \(E_{i}^{K 2}\) is the error. Using this model, it is of primary interest to estimate the fixed effect (size-and-shape) \(M\) based on observed landmark configurations \(X_{1},,X_{n}\). Transformation of the model components \(M\) and \(E_{i}\) using rotations \(R_{i}\) (and translations) in order to align them to the observation \(X_{i}\) may be viewed as an isometric, or norm-preserving, transformation of the coordinate system for \((M+E_{i})\), so that _only the size-and-shape of \(M\) can be reliably recovered, but not \(M\)_[Lele and McCulloch, 2002].

Inspired by size-and-shape analysis of landmark data, and in contrast to existing works using the value-preserving action [Raket et al., 2014, Claeskens et al., 2021], our proposed functional mixed effects model utilizes the norm-preserving action of \(\) on \(^{2}\). Analogous to the model in (2), for a function \(f_{i}^{2}\), one can define a functional perturbation model \(f_{i}=D_{_{i}}(+_{i})=[(+_{i})_{i}] _{i}}\) for a template function \(\) with random phase functions \(_{i}\), wherein the \(^{2}\) coordinate system of the model components \(\) and \(_{i}\) is aligned to the coordinate system of the function \(f_{i}\) via a rotation using \(_{i}\).

To the fixed effect, or signal plus noise model, one can additionally introduce an object-level random effect to increase modeling flexibility, resulting in:

\[f_{i}=D_{_{i}}(+v_{i}+_{i})=[(+v_{i}+_{i}) _{i}]}}.\] (3)

Thus, \(_{i}\)_and \(v_{i}\) act as size-and-shape preserving and altering random effects, respectively_. As in the landmark case, the primary goal of interest is to estimate \(\) and quantify its uncertainty using independent observations \(f_{1},,f_{n}\), and it is possible to reliably infer only the size-and-shape of \(\).

While the model in (3) is written in terms of infinite-dimensional objects, functional data is often observed under a common discretization at time points \(t_{1}=0<t_{2}<<t_{T-1}<t_{T}=1\). The assumption of a common discretization for all functional observations is adopted for clarity and succinctness in presenting the proposed Bayesian model; it can be easily relaxed to accommodate more general scenarios. The model is quite flexible and more realistic assumptions (e.g., arbitrary error dependence structure such as Matern covariance, or non-Gaussian) may easily be incorporated at some computational cost. We instead focus on the phase component, and demonstrate the utility of the size-and-shape perspective in inferring geometric properties of \(\).

Let \(_{i}=(f_{i}(t_{1}),,f_{i}(t_{T}))^{}^{T},\ i=1, ,n\) represent the discretized function values for each observation. The discretized observation model is then given by

\[f_{i}(t_{j})=[(+v_{i}+_{i})_{i}](t_{j})}(t_{j})},\ i=1,,n,\ j=1,,T.\] (4)

Letting \(\{_{k}\}_{k=1}^{}\) and \(\{_{k}\}_{k=1}^{}\) denote two orthonormal basis systems for \(^{2}\), we represent the model components \(\) and \(v_{i}\) as linear combinations of basis functions. For dimension reduction, we define \(:=_{k=1}^{B_{r}}a_{k}_{k}\) and \(v_{i}:=_{k=1}^{B_{r}}c_{i,k}_{k}\), i.e., the two basis sets are truncated to \(B_{f}\) and \(B_{r}\) basis functions for the fixed and (size-and-shape altering) random effects, respectively. We assume that the random effect coefficients are independent and identically normally distributed (iid) \(c_{i,k}{}N(0,_{c}^{2})\). The discretized error is assumed to be iid \(_{i}(t_{j}){}N(0,^{2})\).

### Choice of basis functions and likelihood

Specifications of \(\) and \(v_{i}\) require appropriate orthonormal basis functions, and we consider modified Fourier basis or the B-spline basis for \(\), and the B-spline basis for \(v_{i}\). The modified Fourier basis contains the following elements \(\{t,\ (1-t),\ (2 jt),\ (2 jt);\ j=1,\ 2, ;\ t\}\) and is subsequently orthonormalized via the Gram-Schmidt procedure under the \(^{2}\) metric; larger values of \(j\) yield basis functions with finer harmonics over the domain \(\). This basis is used to specify the fixed effect function \(\) only as it is effective at representing global periodic trends and oscillations. On the other hand, the B-spline basis is defined locally via piecewise polynomials, and is therefore better at capturing local variation and finer function features; we also orthonormalize the B-spline basis via the Gram-Schmidt procedure under the \(^{2}\) metric. In some cases where the underlying \(\) is expected to exhibit more local features, we use the B-spline basis rather than the modified Fourier basis. Finally, one needs to choose the number of basis functions to model \(\) and \(v_{i}\). This choice depends on the application of interest. For example, one may use a larger number of basis functions for \(\) when the observations have a complex shared global structure. Effects of misspecifying the number of basis functions for \(\) and \(v_{i}\) are studied in Appendix H.

The main inferential tasks of interest are to estimate and assess uncertainty in (i) mean size-and-shape \(\) via the coefficient vector \(=(a_{1},,a_{B_{f}})^{}\), (ii) variance of the size-and-shape altering random effect coefficients \(_{c}^{2}\), and (iii) error variance \(^{2}\). Thus, to simplify the inference, we marginalize the likelihood with respect to the size-and-shape altering random effect. Let \(_{i}^{T B_{f}}\) denote the matrix of evaluations of the fixed effect basis, whose \((j,k)\)th entry is given by \((_{k}_{i})(t_{j})}(t_{j})}\). One can view \(_{i}\) as a discretization of the rotated coordinate system, via the norm-preserving action that uses \(_{i}\), for \(\). Similarly, let \(_{i}^{T B_{r}}\) be the matrix of evaluations of the random effect basis, whose \((j,k)\)th entry is \((_{k}_{i})(t_{j})}(t_{j})}\). Let \(^{B_{f}}\) and \(_{i}^{B_{r}},\ i=1,,n\) be the vectors of basis coefficients for \(\) and \(v_{i},\ i=1,,n\), respectively. Finally, let \(_{i}^{_{i}}^{T},\ i=1,,n\) be the vectors of \(_{i}\)-transformed observation errors, with entries \((_{i}_{i})(t_{j})}(t_{j})},\ j=1, ,T\) that are independently distributed as \(N(0,^{2}}(t_{j}))\), conditional on \(_{i}\); the additional time-dependent scaling of the error variance comes from the norm-preserving action. Using this simplified notation, we can rewrite the model in (4) in matrix form as

\[_{i}=_{i}+_{i}_{i}+_{i}^{_{ i}},\ i=1,,n,\] (5)which may be usefully compared to the size-and-shape perturbation model (2) for landmark configurations. With MVN used to denote the multivariate normal distribution, the distribution of \(_{i}\), conditional on the vector of coefficients \(_{i}\), is \(_{i}|_{i}(_{i}+_{i}_{i},^{2}(_{i}(t_{j})))\), where \((_{i}(t_{j}))\) is a \(T T\) diagonal matrix whose \(j\)th diagonal element is \(_{i}(t_{j})\). Then, the following marginal distribution of \(_{i}\) is used to define the likelihood function (see Appendix C for full derivation):

\[_{i}(_{i},^{2}(_{i}(t_{j}))+_{c}^{2}_{i}_{i}^{T}).\] (6)

### Prior distributions

The model parameters that need to be estimated are the fixed effect coefficients \(\), random effect variance \(_{c}^{2}\), variance of observation error \(^{2}\), and individual phase functions \(_{i}\). For \(\), \(_{c}^{2}\) and \(^{2}\), we use weakly informative prior distributions: \((,10000_{_{}})\), \(_{c}^{2}(0.01,0.01)\), \(^{2}(0.01,0.01)\) (IG is the inverse-gamma distribution).

The prior distribution over the space of phase functions \(\), to model the shape-and-size preserving random effect, can be specified in different ways (e.g., Telesca and Inoue, 2008; Bigot, 2013; Lu et al., 2017). In this work, we use two tractable prior distribution models on \(\) to guard against confounding of inference between \(\{_{i}\}\) and \(\): (i) a one-parameter family; (ii) a nonparametric finite-dimensional family compatible with the time discretization. Importantly, the prior models rely on the group structure of \(\).

* **Prior Model 1 (PM1) on \(\).** Each phase function \(_{i}\) is defined via a single parameter \(_{i}\) (Section 5.2 in Srivastava and Klassen (2016)) as \[_{i}(t)=t+_{i}t(t-1),\;_{i}(-1,1),\;t.\] (7) The phase functions defined in (7) form a one-dimensional subset of \(\), making posterior inference more tractable with significant reductions in computational complexity. This subset contains phase functions with \((t)(0,2)\) for all \(t(0,1)\) and no inflection points. At the same time, we sacrifice flexibility in terms of the allowed rotations of \(^{2}\). The \(_{i},\;i=1,,n\) are assumed to be independent _a priori_ following the \((-1,1)\) distribution.
* **Prior Model 2 (PM2) on \(\).** A more flexible nonparametric prior model utilizes a point process-based prior distribution related to the Dirichlet process on \(\)(Bharath and Kurtek, 2020). Under discretized time, each phase function may be represented by a finite number of successive increments \(p(_{i})=(_{i}(t_{2})-_{i}(0),,_{i}(t_{j})-_ {i}(t_{j-1}),,_{i}(1)-_{i}(t_{T_{}-1}))^{ T_{}-1}\); as \(T_{}\), the resulting prior has dense support in \(\). Then, the finite-dimensional prior distribution is placed on the vector of phase increments, \[p(_{i})(_{}),\] (8) where \(=(t_{2},t_{3}-t_{2},...,1-t_{T_{}-1})\) is defined via \(T_{}\) consecutive time points on \(\) and \(_{}\) is a precision parameter. First, the time points defining \(\) can be different from the time points at which the functional observations were recorded. In fact, we usually choose \(T_{}\) to be relatively small, e.g., five or seven, to simplify the prior model. Second, a large value for \(_{}\) regularizes the phase functions toward \(_{id}\). We use \(_{}=30\) in all of our numerical experiments. The resulting \(_{i}\) is a piecewise linear function with changes in the slope \(_{i}\) at \(t_{2},,t_{T_{}-1}\). This prior distribution is more flexible than the one in PM1. However, depending on the chosen number of discretization points \(T_{}\), the dimension of the phase parameter space can be much larger in this case, making posterior inference more challenging. Interested readers can refer to Matuk et al. (2022) for more details behind this choice of prior distribution on phase functions in the context of Bayesian modeling for functional data.

Posterior inference on all parameters is conducted via Markov chain Monte Carlo (MCMC) sampling using the Metropolis-Hastings algorithm. To efficiently explore the parameter space, we use adaptive proposal distributions. We monitor MCMC convergence using standard diagnostic plots, e.g., trace plots and autocorrelation plots. Trace plots provided in Appendix F indicate good convergence for all of the examples presented in this manuscript. Full details of the proposal distributions and the MCMC algorithm are in Appendices D and E.

## 4 Numerical experiments

We present posterior inference results from the model described in Section 3 for simulated and real data. Throughout, we compare our results to those generated by warpMix, a state-of-the-art frequentist functional mixed model (Claeskens et al., 2021); we use the default parameter settings in warpMix. In addition, in Appendix A, we compare our results to those generated by a state-of-the-art Bayesian approach (Cheng et al., 2016), which models functions under the popular square-root velocity transformation (Srivastava et al., 2011) as realizations of a Gaussian process centered at a mean function \(\). Phase variation is incorporated via the value-preserving action of \(\) with a prior model that is the same as PM2 in our model.

The main object of interest for posterior inference is \(\). Note however that, as discussed earlier, \(\) and \(D_{}()=()}\) for any \(\) are equivalent in terms of their size-and-shape. _Thus, we first center all posterior samples for \(\), via an average of the estimated posterior means of object-level phase functions, to obtain size-and-shape representatives in their equivalence classes under the norm-preserving action_; this centering is similar in spirit to the orbit centering in Srivastava et al. (2011). Assuming that we have \(N\) posterior samples of each \(_{i},\ i=1,,n\), we first compute \(:=1/(nN)_{i=1}^{n}_{j=1}^{N}_{i}^{j}\), where \(_{i}^{j}\) is the \(j\)th posterior sample of the phase function \(_{i}\); due to convexity of \(\), note that \(\). We then compute the centered posterior samples of \(\), \((^{j})}\), which may be visualized directly or used to estimate posterior summaries, e.g., pointwise posterior mean and credible interval. In some cases, we also visualize the posterior samples and pointwise posterior mean for a phase function \(_{i}\). For all examples in this section, we use \(N=100,000\) with a burn-in period of \(200,000\) iterations; for visualization of posterior samples for \(\) and \(_{i}\), we use a uniform subsample of size \(1,000\) to ensure that all plots are easily readable.

### Simulations

**Example 1: data generated from our model.** We first consider an example based on data simulated from model in (6). We use \(B_{f}=6\) modified Fourier basis functions for \(\) and \(B_{r}=6\) B-spline basis functions for each \(v_{i}\). The ground truth variances are \(_{c}^{2}=0.25\) and \(^{2}=0.1\). Then, to generate the data, we sample \((,_{_{r}})\), and consider two cases for phase functions based on PM1 and PM2: (i) \(_{i}(-1,1)\), and (2) \(p(_{i})(30),\ =(0,0.25,0.5,0.75,1)\). The sample size in this simulated example is \(n=30\).

Figure 2 displays results based on data generated via PM1 for phase functions (row 1) and PM2 (row 2). The simulated data is shown in panel (a). Upon visual inspection, it is difficult to discern the underlying \(\). Panel (b) displays estimation results for \(\): ground truth in black, centered posterior samples in blue, centered posterior mean in red, and warpMix estimate in yellow. The proposed

Figure 2: Row 1: Phase functions from PM1. Row 2: Phase functions from PM2. (a) Simulated data (\(n=30\)). (b) Estimation of \(\): ground truth (black), posterior samples (blue), posterior mean (red), warpMix estimate (yellow). (c)&(d) Histograms of posterior samples for \(^{2}\) and \(_{c}^{2}\), respectively (posterior mean in red; ground truth in black). (e) Estimation of phase function for a randomly chosen observation: ground truth (black), posterior samples (blue), posterior mean (red).

model is effective at recovering the underlying size-and-shape of \(\), which contains two local minima and maxima. On the other hand, the warpMix estimate only contains one local minimum and maximum, and is clearly an inaccurate representation of the size-and-shape of \(\). Panels (c) and (d) show histograms of posterior samples for the variance parameters \(^{2}\) and \(^{2}_{c}\), respectively; the ground truth values are in black and the estimated posterior means in red. In both cases, we slightly overestimate both variance parameters. Finally, in (e), we show estimation results for a phase function \(_{i}\) corresponding to a randomly chosen observation. As before, posterior samples are shown in blue, posterior mean in red and the ground truth in black. In both cases (phase function generated from PM1 or PM2), we reliably recover the underlying ground truth.

**Example 2: data generated from warpMix model.** Next, we consider a more challenging scenario for the proposed model and specifically focus on a comparison to warpMix. In this case, phase functions and random effect functions are generated using the warpMix model; we set \(^{2}_{c}=0.25\) and \(^{2}=0.0001\). Comparison of estimation accuracy is based on three different fixed effect functions: \(_{1}(t)=\{(3 t)+3 t\}/4\), \(_{2}(t)=^{-(t-0.25)^{2}/0.04}+^{-(t-0.75)^{2}/0.02}\) and \(_{3}(t)=(2 t+/2)\), \(t\). To generate the data, we use the value-preserving action as in the warpMix specification, and not the norm-preserving action that is utilized in our model.

To specify our models, we use (i) \(B_{f}=6\) modified Fourier basis functions or B-spline basis functions for \(\) with PM1 or PM2 for phase functions with \(T_{}=7\), and (ii) \(B_{r}=6\) B-spline basis functions for each \(v_{i}\). In total, we consider four Bayesian models, 1-F, 1-B, 2-F and 2-B, where the number indexes the prior model on phase and the letter indexes the basis used to model \(\).

First, in Figure 3, we present estimation results for (a) \(_{1}\), (b) \(_{2}\) and (c) \(_{3}\) based on Model 2-B. The ground truth is in black, centered posterior samples in blue, centered posterior mean in red, and warpMix estimate in yellow. Visually, both warpMix and Model 2-B are effective at recovering the underlying fixed effect functions. To quantitatively assess estimation accuracy, we adopt the evaluation criterion used in Claeskens et al. (2021): \(_{}:=_{j=1}^{T-1}[(t_{j})-(t_{j})]^{2}(t_{j+1}-t_{j})\). The \(\) for our models is defined as the centered posterior mean. Table 1 reports the results with best performance highlighted in bold. In all three cases, one of our Bayesian models yields the lowest estimation error. For \(_{1}\), only Model 1-B outperforms warpMix, which is not surprising since \(_{1}\) has the simplest structure. Nonetheless, the other three Bayesian models are competitive as well. For \(_{2}\), all four of our models significantly outperform warpMix, with Model 2-F yielding an error reduction of \(82\%\) as compared to warpMix. For \(_{3}\), the two models with PM2 on \(\) outperform warpMix suggesting the need for flexible phase functions in this case. These results show that the proposed models are effective in estimating \(\) even when the underlying data generating process uses value-preserving warping, and supports claim (iii) at the end of Section 2.

   & warpMix & Model 1-F & Model 1-B & Model 2-F & Model 2-B \\  \(_{1}\) & 0.0179 & 0.0194 & **0.0151** & 0.0193 & 0.0182 \\  \(_{2}\) & 0.0394 & 0.0134 & 0.0235 & **0.0070** & 0.0152 \\  \(_{3}\) & 0.0077 & 0.0195 & 0.0111 & 0.0044 & **0.0033** \\  

Table 1: Comparison of fixed effect estimation accuracy based on posterior mean from proposed Bayesian models and warpMix estimate. Smallest estimation errors are highlighted in bold.

Figure 3: Comparison of estimation results based on Model 2-B and warpMix for (a) \(_{1}\), (b) \(_{2}\) and (c) \(_{3}\). In each panel, we show the ground truth (black), centered posterior samples (blue), centered posterior mean (red), and warpMix estimate (yellow).

### Real data examples

We now consider application of the proposed modeling framework to (i) Berkeley growth rate functions (\(n=93\)) [Srivastava et al., 2011b] (Figure 1(a)), and (ii) PQRST complexes (\(n=40\)) [Kurtek et al., 2013] (Figure 1(d)). Our primary interest in the Berkeley data lies in estimating an average pattern of growth spurts. However, the number and magnitudes of growth spurts for each child may differ quite markedly from those in the average growth rate function. Majority of the PQRST complexes exhibit similar pattern of local extrema and we are interested in inferring the average pattern, while accounting for variability in magnitudes of the extrema across observations. A functional mixed effects model is thus appropriate for both these data settings to reliably estimate the size-and-shape of \(\).

For **Berkeley** data, we use modified Fourier basis for \(\) with \(B_{f}=6\), B-spline basis for each \(v_{i}\) with \(B_{r}=6\), and PM1 on \(\); for **PQRST** data we use B-spline basis for \(\) with \(B_{f}=12\), B-spline basis for each \(v_{i}\) with \(B_{r}=6\) to better model the sharp local features of the QRS complex (Figure 1(e)), and the PM2 model on \(\) to allow for inflection points in estimated phase.

Row 1 in Figure 4 shows estimation results for the Berkeley data. In (a), we show centered posterior samples of \(\) in blue with the centered posterior mean in red. We uncover two growth spurts, a small initial one followed by a larger pubertal one. This agrees with previous literature that has considered this data [Srivastava et al., 2011b]. The marginal posterior uncertainty for \(\) is very small throughout the domain. We also show the warpMix estimate, which was only able to recover one small growth spurt. Panels (b) and (c) show histograms of posterior samples of \(^{2}\) and \(^{2}_{c}\), respectively. Panel (d) displays the posterior samples (blue) and posterior mean (red) of a phase function for a randomly chosen observation. Panel (e) shows the observation corresponding to panel (d) in black. In addition, the blue functions are \(D_{^{j}_{i}}(^{j})\), the posterior samples of \(\) rotated using corresponding posterior samples of the phase function, where \(i,j\) index the observation and posterior sample, respectively. Note that the blue functions fit the observed black function well.

Row 2 in Figure 4 shows estimation results for the PQRST data. Panels (a)-(e) are the same as in the previous description. The estimated size-and-shape of \(\) resembles a PQRST complex as desired and contains sharp features that are representative of the observed data. Further, posterior uncertainty appears greater along the P and T waves than the QRS complex. The warpMix model failed to yield an estimate in this case, potentially due to lack of modeling flexibility in capturing the QRS complex and phase variation. The estimated phase function in (d) contains an inflection point motivating our use of PM2 on \(\). Finally, panel (e) shows that the rotated posterior samples of \(\) fit a randomly chosen observation well. Appendix I shows posterior mean and \(95\%\) credible interval estimates, as well as warpMix estimates, of \(\) for five additional datasets.

Figure 4: Estimation results for Berkeley data (row 1) and PQRST complexes (row 2). (a) Posterior samples (blue) and posterior mean (red) of \(\), and warpMix estimate (yellow). The warpMix model was unable to yield an estimate of \(\) for PQRST data. (b)&(c) Histograms of posterior samples for \(^{2}\) and \(^{2}_{c}\), respectively (posterior mean in red). (d) Posterior samples (blue) and mean (red) of phase function for a randomly chosen observation. (e) Observation corresponding to (d) (black) with rotated posterior samples of \(\) (blue).

Discussion

Numerical experiments in Section 4 and Appendices A and I demonstrate benefits of the proposed mixed model in recovering the size-and-shape of a fixed effect function \(\), while outperforming current state-of-the-art. What is lacking is theoretical support for the same, and this is work in progress.

To evolve the MCMC algorithm in MATLAB R2021a for \(300,000\) iterations yielding \(100,000\) posterior samples after burn-in, on a computing server with 6 parallel Intel(R) Xeon(R) CPUs with 20GB of memory, the computing time is approximately \(93\) and \(111\) minutes, respectively, under PMs 1 and 2 on \(\), based on \(n=30\) functions discretized at \(T=50\) points. There is room for improvement of efficiency in the MCMC computations, and alternatives may be explored.

We specify the number of basis functions for the fixed effect \(\) and the size-and-shape altering random effect \(v_{i}\)_a priori_. Alternatively, one could treat the number of basis functions \(B_{f}\) and \(B_{r}\) as random and estimate them. This, however, would require more advanced MCMC algorithms for posterior inference. Further, we use the modified Fourier basis and B-spline basis in our model. Other orthonormal basis functions could also be used, but this choice is not crucial for reliable recovery of the size-and-shape of \(\) since the norm preserving action \(D_{}\) rotates the basis system toward the data, allowing us to learn a data-driven basis for \(\). An alternative approach would be to directly learn an appropriate subspace for \(\), which we plan to consider in future work.

Exciting and novel extensions of the proposed mixed modeling framework are readily available to handle more complex functional data. The proposed model may be easily modified to handle sparsely/irregularly sampled and fragmented, or partially observed, functional data (Matuk et al., 2022). The norm-preserving action of \(\) may be used to perform inference for the size-and-shape of a fixed effect parameterized open/closed curve \(:^{d},\ d>1\)(Srivastava et al., 2011; Kurtek et al., 2012). Finally, for two-dimensional parameterized surfaces \(f:D^{2}^{3}\), a similar norm-preserving action of the reparameterization diffeomorphism group with elements \(:D D\)(Jermyn et al., 2017) may be used to infer the mean size-and shape of a fixed effect surface.

Functional data is arising as a common object in various applications, including computer vision and biomedical imaging, and functional data models are becoming increasingly important in machine learning (Rao and Reimherr, 2023a,b). The ideas we have explored in the proposed framework can be applied more broadly to other regimes. For instance, employing mixed models with random effects to better model correlated input data in neural networks is fast gaining traction (Simchoni and Rosset, 2023). There is also increasing interest in the use of geometry and invariance to nuisance transformations in neural networks (Bronstein et al., 2021). Our framework provides understanding for the type of signal that can be recovered from complex input data in the presence of nontrivial symmetries and geometric information, which offers a new perspective on incorporating geometric constraints in various types of data settings and models.