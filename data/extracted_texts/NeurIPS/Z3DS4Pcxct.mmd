# Addressing Uncertainty in LLMs to Enhance Reliability in Generative AI

Ramneet Kaur1, Colin Samplawski1, Adam D. Cobb1, Anirban Roy1, Brian Matejek1, Manoj Acharya1, Daniel Elenius1, Alexander M. Berenbeim2, John A. Pavlik2, Nathaniel D. Bastian2, Susmit Jha1

###### Abstract

In this paper, we present a dynamic semantic clustering approach inspired by the Chinese Restaurant Process, aimed at addressing uncertainty in the inference of Large Language Models (LLMs). We quantify uncertainty of an LLM on a given query by calculating entropy of the generated semantic clusters. Further, we propose leveraging the (negative) likelihood of these clusters as the (non)conformity score within Conformal Prediction framework, allowing the model to predict a set of responses instead of a single output, thereby accounting for uncertainty in its predictions. We demonstrate the effectiveness of our uncertainty quantification (UQ) technique on two well-known question-answering benchmarks, COQA and TriviaQA, utilizing two LLMs--Llama-2-13b and Mistral-7b. Our approach achieves state-of-the-art (SOTA) performance in UQ, as assessed by metrics such as AUROC, AUARC, and AURAC. The proposed conformal predictor is also shown to produce smaller prediction sets while maintaining the same probabilistic guarantee of including the correct response, in comparison to existing SOTA conformal prediction baseline. Our code is publicly accessible at https://shorturl.at/TyHSq.

## 1 Introduction

Large language models (LLMs) are increasingly being utilized for various tasks, including open-world question answering. However, these models are known to exhibit hallucinations, confidently producing incorrect information or relying on faulty reasoning. Quantifying the uncertainty associated with an LLM for a given input offers a practical method to account for model's reliability on its response. When there is a strong correlation between LLM's accuracy and the computed uncertainty, one can effectively use uncertainty quantification (UQ) approach to determine when to place their trust in the model's responses.

The challenge of UQ for LLMs in generative context differs significantly from that encountered in regression or classification tasks. While the latter has been well-studied Guo et al. (2017); Jha et al. (2019); Xiao and Wang (2019); Hu and Khan (2021); Magesh et al. (2023), UQ for generative models presents unique challenges due to the free-form nature of the responses of varying lengths. Additionally, the syntactic similarity of generated sequences may not necessarily align with their semantic similarity.

Self-consistency theory can be employed to measure LLM's uncertainty on an input query by comparing semantic context of multiple outputs sampled from the LLM for that query (Wang et al., 2022).1 Building on recent observations by Lin et al. (2023); Kuhn et al. (2023), we use embeddingbased semantic similarity to group sampled outputs into semantic clusters, and then quantify LLM's uncertainty by entropy of these clusters. Specifically, we propose a new dynamic semantic clustering algorithm based on the sequential distance dependent Chinese Restaurant Process (DDCRP) Blei and Frazier (2011); Tuncer and Schulz (2016) for quantifying LLM's uncertainty via entropy of the generated clusters.

Furthermore, we present a novel approach towards trustworthy inference from LLMs that combines the model's uncertainty with conformal prediction. Specifically, we propose to use (negative) likelihood of the clusters generated via DDCRP, as the (non)conformity score in the conformal prediction framework (Balasubramanian et al., 2014). This framework takes into account prediction uncertainty by generating a set of a single prediction, where the output set is guaranteed to contain the correct label (or answer in our case) with a certain confidence level. LLMs can generate free-form responses for question answering and so, the conformal prediction set in our approach is different from the usual setting of being a subset of known finite set of labels. We use semantic similarity to identify different or semantically diverse responses while constructing the conformal set. This use of conformal prediction by LLMs in question answering is the key novelty of our approach that aims to combine LLMs uncertainty on an input query with conformal prediction.

We demonstrate the efficacy of our UQ approach on two question-answering benchmarks, COQA and TriviaQA, using two LLMs, Llama-2-13b and Mistral-7b, achieving state-of-the-art (SOTA) results in most test cases using AUROC, AUARC and AURAC as metrics. We also show that our conformal predictor generates smaller prediction sets for the same probabilistic guarantees of including correct response compared to the SOTA conformal prediction baseline by Quach et al. (2023). This highlights not only the validity but also usefulness of our method in practical applications.

## 2 Related Work

**Uncertainty quantification (UQ)** for LLMs has received significant attention over the last few years. One approach is to explicitly query the model for the correctness probability (Kadavath et al., 2022). Another approach relies on utilizing the log-likelihood (Jiang et al., 2020) associated with its generated response by taking a product or an average or other statistical aggregation over the generated tokens. LLMs are known to be not well-calibrated (Mielke et al., 2022) and consequently, methods for calibrating LLMs (Huang et al., 2024) have also been proposed. Semantic entropy or predictive uncertainty that measures the (in)consistency among multiple responses has been proposed as a metric for UQ of LLMs (Kuhn et al., 2023; Lin et al., 2023; Lu et al., 2023). We also use semantic entropy for UQ but adopt a novel semantic clustering approach and empirically demonstrate its effectiveness.

**Conformal prediction (CP)**(Balasubramanian et al., 2014) has been used for deploying deep learning models (Kaur et al., 2022; Haroush et al., 2021; Kaur et al., 2023, 2024; Yang et al., 2024) in high-assurance applications wherein the model predicts a set instead of a single prediction such that one of the responses in the set is guaranteed to be correct with a probability higher than the user specified significance level. In the context of LLMs, conformal prediction has been used for providing coverage guarantees (Ye et al., 2024; Quach et al., 2023). Ye et al. (2024) concentrate on classification settings and propose non-conformity scores in the CP framework accordingly. In contrast, we focus on generative setting for LLMs in applications such as question-answering. Quach et al. (2023) propose generating diverse prediction sets based on the quality of individual responses, and a set scoring function. They utilize CP to derive hyperparameters (\(\)s) for diversity, quality, and set scoring function in their algorithm for coverage guarantees. We, instead propose, using (negative) likelihood of clusters representing semantically diverse responses, as the (non)conformity score in the CP framework for generating sets with coverage guarantees, and compare our results with Quach et al. (2023)'s approach.

## 3 Clustering by Semantic Equivalence

In this section, we introduce the proposed clustering approach, and then describe its usage in uncertainty quantification and building the conformal predictor for LLMs.

_Semantic entropy_ over \(|C|\) equivalence classes (or clusters) of multiple responses sampled from an LLM on an input query \(x\) has been used as the _UQ measure_ for the LLM on \(x\)(Kuhn et al., 2023):

\[SE(x)=-_{c}p(c|x) p(c|x),\]

where the probability of an equivalence class (corresponding to a cluster of embeddings), \(c\), conditioned on \(x\), is given by \(p(c|x)=_{ c}p(|x)\) and \( c\) denotes a sentence (or response) in an equivalence class \(c C\). The probability of each sentence is given by the standard product of the conditional token probabilities:

\[p(|x)=_{i}p(s_{i}|s_{<i},x).\]

The result of using semantic entropy is to sharpen \(p(c|x)\) when there are many responses with the same meaning, and therefore reduce the predicted entropy.

To generate clusters containing semantically equivalent responses, we need to define a function that checks semantic similarity between responses. Kuhn et al. (2023) choose the conservative approach of using Deberta (Natural Language Inference) model He et al. (2020) to only define two sentences to be semantically equivalent if and only if entailment was classified in both directions. Entailment in both directions is not necessary when one response includes additional information than another but they both contain the same relevant semantic information. For instance, let us consider the following input query: "What is the capital of France?" with the first response \(}=\) "Paris", and the second response \(}=\) "Paris, the capital city of France, is one of the most iconic and romantic cities in the world. It has a rich history dating back more than 2,000 years". Although, both the responses are semantically equivalent with respect to the input query, \(}\) entails \(}\) but vice versa is not true. Enforcing entailment in both directions can, therefore, lead to formation of more clusters than required with semantically equivalent information distributed in different clusters.

Thus, our approach computes the probability that two responses, \(_{i}\) and \(_{j}\), are in the same equivalence class (that is, the same semantic cluster), by taking the maximum entailment score output by Deberta, \(p_{ij}=(p(_{i}+_{j}),(p(_{j}_{i}))\). This choice of taking a maximum can be viewed as a quantitative disjunction of entailment in either direction. We then use this approach to build the score that a response, \(_{j}\), belongs to an equivalence class, \(c\), by using the average probability across all the cluster members:

\[w(_{j} c)=_{_{i} c}p_{ij}\] (1)

This is also novel from the existing approaches for semantic clustering where \(}\) is assigned to the cluster \(c\) if it is entailed in both directions by only one member of \(c\). As observed in our qualitative evaluation (and reported in Appendix A.1), we postulate that this could be the reason for assigning semantically irrelevant responses to the same cluster because it is easier to incorrectly assign responses to the same cluster if we rely on only one member instead of all members in the cluster. In contrast, we take an average over all existing members of a cluster making our assignment more robust.

A naive approach would be to greedily assign \(}\) to a cluster with the highest probability. However, this is not sufficient since we need a mechanism for forming new equivalence classes (or clusters). Given a set of responses, we need to decide when to form a new cluster and when to assign \(}\) to an existing cluster \(c\) that has the highest score \(w(} c)\). We use the same mechanism as the Distance Dependent Chinese Restaurant Process (DDCRP) for iterative clustering (Blei and Frazier, 2011; Tuncer and Schulz, 2016). The motivation for using DDCRP is due to its probabilistic and dynamic nature for deciding on the formation of a new cluster or membership in an existing cluster based on semantic equivalence. Following DDCRP, the score for a sentence \(}\) in a new cluster \(c^{*}\) is defined as:

\[w(} c^{*})=,\] (2)

where \(|C|\) is the current number of clusters and \(>0\) is the rate parameter, i.e. prior over forming new clusters. The final (softmax) probabilities of assigning \(}\) to an existing cluster (\(c_{i}\)) and new cluster (\(c^{*}\)) are respectively given by:

\[(z_{i})=}}{_{j}e^{z_{j}}+e^{z^{*}}}\] \[(z^{*})=}}{_{j}e^{z_{j}}+e^{z^{*}}},\] (3)

where \(z_{i}=w(s c_{i}),\ z^{*}=w(s c^{*})\). Since the equivalence class assignment of the new response is related to semantic equivalence with the existing responses, we can map our clustering algorithm as an instance of sequential DDCRP.

Alg. 1 is the proposed clustering approach for iterative clustering of semantically equivalent responses. It is executed in a sequential fashion, starting with an empty set of clusters. After the first response from the LLM, we compute the score for forming a new cluster as: \(=1\). This results in a new cluster probability of 1, leading a new cluster to be formed deterministically. In subsequent rounds, we compute the per cluster assignment scores for the new response as per Equations (1) and (2) for existing and new cluster respectively. We, then, compute the softmax probabilities for these scores from Equation (3), and assign the new response to a cluster (either existing cluster \(c_{i}\) or a new cluster \(c^{*}\)) with the maximum probability.

```
1:Input: query \(x\), LLM model \(M\)
2:Parameter: rate parameter \(>0\), number of responses \(N\)
3:Output: clusters \(C\)
4:Initialize:\(C\)
5:for\(i=1\) to \(N\)do
6:\(_{i}=M(x)\) [generate with LLM]
7:\(scores_{|C|+1}\)
8:for\(c_{j}\) in \(\)do
9:\(scores[j] w(_{i} c_{j})\)
10:endfor
11:\(scores[-1]\)
12:\(probs(scores)\)
13:\(k argmax(probs)\) {cluster assignment}
14:if\(k==|C|+1\)then
15:\(C C\{_{i}\}\) {new cluster}
16:else
17:\(c_{k} c_{k}\{_{i}\}\)
18:endif
19:endfor
20:
21:return\(C\) ```

**Algorithm 1** Clustering by Semantic Equivalence

In all our experiments, we use the rate parameter of \(=0.5\). We performed a grid search over \([0.2,0.3,,0.7]\) and observed very little variance in performance. We set the value of number of responses \(N\) is set to \(20\), which is consistent with the existing work (Kuhn et al., 2023; Lin et al., 2023; Quach et al., 2023).

### Uncertainty Quantification

Different clusters containing semantically diverse responses to an input query can be used to quantify uncertainty of the LLM on the query. Similar to Kuhn et al. (2023), we also use entropy of the generated clusters from Alg. 1 as a measure of UQ for LLMs on a given query. Both qualitative and quantitative results indicate that the proposed clustering approach yields better results than Kuhn's baseline.

### Conformal Set Prediction

For each cluster \(c\), we have \(p(c|x)\). We, therefore, use the negative log probability, \([1/p(c|x)]\), of the individual clusters, as the non-conformity score in conformal prediction (CP) framework (Balasubramanian et al., 2014), for generating prediction sets. Non-conformity scores of calibration datapoints is used to build a reference empirical distribution to compare against when building the prediction set. Specifically, depending on the desired significance level, \(\), prediction set is generated by comparing scores for the test clusters with a threshold from the empirical distribution: non-conformity score of calibration set at \((1-)^{th}\) quantile of the distribution.2 Intuitively, clusters with low negative log probability (or high likelihood) are more likely to be included in prediction sets compared to clusters with high negative log probability (or low likelihood). If an LLM outputs many semantically equivalent responses, then we expect the cluster's \([1/_{ c}p(|x)]\) to decrease due to the summation over the sentence probabilities by sharpening the cluster probability.

The use of CP for constructing the prediction sets gives us coverage guarantees on the true answer in the set with the probability greater than or equal to \(1-\)(Vovk et al., 2005). Alg. 2 is the proposed CP algorithm for generating prediction sets with coverage guarantees.

For an input query \(x\) (from test or calibration set), clusters are generated via Alg. 1. We use negative log probability (nlp = \([1/p(c|x)]\)) of each generated cluster (\(c\)) for \(x\) as the non-conformity score for the cluster. For the desired significance level \((0,1)\), the prediction threshold \(\) is decided as the score at \((1-)^{th}\) quantile of the empirical distribution of non-conformity scores for the calibration clusters. Assuming all responses are semantically equivalent in a cluster, a single response from the test cluster (\(c\)) is added to the prediction set if its non-conformity score (nlp(\(c\))) is below the prediction threshold \(\). In our experiments, prediction set is constructed from the first response in the qualified test cluster.

```
1:Input: query \(x\), LLM model \(M\), prediction threshold \(\) from \((1-)^{th}\) quantile of the empirical distribution of calibration set non-conformity scores
2:Output: Prediction Set \(\) with predictions on \(x\) by \(M\) s.t. \(Pr.() 1-\)
3:\(C=\) set of clusters from Alg. 1 on (\(x\), \(M\))
4:\(S=\) set of non-conformity scores for the generated clusters: \(\{ c C:\)nlp\((c)\}\)
5:\(=\{\)a response from \(C[i]\) s.t. \(S[i]:i=1,,|C|\}\)
6: return \(\) ```

**Algorithm 2** Conformal Prediction Sets by LLM

## 4 Experimental Results

The experimental evaluation focuses on two research questions. **RQ1:** Does the novel semantic clustering approach inspired from CRP improve the UQ of LLMs? **RQ2:** How does Alg 2 perform compared to the CP baseline on LLMs for free form generative responses?

**Datasets and Models**. We use two question-answer datasets: COQA (Reddy et al., 2019) and TriviaQA (Joshi et al., 2017), over which we compare the performance of two LLMs, LLama-2-13b: non-instruct model (Touvron et al., 2023), and Mistral-7b: instruct model (Jiang et al., 2023). Following existing literature (Lin et al., 2023; Kuhn et al., 2023), we deploy three evaluation methods: (1) We query GPT-4 (Achiam et al., 2023) by asking it to provide a rating on whether a response is correct with a value between 0 and 1, and label the response as correct if its rating \(>0.7\); (2) RougeL score (Lin, 2004) with a threshold \(>0.3\); (3) Deberta (He et al., 2020) to check for entailment of correct answer in the generated response.

### UQ Performance

We report Area Under Accuracy-Rejection Curve (AUARC) (Nadeem et al., 2009), and Area Under Rejection-Accuracy Curve (AURAC) for comparing our performance on UQ with Kuhn et al. (2023)'s,and Lin et al. (2023)'s approaches. For Lin et al. (2023)'s approach, we use EigV as their UQ metric3. While AUARC has been used as an evaluation metric previously (Lin et al., 2023), we include AURAC as a new metric. AUARC is an indicator of the accuracy of accepted (or highly certain) samples, and AURAC is an indicator of the accuracy of rejected (or highly uncertain) samples. In addition to AUARC, AURAC also indicates calibration of the UQ metric: we would like the accuracy of the model on the rejected samples by the UQ metric to be as low as possible, i.e. not rejecting samples on which LLMs are accurate.

The results are reported in Tables 1, and 2. Similar to Kuhn et al. (2023)'s, we also report our results with the UQ score unnormalized (Unnorm)/normalized (Norm) on the response's length. We outperform the baseline by Kuhn et al. (2023) in all the test cases, indicating that the proposed clustering approach performs better in UQ. We achieve competitive results in comparison to the current SOTA by Lin et al. (2023) by outperforming them in most cases. We also report AUROC, and compare with other baselines in Appendix A.2.

### Conformal Prediction Results

The desired properties of a prediction set is that the accuracy of the set should be as high as possible with a smaller set size. So, here we report accuracy and set size as the evaluation metrics.

#### 4.2.1 Comparison with the CP Baseline

Fig. 1 shows Alg. 2 results in comparison with the existing baseline by Quach et al. (2023) on using CP for generating prediction sets with coverage guarantees.

   &  &  \\ 
**Model** & **Eval.** & **Model** & **Sem. Ent.** & **EigV** & **Ours** & **Model** & **Sem. Ent.** & **EigV** & **Ours** \\  & & **Acc.** & Unnorm/Norm & & Unnorm/Norm & **Acc.** & Unnorm/Norm & & Unnorm/Norm \\   Llama-13b & GPT-4 & 73.22 & 85.97/56.90 & **54.63** & 58.42/55.32 & 67.03 & 40.09/04.27 & 39.42 & 39.92/**39.38** \\ Mistral-7b & GPT-4 & 73.38 & 63.06/62.02 & **59.83** & 62.77/61.41 & 60.68 & 35.57/35.04 & **33.19** & 35.13/33.29 \\  Mean & GPT-4 & 73.30 & 61.02/59.46 & **57.23** & 60.60/58.37 & 63.86 & 37.83/37.66 & **36.31** & 37.53/36.34 \\  Llama-13b & Rougel.27 & 72.56 & 56.75/55.53 & 53.78 & 55.78/**52.65** & 64.60 & 39.12/39.39 & 38.93 & 38.81/**38.35** \\ Mistral-7b & Rougel.4 & 44.74 & 27.62/62.95 & **77.12** & 27.37/82.26 & 42.33 & 17.51/19.56 & 17.06 & **16.95**/18.11 \\  Mean & Rougel.5 & 85.75 & 42.19/42.59 & **40.45** & 41.57/40.46 & 53.47 & 28.14/29.48 & 28.00 & **27.88**/28.23 \\  Llama-13b & Deberta & 63.74 & 46.07/46.91 & **42.04** & 45.07/43.56 & 63.33 & 37.23/37.94 & **36.70** & 36.88/36.84 \\ Mistral-7b & Deberta & 11.23 & 3.84/5.70 & 4.13 & **3.82**/5.00 & 33.92 & 11.00/13.54 & 11.35 & **10.89**/12.45 \\  Mean & Deberta & 37.49 & 24.96/26.31 & **23.09** & 24.45/24.28 & 48.63 & 24.12/25.74 & 24.03 & **23.89**/24.65 \\  

Table 2: AURAC (\(\)) results in comparison to Kuhn et al. (2023)’s Semantic Entropy (Sem. Ent.) results in most of the cases are with ‘EigV’ metric, and therefore we compare our results with this UQ metric.

   &  &  \\ 
**Model** & **Eval.** & **Model** & **Sem. Ent.** & **EigV** & **Ours** & **Model** & **Sem. Ent.** & **EigV** & **Ours** \\  & & **Acc.** & Unnorm/Norm & & Unnorm/Norm & **Acc.** & Unnorm/Norm & & Unnorm/Norm \\  Llama-13b & GPT-4 & 73.22 & 85.97/56.90 & **54.63** & 58.42/55.32 & 67.03 & 40.09/04.27 & 39.42 & 39.92/**39.38** \\ Mistral-7b & GPT-4 & 73.38 & 63.06/62.02 & **59.83** & 62.77/61.41 & 60.68 & 35.57/35.04 & **33.19** & 35.13/33.29 \\  Mean & GPT-4 & 73.30 & 61.02/59.46 & **57.23** & 60.60/58.37 & 63.86 & 37.83/37.66 & **36.31** & 37.53/36.34 \\  Llama-13b & Rougel.27 & 72.56 & 56.75/55.53 & 53.78 & 55.78/**52.65** & 64.60 & 39.12/39.39 & 38.93 & 38.81/**38.35** \\ Mistral-7b & Rougel.4 & 44.74 & 27.62/62.95 & **77.12** & 27.37/82.26 & 42.33 & 17.51/19.56 & 17.06 & **16.95**/18.11 \\  Mean & Rougel.5 & 85.75 & 42.19/42.59 & **40.45** & 41.57/40.46 & 53.47 & 28.14/29.48 & 28.00 & **27.88**/28.23 \\  Llama-13b & Deberta & 63.74 & 46.07/46.91 & **42.04** & 45.07/43.56 & 63.33 & 37.23/37.94 & **36.70** & 36.88/36.84 \\ Mistral-7b & Deberta & 11.23 & 3.84/5.70 & 4.13 & **3.82**/5.00 & 33.92 & 11.00/13.54 & 11.35 & **10.89**/12.45 \\  Mean & Deberta & 37.49 & 24.96/26.31 & **23.09** & 24.45/24.28 & 48.63 & 24.12/25.74 & 24.03 & **23.89**/24.65 \\  

Table 1: AUARC (\(\)) results in comparison to Kuhn et al. (2023)’s Semantic Entropy (Sem. Ent.) results in most of the cases are with ‘EigV’ metric, and therefore we compare our results with this UQ metric.

The coverage guarantee (or guarantee of the correct answer contained in the prediction set by CP) is expected to be \((1-)\). So, as the value of \(\) increases, the accuracy and the set size is expected to decrease. This is what we observe for both approaches: ours and the baseline, with both the approaches satisfying the coverage guarantees. Quach et al. (2023) report results with different variations of their proposed algorithm (Algorithm 1 of their paper) in terms of the set scoring function (\(\)): First-\(K\), Max, and Sum, and on **TriviaQA with Llama-2-13b**. We outperform these results for all the three variations on both evaluation metrics.

#### 4.2.2 Experiments on COQA

We also evaluate our Alg. 2's performance on COQA. Figure 2 shows these results for both accuracy and set size and with all the three GT evaluation approaches on COQA: GPT-4, RougeL, and Deberta.

Here, we also report the point accuracy, which is the average accuracy of the individual \(N=20\) generations. For \( 0.35\), the prediction set accuracy is always higher than the point accuracy. Consistent with the results on TriviQA, here also the value of accuracy and set size decreases with the increase in the value of \(\). GPT and RougeL evaluations satisfy the coverage guarantee \( 0.15\). Even though conformal prediction provides a rigorous theoretical guarantee, deviations from the coverage guarantee can occur in practice due to limited sample variability in the calibration set (Angelopoulos and Bates, 2021). This justifies the accuracy results with Deberta Evaluation and the other two evaluations with \(<0.15\).

One difference to note here from the TriviaQA experiments is in the set of \(\) values. For TriviaQA, we reported results with \(\{0.2,,0.5\}\), and for COQA we reported results with \(\{0.1,0.2,,0.5\}\). This is because we were getting 'nan' at \(=0.1\) from the Quach's baseline on TriviaQA. While further investigation on their code, we figured it out that they are hard-coding the value as 'nan' where the search for their algorithm's hyperparameters (\(\)s) might be failing.

## 5 Conclusion

This paper takes a step towards enhancing reliability in generative AI by addressing uncertainty in LLMs on a given query. Our approach focuses on the semantic equivalence of responses generated by an LLM when prompted multiple times for the input query. It is based on the idea that an LLM is expected to be accurate if it consistently generates semantically similar outputs when prompted multiple times with the same input. The underlying assumption here is that consistency can serve as an indicator of accuracy. Testing this hypothesis is one of the future works that we intend to investigate. Additionally, we aim to explore alternative scoring methods beyond the probability of response--calculated as the product of conditional token probabilities-- used to determine the likelihood of semantic clusters. This is important because response probability can be sensitive to its length, which poses a significant challenge when dealing with free-form generations produced by LLMs.

Figure 1: Comparison of Accuracy (left) and Set Size of prediction sets (right) with Conformal Prediction baseline (Quach et al., 2023).