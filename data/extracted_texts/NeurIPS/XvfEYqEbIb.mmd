# Non-Rigid Shape Registration via

Deep Functional Maps Prior

 Puhua Jiang\({}^{1,2\#}\)   Mingze Sun\({}^{1\#}\)   Ruqi Huang\({}^{1}\)

1. Tsinghua Shenzhen International Graduate School, China  2. Peng Cheng Lab, China

# indicates equal contribution. Corresponding author: ruqihuang@sz.tsinghua.edu.cn

###### Abstract

In this paper, we propose a learning-based framework for non-rigid shape registration _without correspondence supervision_. Traditional shape registration techniques typically rely on correspondences induced by extrinsic proximity, therefore can fail in the presence of large intrinsic deformations. Spectral mapping methods overcome this challenge by embedding shapes into, geometric or learned, high-dimensional spaces, where shapes are easier to align. However, due to the dependency on abstract, non-linear embedding schemes, the latter can be vulnerable with respect to perturbed or alien input. In light of this, our framework takes the best of both worlds. Namely, we deform source mesh towards the target point cloud, guided by correspondences induced by high-dimensional embeddings learned from deep functional maps (DFM). In particular, the correspondences are dynamically updated according to the intermediate registrations and filtered by consistency prior, which prominently robustify the overall pipeline. Moreover, in order to alleviate the requirement of extrinsically aligned input, we train an orientation regressor on a set of aligned synthetic shapes independent of the training shapes for DFM. Empirical results show that, with as few as dozens of training shapes of limited variability, our pipeline achieves state-of-the-art results on several benchmarks of non-rigid point cloud matching, but also delivers high-quality correspondences between unseen challenging shape pairs that undergo both significant extrinsic and intrinsic deformations, in which case neither traditional registration methods nor intrinsic methods work. The code is available at https://github.com/rqhuang88/DFR.

## 1 Introduction

Estimating correspondences between deformable shapes is a fundamental task in computer vision and graphics, with a significant impact on an array of applications including robotic vision , animation , 3D reconstruction , to name a few. In this paper, we tackle the challenging task of estimating correspondences between _unstructured_ point clouds sampled from surfaces undergoing _significant_ non-rigid deformations.

In fact, this task has attracted increasing interest [59; 26; 35; 24; 8] in shape matching community. These methods all follow a data-driven approach to learn embedding schemes, which project point clouds into certain high-dimensional spaces. By lifting to high-dimensional spaces, the non-rigid deformations are better characterized than in the ambient space, \(^{3}\). The optimal transformations and therefore the correspondences are then estimated in the embedded spaces. Despite the great progresses, such approaches suffer from the following limitations: 1) Their performance on unseen shapes is largely unwarranted; 2) The learned high-dimensional embeddings lack intuitive geometric meaning, and the induced correspondences are difficult to evaluate and analyze without ground-truth labels.

On the other hand, the above limitations are less of a concern from the perspective of shape registration, either axiomatic [1; 55] or learning-based . Unlike the former, the latter deform a source shape to non-rigidly align with a target explicitly in the ambient space \(^{3}\). In consequence, the mapping quality can be directly related to the alignment quality. Given a deformed source shape and a target, one can evaluate both qualitatively (by visual comparison) and quantitatively (by computing Chamfer distance), and, more importantly, further optimize the registration outcome via the correspondence-label-free quantitative metric. However, shape registration itself does not serve as a direct rescue to our problem of interest, as the previous approaches typically rely on the premise that the undergoing non-rigid deformation can be approximated by a set of local, small-to-moderate, rigid deformations, which severely hinders their performance in the presence of large deformations (see Fig. 1) and heterogeneity.

Motivated by the above observations, we propose a framework to take the best of classic shape registration and learning-based embedding techniques. In a nutshell, we leverage the estimated correspondence from the latter to guide shape deformation via the former iteratively. Our key insight is to enforce similarity between the deformed source and target in _both ambient space and learned high-dimensional space_. Intuitively, in the presence of large deformation, the learned correspondence is more reliable than that obtained by proximity in the ambient space. On the other hand, properly deforming source mesh to target point cloud increases spatial similarity in the ambient space, leading to higher similarity in the embedded space and therefore more accurate correspondences. In the end, we can compute correspondences between raw point clouds with a shared source mesh as a hub. As will be shown in Sec. 4, our method allows for choosing source shape during inference, which can be independent of the training data.

While being conceptually straightforward, we strive to improve the performance, robustness and practical utility of our pipeline by introducing several tailored designs. First of all, the key component of our pipeline is an embedding scheme for accurately and efficiently estimating correspondences between the deformed source shape and the target _point cloud_. In particular, to take advantage of Deep Functional Maps (DFM) [29; 7; 49], the current state-of-the-art approach on matching _triangular meshes_, we pre-train an unsupervised DFM  on meshes as a teacher net and then learn a point-based feature extractor (_i.e._, an embedding scheme for points) as a student net on the corresponding vertex sets with a natural self-supervision. Unlike the approach taken in , which heavily relies on DiffusionNet  to extract intricate structural details (e.g., Laplace-Beltrami operators) from both mesh and point cloud inputs, the teacher-student paradigm allows us to utilize a more streamlined backbone - DGCNN . Secondly, in contrast to prior works that either implicitly [31; 55] or explicitly [46; 8; 24] require rigidly aligned shapes for input/initialization, or demand dense correspondence labels . We train an orientation regressor on a large set of synthetic, rigidly aligned shapes to _automatically_ pre-process input point clouds in arbitrary orientations. Last but not least, we propose a dynamic correspondence updating scheme, bijectivity-based correspondence filtering, two-stage registration in our pipeline. We defer the technical details to Sec. 3.

Overall, our framework enjoys the following properties: 1) Due to the hybrid nature of our framework, it can handle point clouds undergoing significant deformation and/or heterogeneity; 2) As our feature extractor is self-supervised by some deep functional maps network, our framework is free of correspondence annotation throughout; 3) Our core operation is performed in the ambient space, enabling more efficient, faithful, and straightforward analysis of registration/mapping results than the

Figure 1: Shape registration methods like NDP  and AMM  estimate intermediate correspondences via extrinsic proximity, therefore suffering from large intrinsic deformations. In contrast, by incorporating a DFM-based point feature extractor, our method successfully deforms a FAUST template (the left-most mesh) to another individual of a different pose (the right-most point cloud).

purely learning-based approaches; 4) Based on a data-driven orientation regressor, we achieve an automatic pipeline for estimating correspondences between deformable point clouds.

As shown in Fig. 2, trained on the SCAPE  dataset, our framework generalizes well and outperforms the competing methods by a large margin in the challenging SHREC07-H dataset, which presents prominent variability in both extrinsic orientation and intrinsic geometry. We conduct a set of experiments to verify the effectiveness of our pipeline. We highlight that it achieves state-of-the-art results in matching non-rigid point clouds in both near-isometric and heterogeneous shape collections. More remarkably, it generalizes well despite the distinctiveness between the training set and test set. Moreover, our method, being point-based, is more robust with respect to topological perturbations within input shapes than the mesh-based baselines.

## 2 Related Works

**Non-rigid Shape Registration:** Unlike the rigid counterpart, non-rigidly aligning shapes is more challenging because of the perplexity of deformation models. In general, axiomatic approaches  assume the deformation of interest can be approximated by local, small-to-moderate, rigid deformations, therefore suffer from large intrinsic deformations. In fact, recent advances such as [60; 28; 55] mainly focus on improving the efficiency and robustness regarding noises and outliers. On the other hand, there exists as well a trend of incorporating deep learning techniques [6; 5; 21]. Among them, NDP  is similar to our method in the sense that the non-learned version follows an optimization-based approach based on some neural encoding. However, its shape registration is purely guided by proximity in the ambient space, hindering its performance in our problem of interest. Perhaps the most relevant approach with our method along this line is TransMatch , which follows a supervised learning scheme and learns a transformer to predict directly 3D flows between input point clouds. As demonstrated in Fig. 2 and further in Sec. 4, as a supervised method, TransMatch generalizes poorly to unseen shapes.

**Non-rigid Point Cloud Matching:** Unlike the above, several recent approaches [26; 30; 59] directly establish correspondence between a pair of point clouds. In general, these methods embed point clouds into a canonical feature space, and then estimate correspondences via the respective proximity. Leapard  learns such feature extractor under the supervision of ground-truth correspondences between partial point clouds with potentially low overlaps. On the other hand, DPC  and CorrnetNet3D  leverage point cloud reconstruction as proxy task to learn embeddings without correspondence label. Since intrinsic information is not explicitly formulated in these methods, they can suffer from significant intrinsic deformations and often generalize poorly to unseen shapes.

**Deep Functional Maps:** Stemming from the seminal work of functional maps  and a series of follow-ups [38; 22; 44; 37; 23], spectral methods have achieved significant progress in axiomatic non-rigid shape matching problem, and consequentially laid solid foundation for the more recent advances on Deep Functional Maps (DFM), which is pioneered by Litany et al. . Unlike axiomatic functional maps frameworks that aim at optimizing for correspondences represented in spectral basis (so-called functional maps) _with hand-crafted features as prior_. DFM takes an inverse

Figure 2: We estimate correspondences between heterogeneous shapes from SHREC’07 with four learning-based methods, all trained on the SCAPE_r dataset. Our method outperforms the competing methods by a large margin. Remarkably, our method manages to deform a SCAPE template shape to heterogeneous shapes, as indicated by the blue shapes.

viewpoint and aims to search for the optimal features, such that the induced functional maps satisfy certain structural priors as well as possible. Recent findings along this direction empirically suggest that the structural priors suffice to train an effective feature extractor, without any correspondence supervision [12; 29; 7; 3]. However, because of the heavy dependence of eigenbasis of Laplace-Beltrami operators, DFM is primarily designed for shapes represented by triangle meshes and can suffer notable performance drop when applied to point clouds without adaptation .

In fact, inspired by the success of DFM, several approaches [24; 8] have been proposed to leverage intrinsic geometry information carried by meshes in the training of feature extractors tailored for non-structural point clouds. Among these, NIE  and SSMSM  are closely related to our approach. As all three works attempt to train an effective, intrinsic-geometry-aware, per-point feature extractor by leveraging meshes during training. However, unlike the former two, our method incorporates optimization-based shape registration techniques, which effectively alleviates the limitation of purely relying on an abstract high-dimensional embedding scheme (_i.e._, the learned feature extractor).

**Combination of Extrinsic and Intrinsic Methods:** Unlike the above, our method operates in both extrinsic and intrinsic spaces. From this point of view, the most relevant work is Smooth Shells , which proposes to perform shape registration under a mixed representation of shapes, including eigenbasis, coordinates, and normal. Though achieving considerable high-quality correspondence on standard benchmarks, it heavily relies on the availability of mesh representation, but also is sensitive to the original extrinsic alignment of input shapes. These limitations are inherited by Deep Shells  - the learning version of the former. Similarly, NeuralMorph  jointly performs interpolation and correspondence estimation between a pair of shapes, which inject the intrinsic information by imposing geodesic preservation loss. As a result, it is non-trivial to lift the requirement of mesh input.

## 3 Methodology

Given a pair of shapes \(,\), our target is to deform \(\) to non-rigidly align with \(\). We assume that \(\) is represented as a triangle mesh so that we can effectively regularize the deformed shape by preserving local intrinsic geometry. On the other hand, we require _no_ structural information on \(\) and generally assume it to be a _point cloud_. Our pipeline can also be extended to compute correspondences between two raw point clouds \(_{1},_{2}\). To this end, we fix a template mesh \(\), perform respective shape registration between \(\) and the target point clouds, and finally compute the map by composition \(T_{12}=T_{s2} T_{1s}\).

Our pipeline is shown in Fig. 3, which consists of three main components: 1) An orientation regressor, \(\), for _extrinsically_ aligning input shapes, either mesh or point cloud; 2) A point feature extractor, \(\)

Figure 3: The schematic illustration of our pipeline. \(\) is a pre-trained orientation regressor for aligning input shapes. Then a pre-trained feature extractor \(\) embeds them into a high-dimensional canonical space. During the iterative optimization procedure of registration, correspondences are dynamically updated according to learned features (Stage-I) and coordinates (Stage-II) of the intermediate shapes. See more details in the text.

trained under deep functional maps scheme; 3) A registration module that iteratively optimizes for deformations non-rigidly aligning \(\) with \(\). In particular, it takes the rigidly aligned shapes from 1) as input, and leverages 2) to update correspondences during optimization.

Though our pipeline leverages a pre-trained feature extractor as registration prior, we highlight that neither the source nor the target is necessarily within or close to the respective training set. We provide throughout experimental evidence in Sec. 4 showing the generalizability of our pipeline.

### Orientation Regressor

Our first objective is to align input point clouds with arbitrary orientations into a canonical frame. We take a data-driven approach by training an orientation regressor  on \(5000\) synthetic SURREAL shapes from , which are implicitly aligned to a canonical frame by the corresponding generative codes. We refer readers to Supplementary Materials for more details.

### Point Feature Extractor

In order to efficiently and accurately estimate correspondences between deformed source shape and the target point cloud during registration, our next goal is to train a feature extractor for point clouds, which is intrinsic-geometry aware. The authors of  propose a multi-modal feature extractor based on DiffusionNet , which can process point clouds with an extra step of _graph_ Laplacian construction . Though it has demonstrated satisfying performance accommodating point cloud representation in , the explicit graph Laplacian construction is computationally heavy. Hence, we adopt the modified DGCNN proposed in  as our backbone, which is lightweight and robust regarding the sampling density and sizes of point clouds.

In particular, our training follows a teacher-student paradigm. Namely, we first train a deep functional maps (DFM) network, \(\), on a collection of meshes. Then we train a DFM network \(\) on the corresponding vertex sets, with an extra self-supervision according to the inclusion map between meshes and their vertex sets. In other words, the feature produced by \(\) is _point-wisely_ aligned with that produced by \(\).

**Training DFM on Meshes:** Our training scheme in principle follows that of , which delivers both accurate map estimation and excellent generalization performance.

1) We take a pair of shapes \(_{1},_{2}\), and compute the leading \(k\) eigenfunctions of the Laplace-Beltrami operator on each shape. The eigenfunctions are stored as matrices \(_{i}^{n_{i} k},i=1,2\).

2) We compute \(G_{1}=(_{1}),G_{2}=(_{2})\), projected into the spaces spanned by \(_{1},_{2}\) respectively, and leverage the differential FMReg module proposed in  to estimate the functional maps \(C_{12},C_{21}\) between the two shapes, then by regularizing the structure of \(C_{12},C_{21}\), say:

\[E_{}}()=\|C_{12}C_{21}-I\|_{F}^{2},E_{}}( )=\|C_{12}C_{12}^{T}-I\|+\|C_{21}C_{21}^{T}-I\|.\] (1)

3) To enhance \(\), we estimate the correspondences between \(_{1},_{2}\) via the proximity among the rows of \(G_{1},G_{2}\) respectively. Namely, we compute

\[_{12}(i,j)=)}{_{j^{}}(- _{ij^{}})}, i[|_{1}|],j[|_{2}|],\] (2)

where \(_{ij}=\|G_{1}(i,:)-G_{2}(j,:)\|\) and \(\) is the temperature parameter, which is increased during training . Then \(_{12}\) is the soft map between the two shapes. Ideally, it should be consistent with the functional maps estimated in Eqn.(1), giving rise to the following loss:

\[E_{}()=\|C_{12}-_{2}^{}_{21}_{1}\|+ \|C_{21}-_{1}^{}_{12}_{2}\|,\] (3)

where \(\) denotes to the pseudo-inverse. To sum up, \(^{*}= E_{}()\), which is defined as:

\[E_{}()=_{}}E_{}}()+ _{}}E_{}}()+_{}E _{}().\] (4)

**Training DFM on Point Clouds:** Now we are ready for training \(\) with a modified DGCNN  as backbone. We let \(F_{1}=(_{1}),F_{2}=(_{2})\). On top of \(E_{}\) in Eqn. (4), we further enforce the extracted feature from \(\) to be aligned with that from \(^{*}\) via PointInfoNCE loss :

\[E_{}(,^{*})=-_{i=1}^{n_{1}}(i,:),G_{1}^{*}(i,:)/)}{_{j=1}^{n_{1}}(  F_{1}(i,:),G_{1}^{*}(j,:)/)}-_{i=1}^{n_{2}}(i,:),G_{2}^{*}(i,:)/)}{_{j=1}^{n_{2} }( F_{2}(i,:),G_{2}^{*}(j,:)/)},\] (5)

where \(.\) refers to the dot products, \(\) is the temperature parameter, and \(n_{i}\) is the number of points of \(_{i}\). So the final training loss is defined as:

\[E()=E_{}()+_{}E_{}( ,^{*}),\] (6)

which is optimized on all pairs of shapes within the training set.

### Shape Registration

Now we are ready to formulate our registration module. We first describe the deformation graph construction in our pipeline. Then we formulate the involved energy functions and finally describe the iterative optimization algorithm. During registration, we denote the deformed source model by \(^{k}=\{^{k},\}\),\(^{k}=\{v_{i}^{k} i=1,,N\}\), where \(k\) indicates the iteration index and \(v_{i}^{k}\) is the position of the \(i-\)th vertex at iteration \(k\). The target point cloud is denoted by \(=\{u_{j} j=1,,M\}\).

Deformation Graph:Following, we reduce the vertex number on \(\) to \(H=[N/2]\) with QSIim algorithm . Then an embedded deformation graph \(\) is parameterized with axis angles \(^{H 3}\) and translations \(^{H 3}\): \(=\{,\}\). The vertex displacements are then computed from the corresponding deformation nodes. For a given \(^{k}\), we can compute displaced vertices via:

\[^{k+1}=(^{k},^{k}).\] (7)

Dynamic correspondence update:Thanks to our point-based feature extractor \(\), we can freely update correspondences between deforming source mesh and target point clouds. In practice, for the sake of efficiency, we update every 100 iterations in optimization (see Alg. 1).

Correspondence Filtering via Bijectivity:One key step in shape registration is to update correspondences between the deforming source and the target. It is then critical to reject erroneous corresponding points to prevent error accumulation over iterations. In particular, we propose a filter based on the well-known bijectivity prior. Given \(^{k}\) and \(\), we first compute maps represented as permutation matrices \(_{},_{}\), either based on the learned feature or the coordinates. For \(v_{i}^{k}^{k}\), we compute the geodesic on \(^{k}\) between \(v_{i}^{k}\) and its image under permutation \(_{}_{}\), then reject all \(v_{i}^{k}\) if the distance is above some threshold. For the sake of efficiency, we pre-compute the geodesic matrix of \(\) and approximate that of \(^{k}\) with it. Finally, we denote the filtered set of correspondences by \(^{k}=\{(v_{i_{1}}^{k},u_{j_{1}}),(v_{i_{2}}^{k},u_{j_{2}})\}\).

In the following, we introduce the energy terms regarding our registration pipeline.

Correspondence Term measures the distance of filtered correspondences between \(^{k}\) and \(\), given as:

\[E_{}=^{k}|}_{(v_{i}^{k},u_{j}) ^{k}}\|v_{i}^{k}-u_{j}\|_{2}^{2}.\] (8)

Chamfer Distance Term has been widely used [31; 30] to measure the extrinsic distance between \(^{k}\) and \(\):

\[E_{}=_{i[N]}_{j[M]}\|v_{i}^{k}-u_{j} \|_{2}^{2}+_{j[M]}_{i[N]}\|v_{i}^{k}-u_{j} \|_{2}^{2}\] (9)

As-rigid-as-possible Term reflects the deviation of estimated local surface deformations from rigid transformations. We follow [20; 27] and define it as:

\[E_{}=_{h[H]}_{l(h)}(\|d_{h,l}() \|_{2}^{2}+\|(R(_{h})-R(_{l} )\|_{2}^{2})\] (10)\[d_{h,l}()=d_{h,l}(,)=R(_{h})(g_{l}-g_{ h})+_{k}+g_{k}-(g_{l}+_{l}).\] (11)

Here, \(g R^{H 3}\) are the original positions of the nodes in the deformation graph \(\), and \((h)\) is the 1-ring neighborhood of the \(h-\)th deformation node. \(R()\) is Rodrigues' rotation formula that computes a rotation matrix from an axis-angle representation and \(\) is the weight of the smooth rotation regularization term.

**Total cost function:** The total cost function \(E_{}\) combines the above terms with the weighting factors \(_{cd},_{corr}\), and \(_{arap}\) to balance them:

\[E_{}=_{}E_{}+_{}E_{ }+_{}E_{}\] (12)

Now we are ready to describe our algorithm for minimizing \(E_{}\), which is shown in Alg. 1.

``` Input: Source mesh \(=\{,\}\) and target point cloud \(\);Trained point feature extractor F Output:\(^{*}\) converging to a local minimum of \(E_{}\); Deformed source model \(\{^{*},\}\); Correspondence \(_{}^{*},_{}^{*}\) between \(\) and \(\).
1 Initialize deformation graph \(\) and \(^{(0)}\) with identity transformations; \(F_{}=()\);k = 0;
2whileTruedo
3 Update source vertex \(^{(k)}\) by Eqn.(7);
4if\(k\%100==0\) and Flag == Stage-Ithen
5\(F_{}^{(k)}=(^{(k)})\); \(_{}^{(k)}=(F_{}^{(k)},F_{ })\) ; \(_{}^{(k)}=(F_{},F_{}^{(k)})\);
6if\(k\%100==0\) and Flag == Stage-IIthen
7\(_{}^{(k)}=(^{(k)},)\) ; \(_{}^{(k)}=(,^{(k)})\);
8 Compute the set of filtered correspondences \(^{k}\) ;
9\(^{(k+1)}= E_{}\)by Eqn.(12)
10if converged and Flag == Stage-Ithen Flag = Stage-II;
11if converged and Flag == Stage-IIthenreturn\(_{}^{*}\);\(_{}^{*}\); \(^{*}\);
12 k = k + 1; ```

**Algorithm 1**Shape registration pipeline.

## 4 Experiments

**Datasets:** We evaluate our method and several state-of-the-art techniques for estimating correspondences between deformable shapes on an array of benchmarks as follows: **FAUST_r:** The remeshed version of FAUST dataset , which consists of 100 human shapes (10 individuals performing the same 10 actions). We split the first 80 as training shapes and the rest as testing shapes; **SCAPE_r:** The remeshed version of SCAPE dataset , which consists 71 human shapes (same individual in varying poses). We split the first 51 as training shapes and the rest as testing shapes; **SHREC19_r:** The remeshed version of SHREC19 dataset , which consists of 44 shapes of different identities and poses. We use it solely in test, and follow the test pair list provided by ; **SHREC07-H:** A subset of SHREC07 dataset , which consists of 20 heterogeneous human shapes of the varying number of vertices. We use it solely in test, and use the accompanied sparse landmark annotations to quantify all the pairwise maps among them; **DT4D-H:** A dataset proposed in , which consists of 10 categories of heterogeneous humanoid shapes. We use it solely in testing, and evaluating the inter-class maps split in ; **TOPKIDS:** This is a challenging dataset  consisting of 26 shapes of a kid in different poses, which manifest significant topological perturbations in meshes.

**Baselines:** We compare our method with an array of competitive baselines, including axiomatic shape registration methods: Smooth Shells , NDP , AMM ; learning-based registration methods: 3D-CODED , Deep Shells , TransMatch , SyNoRiM ; deep functional maps frameworks: SURFMNet , WSupFMNet , GeomFMaps , DiffFMaps , NIE , ConsistFMaps , SSMSM . According to input requirements, we put those relying on pure mesh input on the top, and the rest, suitable for point clouds, in the bottom of both tables.

**Train/Test Cases:** Throughout this section, we consider a highly challenging scenario: for each learning-based method, we train two models respectively with FAUST_r and SCAPE_r dataset, and then we run tests in a range of test cases including FAUST_r, SCAPE_r, SHREC19_r, SHREC07-H, DT4D-H and TOPKIDS. The test pairs of each case have been described above. In the following, \(A/B\) means we train on dataset \(A\) and test on dataset \(B\).

**Datasets Alignment:** There exist extrinsically aligned versions for all the involved datasets but SHREC07-H. We equally feed in aligned datasets to all the baselines when available. On the other hand, the original version of SHREC07-H manifests significant variability of orientations. For the sake of fairness and simplicity, we apply our orientation regressor to it and provide baselines for our automatically aligned data. Note that, all the aligned datasets, as well as the synthetic dataset on which we train our orientation regressor, roughly share the same canonical orientation, which is defined by the SMPL  model. Finally, we always apply automatic alignment before inputting shapes into our pipeline, whatever the original orientation they are.

**Choice of Source Shape:** As mentioned at the beginning of Sec. 3, we compute correspondences between two raw input point clouds by associating them via a common source mesh \(\). In Tab. 1 and Tab. 2, we indicate our choice of source mesh by Ours-_name_, where _name_ indicates the origin of the source mesh. For simplicity, we fix the source mesh from each dataset and visualize them in the appendix. On the other hand, when implementing axiomatic shape registration methods, we only consider deforming the same template we pick from FAUST_r (resp. SCAPE_r) to every test point cloud in the test set of FAUST_r (resp. SCAPE_r), and establish correspondence by map composition, in the same manner as ours.

**Metric:** Though we primarily focus on matching point clouds, we adopt the commonly used geodesic error normalized by the square root of the total area of the mesh, to evaluate all methods, either for mesh or point cloud.

**Hyper-Parameters:** We remark that all the hyper-parameters are fixed for _all_ experiments in this section. In particular, we settle them by performing a grid search with respect to the weights used in the final optimization to seek for the combination that leads to the the best registration results (quantitatively in terms of Chamfer distance and qualitatively by visual inspection) on a few training shapes. We provide more detailed discussion and ablation of the choice of hyper-parameters in the appendix.

### Experimental Results

**Near-isometric Benchmarks:** As shown in Fig. 1, in the presence of large deformation between the template and the target, NDP and AMM fail completely while our method delivers high-quality deformation. Moreover, as illustrated in Table 1, our method achieves the best performance in 5 out of 6 test cases. Remarkably, in the two most challenging tasks, FAUST_r/SHREC19_r and FAUST_r/SHREC19_r, our method indeed outperforms _all_ of the baselines, including the state-of-the-art methods that take meshes as input. Regarding point-based methods, SSMSM  performs well in the standard case and outperforms ours in FASUT_r/FAUST_r, but generalizes poorly to unseen shapes. Another important observation is that our method manifests robustness with respect to the choice of template shapes. In fact, the above observations remain true no matter which template we select.

**Non-isometric Benchmarks:** We stress test our method on challenging non-isometric datasets including SHREC07-H and DT4D-H. We emphasize that these test shapes are unseen during training.

1) SHREC07-H contains 20 heterogeneous human shapes, whose number of vertices ranges from \(3000\) to \(15000\). Moreover, there exists some topological noise (_e.g._, the hands of the rightmost shape in Fig. 2 is attached to the thigh in mesh representation). As shown in Fig. 2, SSMSM  barely delivers reasonable results, which might be due to the sensitivity of graph Laplacian construction on point clouds. Topological noise, on the other hand, degrades mesh-based methods like Deep Shells . Meanwhile, as shown in Tab. 2, our method achieves a performance improvement of 

[MISSING_PAGE_FAIL:9]

### Ablation Study

We report ablation studies in Tab. 4, in which we verify the effectiveness of each core design formulated in Sec. 3. Throughout this part, we train on SCAPE_r and test on SHREC07-H. In the registration stage, we use the SCAPE_r template as the source mesh and deform it to each point cloud from SHREC07-H. It is evident that each ablated module contributes to the final performance. In particular, both stages of registration play an equally important role in our framework.

Finally, to validate the superiority of our registration scheme, we report in Tab. 5 the average errors of the initial maps computed by our point-based DFM, and that of output maps of Ours, NDP , AMM , which are all based on the former. It is evident that, across three different test sets, our method consistently improves the initial maps, while NDP and AMM can even lead to deteriorated maps than the initial input.

## 5 Conclusion and Limitation

In this paper, we propose a novel learning-based shape registration framework without correspondence supervision. Our framework incorporates learning-based shape matching and optimization-based shape registration. Based on the former, our framework can perform registration between shapes undergoing significant intrinsic deformations; On the other hand, thanks to the latter, our method exhibit superior generalizability over the learning-based competitors. Apart from several designs tailored for our intuitive pipeline, we also introduce a data-driven solution to facilitate the burden of extrinsically aligning non-rigid points. We verify our framework through a series of challenging tests, in which it shows superior performance but also remarkable robustness.

**Limitation & Future Work** We identify two main limitations of our method: 1) Our optimization procedure involves iteratively updating correspondences between the intermediate point clouds and the target one, leaving sufficient room for improvement for efficiency; 2) Our pipeline is designed for full shapes, while it is applicable to partial targets, the registration quality is sub-optimal. In the future, we also plan to incorporate more existing techniques (_e.g._, various regularization terms) from shape registration to further enhance the overall performance.