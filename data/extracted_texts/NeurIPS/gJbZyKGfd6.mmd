# HyperLogic: Enhancing Diversity and Accuracy in Rule Learning with HyperNets

Yang Yang1, Wendi Ren1, Shuang Li1

1School of Data Science, The Chinese University of Hong Kong (Shenzhen)

{yangyang8, wendiren}@link.cuhk.edu.cn, lishuang@cuhk.edu.cn

Corresponding author

###### Abstract

Exploring the integration of if-then logic rules within neural network architectures presents an intriguing area. This integration seamlessly transforms the rule learning task into neural network training using backpropagation and stochastic gradient descent. From a well-trained sparse and shallow neural network, one can interpret each layer and neuron through the language of logic rules, and a global explanatory rule set can be directly extracted. However, ensuring interpretability may impose constraints on the flexibility, depth, and width of neural networks. In this paper, we propose HyperLogic: a flexible approach leveraging hypernetworks to generate weights of the main network. HyperLogic can be combined with existing differentiable rule learning methods to generate diverse rule sets, each capable of capturing heterogeneous patterns in data. This provides a simple yet effective method to increase model flexibility and preserve interpretability. We theoretically analyze the benefits of the HyperLogic by examining the approximation error and generalization capabilities under two types of regularization terms: sparsity and diversity regularization. Experiments on real data demonstrate that our method can learn more diverse, accurate, and concise rules. Our code is publicly available at https://github.com/YangYang-624/HyperLogic.

## 1 Introduction

Despite the significant impact of deep learning on society, its lack of interpretability limits its use in critical areas that demand high transparency. For instance, in high-risk domains such as healthcare, finance, and law, the decision-making process of models needs to be fully open and explainable to users and relevant regulatory authorities to gain necessary trust and legitimacy [1; 2; 3]. Compared to the "black box" models, which may perform well but are uninterpretable, people prefer intrinsically interpretable model for decision support [4; 5], such as a set of concise IF-THEN rules.

Traditional rule learning methods, which are based on statistical or heuristic approaches, have been extensively explored but often struggle to simultaneously achieve two key objectives: 1) simplicity and accuracy in rules, and 2) noise tolerance and scalability in data handling [6; 7; 8; 9; 10]. These methods typically rely on search-based techniques, which can be limited when dealing with complex and noisy data. In contrast, deep learning, which focuses on representation learning through embedding, is robust to noise and effectively manages large datasets. This has led to the exploration of differentiable rule learning , which leverages the high performance of deep learning while ensuring interpretability through explicit rule formulation

Differentiable rule learning primarily includes two types of methods. The first approach outputs rules directly through the network, leveraging powerful and diverse neural models to enhance handling of complex data patterns [12; 13; 14]. The second approach is to extract rules from network weights [15; 16; 17], which promotes rapid training and efficient data management while enabling the use of predefined structures to integrate expert priors .

We focus on the second approach, aiming to extract rules like "IF \(a b c\) THEN \(y\) is True" from network weights, where \(a,b,c\) are predefined predicates. Although integrating if-then logic rules within neural network architectures offers clear advantages, their performance is often hindered by the restrictive network structures required for interpretability. These structures tend to be overly simplistic and not scalable, limiting their ability to capture complex data patterns and making them prone to only capturing partial or local patterns in the data. This raises a critical question: How can we modify these models to better harness the full potential of neural networks without compromising their interpretability?

In this work, we introduce **HyperLogic**, a novel framework that integrates hypernetworks with a main rule-learning network (as illustrated in Fig. 1, where an example of a main rule-learning network is shown on the right). Hypernetworks are a type of neural network that generate weights for a main rule-learning network. In our framework, the hypernetwork takes random samples from a high-dimensional Gaussian distribution as input and outputs weights for different parts of the main network. These weights can be utilized in two ways: either directly as the weights for the main network throughout the training process (meaning the main network itself has no parameters), or by retaining trainable weights in the main network and combining them with the hypernetwork-generated weights through weighted fusion. In both scenarios, this approach yields an interpretable set of rules derived from the comprehensive weights.

HyperLogic can be seen as a mixture of expert model with an infinite number of experts, providing a simple yet effective way to enhance model flexibility and adaptability. We analyze the benefits of HyperLogic by examining its approximation error and generalization capabilities under two types of regularization: sparsity and diversity regularization. Our findings demonstrate that HyperLogic acts as a universal approximation estimator in the Barron space  and proves its generalization ability across various regularization methods. These theoretical benefits are further supported by our empirical experiments.

Additionally, hypernetworks enable the generation of multiple candidate rule sets in a single training session without significantly increasing computational overhead. This is in stark contrast to traditional methods, which typically learn only one set of rules at a time. Consequently, HyperLogic greatly enhances the efficiency and flexibility of the rule-learning process.

We summarize our contributions as follows:

1. We introduce HyperLogic, a pioneering framework that integrates hypernetworks into differentiable rule learning, significantly enhancing the rule-learning landscape.

2. We theoretically justify the performance of HyperLogic and provide insights into its effectiveness. Specifically, we examine the approximation error and generalization capabilities under two types of regularization: sparsity and diversity.

3. We validate HyperLogic through extensive experiments on multiple datasets, demonstrating that it enables the learning of multiple diverse rule sets and yields more concise and accurate rules.

## 2 Related Work

Learning Rules from Network WeightsMany methods for extracting rules from model weights are not based on neural networks; instead, they primarily focus on interpreting the weights of smaller,

Figure 1: The framework of HyperLogic: Hypernetwork generates \(\) for the main network, which is a rule-learning network. An example of a main rule-learning network is shown on the right, from which rules can be extracted based on the learned network weights.

simpler models to discover rules [20; 7]. Recently, extensive methods have emerged that attempt to extract rules using neural network models. These approaches often involve data preprocessing techniques to prepare the data before training  or utilize post-hoc methods for rule extraction after model training [22; 23; 24], which can often lead to a loss of accuracy.

A more promising alternative allows for the direct interpretation of neural network weights as precise rules by integrating rule extraction directly during training. This leads to a more seamless and effective learning process. For example, methods such as [25; 26; 27] utilize low-dimensional embeddings to represent atomic conditions and rules, treating rule learning as a differentiable discrete combinatorial optimization problem encoded by a feedforward neural network. Specifically, FinRule  explores higher-order interactions between atomic conditions, which aligns somewhat with our approach of employing hypernetworks. However, it lacks a detailed analysis of the specific roles of these higher-order interactions and cannot learn a rich set of candidate rules as our method does. Additionally, these approaches often impose constraints on rule templates, such as fixing the rule length and the number of rules.

Another common class of methods employs modified simple feedforward neural networks, such as DR-net  and others [28; 29; 30]. These methods simulate logical operations by altering activation functions and implementing mechanisms that ensure differentiability and support backpropagation. While they overcome the limitations of rigid rule templates, their model structures tend to be relatively simple. Furthermore, the training process often involves freezing the weights of one component while adjusting another, which restricts the model's ability to fully optimize performance.

Our HyperLogic is a unified framework that can be integrated with various neural network weight generators, enabling easy adaptation to different main rule learning networks. Currently, our main network draws inspiration from DR-net , but it can be replaced with other architectures based on task requirements. Unlike recent Bayesian approaches, which often require multiple hyperparameters to model uncertainty in network weights, HyperLogic simplifies the process by needing fewer hyperparameters while maintaining scalability. This allows for efficient training and adaptability across various tasks without the added complexity of managing uncertainty. Additionally, our approach can generate multiple sets of rule sets in a single training session, a capability not available in other methods. For further comparisons, including classic rule-based algorithms, please refer to Appendix A.

HypernetworkHypernetworks, or hypernets, are neural networks that generate weights for main networks . Benefiting from over-parameterization and strategic design, these networks enhance training flexibility and adaptability, improve information sharing, and accelerate training processes. While widely used in many areas like continual learning [32; 33], transfer learning , uncertainty quantification [35; 36], natural language processing  and computer vision , their potential in rule learning remains largely untapped. Our HyperLogic framework can bridge this gap. Specifically, our hypernetwork takes inspirations from HyperGAN  and similarly we add a loss term to encourage the diversity of the generated network weights.

Unlike typical applications in other domains that focus on enhancing parameter efficiency and training speed, our approach addresses the unique challenges of adding model flexibility while preserving interpretability. Our main goal is to expand the parameter space to produce more diverse, concise and accurate rule sets.

## 3 HyperLogic

HyperLogic is a versatile framework designed to enhance various existing neural rule-learning methods. The concept of hypernetworks can be applied to different types of main networks, provided they focus on learning a set of interpretable weights in a differentiable manner. Importantly, HyperLogic imposes no additional restrictions on data formats or rule languages; it simply builds upon the capabilities of the chosen main network.

### Main Network: Rule-Learning Network

Our main network is currently based on DR-Net , which features a simple architecture and is designed for binary classification tasks. We chose this architecture for its simplicity, which aids in our proofs and explanations. However, we recognize its limitations, so we can also explore other more flexible neural approaches as the primary network to overcome restrictions related to data formats and rule languages. This is further discussed in Appendix B.

The main network is a two-layer neural network as shown in Fig. 1 (right part). Due to its interpretability, one can directly extract the if-then rules from the trained neural networks. The input layer of the main network is fed with a \(D\)-dimensional binary data \(x=[x_{d}]\), each element \(x_{d}\{1,-1\}\). Here \(x_{d}\) indicates the grounded predicate, where 1 indicates True and -1 means false. Note that common input types may include binary, categorical, or numerical features, all of which are discretized and binarized to form our binary input features. The hidden layer has \(K\) neurons, where \(K\) determines the total number of rules and serves as a hyperparameter. The first layer is referred to as the Rule Layer, and the output layer as the OR layer.

**Rule Layer**: Each neuron in the hidden layer is denoted as \(o_{k}\{0,1\}\). The output represents whether a rule is satisfied. Each neuron is calculated as:

\[o_{k}=\{_{d=1}^{D}w_{d,k}x_{d}-_{d=1}^{D}|w_{d,k}|=0 \},k=1,,K\] (1)

where \(\{\}\) denotes the indicator function. Note that the indicator function is one if and only if all inputs match the sign of the corresponding weights: all positive weights should have the inputs of 1, and all negative weights should have the inputs of -1, and zero weights mean that the corresponding inputs are excluded from the rule.

Note that the indicator function is non-differentiable, which will make the gradient hard to compute. Here, we will instead use a differentiable smooth function to approximate the indicator function (this will also ease the theoretical analyses). For example, we can use \(h(u)=(-}{})\), \(>0\), to approximate \(\{u=0\}\), where \(\) is the tunable temperature and controls the approximation error.

**OR Layer**: The second layer operation is defined as

\[f(x)=_{k=1}^{K}u_{k}o_{k}\] (2)

where we assume that the rules contribute to the final prediction in a weighted additive form to reflect the OR composition, where \(u_{k}\) denotes the weight assigned to the \(k\)-th rule.

### Hypernetwork: Generate Network Weights

Define the network weights for the previous model as \(=(w,u)\), where \(w R^{D K}\), and \(u R^{K}\). Instead of learning only one set of \(\), we will learn the distribution of \(\), denoted as \(\). Specifically, we introduce a generative model as the hypernetwork to produce samples of \(\), i.e.,

\[=G(), p(),  R^{(D+1)K}.\] (3)

Here, \(\) is drawn from some simple base distribution such as Gaussian distribution. More details about the hypernetwork structure can be seen in Appendix C. Note that, in this way, our model parameters have been changed to \(\), which is defined as the distribution of \(\), and the proposed Hyperlogic model is

\[f_{}(x)=_{}[_{k=1}^{K}u_{k}h(_{d=1}^{D}w_{d,k}x_{d}-_{d=1}^{D}|w_{d,k}|)].\] (4)

In practice, we can use the Monte Carlo method to estimate the above expectation by randomly drawing \(M\) samples from \(\), denoted as \(^{1},,^{M}\), and we define

\[f_{M}(x)=_{m=1}^{M}[_{k=1}^{K}u_{k}^{m}h(_{d =1}^{D}w_{d,k}^{m}x_{d}-_{d=1}^{D}|w_{d,k}^{m}|)].\] (5)

This model can be regarded as a mixture of expert models with finite \(M\) experts. Each expert is a shallow two-layer neural network that encodes at most \(K\) if-then rules.

### Expand to High-Dimensional Data

When working with high-dimensional data (e.g., 5000 dimensions), the number of parameters in the main network increases proportionally with the input dimensions, even if the network structure remains unchanged. This makes training a hypernetwork to generate weights for each module of the main network more challenging. To tackle this issue, we considered two strategies:Combining Original Weights with Hypernetwork-Generated WeightsInstead of allowing the hypernetwork-generated weights (\(W_{}\)) to fully dictate the main network's weights, we combine them with the original weights (\(W_{}\)). The final weights are calculated as follows:

\[W_{}= W_{}+(1-) W_{},\]

where \(\) is a learnable parameter constrained between 0 and 1. This strategy enhances stability without sacrificing the hypernetwork's ability to produce diverse weights. If the hypernetwork is poorly trained and generates inappropriate weights, the model adjusts \(\) toward 0, effectively reverting to the standard main network without hypernetwork influence. We employed this strategy in our subsequent experiments.

Generating Weights for Only Some Modules of the Main NetworkWe test this strategy when the dataset dimension and size are very large in the supplementary experiment. It shows that generating only part of the main network's weights using the hypernetwork still significantly improves results. For more details, please see the supplementary experiments in Appendix B.

### Loss Function

One can learn \(\) by minimizing the loss function \((y,f_{}(x))\), where \(f_{}(x)\) can be approximated by the finite-sample estimator in Eq. (5). Our loss contains two parts. One is the task-related loss function, denoted as \(_{task}(y,f_{}(x))\). Suppose the problem is a binary classification problem, one can use the binary cross-entropy loss (BCE), where we first map \(f_{}(x)\) to a probability value between 0 and 1 using a link function such as sigmoid and the loss is defined as the negative log-likelihood of a sample belong to a class. Here, the task-related loss measures the prediction accuracy.

The second part of the loss is the regularization loss, denoted as \(_{reg}\), which is introduced to encourage the diversity of the generated \(\) and model sparsity (rule simplicity for each expert), i.e.,

\[_{reg}=_{1}D_{}(||_{0})+_{2}_{} [|u|].\] (6)

For the first regularization term, we introduce a prior distribution \(_{0}\) with a high entropy, and we minimize the relative entropy or KL divergence of the \(\) and \(_{0}\). Minimizing the relative entropy encourages the diversity of the generated \(\). For the second regularization term, we are considering the \(_{1}\) sparsity norm for the second OR layer's weights, where we hope that for each expert, the discovered number of rules is as compact as possible. In our paper, \(_{reg}\) represents the loss incurred by the hypernetwork, as illustrated in Fig. 1.

## 4 Theoretical Analysis

We will employ theoretical analysis to demonstrate that while the main network (i.e., a two-layer shallow neural network) has low capacity, incorporating the hypernet idea significantly enhances the model's expressive power. Specifically, we will establish that the proposed HyperLogic model serves as a universal approximator in the Barron space , which will be defined later. For simplicity, but without loss of generality, we consider the case where the hypernetwork fully generates the weights and the main network itself has no parameters. Additionally, we will present the generalization error under the above two types of regularization.

**Reparametrization:** To ease the proof, let's first rewrite Eq. (5) as

\[f_{M}(x)=_{m=1}^{M}[_{k=1}^{K}u_{k}^{m}h(w_{k}^{m }x)]\] (7)

by reparametrization. To achieve this, we first use the split variable trick by defining \(w^{+}=\{w,0\}\) and \(w^{-}=-\{w,0\}\), and reparametrize \(w=w^{+}-w^{-}\)and \(|w|=w^{+}+w^{-}\). In this way, we can get rid of the absolute value and have

\[_{d=1}^{D}w_{d,k}x_{d}-_{d=1}^{D}|w_{d,k}|=_{d=1}^{D}w_{d,k}^{+}(x _{d}-1)+_{d=1}^{D}w_{d,k}^{-}(-x_{d}-1).\] (8)

Therefore, we can simply reparametrize \(w_{k}\), where \(w_{k} 0\), as a concatenation of the vector \([w_{d,k}^{+}]_{d=1,,D}\) and \([w_{d,k}^{}]_{d=1,,D}\). We construct the new input data \(x\) by making a copy of the original data and modifying each copy given Eq. (8). That is, for one copy, we subtract it by 1, and for another copy, we flip the sign and subtract it by 1. Then, we concatenate the two copies of data.

Given such a reparametrization, we get a simple form as Eq. (7). In the following analysis, we will still assume that \(w_{k} R^{D}\) and \(x R^{D}\), which doesn't affect the generality.

**Preparation for the Theoretical Analysis:** Our analysis below is based on the following observations. Given the generated random variable \(((w_{1},u_{1}),,(w_{K},u_{K}))^{(D+1)K}\), we have denoted their joint distribution as \(\). Let us further denote the marginal distribution of \((w_{k},u_{k})\) as \(_{k}\), \(k=1,,K\), respectively. Define a random variable \((,)^{D+1}\), which draws a sample from \(_{k}\) with (equal) probability \(1/K\), \(k=1,,K\), and then scale the \(u\)-component by \(K\). Denote the resulting mixture distribution as \(\). Then it follows from the linearity of expectation that

\[f_{}(x) =_{((w_{1},u_{1}),,(w_{K},u_{K}))}[ _{k=1}^{K}u_{k}h(w_{k}^{}x)]\] \[=_{((w_{1},u_{1}),,(w_{K},u_{K}))}[ _{k=1}^{K}_{k}h(w_{k}^{}x)]= _{(,)}[h( {w}^{}x)].\] (9)

We define \(_{}(x):=_{(,) }[h(^{}x)]\) and we have shown that \(f_{}(x)=_{}(x)\) as stated above.

The motivation for introducing \(_{}(x)\) is to facilitate the analysis of approximation error and generalization error. There exist theoretical results for a two-layer neural network of the form \(g_{M}(x)=_{m=1}^{M}u^{m}h(w^{m}x)\), where \(h()\) belongs to certain classes of smooth activation functions, and \((w^{m},u^{m})\), \(m=1,,M\), are \(M\) independent samples drawn from a fixed distribution. In contrast, our proposed HyperLogic model involves randomly drawing samples \(((w_{1},u_{1}),,(w_{K},u_{K}))\) from \(\), each with \(K\) components. To align this with the existing theoretical framework, we perform a transformation as shown in Eq. (9). This involves converting the process of drawing \(M\) samples, each with \(K\) components, into drawing \(MK\) samples, each with a single component. This reformulation maintains the same expectation results, allowing us to leverage existing theoretical results to analyze HyperLogic. Note that the conversion mentioned is purely for theoretical proof purposes and is not implemented in the actual algorithm.

### Approximation Error of Finite Experts

Using the connection as shown in Eq. (9), we can directly leverage the approximation error results for a single hidden layer neural network. Let's first define the Barron space, which provides a set of functions for which neural networks can achieve good approximation properties.

**Definition 1** (Barron Space ).: A function \(f:^{D}\) belongs to the Barron space \(\) if it can be represented as:

\[f(x)=_{^{D}}uh(w^{}x+b )d(u,w,b)\]

where \(h\) is an activation function, \(\) is a probability measure on \(^{D}\), and the following Barron norm is finite:

\[\|f\|_{}=\{_{^{D} }|u|\|(w,b)\|d(u,w,b):f(x)=_{^{D} }uh(w^{}x+b)d(u,w,b)\}.\]

Note that the representation of \(f\) in the form \(f(x)= u(w^{}x+b)d(u,w,b)\) may not be unique. The Barron norm seeks the representation that minimizes the integral of \(|u|\|(w,b)\|\). The introduction of the Barron norm provides a quantitative measure of the "complexity" of a function in the context of neural networks. Functions with a smaller Barron norm are considered simpler and are easier to approximate with neural networks. Next, let's provide the approximation error analysis for our HyperLogic model (the proof can be found in Appendix D):

**Theorem 1**.: _For any function \(f\) in the Barron space, there exist \(M\) experts \(((w_{1}^{m},u_{1}^{m})

### Generalization Error: Entropic Regularization and Sparse Regularization

Let's derive the generalization error bounds for the HyperLogic model under entropic regularization (the first term of Eq. (6)) and sparse regularization (the second term of Eq. (6)). The key steps involve calculating the Rademacher complexity of the model class and then using this to bound the generalization error. The proof can be found in Appendix E. Let's give the results here.

**Theorem 2**.: _For the function class \(_{}:=\{f_{}():D_{}(\|_{0}) B _{}\}\), we have_

\[_{}[(f)]-(f) 2 }}{n}}+C}.\] (10)

_Similarly, for the function class \(_{1}:=\{f_{}():_{}[_ {k=1}^{K}|u_{k}|] B_{1}\}\), we have_

\[_{}[(f)]-(f) 64B_{1}+C }.\]

_Here, \(_{}[(f)]\) is the expected loss over data distribution, \((f)\) is the empirical loss, \(n\) is the number of samples, \(C\) is a constant dependent on the loss function, and \(\) is the confidence level._

From the results, we see that the relative entropy regularization effectively balances fitting the training data and adhering to the prior distribution with high entropy. Increasing the sample size or decreasing the KL bound enhances the model's generalization ability, ensuring good performance on unseen data. Similar conclusions can be arrived for the sparse regularization.

## 5 Experiment

In this section, we report experimental results to answer the following questions:

* **RQ1:** How does the performance of the optimal rule set selected by HyperLogic compare to the rule sets obtained by other methods?
* **RQ2:** How rich are the rule sets generated by HyperLogic, and how are their accuracy and diversity affected by parameters?
* **RQ3:** Can we further leverage the advantages of HyperLogic through ensemble learning to enhance performance?

### Experiment Setup

**Implementation Details:** During training, for each data batch, we randomly generate \(M_{1}\) samples of network weights to approximate the expectation (as shown in Eq. (5), here we compute \(f_{M_{1}}(x)\) as an approximation in the training stage). Increasing \(M_{1}\) enhances the stability of hypernetwork training but raises computational costs. In our experiments, \(M_{1}\) is set to 5 or 10. After training, we generate \(M_{2}\) sets of weights from the hypernetwork, resulting in \(M_{2}\) rule sets. In other words, in the inference stage, we use \(f_{M_{2}}(x)\) instead. While \(M_{1}\) is relatively small, \(M_{2}\) can be large (e.g., 5000). We then select the rule set with the highest training accuracy as the optimal set, though other criteria, such as minimal loss or custom evaluation metrics balancing accuracy and complexity, can also be used.

For HyperLogic, We use Adam as the optimizer, and the learning rate is \(1 10^{-4}\), with weight decay is \(1 10^{-4}\). The number of training epochs is 10000. In the experiments for selecting the optimal rules for comparison, we set hyperparameter \(M_{1}=5\), \(M_{2}=5000\), \(_{1}=0.01\), and \(_{2}=0.1\) (\(_{1}\) and \(_{2}\) are related to the hypernetwork loss or regularization loss, as defined in Eq. (6)). In the following experiments that analyze the influence of hyperparameter, we adjusted only the corresponding hyperparameter while keeping others unchanged.

**Datasets:** We selected four publicly available binary classification datasets: MAGIC gamma telescope (magic), adult census (adult), FICO HELOC (heloc), and home price prediction (house). In all datasets, preprocessing was performed to encode categorical and numerical attributes as binary variables, which can be found in . We compared our model HyperLogic with other state-of-the-art rule learning methods: DR-Net , CG , BRS , and RIPPER . Since CG, BRS, and RIPPER cannot learn negative conditions, we additionally appended negative conditions for these models.

### Performance Comparison

In the performance comparison section, we sampled \(M_{2}=5000\) times from HyperLogic, selecting the rule set that performed best on the training set as the optimal rule set, and compared it with other methods. Table 1 presents the comparison of the accuracy of the optimal rule sets selected byour method and those generated by other methods. Our method further improves upon DR-Net and outperforms other methods across all four datasets.

It is important to note that the rule set that performs best on the training set does not strictly guarantee the best performance on the test set, as shown in Fig. 2. However, this selection method is sufficiently simple, and experiments have shown that it can achieve good performance.

In addition to rule accuracy, we also considered two metrics to measure the compactness of the rules: model complexity and rule complexity. Model complexity is defined as the sum of the number of rules and the total number of conditions in the rule set; rule complexity is the average number of conditions in each rule of the model. Fig. 3 shows that our method reduces both model complexity and rule complexity compared to DR-Net, indicating that we have not only improved the accuracy of the rules but also made them more concise, demonstrating the effectiveness of our framework.

### Rule Analysis

In this section, we primarily considered the effects of three parameters, \(M_{1}\), \(_{1}\), and \(M_{2}\), on the learned rules. Among these, \(M_{2}\) primarily affects the selection of the final optimal rule set by controlling the number of candidate rule sets sampled from the hypernetwork after training phase, while \(M_{1}\) and \(_{1}\) directly influence the training of the hypernetwork.

For \(M_{2}\), we considered the values 10, 100, 1000, 2000, 5000, and 10000 to examine its impact on the accuracy, model complexity, and rule complexity of the generated optimal rules, as shown in Fig.

    &  \\   & magic & adult & house & heloc \\  HyperLogic & **84.90**\(\) 0.73 & **83.11**\(\) 0.55 & **85.22**\(\) 0.62 & **71.03**\(\) 1.07 \\ DR-Net & 83.69 \(\) 0.55 & 82.95 \(\) 0.45 & 85.05 \(\) 0.51 & 70.07 \(\) 0.83 \\ CG\({}^{*}\) & 83.68 \(\) 0.87 & 82.67 \(\) 0.48 & 83.90 \(\) 0.18 & 68.65 \(\) 3.48 \\ BRS\({}^{*}\) & 81.44 \(\) 0.61 & 79.35 \(\) 1.78 & 83.04 \(\) 0.11 & 69.42 \(\) 3.72 \\ RIPPER\({}^{*}\) & 82.22 \(\) 0.51 & 81.67 \(\) 1.05 & 82.47 \(\) 1.84 & 69.67 \(\) 2.09 \\   

Table 1: Test accuracy based on a nested 5-fold cross-validation (%, mean \(\) standard error). Results corresponding to methods marked with * are directly sourced from .

Figure 4: Analysis of the impact of \(M_{2}\) on all datasets

Figure 3: Model complexity and rule complexity comparison

Figure 2: Train and test accuracies for sampled rule sets across four datasets

[MISSING_PAGE_FAIL:9]

The impact of \(_{1}\) on rule diversity and test accuracy is shown in Fig. 6. It can be seen that increasing \(_{1}\) significantly enhances the diversity of the rule sets, but excessive emphasis on rule diversity may affect the accuracy of the rules.

### Ensemble Learning

Since the hypernetwork can generate a diverse and rich set of rule sets, a natural idea is to use ensemble learning to achieve better classification performance. We use the simple averaging voting method for ensemble learning. We select the top \(L\) rule sets based on their accuracy on the training set and report their accuracy on the test set. The values of \(L\) are 1, 5, 10, 30, 50, 100, and 200. As shown in Fig. 7, the test accuracy initially increases with the increase of \(L\), then slightly decreases.

This may because the top single rule set is already highly effective, leaving little room for improvement. When \(L\) is too large, less effective rule sets decrease the ensemble's overall performance. Additionally, our current strategy focuses on balancing diversity and accuracy of single rule sets. Adjusting the strategy specifically for ensemble learning could yield better results.

## 6 Conclusion and Limitations

In this paper, we proposed HyperLogic, a novel framework that enhances the field of differentiable rule learning through the integration of hypernetworks. We also provided a theoretical foundation for HyperLogic's performance, explaining its effectiveness. This includes an analysis of approximation error and generalization capabilities under sparsity and diversity regularization. What's more, we conducted extensive experiments on multiple datasets, demonstrating that HyperLogic accelerates the training process while producing more concise and accurate rules.

Despite these advancements, HyperLogic introduces additional hyperparameters and requires further exploration of ensemble learning within this framework. Future research will focus on alternative training strategies, more stable weight combination methods, and applying HyperLogic to a broader range of datasets and tasks to enhance its generality and practicality.

## 7 Broader Impacts

The development and utilization of interpretable logic rules through HyperLogic have significant positive societal impacts, particularly in high-risk domains such as healthcare, finance, and legal systems. By generating multiple candidate rule sets, HyperLogic provides more flexible and comprehensive insights, enhancing transparency and trust in decision-making processes. This is crucial for ensuring safety and regulatory compliance. However, it is important to note that while our method provides richer rule sets and aids experts in understanding data patterns, these rules should complement rather than replace expert judgment. Relying solely on automated rules without expert oversight in critical areas could pose significant risks. Thus, our approach emphasizes the collaborative role of machine learning models and human experts to mitigate potential negative impacts.

Figure 6: Analysis of the impact of \(_{1}\) on magic dataset

Figure 7: Test accuracy using top \(L\) rule sets in ensemble learning.