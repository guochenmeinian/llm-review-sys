# Marco Celotto

## An information-theoretic quantification of the content of communication between brain regionsUniversity Medical Center Hamburg-Eppendorf

Istituto Italiano di Tecnologia

University of Bologna

marco.celotto@iit.it

**Jan Bim**

Datamole,

Istituto Italiano di Tecnologia

Prague

**Alejandro Tlaie**

Istituto Italiano di Tecnologia

**Vito De Feo**

University of Essex

**Alessandro Toso**

University Medical Center

Hamburg-Eppendorf

**Stefan M. Lemke**

University of North Carolina

**Daniel Chicharro**

City, University of London

**Hamed Nili**

University Medical Center

Hamburg-Eppendorf

**Malte Bieler**

University College Kristiania

**Tobias H. Donner**

University Medical Center

Hamburg-Eppendorf

**Ileana L. Hanganu-Opatz**

University Medical Center

Hamburg-Eppendorf

**Andrea Brovelli**

Aix Marseille Universite

CNRS

**Stefano Panzeri**

University Medical Center Hamburg-Eppendorf

Istituto Italiano di Tecnologia

s.panzeri@uke.deIntroduction

Cognitive functions, such as perception and action, emerge from the processing and routing of information across brain regions [10; 48; 56; 57; 41]. Methods to study within-brain communication [11; 12; 51] are often based on the Wiener-Granger causality principle, which identifies propagation of information between simultaneously recorded brain regions as the ability to predict the current activity of a putative receiving region from the past activity of a putative sending region, discounting the self-prediction from the past activity of the receiving region [21; 61]. While early measures implementing this principle, such as Granger causality , capture only linear interactions, successive information theoretic measures (the closely-related Directed Information  and Transfer Entropy ) are capable of capturing both linear and nonlinear time-lagged interactions between brain regions [6; 7; 58]. Using such measures has advanced our understanding of brain communication [7; 9; 12; 31; 54; 55; 59; 44]; however, they are designed to capture only the overall information propagated across regions, and are insensitive to the content of information flow. Assessing the content of information flow, not only its presence, would be invaluable to understand how complex brain functions, involving distributed processing and flow of different types of information, arise.

Here, we leverage recent progress in Partial Information Decomposition (PID; [62; 32]) to develop a new non-negative measure (Feature-specific Information Transfer; FIT) that quantifies the directed flow of information about a specific feature of interest between neural populations (Fig. 1A). The PID decomposes the total information that a set of source variables encodes about a specific target variable into components representing shared (redundant) encoding between the variables, unique encoding by some of the variables, or synergistic encoding in the combination of different variables. FIT isolates features-specific information flowing from one region to another by identifying the part of the feature information encoded in the current activity of the receiving region that is shared (redundant) with information present in the past activity of the sending region (because a piece of transmitted information is first found in the sender and then in the receiver) and that is new and unique with respect to the information encoded in the past activity of the receiver (because information already encoded would not have come from the sender).

We first mathematically derive a definition of FIT based on PID. We then use it to demonstrate, on simulated data, that it is specifically sensitive to the flow of information about specific features, correctly discarding feature-unrelated transmission. We then demonstrate that FIT is able to track the feature-specific content and direction of information flow using three different types of simultaneous multi-region brain recordings (electroencephalography - EEG, magnetoencephalography - MEG, and spiking activity). We also address how introducing appropriate null hypotheses and defining conditioned versions of FIT can deal with potential confounding factors, such as the time-lagged encoding of information in two regions without actual communication between them.

## 2 Defining and Computing Feature-specific Information Transfer (FIT)

We consider two time-series of neural activity \(X\) and \(Y\) simultaneously recorded from two brain regions over several experimental trials. \(X\) and \(Y\) might carry information about a feature \(S\) varying from trial to trial, e.g. a feature of a sensory stimulus or a certain action. The activity measured in each region, \(X\) and \(Y\), may be any type of brain signal, e.g. the spiking activity of single or multiple neurons, or the aggregate activity of neural populations, such as EEG or MEG. We call \(Y_{pres}\) the activity of \(Y\) at the present time point \(t\), and \(X_{past}\) and \(Y_{past}\) the past activity of \(X\) and \(Y\) respectively (Fig. 1). Established information theoretic measures such as TE  use the Wiener-Granger principle to quantify the overall information propagated from a putative sender \(X\) to a putative receiver \(Y\) as the mutual information \(I\) between the receiver's present neural activity \(Y_{pres}\) and the sender's past activity \(X_{past}\), conditioned on the receiver's past activity \(Y_{past}\) (Fig. 1):

\[TE(X Y)=I(X_{past};Y_{pres}|Y_{past})\] (1)

(see Supplementary Material, SM1.1 for how TE depends on probabilities of past and present activity). TE captures the overall information propagated across regions but lacks the ability to isolate information flow about specific external variables. To overcome this limitation, here we define FIT, which quantifies the flow of information specifically about a feature \(S\) from a putative sending area \(X\) to a putative receiving area \(Y\) (Fig. 1A). We define FIT using the PID . PID decomposes the joint mutual information \(I(S;)\), that a set of \(N\) source variables \(=(X_{1},X_{2},...,X_{N})\) carriesabout a target variable \(S\), into non-negative components called information atoms (see SM1.2). For \(N=2\), PID breaks down the joint mutual information \(I(S;X_{1},X_{2})\) into four atoms: the Shared (or redundant) Information \(SI(S:X_{1},X_{2})\) that both \(X_{1}\) and \(X_{2}\) encode about \(S\); the two pieces of Unique Information about \(S\), \(UI(S:X_{1} X_{2})\) and \(UI(S:X_{2} X_{1})\), provided by one source variable but not by the other ; and the Complementary (synergistic) information about \(S\), \(CI(S:X_{1},X_{2})\), encoded in the combination of \(X_{1}\) and \(X_{2}\). Several measures have been proposed to quantify information atoms [62; 5; 18; 30]. Here we use the measure \(I_{min}\) originally defined in , which guarantees non-negative values for information atoms for any \(N\) (see SM1.2).

Using \(I_{min}\), the Shared Information that \(X_{1}\) and \(X_{2}\) carry about \(S\) is defined as follows:

\[SI(S:X_{1},X_{2})=_{s S}p(s)_{X_{i}\{X_{1},X_{2}\}}I(S=s;X_{i})\] (2)

where \(I(S=s;X_{i})\) is the specific information that source \(X_{i}\) carries about a specific outcome of the target variable \(s S\), and is defined as:

\[I(S=s;X_{i})=_{x_{i} X_{i}}p(x_{i}|s))}{p(s)} \] (3)

Intuitively, the shared information computed as in eq. 2 quantifies redundancy as the similarity between \(X_{1}\) and \(X_{2}\) in discriminating individual values of the feature \(S\). In the general case of \(N\) source variables, information atoms are hierarchically ordered in a lattice structure, and \(I_{min}\) can be used to quantify any atom in the decomposition (including the Unique and Complementary information atoms introduced above for the case \(N=2\); see SM1.2).

We wanted FIT to measure the directed flow of information about \(S\) between \(X\) and \(Y\), rather than the overall propagation of information measured by TE (Fig. 1A). We thus isolated the information about a feature \(S\) in the past of the sender \(X\) that \(Y\) receives at time \(t\). Because of the Wiener-Granger causality principle, such information should not have been present in the past activity of the receiver \(Y\). Therefore, we performed the PID in the space of four variables \(S\), \(X_{past}\), \(Y_{past}\), and \(Y_{pres}\) to compute information atoms that combine Shared, Unique and Complementary Information carried by three sources about one target . One natural candidate atom to measure FIT is the information about \(S\) that \(X_{past}\) shares with \(Y_{pres}\) and is unique with respect to \(Y_{past}\): \(SUI(S:X_{past},Y_{pres} Y_{past})\) (Fig. 1B; Fig. S1B). This atom is defined as the difference between the shared information that the two source variables \(X_{past}\) and \(Y_{pres}\) carry about \(S\), and the shared information that the three source variables \(X_{past}\), \(Y_{pres}\) and \(Y_{past}\) carry about \(S\). Redundancy

Figure 1: Sketch of FIT and TE. (A) TE is the established information-theoretic measure to quantify the overall information propagated between two simultaneously recorded brain regions \(X\) (sender) and \(Y\) (receiver). FIT measures the information flowing from \(X\) to \(Y\) about the stimulus feature S. (B) TE and FIT incorporate content-unspecific and content-specific versions of the Wiener-Granger causality principle. TE is the mutual information between the past activity of \(X\) and the present activity of \(Y\) conditioned on the past of \(Y\). FIT is the feature information in the present of \(Y\) shared with the past information of \(X\) and unique with respect to the past information of \(Y\).

can only decrease when adding more sources. Hence by removing the information that is also redundant with \(Y_{past}\), \(SUI(S:X_{past},Y_{pres} Y_{past})\) quantifies a non-negative component of shared information between \(X_{past}\) and \(Y_{pres}\) about \(S\) that is unique with respect to \(Y_{past}\). Importantly, using unique information to remove the feature information in \(Y_{past}\) is more conservative than conditioning on \(Y_{past}\) as in TE . \(SUI(S:X_{past},Y_{pres} Y_{past})\) intuitively captures what we are interested in, and satisfies two desirable mathematical properties: it is upper bounded by the feature information encoded in the past of \(X\) (\(I(S;X_{past})\)) and in the present of \(Y\) (\(I(S;Y_{pres})\)). This is because the PID defines redundancy between source variables as sub-components of the information about the target carried by each of the sources (see SM1.3.1). However, the information atom \(SUI(S:X_{past},Y_{pres} Y_{past})\) has two undesirable properties. The first is that its value can exceed the total amount of information propagated from \(X\) to \(Y\) (TE). This can happen since the unique information in the PID decomposition is a component of the conditional mutual information about the target. However, the target in \(SUI(S:X_{past},Y_{pres} Y_{past})\) is the feature \(S\), which means that this atom is not constrained to be smaller than the TE, which is independent of \(S\) (see eq. 1 and SM1.3.4). This property is undesirable, because the overall information propagation must be an upper bound to the information transmitted about a specific feature. The second is that by construction (see SM1.3.1) this atom depends on \(X_{past},Y_{pres},S\) only through the pairwise marginal distributions \(P(X_{past},S)\) and \(P(Y_{pres},S)\), but not through the marginal distribution \(P(X_{past},Y_{pres})\), which implies that this atom by itself cannot identify confounding scenarios where both sender and receiver encode feature information at different times with no transmission taking place (see SM1.3.1).

To address these limitations, following  we considered the alternative PID taking \(S\), \(Y_{past}\), and \(X_{past}\) as source variables and \(Y_{pres}\) as a target. In this second PID (Fig. S1B), the atom that intuitively relates to FIT is \(SUI(Y_{pres}:X_{past},S Y_{past})\), the information about \(Y_{pres}\) that \(X_{past}\) shares with \(S\) that is unique with respect to \(Y_{past}\). While being intuitively similar to \(SUI(S:X_{past},Y_{pres} Y_{past})\), \(SUI(Y_{pres}:X_{past},S Y_{past})\) has \(Y_{pres}\) as target variable and hence is upper bounded by TE (but not by \(I(S;X_{past})\)) and depends on the pairwise marginal distribution \(P(X_{past},Y_{pres})\) (see SM1.3.2). Thus, this second atom has useful properties that complement those of the first atom. Importantly, Shannon information quantities impose constraints that relate PID atoms across decompositions with different targets. We  demonstrated that, for PID with \(N=2\) sources, these constraints reveal the existence of finer information components shared between similar atoms of different decompositions. Here, we extended this approach (see SM1.3.3) to \(N=3\) sources and demonstrated that the second atom is the only one in the second PID that has a pairwise algebraic relationship with the first atom, indicating that these atoms share a common, finer information component. Therefore we defined FIT by selecting this finer common component by taking the minimum between these two atoms:

\[FIT=[SUI(S:X_{past},Y_{pres} Y_{past}),SUI(Y_{pres}:X_{past},S  Y_{past})]\] (4)

With this definition, FIT is upper bounded by \(I(S;X_{past})\), by \(I(S;Y_{pres})\) and by \(TE(X Y)\). That FIT satisfies such bounds is essential to interpret it as transmitted information. If FIT could be larger than the feature information encoded by sender \(X\) or receiver \(Y\), or than the total information transmitted (\(TE(X Y)\)), then FIT could not be interpreted as feature information transmitted from \(X\) to \(Y\). Additionally, FIT depends on the joint distribution \(P(S,X_{past},Y_{pres})\) through all the pairwise marginals \(P(S,X_{past})\), \(P(S,Y_{pres})\), and \(P(X_{past},Y_{pres})\), implying that it can rule out, using appropriate permutation tests, false-communication scenarios in which \(X\) and \(Y\) encode the stimulus independently with a temporal lag, without any within-trial transmission (see SM1.3.4).

Note that the definition of FIT holds when defining present and/or past activity as multidimensional variables, potentially spanning several time points. However, use of multidimensional neural responses requires significantly more data for accurate computation of information. For this reason, following , in all computations of TE and FIT we computed the present of \(Y\) at a single time point \(t\) and the past of \(X\) and of \(Y\) at individual time points lagged by a delay \(\): \(X_{past}=X_{t-}\) and \(Y_{past}=Y_{t-}\). Note also that in all calculations of FIT and TE, we estimated probabilities from empirical occurrences after discretizing both features and neural activities. SM1.6 reports details of the procedure and Table S1 the number of bins used for each analysis. Simulations of accuracy of these estimates as function of the data size are reported in SM2.5 and Fig. S6.

## 3 Validation of FIT on simulated data

To test the ability of FIT to measure feature-specific information flow between brain regions, we performed simulations in scenarios of feature-related and feature-unrelated information transfer.

We performed (Fig. 2A-B) a simulation (details in SM2.1) in which the encoded and transmitted stimulus feature \(S\) was a stimulus-intensity integer value (1 to 4). The activity of the sender \(X\) was a two-dimensional variable with one stimulus-feature-informative \(X_{stim}\) and one stimulus-uninformative component \(X_{noise}\). The stimulus-feature-informative dimension had temporally-localized stimulus-dependent activity from 200 to 250ms and had multiplicative Gaussian noise (similar results were found with additive noise, see SM2.1 and Fig. S3). The stimulus-unrelated component was, at any time point, a zero-mean Gaussian noise. The activity of the receiver \(Y\) was the weighted sum of \(X_{stim}\) and \(X_{noise}\) with a delay \(\), plus Gaussian noise. The delay \(\) was chosen randomly in each simulation repetition in the range 40-60ms. Here and in all simulations, we averaged information values across simulation repetitions we determined their significance via non-parametric permutation tests . For TE, we permuted \(X\) across all trials to test for the presence of significant within-trial transmission between \(X\) and \(Y\). For FIT, we conducted two different permutation tests: one for the presence of feature information in \(X\) and \(Y\) (shuffling \(S\) across trials), and another for the contribution of within-trial correlations between \(X\) and \(Y\) to the transmission of \(S\) (shuffling \(X\) across trials at fixed stimulus). We set the threshold for FIT significance as the 99th percentile of the element-wise maximum between the two permuted distributions (see SM1.7).

We investigated how FIT and TE from \(X\) to \(Y\) depended on the amount of stimulus-feature-related transmission (increased by increasing \(w_{stim}\)) and of -unrelated transmission (increased by increasing \(w_{noise}\)). We report values at the first time point in which information in \(Y\) was received from \(X\), but similar results hold for later time points. Both FIT and TE increased when increasing \(w_{stim}\) (Fig. 2A). However, TE increased with \(w_{noise}\) (Fig. 2A), as expected from a measure that captures the overall information propagation. In contrast, FIT decreased when increasing \(w_{noise}\), indicating that FIT specifically captures the flow of information about the considered feature.

We then investigated how well TE and FIT temporally localize the stimulus-feature-related information transmitted from \(X\) to \(Y\) (Fig. 2B). We simulated a case in which stimulus-feature-related information was transmitted from \(X\) to \(Y\) only in a specific window (\(ms\)) and computed FIT and TE at each time point (see SM2.1 for details). FIT was significant only in the time window in which \(Y\) received the stimulus information from \(X\). In contrast, TE was significant at any time point, reflecting that noise was transmitted from \(X\) to \(Y\) throughout the whole simulation time.

Figure 2: Testing FIT on simulated data. (A) FIT and TE as function of stimulus-feature-related (\(w_{stim}\)) and -unrelated (\(w_{noise}\)) transmission strength. * indicate significant values (\(p<0.01\), permutation test) for the considered parameter set. (B) Dynamics of FIT and TE in a simulation with time-localized stimulus-feature-information transmission. Red area shows the window of stimulus-feature-related information transfer. Results plot mean (lines) and SEM (shaded area) across 50 simulations (2000 trials each). (C) Different neural encoding functions used for the simulations in panels D-E. \(\): separation of responses to different features; \(\): Gaussian noise SD. (D) Sketch of simultaneous stimulus feature information profiles. Different types of information content are color-coded. (E) FIT in the \(X Y\) (cyan) and \(Y X\) (grey) directions as a function of SNR \(/\) (plot in log scale). Results plot mean (lines) and SEM (shaded area) across 100 simulations (2000 trials each). Yellow dots in B, E show points with significant FIT (p ¡ 0.01, permutation test).

Importantly, FIT can detect feature-specific information flow even when information is encoded in the sender and receiver with an overlapping timecourse (see SM2.2 for details). To illustrate this, we simulated the activity of two regions \(X\) and \(Y\) encoding an integer stimulus feature \(S\) with the same time course of stimulus-feature information (Fig. 2D), but with feature specific transmission taking place only from \(X\) to \(Y\). Because FIT could correctly detect that the format of information representation of \(S\) in the present of \(Y\) was equal to that of the past of \(X\) but different to that of the past of \(Y\) (Fig. 2D), it could correctly detect that feature information flows from \(X\) to \(Y\) (Fig. 2E).

We also performed simulations to investigate whether the non-parametric permutation test described above can correctly rule out as non-significant feature-specific transmission the scenario in which \(X\) and \(Y\) independently encode \(S\) without actual communication occurring between them. We simulated a scenario in which feature information was encoded with a temporal lag in \(X\) and \(Y\), with no transmission from \(X\) to \(Y\). We found that the resulting values were always non-significant (see SM2.6.1 and Fig. S7C) when tested against a surrogate null-hypothesis distribution (pairing \(X\) and \(Y\) in randomly permuted trials with the same feature) that destroy the within-trial communication between \(X\) and \(Y\) without changing the feature information encoded in \(X\) and \(Y\) (see SM1.7). Importantly, this null hypothesis also ruled out false communication scenarios where the measured FIT and TE were only due to the presence of instantaneous mixing of sources (see SM 2.7).

Finally, we addressed how to remove the confounding effect of transmission of feature information to \(Y\) not from \(X\) but from a third region \(Z\). In Granger causality or TE analyses, this is addressed conditioning the measures on \(Z\)[1; 37]. In an analogous way, we developed a conditioned version of FIT, called cFIT (see SM1.4), which measures the feature information transmitted from \(X\) to \(Y\) that is unique with respect to the past activity of a third region \(Z\). We tested its performance in simulations in which both \(X\) and \(Z\) transmitted feature information to \(Y\) and found that cFIT reliably estimated the unique contribution of \(X\) in transmitting feature information to \(Y\), beyond what was transmitted by \(Z\) (see SM2.6.2 and Fig. S7D).

## 4 Analysis of real neural data

We assessed how well FIT detects direction and specificity of information transfer in real neural data.

### Flow of stimulus and choice information across the human visual system

We analyzed a previously published dataset (, see also SM3.1 for details) of source-level MEG data recorded while human participants performed a visual decision-making task. At the beginning of each trial, a reference stimulus was presented (contrast 50%), followed by a test stimulus that consisted of a sequence of 10 visual samples with variable contrasts (Fig. 3A). After the test stimulus sequence, participants reported their choice of whether the average contrast of the samples was greater or smaller than the reference contrast. The previous study on these data () analyzed the encoding of stimulus and choice signals in individual areas, but did not study information transfer. We focused on gamma-band activity (defined as the instantaneous power of the 40-75Hz frequency band), because it is the most prominent band for visual contrast information encoding [24; 45; 17] and information propagation [7; 3] in the visual system. Previous work has demonstrated that gamma-band transmission is stronger in the feedforward (from lower to higher in the visual cortical hierarchy) than in the feedback (from higher to lower in the visual cortical hierarchy) direction [55; 3; 36], suggesting that gamma is a privileged frequency channel for transmitting feedforward information. However, these previous studies did not determine the content of the information being transmitted.

To address this question, we quantified FIT in a network of three visual cortical areas (Fig. 3B) that we selected because they encoded high amounts of stimulus information and because they were sufficiently far apart (\( 2.8\)cm) to minimize leakage in source reconstruction (see SM3.1.1 Fig. S9) [63; 23]. The areas, listed in order of position, from lower to higher, in the cortical hierarchy were: primary visual cortex (V1), area V3A, and area LO3. Because participants made errors (behavioral performance was 75% correct), in each trial the stimulus presented could differ from the participant's choice. We thus assessed the content of the information flow by computing FIT about either the sensory stimulus (\(FIT_{S}\); using as feature the mean contrast across all 10 visual samples) or the reported choice (\(FIT_{C}\)), in each instant of time in the \([-100,500]\)ms peri-stimulus time window (because stimulus information was higher in the first 500ms post-stimulus, see SM3.1.4 and Fig. S9) and across a range of putative inter-area delays \(\). In Fig. 3C we show the resulting time-delay information maps for the example pair of regions V1 and V3A. A cluster-permutation analysis  revealed significant feedforward stimulus-specific information transmission from V1 to V3A (but no significant feedback from V3A to V1) localized 200-400ms after the stimulus onset, with an inter-area communication delay between 65 and 250ms (see SM3.1.4 and Fig. S9).

We compared properties of overall information propagation (computed with TE) and feature-specific information flow (computed with FIT) across all pairs of areas within the considered visual cortical network. To determine the prevalent content of information flow in the network, we compared \(FIT_{S}\) and \(FIT_{C}\) transmitted in the feedforward and in the feedback directions (Fig. 3D). Gamma-band transmitted more information about the stimulus than about choice (i.e. \(FIT_{S}\)\( FIT_{C}\)) in both the feedforward (\(p<10^{-3}\) two-tailed paired t-test) and in the feedback (\(p<0.01\) two-tailed paired t-test) direction, with a larger difference for the feedforward direction. This result is supported by simulations where we show that, in presence of multiple simultaneously transmitted features, FIT ranks correctly the features about which most information is transmitted (see SM2.3 and Fig. S4). Thus, we focused on stimulus-specific information flow in the following FIT analyses. We then studied the leading direction of information flow. Both the total amount of information propagation (TE) and the stimulus-specific information flow (\(FIT_{S}\)) were larger in the feedforward than in the feedback direction (Fig. 3E), but with a larger effect for \(FIT_{S}\) (\(p<10^{-6}\) two-tailed paired t-test) compared to TE (\(p<0.05\) two-tailed paired t-test). Together, these results show that gamma-band activity in the visual system carries principally information about the stimulus (rather than choice) and propagates it more feedforward than feedback.

We next assessed the behavioral relevance of the feedforward stimulus information transmitted by the gamma band. A previous study showed that the overall (feature-unspecific) strength of feedforward gamma band information propagation negatively correlates with reaction times, indicating that stronger feedforward gamma activity propagation favors faster decisions . However, no study has addressed whether stimulus information transmitted forward in the gamma band promotes decision accuracy. We addressed this question by comparing how \(FIT_{S}\) varied between trials when

Figure 3: Information flow across the human visual hierarchy with MEG. (A) Sketch of task. (B) Cortical surface map of the location of the three considered visual regions. (C) Temporal profiles of stimulus information and time-delay stimulus FIT maps for an example regions pair (V1, V3A). Top to bottom: stimulus information in V1; time-delay FIT map in the feedforward (V1 \(\) V3A) direction; time-delay FIT map in the feedback (V3A \(\) V1) direction; stimulus information in V3A. (D) Comparison between FIT about stimulus (\(FIT_{S}\)) and FIT about choice (\(FIT_{C}\)) in the visual network in the feedforward (left) and feedback (right) directions. (E) Comparison between feedforward and feedback transmission in the network for TE (left) and stimulus FIT (right). (F) Same as E but for feedforward transmission on correct vs error trials. In all panels, lines and image plots show averages and errorbars SEM across participants, experimental sessions and regions pairs (in case of FIT and TE) or regions (in case of mutual information). *: p<0.05, **: p<0.01, ***: p<0.001. Information-theoretic quantities were computed from the gamma band ([40-75]Hz) power of source-level MEG, first computed separately for the left and right hemisphere and then averaged.

participants made a correct or incorrect choice (Fig. 3F). We matched the number of correct and error trials to avoid data size confounds . \(FIT_{S}\) in the feedforward direction was significantly lower in error than in correct trials (Fig. 3F, right; \(p=0.001\) two-tailed paired t-test), while TE did not vary between correct and error trials (Fig. 3F, left; \(p=0.38\) two-tailed paired t-test). Feedback information transmission (both in terms of overall information propagation, TE, and stimulus specific information flow, \(FIT_{S}\)), did not vary between correct and incorrect trials. This indicates that the feedforward flow of stimulus information, rather than the overall information propagation, is key for forming correct choices based on sensory evidence.

These results provide the new discovery that the gamma band transmits feedforward stimulus information of behavioral relevance, and highlight the power of FIT in revealing the content and direction of information flow between brain areas.

### Eye-specific interhemispheric information flow during face detection

We next tested the ability of FIT to detect feature-specific information flow between brain hemispheres. We analyzed a published EEG dataset recorded from human participants detecting the presence of either a face or a random texture from an image covered by a bubble mask randomly generated in each trial (; see SM3.2.1 for details). Previous analysis of these data  showed that eye visibility in the image (defined as the proportion of image pixels in the eye region visible through the mask) is the most relevant image feature for successful face discrimination. It then showed that eye-specific information appears first at \(\)120ms post-image presentation in the Occipito-Temporal (OT) region of the hemisphere contra-lateral with respect to the position of the eye, and then appears \(\)20-40ms later in the ipsi-lateral OT region (Fig. 4A). However, this study did not determine if the eye information in the ipsi-later hemisphere is received from the contra-lateral hemisphere. To address this issue, we computed FIT transmission of eye-specific information between the Left OT (LOT) and Right OT (ROT) regions (using the electrodes within these regions that had most information as in , see SM3.2.2). Left Eye (LE) FIT from the contra- to the ipsi-lateral OT (ROT to LOT) peaked between 150 to 190ms after image onset with transfer delays of 20-80ms (Fig. 4B). Right eye (RE) FIT from the contra- to the ipsi-lateral OT (LOT to ROT) peaked with similar times and delays (Fig. 4C). Both contra-to-ipsi-lateral LE and RE had statistically significant FIT peaks in the time-delay maps (cluster-permutation analysis, p < 0.01; see SM3.2.2 and Fig. S10). Thus, FIT determined the communication window for contra-lateral flow of eye-specific information with high precision.

To gain further insight about the directionality and feature-specificity of the information flow across hemispheres, we compared FIT and TE across transfer directions and/or eye-specific visibility

Figure 4: Inter-hemispheric eye-specific information flow during face detection using human EEG. (A) Schematic of the putative information flow. LOT (ROT) denote Left (Right) occipito-temporal regions. LE (RE) denote the Left (Right) Eye visibility feature. (B) Information (lines) carried by the EEG in each region, and FIT (image plot) about LE contra-lateral transfer. (C) Same as B for RE. (D) Contra- to ipsi-lateral vs ipsi- to contra-lateral transfers for TE and FIT for both LE and RE. Dots and images plot averages and errorbars plot SEM across participants (N=15).

conditions (Fig. 4D, middle and right). Right-to-left LE FIT was significantly larger than left-to-right LE FIT (\(p<0.001\) two-tailed paired t-test) or right-to-left RE FIT (\(p<0.01\) two-tailed paired t-test). Left-to-right RE FIT was significantly larger than right-to-left RE FIT (\(p<0.05\) two-tailed paired t-test) or left-to-right LE FIT (\(p<0.05\) two-tailed paired t-test). In contrast, we found no significant difference between directions for the overall propagated information (TE), Fig. 4D, left). Thus, the use of FIT revealed a temporally localized flow of eye information across hemispheres that was feature-selective (i.e. about mainly the contra-lateral eye) and direction-specific (contra-to-ipsi-lateral), without direction specificity in the overall information propagation (TE) across hemispheres.

Finally, to more tightly localize the origin of eye-specific contra-lateral information flow, we asked whether the contra-lateral OT electrodes selected in our analyses were the sole senders of inter-hemispheric eye-specific information. We used the conditioned version of FIT, cFIT, to compute the amount of transfer of eye information from the contra- to the ipsi-lateral OT after removing the effect of eye-specific information possibly routed through alternative sending locations (see SM3.4). We found (Fig. S12A) that the effect we measured with FIT was robust even when conservatively removing with cFIT the information that could have been routed through other locations.

### Stimulus-specific information flow in a thalamocortical network

We finally used FIT to measure the feature- and direction-specificity of information flow in the thalamocortical somatosensory and visual pathways. We analyzed a published dataset in which multi-unit spiking activity was simultaneously recorded in anaesthetized rats from the primary visual and somatosensory cortices, and from first-order visual and somatosensory thalamic nuclei (, see SM3.3.1 for details), during either unimodal visual, unimodal tactile, or bimodal (visual and tactile) stimulation. This analysis tests FIT on another major type of brain recordings (spiking activity). Moreover, due to the wealth of knowledge about the thalamocortical network [53; 16], we can validate FIT against the highly-credible predictions that information about basic sensory features flows from thalamus to cortex, and that somatosensory and visual pathways primarily transmit tactile and visual information, respectively. Using FIT, we found (see SM3.3.3 and Fig. S11) that sensory information flowed primarily from thalamus to cortex, rather than from cortex to thalamus. We also found that the feedforward somatosensory pathway transmits more information about tactile- than about visually-discriminative features, and that the feedforward visual pathway transmits more information about visually- than tactile-discriminative features. Importantly, TE was similarly strong in both directions, and when considering tactile- or visually-discriminative features. This confirms the power of FIT for uncovering stimulus-specific information transfer, and indicates a partial dissociation between overall information propagation and neural transfer of specific information.

## 5 Comparison with previously published measures

We finally examine how FIT differs from alternative methods for identifying components of the flow of information about specific features. We focus on measures that implement the Wiener-Granger discounting of the information present in the past activity of the sender. Other methods, that do not implement this (and thus just correlate past information of the sender with present information of the receiver), erroneously identify information already encoded in the past activity of the receiver as information transmitted from a sender (see SM4.3).

A possible simple proxy for identifying feature-specific information flow is quantifying how the total amount of transmitted information (TE) is modulated by the feature . For the case of two feature values, this amounts to the difference of TE computed for each individual value. We show in SM4.1, using simulations, that this measure can fail in capturing feature-related information flow even in simple scenarios of feature information transmission. Additionally, when tested on MEG data, it could not assess the directionality of information transmission within brain networks (see SM4.1).

A previous study  defined a measure, Directed Feature Information (DFI), which computes feature-specific information redundant between the present activity of the receiver and the past activity of the sender, conditioned on the past activity of the receiver. However, DFI used a measure of redundancy that conflated the effects of redundancy and synergy (see SM1.5). Because of this, DFI is, both on real and on simulated data, often negative and thus not interpretable as measure of information flow (see SM4.2). In contrast, FIT is non-negative and uses PID to consider only redundant information between sender and receiver, as appropriate to identify transmission of information. Moreover,because DFI discounts only past activity of the sender rather than its feature-specific information, it was less precise, conservative and sensitive in localizing direction and timing of feature-specific information flow (as shown in SM4.2 and Fig. S15 with simulated and real data).

Finally, a study defined feature-specific information using PID in the space of four variables \(S\), \(X_{past}\), \(Y_{past}\), and \(Y_{pres}\). However, this measure was not upper bounded by either feature information encoded in the past of the sending region or the total information flowing between regions.

## 6 Discussion

We developed and validated FIT, an information theoretic measure of the feature-specific information transfer between a sender \(X\) and a receiver \(Y\). FIT combines the PID concepts of redundancy and uniqueness of information  with the Wiener-Granger causality principle  to isolate, within the overall transmitted information (TE), the flow of information specifically related to a feature \(S\).

The strengths and limitations of FIT as a neural data analysis tool stem from those of information theory for studying neural information processing. Information theory has led to major advances to neural coding because of its ability to capture linear and non-linear interactions at all orders making little assumptions [43; 15]. This is important because deviations from linearity and order of interactions vary in often unknown ways between brain areas, stimulus types and recording modalities [13; 28; 20]. Using such a general formalism avoids potentially biasing results with wrong assumptions. However, the price to pay for the fact that information theory includes full probability distributions is that it is data hungry. While our definitions of FIT and cFIT are straightforwardly valid for multivariate analyses including conditioning on the information of multiple regions  (as in cFIT) or obtaining more conservative estimates of information transmission on which information in the receiver \(Y\) is requested to be unique with respect to the information of the sender and receiver at multiple past time points , for data sampling reasons in practice in real data these analyses are confined to conditioning to one region or a single past time point [7; 39; 38]. In future work, we aim to make FIT applicable to analyses of multiple regions or time points coupling it with advanced non-parametric  methods to robustly estimate its multivariate probability distributions.

The generality of our approach lends itself to further developments. Importantly, we defined FIT directly at the level of PID atoms. This means that, although here we implemented FIT using the original definition of redundancy in PID  because it has the advantage of being non-negative for all information atoms, FIT can be easily implemented also using other PID redundancy measures [22; 5; 2; 18; 30] with complementary advantages and disadvantages (see SM1.2).

We individuate two directions for improvement. First, even though the surrogate permutation test we developed to assess FIT significance provided reasonable results on real data and worked work well also with artefacts due to instantaneous mixing of sources (see SM2.7), further research is needed to generate more refined surrogate data generation techniques to rule out more conservatively false feature-specific communication scenarios . Second, how best to select the time of past activity to compute FIT, an issue of significance in Wiener-Granger measures , remains to be determined.

To demonstrate the properties of FIT, we performed numerical simulations in different communication scenarios and compared FIT against TE (Fig. 2). These simulations confirmed that TE effectively detected the overall propagation of information, but it did not detect the flow of feature-specific information. FIT, in contrast, reliably detected feature- and direction-specific information flow with high temporal sensitivity. We confirmed the utility of FIT in applications to neural data. In three brain datasets spanning the range of electrophysiological recordings (spiking activity, MEG and EEG), FIT credibly determined the directionality and feature specificity of information flow. Importantly, in most of these datasets this happened in the absence of variations in the overall information propagation between the same brain regions (measured with TE). The partial dissociation between overall activity flow and feature-specific flow found consistently in simulations and data has important implications. First, it highlights the need of introducing a specific measure of feature information transfer such as FIT, as it resolves question unaddressed by content-unspecific measures. Second, it establishes that measuring feature-specific components of information flow between brain regions is critical to go beyond the measurement of overall neural activity propagation and uncover aspects of cross-area communication relevant for ongoing behavior. Thus, as methods to record from multiple brain regions rapidly advance, FIT is well suited to uncover fundamental principles in how brain regions communicate.

Acknowledgements

This research has received funding from the European Union's Horizon 2020 Framework Programme for Research and Innovation under the Specific Grant Agreement No. 945539 (Human Brain Project SGA3), from the NIH Brain Initiative (grants U19 NS107464, R01 NS109961, R01 NS108410), and from the Simons Foundation (SFARI Human Cognitive and Behavioral Science grant 982347). We thank G. Bondanelli and G.M. Lorenz for useful discussion and feedback on the manuscript.