# Functional Renyi Differential Privacy for

Generative Modeling

 Dihong Jiang1,2, Sun Sun1,3 &Yaoliang Yu1,2

School of Computer Science, University of Waterloo1

Vector Institute2

National Research Council Canada3

{dihong.jiang,sun.sun,yaoliang.yu}@uwaterloo.ca

###### Abstract

Differential privacy (DP) has emerged as a rigorous notion to quantify data privacy. Subsequently, Renyi differential privacy (RDP) has become an alternative to the ordinary DP notion in both theoretical and empirical studies, because of its convenient compositional rules and flexibility. However, most mechanisms with DP (RDP) guarantees are essentially based on randomizing a fixed, finite-dimensional vector output. In this work, following Hall et al.  we further extend RDP to functional outputs, where the output space can be infinite-dimensional, and develop all necessary tools, e.g. (subsampled) Gaussian mechanism, composition, and post-processing rules, to facilitate its practical adoption. As an illustration, we apply functional RDP (f-RDP) to functions in the reproducing kernel Hilbert space (RKHS) to develop a differentially private generative model (DPGM), where training can be interpreted as iteratively releasing loss functions (in an RKHS) with DP guarantees. Empirically, the new training paradigm achieves a significant improvement in privacy-utility trade-off compared to existing alternatives, especially when \(=0.2\). Our code is available at https://github.com/dihjiang/DP-kernel.

## 1 Introduction

Modern machine learning has achieved impressive success thanks to the availability of big data and computing resources. However, there are increasing privacy concerns when training with personal or sensitive data. Differential privacy [DP, 8] has become the de-facto standard technique for releasing statistics of sensitive databases, which is designed to bound the output change of a randomized mechanism \(\) given an incremental input deviation, such that \(\) does not depend too much on any individual point in the dataset. Recently, Mironov  generalizes DP to Renyi differential privacy (RDP) through \(\)-Renyi divergence , which shares many properties with the ordinary DP, yet with tighter and easier composition analysis, thereby attracts more attention in practice.

The popular mechanisms (e.g. Gaussian or Laplace) towards DP or RDP essentially randomize a finite-dimensional vector output with (Gaussian or Laplace) noises. However, if we want to privately release a _function_, vector-based DP mechanisms are not readily amenable, because a function over a real-valued domain is characterized by infinitely many points , which will lead to \(\) bound on the L2/L1-sensitivity if we follow the same sensitivity analysis in Dwork and Roth  for the vector output, and will effectively lead to infinitely large Gaussian/Laplacian noise and is impractical. Moreover, it is unclear how to add noise to an infinite-dimensional output. Examples that require a functional DP mechanism include privately releasing the reward function in reinforcement learning , the kernel function in kernel density estimation and kernel support vector machine (SVM) , and the kernel function in DPGM in this work.

Hall et al.  made the most fundamental contribution to extending DP from vectors to functions. Essentially, the functional Gaussian mechanism is achieved by adding a sample path of Gaussian process to a function, in contrast to adding Gaussian noise to a vector. Evaluating the released DP function at arbitrarily many points (which will form a vector) will retain the same DP guarantee. It is worth mentioning that there are no composition theorems and subsampled Gaussian mechanisms developed for functional DP in Hall et al. , thus restricting its use in deep learning.

Due to the theoretical convenience and practical flexibility of RDP, in this work, we aim to extend RDP to functions, with all necessary tools to facilitate its adoption in deep learning. Furthermore, we demonstrate its value via a particular application in DPGM where the loss function is in an RKHS. Our contributions can be summarized as:

* Theoretically, we develop the functional RDP, which is equipped with many useful tools including (subsampled) Gaussian mechanism, composition, and post-processing theorems. We will show that functional RDP will share many important properties and results with the vector-based variant.
* Empirically, with functional RDP, we propose a novel DPGM training paradigm by privatizing the loss function in an RKHS, rather than truncating the RKHS to a finite-dimensional space and injecting Gaussian noise therein as in existing works. Our method is evaluated and compared across a wide variety of image datasets and DP guarantees, where our method consistently outperforms other baselines by a large margin. Notably, our method indicates better scalability at more stringent DP guarantees (e.g., \(=1\) and \(0.2\)), compared to state-of-the-art (SoTA) baselines.

## 2 Preliminary

Differential privacy quantifies and restricts the output change of a randomized mechanism given an incremental change in the input dataset, such that the privacy of an individual point is protected. The output of a randomized mechanism can be either a vector (Sections 2.1 to 2.3) or a function (Section 2.4). In this section, we recall a few important related works in differential privacy.

### Differential privacy for vectors (v-DP)

**Definition 1** (\((,)\)-DP for vectors, [8; 9]).: _A randomized mechanism \(:\) with domain \(\) and range \(\) satisfies \((,)\)-differential privacy if for any two adjacent inputs \(D,D^{}\) and for any (measurable) subset of outputs \(\) it holds that_

\[[(D)]()[(D^{ })]+,\]

_where adjacent inputs (a.k.a. neighbouring datasets) \(D,D^{}\) only differ in one entry. Particularly, when \(=0\), we say that \(\) is \(\)-DP._

### Renyi differential privacy for vectors (v-RDP)

Mironov  first formalizes Renyi differential privacy (RDP) which extends ordinary DP by using \(\)-Renyi divergence . RDP is shown to provide easier composition properties than the ordinary DP notion, and it can be easily converted to \((,)\)-DP.

**Definition 2** (\((,)\)-RDP for vectors, ).: _A randomised mechanism \(\) is \((,)\)-RDP if for all adjacent inputs \(D,D^{}\), Renyi's \(\)-divergence (of order \(>1\)) between the distributions of \((D)\) and \((D^{})\) satisfies:_

\[_{}((D)\|(D^{})):=_{x q}()^{},\]

_where \(p\) and \(q\) are the density of \((D)\) and \((D^{})\), respectively._

Conveniently, RDP is linearly composable:

**Theorem 1** (Sequential composition of v-RDP, ).: _Let \(f:_{1}\) be \((,_{1})\)-RDP, \(g:_{1}_{2}\) be \((,_{2})\)-RDP, then running \(f,g\) sequentially to obtain \(h:_{1}_{2},h(D):=(f(D),g(f(D),D))\) satisfies \((,_{1}+_{2})\)-RDP._

Similar to the parallel composition theorem for ordinary \(\)-DP as in McSherry , we complement the parallel composition for v-RDP:

**Theorem 2** (Parallel composition of v-RDP).: _If mechanism \(_{i}\) satisfies \((,_{i})\)-RDP for \(i=1,2,,m\), and let \(D_{1},D_{2},,D_{m}\) be the disjoint partitions by executing a deterministic partitioning function \(P\) on \(D\). Releasing \(_{1}(D_{1}),,_{m}(D_{m})\) satisfies \((,_{i\{1,2,,m\}}_{i})\)-RDP._

### Gaussian mechanism for v-DP and v-RDP

Among multiple choices, the Gaussian mechanism is more suitable for the \((,)\)-DP notion (where \(>0\)) and provides additional flexibility (e.g., the sum of Gaussians is still a Gaussian). It is achieved by adding calibrated spherical Gaussian noise to a vector output.

**Proposition 1** (Gaussian mechanism for v-DP and v-RDP, ).: _Given a \(d\)-dimensional function \(f:^{d}\). The Gaussian mechanism is given by:_

\[(D)=f(D)+_{2}f(0,_{d}),\]

_where \(_{2}f=_{D D^{},D,D^{}}\|f(D)-f(D^{ })\|_{2}\). \((D)\) is said to be: (1) \((,)\)-DP if \(/\) for \((0,1)\), or (2) \((,})\)-RDP._

### Differential privacy for functions (f-DP)

Prior DP works mainly focused on the setting when the output of a query is a vector. However, if the output is a _function_, such as the kernel density estimation example in Hall et al.  and the DPGM example in our work (Section 4.3), a few challenges render the direct application of previous DP results on a _functional output_1 intractable: it is unclear (1) how to analyze the sensitivity and (2) how to add Gaussian noise to an infinite-dimensional output. To the best of our knowledge, Hall et al.  are the pioneers in addressing those challenges by starting with defining the \((,)\)-DP for functions:

**Definition 3** (\((,)\)-DP for functions, ).: _Consider a class of functions indexed by database \(D\) over \(T=^{d}\), i.e. \(\{f_{D}:D\}^{T}\). Define cylinder sets2\(C_{S,B}=\{f^{T}:(f(_{1}),,f(_{n}))  B\}\), for all finite subsets \(S=(_{1},,_{n})\) of \(T\) and Borel sets3\(B^{n}\). Then, define \(_{s}=\{C_{S,B}:B(^{n})\}\) and \(_{0}=_{S:|S|<}_{s}\). We say the mechanism \(}\) satisfies \((,)\)-DP over the field of cylinder sets, if for all \(D,D^{}\):_

\[[} A]()[}} A]+, A_{0}.\] (1)

Hall et al.  point out that whenever Eq. (1) holds, for any finite set of points \(_{1},,_{n}\) in \(T\) chosen a-priori, or after the construction of the function, or even adaptively chosen based on the outputs given, releasing the vector \([}(_{1}),,}(_{n})]\) satisfies \((,)\)-DP.

The Gaussian mechanism for f-DP 4 is reached by injecting a sample path of a calibrated Gaussian process5 into the function:

**Proposition 2** (Gaussian mechanism for f-DP, ).: _Let \(G\) be a sample path of a Gaussian process having mean zero and covariance function \(k\). Let \(M\) denote the Gram matrix_

\[M(_{1},,_{n})=k(_{1}, _{1})&&k(_{1},_{n})\\ &&\\ k(_{n},_{1})&&k(_{n},_{n}).\] (2)

_Let \(\{f_{D}:D\}\) be a family of functions indexed by database \(D\). Releasing \(}=f_{D}+/ G\) satisfies \((,)\)-DP whenever_

\[_{D D^{}}_{n<}_{(_{1},,_ {n}) T^{n}}\|M^{-}(_{1},,_{n}) f_{D}(_{1})-f_{D^{}}(_{1})\\ \\ f_{D}(_{n})-f_{D^{}}(_{n})\|_{2} .\] (3)Particularly, Hall et al.  studied how to achieve \((,)\)-DP for functions in an RKHS 6\(\):

**Corollary 1** (Corollary 9 in ).: _For \(\{f_{D}:D\}\), releasing \(}=f_{D}+/ G\) is \((,)\)-DP (with respect to the cylinder \(\)-field) whenever \(_{D,D^{}}\|f_{D}-f_{D^{}}\|_{}\) and when \(G\) is a sample path of a Gaussian process with mean zero and covariance function \(k\) that is given by the reproducing kernel of \(\)._

## 3 Renyi differential privacy for functions (f-RDP)

In this section, we aim to extend the definition of RDP to functional outputs, along with its associated calculus rules to facilitate practical adoption. In particular, we will show that the main results for v-RDP all extend to f-RDP.

### Definition

Consider a class of functions over \(T=^{d}\), i.e. \(\{f_{D}:D\}^{T}\). We can define a functional generalization of the \(\)-Renyi divergence:

**Definition 4** (\((,)\)-RDP for functions).: _Denote the evaluation of function \(}\) on any finite subsets \(S=(_{1},,_{n})\) of \(T\) by \(\{}(_{1}),,}(_{n})\} :=}(S)\). We say \(}\) is \((,)\)-RDP, if for all adjacent inputs \(D,D^{}\), Renyi's \(\)-divergence (of order \(>1\)) between the distributions of \(}(S)\) and \(}}(S)\) satisfies:_

\[_{}}(S)\|}}(S ):=_{x q}( )^{},\] (4)

_where \(p,q\) are the density of \(}(S)\) and \(}}(S)\), respectively._

**Remark 1**.: _Definition 4 essentially claims that the distribution of any finite number of evaluations of function \(}\) and \(}}\) satisfies Definition 2 (v-RDP)._

We have a weaker definition of f-RDP (see Lemma 1 for the _weaker_ definition) also based on cylinder sets as in Definition 3. We also refer interested readers to Appendix F for an alternative unified definition of RDP for both vectors and functions.

### Post-processing theorem

As any data-independent post-processing preserves the DP guarantee for v-RDP (Definition 2), it also preserves DP guarantee for f-RDP with Remark 1. Specifically,

**Theorem 3** (Post-processing theorem of f-RDP).: _If a function \(f_{D}\) is \((,)\)-RDP, so is \(g f_{D}\), where \(g\) is a post-processing mechanism that only depends on a finite number of outputs of \(f_{D}\)._

### Conversion to \((,)\)-Dp

The following conversion is a direct extension of its vector version in Mironov :

**Proposition 3** (f-RDP conversion to f-DP).: _A function \(}\) that is \((,)\)-RDP is \((+,)\)-DP._

### Composition theorems

Similar to Theorem 2, we first derive the parallel composition theorem of RDP for functions:

**Theorem 4** (Parallel composition of f-RDP).: _Given a deterministic partitioning function \(P\), let \(D_{1},D_{2},,D_{m}\) be the disjoint partitions by executing \(P\) on \(D\). If function \(f_{D_{i}}\) satisfies \((,_{i})\)-RDP for \(i=1,2,,m\), releasing \((f_{D_{1}},,f_{D_{m}}):=f_{D}\) satisfies \((,_{i\{1,2,,m\}}_{i})\)-RDP._

Now we move on to the sequential composition theorem of RDP for functions (extension of Theorem 1 to functional mechanisms), which is important and required for composing the total privacy cost when we sample different sample paths from the Gaussian process over training iterations.

First, we note that Theorem 1 implicitly defines \(g\) as a functional mechanism, i.e. \(g:_{2}^{_{1}}\). It means for any \(r_{1}_{1}\), we have \(g_{r_{1}}:=g(r_{1},):_{2}\) is \((,_{2})\)-RDP.

**Theorem 5** (Sequential composition of f-RDP).: _Let \(\{f_{D}:D\}\) and \(\{g_{D}:D\}\) be two families of functions indexed by dataset \(D\), where \(f_{D}_{1}^{T}\) is \((,_{1})\)-RDP and \(g_{D}:_{1}^{T}_{2}^{S}\) is \((,_{2})\)-RDP. Releasing the sequentially composed functional mechanism \(h_{D}=(f_{D},g_{D} f_{D})_{1}^{T}_{2}^{S}= (_{1}_{2})^{T S}\) satisfies \((,_{1}+_{2})\)-RDP._

### Gaussian mechanism

We also need to develop a Gaussian mechanism to retain f-RDP. To make it more convenient, we first rewrite Proposition 1 in a similar form to Proposition 3 in Hall et al.  as:

**Definition 5** (Gaussian mechanism for v-RDP, with non-isotropic Gaussian).: _Let \(M^{d d}\) be a positive definite symmetric matrix, the family of vectors \(\{_{D}:D\}^{d}\) satisfies \(_{D D^{}}\|M^{-}(_{D}-_{D^{ }})\|_{2}\) for all adjacent datasets \(D,D^{}\). The Gaussian mechanism is given by:_

\[_{D}}=_{D}+(0,M).\] (5)

\(_{D}}\) in Eq. (5) satisfies \((,})\)-RDP. Now we define the Gaussian mechanism for f-RDP:

**Proposition 4** (Gaussian mechanism for f-RDP).: _Let \(G\) be a sample path of a Gaussian process having mean zero and covariance function \(k\). Let \(M\) denote the Gram matrix (as defined in Eq. (2)). Let \(\{f_{D}:D\}\) be a family of functions indexed by database \(D\). Releasing \(}=f_{D}+ G\) satisfies \((,})\)-RDP whenever Eq. (3) holds._

Particularly, when the function is in an RKHS \(\), we have the following corollary:

**Corollary 2**.: _For \(\{f_{D}:D\}\), releasing \(}=f_{D}+ G\) is \((,})\)-RDP (with respect to the cylinder \(\)-field) whenever \(_{D,D^{}}\|f_{D}-f_{D^{}}\|_{}\) and when \(G\) is a sample path of a Gaussian process with mean zero and covariance function \(k\) given by the reproducing kernel of \(\)._

### Subsampled Gaussian mechanism (SGM)

Subsampling is a crucial component in existing DP deep learning algorithms (e.g., DP-SGD of ), which incurs a small privacy cost for every sampled batch by querying \(D\), thereby requiring to compose the total privacy loss (measured by \(\)) over training iterations. The same thing could happen for functional mechanisms when we subsample a batch \(S\) from the whole dataset \(D\) to index the function \(f_{S}\).

The current dominant (python-based) DP implementation packages, e.g., Tensorflow privacy and Opacus, apply v-RDP and compute the total \(\) in three main steps: (1) compute the v-RDP guarantee for an SGM, based on a numerical procedure in Mironov et al. ; (2) sequentially compose v-RDP over training iterations; (3) convert v-RDP to v-DP. In previous sections we have already shown that f-RDP shares the same results with v-RDP on steps (2) and (3), now we will show that an SGM for f-RDP can be reduced to v-RDP in Mironov et al. , thus, the numerical procedure in Mironov et al.  (and thereby those DP packages) is amenable to f-RDP in terms of the \(\) accumulation.

We apply the same subsampling strategy as in Mironov et al. . Let \(S\) be a subsampled set from \(D\), where each element of \(S\) is independently drawn from \(D\) with probability \(q\). SGM for f-RDP is given by \(}=f_{S}+ G\), where \(\) and \(G\) are defined in Proposition 4. The reduction is immediate: for any finite set of points \(V=\{_{1},,_{d}\}\) (where \(d<\)), \(f_{S}(V)\) will form a \(d\)-dimensional vector. Let \(g_{S}(V)=M^{-1/2}f_{S}(V)\), we have \(}(V)=g_{S}(V)+(0,_{d})\), where \(g_{S}(V)\) is a \(d\)-dimensional vector and \(}(V)\) is the same SGM as in Mironov et al. . Therefore, f-RDP shares the same guarantee of an SGM with v-RDP. Another intuition is that Mironov et al.  reduce computing the \(\)-Renyi divergence of \(d\)-dimensional Gaussians to 1-dimensional Gaussians, which guides all of their subsequent derivations. When \(d\), we can reach the same reduction from infinite-dimensional Gaussian (Gaussian process) to 1-dimensional Gaussian.

An application in DPGM

To demonstrate the practical value of f-RDP, here we consider a particular example of training a differentially private generative model (DPGM) through Maximum Mean Discrepancy (MMD).

### Background

Assuming a feature map \(:\), where \(\) is an RKHS of some kernel, MMD  is a non-parametric distance measure that compares two distributions \(p,q\) by:

\[_{^{2}}(p,q)=\|_{ p}[( )]-_{ q}[()]\|_{}^ {2},\]

where \(_{ p}[()]\) is also known as the (kernel) mean embedding (KME) of \(p\).

Given a kernel \(k:\), such that7\(k(,)=(),()_{}\), we can play the kernel trick to compute the (squared) MMD in an alternative way:

\[_{^{2}}(p,q)=_{,^{}  p}k(,^{})-2_{ p,  q}k(,)+_{,^ {} q}k(,^{}),\]

which also implicitly lifts the KME into an infinite-dimensional space.

Sriperumbudur et al.  suggest that if \(k\) is a characteristic kernel (e.g., Gaussian kernel), then MMD \(=0\) iff \(p=q\), which makes MMD a practical tool in many applications, such as two-sample test  and generative modeling [e.g., 16, 17].

### Related works

Balog et al.  first proposed a DP database release mechanism via KME, by truncating the infinite-dimensional RKHS to a finite-dimensional feature space through random Fourier features and adding Gaussian noise to the mean of truncated feature embeddings of all data. This idea is further extended to generative modeling by DP-MERF . Specifically, given the samples drawn from two distributions: \(D=\{_{i}\}_{i=1}^{N} p\) (true) and \(W=\{_{j}\}_{j=1}^{M} q\) (generated), empirical MMD with a kernel function \(k\) can be estimated by:

\[_{^{2}}}(p,q)=}_{i=1}^{N} _{p=1}^{N}k(_{i},_{p})-_{i=1}^{N}_{j=1 }^{M}k(_{i},_{j})+}_{j=1}^{M}_{q=1}^ {M}k(_{j},_{q}).\] (6)

DP-MERF approximates the kernel by: \(k(,)=()^{}( )\), where \(()^{d}\) is the random Fourier feature  and \(d\) is the feature dimension. Now the loss becomes:

\[_{^{2}_{eff}}}(p,q)=_{i= 1}^{N}(_{i})-_{j=1}^{M}( _{j})_{2}^{2}=}-_{j=1 }^{M}(_{j})_{2}^{2},\]

where \(}=_{i=1}^{N}(_{i})\) is the empirical KME of \(p\). Calibrated Gaussian noise is added to \(}\) to obtain \(}\) with DP guarantees, which can be viewed as privatized statistics of the whole real dataset. Thereafter, the training objective is to match the KME of generated data with \(}\), without querying the real data any longer. A line of recent follow-up works, e.g., PEARL  and DP-HP , boil down to improving the finite-dimensional truncation and show some further improvement in utility.

Compared to other DPGM approaches via DP-SGD , DP-MERF is appealing in two aspects: (1) training efficiency, since noise is added to the KME of the whole database once and for all, whereas DP-SGD has to clip and perturb the gradient in each training iteration, which leads to significant training time overhead; (2) more scalable to smaller \(\), e.g., \(=1\) or below.

However, we observe that the generation by DP-MERF (and related followup methods) resembles "mean-like" images (e.g. see Figures 1 to 3), which can be explained by their training objective, because matching the KME of all data is likely to lead to _mode collapse_. Moreover, truncating the RKHS into a finite-dimensional space makes it easy to add Gaussian noise, but at the cost of potentially losing the fine ability to distinguish the data distribution from generation (any finite-dimensional RKHS is not characteristic). Therefore, we turn to study the possibility of adding noise in the infinite-dimensional RKHS directly.

### Methodology

We use Gaussian kernel as our kernel function \(k\), i.e., \(k(,)=\{--\|_{2}^{2}}{2^{ 2}}\}\), since it is widely used in related works [13; 19; 31]. Define

\[f_{D}=_{i=1}^{N}(_{i})=_{i=1}^{N}k( _{i},),\]

so we can rewrite Eq. (6) by plugging in \(f_{D}\):

\[_{^{2}}}=_{p=1}^{N}f_{D}( _{p})-_{j=1}^{M}f_{D}(_{j})+} _{j=1}^{M}_{q=1}^{M}k(_{j},_{q}).\]

Privatizing the terms relating to real data \(_{i} D\) (\(i=1,2,,N\)) amounts to privatizing the function \(f_{D}\) by Corollary 2, which leads to our private training objective:

\[_{^{2}}}=_{p=1}^{N} {f_{D}}(_{p})-_{j=1}^{M}}(_{j})+}_{j=1}^{M}_{q=1}^{M}k(_{j},_ {q}),\] (7)

where \(=g_{}()\), i.e., \(\) is generated from standard Gaussian noise \(\) by a generative neural network \(g_{}\). Given the kernel is Gaussian, we can easily bound the sensitivity of \(f_{D}\) in the RKHS norm. Without loss of generality, assume \(D,D^{}\) only differ in the last element, i.e., \(_{N}_{N}^{}\). Then,

\[(f_{D}-f_{D^{}})=_{i=1}^{N}(_{i})-_{i=1}^{N}(_{i}^{})=(_{N} )-(_{N}^{}).\]

Now we play the kernel trick \(k(,)=(),()_{ }\) again:

\[\|f_{D}-f_{D^{}}\|_{}^{2}=}k( _{N},_{N})-2k(_{N},_{N}^{})+k(_ {N}^{},_{N}^{})}:=^{2}.\]

We follow _the batch method_ in Hall et al.  to release function \(}\) in practice, as it naturally fits the batch training manner, which amounts to sampling a path from the Gaussian process specified by any finite collection (batch) of points. Assuming the batch size is \(m\), we concatenate \((,)=\) (of size \(2m\), \(=_{[1:m]},=_{[m+1:2m]}\)), to save an additional privacy cost incurred by an additional sample path in each training iteration. Now we release \(}(_{i})\) and \(}(_{j})\) via \(}()\) as needed in Eq.(7) by:

\[}(_{1})\\ \\ }(_{2m})( f_{D}(_{1})\\ \\ f_{D}(_{2m}),k(_{1}, _{1})&&k(_{1},_{2m})\\ &&\\ k(_{2m},_{1})&&k(_{2m},_{2m}) ).\] (8)

In summary, each training iteration proceeds with (1) subsample a batch \(S\) from \(D\) to index the function \(f_{S}\); (2) perturb \(f_{S}\) by Corollary 2; (3) compute the loss function Eq. (7) by Eq. (8).

Extension to the conditional setting:We follow the approach in DP-MERF to encode labels in the MMD loss. Consider a new kernel \(k^{*}\) as a product of two existing kernels: \(k^{*}(,),(},}) =k_{}(,})k_{}(,})\), where we set \(k_{}\) the same as the unconditional setting (i.e., Gaussian kernel) and \(k_{}\) to be polynomial kernel of order-1, i.e., \(k_{}(,})=^{}}\). Now the function that we want to privately release becomes \(f_{D}^{*}=_{i=1}^{N}k^{*}((_{i},_{i}),( ,))\). The sensitivity of \(f_{D}^{*}\) is the same as \(f_{D}\). Thus, releasing \(f_{D}^{*}\) by _the batch method_ is achieved by replacing \(f_{D},k\) with \(f_{D}^{*},k^{*}\) in Eq. (8).

### Experiments

Since our method is based on making the RKHS features of a (Gaussian) kernel differentially private without truncating the kernel, we term our method **DP-kernel**. In this section, we will evaluate DP-kernel both qualitatively and quantitatively on three image benchmarks, including both grayscale and colorful images. All implementation details are given in Appendix C.

Datasets:We consider widely used image benchmarks in related works, i.e. MNIST , Fashion MNIST , and CelebA . For MNIST and Fashion MNIST, we generate images conditioned on 10 respective labels. For CelebA, we condition on gender. Descriptions and pre-processing of the datasets are given in Appendix B.

Evaluation metrics:For quantitative comparison with baselines, we compute the following two metrics via 60k generated images under the same DP guarantees as baselines:

* Generation fidelity. We mainly use Frechet Inception Distance (FID) , as it is widely compared in related works. However, recent studies suggest that FID is not always consistent with human evaluations (e.g. ), where the authors found that Inception-V3 (the feature extractor used to compute FID, which was proposed in 2015) is not competent enough, and switching to a more recent and powerful feature extractor (e.g. DINOV2 ViT-L/14) seems to overcome this issue. Therefore, we follow Stein et al.  and use their code to compute an additional Frechet Distance, which is denoted by \(_{}\), for our presentation only.
* Generation utility. We train a convolutional neural network (CNN) as the classifier on generated images, then test the classifier on real images, where the performance is measured by the classification accuracy. We take 5 runs and report the average and standard deviation.

Baselines:We compare our method with the following related works: (1) kernel-based methods: DP-MERF , DP-HP , PEARL ; (2) others: DP-CGAN , GS-WGAN , DP-Sinkhorn , G-PATE , DataLens , DPDM . All baselines are developed from v-RDP or v-DP.

Privacy regimes:Note that according to Definition 1, the DP guarantee is weak when \( 10\), because \((10) 2.2 10^{4}\), which is meaningless, because the two probabilities are presumed to be comparable for practical deployment (e.g. \( 1\)). However, a line of recent SoTA DPGMs only generate acceptable images at \(=10\). Instead, we consider three values of \(\), i.e., \(10,1,0.2\), indicating three levels of DP guarantees, where we put comparison under \((10,10^{-5})\)-DP in Appendix D for completeness.

#### 4.4.1 Conditional vs. parallel

The downstream classification task requires access to labels, so we need to consider conditional generative modeling, as introduced at the end of Section 4.3.

Alternatively, we can partition the dataset by labels, train \(K\) (\(K\) is the number of total classes) unconditional sub-models in parallel with DP guarantees, and release the union in the end, which could retain the same level of DP guarantee as the conditional one by parallel composition theorem for f-RDP (Theorem 4). Specifically, we partition the dataset \(D\) into \(K\) subsets by labels, and set the target \(\) (for \(f_{D}\)) the same for all \(f_{D_{K}}\). Thus, releasing \(f_{D_{1}},,f_{D_{K}}\) also satisfies \((,)\)-RDP. We will show both conditional and parallel generation results in the following sections.

#### 4.4.2 Grayscale image sets: MNIST and Fashion MNIST

We first tried our method on MNIST and Fashion MNIST. Qualitatively, while all baselines are able to generate reasonable images under \((10,10^{-5})\)-DP guarantee (see Appendix D), our method indicates more visual improvements for smaller \(\) with more diversity and less artifacts, as shown in Figures 1 and 2. The quantitative comparison is summarized in Table 1. Although DPDM8 is the only related work that is on a par with our method (both variants) when \(=1\), DP-kernel significantly outperforms other baselines when \(=0.2\). Specifically, our method improves the SoTA FID from \(61.9\) to \(26.5\) on MNIST, and from \(78.4\) to \(46.2\) on FMNIST, while SoTA classification accuracy is generally improved for more than \(20\%\) on MNIST and more than \(10\%\) on FMNIST.

The \(_{}\) of our conditional variant on MNIST and FMNIST are \(454.8\) and \(608.9\) when \(=1\), and they are \(410.3\) and \(589.2\) when \(=0.2\).

#### 4.4.3 RGB image sets: CelebA

To test the versatility and scalability of our method, we also evaluate our method on a more complex colorful image dataset, i.e. CelebA. Figure 3 shows that our method generates more diverse face images with identifiable gender attributes compared to baselines, which is quantitatively verified by significant improvement in both FID and Acc in Table 1. Note that DPDM is unconditional on CelebA. Notably, for \(=0.2\), our method improves the SoTA FID from \(264.8\) to \(85.9\), and improves SoTA Acc from \(52.7\) to \(86.5\).

The FD\({}_{}\) of our conditional variant on CelebA are \(1028.2\) when \(=1\) and \(998.9\) when \(=0.2\).

Figure 1: Qualitative comparison under \((1,10^{-5})\)-DP on MNIST and Fashion MNIST

Figure 2: Qualitative comparison under \((0.2,10^{-5})\)-DP on MNIST and Fashion MNIST

## 5 Conclusion

We generalize RDP for vectors to functional mechanisms and develop all building blocks, e.g. (sub-sampled) Gaussian mechanisms, composition theorems, and post-processing theorems, to facilitate its adoption in deep learning frameworks. We show that those main properties or results of v-RDP also hold for f-RDP. Equipped with f-RDP, we propose a novel approach for training a DPGM, by making the loss function in the RKHS private without truncating the RKHS feature map. Experimental results across different datasets and privacy costs indicate that our method (equipped with f-RDP and retaining the full discriminative capability of the kernel) consistently outperforms other kernel-based methods (with v-RDP) as well as non-kernel-based methods by a large margin. We expect our work to bridge the gap between RDP and functional mechanisms and enrich the family of DPGM.

    &  &  &  &  \\   & & FID \(\) & Acc \(\) & FID \(\) & Acc \(\) & FID \(\) & Acc \(\) \\  DP-MERF & 1 & 118.3 & 80.5 & 104.2 & 73.1 & 219.4 & 57.6 \\ GS-WGAN & 1 & 489.8 & 14.3 & 587.3 & 16.6 & 437.3 & 62.9 \\ DP-HP & 1 & - & 74.0 & - & 67.0 & - & - \\ PEARL & 1 & 121.0 & 78.2 & 109.0 & 68.3 & - & - \\ G-PATE & 1 & 153.4 & 58.8 & 214.8 & 58.1 & 293.2 & 70.2 \\ DataLens & 1 & 186.1 & 71.2 & 195.0 & 64.8 & 297.7 & 70.6 \\ DPDM & 1 & 23.4 & 93.4 & **37.8** & 73.6 & \({}^{}\)**71.0** & - \\
**Ours (conditional)** & 1 & 29.5 & 93.4\(\)0.5 & 49.5 & 78.8\(\)0.4 & **81.8** & 86.2\(\)0.9 \\
**Ours (parallel)** & 1 & **21.8** & **95.5\(\)**0.6 & 48.4 & **80.0\(\)**0.5 & 83.8 & **87.0\(\)**0.8 \\  DP-MERF & 0.2 & 119.3 & 75.2 & 151.3 & 67.4 & 264.8 & 52.7 \\ PEARL & 0.2 & 133.0 & 77.6 & 160.0 & 68.0 & - & - \\ G-PATE & 0.2 & - & 22.0 & - & 18.0 & - & - \\ DataLens & 0.2 & - & 23.4 & - & 22.3 & - & - \\ DPDM & 0.2 & 61.9 & 71.9 & 78.4 & 57.0 & - & - \\
**Ours (conditional)** & 0.2 & **26.5** & 91.3\(\)0.8 & **46.2** & 78.4\(\)0.7 & **85.9** & 84.3\(\)1.1 \\
**Ours (parallel)** & 0.2 & 37.3 & **93.7\(\)**0.7 & 65.4 & **79.2\(\)**0.5 & 95.8 & **86.5\(\)**1.2 \\   

Table 1: Quantitative comparison on MNIST, Fashion MNIST (FMNIST) and CelebA. Acc denotes classification accuracy, which is shown in %. \(\) and \(\) refer to higher is better or lower is better, respectively. We use boldface for the best performance. Results of DP-CGAN, GS-WGAN, DP-Sinkhorn are cited from Cao et al.  and Long et al. . Results of PEARL and DPDM are cited from Dockhorn et al. . Results of G-PATE and DataLens are cited from their papers, respectively. (*): DPDM did unconditional generation on CelebA.

Figure 3: The qualitative comparison on CelebA. \(=10^{-5}\). DPDM is unconditional.