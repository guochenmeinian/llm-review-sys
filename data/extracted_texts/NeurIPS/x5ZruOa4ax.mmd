# Ghait Boukachab \({}^{1,3}\)1

Improving _day-ahead_ Solar Irradiance Time Series Forecasting by Leveraging Spatio-Temporal Context

Oussama Boussif \({}^{1,2}\)

Equal contribution.

Corresponding authors: oussama.boussif@mila.quebec, ghait.boukachab@mila.quebec, dan.assouline@mila.quebec**Dan Assouline \({}^{1,2}\)1**

**Stefano Massaroli\({}^{1,2}\)**

**Tianle Yuan\({}^{4}\)**

**Loubna Benabbou\({}^{3}\)**

**Yoshua Bengio\({}^{1,2}\)**

###### Abstract

Solar power harbors immense potential in mitigating climate change by substantially reducing CO\({}_{2}\) emissions. Nonetheless, the inherent variability of solar irradiance poses a significant challenge for seamlessly integrating solar power into the electrical grid. While the majority of prior research has centered on employing purely time series-based methodologies for solar forecasting, only a limited number of studies have taken into account factors such as cloud cover or the surrounding physical context. In this paper, we put forth a deep learning architecture designed to harness spatio-temporal context using satellite data, to attain highly accurate _day-ahead_ time-series forecasting for any given station, with a particular emphasis on forecasting Global Horizontal Irradiance (GHI). We also suggest a methodology to extract a distribution for each time step prediction, which can serve as a very valuable measure of uncertainty attached to the forecast. When evaluating models, we propose a testing scheme in which we separate particularly difficult examples from easy ones, in order to capture the model performances in crucial situations, which in the case of this study are the days suffering from varying cloudy conditions. Furthermore, we present a new multi-modal dataset gathering satellite imagery over a large zone and time series for solar irradiance and other related physical variables from multiple geographically diverse solar stations. Our approach exhibits robust performance in solar irradiance forecasting, including zero-shot generalization tests at unobserved solar stations, and holds great promise in promoting the effective integration of solar power into the grid.

## 1 Introduction

Solar power has become an increasingly important source of renewable energy in recent years, with the potential to help mitigate the effects of climate change by reducing greenhouse gas emissions (Doblas-Reyes et al., 2021; IEA, 2021). However, the variability of solar irradiance - the amount of solar radiation that reaches the earth's surface - presents a challenge for integrating solar power into the grid. Accurate forecasting of solar irradiance can assist grid operators in dealing with the variability of solar power, leading to a more efficient and dependable integration of solar power into the grid. As a result, this can help to reduce the requirement for costly and environmentally damaging backup power sources.

Solar irradiance is influenced by a range of factors, including the time of day, the season, weather patterns, and the position of the sun in the sky. However, one of the most significant factors affecting solar irradiance variability is cloud cover. Clouds can block or scatter solar radiation, leading to rapid changes in solar irradiance at the earth's surface. Forecasting solar irradiance accurately thus requires modeling cloud cover, as well as accounting for the inherent variability of the system.

While a lot of previous work has focused on using pure time-series approaches to forecast solar irradiance (Yang et al., 2022), few have incorporated cloud cover (Nielsen et al., 2021; Bone et al., 2018; Si et al., 2021) and even fewer tackled the challenging **day-ahead forecasting**, often focusing on the easier very short term predictions (2 to 4 hours). When forecasting solar irradiance at a specific station, relying solely on its local physical variables is insufficient due to the significant spatial variability of cloud cover. To accurately anticipate the impact of clouds on incoming solar radiation, it is necessary to consider their motion and trajectory within a larger spatial context encompassing the station. In this paper, we incorporate satellite imaging to forecast solar irradiance at any chosen station and propose a multi-modal architecture that can in principle be used to **forecast any physical variable**. This study reveals the inadequacy of conventional testing schemes using conventional metrics like MAE or RMSE on an entire dataset for evaluating solar irradiance forecasting models. They fail to capture the models' performance in crucial cloud-related scenarios. Hence, we emphasize the necessity of a separate evaluation approach to address the complexity of cloud impact on solar irradiance variability. To allow for the metrics to show such performances by limiting the smoothing effect of the averaging, we propose a testing scheme based on multiple splits of the test data, separating particularly difficult examples from easy ones, for the task at hand. This is particularly important for practical downstream tasks related to solar irradiance estimation, such as the monitoring of solar power plants, where the correct prediction of such difficult examples can have a very high impact, as easy examples (in the presence of light cloud cover) can be treated fairly well by very simple models (such as a clear-sky or persistence model, as presented in section 5.1).

Figure 1: **CrossViViT architecture, in its Multi-Quantile version.** (1) The spatio-temporal context videos are tokenized, partially masked, and encoded with a vision transformer, using Rotary Positional Embedding, (2) The time series are tokenized and encoded in parallel with a transformer, (3) Both resulting latents are fed into \(L\) layers of a _cross transformer_ to mix them into one latent, (4) the output is passed into another transformer decoder, (5) and passed to multiple MLP heads which predict multiple quantiles, forming a prediction interval for each day-ahead time-series prediction.

**Contributions:** Our focus is on the application of machine learning to time-series forecasting, with a particular emphasis on utilizing multi-modal spatio-temporal data that includes physical, weather, and remotely sensed variables. The main contributions of this paper can be summarized as follows:

* We present a deep learning architecture called CrossViViT, designed to leverage spatio-temporal context (such as satellite data) in order to achieve highly accurate medium-term (1 day horizon) time-series forecasting at any given station. This paper focuses specifically on forecasting Global Horizontal Irradiance (GHI).
* We present a Multi-Quantile version of the model which allows to extract uncertainty estimation attached to each prediction. This methodology, although applied here in our context, should be applicable to any forecasting task and framework.
* We present a multi-modal dataset that combines satellite imagery with solar irradiance and other physical variables. The dataset covers a period of 14 years, from 2008 to 2022, and includes data from six geographically diverse solar stations. This dataset is unique in its combination of diverse variables and long time span, and is intended to facilitate the development and evaluation of new multi-modal forecasting models for solar irradiance.
* We propose a forecasting testing scheme based on multiple time splits of the test data, separating particularly difficult examples from easy ones, therefore allowing to capture the models' performances in problematic examples.
* We experimentally show that the proposed approach can generalize to a new station not seen during training in a zero-shot generalization forecasting setting.

## 2 Related works

**Machine Learning for time-series forecasting** Deep learning approaches have gained popularity for time-series forecasting in recent years due to their ability to model complex nonlinear relationships and capture temporal dependencies. These approaches have demonstrated superior performance compared to traditional statistical methods, motivating further research in this area. In a recent survey (Wen et al., 2022), it was found that transformers, renowned for their success in natural language processing and computer vision, were also effective for time-series analysis. The authors discussed the strengths and limitations of transformers and compared the structure and performance of recent transformer-based architectures on a benchmark weather dataset (Zhou et al., 2021). The particular case of solar irradiance forecasting represents an interesting application for time-series models (Wang et al., 2019; Narvaez et al., 2021; Alzahrani et al., 2017). One recent study developed a multi-step attention-based model for solar irradiance forecasting that generates deterministic predictions and quantile predictions as well (Sharda et al., 2021). In a similar perspective, Jonler et al. (2023) developed a probabilistic solar irradiance transformer that incorporates gated recurrent units and temporal convolution networks, demonstrating strong performance for short-term horizons.

**Context mixing / Multimodal learning for time-series forecasting** Previous studies highlight the potential of time-series methods for solar irradiance forecasting, emphasizing the significance of short-term horizons in solar energy management. However, day-ahead forecasting remains challenging due to the influence of cloud cover on surface irradiance (Bone et al., 2018; Si et al., 2021), a problem which we aim to address in this paper. Thus, it is crucial to account for cloud effects in solar irradiance forecasting regardless of the chosen method. For instance, Zhang et al. (2023) investigated the impact of cloud movement on irradiance prediction and proposed an approach to automatically learn the relationship between sky image appearance and solar irradiance. A concurrent work (Liu et al., 2023) proposed a multimodal-learning framework for ultra-short-term (10min-ahead) solar irradiance forecasting. They used Informer (Zhou et al., 2021) to encode historical time-series data, then utilized Vision Transformer (Dosovitskiy et al., 2020) to handle sky images. Finally, they employed cross-attention to couple the two modalities. The studies discussed above highlight the potential of incorporating external data sources, such as sky images and satellite images, in combination with time-series approaches to improve the accuracy of solar forecasting.

**Operator Learning** Utilizing available satellite imagery to forecast GHI over a region presents limitations as it may not capture clouds that exist at a resolution beyond that of the satellite data. To ensure accurate forecasting of quantities of interest, the ability to query the model at any possible resolution and any point within the domain becomes crucial. Recent advancements have witnessedthe rise of algorithms focusing on learning operators capable of mapping across functional spaces, with a focus on solving partial differential equations (PDE) (Lu et al., 2019; Li et al., 2021; Kovachki et al., 2021; Li et al., 2020). These operators can effectively map initial conditions to PDE solutions, making it possible to query the learned solution theoretically anywhere within its domain. Fourier Layers, developed by Li et al. (2021), enable zero-shot prediction on both uniform and non-uniform grids with learnable deformations (Li et al., 2022). Pathak et al. (2022) replace attention in ViT (Dosovitskiy et al., 2020) with Fourier layer mixing for competitive weather forecasting results with faster inference. MeshFreeflowNet (Jiang et al., 2020) learns high-resolution frames from corresponding lower resolution ones by querying the model at any point of the domain for irregular grids. Similarly, Boussif et al. (2022) employ message passing with a low-resolution graph for zero-shot super-resolution PDE learning. Additionally, message passing neural PDE solvers (Brandstetter et al., 2022) exhibit spatio-temporal multi-scale capabilities benefiting from long-expressive memory (Equer et al., 2023; Rusch et al., 2022). We note that while these approaches were developed for PDEs in mind, they can still be used for weather-related applications.

**Uncertainty estimation** When performing solar irradiance forecasting, deterministic forecasts are not sufficient to characterize the inherent variance and uncertainty in solar irradiance data. Probabilistic forecasts, providing uncertainty information, are crucial for energy system management (Wang et al., 2019). (Doubleday et al., 2020) and (Yagli et al., 2020) benchmark solar forecasting methods, emphasizing calibration and sharpness in prediction intervals. Specifically in short term solar irradiance forecasting, Zelikman et al. (2020) delves into post-hoc calibration for better predictions. Turkoglu et al. (2022) introduces FiLM-Ensemble, balancing predictive accuracy and calibration in uncertainty estimation. The deep ensembles approach by Lakshminarayanan et al. (2016) aggregates neural network predictions, capturing both data noise and model uncertainties. Few studies tackle uncertainty evaluation in a regression setting, rather than in classification one, which consists in the estimation of prediction intervals. Sonderby et al. (2020), performing precipitation forecasting, suggests an easy solution: the output is separated in 512 bins and the model predicts the precipitation rate (probability) in each of the bins, resulting ultimately in a distribution. Other methodologies include bootstrapping and ensembling methods, drawing a distribution out of multiple predictions from submodels, following the spirit of Quantile Regression Forests (Meinshausen and Ridgeway, 2006). The evolving landscape of solar irradiance forecasting underscores the importance of a calibrated, comprehensive, and robust probabilistic approach to address inherent uncertainties.

## 3 Methodology

We develop a framework for solar irradiance time-series forecasting, incorporating spatio-temporal context alongside historical time-series data from multiple stations. This framework is inspired by recent advancements in video transformer models (Arnab et al., 2021; Feichtenhofer et al., 2022) and multi-modal models that leverage diverse data sources such as images and time series (Liu et al., 2023). To establish the foundation for our framework, we provide a brief overview of the Rotary Positional Embedding (Su et al., 2021). Subsequently, we present the proposed architecture, CrossViViT, in detail, outlining its key components and design principles. Details about the ViT (Dosovitskiy et al., 2020) and ViViT architectures can be found in the Appendix.

### Rotary Positional Embedding

As we are dealing with permutation-variant data, assigning positions to patches before using attention is necessary. A common approach is to use additive positional embedding, which considers the absolute positions of the patches added into the input sequence. However, for our case, it is more appropriate to have dot-product attention depend on the relative "distance" between the patches. This is because the station should only be concerned with the distance and direction of nearby clouds, and therefore, a relative positional embedding is more sensible.

To this end we make use of RoPE (Su et al., 2021) to mix the station time series and the context. The station and each patch in the context are assigned their _normalized_ latitude and longitude coordinates in \([-1,1]\) which are used as positions for RoPE. Details about the formulation used are left to the Appendix.

### Cross Video Vision Transformer for time-series forecasting (CrossViViT)

CrossViViT.Our approach aims to integrate the available historical time-series data with video clips of spatio-temporal physical context to enhance the prediction of future time series for solar irradiance. The overall methodology, depicted in Figure 1, can be summarized as follows:

1. **Tokenizing**: The video context \(^{T C_{ctx} H W}\), with \(T\) frames for each of the \(C_{ctx}\) channels, and \(H\) and \(W\) respectively the height and width of the video images, is divided into \(N_{p}\) non-overlapping patches and linearly projected into a sequence of \(d\)-dimensional context tokens \(^{ctx}^{T N_{p} d}\). We use the _Uniform frame sampling_ ViViT scheme Arnab et al. (2021) to embed the videos we have at hand, the frames being concatenated along the batch dimension, and the sample frequency being defined at 30 minutes. The historical time series \(^{T C_{tx}}\) are linearly projected into a sequence of \(d\)-dimensional time-series tokens \(^{ts}^{T d}\). We augment the context tokens with RoPE, as presented in section 3.1, and a learnt positional encoding for the time-series tokens.
2. **Masking**: As a regularizing mechanism, we allow the model to mask a portion of the past time series and the video context before adding the positional encodings. During the training phase, a masking ratio \(m_{ctx}\) is randomly sampled from a uniform distribution \(U(0,0.99)\) for the context, and the corresponding patches are masked accordingly. We also explored masking the time series to encourage the model to rely more on the context but in practice, no masking gave the best performance. We note that during inference, no masking is applied.
3. **Encoding:** We encode the time series and the past video context separately with two transformer architectures: a spatio-temporal encoder similar to a ViT for the video context, and a multi layer transformer for the input time series. More specifically, the context tokens alone and time series alone are passed through \(L\) separate transformer layers (we keep the same number of layers \(L\) for both encoders), including Multi-Head Self-Attention (MSA), LayerNorm (LN) and Multi-Layer Perceptron (MLP) blocks, so that for each layer \(l\), we perform the following operations: \[_{l}^{ctx}=((_{l}^{ctx}) )+_{l}^{ctx} _{l}^{ts}=((_{l}^{ts}))+ _{l}^{ts}\] (1) \[_{l+1}^{ctx}=((_{l}^{ctx}) )+_{l}^{ctx} _{l+1}^{ts}=((_{l}^{ts}) )+_{l}^{ts}\] (2)
4. **Mixing:** We combine the resulting context and time-series latents, respectively \(_{L}^{ctx}\) and \(_{L}^{ts}\), within \(L\) layers of a Transformer with Cross Attention (CA) Vaswani et al. (2017) (we keep the same number of layers in the entire encoder-mixer architecture). After adding ROPE, the two \(L\)-th layers are mixed with CA and passed through an MLP block. The output of each layer becomes a mixed latent which is in turn mixed with the context latent \(_{L}^{ctx}\) and again passed through a block of MLP. Formally, the following operations are performed respectively at the first layer (left equations) and on the remaining layers (right equations) of the CA: \[_{1}^{mix}=((_{L}^{ctx}, _{L}^{ts}))+_{L}^{ts} _{l}^{mix}=((_{L}^{ctx}, _{L}^{mix}))+_{l}^{mix}\] (3) \[_{2}^{mix}=((_{1}^{mix}))+ _{1}^{mix} _{l+1}^{mix}=((_{l}^{mix}))+ _{l}^{mix}\] (4)
5. **Decoding:** The sequence of mixed tokens \(_{L}^{mix}\) returned by the layers of Cross Transformer is then passed through \(N\) layers of another Transformer as a decoder, before adding a learnt positional embedding to the token sequence. Each layer \(n\) of the Transformer is again formed by MSA, LN and MLP blocks: \[_{n}=((_{n}))+_{n}\] (5) \[_{n+1}=(((_{n}))+ _{n})\] (6) The output decoded sequence \(_{N}\) is passed through a final MLP head to output the final predicted future time series \(_{pred}^{T C_{ts}}\).

### Multi-Quantiles: Extracting prediction intervals

To obtain prediction intervals for each forecasted value, we propose a easy methodology which can be used for any deep learning forecasting model, here resulting in an alternative version of theCrossViViT architecture. In this modified version, the original MLP head is replaced with \(N_{heads}\) parallel MLPs, each dedicated to predicting a specific quantile of the distribution for each time step. To achieve this, we employ distinct quantile loss functions for each MLP head. By summing these quantile losses, we obtain a comprehensive Multi-Quantile loss, which serves as the training objective for the model. The quantile loss (Koenker and Hallock, 2001)\(L_{}(y,)\) for the \(\) quantile is defined as:

\[L_{}(y,)=\{(-y),(1-)(y-)\}.\] (7)

The Multi-Quantile loss, aiming to learn multiple quantile predictions \(_{}\) for a chosen set of quantiles \(v_{A}\), is then defined as: \(MQL(y,_{ v_{A}})=_{ v_{A}}L_{}(y,_{ })\). The selection of quantile heads \(v_{}\) is a crucial hyperparameter that determines the density of the output distribution generated by the model. To achieve a 96% prediction interval while maintaining a sufficiently dense distribution, we set the list of quantiles as \(v_{A}=[0.02,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.9,0.98]\). It is worth noting that, it is possible to assign different weights to the quantiles to guide the learning process. This approach can be beneficial in scenarios where the task requires a preference for overestimation or underestimation. However, in this study, our primary objective was to provide a prediction interval, leading to the conservative choice of quantile distribution and uniformly weighing the \(L_{}\)'s.

## 4 Dataset

This section provides a comprehensive description of the dataset designed for this study and shared publicly, including all the applied pre-processing steps.

### Time series

The time-series measurements were obtained from Baseline Surface Radiation Network datasets (Driemel et al., 2018). The experiments in this paper use data from six locations (Figure 2), collected at a 30-minute resolution over a 15-year period (2008-2022). The data captures diverse patterns, ranging from consistent irradiance levels under clear skies to fluctuations caused by intermittent clouds affecting surface solar radiation. The data contains measurements of the pressure in the station, clear sky components, Direct Normal Irradiance (DNI), and Diffuse Horizontal Irradiance (DHI).

The GHI component was computed using the formula: \(GHI=DNI z+DHI\) where \(z\) is the zenith angle of the sun obtained from the pyhib python library (Holmgren et al., 2020). The Ineichen model (Ineichen, 2016) available through the same library is utilized to obtain the clear sky components. The 2008-2016 data is used for training while subsets of the 2017-2022 data and stations are used for validation and test performance evaluations. In this study, the models are trained and evaluated to forecast the GHI component for a 24-hour period ahead, based on a history of 24-hour measurements.

Figure 2: **Stations and satellite data.**_Left_: Location of the six meteorological stations considered in the study with the red border indicating the spatial extent (TAM is out of the considered window). Additionally, three of the eleven spectral channels under investigation are highlighted: IR_108, VIS_008 and WV_073 channels are infrared (\(10.8\)), visible (\(0.8 m\)) and water vapor (\(7.3 m\)) channels respectively. _Right_: Table summarizing the geographic coordinates and elevation of each station used in the paper.

### Satellite images

In this study, we utilize the EUMETSAT Rapid Scan Service (RSS) dataset (Holmlund, 2003), which spans a period of 15 years from 2008 to 2022, with an original resolution of 5 minutes, later aligned with the time series data. Our analysis focuses on the non-High Resolution Visible (non-HRV) channels, which encompass 11 spectral channels with a spatial resolution of 6-9km and provide comprehensive coverage of the upper third of the Earth, with a particular emphasis on Europe. These channels, including Infrared and Water vapor, offer valuable information for our investigation. To facilitate our analysis, we reprojected the original geostationary projection data onto the World Geodetic System 1984 (WGS 84) coordinate system (Jacob et al., 2022). The region of interest is depicted in Figure 2. Note that one of the 6 stations, TAM, lies slightly outside the region we consider, and therefore represents an out-of-distribution station in term of the context we use.

To augment the contextual information, we computed the optical flow for each channel using the TVL1 algorithm (Sanchez Perez et al., 2013) from the OpenCV package (Bradski, 2000). The optical flow represents the "velocity" of pixels between consecutive frames, which in our case corresponds to the motion of clouds. Furthermore, we included the elevation map as an additional channel in our dataset. The pre-processed satellite data originally had a resolution of \(512^{2}\), but for computational efficiency, we downscale it to \(64^{2}\).

## 5 Experiments and Results

In this section, we outline the baselines utilized for comparison alongside the suggested architecture. We describe the experimental setup and present the results, benchmarking our framework against state-of-the-art forecasting models across various test configurations. Additionally, we employ a split methodology to assess model performance in challenging prediction scenarios, which hold significant implications for downstream tasks associated with solar irradiance estimation.

The models are trained using a dataset spanning a period of 9 years, from 2008 to 2016, encompassing the stations IZA, CNR, and PAL. Validation is performed on a separate dataset covering 3 years, from 2017 to 2019, for the PAY station. The TAM and CAB stations serve as the test dataset, consisting of 3 years from 2020 to 2022 for CAB, and from 2017 to 2019 for TAM. Each model takes a historical

    &  &  &  \\   & & All (9703) & & Easy (814) & & Hard (**8895**) & All (2299) & Easy (2064) & Hard (**235**) \\   & & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE \\ 
**Preference** & N/A & 63.57 & 131.44 & 52.56 & 109.80 & 80.01 & 159.14 & **32.26** & 94.71 & **20.85** & 99.47 & 132.92 & 238.12 \\
**Fourier** & N/A & 68.91 & 121.23 & 55.61 & 99.54 & 87.46 & 152.39 & 56.00 & 94.85 & 45.48 & 62.62 & 144.28 & 214.47 \\
**Fourier** & N/A & 65.74 & 121.53 & 53.82 & 96.38 & 83.56 & 154.76 & 44.02 & 92.22 & 33.15 & 57.56 & 139.56 & 232.61 \\
**Fourier** & N/A & 64.67 & 142.22 & 62.67 & 99.94 & 82.61 & 155.44 & 40.26 & 93.26 & **95.34** & **95.87** & 139.68 & 231.32 \\
**Clear Sky** (Jonckine, 2016) & 67.19 & 140.81 & 60.55 & 125.66 & 77.12 & 159.28 & 40.61 & 98.02 & 31.07 & 63.3 & 142.42 & 242.26 \\ 
**Reformer** (Skiovo et al., 2009) & 68.64 & 57.42 & 102.73 & 53.35 & 29.97 & 62.92 & 155.81 & 81.6 & 137.04 & 98.57 & 139.74 & 108.22 & 189.55 \\
**Informer** (Zhou et al., 2021) & 56.73 & 72.26 & 122.89 & 80.35 & 118.74 & 73.45 & 128.69 & 68.34 & 140.83 & 82.66 & **96.06** & **156.22** \\
**FiLM** (Zhou et al., 2022) & 9.48 & 68.37 & 116.86 & 59.66 & 53.51 & 144.11 & 62.72 & 99.71 & 54.99 & 77.63 & 130.66 & 210.58 \\
**PatchTS** (Noe et al., 2020) & 9.64 & 60.76 & 11.94 & 54.47 & 107.19 & 135.01 & 69.49 & 132.44 & 62.14 & 124.25 & 107.37 & 197.92 \\
**Lights** (Zhang et al., 2022) & 33.82 & 54.97 & 102.08 & 49.55 & **90.28** & 62.92 & 130.83 & 68.51 & 114.99 & 64.61 & 104.98 & 102.77 & 177.98 \\
**Crossformer** (Zhang and Yan, 2020) & 227.03 & 50.98 & 10.45 & 52.59 & 92.02 & 65.52 & 117.11 & 68.85 & 116.54 & 65.43 & 173.89 & 19.16 & 255.08 \\
**FEDFormizer** (Zhou et al., 2022) & 23.6M & 56.38 & **99.92** & 53.08 & 90.13 & 53.11 & **111.54** & 92.12 & 146.52 & 51.13 & 142.53 & 108.08 & 275.64 \\
**DLinear** (Zhou et al., 2022) & 47.4K & 75.01 & 121.01 & 65.21 & 92.92 & 69.956 & 147.21 & 72.554 & 115.40 & 60.94 & 98.74 & 121.67 & 211.28 \\
**AutoFormizer** (Wu et al., 2011) & 50.4M & 64.34 & 104.53 & 60.81 & 95.14 & 69.63 & 117.17 & 115.88 & 170.91 & 117.36 & 171.07 & 102.87 & 169.47 \\ 
**CrossVIVT** & 145M & **50.38** & **91.83** & **47.04** & **96.50** & **122.09** & 49.46 & 94.96 & 44.00 & 99.91 & 97.40 & 179.39 \\
**CrossVIVT (**Learned PED**) 1 & 145M & 51.11 & 108.66 & 47.31 & 50.53 & 115.31 & 15.31 & 109.86 & 196.41 & 111.13 & 176.73 & 152.87 & 185.61 \\   

Table 1: Comparison of model performances across **test stations** TAM and CAB, during **test years** (2020-2022) for CAB, and **val years** (2017-2019) for TAM. We report the MAE and RMSE for the easy and difficult splits presented in section 5.2 along with the number of data points for each split. We add the MAE resulting from the Multi-Quantile CrossViTiT median prediction, along with \(p_{t}\), the probability for the ground-truth to be included within the interval, averaged across time steps. Additionally, we ablate RoPE against a learned positional embedding.

input of 24 hours and predicts the GHI for the subsequent 24 hours, employing a sliding window approach. Details about the implementation and hyperparameter tuning can be found in the Appendix.

### Baselines

We conduct a comprehensive comparison between our approach and several state-of-the-art deep learning architectures specifically designed for forecasting tasks. These architectures are explicitly mentioned in the results tables, such as Table 1. Additionally, we propose _dummy_ baselines that are tailored to solar irradiance forecasting, namely:

**Persistence**: This baseline relies solely on the past day's time-series data, considering it as the prediction for future values.

**Clear Sky baseline**: This baseline uses the computable clear sky components of solar irradiance (Ineichen model (Ineichen, 2016)), which represent the total amount of irradiance that would reach the station in the absence of clouds.

**Fourier approximations**: We compute Fourier approximations over the previous day's time series, and apply a low-pass filter to keep a limited number of modes. We consider 3 baselines: Fourier\({}_{3}\), Fourier\({}_{4}\), and Fourier\({}_{5}\), corresponding to approximations with 3, 4, and 5 modes, respectively.

### "Hard" vs. "Easy" forecasting scenarios

To assess the capability of the suggested model in capturing cloud-induced variability in GHI forecasts, we perform evaluations on test stations using various time splits, aiming to identify its strengths and limitations in comparison to previous approaches. This analysis allows us to pinpoint the specific scenarios where CrossViViT excels, as well as the areas where it falls short. Furthermore, it provides insights into the comparative strengths and weaknesses of previous approaches.

Given the favorable performance of the Persistence baseline when the GHI values exhibit similarity between consecutive days, we propose a time split approach that categorizes examples as either "Easy" or "Hard" based on the extent of GHI variation. The "Easy" examples entail minimal changes in GHI across consecutive days (the Persistence baseline works well), while the "Hard" examples involve significant variations (the Persistence baseline fails). To quantify the similarity, we employ a measure based on the ratio of the area under the GHI curve for the two days. In order to assign equal importance to ratios such as 0.5 (indicating GHI half that of the previous day) and 2 (indicating GHI double that of the previous day), we utilize the measure \(r=|}|\). Here, \(y\) represents the GHI over a 24-hour period, and \(y_{}\) represents the GHI over the previous 24 hours. Accordingly, we categorize cases as "Easy" when \(r<|()|\), and "Hard" otherwise.

### Performance on stations and years outside the training distribution

Table 1 presents a comprehensive comparison of the proposed CrossViViT approach with state-of-the-art timeseries models and _dummy_ baselines. The evaluation is conducted on the test stations TAM and CAB, covering the periods 2017-2019 and 2020-2022, respectively. It is important to note that due to the unavailability of data for TAM during the 2020-2022 period, we perform the evaluation using the 2017-2019 data instead.

During the 2017-2019 period, CrossViViT achieves the lowest MAE compared to the time-series models on the TAM station. However, it is important to note that the persistence baseline still outperforms our approach. This performance disparity can be attributed to the characteristics of the TAM station, which is situated in a desert region characterized by predominantly clear and sunny days. As we incorporate cloud information, it may occasionally underestimate the GHI in such clear-sky conditions. Furthermore, the training dataset consists of data from only one "sunny" station located in the Canary Islands (IZA), limiting the availability of examples to effectively learn clear-sky patterns. Based on these results, one can see that for stations characterized by low irradiance intermittency, a combination of persistence and clear-sky models might be sufficient. For the 2020-2022 period on the CAB station, CrossViViT outperforms all baselines across different time splits. This notable improvement can be attributed to the specific meteorological conditions of the CAB station, which experiences a higher frequency of cloudy days. This aligns with the primary focus of our research, which aims to accurately forecast GHI under cloudier conditions. Predictions visualisations can be seen in Figure 3, along with the comparison of the fourier spectra of our prediction, the ground truth and a strong baseline, CrossFormer.

### Zero-shot forecasting on unseen stations and in-distribution years

To evaluate the zero-shot capabilities of CrossViViT in terms of performance on unseen stations, we maintain the **same time period as the training data**, thereby emphasizing the **spatial dimension** of the analysis. The radar plots presented in Figure 4 demonstrate that our approach consistently outperforms the baselines across all splits for the CAB and PAY stations, which are characterized by higher cloud cover. However, it is noteworthy that Persistence remains competitive for the TAM station, particularly in the "easy" splits where irradiance variations are minimal throughout the day. This observation further underscores the efficacy of CrossViViT in accurately accounting for cloud conditions, particularly when examining the performance metrics of the "Hard" split.

### Multi-Quantile results

Table 1 also shows results of the Multi-Quantile CrossViViT, including the MAE of the median prediction (the 0.5 quantile), along with the test confidence \(p_{t}\) obtained for the prediction interval: the probability for the ground-truth to be included within the interval, for each time step, averaged across the entire dataset considered. As for the other models, the evaluation is conducted on the test stations TAM and CAB, covering the periods 2017-2019 and 2020-2022, respectively. It is important to note that for this Multi-Quantile version, the goal is not to provide the best prediction from the median but rather to provide confident prediction intervals, with a high \(p_{t}\), ideally close to 96%, which we theoretically should reach using 0.02 and 0.98 extreme quantiles. We include a small version of the Multi-Quantile model, and a large one, matching the number of parameters used for our Cross ViViT model. The small model provides the best performance.

The prediction intervals achieved a high level of confidence, surpassing 0.9, for the unseen CAB station. However, for the TAM station, the harsh environmental conditions of the desert posed a

Figure 3: **Prediction visualisations from CrossViViT for four examples in CAB station, on the 2020-2022 test period. (a) CrossViViT predictions. (b) Multi-Quantile CrossViViT median (\(q_{0.50}\) quantile) predictions with [\(q_{0.02}\),\(q_{0.98}\)] prediction interval. (c) Predictions from a strong baseline, CrossFormer, (d) Fourier spectrum of the target, our prediction, and CrossFormer prediction. Figure (a) illustrates that CrossViViT closely aligns with the ground truth by effectively capturing cloud variations, whereas CrossFormer assumes a clear-sky pattern. This is confirmed by the Fourier spectra depicted in (d), where CrossFormer’s spectrum exhibits a rapid decay in contrast to CrossViViT.**

challenge for reliable estimation of prediction intervals, due to the abundance of clear sky components which is not seen during training. Although the median prediction results were comparatively inferior to those of a baseline method, it demonstrates consistent patterns in its variation across easy and difficult cases. Furthermore, the test confidence of the proposed method remains relatively constant across different splits, for both stations. Prediction visualisations can be seen on Figure 3.

### Ablating the Rotary Positional Embedding

In order to assess the influence of RoPE, we ablate this design choice against a learned positional encoding which was the standard encoding used in ViViT. As Table 1 shows, RoPE contributes to the good performance in OOD stations and OOD years. Moreover, in the hard cases of the CAB station, RoPE outperforms the learnable positional encoding showcasing its importance in capturing cloud-induced variations.

## 6 Conclusion, Limitations, and Future Work

We present CrossViViT, an architecture for accurate day-ahead time-series forecasting of solar irradiance using the spatio-temporal context derived from satellite data. We suggest a testing scheme that captures model performance in crucial situations, such as days with varying cloudy conditions, and we enable the extraction of a distribution for each time step prediction. We also introduce a new multi-modal dataset that provides a diverse collection of solar irradiance and related physical variables from multiple geographically diverse solar stations. CrossViViT exhibits robust performance in solar irradiance forecasting, including zero-shot tests at unobserved solar stations during unobserved years, and holds great promise in promoting the effective integration of solar power into the grid.

However, there are some limitations to our study. Firstly, we would benefit to include more test years and stations to further validate the effectiveness of our approach. It would also be interesting to explore different past and future horizons to further evaluate the robustness of our model across different prediction and context horizons. The training time remains our key limitation since it takes close to 5 hours per epoch on a single GPU (see Appendix), but we plan on optimizing the architecture further in future work. Lastly, we plan to investigate the use of a cropping methodology on the context as a regularization method. Despite these limitations, our study clearly highlights the importance of incorporating spatio-temporal context in solar irradiance forecasting and demonstrates the potential of deep learning in addressing the challenges associated with variability in solar irradiance. Given the promising results observed in our current study, we intend to investigate the applicability of CrossViViT to other physical variables that are significantly influenced by their surrounding context.

Figure 4: Radar plots illustrating the comparative analysis of CrossViViT performance with Persistence and CrossFormer models, during **training years** (the in-distribution period from 2008 to 2016), on the **unobserved stations** of TAM, CAB, and PAY, respectively on (a), (b) and (c). CrossViViT demonstrates greater versatility compared to CrossFormer in forecasting under diverse conditions. Persistence struggles to accurately predict under challenging conditions, particularly on ”Hard” days.