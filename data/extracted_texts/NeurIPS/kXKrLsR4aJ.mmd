# Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space

Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space

 Maximilian Stolzle

Department of Cognitive Robotics

Delft University of Technology

M.W.Stolzle@tudelft.nl

&Cosimo Della Santina

Department of Cognitive Robotics

Delft University of Technology

C.DellaSantina@tudelft.nl

###### Abstract

Even though a variety of methods have been proposed in the literature, efficient and effective latent-space control (i.e., control in a learned low-dimensional space) of physical systems remains an open challenge. We argue that a promising avenue is to leverage powerful and well-understood closed-form strategies from control theory literature in combination with learned dynamics, such as potential-energy shaping. We identify three fundamental shortcomings in existing latent-space models that have so far prevented this powerful combination: (i) they lack the mathematical structure of a physical system, (ii) they do not inherently conserve the stability properties of the real systems, (iii) these methods do not have an invertible mapping between input and latent-space forcing. This work proposes a novel Coupled Oscillator Network (CON) model that simultaneously tackles all these issues. More specifically, (i) we show analytically that CON is a Lagrangian system - i.e., it possesses well-defined potential and kinetic energy terms. Then, (ii) we provide formal proof of global Input-to-State stability using Lyapunov arguments. Moving to the experimental side, we demonstrate that CON reaches SoA performance when learning complex nonlinear dynamics of mechanical systems directly from images. An additional methodological innovation contributing to achieving this third goal is an approximated closed-form solution for efficient integration of network dynamics, which eases efficient training. We tackle (iii) by approximating the forcing-to-input mapping with a decoder that is trained to reconstruct the input based on the encoded latent space force. Finally, we leverage these three properties and show that they enable latent-space control. We use an integral-saturated PID with potential force compensation and demonstrate high-quality performance on a soft robot using raw pixels as the only feedback information.

## 1 Introduction

Learning how the environment evolves around us from high-dimensional observations (i.e., world models ) is essential for achieving both artificial and physical intelligence . For example, world models are required for effectively planning an artificial/robotic agent's actions in complex and unstructured environments . However, learning such dynamics directly in high-dimensional observation space is usually intractable. Seminal works have shown that we can leverage autoencoders to compress the state information into a low-dimensional latent space  in which it is much more feasible to learn the dynamics . However, strong limitations still persist when it comes to using these learned models to generate low-level intelligence.

One outstanding challenge is how to perform closed-loop control in the learned latent space - i.e., how to generate control inputs based on a high dimensional sensory input such that a desired movement is generated. Prior works have explored, among other approaches, Reinforcement Learning (RL) , Model Predictive Control (MPC) , Linear-quadratic Regulators (LQRs)  and gradient-based optimization  for planning and control towards a target evolution that is given in observation space. However, all existing latent-space control strategies have shortcomings, such as a limited planning horizon and slow control rates (MPC and gradient-based approaches), sample inefficiency (RL), or they pose a requirement for learning linear dynamics  (LQR), which is not even possible for systems that are inherently non-linearizable . One interesting avenue is to leverage model-based control approaches, such as potential shaping [23; 24; 10], for effective and computationally efficient control in latent space . For these techniques to be feasible, the dynamical model needs to fulfill four characteristics: (i) the dynamics need to have the mathematical structure of physical systems, (ii) conserve the stability properties of real systems, (iii) the latent state needs to be relatively low-dimensional, and (iv) there needs to exist a well-defined, invertible mapping between the input and the forcing in latent space. However, existing model structures that are used for learning latent dynamics  do not meet all of these criteria. Relevant examples are Multilayer Perceptrons (MLPs), Neural ODEs (NODEs) [27; 28], many variants of Recurrent Neural Networks (RNNs) (e.g., LSTMs , Gated Recurrent Units (GRUs) , etc.), and physics-informed neural networks (e.g., Lagrangian Neural Networks (LNNs) [31; 32; 10], Hamiltonian Neural Networks (HNNs)) . For example, MLPs do not have a physical interpretation and do not provide an invertible mapping of the forcing generated by the input, NODEs are usually not easily stabilizable , most RNNs require a relatively high-dimensional latent space (i.e., many hidden states), and energy-shaping control approaches based on LNNs  do not come with any formal stability guarantees.

In recent years, oscillatory networks [35; 36; 37; 38; 39] have been shown to exhibit state-of-the-art performance on time sequence modeling tasks while being parameter-efficient, thus fulfilling our requirement (iii). Consequently, we believe that they are a promising option for control-oriented dynamics learning in latent space. Still, these models do not fulfill the remaining requirements that we have listed above. Despite being an interpretable combination of harmonic oscillators, they do not have the structure of a physical system - i.e., they do not possess a well-defined energy function. Moreover, only local stability [35; 37] has been shown, with sufficient conditions that appear to be very stringent. Finally, in addition to training an encoder that maps inputs to latent-space forcing, we propose also training a decoder that learns to reconstruct inputs based on latent-space forcing. This enables us to easily switch between inputs and forcing, which is essential when implementing control strategies.

We resolve all the above-mentioned challenges by proposing Coupled Oscillator Networks (CONs), a new formulation of a coupled oscillator network that is inherently Input-to-State Stability (ISS) stable, for learning the dynamics of physical systems and subsequently exploiting its structure for model-based control in latent space. The network consists of damped, harmonic oscillators connected through elastic springs, damping elements, and a neuron-like coupling force and can be excited by a nonlinear actuation term. We identify a transformation into a set of coordinates from which we can derive the networks' kinetic and potential energy. This allows us to leverage Lyapunov arguments  for proving the global asymptotic stability of the unforced system and ISS stability for the forced system under relatively mild assumptions on the network parameters. Even though we constrain the dynamics to a very specific structure, we demonstrate (a) the CON network achieves similar performance as NODEs when learning the dynamics of unactuated, mechanical systems with two

Figure 1: **Panel (a)**: The proposed CON network consists of \(n\) damped harmonic oscillators that are coupled through the neuron-like connection \((Wx+b)\) and the non-diagonal stiffness \(K-k\) and damping coefficients \(D-d\), respectively. The state of the network is captured by the positions \(x(t)\) and velocities \((t)\) of the oscillators. The time-dependent input is mapped through the (possibly nonlinear) function \(g(u)\) to a forcing \(\) acting on the oscillators. **Panel (b)**: Exploiting Coupled Oscillator Networks (CONs) for learning latent dynamics from pixels: We encode the initial observation \(o(t_{0})\) and the input \(u(t)\) into latent space where we leverage the Coupled Oscillator Network (CON) to predict future latent states. Finally, we decode both the latent-space torques \((t)\) and the predicted latent states \(z(t)\).

orders of magnitude fewer parameters and (b) that the proposed model achieves, for the complex task of learning the actuated, highly nonlinear dynamics of continuum soft robots  directly from pixels, a \(60\,\%\) lower prediction error than Coupled Oscillatory Recurrent Neural Network (coRNN)  and reaches the SoA performance across all techniques that we tested. Finally, we show some initial results that the proposed CON model is also able to learn the latent dynamics of Partial Differential Equations (PDEs), in this case containing reaction-diffusion  dynamics.

Subsequently, we derive an approximate closed-form solution, that is, in parameter regimes in which the linear, decoupled dynamics dominate transient, more accurate than numerical integrators with comparable computational requirements and which increases training speed by 2x with a small decrease in prediction accuracy. Finally, as we can derive the system's potential energy, we can leverage potential shaping  to derive a controller that combines an integral-saturated PID controller with a feedforward term compensating potential forces. As the feedback acts on a well-shaped potential field, tuning the feedback gains becomes very simple and out-of-the-box, and the controller exhibits a faster response time and a \(26\,\%\) lower trajectory tracking Root Mean Squared Error (RMSE) than a pure feedback controller based on a latent NODE  model.

The proposed methodology is particularly well-suited for learning the latent dynamics of mechanical systems with continuous dynamics, dissipation, and a single, attractive equilibrium point. Examples of such systems include many soft robots, deformable objects with dominant elastic behavior, Lagrangian systems immersed in a dominant potential field, or locally other mechanical systems such as robotic manipulators, legged robots, etc. For these systems, we can fully leverage the structural prior of the proposed latent dynamics, including the integrated stability guarantees. If the system is actuated, the learned dynamics can be subsequently exploited for model-based control, as demonstrated in Sec. 5.

The code associated with this paper is available on GitHub1.

## 2 Input-to-State Stable (ISS) Coupled Oscillator Networks (CONs)

Formulation.The integral component to (coupled) oscillatory RNNs  are one-dimensional, potentially damped, harmonic oscillators, which are described by their state \(y_{i}=[x_{i}_{i}]^{}^{2}\), where \(x_{i}\) and \(_{i}\) are the position and velocity of the oscillator, respectively. Then, the oscillator's dynamics are defined by the following Equation of Motion (EOM)

\[m_{i}\,_{i}(t)+d_{i}\,_{i}(t)+_{i}\,x_{i}(t)=F_{i}(t), m_{i},_{i},d_{i}^{+}.\] (1)

Here, \(m_{i}\) is the mass, \(_{i}\) is the stiffness, and \(d_{i}\) is the damping coefficient of the damped harmonic oscillator. \(F_{i}(t)\) is a (possibly time-dependent) external forcing term acting on the mass.

Even though the state is extremely low dimensional and the number of parameters is small, this single, damped harmonic oscillator can already exhibit a variety of (designable) behaviors: The expressions \(_{,i}=}{m_{i}}}\) and \(_{i}=}{2\,\,m_{i}}}\) let us determine the natural frequency and the damping factor, respectively and allow us to design the transient behavior. For example, \(_{,i}\) lets us isolate a spectrum of the input signal \(F_{i}(t)\) and \(_{i}\) determines the damping regime: underdamped (\(_{,i}<1\)), critically damped (\(_{,i}=1\)), overdamped (\(_{,i}>1\)). Furthermore, as (damped) harmonic oscillators are omnipresent in nature (and especially in physical systems), they have been intensively studied and are well understood (e.g., characteristics, closed-form solutions, etc.). In this work, we will exploit some of these properties and knowledge to learn stable (latent) dynamics efficiently.

By intercoupling damped harmonic oscillators, we can drastically increase the expressiveness of the dynamical system  while preserving some of the intuition and understanding we have for these systems. In this work, we propose a ISS-stable CON consisting of \(n\) damped harmonic oscillators that are coupled through both linear and nonlinear terms. The networks' state is defined as \(y=x^{}&^{}^{} ^{2n}\) and its dynamics can be formulated as a 2nd-order Ordinary Differential Equation (ODE)

\[(t)=}{t}\\ }{t}=f(y(t),u(t))= (t)\\ g(u(t))-Kx(t)-D\,(t)-(W\,x(t)+b),\] (2)

where \(K,D^{n n}\) are the linear stiffness and damping matrices, respectively. The neuron-inspired term \((W\,x(t)+b)\) with \(W^{n n}\), \(b^{n}\) provides nonlinear coupling between the harmonic oscillators. The network is excited by the time-dependent input \(u(t)^{m}\) through the possibly nonlinear mapping \(g:^{m}^{n}\). Specifically, we consider in this work a formulation where an input-dependent matrix \(B(u)^{n m}\) projects the input \(u(t)\) to a time-dependent forcing on the oscillators: \(=g(u)=B(u)\,u\). Here \(B(u)\) could, for example, be parametrized by a MLP.

We specifically designed the network architecture such that (i) the system exhibits a unique and isolated equilibrium and (ii) we can derive expressions for the kinetic and potential energies. These two features allow us to (a) prove Global Asymptotic Stability (GAS) and ISS stability using an established procedure based on strict Lyapunov arguments , and (b) implement model-based controller based on potential shaping.

One key insight of this work is that in the coordinates \(x(t),(t)\), we cannot derive a potential as the hyperbolic force \((x(t)+b)\) is not symmetric. Therefore, we propose a coordinate transformation into \(\)-coordinates: \(y_{}(t)=x_{}(t)\\ _{}(t)=W\,x(t)\\ \,(t)^{2n}\). The coordinate transformation is valid if its Jacobian is full-rank, which is the case if \((W)=n\). In \(\)-coordinates, the dynamics can be rewritten as

\[_{}(t)=x_{}}{ t}\\ x_{}}{t}=f_{}(y(t),u(t))=_{}(t)\\ M_{}^{-1}\,(g(u(t))-K_{}x_{}(t)-D_{ }\,_{}(t)-(x_{}(t)+b))\] (3)

with \(K_{}=K\,W\), \(D_{}=D\,W\) and \(M_{}=W^{-1}\).

A difference of this formulation compared to prior work  is that (i) the forcing produced by the input term \(=g(u)\) is fully separated from the forcing produced by the elastic coupling terms \(K_{}\), and (ii) the generalized force is symmetric, which we prove in Appendix A.1, allowing us to define a potential energy expression, which we can later on leverage for stability analysis and control.

The equilibria \(_{}=_{}^{}&0^{ }^{}^{2n}\) of the unforced network are given by the roots of the characteristic equation \((_{}+b)+K_{}\,_{}=0\).

**Lemma 1**.: _Let \(K_{} 0\). Then, the dynamics defined in (3) have a single, isolated equilibrium \(_{}=_{}^{}&0^{ }^{}\)._

Proof.: The proof is straightforward and provided in Appendix A.2. 

Next, we introduce a mapping into the tilde coordinates \(_{}=y_{}-_{}\). The residual dynamics (w.r.t. the equilibrium \(_{}\)) can now be stated as

\[}_{}(t)=_{}(y,u)= }_{}(t)\\ M_{}^{-1}\,(g(u(t))-K_{}\,(_{}+_ {}(t))-D_{}\,}_{}(t)-(_{ }+_{}(t)+b))\] (4)

In the following, we will write \(\|A\|\) to denote the induced norm of matrix \(A\) and \(_{m}(A)\), \(_{}(A)\) to refer to its minimum and maximum Eigenvalue respectively.

Global Asymptotic Stability (GAS) for the unforced system.We first consider the unforced system with \(=g(u)=0,\  t[t_{0},t_{})\) and strive to prove global asymptotic stability  for the attractor \(\). We propose a strict Lyapunov candidate with skewed level sets 

\[V_{}(_{}) =\,_{}^{}\,P_{} \,_{}+_{i=1}^{n}_{0}^{_{,i}} (_{,i}++b_{i})\,-_{i=1}^{n} _{0}^{_{,i}}(_{,i}+b_{i})\, ,\] \[=\,_{}^{}\,P_{} \,_{}+_{i=1}^{n}((_{,i}+_{,i}+b_{i})-(_{,i}+b_{i} )-(_{,i}+b_{i})\,_{,i}),\] (5) \[P_{} =K_{}&\,M_{}\\ \,M_{}^{-1}&M_{}^{2n 2n}, ()=(()),>0.\]

**Lemma 2**.: _The scalar function \(V_{}(_{})\) defined in (5) is continuously differentiable and verifies the condition \(V_{}(0)=0\). Furthermore, let \(M_{},K_{} 0\). Now, if we choose \(0<<(M_{})\,_{m}(K_{})}}{\|M_ {}\|}_{}\), then \(V_{}(_{})>0\,\,_{}^{2n}\{0\}\). Additionally, then \(V_{}(_{})\) is radially unbounded as \(\|_{}\| V_{}(_{})\)._

Proof.: We provide the proof in Appendix A.3 and demonstrate that the bounds on \(\) are required for the Lyapunov candidate to be positive-definite. 

**Theorem 1**.: _Let \(M_{},K_{}\) and \(D_{}\) be positive definite and suppose the system be unforced: \(g(u(t))=0\). Then, \(_{}=0\) is globally asymptotically stable for the system dynamics defined (4) such that \(_{}(_{})<0,\,_{} ^{2n}\{0\}\)._

[MISSING_PAGE_FAIL:5]

An approximate closed-form solution for the rollout of CON

To predict future system states, we need to integrate the ODE in Eq. (2), with the solution given by \(y(t_{k+1})=y_{t_{k}}+_{t_{k}}^{t_{k+1}}f(y(t^{}),u(t^{}))\, t^{}\). Unfortunately, a closed-form solution for the nonlinear dynamics \(f(y,u)\) does not (yet) exist. Therefore, we traditionally need to revert to (high-order) numerical ODE solvers that are computationally very expensive and introduce additional memory overhead . This considerably increases the training time of models involving such continuous-time dynamics. While the computational time can be reduced by increasing the (minimum) time step of the integrator, this comes at the expense of an integration error, and we lose (part of) the theoretical guarantees and practical characteristics that the nominal ODE provides. In this work, we take an alternative approach by splitting the problem into (i) decoupled linear dynamics that can be cheaply and precisely integrated using a closed-form solution and (ii) the residual, coupled nonlinear dynamics, which we integrate numerically at a slower time scale:

\[(t)=(t)}_{f_{}(y):}+(t)-(Wx(t)+b)}_{f_{ }(y,u):}\] (9)

where \(=(K_{11} K_{nn})\), \(d=(D_{11} D_{nn})\) are the diagonal components of the stiffness and damping matrices, respectively, and \(F^{n}\) is a constant, external forcing term on the oscillators.

For a short-time-interval \( t\), we now approximate (9) as

\[(t_{k}+ t) f_{}(y(t_{k}+ t),F(t_{k})) F(t_{k})=-f_{}(y(t_{k}),u(t_{k})).\] (10)

For a scalar 2nd-order, linear ODE of form \(_{i}=f_{}(x(t^{}),F(t_{k}))\), a well-known, closed-form solution  exists. We exploit this characteristic by formulating the approximate solution as

\[y(t_{k}+ t)\,f_{}(y(t_{k}),u(t_{k}))=y(t_{k})+ _{t_{k}}^{t_{k}+ t}f_{}(y(t^{}),F(t_{k}))\,t^{}\] (11)

and denote \(f_{}:^{n}^{m}^{n}\) as the Closed-Form Approximation of the Coupled Oscillator Network (CFA-CON) model. The implicit assumption behind (10) is that \(f_{}(y) f_{}(y,u)\) (i.e., the linear, decoupled dynamics dominate the nonlinear, coupled, time-varying dynamics). We refer the interested reader to Appendix B for derivation and implementation details, where we summarize the integration procedure in Algorithm 1. We also provide qualitative results for the integration accuracy in Fig. 2 and quantitative results for the integration accuracy and computational speed-up w.r.t. numerical integrators in Appendix B.

## 4 Learning control-oriented latent dynamics from pixels

We now move towards learning latent dynamical models based on CON and CFA-CON. CONs are an ideal fit for learning latent dynamics as they guarantee that the latent states stay bounded.

We assume to have access to observations in the form of images \(o^{h_{} w_{} c_{}}\), where \(c_{}\) denotes the number of channels. Please note that this could also be other high-dimensional observations such as LiDAR scans, point clouds, etc. We now leverage an encoder-decoder architecture to map these high-dimensional observations into a compressed latent space: The encoder \(:^{h_{} w_{} c_{}} ^{n_{x}}\) with \(n_{z} h_{}\,w_{}\) identifies a low-dimensional latent representation \(z^{n_{z}}\) of the images. The decoder \(:^{n_{z}}^{h_{} w_{}  c_{}}\) approximates the inverse operation by reconstructing an image \(^{h_{} w_{} c_{}}\) based on the latent representation. To promote the learning of a smooth and monotonic mapping into latent space, we specifically choose to implement the autoencoder here as a \(\)-Variational Autoencoder (VAE) . Instead of just statically reconstructing the image \((t_{k})\), we are interested in predicting future observations \((t_{k+l})\), where \(l 1 N\). For this, we train a 2nd-order dynamical model that is, when integrated, able to predict future latent representations \(z(t_{k+l})\). This requires us to define a latent state \((t)=z^{}(t)&^{}(t)^{ }^{2n_{z}}\) consisting of the latent representation and latent velocity \((t)^{n_{z}}\).

We now rely on CON with \(n=n_{z}\) oscillators to provide us with the latent state derivative \(=f_{}(y_{}(t),u(t))\), where we defined \(=y_{}\), and \(z=x_{}\). To ensure stability, we make use of the Cholvesky decomposition to ensure that \(M_{},K_{}\) and \(D_{}\) always remain positive definite (see Theorem 2). It is important to note that we train the encoder, decoder, and dynamical model all jointly. Please refer to Appendix C for more implementation details.

Training.It is important to remember that because we are using a \(\)-VAE , the image encoding becomes stochastic, and the encoder neural network actually outputs \(_{z}(o),2\,(_{z})(o)^{n_{z}}\). After executing the reparametrization trick as \(z(t_{k})(_{z}(t_{k}),_{z}^{2}(t_{k}))\), we formulate the loss function, evaluated on each trajectory consisting of \(N\) time-steps, as

\[=_{k=0}^{N}((o(t_{k}),\, (z(t_{k})))}{N+1}}_{}+_{}((_{z}(t_{k}),\,_{z}(t_{k})) )}{N+1}}_{}+_{k=1}^{N}(_{ }(o(t_{k}),\,((t_{k})))}{N}}_{ }+_{k}(z(t_{k}),\, (t_{k}))}{N}}_{}),\] (12)where \((t_{k})\) is predicted by \((t_{k})=_{t=t_{0}}^{t_{k}}f_{}((t^{}),u(t^{}))\, t^{}\), and \((t_{0})=[z^{}(t_{0})^{}(t_{0})]^{ }\). Here, \(z(t_{0})\) is given by the encoder, and \((t_{0})\) is approximated using finite differences in image-space (see Appendix C.5 for more details). \(,_{},_{u}\) are loss weights.

Models.We train the CON with the input-to-forcing mapping \(g(u)=B(u)\,u\), where \(B(u)\) is parametrized by a MLP with a hyperbolic tangent activation function applied in between layers. We report results for two variants of the CON model: for the medium-sized _CON-M_ and small-sized _CON-S_, the MLP consists of five and two layers with a hidden dimension of \(30\) and \(12\), respectively. The model CFA-CON uses the same architecture as _CON-M_. We compare against several popular latent space model architectures: The NODE model uses a MLP with an hyperbolic activation functions and predicts \((t)=f_{}((t),u(t))\). To make the comparison fair, we parametrize the NODE's MLP in the same fashion as for _CON-M_. The _MECH-NODE_ integrates prior knowledge towards learning 2nd-order mechanical ODEs and, therefore, predicts \((t)=f_{}((t),u(t))\). Furthermore, we consider multiple autoregressive models: RNN, GRU, and coRNN and let them parameterize the following transition function: \((t_{k+1})=f_{}((t_{k}),\,u(t_{k}))\) As common in the relevant literature , we allow the autoregressive models to perform multiple time step transitions before predicting the next sample. For the autoencoder, we use a vanilla Convolutional Neural Network (CNN). More details can be found in Appendix C.

Datasets.We consider in total six datasets that are based on simulations of unactuated mechanical systems, and actuated continuum soft robots. The first three, mechanical dataset are based on the work of Botev et al.  and contain video sequences of a mass-spring system with friction (_M-SP+F_), a single pendulum with friction (_S-P+F_), and a double pendulum with friction (_D-P+F_). Continuum soft robots have theoretically infinite Degree of Freedom (DOF), evolve with highly nonlinear and often time-dependent dynamical behaviors, and are notoriously difficult to model from first principles . For that reason, it is a very interesting proposition if we could learn latent-space dynamical models directly from video  and later leverage them for control . Therefore, we generate three datasets based on the Piecewise Constant Strain (PCS) soft robot model. _CS_ considers one segment with constant strain and is modeled using three configuration variables. _PCC-NS-2_ and _PCC-NS-3_ only consider bending deformations and contain soft robots with two and three segments, respectively. For all datasets, we render images with a resolution of 32x32px of the system's state. More information on the datasets can be found in Appendix C.1.

We tune all hyperparameters for each model and dataset separately using Optuna .

Results.Unactuated mechanical datasets:The results in Tab. 1 show that the _NODE_ model slightly outperforms the _CON_ network on the _M-SP+F_ and _S-P+F_ datasets. However, as the datasets do not consider system inputs, we can remove the input mapping from all models (e.g., _RNN_, _GRU_, _coRNN_, _CON_, and _CFA-CON_). With that adjustment, the _CON_ network has the fewest parameters among all models, particularly two orders of magnitude less than the NODE model. Therefore, we find it very impressive that the CON network is roughly on par with the NODE model. For the _D-P+F_ dataset, we can conclude that the _CFA-CON_ model offers the best performance across all methods. Finally, most of the time, the _CON_ & _CFA-CON_ networks outperform the other baseline methods that have more trainable parameters. **Actuated continuum soft robot datasets:** The results in Tab. 1 show that _CON-M_ matches the performance of the state-of-the-art methods

  
**Model** & **RMSE M-SP+F**  & **RMSE D-P+F**  & **RMSE D-P+F**  & **RMSE CS \(\)** & **RMSE PCC-NS-2** \(\)** & **RMSE PCC-NS-3** \(\)** \\  RNN & \(0.2739 0.0057\) & \(0.2378 0.0352\) & \(0.1694 0.0004\) & \(\) & \(0.1373 0.0185\) & \(0.2232 0.0075\) \\ GRU  & \(0.0275 0.0033\) & \(0.1457 0.0078\) & \(0.1329 0.0005\) & \(0.1129 0.0109\) & \(0.0951 0.0021\) & \(0.2148 0.0196\) \\ coRNN  & \(\) & \(0.1333 0.0044\) & \(0.1324 0.0026\) & \(0.2537 0.0018\) & \(0.2564 0.0089\) & \(0.2474 0.0018\) \\ NODE  & \(\) & \(\) & \(0.1324 0.0024\) & \(0.2415 0.0021\) & \(0.1867 0.0561\) & \(0.3373 0.0565\) \\ MECH-NODE & \(0.0328 0.0034\) & \(0.1650 0.0205\) & \(0.1710 0.0111\) & \(0.2494 0.0028\) & \(0.1035 0.0012\) & \(0.1900 0.0024\) \\ CON-S (only \(0.0303 0.0053\) & \(0.1030 0.0064\) & \(0.1323 0.0018\) & \(0.1093 0.0164\) & \(0.0996 0.0012\) & \(0.1792 0.0038\) \\ CON-M (our) & \(0.0333 0.0053\) & \(0.1303 0.0064\) & \(0.1323 0.0018\) & \(0.1063 0.0027\) & \(0.1008 0.0006\) & \(\) \\ CFA-CON (our) & \(0.0313 0.0026\) & \(0.1352 0.0073\) & \(\) & \(0.1462 0.0211\) & \(0.1124 0.0025\) & \(0.1803 0.0003\) \\   

Table 1: Benchmarking of CON and CFA-CON at learning latent dynamics against baseline methods. The first three datasets, based on , contain samples of a mass-spring with friction (_M-SP + F_), a single pendulum with friction (_S-P + F_), and a double pendulum with friction (_D-P + F_) (all without system inputs). The _CS_ dataset considers a continuum soft robot consisting of one segment with three constant planar strains. The _PCC-NS-2_ and _PCC-NS-3_ datasets contain trajectories of a continuum soft robot made of two and three piecewise constant curvature segments, respectively. We choose the latent dimensions of the models as \(n_{z}=4\), \(n_{z}=4\), and \(n_{z}=12\) for the _M-SP + F_, _S-P + F_, and _D-P + F_ datasets, and \(n_{z}=8\), \(n_{z}=12\), and \(n_{z}=12\) for the _PCC-NS-2_, _PCC-NS-3_, and _CS_ soft robotic datasets. We report the mean and standard deviation over three different random seeds.

  
**Dataset** & \(}\) & **RNN** & **GRU**  & **coRNN**  & **NODE**  & **MECH-NODE** & **CON-S (our)** & **CON-M (our)** & **CFA-CON (our)** \\ 
**M-SP+F** & \(4\) & \(88\) & \(248\) & \(40\) & \(3368\) & \(3244\) & \(\) & \(\) & \(\) \\
**D-P+F** & \(12\) & \(672\) & \(1968\) & \(348\) & \(4404\) & \(4032\) & \(\)

[MISSING_PAGE_FAIL:8]

\(K_{}=1,K_{}=2,K_{}=0.02,=1\) for the _P-satI-D_ controller and \(K_{}=0,K_{}=2,K_{}=0.05,=1\) for the _P-satI-D+FF_ controller, respectively.

Furthermore, we compare the control performance of our model-based controllers with a baseline control strategy based on the _MECH-NODE_ (\(n_{z}=2\)) that achieves an error of \(0.1104\) on the test set. First, we utilize the same P-satI-D feedback controller as for the CON model to generate the control action \((t)\) in latent space. As the MECH-NODE uses an MLP to parameterize the function \(=f_{}(,u)\), we cannot easily map \((t)\) into an input \(u(t)\). Therefore, we linearize the latent space dynamics w.r.t to the input as \(f_{,}(,u)=f_{}(,0)+A()\,u\), where \(A()=}{ u}(,0)\) is computed using autodiff. Then, \(u(t)=A^{}()\,(t)\). After tuning the control gains, we choose \(K_{}=0.001,K_{}=0.02,K_{}=1,=1\).

We train all models (e.g., _MECH-NODE_, _CON_) on three different random seed and choose the best model instance. Please refer to Appendix E for more details on the model selection. We generate a trajectory of \(7\) setpoints, where \(q^{}(t_{j})(-5,5)\,/ ^{2}\) is a sampled configuration of the soft robot. Then, we render an image \(o^{}(t_{j})\) that represents the target observation for the controller and encode it into latent space to retrieve \(z^{}^{2}\). At time step \(k\), we render an image \(o(t_{k})\) of the robot's current configuration \(q(t_{k})\) and encode the image. Subsequently, we evaluate the control law and apply the decoder \(u(t_{k})=((t_{k}))\), which is finally passed to the simulator that integrates the ground-truth dynamics to the next time-step \(t_{k+1}\) considering the actuation \(u(t_{k})\). The controller runs at \(100\,\), and we simulate the ground-truth dynamics with a _Dopi5_ ODE integrator at a time-step of \(1\,\).

Results.As an evaluation metric, we consider the RMSE between the actual and the reference trajectory. The _P-satI-D_ applied to the _MECH-NODE_ model (baseline) achieves an RMSE of \(2.88\,/\) w.r.t. to the desired configuration \(q^{}\) (but unknown to the algorithm). The _P-satI-D_ CON controller, which does not exploit the learned latent dynamics for control, exhibits an RMSE of \(4.08\,/\) w.r.t. to the desired configuration \(q^{}\). The _P-satI-D+FF_ controller exhibits an RMSE of \(2.12\,/\) w.r.t. to the desired configuration \(q^{}\). We also visualize the closed-loop trajectories in Fig. 5 and as sequences of stills in Apx. E. We conclude that the nicely structured latent space generated by the \(\)-VAE allows the _P-satI-D_ controller to effectively regulate the system towards the setpoint, although the response time is rather slow. The _P-satI-D+FF_ controller is able to exploit the structure of the CON model through its potential shaping feedforward term. With that, _CON P-satI-D+FF_ exhibits a faster response time and a \(26\,\%\) lower RMSE than the _MECH-NODE P-satI-D_ baseline. We provide results for the control of an actuated damped harmonic oscillator in Apx. D.

## 6 Conclusion and Limitations

Conclusion.In this work, we propose a new formulation for a coupled oscillator that is inherently input-to-state stable. Additionally, we identify a closed-form approximation, that is able to simulate the network dynamics more accurately compared to numerical ODE integrators with similar computational costs. When learning latent dynamics with CON, we observe that the performance is on par or slightly better compared to SoA methods such as RNNs, NODEs, etc., even though we constrained the solution space to a ISS-stable coupled oscillator structure. Furthermore, we point out that the performance of the CON models is more consistent across latent dimensions compared to the baselines and improved when not specifically tuned for a given dimension. Furthermore, as seen in Tab. 8, the closed-form approximation achieves, with the same number of model parameters, similar accuracies and double the training speed w.r.t. to the continuous-time model. Finally, we demonstrate that even a simple PID-like latent-space controller can effectively regulate the system to a setpoint. By exploiting the

Figure 4: **Panel (a): Samples of some of the datasets used as part of the experimental verification, specifically for the results reported in Tab. 1. The real-world Reaction-Diffusion image is adopted from . Panel (b): Model-based control in latent space by exploiting the physical structure of the CON model.**

network structure and compensating for potential forces, regulation performance can be greatly improved, and response time decreased by more than \(55\,\%\).

Limitations.While we think our proposed method shows great potential and opens interesting avenues for future research, there exist certain limitations. For example, the proposed method of learning (latent) dynamics implicitly assumes that the underlying system adheres to the Markov property (e.g., the full state of the system is observable), that a system with mechanical structure can approximate it, and that it has an isolated, globally asymptotically stable equilibrium. This is, for example, the case for many mechanical systems (e.g., some continuum soft robots, deformable objects, and elastic structures) with continuous dynamics, convex elastic behavior, dissipation, and whose time-dependent effects (e.g., viscoelasticity, hysteresis) are negligible. Even if these conditions are not met globally, the method can be applied to model the local behavior around an asymptotic equilibrium point of the system (e.g., robotic manipulators, legged robots) with added stability benefits for out-of-distribution samples. Alternatively, the method could be extended to relax some of these assumptions, e.g., by allowing for multiple equilibria, zero damping, or by incorporating additional terms to capture discontinuous dynamics (e.g., stick-slip models) or period motions (e.g., limit cycles such as the Van der Pol oscillator). The proposed method might not be suitable for some physical systems, such as nonholonomic systems, partially observable systems, or systems with non-Markovian properties. Examples of such systems include mobile robots and systems with hidden states or delayed observations.

Furthermore, the approximated closed-form solution shows the best integration for situations where linear, decoupled dynamics dominate the transient. For dominant nonlinear, coupled forces, the performance of CFA-CON degrades, and it might be better to revert to numerical integration of the CON ODE. Finally, the control works exceptionally well in the setting where the latent dimension equals the input dimension. We hypothesize that this enables the method to identify a diffeomorphism between the input and the latent-space forcing. Still not investigated is how the performance could degrade if \(n_{z}>m\) (or \(n_{z}<m\) for that matter).

Figure 5: Latent-space control of a continuum soft robot (simulated using two piecewise constant curvature segments) at following a sequence of setpoints: The upper two rows show the performance of a pure P-satI-D feedback controller operating in latent space \(z\) learned with the MECH-NODE and CON models, respectively. The lower row displays the results for a latent space controller based on the CON model that additionally also compensates for the learned potential forces.