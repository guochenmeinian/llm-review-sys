# Mixture of Link Predictors on Graphs

Li Ma\({}^{1}\)1, Haoyu Han\({}^{2}\)1, Juanhui Li\({}^{2}\)1, Harry Shomer\({}^{2}\)1, Hui Liu\({}^{2}\)1, Xiaofeng Gao\({}^{1}\)1, Jiliang Tang\({}^{2}\)

\({}^{1}\)Shanghai Jiao Tong University, \({}^{2}\)Michigan State University

mali-cs@sjtu.edu.cn, gao-xf@cs.sjtu.edu.cn

{hanhaoy1,lijuanh1,shomerha,liuhui7,tangjili}@msu.edu

Equal Contribution.Li Ma and Xiaofeng Gao are in the MoE Key Lab of Artificial Intelligence, Department of Computer Science and Engineering, Shanghai Jiao Tong University.This work is done when Li Ma is a visiting student at Michigan State University.

###### Abstract

Link prediction, which aims to forecast unseen connections in graphs, is a fundamental task in graph machine learning. Heuristic methods, leveraging a range of different pairwise measures such as common neighbors and shortest paths, often rival the performance of vanilla Graph Neural Networks (GNNs). Therefore, recent advancements in GNNs for link prediction (GNN4LP) have primarily focused on integrating one or a few types of pairwise information. In this work, we reveal that different node pairs within the same dataset necessitate varied pairwise information for accurate prediction and models that only apply the same pairwise information uniformly could achieve suboptimal performance. As a result, we propose a simple mixture of experts model Link-MoE for link prediction. Link-MoE utilizes various GNNs as experts and strategically selects the appropriate expert for each node pair based on various types of pairwise information. Experimental results across diverse real-world datasets demonstrate substantial performance improvement from Link-MoE. Notably, Link-MoE achieves a relative improvement of 18.71% on the MRR metric for the Pubmed dataset and 9.59% on the Hits@100 metric for the ogbl-ppa dataset, compared to the best baselines. The code is available at https://github.com/ml-ml/Link-MoE/.

## 1 Introduction

Link prediction (LP) is a central challenge in graph analysis with many real-world applications, such as recommender systems , drug discovery , and knowledge graph completion . Specifically, LP attempts to predict unseen edges in a graph. Unlike node-level tasks where Graph Neural Networks (GNNs) excel in modeling _individual_ node representations , LP demands the use of _pairwise_ node representations to model the existence of a link where vanilla GNNs often fall short . Traditionally, various heuristic methods  were used to identify new links by encapsulating the pairwise relationship between two nodes. For instance, the Common Neighbors (CN) heuristic  counts the number of shared neighbors between a node pair, postulating that the number of common neighbors can indicate the likelihood of a connection. The Katz index  considers the total number of paths between two nodes, assigning a higher weight to those shorter in length. Node feature similarity-based methods  assumes that nodes with similar features tend to connect. Despite their simplicity, these heuristic-based methods are still considered as strong baselines in LP tasks.

To leverage both the representational power of GNNs and the effectiveness of heuristics, recent GNN4LP works have sought to incorporate pairwise information into GNN frameworks, therebyenhancing their expressiveness for better link prediction. For example, NCN/NCNC  exploit the common neighbor information into GNNs. Neo-GNN  further incorporates multi-hop neighbor overlap information. SEAL  and NBFNet  leverage the full and partial labeling trick, respectively, to indict the target node pair, which has been proven to learn heuristic patterns like common neighbors and the Katz index. These GNN4LP methods mark significant progress in link prediction .

However, both traditional heuristic approaches and GNN4LP models typically adopt a one-size-fits-all solution, uniformly applying the same strategy to all target node pairs. There are several limitations with this one-size-fits-all solution: **(1) Limited Use of Heuristics**: These methods utilize only one or a few heuristics. Our preliminary studies in Section 3 have shown that different heuristics tend to complement each other, and employing multiple heuristics within the same dataset can lead to improved link prediction performance. Therefore, methods relying on a single type of heuristic might not be optimal. **(2) Uniform Application of Heuristics**: In Section 3, we also find that different node pairs within the same dataset often require distinct heuristics for predictions. Consequently, these methods that uniformly apply the same heuristic across all node pairs lack this adaptability, potentially leading to suboptimal performance. These findings underscore the pressing need for an approach that can adaptively apply a range of pairwise information specific to node pairs. Inspired by the superior performance of existing GNN4LP, we delved deeper into understanding different GNN4LP models. Our investigation reveals that these models are highly complementary and they excel under specific conditions, often correlated with particular heuristics. For example, the NCN model tends to perform well in scenarios with a high number of common neighbors. These observations motivate us to ask: _can we design a strategy that can simultaneously enjoy the strengths of various GNN4LP models and correspondingly enhance link prediction?_

In response to this question, we introduce a simple yet remarkably effective mixture of experts model for link prediction - **Link-MoE**. This model operates by utilizing a range of existing link predictors as experts. A gating function is learned to assign different node pairs to different experts based on various types of pairwise information. Extensive experimental results showcase the surprisingly effective performance of Link-MoE. For instance, it surpasses the best baseline on Pubmed and ogbl-ppa dataset by 18.71% on the MRR and 9.59% on the Hits@100, respectively.

## 2 Related Work

### Link Prediction

Link prediction aims to predict unseen links in a graph. There are mainly three classes of methods for the link prediction task. An overview of each is given below.

**Heuristic Methods**: Heuristic methods have been traditionally used for link prediction. They attempt to explicitly model the pairwise information between a node pair via hand-crafted measures. Several classes of heuristics exist for link prediction  including: local structural proximity, global structural proximity, and feature proximity. _Local Structural Proximity_ (LSP): These method extract the information in the local neighborhood of a node pair. Common Neighbors (CN) , Adamic-Adar (AA) , and Resource Allocation  are popular measures that consider the number of shared 1-hop neighbors between the node pair. _Global Structural Proximity_ (GSP): These methods attempt to model the interaction of a node pair by extracting the global graph information. The Shortest Path Distance assumes that a shorter distance between nodes results in a higher likelihood of them connecting. Both Katz Index  and Personalized Pagerank (PPR)  consider the paths of disparate length that connect both nodes, giving a higher weight to those shorter paths. _Feature Proximity_ (FP): FP measures the similarity of the node features for both nodes in the pair, positing that nodes with similar features are more likely to form edges. Previous work [21; 22] has derived heuristics algorithms to measure the feature proximity.

**GNN-based Methods**: Recent work has looked to move beyond pre-defined heuristic measures and model link prediction through the use of graph neural networks (GNNs). Earlier work [23; 24; 25] has sought to first use a GNN to learn node representations, and the representations for both nodes in a pair are then used to predict whether they link. However, multiple works [7; 8] have shown that node-based representations are unable to properly model link prediction. As such, newer methods, which we refer to as GNN4LP, attempt to learn pairwise representations to facilitate link prediction. Both SEAL  and NBFNet  condition the GNN aggregation on either both or one of the two nodes in the pair. While expressive, both methods tend to be prohibitively expensive as they require aggregating messages separately for each node pair. Recent methods [14; 13; 26; 27] have attempts to devise more efficient ways of learning pairwise representations by injecting pairwise information in the score function, bypassing the need of customizing the GNN aggregation to each node pair. These methods typically attempt to exploit different structural patterns on the local and global scales.

**Ensemble Methods**: Ensemble-based methods for link prediction primarily fall into two categories: bagging and stacking. Bagging methods create multiple base learners trained on varied data subsets and integrate their predictions for final output [28; 29]. Stacking methods train multiple models on the entire graph and use a meta-model to integrate their predictions ([30; 31; 32; 33]). However, these methods directly combine the predictions of base learner without considering the specific patterns and heuristics of base learners.

### Mixture of Experts

The use of Mixture of Experts (MoE) [34; 35], which is based on the divide-and-conquer principle to divide problem to different experts, has been explored across various domains . Recent researches mainly focus on the efficiency of leveraging the MoE in the NLP [37; 38] or Computer Vision  domains. Chen et al.  attribute the success of MoE to the cluster structure of the underlying problem. In the graph domain, GMoE  integrates the MoE model with GNNs, enabling nodes to learn from information across different hops. Wu et al.  leverage MoE to address the distribution shift issue in GNNs. To the best of our knowledge, Link-MoE represents the first instance of MoE specifically tailored for the link prediction task, showcasing exceptionally effective performance.

## 3 Preliminary

In this section, we begin by analyzing the relationship between various heuristics employed in link prediction, aiming to uncover the complex patterns that exist within the same dataset. Subsequently, we explore the relationship between the performance of different GNN4LP models and these heuristics. This exploration aims to identify the most suitable scenarios for each model, thereby enhancing our understanding of how different approaches can be optimally applied in varying link prediction contexts. Before that, we first introduce key notations and experimental settings.

**Notations and experimental settings.** Let \(=(,)\) be a graph with \(n\) nodes, where \(\) is the node set and \(\) is the edge set. \(_{i}\) denotes the neighborhood node set for node \(v_{i}\). The graph can be denoted as an adjacency matrix \(^{n n}\), and each node \(v_{i}\) may be associated with a \(d\)-dimensional feature \(_{i}\) and we use \(=[_{1},,_{n}]^{}^{n d}\) to denote the node feature matrix. We conduct analysis on the Cora, Citeseer, Pubmed, ogbl-collab, and ogbl-ppa datasets. We use Hits@K as a metric to measure the ratio of positive samples ranked among the top \(K\) against a set of negative samples. The details on each dataset and the evaluation setting can be found in Appendix A. Due to the limited space, we only illustrate partial results in the following subsections. More results can be found in Appendix B.

### Exploring Heuristics in Link Prediction

In this subsection, we focus on three vital types of pairwise factors used in link prediction identified by Mao et al. : (a) local structure proximity, (b) global structure proximity, and (c) feature proximity. For each type, we adopt a single widely used heuristic as a representative metric including Common Neighbors (CN)  for local structure proximity, Shortest Path (SP)  for global structural proximity, and Feature Cosine Similarity (FCS) for feature proximity. We initially evaluate the performance of each heuristic individually and then assess their combinations by simply adding their normalized values. Specifically, we normalize each heuristic value \((h)\) to the range of  using \(}{h_{max}-h_{min}}\), where \(h_{max}\) and \(h_{min}\) are the maximum and minimum heuristic values in the dataset. One exception is the calculation of SP, where a smaller SP indicates a higher likelihood that two nodes are connected. Therefore, we first calculate \(\), and then normalize it in the same way as other heuristics. For this evaluation, we employ Hits@3 as the metric for smaller datasets and Hits@20 for larger OGB datasets. The results for Citeseer and ogbl-collab are illustrated in Figure 1, with diagonal values representing the individual performance of each heuristic. We can have two observations: **(1)** combining different heuristics generally enhances overall performance, indicating that reliance on a single heuristic may be inadequate for accurate link prediction; and **(2)** the performance of each heuristic varies across datasets. For instance, in the Citeseer dataset, FCS and CN exhibit comparable performance. However, in the ogbl-collab dataset, CN significantly outperforms FCS.

We further investigate the overlap in correctly predicted sample pairs by each heuristic. We use the Jaccard Coefficient to calculate the overlapping ratio between each pair of heuristics. For the calculation of the Jaccard coefficient, we use the Hits@K metric for each edge. Specifically, we choose Hits@3 for small datasets and Hits@20 for the OGB datasets. We first rank the prediction scores of each method for both positive and negative edges. If the prediction score of a positive edge is in the Top-K, we label this positive edge as 'present' and add it to the correct prediction set. In this way, we can calculate the Jaccard coefficient by comparing the correct prediction sets for each pair of methods. The results for the Citeseer and ogbl-collab datasets are presented in Figure 2. We observe that the overlapping ratio between certain heuristics is notably low. This implies that the sets of node pairs correctly predicted by different heuristics have a minimal intersection. Therefore, **different node pairs require distinct heuristics for accurate prediction even on the same dataset**.

From the previous analysis, it is enticing to think that simply considering multiple heuristics should result in superior link prediction performance. We test this hypothesis by learning to classify links using multiple popular heuristic methods. For a single link, the individual heuristic scores are concatenated together and passed to an MLP, where the output is then used to classify the link. The full set of heuristic considered can be found in Section 5.1. The results on Citeseer and ogbl-collab can be found in Table 1. We report the MRR for Citeseer and Hits@50 for ogbl-collab. We find that ensembling multiple heuristics can modestly improve the performance. However, it still noticeably lags behind GNN4LP methods in performance. Based on this observation, we are motivated to investigate whether different GNN4LP models can be used to model a wider variety of links.

### Exploring GNN4LP Models and Heuristics

In this subsection, we move beyond analyzing the performance of only heuristic measures and further consider the capabilities of different GNN4LP methods. To better understand the abilities of different GNN4LP models, we first evaluate the overlapping ratio between different models using the Jaccard Coefficient. We also include the MLP and different heuristics in the analysis. The overlapping ratio of different methods on ogbl-collab dataset is shown in Figure 3. These results reveal that the overlapping ratios among different GNN4LP models are rel

    & **Method** & **Citeseer** & **ogbl-collab** \\   & CN & 28.34 & 61.37 \\  & Shortest Path & 31.82 & 46.49 \\  & Katz & 38.16 & 64.33 \\  & Feature Similarity & 31.82 & 26.27 \\  & **Ensemble** & 44.08 \(\) 0.18 & 64.44 \(\) 0.21 \\   & Neo-GNN & \(53.97\)\(\) 5.88 & 66.13 \(\) 0.61 \\  & NCNC & \(64.03\)\(\) 3.67 & 65.97 \(\) 1.03 \\   

Table 1: Performance of ensembling heuristics.

Figure 3: The overlapping ratio on ogbl-collab.

atively low, suggesting that each model is capable of predicting a unique set of links. Furthermore, different GNN4LP models have varying degrees of overlap with different heuristics. These observations lead us to an intriguing question: _Are the unique sets of links correctly predicted by different GNN4LP models related to specific heuristics?_

To answer this question, we first categorize node pairs into 5 groups based on each heuristic and evaluate the performance of different GNN4LP models within these groups. Additionally, we also include the MLP and GCN in our analysis. The performance of these models across different Common Neighbors (CN) groups for Cora and ogbl-collab is depicted in Figure 4. The x-axis represents different groups, along with the proportion of node pairs in each group. From the results, we can find that **no single model consistently outperforms others across all groups** on either dataset. Interestingly, when there are no common neighbors, MLP and GCN tend to excel in both the Cora and ogbl-collab datasets. In situations with a few common neighbors, SEAL shows better performance in the Cora dataset, while BUDDY tends to lead in the ogbl-collab dataset. With an increase in the number of common neighbors, methods that encode CN information, such as NCNC, generally exhibit strong performance. A similar phenomena can be found on other datasets and heuristics in Appendix B.

In conclusion, our analysis underscores that accurate link prediction necessitates the use of multiple heuristics. Different node pairs require distinct heuristics for optimal prediction. Furthermore, the overlapping ratio of different GNN4LP models is relatively low. The performance of powerful GNN4LP models is closely tied to the specific heuristics they encode. And there is no single model that can uniformly achieve the best performance across all scenarios. These findings pave us a way to adaptively select the most suitable model for each node pair to achieve better overall performance in link prediction task.

## 4 Method

The investigations conducted in Section 3 reveal that various heuristics complement each other for the task on link prediction. This implies that different node pairs may need different heuristics to properly predict the existence of a link. Therefore, one approach to potentially achieve better performance in link prediction is to integrate all these heuristics into a single, unified model. However, as shown in Table 1, this strategy fails to outperform existing GNN4LP methods. This suggests that these GNN4LP models are already quite effective. Our findings further suggest that different GNN4LP models demonstrate unique strengths in different scenarios, which are related to specific heuristics. Therefore, leveraging these diverse heuristics as a guidance could help identify the most suitable GNN4LP models for specific node pairs. Based on the above intuitions, we aim to design a framework that can harness the unique strengths of each model to enhance the performance of link prediction.

### Link-MoE - A General Framework

To leverage the strengths of various existing models, we introduce a novel mixture-of-experts (MoE) method tailored for link prediction, which we term - **Link-MoE**. An overview of Link-MoE is depicted in Figure 5(a). There are two major components: the gating model and the multiple expert models. The gating function can be implemented using any neural network and each expert can be any method used for link prediction. When predicting whether a node pair \((i,j)\) are linked, the gating function utilizes their heuristic information to produce normalized weights for each expert.

Figure 4: The performance of different models on each CN group.

These weights dictate the level of contribution each expert model has towards the final prediction. Each expert model processes the graph and node pair information, estimating the likelihood of a connection between the two nodes. The individual expert predictions are then aggregated according to the weights assigned by the gating function. The final prediction is made using the sum of the weighted scores, effectively leveraging the strengths of multiple experts to determine the probability of a link. Formally, the prediction of Link-MoE can be expressed as:

\[Y_{ij}=(_{o=1}^{m}G(_{ij},_{ij})_{o}E_{o}( ,)_{ij}),\] (1)

where \(m\) denotes the number of expert models incorporated, pairwise node features \(_{ij}\) and structural heuristics \(_{ij}\) serves as the input to the gating function, \(G()\) represents the gating model function, \(E_{o}\) refers to the \(o\)-th expert model, and \(\) is a sigmoid activation function. This configuration makes the Link-MoE remarkably flexible and easily adaptable, allowing for the seamless integration of different expert models as required. We will detail our implementation in the following subsections.

### The Design of the Gating Model

As highlighted in our preliminary studies (Section 3), it's evident that different GNN4LP models excel in varying contexts and that their strengths can be indicated by different heuristics. Therefore, we incorporate a broad spectrum of heuristics as inputs to the gating model to leverage these strengths. Specifically we consider CN , AA  and RA  to model the local structural proximity and Shortest Path, Katz index , and PPR  for the global structural proximity. For the feature proximity, to ensure the score is invariant to the ordering of the node pair, we utilize the element-wise product for deriving the feature heuristic of node pair \((i,j)\). This is defined as \(_{ij}=_{i}_{j}\). We also use \(_{ij}=[s_{ij}^{1},s_{ij}^{2},...,s_{ij}^{k}]\) to represent all the \(k\) structural heuristics, and the dimension of each structural heuristics is typically very small. However, the node pair feature heuristic is equal to the input node feature dimension and can span hundreds or even thousands of dimensions. This significant disparity in dimensionality could hinder the model's ability to effectively learn from the structural heuristics. To address this challenge, we design a two-branch gating model, as illustrated in Figure 5(b). Each branch is a simple MLP. One branch is dedicated to encoding the structural heuristics, while the other focuses on processing the node pair features. After that, these two branches are merged via concatenation. Finally, an MLP with the softmax function is applied to this combined output to generate the final weight predictions. This design ensures a balanced consideration of both structural and feature-based heuristics. Formally, the gating function is defined as follows:

\[G(_{ij},_{ij})=ff(_{ ij})||f(_{ij}),\] (2)

where \(f\) is a MLP and \(||\) denotes the concatenation operator.

### Optimization of Link-MoE

Given the experts chosen in Section 5.1, there are several training strategies used by MoE models to combine them. This includes end-to-end training  and the EM algorithm . Given the multiple options, we are then tasked with the question: _how do we optimize Link-MoE?_

Figure 5: An overview of the proposed Link-MoE.

In this work, we employ a two-step training strategy, as detailed in Algorithm 1 in Appendix E. Initially, we train each expert individually using their respective optimal hyperparameters and perform inference on the dataset to obtain the prediction scores for each link. Subsequently, we focus on the training of the gating model. Specifically, we adopt the cross entropy to train the gating function:

\[L=-_{(i,j)}y_{ij} Y_{ij}+(1-y_{ij})( 1-Y_{ij})),\] (3)

where \(y_{ij}=1\) when a link exists between node \(v_{i}\) and \(v_{j}\) in the graph, and \(y_{ij}=0\) otherwise. \(\) and \(\) denote the set of positive/negative links in the graph, respectively.

There are several benefits to our two-step training strategy. **(1)**_Efficiency_: This approach eliminates the need to load every expert into memory simultaneously, as each expert is trained and infers independently; For time efficiency, tuning the gating model to identify the best hyperparameters is more efficient since it involves training only MLPs. **(2)**_Effectiveness_: The two-step training strategy helps to avoid the 'collapse problem' often encountered in MoE models . This issue arises when only a single expert is consistently selected, leading to the under-utilization and inadequate learning of the other experts. By training the experts individually first, we mitigate this risk, ensuring a more balanced and effective utilization of all experts. We compare two-step and end-to-end training strategies in Appendix G. **(3)**_Flexibility_: When introducing new experts into the Link-MoE, it's only necessary to train these new experts and the gating model. All previously trained experts can be seamlessly integrated without the need for retraining.

## 5 Experiments

In this section, we conduct comprehensive experiments to validate the effectiveness of the proposed Link-MoE. Specifically, we aim to address the following research questions: **RQ1:** How does Link-MoE perform when compared to other baseline models? **RQ2:** Are the heuristics effective in aiding the selection of experts? **RQ3:** Can Link-MoE adaptively select suitable experts for different node pairs?

### Experimental Settings

**Datasets**. We evaluate our proposed method on eight datasets including homophilous graphs: Cora, Citeseer, Pubmed , ogbl-ppa, ogbl-collab, and ogbl-citation2  and heterophilic graphs: Chameleon and Squirrel . Please see Appendix A for more details on each dataset.

**Baselines**. We consider a diverse set of baselines include heuristics, embedding methods, GNNs, and GNN4LP methods. This includes: CNs , AA , RA , Shortest Path , Katz , Node2Vec , Matrix Factorization (MF) , MLP, GCN , GAT , SAGE , GAE , SEAL , BUDDY , Neo-GNN , NCN and NCNC , NBFNet , PEG , LPFormer .

Additionally, to comprehensively evaluate the proposed Link-MoE, which integrates multiple link predictors, we design two ensemble baseline methods for comparison. The first method, **Mean-Ensemble**, combines all expert models with uniform weight, ensuring each expert contributes equally to the final prediction. The second method, **Global-Ensemble**, learns a global weight for each expert that is applied when predicting all node pairs. In this approach, each expert contributes to the final prediction based on the learned global weight for all node pairs, allowing for a differentiated influence of each expert based on their performance. See Appendix A.2 for more details on these two methods. Additionally, we compare our method with two other ensemble methods , with the results provided in Appendix H.

**Link-MoE Settings**. In this study, we incorporate both node features and a variety of different heuristics as input features for the gating model. These heuristics include node degree, CN, AA, RA, Shortest Path, Katz, and Personalized PageRank (PPR) . Furthermore, our approach uses a wide range of experts, including NCN, NCNC, Neo-GNN, BUDDY, MLP, Node2Vec, SEAL, GCN, NBFNet, and PEG. NBFNet and PEG are only used for smaller datasets, as they often run into out-of-memory issues on the larger OGB datasets. For the two baselines, Mean-Ensemble and Global-Ensemble, we use the same experts as with Link-MoE. More setting details are in Appendix A.2. For evaluation, we report several ranking metrics including the Hits@K and Mean Reciprocal Rank (MRR). In the main paper, we report the MRR for Cora, Citeseer, and Pubmed and for OGB we use the evaluation metric used in the original study . Results for other metrics are shown in Appendix C.

### Main Results

We present the main results of link prediction for the small datasets and OGB datasets in Table 2. Reported results are mean and standard deviation over 10 seeds. We use "Improv." to denote the relative improvement of Link-MoE over the second best model. From the table, we can have the following observations:

* Link-MoE consistently outperforms all the baselines by a significant margin. For example, it achieves a relative improvement of 18.71% on the MRR metric for the Pubmed dataset and 9.59% on the Hit@100 metric for the ogbl-ppa dataset, compared to the best-performing baseline methods.
* While both the Mean-Ensemble and Global-Ensemble methods also incorporate all the experts used in Link-MoE, their performance is generally subpar in most cases. Although the Global-Ensemble, which learns different weights for each expert, usually outperforms the Mean-Ensemble, it still falls short of the performance of single baseline methods in some scenarios. We attribute this to their inability to adaptively apply different experts to specific node pairs, which demonstrates the effectiveness of the gating model in Link-MoE.
* We further compare against LPFormer , a recent method that attempts to adaptively customize pairwise information to each node pair, resulting in strong performance. We find that our model is able to considerably outperform LPFormer on all datasets. From this we conclude that Link-MoE is better than LPFormer at customizing the pairwise information to each node pair.

Additionally, instead of using all experts, we conducted experiments with only a few experts (i.e., 3 or 4 experts). Furthermore, we also explored a sparse gating strategy , which selectively activates only the Top-K experts for each sample's prediction. The results, presented in Appendix D, demonstrate that these two variants can achieve comparable performance with using all the experts.

We further evaluate the proposed Link-MoE on heterophilic graphs, with results in Appendix F indicating that Link-MoE achieves strong performance. Additionally, we assess Link-MoE in the more challenging HeaRT setting , with results in Appendix J further validating its effectiveness.

    & & **Cora** & **Citeseer** & **Pubmed** & **ogbl-collab** & **ogbl-ppa** & **ogbl-citation2** \\  & Metric & MRR & MRR & MRR & Hits@50 & Hits@100 & MRR \\   & CN & 20.99 & 28.34 & 14.02 & 61.37 & 27.65 & 74.3 \\  & AA & 31.87 & 29.37 & 16.66 & 64.17 & 32.45 & 75.96 \\  & RA & 30.79 & 27.61 & 15.63 & 63.81 & 49.33 & 76.04 \\  & Shortest Path & 12.45 & 31.82 & 7.15 & 46.49 & 0 & \(>\)24h \\  & Katz & 27.4 & 38.16 & 21.44 & 64.33 & 27.65 & 74.3 \\   & Node2Vec\({}^{*}\) & 37.29 \(\) 8.82 & 44.33 \(\) 8.99 & 34.61 \(\) 2.48 & 49.06 \(\) 1.04 & 26.24 \(\) 0.96 & 45.04 \(\) 0.10 \\  & MF & 14.29 \(\) 5.79 & 24.80 \(\) 4.71 & 19.29 \(\) 6.29 & 41.81 \(\) 1.67 & 28.4 \(\) 4.62 & 50.57 \(\) 12.14 \\  & MLP\({}^{*}\) & 31.21 \(\) 7.90 & 43.53 \(\) 7.26 & 16.52 \(\) 4.14 & 35.81 \(\) 1.08 & 0.45 \(\) 0.04 & 38.07 \(\) 0.09 \\   & GCN\({}^{*}\) & 32.50 \(\) 6.87 & 50.01 \(\) 6.04 & 19.94 \(\) 4.24 & 54.96 \(\) 3.18 & 29.57 \(\) 2.90 & 84.85 \(\) 0.07 \\  & GAT & 31.86 \(\) 6.08 & 48.69 \(\) 5.73 & 18.63 \(\) 7.75 & 55.00 \(\) 3.28 & OOM & OOM \\  & SAGE & 37.83 \(\) 7.75 & 47.84 \(\) 6.39 & 22.74 \(\) 5.47 & 59.44 \(\) 1.37 & 41.02 \(\) 1.94 & 83.06 \(\) 0.09 \\  & GAE & 29.98 \(\) 3.21 & 63.33 \(\) 3.14 & 16.67 \(\) 0.19 & OOM & OOM & OOM \\   & SEAL\({}^{*}\) & 26.69 \(\) 5.89 & 39.36 \(\) 4.99 & 38.06 \(\) 5.16 & 63.37 \(\) 0.69 & 48.00 \(\) 5.61 & 86.93 \(\) 0.43 \\  & BDUD\({}^{*}\) & 24.00 \(\) 4.40 & 59.48 \(\) 8.96 & 23.98 \(\) 5.11 & 64.59 \(\) 0.46 & 47.33 \(\) 1.96 & 87.86 \(\) 0.18 \\  & Neo-GNN\({}^{*}\) & 22.65 \(\) 2.60 & 53.97 \(\) 5.88 & 31.45 \(\) 3.17 & 66.13 \(\) 0.61 & 48.45 \(\) 1.01 & 83.54 \(\) 0.32 \\  & NCN\({}^{*}\) & 32.93 \(\) 3.80 & 54.97 \(\) 6.03 & 35.65 \(\) 4.60 & 63.86 \(\) 0.51 & 62.63 \(\) 1.15 & 89.27 \(\) 0.05 \\  & NCN\({}^{*}\) & 29.01 \(\) 3.83 & 64.03 \(\) 3.67 & 25.70 \(\) 4.48 & 65.97 \(\) 1.03 & 62.61 \(\) 0.76 & 89.82 \(\) 0.43 \\  & NBFNet\({}^{*}\) & 37.69 \(\) 3.97 & 38.17 \(\) 3.06 & **44.73 \(\) 2.12** & OOM & OOM & OOM \\  & PEG\({}^{*}\) & 22.76 \(\) 1.84 & 56.12 \(\) 6.62 & 21.05 \(\) 2.85 & 49.02 \(\) 2.99 & OOM & OOM \\  & LPFormer & 39.42 \(\) 5.78 & **65.42 \(\) 4.65** & 40.17 \(\) 1.92 & **68.14 \(\) 0.51** & **63.32 \(\) 0.63** & **89.81 \(\) 0.13** \\   & Mean-Ensemble & **39.74 \(\) 4.70** & 53.73 \(\) 2.83 & 38.54 \(\) 5.40 & 66.82 \(\) 0.40 & 26.70 \(\) 3.92 & 89.55 \(\) 0.55 \\  & Global-Ensemble & 38.13 \(\) 4.60 & 53.96 \(\) 2.79 & 37.63 \(\) 6.54 & 67.08 \(\) 0.34 & 60.67 \(\) 1.44 & **90.72 \(\) 0.72** \\   & Link-MoE & **44.03 \(\) 2.28** & **67.49 \(\) 0.30** & **53.10 \(\) 0.24** & **71.32 \(\) 0.99** & **69.39 \(\) 0.61** & **91.25 \(\) 0.02** \\  & Improv. & 10.80\% & 3.16\% & 18.71\% & 4.67\% & 9.59\% & 0.58\% \\   

Table 2: Main results on link prediction (%). Highlighted are the results ranked **first**, **second**, and third. We use * to highlight the experts we used in Link-MoE. Notably, NBFNet and PEG are not used as experts on OGB datasets due to their OOM issues.

### The Effectiveness of Different Heuristics in Gating

The addition of the gating model enables Link-MoE to significantly surpass both the Mean-Ensemble and Global-Ensemble methods. This improvement underscores the pivotal role of the gating model, which intelligently leverages heuristic information to enhance the overall performance. In this subsection, we delve into the impact of various heuristics utilized by the gating model in Link-MoE. Specifically, there are three types of heuristics: local structure proximity (e.g., CN, AA, RA), global structure proximity (e.g., Shortest Path, Katz), and feature proximity. We design experiments to isolate the effect of specific types of heuristics by including them either individually or in groups. For instance, utilizing only feature proximity is referred to as 'OnlyFeat', combining local and global structure proximities is labeled 'OnlyStruct', employing only local structure proximity is denoted 'OnlyLocalStruct', and using only global structure proximity is marked 'OnlyGlobalStruct'. Additionally, the 'All' is used to indicate leveraging all heuristics. The results on Pubmed and ogbl-ppa datasets are shown in Figure 6. From the experimental results, several observations can be made: **(1)** Using only the feature proximity (OnlyFeat) or only the global structural proximity (OnlyGlobalStruct) typically yields lower performance. **(2)** Combining the local and global structure proximity (OnlyStruct) tends to outperform using either one alone. **(3)** The effectiveness of feature proximity varies between datasets. On Pubmed, it is beneficial to include it but not on ogbl-ppa. This discrepancy could stem from the relative importance of feature information in each dataset, as suggested by the very poor performance of MLP on ogbl-ppa, whose Hits@100 is only around 0.45. Moreover, we explore different inputs for the gating model, the results are presented in Appendix I, which highlights the rationality of the design of our gating model.

### The Importance of Different Experts

In the previous sections, we incorporated all the selected experts in Link-MoE. This subsection aims to explore the impact of each expert's removal on the framework's performance. We conducted experiments on the ogbl-collab and ogbl-ppa datasets, utilizing Hits@50 as the metric for evaluation. The results are presented in Figure 7, where the x-axis indicates the experts removed for each trial. We observe that the removal of individual experts does not significantly impact the performance of Link-MoE on both the ogbl-collab and ogbl-ppa datasets. This phenomenon suggest that Link-MoE possesses an adaptive capability to compensate for the absence of certain models by effectively utilizing other available experts.

### Analysis of the Gating Weights

In this subsection, we explore the mechanism by which the gating model allocates weights to experts based on the heuristics of different node pairs. Similar to Section 3, we categorize the test node pairs into distinct groups according to different heuristics. Subsequently, for each group, we compute the average weights assigned to each expert by the gating model. The results based on Common Neighbors for ogbl-collab and ogbl-ppa are shown in Figure 8. We can have some interesting findings: **(1)**: For the ogbl-collab dataset, when the node pair doesn't have common neighbor, the gating model usually assigns a large weight to the MLP model, which aligns the analysis in Section 3 that the MLP can perform well when there is no CN on ogbl-collab. However, For the ogbl-ppa dataset, when there is no common neighbor, the gating model would assign a high weight to NCNC. This preference arises because node features hold less significance in the ogbl-ppa dataset and NCNC can leverage multi-hop common neighbor information. **(2)**: As the number of common neighbors increases, the gating model increasingly allocates more weight to the NCN. This shift reflects the NCN's capability to efficiently capture and utilize common neighbor information. **(3)**: Not every expert model contributes much to the prediction. This selective engagement is attributed to the overlapping capabilities of certain models. For instance, both Neo-GNN and NCNC are capable of exploiting multi-hop information. In such cases, the gating model opts for one over the other to avoid redundancy and optimize prediction efficacy. This phenomenon is also consistent with the results in Section 5.4 that removing one expert doesn't affect the overall performance. The analysis of gating weights on heterophilic datasets can be found in Appendix F.

While Link-MoE can successfully leverage heuristics to select appropriate experts for different node pairs, we recognize substantial room for further enhancements. For instance, the observed overlapping ratio between Neo-GNN and NCNC on the ogbl-collab dataset is not very high, as shown in Figure 3, even if they exploit similar heuristics. But in Link-MoE, Neo-GNN has very low weights on the ogbl-collab dataset. This observation underscores the vast potential for advancing MoE applications in link prediction, a direction we intend to explore in future work.

## 6 Conclusion

In this study, we explored various heuristics and GNN4LP models for link prediction. Based on the analysis, a novel MoE model Link-MoE is designed to capitalize on the strengths of diverse expert models for link prediction. The extensive experiments underscore the exceptional performance of Link-MoE in link prediction, validating the rationale behind its design. Furthermore, we also showcase the substantial potential of MoE models for link prediction.