# Are More LM Calls All You Need? Towards the Scaling Properties of Compound AI Systems

Lingjiao Chen\({}^{1}\), Jared Davis\({}^{1}\), Boris Hanin\({}^{3}\), Peter Bailis\({}^{1}\),

Ion Stoica\({}^{2}\), Matei Zaharia\({}^{2}\), James Zou\({}^{1}\)

Stanford University\({}^{1}\)

University of California, Berkeley\({}^{2}\)

Princeton University\({}^{3}\)

###### Abstract

Many recent state-of-the-art results in language tasks were achieved using compound systems that perform multiple Language Model (LM) calls and aggregate their responses. However, there is little understanding of how the number of LM calls - _e.g.,_ when asking the LM to answer each question multiple times and taking a majority vote - affects such a compound system's performance. In this paper, we initiate the study of scaling properties of compound inference systems. We analyze, theoretically and empirically, how the number of LM calls affects the performance of Vote and Filter-Vote, two of the simplest compound system designs, which aggregate LM responses via majority voting, optionally applying LM filters. We find, surprisingly, that across multiple language tasks, the performance of both Vote and Filter-Vote can first increase but then decrease as a function of the number of LM calls. Our theoretical results suggest that this non-monotonicity is due to the diversity of query difficulties within a task: more LM calls lead to higher performance on "easy" queries, but lower performance on "hard" queries, and non-monotone behavior can emerge when a task contains both types of queries. This insight then allows us to compute, from a small number of samples, the number of LM calls that maximizes system performance, and define an analytical scaling model for both systems. Experiments show that our scaling model can accurately predict the performance of Vote and Filter-Vote systems and thus find the optimal number of LM calls to make.

## 1 Introduction

Compound AI systems that perform multiple Language Model (LM) calls and aggregate their responses are increasingly leveraged to solve language tasks [ZKC\({}^{+}\)24, DLT\({}^{+}\)23, TAB\({}^{+}\)23, TWL\({}^{+}\)24, WWS\({}^{+}\)22]. For example, Google's Gemini Ultra achieved state-of-the-art results on MMLU using a CoT@32 voting strategy: the LM is called 32 times, and then the majority vote of the 32 responses is used in the final response [TAB\({}^{+}\)23]. Other compound systems filter responses using an LM before selecting one [Alp23].

A natural question is, thus, how does scaling the number of LM calls affect the performance of such compound systems? This question is under-explored in research, but characterizing the scaling dynamics is crucial for researchers and practitioners to estimate how many LM calls are needed for their applications and allocate computational resources aptly. Understanding these scaling dynamics is also helpful in recognizing the limits of compound inference strategies.

As a first step towards answering this question, we study the scaling properties of two popular compound system designs, Vote and Filter-Vote. Vote aggregates multiple proposed answers via majority vote, as in Gemini's CoT@32. Filter-Vote leverages a filter before performing a majorityvote, similar to AlphaCode 2 . While the inference system design space is broad, we focus on Vote and Filter-Vote for two reasons. First, they have already been used in real applications, such as Gemini's CoT@32 strategy. Second, despite their simplicity, they exhibit nontrivial scaling properties. Specifically, although one might expect their performance to monotonically increase as more LM calls are invoked, we have identified a surprising phenomenon, across multiple language tasks, exhibited by these systems: growing the number of LM calls initially improves performance but then degrades it, as shown in Figure 1.

This surprising effect motivates our theoretical study of Vote and Filter-Vote, which explains this non-monotone effect through the diversity of _query difficulty_ in a given task (see Figure 2 and Theorem 2). At a high level, our results show that more LM calls continuously lead to better performance on "easy" queries and worse performance on "hard" queries. When a task is some mixture of "easy" and "hard" queries, the non-monotone aggregate behavior emerges. Formally, a query is easy if a compound system with infinitely many LM calls gives a correct answer and hard otherwise. We provide mathematical conditions under which a query is easy or difficult for Vote or Filter-Vote. We also derive a performance scaling model for both systems that explicitly models query difficulties, and present an algorithm that lets users fit the scaling law's parameters using a small number of samples. In experiments with GPT-3.5, we show that these algorithms can let us estimate the scaling behavior for various problems and identify the optimal number of calls to make to the LM to maximize accuracy. Our main contributions are:

In a nutshell, our work shows that more LM calls do not necessarily improve the performance of compound AI systems and that it is possible, at least in some cases, to predict how the number of LM calls affects AI systems' performance and thus decide the optimal number of LM calls for a given task. Our work focuses on tasks with a fairly small number of possible responses (e.g., multiple-choice questions) that support a majority vote, but tasks with many valid outputs, such as

Figure 1: The scaling behavior of Vote and Filter-Vote. Interestingly, their performance is often a non-monotonic function of the number of LM calls. For example, as the number LM calls increases, Vote’s performance initially increases but then decreases, while Filter-Vote’s performance initially decreases but then increases on the MMLU PHYSICS dataset.

chat, remain under-explored. We have released the code and datasets1 used in this paper, and hope to excite more research regarding the scaling properties of compound AI systems.

## 2 Related Work

Neural Scaling Laws.There has been extensive research on how the training parameters affect the performance of neural language models [KMH\({}^{+}\)20, SGS\({}^{+}\)22, BDK\({}^{+}\)21, MLP\({}^{+}\)23, IPH\({}^{+}\)24]. Among others, the model loss has been empirically shown to follow a power law as the number of model parameters and training tokens [KMH\({}^{+}\)20]. Researchers have also proposed theories to explain the empirical scaling laws [BDK\({}^{+}\)21]. By contrast, recent work has found that scaling up the model parameters leads to performance decay on certain tasks [MLP\({}^{+}\)23]. To the best of our knowledge, there is no study on how the number of LM calls affects the performance of a compound system, which is complementary to scaling laws on training parameters and data set sizes.

Compound Systems using LMs.Many inference strategies that perform multiple model calls have been developed to advance performance on various language processing tasks [XCG\({}^{+}\)23, DLT\({}^{+}\)23, TAB\({}^{+}\)23, TWL\({}^{+}\)24, WWS\({}^{+}\)22, CZZ23, ZKAW23, SPW23]. For example, Gemini reaches state-of-the-art performance on MMLU via its CoT@32 majority voting scheme [TAB\({}^{+}\)23]. Self-consistency [TWWS\({}^{+}\)22] boosts the performance of chain-of-thought via a majority vote scheme over multiple reasoning paths generated by PaLM-540B. Finally, AlphaCode 2 [Alp23] matches the 85th percentile of humans in a coding contest regime by generating up to one million samples per problem via an LM and then filtering the answer set down. While these approaches are empirically compelling, there has been little systematic study of how the number of LM calls affects these systems' performance, and how it should be tuned for a given application.

Compound System Evaluation.Compound AI systems are increasingly evaluated in traditional benchmarks [CKB\({}^{+}\)21, HBK\({}^{+}\)21, TVCM18, NWD\({}^{+}\)19] as well as domain-specific new datasets [KBGA24, MMA\({}^{+}\)24, KCM\({}^{+}\)23] and the agent environments [LYZ\({}^{+}\)23, SYC\({}^{+}\)20, JYW\({}^{+}\)24]. We refer the interested readers to a survey for more details [CWW\({}^{+}\)24]. Existing papers focus on obtaining a single metric of a given system, while our goal is to understand how the a compound system's performance is affected by its parameters (e.g., # of LM calls).

Figure 2: Performance breakdown on MMLU PYHSICS. As the number of LM calls increases, Vote and Filter-Vote perform increasingly better on easy queries but increasingly worse on difficult ones.

``` Input: A user query \(x\), # gen responses \(K\) Output: A response \(\)
1 Sample \(_{1},_{2},,_{K}\) i.i.d. from \(\);
2 Generate \(z_{k}=G(x,_{k}),k=1,,K\);
3 Set \(_{K}=V(z_{1},,z_{K})\);
4 Return \(_{K}\) ```

**Algorithm 1**Vote.

## 3 Inference System Designs

In this paper, we focus on two simple and natural inference system designs: Vote and Filter-Vote. Vote is inspired by and resembles several real-world compound AI systems, such as self-consistency , Medprompt , and Gemini CoT@32 strategy , while Filter-Vote represent many other real-world compound AI systems including AlphaCode 2  and AlphaGeometry . Note that this paper focuses on tasks with a small number of possible answers.

Building Blocks.Vote and Filter-Vote rely on three building blocks, a generator \(G(,)\), a majority voter \(V()\), and a filter \((,,)\). The generator \(G(,)\) takes a user query \(x\) and \(\) as inputs and produces a candidate answer and an explanation. Here, instantiations of \(\) are a design choice of users and can encode many generation strategies. For example, even with a single fixed LM, diverse generations may be achieved by using a non-zero temperature and different prompt wordings or few-shot examples for each call to the LM. If \(\) contains different LMs, then this system definition can also represent LM ensembles. The majority voter \(V\) returns the mode of its input, i.e., \(V(z_{1},z_{2},,z_{K})*{arg\,max}_{a A}_{k =1}^{K}_{z_{k}=a}\), and breaks ties arbitrarily. Here, \(A\) is the space of all possible answers. Finally, the filter \((,)\) takes the user query and multiple candidate answers as input, and only returns the subset that an LM believes is correct.

Vote.Given a user query \(x\), Vote (i) first creates \(K\) candidate answers by calling the generator \(G\), and then (ii) uses the majority voter \(V\) to choose one as the final response \(_{K}\). The details are given in Algorithm 1.

Filter-Vote.Given a user query, Filter-Vote (i) first generates multiple candidate answers, (ii) removes a few candidate answers by the filter \(\), and (iii) then uses the majority voter \(V\) to choose one from the remaining answers as the final response. If all answers are removed by the filter, then \(V\) is applied on the original candidate answers. Algorithm 2 gives the formal description.

``` Input: A user query \(x\), # gen responses \(K\) Output: A response \(\)
1 Sample \(_{1},_{2},,_{K}\) i.i.d. from \(\);
2 Generate \(z_{k},e_{k}=G(x,_{k}),k=1,,K\);
3 Generate \(w_{k}=(x,z_{k},e_{k}),k=1,,K\);
4if\(_{k}w_{k}\)=0then
5 Set \(_{K}=V(z_{1},,z_{K})\);
6else
7 Set \(_{K}=V(\{ z_{k} w_{k}=1\|\})\);
8 Return \(_{K}\) ```

**Algorithm 2**Filter-Vote.

## 4 Analytical Model of Scaling Behavior

Now we present our analytical performance model of Vote and Filter-Vote strategies. Specifically, we are interested in understanding the behavior of \(F(K;D)[_{K}=y]\), where the expectation is over \(D\) and the candidate responses. All notations are summarized in Table 1.

### When do more LM calls lead to an increase or decrease in performance?

Our first key insight is that individual query difficulty is crucial in LM calls' effects. To see this, let us first introduce query difficulty indicator.

**Definition 1**.: _Given a user query \(x\), \(d(x)\) is called an query difficulty indicator if_

\[_{K}F(K,x)=0&d(x)>0,\\ 1&d(x)<0\]Intuitively, a positive query difficulty indicator implies the query is difficult, i.e., infinitely many LM calls lead to an incorrect final answer, and a negative value implies the query is easy, i.e., infinitely many LM calls eventually give a correct final answer. For simplicity, we assume that the limit of \(F(K,x)\) is always either 0 or 1 for Vote and Filter-Vote, i.e., eventually the answer is correct or incorrect. Also note that \(d(x)\) is scale-invariant, i.e., if \(d(x)\) is an item difficulty indicator, then for any positive scalar \(>0\), \( d(x)\) is also a difficulty indicator. We will call a query \(x\) difficult (easy) if \(d(x)>0\) (\(d(x)<0\)). We give two concrete instantiations as follows.

**Lemma 1**.: _For Vote, \(d_{V}(x)_{a y}[G(x,)=a]-[G(x,)=y]\) is an query difficulty indicator. For Filter-Vote, denote \(G(x,)=[G_{1}(x,),G_{2}(x,)]\). Then \(d_{F}(x)_{a y}[G_{1}(x,)=a|(x,G_{1}(x,), G_{2}(x,))=1]-[G_{1}(x,)=y|(x,G_{1}(x,),G_{2}(x,))=1]\) is a query difficulty indicator._

  Symbol & Meaning \\  \(x\) & an input query \\  \(y\) & the correct answer \\  \(K\) & the number of LM calls \\  \(z_{k}\) & the output by one LM call \\  \(_{K}\) & the output by an inference system using \(K\) LM calls \\  \(D/D_{Tr}\) & test dataset/train dataset \\  \(A\) & answer space \\  \(\) & fraction of easy queries \\  \(p_{1}\) & probability of \(z_{k}\) being correct for easy queries \\  \(p_{2}\) & probability of \(z_{k}\) being correct for difficult queries \\  \(F(K;D)\) & Accuracy of an Inference System with \(K\) LM calls per query on \(D\) \\  \(G(K;D)\) & Analytical Performance Model (to approximate \(F(K;D)\)) \\  

Table 1: Notations.

Figure 3: How the query difficulties shape the landscape of a one-layer Voting Inference System’s performance. Informally, if the overall task is “easy” (\(p_{1}+p_{2}>1\)), but the fraction of “hard” queries is large (\(<1-\)), then as the number of LM calls increases, the Voting Inference Systems’ performance increases first but then decreases. We call such a landscape a “inverse U shape”. Similarly, if the overall task is “hard” (\(p_{1}+p_{2}<1\)), but the fraction of “hard” queries is small (\(>1-\)), then enlarging the number of LM calls leads an initial decrease and then increase. Such a landscape is called a “U shape”. When \(\) is large, the U-shape is less likely to occur while the inverse U-shape becomes more common. Smaller \(\) leads to an opposite trend.

Here, \(d_{V}(x)>0\) indicates that an incorrect answer is more likely to be generated than the correct one, hence the query is difficult. Similarly, \(d_{F}(x)>0\) implies that an incorrect answer is more likely to be kept in the filtered answer set.

More LM calls elicit higher performance on easy queries, but lower performance on difficult queries. Therefore, the performance, \(F(K;D)\), is more difficult to characterize when the data set \(D\) contains both easy and difficult queries. Here, we study Vote on a special case of \(D\) to understand how the difficulty impacts the performance function \(F(K;D)\).

A case study on a specific dataset.Let us consider a specific dataset \(D_{,p_{1},p_{2}}\) with answer space cardinality \(|A|=2\). Here, \(\) queries in \(D\) are \(x_{1}\) such that \(Pr[G(x_{1},)=y]=p_{1}>\), and \(1-\) queries are \(x_{2}\) such that \(Pr[G(x_{2},)=y]=p_{2}<\). The following theorem qualitatively characterizes the performance of Vote on this dataset.

**Theorem 2**.: _Let \(t(1-p_{2})(-p_{2})}{p_{1}(1-p_{1})(p_{1}- )}+1\). If \(p_{1}+p_{2} 1\) and \(K\) is odd, then \(F(K;D_{,p_{1},p_{2}})\)_

* _increases monotonically, if_ \(p_{1}+p_{2}>1\) _and_ \( 1-\)__
* _decreases monotonically, if_ \(p_{1}+p_{2}<1\) _or_ \( 1-\)__
* _increases and then decreases, if_ \(p_{1}+p_{2}>1\) _and_ \(<1-\)__
* _decreases and then increases, if_ \(p_{1}+p_{2}<1\) _and_ \(>1-\)__

Theorem 2 precisely connects the query difficulty with the performance landscape. Here, \(t\) is a constant that only depends on \(p_{1}\) and \(p_{2}\), i.e., the probability of an LM's generation being correct on easy and hard queries, respectively. Intuitively, \(t\) quantifies the difficulty similarity between the easy and hard queries: it becomes larger if the easy queries are more difficult (\(p_{1}\) is smaller) or the hard queries are less difficult (\(p_{2}\) is larger). Interestingly, it suggests that, for some query difficulty distribution, a non-monotone effect of the number of LM calls is expected. Informally, if the overall task is "easy" (\(p_{1}+p_{2}>1\)), but the fraction of "hard" queries is large (\(<1-\)), then as the number of LM calls increases, the Voting Inference Systems' performance increases first but then decreases. We call such a landscape a "inverse U shape". Similarly, if the overall task is "hard" (\(p_{1}+p_{2}<1\)), but the fraction of "hard" queries is small (\(>1-\)), then enlarging the number of LM calls leads an initial decrease and then increase. Such a landscape is called a "U shape". This well explains the U-shape of Inference Systems' performance shown in Figure 1.Figure 3 visualizes the effects of query difficulty on the performance landscape in more detail.

### What is the analytical scaling model?

Now we derive an analytical scaling model for both Vote and Filter-Vote. Noting that the performance is the average of \(F(K,x)\) for each \(x\) in the dataset, the key challenge is identifying the shape of \(F(K,x)\) for easy and difficult queries. Let us first consider the special case \(|A|=2\), where we can obtain a close form result for Vote.

**Theorem 3**.: _If \(|A|=2\), then on any query \(x\), the performance of Vote is \(F(K,x)=I_{(x)}{2}}(,)\), where \(I_{x}(a,b)_{0}^{x}t^{a-1}(1-t)^{b-1}dt/_{0}^{1}t^{a-1}(1-t)^ {b-1}dt\) is the regularized incomplete beta function._

Thus, for Vote with \(|A|=2\), \(F(K,D)=_{x D}[I_{(x)}{2}}(, {2})]\).

How about Filter-Vote and the general answer space? Admittedly, an exact scaling model is challenging to obtain. Instead, we give an approximation model inspired by the special case. We first note that \(F(K,x)\) should be treated separately for difficult and easy queries: after all, as a function of \(a\), the incomplete beta function \(I_{x}(a,a)\) monotonically increases/decreases if \(x>\) (\(x<\)). Second, \(I_{x}(a,a)\) grows roughly exponentially in \(x\), and this trend should hold for general answer space and for both Vote and Filter-Vote. Hence, we propose the following scaling model

\[G(K,x)e^{-c_{1}(x)K-c_{2}(x)+c_{3}(x)},& {if }d(x)>0,\\ 1-e^{-c_{1}(x)K-c_{2}(x)+c_{3}(x)},&d(x)<0\]where constants \(c_{1}(x)>0,c_{2}(x)>0,c_{3}(x)\) do not depend on the number of LM calls \(K\). Therefore, our analytical performance scaling model is \(G(K,D)=_{x D}[G(K,x)]\). In practice, one can use a training dataset \(D_{Tr}\) to fit the parameters in \(G(K,D)\). Note that given a query \(x\), the parameters \(c_{i}(x)\) can be different for Vote and Filter-Vote. In particular, if the filter is of high quality, then the performance should converge quickly, and thus the constants \(c_{i}()\) are likely to be larger. Otherwise, the performance should scale slower, and thus the constants \(c_{i}()\) should be smaller. We will show in the experiments that \(G(K,D)\) matches the empirical performance \(F(K,D)\) accurately.

### How to optimize the number of LM calls?

In general, one can always (i) fit the analytical scaling model \(G(K,D)\), and (ii) then use \(_{K}G(K,D)\) to obtain the optimal number of LM calls. Interestingly, we show that for a special case, we can derive the optimal number of LM calls.

**Theorem 4**.: _If \(p_{1}+p_{2}>1\) and \(<1-\), then the number of LM calls \(K^{*}\) that maximizes \(F(K,D_{,p_{1},p_{2}})\) for Vote (up to rounding) is_

\[K^{*}=2-1}{1-2p_{2}}}{(1-p_{2})}{p_{1}(1-p_{1})}}\]

The optimal number of LM calls depends on the query difficulty. For example, \(K^{*}\) will be larger if \(\) grows (up to \(1-\)). That is, if there are more "easy" queries than "difficult" queries, then more LM calls should be adopted.

## 5 Experiments

We compare the empirical performance of Vote and Filter-Vote and the performance predicted by our analytical scaling model. Our goal is three-fold: (i) validate that there are cases where more LM calls do not monotonically improve the performance of these Inference Systems, (ii) justify that the number of LM calls has opposite effects on easy and difficult queries, and (iii) explore whether our analytical scaling model can accurately predict the performance of Vote and Filter-Vote, and thus guide the design of Inference Systems such as optimizing number of LM calls.

Datasets and LM.To understand the scaling properties of Vote and Filter-Vote, we conduct systematical experiments on both (i) real-world datasets and (ii) synthetic datasets with controlled query difficulties. Specifically, the real-world datasets include MMLU PHYSICS , TRUTH-FULQA , GPQA , and AVERTIEC . MMLU PHYSICS contains high school physics questions extracted from the original MMLU dataset. TRUTHFULQA measures whether a language model is truthful in generating answers to questions. GPQA queries are generated by experts in biology, physics, and chemistry. Each query in AVERTIEC is a claim and the goal is to verify its correctness. Each query is prompted as a multiple-choice question for objective evaluation. The details of these datasets and prompts can be found in the Appendix. The synthetic dataset is \(D_{,p_{1},p_{2}}\) as introduced in Section 3, and we study the scaling behavior by varying the parameters. We use GPT-3.5-turbo-0125 on the real-world datasets. All experiments are averaged over 1,000 runs.

Non-monotonic Scaling Behavior.We start by understanding how the number of LM calls affects the performance of Vote and Filter-Vote empirically. As shown in Figure 1, we observe a non-monotonic behavior: more LM calls can sometimes lead to a drop in performance! This underscores the importance of scaling performance modeling.

A case study on AVERTIEC.Now let us perform a case study on the AVERTIEC dataset to understand the intriguing behavior better. In particular, we use the deployment partition of AVERTIEC , which contains 500 fact verification questions. The goal is to determine if a given claim should be (A) refused, (B) supported, or there is (C) conflicting evidence or (D) not enough evidence. We evaluate the performance of both Vote and Filter-Vote on AVERTIEC. In addition, we fit our analytical scaling model with 2, 5, 10, 20, 50, 100 LM calls. Then we use it to predict the performance of Vote and Filter-Vote using 100 randomly drawn number of LM calls.

As shown in Figure 4, there are several intriguing behaviors. First, more LM calls do not always lead to better performance. In fact, the performance of both Vote and Filter-Vote increases first but then decreases as the number of LM calls increases from 2 to 1000 (Figure 4(a)). The performance breakdown (shown in Figure 4(b)) gives a natural explanation. More LM calls lead to higher performance when a query is relatively difficult (\(d_{F}(x)>0\) for Filter-Vote and \(d_{V}(x)>0\) for Vote), but lower performance when a query is relatively easy (\(d_{F}(x)<0\) for Filter-Vote and \(d_{V}(x)<0\) for Vote). We also observe a high correlation between the performance predicted by our proposed analytical scaling model and the empirical performance, as depicted in Figure 4 (c). This implies the optimal number of LM calls can also be accurately predicted by our scaling model. Finally, we also give examples of one easy query and one difficult query in Figures 4 (d). On the easy example, one LM call gives the correct answer with a probability higher than any other answer (67%). Thus, more LM calls eventually give the correct answer. On the difficult query, the probability of the correct answer (34%) is lower than that of an incorrect answer (56%). Thus, Vote with more LM calls eventually always generates a wrong answer.

Scaling model performance on real-world datasets.Next we study how our analytical scaling model generalizes to other real-world datasets. In particular, we fit our analytical model with 2, 5, 10, 50, and 100 LM calls, and then use the scaling model to predict the performance on 100 randomly drawn number of LM calls.

Figure 5 shows the correlation between the predicted and empirical performance on three real-world datasets, namely, MMLU PHYSICS, TRUTHFULQA, and GPQA. We first note that the best performance of the Filter-Vote system is not necessarily better than that of the Vote system. Indeed,

Figure 4: A case study on the AVERITEC dataset. (a) As more LM calls are invoked, the overall performance of Vote and Filter-Vote both initially increases but then decreases. (b) This U-shape can be perfected explained by the opposite effects on easy and difficult queries: More LM calls lead to higher performance on easy queries, but lower performance on difficult ones. (c) Our analytical scaling model accurately predicts the empirical performance. (d) Examples of an easy query and a difficult one. One LM call gives the correct answer with probability higher than any other answers (67%), and thus Vote with more calls eventually gives the correct answer. For the difficult query, the probability of the correct answer (34%) is lower than that of an incorrect answer (56%). Thus, Vote with more LM calls eventually always generates a wrong answer.

on TRUTHFULQA, the Vote system's best performance is higher than that of the Filter-Vote system. This further highlights the importance of performance prediction, even if there is no budget constraint. Second, we observe that our scaling model can predict the performance of both Vote and Filter-Vote systems accurately across all these real-world datasets. This is because our scaling model carefully takes into account both difficult and easy queries and thus reflects the non-monotone behavior. Interestingly, the prediction accuracy on the Vote system is higher than that on the Filter-Vote system. This is perhaps because the Filter-Vote system generalizes the Vote system and thus its scaling behavior can be more complex.

Difficulty distribution determines whether more LM calls help.To systematically understand how the query difficulty affects Inference Systems' performance landscape, we synthesize a bi-level difficult dataset \(D_{,p_{1},p_{2}}\), vary (i) the fraction of the easy subset \(\) and (ii) the query difficulty \(p_{1},p_{2}\), and then study the scaling performance of Vote. When it is clear from the context, we may also call \((p_{1},p_{2})\) query difficulty.

As shown in Figure 6, we observe that query difficulty plays an important role in the number of LM calls' effects. For example, when the difficulty parameter is \((0.85,0.1)\) and the fraction of easy queries is \(=0.6\), Vote's performance is monotonically increasing as the number of LM calls grows. However, adding more hard queries by changing the fraction \(=0.4\) changes the trend: the performance goes down first for small call numbers and then goes up for larger numbers of calls. It is also interesting to notice an inverse "U"-shape. For example, when query difficulty is \((0.85,0.4)\), there is a clear U-shape performance. Overall, this justifies that (i) there are cases where more LM calls is not beneficial, and (ii) the diversity of query difficulty critically determines these cases.

Analytical scaling model predicts the optimal number of LM calls.Identifying the optimal number of calls is an important implication of the scaling properties. Here, we compare the optimal number of calls for Vote predicted by our analytical model and the optimal numbers empirically observed on the bi-level difficult dataset \(D_{,p_{1},p_{2}}\). As summarized in Table 2 (in the Appendix), the predicted optimal number is exactly the observed optimal number of LM calls, for all query difficulties evaluated. This validates the assumptions made by Theorem 4.

## 6 Conclusion

In this paper, we systematically study how the number of LM calls affects the performance of two natural inference strategy designs: majority voting (Vote) and majority voting after filtering results with an LM (Filter-Vote). We find that increasing the number of LM calls can lead to non-monotone behavior, _e.g.,_ first increasing performance and then decreasing it. We offer theoretical analysis

Figure 5: How the proposed analytical scaling model performs on other real-world datasets, namely, (a) MMLU PHYSICS, (b) TRUTHFULQA, and (c) GPQA. Here, we fit the scaling model with 2, 5, 10, 50, and 100 LM calls, and then use the scaling model to predict the performance on 100 randomly drawn number of LM calls. Overall, we observe that our analytical model can predict the performance of the two compound systems accurately. Interestingly, the prediction accuracy on the Vote system is relatively higher than that on the Filter-Vote system. This is expected as the Filter-Vote system generalizes the Vote system and thus its scaling behavior can be more complex.

that attributes this phenomenon to the diversity of query difficulties within a task, and conduct experiments to validate our analysis. Furthermore, we show how to estimate the optimal number of LM calls to make for a given task using a small number of queries to fit the parameters of our analytical model, thus helping practitioners optimize their system designs. Overall, our study shows that more LM calls are not necessarily better and underscores the importance of compound system design. To stimulate further research, we have released our code and datasets, available at https://github.com/lchen001/CompoundAIScalingLaws. We hope our findings and analysis will inspire more research into maximizing the effectiveness of inference time compute.