# IPM-LSTM: A Learning-Based Interior Point Method for Solving Nonlinear Programs

Xi Gao

School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, China

Jinxin Xiong

Akang Wang

Qihong Duan

School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, China

Jiang Xue

Qingjiang Shi

###### Abstract

Solving constrained nonlinear programs (NLPs) is of great importance in various domains such as power systems, robotics, and wireless communication networks. One widely used approach for addressing NLPs is the interior point method (IPM). The most computationally expensive procedure in IPMs is to solve systems of linear equations via matrix factorization. Recently, machine learning techniques have been adopted to expedite classic optimization algorithms. In this work, we propose using Long Short-Term Memory (LSTM) neural networks to approximate the solution of linear systems and integrate this approximating step into an IPM. The resulting approximate NLP solution is then utilized to warm-start an interior point solver. Experiments on various types of NLPs, including Quadratic Programs and Quadratically Constrained Quadratic Programs, show that our approach can significantly accelerate NLP solving, reducing iterations by up to \(60\%\) and solution time by up to \(70\%\) compared to the default solver.

## 1 Introduction

Constrained _Nonlinear Programs_ (NLPs) represent a category of mathematical optimization problems in which the objective function, constraints, or both, exhibit nonlinearity. Popular NLP variants encompass _Quadratic Programs_ (QPs), _Quadratically Constrained Quadratic Programs_ (QCQPs), semi-definite programs, among others. These programs are commonly classified as convex or non-convex, contingent upon the characteristics of their objective function and constraints. The versatility of NLPs allows for their application across a wide array of domains, including power systems (Conejo and Baringo, 2018), robotics (Schaal and Atkeson, 2010), and wireless communication networks (Chiang, 2009).

The primal-dual _Interior Point Method_ (IPM) stands as a preeminent algorithm for addressing NLPs (Nesterov and Nemirovskii, 1994; Nocedal and Wright, 1999). It initiates with an infeasible solution positioned sufficiently far from the boundary. Subsequently, at each iteration, the method refines the solution by solving a system of linear equations, thereby directing it towards the optimal solution. Throughout this iterative process, the algorithm progresses towards feasibility and optimality while keeping the iterate well-centered, ultimately converging to the optimal solution. However, a notable computational bottleneck arises during the process of solving linear systems, necessitating matrix decomposition with a runtime complexity of \((n^{3})\).

Recently, the _Learning to Optimize_ (L2O) (Bengio et al., 2021; Chen et al., 2024; Gasse et al., 2022) paradigm has emerged as a promising methodology for tackling various optimization problems,spanning unconstrained optimization (Chen et al., 2022a), linear optimization (Chen et al., 2022b; Li et al., 2024), and combinatorial optimization (Baker, 2019; Gasse et al., 2022; Han et al., 2023). Its ability to encapsulate common optimization patterns renders it particularly appealing. Noteworthy is the application of learning techniques to augment traditional algorithms such as the gradient descent method (Andrychowicz et al., 2016), simplex method (Liu et al., 2024), and IPM (Qian et al., 2024).

We observe that existing works on learning-based IPMs primarily concentrate on solving LPs (Qian et al., 2024). Motivated by the robustness and efficiency of IPMs for general NLPs, we pose the following question:

_Can we leverage L2O techniques to expedite IPMs for NLPs?_

In this study, we propose the integration of _Long Short-Term Memory_ (LSTM) neural networks to address the crucial task of solving systems of linear equations within IPMs, introducing a novel approach named IPM-LSTM. An illustration of the IPM-LSTM approach is depicted in Figure 1. Specifically, we substitute the conventional method of solving linear systems with an unconstrained optimization problem, leveraging LSTM networks to identify near-optimal solutions for the latter. We integrate a fixed number of IPM iterations into the LSTM loss function and train these networks within the self-supervised learning framework. The substitution is embedded within a classic IPM to generate search directions. Ideally, the primal-dual solution provided by IPM-LSTM should be well-centered with respect to the boundary and associated with a small duality gap. Finally, we utilize such approximate primal-dual solution pairs to warm-start an interior point solver. IPM-LSTM has several attractive features: (_i_) it can be applied to _general NLPs_; (_ii_) it strikes a _good balance between feasibility and optimality_ in the returned solutions; (_iii_) it can _warm-start_ and thereby accelerate interior point solvers.

The distinct contributions of our work can be summarized as follows:

* **Approximating Solutions to Linear Systems via LSTM:** This study marks the first attempt to employ learning techniques for approximating solutions of linear systems in IPMs, achieving significant speedup compared to traditional linear algebra approaches.
* **Two-Stage Framework:** We introduce a two-stage L2O framework. In the first stage, IPM-LSTM generates high-quality primal-dual solutions. In the second stage, these solutions are used to warm-start an interior point solver. This framework effectively accelerates the solving process of IPMs while yielding optimal solutions.
* **Empirical Results:** Compared with existing L2O algorithms, IPM-LSTM demonstrates favorable performance in terms of solution feasibility and optimality across various NLP types, including QPs and QCQPs. Utilizing these solutions as initial points in the state-of-the-art NLP solver IPOPT (Wachter and Biegler, 2006) reduces iterations by up to \(60\%\) and solution time by up to \(70\%\).

Figure 1: An illustration of the IPM-LSTM approach.

Related Works

**Constrained L2O.** Approaches utilizing L2O for constrained optimization can be broadly categorized into two directions: (i) direct learning of the mapping from optimization inputs to full solutions, and (ii) integration of learning techniques alongside or within optimization algorithms (Bengio et al., 2021; Donti et al., 2021). Previous works (Fioretto et al., 2020; Huang et al., 2021; Pan et al., 2023) adopted the former approach, employing a supervised learning scheme to train the mapping. However, this method necessitates a large number of (near-)optimal solutions as training samples, making it resource-intensive. From a self-supervised learning perspective, an intuitive approach is to incorporate the objective and penalization for constraint violation directly into the loss function (Kim et al., 2023; Park and Van Hentenryck, 2023). Nevertheless, such an approach may not guarantee the feasibility of the returned solutions. To address the feasibility issue, notable works such as Donti et al. (2021) first predict a partial solution via neural networks and then complete the full solution by utilizing equality constraints, iteratively correcting the solution towards the satisfaction of inequalities by applying gradient-based methods. However, for general nonlinear inequalities, this correction step may not ensure feasibility (Liang et al., 2023). Other approaches like Li et al. (2023) utilized gauge mappings to enforce feasibility for linear inequalities, while Liang et al. (2023) proposed the homeomorphic projection scheme to guarantee feasibility. However, these methods have limitations; the former is only applicable to linearly constrained problems, and the latter works for problems with feasibility regions homeomorphic to a unit ball. Another critical issue with the approach in Donti et al. (2021) is that the completion step may fail during training when the equality system with some fixed variables becomes infeasible, as highlighted in Han et al. (2024) and Zeng et al. (2024). Consequently, such an approach will not succeed during the training stage. To mitigate this issue, Han et al. (2024) proposed solving a projection problem if the completion step fails. However, the computationally expensive projection step may still be necessary during inference, which hinders its practical value.

**Learning-Based IPMs.** Primal-dual IPMs are polynomial-time algorithms used for solving constrained optimization problems such as LPs and NLPs. The work of Qian et al. (2024) demonstrated that properly designed _Graph Neural Networks_ (GNNs) can theoretically align with IPMs for LPs, enabling GNNs to function as lightweight proxies for solving LPs. However, extending this alignment to NLPs is challenging as representation learning for general NLPs remains unknown. Another avenue of research in learning-based IPMs involves warm-starting implementation. Previous works like Baker (2019), Diehl (2019) and Zhang and Zhang (2022) addressed alternative current optimal power flow (ACOPF) applications and proposed using learning models, such as GNNs, to learn the mapping between ACOPF and its optimal solutions. These predicted solutions are then utilized as initial points to warm-start an interior point optimizer. However, even if these solutions are close to the optimal ones, they may not be well-centered with respect to the trajectory in IPMs, causing the optimizer to struggle in progressing towards feasibility and optimality (Forsgren, 2006).

## 3 Approach

### The Classic IPM

We focus on solving the following NLP (1):

\[^{n}}{}& f(x)\\ & h(x)=0\\ & x 0\] (1)

where the functions \(f:^{n}\) and \(h:^{n}^{m}\) are all assumed to be twice continuously differentiable. Problems with general nonlinear inequality constraints can be reformulated in the above form by introducing slack variables. We note that for simplicity, we assume all variables in (1) are non-negative, though NLPs with arbitrary variable bounds can also be handled effectively. Readers are referred to Appendix A for details.

The primal-dual IPM stands as one of the most widely utilized approaches for addressing NLPs. It entails iteratively solving the perturbed _Karush-Kuhn-Tucker_ (KKT) conditions (2) for a decreasing sequence of parameters \(\) converging to zero.

\[ f(x)+^{} h(x)-z=0& h(x)=0\\ (z)(x)e= e& x,z 0\] (2)

where \(^{m}\) and \(z_{+}^{n}\) denote the corresponding dual variables, \(()\) represents a diagonal matrix, and \(e\) is a vector of ones. Let \(F(x,,z)=0\) denote the system of nonlinear equations in (2). We then employ a one-step _Newton's method_ to solve such a system, aiming to solve systems of linear equations (3).

\[^{2}f(x)+^{}^{2}h(x)& h ^{}(x)&-I\\  h(x)&&\\ (z)&&(x)}_{}  x\\ \\  z=-F(x,,z)\] (3)

The IPM commences with an initial solution \((x^{0},^{0},z^{0})\) such that \(x^{0},z^{0}>0\). At iteration \(k\), the linear system (3) defined by the current iterate \((x^{k},^{k},z^{k})\) is solved, with \(:=[(z^{k})^{}x^{k}]/n\) being the perturbation parameter and constant \((0,1)\). A line-search filter step along the direction \(( x^{k},^{k}, z^{k})\) is then performed to ensure boundary condition satisfaction as well as sufficient progress towards objective value improvement or constraint violation reduction. This process iterates until convergence criteria, such as achieving optimality and feasibility within specified tolerances, are met. The IPM is guaranteed to converge to a KKT point with a superlinear rate. A pseudocode of the IPM is presented as Algorithm 1.

```
0: An initial solution \((x^{0},^{0},z^{0})\), \((0,1)\), \(k 0\)
0: The optimal solution \((x^{*},^{*},z^{*})\)
1:while not converged do
2: Update \(^{k}\)
3: Solve the system \(J^{k}[( x^{k})^{},(^{k})^{},( z^{k})^{ }]^{}=-F^{k}\)
4: Choose \(^{k}\) via a line-search filter method
5:\((x^{k+1},^{k+1},z^{k+1})(x^{k},^{k},z^{k})+^{k }( x^{k},^{k}, z^{k})\)
6:\(k k+1\)
7:endwhile ```

**Algorithm 1** The classic IPM

We note that, in classic IPMs, one typically reformulates the system (3) and then solves a reduced system of equations (i.e., augmented system) for greater efficiency. However, in this work, we are interested in the full systems since they are associated with smaller condition numbers (Greif et al., 2014) that are critical to the performance of our proposed approach. Additionally, various techniques have been proposed to enhance the robustness and efficiency of IPMs, including second-order correction, inertial correction, and feasibility restoration. Interested readers are referred to Wachter and Biegler (2006) for further details about IPMs.

### Approximating Solutions to Linear Systems

The small number of iterations in IPMs does not always guarantee efficiency because, at times, IPMs encounter a high per-iteration cost of linear algebra operations. In the worst-case scenario, the cost of solving a dense optimization problem using a direct linear algebra method to solve the Newton equation system (3) may reach \((n^{3})\) flops per iteration. This motivates us to avoid computing exact solutions to linear systems and instead focus on their approximations. Toward this goal, we consider the following _least squares problem_ (4):

\[_{y}\|J^{k}y+F^{k}\|^{2},\] (4)

where \(\|\|\) denotes the Euclidean norm. If (3) is solvable, then an optimal solution to problem (4) is also the exact solution \([( x^{k})^{},(^{k})^{},( z^{k})^{} ]^{}\) to system (3). Otherwise, we resort to an approximation of the latter. This perspective is similar to the _inexact IPM_(Bellavia, 1998; Dexter et al., 2022).

**Assumption 1**.: _At iteration \(k\), we could identify some \(y^{k}\) such that_

\[\|J^{k}y^{k}+F^{k}\|[(z^{k})^{}x^{k} ]/n\] (5) \[\|y^{k}\|(1++)\|F_{0}(x^{k},^{k},z^{k})\|.\] (6)

_where \((0,1)\) and \(F_{0}(x^{k},^{k},z^{k})\) denotes \(F(x^{k},^{k},z^{k})\) with \(=0\)._

To satisfy Assumption 1, the approximate solution \(y^{k}\) has to be bounded and accurate enough, regardless of whether \(J^{k}\) is invertible.

**Proposition 1** (Bellavia (1998)).: _If \((x^{k},^{k},z^{k})\) is generated such that Assumption 1 is satisfied, let \((x^{*},^{*},z^{*})\) denote a limit point of the sequence \(\{(x^{k},^{k},z^{k})\}\), then \(\{(x^{k},^{k},z^{k})\}\) converges to \((x^{*},^{*},z^{*})\) and \(F_{0}(x^{*},^{*},z^{*})=0\)._

Proposition 1 implies that if solutions with specified accuracy for linear systems in Step 3 are found, the IPM would converge.

### The IPM-LSTM Approach

The problem (4) is an unconstrained convex optimization problem. Various L2O methods have been proposed to solve such problems (Chen et al., 2022; Gregor and LeCun, 2010; Liu et al., 2023). We will employ the LSTM networks in our L2O method for addressing problem (4), hence our approach is called "IPM-LSTM".

**Model Architecture.** LSTM is a type of _recurrent neural network_ designed to effectively capture and maintain long-term dependencies in sequential data (Yu et al., 2019). LSTM networks are commonly considered suitable for solving unconstrained optimization problems due to the resemblance between LSTM recurrent calculations and iterative algorithms (Andrychowicz et al., 2016; Liu et al., 2023; Lv et al., 2017).

The LSTM network consists of \(T\) cells parameterized by the same learnable parameters \(\). Each cell can be viewed as one iteration of a traditional iterative method, as illustrated in Figure 2. Let \((y):=\|J^{k}y+F^{k}\|^{2}\) for convenience. The \(t\)-th cell takes the previous estimate \(y_{t-1}\) and the gradient \((J^{k})^{}(J^{k}y_{t-1}+F^{k})\) as the input and outputs the current estimate \(y_{t}\):

\[y_{t}:=_{}([y_{t-1},(J^{k})^{}(J^{k}y_{t-1}+F^{ k})]).\] (7)

The \(T\)-th cell yields \(y_{T}\) as an approximate solution to problem (4). As suggested by Andrychowicz et al. (2016) and Liu et al. (2023), we utilize a coordinate-wise LSTM that shares parameters not only across different LSTM cells but also for all coordinates of \(y\).

**Model Training.** We train the proposed optimizer by finding the optimal \(\) in (7) on a dataset \(\) of NLPs. Each sample in \(\) is an instance of the optimization problem. During training, we apply the optimizer to each instance \(M\), performing \(K\) IPM iterations in the outer loop and \(T\) LSTM

Figure 2: The LSTM architecture for solving \(}\)\((y)\).

time steps in the inner loop, generating a sequence of iterates \(\{(y_{1}^{1},...,y_{T}^{1}),...,(y_{1}^{K},...,y_{T}^{K})\}\) where the superscript \(k\) denotes the IPM iteration number. We then optimize \(\) by minimizing the following loss function:

\[_{}|}_{M}( _{k=1}^{K}_{t=1}^{T}\|J^{k}y_{t}^{k}( )+F^{k}\|^{2})_{M},\]

where the subscript \(M\) indicates that the corresponding term is associated with instance \(M\). Clearly, our model training falls into the category of _self-supervised learning_. To mitigate memory issues caused by excessively large computational graphs, we employ _truncated backpropagation through time_ after each IPM iteration during training, as done in Chen et al. (2022) and Liu et al. (2023).

**Preconditioning.** The Hessian matrix of \((y)\) is \((J^{k})^{}J^{k}\), whose condition number, \(((J^{k})^{}J^{k})\), is the square of that of \(J^{k}\). Consequently, \(((J^{k})^{}J^{k})\) can easily become very large. Since solving system (4) via LSTM networks emulates iterative first-order methods, the value of \(((J^{k})^{}J^{k})\) strongly affects the performance of LSTM networks. To address this issue, we employ a simple diagonal preconditioning technique that rescales the Hessian matrix \((J^{k})^{}J^{k}\) using the Ruiz scaling method Ruiz (2001) to decrease its condition number.

### Two-Stage Framework

To further enhance the solution quality, we propose a two-stage framework that initially obtains a near-optimal and well-centered primal-dual solution via IPM-LSTM and then utilizes this approximate solution to warm-start an interior point solver. In this study, we select IPOPT Wachter and Biegler (2006), an IPM-based solver renowned for its robustness and efficiency in optimizing NLPs.

Our two-stage framework works as follows: Given an NLP (1), we generate an initial point \((x^{0},^{0},z^{0})\) and formulate the least squares problem (4). Subsequently, the trained LSTM network with \(T\) cells solves this problem and returns a search direction. We then employ the simple fractional-to-boundary method Wachter and Biegler (2006) to determine the step size and reach the new iterate. This procedure is iterated \(K\) times, resulting in a primal-dual solution \((x^{K},^{K},z^{K})\). Finally, the obtained solution serves as the warm-start solution for IPOPT, leading to the optimal solution \(x^{*}\) upon IPOPT convergence.

## 4 Experiments

### Experimental Settings

We evaluate our approach and compare its performance against traditional methods as well as L2O algorithms for solving various types of NLPs. Furthermore, we also quantify the warm-starting effect of our proposed two-stage approach. Our code is available at https://github.com/NetSysOpt/IPM-LSTM.

**Baseline Algorithms.** In our experiments, we denote our algorithm by IPM-LSTM and compare it against both traditional optimizers and L2O algorithms. The traditional optimizers considered are: (i) OSQP Stellato et al. (2020): an ADMM-based solver designed for convex QPs. (ii) IPOPT 3.14.8 Wachter and Biegler (2006): a state-of-the-art IPM-based solver for NLPs with the default linear solver MUMPS Amestoy et al. (2000) and a convergence tolerance of \(10^{-4}\). We also assess several L2O algorithms, including: (i) NN Donti et al. (2021): a straightforward deep learning approach that integrates the objective function and penalty for constraint violations into the loss function. (ii) DC3 Donti et al. (2021): an end-to-end method that uses "completion" steps to maintain equality constraints and "correction" steps for inequality feasibility. (iii) DeepLDE Kim et al. (2023): an algorithm that trains neural networks using a primal-dual approach to impose inequality constraints and employs "completion" for equality constraints. (iv) PDL Park and Van Hentenryck (2023): a self-supervised learning method that jointly trains two networks to approximate primal and dual solutions. (v) LOOP-LC Li et al. (2023): a neural approximator that maps inputs of linearly constrained models to high-quality feasible solutions using gauge maps. (vi) H-Proj Liang et al. (2023): a method that applies a homeomorphic projection scheme to post-process solutions resulting from the completion step in DC3.

**Datasets.** The dataset used in this paper includes randomly generated benchmarks obtained from Chen and Burer (2012), Donti et al. (2021) and Liang et al. (2023), as well as real-world instancesfrom Globallib (see http://www.minlplib.org). These benchmarks encompass QPs, QCQPs, and simplex non-convex programs. For each case, we generate \(10,000\) samples and divide them into a \(10:1:1\) ratio for training, validation, and testing, respectively. All numerical results are reported for the test set.

**Model Settings.** All LSTM networks have a single layer and are trained using the Adam optimizer (Kingma, 2014). During IPM-LSTM training, an early stopping strategy with a patience of \(50\) is employed, halting training if no improvement is observed for \(50\) iterations, while satisfying inequality and equality constraints violation less than 0.005 and 0.01. The learning rate is 0.0001, and the batch size is 128 for each task. Additional IPM-LSTM parameters for each task are provided in Appendix C.

**Evaluation Configuration.** All our experiments were conducted on an NVIDIA RTX A6000 GPU, an Intel Xeon 2.10GHz CPU, using Python 3.10.0 and PyTorch 1.13.1.

### Computational Results

**Convex QPs.** We consider convex QPs with both equality and inequality constraints:

\[^{n}}{}& x^{}Q_{0}x+p_{0}^{}x\\ & p_{j}^{}x q_{j}& j=1,,l\\ & p_{j}^{}x=q_{j}& j=l+1,,m\\ & x_{i}^{L} x_{i} x_{i}^{U}& i=1,,n\] (8)

where \(Q_{0}_{+}^{n}\), \(p_{j}^{n}\), \(q_{j}\), \(x_{i}^{L}\{-\}\) and \(x_{i}^{U}\{+\}\). We conduct experiments on two groups of QPs, each instance with \(200\) variables, \(100\) inequalities and \(100\) equalities. The first group is generated in the same way as Donti et al. (2021), where only the right hand sides of equality constraints are perturbed while the second one considers perturbation for all model parameters. Let "Convex QP (RHS)" denote the former and "Convex QPs (ALL)" denote the latter. It is noteworthy that, in line with Donti et al. (2021), we also investigate the performance of IPM-LSTM and baseline algorithms on smaller-scale convex QPs. Interested readers are directed to Appendix D for details.

We ran IPM-LSTM and all baseline algorithms on the test set "Convex QPs (RHS)", and we reported their computational results, which were averaged across \(833\) instances. The results are presented in Table 1. We denote this experiment by "End-to-End" for convenience. The columns labeled "Max Ineq.", "Mean Ineq.", "Max Eq.", and "Mean Eq." denote the maximum and mean violations for inequalities and equalities, respectively. The columns "Obj." and "Time (s)" represent the final primal objective and the runtime in seconds. Both OSQP and IPOPT solved these instances to guaranteed optimality, with OSQP being significantly more efficient due to its specialization as a QP-specific solver. All L2O baseline algorithms returned solutions very quickly. However, solutions generated by NN and PDL exhibited significant constraint violations. While the solutions from DC3 and DeepLDE were nearly feasible, they corresponded to inferior objective values. On the other hand, LOOP-LC produced feasible and near-optimal solutions, whereas H-Proj generated feasible solutions but with

    &  &  &  &  \\  & Obj. \(\) & Max ineq. \(\) & Mean ineq. \(\) & Max eq. \(\) & Mean eq. \(\) & Time (s) \(\) & Ine. \(\) & Time (s) \(\) & Time (s) \(\) \\   \\  OSQP & -29.176 & 0.000 & 0.000 & 0.000 & 0.000 & 0.009 & - & - & - & - \\ IPOPT & -29.176 & 0.000 & 0.000 & 0.000 & 0.000 & 0.642 & 12.5 & - & - & - \\ HN & -26.787 & 0.000 & 0.000 & 0.631 & 0.235 & 0.001 & 10.5 & 0.560 & 0.560 & 16.051 \\ DC3 & -26.720 & 0.002 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.2 & 0.535 & 0.535 & 18.436 /16.7\% \\ DeepLDE & -3.697 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 12.5 & 0.648 & 0.648 & 0.005 /0.9\% \\ PDL & -28.559 & 0.421 & 0.122 & 0.024 & 0.000 & \(<\)0.001 & 9.7 & 0.514 & 0.514 & 22.43 /**19.9\%** \\ LOOP-LC & -28.512 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.8 & 0.565 & 0.565 & 13.651 /21.0\% \\ IPM-Prej & -23.257 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 11.2 & 0.605 & 0.605 & 10.49\% /5.8\% \\ IPM-LSTM & -29.050 & 0.000 & 0.000 & 0.000 & 0.001 & 0.175 & 7.2 & 0.370 & 0.545 & **42.45**/15.1\% \\   \\  OSQP & -33.183 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & - & - & - & - \\ IPOPT & -33.183 & 0.000 & 0.000 & 0.000 & 0.000 & 0.671 & 12.9 & - & - \\ IPM-LSTM & -32.600 & 0.000 & 0.000 & 0.003 & 0.001 & 0.195 & 8.3 & 0.426 & 0.621 & **35.7\%/7.5\%** \\   

Table 1: Computational results on convex QPs.

larger objective values. Solutions identified by IPM-LSTM showed mild constraint violations but yielded superior objective values very close to the optimal values. Clearly, IPM-LSTM effectively balances feasibility and optimality in the returned solutions. This comes at the cost of longer runtime compared to the L2O baseline algorithms, as the baselines typically employ simple multi-layer perceptrons, whereas IPM-LSTM utilizes a neural network with several dozen LSTM cells.

Since IPM-LSTM is designed to provide interior point optimizers with high-quality initial points, we fed the returned primal-dual solution pair to IPOPT and reported the performance in Table 1. For comparison, we also provided IPOPT with initial points generated from other L2O algorithms. The columns labeled "Ite." and "Time (s)" under "IPOPT (warm-start)" indicate the number of iterations and solver time, respectively, while the column "Total Time (s)" represents the cumulative time for running both the L2O algorithms and IPOPT. The final column, "Gain (Ite/Time)", shows the reduction in iteration number and solution time, with the default IPOPT iteration number listed in the "Ite." column for reference. When initial solutions from IPM-LSTM and most L2O baseline algorithms (except DeepLDE) were used, IPOPT converged with fewer iterations and reduced solution time. Notably, IPM-LSTM achieved the most significant reduction in iterations, from \(12.5\) to \(7.2\), and decreased the average solver time from \(0.642\) seconds to \(0.37\) seconds. Including the computational time for IPM-LSTM, the total runtime was \(0.545\) seconds, reflecting a 15.1% reduction in time. It is worth noting that while IPM-LSTM did not yield the maximum solution time reduction, this was due to its relatively high computational expense.

To our knowledge, there is no existing representation learning approach for general convex QPs. Since the aforementioned L2O baseline algorithms depend on specific representations of QPs, they are not applicable to "Convex QPs (ALL)". Therefore, we only provide results for OSQP, IPOPT, and IPM-LSTM. We also report computational results averaged across \(833\) instances in the test set "Convex QPs (ALL)", presented in Table 1. The results demonstrate that IPM-LSTM can identify high-quality solutions for general convex QPs, and using these solutions as initial points can reduce iterations by \(35.7\%\) and solution time by \(7.5\%\).

**Convex QCQPs.** We now turn to convex QCQPs with both equaltity and inequality constraints:

\[^{n}}{} x^{}Q_{0}x+p_{0}^{}x\] s.t. \[x^{}Q_{j}x+p_{j}^{}x q_{j} j=1,,l\] \[p_{j}^{}x=q_{j} j=l+1,,m\] \[x_{i}^{L} x_{i} x_{i}^{U} i=1,,n\]

where \(Q_{j}_{+}^{n},p_{j}^{n}\), \(q_{j}\), \(x_{i}^{L}\{-\}\) and \(x_{i}^{U}\{\}\). Similar to our experiments on convex QPs, we also consider two groups of convex QCQPs, each with \(200\) variables, \(100\) inequality constraints, and \(100\) equality constraints. The first group (denoted as "Convex QCQPs (RHS)") is generated as described in Liang et al. (2023), with perturbations only to the right-hand sides of the equality constraints. The second group (denoted as "Convex QCQPs (ALL)") considers perturbations to all parameters. We also refer readers to Appendix D for computational experiments on smaller-sized convex QCQPs.

We omit OSQP and LOOP-LC since the former cannot handle QCQPs, while the latter is only applicable to linearly constrained problems. We evaluate IPM-LSTM and compare it against the remaining baseline algorithms. The computational results are reported in Table 2. Again, solutions produced by NN and PDL exhibit significant constraint violations, while those from DC3 and H-Proj are of high quality in terms of feasibility and optimality. Once more, the solutions produced by DeepLDE were deemed feasible but exhibited inferior objective values. Conversely, our approach, IPM-LSTM, produced solutions with superior objective values albeit with minor infeasibility. Compared to the baseline algorithms, utilizing solutions from IPM-LSTM to warm-start IPOPT resulted in the most substantial reduction in iterations.

As the aforementioned L2O baseline algorithms are not applicable to "Convex QCQPs (ALL)", we only report computational results for IPOPT and IPM-LSTM in Table 2. The IPM-LSTM approach produced high-quality approximate solutions to convex QCQPs, and warm-starting IPOPT with these solutions accelerated IPOPT by \(11.4\%\), with a \(33.1\%\) reduction in iterations.

**Non-convex QPs.** We now consider non-convex QPs of exactly the same form as (8) but with \(Q_{0}\) being indefinite. We take \(8\) representative non-convex QPs from the datasets Globallib and RandQP (Chen and Burer, 2012), each with up to \(50\) variables and \(20\) constraints, and perturb the relevant parameters for instance generation. Details can be found in Appendix D.2.

Among all the baselines, only IPOPT is applicable to these general non-convex QPs. Hence, we report computational results for IPOPT and IPM-LSTM in Table 3. IPOPT solved these instances to local optimality, while IPM-LSTM identified high-quality approximate solutions very efficiently. Using these primal-dual approximations to warm-start IPOPT resulted in an iteration reduction of up to \(63.9\%\) and a solution time reduction of up to \(70.5\%\).

**Simple non-convex programs.** Following the approach outlined in Donti et al. (2021), we consider a set of simple non-convex programs where the linear objective term in (8) is substituted with \(p_{0}^{}(x)\). These instances were generated using the same methodology as Donti et al. (2021). We subject these problems to evaluation using both IPM-LSTM and baseline algorithms. Once again, the computational results underscore the high-quality solutions obtained by IPM-LSTM and its superior warm-starting capability. Detailed results are provided in Appendix D.4.

### Performance Analysis of IPM-LSTM

In Assumption 1, we posit that the linear systems (3) can be solved with an acceptable residual (Condition (5)) and that the solutions are properly bounded (Condition (6)). Although the LSTM network cannot guarantee the satisfaction of these conditions, we empirically assess the validity of Assumption 1 in IPM-LSTM. We plot the progress of \(\|J^{k}y^{k}+F^{k}\|\), \([(z^{k})^{}x^{k}]/n\), \(\|y^{k}\|\), and \(\|F_{0}(x^{k},^{k},z^{k})\|\) as the IPM iterations increase in Figure 3(a) and 3(b). Condition (5) is mostly satisfied except during the first few iterations, while Condition (6) is strictly satisfied across all IPM iterations. To assess the precision of the approximate solutions as the LSTM time steps increase, we plot the progress of the residual for linear systems (3) in Figure 3(c). At IPM iteration \(k\), the residual decreases monotonically towards \(0\) as the LSTM time steps increase, indicating that LSTM networks can produce high-quality approximate solutions to system (3). The approximation quality improves with the number of IPM iterations. As shown in Figure 3(d), the primal objective decreases monotonically towards the optimal value with increasing IPM iterations, empirically demonstrating the convergence of IPM-LSTM. Note that the condition number \(((J^{k})^{}J^{k})\) becomes quite large in the later IPM iterations, which can adversely affect the performance of LSTM networks in obtaining approximations to systems (3). Consequently, we terminate IPM-LSTM after a finite number of iterations. Further analysis regarding the number of IPM iterations and LSTM time steps is

    &  &  &  &  \\  & Obj. \(\) & Max incq. \(\) & Mean incq. \(\) & Max eq. \(\) & Mean eq. \(\) & Time (s) \(\) & Ihe. \(\) & Time (s) \(\) & Time (s) \\   \\  IPOPT & -39.162 & 0.000 & 0.000 & 0.000 & 0.000 & 1.098 & 12.5 & - & - & - \\  & NM & -2.105 & 0.000 & 0.000 & 0.552 & 0.169 & +0.001 & 12.1 & 1.311 & 1.311 & 3.25/-19.4\% \\  & DC3 & -35.741 & 0.000 & 0.000 & 0.000 & 0.000 & 0.005 & 9.6 & 1.051 & 1.051 & 20.75/4.8\% \\  & DeepID & -15.132 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 11.5 & 1.222 & 1.22 & 8.90/-11.3\% \\  & PPL & -39.089 & 0.005 & 0.000 & 0.015 & 0.005 & +0.001 & 8.9 & 1.013 & 1.013 & 2.88 /-**9.75** \\  & H-Proj & -36.062 & 0.000 & 0.000 & 0.000 & 0.000 & +0.001 & 9.8 & 1.070 & 1.070 & 21.65/2.6\% \\  & IPM-LSTM & -38.540 & 0.000 & 0.000 & 0.004 & 0.001 & 0.205 & 8.0 & 0.825 & 1.030 & **36.05**/6.2\% \\   \\  IPOPT & -39.868 & 0.000 & 0.000 & 0.000 & 0.000 & 0.801 & 12.4 & - & - & - \\  & IPM-LSTM & -38.405 & 0.004 & 0.000 & 0.001 & 0.000 & 0.203 & 8.3 & 0.507 & 0.710 & **33.15**/**11.4\%** \\   

Table 2: Computational results on convex QCQPs.

    &  &  &  &  &  \\  & Obj. & Ihe. & Time (s) & Obj. & Max Vo. & Time (s) & Obj. & Ihe. & Time (s) & Time (s) & (Ihe./ Time) \\  q1 & 0.001 & 52.0 & 0.707 & 0.045 & 0.008 & 0.017 & 0.001 & 42.0 & 0.559 & 0.576 & 19 27/18.5\% \\ qp2 & 0.001 & 69.0 & 0.674 & 0.034 & 0.008 & 0.029 & 0.001 & 40.0 & 0.347 & 0.376 & 42.05/4.2\% \\  & sJ\_v1 & -58.430 & 215.0 & 0.955 & -34.563 & 0.000 & 0.009 & -58.867 & 16.0 & 6.266 & 0.635 & 21.99/33.5\% \\  & sJ\_v2 & -67.083 & 190.8 & 0.956 & -30.955 & 0.000 & 0.011 & -67.083 & 120.5 & 0.482 & 0.494 & 36.86/38.1\% \\  & sJ\_v3 & 0.000 & 55.0 & 0.781 & 0.818 & 0.000 & 0.017 & 0.000 & 47.0 & 0.616 & 0.634 & 14.59/18.8\% \\  & sJ\_v7 & -132.019 & 449.0 & 2.445 & -61.428 & 0.000 & 0.016 & -131.756 & 162.0 & 0.705 & 0.721 & 63.99/70.5\% \\  & sJ\_v9 & -126.945 & 655.0 & 3.457 & -58.415 & 0.000 & 0.026 & -127.652 & 400.8 & 1.830 & 1.856 & 37.74/64.3\% \\  & qp30\_15\_1\_1 & 37.767 & 16.0 & 0.198 & 37.787 & 0.002 & 0.021 & 37.767 & 9.0 & 0.083 & 0.104 & 33.75/47.5\% \\    Max Vo. denotes the maximum constraint violation.

Table 3: Computational results on non-convex QPs.

presented in Appendix D.5. Additionally, we include the performance of IPM-LSTM under various hyperparameter settings in Appendix D.5.

## 5 Limitations and Conclusions

In this paper, we present a learning-based IPM called IPM-LSTM. Specifically, we propose approximating solutions of linear systems in IPMs by solving least square problems using trained LSTM networks. We demonstrate that IPMs with this approximation procedure still converge. The solutions returned by IPM-LSTM are used to warm-start interior point optimizers. Our computational experiments on various types of NLPs, including general QPs and QCQPs, showcase the effectiveness of IPM-LSTM and its ability to accelerate IPOPT. Although IPM-LSTM generates high-quality primal-dual solutions, it is relatively computationally expensive due to the utilization of multi-cell LSTM networks. In future endeavors, we aim to investigate the efficacy of employing low-complexity neural networks to approximate solutions of linear systems within IPMs.