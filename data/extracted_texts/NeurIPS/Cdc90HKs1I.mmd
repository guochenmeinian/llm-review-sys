# The Genomics Long-Range Benchmark: Advancing DNA Language Models

Evan Trop

InstaDeep

e.trop@instadeep.com &Yair Schiff

Cornell University &Edgar Marroquin

Cornell University &Chia-Hsiang Kao

Cornell University &Aaron Gokaslan

Cornell University &McKinley Polen

InstaDeep, MIT &Mingyi Shao

Cornell University &Bernardo P. de Almeida

InstaDeep &Thomas Pierrot

InstaDeep &Yang Li

University of Chicago &Volodymyr Kuleshov

Cornell University &

###### Abstract

The advent of language models (LMs) in genomics necessitates benchmarks that can assess models' capabilities and limitations. In contrast to protein models, DNA LMs can be used to study non-coding regions of the genome and must account for unique challenges, especially interactions across long sequence lengths. However, existing benchmarks for DNA LMs are defined over short sequence datasets and can involve tasks that are often not considered to be biologically meaningful. Here, we present the Genomics Long-Range Benchmark (LRB), which focuses on biologically meaningful tasks and supports long-range contexts. We complement our benchmark with fine-tuning recipes that meaningfully improve performance and affect model evaluation. We evaluate DNA LMs across nine compiled tasks and observe that DNA LMs achieve competitive performance relative to supervised baselines on several tasks (e.g., genome annotation), but there remains a significant gap in domains, such as variant effect and gene expression prediction. Additionally, we introduce a visualization tool to examine model performance split by various genomic properties. Lastly, we present methods for context-length extrapolation of transformer-based models that enable studying the effect of context length on DNA LM performance. The Genomics LRB is publicly available on Hugging Face.

## 1 Introduction

Pre-training models on a large corpus of unlabeled data and subsequently fine-tuning to solve downstream tasks has demonstrated widespread success across domains, such as natural language processing [2; 77] and computer vision [57; 65]. More recently this paradigm has shown promise in biological applications, enabled by the wealth of unlabeled data coming from next-generation sequencing technologies. A prominent example are protein language models (LMs), which have been used to predict the effects of coding mutations on protein function , generate viable protein sequences conditioned on functional properties , and accurately predict protein structure fromamino acid sequences . The development of these models has been made possible by benchmarks, such as CASP , TAPE , PEER , and ProteinGym .

Genomics represents a potential new frontier for LMs in biology. The common pre-training tasks in language modeling (i.e., filling in missing tokens based on input context) inherently train LMs to model evolutionary forces, such as conservation and co-evolution, and the statistical patterns that these models learn can map to genomic motif identification, which is useful in accurate gene annotation. Indeed, significant progress has been made, with various LMs tailored to DNA sequences . However, modeling genomic data presents unique challenges compared to proteomics. When modeling DNA, we have to account for non-coding regions and contend with interactions that can be orders of magnitude larger . To guide the principled development of new DNA LMs, there is a need for robust benchmarks that accurately reflect these nuances. While several benchmarks have been proposed, these existing works contain important limitations. The vast majority of tasks proposed across existing benchmarks only consider short input contexts (less than 2k base pairs) , disregarding long-range interactions that are highly impactful in genomics. Additionally, tasks in some benchmarks may be overly simplistic, failing to reflect real-world use cases, e.g., some benchmarks have used synthetic data to construct negative sets .

To bridge these gaps, we propose the Genomics Long-Range Benchmark (LRB), a compilation of biologically meaningful tasks in human genomics. Our benchmark deliberately incorporates tasks hypothesized to span both short and long genomic contexts. Allowing users to select arbitrary sequence length inputs for any given dataset enables us for the first time to understand empirically the importance of long-range inputs for our proposed tasks. We also include available genomic annotations and provide a visualization tool that allows users to analyze results in more detail. We demonstrate the benefit of full model fine-tuning compared to previous approaches that keep backbone DNA LM weights frozen during downstream training. Finally, we introduce methods for extending the context size of existing DNA LMs, which allows us quantify the benefits of long-range context on DNA LM performance. To summarize, we make the following contributions:

**1. Release the Genomics Long-Range Benchmark**, composed of biologically meaningful tasks that cover both short- and long-range genomic scales. We provide evaluation results for a selection of prominent DNA LMs in both zero-shot and fine-tuning settings along with comparisons against reference baselines. We find that on genomic annotation tasks DNA LMs perform competitively with existing supervised models, but on the long-range prediction tasks of gene expression and zero-shot mutation effect prediction there persists a large gap.

**2. Develop and analyze improved fine-tuning methods** that better reflect real-world usage in downstream tasks, finding that full model weight fine-tuning significantly improves performance.

**3. Introduce an analysis and visualization tool** to examine models' performance across different genomic properties. This tool enables deeper analyses that reveal more nuanced evidence that DNA LMs lag behind a well-regarded and long-range supervised baseline, Enformer , in modeling long-range interactions. The visualization tool is available here.

**4. Conduct context-length extension for the Nucleotide Transformer LM** to probe the impact of increasing context length on performance on our benchmark.

## 2 Background

### Language Modeling for DNA

Supervised machine learning methods have been successfully applied to genomics . However, these models depend on large amounts of labeled data and tend to be task-specific. LMs have recently gained traction in the genomics domain: the abundance of unlabeled sequences supports robust model pre-training and the widely-used pre-training objectives of next token prediction (NTP) or masked language modeling (MLM) directly lend themselves to models identifying genomic motifs and evolutionary patterns, e.g., conservation. Some notable recent works include DNABERT ,GPN , Nucleotide Transformer (NT) , GENA-LM , HyenaDNA , Evo  and Caduceus . A more thorough review of recent DNA LMs is deferred to Appendix A.2.

### DNA LM Evaluation

The goal of DNA LMs is to learn meaningful representations that can be used to improve performance on downstream tasks. Existing DNA benchmarks, which include the Nucleotide Transformer tasks (NT ), Genomic Benchmark (GB ), Genome Understanding Evaluation (GUE ), and Benchmark for DNA LMs (BEND ), have been crucial for establishing baseline model capabilities. (see Appendix A.3 for a more complete description of existing works). However, these benchmarks contain several important shortcomings: they do not focus on long-range sequences, they can contain synthetic examples, and their evaluations do not take full advantage of pre-trained models.

## 3 The Genomics Long-Range Benchmark

Below we describe the nine tasks that we compiled from various human genome data sources that comprise our proposed Genomics Long-Range Benchmark (LRB). Our suite consists of tasks that are hypothesized to require only short-range contexts as well as those thought to need longer sequences for accurate prediction. By enabling users to download data at arbitrary length scales (the first benchmark to support this feature), these hypotheses can be rigorously tested. Our tasks span various applications that are of interest to practitioners, namely variant effect prediction, gene expression prediction, regulatory element detection, and chromatin factor identification; see Table 2. Below, for each task, we provide details on the biological relevance that motivated its inclusion, a formal task definition, and rationale for hypothesized long-range dependencies (where applicable). We defer additional details, e.g., data source and processing, train / test splits, and metric definition, to Appendix B.

### Variant Effect Prediction

#### 3.1.1 Causal eQTL

Biological RelevancePredicting the effects of genetic variants, particularly expression quantitative trait loci (eQTLs), is essential for understanding the molecular basis of several diseases. eQTLs are

    & **Type** & **\# Outputs** & **\# Train / Test** & **\% Pos. Label** \\  _Variant Effect Prediction_ & & & \\ Causal eQTL & SNP Classification & 1 & 89k / 9k & 50.0 \\ Pathogenic OMIM & SNP Classification & 1 & - / 2.3M & 0.02 \\ Pathogenic ClinVar & SNP Classification & 1 & 39k / 1k & 56.1 \\  _Gene Expression Prediction_ & & & \\ Bulk RNA-seq & Seq-wise Regression & 218 & 23k / 1k & - \\ CAGE profile & Binned Regression & 50 / bin & 34k / 2k & - \\  _Regulatory Element Detection_ & & & \\ Promoter & Seq-wise Classification & 1 & 953k / 96k & 4.7 \\ Enhancer & Seq-wise Classification & 1 & 1.9M / 192k & 52.5 \\  _Chromatin Feature Identification_ & & & \\ Histone Mark Prediction & Seq-wise Classification & 20 & 2.2M / 227k & 7.0 \\ Chromatin Accessibility & Seq-wise Classification & 20 & 2.2M / 227k & 4.4 \\   

Table 2: Overview of the tasks contained in the Genomics Long-Range Benchmark.

    & **Long** & **Human** & **Biologically** \\  & **range** & **centric** & **meaningful** \\  NT  & \& & \\ GB  & \& & \\ GUE  & \& & \\ BEND  & \& & \\ 
**Genomics LRB** & \& & \\   

Table 1: Comparison to existing benchmarks.

genomic loci that are associated with variations in mRNA expression levels among individuals. By linking genetic variants to causal changes in mRNA expression, researchers can uncover how certain variants contribute to disease development .

**Task Definition**: The task is formulated as a binary classification problem to distinguish eQTLs from GTEx  from a set of matched negatives identified in Avsec et al. . Inputs are sequences centered around candidate single nucleotide polymorphisms (SNPs) each assigned a causal probability by fine-mapping using the "Sum of Single Effects" (SuSiE) model . Following Avsec et al. , variants with causal probability greater than 0.9 are labeled as positive and variants with causal probability less than 0.01 are labeled as negative.
**Long-Range**: The regulation of gene expression is modulated by distal, cis-regulatory elements, called enhancers, that can be more than several hundred thousand base pairs (bps) away from a target gene . Variants that impact gene expression are often located at such distal elements, and thus, to predict such variants, models should have long context windows .

#### 3.1.2 Pathogenic OMIM

**Biological relevance**: Predicting the effects of regulatory variants on pathogenicity is crucial for understanding disease mechanisms . Elements that regulate gene expression are often located in non-coding regions, and variants in these areas can disrupt normal cellular function, leading to disease. Accurate predictions can identify biomarkers and therapeutic targets, enhancing personalized medicine and genetic risk assessment.
**Task Definition**: The task is formulated as a binary classification problem where inputs are DNA sequences centered around a SNP and outputs are binary labels. The dataset was constructed following Benegas et al. , where the negative class corresponds to a common (mean allele frequency \(>\) 5%) SNP in gnomAD  and the positive class corresponds to a pathogenic SNP, defined as a SNP in a regulatory region having an implication in a Mendelian disorder in the Online Mendelian Inheritance in Man database .
**Long-Range**: Regulatory elements like enhancers and silencers can exist far from the genes they regulate . Variants in these regulatory elements can lead to aberrant gene expression patterns and ultimately disease, but identifying such regulatory variants is difficult since regulatory elements can modulate the expression of proximal or distal genes. Models that can capture interactions between possibly distal regulatory elements and their target genes while still being able to capture the proximal interactions are essential to identifying non-coding pathogenic variants.

#### 3.1.3 Pathogenic ClinVar

**Biological Relevance**: A coding variant refers to a genetic alteration that occurs within the protein-coding regions of the genome, also known as exons. Such alterations can impact protein structure, function, stability, and interactions with other molecules, ultimately influencing cellular processes and potentially contributing to the development of genetic diseases . Predicting variant pathogenicity is crucial for guiding research into disease mechanisms and personalized treatment strategies, enhancing our ability to understand and manage genetic disorders effectively.
**Task Definition**: This task is formulated as a binary classification problem where inputs are sequences centered around SNPs. The dataset was constructed following Benegas et al. , where the negative class corresponds to a common (minor allele frequency \(>\) 5%) SNP in gnomAD  and the positive class to pathogenic SNPs identified in ClinVar .

### Gene Expression Prediction

#### 3.2.1 Bulk RNA-seq

**Biological Relevance**: Gene expression involves the process by which information encoded in a gene directs the synthesis of a functional gene product, typically a protein, through transcription and translation. Transcriptional regulation determines the amount of mRNA produced, which is then translated into proteins. Developing a model that can predict RNA expression levels solely from sequence data is crucial for advancing our understanding of gene regulation, elucidating disease mechanisms, and identifying functional sequence variants.

**Task Definition** This task is described as a multi-variable, sequence-wise regression task. Data was constructed following Zhou et al.  such that inputs are DNA sequences centered around the transcription start site (TSS) of each gene where the TSS was identified using a combination of annotations from GENCODE  and CAGE data from FANTOM5 . Outputs are RPKM normalized RNA expression counts for each gene obtained from Consortium  that were \((1+x)\) normalized and standardized. For each gene, there are 218 different counts corresponding to the RNA expression level in different tissue types.

**Long-Range** RNA gene expression is regulated by non-coding elements, such as enhancers and silencers, which can be located hundreds of kilo-bps away from the gene , indicating the possible presence of long-range interactions in transcription regulation.

#### 3.2.2 Cap Analysis Gene Expression (CAGE) Profile

**Biological Relevance** CAGE provides accurate high-throughput measurements of RNA expression by mapping TSSs at a nucleotide-level resolution . This is vital for detailed mapping of TSSs, understanding gene regulation mechanisms, and obtaining quantitative expression data to study gene activity comprehensively.

**Task Definition** This task is described as a multi-variable, binned nucleotide-wise regression task. The data was constructed following the approach outlined in Basenji . Inputs are DNA sequences and the outputs are \((1+x)\) normalized CAGE expression counts from FANTOM5  given for each 128 bp bin of the input sequence. For each bin in a sequence, there are 50 different values corresponding to expression amounts across 50 human cell / tissue types.

**Long-Range** The production of RNA via transcription as measured by CAGE is regulated by non-coding elements that can be located hundreds of kilo-bps away from the gene, indicating the presence of long-range interactions in transcription regulation .

### Cis-Regulatory Element Detection

**Biological Relevance** Cis-regulatory elements, such as promoters and enhancers, control the spatial and temporal expression of genes . These elements are essential for understanding gene regulation mechanisms and how genetic variations can lead to differences in gene expression.

**Task Definition** This task is described as a binary classification problem. Data from Search Candidate Regulatory Elements by ENCODE (SCREEN ) was processed according to our approach outlined in Appendix B.3. Inputs are sequences sampled from across the entire human genome and outputs are binary values, where a positive label is assigned to a sequence if the center 200 bps of the input sequence overlap by at least 50% with an annotated enhancer or promoter. This task is composed of two sub-tasks: (1) predicting the presence of promoters and (2) predicting the presence of enhancers.

### Chromatin Feature Identification

**Biological Relevance** Predicting chromatin features, such as histone marks and DNA accessibility, is crucial for understanding gene regulation, as these features indicate chromatin state and are essential for transcription activation .

**Task Definition** This task is a multi-label binary classification problem constructed following Zhou & Troyanskaya , where sequences were sampled from the human genome as inputs and outputs correspond to binary labels for different chromatin profiles. The task contains two sub-tasks: one for predicting histone marks and another for predicting chromatin accessibility. For histone marks, each of the 20 binary values represents a different histone mark in a specific cell type. For DNAaccessibility, each of the 20 binary values corresponds to a different tissue/cell type. A value is labeled as positive if the center 200 bps of the input sequence overlaps by at least 50% with a peak region measured by ChIP-seq (histone marks) or DNase-seq (DNA accessibility) obtained from ENCODE and the Roadmap Epigenomics consortium .

### Improved Evaluation with Full Fine-tuning

To evaluate DNA LMs we perform fine-tuning, i.e., we train a model in a supervised manner on a downstream task. Our fine-tuning strategy involves extracting embeddings from each model which are then input to a task-specific prediction head (see Appendix D for details). In previous benchmarks, authors fine-tuned models by freezing the embeddings . We perform a systematic study of fine-tuning strategies and discover that this strategy significantly hurts DNA LM performance. We therefore provide a recipe for full-parameter fine-tuning and show that it significantly improves performance across many tasks, enabling us to evaluate models more fairly than in previous works and setting new best-practices for DNA LMs (independent of our benchmark).

### Additional Novel Features of the LRB

In addition to our careful curation of tasks and improved fine-tuning methodology, we highlight two more novel aspects of the LRB.

**Visualization Tool**: We provide benchmark users with a visualization tool in the form of an interactive jupyter notebook. To create this tool we collected additional genomic annotation datasets from SCREEN, GENCODE, RepeatMasker  and aligned them to our benchmark task datasets; see Appendix B.5 for details and screenshots. Our tool enables a deeper level of analysis compared to what other benchmarks afford. For example, users can view models' performance in aggregate, by specific annotations, and also by distance to TSSs.
**Arbitrary Sequence Length**: Our benchmark allows users to download arbitrary sequence lengths for any given tasks. This enables the probing of the effect of sequence length and lets users evaluate their LMs on the same context size on which they performed pre-training, mitigating any confounding from sequence length generalization effects.

### Selected Baselines

To contextualize the performance of DNA LMs, we curate a set of task-specific expert methods that are comprised of well-regarded supervised models.

**Combined annotation dependent depletion** (CADD)  is a SVM developed for detecting deleterious DNA variants trained on predicted neutral variants and simulated deleterious variants. We use this method as an expert baseline for our zero-shot variant effect prediction tasks.

**Enformer** is composed of both convolutional and transformer layers and trained in a supervised multi-task manner on various biological tasks using a context length of up to 196k bps. We use Enformer as the expert method for fine-tuning versions of variant effect prediction, gene expression prediction, and regulatory element detection tasks.

**DeepSEA** is a convolutional network trained to predict chromatin profile data, such as transcription factor binding, histone marks, and DNA accessibility. As our chromatin feature tasks are derived from DeepSEA, we use it as the expert method for these tasks.

## 4 Context Length Extension

Motivated by the long-range sequences present in the LRB, we explore methods for extending the context size of existing models. To that end, we focus on the Nucleotide Transformer model (NTv2 ), which originally has a context size of 12k bp and uses rotary positional embeddings (RoPE ). However, processing longer sequences with LMs like NTv2, which use the transformer 

[MISSING_PAGE_FAIL:7]

clearest example where DNA LMs fall short of CADD, which has nearly 2x better performance in ClinVar and about 100x in OMIM. When fine-tuning, we find that DNA LM performance on both variant tasks greatly improves, matching or surpassing the strong Enformer baseline.

**Gene Expression Prediction** While NTv2 is the best performing DNA LM for Bulk RNA and CAGE tasks, the baseline Enformer outperforms LMs by a wide margin.

**Regulatory Element Detection** DNA LMs are able to accurately predict the presence of regulatory elements, especially considering the class-imbalance present in promoter detection, with NTv2 performing best among DNA LMs. However, there remains a gap to the supervised Enformer model.

**Chromatin Feature Identification** For both histone mark and DNA accessibility, NTv2 is the best performing DNA LM, even exceeding the supervised baseline on the former task, and demonstrating significantly better performance than the other DNA LMs.

### Analyzing Results by Genomic Annotations

We developed an analysis and visualization tool to examine models performance across different genomic properties and annotations. Using our tool we are able to perform deeper analyses and extract insights about the performance of each model, which are inaccessible to users of existing benchmarks. We detail some examples in Figure 1.

**Causal eQTL Prediction (Fine-tune)** By stratifying SNPs into protein-coding and non-coding regions in Figure 0(a), we find a potential failure mode for both DNA LMs and supervised models. Non-coding variants presumably entail regulatory and possibly longer-range interactions, and all models perform worse in these regions.

**Bulk RNA Expression Prediction** In Figure 0(b), we see that the performance of DNA LMs and Enformer drops precipitously when focusing on non-\(5^{}\) regions that likely entail longer-range

    & **Context** & **Bulk RNA** & **CAGE** & **Promoter** & **Enhancer** & **Histone** & **DNA** \\  & _(bps)_ & _(\(R^{2}\))_ & _(\(R^{2}\))_ & _(AUPRC)_ & _(AUROC)_ & _(AUPRC)_ & _Accessibility_ \\   &  & _Fine-tune_ & _Fine-tune_ & _Fine-tune_ & _Fine-tune_ & _Fine-tune_ & _Fine-tune_ \\  & & 0.51 \(\) 0.050 & - & 0.71 \(\) 0.112 & 0.81 \(\) 0.022 & 0.24 \(\) 0.091 & 0.15 \(\) 0.064 \\ NTv2 500M & 12k & **0.57**\(\) 0.016 & **0.39**\(\) 0.011 & **0.79**\(\) 0.006 & **0.82**\(\) 0.002 & 0.38 \(\) 0.003 & **0.3**\(\) 0.007 \\ _Extended_ & 96k & 0.56 \(\) 0.037 & 0.36 \(\) 0.011 & 0.78 \(\) 0.003 & **0.82**\(\) 0.005 & **0.38**\(\) 0.004 & **0.3**\(\) 0.006 \\ HyenSDNA & 32k & 0.47 \(\) 0.010 & 0.22 \(\) 0.007 & 0.72 \(\) 0.007 & **0.82**\(\) 0.002 & 0.22 \(\) 0.003 & 0.084 \(\) 0.001 \\   &  0.80 \(\) 0.010 \\ (Enformer) \\  } &  0.49 \(\) 0.000 \\ (Enformer) \\  &  0.86 \(\) 0.006 \\ (Enformer) \\  &  0.92 \(\) 0.002 \\ (Enformer) \\  &  0.35 \\ (DeepSea) \\  & 
 0.44 \\ (DeepSea) \\  \\   

Table 4: Benchmarking performance of DNA LMs and baselines on gene expression, regulatory element, and chromatin features tasks. Models were evaluated in only a fine-tuned setting for this set of tasks. Best LM values are **bolded** and in green if LM beats baseline.

Figure 1: Results split by genomic annotations.

interactions. However, we also observe that the context-extended NTv2 outperforms Enformer on this region, implying that the majority of the performance gap between DNA LMs and the Enformer baseline lies in modeling variants in the 5\({}^{}\) regions.

**Enhancer Detection** In Figure 0(c), we observe that most models, including Enformer, suffer a performance hit when identifying enhancers within simple repeat regions, likely due to the difficulty of detecting enhancers within repetitive regions of the genome.

### Length Extension

To create the context extended model, we conduct additional training (\(\)5B tokens) on the pre-training dataset using the methodology described in Section 4 (and in Appendix D.5). For certain long-range tasks, the additional context extension pre-training improves performance. For example, for Causal eQTL prediction (with fine-tuning) in Figure 2 we see that the context extended NTv2 has the best DNA LM performance and that this trend is more pronounced when stratifying by SNP distance to TSS.

### Effect of Fine-tuning Methodology

In Table 5, we demonstrate the importance of our proposed fine-tuning. For two of the DNA LMs (see additional results in Appendix E.2), we show how full fine-tuning, as opposed to freezing LM weights and only training a prediction head, a common practice in existing benchmarks such as BEND , drastically improves model performance almost uniformly across tasks. We also believe our methodology is more in line with how practitioners would use DNA LMs in real-world settings.

## 6 Discussion and Conclusion

In this work, we introduced the Genomics LRB. Our benchmark is the first to truly evaluate long-range capabilities. We provided initial results for several prominent DNA LMs, with more in-depth analysis than previous benchmarks explored. Our results demonstrate the importance of fully fine-tuning models. Additionally, we identify several domains where a large performance gap needs to be bridged before DNA LMs can be reliably used and some failure modes of DNA LMs. Namely, zero-shot DNA LM variant effect prediction is not yet mature enough to replace widely-used tools, such as CADD. Similarly, for gene expression prediction, DNA LMs lag far behind supervised methods. In contrast, for annotation tasks, DNA LMs already demonstrate competitive performance relative to proven methods. These results demonstrate that future DNA LM efforts should focus on the more difficult tasks that entail long-range interactions, and we hope that our benchmark spurs such development.

**Future Work** One potential limitation of our work is the lack of hyperparameter search for fine-tuning; a more extensive search would better differentiate models. Another limitation is the lack of experimentally verified enhancer-gene pairings, which would allow for a more complete examination of the long-range capabilities of models. In future iterations of our benchmark, we also plan to add more tissue-specific analyses, bp-level annotation tasks, and tasks covering multiple species.

    &  **Causal eQTL** \\ _(AUCROC)_ \\  &  **Pathogenic** \\ _(AUCROC)_ \\  &  **Bulk** \\ _(K\({}^{2}\))_ \\  &  **CAGE** \\ _(R\({}^{2}\))_ \\  &  **Promoter** \\ _(AUPRC)_ \\  &  **Enhancer** \\ _(AUROC)_ \\  &  **Histone** \\ _(AUPRC)_ \\  & 
 **DNA** \\ _(AUPRC)_ \\  \\  NTv2 500M & +0.49 & +4.27 & +18.29 & +42.14 & -1.45 & +0.90 & +22.46 & +47.96 \\ HyenaDNA & +0.35 & +11.58 & +107.48 & +102.91 & +5.09 & +5.39 & +14.43 & -22.67 \\   

Table 5: Difference in performance of DNA LM fine-tuning strategies. Percent increase in performance of full fine-tuning vs. freezing LM weights and only training prediction heads.

Figure 2: Fine-tuned Causal eQTL variant task; by distance to nearest TSS.