# Fast and accurate training and sampling of Restricted Boltzmann Machines

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Thanks to their simple architecture, Restricted Boltzmann Machines (RBMs) are powerful tools for modeling complex systems and extracting interpretable insights from data. However, training RBMs, as other energy-based models, on highly structured data poses a major challenge, as effective training relies on mixing the Markov chain Monte Carlo simulations used to estimate the gradient. This process is often hindered by multiple second-order phase transitions and the associated critical slowdown. In this paper, we present an innovative method in which the principal directions of the dataset are integrated into a low-rank RBM through a convex optimization procedure. This approach enables efficient sampling of the equilibrium measure via a static Monte Carlo process. By starting the standard training process with a model that already accurately represents the main modes of the data, we bypass the initial phase transitions. Our results show that this strategy successfully trains RBMs to capture the full diversity of data in datasets where previous methods fail. Furthermore, we use the training trajectories to propose a new sampling method, _parallel trajectory tempering_, which allows us to sample the equilibrium measure of the trained model much faster than previous optimized MCMC approaches and a better estimation of the log-likelihood. We illustrate the success of the training method on several highly structured datasets.

## 1 Introduction

Energy-based models (EBMs) are a classic approach to generative modeling that has been studied for decades. They were introduced using the Restricted Boltzmann Machine formulation by Smolensky  and later further developed by Sejnowski et al. . They provide a straightforward method for modeling effective interactions within complex data distributions and for sufficiently simple energy functions, such as the Boltzmann machine (BM) , it is also possible to interpret and infer the underlying constituent rules from the observed data. This inference strategy is often associated with the inverse Ising problem and pairwise interaction models , and it has found a great variety of applications in fields such as neuroscience  or computational biology . A recent work has proposed replacing the use of pairwise models with the Restricted Boltzmann Machine (RBM) , as it allows the same direct interpretation of its energy function as an explicit many-body interaction model while greatly extending the expressive power of the model. RBMs are also very useful for grouping data into hierarchical families . On the diametrically opposite side (on interpretability) are generative ConvNets [9; 10], where the energy function is formulated as a deep neural network, which are capable of synthesizing photorealistic images but are almost impossible to interpret as a physical model.

The applications of simple EBMs in science are very diverse. For example, they are often used today to encode the Hamiltonian of physical many-body systems, such as Quantum wave functions  or the accurate determination of ground state wave functions of strongly interacting and entangledquantum spins  or they have proven to be suitable for the representation of the AdS/CFT correspondence in theories of quantum gravity [13; 14]. Simple EBMs are also very common to encode the evolutionary constraints in protein families [6; 15], and to predict mutations , or to generate realistic synthetic sequences, such as fake human genomes [17; 18]. These examples show that, despite their somewhat old-fashioned architecture, shallow EBMs are increasingly seen as useful tools for better understanding modern physics/biology, as they allow for a certain level of analytical description.

Despite the appealing modeling properties of RBMs, they are notoriously difficult to train, a challenge common to EBMs in general. The main difficulty arises from the computation of the log-likelihood gradient, which requires an ergodic exploration of a dynamically evolving and potentially complex free energy landscape using Markov Chain Monte Carlo (MCMC) processes. Recent studies have shown that models trained with non-convergent MCMC processes suffer from out-of-equilibrium dynamic memory effects [19; 20; 21]. This dynamical behavior can be explained analytically using moment-matching arguments [19; 22]. While exploiting these effects can yield fast and accurate generative models, even for highly structured data  or high-quality images with RBMs , this approach results in a sharp separation between the model's Gibbs-Boltzmann distribution and the dataset distribution, thereby undermining the interpretability of the model parameters [22; 7]. Thus, to extract meaningful information from datasets using RBMs, it is essential to ensure proper mixing of the chains during training, in short, one needs _equilibrium models_.

Both the ability to train an RBM in equilibrium and to generate convincing new samples from its equilibrium measure strongly depend on the dataset in question. For typical image datasets such as MNIST or CIFAR-10, good RBMs can be obtained by increasing the number of MCMC steps. However, this approach is no longer feasible for highly structured datasets . Datasets from which one seeks scientific insights are often highly structured, such as genomics/proteomics data or low-temperature many-body physical systems. These datasets typically exhibit distinct clusters, identifiable via principal component analysis (PCA) which form distant groups of similar entries. We show an example of the PCA of 4 clustered dataset we will be studying in this work in Fig. 1: details about these datasets are given in the caption and in the Supplemental Information (SI). During training, the model must evolve from an initial normal distribution to an increasingly multimodal distribution. Sampling from multimodal distributions is particularly challenging because the mixing times are determined by the transition times between modes. But this is not the only difficulty. These distant modes are encoded by second-order phase transitions during training [26; 27; 28], leading to diverging mixing times in these regions -- a phenomenon known as _critical slowdown_ --, which means that mixing times are expected to grow with a power of their system size. This sampling challenge not only hinders the training process, but also limits the model's ability to generate new samples. Obtaining new and independent configurations would require an impractically large number of sampling steps.

## 2 Related work

Training EBMs by maximizing log-likelihood has long been a challenge in the community [29; 10]. EBMs gained popularity with the introduction of the contrastive divergence algorithm , in which a set of parallel chains is initialized on independent examples in the minibatch and the MCMC process iterates for a few steps. Despite its widespread use, this algorithm yields models with poor equilibrium properties that are ineffective as generative models [31; 32; 21]. An improvement is the persistent contrastive divergence (PCD) algorithm , which maintains a permanent chain in which the last configurations used to estimate the previous gradient update are reused. PCD acts like a slow annealing process improving gradient estimation quality. However, it often fails on clustered data as the statistical properties of the permanent chain quickly move away from the equilibrium measure and degrade the model . This problem, which is primarily related to phase coexistence, can be addressed with constrained MCMC methods if appropriate order parameters are identified. For RBMs, these order parameters are related to the singular value decomposition of the model coupling matrix, which enables efficient reconstruction of multimodal distributions . Although this method is effective for evaluating model quality, it is too computationally intensive to be used in training, even if it leads to models with good equilibrium properties. Other optimized MCMC methods, such as the Parallel Tempering (PT)  algorithm, simulate multiple models at different temperatures, facilitating mixing through temperature exchange [35; 32]. However, PT is costly and often ineffective, especially because EBMs undergo first-order phase transitions at the temperature where PT typically fails because one needs too many temperatures to make the moves accepted. We will see below that a more appropriate approach exchanges the models at different training times, which only implies crossing second-order phase transitions.

The population annealing algorithm, which reweights parallel chains during learning based on their relative weight changes during parameter updates, was proposed as an alternative . Similarly, reweighting chains using non-equilibrium physics concepts such as the Jarzynski equality has been proposed . Both approaches struggle with highly structured data sets. To prevent the different chains to get too correlated around the training phase transitions, one must either increase the number of sampling steps or decrease the learning rate, which in practice means very long training processes to ensure a proper equilibrium training. Another strategy is to use EBMs as corrections for straightforward-to-sample flow-based models . This simplifies sampling and learning, but sacrifices the interpretability of the energy function, which was our goal. An evolving flow model can be used as a fast sampling moves proposer for the EBM  objective. This method requires the training of two different networks in parallel and may result in the drop of the move acceptance as the EBM becomes specialized.

For RBMs, a recent method called "stacked tempering"  dramatically speeds up sampling by training smaller RBMs with latent variables from previous models, allowing fast updates to be proposed using a PT like algorithm. Authors also showed that this algorithm was much faster than the standard PT. While effective, it is too cumbersome for use in training. Also for RBMs, it has

Figure 1: **Clustered datasets. In A-C we show the 4 different clustered data sets that we will consider in this paper, projected onto their first two PCA components. In A we show the data of the MNIST 01 dataset (both projected and some instances), which contains only the 0-1 images of the complete MNIST dataset. In B, we show the Mickey dataset, an artificial dataset whose PCA forms a “Mickey” face shape. In C, we show data from the Human Genome Dataset (HGD), which contains binary vectors each corresponding to a human individual and whose sites correspond to selected genes. A value of 1 at a particular position means that a mutation was observed there compared to an individual reference sequence. Details of these data sets can be found in the SI. In D-F we show the samples we generate with the low-rank RBMs that are used as initial point of a standard training.**

recently been shown that it is possible to train a low-rank RBM that accurately reproduces the statistics of the data projected along the \(d\) first data principal directions through a convex and very fast optimization process (see  and the discussion below). This low-rank model can be seen as a good approximation to the correct RBM needed to describe the data, and has the nice property that it can be efficiently sampled via a static Monte Carlo process.

In this paper, we will show how to drastically reduce training times by starting the RBM training process at this low-rank RBM, as this means that the first and strongest dynamic effects associated with them are directly bypassed. We also show that one can exploit the training trajectory to develop an effective sampling method, the _parallel trajectory tempering_ (PTT) that outperforms the "stacked tempering"  and only requires saving a reduced number of models during the training. This strategy also allows to obtain reliable estimations for the log-likelihood in well-trained models, much better than those obtained with the standard Annealing Important Sampling (AIS) techniques . Using both strategies, we show that we are able to train and evaluate methods that accurately represent the different modes in the dataset, where standard methods lead to mode collapse effects.

## 3 The Restricted Boltzmann Machine

The RBM is composed by \(N_{}\) visible nodes and \(N_{}\) hidden nodes. In our study, we primarily use binary variables \(\{0,1\}\) or \( 1\) for both layers. The two layers (visible and hidden) interact via a weight matrix \(\), with no direct couplings within a given layer. Variables are also adjusted by visible and hidden local biases, \(\) and \(\), respectively. The Gibbs-Boltzmann distribution for this model is expressed as

\[p(,)=[-(,)] { where }(,)=-_{ia}v_{i}w_{ia}h_{a}-_{i}_{i}v_{i} -_{a}_{a}h_{a},\] (1)

where \(Z\) is the partition function of the system. As with other models containing hidden variables, the training objective is to minimize the distance between the empirical distribution of the data, \(p_{}()\), and the model's marginal distribution over the visible variables, \(p()=_{}[-(,)]/Z= [-H()]/Z\). Minimizing the Kullback-Leibler divergence is equivalent to maximizing the likelihood of observing the dataset in the model. Thus, the log-likelihood \(=-H()_{}- Z\) can be maximized using the classical stochastic gradient ascent. For a training dataset \(=\{^{(m)}\}_{m=1,,M}\), the log-likelihood gradient is given by

\[}{ w_{ia}}= v_{i}h_{a}_{ }- v_{i}h_{a}_{},\ }{_{i}}= v_{i}_{ }- v_{i}_{},\ }{ _{a}}= h_{a}_{}- h_{a}_{ },\] (2)

where \(_{}\) denotes the average with respect to the entries in the dataset, and \(_{}\) with respect to \(p(,)\). Since \(Z\) is intractable, the model averages in the gradient are typically estimated using \(N_{}\) independent MCMC processes, and observable averages \( o(,)_{}\) are replaced by \(_{r=1}^{R}o(^{(r)},^{(r)})/R\), with \((^{(r)},^{(r)})\) being the last configurations reached with each of the \(r=1,,R\) parallel chains. To obtain reliable estimates, it should be ensured that each of the Markov chains mix well before each parameter update. However, ensuring equilibrium at each update is impractical, slow and tedious. The common use of non-convergent MCMC processes is the cause of most difficulties and weird dynamical behaviors encountered in training RBMs .

Typical MCMC mixing times in RBMs are very small at the beginning of the training and grow as it progresses , suffering with sharp increases every-time the training trajectory crosses each of the critical transitions that give birth to new modes . In order to minimize out-of-equilibrium effects, it is often useful to keep \(R\)_permanent (or persistent)_ chains, which means that the last configurations reached with the MCMC process used to estimate the gradient at a given parameter update \(t\), \(_{t}\{(_{t}^{(r)},_{t}^{(r)})\}_{r=1}^{R}\), are used to initialize the chains of the subsequent update \(t+1\). This algorithm is typically referred as PCD. In this scheme, the process of training can be mimicked to a slow cooling process, only that instead of varying a single parameter, the temperature, a whole set of parameters \(_{t}=(_{t},_{t},_{t})\) are updated at every step to \(_{t+1}=_{t}+_{t}\) with \(_{t}\) being the gradient in Eq. (2) estimated using the configurations in \(_{t}\), and \(\) being the learning rate.

The low-rank RBM pretrained

In Ref. , it was shown that it is possible to train exactly (i.e. by direct numerical integration instead of MCMC sampling) an RBM containing a reduced number of modes in the weight matrix \(\) by exploiting a mapping between the RBM and a Restricted Coulomb Machine and solving a convex optimization problem, see the SI. In other words, it is possible to train a RBM with a coupling matrix of this simplified form

\[=_{=1}^{d}w_{}}_{}_{}^{ },(_{},}_{})^{N_{}}^{N_{}},\] (3)

and where the right singular vectors \(\{_{}\}_{=1}^{d}\) correspond exactly to the first \(d\) principal directions of the data set. Under this assumption, it is possible to write \(p()\) only as a function of \(d\) order parameters given by the _magnetizations_ along each of the \(u_{}\) components, \(m_{}()=_{}/}}\), and in particular,

\[H()=-_{a}(}}_{a}_{= 1}^{d}w_{}m_{}+_{a})=(()),\] (4)

where \(=(m_{1},,m_{})\). As proposed in , the optimal parameters of such a model can basically be determined by solving a regression problem. We describe this method in details in the SI. This means that once the model is trained, we obtain a probability \(p()\) defined on a much lower dimension than the original \(p()\). Such a probability can be straightforwardly sampled using _inverse transform sampling_. Since this method requires a discretization of the \(\)-space both for training and generation, we cannot consider intrinsic space dimension \(d>4\) dimensions in practice. These low-rank RBMs are then trained to reproduce the statistics of the dataset projected in its first \(d\) principal components. Despite their simplicity, the low-rank models are already able to generate an approximate version of the dataset, as shown in Fig. 1-D-F for the 4 datasets previously presented.

In the initial stage of the standard learning process, the model encodes the strongest PCA components of the data through multiple critical transitions . Pre-training with the low-rank construction allows us to bypass these transitions and avoid out-of-equilibrium effects caused by critical slowing down associated to these transitions. Once the main directions are incorporated, training can efficiently continue with standard algorithms like PCD, as the mixing times of pre-trained machines tend to be much shorter. In particular, in the PCD-100 training with MNIST01, relaxation times for the visible variables' time correlation reach \(5 10^{5}\) MCMC steps at the first three transitions, coinciding with the growth of singular values in the model weight matrix \(W\). In contrast, the pre-trained machine has a much shorter relaxation time of \( 10^{3}\), allowing us to safely restart the PCD process from a set of equilibrium samples generated by static sampling of the low-rank RBM.

Overcoming these transitions has dramatic implications for the quality of the models we can train and how accurately they reproduce the statistics of the data. In Fig. 2, we show for 3 datasets the equilibrium samples drawn from 3 RBMs trained with identical number of samples, minibatch size, \(k=100\) Gibbs steps, and learning rate \(=0.01\), but different training strategies. In particular, we consider 2 RBMs trained from scratch with the standard PCD  and the recently proposed Jarzynski reweighing method  (see SI for our specific implementation in the RBM), and a final machine trained with PCD and pre-trained with a low-rank RBM. In all cases, the quality of the generated samples is significantly better when pre-training is used. For the Mickey dataset, neither JarRBM nor normal PCD are able to generate convincing data. For the MNIST01 dataset, all 3 methods are able to generate convincing data, but only Pretrain+PCD is able to correctly balance all modes, as can be seen in Fig. 3, where we compare the histograms of the generated data projected onto the first 3 PCA directions with those of the dataset and a random selection of the generated samples. We see that the pre-training+PCD training perfectly balances the different modes (here we show the first 3 directions, but it goes much further), unlike the other 2 methods, and also generates more diverse images. We can also compare the log-likelihood of all 3 models and find that the pre-trained RBM achieves higher values. At this point, it is important to emphasize that in order to properly quantify the increase in log-likelihood, we need to use the PTT algorithm (see section 5) to correctly thermalize in these well-trained machines. For comparison, we show our PTT measure in dark and solid lines, while the standard AIS  estimate is shown in light dashed lines.

Already from the scatter plots we see that the pre-training has a dramatic effect in obtaining models where all modes are properly balanced, but also has important effects in the maximum test-likelihoodwe can achieve. In all cases, these equilibrium samples are drawn using the trajectory PT algorithm that will be explained in the next section, and the log-likelihood obtained using the equilibrium configurations obtained at different epochs as a result of the trajectory PT flow.

## 5 Standard Gibbs sampling vs. Parallel Trajectory Tempering (PTT)

One major challenge with structured datasets is quantifying the model's quality, since sampling the equilibrium measure of a well-trained model is often too time-consuming. This affects the reliability of generated samples and indirect measures as log-likelihood's estimation through Annealing Importance Sampling (AIS) , making them inaccurate and meaningless.

To illustrate this problem, let us consider the MNIST01 and the HGD datasets. MNIST01 dataset is bimodal and the HGD highly multimodal as shown in their PCA in Figs. 1-A and C. Let us consider that we want to sample the equilibrium measure of the RBMs trained using low-rank RBM pretraining. In order to draw new samples from these models, one would typically run MCMC processes from random initialization and iterate them until convergence. The mixing time is controlled by the jumping time between clusters. To accurately estimate the relative weight between modes, the MCMC processes must be ergodic, requiring many back-and-forth jumps. However, as shown in Figs. 4-A and C for the MNIST01 and HGD datasets, Gibbs sampling dynamics are extremely slow, rarely producing jumps even after \(10^{4}\) MCMC steps. The yellow curves in Figs. 4-B and D show the mean number of jumps over 100 independent chains as a function of MCMC steps, indicating that a proper equilibrium generation would require at least \(10^{6}-10^{7}\) MCMC steps.

One effective way to accelerate the dynamics is to exploit the training trajectory, where the model progressively specializes through second-order phase transitions. To achieve this, we save RBMs trained at various epochs and propose swaps between configurations of similarly trained models. We

Figure 2: We compare the equilibrium samples generated by RBMs trained on the Mickey, MNIST01, and HGD datasets using three different training schemes: Jarzynski (JarRBM), PCD, and PCD initialized on low-rank RBMs (used to generate the samples in Fig. 1–D-F). To assess the fitting of the modes, we show a density plot of the projections of the data in the first two principal directions of each dataset. We compare these results with the density plot of the original datasets in the first column.

call this the _Parallel Trajectory Tempering_ (PTT) algorithm. Unlike the standard Parallel Tempering (PT) algorithm, which attempts swaps configurations between different temperatures, the PTT swaps between model parameters with different degrees of specialization. This approach is more natural for this problem because it involves crossing only second-order transitions, unlike the first-order transitions occurring in temperature annealing. And in fact, we show in Figs. 4-A and C, that this approach allows us to sharply accelerate the dynamics, as opposed to the standard PT algorithm (studied in detail for the MNIST dataset in ).

In the PTT algorithm, the configurations \(=(,)\) of neighboring machines indexed by \(t\) and \(t-1\) are interchanged with the probability

\[p_{}(^{t}^{t-1})=(1, (^{t}(^{t})-^{t}(^{t-1}) )).\]

This move satisfies detailed balance with our target equilibrium distribution \(p()=(-())/Z\), ensuring that the moves lead to the same equilibrium measure. As "nonspecialized" models mix very quickly, either because the distribution is essentially Gaussian at the initialisation of a standard training, or because the low-rank RBM can be sampled with a static Monte Carlo process (yielding independent configurations each time), the trajectory flow significantly accelerates convergence to equilibrium. The time interval between successive machines is selected in such a way that the probability of accepting interchanges between neighboring machines remains around 0.3. Pre-trained machines require a significant fewer number of models to be effective, because most selected models are positioned at the most prominent phase transitions. We give the number of machines used for each sampling process in the SI. We also provide there a specific and detailed description of the algorithm used.

In the red curves in Fig. (4)-B and D, we show the number of jumps between clusters as a function of the number of elementary MCMC steps, which in the PTT scheme refer to 1 Gibbs sampling step + one swap proposal. For the DNA dataset, we have two measures corresponding to jumps along the two principal component directions. We observe at \(10^{4}\) MCMC steps an increase of the number of jumps by a factor of 80 for MNIST01 and by a factor of 1350 for the HGD in this machine, although

Figure 3: We compare the samples generated by the 3 RBMs (JarRBM, PCD, pretrain+PCD) trained with MNIST01 data. In A, we show the histograms of the generated data projected on the first, second and third principal directions with those of the dataset. We see that only the pretrain+PCD correctly balances the different modes. In B we show 10 images generated by each machine. In C, we compare the log-likelihood of each model’s dataset as a function of training time. The dark and full curves were obtained using the PTT algorithm discussed in section 5, and the lighter and dashed curves using the AIS method .

we achieve higher factors in other machines, as we show in the SI. The sampling of RBMs training on the MNIST01 dataset was the subject of the study of the "stacked tempering" algorithm in . If we compare the numbers with their work, we see that we achieve a 3-4 times higher speedup factor, where our model has the advantage that it does not need additional training, but simply uses the stored machines correctly.

Another desirable advantage of our PTT algorithm is that we can easily use it to compute an improved estimate of the AIS log-likelihood, except that in our case we consider the training trajectory instead of a cooling process and use the equilibrium samples obtained for each of the models to compute the model averages. In Figs. 3-C 5-A we compare the log-likelihood estimates obtained with our method (AIS-PTT) in full and dark lines and in light and dashed lines the AIS estimate (AIS). We see that both measures coincide for most parts of the training and that they split when the sampling becomes too long to thermalize along the temperature annealing curve in AIS. This effect is particularly evident for the JarRBM run in 5-A, where AIS takes a long time to recognize that the model suffers from a strong mode-collapse effect.

## 6 Overfitting and privacy loss as quality indicators

In this section, we examine the quality of the samples generated, regarding overfitting and privacy criteria which have been defined for genomic data in particular. We look at this on the models trained with PCD with and without pre-training. We do not include the Jarzynski method here, as this method fails to obtain a reliable model as clearly shown in the evolution of the Log-likelihood in Fig. 5. We focus on the human genome dataset, as shown in Fig. 1-C, to evaluate the ability of various state-of-the-art generative models to generate realistic fake genomes while minimizing privacy concerns (i.e., reducing overfitting). Recent studies [17; 18] have thoroughly investigated this for a variety of generative models. Both studies concluded that the RBM was the most accurate method for generating high-quality and private synthetic genomes. The comparison between models relies primarily on the Nearest Neighbor Adversarial Accuracy (\(AA_{}\)) and privacy loss indicators, introduced in Ref. , which quantify the similarity and the level of "privacy" of the data generated by a model w.r.t. the training set. We have \(AA_{}=AA_{}+AA_{} \) where \(AA_{}\) [resp. \(AA_{}\)] are two

Figure 4: Comparison between PTT and classical Gibbs sampling for the MNIST01 dataset (A and B, respectively) and the human genome dataset (C and D, respectively). In A and C, we show the trajectory of two independent chains (red and orange) projected onto the PCA along the sampling process of the pretraining+PCD model for \(10^{4}\) MCMC steps. The black contour represents the density profile of the dataset and the position of the chains is plotted every 10 steps. In B and D we show the average number of jumps from one cluster to another as a function of the MCMC steps performed. The average is calculated over a population of 100 chains. In D, we show the average jump time between clusters along the first (solid line) and second (dashed line) principal components of the data.

quantities in \(\) obtained by merging two sets of real and synthetic data of equal size \(N_{s}\) and measuring respectively the frequency that a real [rep. synthetic] has a synthetic [resp. real] as nearest neighbor. If the generated samples are statistically indistinguishable from real samples, both frequencies \(AA_{}\) and \(AA_{}\) should converge to 0.5 at large \(N_{}\). \(AA_{}\) can be evaluated both with train or test samples and the privacy loss indicator is defined as \(=AA_{}^{}-AA_{}^{ }\) and is expected to be strictly positive. Fig. 5 shows the comparison of \(AA_{}\) and privacy loss values obtained with our two models, demonstrating that the pre-trained RBM clearly outperforms the other model, and even achieves better results (\(AA_{}\) values much closer to 0.5) than those discussed in .

## 7 Conclusions

We have shown that the strategy of initiating the training on a pre-trained low-rank RBM is an extremely effective strategy to obtain high quality models for structured datasets that accurately represent all the modes in the datasets and with significantly higher log-likelihoods. We have also shown that the models obtained in that way are: (i) better generative models than those obtained with standard trainings, both, in the sense that they over-fit less at the same time they are more indistinguishable from the test samples, (ii) they display faster relaxational dynamics.

We have also proposed a new fast sampling method that exploits the progressive learning of features in the training of RBMs to design an efficient trajectory PT strategy that allows accelerating the parallel Gibbs sampling dynamics by many orders of magnitude and overcome the performance of recent efficient sampling methods without adding any extra cost than saving models during the training.

Both strategies for training and sampling are very general, and could be generalized to more complex EBMs. In this sense, the low-rank RBM model could be used as a more efficient pre-initialisation in deeper structures, and the trajectory PT algorithm is suitable to be directly used in any EBM no matter how complex it is.

## 8 Code availability

The code and datasets are available at https://github.com/nbereux/fast-RBM.

Figure 5: We compare the quality of the RBMs trained with the human genome data (HGD). In A, we show the log-likelihood as a function of the training epochs for the 3 training procedures. Solid lines correspond to AIS-PTT and dashed lines to AIS. The JarRBM falls down because the training breaks eventually. In B and C we compare privacy and overfitting based on the \(AA_{}\) indicator.