# MultiPull: Detailing Signed Distance Functions by Pulling Multi-Level Queries at Multi-Step

Takeshi Noda\({}^{1}\)1 Chao Chen\({}^{1}\)1 Weiqi Zhang\({}^{1}\) Xinhai Liu\({}^{2}\)

Yu-Shen Liu\({}^{1}\)2 **Zhizhong Han\({}^{3}\)**

\({}^{1}\)School of Software, Tsinghua University, Beijing, China

\({}^{2}\)Tencent, Hunyuan, Beijing, China

\({}^{3}\)Department of Computer Science, Wayne State University, Detroit, USA

yeth21@mails.tsinghua.edu.cn chenchao19@tsinghua.org.cn

zwq23@mails.tsinghua.edu.cn adlerxhliu@tencent.com

liuyushen@tsinghua.edu.cn h312h@wayne.edu

Equal contribution. \({}^{}\)The corresponding author is Yu-Shen Liu.

###### Abstract

Reconstructing a continuous surface from a raw 3D point cloud is a challenging task. Recent methods usually train neural networks to overfit on single point clouds to infer signed distance functions (SDFs). However, neural networks tend to smooth local details due to the lack of ground truth signed distances or normals, which limits the performance of overfitting-based methods in reconstruction tasks. To resolve this issue, we propose a novel method, named MultiPull, to learn multi-scale implicit fields from raw point clouds by optimizing accurate SDFs from coarse to fine. We achieve this by mapping 3D query points into a set of frequency features, which makes it possible to leverage multi-level features during optimization. Meanwhile, we introduce optimization constraints from the perspective of spatial distance and normal consistency, which play a key role in point cloud reconstruction based on multi-scale optimization strategies. Our experiments on widely used object and scene benchmarks demonstrate that our method outperforms the state-of-the-art methods in surface reconstruction. Project page: https://takeshie.github.io/MultiPull

## 1 Introduction

Reconstructing surfaces from 3D point clouds is an important task in computer vision. It is widely used in various real-world scenarios such as autonomous driving, 3D scanning and other downstream applications. Recently, using neural networks to learn signed distance functions from 3D point clouds has made huge progress [1; 2; 3; 4; 5; 6; 7; 8]. An SDF represents a surface as the zero-level set of a 3D continuous field, and the surface can be further extracted using the marching cubes algorithm . In supervised methods [10; 11; 12; 13], a continuous field is learned using signed distance supervision. Some methods employ multi-level representations [14; 15], such as Fourier layers and level of detail (LOD) [16; 17], to learn detailed geometry. However, these methods require 3D supervision, including ground truth signed distances or point normals, calculated on a watertight manifold. To address this issue, several unsupervised methods [18; 19; 20; 21; 22] were proposed to directly infer an SDF by overfitting neural networks on a single point cloud without requiring ground truth signed distances and point normals. They usually need various strategies, such as geometric constraints [18; 19; 20] and consistency constraints [22; 23], for smoother and more completed signed distance field. However, the raw point cloud is a highly discrete approximation of the surface, learningSDFs directly from the point cloud is often inaccurate and highly ambiguous. This makes it hard for the network to learn accurate SDFs on local details, resulting in over-smooth reconstruction.

To address this issue, we propose _MultiPull_, to learn an accurate SDF with multi-scale frequency features. It enables network to predict SDF from coarse to fine, significantly enhancing the accuracy of the predictions. Furthermore, to optimize the SDF at different scales simultaneously, we introduce constraints on the pulling process. Specifically, given query points sampled around 3D space as input, we use a Fourier transform network to represent them as a set of Fourier features. Next, we design a network that can leverage multi-scale Fourier features to learn an SDF fields from coarse to fine. To optimize the signed distance fields with multi-scale features, we introduce a loss function based on gradient consistency and distance awareness. Compared with Level of Detail (LOD) methods [16; 17; 24], we can optimize the signed distance fields effectively without a need of signed distance supervision, recovering more accurate geometric details. Evaluations on widely used benchmarks show that our method outperforms the state-of-the-art methods. Our contribution can be summarized as follows.

* We propose a novel framework that can directly learn SDFs with details from raw point clouds, progressing from coarse to fine. This provides a new perspective for recovering 3D geometry details.
* We introduce a multi-level loss function based on gradient consistency and distance awareness, enabling the network to geometry details.
* Our method outperforms state-of-the-art methods in surface reconstruction in terms of accuracy under widely used benchmarks.

## 2 Related Work

Classic methods for geometric modeling [25; 26; 27; 28] have attempted to analyze the geometric modeling of objects, which do not require large-scale datasets. With the advent of extensive and intricate 3D datasets like ShapeNet  and ABC , learning-based methods have achieved significant advancements [18; 12; 31; 32; 22; 33; 34; 35; 36; 37; 38]. These approaches learn implicit representations from various inputs, including multi-view images[39; 40; 41; 42; 43; 44], point clouds [45; 46; 47], and voxels [48; 49; 50].

**Learning Implicit Functions with Supervision**. Supervised methods have made significant progress in recent years. These methods leverage deep learning networks to learn priors from datasets or use real data for supervision [10; 11; 51; 52; 53; 54] to improve surface reconstruction performance. Some supervised approaches use signed distances and point normals as supervision, or leverage occupancy labels to guide the network's learning process. In order to improve the generalization ability of neural networks and learn more geometric details, some studies learn geometry prior of shapes through supervised learning.

Figure 1: Visualization of the 3D shape reconstruction. In (a), (b) and (c), SDFs are learned from a point cloud by optimizing multi-level query points at multi-step. At each step, we optimize query points at one level with frequency features at this specific level as conditions. This enables the network to progressively recover coarse-to-fine geometry details.

**Learning Implicit Functions with Conditions**. To alleviate the dependence on supervised information, recent studies focus on unsupervised implicit reconstruction methods. These methods do not require pretrained priors during optimization. For example, NeuralPull (NP)  learns SDF by pulling query points in nearby space onto the underlying surface, which relies on the gradient field of the network. CAP  further complements this by forming a dense surface by additionally sampling dense query points. GridPull  generalizes this learning method to the grid, by pulling the query point using interpolated signed distances on the grid. In addition, some studies explore surface reconstruction more deeply and propose innovative methods, such as utilizing differentiable Poisson solutions , or learning signed [57; 58; 19; 51] or unsigned functions [59; 55] with priors. However, inferring implicit functions without 3D supervision requires a lengthy convergence process, which limits the performance of unsupervised methods on large-scale point cloud datasets. To address this, we propose a fitting-based frequency feature learning strategy that efficiently learns implicit fields without the need for additional supervision.

**Learning Implicit Functions with LOD**. Level-Of-Detail (LOD) models [16; 17; 24] are used to simplify code complexity and refine surface details through the architecture of multi-level outputs. Previous studies have explored multi-scale architectures in various reconstruction tasks. For example, NGLOD  uses octree-based feature volumes to represent implicit surfaces, which can adapt to shapes with multiple discrete levels of detail and enable continuous level-of-detail switching through SDF interpolation. MFLOD  applies Fourier layers to LOD, which can offer better feasibility in Fourier analysis. However, it is difficult to optimize multi-level features simultaneously to learn 3D shapes. To address this issue, we propose a novel strategy to optimize multi-level frequency features, allowing the network to progressively learn geometric details from coarse to fine.

## 3 Method

**Overview**. The overview of MultiPull is shown in Fig. 2. We design a neural network to learn an implicit function \(f\) from a single 3D point cloud by progressively pulling a set of query points \(Q_{0}\) onto the underlying surface, where \(Q_{0}\) is randomly sampled around the raw point cloud \(S\). Our network mainly consists of two parts as follows.

(1) The Frequency Feature Transformation (FFT) Module ( Fig. 2(a)) aims to convert the query points \(Q_{0}\) into a set of multi-level frequency features \(Y=\{y_{i},i[0,N_{L}-1]\}\). The key insight for introducing frequency features lies in a flexible control of the degree of details. (2) The Multi-Step Pulling (MSP) Module (Fig. 2(b)) is designed to predict \(f\) with coarse-to-fine details under the guidance of frequency features \(Y\). At the \(i\)-th step, we pull \(Q_{i}\) to \(Q_{i+1}\) using the predicted signed distances \(s_{i}=f(Q_{i},y_{i})\) and the gradients at \(Q_{i}\), according to its feature \(y_{i}\). To this end, we constrain query points to be as close to their nearest neighbor point on \(S\).

Figure 2: Overview of our method: (a) Frequency Feature Transformation (FFT) module and (b) Multi-Step Pulling (MSP) module. In (a), we learn Fourier bases \(h_{i}(Q)\) from query points \(Q\) using the Fourier layer and obtain multi-level frequency features \(y_{i}\) through Hadamard product. In (b), using multi-level frequency features from (a) and a linear network **LSNN** with shared parameters, we calculate the distance(D) of \(Q_{i}\) to its corresponding surface target point \(Q_{t}\) to predict a more accurate surface. We visualize the predicted SDF distribution map corresponding to the frequency features in (a) and the reconstruction from each step of SDF predictions on the right side of (b).

### Frequency Feature Transformation (FFT) Module

We introduce a neural network to learn frequency features \(Y\) from point clouds. The network manipulates input \(Q_{0}\) through several linear layers to obtain an initial input \(z_{0}\) and a set of Fourier basis \(h_{i}(Q_{0}),i[0,N_{L}-1]\), formulated as follows.

\[h_{i}(Q_{0})=(_{i}Q_{0}+_{i}),\\  z_{0}=h_{0}(Q_{0}),\] (1)

where \(_{i}\) and \(_{i}\) are the parameters of the network, and \(N_{L}\) is the number of layers of the network.

To effectively represent the expression of the raw input in the frequency space, we choose the sine function as the activation function and employ the Hadamard product to compute the intermediate frequency feature output. Since the Hadamard product allows the representation of frequency components as the product of two feature inputs, denoted as \(a\) and \(b\), which can be formulated as:

\[(a)(b)=((a+b-)+(a-b+)).\] (2)

Through Eq. (2), we can calculate the frequency component \(z_{i}\) of \(h_{i}(Q_{0})\), and then obtain the output \(y_{i}\) of the \(i\)-th layer, formulated as:

\[z_{i}=h_{i}(Q_{0})(W_{i}z_{i-1}+b_{i}),i[1,N_{L}-1],\\ y_{i}=W_{i}z_{i}+b_{i},\] (3)

where \(\) indicates the Hadamard product, \(W_{i},b_{i}\) are parameters of the network.

Frequency networks based on the Multiplication Filter Network (MFN)  typically employ uniform or fixed-weight initialization for network parameters in practice. This approach overlooks the issue of gradient vanishing in deep network layers during the training process, leading to underfitting and making the network overly sensitive to hyperparameter changes. To address this challenge, we propose a new initialization scheme that thoroughly considers the impact of network propagation, aiming at ensuring a uniform distribution of initial parameters. Specifically, we dynamically adjust initial weights, which can be formulated as:

\[_{i}=)},i[1,N_{L}-1],\] (4)

where \(N_{L}\) and \(\) are the number of layers and the parameters of the network, respectively. We leverage the standard deviation as the initialization range to ensure that the parameters in Eq. (3) are within a reasonable range. As shown in Fig. 3, we compared the parameter distributions of different linear layers. The initialization scheme based on MFN results in gradient vanishing and small activations in deeper linear layers. In contrast, our initialization scheme ensures that the parameters of each linear layer follow a standard normal distribution.

### Multi-Step Pulling (MSP) Module

In Fig. 2(b), we demonstrate our idea of learning an accurate implicit function \(f\) with multiple frequency features. Given a set of frequency feature \(Y\), we use frequency features \(y_{i}\) in \(Y\) as the

Figure 3: Comparison of parameter distributions of different linear layers especially in \((L_{2},L_{4},L_{6},L_{8})\). We show the different initialization strategies on the results of the reconstruction task and the visualization effects in B.

input along with query points \(Q_{i}\) for the MSP module. We follow NP to construct initial query points and calculate the stride and direction of \(Q_{i}\) at \(i\)-th step for pulling it to the target surface point. Furthermore, we use the direction of the gradient as \( f(Q_{i},y_{i})\) and signed distance \(f(Q_{i},y_{i})\) for the pulling, where \( f(Q_{i},y_{i})\) represents the fastest increase in signed distance in 3D space, pointing away from the surface direction. Therefore, \(Q_{i}=Q_{i-1}-f(Q_{i-1},y_{i-1}) f(Q_{i-1},y_{i-1})/ f (Q_{i-1},y_{i-1})_{2}\). For each step of pulling the query points \(Q_{i}\), it corresponds to a nearest point \(q_{i}\) on the surface, and the distance between query points and surface points can be described as \(D_{i}=||Q_{i}-q_{i}||_{2}^{2}\). Based on this, we initiate the optimization by pulling query points \(Q_{i}\) the target points \(q_{i}\) progressively. Therefore, we can obtain the combined loss \(_{}\) under optimal conditions:

\[_{}=_{i=1}^{I}D_{i},i[1,I],\] (5)

where \(I\) is the step of moving operation. However, optimizing all query points accurately through this equation alone is challenging when merely constraining surface points. This is because the query points \(Q_{i}\) may be located across multiple spatial scales with inconsistent gradient directions, indicating that simultaneous optimization becomes challenging. Consequently, some outlier points may not be effectively optimized. Additionally, for sampling points near target points, some surface constraints are required to enable the network to accurately predict their corresponding zero level-set to avoid optimization errors. Therefore, we will further advance Eq. (5) from the perspectives of distance constraints, gradient consistency, surface constraints in Sec. 3.3 to enhance network performance.

### Loss Function

**Distance-Aware Constraint**. Inspired by FOCAL , we design a novel constraint with distance-aware attention weights \(\) to ensure that the network pays more attention to the optimization of underfitting query points in space and optimizes the SDFs simultaneously. This allows query points at different distances from the surface to be optimized properly, and assigns higher attention weights for outlier and underlying points:

\[\{ _{1},_{2}&=softmax(D_{1},D_ {2}),\\ _{}&=_{1}D_{1}+_{2 }^{*}D_{2}+D_{3},.\] (6)

where \(_{1}\) and \(_{2}\) are calculated from \(D_{1}\), \(D_{2}\) by the softmax activation, \(\) is a scaling coefficient we set to 2 by default. Here, we only consider 3 steps, which is a trade-off between performance and efficiency.

**Consistent Gradients**. We additionally introduce consistency constraints in the gradient direction. This loss encourages neighboring level sets to keep parallel, which reduces the artifacts off the surface and smooths the surface. We add a cosine gradient consistency loss function to encourage the gradient direction at the query points to keep consistent with the gradient direction at its target point on the surface, which aims to improve the continuity of the gradient during the multi-step pulling. We use \(Q_{1},Q_{2}\) and \(Q_{3}\) to represent the query points that have been continuously optimized by the multiple steps. We take the one with the lowest similarity score to measure the overall similarity.

\[\{ & L_{}(Q_{i})=( f(Q_{i},y_{i}),  f(Q_{0},y_{0})),\\ &_{}=1-\{L_{}(Q_{1}),L_{}(Q _{2}),L_{}(Q_{3})\},.\] (7)

where \(L_{}(Q_{i})\) represents the loss of cosine similarity between query points \(Q\) and target surface points \(q\).

**Surface Constraint**. We introduce the surface constraint for the implicit function \(f\), aiming to assist the network in approaching the zero level-set on the surface at final step. Hence, we constrain the \(f(Q_{I},y_{I})\) approaches zero at the final step:

\[_{}= f(Q_{I},y_{I}).\] (8)

**Joint Loss Function**. Overall, we learn the SDFs by minimizing the following loss function \(\).

\[=_{}+_{}+ _{},\] (9)

where \(\) and \(\) are balance weights. In the subsequent ablation experiments, we validated the effectiveness of different loss functions.

Experiments

In this section, we evaluate the performance of MultiPull in surface reconstruction by conducting numerical and visual comparisons with state-of-the-art methods on both synthetic and real-scan datasets. Specifically, in Sec. 4.1, we experiment on synthetic shape datasets with diverse topological structures. Furthermore, in Sec. 4.2, we report our results across various scales on real large-scale scene datasets. Meanwhile, we consider FAMOUS as the verification dataset in the ablation studies to compare the effectiveness of each module in MultiPull in Sec. 4.3.

### Surface Reconstruction for Shapes

**Datasets and Metrics**. For the single shape surface reconstruction task, we perform evaluation on multiple datasets including ShapeNet , FAMOUS , Surface Reconstruction Benchmark (SRB)  Thingi10K  and D-FAUST . We conduct validation experiments on 8 subcategories within the ShapeNet dataset, while the remaining datasets are experimented on the complete dataset. For metric comparison, we leverage L1 and L2 Chamfer Distance CD\({}_{L1}\) and CD\({}_{L2}\), Normal Consistency (NC), and F-Score as evaluation metrics.

**ShapeNet.**We evaluate our approach on the ShapeNet according to the experimental settings of GP . We compared our methods with methods including ATLAS , DSDF , NP , PCP , GP , as shown in Tab. 1. We report CD\({}_{L2}\), NC and F-Score metrics for ShapeNet, where we randomly sample 10,000 points on the reconstructed object surface for evaluation. MultiPull outperforms the state-of-the-art methods. Compare to previous gradient-based methods in Fig. 4, our method performs better by revealing more local details of these complex structures. We provide detailed results in Appendix C.

**FAMOUS**. We evaluate the performance of our method on the FAMOUS dataset according to the experimental settings of PCP  and NP . Our method demonstrates superiority over recent

  Methods & CD\({}_{L2} 100\) & NC & F-Score\({}^{0.002}\) & F-Score\({}^{0.004}\) \\  ATLAS & 1.368 & 0.695 & 0.062 & 0.158 \\ DSDF & 0.766 & 0.884 & 0.212 & 0.717 \\ NP & 0.038 & 0.939 & 0.961 & 0.976 \\ PCP & 0.0136 & 0.9590 & 0.9871 & 0.9899 \\ GP & 0.0086 & 0.9723 & 0.9896 & 0.9923 \\  Ours & **0.0075** & **0.9737** & **0.9906** & **0.9932** \\  

Table 1: Reconstruction accuracy on ShapeNet in terms of CD\({}_{L2}\), NC and F-Score with thresholds of 0.002 and 0.004.

Figure 4: Visual comparison of reconstructions on ShapeNet.

approaches, including GP , PCP , GenSDF , FGC , NP , and IGR . As shown in Tab. 2, we compared the recent methods using CD\({}_{L2}\) and NC metrics, and our method exhibits outstanding performance. To demonstrate the effectiveness of our method in reconstruction accuracy, we visualize the error-map for comparison in Fig. 5. Compare to the the state-of-art methods, our method has better overall reconstruction accuracy (bluer).

**SRB**. We validate our method on the real scanned dataset SRB, following the experimental settings of VisCo  and GP . In Tab. 3, we compared our approach with recent methods including P2M , SAP , NP , BACON , CAP , GP . We use CD\({}_{L1}\) and F-Score to evaluate performance, and we surpass all others in terms of these metrics. As depicted in Fig. 6, our method excels in reconstructing more complete and smoother surfaces.

**D-FAUST**. We evaluate our method on the D-FAUST dataset with SAP  settings. As indicated in Tab. 4, we compared our approach with recent methods including IGR , SAP , GP . Our method excels in CD\({}_{L1}\), F-Score and NC. As illustrated in Fig. 7, compared to other methods, our approach demonstrates superior accuracy in recovering human body shapes.

**Thingi10K**. We assess the performance of our approach on the Thingi10K dataset, following the experimental setup of SAP . We compared our approach with recent methods including IGR , SAP , BACON , GP . As indicated in Tab. 5, our method surpasses existing methods across in CD\({}_{L1}\), F-Score and NC metrics. As illustrated in Fig. 8, our method can reconstruct surfaces with more accurate details.

  Methods & CD\({}_{L2} 100\) & NC \\  IGR & 1.65 & 0.911 \\ GenSDF & 0.668 & 0.909 \\ NP & 0.220 & 0.914 \\ FGC & 0.055 & 0.933 \\ PCP & 0.044 & 0.933 \\ GP & 0.040 & 0.945 \\  Ours & **0.035** & **0.953** \\  

Table 2: Reconstruction accuracy on FA-MOUS in terms of CD\({}_{L2}\) and NC.

Figure 5: Visual comparison of error maps on FA-MOUS.

Figure 6: Visual comparison on SRB.

[MISSING_PAGE_FAIL:8]

**KITTI**. We validate our method on the large-scale scanned point cloud dataset KITTI , which contains 13.8 million points. As shown in Fig. 10, our approach is capable of reconstructing more complete and accurate surfaces compared to the GP method . GP struggles to reconstruct continuous surfaces such as walls and streets, whereas our method achieves a more detailed reconstruction of objects at various scales in real scanned scenes. It demonstrates that our method is robust when handling point cloud with various scales.

### Ablation Experiments

**Effect of Frequency Layers**. We denote the \(j\)-th layer of the frequency network as \(L_{j}\), a specific combination of frequency feature layers can be formulated as \(\{L_{i},L_{j},L_{k}\}\), where \(\{i,j,k\}[1,N_{L}-1]\). We evaluate the effectiveness of the frequency transformer layers in Tab. 7 with CD\({}_{L2}\) and NC, replacing the frequency network with linear layers results in a decrease in the performance of the CD\({}_{L2}\) and NC metrics. The performance of using only one layer(\(L_{4}\)) surpasses linear layers. With the increase of the frequency layers, \(\{L_{4}\),\(L_{6}\),\(L_{8}\}\) produces best results.

  Methods & CD\({}_{L2} 100\) & CD\({}_{L1}\) & NC \\  ConvOcc & 13.32 & 0.049 & 0.752 \\ NP & 8.350 & 0.0194 & 0.713 \\ PCP & 0.11 & 0.007 & 0.886 \\ GP & 0.10 & **0.006** & 0.903 \\  Ours & **0.094** & **0.006** & **0.918** \\  

Table 6: Reconstruction accuracy on 3DScene in terms of CD\({}_{L1}\), CD\({}_{L2}\) and NC.

  Layer & CD\({}_{L2} 100\) & NC \\  Linear & 0.042 & 0.920 \\ \(L_{4}\) & 0.040 & 0.926 \\ \(L_{4},L_{6}\) & 0.037 & 0.933 \\ \(L_{4},L_{6},L_{8}\) & **0.036** & **0.948** \\  

Table 7: Effect of frequency features.

Figure 10: Visual comparison on KITTI.

**Effect of MSP Module**. We report comparisons with different features in Tab. 8. The 'Layer' column denotes the combination of frequency features obtained by the FFT module. For instance, \(\{L_{4}\), \(L_{6}\), \(L_{8}\}\) represent the frequency features from the \(4^{th}\), \(6^{th}\), and \(8^{th}\) layers guiding the pulling of the query point in the MSP network, respectively. We find that the accuracy of the network increases with the number of steps. After considering both performance metrics and time efficiency, we have set Step=3 by default.

**Effect of Loss Functions**. We compared CD\({}_{L2} 100\) and NC \(\{L_{4}\), \(L_{6}\), \(L_{8}\}\) represent the frequency features from the \(4^{th}\), \(6^{th}\), and \(8^{th}\) layers guiding the pulling of the query point in the MSP network, respectively. We find that the accuracy of the network increases with the number of steps. After considering both performance metrics and time efficiency, we have set Step=3 by default.

**Effect of Loss Functions**. We compared CD\({}_{L2}\) metric under different loss strategies in Tab. 9. As shown in the table, Weighting query points at different scales effectively enhances reconstruction accuracy and the reconstruction loss allows the network to obtain a complete shape with local details. Furthermore, The gradient loss improves the surface continuity of the object. And the surface supervision loss facilitates the learning of more precise zero-level sets, which also improves the accuracy.

**Effect of Different Levels of Noise**.We evaluate the reconstruction performance of our method on the Famous dataset under two levels of noise: Mid-Level and Max-Level noise. As shown in Tab. 10, our method outperforms the majority of approaches even in the presence of noisy inputs.

## 5 Conclusion

We propose a novel method to learn detailed SDFs by pulling queries onto the surface at multi-step. We leverage the multi-level features to predict signed distances, which recovers high frequency details. Through optimization, our method is able to gradually restore the coarse-to-fine structure of reconstructed objects, thereby revealing more geometry details. Visual and numerical comparisons show that our approach demonstrates competitive performance over the state-of-the-art methods.

## 6 Acknowledgment

This work was supported by National Key R&D Program of China (2022YFC3800600), and the National Natural Science Foundation of China (62272263, 62072268), and in part by Tsinghua-Kuaishou Institute of Future Media Data.

  Noise level & NP & PCP & GP & Ours \\  Mid-Noise & 0.280 & 0.071 & 0.044 & **0.037** \\ Max-Noise & 0.310 & 0.298 & 0.060 & **0.058** \\  

Table 10: Effect of different levels of noise.

  Step & CD\({}_{L2} 100\) & NC \\ 
1 & 0.040 & 0.926 \\
2 & 0.037 & 0.933 \\
3 & 0.036 & 0.948 \\
4 & 0.036 & 0.942 \\
5 & **0.0357** & **0.955** \\  

Table 8: Effect of MSP Module.

  Loss & CD\({}_{L2} 100\) & NC \\  \(_{}\) & 0.0443 & 0.937 \\ \(_{}\) & 0.0383 & 0.946 \\ \(_{}+_{}\) & 0.0367 & 0.948 \\ \(_{}+_{}+_{}\) & **0.0352** & **0.954** \\  

Table 9: Effect of loss functions.