# Weight Diffusion for Future: Learn to Generalize in Non-Stationary Environments

Mixue Xie

Beijing Institute of Technology

mxxie@bit.edu.cn

&Shuang Li\({}^{}\)

Beijing Institute of Technology

shuangli@bit.edu.cn

&Binhui Xie

Beijing Institute of Technology

bihuxiie@bit.edu.cn

&Chi Harold Liu

Beijing Institute of Technology

chiliu@bit.edu.cn

&Jian Liang

Kuaishou Technology

liangjian03@kuaishou.com

&Zixun Sun

Tencent

sunzixun@126.com

&Ke Feng

Tencent

richardfeng@tencent.com

&Chengwei Zhu

Tencent

chavezzhu@tencent.com

###### Abstract

Enabling deep models to generalize in non-stationary environments is vital for real-world machine learning, as data distributions are often found to continually change. Recently, evolving domain generalization (EDG) has emerged to tackle the domain generalization in a time-varying system, where the domain gradually evolves over time in an underlying continuous structure. Nevertheless, it typically assumes multiple source domains simultaneously ready. It still remains an open problem to address EDG in the domain-incremental setting, where source domains are non-static and arrive sequentially to mimic the evolution of training domains. To this end, we propose _Weight Diffusion (W-Diff)_, a novel framework that utilizes the conditional diffusion model in the parameter space to learn the evolving pattern of classifiers during the domain-incremental training process. Specifically, the diffusion model is conditioned on the classifier weights of different historical domain _(regarded as a reference point)_ and the prototypes of current domain, to learn the evolution from the reference point to the classifier weights of current domain _(regarded as the anchor point)_. In addition, a domain-shared feature encoder is learned by enforcing prediction consistency among multiple classifiers, so as to mitigate the overfitting problem and restrict the evolving pattern to be reflected in the classifier as much as possible. During inference, we adopt the ensemble manner based on a great number of target domain-customized classifiers, which are cheaply obtained via the conditional diffusion model, for robust prediction. Comprehensive experiments on both synthetic and real-world datasets show the superior generalization performance of W-Diff on unseen domains in the future.

## 1 Introduction

Domain generalization (DG) deals with a fundamental problem in modern machine learning , where performance degeneration often occurs when deep models encounter out-of-distribution (OOD) data . The goal of DG is to learn a model that can perform well on unseen target domains by leveraging labeled data from multiple related but different source domains .

Despite of abundant works on DG and promising progress so far, they typically embark upon the generalization among stationary and discrete environments , where the distribution shift among domains is obvious and remains static over time. In contrast, there have emerged several works on evolving domain generalization (EDG) [24; 29; 51; 2; 44; 50] in recent years, where the data distribution gradually shifts in an underlying continuous structure, e.g., the age-related structural changes in the optic nerve in ocular diseases . But most of EDG methods still assume multiple source domains simultaneously ready, which may be impractical in real world. As the data distribution constantly evolves along time, training data from new data distributions will continue to emerge. Hence, equipping models with lifelong learning ability is crucial for their practical applications.

Despite of the fact that existing researches on continual learning [16; 32; 5] have studied the empowerment of lifelong learning, their focus is on maintaining the performance of seen tasks, instead of generalizing on unseen domains in the future. Therefore, it is still an open problem to achieve evolving domain generalization in the domain-incremental setting, where source domains sequentially arrive to mimic the dynamics of training domains. To this end, previous work EvoS  models the features from each domain as a Gaussian distribution and proposes to capture the evolving pattern at the feature level by leveraging self-attention mechanism to generate the feature mean and variance for future domain based on those of historical domains. However, the assumption that features adhere to a Gaussian distribution may not always be applicable. Different from EvoS, we propose to excavate evolving pattern at the parameter level and further achieve domain-customized parameter generation.

Inspired by neural network diffusion  that there exist specific parameter patterns in optimized model layers and these patterns can be modeled with diffusion model, we propose to capitalize on the strong modeling ability of diffusion models to capture the evolving pattern of optimized classifiers across domains. To achieve this, we propose a _Weight Diffusion (W-Diff)_ approach, which is specialized for EDG in the domain-incremental setting. Specifically, to address the problem of inaccessible historical data, we maintain a first-in-first-out (FIFO) queue to store the optimized classifier weights of historical domains. The stored classifier weights of each historical domain serve as a _reference point_ to calculate the change between the classifier weights of current domain _(regarded as the anchor point)_ and that of corresponding historical domain. The changes of classifier weights between the anchor point and different reference points provide evolving patterns at different time intervals, which can be utilized to make the modeling of evolving patterns more robust.

In addition, for guidance on how to switch from a reference point to the anchor point, we condition the diffusion model on the class prototypes of current domain along with the reference point. Then, the conditional diffusion model is trained to model the distribution of _residual classifier weights_, i.e., the change of classifier weights between the anchor point and reference point. Meanwhile, to reduce the overfitting of the feature encoder and to restrict the evolutionary pattern to be reflected only in the classifier as much as possible, we learn a domain-shared feature space by enforcing the predictions from different classifiers to be consistent. Finally, during the inference stage, we adopt weights ensemble to give robust predictions based on a great number of generated classifier weights by the diffusion model that is conditioned on current class prototypes and different reference points.

**Contributions: 1)** We study the under-explored area of evolving domain generalization in the domain-incremental setting and explore the innovative usage of diffusion model for this problem. **2)** We propose a novel weight diffusion (W-Diff) approach to capture the evolutionary pattern at the parameter level, orthogonal to previous feature level approaches. Capitalizing on the strong generative ability of diffusion model, W-Diff can generate customized parameters by controlling the condition and make robust predictions via weights ensemble. **3)** Comprehensive experiments on both synthetic and real-world datasets verify the effectiveness and superiority of W-Diff on generalization.

## 2 Related Work

**Evolving Domain Generalization (EDG)** learns the evolving pattern underlying in multiple source domains to achieve generalization capability on the unseen future target domains over time [2; 50; 24; 52; 44; 29]. To name a few, SDE-EDG  introduces stochastic differential equations (SDEs) to model the evolving pattern through individual temporal trajectories. DRAIN  builds on the Bayesian framework and leverages LSTM to infer the future status of the whole network. However, most of these methods, except for DRAIN, require multiple source domains to be simultaneously available. Very recently, EvoS  focuses on EDG with sequentially arriving domains, considering the low efficiency of training the model from scratch once the accumulated domains are updated. It assumes that features for each domain follow a Gaussian distribution and then models the evolving pattern of the feature distribution, while this assumption is not always suitable. Besides, in the generalization process of multiple consecutive target domains, the statistics generated from previous timestamps are used as inputs to the attention mechanism to generate the statistics at next timestamp, which in turn serve as the input for next generation. This manner is likely to cause error accumulation if previous generation is not accurate. Orthogonal to EvoS , we proposes to mine the evolving pattern at the model parameter level and further implement domain-oriented parameter generation via controlling the condition of the diffusion model to avoid the potential error accumulation in EvoS.

**Continual Learning (CL)** focuses on the scenario where the model is trained on a sequence of tasks, and the model is required to adapt to current task and meanwhile maintain the performance on previous tasks [53; 16; 5; 39; 43; 32; 11]. The literature on this field is abundant. Most of the techniques can be categorized into architecture-based [34; 9], representation-based [4; 43; 10], regularization-based [16; 53; 32] and replay-based [5; 39; 11]. In this work, we also continually train models on sequential domains, but the goal is to generalize well on novel domains in the near future.

**Parameter Generation** has been gaining great interests with the rise of diffusion models [42; 8; 21; 54]. For example, p-diff  directly generates high-performing neural network parameters from random noises with a standard latent diffusion model, which verifies the feasibility of modeling the parameter distribution via diffusion models. Nevertheless, p-diff uses unconditional diffusion model and can only generate parameters for in-distribution data. G.pt  collects the loss, error or return of task model checkpoints during training as the condition for the diffusion model. However, it is designed for a single dataset to which the training data belongs, thus struggling with distribution shifts. D2NWG  uses CLIP  to extract features for each sample and leverages Set Transformer  to generate dataset encoding from these features. Then, the diffusion model is conditioned on the dataset encoding. But labeled training set samples of a new dataset are required to obtain the dataset encoding, which is infeasible in unlabeled target domains. In addition, ProtoDiff  and MetaDiff  generate prototype classifiers for the meta-test stage by conditioning the diffusion model on the information (e.g., the prototypes in  and the gradients in ) from the support set. Yet, they concentrate on few-shot learning and the support set requires labeled data, which is unavailable in the target domain of EDG. By contrast, we aims at capturing the evolving pattern among source domains and leveraging it to enable generalization on future target domains without any labeled target data.

## 3 Preliminaries

### Problem Formulation

We consider the evolving domain generalization (EDG) in the domain-incremental setting. Formally, during training phase, we are given \(T\) sequentially arriving source (training) domains: \(=\{^{1},^{2},,^{T}\}\), which are collected at timestamps \(t_{1}<t_{2}<<t_{T}\), respectively. Each domain is defined as \(^{t}=\{_{i}^{t},y_{i}^{t}\}_{i=1}^{N^{t}}\), \(t=1,,T\), where \(_{i}^{t}\) is the \(i\)-th sample from the \(t\)-th domain, \(y_{i}^{t}\{0,1,,C-1\}\) is the category label of sample \(_{i}^{t}\), and \(N^{t},C\) are the number of training samples in the \(t\)-th domain and the number of categories, respectively. In the domain-incremental setting, we can only access current domain \(^{t}\) at timestamp \(t_{t}\) and historical domains \(\{^{1},,^{t-1}\}\) are unavailable. This takes into account the data storage burden, privacy concerns and the dynamic evolution of the source domain. Following previous EDG works [24; 29; 2], the label set is the same among domains, but the data distribution of domains is assumed to continuously evolve over time in some patterns. And our goal is to generalize the model, which is composed of a feature encoder \(E_{}\) parameterized with \(\) and a classifier \(H_{}\) parameterized with \(\), on unseen \(K\) target (testing) domains in the future: \(=\{^{T+1},,^{T+K}\}\). To tackle this problem, we propose to model the evolving pattern at the parameter level via the conditional diffusion model and generate customized parameters for future domains by controlling the condition of the diffusion model.

### Diffusion Model

Diffusion models have achieved tremendous success in computer vision by modeling the probability transformation from a prior Gaussian distribution to the target distribution [14; 40]. They typically comprise a diffusion process to progressively add Gaussian noise to data in a multi-step Markov chain and a denoising process to recover data from the noise via reversing the diffusion process.

**Diffusion process.** Given a clean data point \(_{0}\) sampled from a real data distribution \(q()\), i.e., \(_{0} q()\), the diffusion process is characterized as a Markov chain which slowly adds random Gaussian noise to \(_{0}\) in \(S\) steps, obtaining a sequence of noisy samples: \(_{1},,_{S}\). Formally, this process is expressed as

\[q(_{1:S}|_{0})=_{s=1}^{S}q(_{s}|_{s-1}), q( _{s}|_{s-1})=(_{s};}_{s-1},_{s}),\] (1)

where \(\{_{s}(0,1)\}_{s=1}^{S}\) is a variance schedule, \(\) represents Gaussian distribution, and \(\) is the identity matrix. And the forward diffused sample at step \(s\), denoted as \(_{s}\), can be directly obtained in a single step by Eq. (2) without iteratively adding noise:

\[_{s}=_{s}}_{0}+_{s}},(,),\] (2)

where \(_{s}=_{s^{}=1}^{s}(1-_{s^{}})\). When step size \(S\) approaches infinity, \(_{S}\) is equivalent to a data point from an isotropic Gaussian distribution, i.e., the prior Gaussian distribution \((,)\).

**Denoising process.** Given a start noise \(_{S}(,)\), the denoising process moves backward on the multi-step Markov chain as \(s\) decreases from \(S\) to \(1\) to remove the noise at each step \(s\), finally recovering the clean data. Concretely, the formulation of the denoising process at step \(s\) is denoted as

\[_{s-1}=_{}(_{s},s)+_{s}= }}(_{s}-}{_{s}}}_{}(_{s},s))+_{s},\] (3)

where \(_{}(_{s},s)=}}( _{s}-}{_{s}}}_{}( {x}_{s},s))\) and \(_{}(,)\) is a denoising model parameterized with \(\) to estimate the noise. \(_{s}\) is a variance hyperparameter that is theoretically set to \(_{s}^{2}=_{s}\) in most diffusion works [14; 26]. During the training stage, the denoising model \(_{}\) is trained by minimizing the following loss \(_{diff}\) to minimize the noise estimation error:

\[_{diff}=_{_{0},s,}[\|-_{}(_{s}}_{0}+_{s}},s)\|^{2}].\] (4)

**Conditional diffusion model.** The way of conditional diffusion models to generate samples is analogous to the unconditional one, except for the added conditional information. Specifically, as in most conditional diffusion works [25; 17], the denoising model \(_{}(_{s},s)\) is replaced with \(_{}(_{s},s,)\), where \(\) denotes the condition, e.g., class labels, texts, images, etc. The matched condition \(\) regulates the sample generation in a supervised manner to ensure the desired image content. And inspired by the generating of specific image contents via introducing conditional information to diffusion models, we propose to achieve domain-oriented parameter generation by controlling the diffusion condition.

## 4 Methodology

With the preliminary knowledge of EDG in the domain-incremental setting and diffusion models, we will present the details of Weight Diffusion (W-Diff) in this section. We begin with how to obtain the data for diffusion model training in Section 4.1 and then model the evolving pattern of parameters via the conditional diffusion model in Section 4.2. Finally, the inference procedure of W-Diff to generate customized classifiers is presented in Section 4.3. The overview of W-Diff is illustrated in Fig. 1.

### Per-domain Parameter Fitting in Domain-Incremental Setting

In our approach, we try to capture the evolving pattern in optimized model parameters across domains and further generate customized parameters for target domain via leveraging the learned pattern. Considering the unaffordable training cost if modeling the whole parameters for relatively large models, we choose to excavate the evolutionary pattern in the task-specific head, e,g., the classifier for classification tasks. Nevertheless, the remaining parts of the task model would overfit to current domain and cause degraded generalization if without any processing. To avoid this, we learn a domain-shared feature encoder for all domains and a domain-specific classifier for each domain during the domain-incremental training. As \(t\) increases from \(1\) to \(T\), once the training stage on domain \(^{t}\) ends, the classifier weights with the best validation performance on the validation set of \(^{t}\), denoted as \(}^{t}^{C d_{f}}\), is stored in the reference point queue \(Q_{r}\), where \(d_{f}\) the dimension of deep features output by the feature encoder \(E_{}\). \(Q_{r}\) is a global FIFO queue with the maximum length \(L\) and is used to calculate the change of classifier weights between current domain and a given historical domain in Section 4.2, which reflects the evolving pattern at the parameter level.

**Learning Domain-Shared Feature Encoder.** In the domain-incremental setting, we can only access the data from current domain, which prohibits us from utilizing conventional DG methods that require to access multiple domains simultaneously to learn domain-invariant feature representations. To tackle this problem, we resort to the stored different classifiers in \(Q_{r}\). Intuitively, if domain-shared feature representation is learned, classifiers from different domains should give similar predictions for a given data sample. Hence, at timestamp \(t_{t}\), we train the task model on the \(t\)-th domain \(^{t}\) by minimizing the consistency loss \(^{t}_{con}\) to learn a domain-shared feature space:

\[^{t}_{con} =|}} _{t^{}=t-|Q_{r}|}^{t}_{i=1}^{N^{t}}KL(}^{t}_{i} \|^{t,t^{}}_{i}),\] \[}^{t}_{i} =|}_{t^{}=t-|Q_{r}|}^{t}^{t,t^{}}_{i},^{t,t^{}}_{i}=( (}^{t})^{t}_{i}),&t^{}=t\\ ((}^{t^{}})^{t} _{i}),&t^{}<t,\] (5)

where \(^{t}_{i}=E_{}(^{t}_{i})^{d_{f}}\), \(||\) is the length of the object and \(()\) denotes stopping gradients. \(}^{t^{}}\) is the stored classifier weights of historical domain \(^{t^{}}\) and \(^{t}\) is current classifier weights on \(^{t}\).

**Learning Domain-Specific Classifier.** As \(t\) increases from \(1\) to \(T\), domain-specific classifier is directly learned by incrementally training the task model via the supervision loss \(^{t}_{ce}\) on domain \(^{t}\):

\[^{t}_{ce}=}_{i=1}^{N^{t}}CrossEntropy ((^{t}^{t}_{i}),y^{t}_{i}).\] (6)

Overall, when training on domain \(^{t}\), the task model is optimized by the following total loss \(^{t}_{total}\):

\[^{t}_{total}=^{t}_{ce}+^{t}_{con},\] (7)

where \(\) is a tradeoff hyperparameter to balance the two losses.

Figure 1: Overview of W-Diff. The reference point queue \(Q_{r}\) stores classifier weights of recent \(|Q_{r}|\) historical domains, and the anchor point queue \(Q_{a}\) and prototype queue \(Q_{p}\) store the updated classifier weights and prototype matrix at each iteration after the warm-up stage on current domain. \(^{t}_{con}\) is the prediction consistency loss to learn a domain-shared feature space and \(^{t}_{ce}\) is the cross-entropy loss. The conditional diffusion model \(_{}\) is trained with the noise estimation error loss \(^{t}_{diff}\) to model the evolving pattern of classifiers, conditioned on historical reference point and current prototype matrix.

**Collecting Data for Diffusion Model Training.** Considering that parameters at the early stage are unstable, we start to collect the training data for diffusion model after the warm-up stage of the task model is over on corresponding domain. Specifically, when training on the \(t\)-th domain, the warm-up epochs of the task model account for \((0,1)\) of the total training epochs on domain \(^{t}\), where \(\) is a hyperparameter. After the warm-up stage, the updated classifier weights \(^{t}^{C d_{f}}\) via back-propagating the gradients of \(^{t}_{total}\) and the updated prototype matrix \(^{t}^{C d_{f}}\) via Eq. (8) are respectively stored into the anchor point queue \(Q_{a}\) and prototype queue \(Q_{p}\) at each iteration.

\[^{t}[c] :=^{t}[c]+_{i=1}^{B}_{i}^{t,t}[c ]_{i}^{t}}{n^{t}+B},c=0,1,,C-1,\] \[n^{t} :=n^{t}+B.\] (8)

\(^{t}[c]\) is the \(c\)-th row of \(^{t}\), i.e., the prototype of class \(c\) on domain \(^{t}\) based on all data in the seen batches after the warm-up stage on \(^{t}\). \(B\) is the batch size of task model. \(n^{t}\) counts the total number of samples in seen batches after the warm-up stage and is initialized to \(0\) at the start of training on each domain. \(_{i}^{t,t}[c]\) is the predicted probability of \(_{i}^{t}\) belonging to class \(c\) via current classifier of domain \(^{t}\). Here, using predicted probability instead of ground-truth label to compute prototypes avoids the issue of missing categories in a batch and the inaccessibility of labels in testing domains.

In implementation, \(Q_{a}\) and \(Q_{p}\) are both FIFO queue with the maximum length \(M\), i.e., the training batch size of the diffusion model. When they are full, the training of the conditional diffusion model starts. Note that \(Q_{a}\) and \(Q_{p}\) are only used during the training phase and are locally used on each domain. That is, they are initialized to empty at the beginning of the training stage on each domain.

### Modeling Parameter Evolution Pattern with Conditional Diffusion Model

Having prepared the data for diffusion model training, we can utilize them to learn the evolving pattern of parameters during the domain-incremental training process of the task model. To be specific, we use the difference between the classifier weights of current domain and that of a given historical domain to represent the evolution of parameters:

\[_{m}^{t,t^{}}=_{m}^{t}-}^{t^ {}},\] (9)

where \(_{m}^{t}\), \(m=1,2,,M\), is the classifier weights of current domain \(^{t}\), which is cached in the anchor point queue \(Q_{a}\) when training the task model on \(^{t}\). And \(}^{t^{}}\) is the classifier weights of the historical domain \(^{t^{}}\) from the reference point queue \(Q_{r}\), \(t^{}\{t-|Q_{r}|,,t-1\}\). Hence, the residual classifier weights \(\{_{m}^{t,t^{}}\}_{m=1}^{M}\) represent how to evolve from a reference point to the anchor point. Moreover, to guide the evolution, we provide the paired condition for each residual classifier weight matrix \(_{m}^{t,t^{}}\), where the paired condition is formulated as \(_{m}^{t,t^{}}=}^{t^{}}_{m}^{t}^{C d_{f} 2}\) and \(\) denotes concatenating. The additional condition provides the information about the the starting point and knowledge about the distribution of data in the feature space, which is rightly the anchor point, i.e., the optimized classifier, needs to adapt to. Then, when the task model is incrementally trained on the \(t\)-th domain, the conditional diffusion model is also incrementally trained to minimize the following noise estimation error loss \(^{t}_{diff}\) in Eq. (10), so as to learn how to generate the desired residual classifier weights when given the reference point and prototype matrix as the condition.

\[^{t}_{diff}=_{}^{t^{}} Q_{r}, _{m}^{t} Q_{a},(, ),s}[\|-_{}(_{s}} _{m}^{t,t^{}}+_{s}},s,_{m}^{t,t^{}})\|^{2}].\] (10)

In implementation, the conditional diffusion model adopts the similar U-Net structure as LDM  and uses a hybrid conditioning way, i.e., the condition is injected both in the cross-attention and input sides. In Eq. (10), different reference points could enrich the diversity of training data for the conditional diffusion model and provide the evolving pattern at different time intervals.

### Generating Customized Classifiers in Inference Phase

After finishing the training on domain \(^{T}\), we can use the conditional diffusion model to generate customized classifiers for a given testing domain \(^{test}\). Firstly, we calculate the prototype matrix \(^{test}\) of domain \(^{test}\) via \(^{test}[c]=}_{i=1}^{N^{test}}}_{i}^{ test}[c]_{i}^{test}\), where \(}_{i}^{test}=|}_{}^{t^{}}  Q_{r}}(}^{t^{}}_{i}^{ test})\), \(c=0,1,,C-1\). Here, we use the more robust averageprediction of multiple classifiers to compute the prototype matrix in the inference phase. Then, given each reference point \(}^{t^{}}\) in \(Q_{r}\) along with the prototype matrix \(^{test}\), we can generate \(M_{g}\) residual classifier weights: \(\{_{j}^{test,t^{}}\}_{j=1}^{M_{g}}\) by substituting the denoising net in Eq. (3) with its conditional version and applying the denoising process with condition \(^{test,t^{}}=}^{t^{}}^{test}\). Ultimately, we use the following average weight ensemble \(}^{test}\) as the final classifier for label predicting on \(^{test}\):

\[}^{test}=|}}_{ ^{t^{}} Q_{r}}_{j=1}^{M_{g}}(}^{t^{}}+_{j}^{test,t^{}}).\] (11)

In this way, we capitalize on the powerful modeling and generating ability of conditional diffusion model to cheaply produce a great number of target-customized classifiers, which offers more robust and accurate predictions. The pseudo codes of training and testing procedures are in Appendix C.

## 5 Experiments

### Experimental Setup

**Benchmark Datasets.** We evaluate W-Diff on both synthetic and real-world datasets [2; 48], including two text classification datasets (**Huffpost**, **Arxiv**), three image classification datasets (**Yearbook**, **RMNIST**, **fMoW**) and two multivariate classification datasets **(2-Moons**, **ONP**). Except for synthetic datasets 2-Moons and RMNIST that use the rotation angle as a proxy for time, all other datasets collect real-world data with the distribution shift over time. Following , the number of source and target domains is set as Yearbook: (\(T=16,K=5\)), RMNIST: (\(T=6,K=3\)), fMoW: (\(T=13,K=3\)), Huffpost: (\(T=4,K=3\)), Arxiv: (\(T=9,K=7\)), 2-Moons: (\(T=9,K=1\)), ONP: (\(T=5,K=1\)). For each source domain, we randomly divide the data into training and validation sets in the ratio of \(9:1\). For more details on datasets, please refer to Appendix D.1.

**Network Details.** For the task model, we follow the usage in [48; 45]. For the conditional diffusion model, we implement it in a U-Net similar to LDM . Please refer to Appendix D.2 for details.

**Training Details.** For all datasets, we set the batch size \(B=64\), the loss tradeoff \(=10\) and the maximum length \(L=8\) for the reference point queue \(Q_{r}\). To optimize the task model, we adopt the Adam optimizer with momentum 0.9. As for the warm-up hyperparameter \(\), we \(=0.6\) for Huffpost, fMoW and \(=0.2\) for Arxiv, Yearbook, RMNIST, 2-Moons, ONP. For the conditional diffusion model, we set the maximum diffusion step \(S=1000\) and use the AdamW optimizer with batch size \(M=32\), where \(M\) is also the maximum length of queue \(Q_{a}\) and \(Q_{p}\). And the number of generated residual classifier weights based on each reference point is set to \(M_{g}=32\) in the inference stage. All experiments are conducted using the PyTorch packages and run on a single NVIDIA GeForce RTX 4090 GPU with 24GB memory. Three independent experiments with different random seeds are repeated for each task to report the mean and standard deviation (std) of accuracy, which is denoted in the format of "mean \(\) std" in the table. Please refer to Appendix D.3 for more details.

   &  &  Access \\ training \\  } &  Additional \\ data/ \\  } &  &  \\   & & &  &  &  \\   & & & \(^{T+1}\) & & OOD & OOD & \(^{T+1}\) & OOD & OOD \\  Offline & ✗ & ✓ & 72.74 & 71.50 & 69.53 & 57.49 & 52.38 & 49.28 \\ IRM  & ✗ & ✓ & 71.04 & 70.31 & 68.97 & 51.11 & 45.89 & 42.86 \\ CORAL  & ✗ & ✓ & 71.34 & 70.08 & 68.88 & 50.98 & 45.77 & 42.71 \\ Mixup  & ✗ & ✓ & 73.34 & 71.16 & 69.29 & 57.58 & 52.77 & 49.62 \\ LISA  & ✗ & ✓ & 72.19 & 70.24 & 68.60 & 56.53 & 52.41 & 49.67 \\ GI  & ✗ & & 68.06 & 66.32 & 64.64 & 53.43 & 49.19 & 46.13 \\  InFine

**Evaluation Metrics.** We report the generalization performance on \(K\) target domains in the future, including the average accuracy "OOD avg." (\(_{k=1}^{K}(^{T+k})\)) and the worst accuracy "OOD worst" (\(_{k\{1,,K\}}(^{T+k})\)) on \(K\) target domains and the accuracy on \(^{T+1}\).

### Main Results

We provide the quantitative results in Table 1, 2, 3(a), where the results of baselines in the non-incremental and incremental scenarios are reported from . For ONP dataset, we notice that previous continuous domain adaptation methods (CDOT and CIDA) and EDG methods (GI and DRAIN) all perform worse than the Offline method that trains the task model on the cumulation of all source domains. In contrast, our W-Diff still obtains superior accuracy to previous state-of-the-art method (EvoS) on this challenging dataset, which validates the superiority of W-Diff. Besides, our W-Diff also achieves the best results on Huffpost, Arxiv, RMNIST and fMoW, in terms of the OOD worst accuracy. These results benefit from the modeling of parameter evolution pattern and the more robust predictions via the weight ensemble based on the conditional diffusion model. For Yearbook dataset, DRAIN, which models the evolution of whole model parameters via LSTM, is inferior to EvoS, which models the evolution of domain-level feature distribution. It suggests that modeling the evolving pattern at the feature level may be more appropriate for Yearbook, which also explains why W-Diff does not obtain the state-of-the-art performance on Yearbook. But our W-Diff still obviously outperforms DRAIN. Overall, we can observe that W-Diff surpasses the baselines in the incremental-training setup on six out of seven datasets, which shows the superiority of W-Diff.

### Analytical Experiments

**Ablation Study.** Firstly, the significant performance drop of variant A in Table 3(b) suggests that learning domain-invariant feature representations is necessary for EDG in the domain-incremental setting. Otherwise, the feature encoder could easily overfit to current domain, prohibiting the task model from generalization. Then, we try different ways to construct the average weight ensemble \(}^{test}\), including variant C which directly uses the historical classifier weights in \(Q_{r}\), i.e., \(}^{test}=|}_{}^{t^{ }} Q_{r}}}^{t^{}}\), and variant D which augments classifier weights by adding small

Table 2: Accuracy (%) on Yearbook, RMNIST and fMoW. The best and second best results in the incremental setup are bolded and underlined. (Yearbook: \(K=5\), RMNIST: \(K=3\), fMoW: \(K=3\))

Table 3: (a): Error rate (%) on 2-Moons and ONP (\(K=1\)). (b): Ablation study on RMNIST.

noises to the weights in \(Q_{r}\), i.e., \(}^{test}=|}}_{^{t^{ }} Q_{r}}_{j=1}^{M_{g}}(}^{t^{}}+noise_{j}), noise_{j}(-0.01,0.01)\). The inferior results of variant B, C and D indicate that W-Diff benefits from generating meaningful and customized classifier weights via controlling the condition of diffusion model. Finally, different conditioning ways for the diffusion model are explored, including variant E which injects the condition only in the cross-attention, and variant F which injects the condition only in the input by concatenating the condition with diffused residual classifier weights. Results of variant E and F are both unsatisfactory. This is probably due to the large gap between the residual classifier weights in the input side and the full classifier weights in the condition side, which makes the information interaction hard. And injecting the condition only on the input side can lead to insufficient information interaction. Empirically, we find that the hybrid manner works best.

**Decision Boundary Visualization on Future Domain.** In Fig. 2(a), the model is incrementally trained until the training stage on the \(t\)-th domain \(^{t}\) finishes. Then we visualize the decision boundary on the next future domain \(^{t+1}\), \(t=8,9\). From the results, we can see that the decision boundary of W-Diff adapts to the evolution of domains better than that of EvoS, which shows the superiority of W-Diff in addressing evolving domain generalization in the domain-incremental setup.

**t-SNE Visualization of Features.** In this qualitative experiment, we visualize the features of future target domains for RMNIST dataset to show the effectiveness of \(^{t}_{con}\). From Fig. 2(b), we can observe that features from different target domains align well. To some extent, it verifies the effectiveness of \(^{t}_{con}\) to learn a domain-shared feature space, which contributes to the mitigation of distribution shift.

**Visualization of Generated Classifier Weights.** In Fig. 3(a), we plot the generated classifier weights for domain \(^{T+1},T=6,\) on RMNIST, as well as the accuracy range on \(^{T+1}\) of generated classifier weights based on different reference points. In Fig. 3(a), some generated weights locate close to the average fine-tuned weights \(^{7}\), showing that W-Diff generates domain-customized classifiers.

Figure 3: (a): Visualization of classifier weights for \(^{T+1},T=6\), on RMNIST and their accuracy range. \(}^{t^{}},t^{}=1,,6\), is the reference point from \(Q_{r}\), \(}^{7|t^{}}\) is the generated \(M_{g}\) classifier weights based on \(}^{t^{}}\), and \(^{7}\) is the average weights of \(^{7}\) fine-tuned classifier weights in the last 200 iterations. (b): Accuracy of EvoS and W-Diff on RMNIST and Huffpost datasets, where W-Diff\({}_{stream}\) denotes W-Diff is evaluated with batch-data stream for each target domain.

Figure 2: (a): Decision boundary of EvoS  and W-Diff on 2-Moons, where we incrementally train the model until the \(t\)-th domain and then visualize the decision boundary for future domain \(^{t+1}\). (b): visualization of features from target domains, where different colors represent different domains.

Besides, \(}^{7|1}\), \(}^{7|2}\), \(}^{7|3}\) are similar, while \(}^{7|4}\), \(}^{7|5}\), \(}^{7|6}\) are different, due to the more pronounced differences among reference points \(}^{4}\), \(}^{5}\), and \(}^{6}\). This implies that the evolution pattern may be different at different time intervals. And these diverse and high-performing generated weights based on different reference points could reduce to more robust predictions.

**Evaluating in Batch-Data Stream.** In addition to the inference way in Section 4.3, we also provide another version, where the data in target domain arrives batch by batch. Concretely, we use the iterative manner in Eq. (8) along with the average prediction in Section 4.3 to update the prototype matrix \(^{test}\), once a batch of data from \(^{test}\) arrives. Then, we compute the average weight ensemble \(}^{test}\) via Eq. 11 for this data batch. Fig. 3(b) shows the results on RMNIST and Huffpost. The two manners present similar results and users can choose appropriate manner based on their scenarios.

**Equipping Condition with Timestamp Difference.** In this part, we try to explicitly incorporate the timestamp difference between the anchor point and reference point into the condition of diffusion model. Concretely, we scale the reference point \(}^{t^{}}\) in the condition \(^{t,t^{}}\) by a factor \(\), where \(=1.5-}\) and \( t=t_{t}-t_{t^{}}\) is the timestamp difference between reference and anchor points. More distant reference points have larger \( t\) and are weakened. The results on RMNIST dataset are given in Table 4, where the average and worst accuracies of target domains improve slightly. The insignificant performance improvement may be due to the fact that our approach implicitly takes the timestamp difference into account via the domain-incremental training and residual classifier weights.

**Results with Larger Backbones.** We try larger backbones on the fMoW dataset by replacing the DenseNet-121 with DenseNet-169/201/161 , respectively. The results are provided in Table 5. When applying lagers backbones, our method still works well and further performance improvements are obtained. This benefits from the consideration of only modeling the evolution of classifier weights, instead of the whole network parameters. Otherwise, the training difficulty and huge memory burden from the conditional diffusion model would be unbearable, despite of the greater feature extraction capability of larger backbones.

## 6 Conclusion

This work delves into the under-explored problem of evolving domain generalization in the domain-incremental setting, where the source domain is also non-stationary and dynamically evolves. To tackle this, we propose a Weight Diffusion (W-Diff) approach to capture the evolving pattern across domains at the parameter level and further generate customized classifiers for future domains. W-Diff innovatively leverages the conditional diffusion model to learn the evolution of classifiers from historical domain to current domain, conditioned on the historical classifier weights and current prototype matrix. Extensive results on synthetic and real-world datasets verify the efficacy of W-Diff.