# Semi-Open 3D Object Retrieval via Hierarchical Equilibrium on Hypergraph

Yang Xu\({}^{1}\), Yifan Feng\({}^{1}\), Jun Zhang\({}^{2}\), Jun-Hai Yong\({}^{1}\), and Yue Gao\({}^{1}\)

\({}^{1}\)BNRist, THUIBCS, KLISS, BLBCI, School of Software, Tsinghua University, China

\({}^{2}\)Tencent AI Lab

{xuyang9610,evanfeng97}@gmail.com, junejzhang@tencent.com,

{yongjh,gaoyue}@tsinghua.edu.cn

Corresponding author

###### Abstract

Existing open-set learning methods consider only the single-layer labels of objects and strictly assume no overlap between the training and testing sets, leading to contradictory optimization for superposed categories. In this paper, we introduce a more practical _Semi-Open Environment_ setting for open-set 3D object retrieval with hierarchical labels, in which the training and testing set share a partial label space for coarse categories but are completely disjoint from fine categories. We propose the Hypergraph-Based Hierarchical Equilibrium Representation (HERT) framework for this task. Specifically, we propose the Hierarchical Retrace Embedding (HRE) module to overcome the global disequilibrium of unseen categories by fully leveraging the multi-level category information. Besides, tackling the feature overlap and class confusion problem, we perform the Structured Equilibrium Tuning (SET) module to utilize more equilibrial correlations among objects and generalize to unseen categories, by constructing a superposed hypergraph based on the local coherent and global entangled correlations. Furthermore, we generate four semi-open 3DOR datasets with multi-level labels for benchmarking. Results demonstrate that the proposed method can effectively generate the hierarchical embeddings of 3D objects and generalize them towards semi-open environments.

## 1 Introduction

3D objects are of paramount significance, finding extensive applications from computer graphics  to security  and autonomous robotics . As the fundamental task of data acquisition, 3D object retrieval (3DOR)  plays a pivotal role in the computer vision community . 3DOR methods learn to represent 3D objects from the training set and then extract features from query objects to effectively align similar samples. According to the category overlap between training and testing sets, existing 3DOR algorithms can be divided into closed-set and open-set types. The former conducts retrieval for objects whose categories have been seen in the training set , while the latter handles objects of unseen categories .

Existing open-set 3D learning methods are based on the assumption that the labels of object categories are at a single level . In practical scenarios, objects are typically described by multiple hierarchical labels. This leads to categories in training and testing sets showing varying degrees of overlap at different levels. As illustrated in Figure 1(a), we term this scenario, where the training and testing set share a partial label space of coarse categories but are completely disjoint from fine categories, as _Semi-Open Environment_. Besides, existing methods typically extract basic features using pre-trained models, followed by further open-set learning and optimization. However, forcategories with the same coarse label but different fine labels, the training of the basic model and the open-set learning will result in contradictory optimizations as shown in Figure 1(b).

Specifically for 3D object retrieval techniques, only a few methods [7; 32] have been explored for open-set retrieval. These methods consider only the single-layer labels of objects and strictly assume no overlap between the training and testing data distributions. The existing open-set 3DOR method  treats objects from seen and unseen categories as isomorphic vertices and constructs a graph model based on global correlations. On one hand, this isomorphic model overlooks hierarchical correlations inherent in multi-level categories, particularly the shared coarse labels. Consequently, the embedding distribution from structure-aware learning tends to be unbalanced towards the feature space of seen categories in the training set. On the other hand, this structure focuses on global correlations between seen and unseen categories, neglecting intricate local correlations within unseen categories themselves. This lack of local attention may result in issues like feature overlap and class confusion within these unseen categories.

Focusing on this practical semi-open environment for retrieval, where the training and testing set share a partial label space for coarse categories but are completely disjoint from fine categories, we introduce the semi-open 3D object retrieval task and construct four datasets with multi-level labels to expand the application of 3DOR. We propose the Hypergraph-Based Hierarchical Equilibrium Representation (HERT) framework for semi-open 3DOR. To overcome the global disequilibrium of unseen categories, we propose the Hierarchical Retrace Embedding module (HRE) to achieve balanced representation across multi-level categories. This module generates multi-level retrace embeddings for capturing the hierarchical semantics of objects. To tackle the feature overlap and class confusion problem, we propose the Structured Equilibrium Tuning (SET) module. This module utilizes high-order correlations among objects for unseen category generalization, by constructing a superposed Hypergraph based on local coherent and global entangled correlations. In summary, our main contributions are fourfold:

* We introduce the semi-open 3D object retrieval task to refine the setting of the 3D object retrieval task in real-world scenario applications, and we construct four datasets for benchmarking downstream tasks.
* We propose the Hypergraph-Based Hierarchical Equilibrium Representation (HERT) framework for the semi-open 3DOR task, including the Hierarchical Retrace Embedding (HRE) and the Structured Equilibrium Tuning (SET) modules, which are designed to overcome the distribution disequilibrium and confusion of unseen categories.
* We propose a superposed Hypergraph structure to capture high-order correlations among objects, under the guidance of local coherent correlations and global entangled correlations from hierarchical category information.
* Experimental results on the four datasets demonstrate that our method can outperform state-of-the-art retrieval methods towards the semi-open environment.

Figure 1: Illustration of motivation from open-set to semi-open 3DOR. Objects may be more accurately described by hierarchical labels than single-level labels in real-world scenarios. In this semi-open setting, the training and testing set share a partial label space for coarse categories but are completely disjoint from fine categories.

Related Work

3D Object Retrieval.3D object retrieval (3DOR) aims to find the relevant objects from the target set for the query objects, most 3DOR methods construct feature alignment models for 3D objects through metric learning. MMJN  proposes a discrimination loss to minimize the distance between objects belonging to the same categories, and learn discriminative embeddings for retrieval. MIFN  constructs fusion networks by weighted concatenation for modality-specific features. PVNet  proposes a joint network for the fusion of multi-view and point cloud features. PVRNet  proposes an attention mechanism to generate the unified embedding of different modalities. CMCL  designs a cross-modal center loss to compress features of different modalities to a modal-invariant space. However, most existing methods mainly focus on close-set retrieval. Currently, only a few methods [7; 32; 39; 38; 37] have explored open-set retrieval, but they typically assume no overlap between training and testing data distributions, which is at odds with the semi-open setting.

Open-Set Learning.Open-set learning (OSL) methods can be roughly separated into two categories , _i.e._, discriminative methods and generative models. In discriminative models, traditional methods achieve the classification of unknown and known categories based on the Support Vector Machine (SVM) [27; 28] or the Extreme Value Theory (EVT) [12; 26]. Recently, deep learning methods for OSL have made remarkable rapid progress. OpenMax  is the first algorithm proposed to replace the SoftMax layer and calibrate the output probability with the Weibull distribution. Then,  and  utilize the one-vs-rest units and reconstructed latent representation for unknown detection. Generative OSL models are designed to anticipate the distribution of novel classes through training. PROSER  allocates placeholders for both data and classifier to detect the unknown classes, C2AE  propose a two-step framework to tackle open-set recognition problem with close-set training and open-set training, respectively. Both types of open-set learning methods [9; 19] are based on the assumption that there is no overlap between known and unknown data distribution, thus facilitating the design of classifiers for unseen object detection, but are challenging to generalize to practical scenarios that involve hierarchical superposed categories.

Multi-Label Learning.Multi-label learning aims to create a model that can assign multiple labels for each instance simultaneously. Existing multi-label learning methods are mostly designed for recognition tasks, and based on one-vs-all classifiers [40; 24] and embeddings [44; 18]. As for the retrieval task, DMSSPH  proposes a multi-level preserving hashing network, and AMD-GCN  designs a GCN-based network for multi-label pattern image retrieval. TranGCN  proposes a cross-modal attention mechanism at each layer for multi-label embeddings. Although these methods construct effective models for image embedding, they overlook the hierarchical relationship and dependencies between different categories. In this paper, we aim to model the correlations between hierarchical label information and generalize to unseen categories.

## 3 Problem Setup

### 3D Object Retrieval

The goal of the 3D object retrieval (3DOR) is to develop a method using the training set \(_{trn}=\{(o_{i},y_{i}^{c},y_{i}^{f})\}_{i=1}^{L}\), which is then employed to identify similar objects in the retrieval (testing) set \(_{ret}=\{(o_{i},_{i}^{c},_{i}^{f})\}_{i=1}^{R}\), which is comprised of the query set \(_{q}\) and the target set \(_{t}\). Here, \(L\) and \(R\) represent the number of samples in the training and testing (retrieval) sets, respectively. The expressions \(y_{i}^{f}^{f}=\{c_{j}^{f}\}_{j=1}^{Y^{f}}\) and \(y_{i}^{c}^{c}=\{c_{k}^{c}\}_{k=1}^{Y^{c}}\) denote the fine and coarse category labels of 3D object \(o_{i}\), respectively. Typically, \(y_{i}^{c}\) provides the category label from a more general (coarse) level, such as the basic geometric shapes or other common attributes between \(_{trn}\) and \(_{ret}\), whereas \(y_{i}\) provides a semantic-specific (fine) category label. Generally, the number of coarse categories \(Y^{c}\) is much smaller than the number of fine categories, which is \(Y^{c} Y^{f}\). For 3D objects, The \(o_{i}=\{m_{r}\}_{r=1}^{M}\) denotes the representation by \(M\) modalities, _i.e._, multi-view, point cloud and voxel.

### Semi-Open 3D Object Retrieval

In traditional open-set 3DOR, the category spaces of the training set and the retrieval set are not the same fine indicating \(y_{i}^{f}^{f}=\{c_{j}^{f}\}_{j=1}^{Y^{f}},_{i}^{f} }^{f}=\{_{j}^{f}\}_{j=1}^{^{f}}\), and \(^{f}}^{f}\). \(Y^{f}\) and \(}^{f}\) denote the numbers of fine categories in the training set and the retrieval set, respectively. In the practice of semi-open 3DOR, the training set and the testing set share the same space of coarse category, which \(y_{i}^{c}^{c}=\{c_{k}^{c}\}_{k=1}^{Y^{c}}\), \(_{i}^{c}}^{c}=\{_{k}^{c}\}_{k=1}^{^{c}}\), and \(^{c}=}^{c}\), \(Y^{c}\) and \(^{c}\) denote the numbers of coarse categories in the training set and the testing set, respectively. During the retrieval phase, each query object is provided with a coarse category label. For better representation, the semi-open 3DOR defines the retrieval model \(r:=(o_{i}|y_{i}^{c}) z_{i}\) that maps the 3D object \(o_{i}\) into a semantic embedding \(z_{i}^{d}\) under coarse category condition \(y_{i}^{c}\). The task seeks to minimize the expected risk under the conditional constraints of coarse labels:

\[_{(S_{i},S_{j})(_{q},_{t})} [(_{i}^{f}_{j}^{f})e^{-(r(o_{i}|y_{ i}^{c}),r(o_{j}|y_{j}^{c}))}..+(_{i}^{f}=_{j}^{f})(1-e^{- (r(o_{i}|y_{i}^{c}),r(o_{j}|y_{j}^{c}))})],\] (1)

where \(S_{i}=(o_{i},y_{i}^{c},_{i}^{f})\) and \(S_{j}=(o_{j},y_{j}^{c},_{j}^{f})\) are object instances sampled from the query set \(_{q}\) and target set \(_{t}\), \(_{i}^{f}\) and \(_{j}^{f}\) denote the predicted fine labels, \(y_{i}^{c}\) and \(y_{j}^{c}\) are the conditional constraint, which are coarse labels. \(()\) is the indicator function, which returns \(1\) if the expression holds and \(0\) otherwise. \(\) is the hypothesis space of map \(r(|)\). \((z_{i},z_{j})\) is the distance metric function between different embeddings.

## 4 Methodology

### Overall Framework

The overall framework of the Hypergraph-Based Hierarchical Equilibrium Representation (HERT) framework is illustrated in Figure 2. HERT is composed of the _Hierarchical Retrace Embedding (HRE)_ and the _Structured Equilibrium Tuning (SET)_ modules. Given 3D objects represented by multiple modalities, common-used backbones are used to extract the basic features for each modality. Then, the HRE module is introduced to generate the multi-level retrace embeddings of hierarchical semantic information. Next, in the SET module, the superposed hypergraph is constructed based on the local coherent and global entangled correlations. Finally, the hypergraph convolution and memory bank under the superposed structure are used to smooth and distill for feature generalization between seen and unseen categories.

### Hierarchical Retrace Embedding

To obtain fully multi-level embeddings of objects based on hierarchical categories, the HRE module is designed here. Specifically, the HRE utilizes two hierarchical auto-encoders in series as shown in Figure 2. The multi-modal auto-encoder \(_{m}\) encodes the multi-modal basic features of 3D objects

Figure 2: An overview of the proposed Hypergraph-Based Hierarchical Equilibrium Representation framework (HERT) framework for semi-open 3D object retrieval. Our framework is composed of the Hierarchical Retrace Embedding (HRE) and the Structured Equilibrium Tuning (SET) modules, which are designed for multi-level semantic embedding and hierarchical structure-aware tuning.

to get the unified embeddings. The retrace auto-encoder \(_{r}\) encodes the coarse label aligning with the unified embeddings to get retrace embeddings.

Given \(N\) 3D objects \(\{o_{i}\}_{i=1}^{N}\) and feature extractors \(\{^{k}\}_{k=1}^{M}\), the basic feature of \(M\) modalities \(\{^{k}\}_{k=1}^{M}=^{k}\{o_{i}\}_{i=1}^{N}\) can be generated, where \(^{k}^{N d_{f}}\). As shown in Fig. 2, we first compress the input basic features from \(M\) modalities into the latent modal-invariant space and generate the unified embeddings from multi-modal auto-encoder \(_{m}\). Specifically, for the basic features \(f_{i}^{k}\) of object \(o_{i}\), the unified embedding of it can be denoted as \(c_{i}=(_{m}(\{f_{i}^{k}\}_{k=1}^{M})\ )\), where \(\) denotes the aggregation function among modalities and \(c_{i}^{d_{c}}\).

After getting the unified embedding \(c_{i}\), the retrace auto-encoder \(_{r}\) takes the coarse category label \(y_{i}^{c}\) into retrace encoding \(e_{i}\). As shown in Fig. 2, then \(_{r}\) compresses the unified embedding \(c_{i}\) aligned with \(e_{i}\) into the retrace space \(_{r}\) and does the reverse reconstruction to the mixed space \(_{x}\), which can be defined as follows: \(:=_{x}_{f}\) and \(:=_{f}_{x}\), where \(()\) is the encoder that maps the unified embedding \(c_{i}\) aligned with \(e_{i}\) into the retrace space \(_{r}\), the retrace embedding \(r_{i}\) can be generated by as \(r_{i}=(c_{i}+e_{i}),r_{i}^{d_{r}}\). \(()\) is the decoder that maps the retrace embedding to reconstruction feature \(_{i}=(r_{i}),_{i}^{d_{c}}\).

Through the HRE stage, we got the unified embedding \(c_{i}\), retrace embedding \(r_{i}\), and mixed feature \(_{i}\) for each 3D object.

### Structured Equilibrium Tuning

To endow the unified and retrace embeddings of 3D objects with the ability to generalize to unseen categories, we introduce the SET module as shown in Figure 2. Specifically, the _Superposed Hypergraph_ structure is employed to capture the local coherent and global entangled correlations under the constraint of hierarchical category information. Then, hypergraph convolution is employed to utilize the collaborative high-order correlation under the guidance of this superposed Hypergraph. Finally, we use the hypergraph convolution and memory bank to generalize the structure-aware knowledge to generate unbiased features for unseen categories.

#### 4.3.1 Superposed Hypergraph

Despite the lack of fine labels in objects from unseen categories, the implicit information within these categories can enhance the generalization capabilities of 3D object embeddings, especially when prompted by coarse labels. To establish the high-order correlations between 3D objects from both seen and unseen categories under common general space, we design a superposed hypergraph structure. The hypergraph in this paper can be represented as \(=\{,\}\), where \(\) and \(\) are the vertex set and the hyperedge set, respectively.

We construct the vertices in our superposed hypergraph by the multi-level retrace embeddings. Specifically, we combine the unified embedding \(c_{i}\) and retrace embedding \(r_{i}\) to generate the heterogeneous retrace vertices \(v_{i}^{N d_{c}}\), which can be defined as follows:

\[v_{i}= c_{i}+(1-)r_{i}\] (2)

where \(\) is the hyper-parameter to trade-off between embeddings of different levels.

Distinct from the traditional hypergraph , we construct a superposed hypergraph with two types of conditional hyperedges: coherent hyperedges and entangled hyperedges.

Coherent Hyperedge.The coherent hyperedges capture the local coherent correlations in the coarse category space. We define the coherent hyperedge as \(e^{c}_{c}\) under the condition of coarse labels:

\[_{c}=\{_{v}(y^{c}) y^{c}^{c}\},\] (3)

where \(_{v}(y^{c})\) denotes the vertex subset that shares the same coarse label \(y^{c}\) and \(^{c}\) denotes the coarse label space of 3D objects.

Entangled Hyperedge.The entangled hyperedges model the global collaborative correlations among objects between seen and unseen categories. For each vertex, we define its entangled hyperedge as the set of nearest \(K-1\) neighboring vertices. Specifically,

\[_{t}=\{_{_{k}}(v) v\}\] (4)where \(_{_{k}}(v)\) denotes the k-nearest neighbors in the feature space of vertex \(v\).

In this way, we construct \(Y^{c}\) coherent hyperedges and \(N\) entangled hyperedges, where \(Y^{c}\) is the number of coarse categories and \(N\) is the number of vertex in the superposed hypergraph. Finally, we combine the two sets of hyperedges to obtain a complete superposed hypergraph for structure-aware tuning.

\[=_{c}_{t}\] (5)

where \(_{c}\) and \(_{t}\) are the set of coherent and entangled hyperedges, respectively.

#### 4.3.2 Structure-Aware Tuning

To get better generalization on unseen categories, hypergraph convolution and memory bank are adopted here for feature smoothing and distillation.

For the convenience of computation, the hypergraph can be represented by the incidence matrix \(\{0,1\}^{||||}\), where the \(i\)-th hyperedge is the \(i\)-th column of \(\), and \((v,e)=1\) if the hyperedge \(e\) contains the vertex \(v\). \(^{||||}\) is a diagonal matrix, where \(_{i,i}\) denotes the weight of the \(i\)-th hyperedge.

To learn the conditional embeddings \(}^{N d_{c}}\) from multi-level embedding \(^{N d_{c}}\) under the guidance of hypergraph, the hypergraph convolution (HGNNConv ) can be represented as:

\[}=(_{v}^{-} _{e}^{-1}^{}_{v}^{-} ),\] (6)

where \(_{v}\) and \(_{e}\) are the diagonal degree matrices for vertex and hyperedge, respectively. \(^{d_{u} d_{u}}\) is the trainable parameter for the HGNNConv layer .

To increase the generalization ability of the SET module, we construct a memory bank \(\) that contains \(L\) invariant memory anchors for conditional embedding \(_{i}\) of the 3D object \(o_{i}\), we compute the activation score for each memory anchor in the memory bank by \(t_{ij}=_{m}(_{i},a_{j})\), where \(a_{j}\) denotes the anchor and \(D_{m}(,)\) denotes the distance metric function. We rebuild the aligned multi-level embedding of each object by \(z_{i}=_{j=1}^{L}t_{i,j}^{n}a_{j},z_{i}^{d_{c}}\), where \(t_{ij}^{n}\) denotes the normalized values of activation score.

### Training Objective

Loss Function for the HRE.To get a better representation of multi-level label information, we first use the Homology Loss \(_{homo}\) and Bi-reconstruction Loss \(_{br}\) followed  for \(_{m}\) to leverage the collaborative information across modalities, then we adopt the Retrace Cross-Entropy loss \(_{ce}\) to guide the retrace embedding of coarse category information, which can be defined as follows:

\[_{ce}=-_{k=1}^{Y^{c}}y_{i,k}^{c}(p_{i,k}),\] (7)

where \(p_{i,k}=}}{_{k=1}^{Y^{c}}e^{o_{i,k}}}\) is the predicted probability score of the 3D object \(o_{i}\) in \(k\)-th coarse category for the reconstructed mixed feature \(_{i}\). \(y_{i,k}^{c}\) is the \(k\)-th value of the one-hot encoded ground truth coarse label of \(o_{i}\), and \(Y^{c}\) is the number of the coarse categories.

In the hierarchical retrace embedding stage, the overall loss function is given:

\[_{HRE}=(_{homo}+_{br})+(1-) _{ce}\] (8)

where \(\) is the hyper-parameter to trade-off between the loss of multi-modal and multi-level representations.

Loss Function for the SET.To train the hypergraph convolution and learnable memory anchors, we adopt Memory Reconstruction Loss \(_{mr}\) and the Cross-entropy Loss \(_{ce}\):

\[_{mr}=_{i}-z_{i}_{2},\] (9)

\[_{ce}=-_{k=1}^{Y}y_{i,k}(_{ i,k})+y_{i,k}(p_{i,k}),\] (10)where \(_{i,k}=_{i,k}}}{_{m=1}^{Y}e^{u_{i,m}}}\) and \(p_{i,k}=}}{_{m=1}^{Y}e^{u_{i,m}}}\) is the predicted probability score of the 3D object \(o_{i}\) in \(k\)-th fine category for the multi-level embedding \(_{i}\) and memory reconstruction embedding \(z_{i}\). \(y_{i,k}\) is the \(k\)-th value of the one-hot encoded ground truth fine label of \(o_{i}\), and \(Y\) is the number of the coarse categories.

In the structured equilibrium tuning stage, the overall loss function is given by:

\[_{SET}=_{mr}+(1-)_{ce}\] (11)

where \(\) is the hyper-parameter for trade-off between them.

## 5 Experiments

### Dataseta and Evaluation Metrics

Datasets.We generate four semi-open 3DOR datasets, including SO-ESB, SO-NTU, SO-MN40, and SO-ABO, based on the public datasets ESB , NTU , ModelNet40 , and ABO , respectively. We add coarse category labels for each object based on the basic geometric shapes such as solid of revolution, rectangular-cubic, _etc_. Also, we remove some objects that are difficult to categorize based on their shapes. Then, we split the fine categories into seen categories for training and unseen categories for testing, the training and testing sets share the same coarse label space according to the semi-open environment setting. Each object has three modalities including multi-view, voxel, and point cloud. Specifically, the detailed descriptions of dataset generation and setting are shown in Appendix B.

Evaluation Protocols.As for the evaluation criteria, We employ commonly used retrieval metrics for comparison, including Mean Average Precision (mAP), Recall, Normalized Discounted Cumulative Gain (NDCG), Average Normalized Modified Retrieval Rank (ANMRR), and the Precision-Recall Curve (PR-C). For the mAP, Recall, and NDCG metrics, the higher scores is better. For the ANMRR metric, the lower score is better.

    &  &  \\  & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** \\  SDML & 0.4947 & 0.8027 & 0.1858 & 0.5430 & 0.4384 & 0.7009 & 0.1937 & 0.5764 \\ CMCL & 0.4990 & 0.8154 & 0.1880 & 0.5457 & 0.4440 & 0.7053 & 0.1946 & 0.5721 \\ MMSAE & 0.5036 & 0.8503 & 0.1931 & 0.5523 & 0.4454 & 0.7046 & 0.1935 & 0.5745 \\ TranGCN & 0.5063 & 0.9011 & 0.1968 & 0.5408 & 0.4548 & 0.7121 & 0.1961 & 0.5624 \\ C2AE & 0.4809 & 0.7863 & 0.1824 & 0.5501 & 0.4303 & 0.6987 & 0.1915 & 0.5828 \\ HGM\({}^{2}\)R & 0.5049 & 0.8831 & 0.1939 & 0.5551 & 0.4821 & 0.7364 & 0.2026 & 0.5438 \\ 
**Ours** & **0.5756** & **0.9346** & **0.2045** & **0.4874** & **0.5678** & **0.8116** & **0.2251** & **0.4677** \\   

Table 1: Comparisons of retrieval performance on SO-ESB and SO-NTU dataset.

Figure 3: The Precision-Recall Curves (PR-C) of the proposed method and compared methods on the four datasets, respectively.

### Experimental Settings

Implemental Details.In our experiments, we choose three modes of multi-view (12 views), point cloud (1024 points), and voxel (32 dimensions) as the representation of 3D objects. The basic features for framework input are extracted by MVCNN , PointNet , and 3D ShapeNets , respectively. The HRE and SET modules are trained separately with 40 and 120 epochs. The SGD optimizers are used for both two modules with learning rates of \(0.1\) and \(0.001\), respectively. As for the hyper-parameters in HERT, we set \(=0.5\), \(=0.8\), and \(=0.9\). Detailed implemental settings for our framework are provided in Appendix C.

Compared Methods.Under this semi-open setting, since there is no 3D object retrieval method designed specifically for this multi-level settings, we choose the current state-of-the-art methods of close-set 3D retrieval (SDML , CMCL , MMSAE ), close-set multi-label retrieval(TransGCN ), and open-set 3D learning (C2AE , HGM\({}^{2}\)R ). For each method, we add a multi-label learning mechanism  on their basis for comparison. We provide more implemented details of compared methods in Appendix D.

### Comparison with the State-of-the-Arts

To evaluate the effectiveness of the proposed HERT framework, we conduct experiments on SO-ESB, SO-NTU, SO-MN40, and SO-ABO datasets. The comparison of quantitative results is presented in Table 1 and Table 2, respectively. Results demonstrate that the proposed HERT outperforms the state-of-the-art methods on all four datasets. Especially on the SO-NTU and SO-MN40 datasets, our method achieves mAP of \(0.5678/0.6336\) with about \(17.7\%/9.6\%\) improvements compared with the second-best method, and achieves Recall of \(0.8116/0.3993\) with about \(10.2\%/7.9\%\) improvements compared with the second-best method. Besides, we also provide the qualitative results through precision-recall curves as shown in Figure 3, in which the larger area below the curve indicates better performance.

The better results indicate that the proposed HERT framework has the capability to understand and generalize unseen fine categories under the guidance of coarse labels. The proposed HRE and SET modules can fully leverage the hierarchical category information into multi-level retrace embedding and generalize them to unseen categories. This approach better captures the hierarchical semantic correlations in the wild and provides a practical framework for the representation learning of multi-label tasks in semi-open environments. We provide more visualized results in Appendix E.

    &  &  \\  & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** \\  SDML & 0.5018 & 0.3241 & 0.6082 & 0.5106 & 0.4380 & 0.3425 & 0.4726 & 0.5564 \\ CMCL & 0.5086 & 0.3281 & 0.6128 & 0.5060 & 0.4520 & 0.3657 & 0.4816 & 0.5458 \\ MMSAE & 0.5189 & 0.3335 & 0.6226 & 0.4938 & 0.4783 & 0.3863 & 0.4929 & 0.5264 \\ TranGCN & 0.5188 & 0.3358 & 0.6131 & 0.4957 & 0.5175 & 0.3956 & 0.5127 & 0.4801 \\ C2AE & 0.4865 & 0.3152 & 0.5977 & 0.5231 & 0.4669 & 0.3674 & 0.4794 & 0.5313 \\ HGM\({}^{2}\)R & 0.5779 & 0.3698 & 0.6482 & 0.4407 & 0.6069 & 0.4675 & 0.5463 & 0.4154 \\ 
**Ours** & **0.6336** & **0.3993** & **0.6874** & **0.3972** & **0.6339** & **0.4793** & **0.5622** & **0.3836** \\   

Table 2: Comparisons of retrieval performance on SO-MN40 and SO-ABO dataset.

    &  &  \\  & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** \\  HRE w/o ReEnz & 0.5159 & 0.9086 & 0.1953 & 0.5431 & 0.4913 & 0.7534 & 0.2053 & 0.5355 \\ HRE w/o \(_{cc}\) & 0.5133 & 0.8738 & 0.1934 & 0.5365 & 0.5161 & 0.7902 & 0.2162 & 0.5162 \\ SET w/o \(_{c}\) & 0.5358 & 0.8957 & 0.1975 & 0.5184 & 0.5285 & 0.7898 & 0.2184 & 0.4986 \\ GCN-based SET & 0.5405 & 0.8999 & 0.2003 & 0.5192 & 0.5144 & 0.7703 & 0.2140 & 0.5138 \\ MLP-based SET & 0.5014 & 0.8483 & 0.1930 & 0.5476 & 0.4689 & 0.7304 & 0.2023 & 0.5561 \\ 
**HRE+SET** & **0.5756** & **0.9346** & **0.2045** & **0.4874** & **0.5678** & **0.8116** & **0.2251** & **0.4677** \\   

Table 3: Ablation studies on SO-ESB and SO-NTU dataset.

### Ablation Study

We conduct ablation experiments on each module of HERT to demonstrate their effectiveness. First, we remove the retrace encoding \(e_{i}\) (HRE w/o ReEnz) and cross-entropy loss in the HRE module (HRE w/o \(_{ce}\)), where "w/o" denotes "without". This is equivalent to using a naive hierarchical embedding approach for coarse labels. As shown in Table 3, 4, and Figure 4, the proposed retrace embedding approach in the HRE module achieves an mAP improvement of \(9.4\%/6.2\%\) in SO-MN40 dataset and \(7.8\%/4.7\%\) in SO-ABO dataset. These results effectively demonstrate the effectiveness of the HRE module for hierarchical categories.

As for the SET module, we remove the proposed coherent hyperedges (SET w/o \(_{c}\)) for comparison, also we replace the hypergraph convolution with Graph Convolutional Networks (GCN-based SET) and Multilayer Perceptron (MLP-based SET). Ablation results in Table 3, 4, and Figure 4 show that the proposed SET outperforms all other structure learning methods, and the combination of the HRE and the SET yields the best performance. These results demonstrate the proposed SET can effectively utilize the semi-superposed correlations among objects.

## 6 Conclusion

In this paper, we introduce a more practical _Semi-Open Environment_ setting for open-set 3D object retrieval with hierarchical labels, in which the training and testing set share a partial label space for coarse categories but are completely disjoint from fine categories. We propose the Hypergraph-Based Hierarchical Equilibrium Representation (HERT) framework for semi-open 3D object retrieval. Specifically, to overcome the global disequilibrium of unseen categories, we propose the Hierarchical Retrace Embedding (HRE) module to fully leverage the multi-level category information. Besides, we perform the Structured Equilibrium Tuning (SET) module to tackle the feature overlap and class confusion problem. This module utilizes more equilibrial correlations among objects and generalizes to unseen categories, by constructing a superposed hypergraph based on the local coherent and global entangled correlations. Furthermore, we construct four 3D object datasets with multi-level category labels for semi-open 3DOR tasks, _i.e._, SO-ESB, SO-NTU, SO-MN40, and SO-ABO. Results demonstrate that the proposed method can effectively generate and generalize the hierarchical embeddings of 3D objects in semi-open environments. However, due to dataset limitations, we are currently unable to verify the balanced representation effect on more than three levels of labels, which is one of our future research directions. We believe this paper can provide new insights for future research in more practical scenarios of open-set learning.

    &  &  \\  & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** & **mAP\(\)** & **Recall\(\)** & **NDCG\(\)** & **ANMRR\(\)** \\  HRE w/o ReEnz & 0.5791 & 0.3710 & 0.6479 & 0.4410 & 0.6055 & 0.4523 & 0.5535 & 0.4062 \\ HRE w/o \(_{ce}\) & 0.5967 & 0.3783 & 0.6756 & 0.4309 & 0.5885 & 0.4269 & 0.5413 & 0.4230 \\ SET w/o \(_{c}\) & 0.5913 & 0.3757 & 0.6669 & 0.4347 & 0.6006 & 0.4263 & 0.5494 & 0.4132 \\ GCN-based SET & 0.5602 & 0.3573 & 0.6410 & 0.4628 & 0.5686 & 0.4253 & 0.5314 & 0.4415 \\ MLP-based SET & 0.5088 & 0.3290 & 0.6149 & 0.5073 & 0.4880 & 0.3787 & 0.5023 & 0.5159 \\ 
**HRE+SET** & **0.6336** & **0.3993** & **0.6874** & **0.3972** & **0.6339** & **0.4793** & **0.5622** & **0.3836** \\   

Table 4: Ablation studies on SO-MN40 and SO-ABO dataset.

Figure 4: The Precision-Recall Curves (PR-C) of the ablation studies on four datasets, respectively.

Acknowledgement

This work was supported by Beijing Natural Science Foundation (No. L242167), CCF-Tencent Open Research Fund, and Jiangxi Provincial Natural Science Foundation (20224ACB218002).