# Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction

Chih-Yu Lai

Department of EECS, MIT

Cambridge, MA 02139

chihyul@mit.edu

&Fan-Keng Sun

Department of EECS, MIT

Cambridge, MA 02139

fankeng@mit.edu

&Zhengqi Gao

Department of EECS, MIT

Cambridge, MA 02139

zhengqi@mit.edu

&Jeffrey H. Lang

Department of EECS, MIT

Cambridge, MA 02139

lang@mit.edu

&Duane S. Boning

Department of EECS, MIT

Cambridge, MA 02139

boning@mtl.mit.edu

Code available at https://github.com/andrewlai61616/NPSR

###### Abstract

Time series anomaly detection is challenging due to the complexity and variety of patterns that can occur. One major difficulty arises from modeling time-dependent relationships to find contextual anomalies while maintaining detection accuracy for point anomalies. In this paper, we propose a framework for unsupervised time series anomaly detection that utilizes point-based and sequence-based reconstruction models. The point-based model attempts to quantify point anomalies, and the sequence-based model attempts to quantify both point and contextual anomalies. Under the formulation that the observed time point is a two-stage deviated value from a nominal time point, we introduce a _nominality score_ calculated from the ratio of a combined value of the reconstruction errors. We derive an _induced anomaly score_ by further integrating the nominality score and anomaly score, then theoretically prove the superiority of the induced anomaly score over the original anomaly score under certain conditions. Extensive studies conducted on several public datasets show that the proposed framework outperforms most state-of-the-art baselines for time series anomaly detection.

## 1 Introduction

Time series anomaly detection involves identifying unusual patterns or events in a sequence of data collected over time . This technique is crucial in fields such as finance , healthcare , manufacturing , transportation , and more . A comprehensive evaluation of different techniques can be found in . Time series anomaly detection using unsupervised learning approaches is favored by recent studies due to the fact that they don't require labeled data and have better detection of unseen anomalies , which is also the approach used in this work. Most unsupervised time series anomaly detection methods involve calculating an anomaly score at each time point and then comparing this score to some threshold. For calculating this score, we can categorize different methods into three main groups: Reconstruction-based methods involve reconstructing the original time series data and comparing the reconstructed data with the actual data [9; 10; 11]. Prediction-based methods involve predicting the next value in the time series and comparing it with the actual value [12; 13; 14]. Dissimilarity-based methods measure the distance between the value obtained from the model and the distribution or cluster of the aggregated data [15; 16; 17; 18; 19; 20]. There can also be hybrid techniques where multiple methods are applied.

While the classification approaches for the types of anomalies differ in the literature [6; 7], we will focus on two classes: point anomalies and contextual anomalies. Point anomalies refer to individual data points that significantly deviate from the expected behavior of the time series and can be detected by observing the data at a single time point. Contextual anomalies, on the other hand, refer to data points that deviate from the expected behavior of the time series in a specific context or condition. These anomalies cannot be detected by observing the data at a single time point and can only be detected by observing the contextual information. As a result, point anomalies can be detected using any general anomaly detection technique that does not require temporal information. Such models are called _point-based models_ in this work. However, detecting contextual anomalies requires a model that can learn temporal information. Such models require a sequence of input, hence they are termed _sequence-based models_ in this work. A time point may contain both point and contextual anomalies. Obviously, contextual anomalies are harder to detect. An important trade-off arises when a model tries to learn time-dependent relationships for detecting contextual anomalies but loses precision or accuracy in finding point anomalies. This trade-off becomes more significant in high-dimensional data, where modeling the temporal relationship is difficult .

Our intuition comes from the observation that state-of-the-art methods using sequence-based reconstruction models encounter the point-contextual detection trade-off, resulting in noisy reconstruction results and suboptimal performance. As an alternative, we start by experimenting with point-based reconstruction methods, which exhibit a lower variance as they do not require the modeling of time-dependent relationships. Despite the absence of temporal information, we find that the corresponding anomaly score for a point-based reconstruction model can already yield a competitive performance. To further bridge the gap between point-based and sequence-based models, we introduce a _nominality score_ that can be calculated from their outputs and derive an _induced anomaly score_ based on the nominality score and the original anomaly score. We find that the induced anomaly score can be superior to the original anomaly score. To provide theoretical proof of our findings, we frame the reconstruction process as a means to fix the anomalies and identify underlying nominal time points and prove that the induced anomaly score can always perform better or just as well as the original anomaly score under certain conditions. We also conduct experiments on several single and multi-entity datasets and demonstrate that our proposed method surpasses the performance of recent state-of-the-art techniques. We coin our method _Nominality score conditioned time series anomaly detection by Point/Sequential Reconstruction_ (NPSR).

## 2 Related Works

Reconstruction-based techniques have seen a diversity of approaches over the years. The simplest reconstruction technique involves training a separate model sequentially for each channel using UAE . One type of improvement focuses on network architecture, with notable examples like LSTM-VAE , MAD-GAN , MSCRED , OmniAnomaly , and TranAD . Additionally, hybrid architectures like DAGMM  and MTAD-GAT  have been proposed. Another type aims to improve the anomaly score instead of using the original reconstruction error. Designing this anomaly score involves a considerable amount of art, given the high diversity of methods for calculating it across studies. For instance, USAD uses two weighted reconstruction errors , OmniAnomaly employs the "reconstruction probability" as an alternative anomaly score , MTAD-GAT combines forecasting error and reconstruction probability , and TranAD uses an integrated reconstruction error and discriminator loss as the anomaly score . In the context of network architecture, our method utilizes a straightforward performer-based structure without incorporating any specialized components. Based on our insights into the point-sequential detection tradeoff, our approach stands out by integration of point-based and sequence-based reconstruction errors for competitive performance.

## 3 Methods

### Problem Formulation

Let \(=\{_{1},...,_{T}\}\) denote a multivariate time series with \(_{t}^{D}\), where \(T\) is the time length and \(D\) is the dimensionality or number of channels. There exists a corresponding set of labels \(=\{y_{1},...,y_{T}\},y_{t}\{0,1\}\) indicating whether the time point is normal (\(y_{t}=0\)) or anomalous (\(y_{t}=1\)). For a given **X**, the goal is to yield anomaly scores for all time points \(=\{a_{1},...,a_{T}\},a_{t}\) and a corresponding threshold \(_{a}\) such that the predicted labels \(}=\{_{1},...,_{T}\}\), where \(_{t}_{a_{t}_{a}}\), match \(\) as much as possible. To quantify how matched \(}\) and \(\) is, or how good \(\) is for potentially yielding a good \(}\), there are several performance metrics that takes either \(\) or \(}\) into account [11; 12; 29; 30; 31]. This work mainly focuses on the best F1 score (F1\({}^{*}\)) without point-adjust, also known as the point-wise F1 score, which is defined as the maximum possible F1 score considering all thresholds. (A complete derivation for F1\({}^{*}\) is covered in Appendix A.)

### Nominal Time Series and Two-stage Deviation

We denote the observed data as \(^{0}=\{_{1}^{0},...,_{T}^{0}\}\), where \(_{t}^{0}^{D}\). Assume that for each \(^{0}\), there exists a corresponding underlying _nominal_ time series data \(^{*}=\{_{1}^{*},...,_{T}^{*}\}\) that comes from a nominal time-dependent process \(_{t}^{*}=^{*}(t):^{D}\). The corresponding total deviation at \(t\) (\(_{t}^{0}\)) is defined as \(_{t}^{0}_{t}^{0}-_{t}^{*}\). We denote \(^{*}\) as the set of all possible \(_{t}^{*}\) for all \(t\{1,...,T\}\). \(_{t}^{0}\) can be separated two additive factors \(_{t}^{c}\) and \(_{t}^{p}\), such that, by definition, \(_{t}^{c}=_{t}^{*}+_{t}^{p}\) and \(_{t}^{0}=_{t}^{c}+_{t}^{p}\). We define \(_{t}^{c}\) as the _in-distribution deviation_, where \(_{t}^{c}^{*}\); and \(_{t}^{p}\) as the _out-of-distribution deviation_, which is non-zero if and only if \(_{t}^{0}^{*}\). \(_{t}^{0}\) can be a means for quantifying the point anomaly, and \(_{t}^{c}\) can be a means for quantifying the contextual anomaly. This is reasonable, since no matter how large \(_{t}^{c}\) is, we still have \(_{t}^{c}^{*}\), i.e., the in-distribution deviated value \(_{t}^{c}\) is still in the set of all possible nominal time point data, and cannot be detected using a point-based model. On the other hand, it is possible that having learned \(^{*}\), a point-based model can negate the deviated value caused by \(_{t}^{p}\). Fig. 1(a) gives an illustration of the relationships between the variables at time \(t\). We clarify this using the example below.

Assume we obtain a dataset from the streaming data of a 2D position sensor, where \(_{t}^{*},_{t}^{c},_{t}^{0}^{2}\), and we have learned that the nominal time series is the circular movement of a point around the origin with some angular velocity \(\) and radius \(r\), where \(R_{min} r R_{max}\). Accordingly, we can deduce that \(^{*}=\{[x\ y]^{T}|R_{min}^{2} x^{2}+y^{2} R_{ max}^{2}\}\) and \(_{t}^{*}=[r t\ \ r t]^{T}\). One possible cause (among many others) of contextual anomalies might be due to an unexpected change in angular velocity. For instance, failures in the system might lead to a slowdown of the circular movement between \(t_{1}\) and \(t_{2}\), i.e., \(_{t}^{c}=[r(^{}t- t)\ r( ^{}t- t)]^{T}\) for \(t\{t_{1},...,t_{2}\}\) and \(_{t}^{c}=\) elsewhere. Moreover, noisy measurements of individual time points may induce point anomalies in the observed time series, i.e., \(_{t}^{p}=[w_{x,t}\ \ w_{y,t}]^{T}\) where \(w_{x,t}\) or \(w_{y,t}\) is nonzero such that \(_{t}^{0}^{*}\) for some \(t\). Fig. 1(b)(c) gives an illustration of the above example. The black dots are time points where \(_{t}^{0}=_{t}^{*}\) (no anomalies). The blue dots are time points exhibiting a slowdown (contextual anomalies). The red dots are time points with noisy measurements (point anomalies). The purple dots are time points with both slowdown and noisy measurements (point and contextual anomalies). The green dots are time points with noisy measurements but \(_{t}^{0}^{*}\), so are still contextual anomalies since their deviations _cannot_ be detected by observing a single time point.

### The Nominality Score

Now we conceptualize the _Nominality Score_\(N()\). Analogous to the anomaly score, \(N()\) indicates how normal a time point is. A nominality score \(N()\) is _appropriate_ if for every possible \(_{N}>0\), \((N(t)>_{N}|y_{t}=0)>(N(t)>_{N}|y_{t}=1)\) for all \(t\{1,...,T\}\), i.e., the portion of normal points that has a nominality score larger than \(_{N}\) is strictly larger than the portion of anomaly points

Figure 1: (a) Relationships between variables, (b) observed time series on 2D plane, and (c) radial and angular displacement vs time from nominal time series (\(_{t}^{*}\)) for the 2D position sensor example.

that has a nominality score larger than \(_{N}\). There are many ways to define \(N()\). In this study, we define \(N(t)\) as the ratio of the squared L2-norm between \(_{t}^{c}\) and \(_{t}^{p}\).

\[N(t)_{t}^{c}\|_{2}^{2}}{\|_{ t}^{0}\|_{2}^{2}}=_{t}^{c}\|_{2}^{2}}{\|_{ t}^{c}+_{t}^{p}\|_{2}^{2}}=_{t}^{c}-_{t}^{ *}\|_{2}^{2}}{\|_{t}^{0}-_{t}^{*}\|_{2}^{2}}\] (1)

We provide an example as to when \(N()\) will be appropriate. In this derivation, we add an \(n\) and \(a\) in the subscript to denote variables that are only associated with normal and anomaly points, respectively. Consider a toy dataset, where \(_{t,n}^{c},_{t,n}^{p},_{t,a}^{c}\), and \(_{t,a}^{p}\) have been defined:

\[_{t,n}^{c}(0,\;I_{D}),\;\;\;\; _{t,n}^{p}(0,\;I_{D}),\;\;\;_{t,a}^{c} (0,\;I_{D}),\;\;\;_{t,a}^{p}(0,\; ^{2}I_{D})\] (2)

According to (1), we have

\[2N_{n}(t)=2_{t,n}^{c}\|_{2}^{2}}{\|_{ t,n}^{c}+_{t,n}^{p}\|_{2}^{2}}(D,D)\] (3)

\[(1+^{2})N_{a}(t)=(1+^{2})_{t,a}^{c}\|_{2} ^{2}}{\|_{t,a}^{c}+_{t,a}^{p}\|_{2}^{2}} (D,D)\] (4)

where F is the F-distribution with \(D\) and \(D\) degrees of freedom. Fig. 2 illustrates the probability density function of \(N_{n}()\) and \(N_{a}()\) for different \(D\) and \(\). If \(>1\), then \(N()\) becomes an appropriate nominality score, since

\[(N(t)>_{N}|y_{t}=0)=_{2_{N}}^{}f(x;D,D)dx> _{(1+^{2})_{N}}^{}f(x;D,D)dx=(N(t)>_{N}|y_{ t}=1)\] (5)

where \(f(;D,D)\) is the probability density function of the F-distribution with degrees of freedom \(D\) and \(D\). Indeed, it is reasonable to assume that \(_{t,a}^{p}\) has a larger variance than \(_{t,n}^{p}\).

### The Induced Anomaly Score

Having \(N()\) defined, we now propose a method for integrating any given \(N()\) and anomaly score \(A()\) to yield an _induced_ anomaly score \(()\), and show some instances where the performance will improve over using \(A()\) or a smoothed \(A()\). Consider a dataset that contains subsequence anomalies. For two near time points \(t\) and \(\), it is natural to assume that the possibility of \(t\) being anomalous is affected by \(\). We quantify this effect as \(A(t;)\), which is the induced anomaly score at \(t\) due to \(\). By summing over a range of \(\) around \(t\), we get the induced anomaly score at \(t\):

\[(t)_{=(1,t-d)}^{(T,t+d)}A(t;)\] (6)

where \(d\) is the induction length. Furthermore, we define \(A(t;)\) as a _gated_ value of \(A()\), which is controlled by the nominality score from \(\) to \(t\):

\[A(t;) A()_{k=(+1,t)}^{(t-1_{t=},-1 )}g_{_{N}}(N(k))=A()g_{_{N}}(N(+1))...g_{ _{N}}(N(t))&t>\\ A()&t=\\ A()g_{_{N}}(N(-1))...g_{_{N}}(N(t))&t<\] (7)

Figure 2: The probability density function for \(N_{n}\) and \(N_{a}\) of the toy dataset at (a) \(D=2\) and (b) \(D=100\).

where the gate function \(g_{_{N}}(N)\) is some transformation function of \(N\) conditioned on a threshold \(_{N}\). A reasonable assumption is that \(g_{_{N}}(N)\) is a non-increasing function of \(N\), i.e., \(N>N^{}\) implies \(g_{_{N}}(N) g_{_{N}}(N^{})\). Indeed, if \(N(k)\) is large, then time point \(k\) is likely a normal point, and any two points \(t_{1},t_{2}\), where \(t_{1}<k<t_{2}\), are unlikely to be in the same anomaly subsequence, hence \(A(t_{1};t_{2})\) and \(A(t_{2};t_{1})\) should be small. Explicitly, we can use \((t)=(t;g_{_{N}})\) and \(A(t;)=A(t;,g_{_{N}})\) to denote that these values are conditioned on \(g_{_{N}}\). Overall, \(()\) can be thought of as some (unnormalized) weighted smoothed value of \(A()\), where the weights are the product of \(g_{_{N}}(N())\) across some range. We consider the following two cases:

Claim 1Using a _soft_ gate function,

\[g_{_{N}}(N)(0,1-})\] (8)

If there exists \(_{1}\) such that \(N(t)_{1}\) for all normal points (\(y_{t}=0\)), then \(^{*}((;g_{_{1}});)^{*}(A ();)\), i.e., the best F1 score using the induced anomaly score with \(g_{_{1}}\) as the gate function is greater or equal to the best F1 score using the original anomaly score.

Proof 1For any normal time point \(t_{n}\), we have

\[(t_{n};g_{_{1}})=_{=(1,t_{n}-d)}^{(T,t_{n}+d)}A(t _{n};,g_{_{1}})=_{=(1,t_{n}-d)}^{(T,t_{n}+d)}A() _{t_{n}=}=A(t_{n})\] (9)

The equality in the middle arises from the fact that \(g_{_{1}}(N(t_{n}))=0\), according to (8) and the assumptions. However, for any anomaly point \(t_{a}\), we have

\[(t_{a};g_{_{1}})=_{=(1,t_{a}-d)}^{(T,t_{a}+d)}A(t _{a};,g_{_{1}}) A(t_{a})\] (10)

This is because \(N(t_{a})\) might be lower than \(_{1}\), and hence \(g_{_{1}}(N(t_{a})) 0\). By potentially having a higher \((t)\) than \(A(t)\) for anomaly points, we get a potentially higher \(^{*}\).

Such a \(_{1}\) indeed exists in real applications (e.g. the minimum nominality score among all normal points \(t_{n}\)). However, targeting this value barely leads to any improvement for \(^{*}\) in practice. This is because anomaly points are generally fewer than normal points, resulting in barely any anomaly points \(t_{a}\) having \(N(t_{a})<_{1}\). Nevertheless, we have shown that the soft gate function along with the induced anomaly score can provably yield equal or better \(^{*}\) under some threshold.

Claim 2Using a _hard_ gate function,

\[g_{_{N}}(N)_{N<_{N}}\] (11)

If \(d=1\), and there exist two thresholds: (i) \(_{2}\) such that \(N(t)<_{2}\) for all anomaly time points (\(y_{t}=1\)) (ii) \(_{}=\); then \(^{*}((;g_{_{2}});)^{*}( (;g_{_{}});)\), i.e., the best F1 score using the induced anomaly score with \(g_{_{2}}\) as the gate function is greater or equal to the best F1 score using the induced anomaly score with \(g_{_{}}\) as the gate function.

Proof 2For any anomaly time point \(t_{a}\), we have

\[(t_{a};g_{_{2}})=_{=(1,t_{a}-1)}^{(T,t_{a}+1)}A( )=A(t_{a}-1)_{t_{a}>1}+A(t_{a})+A(t_{a}+1)_{t_{a}<T}\] (12)

where the first equality arises from the fact that \(g_{_{2}}(N(t_{a}))=1\), according to (11) and the assumptions. For any normal time point \(t_{n}\), we have

\[(t_{n};g_{_{2}})=_{=(1,t_{n}-1)}^{(T,t_{n}+1)}A(t _{n};,g_{_{2}})\ \ A(t_{n}-1)_{t_{n}>1}+A(t_{n})+A(t_{n}+1)_{t_{n}<T}\] (13)

since \(N(t_{n})\) might be greater than \(_{2}\) and hence \(g_{_{2}}(N(t_{n})) 1\). However, we have

\[(t;g_{_{}})=_{=(1,t-1)}^{(T,t+1)}A()=A(t -1)_{t>1}+A(t)+A(t+1)_{t<T}\] (14)regardless of normal or anomaly points since \(N(t)<_{}\) for any \(t\). Therefore, since \((t_{a};g_{_{2}})=(t_{a};g_{_{}})\) and \((t_{n};g_{_{2}})(t_{n};g_{_{}})\), we get a potentially higher \(1^{*}\) when using \(_{2}\) compared to using \(_{}\).

\((;g_{_{}})\) can be viewed as the smoothed value (or shifted simple moving average) over \(A()\) with a period of \(2d+1\). This averaging method is common among other studies [11; 12; 32; 33]. Claim 2 implies that by conditioning on \(N()\) and calculating \((t)\), the performance can be improved over using a simple smoothing value of \(A()\). In practice, we can relax the constraint of \(d\), and use other gated functions to yield a more flexible architecture. Note that the appropriateness of a nominality score is critical for this to work.

### Point-based Reconstruction Models

Consider some model \(_{pt}\) that reconstructs each time point \(t\) point-wise: \(}_{pt,t}_{pt}(_{t}^{0})\). Using \(_{pt}\), a method for yielding the anomaly score is by using the point-based reconstruction mean-squared error, defined as \(_{pt}=\{a_{pt,1},...,a_{pt,T}\}\), where \(a_{pt,t}\|}_{pt,t}-_{t}^{0}\|_{2}^{2}\). One concern for using this kind of anomaly score is that we are not taking into account any time-dependent relationships for deriving \(_{pt}\), so simply using \(_{pt}\) and \(_{pt}\) can barely be classified as a time series anomaly detection approach. Surprisingly, however, we find that a simple realization of \(_{pt}\) can already achieve impressive results for \(1^{*}\) (section 4.4).

Since \(_{pt}\) learns to capture the distribution of all normal point data, we assume that \(}_{pt,t}^{*}\) or is very close. Moreover, since \(}_{pt,t}\) can offset point-anomalies, we assume \(_{t}^{c}}_{pt,t}\), and implement a point-based reconstruction model to calculate \(}_{pt,t}\) in practice.

\[^{c}=\{_{1}^{c},...,_{T}^{c}\}}^{c}=\{}_{1}^{c},...,}_{T}^{c}\}, \ \ }_{t}^{c}=}_{pt,t}=_{pt}(_{t }^{0})\] (15)

\(_{pt}\) can be any model that has the ability to reconstruct \(^{0}\) point-wise. To our surprise, the best performance can be achieved by using a simple Performer-based autoencoder () that actually has the potential to discover temporal information. Despite having such a possibility, it only learned to reconstruct point-by-point during training. We demonstrated this fact by shuffling the input time points and observing that the result will be the same after reordering the output sequence. One possible explanation is that during training, it is a lot easier to individually reconstruct single time points than to find complex time-dependent relationships; and since the Performer-based autoencoder tries to optimize over a batch of time points, this reduces the effect of overfitting and allows the model to better generalize to unseen data. However, the exact reason for this remains an open question. For the rest of the study, we will use \(_{pt}\) to refer to the Performer-based autoencoder model. Details for the architecture of \(_{pt}\) are shown in Appendix B.1.

### Sequence-based Reconstruction Models

Contrary to \(_{t}^{c}\), \(_{t}^{*}\) should not only be in \(^{*}\) but also obey the time-dependent relationships. Therefore, it is necessary that the model (\(_{seq}\)) for approximating \(_{t}^{*}\) takes a sequence of time points as input.

\[^{*}}^{*}=\{}_{1}^{*},...,}_{T}^{*}\}_{seq}(^{0})\] (16)

How close \(_{seq}(^{0})\) approximates \(^{*}\) depends on the amount of training data and the model capacity. In practice, for computational reasons, only a section of \(^{0}\) is input and reconstructed at a time. We found that given a subsequence \(^{0}_{ab}=\{^{0}_{a},...,^{0}_{b}\}\) as input for reconstruction, a model tends to simply reconstruct individual points and do not take temporal information into account (as discussed in section 3.5). Therefore, we use a Performer-based stacked encoder as \(_{seq}\), which predicts the middle \(\) points from its surrounding \(2\) points to force the learning of time-dependent relationships. We concatenate all the predicted time points output by \(_{seq}\) to construct \(}^{*}\). For the rest of the study, we will use \(_{seq}\) to refer to the Performer-based stacked encoder model. Details for the architecture of \(_{seq}\) are shown in Appendix B.2. Fig. 3 gives an illustration of the architecture for \(_{pt}\), \(_{seq}\), and the overall scheme. By obtaining \(}^{c}\) and \(}^{*}\), we can calculate \(N()\) and select some \(A()\) for calculating \(()\). The algorithm for evaluating a trained \(_{pt}\) and \(_{seq}\) using the soft gate function is shown in **Algorithm 1**.

## 4 Experiments

### Datasets

We evaluate NPSR on the following datasets:

* **SWaT** (Secure Water Treatment) : The SWaT dataset is collected over 11 days from a scaled-down water treatment testbed with 51 sensors. During the last 4 days, 41 anomalies were injected using diverse attack methods, while only normal data were generated during the first 7 days.
* **WADI** (WAter DIstribution testbed) : The WADI dataset is acquired from a reduced city water distribution system with 123 sensors and actuators operating for 16 days. The first 14 days contain only normal data, while the remaining two days have 15 anomaly segments.
* **PSM** (Pooled Server Metrics) : The PSM dataset is collected internally from multiple application server nodes at eBay. There are 13 weeks of training data and 8 weeks of testing data.
* **MSL** (Mars Science Laboratory) and **SMAP** (Soil Moisture Active Passive) [38; 13]: The MSL and SMAP datasets are public datasets collected by NASA, containing telemetry anomaly data derived from the Incident Surprise Anomaly (ISA) reports of spacecraft monitoring systems. The datasets have 55 and 25 dimensions respectively. The training set contains unlabeled anomalies.
* **SMD** (Server Machine Dataset) : The SMD is collected from a large internet company, comprising 5 weeks of data from 28 server machines with 38 sensors. The first 5 days contain only normal data, and anomalies are injected intermittently for the last 5 days.
* **trimSyn** (Trimmed Synthetic Dataset) : The original synthetic dataset was generated using trigonometric functions and Gaussian noises. We obtained the dataset from  and trimmed the test dataset such that only one segment of anomaly is present.

The statistics for the datasets are summarized in Table 1. For multi-entity datasets, Train#/Test# corresponds to the number of train/test time points summed over all entities, and the anomaly rate is calculated from the ratio between the sum of all anomaly points and sum of all test points.

Figure 3: (a) Performer-based autoencoder \(_{pt}\), (b) Performer-based stacked encoder \(_{seq}\), and (c) main scheme for NPSR. GELUs are used as the activation function for each layer.

### Baselines

We evaluate the performance of NPSR against several deep learning algorithms and simple heuristics using \(^{*}\). Due to the exhaustive nature of optimizing for all datasets and algorithms, we follow a three-step approach to populate Table 2. Firstly, we reference values from the original paper, and if unavailable, we search for the highest reported values among other publications. Finally, if no reported values are found, we modify and run publicly available code. We cannot find any reported \(^{*}\) of the PSM dataset using THOC or any publicly available code, hence leaving the value blank. For multi-entity datasets (MSL, SMAP, and SMD), we compare the performance using two methods - (1) combining all entities and training them together; (2) training each entity separately and averaging the results. Moreover, some literature attempt to find a threshold (\(_{a}\)) and then calculate the performance conditioned on it [24; 40]. Since \(_{a}\) can simply be a one-value parameter, we assume that other studies have already optimized this value, and regard their reported \(\) as \(^{*}\). More information on the sources of data can be found in Appendix E.

### Main Results

In Table 2, we report the results for \(^{*}\) on several datasets. Detailed preprocessing steps and training settings are reported in Appendix C. NPSR almost consistently outperforms other algorithms, only being slightly inferior to TranAD on the PSM dataset. NPSR makes use of \(_{pt}\) to precisely capture point anomalies with low false-positive rates (given the best threshold). Moreover, it acquires the ability to detect contextual anomalies by incorporating \(_{seq}\) through the calculation of \(()\), without compromising its capability of detecting point anomalies. We observe that recent studies do not necessarily have higher \(^{*}\) scores than older ones. Interestingly, simple heuristics can even perform fairly well on \(^{*}\), with NPSR being the only algorithm consistently outperforming them.

   Dataset & Entities & Dims & Train \# & Test \# & Anomaly Rate (\%) \\  SWaT & 1 & 51 & 495000 & 449919 & 12.14 \\ WADI & 1 & 123 & 1209601 & 172801 & 5.71 \\ PSM & 1 & 25 & 132481 & 87841 & 27.76 \\ MSL & 27 & 55 & 58317 & 73729 & 10.48 \\ SMAP & 55 & 25 & 140825 & 444035 & 12.83 \\ SMD & 28 & 38 & 708405 & 708420 & 4.16 \\ trimSyn & 1 & 35 & 10000 & 7680 & 2.34 \\   

Table 1: Datasets used in this study before preprocess.

   Algorithm  Dataset & SWaT & WADI & PSM & MSL & SMAP & SMD & trimSyn \\  Simple Heuristic [11; 30; 31] & 0.789 & 0.353 & 0.509 & 0.239 & 0.229 & 0.494 & 0.093 \\ DAGMM  & 0.750 & 0.121 & 0.483 & 0.199 & 0.333 & 0.238 & 0.326 \\ LSTM-VAE  & 0.776 & 0.227 & 0.455 & 0.212 & 0.235 & 0.435 & 0.061 \\ MSCRED  & 0.757 & 0.046 & 0.556 & 0.250 & 0.170 & 0.382 & 0.340 \\ OmniAnomaly  & 0.782 & 0.223 & 0.452 & 0.207 & 0.227 & 0.474 & 0.314 \\ MAD-GAN  & 0.770 & 0.370 & 0.471 & 0.267 & 0.175 & 0.220 & 0.331 \\ MTAD-GAT  & 0.784 & 0.437 & 0.571 & 0.275 & 0.296 & 0.400 & 0.372 \\ USAD  & 0.792 & 0.233 & 0.479 & 0.211 & 0.228 & 0.426 & 0.326 \\ THOC  & 0.612 & 0.130 & - & 0.190 & 0.240 & 0.168 & - \\ UAE  & 0.453 & 0.354 & 0.427 & 0.451 & 0.390 & 0.435 & 0.094 \\ GDN  & 0.810 & 0.570 & 0.552 & 0.217 & 0.252 & 0.529 & 0.284 \\ GTA  & 0.761 & 0.531 & 0.542 & 0.218 & 0.231 & 0.351 & 0.256 \\ Anomaly Transformer  & 0.220 & 0.108 & 0.434 & 0.191 & 0.227 & 0.080 & 0.049 \\ TranAD  & 0.669 & 0.415 & **0.649** & 0.251 & 0.247 & 0.310 & 0.282 \\  NPSR (combined) & - & - & - & 0.261 & **0.511** & 0.227 & - \\ NPSR & **0.839** & **0.642** & 0.648 & **0.551** & 0.505 & **0.535** & **0.481** \\   

Table 2: Best F1 score (\(^{*}\)) results on several datasets, with bold text denoting the highest and underlined text denoting the second highest value. The deep learning methods are sorted with older methods at the top and newer ones at the bottom.

We suggest using these simple heuristic values as a strong baseline for future studies to compare against. In light of recent publications highlighting the limitations of using the point-adjusted F1 score ([11; 30; 31; 42]), and yet the large amount of work still using it, we also report the results using point-adjustment in Appendix D.

For multi-entity datasets, we observe that the standard method (training one point-based and sequence-based model per entity) outperforms the combined method for MSL and SMD datasets. This is not surprising, given that entity-to-entity variations might be large. However, for the SMAP dataset, we observe that the combined method performs better. We attribute such results to the fact that the SMAP spacecraft are routine, hence the resulting telemetry between entities can have similar underlying distributions. This contributes to additive learning from the increased training data .

### Ablation Study

The ablation study conducted in this section sheds light on several aspects of the proposed method. In Table 3, we compare the performance of five methods that yield different anomaly scores (either \(A()\) or \(()\)). For the first two methods, the reconstruction errors of \(_{pt}\) and \(_{seq}\) are used, respectively. Since \(_{pt}\) mostly performs better than \(_{seq}\), we use the point-based reconstruction error as \(A()\) to calculate \(()\) for the last three methods. The third method corresponds to an unnormalized simple smoothed value of \(A()\) (cf. section 3.4). The fourth and fifth methods use gate functions (11) and (8), respectively, but the same \(_{N}\) that corresponds to the 98.5 percentile of the nominality score from the training data (\(N_{trn}\)). This method for setting \(_{N}\) works well enough and can be applied across different datasets. Illustrations of the distribution of nominality scores for the SWaT and WADI datasets, along with the 98.5% threshold value are shown in Fig. 4. We can observe that the distributions are _close to appropriate_ (cf. section 3.3). The results for the last three methods are averaged over induction lengths \(d=1,2,4,8,16,32,64,128\), and \(256\). Each entity is trained separately for multi-entity datasets and the results are pooled together.

Firstly, we observe that \(_{pt}\) outperforms \(_{seq}\) and achieves competitive results on its own, despite _not_ modeling the time-dependent relationships. Secondly, by smoothing \(A()\) (third row), the AUC and \(^{*}\) are increased for most datasets. This means smoothing is generally an effective method for improving performance. Moreover, our experiments show that the soft gate function along with an appropriate \(_{N}\) performed the best on average in terms of \(^{*}\). This suggests that the distribution of nominality scores is predominantly overlapped, and a soft gate function will be more appropriate to prevent excessive accumulation of anomaly scores on normal time points, reducing false-positives (cf. Appendix F). This method will also have a generally stable AUC and \(^{*}\) (low \(_{d}\)) across a wide range of \(d\). This makes sense - when time point \(\) is farther away from time point \(t\), more gate function outputs are multiplied onto \(A()\), hence \(A(t,) 0\). However, the results also suggest that the best choice of gate function and \(_{N}\) may depend on the specific dataset at hand.

### Detection Trade-off Between Point and Contextual Anomalies

We elaborate on the trade-off between detecting point and contextual anomalies and relate them with the performance of \(_{pt}\) and \(_{seq}\). It may seem intuitive that finding temporal information in

   Dataset &  &  &  &  &  &  &  \\  Method & AUC & F1\({}^{*}\) & AUC & F1\({}^{*}\) & AUC & F1\({}^{*}\) & AUC & F1\({}^{*}\) & AUC & F1\({}^{*}\) & AUC & F1\({}^{*}\) & AUC & F1\({}^{*}\) \\  \(_{pt}\) (\(\|}_{t}^{*}-}_{t}^{*}\|_{2}^{2}\)) & 0.908 & **0.839** & 0.819 & 0.629 & 0.790 & 0.626 & 0.640 & 0.366 & 0.647 & 0.329 & 0.820 & 0.485 & 0.721 & 0.100 \\ \(_{seq}\) (\(\|}_{t}^{*}-}_{t}^{*}\|_{2}^{2}\)) & 0.899 & 0.755 & 0.843 & 0.559 & 0.766 & 0.576 & 0.621 & 0.351 & 0.611 & 0.292 & 0.820 & 0.482 & 0.832 & 0.345 \\ \(_{pt}\) (\(\|}_{t}^{*}\) + Hard (11) & \(_{d}\) & **0.912** & 0.813 & 0.827 & 0.630 & 0.775 & 0.621 & 0.708 & 0.451 & **0.665** & **0.389** & 0.835 & 0.492 & 0.785 & 0.144 \\ (\(_{N}\) \(\)) & \(_{d}\) & 0.005 & 0.034 & 0.007 & 0.037 & 0.023 & 0.020 & 0.032 & 0.038 & 0.010 & 0.036 & 0.025 & 0.052 & 0.037 & 0.021 \\ \(_{pt}\) + Hard (11) & \(_{d}\) & **0.912** & 0.820 & 0.844 & 0.625 & 0.779 & 0.624 & **0.718** & **0.467** & 0.659 & 0.386 & 0.833 & 0.495 & 0.791 & 0.292 \\ (\(_{N}=98.55\%_{N_{trn}}\)) & \(_{d}\) & 0.005 & 0.024 & 0.007 & 0.023 & 0.017 & 0.015 & 0.041 & 0.051 & 0.012 & 0.034 & 0.024 & 0.050 & 0.069 & 0.121 \\ \(_{pt}\) + Soft (8) & \(_{d}\) & 0.909 & 0.837 & **0.856** & **0.639** & **0.804** & **0.636** & 0.698 & 0.465 & 0.656 & 0.388 & **0.840** & **0.525** & **0.862** & **0.434** \\ (\(_{N}=98.5\%_{N_{trn}}\)) & \(_{d}\) & 0.000 & 0.001 & 0.011 & 0.008 & 0.005 & 0.004 & 0.031 & 0.061 & 0.005 & 0.039 & 0.003 & 0.011 & 0.063 & 0.099 \\   

Table 3: AUC and F1\({}^{*}\) for different methods and datasets, with bold text denoting the highest and underlined text denoting the second highest value. The mean (\(_{d}\)) and standard deviation (\(_{d}\)) of the performance metrics evaluated across \(d=1,2,4,8,16,32,64,128,256\) are shown.

time series would lead to better performance. However, the modeling complexity increases with the number of time points being considered. This leads to the difficulty of focusing on the reconstruction of single time points. Fig. 5(a) shows \(A()\) calculated using either \(_{pt}\) or \(_{seq}\), and \(()\) calculated by NPSR using the WADI dataset. Given the fact that point \(t\) is predicted anomalous if \(A(t)_{a}\), we can see that \(_{seq}\) has a higher false positive rate due to the spikes. In comparison, \(_{pt}\) more accurately detects anomalies in a point-wise fashion. This highlights the superiority of \(_{pt}\) over \(_{seq}\) for this dataset. Furthermore, the induced anomaly score calculated by NPSR has very low false positive rates, and can sometimes even learn to identify anomalies that are not detected by \(_{pt}\) or \(_{seq}\) (Fig. 5(b), the anomaly subsequence at \(t=15200\) and the subsequence to its left, pointed by the black arrows). This suggests that \(()\) is superior to the original \(A()\) for this dataset. However, \(_{pt}\) might not always perform superior to \(_{seq}\). False negatives can be visualized between \(t=14800\) and \(t=14900\), where \(_{pt}\) struggles to recognize the anomaly but \(_{seq}\) effectively detects anomalous time-dependent relationships. This suggests that the anomaly segment contains relatively more contextual than point anomalies. Since the reconstruction error of \(_{pt}\) is used as \(A()\), we lose the advantage of effectively utilizing the reconstruction error of \(_{seq}\). This results in \(()\) not high enough to reach \(_{a}\) within this segment. An important future direction would be to explore how to appropriately select \(A()\) among multiple models (cf. Appendix F).

## 5 Conclusion

In conclusion, we introduce an improved framework for unsupervised time series anomaly detection. We specify the relationships between point and contextual anomalies and derive the nominality score and induced anomaly score to provide a theory-based algorithm with provable superiority. NPSR captures both point and contextual anomalies, resulting in a high combined precision and recall. Our results show that NPSR exhibits high performance, is widely applicable, and has a relatively straightforward training process. It has the potential to decrease labor needs for fault monitoring and correspondingly accelerates decision making and can also contribute to AI sustainability by preventing energy waste or system failure.

Figure 4: Histograms of the nominality scores for the SWaT and WADI dataset.

Figure 5: (a) Anomaly scores using \(_{pt}\), \(_{seq}\) and NPSR (soft gate function, \(_{N}=99.85\%N_{trn}\), and \(d=16\)), and the true labels of the WADI dataset. (b) Magnification for \(t\{14500,...,15600\}\).

Acknowledgement

We thank Piyush Desai, Raphael Schutz, and Nikhil Deshmukh from Turntide Technologies for their helpful discussions and insights.