# Estimating Propensity for Causality-based Recommendation without Exposure Data

Zhongzhou Liu

School of Computing and Information Systems

Singapore Management University

Singapore, 178902

zzliu.2020@phdcs.smu.edu.sg

Yuan Fang

School of Computing and Information Systems

Singapore Management University

Singapore, 178902

yfang@smu.edu.sg

&Min Wu

Institute for Infocomm Research

A*STAR

Singapore, 138632

wumin@i2r.a-star.edu.sg

Corresponding author

###### Abstract

Causality-based recommendation systems focus on the causal effects of user-item interactions resulting from item exposure (i.e., which items are recommended or exposed to the user), as opposed to conventional correlation-based recommendation. They are gaining popularity due to their multi-sided benefits to users, sellers and platforms alike. However, existing causality-based recommendation methods require additional input in the form of exposure data and/or propensity scores (i.e., the probability of exposure) for training. Such data, crucial for modeling causality in recommendation, are often not available in real-world situations due to technical or privacy constraints. In this paper, we bridge the gap by proposing a new framework, called Propensity Estimation for Causality-based Recommendation (PropCare). It can estimate the propensity and exposure from a more practical setup, where only interaction data are available _without_ any ground truth on exposure or propensity in training and inference. We demonstrate that, by relating the pairwise characteristics between propensity and item popularity, PropCare enables competitive causality-based recommendation given only the conventional interaction data. We further present a theoretical analysis on the bias of the causal effect under our model estimation. Finally, we empirically evaluate PropCare through both quantitative and qualitative experiments.

## 1 Introduction

Recommendation systems have been widely deployed in many real-world applications, such as streaming services , online shopping  and job searching . The primary aim of recommendation systems, such as boosting sales and user engagement , depends heavily on user interactions, such as clicking on or purchasing items. Hence, a classical paradigm is to predict user-item interactions, and accordingly, recommend items with the highest probability of being interacted (e.g., clicked or purchased) to users . This paradigm ignores the causal impact behind recommendation : If an item already has a high probability of being interacted by a user without being recommended, _is there really a need to recommend the item to this user?_Recently, a few studies [38; 30; 28; 37] have shifted the focus to this question. They aim to recommend an item based on the uplift, also called the _causal effect_, in the user's behavior (e.g., clicks or purchases) caused by different treatments (i.e., recommending/exposing the item or not) . Such causality-based recommendation systems posit that recommending items with a higher causal effect carries greater merit than those with a higher interaction probability. Typical approaches involve quantifying the causal effect in the user's behavior, based on the observed data and the counterfactual treatment . Existing works assume that the exposure data (i.e., whether an item has been recommended to a user or not), or the propensity scores  (i.e., the probability of recommending/exposing an item to a user), are observable at least during the training stage. However, in real-world scenarios, those data are often unavailable. For instance, while it is feasible to log each user who purchased an item in a e-commerce platform, it may be difficult to distinguish between purchases made with or without exposure due to technical and privacy constraints in determining if a user has been exposed to the item a priori. Without the exposure data and/or propensity scores provided during training, existing causality-based recommenders cannot be deployed.

Toward practical causality-based recommendation, we consider a more relaxed and realistic setup where exposure and propensity scores are not observable. Although some previous works [38; 42; 1; 14; 21] have attempted to estimate propensity scores in a different context (e.g., addressing biases in recommendation), they further suffer two key limitations. First, most state-of-the-art methods still require exposure data to train the propensity estimator [38; 1; 14]. Second, they fail to integrate prior knowledge into the propensity estimator, resulting in less robust estimation. To address these challenges and bridge the data gap in many recommendation scenarios and benchmarks, we propose a novel framework of **Prop**ensity Estimation for **C**ausality-based **R**ecommendation (PropCare), to estimate the propensity score and exposure of each item for each user. Specifically, we observe a pairwise characteristic that relates propensity scores and item popularity when the probability of user-item interaction is well controlled. (The observation is formalized as Assumption 1 and empirically validated in Sect. 4.2.) Based on the observation, we incorporate item popularity as prior knowledge to guide our propensity estimation. Furthermore, we present a theoretical analysis on the bias of the estimated causal effect. The analysis enables us to investigate the factors that influence our estimation and subsequently guide our model and experiment design.

In summary, we compare previous propensity estimation and PropCare in Fig. 1, highlighting our key advantages: PropCare does not need propensity or exposure data at all, and incorporates prior information for robust estimation. The contributions of this paper include the following. (1) Our proposed framework bridges the gap in existing causality-based recommendation systems, where the propensity score and/or exposure data are often unavailable but required for model training or inference. (2) We incorporate the pairwise relationship between propensity and item popularity as prior knowledge for more robust propensity estimation. We present a further analysis on the factors that influence our model. (3) We conduct extensive experiments to validate the effectiveness of PropCare through both quantitative and qualitative results.

## 2 Related Work

Causal effect estimation in recommendationWhile typical recommendation systems consider positive feedback or interactions like clicks and purchases as successful, it may be more beneficial to optimize the uplift in interactions, also called the causal effect, solely caused by recommendations . However, obtaining the causal effect in real-world scenarios is challenging because of its

Figure 1: Causal diagrams under different frameworks. \(_{i}\) is the popularity (prior) of item \(i\). \(Y_{u,i}\) indicates if user \(u\) interacts with item \(i\). \(Z_{u,i}\) indicates if item \(i\) is exposed to user \(u\).

counterfactual nature . Conducting online A/B tests to compare exposure strategies may be feasible but expensive and susceptible to selection bias . To address these issues, several causal effect estimators have been proposed. The naive estimator  assumes random exposure assignment to all user-item pairs, which is inconsistent with most recommendation scenarios. The inverse propensity score (IPS) estimator  incorporates the propensity score, defined as the probability of exposure , to overcome this limitation. Direct model estimators like CausCF  directly predict outcomes using parametric models based on different exposure statuses. A recently proposed doubly robust estimator  integrates a parametric model with the non-parametric IPS estimator for reduced bias and variance. However, these estimators require access to input data containing propensity scores and/or exposure data, at least during the training stage, which are often unavailable due to technical and privacy limitations.

Propensity estimation in recommendationExisting causal effect estimation approaches require exposure data and/or propensity scores at least in training, which are frequently unavailable or subject to the missing-not-at-random (MNAR) issue . Hence, we have to rely on their estimations. Some methods estimate propensity in a heuristic way, such as using item popularity  or other side information (e.g., items participating in promotional campaigns) . However, these estimations lack personalization and may result in noisy results. Other approaches utilize interaction models (also called click models) [24; 3; 42; 21] to relate propensity scores, relevance and interactions. However, without additional constraints, the interaction model alone can be difficult to optimize as we will elaborate in Sect. 4.1. Besides, matrix factorization [16; 38], linear regression , dual learning  and doubly robust learning  can also learn propensity scores, but they assume exposure data as training labels or known variables, which is incompatible with our setup without any observable propensity or exposure data.

## 3 Preliminaries

Data notationsConsider a typical recommendation dataset that contains only interactions between users and items, such as purchases or clicks. Let \(Y_{u,i}\{0,1\}\) denote the observed interaction between user \(u\{1,2,,U\}\) and item \(i\{1,2,,I\}\). \(D=\{(Y_{u,i})\}\) denotes the collection of observed training user-item interaction data. Note that our framework does not assume the availability of any additional data except the interaction data. Moreover, let \(Z_{u,i}\{0,1\}\) denote an _unobservable_ indicator variable for exposure, i.e., \(Z_{u,i}=1\) iff item \(i\) is exposed/recommended to user \(u\). We use \(p_{u,i}\) to represent the propensity score, which is defined as the probability of exposure, i.e., \(p_{u,i}=P(Z_{u,i}=1)\).

Causal effect modellingLet \(Y^{0}_{u,i}\) and \(Y^{1}_{u,i}\{0,1\}\) be the potential outcomes for different exposure statuses. Specifically, \(Y^{1}_{u,i}\) is defined as the interaction between user \(u\) and item \(i\) when \(i\) has been exposed to \(u\). Accordingly, \(Y^{0}_{u,i}\) is the interaction when \(i\) has not been exposed to \(u\). This setup assumes a counterfactual model: In the real world only one of the scenarios can happen, but not both. Subsequently, the causal effect \(_{u,i}\{-1,0,1\}\) is defined as the difference between the two potential outcomes , i.e., \(_{u,i}=Y^{1}_{u,i}-Y^{0}_{u,i}\). In other words, \(_{u,i}=1\) means recommending item \(i\) to user \(u\) will increase the interaction between \(u\) and \(i\) and \(_{u,i}=-1\) means the opposite. \(_{u,i}=0\) means recommending or not will not change the user's interaction behavior. Naturally, users, sellers and platforms could all benefit from recommendations that result in positive causal effects.

Causal effect estimationThe causal effect cannot be directly computed based on observed data due to its counterfactual nature. Among the various estimators introduced in Sect. 2, direct parametric models [38; 37] are sensitive to the prediction error of potential outcomes . Hence, high-quality labeled exposure data are required in parametric models, which is not the setup of this work. To avoid this issue, we adopt a nonparametric approach, known as the inverse propensity score (IPS) estimator , for causal effect estimation as follows.

\[_{u,i}=Y_{u,i}}{p_{u,i}}-)Y_{u,i}}{1-p_ {u,i}}.\] (1)Interaction modelIn line with prior works [21; 42; 39], we adopt an interaction model 1[24; 3] that assumes the following relationship between interactions, propensity and relevance:

\[y_{u,i}=p_{u,i}r_{u,i},\] (2)

where \(y_{u,i}=P(Y_{u,i}=1)\) is the probability of interaction between user \(u\) and item \(i\), and \(r_{u,i}\) represents the probability that item \(i\) is relevant to user \(u\).

## 4 Proposed Approach: PropCare

In this section, we introduce our propensity estimation approach PropCare. We start with a naive approach, followed by our observation on prior knowledge, before presenting the overall loss for propensity learning and how the learned propensity can be used for causality-based recommendation. We end the section by discussing a theoretical property of our estimation.

### Naive propensity estimator

The overall objective is to estimate propensity scores and exposure from a more practical setup where only interaction data are observable. Since the propensity score \(p_{u,i}\) is the probability of exposure \(P(Z_{u,i}=1)\), we focus on the estimation of propensity scores, whereas the corresponding exposure can be readily sampled based on the propensity. The interaction model in Eq. (2) intuitively leads us to the naive loss function below.

\[_{}=-Y_{u,i} f_{p}(_{u,i};_{p})f_ {r}(_{u,i};_{r})-(1-Y_{u,i})(1-f_{p}(_{u,i}; _{p})f_{r}(_{u,i};_{r})),\] (3)

where \(_{u,i}=f_{e}(u,i;_{e})\) is a joint user-item embedding output by a learnable embedding function \(f_{e}\); \(f_{p}\) and \(f_{r}\) are learnable propensity and relevance functions to produce the estimated propensity score \(_{u,i}\) and relevance probability \(_{u,i}\), respectively. Note that each learnable function \(f_{*}\) is parameterized by \(_{*}\), and we implement each as a multi-layer perceptron (MLP).

However, through the naive loss we cannot learn meaningful propensity and relevance functions (\(f_{p}\) and \(f_{r}\)), since they are always coupled in a product and can be collapsed into one function. It is equivalent to learning a single interaction function, instead of learning each individual factor.

### Incorporating prior knowledge

To avoid the above issue, one solution is to introduce prior knowledge to further constrain the propensity or relevance function. In particular, it has been observed that _more popular items will have a higher chance to be exposed_. The popularity of item \(i\), \(_{i}\), is defined based on the total number of observed interactions in the dataset, i.e., \(_{i}=_{u=1}^{U}Y_{u,i}/_{j=1}^{I}_{u=1}^{U}Y_{u,j}.\) However, this observation , while intuitive, is not adequate in explaining the relationship between popularity and exposure. In particular, items with a higher interaction probability also tend to have a higher chance to be exposed, especially when prior exposure was decided by recommenders in the classical paradigm. To incorporate popularity as a prior toward propensity/exposure estimation, we propose to introduce a control on the interaction probability, and formulate the following assumption.

**Assumption 1** (Pairwise Relationship on Popularity and Propensity): _Consider a user \(u\) and a pair of items \((i,j)\). Suppose the popularity of item \(i\) is greater than that of \(j\), and their interaction probabilities with user \(u\) are similar. Then it follows that item \(i\) is more likely to be exposed to user \(u\) than item \(j\) is. _

The intuition is that, when a user's interaction probabilities are similar toward two items \(i\) and \(j\), but item \(i\) is more likely to be exposed to the user, the reason could be item \(i\) is more popular than \(j\). Our assumption essentially places a control on the interaction probability to eliminate its influence on the exposure, and simultaneously isolate the effect of popularity on the exposure.

Empirical validation of Assumption 1In the following, we examine our assumption by calculating the fraction of item pairs that satisfy this assumption in three datasets, namely, DH_original,DH_personalized and ML (see Sect. 5.1 for dataset descriptions). Specifically, we first estimate the probability \(y_{u,i}\) of each interaction \(Y_{u,i}\) using logistic matrix factorization . We also obtain the propensity score \(p_{u,i}\) from ground truth values provided by the datasets (note that we only use the ground truth for evaluation purposes, not in model training or inference). Then, for each user \(u\), we place an item pair \((i,j)\), where a randomly sampled \(i\) is paired with each of the remaining items, into several bins based on \(i\) and \(j\)'s similarity in their interaction probability with \(u\). More specifically, each bin \(b\) contains \((i,j)\) pairs such that \(|y_{u,j}-y_{u,i}|\) falls into \(b\)'s boundaries. Finally, we compute the ratio of \((i,j)\) pairs consistent with Assumption 1 to the total pairs in each bin \(b\), as follows.

\[_{b}=_{u=1}^{U}-p_{u,i})(_{j}-_{i})>0$}}{}.\] (4)

We report the ratios in Fig. 2. It can be observed that when \(|y_{u,j}-y_{u,i}|\) is smaller (i.e., \(i\) and \(j\)'s interaction probabilities with \(u\) are more similar), a higher fraction of items pairs in the bin satisfy our assumption. In contrast, when \(|y_{u,j}-y_{u,i}|\) grows larger (i.e., the interaction probabilities are not well controlled and become less similar), the validity of the original observation  becomes weaker. In summary, the results on the three datasets demonstrate the validity of Assumption 1.

Integrating prior knowledgeBased on Assumption 1, we utilize item popularity to inject prior knowledge on the probability of exposure (i.e., propensity score) through the following loss.

\[-[(f_{p}(_{u,i})-f_{p}(_{u,j}))]\ \ _{i}>_{j}},\ y_{u,i} y_{u,j},\] (5)

where \(\) is the sigmoid activation and \(y_{u,i}\) is computed as \(f_{p}(_{u,i})f_{r}(_{u,i})\). While Eq. (3) models propensity in a point-wise manner, Eq. (5) incorporates popularity as prior knowledge in a pairwise manner. The advantage is twofold. First, it decouples the propensity and relevance functions, using only item popularity which can be readily computed from the interaction data shown earlier without the need for external information. Second, by separating the estimated propensity of less popular items and more popular items, it prevents all predicted values from clustering in a narrow range near 1 or 0. This is beneficial in mitigating the issue of high variance caused by extreme values .

To materialize the control \(y_{u,i} y_{u,j}\) on the interaction probabilities in Eq. (5), we adopt the following loss that involves a soft version of \(y_{u,i} y_{u,j}\).

\[_{}=-_{u,i,j}[(_{i,j} (f_{p}(_{u,i})-f_{p}(_{u,j})))+(_{ i,j}(f_{r}(_{u,j})-f_{r}(_{u,i})))],\] (6)

where \(_{i,j}\{1,-1\}\) is the sign of \((_{i}-_{j})\) and \(_{u,i,j}\) is a weighting function such that it will assign a higher weight if \(y_{u,i}\) and \(y_{u,j}\) are closer. Specifically, we choose \(_{u,i,j}=e^{(y_{u,i}-y_{u,j})^{2}}\), where \(<0\) is a learnable parameter. Moreover, according to the interaction model in Eq. (2), for a fixed \(y_{u,i}\), a higher \(p_{u,i}\) implies a lower \(r_{u,i}\). This explains the additional constraint on the relevance function \(f_{r}\) in Eq. (6), which will further improve model training.

### Propensity learning

Based on the discussions in Sect. 4.1-4.2, the naive loss essentially optimizes the interaction model, whereas the pairwise loss utilizes popularity as prior information for propensity learning. For more robust learning, we further take a global view on the distribution of propensity scores, which usually follow a long-tailed distribution [40; 42]. In particular, we employ a beta distribution to regularize the

Figure 2: Histogram of item pairs \((i,j)\) that satisfy Assumption 1. The bins are based on the inverse similarity in interaction probabilities, \(|y_{u,j}-y_{u,i}|\), divided by \(\{0,0.01,,0.09,0.1,0.2,,0.5\}\). That is, the first 10 bins have an equal width of \(0.01\) and the last 4 bins have an equal width of \(0.1\).

p propensity scores, as has been done in literature in modeling propensity or other long-tailed quantities [4; 15]. Overall, we minimize the following loss toward propensity learning:

\[_{}=_{u,i,j}(_{}+ _{})+(Q\|(,)).\] (7)

Here \(Q\) is the empirical distribution of all estimated propensity scores \(_{u,i}\). \((,)\) is a reference beta distribution with parameters \(\) and \(\) which are selected to simulate a long-tailed shape. \((\|)\) computes the Kullback-Leibler divergence between two distributions. \(\) and \(\) are trade-off hyperparameters to balance different terms.

Finally, we use the estimated propensity score \(_{u,i}\) to predict the exposure variable \(Z_{u,i}\): \(_{u,i}=1\) if \((_{u,i})\), and \(0\) otherwise, where \(\) is a threshold hyperparameter and \(\) is a normalization function such as \(Z\)-score normalization. The overall training steps are sketched in Algorithm 1 in Appendix A.

### Causality-based recommendation

We resort to DLCE , a state-of-the-art causality-based recommender equipped with an IPS estimator. It takes interaction \(Y_{u,i}\), exposure \(Z_{u,i}\) and propensity \(p_{u,i}\) as input, and outputs a ranking score \(_{u,i}\) for each user-item pair. Given a triplet \((u,i,j)\) such that \(u\) is a user and \(i j\) are randomly sampled from the item set, the loss of DLCE is defined as follows .

\[Y_{u,i}}{(p_{u,i},^{1})}(1+e^{-(_{u, i}-_{u,j})})+)Y_{u,i}}{(1-p_{u,i},^{0})} (1+e^{(_{u,i}-_{u,j})}),\] (8)

where \(^{1},^{0}\) and \(\) are hyperparameters. We follow the standard training procedure of DLCE, except that we substitute the ground-truth exposure and propensity score with our estimated values \(_{u,i}\) and \(_{u,i}\), respectively, in the above loss. Hence, the entire training process for our propensity learning and DLCE do not require any ground-truth exposure or propensity data. After DLCE is trained, for each user \(u\), we generate a ranked list of all items based on the optimized \(_{u,i}\).

### Theoretical property

The performance of causality-based recommendation depends on how accurate we can model the causal effect in the user-item interactions. Although it has been established elsewhere  that the IPS estimator defined in Eq. (1) is unbiased as long as exposure \(Z_{u,i}\) and propensity score \(p_{u,i}\) are correctly assigned, in our setup only estimated propensity scores and exposure are available. Thus, we characterize the bias of the IPS estimator when estimations are used instead.

**Proposition 1**: _Suppose we replace the ground truth values of \(Z_{u,i}\) and \(p_{u,i}\) with the estimated \(_{u,i}\) and \(_{u,i}\) in Eq. (1), respectively. Then, the bias of the estimated causal effect \(_{u,i}\) is_

\[(+[_{u,i}-Z_{u,i}]}{_{u, i}}-1)Y_{u,i}^{1}-(-[_{u,i}-Z_ {u,i}]}{1-_{u,i}}-1)Y_{u,i}^{0}.\] (9)

\(\)

We defer the proof to Appendix B. From the bias stated in Proposition 1, we make two further remarks to guide the learning and evaluation of propensity scores and exposure.

**Remark 1**: _The bias is influenced by three major factors: \(p_{u,i}/_{u,i}\), \((1-p_{u,i})/(1-_{u,i})\) and \([_{u,i}-Z_{u,i}]\). Note that if \(_{u,i}=p_{u,i}\) and \(_{u,i}=Z_{u,i}\), the bias would be zero which is consistent with earlier findings . \(\)_

**Remark 2**: _If the estimated \(_{u,i}\) is extremely close to 0 or 1, the bias can be potentially very large. \(\)_

The above proposition and remarks shed some light on what we should focus on when estimating or evaluate exposure and propensity score. On the one hand, since exposure is a binary variable and the bias is influenced by \([_{u,i}-Z_{u,i}]\), we may evaluate it with binary classification metrics such as F1 score. On the other hand, since propensity is a continuous variable and estimations extremely close to zero or one should be avoided, regularizing the global distribution in Eq. (7) and ensuring a proper scale of the propensity scores would be useful.

## 5 Experiment

In this section, we comprehensively evaluate the effectiveness of the proposed PropCare through both quantitative and qualitative experiments.

### Experiment setup

DatasetsWe employ three standard causality-based recommendation benchmarks. Among them, **DH_original** and **DH_personalized** are two versions of the DunnHumby dataset , which includes purchase and promotion logs at a physical retailer over a 93-week period. The difference in the two versions mainly lies in the derivation of ground-truth propensity scores as stated by Sato et al. , which are based on items featured in the weekly mailer in DH_original, and with a simulated personalization factor in DH_personalized. The third dataset is MovieLens 100K (**ML**) , which includes users' ratings on movies and simulated propensity scores based on the ratings and user behaviors. Note that PropCare do not require any propensity or exposure data at all. The ground-truth values are only used to evaluate model output. On each dataset, we generate the training/validation/test sets following their original work [30; 29], respectively. We summarize each dataset in Tab. 1, listing the number of users (#users) and items (#items), as well as the average value of several key variables including the observed interaction (\(_{u,i}\)), exposure (\(_{u,i}\)), causal effect (\(_{u,i}\)) and propensity (\(_{u,i}\)). Further details can be found in Appendix C.1.

BaselinesWe compare PropCare with the following propensity estimators: (1) **Ground-truth**: Propensity score and exposure values are directly taken from the datasets. (2) **Random**: Propensity scores are assigned randomly between 0 and \(1\). (3) Item popularity **(POP)**: Propensity scores are assigned as item popularity normalized to \((0,1)\). (4) **CJBPR**: An unbiased recommendation model that optimizes propensity and relevance alternately in a point-wise manner. (5) **EM**: An recommendation model that learns propensity scores in a point-wise manner using an expectation-maximization algorithm.

Note that Ground-truth uses the ground-truth values of propensity \(p_{u,i}\) and exposure \(Z_{u,i}\) directly as input to train DLCE . All other baselines do not need such ground-truth values in any stage just as PropCare. In these methods, the estimated propensity \(_{u,i}\) is used to further derive the exposure \(_{u,i}\), in the same way as PropCare (see Sect. 4.3). Finally, we utilize the estimated values to train DLCE (see Sect. 4.4).

Parameter settingsWe tune the hyperparameters based on the validation data, following guidance in the literature. Specifically, in PropCare, the trade-off parameter \(\) and \(\) are set to 10 and 0.4, respectively, on all datasets. For the downstream causal recommender DLCE, we follow the earlier settings . For other settings and implementation details, refer to Appendix C.2.

Evaluation metricsWe evaluate the performance of causality-based recommendation with CP@10, CP@100 and CDCG, whose definitions can be found in Appendix C.3. Additionally, we measure the accuracy of estimated propensity scores w.r.t. the ground-truth values using Kullback-Leibler divergence (KLD) and Kendall's Tau (Tau) , and that of estimated exposure using F1 score. Note that all metrics, except KLD, indicate better performance with a larger value.

### Results and discussions

We first compare the performance of PropCare and the baselines, followed by analyses of model ablation, the regularization term, and various influencing factors. Additional experiments including

   Dataset & \#users & \#items & \(_{u,i}\) & \(_{u,i}\) & \(_{u,i}\) & \(_{u,i}\) \\  DH\_original & 2,309 & 1,372 &.0438 &.6064 &.0175 &.2894 \\ DH\_personalized & 2,309 & 1,372 &.0503 &.6265 &.0178 &.4589 \\ ML & 943 & 1,682 &.0676 &.0593 &.0733 &.0594 \\   

Table 1: Statistics of datasets.

comparison to conventional recommendation methods, evaluation on an alternative backbone, and a scalability study are presented in Appendix D.

Performance comparisonWe evaluate PropCare against the baselines in two aspects: (1) The downstream causality-based recommendation using the estimated propensity and exposure; (2) The accuracy of the estimated propensity and exposure.

We first illustrate the performance of causality-based recommendation in Tab. 2. It is not surprising that Ground-truth achieves the best causal effect by incorporating actual propensity and exposure values in DLCE. However, since ground-truth values are often unavailable, we rely on estimations. Among all baselines, PropCare most closely approaches Ground-truth's performance. Notably, in the DH_personalized dataset, PropCare exhibits only a 6.6% average decrease from Ground-truth across three metrics, significantly outperforming the second-best EM which suffers a 56.6% drop. Furthermore, PropCare surpasses the point-wise CJBPR and EM, implying the advantage of our pairwise formulation based on Assumption 1.

Next, we analyze the accuracy of propensity and exposure estimation in Tab. 3. Among the baselines, POP performs the best in Kendall's Tau. However, the causality metrics of POP is poor (see Tab. 2) due to the ill-fit propensity distribution, reflected in its large KLD from the ground-truth distribution. The estimation of exposure is also challenging for POP in most cases. In contrast, PropCare demonstrates outstanding performance in F1 score and KLD, leading to effective causal metrics. Although its Tau scores lag behind some baselines, a robust distribution on propensity and accurate binary predictions of exposure still contribute to good causal performance. The results in Tab. 3 highlight that causality-based recommendation is influenced by multiple factors, rather than relying solely on a single aspect of estimation. We will discuss these influencing factors further toward the end of this part.

Ablation studyTo evaluate the impact of our key design motivated by Assumption 1, we derive five variants from Eq. (6): (1) **NO_P**: removing the constraint on estimated \(_{u,i}\) by deleting the term with \(f_{p}(_{u,i})-f_{p}(_{u,j})\); (2) **NO_R**: removing the constraint on estimated \(_{u,i}\) by deleting the term with \(f_{r}(_{u,j})-f_{r}(_{u,i})\); (3) **NO_P_R**: removing \(_{}\) entirely from the overall loss to eliminate Assumption 1 altogether; (4) **NEG**: reversing Assumption 1 by replacing \(}_{i,j}\) with \(-}_{i,j}\) to assume that more popular items have smaller propensity scores; (5) \(=\): setting all \(_{u,i,j}\)'s to a constant 1, resulting in equal weighting of all training triplets. Their causal performances are illustrated in Fig. 3. Comparing to the full version of PropCare, NO_R and NO_P show a small drop in performance due to the absence of additional constraints on propensity or relevance, indicating that the pairwise loss is still partially effective. The drop in \(=1\) highlights the need for controlling the similarity between interaction probabilities. The further drop observed in NO_P_R

    &  &  &  \\   & CP@10\(\) & CP@100\(\) & CDCG\(\) & CP@10\(\) & CP@100\(\) & CDCG\(\) & CP@10\(\) & CP@100\(\) & CDCG\(\) \\  Ground-truth &.0658\(\).001 &.0215\(\).001 &.1068\(\).000 &.1304\(\).001 &.0445\(\).001 &.1469\(\).003 &.2471\(\).001 &.1887\(\).000 & 16.29\(\).006 \\  Random &.0154\(\).001 &.0071\(\).002 &.7390\(\).004 &.0479\(\).004 &.0107\(\).005 &.8316\(\).039 &.0124\(\).002 &.0135\(\).005 & 13.16\(\).076 \\ POP &.0200\(\).000 &.0113\(\).000 &.7877\(\).001 &.0457\(\).000 &.0096\(\).001 &.8491\(\).002 &.142\(\).001 &.-092\(\).001 & 11.43\(\).005 \\ CJBPR &.0263\(\).001 &.0087\(\).001 &.7769\(\).002 &.0564\(\).008 &.0106\(\).005 &.8528\(\).032 &.410\(\).002 &.187\(\).001 &.9953\(\).006 \\ EM &.0118\(\).001 &.0067\(\).001 &.7247\(\).001 &.0507\(\).002 &.012\(\).011 &.8779\(\).003 &.437\(\).002 &.194\(\).002 & 10.21\(\).011 \\ PropCare & **.0351\(\).002** & **.0156\(\).001** & **.9268\(\).005** & **.1272\(\).001** & **.0381\(\).00** & **.1426\(\).001** & **.0182\(\).002** & **.0387\(\).002** & **13.80\(\).011** \\   

* Results are reported as the average of 5 runs (mean\(\)std). Except Ground-truth, best results are bolded and runners-up are underlined.

Table 2: Performance comparison on downstream causality-based recommendation.

    &  &  &  \\   & KLD\(\) & Tau\(\) & F1 score\(\) & KLD\(\) & Tau\(\) & F1 score\(\) & KLD\(\) & Tau\(\) & F1 score\(\) \\  Random &.5141\(\).001 &.0002\(\).000 &.4524\(\).013 &.3008\(\).002 &.0001\(\).000 &.4463\(\).021 &.0363\(\).002 &.0002\(\).000 &.4511\(\).022 \\ POP &.5430\(\).000 & **.4726\(\)**.000 &.2851\(\).000 &.4728\(\).000 & **.6646\(\)**.000 &.2772\(\).000 &.0615\(\).000 & **.4979\(\)**.000 &.5050\(\).000 \\ CJBPR &.3987\(\).008 &.3279\(\).011 &.2853\(\).005 &.2650\(\).022 &.6477\(\).013 &.2825\(\).005 &.0230\(\).006 &.4956\(\).045 & **.5189\(\)**.020 \\ EM &.6380\(\).002 &.0834\(\).000 &.4974\(\).001 &.2385\(\).001 &.0934\(\).002 &.4954\(\).009 &.0517\(\).001 &.1321\(\).002 &.3653\(\).005 \\ PropCare & **.3851\(\)**.023 &.3331\(\).065 & **.5846\(\)**.006 & **.1732\(\)**.038 &.4706\(\).072 & **.6059\(\)**.017 & **.0204\(\)**.005 &.3889\(\).034 &.4847\(\).020 \\   

* Results are styled in the same way as in Tab. 2.

Table 3: Performance comparison on propensity score (KLD, Tau) and exposure (F1 score) estimation.

[MISSING_PAGE_EMPTY:9]

### Case study

We conduct a case study to demonstrate the advantages of PropCare in a practical ranking-based recommendation scenario. In Tab. 4, we analyze the top-5 recommended items for an anonymous user with ID 2308 in the DH_personalized dataset. In the first column, by utilizing ground-truth propensity scores and exposure, DLCE effectively generates a ranking list where most items have a positive causal effect. All items with a positive causal effect were eventually purchased, achieving the goal of causality-based recommendation. Comparing the lists generated by CJBPR and PropCare, it is evident that the associated causal effects of the purchased items differ. For example, in the CJBPR list, recommending "strawberries" has zero causal effect, indicating that the user could have still purchased it even without recommendation. In contrast, PropCare recommends "infant soy", which has a positive causal effect, making it a more ideal choice. Overall, given the list recommended by CJBPR, the user would only purchase "strawberries" and "fluid milk". However, given the list from PropCare, in addition to "infant soy" and "fluid milk", the user may still purchase "strawberries" even without being recommended due to its zero causal effect. Besides, POP tends to recommend popular items but with a lower causal effect, even including an item with a negative causal effect. The results suggest that POP is not an appropriate tool for estimating propensity scores in the context of causality-based recommendation.

## 6 Conclusion

In this paper, we introduced PropCare, a propensity estimation model for causality-based recommendation systems without the need to access ground-truth propensity and exposure data. Leveraging our observation on the pairwise characteristics between propensity scores and item popularity, we formulated a key assumption and incorporated it as prior information to enhance our estimation, thereby improving causality-based recommendation. A theoretical analysis was presented to understand the factors influencing the bias in estimated causal effects, thereby informing model design and evaluation. Empirical studies demonstrated the superiority of PropCare over the baselines. Future research avenues include exploring direct exposure estimation without propensity scores, and investigating parametric causal effect estimators that are potentially more powerful.

   Ground-truth & POP & CJBPR & PropCare \\  garlic bread (1176) & bananas (1310) & \(\)**fluid milk** (1169) & \(\)**infant soy** (1232) \\ \(\)**cleansing wipes** (737) & toilet tissue (742) & bananas (1310) & \(\)**fluid milk** (1169) \\ \(\)**fluid milk** (1169) & \(\)**fluid milk** (1169) & cereal (1090) & bananas (1310) \\ \(\)**primal** (807) & white bread (675) & **strawberries** (834) & pure juice (1277) \\ alkaline batteries (754) & \(@paragraph\)**t** & tortilla chips (634) & margarine tubs/bows (1245) & coffee creamers (1169) \\    Each column represents the recommendation list output by DLCE trained with the estimated propensity and exposure by the corresponding baseline. The purchased items are highlighted in bold. Items with positive causal effect (\(_{u,i}=1\)) and negative causal effect (\(_{u,i}=-1\)) are marked by \(\) and in \(@paragraph\), respectively, and unmarked items have zero causal effect (\(_{u,i}=0\)). Numbers in brackets are the popularity ranks in the training set.

Table 4: Case study of an anonymous user.

Figure 6: Correlation analysis on factors influencing recommendation.