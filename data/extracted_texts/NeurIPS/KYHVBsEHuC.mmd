# DiffuPac: Contextual Mimicry in Adversarial Packets Generation via Diffusion Model

Abdullah Bin Jasni

Graduate School of Engineering

Nagaoka University of Technology

Nagaoka, Japan

s203108@stn.nagaokaut.ac.jp

&Akiko Manada

Graduate School of Engineering

Nagaoka University of Technology

Nagaoka, Japan

amanada@vos.nagaokaut.ac.jp

&Kohei Watabe

Graduate School of Science and Engineering

Saitama University

Saitama, Japan

kwatabe@mail.saitama-u.ac.jp

###### Abstract

In domains of cybersecurity, recent advancements in Machine Learning (ML) and Deep Learning (DL) have significantly enhanced Network Intrusion Detection Systems (NIDS), improving the effectiveness of cybersecurity operations. However, attackers have also leveraged ML/DL to develop sophisticated models that generate adversarial packets capable of evading NIDS detection. Consequently, defenders must study and analyze these models to prepare for the evasion attacks that exploit NIDS detection mechanisms. Unfortunately, conventional generation models often rely on unrealistic assumptions about attackers' knowledge of NIDS components, making them impractical for real-world scenarios. To address this issue, we present DiffuPac, a first-of-its-kind generation model designed to generate adversarial packets that evade detection without relying on specific NIDS components. DiffuPac integrates a pre-trained Bidirectional Encoder Representations from Transformers (BERT) with diffusion model, which, through its capability for conditional denoising and classifier-free guidance, effectively addresses the real-world constraint of limited attacker knowledge. By concatenating malicious packets with contextually relevant normal packets and applying targeted noising only to the malicious packets, DiffuPac seamlessly blends adversarial packets into genuine network traffic. Through evaluations on real-world datasets, we demonstrate that DiffuPac achieves strong evasion capabilities against sophisticated NIDS, outperforming conventional methods by an average of 6.69 percentage points, while preserving the functionality and practicality of the generated adversarial packets.

## 1 Introduction

Network Intrusion Detection Systems (NIDS) play a pivotal role in safeguarding the vast array of digital devices and infrastructures that permeate our lives. As of 2023, the global count of active IoT devices is expected to reach approximately 15.14 billion, with projections suggesting a rise to 30 billion by 2030 (Statista ). This explosive growth, fueled by applications spanning from consumer electronics to industrial automation and healthcare, presents formidable security challenges. To meet these challenges, advancements in Machine Learning (ML) and Deep Learning (DL) have significantly bolstered the efficacy of NIDS in monitoring IoT traffic and detecting malicious activities (Talaei Khoei and Kaabouch ; Talaei Khoei et al. ).

However, the rapid evolution of generative AI technologies has ushered in a new era of cybersecurity threats, notably through the creation of adversarial packets designed to evade detection by even the most sophisticated NIDS. These AI-driven attacks can emulate and synthesize legitimate network behaviors, presenting an unprecedented challenge to existing security paradigms. Generative models, particularly those trained on extensive datasets of genuine network traffic, can generate adversarial packets that blend malicious functionalities within seemingly normal packet sequences, thus effectively camouflaging their malicious intents.

In response to these evolving threats, it is critical for cybersecurity defenders to deepen their understanding of these generative AI models. By scrutinizing the mechanisms through which these models generate adversarial packets, defenders can better anticipate and counteract adversarial tactics that compromise the detection capabilities of NIDS (Ibitoye et al. (2019); Khazane et al. (2024)). The urgency to develop innovative solutions that can adapt to and preempt these adversarial tactics is paramount, ensuring the reliability and robustness of NIDS in an increasingly complex threat landscape.

Traditional methods for generating adversarial packets have primarily relied on direct engagement with NIDS or the use of surrogate classifiers, often assuming unrealistic levels of attacker access to NIDS configurations. Table 1 summarizes recent literature on adversarial packet generation, highlighting the limitations of these approaches. Studies using techniques such as Network Emulator (NetEM) and Metasploit (Homoliak et al. (2018)), Generative Adversarial Network (GAN) and Particle Swarm Optimization (PSO) (Han et al. (2021)), and Reinforcement Learning (RL) (Hore et al. (2023)) demonstrate that while these methods successfully modified the packets behavior, their efficacy in evading detection in real-world conditions remains suboptimal. The reliance on detailed knowledge of NIDS models is flawed, as attackers typically operate with limited information about the underlying security infrastructure. This gap underscores the necessity for more practical and effective adversarial generation methods that align with the realistic constraints faced by attackers.

To address these challenges, we introduce _DiffuPac: Contextual Mimicry in Adversarial Packet Generation via Diffusion Model_, a novel solution that leverages the combined strengths of Bidirectional Encoder Representations from Transformers (BERT) and diffusion model. This innovative fusion not only promises high accuracy in generating adversarial packets but also operates under the realistic assumption that attackers lack direct access to NIDS models. DiffuPac leverages the extensive contextual understanding provided by BERT, which has been trained on diverse datasets representing a wide range of network behaviors, along with the generative capabilities of diffusion models. This fusion results in a sophisticated adversarial tactics where the elements of the attack are seamlessly integrated into the network traffic, making them indistinguishable from legitimate data. This capability represents a significant leap forward, offering a stealthy approach that outmaneuvers current NIDS through advanced mimicry rather than direct confrontation.

In summary, the principal contributions of this paper are as follows: (a) we have pioneered the integration of BERT and diffusion models to create DiffuPac, marking a first in the cybersecurity domain. This novel methodology sets a precedent in the field by blending the advanced contextual comprehension of network traffic with sophisticated generative capabilities to produce adversarial packets that are both stealthy and indistinguishable from genuine traffic; (b) we introduce a unique concatenation strategy coupled with targeted noising techniques. These innovations ensure that the adversarial packets not only blend seamlessly into the network environment but also dynamically adapt to evade modern detection systems; (c) DiffuPac advances a classifier-free approach to adversarial packet generation. This approach challenges traditional dependency on surrogate classifiers, offering

    &  &  &  \\  & & & **Techniques** & **Algorithm** \\  Homoliak et al. (2018) & 2018 & ASNM- & Surrogate & NetEM, \\  & NBPO & Classifier & Metasploit \\ Hashemi et al. (2019) & 2019 & CICIDS- & Surrogate & Trial and \\  & 2019 & CICIDS- & Classifier & error \\ Kappa et al. (2019) & 2019 & CICIDS- & Surrogate & Manifold \\  & 2018 & Classifier & Approx. \\ Han et al. (2021) & 2021 & CICIDS- & feature & GAN and \\  & 2017 & extractor & PSO \\ Sharon et al. (2021) & 2021 & CICIDS- & NIDS classifier & LSTM \\  & 2017 &  & \\  &  &  & \\  &  &  & \\ Hore et al. (2023) & 2023 &  & \\   

Table 1: Summary of recent literature on adversarial packets generation.

a new paradigm that more accurately reflects the constraints and capabilities of real-world attackers; (d) Lastly, our extensive experimental evaluations, conducted on real-world datasets, demonstrate that DiffuPac significantly outperforms existing methods in terms of evasion effectiveness, establishing new benchmarks for the generation of adversarial packets. These contributions collectively push the boundaries of what is possible in the realm of network security, paving the way for more resilient cybersecurity defenses and a deeper understanding of adversarial tactics in network environments.

## 2 Related Works

**Adversarial Attacks on ML/DL-based NIDS**. NIDS are crucial for protecting digital infrastructures by monitoring network traffic and identifying potential threats through signature-based and anomaly-based detection paradigms. Signature-based NIDS use pattern matching against predefined threat databases, while anomaly-based NIDS employ machine learning models to detect deviations from benign traffic patterns, providing an advantage in detecting sophisticated threats. The transition to DL in anomaly-based NIDS, as highlighted by Ahmad et al. (2021), has enhanced threat detection due to the capability to learn abstract patterns, though this shift has introduced a vulnerability to adversarial attacks. These attacks modify network data subtly to evade NIDS, a phenomenon first noted in computer vision (Szegedy et al. (2014)) and now challenging DL-based NIDS. Adversarial attack tactics vary based on attacker knowledge, ranging from white-box attacks with full system knowledge to black-box attacks with no classifier knowledge, as outlined by McCarthy et al. (2022). Black-box scenarios are common in real-world threats since attackers generally lack direct NIDS access, necessitating sophisticated modifications of data to exploit DL model vulnerabilities and blur the distinction between normal and malicious traffic.

**Adversarial Attacks Evading NIDS**. In the study of NIDS, researchers explore feature-level and packet-level attacks to enhance robustness. Feature-level attacks modify input network features using methods like GANs to mislead classifiers without direct knowledge of their mechanisms. For instance, Yang et al. (2018) used transfer-based and score-based attacks to deceive a Deep Neural Network (DNN) model on the NSL-KDD dataset, while Sheatsley et al. (2022) developed an Augmented JSMA (AJSMA) to ensure realistic feature modifications. However, these still fail to generate executable malicious packets since they do not provide a method for converting modified features into packet sequences. Conversely, packet-level attacks, which modify network packets directly to maintain their malicious intent while evading detection, are particularly effective. As detailed in Table 1, studies such as Hashemi et al. (2019) show successful modifications using non-payload based and mimicking operations. In the survey He et al. (2023), authors emphasized that the practicality and replayability of packet-level attacks make them more dominant, ensuring adversarial packets evade detection while remaining executable. Given this efficacy, our research model, DiffuPac, is designed to excel in this domain, outperforming previous models in robustness and detection evasion, and setting a new standard for NIDS efficacy in adversarial cybersecurity.

**Diffusion Models**. Represent a breakthrough in generative modeling, offering a novel framework for understanding data as a dynamic and stochastic process. Based on the works of Sohl-Dickstein et al. (2015) and Ho et al. (2020), these models conceptualize data points \(_{0}^{d}\) (where \(d\) is a positive integer) as the end result of a reverse Markov chain. In the forward diffusion process, data points \(_{0}\) are gradually transformed into a noise distribution. This transformation is modeled by a Markov chain starting from the data distribution \(q(_{0})\) and ending in a Gaussian distribution \(_{T}(,)\), where \(T\) represents the total number of timesteps in the forward diffusion process. The transitions are defined \(q(_{t}|_{t-1})=(_{t};}_{t-1},_{t})\) for \(1 t T\), where \(_{t}\) as the variance scale. In the reverse process, the model \(f_{}\) (usually a U-Net or a Transformer) learns to reconstruct the original data \(_{0}\) from the noised data \(_{T}\). It does so by iteratively estimating the parameters \(p_{}(_{t-1}|_{t})=(_{t-1}; _{}(_{t},t),_{t}^{2})\), where \(_{}\) and \(_{t}^{2}\) predict the mean and variance of the distribution.

**BERT and Diffusion Models Approaches in Cybersecurity and Other Fields**. The application of pre-trained models, such as ET-BERT (Lin et al. (2022)) and NetGPT (Meng et al. (2023)), has revolutionized understanding of network traffic by capturing the intricacies of language and interpreting complex network patterns. Meanwhile, diffusion models have emerged as powerful generative tools capable of producing high-fidelity data for applications like image generation and notably, synthetic network traffic generation. These models leverage a unique denoising training objective to closely mimic the original data distribution, making them promising for generating realistic network traffic for testing and analysis. Despite these advancements, combining the contextual understanding of pre-trained models with the generative prowess of diffusion models remains underexplored in adversarial packet generation. This integration offers a synergistic approach, merging the nuanced comprehension of network behaviors by pre-trained models with the high-quality data generation of diffusion models. By leveraging these technologies together, cybersecurity researchers can enhance the realism of simulated network environments and develop more advanced evasion tactics.

## 3 DiffuPac

In this section, we introduce DiffuPac, a first-of-its kind adversarial packet generation model. Figure 1 illustrates the overall framework of the proposed model, consisting of three main phases: pcap pre-processing, pre-training and fine-tuning with diffusion model.

### Data pre-processing

In real network environments, traffic contains diverse flows from various applications, protocols, and services, complicating the learning of stable representations. Therefore, we first split pcap (packet capture) files into sessions (bidirectional flows) based on IP addresses, port addresses, and protocols. To refine the training of the BERT model, we further split sessions into unidirectional flows, categorizing them as either source-to-destination (src-to-dst) packet sequence or destination-to-source (dst-to-src) packet sequence. This categorization is crucial for the BERT model's pre-training. Network traffic varies due to diverse protocols and network services, resulting in different formats and patterns. To handle these variations and encoding requirements, we convert each byte to its corresponding hex number and tokenize using WordPiece (Wu et al. ). Each token ranges from 0 to 65535, with a dictionary size of 65536. We also incorporate special tokens [CLS], [SEP], [PAD], and [MASK] for training tasks. [CLS] is used at the beginning of each sequence and helps in classification tasks. [SEP] separates different sequences or segments within the same input. [PAD] ensures sequences are of uniform length and satisfy the minimum length requirement. [MASK] is used in pre-training task, where it temporarily substitutes tokens to be predicted.

### Pre-training

As shown in Figure 1, the input tokens are processed using an embedding strategy that involves the sum of three types of embeddings: token embeddings, positional embeddings, and segment embeddings. Each embedding has a dimension of 768. _Token Embeddings_ are high-dimensional

Figure 1: Proposed architecture is divided into three phases: pcap pre-processing, pre-training and fine-tuning with diffusion models.

vectors that uniquely represent each token, acting as their exclusive identifiers. _Positional Embeddings_ are used to capture the temporal relationships of tokens, ensuring that the model learns to focus on the order of data transmission. _Segment Embeddings_ differentiate packets within a single flow, as packets may not inherently share semantic associations, and preserving the order of packets to maintain the temporal sequence of events in a session flow.

We design our pre-training tasks based on the approach described in Devlin et al. (2019). Our two proposed pre-training tasks aim to capture the contextual relationships between traffic bytes. The first task involves predicting masked tokens to learn the underlying patterns and dependencies within the traffic data. The second task predicts the transmission order by determining whether packets belong to src-to-dst or dst-to-src sequences, thereby capturing the directional flow of the network traffic.

**Masked Unidirectional Flow Model.** Inspired by BERT's Masked Language Model (MLM) in natural language processing, we adapt this approach for network traffic analysis through our Masked Unidirectional Flow Model. This model is designed to understand and predict the semantic patterns within bidirectional network flows; that are src-to-dst sequence and dst-to-src sequence. During pre-training, each token in the input sequence is masked with a probability of 15%. Amongst these masked tokens 80% are replaced with a [MASK] token, 10% are replaced with a random token from the vocabulary, and 10% are left unchanged. This introduces variability that mimics real-world data inconsistencies. The training objective is to minimize the negative log-likelihood of correctly predicting the original tokens at the masked positions. Formally, the loss function \(L_{}\) for this task is defined as:

\[L_{}=-_{i=1}^{n}1(m_{i}) P(v_{i} V_{}; ),\] (1)

where \(n\) is the total number of tokens in the sequence, \(1(m_{i})\) is an indicator function that is 1 if the token \(v_{i}\) was masked (0 otherwise). \(m_{i}\) indicates the masking status of the \(i\)-th token and \(V_{}\) is the masked sequence. \(v_{i}\) is the actual token at position \(i\) and \(P(v_{i} V_{};)\) is the probability of predicting the original token \(v_{i}\) for given masked sequence and model parameters \(\). The transformer encoder, characteristic of BERT, processes \(V_{}\) to predict each masked token. This architecture leverages self-attention mechanisms to capture dependencies and context effectively, which is crucial for understanding complex patterns in network traffic.

**Same Sequence-origin Prediction**. Inspired by Lin et al. (2022), this task employs a dedicated binary classifier to determine the directional origin of network traffic, specifically whether packets in a sequence originate from src-to-dst or dst-to-src. This classification enhances the model's understanding of network flows and the contextual relationships between packets, which is crucial for recognizing communication patterns and dependencies in network traffic. For this task, each packet \(a_{r}\) is paired with another packet \(a_{s}\). 50% of the time, \(a_{s}\) is the next logical packet in the flow (src-to-dst or dst-to-src); the other 50% of the time, it is a randomly chosen packet from the opposite flow. The classifier then predicts whether \(a_{s}\) follows \(a_{r}\) in the correct directional sequence. This pairing strategy improves the model's capability to discern patterns in packet flows. Let \(A=\{(a_{r},a_{s})\}\) be the set of packet pairs, where each pair is labeled with \(b_{w}\{0,1\}\) (1 if \(a_{s}\) follows \(a_{r}\) in the correct flow, 0 otherwise). The loss function \(L_{}\) for this task can be formulated as:

\[L_{}=-_{w=1}^{K}b_{w} P(b_{w}=1 a_{r},a_{s};)+(1-b _{w})(1-P(b_{w}=1 a_{r},a_{s};)),\] (2)

where \(K\) is the total number of packet pairs and \(\) represents the trainable parameters of the classifier. \(P(b_{w}=1 a_{r},a_{s};)\) is the probability predicted by the classifier that \(a_{s}\) correctly follows \(a_{r}\) in the given network flow direction.

In summary, the final pre-training objective is the sum of the above two losses, which can defined as:

\[L=L_{}+L_{}.\] (3)

Fu et al. (2021) mentioned that the number of packets within each flow can vary significantly. Given the constraints imposed by packet size and the potential volume of network traffic, computational efficiency is a paramount concern. In addressing this problems, as demonstrated in Dai et al. (2023) that the initial packets in a flow contain the most significant information, we limit our analysis to the first three packets of each heavy flow. This means that for each session, we analyze a total of six packets--three from the src-to-dst flow and three from the dst-to-src flow. This strategy ensures a comprehensive view of the session while maintaining efficiency.

### Fine-tuning with Diffusion Models

**Forward Process with Packet Sequences Concatenation Strategy**. In the fine-tuning phase, the goal is to train the model so that malicious packets can mimic normal packets to bypass NIDS. This involves using packet sequences that are only from the src-to-dst, reflecting the adversary's control over the packets being sent (Hore et al. (2023)). The forward process of our diffusion model begins by embedding both normal (benign) packet sequences \(^{}\) and malicious packet sequences \(^{}\). This transformation of discrete packet data into a continuous feature spaces uses an embedding function adapted from Li et al. (2022). Building upon the groundwork of DiffuSeq (Gong et al. (2023)) approach, which typically involves random merging, our model innovates by leveraging the deep contextual insights provided by the pre-trained BERT model (Details in A.2). This allows us to strategically pair normal and malicious sequences with strong contextual alignments that show similarity in network behavior patterns. These contextually aligned pairs are crucial for mimicking normal traffic and increasing the chances of bypassing NIDS. By integrating these contextually aligned pairs into our diffusion process, the model extends the original forward chain to a new Markov transition \(q_{}(_{0}^{})=( (^{}),_{0})\), where \((^{})\) symbolizes the embedding transformation and concatenation of normal and malicious packet sequences. While \(^{}\) denotes the initial concatenated sequence, the forward process gradually perturbs this initial state \(_{0}\) through a series of transitions, producing latent variables \(_{1},_{2},,_{t}\).

**Targeted Noising**. To enhance our diffusion model's capability for adversarial packet generation, we simplify the model's state transitions by defining \(_{t}=_{t}_{t}\), where \(_{t}\) and \(_{t}\) correspond to the portions of \(_{t}\) that belong to \(^{}\) and \(^{}\), respectively. This setup allows us to strategically inject noise into only the malicious packet sequences (represented by \(_{t}\)), rather than the entire state \(_{t}\), during each forward step \(q(_{t}_{t-1})\). This targeted noising, inspired by DiffuSeq, is pivotal for adapting conventional diffusion models for targeted modification.

**Reverse Process With Normal Packet Guidance**. Building upon the foundational principles of DiffuSeq, our model introduces an innovative reverse process tailored for more nuanced handling of network traffic data. This process distinctively utilizes normal packet sequences as a guiding framework, enabling a sophisticated denoising technique that treats the concatenated sequences of normal and noise-added malicious packets as a unified unit. This approach effectively "teaches" the model to perceive these malicious elements as integral parts of the normal traffic pattern. A key aspect of this reverse process is the use of the pre-trained BERT model as the denoising engine during packet reconstruction. In this phase, the BERT model undergoes fine-tuning within the diffusion framework, ensuring that it is specifically adapted for reconstructing packets. As a result, the BERT model is not only responsible for contextual understanding but also plays a central role in recovering malicious packets that have been integrated into normal traffic patterns. The conditional denoising process effectively employs Bayesian inference to parameterize the transition probabilities between states, ensuring precise control over each step in the reverse process. These parameterizations are mathematically articulated through the equations: \(p_{}(_{0:T}):=p(_{T})_{t=1}^{T}p_{}( _{t-1}|_{t})\) and \(p_{}(_{t-1}|_{t})=(_{t-1};_ {}(_{t},t),_{}(_{t},t)\), where \(_{}()\) and \(_{}()\) model the mean and variance necessary for the stochastic reverse transition from \(_{t}\) to \(_{t-1}\), respectively. To rigorously ensure that the malicious packets are not only recovered but also convincingly mimic normal packets, our model optimizes a specially formulated variational lower bound \(L_{VLB}\). This objective underscores the model's effectiveness in blending malicious packets within normal packets:

\[_{}L_{VLB}=_{}[_{t=2}^{T}\|_{0}-f_ {}(_{t},t)\|^{2}+\|(^{})-f_{}(_{1},1)\|^{2}- p_{}( ^{}_{0})]\] (4)

This objective is particularly focused on accurately reconstructing the initial state \(_{0}\) from the noised states, with a distinct emphasis on ensuring that the malicious components are seamlessly integrated into the normal packets pattern.

**Preserving Packets' Integrity**. We propose an innovative approach that utilizes a parallel data structure called _"model dictionary"_ that clearly distinguishes between mutable and immutable fields within each packet. By categorizing fields into mutable (e.g. TCP flags, TTL, and window size) and immutable (including the critical 5-tuple information and payload), we ensure that modifications during training do not compromise the packet's integrity. The model dictionary serves a dual purpose: it retains the original values of immutable fields and establishes a link to their mutable counterparts. This approach allows for dynamic modification of mutable fields during training without affectingthe core attributes of the packet. After training, any changes made to mutable fields are seamlessly integrated with the preserved immutable fields. This recombination ensures that the modified packets maintain their operational integrity and are indistinguishable from genuine traffic in real-world scenarios. By bypassing traditional domain constraints--which typically complicate training and pose convergence challenges--our method simplifies the training process and obviates the need for additional compensatory loss functions (Letcher (2021)). The outcome is a highly effective generation of adversarial packets that are capable of evading detection without compromising the essential characteristics of the original packets.

## 4 Experiments

We conduct experiments to validate the performance of DiffuPac on 6 types of attacks, against 6 classifiers.

### Experimental Setup

**Dataset**. The datasets used for this model are Kitsune Dataset (Mirsky et al. (2018)) and CICIDS-2017 Dataset (Sharafaldin et al. (2018)). Initially, _pre-training of the BERT model_ utilizes a large subset of unlabeled network traffic to leverage the model's capability to capture diverse traffic patterns, accounting for 60% of the total data. _Fine-tuning phase_, the focus shifts to a smaller, labeled dataset, which constitutes 20% of the total data. This dataset is distinctly partitioned into malicious and normal packets, which is crucial for training the model to mimic malicious packets as normal. _Training the classifier and NIDS_ then utilizes another 10% of the total data consisting of labeled portion. _Testing phase_ is conducted with the remaining 10% of the data, reserved exclusively for evaluating the model's efficacy. This phase includes testing both original and mimicked malicious packets to rigorously assess the model's real-world applicability and its capability to generalize across unseen data.

**Baseline Models**. We evaluate two baseline models--Traffic Manipulator (Han et al. (2021)) and TANTRA (Sharon et al. (2021))--both of which represent current strategies for evading NIDS but share a significant limitation in their reliance on specific operational assumptions. Traffic Manipulator formulates the evasions as a bi-level optimization problem, where the first level uses GAN to identify adversarial features closely mimicking the original network features, and the second level utilizes PSO to modify packet characteristics to exploit vulnerabilities in NIDS. TANTRA employs a three-step process involving an LSTM trained to model benign traffic by predicting inter-packet delays. This LSTM then adjusts malicious traffic to mimic these benign patterns before deployment. Both models, however, assume a degree of accessibility to NIDS configurations or feature extractors that is often unrealistic in practical scenarios. This reliance on specific knowledge about NIDS configurations creates a critical dependency that can limit the deployment and scalability of these evasion techniques in diverse operational environments. Conversely, DiffuPac operates under the assumption of zero prior knowledge about NIDS configurations or feature extractors.

**Implementation Details**. DiffuPac leverages a BERT model with 12 transformer blocks, each featuring 12 attention heads and an embedding dimension of 768, to capture nuanced relationships in network traffic. This setup supports the maximum sequence length of 512. The diffusion model incorporates time step embedding to provide temporal context, enhancing the model's understanding of the reverse process. To manage the computational demands, particularly during the sampling phase, a projection layer reduces the embedding dimension to 128. Additionally, DiffuPac utilizes the FAISS library (Douze et al. (2024)), renowned for its capability to handle large-scale similarity search and clustering of dense vectors.

**Experimental Details**. Our experimental framework integrates advanced feature extraction tools and a diverse set of machine learning classifiers, building on methodologies established in the Traffic Manipulator research. We employ 2 feature extractors: AfterImage (Mirsky et al. (2018)), which provides detailed packet statistics, and CICFlowMeter (Draper-Gil et al. (2016)), which assesses connection-level metrics. Recognizing the documented shortcomings of the original CICFlowMeter, our research employs a revised version that integrates enhancements and corrections proposed in recent studies (Engelen et al. (2021); Liu et al. (2022)). These modifications are crucial in ensuring more accurate and reliable feature extraction for our analysis. AfterImage and CICFlowMeter offer a comprehensive view of network traffic, capturing both packet-level and flow-level data essential for nuanced analysis. These feature extractors are integral to NIDS detection as they preprocess network data into structured features that are then analyzed by ML classifiers. This preprocessing step is crucial for transforming raw network traffic into a format that classifiers can effectively interpret, thereby enhancing the accuracy of the anomaly detection. We utilize a variety of machine learning classifiers for anomaly detection, including _KitNET_(Mirsky et al., 2018), an ensemble of autoencoders; _Multi-Layer Perceptron (MLP)_ for deep learning; _Logistics Regression (LR)_, _Decision Tree (DT)_, and _Support Vector Machine (SVM)_ for traditional approaches; and _Isolation Forest (IF)_ for outlier detection. Our experiments cover 6 types of attacks--_Man-in-the-Middle (MITM)_, _Bomet, Brute Force_, _DDoS_, _Port Scan_, and _Infiltration_--utilizing data from Kitsune and the CICIDS-2017 dataset.

**Evaluation**. To assess the effectiveness of the mimicked packets in evading the 6 classifiers, we employed a singular, highly illustrative metric from the Traffic Manipulator: the Malicious traffic Evasion Rate (MER). This metric is calculated using the formula: \(=1-(N^{}/N^{})\), where \(N^{}\) and \(N^{}\) represent the number of detected adversarial and detected malicious packet sequences, respectively. This equation captures the percentage of adversarial packet sequences that goes undetected as compared to the original malicious packet sequences that was detected, effectively measuring the evasion capability of the adversarial packet sequences.

We employed the two-sample Kolmogorov-Smirnov (K-S) test, a powerful non-parametric method used to determine the probabilistic differences between two data samples. Specifically, we compare the empirical cumulative distribution functions (eCDFs) of both the original malicious packets and the adversarial packets generated by our model. The K-S test calculates the maximum distance (K-S statistic, _D_) between these two eCDFs. This statistic measures the greatest deviation between the distribution of our adversarially modified packets and the original malicious packets (Hore et al., 2023; Gretton et al., 2012). A \(D\) value exceeding the critical threshold at a chosen significance level suggests a rejection of the null hypothesis--that is, the two samples are not derive from the same distribution. We demonstrated adversarial packets that were found to be out-of-distribution (OOD) at 95% significance level.

Additionally, we used Wireshark, a widely recognized network protocol analyzer to ensure that during the modifications were made, the immutable fields crucial for the packet's attack functionality were preserved. This visual verification via Wireshark confirms that our adversarial packets maintain their structural integrity and functionality, successfully mimicking genuine network traffic while evading detection (Due to limited space, results and analysis are in Appendix B.1).

We also evaluated DiffuPac's efficacy in generating adversarial packets that maintain their malicious functionality in a controlled test environment using UTM hypervisor technology. This setup included two virtual machines: one running Kali Linux (attacker) and another running Ubuntu 24.04 (victim). The isolation ensured a realistic yet controlled network environment. We conducted the evaluation on two type of attacks: _Port Scan_ and _Brute Force_. (Due to space constraints, results and analysis of the two attacks are in Appendix B.3.1 and B.3.2).

Table 2: Comparative analysis of attack detection and evasion rates.

### Results and Analysis

**Evasion Rate**. We evaluated the evasion rates of the 6 attacks using DiffuPac and two baseline models, and compared the results in Table 2 (Due to space constraints, the other 4 attacks are demonstrated in Appendix B.2). As shown in Table 2, we conclude that DiffuPac is capable of generating adversarial packets that achieves comparable or even higher in evasion rate compared with both Traffic Manipulator (GAN & PSO) and TANTRA (LSTM). Importantly, DiffuPac achieves this high performance without relying on NIDS components, surrogate classifiers or specific insights into the NIDS's feature extraction methods, highlighting its effectiveness in realistic settings where attackers lack access to such insider information. The evasion performance varied significantly across different classifiers, reflecting the inherent variability in their robustness and detection capabilities. Flow-based NIDS exhibited greater resilience against our attacks compared to packet-based NIDS, likely due to DiffuPac's focus on packet-level modifications. Interestingly, the Traffic Manipulator model performed well with KitNet's AfterImage feature extractor, likely because it was trained directly on these features, enhancing its capability to modify them to evade detection. This specific alignment with NIDS features, while effective, does not typically reflect real-world attacker capabilities or constraints.

TANTRA also demonstrated high evasion rates, particularly with AfterImage, thanks to its use of LSTM models trained on benign traffic from the targeted network. This training allows TANTRA to reshape the timing between packets. This specific adjustment of interpacket delays directly impacts the time-based features extracted by AfterImage, making it more difficult for the classifiers to distinguish between normal and malicious packets.

Quantitatively, DiffuPac outperformed Traffic Manipulator by an average of 9.12 percentage points and TANTRA by an average of 4.26 percentage points across all attack types. The overall average improvement of DiffuPac over both baselines is 6.69 percentage points, demonstrating its superior capability to generate adversarial packets that effectively evade detection.

Based on the results of all the attacks, we can conclude that ML classifier are more robust than DNNs to adversarial attacks. Traditional ML models, like DT and IF, have simpler and more interpretable decision boundaries, making them less susceptible to subtle adversarial modifications (Sauka et al. (2022)). In contrast, DNNs with their complex and high-dimensional decision boundaries are more easily misled by the nuanced modifications introduced by DiffuPac.

**Statistical Difference (K-S test)**. The percentage of successful adversarial packets that were found to be OOD are demonstrated in Table 3. From the result, we can obeserve that Brute Force and DDoS attacks show the highest percentage of OOD samples. The grounded reasons for these kind of attacks are due to the inherent nature of their traffic patterns. The nature of Brute Force attacks involves numerous failed login attempts, leading to highly irregular sequence numbers (Javed and Paxson (2013)). Even after modifications by DiffuPac, these attempts will stand out due to their frequency and pattern, resulting in significant deviations in the eCDFs. The sheer volume and repetitive nature of DDoS traffic (Haseeb-ur rehman et al. (2023)) make it difficult to disguise effectively. Despite efforts of intelligent mutation process, the high volume and distinctive traffic patterns will cause substantial deviations in the eCDFs as well. On the other hand, the MITM show the lowest percentage of OOD samples. Adjusting TTL values is straightforward as they can be set to typical ranges seen in normal packets without significantly altering packet behavior, resulting in minimal deviation in the eCDFs.

## 5 Limitations

Our evaluations demonstrated DiffuPac's strong evasion capabilities, enabling the generation of adversarial packets that convincingly mimic legitimate network traffic, particularly in packet header fields. While these results highlight DiffuPac's ability to evade detection by NIDS, there remain areas for further study.

    &  \\  & **OOD Samples (\%)** \\  Botnet & 48.72 \\ MITM & 29.34 \\ Port Scan & 55.23 \\ DDoS & 78.14 \\ Infiltration & 58.06 \\ Brute Force & 69.67 \\   

Table 3: Percentage of successful adversarial samples found to be OOD.

In particular, while we assessed the malicious functionality of generated adversarial packets in a controlled environment using UTM hypervisor technology, this evaluation was limited to _Port Scan_ and _Brute Force_ attacks. Although DiffuPac successfully retained the malicious intent of these attacks, further evaluations are required to determine its effectiveness across a broader range of attacks, especially those with more complex behaviors such as DDoS or Botnet attacks.

We also noted that DiffuPac's evasion performance is not uniform across all scenarios, notably DDoS and Brute Force. This variability is due to the distinct nature of each attack's traffic patterns, which may not be fully captured by the model, especially in highly repetitive or anomalous behaviors. To enhance the model's adaptability and generalizability, we plan to enrich the training dataset with a broader spectrum of real-world attack scenarios.

Moreover, the dual-use nature of adversarial generation models like DiffuPac presents significant ethical and legal challenges. While designed to improve security defenses, these technologies could be misused for malicious activities, such as facilitating cyber-attacks or disrupting services. To mitigate these risks, we have opted not to publicly release saved model checkpoints, aiming to prevent exploitation by malicious entities and ensure that our advancements in adversarial packet generation are used responsibly and within ethical bounds.

## 6 Conclusion and Future Directions

In this study, we introduced DiffuPac, an intelligent generative model that successfully generates adversarial packets capable of evading advanced NIDS while maintaining attack functionality. Unlike previous research, which often assumes attacker access to NIDS, DiffuPac operates under constraints of limited attacker knowledge, reflecting more realistic scenarios. Here, we present the in-depths insights obtained from this study: (a) DiffuPac uniquely combines normal and malicious packet sequences using contextual alignments, ensuring seamless integration into genuine traffic while employing these normal packet sequences to guide the denoising process. Through the performance evaluations with various NIDS, our model achieved an average improvement of approximately 6.69 percentage points in evasion rate compared to the two baselines across all attack types. (b) Evasion rates varied notably across attack types, with DDoS and Brute Force attacks showing higher probabilistic differences due to their complex, repetitive nature. This highlights potential areas for further refinement in DiffuPac's approach to handling voluminous attacks. (c) Simpler ML models like DT and IF displayed surprising resilience due to their less complex decision boundaries, limiting the effectiveness of DiffuPac's modifications. In contrast, DNNs, with their intricate decision boundaries, were more vulnerable, underscoring the complexities inherent in designing robust adversarial tactics. (d) DiffuPac's capability to balance sophisticated attacks with operational stealth makes it especially suitable for environments where attackers lack comprehensive NIDS configurations, enhancing its utility in realistic defense testing.

As future studies, we will compare DiffuPac against a broader generative adversarial packets model and extend testing across more diverse NIDS to better understand its relative strengths and limitations. Next, we will further expand the range of attack types included in the malicious functionality evaluation. Moreover, adversarial defenses are a key focus of our ongoing research, particularly in relation to DiffuPac's capabilities. One promising direction is the development of adversarial purification using diffusion models, a technique successfully applied in image processing. This approach treats adversarial perturbations as noise, utilizing the diffusion model's reverse process to restore network packets to their original state before analysis by NIDS. We believe this method has significant potential for enhancing network security and aim to further develop and test it as a novel defense strategy.