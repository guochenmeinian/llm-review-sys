# SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation

Mengcheng Lan\({}^{1}\) Xinjiang Wang\({}^{3}\) Yiping Ke\({}^{2}\) Jiaxing Xu\({}^{2}\)

Litong Feng\({}^{3}\) Wayne Zhang\({}^{3}\)

\({}^{1}\) S-Lab, Nanyang Technological University

\({}^{2}\) SCSE, Nanyang Technological University

\({}^{3}\) SenseTime Research

{lanm0002, jiaxing003}@e.ntu.edu.sg

ypke@ntu.edu.sg

{wangxinjiang, fenglitong, wayne.zhang}@sensetime.com

https://github.com/mc-lan/SmooSeg

Corresponding author.

###### Abstract

Unsupervised semantic segmentation is a challenging task that segments images into semantic groups without manual annotation. Prior works have primarily focused on leveraging prior knowledge of semantic consistency or priori concepts from self-supervised learning methods, which often overlook the coherence property of image segments. In this paper, we demonstrate that the smoothness prior, asserting that close features in a metric space share the same semantics, can significantly simplify segmentation by casting unsupervised semantic segmentation as an energy minimization problem. Under this paradigm, we propose a novel approach called SmooSeg that harnesses self-supervised learning methods to model the closeness relationships among observations as smoothness signals. To effectively discover coherent semantic segments, we introduce a novel smoothness loss that promotes piecewise smoothness within segments while preserving discontinuities across different segments. Additionally, to further enhance segmentation quality, we design an asymmetric teacher-student style predictor that generates smoothly updated pseudo labels, facilitating an optimal fit between observations and labeling outputs. Thanks to the rich supervision cues of the smoothness prior, our SmooSeg significantly outperforms STEGO in terms of pixel accuracy on three datasets: COCOStuff (+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%).

## 1 Introduction

Semantic segmentation is a crucial task in computer vision that allows for a better understanding of the visual content and has numerous applications, including autonomous driving  and remote sensing imagery . Despite advancements in the field, most traditional semantic segmentation models heavily rely on vast amounts of annotated data, which can be both arduous and costly to acquire. Consequently, unsupervised semantic segmentation [3; 4; 5; 6; 7; 8] has emerged as a promising alternative. Prior knowledge is fundamental to the success of unsupervised semantic segmentation models. One key prior knowledge is the principle of _semantic consistency_, which stipulates that an object's semantic label should remain consistent despite photometric or geometric transformations. Recent advances [3; 9; 4; 10] use contrastive learning to achieve consistent features or class assignments. Another essential prior knowledge is the _priori concepts_ implicitly provided by self-supervised learning techniques, _e.g._, DINO  and precedent arts [12; 8; 6] whose learned features can be employed to partition each image into different segments. Despite their effectiveness,these methods often overlook the coherence property of image segments, resulting in predicted segments that are incomplete and lacking in coherence, as shown in Fig. 1.

Real-world images often demonstrate a natural tendency towards piecewise coherence regarding semantics, texture, or color. Observations close to each other, either in the form of adjacent pixels in the coordinate space or close features in a metric space, are expected to share similar semantic labels, and vice versa. This essential property, known as the _smoothness prior_, plays a crucial role in various computer vision tasks [13; 14; 15]. Surprisingly, it is still under-explored in the field of unsupervised semantic segmentation.

In this paper, we attempt to tackle unsupervised semantic segmentation from the perspective of _smoothness prior_. As a dense prediction task, semantic segmentation aims at finding a labeling \(f\) that assigns each observation (pixel, patch, features) \(p\) a semantic category \(f(p)\), which could be formulated within an energy minimization framework : \(E(f)=E_{}(f)+E_{}(f)\). \(E_{}\) is a pairwise smoothness term that promotes the coherence between observations, and \(E_{}\) represents a pointwise data term that measures how well \(f(p)\) fits the observation \(p\). However, directly applying smoothness prior to unsupervised semantic segmentation faces several obstacles. 1) Due to the large intra-class variations in appearances within an image, it is difficult to define a well-suited similarity (dissimilarity) relationship among low-level observations. This makes it challenging to discover groups of complex observations as coherent segments. 2) \(E_{}\) can lead to a trivial solution where \(f\) becomes smooth everywhere, a phenomenon known as model collapse. 3) Optimizing \(E_{}\) without any observed label can be challenging.

In this study, we propose a novel approach called SmooSeg for unsupervised semantic segmentation to address the aforementioned challenges. By leveraging the advantages of self-supervised representation learning in generating dense discriminate representations for images, we propose to model the closeness relationships among observations by using high-level features extracted from a frozen pre-trained model. This helps capture the underlying smoothness signals among observations. Furthermore, we implement a novel pairwise smoothness loss that encourages piecewise smoothness within segments while preserving discontinuities across image segments to effectively discover various semantic groups. Finally, we design an asymmetric teacher-student style predictor, where the teacher predictor generates smooth pseudo labels to optimize the data term, facilitating a good fit between the observations and labeling outputs.

Specifically, our model comprises a frozen feature extractor, a lightweight projector, and a predictor. The projector serves to project the high-dimensional features onto a more compact, low-dimensional embedding space, and the predictor employs two sets of learnable prototypes to generate the final segmentation results. We optimize our model using a novel energy minimization objective function. Despite its simplicity, our method has demonstrated remarkable improvements over state-of-the-art approaches. In particular, our method significantly outperforms STEGO  in terms of pixel accuracy on three widely used segmentation benchmarks: COCOStuff (**+14.9%**), Cityscapes (**+13.0%**), and Potsdam-3 (**+5.7%**).

Figure 1: A case study of our SmooSeg with two state-of-the-arts, STEGO  and TransFGU , on the COCOStuff dataset. Our observations reveal that the segmentation maps generated by STEGO and TransFGU for regions such as the sand beach (first row) and the grassland (second row) are incomplete and lack smoothness and coherence. In contrast, our SmooSeg exhibits improved segmentation results for all these regions by considering the smoothness prior.

Related work

**Unsupervised semantic segmentation** has gained increasing attention for automatically partitioning images into semantically meaningful regions without any annotated data. Early CRF models [17; 18] incorporate smoothness terms that maximize label agreement between similar pixels. They define adjacency for a given pixel in the coordinate space, _e.g.,_ using 4-connected or 8 connected grid, which relies heavily on the low-level appearance information and falls short in capturing high-level semantic information in images. Recently, many methods [3; 4; 10] have attempted to learn semantic relationships at the pixel level with semantic consistency as a supervision signal. For example, IIC  is a clustering method that discovers clusters by maximizing mutual information between the class assignments of each pair of images. PiCIE  enforces semantic consistency between an image and its photometric and geometric augmented versions. HSG  achieves semantic and spatial consistency of grouping among multiple views of an image and from multiple levels of granularity. Recent advances [19; 12; 6; 8; 20] have benefited from self-supervised learning techniques, which provide priori concepts as supervision cues. For instance, InfoSeg  segments images by maximizing the mutual information between local pixel features and high-level class features obtained from a self-supervised learning model. The work in  directly employs spectral clustering on an affinity matrix constructed from the pre-trained features. TransFGU  generates pixel-wise pseudo labels by leveraging high-level semantic concepts discovered from DINO . Additionally, STEGO  utilizes knowledge distillation to learn a compact representation from the features extracted from DINO based on a correspondence distillation loss, which also implies a smoothness regularization through the dimension reduction process. However, the utilization of smoothness prior in STEGO is implicit and entails separate post-process, such as min-batch K-Means, for the final semantic clustering. Besides, MaskContrast  and FreeSOLO  leverage mask priors and primarily focus on foreground object segmentation. In contrast, we propose to leverage the smoothness prior as a supervision cue to directly optimize the generated semantic map, achieving more coherent and accurate segmentation results.

**Self-supervised representation learning (SSL)** aims to learn general representations for images without additional labels, which has offered significant benefits to various downstream tasks, including detection and segmentation [6; 8]. One main paradigm of SSL is based on contrastive learning [23; 24; 25; 26; 27; 11; 28; 29], which seeks to maximize the feature similarity between an image and its augmented pairs while minimizing similarity between negative pairs. For example, MoCo  trains a contrastive model by using a memory bank that stores and updates negative samples in a queue-based fashion. SimCLR  proposes to learn a nonlinear transformation, _i.e._, a projection head, before the contrastive loss, to improve performance. Notably, DINO , built upon Vision Transformer (ViT) , has a nice property of focusing on the semantic structure of images, such as scene layout and object boundaries. Features extracted by DINO exhibit strong semantic consistency and have demonstrated significant benefits for downstream tasks [12; 6; 8]. Another mainstream belongs to the generative learning approach [31; 32; 33]. MAE  and SimMIM  propose to predict the raw masked patches, while MaskFeat  proposes to predict the masked features of images. Our work also leverages recent progress in SSL for unsupervised semantic segmentation.

## 3 Method

Problem setting.Given a set of unannotated images \(I=[I_{1},,I_{B}]^{B 3 H W}\), where \(B\) denotes the number of images, and \(3,H,W\) represent the channel, height, and width dimensions respectively, the objective of unsupervised semantic segmentation is to learn a labeling function \(f\) that predicts the semantic label for each pixel in each image. We represent the predicted semantic maps as \(Y=[Y_{1},,Y_{B}]\{1,,K\}^{B H W}\), where \(K\) refers to the number of predefined categories.

Architecture.To achieve this goal, we introduce the SmooSeg approach, which capitalizes on self-supervised representation learning and smoothness prior within an energy minimization framework, as illustrated in Fig. 2. SmooSeg comprises three primary components: a feature extractor \(f_{}\), a projector \(h_{}\), and a predictor \(g_{}\). Initially, for each image \(I_{i}\), we employ a pre-trained backbone network, such as a frozen version of DINO, to acquire feature representations \(X_{i}=f_{}(I_{i})^{C N}\), where \(C\) and \(N\) denote the number of feature channels and image patches, respectively. Subsequently, the projector \(h_{}\) maps these features onto a low-dimensional embedding space, resulting in a set of compact features \(Z_{i}=h_{}(X_{i})^{D N}\), where \(D\) denotes the reduced feature dimensionality. Finally, the predictor \(g_{}\) generates the label assignments \(A_{i}^{\{s,t\}}^{K N}\) by computing the similarity scores between the compact features \(Z_{i}\) and the prototypes \(P^{\{s,t\}}\). Here, \(P^{s}\) and \(P^{t}\) represent student and teacher prototypes, respectively. The semantic map \(Y_{i}\) for image \(I_{i}\) can be obtained by reshaping the output \(Y_{i}^{t}\) of the teacher branch.

### Smoothness Prior

Real-world images typically exhibit inherent continuity and coherence in terms of semantics, texture, and color. Within a single object, semantic labels tend to demonstrate smoothness and consistency, ensuring a cohesive representation of the object. In contrast, labels between distinct objects manifest discontinuity and divergence, facilitating the separation of different object instances. This essential property, known as the smoothness prior, is expected to play a critical role in guiding unsupervised semantic segmentation tasks toward more accurate and meaningful segmentation results. We therefore consider the following pairwise smoothness term:

\[E_{}=_{i=1}^{B}_{p,q=1}^{N}W_{pq}^{ii}(Y_{i,p},Y_{i,q}),\] (1)

where \(W^{ii}^{N N}\) is the closeness matrix of image \(I_{i}\). \((Y_{i,p},Y_{i,q})\) is the penalty that takes the value of \(1\) if \(Y_{i,p} Y_{i,q}\), and 0 otherwise. By minimizing this smoothness term, two close patches with different labels will be penalized. In other words, the segmentation model is encouraged to assign similar labels to close patches, thereby promoting the coherence within objects.

Closeness matrix.It is worth noting that the large intra-class variation in appearances within the raw pixel space renders the discovery of well-suited closeness relationships among low-level observations challenging. We therefore propose to model the closeness relationships by the cosine distance in the high-level feature space. Specifically, \(W^{ii}\) can be calculated by:

\[W_{pq}^{ii}= X_{i,q}}{\|X_{i,p}\|\|X_{i,q}\|},\] (2)

where \(X_{i,p}\) and \(X_{i,q}\) represent the feature vectors for patches \(p\) and \(q\) of image \(I_{i}\), respectively. Theoretically, a large element value in the closeness matrix, _i.e.,_ a high cosine similarity, suggests a high possibility of a close patch pair, and vice versa. We apply a zero-mean normalization to this matrix: \(_{p}^{ii}=W_{p}^{ii}-_{q}W_{pq}^{ii}\). This normalization balances the negative and positive forces during optimization, which prevents excessive influence from either the negative or positive components of the closeness matrix and ensures that the optimization process is more stable.

Label penalty.Directly minimizing Eq. 1 to optimize our segmentation model is not feasible due to the non-differentiable property of \((,)\) and the hard label assignment \(Y\). As a result, we have to

Figure 2: Overview of our SmooSeg framework, showing the application of the smoothness prior within image \(I_{i}\) and across images \(I_{i}\) and \(I_{i^{}}\). sg denotes the stop-gradient operation.

resort to another form of penalty cost. Suppose we have the soft label assignment \(A^{t}_{i}^{K N}\) of image \(I_{i}\) (which will be introduced later), by which we can redefine the penalty cost function as:

\[(A^{t}_{i,p},A^{t}_{i,q})=1-_{i,p} A^{t}_{i,q}}{\|A^{t}_{ i,p}\|\|A^{t}_{i,q}\|}.\] (3)

Because the non-negative property of the softmax output, _i.e._, \(0 A^{t}\), \(0(,) 1\) always holds. A larger value of \((,)\) denotes a greater dissimilarity between two labels, thereby indicating a higher penalty cost, and vice versa.

Smoothness prior within and across images.To prevent the model from converging to a trivial solution where the labeling function becomes smooth everywhere, we also apply the smoothness prior across images, acting as a strong negative force, by introducing another image \(I_{i^{}}\) that is randomly selected from the current batch. We then obtain the final smoothness term:

\[E_{}=E_{}^{}+E_{}^{ {across}}=_{i=1}^{B}_{p,q=1}^{N}\{(_{pq}^{ii}-b_{1}) (A^{t}_{i,p},A^{t}_{i,q})+(_{pq}^{ii^{}}-b_{2})( A^{t}_{i,p},A^{t}_{i^{},q})\}.\] (4)

Here, we introduce a scalar \(b_{1}\) to adjust the threshold for applying the penalty. That is, when \(_{pq}^{ii}-b_{1}>0\), indicating that two patches \(p,q\) with a high closeness degree are nearby patches in the embedding space, patches \(p,q\) with different labels will be penalized, encouraging the piecewise smoothness within segments; otherwise, they are rewarded to assign different labels, leading to the discontinuities across segments. By doing so, SmooSeg is capable of finding globally coherent semantic segmentation maps.

Discussion with CRF and STEGO.CRF methods [17; 18] model the closeness relationship of pixels using their spatial coordinates, emphasizing the local smoothness within each image. On the contrary, our SmooSeg encodes the global closeness relationship of image patches based on the cosine distance in the feature space, which can discover the high-level semantic groups of images. Our smoothness term appears to be similar to the correlation loss in STEGO: \(_{}=-(F-b)(S,0)\), but essentially the two losses model different things. In STEGO, \(S\) denotes the feature correlation, by which STEGO aims to learn low-dimensional compact representations for images through a learnable projection head. A separate clustering algorithm, _e.g._, k-means, is required to obtain the final segmentation maps. However, even with the learned compact representations, the coherence of image segments is not guaranteed in STEGO as slight differences in features may lead to inconsistent labels in the clustering stage. In contrast, our SmooSeg aims to directly learn a labeling function (project + predictor) based on the smoothness prior, which encourages piecewise smoothness within segments and preserves disparities across segments, leading to more coherent and semantically meaningful segmentation maps. Additionally, the negative part of \(S\) contradicts the learning intention of STEGO and therefore requires a 0-clamp via \((S,0)\), which however, represents discontinuities between image patches and should be preserved. In contrast, our label penalty \(0(,) 1\) has a desirable property compared to \(S\).

### Asymmetric Predictor

A desirable labeling function learnt through energy minimization should on the one hand produce piecewise smooth results, and on the other hand be well fit between the observations and labeling outputs. For semantic segmentation, we expect the labeling output of an image to align well with its semantic map. In other words, the labeling output should accurately predict a category for each individual pixel with high confidence or low entropy. However, this goal is a nutshell in unsupervised semantic segmentation as there is no observed semantic map.

Self-training [34; 29] emerges as a promising solution for tasks involving unlabeled data. To address the above challenge, we design an asymmetric student-teacher style predictor to learn the labeling function through a stable self-training strategy. The student branch employs a set of \(K\) learnable prototypes (class centers) \(P^{s}=[p^{s}_{1},,p^{s}_{K}]^{K D}\) to predict the semantic maps of images. The teacher branch holds the same number of prototypes \(P^{t}\) as the student, and \(P^{t}\) is updated as an exponential moving average of \(P^{s}\). We then compute the soft assignment \(A^{\{s,t\}}_{i}\) of the embeddings \(Z_{i}\) with the prototypes \(P^{\{s,t\}}\) by computing their cosine similarity. With \(_{2}\)-normalized embeddings\(_{i}=Z_{i}/\|Z_{i}\|\) and prototypes \(^{\{s,t\}}=P^{\{s,t\}}/\|P^{\{s,t\}}\|\), we have

\[A_{i}^{s}=(}(_{i})),\ \ \ A_{i}^{t}=(((}) })/)^{K N},\] (5)

where temperature parameter \(>0\) controls the sharpness of the output distribution of the teacher branch. The teacher branch is responsible for generating smoothly updated pseudo labels to supervise the student prototypes' learning. By using a patch-wise cross-entropy loss, we have the data term as

\[E_{}=-_{i=1}^{B}_{p=1}^{N}_{k=1}^{K}_{Y_{i,p} ^{t}=k} A_{i,p,k}^{s},\] (6)

where \(\) is an indicator that outputs 1 if the argument is true, and 0 otherwise. \(Y_{i}^{t}=\ A_{i}^{t}\) is the hard pseudo label for patch \(p\) of image \(I_{i}\). By minimizing \(E_{}\), the segmentation model is expected to generate label assignments for each patch with high confidence, thus ensuring a better fit between the observations and their predicted labels.

### Overall Optimization Objective

Our final optimization objective function for training SmooSeg is obtained by incorporating the smoothness term and the data term as follows:

\[&=_{i=1}^{B}_{p,q =1}^{N}\{(_{pq}^{ii}-b_{1})(A_{i,p}^{t},A_{i,q}^{t})+(_{pq}^{ii^{}}-b_{2})(A_{i,p}^{t},A_{i^{},q}^{t})\}\\ &-_{i=1}^{B}_{p=1}^{N}_{k=1}^{K}_{Y_{i,p} ^{t}=k} A_{i,p,k}^{s}.\] (7)

In practice, \(\) could be approximately minimized using Stochastic Gradient Descent (SGD). During each training iteration, the projector is optimized using gradients from the smoothness loss, while the student prototypes are optimized using gradients from the data loss. The teacher prototypes are updated as an exponential moving average of the student prototypes: \(P^{t}= P^{t}+(1-)P^{s}\), with \(\) denoting the momentum value. After training, we use the output from the teacher branch as the segmentation results. The overall procedure in pytorch-like pseudocode of SmooSeg is summarized in Algorithm 1.

Experiments

### Experimental Setup

Datasets.Our experimental setup mainly follows that in previous works [8; 4] in datasets and evaluation protocols. We test on three datasets. **COCOStuff** is a scene-centric dataset with a total of 80 things and 91 stuff categories. Classes are merged into 27 categories for evaluation, including 15 stuff and 12 things. **Cityscapes** is a collection of street scene images from 50 cities, with classes merged into 27 classes by excluding the "void" class. **Potsdam-3** is a remote sensing dataset with 8550 images belonging to 3 classes, in which 4545 images are used for training and 855 for testing.

Evaluation metrics.For all models, we utilize the Hungarian matching algorithm to align the prediction and the ground-truth semantic map for all images. We also use a CRF [17; 8] as the post-processing to refine the predicted semantic maps. Two quality metrics including mean Intersection over Union (**mIoU**) and Accuracy (**Acc**) over all the semantic categories are used in the evaluation.

Implementation details.Our experiments were conducted using PyTorch  on an RTX 3090 GPU. To ensure a fair comparison with previous works [6; 8], we use DINO  with a ViT-small \(8 8\) backbone pre-trained on ImageNet as our default feature extractor, which is frozen during model training. Our projector consists of a linear layer and a two-layer SiLU MLP whose outputs are summed together. The predictor contains two sets of prototypes with the same initialization. The exponential moving average (EMA) hyper-parameter is set to \(=0.998\). The dimension of the embedding space is \(D=64\). The temperature is set to \(=0.1\). We use the Adam optimizer  with a learning rate of \(1 10^{-4}\) and \(5 10^{-4}\) for the projector and predictor, respectively.

We set a batch size of 32 for all datasets. For Cityscapes and COCOStuff datasets, we employ a five-crop technique to augment the training set size. We train our model with a total of 3000 iterations for Cityscapes and Potsdam-3 datasets, and 8000 iterations for the COCOStuff dataset.

### Comparison with State-of-the-Arts

Quantitative results.We summarise the quantitative results on three datasets in Tables 1, 2 and 3, respectively. Results of baselines, ResNet50, MoCoV2 and DINO are directly cited from the paper , while the results of DINOV2  (Table 3) are obtained by our implementation. For these baselines, we first extracted dense features for all images, then utilized a minibatch k-means algorithm to perform patches grouping, which resulted in the final segmentation maps. Our SmooSeg significantly outperforms all the state-of-the-art methods in terms of both pixel accuracy and mIoU on all datasets. In particular, on the COCOStuff dataset in Table 1, with DINO ViT-S/8 as backbone, SmooSeg gains a 14.9% improvement in pixel accuracy and a 2.2% improvement in mIoU over the best-performing baseline STEGO.

We observe that TransFGU outperforms STEGO in terms of accuracy, but is inferior in mIoU on both COCOStuff and Cityscapes. This is due to

   Methods & backbone & Acc. & mIoU \\  ResNet50  & ResNet50 & 24.6 & 8.9 \\ IIC  & R18+FPN & 21.8 & 6.7 \\ MDC  & R18+FPN & 32.2 & 9.8 \\ PiCIE  & R18+FPN & 48.1 & 13.8 \\ PiCIE+H  & R18+FPN & 50.0 & 14.4 \\ SlotCon  & ResNet50 & 42.4 & 18.3 \\  MoCoV2  & ResNet50 & 25.2 & 10.4 \\ + STEGO  & ResNet50 & 43.1 & 19.6 \\  + SmooSeg & ResNet50 & 52.4 & 18.8 \\  DINO  & ViT-S/8 & 29.6 & 10.8 \\ + TransFGU  & ViT-S/8 & 52.7 & 17.5 \\ + STEGO  & ViT-S/8 & 48.3 & 24.5 \\  + SmooSeg & ViT-S/8 & **63.2** & **26.7** \\   

Table 1: Performance on the COCOStuff dataset (27 classes).

   Methods & backbone & Acc. & mIoU \\  IIC  & R18+FPN & 47.9 & 6.4 \\ MDC  & R18+FPN & 40.7 & 7.1 \\ PiCIE  & R18+FPN & 65.5 & 12.3 \\  DINO  & ViT-S/8 & 40.5 & 13.7 \\ + TransFGU  & ViT-S/8 & 77.9 & 16.8 \\ + STEGO  & ViT-S/8 & 69.8 & 17.6 \\  + SmooSeg & ViT-S/8 & **82.8** & **18.4** \\   

Table 2: Performance on the Cityscapes Dataset (27 Classes).

[MISSING_PAGE_EMPTY:8]

[MISSING_PAGE_FAIL:9]

image patches. Therefore, it is reasonable to see that \(E_{}\) contributes significantly to the overall performance. On the contrary, the data term operates in a self-training fashion with pseudo labels derived from the teacher branch, which alone cannot generate accurate segmentation maps. These findings demonstrate the crucial role of both the data and smoothness terms for optimal performance of SmooSeg in unsupervised semantic segmentation.

Temperature parameter \(\).We investigate the effect of the temperature parameter \(\) on the performance of SmooSeg on the COCOStuff dataset, and report the results in Fig. 7. Theoretically, a smaller \(\) sharpens the softmax output, providing greater gradients and supervision signals for model training. Fig. 7 shows that \(\) plays a critical factor in the success of SmooSeg. Specifically, SmooSeg achieves good results when \( 0.1\), while performance drops considerably when \( 0.2\) because the softmax output tends to become uniformly distributed.

Momentum parameter \(\).We also study the impact of the \(\) on SmooSeg. \(\) controls the smoothness of the update of the teacher predictor from the student predictor. We plot the performance on the COCOStuff dataset as \(\) changes from 0.1 to 1 in Fig. 7. The performance of SmooSeg gradually improves as \(\) increases, and reaches stable when \(0.99\).

Limitation.Setting hyper-parameters without cross-validation is always a challenge for unsupervised learning methods. The main limitation of our method is that it involves two dataset-specific hyper-parameters in the smoothness term. We present a feasible strategy in Appendix A to alleviate this issue.

## 5 Conclusions

In this paper, we propose SmooSeg, a simple yet effective unsupervised semantic segmentation approach that delves into the potential of the smoothness prior, emphasizing the coherence property of image segments. In particular, we implement a pairwise smoothness loss to effectively discover semantically meaningful groups. We also design an asymmetric teacher-student style predictor to generate high-quality segmentation maps. SmooSeg comprises a frozen extractor, as well as a lightweight projector and a predictor which could be optimized using our energy minimization objective function. Experimental results show that SmooSeg outperforms state-of-the-art approaches on three widely used segmentation benchmarks by large margins.

Acknowledgement.This research is supported under the RIE2020 Industry Alignment Fund - Industry Collaboration Projects (IAF-ICP) Funding Initiative, as well as cash and in-kind contribution from the industry partner(s), by the National Research Foundation, Singapore under its Industry Alignment Fund - Pre-positioning (IAF-PP) Funding Initiative, and by the Ministry of Education, Singapore under its MOE Academic Research Fund Tier 2 (STEM RIE2025 Award MOE-T2EP20220-0006). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore, and the Ministry of Education, Singapore.