# Statistically Valid Variable Importance Assessment through Conditional Permutations

Ahmad Chamma

Inria, Universite Paris Saclay, CEA

ahmad.chamma@inria.fr

&Denis A. Engemann

Roche Pharma Research and Early Development,

Neuroscience and Rare Diseases,

Roche Innovation Center Basel,

F. Hoffmann-La Roche Ltd., Basel, Switzerland

denis.engemann@roche.com

Bertrand Thirion

Inria, Universite Paris Saclay, CEA

bertrand.thirion@inria.fr

###### Abstract

Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that _CPI_ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, _CPI_ consistently showed top accuracy across benchmarks. An experiment on real-world data analysis in a large-scale medical dataset showed that _CPI_ provides a more parsimonious selection of statistically significant variables. Our results suggest that _CPI_ can be readily used as drop-in replacement for permutation-based methods.

## 1 Introduction

Machine learning is an area of growing interest for biomedical research (Iniesta et al., 2016; Taylor and Tibshirani, 2015; Malley et al., 2011) for predicting biomedical outcomes from heterogeneous inputs (Hung et al., 2020; Zheng and Agresti, 2000; Giorgio et al., 2022; Sechidis et al., 2021). Biomarker development is increasingly focusing on multimodal data including brain images, genetics, biological specimens and behavioral data (Coravos et al., 2019; Siebert, 2011; Ye et al., 2008; Castillo-Barnes et al., 2018; Yang et al., 2022). Such high-dimensional settings with correlated inputs put strong pressure on model identification. With complex, often nonlinear models, it becomes harder to assess the role of features in the prediction, aka _variable importance_(Casalicchio et al., 2019; Altmann et al., 2010). In epidemiological and clinical studies, one is interested in _population-level_ feature importance, as opposed to instance-level feature importance.

In that context, variable importance is understood as _conditional_ importance, meaning that it measures the information carried by one variable on the outcome _given_ the others, as opposed to the easily accessible marginal importance of the variables. Conditional importance is necessary e.g. to assesswhether a given measurement is worth acquiring, on top of others, for a diagnostic or prognostic task. As the identification of relevant variables is model-dependent and potentially unstable, point estimates of variable importance are misleading. One needs confidence intervals of importance estimates or statistical guarantees, such as type-I error control, i.e. the percentage of non-relevant variables detected as relevant (false positives). This control depends on the accuracy of the p-values on variable importance being non-zero (Cribbie, 2000).

Within the family of removal-based importance assessment methods (Covert et al., 2022), a popular model-agnostic approach is _permutation_ variable importance, that measures the impact of shuffling a given variable on the prediction (Janitza et al., 2018). By repeating the _permutation_ importance analysis on permuted replicas of the variable of interest, importance values can be tested against the null hypothesis of being zero, yielding p-values that are valid under general distribution assumptions. Yet, statistical guarantees for permutation importance assessment do not hold in the presence of correlated variables, leading to selection of unimportant variables (Molnar et al., 2021; Hooker et al., 2021; Nicodemus et al., 2010; Stigler, 2005). For instance, the method proposed in (Mi et al., 2021) is a powerful variable importance evaluation scheme, but it does not control the rate of type-I error.

In this work, we propose a general methodology for studying the properties of Conditional Permutation Importance in biomedical applications alongside tools for benchmarking variable importance estimators:

* Building on the previous literature on CPI, we develop theoretical results for the limitations regarding Permutation Importance (PI) and advantages of conditional Permutation Importance (CPI) given correlated inputs (section 3).
* We propose a novel implementation for CPI allowing us to combine the potential advantages of highly expressive base learners for prediction (a deep neural network) and a comparably lean Random Forest model as a conditional probability learner (section 4).
* We conduct extensive benchmarks on synthetic and heterogeneous multimodal real-world biomedical data tapping into different correlation levels and data-generating scenarios for both classification and regression (section 5).
* We propose a reusable library for simulation experiments and real-world applications of our method on a public GitHub repo https://github.com/achamma723/Variable_Importance.

## 2 Related work

A popular approach to interpret black-box predictive models is based on _locally interpretable_, i.e. _instance-based_, models. _LIME_(Ribeiro et al., 2016) provides local interpretable model-agnostic explanations by locally approximating a given complex model with a linear model around the instance of interest. _SHAP_(Burzykowski, 2020) is a popular package that measures _local_ feature effects using the Shapley values from coalitional game theory.

However, global, i.e. population-level, explanations are better suited than instance-level explanations for epidemiological studies and scientific discovery in general. Many methods can be subsumed under the general category of removal-based approaches (Covert et al., 2022). _Permutation_ importance is defined as the decrease in a model score when the values of a single feature are randomly shuffled (Breiman, 2001). This procedure breaks the relationship between the feature and the outcome, thus the drop in model performance expresses the relevance of the feature. Janitza et al. (2018) use an ensemble of Random Forests with the sample space equally partitioned. They approximate the null distribution based on the observed importance scores to provide p-values. Yet, this coarse estimate of the null distribution can give unstable results. Recently, a generic approach has been proposed in (Williamson et al., 2021) that measures the loss difference between models that include or exclude a given variable, also applied with LOCO (Leave One Covariate Out) in the work by Lei et al. (2018). They show the asymptotic consistency of the model. However, their approach is intractable, given that it requires refitting the model for each variable. A simplified version has been proposed by Gao et al. (2022). However, relying on linear approximations, some statistical guarantees from (Williamson et al., 2021) are potentially lost.

Another recent paper by Mi et al. (2021) has introduced model-agnostic explanation for black-box models based on the _permutation_ approach. _Permutation_ importance (Breiman, 2001) can work with any learner. Moreover, it relies on a single model fit, hence it is an efficient procedure. Strobl et al. (2008) pointed out limitations with the _permutation_ approach in the face of correlated variables. As an alternative, they propose a _conditional permutation_ importance by shuffling the variable of interest conditionally on the other variables. However, the solution was specific to Random Forests, as it is based on bisecting the space with the cutpoints extracted during the building process of the forest.

With the _Conditional Randomization Test_ proposed by Candes et al. (2017), the association between the outcome \(y\) and the variable of interest \(x^{j}\) conditioned on \(^{-}\) is estimated. The variable of interest is sampled conditionally on the other covariates multiple times to compute a test statistic and p-values. However, this solution is limited to generalized linear models and is computationally expensive. Finally, a recent paper by Watson and Wright (2021) showed the necessity of conditional schemes and introduced a knockoff sampling scheme, whereby the variable of interest is replaced by its knockoff to monitor any drop in performance of the leaner used without refitting. This method is computationally inexpensive, and enjoys statistical guarantees from from (Lei et al., 2018). However, it depends on the quality of the knockoff sampling where even a relatively small distribution shift in knockoff generation can lead to large errors at inference time.

Other work has presented comparisons of select models within distinct communities (Liu et al., 2021; Chipman et al., 2010; Janitza et al., 2018; Mi et al., 2021; Altenmuller et al., 2021), however, lacking conceptualization from a unified perspective. In summary, previous work has established potential advantages of conditional permutation schemes for inference of variable importance. Yet, the lack of computationally scalable approaches has hampered systematic investigations of different permutation schemes and their comparison with alternative techniques across a broader range of predictive modeling settings.

## 3 Permutation importance and its limitations

### Preliminaries

NotationsWe will use the following system of notations. We denote matrices, vectors, scalar variables and sets by bold uppercase letters, bold lowercase letters, script lowercase letters, and calligraphic letters, respectively (e.g. \(\), \(\), \(x\), \(\)). We call \(\) the function that maps the sample space \(^{p}\) to the sample space \(\) and \(\) is an estimate of \(\). Permutation procedures will be represented by (_perm_). We denote by \([\![n]\!]\) the set \(\{1,,n\}\).

Let \(^{n p}\) be a design matrix where the i-th row and the j-th column are denoted \(}\) and \(}\) respectively. Let \(}=(},,},}, ,})\) be the design matrix, where the \(j^{th}\) column is removed, and \(}=(},,},\{}\}^{ perm},},,})\) the design matrix with the \(j^{th}\) column shuffled. The rows of \(}\) and \(}\) are denoted \(_{i}}\) and \(_{i}}\) respectively, for i \([\![n]\!]\).

Problem settingMachine learning inputs are a design matrix \(\) and a target \(^{n}\) or \(\{0,1\}^{n}\) depending on whether it is a regression or a classification problem. Throughout the paper, we rely on an i.i.d. sampling train / test partition scheme where the \(n\) samples are divided into \(n_{train}\) training and \(n_{test}\) test samples and consider that \(\) and \(\) are restricted to the test samples - the training samples were used to obtain \(\).

### The _permutation_ approach leads to false detections in the presence of correlations

A known problem with _permutation_ variable importance is that if features are correlated, their importance is typically over-estimated (Strobl et al., 2008), leading to a loss of type-I error control. However, this loss has not been precisely characterized yet, which we will work through for the linear case. We use the setting of (Mi et al., 2021), where the estimator \(\), computed with empirical risk minimization under the training set, is used to assess variable importance on a new set of data (test set). We consider a regression model with a least-square loss function for simplicity. The importance of variable \(}\) is computed as follows:

\[^{j}=}_{i=1}^{n_{test}}((y_{i}-( _{i}}))^{2}-(y_{i}-(}))^{2}).\] (1)Let \(_{i}=y_{i}-(})\) for \(i[n_{test}]\). Re-arranging terms yields

\[^{j}= }_{i=1}^{n_{test}}((})- (^{(j)}}))(2(})-(}) -(^{(j)}})+2_{i}).\] (2)

Mi et al. (2021) argued that these terms vanish when \(n_{test}\). But it is not the case as long as the training set is fixed. In order to get tractable computation, we assume that \(\) and \(\) are linear functions: \(()=\) and \(()=}\). Let us further consider that \(}\) is a null feature, i.e. \(w^{j}=0\). This yields \(=x^{j}w^{j}+}}= }}\). Denoting the standard dot product by \(.,.\), this leads to (Detailed proof of getting from Eq. 2 to Eq. 3 can be found in supplement section A)

\[^{j}=^{j}}{n_{test}}<}-\{ }\}^{perm},}(}-}^{-j})+>\] (3)

as \((\|}\|^{2}-\|\{}\}^{perm}\|^{2})=0\). Next, \(}(\{}\}^{perm},}(}- }^{-j})) 0\) and \(}}-\{}\}^{perm}, 0\) when \(n_{test}\) with speed \(}}\) from the Berry-Essen theorem, assuming that the first three moments of these quantities are bounded and that the test samples are i.i.d. Let us assume that the correlation within \(\) takes the following form: \(}=}+\), where \(^{p-1}\) and \(\) is a random vector independent of \(}\). By contrast, \(^{j}}{n_{test}}(},}(}- }^{-j}))\) has a non-zero limit \(2^{j}^{T}Cov(})(}-}^{-j})\), where \(Cov(})=_{n_{test}}}^{T} }}{n_{test}}\) (remember that both \(}\) and \(}^{-j}\) are fixed, because the training set is fixed). Thus, the permutation importance of a null but correlated variable does not vanish when \(n_{test}\), implying that this inference scheme will lead to false positives.

## 4 _Conditional sampling_-based feature importance

### Main result

We define the permutation of variable \(x^{j}\) conditional to \(}\), as a variable \(^{j}\) that retains the dependency of \(x^{j}\) with respect to the other variables in \(}\), but where the independent part is shuffled, \(^{(j)}}\) is the vector \(\) where \(x^{j}\) is replaced by \(^{j}\). We propose two constructions below (see Fig. E1). In the case of regression, this leads to the following importance estimator:

\[^{j}_{CPI}=}_{i=1}^{n_{test}}((y_{i}- (_{i}^{(j)}}))^{2}-(y_{i}-(}))^{2} ).\] (4)

As noted by Watson and Wright (2021), this inference is correct, as in traditional permutation tests, as long as one wishes to perform inference conditional to \(\). However, the following proposition states that this inference has much wider validity in the asymptotic regime.

**Proposition**.: _Assuming that the estimator \(\) is obtained from a class of functions \(\) with sufficient regularity, i.e. that it meets conditions (A1, A2, A3, A4, B1 and B2) defined in supplementary material, the importance score \(^{j}_{CPI}\) defined in (4) cancels when \(n_{train}\) and \(n_{test}\) under the null hypothesis, i.e. the \(j\)-th variable is not significant for the prediction. Moreover, the Wald statistic \(z^{j}=^{j}_{CPI})}{std(^{j}_{CPI})}\) obtained by dividing the mean of the importance score by its standard deviation asymptotically follows a standard normal distribution._

This implies that in the large sample limit, the p-value associated with \(z^{j}\) controls the type-I error rate for all optimal estimators in \(\).

The proof of the proposition is given in the supplement (section C). It consists in observing that the importance score defined in (4) is \(0\) for the class of learners discussed in (Williamson et al., 2021), namely those that meet a certain set of convergence guarantees and are invariant to arbitrary change of their \(j^{th}\) argument, conditional on the others. In the supplement, we also restate the precise technical conditions under which the importance score \(^{j}_{CPI}\) used is (asymptotically) valid, i.e. leads to a Wald-type statistic that behaves as a standard normal under the null hypothesis.

It is easy to see that for the setting in Sec. 3.2, all terms in Eq. 4 vanish with speed \(}}\).

### Practical estimation

Next, we present algorithms for computing conditional permutation importance. We propose two constructions for \(^{j}\), the conditionally permuted counterpart of \(x^{j}\). The first one is additive: on test samples, \(x^{j}\) is divided into the predictable and random parts \(^{j}=(x^{j}|^{-})+(x^{j}- (x^{j}|^{-}))^{perm}\), where the residuals of the regression of \(x^{j}\) on \(^{-}\) are shuffled to obtain \(^{j}\). In practice, the expectation is obtained by a universal but efficient estimator, such as a random forest trained on the test set.

The other possibility consists in using a random forest (RF) model to fit \(x^{j}\) from \(^{-}\) and then sample the prediction within leaves of the RF.

Random shuffling is applied B times. For instance, using the additive construction, a shuffling of the residuals \(}^{,}\) for a given \(b B\) allows to reconstruct the variable of interest as the sum of the predicted version and the shuffled residuals, that is

\[}^{,}=}^{}+ }^{,}.\] (5)

Let \(}^{,}=(^{},, ^{-},}^{,},^{+},,^{})^{n_{test} p}\) be the new design matrix including the reconstructed version of the variable of interest \(^{}\). Both \(}^{,}\) and the target vector \(\) are fed to the loss function in order to compute a loss score \(l_{i}^{j,b}\) defined by

\[l_{i}^{j,b}=\{y_{i}(_{i})}{S( _{i}^{b})})+(1-y_{i})(_{i})}{1-S( _{i}^{b})})\\ (y_{i}-_{i}^{b})^{2}-(y_{i}-_{i})^{2}.\] (6)

for binary and regression cases respectively where \(i n_{test}\), \(j p\), \(b B\), \(i\) indexes a test sample of the dataset, \(_{i}=(_{})\) and \(_{i}^{b}=(}_{}^{,})\) is the new fitted value following the reconstruction of the variable of interest with the \(b^{th}\) residual shuffled and \((x)=}\).

The variable importance scores are computed as the double average over the number of permutations \(B\) and the number of test samples \(n_{test}\) (line 15 of Alg. 1), while their standard deviations are computed as the square root of the average over the test samples of the quadratic deviation over the number of permutations (line 17). Note that, unlike Williamson et al. (2021), the variance estimator is non-vanishing, and thus can be used as a plugin. A \(z_{CPI}^{j}\) statistic is then computed by dividing the mean of the corresponding importance scores with the corresponding standard deviation (line 18). P-values are computed using the cumulative distribution function of the standard normal distribution (line 19). The conditional sampling and inference steps are summarized in Algorithm 1. This leads to the _CPI-DNN_ method when \(\) is a deep neural network, or _CPI-RF_ when \(\) is a random forest. Supplementary analysis reporting the computational advantage of _CPI-DNN_ over a remove-and-relearn alternative a.k.a. _LOCO-DNN_, can be found in supplement (section D), which justifies its _computational leanness_.

## 5 Experiments & Results

In all experiments, we refer to the original implementation of the different methods in order to maintain a fair comparison. Regarding _Permfit-DNN, CPI-DNN_ and _CPI-RF_ models specifically, our implementation involves a 2-fold internal validation (the training set of further split to get validation set for hyperparameter tuning). The scores from different splits are thus concatenated to compute the final variable importance. We focus on the _Permfit-DNN_ and _CPI-DNN_ importance estimators that use a deep neural network as learner \(\), using standard permutation and algorithm 1, respectively. All experiments are performed with \(100\) runs. The evaluation metrics are detailed in the supplement (section E).

### Experiment 1: Type-I error control and accuracy when increasing variable correlation

We compare the performance of _CPI-DNN_ with that of _Permfit-DNN_ by applying both methods across different correlation scenarios. The data \(\{_{i}\}_{i=1}^{n}\) follow a Gaussian distribution with a prescribed covariance structure \(\) i.e. \(_{i}(0,) i n\). We consider a block-designed covariance matrix \(\) of 10 blocks with an equal correlation coefficient \(\{0,0.2,0.5,0.8\}\) among the variables ofeach block. In this experiment, \(p=100\) and \(n=300\). The first variable of each of the first 5 blocks is chosen to predict the target \(y\) with the following model, where \((0,)\):

\[y_{i}=x_{i}^{1}+2(1+2(x_{i}^{11})^{2}+(x_{i}^{21}+1)^{2})+x_{i}^{31} x_{i}^{41}+_{i},\  i[\![n]\!]\]

The AUC score and type-I error are presented in Fig. 1. Power and computation time are reported in the supplement Fig. 1 - S1. Based on the AUC scores, _Permfit-DNN_ and _CPI-DNN_ showed virtually identical performance. However, _Permfit-DNN_ lost type-I error control when correlation in \(\) is increased, while _CPI-DNN_ always controlled the type-I error at the targeted rate.

### Experiment 2: Performance across different settings

In the second setup, we check if _CPI-DNN_ and _Permfit-DNN_ control the type-I error with an increasing total number of samples \(n\). The data are generated as previously, with a correlation \(=0.8\). We fix the number of variables \(p\) to \(50\) while the number of samples \(n\) increases from \(100\) to \(1000\) with a step size of \(100\). We use 5 different models to generate the outcome \(\) from \(\): _classification_, _Plain linear_, _Regression with ReLu_, _Interactions only_ and _Main effects with interactions_. Further details regarding each data-generating scenario can be found in supplement (section G).

Figure 1: **CPI-DNN vs Permfit-DNN: Performance at detecting important variables on simulated data with \(n=300\) and \(p=100\). (A): The type-I error quantifies to which extent the rate of low p-values (\(p<0.05\)) exceeds the nominal false positive rate. (B): The AUC score measures to which extent variables are ranked consistently with the ground truth. Dashed line: targeted type-I error rate. Solid line: chance level.**

The AUC score and type-I error of _Permfit-DNN_ and _CPI-DNN_ are shown as a function of sample size in Fig. 2. The accuracy of the two methods was similar across data-generating scenarios, with a slight reduction in the AUC scores of _Permfit-DNN_ as compared to _CPI-DNN_. Only _CPI-DNN_ controlled the rate of type-I error in the different scenarios at the specified level of \(0.05\). Thus, _CPI-DNN_ provided an accurate ranking of the variables according to their importance score while, at the same time, controlling for the type-I error in all scenarios.

### Experiment 3: Performance benchmark across methods

In the third setup, we include _Permfit-DNN_ and _CPI-DNN_ in a benchmark with other state-of-the-art methods for variable importance using the same setting as in Experiment 2, while fixing the total number of samples \(n\) to \(1000\). We consider the following methods:

* Marginal Effects: A univariate linear model is fit to explain the response from each of the variables separately. The importance scores are then obtained from the ensuing p-values.
* Conditional-RF (Strobl et al., 2008): A conditional variable importance approach based on a Random Forest model. This method provides p-values.
* d\({}_{0}\)CRT (Liu et al., 2021; Nguyen et al., 2022): The Conditional Randomization Test with distillation, using a sparse linear or logistic learner.
* Lazy VI (Gao et al., 2022).
* Permfit-DNN (Mi et al., 2021).
* LOCO (Lei et al., 2018): This method applies the remove-and-retrain approach.
* cpi-knockoff (Watson and Wright, 2021): Similar to CPI-RF, but permutation steps are replaced by a sampling step with a knockoff sampler.
* CPI-RF: This corresponds to the method in Alg. 1, where \(\) is a Random Forest.
* CPI-DNN: This corresponds to the method in Alg. 1, where \(\) is a DNN.

The extensive benchmarks on baselines and competing methods that provide p-values are presented in Fig. 3. For type-I error, \(d_{0}\)_CRT, CPI-RF, CPI-DNN, LOCO_ and _cpi-knockoff_ provided reliable control, whereas Marginal effects, _Permfit-DNN_, _Conditional-RF_ and _Lazy VI_ showed less consistent results across scenarios. For AUC, we observed that marginal effects performed poorly, as they do not use a proper predictive model. _LOCO_ and _cpi-knockoff_ behave similarly. \(d_{0}\)_CRT_ performed well when the data-generating model was linear and did not include interaction effects. _Conditional-RF_ and _CPI-RF_ showed reasonable performance across scenarios. Finally, _Permfit-DNN_ and _CPI-DNN_ outperformed all the other methods, closely followed by _Lazy VI_.

Additional benchmarks on popular methods that do not provide p-values, e.g. BART (Chipman et al., 2010) or local and instance-based methods such as Shapley values (Kumar et al., 2020), are reported in the supplement (section H). The performance of these methods in terms of power and computation

Figure 2: **Model comparisons across data-generating scenarios**: The **(A)** type-I error and **(B)** AUC scores of _Permfit-DNN_ and _CPI-DNN_ are plotted as function of sample size for five different settings. The number \(n\) of samples increased from \(100\) to \(1000\) with a step size of \(100\). The number of variables \(p\) was set to 50. Dashed line: targeted type-I error rate. Solid line: chance level.

time are reported in the supplement Figs. 3 - S2 & 3 - S3 respectively. Additional inspection of power showed that across data generating scenarios, _CPI-DNN_, _Permfit-DNN_ and _conditional-RF_ showed strong results. _Marginal_ and _d0CRT_ performed only well in scenarios without interaction effects. _CPI-RF_, _epi-knockoff_, _LOCO_ and _Lazy VI_ performed poorly. Finally, to put estimated variable importance in perspective with model capacity, we benchmarked prediction performance of the underlying learning algorithms in the supplement Fig. 3 - S4.

### Experiment 4: _Permfit-DNN_ vs _Cpi-Dnn_ on Real Dataset UKBB

Large-scale simulations comparing the performance of _CPI-DNN_ and _Permfit-DNN_ are conducted in supplement (section L). We conducted an empirical study of variable importance in a biomedical application using the non-conditional permutation approach Permfit-DNN (no statistical guarantees for correlated inputs) and the safer CPI-DNN approach. A recent real-world data analysis of the UK Biobank dataset reported successful machine learning analysis of individual characteristics. The UK Biobank project (UKBB) curates phenotypic and imaging data from a prospective cohort of volunteers drawn from the general population of the UK [Constantinescu et al., 2022]. The data is provided by the UKBB operating within the terms of an Ethics and Governance Framework. The work focused on age, cognitive function and mood from brain images and social variables and put the ensuing models in relation to individual life-style choices regarding sleep, exercise, alcohol and tobacco [Dadi et al., 2021].

A coarse analysis of variable importance was presented, in which entire blocks of features were removed. It suggested that variables measuring brain structure or brain activity were less important for explaining the predictions of cognitive or mood outcomes than socio-demographic characteristics. On the other hand, brain imaging phenotypes were highly predictive of the age of a person, in line with the brain-age literature [Cole and Franke, 2017]. In this benchmark, we explored variable-level importance rankings provided by the _CPI-DNN_ and _Permfit-DNN_ methods.

The real-world empirical benchmarks on predicting personal characteristics and life-style are summarized in Fig. 4. Results in panel **(A)** suggest that highest agreement for rankings between _CPI-DNN_ and _Permfit-DNN_ was achieved for social variables (bottom left, orange squares). At the same time, _CPI-DNN_ flagged more brain-related variables as relevant (bottom right, circles). We next computed counts and percentage and broke down results by variable domain (Fig. 4, **B**). Naturally, the total relevance for brain versus social variables varied by outcome. However, as a tendency, _CPI-DNN_ seemed more selective as it flagged fewer variables as important (blue) beyond those flagged as important by both methods (light blue). This was more pronounced for social variables where _CPI-DNN_

Figure 3: **Extended model comparisons**: _CPI-DNN_ and _Permfit-DNN_ were compared to baseline models (outer columns) and competing approaches across data-generating scenarios (inner columns). Prediction tasks were simulated with \(n\) = 1000 and \(p\) = 50. **(A)**: Type-I error. **(B)**: AUC scores. Dashed line: targeted type-I error rate. Solid line: chance level.

sometimes added no further variables. As expected by the impact of aging on brain structure and function, brain data was most important for age-prediction compared to other outcomes. Interestingly, most disagreements between the methods occurred in this setting as _CPI_ rejected 16 out of 66 brain inputs that were found as important by _Permfit_. This outlines the importance of correlations between brain variables, that lead to spurious importance findings with _Permfit_. We further explored the utility of our approach for age-prediction from neuromagnetic recordings (Engemann et al., 2020) and observed that _CPI-DNN_ readily selected relevant frequency bands without fine-tuning the approach (section M in the supplement).

## 6 Discussion

In this work, we have developed a framework for studying the behavior of marginal and conditional permutation methods and proposed the _CPI-DNN_ method, that was inspired by the limitations of the _Permfit-DNN_ approach. Both methods build on top of an expressive DNN learner, and both methods turned out superior to competing methods at detecting relevant variables, leading to high AUC scores across various simulated scenarios. However, our theoretical results predicted that _Permfit-DNN_ would not control type-I error with correlated data, which was precisely what our simulation-based analyzes confirmed for different data-generating scenarios (Fig. 1 - 2). Other popular methods (Fig. 3) showed similar failures of type-I error control across scenarios or only worked well in a subset of tasks. Instead, _CPI-DNN_ achieved control of type-I errors by upgrading the _permutation_ to _conditional permutation_. The consequences were pronounced for correlated predictive features arising from generative models with product terms, which was visible even with a small fraction of data points for model training. Among alternatives, the _Lazy VI_ approach (Gao et al., 2022) obtained an accuracy almost as good as _Permfit-DNN_ and _CPI-DNN_ but with an unreliable type-I error control.

Taken together, our results suggest that _CPI-DNN_ may be a practical default choice for variable importance estimation in predictive modeling. A practical validation of the standard normal distribution assumption for the non important variables can be found in supplement (section N). The _CPI_ approach is generic and can be implemented for any combination of learning algorithms as a base learner or conditional means estimator. _CPI-DNN_ has a linear and quadratic complexity in the number of samples and variables, respectively. This is of concern when modeling the conditional distribution of the variable of interest which lends itself to high computational complexity. In our work, Random Forests proceed to be useful default estimators as they are computationally lean and their model complexity, given reasonable default choices implemented in standard software, can be well controlled by tuning the tree depth. In fact, our supplementary analyses (section O) suggest that proper hyperparameter tuning was sufficient to obtain good calibration of p-values. As a potential limitation, it is noteworthy the current configuration of our approach uses a deep neural network as

Figure 4: **Real-world empirical benchmark**: Prediction of personal characteristics (age, cognition, mood) and life-style habits (alcohol consumption, sleep, exercise & smoking) from various sociodemographic and brain-imaging derived phenotypes in a sample of \(n=8357\) volunteers from the UK Biobank. **(A)** plots variable rankings for _Permfit-DNN_ (x axis) versus _CPI-DNN_ (y axis) across all outcomes. Color: variable domain (brain versus social). Shape: variables classified by both methods as important (squares), unimportant (crosses) or by only one of the methods, _i.e._, _CPI-DNN_ (circles) or _Permfit-DNN_ (triangles). **(B)** presents a detailed breakdown of percentage and counts of variable classification split by variable domain.

the base learner. Therefore, in general, more samples might be needed for good model performance, hence, improved model interpretation.

Our real-world data analysis demonstrated that _CPI-DNN_ is readily applicable, providing similar variable rankings as _Permfit-DNN_. The differences observed are hard to judge as the ground truth is not known in this setting. Moreover, accurate variable selection is important to obtain unbiased interpretations which are relevant for data-rich domains like econometrics, epidemiology, medicine, genetics or neuroscience. In that context, it is interesting that recent work raised doubts about the signal complexity in the UK biobank dataset (Schulz et al., 2020), which could mean that underlying predictive patterns are spread out over correlated variables. In the subset of the UK biobank that we analysed, most variables actually had low correlation values (Fig. E4), which would explain why _CPI-DNN_ and _Permfit-DNN_ showed similar results. Nevertheless, our empirical results seem compatible with our theoretical results as _CPI-DNN_ flagged fewer variables as important, pointing at stricter control of type-I errors, which is a welcome property for biomarker discovery.

When considering two highly correlated variables \(}\) and \(}\), the corresponding conditional importance of both variables is 0. This problem is linked to the very definition of conditional importance, and not to the _CPI_ procedure itself. The only workaround is to eliminate, prior to importance analysis, degenerate cases where conditional importance cannot be defined. Therefore, possible future directions include inference on groups of variables, e.g, gene pathways, brain regions, while preserving statistical control offered by _CPI-DNN_.

AcknowledgementThis work has been supported by Bertrand Thirion and is supported by the KARAIB AI chair (ANR-20-CHIA-0025-01), and the H2020 Research Infrastructures Grant EBRAIN-Health 101058516. D.E. is a full-time employee of F. Hoffmann-La Roche Ltd.