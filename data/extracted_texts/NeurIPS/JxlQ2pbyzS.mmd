# Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling

Weibo Gao1 Qi Liu1,2* Linan Yue1 Fangzhou Yao1 Hao Wang1

Yin Gu1 Zheng Zhang1

1 State Key Laboratory of Cognitive Intelligence, University of Science and Technology of China

2 Institute of Artificial Intelligence, Hefei Comprehensive National Science Center

weibogao@mail.ustc.edu.cn; qiliuql@ustc.edu.cn; {lnyue, fangzhouyao}@mail.ustc.edu.cn; wanghao3@ustc.edu.cn; {gy128, zhangzheng}@mail.ustc.edu.cn

###### Abstract

Learners sharing similar implicit cognitive states often display comparable observable problem-solving performances. Leveraging collaborative connections among such similar learners proves valuable in comprehending human learning. Motivated by the success of collaborative modeling in various domains, such as recommender systems, we aim to investigate how collaborative signals among learners contribute to the diagnosis of human cognitive states (i.e., knowledge proficiency) in the context of intelligent education. The primary challenges lie in identifying implicit collaborative connections and disentangling the entangled cognitive factors of learners for improved explainability and controllability in learner Cognitive Diagnosis (CD). However, there has been no work on CD capable of simultaneously modeling collaborative and disentangled cognitive states. To address this gap, we present Coral, a Collaborative cognitive diagnosis model with disentangled representation learning. Specifically, Coral first introduces a disentangled state encoder to achieve the initial disentanglement of learners' states. Subsequently, a meticulously designed collaborative representation learning procedure captures collaborative signals. It dynamically constructs a collaborative graph of learners by iteratively searching for optimal neighbors in a context-aware manner. Using the constructed graph, collaborative information is extracted through node representation learning. Finally, a decoding process aligns the initial cognitive states and collaborative states, achieving co-disentanglement with practice performance reconstructions. Extensive experiments demonstrate the superior performance of Coral, showcasing significant improvements over state-of-the-art methods across several real-world datasets. Our code is available at https://github.com/bigdata-ustc/Coral.

## 1 Introduction

It is a common notion that individuals with similar implicit states frequently exhibit similar explicit behaviors. Therefore, establishing interconnections among similar users is crucial for understanding human behaviors. For instance, social connections play a pivotal role in understanding current consumer preferences and predicting future behaviors . Similarly, in the

Figure 1: An example of human learning, where learners individually select questions to practice. Each question tests at least one knowledge concept.

context of intelligent education, a better modeling of like-minded learners with similar learning experiences, is essential for understanding the human learning process , analyzing their knowledge proficiency and facilitating personalized tutoring tailored to individual needs .

As illustrated in Figure 1, we can infer Nancy is likely to answer the _Cone_-related question \(q_{5}\) correctly according to the correct practice responses of Bob and Alice, who share similar learning behaviors with Nancy. The underlying psychological assumption is that learners with similar experiences generally possess similar cognitive states -- how well the learner masters each knowledge concept, influencing their subsequent responses. To gain a deeper understanding of the human learning process, it is crucial to explicitly diagnose unobservable cognitive states. Existing Cognitive Diagnosis (CD) methods seek to enhance diagnostic accuracy by fully utilizing the inner-learner information (i.e., individual attributions  and explicit practice records) and question-side features (e.g., difficulty , textual content , and educational relations [12; 14]). However, the issue of how similar (a.k.a. collaborative) connections among inter-learners with similar states facilitate understanding of learners' knowledge proficiency remains largely unexplored.

In this study, to efficiently harness collaborative information among similar learners and thereby more accurately diagnose the cognitive states of each individual, we advocate for the incorporation of inter-learner connections into the CD process. However, designing a collaborative CD model in educational scenarios presents two distinct challenges due to the complexity of human learning.

* First, acquiring explicit collaborative connections among learners proves to be a formidable challenge. On the one hand, unlike many well-defined social scenarios (e.g., _Twitter.com_), where user preference similarities are manifested through explicit social actions such as following and liking, the directly available social behaviors among learners in learning environments (e.g., _LeetCode.com_) cannot be used for diagnosis modeling since these social attributes cannot reflect true cognitive-oriented connections. On the other hand, some related studies [28; 13] attempt to design different similarity functions based on practice data to compute cognitive similarities among learners. However, these approaches pose a significant challenge of manually selecting appropriate metrics and corresponding thresholds, introducing additional inductive biases. Although various methods for constructing user relationships have been proposed in other domains [22; 9], these approaches do not consider the domain-specific attributes of students in learning scenarios and cannot be directly applied in educational contexts.
* Second, an ideal collaborative diagnosis procedure requires disentangling and uncovering the mixed explanatory latent factors hidden in the observed learning behaviors. The basic motivation is that learners demonstrate complex and diverse patterns driven by entangled states across both inner- and inter-learner perspectives. For instance, from an inner perspective, Nancy may not master _Cone_ since she does not practice _Cone_-related questions. However, based on inter-learner data, one can infer a high probability that she has mastered _Cone_. Most prior attempts can not fulfill this requirement since they learn representations in an entangled way. Although recent models [8; 50] achieve a dimension-level disentanglement of cognitive states, they lack consideration of modeling the influence of collaborative connections, ignoring the complex relations between inner- and inter-learner connections of different individuals. Thereby, it needs to find a suitable way to achieve the co-disentanglement from both the inner- and inter-learner views for cognitive representations with higher interpretability and controllability.

To tackle the above challenges, we propose Coral, a Collaborative cognitive diagnosis model with disentangled representation learning, to reveal learner cognitive states while simultaneously modeling both inner- and inter-learner learning information. Specifically, our approach begins with the disentangled cognitive representation encoding to establish initial disentangled learner states through reconstructing their practice performance from the inner-learner perspective. Next, our focus shifts to effectively learning collaborative cognitive representations from the inter-learner perspective. The most significant point is to find the implicit collaborative relations between learners. To address this challenge, we present a context-aware collaborative graph learning mechanism that automatically explores all \(K\)-optimal neighbors for each learner given their basic cognitive states to facilitate the explicit modeling of collaborative connections among learners. Based on the constructed graph, collaborative information can be effectively fused into disentangled learner cognitive states through learning collaborative node representations. Finally, a decoding and reconstruction process is conducted to merge initial states and collaborative states so as to achieve co-disentanglement from both the inner- and inter-learner perspectives. Extensive experiments demonstrate the superior performance of Coral, showing significant improvements over SOTA methods across several datasets.

Related Work

**Cognitive Diagnosis** As a fundamental task, cognitive diagnosis (CD) has been well-researched for decades in educational psychology [25; 4; 53]. It aims to profile the implicit cognitive states (i.e., the proficiency of specific knowledge concepts) of learners by exploiting observed practice records (e.g., correct or wrong). Existing research on CD assumes that learners' knowledge proficiency is proportional to their practice performance and thus can be diagnosed through predicting their practice performance . Since the diagnostic results can be applied to many intelligent applications, such as exercise recommendation  and learning path suggestions , many CD models have been proposed in recent years. The early works from psychology like IRT  and MIRT  focus on modeling learners' answering process by predicting the probability of a learner answering a question correctly, which utilizes latent factors as the learner's ability. These methods lack interpretability, i.e., they are inability to output explicit multidimensional diagnostic results on each knowledge concept. To achieve better interpretability, later diagnostic models focus on incorporating knowledge concepts of questions to diagnose learners' proficiency on all knowledge concepts [38; 45; 46; 32]. Representative NCDM  adopts neural networks to model non-linear interactions instead of handcrafted interaction functions in previous works (e.g., IRT, and MIRT). In summary, existing CD studies enhance diagnostic accuracy by fully utilizing the inner-learner information (i.e., individual attributions and explicit practice records) [41; 50]and question-side features (e.g., difficulty [16; 38], textual content , and educational relations [12; 14; 8]). However, to the best of our knowledge, the problem of collaborative diagnostic remains largely unexplored.

**Collaborative modeling in Education** Collaborative connections among learners in the education context commonly refer to learners with similar explicit practice behaviors, testing scores and implicit knowledge proficiency [28; 54; 44]. However, due to the complexity and implicitness of the human learning process, these relations are commonly not explicitly and directly available. Existing studies [28; 13] in AI Education have attempted to design different similarity functions based on practice data to compute cognitive similarities among learners. However, these methods pose a significant challenge of manually selecting appropriate metrics and corresponding thresholds, introducing additional inductive biases.

**Disentangled Representation Learning** Disentangled Representation Learning (DRL), which aims to produce robust, controllable, and explainable representations, has become one of the core problems in machine learning. Typical methods include variational method , weakly supervised models , as well as the recent combination with the diffusion model . DRL has a wide range of applications in user modeling to disentangle attributes. For example, recommendation with several aspects of users' interests [24; 33], fair user representation to disentangle sensitive attributes . In education, DCD  attempts to disentangle learners' cognitive representations via variational framework, which motivates us to conduct a further study on collaborative CD setups.

## 3 Coral

We first introduce the problem setup, followed by details on three core components of Coral: i) Disentangled Cognitive Representation Encoding, ii) Collaborative Representation Learning and iii) Decoding and Reconstruction. Figure 2 shows the framework. The algorithm is listed in Algorithm 1.

### Problem Setup

Our setup considers the human learning dataset \(D\) including the practice records between \(M\) learners and \(N\) questions. The practice records of each learner \(u\) is denoted by \(_{u}=\{x_{u,i}\}\), where \(x_{u,i}\) equals \(1\) or \(0\), representing that learner \(u\) answered question \(i\) correctly or not, respectively. Each question is related to at least one knowledge concept. The association relations between \(N\) questions and \(C\) knowledge concepts is represented by \(=\{_{i}\}_{i=1}^{N}\), where \(_{i}^{C}\) and \(c_{i,c}\) equals \(1\) or \(0\) denoting that question \(i\) is related to concept \(c\) or not. The practice records are regarded as the explicit inner-learning information in our context.

Besides, we consider the collaborative connections among learners with similar cognitive states, which provide the inter-learner information. We define collaborative connections as a graph structure \(G=(V,E)\) which contains a set of nodes (i.e., learners) \(V\) and a set of edges \(E\) where \((u,v) E\) or \((u,v) G\) indicates that the existence of a collaborative connection between learner \(u\) and \(v\) (i.e., \(u\) and \(v\) have similar latent cognitive states). Notably, the collaborative connections in educational scenarios are generally not explicitly or directly available, and it needs to design an adaptive strategy to automatically infer similar learners from observed learning data during the training process.

To achieve cognitive state disentanglement, we initially assign \(C\) factorized representations to each learner, i.e., \(_{u}=[_{u}^{(1)};_{u}^{(2)};;_{u}^{ (C)}]^{d C}\) with Gaussian Mixture initialization since the Gaussian distribution has long been recognized as a proper statistic model for the cognitive states of learners in educational psychology . The component \(_{u}^{(c)}\) is expected to capture the learner \(u\)'s cognitive state over knowledge concept \(c\). We denote \(\) as the set of trainable parameters for the proposed model. Based on the above setups, the goal of Coral is to learn co-disentangled representations \(}=\{}_{u}\}_{u=1}^{M}\) for the \(M\) learners from both the inner-learner practice perspective and inter-learner collaborative perspective.

### Disentangled Cognitive Representation Encoding

The practice response \(_{u}\) of each learner \(u\) provides valuable inner-learner insights regarding his/her proficiency since learners' performance on each question is assumed to be proportional to their cognitive proficiency on question-related knowledge concepts . Therefore, we implement an encoder for encoding the disentangled cognitive state \(_{u}\) of each learner \(u\) by reconstructing their practice responses. For a learner \(u\), we assume that his/her practice performance on candidate questions can be generated from the following distribution:

\[p_{}(_{u})=_{p()}[ p _{}(_{u}_{u},)p_{}( _{u})d_{u}],\] (1)

where \(p()=p_{D}()\) and \(p_{}(_{u}_{u},)\) is naturally a cognitive diagnosis procedure to predict practice performance. The key point of this task is to learn an optimal encoder \(p_{}(_{u})\) via practice records \(_{u}\) to encode the cognitive state \(_{u}\) of each learner \(u\). To optimize \(\), we introduce a variational distribution \(q_{}(_{u}_{u})\) to approximate \(p_{}(_{u})\), following the VAE literature , through maximizing a lower bound of \( p_{}(_{u})\) based on the following property.

**Property 1**.: \( p_{}(_{u})\) _is bounded as follows:_

\[ p_{}(_{u})_{p()q_{ }(_{u}_{u})}[ p_{}(_{u}_{u})]-_{p()}[D_{} (q_{}(_{u}_{u})\ \|\ p_{}(_{u}))].\] (2)

See the Appendix A for the proof.

In Property 1, the first term reconstructs the true practice performance \(_{u}\) of learner \(u\) and the variational encoder \(q_{}(_{u}_{u})\) in the second term approximates the true encoder \(p_{}(_{u})\) by minimizing the KL divergence \(D_{}\). The variational distribution \(q_{}(_{u}_{u})\) and the expectation \(_{q_{}(_{u}_{u})}\) are intractable, thus we employ the re-parameterization trick  for the model optimization.

Furthermore, the diagnosis procedure \(p_{}(_{u}_{u},)\) is achieved by estimating how well a learner \(u\) answers question \(i\) from both the perspectives of cognitive states and comprehensive abilities. From the perspective of cognitive states, solving question \(i\) requires learner \(u\) to master all knowledge concepts related to this question. Regarding comprehensive abilities, each learner possesses a latent state reflecting their overall learning ability, which is shared when addressing different questions.

Figure 2: The overall framework of Coral.

Formally, this process can be described as:

\[& p_{}(_{u}_{u}, )=_{x_{u,i}_{u}}p_{}(x_{u,i} _{u},),\\ & p_{}(x_{u,i}_{u},)= _{c=1}^{C}c_{i,c}_{}(_{u}_{u}^{(c )}-_{i}),_{u}=_{c=1}^{C}_{}(_{u}^{(c)}),\] (3)

where \(_{}()\) and \(_{}():^{d}^{+}\) are two shallow neural networks. \(_{}()\) estimates the comprehensive ability of the learner and \(_{}()\) predicts the performance of a learner with a given cognitive state \(_{u}^{(c)}\) and a comprehensive ability \(_{u}\) over question \(i\) in terms of concept \(c\). \(_{i}\) is a learnable latent representation for question \(i\). Besides, to ensure psychometric interpretability of prediction, we set the weights of \(_{}()\) are positive values, i.e., \(_{}()/_{u}>0\), assuming that the probability of correctly answering the question monotonically increases with learners' cognitive state. Please note that we found that the mean operation here can also be replaced with a neural network (i.e., \(_{}^{}:^{C}^{+}\)) with positive weights, formulated as \(_{}^{}(_{i}(_{u}_{u}^{(c)}-_{i}))\), as in , without affecting prediction performance. Particularly, in contrast to most methods that consider entangled cognitive factors as input, our diagnosis model can better capture learners' proficiency on each knowledge concept by disentangling cognitive states under each concept.

Furthermore, inspired by the outstanding performance of \(\)-TCVAE  in disentanglement, we prompt statistical independence among its dimensions to obtain a better trade-off between the reconstruction accuracy and the quality of disentangled representation through \(q(_{u}^{(c)})=_{j=1}^{d}q_{}(z_{u,j}^{(c)})\) where \(q_{}(_{u}^{(c)})\) is the aggregated posterior of \(_{u}\), i.e., \(q_{}(_{u}^{(c)})= q_{}(_{u}^{(c)} _{u})p(_{u})d_{u}\) where \(p(_{u})=p_{data}(_{u})\). This setup is encouraged by the term \(D_{}()\) in Eq. (2) based on Property 2.

**Property 2**.: _The \(D_{}()\) in Eq. (2) can be rewritten as:_

\[D_{}(q_{}(_{u}_{u})  p_{}(_{u}))=I(_{u}, _{u})+D_{}(q_{}(_{u}) p _{}(_{u})).\] (4)

See Appendix A for the proof. On one hand, \(I(_{u},_{u})\) maximizes the mutual information (MI) between \(_{u}\) and \(_{u}\) which obtains the useful information for the diagnosis task as much as possible according to the information bottleneck theory . On the other hand, given a Gaussian distribution \(p_{}(_{u}^{(c)})=_{j=1}^{d}p_{}(z_{u,j}^{(c)})\), the KL divergence term encourages independence among the dimensions of \(_{u}^{(c)}\) by preventing each latent variable from deviating too far from specified priors. Compared to prior VAE-based CD models [50; 8], Coral additionally considers ability parameters from psychology  to enhance the expressive power of disentangled cognitive states.

Overall, we penalize Eq. (2) by a Lagrange multiplier \(\) resulting in the following objective:

\[& p_{}(_{u}) _{p()q_{}(_{u}_{u})}[  p_{}(_{u}_{u})]- _{p()}[D_{}(q_{}( _{u}_{u}) p_{}(_{u} ))].\] (5)

### Collaborative Representation Learning

Collaborative information among similar learners provides an auxiliary inter-learner insight for cognitive representation learning. However, collaborative connections among learners with similar states are typically not readily accessible. To address this challenge, we design a context-aware graph construction strategy that searches similar neighbors automatically via the initial disentangled cognitive states. Based on the constructed collaborative graph, we can learn collaborative node representations by aggregating collaborative signals to generate collaborative cognitive states.

#### 3.3.1 Context-aware Collaborative Graph Learning

The core goal of constructing the collaborative graph is to find \(K\) optimal neighbors for each learner node in \(V\) via their initial disentangled cognitive state \(\{^{(c)}\}_{c=1}^{C}\). For different knowledge concepts, the cognitive connections between the same learner pair are typically different. Thereby, it needs to search \(C\) groups of similar neighbors for each learner via each disentangled component \(^{(c)}\). This means that we would generate \(C\) collaborative graphs, i.e., \(G=\{G_{(c)}\}_{c=1}^{C}\). Each collaborative graph \(G_{(c)}\) under concept \(c\) is expected to characterize the cognitive similarities of learners regarding concept \(c\). Formally, this task is defined as computing \(p_{}(G V,)\) by identifying all the \(K\) similar neighbors for each learner covering each concept \(c\). Let \(_{u}^{(c)}\) denote the set of \(K\) similar neighbors for the learner \(u\), the task can be described as:

\[ p_{}(G V,):=_{c=1}^{C}_{p_{}(_{u}^{(c)},_{u}^{(c)})}[  p_{}(_{u}^{(c)}_{u}^{(c)})]\] (6) \[=_{c=1}^{C}I(^{(c)};^{(c)} )+_{c=1}^{C}_{p_{}(^{(c)})} [ p_{}(^{(c)})]_{c=1}^{C }I(^{(c)};^{(c)}),\]

where \(^{(c)}\) and \(^{(c)}=\{_{u}^{(c)}\}_{u=1}^{M}\) are the neighbor set and feature set of all the learners regarding knowledge concept \(c\), respectively. The number of \(_{u}^{(c)}\) equals the combination of arbitrary \(K\) neighbors from all \(M\) learners for each learner node \(u\) under each concept \(c\), i.e., \(|_{u}^{(c)}|=\), thus Eq. (6) is computationally expensive especially for larger \(M\) and \(K\). To facilitate computation, we transform the Eq. (6) that requires global MI maximization to the task of maximizing MI locally via locally available context information inspired by  and derive a lower bound of it as the following Property 3.

**Property 3.**\( p_{}(G V,)\) _is bounded as follows:_

\[ p_{}(G V,)-_{c=1}^{C}_{u=1}^{M}_{ k=1}^{K}_{u}^{(c),k}_{u}^{(c),k}=-(b_{u}^{(c),k};r_{u}^{(c),k-1} ))}{_{v V_{u}^{(c)}}(f_{(c)}(v;r_{u}^{(c),k-1} ))}.\] (7)

See the Appendix A for the proof. The Eq. (7) iteratively searches \(K\) neighbors for the learner \(u\) under each knowledge concept \(c\) from step \(k=1\) to \(K\). \(_{u}^{(c),k}\) is the well-known InfoNCE loss function . Let \(r_{u}^{(c),k-1}\) denote the current context at step \((k-1)\) (i.e., the set of \((k-1)\) neighbors selected from step 1 to \((k-1)\)). \(b_{u}^{(c),k}\) is the affinity candidate learner in the \((M-k)\) nonneighbor learners. Let \(V_{u}^{(c)}\) denote the current set of nonneighbor learners, and we hence have \(b_{u}^{(c),k} V_{u}^{(c)}\). \(f_{(c)}(b_{u}^{(c),k};r_{u}^{(c),k-1})\) is a matching function measuring the similarity between of nonneighbor \(b_{u}^{(c),k}\) and the current context \(r_{u}^{(c),k-1}\), where the higher the scalar score means the higher likelihood of \(b_{u}^{(c),k}\) is a new neighbor.

Furthermore, we have \(_{u}^{(c),k} f_{(c)}(b_{u}^{(c),k};r_{u}^{(c),k-1})\). Thus, given the context of \((k-1)\) neighboring learners (i.e., we have found \((k-1)\) neighbors for the learner \(u\)) and matching function \(f_{(c)}()\), our **goal** following the Property 3 is to find a learner \(b_{u}^{(c),k}\) from nonneighbor set \(V_{u}^{(c)}\) that can maximize the matching score \(f_{(c)}()\) as the \(k\)-th neighbor of \(u\). In other words, \(p(G V,)\) can be optimized through maximizing the matching score \(f_{(c)}()\) from \(k=1\) to \(K\) iteratively. Thereby, at each step \(k\), we sort the scores of the nonneighbor learners and select the learner with the highest score to label as \(k\)-th neighbor \(b_{u}^{(c),k}\), i.e., \(b_{u}^{(c),k}_{v}f_{(c)}(v;r_{u}^{(c),k-1}),v V_{u}^{(c)}\). After obtaining the \(k\)-th neighbor \(b_{u}^{(c),k}\), the context \(r_{u}^{(c),k-1}\) is updated to \(r_{u}^{(c),k}\) by absorbing \(b_{u}^{(c),k}\).

The calculation of matching score \(f_{(c)}()\) usually relies on the node representations (i.e., learner cognitive states). However, the sub-optimal cognitive state learning during the initial training epochs probably results in the matching function exhibiting biases. To enhance the stability of model training, instead of directly aggregating node representations as the context \(r_{u}^{(c),k-1}\) as many graph learning works, we denote it using relative representations w.r.t. the learner \(u\). Without loss of generality, we first establish relative collaborative coordinate systems with learner node \(u\) as the origin, and process relationship measurements between node \(u\) and each of its neighbors \(v\) as \(_{u,v}^{(c)}=\|_{u}^{(c)}-_{v}^{(c)}\|_{2}\). Then the context-aware features can be generated by aggregating each node in the context \(r_{u}^{(c),k-1}\), i.e., \(_{u}^{(c),k-1}=_{v r_{u}^{(c),k-1}}_{u,v}^{(c)}\). Thereby, let \(v_{k}\) denote \(b_{u}^{(c),k}\) with feature \(_{v_{k}}^{(c)}\), we have \(f_{(c),v_{k}}=f_{(c)}(b_{u}^{(c),k};r_{u}^{(c),k-1})=_{v_{ k}}^{(c)}_{u}^{(c),k-1}\).

#### 3.3.2 Collaborative Graph Modeling

After iteratively searching \(K\) neighbors under each concept, we can obtain \(C\) collaborative graphs regarding each learner, i.e., \(\{G_{(c)}\}_{c=1}^{C}\). Then, we consider collaborative modeling as a node representation learning task within each collaborative graph \(G_{(c)}\). It relies on a nonlinear kernel function \(_{}()\) to aggregate neighboring information and update each disentangled cognitive state, i.e., \(_{u}^{(c)}=_{}(_{u}^{(c)},\{_{v}^{( c)}:(u,v) G_{(c)}\})\). Given the disentangled learner cognitive states generated by the variational posterior distribution \(q_{}(_{u}|_{u})\) from Property 1, \(_{}()\) is naturally expected to contain \(C\) channels to extract different concept features from similar learners, though projecting the representation \(_{u}\) into different subspaces, i.e., \(}_{u}^{(c)}=(_{(c)}^{}_{u}^{ (c)}+b_{(c)})/\|(_{(c)}^{}_{u}^{(c)}+b_{(c )})\|_{2}\), where \(_{(c)}^{d}\) and \(b_{(c)}^{d}\) are learnable parameters of channel \(c\) and \(()\) is a nonlinear activation function (e.g., Sigmoid), and \(\|\|_{2}\) is \(L_{2}\) normalization ensuring numerical stability. Then the collaborative learner representation modeling in terms of concept \(c\) can be described as:

\[_{u}^{(c)}=_{u}^{(c)}|}_{v_{ u}^{(c)}}s_{u,v}^{(c)}}_{v}^{(c)},\ s_{u,v}^{(c)}=}_{u}^{(c) }}_{v}^{(c)}}{_{j_{u}^{(c)}} }_{u}^{(c)}}_{j}^{(c)}}+}{_{k=1}^{K}f_{(c),v_{k}}},\] (8)

where \(s_{u,v}^{(c)}\) is the attention weight between \(u\) and \(v\), considering both the collaborative aggregation (the first term) commonly used in graph modeling works and the corresponding context-aware attention (the second term) calculated in the iterative graph construction process in Eq. (7). When \(K\) is set large in Eq. (7), there is a possibility of introducing non-collaborative noise. In such cases, \(s_{u,v}^{(c)}\) can assign lower values to non-collaborative neighbors to mitigate the negative impact of noise, allowing for the adaptive tuning of attention in graph modeling. During training, the channels will remain changing because different subsets of the neighborhood will be searched for dynamically aggregating neighbor information in different iterations.

With Gaussian Mixture initialization from the Disentangled Cognitive Representation Encoding (section 3.2), we derive the theorem on convergence as:

**Theorem 1.** The Collaborative Representation Learning (section 3.3) procedure is equivalent to an expectation-maximization (EM) algorithm  for the mixture model. In particular, it converges to a point estimate of \(\{_{u}^{(c)}\}_{c=1}^{C}\) that maximizes the marginal likelihood \(l(\{a_{v}^{(c)}:(u,v) G_{(c)}\}_{c=1}^{C};\{_{u}^ {(c)}\}_{c=1}^{C})\), where \(a_{u,v}^{(c)}\) equals \(1\) or \(0\) denoting whether learner \(v\) is a collaborative neighbor of learner \(u\) regarding concept \(c\) or not. See the Appendix A for the proof.

### Decoding and Reconstruction

Given the initial disentangled encoding via inner-learner information (section 3.2) and the collaborative representation learning via inter-learner information (section 3.3), this part encourages an alignment between the initial encode \(_{u}\) and collaborative state \(_{u}\), formulating a co-disentangled representation as \(}_{u}=_{u}+_{u}\). This operation is inspired by the residual block  to address the second challenge, where \(_{u}\) can be treated as a disentangled auxiliary information of \(_{u}\) from collaborative graphs.

The decoding process predicts the practice performance of each learner \(u\) on candidate questions, given her co-disentangled representation \(}_{u}=[}_{u}^{(1)},}_{ u}^{(2)},,}_{u}^{(C)}]\), i.e., \(p_{}(}_{u})=_{p_{}( )}[p_{}(}_{u}}_{u},)]\), similar to the reconstruction procedure in Eq. (1). Thus, putting Eq. (5) and Eq. (7) together, we have the overall training objective:

\[ =_{u=1}^{M}_{x_{u,i}_{u}}  BCE(x_{u,i},p_{}(x_{u,i}_{u}, ))- D_{}^{u}\] (9) \[+_{x_{u,i}_{u}}BCE(x_{u,i},p_{}( _{u,i})),\] s.t. \[_{c=1}^{C}_{k=1}^{K}_{u}^{(c),k},\]where \(BCE(,)\) is the binary cross entropy loss function between ground-truth practice behaviors \(_{u}\) and the reconstructed ones. \(\) and \(\) are hyper-parameters.

By optimizing with minimizing the above loss function Eq. (9), the cognitive state \(}_{u}\) of each learner \(u\) can be jointly refined serving as the diagnostic results. During the testing phase, we evaluate the model performance by matching the difference between the predicted score \(p_{}(_{u,i})\) and the true score \(_{u}\). Specifically, when a proficiency value is required instead of the vector \(}_{u}^{(c)}\), we can obtain it by averaging each dimension of \(}_{u}^{(c)}\).

## 4 Experiments

We empirically evaluate the performances of the proposed Coral model over three real-world datasets and conduct several experiments to prove its effectiveness.

### Experimental Setup

**Datasets** We conduct experiments on three real-world datasets: ASSIST , Junyi  and NeurIPS2020EC . The statistics of datasets are listed in Table 1. The details about datasets and preprocessing are depicted in the Appendix C.

**Baselines** The baselines include the matrix factorization-based model, i.e., PMF , the typical latent factor models derived from educational psychology, including IRT , MIRT , and the neural networks-based models, including NCDM , RCD , KaNCD  and DCD .

**Evaluation** Since cognitive states cannot be directly observed in practice, it is common to indirectly evaluate CDMs through the student performance prediction task on test datasets . To evaluate prediction performance, we adopt ACC and AUC and F1-score as metrics from the perspective of classification, using a threshold of 0.5, and RMSE as metrics from the perspective of regression, following previous work [12; 23].

**Settings** We set the dimension size \(d\) as \(20\), the layer of graph modeling as \(2\), and the mini-batch size as \(512\). In the training stage, we select the learning rate from \(\{0.002,0.005,0.01,0.02,0.05\}\), select \(\) from \(\{0.05,0.1,0.5,1\}\) and \(\) from \(\{0.25,0.5,1\}\), and select neighboring number \(K\) from \(\{1,2,3,4,5,10,15,20,15,30,25,40,45,50\}\). All network parameters are initialized with Xavier initialization . Each model is implemented by PyTorch  and optimized by Adam optimizer . Specially, for the implementation of baselines, we set the dimensional sizes of each representation in PMF, NCDM, KaNCD, RCD and DCD as the number of knowledge concepts. All experiments are conducted on a Linux server equipped with two 3.00GHz Intel Xeon Gold 5317 CPUs and two Tesla A100 40G GPUs.

### Experimental Results

**Prediction Comparison** We evaluate prediction performance of Coral against baselines under three setups: normal, sparse, and cold-start scenarios.

Table 2 reports the performance comparison under normal settings for all the models across three datasets on four evaluation metrics. In this setting, we split all the datasets with a 7:1:2 ratio into training sets, validation sets, and test sets. The proposed Coral model significantly outperforms most baselines. This demonstrates two key benefits of Coral. First, the iterative graph construction process effectively generates collaborative connections for modeling. Second, the co-disentangled representation learning successfully discovers disentangled cognitive states for each learner.

We extend our analysis to assess the performance of Coral in sparse scenarios. In order to simulate varied sparse environments, we systematically discard 80%, 60%, 40%, and 20% of the training data from the ASSIST dataset under the normal settings described above. The experimental results

   Datasets & ASSIST & Junyi & NeurIPS2020EC \\  \#students & 1,256 & 1,400 & 1,000 \\ \#questions & 16,818 & 674 & 919 \\ \#knowledge concepts & 120 & 40 & 30 \\ \#concepts per exercise & 1.21 & 1 & 4.02 \\ \#records & 199,790 & 70,797 & 331,187 \\ \#records per student & 159,07 & 50.67 & 331.19 \\ \#correct records / \#incorrect records & 67.08\% & 77.20\% & 53.87\% \\   

Table 1: The statistics of three datasets.

shown in Figure 3 (a) reveal that Coral consistently outperforms baselines across a range of sparse environments. Moreover, our model exhibits robust performance consistently, demonstrating its adaptability and effectiveness in diverse sparse scenarios.

Moreover, we conduct an analysis of Coral's performance in a cold-start environment. To replicate this scenario, we retain solely the cold-start response data for each learner in the test set of Junyi, corresponding to the knowledge concepts they had not previously practiced in the training set. The Figure 3 (b) illustrates the experimental results, highlighting the exceptional performance of the Coral model (with \(K=10\)) in a cold-start scenario.

**Collaborate Graph Learning** We investigate the influence of the generated neighbor number \(K\) on diagnostic performance. Figure 3 (c) displays the prediction performances for various values of \(K\) on Junyi under the normal scenario. The model performance exhibits improvement as \(K\) increases, particularly noticeable when \(K\) is small. This observation suggests that the inter-learner information automatically retrieved by Coral contributes positively to the model. However, once \(K\) surpasses a threshold, the performance gain becomes less pronounced. This diminishing effect arises because users beyond the threshold (i.e., \(K=10\) in this dataset) may lack significant collaborative relationships, thus limiting the useful clues they can offer. We observe that when \(K\) exceeds the threshold, the model's performance remains acceptable, and even the performance improves after \(K\) exceeds \(30\). This indicates that Coral effectively perceives the similarity functions of the scenario and collaborative context. Consequently, it assigns lower similarity scores to non-collaborative neighbors, robustly adjusting the attention weight in graph modeling.

To obtain a more intuitive insight into the iterative graph construction process, we randomly select two learners (called target learners) from the Junyi dataset (with the normal setup) and visualize their neighbor selection process. Initially, we utilize t-SNE  to present the aggregated cognitive vector of each learner \(u\), which can be obtained by aggregating each disentangled cognitive component learned by Coral (setting \(K=30\)), i.e., \(_{c=1}^{C}}_{u}^{(c)}\). The embedding of the target learner is highlighted in red, while the nodes representing neighboring learners are color-coded based on the selection steps, with unselected points displayed in gray. The outcomes are illustrated in Figure 4 (a), showcasing how Coral organizes neighbors according to cognitive states and exemplifying a compelling strategy for neighbor selection that takes into account cognitive similarity.

**Disentanglement** We evaluate the disentanglement level achieved by assessing independence of dimensions within \(_{u}\). The independence level \(IL(u)\) of each \(_{u}\) is quantified as \(IL(u)=_{c=1}^{C}_{1 i,j d}|z_{u}^{(c )}[i]-z_{u}^{(c)}[j]|\), where \(z_{u}^{(c)}[i]\) represents the \(i^{th}\) dimension of \(_{u}^{(c)}\), following a prior methodology . In Figure 3 (d), we depict \(IL=_{u=1}^{M}IL(u)\) and the corresponding model performances at different training epochs on ASSIST (with the normal setup). Notably, Coral (setting \(K=10\)) gradually achieves a high degree of disentanglement during the training process, and the model performances generally exhibit a positive correlation with the degree of disentanglement. This observation reveals the effectiveness of the disentanglement process.

Additionally, we visualize the disentangled cognitive component representations (i.e., \(}_{u}^{(c)}\)) of each learner \(u\) learned by Coral. We treat each knowledge component in the representation as independent points, with each component colored differently. For visual clarity, we randomly select 200 learners and 5 knowledge concept components for display. The results in Figure 4 (b) uses t-SNE to visualize

    &  &  \\   & & ACC \(\) & AUC \(\) & F1-score \(\) & RMSE \(\) \\   & IRT & 69.36 & 69.81 & 78.14 & 45.61 \\  & MIRT & 71.26 & 72.59 & 79.80 & 44.50 \\  & PMF & 71.34 & 72.27 & 80.68 & 48.67 \\  & NCDM & 72.27 & 74.27 & 79.97 & 48.67 \\  & KaNCD & **72.43** & **75.38** & 80.22 & 48.67 \\  & RCD & 72.04 & 73.14 & 80.60 & 43.74 \\  & DCD & 70.33 & 73.98 & 79.09 & 43.94 \\  & Coral & 71.53 & 74.72 & **81.16** & **43.66** \\   & IRT & 79.26 & 76.46 & 87.54 & 38.38 \\  & MIRT & 77.74 & 74.46 & 86.05 & 40.29 \\  & PMF & 79.65 & 77.17 & 88.18 & 44.10 \\  & NCDM & 79.91 & 78.91 & 87.73 & 38.35 \\  & KaNCD & **81.79** & 80.93 & 89.02 & 36.11 \\  & RCD & 81.02 & 80.22 & 88.00 & 37.23 \\  & DCD & 79.29 & 79.55 & 87.62 & 37.83 \\  & Coral & 81.15 & **80.94** & **89.12** & **36.08** \\   & IRT & 70.11 & 75.60 & 71.59 & 44.68 \\  & MIRT & 69.65 & 75.52 & 71.24 & 45.51 \\   & PMF & 69.85 & 75.39 & 72.62 & 48.33 \\   & NCDM & 71.66 & 78.57 & 71.36 & 43.21 \\   & KaNCD & 71.28 & 77.60 & 72.50 & 43.71 \\   & RCD & 70.43 & 77.25 & 72.64 & 44.01 \\   & DCD & 71.53 & 75.63 & 71.13 & 45.60 \\   & Coral & **71.72** & **78.88** & **72.82** & **43.20** \\   

Table 2: Performance comparison. The best performance is highlighted in **bold**. \(\) (\(\)) means the higher (lower) score the better (worse) performance, the same as below.

learners' cognitive states, with each color representing a distinct category of knowledge-related learner states. This illustrates Coral's ability to achieve well-separated representations.

**Explainability** We further investigate the interpretability of the cognitive diagnosis outputs based on Coral. We aim to explore whether Coral can provide reasonable predictions for knowledge concepts that learners have not practiced in the training set during actual inference. Firstly, we randomly select a target student \(u\) from the Junyi dataset and identify 5 knowledge concepts (denoted as \(A E\)) that \(u\) has not learned in the training data. Subsequently, based on the refined model, we retrieve the top 4 most similar neighboring learners (i.e., \(u_{1} u_{4}\)) to the target student \(u\). Figure 5 depicts the assessed knowledge concepts (\(A E\)) and the corresponding mastery levels of selected neighbors using a radar chart. Table 3 presents the diagnostic outputs for the proficiency of \(u\), along with 5 questions related to knowledge \(A E\), the predicted scores answering correctly and the actual performances of \(u\). We observe that, despite the cold-start nature of these knowledge concepts for Coral, the model effectively outputs cognitive states that align with the true performance of \(u\) by considering the mastery levels of collaborative learners with similar cognitive states. This sufficiently demonstrates the interpretability of Coral's diagnostic results.

## 5 Conclusion

We are pioneering the exploration of collaborative cognitive diagnosis by disentangling the implicit cognitive representations of learners. Extensive experiments demonstrate the superior performance of Coral, showcasing significant improvements over SOTA methods across several real-world datasets. We believe this endeavor marks a crucial step towards collaborative modeling for "AI Education". Furthermore, this work offers valuable insights into conscious-aware learner modeling, under the assumption that human learner proficiency can be effectively represented in a disentangled manner.