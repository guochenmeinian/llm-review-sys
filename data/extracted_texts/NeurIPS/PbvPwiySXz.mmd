# Disentangling Linear Mode Connectivity

Gul Sena Altintas

Gregor Bachmann   Lorenzo Noci   Thomas Hofmann

ETH Zurich

{galtintas, gregorb, lnoci}@ethz.ch

###### Abstract

Linear mode-connectivity (LMC) (or lack thereof) is one of the intriguing characteristics of neural network loss landscapes. While empirically well established, it unfortunately still lacks a proper theoretical understanding. Even worse, although empirical data points are abound, a systematic study of when networks exhibit LMC is largely missing in the literature. In this work we aim to close this gap. We explore how LMC is affected by three factors: (1) architecture (sparsity, weight-sharing), (2) training strategy (optimization setup) as well as (3) the underlying dataset. We place particular emphasis on minimal but non-trivial settings, removing as much unnecessary complexity as possible. We believe that our insights can guide future theoretical works on uncovering the inner workings of LMC.

## 1 Introduction

In recent years, there has been a growing interest in understanding the geometry of loss landscapes, how modern stochastic first-order gradient-based algorithms navigate them and the relationship between different optima. There is a large body of work on the mode-connectivity (MC) ([9; 6; 2]), _linear_ mode-connectivity (LMC) (), permutation invariance ([7; 1; 3; 15]) and a broader range of symmetries () of neural networks, showing that loss landscapes are not solely characterized by high non-convexity and isolated minima but can often contain flat connected regions. A more detailed account of these works are included in Appendix B.

Crucial to this work, LMC (and the lack of it) has been observed in disparate settings, however its root causes have not been epistemically investigated. For instance, when it comes to architectural components, it is well-known that convolution-based architectures lack LMC () compared to fully-connected models even after accounting for permutation invariance ([7; 1]). The varying factors that distinguish these two architectures (such as locality, weight-sharing, pooling layers, etc.) make it hard to pinpoint the source of disruption for LMC. Furthermore, these architectures are often trained under different optimization schemes and with different datasets, which are likely to be confounding factors.

In this paper, we systemically isolate some of the causes of LMC. We start from the simplest connected setting of logistic regression, i.e. linear model with no hidden layers, and gradually incorporate architectural changes, training techniques, and datasets typically used in modern deep learning pipelines. We identify the minimal non-linear setting, namely an MLP with one hidden layer and ReLU activation, where LMC can be robustly observed over different optimization schemes and datasets. We then analyze which components break LMC, in particular we study:

* The effect of the model architecture by introducing locality, weight-sharing, and sparsity to the hidden layer. This way, we recover locally connected, convolutional, and attention-based models that have a correspondence with the minimal model. Our experiments show that while locality preserves LMC, weight-sharing breaks it.
* Optimization algorithm and training strategy. We show that ADAM breaks connectivity more than SGD, while it can be recovered by modifying learning rate and adding warm-up.

* How dataset complexity affects LMC by training MLPs with increasing dataset complexity, namely MNIST, CiFAR-10, CiFAR-100 and TinyImageNet. We observe that LMC can be more easily broken under more complex datasets.

## 2 Background

We consider the classification problem for a general \(L\)-layer model with \(\) activation trained with the cross entropy loss, whose intermediate output at layer \(l<L\) is given by:

\[_{l} f_{l}(;_{l})=(W_{l}_{l -1}+_{l})\]

and the final output is \( W_{L}_{L-1}+_{L}\). When \(L=1\) we recover logistic regression, and if \(\) is the identity function we have an \(L\)-layer linear model. All models in the rest of the text are trained for 200 epochs and non-linear models reach \( 0\) training loss.

Linear Interpolation:For two networks \(A\) and \(B\) with parameters \(_{A}\) and \(_{B}\), their linear interpolation is defined with respect to the convex combination of the parameters at each layer, i.e. \(()\{(1-)W_{A_{i}}+ W_{B_{i}},(1-) _{A_{i}}+_{B_{i}}\}_{i:1 L}\).

Error Barrier:We are interested in how the error evolves along the linear path between two models \(A,B\), where \(_{B}_{A}\), during training. Do they stay linearly mode-connected even though they are trained separately, i.e. with different SGD noise (data orderings and augmentation). We base our measure of connectivity on 's definition of the error barrier (Equation 1).

\[=_{}(f(;()))-( (f(;_{A}))+(f(;_{B})))\] (1)

The error is quantified as the ratio of incorrect predictions, represented as \(()(1-()),\ ()\). While the current barrier definition offers an absolute measure, it doesn't differentiate the extent of performance loss, which is the primary focus of LMC research, across various levels of task complexity. Hence, we propose to use a normalized version that accounts for test accuracy when comparing the same architecture on different datasets.

\[=}{(_{te}(f(;_{A}) )+_{te}(f(;_{B})))}\] (2)

We follow the convention in the literature and evaluate \(()\) at \(T\) equidistant values of \(\) between 0 and 1. T is set to 11, i.e. the model is evaluated at \(\{0,0.1,,1\}\). We refer to a model as linearly mode-connected if two independent runs of SGD starting from the _same_ random initialization exhibit low barrier, \(<(0.02)\).

    &  &  \\  & High Lar (0.1) & Med & Lr (0.01) & High Lar (0.005) & Med & Lr (0.001) \\  & Test & Train & Test & Train & Test & Train & Test & Train \\ 
1-Layer, BS=30K & 0.05 & 0.01 & 0.00 & 0.00 & 0.03 & 0.00 & 0.01 & 0.01 \\
1-Layer, BS=1024 & 0.06 & 0.04 & 0.06 & 0.00 & 0.12 & 0.07 & 0.08 & 0.05 \\
2-Layer, BS=30K & 0.01 & 0.01 & 0.00 & 0.00 & 0.11 & 0.14 & 0.05 & 0.01 \\
2-Layer, BS=1024 & 0.01 & 0.14 & 0.05 & 0.09 & 1.30 & 1.45 & 0.18 & 0.16 \\
4-Layer, BS=1024 & 0.06 & 0.06 & 0.02 & 0.01 & 47.74 & 48.91 & 0.07 & 0.14 \\
8-Layer, BS=1024 & \(\) & \(\) & 0.06 & 0.00 & **68.22** & **68.87** & **73.78** & **74.32** \\   

Table 1: Summary of training and testing error barriers in percentage \((100)\) for an \(L\)-layer linear model across various optimization schemes (optimizer/learning rate/batch size(BS)). Each model reaches train cross entropy between 0.2 and 0.3 and above 90% test accuracy except for the high learning rate regime noted with \(\), where the training is unstable.

Finding a minimal model

Logistic regression:The simplest model is given by logistic regression, i.e. a linear model with no hidden layers. We are interested in studying LMC as the complexity of the underlying setting increases, thus logistic regression is an intuitive starting point. Since it is a convex problem, we expect it to satisfy LMC (even for _different_ initializations). We show the results in the first row of Table 1. We indeed confirm this empirically, as the model remains connected for all datasets, batch sizes and optimizers.

Linear networks:Next, we study how the dynamics change when more layers are added while keeping the network linear. We show the analogous results for several depths \(L\{2,4,8\}\) in Table 1. Surprisingly, we observe that for SGD with momentum, linear networks remain very connected even up to \(8\) layers. ADAM on the other hand quickly breaks connectivity even for \(L=2\). We attribute the difference to ADAM's adaptivity. This already hints at a re-occurring theme in this work; for all the considered settings, ADAM tends to amplify the resulting barriers.

Non-linear networks:We now consider the role of the non-linearity. Since ADAM already breaks connectivity even for the linear setting, we focus on SGD in order to avoid confounding. We gradually turn the network non-linear by taking Leaky-ReLU with various slopes ranging from \(1\) (linear) to \(0\) (ReLU). We display connectivity as a function of the slope in Figure 1 for MLPs of different depths. Non-linearity coupled with larger depth enlargens the barriers, even for SGD with momentum, highlighting that non-linearity has a detrimental effect on connectivity. The 1 hidden layer case however remains surprisingly robust in terms of connectivity.

Minimal model:Given its strong connectivity values and non-trivial nature, we will adopt the 1 hidden-layer ReLU MLP trained with SGD as our **minimal** model which still exhibits LMC. We will show in the following, how various interventions such as optimizer choice, architectural changes as well the dataset can affect LMC. This gives us a clean minimal setting to disentangle different effects.

## 4 Interventions to minimal model

Training Strategy:Table 1 already suggests that the optimization algorithm plays an important role in connectivity. We attempt to decouple its effect further over three dimensions: (1) Choice of the algorithm: SGD or ADAM (2), Learning Rate: High (0.005 for ADAM and 0.1 for SGD) denoted by \(\), and Medium (0.001 for ADAM and 0.01 for SGD), denoted by \(\) and (3) Warmup: either no warmup or linear warmup for 10 epochs, i.e. 5% of total training time. We display the resulting connectivity values when varying the minimal model along the outlined factors in Table 2. We again observe a very similar pattern; Switching to the ADAM optimizer results in a significantly less connected model. Using warm-up on the other hand leads to a significant reduction in barrier, suggesting that LMC is determined early in the training.

Architecture:We now explore the role of the layer-type in the \(1\)-hidden layer model. We are especially interested in how _locality_ and _weight-sharing_ affect LMC in this simple model. Let us denote the underlying weight matrix by \(W^{m d}\) where \(d\) is the input dimension and \(m\) the number of hidden units.

Figure 1: Barrier with respect to the negative slope \(p\) of the Leaky ReLU for \(p\{0,0.01,0.1,0.2, 0.9,0.99\}\). It is equivalent to ReLU for \(p=0\) and Identity for \(p=1\).

It is simple to show that a locally-connected CNN (exhibiting locality) and a CNN (exhibiting both locality and weight-sharing) can be obtained by imposing sparsity on \(W\) and tying its parameters correctly (see Appendix D for details). Using this correspondence between MLP, LC-CNN and CNN we can understand the effect of these structural choices in a controlled manner. For completeness, we also experiment with using a single attention layer. While in this case we do not have a direct correspondence, attention still offers both locality and weight-sharing. We show the effects of such architectural changes in Figure 2. We observe that the LC-CNN remains very connected but both the CNN and attention-based model experience a decay in connectivity. These results suggest that weight-sharing might play a more important role for connectivity than previously appreciated.

Role of dataset:So far, we focused on the MNIST dataset. We now investigate how increasing task complexity affects LMC for our minimal model. To account for the performance gap we use the normalized performance-aware barrier (Equation 2). We elaborate on the different task complexities in Appendix E. In Figure 3, we observe that task complexity hinders LMC when accounted for the overall performance. The more complex the dataset, the larger the barrier and the difference between the training and test barriers.

## 5 Discussion

In this work, we examined how each individual component, training strategy, architecture and dataset impact LMC of two networks that are trained from the same initialization with different SGD noise. We identified a minimal but non-trivial model amenable to theoretical analysis which show-cases precisely how several factors such as (1) optimization setup, (2) architectural design,and (3) dataset choice influence connectivity. We believe that our results can serve as a guide for theoretical progress in this topic, equipping the theorist with a model that is very simple but at the same time very rich in phenomenology. We thus hope that future work can build upon our empirical findings.

    & SGD \(\) Lor & SGD \(\) Lor W-up & ADAM \(\) Lor & ADAM \(\) Lor & ADAM \(\) Lor + W-up \\  \(\%_{}\) & 0.00 & 0.00 & 0.00 & 2.92 & 0.17 \\ \(\%_{}\) & 0.05 & 0.02 & 0.06 & 2.86 & 0.23 \\   

Table 2: Error barriers presented in percentage when changing the optimization setup for the minimal model, MLP with one hidden layer and ReLU activation.

Figure 3: Effect of dataset complexity on LMC on an \(L\)-layer MLP. Note that to account for the task complexity we compare LMC using the normalized performance-aware barrier (Equation 2).

Figure 2: Error barriers when varying the hidden layer. Note that previous SGD learning rates were too high for the ViT, hence we introduce the _Low-Lr_ of 0.001 where ViTs are also connected