# Truthfulness of Calibration Measures

Nika Haghtalab, Mingda Qiao, Kunhe Yang, and Eric Zhao

University of California, Berkeley

{nika,mingda.qiao,kunheyang,eric.zh}@berkeley.edu

###### Abstract

We study calibration measures in a sequential prediction setup. In addition to rewarding accurate predictions (completeness) and penalizing incorrect ones (soundness), an important desideratum of calibration measures is _truthfulness_, a minimal condition for the forecaster not to be incentivized to exploit the system. Formally, a calibration measure is truthful if the forecaster (approximately) minimizes the expected penalty by predicting the conditional expectation of the next outcome, given the prior distribution of outcomes. We conduct a taxonomy of existing calibration measures. Perhaps surprisingly, all of them are far from being truthful. We introduce a new calibration measure termed the _Subsampled Smooth Calibration Error (SSCE)_, which is complete and sound, and under which truthful prediction is optimal up to a constant multiplicative factor. In contrast, under existing calibration measures, there are simple distributions on which a polylogarithmic (or even zero) penalty is achievable, while truthful prediction leads to a polynomial penalty.

## 1 Introduction

Probability forecasting is a central prediction task to a wide range of domains and applications, such as finance, meteorology, and medicine . For forecasts to be useful, a common minimum requirement is that they are _calibrated_, i.e., the predictions are unbiased conditioned on the predicted value. Formally, for a sequence of \(T\) binary events, a forecaster who predicts probabilities in \(\) is _perfectly calibrated_ if for every \(\), among the time steps on which \(\) is predicted, an \(\) fraction of the outcomes is indeed \(1\). Since perfectly calibrated forecasts are often unachievable, _calibration measures_ have been introduced to quantify some form of deviation from perfectly calibrated forecasts. Common examples of these measures include the expected calibration error (ECE) , the smooth calibration error , and the distance from calibration .

As these calibration measures are commonly used to evaluate the performance of forecasters, it is important that their use encourages forecasters to incorporate the highest quality information available to them (e.g., via their expert knowledge or side information) about the next outcome. This desideratum, formally referred to as _truthfulness_, requires that a calibration measure incentivizes the forecasters to predict truthfully when the true distribution of the next outcome is known to them. Lack of truthfulness can have severe consequences: it serves as a poor measure of quality of forecasts, tempts forecasters to make deliberately biased predictions in order to game the system, and erodes trust in predictions provided by third-party forecasters. _Given the importance of truthfulness, we set out to identify calibration measures that demonstrate truthfulness._

While truthfulness of calibration measures has not been systematically investigated to date, evidence of the lack of truthfulness of some calibration measures has emerged in recent literature. For example,  noted that a forecaster can lower their ECE by predicting according to the past. This observation was applied in the algorithm of  and motivated the "sidestepping" technique in the lower bound proof of . More recently,  highlighted a large gap in the truthfulness of a recently proposed calibration measure (called the _distance from calibration_) byshowing that in a simple setup of predicting i.i.d. outcomes, the truthful forecaster incurs a distance of \(()\) from calibration but there is a forecasting algorithm that achieves \((T)\) distance from calibration. We call this a \((T)\)-\(()\)_truthfulness gap_. On the other hand, we say that a calibration measure is \((,)\)-truthful if predicting the next outcome according to its conditional distribution incurs a measure that is no more than \(+\), where \(\) is the minimum value of the calibration measure achievable by any forecaster. Faced with evidence that some calibration measures suffer from large truthfulness gaps, we will systematically examine the truthfulness (or a gap thereof) of a wide range of calibration measures.

For a truthful calibration measure to also be useful it must distinguish accurate predictions from inaccurate ones. After all, a measure that is uniformly \(0\) regardless of the quality of predictions is perfectly truthful (formally \((1,0)\)-truthful) but provides no insights into the quality of the predictions. We formalize the minimum requirement for a measure to be useful by its _completeness_ and _soundness_ when predicting i.i.d. Bernoulli outcomes. The former requires that predicting the outcomes according to the correct parameter of the generating Bernoulli distribution incurs no or \(o(T)\) penalty, whereas the latter requires the penalty to be \((T)\) when predictions systematically deviate from the correct parameter. An equally important feature of a calibration measure is that it defines an ideal that could be asymptotically achieved for all prediction tasks. This is formalized by the existence of forecasting algorithms with an \(o(T)\) penalty in the adversarial sequential prediction setting , where the sequence of outcomes is produced by an adaptive adversary.

With these desiderata in place (namely truthfulness, soundness, completeness, and asymptotic calibration), we ask _whether there are calibration measures that simultaneously satisfy all these criteria?_ We answer this question in three parts:

**Part I: We show that existing calibration measures do not simultaneously meet these criteria.** We conduct a taxonomy of several existing calibration measures in terms of their completeness, soundness and truthfulness (formally defined in Section 2). We show that almost all of them have large _truthfulness gaps_: There are simple distributions on which an \(O(1)\) (or even zero) penalty is achievable, while truthful predictions lead to a \((T)\) penalty; see Table 1 for details.

Indeed, this lack of truthfulness is not limited to specific or contrived distributions. In the next theorem which we will prove in Appendix B, we strengthen these findings by showing that a commonly used notion of calibration systematically suffers large truthfulness gaps in most forecasting instances.

**Theorem 1.1** (Informal).: _For every product distribution with marginals bounded away from \(0\) and \(1\), the truthful forecaster incurs \(()\) smooth calibration error but there exists a forecasting algorithm that incurs only \((T)\) smooth calibration error._

A notable exception in Table 1 is the class of calibration measures induced by _proper scoring rules_, i.e., loss functions for probabilistic predictions that are optimized by truthful forecasts. By definition, these calibration measures are \((1,0)\)-truthful. However, none of them is complete: as we show in Appendix A, even on i.i.d. Bernoulli trials, the optimal and truthful predictions incur an \((T)\) penalty.

**Part II: We introduce a new calibration measure, called SSCE, that is sound, complete, and approximately truthful.** We do this using a simple adjustment to an existing notion of calibration measure: we _subsample_ a subset of the time steps and evaluate the _smooth calibration error_ on this sampled set only. We call this the _Subsampled Smooth Calibration Error (SSCE)_ and formally define it in Section 2. Our main result is that SSCE is \((O(1),0)\)-truthful.

**Theorem 1.2** (Main Theorem).: _There exists a universal constant \(c>0\) such that the SSCE is \((c,0)\)-truthful. Furthermore, the SSCE is complete and sound._

As shown in Table 1, to the best of our knowledge, SSCE is the first calibration measure that simultaneously achieves completeness, soundness, and non-trivial truthfulness.

While our methodology for constructing this calibration measure is simple, the analytical steps required to establish the \((O(1),0)\)-truthfulness guarantee are far from simple. We dedicate most of the main body of this paper to illustrating the proof ideas in a series of warmups to Theorem 1.2.

**Part III: There is a forecasting algorithm that achieves \(O()\) SSCE even in the adversarial setting.** While our study of truthfulness of calibration measures is necessarily focused on when the forecaster knows the conditional distribution of the next outcome, it is important to ensure that, even in the adversarial setting, a sublinear penalty can be achieved for this calibration measure. For this, we study the sequential calibration setting (e.g., ) where the outcome at time \(t\) is chosen by an adaptive adversary who has observed the sequence of earlier outcomes and predictions. We show that an \(O()\) SSCE is achievable.

**Theorem 1.3**.: _In the adversarial sequential calibration setting, there is a deterministic strategy for the forecaster that achieves an \(O()\) SSCE._

An interesting and important feature of this result is that it achieves an \(O()\) rate whereas an \(O()\) rate for the expected calibration error is known to be impossible to achieve . Together our Theorems 1.2 and 1.3 establish that SSCE is a truthful and useful calibration measure.

### Related Work

There is a large body of work on calibration, a notion that dates back to the 1950s  and has been applied to game theory , machine learning , and algorithmic fairness . We will restrict our discussion to sequential calibration and the systematic study of calibration measures, which are the closest to this work.

Sequential calibration.Foster and Vohra  first proved that one can achieve _asymptotic calibration_ on arbitrary and adaptive outcomes. Formally, they gave a forecasting algorithm with an \(O(T^{2/3})\) ECE in expectation, when predicting \(T\) binary outcomes chosen by an adaptive adversary. Subsequent work gave alternative and simpler proofs of the result , extended the result to other calibration measures , and proved lower bounds on the optimal ECE . Most closely related to our approach is the work of , who studied a stronger notion that requires calibration on a family of _checking rules_, where each checking rule specifies a subset of the time horizon. Despite the apparent similarity, their notion is qualitatively different from the SSCE, since we take an expectation over the subsampled horizon, whereas they take the maximum. In particular, no forecaster can be calibrated in their definition if the checking rule family contains all subsets of \([T]\), since there always exists a checking rule that strongly correlates with the outcomes.

Calibration measures.The recent work of Blasiok, Gopalan, Hu and Nakkiran  initiated the rigorous study of calibration measures. Their work focused on the offline setup, where there is a known marginal distribution over the feature space, and each predictor maps the feature space to \(\). They proposed to use the _distance from calibration_--the \(_{1}\) distance from the predictor to the closest predictor that is perfectly calibrated--as the ground truth, and studied whether existing

  Calibration Measure & Complete? & Sound? & Truthful? \\  Expected Calibration Error, Maximum Swap Regret & ✓ & ✓ & \(0\)-\((T)\) gap \\  Smooth Calibration, Distance from Calibration, & ✓ & ✓ & \(0\)-\(()\) gap \\ Interval Calibration, Laplace-Kernel Calibration & ✓ & ✓ & \(O(1)\)-\(()\) gap \\  U-Calibration Error & ✓ & ✓ & \(O(1)\)-\(()\) gap \\  Proper Scoring Rules & \(\) & ✓ & \((1,0)\)-truthful \\  
**Subsampled Smooth Calibration Error** & ✓ & ✓ & \((O(1),0)\)-truthful \\  

Table 1: Evaluation of existing calibration measures along with SSCE, in terms of completeness, soundness and truthfulness (Definitions 2.2 and 2.5). An \(\)-\(\) truthfulness gap means that there is a prediction instance on which forecasting according to the true conditional distribution of the next outcome incurs more than \(\) penalty, but there is a forecasting strategy that incurs at most \(\) penalty. See Appendix A for more details.

calibration measures are consistent with it. Note that completeness and soundness are defined differently in : a calibration measure is called complete (resp., sound) if it is upper (resp., lower) bounded by a polynomial of the distance from calibration. Since the distance from calibration is far from being truthful in the online setup (as shown by ), our definition of completeness and soundness set up minimal conditions for an error metric to be regarded as measuring calibration, rather than enforcing closeness to the distance from calibration.

Subsampling.Our new calibration measure is derived from subsampling the time horizon. This simple idea has been shown to be effective in various different contexts, including privacy amplification in differential privacy (e.g.,[14, Section 6]), handling adversarial corruptions , as well as adaptive data analysis .

Proper scoring rules.Proper scoring rules  are error metrics for probabilistic forecasts that are optimized when the forecaster predicts according to the true distribution. While the error metrics induced by proper scoring rules are (perfectly) truthful by definition, as we show in Appendix A, they are qualitatively different from the usual calibration measures and, in particular, do not meet the completeness criterion. We note that a recent line of work  studied the _optimization of scoring rules_, namely, finding the proper scoring rule that maximally incentivizes the forecaster to exert effort to obtain additional information.

## 2 Preliminaries

Sequential prediction.We consider the following prediction setup: First, a sequence \(x\{0,1\}^{T}\) is sampled from distribution \(\). At each step \(t[T]\), the forecaster makes a prediction \(p_{t}\), after which \(x_{t}\) is revealed. Formally, a deterministic forecaster is a function \(:_{t=1}^{T}\{0,1\}^{t-1}\), where \((b_{1},b_{2},,b_{t-1})\) specifies the forecaster's prediction at step \(t\) if the first \(t-1\) observations match \(b_{1:(t-1)}\). Distribution \(\) and forecaster \(\) naturally induce a joint distribution of \((x,p)\{0,1\}^{T}^{T}\) via sampling \(x\) and predicting \(p_{t}=(x_{1},x_{2},,x_{t-1})\).

Note that we could have defined the forecaster as a function of both the outcomes \(x_{1:(t-1)}\) and the predictions \(p_{1:(t-1)}\) in the past. This alternative definition is equivalent to ours, since \(p_{1:(t-1)}\) would be uniquely determined by \(x_{1:(t-1)}\). We could also have considered _randomized_ forecasters, which are specified by distributions over deterministic forecasters. However, as we will see later, restricting our attention to deterministic forecasters does not affect the subsequent definitions.

Calibration measures.The quality of the forecaster's predictions in the setting above is quantified by calibration measures. Formally, a calibration measure \(\) is a family of functions \(\{_{T}:T\}\), where each \(_{T}\) maps \(\{0,1\}^{T}^{T}\) to \([0,T]\). We will frequently omit the subscript \(T\), since it is usually clear from the context. With respect to calibration measure \(\), the expected penalty incurred by forecaster \(\) on distribution \(\) is defined as \(_{}(,)_{(x,p )(,)}[(x,p)]\), where \((x,p)(,)\) denotes sampling a sequence \(x\) and predictions \(p\) from the joint distribution induced by \(\) and \(\).

One example of calibration measures is the _smooth calibration error_ introduced by  that is defined as \((x,p)_{f}_{t=1}^{T}f(p_{t})(x_{t} -p_{t}),\) where \(\) is the family of \(1\)-Lipschitz functions from \(\) to \([-1,1]\). In this work, we introduce a new calibration measure called _Subsampled Smooth Calibration Error (SSCE)_ that is defined by subsampling a subset of the time horizon, and evaluating the smooth calibration error on it. We will formally define this measure next. In the following, \((S)\) denotes the uniform distribution over a finite set \(S\). For a \(T\)-dimensional vector \(x\) and \(S[T]\), \(x|_{S}\) denotes the \(|S|\)-dimensional vector formed by the entries of \(x\) indexed by \(S\).

**Definition 2.1** (Subsampled Smooth Calibration Error).: _For a sequence of outcomes \(x\{0,1\}^{T}\) and predictions \(p^{T}\), the Subsampled Smooth Calibration Error (SSCE) is defined as_

\[(x,p)*{}_{S(2^{  T})}[(x|_{S},p|_{S})]=*{ }_{y(\{0,1\}^{T})}[_{f} _{t=1}^{T}y_{t} f(p_{t})(x_{t}-p_{t})].\]

Completeness and soundness.We give minimal conditions for a calibration measure to be regarded as complete (intuitively "accurate" predictions have a small penalty) and sound (intuitively "inaccurate" predictions have a large penalty).

**Definition 2.2** (Completeness and soundness).: _A calibration measure \(\) is complete if: (1) For any \(x\{0,1\}^{T}\), \(_{T}(x,x)=0\); (2) For any \(\), \(_{x_{1},,x_{T}()}[_{ T}(x,_{T})]=o_{}(T)\). The calibration measure is sound if: (1) For any \(x\{0,1\}^{T}\), \(_{T}(x,_{T}-x)=(T)\); (2) For any \(,\) such that \(\), \(_{x_{1},,x_{T}()}[ _{T}(x,_{T})]=_{,}(T)\). Here, \(o_{}()\) and \(_{,}()\) may hide constant factors that depend on the parameters in the subscript._

Truthfulness.To define the truthfulness of a calibration measure, we introduce the _truthful forecaster_ and the _optimal error_ for a distribution \(\).

**Definition 2.3** (Truthful forecaster).: _With respect to distribution \((\{0,1\}^{T})\), the truthful forecaster is defined as \(^{}()(b_{1},b_{2},,b_{t-1}) _{x}[x_{t}=1\,|\,x_{1:(t-1)}=b_{1:(t-1)}]\)._

Arguably, \(^{}()\) is the only forecaster that makes the "right" predictions on distribution \(\).

**Definition 2.4** (Optimal error).: _The optimal error on distribution \((\{0,1\}^{T})\) with respect to calibration measure \(\) is defined as \(_{}()_{}_{}(,)\), where \(\) ranges over all deterministic forecasters._

Note that by an averaging argument, the definition of \(_{}()\) is unchanged if we take an infimum over randomized forecasters.

A calibration measure is truthful if, on every distribution, the truthful forecaster is near-optimal.

**Definition 2.5** (Truthfulness of calibration measures).: _A calibration measure \(\) is \((,)\)-truthful if, for every \((\{0,1\}^{T})\), \(_{}(,^{}( ))_{}()+\). Conversely, \(\) is said to have an \(\)-\(\) truthfulness gap if, for some distribution \(\), \(_{}()\) and \(_{}(,^{}( ))\)._

## 3 Technical Overview

In this section, we briefly discuss the main technical ideas and challenges behind the proofs of Theorems 1.1, 1.2, and 1.3. We provide more details on our main result, i.e., that SSCC is \((O(1),0)\)-truthful, in Sections 4 through 6. Theorem 1.3 follows from a recent result of  on minimizing the distance from calibration in the adversarial setup, along with a new result connecting SSCE to distance from calibration, and is proved in Section 7. We defer the proof of Theorem 1.1 to Appendix B.

A simple distribution that witnesses truthfulness gaps.Inspired by [15, Example 2], we consider the distribution \(\) specified as follows: The time horizon is divided into \(T/3\) blocks of length \(3\), each with a uniformly random bit, followed by a zero and a one. Within each block, the truthful forecaster predicts \(1/2\), \(0\) and \(1\) in order. Then, among the steps on which \(1/2\) is predicted, the frequency of ones is typically \(1/2(1/)\). This deviation results in a \(()\) penalty under most calibration measures (concretely, all calibration measures in the first two rows of Table 1).

However, there is a different strategy that ensures perfect calibration, and thus a zero penalty under most calibration measures. Within each block, the forecaster predicts \(1/2\) on the first step. If the bit turns out to be \(1\), the forecaster maintains perfect calibration by predicting \(1/2\) on the second step, on which the outcome is known to be \(0\); otherwise, the forecaster accomplishes the same by predicting \(1/2\) on the third step. Therefore, the distribution \(\) witnesses a \(0\)-\(()\) truthfulness gap for every calibration measure in the first two rows of Table 1.

The importance of subsampling in the SSCE becomes apparent in light of the example above. On distribution \(\), the truthful forecaster has to pay a \(()\) cost for the mild deviation from the expectation, while a strategic forecaster avoids this deviation by correlating the predictions with the biases in the past. With the subsampling, however, the forecaster is no longer sure about the biases that factor into the penalty. This ensures that, compared to truth-telling, the benefit from predicting strategically is marginal, and thus makes the truthfulness guarantee in Theorem 1.2 possible.

Establishing truthfulness via martingale inequalities.We prove that the SSCE is \((O(1),0)\)-truthful in three steps: (1) Define a complexity measure \(()\) of distribution \(\); (2) Show that \(_{}(,^{}( ))=O(())\); (3) Show that \(_{}()=(())\).

As we elaborate in Section 5, the crux of Step (2) is to control the expected deviation of a martingale \((M_{t})_{0 t T}\) with respect to filtration \((_{t})\) by the its _realized variance_\(_{t}_{s=1}^{t}[M_{s}|_{s- 1}]\), which is highly non-trivial as the two processes \((M_{t})\) and \((_{t})\) are correlated. In more detail, the filtration \((_{t})\) corresponds to the randomness in \(x\), while \((M_{t})\) tracks the biases in the predictions (on a subset of the time horizon) tested by a Lipschitz function. We note that such a bound would easily follow from "off-the-shelf" concentration inequalities for martingales (e.g., Freedman's inequality ), if the total realized variance \(_{T}\) were uniformly bounded. However, in general, \(_{T}\) may vary drastically, and directly applying these concentration inequalities would introduce an extra super-constant factor. Our workaround is a "doubling trick" that divides the time horizon into _epochs_, the realized variances in which grow exponentially. We then apply Freedman's inequality to each epoch separately. In Section 5, we formulate a toy random walk problem that highlights this challenge and demonstrates our solution to it, which is of independent interest.

Similarly, as we show in Section 6, the crux of Step (3) is to establish another martingale inequality. We first show that for fixed \(x\) and \(p\), we have \((x,p)=(})\), where \(N_{t}_{s=1}^{t}[|x_{s}-p_{s}| 1/2]\). Furthermore, over the randomness in \(x\), the realized variance process \((_{t})\) defined above is shown to lower bound \((N_{t})\), i.e., \((N_{t}-_{t})\) is a sub-martingale. However, the desired result requires the lower bound \([}](1)[_{T}}]\), which does _not_ follow from \([N_{T}-_{T}] 0\) in general. This challenge necessitates a more careful analysis tailored to the specific properties of the processes \((N_{t})\) and \((_{t})\).

Deterministic forecasting strategy via reduction to \(\).We build on the result of  showing the existence of a deterministic forecasting strategy guaranteeing an \(O()\) bound on \(\). In particular, we show via a standard chaining argument that \(\) is upper bounded by \(\) plus a variance term that can be upper bounded by \(O()\). The result of  then implies a deterministic forecasting algorithm achieving an \(O()\)\(\).

## 4 Warmup: The Product Distribution Case

As a warmup, in this section, we start by showing that \(\) is \((O(1),O( T))\)-truthful for product distributions. This is a weaker version of Theorem 1.2 in terms of both the truthfulness parameters of \(\) and the restriction to product distributions. In Sections 5 and 6, we outline how we will remove these restrictions and improve the analysis of truthfulness.

For distribution \(=_{t=1}^{T}(p_{t}^{})\), take \(^{2}_{x}[_{t=1}^{T}x_{t} ]=_{t=1}^{T}p_{t}^{}(1-p_{t}^{})\) as a complexity measure of the distribution of outcomes. We will show that \(_{}(,^{}( ))=O(+ T)\) and \(_{}()=()-O(1)\).

### Upper Bound the SSCE of the Truthful Forecaster

We first show that the truthful forecaster for \(\), which predicts \(p_{t}=p_{t}^{}\) at every step \(t\), gives \(_{x}[(x,p^{})]=O(+  T)\). For this purpose, it suffices to prove

\[_{x}[(x,p^{})]=O( + T),\] (1)

since for each fixed \(S[T]\), applying (1) to \(x|_{S}\) and \(p^{}|_{S}\) gives \(_{x}[(x|_{S},p^{}|_{S})]  O(+ T)\), and taking an expectation over \(S(2^{[T]})\) gives the desired bound on \(\).

Recall that \([(x,p^{})]=[_{f }_{t=1}^{T}f(p_{t}^{})(x_{t}-p_{t}^{})]\). If we replace \(\) with the family of _constant_ functions from \(\) to \([-1,1]\), the right-hand side would reduce to

\[_{x}[|_{t=1}^{T}(x_{t}-p_{t}^{}) |]_{x}[(_{t=1}^{T }(x_{t}-p_{t}^{}))^{2}]}=_{x }[_{t=1}^{T}x_{t}]}=.\]Therefore, to prove the upper bound in (1), we need to show that the family of one-dimensional Lipschitz functions is not significantly richer than constant functions.

At a high level, this is done by taking finite coverings of Lipschitz functions and using Dudley's chaining technique  to upper bound the value of this stochastic process. In more detail, let \(_{}\) be the smallest \(\)-covering of \(\) in the uniform norm, i.e., for each \(f\), there exists \(f_{}_{}\) such that \(\|f-f_{}\|_{}\). It is well-known that \(|_{}|=e^{O(1/)}\), and a chaining argument gives

\[*{}_{x}[_{f}_ {t=1}^{T}f(p_{t}^{})(x_{t}-p_{t}^{})] 1+_{k=0}^{O(  T)}*{}_{x}[_{g _{2^{-k}}}_{t=1}^{T}g(p_{t}^{})(x_{t}-p_{t}^{}) ],\] (2)

where \(_{}\{f_{}-f_{/2}:f_{}_{},f_{/2}_{/2},\|f_{}-f_{/2}\|_{ } 3/2\}\).

It remains to bound the second term of (2). Note that for a fixed \(g\), because of the independence of \(x_{t}\)s, \(g(p_{t}^{})(x_{t}-p_{t}^{})\) is independent across \(t[T]\). Therefore, we can control the tail probability of \(_{t=1}^{T}g(p_{t}^{})(x_{t}-p_{t}^{})\) by Bernstein inequalities. For each fixed \(\), using a Bernstein tail bound, taking a union bound over \(g_{}\), and noting that \(|_{}||_{}||_{/2}| =e^{O(1/)}\), we have

\[*{}_{x}[_{g_{ }}_{t=1}^{T}g(p_{t}^{})(x_{t}-p_{t}^{})] O () O(|_{}|}+| _{}|)=O(+1).\]

Plugging this into (2) proves (1) and thus the desired bound \(*{}_{x}[(x,p^{}) ]=O(+ T)\).

### Lower Bound the Optimal SSCE

Next, we lower bound \(_{}()\) by showing that _every_ forecasting strategy must incur an \(()\) SSCE on \(\). Recall that \((x,p)\) is given by

\[*{}_{y(\{0,1\}^{T})}[_{f }_{t=1}^{T}y_{t} f(p_{t})(x_{t}-p_{t})] *{}_{y(\{0,1\}^{T})}[|_{ t=1}^{T}y_{t}(x_{t}-p_{t})|],\]

where we use the fact that \(\) contains the constant functions \(1\) and \(-1\).

Fix \(x\{0,1\}^{T}\), \(p^{T}\) and let \(N_{t=1}^{T}[|x_{t}-p_{t}| 1/2]\). Over the randomness in \(y(\{0,1\}^{T})\), the quantity \(_{t=1}^{T}y_{t}(x_{t}-p_{t})\), by the central limit theorem, is approximately distributed as a normal distribution with variance \(_{t=1}^{T}(x_{t}-p_{t})^{2}_{t=1}^{T} [|x_{t}-p_{t}| 1/2]=(N)\), so its expected absolute value is \(()\).

Now it remains to lower bound the expectation of \(\) induced by an arbitrary forecaster. Conditioning on \(x_{1:(t-1)}\), \(x_{t}\) always follows \((p_{t}^{})\). Thus, regardless of the choice of \(p_{t}\), the condition \(|x_{t}-p_{t}| 1/2\) holds with probability at least \(\{p_{t}^{},1-p_{t}^{}\} p_{t}^{}(1-p_{t}^{})\). Then, over the \(T\) steps, we expect that \(N(_{t=1}^{T}p_{t}^{}(1-p_{t}^{}))=(^{2})\) holds with probability \((1)\), as long as \(=(1)\). This gives the desired lower bound \(*{}[(x,p)]*{ }[]=()-O(1)\).

## 5 Upper Bound the SSCE of the Truthful Forecaster

To extend the proof strategy sketched in Section 4 to non-product distributions, the first challenge is to define an appropriate complexity measure of a general distribution \(\). Consider the stochastic process \((_{t})_{0 t T}\) defined as \(_{t}_{s=1}^{t}p_{s}^{}(1-p_{s}^{})\), where \(x\) and \(p_{t}^{}*{}_{x^{}} [x_{t}^{}|x_{1:(t-1)}^{}=x_{1:(t-1)}]\) is now a random variable that denotes the conditional expectation of \(x_{t}\) after observing \(x_{1:(t-1)}\). The "right" definition turns out to be roughly \(()*{}[_{T}}]\). In this section, we prove the following weaker upper bound on the SSCE incurred by the truthful forecaster. We provide a stronger bound (Theorem C.1) in Appendix C.

**Theorem 5.1**.: _For any \((\{0,1\}^{T})\), \(_{}(,^{}( ))=O(*{}[_{T}} ]+^{2}T)\)._

Proof sketch.: We begin by repeating the chaining argument in Section 4. Recall that, for any \(>0\), there is a \(\)-covering \(_{}\) of \(\) in the \(\)-norm that has size \(e^{O(1/)}\). Letting \(_{}(f)\) denote the mappingof a function \(f\) onto the covering \(_{}\) such that \(\|f-_{}(f)\|_{}\), we can write for any \(M_{+}\):

\[(x,p) 2^{-M} T+(\{0,1\}^{T})}{ }[_{k=0}^{M}}_{t=1}^ {T}y_{t}(_{2^{-k}}(f)(p_{t})-_{2^{1-k}}(f)(p_{t}))(x_{t}-p_{t} )}_{=W_{k}}].\]

To control the expectation of each \(W_{k}\), we note that the set \(_{k}\{_{2^{-k}}(f)-_{2^{1-k}}(f):f\}\) is of size at most \(|_{2^{-k}}||_{2^{1-k}}|\). Furthermore, every function \(g_{k}\) satisfies

\[\|g\|_{}=\|_{2^{-k}}(f)-_{2^{1-k}}(f)\|_{}\|_{2^{-k} }(f)-f\|_{}+\|f-_{2^{1-k}}(f)\|_{}=O(2^{-k})\]

for some \(f\). We apply the following technical lemma, which we prove in Appendix C.

**Lemma 5.2**.: _Given a function \(f:[-1,1]\) and \(y\{0,1\}^{T}\), consider the martingale \(M_{t}(f,y)_{s=1}^{t}y_{s} f(p_{s}^{})(x_{s}-p_{s} ^{})\) where \(x\). Then, for any finite family \(\) of functions from \(\) to \([-1,1]\) and any \(y\{0,1\}^{T}\), we have_

\[}{}[_{f}M_{T}(f,y) ] O(|| T+|} }{}[_{T}}] ).\]

Applying Lemma 5.2 to each \(_{k}\) scaled up by a \((2^{k})\) factor and noting that \(|_{k}||_{2^{-k}}|+|_{2^{1-k} }|=O(2^{k})\) gives

\[_{}(,^{}())  2^{-M} T+_{k=0}^{M}O(2^{-k}) O(2^{k} T +2^{k/2}}{}[_{T}} ])\] \[ 2^{-M} T+_{k=0}^{M}O( T+2^{-k/2} }{}[_{T}}])\] \[ 2^{-M} T+O(M T+}{ }[_{T}}]).\]

Choosing \(M=( T)\) proves the theorem. 

We remark that the proof of Lemma 5.2 is highly non-trivial. As mentioned in Section 3, such an upper bound would follow from Freedman's inequality, if \(_{T}\) were _always_ bounded by \(O(([_{T}}])^{2})\). However, in general, applying Freedman's inequality to each \(M_{T}(f,y)\) necessarily requires an additional union bound over possible values of \(_{T}\), and introduces a super-constant multiplicative factor.

The challenge in dealing with the randomness in \(_{T}\) is captured by the following toy problem:

**Random walk with early stopping:** Let \((X_{t})_{0 t T}\) be the random walk such that \(X_{0}=0\) and each \(X_{t}-X_{t-1}\) independently follows \((\{ 1\})\). Let \(\) be an arbitrary stopping time with respect to \((X_{t})\). Prove that \([|X_{}|] O(1)[]\).

Indeed, the above corresponds to a special case of Lemma 5.2 in which: (1) the sequence \(p^{}\) starts with entry \(1/2\), and may switch to entry \(0\) at any point, depending on the realization of \(x_{t}\)s; (2) the family \(\) consists of two constant functions \(1\) and \(-1\).

One might be tempted to prove \([|X_{}|] O(1)[]\) by first proving \([|X_{}||=t]=O()\) for all \(t[T]\), and then applying the law of total expectation. Such an approach is doomed to fail, because the stopping time \(\) might significantly bias the conditional expectation of \(|X_{}|\) on some event \(=t_{0}\), e.g., by stopping at time \(t_{0}\) only if \(|X_{t_{0}}|}\).

Our workaround is inspired by the standard doubling trick in online learning. We break the time horizon into _epochs_ of geometrically increasing lengths: the \(k\)-th epoch contains \(2^{k}\) steps. We break \(|X_{}|\) into the displacements accumulated in different epochs; their sum clearly upper bounds \(|X_{}|\)Furthermore, we can show that, conditioning on reaching epoch \(k\), the displacement within the epoch is \(O(})\). This allows us to establish the desired inequality via

\[[|X_{}|] O(1)_{k=1}^{O( T)} [k]} O(1) [].\]

To prove Lemma 5.2, we extend this technique to a general martingale \(M_{T}(f,y)\) by dividing the time horizon into epochs according to the doubling of \(_{t}\), and then applying Freedman's inequality to each epoch.

Towards a stronger upper bound.In our actual proof, we use a slightly different complexity measure \(_{}()[(_{T})]\), where \((x)=x\) if \(x<1\) and \((x)=\) otherwise. Roughly speaking, this definition accounts for the fact that a sum of independent Bernoulli random variables behaves quite differently when its mean is close to \(0\). To remove the extra \(^{2}T\) term in Theorem 5.1, our actual proof also uses a variant of Lemma 5.2, Lemma C.9, which involves a more careful application of Freedman's inequality tailored to specific coverings of Lipschitz functions.

## 6 Lower Bound the Optimal SSCE

In this section, we outline a weaker lower bound on the optimal SSCE achievable on a distribution.

**Theorem 6.1**.: _For any \((\{0,1\}^{T})\), \(_{}()=([_{T}}])-O(1)\)._

Similar to the product distribution case (Section 4), the key quantity in the proof is the stochastic process \((N_{t})_{0 t T}\) defined as \(N_{t}_{s=1}^{t}n_{s}\) and \(n_{t}[|x_{t}-p_{t}| 1/2]\). This is formalized by the following lemma, which applies to any realization of \(x\), \(p\), and \(N_{T}=_{t=1}^{T}[|x_{t}-p_{t}| 1/2]\):

**Lemma 6.2**.: _For any \(x\{0,1\}^{T}\) and \(p^{T}\), we have \((x,p)(})\)._

It remains to lower bound the quantity \([}]\) induced by an arbitrary forecaster. As argued earlier, conditioning on \(x_{1:(t-1)}\), we always have \([n_{t}=1] p_{t}^{}(1-p_{t}^{})=_{t}-_{t-1}\), where \(p_{t}^{}\) and \(_{t}\) are defined as in Section 5. Thus, \((N_{t}-_{t})\) is a sub-martingale, which implies \([N_{T}][_{T}]\). However, this does _not_ imply that \([}]([_{T}}])\). In fact, such an inequality does _not_ hold in general: When \(p_{t}^{}= 1\) and \(p_{t}^{}=0\) for all \(t 2\), \([}]\) could be \(O()\), yet \([_{T}}]=() O ()\).

The following technical lemma circumvents this counterexample by subtracting a constant term from the right-hand side:

**Lemma 6.3**.: _The stochastic process \((N_{t})_{t[T]}\) satisfies \([}]([_{T}}])-O(1)\)._

Note that Theorem 6.1 directly follows from Lemmas 6.2 and 6.3, which we prove in Appendix D.1. To avoid the extra \(-O(1)\) term in the lower bound, our actual proof (deferred to Appendix D.3) works with the slightly different complexity measure \(_{}()[(_{T})]\) defined in Section 5.

## 7 Forecasting with \(O()\) Ssce

In this section, we prove Theorem 1.3, which states the existence of a deterministic forecaster that incurs an \(O()\) SSCE against all adaptive adversaries. Recall the definition of the smooth calibration error (\(\)) from Section 2. Using standard chaining arguments, we can show the following relation between \(\) and \(\), whose proof we defer to Appendix F.

**Lemma 7.1**.: _For any \(x\{0,1\}^{T}\) and \(p^{T}\),_

\[(x,p)(x,p)+O(),\]

_where the \(O()\) notation hides a universal constant that does not depend on \(T\), \(x\) or \(p\)._

Theorem 1.3 follows from the lemma above and a recent result of .

Proof of Theorem 1.3.: It was shown by  that there exists a deterministic forecaster with an \(O()\) distance from calibration (\((x,p)\)) against every adaptive adversary in the adversarial sequential calibration setup. Lemma 7.1 together with the inequality \((x,p)(x,p)\) from [1, Lemma 5.4 and Theorem 7.3] implies that

\[(x,p)(x,p)+O(),\]

so the same forecaster incurs an SSCE of \(O()\) as well. 

## 8 Discussion

We formulate three natural desiderata of calibration measures that evaluate the quality of probabilistic forecasts: truthfulness, completeness, and soundness. They serve as minimal requirements for an error metric to be considered as measuring calibration and not to create a significant incentive for forecasters to predict untruthfully. While existing calibration measures fail to simultaneously meet all these criteria, we propose the new calibration measure (SSCE) that is shown to be approximately truthful via a non-trivial analysis. In the following, we discuss two natural directions of future work.

Inherent trade-offs among different desiderata?As shown in Table 1, the SSCE and the error metrics induced by proper scoring rules give a trade-off between truthfulness and completeness: The former is complete and approximately truthful, while the latter is perfectly truthful but not complete. Is there a calibration measure that achieves the best of both worlds? Taking a step back, while our definition of truthfulness seems natural, the completeness and soundness criteria, as defined, only serve as minimal requirements. It still remains to explore ways to formally quantify the latter two, and investigate the inherent quantitative trade-offs among truthfulness, completeness and soundness.

Truthfulness against adaptive adversaries?One may wonder whether the truthfulness guarantee of \(\) can be extended to handle _adaptive_ adversaries as well. Assuming that the forecaster is given an adversary's (randomized) strategy for choosing \(x_{t}\) based on \(x_{1:(t-1)}\) and \(p_{1:(t-1)}\), is it still approximately optimal to always predict the conditional probability? Here, "adaptive" emphasizes that \(x_{t}\) may depend on both \(x_{1:(t-1)}\) and \(p_{1:(t-1)}\); the formulation in Section 2 is equivalent to that \(x_{t}\) only depends on \(x_{1:(t-1)}\).

Unfortunately, as we show in Appendix G, such a guarantee does not hold for \(\), and is unlikely to hold for any natural calibration measure: An adversary can "force" the forecaster to predict untruthfully by "threatening" to increase the variance of the subsequent bits. However, this adversary is highly contrived and unrealistic for practical scenarios. We may thus identify reasonable restrictions on the adaptive adversary to sidestep this counterexample.

## 9 Acknowledgements

This work is supported in part by the National Science Foundation under grants CCF-2145898 and the Graduate Research Fellowship Program under grant DGE 2146752, the Office of Naval Research under grant N00014-24-1-2159, an Alfred P. Sloan fellowship, a Schmidt Sciences AI2050 fellowship, and a Google Research Scholars award. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the funding agencies.