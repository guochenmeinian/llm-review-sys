# Safety Verification of Decision-Tree Policies

in Continuous Time

 Christian Schilling

Aalborg University

Aalborg, Denmark

christianns@cs.aau.dk

&Anna Lukina

TU Delft

Delft, The Netherlands

a.lukina@tudelft.nl

Emir Demirovic

TU Delft

Delft, The Netherlands

e.demirovic@tudelft.nl

Kim Guldstrand Larsen

Aalborg University

Aalborg, Denmark

kgl@cs.aau.dk

###### Abstract

Decision trees have gained popularity as interpretable surrogate models for learning-based control policies. However, providing safety guarantees for systems controlled by decision trees is an open challenge. We show that the problem is undecidable even for systems with the simplest dynamics, and **PSPACE**-complete for finite-horizon properties. The latter can be verified for discrete-time systems via bounded model checking. However, for continuous-time systems, such an approach requires discretization, thereby weakening the guarantees for the original system. This paper presents the first algorithm to directly verify decision-tree controlled systems in continuous time. The key aspect of our method is exploiting the decision-tree structure to propagate a set-based approximation through the decision nodes. We demonstrate the effectiveness of our approach by verifying safety of several decision trees distilled to imitate neural-network policies for nonlinear systems.

## 1 Introduction

Deep reinforcement learning has shown success in deriving control policies for _nonlinear_ systems for which classical optimal control theory provides no solution (Mnih et al., 2015). Despite impressive performance, there are two key drawbacks: (i) the resulting policy is difficult to interpret, and (ii) there are no guarantees that the system always reaches the desired goal and avoids unsafe states. The interpretability challenge has led to a review of _decision trees_ as well-performing, compact, and transparent surrogates for deep neural networks (Ashok et al., 2020, 2019, David et al., 2015, Alamdari et al., 2020, Vos and Verwer, 2023). To provide safety guarantees, prior work proposed to encode a discrete, time-bounded system controlled by a decision-tree policy as a set of logical constraints (Bastani et al., 2018). However, this approach does not apply to continuous-time dynamics.

**Example 1**.: _To illustrate the problem, we consider a quadrotor system (Ivanov et al., 2019) in Figure 1(a), where the task is to follow the brown reference trajectory from \((0,0)\) and stay within the blue dashed safety corridor. Illustrated schematically in Figure 1(b), we may observe a trajectory that exhibits safe behavior for each discrete time point but leaves the safety corridor in between. Since the trajectory returns quickly enough, this violation is missed by a discrete-time analysis._

In this work, we address, for the first time, the problem of verifying safety (reach-avoid) properties of a decision-tree controlled system (DTCS) with (nonlinear) _continous-time_ dynamics. We propose an algorithm that exploits the structure of the decision-tree policy and propagates ssplitting at the decision boundaries. This way we obtain a sound enclosure of the true reachable states even for continuous dynamics, which guarantees safe goal reachability for all behaviors of the controlled system. Furthermore, our approach naturally generalizes to discrete-time systems, for which, compared to the aforementioned approach based on logical encoding (Bastani et al., 2018), our approach provides visual interpretability of the verification process.

To summarize our contributions, we first provide an algorithm to verify a decision-tree policy of a nonlinear continuous-time system. Our general algorithm is parameterized in two procedures for respectively analyzing the dynamical system and the policy. For these procedures, we formulate sufficient conditions for the algorithm to be sound and relatively complete. Second, we describe an instantiation of the algorithm for nonlinear systems based on Taylor models (Berz and Makino, 1998). In a nutshell, this procedure propagates a set of states through the system dynamics. For analyzing the decision-tree policy, we focus on the common class of axis-aligned predicates ("\(x c\)") and propose an instantiation that exploits this structure. Third, we show that the problem of verifying decision-tree policies is **PSPACE**-complete even for very simple (namely, state-independent) dynamics. Finally, we demonstrate that our algorithm can verify several reinforcement-learning benchmarks from classical control and the quadrotor from Figure 1, even for unbounded time.

### Related Work

A decision tree is a popular machine-learning model that has recently regained interest due to its high interpretability (Du et al., 2020). Decision-tree policies can be trained directly from a tabular dataset of state-action pairs (Quinlan, 1996), e.g., using the CART algorithm (Breiman et al., 1984) or dtControl (Ashok et al., 2020). Since these algorithms perform an equivalence transformation, safety guarantees transfer from the dataset to the decision tree. Ashok et al. (2019) show how to extract a safe-by-design decision tree from a safe policy synthesized with Uppaal Stratego (David et al., 2015) for a priced timed game. However, for nonlinear systems it is generally unclear how to obtain safe-by-design policies. In practice one uses best-effort methods such as reinforcement learning. As these approaches cannot guarantee that the resulting policy is safe, there is need for approaches to verify a given policy after learning.

Decision trees can be trained to imitate another model such as a neural network. For instance, the Viper algorithm incorporates decision-tree learning into the imitation procedure (Bastani et al., 2018). As this imitation provides no correctness guarantees, a separate analysis is required. The authors encode the bounded-time reachability problem for a discrete-time system in logical constraints. This encoding is the only verification approach for discrete-time DTCS we are aware of. Other verification efforts for decision trees have focused on robustness and adversarial examples in a supervised setting (Urban and Mine, 2021), which are orthogonal problems to our setting of verifying a policy.

For purely dynamical systems (without a control policy), reachability analysis has been studied extensively (Doyen et al., 2018; Althoff et al., 2021). One prominent approach is based on Taylor models (Berz and Makino, 1998), which we also employ in our implementation. Combining a

Figure 1: A sketch of the quadrotor system and motivation for continuous-time analysis.

dynamical system with a control policy results in a hybrid system (Henzinger, 1996). Applying tools for general hybrid-system verification to DTCS is not feasible because they do not exploit the specific structure (we discuss this further in Appendix D). The reach-avoid problem is undecidable for nonlinear dynamics (even without a control policy), and most approaches (including ours) consider only time-bounded analysis. However, as we discuss later, under certain conditions, our results still generalize to unbounded time via fixpoint techniques (Giacobbe, 2019; Bacci et al., 2021). For piecewise-constant dynamics, axis-aligned policies resemble systems that can be efficiently dealt with using interval-based arithmetic constraint solving (Franzle and Herde, 2007; Franzle and Herde, 2007).

Closely related to DTCS are neural-network controlled systems (NNCS), where the policy is implemented by a neural network. Recently, many reachability approaches have been proposed (Dutta et al., 2019; Tran et al., 2020; Fan et al., 2020; Akintunde et al., 2022; Ivanov et al., 2021; Schilling et al., 2022; Kochdumper et al., 2023), and implementations compete in a yearly competition (Lopez et al., 2022). The main difference to DTCS is that the control action comes from a continuous domain and the neural network implements a smooth function. Hence such policies typically yield a similar control action for similar states, which benefits set-based reachability analysis. In contrast, given two similar states, a decision tree can yield vastly different control actions. Thus tools for verifying NNCS are not applicable to our problem. NNCS are Turing-complete (Hyotyniemi, 1996). We show the same result for DTCS even with the simplest environment dynamics, which yields an undecidable problem in unbounded time and a **PSPACE**-complete problem in bounded time.

To summarize, decision-tree policies are highly desirable due to their interpretability. The most successful methods in obtaining such policies use machine learning, which do not guarantee safety of the resulting policy. While previous work managed to verify discrete-time policies, continuous-time policy verification remains an open problem. Our work bridges this gap with the first algorithm to verify decision-tree policies for continuous-time systems.

Outline.We organize the remainder of the paper as follows. First we formalize DTCS and the reach-avoid problem. Then we describe our verification algorithm and discuss the problem complexity. Next we report on experimental results. Finally we conclude and discuss directions for future work.

## 2 Preliminaries

### Decision-Tree Controlled Systems

Let \(^{n}\) be an \(n\)-dimensional state space and \(^{m}\) an \(m\)-dimensional action (or input) space. A _decision tree_\(\) over \(\) and \(\) is a binary tree such that each inner node is labeled with a predicate \(p:\) (with \(=\{,\}\)) and each leaf is labeled with an action \(u\). The nodes in the tree are organized in levels, with the root node being at level \(1\). Let \(()\) denote the root node of \(\), \(()\) resp. \(()\) denote the left resp. right sub-tree of \(\), and \(()\) denote the label at the root of \(\) (i.e., if \(\) is a leaf, \(()\) is an action and otherwise a predicate). We can interpret \(\) as a function from \(\) to \(\) as follows. Given a state \(x\), the image under \(\), written \((x,)\), is defined recursively. For a leaf \(\), \((x,)\) is just \(()\). For a proper tree with root predicate \(p\), \((x,)\) is \((x,())\) if \(p(x)=\), and \((x,())\) otherwise. In this paper, we restrict our analysis to predicates of the form \(x_{i} c\) where \(x_{i}\) is the \(i\)-th state and \(c\) is a constant. Geometrically, these predicates are axis-aligned half-spaces. This class of predicates is commonly used, e.g., in the tools Uppaal Stratego (David et al., 2015) (with industrial applications in control of smart homes (Larsen et al., 2016) and traffic lights (Eriksen et al., 2017)) and dtControl (Ashok et al., 2020).

We consider environments modeled by a system of ordinary differential equations (ODEs), \(=f(x,u)\), where \(x(t)\) is the state vector and \(u(t)\) is the vector of control actions. Given an initial state \(x(0)=x_{0}\) and an action \(u_{0}\), we assume that the solution to the corresponding initial-value problem at time \(t 0\), written \((x_{0},u_{0},t,f)\), exists and is unique (e.g., by Lipschitz continuity).

A _decision-tree controlled system (DTCS)_ is a triple \((f,,)\) where \(f\) describes a system of ODEs, \(\) is a decision tree, used as policy, and \(^{+}\) is a control period. Figure 2 shows a conceptual sketch. The DTCS periodically queries the policy for a new control action. At time points \(k\), \(k\), the current state \(x(k)\) is passed to the policy \(\), which instantaneously yields the new control action \(u_{k}\); this action is then used for the next control period \(\) in the system dynamics \(f\). Formally, given an initial state \(x_{0}\) at \(t=0\), we recursively define the sequence of actions \(u_{k}=(x(k),)\), \(k\), and the evolution of the state \(x(t)=(x(k),u_{k},t-k,f)\) (i.e., a trajectory) for \(t(k,(k+1)]\).

### Reachable States and Reach-Avoid Problem

Given a DTCS and a set of initial states \(_{0}\), we are interested in the _reachable states_, either at time \(t\) as \(_{t}=\{x(t) x(0)_{0}\}\) or the generalization to time intervals \(_{[T_{0},T_{1}]}=_{t[T_{0},T_{1}]}_{t}\).

Similarly, a _discrete-time DTCS_ is a pair \((f,)\) where \(f\) describes a recurrence \(x_{k+1}=x_{k}+f(x_{k},u_{k})\) and \(\) is a decision tree. The reachable states at step \(k\) are \(_{k}=\{x_{k} x_{0}_{0}\}\) and analogously \(_{[K_{0},K_{1}]}=_{k[K_{0},K_{1}]}_{k}\). By default, _DTCS_ refers to the _continuous-time DTCS_ introduced above.

The _reach-avoid problem_ for DTCS is, given a DTCS \((f,,)\) over \(\), a set of initial states \(_{0}\), a bounded number of control cycles \(k_{}\), and two sets \(,\), to decide whether all trajectories \(x(t)\) reach the goal set \(\) without reaching the error set \(\) before time \(T_{}=k_{}\), i.e., \( t^{*} T_{}\). \(x(0)_{0} x(t^{*}) t[0,t^{*}]\). \(x(t)\). If we assume that the goal states \(\) are absorbing, this is equivalent to checking

\[_{T_{}}_{[0,T_{ }]}=.\] (1)

**Example 2**.: _Consider again the quadrotor model from Figure 1. A full model description is given in Appendix B.1. The reach-avoid problem here consists of the shaded area at the top as the goal set \(\), the set of states outside the red corridor as the error set \(\), and \(k_{}=30\) control cycles._

Determining reachability is already undecidable for uncontrolled nonlinear dynamical systems , and hence also for DTCS with nonlinear dynamics. A DTCS can be seen as a hybrid (mixed discrete-continuous) system, for which reachability is undecidable even with linear dynamics . Due to these complexity barriers, we aim at _enclosing_, or overapproximating, the reachable states up to time horizon \(T_{}\) by computing a set \(}_{[0,T_{}]}\).

## 3 Approach

```
1:DTCS \((f,,)\), initial set \(_{0}\), time/cycle bounds \(T_{}=k_{}\)
2:set of states \(}_{[0,T_{}]}\)
3:\(}_{0}\)
4:\(Q\{(_{0},0)\}\)
5:while\(\) isempty(\(Q\))do
6:\((,t_{0})\) pop(\(Q\))
7:if\(t_{0} T_{}\)then
8: continue
9:endif
10:\(t_{1}=(t_{0}+,T_{})\)
11:for\((_{u},u)_{}(,)\)do
12:\((,_{t_{1}})\)\(_{f}(_{u},u,f,[t_{0},t_{1}])\)
13:\(}}\)
14: push(\(Q\), \((_{t_{1}},t_{1})\))
15:endfor
16:endwhile
17:return\(}\) ```

**Algorithm 1** Reachability algorithm for DTCS

In this section, we present our approach to reachability analysis for DTCS. We first describe a general high-level algorithm, which resembles standard reachability schemes for hybrid systems. It is, however, tailored to policies over a finite action space \(\). As such, it is applicable to policies beyond decision trees, but for instance not to typical neural-network policies. We then outline conditions under which the algorithm is sound and relatively complete (i.e., does not introduce additional approximation errors). Finally, we instantiate the algorithm specifically for decision-tree policies, which is a novel contribution of this paper.

Algorithm 1 shows our high-level reachability method, which can be used to solve the reach-avoid problem (Section 2.2). The algorithm is parametric in two procedures, \(_{}\) and \(_{f}\), which together compute an enclosure of the reachable states for one control cycle. The queue \(Q\) contains pairs \((,t)\), where \(\) is a set of states that needs to be explored, and \(t\) is a time point. Each iteration of the while loop (line 3) analyzes one control cycle from \(\) and \(t\) (unless the time horizon \(T_{}\) is reached, line 6). The result is added to the set \(}\) of reachable states in line 11. Next we describe the requirements for the _post_ procedures.

Figure 2: A decision-tree controlled system \((f,,)\).

The procedure \(_{}\), which is a new contribution of this paper, takes a set of states \(\) and a decision tree \(\) and returns a finite set of pairs \((_{i}^{u},u)\), where \(_{i}^{u}\) is a set of states and \(u\) is an action. Since multiple leaves of a decision tree can be associated with the same action \(u\), we allow multiple sets \(_{i}^{u}\) to be associated with \(u\) as well. For each action \(u\), the union of the sets \(_{i}^{u}\) should enclose the set \(_{u}(,)=\{x (x,)=u\}\), so we have an index set \(I_{u}\) (possibly empty) for each action \(u\) such that

\[_{u}(,)_{i I_{u}} _{i}^{u}.\] (2)

Procedure \(_{}\) wraps the sets \(_{i}^{u}\) together with action \(u\).

\[_{}(,)=_{u }_{i I_{u}}\{(_{i}^{u},u)\}\] (3)

For \(_{}\) to be sound, we connect equations (2) and (3) and untangle the pairing with \(u\) as follows:

\[ u.\ \{x_{i}^{u}(_{i}^{u },u)_{}(,)\} _{u}(,)\] (4)

The procedure \(_{f}\) receives a set of states \(\), a control action \(u\), the environment \(f\), and a time interval \([t_{0},t_{1}]\). (Note that we actually only need the duration \(t_{1}-t_{0}\), which is \(\) most of the time, because we consider time-invariant systems. We only pass the time interval for notational purposes to refer to \(t_{1}\).) The goal is to perform a classical time-bounded reachability computation and return two sets \(\) and \(\) such that \(\) encloses the reachable states for the given time interval and \(\) encloses the reachable states at the final time point \(t_{1}\). Thus for \(_{f}\) to be sound, the following must hold:

\[_{f}(,u,f,[t_{0},t_{1}])=(,) _{[t_{0},t_{1}]} _{t_{1}}\] (5)

Algorithm 1 in combination with equations (4) and (5) computes a sound enclosure. Let us write \(_{}^{*}\) and \(_{f}^{*}\) for the procedures such that the inclusions in equations (4) and (5) are satisfied with equality. With such procedures, the algorithm even produces the exact result (proven in Appendix C.1).

**Theorem 1** (Termination, soundness, relative completeness).: _Assume Eq. (4) and Eq. (5) are satisfied. (1) Algorithm 1 terminates if all calls to \(_{}\) and \(_{f}\) terminate. (2) Let \(\{,=\}\). The result \(}\) of Algorithm 1 encloses (\(\)) resp. equals (=) the reachable states, \(}_{[0,T_{}]}\), if in all steps \(_{}(,)_{}^{*}(,)\) and \(_{f}(_{u},u,f,[t_{0},t_{1}])_{f}^{*}(_{u},u,f,[t_{0},t_{1}])\) hold._

### Implementing the Post Procedures

```
0: set \(\), control action \(u\), environment \(f\), interval \([t_{0},t_{1}]\)
0: pair \((,)\) such that \(_{[t_{0},t_{1}]}\) and \(_{t_{1}}\)
1:\(P(t)\) TM_reach(\(,u,f,[t_{0},t_{1}]\))
2:\(\) evaluate(\(P(t),[t_{0},t_{1}]\))
3:\(\) evaluate(\(P(t),t_{1}\))
4:return\((,)\) ```

**Algorithm 2** Post for the environment

For implementing \(_{f}\), we use an algorithm based on Taylor models  for reachability analysis of nonlinear dynamical systems. A Taylor model approximates a function as a polynomial together with an interval remainder over a domain , which we interpret as sets of states. For example, the one-dimensional Taylor model with polynomial \(p(x)=x^{2}-x+1\) and remainder \([-0.5,0.5]\) over the domain \([-1,1]\) around expansion point \(0\) encodes the set \(\{p(x)+r x[-1,1],r[-0.5,0.5]\}\). Taylor models subsume common set representations. Thus we assume that the initial set \(_{0}\) is given as a Taylor model.

Algorithm 2 summarizes the implementation of \(_{f}\). Here TM_reach(\(,u,f,[t_{0},t_{1}]\)) (line 1) computes a special Taylor model \(P(t)\) that depends on time \(t\). To obtain \(\) and \(\), we evaluate this Taylor model with different values for \(t\): For \(\) we evaluate with the time interval \([t_{0},t_{1}]\), which results in an enclosure of \(_{[t_{0},t_{1}]}\). For \(\) we evaluate with the time point \(t_{1}\), which results in an enclosure of \(_{t_{1}}\). Algorithm 2 can be adapted for discrete-time systems, where the procedure TM_reach is replaced appropriately, line 2 is skipped, and the result is \((,)\).

**Proposition 1**.: _Algorithm 2 implements procedure \(_{f}\) satisfying Eq. (5)._

Algorithm 3 instantiates \(_{}\). Recall that the goal of this procedure is to compute enclosures of \(_{u}(,)\), which are the sets of states that result in an action \(u\). Given a set \(\) and a decision tree \(\), the idea is to propagate \(\) down the branches that the states \(x\) would take. While the algorithm is agnostic of the predicates in \(\) (interpreted as sets of states) on a conceptual level, it is generally difficult to implement the algorithm for arbitrary predicates. In our implementation, we exploit the structure of axis-aligned half-space predicates \(P\). Let \(()\) be the interval enclosure of \(\), which is easy to obtain for a Taylor model. In line 9, we check if all states in \(\) take the left branch of \(\). We have \( P\) if and only if \(() P\). In line 11 we check if all states in \(\) take the right branch of \(\). We have \( P=\) if and only if \(() P=\). If both conditions fail, \(\) is bisected into \(_{1}=\{x x P\}\) and \(_{2}=\{x x P^{C}\}\) in line 14. Here \(P^{C}\) denotes the complement of \(P\), which is also a half-space. Since the above sets are hard to compute, we replace \(\) by \(()\) in the implementation. Note that \(() P( P)\) in our setting. We discuss this further in Appendix A.1.

**Proposition 2**.: _Algorithm 3 implements procedure \(_{}\) satisfying Eq. (4). Furthermore, if all bisections are exact, Eq. (4) is satisfied with equality._

Further details relevant for using our method in practice are given in Appendix A.

**Example 3**.: _We walk through Algorithm 1 for the first control cycle, illustrated in Figure 3. Figure 3(a) shows how Algorithm 2 computes the pair \((,)\), consisting of an enclosure \(}_{[0,]}\) of the reachable states up to time point \(\) and an enclosure \(}_{}\) of the reachable states at the last time point. Figure 3(b) shows how Algorithm 3 bisects the set \(\) along the predicate \(x 3\) into sets \(Z_{1}\) and \(Z_{2}\). We furthermore illustrate the approximation with interval enclosures. Assuming this is the only predicate of the decision tree, Algorithm 1 would continue the analysis from these two sets in the next iteration._

### Generalization to Unbounded Time via Fixpoints

Next we discuss how to employ a set-based fixpoint check; for details we refer to the literature . Roughly speaking, if we do not encounter new states after an iteration, we have found a fixpoint. Algorithm 1 iteratively adds states to \(}\) to enclose the sequence \(_{[k,(k+1)]}\), \(k<k_{}\) (Section 2.2). Let us view the exploration of the elements \((,t)\) in the queue \(Q\) as a search tree. First, the search in a node can be terminated if the set \(\) is contained in the union of the sets in the other nodes (i.e., if a fixpoint has been found). Second, if this condition holds in all branches, we have computed the reachable states in unbounded time. However, due to the discrete nature of

Figure 3: Example execution of Algorithm 1 for the first control cycle.

[MISSING_PAGE_FAIL:7]

We obtain decision-tree policies via neural-network distillation (see Table 1 on the depth and number of nodes and actions). For the quadrotor system we collected 500 samples of state-action pairs from a neural-network policy used by Ivanov et al. (2019) and learned a decision tree of depth 10 using behavioral cloning. For the three other systems (cart/pole, acrobot, mountain/car) we first used deep Q-learning to train a two-layer convolutional neural network (Mnih et al., 2013) and then adopted the Viper algorithm (Bastani et al., 2018) to imitation-learn decision trees for these systems. We manually prune the resulting trees of redundant nodes (as Viper produces balanced trees).

All experiments were conducted on a laptop with an i7 1.80 GHz CPU and 32 GB RAM.

### Evaluation on a Decision Tree for Quadrotor Control

We evaluate our verification approach on a decision tree controlling a six-dimensional quadrotor, tasked to follow a piecewise-linear plan (see, Example 1). The actions represent possible combinations of pitch, roll, and thrust acceleration. This is a complex continuous-time system (see Appendix B.1 for full details). The policies for such high-dimensional systems are typically approximated by a learned model, e.g., a neural network (Royo et al., 2019). We train a decision-tree policy of depth \(10\) imitating the neural network from (Ivanov et al., 2019).

Figure 4 shows the set of reachable states. Ivanov et al. (2019) verified the neural-network policy, for which they had to split the initial set into \(16\) subsets to tame the approximation error. Computing the reachable states took between 10 and 59 minutes for each subset. Our method can be applied to the full initial set directly and verifies the system in \(6.5\) minutes.

### Evaluation on Decision Trees for Classic Nonlinear Control Problems

Next we study three classical control systems, for which we trained small, interpretable decision trees (see Table 1). Small decision trees are often sufficient for optimality (Vos and Verwer, 2023).

Cart-Pole System.We consider the cart-pole system (Barto et al., 1983). A description is given in Appendix B.2. The goal is for the pole to remain vertically stable within an angle of \( 0.06^{}\). This system is challenging because of quick alternations in the control action. In Figure 5(a), we show the reachable states in the \(\)/\(\) projection together with the decision boundaries (e.g., the policy moves the cart to the left in the green region). The analysis terminates in 40 seconds and proves that the blue dashed line \(=0.06\) is not exceeded. Furthermore, the fixpoint check allows to generalize the results to infinite time; thus we can conclude that the policy is able to balance the pole forever.

Figure 4: Reachable states (red) and simulations (colored) for the quadrotor system. The initial states are shown in yellow on the left, the goal region is shown in blue at the top, the reference plan is shown in brown, and the dashed blue lines mark the safety corridor.

[MISSING_PAGE_EMPTY:9]

starts, and prints errors about numerical instability. This demonstrates that our algorithm is the first _feasible_ solution to the reach-avoid problem for DTCS.

Our algorithm exploits the decision-tree structure to only explore the feasible automaton transitions (most of the time this is just one). Furthermore, given the periodic control policy, we only have to check the transitions at specific time points (an observation we already made in earlier work (Forets et al., 2020)). Moreover, since we focus on axis-aligned predicates, interval enclosures are often sufficient. Finally, often only one branch of the decision tree is relevant, which allows us to ignore the complement branch and avoid unnecessary calculations. Even if several leaves of the decision tree are reached, these may still all be annotated with the same control action. In that case we do not have to bisect the set (which avoids the main source of approximation error).

The other tool views the automaton as a black-box model and thus cannot make use of this structure; instead it needs to perform many intersection operations, which are expensive and typically force to use a more complex set representation. These structural insights make our analysis not only more efficient but also more precise in practice because general hybrid-automata tools would typically approximate these operations.

## 5 Conclusion

In this paper, we studied the reach-avoid problem for continuous-time and discrete-time dynamical systems controlled by a decision tree. The problem is undecidable for nonlinear systems, and we showed undecidability even for the simplest dynamics as well as **PSPACE**-completeness in the bounded-time setting. We proposed the first practical algorithm to solve this problem in continuous time. The abstract algorithm is sound and, for simple systems, complete. We implemented the algorithm for nonlinear systems and decision trees with axis-aligned predicates. Our evaluation shows that the algorithm is precise and performant on typical problems. Our approach enriches the verification toolset for machine-learning based systems and opens novel cross-community research challenges. Our approach lends itself to visualization and can serve for further analysis and refinement of decision trees, which themselves are interpretable surrogates for black-box policies.

Coming to the limitations of our approach, we have only considered time-invariant systems. While the algorithms are general, the fixpoint check we used does not apply to time-varying systems. In our experiments, with the exception of the quadrotor, we focused on small decision trees. We note that the size of the decision tree is not necessarily a good measure for complexity. Multiple leaves may share the same action, and some leaves may not be used at all during the execution. The main impact on the verification method, in our experience, is the number of times the decision boundaries are partially crossed by the reachable states (after a time step). Furthermore, the control systems we verified in the evaluation, while nontrivial from a verification perspective, have relatively simple control tasks where a decision tree is not required. We plan to investigate how our method performs on systems with more challenging control tasks, e.g., the cart/pole system starting with the pole hanging downward (which we were not able to verify in a preliminary attempt).

In future work we will also study how the analysis can be improved both in terms of precision and scalability. For precision, we plan to employ set representations that are closed under bisection, e.g., constrained polynomial zonotopes (Kochdumper and Althoff, 2023), which generalize Taylor models. For scalability, we aim to improve the fixpoint check using simulation-based heuristics. Another natural direction is to apply the approach to learning a safe decision-tree policy, for which methods to compute underapproximations in order to refute unsafe models would be useful. Finally, our recent algorithm to synthesize a safety shield for policies of systems with complex hybrid dynamics (Brorholt et al., 2023) only detects discrete-time safety violations; hence we aim to find synergies with the method presented in this paper.

Acknowledgements.We are grateful for the anonymous reviewers' helpful comments to improve the paper and suggesting the swing-up cart/pole experiment as future challenge. Anna Lukina thanks Mustafa Mert Celikok and Alexandru Babeanu for their timely feedback. This research was partly supported by DIREC - Digital Research Centre Denmark under reference number 9142-0001B and the Villum Investigator Grant S4OS under reference number 37819.