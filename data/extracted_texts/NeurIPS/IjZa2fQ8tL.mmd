# StableFDG: Style and Attention Based Learning for Federated Domain Generalization

Jungwuk Park

KAIST

savertm@kaist.ac.kr

&Dong-Jun Han

Purdue University

han762@purdue.edu

&Jinho Kim

SK Hynix

jinho123.kim@sk.com

Shiqiang Wang

IBM Research

wangshiq@us.ibm.com

&Christopher G. Brinton

Purdue University

cgb@purdue.edu

&Jaekyun Moon

KAIST

jmoon@kaist.edu

Authors contributed equally to this work.

###### Abstract

Traditional federated learning (FL) algorithms operate under the assumption that the data distributions at training (source domains) and testing (target domain) are the same. The fact that domain shifts often occur in practice necessitates equipping FL methods with a domain generalization (DG) capability. However, existing DG algorithms face fundamental challenges in FL setups due to the lack of samples/domains in each client's local dataset. In this paper, we propose StableFDG, a _style and attention based learning strategy_ for accomplishing federated domain generalization, introducing two key contributions. The first is style-based learning, which enables each client to explore novel styles beyond the original source domains in its local dataset, improving domain diversity based on the proposed style sharing, shifting, and exploration strategies. Our second contribution is an attention-based feature highlighter, which captures the similarities between the features of data samples in the same class, and emphasizes the important/common characteristics to better learn the domain-invariant characteristics of each class in data-poor FL scenarios. Experimental results show that StableFDG outperforms existing baselines on various DG benchmark datasets, demonstrating its efficacy.

## 1 Introduction

Federated learning (FL) has now become a key paradigm for training a machine learning model using local data of distributed clients . Without directly sharing each client's data to the third party, FL enables the clients to construct a global model via collaboration. However, although FL has achieved remarkable success, the underlying assumption of previous works is that the data distributions during training and testing are the same. This assumption is not valid in various scenarios with domain shifts; for example, although the FL clients only have data samples that belong to the source domains (e.g., images on sunny days and rainy days), the trained global model should be also able to make reliable predictions for the unseen target domain (e.g., images on snowy days). Therefore, in practice, FL methods have to be equipped with a domain generalization (DG) capability.

Given the source domains in the training phase, DG aims to construct a model that has a generalization capability to predict well on an unseen target domain. Various DG methods have been proposed in a centralized setup . However, directly applying centralized DG schemes to FL can potentially restrict the model performance since each client has limited numbers of data samples and styles in its local dataset. The local models are unable to capture the domain-invariant characteristics due to lack of data/styles in individual clients.

Although several researchers have recently focused on DG for FL [25; 2; 35; 28], they still do not directly handle the fundamental issues that arise from the lack of data and styles (which represent domains) in individual FL clients. These performance limitations become especially prevalent when federating complex DG datasets having large style shifts between domains or having backgrounds unrelated to the prediction of class, as we will see in Sec. 4. Despite the practical significance of federated DG, this field is still in an early stage of research and remains a great challenge.

**Contributions.** In this paper, we propose StableFDG, a _style and attention based learning strategy_ tailored to federated domain generalization. StableFDG tackles the fundamental challenges in federated DG that arise due to the lack of data/styles in each FL client, with two novel characteristics:

* We first propose _style-based learning_, which exposes the model of each FL client to various styles beyond the source domains in its local dataset. Specifically, we (i) design a style-sharing method that can compensate for the missing styles in each client by sharing the style statistics with other clients; (ii) propose a style-shifting strategy that can select the best styles to be shifted to the new style to balance between the original and new styles; and (iii) develop style-exploration to further expose the model to a wider variety of styles by extrapolating the current styles. Based on these unique characteristics, our style-based learning handles the issue of the lack of styles in each FL client, significantly improving generalization capability.
* We also propose an _attention-based feature highlighter_, which enables the model to focus only on the important/essential parts of the features when making the prediction. Our key contribution here is to utilize an attention module to capture the similarities between the features of data samples in the same class (regardless of the domain), and emphasize the important/common characteristics to better learn the domain-invariant features. Especially in data-poor FL scenarios where models are prone to overfitting to small local datasets, our new strategy provides advantages for complicated DG tasks by removing background noises that are unrelated to class prediction and focusing on the important parts.

The two suggested schemes work in a complementary fashion, each providing one necessary component for federated DG: our style-based learning improves domain diversity, while the attention-based feature highlighter learns domain-invariant characteristics of each class. Experiments on various FL setups using DG benchmarks confirm the advantage of StableFDG over (i) the baselines that directly apply DG methods to FL and (ii) the baselines that are specifically designed for federated DG.

## 2 Related Works

**Federated learning.** FL enables multiple clients to train a shared global model or personalized models without directly sharing each client's data with the server or other clients. FedAvg  is a well-known early work that sparked interest in FL in the machine learning community. Since then, various FL strategies have been proposed to handle the communication burden issue [31; 9], data heterogeneity issue [20; 12], adversarial attack issue [34; 29; 7], and personalization issue [3; 18; 5]. However, existing FL methods do not have generalization capabilities to predict well on an arbitrary unseen domain. In other words, most prior FL methods are not able to handle the DG problem.

**Domain generalization.** DG is one of the emerging fields in the AI community due to its significance in practical applications. Existing DG strategies based on domain alignment [17; 24; 23], meta-learning [16; 4; 15; 37] and style/data-augmentation [39; 21; 36; 38] have shown great success in a centralized setup where the whole dataset is accessible during training. Recently, style-augmentation methods [39; 21; 36] including MixStyle  and DSU  are receiving considerable attention due to their high compatibility with various tasks and model architectures. However, although existing DG solutions work well in a centralized setup, they face challenges in FL scenarios; in data-poor FL setups, prior works achieve relatively low performance due to the lack of data samples or domains in each client, resulting in compromised generalization capabilities. The applications of meta-learning or domain alignment methods could be also limited when domain labels are not accessible in each client. Compared to these prior works focusing on a centralized DG setup, we develop a style and attention based DG strategy tailored to FL. The advantages of our methodology against these baselines are confirmed via experiments in Sec. 4.

**Federated domain generalization.** Only a few recent works [25; 2; 35; 28] have focused on the intersection of FL and DG. Based on the training set distributed across clients, the goal of these works is to construct a global model that is generalizable to an unseen target domain. In , the authorsproposed to share the style statistics across different clients that could be utilized during local updates. However, this method does not utilize the styles beyond the clients' domains and shows limited performance in specific datasets where the data samples are not well separated in the style space. Moreover, it increases the computation and memory costs for generating new images in each client using a pretrained style transfer. In our work, we handle these issues via style exploration and the attention-based feature highlighter to train the model with novel styles while capturing the important knowledge of each class. In , the authors proposed to exchange distribution information among clients based on Fourier transform, especially targeting image segmentation tasks for medical data. The authors of  proposed a strategy for federated DG based on the domain-invariant feature extractor and an ensemble of domain-specific classifiers. Two regularization losses are developed in  aiming to learn a simple representation of data during client-side local updates.

Although these prior works [25; 35; 28] improve DG performance, the authors do not directly handle the issues that arise from limited styles and data in each client. Compared to these works, we take an orthogonal approach based on style and attention based learning to effectively learn style-invariant features while capturing common knowledge of classes. Experimental results in Sec. 4 reveals that our scheme outperforms existing ideas tackling federated DG in practical data distribution setups.

## 3 Proposed StableFDG Algorithm

**Problem formulation.** We consider a FL setup with \(N\) clients distributed over the network. Let \(_{n}=\{(x_{i}^{n},y_{i}^{n})\}_{i=1}^{_{n}}\) be the local dataset of the \(n\)-th client, which consists of \(_{n}\) pairs of data sample \(x\) and the corresponding label \(y\). Here, each client \(n\) can have data samples from either a single or multiple source domains in its local dataset \(_{n}\). Previous works on FL focus on constructing a global model that predicts well on the overall dataset \(=\{_{1},_{2},,_{N}\}\) or personalized models that work well on individual local datasets \(_{n}\). In contrast to the conventional FL setup, given the overall dataset (or source domains) \(\), the goal of this work is to construct a shared global model \(\) that has a generalization capability to predict well on any unseen target domain \(\).

**Background.** Let \(s^{C H W}\) be the feature of a sample which is obtained at a specific layer of the neural network. Here, \(C\), \(H\), \(W\) denote the dimensions of channel, height, width, respectively. Given the feature \(s\) of a specific data sample, the channel-wise mean \((s)^{C}\) and the channel-wise standard deviation \((s)^{C}\) can be written as

\[(s)_{c}=_{h=1}^{H}_{w=1}^{W}s_{c,h,w},\ ^{2}(s)_{c}=_{h=1}^{H}_{w=1}^{W}(s_{c,h,w}-(s)_{c })^{2},\] (1)

respectively. These variables are known as _style statistics_ as they contain style information of an image in CNNs . Based on these style statistics, various style-augmentation schemes such as MixStyle  or DSU  have been proposed in the literature targeting a centralized setup.

**Overview of approach.** Fig. 1 provides an overview of the problem setup and our StableFDG algorithm. As in conventional FL, the training process consists of multiple global rounds, which we index \(t=1,2,,T\). In the beginning of round \(t\), a selected set of clients download the current global model \(_{t}\) from the server. Before local training begins, each client \(n\) computes its own style information \(_{n}=[_{n},_{n},_{n}(),_{n}()]\) using its local dataset according to (2), which will be clarified soon. This information is sent to the server, and the server shares these information with other clients to compensate for the lack of styles or domains in each client. During the local update process, each client selectively shifts the styles of the original data in the mini-batch to the new style (received from the server) via adaptive instance normalization (AdaIN) , to improve domain diversity (inner box in Fig. 1(b)). After this style sharing and shifting process, each client performs style exploration via feature-level oversampling to further expose the model to novel styles beyond the current source domains of each client (outer box in Fig. 1(b)). Finally, at the output of the feature extractor, we apply our attention-based

Figure 1: Overview of our problem setup and algorithm for federated domain generalization. Each client can have a single source domain as described in Fig. 1, or even multiple source domains in its local dataset.

feature highlighter to extract common/important feature information within each class and emphasize them for better generalization (Fig. 3). When local updates are finished, the server aggregates the client models and proceeds to the next round.

In the following, we first describe our style-based learning in Sec. 3.1, which determines how the style information is shared and utilized in each FL client, and how style exploration is conducted, to overcome the lack of styles in each client. In Sec. 3.2, we show how attention mechanism is utilized to capture the essential characteristics of each class for better generalization in data-poor FL setups.

### Style-based Learning for Federated DG

The main components of our style-based learning are style-sharing, selective style-shifting, and style-exploration, each having its own role to handle the style limitation problem at each client. As illustrated in Fig. 2, this fundamental challenge of federated DG is not directly resolvable using existing style-augmentation DG methods that can only explore limited areas in the style-space.

**Step 1: Style information sharing.** Based on the data samples in its local dataset \(_{n}\), at a specific layer of the model, each client \(n\) computes the average of channel-wise means, \(_{n}\), and the variance of the channel-wise means, \(_{n}()\), as follows:

\[_{n}=}_{i=1}^{_{n}}(s_{i}^{n}),\ \ _{n}()=}_{i=1}^{_{n}}(_{n}-(s_{i}^{n}) )^{2},\] (2)

where \(s_{i}^{n}^{C H W}\) is the feature of the \(i\)-th sample in the \(n\)-th client's local dataset, and the square operation \(()^{2}\) works in an element-wise manner. Similarly, the average and the variance of channel-wise standard deviations are computed as \(_{n}=}_{i=1}^{_{n}}(s_{i}^{n})\), \(_{n}()=}_{i=1}^{_{n}}(_{n}- (s_{i}^{n}))^{2}\), respectively. Here, \(_{n}\) and \(_{n}\) represent the center of the style statistics of client \(n\), while \(_{n}()\) and \(_{n}()\) show how these style statistics of client \(n\) are distributed around the center. Now we define

\[_{n}=[_{n},_{n},_{n}(),_{n}()]\] (3)

as the _style information_ representing the domain identity of the \(n\)-th client in the style-space. Each client \(n\) sends \(_{n}\) to the server, and the server randomly shares the style information to other clients in a one-to-one manner; client \(n\) receives \(_{n^{}}\) that belongs to client \(n^{}\) (\(n n^{}\)) without overlapping with other clients. By compensating for the lack of styles in each FL client, this style-sharing process is the first step that provides an opportunity for each model to get exposed to new styles (blue region in Fig. 1(b)) beyond the client's original styles (orange region in Fig. 1(b)).

**Step 2: Selective style shifting.** Suppose client \(n\) received \(_{n^{}}\) from the server. Now the question is, how should each client utilize this additional style information during training to improve domain/style diversity? Our idea is to selectively shift the styles of the samples from the original style to the

Figure 2: **Proposed style-based learning strategy (Sec. 3.1):** Compared to existing style-based DG methods that rely on interpolation or style shift near the original style of each sample, our style-based learning (i) effectively utilizes other FL clients’ styles based on style sharing and shifting, and (ii) enables the model to further explore a wider style space via feature-level oversampling and extrapolation, handling the issue of domain-limited FL settings.

new style to effectively balance between the original/new source domains. To this end, given a mini-batch with size \(B\), each client runs \(k\)-means++ with \(k=B/2\) in the style-space for one iteration and selects \(B/2\) cluster centers. This enables each client to choose the \(B/2\) styles that are similar to the remaining \(B/2\) styles, so that the model can get exposed to new styles while not losing the performance on the original styles. The selected \(B/2\) samples keep their original styles, while for the remaining \(B/2\) samples, we shift the style of their feature \(s\) to the new style via AdaIN  as \(f(s)=(_{n^{}}+_{}_{n^{}}()) +(_{n^{}}+_{}_{n^{ }}())\), where \(f(s)\) is the new feature shifted from \(s\) and \(_{}(0,_{n}())\), \(_{}(0,_{n}())\) are the values sampled from normal distributions. Then, the mini-batch applied with new styles in \(_{n^{}}\) is forwarded to the next layer. The inner box in Fig. 1(b) shows how style shifting is performed in client \(n\) based on the new style information \(_{n^{}}\).

Overall, based on the shared style statistics in Step 1, our style shifting in Step 2 balances between the original source domain and the new source domain via \(k\)-means++ for better generalization, which cannot be achieved by previous methods in Fig. 1(a) that rely on interpolation or style-shift near the original style. In the following, we describe our style exploration that can further resolve the style-limitation problem based on feature-level oversampling and extrapolation.

**Step 3: Feature-level oversampling.** Let \(s^{n}^{B C H W}\) be a mini-batch of features in client \(n\) at a specific layer, obtained after Steps 1 and 2 above. Here, we oversample the features by the mini-batch size \(B\) in a class-balanced manner; the samples belonging to minority classes are compensated as balanced as possible up to size \(B\). For example, suppose that the number of samples for classes \(a\), \(b\), \(c\) are 3, 2, 1, respectively in the mini-batch. Using oversampling size of \(6\), we oversample by 1, 2, 3 data points for classes \(a\), \(b\), \(c\), respectively, to balance the mini-batch in terms of classes. Based on this, we obtain a new oversampled mini-batch \(^{n}\) with size \(B\), and concatenate it with the original mini-batch as follows: \(^{n}=[s^{n},^{n}]\). This not only mitigates the class-imbalance issue in each client but also provides a good platform for better style exploration; the oversampled features are utilized to explore a wider style-space beyond the current source domains, as we will describe in Step 4. The oversampling size can be adjusted depending on the clients' computation/memory constraints.

**Step 4: Style exploration.** In order to further expose the model to a wider variety of styles, we transfer the styles of tensors in \(^{n}\) (i.e., the set of oversampled features) to novel styles beyond the style of each client. Let \(^{n}_{i}\) be the feature of \(i\)-th sample in the oversampled mini-batch \(^{n}\). We obtain the new styles by extrapolating the original styles in \(^{n}\) around the average of channel-wise mean \(_{n}(^{n})\) and the average of standard deviations \(_{n}(^{n})\) computed on the concatenated mini-batch \(^{n}=[s^{n},^{n}]\) as

\[_{new}(^{n}_{i}) =(^{n}_{i})+((^{n}_{i})-_{ n}(s^{n})),\] (4) \[_{new}(^{n}_{i}) =(^{n}_{i})+((^{n}_{i})- _{n}(s^{n})),\] (5)

where \(\) is the _exploration level_. We perform AdaIN to shift the style of \(^{n}_{i}\) to the new style statistics \(_{new}(^{n}_{i})\) and \(_{new}(^{n}_{i})\). If \(=0\), the styles remain unchanged, and as \(\) increases, the styles are shifted farther from the center. The outer box in Fig. 1(b) describes the concept of our style exploration.

**Step 5: Style augmentation.** After style exploration, we can apply existing style-augmentation methods during training. In this work, we mix the style statistics of the entire samples in \(^{n}\) to generate diverse domains as in  as \(_{new}(^{n}_{i})=(^{n}_{i})+(1-) (^{n}_{j})\) and \(_{new}(^{n}_{i})=(^{n}_{i})+(1- )(^{n}_{j})\), where \(^{n}_{i}\) and \(^{n}_{j}\) are arbitrary two samples in \(^{n}\) and \(\) is a mixing parameter sampled from the beta distribution. Below, we wish to highlight two important points.

**Remark 1 (Privacy).** It is already well-known that there is an inherent clustering of samples based on their domains in the style-space, regardless of their labels . This indicates that label information is not contained in the style statistics, resolving privacy issues. Note that some prior works on federated DG  also adopt sharing style information between clients, but in different ways (see Sec. 2).

**Remark 2.** By enabling the model to explore a wider region in the style space based on the exploration level \(\), our style exploration in Step 4 is especially beneficial when the target domain is significantly far from the source domains (e.g., Sketch domain in PACS dataset). Existing style-based DG methods (e.g., MixStyle, DSU) are ineffective in this case as they can explore only some limited areas near the original styles in each client (Fig. 1(a) vs. Fig. 1(b)), which leads to performance degradation especially in data-poor FL scenarios. It turns out that our scheme has significant performance improvements over these baselines even with a rather arbitrarily chosen \(\), as we will see in Sec. 4.3.

### Attention-based Feature Highlighter

In this subsection, we describe the second component of our solution, the attention-based feature highlighter, which operates at the output of the feature extractor to tackle the remaining challenge of federated DG: limited generalization in each client due to the lack of data. To handle this issue, we start from our key intuition that the images from the same class have inherently common characteristics regardless of domains to which they belong (e.g., Fig. 3). Based on this insight, we take advantage of attention to find the essential characteristics of images in the same class and emphasize them, which turns out to be very effective in data-poor FL scenarios.

**Attention score.** Consider the \(i\)-th data sample of client \(n\). Given the feature \(z_{i}^{n}^{C H W}\) obtained from the output of the feature extractor, we flatten it to a two-dimensional tensoro \(X_{i}^{C HW}\) with a size of \((C,HW)\), where we omit the client index \(n\) for notational simplicity. Now consider another \(X_{j}\) (\(j i\)) in a mini-batch that belongs to the same class as \(X_{i}\), where the domains of \(X_{i}\) and \(X_{j}\) can be either same or different. Inspired by the attention mechanism , we measure the spatial similarity \(S^{HW HW}\) between \(X_{i}\) and \(X_{j}\) as follows:

\[S:=(X_{i},X_{j})=(_{q}X_{j})^{T}(_{k}X_{i}),\] (6)

where \(_{q}^{d C}\), \(_{k}^{d C}\) are the learnable parameters trained to extract important information in each class from the given samples and \(d\) is the embedding size of queries \(Q=_{q}X_{j}\) and keys \(K=_{k}X_{i}\). Then, we reshape \(S^{HW HW}\) to \(S_{r}^{HW H W}\); the \((m,n)\)-th spatial feature (\(^{HW 1 1}\)) of \(S_{r}\) represents the similarity between the \((m,n)\)-th spatial feature of the key feature \(X_{i}\) and the overall spatial feature of the query feature \(X_{j}\). Then by taking the mean of \(S_{r}\) along the first dimension, we obtain the _attention score_\(a_{s}\), which represents how the spatial feature at each location of key \(X_{i}\) is similar to the overall features of query \(X_{j}\): \(a_{s}=(S_{r})^{H W}\). A higher score \(a_{s}\) indicates a higher similarity. Finally, we normalize the attention score through softmax function so that the total sum is one: \(a_{s}(a_{s})^{H W}\).

**Attention-based weighted averaging.** Based on the attention score, we take the weighted average of \(z_{i}^{C H W}\) to generate an attention feature \(A(z_{i})^{C}\) in which the important parts of the _key image_, having common characteristics with the _query image_ (in the same class), are emphasized:

\[A(z_{i})_{c}=_{h=1}^{H}_{w=1}^{W}(a_{s})_{h,w}(z_{i})_{c,h,w}.\] (7)

As shown in Fig. 3, this attention feature is concatenated with the last embedding feature (e.g., after the global average pooling in ResNet) before the classifier, and it goes through the classifier to compute the loss during training. One important thing to note is that \(_{q}\) and \(_{k}\) are trained so that the common features of query and key images become close in the embedding space while unimportant factors such as backgrounds are effectively distanced (i.e., less emphasized).

When implementing attention-based weighted averaging in practice, instead of directly adopting equation (6), we modify the similarity function using the query of its own as

\[_{}(X_{i},X_{j})=(X_{j}+ _{q}X_{i}}{2})^{T}(_{k}X_{i}),\] (8)

to avoid performance degradation when there is little commonality between key and query images. In other words, StableFDG takes advantage of both cross-attention and self-attention, enabling the model to extract and learn important characteristics across images (via cross-attention), and within the image (via self-attention). A more detailed analysis on (8) can be found in Appendix.

Figure 3: **Proposed attention-based feature highlighter (Sec. 3.2):** Our attention-based learning captures important characteristics within each class (regardless of the domain) for better generalization.

**Inference.** During testing, given a new test sample, we compute the spatial similarity of the test sample itself as \((X_{i},X_{i})\) based on self-attention, take the weighted average, and concatenate the features to make a prediction.

**Remark 3**.: It is interesting to note that we can adopt _self-attention_ during testing. This is because \(_{q}\) and \(_{k}\) are trained to capture the essential characteristics of each class, which enables the attention module to effectively find the important parts of individual samples via self-attention (e.g., see heat map visualization in Fig. 3). Moreover, with only 0.44% of additional model parameters for the attention module, this strategy turns out to be very effective in learning domain-invariant characteristics of classes in data-poor FL setups, handling the key challenge of federated DG.

### StableFDG

Finally, we put together StableFDG. In each FL round, the clients first download the global model from the server and perform style sharing, shifting, and exploration according to 3.1, which are done in the early layers of CNNs where the style information is preserved. Then, at the output of the feature extractor, attention-based weighted averaging is applied according to Sec. 3.2. These two components have their own roles and work in a complementary fashion to handle the challenging DG problem in FL; our style-based strategy is effective in improving the domain diversity, while our attention-based method can directly capture the domain-invariant characteristics of each class. After the local update process, the server aggregates the client models and proceeds to the next round.

**Remark 4** (Computational complexity).: The computational complexity of StableFDG depends on the oversampling size in Sec. 3.1 and the attention module size in Sec. 3.2, which could be controlled depending on the resource constraints of clients. We show in Sec. 4 that StableFDG achieves the state-of-the-art performance with (i) minimal oversampling size and (ii) negligible cost of attention module. A more detailed discussion on the computational complexity is in Appendix.

## 4 Experimental Results

### Experimental Setup

**Datasets.** We consider five datasets commonly adopted in DG literature: PACS , VLCS , Digits-DG , Office-Home , and DomainNet . PACS consists of 7 classes from 4 different domains, while VLCS contains 4 domains with 5 classes. Digits-DG is composed of 4 different digit datasets, MNIST , MNIST-M , SVHN , SYN , each corresponding to a single domain. Office-Home consists of 65 classes from 4 domains, while DomainNet has 345 classes from 6 domains. The DomainNet results are reported in Appendix.

**Data partitioning for FL.** When evaluating the model performance, we follow the conventional leave-one-domain-out protocol where one domain is selected as a target and the remaining domains are utilized as sources. Compared to the centralized setup, in FL, the source domains are distributed across the clients. We consider a setup with \(N=30\) clients and distribute the training set into two different ways: _single-domain data distribution_ and _multi-domain data distribution_ scenarios. In a single-domain setup, we let each client to have training data that belong to a single source domain. Since there are three different source domains during training (except DomainNet), the training data of each domain is distributed across 10 clients uniformly at random. In a multi-domain distribution setup, each client can have multiple domains, but the domain distribution within each client is heterogeneous. For each domain, we sample the heterogeneous proportion from Dirichlet distribution with dimension \(N=30\) and parameter of 0.5, and distribute the train samples of each domain to individual clients according to the sampled proportion. In Appendix, we also report the results with \(N=3\) following the settings of prior works in federated DG [2; 28].

**Implementation.** Following , we utilize ResNet-18 pretrained on ImageNet as a backbone while the results on ResNet-50 are reported in Sec. 4.3. The exploration level \(\) is set to 3 for all experiments regardless of datasets. For our attention module, we set the embedding size \(d\) of queries \(Q\) and keys \(K\) to 30, where \(Q\) and \(K\) matrices are extracted from the output of the last residual block using \(1 1\) convolution such that the channel size of each output is 30. When the attention module is applied, the input dimension of the classifier becomes twice as large since we concatenate the attention feature with the last embedding feature before the classifier. The number of additional model parameters for the attention module is only 0.44% of the entire model. FL is performed for 50 global rounds and we trained the local model for 5 epochs with a mini-batch size of 32. Among atotal of \(N=30\) clients, 10 clients participate in each global round. All reported results are averaged over three random seeds.

**Where to apply style-based modules.** Inspired by [39; 21], we apply our style-based modules with a probability of 0.5 at specific layers. In particular, style sharing and shifting are executed at the first residual block of ResNet with a probability 0.5, while the style exploration module is performed at the first or second or third residual blocks independently with probability 0.5 after style sharing/shifting.

**Baselines. (i) FL baselines:** First, we consider FedAvg  and FedBN , which are the basic FL baselines not specific to DG. **(ii) DG baselines applied to each FL client:** We apply MixStyle  during the local update process of each client and aggregate the model via FedAvg. Similarly, we also apply DSU  at each client and then perform FedAvg to compare with our work. **(iii) Federated DG baselines:** Among DG schemes tailored to FL, we implement the recently proposed CCST , FedDG , FedSR  and evaluate the performance. For a fair comparison, we reproduced all the baselines in accordance with our experimental setup. The _augmentation level_ in CCST, a hyperparameter that controls the amount of augmented images, is set to 3 as in the original paper . The hyperparameters in FedSR, that control the regularization losses, are tuned to achieve the best performance in our setup. Except for these, we adopted the parameter values in the original papers.

### Main Experimental Results

**Single-domain data distribution.** Table 1 shows our results in a single-domain data distribution setup. We have the following observations. Compared to the previous results provided in the centralized DG works [39; 21], the performance of each method is generally lower. This is due to the limited numbers of styles and data samples in each FL client, which restricts the generalization performance of individual client models. It can be seen that most of the baselines perform better than FedAvg and FedBN that do not tackle the DG problem. The proposed StableFDG achieves the best average accuracy for all benchmark datasets, where the gain is especially large in PACS having large shifts between domains. In contrast to our scheme, the prior works [2; 25; 28] targeting federated DG show marginal performance gains relative to FedAvg in our practical experimental setup with (i) more clients (which results in less data in each client) and (ii) partial client participations.

**Multi-domain data distribution.** In Table 2, we report the results in a multi-domain data distribution scenario. Compared to the results in Table 1, most of the schemes achieve improved performance in Table 2. This is because each client has multiple source domains, and thus providing a better platform for each client model to gain generalization ability. The proposed StableFDG still performs the best, demonstrating the effectiveness of our style and attention based learning strategy for federated DG.

Table 1: **Main result 1 (single-domain data distribution):** Each client has one source domain in its local data. The proposed StableFDG achieves the best generalization, underscoring its effectiveness.

### Ablation Studies and Discussions

**Effect of each component.** To see the effect of each component of StableFDG, in Table 3, we apply our style-based learning and attention-based learning one-by-one in a multi-domain data distribution setup using PACS. We compare our results with style-augmentation DG baselines, MixStyle  and DSU . By applying outperforms prior style-augmentation methods. Furthermore, by adopting only one of the proposed components, our scheme performs better than all the baselines in Table 2. Additional ablation studies using other datasets are reported in Appendix.

**Effect of hyperparameters.** In DG setups, it is generally impractical to tune the hyperparameter using the target domain, because there is no information on the target domain during training. Hence, we used a fixed exploration level \(=3\) throughout all experiments without tuning. In Fig. 4, we observe how the hyperparameters affect the target domain performance on PACS. In the first plot of Fig. 4, if \(\) is too small, the performance is relatively low since the model is not able to explore novel styles beyond the client's source domains. If \(\) is too large, the performance could be slightly degraded because the model would explore too many redundant styles. The overall results show that StableFDG still performs better than the baselines with an arbitrarily chosen \(\), which is a significant advantage of our scheme in the DG setup where hyperparameter tuning is challenging. The second plot of Fig. 4 shows how the oversampling size (introduced in Step 3 of Sec. 3.1) affects the DG performance. StableFDG still outperforms the baseline with minimal oversampling size, indicating that other components of our solution (style sharing/shifting and attention-based components) are already strong enough. The size of oversampling can be determined depending on the clients' computation/memory constraints, with the cost of improved generalization.

**Performance in a centralized setup.** Although our scheme is tailored to federated DG, the ideas of StableFDG can be also utilized in a centralized setup. In Table 3(a), we study the effects of our style and attention based strategies in a centralized DG setting using PACS, while the other settings are

Table 2: **Main result 2 (multi-domain data distribution): Each client has multiple source domains in its local dataset. The results are consistent with the single-domain scenario in Table 1.**

Figure 4: Effects of exploration level \(\) (left) and oversampling size (right) in StableFDG.

Table 3: Effect of each component of StableFDG.

the same as in the FL setup. The results demonstrate that the proposed ideas are not only specific to data-poor FL scenarios but also have potentials to be utilized in centralized DG settings.

**Performance with ResNet-50.** In Table 3(b), we also conduct experiments using ResNet-50 on PACS dataset in the multi-domain data distribution scenario. Other settings are exactly the same as in Table 2. The results further confirm the advantage of StableFDG with larger models.

**Attention score visualization.** To gain an intuitive understanding of the effect of our attention-based learning, in Fig. 5, we visualize the score maps obtained via our attention module at testing. The score maps are interpolated so that it has the same size as the original image. A warmer color indicates a higher value. It can be seen that our attention module highlights important parts of each class even in the presence of unrelated backgrounds.

**Additional results.** Other implementation details, comprehensive ablation studies for each component, discussions on complexity, and results on DomainNet dataset are in Appendix.

## 5 Conclusion

Despite the practical significance, the field of federated domain generalization is still in the early stage of research. In this paper, we proposed StableFDG, a new training strategy tailored to this unexplored area. Our style-based strategy enables the model to get exposed to various novel styles beyond each client's source domains, while our attention-based method captures and emphasizes the important/common characteristics of each class. Extensive experimental results confirmed the advantage of our StableFDG for federated domain generalization with data-poor FL clients.

**Limitations and future works.** StableFDG requires 0.45 % more communication load compared to FedAvg for sharing the attention module and style statistics, which is the cost for a better DG performance. Further developing our idea to tailor to centralized DG and extending our attention strategy to segmentation/detection DG tasks are also interesting directions for future research.