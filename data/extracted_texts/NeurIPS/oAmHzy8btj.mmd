# Exact Random Graph Matching with Multiple Graphs

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

This work studies fundamental limits for recovering the underlying correspondence among _multiple_ correlated random graphs. We identify a necessary condition for any algorithm to correctly match all nodes across all graphs, and propose two algorithms for which the same condition is also sufficient. The first algorithm employs global information to simultaneously match all the graphs, whereas the second algorithm first partially matches the graphs pairwise and then combines the partial matchings by transitivity. Both algorithms work down to the information theoretic threshold. Our analysis reveals a scenario where exact matching between two graphs alone is impossible, but leveraging more than two graphs allows exact matching among all the graphs. Along the way, we derive independent results about the \(k\)-core of Erdos-Renyi graphs.

## 1 Introduction

The information age has ushered an abundance of correlated networked data. For instance, the network structure of two social networks such as Facebook and Twitter is correlated because users are likely to connect with the same individuals in both networks. This wealth of correlated data presents both opportunities and challenges. On one hand, information from various datasets can be combined to increase the fidelity of data - translating to better performance in downstream learning tasks. On the other hand, the interconnected nature of this data also raises privacy and security concerns. Linkage attacks, for instance, exploit correlated data to identify individuals in an anonymized network by linking to other sources . This poses a significant threat to user privacy.

Graph matching is the problem of recovering the underlying latent correspondence between correlated networks. The problem finds many applications in machine learning: de-anonymizing social networks , identifying similar functional components between species by matching their protein-protein interaction networks , object detection  and tracking  in computer vision, and textual inference for natural language processing . In most applications of interest, data is available in the form of _several_ correlated networks. For instance, social media users are active each month on 6.7 social platforms on average . Similarly, reconciling protein-protein interaction networks among _multiple_ species is an important problem in computational biology . As a first step toward this objective, many research works have studied the problem of matching _two_ correlated graphs.

### Related Work

The theoretical study of graph matching algorithms and their performance guarantees has primarily focused on Erdos-Renyi (ER) graphs. Pedarsani and Grossglauser  introduced the subsampling model to generate two such correlated graphs. The model entails twice subsampling each edge independently from a parent ER graph to obtain two sibling graphs, both of which are marginally ER graphs themselves. The goal is then to match nodes between the two graphs to recover theunderlying latent correspondence. This has been the framework of choice for many works that study graph matching. For example, Cullina and Kiyavash studied the problem of _exactly matching_ two ER graphs, where the objective is to match _all_ vertices correctly . They identified a threshold phenomenon for this task: exact recovery is possible if the problem parameters are above a threshold, and impossible otherwise. Subsequently, threshold phenomena were also identified for _partial_ graph matching between ER graphs - where the objective is to match only a positive fraction of nodes . The case of almost-exact recovery - where the objective is to match all but a negligible fraction of nodes - was studied by Cullina and co-authors: a necessary condition for almost exact recovery was identified, and it was shown that the same condition is also sufficient for the _\(k\)-core estimator_; the estimator is described formally in Section 3. This estimator proved useful to uncover the fundamental limits for graph matching in other contexts such as the stochastic block model  and inhomogeneous random graphs . Ameen and Hajek  showed some robustness properties of the \(k\)-core estimator in the context of matching ER graphs under node corruption. The estimator plays an important role in the present work as well.

A sound understanding of ER graphs inspires algorithms for real-world networks. Various _efficient_ algorithms have been proposed, including algorithms based on the spectrum of the graph adjacency matrices , node degree and neighborhood based algorithms  as well as algorithms based on iterative methods  and counting subgraphs . Some of these are discussed in Section 5 in relation to the present work.

Incorporating information from multiple graphs to match them has been recognized as an important research direction, for instance in the work of Gaudio and co-authors . To our knowledge, the only other papers to consider matchings among multiple graphs are the works of Josephs and co-authors , and of Racz and Sridhar . However, these works have different objectives and are not concerned with the fundamental limits for matching \(m\) graphs. In fact, both works note that it is possible to exactly match \(m\) graphs whenever it is possible to exactly match any two graphs by pairwise matching all the graphs exactly. In contrast, we show that under appropriate conditions, it is possible to exactly match \(m\) ER graphs even when no two graphs can be pairwise matched exactly.

ContributionsIn this work, we investigate the problem of combining information from _multiple_ correlated networks to boost the number of nodes that are correctly matched among them. We consider the natural generalization of the subsampling model to generate \(m\) correlated random graphs, and identify a threshold such that it is impossible for any algorithm to match all nodes correctly across all graphs when the problem parameters are below this threshold. Conversely, we show that exact recovery is possible above the threshold. This characterization generalizes known results for exact graph matching when \(m=2\). Subsequently, we show that there is a region in parameter space for which exactly matching any two graphs is impossible using only the two graphs, and yet exact graph matching is possible among \(m>2\) graphs using all the graphs.

We present two algorithms and prove their optimality for this task. The first algorithm matches all \(m\) graphs simultaneously based on global information about the graphs. In contrast, the second algorithm first _pairwise_ matches graphs, and then combines them to match all nodes across all graphs. We show that both algorithms correctly match all the graphs all the way down to the information theoretic threshold. Finally, we illustrate through simulation that our subroutine to combine information from pairwise comparisons between networks works well when paired with efficient algorithms for graph matching. Our analysis also yields some theoretical results about the \(k\)-core of ER graphs that are of independent interest.

## 2 Preliminaries and Setup

NotationIn this work, \(G(n,p)\) denotes that the graph \(G\) is sampled from the Erdos-Renyi distribution with parameters \(n\) and \(p\), i.e. \(G\) has \(n\) nodes and each edge is independently present with probability \(p\). For a graph \(G\), we denote the set of its vertices by \(V V(G)\) and its edges by \(E(G)\). The _edge status_ of each vertex pair \(\{i,j\}\) with \(i j\) is denoted by \(G\{i.j\}\), so that \(G\{i,j\}=1\) if \(\{i,j\} E(G)\) and \(G\{i,j\}=0\) otherwise. The degree of a node \(v\) in graph \(G\) is denoted \(_{G}(v)\). Let \(\) denote a permutation on \(V(G)=\{1,,n\}\). For a graph \(G\), denote by \(G^{}\) the graph obtained by permuting the nodes of \(G\) according to \(\), so that

\[G\{i,j\}=G^{}\{(i),(j)\}\ \ i,j V(G)i j.\]

Standard asymptotic notation \((O(),o(),)\) is used throughout and it is implicit that \(n\).

Subsampling modelConsider the subsampling model for correlated random graphs , which has a natural generalization to the setting of \(m\) graphs. In this model, a parent graph \(G\) is sampled from the Erdos-Renyi distribution \((n,p)\). The \(m\) graphs \(G_{1},G_{2}^{},,G_{m-1}^{},G_{m}^{}\) are obtained by independently subsampling each edge from \(G\) with probability \(s\). Finally, the graphs \(G_{2},,G_{m}\) are obtained by permuting the nodes of each of the graphs \(G_{2}^{},,G_{m}^{}\) respectively according to independent permutations \(_{12}^{*},,_{1m}^{*}\) sampled uniformly at random from the set of all permutations on \([n]\), i.e.

\[G_{j}=(G_{j}^{})^{_{ij}^{*}}\ j\{2,,m\}.\]

Figure 1 illustrates this process of obtaining correlated graphs using the subsampling model. In this work, we are interested in the setting where \(s\) is constant and \(p=C(n)/n\) for some \(C>0\).

**Objective 1**.: _Determine conditions on parameters \(C\), \(s\) and \(m\) so that given correlated graphs \(G_{1},,G_{m}\) from the subsampling model, it is possible to exactly recover the underlying correspondences \(_{12}^{*},,_{1m}^{*}\) with probability \(1-o(1)\)._

Stated thus, the underlying correspondences use the graph \(G_{1}\) as a reference. Thus, for ease of notation, we will use \(G_{1}\) and \(G_{1}^{}\) interchangeably. Note that the underlying correspondence between all the graphs is fixed upon fixing \(_{12}^{*},,_{1m}^{*}\): for any two graphs \(G_{i}\) and \(G_{j}\), their underlying correspondence is given by \(_{ij}^{*}:=_{1j}^{*}(_{1i}^{-})^{-1}\).

Formally, a _matching_\((_{12},,_{1m})\) is a collection of injective functions with domain \((_{1i}) V\) for each \(i\), and co-domain \(V\). An _estimator_ is simply a mechanism to map any collection of graphs \((G_{1},,G_{m})\) to a matching. We say that an estimator _completely_ matches the graphs if the output mappings \(_{12},_{1m}\) are all complete, i.e. they are all permutations on \(\{1,,n\}\).

## 3 Main Results and Algorithm

This section presents necessary and sufficient conditions to meet Objective 1.

**Theorem 2** (Impossibility).: _Let \(G_{1},,G_{m}\) be correlated graphs obtained from the subsampling model with parameters \(C\) and \(s\), and let \(_{12}^{*},,_{1m}^{*}\) denote the underlying latent correspondences between \(G_{1}\) and \(G_{2},,G_{m}\) respectively. Suppose that_

\[Cs(1-(1-s)^{m-1})<1.\]

_The output \(_{12},,_{1m}\) of any estimator satisfies_

\[(_{12}=_{12}^{*},\,_{13}=_{13} ^{*},,\,_{1m}=_{1m}^{*})=o(1).\]

Figure 1: Illustration of obtaining \(m\) correlated graphs from the subsampling model

Theorem 2 implies that the condition \(Cs(1-(1-s)^{m-1}>1\) is a necessary condition to exactly match \(m\) graphs with probability bounded away from \(0\). We show that this condition is also sufficient to exactly match \(m\) graphs with probability going to \(1\).

**Theorem 3** (Achievability).: _Let \(G_{1},,G_{m}\) be correlated graphs obtained from the subsampling model with parameters \(C\) and \(s\), and let \(_{12}^{*},,_{1m}^{*}\) denote the underlying latent correspondences between \(G_{1}\) and \(G_{2},,G_{m}\) respectively. Suppose that_

\[Cs(1-(1-s)^{m-1})>1.\]

_There is an estimator whose output \(_{12},,_{1m}\) satisfies_

\[(_{12}=_{12}^{*},\;_{13}=_{13}^ {*},,\;_{1m}=_{1m}^{*})=1-o(1).\]

Theorems 2 and 3 together characterize the threshold for exact recovery. A few remarks are in order.

1. For \(m=2\), the condition \(Cs(1-(1-s)^{m-1})>1\) reduces to \(Cs^{2}>1\), which is known to be necessary and sufficient for exactly matching two graphs .
2. For any \(m>2\), there is a non-empty region in the parameter space defined by \[Cs(1-(1-s)^{m-1})>1>Cs^{2}.\] For any \(C\) and \(s\) in this region, it is impossible to exactly match any two graphs \(G_{i}\) and \(G_{j}\) without using the other \(m-2\) graphs as side information. Upon using them, however, it is possible to exactly match all nodes across the \(m\) graphs. This is illustrated in Figure 2.

### Algorithms for exact recovery

For any two graphs \(H_{1}\) and \(H_{2}\) on the same vertex set \(V\), denote by \(H_{1} H_{2}\) their _union graph_ and by \(H_{1} H_{2}\) their _intersection graph_. An edge \(\{i,j\}\) is present in \(H_{1} H_{2}\) if it is present in either \(H_{1}\) or \(H_{2}\). Similarly, the edge is present in \(H_{1} H_{2}\) if it is present in both \(H_{1}\) and \(H_{2}\).

A natural starting point is to study the maximum likelihood estimator (MLE) because it is optimal. To that end, we compute the log-likelihood function; the details are deferred to Appendix A.

**Theorem 4**.: _Let \(_{12},,_{1m}\) denote a collection of permutations on \(\{1,,n\}\). Then_

\[(G_{1},,G_{m}_{12}^{*}=_{12},,_{1 m}^{*}=_{1m})-|E(G_{1} G_{2}^{ _{12}} G_{m}^{_{1m}})|,\]

_where const. depends only on \(p,s\) and \(G_{1},,G_{m}\)._

Theorem 4 reveals that the MLE for exactly matching \(m\) graphs has a neat interpretation: simply pick \(_{12},,_{1m}\) to minimize the number of edges in the corresponding union graph. This is presented as Algorithm 1. Despite this nice interpretation of the MLE, its analysis is quite cumbersome. We instead present and analyze a different estimator, presented as Algorithm 2.

Figure 2: Regions in parameter space. _Orange_: Exactly matching \(m\) graphs is impossible even with \(m\) graphs. _Blue_: Exactly matching \(2\) graphs is possible with \(2\) graphs. _Striped_: Impossible to match \(2\) graphs using only the \(2\) graphs, but possible using \(m\) graphs as side information.

Algorithm 2 runs in two steps: In step 1, the \(k\)-core estimator, for a suitable choice of \(k\), is used to pairwise match all the graphs. For any \(i\) and \(j\), the \(k\)-core estimator selects a permutation \(_{ij}\) to maximize the size of the \(k\)-core1 of \(G_{i} G_{j}^{_{ij}}\). It then outputs a matching \(_{ij}\) by restricting the domain of \(_{ij}\) to \(_{k}(G_{i} G_{j}^{_{ij}})\). These matchings \(_{ij}\) need not be complete - in fact, each of them is a partial matching with high probability whenever \(Cs^{2}<1\). In step 2, these partial matchings are _boosted_ as follows: If a node \(v\) is unmatched between two graphs \(G_{i}\) and \(G_{j}\), then search for a sequence of graphs \(G_{i},G_{k_{1}},,G_{k_{}},G_{j}\) such that \(v\) is matched between any two consecutive graphs in the sequence. If such a sequence exists, then extend \(_{i,j}\) to include \(v\) by transitively matching it from \(G_{i}\) to \(G_{j}\).

In Section 4.2, we show that Algorithm 2 correctly matches all nodes across all graphs with probability \(1-o(1)\), whenever the necessary condition \(Cs(1-(1-s)^{m-1})>1\) holds. We remark that this also implies that Algorithm 1 succeeds under the same condition, because the MLE is optimal. Note that the MLE selects all permutations \(_{12},,_{1m}\)_simultaneously_ based on their union graph. In contrast, Algorithm 2 only ever makes _pairwise_ comparisons between graphs. Perhaps surprisingly, it turns out that this is sufficient for exact recovery. An analysis of Algorithm 2 is presented in Section 4. Along the way, independent results of interest on the \(k\)-core of Erdos-Renyi graphs are obtained.

Proof Outlines and Key Insights

### Impossibility of exact graph matching (Theorem 2)

This result has a simple proof following a genie-aided converse argument. The idea is to reduce the problem to that of matching two graphs by providing extra information to the estimator.

Proof of Theorem 2.: If the correspondences \(_{12}^{*},,_{1,m-1}^{*}\) were provided as extra information to an estimator, then the estimator must still match \(G_{m}\) with the union graph \(G_{1}^{} G_{2}^{} G_{m-1}^{}\). This can be viewed as an instance of matching two graphs obtained by _asymmetric_ subsampling: the graph \(G_{m}\) is obtained from a parent graph \(G(n,C(n)/n)\) by subsampling each edge independently with probability \(s_{1}:=s\), and the graph \(_{m-1}:=G_{1}^{} G_{2}^{} G_{m-1}^ {}\) is obtained from \(G\) by subsampling each edge independently with probability \(s_{2}:=1-(1-s)^{m-1}\). Cullina and Kiyavash studied this model for matching two graphs: Theorem 2 of  establishes that matching \(G_{m}\) and \(_{m-1}\) is impossible if \(Cs_{1}s_{2}<1\), or equivalently if \(Cs(1-(1-s)^{m-1})<1\). 

### Achievability of exact graph matching (Theorem 3)

Algorithm 2 succeeds if both step 1 and step 2 succeed, i.e.

1. Each instance of pairwise matching using the \(k\)-core estimator is correct on its domain, i.e. \[_{ij}(v)=_{ij}^{*}(v)\  v(_{ ij}),\  i,j.\]
2. For each node \(v\) and any two graphs \(G_{i}\) and \(G_{j}\), there is a sequence of graphs such that \(v\) can be transitively matched through those graphs between \(G_{i}\) and \(G_{j}\).

On step 1This falls back to the regime of analyzing the performance of the \(k\)-core estimator in the setting of two graphs. Cullina and co-authors  showed that the \(k\)-core estimator is _precise_: For any two correlated graphs \(G_{i}\) and \(G_{j}\) with \(p=C(n)/n\) and constant \(s\), the \(k\)-core estimator correctly matches all nodes in \(_{k}(G_{i}^{} G_{j}^{})\) with probability \(1-o(1)\). In fact, this is true for any \(C>0\) and for any \(k 13\). Therefore, using the fact that the number of instances of pairwise matchings is constant whenever \(m\) is constant, a union bound reveals

\[(\ 1 i<j m _{ij}(v)_{ij}^{*}(v)v_{k}(G_{i}^{} G_{j}^{}))\] \[_{i=1}^{m}_{j=1}^{m}(_{i, j}(v)_{i,j}^{*}(v)v_{k}(G_{i}^{} G_{j}^{}))\] \[=o(1).\]

We have proved the following.

**Proposition 5**.: _Let \(G_{1},,G_{m}\) be correlated graphs from the subsampling model. Let \(k 13\) and let \(_{ij}\) denote the matching output by the \(k\)-core estimator on graphs \(G_{i}\) and \(G_{j}\). Then,_

\[(\ 1 i<j m,v_{k}(G_{i}^{ } G_{j}^{}))_{ij}(v)_{ij}^{*}(v))=o(1).\]

On step 2The challenging part of the proof is to show that boosting through transitive closure matches all the nodes with probability \(1-o(1)\) if \(Cs(1-(1-s)^{m-1})>1\). It is instructive to visualize this using _transitivity graphs_.

**Definition 6** (Transitivity graph, \((v)\)).: _For each node \(v V\), let \((v)\) denote the graph on the vertex set \(\{g_{1},,g_{m}\}\) such that an edge \(\{g_{i},g_{j}\}\) is present in \((v)\) if and only if \(v_{k}(G_{i}^{} G_{j}^{})\)._

On the event that each instance of pairwise matching using the \(k\)-core is correct, the edge \(\{g_{i},g_{j}\}\) is present in \((v)\) if and only if \(v\) is correctly matched using the \(k\)-core estimator between \(G_{i}\) and \(G_{j}\), i.e. \(_{1i}^{*}(v)\) is matched to \(_{1j}^{*}(v)\). Thus, in order for Step 2 to succeed (i.e. to exactly match all vertices across all graphs), it suffices that the graph \((v)\) is connected for each node \(v V\). However, studying the connectivity of the transitivity graphs is challenging because in any graph \((v)\), no two edges are independent. This is because the \(k\)-cores of any two intersection graphs \(G_{a}^{} G_{b}^{}\) and \(G_{c}^{} G_{d}^{}\) are correlated, because all the graphs \(G_{a},G_{b},G_{c}\) and \(G_{d}\) are themselves correlated. To overcome this, we introduce another graph \(}(v)\) that relates to \((v)\) and is amenable to analysis.

**Definition 7**.: _For each node \(v V\), let \(}(v)\) denote a complete weighted graph on the vertex set \(\{g_{1},,g_{m}\}\) such that the weight on any edge \(\{g_{i},g_{j}\}\) is \(_{v}(i,j):=_{G^{}_{i} G^{}_{j} }(v)\)._

The relationship between the graphs \((v)\) and \(}(v)\) stems from a useful relationship between the degree of node \(v\) in \(G^{}_{i} G^{}_{j}\) and the inclusion of \(v\) in \(_{k}(G^{}_{i} G^{}_{j})\) for each \(i\) and \(j\). Since this result is of independent interest in the study of random graphs, we state it below for general Erdos-Renyi graphs.

**Lemma 8**.: _Let \(n\) and \(k\) be positive integers and let \(G(n,(n)/n)\) for some \(>0\). Let \(v\) be a node of \(G\) and let \(_{G}(v)\) denote the degree of \(v\) in \(G\). Then,_

\[(\{v_{k}(G)\}\{_{G}(v) k+1/ \})=o(1/n).\] (1)

For any \(i\) and \(j\), the graph \(G^{}_{i} G^{}_{j}(n,Cs^{2}(n)/n)\). Thus, Lemma 8 implies that with probability \(1-o(1/n)\), if a pair \(\{g_{i},g_{j}\}\) has edge weight \(_{ij} k+1/\) in \(}(v)\), then the corresponding edge \(\{g_{i},g_{j}\}\) is present in the transitivity graph \((v)\). Equivalently, \(v\) is correctly matched between \(G_{i}\) and \(G_{j}\) in the instance of pairwise \(k\)-core matching between them.

The graph \((v)\) is not connected only if it contains a (non-empty) vertex cut \(U\{1,,m\}\) with no edge crossing between \(U\) and \(U^{c}\). Let \(c_{v}(U)\) denote the number of such crossing edges in \((v)\). Furthermore, define the _cost_ of the cut \(U\) in \(}(v)\) as

\[_{v}(U):=_{i U}_{j U^{c}}_{v}(i, j).\]

Lemma 8 is a statement about a single graph, but we show it can be invoked to prove the following.

**Theorem 9**.: _Let \(G_{1},,G_{m}\) be correlated graphs from the subsampling model with parameters \(C\) and \(s\). Let \(v V\) and let \(U\) be a vertex cut of \(\{1,,m\}\) such that \(|U| m/2\). Then,_

\[(\{c_{v}(U)=0\}\{_{v}(U)>}{4} (k+})\})=o(1/n).\] (2)

It suffices therefore to analyze the probability that the graph \(}(v)\) has a cut \(U\) such that its cost \(_{v}(U)\) is too small. To that end, we show that the bottleneck arises from vertex cuts of small size. Formally,

**Theorem 10**.: _Let \(G_{1},,G_{m}\) be correlated graphs from the subsampling model. Let \(v V\) and let \(U_{}\) denote the set \(\{1,,\}\) for \(\) in \(\{1,, m/2\}\). For any vertex cut \(U\) of \(\{1,,m\}\), let \(_{v}(U)\) denote its cost in the graph \(}(v)\). The following stochastic ordering holds:_

\[_{v}(U_{1})_{v}(U_{2}) _{v}(U_{ m/2}).\]

Theorems 9 and 10 imply that the tightest bottleneck to the connectivity of \((v)\) is the event that \(_{v}(U_{1})\) is below the threshold \(r:=}{4}(k+})\), i.e. the sum of degrees of \(v\) over the intersection graphs \((G_{1} G^{}_{j}:j=2,,m)\) is less than \(r\). This event occurs only if the degree of \(v\) is less than \(r\) in each of the intersection graphs \((G_{1} G^{}_{j}:j=2,,m)\). However, under the condition \(Cs(1-(1-s)^{m-1})>1\), it turns out that this event occurs with probability \(o(1/n)\).

**Theorem 11**.: _Let \(G_{1},,G_{m}\) be obtained from the subsampling model with parameters \(C\) and \(s\). Let \(r=}{4}(k+})\). Let \(v[n]\) and suppose that \(Cs(1-(1-s)^{m-1})>1\). Then,_

\[(_{v}(U_{1}) r)(\{ _{G_{1} G^{}_{2}}(v) r\}\{ _{G_{1} G^{}_{m}}(v) r\})=o(1/n).\]

### Piecing it all together: Proof of Theorem 3

Proof of Theorem 3.: Let \(_{12},,_{1m}\) denote the output of Algorithm 2 with \(k 13\). Let \(E_{1}\) (resp. \(E_{2}\)) denote the event that Algorithm 1 (resp. Algorithm 2) fails to match all \(m\) graphs exactly, i.e.

\[E_{1}=\{_{12}^{}_{12}^{*}\} \{_{1m}^{}_{1m}^{*}\}, E_{2}= \{_{12}\ _{12}^{*}\}\{_{1m}_{1m}^{ *}\}.\]First, we show that the output of Algorithm 2 is correct with probability \(1-o(1)\) whenever \(Cs(1-(1-s)^{m-1})>1\). If the event \(E_{2}\) occurs, then either step 1 failed, i.e. there is a \(k\)-core matching \(_{ij}\) that is incorrect, or step 2 failed, i.e. at least one of the graphs \((v)\) is not connected. Therefore,

\[(E_{2})(_{i,j}_{v _{k}(G_{i}^{} G_{j}^{})} _{ij}_{ij}^{}})+(_{v V} \{(v)\}) o(1)+_{v V}q _{v},\]

where the last step uses Proposition 5, and \(q_{v}\) denotes the probability that the transitivity graph \((v)\) is not connected. For each \(\) in the set \(\{1,, m/2\}\), let \(U_{}\) denote the set \(\{1,,\}\). Then,

\[q_{v} =(_{=1}^{ m/2}\{ \;U\{1,,m\}:|U|=c_{v}(U)=0\})\] \[_{=1}^{ m/2} (c_{v}(U_{})=0)\] \[_{=1}^{ m/2}[ (_{v}(U_{})}{4}k\!+ \!}\!)\!+\!(\{c_{v}(U_{})=0 \}\{_{v}(U_{})>}{4}k\!+\!}\}))\!\] \[}{}_{=1}^{ m/2} [(_{v}(U_{})}{4}k\!+\!}\!)\!+\!o( )]\] \[}{}_{=1}^{ m/2} [(_{v}(U_{1})}{ 4}k\!+\!}\!)\!+\!o( )]\] \[}{}_{=1}^{ m/2}m^{ }[o()+o()]=o( ).\]

Here, (a) uses Theorem 9, and (b) uses the fact that for any \( 2\), the random variable \(_{v}(U_{})\) stochastically dominates \(_{v}(U_{1})\) (Theorem 10). Finally, (c) uses Theorem 11 and the fact that \(Cs(1-(1-s)^{m-1})>1\). Therefore, a union bound over all the nodes yields

\[(E_{2}) o(1)+_{v V}q_{v} o(1)+n o(1/ n)=o(1).\]

Finally, by optimality of the MLE, it follows that

\[(E_{1})(E_{2})=o(1),\]

whenever \(Cs(1-(1-s)^{m-1})>1\). This concludes the proof. 

## 5 Discussion and Future Work

In this work, we introduced and analyzed matching through transitive closure - an approach that combines information from multiple graphs to recover the underlying correspondence between them. Despite its simplicity, it turns out that matching through transitive closure is an optimal way to combine information in the setting where the graphs are pairwise matched using the \(k\)-core estimator. A limitation of our algorithms is the runtime: Algorithm 2 does not run in polynomial time because it uses the \(k\)-core estimator for pairwise matching, which involves searching over the space of permutations. Even so, it is useful to establish the fundamental limits of exact recovery, and serve as a benchmark to compare the performance of any other algorithm.

The transitive closure subroutine (Step 2) itself is _efficient_ because it runs in polynomial time \(O(mn)\). Therefore, a natural next step is to modify Step 1 in our algorithm so that the pairwise matchings are done by an _efficient_ algorithm. However, it is not clear if transitive closure is optimal for combining information from the pairwise matchings in this setting. For example, there is a possibility that the pairwise matchings resulting from the efficient algorithm are heavily correlated, and transitive closure is unable to boost them. In Figure 3, we show experimentally that this is not the case for two algorithms of interest: GRAMPA  and Degree Profiles .

1. GRAMPA is a spectral algorithm that uses the entire spectrum of the adjacency matrices to match the two graphs. The code is available in .
2. Degree Profiles associates with each node a signature derived from the degrees of its neighbors, and matches nodes by signature proximity. The code is available in .

Evidently, both algorithms benefit substantially from using transitive closure to boost the number of matched nodes. This suggests that transitive closure can be a practical algorithm to boost matchings between networks by using other networks as side-information. Unfortunately, both GRAMPA and Degree Profiles require the graphs to be close to isomorphic in order to perform well, and so they do not perform well when the model parameters are close to the information theoretic threshold for exact recovery. Subsequently, they cannot be used to answer the question in Objective 1.

Our work presents several directions for future research.

* this precision is present in the \(k\)-core estimator and enables the transitive closure subroutine to work correctly. Can the performance guarantees of the \(k\)-core estimator be realized through polynomial time algorithms that meet this constraint?
* **Beyond Erdos-Renyi graphs.** The study of matching _two_ ER graphs provided tools and techniques that extended to the analysis of more realistic models. For instance, the \(k\)-core estimator itself played a crucial role in establishing limits to matching two correlated stochastic block models  and two inhomogeneous random graphs . Can the techniques developed in the present work be used to identify the information theoretic limits to exact recovery in these models in the general setting of \(m\) graphs?
* **Boosting for partial recovery.** This work focused on _exact_ recovery, where the objective is to match _all_ nodes across _all_ graphs. It would be interesting to consider a regime where any instance of pairwise matching recovers at best a small fraction of nodes. Is it possible to quantify the extent to which transitive closure boosts the number of matched nodes?
* **Robustness.** Finally, how sensitive to perturbation is the transitive closure algorithm? Is it possible to quantify the extent to which an adversary may perturb edges in some of the graphs without losing the performance guarantees of the matching algorithm? Algorithms that perform well on models such as ER graphs and are further generally robust are expected to also work well with real-world networks.

Figure 3: Matching through transitive closure