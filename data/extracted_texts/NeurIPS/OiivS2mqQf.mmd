# Augmentation-Aware Self-Supervision

for Data-Efficient GAN Training

 Liang Hou\({}^{1,3,4}\), Qi Cao\({}^{1}\), Yige Yuan\({}^{1,3}\), Songtao Zhao\({}^{4}\), Chongyang Ma\({}^{4}\),

**Siyuan Pan\({}^{4}\), Pengfei Wan\({}^{4}\), Zhongyuan Wang\({}^{4}\), Huawei Shen\({}^{1,3}\), Xueqi Cheng\({}^{2,3}\)**

\({}^{1}\)CAS Key Laboratory of AI Safety and Security,

Institute of Computing Technology, Chinese Academy of Sciences

\({}^{2}\)CAS Key Laboratory of Network Data Science and Technology,

Institute of Computing Technology, Chinese Academy of Sciences

\({}^{3}\)University of Chinese Academy of Sciences

\({}^{4}\)Kuaishou Technology

lianghou96@gmail.com

###### Abstract

Training generative adversarial networks (GANs) with limited data is challenging because the discriminator is prone to overfitting. Previously proposed differentiable augmentation demonstrates improved data efficiency of training GANs. However, the augmentation implicitly introduces undesired invariance to augmentation for the discriminator since it ignores the change of semantics in the label space caused by data transformation, which may limit the representation learning ability of the discriminator and ultimately affect the generative modeling performance of the generator. To mitigate the negative impact of invariance while inheriting the benefits of data augmentation, we propose a novel augmentation-aware self-supervised discriminator that predicts the augmentation parameter of the augmented data. Particularly, the prediction targets of real data and generated data are required to be distinguished since they are different during training. We further encourage the generator to adversarially learn from the self-supervised discriminator by generating augmentation-predictable real and not fake data. This formulation connects the learning objective of the generator and the arithmetic - harmonic mean divergence under certain assumptions. We compare our method with state-of-the-art (SOTA) methods using the class-conditional BigGAN and unconditional StyleGAN2 architectures on data-limited CIFAR-10, CIFAR-100, FFHQ, LSUN-Cat, and five low-shot datasets. Experimental results demonstrate significant improvements of our method over SOTA methods in training data-efficient GANs.1

## 1 Introduction

Generative adversarial networks (GANs)  have achieved great progress in synthesizing diverse and high-quality images in recent years . However, the generation quality of GANs depends heavily on the amount of training data . In general, the decrease of training samples usually yields a sharp decline in both fidelity and diversity of the generated images . This issue hinders the wide application of GANs due to the fact of insufficient data in real-world applications. For instance, it is valuable to imitate the style of an artist whose paintings are limited. GANs typically consist of a generator that is designed to generate new data and a discriminator that guides the generator to recover the real data distribution. The major challenge of training GANs under limited data is that the discriminator is prone to overfitting , and therefore lacks generalization to teach the generator to learn the underlying real data distribution.

In order to alleviate the overfitting issue, recent researches have suggested a variety of approaches, mainly from the perspectives of training data , loss functions , and network architectures . Among them, data augmentation-based methods have gained widespread attention due to its simplicity and extensibility. Specifically, DiffAugment  introduced differentiable augmentation techniques for GANs, in which both real and generated data are augmented to supplement the training set of the discriminator. However, this straightforward augmentation method overlooks augmentation-related semantic information, as it solely augments the domain of the discriminator while neglecting the range. Such a practice might introduces an inductive bias that potentially forces the discriminator to remain invariant to different augmentations , which could limit the representation learning of the discriminator and subsequently affect the generation performance of the generator .

In this paper, we propose a novel augmentation-aware self-supervised discriminator that predicts the augmentation parameter of augmented data with the original data as reference to address the above problem. Meanwhile, the self-supervised discriminator is required to be distinguished between the real data and the generated data since their distributions are different during training, especially in the early stage. The proposed discriminator can benefit the generator in two ways, implicitly and explicitly. On one hand, the self-supervised discriminator can transfer the learned augmentation-aware knowledge to the original discriminator through parameter sharing. On the other hand, we allow the generator to learn adversarially from the self-supervised discriminator by generating augmentation-predictable real and not fake data (Equation (6)). We also theoretically analyzed the connection between this objective function and the minimization of a robust \(f\)-divergence divergence (the arithmetic \(-\) harmonic mean divergence ). In experiments, we show that the proposed method compares favorably to the data augmentation counterparts and other state-of-the-art (SOTA) methods on common data-limited benchmarks (CIFAR-10 , CIFAR-100 , FFHO , LSUN-Cat , and five low-shot image generation datasets ) based on the class-conditional BigGAN  and unconditional StyleGAN2  architectures. In addition, we carried out extensive experiments to demonstrate the effectiveness of the objective function design, the adaptability to stronger data augmentations, and the robustness of hyper-parameter selection in our method.

## 2 Related Work

In this section, we provide an overview of existing work related to training GANs in data-limited scenarios. We also discuss methodologies incorporating self-supervised learning techniques.

### GANs under Limited Training Data

Recently, researchers have become interested in freeing training GANs from the need to collect large amounts of data for adaptability in real-world scenarios. Previous studies typically fall into two main categories. The first one involves adopting a pre-trained GAN model to the target domain by fine-tuning partial parameters [41; 31; 42; 30]. However, it requires external training data, and the adoption performance depends heavily on the correlation between the source and target domains.

The other one focuses on training GANs from scratch with elaborated data-efficient training strategies. DiffAugment  utilized differentiable augmentation to supplement the training set to prevent discriminator from overfitting in limited data regimes. Concurrently, ADA  introduced adaptive data augmentation with a richer set of augmentation categories. APA  adaptively augmented the real data with the most plausible generated data. LeCam-GAN  proposed adaptive regularization for the discriminator and showed a connection to the Le Cam divergence .  discovered that sparse sub-network (lottery tickets)  and feature-level adversarial augmentation could offer orthogonal gains to data augmentation methods. InsGen  improved the data efficiency of training GANs by incorporating instance discrimination tasks to the discriminator. MaskedGAN  employed masking in the spatial and spectral domains to alleviate the discriminator overfitting issue. GenCo  discriminated samples from multiple views with weight-discrepancy and data-discrepancy mechanisms. FreGAN  focused on discriminating between real and fake samples in the high-frequency domain. DigGAN  constrains the discriminator gradient gap between real and generated data. FastGAN  designed a lightweight generator architecture and observed that a self-supervised discriminator could enhance low-shot generation performance. Our method falls into the second category, supplementing data augmentation-based GANs and can be also applied to other methods.

### GANs with Self-Supervised Learning

Self-supervised learning techniques excel at learning meaningful representations without human-annotated labels by solving pretext tasks. Transformation-based self-supervised learning methods such as rotation recognition  have been incorporated into GANs to address catastrophic forgetting in discriminators [4; 38; 12]. Various other self-supervised tasks have also been explored, including jigsaw puzzle solving , latent transformation detection , and mutual information maximization . Moreover, ContraD  decouples the representation learning and discrimination of the discriminator, utilizing contrastive learning for representation learning and a discriminator head for distinguishing real from fake upon the contrastive representations. In contrast to ours, CR-GAN  and ICR-GAN proposed consistency regularization for the discriminator, which corresponds to an explicit augmentation-invariant of the discriminator. both our proposed method and SSGAN-LA  belong to adversarial self-supervised learning, they differ in the type of self-supervised signals and model inputs. SSGAN-LA is limited to categorical self-supervision , which is incompatible with popular augmentation-based GANs like DiffAugment . Our method is applicable for continuous self-supervision and integrates seamlessly with DiffAugment. Furthermore, continuous self-supervision have a magnitude relationship and thus can provide more refined gradient feedback for the model to overcome overfitting in data-limited scenarios. Additionally, unlike SSGAN-LA, our method does not constrain the invertibility of data transformations (Theorem 1) because it additionally take the original sample as input for the self-supervised discriminator (Equation (5)).

## 3 Preliminaries

In this section, we introduce the necessary concepts and preliminaries for completeness of the paper.

### Generative Adversarial Networks

Generative adversarial networks (GANs)  typically contain a generator \(G:\) that maps a low-dimensional latent code \(\) endowed with a tractable prior \(p()\), e.g., multivariate normal distribution \((,)\), to a high-dimensional data point \(\), which induces a generated data distribution (density) \(p_{G}()=_{}p()(-G())\) with the Dirac delta distribution \(()\), and also contain a discriminator \(D:\) that is required to distinguish between the real data sampled from the underlying data distribution (density) \(p_{}()\) and the generated ones. The generator attempts to fool the discriminator to eventually recover the real data distribution, i.e., \(p_{G}()=p_{}()\). Formally, the loss functions for the discriminator and the generator can be formulated as follows:

\[_{D} =_{ p_{}()}[f(D( ))]+_{ p()}[h(D(G()))],\] (1) \[_{G} =_{ p()}[g(D(G()))].\] (2)

Different real-valued functions \(f\), \(h\), and \(g\) correspond to different variants of GANs . For example, the minimax GAN  can be constructed by setting \(f(x)=-((x))\) and \(h(x)=-g(x)=-(1-(x))\) with the sigmoid function \((x)=1/(1+(-x))\). In this study, we follow the practices of DiffAugment  to adopt the hinge loss , i.e., \(f(x)=h(-x)=(0,1-x)\) and \(g(x)=-x\), for experiments based on BigGAN  and the log loss , i.e., \(f(x)=g(x)=-((x))\) and \(h(x)=-(1-(x))\), for experiments based on StyleGAN2 .

Figure 1: Examples of images with different kinds of differentiable augmentation (including the original unaugmented one) and their re-scaled corresponding augmentation parameters \(^{d}\).

### Differentiable Augmentation for GANs

DiffAugment  introduces differentiable augmentation \(T:}\) parameterized by a randomly-sampled parameter \(\) with a prior \(p()\) for data-efficient GAN training. The parameter \(\) determines exactly how to transfer a sample \(\) to an augmented one \(}}\) for the discriminator. After manually re-scaling (for \(^{d}\)), the parameters of all three kinds of differentiable augmentation used in DiffAugment for 2D images can be expressed as follows:

* color: \(_{}=(_{},_{},_{})^{3}\);
* translation: \(_{}=(x_{},y_{})^{2}\);
* cutout: \(_{}=(x_{},y_{})^{2}\).

Figure 1 illustrates the augmentation operations and their parameters. Formally, the loss functions for the discriminator and the generator of GANs with DiffAugment are defined as follows:

\[_{D}^{}=_{ p_{ }(), p()}[f(D(T( ;)))]+_{} p(}), p()}[h(D(T(G();)))],\] (3) \[_{G}^{}=_{} p( }), p()}[g(D(T(G();)))],\] (4)

where \(\) can represent any combination of these parameters. We choose all augmentations by default, which means augmentation color, translation, and cutout are adopted for each image sequentially.

## 4 Method

Data augmentation for GANs allows the discriminator to distinguish a single sample from multiple perspectives by transforming it into various augmented samples according to different augmentation parameters. However, it overlooks the differences in augmentation intensity, such as color contrast and translation magnitude, leading the discriminator to implicitly maintain invariance to these varying intensities. The invariance may limit the representation learning ability of the discriminator because it loses augmentation-related information (e.g., color and position) . Figure 2 confirms the impact of this point on the discriminator representation learning task . We argue that a discriminator that captures comprehensive representations contributes to better convergence of the generator [35; 22]. Moreover, data augmentation may lead to augmentation leaking in generated data, when using specific data augmentations such as random 90-degree rotations [18; 12]. Therefore, our goal is to eliminate the unnecessary potential inductive bias (invariance to augmentations) for the discriminator while preserving the benefits of data augmentation for training data-efficient GANs.

To achieve this goal, we propose a novel augmentation-aware self-supervised discriminator \(:}^{+}^{-}\) that predicts the augmentation parameter and authenticity of the augmented data given the original data as reference. Distinguishing between the real data and the generated data with different self-supervision is because they are different during training, especially in the early stage. Specifically, the predictive targets of real data and generated data are represented as \(^{+}^{+}\) and \(^{-}^{-}\), respectively. They are constructed from the augmentation parameter \(\) with different transformations, i.e., \(^{+}=-^{-}=\). Since the augmentation parameter is a continuous

Figure 2: Comparison of representation learning ability of discriminator between BigGAN + DiffAugment and our AugSelf-BigGAN on CIFAR-10 and CIFAR-100 using linear logistic regression.

vector, we use mean squared error loss to regress it. The proposed method combines continuous self-supervised signals with real-vs-fake discrimination signals, thus can be considered as soft-label augmentation . Comparison with self-supervision that does not distinguish between real and fake is referred to Table 6 in Appendix C. Notice that the predictive targets (augmentations) can be a subset of performed augmentations (see Table 7 in Appendix C for comparison). Mathematically, the loss function for the augmentation-aware self-supervised discriminator is formulated as the following:

\[^{}_{}=_{, }[\|(T(;),)-^{+}\|_{2}^{2}]+_{,}[ \|(T(G();),G())-^{-}\|_{2}^{2}].\] (5)

In our implementations, the proposed self-supervised discriminator \(=\) shares the backbone \(:^{d}\) with the original discriminator \(D=\) except the output linear layer \(:^{d}^{+}^{-}\). This parameter-sharing design not only improves the representation learning ability of the original discriminator but also saves the number of parameters in our model compared to the base model, e.g., \(0.04\%\) more parameters in BigGAN and \(0.01\%\) in StyleGAN2. More specifically, the self-supervised discriminator predicts the target based on the difference between learned representations of the augmented data and the original data, i.e., \((T(;),)=((T(;))-())\) (see Table 8 in Appendix C for comparison with other architectures). The philosophy behind our design is that the backbone \(\) should capture rich (which necessitates the design of a simple head \(\)) and linear (inspiring us to perform subtraction on the features) representations.

In order for the generator to directly benefit from the self-supervision of data augmentation, we establish a novel adversarial game between the augmentation-aware self-supervised discriminator and the generator with the objective function for the generator defined as follows:

\[^{}_{G}=_{,}[ \|(T(G();),G())-^{+}\|_{2}^{2}]-_{,}[ \|(T(G();),G())-^{-}\|_{2}^{2}].\] (6)

The objective function is actually the combination of the non-saturating loss (regarding the generated data as real, \(_{G}_{,}[\|(T(G() ;),G())-^{+}\|_{2}^{2})\)) and the saturating loss (reversely optimizing the objective function of the discriminator, \(_{G}_{,}[\|(T(G() ;),G())-^{-}\|_{2}^{2})\) (see Table 9 in Appendix C for ablation). Intuitively, the non-saturating loss encourages the generator to produce augmentation-predictable data, facilitating fidelity but reducing diversity. Conversely, the saturating loss strives for the generator to avoid generating augmentation-predictable data, promoting diversity at the cost of fidelity. We will elucidate in Section 5 how this formalization assists the generator in matching the fidelity and diversity of real data, ultimately leading to an accurate approximation of the target data distribution.

The total objective functions for the original discriminator, the augmentation-aware self-supervised discriminator, and the generator of our proposed method, named AugSelf-GAN, are given by:

\[_{D,}^{}_{D}+_{d} ^{}_{},\] (7) \[_{G}^{}_{G}+_{g}^{ }_{G},\] (8)

Figure 3: Diagram of AugSelf-GAN. The original augmentation-based discriminator is \(D(T())=((T()))\). The augmentation-aware self-supervised discriminator is \((T(),)=((T())-())\), where \(\) is our newly introduced linear layer with negligible additional parameters.

where the hyper-parameters are set as \(_{d}=_{g}=1\) in experiments by default unless otherwise specified (see Figure 6 for empirical studies). Details of objective functions are referred to Appendix B.

## 5 Theoretical Analysis

In this section, we analyze the connection between the theoretical learning objective of AugSelf-GAN and the arithmetic \(-\) harmonic mean (AHM) divergence  under certain assumptions.

**Proposition 1**.: _For any generator \(G\) and given unlimited capacity in the function space, the optimal augmentation-aware self-supervised discriminator \(^{*}\) has the form of:_

\[^{*}(},)=}( ,,})^{+} + p_{G}(,,})^{-}}{p_{}(,})+p_{G}(,})}\] (9)

The proofs of all theoretical results (including the following ones) are deferred in Appendix A.

**Theorem 1**.: _Assume that \(^{+}=-^{-}=\) is constant, under the optimal self-supervised discriminator \(^{*}\), optimizing the self-supervised task for the generator \(G\) is equivalent to:_

\[_{G}4c M_{}(p_{}(, })\|p_{G}(,})),\] (10)

_where \(c=\|\|_{2}^{2}\) is constant and \(M_{}\) is the arithmetic \(-\) harmonic mean divergence , of which the minimum is achieved if and only if \(p_{G}(,})=p_{}(,}) p_{G}()=p_{}()\)._

Theorem 1 reveals that the generator of AugSelf-GAN theoretically still satisfies generative modeling, i.e., accurately learning the target data distribution, under certain assumptions. Although AugSelf-GAN does not obey the strict assumption, we note that this is not rare in the literature.2 Under this assumption, AugSelf-GAN can be regarded as a multi-dimensional extension of LS-GAN  in terms of the loss function, while excluding that of the generator. Additionally, our analysis offers an alternative theoretically grounded generator loss function for the LS-GAN family.3

**Corollary 1**.: _The following equality and inequality hold for the AHM divergence:_

* \(M_{}(p_{}(,})\|p_{G}( ,}))+M_{}(p_{G}(,})\|p_{}(,}))=(p_{}( ,})\|p_{G}(,}))\)__
* \(M_{}(p_{}(,})\|p_{G}( ,}))=1-W(p_{}(,})\|p_{G}(,})) 1\)__

_where \(\) is the Le Cam (LC) divergence , and \(W\) is the harmonic mean divergence ._

Corollary 1 reveals an inequality \(M_{}(p_{}(,})\|p_{G}( ,}))(p_{}(,})\|p_{G}(,}))\) because of non-negativity of AHM divergence \(M_{}(p_{G}(,})\|p_{}( ,})) 0\). Figure 4 plots the function \(f\) in AHM divergence and other common \(f\)-divergences in the GAN literature. The AHM divergence shows better robustness of the function \(f\) than others for extremely large inputs \(p()/q()=D^{*}()/(1-D^{*}())\), which is likely for the optimal discriminator \(D^{*}\) in data-limited scenarios.

Figure 4: Comparison of the function \(f\) in different \(f\)-divergences. The \(f\)-divergence between two probability distributions \(p()\) and \(q()\) is defined as \(D_{f}(p()\|q())=_{}q()f(p( )/q())\) with a convex function \(f:_{ 0}\) satisfying \(f(1)=0\). The x- and y-axis denote the input and the value of the function \(f\) in the \(f\)-divergence. The function \(f\) of the AHM divergence yields the most robust value for large inputs.

## 6 Experiments

We implement AugSelf-GAN based on DiffAugment , keeping the backbones and settings unchanged for fair comparisons with prior work under two evaluation metrics, IS  and FID . The mean and standard deviation (if reported) are obtained with five evaluation runs at the best FID checkpoint. Each of experiments in this work was conducted on an 32GB NVIDIA V100 GPU.

### Comparison with State-of-the-Art Methods

Cifar-10 and CIFAR-100.Table 1 reports the results on CIFAR-10 and CIFAR-100 . These experiments are based on the BigGAN architecture . Our method significantly outperforms the direct baseline DiffAugment  and yields the best generation performance in terms of FID and IS compared with SOTA methods. Notably, our method achieves further improvement when using stronger augmentation (see Table 5), i.e., AugSelf-BigGAN+ (translation\(\) and cutout\(\)).

FFHQ and LSUN-Cat.Table 2 reports the FID results on FFHQ  and LSUN-Cat . The hyper-parameter is \(_{g}=0.2\). AugSelf-GAN performs substantially better than baselines with the same network backbone. Also, stronger augmentation, i.e., AugSelf-StyleGAN2+ (translation\(\) and cutout\(\)), further improves the performance when training data is very limited.

    &  &  &  \\   & & IS (\(\)) & FID (\(\)) & IS (\(\)) & FID (\(\)) & IS (\(\)) & FID (\(\)) \\   **CIFAR-10** \\ **CIFAR-100** \\ **C

[MISSING_PAGE_FAIL:8]

Stronger augmentation.Translation and cutout actually erase parts of image information, which help prevent the discriminator from overfitting, but could suffer from underfitting if excessive. Our self-supervised task enables the discriminator to be aware of different levels of translation and cutout, which helps alleviate underfitting and allows us to explore stronger translation and cutout. Table 5 compares AugSelf-GAN with DiffAugment in this setting. Overall, when data is limited, AugSelf-GAN can further benefit from stronger translation and cutout and achieve new SOTA FID results, while DiffAugment cannot. This implicitly indicates that our method enables the model o learn meaningful features to overcome underfitting, even under strong data augmentation.

Hyper-parameters.Figure 6 plots the FID results of AugSelf-GAN with different hyper-parameters \(=_{d}=_{g}\) ranging from \(\) on CIFAR-10 and CIFAR-100. Notice that \(=0\) corresponds to the baseline BigGAN + DiffAugment. AugSelf-BigGAN performs the best when \(\) is near \(1\). It is worth noting that AugSelf-BigGAN outperforms the baseline even for \(=10\) with \(10\%\) and \(20\%\) training data, demonstrating superior robustness with respect to the hyper-parameter \(\).

## 7 Conclusion

This paper proposes a data-efficient GAN training method by utilizing augmentation parameters as self-supervision. Specifically, a novel self-supervised discriminator is proposed for predicting the augmentation parameters and data authenticity of augmented (real and generated) data simultaneously, given the original data. Meanwhile, the generator is encouraged to generate real rather than fake data of which augmentation parameters can be recognized by the self-supervised discriminator after augmentation. Theoretical analysis reveals a connection between the optimization objective of the generator and the arithmetic \(-\) harmonic mean divergence under certain assumptions. Experiments on data-limited benchmarks demonstrate superior qualitative and quantitative performance of the proposed method compared to previous methods.

    &  &  &  &  \\   & & IS (\(\)) & FID (\(\)) & IS (\(\)) & FID (\(\)) & IS (\(\)) & FID (\(\)) \\   CSV \\  } & DiffAugment & 9.29\({}_{.02}\) & 8.48\({}_{.13}\) & 8.84\({}_{.12}\) & 15.14\({}_{.47}\) & **8.80\({}_{.01}\)** & 20.60\({}_{.13}\) \\  & + trans.\(\) cut.\(\) & 9.28\({}_{.06}\) & 8.42\({}_{.18}\) & 8.78\({}_{.06}\) & 14.28\({}_{.27}\) & 8.69\({}_{.07}\) & 20.93\({}_{.21}\) \\  & AugSelf-GAN & **9.43\({}_{.14}\)** & 7.68\({}_{.06}\) & 8.98\({}_{.09}\) & 10.97\({}_{.09}\) & 8.76\({}_{.05}\) & 15.68\({}_{.26}\) \\  & + trans.\(\) cut.\(\) & 9.27\({}_{.05}\) & **7.54\({}_{.04}\)** & **9.08\({}_{.04}\)** & **9.95\({}_{.17}\)** & 8.79\({}_{.04}\) & **12.76\({}_{.14}\)** \\   CSV \\  } & DiffAugment & 11.02\({}_{.07}\) & 11.49\({}_{.21}\) & 9.45\({}_{.05}\) & 24.98\({}_{.48}\) & 8.50\({}_{.09}\) & 34.92\({}_{.63}\) \\  & + trans.\(\) cut.\(\) & 11.10\({}_{.08}\) & 11.28\({}_{.20}\) & 9.58\({}_{.05}\) & 24.10\({}_{.66}\) & 8.59\({}_{.04}\) & 35.32\({}_{.46}\) \\   & AugSelf-GAN & **11.19\({}_{.09}\)** & **9.88\({}_{.07}\)** & **10.25\({}_{.06}\)** & 16.11\({}_{.25}\) & 9.78\({}_{.08}\) & 21.30\({}_{.15}\) \\   & + trans.\(\) cut.\(\) & 11.12\({}_{.10}\) & 10.09\({}_{.05}\) & 10.14\({}_{.11}\) & **15.33\({}_{.20}\)** & **9.93\({}_{.06}\)** & **18.64\({}_{.09}\)** \\   

Table 5: Study on stronger augmentation. The best is in **bold** and the second best is underlined.

Figure 6: FID curves with varying hyper-parameters \(=_{d}=_{g}\) on CIFAR-10 and CIFAR-100. The hyper-parameter \(=0\) corresponds to the baseline BigGAN + DiffAugment.

Limitations.In our experiments, we observed less significant improvement of AugSelf-GAN under sufficient training data. Furthermore, its effectiveness depends on the specific data augmentation used. In some cases, inappropriate data augmentation may limit the performance gain.

Broader impacts.This work aims at improving GANs under limited training data. While this may result in negative societal impacts, such as lowering the threshold of generating fake content or exacerbating bias and discrimination due to data issues, we believe that these risks can be mitigated. By establishing ethical guidelines for users and exploring fake content detection techniques, one can prevent these undesirable outcomes. Furthermore, this work contributes to the overall development of GANs and even generative models, ultimately promoting their potential benefits for society.