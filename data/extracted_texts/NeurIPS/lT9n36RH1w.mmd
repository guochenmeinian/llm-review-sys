# Unconstrained Dynamic Regret via Sparse Coding

Zhiyu Zhang

Harvard University

zhiyuz@seas.harvard.edu &Ashok Cutkosky

Boston University

ashok@cutkosky.com &Ioannis Ch. Paschalidis

Boston University

yannisp@bu.edu

Work done at Boston University. Future versions available at https://arxiv.org/abs/2301.13349.

###### Abstract

Motivated by the challenge of nonstationarity in sequential decision making, we study Online Convex Optimization (OCO) under the coupling of two problem structures: the domain is unbounded, and the comparator sequence \(u_{1},,u_{T}\) is arbitrarily time-varying. As no algorithm can guarantee low regret simultaneously against all comparator sequences, handling this setting requires moving from minimax optimality to comparator adaptivity. That is, sensible regret bounds should depend on certain complexity measures of the comparator relative to one's prior knowledge. This paper achieves a new type of such adaptive regret bounds leveraging a sparse coding framework. The complexity of the comparator is measured by its energy and its sparsity on a user-specified dictionary, which offers considerable versatility. For example, equipped with a wavelet dictionary, our framework improves the state-of-the-art bound  by adapting to both (\(i\)) the magnitude of the comparator average \(\|\|=\|_{t=1}^{T}u_{t}/T\|\), rather than the maximum \(_{t}\|u_{t}\|\); and (\(ii\)) the comparator variability \(_{t=1}^{T}\|u_{t}-\|\), rather than the uncentered sum \(_{t=1}^{T}\|u_{t}\|\). Furthermore, our analysis is simpler due to decoupling function approximation from regret minimization.

## 1 Introduction

Nonstationarity is prevalent in sequential decision making, which poses a critical challenge to the vast majority of existing approaches developed offline. Consider weather forecasting for example . A meteorologist typically starts from the governing physical equations and simulates them online using high performance computing; the imperfection of this physical model can lead to time-varying patterns in its forecasting error. Alternatively, a machine learning scientist may build a data-driven model from historical weather datasets, but its online deployment is subject to distribution shifts. If the structure of such nonstationarity can be exploited in our algorithm, then we may expect better forecasting performance. This paper investigates the problem from a theoretical angle - we aim to improve nonstationary online decision making by incorporating _temporal representations_.

Concretely, we study _Online Convex Optimization_ (OCO), which is a repeated game between us (the player) and an adversarial environment \(\). In each (the \(t\)-th) round, with a mutually known Lipschitz constant \(G\):

1. We make a prediction \(x_{t}^{d}\) based on the observations before the \(t\)-th round.
2. The environment \(\) reveals a convex loss function \(l_{t}:^{d}\) dependent on our prediction history \(x_{1},,x_{t}\); \(l_{t}\) is \(G\)-Lipschitz with respect to \(_{2}\).
3. We suffer the loss \(l_{t}(x_{t})\).

The game ends after \(T\) rounds, and then, our total loss is compared to that of an alternative sequence of predictions \(u_{1},,u_{T}^{d}\). Without knowing the time horizon \(T\), the environment \(\) and the_comparator sequence_\(\{u_{t}\}_{t}\), our goal is to achieve low _unconstrained dynamic regret_

\[_{T}(u_{1:T}):=_{}[_{t=1}^{T}l_{t} (x_{t})-_{t=1}^{T}l_{t}(u_{t})].\] (1)

Fixing any comparator \(\{u_{t}\}_{t}\): if such an expression can be upper-bounded by a sublinear function of \(T\), then asymptotically, in any environment, we perform at least as well as the \(\{u_{t}\}_{t}\) sequence.

The above setting deviates from the most standard setting of OCO  in two ways.

* **Structure 1.** The domain \(^{d}\) is unbounded.
* **Structure 2.** The comparator is allowed to be time-varying.

While the latter has been studied extensively in the literature (since ) to account for nonstationarity, most existing approaches require a _time-invariant bounded domain_ to set the hyperparameters properly, which, to some extent, limits the amount of nonstationarity they can handle. One might argue that most practical problems have a finite range, which could be heuristically estimated from offline datasets. However, such a heuristic is not robust in nature, as underestimates will invalidate the theoretical analysis, and overestimates will make the regret bound excessively conservative. It is thus important to study the more challenging unconstrained dynamic setting2 combining the two problem structures, where algorithms cannot rely on pre-selected range estimates at all.

Taking a closer look at their analysis, it is perhaps a little surprising that these two problem structures share a common theme, despite being studied mostly separately. In either the unconstrained static setting  or the bounded dynamic setting , the standard form of _minimax optimality_ becomes vacuous, as it is impossible to guarantee that \(_{u_{1:T}}_{T}(u_{1:T})\) is sublinear in \(T\). Circumventing this issue relies on _comparator adaptivity3_ - instead of only depending on \(T\), any appropriate regret upper bound, denoted by \(_{T}(u_{1:T})\), should also depend on the comparator \(u_{1:T}\) through a certain _complexity measure_. Intuitively, despite the intractability of hard comparators, nonvacuous bounds can be established against "easy ones". A total loss bound then follows from the _oracle inequality_

\[_{t=1}^{T}l_{t}(x_{t})_{u_{1:T}}[_{t=1}^{T}l_{t}(u_{t})+ _{T}(u_{1:T})].\] (2)

A crucial observation is that the complexity of \(u_{1:T}\) is not uniquely defined: one could imagine bounding \(_{T}(u_{1:T})\) by many different non-comparable functions of \(u_{1:T}\). Essentially, this complexity measure serves as a _Bayesian prior_:4 choosing it amounts to assigning different priorities to different comparators \(u_{1:T}^{d T}\). The associated algorithm guarantees lower \(_{T}(u_{1:T})\) against comparators with higher priority, and due to Eq.(2), the total loss of our algorithm is low if some of these high priority comparators _actually_ achieve low loss \(_{t=1}^{T}l_{t}(u_{t})\). Such a Bayesian reasoning highlights the importance of versatility in this workflow: in order to place an arbitrary application-dependent prior, we need a versatile algorithmic framework that adapts to a wide range of complexity measures. This leads to the limitations of existing results, discussed next.

To our knowledge,  is the only existing work that considers our setting. Two unconstrained dynamic regret bounds are presented based on three statistics of the comparator sequence, the _maximum range_\(M:=_{t}\|u_{t}\|_{2}\), the _norm sum_\(S:=_{t=1}^{T}\|u_{t}\|_{2}\) and the _path length_\(P:=_{t=1}^{T-1}\|u_{t+1}-u_{t}\|_{2}\). First, using a 1D unconstrained static algorithm as a simple range scaler, the paper achieves [14, Lemma 10]

\[_{T}(u_{1:T})().\] (3)Then, by developing a customized mirror descent approach, most of the effort is devoted to improving \(MT\) to \(S\)[14, Theorem 4], i.e., adapting to the magnitude of individual \(u_{t}\).

\[_{T}(u_{1:T})().\] (4)

Despite the strengths of these results and their nontrivial analysis, a shared limitation is that both bounds depend explicitly on the path length \(P\). Intuitively, it means that good performance is only guaranteed in _almost static_ environments: in the typical situation of \(S=(T)\), these bounds are only sublinear when \(P=o(T)\), which rules out important persistent dynamics such as periodicity. Moreover, even the second bound still depends on \(MS\) instead of a finer characterization of each individual \(u_{t}\)'s magnitude. That is, the mission of removing \(M\) is not fully accomplished yet.5

The goal of this paper is to extend comparator adaptivity to a wider range of complexity measures. For almost static environments in particular, quantitative benefits will be obtained from specific instances of this general approach.

### Contribution

The contributions of this paper are twofold.

1. First, we present an algorithmic framework achieving a new type of unconstrained dynamic regret bounds. It is based on a conversion to vector-output _Online Linear Regression_ (OLR): given a dictionary \(\) of orthogonal feature vectors spanning the _sequence space_\(^{dT}\), we use an unconstrained static OCO algorithm to linearly aggregate these feature vectors, which are themselves time-varying prediction sequences. Such a procedure guarantees \[_{T}(u_{1:T})(_{}}),\] (5) where \(E=_{t=1}^{T}\|u_{t}\|_{2}^{2}\) is the _energy_ of the comparator \(u_{1:T}\), and \(_{}\) measures the sparsity of \(u_{1:T}\) on the dictionary \(\).6 Both \(E\) and \(_{}\) are unknown beforehand. Compared to , the main advantage of this framework is its versatility. Prior knowledge on the _transform domain_ can be incorporated by picking \(\), and favorable algorithmic properties can be conveniently inherited from static online learning. 2. Our second contribution is quantitative: although  is specifically crafted to handle almost static environments, we show that equipped with a _Haar wavelet_ dictionary, our framework actually guarantees better bounds (Table 1) in this setting, which is a surprising finding to us.
3. With the _comparator average_\(:=_{t=1}^{T}u_{t}/T\) and the _first order variability_\(:=_{t=1}^{T}\|u_{t}-\|_{2}\), our Haar wavelet algorithm guarantees \[_{T}(u_{1:T})(\|\|_{2} {T}+}).\]

 
**Algorithm** & \(P\)**-dependent bound** & \(K\)**-switching regret** & **Example 1** & **Example 2** \\   Ader (meta-expert OGD) & \(()\) & \((D)\) & N/A & \((T^{3/4})\) \\
[14, Algorithm 6] (range scaling) & \(()\) & \((M)\) & \((T)\) & \((T^{3/4})\) \\
[14, Algorithm 2] (centered MD) & \(()\) & \(()\) & \((T^{3/4})\) & \((T^{3/4})\) \\  Ours (Haar OLR) & \((\|\|_{2}+})\) & \((\|\|_{2}+})\) & \(()\) & \(()\) \\  

Table 1: Comparison in almost static environments. Each row improves the previous row (omitting logarithmic factors), c.f., Appendix A.

It improves Eq.(4) by (\(i\)) a better dependence on the comparator magnitude (\(\|\|_{2}\)); and (\(ii\)) decoupling the bias \(\) from the characterization of variability (\(\)).
* With the _number of switches_\(K:=_{t=1}^{T-1}[u_{t+1} u_{t}]\) and the _second order variability_\(:=_{t=1}^{T}\|u_{t}-\|_{2}^{2}\), the same Haar wavelet algorithm guarantees an _unconstrained switching regret bound_ \[_{T}(u_{1:T})(\|\|_{2}+}),\] which improves the existing \(()\) bound resulting from Eq.(4) and \(P=O(KM)\). Due to the _local property_ of wavelets, our algorithm runs in \(O(d T)\) time per round, matching that of the baselines. As for the regret, our bounds are never worse than the baselines, and in two examples corresponding to \(\|\|_{2} M\) and \( S\), they reduce to clearly improved rates in \(T\). Furthermore, our analysis follows from the generic regret bound Eq.(5) and the _wavelet approximation theory_, providing an intriguing connection between disparate fields.

The paper concludes with an application in fine-tuning time series forecasters, where unconstrained dynamic OCO is naturally motivated. Due to limited space, this is deferred to Appendix E, with experiments that support our theoretical results.

### Related work

Our paper addresses the connection between unconstrained OCO and dynamic OCO. Although they both embody the idea of comparator adaptivity, unified studies have been scarce.

Unconstrained OCOTo obtain static regret bounds in OCO, _Online Gradient Descent_ (OGD)  is often the default approach. With learning rate \(\), it guarantees \(O(^{-1}\|u\|_{2}^{2}+ T)\) regret with respect to any _unconstrained_ static comparator \(u^{d}\), and the optimal choice in hindsight is \(=O(\|u\|_{2}/)\). Without the oracle knowledge of \(\|u\|_{2}\), it is impossible to tune \(\) optimally. To address this issue, a series of works (also called _parameter-free online learning_)  developed vastly different strategies to achieve the _oracle optimal rate_\(O(\|u\|)\) up to logarithmic factors. That is, the algorithm performs as if the complexity measure \(\|u\|\) is known beforehand.

There is certain flexibility in the choice of the norm \(\|\|\): \(L_{1}\) and \(L_{2}\) norm bounds were presented in , while Banach norm bounds were developed by . Historically, the connection between the \(L_{1}\) norm and sparsity has powered breakthroughs in batch data science, including LASSO  and compressed sensing . However, the parallel path in online learning remains less studied: while the sparsity implication of the \(L_{1}\) norm adaptive bounds has been discussed in the literature , there is in general a lack of downstream investigations with concrete benefits. In this paper, we show that the sparsity of the comparator can be naturally associated to the _structural simplicity_ of a nonstationary environment.

Dynamic OCOComparing against dynamic sequences is a classical research topic. It is clear that one cannot go beyond linear regret in the worst case, therefore various notions of complexity should be introduced.

* The closest topic to ours is the _universal dynamic regret_, where the regret bound adapts to the complexity of an arbitrary \(u_{1:T}\) on a bounded domain with \(L_{p}\)-diameter \(D\). In the most common framework, the complexity measure is an \(L_{p,q}\) norm of the difference sequence \(\{u_{t+1}-u_{t}\}\), such as the \(L_{p,1}\) norm, i.e., the path length \(P=_{t=1}^{T-1}\|u_{t+1}-u_{t}\|_{p}\).7 Omitting the dependence on the dimension \(d\) (thus also the choice of \(p\)), the optimal bound under convex Lipschitz losses is \(()\), while the accelerated rate8\((P^{2/3}T^{1/3} 1)\) can be achieved with strong convexity . Improvements have been studied under the additional smoothness assumption . These bounds subsume results in _switching (a.k.a., shifting) regret_, where the complexity of \(u_{1:T}\) is measured by its number of switches \(K\), as \(P\) is dominated by \(DK\). A notable exception is the _dynamic model_ framework from . Still considering a bounded domain, it takes a collection of dynamic models as input, which are mappings from the domain to itself. Then, the complexity of a comparator \(u_{1:T}\) is measured by how well it can be reconstructed by the best dynamic model in hindsight. Essentially, the use of temporal representations is somewhat similar to the dictionary in our framework. The important difference is that instead of using the best feature (or the best convex combination of the features) to measure the comparator, we use _linear combinations_ of the features - this allows handling unconstrained domains through subspace modeling.
* this is an important setting in our investigation. 
Unconstrained (universal) dynamic regretTo our knowledge,  is the only work studying the universal dynamic regret without a bounded domain, whose contributions have been summarized in our Introduction. Here we survey some negative results in the literature.

* The restricted dynamic regret is a special case of the universal dynamic regret, therefore lower bounds for the former apply to the latter as well. For convex Lipschitz losses  and strongly convex losses , any algorithm should suffer the dynamic regret of \((P)\) and \((P^{2})\), respectively.
* For dynamic OCO on bounded domains, a recurring analysis goes through the notion of _strong adaptivity_: one first achieves low _static_ regret bounds on _every subinterval_ of the time horizon \([1:T]\), and then assembles these local bounds appropriately to bound the global dynamic regret . Following this route in the unconstrained setting appears to be challenging, as [13, Section 4] showed that (a natural form of) strong adaptivity cannot be achieved there. Additional discussions of related works are deferred to Appendix B, including the more general problem of _online nonparametric regression_, the more specific problem of _parametric time series forecasting_, and other orthogonal uses of sparsity in online learning.

### Notation

For two integers \(a b\), \([a:b]\) is the set of all integers \(c\) such that \(a c b\). The brackets are removed when on the subscript, denoting a tuple with indices in \([a:b]\). Treating all vectors as column vectors, \((A)\) represents the column space of a matrix \(A\). \(\) is natural logarithm when the base is omitted, and \(_{+}():=0()\). \(\) denotes a poly-logarithmic function of its input. \(0\) represents a zero vector whose dimension depends on the context.

## 2 The general sparse coding framework

This section presents our sparse coding framework, achieving the generic sparsity adaptive regret bound Eq.(5). The key idea is to view online learning on the sequence space \(^{dT}\), rather than the default domain \(^{d}\). Despite its central role in signal processing (e.g., the _Fourier transform_), such a view is (in our opinion) under-explored by the online learning community.10

### Setting

To begin with, we follow the conventions in online learning  to linearize convex losses. Consider that instead of the full loss function \(l_{t}\), we only observe its subgradient \(g_{t} l_{t}(x_{t})\) at our prediction \(x_{t}\). By using the linear loss \( g_{t},\) as a surrogate, we can still upper bound the regret Eq.(1) due to \(l_{t}(x_{t})-l_{t}(u) g_{t},x_{t}-u\). The linear loss problem is also called _Online Linear Optimization_ (OLO), where each observation \(g_{t}\) is a \(d\) dimensional vector satisfying \(\|g_{t}\|_{2} G\).

Now, consider the length \(T\) sequences of predictions \(x_{1:T}\), gradients \(g_{1:T}\) and comparators \(u_{1:T}\). Let us flatten everything and treat them as \(dT\) dimensional vectors, concatenating per-round quantities in \(^{d}\). These are called _signals_. The comparator statistics could be more succinctly represented using vector notations, e.g., the energy \(E=_{t=1}^{T}\|u_{t}\|_{2}^{2}=\|u_{1:T}\|_{2}^{2}\).

Our framework requires a _dictionary_ matrix \(^{dT N}\), possibly revealed online, whose columns are \(N\) nonzero _feature vectors_. We write \(\) in an equivalent block form as \([h_{t,n}]_{1 t T,1 n N}\), where each block \(h_{t,n}^{d 1}\). The accompanied linear transform \(u=\) relates a signal \(u^{dT}\) to a coefficient vector \(^{N}\) (if it exists). Adopting the convention in signal processing, we will call \(^{dT}\) the _time domain_, and \(^{N}\) the _transform domain_. In general, symbols without hat refer to time domain quantities, while their transform domain counterparts are denoted with hat.

Summarizing the above, we consider the following concise interaction protocol.11 Despite its parametric appearance, our main focus is on the _nonparametric_ regime, where the dictionary size \(N\) scales with the amount of data \(T\).

Vector-output OLR with linear lossesIn the \(t\)-th round, our algorithm observes a \(d\)-by-N feature matrix \(_{t}:=[h_{t,n}]_{1 n N}\), linearly combines its columns into a prediction \(x_{t}^{d}\), receives a loss gradient \(g_{t}^{d}\), and then suffers the linear loss \( g_{t},x_{t}\). We assume that12\(\|h_{t,n}\|_{2} 1\), \(_{t=1}^{T}\|h_{t,n}\|_{2}^{2} 1\) and \(\|g_{t}\|_{2} G\). The performance metric is the unconstrained dynamic regret defined in Eq.(1).

### Main result

In a nutshell, our strategy is to apply an unconstrained static OLO algorithm on the transform domain, and in a coordinate-wise fashion. This is remarkably simple, but also contains a few twists. To make it concrete, let us start with a single feature vector.

Size 1 dictionaryConsider an index \(n[1:N]\), which is associated to the feature \(h_{1:T,n}:=[h_{1,n},,h_{T,n}]^{dT}\). We suppress the index \(n\) and write it as \(h_{1:T}=[h_{1},,h_{T}]\). For any comparator \(u_{1:T}(h_{1:T})\), there exists \(\) such that \(u_{1:T}=h_{1:T}\). The cumulative loss of \(u_{1:T}\) can be rewritten as

\[ g_{1:T},u_{1:T}= g_{1:T},h_{1:T}\,=_{t =1}^{T} g_{t},h_{t},\]

which is the loss of the coefficient \(\) in a 1D OLO problem with surrogate loss gradients \( g_{t},h_{t}\). Essentially, to compete with a 1D comparator subspace \((h_{1:T})\), it suffices to run a 1D static regret algorithm \(\) that competes with \(\). Such a procedure is presented as Algorithm 1.

It still remains to choose the static algorithm \(\). Technically, all known static comparator adaptive algorithms can be applied. As an illustrative example, we adopt the FreeGrad algorithm , which simultaneously achieves static comparator adaptivity and _second order gradient adaptivity_.13 Its pseudocode and static regret bound are presented in Appendix C.1 for completeness.

In summary, our single feature learner (Algorithm 1) has the following simplified guarantee, with the full gradient adaptive version deferred to Appendix C.

**Lemma 2.1**.: _Let \(>0\) be an arbitrary hyperparameter for FreeGrad (Algorithm 3 in Appendix C.1). Applying its 1D version as the static subroutine, for all \(T_{+}\) and \(u_{1:T}(h_{1:T})\), Algorithm 1 guarantees_

\[_{T}(u_{1:T}) G+\|u_{1:T}\|_{2}G (_{t}\|u_{t}\|_{2},T,^{-1} ).\]

Note that the hyperparameter \(\) can be arbitrarily small. Further neglecting poly-logarithmic factors, the bound is essentially \((G\|u_{1:T}\|_{2})\).

General dictionaryGiven the above single feature learner, let us turn to the general setting with \(N\) features. We run \(N\) copies of Algorithm 1 in parallel, aggregate their predictions, and the regret bound sums Lemma 2.1, similar to  in the static setting. The pseudocode is presented as Algorithm 2, and the regret bound is Theorem 1.

```
0: A dictionary \(=[h_{t,n}]\), where \(h_{t,n}^{d}\); and a hyperparameter \(>0\).
1: For all \(n[1:N]\), initialize a copy of Algorithm 1 as \(_{n}\). It runs the 1D version of Algorithm 3 as a subroutine, with hyperparameter \(/N\).
2:for\(t=1,2,\)do
3: Receive \(_{t}=[h_{t,n}]_{1 n N}\). For all \(n\), send \(h_{t,n}\) to \(_{n}\), and query its prediction \(w_{t,n}\).
4: Predict \(x_{t}=_{n=1}^{N}w_{t,n}\).
5: Receive loss gradient \(g_{t}\), and send it to \(_{1},,_{N}\) as loss gradients.
6:endfor ```

**Algorithm 2** Sparse coding with general dictionary.

**Theorem 1**.: _Consider any collection of signals \(z^{(n)}(h_{1:T,n})\), \( n\). We define its reconstruction error (for the comparator \(u_{1:T}\)) as \(z^{(0)}=u_{1:T}-_{n=1}^{N}z^{(n)}^{dT}\). Then, for all \(T_{+}\) and \(u_{1:T}^{dT}\), Algorithm 2 guarantees_

\[_{T}(u_{1:T}) G+G(_{n=1}^{N}\|z^{ (n)}\|_{2})(_{t,n}\|z^{(n)}_{t }\|_{2},T,N,^{-1})+G_{t=1}^{T}\|z^{(0)}_{t} \|_{2},\]

_where \(z^{(n)}_{t}^{d}\) is the \(t\)-th round component of the sequence \(z^{(n)}^{dT}\)._

To interpret this very general result, let us consider a few concrete settings.

* **Static regret.** If the size \(N=d\) and the dictionary \(_{t}=I_{d}\), then for any static comparator (\(u_{t}=u^{d}\)), we can let \(z^{(n)}\) be the projection of the sequence \(u_{1:T}\) onto \((h_{1:T,n})\). This leaves zero reconstruction error, i.e., \(u_{1:T}=_{n=1}^{N}z^{(n)}\). Theorem 1 reduces to \[_{T}(u_{1:T}) G+\|u\|_{1}G (\|u\|_{},T,d,^{-1} ),\] (6) which recovers a standard \((\|u\|_{1})\) bound in coordinate-wise unconstrained static OLO [14, Section 9.3]. The gradient adaptive version yields a better \((\|u\|_{2})\) bound, c.f., Appendix C.2.
* **Orthogonal dictionary.** Entering the dynamic realm, we now consider the situation where feature vectors are orthogonal (standard in signal processing), and the comparator \(u_{1:T}()\). Same as the static setting, we are free to define \(z^{(n)}\) as the projection \[z^{(n)}= h_{1:T,n},u_{1:T}}{\|h_{1 :T,n}\|_{2}^{2}}.\]Due to orthogonality, the projection preserves the energy of the time domain signal, i.e, \(E=\|u_{1:T}\|_{2}^{2}=_{n=1}^{N}\|z^{(n)}\|_{2}^{2}\). By further defining \(_{}:=(_{n=1}^{N}\|z^{(n)}\|_{2})^{2}/ _{n=1}^{N}\|z^{(n)}\|_{2}^{2}\) (arbitrary when the denominator is zero), Theorem 1 reduces to \[_{T}(u_{1:T})(_{ }}).\] (7) Note that as the squared \(L_{1}\)/\(L_{2}\) ratio, \(_{}\) is a classical sparsity measure  of the decomposed signals \(\{z^{(n)}\}_{1 n N}\): if there are only \(N_{0} N\) nonzero vectors within this collection, then \(_{} N_{0}\) due to the Cauchy-Schwarz inequality. Therefore, the generic sparsity adaptive bound Eq.(7) depends on (\(i\)) the energy of the comparator \(u_{1:T}\); and (\(ii\)) the sparsity of its representation, without knowing either condition beforehand. The easier the comparator is (low energy, and sparse on \(\)), the lower the bound becomes.
* the regret bound adapts to the quality of the optimal (comparator-dependent) sub-dictionary \(}\).

How to choose the dictionary \(\)? In practice, we may use prior knowledge on the dynamics of the environment. For example, if the environment is periodic, such as the weather or the traffic, then a good choice could be the Fourier dictionary. Similarly, wavelet dictionaries are useful for piecewise regular environments. Another possibility is to learn the dictionary from offline datasets, which is also called _representation learning_. Overall, such prior knowledge is not required to be _correct_ - our algorithm can take any dictionary as input, and the regret bound naturally adapts to its quality. The established connection between adaptivity and signal structures is a key benefit of our framework.

Power lawFor a more specific discussion, let us consider an empirically justified setup. In signal processing, the study of sparsity has been partially motivated by the _power law_: under the standard Fourier or wavelet transforms, the \(n\)-th largest transform domain coefficient of many real signals can have magnitude roughly proportional to \(n^{-}\), where \((0.5,1)\). We also observe this phenomenon from a weather dataset, with details presented in Appendix E.1. Figure 1 plots the sorted Fourier coefficients of an actual temperature sequence, on a log-log scale. A fitted dashed line is shown in orange, with (negative) slope \(=0.68\).

When the power law holds, our bound Eq.(7) has a more interpretable form. Assuming \(d=1\) and \(N=T\),

\[_{}=^{T}n^{-})^{2}}{_{ n=1}^{T}n^{-2}}=O(T^{2-2}).\]

In a typical setting of \(E=(T)\), we obtain a sublinear \((T^{1.5-})\) dynamic regret bound.

## 3 The Haar OLR algorithm

This section presents the quantitative contributions of this paper: despite its generality, our sparse coding framework can improve existing results . Our workhorse is the ability of wavelet bases to sparsely represent smooth signals.

### Haar wavelet

Wavelet is a fundamental topic in signal processing, with long lasting impact throughout modern data science. Roughly, the motivation is that a signal can simultaneously exhibit nonstationarity at different time scales, such as slow drifts and fast jumps, therefore to faithfully represent it, we should apply feature vectors with different resolutions. We will only use the simplest Haar wavelets, which is already sufficient. Readers are referred to  for a thorough introduction to this topic.

Figure 1: The power law.

Specifically, we start from the 1D setting (\(d=1\)) with a dyadic horizon (\(T=2^{m}\), for some \(m_{+}\)). The Haar wavelet dictionary consists of \(T\) (unnormalized) orthogonal feature vectors, indexed by a _scale_ parameter \(j[1:_{2}T]\) and a _location_ parameter \(l[1:2^{-j}T]\). Given a \((j,l)\) pair, define a feature \(h^{(j,l)}=[h^{(j,l)}_{1},,h^{(j,l)}_{T}]^{T}\) entry-wise as

\[h^{(j,l)}_{t}=1,&t[2^{j}(l-1)+1:2^{j}(l-1)+2^{j-1}];\\ -1,&t[2^{j}(l-1)+2^{j-1}+1:2^{j}l];\\ 0,&.\]

It means that \(h^{(j,l)}\) is only nonzero on a length-\(2^{j}\) interval, while changing its sign once in the middle of this interval. Collecting all the \((j,l)\) pairs yield \(T-1\) features; then, we incorporate an extra all-one feature \(h^{*}=[1,,1]\) to complete this size \(T\) dictionary.

The defined features can be assembled into the columns of a matrix \(_{m}\). To help with the intuition, \(_{2}\) with \(T=4\) is presented in Eq.(8). The columns from the left to the right are \(h^{*}\), \(h^{(2,1)}\), \(h^{(1,1)}\) and \(h^{(1,2)}\). Observe that they are orthogonal, and the norm assumption from Section 2.1 is satisfied. Therefore, our sparsity adaptive regret bound Eq.(7) is applicable.

\[_{2}=1&1&1&0\\ 1&1&-1&0\\ 1&-1&0&1\\ 1&-1&0&-1.\] (8)

Given this 1D Haar wavelet dictionary, we apply a minor variant of Algorithm 2 to prevent the dimension \(d\) from appearing in the regret bound. When \(d=1\), the algorithm is exactly Algorithm 2, where intuitions are most clearly demonstrated. Then, the doubling trick [11, Section 2.3.1] is adopted to relax the knowledge of \(T\). The pseudocode is presented as Algorithm 5 in Appendix D.

ComputationAn appealing property is that most Haar wavelet features are supported on short local intervals. Despite \(N=T\), there are only \(_{2}T\) active features in each round. Therefore, the runtime of our algorithm is \(O(d T)\) per round, matching that of all the baselines we compare to. This local property holds for compactly supported wavelets, most notably the _Daubechies family_. The latter can represent more general, piecewise polynomial signals.

### Main result

For almost static environments, our Haar OLR algorithm guarantees the following bounds, by relating comparator smoothness to the sparsity of its Haar wavelet representation. Different from  which only contains \(P\)-dependent bounds, we also provide a \(K\)-switching regret bound, in order to avoid using \(P=O(KM)\).14 Interestingly, the proofs of the following two bounds are quite different: the first uses _exact sparsity_, while the second uses _approximate sparsity_.

**Theorem 2** (Switching regret).: _For all \(T_{+}\) and \(u_{1:T}^{dT}\), Algorithm 5 guarantees_

\[_{T}(u_{1:T})(\|\|_{2 }+}).\] (9)

**Theorem 3** (Path length bound).: _For all \(T_{+}\) and \(u_{1:T}^{dT}\), Algorithm 5 guarantees_

\[_{T}(u_{1:T})(\|\|_{2 }+}).\] (10)

It can be verified (Appendix A) that for _all_ comparators \(u_{1:T}\), our bounds are at least as good as prior works (Table 1). The optimality is a more subtle issue, as one should compare _upper bound functions_ (of \(u_{1:T}\)) to _lower bound functions_ in a global manner, rather than comparing the exponents of \(T\) in minimax online learning.

Nonetheless, we present two examples of \(u_{1:T}\), where the improvement can be clearly seen through better exponents of \(T\). To give it a concrete background, suppose we want to sequentially predict a 1D time series \(z_{1},,z_{T}\). This could be formulated as a OCO problem where the decision \(x_{t}\) there is our prediction of \(z_{t}\), and the loss function is the absolute loss \(l_{t}(x)=|x-z_{t}|\). A natural choice of the comparator is the ground truth sequence \(z_{1:T}\), and due to Eq.(2), any upper bound on \(_{T}(z_{1:T})\) also upper-bounds the total forecasting loss of our algorithm. Below we present specific 1D comparator sequences \(u_{1:T}\) to demonstrate the strength of our results, which could be intuitively thought as the true time series \(z_{1:T}\) in this more restricted discussion.

**Example 1** (Tracking outliers).: _Consider the situation where \(u_{1:T}\) has a locally outlying scale: we set all the instantaneous comparators \(u_{t}\) to \(1\), except \(k\) consecutive members which are set to \(\). Crucially, \(||=O(1)\) and \(=O(k)\), while \(M=\) and \(S=(T)\). With details deferred to Appendix D.7, both our bounds, i.e., Eq.(9) and (10), are \(()\), while the fine baseline Eq.(4) is \((T^{3/4})\), and the coarse baseline Eq.(3) is \((T)\). The largest gain is observed when \(k\) is a constant, i.e., the comparator is subject to a short but large perturbation._

**Example 2** (Persistent oscillation).: _Consider the situation where \(=1\), and all the instantaneous comparators oscillate around \(\): \(u_{t}=+_{t}/\). \(_{t}=1\) or \(-1\), and it only switches sign for \(k\) times. Notice that \(=\), while \(S=(T)\). All the baselines are \((+k^{1/2}T^{1/4})\), while both our bounds are \(()\). The largest gain is observed when \(k=T-1\), i.e., the comparator switches in every round._

In summary, we show that existing bounds are suboptimal, while the optimality of our results remains to be studied. It highlights the importance of _comparator energy_ and _variability_ in the pursuit of better algorithms, which have not received enough attention in the literature. Next, we briefly sketch the proofs of these bounds.

Proof sketchThe switching regret bound mostly follows from a very simple observation: if a sequence is constant throughout the support of a Haar wavelet feature, then its transform domain coefficient for this feature is zero. As features on the same scale \(j\) do not overlap, a \(K\)-switching comparator can only induce \(K\) nonzero coefficients on the \(j\)-th scale. There are at most \(K_{2}T\) nonzero coefficients in total, therefore \(_{}=(K)\). The bound Eq.(9) is obtained by applying this argument after taking out the average of \(u_{1:T}\).

As for the path length bound, the idea is to consider the _reconstructed_ sequences, using transform domain coefficients on a single scale \(j\). These are usually called _detail sequences_ in the wavelet literature . Each detail sequence has a relatively simple structure, whose path length and variability can be associated to the magnitude of its transform domain coefficients. Moreover, as these detail sequences are certain "locally averaged" and "globally centered" versions of the actual comparator \(u_{1:T}\), their regularities are dominated by the regularity of \(u_{1:T}\) itself. In combination, this yields a relation between \(P\) and the coefficients' \(L_{1}\) norm, i.e., \(_{n=1}^{N}\|z^{(n)}\|_{2}\) in Theorem 1, from which the bound is established.

Compared to the analysis of , the key advantage of our analysis is the decoupling of function approximation from the generic sparsity-based regret bound. The former is algorithm-independent, while the latter can be conveniently combined with advances in static online learning. With the help of approximation theory (e.g., Fourier features, wavelets, and possibly deep learning further down the line), intuitions are arguably clearer in this way, and solutions could be more precise (compared to analyses that "mix" function approximation with regret minimization).

Additional discussionFinally, due to limited space, we defer additional discussion of our technical results to Appendix F, including

* The related use of _Multi-Resolution Analysis_ (MRA) in the existing online learning literature.
* The comparison between Lipschitz and strongly convex losses in unconstrained dynamic OCO.

## 4 Conclusion

This paper presents a unified study of unconstrained and dynamic online learning, where the two problem structures are naturally connected via comparator adaptivity. Building on the synergy between static parameter-free algorithms and temporal representations, we develop an algorithmic framework achieving a generic sparsity-adaptive regret bound. Equipped with the wavelet dictionary, our framework improves the quantitative results from , by adapting to finer characterizations of the comparator sequence.