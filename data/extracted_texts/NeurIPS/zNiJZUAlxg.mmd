# ResAD: A Simple Framework for Class Generalizable Anomaly Detection

Xincheng Yao\({}^{1}\), Zixin Chen\({}^{1}\), Chao Gao\({}^{3}\), Guangtao Zhai\({}^{1}\), Chongyang Zhang\({}^{1,2}\)

\({}^{1}\)School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University

\({}^{2}\)MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University

\({}^{3}\)China Pacific Insurance (Group) Co., Ltd.

{i-Dover, CZX15724137864, zhaiguangtao, sunny_zhang}@sjtu.edu.cn\({}^{1}\)

gaochao-027@cpic.com.cn\({}^{3}\)

Corresponding Author.

###### Abstract

This paper explores the problem of class-generalizable anomaly detection, where the objective is to train one unified AD model that can generalize to detect anomalies in diverse classes from different domains without any retraining or fine-tuning on the target data. Because normal feature representations vary significantly across classes, this will cause the widely studied one-for-one AD models to be poorly class-generalizable (_i.e._, performance drops dramatically when used for new classes). In this work, we propose a simple but effective framework (called ResAD) that can be directly applied to detect anomalies in new classes. Our main insight is to learn the residual feature distribution rather than the initial feature distribution. In this way, we can significantly reduce feature variations. Even in new classes, the distribution of normal residual features would not remarkably shift from the learned distribution. Therefore, the learned model can be directly adapted to new classes. ResAD consists of three components: (1) a Feature Converter that converts initial features into residual features; (2) a simple and shallow Feature Constraintor that constrains normal residual features into a spatial hypersphere for further reducing feature variations and maintaining consistency in feature scales among different classes; (3) a Feature Distribution Estimator that estimates the normal residual feature distribution, anomalies can be recognized as out-of-distribution. Despite the simplicity, ResAD can achieve remarkable anomaly detection results when directly used in new classes. The code is available at https://github.com/xcyao00/ResAD.

## 1 Introduction

Anomaly detection (AD) has achieved rapid advances in many application domains, such as industrial inspection, video surveillance, and medical lesion detection . However, applying AD algorithms in real-world scenarios still confronts many challenges. A critical challenge is that there are usually diverse classes2 and new classes are continually emerging. Most previous one-for-one and also one-for-many (_i.e._, learning one AD model for multiple classes) AD methods  are still insufficient to satisfy the requirements of real-world applications. Because such methods still require retraining or fine-tuning when encountering new classes, but application users generally don't have such ability. Another more fatal point is that some scenarios may not allow retraining on target classes due to data privacy issues . Therefore, the class-generalizable ability is a critical issue in the AD community, but it still hasn't been well studied in most AD literatures.

In this paper, we aim to tackle an academy-valuable and application-required task: few-shot class-generalizable anomaly detection, _i.e._, one unified model is trained with samples from multiple known classes, and the goal is that the trained model can generalize to detect anomalies in new3 classes without any retraining or fine-tuning on the target data, only few-shot new class normal samples are required. Nonetheless, solving such a task is quite challenging. The current one-for-one/many AD models have almost no ability to directly generalize to new classes. The main challenge is: _the normal patterns from different classes are significantly different._ This can lead to many normal misdetections of new classes, _i.e._, normal patches from new classes may be mistaken as abnormal as they are quite different from the learned normal patterns. Thus, how to design a class-generalizable AD model under the feature variation circumstance? Our design philosophy is: "seeking invariant from variation". We think that residual features (_i.e._, formed by subtracting normal reference features) can be regarded as class-invariant4 representations compared to the significantly variant initial features. As shown in Fig.1(b), the main merit of normal residual features is: even in new classes, the distribution of normal residual features would not remarkably shift from the learned distribution. Regardless of classes, larger residuals are expected for abnormal features than normal features (please see Sec.3.1).

To this end, we propose a simple but effective class-generalizable AD framework, called ResAD (_i.e._, **R**esidual Feature Learning based Class-Generalizable **A**nomaly **D**etection). ResAD is based on one key insight: residual feature learning, and consists of two key designs: feature hypersphere constraining and feature distribution estimating. First, we propose to use residual features for reducing class feature variations. We employ a pre-trained feature extractor to generate normal reference features from few-shot normal reference samples. Each input feature will match the nearest normal reference feature and subtract it to form the residual feature. In this way, the most variable class-related components are very likely to be mutually eliminated, resulting in residual features distributed in a relatively fixed origin-centered region (please see Sec.3.1). Second, to further reduce the variations in the residual feature space, we take the idea from the one-class-classification (OCC) learning [37; 22] to constrain the feature space. Specifically, we employ a simple and shallow network and propose an abnormal invariant OCC loss to transform normal residual features into a constrained spatial hypersphere. Third, with the hypersphere-constrained feature space, we can easily utilize a feature distribution estimator  to learn and estimate the normal residual feature distribution, anomalies can be recognized as out-of-distribution. For new classes, as the residual features have fewer variations or are covered by the learned distribution, the whole framework is more class-generalizable. Our contributions are as follows:

1. To accomplish class-generalizable anomaly detection, we propose a simple but effective framework: ResAD, which can be applied to detect and localize anomalies in new classes.

2. We are innovatively based on residual feature learning to address the issue of previous one-for-one/many AD methods not being able to generalize to new classes.

Figure 1: **(a)**: Intuitive illustration of class-generalizable anomaly detection **(b)**: Conceptual illustration of residual features. The residual feature space has fewer variations compared to the initial feature space. The decision boundary of the residual feature distribution can more effectively distinguish anomalies in new classes, rather than treating features of new classes as anomalies.

3. Comprehensive experiments on six real-world AD datasets are performed to evaluate the AD model's class-generalizable ability. With only 4-shot normal samples as reference, ResAD can achieve remarkable AD results, significantly outperforming the state-of-the-art competing methods.

## 2 Related Work

**One-for-One/Many AD Methods.** Most AD methods follow the one-for-one/many paradigm. (1) _Reconstruction-based methods_ are the most popular AD methods. These methods hold the insight that models trained by normal samples would fail in abnormal image regions. Many previous works utilize auto-encoders [8; 27; 42], masked auto-encoders , variational auto-encoders  and generative adversarial networks [36; 1] to encode and reconstruct normal data. UniAD  is a transformer-based reconstruction model and mainly based on neighbor masked attention to address the "identical shortcut" issue to achieve one-for-many AD. (2) _Distillation-based methods_ can also be considered as belonging to the reconstruction type. These methods train student networks to reconstruct the representation of teacher networks on normal samples, and the assumption is that the student would fail in abnormal features. Recent works mainly focus on feature pyramid [35; 39], reverse distillation [13; 38], and asymmetric distillation . (3) _Embedding-based methods_ mainly rely on good feature representation and assume that abnormal features are usually far from the normal clusters. Most superior methods [11; 4; 12; 29; 30] utilize ImageNet pre-trained networks for feature extraction. However, industrial images generally have an obvious distribution shift from ImageNet. To better account for the distribution shift, subsequent adaptations should be done. The normalizing flow-based methods [31; 17; 32; 48; 44] are proposed to transform the pre-trained feature distribution into latent Gaussian distribution, and thus can better learn the normal data distribution. HGAD  proposes a novel hierarchical Gaussian mixture normalizing flow modeling method to address the "homogeneous mapping" issue for accomplishing one-for-many AD.

**Few-Shot AD Methods.** The few-shot AD methods have more similarities with ours. Distance-based approaches such as SPADE , PaDiM , and PatchCore  can be adapted to address few-shot AD by only making use of few-shot normal samples to calculate distance-based anomaly scores without training networks. RegAD  proposes to train a feature registration network to align input images and follows PaDiM  to model Multivariate Gaussian distribution with few-shot normal samples. The idea in FastRecon  is to reconstruct an anomalous sample to its normal version by few-shot support samples. A novel regression with distribution regularization is proposed to obtain the optimal transformation from support to query features. Recently, the CLIP-based AD methods, including WinCLIP  and VAND  show better few-shot AD performance. They both employ a text prompt ensemble strategy to obtain the language-guided anomaly map.

We think class-generalizable AD and few-shot AD are still not the same, they still have some differences. Class-generalizable AD requires the model to be class-generalizable, and we only extract features of normal samples in the new class as reference. Few-shot AD mainly focuses on how to effectively utilize few-shot normal samples to construct AD models, some dedicated modules may be introduced to handle the few-shot normal samples. These methods usually still need to re-model in new classes based on few-shot normal samples, _e.g._, RegAD needs to re-model Multivariate Gaussian distribution for new classes. The CLIP-based methods can be seen as class-generalizable, as these methods can obtain anomaly maps by aligning vision features with text features. However, they heavily rely on the visual-language comprehension abilities of CLIP and handcrafted text prompts about defects, making them difficult to generalize to anomalies in diverse classes. Compared to the few-shot AD methods, our method can learn a class-generalizable AD model, which can be directly applied to new classes only requiring extracting features of few-shot normal samples as reference.

More recently, InCTRL  proposes to use few-shot normal images as sample prompts and learn to capture in-context residuals between the query image and sample prompts. The idea of in-context residuals in InCTRL is very similar to ours. But our method has obvious differences with InCTRL in the definition and utilization of residuals (please see the detailed differences in Appendix A.1).

## 3 Method

**Problem Statement.** In the class-generalizable AD task, we focus on the performance of new classes. Formally, let \(_{train}=^{n}^{a}\) be a training dataset with normal images and some anomalies (_i.e._,anomalies that exist in training set should also be effectively utilized), where \(^{n}=\{I_{i}^{n}\}_{i=1}^{N}\) and \(^{a}=\{I_{j}^{a}\}_{j=1}^{M}\) indicate the collection of normal samples and abnormal samples. As for testing, the model is evaluated on a collection of other AD datasets (\(=\{_{1}^{test},_{2}^{test},,_ {T}^{test}\}\)) except the training dataset. The classes in the test set are drawn from unknown classes \(_{u}\) that are different from the known classes \(_{k}\) in the training set. Then the goal is to learn one unified model \(:\) that is trained with known classes \(_{k}\) and can directly adapt to unknown classes \(_{u}\) without any retraining or fine-tuning on the target data (only few-shot (_e.g._, 4) normal samples as reference).

**Overview.** The proposed ResAD framework is illustrated in Fig.2. The ResAD framework consists of three parts: a _Feature Extractor_, a _Feature Constraintor_, and a _Feature Distribution Estimator_. These modules will be described below in sequence.

### Residual Feature Generating

Residual feature learning is our core insight for solving class-generalizable anomaly detection. In this subsection, we describe how to generate residual features. For any input image \(I_{i}^{H W 3}\), we follow the common practice of previous AD methods to employ a pre-trained feature extraction network \(\) to extract features from different levels. Formally, we define \(L\) as the total number of levels for use. The feature map from level \(l\{1,2,,L\}\) is denoted as \(^{l}(I_{i})^{H_{l} W_{l} C_{l}}\), where \(H_{l}\), \(W_{l}\) and \(C_{l}\) are the height, width, and channel dimension of the feature map. For an entry \(x_{h,w}^{l}=^{l}(I_{i})_{h,w}^{C_{l}}\) at level \(l\) and location \((h,w)\), we will match it with the nearest normal reference feature from the corresponding reference feature pool, and then convert it into the residual feature. The details are described in the following:

**Reference Feature Pools.** The reference feature pools are utilized to store some normal features as reference. For new classes, we will provide few-shot normal samples (_i.e._, randomly selected and then fixed, please see our discussion on sample selection in Appendix A.2) as reference. The pre-trained network \(\) will extract hierarchical features for these normal reference images, then the extracted features are sent into the feature pools as reference features. For \(l\)th level, the \(l\)th reference feature pool is composed of \(_{l}=\{x_{h,w}^{l,i}\ |h\{1,,H_{l}\},w\{1,,W_{l}\},l \{1,,L\},i\{1,,N_{fs}\}\}\), where \(i\) denotes the \(i\)th normal sample, the \(N_{fs}\) is the number of normal reference samples.

**Residual Features.** For each initial feature \(x_{h,w}^{l}\), we can search the nearest nominal reference feature \(x_{n}^{*}=*{argmin}_{x_{l}}||x-x_{h,w}^{l}||_{2}\) from the \(l\)th reference feature pool \(_{l}\). Then, we define the residual representation of \(x_{h,w}^{l}\) to its closest normal reference feature as:

\[x_{h,w}^{l,r}=x_{h,w}^{l}-x_{n}^{*}.\] (1)

**Why can residual features be less sensitive to new classes compared to initial features**? Because they are obtained by matching and then subtracting. From the principles of representation learning,

Figure 2: Framework overview. Note that the training samples belong to different classes. First, few-shot normal reference samples are fed into a pre-trained _Feature Extractor_ to obtain normal reference features. Each initial feature will match the nearest normal reference feature and subtract it to form the residual feature. Then, a _Feature Constraintor_ is utilized to transform the normal residual features into a constrained spatial hypersphere. Finally, we employ a normalizing flow model as the _Feature Distribution Estimator_ to learn and estimate the residual feature distribution.

we know that features of each class generated by well-trained neural networks usually have some class-related attributes to the class for distinguishing from other classes . The "class-related" means these attributes are typical to the class and distinctive from other classes, representing the most discriminative characteristics of the class. Thus, features from different classes are usually located in different feature domains . However, as class-related attributes can also exist in normal reference features (they are usually in the same feature domain as the input query feature), the matching process can be seen as matching the most similar class-related attributes to each query feature. Therefore, by subtracting, the class-related components in the initial features are very likely to be mutually eliminated, leaving the highlighted discrepancy between normals and anomalies (_i.e._, larger residuals are more likely to be anomalies than normal features). Thus, it can be imagined that the normal residual features generally will be distributed in an origin-centered region, even in new classes, the feature distribution region would not remarkably shift (please see the t-SNE visualization in Fig.3).

### Feature Hypersphere Constraining

Even if the feature variations in the residual feature space will be significantly reduced relative to the initial feature space. Features of different classes may still have significant differences in scale, namely, the numerical value scales in the features of different classes may be remarkably different. This can lead to difficulty in obtaining a unified normal-abnormal decision boundary of different classes, _i.e._, the scales of decision boundaries in different classes may be significantly different, a good decision boundary in one class may be poor in another class. In order to further reduce feature variations and also maintain the consistency in feature scales among different classes, we take the idea from one-class-classification (OCC) learning [34; 22] and propose a _Feature Constraint_ to constrain the initial normal residual features to a spatial hypersphere. The _Feature Constraint_\(C_{_{1}}\) projects the initial residual feature \(x_{h,w}^{l,r}\) to the constrained feature \(x_{h,w}^{r,l,r}\) as \(x_{h,w}^{r,l,r}=C_{_{1}}(x_{h,w}^{l,r})\).

Because we only want to further reduce the variations in the initial residual distribution by constraining and don't want to change the distribution overly, we adopt a simple Conv+BN+ReLU layer as the network of our _Feature Constraint_. A complex network may lead to overfitting known features, reducing the generalization ability for new classes (please see ablation studies in Tab.2(b)).

**Abnormal Invariant OCC Loss.** We propose an abnormal invariant OCC loss to optimize our _Feature Constraint_or. The loss is defined as:

\[_{occ}=_{l=1}^{L}W_{l}}_{h =1}^{H_{l}}_{w=1}^{W_{l}}(1-y_{h,w}^{l})||^{r,l,r}||_{2}+1} -1||_{1}+y_{h,w}^{l}||x_{h,w}^{r,l,r}-x_{h,w}^{l,r}||_{2}.\] (2)

where \(y_{h,w}^{l}=1\) denotes the \((h,w)\) position on the feature map is anomalous and \(y_{h,w}^{l}=0\) denotes a normal position (we can downsample the ground-truth mask to a low-resolution mask, which can indicate normal and abnormal positions). The first part in the loss function is a pseudo-Huber loss , which is used for constraining the normal residual features to a hypersphere. However, if we only constrain features to the hypersphere, the network may more easily overfit and simply map all features to the hypersphere. If we give the network another objective for anomalous features, this will urge the network to distinguish between normal and abnormal, rather than forming a shortcut solution. Thus, we further introduce an abnormal invariant term by simply predicting the initial features \(||x_{h,w}^{r,l,r}-x_{h,w}^{l,r}||_{2}\). "Invariant" means the abnormal residual features remain relatively unchanged relative to themselves and will not be mapped to the hypersphere. In this way, our proposed abnormal invariant OCC loss can not only make the distribution of normal residual features more compact but also keep abnormal residual features as invariant as possible. In addition, by constraining normal features into a hypersphere, the normal feature scales of different classes can also be more consistent. Therefore, after the _Feature Constraint_or, the normal and abnormal residual features are more distinguishable (see Fig.3), namely, we can obtain a better unified decision boundary.

### Feature Distribution Estimating

We employ the normalizing flow (NF) model  as our _Feature Distribution Estimator_ to estimate the residual feature distribution. Note that our framework is not limited to normalizing flow, and other generative models can also be used as the distribution estimator. Formally, we denote \(_{_{2}}:^{C_{l}} ^{C_{l}}\) as our NF model. The input residual feature \(x_{h,w}^{r,l,r}\) will be transformed into a latent feature \(z^{l}_{h,w}=_{_{2}}(x^{l,r}_{h,w})\) by the NF model. The estimated residual distribution \(p_{_{2}}(x)\) can be calculated according to the change of variables formula as follows [14; 20]:

\[p_{_{2}}(x)=p_{Z}(z)+|J|.\] (3)

where the \(J=_{x}z\) is the Jacobian matrix of the bijective transformation \(_{_{2}}\). The model parameters \(_{2}\) can be optimized by maximizing the log-likelihoods, and the latent variables \(Z\) for normal features are usually assumed to obey \((0,I)\). The maximum likelihood loss function for learning normal residual feature distribution is derived as:

\[_{ml}=_{l=1}^{L}W_{l}}_{h= 1}^{H_{l}}_{w=1}^{W_{l}}}{2}(2)+(z^{l }_{h,w})^{T}z^{l}_{h,w}-|J^{l}_{h,w}|.\] (4)

In the class-generalizable AD task, in addition to learning from normal samples, it's also valuable for us to effectively utilize abnormal samples that exist in known classes. Considering that we focus on detecting unknown anomalies in new classes, we cannot overfit the anomalies in known classes. Thus, following BGAD , we employ the explicit boundary guided semi-push-pull loss to learn a more discriminative and also generalizable feature distribution estimator. The loss is defined as:

\[_{bg-spp}=_{i=1}^{N_{n}}|(p_{i}-b_{n},0 )|+_{j=1}^{N_{a}}|(p_{j}-b_{n}+,0)|.\] (5)

where \(b_{n}\) is an explicit normal boundary, \(\) is a margin, \(N_{n}\) and \(N_{a}\) denote the number of normal and abnormal features in a training batch. We set \(b_{n}\) according to the way in BGAD, and \(\) is set to 0.1. Then, the whole loss function for training is as follows:

\[=_{occ}+_{ml}+_{bg-spp}.\] (6)

In Appendix E, we further discuss the sensitivity of balancing among the three loss terms.

### Inference and Anomaly Scoring

For new classes, our method only requires few-shot normal samples to extract features as reference, without any fine-tuning. We feed each test feature \(x^{l}_{i}\) into the _Feature Constraintor_\(C_{_{1}}\) and the _Feature Distribution Estimator_\(_{_{2}}\) to get the latent feature \(z^{l}_{i}\). The anomaly score is calculated as:

\[s(x^{l}_{i})=1--}{2}(2)-(z^{l}_{i})^{T}z^{l}_{i}+|J^{l}_{i}|.\] (7)

Then, we upsample all \(s(x^{l}_{i})\) in the \(l\)th level to the input image resolution (\(H W\)) using bilinear interpolation and combine all levels (_i.e._, sum) to obtain the final anomaly map. The maximum score of the anomaly map is taken as the anomaly detection score of the image.

## 4 Experiments

### Experimental Setup

**Datasets and Metrics.** We conduct comprehensive experiments on four real-world industrial AD datasets, including MVTecAD , VisA , BTAD , and MVTec3D . The detailed introduction to these datasets is provided in Appendix D. For MVTec3D, we only use RGB images in the dataset. As for our method's generalizability to other domains, we further evaluate our method on a medical image dataset, BraTS  (for brain tumor segmentation) and a video AD dataset, ShanghaiTech . As our method is image-based, we extract video frames in ShanghaiTech as images for use.

Following previous works [5; 6], the anomaly detection performance is evaluated using the Area Under the Receiver Operating Characteristic Curve (AUROC).

To examine the model's class-generalizable ability, we evaluate the cross-dataset performance. We combine the training and test sets of the MVTecAD dataset to train AD methods, and they are subsequently evaluated on the test set of other five datasets without any retraining, _e.g._, we train ADmodels on MVTecAD and test on VisA. For MVTecAD, we train AD models on VisA. We report the performance with the number of few-shot normal samples set to \(K=2,4\).

**Implementation Details.** All the training and test images are resized and cropped to \(224 224\) resolution. Following the common practice in AD literatures, we utilize the commonly used WideResNet50  as the feature extractor, and the outputs from the \(\) layers of WideResNet50 are used as the pre-trained features. The parameters of the feature extractor are frozen during training. The layer numbers of the NF model are set as 8. We use the Adam  optimizer with weight decay \(5e^{-4}\) to train the model. The total training epochs are set as 100, and the batch size is 32. The learning rate is \(1e^{-5}\) initially and dropped by 0.1 after \(\) epochs. During training, we randomly select reference samples for each input image to increase residual feature diversity. The network details are in Appendix B, we also evaluate the computation costs of our model and other competing models. We run all the experiments with a single NVIDIA RTX 4090 GPU and random seed 42.

**Competing Methods.** We select the representative one-for-one AD method (RDAD ) and the one-for-many AD method (UniAD ) as baselines. Our method is mainly compared with few-shot AD methods. Following WinCLIP , we adapt three conventional full-shot AD methods, including SPADE , PaDiM , and PatchCore , to the few-shot setting by making use of few-shot normal samples to calculate distance-based anomaly scores. We also compare with the few-shot AD method RegAD . Most of these methods are based on WideResNet50 to extract features. However, these methods still need to re-model in new classes based on few-shot normal samples (see Sec.2), while our ResAD can be directly applied to new classes only requiring extracting features of few-shot normal samples as reference. Then, we also compare with the recent CLIP-based few-shot AD methods, including WinCLIP 5 and InCTRL . To guarantee the rationality of result comparison, we ensure all methods use the same few-shot normal samples, and all results are evaluated based on 224\(\)224 resolution.

### Main Results

Tab.1 represents the comparison results of our ResAD and other SOTA competing methods in image-level AUROC and pixel-level AUROC, respectively, on six real-world AD datasets. Note that all

   &  &  &  &  \\  & & RDAD & UniAD &  &  &  PatchCore \\ CVPR2022 \\  } &  ResAD \\ CVPR2022 \\  } &the results are dataset-level average results across their respective data subsets. Compared to the results on known classes (results in the original papers), the performance of conventional AD methods will drop dramatically when used for new classes, whether it is the one-for-one6 (RDAD) or the one-for-many (UniAD) AD method.

By comparison, we can see that our ResAD can significantly outperform all non-CLIP-based AD methods on both the 2-shot and 4-shot settings. With more few-shot normal images, the performance of all methods generally becomes better. On average, our ResAD outperforms the best competing model, RegAD, with up to 7.2%/2.9% and 7.6%/2.9% improvements under the 2-shot and 4-shot settings, respectively. In addition, please note that when evaluating RegAD, we utilize the few-shot normal samples to re-model the Multivariate Gaussian distribution for each new class (see Sec.2), while our ResAD is directly applied to each new class without any re-modeling or fine-tuning. Even with re-modeling, our method still has advantages over the conventional few-shot AD methods in cross-class detection.

We further implement a ResAD\({}^{}\) model by utilizing the powerful ImageBind  as the feature extractor. The outputs from the [8; 16; 24; 32] layers of ImageBind-Huge are used as the pre-trained features. ImageBind is a recently proposed large-scale pre-trained multimodal model, which shows emergent zero-shot and few-shot recognition capabilities across many vision tasks. As shown in Tab.1, by employing a model with stronger representation capability, our method can achieve better cross-dataset performance, which significantly outperforms the SOTA CLIP-based AD methods, WinCLIP and InCTRL. This demonstrates that our framework can effectively combine the latest vision models to manifest stronger class-generalizable ability. What's more, under the 4-shot setting, our ResAD by only using WideResNet50 can achieve comparable or even better results than WinCLIP and InCTRL (with more powerful CLIP-based ViT-B/16+), further demonstrating our superiority. Moreover, these two CLIP-based methods also heavily rely on CLIP-based image encoders. When we employ WideResNet50 in these two methods, our method has more advantages than these two methods (please see Appendix Tab.7).

When applied to other domains (medical images and video scenarios), our method also has better cross-domain generalization ability, despite it being trained on industrial data (the MVTecAD dataset).

### Ablation Studies

In ablation studies, we conduct experiments under the "VisA to MVTecAD" case and use the commonly used WideResNet50  as the feature extractor.

**Residual Feature Learning.** As shown in Tab.2(a), without residual feature learning, the cross-dataset performance drops dramatically from 90.5%/95.7% to 72.8%/82.9%. This verifies our confirmation that residual feature learning is of vital significance for class-generalizable anomaly detection. Analogously, any method that can reduce the variations of new class distribution relative to known class distributions is also promising to achieve class-generalizable anomaly detection.

**Feature Constraintor.** The ablation study on the effectiveness of the Feature Constraintor is also in Tab.2(a). "w/o Feature Constraintor" means the \(_{occ}\) in Eq.(6) is not used. The effectiveness indicates that by further reducing the variations in the feature distribution and making the distribution of new classes more consistent with the learned distribution, we can achieve better cross-class AD results. In Fig.3, we also present a visualization figure to intuitively show the effect of the Feature Constraintor.

**Abnormal Invariant OCC Loss.** The effectiveness of abnormal invariant OCC loss is validated in Tab.2(a). "w/o Abnormal Invariant OCC Loss" means the \(_{occ}\) only has the first part of Eq.(2). With the abnormal invariant OCC loss, image-level and pixel-level AUROCs can be improved by 5.6% and 1.8%, respectively. Moreover, we also find that without this loss, the results would rapidly decrease after certain epochs of training (_i.e._, overfitting). This shows that keeping abnormal residual features as invariant as possible is beneficial to avoid the Feature Constraintor overfitting and thus achieve better results.

**Feature Constraintor Configuration.** We further ablate the network architectures of the Feature Constraintor, the results are shown in Tab.2(b). The results indicate that the simple Conv+BN+ReLUnetwork can yield the best performance. We observe a significant performance drop with a more complex feature constraintor (_e.g._, Bottleneck, MultiScaleFusion). One possible reason is that a complex network may lead to overfitting, reducing the generalization ability for various anomalies in new classes.

**Cross-Class Within One Dataset.** We show the results of training with \(n\) classes from MVTecAD and testing on the remaining \(15-n\) classes. By varying \(n\), we can demonstrate the sensitivity of the model to different numbers of training classes. Note that different \(n\) means the number of test classes is different (this will cause the test results of different \(n\) cannot be compared with each other). Thus, we use fixed \(5\) classes as the test classes, including hazelnut, pill, tile, carpet, and zipper. For \(n=5\), the training classes include bottle, cable, capsule, grid, and leather. For \(n=10\), the training classes include bottle, cable, capsule, grid, leather, metal nut, screw, toothbrush, transistor, and wood. The results under the 4-shot setting are in Tab.3. The results demonstrate that cross-dataset generalization is more challenging than cross-class generalization in a single dataset. With more training classes, the results will be better, but the model is not very sensitive.

### Generalization to Other Anomaly Detection Frameworks

Furthermore, we think that our residual feature learning insight is not limited to the model proposed in this paper, but can be considered as an effective and general method for solving class-generalizable anomaly detection. The main reasons are: 1) The process of converting initial features to residual features can be easily applied to other AD models. 2) Residual features are less sensitive to new classes (see Sec.3.1). In this subsection, we further extend our method to the popular reconstruction-based AD framework. Specifically, we employ UniAD  as baseline and incorporate our method into it. As UniAD is feature-based AD method, combining our residual feature learning with it is straightforward.

Table 2: Ablation studies on MVTecAD. (a) “Ours” implementation follows the same configuration as in Tab.1. “w/o...” indicates that we remove a certain component relative to “Ours”. I-AUROC and P-AUROC mean image-level AUROC and pixel-level AUROC, respectively. (b) “ConvBnRelu” implements a simple Conv+BN+ReLU network. “BasicBlock” adopts the BasicBlock in ResNet. “BottleNeck” adopts the BottleNeck in ResNet. “MultiScaleFusion” is a FPN-like architecture to fuse multi-scale features. In “MultiScaleFusion+BasicBlock/BottleNeck”, we add BasicBlock/BottleNeck after the multi-scale fusion.

Table 3: Cross-class results with different numbers of training classes n.

Figure 3: Feature t-SNE visualization. (a) In the initial feature space, the features from different classes are significantly different. (b) In the residual feature space, even the residual feature distribution of unknown classes would not remarkably shift from the known distribution. Note that in (a) and (b), we only show normal residual features and use different colors to represent different classes. (c) The initial residual features. (d) The residual features after the Feature Constraintor.

MVTecAD) validate the effectiveness and generalizability AD models.

### Visualization and Qualitative Results

**Visualization Results.** Fig.3(a) and (b) show the t-SNE visualization of initial features and residual features. It can be found that in the initial feature space, the feature distribution of new classes is significantly different from the distribution of known classes, resulting in poor adaptability of AD models to new classes. However, the variations between different classes can be significantly reduced by converting into residual space. In this way, the model's generalizability to new classes can be effectively improved. Fig.3(c) and (d) show the t-SNE visualization of initial residual features and residual features after the Feature Constraintor. Results show that the Feature Constraintor can make the normal residual features more compact and more separated from the abnormal features.

**Qualitative Results.** Fig.4 shows qualitative results under the "VisA to MVTecAD" case with WideResNet50 as the feature extractor. It can be seen that most SOTA methods fail to generate good anomaly localization maps for new classes, mainly existing many false positives in normal regions. However, our method can effectively avoid false positives in normal regions and locate anomalies more accurately. More qualitative results are in Appendix Fig.5.

## 5 Conclusion

In this paper, we propose a simple but effective framework: ResAD, for achieving class-generalizable anomaly detection. ResAD consists of several simple neural network modules that are easy to train and apply in real-world scenarios. Despite the simplicity, ResAD achieves remarkable anomaly detection results in new classes. We conclude our findings for future research: residual features are really effective for designing generalizable AD models, and our feature constraining insight also has good reference values for future work.

**Limitations.** The limitations of our method are discussed in Appendix C.

**Social Impacts.** As a unified model for class-generalizable anomaly detection, the proposed method does not suffer from particular ethical concerns or negative social impacts. All datasets used are public. All qualitative visualizations are based on industrial product images, which does not infringe personal privacy.