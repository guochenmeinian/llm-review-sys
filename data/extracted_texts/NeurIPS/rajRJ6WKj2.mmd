# DeBaRA: Denoising-Based 3D Room Arrangement Generation

Leopold Maillard\({}^{1,2}\) Nicolas Sereyjol-Garros\({}^{*}\) Tom Durand\({}^{2}\) Maks Ovsjanikov\({}^{1}\)

\({}^{1}\)LIX, Ecole Polytechnique, IP Paris \({}^{2}\)Dassault Systemes

{maillard,maks}@lix.polytechnique.fr {firstname.lastname}@3ds.com

Work done during internship at Dassault Systemes.

###### Abstract

Generating realistic and diverse layouts of furnished indoor 3D scenes unlocks multiple interactive applications impacting a wide range of industries. The inherent complexity of object _interactions_, the limited amount of available data and the requirement to fulfill spatial constraints all make generative modeling for 3D scene synthesis and arrangement challenging. Current methods address these challenges autoregressively or by using off-the-shelf diffusion objectives by simultaneously predicting all attributes without 3D reasoning considerations. In this paper, we introduce DeBaRA, a score-based model specifically tailored for precise, controllable and flexible arrangement generation in a bounded environment. We argue that the most critical component of a scene synthesis system is to accurately establish the _size_ and _position_ of various objects within a restricted area. Based on this insight, we propose a lightweight conditional score-based model designed with 3D spatial awareness at its core. We demonstrate that by focusing on spatial attributes of objects, a single trained DeBaRA model can be leveraged at test time to perform several downstream applications such as scene synthesis, completion and re-arrangement. Further, we introduce a novel _Self Score Evaluation_ procedure so it can be optimally employed alongside external LLM models. We evaluate our approach through extensive experiments and demonstrate significant improvement upon state-of-the-art approaches in a range of scenarios.

## 1 Introduction

Systems capable of generating realistic environments comprising multiple interacting objects would impact several industries including video games, robotics, augmented and virtual reality (AR/VR) and computer-aided interior design. As a result and in tandem with the growing availability of synthetic datasets of indoor layouts , which can be populated with high-quality 3D assets , data-driven approaches for automatically generating and arranging 3D scenes have been actively investigated by the computer vision community. Notably, the ongoing success of deep generative models for controllable content creation in the text and image domains has recently been extended to scene synthesis, allowing users to craft realistic indoor environments from a set of multimodal constraints .

Challenges associated with 3D indoor scene generation are numerous as the intricate nature of multi-object interactions is difficult to capture and model precisely. Items should be placed, potentially resized and oriented relative to one another, in a way that is both plausible and aligned with subjective and context-dependent priors such as style, as well as ergonomic and functional preferences. Additionally, objects should fit within a bounded, restricted area, and a subtle mismatch can break the perceived validity of the synthesized environment (e.g., overlapping, floating or out-of-boundsobjects, inaccessible areas). Finally, the limited availability of high-quality data [10; 42] requires learning-based approaches to make careful design choices and trade-offs.

Early data-driven approaches often rely on intermediate hand-crafted representations [43; 54; 36; 62] that are closely related to the considered dataset, which introduces significant biases. Concurrently, popular methods have been adopting autoregressive architectures that treat scene synthesis as a set generation task [55; 38; 27; 21; 37] by sequentially adding individual objects. More recently, score-based generative models (also known as _denoising diffusion models_) have shown promising capabilities in various 3D scene understanding applications [18; 58] including controllable scene synthesis [51; 62; 60] and re-arrangement . In contrast to previous methods, denoising-based approaches enable a stable and scalable training phase and can output all scene attributes simultaneously. The iterative sampling framework brings an improved consideration for the conditioning information and an attractive balance between generation quality and variety. However, current methods leveraging score-based generative models try to model all attributes (both categorical and spatial) within a single framework, which, as we demonstrate below, is less data-efficient and leads to suboptimal solutions.

In this context, our work aims to establish principled and robust capabilities for generating accurate and diverse 3D layouts. Specifically, our key contributions are threefold:

1. We propose a score-based conditional objective and architecture designed to effectively learn spatial attributes of interacting 3D objects in a constrained indoor environment. In contrast to previous approaches [51; 38], we disentangle the design space and reduce the model's prediction to a minimal representation consisting solely of oriented 3D bounding boxes, taking as conditioning input the room's floor plan and list of object semantic categories.
2. We propose a set of approaches which allows a model trained following our method to be flexibly employed at test time to perform several user-driven tasks enabling object or attribute-level control. In particular, we demonstrate strong capabilities on controllable scenarios such as scene re-arrangement or room completion, from a single trained network.
3. Finally, we introduce a novel _Self Score Evaluation_ (SSE) procedure, which enables 3D scene synthesis by selecting the set of inputs provided by external sources, such as a LLM, that lead to the most realistic layouts.

We exhibit our model's capabilities across a wide range of experimental scenarios and report state-of-the art 3D layout generation and scene synthesis performance.

## 2 Related Work

Score-based Generative ModelsBy smoothly perturbing training examples with noise, Diffusion Models map a complex data distribution to a known Gaussian prior from which they sample back via

Figure 1: **Application scenarios overview.** Besides generating diverse and realistic 3D indoor layouts, a single trained DeBaRA model can be employed to execute several related tasks by tweaking the initial sampling noise level \(_{}\) and/or performing object or attribute-level layout inpainting. Our novel SSE procedure enables 3D Scene Synthesis capabilities by efficiently selecting conditioning semantics from external sources using density estimates provided by the pretrained model.

iterative denoising using a neural network trained over multiple noise levels. This family of generative models has been motivated by several theoretical foundations over the past years: DDPMs [16; 33] parameterize the diffusion process as a discrete-time Markov chain, as opposed to _continuous-time_ approaches [49; 48]. The seminal EDM [19; 20] training and sampling settings later unified previous methods into an improved ideal framework defined by a set of interpretable parameters. Originally motivated by image generation, diffusion models have demonstrated impressive capabilities on various conditional tasks such as text-to-image synthesis [34; 45], image-to-image generation from various 2D input modalities [45; 64; 56], text-to-3D asset creation [40; 23] or environment-aware human motion synthesis [18; 24]. Relevant to our work, diffusion models have been applied to the generation of point clouds [31; 52] and other geometric representations involving 3D coordinates .

Lifting Pretrained Diffusion ModelsKnowledge of trained diffusion models can be leveraged in various settings including content inpainting[30; 18], score distillation , exact likelihood computation [49; 19] or teacher-student distillation [47; 32]. More relevant to our work, image-domain diffusion priors have demonstrated compelling performance in discriminative tasks including zero-shot image classification [22; 6; 5] and segmentation . More precisely, Diffusion Classifiers assign a label, from a finite set of possible classes \(\{_{i}\}_{i=1}^{N}\) to an observed sample \(_{0}\) by computing class-conditional density estimates from a pretrained diffusion model under the assumption of a uniform prior \(p(_{i})=1/N\). In practice, this is done by, for each class, iteratively adding noise to the observed sample \(_{0}\) and computing a Monte Carlo estimate of the expected reconstruction loss using the class-conditioned model.

Controllable 3D Scene SynthesisSynthesizing indoor 3D layouts from a partial set of information or constraints has come in various settings depending on provided vs. predicted entities and enabled control granularity. A prolific line of research has been adopting intermediate 3D scene representations such as graphs [25; 43; 54; 36; 62; 13; 26], furniture matrices  or multi-view images . Autoregressive furnishing approaches [55; 38] have been supplemented by object attribute-level conditioning [37; 27] and additional ergonomic constraints . However, their _one object at a time_ strategy does not comprehensively capture complex relationships between all the interacting elements and is known to easily fall into local minima in which new items fail to be accurately inserted to the current configuration. Lately, methods have unfolded LLMs double-edged capabilities in this area [9; 61] as they excel at generating sensible furniture descriptions while struggling in accurately arranging them in the 3D space, which  addresses by introducing a costly refinement stage. In the light of that, LLMs appear to be ideal candidates to supplement a specialized 3D layout generation model.

Denoising Indoor ScenesPrevious methods have explored diffusion-based approaches in the context of 3D scene synthesis. Pioneering their usage, LEGO-Net  performs scene re-arrangement (i.e., recovering a _clean_ object layout from a _noisy_ one) in the 2D space using a transformer backbone that is not noise-conditioned, which we argue is the root cause of its main limitations. PhyScene augment diffusion-based 3D scene synthesis with additional physic-based guidance to enable practical embodied agent applications. Most relevant to our work, DiffuScene  achieves 3D scene synthesis by fitting a DDPM  on stacked 3D object features, resulting in a high-dimensional composite distribution that is hard to learn and interpret. It does not enforce spatial configurations over other predicted features. More importantly, its generative process is not conditioned on the room's floor plan (i.e., bounds) that constrains objects to be placed within a restricted area.

## 3 Method

### 3D Scene Representation

Our method is based on encoding the state of a 3D indoor scene \(\) that is defined by a floor plan (i.e., bounds) \(\) and an unordered set of \(N\) objects \(=\{o_{1},,o_{N}\}\), each being modeled by its typed 3D bounding box \(o_{i}=\{_{i},_{i}\}\) where \(_{i}\{0,1\}^{k}\) is the one-hot encoding of the semantic category among \(k\) classes and \(_{i}=(_{i},_{i},_{i})^{8}\) comprises 3D spatial attributes. More specifically, \(_{i}^{3}\) denotes the object's center coordinate position, \(_{i}=(_{i},_{i})^{2}\) is a continuous encoding of the rotation of angle \(_{i}\) around the scene's vertical axis  and \(_{i}^{3}\) is the dimension.

[MISSING_PAGE_EMPTY:4]

common 3D space. Importantly, a noise token \(_{}\) is computed from the current noise level \(\), making our architecture _noise-aware_, i.e., able to denoise layouts \(_{}\) at any perturbation magnitude.

All the previously encoded tokens form a sequence \(=\{_{},_{},_{o_{i} },,_{o_{N}}\}\) from which a global scene encoder \(T_{}\) computes rich representations \(}\). We design the method without any token ordering and use padding mask for scene with fewer objects than the transformer capabilities. A final shared decoder MLP takes as input object tokens \(\{}_{o_{i}}\}_{i=1}^{N}\) and returns denoised spatial attribute values \(}=\{(}_{i},}_{i},}_{i})\}_{i=1}^{N}\). We provide implementation details on the denoiser in Appendix B.1.

### 3D Spatial Objective

Our noise-conditioned model \(D_{}\) is optimized towards a novel semantic-aware Chamfer Distance objective that does not penalize permutation of 3D bounding boxes sharing the same semantic category between the predicted scene objects layout \(}\) and the ground truth one \(\):

\[_{CD}(},)=(_{}_{o}l(,o)+_{o }_{}}l(,o)),\] (1)

\[ l(,o)=\|}-\|_{2}^{2}+1 -_{}(,o).\] (2)

Here, \(\) is a large value so that a significant penalty is applied to objects that do not share the same semantic category \(\), preventing them to be returned by the \(\) operator.

We can finally rewrite the usual score-based training objective [49; 19] as:

\[_{p_{}(),,}() _{CD}(D_{}(+;,),) \] (3)

where \(()\) is a noise-dependent loss weighting function.

### Self Score Evaluation

While specifying complete conditioning information such as the set of object semantics \(\) could be tedious, it can be _provided_ by either a LLM or a separately trained sequence generation model. However, using independent models is inherently suboptimal since it does not guarantee that the generated conditioning input will be aligned with the score model knowledge. As a result, we propose a novel method to select conditioning inputs that are attuned with the model's capabilities.

More specifically, we evaluate a finite set of \(C\) object semantic categories _candidates_, where each candidate is associated to a 3D spatial layout sampled from the learned conditional density, i.e.,

\[=_{j},_{j} p_{} |,_{j})}_{j=1}^{C}\] (4)

Then, the optimal conditioning candidate \(^{*}\) is derived from a density estimate of its corresponding 3D spatial layout \(^{*}\) provided by the unconditional network:

\[^{*}=\,_{_{i}}_{,}_{CD}\{D_{}(_{i}+\,;\,,, ),_{i}\}\] (5)

```
0: a diffusion prior \(D_{}\) trained with conditioning dropout and by optimizing \(_{CD}\)
0: conditioning candidates \(\{_{j}\}_{j=1}^{C}\), number of score evaluation trials \(T_{}\)
1: sample\(_{j} p_{}(|,_{j})\) for each candidate \(_{j}\) using iterative sampling
2: initialize scores[\(_{j}\)] = list() for each \(_{j}\)
3:for trial \(t=1,,T_{}\)do
4: sample\((0,_{s});(, )\)
5:for candidate \(_{k}\), sample \(_{k}\)do
6: scores[\(_{k}\)].append(\(_{CD}[D_{}(_{k}+,;\,,, ),_{k}]\))
7:endfor
8:endfor
9:return\(\,_{_{j}}_{j}\) ```

**Algorithm 1** Self Score EvaluationIn practice, we compute an unbiased Monte Carlo estimate of each candidate expectation using \(T_{}\) fixed \((,)\) pairs. Although similar in some aspects, SSE fundamentally differs from diffusion classifiers  as in our case, the uniform assumption over conditioning probabilities does not hold. Indeed, in our setting some input signals cannot lead to a plausible arrangement at all. As a result, density estimates of observed samples generated by the class-conditioned model are computed using the unconditional one, while diffusion classifiers compute density estimates of a single observed sample using the class-conditioned model. The SSE procedure is detailed in Algorithm 1. It is further illustrated and discussed in Appendix C.

### Application Scenarios

As shown in Figure 1, a single trained DeBaRA model can be used at test time to perform multiple downstream interactive applications. Usual generation procedures, such as EDM 2nd order stochastic sampler  can be applied using our trained denoiser to generate novel 3D layouts via \(T\)-step iterative denoising at discretized noise levels \(_{0}=_{}>>_{T}=0\).

In particular, several applications can be performed by inpainting , i.e., predicting missing spatial features from those specified (i.e., fixed) in the input layout \(^{N 8}\). To do so, we introduce a binary mask \(\{0,1\}^{N 8}\) specifying values to retain from the input. The predicted layout at any sampling iteration \(t\) can be expressed as:

\[}_{_{t}}=}_{_{t}}(1-)+ {x}_{_{t}}\] (6)

3D Layout GenerationNovel and diverse 3D layouts can be generated from an input set of semantic categories \(\) and a floor plan \(\) by sampling from a high initial noise level \(_{}>>_{}\), arbitrarily initialized 3D spatial features \(_{_{0}}\) and with \(=_{N 8}\).

3D Scene SynthesisDeBaRA can perform 3D scene synthesis via 3D layout generation from semantic categories provided by external sources such as a LLM . Input conditioning candidates can further be optimally selected using the Self Score Evaluation procedure.

Scene CompletionAdditional objects \(o_{u}\) can be inserted to an existing scene partially furnished with \(k\) objects \(o_{e}\). To do so, their 3D spatial attributes \(_{a}\) are inpainted from the existing ones \(_{e}\) with \(D_{}\) conditioned on the updated set of semantic categories \(=_{e}\|_{a}\) using \((i,j)=_{\{i k\}}\).

Re-arrangementIn the context of scene synthesis, re-arrangement  consists in recovering the closest _clean_ spatial configuration of existing objects from a _messy_ one, which has practical applications in robotics . DeBaRA can perform re-arrangement by sampling from an initial noise \(_{}\) that depends on the scene perturbation magnitude. During denoising, object positions and rotations \((,)^{N 5}\) are inpainted from the known object dimensions using \((i,j)=_{\{j>5\}}\).

Figure 3: We compare our method with established baselines for generating a 3D layout from a floor plan and set of object categories. DeBaRA produces less failure cases while consistently generating regular arrangements within the room’s bounds.

Optimal Object Retrieval3D scene synthesis systems depend on external 3D asset databases for furnishing rooms. For each object of semantic class \(\), a textured furniture is retrieved by minimizing the mismatch with the generated dimension \(_{^{x}}\). This is inherently suboptimal as the resulting scene quality is limited by the size of the external database. To overcome this issue, we introduce a post-retrieval refinement stage by performing additional _re-arrangement_ steps starting from a noise level \(_{}\) derived from the mismatch between generated and retrieved object dimensions.

Generation from Coarse SpecificationsWe propose a time-dependent masking approach to synthesize layouts from _rough_ input spatial features (i.e., instead of _exact_ ones), that are adjusted in the late denoising iterations. To indicate approximate e.g., object dimensions, we set, at any sampling step \(t\), \((i,j)=_{\{j>5t<T_{s}\}}\). The denoising step \(T_{s}\) from which \(\) is _relaxed_ (i.e., set to \(\)) can be derived from its corresponding noise level \(_{T_{s}}\) and the precision of specified input features.

## 4 Experiments

In this section, we provide a comprehensive experimental evaluation of DeBaRA that we compare with established baselines from different model families. We also demonstrate the capabilities of our approach in various practical scenarios, enabling a wide range of applications.

DatasetsOur experiments are conducted on the 3D-FRONT  synthetic indoor layouts, furnished with assets from 3D-FUTURE  that we use as the object retrieval database. Out of the available room types in the dataset, we independently consider living rooms and dining rooms which are more densely furnished and feature complex floor plans. We follow the preprocessing from ATISS , leading respectively to \(2338/587\) and \(2071\)/\(516\) train/test splits.

BaselinesWe compare DeBaRA with ATISS  autoregressive transformer and DiffuScene  denoising network. To ensure a fair comparison with our method, we retrained both models with floor plan conditioning on each 3D-FRONT subset using their official implementations. To perform 3D arrangement generation with DiffuScene, we implemented DDPM inpainting  of object spatial features from their known semantic categories. Additionally, we report experimental results obtained by LayoutGPT  that we implemented with a Llama-3-8B backbone  that we also use to provide semantic categories in scene synthesis scenarios. Following the paper, we perform prompting with _supporting examples_: for each test scene, we retrieve top-\(k\) samples from the training set that have the most similar floor plan and include their spatial configuration as few-shot exemplars. Note that LayoutGPT adopts a training-free approach and is therefore not directly comparable to our method. However, we show how it can be used _alongside_ a specialized model such as DeBaRA. Full implementation details and LLM prompting strategies are reported in Appendix B.3.

Evaluation MetricsWe follow previous work [43; 38; 51; 9; 55] and evaluate the realism and diversity of generated arrangements by reporting the \(256^{2}\) Frechet Inception Distance (FID) , Kernel Inception Distance (KID \( 1,000\))  and Scene Classification Accuracy (SCA, values closer to \(50\%\) are better) computed on top-down orthographic renderings. Resulting projections feature the scene's floor plan and objects colored according to their semantic class . The generation spatial validity is further assessed by reporting the cumulated out of bounds objects area (OBA, in \(m^{2}\)). Related indicators are provided and discussed in Appendix D.1. Metrics are computed across each test subset, for which we generate the same number of scenes as the number of _real_ ones.

Figure 4: Qualitative results on **scene re-arrangement** (left) and **completion** (right). DeBaRA is able to recover a plausible layout from a messy one, and to finely take into account initial configurations.

### 3D Layout Generation

The primary task of DeBaRA is to generate diverse and valid 3D layouts within a given floor plan and a list of object semantics. We showcase qualitative generation results and comparisons in Figure 3. As highlighted by previous work [57; 51], denoising-based methods better capture the interplay between interacting objects. We also observe that DeBaRA largely outperforms baselines at respecting the scene's bounds while consistently producing more natural arrangements. These observations are quantitatively verified in Table 1 and visualized in Figure 3.

### 3D Scene Synthesis and Self Score Evaluation

We demonstrate competitive or state-of-the-art capabilities on 3D scene synthesis against methods that have been specifically trained for this task. We consider several settings depending on the source of input object categories and report our results in Table 2. First, we observe that randomly picking input semantics from the training set (_Dataset Random_) or taking the set \(\) generated by _LayoutGPT_ outperform baselines by a significant margin on the 3D-FRONT living rooms test set. Then, to measure the individual impact of SSE, we compare a setup in which input semantics are selected from a set of LLM-generated ones, either randomly (_LLM_) or by applying _SSE_. As LLMs often hallucinate or produce out-of-distribution sets, our procedure consistently improves realism and validity of the synthesized indoor scenes, which can also be qualitatively observed in Figure 5. These results further validate our choice to focus solely on 3D spatial features of objects.

    &  &  \\   & FID (\(\)) & KID (\(\)) & SCA (\%) & OBA (\(\)) & FID (\(\)) & KID (\(\)) & SCA (\%) & OBA (\(\)) \\  LayoutGPT  & 35.53 & 13.69 & 72.8 & 2913.6 & 32.80 & 8.99 & 67.6 & 2447.4 \\  ATISS  & 25.67 & 8.91 & 71.8 & 857.3 & 28.05 & 9.26 & 63.2 & 702.4 \\ DiffitScene  & 21.54 & 6.40 & 69.7 & 341.1 & 23.06 & 5.35 & 57.7 & 266.4 \\
**DeBaRA (ours)** & **18.89** & **3.57** & **68.3** & **167.8** & **22.04** & **4.41** & **52.4** & **132.8** \\   

Table 1: Quantitative experiment results on **bounded 3D layout generation** (providing a floor plan and a list of object semantic categories). We compare our method against other learning-based approaches and additionally indicate results obtained from a training-free LayoutGPT.

    &  &  \\   & FID (\(\)) & KID (\(\)) & SCA (\%) & OBA (\(\)) & FID (\(\)) & KID (\(\)) & SCA (\%) & OBA (\(\)) \\  LayoutGPT  & 34.26 & 10.17 & 72.1 & 2902.7 & 37.78 & 11.31 & 60.2 & 1982.1 \\ ATISS  & 27.02 & 10.99 & 73.0 & 848.4 & 28.26 & 9.28 & 58.2 & 759.1 \\ DiffitScene  & 21.64 & 5.94 & **66.0** & 323.1 & **23.85** & 5.66 & 54.6 & 289.8 \\   & _LayoutGPT_ & 20.97 & 3.53 & 69.8 & 193.0 & 26.67 & 7.14 & 56.6 & 151.8 \\  & _Dataset Random_ & **19.52** & **3.53** & 67.6 & **159.0** & 25.45 & **5.11** & **52.5** & **139.5** \\    & _LLM_ & 21.58 & 3.53 & 72.4 & 154.3 & 27.09 & 7.38 & 60.5 & 140.4 \\  & _LLM + SSE_ & **20.59** & **3.47** & **70.7** & **152.0** & **24.50** & **5.34** & **54.0** & **134.4** \\   

Table 2: Quantitative experiment results on **3D scene synthesis**. DeBaRA is evaluated in various settings based on the source of object semantic categories \(\). Precise settings are detailed and discussed in Appendix B.4. DeBaRA outperforms established baselines on most evaluation metrics.

Figure 5: Top-down views of scenes generated by DeBaRA from several _conditioning candidates_ provided by a LLM and their associated SSE values. We qualitatively observe that lower scores (_green_) corresponds to more natural layouts while higher scores (_red_) can be filtered out.

### Other Application Scenarios

We present DeBaRA's capabilities at performing additional controllable tasks. Notably, we include quantitative (Table 3) and qualitative (Figure 7) experimental evaluations against LEGO-Net  on scene-rearrangement. Results highlight that our method is able to recover more realistic arrangements, while being closer to their initial, _messy_ configurations. This is remarkable as the LEGO-Net baseline has been specifically trained to perform this task.

We also provide additional re-arrangement results and showcase DeBaRA's scene completion capabilities, by inserting objects from a list of additional semantics, in Figure 4.

### Ablations

We evaluate the individual contributions of some of our framework's key components on the base 3D layout generation task. Notably, results reported in Table 4 highlight the advantage of our novel objective (Section 3.3) over common formulations as well as the benefits of modeling both the unconditional and class-conditional densities of 3D layouts during training (Section 3.2).

### Additional Results

Complex Floor PlansWe notice that the 3D-FRONT dataset mostly contains _simple_ floor maps (i.e., single room, squared, rectangular) both for training and evaluation. As a result, we manually designed irregular floor shapes and report DeBaRA's generation in Figure 8, which further highlights the robustness of our method and its consideration for the conditioning input.

    &  &  \\  \((,)\) & \(p_{}\) & FID (\(\)) & KID (\(\)) & SCA (\%) & OBA (\(\)) & FID (\(\)) & KID (\(\)) & SCA (\%) & OBA (\(\)) \\  \(MSE\) & 0.0 & 21.66 & 6.55 & 70.9 & 237.0 & 23.89 & 5.51 & 56.9 & 136.5 \\ \(CD\)_standard_ & 0.0 & 21.76 & 7.05 & 71.7 & 225.1 & 25.21 & 6.75 & 59.4 & 294.7 \\ \(CD\)_semantic-aware_ (**ours**) & 0.0 & 19.89 & 4.82 & **63.5** & 220.0 & 22.60 & 4.87 & 53.4 & 159.4 \\  \(CD\)_semantic-aware_ (**ours**) & 0.2 & **18.89** & **3.57** & 68.3 & **167.8** & **22.04** & **4.41** & **52.4** & **132.8** \\   

Table 4: Ablation study on DeBaRA **training setup**. We evaluate the individual impact, on 3D layout generation, of different learning objectives \(\) and of applying conditioning dropout with rate \(p_{}\). Notably, the use of our novel Chamfer distance results in a significant performance increase.

    & FID (\(\)) & KID (\(\)) & 
 Distance \\ Moved (\(\)) \\  \\  LEGO-Net  & 26.81 & 13.18 & 0.094 \\
**DeBaRA** & **24.92** & **9.47** & **0.082** \\   

Table 3: Quantitative evaluation on **scene rearrangement**. DeBaRA is able to recover more realistic arrangements, closer to their initial _noisy_ configurations.

Figure 8: Generated layouts from a given set of objects and **complex floor plans**, selected from the 3D-FRONT test set or handcrafted to irregular, out-of-distribution shapes. While challenging, DeBaRA is able to output plausible layouts in which objects are scattered across the input floor plans.

Figure 7: Qualitative comparison against LEGO-Net  on **scene re-arrangement**.

Iterative SamplingWe provide a visualization of the iterative denoising process over time when generating a 3D layout from arbitrarily initialized object bounding boxes in Figure 9.

Generation Variety and ValidityWe also perform scene completion by adding a bookshelf and a coffee table, repeat the experiment ten times and report in Figure 10 the denoising object trajectories, intermediate and final positions (colored and black dots respectively). This allows to observe the variety of predicted layouts. Notably, we can see that the bookshelf ends up in various different positions, always next to a wall, while the coffee table, which is functionally constrained by its surrounding objects, is placed at similar valid locations.

Network EfficiencyFinally, we compare the number of parameters as well as the sampling (i.e., generation) time, measured on the 3D layout generation task, of our DeBaRA backbone with those of other recent data-driven approaches in Table 5. We can see that our lightweight architecture is bridging the gap with autoregressive methods in terms of inference efficiency.

## 5 Conclusion, Limitations and Future Work

In this paper we proposed DeBaRA, a novel score-based framework, which achieves state-of-the-art results in 3D layout generation. Our approach is distinctive in its design choices, which both favor data-efficiency with enhanced spatial reasoning, while, at the same time, enabling a range of applications such as scene re-arrangement and completion. Furthermore, we introduce a novel Self Score Evaluation procedure, which allows us to leverage a trained model to select the conditioning signals, which lead to the most plausible results. Overall, our work is the first to unify the conditioning and prediction spaces of score-based models within the context of 3D generative layout.

While powerful, our method currently does not enforce physical constraints between interacting objects, which can lead to collisions. We also assume that object semantic classes are selected among a finite set of predefined categories. Finally, we do not enforce _style consistency_ between objects, which can, nevertheless, be performed at retrieval time.

We believe that our approach can enhance other generative models (e.g., architectural layouts, images) by both evaluating the quality and by promoting more plausible 3D layout designs. Furthermore, it will be interesting to combine our approach with encoders from other modalities for a unified multi-modal layout generation.

Figure 10: Visualization of sampling trajectories and final positions of a pair of objects, inserted into a scene across ten trials.

    & Network & Generation \\  & Parameters (\(10^{6}\)) & Time (s) \\  ATISS  & 36.1 & 0.160 \\ DiffuScene  & 89.7 & 32.796 \\
**DeBaRA** & 12.2 & 0.488 \\
**DeBaRA + SSE** & 12.2 & 0.894 \\   

Table 5: Generation times are averaged on the 3D-FRONT  living room test subset. DeBaRA is implemented with \(T=50\) sampling steps and \(T_{}=100\) Self Score Evaluation trials.

Figure 9: Visualization of intermediate layouts throughout the DeBaRA **denoising process**. _Coarse_ object attributes (positions, rotations and dimensions) are determined in the early steps, and then refined in the late iterations.