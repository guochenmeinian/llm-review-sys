# Personalized Federated Learning with

Mixture of Models for Adaptive Prediction and

Model Fine-Tuning

 Pouya M. Ghari

University of California Irvine

pmollaeb@uci.edu

&Yanning Shen

University of California Irvine

yannings@uci.edu

Corresponding author

###### Abstract

Federated learning is renowned for its efficacy in distributed model training, ensuring that users, called clients, retain data privacy by not disclosing their data to the central server that orchestrates collaborations. Most previous work on federated learning assumes that clients possess static batches of training data. However, clients may also need to make real-time predictions on streaming data in non-stationary environments. In such dynamic environments, employing pre-trained models may be inefficient, as they struggle to adapt to the constantly evolving data streams. To address this challenge, clients can fine-tune models online, leveraging their observed data to enhance performance. Despite the potential benefits of client participation in federated online model fine-tuning, existing analyses have not conclusively demonstrated its superiority over local model fine-tuning. To bridge this gap, the present paper develops a novel personalized federated learning algorithm, wherein each client constructs a personalized model by combining a locally fine-tuned model with multiple federated models learned by the server over time. Theoretical analysis and experiments on real datasets corroborate the effectiveness of this approach for real-time predictions and federated model fine-tuning.

## 1 Introduction

Federated learning enables a group of learners, known as _clients_, to collaborate and collectively train a model under the coordination of a central _server_, without revealing their data. In this framework, clients perform local model updates and share these updates with the server. By aggregating these local updates, the server globally updates the model. Many prior works in the literature have assumed that each client stores a batch of training data and updates models locally based on this stored data (see e.g., [38; 29; 47; 5; 34; 53]). However, in some cases, clients may need to make real-time predictions, and streams of data arrive sequentially, making it challenging to store and process data in batch. Furthermore, if clients operate in a non-stationary and dynamic environment, employing pre-trained models may fall short in prediction accuracy, requiring clients to fine-tune their models to adapt to their data.

A federated learning framework, commonly referred to as online federated learning [37; 26; 19], specifically addresses situations where clients engage in real-time predictions using a shared global model. After making predictions, clients collaborate with the server to update the global model for subsequent predictions in the future. Specifically, after making predictions, clients incur losses and based on the incurred losses, clients update the model locally and send their local updates to the server. The server updates the global model upon aggregating local updates and then distributes the updated global model to clients for use in the ongoing online prediction task. In this context, theperformance of clients can be assessed using the notion of _regret_[4; 3]. The regret of a client at a given time step is defined as the difference between its prediction loss and that of the best model in hindsight. The best model in hindsight is determined as the model that achieves the minimum total prediction loss over time across all clients' data. The primary objective is to minimize the cumulative regret of all clients over time.

In the literature, federated learning algorithms based on online gradient descent have been proposed that achieve sub-linear regret upper bounds [37; 26; 19]. This suggests that over the long run, these algorithms perform as well as the best model in hindsight. However, in Section 3, this paper demonstrates that these federated learning algorithms do not obtain tighter regret bounds compared to the scenario where each client learns its own model locally without participating in federated learning. This indicates that participation in federated learning may not provide any benefit for clients performing online prediction. Specifically, if data is distributed non-i.i.d. among clients and data distributions are time-variant and not known a priori, it is likely that local model training by clients will achieve better prediction accuracy than participation in federated learning. Although the benefit of federated learning in online prediction is not evident in existing theoretical analyses, models learned through federated learning enjoy higher generalizability as they are trained on all data samples distributed among clients. This motivates the idea that combining the model learned through federated learning with the locally learned one may prove effective in scenarios where clients need to perform online prediction.

This paper proposes the Fed-POE (Federated Learning with Personalized Online Ensemble) algorithm, through which each client constructs a personalized model for online prediction by adaptively ensembling the locally learned model and the model learned through federated learning. With Fed-POE, clients can adapt their local models to their data while benefiting from the higher generalizability of the federated model. Theoretical analysis for convex cases demonstrates that Fed-POE achieves sublinear regret bounds with respect to both the best federated and local models in hindsight. This indicates that Fed-POE effectively leverages the advantages of both federated and local models. Providing such theoretical guarantees may not be feasible for non-convex models such as neural networks. These models may suffer from the forgetting process [51; 45], where fine-tuning on streaming data 'on the fly' can lead to forgetting previously observed data samples. To overcome this challenge, the present paper proposes a novel framework in which the server periodically stores federated model parameters over time. Each client adaptively selects a personalized subset of stored models on the server based on the performance of these models in the client's online prediction task. Clients then use the selected models, along with the federated and local models, to construct an ensemble model for prediction. Clients select a subset of models to both control the memory and computational complexity of prediction and to prune models with relatively lower accuracy, thereby improving prediction performance. Theoretical analysis proves that Fed-POE achieves sublinear regret with respect to the best model in hindsight among the local model, federated model, and all models stored by the server. The contributions of the present paper are summarized as follows:

* Fed-POE enables clients to utilize the advantages of both local and federated models for online prediction tasks.
* To address the issue of forgetting in online prediction, Fed-POE introduces a novel federated framework for collaboration between clients and the server.
* Theoretical analyses for both convex and non-convex cases prove that Fed-POE achieves sublinear regret with respect to the best model in hindsight.
* Extensive experiments on regression and image classification datasets show that Fed-POE effectively leverages the benefits of local and federated models, achieving higher online prediction accuracy compared to state-of-the-art federated learning algorithms.

## 2 Related Works

**Personalized Federated Learning.** Personalized federated learning involves developing individualized models for each client, derived from a global model learned through federated learning. Several personalized federated learning algorithms have been proposed in the literature [50; 6; 54; 56]. In [24; 11; 30; 33], clients construct their personalized models by adding a regularization term to the local objective and using the global federated model. Algorithms in [12; 1] allow clients to fine-tune the global federated model using model-agnostic meta-learning  to learn their personalizedmodels. With Fed-Rep , each client generates a representation using the global model and learns its own local head for prediction. Algorithms in [10; 32; 57] enable clients to achieve personalized models by combining local and global models. However, none of these works have addressed the problem of online prediction while clients collaborate on training their personalized models.

**Federated Learning with Streaming Data.** Several studies have explored the problem of federated learning when clients receive a stream of data in real time. While [7; 36; 35] investigate federated learning scenarios where clients receive new training data in each learning round, they do not address the aspect of online prediction by clients. Consequently, these works cannot provide regret guarantees for online prediction. Additionally,  studies the issue of staleness in online federated learning to both train and make prediction with the model; however, it lacks rigorous theoretical analysis. In , an online federated learning algorithm is introduced, utilizing online mirror descent, with a proven sublinear regret bound. Similarly, [42; 16] propose online federated learning algorithms with guaranteed sublinear regret. Furthermore,  analyzes the benefits of collaboration in online federated learning, particularly in scenarios where only loss values at queried points are available to clients, without access to loss gradients. Regarding online federated kernel learning, algorithms are introduced in [17; 23], albeit without accompanying regret analysis, leading to an absence of guaranteed regret bounds. In [26; 19], multiple kernel-based models and random feature-based online federated kernel learning algorithms are proposed, with demonstrated sublinear regret.

## 3 Preliminaries

This section explains the problem of federated learning for real-time prediction and model training. The present section studies the cases where clients either collaborate in federated learning or employ online gradient descent methods to locally train the model in real-time. This study highlights the motivation behind the proposed ensemble approach to federated learning.

### Online Prediction and Federated Learning

Let there are \(N\) clients interact with a server to train a model \(f(;)\). Also, let \([N]:=\{1,,N\}\). At each time step \(t\), client \(i\), \( i[N]\) receives a data sample \(_{i,t}^{d}\) and makes the prediction \(f(_{i,t};_{t})\) where \(_{t}\) denotes the parameter of the model at time step \(t\). Note that generalization to the scenario where at each time step, each client receives a dataset instead of a single data sample is straightforward. After making prediction, client \(i\), \( i[N]\) observes label \(y_{i,t}\). Then client \(i\), \( i[N]\) computes the loss of its prediction \((f(_{i,t};_{t}),y_{i,t})\) where \((,)\) denotes the loss function. After computing the loss, clients send their updates to the server (e.g., by sending the gradient loss \((f(_{i,t};_{t}),y_{i,t})\)) and the server aggregates information from clients to update \(_{t}\) to \(_{t+1}\) to be used by clients to make predictions at time step \(t+1\). For ease of presentation, it is assumed that all clients can send their updates to the server every time step. Generalizing the results for the cases where only a fraction of clients can send their updates is straightforward. Furthermore, it is assumed that the label \(y_{i,t}\) for any \(i\) and \(t\) is determined by the environment through a process unknown to the clients. This implies that the data distribution observed by client \(i\) can be non-stationary, and client \(i\), \( i[N]\) does not know the distribution. Additionally, the data distribution can differ across clients. The goal is to enable clients to collaborate with the server to minimize the cumulative regret of clients over time. The regret of client \(i\) at time step \(t\) is defined as the difference between the prediction loss \((f(_{i,t};_{t}),y_{i,t})\) and the loss \((f(_{i,t};^{*}),y_{i,t})\) corresponding to the model with the optimal parameter \(^{*}\). Therefore, the average cumulative regret of clients up to time horizon \(T\) is defined as

\[R_{T}=_{t=1}^{T}_{i=1}^{N}(f(_{i,t};_{t}),y_{i,t})-_{t=1}^{T}_{i=1}^{N}(f( {x}_{i,t};^{*}),y_{i,t})\] (1)

where \(^{*}\) denotes the optimal model parameter in hindsight and can be expressed as

\[^{*}=*{arg\,min}_{}_{t=1}^{T}_{i= 1}^{N}(f(_{i,t};),y_{i,t}).\] (2)

One common way to solve the problem is that clients employ online gradient descent to update models locally and the server exploits federated averaging [31; 37] to update the global model.

### Federated Learning with Online Gradient Descent

At each time step \(t\), client \(i\) obtains the locally updated model parameter \(_{i,t+1}\) as follows:

\[_{i,t+1}=_{t}-(f(_{i,i};_{t}),y_{i,t})\] (3)

where \(\) is the learning rate. Aggregating locally updated model parameters, the server obtains the updated global model parameter for time step \(t+1\) as

\[_{t+1}=_{i=1}^{N}_{i,t+1}.\] (4)

This continues up until the time horizon \(T\). This paper examines regret under some or all of the following assumptions:

**A1.** The loss function \((f(;),y)\) is convex with respect to \(\).

**A2.** The gradient of the loss is bounded as \(\|(f(;),y)\| G\).

**A3.** For any \(\), \(\), the loss is bounded as \(0(f(;),y) 1\).

The following theorem specifies the regret bound for federated learning employing online gradient descent under A1 and A2.

**Theorem 1**.: _Employing online gradient descent, the following cumulative regret upper bound is guaranteed for federated learning under assumptions A1 and A2:_

\[_{t=1}^{T}_{i=1}^{N}(f(_{i,t}; _{t}),y_{i,t})-_{t=1}^{T}_{i=1}^{N}(f(_{i,t};^{*}),y_{i,t})^{*}\|^{2}}{2}+G^{2}T.\] (5)

Proof of Theorem 1 can be found in Appendix A. According to Theorem 1, choosing \(=()\), the cumulative regret in (5) is bounded from above as \(()\). If the time horizon \(T\) is unknown, the doubling trick technique (see e.g., ) can be effectively used to set the learning rate to maintain theoretical guarantees. Consider the case where each client learns the model locally using online gradient descent without collaborating with other clients and the server. Let \(_{i,t}\) denote the local model parameter learned by client \(i\) at time step \(t\), employing online gradient descent locally. The regret of client \(i\) in this case is equivalent to federated learning regret where there is only one client. Therefore, substituting \(N=1\) and \(_{0}=\) in (27) of Appendix A, for the cumulative regret of client \(i\) with respect to any \(\), we get

\[_{t=1}^{T}(f(_{i,t};_{i,t}),y_{i,t})-_{t=1} ^{T}(f(_{i,t};),y_{i,t})\| ^{2}}{2}+G^{2}T.\] (6)

Averaging (6) over all clients and substituting \(\) with \(^{*}\) in (6), we obtain

\[_{t=1}^{T}_{i=1}^{N}(f(_{i,t};_{i,t}),y_{i,t})-_{t=1}^{T}_{i=1}^{N}(f(_{i,t} ;^{*}),y_{i,t})^{*}\|^{2}}{2}+G^{2}T.\] (7)

Comparing (5) with (7), it can be inferred that under assumptions A1 and A2, federated learning does not achieve tighter regret bound than the case where each client independently learns its local model. Hence, from a theoretical standpoint, it remains uncertain whether collaboration in federated learning yields any improvement over local online model training. Intuitively, collaboration in federated learning may prove advantageous when there exists similarity among data samples observed by clients over time. However, in cases where data distribution is heterogeneous and such similarities are lacking, employing online local training may yield superior results for a client. Given the lack of prior information on data distribution in online scenarios, each client can independently assess over time whether utilizing the model learned through federated learning for predictions is beneficial.

Furthermore, according to assumption A1, the theoretical guarantees obtained in (5) and (7) hold if the loss is convex with respect to the model parameter. However, in the case of non-convex models, such as neural networks, these theoretical guarantees are not applicable. Non-convex models, like neural networks, may encounter the forgetting process , where the model tends to overfit to recently observed data samples. Consequently, it may not be feasible to derive a single model parameter using online gradient descent that achieves sublinear regret with respect to the best model in hindsight. The subsequent section introduces a novel algorithm aimed at assisting clients in addressing such scenarios.

Personalized Federated Learning Methods

The current section introduces personalized federated learning algorithms where each client dynamically learns the prediction performance of both the models trained through federated learning over time and the locally learned model.

### Ensemble Learning

At each time step, each client constructs an ensemble model comprising the federated model and its locally learned model to make a prediction. Let \(_{i,t}\) be the model parameter locally learned by client \(i\) such that at each time step \(t\), client \(i\) updates \(_{i,t}\) via gradient descent as

\[_{i,t+1}=_{i,t}-(f(_{i,t};_{i,t}),y_{i,t}).\] (8)

Furthermore, let clients and the server collaborate to update the _federated_ model parameter \(_{t}\) as outlined in (3) and (4). At time step \(t\), client \(i\) makes the prediction for \(_{i,t}\) using its personalized ensemble model \(f_{i,t}()\) expressed as

\[f_{i,t}(_{i,t})=}{_{i,t}+_{i,t}}f(_{i, t};_{t})+}{_{i,t}+_{i,t}}f(_{i,t}; _{i,t})\] (9)

where \(_{i,t}\) and \(_{i,t}\) represent the weights assigned by client \(i\) to the federated and local models, respectively, indicating the credibility of predictions from each model. After making predictions and observing the label \(y_{i,t}\), client \(i\) computes the loss of predictions from the federated and local models, updating the weights \(_{i,t}\) and \(_{i,t}\) using the multiplicative update rule as follows:

\[_{i,t+1} =_{i,t}(-_{c}(f(_{i,t};_{t}),y_{i,t})),\] (10a) \[_{i,t+1} =_{i,t}(-_{c}(f(_{i,t};_{i,t}),y_{i,t}))\] (10b)

where \(_{c}\) is a learning rate. Client \(i\) initializes \(_{i,1}=1\) and \(_{i,1}=1\). The proposed algorithm is personalized since according to (9), each client constructs its own ensemble model to perform prediction. The personalized regret of client \(i\) is defined as \(C_{i,T}=_{t=1}^{T}(f_{i,t}(_{i,t}),y_{i,t})-_{t=1}^{T} (f(_{i,t};_{i}^{*}),y_{i,t})\) where \(_{i}^{*}\) denotes the best hindsight model parameter for client \(i\) which can be expressed as \(_{i}^{*}=_{}_{t=1}^{T}(f(_{i,t} ;_{i}),y_{i,t})\). The following theorem establishes the personalized regret upper bound for client \(i\) as well as global regret of all clients with respect to the best model parameter in hindsight.

**Theorem 2**.: _Under assumptions A1-A3, employing the ensemble model in (9) for online prediction, the global regret of all clients is bounded from above as_

\[\!_{t=1}^{T}\!_{i=1}^{N}\!(f_{i,t}(_{i,t} ),y_{i,t})\!-\!\!_{t=1}^{T}\!_{i=1}^{N}\!(f( _{i,t};^{*}),y_{i,t})\!\!^{*}\|^{2}}{2}\! +\!}\!+\!T}{2}\] (11)

_while client \(i\) achieves the following personalized regret upper bound:_

\[_{t=1}^{T}(f_{i,t}(_{i,t}),y_{i,t})-_{t=1}^{T} (f(_{i,t};_{i}^{*}),y_{i,t})_{i }^{*}\|^{2}}{2}+}+G^{2}T+T }{2}.\] (12)

Proof of Theorem 2 is given in Appendix B. According to (11) and (12) in Theorem 2, setting \(=(1/)\), \(_{c}=(1/)\) both the global regret for all clients and the personalized regret of each client \(i\) achieve a regret bound of \(()\). This demonstrates that while the ensemble model in (9) ensures personalized regret guarantees for each client with respect to its best model in hindsight, it also enables clients to leverage federated learning, thus enjoying sublinear regret in comparison to the best global model in hindsight.

**Comparison with Federated and Local Models.** The main advantage of using the ensemble model instead of the federated model lies in Theorem 2, where it is shown that the ensemble model can attain the global regret guarantee provided by the federated model while employing the federated model, achieving the personalized regret guarantee in (12) is not feasible. However, according to (6) and (7), using the online local training, each client achieves sublinear regret with respect to its best model while all clients achieve sublinear regret with respect to the best global model in hindsight.

This efficacy of local training stems from clients adapting the model to their individual data. In contrast, in federated learning, the model is trained on all data samples across clients, potentially leading to higher generalizability compared to its local counterpart. If there are similarities in the distribution of data samples among clients over time, the federated model is anticipated to achieve greater accuracy in online prediction. However, due to the lack of available information regarding the relationships between data samples observed by clients before online prediction, these advantages may not be reflected in theoretical bounds. The proposed method constructs an ensemble to harness the advantages of both federated and local models for online prediction, as evidenced by Theorem 2. Experimental results in Subsection 5.1 confirm that the ensemble model achieves superior performance compared to both local and federated models.

### Model Selection

Regret guarantees for the ensemble method, as outlined in Theorem 2, are contingent upon the model's convexity. However, if the model is non-convex, achieving such guarantees may not be feasible. Particularly, non-convex models such as neural networks are susceptible to the forgetting process , wherein applying online gradient descent may lead to overfitting to recently observed data samples. This section introduces a novel algorithm that allows clients to make online predictions using non-convex models while simultaneously collaborating to fine-tune the model. The scenario assumes the existence of a pre-trained model, and the objective for clients is two-fold: to make real-time predictions and to refine the model for alignment with their preferences. This situation may arise, for instance, in fine-tuning large foundation models to tailor them to client preferences.

Let the server and clients collaborate to fine-tune the non-convex model \(f(;)\). At each time step \(t\), client \(i\) updates the model on the batch of recently observed samples with size \(b\) as

\[_{i,t+1}=_{t}-_{=t-b}^{t} (f(_{i,};_{t}),y_{i,}).\] (13)

Then the server aggregates locally updated parameters and updates the federated model parameter as in (4). Furthermore, each clients learns its own local model by fine-tuning the pre-trained model locally via online gradient descent as in (8) on the batch of \(b\) recently observed samples. While online gradient descent methods are well-known for their efficiency in handling dynamic environments, employing the update rule of (13) for non-convex models may lead to overfitting to recently observed batches. To mitigate potential forgetting, the server saves the federated model parameters every \(n\) time step, where \(n\) is an integer hyperparameter.

Let \(_{t}\) represent the set of model parameters stored by the server at time step \(t\). At time step \(=(j-1)n+1\), the server adds \(_{}\) to \(_{}\) meaning that \(_{+1}=_{}\{_{}\}\). Let \(_{j}\) denotes the \(j\)-th model parameter in \(_{t}\). It can be concluded that \(_{j}=_{(j-1)n+1}\). The server continues saving model parameters every \(n\) time steps until time step \(U T\). Client \(i\) assigns a weight \(w_{ij,t}\) to the \(j\)-th model in \(_{t}\), which assesses the credibility of the predictions given by the model parameter \(_{j}\). Client \(i\) initializes \(w_{ij,1}=1\). At each time step \(t\), client \(i\) selects \(M\) models with replacement from \(_{t}\) to construct its model set \(_{i,t}\). Algorithm 1 illustrates the model selection process conducted by client \(i\) at time step \(t\). During each round of model selection, client \(i\) chooses a model according to a probability mass function (PMF) proportional to weights \(\{w_{ij,t}|1 j|_{t}|\}\) where \(||\) denotes the cardinality of a set (see step 3 in Algorithm 1). Client \(i\) adds the chosen model to \(_{i,t}\) if it is not already present. Therefore, it can be concluded that \(|_{i,t}| M\), \( i,t\). Then at each time step \(t\),client \(i\) downloads all models in \(_{i,t}\) from the server. Upon receiving the models, client \(i\) constructs an ensemble model \(_{i,t}()\) as

\[_{i,t}()=_{j_{i,t}}}{_{m _{i,t}}w_{im,t}}f(;_{j}).\] (14)

Client \(i\) makes the prediction for \(_{i,t}\) as

\[_{i,t}(_{i,t})=}{_{i,t}+_{i,t}}f_{i, t}(_{i,t})+}{_{i,t}+_{i,t}}_{i,t}( _{i,t})\] (15)

where \(f_{i,t}(_{i,t})\) is the ensemble of local and federated models as defined in (9). Furthermore, \(_{i,t}\) and \(_{i,t}\) are weights assigned by client \(i\) to ensemble models \(f_{i,t}()\) and \(_{i,t}()\), respectively. Upon observing the label \(y_{i,t}\) after prediction, client \(i\) updates weights \(_{i,t}\) and \(_{i,t}\) as

\[_{i,t+1} =_{i,t}(-_{c}(f_{i,t}(_{i,t} ),y_{i,t})),\] (16a) \[_{i,t+1} =_{i,t}(-_{c}(_{i,t}(_{i,t}),y_{i,t})).\] (16b)

Furthermore, \(_{i,t}\) and \(_{i,t}\) which are used to construct \(f_{i,t}(_{i,t})\) in (9) are updated as in (10). The weight \(w_{ij,t}\) is updated using the importance sampling loss as

\[w_{ij,t+1}=w_{ij,t}(-_{c}(f(_{i,t};_{j}),y_{i,t})}{q_{ij,t}}_{j_{i,t}})\] (17)

where \(_{j_{i,t}}\) denotes the indicator function and is 1 if \(j_{i,t}\). Moreover, \(q_{ij,t}\) is the probability that client \(i\) selects the \(j\)-th model in \(_{t}\) to be in \(_{i,t}\) and can be expressed as \(q_{ij,t}=1-(1-p_{ij,t})^{M}\) where \(p_{ij,t}\) is defined in step 3 of Algorithm 1. The proposed algorithm, named Federated Learning with Personalized Online Ensemble (Fed-POE) is summarized in Algorithm 2. It is useful to note that the proposed method in Subsection 4.1 is a special case of Fed-POE by setting \(M=0\) and \(b=1\).

```
1:Input: Model \(f(;)\), batch size \(b\), \(n\), \(U\), \(_{i,1}=\).
2:for\(t=1,,T\)do
3: The server transmits \(_{t}\) to all clients.
4:for all\(i[N]\), client \(i\)do
5: Performs model selection given \(_{t}\) according to Algorithm 1 to obtain \(_{i,t}\).
6: Makes prediction \(_{i,t}(_{i,t})\) as in (15) using chosen model set \(_{i,t}\).
7: Upon receiving \(y_{i,t}\), updates \(_{i,t}\), \(_{i,t}\), \(_{i,t}\), \(_{i,t}\) and \(\{w_{ij,t}\}_{j=1}^{[D_{i}]}\) as in (10), (16) and (17).
8: Updates the local model as \(_{i,t+1}=_{i,t}-_{=t-b}^{t} (f(_{i,t};_{i,}),y_{i,t})\).
9: Updates the federated model as \(_{i,t+1}=_{t}-_{=t-b}^{t} (f(_{i,};_{t}),y_{i,})\).
10: Sends \(_{i,t+1}\) to the server.
11:endfor
12:if\(t U\) and \(t n=0\)then
13: The server updates \(_{t}\) as \(_{t+1}=_{t}\{_{t}\}\).
14:endif
15: The server updates \(_{t}\) as \(_{t+1}=_{i=1}^{N}_{i,t+1}\).
16:endfor ```

**Algorithm 2** Fed-POE: Federated Learning with Personalized Online Ensemble

**Efficiency of Fed-POE.** To perform model selection using Fed-POE, clients do not need to store all model parameters in \(_{t}\) for all \(t[T]\). Instead, the server, which has higher storage capacity than the clients, stores all model parameters, and clients download a subset of at most \(M\) model parameters. The hyperparameter \(M\) can be chosen such that clients can handle the memory and computational requirements of making predictions with the selected subset of models. Let \(C_{F}\) denote the number of computations required to fine-tune the model \(f\), and let \(C_{I}\) represent the number of computations required to make an inference with model \(f\). Assume that the complexity of model selection in Algorithm 1 is negligible compared to fine-tuning and making inferences with model \(f\). According to Algorithm 2, each client performs \(2C_{F}+(M+2)C_{I}\) computations per time step. Therefore, the computational complexity of Fed-POE for each client is \((C_{F}+MC_{I})\). Beyond memory and computational considerations, selecting a subset of models from \(_{t}\) helps clients improve their prediction accuracy. Specifically, using the model weights \(\{w_{ij,t}\}\) at time step \(t\), client \(i\) selects models that perform better on its data while pruning those with lower performance.

Let \(h_{j}(_{i,t})=f(_{i,t};_{j})\) denote the model associated with the \(j\)-th model parameter in \(_{t}\). Furthermore, \(h_{}(_{i,t})=f(_{i,t};_{i,t})\) and \(h_{}(_{i,t})=f(_{i,t};_{t})\) represent the local and federated models, respectively,. Let the set of models \(\) be defined as \(:=\{h_{j}\ |\  j:1 j|_{T}|\}\{h_{ },h_{}\}\). This set \(\) includes all models that can be employed by each client using Fed-POE. The best model in hindsight \(h^{*}\) and the best model in hindsight for client \(i\), \(h^{*}_{i}\) are defined as

\[h^{*}= _{h}_{t=1}^{T}_{i=1}^{N}(h( _{i,t}),y_{i,t}),\] (18a) \[h^{*}_{i}= _{h}_{t=1}^{T}(h(_{i,t}),y_ {i,t}).\] (18b)

The following theorem provides the regret upper bound of Fed-POE.

**Theorem 3**.: _Under assumption A3, employing Fed-POE in Algorithm 2, the expected global regret of all clients is bounded from above as_

\[_{t=1}^{T}_{i=1}^{N}_{t}[ (_{i,t}(_{i,t}),y_{i,t})]-_{t=1}^{T}_{i=1}^{N} (h^{*}(_{i,t}),y_{i,t})\] \[ }+}{2}(+1)T+( 1-}{2n}U)U\] (19)

_while client \(i\) achieves the following expected personalized regret upper bound:_

\[_{t=1}^{T}_{t}[(_{i,t}(_{i, t}),y_{i,t})]-_{t=1}^{T}(h^{*}_{i}(_{i,t}),y_{i,t})\] \[ }+}{2}(+1)T+( 1-}{2n}U)U.\] (20)

_The expectation is taken with respect to randomization in model selection._

The proof of Theorem 3 can be found in Appendix C. According to (19) and (20), setting \(_{c}=(1/)\), \(n=()\) and \(U=()\), both the personalized and global regrets of clients achieve sublinear regret of \(()\). Since clients construct their ensemble models using a time-varying subset of models, employing existing model selection and ensemble learning approaches [13; 15; 39; 46; 20; 41; 21] may not ensure the sublinear regrets stated in Theorem 3. However, by using the proposed Algorithm 1, Fed-POE guarantees sublinear regret bounds while allowing clients the flexibility to select time-varying and personalized subsets of models for their ensembles.

## 5 Experiments

The present section studies the performance of Fed-POE in Algorithm 2 compared to other baselines. Experiments are conducted on both image classification and regression tasks. The performance of federated learning is examined in both convex and non-convex cases. Codes are available at https://github.com/pouyamghari/Fed-POE.

### Regression

The performance of the proposed Fed-POE is evaluated on online regression tasks. For these tasks, clients and the server collaborate to train a random feature kernel-based model, which is known to be convex [25; 48; 18]. Details about the random feature kernel-based model used in the experiments can be found in Appendix D. The performance of Fed-POE is compared with a baseline called Local, where clients train their models locally without participating in federated learning. Additionally, Fed-POE is compared to personalized federated learning baselines Ditto  and Fed-Rep , the online federated learning baseline Fed-OMD , and online federatedkernel learning baselines eM-KOFL  and POF-MKL . Mean square error (MSE) is used as the metric to evaluate the performance of algorithms on regression task. MSE for client \(i\) can be expressed as \(_{i}=_{t=1}^{T}{(_{ij,t}-y_{i,t})^{2}}\) where \(_{ij,t}\) denotes the prediction of client \(i\) at time step \(t\). The performance of algorithms are tested on two regression datasets Air  and WEC . Air dataset is a time-series dataset that each data sample contains air quality features and the goal is to predict the concentration of contamination in the air. Each sample in WEC dataset contains features of different wave energy converters and the goal is to predict power output. Data samples are distributed non-i.i.d among \(400\) clients. Time horizon \(T\) for both datasets is \(250\). More information about datasets and distributed data among clients is presented in Appendix D.

Table 1 presents the MSE of algorithms and their standard deviation across clients. For all algorithms, the learning rates are set to \(=_{c}=1/\). Table 1 shows that when data is distributed non-i.i.d. among clients, local model training can achieve higher accuracy compared to federated learning. For the Air dataset, Local achieves lower MSE than other federated learning baselines except for Fed-POE. For the WEC dataset, only POF-MKL achieves lower MSE than Local. This indicates that the performance of federated learning approaches compared to Local depends on the dataset. By utilizing both federated and local models, Fed-POE achieves the lowest MSE. Table 1 shows that the performance of Fed-POE relative to other baselines is more consistent across different datasets.

### Image Classification

The performance of the proposed Fed-POE on an image classification task is compared with Local, Ditto , Fed-Rep , Fed-OMD , Fed-ALA , and Fed-DS . Fed-ALA  is a personalized federated learning model suitable for deep neural networks, while Fed-DS  is a federated learning algorithm designed to handle data streams. Experiments are conducted on CIFAR-10  and Fashion MNIST (FMNIST)  datasets. CIFAR-10 and FMNIST contain \(60,000\) and \(70,000\) images. For both CIFAR-10 and FMNIST, a CNN with a VGG architecture , consisting of two blocks, is pre-trained on a subset of training samples from each dataset. The training datasets are biased towards class \(0\). More details about training the CNNs can be found in Appendix D. For both the CIFAR-10 and FMNIST datasets, \(10,000\) test samples are sequentially received by clients. There are \(20\) clients in total, and the data samples are distributed non-i.i.d. among them. For CIFAR-10, each client is biased towards one specific class, with \(55\%\) of the samples belonging to that class and \(5\%\) of the samples belonging to each of the other 9 classes. For FMNIST, each client is biased towards two classes, and the distribution of samples is time-variant. More details about the data distribution among clients and experimental setup can be found in Appendix D. At each time step, all algorithms employ batch of size \(10\) for model update. The learning rates for all algorithms are set to \(=0.01/\) and \(_{c}=1/\). The server stores models every \(n=20\) time steps. The metric to evaluate the performance of algorithms is the accuracy. The accuracy for client \(i\) is defined as \(_{i}=_{t=1}^{T}{ 1}_{_{i,t}=y_{i,t}}\) where \(_{i,t}\) denotes the label predicted by client \(i\) at time step \(t\).

Average accuracy and its standard deviation across clients for CIFAR-10 and FMNIST are reported in Table 2. At each time step \(t\), clients can store \(10\) model parameters. Therefore, \(M\) is set to \(M=8\) for Fed-POE. The results indicate that the performance of Local relative to federated learning baselines depends on the dataset. While Local outperforms all federated baselines except for Fed-Rep and Fed-POE on FMNIST, it obtains the worst accuracy on CIFAR-10. Conversely, Fed-POE achieves the highest accuracy for both datasets, indicating

  
**Methods** &  &  \\  Local & \(9.12 3.59\) & \(17.64 0.44\) \\ Ditto & \(10.65 5.69\) & \(33.88 16.08\) \\ Fed-Rep & \(10.48 5.23\) & \(35.13 10.38\) \\ Fed-OMD & \(11.48 6.84\) & \(32.61 27.38\) \\ eM-KOFL & \(11.51 6.71\) & \(72.29 62.48\) \\ POF-MKL & \(10.66 6.07\) & \(16.94 15.92\) \\  Fed-POE & \({ 9.06 3.73}\) & \({ 11.83 4.60}\) \\   

Table 1: Average MSE (\( 10^{-3}\)) and its standard deviation (\( 10^{-3}\)) across clients for online regression on Air and WEC datasets.

  
**Methods** &  &  \\  Local & \(50.35\% 10.11\%\) & \(78.81\% 2.12\%\) \\ Ditto & \(56.87\% 9.06\%\) & \(78.73\% 1.89\%\) \\ Fed-Rep & \(63.86\% 7.97\%\) & \(79.04\% 1.77\%\) \\ Fed-OMD & \(65.09\% 7.39\%\) & \(74.60\% 6.52\%\) \\ Fed-ALA & \(61.48\% 8.88\%\) & \(75.13\% 6.39\%\) \\ Fed-DS & \(64.26\% 7.03\%\) & \(75.62\% 6.58\%\) \\  Fed-POE & \({ 66.54\% 8.07\%}\) & \({ 79.23\% 1.88\%}\) \\   

Table 2: Average accuracy and its standard deviation across clients for image classification.

that Fed-POE efficiently leverages the advantages of both federated and local models. To analyze the effect of the number of models \(M\) and batch size \(b\) on the Fed-POE performance, experiments are conducted on the CIFAR-10 dataset, varying the batch size \(b\) and the number of models \(M\) selected by each client to construct the ensemble model. As observed in Table 3, the batch size \(b=1\) results in the worst accuracy, mainly due to the forgetting process where models overfit to the most recently observed data. However, increasing the batch size from \(b=10\) or \(b=20\) to \(b=30\) does not significantly improve the accuracy. Larger batch sizes may lead the model to perform better on older data, as the model is trained on older data over more iterations. Therefore, this study concludes that a moderate batch size is optimal, considering that increasing the batch size also increases computational complexity. Table 4 in Appendix D presents the accuracy of Fed-POE on both the CIFAR-10 and FMNIST datasets with varying values of \(M\). The table shows that employing the saved models by the server in \(_{t}\) improves performance, as setting \(M=0\) results in the worst accuracy. Moreover, it can be observed that increasing \(M\) does not necessarily lead to further accuracy improvement. This aligns with the intuition behind selecting a subset of models rather than using all models.

## 6 Conclusions

This paper proposed Fed-POE, a personalized federated learning algorithm designed for online prediction and model fine-tuning. Fed-POE constructs an ensemble using local models and federated models stored by the server periodically over time. Theoretical analysis demonstrated that Fed-POE achieves sublinear regret. Experimental results revealed that the relative performance of local models compared to federated models depends on the dataset, making the decision between local model training and federated learning challenging. However, experimental results also show that Fed-POE consistently outperforms both local and federated models across all datasets. This indicates that Fed-POE effectively leverages the advantages of both local and federated models.