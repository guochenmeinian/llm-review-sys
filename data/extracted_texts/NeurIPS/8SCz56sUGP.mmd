# Real-World Image Super-Resolution as Multi-Task Learning

Wenlong Zhang\({}^{1,2}\), Xiaohui Li\({}^{2,3}\), Guangyuan Shi\({}^{1}\), Xiangyu Chen\({}^{2,4,5}\)

Xiaoyun Zhang\({}^{3}\), Yu Qiao\({}^{2,5}\), Xiao-Ming Wu\({}^{1}\), Chao Dong\({}^{2,5}\)\({}^{}\)

\({}^{1}\)The HongKong Polytechnic University \({}^{2}\)Shanghai AI Laboratory

\({}^{3}\)Shanghai Jiao Tong University \({}^{4}\)University of Macau

\({}^{5}\)Shenzhen Institute of Advanced Technology, CAS

wenlong.zhang@connect.polyu.hk, xiao-ming.wu@polyu.edu.hk, chao.dong@siat.ac.cn

Corresponding author

###### Abstract

In this paper, we take a new look at real-world image super-resolution (real-SR) from a multi-task learning perspective. We demonstrate that the conventional formulation of real-SR can be viewed as solving multiple distinct degradation tasks using a single shared model. This poses a challenge known as task competition or task conflict in multi-task learning, where certain tasks dominate the learning process, resulting in poor performance on other tasks. This problem is exacerbated in the case of real-SR, due to the involvement of numerous degradation tasks. To address the issue of task competition in real-SR, we propose a task grouping approach. Our approach efficiently identifies the degradation tasks where a real-SR model falls short and groups these unsatisfactory tasks into multiple task groups. We then utilize the task groups to fine-tune the real-SR model in a simple way, which effectively mitigates task competition and facilitates knowledge transfer. Extensive experiments demonstrate our method achieves significantly enhanced performance across a wide range of degradation scenarios. The source code is available at https://github.com/XPixelGroup/TGSR.

## 1 Introduction

**Real-world image super-resolution** (real-SR) aims to enhance the resolution and quality of low-resolution images captured in real-world scenarios. Real-SR algorithms enable improved image quality and better visual understanding, making them valuable in a wide range of applications . Unlike non-blind SR  and classical blind SR  that assumes a simple degradation process, real-SR deals with complex and unknown degradations present in real-world imaging conditions, such as noise, blur, compression artifacts, and sensor limitations. The diversity of real-world degradations and unknown degradation parameters make it challenging to reverse the specific degradation effects and accurately recover high-resolution details.

**Prior studies** tackle real-SR by designing various degradation models to simulate the degradation process in real-world scenarios. For instance, they generate synthetic paired training data with a shuffled degradation model (BSRGAN ), a high-order degradation model (RealESRGAN ), or a three-level degradation model (DASR ). Existing methods commonly train a single real-SR network with training data generated by a sophisticated degradation model, aiming to cover as many degradation cases as possible during the training process. Under this framework, recent works have focused on enhancing various aspects of the real-SR network, including improving the backbone network architecture , optimizing inference efficiency , enhancing generalization capabilities , and improving modulation ability .

**This study takes a new look at real-SR from a multi-task learning perspective.** We show that the conventional formulation of real-SR essentially corresponds to a multi-task learning problem, which involves solving a large number of different degradation tasks simultaneously with a single shared model. Consequently, real-SR faces a well-known challenge in multi-task learning, namely _task competition or task conflict_. It refers to the situation that tasks compete for model capacity, potentially resulting in certain tasks dominating the learning process and adversely affecting the performance of other tasks. This problem is severely aggravated in the case of real-SR, where a large number of degradation tasks (up to thousands) are typically involved. In our pilot experiment (Fig. 1), we have observed that a real-SR network trained with the multi-task objective fails to yield satisfactory results for a significant portion of degradation tasks.

**We propose a task grouping approach** (Fig. 2) to alleviate the negative impact of task competition for real-SR. Task grouping [48; 37; 35; 10] is an effective technique in multi-task learning that helps mitigate negative transfer by training similar tasks together. This approach typically involves learning the relationship or relevance between pairs of tasks through validation or fine-tuning, which becomes impractical in the context of real-SR where there is a large number of tasks to consider. Hence, we resort to design indirect measures to assess task affinity. Specifically, we introduce a performance indicator based on gradient updates to efficiently identify the degradation tasks that a real-SR model falls short of. Then, we propose an algorithm to group these unsatisfactory tasks into multiple groups based on a performance improvement score. Finally, we propose TGSR, a simple yet effective real-SR method, which leverages the identified task groups to fine-tune the pre-trained real-SR network. Our key contributions are summarized as follows:

* We take a new look at real-SR from a multi-task learning perspective and highlight the task competition problem.
* We propose a task grouping approach to effectively address the task competition problem for real-SR and develop a task grouping based real-SR method (TGSR).
* We conduct extensive experiments to validate the effectiveness of TGSR, and the results demonstrate its superior performance compared to state-of-the-art real-SR methods.

## 2 Related Work

**Image super-resolution.** Since Dong _et al._ first introduced Convolutional Neural Networks (CNNs) to the SR problem, a series of learning-based SR methods have made great progress, including deep networks , dense connections , channel attention of , residual-in-residual dense blocks , and transformer structure . To reconstruct realistic textures, Generative Adversarial Networks (GANs) [24; 41; 53; 42] have been employed to generate visually pleasing results. However, these methods adopt a bicubic down-sampling degradation that is insufficient for real-world images.

**Real-world super-resolution.** To address the SR problem in real-world scenarios, classical blind SR methods primarily use Gaussian blur and noise to model the distribution of real-world images. Significant progress has been made through a variety of approaches, including the use of a single SR network with multiple degradations , kernel estimation [13; 18; 44; 2], and representation learning . Additionally, BSRGAN  proposes a large degradation model that incorporates multiple degradations using a shuffled strategy, while RealESRGAN  employs a high-order strategy to construct a large degradation model. DASR  adopts a three-level degradation distribution (i.e., two one-order and one high-order degradation models) to simulate the distribution of real-world images. These works demonstrate the potential of large degradation models for real-world applications. In addition, recent works also improve real-SR in multiple dimensions, such as network backbone , efficiency , generalization [23; 54; 52] and modulation ability .

**Multi-task learning**. Multi-task learning methods can be roughly divided into three categories: task balancing, task grouping, and architecture design. Task balancing [16; 20; 47; 27; 34; 15; 8; 7; 19] methods address task/gradient conflicts by re-weighting the loss or manipulating the update gradient. Task grouping [48; 37; 35; 10] methods mainly focus on identifying which tasks should be learned together. Zamir et al.  provide a task taxonomy that captures the notion of task transferability. TAG  determines task groups by computing affinity scores that capture the effect between tasks. Architecture design methods can mainly be divided into hard parameter sharing methods [22; 28; 3] and soft parameter sharing methods [30; 33; 12; 11]. Hard parameter sharing methods requiredifferent decoders for different tasks, while soft parameter sharing methods do cross-talk between different task networks. We focus on a task grouping strategy in our TGSR. The strategy identifies unsatisfactory degradation tasks in a large degradation space. Subsequently, we can further improve the overall performance of the real-SR network by fine-tuning it in the unsatisfactory tasks.

## 3 Real-SR as a Multi-task Learning Problem

Problem FormulationReal-SR aims to restore a high-resolution (HR) image \(x\) from its low-resolution (LR) counterpart \(y\) that has undergone an unknown and intricate degradation process:

\[y=(x)=(f_{n} f_{2} f_{1})(x),\] (1)

where \(f_{i}\) represents a degradation function such as Gaussian blurring with a kernel width [0.1, 2.4], adding Gaussian noise with a noise level , a downsampling operation with a scale factor \(r\), or applying the JPEG compression. Hence, \(\) represents a vast continuous degradation space that encompasses an infinite number of degradations. Existing real-SR models such as BSRGAN , RealESRGAN , and DASR  make different assumptions in the generation of \(\), aiming to simulate the highly complex degradation process in real-world scenarios.

An SR task \(\) can be defined as a training pair \((x,y=d(x))\) formed by sampling a degradation \(d\) from the degradation space \(\) and applying it on an HR image \(x\) to generate an LR image \(y\). Due to the infinite size of \(\), it is impossible to consider every degradation case. Hence, a common approach is to sample a large number of degradations to sufficiently represent the degradation space. Given a set of high-resolution images \(\), with \(N\) different degradations sampled from \(\) (\(N||\)), we can generate a set of SR tasks: \(=\{_{i}=(x_{i},y_{i})\}_{i=1}^{N}\), where \(x_{i}\) and \(y_{i}\) is obtained by applying a degradation on \(x_{i}\). A real-SR model is commonly trained by minimizing the empirical risk:

\[_{}()=_{i=1}^{N}_{i}(_{i}; ),\] (2)

where \(_{i}\) is the loss on task \(_{i}\), and \(\) are the trainable model parameters shared by all \(N\) tasks. Therefore, real-SR is essentially a multi-task learning problem, aiming to solve \(N\) different SR tasks with a single shared model. In the following, we refer to \(_{i}\) as a _degradation task_.

Task CompetitionFrom the view of multi-task learning, real-SR is a challenging problem as it intends to solve a large number of different degradation tasks (e.g., \(N=10^{3}\)) altogether with a single model, inevitably suffering from task competition that some tasks may dominate the training process leading to poor performance on other tasks .

To illustrate the impact of task competition, we randomly sample 100 degradation tasks with the degradation model in  and train a real-SR network with the multi-task objective in Eq. 2. Next, we fine-tune the real-SR network on each degradation task independently and obtain 100 fine-tuned

Figure 1: **Illustration of task competition. The jointly-trained multi-task real-SR network falls short in producing satisfactory results for almost half of the degradation tasks, on which the fine-tuned single-task networks obtain more than 0.4dB performance gain, indicating these tasks are dominated by other tasks during the learning process.**

models, which we call single-task networks. We then compare the performance between the real-SR network and the single-task networks on each degradation task by computing their PSNR distance. The results in Fig. 1 show that for nearly half of the degradation tasks, the PSNR distance between the real-SR network and single-task network exceeds 0.4dB, indicating that these tasks are not well solved by the real-SR network, which we refer to as _unsatisfactory tasks_. From an optimization perspective, the other tasks (those with PSNR distance less than 0.4dB) dominate the learning process and are effectively solved by the real-SR network, which we refer to as _satisfactory tasks_.

## 4 Real-SR via Task Grouping

Our analysis in Sec. 3 shows that when a real-SR network is tasked with many degradation tasks, they may compete for model capacity or interfere with each other, resulting in a significant decline in performance for certain tasks. This phenomenon, commonly referred to as _negative transfer_, is a well-known challenge in the field of multi-task learning. An effective approach to mitigate negative transfer is task selection or task grouping [10; 37; 48]. By finding groups of tasks that may benefit from training together, the interference among tasks can be minimized.

### Which Tasks Should Be Learned Together for Real-SR?

The results in Fig. 1 suggest that the satisfactory tasks should be grouped together. These dominant tasks may share certain characteristics or similarities that lead to minimal task conflicts, making them more prominent in the training process. More importantly, considering that the real-SR network has effectively tackled these tasks and reached a satisfactory performance level, we may focus on the unsatisfactory tasks that present greater potential for improvement.

**Efficiently Identifying Unsatisfactory Tasks** To identify the unsatisfactory tasks, we may use the approach described in Sec. 3 and Fig. 1, by comparing the performance between the jointly-trained multi-task real-SR network (referred to as the _pre-trained_ real-SR network hereafter) and the fine-tuned single-task networks. However, the cost of adopting this approach is prohibitive due to the large number of degradation tasks (e.g., thousands or tens of thousands) involved in real-SR.

Therefore, to efficiently identify the unsatisfactory tasks, we propose a measure to assess whether a degradation task has been well solved by the real-SR network, which is done through fine-tuning the pre-trained real-SR network for a small number of iterations (e.g., 100) on the degradation task. Specifically, we assess the impact of the gradient update of task \(_{i}\) on the shared parameters \(\) (i.e., the pre-trained real-SR network), by comparing the loss of \(_{i}\) before and after updating \(\). We develop a _performance indicator_ defined as:

\[z_{i}^{t}=_{i}(_{i},_{i}^{t})}{_{i}( _{i},)},\] (3)

where \(_{i}^{t}\) are the parameters updated on task \(_{i}\) at the time step \(t\). Notice that a high value of \(z_{i}^{t}\) indicates the loss of task \(_{i}\) is not significantly reduced after fine-tuning, suggesting that the pre-trained real-SR network has achieved good performance on this task.

Figure 2: Overview of our proposed task grouping approach for real-SR.

For stability, we consider the average performance indicator during the fine-tuning process on task \(_{i}\):

\[_{i}=-t_{s}}_{t=t_{s}}^{t_{e}}z_{i}^{t},\] (4)

where \(t_{s}\) and \(t_{e}\) represent the starting and end points of a time span, respectively. With the computed average performance indicator of each task, we can set a threshold to select the unsatisfactory tasks. The effectiveness of \(_{i}\) is validated in Sec. 5.2 and Sec. 5.3.

Grouping Unsatisfactory Tasks into Multiple Task GroupsThe number of identified unsatisfactory degradation tasks can still be significant, typically in the range of hundreds in our experiments. Given the potential variance among these tasks, it would be advantageous to further divide them into multiple task groups based on their similarity to reduce negative transfer. A common approach for task grouping in multi-task learning is to learn pairwise performance indicator between tasks [48; 10; 37], which is impractical for real-SR due to the large number of degradation tasks involved.

A feasible way is to learn an indirect measure of task similarity by fine-tuning the pre-trained real-SR network on each degradation task independently and computing the PSNR distance as described in Sec. 3 and Fig. 1. However, this approach is still time-consuming given the large number of unsatisfactory tasks. Another alternative of indirect measure is the average performance indicator in Eq. 4, which, although efficient, may not be accurate enough. Hence, we make a trade-off to fine-tune the pre-trained real-SR network \(\) on all unsatisfactory tasks simultaneously through joint-training to obtain a new network \(\). Then, we test the fine-tuned network \(\) on each degradation task with an available validation set and compute a _performance improvement score (PIS)_ defined as:

\[s_{j}=I(_{j}^{};)-I(_{j}^{};),\] (5)

where \(_{i}^{}\) represents the validation set of an unsatisfactory task \(_{i}\), \(I\) is an IQA (image quality assessment) metric such as PSNR, and \(s_{i}\) is the PIS of task \(_{i}\). We then select the tasks with PIS larger than some threshold to form a task group, which should have small conflicts as they dominate the fine-tuning process. We repeat this process to find the rest of task groups as described in Alg. 1.

``` Input: A set of degradation tasks \(=\{_{1},_{2},...,_{n}\}\), the pre-trained real-SR model \(\), the number of groups \(c\), and the threshold values \(t_{0}\), \(t_{1},,t_{c}\). for any\(_{i}\)do  Compute the average performance indicator \(_{i}\) with Eq. 4;  end for // Select unsatisfactory tasks  Let \(}=\{_{i}|_{i}>t_{0}\}\) ; // Group unsatisfactory tasks for\(i=1,,c\)do  Fine-tune the pre-trained real-SR network with all unsatisfactory tasks; for any\(_{j}}\)do  Compute the performance improvement score \(s_{j}\) with Eq. 5;  end for  Let \(G_{i}=\{_{j}|s_{j}>t_{i}\}\), where \(t_{i}\) is the threshold for group \(i\);  Let \(}=} G_{i}\);  end for Output: Degradation task groups \(=\{G_{1},G_{2},..,G_{c}\}\). ```

**Algorithm 1**Degradation Task Grouping for Real-SR

### TGSR: A Task Grouping Based Real-SR Method

With the identified degradation task groups \(=\{G_{1},G_{2},..,G_{c}\}\), we adopt a straightforward method to fine-tune the pre-trained real-SR network, referred to as TGSR. We first form \(}=\{G_{0},\}=\{G_{0},G_{1},G_{2},..,G_{c}\}\), where \(G_{0}\) represents the entire degradation space and serves for preventingcatastrophic forgetting during the fine-tuning process. Then, we randomly select a group from \(}\) and randomly sample a task from the chosen group for fine-tuning. This approach effectively increases the inclusion of the unsatisfactory tasks during the fine-tuning process and weights their likelihood of being chosen based on their respective group size (i.e., tasks in smaller groups have a higher probability to be selected). In essence, it is similar to the task re-weighting approach commonly used in multi-task learning.

## 5 Experiments

### Experimental Setup

**Datasets and evaluation.** We employ DIV2K , Flickr2K  and OutdoorSceneTraining  datasets to implement our task grouping algorithm and train the TGSR network. For evaluation, we use DIV2K validation set to construct a DIV2K5G dataset consisting of 5 validation sets according to the divided 5 different degradation groups by the task grouping algorithm, as shown in Fig. 3. Each validation set contains 100 image pairs. In addition to the task group based test set, we employ the synthetic test set AIM2019  and DIV2K_random for evaluation. The DIV2K_random is generated using the RealESRGAN degradation model on the DIV2K validation set. Furthermore, we incorporate the real-world test set, RealSR set , into our evaluation process. All evaluations are conducted on \( 4\) SR and PSNR is computed on the Y channel of YCbCr color space.

**Implementation details.** We adopt the high-order degradation model proposed by RealESRGAN  as the real-SR degradation model in our experiments. To compute the performance indicator, \(N\) (\(4 10^{3}\)) degradation tasks are sampled from the whole degradation space. The single-task network is fine-tuned from the pre-trained RealESRNet model for 100 iterations. The performance indicator is computed based on the average of the last 10 iterations considering the instability of the training procedure. To implement the degradation grouping, the degradation tasks with the top 40% higher performance indicators (\(1.6 10^{3}\) degradation tasks) are selected as unsatisfactory tasks. Then, we fine-tune the pre-trained RealESRNet for \(1 10^{4}\) iterations based on all unsatisfactory tasks. After that, we evaluate the model on Set14  for each unsatisfactory degradation task. By using the proposed performance improvement score, we divide the degradation tasks into five groups based on the thresholds of [0.8, 0.6, 0.4, 0.2]. According to this set of thresholds, we obtain four groups with the number of tasks in each group being [14; 29; 84; 200] as groups1-4. Then, we label the entire degradation space beyond the four degradation groups as Group0. To avoid forgetting the satisfactory tasks, we uniformly sample degradation tasks from each group to fine-tune the pre-trained real-SR network. Other basic training settings follow RealESRGAN.

### Comparison with State-of-the-Art

We compare our TGSR with the state-of-the-art methods, including SRGAN , ESRGAN , RDSR , MM-RealSR  BSRGAN , SwinIR , RealESRGAN , DASR  and HAT [6; 5]. Officially released pre-trained models are used for the compared methods.

**Our TGSR improves the overall performance.** The quantitative results of different methods are presented in Tab. 1. ESRGAN is based on a single-degradation model (i.e., Bicubic setting), so it performs worst under the multi-degradation evaluation system. RDSR is an MSE-based method, so it achieves the highest PSNR but performs rather poorly (the second worst) performance on LPIPS. BSRGAN, RealSwinIR, and DASR employ a one-order degradation model. They sacrifice performance on PSNR for better perceptual quality (reflected in low LPIPS). MM-RealSR and

Figure 3: Sample images from different degradation task groups in our DIV2K5G datasets.

RealESRGAN utilize a more complex high-order degradation. As a result, they achieve better LPIPS for real-SR evaluation. However, the two approaches obtain low PSNR performance due to the great difficulty of optimizing. Notably, we can enhance the performance of the pre-trained real-SR network by fine-tuning it on the identified Task Groups (TG). This improvement is particularly significant in Groups 1-4. For instance, on RealESRGAN-TG, we can observe a maximum boost of 1 dB in PSNR and 0.03 in LPIPS.

**Our TGSR demonstrates significant superiority when applied to a large degradation space.** It is noticeable that RealESRGAN-TG outperforms RealESRGAN even in Group0. This indicates that our approach enhances real-SR performance across nearly the entire degradation space, not just the specifically addressed Groups 1-4. In addition to the identified task groups, our TGSR can also achieve performance gains on the randomized synthetic test sets DIV2K_random and AIM2019 test set as shown in Tab. 2. Additionally, our method achieves a gain on the real scene test set RealSRset. These results clearly demonstrate that our approach does not compromise the performance of certain degradation tasks to enhance the performance of others.

    &  &  &  &  &  \\  & PSNR & LPIPS & PSNR & LPIPS & PSNR & LPIPS & PSNR & LPIPS & PSNR & LPIPS \\  ESRGAN & 21.49 & 0.6166 & 20.29 & 0.6697 & 20.95 & 0.6530 & 22.42 & 0.5940 & 22.02 & 0.5837 \\ RDSR & 25.00 & 0.5196 & 21.18 & 0.6167 & 23.06 & 0.5586 & 25.00 & 0.4993 & 25.58 & 0.4814 \\ MM-RealSR & 23.49 & 0.4549 & 19.74 & 0.5326 & 21.76 & 0.4731 & 23.37 & 0.4205 & 23.97 & 0.3989 \\ DASR & 23.87 & 0.4683 & 19.97 & 0.5752 & 22.31 & 0.5093 & 24.00 & 0.4474 & 24.85 & 0.4225 \\ BSRGAN & 23.99 & 0.4549 & 20.07 & 0.5799 & 22.45 & 0.4961 & 24.34 & 0.4388 & 24.80 & 0.4210 \\  RealSRGAN & 23.88 & **0.4599** & 20.10 & 0.5586 & 22.12 & 0.5019 & 23.85 & 0.4499 & 24.48 & 0.4270 \\ RealSRGAN-TG & **23.95** & 0.4617 & **21.14** & **0.5323** & **23.06** & **0.4802** & **24.69** & **0.4248** & **25.05** & **0.4112** \\  RealESRGAN & 23.85 & 0.4325 & 20.10 & 0.5355 & 22.07 & 0.4701 & 24.30 & 0.4147 & 24.58 & 0.3970 \\ RealESRGAN-TG & **23.99** & **0.4286** & **21.10** & **0.5056** & **23.15** & **0.4494** & **24.62** & **0.3975** & **25.03** & **0.3851** \\  RealSwinIR & 23.35 & 0.4468 & 19.60 & 0.5624 & 21.65 & 0.4905 & 23.66 & 0.4265 & 24.16 & 0.4077 \\ RealSwinIR-TG & **23.90** & **0.4168** & **20.62** & **0.4925** & **22.70** & **0.4377** & **24.56** & **0.3815** & **24.98** & **0.3670** \\  RealHAT & 24.26 & 0.4084 & 20.64 & 0.5022 & 22.44 & 0.4468 & 24.42 & 0.3918 & 25.02 & 0.3734 \\ RealHAT-TG & **24.31** & **0.4110** & **21.41** & **0.4932** & **23.20** & **0.4395** & **24.87** & **0.3841** & **25.32** & **0.3674** \\   

Table 1: Quantitative results of different methods on DIV2K5G. Group0 denotes the validation set with satisfactory degradation tasks, and Group1-4 represent the validation sets with unsatisfactory degradation tasks. The ESRGAN trained on the non-blind setting and RDSR trained on the MSE-based setting are marked in gray.

Figure 4: Qualitative results of different methods. Zoom in for details.

**Our TGSR obtains better visual results than other methods.** The visual results of different methods are shown in Fig. 4 and Fig. 5. TGSR significantly improves existing methods by removing various degradation artifacts and noticeable unpleasant artifacts. For the first four rows of images with complex degradation, the other methods cannot remove the degradation or generate unacceptable artifacts. In contrast, our TGSR handles the degradation well and produces visually pleasant results. For the image on the last row, our method can generate more realistic results than other methods with clear textures. In the RealSwinIR results of Fig. 5, we can observe the unpleasant artifacts in the flat area of _Flower_ image and the fur of _cat_ image. In the RealHAT results, we also find semantic textures appearing where they shouldn't be. For example, a _tree_ texture appears on the _train_, and fur-like textures are present in the background of the _Wolf_ image. However, our method can remove these artifacts by fine-tuning the real-SR network on identified task groups.

### Ablation and Analysis

**Effectiveness of the performance indicator. 1)** In Fig. 6 (a) and (b), we present the PSNR improvement achieved by fine-tuning the real-SR network on individual tasks with lower and higher performance indicators. It can be observed that tasks with higher performance indicators exhibit a significant PSNR improvement (about 0.4-1.4dB), while tasks with lower performance indicators

    & DIV2K\_random &  &  &  \\  & PSNR & LPIPS & PSNR & LPIPS & PSNR & LPIPS & PSNR & LPIPS \\  ESRGAN & 20.63 & 0.6345 & 23.16 & 0.5500 & 27.40 & 0.4132 & 27.73 & 0.4054 \\ RDSR & 24.61 & 0.5268 & 24.44 & 0.4803 & 26.39 & 0.4053 & 26.93 & 0.3795 \\ MM-RealSR & 23.17 & 0.4394 & 23.48 & 0.3917 & 23.78 & 0.3841 & 24.42 & 0.3664 \\ DASR & 23.52 & 0.4832 & 23.76 & 0.4210 & 26.68 & 0.3972 & 27.68 & 0.3792 \\ BSRGAN & 23.76 & 0.4622 & 24.20 & 0.4000 & 26.11 & 0.3900 & 26.90 & 0.3648 \\ SwinIR & 23.13 & 0.4432 & 23.89 & 0.3870 & 26.20 & 0.3616 & 26.68 & 0.3469 \\ RealSERGAN & 23.54 & 0.4423 & 23.89 & 0.3960 & 25.62 & 0.3820 & 26.06 & 0.3629 \\  RealSRGAN & 23.58 & 0.4710 & 23.72 & 0.4247 & 24.71 & 0.4159 & 25.42 & 0.3902 \\ RealSRGAN-TG & **23.79** & **0.4705** & **23.97** & **0.4174** & **25.18** & **0.4018** & **25.93** & **0.3759** \\  RealESRGAN & 23.54 & 0.4423 & 23.89 & 0.3960 & 25.62 & 0.3820 & 26.06 & **0.3629** \\ RealESRGAN-TG & **23.84** & **0.4368** & **24.27** & **0.3899** & **26.01** & **0.3819** & **26.33** & 0.3637 \\  RealSwinIR & 23.67 & 0.4216 & 23.98 & 0.3804 & 25.70 & **0.3700** & 26.43 & **0.3506** \\ RealSwinIR-TG & **23.74** & **0.4190** & **24.10** & **0.3766** & **26.36** & 0.3751 & **27.18** & 0.3585 \\  RealHAT & 24.04 & **0.4156** & 24.19 & 0.3742 & 25.88 & **0.3532** & 26.56 & **0.3339** \\ RealHAT-TG & **24.21** & 0.4189 & **24.41** & **0.3723** & **26.12** & 0.3635 & **26.69** & 0.3451 \\   

Table 2: Quantitative results of different methods on the real-world test set. The ESRGAN trained on the non-blind setting and RDSR trained on the MSE-based setting are marked in gray.

Figure 5: RealSwinIR and RealHAT may unreasonably generate unpleasant artifacts or semantic textures that shouldn’t be there. However, our method does not have this problem.

show only a small PSNR improvement (about 0.2 dB). This finding indicates that our proposed performance indicator can effectively distinguish between satisfactory and unsatisfactory tasks for a real-SR model in a large degradation space. Additionally, Fig. 6 (c) illustrates that significant visual improvements can be achieved with the unsatisfactory degradation task. **2)** Directly fine-tuning a model for each task incurs a high computational cost (empirically requiring at least 10,000 iterations). However, our performance indicator requires only 100 iterations of fine-tuning. It suggests that utilizing the performance indicator can be 100 times faster than direct fine-tuning for distinguishing the unsatisfactory and satisfactory degradation tasks. This further illustrates the superiority of the proposed performance indicator.

**Effectiveness of our task grouping algorithm.** We compare the performance of RealESRGAN-TG with our task grouping and random grouping to demonstrate the effectiveness of our method. As shown in Fig. 7 (a) and (b), random grouping can only bring very limited performance gains of about 0.2dB on PSNR and about 0.01 on LPIPS. In contrast, the groups generated by our task grouping algorithm show a significant improvement up to 1dB on PSNR and 0.03 on LPIPS. These results demonstrate the significance of a well-designed task grouping approach. Furthermore, Fig. 7 (c) shows that random grouping can not select the unsatisfactory task, while our task grouping algorithm can find it.

**Study of the performance upper bound. (1)** We randomly select 100 single tasks and then add the corresponding small range of similar degradation parameters to each task, named single-task network with range (see details in appendix). Fig. 8 shows that the existence of related tasks can improve the upper bound of some tasks (about 40%). However, there has been a performance drop for other tasks due to similar degradation parameters that may not strictly represent similar tasks. **(2)** To further show the superiority of our TGSR, we fine-tune the RealESRGAN model on each group to obtain

Figure 6: Performance comparison of real-SR networks that trained on the degradation tasks with (a) lower performance indicators and (b) higher performance indicators. The degradation tasks with a lower performance indicator can be further improved in quantitative and qualitative results.

Figure 7: Performance comparison of RealESRGAN and our TGSR/ TGSR with random grouping on (a) PSNR and (b) LPIPS. The results indicate random grouping achieves limited improvement compared with our proposed task grouping. (c) Visual results demonstrate that random grouping chooses a satisfactory degradation task that is not required for further training, while our task grouping method finds an unsatisfactory degradation task that needs to be further improved.

their empirical performance upper bound for these degradation groups, and the results are denoted as RealESRGAN-SG. As presented in Tab. 3, the fine-tuned models exceed the baseline models and obtain significant performance improvement on LPIPS. Although RealESRGAN-TG cannot surpass the empirical upper bound performance on LPIPS, it still achieves comparable performance. Moreover, our RealESRGAN-TG obtains higher PSNR compared to RealESRGAN-SG. This further shows the superiority of our method and suggests that multi-task learning enhances the performance of the specific task.

**Impact of the number of task groups.** In Tab. 4, we group the unsatisfactory tasks into more compact new groups using new thresholds of [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2], with the corresponding number of degradation tasks being [14; 15; 14; 31; 53; 116; 258]. The results demonstrate that our TGSR method exhibits steady improvement on the unsatisfactory tasks in Groups 1-7, while achieving comparable performance on the satisfactory tasks in Group 0. This indicates that our approach can be applied with a more fine-grained division of unsatisfactory tasks based on user requirements.

## 6 Conclusion

We have re-examined the real-SR problem through the lens of multi-task learning and introduced a novel approach, TGSR, to address task competition in real-SR. TGSR aims to identify and enhance the degradation tasks where a real-SR model underperforms. It involves a task grouping method and a simple fine-tuning approach using the identified task groups. Comprehensive evaluation confirms the effectiveness of our approach in producing high-quality super-resolution results in real-world scenarios. One potential limitation of our method is the need for adequate sampling from the degradation space.

    & Metrics & ESRGAN & RDSR & BSRGAN & Real-SwinIR & DASR & MM-RealSR & RealESRGAN & RealESRGAN \\  & & & & & & & & -TG (ours) \\   & PSNR (\(\)) & 21.39 & 25.12 & 24.19 & 23.61 & 23.97 & 23.61 & 24.08 & **24.10** \\  & LPIPS (\(\)) & 0.6251 & 0.5181 & 0.4567 & 0.4430 & 0.4697 & 0.4335 & 0.4297 & **0.4262** \\   & PSNR (\(\)) & 19.81 & 20.99 & 19.96 & 19.52 & 19.77 & 19.52 & 19.92 & **20.97** \\  & LPIPS (\(\)) & 0.6812 & 0.6325 & 0.6151 & 0.5954 & 0.6012 & 0.5572 & 0.5584 & **0.5249** \\   & PSNR (\(\)) & 21.10 & 22.55 & 21.91 & 21.16 & 21.77 & 21.39 & 21.67 & **22.72** \\  & LPIPS (\(\)) & 0.6636 & 0.5755 & 0.5091 & 0.4988 & 0.5175 & 0.4814 & 0.4823 & **0.4652** \\   & PSNR (\(\)) & 21.02 & 23.82 & 23.24 & 22.66 & 23.06 & 22.54 & 22.94 & **23.93** \\  & LPIPS (\(\)) & 0.6301 & 0.5225 & 0.4657 & 0.4528 & 0.4795 & 0.4445 & 0.4390 & **0.4188** \\   & PSNR (\(\)) & 22.10 & 24.64 & 23.96 & 23.37 & 24.05 & 23.20 & 23.63 & **24.41** \\  & LPIPS (\(\)) & 0.6221 & 0.5171 & 0.4617 & 0.4429 & 0.4596 & 0.4335 & 0.4294 & **0.4097** \\   & PSNR (\(\)) & 22.78 & 25.30 & 24.64 & 23.99 & 24.49 & 23.61 & 24.36 & **25.14** \\  & LPIPS (\(\)) & 0.5705 & 0.4873 & 0.4248 & 0.4113 & 0.4245 & 0.4072 & 0.4043 & **0.3821** \\   & PSNR (\(\)) & 22.42 & 25.32 & 24.58 & 23.87 & 24.52 & 23.71 & 24.38 & **24.86** \\  & LPIPS (\(\)) & 0.5849 & 0.4917 & 0.4255 & 0.4153 & 0.4269 & 0.4060 & 0.4039 & **0.3889** \\   & PSNR (\(\)) & 22.49 & 25.37 & 24.50 & 23.85 & 24.43 & 23.74 & 24.37 & **24.76** \\  & LPIPS (\(\)) & 0.5868 & 0.4958 & 0.4337 & 0.4227 & 0.4398 & 0.4110 & 0.4083 & **0.3976** \\   

Table 4: Quantitative results of different methods on DIV2K8G. Group0 denotes the validation set with satisfactory degradation tasks, and Group1-7 represents the validation sets with unsatisfactory degradation tasks. The ESRGAN trained on the non-blind setting and RDSR trained on the MSE-based setting are marked in gray.

Figure 8: Performance comparison of SR network with a single task and a _range_ of tasks.