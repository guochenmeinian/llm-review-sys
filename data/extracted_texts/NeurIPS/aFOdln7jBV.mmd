# An Accelerated Gradient Method for Convex Smooth Simple Bilevel Optimization

Jincheng Cao

ECE Department

UT Austin

jinchengcao@utexas.edu

&Ruichen Jiang

ECE Department

UT Austin

rjiang@utexas.edu

&Erfan Yazdandoost Hamedani

SIE Department

The University of Arizona

erfany@arizona.edu

&Aryan Mokhtari

ECE Department

UT Austin

mokhtari@austin.utexas.edu

###### Abstract

In this paper, we focus on simple bilevel optimization problems, where we minimize a convex smooth objective function over the optimal solution set of another convex smooth constrained optimization problem. We present a novel bilevel optimization method that locally approximates the solution set of the lower-level problem using a cutting plane approach and employs an accelerated gradient-based update to reduce the upper-level objective function over the approximated solution set. We measure the performance of our method in terms of suboptimality and infeasibility errors and provide non-asymptotic convergence guarantees for both error criteria. Specifically, when the feasible set is compact, we show that our method requires at most \((\{1/},1/_{g}\})\) iterations to find a solution that is \(_{f}\)-suboptimal and \(_{g}\)-infeasible. Moreover, under the additional assumption that the lower-level objective satisfies the \(r\)-th Holderian error bound, we show that our method achieves an iteration complexity of \(}(\{_{f}^{-},_{g}^{- }\})\), which matches the optimal complexity of single-level convex constrained optimization when \(r=1\).

## 1 Introduction

In this paper, we investigate a class of bilevel optimization problems known as simple bilevel optimization, aiming to minimize an upper-level objective function over the solution set of a corresponding lower-level problem. This class has recently gained attention due to its broad applications in continual learning , hyper-parameter optimization , meta-learning , and over-parameterized machine learning . Specifically, we focus on the following bilevel optimization problem:

\[_{^{n}}\ f()*{argmin}_{}\ g(), \]

where, \(\) is a convex set, and \(f,g:^{n}\) are convex, continuously differentiable functions on an open set containing \(\). We assume that the lower-level objective function \(g\) is convex but not strongly convex, so the lower-level problem may have multiple optimal solutions. Throughout the paper, we use \(^{*}\) to denote an optimal solution of problem (1). We define \(f^{*} f(^{*})\) and \(g^{*} g(^{*})\), representing the optimal value of problem (1) and the optimal value of the lower-levelobjective \(g\), respectively. This class of problems is referred to as the "simple bilevel problem"  to distinguish it from more general settings with parameterized lower-level problems.

The main challenge in solving problem (1) is that the feasible set, i.e., the optimal solution set of the lower-level problem, lacks a simple characterization and is not explicitly provided. This makes direct application of projection-based or projection-free methods infeasible, as projecting onto or solving a linear minimization problem over such an implicitly defined feasible set is intractable. Instead, our approach constructs an approximation set with specific properties, serving as a surrogate for the true feasible set. In Section 3, we detail how this set is constructed. Using this technique and building on the projected accelerated gradient method, we establish the best-known complexity bounds for solving problem (1).

To provide context, the best-known complexity bound for achieving an \(\)-accurate solution in single-level convex constrained optimization is \((^{-0.5})\), as demonstrated in . This optimal bound was achieved using the accelerated proximal method or FISTA (Fast Iterative Shrinkage-Thresholding Algorithm), which also influenced the development of our algorithm. While the literature on bilevel optimization is not as extensive as that for single-level optimization, there have been recent non-asymptotic results for solving this class of problems, which we summarize in Table 1.

Specifically, these results aim to establish convergence rates on the _infeasibility gap_\(g(_{k})-g^{*}\) and the _suboptimality gap_\(f(_{k})-f^{*}\) after \(k\) iterations. In , an iterative regularization-based method demonstrated a convergence rate of \((1/k^{0.5-b})\) in terms of suboptimality and a rate of \((1/k^{b})\) in terms of infeasibility, where \(b(0,0.5)\) is a user-defined parameter. Setting \(b=0.25\) to balance these rates requires an iteration complexity of \((\{1/_{f}^{4},1/_{g}^{4})\}\) to find a solution that is \(_{f}\)-optimal and \(_{g}\)-infeasible. Later, the Bi-Sub-Gradient (Bi-SG) algorithm was proposed in  to address convex simple bilevel optimization problems with nonsmooth upper-level objective functions. It showed convergence rates of \((1/k^{1-})\) and \((1/k^{})\) in terms of suboptimality and infeasibility, respectively, where \((0.5,1)\) serves as a hyper-parameter. Balancing the rates by setting \(=0.5\) results in an iteration complexity of \((\{1/_{f}^{2},1/_{g}^{2}\})\). Additionally, a structure-exploiting method introduced in  achieved an iteration complexity of \((\{1/_{f}^{2},1/_{g}^{2}\})\) when the upper-level objective is convex and the lower-level objective is convex and smooth. Imposing additional assumptions on the upper-level function, such as smoothness or strong convexity, does not result in faster rates for this method.

Recently,  presented a projection-free conditional gradient method (CG-BiO) that uses a cutting plane to approximate the solution set of the lower-level problem. Assuming both upper- and lower-level objective functions are convex and smooth, CG-BiO achieves a complexity of \((\{1/_{f},1/_{g}\})\). Since the suboptimality gap \(f(})-f^{*}\) may be negative for an infeasible point \(}\), a more desirable metric is the _absolute suboptimality gap_\(|f(})-f^{*}|\). To ensure this,  introduced the Holderian error bound condition on \(g\). Specifically, under the \(r\)-th order Holderian error bound condition, CG-BiO finds a solution \(}\) with \(|f(})-f^{*}|_{f}\) and \(g(})-g^{*}_{g}\)

    & Upper level & Lower level & Convergence \\   & Objective \(f\) & Objective \(g\) & Feasible set \(\) & Upper level & Lower level \\  a-IRG  & Convex, Lipschitz & Convex, Lipschitz & Closed & \((1/_{f}^{4})\) & \((1/_{g}^{4})\) \\  Bi-SG  & Convex, Nonsmooth & Convex, Composite & Closed & \((1/_{f}^{})\) & \((1/_{g}^{}),(0.5,1)\) \\  SEA  & Convex & Convex, Smooth & Compact & \((1/_{f}^{2})\) & \((1/_{g}^{2})\) \\  CG-BiO  & Convex, Smooth & Convex, Smooth & Compact & \((1/_{f})\) & \((1/_{g})\) \\  R-APM  & Convex, Smooth & Convex, Composite & Closed & \((1/_{f})\) & \((1/_{g})\) \\ 
**AGM-BiO (Ours)** & Convex, Smooth & Convex, Smooth & Compact & \((1/_{f}^{0.5})\) & \((1/_{g})\) \\  R-APM  & Convex, Smooth & Convex, Composite & Closed & \((1/_{f}^{0.5})\) & \((1/_{g}^{0.5})\) \\  Bisec-BiO \(}\) & Convex, Composite & Convex, Composite & Closed & \((\{1/_{f}^{0.5},1/_{g}^{0.5}\})\) \\ 
**AGM-BiO (Ours)** & Convex, Smooth & Convex, Smooth & Closed & \((1/_{f}^{0.5})\) & \((1/_{g}^{0.5})\) \\  PB-APG \(}\) & Convex, Composite & Convex, Composite & Compact & \((1/_{f}^{0.5})+(1/_{g}^{0.5})\) \\ 
**AGM-BiO (Ours)** & Convex, Smooth & Convex, Smooth & Closed & \((1/_{f}^{})\) & \((1/_{g}^{})\) \\   

Table 1: Non-asymptotic results on simple bilevel optimization. (\(\): with a first-order Hölderian error bound assumption on \(g\); \(\): with an \(r\)th-order (\(r 1\)) Hölderian error bound assumption on \(g\); \(\): additional assumption implying that the projection onto the sublevel set of \(f\) is easy to compute.)after \((\{1/_{f}^{},1/_{g}\})\) iterations. More recently,  introduced the regularized proximal accelerated method (R-APM), which runs the proximal accelerated gradient method on a weighted sum of the upper- and lower-level objective functions. Assuming both functions are convex and smooth, they established a complexity bound of \((\{1/_{f},1/_{g}\})\) to find an \((_{f},_{g})\) solution. This bound is worse than the \((\{1/},1/_{g}\})\) complexity achieved by our proposed AGM-BiO method, assuming the feasible set \(\) is compact. Additionally,  showed that when the lower-level objective function \(g\) satisfies the weak sharpness property (equivalent to the Holderian error bound condition with \(r=1\)), R-APM finds an \((_{f},_{g})\)-absolute optimal solution after at most \((\{1/},1/}\})\) iterations. This result is comparable to our convergence result for AGM-BiO, which considers a more general Holderian error bound condition.

**Contributions.** In this paper, we present a novel accelerated gradient-based bilevel optimization method, AGM-BiO, which offers state-of-the-art non-asymptotic guarantees for both suboptimality and infeasibility. At each iteration, AGM-BiO uses a cutting plane to linearly approximate the solution set of the lower-level problem, followed by a variant of the projected accelerated gradient update on the upper-level objective function. Below, we summarize our theoretical guarantees:

* When the feasible set \(\) is compact, we show that AGM-BiO finds \(}\) that satisfies \(f(})-f^{*}_{f}\) and \(g(})-g^{*}_{g}\) within \((\{1/},1/_{g}\})\) iterations, where \(f^{*}\) is the optimal value of problem (1) and \(g^{*}\) is the optimal value of the lower-level problem.
* With an additional \(r\)-th-order (\(r 1\)) Holderian error bound assumption on the lower-level problem, AGM-BiO finds \(}\) satisfying \(f(})-f^{*}_{f}\) and \(g(})-g^{*}_{g}\) within \(}(\{_{f}^{-},_{g}^{- {2r-1}{2r}}\})\) iterations. Moreover, it achieves the stronger guarantee that \(|f(})-f^{*}|_{f}\) and \(g(})-g^{*}_{g}\) within \(}(\{_{f}^{-},_{g}^{- {2r-1}{2r}}\})\) iterations.

These bounds all achieve the best-known complexity bounds in terms of both suboptimality and infeasibility guarantees for the considered settings. All the non-asymptotic results are summarized and compared in Table 1.

**Discussions on two concurrent works**. The authors in  proposed a bisection algorithm with a total operation complexity of \(}(\{_{f}^{-0.5},_{g}^{-0.5}\})\) to find an \((_{f},_{g})\)-optimal solution, assuming the upper-level objective \(f\) meets specific criteria. Specifically, Assumption 1(iv) in  implies the ability to compute the projection onto the sublevel set of the upper-level function \(f\). However, this assumption may not hold for general functions, such as the mean squared loss function in our over-parameterized regression example in Section 5. In , the authors introduced the penalty-based accelerated proximal gradient method (PB-APG) for solving simple bilevel optimization problems with the \(r\)-th order Holderian error bound assumption on the lower-level objective \(g\). Their algorithm, similar to , runs the accelerated proximal gradient method on a weighted sum of the upper and lower-level objective functions. PB-APG achieves a complexity of \((_{f}^{-0.5r})+(_{g}^{-0.5})\) to find an \((_{f},_{g})\)-optimal solution. The term \((1/_{f}^{0.5r})\) can become significantly large as the order of the Holderian error bound \(r\) increases. In contrast, our algorithm, AGM-BiO, avoids this issue, requiring at most \(}(\{_{f}^{-},_{g}^{- {2r-1}{2r}}\})\) iterations to achieve an \((_{f},_{g})\)-optimal solution. Therefore, regardless of how large \(r\) is, the worst-case complexity for AGM-BiO is \(}(\{_{f}^{-1},_{g}^{-1}\})\). Thus, our method achieves a better rate than PB-APG when \(r>1\).

## 2 Preliminaries

In this section, we state the assumptions and introduce the notions of optimality used in the paper.

### Assumptions and Definitions

We focus on the case where both the upper and lower-level functions \(f\) and \(g\) are convex and smooth. Formally, we make the following assumptions.

**Assumption 2.1**.: _Let \(\|\|\) be an arbitrary norm on \(^{n}\) and \(\|\|_{*}\) be its dual norm. We assume these conditions hold:_

1. \(^{n}\) _is convex and compact with diameter_ \(D\)_, i.e.,_ \(\|-\| D\) _for all_ \(,\)_
* \(g\) _is convex and continuously differentiable on an open set containing_ \(\)_, and its gradient is_ \(L_{g}\)_-Lipschitz, i.e.,_ \(\| g()- g()\|_{*} L_{g}\|-\|\) _for all_ \(,\)_._
* \(f\) _is convex and continuously differentiable and its gradient is Lipschitz with constant_ \(L_{f}\)_._

In this paper, we denote the optimal value and the optimal solution set of the lower-level problem as \(g^{*}_{}g()\) and \(^{*}_{g}*{argmin}_{ }g()\), respectively. By Assumption 2.1, the set \(^{*}_{g}\) is nonempty, compact, and convex, but in general, not a singleton since \(g\) could have multiple optimal solutions on \(\), as \(g\) is only convex but not strongly convex. Moreover, we use \(f^{*}\) to denote the optimal value and \(^{*}\) to denote an optimal solution of problem (1).

In the simple bilevel problem, the suboptimality of a solution \(}\) is measured by \(f(})-f^{*}\). Similarly, its infeasibility is indicated by \(g(})-g^{*}\). To ensure minimal suboptimality and infeasibility, we formally define an \((_{f},_{g})\)-optimal solution as follows.

**Definition 2.1**.: \(((_{f},_{g})\)_-optimal solution). A point \(}\) is \((_{f},_{g})\)-optimal for problem (1) if \(f(})-f^{*}_{f}\) and \(g(})-g^{*}_{g}\)._

This definition is commonly used in bilevel optimization literature [6; 7; 8; 13]. Due to the unique structure of bilevel optimization, it is not guaranteed that \(f(})-f^{*}\) will always be positive. To address this, we propose using \(|f(})-f^{*}|\) as the absolute optimal criterion.

**Definition 2.2**.: \(((_{f},_{g})\)_-absolute optimal solution). A point \(}\) is \((_{f},_{g})\)-absolute optimal for problem (1) if \(|f(})-f^{*}|_{f}\) and \(|g(})-g^{*}|_{g}\)._

## 3 Algorithm

Before presenting our method, we first introduce a conceptual accelerated gradient method for solving the simple bilevel problem in (1). The first step is to recast it as a constrained optimization problem:

\[_{^{n}}\ f()^{*}_{g}, \]

where \(^{*}_{g}*{argmin}_{ }\ g()\) is the solution set of the lower-level objective. Conceptually, we apply Nesterov's accelerated gradient method (AGM) to achieve a rate of \((1/k^{2})\) on the upper-level objective \(f\). Several variants of AGM have been proposed; see, e.g., . Here, we consider a variant proposed in . It involves three intertwined sequences of iterates \(\{_{k}\}_{k 0},\{_{k}\}_{k 0},\{_{k}\}_{k  0}\) and the scalar variables \(\{a_{k}\}_{k 0}\) and \(\{A_{k}\}_{k 0}\). In the first step, we compute the auxiliary iterate \(_{k}\) by \(_{k}=}{A_{k}+a_{k}}_{k}+}{A_{k}+a_{ k}}_{k}\). Then in the second step, we update \(_{k+1}\) by

\[_{k+1}=_{^{*}_{g}}(_{k}-a_{k} f( _{k})), \]

where \(_{^{*}_{g}}()\) denotes the Euclidean projection onto the set \(^{*}_{g}\). Finally, in the third step, we compute \(_{k+1}=}{A_{k}+a_{k}}_{k}+}{A_{k}+a _{k}}_{k+1}\) and \(A_{k+1}=A_{k}+a_{k}\). It can be shown that if the stepsize is selected as \(a_{k}=}\), then the suboptimality gap \(f(_{k})-f(^{*})\) of the iterates generated by the method above converges to zero at the optimal rate of \((1/k^{2})\). In this case, indeed all the iterates are feasible as it is possible to project onto the set \(^{*}_{g}\). However, the conceptual method above is not directly implementable for the simple bilevel problem considered in this paper, as the constraint set \(^{*}_{g}\) is not explicitly given. As a result projection onto the set \(^{*}_{g}\) is not computationally tractable.

To address this issue, we replace the implicit set \(^{*}_{g}\) in (3) with \(_{k}\), which can be explicitly characterized, making the Euclidean projection onto \(_{k}\) feasible. Additionally, \(_{k}\) must encompass the optimal solution set \(^{*}_{g}\). Inspired by the cutting plane approach in , we define \(_{k}\) as the intersection of \(\) and a halfspace:

\[_{k}\{:g(_{k})+  g(_{k}),-_{k} g_{k}\}. \]

Here, the auxiliary sequence \(\{g_{k}\}_{k 0}\) should be selected such that \(g_{k} g^{*}\) and \(g_{k} g^{*}\). One straightforward way to generate this sequence is by applying an accelerated projected gradient method to the lower-level objective \(g\) separately. The loss function of the iterates generated by this algorithm can be considered as \(\{g_{k}\}\) for the above halfspace. Note that in this case, it is known that

\[0 g_{k}-g^{*}\|_{0}-^{*}\|^{2}}{(k+1)^ {2}}, k 0. \]Hence, the above requirements on the sequence \(\{g_{k}\}\) are satisfied. Two remarks on the set \(_{k}\) are in order. First, the set \(_{k}\) in (4) has an explicit form, making the Euclidean projection onto \(_{k}\) tractable. It can also be verified that \(_{k}\) always contains the lower-level problem solution set \(_{g}^{*}\). To prove this, let \(}^{*}\) be any point in \(_{g}^{*}\). By using the convexity of \(g\), we obtain \(g(_{k})+ g(_{k}),}^{*}-_{k} g(}^{*})=g^{*} g_{k}\). Thus, \(}^{*}\) satisfies both constraints in (4), so \(}^{*}_{k}\).

Now that we have identified an appropriate replacement for the set \(_{g}^{*}\), we can easily implement a variant of the projected accelerated gradient method for the bilevel problem using the surrogate set \(_{k}\). We refer to our method as the Accelerated Gradient Method for Bilevel Optimization (AGM-BiO) and its steps are outlined in Algorithm 1. It is important to note that the iterates, when projected onto the set \(_{k}\), may not belong to the set \(_{g}^{*}\), as \(_{k}\) is an approximation of the true solution set. Consequently, the iterates might be infeasible. However, the design of \(_{k}\) allows us to control the infeasibility of the iterates, as we will demonstrate in the convergence analysis section.

_Remark 3.1_.: The design of the halfspace as specified in (4) should be recognized as a nuanced task. Various alternative formulations of halfspaces could fulfill the same primary conditions, such as \(\{:g(_{k})+ g(_{k}), -_{k} g_{k}\}\) and \(\{:g(_{k})+ g(_{k}), -_{k} g_{k}\}\). However, the selection of the gradient at \(_{k}\) for constructing the halfspace is not arbitrary but essential as we characterize in the convergence analysis of our method.

_Remark 3.2_.: How to project onto the set \(_{k}\)? In some cases, such as our over-parameterized regression problem, \(_{k}\) is the intersection of an \(L_{2}\) ball and a half-space, for which a closed-form solution exists to find the projected iterates. In other cases, such as our linear inverse problem, we may not be able to find \(_{k}\) directly. Instead, we can solve the projection subproblem using Dykstra's projection algorithm . In this case, an additional loop is needed to solve the subproblem.

```
1:Input: A sequence \(\{g_{k}\}_{k=0}^{K}\), a scalar \((0,1]\)
2:Initialization:\(A_{0}=0\), \(_{0}=_{0}\)
3:for\(k=0,,K\)do
4: Set \(a_{k}=}\)
5: Compute \(_{k}=}{A_{k}+a_{k}}_{k}+}{A_{k}+a_{k }}_{k}\)
6: Compute \(_{k+1}=_{_{k}}(_{k}-a_{k} f(_{k}))\), where \[_{k}\{:g(_{k})+  g(_{k}),-_{k} g_{k}\}\]
7: Compute \(_{k+1}=}{A_{k}+a_{k}}_{k}+}{A_{k}+a_ {k}}_{k+1}\)
8: Update \(A_{k+1}=A_{k}+a_{k}\)
9:endfor
10:Return:\(_{K}\)
```

**Algorithm 1** Accelerated Gradient Method for Bilevel Optimization (AGM-BiO)

### Algorithm for the Composite Setting

While our paper focuses on the smooth setting, our proposed method can be also extended to the composite setting. Let us consider the composite counterpart of Problem (1):

\[_{^{n}}\ f():=f_{1}()+f_{2}( )*{argmin}_{ ^{n}}g():=g_{1}()+g_{2}(), \]

where \(f_{1},g_{1}:^{n}\) are smooth convex functions and \(f_{2},g_{2}:^{n}\) are nonsmooth convex functions, respectively. To analyze and implement the proximal gradient-based methods, we need the following definition concerning the property of the proximal mapping.

**Definition 3.1**.: _Given \(h:^{n}(-,+]\) and \(>0\), the proximal map of \(h\) is defined as_

\[_{ h}()*{argmin}_{ ^{n}}\{\|-\|^{2}+h()\}. \]

To handle the upper-level nonsmooth part \(f_{2}\), we change the projection step in Step 6 of Algorithm 1 to a proximal update, which is similar to the accelerated proximal gradient method for single-level problems in .

On the other hand, to deal with the lower-level nonsmooth part \(g_{2}\), it is necessary to modify the approximated lower-level solution set \(_{k}\). Specifically, we keep the linear approximation of the smooth part of the lower-level objective function \(g_{1}\) while adding the nonsmooth part \(g_{2}\) as a lower bound of \(g_{k}\) to construct \(_{k}\). Note that the constructed set \(_{k}\) is no longer a halfspace in this setting due to the possibly non-linear nature of \(g_{2}\). We refer to our method as the Proximal Accelerated Gradient Method for Bilevel Optimization (P-AGM-BiO) and its steps are outlined in Algorithm 2.

```
1:Input: A sequence \(\{g_{k}\}_{k=0}^{K}\), a scalar \((0,1]\)
2:Initialization:\(A_{0}=0\), \(_{0}=_{0}^{n}\)
3:for\(k=0,,K\)do
4: Set \(a_{k}=}\)
5: Compute \(_{k}=}{A_{k}+a_{k}}_{k}+}{A_{k}+a _{k}}_{k}\)
6: Compute \(_{k+1}=Prox_{a_{k}(f_{2}+_{_{k}})}(_{k}- a_{k} f_{1}(_{k}))\), where \[_{k}\{^{n}:g_{1}(_{k})+  g_{1}(_{k}),-_{k}+g_{2}( ) g_{k}\}\]
7: Compute \(_{k+1}=}{A_{k}+a_{k}}_{k}+}{A_{k}+ a_{k}}_{k+1}\)
8: Update \(A_{k+1}=A_{k}+a_{k}\)
9:endfor
10:Return:\(_{K}\)
```

**Algorithm 2** Proximal Accelerated Gradient Method for Bilevel Optimization (P-AGM-BiO)

Different proximal-friendly assumptions are commonly used in the literature of composite single-level/bilevel optimization [8; 15; 16; 17]. The following proximal-friendly assumption is necessary for our method in the composite setting.

**Assumption 3.1**.: _The function \(f_{2}+_{_{k}}\) in the Step 6 of Algorithm 2 is proximal-friendly, i.e. the proximal mapping in Definition 3.1 is easy to compute, where \(_{_{k}}()\) is the indicator function._

This assumption implies that \(f_{2}\) is proximal-friendly and that projecting onto the constructed set \(_{k}\) can be done efficiently. Moreover, the function \(f_{2}+_{_{k}}\) is the sum of two convex functions, and the study of proximal mappings for such sums is well-documented in the literature [21; 22; 23; 24]. Under this assumption, all analysis for the smooth case can be extended to the composite setting. The details are provided in Section B of the Appendix.

## 4 Convergence Analysis

In this section, we analyze the convergence rate and iteration complexity of our proposed AGM-BiO method for convex simple bilevel optimization problems. We choose the stepsize \(a_{k}=}\), which is inspired from our theoretical analysis. The main theorem is as follows,

**Theorem 4.1**.: _Suppose Assumption 2.1 holds. Let \(\{_{k}\}_{k 0}\) be the sequence of iterates generated by Algorithm 1 with stepsize \(a_{k}=}\) for \(k 0\) and suppose the sequence \(g_{k}\) used for generating the cutting plane satisfies (5). Then, for any \(k 0\) we have,_

1. _The function suboptimality is bounded above by_ \(f(_{k})-f(^{*})\|_{0}- ^{*}\|^{2}}{k(k+1)}\)_._
2. _The infeasibility term is bounded above by_ \(g(_{k})-g(^{*})\|_{0}- ^{*}\|^{2}(k+1)}{k(k+1)}+D^{2}}{k+1}\)_._
3. _Furthermore, if the condition_ \(f(_{k}) f(^{*})\) _holds, then the infeasibility term is bounded above by_ \(g(_{k})-g(^{*})\|_{0}- ^{*}\|^{2}(k+1)}{k(k+1)}\)_._

Theorem 4.1 shows the upper-level objective function gap is upper bounded by \((1/k^{2})\), which matches the convergence rate of the accelerated gradient method for single-level optimization problems. On the other hand, the suboptimality of the lower-level objective which measures infeasibility for the bilevel problem in the worst case is bounded above by \((1/k)\). In the case where \(f(_{k}) f^{*}\), this upper bound improves to \((1/k^{2})\). As a corollary of the worst-case bounds, Algorithm 1 will return an \((_{f},_{g})\)-optimal solution after at most the following number of iterations \((\{}},}\})\). We should emphasize that, under the assumptions being considered, this complexity bound represents the best-known bound among all previous works summarized in Table 1.

_Remark 4.1_ (The necessity of compactness of \(\)).: For the lower-level objective, we show that \(A_{k}(g(_{k})-g(^{*}))_{i=0}^{k-1}a_{i}(g_{i}-g^{* })+}{4L_{f}}_{i=0}^{k-1}\|_{i+1}-_{i}\|^{2}\) ((24) in Section A). The main challenge in obtaining an accelerated rate of \((1/k^{2})\) for \(g\) is controlling \(_{i=0}^{k-1}\|_{i+1}-_{i}\|^{2}\). Without a lower bound on \(f\), this term cannot be bounded by the upper-level suboptimality alone. If \(f(_{k}) f(^{*})\), we can achieve the rate of \((1/k^{2})\) for \(g\). Otherwise, we use the compactness of \(\) to achieve \((1/k)\) for \(g\). Please refer to Section A for more details.

_Remark 4.2_ (Removable \(\) terms).: The \(\) terms in all the complexity results can be removed by choosing the auxiliary sequence \(g_{k}=g_{K}\) for all \(0 k K\), which satisfies the condition (5). This eliminates the \(\) term in (24) and all subsequent results. However, this choice of \(\{g_{k}\}_{k 0}\) requires predetermining the total number of iterations \(K\).

Since the algorithm's output \(}\) may fall outside the feasible set \(_{g}^{*}\), the expression \(f(})-f^{*}\) may not necessarily be non-negative. On the other hand, under the considered assumptions, proving convergence in terms of \(|f(})-f^{*}|\) is known to be impossible due to a negative result presented by . Specifically, for any first-order method and a given number of iterations \(k\), they demonstrated the existence of an instance of Problem (1) where \(|f(_{k})-f^{*}| 1\) for all \(k 0\). Thus, to provide any form of guarantee in terms of the absolute value of the suboptimality, i.e., \(|f(})-f^{*}|\), we need an additional assumption to obtain a lower bound on suboptimality and to provide a convergence bound for \(|f(})-f^{*}|\). We will address this point in the following section.

### Convergence under Holderian Error Bound

In this section, we introduce an additional regularity condition on \(g\) to establish a lower bound for \(f(})-f^{*}\). Specifically, we assume that the lower-level objective function \(g\) satisfies the Holderian Error Bound condition, which governs how \(g()\) grows as \(\) moves away from the optimal solution set \(_{g}^{*}\). Intuitively, since our method's output \(}\) is \(_{g}\)-optimal for the lower-level problem, it should be close to \(_{g}^{*}\) under this regularity condition. We can then use this proximity and the smoothness property of \(f\) to establish a lower bound for \(f(})-f^{*}\).

**Assumption 4.1**.: _The function \(g\) satisfies the Holderian error bound for some \(>0\) and \(r 1\), i.e,_

\[(,_{g}^{*} )^{r} g()-g^{*},, \]

_where \((,_{g}^{*}) _{^{}_{g}^{*}}\|-^{ }\|\)._

We note that the Holderian error bound condition in (8) is well-studied in the optimization literature  and is known to hold in general when function \(g\) is analytic and the set \(\) is bounded . There are two important special cases of the Holderian error bound condition: 1) \(g\) satisfies (8) with \(r=1\) known as the weak sharpness condition ; 2) \(g\) satisfies (8) with \(r=2\) known as the quadratic functional growth condition . By using the Holderian error bound condition,  established a stronger relation between suboptimality and infeasibility, as shown next.

**Proposition 4.2** ([6, Proposition 1]).: _Assume that \(f\) is convex and \(g\) satisfies Assumption 4.1, and define \(M=_{_{g}^{*}}\| f()\|_{*}\). Then \(f(})-f^{*}-M(})-g^{*})}{})^{ }\) for any \(}\)._

Hence, under Assumption 4.1, Proposition 4.2 shows that the suboptimality \(f(})-f^{*}\) can also be bounded from below when \(}\) is an approximate solution of the lower-level problem. As a result, we can establish a convergence bound on \(|f(_{k})-f^{*}|\) by combining Proposition 4.2 with the upper bounds in Theorem 4.1. Moreover, it also allows us to improve the convergence rate for the lower-level problem. To prove this claim, we first introduce the following lemma which establishes an upper bound on the weighted sum of upper and lower-level objectives.

**Lemma 4.3**.: _Suppose conditions (ii) and (iii) in Assumption 2.1 hold. Let \(\{_{k}\}\) be the sequence of iterates generated by Algorithm 1 with stepsize \(a_{k}=}\), where \(0< 1\). If the sequence used for generating the cutting plane satisfies (5), then for any \(}{(2/-1)L_{f}}\) and \(k 0\) we have_

\[(f(_{k})-f(^{*}))+g(_{k})-g(^{*}) \|_{0}-^{*}\|^{2}(k+1)}{k(k+1)}+\|_{0}-^{*}\|^{2}}{ k(k+1)}. \]

This result characterizes and upper bound of \(}(1/k^{2})\) on the expression \((f(_{k})-f(^{*}))+g(_{k})-g(^{*})\). That said, the first term in this expression, a.k.a., \((f(_{k})-f(^{*}))\) may not be non-negative for a bilevel problem as discussed earlier. Hence, we cannot simply eliminate \((f(_{k})-f(^{*}))\) to show an upper bound of \((1/k^{2})\) on infeasibility, a.k.a., \(g(_{k})-g(^{*})\). Instead, we leverage the Holderian error bound on \(g\) and apply Proposition 4.2 to the first term. As a result, we can eliminate the dependence on \(f\) in (9). In this case, we can establish an upper bound on infeasibility.

**Theorem 4.4**.: _Suppose conditions (ii) and (iii) in Assumption 2.1 hold and the lower-level function \(g\) satisfies the Holderian error bound with \(r>1\). Let \(\{_{k}\}\) be the iterates generated by Algorithm 1 with stepsize \(a_{k}=}\), where \(=1/(}{L_{f}}K^{}+2)\) and \(K\) is the total number of iterations. Moreover, suppose the sequence \(q_{k}\) used for generating the cutting plane satisfies (5). If we define the constants \(C_{f} 8L_{f}\|_{0}-^{*}\|^{2}\), \(C_{g} 12L_{g}\|_{0}-^{*}\|^{2}\) and \(C M()^{}\), where \(M_{_{g}^{*}}\| f()\|\), \(\) and \(r\) are the parameters in Assumption 4.1, then the following results hold:_

1. _The function suboptimality is bounded above by_ \[f(_{K})-f(^{*})( K+1)}{K^{}}+}{K^{2}}.\]
2. _The function suboptimality is bounded below by_ \[f(_{K})-f(^{*})-C\{( K+1))^{ }}{K^{}}+)^{}}{K^{}},}}{K^{}}\}\]
3. _The infeasibility term is bounded above by_ \[g(_{K})-g(^{*})\{( K+1)}{K^{ }}+}{K^{2}},}}{K^{}}\}\]

Before unfolding this result, we would like to highlight that unlike the result in Theorem 4.1, the above bounds in Theorem 4.4 do not require the feasible set to be compact. Since \(r>1\), the first result shows \(f(_{K})-f(^{*})\) has an upper bound of \(}(()^{})\) and the second result guarantees a lower bound of \(-}(()^{})\). These two bounds together lead to an upper bound of \(}(()^{})\) for the absolute error \(|f(_{K})-f(^{*})|\). Moreover, the third result implies that the lower-level problem suboptimality which measures infeasibility is bounded above by \(}(()^{})\).

The previous result presented in Theorem 4.4 is applicable when \(r>1\). However, for the case that 1st-order Holderian error bound condition on \(g\) holds (i.e., weak sharpness condition), we require a distinct analysis and a different choice of \(\) to achieve the tightest bounds. In the subsequent theorem, we present our findings for this specific scenario.

**Theorem 4.5**.: _Suppose conditions (ii) and (iii) in Assumption 2.1 are met and that the lower-level objective function \(g\) satisfies the Holderian error bound with \(r=1\). Let \(\{_{k}\}\) be the sequence of iterates generated by Algorithm 1 with stepsize \(a_{k}=}\), where \(0<\{}{2ML_{g}+ L_{f}},1\}\). Moreover, suppose the sequence \(q_{k}\) used for generating the cutting plane satisfies (5), and recall \(M_{_{g}^{*}}\| f()\|\) and \(\) in Assumption 4.1. If we define the constants \(C_{f} 4L_{f}\|_{0}-^{*}\|^{2}\) and \(C_{g} 8L_{g}\|_{0}-^{*}\|^{2}\), then for any \(k 0\):_

1. _The function suboptimality is bounded above by_ \(f(_{k})-f(^{*})}{ k(k+1)}\)_._
2. _The function suboptimality is bounded below by_ \(f(_{k})-f(^{*})-M}{ k(k+1)}-}{ k(k+1)}\)_._
3. _The infeasibility term is bounded above by_ \(g(_{k})-g(^{*})( k+1)}{k(k+1)}+}{ Mk(k+1)}\)_._

Theorem 4.5 shows that under the Holderian error bound with \(r=1\), also known as weak sharpness condition, the absolute value of the function suboptimality \(|f(_{k})-f(^{*})|\) approaches zero at a rate of \((1/k^{2})\) - ignoring the log term. The lower-level error \(g(_{k})-g(^{*})\), capturing the infeasibility of the iterates, also approaches zero at a rate of \((1/k^{2})\). As a corollary, Algorithm 1 returns an \((_{f},_{g})\)-absolute optimal solution after \(}(\{}},}}\})\) iterations.

## 5 Numerical Experiments

In this section, we evaluate our AGM-BiO method on two different bilevel problems using real and synthetic datasets. We compare its runtime and iteration count with other methods, including a-IRG , CG-BiO , Bi-SG , SEA , R-APM , PB-APG , and Bisec-BiO .

**Over-parameterized regression.** We examine problem (1) where the lower-level problem corresponds to training loss, and the upper-level pertains to validation loss. The objective is to minimize the validation loss by selecting an optimal training loss solution. This method is also referred to as lexicographic optimization . A common example of that is the constrained regression problem, where we aim to find an optimal parameter vector \(^{d}\) for the validation loss that minimizes the loss \(_{}()\) over the training dataset \(_{}\). To represent some prior knowledge, we constrain \(\) to be in some subset \(^{d}\), e.g., \(=\{_{1}_{d}\}\) in isolation regression and \(=\{\|\|_{p}\}\) in \(L_{p}\) constrained regression. Without explicit regularization, an over-parameterized regression over the training dataset has multiple global minima, but not all these optimal regression coefficients perform equally on validation or testing datasets. Thus, the upper-level objective serves as a secondary criterion to ensure a smaller error on the validation dataset \(_{}\). The problem can be cast as

\[_{^{d}}f()_{}( )*{argmin}_{} }\;g(})_{}(})\]

In this case, both upper-level and lower-level objectives are convex and smooth if the loss \(\) is smooth and convex. Since projections onto the sublevel set of \(f\) are difficult to compute, Bisec-BiO is excluded from this experiment.

We apply the Wikipedia Math Essential dataset  which is composed of a data matrix \(}^{n d}\) with \(n=1068\) samples and \(d=730\) features and an output vector \(}^{n}\). We use \(75\%\) of the dataset as the training set \((}_{},}_{})\) and \(25\%\) as the validation set \((}_{},}_{})\). For both upper- and lower-level loss functions, we use the least squared loss. Then the lower-level objective is \(g()=\|}_{tr}-}_{tr }\|_{2}^{2}\), the upper-level objective is \(f()=\|}_{val}-}_{ val}\|_{2}^{2}\), and the constraint set is chosen as the unit \(L_{2}\)-ball \(=\{\|\|_{2} 1\}\). Note that this regression problem is over-parameterized since the number of features \(d\) is larger than the number of data points in both the training set and validation set.

In Figures 1(a) and 1(c), we observe that the three accelerated gradient-based methods (R-APM, PB-APG, and AGM-BiO) converge faster in reducing infeasibility, both in terms of runtime and number of iterations. In terms of absolute suboptimality, shown in Figures 1(b) and 1(d), AGM-BiO achieves the smallest absolute suboptimality gap among all algorithms. Unlike the infeasibility plots, R-APM and PB-APG underperform compared to AGM-BiO. Note that the lower-level objective in this problem does not satisfy the weak sharpness condition, so the regularization parameter \(\) in R-APM is set as \(1/(K+1)\). Consequently, the suboptimality for R-APM converges slower than AGM-BiO, as suggested by the theoretical results in Table 1.

**Linear inverse problems.** In the next experiment, we concentrate on a problem that fulfills the Holderian Error Bound condition for some \(r>1\). We aim to evaluate the performance of our method in this specific context and verify the validity of our theoretical results for this scenario. Specifically, we focus on the so-called linear inverse problems, commonly used to evaluate convex

Figure 1: Comparison of a-IRG, CG-BiO, Bi-SG, SEA, R-APM, PB-APG, and AGM-BiO for solving the over-parameterized regression problem.

bilevel optimization algorithms, which originate from . The goal of linear inverse problems is to obtain a solution \(^{n}\) to the system of linear equation \(=\). Note that if \(\) is rank-deficient, there can be multiple solutions, or there might be no exact solution due to noise. To address this issue, we chase a solution that has the smallest weighted norm with respect to some positive definite matrix \(\), i.e., \(\|\|_{}:=^{}}\). This problem can be also cast as the following simple bilevel problem:

\[_{^{n}}f()\|\|_{}^{2}*{argmin}_{}g( )\|-\|_{2}^{2}\]

For this class of problem, if \(\), \(\), and \(\) are generated randomly or by the "regularization tools" like [14; 35], we are not able to obtain the exact optimal value \(f^{*}\). To the best of our knowledge, no existing solver could obtain the exact optimal value \(f^{*}\) for this bilevel problem. Specifically, the existing solvers either fail to solve this bilevel problem or return an inaccurate solution by solving a relaxed version of the problem. Hence, in [14; 35] they only reported the upper-level function value. However, in this paper, we intend to obtain the complexity bounds for finding \((_{f},_{g})\)-optimal and \((_{f},_{g})\)-absolute optimal solutions. Without knowing \(f^{*}\), we can not characterize the behavior of \(|(_{k})-f^{*}|\). Therefore, we choose an example where we can obtain the exact solution. Specifically, we set \(=_{n}\), \(=_{n}^{}\), \(=1\), and the constraint set \(=_{+}^{n}\). In this case, the optimal solution \(^{*}=_{n}\) and optimal value \(f^{*}=\). This specific example essentially involves seeking the minimum norm for an under-determined system. Note that the lower-level objective in this problem satisfies the Holderian Error Bound condition with order \(r=2\). Hence, we do not need the constraint set \(\) to be compact as shown in Theorem 4.4. Due to the unbounded nature of the constraint set, Frank-Wolfe-type methods are not viable options. Consequently, we have opted not to incorporate CG-BiO in this experiment.

We explored examples with two distinct dimensions: \(n=3\) and \(n=100\), evaluating a total of \(2000\) gradients. In Figures 2(a) and 2(c), AGM-BiO shows superior performance in terms of infeasibility. In Figures 2(b) and 2(d), we compare methods in terms of absolute error of suboptimality. The gap between R-APM and AGM-BiO is smaller for \(n=3\), but for \(n=100\), AGM-BiO significantly outperforms all other methods, including R-APM. Since the regularization and penalty parameters in R-APM and PB-APG are fixed, they might get stuck at a certain accuracy level, as seen in Figures 2(a) and 2(c). In contrast, AGM-BiO uses a dynamic framework for minimizing the upper and lower-level functions, consistently reducing both suboptimality and infeasibility. Although Bisec-BiO theoretically has the best complexity results due to the ease of projecting onto the sublevel set of \(f\), its performance in the last iteration is inconsistent, as shown in Figure 2.

## 6 Conclusion

In this paper, we introduced an accelerated gradient-based algorithm for solving a specific class of bilevel optimization problems with convex objective functions in both the upper and lower levels. Our proposed algorithm achieves a computational complexity of \((\{_{f}^{-0.5},_{g}^{-1}\})\). When an additional weak sharpness condition is applied to the lower-level function \(g\), the iteration complexity improves to \(}(\{_{f}^{-0.5},_{g}^{-0.5}\})\), matching the well-known fastest convergence rate for single-level convex optimization problems. We further extended this result to an iteration complexity of \(}(\{_{f}^{-},_{g}^{- {2r-1}{2r}}\})\) when the lower-level loss satisfies the Holderian error bound assumption.

Figure 2: Comparison of a-IRG, Bi-SG, SEA, R-APM, PB-APG, Bisec-BiO, and AGM-BiO for solving the linear inverse problem.