# Timewarp: Transferable Acceleration of Molecular Dynamics by Learning Time-Coarsened Dynamics

Leon Klein

Freie Universitat Berlin

leon.klein@fu-berlin.de&Andrew Y. K. Foong1

Microsoft Research AI4Science

andrewfoong@microsoft.com&Tor Erlend Fjelde1

University of Cambridge

ter30@cam.ac.uk

Bruno Mlodozeniec1

University of Cambridge

bkm28@cam.ac.uk

Marc Brockschmidt2

University of Cambridge

ter30@cam.ac.uk

Sebastian Nowozin2

Frank Noe

Microsoft Research AI4Science

Freie Universitat Berlin

franknoe@microsoft.com

###### Abstract

Molecular dynamics (MD) simulation is a widely used technique to simulate molecular systems, most commonly at the all-atom resolution where equations of motion are integrated with timesteps on the order of femtoseconds (\(1=10^{-15}\)). MD is often used to compute equilibrium properties, which requires sampling from an equilibrium distribution such as the Boltzmann distribution. However, many important processes, such as binding and folding, occur over timescales of milliseconds or beyond, and cannot be efficiently sampled with conventional MD. Furthermore, new MD simulations need to be performed for each molecular system studied. We present _Timewarp_, an enhanced sampling method which uses a normalising flow as a proposal distribution in a Markov chain Monte Carlo method targeting the Boltzmann distribution. The flow is trained offline on MD trajectories and learns to make large steps in time, simulating the molecular dynamics of \(10^{5}-10^{6}\,\). Crucially, Timewarp is _transferable_ between molecular systems: once trained, we show that it generalises to unseen small peptides (2-4 amino acids) at all-atom resolution, exploring their metastable states and providing wall-clock acceleration of sampling compared to standard MD. Our method constitutes an important step towards general, transferable algorithms for accelerating MD.

## 1 Introduction

Molecular dynamics (MD) is a well-established technique for simulating physical systems at the atomic level. When performed accurately, it provides unrivalled insight into the detailed mechanics of molecular motion, without the need for wet lab experiments. MD simulations have been used to understand processes of central interest in molecular biophysics, such as protein folding [29; 22], protein-ligand binding , and protein-protein association . Many crucial applications of MD boil down to efficiently sampling from the _Boltzmann distribution_, _i.e._, the equilibrium distributionof a molecular system at a temperature \(T\). Let \((x^{p}(t),x^{v}(t)):=x(t)^{6N}\) be the state of the molecule at time \(t\), consisting of the positions \(x^{p}(t)^{3N}\) and velocities \(x^{v}(t)^{3N}\) of the \(N\) atoms in Cartesian coordinates. The Boltzmann distribution is given by:

\[(x^{p},x^{v})(-T}(U(x^{p})+K(x^{v}))), (x^{p})=(x^{p},x^{v})\,x^{v}.\] (1)

where \(U(x^{p})\) is the potential energy, \(K(x^{v})\) is the kinetic energy, and \(k_{B}\) is Boltzmann's constant. Many important quantities, such as the free energies of protein folding and protein-ligand binding, can be computed as expectations under \((x^{p})\). A popular MD method to sample from \((x^{p})\) is _Langevin dynamics_, which obeys the following stochastic differential equation (SDE):

\[m_{i}x^{v}_{i}=-_{i}Ut- m_{i}x^{v}_{i} t+ k_{B}T}B_{t}.\] (2)

Here \(i\) indexes the atoms, \(m_{i}\) is the mass of atom \(i\), \(U(x^{p})\) is the potential energy, \(\) is a friction parameter, and \(B_{t}\) is a standard Brownian motion process. Starting from an initial state \(x(0)\), simulating Equation (2), along with the relationship \(x^{p}=x^{v}t\), yields values of \(x(t)\) that are distributed according to the Boltzmann distribution as \(t\). Standard MD libraries discretise this SDE with a timestep \( t\), which must be chosen to be \( 1=10^{-15}\) for stability. Unfortunately, many biomolecules contain metastable states separated by energy barriers that can take milliseconds of MD simulation time (\( 10^{12}\) sequential integration steps) to cross, rendering this approach infeasible. To overcome this, prior work has produced an array of _enhanced sampling methods_, such as coarse graining  and metadynamics . However, these methods require domain knowledge specific to each molecular system to implement effectively.

Standard MD simulations do not transfer information between molecular systems: for each system studied, a new simulation must be performed. This is a wasted opportunity: many molecular systems exhibit closely related dynamics, and simulating one system should yield information relevant to similar systems. In particular, proteins, being comprised of sequences of 20 kinds of amino acids, are prime candidates to study this kind of transferability. We propose _Timewarp_, a general, transferable enhanced sampling method which uses a _normalising flow_ as a proposal for a Markov chain Monte Carlo (MCMC) method targeting the Boltzmann distribution. Our main contributions are:

1. We present the first ML algorithm working in general Cartesian coordinates that demonstrates _transferability_ to small peptide systems unseen during training.
2. We demonstrate, for the first time, wall-clock acceleration of asymptotically unbiased MCMC sampling of the Boltzmann distribution of unseen peptide systems.
3. We define an MCMC algorithm targeting the Boltzmann distribution using a conditional normalising flow as a proposal distribution, with a Metropolis-Hastings (MH) correction step to ensure detailed balance (Section 3.4).
4. We design a permutation equivariant, transformer-based normalising flow.
5. We produce a novel training dataset of MD trajectories of thousands of small peptides.
6. We show that even when deployed _without_ the MH correction (Section 3.5), Timewarp can be used to explore metastable states of new peptides much faster than MD.

Figure 1: (a) Initial state \(x(t)\) (_Left_) and accepted proposal state \(x(t+) p_{}(x(t+)|x(t))\) (_Right_) sampled with Timewarp for the dipeptide HT (unseen during training). (b) TICA projections of simulation trajectories, showing transitions between metastable states, for a short MD simulation (_Left_) and Timewarp MCMC (_Right_), both run for 30 minutes of wall-clock time. Timewarp MCMC achieves a speed-up factor of \( 33\) over MD in terms of effective sample size per second.

The code is available here: https://github.com/microsoft/timewarp. The datasets are available upon request3.

## 2 Related work

There has recently been a surge of interest in deep learning on molecules. _Boltzmann generators_[28; 17; 15] use flows to sample from the Boltzmann distribution asymptotically unbiased. There are two ways to generate samples: (i) Produce i.i.d. samples from the flow and use statistical reweighting to debias expectation values. (ii) Use the Boltzmann generator in an MCMC framework , as in Timewarp. Currently, Boltzmann generators lack the ability to generalize across multiple molecules, in contrast to Timewarp. The only exception is , who propose a diffusion model in torsion space and use the underlying ODE as a transferable Boltzmann generator. However, in contrast to Timewarp, they use internal coordinates and do not operate in the all atom system. Moreover, [13; 25] recently introduced a Boltzmann generators in Cartesian coordinates for molecules, potentially enabling transferable training. Recently,  proposed _GeoDiff_, a diffusion model that predicts molecular conformations from a molecular graph. Like Timewarp, GeoDiff works in Cartesian coordinates and generalises to unseen molecules. However, GeoDiff was not applied to proteins, but small molecules, and does not target the Boltzmann distribution. In contrast to Timewarp,  learn the transition probability for multiple time-resolutions, accurately capturing the dynamics. However, they do not show transferability between systems. Most similarly to Timewarp, in recent work,  trained a transferable ML model to simulate the time-coarsened dynamics of polymers. However, unlike Timewarp, their model acts on coarse grained representations. Additionally, it was not applied to proteins, and there is no MH step, which means that errors can accumulate in the simulation without being corrected.

_Markov state models_ (MSMs) [32; 40; 10] work by running many short MD simulations, which are used to define a discrete state space, along with an estimated transition probability matrix. Similarly to Timewarp, MSMs estimate the transition probability between the state at a time \(t\) and the time \(t+\), where \( t\). Recent work has applied deep learning to MSMs, leading to _VAMPnets_ and _deep generative MSMs_, which replace the MSM data-processing pipeline with deep networks. In contrast to Timewarp, these models are not transferable and model the dynamics in a coarse-grained, discrete state space, rather than in the all-atom coordinate representation.

There has been much previous work on _neural adaptive samplers_[38; 20; 21], which use deep generative models as proposal distributions. _A-NICE-MC_ uses a volume-preserving flow trained using a likelihood-free adversarial method. Other methods use objective functions designed to encourage exploration. The entropy term in our objective function is inspired by . In contrast to these methods, Timewarp focuses on _generalising_ to new molecular systems without retraining.

Numerous enhanced sampling methods exist to for MD, such as parallel tempering [39; 6] or proposing updates of collective variables along transition paths [18; 27]. Given Timewarp's ability to accelerate MD, it often offers the opportunity to be integrated with these techniques.

## 3 Method

Consider the distribution of \(x(t+)\) induced by an MD simulation of Equation (2) for a time \( t\), starting from \(x(t)\). We denote this conditional distribution by \((x(t+)|x(t))\). Timewarp uses a deep probabilistic model to approximate \((x(t+)|x(t))\) (see Figure 1). Once trained, the model is used in an MCMC method to sample from the Boltzmann distribution.

### Conditional normalising flows

We fit a _conditional normalising flow_, \(p_{}(x(t+)|x(t))\), to \((x(t+)|x(t))\), where \(\) are learnable parameters. Normalising flows are defined by a base distribution (usually a standard Gaussian), and a _diffeomorphism_\(f\), _i.e._ a differentiable bijection with a differentiable inverse. Specifically, we set \(p_{}(x(t+)|x(t))\) as the density of the distribution defined by the following generative process:

\[z^{p},z^{v}(0,I), x^{p}(t+),x^{v}(t+) f _{}(z^{p},z^{v};x^{p}(t),x^{v}(t)).\] (3)Here \(z^{p}^{3N}\) and \(z^{v}^{3N}\). For all settings of \(\) and \(x(t)\), \(f_{}(\ \ ;x(t))\) is a diffeomorphism that takes the latent variables \((z^{p},z^{v})^{6N}\) to \((x^{p}(t+),x^{v}(t+))^{6N}\). The conditioning state \(x(t)\) parameterises a family of diffeomorphisms, defining a _conditional_ normalising flow . Note that there are no invertibility constraints on the mapping from \(x(t)\) to the output \(x(t+)\), only the map from \(z\) to \(x(t+)\) must be invertible. Using the change of variables formula, we can evaluate:

\[p_{}(x(t+)|x(t))=(f_{}^{-1}(x(t+);x(t));0, I)|_{f_{}^{-1}(\ ;x(t))}(x(t+))|,\]

where \(f_{}^{-1}(\ \ ;x(t)):^{6N}^{6N}\) is the inverse of the diffeomorphism \(f_{}(\ \ ;x(t))\), and \(_{f_{}^{-1}(\ ;x(t))}(x(t+))\) denotes the Jacobian of \(f_{}^{-1}(\ \ ;x(t))\) evaluated at \(x(t+)\).

### Dataset generation

We generate MD trajectories by integrating Equation (2) using the _OpenMM_ library . We simulate small proteins (peptides) in implicit water, _i.e._, without explicitly modelling the degrees of freedom of the water molecules. Specifically, we generate a dataset of trajectories \(=\{_{i}\}_{i=1}^{P}\), where \(P\) is the number of peptides. Each MD trajectory is temporally subsampled with a spacing of \(\), so that \(_{i}=(x(0),x(),x(2),)\). During training, we randomly sample pairs \(x(t),x(t+)\) from \(\). Each pair represents a sample from the conditional distribution \((x(t+)|x(t))\). Additional details are provided in Appendix E. Since the flow is trained on trajectory data from _multiple_ peptides, we can deploy it at test time to generalise to _new_ peptides not seen in the training data.

### Augmented normalising flows

We are typically primarily interested in the distribution of the _positions_\(x^{p}\), rather than the velocities \(x^{v}\). Thus, it is not necessary for \(x^{v}(t),x^{v}(t+)\) to represent the actual velocities of the atoms in Equation (3). We hence simplify the learning problem by treating \(x^{v}\) as _non-physical auxiliary variables_ within the _augmented normalising flow_ framework . For each datapoint \(x(t)=x^{p}(t),x^{v}(t)\) in \(\), instead of obtaining \(x^{v}(t)\) by recording the velocities in the MD trajectory, we _discard_ the MD velocity and independently draw \(x^{v}(t)(0,I)\). The auxiliary variables \(x^{v}(t)\) now contain no information about the future state \(x^{p}(t+),x^{v}(t+)\), since \(x^{v}(t)\) and \(x^{v}(t+)\) are drawn independently. Hence we can simplify \(f_{}\) to depend only on \(x^{p}(t)\), with \(x^{p}(t+),x^{v}(t+) f_{}(z^{p},z^{v};x^{p}(t))\). We include auxiliary variables for two reasons: First, they increase the expressivity of the distribution for \(x^{p}\) without a prohibitive increase in computational cost [9; 2]. Second, constructing a conditional flow that respects _permutation equivariance_ is simplified with auxiliary variables -- see Section 4.1.

### Targeting the Boltzmann distribution with asymptotically unbiased MCMC

After training the flow \(p_{}(x(t+)|x(t))\), we use it as a proposal distribution in an MCMC method to target the joint distribution of the positions \(x^{p}\) and the auxiliary variables \(x^{v}\), which has density:

\[_{}(x^{p},x^{v})(-)}{k_{B}T} )(x^{v};0,I).\] (4)

Starting from an initial state \(X_{0}=(X_{0}^{p},X_{0}^{v})^{6N}\) for state \(m=0\), we iterate:

\[_{m} p_{}(\ \ |X_{m}^{p}), X_{m+1}:= _{m}&(X_{m},_{m})\\ X_{m}&1-(X_{m},_{m})\] (5)

where \((X_{m},_{m})\) is the _Metropolis-Hastings (MH) acceptance ratio_ targeting Equation (4):

\[(X,)=(1,\,}()p_{ }(X\ |\ ^{p})}{_{}(X)p_{}(\ |\ X^{p})})\] (6)

The flow used for \(p_{}\) must allow for efficient sampling _and_ exact likelihood evaluation, which is crucial for fast implementation of Equations (5) and (6). Additionally, after each MH step, we resample the auxiliary variables \(X^{v}\) using a _Gibbs sampling_ update:

\[(X_{m}^{p},X_{m}^{v})(X_{m}^{p},),(0,I).\] (7)Iterating these updates yields a sample \(X^{p}_{m},X^{v}_{m}_{}\) as \(m\). To obtain a Boltzmann-distributed sample of the positions \(X^{p}_{m}\), we simply discard the auxiliary variables \(X^{v}_{m}\). As sending \(m\) is infeasible, we simulate the chain until a fixed budget is reached. In practice, we find that acceptance rates for our models can be low, around \(1\%\). However, we stress that even with a low acceptance rate, our models can lead to faster exploration if the changes proposed are large enough, as we demonstrate in Section 6. Furthermore, we introduce a _batch sampling_ procedure which significantly speeds up sampling whilst maintaining detailed balance. This procedure samples a batch of proposals with a single forward pass, and accepts the first proposal that meets the MH acceptance criterion. Pseudocode for the MCMC algorithm is given in Algorithm 1 in Appendix C.

### Fast but biased exploration of the state space without MH corrections

Instead of using the MH correction to guarantee asymptotically unbiased samples, we can opt to use Timewarp in a simple _exploration_ algorithm. In this case, we neglect the MH correction and accept all proposals with energy changes below some cutoff. This allows much faster exploration of the state space, and in Section 6 we show that, although technically biased, this often leads to qualitatively accurate free energy estimates. It also succeeds in discovering all metastable states orders of magnitude faster than Algorithm 1 and standard MD, which could be used, _e.g._, to provide initialisation states for a subsequent MSM method. Pseudocode is given in Algorithm 2 in Appendix D.

## 4 Model architecture

We now describe the architecture of the flow \(f_{}(z^{p},z^{v};x^{p}(t))\), which is shown in Figure 2.

RealNVP coupling flowOur architecture is based on RealNVP , which consists of a stack of _coupling layers_ which affinely transform subsets of the dimensions of the latent variable based on the other dimensions. Specifically, we transform the position variables based on the auxiliary variables, and vice versa. In the \(\)th coupling layer of the flow, the following transformations are implemented:

\[z^{p}_{+1} =s^{p}_{,}(z^{v}_{};x^{p}(t)) z^{p}_{}+t^ {p}_{,}(z^{v}_{};x^{p}(t)),\] (8) \[z^{v}_{+1} =s^{v}_{,}(z^{p}_{+1};x^{p}(t)) z^{v}_{}+t ^{v}_{,}(z^{p}_{+1};x^{p}(t)).\] (9)

Going forward, we suppress the coupling layer index \(\). Here \(\) is the element-wise product, and \(s^{p}_{}:^{3N}^{3N}\) is our _atom transformer_, a neural network based on the transformer architecture  that takes the auxiliary latent variables \(z^{v}\) and the conditioning state \(x(t)\) and outputs scaling factors for the position latent variables \(z^{p}\). The function \(t^{p}_{}:^{3N}^{3N}\) is implemented as another atom transformer, which uses \(z^{v}\) and \(x(t)\) to output a translation of the position latent variables \(z^{p}\). The affine transformations of the position variables (in Equation (8)) are interleaved with similar affine transformations for the auxiliary variables (in Equation (9)). Since the scale and translation factors for the positions depend only on the auxiliary variables, and vice versa, the Jacobian of the transformation is lower triangular, allowing for efficient computation of the density. The full flow \(f_{}\) consists of \(N_{}\) stacked coupling layers, beginning from \(z(0,I)\) and ending with a sample from \(p_{}(x(t+)|x(t))\). This is depicted in Figure 2, Left. Note that there is a skip connection such that the output of the flow predicts the _change_\(x(t+)-x(t)\), rather than \(x(t+)\) directly.

Atom transformerWe now describe the _atom transformer_ network. Let \(x^{p}_{i}(t),z^{p}_{i},z^{v}_{i}\), all elements of \(^{3}\), denote respectively the position of atom \(i\) in the conditioning state, the position latent variable for atom \(i\), and the auxiliary latent variable for atom \(i\). To implement an atom transformer which takes \(z^{v}\) as input (such as \(s^{p}_{}(z^{v},x^{p}(t))\) and \(t^{p}_{}(z^{v},x^{p}(t))\) in Equation (8)), we first concatenate the variables associated with atom \(i\). This leads to a vector \(a_{i}:=[x^{p}_{i}(t),h_{i},z^{v}_{i}]^{}^{H+6}\), where \(z^{p}_{i}\) has been excluded since \(s^{p}_{},t^{p}_{}\) are not allowed to depend on \(z^{p}\). Here \(h_{i}^{H}\) is a learned embedding vector which depends only on the atom type. The vectors \(a_{i}\) are fed into an MLP \(_{}:^{H+6}^{D}\), where \(D\) is the feature dimension of the transformer. The vectors \(_{}(a_{1}),,_{}(a_{N})\) are then fed into \(N_{}\) stacked transformer layers. After the transformer layers, they are passed through another atom-wise MLP, \(_{}:^{D}^{3}\). The final output is in \(^{3N}\) as required. This is depicted in Figure 2, Middle. When implementing \(s^{v}_{}\) and \(t^{v}_{}\) from Equation (9), a similar procedure is performed on the vector \([x^{p}_{i}(t),h_{i},z^{p}_{i}]^{}\), but now including \(z^{p}_{i}\) and excluding \(z^{v}_{i}\). There are two key differences between the atom transformer and the architecture in . First, to maintain permutation equivariance,we do not use a positional encoding. Second, instead of dot product attention, we use a simple _kernel self-attention_ module, which we describe next.

Kernel self-attentionWe motivate the kernel self-attention module with the observation that physical forces acting on the atoms in a molecule are _local: i.e._, they act more strongly on nearby atoms. Intuitively, for values of \(\) that are not too large, the positions at time \(t+\) will be more influenced by atoms that are nearby at time \(t\), compared to atoms that are far away. Thus, we define the attention weight \(w_{ij}\) for atom \(i\) attending to atom \(j\) as follows:

\[w_{ij}=^{p}-x_{j}^{p}\|_{2}^{2}/^{2})}{_{j^{} =1}^{N}(-\|x_{i}^{p}-x_{j^{}}^{p}\|_{2}^{2}/^{2})},\] (10)

where \(\) is a lengthscale parameter. The outputs \(\{r_{,i}\}_{i=1}^{N}\), given the inputs \(\{r_{,i}\}_{i=1}^{N}\), are then:

\[r_{,i}=_{j=1}^{N}w_{ij}V r_{,j},\] (11)

where \(V^{d_{} d_{}}\) is a learnable matrix. This kernel self-attention is an instance of the RBF kernel attention investigated in . Similarly to , we introduce a _multihead_ version, where each head has a different lengthscale. This is illustrated in Figure 2, Right. We found that kernel self-attention was significantly faster to compute than dot product attention, and performed similarly.

### Symmetries

The MD dynamics respects certain physical _symmetries_ that would be advantageous to incorporate. We now describe how each of these symmetries is incorporated in Timewarp.

Permutation equivarianceLet \(\) be a permutation of the \(N\) atoms. Since the atoms have no intrinsic ordering, the only effect of a permutation of \(x(t)\) on the future state \(x(t+)\) is to permute the atoms similarly, _i.e._,

\[( x(t+)| x(t))=(x(t+)|x(t)).\] (12)

Our conditional flow satisfies permutation equivariance exactly. To show this, we use the following proposition proved in Appendix A.1, which is an extension of  for conditional flows:

Figure 2: Schematic illustration of the Timewarp conditional flow architecture, described in Section 4. _Left_: A single conditional RealNVP coupling layer. _Middle_: A single atom transformer module. _Right_: the multihead kernel self-attention module.

**Proposition 4.1**.: _Let \(\) be a symmetry action, and let \(f(\ \ ;\ \ )\) be an equivariant map such that \(f( z; x)= f(z;x)\) for all \(,z,x\). Further, let the base distribution \(p(z)\) satisfy \(p( z)=p(z)\) for all \(,z\). Then the conditional flow defined by \(z p(z)\), \(x(t+):=f(z;x(t))\) satisfies \(p( x(t+)| x(t))=p(x(t+)|x(t))\)._

Our flow satisfies \(f_{}( z; x(t))= f_{}(z;x(t))\) since the transformer is permutation equivariant, and permuting \(z\) and \(x(t)\) together permutes the inputs. Furthermore, the base distribution \(p(z)=(0,I)\) is permutation invariant. Note that the presence of auxiliary variables allows us to easily construct a permutation equivariant coupling layer.

Translation and rotation equivarianceConsider a transformation \(T=(R,a)\) that acts on \(x^{p}\):

\[Tx_{i}^{p}=Rx_{i}^{p}+a, 1 i N,\] (13)

where \(R\) is a \(3 3\) rotation matrix, and \(a^{3}\) is a translation vector. We would like the model to satisfy \(p_{}(Tx(t+)|Tx(t))=p_{}(x(t+)|x(t))\). We achieve translation equivariance by subtracting the average position of the atoms in the initial state (Appendix A.2). Rotation equivariance is not encoded in the architecture but is handled by data augmentation: each training pair \((x(t),x(t+))\) is acted upon by a random rotation matrix \(R\) to form \((Rx(t),Rx(t+))\) in each iteration.

## 5 Training objective

The model is trained in two stages: (i) _likelihood training_, the model is trained via maximum likelihood on pairs of states from the trajectories in the dataset. Let \(k\) index training pairs, such that \(\{(x^{(k)}(t),x^{(k)}(t+))\}_{k=1}^{K}\) represents all pairs of states at times \(\) apart in \(\). We optimise:

\[_{}():=_{k=1}^{K} p_{} (x^{(k)}(t+)|x^{(k)}(t)).\] (14)

(ii) _acceptance training_, the model is fine-tuned to maximise the probability of MH acceptance. Let \(x^{(k)}(t)\) be sampled uniformly from \(\). Then, we use the model to sample \(_{}^{(k)}(t+) p_{}(\,\,|x^{(k)}(t))\) using Equation (3). We use this to optimise the acceptance probability in Equation (6) with respect to \(\). Let \(r_{}(X,)\) denote the model-dependent term in the acceptance ratio in Equation (6):

\[r_{}(X,):=}()p_{}(X ^{p})}{_{}(X)p_{}( X^{p})}.\] (15)

The acceptance objective is then given by:

\[_{}():=_{k=1}^{K} r_{} (x^{(k)}(t),_{}^{(k)}(t+)).\] (16)

Training to maximise the acceptance probability can lead to the model proposing changes that are too small: if \(_{}^{(k)}(t+)=x^{(k)}(t)\), then all proposals will be accepted. To mitigate this, during acceptance training, we use an objective which is a weighted average of \(_{}()\), \(_{}()\) and a Monte Carlo estimate of the average differential entropy,

\[_{}():=-_{k=1}^{K} p_{} (_{}^{(k)}(t+)|x^{(k)}(t)).\] (17)

## 6 Experiments

We evaluate Timewarp on small peptide systems. To compare with MD, we focus on the slowest transitions between metastable states, as these are the most difficult to traverse. To find these, we use _time-lagged independent component analysis_ (TICA) , a linear dimensionality reduction technique that maximises the autocorrelation of the transformed coordinates. The slowest components, TIC 0 and TIC 1, are of particular interest. To measure the speed-up achieved by Timewarp, we compute the _effective sample size_ per second of wall-clock time (ESS/s) for the TICA components. The ESS/s is given by

\[=}}{t_{}}=}(1+2_{=1}^{}_{})},\] (18)where \(M\) is the chain length, \(M_{}\) is the effective number of samples, \(t_{}\) is the sampling wall-clock time, and \(_{}\) is the autocorrelation for the lag time \(\). The speed-up factor is defined as the ESS/s achieved by Timewarp divided by the ESS/s achieved by MD. Additional experiments and results can be found in Appendix B. We train three flow models on three datasets: (i) \(AD\), consisting of simulations of alanine dipeptide, (ii) \(2AA\), with peptides with 2 amino acids, and (iii) \(4AA\), with peptides with 4 amino acids. All datasets are created with MD simulations performed with the same parameters (see Appendix E). For 2AA and 4AA, we train on a randomly selected trainset of short trajectories (\(50=10^{8}\) steps), and evaluate on unseen test peptides. The relative frequencies of the amino acids in 2AA and 4AA are similar across the splits. For 4AA, the training set consists of about \(1\%\) of the total number of possible tetrapeptides (\(20^{}\)), making the generalisation task significantly more difficult than for 2AA. For more details see Table 2 in Appendix E.

Alanine dipeptide (AD)We first investigate alanine dipeptide, a small (22 atoms) single peptide molecule. We train Timewarp on AD as described in Section 5 and sample new states using Algorithm 1 for a chain length of 10 million, accepting roughly \(2\%\) of the proposals. In Figure 3a we visualise the samples using a _Ramachandran plot_, which shows the distribution of the backbone dihedral angles \(\) and \(\). Each mode in the plot represents a metastable state. We see that the Timewarp samples closely match MD, visiting all the metastable states with the correct relative weights. In Figure 3b we plot the free energy (_i.e._, the relative log probability) of the \(\) and \(\) angles, again showing close agreement. The roughness in the plot is due to some regions of state space having very few samples. In Figure 3c we show, for an initial state \(x(t)\), the conditional distribution of MD obtained by integrating Equation (2), \((x(t+)|x(t))\), compared with the model \(p_{}(x(t+)|x(t))\), demonstrating close agreement. Finally, Figure 3d shows the time-evolution of the \(\) angle for MD and Timewarp. Timewarp exhibits significantly more transitions between the metastable states than MD. As a result, the autocorrelation along the \(\) angle decays much faster in terms of wall-clock time, resulting in a \( 7\) speed-up in terms of ESS/s compared to MD (see Appendix B.4).

Dipeptides (2AA)Next, we demonstrate transferability on dipeptides in 2AA. After training on the train dipeptides, we deploy Timewarp with Algorithm 1 on the test dipeptides for a chain length of 20 million. Timewarp achieves acceptance probabilities between \(0.03\%\) and \(2\%\) and explores all metastable states (Appendix B.1). The results are shown for the dipeptides QW and HT in Figure 3ef, showing close agreement between Timewarp and long MD chains (1 \(\)s = \(2 10^{9}\) steps). For these dipeptides, Timewarp achieves ESS/s speed-up factors over MD of 5 and 33 respectively (Appendix B.4). In Figure 4, Left, we show the speed-up factors for Timewarp verses MD for each of the \(100\) test dipeptides. Timewarp provides a median speed-up factor of about five across these peptides. In addition, we generate samples with the Timewarp model _without_ the MH correction as detailed in Section 3.5. We sample \(100\) parallel chains for only \(10000\) steps starting from the same

Figure 3: _Left half:_ **Alanine dipeptide experiments.** (a) Ramachandran plots for MD and Timewarp samples generated according to Algorithm 1. (b) Free energy comparison for the two dihedral angles \(\) and \(\). (c) Ramachandran plots for the conditional distribution of MD compared with the Timewarp model. Red cross denotes initial state. (d) Time dependence of the \(\) dihedral angle of MD and the Markov chain generated with the Timewarp model. _Right half:_ **Experiments on 2AA test dipeptides QW (top row) and HT (bottom row). (e) TICA plots for a long MD chain and samples generated with the Timewarp MCMC algorithm (Algorithm 1). (f) Free energy comparison for the MD trajectory, Timewarp MCMC (Algorithm 1), and Timewarp exploration (Algorithm 2).

initial state for each test peptide. For each peptide we select _only one_ of these chains that finds all meta-stable states for evaluations. As before, we compute the ESS/s to compare with MD, showing a median speedup factor of \( 600\) (Figure 3(c)). Note that the actual speedup when using all the chains sampled in parallel will be much larger. Timewarp exploration leads to free energy estimates that are qualitatively similar to MD, but less accurate than Timewarp MCMC (Figure 2(f)).

Tetrapeptides (4AA)Finally, we study the more challenging 4AA dataset. After training on the trainset, we sample \(20\) million Markov chain states for each test tetrapeptide using Algorithm 1 and compare with long MD trajectories (\(1\)s). In contrast to the simpler dipeptides, both Timewarp MCMC and the long MD trajectories miss some metastable states. However, Timewarp in exploration mode (Algorithm 2) can be used as a validation tool to quickly verify exploration of the whole state space. Figure 4(a) shows that metastable states unexplored by MD and Timewarp MCMC can be found by the Timewarp exploration algorithm. We carefully confirm the physical validity of these discovered states by running shorter MD trajectories in their vicinity (see Appendix B.5), to ensure that they are not simply artefacts invented by the model. As with 2AA, we again report the speedup factors for Timewarp relative to MD in Figure 3(b),d. Although Timewarp MCMC fails to speed up sampling for most tetrapeptides, Timewarp _exploration_ shows a median speedup factor of \( 50\). For 8 test tetrapeptides, MD fails to explore all metastable states, whereas Timewarp succeeds -- these are marked in green. For 10 tetrapeptides, Timewarp MCMC fails to find all metastable states found by MD -- these are marked in grey. Figure 4(b) shows that when Timewarp MCMC discovers all metastable states, its free energy estimates match those of MD very well. However, it sometimes

Figure 4: Speed-up factors in terms of ESS/s ratios for the slowest TICA component for the Timewarp MCMC and exploration algorithms, compared to MD. The dashed red line shows a speed-up factor of one. Gray areas depict peptides where Timewarp fails to explore all meta-stable states within \(20\) million steps, but MD does. Green areas depict peptides where MD fails to find all metastable states, but Timewarp does. (a), (c) Speed-up for the Timewarp MCMC algorithm (Algorithm 1) on test dipeptides (2AA) and tetrapeptides (4AA), respectively. (b), (d) Speed-up for the Timewarp exploration algorithm (Algorithm 2) on test dipeptides (2AA) and tetrapeptides (4AA), respectively.

Figure 5: Experiments on 4AA test tetrapeptides SAEL, CTSA and LPEM (top, middle and bottom rows respectively). Samples were generated via MD, Timewarp exploration (Algorithm 2), and Timewarp MCMC (Algorithm 1). (a) TICA plots of samples. (b) Free energies along the first two TICA components. (c) Potential energy distribution.

misses metastable states leading to poor free energy estimates in those regions. Figure 5c shows that Timewarp MCMC also leads to a potential energy distribution that matches MD very closely. In contrast, Timewarp exploration discovers all metastable states (even ones that MD misses), but has less accurate free energy plots. It also has a potential energy distribution that is slightly too high relative to MD and Timewarp MCMC.

## 7 Limitations / Future work

The Timewarp MCMC algorithm generates low acceptance probabilities (\(<1\%\)) for most peptides (see Appendix B.1). However, this is not a limitation in itself. In general, a larger proposal timestep \(\) yields smaller acceptance rates as the prediction problem becomes more difficult. However, due to Algorithm 1, we can evaluate multiple samples in parallel at nearly no additional costs. As a result, a lower acceptance rate, when coupled with a larger timestep \(\), is often a favorable trade-off. While we speed-up only roughly a third of the 4AA peptides when using the MH correction, beating MD in wall-clock time on unseen peptides in the all-atom representation is a challenging task which has not been demonstrated by ML methods before. Furthermore, one could consider targeting systems using a semi-empirical force field instead of a classical one. Given that Timewarp requires considerably fewer energy evaluations than MD simulations, one can anticipate a more substantial acceleration in this context.

Although MD and Timewarp MCMC fail to find some metastable states that were found by Timewarp exploration, we refrained from running MD and Timewarp MCMC longer due to the high computational cost (Appendix F). Timewarp generates fewer samples compared to traditional MD simulations within the same timeframe. Consequently, this scarcity of samples becomes even more pronounced in transition states, which makes Timewarp difficult to apply to chemical reactions.

Timewarp could be integrated with other enhanced sampling methods, like parallel tempering or transition path sampling. In the case of parallel tempering, the effective integration requires the training of the Timewarp model across multiple temperatures, which then allows to sample all the replicas with Timewarp instead of MD. We could also alternate Timewarp proposals with learned updates to collective variables, like dihedral angles. These combined steps would still allow unbiased sampling from the target distribution .

Moreover, we only studied small peptide systems in this work. Scaling Timewarp to larger systems remains a topic for future research, and there are several promising avenues to consider. One approach is to explore different network architectures, potentially capturing all the symmetries inherent in the system. Another option is to study coarse-grained structures instead of all-atom representations, to reduce the dimensionality of the problem.

## 8 Conclusion

We presented Timewarp, a transferable enhanced sampling method which uses deep networks to propose large conformational changes when simulating molecular systems. We showed that Timewarp used with an MH correction can accelerate asymptotically unbiased sampling on many unseen dipeptides, allowing faster computation of equilibrium expectation values. Although this acceleration was only possible for a minority of the _tetrapeptides_ we considered, we showed that Timewarp used _without_ the MH correction explores the metastable states of both dipeptides and tetrapeptides much faster than standard MD, and we verify the metastable states discovered are physically meaningful. This provides a promising method to quickly validate if MD simulations have visited all metastable states. Although further work needs to be done to scale Timewarp to larger, more interesting biomolecules, this work clearly demonstrates the ability of deep learning algorithms to leverage transferability to accelerate the MD sampling problem.