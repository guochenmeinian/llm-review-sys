# Forgetting, Ignorance or Myopia: Revisiting Key Challenges in Online Continual Learning

Xinrui Wang\({}^{1,2}\)  Chuanxing Geng\({}^{1,2}\)  Wenhai Wan\({}^{3}\)  Shao-yuan Li\({}^{1,2}\)  Songcan Chen\({}^{1,2}\)

\({}^{1}\)College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics

\({}^{2}\)MIIT Key Laboratory of Pattern Analysis and Machine Intelligence

\({}^{3}\) School of Computer Science and Technology, Huazhong University of Science and Technology

Corresponding author. Code link: https://github.com/wxr99/Forgetting-Ignorance-or-Myopia-Revisiting-Key-Challenges-in-Online-Continual-Learning

###### Abstract

Online continual learning (OCL) requires the models to learn from constant, endless streams of data. While significant efforts have been made in this field, most were focused on mitigating the _catastrophic forgetting_ issue to achieve better classification ability, at the cost of a much heavier training workload. They overlooked that in real-world scenarios, e.g., in high-speed data stream environments, data do not pause to accommodate slow models. In this paper, we emphasize that _model throughput_- defined as the maximum number of training samples that a model can process within a unit of time - is equally important. It directly limits how much data a model can utilize and presents a challenging dilemma for current methods. With this understanding, we revisit key challenges in OCL from both empirical and theoretical perspectives, highlighting two critical issues beyond the well-documented catastrophic forgetting: (i) Model's ignorance: the single-pass nature of OCL challenges models to learn effective features within constrained training time and storage capacity, leading to a trade-off between effective learning and model throughput; (ii) Model's myopia: the local learning nature of OCL on the current task leads the model to adopt overly simplified, task-specific features and _excessively sparse classifier_, resulting in the gap between the optimal solution for the current task and the global objective. To tackle these issues, we propose the Non-sparse Classifier Evolution framework (NsCE) to facilitate effective global discriminative feature learning with minimal time cost. NsCE integrates non-sparse maximum separation regularization and targeted experience replay techniques with the help of pre-trained models, enabling rapid acquisition of new globally discriminative features. Extensive experiments demonstrate the substantial improvements of our framework in performance, throughput and real-world practicality.

## 1 Introduction

Online continual learning (OCL) is the learning paradigm that enables models to learn continuously from a dynamic data stream \(=\{_{1},_{2},,_{t},\}\), where \(_{t}=\{x_{i},y_{i}\}_{i=1}^{N_{t}}\) is the dataset of task \(t\) sampled from distribution \(_{t}\). Existing OCL methods are designed to promote effective learning by mitigating catastrophic forgetting and improving model plasticity through various techniques like gradient regularization, contrastive learning, experience replay and knowledge distillation. However, these methods often fail to consider the assessment of model throughput, an essential metric especially crucial for managing data streams with varying arrival speeds.

According to , a _model's throughput_ is defined as the maximum number of training sample data that a model can process within a unit of time. When the training speed of the model is slower than the speed that data stream arrives, the model is forced to discard some training data which wastes dataand harms model's performance. Furthermore, maintaining a real-time accessible memory buffer, as required by current OCL methods, also proves challenging in real-world applications[38; 42]. Under these practical concerns, a reexamination of the challenges in OCL from both empirical and theoretical perspectives is in urgent need. In this paper, we reveal that **model's ignorance** caused by single pass nature of data streams and **model's myopia** resulting from the continuous arrival of tasks may be more impactful than the well-documented catastrophic forgetting phenomenon.

**Model's ignorance.** Our first focus lies in whether models can acquire sufficient discriminative features within the limited time during the single-pass training. To independently study this challenge and avoid other issues like catastrophic forgetting and task interference or collision caused by the continuous arrival of tasks, we introduce a relaxed setting for streaming data called **single task setting.** The data stream is sampled from a unified task, allowing data from any category to appear at any moment with equal probability. Under this controlled setting, we have observed that, 1) models trained from scratch under-perform significantly compared to expectations. The single-pass nature of OCL inhibits the model's ability to fully harness the semantic information from the data stream, a phenomenon we term as **model's ignorance**; 2) It is also noticed that existing strategies like contrastive learning and knowledge distillation to mitigate this issue significantly increase the training time of the model, consequently reducing its throughput.

**Model's myopia.** Even if models can quickly achieve decent performance on individual tasks, performance degradation remains a persistent issue for existing OCL models. Previous studies often attribute this to the model forgetting previously learned information. But in this paper, we propose a different perspective. We observed that, in OCL training, the model initially acquires perfect classification accuracy for a specific class, e.g., "car". However, there arrives a critical moment when the model becomes completely confused, mistakenly identifying a "car" as a newly introduced class (e.g., "truck"). We believe this confusion cannot solely be attributed to the model forgetting previous learned knowledge, as _the forgetting process should be gradual rather than abrupt_. Besides, as training progresses, the parameters in the final layer of the model's classifier become increasingly sparse. The emergence of such an _excessively sparse classifier_ causes the model to focus on few discriminative features specialized for the current task. When the model is exposed to only a limited range of categories, this narrow focus on the current task restricts its capability to acquire features with broader discriminative power. We term this limitation **model's myopia**.

In addition to empirical verification, we adopt the Pac-Bayes theorem to provide insights into the dilemma between effective learning and model throughput. The upper bound of expected risk summation can be segmented into three terms correlated to empirical risk, model throughput and task divergence respectively. Our theory places a particular emphasis on model throughput, which has been long overlooked in the context of OCL. To the best of our knowledge, this is the first attempt to provide theoretical insights into the relationship between model throughput and performance in this area. Given that model needs to adapt to varying data flow rates to ensure its performance, this factor also warrants recognition in theoretical discussions. Plus, interestingly, model's myopia and forgetting can be perceived as two complementary aspects of the proposed task divergence term.

Built on the above analysis, we propose a new OCL framework called Non-sparse Classifier Evolution (NsCE), which capitalizes on the benefits of pre-trained initialization. This framework introduces a non-sparse regularization term and employs a maximum separation criterion between classes, aimed at mitigating the issue of parameter sparsity while maintaining the model's ability in differentiating classes. As a regularization applied uniformly across tasks, it helps to minimize the differences in the distributions of model parameters between tasks. Furthermore, to enhance the model's throughput and diminish the reliance on a real-time memory buffer, we propose an efficient selective replay mechanism. By selectively replaying past experiences, we specifically target data from classes that the model frequently misidentifies and implement the targeted binary classification tasks on them during experience replay. This approach not only enhances model's throughput but also boosts its performance in handling high-speed data streams. Extensive experiments demonstrate that these techniques are crucial for deploying a OCL model where high performance, real-world practicality and computational efficiency are all paramount.

## 2 Ignorance: Trade-off between Effective Learning and Model Throughput

In OCL, the most extensively studied challenge is the issue of catastrophic forgetting when learning new tasks. However, the poor performance of existing OCL methods on some large datasets inevitably leads us to question whether, before considering the issue of forgetting, the model can truly acquire sufficient discriminative features and subsequent classification capabilities. To isolate the challenge brought by the continual arrival of tasks and concentrate on model's behavior on the single pass data stream, we first construct a data stream setting called **single task setting**. As displayed in Figure1, we consolidate classes from multiple tasks into a single unified task, where samples from different classes are introduced at random timestamps with equal probability. It ensures a stable and balanced data stream, mitigating concerns about catastrophic forgetting or class imbalance.

**Unsatisfactory model performance.** Under this controlled setup, a simple supervised model is optimized using cross-entropy loss \(_{ce}=-_{i=1}^{N}_{c=1}^{C}y_{i,c}((f_{c}(x_{i})))\) where \(()\) represents the classifier, \(f()\) denotes the feature extractor. We implemented common OCL strategies such as experience replay, contrastive learning and knowledge distillation to make a comparison. As illustrated in Figure 1, models trained from scratch fail to reach satisfactory performance in single-pass training scenarios, unlike those benefiting from pre-trained initialization. On CIFAR100, model's average accuracy remains below 10% even without any inter-task interference. Single-pass nature of OCL prevents the model from fully leveraging the semantic information from the data stream, which we refer as **model's ignorance**. Meanwhile, as we integrate additional techniques like experience replay, contrastive learning, and distillation chains, the model's accuracy progressively improves, from 10% to 20%. Under such circumstances, leveraging additional prior knowledge seems to be the only viable solution. Empirical evidence also supports this viewpoint, as displayed by the performance when using pre-trained initialization in Figure1. While the selection of an appropriate pre-trained model is beyond the primary focus of this paper, we investigate the effects of various pre-training methods on different OCL downstream tasks in Appendix C.3.

Figure 1: Real-time accuracy of OCL models trained under the standard cross entropy loss \(L_{ce}\) both with and without pre-trained models (pre-trained on ImageNet) under our designed **single task setting** and the impact of some commonly used strategies. Results on additional datasets, influence of different pre-trained models (pre-trained on different datasets, using different backbones and different pre-train tasks) and implementation details are provided in Appendix C.3.

Figure 2: **Left:** Throughput of the model trained using vanilla cross-entropy, experience replay, supervised contrastive replay and distillation chain. **Right:** Performance(\(A_{AUC}\): Area Under the Curve of Accuracy) and running time of the above strategies on CIFAR10. “_CE++_” denotes that we compute and perform extra gradient descent per time step to match the delay of the compared-against strategies. All experiments are conducted under **single task setting**.

**Decreased model throughput.** Despite the partial effectiveness of commonly used strategies in mitigating **model's ignorance**, they inevitably extend the training time for the same amount of data and increase the demands on the memory buffer's real-time accessibility. As shown in Figure 2(**Left**), the integration of additional techniques consistently increases the training time. But in the context of OCL, this extended training duration leads to processing fewer data units per unit of time, resulting in lower _model throughput_. Given that the volume of training data is widely recognized as a crucial factor in determining model performance, this highlights a significant flaw in the current evaluation of OCL models. When the data stream's flow rate exceeds the training speed, model throughput and effective learning emerge as two interrelated factors subject to trade-offs.

More surprisingly, our findings suggest that these strategies are actually no more effective than simply training the model multiple times (_CE++_) on the same data to offset the delays caused by these methods. As illustrated in Figure 2, when handling data at the same flow rate, _CE++_ can achieve comparable model performance through the application of experience replay, contrastive techniques and distillation chains. Furthermore, the challenges of maintaining a continuously accessible real-time memory buffer, caused by issues like network connectivity and privacy protection, are frequently overlooked, adding further obstacles to the effective implementation of these strategies.

## 3 Myopia: Key Factor for Performance Degradation

In addition to issues of **model's ignorance** and decreased model throughput, we recognize that while pre-trained initialization allows the model to quickly classify training data, relying solely on this initialization does not ensure satisfactory overall performance. Performance degradation continues to pose challenges in OCL . Most previous studies attribute it to the phenomenon of catastrophic forgetting, which is caused by interference between current task and previously learned knowledge . Some studies also suggest it is due to the model learning some trivial features. To clarify this issue, we conduct a comprehensive monitoring of the model's predictions by visualizing the predicting confusion matrix throughout the entire training process. Specifically, the model is trained by vanilla cross-entropy loss (Eq.1), without employing any other techniques.

\[_{ce}=-_{t=1}^{T}_{i=1}^{N_{t}}_{c=1}^{C_{t}}y_{i}^{t,c} (^{c}(f(x_{i}^{t}))),(x_{i}^{t},y_{i}^{t})_{t}.\] (1)

We separately assess the discrimination ability of the classifier and feature extractor by evaluating the model's performance using a softmax classifier and an online updating NCM (Nearest Class Mean) classifier which are both very common approaches for prediction in OCL. For the NCM classifier, we compute a dynamic class mean prototype for each class using Equation 2 and apply a momentum update with the parameter \(\). This update calculates the new class mean prototype \(_{c}^{new}\) based on the \(n_{c}\) data points from class \(c\) in the current data stream and the previous prototypes \(_{c}^{old}\). Then, class label of new data can be assigned to the most similar prototype.

\[_{c}^{new}=(1-)_{c}^{old}+}_{i}f(x_{i}) \{y_{i}=c\},y^{*}=*{arg\,min}_{c=1 C}||f(x)- _{c}||.\] (2)

Figure 3: Normalized confusion matrix of NCM classifier (green) and softmax classifier (CIFAR10) (blue) with ImageNet supervised pre-trained initialization. Due to space limitations, we present a partial training process in the main text. Comprehensive training process is in AppendixE.

Although pre-trained initialization provides the model with a broader perspective and prior knowledge, performance degradation still occurs with the introduction of new tasks. As illustrated in Figure 3, the precision for the class 'car' dramatically drops from \(0.95\) to nearly \(0\) during the training of the fifth task. When closer examining the classes that the model confuses during training, such as 'car' and 'cat', we suppose that distinguishing between them becomes challenging when highly discriminative features from past tasks reappear in new classes. For example, 'car' and 'truck' share similar shapes and backgrounds, while 'cat' and 'dog' share similar textures, making differentiation difficult. Different from the well-documented catastrophic forgetting, we propose a different perspective that the confusion arises since the discriminative features or knowledge acquired from previous tasks may not be helpful in distinguishing these classes from some new classes in future tasks from the outset. In other words, the previously learned representations may not capture the essential characteristics necessary for effectively differentiating these classes with new classes and this is something perfectly normal even for us as humans. During the training process, the model naturally focuses on features and discriminant criteria that are more important for the current task. The independent arrival of tasks results in such **a myopic model**, which is the key factor in the decline of OCL performance.

Plus, we observed that softmax classifiers are more frequently susceptible to performance degradation compared to NCM classifiers. As depicted in Figure 3, during the fourth and fifth tasks, predictions made by the softmax classifier are more biased towards classes in the current task compared to those made by the NCM classifier. Meanwhile, although the features extracted by the model are initially separable, a biased classifier soon leads to significant confusion between classes, causing the features to lose discriminative power over time. Such phenomenons is better displayed by the complete visualization in Figure15 (AppednikE).

To better analyze the reasons behind model's performance degradation and verify our suppose on **model's myopia**, we evaluate and subsequently visualize the sparsity as \(1/s()\) and mean \(m()\) of the parameters in the final fully connected layer of the classifier for each task, as detailed in Eq.3. We represent this final fully connected layer by a matrix \(W^{d C}\), where \(d\) represents the feature dimension and \(C\) denotes the number of classes. The variable \(w^{c}\) refers to the \(c\)-th column vector extracted from \(W\), and \(w^{c}^{d}\).

\[m(w)=^{2}+w_{2}^{2}++w_{d}^{2}};s(w)=|+|w_{2}|+ +|w_{d}|)/d}{(|w_{1}|,|w_{2}|,,|w_{d}|)}\] (3)

As depicted in Figure 4, the mean and sparsity of parameters in the classifier continuously decrease when each new task is introduced. Prior studies in continual learning  have linked this pronounced prediction bias towards recent tasks to the decreasing mean weights for old classes. Interestingly, unlike scenarios involving training from scratch, using a pre-trained initialization prevents the model from arbitrarily classifying class \(0\) as belonging to the current task. Moreover, although the mean weights for the old classes consistently decline, class confusion only manifests with the arrival of task \(4\). These observations all suggest that the reduction in weights is not solely responsible for the observed bias in the classifier. This leads us to question whether, during training

Figure 4: **Left: averaged weights of the final FC layer for class 0 in CIFAR10. Right: \(s(w)\) (lower \(s(w)\) stands for increasing sparsity) of the final FC layer for \(w^{0}\) corresponds to class 0 in CIFAR10. During the training of task 5, the class confusion occurs as Figure 3 where model classify ”car” as “truck”.**

process, the model's criteria for categorizing become simpler. In other words, the model increasingly focuses solely on a limited set of discriminative features that it deems beneficial for the current task, and this focus is precisely the cause of **model's myopia**. This trend towards simplification is illustrated in Figure 4(**Right**), where there is a noticeable increase in the sparsity of parameters associated with older tasks as new ones are introduced. While relying on few discriminative features is beneficial in traditional supervised learning settings, in OCL, the emergence of such an _excessively sparse classifier_ causes inevitable class confusions across tasks.

## 4 Theoretical Analysis

In addition to the empirical analysis, we try to provide theoretical insights into the OCL problem and illustrate the aforementioned trade-off between adequate feature learning and model throughput. Specifically, we approach the OCL problem from a Pac-Bayes perspective, as outlined in Theorem 4.1. Following the common notations used in Pac-Bayes literature , we define a model space \(\) and a loss function \(:^{+}\), which is bounded by a constant \(K>0\). Here, \(\) represents the whole training set and \(_{t}\) stands for data distribution of task \(t\). In line with the approach described in , we denote a sequence of distributions \((Q_{i})_{i=0..T}\) on \(\), representing the evolution of the model's learning process. Here, \(Q_{i}\) is the distribution of the model parameters after training task \(i\), with \(Q_{0}\) representing the initial parameter distribution and \(T\) indicates the total number of tasks. Meanwhile, we denote the flow rate of the data stream (\(\#\)samples coming from data stream in the unit time) as \(v_{s}\), the model throughput (\(\#\)samples model can train in the unit time) as \(v_{m}\) and \(_{t}\) as the duration time of task \(t\) in the data stream. The sum of expected risks \(\) across different tasks can be written as \(_{t=1}^{T}_{h_{t} Q_{t}}[_{z_{t}_{t}} [(h_{t},z_{t})]]\) and the empirical risk \(}\) is \(_{t=1}^{T}_{j=1}^{m_{t}}_{h_{t} Q_{t}}[(h_{t},z_{t}^{*})]}{m_{t}}\).

**Theorem 4.1**.: _For any distributions \(_{1},...,_{T}\) over \(\), let \(_{t}\) be an iid set with \(m_{t}=(v_{s},v_{m})_{t}\) samples sampled from \(_{t}\) as the dataset of task \(t\), for any \(>0\) and any online predictive sequence \((Q_{0},Q_{1},...,Q_{T})\), the following inequality holds with probability \(1-\):_

\[}+^{T}}{(v_{s},v_{m})_{t}}}_{}\ \ +^{T}(Q_{t}\|Q_{t-1})}{}}_ {}+}_{constant}.\] (4)

It is clear that the upper bound of \(\) can be segmented into three terms, along with a constant related to the task number \(T\). They are identified as empirical risk \(}\), model throughput term \(\), and task divergence term \(\). Among them, the model throughput term \(\) is determined by the amount of data accessible to the model and this is directly influenced by the model's throughput \(v_{m}\) when data stream's flow rate \(v_{s}\) exceeds \(v_{m}\). However, achieving a lower empirical risk \(}\) by data augmentations, knowledge distillation or training the model for multiple times typically requires more training time and consequently reducing model throughput \(v_{m}\), which theoretically explains the trade-off we mentioned in Section2 between \(}\) and \(\).

When examining the task divergence term \(\) more closely, we see that nearly all OCL methods aiming at addressing forgetting attempt to minimize the deviation from the parameter distribution of previous tasks by adjusting the current model parameter distribution. Our proposed concept of **model's myopia** offers a fresh perspective. By aligning the distribution of current model with future ones, the divergence term \(\) can be also reduced. It leads us to considering the use of structural constraints (e.g. non-sparse regularization) or pre-trained initialization as promising strategies to enhance model performance. Meanwhile, it's important to acknowledge that our analysis has limitations; the bound discussed is intended to illustrate the sum of generalization risk for each individual task and can not represent a global expectation. We provide detailed discussions and proof in AppendixB.

## 5 Method

After conducting a series of analysis on the key challenges in OCL, in this section, we provide the NsCE framework to tackle these issues based on the utilization of pre-trained initialization. Our goal is not only to reduce the risks of model ignorance and myopia but also to enhance the throughput of OCL models. We aim to accelerate training speeds to keep pace with data stream progress and reduce the dependence of existing methods on real-time accessible memory buffers.

**Non-sparse regularization.** Unlike some previous methods that aim to acquire task-specific features capable of generalization, in this study, we acknowledge the unrealistic expectation of obtaining a model with absolute discriminative ability within a limited scope of classes, even with the rich prior knowledge provided by a pre-trained model. Instead, our focus lies in ensuring the diversity of discriminant features during training and enabling the model to swiftly develop the ability to differentiate between categories from different tasks. As posited in the previous section, in the context of OCL, contrary to traditional settings where a sparse classifier is often considered desirable for achieving high classification performance, the overly sparse parameters can cause the model to focus solely on a limited set of highly discriminative features, increasing the risk of **model's myopia**. To mitigate this issue, we propose a straightforward idea of constraining the sparsity of the final fully connected layer of (softmax classifier) of the model. Our goal is to ensure that the model maintains a diverse set of discriminative features during training, allowing it to effectively handle different tasks without being overly biased towards specific features. Meanwhile, it helps reduce the divergence of model distribution across tasks. In specific implementation, considering that the \(()\) function is easily affected by a small number of outliers in the parameters, we opt to replace it with the \(l_{2}\) norm as a more robust alternative in our sparsity regularization:

\[_{s}=-_{c=1}^{C}^{c}|+|w_{2}^{c}|++|w_{d}^{c }|)/d}{^{c}{}^{2}+w_{2}^{c}{}^{2}++w_{d}^{c}{}^{2}}}.\] (5)

**Maximum separation.** While a smooth classifier can help to mitigate the model's myopia, it hinders the model's ability to rapidly perform classification in the current task. Moreover, in OCL, it is also hard to have simultaneous access to data from all categories, especially when there are restrictions on the use of memory buffers. This leads to severe class imbalance during the learning process, which is a well-recognized challenge in the context of continual learning. Thus, we draw inspiration from the famous Neural Collapse  and Maximum Class Separation criterion. It also serves as a structure constraints on model parameters to minimize the model distribution divergence across the tasks. For learned representations from different categories \(\{f(x_{1}),f(x_{2}), f(x_{C_{t}})\}\), their cosine similarity should satisfy a maximum separation criterion and converge to an ideal simplex equiangular tight frame (ETF), \(_{i,j,i j}(f(x_{i}),f(x_{j}))=--1}\).

\[_{p}=^{2}}_{i,j=1}^{C}( f(x_{i}),f(x_{j}) -p_{ij})^{2},p_{ij}=}{C_{t}-1}_{i,j}--1}\] (6)

where \(_{i,j}\) is Kronecker delta symbol that designates the number \(1\) if \(i=j\) and \(0\) if \(i j\). To address categories not present in the current task, we use the class mean in Eq.2 to replace the representation of the corresponding category. Thus, we can denote our total loss function as:

\[=_{ce}+(_{p}+_{s})\] (7)

**Targeted experience replay.** To enable the model to learn globally discriminative features and correct existing class confusion, we prioritize the categories that the model has previously struggled to distinguish when accessing the memory buffer. During experience replay, we compute a confusion matrix to identify frequently confused categories. To address each group of confused categories, we devise a separate binary classification loss specifically designed to expedite the acquisition of discriminative abilities between these confused classes, as shown in Eq.8.

\[_{b}=-_{i=1}^{||}_{m,n=1}^{C}\{ _{m,n}^{b}>\}[y_{i}^{m}(^{m}(f(x_{i})))+y_{i}^{n} (^{n}(f(x_{i})))],m n.\] (8)

\(^{b}\) represents a normalized confusion matrix and \(_{m,n}^{b}>\) indicates that the proportion of data belonging to class \(m\) being classified as class \(n\) exceeds the threshold \(\). To further enhance model's throughput and diminish the reliance on a real-time memory buffer, we impose limitations on the number of requests allowed to retrieve data from the memory buffer. Compared to traditional experience replay, our way of replay achieves higher model throughput and is more specifically targeted at addressing existing class confusion. For a complete description of the algorithm process, please refer to Algorithm1. Moreover, our findings indicate that when selecting an appropriate pre-trained model, halting gradient back-propagation in the feature extractor often enhances throughput without compromising performance. More discussions are provided in AppendixC.2.2.

[MISSING_PAGE_FAIL:8]

propose provides performance improvements, among which **targeted ER** has the most obvious effect. (2) Constraints on classifier sparsity, as defined by \(_{s}\), prove to be more effective in class incremental scenarios where model's myopia tends to be more pronounced. (3) The maximum separation term \(_{p}\) achieves consistent performance improvements across datasets.

**Sensitivity analysis.** We analyze the impact of the threshold \(\) in targeted experience replay and the coefficient on the non-sparse maximum separate regularization. As depicted in Figure 6, we observe that as the threshold \(\) increases, our proposed NsCE has a relatively lower area under the accuracy curve (\(A_{AUC}\)). This trade-off between performance and efficiency is expected, as higher values of \(\) lead to fewer samples being replayed, resulting in improved model throughput but potentially compromising performance. Furthermore, our approach demonstrates robust outcomes when the coefficient \(\) is not too small, and it basically achieves the best performance when \(=0.01\).

**Classifier sparsity.** We are also very interested in how sparsity would be affected by the proposed NsCE and methods focusing on re-arranged last layer weight updates. After implementing ER-ACE and ER-AML, we found that the phenomenon of parameters rapidly becoming sparse is indeed somewhat mitigated, though not as significantly as with our proposed regularization term \(_{s}\), as illustrated in Figure 6. While incorporating ACE or AML can also boost performance for baselines

Figure 5: The detailed normalized confusion matrix (CIFAR10) evolution of our proposed NsCE framework (memory buffer size is 100 and replay frequency is 1/100).

   & CIFAR10 & CIFAR100 & EuroSat & CLEAR100 & ImageNet \\   & \(M-0.16\) & \(M-0.85\) & \(M-0.16\) & \(M-1k\) & \(M-10k\) \\  & \(Freg-1/100\) & \(Freg-1/100\) & \(Freg-1/100\) & \(Freg-1/100\) & \(Freg-1/100\) \\   vanilla \(_{c}\) w/ ER & 82.6\(\)0.5 & 61.3\(\)0.3 & 58.6\(\)0.08 & 80.1\(\)0.06 & 53.6\(\)0.4 \\ vanilla \(_{c}\) w/ ER \(_{c}\) & 84.5\(\)1.3 & 64.5\(\)0.7 & 62.0\(\)0.4 & 77.6\(\)0.8 & 56.2\(\)0.7 \\ vanilla \(_{c}\) w/ ER \(_{c}\) \& 86.2\(\)0.8 & 66.1\(\)0.4 & 66.9\(\)0.7 & 81.3\(\)1.1 & 59.4\(\)1.1 \\ vanilla \(_{c}\) w/ targeted ER & 87.2\(\)0.9 & 71.9\(\)0.9 & 72.4\(\)0.4 & 83.7\(\)0.6 & 58.2\(\)1.3 \\  NCE & **89.9\(\)0.4** & **74.1\(\)0.7** & **75.7\(\)0.4** & **84.3\(\)0.4** & **64.6\(\)0.7** \\  

Table 3: Ablation study of the proposed NsCE framework.

Figure 6: **Left: Sensitivity analysis on \(\) and \(\). Right: Sparsity (\(1/s(w)\)) of the classifier under different algorithms.**

like ER and SCR. We believe that when ACE and AML nudge the learned representations to be more robust to new future classes, they indirectly decrease the sparsity of the model parameters. For GSA, the sparsity is not affected. But we are not entirely sure whether this part is perfectly embedded or if further tuning would help, as the authors only provide hyperparameters for CIFAR-100. For SS-IL, we did not find its implementation, so it may be left for future works.

## 7 Conclusion

In this study, we conduct a thorough reevaluation of the major challenges in current OCL methods. We delve into the underlying causes of these challenges and the limitation of existing methods. Our analysis highlights two critical limiting factors: **model's ignorance and myopia**, which can have a more significant impact than the widely recognized issue of catastrophic forgetting. Furthermore, we introduce the NsCE framework, which incorporates non-sparse maximum separation regularization and targeted experience replay techniques with a focus on balancing performance, throughput and practicality. Our work aims to provide a fresh perspective and inspire the OCL field to prioritize both model's performance and efficiency in more real-world scenarios.

## 8 Acknowledgments and Disclosure of Funding

This work was supported by the National Science and Technology Major Project 2022ZD0114801, Natural Science Foundation of China (NSFC) (Grant No.62376126), the National Key R&D Program of China (2022ZD0114801), National Natural Science Foundation of China (61906089), Natural Science Foundation of China (NSFC) (Grant No.62106102), Natural Science Foundation of Jiangsu Province (BK20210292), Graduate Research and Practical Innovation Program at Nanjing University of Aeronautics and Astronautics (xcxih20221601).