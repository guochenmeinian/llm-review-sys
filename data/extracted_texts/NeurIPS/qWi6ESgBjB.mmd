# Prune and Repair: Content-Aware Image Retargeting for any Ratio

Feihong Shen\({}^{1,2,4}\)

feihongshen@seu.edu.cn

&Chao Li\({}^{2}\)

llllcho.lc@alibaba-inc.com

&Yifeng Geng\({}^{2}\)

cangyu.gyf@alibaba-inc.com

&Yongjian Deng\({}^{3}\)

yjdeng@bjut.edu.cn

&Hao Chen\({}^{*1,4}\)

haochen303@seu.edu.cn

\({}^{1}\)Southeast University \({}^{2}\)Alibaba Group \({}^{3}\)Beijing University of Technology

\({}^{4}\)Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University), Ministry of Education, China

Corresponding author (haochen303@seu.edu.cn)

###### Abstract

Image retargeting is the task of adjusting the aspect ratio of images to suit different display devices or presentation environments. However, existing retargeting methods often struggle to balance the preservation of key semantics and image quality, resulting in either deformation or loss of important objects, or the introduction of local artifacts such as discontinuous pixels and inconsistent regenerated content. To address these issues, we propose a content-aware retargeting method called PruneRepaint. It incorporates semantic importance for each pixel to guide the identification of regions that need to be pruned or preserved in order to maintain key semantics. Additionally, we introduce an adaptive repainting module that selects image regions for repainting based on the distribution of pruned pixels and the proportion between foreground size and target aspect ratio, thus achieving local smoothness after pruning. By focusing on the content and structure of the foreground, our PruneRepaint approach adaptively avoids key content loss and deformation, while effectively mitigating artifacts with local repainting. We conduct experiments on the public RetargetMe benchmark and demonstrate through objective experimental results and subjective user studies that our method outperforms previous approaches in terms of preserving semantics and aesthetics, as well as better generalization across diverse aspect ratios. Codes will be available at https://github.com/fhshen2022/PruneRepaint.

## 1 Introduction

With the popularity of multi-screen and multi-aspect environments, people's demands for the adaptability and aesthetics of images across different devices are increasing. Consequently, image retargeting , which aims to adjust the aspect ratio to fit various display devices or presentation environments while preserving the key content and maintaining the quality of the images, has distinctive applications yet is understudied.

The core challenge of image retargeting lies in simultaneously 1) preserving the main information and 2) avoiding artifacts such as deformation and distortion on key objects. Intuitive solutions for this task include scaling and cropping. As shown in Figure 1 (b), scaling entirely preserves all contents but results in severe deformation, decreasing aesthetic appeal and image quality, making it difficultto recognize the figures. On the contrary, crop-based methods  introduce no artifacts but often results in the loss of key semantics (see Figure 1 (c)). To relieve these problems, following methods typically use pixel-shifting operators. Noticeable works include seam-carving , which calculates energy using manual operators  to identify seams for deletion. Some other works  further integrate these traditional operators to enhance the generalization to different scenarios. However, as illustrated in Figure 1 (d), without semantics guidance for crucial regions, this line of methods often leads to content loss or distortion on important objects, as well as inconsistent pixels in the foreground.

Regarding the power of deep learning tools, some methods  integrate deep semantic features to guide the deletion or preservation of pixels in traditional pixel-shifting methods. However, these methods fail to differentiate the semantic significance within objects (e.g., face is more important than hair in a person), thus often leading to object distortion when meets oversized objects. Moreover, these methods only focus on foreground regions, typically leading to discontinuous backgrounds and decreased aesthetic appeal. Towards better aesthetics and region consistency, other works  achieve image retargeting from a generative perspective with Generative Adversarial Networks (GANs) . These methods often implicitly learn the semantic distribution of images to regenerate retargeted images. Due to the absence of explicit semantic prior and the weakness of GANs in capturing the global data distribution , these methods will generate all regions without selection, resulting in inconsistent generation of key objects (Figure 1 (e)).

To tackle the issues mentioned above, we present a content-aware retargeting model that can maintain the essential semantics, their appearance consistency, and aesthetics while being adaptable to any aspect ratio. To alleviate semantic loss, we introduce content-aware seam-carving (CSC), which incorporates hierarchical semantic information induced from semantic/spatial saliency to differentiate the energy to perform scene-level (i.e., background and foreground) and object-level (i.e., components in the foreground) pruning, thereby maximizing the preservation of key objects and their discriminative semantic elements. To mitigate artifacts introduced by pixel removal, we further propose an adaptive repainting (AR) method based on diffusion models, consisting of an Adaptive Repainting Region Determination (ARRD) module and an Image-guided Repainting (IR) module.

The two modules work together to adaptively repaint scenes with varying foreground sizes. The ARDD module is responsible for determining which regions of the image need to be repainted. It does this by identifying abrupt pixels that have a high density of removed surrounding pixels. Then, it considers the foreground size and desired ratio to determine inpainting or outpainting. This approach ensures that important objects are preserved in the image even if they exceed the expected size, resulting in a flexible method that can handle images with any aspect ratio. Subsequently, IR refines the repainting process by using the original image as a reference to restore and repaint these regions. Compared to previous global generation methods  without maintaining foreground consistency with the original image, our approach selectively regenerates the abrupt pixels, preserving the foreground consistency and local smoothness effectively.

Our contributions can be summarized as follows:

1) We introduce a content-aware image retargeting framework that is applicable to any aspect ratio. By incorporating content-aware seam-carving, our approach enables pixel pruning with hierarchical semantic differentiation.

Figure 1: An example to show bad cases such as deformation, content loss, discontinuity in lines, inconsistent results and a good case.

2) We propose an adaptive repainting method that utilizes image-conditioned stable diffusion models. This method dynamically determines whether to inpaint or outpaint based on different aspect ratios, leading to local smoothness and aesthetically pleasing outcomes.

3) Through extensive experiments involving various aspect ratios, our method demonstrates superior performance compared to other approaches in terms of both objective and subjective evaluations. It excels in preserving object completeness, coherence, and generalization.

## 2 Related Work

### Image Retargeting

Existing image retargeting methods revolve around two main themes: preserving the main information and avoiding artifacts. Early image retargeting methods often fail to balance these two aspects. For instance, scaling attempts to maintain overall elements by uniformly removing pixels but struggles with significant changes in aspect ratios, resulting in severe deformation of key objects. Cropping-based methods [38; 29] chooses the best window of target size from the original image, which preserves the structure but leads to the loss of crucial information outside the window. Seam-carving  attempts to balance content completeness and quality by calculating energy maps to remove lower-energy seams. However, due to the lack of semantics, when the background is complex, this method usually result in the distortion in foreground.

The rise of deep learning  has introduced semantic information to image retargeting. DeepIR  adopts pretrained VGG  to explicitly extract semantic information and retargets the image from a coarse semantic space to fine pixel space. SmartScale  utilizes existing object detection model to assist seam-carving. However, these methods ignore the semantic differences within important regions, resulting in deformation within the oversized regions. In addition, neglecting the background can lead to discontinuities in background pixels, thereby affecting the aesthetic appeal of the image. For aesthetics and local smoothness, some methods adopt Generative Adversarial Networks (GANs)  to generate the retargeted results. InGAN  and SinGAN  divide the image into patches and learn the internal distribution of patches, destroying the overall semantics. To training a GAN without partitioning the image, MRGAN  adopts multi-operator to generate a paired dataset, which is constrained by the handcraft, MCGAN  introduces mask to highlight importance areas. However, due to the limitations of implicit semantic expression, these methods preserve the global semantics but destroy the details, resulting in inconsistent appearance with the original image.

In contrast, our method is content-aware for selective pruning and adaptive repainting. It is able to maintain the key semantics and appearance while ensuring local smoothness and aesthetics, and it demonstrates stronger generalization for different aspect ratios.

### Diffusion Models for Image Generation

Nowadays, diffusion models [11; 33; 26] have become the mainstream models for generative tasks due to their powerful ability to model complex distributions. Stable Diffusion  is the first generative model based on latent diffusion models. The progressively denoising diffusion in latent space significantly enhances the efficiency, stability, realism, and controllability of image generation. Subsequently, various improvements  and variations [37; 36] of stable diffusion models have been proposed. For instance, SDXL  adopts a larger backbone and finetunes it using a complicated dataset with multiple aspect ratios to improve its versatility.

However, such text-to-image (T2I) models are hard to generate complex scenes and achieve more detailed control, as a significant amount of text control is labor-intensive and the T2I models struggle to accurately comprehend numerous and complex text prompts. To tackle this issue, other conditioning methods [37; 36] are proposed. The introduction of ControlNet  expands the applications of Stable Diffusion with different image-based conditional control, including depth images, mask images, canny images, etc. IP-Adapter , a newly proposed image-to-image (I2I) model, introduces image prompts to control condition with an decoupled cross-attention adapter branch, highly enhancing the controllability of the generative image.

In our task, we introduce image-guided local reppainting into image retargeting, which enjoys the advantage of more precise semantic preservation and more controllable local generation compared to global regeneration.

## 3 Method

### Overall Architecture

The overall architecture is illustrated in Figure 2. Specifically, a saliency detection model is adopted to obtain the semantic saliency, which will further be combined with the initial energy map to guide the determination of pruning pixels, making the pruning content-aware. After that, an adaptive repainting region determination module is applied to identify the abrupt pixels and determine the repainting regions, and an image-guided stable repainting module is further used to repaint them to output the final retargeted image.

### Content-aware Seam-carving

Seam-carving is a typical pixel-shifting retargeting method, which calculates the energy of image and prioritizes deleting the seams with lower energy. For simplicity, we only discuss the scenario of deleting vertical seams in this section. The energy function in seam-carving is formulated as follows:

\[Energy(I(x,y))=|I(x,y)|+|I(x,y)|,\] (1)

where \(I(x,y)\) denotes the pixel at position (x,y) in the image. Seam-carving is often criticized for its lack of semantic information, which can lead to the distortion of key objects. To address this issue, we propose content-aware seam-carving (CSC), which incorporates semantic and spatial saliency priors. As illustrated by the blue region in Figure 2, the energy function of semantic seam-carving is formulated as follows:

\[Energy(I(x,y))=|I(x,y)|+|I(x,y)|+S(x,y)(1-|}{W}),\] (2)

where \(\) denotes element-wise multiplication, \(S(x,y)\) represents the saliency value at position (x,y), \(x_{0}\) is the x-coordinate of the saliency centroid achieved by averaging the x-coordinates of all salient

Figure 2: The overall architecture of our proposed PruneRepaint. The input consists of a RGB image and a target ratio. The saliency map, obtained by saliency detection, is further introduced into content-aware seam-carving module for preliminary retargeting. The preliminary retargeted result is then processed by the adaptive repainting region determination module to identify the abrupt pixel regions that need to be repainted. Utilizing the original image as guidance, the image is inpainted with the image-guided repainting module, generating the final targeted image with target ratio.

pixels in the saliency map, \(W\) is the width of the image. The saliency map can be obtained through a pretrained salient object detection network . By enhancing the energy in important areas, the saliency prior \(S(x,y)\) prevents key objects from deformation. The spatial prior \((1-|}{W})\) further differentiates the importance within key regions, where the significance gradually decreases from the centroid towards the edges, thereby encouraging the model to prioritize seam removal from outer regions and retain key semantic elements for an object, ultimately avoiding distortion.

For convenience, we follow  to describe a vertical seam in an image as \(s^{x}=\{s_{i}^{x}\}_{i=1}^{W}=\{(x(i),i)\}_{i=1}^{W}\), where \(x()\) is a mapping subject to \(|x(i)-x(i-1)| 1\). Given the energy function, we define the cost of a seam as \(cost(s)=_{i=1}^{W}Energy(s_{i})\). The seam to be deleted is selected by minimizing the cost:

\[s^{*}=min_{s}_{i=1}^{W}Energy(s_{i}).\] (3)

Using dynamic programming, we can efficiently find the seams with the least energy. We set a tolerable saliency loss ratio \(\) to control the maximum loss of salient regions, which will be elaborated in Section 3.3.1. The maximum number of deleted seams is determined jointly by the saliency map and the tolerable saliency loss ratio \(\). Specifically, the quantity of seams to be deleted, which intersect the saliency map, must not exceed the product of the saliency width \(W_{s}\) and the tolerable saliency loss ratio \(\), whether the image reaches the target ratio. We further get a binary mask \(S\) where \(0\) represents the low energy pixel to delete and \(1\) is the pixel to be preserved. The initial retargeting results can be obtained by performing a dot product between the original image and the mask \(S\) and then concatenating the non-zero pixel regions.

### Adaptive Repainting

The pixel-shift method inherently introduces pixel inconsistency, and bridging the resulting pixel gap poses a significant challenge. To address this issue, we introduce Adaptive Repainting (AR), a novel approach consisting of two primary components: the Adaptive Repainting Region Determination module (ARRD) and the Image-guided Repainting module (IR).

#### 3.3.1 Adaptive Repainting Region Determination

The ARRD is designed to dynamically identify regions that require inpainting, which are characterized by inconsistencies among individual pixels. Additionally, ARRD determines the optimal repaint strategy (_i.e._, inpaint or outpaint) and corresponding regions by comparing the current ratio with the target ratio.

To generate the inpainting mask, we identify pixels with a high number of deleted neighboring pixels in the content-aware seam carving (CSC) result as abrupt. As depicted by the green region in Figure 2, we employ a one-dimensional sliding window of length \(l\) on the mask map \(S\) of seam-carving to calculate the mean value within the window. This can be formalized as a one-dimensional convolution: \(M=conv1d(S,K)/l\), where \(conv1d\) is a one-dimension convolution operator, k is a one-dimensional convolution kernel of length \(l\) with all values equal to 1. We then binarize \(M\) into \(\) using a threshold \(\), where 0 indicates areas to be inpainted and 1 denotes pixels to be preserved.

To generate the outpainting mask, we binarize the saliency map \(S\) into \(\) using the mean value as the threshold. For each connected region in the saliency map, we compute its maximum width and then take the union of all these widths to obtain the saliency width \(W_{s}\). This can be formalized as:

\[W_{s}=sum(Union(w_{1},...,w_{H})),\] (4)

where \(w_{i}\) is the _i_-th row of the binary saliency map \(\), \(Union(a,b)\) represents the union of two binary vectors \(a\) and \(b\), and \(sum(a)\) denotes the sum of all elements in the vector \(a\). Given the target ratio \(r\), we compare it with the target width \(W_{t}\), which can be calculated as: \(W_{t}=H*r,\) where \(H\) is the height of original image. The final targeted width \(W_{f}\) can be determined as:

\[W_{f}=W_{s}*(1-),&W_{s}*(1-)>W_{t}\\ W_{t},&W_{s}*(1-) W_{t},\] (5)

where \(\) is the tolerable saliency loss ratio, set to 0.3 in our experiment. The final height \(H_{f}\) is then calculated as \(W_{f}/r\), and we can determine if the image needs expanding by comparing \(H_{f}\) and \(H\).

The expanded height \((H_{f}-h)\) will be evenly distributed to the top and bottom of the image. The outpainting mask in this stage can be merged into the inpainting mask \(\), hence the retargeting results can be obtained with a unified repainting process with \(\).

#### 3.3.2 Image-guided Repainting

As shown in Figure 3, to achieve repainting, a pretrained ControlNet , replicated from the Stable Diffusion (SD)  Unet, is parallelly combined with the SD model. This ControlNet (specifically, the inpaint version) serves to introduce features associated with visible regions of the image to be repainted. To harness the guidance provided by the original image, we further introduce an IP-Adapter , which consists of a CLIP image encoder  and a lightweight adapter , to fuse image prompts with text prompts using decoupled cross-attention.

With the repainting mask \(\) obtained in Section 3.3.1, we can formulate one reverse step in the diffusion process  to achieve repainting as follows:

\[y_{t-1}= y_{t-1}^{known}+(1-) y_{t-1}^{unknown},\] (6)

where \(y_{t-1}^{known}\) is sampled with the unmasked pixels in the given image \( y_{0}\), while \(y_{t-1}^{unknown}\) is sampled from the model with the previous iteration \(y_{t}\).

## 4 Experiments

### Dataset and Evaluation Metrics

We evaluate the proposed method on the public image retargeting datasets, RetargetMe , which contains 80 images from various scenes. According to the common sizes of prevalent electronic devices, we set the target aspect ratio for image retargeting as 16:9, 1:1, 4:3 and 9:16.

The metrics for image retargeting have remained undetermined and existing evaluation metrics [21; 18; 13] exhibit discrepancies with human perception, such as treating foreground and background equally. To intuitively evaluate the effectiveness of image retargeting methods, we propose **Saliency Discard Ratio** (SDR) to assess the semantic preservation. The SDR can be calculated as follows:

\[SDR=^{ori}-W_{s}^{out}}{W_{s}^{ori}},\] (7)

where \(W_{s}^{ori}\) is the saliency width of the original image defined in equation 4 and \(W_{s}^{out}\) is the saliency width of the retargeted image.

**User study metric.** Given the subjective nature of retargeting results, we employ manual scoring as an additional evaluation method. Specifically, we invite 20 volunteers to rate the results on a scale

Figure 3: The architecture of the image-guided repainting module.

from 0 to 3 across four aspects: content completeness, deformation, local smoothness, and aesthetics. These aspects are defined as follows: content completeness assesses whether key areas are cropped, deformation examines the degree of deformation within crucial areas, local smoothness evaluates the continuity of local regions in the image, and aesthetics evaluates the overall harmony and aesthetic appeal of the visual composition. A higher score indicates better performance.

### Implement Details

Our method is implemented using Pytorch on a RTX 3090. The length of the sliding window in Section 3.3.1 is set to \(l=25\), and the threshold is set to \(=15\). We utilize the VST model  for salient object detection in CSC. For the image-to-image repainting model in AR, we employ a composition of SD1.5*, ControlNet-Inpainting* and IP-Adapter .

Footnote *: https://huggingface.co/runwayml/stable-diffusion-v1-5

Footnote *: https://huggingface.co/lllyasviel/control_v11p_sd15_inpaint

### Compare with Other Retargeting Methods

We quantitatively evaluate the performance of our proposed model by comparing it with three other prevalent image retargeting methods, namely scaling, cropping, seam-carving , InGAN  and full repainting which repaints the whole image with SD1.5 and IP-Adapter , using the objective metric 'SDR' and four subjective metrics across different aspect ratios.

Table 1 presents the performance of different methods on four subjective evaluation metrics. As shown in the table, shown in the table, scaling and cropping exhibit two extremes, with scaling prioritizing content completeness and cropping prioritizing shape control. In contrast, our method receives high ratings across all four evaluation metrics. Notably, when compared to Table 1, scaling exhibits significant discrepancies between subjective and objective metrics in terms of key content preservation. We believe this is because the human eye has a natural interpolation ability compared to machines. Therefore, for scaling methods that uniformly delete pixels, subjective observers may not perceive strong content loss, even though objective metrics may indicate otherwise.

  Aspect Ratio & 16/9 & 4/3 & 1/1 & 9/16 \\  Scale & 0.571 & 0.446 & 0.307 & 0.222 \\ Crop & 0.386 & 0.259 & 0.129 & 0.094 \\ seam-carving & 0.490 & 0.367 & 0.242 & 0.161 \\ InGAN & 0.569 & 0.442 & 0.263 & 0.222 \\ FR & 0.524 & 0.423 & 0.294 & 0.214 \\ Ours & **0.151** & **0.074** & **0.031** & **0.006** \\  

Table 1: Comparison of SDR values with other retargeting methods on the RetargetMe dataset with different aspect ratios. Lower values indicate better semantic completeness. The best results are highlighted in **bold**.

  Settings & Content completeness & Deformation & Local smoothness & Aesthetic & **Average** \\  & score \(\) & score \(\) & score \(\) & score \(\) & **score \(\)** \\  Scale & **2.875** & 0.975 & 1.878 & 1.153 & 1.720 \\ Crop & 1.295 & **2.905** & **2.926** & 2.355 & 2.370 \\ Seam-carving & 2.829 & 0.973 & 1.000 & 1.038 & 1.461 \\ InGAN & 1.662 & 0.975 & 1.007 & 0.866 & 1.126 \\ FR & 1.327 & 1.812 & 1.702 & 1.535 & 1.594 \\ Ours & 2.345 & 2.757 & 2.689 & **2.538** & **2.582** \\  

Table 2: Subjective comparison with other retargeting methods in aspect ratio 16:9. \(\) indicates that larger are better. The best results are highlighted in **bold**.

To qualitatively evaluate the performance of our proposed method, we visually compare our model with other 5 retargeting methods, including scaling, cropping, seam-carving , InGAN  and full repainting (FR, which repaints the whole image with the guidance of original image using IP-Adapter ) on different ratios. We conduct experiments with different ratios to provide an overall assessment of each method. Figure 4 and Figure 5 illustrate the comparison of retargeting results with two extreme target ratios respectively. We can intuitively observe that most traditional methods produce inferior results due to the lack of semantic information or the oversized salient areas. They struggle to balance the trade-off between preserving key content and preventing significant object deformation. In contrast, our proposed method effectively preserves the essential content and structure of foreground objects while simultaneously maintaining harmonious and consistent background.

### Ablation Study

In this section, we comprehensively conduct ablation experiments to verify the effectiveness of each design in our proposed model on the popular aspect ratio 16:9.

**Effectiveness of content-aware seam-carving.** As shown in Table 3, content-aware seam-carving (denoted by '+CSC') significantly reduces the SDR, which means the salient objects are preserved much better. Besides, CSC can better preserve the structure of key objects, as evidenced by Figure 6. Different from the original seam-carving, the addition of the CSC module results in minimal

Figure 4: Visual comparison to other retargeting methods on ratio 16:9.

Figure 5: Visual comparison to other retargeting methods on ratio 9:16.

deformation for the car. Also, the house with more complex patterns maintains its basic structure and avoids significant global deformation.

**Effectiveness of adaptive repainting.** The comparison between '+CSC' and '+CSC+AR' in Table 3 shows consistent improvement by the adaptive repainting module. As shown in Figure 6, AR adaptively identifies areas with abrupt pixels for repainting and adjusts the mask according to the target aspect ratio, leading to enhanced results.

**Comparison between background repainting and adaptive repainting.** To further validate the advantages of our proposed adaptive repainting method, we introduce the Background Repainting (BR) strategy for comparison. BR identifies the background based on saliency maps as the region for regeneration. Table 4 demonstrates the advantages of our AR method in preserving salient regions, which is supported by Figure 6. Specifically, BR is unable to address discontinuities in foreground pixels (see the car and the building in Figure 6), and the retargeting results are constrained by the ratio (the structure of car in the first row of Figure 6 due to extreme ratio). In contrast, our AR can identify all abrupt pixel regions and adapt well to extreme ratios.

### Limitations

Constrained by the Stable Diffusion model, the inference speed of our method is relatively slow, averaging 7 seconds per image on the RetargetMe dataset . This may limit its real-time applicability in certain scenarios. Moreover, the repainting region generated by ARRD is not complete enough, as ARRD searches the local pixel displacement area without global understanding. For instance, in comparing the 'Original image' and '+CSC+AR' images in the second row of Figure 6, several

  Methods & SDR\(\) \\  Background Repainting & 0.190 \\ Adaptive Repainting & **0.151** \\  

Table 4: Comparison of background repainting (BR) and our adaptive repainting (AR) on ratio 16:9.

Figure 6: Visualization to demonstrate the effectiveness of each component in our method. ‘+CSC’ denotes content-aware seam-carving in section 3.2, ‘+CSC+BR’ means adopt background repainting based on CSC, ‘+CSC+AR’ means adaptive repainting in section 3.3 based on CSC.

  Methods & SDR\(\) \\  Seam-carving & 0.490 \\ +CSC & 0.190 \\ +CSC+AR & **0.151** \\  

Table 3: Ablation study of our retargeting methods on ratio 16:9.

seams passing through the streetlight were removed, causing misalignment. AR only repaints the pixels around the deleted seams instead of the entire streetlight, resulting in a streetlight that remains misaligned in the generated image.

## 5 Conclusion

Our paper introduces a new image retargeting model called PruneRepaint. This model is content-aware and adaptive, allowing it to work with any target ratio. The content-aware seam-carving method protects important semantic regions, while the adaptive repainting module helps to maintain visual quality even after pixels are deleted. Through extensive experiments, we have demonstrated the effectiveness of our design and the advantages of using PruneRepaint for image retargeting.