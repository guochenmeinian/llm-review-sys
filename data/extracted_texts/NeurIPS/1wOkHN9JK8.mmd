# Hierarchical VAEs provide a normative account of motion processing in the primate brain

Hadi Vafaii\({}^{1}\)

vafaii@umd.edu

Jacob L. Yates\({}^{2}\)

yates@berkeley.edu

Daniel A. Butts\({}^{1}\)

dab@umd.edu

University of Maryland, College Park

UC Berkeley

###### Abstract

The relationship between perception and inference, as postulated by Helmholtz in the 19th century, is paralleled in modern machine learning by generative models like Variational Autoencoders (VAEs) and their hierarchical variants. Here, we evaluate the role of hierarchical inference and its alignment with brain function in the domain of motion perception. We first introduce a novel synthetic data framework, Retinal Optic Flow Learning (ROFL), which enables control over motion statistics and their causes. We then present a new hierarchical VAE and test it against alternative models on two downstream tasks: (i) predicting ground truth causes of retinal optic flow (e.g., self-motion); and (ii) predicting the responses of neurons in the motion processing pathway of primates. We manipulate the model architectures (hierarchical versus non-hierarchical), loss functions, and the causal structure of the motion stimuli. We find that hierarchical latent structure in the model leads to several improvements. First, it improves the linear decodability of ground truth factors and does so in a sparse and disentangled manner. Second, our hierarchical VAE outperforms previous state-of-the-art models in predicting neuronal responses and exhibits sparse latent-to-neuron relationships. These results depend on the causal structure of the world, indicating that alignment between brains and artificial neural networks depends not only on architecture but also on matching ecologically relevant stimulus statistics. Taken together, our results suggest that hierarchical Bayesian inference underlines the brain's understanding of the world, and hierarchical VAEs can effectively model this understanding.

## 1 Introduction

Intelligent interactions with the world require representation of its underlying composition. This inferential process has long been postulated to underlie human perception [1; 2; 3; 4; 5; 6; 7; 8; 9], and is paralleled in modern machine learning by generative models [10; 11; 12; 13; 14; 15; 16; 17], which learn latent representations of their sensory inputs. The question of what constitutes a "good" representation has no clear answer [18; 19], but several desirable features have been proposed. In the field of neuroscience, studies focused on object recognition have suggested that effective representations "_untangle_" the various factors of variation in the input, rendering them linearly decodable [20; 21]. This intuitive notion of linear decodability has emerged in the machine learning community under different names such as "_informativeness_"  or "_explicitness_" . Additionally, it has been suggested that "_disentangled_" representations are desirable, wherein distinct, informative factors of variations in the data are separated [24; 25; 26; 27; 28; 29]. Artificial neural networks (ANNs) are also increasingly evaluated based on their alignment with biological neural processing [30; 31; 32; 33; 34; 35; 36; 37; 38], because of the shared goals of ANNs and the brain's sensory processing [25; 39; 40]. Such alignment also provides the possibility of gaining insights into the brain by understanding the operations within an ANN [41; 42; 43; 44; 45; 46; 47].

In this work, we investigate how the combination of (i) model architecture, (ii) loss function, and (iii) training dataset, affects learned representations, and whether this is related to the brain-alignment of the ANN [41; 44]. We focus specifically on understanding the representation of motion because large sections of the visual cortex are devoted to processing motion , and the causes of retinal motion (moving objects and self-motion ) can be manipulated systematically. Crucially, motion in an image can be described irrespective of the identity and specific visual features that are moving, just as the identity of objects is invariant to how they are moving. This separation of motion and object processing mirrors the division of primate visual processing into dorsal (motion) and ventral (object) streams [49; 50; 51].

We designed a _naturalistic_ motion simulation based on distributions of ground truth factors corresponding to the location and depth of objects, motion of these objects, motion of the observer, and observer's direction of gaze (i.e., the fixation point; Fig. 1a). We then trained and evaluated an ensemble of autoencoder-based models using our simulated retinal flow data. We based our evaluation on (1) whether the models untangle and disentangle the ground truth factors in our simulation; and (2) the degree to which their latent spaces could be directly related to neural data recorded in the dorsal stream of primates (area MT).

We introduce a new hierarchical variational autoencoder, the "compressed" Nouveau VAE (cNVAE) . The cNVAE exhibited superior performance compared to other models across our multiple evaluation metrics. First, it discovered latent factors that accurately captured the ground truth factors in the simulation in a more disentangled manner than other models. Second, it achieved significant improvements in predicting neural responses compared to the previous state-of-the-art model , doubling the performance, with sparse mapping from its latent space to neural responses.

Taken together, these observations demonstrate the power of the synthetic data framework and show that a single inductive bias--hierarchical latent structure--leads to many desirable features of representations, including brain alignment.

## 2 Background & Related Work

Neuroscience and VAEs.It has long been argued that perception reflects unconscious inference of the structure of the world constructed from sensory inputs. The concept of "perception as unconscious inference" has existed since at least the 19th century [1; 2], and more recently inspired Mumford  to conjecture that brains engage in hierarchical Bayesian inference to comprehend the world [3; 4]. These ideas led to the development of Predictive Coding [5; 5; 9; 53; 54; 55; 56; 57; 58], Bayesian Brain Hypothesis [6; 59; 60; 61; 62; 63; 64; 65], and Analysis-by-Synthesis , collectively suggesting that brains contain an internal generative model of the world [66; 67; 7; 8]. A similar idea underlies modern generative models [68; 69; 15; 16; 17; 18; 17; 67; 16], especially hierarchical variants of VAEs [71; 72; 73; 52].

The Nouveau VAE (NVAE)  and very deep VAE (vdvae)  demonstrated that deep hierarchical VAEs can generate realistic high-resolution images, overcoming the limitations of their non-hierarchical predecessors. However, neither work evaluated how the hierarchical latent structure changed the quality of learned representations. Additionally, both NVAE and vdvae have an undesirable property: their convolutional latents result in a latent space that is several orders of magnitude larger than the input space, defeating a main purpose of autoencoders: compression. Indeed, Hazami et al.  showed that a tiny subset (around \(3\%\)) of the vdvae latent space is sufficient for comparable input reconstruction. Here, we demonstrate that it is possible to compress hierarchical VAEs and focus on investigating their latent representations with applications to neuroscience data.

Evaluating ANNs on predicting biological neurons.Several studies have focused on evaluating ANNs on their performance in predicting brain responses, but almost entirely on describing static ("ventral stream") image processing [30; 36; 33]. In contrast, motion processing (corresponding to the dorsal stream) has only been considered thus far in Mineault et al. , who used a 3D ResNet ("DorsalNet") to extract ground truth factors about self-motion from drone footage ("AirSim", ) in a supervised manner. DorsalNet learned representations with receptive fields that matched known features of the primate dorsal stream and achieved state-of-the-art on predicting neural responses on the dataset that we consider here. In addition to our model architecture and training set, a fundamental difference between our approach and Mineault et al.  is that they trained their models using direct supervision. As such, their models have access to the ground truth factors at all times.

[MISSING_PAGE_FAIL:3]

such that the prior is given by \(p()=p(_{1})_{=2}^{L}p(_{}|_{<})\), and approximate posterior is given by \(q(|)=_{=1}^{L}q(_{}|_{<},)\) (more details in section 9.1). Additionally, different latent groups in the NVAE operate at different spatial scales (Fig. 2, left), with multiple groups per scale. Crucially, such scale-dependent grouping is absent from non-hierarchical VAEs (Fig. 2, right).

The cNVAE closely follows the NVAE , with one important difference: the original NVAE latent space is convolutional, and ours is not. We modified the _sampler_ layers (grey trapezoids, Fig. 2) such that their receptive field sizes match the spatial scale they operate on. Thus, sampler layers integrate over spatial information before sampling from the approximate posterior. The spatial patterns of each latent dimension are then determined by _expand_ modules (yellow trapezoids, Fig. 2), based on a deconvolution step. Further details about the processing of the sampler and expand layers are provided in Supplementary section 9.2.

Our modification of the NVAE serves two purposes. First, it decouples spatial information from the functionality of latent variables, allowing them to capture abstract features that are invariant to particular spatial locations. Second, it has the effect of compressing the input space into a lower-dimensional latent code. We explain this in more detail in Supplementary section 9.3.

Our model has the following structure: 3 latent groups operating at the scale of \(2 2\); 6 groups at the scale of \(4 4\); and 12 groups at the scale of \(8 8\) (Table 4, Fig. 2). Therefore, the model has \(3+6+12=21\) hierarchical latent groups in total. Each latent group has \(20\) latent variables, which results in an overall latent dimensionality of \(21 20=420\). See Table 4 and Supplementary section 9.3 for more details.

Alternative models.We evaluated a range of unsupervised models alongside cNVAE, including standard (non-hierarchical) VAEs [11; 12], a hierarchical autoencoder with identical architecture as

Figure 1: Retinal Optic Flow Learning (ROFL): a simulation platform for synthesizing naturalistic optic flow patterns. **(a)** The general setup includes a moving or stationary observer and a solid background, with optional moving object(s) in the scene. More details are provided in the appendix (section 13). **(b)** Example frames showcasing different categories (see Table 1 for definitions). **(c, d)** Demonstrating the causal effects of varying a single ground truth factor while keeping all others fixed: **(c)**\(X_{obj}\), the \(x\) component of object position (measured in retinal coordinates, orange), and **(d)**\(F_{x}\), the \(X\) component of the fixation point (measured in fixed coordinates, gray).

the cNVAE but trained only with reconstruction loss (cNAE), and an autoencoder (AE) counterpart for the VAE (Table 2). All models had the same latent dimensionality (Table 4), and approximately the same number of parameters and convolutional layers. We used endpoint error as our measure of reconstruction loss, which is the Euclidean norm of the difference between actual and reconstructed flow vectors. This metric works well with optical flow data .

Model representations.We define a model's internal representation to be either the mean of each Gaussian for variational models (i.e., samples drawn from \(q(|)\) at zero temperature), or the bottleneck activations for autoencoders. For hierarchical models (cNVAE, cNAE), we concatenate representations across all levels (Table 4).

Training details.Models were trained for \(160{,}000\) steps at an input scale of \(17 17\), requiring slightly over a day on Quadro RTX 5000 GPUs. Please refer to Supplementary section 9.4 for additional details.

Disentanglement and \(\)-VAEs.A critical decision when optimizing VAEs involves determining the weight assigned to the KL term in the loss function compared to the reconstruction loss. Prior research has demonstrated that modifying a single parameter, denoted as \(\), which scales the KL term, can lead to the emergence of disentangled representations . Most studies employing VAEs for image reconstruction typically optimize the standard evidence lower bound (ELBO) loss, where \(\) is fixed at a value of 1 . However, it should be noted that due to the dependence of the reconstruction loss on the input size, any changes in the dimensionality of the input will inevitably alter the relative contribution of the KL term, and thus the "effective" \(\).

Furthermore, Higgins et al.  recently established a strong correspondence between the generative factors discovered by \(\)-VAEs and the factors encoded by inferotemporal (IT) neurons in the primate ventral stream. The alignment between these factors and IT neurons exhibited a linear relationship with the value of \(\). In light of these findings, we explicitly manipulate the parameter \(\) within a range spanning from \(0.01\) to \(10\) to investigate the extent to which our results depend on its value.

   Model & Architecture & Loss & Kullback–Leibler term (KL) \\  cNVAE & Hierarchical & EPE \(+*\) & \(=_{=1}^{L}_{q(_{<}|)} [_{}],\) where \\  & & & \(_{}_{}[q(_{} |,_{<})\|\,p(_{}|_{<} )].\) \\  VAE & Non-hierarchical & EPE \(+*\) & \(=_{}[q(|)\| \,p()]\) \\  cNAE & Hierarchical & EPE & - \\  AE & Non-hierarchical & EPE & - \\   

Table 2: Model details. Here, _hierarchical_ means that there are parallel pathways for information to flow from the encoder to the decoder (Fig. 2), which is slightly different from the conventional notion. For variational models, this implies hierarchical dependencies between latents in a statistical sense . This hierarchical dependence is reflected in the KL term for the cNVAE, where \(L\) is the number of hierarchical latent groups. See Supplementary section 9.3 for more details and section 9.1 for a derivation. All models have an equal # of latent dimensions (\(420\), see Table 4), approximately the same # of convolutional layers, and # of parameters (\( 24\)\(M\)). EPE, endpoint error.

Figure 2: Architecture comparison. Left, compressed NVAE (cNVAE); right, non-hierarchical VAE. We modified the NVAE _sampler_ layer (grey trapezoids) and introduced a deconvolution _expand_ layer (yellow trapezoids). The encoder (inference) and decoder (generation) pathways are depicted in red and blue, respectively. \(r\), residual block; \(h\), trainable parameter; \(+\), feature combination.

[MISSING_PAGE_FAIL:6]

perfectly. The fixation location has a highly nontrivial effect on the flow patterns, and varying it causes both global and local changes in the flow patterns (Fig. 1d).

Furthermore, cNVAE is the only model that reliably captures object position and velocity: especially note \(V_{obj,z}\) (last column in Fig. 4). Inferring object motion from complex optic flow patterns involves two key components. First, the model must extract self-motion from flow patterns. Second, the model must understand how self-motion influences flow patterns globally. Only then can the model subtract self-motion from global flow vectors to obtain object motion. In vision science, this is known as the _"flow-parsing hypothesis"_. Such flow-parsing is achieved by the cNVAE but none of the other models. See Supplementary section 11 for further discussion of this result and its implications.

Disentanglement: the cNVAE produces more disentangled representations.The pursuit of disentanglement in neural representations has garnered considerable attention . In particular, Locatello et al.  established that learning fully disentangled representations is fundamentally impossible without inductive biases. Prior efforts such as \(\)-VAE  demonstrated that increasing the weight of the KL loss (indicated by \(\)) promotes disentanglement in VAEs. More recently, Whittington et al.  demonstrated that simple biologically inspired constraints such as non-negativity and energy efficiency encourage disentanglement. Here, we demonstrate that another biological inductive bias, hierarchy in the latent space, will promote disentanglement of the latent representations learned by VAEs.

To evaluate the role of hierarchy, we adopted the DCI framework  which offers a well-rounded evaluation of latent representations. The approach involves training a simple decoder (e.g., lasso regression) that predicts data generative factors \(\) from a latent code \(\); followed by computing a matrix of relative importances (e.g., based on lasso weights) which is then used to evaluate different aspects of the code quality: _Informativeness_--measures whether \(\) contains easily accessible information about \(\) (similar to untangling from above). _Disentanglement_--measures whether individual latents correspond to individual generative factors. _Completeness_--measures how many \(z_{i}\) are required to capture any single \(g_{j}\). If a single latent contributes to \(g_{j}\)'s prediction, the score will be 1 (complete). If all latent variables equally contribute to \(g_{j}\)'s prediction, the score will be 0 (maximally overcomplete). Note that "_completeness_" is also referred to as "_compactness_" . See Fig. 9 and Supplementary

Figure 4: Hierarchical VAE untangles underlying factors of variation in data. The linear decodability of ground truth factors (x-axis) from different latent codes is shown. Untangling scores averaged across all ground truth factors are \(=0.898\), \(=0.639\), \(=0.548\), \(=0.456\), \(=0.477\), \(=0.236\), and \(=0.235\). For variational models, the best performing \(\) values were selected: cNVAE, \(=0.15\); VAE, \(=1.5\) (see Supplementary section 9.5 for more details).

Figure 5: Evaluating the learned latent codes using the DCI framework . Larger values are better for all metrics. Note that _informativeness_ is closely related to _untangling_. See also Fig. 9.

section 9.7.1 for more details, ref.  for a review, and ref.  for a recent extension of the DCI framework.

We follow the methods outlined by Eastwood and Williams  with two modifications: (1) we replaced lasso with linear regression to avoid the strong dependence on the lasso coefficient that we observed, and (2) we estimate the matrix of relative importances using a feature permutation-based algorithm (sklearn.inspection.permutation_importance), which measures the relative performance drop that results from shuffling a given latent.

We found that cNVAE outperforms competing models across all metrics for a broad range of \(\) values (Fig. 5). The observed pattern of an inverted U shape is consistent with previous work , which suggests that there is an optimal \(\) that can be empirically determined. In this case, cNVAE with \(=0.5\) achieved the best average DCI score. Further, we found that VAEs lacking hierarchical structure learn highly overcomplete codes, such that many latents contribute to predicting a single ground truth factor. In conclusion, the simple inductive bias of hierarchy in the latent space led to a substantial improvement in VAE performance across all components of the DCI metric.

Brain-alignment: the cNVAE aligns more closely with MT neurons.To evaluate the performance of models in predicting neuronal activity in response to motion stimuli, we used an existing dataset of \(N=141\) MT neurons recorded while presented with random dot kinematograms representing smoothly changing combinations of optic flow velocity fields . A subset of these neurons (\(N=84\)) are publicly available on crcns.org, and were recently used in Mineault et al.  that we compare to.

To measure neuronal alignment, we first determined the mapping from each model's latent representation to MT neuron responses (binned spike counts, Fig. 6a). Here, the latent representation is defined as the mean of predicted Gaussian distributions for VAEs, and the bottleneck activations for AEs. We learn this linear latent-to-neuron mapping using ridge regression. Figure 6b shows the average firing rate of an example neuron along with model predictions. Because sensory neurons have a nonzero response latency, we determined each neuron's optimal response latency, which maximized cross-validated performance. The resulting distribution of best-selected latencies (Fig. 6c) peaked around \(100\ ms\): consistent with known MT latencies . We also empirically optimized ridge coefficients to ensure each neuron has its best fit. Figure 6d shows that the models capture the receptive field properties of MT neurons as measured by the spike-triggered average stimulus. To evaluate performance, we follow methods established by Mineault et al. : whenever repeated trials were available, we report Pearson's \(R\) on that held-out data, normalized by maximum explainable variance . When repeats were not available, we performed 5-fold cross-validation and reported the held-out performance using Pearson's \(R\) between model prediction and spike trains.

Evaluating brain alignment.We use two measures of brain alignment: the success at predicting the neural response (Pearson's \(R\), Fig. 7, Table 3); and, the "_alignment_" between neurons and individual model latents (Fig. 8, ). These mirror the untangling and completeness metrics described above (more details are provided below).

Figure 6: **(a)** Experimental setup form . **(b)** Both models explain MT neural variability well. **(c)** Distribution of best estimated latencies. **(d)** Spike-triggered averages (STA) are shown.

All models predict MT neuron responses well.After training a large ensemble of unsupervised models on fixate-1 and learning the neural mapping, we found that both hierarchical (cNVAE & cNAE) and non-hierarchical (VAE & AE) variants had similar ability to predict neural responses (Fig. 7). The performance did depend on the loss function itself, with the variational loss outperforming simple autoencoder reconstruction loss (Table 3).

Hierarchical VAEs are more aligned with MT neurons.We next tested how these factors affect neural alignment, i.e., how closely neurons are related to individual latents in the model. Figure 8a demonstrates what we mean by "alignment": a sparse latent-to-neuron relationship means larger alignment, indicative of a similar representational "form" . See Fig. 10 for an illustration of this idea. To formalize this notion, we use feature permutation importance (described above), applied to the ridge regression models. This yields a \(420\)-dimensional vector per neuron. Each dimension of this vector captures the importance of a given latent variable in predicting the responses of the neuron. We normalize these vectors and interpret them as the probability of importance. We then define alignment score \(a_{i}\) of neuron \(i\) as \(a_{i}=1+_{k=1}^{K}p_{ik}_{K}p_{ik}\), where \(p_{ik}\) is interpreted as the importance of \(k-\)th latent variable in predicting neuron \(i\) (Fig. 8a). This concept is closely related to the "_completeness_" score from the DCI framework as discussed above.

Figure 8: Hierarchical models (cNVAE, cNAE) are more aligned with MT neurons since they enable sparse latent-to-neuron relationships. **(a)** Alignment score measures the sparsity of permutation feature importances. \(a_{i}=0\) when all latents are equally important in predicting neuron \(i\); and, \(a_{i}=1\) when a single latent predicts the neuron. **(b)** Feature importances are plotted for an example neuron (same as in Fig. 6b). cNVAE (\(=0.01\)) predicts this neuron’s response in a much sparser manner compared to non-hierarchical VAE (\(=5\)). Supplementary section 9.5 contains a discussion of our rationale in choosing these \(\) values. **(c)** Alignment across \(\) values, and autoencoders (ae).

Figure 7: All models (pretrained on fixate-1) perform comparably in predicting MT neuron responses. Dashed line corresponds to the previous state-of-the-art on this data .

For almost all \(\) values, the cNVAE exhibited a greater brain alignment than non-hierarchical VAE (Fig. 8c; cNVAE > VAE, paired \(t-\)test; see Fig. 16 and Table 5). Similarly, for the autoencoders, we found that the hierarchical variant outperformed the non-hierarchical one (cNAE > AE). Based on these observations, we conclude that higher brain alignment is primarily due to hierarchical latent structure. However, note that hierarchy in the traditional sense did not matter: all these models had approximately the same number of convolutional layers and parameters.

Factors leading to brain-alignment.To test the effect of the training dataset (i.e., category of ROFL) on model performance, we trained cNVAE models using fixate-0, fixate-1, and obj-1 categories (Table 1), while also exploring a variety of \(\) values. We found that fixate-1 clearly outperformed the other two ROFL categories (Table 3), suggesting that both global (e.g., self-motion) and local (e.g., object motion) sources of variation are necessary for learning MT-like representations. The effect of loss function was also visible: some \(\) values led to more alignment. But this effect was small compared to the effect of hierarchical architecture (Fig. 8c).

## 5 Discussion

We introduced a new framework for understanding and evaluating the representation of visual motion learned by artificial and biological neural networks. This framework provides a way to manipulate causes in the world and evaluate whether learned representations untangle and disentangle those causes. In particular, our framework makes it possible to test the influence of architecture (Fig. 2), loss function (Table 2), and training set (Table 1) on the learned representations, encompassing 3 out of the 4 core components of a recently proposed neuroconnectionist research programme . Our framework brings hypothesis-testing to understand [biological] neural processing of vision and provides an interpretive framework to understand neurophysiological data.

The goal of the present work was to establish our framework and demonstrate its potential. To this end, we made several simplifying choices, such as training on individual flow frames rather than time-evolving videos. We provide a detailed discussion of study limitations in Supplementary section 8. Future work will address these by rendering images in simulations and using image-computable models, incorporating real eye-tracking and scene data in ROFL , testing our approach on more data from other brain areas such as MST , and using more sophisticated methods to measure representational alignment between ANNs and brains .

Conclusion.We used synthetic data to test how causal structure in the world affects the representations learned by autoencoder-based models and evaluated the learned representations based on how they represent ground truth factors and how well they align with biological brains. We found that a single inductive bias, hierarchical latent structure, leads to desirable representations and increased brain alignment.

    & Pretraining &  \\   & dataset & \(=0.5\) & \(=0.8\) & \(=1\) & \(=5\) \\   & fixate-1 & \(\) & \(\) & \(\) & \(\) \\  & fixate-0 & \(\) & \(\) & \(\) & \(\) \\  & obj-1 & \(\) & \(\) & \(\) & \(\) \\   & fixate-1 & \(\) & \(\) & \(\) & \(\) \\   & fixate-1 & \)} \\   & fixate-1 & \)} \\  CPC  & AirSim  & \) (Mineault et al. )} \\  DorsalNet & AirSim  & \) (Mineault et al. )} \\   

Table 3: Both cNVAE and VAE perform well in predicting MT neuron responses, surpassing previous state-of-the-art models by more than a twofold improvement. Moreover, the clear gap between fixate-1 and other categories highlights the importance of pretraining data .

Code & Data

Our code and model checkpoints are available here: https://github.com/hadivafaii/ROFL-cNVAE.

## 7 Acknowledgments

This work was supported by NSF IIS-2113197 (HV and DAB), NSF DGE-1632976 (HV), and NIH R00EY032179 (JLY). We thank our anonymous reviewers for their helpful comments, and the developers of the software packages used in this project, including PyTorch , NumPy , SciPy , scikit-learn , pandas , matplotlib , and seaborn .