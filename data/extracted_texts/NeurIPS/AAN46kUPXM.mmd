# Neural expressiveness for beyond importance model compression

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Neural Network Pruning has been established as driving force in the exploration of memory and energy efficient solutions with high throughput both during training and at test time. In this paper, we introduce a novel criterion for model compression, named "Expressiveness". Unlike existing pruning methods that rely on the inherent "Importance" of neurons' and filters' weights, "Expressiveness" emphasizes a neuron's or group of neurons ability to redistribute informational resources effectively, based on the overlap of activations. This characteristic is strongly correlated to a network's initialization state, establishing criterion autonomy from the learning state (_stateless_) and thus setting a new fundamental basis for the expansion of compression strategies in regards to the "When to Prune" question. We show that expressiveness is effectively approximated with arbitrary data or limited dataset's representative samples, making ground for the exploration of _Data-Agnostic strategies_. Our work also facilitates a "hybrid" formulation of expressiveness and importance-based pruning strategies, illustrating their complementary benefits and delivering up to 10\(\) extra gains w.r.t. weight-based approaches in parameter compression ratios, with an average of 1% in performance degradation. We also show that employing expressiveness (independently) for pruning leads to an improvement over top-performing and foundational methods in terms of compression efficiency. Finally, on YOLOv8, we achieve a 46.1% MACs reduction by removing 55.4% of the parameters, with an increase of 3% in the mean Absolute Precision (\(mAP_{50-95}\)) for object detection on COCO dataset.

## 1 Introduction

To address the computational constraints of existing models, Model Compression  has emerged as a prominent solution in exploring models that achieve comparable performance, but with reduced computational complexity . Within this scope, Floating Point Operations (_FLOPs_) are used to estimate a model's computational complexity, by measuring the arithmetic operations required for a forward pass, while parameters (_params_) are associated with a model's size in terms of memory space  and their reduction can be a precursor towards more energy efficient solutions . Although _FLOPs_ and _params_ often correlate, their relationship isn't strictly linear. For instance, VGG16  has 17\(\) more parameters than ResNet-56  but only 3\(\) more _FLOPs_, largely due to VGG16's extensive use of fully connected layers. At first sight, this can be attributed to the differences in network topologies. From a deeper perspective, the intricacies of various operations at handling computational workloads, such as residual structures [17; 55], depthwise separable convolutions , inverted residual modules , channel shuffle operations  and shift operations , coupled with their interplay, may significantly affect the relationship between _FLOPs_ and _params_ in a neural network. In a nutshell, besides the use of more computationally efficient operations as abovementioned, Model Compression aims to maintain model performance while optimizing the two aforementioned metrics via tensor decomposition, data quantization, and network sparsification .

In this paper we emphasize on the sparsification strategy of pruning , which we use as a basis framework to introduce **"Expressiveness"** as a new criterion for compressing neural networks. Existing pruning methods focus on removing redundant network elements - be they weights, neurons, or structures of neurons - in ways that minimally affect the overall performance of a network, based on the criterion of **"Importance"**, e.g. [38; 58; 20; 30]. Importance-based methods address questions like "How much does the removal of a network's element cost in terms of performance degradation?" and "How much information does a network element contain?" in various ways. More specifically, they are motivated by the information inherent in network elements, such as the magnitude of weights [15; 28], similarity of weights or weight matrices [29; 60] ; and their sensitivity to the network's loss function, such as the magnitude of gradients  and more [49; 3]. Such dependencies on weights' distributions constitute the aforementioned pruning methods to be "data-aware" since they intrinsically rely on the input data and the information state of the model, making the importance estimation of the network's elements challenging and often costly due to factors like i) the stochasticity from training with minibatches, ii) the presence of plateau areas in the optimization space, and iii) the complexity introduced by nonlinearities . Liu et al.  have also discussed limitations in the perception of importance within trained models, i.e. the authors criticize the ability of network's elements importance to generalize to pruned derivatives, while also questioning the necessity of training large-scale models prior pruning.

Inspired by the concepts of "Information Plasticity"  and the "Lottery Ticket Hypothesis" (LTH) , we aim to address the limitations of previous importance-based methods through elaborating the "Expressiveness" criterion in model compression. In contrast to "Importance", we focus on understanding the capability of network elements to redistribute informational resources to subsequent network elements. We define "Expressiveness" as - _"A neuron's or group's of neurons potential (when a network is not fully trained) or ability (when it is trained) to extract features that maximally separate different samples"_. As derived by , the early training phase of a model is crucial in shaping its expressiveness, with the formation of critical paths --strong connections that determine the "workload distribution"-- being particularly significant during these initial stages. It's essential to note that the network's initialization state influences the formation of those paths, which interestingly enables "Expressiveness" to be a fit criterion for compression during all time instances of a networks' convergence , setting a baseline for answering the question of "When to prune?" . _Our proposed pruning metric centers on measuring the overlap of activations between datapoints of the feature space_. In that way, expressiveness is based on effectively evaluating the inherent ability of the network's neurons to differentiate sub-spaces within the feature space. We experimentally show that utilizing either small sets of arbitrary data points from the feature space or stratified sampling  from each class yields consistent estimations of expressiveness. Finally, we propose and implement a new "hybrid" pruning optimization strategy that cooperatively searches, exploits and characterizes the complementary benefits between "Importance" and "Expressiveness" for model compression. In summary, this work offers the following four-fold contribution: (i) we propose Expressiveness, a novel criterion based on the overlap of activations for model compression; (ii) we provide an in-depth theoretical analysis of both the fundamental principles and the technical intricacies of the proposed criterion; (iii) we validate the hypothesis that Expressiveness can be approximated with little to none input data, opening the road for data-agnostic pruning strategies; and (iv) through extensive experimentation we offer a thorough comparison w.r.t to both foundational and state-of-the-art methods demonstrating the efficiency and effectiveness of the proposed technique in model compression, while also examining the feasibility and effectiveness of a "hybrid" expressiveness-importance pruning strategy.

Specifically, we validate "Expressiveness" on the CIFAR-10  and ImageNet  datasets using a variety of models with different design characteristics [44; 17; 45; 21; 19]. We demonstrate the superiority of our novel criterion over existing solutions, including many top performing structural pruning methods [31; 61; 58; 32; 23; 46; 11], and show significant params reduction while maintaining comparable performance. We experimentally explore and analyze the complementary nature of expressiveness and importance, showing that summary numeric evaluation provides up to 10x additional parameter compression ratio gains, with an average of 1% loss decrease w.r.t group \(\)1-norm . Finally, we experiment on the current state-of-the-art computer vision model (YOLOv8 [9; 22]), showcasing notable compression rates of 53.9% together with performance gains of 3% on the COCO dataset , and highlighting the ability of more expressive neurons to better recover lost information from the pruning operation.

## 2 Related Work

**Weight (Non-Structural) Importance.** Han et al. [15; 14] and Guo et al.  approached the importance of weights based on their magnitude, removing connections below given thresholds. However, earlier works [25; 16] emphasized on the Hessian of the loss and have questioned whether magnitude is a reliable indicator of weight's importance, as small weights can be necessary for low error. In this direction, several studies [4; 47; 41; 8] have proposed strategies of iterative magnitude pruning, in the form of "adaptive weight importance", where weights are ranked based on their sensitivity to the loss. From a different perspective, Yang et al.  address the limitations of individual weight's saliency that fail to account for their collective influence and provide a formulation of weight's importance based on the error minimization of the output feature maps. Expanding on this concept, Xu et al.  propose a layer-adaptive pruning scheme that encapsulates the intra-relation of weights between layers, focusing on minimizing the output distortion of the network. Amongst other factors and limitations (as also discussed in 1), weight importance is very expensive to measure, mainly because of the increased complexity induced by the mutual influences of the weights among interconnected neurons. This, coupled with the requirement for specialized hardware to manage the irregular sparsity patterns resulting from weight pruning , has shifted research focus towards structural pruning , where neurons or entire filters are removed.

**Neuron and Filter (Structural) Importance.** Many where driven by the success of Iterative Shrinkage and Thresholding Algorithms (ISTA)  in non-structural sparse pruning and proposed filter-level adaptations [28; 29; 32; 26], based on the relaxation (\( 1\) and \( 2\)) of \( 0\) norm minimization. However, the loss of universality of such magnitude-based methods remains a limitation in the approximation of importance even in the structural scope. Yu et al.  further elaborate on the idea of error propagation ignorance, where the analysis is limited to the statistical properties of a single [28; 29] or two consecutive layers . The authors suggest that the importance of neurons is better approximated from the minimization of the reconstruction error in the final response layer from which it is propagated to previous layers. In contrast to this view, Zhuang et al.  emphasize on the discriminative power of a filter as a more effective measure of importance and highlight that this aspect is not effectively assessed by the minimization of the reconstruction error. In a manner that reflects the progression of weight importance, Molchanov et al.  define "adaptive filter importance" as the squared change in loss and apply first and second-order Taylor expansions to accelerate importance's computations. Predominantly, the data-awareness imposed by most pruning strategies is added to their already high-complexity - i.e. mostly non-convex, NP-Hard problems that require combinatorial searches. This renders the estimation of importance both computationally expensive and labor-intensive, similarly to non-structural approaches. Notably, Lin et al.  propose a less data-dependent solution based on the observation that the average rank of multiple feature maps generated by a single filter remains constant. HRank , alongside several other feature-guided filter pruning approaches, are valuable indicators towards data independence. Such works form a principle that pruning elements are better evaluated in the activation phase, where the importance of information and the richness of characteristics for both input data and filters are better reflected. In this work, we expand on this belief and we through extensive experimental analysis, we demonstrate that neither the information state nor the input data is required for the discriminative characterization of an element.

## 3 Neural Expressiveness

### Weights and Activations: Importance vs Expressiveness

Neurons are the main constituent element of a neural network. Given a neural network \(\), we denote neurons by \(a_{i}^{(l)}\), where \(l{}L\) is indicative of the neuron's layer in a network with \(L=\{l_{0},...,l_{l},...,l_{|L|}\}\) layers and \(i\) of its position in the given layer \(l=\{a_{0},...,a_{i},...,a_{|l|}\}\). Another important element are the learning parameters of the network. Otherwise the weights represent the strength of connections between neurons in adjacent layers and are denoted by \(w_{ij}^{(l)}\), where \(i\) and \(j\) index the neurons in the current and previous layers. In that manner, neuron's can be perceived as switches that allow or block information from propagating through-out a network. The activation (or not) of a neuron \(a_{i}^{(l)}\) depends on the output value of its activation function \(()\), where there are many popular options for the definition of \(\), e.g., sigmoid, tanh, and ReLU functions. Specifically, a neuron's output is defined as follows,

\[a_{i}^{(l)}=(_{j}w_{ij}^{(l)}a_{j}^{(l-1)}+b_{i}^{(l)})\] (1)

where \(b_{i}^{(l)}\) denotes the bias term. From eq. 1, we observe that a neuron's activation is affected by the activation of the previous layers, hence affecting in the same way the consecutive layers. This interdependence between activations \(a^{(l)}\), for a given layer \(l\) defines a recurrent form that can be generalized as follows,

\[a^{(l)}=(W^{(l)}f(a^{(l-2)},,a^{(1)})+b^{(l)} ).\] (2)

On the other hand, weights are a more static representation of information as they modulate how much influence one neuron's activation has on another's, compared to activations that control the flow of information in a network. This differentiation has motivated us to define two axes of study in the categorisation of pruning criteria, one based on the weights ("importance") and one based on the activation phase ("expressiveness").

Generalization of concepts in a structural level.The aforementioned principles extend to the structural representations of weights and activations, the most common being Convolutional Neural Networks (CNNs). For a CNN model with a set of \(K\) convolutional layers, where \(C^{l}\) is the \(l-th\) convolutional layer. We denote filters (weight maps) and feature maps (activation maps) as \(F_{k}^{l}\) and \(C_{k}^{l}\) respectively, where \(k\) the is index within a layer. Given filter with dimensions \(m n\), eq. 1 is adapted as follows,

\[C_{k}^{(l)}(x,y)=(_{i=1}^{m}_{j=1}^{n}F_{ij}^{(l,k)}a_{x+i- 1,y+j-1}^{(l)}+b_{k}^{(l)})\] (3)

where \((i,j)\) and \((x,y)\) are the coordinates of weights and output activations within the filter and the output activation map respectively. Similarly, a convolution layer \(l\) can be analyticaly expressed as follows,

\[C^{(l)}=(_{k=1}^{K^{(1)}}F^{(1,k)} X+B^ {(1)})&l=1\\ (_{k=1}^{K^{(1)}}F^{(l,k)} C^{(l-1)}+B^{(l)})& l>1\] (4)

with \(X\) being the input to the first layer of the network, and where symbol \(\) denotes convolution operation and \(\) denotes the concatenation operation. Within this context1, eq. 2 is generalized as follows,

\[C^{(l)}=(_{k=1}^{K^{(l)}}F^{(l,k)} f(C^{(l-2)}, ,C^{(1)})+B^{(l)}).\] (5)

Conceptualization of information propagation.Consider a task with \(X=\{x_{i}\}_{i=1}^{|D|}\) denoting dataset samples, where \(|D|\) is the size of the dataset. Given the information state (weight state) of a CNN model with \(K\) convolutional layers at a given time \(t_{i}\), X is mapped through the network as \(f(X,W_{t_{i}})\), where \(W_{t_{i}}=\{F_{t_{i}}^{1},,F_{t_{i}}^{l},,F_{t_{i}}^{|K|}\}\) and \(F_{t_{i}}^{l}=\{F_{t_{i}}^{(l,1)},,F_{t_{i}}^{(l,k)},,F_{t_{i}}^{ (l,K^{(l)})}\}\), with \(K^{(l)}\) being the amount of weight maps (filters) in a given layer \(l\). This process can be further analyzed as follows,

\[f(X,_{t_{i}})=_{|K|}(_{|K|-1}(_{1}(X;_{t_{i}}^{1});_{t_{i}}^{2});;_{t_{i}}^{ |K|}),\] (6)

where \(_{l}\) represents the mapping operation of convolutional layer \(l\).

Based on eq. 2 and eq. 5, the equivalent of the previous based on the activations of the layers can be expressed as,

\[f(X,_{t_{i}})=C^{(|K|)}((C^{(2)}(C^{(1)}( X,_{t_{i}}^{1}),_{t_{i}}^{2})),_{t_{i}}^ {|K|}).\] (7)Here, \(C^{(l)}\) represents the activation map of the \(l\)-th layer, where \(C^{(l)}=_{l}(C^{(l-1)};_{t_{i}}^{l})\) aligns with the structure defined in eq. 4. In this formulation, \(C^{(1)}\) is the activation map of the first layer, computed using the input \(X\) and the first layer's filters \(_{t_{i}}^{1}\). Subsequent layers' activation maps \(C^{(l)}\) are derived from the previous layer's output \(C^{(l-1)}\) and their respective filters \(_{t_{i}}^{l}\). Assuming a classification task, the final layer \(C^{(|K|)}\) is considered the classification layer, effectively summarizing the hierarchical feature extraction and transformation process across all convolutional layers.

### Mathematical Foundation of Neural Expressiveness.

We observe that the training parameters of the model, in this case \(W_{t_{i}}\)2, are responsible for transforming the original input feature space \(X\) into a sequence of intermediate feature spaces\(\{C^{(1)},,C^{(|K|-1)}\}\), progressing towards the final prediction formulated by the prediction layer \(C^{(|K|)}\).

Based on this intrinsic characteristic of neural networks and inspired by the goal of optimizing feature discrimination, akin to the entropy reduction strategy in decision trees , we assess network elements ability, in this scenario filters, to extract features, i.e., activation patterns, that maximally separate different input samples \(x_{i}\). In other words, we score the expressiveness of the filters within \(W_{t_{i}}\), based on the discriminative quality of the intermediate feature spaces they generate, where the feature space generated by a filter \(F_{k}^{l}\), is denoted as \(C_{k}^{l}\).

Neural Expressiveness foundational concept.When assessing the expressiveness of an element within \(W_{t_{i}}\) based on its generated feature spaces, e.g., \(NEXP(F_{t_{i}}^{l};C^{l})\), we cooperatively evaluate all of its preceding elements, as derived from eq. 5. This can be formulated as,

\[NEXP(F_{t_{i}}^{l};C^{l})=NEXP(F_{t_{i}}^{l};(C^{(l-1)},C^{(l-2)},,C^{(1 )})),\] (8)

which can be further extended to incorporate the inter-dependencies between the examined element and its predecessors, in accordance with eq. 7, as detailed below:

\[NEXP(F_{t_{i}}^{l};(C^{(l-1)},C^{(l-2)},,C^{(1)} ))=\] \[NEXP(F_{t_{i}}^{l};((C^{(l-2)},_{t_{i}}^{l-1 }),(C^{(l-3)},_{t_{i}}^{l-2}),,(X,_{t_{i}}^{1}) )).\] (9)

The aforementioned eqs. 8 and 9 provide the _foundational concepts for utilizing the evaluation of the activation phase_, in an endeavor to encourage the development of more universal solutions by addressing the limitations of universality inherent in the assessment of the weight state alone (as also discussed in sections 1 and 2).

Formulation of Neural Expressiveness (NEXP) Score.Diving deeper into the Neural Expressiveness (NEXP) scoring process, we follow eq. 9 previously and assume a mini-batch \(X^{{}^{}}=\{x_{i}^{{}^{}}\}_{i=1}^{N}\), with \(N\) being the number of samples in it. Mapping the batch through the network, based on eqs. 6 and 7, generates a set of sequences of feature spaces (activation maps), denoted as \(S=\{s_{1},,s_{i},,s_{N}\}\), where \(s_{i}=\{x_{i}^{{}^{}},,C_{i}^{l},,C_{i}^{|K|}\}\) is the sequence of the activation patterns generated from sample \(x_{i}^{{}^{}} X^{{}^{}}\) and \(|s_{i}|=|K|+1\) is its cardinality, including the feature space of sample \(x_{i}^{{}^{}}\). To evaluate a specific filter \(k\) in layer \(l\), denoted as \(F_{k}^{l}\), we utilize the retrieved activation patterns from that filter, denoted as \(\{s_{i,k}^{l}\}_{i=1}^{N}\), where \(s_{i,k}^{l}=C_{i,k}^{l}\) is the activation pattern retrieved from filter \(k\) in layer \(l\).

To score the Neural Expressiveness of \(F_{k}^{l}\), we first construct a \(N N\) matrix that expresses all possible combinations of the activation patterns derived from the different input samples. This table can be visualised as follows,

\[s_{(1,1),k}^{l}&s_{(1,2),k}^{l}&&s_{(1,N),k}^{l}\\ s_{(2,1),k}^{l}&s_{(2,2),k}^{l}&&s_{(2,N),k}^{l}\\ &&&\\ s_{(N,1),k}^{l}&s_{(N,2),k}^{l}&&s_{(N,N),k}^{l}.\] (10)where \(s^{l}_{(i,j),k}\) denotes the dissimilarity of activations patterns between the \(i\)-th and the \(j\)-th sample of the batch. In other words, the matrix in eq. 10 represents all the possible combinations of NEXP calculations, where each element \(s^{l}_{(i,j),k}\) derives from \(f(s^{l}_{i,k},s^{l}_{j,k})\), with \(f\) being any dissimilarity function. Without loss of generality, for the rest of the study, we use the Hamming distance as the operator implementing dissimilarity function. Activations are first binarized (values greater than 0 become 1, and the rest become 0), i.e. enabling to evaluate the degree of overlap between the binary activation patterns using \(f\).

We note that the matrix's diagonal, where \(i\) equals \(j\), along with the elements below the diagonal, where \(i\) is greater than \(j\), do not contribute additional value to quantifying the discriminative ability of an element. The diagonal elements represent comparisons of the same sample's activation patterns, rendering them redundant. Meanwhile, the lower triangular elements are considered duplicates since \(s^{l}_{(i,j),k}\) is equal to \(s^{l}_{(j,i),k}\), thereby not adding any new information. Drawing from these two observations, we define the Neural Expressiveness score (NEXP) as follows,

\[NEXP(F^{t}_{k})=}_{i=1}^{N}_{j=i+1}^{N}f(s^{ l}_{i,k},s^{l}_{j,k})\] (11)

The **more similar** the activation patterns derived from an element are, the **less expressive** it is declared to be. In eq. 11, we also normalize the score w.r.t the total amount of combinations (\(\)), thereby deriving the average expressiveness score. This average score is then utilized to characterize the discriminative capability/capacity of the examined network element. In this study, we used the mean operation, however, we note that alternate statistical measures, e.g., minimum, maximum, median, etc., could feasibly be applied in the computation of the overall score.

### Dependency to Input Data

NEXP evaluates the inherent property of network elements to maximally distinguish between input samples. We extend this line of thought and assess its sensitivity to input data \(X\) and mini-batch size \(N\), in order to delineate the dependence between NEXP and the input data. To achieve that, we perform a sensitivity analysis of NEXP to the mini-batch data \(X\), using two input sampling strategies to assemble a batch with 60 samples, namely random sampling (denoted as 'random') and class-representative sampling via k-means (denoted as 'k-means'). We define the true NEXP score (denoted as 'non-approx') for each filter as the value obtained by comparing all activation patterns across the _entire training dataset_ (more info in A.1). Fig. 1 presents a detailed comparative illustration of the results that highlight the similarities in NEXP estimations across various trained networks, including VGGNet , ResNet , MobileNet  and DenseNet  on CIFAR-10 dataset. Columns represent the aforementioned sampling strategies, while colors indicate expressiveness levels, with higher values signifying greater expressiveness. In each sub-figure, the x-axis indicates

Figure 1: **Expressiveness statistics of feature maps from different convolutional layers and architectures on CIFAR-10.**

[MISSING_PAGE_FAIL:7]

show +1.21\(\) average params reduction gains in the 2.87\(\)-3.27\(\) FLOPs reduction regime, with -0.67% and +0.26% percentage difference in loss respectively to ABC  and HRank . Similar observations are evident across all tables, where in certain regimes we also show notable performance gains, up to +1.5%, especially for VGGNet, which is more prone to params reductions due to its plain structure.

Object Detection with YOLOv8.We evaluate expressiveness against four importance based methods, i.e layer-adaptive magnitude-based pruning (LAMP) , network slimming (SLIM) , Wang's et al. proposed method (DepGraph)  and random pruning that serves as a generic pruning baseline . The experiments were conducted on the YOLOv8m model version , utilizing the DepGraph pruning framework  with an iterative pruning schedule of 16 steps, where after each pruning step the model was fine-tuned for 10 epochs using the coco128 dataset.

Outcomes and Discussion.We report the comparative pruning progress of expressiveness versus the baseline methods, i.e. the remaining percentage of the original model in terms of _MACs_ and _params_ after each pruning step, named MACs Size Percentage (MSP) and Parameters Size Percentage (PSP) respectively, and highlight the \(mAP_{50-95}^{val}\) both after pruning (pruned mAP) and fine-tuning (recovered mAP). We observe that expressiveness outperforms the rest of the reported methods across the whole pruning spectrum, as shown in Fig. 2 (more in Appendix D.2), preserving the initial performance of the model for percentage sizes that reach up to 40% (\(2.5\)) of that of the original model, with less than 0.5% of recovered performance degradation. Our method even achieves a 3% increase in recovered mAP for 46.1% MSP (\(2.17\)), in comparison to the baselines that showcase weak recovery capabilities after the 60% (\(1.67\)) mark in both MSP and PSP. This can be attributed to the intrinsic property of expressiveness to maintain network elements that are more robust to information redistribution, in contrast to "important" labeled structures by other methods. In our experimental scenario, that characteristic is further amplified by the iterative pruning format and the higher amount of fine-tuning epochs at each step, in comparison to conventional pruning schedules that fine-tune for 1 epoch after each iteration or perform a unified fine-tuning session after the last pruning iteration. Interestingly, our criterion also demonstrates significant resistance to performance loss after pruning, achieving 18% increased average performance in terms of pruned mAP compared to the importance-based methods. We have empirically observed that expressiveness benefits from increased cardinality in pruning granularity settings, e.g amount of intermediate steps to achieve a given compression ratio. This stems from expressiveness interactive nature of all elements, as also explained in Sec. 3, where smaller pruning steps combined with iterative fine-tuning, enhance pruning precision and allow for "smoother" redistribution of information in a network, thus contributing to the increased resistance to performance deficits after each pruning step.

### Assessing Hybrid Compression space

In this section, we assess the potential efficiency of "hybrid" pruning strategies exploiting the cooperation between importance and expressiveness. We explore the solution space of "hybrid" compression, using a linear combination of importance and neural expressiveness criteria. We guide exploration through the scoring function: \(W_{}+W_{}\) and conduct experiments with

    &  &  \\  & Base (\%) & \(\) (\(\%\)) & \#Params & \#FLOPs \\  L1  & 93.06 & +0.02 & 1.16\(\) & 1.37\(\) \\ NEXP (Ours) & 93.36 & +0.05 & **1.69\(\)** & 1.53\(\) \\ GAL-0.6  & 93.26 & +0.12 & 1.13\(\) & 1.60\(\) \\ NISP-56  & - & -0.03 & 1.74\(\) & 1.77\(\) \\  DCP-Adap  & 93.80 & +0.01 & 3.37\(\) & 1.89\(\) \\ HRank  & 93.26 & -0.09 & 1.74\(\) & 2.01\(\) \\ SCP  & 93.69 & -0.46 & 1.94\(\) & 2.06\(\) \\ NEXP (Ours) & 93.36 & -0.41 & 2.87\(\) & 2.11\(\) \\ ABC  & 93.26 & -0.03 & 2.18\(\) & 2.18\(\) \\  NEXP (Ours) & 93.36 & -1.58 & **4.3\(\)** & 2.50\(\) \\ GAL-0.8  & 93.26 & -1.68 & 2.93\(\) & 2.51\(\) \\  HRank  & 93.26 & -2.54 & 3.15\(\) & 3.86\(\) \\ NEXP (Ours) & 93.36 & -5.12 & **21.5\(\)** & 5.00\(\) \\   

Table 1: Analytical Comparison of Importance-based solutions and Expressiveness on CIFAR-10 using ResNet architectures  - ResNet-56 (left) and ResNet-110 (right).

various weight combinations, subject to the constraint \(W_{}+W_{}=1\). Given that exhaustive search is impractical, we introduce the hyper-parameter \(\{0.0,0.2,,0.8,1.0\}\) to restrict the set of permissible combinations, and modify the constraint to \((1-) W_{}+ W_{}=1\). We use group L1-norm  as the importance criterion (IMP) and assess all permissible combinations across a linear scale, denoted as \(\), representing the target FLOPs compression ratios that we utilized for pruning, on ResNet-56 for CIFAR-10. The outcomes are visualized in Figure 3, which maps our predetermined \(\) values on the x-axis against the various parameter compression ratios achieved by each combination. Regarding performance, we report the averaged percentage differences in top-1 accuracy between the baseline importance method (L1) and each hybrid format: -0.21% for hb-0.2, -0.96% for hb-0.4, -1.55% for hb-0.6, -1.07% for hb-0.8, and -2.18% for NEXP.

**Observations.** A consistent pattern is observed across the values of \(\), where larger values yield higher params compression ratios. Notably, hybrid derivatives allow us to explore sub-spaces with higher parameter compression ratios by sacrificing slight performance accuracy. We also observe that the solution vectors corresponding to IMP and EXP act as extremal points in the solution space of hybrid combinations, thus suggesting a degree of partial orthogonality between the two criteria. Furthermore, the findings reveal a polynomial relationship between parameter compression ratios and FLOPs reduction, with compression ratios increasing polynomially to linear increments in FLOPs reduction, and thus enabling more efficient explorations.

### Evaluating Neural Expressiveness at Initialization

The nature of NEXP allows to be applied in a weight agnostic manner, i.e. on untrained networks. An extended version of the section's 3.3 analysis, which also includes untrained models (Appendix A), reveals that \(NEXP_{}\)'s obtained at initialization and after network convergence share some expressiveness pattern similarities, particularly in the initial layers. Our numeric evaluation shows a notable correlation between the initialization and converged states for DenseNet-40 and VGG-19, with cosine similarities of 84.10% and 86.82%, respectively. It also indicates greater consistency in neural expressiveness measurements for the first layers of all networks, which could be considered important for the formation of critical paths . Motivated by these observations, we also assess the efficacy of expressiveness as criterion for Pruning at Initialization against various SOTA approaches  (Appendix D.1). Our method consistently outperforms (in terms of top-1 acc) all other algorithms, particularly in regimes of lower compression, up to \(10^{2}()\) with an average increase of 1.21% over SynFlow, while maintaining competitiveness at higher compression levels, above \(10^{2}()\) with an average percentage difference of 4.82%, 3.72% and -2.74%, compared to  and . In summary, under the assumption that the selection of hyperparameters remains congruent with the initialization , consistent map measurements between initial and final states can effectively evaluate NEXP's ability to identify winning tickets. However, a robust evaluation should also consider the initial state quality and the training process, while addressing the "When to prune" question .

## 5 Conclusions

In this work, we have introduced "Neural Expressiveness" as a new criterion for model compression. In our NEXP steps, we will explore optimal solutions for the "When" and "How" to prune questions.

   Method &  &  &  \\  & top-1 & top-5 & top-1 & top-5 & \#Params \(\) & \#FLOPs \(\) \\  NISP-50-B  & - & - & -0.89 & - & 1.78\(\) & 1.79\(\) \\ NEXP (Ours) & 76.13 & 92.86 & -1.35 & -0.93 & 2.00\(\) & 2.02\(\) \\ ThNet  & 72.88 & 91.14 & -1.87 & -1.12 & 2.06\(\) & 2.25\(\) \\ DCP  & 76.01 & 92.93 & -1.06 & -0.56 & 2.06\(\) & 2.25\(\) \\ ABC  & 76.01 & 92.96 & -2.49 & -1.45 & 2.27\(\) & 2.30\(\) \\  NEXP (Ours) & 76.13 & 92.86 & -6.77 & -3.43 & **4.05\(\)** & 3.04\(\) \\ GAL-1-joint  & 76.15 & 92.87 & -6.84 & -3.75 & 2.50\(\) & 3.68\(\) \\ Harak  & 76.15 & 92.87 & -7.15 & -3.29 & 3.08\(\) & 4.17\(\) \\   

Table 2: Analytical Comparison of Importance-based solutions and Expressiveness on ImageNet-1k using ResNet-50 .

Figure 3: **Linear exploration of the combinatorial space between importance and expressiveness.**