# Optimal Algorithms for Learning Partitions with Faulty Oracles

Adela Frances DePavia

University of Chicago

adepavia@uchicago.edu

Olga Medrano Martin del Campo

University of Chicago

omedrano@uchicago.edu

Erasmo Tani

University of Chicago

etani@uchicago.edu

###### Abstract

We consider a clustering problem where a learner seeks to partition a finite set by querying a faulty oracle. This models applications where learners crowdsource information from non-expert human workers or conduct noisy experiments to determine group structure. The learner aims to exactly recover a partition by submitting queries of the form "are \(u\) and \(v\) in the same group?" for any pair of elements \(u\) and \(v\) in the set. Moreover, because the learner only has access to faulty sources of information, they require an error-tolerant algorithm for this task: i.e. they must fully recover the correct partition, even if up to \(\) answers are incorrect, for some error-tolerance parameter \(\). We study the question: for any given error-tolerance \(\), what is the minimum number of queries needed to learn a finite set partition of \(n\) elements into \(k\) groups? We design algorithms for this task and prove that they achieve optimal query complexity. To analyze our algorithms, we first highlight a connection between this task and correlation clustering. We then use this connection to build a Renyi-Ulam style analytical framework for this problem, which yields matching lower bounds. Our analysis also reveals an inherent asymmetry between the query complexity necessary to be robust against false negative errors as opposed to false positive errors.

## 1 Introduction

Learning cluster structure from data is a fundamental task in machine learning. While the statistical setting is typically concerned with using batch data to approximately recover cluster structure with high probability, some applications allow for the learner to make explicit queries, and some require exact recovery guarantees.

We highlight two key settings. In several scientific domains, particularly bioinformatics, researchers conduct physical experiments to learn whether two objects are part of the same class [9; 11; 20; 35]. Another major application is learning cluster structure by collecting information from human workers via crowdsourcing services [15; 30; 37]. While some traditional methods focus on querying workers for class labels, alternative approaches use simpler _same-cluster_ queries. For example, Vinayak and Hassibi  point out that, given images of birds, it may be easier for non-experts to correctly answer the question "Do these two birds belong to the same species?" as opposed to "What species does this bird belong to?" In both of these application domains, the learner typically seeks to minimize the number of queries made, as queries require carrying out potentially expensive measurements or time-consuming experiments.

We consider a very general setting and develop algorithms that make no assumptions about the specific type of data involved, but rather rely solely on the same-cluster queries to infer structure. In particular, we model this task by assuming that the algorithm only interfaces with the data via a _same-cluster oracle_. In this setting, the learner obtains information about a hidden partition \(\) of a finite set \(V\) by repeatedly choosing two elements \(u,v V\) and asking questions of the form "Areand \(v\) part of the same cluster?", i.e. given \(\) and \(V\), a same-cluster oracle is an oracle \(_{}\) that takes as input \(u\) and \(v\) in \(V\), and returns \(1\) if \(u\) and \(v\) belong to the same cluster in \(\), and \(-1\) otherwise. The power and limitations of same-cluster oracles have been studied in a variety of settings, including the clustering problem described above [8; 26; 33; 34].

However, previous work on this model makes the arguably unrealistic assumption that all queries return the correct answer. In the motivating applications, queries are often at risk of failure that results from relying on non-expert workers or suffering from experimental noise. The learner's goal is to recover the partition in spite of these errors. Such errors are also often not persistent: in the presence of noise, repeating an experiment multiple times may yield different answers, and querying different human workers may result in conflicting responses. Nonetheless, practitioners may need to achieve exact recovery of the underlying partition. However, existing theory either focuses on the error-free regime [26; 33], assumes that errors are persistent [16; 32], or focuses on probabilistic guarantees rather than exact recovery .

To address this literature gap, we study algorithms for partition learning via same-cluster oracles that are robust to non-persistent errors. A typical way to incorporate uncertainty and noise is to assume that errors occur independently at random with some small probability on every query. However, it is not possible to guarantee exact recovery of the underlying clusters in this model. Instead, we focus on a model in which the learner sets an error-tolerance parameter \(\), and they require guaranteed full recovery of the hidden partition as long as the error incurred is within this tolerance. In particular, we say a same-cluster oracle \(_{}\) is \(\)-faulty if it may return an incorrect answer up to \(\) times. We do not assume that errors are persistent: if a single pair of elements is queried repeatedly, an \(\)-faulty oracle may return inconsistent responses. We define the \(\)_-bounded error partition learning_ (\(\)-PL) problem, as the problem of exactly recovering a hidden partition via access to an \(\)-faulty same-cluster oracle.

We design algorithms for the \(\)-PL problem and related variants, and analyze their query complexity. We introduce a two-player game based on _correlation clustering_, and we show that the minimax value of this game is closely linked to the query complexity of the \(\)-PL problem. We then use this game as a framework to give tight lower bounds for the query complexity of this task, proving the proposed algorithms are optimal.

We find that the \(\)-PL problem occupies a unique position at the intersection of different research streams. In fact, the study of this problem complements work on clustering with same-cluster query advice, and the techniques used for its analysis draw from the theory of graph learning with oracle queries and the study of Renyi-Ulam liar games1. We are hopeful that the impact of these connections will go beyond the results presented in this paper.

### Background and related results

Clustering with same-cluster oraclesIn the error-free regime, Liu and Mukherjee  studied the query complexity of recovering partitions of a finite set in different oracle models. They prove tight lower bounds on the query complexity of learning partitions with error-free same-cluster oracles, and point out that an algorithm proposed by Reyzin and Srivastava  exactly achieves this query complexity.

In many motivating applications of this model queries may return the wrong answer, such as when labels result from non-expert human input or noisy scientific experiments. Vinayak and Hassibi  consider multiple query models for collecting information from human workers, pointing out that same-cluster queries can accomplish similar end goals as label queries while potentially being easier questions for non-experts to answer correctly. They also provide an algorithm that works for the setting in which triangle queries-which ask the worker to provide all pairwise relationships between three data points-are made. Mazumdar and Saha  initiate the formal study of clustering with same-cluster oracles in the presence of persistent i.i.d. errors. They point out that under these assumptions, learning a partition has a strong relationship to recovering community structure in the stochastic block model (SBM). This work inspired a productive line of research on the i.i.d. noise model, which also leverages connections to the SBM to study related problems. In fact, this problem has been studied in the setting when \(k=2\), when the underlying clusters are nearly-balanced , and in the semi-random noise model, in which errors occur with some i.i.d. probability, but when they do occur the (erroneous) answer may be chosen adversarially . Models for non-persistenterror have also been considered. Chen et al.  study same-cluster queries in the presence of i.i.d. error, allowing for repeated querying of pairs. They give an efficient algorithm with recovery guarantees that does not require a-priori knowledge of the probability of query failure. Similar results were also subsequently established in a recent paper by Gupta et al. . Our work complements this line of research by considering a setting in which exact recovery is possible in spite of errors and providing a full characterization of the query complexity of the problem in this setting.

Renyi-Ulam gamesIn his autobiography, Stanislaw Ulam, introduced the following two-player game . One player (the responder) thinks of a number in \(x[N]\) for some \(N\), and the other player (the questioner), given \(N\), tries to guess \(x\) by asking only yes/no questions. The main twist to this setup is that the responder is allowed to lie up to \(\) times. The term "Renyi-Ulam games" has since been used to identify a wide range of problems involving asking questions to an oracle who is allowed some limited amount of lying (see e.g. ). The question of finding the worst-case query complexity of the \(\)-PL problem can be naturally formulated as a Renyi-Ulam game, in which the learning algorithm takes the role of the questioner, and the oracle plays the part of the responder.

Correlation clusteringBansal et al.  introduced correlation clustering. In this problem, one is given a signed graph \(G=(V,E,)\), where \(:E\{ 1\}\) is a function representing one's prior belief about which pairs of vertices belong to the same cluster. The goal of the problem is to return a partition of the vertices of \(G\) into clusters that minimizes the amount of disagreement with the edge signs given by \(\). The problem is known to be NP-Hard. Many variations of problem have been proposed, including versions with weighted edges , a version where the number of clusters is constrained to some fixed \(k\), and an agreement maximization setting. Different assumptions have also been studied, such as instance stability and noisy partial information .

### Discussion of the Model

In the previous sections, we introduce a problem in which a learner has to exactly recover a hidden partition by making same-cluster queries that could be subject to up to \(\) errors. Other plausible models for learning partitions with errors could be considered. In this section, we discuss some of the key design features of the model and provide justification and examples.

In general, even in the regime in which \(k\) the number of clusters is known to the learner, it is not possible to recover the partition exactly unless one is able to resolve all but at most \(2\) of the pairwise same-cluster relationship between the elements. This follows from a result of Reyzin and Srivastava (this is a key idea leveraged in the proof of Proposition 3 in ). In particular, simple extensions of these core arguments imply that in the setting in which the answers to the queries are persistent, it is impossible to solve the problem even for small constant values of \(\). Furthermore, this implies that even in the non-persistent error-model, one cannot solve the problem for a value of \(\) that grows linearly with \(n\). Below, we give two general motivating examples, in the technology and scientific domains respectively, illustrating the role of \(\) in partition learning tasks.

Example 1: Robustness to MisinformationConsider a setting where a user is trying to cluster a dataset by crowdsourcing information in the form of same-cluster questions. However, the user suspects that an ill-intentioned competitor organization is attempting to corrupt the learning process by entering a number of bad actors in the crowd to strategically mislabel queries. If the user selects a new person every time they submit a query, then the number of adversarial answers they encounter is finite and does not grow with the number of queries submitted. In this scenario, \(\) plays the role of a security parameter, and the algorithm is guaranteed to be robust to up to \(\)-many poisoned responses. The user can set \(\) based on, e.g., their prior belief about the resources of the competitor organization. Our results can be interpreted as quantifying the cost (in queries / crowd size) of implementing a fixed security parameter \(\).

Example 2: Trustworthy ScienceConsider a setting in which a scientist is attempting to group items into classes by running experiments that reveal whether two items are in the same class, such as the example of clustering compatible molecules described in Gupta et al. . The scientist has limited resources (e.g. limited materials or time) and can only conduct a finite number of experiments. Our results allow the scientist to derive the maximum number of errors to which their learning procedure can be tolerant, given their fixed query budget. They can use this maximum value as the setting for \(\), and then use our algorithms to guide their choice of experiments. Our analysis would then allow them to measure the significance of their findings by quantifying the number of experiments that would need to have failed for the finding to be incorrect.

## 2 Technical preliminaries

Basic definitionsGiven a positive integer \(n\) we denote with \([n]\) the set \(\{1,...,n\}\). Given any finite set \(V\) we denote with \(\) the set \(\{\{i,j\} V i j\}\). A graph \(G=(V,E)\) is a pair containing a finite vertex set \(V\) and a subset \(E\). Given a finite set \(V\) a \(k\)-partition of \(V\) is a collection of \(k\) pairwise disjoint non-empty subsets \(=\{C_{1},...,C_{k}\}\) of \(V\) such that \(_{a=1}^{k}C_{a}=V\). We will denote by \(n\) the cardinality \(|V|\) of \(V\) and we may assume without loss of generality that \(V=[n]\). Given two elements \(u\) and \(v\) of \(V\), we write \(u_{}v\) (resp. \(u_{}v\)) for the statement \( C,\{u,v\} C\) (resp.\( C,\{u,v\} C\)). We denote by \([u]_{}\) the equivalence class of \(u\) with respect to \(\), i.e. \([u]_{}\) is the unique \(C\) containing \(u\). Given two partitions \(_{1}\) and \(_{2}\) we say \(_{2}\) is a _refinement_ of \(_{1}\) if for every \(C_{2}\) there is a \(C^{}_{1}\) such that \(C C^{}\).

## 3 A hierarchy of problems

In the introduction we consider learning a partition \(\) of a finite set \(V\) by asking questions of the form "Are \(u\) and \(v\) part of the same cluster in \(\)?", where up to \(\) of the answers may be incorrect. We refer to this as the \(\)-PL problem. We characterize the hardness of the \(\)-PL problem by considering a family of related tasks. In particular, we introduce a hierarchy of problems with different degrees of difficulty (see Figure 1) and establish matching upper lower bounds in nearly all of these tasks. We summarize our results in Table 1.

At the bottom of the hierarchy, we have the problem first studied by Reyzin and Srivastava  of learning partitions with same-cluster queries, where the answer to every query is guaranteed to be

  & Query Complexity \\  & \(k\)-known & \(k\)-unknown \\   Weighted \(\)-PL & \(RS^{k}(n,k)+\) (Thm. 1, 3, and 5) & \(ORS^{u}(n,k)+\) (\(n-k)\{_{},_{}\}+k^{2}_{}\) \\  \(\)-PL (Cor. 2 and 4, Thm. 5) & \((RS^{k}(n,k)+(n-k)+k^{2})\) & \((RS^{u}(n,k)+(n-k)+k^{2})\) \\  \(\)-PL(Thm. 1, 3, and 19) & \((RS^{k}(n,k)+k^{2})\) & \((RS^{u}(n,k)+(n-k)+k^{2})\) \\  \(\)-PL(Thm. 1, 3, and 21) & \((RS^{k}(n,k)+(n-k))\) & \((RS^{u}(n,k)+(n-k))\) \\  Error-Free (Results from [26; 33]) & \(RS^{k}(n,k)\) & \(RS^{u}(n,k)\) \\ 

Table 1: The query complexity of the different variants of the \(\)-PL problem, for both the \(k\)-known ad the \(k\)-unknown setting. We obtain matching upper and lower bounds for all the variants with the exception of the weighted \(\)-PL problem in \(k\)-unknown setting, for which the upper bound does not match the lower bound (given for the \(k\)-unknown case) exactly. The results are given in terms of the complexity \(RS^{k}(n,k)\) and \(RS^{u}(n,k)\) (defined in Equations 1 and 2) of solving the problem without errors.

correct. They give an algorithm that can learn the underlying partition with:

\[RS^{k}(n,k)}}{{=}}n(k-1)-\] (1)

many queries when the number \(k\) of clusters is known to learner and:

\[RS^{u}(n,k)}}{{=}}nk-\] (2)

when \(k\) is unknown to the learner. Recently, Liu and Mukherjee  showed that no algorithm can guarantee full recovery of the underlying partition in fewer that \(RS^{k}(n,k)\) (resp. \(RS^{u}(n,k)\)) queries when \(k\) is known (resp. unknown) to the learner, showing that the algorithms of Reyzin and Srivastava are optimal down to the exact constants. Since this is the "easiest" version of the problem we will be considering, the lower bounds of Liu and Mukherjee immediately imply the same lower bounds for all the other problems in the family.

We then consider two variants of this problem, each only admitting one-sided error. In the first variant, which we refer to as the \(\)_-bounded error partition learning with false positives_ (\(\)-PL\({}^{}\)) problem, the oracle might return the answer \(+1\) even when two elements are not part of the same cluster. We refer to this kind of fault as a _false positive_ answer. Here, we restrict the oracle to return at most \(\) many false positive answers, for some fixed positive integer \(\), and to always return \(-1\) when the two elements being queried are not part of the same cluster.

In the second variant, which we refer to as the \(\)-PL\({}^{}\) problem, the oracle behaves the opposite way, and it may return \(-1\) even if the two elements being queried are part of the same cluster in the hidden partition (a _false negative answer_), but it cannot return a false positive answer. Similarly to the previous variant, we restrict the number of false negative answers to be at most some fixed \(\). We give precise definitions of the \(\)-PL\({}^{}\) and \(\)-PL\({}^{}\) problems below.

The \(\)-PL problem is then a generalization of all of the three variants described above (false positives, false negatives and no error), and hence, it inherits hardness results from all three of these problems. Instead of directly designing an algorithm for the \(\)-PL problem, we consider a yet more general version of the problem, and use results from that generalized version to obtain algorithms for all of the other problems in the class. This final variant is a more fine-grained problem, which allows false positive answers and false negative answers to incur different penalties. In particular we consider a weighted version of \(\)-PL, which is formalized in the following definition:

**Definition 1** (\((_{},_{})\)-Faulty Oracle and Weighted \(\)-PL Problem).: Let \(V\) be a finite set, and \(\) be a partition of \(V\). A _\((_{},_{})\)-faulty oracle_ for \(\) is an algorithm \(_{}\) which, given as input a pair of elements \(uv\), returns a value \(r=\{ 1\}\) so that for any sequence of queries \(\{u_{t}v_{t}\}_{t[T]}\) the sequence of responses \(\{r_{t}=_{}(u_{t}v_{t})\}_{t[T]}\) satisfies:

\[_{C}v_{t} r_{t}=+1\}|}{_{}}+ _{C}v_{t} r_{t}=-1\}|}{_{}} 1.\]

Note that we assume the oracle can maintain an internal state, so its answers may depend on the query history. The _weighted_\(\)-PL problem asks one to recover an unknown \(k\)-partition of \(V\) given access to an \((_{},_{})\)-faulty oracle for \(\).

Observe that by setting \(_{}<1\) (resp. \(_{}<1\)) one would require the oracle to not return any false positive (resp. false negative) answer. As a convention, we will write \(_{}=0\) or \(_{}=0\) to indicate any setting that ensures the oracle may not return any false positive or false negative answers respectively. We note that, up to rescaling \(_{}\) and \(_{}\) by a factor of \(2\), this problem is equivalent to a version of the problem in which the oracle has separate constraints for the number of false positive answers and false negative answers, a simple fact which we prove in Appendix B.

Given this definition, the (unweighted) \(\)-PL can be cast as a homogeneous version of the above, one in which \(_{}=_{}\), as follows:

**Definition 2** (\(\)-Faulty Oracle and \(\)-PL Problem).: An \(\)-faulty oracle is an \((,)\)-faulty oracle. The \(\)-PL problem is the problem of learning a partition with access to an \(\)-faulty oracle.

The \(\)-PL\({}^{}\) and \(\)-PL\({}^{}\) problems discussed above can now be formally described as special instances of the weighted \(\)-PL problem.

**Definition 3** (\(\)-PL\({}^{}\) Problem and \(\)-PL\({}^{}\) Problem).: The \(\)-PL\({}^{}\) problem is the problem of learning a partition with access to an \((,0)\)-faulty oracle. Intuitively, this corresponds to the problem of learning partitions subject to at most \(\) false-positive responses and no false negatives. The \(\)-PL\({}^{}\) problem is the problem of learning a partition with access to an \((0,)\)-faulty oracle. This corresponds to learning partitions subject to at most \(\) false-negatives responses and no false positives.

In the rest of the paper, we will always assume that the set \(V\), its cardinality \(n\), and the parameters \((_{},_{})\) are known to the learner. We will consider both the \(k\)-_known_ setting, in which the number \(k\) of clusters is known to learner, and the \(k\)-_unknown_ setting, in which it is not. It is easy to see that the query complexity of every problem in the \(k\)-unknown setting is no smaller than that of the same problem in the \(k\)-known setting, since any learning algorithm could simply ignore the value of \(k\). We design separate algorithms for the \(k\)-known and the \(k\)-unknown setting, while the lower bounds, which we only prove for the \(k\)-known setting, apply directly to the \(k\)-unknown setting.

In the next section we describe a number of algorithmic results to solve variants of the \(\)-PL problem. In particular, Theorem 1 describes the performance of an algorithm for the weighted \(\)-PL problem in the \(k\)-known setting. We briefly comment that it is actually not necessary for the number of false negatives \(_{}\) to be bounded or known in advance in order to run this algorithm and achieve optimal query complexity. Rather the value of \(_{}\) that appears in the query complexity analysis will be the true number of false-negative responses that occur during the execution of the algorithm. In particular, this implies that in the version of the problem in which no false positives can occur, one does not need to set any upper bound on the error at all. In contrast in the \(k\)-unknown setting, in order to achieve the bound described in Theorem 3 our proposed algorithm does require a user-chosen value for \(_{}\). Here, a simple argument shows that it is impossible to guarantee one has found the correct answer unless they can upper bound both \(_{}\) and \(_{}\).

## 4 Algorithmic results

Our first result is an algorithm for the weighted \(\)-PL problem in the \(k\)-known setting.

**Theorem 1**.: _There exists an algorithm for the weighted \(\)-PL problem which recovers the full partition \(\) in the \(k\)-known setting with query complexity bounded by_

\[O(RS^{k}(n,k)+(n-k)_{}+k^{2}_{}).\]

We observe an asymmetry in the dependence on \(_{}\) and \(_{}\) respectively, indicating that false-negative and false-positive errors cause the algorithm to incur different costs. In Section 5 we prove lower bounds showing that this is not a mere artifact of the algorithm or its analysis, but rather a fundamental aspect of the problem.

We describe the algorithm and prove Theorem 1 in Section 6. Throughout the paper, when considering the \(k\)-known setting, we shall assume that \(k\{1,n\}\), for otherwise the problem is trivially solved without the need to query the oracle. Because the weighted \(\)-PL problem generalizes the \(\)-PL problem, this yields an algorithm for the \(\)-PL problem as well:

Figure 1: The lattice of problems considered in this paper. Algorithmic results propagate from left to right while lower bound results propagate right to left.

**Corollary 2**.: _There exists an algorithm for the \(\)-PL problem which learns the correct partition in the \(k\)-known setting with query complexity bounded by_

\[O(RS^{k}(n,k)+(n-k)+k^{2}).\]

As our final algorithmic result, in Section D we show that the algorithm can be adapted to obtain optimal asymptotic performance for the \(\)-PL problem in the \(k\)-unknown setting.

**Theorem 3**.: _There exists an algorithm for the weighted \(\)-PL problem which recovers the full partition \(\) in the \(k\)-unknown setting with query complexity bounded by_

\[O(RS^{u}(n,k)+(n-k)\{_{},_{}\}+k^{2} _{}).\]

An immediate corollary bounds the query complexity of the \(\)-PL problem in the \(k\)-unknown setting.

**Corollary 4**.: _There exists an algorithm for the \(\)-PL problem which learns the correct partition in the \(k\)-unknown setting with query complexity bounded by_

\[O(RS^{u}(n,k)+(n-k)+k^{2}).\]

In the following section we show that all the bounds discussed in this section are asymptotically optimal. While the results are stated only asymptotically, we note that the upper bounds we obtain are only a small constant factor away from the lower bounds, and we give the exact upper bounds in Section D, where we prove Theorem 3.

## 5 Lower bound techniques: correlation clustering and the chip-liar game

Underlying our lower bound analysis is a connection between partition learning problems, Renyi-Ulam and Chip-Liar games, and correlation clustering. The Renyi-Ulam game, as defined in the background is equivalent to the following Chip-Liar game (see e.g. Chapter 15, in the book of Alon and Spencer ). In the game, \(N\) chips, numbered \(1\) to \(N\) are placed on a game board that has \(+1\) positions, labeled \(0,,\). At the start of the game, all of the chips begin at position \(0\) on the board. The game takes place in rounds. On each round the questioner player \(Q\) selects a subset \(S\) of the chips, and the responder player \(R\) decides on one of the following moves: they can either increase the position of every chip in \(S\) by \(1\), or increase the position of every chip in \(\) by \(1\). If a chip at position \(\) is in a group whose position is advanced, the chip is said to _have fallen off the board_. After this point such chips will no longer advance. The rules of the game constrain \(R\)'s responses; \(R\) must ensure that on every round, at least one chip remains on the board at position \(i\). The game terminates when there is a unique chip remaining on the board.

Note that one can think of the \(\)-PL problem as a constrained version of this Chip-Liar game. In the \(k\)-known setting2, the chips are equivalent to \(k\)-partitions of the finite set \(V\), so that the number \(N\) of chips is the Stirling Number of the second kind \(N=}{0.0pt}{}{n}{k}\). Moreover, unlike the general Chip-Liar game, in our setup the questioner may only select specific subsets \(S\): for any pair of elements \(u,v V\), the questioner can select \(S\) to be the set of all partitions in which \(u\) and \(v\) are part of the same cluster. When the questioner submits a query ("Are \(u\) and \(v\) in the same group?"), all chips whose partitions are inconsistent with the response advance by one position on the board.

This allows one to adopt the following perspective. One may think of the queries \(\{u_{t}v_{t}\}_{t[T]}\) made by the questioner together with the signs given by the responses to the queries as making up an instance of the correlation clustering problem. The position of a chip on the board will then be equal the cost of the corresponding partition as a solution of the correlation clustering instance constructed. In Appendix E.1 and Appendix E.2, we formalize this intuition by defining _Renyi-Ulam Correlation Clustering_ (RUCC) games, which are the key tools we use to lower bound query complexity.

Leveraging the above techniques, we lower bound the query complexity of the \(\)-PL\({}^{}}\) and \(\)-PL\({}^{}}\) problems. Combining these lower bounds with results in the error-free regime yield the following lower bounds on the \(\)-PL problem.

**Theorem 5**.: _Every algorithm for the \(\)-PL problem requires at least:_

\[(\{RS(n,k),(n-k), k^{2}\})\]

_queries both in the \(k\)-known and in the \(k\)-unknown setting. Moreover every algorithm for the weighted \(\)-PL problem requires at least:_

\[(\{RS(n,k),_{}(n-k),_{}k^{2}\})\]

_queries both in the \(k\)-known and in the \(k\)-unknown setting. Here \(RS(n,k)\) represents \(RS^{k}(n,k)\) in the \(k\)-known setting, and \(RS^{u}(n,k)\) in the \(k\)-unknown setting._

This theorem is a corollary of Theorems 19 and 21, which we prove in Appendix F.1 and Appendix F.2.

Intuitively, the difference in complexity we observe between the case of false negative errors and the case of false positive errors is due to the following. On one hand, certifying the existence of \(k\)-clusters using positive answers requires building a spanning forest, which has \((n-k)\) edges. On the other hand, accomplishing the same task using negative answers requires constructing a clique on \(k\) vertices which requires \(O(k^{2})\) edges. This intuition is made precise in Section E in the proofs of Theorem 19 and 21 respectively.

## 6 Algorithm for weighted \(\)-PL with \(k\)-known

In this section we give an algorithm that solves the weighted \(\)-PL problem in the \(k\)-known setting with asymptotically optimal query complexity. We later adapt this algorithm to the \(k\)-unknown setting in Appendix D.

We begin by briefly providing intuition for the algorithm. The algorithm maintains \(^{}\) a refinement of the correct hidden partition \(\). At the start of the algorithm \(^{}\) is the set of all singleton elements in \(V\). The algorithm repeatedly makes sequences of queries that guarantee progress towards either (a) learning \(\), in the form of establishing that a pair of vertices \(u\) and \(v\) must be part of the same cluster, or (b) certifying that an error has occurred in the oracle's responses.

In particular, the algorithm repeatedly attempts to construct \((k+1)\)-cliques of \(-1\) responses. If at any point the oracle responses form such a clique, then a false-negative response must have occurred, as vertices in \(V\) belong to at most \(k\) distinct clusters (note that \(k\) is assumed to be known to the algorithm). In this case, the algorithm has certified a false-negative response. On the other hand, the only way that this process may be interrupted is if the algorithm receives a \((+1)\) response to some query \(uv\). However, if such a positive response is received, repeatedly querying the pair \(uv\) will either quickly determine that \(u\) and \(v\) must be part of the same cluster or it will reveal that an error has occurred. In the first case, the algorithm makes progress towards learning \(\), and in the second case it has certified the occurrence of an error.

We provide the pseudocode for the algorithm and describe in prose the main functions of each subroutine. The algorithm is comprised of subroutines Learn, Get_New, Insert and Compare:

LearnThis is the core component of the algorithm. It maintains a partition \(^{}\) for \(V\). Throughout the algorithm, \(^{}\) is guaranteed to be a refinement of the true hidden partition \(\). \(^{}\) is initialized as the set of singletons for every element in \(V\). The algorithm then repeatedly tries to construct a clique of negative answers, supported on some set \(S V\) until \(|S|=k+1\). It does so by inserting new vertices \(v\) into \(S\) by calling the subroutine Insert. Insert may then either make progress towards constructing the clique (by increasing the size of \(S\)) or towards learning the hidden partition by decreasing the size of \(^{}\) (merging two clusters together).

Get_NewGiven \(S V\) and \(^{}\) a partition of \(V\), Get_New returns an element \(v V S\) representing a cluster in \(^{}\) that's not yet represented in \(S\), i.e. \(v[u]_{^{}}\) for any \(u S\).

InsertGiven an element \(v\) and a subset \(S V\), Insert compares \(v\) against every element in \(S\) by passing \(u\) and \(v\) to the function Compare. Compare returns result\(\{ 1\}\). If Compare returns a negative result for each \(u S\), then Insert adds \(v\) to the subset \(S\). On the other hand, if Compare returns a positive result for \(v\) and some element \(u S\), then Insert updates the partition \(^{}\) to reflect that \(u\) and \(v\) must be in the same cluster. The latter is done by merging \([u]_{^{}}\) with \([v]_{^{}}\).

```
0:A finite set \(V\), an \((_{},_{})\)-faulty oracle \(_{}\), a target number of clusters \(k\), and error parameters \(_{}\). Output: A partition \(^{}\) of \(V\).
1\(S\{\}\), \(^{}\{\{v\} v V\}\)
2while\(|^{}|>k\)do
3\(v\)Get_New\((S,^{})\)
4\(^{},S(V,,S,^{ },_{})\)
5if\(|S|=k+1\)then
6\(S\{\}\)
7 end if
8
9 end while return\(^{}\) ```

**Algorithm 1**Learn\((V,,k,_{})\)

``` Input:A partition \(^{}\) of some finite set \(V\), and a subset \(S V\) such that \(|S||^{}|\) Output: An element \(v V\) representing a set in \(^{}\) which is currently not represented by any element of \(S\).
1for\(v V\)do
2if\([v]_{^{}} S=\)then
3return\(v\)
4 end if
5
6 end for return\(\) ```

**Algorithm 2**Get_New\((S,^{})\)

``` Input:A partition \(^{}\) of some finite set \(V\), and a subset \(S V\) such that \(|S||^{}|\) Output: An element \(v V\) representing a set in \(^{}\) which is currently not represented by any element of \(S\).
1for\(v V\)do
2if\([v]_{^{}} S=\)then
3return\(v\)
4 end if
5
6 end for return\(\) ```

**Algorithm 3**Insert\((v,,^{},S,_{})\)

``` Input:A finite set \(V\),a same-cluster oracle \(\) for \(V\), a partial clique \(S\), a candidate partition \(^{}\) of \(V\), and error parameter \(_{}\). Output: A new candidate cluster \(^{}\), partial clique \(S\).
1for\(u S\)do
2// Returns either result\(=-1\) or \(+1\) result\((u,v,,_{})\) // If \(+1\): it is guaranteed that \(u\) and \(v\) are part of the same cluster and \(^{}\) is edited to reflect this if\(result=+1\)then
3new_set\([v]_{^{}}[u]_{^{}}\) \(^{}(^{}\{[v]_{ }^{},[u]_{^{}}\})\) return\(^{},S\)
4 end if
5
6 end for
7// If \(S\) is empty or if result\(=-1\) for every \(u S\) then a new item is inserted into \(S\)\(S S\{v\}\) return\(^{},S\) ```

**Algorithm 4**Insert\((v,,^{},S,_{})\)

We briefly remark that for the \(k\)-unknown setting, Algorithm 9 proposed in the appendix, works in an analogous fashion. The key difference between the two settings is that rather than building cliques of size \(k+1\), Algorithm 9 builds the largest clique possible. We then give a charging argument that shows that this strategy does not lead to a significantly higher query complexity. The algorithm and analysis are presented in Section D.

``` Input: A pair of vertices \(u\) and \(v\) from some finite set \(V\), a same-cluster oracle \(\) for \(V\), and error parameter \(_{}\). Output:\(\{ 1\}\).
1 // Initialize count to track "how many more times have we observed \(r=+1\) compared to \(r=-1\)"
2count\( 0\)
3while\( 0\)do
4\(r(u,v)\)
5if\(r=-1\)and\(\)\(>0\)then
6count\(\)count\(-1\)
7elseif\(r=-1\)and\(\)\(=0\)then
8 /* If the number of \(-1\) responses exceeds the number of \(+1\) responses seen so far, we return \(-1\)*/
9return\(-1\)
10else
11count\(\)count\(+1\)
12 end if
13 // If \(/_{}>1\) then we have verified that \(u_{*}v\) so return \(=+1\)
14if\(/_{}>1\)then
15return\(1\)
16
17 end if
18
19 end while ```

**Algorithm 4**\((u,v,,_{})\)

## 7 Conclusions, Limitations, and Future Directions

In this paper we initiated the study of learning partitions from same-cluster queries subject to bounded adversarial errors. We completely characterize the query complexity of the core problem as well as some of its relevant variants. To do so, we introduce a novel Renyi-Ulam style game based on correlation clustering.

The aim of this paper is to resolve the query complexity of exact recovery with a fixed error tolerance. In particular, the results in this paper do not apply to any setting in which the error may exceed the tolerance \(\), e.g. when errors occur probabilistically and independently on every query. This limitation is analogous to those encountered when considering the Hamming (worst-case, bounded) model of error in the theory of error-correcting codes (see e.g. ). Thus, like the theory for bounded-error codes, results in this paper should be assumed to hold verbatim in stochastic error settings.

The results in this paper open up several avenues for future research. First, while we settle the complexity of all the variants of the problem in the \(k\)-known setting, the exact complexity of weighted \(\)-PL problem in the setting of \(k\)-unknown remains to be determined. Specifically, the lower bounds of \((k^{2}_{})\) and \(((n-k)_{})\) that we prove for \(k\)-known directly extend to the \(k\)-unknown setting. However, the analysis of Algorithm 9 can be used to establish upper bounds with terms \(O(k^{2}_{}+(n-k)\{_{},_{}\})\). The question of whether the upper bounds can be tightened to \(O(k^{2}_{}+(n-k)_{})\), or whether the corresponding lower bound can be strengthened to e.g. \(((n-k)\{_{},_{}\})\) in the \(k\)-unknown setting, remains open. Another interesting open question is whether there exist algorithms that can achieve exact recovery in the setting of \(k\)-known when the number of false-positives, \(_{}\), is _not_ known to the algorithm a priori. In this work we established that such algorithms exist without knowing \(_{}\) in advance, but it is unclear whether \(_{}\) has analogous properties.

We focus on same-cluster queries due to their popularity and simplicity, but there are other practical query models that may interest the community. One such example includes the triangle queries introduced by Vinayak and Hassibi  in which a worker is asked to input all pairwise same-cluster responses for three data points at a time. It would be interesting to explore whether the analysis techniques introduced in this work can determine the query complexity of learning partitions under other query models.

**Acknowledgements.** The authors wish to thank Daniel Di Benedetto for providing helpful advice early on in the project; Yibo Jiang for suggesting related work; Mark Olson, Angela Wang, and Nathan Waniorek for useful discussions. AD is supported by NSF DGE 2140001.