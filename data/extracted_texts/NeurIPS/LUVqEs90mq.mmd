# Stochastic Optimal Control for Collective Variable

Free Sampling of Molecular Transition Paths

 Lars Holdijk\({}^{*}\)

University of Oxford

&Yuanqi Du\({}^{*}\)

AMLab

University of Amsterdam

&Ferry Hooft

Computational Chemistry Group

University of Amsterdam

Priyank Jaini

Google DeepMind

&Bernd Ensing

AI4Science Lab

Computational Chemistry Group

University of Amsterdam

&Max Welling

AMLab

University of Amsterdam

###### Abstract

We consider the problem of sampling transition paths between two given metastable states of a molecular system, e.g. a folded and unfolded protein or products and reactants of a chemical reaction. Due to the existence of high energy barriers separating the states, these transition paths are unlikely to be sampled with standard Molecular Dynamics (MD) simulation. Traditional methods to augment MD with a bias potential to increase the probability of the transition rely on a dimensionality reduction step based on Collective Variables (CVs). Unfortunately, selecting appropriate CVs requires chemical intuition and traditional methods are therefore not always applicable to larger systems. Additionally, when incorrect CVs are used, the bias potential might not be minimal and bias the system along dimensions irrelevant to the transition. Showing a formal relation between the problem of sampling molecular transition paths, the Schrodinger bridge problem and stochastic optimal control with neural network policies, we propose a machine learning method for sampling said transitions. Unlike previous non-machine learning approaches our method, named PIPS, does not depend on CVs. We show that our method successful generates low energy transitions for Alanine Dipeptide as well as the larger Polyproline and Chignolin proteins.

## 1 Introduction

Molecular Dynamics (MD) is a central tool in the (bio-)chemistry toolbox. By integrating Newton's equations of motion on a molecular scale, MD can provide insight into chemical processes and systems without requiring expensive lab testing (Frenkel and Smit, 2001; Hollingsworth and Dror, 2018). However, MD is limited when interested in _transitions_ between two metastable configurations of a system, such as the folding of a protein, general conformational changes, and chemical reactions. These meta-stable states are separated by regions of high energy which are unlikely to be sampled within a reasonable timespan. While machine learning based approximations of the interatomic forces using neural force fields (Unke et al., 2021) have pushed the boundary in terms of system scale, it does not address the problem of sampling molecular transition paths directly (Fu et al., 2022).

To overcome this issue, prior work in computational and physical chemistry has developed several methods for the enhanced sampling of molecular transitions such as transition path sampling (Bolhuis et al., 2002), umbrella sampling(Torrie and Valleau, 1977) and meta-dynamics (Laio and Parrinello, 2002). Most of these methods speed up the sampling of transition paths by augmenting the MD simulation with a (learned) bias potential that pushes the system to cross the energy barrier separating two states. However, due to the large configuration space of molecular trajectories, finding such a bias potential is in itself a computationally expensive task.

To circumvent this problem, prior methods depend on _Collective Variables_ (CVs). CVs are functions of atomic coordinates that have been identified as playing a role within the transition period. Biasing methods rely on these CVs to reduce the complexity of the bias potential by only biasing the system along them. Limiting the bias potential to act on the CVs is an intuitive approach since the most common reason to sample transition paths, deriving transition dependent quantities such as reaction free-energy and reaction rate, are functions of CVs themselves (Bussi and Branduardi, 2015). See fig. 1 for an illustration of the free-energy barrier separating two metastable states of the Alanine Dipeptide protein for which the dihedral angles \(\) and \(\) are known to be CVs.

However, while sensible, depending on CVs to reduce the dimensionality of bias potential search space is not always suitable. While some methodological approaches are available (Hooft et al., 2021) for smaller systems, selecting CVs relies on prior expert knowledge. This limits the applicability of bias potential enhanced sampling to systems for which this information is available. Additionally, when CVs are incorrectly chosen, depending the bias potential on these CVs might result in errors in determining dependent quantities (Bolhuis et al., 2000) and incorrect interpretation of the transition process.

For this purpose, we propose PIPS, a Path Integral stochastic optimal control (Kappen, 2005; Kappen and Ruiz, 2016) method for Path Sampling of molecular transitions. PIPS leverages stochastic optimal control theory to train a parameterised bias potential that, unlike previous methods from computational chemistry, operates on the entire geometry of the molecule instead of depending on predetermined CVs. This way, PIPS can be scaled to larger systems.

**Contributions and outline** Our contributions are organised as follows. First, we introduce the problem of sampling transition paths in section 2. Second, we formally show in section 3 the relationship between the problem of sampling transitions paths, the Schrodinger Bridge Problem (section 3.1) and Stochastic Optimal Control (SOC) (section 3.3). Following this, we use the gained insights regarding SOC in section 4 to propose PIPS; a method based on the PICE algorithm designed for sampling molecular transition paths that does not depend on Collective Variables. Lastly, we demonstrate the efficacy of PIPS on conformational transitions in three molecular systems of varying complexity, namely Alanine Dipeptide, Polyproline, and Chignolin in section 5.

## 2 Preliminaries, Problem Setup, and Related Work

### Molecular Dynamics

Given the state of a molecular system \(_{t}:=(_{t},_{t})\) consisting of positions \(_{t}^{3n}\) and velocities \(_{t}^{3n}\) at time \(t\) with \(n\) atoms sampled from the Gibbs distribution \(_{G}(_{t})=(-T}(_{t},_{t}))\), Molecular Dynamics (MD) describe the time evolution of the state over time. \(\) is known as the Hamiltonian \((_{t},_{t})=U(_{t})+K(_{t})\), where \(U(_{t})\) and \(K(_{t})=^{2}\), with mass \(\), respectively denote the Potential and Kinetic Energy of the system. The potential energy of a system is defined by a parameterized sum of pairwise empirical potential functions, such as harmonic bonds, angle potentials, inter-molecular electrostatic and Van der Waals potentials.

One common approach of integrating the molecular dynamics is Langevin Dynamics (Bussi and Parrinello, 2007) which couple the deterministic Newtonian equations of motion with a stochastic thermostat that acts like a heat bath. Langevin dynamics obey the following SDEs

\[ =t\] (1) \[ =}U()}{}t- t+ k_{B}T}\,,\] (2)

where \(k_{B}\) is the Boltzmann constant, \(T\) the temperature of the health bath, and \(\) standard Brownian Motion. \(\), the friction term, couples the dynamics and the heat bath. Following this SDE samples samples from the Canonical of NVT ensemble with constant temperature.

Figure 1: Free-energy surface of Alanine Dipeptide as a function of CV dihedral angles \(\) and \(\) highlighting the high energy barrier separating the two metastable states. White stars indicate saddle points in the high energy barrier where the transition is likely to occur.

### Sampling Transition Path Sampling

By sampling an initial configuration \(_{0}=(_{0},_{0})_{G}\) and following the MD simulation for a fixed amount of time, one can generate trajectories \(_{0:}=\{_{0},,_{}\}\), of length \(\). These trajectories represent samples from the probability distribution over trajectories given by:

\[(_{0:})=_{G}(_{0})_{t=1}^{}(_{t}|_{t-1},_{t-1}),\] (3)

with \(_{t}=(_{t}t,}U(_{t})} {}t-_{t}t)^{T}\) and \(=(0,2 k_{B}T)\).

However, in the context of sampling transition paths, we are interested in trajectories with a predefined an initial and final state. Ie. \(_{0} R^{3n}\) and \(_{} P^{3n}\). For example, \(R\) can describe the set of reactants and \(P\) the set of products of a chemical reaction. Or, \(R\) can be the set of stable native states of a protein while \(P\) is the set of folded proteins.

We will refer to the distribution over trajectories with restricted initial and target states as the _Transition Path_ (TP) distribution [Dellago et al., 1998].

**Definition 1** (Transition Path (TP) distribution).: _Given a set of initial states \(R\), target states \(P\), potential energy \(U\) and a transition length \(\) the Transition Path (TP) distribution is defined as;_

\[^{*}(_{0:})=_{R}(_{0})(_{0: })_{P}(_{})\] (4)

_where \(_{R}\) and \(_{P}\) are indicator functions and \((_{0:})\) is defined according to eq. (3)._

We can naively apply rejection sampling to sample from the TP distribution by sampling a system \(_{0}_{R}(_{0})_{G}(_{0})\), evolving it for \(\) steps according to the MD in eq. (1) and rejecting it when \(_{} P\). Unfortunately, when using standard molecular dynamics, it is very unlikely for any trajectory starting in a state \(_{0} R\) to terminate with \(_{} P\) due to the two sets of states being separated by a high-energy barrier. Ie. for all \(_{0:}^{*}\) some \(_{t}\) has \(U(_{t})>>U(_{0})\). To be able to obtain a representative number of trajectories, one is thus forced to generate a high number of trajectories, making naive sampling from the TP distribution computationally very expensive.

### Bias Potential Enhanced Sampling

To solve the problem caused by high-free energy barriers and to sample from the TP distribution various enhanced sampling approaches are available. These will be further discussed in the related work section. In this work, we will focus on a specific branch of enhanced sampling methods called _Bias Potential Enhanced Sampling_ (BPES). In BPES approaches, the stochastic dynamics are enhanced with a bias potential \(b(,)\) such that when a system \(_{0}_{R}(_{0})_{G}(_{0})\) is transformed according to the biased dynamics

\[ =t\] (5) \[ =}U()+b(,) }{}t-t+ k_{ B}T}\,,\] (6)

a trajectory, of length \(\), always terminates with \(_{} P\).

Trajectories sampled by following these bias potential enhanced dynamics are sampled according to what we refer to as the Bias Potential enhanced Transition Path (BPTP) distribution

\[^{b}(_{0:})=_{R}(_{0})_{G}(_{0}) _{t=1}^{}(_{t}|}_{t-1},_{t-1 }),\] (7)

with \(}_{t}=(_{t}t,}U (_{t})+b(_{t},_{t})}{}t- _{t}t)^{T}\) and \(=(0,2 k_{B}T)\).

Finding the bias potential \(b(,)\) such that trajectories sampled from the BPTP distribution are distributed according to the TP distribution is referred to as the BPTP problem.

**Definition 2** (Bptp problem).: _Given a set of initial states \(R\), target states \(P\) and a Potential Energy function \(U\), the BPTP problem describes the task of finding an optimal bias potential \(b^{*}\) such that trajectories sampled from the BPTP distribution \(^{b^{*}}\) are close to samples sampled to the TP distribution \(^{*}\), ie._

\[b^{*}=*{arg\,min}_{b}_{}(^{b}|^{*}).\] (8)

#### 2.3.1 Related Enhanced Sampling Methods

**CV dependent Enhanced Sampling** Most closely related to our work are the metadynamics (Liao and Parrinello, 2002; Bussi and Branduardi, 2015; Barducci et al., 2008) and the Adaptive Biasing Force (ABF) methods (Darve and Pohorille, 2001; Comer et al., 2015). In metadynamics, the bias potential is iteratively built as a sum of Gaussians centered at conformational states previously visited during the MD simulation. This consecutively pushes the system outwards to regions of higher energy not previously visited. Contrarily to metadynamics, ABF does not aim to learn the bias potential \(b(,)\), but instead aims to control the system through the _bias force_\((,)=_{}b(,)^{3n}\). The intuition behind ABF is to learn a bias force that cancels out the deterministic force from the molecular potential. As a result, the only remaining driving force is the stochastic Langevin thermostat which is not affected by the high energy barriers. Other approaches to sampling transition paths using a bias potential include umbrella sampling Torrie and Valleau (1977), hyper-MD (Voter, 1997), the Wang-Landau method (Wang and Landau, 2001) and various less commonly applied others (Sprik and Ciccotti, 1998; Grubmuller, 1995; Huber et al., 1994; Carter et al., 1989). All these methods depend on dimensionality reduction steps using CVs while our proposed method does not.

**CV free Enhanced Sampling** In addition to the CV dependent methods a different family of MCMC based approaches for direct sampling from the TP distributions is available. These methods, such as Transition Path Sampling (Dellago et al., 1998; Bolhuis et al., 2002) and Nudge Elastic Band sampling (Henkelman et al., 2000), generally do not use a bias potential or CVs.

Recently, several machine learning solutions for the BPTP and related problems have been proposed. For example, Das et al. (2021) use Reinforcement Learning to sample from the TP distribution under Brownian dynamics, Schneider et al. (2017) consider the modelling of the free-energy surface using neural networks, and both Sultan et al. (2018) and Sun et al. (2022) use neural networks find CVs.

## 3 Sampling Transition Paths using Stochastic Optimal Control theory

In this section we will formally discuss the relationship between the BPTP problem and two topics from the machine learning literature; the Schrodinger Bridge problem and Stochastic Optimal Control.

### The BPTP problem is a Schrodinger Bridge Problem

First introduced by Schrodinger (Schrodinger, 1931, 1932), the Schrodinger Bridge (SB) problem studies the transition between two distributions over time under some fixed drift and diffusion components. Formally, the SP problem is defined as

**Definition 3** (Schrodinger Bridge (SB) problem).: _Given a reference distribution \(_{0:}\) over trajectories with predefined marginals \(_{0}\) and \(_{}\), the Schrodinger Bridge (SB) Problem aims to find an alternative distribution \(_{0:}\) such that_

\[^{*}_{0:}:=*{arg\,min}_{(_{0:})(_{0},_{})}_{} _{0:}\|_{0:} \] (9)

_where \((_{0},_{})\) is the space of path measures with marginals \(_{0}\) and \(_{}\)._

Recently, machine learning approaches for parameterizing this alternative distribution \(\) to approximate the reference distribution \(\) have received attention (Vargas et al., 2021; De Bortoli et al., 2021). In the following theorem, we show that these approaches also provide a solution to the BPTP problem when the correct marginal distributions are specified.

**Theorem 3.1** (BPTP problem is a SB problem).: _Let \(b\) be the set of functions such that \(_{0}=_{G}(_{0})_{R}(_{0})\) and \(_{}=_{G}(_{})_{R}(_{})\), we have that a solution to the SB problem with reference distribution \(^{*}\) is also a solution to the BPTP problem, ie._

\[_{b}_{}(^{b}|^{*})=*{arg\,min}_{ ^{b}(_{0},_{})}_{}^{b} ^{*}\] (10)

Proof.: This follows from the definition of the BPTP and SB problems. 

Following this theorem, we can use proposed solutions for solving the SBP to solve the BPTP problem using a bias potential. In this work, we will specifically focus on Stochastic Optimal Control theory, which has been shown to solve the SBP in (Chen et al., 2016).

### Background: Stochastic Optimal Control

Before formally introducing the relation between Stochastic Optimal Control (SOC) and the BPTP problem we first review some of the basic concepts of SOC and, more specifically, the Path Integral Stochastic Optimal Control (PISOC) branch of SOC theory.

Given an arbitrarily controlled dynamical system

\[_{t}=(_{t})\,t+(_{t}) (_{t})\,t+,_{0}_{0},\] (11)

where \(:^{d}^{+}^{d}\) and \(:^{d}^{+}^{d d}\) are deterministic functions representing the drift and volatility of the system and \(\) is Brownian Motion with variance \(\), Stochastic Optimal Control theory aims to find a policy \((_{t})\) that minimizes some expected cost \(C\) over the trajectories:

\[^{*}=*{arg\,min}_{}_{_{0:} _{u}}C(x_{0:})\] (12)

Here \(_{u}\) represents the distribution over trajectories similar to eq. (7) with \(_{t}=_{t}+(_{t},t)\,t+(_{t})( (_{t})\,t)\) and \(_{t}=(_{t})^{T}(_{t})\).

In this work we will specifically rely on a branch of SOC called Path Integral Control (PISOC), first introduced by Kappen (2007). In PISOC the cost of a trajectory is defined as

\[C(_{0:})=(_{})+_{t=0}^{ -1}(_{t})^{T}(_{t})+( _{t})^{T}_{t}\] (13)

where \(_{t}=^{-1}(_{t})(-(_{ t})\,t)-(_{t})\), \(\) denotes the terminal cost, \(\) is a constant and \(\) is the cost of taking action \(\) in the current state and is given as a weight matrix for a quadratic control cost. To clarify, \(_{t}\) is the noise introduced into the trajectories by the Langevin thermostat.

The last term in the cost function in eq. (13) relating the Brownian motion and the control is unusual and devoid of a clear intuition. However, this term plays an important role when relating the cost to a KL-divergence which we will establish next. Additionally, as discussed by Thijssen and Kappen (2015), the additional cost vanishes under expectation (\(_{_{0:}_{u}}[(_{t})^{T}_{t}]=0\)) and thus, does not influence the optimal control \(^{*}\) given by eq. (12).

### Stochastic Optimal Control solves the BPTP problem

We can see that SOC dynamical system (eq. (11)) is similar to the dynamics of the BPTP distribution (eq. (5)). In fact, as we will see next, with a properly defined \(\), minimizing the trajectory cost (eq. (13)) results in finding a control \(\) that solves the BPTP problem.

**Theorem 3.2** (SOC solves the BPTP problem).: _Given \(_{t}=(_{t},_{t})^{T}\), \((_{t})=(_{t},_{t}}U(_{t})}{} -_{t})^{T}\), \((_{t})=(_{3n},_{3n})^{T}\), \((_{t})=_{t}}b(_{t},_{t})}{}\), \(=2 k_{B}T\), and \(_{0}=_{G}\), such that the SOC dynamics (eq. (11)) describe the dynamics of the BPTP distribution \(^{b}\) (eq. (5))._

_If we define \((_{})=-(_{P}(_{}))\), \(=^{-1}=(2 k_{B}T)^{-1}\) and assume \(_{0} R\), we have_

\[*{arg\,min}_{b}_{_{0:}^{b}}C( _{0:})=*{arg\,min}_{b}_{}( ^{b}|^{*}),\] (14)

_where \(^{*}\) is the TP distribution._

Proof.: See appendix A. The proof relates \(^{b}\) and \(^{0}\) using Girsanov's theorem to rewrite the expectation over cost \(C\) as the summation of the terminal cost and a KL divergence. 

Using the established connection we now thus have a tool to solve the BPTP problem by learning a parameterized control \(_{}(_{t})=_{t}}b_{}(_{t}, {v}_{t})}{}\) and consequentially the parameterized bias potential \(b_{}\) using SOC theory. In the following section we will look at one specific approach for doing so.

PIPS: Path Integral SOC for Path Sampling

Following the formal construction of the relationship between SOC and the BPTP problem, we now introduce our proposed method to find the parameterized bias potential \(b_{}\) based on this connection.We refer to this method as PIPS: Path Integral Path Sampling. PIPS is an adaptation of the Path Integral Cross Entropy (PICE) (Kappen and Ruiz, 2016) method to the setting of sampling molecular transition paths where we have a single initial \(R=\{_{0}^{*}\}\) and target \(P=\{_{}^{*}\}\) system.

Background: Path Integral Cross EntropyKappen and Ruiz (2016) introduced the Path Integral Cross Entropy (PICE) method for solving Equation (12). The PICE method derives an explicit expression for the distribution \(^{^{*}}\) under optimal control \(^{*}\) when \(=\) given by:

\[^{^{*}}=,t)}^{}_{0:} (-C(_{0:}))\] (15)

where \(()=_{_{0:}^{0}}[(- (_{})]\) is the normalization constant. This establishes the optimal distribution \(^{^{*}}\) as a reweighing of any distribution induced by an arbitrary control \(\).

PICE, subsequently, achieves this by minimizing the KL-divergence between the optimal controlled distribution \(^{^{*}}\) and a parameterized distribution \(^{_{}}\) using gradient descent as follows:

\[_{}(^{^{*}}|^{_{}})} {}=-_{_{0:}_{_{ }}}[(-C(_{0:},_{}))_{t=0}^{}( _{t}_{}}{})]\] (16)

Similar to the optimal control in eq. (15), the gradient used to minimize the KL-divergence is found by reweighing for each sampled trajectory, \(_{0:}\), the gradient of the control policy \(_{}\) by the cost of the trajectory. See Algorithm 1 in the appendix for an algorithmic description of PICE.

### Adaptations to PICE

In this section we will specify the adaptations made to the PICE algorithm to apply it to solve the BPTP problem for the molecular transition path setting.

Smoothing the loss functionAs shown in the previous section, when using the target loss \((_{})=-(_{P}(_{}))\), SOC solves the BPTP problem. However, while optimal, this loss function is hard to use in the PICE optimization task as it is infinite for all \(_{0:}\) where \(_{}_{}^{*}\). As such, we instead use a smoothed version \((_{t})=_{i,j}^{n}(d_{ij}(_{t})-d_{ij}(_{ }))^{2}\) where \(d_{ij}(_{t})=\|(_{t})_{i}-(_{t})_{j}\|_{2}^{2}\). This exponentiated pairwise distance between the atoms is a commonly used distance metric (Shi et al., 2021) that is invariant to rotations and translations of the molecular system.

Architectural considerationsThe learnable component of PIPS is the bias potential \(b\). However, as the BPTP dynamics show in eq. (5), instead of using the bias potential directly, MD depends on the _bias force_ -- the gradient of the bias potential \((,)=_{}b(,)^{3n}\). This consideration allows for two different modelling approaches for the bias force similar to the distinction between metadynamics and adaptive bias force discussed in section 2.3.1. One can either parameterise the bias force directly \((,)=_{}(,)\) or, alternatively, model \(b_{}(,)\) the bias potential and calculate the corresponding bias force by backpropagation, \((,)=_{}b_{}(,)\). The advantage of the latter is that the forces are conservative by construction.

In section 5.1 we will compare both these modelling approaches. In both cases we will use a MLP with ReLU activation for either the parameterized bias force or bias potential. Alternatively, \(_{}\) or \(b_{}\) could be implemented using recent advances in physics inspired equivariant neural networks (Cohen and Welling, 2016; Satorras et al., 2021) that take into account the \((3)\) symmetry of the system. We provide details for training the control network \(_{}\) in Appendix B.

Integration with MD simulation frameworksTo efficiently calculate the Potential \(U()\) and integrate the MD in eq. (1), various optimized simulation frameworks are available. In our work we use the OpenMM framework (Eastman et al., 2017). The bias force \((,)\) is integrated in OpenMM as a _custom external force_. Implementing the control this way allows us to use the optimized configuration capabilities of OpenMM, such as forcefield definitions (the potential function description) and integrators (for the time-discretization of our dynamics).

One downside of using OpenMM for integrating the MD is that it does not provide access to the noise \(_{t}T}\,\) used in the Langevin thermostat that is needed to calculate the update to the policy weights. To circumvent this, we instead sample an additional exploratory noise term \(_{t}\) with variance \(\) that is used to optimize the policy and assume the Langevin noise to be part of the drift of the system \(\). While this loses the formal guarantees presented in section 3, we found this to be experimentally stable and provide close to optimal trajectory paths (as shown in section 5.1).

## 5 Experiments

We evaluate PIPS using three molecular systems, namely (i) **Alanine Dipeptide**, to compare PIPS to CV free and CV dependent baselines, (ii) **Polyproline**, to evaluate PIPS as a method to select candidate CVs, and (iii) **Chignolin**, as a use-case of PIPS scalabilty to proteins without knowns CVs.

We report the molecule specific OpenMM configuration as well as the used neural network architecture to learn the bias potential/force in appendix C. Generally, we run our simulations at \(300\,\) and use 6 layer MLP with the width of the layers dependent on the number of atoms in the molecule under consideration. Our code, including a full stand-alone notebook re-implementation, is available here: https://github.com/LarsHoldijk/SOCTransitionPaths.

### Alanine Dipeptide

In this section we evaluate PIPS on the extensive studied Alanine Dipeptide (AD) molecule. AD is a relatively small protein for which the CVs (two dihedral angles \(\) and \(\)) are readily available and is therefore well suited for the development of enhanced sampling methods that require CVs. While PIPS does not use the CVs during training, their availability does come in useful to evaluate the sampled transition. The transition evaluated here have a \(500\,\) time horizon.

#### 5.1.1 Quantitative comparison to CV free baselines

As discussed, our work is the first to consider CV free sampling of transition paths at this scale and as such other baselines or metrics are not available. In table 1 we therefore evaluate PIPS using MD simulations with extended time-horizon and increased system temperature as baselines and introduce three metrics to evaluate the quality of the transition paths. (i) _Expected Pairwise Distance_ (EPD) measures the euclidean distance between the final conformation in the trajectory and the target conformation, reflecting the goal of the transition to end in the target state, (ii) _Target Hit Percentage_ (THP) assures that the final configuration is also close in terms of CVs by measuring the percentage of trajectories correctly transforming these CVs, and (iii) _Energy Transition Point_ (ETP)

    & \(\) & Temp. & EPD (\(\)) & THP (\(\)) & ETP (\(\)) \\  & \(\) & \(\) & \( 10^{-3}\) & \% & \(}\) \\  Bias Force Prediction & 500 & \(300\) & \(2.56 0.34\) & 45.0 \% & 0.55 \(\) 11.30 \\ Bias Potential Prediction & 500 & \(300\) & \(1.21 0.31\) & 63.5 \% & -8.35 \(\) 8.04 \\  MD w. fixed timescale & 500 & \(300\) & \(8.50 0.67\) & 0\% & - \\  & 500 & \(1500\) & \(7.75 1.72\) & 0\% & - \\  & 500 & \(4500\) & \(6.77 2.41\) & 0.1\% & 317.79 \(\) 0.00 \\  & 500 & \(9000\) & \(6.99 2.56\) & 1.6 \% & 772.57 \(\) 108.55 \\  MD w/ fixed timescale & 6818.4 \(\) 5420.8 & \(1500\) & \(3.08 0.68\) & 100\% & 393.76 \(\) 68.67 \\  & 3471.7 \(\) 1646.5 & \(4500\) & \(6.42 2.67\) & 100\% & 1186.84 \(\) 212.00 \\   

Table 1: Benchmark scores for the proposed method and extended MD baselines. From-left-to-right: Time-horizon \(\) representing the trajectory length (note that we take one policy step every \(1\,\)), simulation temperature, Expected Pairwise distance (EPD), Target Hit Percentage (THP), and Energy Transition Point (ETP). ETP can only be calculate when a trajectory reaches the target. All metrics are averaged over 1000 trajectories except for MD w/ fixed timescale which is ran only for 10 trajectories.

which evaluates the capacity of each method to find transition paths that cross the high-energy barrier at a low point by taking the maximum potential energy of the molecule along the trajectory. A good trajectory will be one that passes through the minimal high-energy barrier and ETP aims to measure this. We provide more details in Appendix C.2.1.

**Results:** We find that the trajectories generated by both the policy networks outperform the MD baselines, but the more physics-aligned potential predicting policy performs best under our metrics. This policy network consistently reaches the target conformation both in terms of full geometry and the CVs orientation. Furthermore, our policy network generates these trajectories in a significantly shorter time than temperature enhanced MD simulations without a fixed timescale. When we do limit MD to run for the same timescale as the proposed method, we found that, in contrast to the proposed method, temperature enhanced MD simulations are unable to generate successful trajectories. We will use the bias potential predicting policy in the following.

#### 5.1.2 Qualitative comparison to CV dependent metadynamics

In fig. 2 we visualise an AD transition sampled by PIPS using the bias potential predicting policy. In the top left, we overlay the transition projected onto CV space on the free-energy surface generated using metadynamics. The free-energy surface thus serves as a ground-truth generated using a method that requires extensive domain knowledge. We aim to show that the trajectory sampled using PIPS aligns with the saddle points of the metadynamics free-energy surface.

**Results:** The trajectory in Figure 2 demonstrates that the bias potential control policy transforms the molecule from the initial position (A) to the final position (E) by transitioning over the same saddle point in the free-energy barrier found by metadynamics (C). This shows that the trajectory follows the same transition in CV space as metadynamics despite, contrarily to metadynamics, not being biased to do so. The potential energy goes up during the transition until it reaches the lowest point of the energy barrier (C) and consecutively settles down in its new low-energy state.

### Polyproline Helix

Second, we consider a Polyproline trimer with 3 proline residues. Polyproline is a more complex protein then AD and as such its CVs are less well understood. We therefore use this protein to determine if PIPS biases the system along the correct CVs when a collection of candidate CVs are available. Specifically, we consider the peptide bond orientation (\(\)) and two backbone dihedral angles (\(\) and \(\)). As initial and target state we provide a single example of Polyprolines PP-I form (with cis-isomer peptide bonds) and PP-II form (with trans-isomer peptide bonds) respectively. For this transition it is known that the CV of interest are the peptide bond orientation. Additionally, to

Figure 2: Visualization of a trajectory sampled with PIPS. _Left:_ The sampled trajectory projected on the free energy landscape of AD as a function of two CVs _Right:_ Conformations along the sampled trajectory: A) starting conformation showing the CV dihedral angles, B-D) intermediate conformations with C being the highest energy point on the trajectory, and E) final conformation, which closely aligns with the target conformation. _Bottom:_ Potential energy during transition.

study PIPS resilience to target misspecification, the supplied PP-II form also contains a transformation in one of the \(\)-dihedral angles which is irrelevant to the transition. The transition time is \(5000\,\).

**Results:** We visualize the transformation of the three collective variables \((,,)\) as well as the corresponding potential energy of the conformation in Figure 3 for a sampled transition path. We observe that the transition correctly occurs along the \(\) CV going from \(180^{}\) to \(0^{}\). This suggest that PIPS could be used for testing the validity of candidate CVs. However, we also observe that in addition to the peptide bonds PIPS also biases the system along one of the \(\)-dihedral angles due to the introduced target misspecification. As the small fluctuations are to be expected when sampling a single target from the Boltzmann distribution, alternative methods for specifying the target state should be explored in future work.

### Chignolin

Lastly, we consider the small \(\)-hairpin protein Chignolin. Chignolin was artificially constructed to study protein folding mechanisms (Honda et al., 2004; Seibert et al., 2005). Due to its small size, its folding process is easier to study than larger scale proteins while being similar enough to shed light on this complex process. In contrast to Alanine Dipeptide and Polyproline, there is no agreement on the transition mechanism describing the folding of Chignolin. Both the CVs involved (Satoh et al., 2006; Paissoni and Camilloni, 2021), as well as the sequence of steps (Harada and Kitao, 2011; Satoh et al., 2006; Suenaga et al., 2007; Enemark et al., 2012) describing the folding process have multiple different interpretations. Chignolin thus serves as a usecase study for scaling PIPS beyond traditional CV-based approaches to solve the BPTP-problem. We sample transition paths between the folded and unfolded state of the Chignolin protein using a total time horizon of \(5000\,\). Note that the typical folding time of Chignolin is recorded to be \(0.6\,\)(Lindorff-Larsen et al., 2011).

**Results:** In Figure 4, we visualize the transition of Chignolin at 5 different timesteps during the transition path. We observe that to transition the protein from its low energy unfolded state to the folded conformation, the proposed method guides the protein into a region of higher energy. This increase is initially more steep (0\(\)1500) than in the later stages. Additionally, most of the finer-grained folding (2500\(\)4000) occurs with a high potential energy before settling into the lower-energy folded state. We notice that for the restricted folding time we use in our experiments (\(5000\,\) vs \(0.6\,\)), the molecule does not end at the final configuration but reaches close to it as shown by the plot on pairwise distance. Furthermore, the learned policy network is able to transition through the high energy transition barrier in this restricted time. We do not encounter this for molecules with a shorter natural transition time (as illustrated by the potential energy of Alanine Dipeptide in fig. 2).

Figure 3: Visualization of the Polyproline transformation from PP-II to PP-I. _From-top-to-bottom_ 5 stages of the transition, \(\), \(\), \(\) candidate CVs, and Potential Energy. For the candidate CVs multiple instances of the same dihedral angles can be found in a single molecule. Stars indicate target candidate CV states. Colored bonds represent the bonds involved in the \(\) CV.

## 6 Discussion

In this work, we have proposed PIPS--a path integral stochastic optimal control method for the problem of molecular sampling transition paths using a bias potential. In contrast to prior work, PIPS does not require prespecifying CVs along which the system should be biased. We show the benefits of PIPS using three different molecular systems of varying sizes. In passing, we gave an introductory description of the problem of sampling transition paths and related it to the stochastic optimal control and the Schrodinger bridge problem. With this, we hope to not only have motivated our own work but also provided a starting point for future work consideration of this important problem by the machine learning community. For future work, we specifically note that the use of PIPS for CV discovery and the exploration of other approaches for specifying the target state, possibly using an ensemble of samples, is a promising direction as exemplified by our Polyproline experiment.