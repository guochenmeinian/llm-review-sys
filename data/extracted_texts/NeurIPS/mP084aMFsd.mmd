# A Simple yet Scalable Granger Causal Structural Learning Approach for Topological Event Sequences

Mingjia Li1  Shuo Liu1  Hong Qian2  Aimin Zhou

Shanghai Institute of AI for Education and School of Computer Science and Technology,

East China Normal University, Shanghai 200062, China

{limj,shuoliu}@stu.ecnu.edu.cn

{hqian,amzhou}@cs.ecnu.edu.cn

Equal contribution.

###### Abstract

In modern telecommunication networks, faults manifest as alarms, generating thousands of events daily. Network operators need an efficient method to identify the root causes of these alarms to mitigate potential losses. This task is challenging due to the increasing scale of telecommunication networks and the interconnected nature of devices, where one fault can trigger a cascade of alarms across multiple devices within a topological network. Recent years have seen a growing focus on causal approaches to addressing this problem, emphasizing the importance of learning a Granger causal graph from topological event sequences. Such causal graphs delineate the relations among alarms and can significantly aid engineers in identifying and rectifying faults. However, existing methods either ignore the topological relationships among devices or suffer from relatively low scalability and efficiency, failing to deliver high-quality responses in a timely manner. To this end, this paper proposes S\({}^{2}\)GCSL, a simple yet scalable Granger causal structural learning approach for topological event sequences. S\({}^{2}\)GCSL utilizes a linear kernel to model activation interactions among various event types within a topological network, and employs gradient descent to efficiently optimize the likelihood function. Notably, it can seamlessly incorporate expert knowledge as constraints within the optimization process, which enhances the interpretability of the outcomes. Extensive experimental results on both large-scale synthetic and real-world problems verify the scalability and efficacy of S\({}^{2}\)GCSL.

## 1 Introduction

Telecommunication networks are an important component of infrastructure of modern society, where thousands of alarms may be generated by various types of faults on a daily basis. It is crucial for network operators to efficiently identify the root causes of these alarms since for every additional minute that a fault persists in telecommunication networks, it can lead to significant economic losses and cause negative public sentiment. However, the increasing scale of telecommunication networks and the interconnected nature of devices make this task particularly challenging. A single fault has the potential to trigger a cascade of alarms across multiple devices within a topological network. How to model the generation of event sequences, especially in large-scale, multi-event-type scenarios, has become more and more urgent in the telecommunication network fault diagnosis (TNFD) task.

One promising approach to understanding and predicting the generation and propagation of event sequences is the application of Granger causality analysis , which in the context ofTNFD, can help in identifying whether a type of alarm can be the evidence of the occurrence of particular faults. As shown in the left panel of Figure 1, the mutual activation effects among various types of events are considered as a form of Granger causality and the task can be formulated as a causal structural learning problem. However, within the scope of learning Granger causality from event sequences, most of the methods rely on the assumption that event sequences are independent and identically distributed (i.i.d.). Yet, in the scenario of TNFD, the topological nature of devices inherently links events across the network, challenging the validity of such i.i.d. assumption.

Fortunately, a number of notable methods (Cai et al., 2024; Liu et al., 2024) have emerged very recently to solve the problem of Granger causal structural learning from event sequences under non-i.i.d. assumptions, where the generation of alarm sequences is modeled by the topological multivariate Hawkes process (TMHP) (Cai et al., 2024). However, all of these existing TMHP-based approaches suffer from the issue of efficiency or scalability, which is essential in the scenario of large-scale TNFD. Specifically, topological Hawkes process (THP) (Cai et al., 2024) proposes the TMHP model whose likelihood function of the Granger causal graph is optimized through a gradient-free manner, where the optimization of structure and parameter is decoupled, leading to relative inefficiency. On the other hand, the topological neural Poisson auto-regressive model (TNPAR) (Liu et al., 2024) proposes to utilize the neural point process (NPP) to implement the intensity function in TMHP, which greatly enhances the model's ability to model complex relationships among events. However, since NPP relies on deep neural networks, it lacks an analytical expression for its likelihood function. Consequently, optimization is only feasible through the prediction of event sequences, which slows down the training process and limits the model's scalability.

To address the challenges of scalability as well as efficiency presented in the TNFD task, this paper proposes S\({}^{2}\)GCSL, a simple yet scalable Granger causal structural learning approach for topological event sequences. S\({}^{2}\)GCSL utilizes a linear kernel to implement the activation effect among various event types and adopt a gradient descent manner to optimize the likelihood function. It is worth noting that multiple prior expert knowledge, namely, sparsity and acyclicity, can be integrated into this optimization procedure in a simple form of constraints, which improves the interpretability of results. Extensive experiments on both large-scale synthetic problems and a real-world TNFD problem on metropolitan telecommunication network alarm data verify the scalability and efficacy of S\({}^{2}\)GCSL. In a nutshell, the main contribution of this paper includes:

* We propose a simple yet scalable Granger causal structural learning method, incorporating simple modeling and gradient-based optimization, to efficiently infer Granger causal graph from topological event sequences of alarms in telecommunication networks.
* By incorporating experts' prior knowledge as constraints into the objective function, we provide a simple method to guarantee the interpretability during the process of optimization within the context of TNFD.
* Extensive experiments show that S\({}^{2}\)GCSL not only achieves superior performance in effectiveness, efficiency and scalability, but also maintains robustness across diverse scenarios, validating its practical applicability in real-world telecommunication network environments.

Figure 1: The left panel shows an example of the topological event sequences generated by a mobile network, where a Granger causal graph is expected to be inferred to serve the TNFD task. The right panel illustrates the abstracted generation and inference processes. Solid lines represent the data generation process for event sequences, while dashed lines correspond to the inference process for the causal graph. Solid circles denote observed variables, and dashed circles represent latent variables.

The subsequent sections of this paper respectively recap the related work, introduce the proposed method, present the experimental results and analysis, and finally conclude the paper.

## 2 Related Work

**Temporal Point Processes.** Temporal point processes are stochastic processes used for modeling event sequences. They can be categorized into statistical point processes and neural point processes. Statistical point processes focus on developing appropriate intensity functions, often with parameters that have specific physical interpretations. Examples of statistical point processes include the Poisson process (Cox and R, 1955), Hawkes process (Hawkes and G, 1971), self-correcting process (Isham et al., 1979) and reactive point process (Ertekin et al., 2015). On the other hand, NPP (Shchur et al., 2021) utilize the powerful learning capabilities of neural networks to implement the intensity functions, allowing the model to potentially capture complex relationships among events.

**Granger Causality for Event Sequences.** Various methods exist for discovering Granger causality from event sequences. For example, Hawkes process based methods (Zhou et al., 2013; Xu et al., 2016) operate on the assumption that past events stimulate the occurrence of related events in the future only if the former Granger causes the latter. However, these Hawkes process based methods significantly rely on the i.i.d. assumption, which is violated in TNFD due to the interconnected nature of devices. To address the non-i.i.d. challenge, THP (Cai et al., 2024) generalizes the Hawkes process to non-i.i.d. case by incorporating the topological information among devices. However, due to the use of gradient-free optimization to search for Granger causal structures, THP has efficiency shortcomings, which could undermine its competitiveness in the TNFD task. Inspired by THP, TNPAR (Liu et al., 2024) further proposes to utilize an NPP to model the intensity function, which significantly improves the model's capability to represent intricate event relationships. However, due to the lack of an analytical expression for the likelihood function, NPP optimization is limited to reconstructing training data from event sequences and conducting training in a supervised learning manner, which not only lacks theoretical guarantees but also performs relatively inefficient. This could make TNPAR unable to handle large-scale problems as well. Other NPP based methods include causality from attributions on sequence of events (CAUSE) (Zhang et al., 2020) and transformer Hawkes process (TransHP) (Zuo et al., 2020). CAUSE uses an attribution method to extract Granger causality from the well-trained NPP, and in TransHP, the temporal dependencies among event sequences are captured by a transformer. These NPP based methods are typically flexible, and thus can incorporate topology information through some modifications. Unfortunately, the scalability of these methods are also not ideal due to the same reason as TNPAR.

In a different context, our work is also related to Granger causal discovery from time series. In (Brillinger and R, 1994), researchers aggregate event sequences into time series, enabling the analysis of event sequences using auto-regressive models. Amortized causal discovery (ACD) (Lowe et al., 2022) applies an amortized model to infer Granger causal structures from time series. In addition, PC with momentary conditional independence test (PCMCI) (Runge, 2020) and methods based on transfer entropy (Mijatovic et al., 2021; Chen et al., 2020), are founded on strict causal assumptions rather than Granger causality and utilize independence tests or measures to discover the causal structure from event sequences.

## 3 The Proposed S\({}^{2}\)Gcsl

### Problem Formulation

In the problem of learning Granger causal structure from topological event sequences in telecommunication networks, suppose the topological connections between devices are represented as an undirected graph \(_{N}(,})\), where \(\) is the device set and the edges \(E_{N}\) indicate physical connections between these devices. Besides, a directed graph \(_{V}(,})\) captures the Granger causal relationships among different event types \(\), with \(}\) representing the causal edges between two different event types. In this scenario, an event can not only influence future events at its location but also at devices that are topologically connected to it.

Given this setup, we consider topological event sequences of length \(m\), denoted by \(=\{(v_{i},n_{i},t_{i},_{i})|i\{1,,m\}\}\). These sequences arise from the causal interactions defined in \(_{V}\) and occur within the structure of \(_{N}\). Here, \(v_{i}\) represents the event type, \(n_{i}\) denotes the device where the event occurs, \(t_{i}[0,T]\) refer to the start timestamps of the event and \(_{i}^{+}\) denotes how many timestamps the event last. We can model the occurrence of these events as a series of counting processes \(\{C_{v,n}(t)|v,n,t[0,T]\}\), where \(C_{v,n}(t)\) counts the number of times event type \(v\) has occurred at device \(n\) up to time \(t\). For practical analysis, the continuous interval \([0,T]\) is segmented into \([T/]\) smaller intervals, where \(^{+}\) is chosen based on the application context. The number of occurrences within these intervals are recorded as \(^{,}=\{O_{t}^{v,n}|t\{1,, T/\},v ,n\}\), where \(O_{t}^{v,n}=C_{v,n}(t)-C_{v,n}((t-1))\) reflects the occurrences of event type \(v\) on device \(n\) within the interval \(((t-1),t]\).

Assuming that the counting processes within each time interval follow a Poisson process, where the intensity \(_{t}^{v,n}\) refers to the expected number of occurrences in an interval of event type \(v\) on device \(n\) at time \(t\), and the probability of observing \(O_{t}^{v,n}\) occurrences can be formulated using the Poisson probability function as follows:

\[P(O_{t}^{v,n}=o)=^{v,n})^{o}}{o\,!}e^{-_{t}^{v,n}}, o=0,1,2,\,.\] (1)

This sets the stage to define the problem of causal discovery from topological event sequences as Definition 1 below.

**Definition 1** (Granger Causal Discovery from Topological Event Sequences).: _Given the records of event sequences \(=\{(v_{i},n_{i},t_{i},_{i})|i\{1,,m\}\}\), and the existing topological network \(_{N}(,_{})\), the objective of Granger causal discovery from topological event sequences is to deduce the Granger causal graph \(_{V}(,_{})\) among the event types._

To address this problem, we introduce the S\({}^{2}\)GCSL model, which includes both a generation process and an inference process.

### Generation Process of the Event Sequences

The generation process of S\({}^{2}\)GCSL is illustrated with solid lines in the right panel of Figure 1, where the occurrence \(O_{t}^{v_{i},n_{j}}\) is influenced by historical event sequences \(_{h}=\{(v_{i},n_{i},t_{i},_{i})|t_{i}<t t_{i}+_{i}\}\), along with two types of matrices, \(\) and \(_{0:k}\). Here, \(\) is a \(||||\) binary matrix indicating Granger causality between event types. The element \(_{v_{i},v_{j}}\) from matrix \(\) at row \(i\) and column \(j\) denotes the causality: if \(_{v_{i},v_{j}}=0\), it means that there is no Granger causality between event type \(v_{i}\) and \(v_{j}\). Otherwise, there exists a causality. \(_{0:k}\) represents a set of matrices \(\{_{0},_{1},,_{k}\}\), where each \(_{k}\) is a \(||||\) binary matrix showing the physical connections between devices at a geodesic distance [Bouttier et al., 2003] of \(k\) within \(_{N}\). The element \(_{n_{i},n_{j}}^{k}\) in matrix \(_{k}\) at row \(i\) and column \(j\) specifies this connection: if \(_{n_{i},n_{j}}^{k}=1\), then the geodesic distance between device \(n_{i}\) and \(n_{j}\) is less than or equal to \(k\). Otherwise, \(_{n_{i},n_{j}}^{k}\) is set to \(0\).

In this paper, we utilize a linear activation function to model the causal relationships among event types, and the intensity \(_{t}^{v,n}\) of an event type \(v\) on a device \(n\) is given as:

\[_{t}^{v,n}=^{v,n}+_{i:t_{i}<t t_{i}+_{i}}_{v_{i}v} _{v_{i},v}_{n_{i},n}^{k}\,,\] (2)

where \(^{v,n}\) is a constant representing the baseline intensity of event type \(v\) on device \(n\) and \(_{v_{i}v}\) is a coefficient denoting the activation intensity of event type \(v_{i}\) on event type \(v\), which can be considered as the Granger causality of \(v_{i} v\). \(_{i:t_{i}<t t_{i}+_{i}}\) means the summation over all the events \(j\) that the event \(i\) occurs during the duration of \(j\).

Counterintuitively, such a simple assumption based on linear activation function can effectively model complex functions that depict how event intensities vary over time. This capability arises because the intensity of an event at a given time may be influenced by countless preceding events. Even though the impact of each individual event is simple, the superposition of numerous linear functions can approximate arbitrarily complex intensity functions.

### Inference Process of the Granger Causal Graph

The inference mechanism of S\({}^{2}\)GCSL is illustrated with dashed lines in the right panel of Figure 1. The diagram indicates that the causal matrices \(\) are deduced by integrating the current event occurrences \((t_{0})\), historical event sequences \(_{h}=\{(v_{i},n_{i},t_{i},_{i})|t_{i}<t t_{i}+_{i}\}\), and the topological network \(_{0:k}\).

Considering the generation model defined in Eq. 2, the coefficient \(_{v_{i}v}\) is treated as the Granger causality statistic of event type \(v_{i}\) on event type \(v\). Consequently, the weighted Granger causal matrix \(}^{||||}\), where \(^{}_{i,j}=_{i,j}_{i,j}\), along with the baseline intensity matrix \(\) can be seen as the parameters of the generation model \(=\{},\}\), and the log-likelihood function of \(\) given the observed event sequences \(=\{(v_{i},n_{i},t_{i},_{i})|i\{1,,m\}\}\) can be expressed as follows:

\[L(},) =_{n}(_{i:n_{i}=n}_{t_{i}}^{v_{i},n}- _{v}_{0}^{T}_{t}^{v,n}\,dt)\] \[=_{n}(_{i:n_{i}=n}(^{v_{i},n}+_{j:t_{j}<t _{i} t_{j}+_{j}}}_{v_{j},v_{i}}_{n_{j},n_{i}}^{k}).\] \[.-T_{v}^{v,n}-_{v}_{i:n_{i}=n}} _{v_{i},v}_{n_{i},n}^{k}_{i})\,,\] (3)

where \(_{i:n_{i}=n}\) means the summation over all the events \(i\) that occur on device \(n\). With such log-likelihood function, the Granger causal discovery problem can be transformed into the following optimization problem that estimates the optimal parameters \(^{}=\{},}\}\) as:

\[},}=*{arg\,min}_{}, {}}-L(},)\,,\] (4)

where \(}\) denotes the inferred weighted Granger causal matrix.

As mentioned before, some prior expert knowledge of the causal structures in the TNFD scenario should be taken into consideration to ensure the inferred causal graph interpretable. Specifically, we focus on two properties of the causal graph among event types, namely sparsity and acyclicity. The sparsity of activation effects suggest that most event types only influence a small fraction of other event types in telecommunication networks. The sparsity can be reflected in the entry-norm constraint of \(}\) as:

\[||}||_{1}=_{i=1}^{||}_{j=1}^{||}|}_{i,j}|\,,\] (5)

where \(||}||_{1}\) denotes the \({}_{1,1}\) entry-norm of \(}\) and \(\) is a small positive constant.

Besides, acyclicity suggests that the activation effects among event types should not form cycles and there is no self-excitation. As a result, the deduced causal graph should a DAG, which motivates us to introduce the acyclic constraint (Zheng et al., 2018) as:

\[h(})=trace[(+}})^{ ||}]-|V|=0\,,\] (6)

where \(\) is the identity matrix, \(\) is a constant and \(\) denotes the Hardamard product. Consequently, the optimization with constraints can be written as:

\[_{},}-L(},) s.t.||}||_{1},h(})=0\,.\] (7)

By leveraging the Lagrangian multiplier method, the final optimization problem is defined as:

\[},}=*{arg\,min}_{}, {}}-L(},)+_{1}||}||_{1}+_ {2}h(})\,,\] (8)

where \(_{1}\) and \(_{2}\) refer to the regularized hyperparameters. For the optimization procedure, the Adam optimizer (Kingma and Ba, 2015) which is known for its efficiency and stability is adopted with learning rate \(lr=0.05\).

After the optimization, we got the weighted Granger causal matrix \(^{}\), and to deduce the final binary adjacency matrix \(\), edges with too small weights are pruned, i.e.,

\[=(a_{i,j}), a_{i,j}=1&^{}_{i,j}> \\ 0&^{}_{i,j},\] (9)

and \(\) is a constant hyperparameter to control the pruning threshold.

## 4 Experiments

In this section, we will implement the proposed \(^{2}\)GCSL method and the baseline approaches on both simulated data and metropolitan telecommunication network alarm data. All methods will undergo testing using 10 different random seeds, and the results will be reported in the form of mean and standard deviation over these 10 repetitions. The evaluation metrics for the experiments will encompass F1 score (Powers, 2020), Structural Hamming Distance (SHD), and Structural Intervention Distance (SID) (Peters and Buhlmann, 2015).

Specifically, precision denotes the proportion of predicted edges that are actually present among the true edges, while recall represents the proportion of true edges that have been correctly predicted. F1 score is the weighted harmonic mean of both Precision and Recall, and is calculated as \(F1=\), the higher F1 score the better (\(\)). SHD indicates the number of edge insertions, deletions, or flips required to transform one graph into another, the lower SHD the better (\(\)). SID is a measure that quantifies the similarity between two DAGs based on their corresponding causal inference statements, the lower SID the better (\(\)).

In experiments, we use the following Granger causal discovery methods as comparisons: TNPAR (Liu et al., 2024), ADM4 (Zhou et al., 2013), CAUSE (Zhang et al., 2020), PCMCI (Runge, 2020), MLE_SGL (Xu et al., 2016) and ACD (Lowe et al., 2022). We would like to point out that THP (Cai et al., 2024) and TransHP (Zuo et al., 2020) are not included because they are too inefficient to produce results within required time under most settings. All the experiments are conducted on a Linux server with two 3.00GHz Intel Xeon Gold 6354 CPUs and one RTX3090 GPU. All the models are implemented by PyTorch (Paszke et al., 2019), and the code is available at https://github.com/Mingjiali666/S2GCSL.

### Implementation and Hyperparameters

In the algorithm implementation of \(^{2}\)GCSL, the involved hyperparameters include: the geodesic distance in the topological network \(k\), the regularization coefficients \(_{1}\), \(_{2}\) and the pruning threshold \(\). In the synthetic experiments, we set these hyperparameters as follows: \(k=2\), \(=1 10^{-3}\). Worth noting that the proper values of \(_{1}\) and \(_{2}\) are related to the scale of sample size and thus vary over different settings. We adopt a heuristic way to estimate the proper range of \(_{1}\), \(_{2}\) that calculate the local gradient of loss over \(||^{}||_{1}\) and \(h(^{})\) respectively. In the real-world experiments, we set the hyperparameters as follows: \(k=1\), \(=5 10^{-4}\), \(_{1}=5 10^{5}\) and \(_{2}=1 10^{5}\).

### Synthetic Experiments

#### 4.2.1 Synthetic Experimental Setup

The synthetic data is generated in the following manner: a) A Granger causal graph and a topological graph are randomly created using \(Erds\)\(Rnyi\) random graph generator. b) Root event records are produced using a Poisson process with a base intensity parameter \(\) in the Hawkes process. These root event records occur spontaneously within the system. c) Based on the root event records, propagated event records are discretely generated according to both the time interval \(\) and the excitation coefficient \(\). It is worth noting that event sequences can be sparse in real-world scenarios. To address this, a time interval parameter \(\) is introduced to the generation process, dividing the time domain \([0,T]\) into small intervals with indexes as \(\{1,, T/\}\) where \(\) refers to the ceiling function. Then, the event records can be summarized within the same timestamp. Note that \( 0\), and \(=0\) implies the use of the original event sequences. The simulated data is generated by systematically varying one parameter at a time in the generation process, while keeping the default parameters constant. The parameters included in the generation process are as follows: the number of devices (\(||\)), the number of event types (\(||\)), the sample size (\(m\)), the range of baseline intensity (\(\) range), the range of activation intensity (\(\) range) and the time interval \(\). The ranges of the above parameters are: \(||=\{20,,60,80\}\), \(||=\{5,10,15,,25,50,100\}\), \(m=\{50\,000,100\,000,150\,000,,250\,000,300\,000\}\), \(\) range \(( 10^{-5})=\{(1,3),,(5,7),(7,9)\}\), \(\) range \(( 10^{-2})=\{(1,2),,(3,4),(4,5),(5,6)\}\) and \(=\{1,,3,4,5\}\), where the default parameters are denoted in bold.

#### 4.2.2 Results on Synthetic Data

**Effectiveness.** The F1 Score, SHD and SID of different methods on the synthetic data are shown in Figure 2, 3 and 4 respectively. Note that if the result for a particular baseline is missing at some points, it indicates that the method is unable to produce results within 1 hour (S\({}^{2}\)GCSL gives results for problems with 100 event types in approximately 9 minutes.) under the setting of such points. Based on the results depicted in these 3 figures, S\({}^{2}\)GCSL exhibit superior effectiveness across all scenarios when compared to other baselines. Besides, from Figure 2, S\({}^{2}\)GCSL demonstrates strong robustness across all parameters including both baseline activation intensity, the sample size of data, the time interval of recording, the causal graph scale and the topological network scale. Such results indicate the robustness of S\({}^{2}\)GCSL, i.e., S\({}^{2}\)GCSL is expected to be effective in most scenarios.

Figure 3: The SHD of different methods on synthetic data.

Figure 2: The F1 Scores of different methods on synthetic data.

**Efficiency.** The wall-clock execution time results of different methods on different scale of problems are presented in Table 1. According to Table 1, S\({}^{2}\)GCSL is able to produce results within 10 minutes even for problems scaling up to 100 event types. Worth noting that only two of the compared methods, namely S\({}^{2}\)GCSL and ADM4, are scalable to problems with 50 event types, both of which have nearly an order of magnitude advantage on efficiency over other methods in comparison. Besides, compared to ADM4, S\({}^{2}\)GCSL is more efficient on larger-scale problems (25 and 50), indicating its greater potential for application in large-scale real-world scenarios (Given that the real-world problem involved in this paper is with 38 event types).

**Summary.** To sum up, considering both effectiveness and efficiency, S\({}^{2}\)GCSL demonstrates clear advantages in effectiveness and scalability compared to other methods, thanks to its simple yet problem-adapted design. In the next subsection, this paper will study the performance of S\({}^{2}\)GCSL on a real-world TNFD task in metropolitan telecommunication networks.

### Real-World Experiments

#### 4.3.1 Metropolitan Telecommunication Network Alarm Data

The real-world dataset utilized in this study was sourced from a business setting in metropolitan telecommunication network collected by a multinational communications company and is accessible through the NeurIPS 2023 competition of _Causal Structure Learning from Event Sequences and Prior Knowledge_3 (Phase 2 real-world dataset). It comprises a sequence of alarm records generated based on both a topological network \(_{N}\) and a causal structure \(_{V}\). The topological network \(_{N}\) consists of

   Algorithms & 5 & 10 & 15 & 20 & 25 & 50 & 100 \\  S\({}^{2}\)GCSL & \(}\) & \(}\) & \(}\) & \(5.48 10^{1}\) & \(8.64 10^{1}\) & \(}\) & \(}\) \\ TNPAR & \(3.61 10^{2}\) & \(6.40 10^{2}\) & \(7.82 10^{2}\) & \(9.93 10^{2}\) & \(1.46 10^{3}\) & - & - \\ ADM4 & \(1.17 10^{1}\) & \(2.11 10^{1}\) & \(3.00 10^{1}\) & \(}\) & \(}\) & \(2.51 10^{2}\) & \(7.58 10^{2}\) \\ CAUSE & \(6.88 10^{2}\) & \(9.05 10^{2}\) & \(1.21 10^{3}\) & \(1.66 10^{3}\) & \(1.92 10^{3}\) & - & - \\ PCMCI & \(1.70 10^{1}\) & \(2.58 10^{2}\) & \(8.91 10^{2}\) & \(1.78 10^{3}\) & \(2.86 10^{3}\) & - & - \\ MLE\_SGL & \(1.28 10^{2}\) & \(3.22 10^{2}\) & \(6.04 10^{2}\) & \(8.23 10^{2}\) & \(1.08 10^{3}\) & - & - \\ ACD & \(3.80 10^{1}\) & \(9.90 10^{1}\) & \(1.93 10^{2}\) & \(2.35 10^{2}\) & \(4.70 10^{2}\) & - & - \\   

Table 1: The wall-clock execution time (s) of different methods on different scale of synthetic problems. The algorithm with the highest efficiency under each scale of problem is marked in bold, and “-” indicates that results cannot be obtained within one hour.

Figure 4: The SID of different methods on synthetic data.

65 devices, and the alarm records cover 38 types of alarm events, amounting to 492,877 alarm event records. It is worth noting that, due to the equipment characteristics and as verified by experts, the collected timestamps of alarm events display specific time intervals.

#### 4.3.2 Results on Metropolitan Telecommunication Network Alarm Data

The results of the experiments on metropolitan telecommunication network alarm data can be found in Table 2, where the F1 Score, SHD, SID and wall clock execution time (ET(s)) for the compared methods are reported. The results show that the methods incorporating the topological network (S\({}^{2}\)GCSL, CAUSE and TNPAR) outperform those that rely on the i.i.d. assumption with respect to F1 Score. This suggests that in the real-world telecommunications networks, alarm events do indeed propagate through devices within the topological network, consistent with the expert's knowledge and our model assumptions. However, both TNPAR and CAUSE take over an hour (for CAUSE, it needs 2 hours) to produce results, which is unacceptable in the race against time for TNFD, compared to just over ten minutes for S\({}^{2}\)GCSL. From the perspective of effectiveness, S\({}^{2}\)GCSL shows the highest F1 Score and the lowest SHD, indicating its relative insensitivity to weak Granger causal strength between event types, which may exhibit in real-world scenarios [Liu et al., 2024]. Additionally, S\({}^{2}\)GCSL achieves a good SID, only being slightly higher than PCMCI (however, this is because PCMCI often deduce very sparse causal graphs), which highlight S\({}^{2}\)GCSL's superior capability for causal inference [Peters and Buhlmann, 2015]. Therefore, from a comprehensive perspective, only S\({}^{2}\)GCSL has the potential to be applied and work well in real-world scenarios.

## 5 Conclusion

This paper addresses the critical issue of fault diagnosis in large-scale telecommunication networks by proposing a simple method for efficient and scalable Granger causal structural learning from topological event sequences. The proposed approach, referred to as S\({}^{2}\)GCSL, leverages a linear kernel to model the activation effects among different event types and uses gradient descent for the optimization of the likelihood function. This method simplifies the modeling and the optimization process to enhance the scalability and efficiency of inferring causal structures from large datasets of network alarms. Besides, S\({}^{2}\)GCSL also include the integration of expert knowledge as constraints within the optimization process, ensuring the model's explainability via aligning with domain-specific insights, which is crucial for practical applications. By conducting extensive experiments on both synthetic datasets and real-world data from a metropolitan telecommunication network, we verify that S\({}^{2}\)GCSL significantly outperforms existing methods in terms of scalability or efficiency, while maintaining good effectiveness.

Despite the advancements presented in this paper, there are several limitations that suggest avenues for future research. Firstly, while S\({}^{2}\)GCSL provides an efficient solution for large-scale datasets, its application is currently limited by the simplicity of its modeling approach. The linear kernel may not capture the full complexity of interactions in more dynamically evolving network environments where non-linear relationships and non-stationary patterns prevail. Additionally, further research could focus on extending the applicability of S\({}^{2}\)GCSL to other types of networks, such as power grids

   Algorithms & F1 Score (\(\)) & SHD (\(\)) & SID (\(\)) & ET(s) (\(\)) \\  S\({}^{2}\)GCSL & \(}\) & \(}\) & \(397_{ 30.2}\) & \(\)s \\ TNPAR & \(0.23_{ 0.06}\) & \(83.1_{ 6.07}\) & \(543_{ 62.6}\) & 4604s \\ ADM4 & \(0.19_{ 0.03}\) & \(83.5_{ 4.15}\) & \(475_{ 50.4}\) & 861s \\ CAUSE & \(0.29_{ 0.04}\) & \(78.1_{ 4.09}\) & \(468.7_{ 29.4}\) & 7209s \\ PCMCI & \(0.08_{ 0.02}\) & \(75.5_{ 4.32}\) & \(}\) & 9342s \\ MLE\_SGL & \(0.19_{ 0.05}\) & \(77.2_{ 4.77}\) & \(406_{ 29.0}\) & 3253s \\ ACD & \(0.14_{ 0.04}\) & \(107_{ 6.07}\) & \(655_{ 54.6}\) & 1943s \\   

Table 2: Performances of different methods on metropolitan telecommunication network alarm data. The algorithm perform best under each metric is highlighted in bold.

or transport networks, where similar challenges in fault diagnosis are present. This would involve adapting the current framework to different kinds of event data and potentially different topologies.