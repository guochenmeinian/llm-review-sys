# Bounce: Reliable High-Dimensional Bayesian Optimization for Combinatorial and Mixed Spaces

Leonard Papenmeier

Lund University

leonard.papenmeier@cs.lth.se

&Luigi Nardi

Lund University, Stanford University, DBtune

luigi.nardi@cs.lth.se

&Matthias Poloczek

Amazon

San Francisco, CA 94105, USA

matpol@amazon.com

###### Abstract

Impactful applications such as materials discovery, hardware design, neural architecture search, or portfolio optimization require optimizing high-dimensional black-box functions with mixed and combinatorial input spaces. While Bayesian optimization has recently made significant progress in solving such problems, an in-depth analysis reveals that the current state-of-the-art methods are not reliable. Their performances degrade substantially when the unknown optima of the function do not have a certain structure. To fill the need for a reliable algorithm for combinatorial and mixed spaces, this paper proposes Bounce that relies on a novel map of various variable types into nested embeddings of increasing dimensionality. Comprehensive experiments show that Bounce reliably achieves and often even improves upon state-of-the-art performance on a variety of high-dimensional problems.

## 1 Introduction

Bayesian optimization (BO) has become a 'go-to' method for optimizing expensive-to-evaluate black-box functions [27; 83] that have numerous important applications, including hyperparameter optimization for machine learning models [9; 27], portfolio optimization in finance , chemical engineering and materials discovery [13; 15; 26; 33; 37; 38; 40; 57; 68; 71; 81], hardware design [22; 36; 51], or scheduling problems . These problems are challenging for a variety of reasons. Most importantly, they may expose hundreds of tunable parameters that allow for granular optimization of the underlying design but also lead to high-dimensional optimization tasks and the 'curses of dimensionality' [10; 63]. Typical examples are drug design [53; 76] and combinatorial testing . Moreover, real-world applications often have categorical or ordinal tunable parameters, in addition to the real-valued parameters that BO has traditionally focused on [10; 27; 70]. Recent efforts have thus extended BO to combinatorial and mixed spaces. Casmopolitan of Wan et al.  uses trust regions (TRs) to accommodate high dimensionality, building upon prior work of Eriksson et al.  for continuous spaces. COMBO of Oh et al.  constructs a surrogate model based on a combinatorial graph representation of the function. Recently, Deshwal et al.  presented BOD1 that employs a novel type of dictionary-based embedding and showed that it outperforms the prior work. However, the causes for BOD1's excellent performance are not yet well-understood and require a closer examination. Moreover, the ability of methods for mixed spaces to scale to higher dimensionalities trails behind BO for continuous domains. In particular, Papenmeier et al.  showed that nested embeddings allow BO to handle a thousand input dimensions, thus outperforming vanilla TR-based approaches and raising the question of whether similar performance gains are feasible for combinatorial domains.

In this work, we assess and improve upon the state-of-the-art in combinatorial BO. In particular, we make the following contributions:

1. We conduct an in-depth analysis of two state-of-the-art algorithms for combinatorial BO, COMBO and BODi. The analysis reveals that their performances often degrade considerably when the optimum of the optimization problem does not exhibit a particular structure common for synthetic test problems.
2. We propose Bounce (**B**ayesian **o**ptimization **u**sing increasingly high-dimensional combinatorial and continuous embeddings), a novel high-dimensional Bayesian optimization (HDBO) method that effectively optimizes over combinatorial, continuous, and mixed spaces. Bounce leverages parallel function evaluations efficiently and uses nested random embeddings to scale to high-dimensional problems.
3. We provide a comprehensive evaluation on a representative collection of combinatorial, continuous, and mixed-space benchmarks, demonstrating that Bounce is on par with or outperforms state-of-the-art methods.

## 2 Background and related work

Bayesian optimization.Bayesian optimization aims to find the global optimum \(^{*}\) of a black-box function \(f:\), where \(\) is the \(D\)-dimensional search space or _input space_. Throughout this paper, we consider minimization problems, i.e., we aim to find \(^{*}\) such that \(f(^{*}) f()\) for all \(\). The search space \(\) may contain variables of different types: continuous, categorical, and ordinal. We denote the number of continuous variables in \(\) by \(n_{}\) and the number of combinatorial variables by \(n_{}=n_{}+n_{}=D-n_{}\), where we denote the number of categorical variables by \(n_{}\) and the number of ordinal variables by \(n_{}\).

Combinatorial domains.Extending BO to combinatorial spaces is challenging, for example, because the acquisition function is only defined at discrete locations or the dimensionality of the space grows drastically when using one-hot encoding for categorical variables. Due to its numerous applications, combinatorial BO has received increased attention in recent years. BOCS handles the exponential explosion of combinations by only modeling lower-order interactions of combinatorial variables and imposing a sparse prior on the interaction terms. COMBO models each variable as a graph and uses the graph-Cartesian product to represent the search space. We revisit COMBO's performance on categorical problems in Appendix H.1. CoCaBo combines multi-armed bandits and BO to allow for optimization in mixed spaces. It uses two separate kernels for continuous and combinatorial variables and proposes a weighted average of a product and a sum kernel to model mixed spaces. Liu and Wang  show that certain, possibly combinatorial functions can be modeled by parametric function approximators such as neural networks or random forests. As a general method to optimize the acquisition function with gradient-based methods, Daulton et al.  propose probabilistic reparametrization.

High-dimensional continuous spaces.Subspace-based methods are primarily used for continuous spaces. Wang et al.  propose REMBO for HDBO in continuous spaces using Gaussian random projection matrices. REMBO suffers from distortions and projections outside the search domains that the corrections of Binois et al. [11; 12] address. The HeSBO algorithm of Nayebi et al.  avoids the need for corrections by using the CountSketch embedding . Alebo of Letham et al.  builds upon REMBO, learning suitable corrections of distortions. TuRBO is a method that operates in the full-dimensional input space \(\), relying on trust region (TR) to focus the search on promising regions of the search space. BAxUS of Papenmeier et al.  combines the trust region approach of TuRBO with the random subspace idea of HeSBO. BAxUS uses a novel family of _nested_ random subspaces that exhibit better theoretical guarantees than the CountSketch embedding. While BAxUS handled a \(1000D\) problem, it only considers continuous problems and cannot leverage parallel function evaluations. GTBO assumes the existence of an axis-aligned active subspace. The algorithm first identifies "active" variables and optimizes in the full-dimensional space by placing separate strong length scale priors onto active and inactive variables. Another line of recent approaches employs Monte-Carlo tree search (MCTS) to reduce the complexity of the problem. Wang et al.  use MCTS to learn a partitioning of the continuous search space to focus the search on promising regions in the search space. Song et al.  use a similar approach, but instead of learning promising regions in the search space, they assume an axis-aligned active subspace and use MCTS to select important variables. Linear embeddings and random linear embeddings [14; 46; 52; 60; 84] require little or no training data to construct the embedding but assume a linear subspace.

Combinatorial high-dimensional domains.These works optimize black-box functions defined over a combinatorial or mixed space with dozens of input variables. Thebelt et al.  use a tree-ensemble kernel to model the Gaussian process (GP) prior and derive a formulation of the upper-confidence bound (UCB) that allows it to be optimized globally and to incorporate constraints. RDUCB  relies on random additive decompositions of the GP kernel to model the correlation between variables. Casmopolitan follows TuRBO in using TRs to focus the search on promising regions of the search space and uses the Hamming distance to model TRs for combinatorial variables. For mixed spaces, Casmopolitan uses interleaved search and models continuous and categorical variables with two separate TRs. Kim et al.  use a random projection matrix to approach combinatorial problems in a continuous embedded subspace. When evaluating a point, their approach projects the continuous candidate point to the high-dimensional search space and then rounds to the next feasible combinatorial solution. Deshwal et al.  propose two algorithms for _permutation spaces_, which occur in problems such as compiler optimization  and pose special challenges due to the superexponential explosion of solutions. BDDi proposes an embedding type based on a dictionary of anchor points in the search space. The pairwise Hamming distances between the point and each anchor point \(_{i}\) in the dictionary represent a point in the search space. The anchor points in the dictionary change at each iteration of the algorithm. They are sampled from the search space to cover a wide range of'sequencies', i.e., the number of changes from \(0\) to \(1\) (and vice versa) in the binary vector. The authors hypothesize that the diverse sampling procedure leads to BDDi's remarkable performance in combinatorial spaces with up to \(60\) dimensions. To our knowledge, BDDi is the only other method combining embeddings and combinatorial spaces. We show in Section 4.6 that BDDi's reported good performance relies on an artificial structure of the optimizer \(^{}\) and that its performance degrades considerably when this structure is violated.

## 3 The Bounce algorithm

To overcome the aforementioned challenges in HDBO for real-world applications, we propose Bounce, a new algorithm for continuous, combinatorial, and mixed spaces. Bounce uses a GP  surrogate in a lower-dimensional subspace, the _target space_, that is realized by partitioning input variables into 'bins', the so-called _target dimensions_. Bounce only bins variables of the same type (categorical, binary, ordinal, and continuous). When selecting new points to evaluate, Bounce setsall input variables within the same bin to a single value. It thus operates in a subspace of lower dimensionality than the input space and, in particular, maximizes the acquisition function in a subspace of lower dimensionality. Bounce iteratively refines its subspace embedding by splitting bins into smaller bins, allowing for a more granular optimization at the expense of higher dimensionality. Note that by splitting up bins, Bounce asserts that observations taken in earlier subspaces are contained in the current subspace; see Papenmeier et al.  for details. Thus, Bounce operates in a series of nested subspaces. It uses a novel TR management to leverage batch parallelism efficiently, improving over the single point acquisition of BAxUS.

The nested subspaces.To model the GP in low-dimensional subspaces, Bounce leverages BAxUS' family of nested random embeddings . In particular, Bounce employs the sparse count-sketch embedding  in which each input dimension is assigned to exactly one target dimension. When increasing the target dimensionality, Bounce creates \(b\) new bins for every existing bin and redistributes the input dimensions that had previously been assigned to that bin across the now \(b+1\) bins. Bounce allocates an individual evaluation budget \(m_{i}\) to the current target space \(_{i}\) that is proportional to the dimensionality of \(_{i}\). When the budget for the current target space is depleted, and Bounce has not found a better solution, Bounce will increase the dimension of the target space until it reaches the input space of dimensionality \(D\). Let \(d_{}\) denote the dimensionality of the first target space, i.e., the random embedding that Bounce starts with. Then Bounce has to increase the target dimension \(_{b+1}D/d_{} k\)-times to reach the input dimensionality \(D\). After calculating \(k\), Bounce re-sets the split factor \(b\) such that the distance between the predicted final target dimensionality \(d_{k}=d_{}(b+1)^{k}\) and the input dimensionality \(D\) is minimized: \(b=_{k}(D/d_{})-1\), where \( x\) denotes the integer closest to \(x\). This ensures that the predetermined evaluation budget for each subspace will be approximately proportional to its dimensionality. This contrasts to BAxUS that uses a constant split factor \(b\) and adjusts the initial target dimensionality \(d_{}\). The evaluation budget \(m_{i}\) for the \(i\)-th subspace \(_{i}\) is \(m_{i} d_{i}}{d_{} (1-(b+1)^{k+1})}\), where \(m_{D}\) is the budget until \(D\) is reached and \(b\) is the maximum number of bins added per split.

Trust region management.Bounce follows TuRBO and Casmopolitan in using trust regions (TRs) to efficiently optimize over target spaces of high dimensionality. TRs allow focusing on promising regions of the search space by restricting the next points to evaluate to a region centered at the current best function value . TR-based methods usually expand their TR if they find better points and conversely shrink it if they fail to make progress. If the TR falls below the threshold given by the _base length_, TuRBO and Casmopolitan restart with a fresh TR elsewhere. Casmopolitan uses different base lengths for combinatorial and continuous variables. For combinatorial variables, the distance to the currently best function value is defined in terms of the Hamming distance, and the base length is an integer. For continuous variables, Casmopolitan defines the base length in terms of the Euclidean distance, i.e., a real number. Similarly, Bounce has separate base lengths \(L_{}^{}\) and \(L_{}^{}\) for continuous and combinatorial variables but does not fix the factor by which the TR volume is increased or decreased upon successes or failures. Instead, the factor is adjusted dynamically so that the evaluation budget \(m_{i}\) for the current target space \(_{i}\) is adhered to. This design is crucial to enable batch parallelism, as we describe next.

Batch parallelism.We allow Bounce to efficiently evaluate batches of points in parallel by using a scalable TR management strategy and \(q\)-expected improvement (qEI)  as the acquisition function for batches of size \(B>1\). When Bounce starts with a fresh TR, we sample \(n_{}\) initial points to initialize the GP, using a Sobol sequence for continuous variables and uniformly random values for combinatorial variables.

The TR management strategy of Bounce differs from previous strategies  in that it uses a dynamic factor to determine the TR base length. Recall that Bounce shrinks the TR if it fails to make progress and starts a fresh TR if the TR falls below the threshold given by the base length. Bounce's rule is based on the idea that the minimum admissible TR base length should be reached when the current evaluation budget is exhausted. If one employed the strategies of TuRBO, Casmopolitan, or BAxUS for larger batch sizes \(B\) and Bounce's nested subspaces, then one would spend a large part of the evaluation budget in early target spaces. For example, suppose a continuous problem, the common values for the initial, minimum, and maximum TR base length, and the constant shrinkage factor of . Then, such a method has to shrink the TR base length at least seven times (i.e., evaluate \(f\)\(7B\)-times) before it would increase the dimensionality of the target space. Thus, the method would risk depleting its budget before reaching a target space suitable for the problem. On the other hand, we will see that Bounce chooses an evaluation budget that is smaller in low-dimensional target spaces and higher for later target spaces of higher dimensionality. Considering a \(1000\)-dimensional problem with an evaluation budget of \(1000\), it uses only \(3,12\), and \(47\) samples for the first three target spaces of dimensionalities \(2\), \(8\), and \(32\).

Bounce's strategy permits flexible TR shrinkage factors and base lengths, i.e., TR base lengths to vary within the range \([L_{},L_{}]\). This allows Bounce to comply with the evaluation budget \(m_{i}\) for the current target space \(_{i}\). Suppose that Bounce has evaluated \(j\) batches of \(B\) points each since it last increased the dimensionality of the target space, and let \(L_{j}\) denote the current TR base length. Observe that hence \(m_{i}-jB\) evaluations remain for \(_{i}\). Then Bounce sets the TR base length to \(L_{j+1}_{j}^{-B}L_{j}\) with \(_{j}<1\), if it found a new best point whose objective value improves upon the incumbent by at least \(\). We call this a'success'. Otherwise, Bounce observes a 'failure' and sets \(L_{j+1}_{j}^{+B}L_{j}\). The rationale of this rule is that if the algorithm is in iteration \(j\) and only observes failures subsequently, then we apply this factor \((m_{i}-jB)\)-times, which is the remaining number of function evaluations in the current subspace \(_{i}\). Hence, the last batch of the \(i\)-th target space \(_{i}\) will have the minimum TR base length, and Bounce will increase the target dimensionality afterward. If the TR is expanded upon a'success', we need to adjust \(_{j}\) not to use more than the allocated number of function evaluations in a target space. At each iteration, we therefore set adjustment factor \(_{j}=(L_{}/L_{j})^{1/(m_{i}-jB)}\). Note that \(_{j}\) remains unchanged under this rule unless the TR expanded in the previous iteration.

The kernel choice.To harvest the sample efficiency of a low-dimensional target space, we would like to combine categorical variables into a single bin, even if they vary in the number of categories. This is not straightforward. For example, note that the popular one-hot encoding of categorical variables would give rise to multiple binary input dimensions, which would not be compatible with the above strategy of binning variables to form nested subspaces. Bounce overcomes these obstacles and allows variables of the same type to share a representation in the target space. We provide the details in Sect. 3.1.

For the GP model, we use the CoCaBo kernel . In particular, we model the continuous and combinatorial variables with two separate \(}{{2}}-\)Matern kernels where we use automatic relevance determination (ARD) for the continuous variables and share one length scale for all combinatorial variables. Following Ru et al. , we use a mixture of the sum and the product kernel:

\[k(,^{})=_{f}^{2}( k_{}(_{},^{}_{})k_{}(_{},^{ }_{})+(1-)(k_{}(_{},^{ }_{})+k_{}(_{},^{}_{ }))),\]

where \(_{}\) and \(_{}\) are the continuous and combinatorial variables in \(\), respectively, and \(_{f}^{2}\) is the signal variance. The trade-off parameter \(\) is learned jointly with the other hyperparameters _via_ likelihood maximization. See Appendix G.2 for additional details.

Algorithm 1 gives a high-level overview of Bounce. In Appendix A, we prove that Bounce converges to the global optimum under mild assumptions. We now explain the different components of Bounce in detail.

### The subspace embedding of mixed spaces

Bounce supports mixed spaces of four types of input variables: categorical, ordinal, binary, and continuous variables. We discuss binary and categorical variables separately because we model them differently. The proposed embedding maps only variables of a single type to each 'bin', i.e., no target dimension of the embedding has variables of different types. Thus, target dimensions are homogeneous in this regard. Note that the number of target dimensions of each type is implied by the current bin size of the embedding that may grow during the execution. The proposed embedding can handle categorical or ordinal input variables that differ in the number of discrete values they can take.

Continuous variables.As common in BO, we suppose that each continuous variable takes values in a bounded interval. Thus, we may normalize each interval to \([-1,1]\). The embedding of continuous variables, i.e., input dimensions, follows BAXUS: each input dimension \(D_{i}\) is associated with a random sign \(s_{i}\{-1,+1\}\) and one or multiple input dimensions can be mapped to the same target dimension of the low-dimensional embedded subspace. Recall that Bounce works on the low-dimensional subspace and thus decides an assignment \(v_{j}\) for every target dimension \(d_{j}\) of the embedding. Then, all input variables mapped to this particular target dimension are set to this value \(v_{j}\).

Binary variables.Binary dimensions are represented by the values \(-1\) and \(+1\). Each input dimension \(D_{i}\) is associated with a random sign \(s_{i}\{-1,+1\}\), and the subspace embedding may map one or more binary input dimensions to the same binary target dimension. While the embedding for binary and continuous dimensions is similar, Bounce handles binary dimensions differently when optimizing the acquisition function.

Categorical and ordinal variables.Categorical variables that differ in the number of categories may be mapped to the same target dimension (bin). Suppose that the categorical variables \(v_{1},,v_{}\) with cardinalities \(c_{1},,c_{}\) are mapped to a single bin that is associated with the target dimension \(d_{j}\) of the subspace embedding. Then \(d_{j}\) is of categorical type and has \(\{c_{i} 1 i\} c_{}\) distinct categories, that is, its cardinality is given by the maximum cardinality of any variable mapped to it. Thus, the bin \(d_{j}\) can represent every category of these input variables.

Suppose that Bounce assigns the category \(k\{1,,c_{}\}\) to the categorical bin (target dimension) \(d_{j}\). We transform this label to a categorical assignment to each input variable \(v_{1},,v_{}\), setting \(v_{i}= k(c_{i}/c_{})\). Recall that Bounce may split up bins, i.e., target dimensions, to increase the dimensionality of its subspace embedding. In such an event, every derived bin inherits the cardinality of the parent bin. This allows us to retain any observations the algorithm has taken up to this point. Analogously to the random sign for binary variables, we randomly shuffle the categories before the embedding. This reduces the risk of Bounce being biased towards a specific structure of the optimizer (see Appendix E).

We treat ordinal variables as categorical variables whose categories correspond to the discrete values the ordinal variable can take. For the sake of simplicity, we suppose here that an ordinal variable \(v_{i}\) has range \(\{1,2,,c_{i}\}\) and \(c_{i} 2\) for all \(i\{1,,\}\). Figure 1 shows examples of the binning of categorical and ordinal variables.

### Maximization of the acquisition function

We use expected improvement (EI)  for batches of size \(B=1\) and qEI  for larger batches. We optimize the EI using gradient-based methods for continuous problems and local search for combinatorial problems. We interleave gradient-based optimization and local search for functions defined over a mixed space; see Appendix G.1 for details.

## 4 Experimental evaluation

We evaluate Bounce empirically on various benchmarks whose inputs are combinatorial, continuous, or mixed spaces. The evaluation comprises the state-of-the-art algorithms BODi, Casmopolitan, COMBO, SMAC, and RDUCB , using code provided by the authors. We also report Random Search as a baseline. For categorical problems, COMBO's implementation suffers from a bug explained in Appendix H.2. We report the results for COMBO with the correct benchmark implementation as "COMBO (fixed)".

The experimental setup.We initialize every algorithm with five initial points. The plots show the performances of all algorithms averaged over 50 repetitions except BODi, which has 20 repetitions due to resource constraints caused by its high memory demand. The shaded regions give the standard error of the mean. We use common random seeds for all algorithms and for randomizing the

Figure 1: The mapping (or binning) of categorical and ordinal variables. Suppose that variable \(v_{k}\) has two categories and that \(v_{}\) has three categories. Both are mapped to the target dimension \(d_{i}\) that has cardinality \(3=\{2,3\}\). While the mapping of \(v_{}\) to \(d_{i}\) is a straightforward bijection, \(v_{k}\) has fewer categories than \(d_{i}\). Thus, the mapping of \(v_{k}\) to \(d_{i}\) repeats label 1. Ordinal variables are mapped similarly.

benchmark functions. We run all methods for 200 function evaluations unless stated otherwise. The Labs (Section 4.1) and MaxSat125 (Section 4.2) benchmarks are run for 500 evaluations.

The benchmarks.The evaluation uses seven established benchmarks : \(53\)D SVM, \(50\)D LABS, \(125\)D ClusterExpansion, \(60\)D MaxSAT60, \(25\)D PestControl, \(53\)D Ackley53, and \(25\)D Contamination. Due to space constraints, we moved the results for the MaxSAT60, Contamination, and Ackley53 benchmarks to Appendix B.1. For each benchmark, we report results for the originally published formulation and for a modification where we move the optimal point to a random location. The randomization procedure is fixed for each benchmark for all algorithms and repetitions. For binary problems, we flip each input variable independently with probability \(0.5\). For categorical problems, we randomly permute the order of the categories. We motivate this randomization in Section 4.6.

### 50D Low-Autocorrelation Binary Sequences (Labs)

LABS has \(n=50\) binary dimensions. It has important applications in communications engineering and mathematics; see  for details. LABS is a hard combinatorial problem and currently solved _via_ exhaustive search. The goal is to find a sequence \(\{-1,+1\}^{n}\) with a maximum merit factor \(F()=}{2E()}\), where \(E()=_{k=1}^{n-1}C_{k}^{2}()\) and \(C_{k}()=_{i=1}^{n-k}x_{i}x_{i+k}\) for \(k=0,,n-1\) are the autocorrelations of \(\). Figure 2 summarizes the performances. We observe that Bounce outperforms all other algorithms on the benchmark's original and randomized versions.

### Industrial Maximum Satisfiability: 125D ClusterExpansion benchmark

MaxSat is a notoriously hard problem for which various approximations and exact (exponential time) algorithms have been developed; see  for an overview. We evaluate Bounce and the other algorithms on the 125-dimensional ClusterExpansion benchmark, a real-world MaxSAT instance with many applications in materials science . Unlike the MaxSAT60 benchmark (see Appendix B.1.3), ClusterExpansion is not a crafted benchmark, and its optimum has no synthetic structure . We treat the MaxSat problems as black-box problems; hence, algorithms do not have access to the clauses, and we cannot use the usual algorithms.

Figure 3 shows the total negative weight of the satisfied clauses as a function of evaluations. We cannot plot regret curves since the optimum is unknown . We observe that Bounce finds better solutions than all other algorithms. BODi is the only algorithm for which we observe sensitivity to

Figure 3: The 125D weighted ClusterExpansion maximum satisfiability problem. We plot the total negative weight of clauses. Bounce produces the best assignments.

Figure 2: The 50D low-autocorrelation binary sequence problem. Bounce finds the best solutions, followed by COMBO.

the location of the optimal assignment: for the published version of the benchmark, BODi quickly jumps to a moderately good solution but fails to make further progress.

### 25D Categorical Pest Control

PestControl is a more complex version of the Contamination benchmark and has 25 categorical variables with five categories each . The task is to select one out of five actions \(\{1,2,,5\}\) at each of \(25\) stations to minimize the objective function that combines total cost and a measure of the spread of the pest. We note the setting \(=(5,5,,5)\) achieves a good value of \(12.57\), while the best value found in our evaluation is \(12.07\) is \(=(5,5,,5,1)\) and thus has a Hamming distance of one. The random seed used in our experiments is zero. Figure 4 summarizes the performances of the algorithms. Bounce is robust to the location of the global optimum and consistently obtains the best solutions. In particular, the performances of COMBO and BODi depend on whether the optimum has a certain structure. We discuss this issue in detail in Appendix H.1.

### Svm - a 53D AutoML task

In the SVM benchmark, we optimize over a mixed space with 50 binary and 3 continuous parameters to tune an \(\)-support vector regression (SVR) model . The 50 binary parameters determine whether to include or exclude an input feature from the dataset. The 3 continuous parameters correspond to the regularization parameter \(C\), the kernel width \(\), and the \(\) parameter of the \(\)-SVR model . Its root mean squared error on a held-out dataset gives the function value. Figure 5 summarizes the performances of the algorithms. We observe that Bounce, BODi, and Casmopolitan achieve comparable solutions. BODi performs slightly worse if the ordering of the categories is shuffled and slightly better if the optimal assignment to all binary variables is one. COMBO does not support continuous variables and thus was omitted.

### Bounce's efficacy for batch acquisition

We study the sample efficiency of Bounce when it selects a batch of \(B\) points in each iteration to evaluate in parallel. Figure 6 shows the results for \(B=1,3,5,10\), and \(20\), where Bounce was run for \((2000,200 B)\) function evaluations. We configure Bounce to reach the input dimensionality after \(100\) evaluations for \(B=1,3,5\) and after \(25B\) for \(B=10,20\). We observe that Bounce leverages parallel function evaluations effectively: it obtains a comparable function value at a considerably smaller number of iterations, thus saving wall-clock time for applications with time-consuming function evaluations. We also studied batch acquisition for continuous problems

Figure 4: The 25D categorical pest control problem. Bounce obtains the best solutions, followed by Casmopolitan. BODi’s performance degrades significantly when shuffling the order of categories.

Figure 5: The 53-dimensional SVM benchmark. Bounce, BODi, and Casmopolitan achieve comparable solutions.

and found that Bounce also provides significant speed-up. Due to space constraints, we deferred the discussion to Appendix C.

### The sensitivity of BODi and COMBO to the location of the optima

The empirical evaluation reveals that the performances of BODi and COMBO are sensitive to the location of the optima. Both methods degrade on at least one benchmark when the optimum is moved to a randomly chosen point. This is particularly unexpected for categorical variables where moving the optimum to a random location is equivalent to shuffling the labels of the categories of each variable. Such a change of representation should not affect the performance of an algorithm.

BODi is more susceptible to the location of the optimizer than COMBO. The performance of COMBO degrades only on the categorical PestControl benchmark, whereas BODi degrades on five out of seven benchmarks. Looking closer, we observe that BODi's performance degradation is particularly large for synthetic benchmarks like Ackley53 and MaxSAT60, where setting all variables to the same value is optimal. Figure 7 summarizes the effects of moving the optimum on BODi. Due to space constraints, we moved the details and a discussion of categorical variables to the appendix. Similarly, setting all binary variables of the SVM benchmark to one produces a good objective value. It is not surprising, given that the all-one assignment corresponds to including all features previously selected for the benchmark because of their high importance.

We show in Appendix H.1 that BODi adds a point to its dictionary with zero Hamming distance to an all-zero or all-one solution, with a probability that increases with the dictionary size. Deshwal et al. [21, p. 7] reported that BODi's performance 'tends to improve' with the size of the dictionary. Moreover, BODi samples a new dictionary in each iteration, eventually increasing the chance of having such a point in its dictionary. Thus, we hypothesize that BODi benefits from having a near-optimal solution in its dictionary, likely for all-zero or all-one solutions. For COMBO, Figure 4 shows that the performance on PestControl degrades substantially if the labels of the categories are shuffled. Then COMBO's sample-efficiency becomes comparable to Random Search.

## 5 Discussion

BO in combinatorial spaces has many exciting and impactful applications. Its applicability to real-world problems, such as LABS that defy a closed-form solution, makes it a valuable tool for practitioners. Our empirical evaluation reveals that state-of-the-art methods fail to provide good solutions reliably. In particular, it finds that BODi and COMBO, which performed best in recent publications, are sensitive to the location of the optimizer. We identified design flaws in BODi and an implementation bug in COMBO as the root causes of the performance degradations.

The proposed Bounce algorithm is reliable for high-dimensional black-box optimization in combinatorial, continuous, and mixed spaces. The empirical evaluation demonstrates that Bounce reliably outperforms the state-of-the-art on a diverse set of problems. Using a novel TR management strategy, Bounce leverages parallel evaluations of the objective function to improve its performance. We

Figure 6: Bounce benefits from the batch acquisition that allows parallelizing function evaluations. We show the best function values obtained after each batch for batch sizes \(1,3,5,10\), and 20.

anticipate headroom by tailoring the modeling of combinatorial objects, e.g., arising in the search for peptides or materials discovery [28; 34; 37; 59; 75; 78]. Here it seems particularly interesting to incorporate prior belief on the importance of decision variables while maintaining the overall scalability. Moreover, extending the present work to black-box constraints [24; 30], multiple objectives, and multiple information sources [18; 31; 62] will considerably expand the applicable use cases.

Limitations.Bounce is not designed to handle noisy evaluations of the objective function. While it seems straightforward to extend Bounce to handle noisy evaluations, e.g., by using a Gaussian process with a noise term and acquisition functions that account for noise , we leave this for future work. Moreover, in applications where the categorical or ordinal variables vary substantially in the number of values they can take, there may be better ways to 'bin' them.

Societal impact.Bayesian optimization has recently gained wide-spread popularity for tasks in drug discovery , chemical engineering [15; 33; 38; 68; 71], materials discovery [28; 34; 37; 59; 75; 78], aerospace engineering [6; 45; 49], robotics [16; 17; 48; 50; 64], and many more. This highlights the Bayesian optimization community's progress toward providing a reliable 'off-the-shelf optimizer.' However, this promise is not yet fulfilled for the newer domain of mixed-variable Bayesian optimization that allows optimization over hundreds of 'tunable levers', some of which are discrete, while others are continuous. This domain is of particular relevance for the tasks above. Bounce's ability to incorporate more such levers in the optimization significantly impacts the above practical applications, allowing for more granular control of a chemical reaction or a processing path, to give some examples. The empirical evaluation shows that the performance of state-of-the-art methods is highly sensitive to the location of the unknown global optima and often degenerates drastically, thus putting practitioners at risk. The proposed algorithm Bounce, however, achieves robust performance over a broad collection of tasks and thus will become a 'goto' optimizer for practitioners in other fields. Therefore, we open-source the Bounce code.1