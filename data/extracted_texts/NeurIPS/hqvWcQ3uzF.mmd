# FT-AED: Benchmark Dataset for Early Freeway Traffic Anomalous Event Detection

Austin Coursey\({}^{1,2,}\), Junyi Ji\({}^{1,3,}\), Marcos Quinones-Grueiro\({}^{1}\), William Barbour\({}^{1}\), Yuhang Zhang\({}^{1,3}\), Tyler Derr\({}^{2}\), Gautam Biswas\({}^{1,2}\), Daniel B. Work\({}^{1,2,3}\)

\({}^{1}\)Institute for Software Integrated Systems, \({}^{2}\) Department of Computer Science

\({}^{3}\)Department of Civil and Environmental Engineering

Vanderbilt University

\({}^{}\)Corresponding authors: {austin.c.coursey, junyi.ji}@vanderbilt.edu

###### Abstract

Early and accurate detection of anomalous events on the freeway, such as accidents, can improve emergency response and clearance. However, existing delays and mistakes from manual crash reporting records make it a difficult problem to solve. Current large-scale freeway traffic datasets are not designed for anomaly detection and ignore these challenges. In this paper, we introduce the first large-scale lane-level freeway traffic dataset for anomaly detection. Our dataset consists of a month of weekday radar detection sensor data collected in 4 lanes along an 18-mile stretch of Interstate 24 heading toward Nashville, TN, comprising over 3.7 million sensor measurements. We also collect official crash reports from the Tennessee Department of Transportation Traffic Management Center and manually label all other potential anomalies in the dataset. To show the potential for our dataset to be used in future machine learning and traffic research, we benchmark numerous deep learning anomaly detection models on our dataset. We find that unsupervised graph neural network autoencoders are a promising solution for this problem and that ignoring spatial relationships leads to decreased performance. We demonstrate that our methods can reduce reporting delays by over 10 minutes on average while detecting 75% of crashes. Our dataset and all preprocessing code needed to get started are publicly released at https://vu.edu/ft-aed/ to facilitate future research.

## 1 Introduction

One primary concern of a freeway traffic management center revolves around anomalous incident detection and response . On the freeway, these events could be vehicle accidents, vehicle malfunctions, slow-moving vehicles, or severe weather conditions. Early and accurate detection could reduce the risk of secondary accidents and ease traffic congestion . A current operational system for handling incidents on highways involves staff continuously monitoring live camera feeds. They must wait to receive an accident report before initiating management actions, and these actions are only triggered after the incident is either reported by a driver or observed by an officer through the cameras. These systems highly rely on manual efforts, and there is a clear need to automate the incident detection process to improve intelligent transportation systems . Additionally, numerous incidents go unreported but lead to more severe secondary crashes as traffic conditions worsen .

Recently, researchers have explored deep-learning techniques for incident detection. Some of these have been supervised, using common approaches like Convolutional Neural Networks , Support Vector Machines and Probabilistic Neural Networks , Recurrent Neural Networks , and models that combine spatial and temporal information [13; 12]. Accurate crash or incidentinformation may not be available due to reporting delays. Therefore, unsupervised methods for crash detection may be preferred. One way of doing this is by framing the incident detection problem as an anomaly detection problem [30; 5]. As with all deep-learning methods, these approaches rely on the availability of large, realistic freeway traffic datasets.

While large datasets exist for the widely-studied problem of traffic forecasting [18; 7], there is limited data focused on freeway anomalous event detection (see Section 2). Specifically, no current datasets address the fact that, **in the real world, there is a delay in incident reporting**. Imagine that a crash occurs on the freeway. Once it is safe, a witness may notify emergency services. Then, emergency services may dispatch first responders and contact the local traffic management center. Once the traffic management center has assessed the situation and made the appropriate decisions, they may manually log the crash, potentially minutes after it occurred. This challenge necessitates unique metrics and solutions as there is a level of uncertainty and distrust in labeled incident reports.

In this work, we make the following contributions.

1. To the best of our knowledge, we release the **first large-scale lane-level freeway traffic dataset designed for anomaly detection**. This dataset encapsulates traffic states for every workday in October 2023, captured at 30-second intervals using 49 radar detection sensors placed along the Interstate 24 (I-24) corridor, stretching from Murfreesboro to downtown Nashville, Tennessee. Additionally, we sourced true incident labels from the Tennessee Department of Transportation Traffic Management Center and provide anomaly labels based on expert analysis of the traffic speed profiles. This dataset is publicly released along with code at https://vu.edu/ft-aed.
2. We define a **new problem** of lane-level anomaly detection, emphasizing the challenges of delayed crash reporting.
3. We establish the Freeway Traffic Anomalous Event Detection (FT-AED) benchmark according to our collected data and problem definition. We conduct a **thorough benchmarking of various autoencoder-based deep-learning anomaly detection methods** to establish a baseline for the proposed novel task of lane-level freeway anomaly detection.

## 2 Background

### Existing Datasets

Many datasets for traffic anomaly detection focus on detecting anomalies from videos . Recent ones consist of CCTV videos of accidents in India , dash cam accident videos , and college campus security camera videos . While videos are rich in information, they are computationally expensive to store and process. Obtaining high-quality anomaly annotations can be a labor-intensive process. Additionally, videos may raise privacy concerns. For these reasons, deploying vision-based anomaly detection models along major freeways may not always be feasible. Therefore, large-scale freeway traffic datasets typically use sensor measurements.

A number of large sensor-based freeway traffic datasets exist, and these have been used extensively for tasks like traffic forecasting . One of the most popular sources of freeway sensor data is the Performance Measurement System (PeMS) . This data source comprises estimated traffic measurements from thousands of loop detectors across California freeways. Large subsets of this data source have been processed and publicly released, the most recent of which contains billions of data samples . Two popular smaller subsets of PeMS are PEMS-BAY and METR-LA .

Figure 1: Map of the Radar Detection Systems (RDS) sensor network deployed for data collection. 49 RDS sensors are deployed along Interstate 24 toward Nashville, Tennessee. Each sensor captures speed, occupancy, and volume data for each of the four lanes every 30 seconds.

However, none of these datasets contain any anomaly information. To perform anomaly detection, researchers need to go through the process of manually finding and matching external report logs to sensor data [16; 4; 19] or even generate anomalies themselves . Some papers have done this work and released their processed subset of the PeMS data source, such as the ATTAIN LA data . Even after doing so, data is typically aggregated every 5 minutes, which may not be granular enough for real-world applications requiring fast anomaly responses.

To address the limitations of current datasets, we collect and release the Freeway Traffic Anomalous Event Detection (FT-AED) dataset. The FT-AED dataset is designed for anomaly detection, focusing on a month of weekday morning rush hour traffic where anomalies, such as crashes, are more likely. Data is captured at the lane level every 30 seconds, enabling quick anomaly detection. See Table 1 for an overview of our dataset in comparison to other freeway anomaly detection datasets. Note that the DoTA dataset is not the only vision-based traffic anomaly detection dataset, but it is selected as a representative dataset from that category, as the focus of this paper is not on video anomaly detection.

### Problem Formulation

In this paper, we propose a dataset and form an initial benchmark of baseline methods for the problem of **lane-level freeway anomaly detection**. As we have sensors at each lane and millemarker that collect data over time, we formulate this as a node-level graph anomaly detection problem.

Consider a graph \(G=(V,E)\) with a set of nodes, \(V=\{v_{1},,v_{N}\}\), and a set of directed or undirected edges, \(E\), represented using an adjacency matrix. Each node has features corresponding to sensor data at a specific lane and millemarker, \(v_{i}^{d}\). For our dataset, \(N=49\) and \(d=3\). Then, the goal of node-level graph anomaly detection is to create a mapping, \(f:G_{t}\{0,1\}_{t}^{N}\), that determines whether each node is anomalous at time \(t\).

This problem is particularly challenging because the true anomaly labels are not known. Additionally, even with some known anomalies, such as crashes, the exact time the crashes occurred is unknown and likely to be delayed. Therefore, while the primary objective is to correctly detect anomalies, **an additional objective is to detect known anomalies, like crashes, before they are reported**.

To this end, we introduce a new metric to minimize called the **Reduction in Reporting Delay**. Since the exact time and location of an incident officially reported by the traffic management center are unknown, this metric measures how much quicker an anomaly is detected. It is defined as follows:

\[=t_{}-t_{}\] (1)

where \(t_{}\) is the time an anomaly was detected and \(t_{}\) is the time an incident was officially reported. In practice, determining the time an anomaly was detected requires assumptions about the maximum delay in reporting and how long an incident can last. Additionally, since incidents can impact traffic behavior at locations other than where the incident occurs, this metric does not consider the specific node where the anomaly was detected.

## 3 FT-AED Dataset

In this paper, we present the Freeway Traffic Anomalous Event Detection (FT-AED) dataset consisting of high-fidelity traffic measurements derived from Radar Detection Systems (RDS). Our dataset

   Dataset & Sensor & Rate & Nodes & Samples & Lane Level & Anomalies \\  DoTA  & Dashcam Video & 10 fps & N/A & 731K & ✗ & ✓ \\ METR-LA  & Loop Detector & 5 min & 207 & 7.09M & ✗ & ✗ \\ PEMS-BAY  & Loop Detector & 5 min & 325 & 16.94M & ✗ & ✗ \\ ATTAIN LA  & Loop Detector & 5 min & 223 & 822K & ✗ & ✓ \\
**FT-AED (Ours)** & **Radar** & **30 sec.** & **196** & **3.76M** & ✓ & ✓ \\   

Table 1: High-level comparison of datasets that have been used for freeway anomaly detection. “Anomalies” means whether anomaly labels are included with the dataset. With the METR-LA and PEMS-BAY datasets, anomalies can be externally sourced but are not included by default. Our dataset contains lane-level features captured every 30 seconds from radar sensors. This increased granularity allows for quicker incident detection and response than most PeMS-sourced datasets.

is one of the first large-scale freeway traffic anomaly detection datasets and offers the potential for real-time incident response and active traffic management. Our dataset consists of traffic data recorded by 49 sensors placed along the Interstate 24 (I-24) corridor, stretching from Murfreesboro to downtown Nashville. This dataset encapsulates traffic states for every workday in October, captured at 30-second intervals. Additionally, we utilize a complementary dataset of event reports, sourced from the Tennessee Department of Transportation Traffic Management Center. These reports are compiled by officers dedicated to monitoring road conditions and identifying unusual occurrences. This dataset not only serves as a benchmark but also paves the way for future research in traffic management and incident response.

### Data Collection

To create our anomaly detection dataset, we gathered sensor data from a real-world freeway and incident reports from the traffic management center managing that same freeway.

#### 3.1.1 Radar Detection Systems

To detect anomalous incidents on the freeway, we need to represent normal and abnormal traffic behavior using data. In this project, we deployed Radar Detection Systems (RDS), which have been shown to measure traffic speed accurately , approximately 0.3 miles apart along an 18-mile stretch of Interstate 24 heading toward Nashville, Tennessee. An image showing the locations of these sensors can be seen in Figure 1. These 49 sensors collected traffic speed, occupancy, and volume data for the four interstate lanes every 30 seconds. We limited the data collected to the peak morning traffic hours of 4:00 am to 12:00 pm during workdays in October 2023. This time window was chosen to limit the focus of anomaly detection to when crashes are most likely to occur. With 8 hours of data from each day every 30 seconds, we have over 3.7 million data points across the 196 nodes.

At each lane and milemaker, we collected sensor data and metadata useful for analysis. The features collected from the RDS sensors are shown below.

* **time_unix**: the time the measurement was taken.
* **milemarker**: location of sensor on the interstate. This comes from the Tennessee Department of Transportation's coordination system and is consistent with what is labeled on the road
* **lane**: the lane number. There are four lanes, where lane 1 is the left-most lane.
* **speed**: 30-second average speed of the vehicles passing through the area.
* **volume**: 30-second average number of vehicles passing through the area.
* **occupancy**: 30-second average percentage of time that the detection zone of the radar sensor is occupied by a vehicle.

#### 3.1.2 Incident Labels

With millions of data points across sensor features, it is difficult to define and label all possible anomalies. However, some anomalous incidents of high importance, such as crashes, are tracked by the Tennessee Department of Transportation Traffic Management Center. We sourced the incident logs corresponding to October 2023. These logs contained raw, largely unstructured text detailing each reported crash for the month. We manually parsed these logs, recording the time of each crash. This process uncovered 42 crashes.

Despite their utility, labels from these incident logs have limitations: (1) owing to their reliance on manual reporting, there is an inherent delay in the documentation of events, with the extent of this delay being uncertain, (2) the data structure is somewhat unorganized, being primarily chronological in its event handling; as a result, the recorded end times of incidents may not accurately reflect the actual resolution of the events, complicating their usage, (3) the dataset is susceptible to errors due to the human element in data entry. Despite these drawbacks, the strength of the dataset lies in its ability to offer extensive information and insights upon retrospective analysis of detected anomalies, thereby contributing significantly to the understanding of these events.

Along with labels from event logs, we annotated additional possible anomaly labels using expert knowledge. These labels do not necessarily correspond with crashes and do not suffer from the delayed reporting that the event logs do. We employed space-time diagrams, a frequently used tool for visualizing traffic speed patterns. Through these diagrams, we were able to identify and label two types of inspected anomalous events not reported in the event records. See Section A.4 in the Appendix for more information. This process led to 19 more labeled anomalies. In our analysis we focus on crash detection, using only the crashes that were officially reported for validation. We use these additional labels to ensure our training data is free of anomalies, a common step in autoencoder-based anomaly detection. By integrating both official reporting logs and diagram analysis, we ensured a comprehensive and accurate labeling of traffic anomalies in the RDS data. An ablation showing the impact of missed anomaly labels is provided in the Appendix (Section A.9).

### Data Processing

Over the month of data collection, some sensor data was missing. To ensure our data was compatible with anomaly detection methods that cannot handle missing data, we imputed missing values. To impute speed values we used a domain-specific imputation method that tries to enforce the wave-like patterns in traffic speeds. See Section A.2 in the Appendix for more information. The cleaned speed values for the whole month are shown in the time-space diagrams in Figure 2. For the volume and occupancy features, we used a simple local averaging.

As the goal of the dataset is to perform node-level anomaly detection, graph-based methods can naturally be applied. We propose a baseline graph structure to facilitate easy dataset use for future research. We represent each lane at each milemarker as a node. We connect nodes to adjacent nodes at the same milemarker with the intuition that cars can change lanes at the same milemarker. We connect nodes to all lanes at milemarkers ahead and behind since cars could have changes to any of the four lanes in the 0.3 mile gap between sensors. We formulate this as an undirected unweighted

Figure 2: _Freeway traffic dynamics_: October, 2023 weekday lane 1 (high-occupancy vehicle (HOV) lane, often refers to the leftmost lane) speed data visualization for the Westbound (the direction to downtown Nashville) of I-24 section from road reference marker mile 71 to 53, morning peak hours from 4AM and 12PM, sensors are deployed with about a 0.3 to 0.4 mile interval on freeway.

graph, making no assumptions about which direction the impact of anomalies flows. A visualization of this graph during a high traffic time can be seen in Figure 8 in the Appendix.

### Dataset Usage

The full month of cleaned data is publicly released at the dataset link on our project page https://vu.edu/ft-aed. In this repository and the supplementary materials of this paper, there is a dataset card describing additional information for usage. Additionally, we provide a Demo.ipynb notebook showing how to import the data and put it into a graph structure for machine learning tasks.

## 4 Experiments

To showcase the potential for our dataset to be used to design and evaluate algorithms for freeway traffic anomaly detection, we conducted initial experiments on our dataset, shown in this section. Numerous additional experiments and more details are also presented in the Appendix.

### Additional Preprocessing

Although the general preprocessing steps were described in Section 3, we performed additional preprocessing for our experiments.

**Removing Anomalies.** A common and powerful approach to anomaly detection classifies anomalies based on the reconstruction error of an autoencoder. An autoencoder is trained to reconstruct nominal input. At test time, a point is classified as an anomaly if it is reconstructed poorly since the autoencoder learned to reconstruct nominal points well. We applied this principle to detect incidents and reduce the crash reporting delay. To ensure the training dataset was free of anomalies, we made the following conservative assumptions.

* If a crash has been reported, there could be up to a 30-minute delay in reporting. The impacts of the crash could be present in the data for up to two hours after the crash is reported.
* If an anomaly has been manually labeled, there is no delay. The impacts of the anomaly could be present in the data for up to two hours after the anomaly has been labeled.

**Temporal and Relational Spatiotemporal Graph Design.** Although the primary graph design presented in Section 3.2 describes the network for a single time snapshot, the temporal evolution of the network may also be important. To that end, we designed two additional modifications to the proposed graph structure. First, we designed a **graph time series**. To do this, along with the current graph, we collected the \(k\) previous graphs into a time window \(=\{G_{t},G_{t-1},,G_{t-k}\}\). These time windows allow a spatiotemporal model to learn spatial and temporal relationships in the data. Second, we designed a **relational spatiotemporal graph**. First, we connected all \(k\) graphs into a single graph, allowing time to be considered by spatial methods. Additionally, each edge was given a relational class describing how the two connected nodes are related. This allows a graph algorithm to learn

Figure 3: Relational spatiotemporal graph design, illustrated over an example freeway. The full graph is made by forming these connections for all nodes across the time horizon.

different weights for each relation type, passing information differently on the edge category. This relational spatiotemporal graph is illustrated from the perspective of a single node in Figure 3.

### Model Training

With the data processed, we trained anomaly detection models on the data. The models we trained are described below.

* Relational Graph Convolutional Network Autoencoder. This model uses the relational spatiotemporal graph of the freeway network as input and Relational Graph Convolution  blocks.
* Graph Attention Network Autoencoder. This model uses the spatiotemporal graph without edge relations as input and Graph Attention  blocks for spatiotemporal learning.
* Graph Convolutional Network Autoencoder with temporal aggregation in the latent space using a Long Short-Term Memory Network. It accepts a time series of spatial graphs as input. It uses Graph Convolution  blocks for spatial processing and LSTMs for temporal processing.
* Graph Convolutional Network Autoencoder. This is a special case of the STG-RGCN AE without edge relations and using only the current graph as input.
* Transformer Autoencoder. It processes the time series of node features, treating each node as independent. It uses temporal but not spatial features.
* Multi-layer Perceptron Autoencoder. This is a standard autoencoder that treats each node as independent and does not consider temporal or spatial features. It reconstructs each node using its own features.

To train the models, we minimized the reconstruction error of the node features of the current graph. The loss function is shown below, where \(X_{t}\) are all the node features captured from the freeway at time \(t\) and \(_{t}\) are the reconstructions of those features given by the model.

\[_{}=}_{X}||X_{t}-_{t}||_{2}^{2},\] (2)

We also optimized the hyperparameters of each of the trained models. Using the optimized hyperparameters, we trained each model on 14 days of morning data. We kept 5 days for validation and left 1 day out due to excessive, uncertain anomalies. With a trained model, anomalies were detected for each node in the network using the following:

\[(X_{t},_{t})=(X_{t}-_{t})^{2}>T,\] (3)

where \(T\) is a vector of thresholds, one for each node. We set this as the maximum squared reconstruction error on the training set for each node. Therefore, no samples in the training data were classified as anomalies. However, we tuned this threshold to control the false positive rate in our experiments. Additional details regarding hyperparameter optimization, figures showing model architectures, and formal definitions of the graph operations are shown in the Appendix Section A.6.

### Anomaly Detection Results

To evaluate the anomaly detection performance, we computed the following metrics after applying the trained models to the 5 days of validation data.

* **Reduction in Reporting Delay**: see Equation 1. We consider this the most important metric. A lower reduction in reporting delay implies that the model is detecting anomalies sooner than they are noticed and recorded by the traffic management center. We calculate this within a 15-minute window before and after a crash occurs. Lower is better.
* **Miss Percentage**: the percentage of crashes that were not detected as anomalies within 15 minutes of being officially reported. Lower is better.
* **Reconstruction Error**: see Equation 2. The mean squared reconstruction error on the data free of anomalies. A model that has better learned to reconstruct the node features may have better learned general nominal traffic behavior and may more accurately detect anomalies, especially in cases with heavy traffic congestion. Lower is better.

* **False Positive Rate (FPR)**: the percentage of detected anomalies that were not anomalies. To determine whether a predicted anomalous time was a True Positive or True Negative, we assume that there was no longer than a 15-minute delay in reporting and that the impacts of a crash can last up to 2 hours, similar to [19; 4]. These assumptions are purposefully conservative and impact the usefulness of typical binary classification metrics. See Section 5 for further discussion. Lower is better.
* **Area Under the Curve (AUC)**: the area under the receiver operating characteristic curve, demonstrating the tradeoff between True Positive and False Positive Rate at all anomaly thresholds. Higher is better.

The overall relative performance of each method can be seen in Table 2. The **GCN Autoencoder with no temporal information (GCN) achieved the lowest average detection delay of the crashes detected** with the lowest variance. It detected crashes well before they were officially reported, over 10 minutes on average. It also achieved a higher AUC than the other methods. This implies that the temporal relationships between nodes was less important than the spatial relationships. Considering the task of an Autoencoder, this makes sense. Most of the information needed to reconstruct the current graph was present in the current graph. More evidence for this point is shown by the poor performance of the Transformer Autoencoder. A simpler MLP vanilla Autoencoder detected crashes faster on average than the more complex Transformer model. (Though neither of their reconstructions were reasonable due to having to project from a 3-dimensional latent space to a 2-dimensional latent space.) Additionally, the GCN model missed a larger percentage of the crashes than two of the other methods, implying that temporal information may be necessary to detect some crashes.

Next, we can consider the Reconstruction MSE on the nominal data from the 5-day validation set. The GAT Autoencoder with the spatiotemporal graph (STG-GAT) achieved the lowest reconstruction error. Since this was the training task, this model appears to have learned and generalized best, but the practical differences among the MSEs are not clear from this metric alone. The RGCN Autoencoder with the spatiotemporal graph (STG-RGCN) had the second-lowest detection delay but had a higher variance in its detection delay. Finally, the GCN Autoencoder with an LSTM for temporal aggregation (GCN-LSTM) had the highest detection delay with the highest variance, highest Reconstruction Error, and lowest AUC. In this case, it was the worst model in all metrics. **Moving the temporal aspect of the framework into the data instead of the model improved the performance.** At the same time, it improved the parallelization of the computations by removing the recurrent layers.

### Case Study

Next, we can analyze a case study of a specific crash, chosen from the validation set. On October 11, 2023, the incident logs from the traffic management system reported, _"Crash in RUTHERFORD county going Westbound on Interstate 24 beyond MILE MARKER 63.4 Last updated 10/11/2023 6:24:31 AM"_ and _"Crash in RUTHERFORD county going Westbound on Interstate 24 beyond MILE MARKER 63.4 with **Left lane blocked"_** was reported just over a minute later.

We ran our STG-GAT AE model with an anomaly threshold that fixed the validation FPR at \(10\%\) on October 11, 2023 morning data. In Figure 3(a), the vehicle speeds over time and space in the left lane are shown. Our model detected a large number of anomalies beyond milemarker 63.5 starting at 6:07:30 AM and ending at 6:42:00 AM. **We consistently detected the crash at the correct location 17 minutes before it was officially reported.** Additionally, qualitatively, there were a small number of false positives in the plot. In fact, two of the minutes of data were incorrectly determined to be false

   Autoencoder Model & Reporting Delay & Miss Percentage & Recons. MSE & AUC \\  STG-RGCN & \(-8.95 7.59\) & \(\) & \(0.0102\) & \(0.67\) \\ STG-GAT & \(-7.75 6.58\) & \(\) & \(\) & \(0.68\) \\ GCN-LSTM & \(-6.83 8.18\) & \(25\%\) & \(0.0119\) & \(0.65\) \\ GCN & \(-\) & \(25\%\) & \(0.0095\) & \(\) \\ Transformer & \(+2.42 8.35\) & \(41.67\%\) & \(0.0312\) & \(0.60\) \\ MLP & \(-6.86 6.87\) & \(41.67\%\) & \(0.0122\) & \(0.62\) \\   

Table 2: Overall relative performance of each proposed method. Note that Reporting Delay (mean \(\) standard deviation) was computed using an anomaly threshold that fixed the FPR at \(5\%\). Reconstruction Error on anomaly-free validation data.

positives when they were directly connected to the crash because they were more than 15 minutes before it was reported. The reconstruction errors are shown in Figure 3(b). From this Figure, we can see that the points around the crash were reconstructed worse than the nominal points. This is further evidence of the appropriateness of reconstruction-based approaches for this problem.

## 5 Future Directions and Limitations

From our dataset design and baseline benchmark, we have opened the door to future research. In this section, we briefly detail future research directions to build on the dataset challenges and limitations.

**Anomalies are detected at the lane level, but validation is not done at the lane level.** As shown in Figure 4, our proposed methods detected anomalies accurately at the lane level. However, since most of the labeled anomalies our dataset had were crashes, the impacts of these may cause anomalous traffic behavior in locations other than the crash site (e.g., everywhere behind the crash is now stuck in traffic). Future methods can research how to validate the location of detected anomalies.

**There is a need for an overall performance metric besides AUC.** Since anomalies were recorded as instantaneous points in time and the definition of a true positive or true negative are unknown for complex anomalies like crashes, AUC can be a misleading metric. Future research can evaluate different metrics to determine which metric corresponds best with practical performance.

**The speed reconstructions lose some of the dynamics of the traffic system.** Comparing the reconstructions in Figure 4 to Figure 2, the reconstructions are reasonable. However, upon further inspection, they appear to lose some of the "wave" patterns present in the real data. This may cause subtle anomalies, especially when crashes occur, to go undetected. Therefore, future methods can explore how to reconstruct the speed more accurately without losing the autoencoder bottleneck. We suspect enforcing the wave-like behavior as a regularization term in the loss function would help.

**More anomaly detection approaches should be benchmarked.** In our baseline experiments, we only used reconstruction-based autoencoder anomaly detection approaches. This was due to the uncertainty in the data labels; supervised approaches may fail. However, other rule-based and unsupervised anomaly detection methods exist. See Appendix A.8 for an initial exploration into the performance of clustering and rule-based methods. Future research should use our dataset as a benchmark for more anomaly detection algorithms.

## 6 Conclusion

In this paper, we presented the Freeway Traffic Anomalous Event Detection (FT-AED) dataset, the first large-scale real-world dataset focused on lane-level freeway anomaly detection. The FT-AED dataset comprises over 3.7 million sensor measurements, capturing the vehicle speed, occupancy, and volume in 4 lanes along 49 mimemarkers over the weekday mornings of October 2023. We sourced crash records from the Tennessee Department of Transportation Traffic Management Center as ground truth anomaly labels. Due to human delays and errors, there is uncertainty in the reported crash time, leading to a unique challenge in training and validating anomaly detection models. We also manually labeled additional potential anomalies based on expert inspection of the vehicle speed

Figure 4: Case study. Crash detection and reporting for the morning of October 11, 2023, using STG-GAT AE. The threshold was chosen such that there was a \(10\%\) validation FPR.

profiles. To assess the ability of our dataset to be used as a benchmark, we trained and validated 6 autoencoder-based anomaly detection methods. In this, we found that GNN Autoencoders detected anomalies better than purely temporal or feature-based models and that introducing a spatiotemporal graph could help reduce the number of missed crashes. We detected crashes minutes before they were officially reported, highlighting a specific case where our methods detected a crash at the correct location 17 minutes before it was reported. We hope that developing and releasing this dataset will lead to further advancements in anomaly detection methods and automate incident response so delays like this can be avoided.