# Trading Place for Space: Increasing Location Resolution Reduces Contextual Capacity in Hippocampal Codes

Trading Place for Space: Increasing Location Resolution Reduces Contextual Capacity in Hippocampal Codes

 Spencer Rooke\({}^{1}\)   Zhaoze Wang\({}^{2}\)   Ronald W. Di Tullio\({}^{3*}\)   Vijay Balasubramanian\({}^{1,4,5*}\)

\({}^{1}\)Departments of Physics   \({}^{2}\) of Computer and Information Science and \({}^{3}\) Neuroscience

University of Pennsylvania; \({}^{4}\)Rudolf Peierls Centre for Theoretical Physics, University of Oxford;

and \({}^{5}\)Santa Fe Institute   \(*\): Equal contribution

srooke@sas.upenn.edu   zhaoze@seas.upenn.edu

ron.w.ditullio@gmail.com   vijay@physics.upenn.edu

###### Abstract

Many animals learn cognitive maps of their environment - a simultaneous representation of context, experience, and position. Place cells in the hippocampus, named for their explicit encoding of position, are believed to be a neural substrate of these maps, with place cell "remapping" explaining how this system can represent different contexts. Briefly, place cells alter their firing properties, or "remap", in response to changes in experiential or sensory cues. Substantial sensory changes, produced, e.g., by moving between environments, cause large subpopulations of place cells to change their tuning entirely. While many studies have looked at the physiological basis of remapping, we lack explicit calculations of how the contextual capacity of the place cell system changes as a function of place field firing properties. Here, we propose a geometric approach to understanding population level activity of place cells. Using known firing field statistics, we investigate how changes to place cell firing properties affect the distances between representations of different environments within firing rate space. Using this approach, we find that the number of contexts storable by the hippocampus grows exponentially with the number of place cells, and calculate this exponent for environments of different sizes. We identify a fundamental trade-off between high resolution encoding of position and the number of storable contexts. This trade-off is tuned by place cell width, which might explain the change in firing field scale along the dorsal-ventral axis of the hippocampus. We demonstrate that clustering of place cells near likely points of confusion, such as boundaries, increases the contextual capacity of the place system within our framework and conclude by discussing how our geometric approach could be extended to include other cell types and abstract spaces.

## 1 Introduction

Decades of experiments suggest that the mammalian hippocampus is crucial for the formation of episodic memories and spatial navigation [1; 2; 3]. Neural recordings of rodents during active navigation led to the discovery of place cells by John O'keefe , named for their spatially localized firing patterns. These place cells were quickly theorized to be the substrate of the cognitive map - an animal's simultaneous and abstract representation of context, experience, and position [3; 5]. Further experiments led to the discovery of remapping [6; 7; 8], during which place cells alter their firing properties in response to changes in sensory and contextual cues. Large contextual changes lead to global remapping, in which population level maps of activity appearing in different contexts are nearly orthogonal, independent of correlations within an environment [9; 10]. Many have speculated that the place cell system encodes context via global remapping and that this encoding scheme should be able to store a large number of contexts [11; 12], but precise calculations backing these speculations are lacking. Here, we analyze the geometry of hippocampal codes to approximate the capacity and properties of context encoding by place cells.

We treat place cell population activity as a high dimensional space into which we can embed contexts (**Fig. 1,B**). Since a large fraction of hippocampal neurons are place cells [13; 14], we expect this activity space to have thousands of dimensions, depending on the species. While the defining features that distinguish context are not fully known [6; 7; 8], we define it as a choice of surrounding environment, as is often done in practice in experiments [9; 11; 15; 16; 17; 18; 19]. Embedding an environment in the firing rate space produces a neural manifold, with position on the manifold corresponding to particular patterns of neural population activity that reflect location in real space. Without noise, the dimensionality of this manifold matches the dimensions of the encoded environment. For example, different linear tracks would be encoded as different 1D curves embedded in the population activity space (**Fig. 1B**). In this geometric framework, the distance between two manifolds indicates how differently the neural populations encode each environment  (**Fig. 1B**); and if two manifolds do not overlap at any point, the underlying context can always be determined without confusion. In the noiseless case, we expect that it is trivial to discriminate context because pairs of very low dimensional manifolds are unlikely to overlap in such a high dimensional space. Real neurons, however, will have noisy responses which "blur" our manifolds, giving them a characteristic width around the noiseless, low dimensional embedding of an environment. As such, our criterion for separability of contexts requires that these thickened manifolds for each context do not overlap extensively in rate space (**Fig. 1D**). We consider two models of neuronal noise for our rate based neurons: one in which noise is additive and constant, and a second in which noise is additive, but with variance scaling with neural activity. The latter mirrors an underlying Poisson-like process of spike generation that is often assumed for hippocampal neurons. We investigate the effect of these different noise models on pairwise overlap, and from this extrapolate the probability that multiple contexts are discriminable.

When the number of neurons \(N\) is large, these manifolds grow far apart, and are more easily distinguished. In weak to moderate noise regimes, we find that the number of contexts that can be stored by a place-like coding scheme grows exponentially in \(N\), even when we enforce strict requirements that the system can discriminate between contexts at _any_ position within an environment. We further find that place cell width tunes both the ability to decode local position and the typical distance between contextual manifolds. Large place cell widths generate greater overlap between firing fields, which in turn increases discriminability between contexts. Conversely, small place cell widths increase the spatial resolution of encodings, but decrease the separability of contextual manifolds. This leads to a fundamental trade-off between decoding context and local position. We propose that this trade-off accounts for the observed change in firing field width across the dorsal-ventral axis in the rodent hippocampus, and predict that selective inhibition along the hippocampus will lead to

Figure 1: Place cell firing fields remap in one **(A)** and two **(C)** dimensions. **(B)** The maps \(f_{A}\), \(f_{B}\) of one dimensional contexts correspond to curves in neural population activity space, parametrized by position. With constant Gaussian noise, we require that these curves be a distance \(2(+q)\) apart in order to discriminate contexts. **(D)** The maps \(f_{A}\), \(f_{B}\) of two dimensional contexts correspond to surfaces in activity space, parametrized by position in physical space. With activity dependent, Poisson-like noise, firing patterns exponentially localize to characteristic ellipsoids. We require that these thickened surfaces do not intersect in order to discriminate contexts.

different types of memory impairment for spatial tasks, consistent with existing experimental evidence [21; 22; 23; 24; 25; 26]. Finally, we find that when fields are uniformly distributed, confusion between contexts is most likely to occur near boundaries. This effect can be compensated for by biasing the density of place field centers towards the boundary, recreating a known feature of rodent place coding [27; 28]. We predict that the observed place cell clustering near boundaries allows the place system to segregate different contexts with greater efficiency, and the extent of this clustering is additionally a function of cell location along the ventral-dorsal axis.

### Model Description

We consider a population of \(N\) place cells, indexed by \(j\), with activity described by a population activity vector \(\). We treat this vector as a random variable that depends both on context (\(A\)), and position within a context (\(x_{A}\)). We consider physical environments in one or two dimensions, as this is common experimentally, so that \(x_{A}\) is either a one or two dimensional vector describing location. Each context \(A\) is equipped with a place map \(f_{A}\), which defines the tuning of each neuron when the animal is within \(A\). That is, \(f_{A}\) sets the mean firing rate of each neuron, \( r_{j}(x_{A},A)=f_{A,j}(x_{A})\). Each map \(f_{A}\) can be viewed as an encoding for a particular context that embeds \(x_{A}\) into a certain set of population activity vectors \(\) (**Fig. 1A,B**). We restrict our analysis to rate coding models of population activity, where \(\) represents population firing rates (rather than spike counts) and has additive noise.

We assume that place maps are constructed stochastically for each environment, consistently with known properties of place cells. Within an environment, each place cell has \(a_{j}\) distinct firing fields, where \(a_{j}\) is drawn from a gamma-poisson distribution, following recent experimental observations in rodents [29; 30], (**Supplemental**). For small environments (1-2 m), typical place cells have 0-2 firing fields under these statistics, with greater recruitment as environment size increases. We give each firing field a gaussian shape, and vary the widths parametrically. The tuning curve of each neuron is then a sum of gaussians:

\[f_{A,j}(x_{A})=.1Hz+C_{j,A}_{i}^{a_{j}}/2)^{2}}( _{A}-_{A,i})^{2}}\] (1)

For simplicity, the normalization \(C_{j,A}\) is chosen so that all neurons have a baseline firing rate of \(.1Hz\), and a maximum firing rate of \(30Hz\) in environments in which they are active.

With additive noise, neural activity is given by \(r_{j}(x_{A},A)=f_{A,j}(x_{A})+_{j}\). We consider two noise model. In the first, \(\) is gaussian distributed, and noise is not correlated between place cells, so that \((0,^{2})\). Note that \(^{2}\) is the variance in noise magnitude and thus has units of \(Hz^{2}\). In the second model, we scale the noise variance of each place cell with activity to match underlying Poisson-like statistics associated with spike generation. In this case, \(_{j}(0, f_{A,j}(x_{A}))\). Here, \(\) is a dispersion coefficient that sets how noisy the place system is, and has units of \(Hz\). We can write our two models of place cell activity as \((x_{A},A)(f_{A}(x_{A}),^{2})\) and \((x_{A},A)(f_{A}(x_{A}),[f_{A}(x_{A})])\), respectively. Additive noise can generate negative firing rates, and so we rectify all negative firing rates to 0 Hz.

## 2 Results

### Place Coding Can Store Exponentially Many Contexts

With the above model in hand, we sought to explore the context coding capacity of the place cell network. To do so, we first defined what it means to discriminate two contexts \(A\) and \(B\). In our formulation, \(f_{A}(x_{A})\) and \(f_{B}(x_{B})\) define two manifolds in the space of neural activity (**Fig. 1**). Without noise, if these two manifolds do not intersect, then the firing patterns that arise in each environment are unique to that environment. In this case, both position and context can be uniquely determined from population activity, and so the contexts \(A\) and \(B\) are discriminable so long as \(f_{A}\) and \(f_{B}\) do not intersect. For the moment, we disregard considerations of computational complexity required for manifold discrimination, such as requiring linear separability as in [31; 32].

When there is no noise, there is a very low probability that the surfaces defined by \(f_{A}\) and \(f_{B}\) intersect at any point in our high-dimensional firing rate space, and the intersection criterion is trivial to fulfil.

The introduction of noise gives the manifolds defined by \(f_{A}\) and \(f_{B}\) a characteristic width, whose scale and geometry depends on the nature of the noise. In the model where noise variance \(^{2}\) is constant, the characteristic manifold width scales like \(\) when \(N\) is sufficiently large. This is due to a well known characteristic of gaussians in high dimensions, in which normal distributions have the majority of their mass sitting near a thin annulus of radius \(\) (**Supplemental**). That is, the probability density for the radius of vectors pulled from high dimensional spherical gaussians peaks at \(\), and falls off exponentially away from this shell as \(p_{R}(+q) p_{R}()e^{-q^{2}}\). For example, when \(q=2\) this leads an approximate four e-fold decrease in the probability density, so that the majority of the probability mass (\(>99\%\) for large \(N\)) is within a radius of \(+q\). Importantly, this exponential fall off is independent of \(N\), and so the width of the annulus is of order 1 in \(N\). In the rate dependent noise model, we instead get a probability mass that is exponentially localized to an ellipsoid with major axes whose lengths depend on firing rates, \(^{i}(x_{A})}\).

We would then like a way to determine the effect of both noise models on manifold overlap, and by extension, decrease in context discriminability. We solve this problem geometrically. For the rate independent (gaussian) noise model, the manifold \(f_{A}(x_{A})\) acquires a width of \((+q)\) in every direction. Here, \(q\) accounts for the non-zero width of the noise annulus. In any case, our condition that two contexts \(A\) and \(B\) be distinguishable then becomes a requirement that the minimum distance between \(f_{A}(x_{A})\) and \(f_{B}(x_{B})\) in rate space overcomes this width set by noise (**Fig. 1C**):

\[_{x_{A},x_{B}}d(f_{A}(x_{A}),f_{B}(x_{B}))>2(+q)\] (2)

The manifold width acquired from the rate dependent (Poisson-like) noise model will vary in each direction of the firing rate space with the neural firing rate. Intuitively, we can think of this widening of the manifold as placing an ellipsoid at each point along our manifold, with principle axes set by the firing rates of each neuron (**Fig. 1D**). We then check if our thickened manifolds overlap. Unlike the case with constant noise, where it sufficed to check that the distance between points between different manifolds is greater than the minimum distance set by noise, we must check that the ellipsoids centered at \(f_{A}(x_{A})\) and \(f_{B}(x_{B})\) do not overlap for any pair \(x_{A},x_{B}\) on the two manifolds. For ellipsoids with centers \(_{A}=f_{A}(x_{A})\) and \(_{B}=f_{B}(x_{B})\) and covariances \(_{A}\) and \(_{B}\), we can define the set:

\[_{s}=\{s(-_{A})^{T}_{A}(-_{A })+(1-s)(-_{B})^{T}_{B}(-_{B}) 1\}\] (3)

Here, \(s\). For \(s=0\) or \(s=1\), this set describes the interior of the ellipsoid centered at \(_{A}\) or \(_{B}\), respectively, and varying \(s\) interpolates between the two. For other values of \(s\), \(_{s}\) is either empty, a single point, or the interior of an ellipse. We also note that, for any \(s\), the intersection of the two ellipsoids is always contained in \(_{s}\), and so if there is an \(s\) for which this set disappears, then the two ellipsoids do not intersect . We can rewrite \(_{s}\) as

\[_{s}=\{(-_{s})^{T}_{s}(-_{s} ) K(s)\}\] (4)

where \(_{s}=s_{A}+(1-s)_{B}\) and \(_{s}=_{s}^{-1}(s_{A}_{a}+(1-s)_{B}_{b})\). Thus, the two ellipsoids centered at \(_{A}\) and \(_{B}\) do not intersect if and only if \(K(s)\) is negative for some \(s\); i.e., \(_{s}\) is empty for some \(s\). As the centers of each ellipsoid are a function of position within their respective contexts, we find that (**Supplemental**):

\[K(s,x_{A},x_{B})=1-+q)^{2}}_{i}^{N}^{i} (x_{B})-f_{A}^{i}(x_{A}))^{2}}{(f_{A}^{i}(x_{A})+f_{B}^ {i}(x_{B}))}\] (5)

If for every pair \(x_{A},x_{B}\), there is an \(s\) for which this is negative, then our two thickened manifolds do not intersect. As such, we let \(s^{*}(x_{A},x_{B})\) minimize \(K(s,x_{A},x_{B})\) for each choice of \(x_{A},x_{B}\). To put this condition in a similar form as equation (2), we define \(^{*}\):

\[^{*}(x_{A},x_{B})=_{i}^{N}^{i}(x_{B})-f_{A}^{i} (x_{A}))^{2}}{((x_{A},x_{B})}f_{A}^{i}(x_{A})+( x_{A},x_{B})}f_{B}^{i}(x_{B}))}\] (6)

Our condition on \(K(s,x_{A},x_{B})\) can then be written in a similar form to the simpler noise model:

\[_{x_{A},x_{B}}N^{*}(x_{A},x_{B})>(+q)^{2}\] (7)Here, \(q\) again accounts for the nonzero width of the noise annulus. For both models, the width of the annulus \(q\) is \((1)\) in \(N\), and so makes no contribution to our final results at large \(N\). Indeed, we performed the numerical calculations for multiple values of \(q\), and find that at large \(N\) our results are unchanged. In generating our figures, we use \(q=2\). Note that we are enforcing a very strict definition of separability for both noise models. When separation between the two manifolds is greater than the threshold distance, the probability of confusing the two contexts is vanishingly small. Less strict conditions would still allow for good (in a practical sense) performance in context discrimination, but our stricter definition engenders several advantages. First, the geometric approach we are using to assess capacity allows us to easily generalize to more than two contexts. Second, it is important to be as conservative as possible in capacity calculations and such strictness should prevent overestimation of the number of decodable contexts. Finally, our approach avoids ceiling effects for changing parameters of the model; that is, by making the task as hard as possible we can observe impacts of changing different parameters on performance that would be hidden by performance plateaus on easier tasks.

Having these pairwise separability conditions for two contexts, we then wanted to determine how many contexts \(M\) are storable by the place cell system. To do so, we first replace our statements for particular environments \(A\) and \(B\) with probabilistic statements for any pair of rooms \(A\) and \(B\) generated at random. The probability that two rooms are distinguishable is then the probability that the following pairwise separation conditions are true:

\[P(2)=P(_{x_{A},x_{B}}d(f_{A}(x_{A}),f_{B}(x_{B}))>2(+q))\] (8)

\[P(2)=P(_{x_{A},x_{B}}N ^{*}(x_{A},x_{B})>(+q)^{2})\] (9)

For notational convenience, we define \(_{min}_{x_{A},x_{B}}d(f_{A}(x_{A}),f_{B}(x_{B}))\) and \(^{*}_{min}_{x_{A},x_{B}}^{*}(x_{A},x_{B})\). The probability that two rooms are distinguishable can then be written in terms of distributions over these variables as:

\[P_{2}=1-_{0}^{2(+q)}P( _{min})d_{min}\] (10) \[P_{2}=1-_{0}^{(+q)^{2}}P(N ^{*}_{min})Nd^{*}_{min}\] (11)

That is, we can determine \(P_{2}\) as long as we can calculate the distributions \(P(_{})\) and \(P(^{*}_{})\). These distributions approach normal distributions for large \(N\) (**Fig. 2A, Supplemental**). We use

Figure 2: **(A) The distributions for the minimum distance in rate space of \(_{min}\) (Top) and the analogue used for the rate dependent noise model, \(N^{*}_{min}\) (Bottom), constructed from kernel density estimates. At large \(N\), these approach gaussian. Plots are for one dimensional rooms, with room length \(L=1m\) and firing field widths \(W=1/3m\). (B) The probability that two contexts are distinguishable as a function of the number of neurons and at different noise levels, for the rate independent (Top) and dependent (Bottom) noise models. (C) The logarithm of \(M(N)\), the number of storable contexts as a function of \(N\), at \(P_{M}=.95\%\) confidence. In black is the predicted large \(N\) scaling, \( N+ N\).**

numerical methods to find the mean and variance of these distributions. That is, we generate many pairs of rooms with unique place maps for each room and then reconstruct these underlying distributions using normalized Kernel Density Estimation (KDE) while varying the value of \(N\) (the number of neurons). Finally we can use these reconstructed distributions to calculate \(P_{2}\) for both noise models as a function of \(N\) and the strength of the noise (**Fig. 2B**).

Given the above, we can estimate the total number of storable contexts, \(M\), of the place system as a function of key parameters of the system. First, we determine how \(M\) scales with the number of neurons \(N\). Given the probability that any pair of rooms is distinguishable, we can estimate the probability that \(M\) environments are distinguishable, \(P_{M}\), via a union bound:

\[P()=P(_{i j}ij) P_{2}^{}\] (12)

In weak to moderate noise regimes, this inequality becomes approximately saturated (**Supplemental**). Thus, we have \(P_{M} P_{2}^{}\). To find the number of storable contexts given \(N\) neurons, \(M(N)\), we can increase \(M\) until \(P_{M}\) falls below a desired confidence or allowable error, and call the \(M\) where this occurs the number of storable contexts. For numerically derived values, we use \(P_{M}=.95\), but note that this only changes prefactors, and the scaling behaviour is independent of this choice. Equivalently, we can simply invert \(P_{M} P_{2}^{}\) to find \(M(N)\) for a given confidence \(P_{M}\) (**Supplemental**):

\[M(N))}{(P_{2}(N))}+}+1/2(N^{ 1/4}+(N^{1/8}))e^{ N}\] (13)

In the limit of a system dominated by noise, we can never meet our geometric constraints, and \(M(N)=1\). However, if the noise is more reasonable, we find that \(M\) scales exponentially with \(N\) for both noise models (**Fig. 2C**, **Supplemental**). Here, \(\) is a constant that depends on firing field widths, noise, and room geometry but, critically, is independent of \(N\) at large \(N\). We can calculate \(\) in terms of the distributions of \(_{min}\) and \(N_{min}^{*}\) as (**Supplemental**):

\[_{}=([_{min}]/-2}{2[_{min}]}})^{2}_{}=([_{min}^{*}]-}{2[_{min}^{*}]}})^{2}\] (14)

Here, \(_{}\) and \(_{}\) refer to the exponents in the fixed noise model and variable noise model, respectively. One can readily show that at large \(N\), the equations for gamma for both noise models will become independent of \(N\) (**Supplemental**). In this large \(N\) regime, we can then characterize the number of storable contexts solely using the mean and variance of the distributions \(P(_{min})\) and \(P(N_{min}^{*})\). We accordingly calculated the number of distinguishable contexts numerically, and compared with the predicted large \(N\) behaviour (**Fig. 2C**), finding good agreement. Our results demonstrate that place coding allows encoding of exponentially many contexts with an exponent controlled by the amount of neuronal noise (**Fig. 3**).

### A Trade-off Between Spatial Specificity and Context Segregation

Realistic hippocampal place cells have tuning curves of varying widths. Indeed, across the dorso-ventral axis of the hippocampus, place field widths can vary by nearly an order of magnitude [21; 24], with ventral place cells having wider tuning than dorsal cells. As such, we next explored how the exponent of the number of stored contexts \(\) scales as a function of firing field width (**Fig. 3**, **Supplemental**). To do so, we numerically reconstructed the distributions \(P(_{min})\) and \(P(N_{min}^{*})\) for various place cell widths. In our model, increasing the widths of place field tunings starting from small sizes generally leads to an increase in the distance between representations of environments.

That is because, especially in small environments, a relatively small number of place cells will show place fields, and hence small place fields lead to sparse population activity, reducing the absolute distance between firing vectors in different environments. Increasing place field widths increases the average neuronal activity within an environment, thus pushing the encoding manifolds apart. As a result, we expect larger fields to increase contextual capacity. In fact, in small environments (\(1m-4m\)), optimal context discrimination performance occurs with firing fields that are about the size of the environment (**Fig. 3**). We can get a sense of why this happens as follows. Consider smaller environments in which less than half of all place cells are active due to the Gamma-Poissonstatistics of place cell activation [29; 30]. When place cells have extremely large widths in this regime, each neuron is either completely on or off within a given environment, and so each context becomes associated with a random binary identifier, that will be unique with high probability. Thus the environmental context can be read off simply by noting which place cells are active, although there is no location resolution at all. By contrast, in larger rooms, most place cells will have at least one firing field. So, although the sparse firing of narrow place fields makes it harder to discriminate contexts based on their responses, the largest, environment-sized firing fields also become useless in this case because essentially all cells will be active in every room (**Supplemental**). In either case, we expect a tradeoff between the twin goals of context and location discrimination that depends directly on place field size, and indirectly on environment size due to the gamma-poisson statistics used to generate place field centers.

Tuning the firing field widths lets us explore the trade-off between two presumed objectives for hippocampal function; encoding of position and encoding of multiple contexts. While wider fields are generally better for context segregation, it is clear that they are not optimal for spatial specificity, as wider fields result in less variation in population level firing between locations. Thus we expect a trade-off between spatial information encoded within a context, and the ability to separate contexts, tuned by the widths of place cell firing fields. To formalize this trade-off, we must determine how we will explicitly characterize both spatial specificity and context segregation. To characterize spatial specificity, we chose to utilize average decoding performance on decoding current position \(\) from the firing rates \((x)\) of the place cell system. Naturally, good performance occurs when the decoded position typically agrees with the true position, or \((-x)^{2}_{|x}\) is small at most positions. To avoid a particular choice of decoder, we invoke the Cramer-Rao bound, which lower bounds the covariance of _any_ estimator by the inverse Fisher Information:

\[(-x)(-x)^{T}_{P(r|x)} ^{-1}(x)=(_{r}[(_{x}t)( _{x}t)])^{-1}\] (15) \[(-x)^{2}_{P(r|x)} [^{-1}(x)]\] (16)

When \(x\) represents position in a one dimensional context, the inverse Fisher Information is a scalar. If \(x\) is not one dimensional, then the inequality is a statement about the difference between the covariance and the inverse of the Fisher Information being positive semi-definite, so that a bound on the mean squared error can be found by taking a trace. In both noise models, the Fisher Information can be calculated exactly in terms of the tunings of each neuron within an environment as (**Supplemental**):

\[_{}=}_{i}_{x}f_{A}^{i} _{x}f_{A}^{i} 42.679134pt_{}=_{i}(^{i}(x)}+^{i}(x)^{2}})_{x}f_{A}^{i} _{x}f_{A}^{i}\] (17)

We can now characterize spatial specificity by calculating the average spatial resolution by averaging the Cramer-Rao bound with respect to both position and context. The objective for maximizing the spatial resolution can be formalized by minimizing \([^{-1}(x)]_{x}_{A}\) (**Fig. 4A**). Tuning firing fields for high spatial resolution drives the firing field widths to a minimum set by the population size. Clearly, this is at odds with the first objective for storing many contexts, which drives firing fields to be larger. Here we find our anticipated firing field width trade-off between these two objectives. The character of this trade-off depends on how we formalize an objective function with respect to firing

Figure 3: The calculated value of the exponential \(\) at large \(N\) of equation (14), as a function of firing field width and neuronal noise. The environments are \(1m\) (**A and B**) and \(1m^{2}\) (**C and D**). (**A and C**) represent the rate independent noise model (Gaussian), while (**B and D**) are the noise dependent model (Poisson-like). White lines demarcate the transition into the non-separable regime. We find better performance for the lower dimensional environments and the Poisson-like model. For larger environments, smaller relative widths become preferable (**Supplemental**, Fig. 8).

field width \(W\). We consider two objective functions:

\[_{1} =(-1)(M(N,W))+(1-)[ ^{-1}]_{x}_{A}\] (18) \[_{2} =(-1)(P_{2}(N,W))+(1-) [^{-1}]_{x}_{A}\] (19)

Here \(\) interpolates between the two objectives by setting the relative importance of each, \(N\) is the number of neurons, \(W\) is the width of the firing fields, \(P_{2}\) is the probability that 2 rooms are separable given \(N\) and \(W\), and \(M(N,W)\) is the number of storable contexts (see discussion below eq. 12). As the relative importance shifts from a high contextual capacity to high contextual resolution, the optimal firing field width shrinks to a minimum set by the averaged Cramer-Rao bound. Such capacity-resolution trade-offs are consistent with those demonstrated in recurrent neural networks . For the first choice of objective function, the optimal width jumps abruptly as we vary \(\) (**Fig. 4B**). The second choice of objective function, on the other hand, strongly penalizes widths for which context segregation becomes impossible, leading to a smooth transition of the optimal firing field as we vary \(\) (**Fig. 4C**). Regardless, we see the same clear trade-off between our two objectives for each choice of formalization. This result suggests that the difference in field size across the dorsal-ventral axis of the hippocampus may reflect a segregation of coding function by optimizing for different objectives rather than just a gradient of spatial resolution as is commonly posited [17; 11]. This is also consistent with experimental evidence that dorsal hippocampus is largely recruited for spatial tasks, while ventral hippocampus typically shapes contextual response [22; 23; 24; 25; 26].

### Field Clustering near Boundaries improves Context Segregation

So far, we have assumed that the firing field centers are uniformly distributed. In reality, place cells often drift near positions of interest and frequented locations, such as boundaries or rewards. If place cells form a compressed representation of experience, then we can reasonably propose that the density of place cells at a location should reflect an increased resolution for memory formation near that location. This clustering could also have an effect on context separability. Indeed, we predict that such clustering improves context segregation, and demonstrate that biasing place cells towards the boundaries of contexts can improve the ability of the place system to discriminate between them.

A uniformly distributed place cell population will, in general, have less overlapping fields near the boundaries of an environment. Since discrimination between contexts critically depends on the overlap between place cell firing fields, this lack of density by the boundaries increases the probability of confusion between contexts. This observation matches perceptual intuition. In the center of environments, animals are able to reference distal cues as well as different proximal cues in the

Figure 4: **(A) The Cramer Rao Bound for both noise models. (Top) represents the rate independent model, while (Bottom) represents the rate dependent model. (B-C) The optimal width as a function of the relative importance between the two objectives. Using \( M\) to characterize context decoding leads to a sharp change in the optimal width, while \( P_{2}\) leads to a more gradual change. In both cases, there is a trade-off between storing high resolution information and storing many contexts, tuned by firing field width.**

environment. Adjacent to a boundary, the boundary is the dominate cue and likely obscures other cues that could potentially distinguish environments. In our model, we can add an in-homogeneity to the point process for generating place field centers to increase place field density near the boundaries. For one dimensional contexts, we can parameterize this in-homogeneity via a symmetric beta distribution, \((x/L;,)\) (**Supplemental**) over space. Here \(\) acts as a 'uniformity' parameter. With \(=1\) we recover the homogeneous process and have uniformly distributed place cells. Values of \(<1\) will progressively bias firing field centers towards the boundaries.

To understand the effect of the bias \(\) on discrimination of pairs of contexts \(A\) and \(B\), we can look at where the distance in rate space is smallest. These distances are given by \(d(f_{A}(x_{A}),f_{B}(x_{B}))\) and \(K(s(x_{A},x_{B}),x_{A},x_{B})\) for each noise model, respectively. For one dimensional contexts, these can be viewed as two dimensional surfaces swept out by \(x_{A}\) and \(x_{B}\) (**Fig. 5A**), while for two dimensional contexts these could be viewed as four dimensional surfaces. We take the sample to sample (annealed) average first, to find where, on average, the minimum of this surface is likely to be found (**Fig. 5D**). With \(=1\) this minimum occurs most often near the boundaries of either context \(A\) or \(B\). As we decrease \(\), the minimum of the averaged surface near the boundaries increases until it eventually jumps discontinuously to the center (**Fig. 5D**). The value of \(\) for which this jump occurs is dependent on firing field width and the noise model under consideration, but is independent of \(N\) at large \(N\) (**Fig. 5B**). Wider firing fields tend to lead to a larger optimal bias (**Fig. 5C**). In two dimensions, we considered a distribution of firing field centers that is a product of beta distributions, \((x/L;_{x},_{x})(y/L;_{y},_{y})\). The analysis for the \(x\) direction and \(y\) direction separate, which leads to identical optimal values for the uniformity parameter \(\) as in the 1-D case.

## 3 Discussion

Many researchers have proposed that the place system in the neural substrate of the cognitive map and that global place cell remapping plays a critical role in storing information about environmental context [11; 15; 16; 17; 6; 7; 8]. Further, recent work may implicate the role of place maps in general, short term memory formation [11; 37; 38; 39; 40], which might explain the need for such a large contextual capacity. In this work, we have built upon these proposals by explicitly demonstrating under realistic firing statistics that the place cell system's context storage capacity grows exponentially

Figure 5: **(A)** An example surface swept out between distances in code space by positions \(x_{A}\),\(x_{B}\), \(d(f_{A}(x_{A}),f_{B}(x_{B}))\). We have analogous surfaces for the rate dependent noise model. **(B)** The height, on average, of the minimum of the this surface for both noise models, and various firing field widths. **(C)** The optimal values of \(\) derived from this approach, for both noise models and an approximation from equalizing firing ratios from the boundary and the bulk (**Supplemental**). **(D)** The sample to sample average of the surface removes variations due to the random choice of \(f_{A}\). The minimum of this surface is near the boundaries at \(=1\), but jumps discontinuously the center as \(\) decreases.

with the number of neurons, and by calculating the associated exponents. This large capacity is consistent with the notion that the hippocampus is capable of pattern separating context and encoding many experiences , and here we demonstrate that a place-like coding scheme alone is sufficient in this regard. To achieve this result, we developed a geometric model of place cell activity, which allowed us to explore how this capacity changes as a function of the number of place cells in the system and of place cell firing field properties. While our strict conditions on pairwise separability leads to a coding scheme that is robust to noise, we note that less strict conditions may be more realistic, and better suit an animals behavioural needs. We primarily focused on global remapping here, but conjecture that the qualitative structure of our results remain unchanged by including the effects of partial remapping. Including these effects will give each manifold an additional width along a few dimensions due to variations that are not due to neural noise, but rather due to partial or rate remapping. Additionally, we have not considered here the complexity of decoders of the hippocampus. Although we show that context separation is achievable, the requirement of simple decoding, as well as the architecture of the underlying hippocampal network, will further constrain the contextual capacity .

We then explored implications of this model as it pertains to various objectives of the hippocampal code. In particular, we revealed a trade-off between precise encoding of local position and discrimination between different contexts. We found that tuning individual place cells for encoding local position leads to smaller place field widths, while increasing place field widths leads to improved performance for context discrimination. The size of place fields increases from the dorsal hippocampus to the ventral hippocampus , and we suggest that this mixed population of neurons allows the hippocampus to perform both objectives efficiently. That is, our model suggests that place cells of the dorsal hippocampus are better tuned for fine grained memory, while the more widely tuned ventral cells are better tuned for pattern separation and storage of many contexts. This is consistent with experimental evidence, in which dorsal lesion typically impair spatial memory, while ventral lesions do not. Conversely, ventral lesions have been demonstrated to impair contextual memory, for example decreasing response in contextual fear experiments, but have minimal affect on spatial tasks .

We also found that biasing place cell centers to cluster near environmental borders improves context discrimination. Over-representation of place field activity near boundaries is well documented , and we predict that this bias will systematically vary across the dorsal-ventral axis of the hippocampus, with the more widely tuned ventral place cells displaying greater bias than dorsal place cells. As rodents typically explore near boundaries of an environment, the need for higher spatial resolution in these locations may also lead to a similar bias. In fact it is well established that developmental and self-organization mechanisms can produce efficient structural and functional optimizations (vision: ; audition: ; olfaction: ; spatial cognition: ) and here we are suggesting that similar processes may operate in the place system.

While we have explored hippocampal codes in isolation, interactions with other spatially tuned cells, such a egocentric and allocentric border cells, likely have an effect on this bias not explored here, suggesting yet another intricate interaction between allocentric-egocentric representations in the hippocampus . If place cells are implicated for general episodic memory, such an interaction may imply that boundary cells play a role in general memory. Exploring this interaction is a topic for future work, and our approach provides a foundation for exploring these avenues.

Finally, we have also focused on physical one and two dimensional contexts in this work, but our geometric formulation generalizes to higher dimensional and abstract spaces. Our derivation of the exponential scaling is independent of the dimension, and so we predict that the hippocampus should also be able to segregate context and distinguish locations in more abstract spaces efficiently. It is worth noting however that there is still an appreciable drop in performance when moving from one to two dimensional spaces, and so the system is likely incentivized to encode abstract spaces with lower dimensional structures when possible.

**Acknowledgments:** We thank Dori Derdikman, Genela Morris, and Shai Abramson for many illuminating discussions in the course of this work, which was supported in part by NIH CRCNS grant 1R01MH125544-01 and by the NSF and DoD OUSD (R&E) under Agreement PHY-2229929 (The NSF AI Institute for Artificial and Natural Intelligence). VB was supported in part by the Eastman Professorship at Balliol College, Oxford.