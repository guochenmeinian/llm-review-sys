# SODA: Robust Training of Test-Time Data Adaptors

Zige Wang\({}^{1,2}\) Yonggang Zhang\({}^{2}\) Zhen Fang\({}^{3}\) Long Lan\({}^{4}\)

Wenjing Yang\({}^{4}\) Bo Han\({}^{2}\)

\({}^{1}\)School of Computer Science, Peking University \({}^{2}\)Hong Kong Baptist University

\({}^{3}\)University of Technology Sydney \({}^{4}\)National University of Defense Technology

###### Abstract

Adapting models deployed to test distributions can mitigate the performance degradation caused by distribution shifts. However, privacy concerns may render model parameters inaccessible. One promising approach involves utilizing zeroth-order optimization (ZOO) to train a data adaptor to adapt the test data to fit the deployed models. Nevertheless, the data adaptor trained with ZOO typically brings restricted improvements due to the potential corruption of data features caused by the data adaptor. To address this issue, we revisit ZOO in the context of test-time data adaptation. We find that the issue directly stems from the unreliable estimation of the gradients used to optimize the data adaptor, which is inherently due to the unreliable nature of the pseudo-labels assigned to the test data. Based on this observation, we propose pseudo-label-robust data adaptation (SODA) to improve the performance of data adaptation. Specifically, SODA leverages high-confidence predicted labels as reliable labels to optimize the data adaptor with ZOO for label prediction. For data with low-confidence predictions, SODA encourages the adaptor to preserve data information to mitigate data corruption. Empirical results indicate that SODA can significantly enhance the performance of deployed models in the presence of distribution shifts without requiring access to model parameters.

## 1 Introduction

Deep neural networks have emerged as a dominant tool in solving artificial intelligence problems due to their exceptional performance across various tasks , thus being deployed to various environments. However, in practice, these models typically suffer performance degradation due to distribution discrepancies between training and test data . To mitigate this issue, Test-Time Adaptation (TTA) is proposed as a promising solution, where unlabeled test data are leveraged to modify the parameters of deployed models to alleviate performance degradation .

In practice, the parameters of deployed models may be unmodifiable and inaccessible in many applications due to intellectual property protection, misuse prevention, or privacy concerns in healthcare and finance . The difficulty in modifying model parameters has hindered previous efforts aimed at adapting deployed models to the test distribution . It is shown that training a data adaptor to modify test data offers an alternative solution to mitigate the performance degradation caused by distribution discrepancy . However, the difficulty in accessing model parameters makes gradient computation a challenging task, hindering these data adaptation methods.

One straightforward approach involves utilizing zeroth-order optimization (ZOO)  to train the data adaptor to adapt test data to fit deployed models. In particular, ZOO can be employed to estimate gradients for the optimization of data adaptors without modifying and accessing the parameters of deployed models. Therefore, test-time data adaptation with ZOO makes it possible to improve the performance of deployed models in many practical scenarios. However, introducing data adaptorstrained with ZOO brings limited improvement. To endow data adaptors with reliability in improving model performance, we revisit ZOO in the context of test-time data adaptation. Training of the data adaptor depends heavily on the predicted labels. Thus, unreliable predicted labels will lead to unreliable gradient estimations in ZOO, which makes data features corrupted rather than adapted to deployed models. This is consistent with our observations as depicted in Figure 1.

Built upon the observation, we propose pseudo-label-robust data adaptation (SODA) to enhance deployed models with inaccessible parameters. SODA robustifies the training of data adaptors by splitting the test dataset into two subsets. One subset contains data with high-confidence predictions and is regarded as a reliable dataset. The other contains the remaining data points, considered to be an unreliable subset. For data in the reliable dataset, SODA trains the data adaptor using ZOO in a supervised manner. In the meantime, SODA encourages the data adaptor to preserve input information in an unsupervised manner for data corruption mitigation over unreliable data. To verify the efficacy of SODA, we evaluate it on three widely used benchmark datasets under various settings. Our experimental results demonstrate that SODA can effectively mitigate the performance degradation of deployed models in the presence of distribution shifts.

To sum up, our main contributions are presented as follows:

* To enhance deployed models with unmodifiable and inaccessible parameters, we propose to shift from model adaptation to data adaptation, where zeroth-order optimization is employed to estimate gradients for the training of the data adaptor. Unfortunately, test-time data adaptation causes corruption of data features, leading to limited performance improvements.
* To exploit the potential of test-time data adaptation, we find that the limited improvement issue stems from the unreliable nature of the predicted labels used in ZOO. Thus, we propose SODA to robustify the training of test-time data adaptation, where the data adaptor is trained to preserve input information for data with unreliable predictions.
* We verify the effectiveness of SODA under various settings. Our experimental results demonstrate that SODA can directly enhance the deployed model under distribution shifts without accessing and modifying the model parameters.

## 2 Related Work

**Test-time adaptation.** Test-time adaptation is a machine learning technique that addresses the distribution shift problem using only unlabeled test data before making predictions. To mitigate the distribution discrepancy, most previous works adapt the pre-trained model to test data by modifying

Figure 1: Demonstration of corrupted data and adapted data. The left part shows examples of the original test data from CIFAR-10-C, the corrupted data generated by the data adaptor trained with unreliable pseudo-labels, and the adapted data generated by the data adaptor in SODA. The right part shows the corresponding accuracy of test data, corrupted data, and adapted data on CIFAR-10/100-C.

the full or part of the model parameters. Some advanced works [7; 21] adapt the feature extractor to obtain more efficient feature representations of test data, while others [16; 17; 45] modify or replace the last linear classification layer to improve prediction over the extracted features. Batch normalization calibration [23; 34; 43; 49] is also exploited to adjust the statistics and affine parameters in batch normalization layers. Unlike previous works, our work focuses on situations where model parameters are unmodifiable and adapts test data to the pre-trained model as an alternative solution.

**White-box input adaptation.** Recently, several works have put effort into input-level optimization in test-time adaptation by changing the input data or features. Auxiliary auto-encoders [12; 18], amplitude features and Fourier-style calibration , label-preserving features along with a generative model , and generative diffusion model  are utilized to achieve input-level adaptation. These works require either modification of the model training process or gradients from the deployed model at test time. In contrast, our work focuses on test-time data adaptation without accessing the training process and gradients of the deployed model, making it more practical and broadly applicable.

**Domain adaptation of black-box predictors.** Domain Adaptation of Black-Box Predictors (DABP) is a subcategory of unsupervised domain adaptation [9; 30] that solves a more restricted and practical application setting. Under this setting, the pre-trained model is treated as a black box, and only the model's output is available during adaptation. Few works [22; 32; 46] have proposed solutions to this challenge using knowledge distillation to transfer knowledge from the black-box model to target models. In this work, we address the black-box setting in the context of test-time adaptation and propose to perform data adaptation without knowledge transfer. Besides, while previous DABP works require training on the entire unlabeled test dataset, our proposed method can also deal with online black-box settings where the test data arrive sequentially.

**Zeroth-order optimization.** Zeroth-order optimization (ZOO)  is a family of optimization methods that do not require gradient information to search for the optimal solution. Instead, it explores the searching space using various techniques [6; 24] to estimate the optimization direction. Although it can be less efficient than first-order optimization methods, ZOO methods can be helpful in scenarios where gradient information is unavailable or expensive to compute. For instance, recent studies have applied ZOO to perform adversarial attacks to black-box neural networks , hyperparameter optimization in federated learning without gradient descent , and transfer learning on black-box models . In this work, we propose to leverage ZOO for test-time data adaptation on deployed models with inaccessible gradient information.

## 3 Methodology

We mainly focus on the \(C\)-way image classification task with a distribution shift between the training and test data, following previous works [26; 39; 43]. Given a deployed model \(\) with inaccessible parameters, our purpose is to improve its prediction accuracy on unlabeled test data \(=\{_{1},...,_{n}\}\). Since the parameters and inner structures of \(\) are unknown, only the output prediction probabilities are available from \(\) during the entire adaptation process. Namely, the proposed method pseudo-label-robust data adaptation (SODA) aims to adapt \(\) to \(\) without requiring access to the parameters of \(\). The overall framework of SODA is shown in Figure 2.

### Preliminary

Before elaborating on our proposed framework, we introduce zeroth-order optimization (ZOO). ZOO is a gradient-free alternative of first-order optimization (FOO), e.g., SGD, SCD, and Adam. Most ZOO methods follow the structure of FOO and consist of three fundamental steps : gradient estimation, descent direction computation, and point updating. They utilize function-value-based gradient estimations to approximate the full or stochastic gradients computed in FOO.

One commonly used ZOO gradient estimation strategy is multi-point estimation [6; 24]. Given a continuously differentiable objective function \(f()\) on a \(d\)-dimensional variable \(^{d}\), multi-point estimation computes directional derivative approximation as follows:

\[_{}f():=_{i=1}^{q} (f(+_{i})-f())_{i},\] (1)where \(_{1},...,_{q}\) are \(q\) random direction vectors typically drawn from the standard multivariate normal distribution \((,)\), and \(\) is the smoothing parameter. On a mini-batch of data points \(_{1},...,_{l}\), the estimated gradient \(}\) is the average of the multi-point estimations to all data points \(_{1},...,_{l}\):

\[}=_{i=1}^{l}_{}f( ;_{i}).\] (2)

Various strategies are adopted to compute the descent direction. For zeroth-order stochastic gradient descent (ZO-SGD) utilized in our work, the descent direction is set as the current gradient estimation \(}\). The point updating rule is the same as in traditional SGD: with learning rate \(\),

\[=-}.\] (3)

### Zeroth-Order Optimization in Test-Time Data Adaptation

Let \(\) with parameters \(\) be the data adaptor for test-time data adaptation. For each test data point \(_{i}\) (\(i=1,...,n\)), \(\) transforms it to form the adapted data \(_{i}^{}\) for inference as follows:

\[_{i}^{}=(_{i};).\] (4)

Ideally, the data adaptor \(\) should be trained by minimizing the KL divergence between the predicted probabilities of the adapted data and the true labels of test data. Typically, the training process requires back-propagating the gradients from the deployed model to the data adaptor. A challenge arises as gradient computation is infeasible for the deployed model \(\) with inaccessible parameters. In this regard, ZOO provides an effective approach to estimating gradients, as discussed in the previous section. Considering the parameters \(\) of the data adaptor \(\) as the variables to be optimized, utilizing ZOO in test-time data adaptation is to replace the objective function \(f()\) with the training objective function used to train the data adaptor \(\). Assuming that the true one-hot label \(_{i}\) of a test data point \(_{i}\) is given, and replacing the function \(f()\) in Eq. (1) with KL divergence loss \((,):=(\|)\), the directional derivative approximation w.r.t. \((,)\) and \((_{i},_{i})\) is

\[_{}_{i}=_{j=1}^{q} (_{i},(_{i};+_{j}))-(_{i}, (_{i};))_{j}.\] (5)

Figure 2: The overall framework of SODA. (a) Before adaptation, SODA first performs reliable pseudo-label selection according to prediction confidence. (b) During adaptation, the data adaptor with parameter \(\) is trained over the test data with reliable pseudo-labels using cross-entropy loss and those with unreliable pseudo-labels using mutual information maximization. The gradient is estimated using (c) zeroth-order optimization.

In test-time adaptation, the true labels of test data are obviously unknown. A common strategy is to use the predicted pseudo-label \(}_{i}\) as the substitute of the true label \(_{i}\).

However, the pseudo-labels are unreliable due to the inaccurate model prediction under distribution shifts, causing the corrupted data features depicted in Figure 1. Let \(_{i}\) denote the disturbance of pseudo-label \(}_{i}\), i.e., \(}_{i}=_{i}+_{i}\), and \(}_{i}^{}=(_{i}; )\) denote the predicted probability of the adapted data point \(_{i}^{}=(_{i};)\), the KL divergence loss at test point \(_{i}\) becomes:

\[_{i}=-H(_{i}+_{i})+_{ ce}( _{i},}_{i}^{})-_{i}}_{i}^{},\] (6)

where \(_{ ce}(,)\) is the cross-entropy loss. Then, replacing \(_{i}\) with \(}_{i}\) in Eq. (5), the directional derivative approximation becomes

\[_{}}_{i}=_{ {}}_{ ce}+_{i}}{ q}_{j=1}^{q} }_{i}^{}}{}_{i}^{+ _{j}}}_{j},\] (7)

where \(_{}_{ ce}=_{j=1}^ {q}_{ ce}(_{i},}_{i}^{ +_{j}})-_{ ce}(_{i},}_{i}^{})_{j}\) is the ideal directional derivative approximation. The derivations of Eq. (6) and Eq. (7) are deferred to Appendix A. In Eq. (7), the last term is the disturbing term directly introduced by \(_{i}\), causing the difference between \(_{}_{ ce}\) and the unreliable directional derivative approximation \(_{}}_{i}\). \(_{}}_{i}\) further leads to unreliable estimated gradients in Eq. (2), which hinders the optimization of \(\) and the training of \(\).

### Pseudo-Label-Robust Training

A direct strategy to alleviate the impact of the disturbing term in Eq. (7) is to select pseudo-labels with small \(_{i}\). The selected pseudo-labels form reliable pseudo-label set \(}_{r}\) to train the data adaptor in a supervised manner. In particular, two basic criteria for reliable pseudo-label selection are adopted in SODA: 1) the prediction confidence should be higher than a threshold \(\), indicating the selected pseudo-labels have small disturbances; 2) the number of selected reliable pseudo-labels for each class should be less than \((1-)n/C\) to maintain the balance among classes, where \(\) is the noise ratio, and \(C\) is the number of classes. The test data points corresponding to the selected reliable pseudo-labels are considered as reliable data set \(_{r}\), which is trained over with cross-entropy loss \(_{ ce}\) and \(}_{r}\).

To mitigate the data corruption over the remaining test data points \(_{u}\) with unreliable pseudo-labels, SODA trains over them in an unsupervised manner. Following previous works [21; 22], mutual information maximization [4; 36; 41] is a widely-used unsupervised loss that can encourage both global diversity and local certainty of model predictions by maximizing the mutual information between the input data sample and the predicted probabilities. Thus, it is adopted to preserve input information in \(_{u}\) as shown in Eq. (8), where \(_{i}^{}=(_{i};)\) and \(}_{i}=(_{i};)\).

\[_{ im}(_{u}^{})=_{_{i} ^{}_{u}^{}}[_{k=1}^{C}} _{ik}}_{ik}]-_{k=1}^{C}_{_{i}^{ {}}_{u}^{}}}_{ik}_ {_{i}^{}_{u}^{}}}_{ ik}.\] (8)

### Theoretical Analysis

To theoretically show the effectiveness of the proposed pseudo-label-robust training strategy, we analyze the expected gradient estimation error [5; 24] in the training of test-time data adaptor with zeroth-order optimization. For simplicity, we consider the special case where the estimated gradient equals directional derivative approximation with mini-batch size equal to 1. The expected gradient estimation error \(_{}\) between the estimated gradient \(_{}}_{i}\) and the true gradient \(_{}_{i}\) w.r.t. the whole test dataset \(\) is:

\[_{}=_{}[ {}_{}}_{i}-_{} _{i}_{2}].\] (9)

Denoting \(h(_{i})=-_{i}}_{i}^{}\) in Eq. (6), the gradient of the KL divergence loss is \(_{}_{i}=_{}_{ ce}+ _{}h\). Accordingly, the estimated gradient of the KL divergence loss is \(_{}}_{i}=_{}_{ ce}+_{}h\). Then, before applying pseudo-label-robust data adaptation, the upper bound of expected gradient estimation error is:

\[_{}_{}[ _{}}_{ ce}-_{}_{ ce}_{2}]+[_{}h-_{}h_{2}].\] (10)

[MISSING_PAGE_FAIL:6]

**Baselines. Deployed** is the deployed model without adaptation. We compare our proposed SODA framework with two DABP baselines utilizing knowledge distillation. **DINE** distills the knowledge from the deployed model to a target model by minimizing the KL divergence between smoothed pseudo-labels and target model predictions. **BETA** divides the target domain into easy- and hard-to-adapt subdomains, then mutually distills twin networks with weak-strong augmentation on two subdomains. We further implement four vanilla baselines of test-time data adaptation using ZOO. **DA-Direct** directly generates adapted data instead of perturbations using the same network structure and initial pseudo-labels. **DA-PGD** adopts PGD  to directly generate perturbations using estimated gradients computed by ZOO and the training objective of SODA. **DA-ZOO-Input** uses the same data adaptor and training objective as SODA, except that the variables optimized in ZOO are the input data of the deployed model, i.e., the output adapted data of the data adaptor. The gradients of data adaptor parameters are computed based on the estimated gradients w.r.t. the adapted data. **DA-PL** trains the same data adaptor as SODA using initial pseudo-labels. Assuming gradient information is accessible, we also implement **SODA-R** using first-order gradients computed from the deployed model. To compare SODA with model adaptation, we implement **MA-SO** that modifies model parameters (except the last linear layer) using the same training objective as SODA.

**Deployed model settings.** For all experiments regarding CIFAR-10/100-C tasks, we adopt the CIFAR-10/100 pretrained ResNet-50  model used in  and  as the deployed model. For experiments regarding the ImageNet-C task, we adopt the ImageNet pre-trained ResNet-50 model provided by TorchVision  as the deployed model. Except for SODA-R and MA-SO, the deployed model is frozen with only output probabilities accessible. For SODA-R, the deployed model is also frozen, but gradients can be computed and back-propagated through the model. For MA-SO, the deployed model is set in training mode, and all parameters can be modified.

**Implementation details.** For SODA, the data adaptor uses a small network with two convolutional layers and an instance normalization layer in between to generate perturbations added to the original test data. For SODA-R in the CIFAR-10/100-C tasks, two ResNet blocks as in  are inserted between the convolutional layers to form a larger data adaptor. For SODA-R in the ImageNet-C task, one ResNet block and a couple of downsampling/upsampling layers are inserted instead. Detailed data adaptor structure is described in Appendix B.3. For all methods except DINE, BETA, DA-PGD, and SODA-R, the data adaptor/model is optimized using SGD with learning rate = 1e-3, momentum = 0.9, and weight decay = 1e-5. For DINE and BETA, we follow the same settings as in  and , and the target models are both ResNet-50 initialized with ImageNet-pretrained weights downloaded from TorchVision . For DA-PGD, the step size is also set to be 1e-3. SODA-R is optimized using Adam with learning rate = 1e-3 and weight decay = 1e-5. Batch size = 256 is fixed for all methods. The number of training epochs = 150 for all baselines except DINE and BETA, we train them for 120 epochs and fine-tune them for 30 epochs. For all methods using ZOO, the query number \(q\) = 5 for CIFAR-10-C and ImageNet-C and \(q\) = 10 for CIFAR-100-C, smoothing parameter

   Categories & Methods & FO Grad. & Model Mod. & C10-C & C100-C & IN-C \\  - & Deployed & - & - & 72.39 & 41.41 & 31.36 \\   & DINE & ✓ & ✗ & 73.86 & 40.52 & - \\  & BETA & ✓ & ✗ & 75.71 & 39.62 & - \\   & DA-PGD & ✗ & ✗ & 24.63 & 4.15 & 14.39 \\  & DA-ZOO-Input & ✗ & ✗ & 68.70 & 31.53 & 17.57 \\   & DA-Direct & ✗ & ✗ & 70.48 & 37.67 & 29.37 \\   & DA-PL & ✗ & ✗ & 72.93 & 41.44 & 31.91 \\   & SODA (Ours) & ✗ & ✗ & **82.55** & **52.41** & **42.14** \\   & SODA-R (Ours) & ✓ & ✗ & **88.39** & 60.31 & 48.70 \\  MA & MA-SO & ✓ & ✓ & 86.54 & **62.02** & **56.90** \\   

Table 1: Average accuracies (%) on CIFAR-10-C (**C10-C**), CIFAR-100-C(**C100-C**) and ImageNet-C (**IN-C**). **FO Grad.** means the requirement of first-order gradient from the target model or deployed model. **Model Mod.** means the requirement of modifying the parameters of deployed models. **Distill.** indicates methods using knowledge distillation to learn target models. **DA** indicates methods using test-time data adaptation. **MA** indicates methods using model adaptation.

\(\) = 1e-3. All experiments are repeated with three random seeds. The code implementation can be found at https://github.com/tmlr-group/SODA.

### Experimental Results

**Effectiveness of SODA.** Table 1 shows the accuracies on CIFAR-10-C, CIFAR-100-C and ImageNet-C averaged over 19 corruptions. In the mostly restricted setting where first-order gradient computation and model modification are both not allowed, SODA improves the deployed model prediction accuracy by a large margin, 10% on CIFAR-10-C, 11% on CIFAR-100-C and 11% on ImageNet-C. SODA also outperforms the DABP baselines on CIFAR10-C and CIFAR100-C tasks. Note that DINE and BETA are excluded in experiments on ImageNet-C because they are required to initialize their target models by ImageNet pre-trained weights, which violates the TTA setting. Especially on CIFAR-100-C and ImageNet-C task with much lower initial prediction accuracy, all baselines except MA-SO fail to improve, while SODA and SODA-R make significant improvement.

**SODA v.s. model adaptation.** Further relaxing the restriction on the deployed model, when parameters of the deployed model are frozen, but gradient computation is feasible, SODA-R achieves comparable accuracy with completely unrestricted MA-SO on CIFAR-100-C and even better accuracy on CIFAR-10-C. It shows that data adaptation can be as effective as model adaptation for deployed models with inaccessible parameters. On ImageNet-C, SODA-R performs worse than MA-SO, suggesting that improvement is still needed on large-scale datasets.

**Effect of pseudo-label-robust training strategy in SODA.** The failures of DA-Direct show that directly generating data using unreliable pseudo-labels fails to adapt data to the deployed model due to the corrupted data features. By adding perturbations to the original test data, DA-PL improves from DA-Direct to a small degree but still fails to enhance the deployed model. With the same data adaptor as DA-PL, SODA can improve the model prediction to a large degree, indicating the effectiveness of the proposed pseudo-label-robust training strategy.

**Effect of data adaptor parameter ZOO in SODA.** Both using a perturbation generation strategy, DA-PGD fails by directly generating perturbations using estimated gradients without learning a data adaptor, and DA-ZOO-Input achieves worse results by directly optimizing the model input using ZOO. With the same training objective, the significant improvements made by SODA indicate the effectiveness of the data adaptor parameter ZOO adopted in SODA.

### Discussion

**Effect of query number in ZOO.** To analyze the relation between query number \(q\) and adaptation accuracy in SODA, we conduct experiments with \(q\{2,5,10,20,50\}\). The results in Table 2 show that SODA is not sensitive to query number used in ZOO. Especially on CIFAR-10-C, only a slight performance drop is observed when \(q\) = 2. On CIFAR-100-C, a larger query number contributes to accuracy improvement more observably, but when \(q>10\), the contribution becomes less efficient, as the computation cost is also increased. Balancing the trade-off between accuracy and computation costs, we finally choose \(q\) = 5 for CIFAR-10-C and 10 for CIFAR-100-C.

**Zeroth-order optimization v.s. first-order optimization.** To better illustrate the effect of ZOO, we implement a comparing baseline as SODA-FO that shares the same setting with SODA but uses the first-order gradients back-propagated from the deployed model. Note that SODA-FO and SODA-R differ in data adaptor network structure, optimizer, and other strategies as discussed in Appendix C.1. As shown in Table 2, although SODA does not achieve the same accuracies as SODA-FO due to the unavoidable gradient estimation error, it still indicates competitive performance when gradient computation is infeasible. In Figure 3, SODA using ZOO has the slowest convergence speeds

   Query Numbers & 2 & 5 & 10 & 20 & 50 & SODA-FO \\  CIFAR-10-C & 82.43 & 82.55 & 82.57 & 82.59 & 82.53 & 85.97 \\ CIFAR-100-C & 51.03 & 52.19 & 52.41 & 52.97 & 52.97 & 54.32 \\   

Table 2: Comparison of SODA using ZOO with different query numbers and SODA using first-order gradients. The network structure, training objective, and training strategy are the same. Averaged accuracies (%) over 19 corruptions are reported.

and lowest accuracies on both datasets. SODA-FO has similar convergence speeds as SODA-R but converges to lower accuracies, indicating that the strategies used in SODA-R with first-order optimization, i.e., deeper network and Adam optimizer, can boost the training of the data adaptor.

**Effect of data adaptor network complexity.** We also explore the effect of data adaptor network complexity on SODA and SODA-R. To increase network complexity, we change the number of ResNet blocks in the data adaptor. Results of data adaptor with {0, 1, 2, 3} ResNet blocks are reported in Table 3. For SODA, accuracy decreases as network complexity increases, indicating that complex networks hinder data adaptation using ZOO. However, the accuracy of SODA-R increases along with network complexity. This contrast illustrates that a more complex data adaptor can achieve higher accuracy but is restricted and even encumbered by zeroth-order gradient estimation.

**SODA with fewer test data points.** We further explore the effectiveness of SODA with fewer test data points. We randomly choose \(\{50,100,500,1000,5000,10000\}\) test data points evenly distributed across 10 classes in CIFAR-10-C for each corruption as smaller test datasets. The averaged accuracies are reported in Figure 4. The performance of SODA is better when training data adaptor over more test data points. Nevertheless, training over 5,000 data points achieves comparable accuracy with training over 10,000 data points, showing that SODA does not require an extremely large number of data points to achieve good performance. Besides, SODA can still improve with less than 500 test data points, providing promising insights for test-time data adaption with smaller test datasets.

**Hyperparameter sensitivity.** We conduct sensitivity analysis regarding the noise ratio \(\), the confidence threshold \(\) and the balancing parameter \(\). The detailed results illustrated in Appendix C.3 show that SODA is robust to different combinations of hyperparameters, but adapting an adapted threshold instead of a fixed threshold might further improve the performance of SODA.

### SODA for Online Test-Time Adaptation

More practically, test data is not entirely available but arrives sequentially, i.e., online test-time adaptation. Hence, we further implement SODA-O as a variant of SODA under online settings. Given mini-batches of test data arrived sequentially \(\{_{1},...,_{T}\}\), SODA-O adapts one mini-batch at a time before processing the next mini-batch with knowledge accumulated from the previous mini-batches.

The main difference between SODA-O and SODA lies in the reliable pseudo-label selection. Without access to the test data before adaptation, SODA-O maintains an ordered queue \(\) with maximum size \(S\) to store the selected reliable pseudo-labels \(_{r}\) and their corresponding data points \(_{r}\). Specifically,for a mini-batch \(_{t}\) arrives at time \(t\), reliable pseudo-labels \(_{r_{t}}\) with prediction confidences higher than \(\) are selected and pushed into \(\) along with their corresponding test data points \(_{r_{t}}\). To maintain the class balance in \(\), the pseudo-labels with the smallest confidence for class \(k\) will be popped out once the number of pseudo-labels for \(k\) in \(\) is larger than \(S/C\). Then, the remaining data points \(_{u_{t}}\) in \(_{t}\) are considered as \(^{}_{u_{t}}\), all pseudo-labels and data points stored in \(\) are considered as \(^{}_{r_{t}}\) and \(^{}_{r_{t}}\). \(^{}_{u_{t}}\) and \(^{}_{r_{t}}\) form a small test dataset to train the data adaptor as in SODA, i.e. Step 2 in Algorithm 1. After adaptation, the inference of \(_{t}\) is given by the current data adaptor and the deployed model. Note that the optimization in SODA-O is not repeated after reaching the entire test dataset but only repeats for the current test data batch and the cached queue. During the adaptation of the current test data batch, the previous data batches are no longer available except for those saved in the queue. The data adaptor, hyperparameter setting, and training strategy of SODA-O are the same as SODA. The queue size \(S\) = 1,000 for both CIFAR-10-C and CIFAR-100-C.

**Effect of epochs per mini-batch.** We fix batch size = 256 and conduct experiments with different numbers of epochs per mini-batch, i.e., {5, 10, 30, 50, 100, 150} epochs/batch. As shown in Table 5, SODA-O is effective under online setting. As epochs/batch increase, the accuracy of SODA-O also increases and approaches the accuracy of SODA. But more training epochs means more processing time for each mini-batch, leading to a time-accuracy trade-off. With 10 epochs/batch, SODA-O can still improve the deployed model by 5% and 4% on CIFAR-10-C and CIFAR-100-C.

**Effect of batch size.** Fixing epochs/batch = 10, we also conduct experiments with different batch sizes, {32, 64, 128, 256}. The averaged accuracies are shown in Table 4. The results show that the performance of SODA-O is stable across different batch sizes. The best performance is achieved with batch size = 128. Only a slight performance drop is observed when batch size is reduced to 32, indicating that SODA-O can handle relatively small batch size.

## 5 Limitations

While providing valuable insights into robust test-time data adaptation for deployed models with inaccessible parameters, it is also essential to consider the limitations that may have affected the efficiency and effectiveness of our proposed framework. The main limitation of SODA is the time consumption brought by i) multiple queries required for gradient estimation in ZOO and ii) multiple passes required for training the random initialized data adaptor. In the future, one solution to alleviate this issue could be leveraging ZOO methods with higher query efficiency and less estimation error. Moreover, it is unclear whether SODA designed for OOD generalization can benefit OOD detection [8; 44]. Thus, we leave the exploration for OOD detection as our future work.

## 6 Conclusion

This paper focuses on two major challenges in adapting deployed machine learning models with inaccessible parameters at test-time: unmodifiable model parameters and infeasible gradient computation. Without modifying the model parameters, a data adaptor is adopted to adapt test data to the deployed model. Zeroth-order optimization is further leveraged to train the data adaptor with estimated gradients. Revisiting ZOO in test-time data adaptation, we discover that the unreliable gradient estimation in ZOO is due to the unreliable pseudo-labels assigned to test data. The proposed pseudo-label-robust data adaptation (SODA) addresses this issue with reliable pseudo-label selection and input information maximization. Our experiments on three widely used out-of-distribution benchmarks demonstrate the effectiveness of SODA in both offline and online settings.

   Methods & Deployed &  & SODA \\  Epochs/Batch & - & 5 & 10 & 30 & 50 & 100 & 150 & 150* \\  CIFAR-10-C & 72.39 & 75.22 & 77.03 & 79.63 & 80.38 & 81.33 & 81.71 & 82.55 \\ CIFAR-100-C & 41.41 & 43.59 & 45.81 & 48.56 & 49.26 & 50.04 & 50.12 & 52.41 \\   \\   

Table 5: Average accuracies (%) on CIFAR-10-C and CIFAR-100-C under online setting with different number of epochs per batch (batch size = 256).