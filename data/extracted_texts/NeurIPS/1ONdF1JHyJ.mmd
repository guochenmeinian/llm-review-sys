# Causal Deciphering and Inpainting in Spatio-Temporal Dynamics via Diffusion Model

Yifan Duan\({}^{1}\), Jian Zhao\({}^{2}\),, pengcheng\({}^{5}\), Junyuan Mao\({}^{1}\), Hao Wu\({}^{1}\), Jingyu Xu\({}^{3}\),

**Shilong Wang\({}^{1}\), Caoyuan Ma\({}^{3}\), Kai Wang\({}^{4}\), Kun Wang\({}^{6}\)\({}^{}\), Xuelong Li\({}^{2}\)\({}^{}\)**

\({}^{1}\)University of Science and Technology of China, \({}^{2}\)TeleAI, China Telecom, \({}^{3}\)Wuhan University,

\({}^{4}\)National University of Singapore, \({}^{5}\)Beijing Forestry University, \({}^{6}\)Nanyang Technological University

{duanyifan28,wslong1259,maojunyuan,wuhao2022}@mail.ustc.edu.cn,

{kevinxu,macaoyuan}@whu.edu.cn,pengcheng2022@bjfu.edu.cn,li@nwpu.edu.cn,

wk520529wjh@gmail.com,{E0823044,zhaojian90}@u.nus.edu

Equal contributionCorresponding authors

###### Abstract

Spatio-temporal (ST) prediction has garnered a _De facto_ attention in earth sciences, such as meteorological prediction, human mobility perception. However, the scarcity of data coupled with the high expenses involved in sensor deployment results in notable data imbalances. Furthermore, models that are excessively customized and devoid of causal connections further undermine the generalizability and interpretability. To this end, we establish a framework for ST predictions from a causal perspective, termed CaPaint, which targets to identify causal regions in data and endow model with causal reasoning ability in a two-stage process. Going beyond this process, we build on the front door adjustment as the theoretical foundation to specifically address the sub-regions identified as non-causal in the upstream phase. By using a fine-tuned unconditional Diffusion Probabilistic Model (DDPM) as the generative prior, we in-fill the masks defined as environmental parts, offering the possibility of reliable extrapolation for potential data distributions. CaPaint overcomes the high complexity dilemma of optimal ST causal discovery models by reducing the data generation complexity from exponential to quasi-linear levels. Extensive experiments conducted on five real-world ST benchmarks demonstrate that integrating the CaPaint concept allows models to achieve improvements ranging from 3.7%\(\)77.3%. Moreover, compared to traditional mainstream ST augmenters, CaPaint underscores the potential of diffusion models in ST data augmentation, offering a novel paradigm for this field. Our project is available at CaPaint.

## 1 Introduction

Deep learning methodologies have achieved groundbreaking success across a wide array of spatio-temporal (ST) dynamics systems , which include meteorological forecasting , wildfire spread modeling , intelligent transportation , and human mobility systems , to name just a few. Traditional ST dynamics approaches, based on first-principles , often come with high computational costs. In contrast, ST dynamic analysis methods based on deep learning are not directly reliant on the explicit expression of physical laws but are data-driven , relying on training models with large-scale observable datasets .

In a parallel vein, numerous efforts aim to incorporate physical laws into deep networks , termed Physics-Informed Neural Networks (PINNs), which blend deep learning principles with physics to address challenges in scientific computing, particularly in fluid dynamics.

PINNs augment traditional neural network models by including a term in the loss function that accounts for the physical laws governing fluid dynamics, such as the Navier-Stokes equations . This ensures that the network's predictions are not only consistent with empirical data but also comply with the fundamental principles of fluid dynamics. However, the off-the-shelf PINNs often suffer from limited generalization capabilities, primarily due to their _customized loss function_ designs and the _neglect of specific network parameter_ contexts [70; 16].

To date, the data-driven deep models are still dominant in ST dynamical systems, where the numerical simulation methods and PINNs generally lag behind. The reason may stem from the rise of large models [1; 76; 28] and the high costs associated with collecting ST data from sensors [93; 39], which creates a significant conflict between the increasing size of _data-hungry_ models and the _uneven, insufficient_ data collection. To this end, in the ST domain, there is looming research aimed at enhancing the causality and interpretability of models.

Unfortunately, research into causality within the field of ST dynamics is lagging. Although some work has considered causal design, due to specific domain constraints and architectural design, it can only enhance the tailor-made capabilities of the model for specific tasks [95; 38]. Moreover, causal discovery tools [12; 15] applied to ST systems often confront the "curse of dimensionality" issue during dimension reduction, despite their effectiveness in elucidating causal relationships from statistical data [75; 47]. Furthermore, Nuwabynamics for the first time proposed decomposing causal and non-causal regions in ST sequences and enhancing the robustness and generalizability of downstream model training by generating more potential distribution ST sequences through mixup . CauSTG  and CaST  address the issue of ST distribution shifts by implicitly modeling the time series embeddings and employing intervention techniques to observe these shifts.

Though promising, CauSTG  and CaST  focus on modeling graph-related data, they lack an understanding of high-dimensional observational data (Dimension \(<256\)). Nuwabynamics, on the other hand, explores all environments through backdoor adjustments , generating a vast number of sequences, which lead to nearly \((T_{E}^{(*)})\) training complexity (\(T\) represents history time step, \(_{E}\) and \((*)\) are the number of the environmental patches and mixup, respectively).

In light of this, we propose a general causal structure plugin, termed _CaPaint_, designed to decipher causal regions in ST data without adding extra computational cost, while intervening in non-causal areas to boost the model's generalizability and interpretability. Specifically, our method employs a straightforward approach to causal deciphering, utilizing a vision transformer architecture  for self-supervised ST data reconstruction. During reconstruction, we leverage _attention scores_ from the self-attention mechanism  to map onto important causal patches, thus endowing the model with interpretability. By ranking the entire set of importance scores, we define those with lower scores as environmental patches, which contribute minimally to the model. Building on this, we perform **causal interventions** in these environmental areas to aid the model in understanding more latent, complex, and imperceptible distributions, thereby enhancing the overall generalizability of the model (see Figure 1). Concretely, we mask trivial regions and perform generation using DDPM [24; 32] fine-tuned on specific ST data, which can also be interpreted as a ST data inpainting approach.

**Insight.** **CaPaint obeys the causal deciphering, and guided by the principle of frontdoor adjustment [51; 52] from causal theory, CaPaint performs diffusion inpainting interventions on the environmental (non-causal) diffusion patches while reducing the temporal complexity to a manageable \((_{})\) (from \((T_{E}^{(*)})\) in ). **CaPaint** performs regional inpainting in a more natural manner, avoiding the predicament of repeatedly selecting and perturbing environmental patches. Through diffusion inpainting , it generates images that are more aligned with the global distribution. **CaPaint** can be understood as a ST augmenter, offering a more rational concept of ST enhancement without disrupting the inherent distribution characteristics of space and time . Our major contributions can be summarized as follow:

Figure 1: Illustration of the CaPaint overview and advantage across SOTA ST causal model on complexity.

* In this paper, we introduce a novel causal structure plugin, CaPaint, which leverages the concept of frontdoor adjustment from causal theory. CaPaint enables various backbone models to learn from a broader distribution of data while providing enhanced interpretability for the models' predictions.
* By integrating diffusion generative models with ST dynamics, CaPaint selectively perturbs non-causal regions while maintaining the integrity of core causal areas. This approach generates valuable and reliable data for scenarios where high-quality data are scarce.
* We conduct extensive experiments across five diverse and representative datasets from different domains, utilizing seven backbone models to assess the effectiveness of the CaPaint method. The empirical results demonstrate that CaPaint consistently enhances performance on all tested datasets and across all backbone models (3.7%\(\)77.3%).

## 2 Related work & Technical Background

**Spatio-temporal Predictive Learning:** Various architectures have achieved significant predictive performance in ST domain, which can primarily be categorized as follows: CNN-based models utilize convolutional layers to effectively capture spatial features [45; 48; 77; 9]. RNN-based models, are capable of processing temporal sequence data and are well-suited for understanding temporal changes, showing excellent performance in the prediction of action continuity [69; 80; 86; 72]. GNN-based models effectively capture spatial dependencies and temporal dynamics in data, making them suitable for complex tasks involving geographic locations and temporal changes [44; 25; 36; 17; 99; 83; 14]. Transformer-based models employ self-attention mechanisms to process sequential data in parallel, enhancing the learning of long-term dependencies, and have been used for ST data prediction in complex scenarios [2; 19; 88; 91; 10; 89].

**Causal inference:** causal discovery algorithms, originally devised for unstructured random vectors [66; 104], have progressively been adapted for ST data analysis [75; 47]. Within the extensive field of deep learning research, the study of causal inference aims to ensure a more stable and robust learning and reasoning paradigm. Recently, an array of techniques has been developed to delve into the nuances of causal features [60; 61; 43; 97], identifying and eliminating spurious correlations [21; 34; 56].

**Generative models** especially diffusion-based model has gained significant popularity particularly in image and video generation [24; 64; 62]. Sampling optimization algorithms have been used to accelerate the sampling process of diffusion models, significantly reducing the number of steps while improving efficiency. [67; 41]. Additionally, generative models have also been applied to 3D scene generation and point cloud processing, as demonstrated in [40; 30; 73; 74; 22; 63]

**Image Inpainting** is a technique used to fill in missing or damaged parts of an image. This field can be broadly categorized into the following types. VAE-based methods: These methods leverage Variational Autoencoders to balance diversity and reconstruction [101; 103; 26]. GAN-based methods: Since the introduction of Generative Adversarial Networks, these methods have been widely used for image inpainting [55; 102; 49]. Diffusion model-based methods: Diffusion models have recently shown outstanding performance in image inpainting [46; 68; 57].

## 3 Methodology

In this section, we systematically introduce causal structure plugin, CaPaint. Initially, we elucidate the methods employed in the upstream phase to delineate causal and non-causal regions (Sec 3.1). Subsequently, we showcase the theoretical underpinnings supporting the CaPaint (Sec 3.2). Building on this causal theory, we further engage in causal intervention within observational data (Sec 3.3). Lastly, we demonstrate how sampling-enhanced ST observations can benefit the complexity of the model's _on-device deployment_ (Sec 3.4).

**Problem Formulation.** In ST settings, We represent ST observations as a sequence \(\{X_{t}\}_{t=1}^{T}\), where each observation \(X_{t}^{H W C_{}}\) originates from these sequences. Our objective is to predict the trajectory for the forthcoming \(K\) steps, denoted as \(\{X_{t+1}\}_{t=T}^{T+K}\), with each future state \(X_{t+k}\) mapped within \(^{H W C_{}}\). Here, \(H\) and \(W\) indicate the spatial grid dimensions, while \(C_{}\) and \(C_{}\) define the input and output dimensionality of the observations, respectively.

### Causal Deciphering

To find the causal (non-causal) patches with **no labels**, we employ a self-supervised reconstruction approach based on the Vision Transformer (ViT)  to identify key regions within ST observations. ViT segments the image into multiple patches and calculates the relationships between them using a self-attention mechanism. Due to no label property, we intentionally omit the use of the [Cls] token in classification task and send data into ViT for encouraging _"local-to-global"_ reconstruction.

Specifically, each ST data \(X_{t}\), is divided into \(N=HW/p^{2}\) patches, where each patch \(x_{t}^{patch}^{N(p^{2} C_{n})}\), with \((H,W)\) being the resolution of the original ST data and \((p,p)\) the resolution of each patch. Subsequently, each patch is mapped to a \(\)-dimensional token through a learnable linear layer, incorporating position embedding to enhance the model's sensitivity to positional information. These tokens are then fed into successive \(L\) stacked transformer blocks, as described in Equation 1:

\[L(}=(())}_{}\ \ \ \ X_{}=}+( (}))}_{})\] (1)

where LN denotes layer normalization, and MLP represents multi-layer perceptron. The upstream self-supervised reconstruction task enables the model to learn intrinsic property of ST data. Navigating the MSA mechanism , each patch \(x_{t}^{patch}\) derived from the ST observation \(X_{t}\) is transformed into queries \(q\), keys \(k\), and values \(v\), and then calculates the relevance of each patch to others, forming a weighted representation that focuses on the most informative parts. The attention weights \(A_{i,j}^{h}\) stored in the attention map \(A^{h}\) in each head are computed using the scaled dot-product:

\[\{Q,K,V\}=X_{t}_{tr},\ \ \ A^{h}= (}{}})=(A_{1,1}^{h }&&A_{1,N}^{h}\\ &&\\ A_{N,1}^{h}&&A_{N,N}^{h})_{A_{\{i,j\} 1 N }^{h}}\] (2)

where \(_{tr}^{N 3D_{h}}\) are the parameter matrices, \(D_{h}\) represents the dimension of each head, \(Q\), \(K\), and \(V\) collectively denote the sets of queries \(q\), keys \(k\), and values \(v\). In our approach, the determination of causal patches, is driven by an analysis of the attention maps \(A\). Each row in an attention map is normalized and represents the importance of other patches relative to the current patch \(x_{t}^{i}\). However, to ascertain the overall importance of each patch across the entire input, _we aggregate the contributions by summing the values along the columns of the \(A\)_. To integrate insights across multiple heads, we sum these measures across all heads and then normalize the resultant vector to derive a comprehensive importance score for each patch:

Figure 2: The details of CaPaint. (_Upper._) The initial phase of discovering causal patches. (_Bottom._) The update phase designed to eliminate spurious correlation shifts. Following the upstream training of the ViT, a diffusion model is trained in parallel. Using the identified causal patches as conditions, this generative model then performs inpainting for generating multiple sequences.

\[S^{N}=(_{h=1}^{H}_{i=1}^{N}A_{i,j}^{h})\] (3)

where \(S\) represents the normalized importance score vector, \(A_{i,j}^{h} A\) denotes the attention that \(x_{t}^{i}\) pays to \(x_{t}^{j}\) for each head, \(H\) is the number of heads. We sort the importance scores in \(S\) and select the patches corresponding to the lowest \(K\) scores as environmental patches storing in \(O_{e}\). The remaining patches are considered causal patches \(O_{c}\):

\[O_{c}=((S)\%,\;\; *{arg\,max}_{S_{i} S}\{((X_{t} ))\})\] (4)

where \(C(S)\) is the counting function, \(\) represents the proportion of patches selected as causal, and \((X_{t})\) denotes the set of patches in the ST observation \(X_{t}\). We identify the causal patches by locating the indices with the highest values in \(S\) and define the non-causal parts as the environmental parts. Our goal is to perform causal interventions on the environmental parts.

### Backdoor Adjustment v.s Frontdoor Adjustment

To address issues of ST data scarcity and poor transferability, we examine the evaluation process using a Structural Causal Model (SCM) , as shown in Fig 3. We represent abstract data variables by nodes, with directed links symbolizing causality. The SCM illustrates the interaction among variables through a graphical definition of causation, demonstrating the interconnected nature of these elements. As depicted in the left part, NuwaDynamics employs the backdoor adjustment to enhance the model's generalization performance:

* \(_{}_{ }\). The input \(\) consists of two disjoint parts \(_{}\) (causal part) and \(_{}\) (environmental or trivial part).
* \(_{}_{ }\). Here, \(_{}\) represents the sole endogenous parent that determines the ground truth \(\). However, in practical scenarios, \(_{}\) is also employed in predicting \(\), which leads to the formation of spurious associations.

In general, a model \(_{}\) trained using Empirical Risk Minimization (ERM) often struggles to generalize to the test data \(_{te}_{te}\). Such distribution shifts are often induced by variations in environmental patches. Hence, addressing the confounding effect caused by the environmental confounder is crucial. Backdoor adjustment techniques are employed to perturb the environmental components, thereby enhancing the model's potential to observe a broader range of latent distributions by forcibly perturbing the environmental variables \(_{}\) (referred to as the **do-calculus** operator). Unfortunately, **O** traversing all environmental variables is quite challenging. Although NuwaDynamics uses Gaussian sampling to mitigate the issue of complexity, controlling Gaussian sampling in temporal sequence operations is particularly difficult. It requires meticulous adjustment of mean and variance to ensure a balance between the number of environmental samples and the training burden. **O** Worse still, by traversing all environments, it likely violates underlying properties, including distribution shift content and nonexistent scenarios . To address this issue, we employ front-door adjustment, as illustrated in the right half of the Fig 3:

* \(}_{}\). In this structure, \(\) serves as a confounder, creating a misleading path between \(}_{}\) and \(\). Here, \(}_{}\) represents the causal component within \(}\).
* \(}_{}}_{}^ {*}\). \(}_{}^{*}\) acts as the surrogate variable of \(}_{}\) and completes \(}_{}\) to align it with the data distribution. Initially, it derives from and encompasses \(}_{}\). Specifically, it envisions the potential complete observations that should exist when observing the sub-counterpart \(}_{}\). Additionally, \(}_{}^{*}\) adheres to the data distribution and upholds the intrinsic knowledge of graph properties, thus eliminating any link between \(\) and \(}_{}^{*}\). Consequently, \(}_{}^{*}\) is well-suited to act as the mediator, which in turn influences the model's predictions (\(\)).

Figure 3: Different SCM architectures of SOTA and CaPaint.

In our front-door adjustment framework, we utilize **do-calculus** on the variable \(}_{}\) to eliminate the spurious correlations introduced by \(\). Specifically, we achieve this by summing over potential surrogate observations \(_{}^{*}\). This approach allows us to connect two identifiable partial effects: \(}_{}}_{}^ {*}\) and \(}_{}^{*}\):

\[& P(|do(}_{ }=_{}))=_{_{ }}P(|do(}_{}^{*}= _{}^{*}))P(}_{}^{*}=_{}^{*}|do(}_{}= _{}))\\ &=_{_{}^{*}}_{_{}^ {*}}P(|}_{}^{*}=_{ }^{*};_{}=_{}^{{}^{} })P(}_{}^{*}=_{}^ {*})P(}_{}^{*}=_{}^ {*}|do(}_{}=_{} ))\\ &=_{_{}^{*}}_{_{}^ {*}}P(|}_{}^{*}=_{ }^{*};_{}^{*}=_{}^{{}^{ }})P(}_{}^{*}=_{ }^{*})P(}_{}^{*}=_{ }^{*}|}_{}=_{})\] (5)

\(P(}_{}^{*}|do(}_{ }=_{}))=P(}_ {}^{*}|}_{}=_{})\) holds as \(}_{}\) is the only parent of \(}_{}^{*}\). With data pair \((}_{},}_{}^{*})\), we can feeding the surrogate observations \(}_{}^{*}\) into our ST framework, conditional on the \(}_{}\), to estimate \(P(|}_{}^{*}=_{}^{*};}_{}=_{}^{{}^{} })\). Compared to previous work NuwaDynamics, CaPaint utilizes causal regions to generate global surrogate variables in a more rational manner, circumventing the cumbersome need to traverse environmental variables inherent in backdoor adjustments. **In fact, backdoor adjustments often likely violate underlying properties, leading to the generation of non-existent data distributions.** The broader scenarios of CaPaint will be detailed in Appendix C.

### Causal Intervention via Diffusion Inpainting

Building on the principles of causal analysis outlined above, we proceed to perform interventions on the environmental patches using diffusion inpainting, which enables us to manipulate the environmental areas. Initially, given the unique complexities of ST datasets, we _fine-tune_ the diffusion parameters to adapt seamlessly to the domain-specific challenges, which enhances the accuracy of our interventions on environmental patches. Diffusion models learn the distribution of data through a forward noise addition process and a reverse denoising process:

\[q(X_{t} X_{t-1})=(X_{t};}X_{t-1},_{t}I),  p_{}(X_{t-1} x_{t})=(X_{t-1};_{}(X_{t},t), _{}(X_{t},t))\] (6)

where \(X_{t}\) represents the data state at time step \(t\), undergoing a transformation from its previous state \(x_{t-1}\), \(_{t}\) controls the variance of the noise added at each step in the forward process, \(_{}\) and \(_{}\) are neural network outputs that approximate the mean and covariance, respectively. The fine-tuning objective of the diffusion process is designed to approximate the data distribution more accurately. Specifically, the training objective for diffusion models, denoted as \(_{}\), which predicts the noise, is typically defined as a simplified version of the variational bound:

\[L_{}=_{X_{0},( ,),,t}\|-_{} X_{t},,t\|^{2}\] (7)

where \(c\) is the condition information. In this paper, we perform inpainting on the environmental patches of ST data. Inspired by , we generate a mask image for each ST data where the causal patches are black and the environmental patches are white. By independently sampling the causal and environmental patches and applying the diffusion inpainting process, we are able to generate augmented ST observation data. The detailed algorithmic process is shown in Appendix A.

\[X_{t-1}^{cau}=}_{t}X_{0}+(1-_{t}), X _{t-1}^{env}=}}(X_{t}-}{_{t}}}_{}(X_{t},t)+_{t}z)\] (8)

\[X_{t-1}=m X_{t-1}^{cau}+(1-m) X_{t-1}^{env}\] (9)

where \(X^{cau}\) and \(X^{env}\) denote causal patches and environmental patches, \(m\) is a binary mask matrix, \(_{t}\) represents the scaling factor at each diffusion step, determining the variance retained in the transition from \(X_{t-1}\) to \(X_{t}\). The cumulative product \(_{t}=_{i=1}^{t}_{i}\) represents the accumulated scaling effect from the \(T=0\) to step \(t\). Equation 9 illustrates the merging of environmental patches and causal patches. Finally, the enhanced ST observation data are stored within our temporal sequence repository to bolster the downstream backbone.

### ST Sequence Sampling Modeling

Previous work  assumed that the closer the time point is to the present, the greater its influence, and thus used Gaussian sampling to select more ST data closer to the current time point. However, we argue that uniform sampling can better enhance the model's generalization ability. To enhance computational efficiency while ensuring prediction accuracy, we employ a ST sequence modeling approach that samples at each time point with a fixed probability controlled by the hyperparameter \(p\). This method allows us to sample from both original and generated data at each time point, thereby creating a new spatiotemporal sequence. We use two hyperparameters: \(p\), which controls the sampling probability, and \(r\), which determines the number of generated spatiotemporal sequences, achieving an optimal balance between computational efficiency and prediction accuracy. The specific sampling process can be represented by the following equation:

\[X_{t}^{}=(X_{t},p,r)\] (10)

where \(X_{t}\) represents the collection of original and generated data at time point \(t\), and \((X_{t},p)\) denotes the dataset obtained by sampling from \(X_{t}\) with probability \(p\). The hyperparameter \(p\) is directly set as the sampling probability, while \(r\) is used to specify the number of generated ST sequences.

## 4 Experiments

In this section, we will validate the effectiveness of our proposed causal structure plugin, CaPaint. We design four research questions (RQs) to comprehensively evaluate the performance of CaPaint:

**RQ1:** Does CaPaint effectively enhance model performance and applicability? **RQ2:** How does CaPaint perform in data-scarce scenarios? **RQ3:** How does the performance of CaPaint compare with other augmentation methods? **RQ4:** Is CaPaint effective for long-term time step predictions? Through these research questions, we aim to validate the effectiveness and advantages of CaPaint in handling ST data from multiple perspectives.

### Experimental settings

**Datasets.** We extensively evaluate our proposal using a diverse range of benchmark datasets spanning multiple fields, include FireSys , SEVIR , Diffusion reaction system (DRS) , KTH  and TaxiBJ+ . Specifically, FireSys represents fire dynamics, SEVIR covers meteorological events, DRS involves physical control systems, KTH focuses on human motion dynamics, and TaxiBJ+ is a transportation dataset. Detailed information can be found in the Appendix B.

**Backbones and Metrics** To validate the generalizability of CaPaint, we select multiple model frameworks for our experiments, including the classic model like ConvLSTM , PredRNN-V2 , Vision Transformer (ViT) , MAU , the efficiency-focused SimVP , and some of the latest models like MmVP  and Earthfarsser . Our evaluation metrics include mean absolute error (MAE), mean squared error (MSE), and structural similarity index measure (SSIM). Detailed information can be found in the Appendix D.

Figure 4: Visualization of prediction results for TaxiBJ+ and SEVIR datasets. The left side shows the predicted results of the last 5 frames for TaxiBJ+. The middle presents the results of long-term predictions for SEVIR, displaying the last five frames from step 10 \(\) step 20. The right side compares SSIM metrics with and without the incorporation of CaPaint.

[MISSING_PAGE_FAIL:8]

training data proportions. This indicates that CaPaint is effective regardless of the amount of training data available, reinforcing its versatility and applicability in diverse scenarios.

**Obs 2. Significant performance gains in low data scenarios.** The results indicate that CaPaint yields substantial performance improvements, especially in low data scenarios. For instance, with only 10% of the training data, the SSIM improvement is most pronounced, highlighting the method's effectiveness in data-scarce environments. For example, in the TaxiBJ+ dataset with ViT backbone, the SSIM improvement reaches up to more than 50%, showcasing CaPaint's capability to enhance model performance with limited data.

**Obs 3. Diminishing returns with increased training data.** While _CaPaint_ consistently enhances performance, the degree of improvement diminishes as the proportion of training data increases. This trend suggests that the primary benefits of _CaPaint_ are most evident when data is scarce, but the method remains beneficial even as more data becomes available.

**Obs 4. CaPaint demonstrates superior performance with equivalent data volumes.** As illustrated in Fig 7, when comparing 25% original plus 25% augmented data with 50% original data, _CaPaint_ achieves lower MAE and MSE. This demonstrates that _CaPaint_ consistently outperforms the original model by effectively using a mix of original and augmented data, which together match the data volume used by the original model alone.

### Performance Comparison (RQ3)

In this section, we compare the performance of different data augmentation methods. Tab 2 shows the model performance using various data augmentation methods across multiple datasets, measured by MAE. It can be seen that traditional data augmentation methods, such as flipping, rotation, and cropping, produce results that are either on par with or slightly worse than the original data. Take the FireSys dataset as an example, MAE increased from 17.01 \(\) 17.07 after rotation augmentation. This indicates that conventional data augmentation methods may **disrupt the intrinsic properties** of ST data, thereby negatively impacting model performance.

In contrast, our method _CaPaint_ achieves the best performance **across all datasets**. For instance, on the TaxiBJ+ dataset, the MAE with _CaPaint_ augmentation is \(12.87\), which is significantly better than the MAE of \(15.11\) with _NuvaDynamics_ manual mixup augmentation and the MAE of \(15.94\) with other traditional augmentation methods such as cropping. These results highlight the advantage of our method in preserving the integrity of ST data properties. CaPaint not only effectively avoids the disruption caused by data augmentation processes on ST data characteristics but also significantly enhances the model's predictive capability.

## 5 Conclusion & Future Work

In this study, we advance the exploration of applying front-door adjustment and causality principles to spatio-temporal forecasting tasks through the introduction of _CaPaint_. Building upon the foundation of upstream self-supervised learning, we identify causal regions as crucial elements for generating

   Datasets & Fip & Rotate & Crop & NuWa & CaPaint \\  DRS & \(2.10 0.16\) & \(2.11 0.19\) & \(2.34 0.26\) & \(2.02 0.09\) & \(1.57 0.14\) \\ KTH & \(23.15 1.95\) & \(23.14 1.67\) & \(23.11 1.83\) & \(22.32 0.94\) & \(20.56 1.02\) \\ SEVIR & \(15.41 1.49\) & \(15.45 1.32\) & \(15.95 1.64\) & \(15.14 1.57\) & \(14.63 1.89\) \\ TaxiBJ+ \(16.47 0.99\) & \(16.39 1.32\) & \(15.94 1.45\) & \(15.11 0.87\) & \(12.87 0.76\) \\ FireSys & \(17.02 2.17\) & \(17.07 1.94\) & \(17.15 2.45\) & \(16.68 1.79\) & \(15.79 1.88\) \\   

Table 2: Comparison between CaPaint and other data augmentation methods across various datasets.

Figure 6: SSIM Improvement on DRS across various backbones

Figure 7: Visualizations in both MAE and MSE with Simpy and + CaP at various training data proportions.

comprehensive and potential data distributions. By integrating diffusion generative models, we ensure the generated data's rationality and generalizability, thereby enhancing the downstream models' ability to generalize beyond the observed distribution and improving their interpretability. Moving forward, we plan to explore various generative models for the production of arbitrary-channel ST data to enhance the _CaPaint_ robustness.

## 6 Acknowledgement

This work was supported by National Natural Science Foundation of China (62476224).