# Agnostic Multi-Group Active Learning

Nick Rittler

University of California - San Diego

nritller@ucsd.edu &Kamalika Chaudhuri

University of California - San Diego

kamalika@cs.ucsd.edu

###### Abstract

Inspired by the problem of improving classification accuracy on rare or hard subsets of a population, there has been recent interest in models of learning where the goal is to generalize to a collection of distributions, each representing a "group". We consider a variant of this problem from the perspective of active learning, where the learner is endowed with the power to decide which examples are labeled from each distribution in the collection, and the goal is to minimize the number of label queries while maintaining PAC-learning guarantees. Our main challenge is that standard active learning techniques such as disagreement-based active learning do not directly apply to the multi-group learning objective. We modify existing algorithms to provide a consistent active learning algorithm for an agnostic formulation of multi-group learning, which given a collection of \(G\) distributions and a hypothesis class \(\) with VC-dimension \(d\), outputs an \(\)-optimal hypothesis using \(((^{2}/^{2})Gd_{}^{2}^{2}(1/ )+G(1/)/^{2})\) label queries, where \(_{}\) is the worst-case disagreement coefficient over the collection. Roughly speaking, this guarantee improves upon the label complexity of standard multi-group learning in regimes where disagreement-based active learning algorithms may be expected to succeed, and the number of groups is not too large. We also consider the special case where each distribution in the collection is individually realizable with respect to \(\), and demonstrate \((Gd_{}(1/))\) label queries are sufficient for learning in this case. We further give an approximation result for the full agnostic case inspired by the group realizable strategy.

## 1 Introduction

There is a growing theory literature concerned with choosing a classifier that performs well on multiple subpopulations or "groups" [1; 2; 7; 6; 4; 5; 6; 3]. In many cases, the motivation comes from a perspective of fairness, where a typical requirement is that we classify with similar accuracy across groups [7; 6; 4]. In other cases, the motivation may simply be to train more reliable classifiers. For example, cancer detection models with good overall accuracy often suffer from poor ability to detect rare subtypes of cancer that are not well-represented or identified in training. This suggests that naive ERM may be insufficient in practice .

In this work, we consider the following formulation of "multi-group" learning. The learner is given a collection of distributions \(=\{D_{g}\}_{g=1}^{G}\), each corresponding to a group, and a hypothesis class \(\), and wants to pick a classifier that approximately minimizes the maximum classification error over group distributions. We consider this problem from an active learning perspective, where the learner has the power to choose which examples from each group it wants to label during training. In a standard extension of the active learning literature, we set out to design schemes for choosing which examples from each group should be labeled, where the goal is to minimize the number of label queries while retaining PAC-learning guarantees.

A major challenge in harnessing the power of active algorithms even in standard agnostic settings is making sure they are consistent. In the case of active learning, this means that as the numberof number of labels requested approaches infinity, the learner outputs an optimal hypothesis. To complicate things further, the main algorithmic paradigm for consistent agnostic active learning over a single distribution - disagreement based active learning (DBAL) - fails to admit direct application in the multi-group learning objective. The fundamental idea in DBAL is that the learner may safely spend its labeling budget in the "disagreement region", a subset of instance space where empirically well-performing hypotheses disagree about how new examples should be labeled. When the learner need only consider a single distribution, error differences between classifiers are specified entirely through their performance on the disagreement region, and so spending the labeling budget here allows the learner to figure out which hypotheses are best while saving on labels. The problem is that when multiple group distributions must be considered, the absolute errors of classifiers on each group must be estimated to compare performance of two classifiers in their worst case over collection, and this property no longer holds.

We resolve this via the observation that, while we cannot spend all our labeling budget in the disagreement region, we can exploit the agreement in its complement to cheaply estimate absolute errors of classifiers on each group. In particular, we estimate the absolute errors by choosing a representative classifier \(h_{^{}}\) in the set of empirically well-performing classifiers \(^{}\), and estimating its error on the complement of the disagreement region on each group distribution. These error estimates can be used to construct estimates for the absolute errors on each group for each \(h^{}\) at the statistical cost of estimating a coin bias, leading to a relatively cheap, consistent active strategy.

We analyze the number of label queries made by this scheme in terms of a standard complexity measure in the active learning literature called the "disagreement coefficient" [9; 10], and show an upper bound of \(((^{2}/^{2})Gd_{}^{2}^{2}(1/ )+G(1/)/^{2})\), where \(_{}\) is the maximal disagreement coefficient over the collection of group distributions. We discuss some regimes where this label complexity can be expected to push below sample complexity lower bounds for a learner that can request samples from each group distribution during training, but does not have power to abstain from labeling specific examples.

We also consider the special case of agnostic learning where each group distribution is individually realizable, but no single hypothesis separates all groups simultaneously. In this case, we show that all dependence on \(1/^{2}\) in the label complexity can be replaced with \((1/)\) when disagreement coefficients are bounded. It turns out that using the strategy we develop in this special case leads to an approximation algorithm for the general agnostic case, for which we give guarantees.

## 2 Related Work

### Multi-Group Learning

The majority of the empirical work on multi-group learning has been through the lens of "Group-Distributionally Robust Optimization" (G-DRO) [11; 12; 13]. The goal in G-DRO is to choose a classifier that minimizes the maximal risk against an unknown mixture over a collection of distributions \(\{D_{g}\}_{g=1}^{G}\) representing groups. One assumes a completely passive sampling setting - all data is given to the learner at the beginning of training, and the learner has no ability to draw extra, fine-grained samples. The strategy is usually empirical risk minimization (ERM) - or some regularized variant - on the empirical max loss over groups; for a set of classifiers parameterized by \(\), letting \(S_{g}\) denote the set of examples in the training set coming from \(D_{g}\), one performs \(_{}_{g[G]}|}_{(x_{i},y_{i}) S_{g}}l (f_{}(x_{i}),y_{i})\) for some loss \(l\). It is important to note that the learner knows the group identity of each sample in the training set, but is not provided with group information at test time, precluding the possibility of training a separate classifiers for each group.

"Multi-group PAC learning" consider the multi-group problem under the passive sampling assumption from a more classical learning-theoretic perspective [7; 6]. Here, one assumes there is a single distribution \(D\) from which one is given samples, but also a collection of subsets of instance space \(\) over which one wants to learn conditional distributions. Given a hypothesis class \(\), the learner tries to improperly learn a classifier \(f\) that competes with the optimal hypothesis on each conditional distribution specified by a group \(g\) in the collection - formally, one requires that for a given error tolerance \(\), \(f\) has the property \( g,\ \ _{D}(f(x) y|x g)_{h }_{D}(h(x) y|x g)+\) with high probability. An interesting wrinkle in this literature is that the group identity of samples is available at both training and test times. It has been shown that a sample complexity of \(((||)/^{2})\) is sufficient for agnostic learning in this model, where \(\) is the minimal mass of a group \(g\) under \(D\).

"Collaborative learning" studies the multi-group problem under an alternative sampling model [1; 2; 3]. In this case, we are given a collection of distributions \(\{D_{g}\}_{g=1}^{G}\), each corresponding to a group. Given some hypothesis class \(\), the goal is to learn a classifier \(f\), possibly improperly, that is evaluated against its worst-case loss over \(D_{1},,D_{G}\); formally, we would like \(f\) to satisfy \(_{g[G]}_{D_{g}}f(x) y_{h}_{g[G]}_{D_{g}}(h(x) y)+\). In contrast with multi-group PAC learning, the learner may decide how many samples from each \(D_{g}\) it wants to collect during training, and group identity is hidden on test examples. This models the case where a learner may want to collect more data from a particularly difficult group of instances, such as a rare or hard-to-diagnose type of cancer. It has been shown for finite hypothesis classes that \(((||)/^{2}+G/^{2})\) total samples over all groups are necessary and sufficient to learn in this model; \((d(1/)/^{2}+G/^{2})\) total samples are sufficient for VC-classes .

Our work extends the model of collaborative learning, and endows the learner with the ability to decide which samples from each group distribution \(D_{g}\) should be labeled. This is the standard framework of active learning, applied to the multi-group setting. As in collaborative learning, we assume group identity is hidden at test time.

### Active Learning

Active learning concerns itself with the development of learning algorithms for training classifiers that have power over which training examples should be labeled [14; 15]. The field has largely focused on uncovering settings in which algorithmic approaches reduce the amount of labels required for PAC-style learning guarantees beyond sample complexity lower bounds that apply to i.i.d. data collection from the underlying distribution [16; 17]. In the agnostic, 0-1 loss setting, the standard upper bounds for label complexity follow \(((d(1/)+d^{2}/^{2})\). Here, \(\) is the "noise rate", i.e. the true error of the optimal hypothesis \(h^{*}\), and \(\) is a distribution-dependent parameter called the "disagreement coefficient". Thus, gains of active strategies over standard passive lower bounds of \((d/^{2})\) depend on certain easiness conditions like small noise rates and bounded disagreement coefficients .

The vast majority of the work on active learning has been done in the 0-1 loss setting [18; 9; 10; 19; 20; 21]. It has been significantly harder to push the design of active learning algorithms past the regime of accuracy on a fixed distribution. While some work has attempted to generalize classical ideas of active learning to different losses , these are heavily outnumbered in the literature.

As previously mentioned, the most difficult part of designing agnostic active learning strategies is maintaining consistency. The issue comes down to a phenomenon referred to as "sampling bias" : because active learners would like to target certain parts of space to save on labels, there is a risk that the learner prematurely stops sampling on a part of space in which there is some detail in the distribution that could not be detected at a higher labeling resolution. This can easily lead to inconsistent strategies . Thus, a major contribution of our work is exhibiting a consistent active scheme for the multi-group problem.

   Problem & Full Agnostic & Group-Realizable \\  Passive Multi-Group  & \(((||)/^{2})\) & \(((||)/)\) \\ Collaborative Learning  & \((d(1/)/^{2}+G/^{2})\) &? \\ Active Multi-Group (us) & \(((^{2}/^{2})Gd_{}^{2}^{2}(1/ )+G(1/)/^{2})\) & \((Gd^{2}(1/))\) \\   

Table 1: Overview of the complexity of multi-group learning. The \(\) notation hide factors logarithmic in \(d\), \(G\), \(1/\), and \((1/)\). We reserve discussion of regimes in which our algorithm improves on results in Collaborative Learning for Section 5.

Preliminaries

### Learning Problem

We study a binary classification setting where examples fall in some instance space \(\), and labels lie in \(:=\{-1,1\}\). We suppose we are given some pre-specified, finite collection of distributions \(=\{D_{g}\}_{g=1}^{O}\) over \(\) corresponding to groups. Given a hypothesis class \(\) of measurable classifiers with VC-dimension \(d\), the goal of the leaner is to pick some \(h\) from finite data that performs well across all the distributions in \(\) in the worst case. Let \(L_{}(h g):=_{D_{g}}(h(x) y)\) be the error of a hypothesis \(h\) on group \(g\). Formally speaking, the learner would like to choose a classifier approximately obtaining

\[_{h}_{g[G]}L_{}(h g),\]

using finite data. We often use \(L_{}^{}(h)\) as shorthand for \(_{g[G]}L_{}(h g)\). We use \(:=_{h}L_{}^{}(h)\) to denote the "noise rate" of \(\) on the multi-distribution objective. The use of the term "agnostic" throughout reflects the fact that we make no assumption that \(=0\) in our algorithm design or analysis. We assume for simplicity that there is some \(h^{*}\) attaining \(\).

### Active Learning Model

We consider a standard active learning model specified as follows. Let \(supp(g)\) denote the support of the marginal over instance space of \(D_{g}\). The active learner has access to two sampling oracles for each distribution specified by \(D_{g}\). The first is \(U_{g}()\), which given a set \(S\) measurable with respect to \(D_{g}\), returns an unlabeled sample from \(D_{g}\) conditioned on \(S\); if \(_{D_{g}}(x S)=0\), then \(U_{g}(S)\) returns "None". The second is \(O_{g}()\), which given a point in \(supp(g)\), returns a sample from the conditional distribution over labels specified by \(x\) and \(g\). More formally, querying \(U_{g}(S)\) for \(S\) such that \(_{D_{g}}(x S) 0\) is equivalent to drawing i.i.d. samples according to marginal over instance space of \(D_{g}\) (independent of previous randomness), and returning the first example that falls in \(S\); querying the oracle \(O_{g}(x)\) for \(x supp(g)\) is equivalent to receiving a sample from a Rademacher random variable with parameter \(_{D_{g}}(Y=1|X=x)\).

As is standard in active learning, the active learner is assumed to have functionally unlimited access to queries from \(U_{g}()\). On the other hand, queries to oracles \(O_{g}()\) are precious: the "label complexity" of a strategy executed by the active learner is the sum of queries to oracles \(O_{g}()\) over all \(g\), and is to be minimized given a desired generalization error guarantee.

## 4 Challenges in Multi-Group Active Learning

In this section, we give some background on classical disagreement-based methods on a single distribution, and discuss in more detail the challenge of designing consistent active learning strategies in the multi-group setting.

### Background on Disagreement-Based Active Learning

Almost all agnostic active learning algorithms for accuracy over a single distribution boil down to disagreement-based methods [18; 10; 15; 16]. The fundamental idea in this school of algorithms is that one can learn the relative accuracy of two classifiers \(h\) and \(h^{}\) by only requesting labels for examples in the part of instance space on which they disagree about how examples should be labeled. More generally, given a set of classifiers \(^{}\), one can consider the "disagreement region" of \(^{}\), defined as

\[(^{}):=\{x: h,h^{} ^{}\;s.t.\;h(x) h^{}(x)\}.\]

As alluded to above, the difference in accuracy of classifiers \(h,h^{}^{}\) is specified entirely through this inherently label-independent notion. For a single distribution \(D\), we may write

\[_{D}(h(x) y)-_{D}(h^{}(x)  y)}{_{D}((^{}))}= _{D}h(x) y(^{})-_{D}(h^{}(x) y(^{})),\]

as by definition, \(h,h^{}\) have the same conditional loss on \((^{})^{c}\). Inspired by this observation, the idea is to label examples in \((^{})\), and ignore those outside of it. This allows the learner to learn about the relative performance of classifiers while saving on the labels of examples falling in \((^{})^{c}\)In running a DBAL algorithm, one hopes certain classifiers quickly reveal themselves to be empirically so much worse on \((^{})\) than the current ERM hypothesis, that by standard concentration bounds, they can be inferred to be worse than \(\)-optimal on \(D\) with high probability. Elimination of these classifiers shrinks the disagreement region, allowing the labeling to become further fine-grained. Given the above loss decomposition, this leads to consistent active learning strategies.

### Labeling in the Disagreement Region: No Longer Enough

In the multi-group setting, the strategy of comparing performance of classifiers solely on \((^{})\) breaks down. Although the classifiers in \(^{}\) still agree in \((^{})^{c}\), this is not enough to infer differences in the worst case error over groups \(L_{}^{}\); this is because differences in performance on \((^{})\) are not generally representative of differences in absolute errors over group distributions. The following simple example makes this concrete.

**Example 1**.: Consider the task of determining which of two classifiers \(h\) and \(h^{}\) has lower worst case error over distributions \(D_{1}\) and \(D_{2}\) with marginal supports \(S_{1}\) and \(S_{2}\). Let their disagreement region be denoted by \(=\{x:h(x) h^{}(x)\}\), and let \(l(f,i,A)\) denote the conditional loss of classifier \(f\) on \(S_{i} A\) under \(D_{i}\). Suppose we only know their conditional losses on \( S_{1}\) and \( S_{2}\) under \(D_{1}\) and \(D_{2}\), respectively. We see for \(h\) that

\[l(h,i,A)=49/100&i=1,A= S_{1}\\ 52/100&i=2,A= S_{2}\\?&i=1,A=^{c} S_{1}\\?&i=2,A=^{c} S_{2}\]

and for \(h^{}\) that

\[l(h^{},i,A)=51/100&i=1,A= S_{1}\\ 48/100&i=2,A= S_{2}\\?&i=1,A=^{c} S_{1}\\?&i=2,A=^{c} S_{2}.\]

Consider ignoring the performance of classifiers in \(^{c}\), and using as a surrogate for the multi-group objective

\[_{i\{1,2\}}l(h,i,S_{i}).\]

In this case, we would choose \(h^{}\) has the better of the two hypotheses.

Suppose now that \( S_{1}\) and \( S_{2}\) have mass \(\) under both \(D_{1}\) and \(D_{2}\), and that \(l(h,1,^{c} S_{1})=l(h^{},1,^{c} S_{1})=3/10\). Finally, suppose that \(l(h,2,^{c} S_{2})=l(h^{},2,^{c} S_{2})=2/10\). Then under the true multi-group objective, by decomposing the group losses, one can compute that \(h\) has a lower worst case error over groups \(D_{1}\) and \(D_{2}\).

Thus, to utilize the disagreement region in multi-group algorithms, we will need to at least label some samples on \((^{})^{c}\) as \(^{}\) shrinks. The specification of such a strategy is the content of the next section.

## 5 General Agnostic Multi-Group Learning

### An Agnostic Algorithm

The basic idea in Algorithm 1 is similar to classical DBAL approaches for a single distribution. We start with the full hypothesis class \(\), and look to iteratively eliminate hypotheses from contention as we learn about how to classify on each group through targeted labeling.

Our solution to the problem posed to DBAL above is to keep track of the errors of well-performing hypotheses on the complement of the disagreement region in a way that exploits the agreement property. To do this, we construct a two-part estimate for the loss of a hypothesis on a given group. Denote the set of hypotheses still in contention at iteration \(i\) is \(_{i}\). Let \(R_{i}=(_{i})\) and \(S_{R_{i},g}\) be a labeled sample from \(U(R_{i})\) and \(S_{R_{i}^{c},g}\) be a labeled sample from \(U(R_{i}^{c})\). We can now estimate the loss for some \(h_{i}\) on group \(g\) via

\[L_{S;R_{i}}(h g):=_{D_{G}}(x R_{i}) L_{S_{R_{i},g}}(h)+ _{D_{G}}(x R_{i}^{c}) L_{S_{R_{i}^{c},g}}(h_{_{i} }),\]where \(L_{S}(h):=1/||_{(x,y) S}[h(x) y]\) is a standard empirical loss estimate1, and \(h_{_{i}}\) is an _arbitrarily_ chosen hypothesis from \(_{i}\) that is used in the loss estimate of every \(h_{i}\). This leads to an unbiased estimator given that every \(h_{i}\) labels the sample from this part of space in exactly the same way.

The utility of this estimator is that by choosing an arbitrary representative \(h_{_{i}}\), we can estimate the loss of all hypotheses still in contention to precision \(O()\) on \(R_{i}^{c}\) with \((1/^{2})\) samples, removing the usual dependence of the VC-dimension. On the other hand, as the disagreement region shrinks, \(_{D_{G}}(x R_{i})\) shrinks as well, so while we will still need to invoke uniform convergence to get reliable loss estimates in \(R_{i}\), the precision to which we need to estimate losses in this part of space decreases with every iteration, and eventually the overall dependence on the VC-dimension is diminished. This later observation is the standard source of gains in DBAL .

After forming these loss estimates on each group, we construct unbiased loss estimates for the worst case over groups via

\[L_{;R_{i}}^{}(h):=_{g}L_{S;R_{i}}(h g).\]

These loss estimates inherit concentration properties from the two-part estimator above. We draw enough samples at each iteration \(i\) such that we essentially learn the multi-group problem to precision \(2^{(1/)-i}\).

We note that Algorithm 1 assumes access to the underlying group marginals measures \(_{D_{G}}\). This is common in the active learning literature . Probabilities of events in instance space can be estimated to arbitrary accuracy using only unlabeled data, so this assumption is not dangerous to our goal of lowering label complexities.

### Guarantees

Vitally, the scheme given in Algorithm 1 is consistent. It is a lemma of ours that the number of samples drawn at each iteration is sufficiently large that the true error of any \(h_{i+1}\) is no more than \(2^{(1/)-i}\). Thus, after \((1/)\) iterations, the ERM hypothesis on \(L^{}_{;R_{i}}()\) is then \(\)-optimal with high probability.

We can bound the label complexity of the algorithm using standard techniques from DBAL. A ubiquitous quantity in the analysis of disagreement-based schemes is that of the "disagreement coefficient" [9; 25]. The general idea is that the disagreement coefficient bounds the rate of decrease in \(r\) of the measure of the the disagreement region of a ball of radius \(r\) around \(h^{*}\) in the pseudo-metric \(_{g}(h,h^{}):=_{D_{g}}(h(x) h^{}(x))\). Precisely, we use the following definition of the disagreement coefficient in our analysis [10; 24]: given a group \(D_{g}\), the disagreement coefficient on \(g\) is

\[_{g}:=_{h}_{r^{} 2+}_{D_{g}}(x(B_{g}(h,r^{})))}{r^{}},\]

where \(B_{g}(h,r^{}):=\{h^{}:_{g}(h,h^{}) r ^{}\}\) is a ball of radius \(r^{}\) about \(h\) in pseudo-metric \(_{g}\). We further notate the maximum disagreement coefficient over the groups \(\) as \(_{}:=_{g}_{g}\).

The disagreement coefficient is trivially bounded above by \(1/\), but can be bounded independently of \(\) in many cases [10; 25]. For example, when \(\) is the class of linear separators in \(d\) dimensions and the underlying marginal distribution is uniform over the Euclidean unit sphere, the disagreement coefficient is \(()\).

**Theorem 1**.: _For all \(>0\), \((0,1)\), collections of groups \(\), and hypothesis classes \(\) with \(d<\), with probability \( 1-\), the output \(\) of Algorithm 1 satisfies_

\[L^{}_{}() L^{}_{}(h^{*})+,\]

_and its label complexity is bounded by_

\[G\;_{}^{2}}{^ {2}}+1d(1/)+(1/)(1/)+ }.\]

Here, the \(\) notation hides factors of \(((1/))\) and \((G)\); we leave all proofs for the Appendix. Theorem 1 tell us that Algorithm 1 enjoys the following upside over passive and collaborative learning approaches: the dependence on the standard interaction of the VC-dimension \(d\) and \(1/^{2}\) is removed, and replaced with \(Gd_{}^{2}^{2}(1/)^{2}/^{2}\), which in settings with small disagreement coefficients and low noise rates, will be significant for small \(\).

### Comparison to Lower Bounds in Collaborative Learning

We compare our label complexity guarantees to results in collaborative learning, where the learner has the power to ask for samples from specific group distributions, but not selectively label these samples. This is a strictly more demanding comparison than to pure passive settings, but a fair one, given that active learners have the option of executing any collaborative learning strategy. In collaborative learning, for finite hypothesis classes \(\), it is known that

\[(|)}{^{2}}+|,G)/)}{^{2}})\]

total labels over all groups are necessary . We consider comparing this lower bound to a simplified version of the label complexity guarantee in Theorem 1:

\[(dG_{}^{2}^{2}(1/)+}),\]

thus implicitly assuming \(\) is neglectably small, and making all comparisons up to factors logarithmic in \(G\), \(1/\) and \((1/)\). This former assumption is a standard assumption under which we may hope an agnostic active learner to succeed .

``` proceduregroup_realizable(\(,,\), active learner \(\), \(\{U_{g}()\}_{g=1}^{G},\{O_{g}()\}_{g=1}^{G}\)) for\(g[G]\)do \(_{g}(,/6,/2G,U_{g}( ),O_{g})\) \(S_{g}^{} 144/^{2}(2d(24/)+(8G/ ))\) samples from oracle \(U_{g}()\) \(_{g}\{(x,_{g}(x)):x S_{g}^{ }\}\) endfor return\(=_{h}_{g[G]}_{g}|}_{(x, )_{g}}1[h(x)]\) endprocedure ```

**Algorithm 2** Group Realizable Algorithm

Even the simplified upper bound does not admit the cleanest comparison this to lower bound, due to our excess factor of \((1/)\) in the second term. However, it does showcase that while we pay slightly more per group than necessary, under conditions amenable to active learning, we pay significantly less per dimension \(d\). Particularly for small \(\), one can see that's approximately sufficient that \(G<o(_{}^{2}((1/))^{2})^{-1})\) for the simplified upper bound to beat the lower bound.

For a more fine-grained comparison that in some sense underestimates the power of Algorithm 1, assume that the following condition governs the relationship of \(G\), \(d\), and \(\):

\[G(1/) d<(_{}^{2}^{2}^{2}(1/ ))^{-1}.\]

Then the simplified bound is smaller in order than the lower bound above.

## 6 Group Realizable Learning

A special case of the learning problem, where extreme active learning gains can be readily seen, comes when the hypothesis class \(\) achieves zero noise rate on each group \(D_{g}\). This setting has been considered in the passive "multi-group learning" literature . Formally speaking, in the group realizable setting, the following condition holds:

\[ g[G], h_{g}^{*}\ s.t.\ L_{}(h_{g}^{* } g)=0,\]

i.e. for all groups in the collection \(\), there is some hypothesis achieving 0 error on that group. Note that this differs from the fully realizable setting where there is some \(h^{*}\) with \(L_{}^{}(h^{*})=0\). While fully realizable implies group realizable, the converse is not true. Thus, group realizability represents an intermediate regime between the realizable setting and the full agnostic settings.

### Algorithm

In the group realizable case, it is possible to show a reduction of the problem of active learning over hypothesis classes with respect to a single distribution.

This can be accomplished as follows. For each \(D_{g}\), we call as a subroutine an active learner that is guaranteed to find an order \(\)-optimal hypothesis \(_{g}^{*}\) with high probability over it's queries. It then gathers new unlabeled samples from each \(D_{g}\), and instead of requesting labels from \(O_{g}()\), labels each unlabeled point with \(_{g}^{*}\). The final step is to do an empirical risk minimization on these artificially labeled samples with respect to the multi-group objective. See Algorithm 2 for a formal specification of the strategy.

### Guarantees

The strategy given in Algorithm 2 leads to a consistent active learning scheme, provided the active learners called as subroutines have standard guarantees that can be inherited.

Theorem 2 gives a guarantee to this end. The proof follows from an argument similar to one used in  - because the subroutine calls return hypotheses with near 0 error on each group, the artificially labeled training set used in the ERM step looks nearly identical to a counterfactual training set for the ERM step constructed by querying labels \(O_{g}(x)\) for each unlabeled \(x\). This is similar to the idea in . We present Theorem 2 assuming access to a classical, realizable active learner due to .

**Theorem 2**.: _Suppose Algorithm 2 is run with the active learner \(_{CAL}\) of . Then for all \(>0\), \((0,1)\), hypothesis classes \(\) with \(d<\), and collections of groups \(\) with the group realizability property under \(\), with probability \( 1-\), the output \(\) satisfies_

\[L_{}^{}() L_{}^{}(h^{*})+,\]

_and the number of labels requested is_

\[dG_{}(1/).\]

Thus, when disagreement coefficients across the collection of groups are bounded independently of \(\), the usual, passive dependence on \(1/^{2}\) is replaced by \((1/)\).

In the passive multi-group setting of , it has been shown that \(((||)/)\) samples are sufficient for group realizable learning, where we recall \(\) is a lower bound on the probability of getting a sample in each group .

## 7 Full Agnostic Approximation

### Inconsistency of the Reduction in the Full Agnostic Regime

Algorithm 2 admits clean analysis, and nicely harnesses the power of realizable active learners for a single distribution. One might wonder if a similar strategy might provide a consistent strategy in full agnostic regime. Unfortunately, the direct application of Algorithm 2 using agnostic learners does not yield a consistent active learning algorithm. In fact, consistency fails even when for each \(g[G]\), \(h_{g}^{*}\) is the Bayes optimal classifier on \(D_{g}\), and \(_{g}:=_{h}L_{}(h g)\) is small. This lack of consistency comes down to the fact that labeling with the Bayes optimal underestimates noise rates on each group, which in turn may bias the output of the ERM step.

### A \(3\)-Approximation Algorithm

Although the strategy of creating an artificially labeled training set with near-optimal hypotheses on each group fails outside of the group realizable case, it possesses a nice approximation property.

We give a guarantee to this end in Theorem 3. It states that if we call an active learner with agnostic guarantees on each group \(D_{g}\), and then use the outputs \(_{g}^{*}\) to artificially label a new batch of unlabeled data from each group, using ERM on this artificially labeled data gives at worst a \(2+\)-optimal hypothesis with high probability.

**Theorem 3**.: _Suppose Algorithm 2 is run with the agnostic active learner \(_{DMM}\) of . Then for all \(>0\), \((0,1)\), hypothesis classes \(\) with \(d<\), and collections of groups \(\), with probability \( 1-\), the output \(\) satisfies_

\[L_{}^{}() L_{}^{}(h^{*})+2 _{g[G]}_{g}+ 3 L_{}^{}(h^{*})+,\]

_and the number of labels requested is_

\[dG_{}^{2}(1/)+}{^{2}}.\]

The proof is very similar to that of Theorem 2, but notes in addition that \(_{g}^{*}\) mislabels on a roughly \(_{g}\)-fraction of the unlabeled samples from each group \(G\). This allows us to upper bound the distortion of the ERM step.

## 8 Conclusion

In this work, we have taken a first look at active multi-group learning. Though the design of general agnostic strategies in this setting is quite challenging, an interesting future direction may be the search for strategies that work in more specific cases, for example extending our work in the group realizable setting. In particular, the search for algorithms with small label complexities under specific low-noise conditions, such as Tsybakov noise on each \(D_{g}\), may prove fruitful .