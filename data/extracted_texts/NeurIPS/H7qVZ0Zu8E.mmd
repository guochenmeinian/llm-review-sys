# Achieving Linear Convergence with Parameter-Free Algorithms in Decentralized Optimization

Ilya Kuruzov

Innopolis University

kuruzov.ia@phystech.edu.

&Gesualdo Scutari

Purdue University

gscutari@purdue.edu.

&Alexander Gasnikov

Innopolis University

gasnikov@yandex.ru

###### Abstract

This paper addresses the minimization of the sum of strongly convex, smooth functions over a network of agents without a centralized server. Existing decentralized algorithms require knowledge of functions and network parameters, such as the Lipschitz constant of the global gradient and/or network connectivity, for hyperparameter tuning. Agents usually cannot access this information, leading to conservative selections and slow convergence or divergence. This paper introduces a decentralized algorithm that eliminates the need for specific parameter tuning. Our approach employs an operator splitting technique with a novel variable metric, enabling a local backtracking line-search to adaptively select the stepsize without global information or extensive communications. This results in favorable convergence guarantees and dependence on optimization and network parameters compared to existing nonadaptive methods. Notably, our method is the first _adaptive_ decentralized algorithm that achieves linear convergence for strongly convex, smooth objectives. Preliminary numerical experiments support our theoretical findings, demonstrating superior performance in convergence speed and scalability.

## 1 Introduction

We study optimization across a network of \(m>1\) agents, modeled as an undirected, static graph, possibly with no centralized server. The agents cooperatively solve the following problem:

\[_{x^{n}}\;_{i=1}^{m}f_{i}(x),\] (P)

where \(f_{i}:^{n}\) is the loss function of agent \(i\), assumed to be strongly convex and smooth (i.e., with gradient being Lipschitz continuous), and accessible only to agent \(i\).

This formulation applies to various fields, particularly emphasizing decentralized machine learning problems where datasets are produced and collected at different locations. Traditionally, statistical and computational methods in this domain have relied on a centralized paradigm, aggregating computational resources at a single, central location. However, this approach is increasingly unsuitable for modern applications with many machines, leading to server congestion, inefficient communication, and high energy consumption . This has motivated the surge of learning algorithms that target _decentralized_ networks with _no servers_, a.k.a. _mesh_ networks, which is the setting of this paper.

Decentralized convex optimization has a long history, with numerous algorithms applicable to Problem (P); recent tutorials include . **Lack of adaptivity:** These methods share the hurdle of relying sensibly on the tuning of hyperparameters, such as the stepsize (a.k.a. learning rate), for both theoretical and practical convergence. Existing theories ensure convergence under generally conservative bounds on the stepsize, which depend on parameters like the Lipschitz constant of the global gradient, the spectral gap of the graph adjacency matrix, or other topological properties. Acquiring such information is challenging in practice, due to physical or privacy limitations and computational/communication constraints. This often leads to manual tuning, which is not only tedious but also results in less predictable, problem-dependent, and non-reproducible performance.

**Parameter-free centralized methods:** On the the hand, significant progress has been made in the _centralized_ setting to automate the selection of the stepsize across various optimization and learning problem classes. **(i)** Traditional approaches in optimization-such as line-search methods , Barzilai-Borwein's stepsize , and Polyak's stepsize -have been supplemented by recent adaptive stepsize rules based on estimates of local curvature  and subsequent techniques . **(ii)** In the ML community, adaptive gradient methods such as AdaGrad , Adam , AMSGrad , NSGD-M , and variants  have gained significant attention for training large-scale learning models. These methods apply to stochastic, nonconvex optimization problems. **(iii)** Further advancements extend adaptivity to stochastic/online convex optimization problems, e.g., .

**Distributed adaptive methods:** While variant of these centralized algorithms have been adapted to federated architectures (server-client systems), e.g., in , their application to mesh networks is _not feasible_. In federated learning, a central server aggregates local model updates, a process integral to its hierarchical structure. However, mesh networks, which lack a centralized coordinating node, do not support such a direct aggregation of large-scale vectors. Recent attempts to implement some form of stepsize adaptivity for _stochastic (non)convex/online_ optimization problems over mesh networks are . These methods generally achieve adaptivity by properly normalizing agents' gradients using past information. However, with the exception of , they rely on the strong assumption that the (population) losses are _globally_ Lipschitz continuous (i.e., their gradients are bounded). In fact, Lipschitz continuity in convex optimization readily unlocks parameter-free convergence by using stepsize tuning of \((1/)\) (here, \(k\) is the iteration index). Moreover,  still require knowledge of some optimization parameters for the stepsize tuning, to guarantee convergence.

Attempts to introduce adaptivity in decentralized optimization for solving (P) have been explored in . These methods bring the Barzilai-Borwein (BB)'s stepsize strategy into gradient tracking algorithms . **(i)** However, convergence of these algorithms _is not guaranteed_ under the proposed BB strategy, unless the stepsizes _remain uniformly bounded from below and above_ throughout the algorithm's trajectory-a condition the BB rule _does not inherently satisfy_ in decentralized settings. Furthermore, these bounds for the stepsizes are typically unknown to the agents, as they depend on the strong convexity and smoothness constants of all agents' losses. Even with such knowledge, enforcing these conservative bounds contradicts the principle of adaptivity by potentially negating the advantages of a variable stepsize strategy that adapts based on local loss curvature, producing stepsize values significantly larger than theoretical thresholds used in nonadaptive methods. **(ii)** Additionally, to ensure contraction of the iterates, studies such as  require multiple rounds of communications per iteration (gradient evaluation)-this demands the knowledge of network and optimization parameters at the agents' sides, making practical implementation unfeasible. **(iii)** None of these studies offer expressions of convergent rates for the explored algorithms, leaving it unclear whether the BB stepsize rule can provably outperform nonadaptive methods. **(iv)** Lastly, the methods discussed employ the traditional BB rule, which is only proven in centralized settings to produce convergence methods when minimizing _quadratic_ losses. Simulations in  are in fact performed only on quadratic functions.

**Open questions and challenges:** To our knowledge, no deterministic, parameter-free decentralized algorithms exist that solve Problem (P) over mesh networks, particularly achieving linear convergence when agents' functions are strongly convex and smooth. The current decentralized adaptive stochastic methods  discussed earlier do not adequately bridge this gap. Tailored for stochastic environments, these methods merely ensure that cumulative consensus errors along the iterations remain bounded, _not necessarily decreasing_. This typically involves either diminishing stepsizes or adjustments based on the final horizon to manage the bias-variance trade-off. These strategies fall short in deterministic scenarios like Problem (P), failing to ensure convergence to _exact_ solutions, and achieve faster \((1/k)\) convergence rates in convex cases or _linear_ rates in strongly convex scenarios.

**Major contributions:** This paper addresses this open problem. Our contributions are the following:

_1. A new parameter-free decentralized algorithm:_ We propose a decentralized algorithm that eliminates the need for specific tuning of the stepsize. Our approach leverages a Forward-Backward operator splitting technique combined with a novel variable metric, enabling a local backtracking line-search procedure to adaptively select the stepsize at each iteration without requiring global information on optimization and network parameters or extensive communications. We are not aware of any other provable decentralized line-search methods over mesh networks.

Designing decentralized line-search procedures that are well-defined (terminating in a finite number of steps), locally implementable, and ensure algorithm convergence through satisfactory descent on an appropriate merit function presents significant challenges. A major issue is that line-search procedures merely based on the local curvature of agents' functions often fail to ensure convergence, producing _excessively large_, heterogeneous stepsizes that, e.g., poorly connected networks cannot support. This necessitates the identification of line-search _directions_ and _surrogate functions_ that encapsulate _both_ optimization and network influences, aspects that have not yet formalized. Our design guidelines (cf., Sec. 3) are of independent interest; hopefully they will provide valuable insights for the development of other decentralized adaptive schemes, such as those based on alternative operator splittings.

_2. Convergence guarantees:_ We have established linear convergence for the proposed decentralized adaptive method. Our analysis identifies critical quantities that capture the interplay between optimization conditions and network topology, directly influencing the convergence rates. Specifically: (a) In "well-connected" networks, the convergence rate exhibits a _separation property_: the overall rate is dictated by the slower of either the centralized gradient algorithm solving the same problem or a consensus algorithm run on the same mesh network. (b) Conversely, in "poorly" connected networks, the separation property vanishes, and the convergence rates are adversely affected by network degradation terms, still exhibiting a linear dependence on the condition number of the optimization loss. **(ii)** Unlike many existing distributed optimization frameworks, the optimization parameters in our rate expressions-such as smoothness and strong convexity constants-are localized to the _convex hull_ of the traveled iterates. This localization arises from our adaptive stepsize strategy, which employs a line-search procedure tailored to local geometries, yielding more favorable dependencies on optimization parameters and thus enhanced convergence guarantees. **(iii)** Numerical experiments demonstrate superior performance of the proposed adaptive algorithm in convergence speed and scalability compared to existing non-adaptive methods.

### Notation and paper organization

Capital letters denote matrices. Bold capital letters represent matrices where each row is an agent's variable, e.g., \(=[x_{1},,x_{m}]^{}\). For such matrices, the \(i\)-th row is denoted by the corresponding lowercase letter with the subscript \(i\); e.g., for \(\), we write \(x_{i}\) (as column vector). Let \(^{m}\), \(^{m}_{+}\), and \(^{m}_{++}\) be the set of \(m m\) (real) symmetric, symmetric positive semidefinite, and symmetric positive definite matrices, respectively; \(A^{}\) denotes the Moore-Penrose pseudoinverse of \(A\). The eigenvalues of \(W^{m}\) are ordered in nonincreasing order, and denoted by \(_{1}(W)_{m}(W)\). For two operators \(A\) and \(B\) of appropriate size, \((A B)()\) stands for \(A(B())\). We denote: \([m]=\{1,,m\}\), for any integer \(m 1\); \([x]_{+}\):\(=(x,0)\), \(x\); \(1_{m}^{m}\) is the vector of all ones; \(I_{m}\) (resp. \(0_{m}\)) is the \(m m\) identity (resp. the \(m m\) zero) matrix; the information on the dimension is omitted when not necessary; \((A)\) (resp. \((A)\)) is the nullspace (resp. range space) of the matrix \(A\). Let \( X,Y:=(X^{}Y)\), for any \(X\) and \(Y\) of suitable size (\(()\)) is the trace operator; and \(\|X\|_{M}:=\), for any symmetric, positive definite \(M\) and \(X\) of suitable dimensions. We still use \(\|X\|_{M}\) when \(M\) is positive semidefinite and \(X(M)\).

## 2 Problem Setup

We investigate Problem (P) over a network of \([m]\) agents, modeled as an undirected, static, connected graph \(=([m],)\), where \((i,j)\) if there is communication link (edge) between \(i\) and \(j\). For each agent \(i\), we define by \(_{i}:=\{j:\,|\,(i,j),\,\,\,i[m]\}\{i\}\) the set of immediate neighbors of agent \(i\) (including agent \(i\) itself).

**Assumption 1**.: **(i)** _Each function \(f_{i}\) in (P) is \(L\)-smooth and \(\)-strong convex on \(^{n}\), for some \(L(0,)\) and \((0,)\); and_ **(ii)** _each agent \(i\) has access only to its own function \(f_{i}\)._

The following matrices are commonly utilized in the design of gossip-based algorithms.

**Definition 2** (Gossip matrices).: _Let \(_{}\) denote the set of matrices \(=[_{ij}]_{i,j=1}^{m}\) that satisfy the following properties:_ **(i)** _(compliance with \(\)) \(_{ij}>0\) if \((i,j)\); otherwise \(_{ij}=0\). Furthermore, \(_{ii}>0\), for all \(i[m]\); and_ **(ii)** _(doubly stochastic) \(^{m}\) and \(1_{m}=1_{m}\)._

These matrices are standard in the literature on decentralized optimization algorithms, and several instances have been employed in practice; see [34; 41; 33] for some representative examples. Noticethat for any \(_{}\) (assuming \(\) connected) it hold: **(i)** (null space condition) \((I_{m}-W)=(1_{m})\); and **(ii)** (eigen-spectrum distribution) \(2I+I 0_{m}\).

## 3 Algorithm Design

Our approach to solving Problem (P) involves a saddle-point reformulation tackled via a variable metric operator splitting, implementable across the graph \(\). The innovative aspect of the proposed method lies in the selection of the variable metric that, coupled with a Forward Backward Splitting (FBS), enable adaptive stepsize selections through a decentralized line-search procedures.

Introducing local copies \(x_{i}^{d}\) of the shared variable \(x\) (the \(i\)-th one is controlled by agent \(i\)), and the stack matrix \(:=[x_{1},,x_{m}]^{}^{m n}\), let us consider the following auxiliary problem:

\[_{^{m n}}[F(K):=_{i=1}^{m }f_{i}([K]_{i})],\ \ \ \,=0.\] (P \[{}^{}\] )

Here, \(\) and \(K\) are \(m m\) matrices that meet the following criteria: **(c1)**\(^{m}\) and \(()=(1_{m})\); **(c2)**\(K^{m}_{++}\) and \((I-K)=(1_{m})\); and **(c3)**\(\) and \(K\) commute. Conditions (c1) and (c2) ensure that (P) and (P\({}^{}\)) are equivalent. Specifically, any solution \(^{}\) of (P\({}^{}\)) has the form of \(^{}=1_{m}(x^{})^{}\), where \(x^{}\) solves (P), and vice versa. While not essential, condition (c3) is postulated to simplify the algorithm derivation.

Primal-dual optimality for (P\({}^{}\)) reads, with \(\) being the dual-variable associated with the constraints,

\[(A+B)(^{}\\ ^{})=0, A:= K F K&0\\ 0&0\ \ \ B:=0&\\ -&0.\]

Given \(^{k}\), \(^{k}\) at iteration \(k\), the update \(^{k+1}\), \(^{k+1}\) via FBS with metric \(C^{2m}_{++}\) reads 

\[(C+B)(^{k+1}\\ ^{k+1})=(C-A)(^{k }\\ ^{k}).\] (1)

Monotone operator theory  ensures convergence of (1) under the following conditions:

**(c4)**\(B\) is a monotone operator, \(C^{2m}_{++}\), and **(c5)**\(I-C^{-1/2}AC^{-1/2}\) is an averaged operator.

Condition (c4) is satisfied by construction; (c5) can be enforced through a suitable selection of \(C^{2m}_{++}\) while leveraging the co-coercivity of \(A\) (implied by Assumption 1). Denoting by \(>0\) the stepsize employed in the algorithm, we seek for \(C\) with the following structure:

\[C=^{-1}C_{1}&0\\ 0&C_{2}, C_{1},C_{2}^{m}_{++}\]

to be determined. We proceed solving (1). Taking \((C+B)^{-1}\), we have

\[&^{k+1}=(I)(^{k})- ((II)(^{k})+(III)(^{k}) ),\\ &^{k+1}=(IV)(^{k})+(V)(^{k }),\] (2)

where

\[(I)&:=\,I_{m}- C_{1}^{-1}\, \,(C_{2}+\,C_{1}^{-1}\,)^{-1}\, ,\\ (II)&:=(I)\,C_{1}^{-1}\,K\, F K,\\ (III)&:=\,C_{1}^{-1}\,\,(C_{2}+ \,C_{1}^{-1}\,)^{-1}\,C_{2},\\ (IV)&:=(C_{2}+\,C_{1}^{-1}\, )^{-1}\,C_{2},\\ (V)&:=(C_{2}+\,C_{1}^{-1}\, )^{-1}(I- C_{1}^{-1}K\, F K). \] (3)

In addition to satisfying (c5), \(C_{1},C_{2}^{m}_{++}\) must be strategically chosen to facilitate the design of a decentralized line-search procedure for \(\). We propose the following guiding principles:

**(c6)** The range of admissible stepsize values \(\) ensuring convergence-hence satisfying (c5)-should be independent of the network parameters; and 

[MISSING_PAGE_FAIL:5]

specified in (4), is critical to obtain a valid line-search procedure that is also implementable across the network. For instance, popular decentralized algorithms such as EXTRA  and NIDS  can be interpreted as FBS with suitable metrics associated with the primal-dual reformulation of (P) as (P\({}^{}\)) but with \(K=I_{m}\). However, these schemes do not facilitate any suitable line-search, as no stepsize-independent descent direction can be identified in their updates. Hopefully, our approach will provide principled guidelines for the design of other parameter-free decentralized algorithms, stemming from alternative decentralized formulations of (P) and their corresponding operator splittings.

**On the backtracking:** The following Lemma shows that the line-search procedure in Algorithm 2 is well-defined, as long as the function \(f\) therein is locally smooth.

**Lemma 3**.: _Let \(f\) in Algorithm 2 be any \(L_{f}\)-smooth and \(_{f}\)-strongly convex function on the segment \([x,x+ d]\), where \(L_{f}(0,)\), \(_{f}[0,)\), and \([1,)\). The following hold for Algorithm 2:_

_(i) The returned \(^{+}\) satisfies_

\[(,})^{+} (,}).\] (8)

_Therefore, the backtracking procedure terminates in at most \((1,_{2}}{})\)\(t\)-steps;_

_(ii) For any \(^{+}\) returned by Algorithm 2, any \(^{+}(0,^{+}]\) also satisfies the backtracking condition._

Notice that the last statement of the lemma guarantees that the each \(^{k}=_{i[m]}_{i}^{k}\) satisfies the descent property (6) on the global loss \(F^{k}\), as each \(_{i}^{k}\) meets the local condition (7).

The sequence \(\{^{k}\}_{k=1}^{}\) used in line 1 of the backtracking algorithm, with each \(^{k} 1\), is introduced to favor nonmonotone, and thus potentially larger, stepsize values between two consecutive line search calls. Any sequence satisfying \(^{k} 1\) and \(_{k=1}^{}^{k}=\), is advisable. In our experiments, we found the following rule quite effective: \(^{k}=((k+_{1})/(k+1))^{_{2}}\), for some \(_{2}>0\) and \(_{1} 1\). One can also opt for \(^{k}=1\), for all \(k\), thus eliminating this extra parameter, if simplicity is desired.

**On the min-consensus:** Step (S.3) involves a min-consensus across the network to establish a common stepsize, \(^{k}=_{i[m]}_{i}^{k}\), among the agents. This procedure is easily implemented in federated systems, where a server node facilitates information exchange between clients. Interestingly, this min-consensus protocol is also well-suited to current wireless mesh network technologies. Modern networks support multi-interface communications, including WiFi and LoRa (Low-Range) [17; 2; 16]. WiFi allows high-speed, short-range communications, supporting a mesh topology where nodes transmit large data volumes to immediate neighbors. Conversely, LoRa facilitates long-range but low-rate communications, ideal for communication flooding that reaches all network nodes in a single hop but transmits minimal information. Therefore, in multi-interface networks, the proposed algorithm operates by transmitting vector variables in Steps (S.1) via WiFi, while LoRa is used for the min-consensus in Step (S.3). Furthermore, the values \(_{i}^{k}\)s can be quantized to their nearest lower values using a few bits before transmission. Based on Lemma 3(ii), this quantization ensures that the descent condition (6) is still met with the resultant min quantized stepsize. This approach renders the extra communication cost for implementing the global min-consensus step negligible.

For networks where LoRa technology cannot be used, Sec. 5 proposes a variant of Algorithm 1 wherein the global min-consensus step (S.3) is replaced by a local min-consensus procedure.

## 4 Convergence Results

We begin introducing a quantity of interest that helps identifying different operational regimes of the proposed algorithm. Let \((^{},^{})\) be a fixed point of Algorithm 1 (whose existence is ensured by Assumption 1), and let \(\{(^{k},^{k})\}\) be the iterates generated by Algorithm 1. Define

\[r^{k}=)^{2}}\|^{k}\|_{c(I- {W})}^{2}+\|c(I-)( F(^{k+1/2})+^{k})\|_{M}^{2}}}{(}\|^{k}- ^{}\|,\|^{k}-^{}\|_{M})},M:=c^{-1}(I-)^{}-I.\] (9)

The following comments are in order. **(i)** Both \(^{k}\) and \(^{}\) lie in the \((I-)=(I-W)\), for all \(k\), and \(M\) is positive defined on this span. Consequently, \(\|^{k}-^{}\|_{M}>0\) for all \(^{k}^{}\), and \(\|^{k}-^{}\|_{M}=0\) if and only if \(^{k}=^{}\). **(ii)** Under Assumption 1, \(^{}=1(x^{})^{}\), where \(x^{}\) is the solution of (P). **(iii)** The quantity \(r^{k}\) reflects the algorithm's convergence progress through the evolution of the dual variables and consensus error. Rewriting the update of the dual variables as \(^{k+1}=^{k}+}(I-)^{k}-c(I-)( F(^{k+1/2})+^{k})\), we observe that small values of \(\|}(I-)^{k}-c(I-) ( F(^{k+1/2})+^{k})\|\) compared to \(\|^{k}-^{}\|\) and \(\|^{k}-^{}\|\)-hence small \(r^{k}\) values-indicate slow convergence improvements (see Lemma 8 in the appendix).

We remark that \(r^{k}\) need not be known by the agents; it is instrumental only for the analysis and posterior assessment of algorithm performance.

Linear convergence is established below via contraction of the following merit function

\[V^{k}:=\|^{k}-^{}\|^{2}+(^{k-1})^{2 }\|^{k}-^{}\|_{M}^{2}.\] (10)

**Theorem 4**.: _Given Problem (P) under Assumption 1, let \(\{(^{k},^{k})\}\) be the iterates generated by Algorithm 1. Then, the following holds_

\[V^{k+1}(}{^{k-1}},1)^{2}(1- (_{1}^{k},(r^{k})^{2}))V^{k},_{1}^{k}:=^{k}}{2}(1-c(1-_{m}( )))^{2}<1.\] (11)

_If \(r^{k}</4\), then_

\[V^{k+2}(}{^{k}},1)^{2}( }{^{k-1}},1)^{2}(1-_{2}^{k})V^{k},\] (12)

_where_

\[_{2}^{k}:=()))^{2}}{128(^{k})^{ 2}(1,_{}(M))}(^{k+1}^{k+1},^{k}^{k},^{k}})<1.\]_Here \(^{k}\) (resp. \(^{k+1}\)) and \(L^{k}\) are the strong convexity and smoothness constants of (each) \(f_{i}\) along the segment \([x_{i}^{k+1/2},x^{}]\) (resp. \([x_{i}^{k+1+1/2},x^{}]\)), respectively._

The theorem establishes linear convergence of Algorithm 1. As \((1,(^{k}/^{k-1})^{2})\) is bounded away from zero and uniformly upper bounded (with value depending on the sequence \(\{^{k}\}\))-see Lemma 3-the convergence rate is predominantly determined by \(\{_{1}^{k}\}\), \(\{_{2}^{k}\}\), and \(\{r^{k}\}\). Notice that, in the setting of the theorem, each \(_{1}^{k},_{2}^{k}[0,1)\). Intriguingly, the algorithm exhibits different operational regimes based on the range of values \(r^{k}\) takes along the traveled trajectory. At the high level, if \(r^{k}\) remains "large", faster convergence can be guaranteed, as certified by (11); otherwise \(V^{k}\) decreases every two consecutive iterations (see (12)), yielding to a slower convergence. The number of iterations required to reach a desired termination accuracy is given next.

**Corollary 4.1**.: _Instate the setting of Theorem 4, with now \(\{^{k}\}\) being chosen such that \(^{k}((k+_{1})/(k+1))^{_{2}}\), for all \(k\) and some \(_{1} 1,_{2}>0\). Then_

\[\|^{k+1}-^{}\|^{2}+}\| ^{k+1}-^{}\|_{M}^{2},\]

_for all \(k N_{}\), where \(N_{}\) is given as follows:_

\[r^{k} r_{1}:=} (,(M)}}),\ \ k,\] \[N_{}=(( ()},( )))^{2}})(V^{0}/));\] (13) \[\] \[N_{}=(()))^{2}c(1-_{2}())}(V^{0}/ )).\] (14)

_Here \(\) is the condition number of each \(f_{i}\) restricted to the convex hull of \(\{x^{},\{x_{i}^{k},x_{i}^{k+1/2}\}_{k=0}^{N_{}}\}\), and \(\) hides the dependence on \(_{1}\) and \(_{2}\)._

Corollary 4.1 identifies the following two different operational regimes of the algorithm, resulting in difference performance based upon the network connectivity and optimization condition number.

**(1) Strong connectivity regime:** when \(r^{k} r_{1}\), for all \(k\), a fact that numerically has been observed for'relatively good' network connectivity, the convergence rate exhibits a separation in the dependence on the network and optimization parameters. Since \(1-c(1-_{m}())>1-2c\), it follows that, when \(c(1-_{2}())(1-2c)/\), \(N_{}\) reduces to \(()\) (omitting the dependence on \(\)), which matches the complexity of the centralized gradient algorithm. This suggests scenarios where the optimization problem is harder than a consensus problem over the same network, resulting in the bottleneck between the two. Conversely, when the condition number \(\) is large relative to the network connectivity \(1-_{2}()\), the rate is determined by that of the consensus algorithm running on the same network, that is, \(((1-_{2}())^{-1})\). The above rate separation property mirrors that of certain _nonadaptive_ primal-dual decentralized schemes including NEXT , AugDGM , Exact Diffusion  (with rate expression as improved in ), NIDS , and ABC .

**(2) Worst-case regime:** This regime reflects the algorithm's worst-case performance, typically registered in "weakly" connected networks: the convergence rate reads \((/(1-_{2}()))\), where optimization and network parameters are now mixed. This rate aligns with those of _nonadaptive_ decentralized gradient-tracking schemes, such as DGing , SONATA  (subject to sufficiently small network connectivity), and .

In summary, the convergence rate of Algorithm 1 resembles in the form that of existing nonadaptive decentralized methods, but offers more favorable dependence on the condition number than that typically found in those algorithms. Specifically, the condition number in (13 ) and (14 ) is the _local_ condition number, defined on the convex hull of the trajectory, which is generally much smaller than the _global_ condition number governing decentralized algorithms in the literature. This demonstrates the algorithm's capability to adapt to the local geometry of the optimization problem.

From Global to Local Min-Consensus

This section extends Algorithm 1 to settings where the global min-consensus procedure in (S.3) is not implementable. For these cases, we propose to replace such a step with a _local_ min-consensus procedure. The new algorithm is formally described in Algorithm 3 and briefly commented next.

In step (S.3), each agent now computes its stepsize taking the minimum values among those of their immediate neighbors only (including itself). This produces possibly different stepsizes \(_{i}^{k}\) for each agent, collected in the diagonal matrix \(^{k}=(_{1}^{k}_{m}^{k})\). Because of that, in order to still guarantee \(^{k}(I-)\)-a key property for the convergence of the algorithm-we slightly modified the updates of the dual variable in (S.4), compared with the same step in Algorithm 1. Specifically, the updating direction of the dual variable as in Algorithm 1, \((^{k})^{-1}(^{k}-^{k+1/2}-^{k} F(^{k+1/2}))\), is replaced in Algorithm 3 by \((^{k})^{-1}^{k}-^{k+1/2}_{}- F(^{k+1/2})\), where \(^{k+1/2}_{}=W(^{k})^{-1}^{k}\). Notice that, if all the stepsizes are equal, the update (S.4) in Algorithm 3 reduced to that in Algorithm 1. Finally, we point out that the computation of \(^{k+1/2}_{}\) requires only the extra communication of neighboring stepsizes (thus scalar) values, which has a negligible cost.

``` Data: (i) Initialization \(^{0}^{m n}\) and \(^{0}=0\); (ii) initial value \(_{-1}(0,)\); (iii) Backtracking parameters \((0,1]\); (iv) nondecreasing sequence \(\{^{k}\}_{k}[1,)\) (v) Gossip matrix \(W:=(1-c)I_{m}+c\), with \(_{}\), and \(c(0,1/2]\). Set the iteration index \(k=0\).
1: (S.1) Communication step: Agents updates primal and dual variables via gossiping: \[^{k+1/2}=W\,^{k}^{k+1/2}=W \,(^{k}+ F(^{k+1/2}));\]
2: (S.2) Decentralized line-search: Each agent updates \(_{i}^{k}\) according to \[_{i}^{k}=(^{k-1},f_{i},x_{i} ^{k+1/2},d_{i}^{k+1/2},^{k},);\]
3: (S.3) Local min-consensus: \[_{i}^{k}=_{j_{i}}_{j}^{k},  i[m];\] Define \(^{k}=(_{1}^{k}_{m}^{k})\);
4: (S.4) Local updates of the primal and dual variables: \[^{k+1} =^{k+1/2}-^{k}^{k+1/2}, ^{k+1/2}_{}=W(^{k})^{-1}^{k},\] \[^{k+1} =^{k+1/2}+(^{k})^{-1}^{k}-^{ k+1/2}_{}- F(^{k+1/2}).\]
5: (S.5) If a termination criterion is not met, \(k k+1\) and go to step (S.1). ```

**Algorithm 3**

Convergence of Algorithm 3 is established in the following theorem.

**Theorem 5**.: _Instate assumptions in Theorem 4, applied now to Algorithm 3, with \(\{^{k}\}\) being chosen such that \(^{k}((k+_{1})/(k+1))^{_{2}}\), for all \(k\) and some \(_{1} 1,_{2}>0\). Further, suppose there exists a constant \(R>0\) such that \(V^{k} R\), for all \(k\). Then_

\[_{j[1,N+1]}\|^{j}-^{}\|^{2}+ {4L^{2}}\|^{j}-^{}\|_{M}^{2},\]

_with_

\[N=(( d_{}+ N_{}, _{0}L)(N_{},d_{})),\]

_where \(N_{}\) is defined as in Corollary 4.1 (replacing therein \(V_{0}\) with \(R\))._

Interestingly, Theorem 5 states that the degradation of the convergence rate when a local-min consensus is used instead of the global one is mild. Specifically, up to log factors, the total number of iterations to \(\)-optimality depends on \(d_{}\) (the diameter of the graph \(\)), if \(d_{}>N_{}\). This result is somehow expected, as min-consensus requires a number of iterations proportional to \(d_{}\) to propagate through the entire network. However, monotonicity in the decrease of the primal and dual errors can no longer be guaranteed when min-consensus is employed.

Numerical Results

This section presents some preliminary numerical results. We compare Algorithm 1 and Algorithm 3 with EXTRA  and NIDS  on a ridge regression problem using synthetic data. Further experiments are presented in the appendix. All experiments are run on Acer Swift 5 SF514-5STA-56B6, with processor Intel(R) Core(TM) i5-8250U @ CPU 1.60GHz, 1800 MHz.

**Ridge regression:** It is an instance of (P), with \(f_{i}(x)=\|A_{i}x_{i}-b_{i}\|^{2}+\|x_{i}\|_{2}^{2}\), where we set \(A_{i}^{20 300},b_{i}^{20},\) and \(=0.1\).The elements of \(A_{i},b_{i}\) are independently sampled from the standard normal distribution; the regularization is set to \(=0.1\). We simulated a network of \(m=20\) agents, and the following three different graph topologies, reflecting varying connectivity levels: **(i)**\(_{1}\): Graph-path with \(m-1\) edges and diameter \(m-1\), i.e., \(=\{[m],\{(i,i+1)\}_{i=1}^{m-1}\}\); **(ii)**\(_{2}\): Erdos-Renyi graph, sparsely connected; and **(iii)**\(_{3}\): Erdos-Renyi graph, well-connected.

Results are summarized in Fig. 1 and Fig. 2. For EXTRA and NIDS we use a grid-search tuning, chosen to achieve the best practical performance. Algorithm 1 and Algorithm 3 are simulated under the following choice of the line-search parameters satisfying Corollary 4.1: \(^{k}=(k+2)/(k+1)\), \(=1\). For all the algorithms we used the Metropolis-Hastings weight matrix \(W_{}\).

The figures demonstrate that the proposed method consistently outperforms both EXTRA and NIDS, even when using the local min-consensus strategy, with a significant gap emerging as the condition number increases. This performance is particularly noteworthy given that Algorithm 1 and 3 operate effectively without requiring tedious tuning or global knowledge of the optimization and network parameters. Notably, Algorithms 1 and 3 exhibit different convergence behaviors: as predicted by Theorem 5, local min-consensus results in nonmonotonic error dynamics \(\|^{k}-^{}\|^{2}\). However, the practical convergence speed remains largely unaffected compared to the global min-consensus.