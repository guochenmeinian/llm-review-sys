# Puca: Patch-Unshuffle and Channel Attention for Enhanced Self-Supervised Image Denoising

Hyemi Jang\({}^{1}\), Junsung Park\({}^{1}\), Dahuin Jung\({}^{1}\), Jaihyun Lew\({}^{2}\), Ho Bae\({}^{3,}\), Sungroh Yoon\({}^{1,2,}\)

\({}^{1}\)Department of Electrical and Computer Engineering, Seoul National University

\({}^{2}\)Interdisciplinary Program in Artificial Intelligence, Seoul National University

\({}^{3}\)Department of Cyber Security, Ewha Womans University

wkdal9512@snu.ac.kr jerryray@snu.ac.kr annajung0625@snu.ac.kr fudojhl@snu.ac.kr hobae@ewa.ac.kr sryoon@snu.ac.kr

Corresponding Authors

###### Abstract

Although supervised image denoising networks have shown remarkable performance on synthesized noisy images, they often fail in practice due to the difference between real and synthesized noise. Since clean-noisy image pairs from the real world are extremely costly to gather, self-supervised learning, which utilizes noisy input itself as a target, has been studied. To prevent a self-supervised denoising model from learning identical mapping, each output pixel should not be influenced by its corresponding input pixel; This requirement is known as \(\)-invariance. Blind-spot networks (BSNs) have been a prevalent choice to ensure \(\)-invariance in self-supervised image denoising. However, constructing variations of BSNs by injecting additional operations such as downsampling can expose blinded information, thereby violating \(\)-invariance. Consequently, convolutions designed specifically for BSNs have been allowed only, limiting architectural flexibility. To overcome this limitation, we propose PUCA, a novel \(\)-invariant U-Net architecture, for self-supervised denoising. PUCA leverages patch-unshuffle/shuffle to dramatically expand receptive fields while maintaining \(\)-invariance and dilated attention blocks (DABs) for global context incorporation. Experimental results demonstrate that PUCA achieves state-of-the-art performance, outperforming existing methods in self-supervised image denoising.

## 1 Introduction

Figure 1: **Visual comparison with other denoising methods on the SIDD validation dataset .** DnCNN was trained with real clean-noisy pairs of SIDD. AP-BSN  and PUCA were trained in a self-supervised manner solely on noisy images.

Image denoising is a traditional task in computer vision, aiming to recover a clean image from a noisy one. With the advent of convolutional neural networks (CNNs) , deep learning-based methods have dominated the field. [23; 24; 46; 30; 47] These methods train a denoiser in a supervised manner using synthesized clean-noisy image pairs. However, denoising models trained on synthesized image pairs have limitations when dealing with real noise because of the domain gap between synthetic and real noise . To overcome the limitations, several researchers [1; 5] have collected real-world clean-noisy image pairs in a controlled environment. However, this process requires a lot of manual effort and post-processing, and it is challenging to collect enough data, resulting in limited generalization ability. Therefore, self-supervised denoising methods have been proposed to train a denoising model solely relying on noisy images.

In self-supervised learning, where the model is trained using an identical image as input and target, it is essential to satisfy \(\)-invariance  to prevent the model from learning an identity mapping. \(\)-invariance refers to eliminating the influence of each pixel on the corresponding output pixel. Blind-spot networks (BSN), which basically meet the \(\)-invariance requirement, have been introduced to effectively denoise noisy inputs in a self-supervised manner [18; 36; 21]. BSNs [36; 21] achieve the requirement by incorporating centrally masked convolution, where the central pixel of the kernel has a zero value, and dilated convolutions. BSNs can be constructed with two choices of layers only, centrally masked convolutions and dilated convolutions, and cannot utilize varying operations such as downsampling. This constraint arises from the necessity to maintain \(\)-invariance. Consequently, the previously proposed architectures have been restricted due to the harsh requirement. In contrast, supervised denoising models enjoy more flexibility in terms of network structures since real clean-noisy image pairs are provided, alleviating the need for \(\)-invariance. This flexibility enabled the exploration of diverse architectures, and recently, the encoder-decoder based U-Net architectures [2; 8; 19; 33; 41; 43; 44], which preserve hierarchical multi-scale representations, have become prevalent.

As highlighted by the success of supervised denoising models, aggregating spatial information plays a critical role in effective denoising. In particular, U-Net architectures have shown superior improvements in modeling long-range dependencies and coarse-to-fine representation [2; 8; 19; 33; 41; 43; 44]. To benefit from the U-Net structure  in self-supervised learning, we propose **patch-unshuffle/shuffle**, a novel downsampling/upsampling technique that preserves \(\)-invariance. By incorporating downsampling/upsampling as a design option for BSN, we increase flexibility in network structures. Furthermore, patch-unshuffle expands receptive fields and utilizes multi-scale representation in BSN. We also introduce the **dilated attention block (DAB)**, a \(\) -invariant channel attention mechanism incorporating global information. DABs effectively remove noise by attentive connections between instances sub-sampled via patch-unshuffle. Hence, we integrate **Patch-Unshuffle and Channel Attention (PUCA)**, a novel U-Net architecture, while meeting the \(\)-invariant requirement. PUCA significantly outperforms existing state-of-the-art self-supervised denoising methods and unsupervised/unpaired approaches. As shown in Figure 1, PUCA shows comparable denoising quality with the ground truth. Our contributions can be summarized as follows:

* We propose patch-unshuffle/shuffle, a \(\)-invariant downsampling/upsampling method that effectively utilizes multi-scale representation and expands receptive fields. Moreover, patch-unshuffle/shuffle unleashes the constrained architecture design for blind-spot networks (BSNs).
* We introduce dilated attention blocks (DABs), which effectively incorporate global context through channel attention. The combination of DAB with patch-unshuffle/shuffle provides an advantage for noise removal by leveraging information from an ensemble of subsamples.
* By taking advantage of patch-unshuffle/shuffle and dilated attention block (DAB), PUCA, our proposed \(\)-invariant U-Net, outperforms other self-supervised and unpaired solutions by a substantial margin. Code is available at https://github.com/HyemiEsme/PUCA

## 2 Preliminaries

### \(\)-invariant Network

In self-supervised learning, the denoising model needs to maintain \(\)-invariance to prevent learning identity mapping. \(\)-invariance is to remove the influence of the input pixel on the corresponding output pixel. Since spatially correlated noise can expose evidence for the masked pixels, previous works [18; 4; 36] assume zero-mean pixel-wise independent noise. We also adopt the same noise assumption, and the definition of \(\)-invariance introduced in Noise2Self  is as follows.

**Definition 1** (Batson and Royer, 2019) Consider a partition \(\) of the dimensions \(\{1,...,m\}\), an observed noisy signal \(x\), and a sub-sample \(x_{J}\) of \(x\) limited to \(J\). Let \(g:^{m}^{m}\) be a function. A function \(g\) is \(J\)-invariant if the value of \(g(x)_{J}\) does not depend on the particular value of \(x_{J}\); \(g\) is \(\)-invariant if it is \(J\)-invariant for every \(J\).

The \(\)-invariant network is trained to predict the value of each pixel using that of its surrounding pixels. To demonstrate the correspondence of self-supervised loss for supervised loss, we adopt the proposition from \(\)-invariant definition of Noise2Self .

**Proposition 1** (Batson and Royer, 2019) Let \(x\) (a noisy image) be an unbiased estimator of \(y\) (a clean image), denoted as \([x|y]=y\). Considering the \(\)-invariant function \(g\), then the self-supervised loss,

\[||g(x)-x||^{2}=||g(x)-y||^{2}+||x-y||^{2}\] (1)

Under the assumption of zero-mean pixel-wise independent noise, the self-supervised loss is equal to the general supervised loss in addition to the variance of the noise. Therefore, by training the \(\)-invariant function \(g\) using the self-supervised loss, \(g\) can learn a way of eliminating the encoded general noise.

Blind-spot network (BSN)BSNs [18; 20; 36] incorporate blind spots to the denoising framework to preserve \(\)-invariance in self-supervised learning. D-BSN  is a popular BSN architecture that utilizes centrally masked convolution in the first layer to exclude input pixel information. To maintain \(\)-invariance, D-BSN employs dilated convolution with dilation 2 when using a \(3 3\) centrally masked convolution and dilation 3 when using a \(5 5\) centrally masked convolution. The dependence of output pixels on the central pixel of input after stacking centrally masked convolution and dilated convolution is illustrated in Figure 2. The combination of the centrally masked convolution and the dilated convolution satisfies the \(\)-invariance.

### Pixel-Shuffle Downsampling

Contrary to the assumption of zero-mean pixel-wise independent noise in BSN, real noise demonstrates correlations that enable noise prediction from neighboring pixels. To address this, Zhou et al.  introduced pixel-shuffle downsampling (PD), allowing denoisers trained on synthetic noise to handle real noise effectively by breaking spatial noise correlation. However, the analysis of AP-BSN  on real noise in SIDD reveals that images downsampled by the PD with a small stride factor still exhibit spatial noise correlation. To mitigate this, PD with a large stride factor is used during training. Nonetheless, using a PD with a large stride factor leads to a loss of input details. To preserve the details, a PD with a small stride factor is employed during testing. We also adopt asynchronous PD, utilizing different PD sizes for train and test phases.

## 3 Method

We propose PUCA, a novel \(\)-invariant U-Net as shown in Figure 3. Initially, we provide an overview of PUCA. Subsequently, we delve into the two essential elements of PUCA: (1) Patch Unshuffle/Shuffle and (2) Dilated Attention Block (DAB).

Figure 2: **Dependency between the input and output pixels with a centrally masked convolution and d-dilated convolutions.** The green pixels indicate the pixels that are dependent on the center pixel in input, while the blue pixels represent the area independent of the central pixel. The yellow pixels represent the convolution weights.

PUCA OverviewFirst, \(1 1\) convolution and pixel-shuffle downsampling are applied to break noise correlation in the noisy image \(I^{H W 3}\). Subsequently, centrally masked convolution and multiple \(1 1\) convolutions derive low-level feature embeddings \(F_{0}^{H W C}\). \(H W\) represents the spatial dimensions, and \(C\) denotes the number of channels. The initial features \(F_{0}\) are then processed through a 3-level encoder-decoder structure with multiple DABs at each level, resulting in deep features \(F_{d}^{H W C}\). The encoder begins with the high-resolution input and incrementally shrinks its spatial size while augmenting channel capacity. Conversely, the decoder starts with low-resolution latent features \(F_{l}^{ 4 C}\) and progressively restores high-resolution representations. Patch-unshuffle and patch-shuffle operations (Figure 3(b)) are used for feature downsampling and upsampling, respectively. To retain detailed structures and textures in the restored images, skip connections merge features from the encoder and decoder. Finally, a sequential application of \(1 1\) convolution layers generates the output image \(^{H W 3}\), which represents the enhanced and denoised version of the original noisy image.

### Patch Unshuffle/Shuffle

We propose a patch unshuffle/shuffle that dramatically increases receptive fields, as shown in Figure 5. Downsampling helps to capture long-range dependencies and multi-scale context. By incorporating multi-scale context through downsampling, denoisers can better understand the relationships and dependencies between different image parts. Among the downsampling methods, pixel-unshuffle/shuffle  that preserves original pixels is known to be effective in image restoration. However, pixel-unshuffle with BSN  disrupts \(\)-invariance.

Let's consider BSN denoted as \(f\), composed of fully convolutional layers. \(f\) comprises \(d\)-dilated convolutions \(f^{(l)}\) for all \(l(1,L)\), with a kernel size of \(3 3\). We can express the function \(f\) as a sequential application of \(f^{(l)}\), resulting in \(f(x)=f^{(L)}(f^{(L-1)}(...f^{(1)}(f^{(0)}(x))))\). Here,

Figure 4: **Difference between pixel-unshuffle/shuffle and patch-unshuffle/shuffle. The pixels except for blue are dependent on the central pixel of input, and only blue pixels are independent. We assume 2-dilated convolution is applied.**

Figure 3: **Overview of PUCA. Our method utilizes an encoder-decoder-based U-Net architecture. During encoding, we extract global context through patch-unshuffling, and during decoding, we combine local and global context through skip connections.**

\(f^{(0)}\) represents a convolutional layer using a \((2d-1)(2d-1)\) centrally masked filter, and \(x\) denotes the input noisy image. The output features for each convolutional layer \(l\) are represented as \(y^{(l)}=f^{(l)}(f^{(l-1)}(...f^{(1)}(f^{(0)}(x))))\)).

Let \(x_{i,j}\) a pixel of a noisy image \(x\), where \(i,j\) are the coordinates satisfying \(i q=0\) and \(j q=0\). \(q\) denotes the scale factor of pixel-unshuffle. The application of dilated convolution exposes \(x_{i,j}\)'s features to its neighboring pixels. Pixel-unshuffle (Figure 3(a)) aligns pixels \(y^{(l)}_{m,n}\), where \(i m<i+q\) and \(j n<j+q\) to the channel axis of the same spatial position as \(y^{(l)}_{i,j}\), and convolution operations following this would expose \(x_{i,j}\)'s features to \(y^{(l)}_{i,j}\), breaking the \(\)-invariance.

We propose patch-unshuffle to solve the problem of pixel-unshuffle mentioned above. Patch-unshuffle transforms a tensor of size \(H W C\) into a reshaped tensor of size \( C p^{2}\), as illustrated in Figure 3(b). This process can be mathematically defined as follows:

\[(y^{(l)}_{i,j,k},p)=(p}+i  p,p}+j p,C(p}{ p}+}{p})+k)\] (2)

Incorporating patch-unshuffle in the function \(f(x)\) preserves \(\)-invariance under specific conditions.

Proposition 2.Patch-unshuffle maintains \(\)-invariance if \(p\), patch size, is a multiple of the dilation \(d\) used in dilated convolution

Proof.Assuming a simplified one-dimensional case for clarity without loss of generality, the satisfaction of \(\)-invariance requires patch-unshuffle to meet the condition where pixels with the same position as \(x_{J}\) in each channel remain unaffected by \(x_{J}\), \(J\{1,...,m\}\).

After central masked convolution in the first layer, neighboring pixels are affected by \(x_{J}\), with the receptive field \((y^{(0)},x_{J})=\{J-(d-1),...,J-1,J+1,J+(d-1)\}\). \((y^{(l)},x_{J})\) indicates the receptive field of \(x_{J}\) in \(y^{(l)}\). Sequentially, dilated convolution spreads the information of \(x_{J}\).

\[(y^{(l)},x_{J})=_{j\{-d,0,d\}}\{i+j|i(y^{(l-1) },x_{J})\}\] (3)

There exist pixels that do not depend on \(x_{J}\) with a period of \(d\). To downsample \(y^{(l)}\), we use patch-unshuffle. To facilitate comprehension, our emphasis lies on spatial location while disregarding the channel axis.

\[(y^{(l)}_{i},p)=p}+i p\] (4)

The pixels \(s\) that have identical spatial position with \(J\) satisfy

\[p}+s p=p}+J  p\] (5)

\[ p(}-})=| (J-s) p\] (6)

Figure 5: **Visualization of the receptive field for AP-BSN  and PUCA based on depth variations.** We calculate the influence of input pixels on the output’s central pixel through gradients. Brighter colors indicate a stronger influence PUCA exhibits significantly wider receptive fields than AP-BSN. We observe that the receptive fields become wider as the depth increases.

In Equation 6, the left-hand side is a multiple of \(p\), and the right-hand side is the remainder when divided by \(p\), making it smaller than \(p\). Thus, for the equation to be valid, both sides must be 0 so that the positional difference between \(s\) and \(J\) is a multiple of \(p\) from \(J\). By considering the periodicity \(d\) of pixels in \(y^{(l)}\) that do not depend on \(x_{J}\), resulting from the combination of centrally masked convolution and dilated convolution, we can infer that when the patch size \(p\) is a multiple of the dilation factor \(d\), patch-unshuffle guarantees the independence on \(x_{J}\) along the channel axis. \(\)

By employing patch-unshuffle with a patch size \(p\) that is a multiple of the dilation factor \(d\), \(\)-invariant networks ensure the preservation of \(\)-invariance. This successful integration of patch-unshuffle in BSN allows for effective downsampling operations. Moreover, patch-shuffle in Figure 3(b), which acts as the reverse operation of patch-unshuffle, facilitates the upsampling of downsampled feature maps to restore them to their original image sizes.

### Dilated Attention Block

We also adopt channel attention  in addition to U-Net to fully exploit the global information in the image. The feature interaction that can be obtained from each is different. While channel attention based on global pooling extracts the most prominent features among the global information, U-Net is more suited for leveraging feature relations by expanding the receptive fields. However, directly applying channel attention to BSN is not straightforward due to the blind spot requirement. We aim to design a channel attention block that satisfies the blind spot requirement when combined with patch-unshuffle and patch-shuffle operations. To fulfill this requirement, we incorporate a \(d\)-dilated \(3 3\) depth-wise convolution (DDC) before gating and attention, taking inspiration from D-BSN . The resulting dilated attention block (DAB), consists of LayerNorm , \(1 1\) convolution, skip connection , SimpleGate and Simplified Channel Attention (SCA) , along with DDC (as shown in Figure 3). The utilization of SimpleGate and SCA enhances the integration of local and global information by suppressing less informative features . For the input feature map \(\)

\[(_{1},_{2})=_{1} _{2},\] (7)

where \(\) is element-wise multiplication, \(_{1}\) and \(_{2}\) are two parts of \(\) along the channel axis of the same size.

\[()=*(P_{}()),\] (8)

where \(P_{}\), \(\), and * denotes global average pooling, a fully-connected layer, and channel-wise product operation, respectively.

## 4 Experiments

### Datasets and Implementation Details

**Smartphone Image Denoising Dataset (SIDD) ** is a collection of real-world images for denoising captured by five different smartphone cameras. Specifically, the SIDD-Medium dataset consists of 320 pairs of noisy and clean images for training purposes. In addition, the SIDD validation set and benchmark set are used for validation and evaluation, respectively. Both sets consist of 1,280 noisy patches with a size of \(256 256\), and corresponding clean images are provided only for the validation set. We train our model for SIDD validation and evaluation on the SIDD-medium dataset.

**Darmstadt Noise Dataset (DND) ** is a dataset used for benchmarking image denoising algorithms. It contains 50 real-world noisy images without any ground truth provided, and the only way to obtain results is through an online submission system. A fully self-supervised learning approach can be used to train the denoising model directly on the test set without using any external data. We train our model for DND evaluation on the DND benchmark.

**Implementation Details** We trained the model using an NVIDIA TESLA P100 GPU and implemented it with Pytorch 2.0.0. The model was trained with L1 loss between the input noisy image and the output, using Adam optimizer with an initial learning rate of 1e-4. We trained the model for 20 epochs until it fully converged. More detailed information can be found in our supplementary material. We use peak signal-to-noise ratio (PSNR) and structural similarity (SSIM)  as evaluation metrics for denoising. The SIDD and DND benchmark results are obtained from online submission scores, and for the SIDD validation data, we evaluate the performance using the corresponding functions in the skimage.metrics library.

[MISSING_PAGE_FAIL:7]

shuffle downsampling and patch-unshuffle drastically reduce the latent features to an extremely small resolution leading to the degradation of global semantics.

Table 3 confirms the effect of DAB and patch-unshuffle. As explained in Section 3.1, the generated output of pixel unshuffle as downsampling in a 3-layer U-Net structure is equal to the original noisy input (Table 3 (a)) because the model learns identity mapping. We run experiments with each component to test the role of DAB and patch-unshuffle. For Table 3 (b), we use a 1-level network without downsampling. For Table 3 (c), we utilize the D-BSN block instead of DAB. In accordance with our intuition, Table 3 (d), which utilizes both DAB and patch-unshuffle, exhibits the best performance compared to the ablated results.

## 5 Related Work

### Image Denoising

Supervised Image Denoising with Synthetic PairsSince the success of CNNs [17; 29; 14], deep learning-based methods with CNNs have dominated the field of computer vision, including image denoising. DnCNN  first adopted the CNN architecture to image denoising, training on synthesized image pairs. Following this pioneering work, many studies have aimed to build a better architecture for image denoising [23; 24; 46; 30]. These learning-based methods rely on clean-noisy image pairs for training, where noisy images are synthesized with additive white Gaussian noise (AWGN). Recently, Guo et al.  has shown that this assumption of AWGN does not hold in

    & DAB & Unshuffle & PSNR & SSIM \\  (a) & - & Pixel & 23.662 & 0.328 \\ (b) & ✓ & - & 36.768 & 0.875 \\ (c) & - & Patch & 37.386 & **0.880** \\ (d) & ✓ & **Patch** & **37.492** & **0.880** \\   

Table 3: Ablation study on PUCA components with SIDD validation 

Figure 6: **Qualitative comparison on SIDD benchmark . Access to the ground truth image and evaluation values for a denoised image is unavailable.**

Figure 7: **Qualitative comparison on DND benchmark .**

practice, and these methods show poor generalization performance due to the domain gap between real and synthetic noise.

Unsupervised Image DenoisingVarious approaches have been introduced to deal with the mentioned domain gap between training and testing in image denoising. One straightforward approach uses the clean-noisy pairs captured from real-world [1; 5]. However, this approach is impractical since data collection is extremely labor-intensive and requires a sophisticated process.

Another line of work is synthesizing realistic clean-noisy image pairs. Guo et al.  considers the in-camera Image Signal Processing (ISP) pipeline for realistic noise synthesis. GCBD  adopt adversarial training  to model the noise distribution and build a paired dataset for training. C2N  takes the properties of real-world noise into account in noise simulation.

Due to the notorious difficulty of acquiring clean-noisy pairs, self-supervised methods without clean images have been proposed. Noise2Noise  showed that denoising models could be trained without clean images. Noise2Void  and Noise2Self  use a masking strategy for self-supervision. The concept of blind-Spot Networks (BSNs)  was further improved by Laine et al.  and Wu et al. . On the other hand, there have been some works on loss functions [37; 32] instead of explicitly masking to prevent learning identity mapping. These methods are all based on a strong assumption that noise is pixel-wise independent. Yet, they eventually learn identity mapping when applied to real-world scenarios where noise is spatially correlated. Zhou et al.  suggests pixel-shuffle downsampling (PD) to break the spatial correlation of real noise so that models trained with AWGN could adapt well. AP-BSN  enhances this with asymmetric strides during training and testing. LG-BPN , a contemporary work to ours, proposes a denser sampling kernel to recover local texture better and a global branch with larger receptive fields.

### Long Range Dependency

Large receptive fields are important to extract meaningful features in consideration of context. Stacking convolutional layers can linearly expand the receptive fields of a network. Yet, downsampling operation enables exponential growth of receptive fields and thus is a more favored option in increasing receptive fields. U-Net  is a representative structure used in low-level vision, which employs downsampling and upsampling and it enables long-range interaction of pixels. Also, the effectiveness of U-Net's coarse-and-fine representation has been demonstrated by previous works [2; 8; 19; 33; 41; 43; 44]. Self-attention , another form of handling long-range dependencies, was first introduced in natural language processing (NLP) and it has been known to be also effective in computer vision . Although self-attention has shown promising results recently, it has a critical shortcoming of complexity quadratic to the input resolution. Restormer  proposes to operate self-attention on the channel dimension rather than the spatial dimension in order to capture global information while saving computational cost. NAFNet  shows that simple gating and channel attention is sufficient to incorporate global context with better efficiency and performance. Following these lines of work, we aimed to apply these findings to self-supervised image denoising incorporating global context and coarse-and-fine features of large receptive fields.

## 6 Conclusion

We present PUCA, a novel \(\)-invariant U-Net tailored for self-supervised image denoising. By incorporating patch-unshuffle/shuffle and dilated attention block (DAB), we successfully alleviate the constrained architecture design imposed by \(\)-invariance. First, we propose a novel downsampling technique called patch-unshuffle, which plays a vital role in leveraging multi-scale representation and significantly expanding the receptive fields. Second, we propose DAB, which integrates global context and suppresses less informative features. The experimental results demonstrate the superiority of PUCA over existing self-supervised image denoising methods. Despite achieving state-of-the-art performance in self-supervised image denoising, PUCA still has certain limitations. One such limitation is the degradation of global semantics when using an excessive number of levels. One potential approach to address this issue is to explore methods that can break input noise correlation, thus preserving the resolution of the input. In terms of societal impacts, like other denoising methods, PUCA could be misused to invade privacy or make incorrect diagnoses.

Acknowledgements

This work was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (2022R1A3B1077720 and 2022R1A5A708390811), Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government(MSIT) [2021-0-01343: Artificial Intelligence Graduate School Program (Seoul National University) and 2021-0-02068: Artificial Intelligence Innovation Hub] and the BK21 FOUR program of the Education and Research Program for Future ICT Pioneers, Seoul National University in 2023.