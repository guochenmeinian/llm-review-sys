# GEPS: Boosting Generalization in Parametric PDE Neural Solvers through Adaptive Conditioning

Armand Kassai Koupai \({}^{1}\)1 Jorge Mifsut Benet \({}^{1}\)2 Yuan Yin \({}^{2}\)

Jean-Noel Vittaut\({}^{3}\) Patrick Gallinarii\({}^{1,4}\)3

###### Abstract

Solving parametric partial differential equations (PDEs) presents significant challenges for data-driven methods due to the sensitivity of spatio-temporal dynamics to variations in PDE parameters. Machine learning approaches often struggle to capture this variability. To address this, data-driven approaches learn parametric PDEs by sampling a very large variety of trajectories with varying PDE parameters. We first show that incorporating conditioning mechanisms for learning parametric PDEs is essential and that among them, _adaptive conditioning_, allows stronger generalization. As existing adaptive conditioning methods do not scale well with respect to the number of parameters to adapt in the neural solver, we propose GEPS, a simple adaptation mechanism to boost GEneralization in Pole Solvers via a first-order optimization and low-rank rapid adaptation of a small set of context parameters. We demonstrate the versatility of our approach for both fully data-driven and for physics-aware neural solvers. Validation performed on a whole range of spatio-temporal forecasting problems demonstrates excellent performance for generalizing to unseen conditions including initial conditions, PDE coefficients, forcing terms and solution domain. _Project page_: https://geps-project.github.io/

## 1 Introduction

Solving parametric partial differential equations, i.e. PDE in which certain parameters--such as initial and boundary conditions, coefficients, or forcing terms--can vary, is a crucial task in scientific and engineering disciplines, as it plays a central role in enhancing our ability to model and control systems, quantify uncertainties, and predict future events (Cohen and Devore, 2015). Neural networks (NNs) are increasingly employed as surrogate models for solving PDEs by approximating their solutions (Long et al., 2018; Lu et al., 2021; Li et al., 2021). A primary challenge with these data-driven solvers is their ability to generalize across varying contexts of the physical phenomena. This is especially pronounced for dynamical systems, which can exhibit significantly different behaviors when subject to small changes in PDE parameters.

The usual approach for solving a parametric PDE with neural networks involves sampling instances from the PDE parameter distribution (e.g., the PDE coefficients), and then sampling trajectories for each instance of the underlying PDE (Takamoto et al., 2022). The training set thus consists of multiple trajectories per parameter instance, with the objective of generalizing to new instances. This approach aligns with the classical empirical risk minimization (ERM) framework: it assumes that the training dataset is large enough to represent the distribution of the dynamical system behaviors and that this distribution is i.i.d. (Bodnar et al., 2024). However, given the complexity of dynamicalsystems and the variety of PDE terms and parameters, these assumptions are rarely met in practice. To address this difficulty, some methods relax these assumptions. For instance, certain approaches embed the PDE parameters as inputs, aiming to generalize to new dynamics (Brandstetter et al., 2023; Takamoto et al., 2023). While this can alleviate the issue, it does not facilitate generalization beyond the training distribution. Other approaches focus on few-shot settings, where a pre-trained model is fine-tuned for each new context (Subramanian et al., 2023; Herde et al., 2024). As we will see, fine-tuning NN solvers typically requires a substantial amount of data, when it is often scarce in practice. In general, given the complexity of physical phenomena, it is often unrealistic to expect a sample distribution that is sufficiently representative to enable reliable generalization to new instances of the same phenomenon.

Our claim is that neural PDE solvers should be explicitly trained with an _adaptive conditioning_ mechanism to enable generalization to new parameter instances. For practical applications, this mechanism should condition the network on new dynamics using only a small amount of data. We assume access to several environments governed by the same general PDE, each defined by a unique set of parameters, from which trajectories can be sampled. This assumption aligns with approaches in multi-task learning (Yin et al., 2022) and meta-learning (Wang et al., 2022; Kirchmeyer et al., 2022), where network weights are conditioned on a context that encapsulates environment-specific information. Although various adaptive conditioning mechanisms have been proposed (Finn et al., 2017; Kirchmeyer et al., 2022; Wang et al., 2022), they are often limited to specific neural network architectures (Karimi Mahabadi et al., 2021) and struggle to scale effectively with data size or with the number of environments. We then propose an adaptation method that can handle a diversity of physical dynamics, is compatible with various NN backbones, and scales effectively with data size and the number of environments.

After introducing the problem in Section 2, we emphasize in Section 3 the need for adaptive conditioning to solve parametric PDEs and illustrate the limitations of traditional ERM based approaches. We then introduce GEPS, a low-rank \(1^{}\)-order gradient-efficient adaptation mechanism for learning parametric PDE solvers. At inference, GEPS adapts to a new unseen environment, by learning a compact context vector \(c^{e}\). This approach is instanciated in two representative settings: (i) purely agnostic approaches, where the solver is trained without any prior physical knowledge, and (ii) physics-aware approaches that combine differentiable numerical solvers with NN components in a hybrid framework. Finally section 5 compares GEPS with alternative adaptation baselines. Our contributions are as follows:

* We demonstrate on example PDEs that adaptive conditioning generalizes to multiple and new contexts, while classical ERM approaches fail to handle parametric PDEs.
* We propose an effective and scalable adaptive conditioning framework for learning neural solvers. It is based on a first-order meta-learning approach and leverages low-rank adaptation, enabling adaptation to unseen environments in a few shot context. This formulation is versatile enough to encompass both pure data-driven and physics-aware models.
* We provide experimental evidence of the performance and versatility of the approach on representative families of parametric PDEs, incorporating changes in initial conditions, PDE coefficients, forcing terms, and domain definitions, thereby covering both in-distribution and out-of-distribution scenarios.

## 2 Problem Description

We consider parametric time-dependent PDEs and aim to train models that generalize across a wide range of the PDE parameters, including initial conditions, boundary conditions, coefficient parameters, and forcing terms. For a given PDE, an environment \(e\) is an instance of the PDE characterized by specific parameter values. We assume that all environments share common global features, such as the general form of the dynamics, while each environment \(e\) exhibits some unique and distinct behaviors. A solution \(^{e}(x,t)\) of the PDE in environment \(e\) satisfies the PDE:

\[^{e}(x,t)}{ t} =F^{e}(^{e},^{e}}{ x}, ^{e}}{ x^{2}},,,),  x, t(0,T]\] (1) \[(^{e})(x,t) =0, x, t(0,T]\] (2) \[^{e}(x,0) =^{e}_{0}, x\] (3)where \(F^{e}\) is a function of the solution \(^{e}\), its spatial derivatives, the PDE coefficients \(\) and forcing terms \((x,t)\); \(\) is the boundary condition (e.g., spatial periodicity, Dirichlet, or Neumann) that must be satisfied at the domain boundary \(\) and \(_{0}\) is the initial condition (IC) sampled with a probability measure \(_{0}^{0}(.)\). Environment \(e\) is thus defined by a set of parameters \(=\{,^{0},,\}\).

The targeted task is dynamics forecasting, where a neural solver is auto-regressively rolled out on a temporal horizon \(t[0,T]\). The goal is to approximate the evolution operator \(F^{e}\) with a neural solver \(_{}(^{e}(x,t))\) parametrized by \(^{d_{}}\), capable of generalizing to various PDE instances \(\), both within (in-distribution) and outside (out-of-distribution) the training parameter distribution.

Therefore, we posit the observation of a set of environments \(e\), each characterized by its specific PDE parameters \(\); trajectories are sampled for each environment, each characterized by an IC \(_{0}^{e}\). We define \(_{}\) as the set of environments used to train our model. In each training environment, \(N_{}\) trajectories are available \(_{}^{e}=\{_{i}(x,t)\}_{i=1}^{N_{}}\). For the _in-distribution_ evaluation, the model has already learned conditioning context parameters (described later in section 4.1) for each training environment and is simply tested on new trajectories from the same environments using the appropriate context. For _out-of-distribution_, the model is evaluated on trajectories from new environments from an evaluation set \(_{}\) and is adapted. We then assume access to \(N_{}\) trajectories \(_{}^{e}=\{_{i}(x,t)\}_{i=1}^{N_{}}\) from the new environments to adapt the network. In our experiments we consider a scarce data, few-shot scenario where \(N_{}=1\). After adaptation, we test our model on new unseen trajectories from these evaluation environments \(_{}\). This setting is illustrated in Figure 1.

Before introducing our method, we first aim to motivate the need for adaptive conditioning in learning to solve parametric PDEs, while illustrating the limitations of the classical ERM setting.

## 3 Motivations: ERM versus adaptive approaches for parametric PDEs

The classical ERM approach learns a single model on the data distribution, assuming that the training dataset is large enough to approximate the true data distribution. In practice, data acquisition is often costly and even simple physical systems can demonstrate a large variety of behaviors due to changes in the parameters. This may lead to poor generalization especially with scarce data.

To illustrate this, we will compare the performance and behavior of classical ERM approaches and of our adaptive conditioning method for solving parametric PDEs, on two example datasets: the 2D Gray-Scott and the 1D Burgers equations. In these experiments, we generate for each PDE a series of environments by sampling only the physical coefficients of the PDE \(=\{\}\) (more details in Appendix B). We consider in-distribution generalization and out-of-distribution generalization (respectively in sections 3.1 and 3.2, both for an initial value problem (IVP), a common setting where the initial condition \(_{0}\) corresponds to the system state at one time \(t_{0}\) only. We then consider an alternative setting, where the neural solver is conditioned over a sequence of past states instead of

Figure 1: Multi-environment setup for the Kolmogorov PDE. The model is trained on multiple environments with several trajectories per environment (left). At inference, for a new unseen environment it is adapted on one trajectory (right).

one state only (section 3.3), this is denoted as "temporal conditioning". For all experiments, reported results correspond to the averaged relative L2 loss on 32 unseen trajectories per environment.

### In-distribution generalization for IVP: classical vs. adaptive conditioning approaches

Let us first compare adaptive conditioning and ERM approaches, for in-distribution evaluation, when scaling the number of training environments and trajectories. The models are trained on a range of environments - corresponding to different coefficients of the underlying PDE - and evaluated on the same environments with different initial conditions. Here GEPS is implemented with a classical CNN, while the tests for ERM are performed with four different backbones: the same CNN as used for GEPS but without adaptive conditioning, FNO (Li et al., 2021), MP-PDE (Brandstetter et al., 2023) and Transolver (Wu et al., 2024). Additionally, we also compared with a reference foundation model "Poseidon" (Herde et al., 2024). This model has been pre-trained on a variety of IVP PDE equations and is fine-tuned on our data. Poseidon being trained on 2D data is thus evaluated only for the Gray-Scott equation. For all the baselines, we consider the classical IVP setting where only one initial state is given as input.

Scaling w.r.t. the number of environments.We first examine how the number of training environments affects generalization to unseen trajectories within the same range of environments. The models are trained on 4 and 1024 environments with 4 trajectories per environments corresponding to different initial conditions. The evaluation is performed on 32 new trajectories from the same set of environments. As shown in Figure 2, Transolver, FNO, MP-PDE, and CNN fail to capture the diversity of behaviors and their performance stagnate when increasing the number of training environments. Non-conditioned methods are not able to capture the diversity of behaviors for several environments, regardless of the backbone used, when using only an initial state as input. Poseidon on its side behaves much better on Gray-Scott and is able to capture this diversity of dynamics. Our adaptive conditioning approach (GEPS on the figures) performs significantly better than all the baselines, outperforming also the large Poseidon foundation model. We can also observe that GEPS benefits from being trained on a large amounts of environments, as its generalization performance improves with the number of training environments.

Scaling w.r.t. the number of trajectories per training environment.For this second series of experiments, we fix the number of environments at 4 and vary the number of training trajectories per environment from 4 up to 1024. Figure 3 shows the same behavior as for the previous experiments: ERM approaches rapidly reach a plateau and do not capture the variety of behaviors, even with a large number of trajectories, while GEPS scales well and improves with the number of training samples per environment. We additionally make a comparison with a CNN model trained and evaluated separately for each environment. We plot the average of the models' scores (indicated as "average" on the figure). This is an upper-bound of the performance that could be obtained with ERM models trained from scratch (no pretraining as for Poseidon). Note that this requires as many models as environments and is not scalable. While this performs significantly better than training over all the environments, GEPS matches or surpasses this approach.

Figure 2: Comparison of ERM approaches (shades of blue) and Poseidon foundation model (green) with our framework GEPS (red) when increasing the number of training environments.

The experiments highlight that non-conditioned ERM approaches are unable to learn multi-environments datasets for solving IVP, whereas adaptive conditioning approaches like GEPS exhibit strong generalization performance, scaling with the number of training trajectories and environments.

Out-of-distribution generalization to new environments for IVP: classical vs. adaptive conditioning approaches

Let us now consider the out-of-distribution behavior of the two approaches. The models are trained on a sample of the environments from \(_{}\) and their associated trajectories, in the same condition as for section 3.1. They are then evaluated on the trajectories of new environments. We report in figure 4 the out-of-distribution generalization performance of ERM methods and GEPS, for the Gray-Scott and Burgers equations, when pretrained on 4 (left) and 1024 (right) environments, with 4 trajectories per environment. For the test, one considers 4 new environments and evaluate on 32 trajectories per environment. Adaptation (GEPS) or fine tuning (baselines) is performed on one trajectory of a new environment. As for the baselines, we consider CNN and Transolver, plus the Poseidon foundation model for the 2-D Gray-Scott equation only. As above, one may observe a large performance gap between the non adaptive approaches and the adaptive GEPS. This supports our claim on the limitations of pure ERM based approaches to generalize to unseen dynamics configurations and new environments.

### In and out-of-distribution generalization performance with temporal conditioning

So far we have considered the classical IVP setting with only one initial state provided at time \(t_{0}\). We consider now the situation where the model has access at \(t_{0}\) to an history of past states and not to a

Figure 4: Out-distribution generalization on 4 new environments using one trajectory per environment for fine-tuning or adaptation. Models have either been pretrained on 4 environments (left column) or 1024 environments (right columns). Metric is Relative L2 loss.

Figure 3: Comparison of ERM approaches (shades of blue) and Poseidon (green) with our framework GEPS (red) when increasing the number of trajectories per environment.

single initial state only. This is a common setting for learning PDE solvers: this allows the model to infer information on the dynamics and represents a more favorable case for the ERM baselines. We report in table 1 the in-distribution (_In-d_) and out-distribution (_Out-d_) distribution performance of ERM methods and GEPS, for Burgers and Gray-Scott PDEs. We did not consider the Poseidon (Herde et al., 2024) model that has been pre-trained only for one initial state IVPs. For in-distribution results, all methods are trained on 4 environments and evaluated on 32 new trajectories from the same environments. For out-of-distribution, adaptation (GEPS) and fine-tuning (baselines) is done on 1 trajectory per environment; 4 new environments are sampled and evaluation is performed on 32 new trajectories. We consider three different history sizes: 3, 5 and 10. Considering past history helps improve all the models. GEPS and the baselines show close performance for in-distribution, while GEPS is an order of magnitude better than the baselines for out-of-distribution.

## 4 GEPS method

We introduce our framework for learning to adapt neural PDE solvers to unseen environments. It leverages a \(1^{st}\) order adaptation rule and low-rank adaptation to a new PDE instance. We consider two settings commonly used for learning the PDE solvers. The first one leverages pure agnostic data-driven approaches, as already considered in section 3. The second one leverages incomplete physics priors and considers hybrid approaches that complement differentiable numerical solvers with deep learning components. The general framework is illustrated in Figure 5.

### Adaptation rule

We aim to train a model \(_{}\) to forecast dynamical systems coming from multiple environments. We perform adaptation in the parameter-space: some parameters are shared across all the environments while others are environment-specific. Training consists in estimating the shared parameters and learning to condition the model on environment specific parameters. At test time, the shared

  
**History \(\)** &  &  &  \\ 
**Method** & _In-d_ & _Out-d_ & _In-d_ & _Out-d_ & _In-d_ & _Out-d_ \\   \\ Transolver & 1.95e-1 & 3.22e-1 & 1.12e-1 & 3.03e-1 & 5.64e-2 & 2.49e-1 \\ FNO & 4.28e-1 & 7.68e-1 & 3.07e-1 & 6.43e-1 & 6.13e-2 & 2.55e-1 \\ CNN & 1.84e-1 & 4.44e-1 & 1.62e-1 & 3.34e-1 & 3.16e-2 & 6.32e-2 \\ GEPS & **1.25e-2** & **1.63e-2** & **8.61e-3** & **1.04e-3** & **6.14e-3** & **8.73e-3** \\   \\ Transducer & 1.82e-1 & 4.33e-1 & 9.88e-2 & 3.90e-1 & 9.57e-2 & 3.60e-1 \\ FNO & 1.86e-1 & 4.67e-1 & 1.76e-1 & 3.87e-1 & 1.93e-1 & 4.03e-1 \\ CNN & 7.12e-2 & 3.51e-1 & 5.96e-2 & 2.18e-1 & 6.54e-2 & 2.23e-1 \\ GEPS & **4.02e-2** & **5.78e-2** & **3.04e-2** & **5.02e-2** & **3.82e-2** & **5.14e-2** \\   

Table 1: In-distribution and out-distribution results comparing different history window sizes. Metric is the Relative L2 loss.

Figure 5: Our adaptation framework for our data-driven model. Block in blue refers to the data-driven module \(_{a}\). Blocks \(L_{i}\) in pink refer to the trainable modules. The green block describes the adaptation mechanism for the data-driven component, with \(_{L_{i}}\) the weights of layer \(L_{i}\). Context vector \(^{e}\) conditions _all_ the layers \(_{L_{i}}\).

parameters are frozen and adaptation is performed on the environment specific parameters only. This setting is common to adaptation based approaches (Zintgraf et al., 2019; Kirchmeyer et al., 2022), however most of them do not scale to large problems while GEPS introduces an efficient scalable adaptation mechanism.

FormulationWe adapt the parameters of our model \(_{}\) using a low-rank formulation. Most deep-learning architectures can be decomposed into modules or layers - in our experiments we use MLPs, CNNs and FNOs. For simplification let us then consider a layer \(L_{i}\) from \(_{}\) parameterized by a weight matrix \(_{L_{i}}^{d_{in} d_{out}}\). Adaptation to an environment is performed through a low-rank matrix \(_{L_{i}}^{e}=A_{L_{i}}(^{e})B_{L_{i}}\), where \(_{L_{i}}^{d_{in} r},_{L_{i}}^{r  d_{out}},^{e}^{r}\). The weights of layer \(L_{i}\) with the adaptation mechanism are then:

\[_{L_{i}}^{e}=_{L_{i}}+_{L_{i}}(^{e})_ {L_{i}}\] (4)

where \((^{e})\) is a diagonal matrix capturing environment specific information and \(_{L_{i}},_{L_{i}},_{L_{i}}\) are shared parameter matrices across all environments. Ideally, we want \(^{e}\) to capture the number of degrees of variations for our environments. If for example our model \(_{}\) is an MLP, the adaptation mechanism for a linear layer \(L_{i}\) corresponds to:

\[_{i}^{e}=(_{L_{i}}+_{L_{i}}(^{e})_{L_ {i}})_{i-1}^{e}+_{L_{i}}^{1}+_{L_{i}}^{2}^{e}\] (5)

where \(_{L_{i}},_{L_{i}},_{L_{i}},_{L_{i}}^{1},_{L_{i}} ^{2}\) are the parameters of layer \(L_{i}\), shared across all environments. Only \(^{e}\) is specific to each environment, but shared across all the layers of the network (cf Fig. 5).

Considering a low-rank adaption rule is popular in NLP, where large pre-trained models are adapted to new tasks by learning a low-rank matrix \(=\) added to the frozen weights \(\) of the pre-trained model (Hu et al., 2022). Our approach differs in two ways from this setting: (i) the model is learned from scratch without pretraining, i.e., we learn parameters \(\{,,,^{e}\}\) jointly, (ii) during adaptation, we can adapt to new environments \(e_{}\) by optimizing only the context vector \(^{e}\), where it is initialized as \(^{e}=_{}\), with \(_{}\) the averaged value of contexts learned during training. We experimentally show in Appendix D.3 that the classical Gaussian parameter initialization proposed in LoRA is inefficient in our context.

### Two-step training procedure

This meta-learning framework operates in two steps: Training and Adaptation at inference. The goal is to learn an initial starting point during the training stage using a sample of environments, allowing adaptation to a new environment by adjusting a small subset of parameters based on a limited data sample from the new environment. Unlike many meta-learning gradient based approaches, GEPS does not involve an inner loop and is a \(1^{st}\) order method. During the adaptation phase, all the parameters except the context parameters \(^{e}\) are frozen and \(^{e}\) is learned from the new environment sample. This approach ensures rapid adaptation by keeping \(^{e}\) low-dimensional. For simplicity, we refer to parameters shared across environments as \(^{s}\) and parameters specific to each environment as \(^{e}^{e}\), and denote \(^{e}=\{^{s},^{e}\}\). The optimization problem can thus be formulated as follows:

\[_{^{s},^{e}}_{^{e}_{} _{}}(\{^{s},^{e}\}, ^{e}_{})\] (6) subject to \[^{e}=*{arg\,min}_{^{e}}_{ ^{e}_{}_{}}(\{^{s}, ^{e}\},^{e}_{})\]

We separate training and adaptation steps into a training and an adaptation loop as described in the pseudo-code Algorithm 1.

### Hybrid formulation for learning dynamics

We consider here an alternative problem to the above agnostic formulation. We assume that part of the physics is modeled through a PDE equation and shall be complemented with a statistical module. This is a common situation in many domains where prior physical knowledge is available, but only in an incomplete form. We follow the formulation in Yin et al. (2021) were starting from a complete PDE, we assume that part of the equation is known and will be modeled with a differentiable solver,while it is complemented with a deep learning component for modeling the unknown part. We also assume that the coefficients of the known part of the PDE are unknown and shall be estimated. We thus aim at solving both a direct problem (the NN parameters) and an inverse problem (the PDE coefficients of the known PDE part). We consider dynamics for a given environment of the form:

\[^{e}(x,t)}{ t}=H(F^{e}((x,t), ),R^{e}((x,t),)), x, t(0,T]\] (7)

\(F^{e}\) and \(R^{e}\) respectively represent the known and unknown physics of environment \(e\) and \(H\) is a function combining the two components which is unknown in practice. As for \(_{}\), our model of the evolution operator for this physics-aware setting, we will use a simple combination:

\[_{}=_{a}_{p}\] (8)

where \(_{p}\) encodes the physical knowledge and corresponds to the known part of the PDE physical model and \(_{a}\) is the data-driven model term complementing \(_{p}\). With this model, we use an auto-regressive formulation to generate the full trajectory, using a Neural ODE (Chen et al., 2018) as time-stepper for predicting the state \(u_{t+}\) as \(u_{t+}=u_{0}+_{t_{0}}^{}_{}(u())\), as illustrated in Figure 15. The model is trained directly from trajectories simulated with the full PDE (known + unknown PDE components) using the MSE loss \(_{}^{e}\) (more details in Appendix C):

\[(,_{}^{e})=_{j=1}^{N}_{t I,x }\|(_{}(_{j}(x,t))-H(F^{e}(x,t,_{j} (x,t)),R^{e}(x,t,_{j}(x,t)))\|_{2}^{2}x t\] (9)

The NN component is adapted as in section 4.1 through a \(^{e}\) parameter context vector. For estimating the PDE coefficients, we considered two alternatives. One consists in using the learned code \(^{e}\) for adapting the physical parameters \(_{p}^{e}=_{p}+W_{p}^{e}\), where \(_{p},W_{p}\) are shared parameters across all environments. The second one directly learns the parameters \(_{p}^{e}\) for each environment by gradient descent on the loss function. In the first approach, only context vectors \(^{e}\) are learned while in the second approach, \(^{e}\) and \(_{p}^{e}\) are learned jointly during adaptation. The performance of the two methods are similar. For the experiments, we evaluated both and used the better-performing one.

## 5 Experiments

### Dynamical systems

We performed experiments on four dynamical systems, including one ODE and 3 PDEs. The ODE models the motion of a pendulum, which can be subject to a driving or damping term. We consider a Large Eddy Simulation (LES) version of the Burgers equation, a common equation used in CFD where discontinuities corresponding to shock waves appear (Basdevant et al., 1986). We additionally study two PDEs on a 2D spatial domain: Gray-Scott (Pearson, 1993), a reaction-diffusion system with complex spatio-temporal patterns and a LES version of the Kolmogorov flow, a 2D turbulence equation for incompressible flows. For the pure data-driven approaches, we make no prior assumption on the underlying physics, while for the physics-aware hybrid modeling problem, we assume that the physical equation is partially known and that the deep learning component targets the modeling of the unknown terms (details on the known/unknown terms for each equation are provided in Appendix B). The setting is the classical IVP formulation when only one initial state \(_{0}^{c}\) is provided.

### Evaluation Setting

While in section 3 we compared GEPS with baselines ERM approaches and with a foundation model, our objective here is to assess the performance of GEPS w.r.t. alternative adaptation based approaches. We evaluate the model performance on two key aspects. \(\)**In-distribution generalization**: the model capability to predict trajectories defined by unseen ICs on all training environments \(e_{}\), referred as _In-d_. \(\)**Out-of-distribution generalization**: the model ability to adapt to a new environment \(e_{}\) by predicting trajectories defined by unseen ICs, referred as _Out-d_. Each environment \(e\) is defined by changes in system parameters, forcing terms or domain definition. \(d_{p}\) represents the degrees of variations used to define an environment for each PDE equation; \(d_{p}=4\) for the pendulum equation, \(d_{p}=3\) for the 1D Burgers, \(d_{p}=2\) and \(d_{p}=3\) for the Gray-Scott and the Kolmogorov flow equation respectively (more details in Table 4 in Appendix B). For each dataset, we collect \(N_{}\) trajectories per training environment. For adaptation, we consider \(N_{}=1\) trajectory per new environment in \(_{}\) to infer the context vector \(c^{e}\). Evaluation is performed on 32 new test trajectories per environment. We report in Table 2 the relative MSE: \(_{i=1}^{N}-y_{i}\|_{2}^{2}}{\|y_{i}\|_{2}^{2}}\).

### Generalization results

ImplementationWe used a standard MLP for the Pendulum equation, a ConvNet for GS and Burgers equations and FNO for the vorticity equation. All activation functions are Swish functions. We use an Adam optimizer over all datasets. Contrary to Section 3, we perform time-integration with a NeuralODE (Chen, 2018) with a RK4 solver, as it was done for other multi-environments frameworks for physical systems (Yin et al., 2022; Kirchmeyer et al., 2022). Architectures and training details are provided in Appendix E.

BaselinesAs baselines, for the pure data-driven problem, we consider four families of multi-environment approaches. The first one consists in gradient-based meta-learning methods with CAVIA (Zintgraf et al., 2019) and FOCA (Park et al., 2023). The second one is a multi-task learning method for dynamical systems: LEADS (Yin et al., 2022). The third one is a hyper-network-based meta-learning method which is currently SOTA among the adaptation methods, CoDA (Kirchmeyer et al., 2022). As for the hybrid physics-aware problem, we implemented a meta-learning formulation of the hybrid method APHYNITY (Yin et al., 2021), where the adaptation is performed on the physical PDE coefficients only while the NN component is shared across all the environments. GEPS-Phy is our physics-aware model (section 4.3) were all the parameters, PDE coefficients and context vector \(^{e}\) are adapted at inference. We also implemented "Phys-Ad", where we use the same formulation as for the hybrid GEPS-Phy, but adaptation is performed on the coefficients of the physical component only while the neural network component is shared across all environments. All the baselines share the same network architectures than the ones used for GEPS, indicated in the implementation paragraph above. More details on baselines implementation are provided in Appendix E.6.

In-distribution and out-of-distribution resultsWe report results for in and out-of-distribution generalization in table 2 for both the data-driven and the hybrid settings. Across all datasets, our framework performs competitively or better than the baselines for the two settings. Our method is able to correctly adapt to new environments in an efficient manner, updating only context parameters \(c^{e}\). For the agnostic data-driven experiments, GEPS obtains the best results, although being on the same range of performance as other methods.

_The main differentiator of GEPS w.r.t. the baselines lies in its lower complexity_. In terms of training time, GEPS is way less expensive than gradient-based approaches like CAVIA that involves an outer and inner loop and LEADS, which learns a model specific to each environment. In terms of number of parameters, CoDA needs more training parameters because of its adaptation mechanism relying on a hyper-network. A comparison with the baselines in terms of parameter complexity is provided in table 10. Additional results in Appendix D, show that our data-driven framework adapts faster than the strong baseline CoDA. Concerning the hybrid learning problem, incorporating physical knowledge leads to better results on all datasets except Burgers, where the fully data-driven method performs better. GEPS-Phy is better on all the datasets but Gray-Scott for which APHYNITY baseline is best. For Kolmogorov, the baselines did not converged at training.

### Scaling to a larger dataset

To further illustrate the benefits of GEPS, we compare it to CoDA, the SOTA adaptation model, on a large dataset with a larger model than the ones used for the previous experiments. We use a dataset generated from a PDE with multiple differentiable terms that encompasses several generic PDEs, inspired from Brandstetter et al. (2022). The PDE writes as (more details in Appendix B):

\[[_{t}u+_{x}( u^{2}-_{x}u+_{ xx}u+_{xxx}u)](t,x)=0,\] (10)

We report the results in table 3. All the methods are trained using a ResNet (He et al., 2016) architecture, using a context size \(^{e}\) of size 8. For _In-d_, we trained our model on 1200 environments with 16 training trajectories per environment and evaluated it on 16 new trajectories. For _Out-d_, we further adapt each model to 10 new environments given 1 context trajectory per environment and then evaluate it on 16 new trajectories per environment.

GEPS outperforms CoDA in terms of performance and number of parameters. This demonstrates the importance of scalable adaptation for few shot learning: GEPS is able to scale on large datasets using deep models while remaining parameter efficient.

## 6 Discussion and limitations

LimitationsWe have seen that adaptation is essential for learning to generalize neural PDE solvers, and that within this setting, integrating physical knowledge may help. Adaptation still requires sufficient training samples - both environments and trajectories. These findings are still to be confirmed for more complex dynamics and real world conditions for which the variety of behaviors should be much larger than for the simple dynamics we experimented with.

ConclusionWe empirically demonstrated the importance of adaptation for generalizing to new environments and its superiority with respect to ERM strategies. We proposed a new \(1^{st}\) order and low-rank scalable meta-learning framework for learning to generalize time-continuous neural PDE solvers in a few-shot setting. We also highlighted the benefits of directly embedding PDE solvers as hard constraints in data-driven models when faced with scarce environments.

  
**Method** & \))**} & \))**} & \))**} & \))**} \\   & _In-d_ & _Out-d_ & _In-d_ & _Out-d_ & _In-d_ & _Out-d_ & _In-d_ & _Out-d_ \\  _Data-driven_ & & & & & & & & \\ LEADS & \(20.8 1.01\) & \(51.1 3.47\) & \(3.11 0.25\) & \(3.81 0.77\) & \(6.31 0.52\) & \(64.1 2.65\) & \(5.61 0.37\) & \(9.18 0.14\) \\ CAVIA & \(56.8 9.73\) & \(91.8 15.8\) & \(1.63 3.82\) & \(23.1 6.86\) & \(15.5 1.06\) & \(225 7.94\) & \(6.19 0.02\) & \(8.48 0.16\) \\ FOCA & \(41.0 4.31\) & \(91.4 9.70\) & \(1.71 5.10\) & \(14.5 3.34\) & \(92.2 8.21\) & \(157 2.36\) & \(6.30 0.02\) & \(9.18 0.14\) \\ CoDA & \(21.7 1.08\) & \(66.2 3.17\) & \(3.19 0.07\) & \(2.89 4.03\) & \(4.98 0.19\) & \(74.5 6.15\) & \(4.02 0.57\) & \(6.34 1.11\) \\ _GEPS_ & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\ _Hybrid_ & & & & & & & & \\ APHYNITY & \(67.2 9.68\) & \(69.0 0.35\) & \(\) & \(\) & \(31.9 0.08\) & \(307 1.40\) & – & – \\ Phys-Ad & \(64.4 1.10\) & \(58.4 1.85\) & \(1.55 1.41\) & \(1.82 6.42\) & \(15.1 0.10\) & \(89.9 8.65\) & – & – \\ _GEPS-Phy_ & \(\) & \(\) & \(0.67 0.05\) & \(0.83 0.05\) & \(\) & \(\) & \(\) & \(\) \\   

Table 2: **In-distribution and Out-of-distribution results on 32 new test trajectories per environment**. For out-of-distribution generalization, models are fine-tuned on 1 trajectory per environment. Metric is the relative L2 loss. ’-’ indicates inference has diverged.

  
**Method** & \))**} \\   & _In-d_ & _Out-d_ & \(\#\)_Params_ \\  GEPS & 7.52e-3 & 8.29e-2 & 4M \\ CoDA & 9.32e-2 & 1.78e-1 & 35M \\   

Table 3: **In-distribution and Out-distribution results**. Metric is the relative L2.

Acknowledgments

We acknowledge the financial support provided by DL4CLIM (ANR-19-CHIA-0018-01), DEEPNUM (ANR-21-CE23-0017-02), PHLUSIM (ANR-23-CE23-0025-02), and PEPR Sharp (ANR-23-PEIA-0008, ANR, FRANCE 2030).