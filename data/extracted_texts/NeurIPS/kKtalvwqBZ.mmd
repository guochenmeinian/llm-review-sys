# Benchmarking Structural Inference Methods for

Interacting Dynamical Systems with Synthetic Data

 Aoran Wang \({}^{1}\) Tsz Pan Tong \({}^{1}\) Andrzej Mizera \({}^{2}\) Jun Pang \({}^{1}\)

\({}^{1}\) University of Luxembourg \({}^{2}\) IDEAS-NCBR & University of Warsaw

{aoran.wang, tszpan.tong, jun.pang}@uni.lu andrzej.mizera@ideas-ncbr.pl

Equal first contributions

###### Abstract

Understanding complex dynamical systems begins with identifying their topological structures, which expose the organization of the systems. This requires robust structural inference methods that can deduce structure from observed behavior. However, existing methods are often domain-specific and lack a standardized, objective comparison framework. We address this gap by benchmarking 13 structural inference methods from various disciplines on simulations representing two types of dynamics and 11 interaction graph models, supplemented by a biological experimental dataset to mirror real-world application. We evaluated the methods for accuracy, scalability, robustness, and sensitivity to graph properties. Our findings indicate that deep learning methods excel with multi-dimensional data, while classical statistics and information theory based approaches are notably accurate and robust. Additionally, performance correlates positively with the graph's average shortest path length. This benchmark should aid researchers in selecting suitable methods for their specific needs and stimulate further methodological innovation.

Project website: https://structinfer.github.io/.

## 1 Introduction

Dynamical systems pervade various domains, from gravitational interactions among galaxies to intricate chemical reactions. A common characteristic of these systems is their representation as interaction graphs, where nodes symbolize agents, edges depict interactions, and the adjacency matrix encapsulates the underlying structure. Examples of inherent interaction graphs are found in physical systems [61; 42; 111], multi-agent systems [15; 62], and biological systems [102; 85]. Understanding the structure of these interaction graphs is crucial as it enhances predictability and manipulability of dynamical systems, despite the complexity of the task .

Often, only observable node attributes within a specific timeframe are available, partially or fully obscuring the interaction graph's underlying structure amid dynamic complexities. This necessitates an approach to uncover the hidden structure of dynamical systems through observable features, leading to the concept of _structural inference_. Here, the compilation of observed features over time, termed a _trajectory_, is crucial for understanding dynamical systems. Unraveling the graph's structure simplifies interaction modeling, especially when the graph dimensions and interactions are known and time-independent.

Structural inference, rooted in statistics, has evolved significantly within the Bayesian network framework, prompting numerous algorithm proposals [70; 100; 101; 89; 25]. Notable advancements, such as in genome sequencing , have enabled the study of gene expression and regulatory mechanisms, fostering various structural inference methods for gene regulatory networks (GRNs) [71;33, 52, 46, 2, 72, 80]. Conversely, recent deep learning approaches focus primarily on general dynamical systems .

Existing methods are often evaluated on distinct datasets and specific graph types, each tailored to different research domains with unique underlying assumptions. To address this fragmentation, we developed the Dataset for Structural Inference (DoSI), featuring a variety of interaction graphs and dynamical transition functions. We then established a unified and impartial benchmark to evaluate a broad range of techniques across diverse domains. This benchmark assesses established and cutting-edge methods using over 213,445 trajectories from both the meticulously curated DoSI and real-life biological datasets. These datasets include both one-dimensional and multi-dimensional trajectories, further enriched with varying levels of Gaussian noise to simulate real-world conditions.

This pioneering benchmark, requiring over 706,800 CPU hours and 263,400 GPU hours, allows us to rigorously evaluate the accuracy, scalability, robustness, and data efficiency of these methods. Our findings reveal that classical statistic methods are scalable and reliable across various datasets, information theory-based methods are notably robust, and deep learning methods excel in handling multi-dimensional features. This comprehensive evaluation offers valuable insights and sets the stage for future advancements in structural inference research. In summary, the contributions are:

* We developed the Dataset for Structural Inference, a versatile dataset featuring a range of interaction graphs and dynamical functions to facilitate broad applicability in structural inference research.
* The study introduces a unified and impartial benchmark that evaluates 13 structural inference methods using over 213,445 trajectories from synthetic and real-life datasets, encompassing both one-dimensional and multi-dimensional data.
* The benchmark provides comprehensive insights, revealing that classical statistical methods excel in scalability, information theory-based methods in robustness, and deep learning methods in handling complex multi-dimensional features.
* The findings from this extensive evaluation not only enhance our understanding of different structural inference approaches but also set the groundwork for future innovations to tackle dynamic and noisy systems.

## 2 Preliminaries

In this section, we delve into the intricacies of structural inference of dynamical systems. We conceptualize a dynamical system as a directed underlying interaction graph, wherein the system's agents translate to nodes, and the directed interactions among these agents manifest as edges in the graph. Denoted as \(=(,)\), the directed graph consists of \(\), the feature set of \(n\) nodes represented by \(\{V_{i},1 i n\}\), and \(\), the set of edges. The temporal evolution of nodes' features is encapsulated in trajectories: \(=\{V^{0},V^{1},,V^{T}\}\), spanning \(T+1\) time steps, with \(V^{t}\) signifying the feature set of all \(n\) nodes at time step \(t\): \(V^{t}=\{V^{t}_{0},V^{t}_{1},,V^{t}_{n}\}\). The feature vector at time \(t\) for node \(i\), denoted as \(V^{t}_{i}^{n},1 t T\), is n-dimensional.

In our assumptions, the nodes are observed in their entirety, and \(\) remains immutable during the observation. From \(\), we derive an asymmetric adjacency matrix denoted as \(^{n n}\). Within \(\), each element \(_{ij} 0,1\) indicates the presence (\(_{ij}=1\)) or absence (\(_{ij}=0\)) of an edge from node \(i\) to node \(j\). An alternative representation for the graph structure is an edge list, where each entry \([i,j]\) in the list signifies a directed edge originating from node \(i\) and terminating at node \(j\). Given the node features observed over a time interval in \(\), the primary focus of this paper centers on the challenge of structural inference. This challenge involves the unsupervised reconstruction of either the asymmetric adjacency matrix \(\) or the edge list that encapsulates the underlying interaction graph. It is important to note that this problem is distinct from link prediction tasks, where connections are at least partially observable .

## 3 Methods for structural inference

### Methods based on classical statistics

Statistical methods prioritize inference accuracy and uncertainty. Its results are interpreted conservatively, making it widely applicable across diverse scenarios:

\(\)**ppcor**: ppcor method computes semi-partial correlations between pairs of nodes, quantifying the specific portion of variance attributed to the correlation between two nodes while accounting for the influence of other nodes. This computation draws on both Pearson and Spearman correlations.

* **TIGRESS**: Contrasting with other structural inference methods, which remove redundant edges from predicted edges, TIGRESS focuses on feature selection by iteratively adding more nodes to predict the target node using least angle regression and bootstrapping.

### Methods based on information theory

Mutual information (MI) is a probabilistic measure of dependency described by the equation: \(I(X;Y)=H(X)+H(Y)-H(X,Y)\), where \(X,Y\) are random variables, \(H()\) and \(H(,)\) are the entropy and joint entropy, respectively. MI possesses the ability to capture nonlinear interactions , rendering it widely used in various fields including neuroscience [83; 55], bioinformatics , and machine learning . However, despite direct interactions, indirect interactions and data noise can introduce complexity and challenges. Different methods were proposed to tackle this problem:

* **ARACNe**: ARACNe is a popular method for GRN inference. The algorithm is initiated by calculating pairwise MI and subsequently employing the Data Processing Inequality principle to eliminate indirect interactions. This principle posits that the MI between two nodes connected by an indirect interaction should not surpass the MI of either node connected directly to a third node.
* **CLR**: Similar to ARACNe, CLR employs pairwise MI but differs in the interpretation of calculated MI. CLR relies on assuming a background noise distribution for MI and subsequently identifies interactions as MI outliers after both row- and column-wise standardization.
* **PIDC**: Partial Information Decomposition (PID)  undertakes the decomposition of MI into redundant, synergistic, and unique information. PIDC adopts the concept of PID to GRN inference and interprets aggregated unique information as the strength of gene interaction.
* **Scribe**: Scribe utilizes Restricted Directed Information  and its variants  to quantify causality within the structure by considering the influence of confounding factors.

### Methods based on tree algorithms

The decision tree is a powerful supervised method that divides the feature space into subspaces and uses linear regressions within each. Despite its versatility across data types , decision trees can overfit, prompting strategies like boosting and bagging. Examples include AdaBoost , random forests , extremely randomized trees , XGBoost , and LightGBM . Yet, applying tree-based methods directly to structural inference is constrained by the unsupervised task nature. GENIE3 , using random forests, addresses this, succeeding in modeling GRNs. GENIE3 models gene dynamics using other genes' behavior, revealing how supervised methods can aid structural inference.

* **dynGENIE3**: dynGENIE3 extends GENIE3 by concentrating on the temporal aspect, employing ordinary differential equations (ODEs) to model time series dynamics. In this approach, a random forest is employed for each gene to capture the derivatives within the time series.
* **XGBGRN**: XGBGRN aligns with the principles of dynGENIE3, though it diverges in its choice of algorithm. Specifically, XGBGRN leverages XGBoost, in place of random forests, to model the derivatives of the time series data.

### Methods based on deep learning

Contemporary structural inference methods [58; 68; 19; 106] leverage the information bottleneck (IB) principle [99; 98; 94] and variational autoencoders (VAEs), a form of variational IB approximation . As outlined in , these VAE-based methods solve: \(=_{}I(;V^{t},)-  I(;V^{t+1})\), where \(\) is the latent feature space, \(V^{t}\) represents node features at time \(t\), \(\) is the adjacency matrix, and \(\) is the Lagrangian multiplier. This approach extracts the dynamical system's structure through VAE sampling. Extensions to this framework [78; 120] incorporate architectural designs in graph neural networks and diffusion models to better suit data characteristics. Moreover, neural networks enable handling both one-dimensional and multi-dimensional features, unlike earlier non-deep learning methods focused on one-dimensional features. Prominent deep learning structural inference methods encompass:

* **NRI**: NRI stands as a pioneering method that employs a VAE for structure inference. Its encoder integrates node-to-edge and edge-to-node processes to collect node features and acquire edge features. In this context, NRI assumes a fixed fully connected \(\) within the encoder.

* **ACD**: ACD introduces a probabilistic approach to amortized causal discovery to learn the causal graph from time series. This method also addresses latent confounding issues by predicting an additional variable and implementing structural bias.
* **MPM**: MPM, distinct from typical message-passing approaches, utilizes relational interaction in the encoder and spatio-temporal message-passing in the decoder. This alteration comprehensively captures relationships and enhances the grasp of dynamical rules.
* **iSIDG**: iSIDG diverges from other VAE-based methods by iteratively updating **A** based on direction information deduced from the adjacency matrix. Its goal centers on inferring the authentic interaction graph by removing indirect edges that contribute to confusion.
* **RCSI**: RCSI, a variant of iSIDG, incorporates reservoir computing units that concentrate on time series prediction, enabling the VAE to prioritize structure inference. This modification significantly reduced the number and length of trajectories required for training.

### More related works

Besides the methods previously discussed, fMRI decomposes the inferred interaction graph into a multiplex graph, with each layer signifying a distinct interaction type . MetaNRI employs modular meta-learning to implicitly encode time invariance and contextually infer relationships . In the adjacent field of causal structural discovery, many methods necessitate interventional data or rely on strong assumptions that may not be suitable for our settings [121; 27; 16; 40; 114; 53; 113; 13; 21]. Recent approaches like LOCS  and Aether  offer structural inference techniques for hybrid dynamical systems, while Graph-Switching Dynamical Systems  and Amortized Equation Discovery  target systems with switching dynamics. Methods like REDSDS  and recurrent SLDS  also contribute to the growing pool of structural inference techniques by focusing on systems with latent switching behavior. As we are updating the benchmark with more recent papers, we will include these methods in the near future. While this paper does not exhaust all methods, such as [117; 23], we recommend that researchers use our datasets to benchmark their approaches.

**Other benchmarks for structural inference.** This study is, to our knowledge, the first to introduce a unified, objective, and reproducible benchmark for structural inference in interacting dynamical systems. Prior benchmarks have been domain-specific, addressing areas such as GRNs in single-cell data [9; 84; 119], gene co-expression networks [22; 77], map inference algorithms [14; 1; 18], chemical reaction networks [67; 11], and functional connectivity [24; 66]. Although benchmarks in causal discovery exist [6; 74], they operate under different assumptions. Notably, the closest related work  primarily focuses on time-series forecasting. Our benchmark distinguishes itself by offering a comprehensive, cross-domain framework that advances structural inference methodologies and enables meaningful comparisons across diverse approaches.

## 4 Datasets for benchmarking

While domain-specific datasets like Boolean models and miRNA-target genes datasets exist for structural inference [84; 22], they are often too specialized, limited in size, or challenging to interpret. This highlights a significant gap for a unified, interpretable dataset in the field. To address this, we developed the **D**ataset **for** **S**tructural **I**nference (DoSI), which involves 1) creating interaction graphs and 2) simulating dynamical systems, detailed in subsequent sections. Additionally, we incorporated a real-world biological dataset to not only demonstrate the practical applicability of structural inference methods but also to highlight the dataset's limitations.

### Underlying interaction graphs of DoSI

Our primary goal is to use synthetic data to evaluate structural inference methods, taking into account the diversity in structure and characteristics of underlying interaction graphs. We referenced existing literature [8; 7; 32] to gather properties from 11 types of real-world graphs, including brain networks (BN), chemical reaction networks in the atmosphere (CRNA), food webs (FW), gene coexpression networks (GCN), gene regulatory networks (GRN), intercellular networks (IN), landscape networks (LN), man-made organic reaction networks (MMO), reaction networks inside living organisms (RNLO), social networks (SN), and vascular networks (VN). These graphs' properties--such as clustering coefficient \(C\), average shortest path length \(d\), the power-law exponent of the degree distribution \(\), average degree \( k\), density \(\), and if available, the power-law exponent of the in-/out-degree distribution \(^{}\) and \(^{}\) -are detailed in Table 1 in the Appendix.

This table shows significant variability in graph properties, underscoring the importance of mimicking this diversity in our synthetic graph generation to effectively evaluate structural inference methods. The size of these graphs, ranging from 15 to 250 nodes, also influences method performance. Tailored creation pipelines for different graph types, based on these properties and structural biases from literature [58; 19; 68; 106], are further discussed in Appendix B.1.

### Dynamical systems

In DoSI, we use the generated graphs as interaction graphs to simulate dynamical systems, where node features evolve over time and are influenced by both the interaction graph and the dynamic function. The interaction graph determines which nodes interact, and the dynamic function quantifies these interactions' impact. We utilize two common simulations, "Springs" and "NetSims" [19; 58; 68; 106; 108], to generate trajectories. We detail the functionality of these simulations, modifications for our purposes, and the generation of trajectories with varying Gaussian noise levels. Additionally, we prepare an experimental biological dataset to evaluate the effects of noise and imperfections in data collection. The method of preparing this dataset through trajectory reconstruction is detailed as well. For further information on the dynamical simulations, please see Appendix B.2 and B.4.

**Springs simulation.** Inspired by prior work , we simulate the motion of spring-connected particles within a 2D box. Particles (nodes) are interconnected by springs (edges) adhering to Hooke's law. We use interaction graphs to set up these connections and generate trajectories with various initial conditions. The dynamics are governed by a second-order ODE, simplified here for clarity:

\[m_{i} x_{i}^{}(t)=_{j_{i}}-kx_ {i}(t)-x_{j}(t),\] (1)

where each node's mass \(m_{i}\) is assumed to be \(1\), and the spring constant \(k\) is also set to \(1\). \(_{i}\) refers to the set of neighboring nodes with directed connections to node \(i\). We integrate this equation to compute \(x_{i}^{}(t)\) and subsequently \(x_{i}(t)\) for each time step. The sampled values of \(x_{i}^{}(t)\) and \(x_{i}(t)\) form the 4D node features. We produce trajectories with 49 time steps for training and validation, and 100 for testing, resulting in 8,000 training, 2,000 validation, and 2,000 test trajectories per graph.

**NetSims simulation.** This simulation models brain activity data using nodes that represent brain regions, and edges that define interactions based on prior interaction graphs . The dynamics follow a first-order ODE:

\[x_{i}^{}(t)=_{j_{i}}x_{j}(t)- x _{i}(t)+C u_{i},\] (2)

where \(\) controls temporal smoothing and is set to \(0.1\), and \(C\), the interaction weight, is zero to minimize noise. The 1D node features at each time step are formed using the sampled \(x_{i}(t)\). We generate trajectories under conditions similar to those of the Springs simulation.

To this end, our benchmark includes two types of dynamical systems modeled by first-order ODEs (NetSims) and second-order ODEs (Springs), covering a broad spectrum of real-world phenomena from motion dynamics to single-cell behavior. Additionally, with the inclusion of 'Charged Particles' detailed in Appendix 6.4, we address systems influenced by quadratic dependencies like electrostatic and gravitational forces, further expanding the applicability of our benchmark. Each dynamical system chosen aims to represent a comprehensive category of real-world systems.

**Addition of Gaussian noise.** Furthermore, to assess the performance of the structural inference methods under noisy conditions, we add Gaussian noise at various levels to the generated trajectories. The node features with added noises \(_{i}^{t}\) can be summarized as: \(_{i}^{t}=v_{i}^{t}+ 0.02,(0,1)\), \(v_{i}^{t}\) is the original feature vector of node \(i\) at time \(t\), and \(\) is the noise level. The noise levels range from 1 to 5 to all the original trajectories.

**EMT dataset.** To compare model performance between synthetic and real-world data, we applied benchmarking models on a single-cell RNA sequencing (scRNA-seq) dataset from an epithelial-mesenchymal transition (EMT) study, originally collected by Cook and Vanderhyden  and processed by Sha et al. . This dataset includes 3,133 cells and 3,000 genes, sampled across 5time points in 7 days. Using the STRING database , we identified the interaction network of the top 50 high-variance genes, serving as the ground-truth GRN. After removing isolated components, the network was reduced to 36 nodes with 103 edges. Trajectories were reconstructed using Waddington-OT  and interpolation methods, resulting in 577 trajectories of 22 time steps each. Detailed dataset construction information is available in Appendix B.4.

## 5 Benchmarking setup

To compare the structural inference methods in a unified, objective, and reproducible manner across different domains, we design three sets of experiments:

1. **Evaluation on original Trajectories**: This assesses methods using original, noise-free trajectories to understand how the properties of the underlying interaction graph affect inference results.
2. **Scalability analysis**: Following initial evaluations, this experiment tests the scalability of methods by analyzing their performance with varying computational resources and graph sizes.
3. **Evaluation on noisy trajectories**: Methods are tested against trajectories with different levels of Gaussian noise to determine their robustness.

Additionally, we explore the data efficiency of these methods by evaluating their performance on shorter trajectories, with results detailed in Appendix D.3. Note that methods based on classical statistics, information theory, and tree algorithms are evaluated only with one-dimensional trajectories due to compatibility issues with multi-dimensional features.

For performance metrics, we use the Area Under the Receiver Operating Characteristic curve (AUROC), which measures inference accuracy and the ability to distinguish true from false edges in the interaction graph. We ensure robust evaluation by averaging results from three runs of each method on labeled trajectory sets and performing an additional run on the set with the lowest AUROC value. AUROC is chosen over other metrics like accuracy, F1 score, and Hamming distance due to its effectiveness in handling imbalanced datasets and providing a comprehensive performance assessment at various thresholds (see Appendix D.4 for more on metric selection).

Additionally, we introduce the "Charged Particles" dataset, which simulates multi-dimensional trajectories governed by Coulomb force, tailored for deep learning models due to its complexity. This dataset contrasts with the Springs simulation's Hooke's law dynamics by featuring sophisticated ejection and entanglement dynamics (see Appendix 6.4 for details and benchmarking results). We also evaluate the performance of structural inference methods on the EMT dataset, a single-cell RNA sequencing dataset, with findings discussed in Appendix D.5.

Figure 1: Results of investigated methods clustered by the type of interaction graphs and the correlations with the graph properties.

Benchmarking results

### Benchmarking over different interaction graphs

To evaluate the structural inference methods discussed in Sections 3.1 - 3.4, we conducted tests on trajectories generated using all 11 types of underlying interaction graphs described in Section 4.1. These tests included both types of simulations and were executed without any added noise. Despite using Tesla V100 GPU cards and facing computational limits, we successfully processed graphs up to 100 nodes, with a total of 706,816 CPU hours and 263,473 GPU hours.

Appendix C details the implementation of each method, including computational resources and hyperparameter optimization. Additionally, this section presents a clustering analysis of the AUROC results by interaction graph type and simulation, displaying average AUROC values in Fig. 0(a) and providing detailed data in Appendix D.1. Fig. 0(b) presents a heatmap showing correlations between the methods' average AUROC values and the properties of the interaction graphs, using terminologies from Section 4.1.

Deep learning methods like NRI and ACD exhibit superior performance on multi-dimensional data, which is especially evident when comparing the Springs and NetSims simulations. For example, NRI shows a 46.35% higher AUROC on gene cocpression networks, and ACD shows a 34.30% increase on landscape networks, as seen in Fig. 0(a). These results highlight that multi-dimensional features provide a wealth of information, enhancing the effectiveness of these methods in structural inference by leveraging the complex interrelationships between different feature dimensions. Conversely, classical statistical methods such as ppcor and TIGRESS demonstrate remarkable consistency across various graph types, maintaining medium to high ranks across datasets. Their stable performance, illustrated in Fig. 0(a), underscores their robustness and adaptability, making them reliable choices for scenarios where interaction graph structures do not match more complex or specialized models.

The correlation between the performance of structural inference methods and the properties of interaction graphs, as shown in Fig. 0(b), reveals key insights. Generally, there is a positive correlation with the average shortest path length and a negative correlation with the average degree of the graphs. This indicates that methods perform better on sparser graphs with longer path lengths, where the simpler connections likely enhance method effectiveness. In contrast, denser graphs with high connectivity and shorter path lengths reduce performance, possibly due to increased complexity and noise, which can mask the underlying structures these methods seek to discern.

### Benchmarking over scalability

Using the raw results from Section 6.1, we conducted a clustering analysis based on the number of nodes in the interaction graphs to assess the scalability of the structural inference methods. The outcomes of this analysis are displayed in Fig. 2.

The performance of the majority of the methods tends to deteriorate as the dynamical systems increase in size, as demonstrated by a consistent trend in Fig. 2. Notably, PIDC and dynGENIE3 show improved inference results for larger systems, suggesting that these methods can effectively utilize the increased information available in larger graphs. This indicates that while larger systems provide more data, extracting and leveraging this information efficiently remains critical for enhancing method performance.

Deep learning methods show a significant sensitivity to graph size compared to classical statistical methods. The smallest decrease in AUROC among deep learning methods is 7.94%, in stark contrast to classical methods like ppcor, which only shows a 0.71% decrease when comparing graphs with 100 nodes to those with 15 nodes. This illustrates the scalability challenges for deep learning methods, despite their versatility in handling diverse feature types.

Figure 2: Average AUROC values (in %) of structural inference methods on noise-free trajectories, clustered by the number of nodes in graphs and the type of simulations.

Moreover, classical statistical methods such as ppcor and TIGRESS prove to be highly scalable, maintaining stable performance across various graph sizes. Their consistent performance across different node counts, combined with their robustness across diverse interaction graphs, underscores their reliability among the evaluated structural inference methods.

### Benchmarking over robustness

The robustness of structural inference methods is crucial for real-world applications, where data often contain noise. To evaluate this robustness, we generated noisy trajectories using NS_BN with varying levels of Gaussian noise. The differences in AUROC values between noisy and noise-free data, denoted as \(\)AUROC, along with their standard deviations, are summarized in Fig. 3 and detailed in Appendix D.3.

Deep learning methods, while maintaining consistently low standard deviations, exhibit a decline in average performance under noisy conditions. This pattern suggests that deep learning methods may struggle to differentiate between noise effects and genuine data perturbations, leading to decreased performance as noise levels increase.

### Benchmarking with Charged Particles

We observed that the two dynamic simulations do not encompass a prevalent type of real-world dynamical system characterized by quadratic dependencies. To address this gap, we introduce a third simulation of dynamical systems, grounded in the Coulomb force interactions among charged particles, and we have named it the "Charged Particles" simulation.

**Simulation of Charged Particles**. We simulate the movement of charged particles within a 2D enclosure, where nodes represent particles and edges symbolize the Coulomb forces acting between pairs of particles. Unlike the Springs and NetSims simulations, the Charged Particles simulation entails a unique approach: all nodes are interconnected, and none of the 11 types of generated underlying interaction graphs are employed. Consequently, every pair of nodes interacts, even if the interaction might be weak when the nodes are distant. These interactions involve either attraction or repulsion. Drawing inspiration from  and following a concept akin to the Springs simulation, our simulation involves \(N\) particles (point masses) located within a 2D enclosure and subject to no external forces. The parameter \(N\) is chosen from the set \(15,30,50,100\). The simulation accounts for elastic collisions with the boundary of the enclosure. The particles carry charges \(q_{i} q\), sampled uniformly at random. The inter-particle interactions are governed by Coulomb forces, defined as \(F_{ij}(t)=C(q_{i} q_{j})(t)-x_{j}(t) \|^{2}}\), with a constant \(C\) set to \(1\). Here, \(F_{ij}(t)\) denotes the force exerted on particle \(i\) by particle \(j\) at time \(t\), and \(x_{i}(t)\) represents the 2D location vector of particle \(i\) at time \(t\). So the adjacency matrix \(\) in this simulation is formed as a matrix with each element \(a_{ij}\) in it as either \(+1\) or \(-1\), where \(a_{ij}=+1\) stands for repelling between node \(i\) and \(j\), while \(a_{ij}=-1\) stands for attracting between node \(i\) and \(j\). The dynamics of the Charged Particles simulation are

Figure 3: Performance drops (in %) on BN trajectories with different levels of added Gaussian noise.

encapsulated in an ODE characterized by quadratic dependencies on particle locations, expressed as:

\[m_{i} x_{i}^{}(t)=_{j_{i}}C(q_{ i} q_{j})(t)-x_{j}(t)\|^{2}},\] (3)

Here, \(m_{i}\) represents the mass of node \(i\), assumed to be \(1\) for simplicity. \(_{i}\) refers to the set of neighboring nodes with connections to node \(i\). Here it represents all nodes in the system. The equation is integrated to compute \(x_{i}^{}(t)\), and subsequently, \(x_{i}(t)\) is determined for each time step. These calculated values of \(x_{i}^{}(t)\) and \(x_{i}(t)\) collectively constitute the 4D node features at each time point. Initially, the positions are drawn from a Gaussian distribution \((0,0.5)\), while the initial velocities, represented as 2D vectors, are randomly generated with a norm of \(0.5\). With these initial positions and velocities in the 2D plane, trajectories are simulated using the solutions to Eq. 3. The simulation employs leapfrog integration with a small time step size of 0.001 seconds, and the trajectories are sampled at intervals of 100 minor time steps. As a result, the feature representation of each node at each time step consists of a 4D vector encompassing 2D positions and 2D velocities.

The simulation's design ensures that the next value of a particle's feature depends on its present value and interactions with other particles. Utilizing a set of initial positions and velocities, we generate trajectories for the current interacting dynamical system, encapsulating the feature vectors of all particles within the designated time frame. Specifically, trajectories comprising 49 time points (obtained through integration over 4,900 minor time steps) are generated for training and validation purposes. For testing, trajectories with 100 time steps are generated, aligning with the requirements in . To ensure robustness, a total of 8,000 trajectories are generated for training, along with 2,000 for validation and 2,000 for testing. This process is repeated thrice, yielding three sets of trajectories with the same node count but distinct initializations.

**Implementation of Structural Inference Methods**. For methods reliant on deep learning, we maintain uniform settings akin to those utilized for the Springs simulation trajectories. Furthermore, we configure the parameter "edge_types" to a value of two, aligning with the requirement to infer the two distinct edges corresponding to \(a_{ij}= 1\). However, it's crucial to note that the remaining methods are tailored explicitly for structural inference tasks involving trajectories featuring one-dimensional attributes. Regrettably, their respective literature lacks both theoretical and practical guidelines pertaining to adapting these methods for trajectories characterized by multi-dimensional attributes. Additionally, these methods inherently lack the capability to deduce multiple edge types, thereby restricting their applicability in this context. Consequently, the deep learning structural inference methods were exclusively employed for the analysis of the Charged Particles dataset.

**Results**. Figure 4 provides a comprehensive summary of the average AUROC values and standard deviations for each method across various node counts within the graph. A comparison of these results with those from the Springs dataset reveals that while all methods continue to successfully infer the structure of the underlying interaction graphs, their performance is relatively diminished in this case. The reason lies in the increased complexity of the task, as the methods are now required to infer two distinct edge types, which inherently poses a greater challenge. Moreover, it is noteworthy that the performance of all methods is influenced by the number of nodes present within the graph, corroborating with Section 6.2. The sensitivity to node count underscores the intricate interplay between the size of the graph and the efficacy of the methods. In light of the presented data, it becomes evident that the feasibility of deep learning methods in the structural inference of dynamical systems governed by quadratic dependencies on locations is empirically substantiated.

## 7 Conclusion

In this study, we benchmarked 13 structural inference methods using trajectories from two types of dynamical simulations and various underlying interaction graphs, assessing their performance in the

Figure 4: AUROC values (in %) of deep learning structural inference methods on Charged Particles trajectories.

presence of noise, varying trajectory lengths, and real-world scenarios. Our findings highlight several key insights:

* **Leveraging correlations:** Methods like ppcor and TIGRESS, based on classical statistics, excel in stability and accuracy, effectively leveraging time-series correlations between nodes to enhance structural inference. These methods are robust against noisy and short trajectories, illustrating their efficacy in challenging data conditions.
* **Importance of dimensionality:** Deep learning methods outperform in multi-dimensional settings, underscoring the value of diverse, multi-dimensional data in capturing complex node dynamics and improving inference accuracy. In contrast, classical methods are preferable when only one-dimensional data is available.
* **Performance on sparse graphs:** All evaluated methods yield better results with trajectories from sparse and less connected graphs, suggesting potential for developing techniques to estimate graph properties without prior knowledge.
* **Leveraging mutual information against noise:** Information theory-based methods like PIDC and Scribe demonstrate robustness against Gaussian noise, leveraging mutual information metrics to mitigate noise effects and inform robust algorithm design.

Despite these insights, the study's limitations include reliance on static graph assumptions and a focus on a limited set of methods. For a detailed discussion of these limitations, see Appendix E.

**Updating Plan.** n the near future, we plan to update the benchmark by incorporating results from additional methods, including recurrent SLDS , LOCS , REDSDS , Aether , SDS  and AMORE . We will also stay attentive to the latest advancements in structural inference and continually integrate new methods into the benchmark. We encourage researchers in the field to benchmark their methods using the DoSI dataset to further advance this area of research.

**Outlook.** The findings underscore the value of leveraging correlations and mutual information in structural inference. Future research could explore innovative methods that apply these principles across both one-dimensional and multi-dimensional feature trajectories, potentially using neural networks to learn feature representations and perform advanced correlation and mutual information analyses. These approaches could extend the scope of structural inference to more complex and dynamic systems, making them more applicable to real-world scenarios.

In addition, developing and evaluating structural inference methods for systems with evolving structures should be a key focus. Many real-world dynamical systems, such as biological networks, social systems, and technological infrastructures, exhibit dynamic topologies where nodes and edges change over time. Capturing these evolving structures is crucial for accurately modeling and understanding such systems.

Another important direction is bridging the gap between simulated and real-world data by incorporating partial observations and various types of noise. This would help address the challenges posed by limited real-world data and create more realistic simulations, ultimately enhancing the applicability and robustness of structural inference methods in practice.

As we continue to benchmark structural inference methods that meet our criteria, we encourage researchers to utilize the Dataset for Structural Inference (DoSI) to evaluate their methods or to contact us for benchmarking. We are open to new approaches and are eager to advance research in structural inference.