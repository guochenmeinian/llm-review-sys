# Causal de Finetti: On the Identification of Invariant Causal Structure in Exchangeable Data

Siyuan Guo\({}^{12}\)

\({}^{1}\)University of Cambridge \({}^{2}\)Max Planck Institute for Intelligent Systems

{syg26,fh277}@cam.ac.uk

toth.viktor7400@gmail.com

bs@tuebingen.mpg.de

Viktor Toth\({}^{1}\)1

Bernhard Scholkopf\({}^{2}\)

Ferenc Huszar\({}^{1}\)

\({}^{1}\)University of Cambridge \({}^{2}\)Max Planck Institute for Intelligent Systems

{syg26,fh277}@cam.ac.uk

toth.viktor7400@gmail.com

bs@tuebingen.mpg.de

Equal contribution

###### Abstract

Constraint-based causal discovery methods leverage conditional independence tests to infer causal relationships in a wide variety of applications. Just as the majority of machine learning methods, existing work focuses on studying _independent and identically distributed_ data. However, it is known that even with infinite i.i.d. data, constraint-based methods can only identify causal structures up to broad Markov equivalence classes, posing a fundamental limitation for causal discovery. In this work, we observe that exchangeable data contains richer conditional independence structure than i.i.d. data, and show how the richer structure can be leveraged for causal discovery. We first present causal de Finetti theorems, which state that exchangeable distributions with certain non-trivial conditional independences can always be represented as _independent causal mechanism (ICM)_ generative processes. We then present our main identifiability theorem, which shows that given data from an ICM generative process, its unique causal structure can be identified through performing conditional independence tests. We finally develop a causal discovery algorithm and demonstrate its applicability to inferring causal relationships from multi-environment data. Our code and models are publicly available at: https://github.com/syguo96/Causal-de-Finetti

## 1 Introduction

Learning causal structure from observational data is a key step towards causally robust predictions in machine learning. Most existing causal discovery theory (Pearl, 2009) focuses on the study of _independent and identically distributed (i. i. d.)_ data. Indeed, a majority of practical methods (Chickering, 2002; Spirtes et al., 2000a,b) based on i.i.d. data only allows us to determine causal structure up to broad equivalence classes, and going beyond that is known to be impossible without further constraints (Pearl, 2009). For example, the basic task of identifying a bivariate cause-effect relationship (i.e. \(X\) causes \(Y\) or \(Y\) causes \(X\)) on i.i.d. data is known to be impossible. Current methods impose additional restrictions, e.g., linearity assumptions (Hoyer et al., 2012; Shimizu et al., 2006, 2011) or assumptions about the additive nature of noise (Hoyer et al., 2008a; Peters et al., 2014; Zhang and Hyvarinen, 2009) to ensure identification.

A more recent line of work relaxes the i.i.d. assumption and considers inferring causal structure from grouped or multi-environment data (Arjovsky et al., 2019; Heinze-Deml et al., 2018; Huang et al., 2020; Peters and Meinshausen, 2016; Rojas-Carulla et al., 2018; Tian and Pearl, 2001). Our key observation is that studying grouped data is akin to relaxing the assumption on the data generating process from i.i.d. to exchangeable. In this work, we study causal structure learning in exchangeable data and show unique causal structure identification is enabled by the richer conditional independence structure of exchangeable processes.

Several works in multi-environment data implicitly leverage the _independent causal mechanism (ICM)_ assumption (Aldrich, 1989; Janzing and Scholkopf, 2010; Pearl, 2009), which postulates that causal mechanisms of the true underlying generating process do not inform or influence one another. Despite having been widely applied (Brehmer et al., 2022; Goyal et al., 2019; Madan et al., 2021; Parascandolo et al., 2018), the ICM assumption is rarely stated any more formally than above, and thus lacks a statistical formalization. It is also unknown what the fundamental limitations of inferring causal structure under the ICM assumptions are. Our work makes three contributions to clarify these questions:

* **Causal de Finetti theorems** (SS 3) provide a mathematical justification for the _independent causal mechanism (ICM)_ assumption in data generating processes. It states that any exchangeable process satisfying a certain set of conditional independence properties can be represented as a generative process in which factors in a Markov factorization are statistically independent. We show how causal de Finetti substantiates the ICM principle and call such models ICM-generative processes.
* **Our main identifiability theorem** (SS 4), informally stated, shows that if data is sampled from an ICM generative process, the causal graph is uniquely identifiable by testing conditional independence relationships.
* **Causal discovery in multi-environment data:** Section 5 connects the identifiability theorem for ICM generative models to the analysis of multi-environment data. This section establishes that multi-environment data can be viewed as observing finite marginals of i.i.d. copies of an exchangeable process. This then allows us to develop an algorithm for recovering causal structure from data coming from a sufficient number of environments.

Our work thus provides strong probabilistic justification for approaches based on the independent causal mechanisms assumption and algorithms that require non-i.i.d. grouped data. We review the use of exchangeability in causality and approaches for causal structure learning in grouped data in Section 7. In Section 6, we present experiments that validate our approach to inferring causal structure from multi-environment data using conditional independence testing. Fig. 1 summarizes the main contributions of the paper and Fig. 2 illustrates differences between data generated by causal graph under i.i.d. process and ICM-generative process.

## 2 Preliminaries

### The Causal Framework

A joint distribution \(P(X_{1},,X_{N})\) over a set of variables \(X_{1},,X_{N}\) can be decomposed into simpler components in multiple ways. For example, by the chain rule of probability, one can factorize

Figure 1: (a) is an illustration showing how i.i.d. data and certain exchangeable data differ in identifying the correct causal structure for a bivariate model. Each quadrant represents a causal structure, \(X} 1.0pt}Y\), \(X Y\), \(X Y\). The inner circle represents i.i.d. regime and the outer circle represents certain exchangeable regime. Under i.i.d. data, one can only identify \(X} 1.0pt}Y\), whereas certain exchangeable data (i.e., ICM-generative processes) enables one to identify unique causal structures. (b) illustrates a differentiating factor between de Finetti and causal de Finetti’s representation on exchangeable data. Causal de Finetti disentangles the latents and substantiates causal mechanisms are independent in the sense latent parameters governing each mechanisms are statistically independent.

the joint as \(P(X_{1},,X_{N})=_{i=1}^{N}P(X_{i} X_{1},,X_{i-1})\). We say the joint distribution satisfies the _Markov factorization_ property with respect to a directed acyclic graph \(\) if

\[P(X_{1},,X_{N})=_{i=1}^{N}P(X_{i}_{i}),\] (1)

where \(_{i}\) are the direct parents of node \(X_{i}\) in \(\). While many factorisations can represent the same joint \(P\), a specific one is called the _causal Markov factorization_: in it, the factors \(P(X_{i}_{i})\) represent the causal mechanisms of the true underlying data generating process. One can use the causal factorization to predict effects of interventions, which we model mathematically by replacing the corresponding factor (Pearl, 2009).

Causal discovery aims at recovering the causal graph \(\) and the corresponding causal Markov factorization from the joint distribution \(P\). This can be done by matching the conditional independence structure implied by the graph \(\) to those observable in the joint distribution \(P\). To facilitate this matching, an elaborate graphical terminology has been developed, as detailed in Appendix A. Unfortunately, under the assumption that data is sampled i.i.d. from \(P\), the true underlying \(\) cannot be uniquely determined, only up to broad equivalence classes. The conditional independence structure of i.i.d. processes is not rich enough to facilitate identifiability of the causal structure \(\).

**Independence of Causal Mechanisms, Causal and Anti-Causal Machine Learning** In addition to the study of Markov factorization, recent work (Janzing and Scholkopf, 2010) studies the behaviour of causal mechanisms and postulates the _Independent Causal Mechanism (ICM)_ principle, which states:

Causal mechanisms are independent of each other in the sense that a change in one mechanism

\(P(X_{i}_{i})\) does not inform or influence any of the other mechanisms \(P(X_{j}_{j})\), for \(i j\).

The notion of invariant, independent and autonomous mechanisms have a long history in causality research: Havelmo (1944) and Aldrich (1989) discuss the historical development of autonomous mechanisms in economics and Pearl (2009) also argues that causal mechanisms are modular in nature. Scholkopf et al. (2012) pointed out the implications of this principle when using machine learning techniques in _causal or anti-causal learning_ settings, i. e., when the task is to predict an effect from a cause or a cause from an effect, respectively. The ICM principle implies that semi-supervised learning is only successful in the anti-causal direction, while the predictor can be robustly applied to new domains if learning is in the causal direction. While these observations seem intuitively true, it is difficult to ground their meaning in the langauge of probability or information. As we will see, these difficulties can be resolved once we consider non-i.i.d. data generating processes.

Figure 2: An illustration demonstrates different conditional independence relationships contained in i.i.d. process and ICM-generative process. (a): A causal graph generated under an i.i.d. process; (b): A causal graph generated under ICM-generative process; Unrolling the inner plate notation from (b), we visualize the process with two samples. Causal graphs \(X Y\) and \(Y X\) generated under an i.i.d. process share the same conditional independences \(\{\}\) and are thus observationally equivalent. (c) and (d) show the corresponding graphs under ICM-generative processes. (c) has \(X_{1}_{2} X_{2}\) which does not hold in (d) and (d) has \(X_{1}_{2} Y_{1}\) which does not hold in (c). One can thus differentiate the bivariate causal direction in ICM-generative processes.

### Exchangeability

As we have seen, i.i.d. processes have a limitation that their conditional independence structure is not rich enough to support identifiability of the full causal graph. We thus turn our attention to a richer class of processes, exchangeable sequences.

**Definition 1** (Exchangeable sequence).: _A finite sequence of random variables \(X_{1},X_{2},,X_{N}\) is **exchangeable**, if for any permutation \(\) of its indices \(\{1,,N\}\):_

\[P(X_{(1)},,X_{(N)})=P(X_{1},,X_{N})\] (2)

_An **infinite exchangeable** sequence is a sequence where for any \(N\), its finite sequence of length \(N\) is exchangeable._

Exchangeability is a notion of symmetry. Definition 1 informally states the order of observations does not matter. Recall a finite sequence of random variables is _independent and identically distributed_ if its joint distribution satisfies \(P(X_{1},,X_{N})=_{i=1}^{N}P(X_{i})\). Of course, such an i.i.d. sequence is automatically exchangeable but not all exchangeable sequences are i.i.d. To clarify the connection between exchangeable and i.i.d. sequences, recall the de Finetti theorem:

**Theorem 1** (De Finetti's representation theorem (de Finetti, 1931)).: _Let \((X_{n})_{n}\) be an infinite sequence of binary+ random variables. The sequence is exchangeable if and only if there exists a random variable \(\) such that \(X_{1},X_{2},...\) are conditionally independent and identically distributed given \(\), with a probability measure \(\) on \(\). Mathematically speaking, given any sequence \((_{1},..,_{N})\{0,1\}^{N}\):_

Footnote †: De Finetti’s representation theorem has been extended to categorical and continuous variables (Klenke, 2008).

\[P(_{1},,_{N})=_{i=1}^{N}p(_{i} )d()\] (3)

Informally, the theorem states that an exchangeable sequence can always be represented as a mixture of i.i.d. sequences. De Finetti's representation theorem has important consequences for Bayesian inference. Bayesian statistics, unlike frequentist, takes the view that the parameter is a latent variable, instead of an unknown point estimate. Bayes' theorem estimates the parameter via calculating posterior density \(p(|_{1},..,_{N})\). De Finetti's representation theorem demonstrates (O'Neill, 2009) that rather than metaphysical belief about the true model, it is due to our judgement that the observations are exchangeable that underlies our standard use of Bayesian modelling involving observations are i.i.d. conditioned on some unknown latent variable.

## 3 Causal de Finetti Theorems

Just as de Finetti justifies Bayesian modelling, we will introduce causal de Finetti theorems that justify causal modelling via probability theory. We first motivate our study of exchangeable sequences by noting that they have a richer conditional dependence structure than i.i.d. sequences. We illustrate what this means concretely in the simplest possible case of a pair of variables.

Let \(X\) denote a random variable and \(x\) denote a random variable's particular realization. Let \([n]\) denotes the set of positive integers that are less than or equal to \(n\), i.e. \([n]=\{1,,n\}\).

**Definition 2** (Exchangeable pairs).: _An infinite sequence of random variable pairs \((X_{n},Y_{n})_{n}\) is exchangeable if for any permutation \(\) and for any finite number \(N\), it satisfies_

\[P(X_{(1)},Y_{(1)},,X_{(N)},Y_{(N)})=P(X_{1},Y_{1},,X_{N },Y_{N})\] (4)

In an i.i.d. sequence over pairs, the only non-trivial independence is \(X_{i} Y_{i}\). Since the distribution is identical, it either holds for all \(i\) or does not hold for all \(i\). In an exchangeable sequence of pairs, one can consider other non-trivial independence, for example, \(Y_{i} X_{j} X_{i}\). This conditional independence relationship trivially holds in i.i.d. sequences, but it may or may not hold in exchangeable sequences. Therefore, one can hope its absence or presence carries some useful information about some underlying causal structure. Here, we present the causal de Finetti theorems, which illustrate the type of causal structure this conditional independence relationship implies.

**Theorem 2** (Causal de Finetti - bivariate).: _Let \(\{(X_{n},Y_{n})\}_{n}\) be an infinite sequence of binary random variable pairs. The sequence is:_

1. _infinitely exchangeable, and satisfies_
2. \( n\)_:_ \(Y_{[n]}\!\!\! X_{n+1} X_{[n]}\)__

_if and only if there exist two random variables \(\) and \(^{2}\) with probability measures \(,\) such that the joint probability can be represented as_

\[P(x_{1},y_{1},,x_{N},y_{N})=_{n=1}^{N}p(y_{n} x_{n},)p(x_{n})d()d()\] (5)

Informally, the theorem states that an exchangeable sequence of random variable pairs satisfying an additional set of conditional independence properties, can always be represented as a mixture of i.i.d. sequences which all share the same underlying Markov factorization structure, and thus, an _invariant causal structure_. In fact, such exchangeable data can be interpreted as data generated under the ICM assumption. Recall the independent causal mechanism is loosely denoted as "\(P_{|}\!\!\! P_{}\)". ICM assumption can be modelled by Eq. 5 in the sense that causal mechanisms are characterized by latent variables: mechanisms do not influence each other if one can separately manipulate each latent variable controlling different mechanisms; further, latent variables governing each mechanism are statistically independent with each other, supporting mechanisms do not inform one another. We thus call the generative process in Eq. 5 as ICM-generative process. Causal de Finetti, just as how de Finetti substantiates Bayesian modelling, demonstrates that rather than metaphysical belief about independent causal mechanisms, it is due to our judgement that observations are exchangeable and the sufficiency to predict the target variable \(Y\) with the corresponding \(X\) values irrespective of other \(X\) observations underlie our standard use of causal modelling. We thus substantiate ICM by detailing the statistical assumptions one implicitly make when assuming ICM.

As an example, consider the causal graph on the right. Imagine in a hospital there are two patients. A patient's symptom is the cause of a doctor's diagnosis. Suppose we are interested to predict a patient's diagnosis given her symptom. The conditional independence says knowing another patient's symptom will not help us to predict the diagnosis of this patient if we know this patient's symptoms already. The conditional independence thus formulated the intuition behind causal and anti-causal problem in the language of probability: the distribution of the cause, other patients' symptoms in this case, will not help prediction about the effect given cause, i.e., one patient's diagnosis given his own symptoms.

**Causal de Finetti vs. de Finetti** To see the difference between causal de Finetti and de Finetti's representation theorem, we observe that a direct application of de Finetti theorem on exchangeable data that may or may not contain causal information results in a factorization as:

\[P(x_{1},y_{1},,x_{N},y_{N})=_{n=1}^{N}p(y_{n},x_{n})d ()\] (6)

As observations are conditionally i.i.d. given latent variable \(\), learning \(\) is thus sufficient to achieve maximum prediction power. This finding corroborates empirical results in the machine learning community, where training often produces an entangled representation that achieves strong prediction accuracy. However, with the fast development of powerful machine learning applications (Brown et al., 2020), both deep learning and causal communities advocate the need for disentangled representations (Bengio et al., 2013; Locatello et al., 2019; Scholkopf et al., 2021), which offer greater control, interpretability, and generalization capabilities. Causal de Finetti shows that, in fact, given exchangeable data satisfying the causal and anti-causal learning phenomenon formulated in conditional independences, there are statistically independent latent variables controlling each causal mechanism. It shows one can achieve both maximum prediction power and disentangled representations. Fig. 0(b) illustrates a visualization of the differences between de Finetti and causal de Finetti theorems.

We next illustrate causal de Finetti in the general multivariate form (see Appendix B for proof):

**Definition 3** (Exchangeable arrays).: _An array of size \(d\) contains variables \((X_{1:n},,X_{d:n})\) where \(X_{d:n}\) denotes the \(d\)-th random variable in \(n\)-th array. Such an array is denoted as \(_{::n}\). A finite sequence of size \(d\) arrays is **exchangeable**, if_

\[P(_{::n},,_{::n}(N))=P(_{::1},, _{::N})\] (7)

**Theorem 3** (Causal de Finetti - multivariate).: _Let \(\{(X_{1:n},X_{2:n}, X_{d:n})\}_{n}\) be an infinite sequence of \(d\)-tuple binary random variables. The sequence is_

1. _infinitely exchangeable, and_
2. _if there exists a DAG_ \(\) _such that_ \( i[d], n\)_:_ \[X_{i:[n]}}_{i:[n]},_{i:n+1}|_{ i:[n]}\] _where_ \(_{i}\) _selects parents of node_ \(i\) _and_ \(_{i}\) _selects non-descendants of node_ \(i\) _in_ \(\)_._ \(}_{i}\) _denotes the set of non-descendants of node_ \(i\) _excluding its own parents._

_if and only if there exist \(d\) random variables where \(_{}^{2^{|_{i}|}}\) with suitable probability measures \(\{_{i}\}\) such that the joint probability can be written as_

\[P(_{::1:N})=_{n=1}^{N}_{i=1}^{d}p(x_{i:n} _{i:n},_{i})d_{1}(_{ }) d_{d}(_{}),\] (8)

_where \(_{::1:N}:=\{(x_{1:n},,x_{d:n})\}_{n=1}^{N}\)._

Theorem 2 is a special case of Theorem 3 when \(d=2\). Informally, it states that an exchangeable sequence of size \(d\) random arrays satisfying an additional set of conditional independence properties with respect to a DAG, can always be represented as a mixture of i.i.d. sequences which all share the same underlying Markov factorization structure as the corresponding DAG. The set of conditional independence properties in condition \(2\) can be interpreted via its decomposition:

\[X_{i:[n]}}_{i:[n]}_{i:[n]}\]

This shows that the direct parents of one node form a Markov blanket for its other non-descendant nodes. In other words, to infer about the variable of interest, it is sufficient to know the variable's direct parents irrespective of other non-descendants.

\[X_{i:[n]}_{i:n+1}_{i:[n]}\]

This conditional independence is another example that exchangeable data has richer conditional independence structure. It trivially holds in i.i.d. sequences but may or may not hold in exchangeable data. Informally, it states that to infer the variable of interest, it is sufficient to know its corresponding parents irrespective of non-descendants in other observations. This formulated the intuition behind the causal and anti-causal problem in the language of probability: the distribution of the variables in the causal direction, in this case, non-descendants in other observations will not help prediction if covariates contain a complete set of the corresponding direct causal parents.

To illustrate how Theorem 3 also justifies the ICM in action, consider the causal graph to the right. Imagine high schools host campaigns to advertise university opportunities and encourage students to apply. Students' decision to apply is the cause of their university admission outcomes. Suppose we are interested in understanding how influential school campaigns are on students' decision to apply, i.e., the mechanism of "Apply \(|\) Campaign". We expect that knowing a particular student's decision to apply after attending a school campaign will not be influenced by the other school campaigns the student did not attend; instead, knowing other students' decisions to apply after their attendance in campaigns will help the prediction of this particular student's decision to apply. Similarly, knowing other students' university admission outcomes will also be helpful. This is because more students decide to apply implies the effectiveness of school campaigns, and more university admission acceptance implies more students decide to apply. Causal de Finetti says given such assumptions and exchangeable data, it naturally holds that there exist latent variables, represented by high school, student and university, and they are independent.

**Extension beyond binary** Above theorems are presented in its bivariate and multivariate forms for binary variables. In general, it is easy to extend the results to categorical variables*. Just as the progression of the proofs for de Finetti's theorem, we hypothesize causal de Finetti holds true for continuous variables. Here we state the theorem in its multivariate form for categorical variables.

Footnote *: (Barrett and Leifer, 2009) provides an alternative proof of conditional de Finetti in quantum theory for categorical variables.

**Theorem 4** (Causal de Finetti - multivariate and categorical).: _Consider an infinite sequence of size-random arrays \(\{(X_{1;n},X_{2;n}, X_{d;n})\}_{n}\), where each variable \(X_{i;n}\) takes values in \(\{1,,k_{i}\}\). The sequence is:_

1. _infinitely exchangeable, and_
2. _if there exists a DAG_ \(\) _such that_ \( i[d], n\)_:_ \[X_{i;[n]}}_{i;[n]},_{i;n+1}|_{ i;[n]}\] _where_ \(_{i}\) _selects parents of node_ \(i\) _and_ \(_{i}\) _selects non-descendants of node_ \(i\) _in_ \(\)_._ \(}_{i}\) _denotes the set of non-descendants of node_ \(i\) _excluding its own parents._

_if and only if there exist \(d\) random variables where \(_{}^{k_{i}_{X_{j} _{}}k_{j}}\) and every column of \(_{i}\) sum to \(1\) with suitable probability measures \(\{_{i}\}\) such that the joint probability can be written as_

\[P(_{:,1:N})=_{n=1}^{N}_{i=1}^{d}p(x_{i;n}|_{i;n},_{})d_{1}(_{ }) d_{d}(_{}),\] (9)

_where \(_{:,1:N}:=\{(x_{1;n},,x_{d;n})\}_{n=1}^{N}\)._

## 4 Identifiability Result

The causal de Finetti theorems show that exchangeable processes can be represented as ICM generative process when certain CI statements hold. However, such a representation is only really useful for causal discovery if it is unique - in other words we would like if only one such decomposition were possible for any given exchangeable process. This property is called _identifiability_. In this section we study the identifiability of ICM generative process. We start by introducing graphical terminology.

**Definition 4** (Acyclic directed mixed graph (ADMG) (Richardson, 2003)).: _An acyclic directed mixed graph can contain two types of edges: directed '\(\)' or bi-directed '\(\)'. When an ADMG does not contain any bi-directed edge, it becomes a directed acyclic graph (DAG)._

**Definition 5** (\(\)-map (Koller and Friedman, 2009)).: _Given \(P\) is a distribution, \((P)\) denotes the set of conditional independence relationships of the form \(X Y Z\) that hold in \(P\). Given \(\) be a ADMG, \(()\) denotes the set of conditional independence assumptions encoded in \(\) which can be directly read-off via m-separation (Zhang and Spirtes, 2012). When \(\) is a DAG, \(()\) can be directly read-off via d-separation (Pearl, 1988)._

**Definition 6** (Global Markov property and faithfulness (Zhang and Spirtes, 2012)).: _Given a ADMG \(\) and a joint distribution \(P\), the distribution satisfies global Markov property with respect to \(\) if \(()(P)\). Sometimes it is also called \(P\) is **Markovian** with respect to \(\). We say \(P\) is **faithful** to \(\) if \((P)()\)._

Definition 7 defines the mapping from causal graphs generated under an i.i.d. process to those generated under an exchangeable process. The latent variables in causal de Finetti theorems can be represented by bi-directed edges in Definition 4.

**Definition 7** (ICM operator on a DAG).: _Let \(U\) be the space of all DAGs whose nodes represent \(X_{1},,X_{d}\). Let \(V\) be the space of ADMGs whose nodes represent \(\{(X_{i;n})\}\), where \(i[d],n\). A mapping \(F\) from \(U\) to \(V\) is an ICM operator if \(F()\) satisfies:_

* \(F()\) _restricted to the subset of vertices_ \(\{X_{1;n},,X_{d;n}\}\) _is a DAG_ \(\)_, for any_ \(n\)_,_
* \(X_{i;n} X_{i;m}\) _whenever_ \(n m\) _for all_ \(i[d]\)__* _there are no other edges other than stated above_

_We denote the resulting ADMG as \(ICM()\). Let \(^{}_{i;n}\) denote the parents of \(X_{i;n}\) in \(ICM()\) and similarly for \(^{}_{i;n}\) for corresponding non-descendants._

**Theorem 5** (Identifiability Theorem).: _Consider the set of distributions that are both Markovian and faithful to \(ICM()\), i.e., \(():=\{P:(P)=(())\}\). Then,_

\[(_{1})=(_{2})_{1}=_{2}\] (10)

The set of graphs \(\{()\}\) characterizes the set of causal graphs for data sampled from ICM-generative processes. Given any two causal structures \(_{1}\) and \(_{2}\) underlying data sampled from ICM-generative processes, we say they are Markov equivalent if \((_{1})=(_{2})\). Theorem 5 states given a distribution \(P\) that is Markovian and faithful to \(ICM()\), one can identify its unique causal structure as each graph induces unique conditional independences. See Appendix C for proof.

**Connection to i. i. d.** Causal de Finetti theorems though stated formally under exchangeable process, it automatically holds for data generated under an i.i.d. process. When observing i.i.d. data, the measures \(_{i}\) in (8) are Dirac measures, and the de Finetti parameters \(\{_{i}\}\) are deterministic, i.e., fixed across multiple samples generated from the process. The identifiability theorem stated here, however, excludes distributions generated by marginally i.i.d. processes. It requires \(P\) to be faithful to \(ICM()\). If any one of the marginal distributions of \(P\) can collapse to an i.i.d. process, i.e., there exists an index \(d\) such that \(P(X_{d;1},,X_{d;N})=_{n}P(X_{d;n})\), then \(P\) is not faithful to \(ICM()\) since it contains extra conditional independence relationships. Fig. 2 illustrates that compared to i. i. d process, ICM-generative processes enable unique causal structure identification.

## 5 Causal Structure Learning in Multi-environment Data

We established in Thm. 5 that causal structure is identifiable in ICM generative models by testing for CI relationships in exchangeable data. For example, if \(Y_{i} X_{j} X_{i}\) holds for an exchangeable pair \((X_{n},Y_{n})\), we conclude that \(X Y\), i. e. \(X\) causes \(Y\). But how exactly does one test for this in data?

To test if a CI statement holds between a set of random variables, one typically requires multiple samples, that is i.i.d. copies of the variables in question. Similarly, to apply our identification results in practice, we need access to multiple i.i.d. copies of the exchangeable pair \((X_{n},Y_{n}),n\) (see Def. 2). Each copy of \(\{(X_{n},Y_{n})\}_{n}\) gives us a whole dataset containing a sequence of individual pairs, thus, we need multiple independent datasets to test for the CI condition. This requirement for multiple datasets connects our work to grouped or multi-environment data.

In the causal literature, grouped data refers to data available from multiple environments, each producing (conditionally) i. i. d observations from a different distribution, which are related through some _invariant causal structure_ shared by all environments. Grouped data underlies a wide range of causal discovery approaches (Arjovsky et al., 2019; Heinze-Deml et al., 2018; Huang et al., 2020; Peters and Meinshausen, 2016; Rojas-Carulla et al., 2018; Tian and Pearl, 2001). We can interpret multi-environment data through the lens of exchangeability as follow: In each environment \(e\), we observe exchangeable samples \(^{e}_{:,:1:N_{e}}=\{(X^{e}_{1;n},,X^{e}_{d;n})\}_{n=1 N_ {e}}\), where \(X^{e}_{d;n}\) denotes the \(d\)-th random variable in \(n\)-th sample in environment \(e\) and \(N_{e}\) is the number of samples from environment \(e\). Data across environments are independent and identically distributed in the sense that the distribution of \(^{e}_{:,:1:N}\) and \(^{e^{}}_{:,:1:N}\) is identical for all \(N<(N_{e},N_{e^{}})\). Each environment thus provides a finite marginal of an i.i.d copy of the same exchangeable process, just as we needed for testing CI. Alternatively, one can also interpret environments as samples from latent variables, i.e. \((^{e},^{e})\) i.i.d. drawn from \(p(),p()\) characterizes environment \(e\).

Next, we propose the _Causal-de-Finetti_ algorithm, which guarantees to recover the DAG given multi-environment data consistent with ICM. In particular, the algorithm utilizes two samples per environment and a sufficiently large number of independent environments to enable identification.

**Notation**: As every sample in all environments shares the same causal structure, we sometimes abbreviate the variable \(X^{e}_{i;n}\) to \(X_{i;n}\) or \(X_{i}\). The results proved under abbreviated indices mean the abbreviated indices could take any values and the result remains the same. Let \(S_{n}\) denotes the set containing nodes belong to \(n-\)th rank in a DAG \(\)'s topological ordering. (See details in Appendix D)

**Lemma 1**.: _A node \(X_{i;n} S_{1}\) if and only if for every \(m n\) and \(j i\), \(X_{i;n} X_{j;m}\{X_{k;n}\}_{k i}\)._

**Lemma 2**.: _Let node \(X_{i} S_{n}\) and \(X_{j} S_{m}\) where \(m<n\). Set \(k:=n-m\). There does not exist a directed edge from \(X_{i}\) to \(X_{j}\) if and only if when \(k=1\), \(X_{i} X_{j} S_{>n}\); and when \(k>1\): \(X_{i} X_{j} Z\), where \(Z=S_{>n}(_{j} S_{<n})(S_{n} X_{i})\)._

Lemma 1 states the necessary and sufficient conditions to identify leaf nodes. Lemma 2, intuitively says, to decide whether \(X_{i}\) and \(X_{j}\) have a direct edge, one should block all the potential non-directed paths. Step 1 of the algorithm is to iteratively identify and remove the current set of leaf nodes, and then search for the next set of leaf nodes until all nodes have been classified into their topological orders. Step 2 of the algorithm is to apply Lemma 2 to determine the existence of an edge between different topological orders. Algorithm 1 in Appendix D details the exact procedure.

## 6 Experiments

We benchmark our method's performance against several state-of-the-art methods. As a measure of performance against methods for heterogeneous data, we compare against CD-NOD (Huang et al., 2017, 2020; Zhang et al., 2017). As a measure of performance against methods designed for i.i.d. data, we compare with common causal structure learning algorithms, e.g. FCI (Spirtes et al., 1995), GES (Chickering, 2002), NOTEARS (Zheng et al., 2018), DirectLinGAM (Shimizu et al., 2011) and PC algorithm (Spirtes et al., 2000b). Lastly, we compare with a random guess baseline.

**Bivariate Causal Discovery** We generate multi-environment data as described in Section 5. Latent factors \(\) were randomly generated with distinct and independent elements in each environment. Samples within each environment have the noise variables \(}\) generated via Laplace distributions conditioned on the latent factor. We observe bivariate data \(^{2}\) with \(X_{1}\) and \(X_{2}\) denotes the first and second entry of \(\) and aim to uncover the causal direction between \(X_{1}\) and \(X_{2}\). Let \({}^{e}\) denote variables contained in environment \(e\).

\[^{} [-1,1]\] \[}^{} (,1)\] \[^{} =^{}}^{}+^{}}^{ 2}_{}(e)\]

where \( 2\) denotes elementwise square operation. Specifically, \(^{e}^{2 2}\) is a randomly sampled triangular matrix and \(^{}=^{}-\). We randomly sample bivariate structures, \(X_{1} X_{2},X_{2} X_{1},X_{1} X_{2}\), by ensuring \(\) is either a lower triangular, upper triangular or diagonal matrix. Our data further simulates a realistic situation, i.e., the causal structure remains invariant with changing functional relationships across environments. This is implemented by randomly sampling the existence of nonlinear dependence indicator \(_{}(e)\) per environment. We perform three conditional independence tests with \(=0.05\) and output our estimate as the causal structure corresponding to the test with the highest \(p\)-value. We repeat the experiment for \(100\) times and report the proportion of correct causal direction identified with varying numbers of environments. Figure 3(a) shows the proportion of correct bivariate causal direction detected as the number of environments \(||\) increases and the number of observations within each environment as fixed to be \(2\). We observe Causal-de-Finetti algorithm outperforms all the other state-of-the-art methods and its accuracy converges close to \(100\%\). This demonstrates its capability to handle datasets with limited samples per environment and changing functional relationships across environments.

**Multivariate Causal Structure Discovery** We further test our algorithm's performance in identifying multivariate causal structure. We randomly generate causal graphs with \(3\) variable nodes where each variable takes binary values. Figure 3(b) shows the Structural Hamming Distance (Tsamardinos et al., 2006) between true and estimated DAG averaged over \(100\) experiments. We again observe Causal-de-Finetti outperforms all the other baselines, which validates our identifiability theorem and demonstrates algorithms designed for i.i.d. data does not work in our setting.

## 7 Discussion

**Causal exchangeability**Dawid (2021) introduces a decision-theoretic framework for causality and uses pre-treatment and post-treatment exchangeability as foundational assumptions on external data used to solve the decision problem. Jensen et al. (2020) studies object conditioning and show its probabilistic interpretations can be explained using exchangeability. Object conditioning, due to exchangeability, thus mitigates latent confounding and measurement errors for causal inference. Our work provides a statistical understanding of ICM assumption: it is equivalent to assuming exchangeability and certain conditional independence conditions.

**Causal structure learning** Within the study of i.i.d. data, it is well-known that one can only identify causal structures up to Markov equivalence classes (Pearl, 1988), and going beyond that is known to be impossible without further parametric constraints (Hoyer et al., 2008; Shimizu et al., 2006). A recent line of work considers a mixture of observational multi-environment data and interventional data to perform inference: Arjovsky et al. (2019); Peters and Meinshausen (2016); Rojas-Carulla et al. (2018) use causal invariance property to discover stable predictors and Huang et al. (2017, 2020) estimate kernel mean embeddings of heterogenous data distributions to test the independence of causal mechanisms. Monti et al. (2020) discovers bivariate causal direction by first recovering the underlying generating sources and then performing conditional independence tests on the recovered source factors. These algorithms on non-i.i.d. grouped data all demonstrate success, though it is unclear the connection between causal assumptions and probabilistic implications of grouped data. Our work observes that grouped data is akin to exchangeable sequences, containing richer conditional independence structures. In particular, ICM-generative processes with a sufficient number of environments allow unique causal structure identification.

**Relations to causality in time-series** The study of data generated from i.i.d. process, exchangeable process, and time-series can be seen as a progression to understand more structured data. Appendix E details the connections between ICM-generative processes and causality in time series (Runge, 2020).

**Conclusion** We prove causal de Finetti theorems formalizing the independent causal mechanism assumption in data generating processes as concrete statistical conditions. We call the induced generative models ICM-generative processes. For data sampled from ICM-generative processes, we show that one can identify unique causal structure. We build the connection between exchangeable and grouped data and justify the success of many methods leveraging ICM and algorithms in non-i.i.d. grouped data. Going beyond the i.i.d. assumption has been the bottleneck to applying machine learning to real-world situations. Rather than considering it a nuisance, our work shows an example of a theoretical advantage of exchangeable data in causal structure identification.