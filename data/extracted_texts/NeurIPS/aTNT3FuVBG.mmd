# SureMap: Simultaneous mean estimation

for single-task and multi-task disaggregated evaluation

 Mikhail Khodak

Princeton University

mkhodak@cs.cmu.edu

&Lester Mackey, Alexandra Chouldechova, Miroslav Dudik

Microsoft Research

{lmackey,alexandrac,mdudik}@microsoft.com

Work done in part while at Microsoft Research and supported in part by a CMU TCS Presidential Fellowship.

###### Abstract

Disaggregated evaluation--estimation of performance of a machine learning model on different subpopulations--is a core task when assessing performance and group-fairness of AI systems. A key challenge is that evaluation data is scarce, and subpopulations arising from intersections of attributes (e.g., race, sex, age) are often tiny. Today, it is common for multiple clients to procure the same AI model from a model developer, and the task of disaggregated evaluation is faced by each customer individually. This gives rise to what we call the _multi-task disaggregated evaluation problem_, wherein multiple clients seek to conduct a disaggregated evaluation of a given model in their own data setting (task). In this work we develop a disaggregated evaluation method called **SureMap** that has high estimation accuracy for both multi-task _and_ single-task disaggregated evaluations of blackbox models. SureMap's efficiency gains come from (1) transforming the problem into structured simultaneous Gaussian mean estimation and (2) incorporating external data, e.g., from the AI system creator or from their other clients. Our method combines _maximum a posteriori_ (MAP) estimation using a well-chosen prior together with cross-validation-free tuning via Stein's unbiased risk estimate (SURE). We evaluate SureMap on disaggregated evaluation tasks in multiple domains, observing significant accuracy improvements over several strong competitors.

## 1 Introduction

Evaluation is a key challenge in modern AI, with much effort spent deciding what metrics to measure, with which methods, and on what data. This challenge is especially acute in fairness assessment, which requires not only high-quality data to run a model and score its outputs but also demographic information for defining groups. Due to the high cost of obtaining high-quality evaluation data, the issue of sample complexity--sample size needed to get a good performance estimate--remains salient, especially when we want to release not just one overall measure but instead to output a _disaggregated evaluation_ that captures variation among demographic subpopulations of the data . For instance, we might want to assess group fairness by examining the variation in performance across groups of users defined by intersections of the demographic attributes age, race, and sex. The naive approach of independently evaluating each group's performance on its own data can fail because the sample sizes of intersection groups rapidly decrease as we consider more attributes . Recent work has shown how to improve upon naive methods by combining data from multiple subpopulations to inform their individual performance estimates .

In today's technology landscape it is common for multiple clients to _procure_ the same model (e.g., an automated speech recognition or language model) from an AI developer, with each client performing a disaggregated evaluation of _the same model_ on _their own data_. We refer to this problem as the **multi-task disaggregated evaluation**. We formalize and study this problem, showing that one can improve the disaggregated evaluations of individual clients by using multi-task data in the form ofsummary statistics from other clients or from the model provider. Our approach uses the (out-of-distribution) multi-task data to set the parameters of a multivariate normal prior and then performs _maximum a posteriori_ (MAP) inference on the (in-distribution) client data. Formally, we model the problem as Gaussian mean estimation and design a simple-yet-expressive additive prior that can capture many different relationships between subpopulations. Drawing upon classical statistics, we fit prior parameters by minimizing Stein's unbiased risk estimator (SURE, Stein, 1981). While motivated by multi-task considerations, we show that our method also performs well in the single-task setting.

### Contributions

1. **SureMap**: We introduce a method that uses SURE to tune the parameters of a well-chosen Gaussian prior before applying MAP estimation. The prior is motivated by its attainment of a good efficiency-expressivity tradeoff, requiring only a linear (in the number of subpopulations) number of parameters to recover several natural baselines for disaggregated evaluation.
2. **Datasets**: Disaggregated evaluation has few benchmarks (Herlihy et al., 2024), so we introduce new ones for both the single-task and multi-task settings, covering automated speech recognition (ASR) and also tabular domains (with linear models and also in-context LLMs).
3. **Single-task:** We find that SureMap is always competitive with strong baselines from prior work, while improving significantly in some settings with intersectional sensitive attributes.
4. **Multi-task:** Incorporating data from multiple clients into SureMap yields significant improvements across all evaluated settings. This multi-task approach is more accurate even with just one additional task and is the only method to consistently outperform the naive and pooling baselines.

### Related work

Disaggregated evaluation is a core task in the fairness assessment of AI systems (Barocas et al., 2021). Past work has sought to improve estimation accuracy by combining information across different groups, e.g., via Bayesian modeling (Miller et al., 2021), Gaussian process approximation of loss surfaces (Piartala et al., 2021), and structured regression (Herlihy et al., 2024). The last work found that classical James-Stein-type mean estimation (James and Stein, 1961; Bock, 1975) is often competitive, and so we adopt it as our first non-naive baseline. We also compare to structured regression itself, which turns out to have a tight mathematical connection to SureMap; indeed, apart from our use of Gaussian (ridge) rather than Laplace (lasso) priors (regularization)--as well as our use of a more flexible tuning based on SURE rather than cross-validation--the method of Herlihy et al. (2024) can be viewed as the discriminative counterpart to our generative approach (see SE for details).

Within the disaggregated evaluation literature we are the first to formulate and study _multi-task_ disaggregated evaluation. This is an important direction because (a) model providers often have their own data or data from multiple clients that can inform the evaluation and (b) transferring information across distributions is a key way to handle very low-sample regimes. We also contribute several datasets that we hope will spur further development in disaggregated evaluation.

SureMap relies on applying classical mean estimation tools to quantities modeled as Gaussian means. Notably, Miller et al. (2021) model _scores_ via well-studied distributions--e.g., Gaussians--but since scores are related non-linearly to metrics it is unclear if this can lead to similarly simple estimators. To tune parameters, we use SURE, a popular statistical approach (Li, 1985; Donoho and Johnstone, 1995). Specifically, in the empirical Bayes tradition, we use it to set the MAP estimator of a hierarchical model. Using SURE to tune the scale of an isotropic Gaussian prior was shown to be asymptotically (in the dimension) optimal in the case of heteroskedastic data distributions (Xie et al., 2012). Since disaggregated evaluation data is highly heteroskedastic due to variation in group size, this is positive evidence for our approach, although our prior is non-isotropic and has many more variance parameters.

## 2 Setup

We first describe the disaggregated evaluation problem (SS2.1), recast it as a Gaussian mean estimation (SS2.2), and motivate a multi-task variant (SS2.3), all while introducing several baselines estimators.

### Setting and baselines

We want to assess a predictive model \(p:\) under some distribution \(\) over input space \(\) and output space \(\) using error measure \(:\). For example, in image classification, \(\) is a distribution over (image, label) pairs and \(\) is the 0-1 error. To simplify notation, we mainly deal with the composite function \(f(z)=(y,p(x))\) acting on points \(z=(x,y)\) in the product space \(=\).

In _disaggregated_ evaluation, \(\) is assumed to be a union of \(d 1\) disjoint subsets \(_{g}\), each associated to some subpopulation or _group_\(g[d]\), where we use \([k]\) to denote the set \(\{1,,k\}\). As a running example, suppose each point \(z\) is an individual whose sex \(s\) and age \(a\) are categorical variables with \(d_{1}\) and \(d_{2}\) possible values, respectively. Then \(d=d_{1}d_{2}\) and each point has an associated index \(g=(s-1)d_{2}+a\) denoting its intersection of sex \(s[d_{1}]\) and age \(a[d_{2}]\). The task is then to use a set \(S^{n}\) of \(n 1\) i.i.d. samples from the distribution \(\) to estimate the vector of true subpopulation errors \(^{d}\), with components \(_{g}=_{z|_{g}}[f(z)]\).1 We write \(}(S)^{d}\) for an estimator of \(\) with components denoted as \(_{g}(S)\).

Empirically, we measure estimation accuracy, i.e., the performance of the performance estimate, via **mean absolute error** (MAE) \(L^{}_{}(}(S))=\|}(S)- \|_{1}\), which is easy to interpret and less sensitive to outliers than **mean squared error** (MSE). Our method development, however, is based on a count-weighted version of MSE, where we denote group counts as \(n_{g}=|S_{g}|\):

\[L^{}_{}(}(S))=_{g=1}^{d}n_{g}( _{g}(S)-_{g})^{2}.\] (1)

We conclude the setup with two baselines. The first is the **naive estimator** returning group means:2

\[^{}_{g}(S)=}_{z S_{g }}f(z).\] (2)

While unbiased, \(}^{}\) can perform poorly on groups with few samples. The second baseline, the **pooled estimator**, returns an identical quantity--the overall sample mean--for all groups:

\[^{}_{g}(S)=_{z S}f(z)=_ {g=1}^{d}n_{g}^{}_{g}(S).\] (3)

This estimator is generally biased (unless all group means are equal), but it can perform well in low-sample regimes thanks to a much lower variance.

### A Gaussian model for disaggregated evaluation

We use a simple but natural model to aid in the design of disaggregated evaluation methods. Specifically, denoting the naive estimator by \(=}^{}(S)^{d}\), we model group \(g\)'s entry \(y_{g}\) as being drawn from a Gaussian with (unknown) mean \(_{g}\) and (known) variance \(^{2}/n_{g}\), where \(^{2}\) is shared across groups. This reduces the problem of disaggregated evaluation, as defined in SS2.1, to that of estimating the mean of a multivariate Gaussian with known diagonal covariance \(_{g,g}=^{2}/n_{g}\) given a single sample \((,)\). Our model has many advantages in the disaggregated evaluation setting:

1. By the central limit theorem, \(\) is asymptotically normal with mean \(\) and diagonal covariance \(\) for many distributions \(\) of interest, even when the underlying data is non-Gaussian. Furthermore, because the methods derived from our model only take \(\) and \(\) as input, they can be applied even when the evaluated statistic is not the pointwise average assumed by the setup in SS2.1, so long as \((,)\) holds asymptotically. An example of this is when \(y_{g}=^{}_{g}(S)\) corresponds to the area under the ROC curve (AUC) computed over group \(g\)'s data \(S_{g}\)(Lehmann, 1951); we demonstrate SureMap's applicability to AUC empirically in SS6 (Figures 10 & 12).
2. While a shared variance is a strong assumption, it is perhaps the simplest way of incorporating the inductive bias that \(_{g,g}\) will be highly correlated with the inverse of \(n_{g}\), the number of samples from group \(g\). In practice, we set \(^{2}\) to be the pooled estimate \(_{g=1}^{d}_{z S_{g}}(f(z)-y_{g})^{2}\).
3. Gaussian mean estimation is one of the best-studied problem in statistics, with numerous well-tested baselines and approaches for developing new methods. In particular, we make significant use of the classic James-Stein approach (James and Stein, 1961; Bock, 1975), SURE (Stein, 1981), and empirical Bayesian estimation methods (Bock, 1975).
4. In the multi-task setting, clients are likely to be unwilling to share their actual data but possibly more willing to share group summary statistics. Thus methods developed for our Gaussian model--which only require the group means \(\), group counts \(\), and an estimate of \(^{2}\)--will be more broadly applicable than methods that act directly on the dataset \(S\).

This model can also be naturally extended--using a non-diagonal covariance \(\)--to disaggregated evaluation with non-disjoint groups, e.g., to simultaneously estimate performance both for all women and for only women in their forties. In the interest of brevity we focus on the disjoint group setting.

### The multi-task setting

We can easily extend this model to study multi-task disaggregated evaluation, in which for each task \(t=1,,T\) (e.g., a client of the model provider) we observe a set \(S_{t}\) of \(n_{t}\) samples from the task distribution \(_{t}\). The goal is then to output \(T\) vectors \(}_{t}\) that are close on-average to the tasks' subpopulation errors \(_{t;g}=_{z_{t}}[f(z)|z_{g}]\). Converting to our Gaussian model, we observe \(T\) vectors \(_{t}(_{t},_{t})\)--where we set \(_{t;g,g}=^{2}/n_{t;g}\) for some globally shared \(^{2}\) and task-specific group count vectors \(_{t}_{ 0}^{d}\)--and must output \(T\) mean estimates \(}_{t}(\{_{t}\}_{t=1}^{T})^{d}\).

We consider two natural multi-task baseline estimators. The first is the **global naive estimator** (or global estimator for short), which combines the data from all tasks, computes a single global vector of group averages, and uses it as the estimate for each task:

\[}_{t}^{}(\{S_{t}\}_{t=1}^{T})=}^{ {naive}}\!(_{t=1}^{T}S_{t}) }_{t}^{}(\{_{t}\}_{t=1}^{T})=(_{t=1}^{T}_{t}^{-1})^{-1}_{t=1}^{T}_{t}^{-1}_{t}.\] (4)

While low variance, the global estimator ignores variation across tasks. Our second baseline--the **multi-task offset estimator**--shifts the global estimate on each task to ensure that the task's pooled mean is preserved (thus accounting for the variation in pooled means across individual tasks):

\[}_{t}^{}(\{_{t}\}_{t=1}^{T})=+ }^{}(_{t}-), =}_{t}^{}(\{_{t}\}_{t=1} ^{T}).\] (5)

## 3 Methods

In the last section we reduced the problem of disaggregated evaluation to that of estimating a mean \(^{d}\) given a sample \((,)\), where \(\) is known and diagonal. We now design a method, **SureMap**, for the latter problem. Our technical approach involves the following two steps:

1. **Choosing a parameterized mean estimator.** We use the MAP estimator under a multivariate normal prior that we design specifically for intersectional subpopulations.
2. **Tuning the estimator's hyperparameters.** We use SURE to estimate the quality of our estimator, which we then optimize over the choice of hyperparameters using the L-BFGS-B algorithm.

### Designing a parameterized estimator

As mean estimation is a vast area, we use three criteria for designing an estimator: it should (1) dominate baselines such as \(}^{}\) and \(}^{}\); (2) have relatively few hyperparameters; and (3) handle _heteroskedasticity_ stemming from variation in group sizes. One natural source of candidates are James-Stein-type shrinkage estimators: the original James-Stein estimator famously dominates \(}^{}\) in MSE and has no hyperparameters to tune (James and Stein, 1961), satisfying our first two desiderata. Furthermore, while James and Stein (1961) assumed an isotropic \(\), subsequent estimators such as the following variant of an estimator due to Bock (1975) do handle heteroskedastic \(\):3 
\[}_{}^{}()=+(1- -)^{}^{-1}(-)})_{+}(-),\] (6)

where \(()_{+}=\{,0\}\), and \(^{d}\) is a default estimate towards which \(\) is shrunk.4

However, empirically we find that this often underperforms the pooled estimator in low-sample regimes; further, the form of \(}_{}^{}\) shows that the amount of shrinkage towards \(\) is the same for each coordinate \(g[d]\), despite intuition suggesting that we should shrink less for groups \(g\) with more samples. Corrections to this tend to be involved and difficult to generalize (Efron and Morris, 1973).

We thus turn to a different family of well-known Gaussian mean estimators: those that return the mode of the posterior distribution assuming \(\) is sampled from the conjugate prior \((,)\) with mean \(^{d}\) and positive-definite covariance \(^{d d}\) (e.g., Gelman et al. (2014, Equation 3.12)):

\[}_{,}^{}()=( ^{-1}+^{-1})^{-1}(^{-1}+^{-1} ).\] (7)MAP naturally handles heteroskedasticity by weighting low-variance coordinates \(g\) more heavily, satisfying our third criterion; however, its most general form has \((d^{2})\) hyperparameters, violating the second. We next use problem structure to restrict the number of hyperparameters needed to define \(\) while still allowing \(}_{,}^{}\) to express every baseline introduced in SS2.1, satisfying our first criterion.

#### 3.1.1 An additive intersectional effects prior

For brevity, we build up our estimator somewhat informally; a full description is in SSC.1. We return to our simple example where each group \(g[d]\) corresponds to an intersection \((s,a)[d_{1}][d_{2}]\) of two attributes: a sex \(s[d_{1}]\) and an age \(a[d_{2}]\). A simple prior that additively incorporates individual attribute effects into intersectional group means is the following:

\[_{g}=_{}+_{}_{a}^{}+_{ }_{a}^{}+_{}_{g}+_{g}\] (8)

where \(^{d}\) and \(_{},_{},_{},_{} _{ 0}\) are hyperparameters, \((0,1)\) is a scalar effect shared across all groups, the vector \(^{}^{d_{1}}\) has its \(s\)th entry \(_{a}^{}(0,1)\) shared by all groups \(g\) whose sex is \(s\), the vector \(^{}^{d_{2}}\) has its \(a\)th entry \(_{a}^{}(0,1)\) shared by all groups \(g\) whose age is \(a\), and the vector \((_{d},_{d})\) contains an independent noise term \(_{g}\) for each group \(g\).

The hyperparameter \(_{}\) quantifies how much we expect all of the means to be shifted (by a shared positive or negative value) from the default \(\). Hyperparameters \(_{}\) and \(_{}\) express how large we expect contributions of sex and age alone to be towards the means. And finally, non-zero \(_{}\) gives the prior flexibility to model heterogeneity across all intersectional groups.

Given the vector of hyperparameters \(=(_{},,_{})_{ 0}^{4}\), the prior can be written more compactly as \((,( ))\), where the covariance is

\[()=_{A\{\}} _{A}^{2}_{A}=_{}^{2}_{}+_{ }^{2}_{}+_{}^{2}_{ {age}}+_{}^{2}_{}\] (9)

for matrices \(_{A}\{0,1\}^{d d}\) s.t. each entry \(C_{A;g,h}\) is one iff groups \(g\) and \(h\) agree on the attributes included in \(A\). In particular, we have that \(_{}=_{d d}\) is the all-ones matrix, the entries \(C_{;g,h}\) of \(_{}\{0,1\}^{d d}\) are one iff groups \(g\) and \(h\) share the same sex attribute, the matrix \(_{}\) is analogous, and \(_{}=_{d}\) is the \(d d\) identity. This structure is visualized in Figure 1.

Figure 1: Matrices \(_{A}\{0,1\}^{d d}\), whose linear combination defines the covariance \(()\) of our additive intersectional effects prior (Eq. 9). In this example, there are two categories for sex (F,M) and three for age (<25,25-64,>64), yielding \(d=6\) groups. Shaded squares are 1s, unshaded are 0s.

#### 3.1.2 Efficiency and expressivity

As detailed in SSC.1, this prior can be naturally extended to any number of attributes \(k\) using a covariance matrix \(()^{d d}\) specified by a vector \(^{2^{k}}_{ 0}\) of \(2^{k}\) hyperparameters. Since \(k_{2}d\), the total number of hyperparameters (including \(^{d}\)) is \(d+2^{k}=(d)\), which is much smaller than the \((d^{2})\) complexity of the general case. We can further reduce this by fixing the entries of \(\), constraining them to be identical, or setting them using external (e.g., multi-task) data.

Despite this reduction in hyperparameters, we can show that for a suitable choice of \(\), the estimator \(}_{,()}^{}\) recovers many estimators of interest, including the naive estimator and the (possibly offset) pooled estimator (see SSC.2). This means that MAP with our structured prior should be able to outperform all four baselines from the previous section, if appropriately tuned.

### Tuning by minimizing expected risk

Having specified a parameterized estimator, there remains the question of setting its parameters \(\) and \(\). One might want to treat this as a hyperparameter tuning problem and use a data-splitting approach; however, the dimensionality of the problem makes standard techniques either expensive or noisy, and data splitting introduces additional randomness and design decisions into an already data-poor environment. We instead make continued use of our Gaussian assumption and turn to SURE, which given a differentiable estimator \(}:^{d}^{d}\) returns an unbiased estimate of its weighted MSE \(L_{}^{}\) using sample data \((,)\):

\[_{}^{}()=}{d}\|}()-\|_{^{-1}}^{2}-d+2_{ }}(),\] (10)

where given any \(_{d d}\) we denote \(\|\|_{}^{2}=,\)\(\)\(^{d}\). Using SURE we can now tune the parameters of \(}\) by minimizing \(_{}^{}()\) in a manner similar to empirical risk minimization.

#### 3.2.1 Single-task SureMap

In the single-task setting, we fix \(=_{d}\) and tune the variance parameters \(^{2^{k}}_{ 0}\). Letting \(()=(^{-1}()+^{-1})^{-1} ^{-1}()\), we define the **single-task SureMap estimator** as

\[}^{}()=}_{_{d },(})}^{}()=(_{d}- (}))\] (11) \[\;\;}=*{arg\,min}_{ ^{2^{k}}_{ 0}}\|()\|_{^{-1}}^{2}-2(()).\] (12)

The optimization problem in the second line comes from substituting \(}_{_{d},(})}^{}\) into SURE (Eq. 10). It is nonconvex, but we find that it can be quickly solved to sufficient accuracy with L-BFGS-B (Byrd et al., 1995), a standard method for bound-constrained optimization of differentiable functions.

#### 3.2.2 Multi-task SureMap

To generalize SureMap to the multi-task setting we propose to specify \(}\) and \(}\) by minimizing SURE aggregated across tasks, i.e., \(_{t=1}^{T}_{_{t}}^{_{t}}(_{t})\). While setting both parameters via direct optimization of this objective is the most straightforward approach, we find that it performs worse than single-task SureMap when there are only a few tasks (\(T 5\)) and rarely improves significantly above the multi-task global and offset estimators. This can be explained by observing the few-task limit--i.e. \(T=1\)--in which case optimizing the aggregated SURE objective results in setting \(}=_{1}\) and thus makes the multi-task estimator equivalent to the naive estimator.

We find that a better approach is to treat the choice of \(}\) as its own simultaneous mean estimation problem and apply the SureMap approach to it. In particular, our model \(_{t}(_{t},_{t})\) and our prior \(_{t}(,)\) imply that the samples \(_{t}(,+_{t})\) have mean \(\) and known covariances (apart from tuning parameters). Therefore, the MAP estimator of \(\) itself given a hyperprior \((_{d},)\) with covariance \(\) will have the form \(}=^{-1}+_{t=1}^{T}(+_{t})^{-1}^{-1}_{t=1}^{T}(+_{t})^{-1} _{t}\).

To reduce the number of tuning parameters, we use a prior of the same form as before by specifying \(=()\) for \(^{2^{k}}_{ 0}\), i.e., the same structured covariance as described in SS3.1.1 but with separately tuned parameters (see SS3.1.1 and SSC.1). Substituting the meta-level MAP estimator of \(\) into the MAP estimator of \(_{t}\) and tuning the parameters \(\) and \(\) by optimizing the sum of SUREs (Eq. 10)

[MISSING_PAGE_EMPTY:7]

**Common Voice.** This is a single-task dataset obtained by combining the validation and test partitions of the CV dataset. We calculate the word-error rate (WER) across all the utterances of each individual, which becomes the target metric to be predicted.

**Common Voice Clusters (CVC).** This is a multi-task ASR dataset. To construct it, we first cluster the utterances in the train partition of the CV dataset into 20 clusters by applying \(k\)-means to the sums of Glo've word embeddings (Pennington et al., 2014) of their corresponding text strings. To model task relatedness, we then randomly reassign each utterance to a random cluster with probability \(\). The resulting clusters are the tasks. The target metric is the word-error rate (WER) across all the utterances of each individual in a given cluster. In most experiments we use \(=\), but we also investigate what happens when \(\) varies between zero, i.e., the original clusters, and one, corresponding to identically distributed tasks.

## 5 Evaluation

Our main metric is MAE relative to a ground truth vector, which we take to be the mean of all available data for each subpopulation \(g[d]\), except those with fewer than 40 samples. In our main results we subsample with replacement from the entire dataset at different rates and track performance as a function of the sizes of the resulting datasets. To obtain 95% confidence intervals we conduct 200 and 40 random trials at each subsampling rate in the single-task and multi-task settings, respectively.

### Single-task

We compare SureMap to the naive (Eq. 2) and pooled (Eq. 3) baselines, as well as to the Bock estimator with shrinkage towards the pooled estimator (Eq. 17) and the structured regression estimator of Herlihy et al. (2024). On both Diabetes and Adult, SureMap significantly outperforms all competitors (Figure 2, top & middle), the greatest improvement is on subpopulations with limited data. In SSG, we consider a regression variant of Diabetes and observe similar results (Figure 8). On the Common Voice task, SureMap performs roughly similarly to Bock, while outperforming structured regression at some subsampling rates (Figure 2, bottom); here again the gains are driven

Figure 2: Single-task evaluations on Diabetes (top, disaggregating by race, sex, and age), Adult (middle, disaggregating by race, sex, and age), and Common Voice (bottom, disaggregating by sex and age). The MAE is averaged across all groups (left), large groups (center), or small groups (right). Large and small groups are defined as above and below median group size.

by better performance on small groups. Pooling performs best when data is extremely limited, but it is not competitive with even modestly more data, and also underperforms on small groups.

### Multi-task

In the multi-task setting, we use all the single-task methods as baselines while adding multi-task (MT) ones, including MT global (Eq. 4), MT offset (Eq. 5), and an MT extension of Bock (Eq. 6) in which \(_{g}\) is set using the average across the group \(g\) data on all _other_ tasks. We first consider the SLACS task, for which Figure 3 (top left) shows that MT SureMap significantly outperforms other methods in the low-data regime while matching the best one (MT Bock) in the high-data regime. At subsampling rate 0.1, Figure 3 (top right) also shows that using multi-task data leads to improvement on all but two of the fifty tasks, that the reduction in MAE over the naive estimator on a typical task is 2x, and that this improvement only loosely correlates with the task's ground truth distance from the multi-task median. On the other hand, it also shows that while MT Bock's improvements are typically smaller, on SLACS it improves performance for _every_ state (including the two where MT SureMap is worse).

On the CVC task, the MT offset baseline is the most competitive, except at the lowest subsampling rate where pooling is better and at higher subsampling rates where it stops improving with additional data (Figure 3, bottom left). SureMap outperforms it and all other methods across all subsampling rates and its advantage is greatest in low-data regimes, where it even outperforms pooling. In the task-level evaluation in Figure 3 (bottom right) we see that on every task, MT SureMap attains an improvement of 2-3.5x over the naive baseline _and_ almost always outperforms MT Bock. Furthermore, the latter performs substantially worse on tasks whose ground truth vectors are far away from the multi-task center while MT SureMap is not affected.

### Ablations

We next look at how the degree of included intersectional effects and multi-task structure affect performance. In Figure 4 (left), we evaluate utility of including higher-order interactions in the structured prior. We implement SureMap variants with up to \(\)th-order interactions by setting \(_{A}\) for \(|A|\{+1,,k-1\}\) to zero (but not for \(|A|=k\)). We observe that including zeroth-order effects (\(=0\)) in single-task SureMap (i.e., shrinkage to pooling) improves upon the usual single-parameter Gaussian prior (\(=-1\)) in low-data regimes. Adding first-order effects (\(=1\)) leads to substantial further im

Figure 3: Multi-task evaluations on SLACS (top, disaggregating by race, sex, and age) and CVC (bottom, disaggregating by sex and age). _Left:_ Performance across different subsampling rates. _Right:_ Multiplicative improvement in MAE over naive estimator on individual tasks; subsampling rate=0.1.

provement, but second-order effects (\(=2\)) make performance slightly worse. A similar effect can be observed among the multi-task variants, except there is no loss (but also no gain) to using the highest-order variant (\(=2\)). Overall, this study suggests that using the full-order SureMap is a reasonable default but that most of the method's effectiveness comes from zeroth- and first-order effects.

Figure 4 (right) tracks performance as the task-similarity parameter defining the CVC task is varied. MT SureMap outperforms all methods at all settings and is also not as strongly affected by the task similarity, at least as it is defined for the CVC data. This suggests that the structured prior we use may be useful even if the dataset means are quite different but the underlying evaluation problem (in this case estimating WER of ASR models) is the same.

Lastly, in Figure 5 we study how the number of tasks affects multi-task performance. On both SLACS and CVC, MT SureMap outperforms all single-task baselines (the best one being the single-task SureMap) at \(T=2\) tasks, i.e., it can take advantage of even very little external information. In contrast, on CVC, the competitor multi-task methods (e.g., MT offset and MT Bock) do not even outperform single-task methods until \(T 5\) tasks. These results demonstrate that, unlike these comparators, multi-task SureMap can be confidently used even when only one additional client's worth of data is available.

## 6 Conclusion

We have introduced SureMap, a disaggregated evaluation approach, which combines MAP estimation under a structured Gaussian prior with hyperparameter tuning via SURE. SureMap achieves substantial empirical improvements over strong baselines in both single-task and multi-task settings. Valuable future directions include improving robustness to heavy-tailed data and developing multi-task methods that can handle client privacy concerns. More broadly, we hope our work will have a positive impact by allowing model users to more accurately identify fairness-related harms, the first step towards mitigating them. However, using SureMap and any other disaggregated evaluation approach must be done with care, so as to not risk overconfidence in a model's fairness.

Figure 4: _Left:_ Comparison of SureMap variants on SLACS. The SureMap (\(\)) variant sets to zero the entries of \(\) corresponding to interactions of size \(>\) (except for the highest-order interactions). _Right:_ Evaluation of different methods as the interpolation coefficient that defines the CVC tasks is varied.

Figure 5: Performance as the number of tasks varies, evaluated on SLACS (left) and CVC (right).