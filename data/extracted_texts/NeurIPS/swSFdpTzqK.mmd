# Dataset and Preprocessing

[MISSING_PAGE_EMPTY:1]

**Federated learning (FL)** has emerged as a promising solution to these challenges by enabling multiple institutions to collaboratively train models without sharing sensitive data (Fig. 1) [10; 11]. This approach preserves privacy while leveraging the collective power of diverse datasets. This work proposes a **federated learning framework** based on the Message Queuing Telemetry Transport (MQTT) communication protocol to predict stroke severity using Graph Neural Networks (GNNs) on brain networks extracted from EEG data. GNNs are particularly suited for this task due to their ability to model complex relationships within brain networks, capturing both structural and functional connectivity patterns to provide a better assessment of the stroke impact on brain regions [12; 13; 14; 15]. Moreover, the integration of **explainability mechanisms** enhances the interpretability of the model, which is of primary importance in clinical settings where understanding the rationale behind networks' decisions is critical.This study utilizes a comprehensive dataset comprising EEG recordings from 72 patients collected during hospitalization across four medical centers. The EEG data were analyzed across various frequency bands to construct brain connectivity graphs. The distribution of patients among the hospitals is shown in Fig. 2. A standardized data collection protocol was implemented across all hospitals. EEG signals were recorded at rest, with patients' eyes closed, for at least \(5\) minutes during their stay in the stroke unit. The recordings were obtained using \(31\) electrodes positioned according to the international \(10-10\) system, with a common reference electrode placed on the mastoid and a ground electrode.

The EEG data were preprocessed with a band-pass filter between \(0.2\) and \(47\) Hz at a \(512\) Hz sampling rate, followed by artifact removal through Independent Component Analysis (ICA) . Next, eLORETA  was employed to reconstruct whole-brain sources and calculate Lagged Linear Coherence (LLC) graphs for the first five frequency bands: \(\) (\(2-4\) Hz), \(\) (\(4-8\) Hz), \(_{1}\) (\(8-10.5\) Hz), \(_{2}\) (\(10.5-13\) Hz), and \(_{1}\) (\(13-20\) Hz) .

The NIH Stroke Scale (NIHSS) is an objective assessment tool to quantify the impact of stroke-related events. Initially intended to evaluate the effects of intervention in clinical trials, it has since become a standard tool in clinical and emergency settings for assessing stroke severity. It is an integer value between \(1\) and \(42\), which quickly determines the level of neurological impairment and guides treatment decisions by systematically evaluating factors such as consciousness, visual fields, motor function, and language ability.

Despite the growing interest in applying graph theory to brain graphs in the context of neuroscience [18; 19; 20; 21], existing approaches often fall short in addressing the unique challenges posed by EEG data. Traditional models lack the structured inductive bias required to capture the connectivity patterns inherent in EEG data [22; 23; 24; 7]. Our approach addresses these limitations and ensures that collaborating institutions maintain data privacy [25; 26; 27]. In particular, our

Figure 1: Illustration of a FL setup with hospitals acting as nodes. Each hospital processes data locally while sharing model updates (represented by arrows) with a central server.

approach leverages explicitly a **multilayer GNN** to capture insights from graphs extracted from the five different EEG frequency bands defined above. The multilayer network representation allows for integrating information from various neural oscillatory patterns, enabling the model to learn interactions across different frequency bands and enhancing its ability to predict stroke severity.

ContributionsIn this work, we design a federated learning framework building upon recent work on Multilayer Dynamic Graph Attention Networks for neurological assessments  to predict stroke severity from EEG signals in a privacy-preserving setup. This enables multiple healthcare institutions to unify multiple graph representations. We evaluate both FedAvg  and SCAFFOLD  algorithms, comparing their performance in handling the statistical heterogeneity inherent in multi-institutional EEG data. Our federated learning system integrates MQTT as an efficient communication protocol, demonstrating its security in dispatching model updates and aggregation across distributed clients. We validate our method approach on a dataset of EEG recordings from 72 stroke patients across multiple institutions, demonstrating its effectiveness in providing accurate predictions while ensuring data privacy and robustness. Finally, we provide interpretable explanations of model decisions using EdgeSHAPer  to allow for transparent and trustworthy decisions of our predictive framework.

## 2 Background and Related Works

This section reviews the concepts of GNNs and FL and discusses previous studies related to EEG-based stroke assessment.

### Graph Neural Networks

GNNs operate on graph-structured data, where a graph \(=(,)\) consists of nodes \(v\) and edges \((u,v)\). Each node \(v\) is associated with a feature vector \(_{v}^{d}\). GNNs can be formally defined as functions of the form \(_{}:(,\{_{v}\}_{v V},)  y_{}\), where \(\) represents a set of trainable parameters. The core idea behind GNNs is to learn node or graph-level representations by iteratively updating node features through message passing:

\[_{v}^{l+1}=(_{v}^{l},(v)}{}((_{u}^{l},_{v}^{l},_{uv}))),\] (1)

where \(_{v}^{l}\) represents the hidden feature vector of \(v\) at layer \(l\), and \(_{v}^{0}=_{v}\), while \((v)\) is the set of neighbors of \(v\). For the edge between \(u\) and \(v\), \(_{uv}\) represents its hidden feature vector. The function com updates the hidden feature vector with messages received from \(u(v)\), agg is a permutation-invariant aggregation function and \(\) is a message function.

Graph Attention NetworksGATv2  introduces a self-attention mechanism to account for the varying importance of neighboring nodes during message passing. For a node \(v\) and its neighbor \(u(v)\), the attention score \(s_{}(_{v},_{u})\) is computed as \(s_{}(_{v},_{u})=^{}( [_{v}_{u}])\), where \(\) is a learnable weight matrix, \(\) is a learnable vector of attention coefficients, \(\) is the LeakyReLU activation function and \(\) denotes concatenation. The attention scores are then normalized via \(_{v,u}=_{u(v)}(s_{}(_{v},_{u}))\).

### Multi-layer Brain Networks

To represent brain connectivity across different frequency bands, a multi-layer graph approach has been proposed . The multi-layer graph \(\), illustrated in Fig. 3, is defined as \(=\{_{_{1}},_{_{2}},_{ _{1}}\}\), where each \(_{i}=(,_{i})\) represents a graph for a specific frequency band, sharing the same vertices

Figure 2: Number of patients for each hospital in our federation.

V but with unique edge sets \(_{i}\). Inter-layer edges \(_{}\) connect nodes across different layers, allowing cross-frequency communication.

**Rewiring Brain Networks** To address the issue of over-smoothing [32; 33] in fully connected graphs when using GNNs, a rewiring strategy has been developed . This process transforms the graph \(_{l}=(,_{l})\) of each brain network layer into a sparse graph \(^{}_{l}=(,^{}_{l})\) through structural and functional rewiring.

1. **Structural Rewiring**: a spatial proximity function \(:^{+}\) is defined based on Euclidean distance between Brodmann areas. For each node \(v\), the \(k=3\) spatially closest nodes are selected.
2. **Functional Rewiring**: a function \(_{l}:_{l}\) is defined, mapping each edge to its LLC value in layer \(l\). Edges above the \(99^{th}\) percentile of LLC values are retained. The final set of edges in the rewired graph for each layer is \(^{}_{l}=_{}\ \ _{}\{(v,v):v\}\), where \(_{}\) represents structural connections, \(_{}\) represents functional connections, and self-loops are included.

This rewiring strategy reduces edge density (retaining only \( 5\%\) of the initial number of edges) while preserving critical functional and structural information, enhancing the GNN's ability to learn from the underlying brain network topology.

The proposed GNN architecture, combined with the multi-layer graph representation and rewiring strategy, allows effective learning from the complex, sparse brain networks derived from EEG data.

### Federated Learning

FL is a paradigm that enables collaborative model training across a federation of multiple institutions [10; 34]. This approach has gathered interest in domains like digital healthcare, where regulations and ethical considerations often restrict data sharing . Formally, let \(_{c_{i}}\) represent the local dataset on client \(c_{i}\) and \(\) denote the global model parameters. Each client \(c_{i}\) updates the global model by minimizing a local loss function \(_{c_{i}}(;_{c_{i}})\). The global objective can be expressed as:

\[_{}_{i=1}^{N}}{n}\ _{c_{i}}( ;_{c_{i}})\] (2)

where \(n_{i}\) is the number of samples on device \(c_{i}\) and \(n=_{i=1}^{N}n_{i}\) is the total number of samples across all devices.

**Federated Averaging (FedAvg)** is one of the most popular algorithm for FL aggregation . FedAvg aims to address the challenges of statistical heterogeneity among participants in federated systems. The algorithm operates as follows: the server initializes the global model parameters \(^{0}\). Then, for each round \(r=1,,R\), the server _samples a subset of clients_\(S_{r}\) according to a probability distribution \(\) and sends the current global model \(^{r-1}\) to each of the clients in the sampled subset. Each client \(c_{i} S_{r}\)_updates the model locally_ using their dataset \(_{c_{i}}\) by computing \(^{r}_{c_{i}}=(^{r-1},c_{i})\), where OPT is the local optimization algorithm (e.g., SGD,

Figure 3: Illustration of the multi-layer network structure. Each layer corresponds to a specific frequency band, with inter-layer connections helping cross-frequency information flow .

Adam, RMSProp). The clients then _send their updated models_ back to the server. The server _aggregates these local models_ to update the global model using a weighted average:

\[^{r}=_{c_{i}_{r}}}}{n_{S_{r}}}\, ^{r}_{c_{i}}\] (3)

where \(n_{c_{i}}=|_{c_{i}}|\) and \(n_{S_{r}}=_{c_{i}_{r}}n_{c_{i}}\). This process repeats for \(R\) rounds, resulting in the final global model \(^{*}=^{R}\). FedAvg unifies the representations learned by individual clients on their local datasets into a single global model by aggregating their locally updated models. This process effectively captures patterns and features from each client's data, integrating them into a single model that generalizes across the entire dataset distribution. This way of averaging local models allows FedAvg to unify the collective knowledge of all clients into a single representation while preserving data privacy, resulting in an improved global model without direct access to the client's raw data.

**Stochastic Controlled Averaging for Federated Learning (SCAFFOLD)** is an algorithm proposed in  to address the client drift problem in heterogeneous settings. SCAFFOLD introduces control variates to correct for the drift in local updates. thereby aligning the clients' learning processes more closely with the global objective. Initially, the server initializes the global model parameters \(^{0}\), the server control variate \(c^{0}\) and sets all client control variates \(c^{0}_{c_{i}}=0\) for each client \(c_{i}\). For each round \(r=1, R\), the server samples a subset of clients \(S_{r}\) according to a probability distribution \(\) and sends the current global model \(^{r-1}\) along with the server control variate \(c^{r-}\) to the selected clients.

Each client \(c_{i} S_{r}\) initializes their local model with the global model: \(^{r,0}_{c_{i}}=^{r-1}\). The client then performs \(K\) local update steps. At each local step \(k=1, K\), the client updates the model as:

\[^{r,k}_{c_{i}}=^{r,k-1}_{c_{i}}-_{l}( F_ {c_{i}}^{r,k-1}_{c_{i}}-c^{r-1}_{c_{i}}+c^{r-1})\] (4)

where \(_{l}\) is the _local learning rate_, \( F_{c_{i}}^{r,k-1}_{c_{i}}\) is the gradient of the local loss function for client \(c_{i}\), \(c^{r-1}_{c_{i}}\) is the client control variate, and \(c^{r_{1}}\) is the server control variate. After completing the local updates, the client computes the model update: \(_{i}=^{r}_{c_{i}}-^{r-1}\), and updates its control variate as:

\[c^{r}_{c_{i}}=c^{r-1}_{c_{i}}-c^{r-1}+K)}_{i}\] (5)

The client then returns \(_{i}\), and the updated control variate \(c^{r}_{c_{i}}\) to the server. Upon receiving the updates from all participating clients, the server aggregates the update to update the global model and the server control variate:

\[^{r}=^{r-1}+}{|S_{r}|}_{c_{i} _{r}}_{i}\] (6)

\[c^{r}=c^{r-1}=|}_{c_{i}_{r}}(c^{r}_{c_{i}}-c^ {r-1}_{c_{i}})\] (7)

This process repeats for \(R\) rounds, resulting in the final global model \(^{*}=^{R}\).

SCAFFOLD enhanced model aggregation over FedAvg by utilizing control variates to correct for client drift caused by data heterogeneity. In particular, adjusting local updates with these control variates allows SCAFFOLD to ensure that the federated learning process aligns clients' representation into a unified global model that remains synchronized with the global objective, mitigating undesired effects of non-I.I.D. data distributions due to statistical heterogeneity. Consequently, SCAFFOLD is a theoretically sound algorithm that aims to achieve a more accurate and generalized global model that unifies the collective knowledge of all clients while preserving data privacy. It is also worth emphasizing that if an early stopping mechanism is implemented for FedAvg and SCAFFOLD, the training may end at an earlier round \(r^{}<R\) when certain convergence criteria are met (e.g., the validation loss stops decreasing). In this case, the final global model becomes \(^{*}=^{r^{}}\).

### Edge Shapley Values for Model Explainability

While the model in  effectively predicts stroke severity from EEG data, its interpretability is limited to the noise introduced by random initialization of the attention coefficients \(a\). In particular,the functional communication between brain regions allows clinicians to understand _why_ the model makes specific predictions, allowing clinicians to trust and utilize these insights in personalized treatment plans. Traditional attention mechanisms provide some interpretability by highlighting important nodes and edges, but they often lack a theoretically grounded measure of each edge's contribution to the prediction.

To address this gap, we incorporate **EdgeSHAPer**, as an edge-centric explanation method based on the Shapley value concept from cooperative game theory . EdgeSHAPer assigns a Shapley value to each edge in the brain network, quantifying its contribution to the model's output. This method uses a principled way to assess the importance of individual neural connections, thereby offering more profound insights into the brain's functional reorganization after a stroke.

EdgeSHAPer estimates the Shapley value \((e_{i})\) for each edge \(e_{i}\) in the graph \(\), representing the average marginal contribution of \(e_{i}\) to the model's prediction over all possible subsets of edges. The Shapley value for an edge is defined as:

\[(e_{i})=|}_{S\{e_{i} \}})-f(S)}{|-1}{|S|}}\] (8)

where \(\) is the set of all edges in \(\), \(S\) is a subset of edges not containing \(e_{i}\), and \(f(S)\) is the model's prediction when only the edges in \(S\) are present. The factorial terms account for all possible orderings of edges, ensuring a fair attribution of importance. Computing the exact Shapley values is computationally intractable for graphs with many edges due to the combinatorial number of subsets. Therefore, we employ a Monte Carlo approximation :

\[(e_{i})_{k=1}^{M}[f(S_{k} e_{i})-f(S_{k}) ],\] (9)

where \(M\) is the number of sampled subsets \(S_{k} E\{e_{i}\}\). We generate these subsets by random sampling, ensuring that each edge's contribution is estimated over diverse contexts.

### Related Works

The impact of acute stroke on the topology of cortical networks has been extensively investigated through EEG analysis, revealing significant, frequency-dependent alterations in network properties. Specifically, stroke leads to decreased small-worldness in the \(\) and \(\) bands and increased small-worldness in the \(_{2}\) band across both hemispheres, regardless of lesion location . Distinct modifications in functional cortical connectivity due to acute cerebellar and middle cerebral artery strokes have been highlighted, showing different impacts on network architecture and small-world characteristics across various EEG frequency bands, independent of ischemic lesion size .

Additionally, research has shown that acute cerebellar and middle cerebral artery strokes distinctly affect functional cortical connectivity, with significant differences in EEG-based network remodeling across \(\), \(_{2}\), and \(\) frequency bands, highlighting the unique impact of stroke location on brain network dynamics . The prognostic role of hemispherical differences in brain network connectivity in acute stroke patients has been explored using EEG-based graph theory and coherence analysis. Findings indicate that stroke-induced alterations in network architecture can predict functional recovery outcomes, providing a basis for tailored rehabilitation strategies .

The relevance of brain network analysis for stroke rehabilitation has been studied, highlighting the potential of network-based approaches to inform and guide therapeutic interventions in stroke recovery . Dynamic functional reorganization of brain networks post-stroke has been emphasized, providing critical insights into the brain's adaptive mechanisms following a stroke and supporting network analysis to understand structural and functional reorganization . Finally, changes in the contralesional hemisphere following stroke and the implications of the stroke connectome for cognitive and behavioral outcomes have been explored, enhancing our understanding of the complex network dynamics involved in stroke pathology and recovery 

## 3 Experimental setup

We designed two distinct federated learning setups to investigate how data distribution affects model performance. The first configuration mimics real-world conditions by treating individual hospitalsas clients in the federation, reflecting the natural data distribution within healthcare systems. We curated three evenly distributed datasets in the second setup, creating a more controlled, idealized scenario. By comparing these two approaches, we assess whether having a representative distribution of the entire dataset at each client significantly impacts the learning outcomes. All experiments were conducted using the same model architecture and training hyper-parameters. We used a batch size of \(2\) and applied the mean squared error (MSE) loss function. We implemented gradient clipping with a threshold of \(10\) to avoid exploding gradient issues. The model's parameters were optimized using the Adam optimizer with a learning rate of \(0.003\) and a weight decay of \(0.01\) to prevent overfitting. For both setups, we fixed a test set by randomly sampling \(11\) elements across the clients to be representative of the overall data distribution, ensuring consistency in the evaluation process and reducing the risk of bias. We used \(M=100\) for the Monte Carlo approximation in 9 to estimate Shapley values efficiently.

**Network architecture and Communication Protocol** The model architecture was built on top of the GATv2 message-passing scheme . The core GNN consisted of \(3\) GATv2 layers, each with \(6\) attention heads. To reduce overfitting, we incorporated dropout with a \(0.1\) probability of randomly deactivating neurons during training and used the ReLU activation function for non-linearity. A mean pooling layer was employed as the readout operation following the final GNN layer.

At the core of federated learning systems lies the need for efficient communication protocols to maintain model performance under resource constraints . Ensuring efficient and secure data exchange among distributed actors of federated systems requires carefully tailoring the protocol for communicating models' parameters among the network nodes. We chose the MQTT protocol instead of HTTP REST for our setup due to superior bandwidth efficiency, lower latency, and low overhead, making it suitable for low-power IoT devices . On top of the aforementioned benefits, MQTT offers one-to-many communication, which is the central point when distributing global models during FL rounds. It also supports large message payloads (with fragmentation if necessary), serialization, and compression. The communication network orchestrates FL processes through MQTT's publish-subscribe mechanism. Clients (healthcare institutions) exchange model parameters and configurations by publishing their local models and downloading global models via specific MQTT topics .

This architecture handles both synchronous (all clients wait for each other) and asynchronous (clients act independently of others) FL operations. For the FL orchestration, there are four different setups:

1. Both the Parameter Server (PS) and the clients operate synchronously, waiting for all clients to finish local model optimization before aggregating the global model.
2. The PS is synchronous, but clients are asynchronous, continuing local training until they receive a global model update.
3. Both PS and clients are asynchronous, where the PS aggregates models at regular intervals, regardless of client completion.
4. Fully decentralized and asynchronous, clients exchange models directly via MQTT without a central PS.

We chose option (a) for our experimental setup since we prioritize stability and consistency in the model aggregation process due to the small data samples. All MQTT exchanges are encrypted via TLS, and the MQTT broker manages local models until training is completed. The flexible architecture supports dynamic scaling based on task complexity and computational resources .

**Comparative Analysis:** Our experimental framework spans several learning paradigms, allowing us to comprehensively evaluate the performance of FL in the context of GNNs. The scenarios explored include:

1. **Realistic FL Setup:** Simulating real-world data distribution among hospital clients.
2. **Idealized FL Setup:** Using manually curated datasets with equal distribution.
3. **Centralized Learning:** Training a single model on the entire dataset pooled together.
4. **Isolated Learning:** Training separate models for each client without collaboration.

This approach allows us to:1. [label=()]
2. Examine how data distribution affects FL performance by comparing realistic and idealized setups.
3. Quantify the benefits of collaborative learning in FL versus training models independently for each client.
4. Analyze the trade-offs between FL and centralized learning, providing insights into the viability of FL in situations where data sharing is limited.

Computational Resources and Code AssetsIn all experiments we used a machine with an NVIDIA(r) RTX 3090 GPU with an Intel(r) Xeon(r) @ 2.30GHz on Ubuntu 22.04 LTS 64-bit. The model was implemented in PyTorch  by building on top of PyTorch Geometric library (MIT license) . PyTorch, NumPy , SciPy  are BSD licensed, Matplotlib  is PSF licensed.

## 4 Experimental result

The performances across different learning setups are summarized in Tab. 1. Results reflect the mean absolute error (MAE) and standard deviation across five initializations. The statistics are also computed across clients in isolated learning setups, while federated and centralized setups leverage collaborative training.

The **Isolated Learning** approach, where models are trained independently for each client, shows weaker performance compared to collaborative methods. In the realistic isolated learning setup, a MAE of \(3.68 0.26\) was obtained, while the idealized isolated setup, though more controlled, resulted in a higher MAE of \(3.92 0.87\). The high variance in the idealized setting suggests that the data distribution across clients introduces inconsistencies in model performance, even when the data covers the full value range. This reflects the challenge of achieving stable results when training independently without data sharing.

**FL** consistently outperformed isolated learning. In the realistic FL setup, **FedAvg** achieved a MAE of \(3.23 0.06\), and **SCAFFOLD** slightly improved with an MAE of \(3.22 0.05\). This indicates the robustness of federated learning in harnessing distributed data while maintaining privacy. The marginal improvement of SCAFFOLD over FedAvg in the realistic scenario suggests that SCAFFOLD's correction of client drift is particularly beneficial when client data distributions closely resemble real-world conditions.

Performance was slightly lower in the **Idealized Federated Learning** setup, which uses a more balanced and mixed data distribution across clients. FedAvg reported MAE of \(3.34 0.08\), while SCAFFOLD had an MAE of \(3.44 0.07\). Although more evenly distributed, the idealized setup may obscure the natural variations in client data in realistic conditions. This could explain why models trained in the idealized setup generalize less effectively to the test set, which likely follows a more realistic data distribution. Thus, the realistic setup mirrors client-specific data patterns, enhancing predictive accuracy.

The **Centralized Learning** setup, where all client data is pooled into a single model, achieved a MAE of \(3.22 0.12\), which is identical to the performance of the **Realistic Federated Learning** setup using the SCAFFOLD algorithm. This highlights that federated learning, when properly configured, can achieve the same level of accuracy as centralized learning without requiring data sharing. Given the privacy constraints in medical settings, federated learning presents a substantial

  
**Experiment** & **Setup** & **Algorithm** & **MAE** \\   & Realistic & - & \(3.68 0.26\) \\  & Idealized & - & \(3.92 0.87\) \\   & Realistic & FedAvg & \(3.23 0.06\) \\  & & SCAFFOLD & \(3.22 0.05\) \\   & Idealized & FedAvg & \(3.34 0.08\) \\   & SCAFFOLD & \(3.44 0.07\) \\  Centralized Learning & - & - & \(3.22 0.12\) \\   

Table 1: Mean and standard deviation across five different initializations for each setup. In isolated learning, the statistics are also computed across the different clients.

alternative, offering equivalent performance while preserving data locality and complying with privacy regulations. Fig. 4 provides further insights into model convergence across different setups. The plot shows that centralized learning achieves the fastest convergence, as expected, given its access to the full dataset. Among federated approaches, the realistic setup converges as smoothly as the idealized setup.

**Explainable Insights**  Integrating EdgeSHAPer values into our framework enables us to assign a Shapely value to each edge, which offers several key advantages:

1. **Quantitative Edge Importance**: Shapley values provide a theoretically robust measure of each edge's significance, enabling us to rank physiological connections based on their contributions to the model's predictions. This quantitative assessment ensures a fair and consistent evaluation of edge importance across brain networks.
2. **Interpretable Visualizations**: We visualize the brain network by coloring edges based on their corresponding Shapley values and sizing nodes according to their weighted degree centrality derived from those values (see Fig. 5). This dual representation effectively highlights critical brain regions and their interconnections, making the network dynamics more comprehensible.
3. **Actionable Insights**: Identifying the most significant edges allows clinicians to understand which neural pathways were most affected by the stroke. This understanding informs the development of targeted therapeutic interventions, enabling personalized treatment plans that address the specific neural disruptions identified by our model.

We used a similarity metric based on the normalized Euclidean distance to assess the similarity between different model variants. This metric was applied to compare sets of weight vectors derived from the various experiments. Our analysis revealed an average similarity of \(0.76\), indicating high coherence among the weight vectors. Notably, the _idealized subgroup_ exhibited an average similarity of \(0.75\), while the _realistic subgroup_ achieved a higher similarity of \(0.78\). The similarity matrix demonstrated consistently high values across all vector pairs, ranging from \(0.73\) to \(0.78\). This approach provides insights into the convergence patterns and consistency of diverse federated learning strategies and setups. Furthermore, these results align with our observations regarding the best MAE, suggesting a strong correlation between higher performance metrics and more cohesive latent representations. Fig. 5 illustrates these findings, depicting the Edge Shapley Values for our federated learning setups and highlighting the relative contributions of different nodes and edges to the model's predictions.

Figure 4: Convergence of MAE over training rounds for different setups. Centralized learning shows the fastest and most stable convergence. The federated learning setups converge more slowly but arrive at the same level as the centralized. The isolated learning approaches exhibit higher error and slower convergence, confirming the benefits of collaborative training in federated setups.

## 5 Conclusions

**Broader Impact** The proposed federated learning framework for stroke assessment can assist clinical neuroscientists' evaluations by enabling collaborative research and model development across multiple institutions while maintaining strict data privacy. By allowing hospitals to unify insights without sharing raw patient data, this approach addresses privacy concerns and broadens the scope of multi-healthcare collaborations. The model's ability to predict stroke severity with an error rate close to human performance and interpretability modules can help clinicians better understand brain network changes post-stroke, leading to more personalized treatment plans.

**Limitations** While the proposed federated learning framework offers significant privacy advantages and demonstrates solid predictive performance, some limitations must be acknowledged. First, the relatively small sample size of 72 patients restricts the model's generalizability to more extensive and diverse clinical populations. Additionally, scalability to broader multi-institutional settings may face challenges due to variations in data quality, preprocessing protocols, and hardware capabilities across institutions.

**Conclusion** This study introduces a novel federated learning framework using GNNs for neurological assessments, demonstrating its ability to predict stroke severity from EEG data across multiple institutions. We show the effectiveness of collaborative model training while preserving data privacy. Incorporating explainability through EdgeSHAPer further enhances the model's potential clinical relevance by providing insights into the neural connections driving predictions. Future work will focus on expanding the dataset and addressing the technical challenges of scaling the system to larger, more diverse populations.

Figure 5: Illustration of Edge Shapley Values for various federated learning setups for the same patient. The color intensity is proportional to the contributions to model predictions. Node sizes are proportional to their weighted degree centrality, adjusted for the number of connections, highlighting each node’s significance within the network.