# Full-Distance Evasion of Pedestrian Detectors in the Physical World

Zhi Cheng

Department of Computer Science and Technology, Tsinghua University, Beijing, China

Zhanhao Hu

Department of Electrical Engineering and Computer Sciences, UC Berkeley

Yuqiu Liu

Department of Technology, Beijing Forestry University, Beijing, China

Jianmin Li

Department of Computer Science and Technology, Tsinghua University, Beijing, China

Hang Su

Department of Computer Science and Technology, Tsinghua University, Beijing, China

Xiaolin Hu

Corresponding Author Department of Electrical Engineering and Computer Sciences, UC Berkeley

###### Abstract

Many studies have proposed attack methods to generate adversarial patterns for evading pedestrian detection, alarming the computer vision community about the need for more attention to the robustness of detectors. However, adversarial patterns optimized by these methods commonly have limited performance at medium to long distances in the physical world. To overcome this limitation, we identify two main challenges. First, in existing methods, there is commonly an appearance gap between simulated distant adversarial patterns and their physical world counterparts, leading to incorrect optimization. Second, there exists a conflict between adversarial losses at different distances, which causes difficulties in optimization. To overcome these challenges, we introduce a Full Distance Attack (FDA) method. Our physical world experiments demonstrate the effectiveness of our FDA patterns across various detection models like YOLOv5, Deformable-DETR, and Mask RCNN. Codes available at https://github.com/zhicheng2T0/Full-Distance-Attack.git

## 1 Introduction

Currently, various adversarial attack methods have been proposed to evade deep-neural-network-based pedestrian detectors in the physical world  by crafting patches or clothes covered with adversarial patterns. These works have alarmed the computer vision community on the robustness of the existing Deep Nerual Network based detectors . However, as shown in previous works , a common limitation of the existing attack methods is that the generated adversarial patterns are not adversarially effective at medium to long distances (see also Figure 1(a)). This limitation might brings a false impression to the computer vision community that existing pedestrian detectors are robust to physical world attacks at such distances.

In this study, we find that the major cause of the aforementioned limitation is the naive distant image simulation technique used when optimizing the adversarial patterns. More specifically, as demonstrated in Figure 1(b), to simulate the appearance of a distant adversarial pattern during optimization, the existing attack algorithms usually naively downscale and apply the adversarial patterns according to the size of the pedestrians . Such a naive technique creates a widening appearance gap between the simulated patterns and their real-world counterparts as distance increases. This leads to the optimization of incorrect adversarial patterns.

To solve this problem, we propose a Distant Image Converter (DIC) to convert images of short-distance objects into an appearance similar to their physical world counterparts at long distances. In DIC, We find it necessary to simulate three factors in the physical world that contribute to the appearance gap. These factors include the effect of _atmospheric perspective_ which changes object colors due to increasing scattering of light as distance increases, the effect of _camera hardware_ which blurs the field of light projected from the target object to form a digital image, and the effect of the default _effect filters_ commonly installed in digital cameras which change the color and texture details of the captured images for better visual appearances.

By applying the DIC during optimization, we found that different low frequency patterns were required at short and long distances, causing a conflict, hindering full distance attack (FDA) pattern optimization. To overcome the difficulty, we propose a Multi-Frequency Optimization (MFO) technique.

By combining DIC and MFO, we form the FDA method which generates effective adversarial patterns for evading pedestrian detectors at varying distances. Our physical world experiments demonstrate the effectiveness of our FDA patterns across various detection models like YOLOv5 , Deformable-DETR , and Mask RCNN .

## 2 Background and Related Work

**Atmospheric Perspective.** Atmospheric perspective refers to the phenomenon that as distance increases, the observed color of a target object exponentially shifts toward the color of the skylight (color of the sky in the direction of the object) due to the scattering of light by air molecules, dust and moisture as distance increases. Figure 2 (a) illustrates the phenomenon and Figure 2 (b) gives an intuitive example, where trees with a color of green and yellow appear blue at long distances due to atmospheric perspective.

**Camera Imaging Pipeline.** To form an image, a camera receives an input light field and processes it through various lenses, including an anti-aliasing filter that blurs the light to prevent aliasing. Aliasing occurs when the camera's sensors naively sample the analog light field, leading to the incorrect recording of non-existent moire patterns (e.g., Figure 3 (b)) . The intuition of the phenomenon is illustrated in Figure 3 (c) with a 1-D example. That is, if the high-frequency blue curve is sampled at a low frequency, it can be inaccurately recorded as the red dotted curve with a wrong frequency. If a camera has a limited sampling rate, it may inaccurately sample high-frequency light information, resulting in moire patterns. To prevent aliasing, anti-aliasing filters, or blurring filters, are commonly

Figure 1: Illustrating FDA. (a) Visualizing attack performance of baseline  and FDA pattern. Red boxes are detection results from YOLOv5  with confidence greater than 0.5. (b) Appearance gap between the naively simulated patch and its physical world counterparts at different distances.

Figure 2: Atmospheric perspective. (a) Illustrating the phenomenon. (b) An example.

applied before the imaging chip to filter out the high-frequency information that the imaging chip cannot correctly sample. In Figure 3 (d), an example image obtained by applying the anti-aliasing filter before sampling is demonstrated. After different lenses, the light field would pass through the aperture and shutter, and get sampled by the imaging chip with an array of rectangular light sensors. In the imaging chip, each sensor produces an RGB value by averaging the light projected onto it, resulting in an output image  that is further blurred relative to the field of light from the anti-aliasing filter.

**Effect Filters.** After obtaining a digital image with the imaging chip, digital cameras typically apply a variety of effect filters to enhance the visual appeal of the images . Common effect filters include brightness, saturation, sharpening, exposure, contrast, highlight, shadow, vibrance, color temperature and so on. See Figure 3 (d) and (e) for visualization on the effect of applying the sharpening and contrast filters.

**Physical World Attacks with Adversarial Pattern.** A well-known limitation to deep learning models [13; 6; 30; 37; 26; 14; 8; 43] is that they are vulnerable to adversarial attacks [39; 9; 5; 28; 2]. Such a limitation makes crafting adversarial patterns effective for evading pedestrian detectors possible. Adv-Patch  is one of the earliest works that discovered adversarial patterns can disrupt detector decisions in the physical world. After that, many methods have been proposed to keep adversarial patterns effective when printed onto clothing (Adv-Tshirt ), to improve adversarial clothing performance at different angles (TCA ) and to improve naturalness of the adversarial clothing [33; 16; 18; 10]. In addition, many physical adversarial attack methods have been proposed for attacking vehicle detectors [35; 20; 7; 31; 15; 40], person re-identification models  and object tracking models[41; 4]. However, to the best of our knowledge, few works have addressed the decline of attack performance when distance increases.

## 3 Distant Image Converter

To bridge the appearance gap between distant adversarial pedestrian images in the physical and digital worlds, we propose to implement a Distant Image Converter (DIC). An intuitive solution is to train multiple neural networks, each specialized for image conversion at specific distances. However, this approach demands a large training set due to the large amount of parameters involved. In this work, we address this by implementing a physics-based DIC, leveraging principles of physics and camera hardware design. This ensures realistic image conversion with only 15 learnable parameters. Specifically, when given an input image, target distance, and environmental parameters like skylight RGB and turbidity values, the DIC should produces an output image that simulates the visual effect of positioning the input image at the target distance.

Figure 4: The overall pipeline of the DIC. The continuous arrows indicate the inference pipeline. The dashed arrows are used during training.

Figure 3: Factors influencing image effect. (a) Original light field, represented with an image. (b) Aliasing effects (simulated by applying sampling). (c) 1D aliasing. (d) Applying anti-aliasing before sampling. (e) Applying effect filters of sharpening and contrast. Images are from .

The inference pipeline of our DIC is illustrated in Figure 4. That is, the DIC converts an input image with the _atmospheric perspective_ module, the _camera simulation_ module, and the _effect filter_ module, simulating the physical world factors contributing to the appearance gap in sequence. We make the unknown physical world parameters controlling the effect of each module \(_{A},_{C},_{E}\) learnable so that they can be effectively estimated through Stochastic Gradient Descent (SGD) with some training data. In the following, we first introduce each module then the training method.

### Atmospheric Perspective Module

As demonstrated in Figure 2 (a), when an observer takes photos of a distant target at distance \(d\), the ray of lights emitted from the target toward the observer (represented by image \(^{}^{3 w h}\), \(w\) and \(h\) being image width and height respectively) would be scattered away by molecules in the air, causing a decrease in brightness. At the same time, skylight with RGB values of \(^{}^{3}\) would be scattered toward the observer, shifting the target object's observed color towards the skylight.

To simulate the effect, we implement an atmospheric perspective module \(F^{}\) following previous works [29; 12]. The inputs of the module include image \(^{}\) of the target object, a turbidity value \(T\) representing air quality, the target distance \(d\) to convert the image, and the skylight RGB value \(^{}\). The module produces an output image \(^{}_{d}\) that simulates the effect of the target object at distance \(d\) by processing \(^{}\) with

\[^{}_{d}=F^{}(^{},T,d, ^{},_{A})=^{}e ^{-(_{A},T)d}+tile(^{})(1-e^{- (_{A},T)d}),\] (1)

where \(tile\) is the tiling function that repeats \(^{}\) to form an image with the same shape of \(^{}\), \(_{A}\) represents the estimated physics-related parameters and the \(\) function represents the decay rate. See Appendix A for more details on \(_{A}\) and \(\).

### Camera Simulation Module

To simulate the blurring effect introduced by the Anti-Aliasing Filter (AAF) and the Imaging Chip (IC) in camera, we model the camera using two convolutional layers in sequence. The blurring done by the layers is illustrated in Figure 5(a).

**Convolutional Layer Kernel Generation.** The AAF blurs each ray of light with neighboring light rays within a certain radius and the sensors on the IC to form their outputs by averaging all light rays projected onto them. To simulate their effects, convolutional layers with blurring kernels that take averages within circular and square regions in their local input windows at each stride should be used . Additionally, since the camera simulation module needs to approximate the unknown AAF blurring strength and IC sensor size of different target cameras, the amount of pixels averaged by the kernels should be learnable through back-propagation.

To achieve this goal, although there are many alternative ways, we found that an effective approach is to implement a unified kernel generation function \(f\) for both the AAF and IC simulation layers.

Figure 5: Camera simulation module. (a) An illustration of the blurring operations performed by the camera simulation module. (b) Visualizing outputs of function \(\) with different parameters.

That is, as illustrated in Figure 5(b), we first implement a function \(\), which outputs values close to 1 when the \(L^{n}\) norm of the coordinate \((i,j)\) within the kernel is less than \(\) and outputs values near 0 otherwise:

\[(,i,j,n)\ =\ ((i^{n}\,+\,j^{n})^{}\,+\, )\,*3\,+\,(\,-\,(i^{n}\,+\,j ^{n})^{})\,*3\,-\,1.\] (2)

Then, we take the normalized version of \(\) as the function \(f\) that generates the \(j^{th}\) value in the \(i^{th}\) row of the kernel weight \(^{k k}\). That is, we let

\[_{i,j}=f(,k,i,j,n)=(_{d},i,j,n)}{_{i =-k}^{k}_{j=-k}^{k}(_{d},i,j,n)}.\] (3)

By setting \(n=2\), the generated kernel takes averages within circular regions in its local input windows at each stride, allowing it to approximate the blurring done by the AAF. By setting \(n=\), the kernel takes averages within rectangular regions in its local input windows at each stride, mimicking the blurring done by the IC sensors. Moreover, by adjusting the learnable parameter \(\), the number of pixels averaged by the kernel within its local input windows at different strides is altered, allowing for the simulation of various blurring strengths in the AAF and sensor sizes in the IC.

**Simulating AAF.** At a target distance \(d\), to simulate the effect of the AAF averaging every incoming light ray with neighboring light rays within its blurring radius, we set the stride of the corresponding convolutional layer to 1, and generate the different entries of the kernel \(_{d}^{}\) within the layer using the function \(f\) with \(n=2\). That is, we let

\[_{d,i,j}^{}=f(_{d}^{},k_{d}^{}, i,j,2).\] (4)

**Simulating Imaging Chip.** Similarly, we simulate the effect of IC at target distance \(d\) with another convolutional layer. To simulate the effect that when a digital image with height \(l_{0}\) is placed at a long distance \(d\), the imaging chip would capture it with fewer sensors to form a smaller image with height \(l_{d}\), as illustrated in Figure 5(a), we set the stride of the convolutional layer to \(x_{d}=l_{0}/l_{d}\). To simulate the blurring done by the square imaging sensors, we generate different entries of its kernel \(w_{d}^{}\) using function \(f\) with \(n=\), that is

\[_{d,i,j}^{}=f(_{d}^{},k_{d}^{}, i,j,).\] (5)

**Implementation of camera blurring strengths \(_{}^{}\) and \(_{}^{}\).** To set proper blurring strength \(_{d}^{}\) and \(_{d}^{}\) for simulating the AAF and IC at different distances, we observe that in the physical world, more distant objects are smaller relative to the fixed physical blurring strength in AAF (\(^{A}\)) and IC (\(^{}\)). That is, the blurring strength (\(\)) to image height (\(l_{d}\)) ratio increases as distance increases.

In the digital world, when given a digital input image with height \(l_{0}\), to consistently simulate the aforementioned ratio at different distances, we set \(_{d}^{}=^{} x_{d}\) and \(_{d}^{}=^{} x_{d}\). In this way, the blurring strength to image height ratio in the digital world (\(_{d}/l_{0}= x_{d}/l_{0}\)) is identical to that in the physical world (\(/l_{d}\)) since \(l_{d}=l_{0}/x_{d}\). A more detailed explanation with visualization is provided in Appendix B.

By setting \(_{C}=[^{},^{}]\) and optimizing \(_{C}\), the camera simulation module can be trained to approximate the blurring effect of any target camera.

**Implementation of camera simulation module.** We express the camera simulation module \(F^{}\) with two channel-wise convolutional layers \(\) in sequence simulating the effect of AAF and IC at distance \(d\) as

\[_{d}^{}=F^{}(_{d}^{},d, _{d}^{},_{d}^{})=(( _{d}^{},s=1,w=_{d}^{}),s=x_{d},w=_{d}^ {}),\] (6)

where \(_{d}^{}\) is the output of the atmospheric perspective module, \(s\) and \(w\) indicate the stride and kernel size of the two convolutional layers.

### Effect Filter Simulation Module

In this module, we let \(f_{e}\) denote the mapping function of a specific effect filter, and \(F^{}\) denote the mapping performed by a sequence of effect filters. We define \(F^{}\) as:

\[_{d}^{}=F^{}(_{d}^{}, _{E})=f_{e}(...f_{1}(_{d}^{},_{1} ),...,_{e}),\] (7)where \(_{d}^{C}\) is the output of the camera simulation module, \(_{E}=[_{1},...,_{e}]\) is the learnable parameter that controls the output effect of each effect filter, \(_{d}^{C}\) is the input RGB image from the camera simulation module and \(_{d}^{E}\) is the output image. By identifying the effect filters commonly involved in the target cameras and obtaining appropriate value for \(_{E}\), the influence of effect filters can be simulated. Please refer to Appendix C for the exact computation of each effect filter.

### Distant Image Converter Training

We collect a small distant image dataset and optimize the DIC to obtain appropriate DIC parameter values (\(_{A},_{C},_{E}\)). As illustrated in Figure 4, we first printed images on papers, then by photographing the printed images at different distances and extracting crops that capture the same content as the original digital world images, we collected pairs between digital world images and their distant versions in the physical world. With this dataset, the parameters of the DIC can be optimized with stochastic gradient descent (SGD) using Mean Square Error (MSE) loss as the objective function, where the MSE loss is calculated between the DIC outputs and the corresponding physical world ground truth images with identical shape.

## 4 Full-Distance Attack

The optimization pipeline of the FDA method is illustrated in Figure 6. The adversarial patterns are first randomly cropped (as explained in Section 4.1) and applied onto short-distance pedestrian images. With the sub-patches applied, the pixels of the adversarial pedestrian are extracted (e.g. based on pedestrian masks generated with segmentation models). The extracted pixels are transformed by the DIC into their distant counterpart and superimposed onto randomly selected background images, generating a batch of distant adversarial pedestrian images. Within the same batch, different pre-selected distances are used to perform the distant image conversion. The parameter \(T\) and \(^{}\) for DIC (from Equation (1)) are obtained by random sampling, allowing the FDA pattern optimized to be effective not only under different distances, backgrounds but also under different atmospheric conditions. Also, we apply EOTs  on \(_{A},_{C}\) and \(_{E}\) to make the resulting FDA pattern robust against potential physical world disturbances. By feeding the current batch of adversarial pedestrian images into the target detector and calculating the loss function for performing the adversarial attack, the FDA pattern can be optimized through SGD.

At \(D\) different simulated distances, we minimize the confidence \(c\) and IOU \(u\) of all \(K\) correctly predicted pedestrian bounding boxes generated by the target detector. That is,

\[_{}=_{d=1}^{D}_{i=1}^{N_{d}}(}{K }_{k=1}^{K}c_{i,k}^{d}+}{K}_{k=1}^{K}u_{i,k}^{d}),\] (8)

where \(_{c}\) and \(_{u}\) are manually set parameters balancing the two terms, \(N_{d}\) is the number of images generated with adversarial pedestrians at distance \(d\).

Please note that, without the green box part, the pipeline in Figure 6 degenerates to the Adv-Tshirt pipeline  with the only difference being that we sample random sub-patches of different sizes.

### Multi-Frequency Optimization

Empirically, we found that by optimizing the FDA pattern with our proposed pipeline, there was a conflict in performance between short and long distances. We conjecture that this conflict might be due to the following two properties:

Figure 6: FDA overall optimization pipeline. \(T_{i}\) and \(^{}_{i}\) are randomly sampled turbidity and skylight values.

* At short distances, with a high resolution, both the low frequency patterns (or overall patterns) and high frequency patterns (or fine textures) can be optimized for performing attacks.
* At long distances, due to the reduced resolution, only the low frequency patterns remain, so only the low frequency patterns can be optimized for performing attacks.

A conflict could be resulted if the required low frequency patterns at short distances and long distances are different. To address this problem, we propose two Multi-Frequency Optimization (MFO) techniques to encourage the low frequency components of the adversarial patterns to be optimized for long distance attacks and the high frequency patterns to be optimized for short distance attacks.

**Multi-Scale Cropping (MSC) technique.** We set a smaller crop and patch application size for the adversarial patch when optimizing at short distances. In this way, it is harder for the short-distance optimization objectives to alter the overall pattern of the patch, preserving the low frequency patterns for long distance attacks.

**Two Stage Optimization (TSO) technique.** In TSO, we divide the optimization pipeline into two stages. In the first stage, the patch is optimized with a larger bias on long distances to obtain low frequency components for long distance attack by optimizing with more long distance images. In the second stage, the patch is optimized with a larger bias to obtain high frequency component for short distance attack by optimizing with more short distance pedestrian images. In addition, in the second stage, we add a loss function term that restrict the low-frequency components of the patch to remain unchanged. The loss function term introduced is described in Appendix D.

## 5 Experiments

**Subjects.** To evaluate the performance of different adversarial patterns in the physical world, we recruited five subjects (three males and two females with age ranging from 25 to 55) to collect test images and form demo videos. The recruitment and study procedures were approved by the Department of Psychology Ethics Committee, Tsinghua University, Beijing, China.

**Experiment settings.** Unless otherwise stated, we present our results with YOLOv5  as the target model, the camera used to capture the physical world testing images was the back camera of Xiaomi-CIVI smart phone. For optimization details, we used configurations of Adv-Tshirt  and TCA  for patch and clothing experiments respectively. Given that all models failed to detect pedestrians reliably beyond around 41 meters, we optimized the adversarial patterns at simulated 4m, 8m, 14m, 20m, 26m, 34m and 40m, tested the patterns at 3.5m, 6m, 12m, 18m, 24m, 32m and 41m in the physical world unless otherwise stated. Appendix E provides a detailed analysis on the choice of the current distance range and the influence of holding a patch. To report reliable results, all physical world attack results reported are averaged over three trials, each trial had a different subject and a different location.

**Evaluation Metric.** We evaluated the performance of adversarial patterns with average attack success rate (ASR) across different distances. The ASR at a certain distance is defined as \(1-}{}\) where TP denotes the number of True Positives and GT denotes the number of Ground Truths. Following TCA , we set both the IOU and confidence thresholds for calculating TP to be 0.5.

**Distant Image Dataset.** To form a distant image dataset to train the DIC (Figure 4 (a)), we printed 45 training images and 9 testing images onto papers, collected photos of all printed images at 7 distances (4m, 8m, 14m, 20m, 26m, 34m, 40m) in 5 days and removed ones with noises (e.g. reflections and shadows). When photographing, skylight RGB values of the days were also recorded. Samples of training, test and skylight images are provided in Appendix F. We empirically found that though the dataset was small, it was enough to train a good DIC as the DIC only has 15 parameters (Section 5.1).

**Datasets for Pedestrian Attack.** To optimize the FDA patterns in the digital world, we created a pedestrian dataset and a background dataset. 1100 pedestrian images were extracted from existing datasets (INRIA , PennFudan  and COCO ). Additionally, we gathered 1000 more pedestrian images from online sources to boost diversity. We manually selected all images to ensure they had a similar resolution and scale to the 4-meter pedestrian images. Samples from the dataset are provided in Appendix F. We used the background dataset provided by an existing work . Toeliminate the potential for FDA patterns to over-fit to elements in our local environment, we excluded self-collected background images and self-collected 4-meter pedestrian images during optimization.

**Digital Patch Attack Evaluation Configuration.** To evaluate the average ASR of a patch in the digital world, we applied the patch onto 300 held out testing pedestrian images and converted them into their distant versions at different distances as in the training pipeline in Figure 6. By feeding the distant adversarial pedestrian images into the detector, the digital world ASRs of the patterns could be calculated.

### DIC Results

We compared the performances of DIC and the naive distant image conversion method (achieved through image size reduction). In addition, we trained seven Fully Convolutional Network (FCN)  to convert distant images, each designed for a specific distance (See Appendix G for details). We used the \(l_{2}\)-norm error between labeled images from the physical world and the conversion results as the evaluation metric. As illustrated in Figure 7 (a), the DIC obtained a stable \(l_{2}\)-norm error of around 0.11 across different distances, where the \(l_{2}\)-norm error of the FCN and the naive method increased from around 0.11 to 0.16 as distance increased.

Figure 7 (b) visualizes the results of different methods. At different distances and on different days, it can be observed that compared to the conversion results generated by the naive method and the FCN method, the results generated by the DIC had the closest visual effect to the real world images.

### Adversarial Patch Attack in the Physical World

**Settings.** Using adversarial patches, we evaluated the performance of patterns optimized with our FDA method against patterns obtained with different baseline methods in the physical world. For all patterns, we set a patch size of \(200 133\) and printed it onto a piece of paper with a size of 72 cm

Figure 8: Physical world patch attack results. (a) ASR of different attack methods. Average ASRs of each curved reported in the brackets of the legend. (b) Adversarial patterns generated by different methods.

Figure 7: DIC results. (a) Performance of different distant image conversion methods on the test set of the distant image dataset. (b) Visualization of distant image conversion results. R.W. indicates real world.

50 cm. Each patch was tested at seven distances between 3.5 and 41 meters, with about 30 images collected at each distance within each trail (out of three trails) to calculate distance specific ASRs.

**Main Results.** Figure 8 (a) shows the ASR of our (YOLOv5) FDA pattern with respect to distance. For comparison, we also plot the results of the normal pedestrian (without holding an adversarial patch), a random pattern (formed by random RGB blocks) and an Adv-Tshirt pattern . The patterns generated are visualized in Figure 8 (b). The FDA pattern achieved the highest average ASR of 74%. The corresponding digital world evaluation result is presented in Appendix H. We have also reproduced NAP and T-SEA and tested the patterns under comparable setting. The two patterns obtained average ASRs of 19% and 42% respectively. For visualization on FDA performance, we included demo videos in the supplementary material.

**Generalizing Across Scenarios.** When we used the back camera of Huawei-Nova-11-SE and OPPO-A9 smart phones when obtaining the testing images, the FDA pattern obtained average ASRs of 68% and 72% respectively. When the FDA pattern was tested under eight new test distances neighboring our original test distances, it obtained an average ASR of 76% (More details are provided in Appendix I). Such results demonstrate that the FDA pattern generalizes well across different scenarios.

**Adv-Tshirt with EOTs.** To investigate if it is possible to achieve FDA with a strong EOT  that might cover the effect of increased distance, we optimized three Adv-Tshirt patterns with EOTs in color and noise that were 1 time, 3 times and 10 times larger relative to the original strength. The corresponding patches only obtained average ASRs of 22%, 10% and 8% respectively, demonstrating that a larger EOT is not helpful for performing FDA.

**Ablation Studies.** To evaluate the influence of different design components, we first removed both DIC and MFO. The resulting FDA pattern obtained an average ASR of 22%. By adding the DIC and MFO back into the optimization pipeline, the average ASR of the resulting patterns increased to 65% and 74% respectively, indicating that they both contributed to the performance of FDA. Analysis on the influence of different components in DIC and MFO, together with analysis on the presence of conflict in attack performance between short and long distances are provided in Appendix J.

**Black-Box Attacks.** To investigate the generalizability of FDA patterns across detectors, we transfered the FDA pattern optimized for YOLOv5 to attack 6 black-box models (as shown in Table 1). Without specific designs for boosting transferability, the FDA pattern did not achieve good ASRs except on the Deformable DETR. We then integrated FDA with ensemble attack  (by optimizing the FDA pattern to be effective for both Mask RCNNs with ResNet backbone  and Swin backbone ), the resulting FDA pattern achieved good black-box attack performance, obtaining average ASRs of more than 75% on all black-box models. The FDA pattern optimized for ensemble attack is visualized in Figure 8 (b).

### Clothing Attacks in the Physical World

To optimize the FDA pattern for clothing attacks, we incorporated toroidal cropping  into the FDA pipeline. We followed the process outlined in Figure 6, with the sole modification that we tiled the adversarial patch prior to multi-scale cropping by tripling the patch both vertically and horizontally. By integrating toroidal cropping, we enabled the FDA clothing to attack from all angles as for the TCA clothing (we leveraged TCA instead of TC-EGA since we found the TCA method to be more effective on YOLOv5). Different clothing tested targeting YOLOv5 are illustrated in Figure 9 (b). The clothing tailoring process and different adversarial patterns tested are provided in Appendix K.

  SourceTarget & YOLOv5  & Mask RCNN  & Mask RCNN [SWIN] & FrRCNN  & RetinaNet [PVD] & YOLOv8  & D-DETR  \\   Random & 5\% & 7\% & 12\% & 9\% & 19\% & 4\% & 6\% \\  YOLOv5 & 74\% & 34\% & 29\% & 26\% & 34\% & 49\% & **63\%** \\   Ensemble & **79\%** & 74\% & 77\% & **77\%** & **87\%** & **80\%** & **75\%** \\  

Table 1: Physical world black-box attack results. _Source_ indicates the models that the FDA patterns were optimized against, _target_ indicates the model attacked by the FDA patterns, _random_ indicates random pattern and _ensemble_ indicates ensemble attack. Black-box attack results with average ASRs \(\) 50% are highlighted in bold face. White-box attack results are indicated with blue italic font.

In the experiments, we tested the FDA clothing, TCA clothing , random clothing and normal clothing. Each clothing was tested at seven distances between 3.5 and 41.0 meters, with about 30 images collected within each trail (out of three trails) at each distance to calculate the ASRs.

As demonstrated in Figure 9 (a), when targeting the YOLOV5  model, in the front and back view, both the random clothing and the normal clothing had near zero attack performance. By covering the entire body of the subject, the TCA clothing obtained an average ASR of 37%. The FDA clothing outperformed the TCA clothing with an average ASR of 76%. Similarly, in the side view, the FDA clothing obtained an average ASR of 61%, being 15% higher than TCA, while the random and normal clothing had average ASRs of 0%.

Additionally, when treating the Deformable DETR  and the RetinaNet with PVT backbone  as the target model, in the front and back view, the FDA clothing has also attacked the target models effectively by obtaining average ASRs of 71% and 73% respectively.

If we calculate the mean average ASRs across confidence thresholds of 0.1, 0.2,..., 0.9, when targeting YOLOV5, in the front and back view, the mean average ASR of the FDA clothing, TCA clothing, random clothing and normal clothing was 78%, 43%, 9% and 3% respectively. Analysis on the performance of different FDA clothing under different IOU thresholds is included in Appendix K.

The results confirm that our proposed method has the ability to boost FDA performance at all angles and the FDA method is effective for clothing attacks.

## 6 Limitation and Potential Social Impact

As described in Appendix K, depending on the target model and attack method used, if abstract human-like patterns appear on the FDA pattern, the detector may generate small pedestrian bounding boxes for these patterns, even when the actual pedestrian subjects are not detected. This could lead to a decrease in FDA performance on some models when a smaller IOU threshold is applied. However, this is not specific to the FDA method as human-like patterns have appeared in previous attack methods [34; 17].

Physical-world adversarial attack research can lead to unwanted applications in real-world scenarios such as evading security cameras, but we publish our work to inspire researchers to propose more reliable detectors with adversarial defense mechanisms. We also urge readers and future researchers to set strict access controls for adversarial patterns and pattern generation codes targeting detectors in security-sensitive areas. This may include user authentication, licensing agreements, and usage monitoring.

## 7 Conclusion

In this work, we bridge the appearance gap between the digital world and the physical world by proposing the DIC. Moreover, we avoid conflicts that impede optimization by proposing two MFO optimization techniques. Together, the FDA patterns gained high ASRs targeting different detectors within a wide range of distances in the physical world.

Figure 9: Clothing attack. (a) Attack results. (b) Front and side view of different clothing.