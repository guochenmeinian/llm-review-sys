# Smoothed Online Classification can be Harder than Batch Classification

Vinod Raman

Department of Statistics

University of Michigan

Ann Arbor, MI 48104

vkraman@umich.edu

&Unique Subedi

Department of Statistics

University of Michigan

Ann Arbor, MI 48104

subedi@umich.edu

&Ambuj Tewari

Department of Statistics

University of Michigan

Ann Arbor, MI 48104

tewaria@umich.edu

Equal Contribution

###### Abstract

We study online classification under smoothed adversaries. In this setting, at each time point, the adversary draws an example from a distribution that has a bounded density with respect to a fixed base measure, which is known apriori to the learner. For binary classification and scalar-valued regression, previous works  have shown that smoothed online learning is as easy as learning in the iid batch setting under PAC model. However, we show that smoothed online classification can be harder than the iid batch classification when the label space is unbounded. In particular, we construct a hypothesis class that is learnable in the iid batch setting under the PAC model but is not learnable under the smoothed online model. Finally, we identify a condition that ensures that the PAC learnability of a hypothesis class is sufficient for its smoothed online learnability.

## 1 Introduction

Classification is a canonical machine learning task where the goal is to classify examples in \(\) into one of the possible classes in \(\). There are two common classification settings based on how the data is available to the learner: batch and online. In the batch setting, the learner is provided with a fixed set of training samples that are used to train a classifier, which is then deployed to make predictions on new, real-world examples . On the other hand, data arrives sequentially in the online setting and predictions need to be made in each round . The batch setting is often studied under the iid assumption, whereas the stream can be fully adversarial in the online setting.

For binary classification (i.e. \(||=2\)), the batch learnability of a hypothesis class \(^{}\) under the PAC model  is characterized in terms of a combinatorial parameter called the Vapnik-Chervonenkis \(()\) dimension of \(\). On the other hand, the Littlestone dimension characterizes the learnability of \(\) under the adversarial online model . As Haghtalab et al.  remark, the latter characterization is often interpreted as an impossibility result because even simple classes like \(1\)-dimensional thresholds have infinite Littlestone dimension. This hardness result arises mainly because the adversary can deterministically choose hard examples, even possibly adapting to the learner's strategy. One way to circumvent this hardness result is to consider a smoothed online model, where the adversary has to choose and draw examples from sufficiently anti-concentrated distributions . This idea is inspired from the seminal work by Spielman and Teng , who showed that the smoothed analysis of the simplex method yields a polynomial time complexity in the input size, instead of the known worst-case exponential time complexity.

In smoothed online classification, a learner plays a game with the adversary over \(T\) rounds. Before the game begins, the adversary reveals a base measure \(\) over \(\) and an anti-concentration parameter \(>0\) to the learner. The distribution \(\) can be fairly non-informative such as uniform when applicable for \(\). Then, in each round \(t[T]\), the adversary picks a labeled sample \((x_{t},y_{t})\), where \(x_{t}\) is drawn from a \(\)-smooth distribution \(_{t}\) with respect to \(\). That is, \(_{t}(E)(E)/\) for all measurable subsets \(E\) in \(\). The adversary then reveals \(x_{t}\) to the learner, who makes a prediction \(_{t}\). Finally, the adversary reveals the true label \(y_{t}\) and the learner suffers the loss \(\{_{t} y_{t}\}\). Given a hypothesis class \(^{}\), the goal of the learner is to minimize the regret, the difference between its cumulative loss and the best possible cumulative loss over hypotheses in \(\).

The smoothed online model interpolates between the iid setting (\(=1\)) and the adversarial setting (\(=0\)). When \(||=2\), Haghtalab (2018) and Haghtalab et al. (2020) showed that all VC classes are learnable in the smoothed setting with the regret \(O(()\ \ (T/)})\). Extending this result to real-valued regression, where \(=[-1,1]\), with the absolute-value loss, Block et al. (2022) showed that the finiteness of the fat-shattering dimension (Bartlett et al., 1996; Alon et al., 1997) of \(^{}\) is a sufficient condition for smoothed online learnability. Since the finiteness of \(\) and fat-shattering dimensions are characterizations of learnability under the PAC model, these results suggest that smoothed online learning may be as easy as batch learning.

In this work, we study smoothed online classification for arbitrary label spaces \(\) under _oblivious_ adversary - one that picks \(\)-smooth distributions \(_{1},..,_{T}\), samples \(x_{1}_{1},...\), \(x_{T}_{T}\) independently, and finally picks the labels \(y_{1},...,y_{T}\), all before the game begins. This oblivious model has been studied in the past Wu et al. (2023), but is slightly different than the one studied by (Haghtalab, 2018; Haghtalab et al., 2020; Block et al., 2022) (see Section 2.1 for more details). For this model, we show that smoothed online classification continues to be as easy as batch classification when \(||<\). However, when \(||\) is not finite, we show that smoothed online classification can be _harder_ than batch classification. We note that there has been recent interest in studying multiclass learnability when \(||\) is unbounded (Brukhim et al., 2022; Hanneke et al., 2023; Pabbaraju, 2024). Studying infinite label spaces is important for understanding when one can establish learning guarantees independent of the label size. This is quite a practical question as many modern machine learning paradigms have massive label space, such as in face recognition and protein structure prediction, where the dependence of label size in learning bounds would be undesirable.

**Theorem** (Informal) Let \(=\). Then, there exists \(^{}\) that is PAC learnable but not learnable in the smoothed online setting with \(=()\) and \(=1\).

We also provide a quantitative version of this theorem that shows a regret lowerbound linear in \(T\) even when \(||<\) but bigger than \(2^{T(T)}\). Note that this is tight up to a factor of \( T\) because we prove a sublinear upperbound as long as \(||=2^{o(T)}\) in Section 4. To prove these results, we exploit the large size of the label space to construct a hypothesis class \(^{}\) such that for every \(h\), its output on a finite subset of \(\) effectively reveals its identity. We then show that such a hypothesis class has a sample compression scheme of size \(1\). Then, the result "compression implies learning" by David et al. (2016) shows that \(\) is PAC learnable. However, we show that even the adversary that generates iid samples from \(()\) can construct a difficult stream for the learner. Our construction is inspired by the hypothesis class from (Hanneke et al., 2024; Claim 5.4). However, a key challenge in our construction is the fact that the adversary does not have full control over the sequence of examples the learner will observe (due to \(\)-smoothness) whereas the adversary in Hanneke et al. (2024) can pick hard examples deterministically.

In light of this hardness result, we identify a sufficiency condition for smoothed online learnability. To do so, let \((,)\) denote the set of all \(\)-smooth distributions with respect to \(\). For any \(x_{1},,x_{n}\), let us define an empirical metric on \(d_{n}\) on \(\) as \(d_{n}(h_{1},h_{2})=n^{-1}_{i=1}^{n}\{h_{1}(x_{i}) h_{2}(x_ {i})\}\). Define \((,,d_{n})\) to be the covering number of \(\) under metric \(d_{n}\). Then, \(\) is said to have uniformly bounded expected empirical metric entropy (UBEME) if \(_{n}_{_{1:n}(,)}_{x_{1: n}_{1:n}}(,,d_{n})]<\) for every fixed \(>0\). We show that if \(\) has the UBEME property, then it online learnable under smoothed adversaries.

**Theorem** (Informal) If \(_{n}_{_{1:n}(,)}_{x_{1: n}_{1:n}}[(,,d_{n})]<\) for every fixed \(,>0\), then \(\) is smoothed online learnable under the base measure \(\).

When \(||=2\), Haussler's packing lemma implies that \((,,d_{n})(41\,^{-1})^ {()}\)(Haussler, 1995). That is, every class with finite VC satisfies UBEME, and thus our sufficiency condition recovers the result from Haghtalab (2018) on the smoothed learnability of VC classes. For \(||<\), we generalize the packing lemma to show that \((,,d_{n})(|}{ })^{()}\), where \(()\) is the graph dimension of \(\). This inequality shows that PAC learnability of \(\) is sufficient for its smoothed online learnability when \(||<\).

A key contribution of our sufficiency result is going beyond VC and Graph dimension and giving the weaker sufficiency condition than the worst-case empirical entropy. Indeed, in Section 4, we show that our sufficiency condition still provides meaningful upperbounds even when the VC and Graph dimensions are infinite. To prove our sufficiency result, we show that UBEME implies the bounded metric entropy of \(\) with respect to the base measure \(\). That is, for \(d_{}(h_{1},h_{2})=_{x}[h_{1}(x) h_{2}(x)]\), we have \((,,d_{})<\) for every fixed \(>0\). Then, we use algorithmic ideas from Haghtalab (2018) that involve running multiplicative weights using the cover of \(\) under \(d_{}\). Unfortunately, when \(||\) is unbounded, the sufficiency condition (the UBEME of \(\)) is not necessary. This is demonstrated by constant functions \(=\{x a:a\}\) that is easy to learn but \((,,d_{1})=\).

Given our separation and sufficiency results, it is natural to ask for a characterization of learnability for smoothed online classification. Any meaningful characterization must be a joint property of both \(\) and \(\). This is because choosing \(\) to be a Dirac distribution will make any \(\), even the set of all measurable functions from \(\) to \(\), trivially learnable. Since the most natural joint complexity measure of \(\) and \(\) is \((,,d_{})\), one might ask whether \((,,d_{})<\) for every \(>0\) is necessary and sufficient for smoothed online learnability of \(\) under \(\). Surprisingly, we show that this condition is neither necessary nor sufficient (see Theorem 4.3). These results highlight the difficulty of characterizing learnability in the smoothed setting.

## 2 Preliminaries

Let \(\) denote the instance space and \(\) denote the label space. We assume that \((,)\) is a measurable space and let \(()\) denote the set of all probability measures on \((,)\). Let \(^{}\) denote an arbitrary hypothesis class consisting of predictors \(h:\). For any \(T\), we use the notation \(z_{1:T}\) to denote the sequence \(\{z_{t}\}_{t=1}^{T}\). Finally, we let \([N]:=\{1,2,,N\}\).

### Smoothed Online Learning

In the smoothed online model, an adversary plays a sequential game with the learner over \(T\) rounds. Before the game begins, the adversary reveals a base measure \(()\) and a scalar \(>0\) to the learner. As mentioned before, \(\) can be non-informative measures such as uniform if \(\) is totally-bounded. Then, in each round \(t[T]\), an adversary picks a labeled sample \((x_{t},y_{t})\), where \(x_{t}\) is drawn from a distribution \(_{t}()\) that satisfies \(_{t}(E)\) for every \(E\). The adversary then reveals \(x_{t}\) to the learner \(\). Using all the past examples \((x_{1},y_{1}),,(x_{t-1},y_{t-1})\), the learner then makes a potentially randomized prediction \((x_{t})\). The adversary then reveals the true label \(y_{t}\) and the learner suffers the loss \(\{(x_{t}) y_{t}\}\). Given a hypothesis class \(^{}\), the goal of the learner is to output predictions \((x_{t})\) that minimizes the regret, which is the difference between its cumulative loss and the best possible cumulative loss over hypotheses in \(\). To formally define the regret, let \((,):=\{()\,:(E)E / E\}\) denote the set of all \(\)-smooth distributions on \(\) with respect to \(\). Given \(^{}\), the worst-case expected regret of an algorithm \(\) is defined as

\[_{}^{,}(T,):=_{_{1},,_ {T}(,)}}_{x_{1:T}_{1:T}}[ _{y_{1:T}}(_{t=1}^{T}}_{}[ \{(x_{t}) y_{t}\}]-_{h}_ {t=1}^{T}\{h(x_{t}) y_{t}\})].\]

Note that as \( 0\), the set \((,)\) contains all Dirac distributions on \(\). This amounts to replacing \(_{_{1},,_{T}(,)}}_{x_{1 :T}_{1:T}}[]\) operator in the definition of regret above by \(_{x_{1:T}}\), which yields the expected regret of \(\) in the fully adversarial model under an oblivious adversary. Thus, our adversary is a generalization of the online oblivious adversary for the smoothed setting. Given this definition of expected regret, we adopt the minimax perspective to define the learnability of a hypothesis class.

**Definition 1** (Smoothed Online Learnability).: _The class \(^{}\) is learnable in the smoothed online setting if and only if for every \(>0\) and \(()\), we have_

\[_{}\,^{,}_{}(T,)=o(T).\]

Our worst-case expected regret is defined with respect to an _oblivious_ adversary that picks the entire stream \((x_{1},y_{1}),,(x_{T},y_{T})\) before the game begins. Moreover, the sequence of distributions \(_{1},,_{T}\) has to be chosen upfront before the sampling step \((x_{1},,x_{T})(_{1},,_{T})\). That is, the distribution \(_{t}\) cannot depend on the realization of previous instances \(x_{1},,x_{t-1}\). This ensures that the instances \(x_{1},,x_{T}\) are independent random variables. One can also consider an oblivious adversary, where \(_{t}\) can depend on the past instances \((x_{1},,x_{t-1})\) sampled from \((_{1},,_{t-1})\). Since the primary contribution of this work is the hardness result in Section 3, we only focus on the case where \(_{1},,_{T}\) are chosen upfront. As the first adversary is a special case of the second adversary, our hardness result also applies for the second adversary. The fully general setting of adaptive adversaries where \(_{t}\) can depend on the _entire_ history of the game up to time point \(t-1\) has been studied extensively in (Hagthalab et al., 2020; Block et al., 2022), where the dependence among \(x_{1},,x_{T}\) is handled through coupling.

There are three natural choices for how \(y_{t}\) may be selected by an oblivious adversary. In the first choice, \(y_{t}\) may depend only on the \(x_{t}_{t}\). In the second choice, \(y_{t}\) may depend on prefix on \(x_{1}_{1},...,x_{t}_{t}\). Finally, in the last choice, \(y_{t}\) may depend on the entire sample \(x_{1}_{1},...,x_{T}_{T}\). The first choice is considered in Hagthalab (2018)and the second by Hagthalab et al. (2020), Block et al. (2022). In this work, we focus on the third choice, which has been considered by Wu et al. (2023). This choice is natural because \(\)-smoothness is just a property of the instances and should not impact how the labels are selected. Since the third choice is the strongest, our sufficiency result in Section 4 holds for the first two choices. However, establishing the separation result for the first two choices remains an open question.

### PAC Learning and Sample Compression Schemes

In contrast to existing work, we establish a separation between smoothed online learnability and batch learnability. The notion of batch learnability we consider is PAC learnability, a canonical model in statistical learning theory. See Appendix A for a complete definition. To prove the agnostic PAC learnability of hypothesis classes, we use the relationship between learnability and the existence of sample compression schemes.

A compression scheme \((,)\) consists of a compression function \(\) and a reconstruction function \(\). The compression function \(:_{i 1}()^{i}_{i 1 }()^{i}\) maps a sample \(S=\{(x_{1},y_{1}),,(x_{n},y_{n})\}\) to a subsample \(S^{} S\). The reconstruction function \(:_{i 1}()^{i}^{ }\) takes \(S^{}\) as input and outputs a function \(f^{}\). We define the size of the compression scheme \((,)\) on a sample \(S\) to be \(|S^{}|\), where \((S)=S^{}\). We let the quantity \(k(n)\) denote the maximum size of the compression scheme on all samples \(S\) such that \(|S|=n\). A hypothesis class \(^{}\) has a compression scheme \((,)\) of size \(k(n)\) if for every sample \(S=\{(x_{1},h(x_{1})),,(x_{n},h(x_{n}))\}\) for some \(h\), we have \(f=((S))\) such that \(f(x_{i})=h(x_{i})\) for all \(i[n]\).

The compression scheme in David et al. (2016) is slightly more general as their compression function \(\) can output \((S^{},b)\) where \(b\) is a finite bitstring. However, the restricted notion of a compression scheme without \(b\) is sufficient for our purpose. The following Theorem shows that the existence of sample compression schemes for \(\) implies agnostic PAC learnability of \(\).

**Theorem 2.1** (Compression \(\) Learnability (David et al., 2016)).: _Let \((,)\) be a sample compression scheme for \(^{}\) of size \(k(n)\) and define \(f_{S}=((S))\) for any \(S()^{n}\). Then, for every \(\) on \(\) and \(n\) such that \(k(n) n/2\), with probability at least \(1-\) over \(S^{n}\), we have_

\[_{(x,y)}[\{f_{S}(x) y\}]_{h }_{(x,y)}[\{h(x) y\}]+100 +k(n)+}{n}}.\]

### Covering Numbers, Metric Entropy, and Complexity Measures

In Section 4, we provide conditions for which a hypothesis class \(\) is online learnable under smoothed adversaries. While sufficient conditions for learnability are typically established via combinatorialdimensions, our sufficient conditions will be in terms of covering/packing numbers of \(\) using a distance metric that depends on the base measure \(\). This discrepancy with existing literature is due to a simple observation: any parameter of \(\) alone cannot characterize smoothed online classification. Indeed, if one takes the base measure \(\) to be a Dirac measure, then every \(^{}\) is trivially online learnable under a smoothed adversary. Accordingly, any meaningful characterization of smoothed online classification must be in terms of both \(\) and \(\).

To start, we first define \(\)-covering numbers for generic metric spaces \((,d)\).

**Definition 2** (Covering Number).: _Let \((,d)\) be a bounded metric space. A subset \(^{}\) is an \(\)-cover for \(\) with respect to \(d\) if for every \(g\), there exists an \(g^{}^{}\) such that \(d(g,g^{})\). The covering number of \(\) at scale \(\), denoted \((,,d)\), is the smallest \(n\) such that there exists an \(\)-cover of \(\) with cardinality \(n\). That is, \((,,d):=\{|^{}|:^{}$}\}\)._

The metric entropy for \((,d)\) at scale \(>0\) is defined as \((,,d)\). In this paper, we consider the metric space \((,d_{})\) where \(^{}\) is a hypothesis class and \(d_{}(h_{1},h_{2})=_{x}[h_{1}(x) h_{2}(x)]\) for some \(()\). The key complexity measure in this work is

\[C_{,}(,):=_{n}\;_{_{1, n}(,)}\;_{1:n}}{}[ (,,d_{_{n}})],\]

where \(_{n}\) denotes the _empirical_ measure over \(x_{1:n}\). At a high-level, \(C_{,}(,)\) measures the complexity of \(\) in terms of its average empirical covering number, where the average is taken over processes from \((,)\). Using \(C_{,}(,)\), we define the property of uniformly bounded empirical metric entropy.

**Definition 3** (Uniformly Bounded Empirical Metric Entropy).: _A hypothesis class \(^{}\) has the Uniformly Bounded Empirical Metric Entropy (UBEME) property with respect to \(\) if \(C_{,}(,)<\) for every \(,>0\)._

In Theorem 4.1, we show that \(\) is online learnable under smoothed adversaries if \(\) enjoys the UBEME property with respect to the base measure \(\).

## 3 PAC Learnability is Not Sufficient for Smoothed Online Learnability

In Section 4, we show that the PAC learnability of \(\) is sufficient for its smoothed online learnability when \(||<\). Here, we show that this is not the case when \(||\) is unbounded by constructing a PAC learnable hypothesis class that is not smoothed online learnable. In fact, we prove a _stronger_ result.

**Theorem 3.1**.: _There exists a hypothesis class \(^{}\) such that following holds:_

1. \(\) _has a compression scheme of size_ \(1\)_._
2. _For_ \(=()\) _and_ \(=1\)_, we have_ \(_{}\;_{}^{,}(T,) \)_._

The part (i) of Theorem 3.1, together with Theorem 2.1, shows that \(\) is agnostic PAC learnable with error rate \((,n)=O(})\). On the other hand, based on Definition 1, part (ii) shows that \(\) is not smoothed online learnable. Together, we infer the following corollary.

**Corollary 3.2** (Agnostic PAC Learnability \(\) Smoothed Online Learnability).: _There exists \(^{}\) such that \(\) is agnostic PAC learnable but not learnable in the smoothed setting under \(=()\) and \(=1\)._

When \(||<\), the existence of a \(O(1)\)-size compression schemes and agnostic PAC learnability are equivalent (David et al., 2016). Thus, there is no qualitative difference between Theorem 3.1 and Corollary 3.2. However, when \(||=\), a recent work has shown that the multiclass PAC learnability does not imply the existence of \(O(1)\)-size compression schemes (Pabbaraju, 2024). Thus, Theorem 3.1 is a qualitatively stronger result than Corollary 3.2. Moreover, our proof of Theorem 3.1 below provides an explicit PAC learner for \(\).

Proof.: (of Theorem 3.1) Let \(=\). Given a bitstring \(=(_{1},,_{n})\{0,1\}^{n}\), define \(_{ t}:=(_{1},,_{t})\) and \(_{<t}:=(_{1},,_{t-1})\) for any \(t\{1,,n\}\). Fix an \(n\) and ordered 

[MISSING_PAGE_FAIL:6]

are distinct with probability \(1\). Moreover, as all the instances are drawn from the same distribution \(\), this adversary is \(\)-smooth for \(=1\). To specify \(y_{1},,y_{T}\), we first draw \((\{0,1\}^{T})\) and define \(y_{t}=((x_{1},,x_{T}),_{ t})\) for all \(t[T]\). Given distinct \(x_{1},,x_{T}\), for any algorithm \(\), we first show that

\[*{}_{(\{0,1\}^{T})}( _{t=1}^{T}*{}_{}[\{ (x_{t}) y_{t}\}]-_{h}_{t=1}^{T} \{h(x_{t}) y_{t}\}).\] (1)

The probabilistic method implies the existence of a \(\{0,1\}^{T}\) such that the claimed bound of \(T/2\) holds. This subsequently implies that, for a distinct \(x_{1},,x_{T}\), we have

\[_{y_{1:T}}(_{t=1}^{T}*{}_{} [\{(x_{t}) y_{t}\}]-_{h}_{t=1}^{T}\{h(x_{t}) y_{t}\}).\]

Finally, using the fact that \(x_{1},,x_{T}\) are distinct with probability \(1\), we obtain the bound

\[_{}\,*{R}_{}^{,}(T,)*{}_{x_{1},,x_{T}}[_{y_{1: T}}(_{t=1}^{T}*{}_{}[ \{(x_{t}) y_{t}\}]-_{h}_ {t=1}^{T}\{h(x_{t}) y_{t}\})].\]

To complete our proof, it now suffices to prove Equation (1). Fixing distinct \(x_{1},,x_{T}\), the lowerbound on the expected cumulative loss of the algorithm \(\) is

\[_{t=1}^{T}*{}_{( \{0,1\}^{T})}*{}_{}[\{(x_{t}) y_{t}\}] =_{t=1}^{T}*{}_{_{t}}[ *{}_{_{t}}[\,\{(x_{t })((x_{1},,x_{T}),_{ t})\}]\,|\,,_{ <t}]\] \[=_{t=1}^{T}*{}_{}[\{(x_{t})(x_{1:T}),(_{<t},0) \}+\{(x_{t})x _{1:T},(_{<t},1)\}]\] \[_{t=1}^{T}=.\]

At a high-level, we use the fact that \(_{t}\) is sampled uniformly at random from \(\{0,1\}\) and is independent of \(\) as well as \(_{i}\) for all \(i t\). Thus, on each round, the algorithm cannot do any better than randomly guessing the value of \(_{t}\). Next, we upperbound the expected loss of the best-fixed function in hindsight. Given distinct \(x_{1},,x_{T}\) and \(\{0,1\}^{T}\), we can pick the hypothesis \(h_{(x_{1},,x_{T})}^{}\). By definition of this hypothesis, we have \(h_{(x_{1},,x_{T})}^{}(x_{t})=((x_{1},,x_{T}),_{ t} )=y_{t}\). Thus, for every distinct \(x_{1},,x_{T}\), we have

\[*{}_{(\{0,1\}^{T})}[_{h }_{t=1}^{T}\{h(x_{t}) y_{t}\}] *{}_{(\{0,1\}^{T})}[_{t= 1}^{T}\{h_{(x_{1},,x_{T})}^{}(x_{t}) y_{t}\}]=0.\]

Finally, equation (1) follows upon combining the lowerbound on the cumulative loss of \(\) and the upperbound on the cumulative loss of the optimal hypothesis in hindsight. 

To prove the qualitative separation between PAC and smoothed online learnability in Theorem 3.1, we required \(||\) to be unbounded. The following theorem, proved in Appendix C, shows the quantitative dependence of the regret on \(||\) when it is bounded.

**Theorem 3.3**.: _For every \(K\), there exists \(^{}\) with \(||=K\) such that \(\) has a compression scheme of \(1\), but \(_{}\,*{R}_{}^{,}(T,)\) for \(=()\) and \(=1\)._

Theorem 3.3 shows that one can get quantitative separation whenever \(K 2^{T T}\).

## 4 A Sufficient Condition for Smoothed Online Classification

In this section, we provide a sufficient condition for smoothed online classification. Our main result provides a quantitative upperbound on the expected regret in terms of \(C_{,}(,)\).

**Theorem 4.1**.: _For every \(^{}\), \(()\) and \(>0\), we have that_

\[_{}\,^{,}_{}(T,) 6 _{>0}+,}(,))}}.\]

Theorem 4.1 shows that as long as \(\) satisfies the UBEME condition with respect to \(\), it is online learnable under a smoothed adversary. As a corollary, we also establish the following sufficient condition in terms of the Graph dimension, a combinatorial dimension characterizing PAC learnability when \(||<\) (see Appendix A for a complete definition) .

**Corollary 4.2**.: _For every \(^{}\), \(()\) and \(>0\), we have that_

\[_{}\,^{,}_{}(T,) 6 _{>0}+()\,|}{^{2}} }} 12()\,|}{^{2}}},\]

_where \(()\) denotes the Graph dimension of \(\)._

Corollary 4.2, whose proof is in Appendix E, shows that PAC learnability of \(\) is sufficient for smoothed online classification whenever \(||<\). When \(||=2\), this bounds, up to a constant factor, recovers that from Haghtalab . We now proceed with the proof of Theorem 4.1.

Proof.: (of Theorem 4.1) Let \(_{1},,_{T}\,(,)\) denote the sequence of \(\)-smooth distributions picked by the adversary. Fix a \(>0\). Then, by Lemma B.2, we have that \((,,d_{}) C_{, }(,)\). Let \(^{}\) denote an \(\)-cover with respect to \(d_{}\) of size at most \(C_{},}(,)\). Let \(\) denote the online learner that runs the Randomized Exponential Weights Algorithm (REWA) on the the data stream \((x_{1},y_{1}),...,(x_{T},y_{T})\) using \(^{}\) as its set of experts. By the guarantees of REWA,

\[}_{}[_{t=1}^{T} \{(x_{t}) y_{t}\}] _{h^{}^{}}_{t=1}^{T} \{h^{}(x_{t}) y_{t}\}+^{ }|)}\] \[_{h^{}^{}}_{t=1}^{T} \{h^{}(x_{t}) y_{t}\}+,}(,))}\] \[_{h}_{t=1}^{T}\{h(x_{t}) y _{t}\}+_{h}_{h^{}^{}}_{t=1 }^{T}\{h^{}(x_{t}) h(x_{t})\}+,}(,))}\]

where the expectation is only taken with respect to the randomness of the REWA and the last inequality follows by the triangle inequality. Taking an outer expectation with respect to the process \(x_{1:T}_{1:T}\), we have \(}_{t=1}^{T}\{(x_{t}) y _{t}\}\) is at most

\[}_{x_{1:T}_{1:T}}[_{h}_{t= 1}^{T}\{h(x_{t}) y_{t}\}]+}_{x_{1:T} _{1:T}}[_{h}_{h^{}^{}} _{t=1}^{T}\{h^{}(x_{t}) h(x_{t})\}]+,}(,))}.\]

It remains to bound \(}[_{h}_{h^{}^ {}}_{t=1}^{T}\{h^{}(x_{t}) h(x_{t})\}]\). We provide a sketch of the proof here and defer the full details to Appendix D. Consider the class \(=\{x\{h^{}(x) h(x)\}:\)\(h\}\), where \(h^{}^{}\) denotes the \(\)-cover of \(h\) with respect to \(d_{}\), and note that

\[}_{x_{1:T}_{1:T}}[_{h}_{h^{ }^{}}_{t=1}^{T}\{h^{}(x_{t}) h (x_{t})\}]}_{x_{1:T}_{1:T}}[_{g }_{t=1}^{T}g(x_{t})].\]

By standard symmetrization arguments, we get

\[}_{x_{1:T}_{1:T}}[_{g}_{t= 1}^{T}g(x_{t})]_{g}}_{x_{1:T} _{1:T}}[_{t=1}^{T}g(x_{t}^{})]+2T}_{x_ {1:T}_{1:T}}[}(,x_{1:T})]\]

where \(}(,x_{1:T})\) is the Rademacher complexity of \(\) (see Appendix A). Note that \(\) where \(:=\{x\{h_{1}(x) h_{2}(x)\}:h_{1},h_{2}\}\), and thus \(}(,x_{1:T})}( ,x_{1:T})\). Usingthe discretization-based upperbound (Lemma A.1) on the empirical Rademacher complexity and a relation between the covering numbers of \(\) and \(\) (Lemma B.3), we have

\[}(,x_{1:T})+(,,_{_{T}} )}{T}}+(^{2},,d_{_{T}})}{T}}+2(}{2},,d_{_{T}})}{T}}.\]

Plugging in the upperbound on the Rademacher complexity and using the change of measure, \(\)-smoothness, and the definition of \(^{}\) on the first term gives

\[}_{x_{1:T}_{1:T}}[_{g}_{t= 1}^{T}g(x_{t})]+2\,T+4}_{x_{1:T}_{1:T}}[ (}{2},,d_{_{T}})])}.\]

Using the definition of \(C_{,}(,)\) to get

\[}_{x_{1:T}_{1:T}}[_{h}_{h ^{}}_{t=1}^{T}\{h^{}(x_{t}) h(x_ {t})\}]+2\,T+4}{2},}(,)},\]

substituting into the regret bound for \(\), and doing some algebra completes the proof sketch. 

Our upperbounds in terms of expected empirical covering numbers can be meaningful even when \(\) and Graph dimension of \(\) is infinity. As a simple example, let \(=\), \(=()\), and consider the binary hypothesis class \(=\{x\{x A\}:A,|A|<\}\). It's not too hard to see that \(()=\). On the other hand, \(C_{,}(,)=1\) since for every \(n\), the sample \(x_{1:n}\) does not lie in \(\) almost surely, and when \(x_{1:n}\), \(d_{_{n}}(h_{1},h_{2})=0\) for all \(h_{1},h_{2}\).

To prove Theorem 4.1, we show that the UBEME implies a bound on the metric entropy \((,,d_{})\). It is natural ask whether the finiteness of \((,,d_{})\) for every \(>0\) alone is necessary and sufficient for smoothed online learnability. Unfortunately, it is neither sufficient nor necessary.

**Theorem 4.3**.: _Let \(=\) and \(=()\). Then,_

1. _There exists a_ \(\{0,1\}^{}\) _such that_ \((,,d_{})=1\) _for every_ \(>0\) _but_ \(^{,}_{}(T,)\) _for every_ \(>0\)_._
2. _There exists_ \(^{}\) _such that_ \((,,d_{})=\) _for every_ \(>0\) _but_ \(_{}^{,}_{}(T,)=O( )\) _for every_ \(>0\)_._

Proof.: We first prove (i). Consider the hypothesis class \(=\{x\{x S\}:S,|S|<\}\). Note that for every \(h_{1},h_{2}\), we have that \(d_{}(h_{1},h_{2})=_{x}[h_{1}(x) h_{2}(x)]=0\) since \(h_{1}\) and \(h_{2}\) disagree on at most a finite number of points in \(\). Thus, for every \(>0\), \(\) is trivially coverable using exactly one hypothesis in \(\). To show that \(^{,}_{}(T,)\) for every \(>0\), consider the adversary that picks \(_{t}=\) for all \(t[T]\). The process \(x_{1:T}_{1:T}\) is then an iid draw from \(\) of length \(T\). Consider the data stream \((x_{1},y_{1}),...,(x_{T},y_{T})\) where \(x_{1:T}^{T}\) and \(y_{t}(\{0,1\})\) for every \(t[T]\). Such a stream is realizable by \(\) almost surely since the the sequence of instances \(x_{1:T}\) are all distinct with probability \(1\) and there can be at most a finite number of timepoints where \(y_{t}=1\). On the other hand, any learning algorithm \(\) must make at least \(T/2\) mistakes in expectation (with respect to all sources of randomness), since the labels \(y_{t}(\{0,1\})\). Thus, by the probabilistic method, for every learning algorithm \(\), there must exist a sequence of labels \(y_{1:T}\), such that \(\)'s expected regret is \(T/2\).

We now prove (ii). Let \(=\{x a:a\}\) be the class of constant functions. Note that for every \(h_{1},h_{2}\), we have that \(d_{}(h_{1},h_{2})=1\) since \(h_{1}\) and \(h_{2}\) disagree everywhere on \(\). Thus, for every \(<1\), we have that \((,,d_{})=\) since \(||=\). On the other hand, the Littlestone dimension of \(\) is \(1\). Thus, by Theorem 4 from Hanneke et al. (2023), we get that \(_{}^{,}_{}(T,)=O()\) for every \(>0\). 

## 5 Discussion

In this work, we show a separation between the learnability of \(^{}\) in the PAC setting and the smoothed online setting when \(||\) is unbounded. We also provide a sufficient condition for smoothedonline learnability under any base measure \(\). However, as noted in Section 4, our sufficient condition is not necessary for the smoothed learnability of \(\). Thus, an important open question is to find a condition that is both necessary and sufficient for smoothed online learnability. Traditionally, in learning theory, learnability is characterized in terms of a combinatorial property of just the hypothesis class \(^{}\). However, the property of \(\) alone cannot provide a characterization of learnability in the smoothed online setting. Choosing \(\) to be a Dirac distribution will make any \(\), even the set of all measurable functions from \(\) to \(\), trivially learnable. Thus, the characterization of learnability must necessarily be a property of the tuple \((,)\). To that end, we pose the following question.

Given \((,)\), is there a complexity measure that characterizes the smoothed online learnability of \(\) with base measure \(\)?