# Flat Seeking Bayesian Neural Networks

Van-Anh Nguyen\({}^{1}\)   Tung-Long Vuong\({}^{1,2}\)   Hoang Phan\({}^{2,3}\)   Thanh-Toan Do\({}^{1}\)

Dinh Phung \({}^{1,2}\)   Trung Le \({}^{1}\)

\({}^{1}\)Department of Data Science and AI, Monash University, Australia

\({}^{2}\)VinAI, Vietnam

\({}^{3}\)New York University, United States

{wan-anh.nguyen, tung-long.vuong, toan.do, dinh.phung, trunglm}@monash.edu

hvp2011@nyu.edu

###### Abstract

Bayesian Neural Networks (BNNs) provide a probabilistic interpretation for deep learning models by imposing a prior distribution over model parameters and inferring a posterior distribution based on observed data. The model sampled from the posterior distribution can be used for providing ensemble predictions and quantifying prediction uncertainty. It is well-known that deep learning models with lower sharpness have better generalization ability. However, existing posterior inferences are not aware of sharpness/flatness in terms of formulation, possibly leading to high sharpness for the models sampled from them. In this paper, we develop theories, the Bayesian setting, and the variational inference approach for the sharpness-aware posterior. Specifically, the models sampled from our sharpness-aware posterior, and the optimal approximate posterior estimating this sharpness-aware posterior, have better flatness, hence possibly possessing higher generalization ability. We conduct experiments by leveraging the sharpness-aware posterior with state-of-the-art Bayesian Neural Networks, showing that the flat-seeking counterparts outperform their baselines in all metrics of interest.

## 1 Introduction

Bayesian Neural Networks (BNNs) provide a way to interpret deep learning models probabilistically. This is done by setting a prior distribution over model parameters and then inferring a posterior distribution over model parameters based on observed data. This allows us to not only make predictions, but also quantify prediction uncertainty, which is useful for many real-world applications. To sample deep learning models from complex and complicated posterior distributions, advanced particle-sampling approaches such as Hamiltonian Monte Carlo (HMC) , Stochastic Gradient HMC (SGHMC) , Stochastic Gradient Langevin dynamics (SGLD) , and Stein Variational Gradient Descent (SVGD)  are often used. However, these methods can be computationally expensive, particularly when many models need to be sampled for better ensembles.

To alleviate this computational burden and enable the sampling of multiple deep learning models from posterior distributions, variational inference approaches employ approximate posteriors to estimate the true posterior. These methods utilize approximate posteriors that belong to sufficiently rich families, which are both economical and convenient to sample from. However, the pioneering works in variational inference, such as , assume approximate posteriors to be fully factorized distributions, also known as mean-field variational inference. This approach fails to account for the strong statistical dependencies among random weights of neural networks, limiting its ability to capture the complex structure of the true posterior and estimate the true model uncertainty. To overcome this issue, latter works have attempted to provide posterior approximations with richerexpressiveness [61; 52; 53; 54; 20; 45; 55; 30; 48]. These approaches aim to improve the accuracy of the posterior approximation and enable more effective uncertainty quantification.

In the context of standard deep network training, it has been observed that flat minimizers can enhance the generalization capability of models. This is achieved by enabling them to locate wider local minima that are more robust to shifts between train and test sets. Several studies, including [27; 47; 15], have shown evidence to support this principle. However, the posteriors used in existing Bayesian neural networks (BNNs) do not account for the sharpness/flatness of the models derived from them in terms of model formulation. As a result, the sampled models can be located in regions of high sharpness and low flatness, leading to poor generalization ability. Moreover, in variational inference methods, using approximate posteriors to estimate these non-sharpness-aware posteriors can result in sampled models from the corresponding optimal approximate posterior lacking awareness of sharpness/flatness, hence causing them to suffer from poor generalization ability.

In this paper, our objective is to propose a sharpness-aware posterior for learning BNNs, which samples models with high flatness for better generalization ability. To achieve this, we devise both a Bayesian setting and a variational inference approach for the proposed posterior. By estimating the optimal approximate posteriors, we can generate flatter models that improve the generalization ability. Our approach is as follows: In Theorem 3.1, we show that the standard posterior is the optimal solution to an optimization problem that balances the empirical loss induced by models sampled from an approximate posterior for fitting a training set with a Kullback-Leibler (KL) divergence, which encourages a simple approximate posterior. Based on this insight, we replace the empirical loss induced by the approximate posterior with the general loss over the entire data-label distribution in Theorem 3.2 to improve the generalization ability. Inspired by sharpness-aware minimization , we develop an upper-bound of the general loss in Theorem 3.2, leading us to formulate the sharpness-aware posterior in Theorem 3.3. Finally, we devise the Bayesian setting and variational approach for the sharpness-aware posterior. Overall, our contributions in this paper can be summarized as follows:

* We propose and develop theories, the Bayesian setting, and the variational inference approach for the sharpness-aware posterior. This posterior enables us to sample a set of flat models that improve the model generalization ability. We note that SAM  only considers the sharpness for a single model, while ours is the first work studying the concept and theory of the sharpness for a distribution \(\) over models. Additionally, the proof of Theorem 3.2 is very challenging, elegant, and complicated because of the infinite number of models in the support of \(\).
* We conduct extensive experiments by leveraging our sharpness-aware posterior with the state-of-the-art and well-known BNNs, including _BNNs with an approximate Gaussian distribution _, _BNNs with stochastic gradient Langevin dynamics (SGLD) _, _MCDropout _, _Bayesian deep ensemble _, and _SWAG _ to demonstrate that the flat-seeking counterparts consistently outperform the corresponding approaches in all metrics of interest, including the ensemble accuracy, expected calibration error (ECE), and negative log-likelihood (NLL).

## 2 Related Work

### Bayesian Neural Networks

**Markov chain Monte Carlo (MCMC):** This approach allows us to sample multiple models from the posterior distribution and was well-known for inference with neural networks through the Hamiltonian Monte Carlo (HMC) . However, HMC requires the estimation of full gradients, which is computationally expensive for neural networks. To make the HMC framework practical, Stochastic Gradient HMC (SGHMC)  enables stochastic gradients to be used in Bayesian inference, crucial for both scalability and exploring a space of solutions. Alternatively, stochastic gradient Langevin dynamics (SGLD)  employs first-order Langevin dynamics in the stochastic gradient setting. Additionally, Stein Variational Gradient Descent (SVGD)  maintains a set of particles to gradually approach a posterior distribution. Theoretically, all SGHMC, SGLD, and SVGD asymptotically sample from the posterior in the limit of infinitely small step sizes.

**Variational Inference**: This approach uses an approximate posterior distribution in a family to estimate the true posterior distribution by maximizing a variational lower bound.  suggests fitting a Gaussian variational posterior approximation over the weights of neural networks, which was generalized in [32; 33; 5], using the reparameterization trick for training deep latent variable models. To provide posterior approximations with richer expressiveness, many extensive studies have been proposed. Notably,  treats the weight matrix as a whole via a matrix variate Gaussian  and approximates the posterior based on this parameterization. Several later works have inspected this distribution to examine different structured representations for the variational Gaussian posterior, such as Kronecker-factored [59; 52; 53], k-tied distribution , non-centered or rank-1 parameterization [20; 14]. Another recipe to represent the true covariance matrix of Gaussian posterior is through the low-rank approximation [45; 55; 30; 39].

**Dropout Variational Inference:** This approach utilizes dropout to characterize approximate posteriors. Typically,  and  use this principle to propose Bayesian Dropout inference methods such as MC Dropout and Variational Dropout. Concrete dropout  extends this idea to optimize the dropout probabilities. Variational Structured Dropout  employs Householder transformation to learn a structured representation for multiplicative Gaussian noise in the Variational Dropout method.

### Flat Minima

Flat minimizers have been found to improve the generalization ability of neural networks. This is because they enable models to find wider local minima, which makes them more robust against shifts between train and test sets [27; 47; 15; 44]. The relationship between generalization ability and the width of minima has been investigated theoretically and empirically in many studies, notably [23; 42; 12; 17]. Moreover, various methods seeking flat minima have been proposed in [46; 9; 29; 25; 16; 44]. Typically, [29; 26; 57] investigate the impacts of different training factors such as batch size, learning rate, covariance of gradient, and dropout on the flatness of found minima. Additionally, several approaches pursue wide local minima by adding regularization terms to the loss function [46; 61; 60; 9]. Examples of such regularization terms include softmax output's low entropy penalty  and distillation losses [61; 60].

SAM, a method that aims to minimize the worst-case loss around the current model by seeking flat regions, has recently gained attention due to its scalability and effectiveness compared to previous methods [16; 56]. SAM has been widely applied in various domains and tasks, such as meta-learning bi-level optimization , federated learning , multi-task learning , where it achieved tighter convergence rates and proposed generalization bounds. SAM has also demonstrated its generalization ability in vision models , language models , domain generalization , and multi-task learning . Some researchers have attempted to improve SAM by exploiting its geometry [34; 31], additionally minimizing the surrogate gap , and speeding up its training time [13; 37]. Regarding the behavior of SAM,  empirically studied the difference in sharpness obtained by SAM  and SWA [24; 40] showed that SAM is an optimal Bayes relaxation of the standard Bayesian inference with a normal posterior, while  proved that distribution robustness [4; 49] is a probabilistic extension of SAM.

## 3 Proposed Framework

In what follows, we present the technicality of our proposed sharpness-aware posterior. Particularly, Section 3.1 introduces the problem setting and motivation for our sharpness-aware posterior. Section 3.2 is dedicated to our theory development, while Section 3.3 is used to describe the Bayesian setting and variational inference approach for our sharpness-aware posterior.

### Problem Setting and Motivation

We aim to develop Sharpness-Aware Bayesian Neural Networks (SA-BNN). Consider a family of neural networks \(f_{}(x)\) with \(\) and a training set \(=\{(x_{1},y_{1}),...,(x_{n},y_{n})\}\) where \((x_{i},y_{i})\). We wish to learn a posterior distribution \(_{S}^{SA}\) with the density function \(q^{SA}(|)\) such that any model \(_{S}^{SA}\) is aware of the sharpness when predicting over the training set \(\).

We depart with the standard posterior

\[q()_{i=1}^{n}p(y_{i} x_{i},, )p(),\]where the prior distribution \(\) has the density function \(p()\) and the likelihood has the form

\[p(y x,,)\{-|}(f_{}(x),y)\}=\{-(f_{}(x),y)\}\]

with the loss function \(\). The standard posterior \(_{}\) has the density function defined as

\[q()\{-_{i=1}^{n} (f_{}(x_{i}),y_{i})\}p(), \]

where \( 0\) is a regularization parameter.

We define the general and empirical losses as follows:

\[_{}()=_{(x,y)} [(f_{}(x),y)].\]

\[_{}()=_{(x,y)} [(f_{}(x),y)]=_{i=1} ^{n}(f_{}(x_{i}),y_{i}).\]

Basically, the general loss is defined as the expected loss over the entire data-label distribution \(\), while the empirical loss is defined as the empirical loss over a specific training set \(\).

The standard posterior in Eq. (1) can be rewritten as

\[q()\{-_{} ()\}p(). \]

Given a distribution \(\) with the density function \(q()\) over the model parameters \(\), we define the empirical and general losses over this model distribution \(\) as

\[_{}() =_{}_{}()d ()=_{}_{}( )q()d.\] \[_{}() =_{}_{}()d ()=_{}_{}( )q()d.\]

Specifically, the general loss over the model distribution \(\) is defined as the expectation of the general losses incurred by the models sampled from this distribution, while the empirical loss over the model distribution \(\) is defined as the expectation of the empirical losses incurred by the models sampled from this distribution.

### Our Theory Development

We now present the theory development for the sharpness-aware posterior whose proofs can be found in the supplementary material. Inspired by the Gibbs form of the standard posterior \(_{}\) in Eq. (2), we establish the following theorem to connect the standard posterior \(_{}\) with the density \(q()\) and the empirical loss \(_{}()\).

**Theorem 3.1**.: _Consider the following optimization problem_

\[_{<<}\{_{S}( )+KL(,)\}, \]

_where we search over \(\) absolutely continuous w.r.t. \(\) and \(KL(,)\) is the Kullback-Leibler divergence. This optimization has a closed-form optimal solution \(^{*}\) with the density_

\[q^{*}()\{-_{} ()\}p(),\]

_which is exactly the standard posterior \(_{}\) with the density \(q()\)._

Theorem 3.1 reveals that we need to find the posterior \(_{}\) balancing between optimizing its empirical loss \(_{}()\) and simplicity via \(KL(,)\). However, minimizing the empirical loss \(_{}()\) only ensures the correct predictions for the training examples in \(\), hence possibly encountering overfitting. Therefore, it is desirable to replace the empirical loss by the general loss to combat overfitting.

To mitigate overfitting, in (3), we replace the empirical loss by the general loss and solve the following optimization problem (OP):

\[_{<<}\{_{}( )+KL(,)\}. \]

Notably, solving the optimization problem (OP) in (4) is generally intractable. To make it tractable, we find its upper-bound which is relevant to the sharpness of a distribution \(\) over models as shown in the following theorem.

**Theorem 3.2**.: _Assume that \(\) is a compact set. Under some mild conditions, given any \([0;1]\), with the probability at least \(1-\) over the choice of \(^{n}\), for any distribution \(\), we have_

\[_{}()_{ }[_{^{}\|^{}-\|} _{}(^{})]+f(_{ }\|\|^{2},n),\]

_where \(f\) is a non-decreasing function w.r.t. the first variable and approaches \(0\) when the training size \(n\) approaches \(\)._

We note that the proof of Theorem 3.2 is not a trivial extension of sharpness-aware minimization because we need to tackle the general and empirical losses over a distribution \(\). To make explicit our sharpness over a distribution \(\) on models, we rewrite the upper-bound of the inequality as

\[_{}[_{^{}\|^{ }-\|}_{}(^{}) -_{}()]+_{ }()+f(_{}\|\|^{ 2},n),\]

where the first term \(_{}[_{^{}\|^{ }-\|}_{}(^{}) -_{}()]\) can be regarded as _the sharpness over the distribution \(\) on the model space_ and the last term \(f(_{}\|\|^{2},n)\) is a constant.

Moreover, inspired by Theorem 3.2, we propose solving the following OP which forms an upper-bound of the desirable OP in (4)

\[_{<<}\{_{} [_{^{}\|^{}-\|} _{}(^{})]+KL(,)\}. \]

The following theorem characterizes the optimal solution of the OP in (5).

**Theorem 3.3**.: _The optimal solution the OP in (5) is the sharpness-aware posterior distribution \(_{}^{SA}\) with the density function \(q^{SA}(|)\):_

\[q^{SA}(|)\{-_{^{} \|^{}-\|}_{}(^{ })\}p()=\{-_{ }(s())\}p(),\]

_where we have defined \(s()=\|^{}-\| }{argmax}_{}(^{})\)._

Theorem 3.3 describes the close form of the sharpness-aware posterior distribution \(_{}^{SA}\) with the density function \(q^{SA}(|)\). Based on this characterization, in what follows, we introduce the SA Bayesian setting that sheds lights on its variational approach.

### Sharpness-Aware Bayesian Setting and Its Variational Approach

**Bayesian Setting:** To promote the Bayesian setting for sharpness-aware posterior distribution \(_{}^{SA}\), we examine the sharpness-aware likelihood

\[p^{SA}(y x,,)\{-|}(f_{s()}(x),y)\}= \{-(f_{s()}(x),y) \},\]

where \(s()=\|^{}-\| }{argmax}_{}(^{})\).

With this predefined sharpness-aware likelihood, we can recover the sharpness-aware posterior distribution \(_{}^{SA}\) with the density function \(q^{SA}(|)\):

\[q^{SA}(|)_{i=1}^{n}p^{SA}(y_{i} x_{i}, ,)p().\]

**Variational inference for the sharpness-aware posterior distribution:** We now develop the variational inference for the sharpness-aware posterior distribution. Let denote \(X=[x_{1},...,x_{n}]\) and\(Y=[y_{1},...,y_{n}]\). Considering an approximate posterior family \(\{q_{}():\}\), we have

\[ p^{SA}(Y X,)=_{}q_{} () p^{SA}(Y X,)d\] \[=_{}q_{}()(Y ,X,)p()}{q_{}( )}()}{q^{SA}(|)}d\] \[=_{q_{}()}[_{i=1}^{n} p ^{SA}(y_{i} x_{i},,)]-KL(q_{},p )+KL(q_{},q^{SA}).\]

It is obvious that we need to maximize the following lower bound for maximally reducing the gap \(KL(q_{},q^{SA})\):

\[_{q_{}}\{_{q_{}()}[_{i=1} ^{n} p^{SA}(y_{i} x_{i},,)]-KL( q_{},p)\},\]

which can be equivalently rewritten as

\[_{q_{}}\{_{q_{}()}[ _{}(s())]+KL(q_{ },p)\}\] \[_{q_{}}\{_{q_{}( )}[_{^{}:\|^{}-\| }_{}(^{})]+KL(q_{ },p)\}. \]

**Derivation for Variational Approach with A Gaussian Approximate Posterior:** Inspired by the geometry-based SAM approaches , we incorporate the geometry to the SA variational approach via the distance to define the ball for the sharpness as \(\|^{}-\|_{(T_{})}=-)^{T}(T_{})^{-1}(^{ }-)}\) as

\[_{q_{}}\{_{q_{}()}[ _{^{}:\|^{}-\|_{(T_{ })}}_{}(^{}) ]+KL(q_{},p)\}.\]

To further clarify, we consider our SA posterior distribution to Bayesian NNs, wherein we impose the Gaussian distributions to its weight matrices \(W_{i}(_{i},_{i}^{2}),i=1,,L @note{footnote}{We absorb the biases to the weight matrices.}\). The parameter \(\) consists of \(_{i},_{i},i=1,,L\). For \(=W_{1:L} q_{}\), using the reparameterization trick \(W_{i}=_{i}+(_{i})_{i},_{i} (0,)\) and by searching \(^{{}^{}}=W_{1:L}^{{}^{}}\) with \(W_{i}^{{}^{}}=_{i}^{{}^{}}+(_{i})_{i},_{i}(0,)\), the constraint \(\|-^{}\|_{(T_{})}=\|- ^{{}^{}}\|_{(T_{})}\) with \(=_{1:L}\) and \(^{{}^{}}=_{1:L}^{{}^{}}\). Thus, the OP in (6) reads

\[_{,}\{_{}[_{\|^{{ }^{}}-\|_{(T_{,})}}_{ }([_{i}^{{}^{}}+(_{i}) _{i}]_{i=1}^{L})]\}, \]

where \(=_{1:L}\), \(=_{1:L}\), and we define \((T_{})=(T_{,})\) in the distance of the geometry.

To solve the OP in (7), we sample \(=_{1:L}\) from the standard Gaussian distributions, employ an one-step gradient ascent to find \(^{{}^{}}\), and use the gradient at \(^{{}^{}}\) to update \(\). Specifically, we find \(^{}\) (Chapter 9) as

\[^{}=+(T_{,})_{}_ {}([_{i}+(_{i})_{i}] _{i=1}^{L})}{\|(T_{,})_{}_ {}([_{i}+(_{i})_{i}] _{i=1}^{L})\|}.\]

The diagnose of \((T_{,})\) specifies the importance level of the model weights, i.e., the weight with a higher importance level is encouraged to have a higher sharpness via a smaller absolute partial derivative of the loss w.r.t. this weight. We consider \((T_{,})=\) (i.e., _the standard SA BNN_) and \((T_{,})=()\) (i.e., _the geometry SA BNN_). Here we note that \(\) represents the element-wise division.

Finally, the objective function in (6) indicates that we aim to find an approximate posterior distribution that ensures any model sampled from it is aware of the sharpness, while also preferring simpler approximate posterior distributions. This preference can be estimated based on how we equip these distributions. With the Bayesian setting and variational inference formulation, our proposed sharpness-aware posterior can be integrated into MCMC-based and variational inference-based Bayesian Neural Networks. The supplementary material contains the details on how to derive variational approaches and incorporate the sharpness-awareness into the BNNs used in our experiments including BNNs with an approximate Gaussian distribution , BNNs with stochastic gradient Langevin dynamics (SGLD) , MC-Dropout , Bayesian deep ensemble , and SWAG .

## 4 Experiments

In this section, we conduct various experiments to demonstrate the effectiveness of the sharpness-aware approach on Bayesian Neural networks, including BNNs with an approximate Gaussian distribution  (i.e., SGVB for model's reparameterization trick and SGVB-LRT for representation's reparameterization trick), BNNs with stochastic gradient Langevin dynamics (SGLD) , MC-Dropout , Bayesian deep ensemble , and SWAG . The experiments are conducted on three benchmark datasets: CIFAR-10, CIFAR-100, and ImageNet ILSVRC-2012, and report accuracy, negative log-likelihood (NLL), and Expected Calibration Error (ECE) to estimate the calibration capability and uncertainty of our method against baselines. The details of the dataset and implementation are described in the supplementary material2.

    &  &  \\ Method & ACC \(\) & NLL \(\) & ECE \(\) & ACC \(\) & NLL \(\) & ECE \(\) \\  
**Variational inference** & & & & & & \\ MC-Dropout & 96.18 \(\) 0.02 & 0.1270 \(\) 0.0030 & 0.0162 \(\) 0.0007 & 96.39 \(\) 0.09 & 0.1094 \(\) 0.0021 & **0.0094 \(\) 0.0044** \\ F-MC-Dropout & **96.39 \(\) 0.18** & **0.1137 \(\) 0.0024** & **0.0118 \(\) 0.0006** & **97.10 \(\) 0.12** & **0.0966 \(\) 0.0047** & 0.0095 \(\) 0.0008 \\  Deep-ens & 96.39 \(\) 0.09 & 0.1277 \(\) 0.0030 & 0.0108 \(\) 0.0015 & 96.96 \(\) 0.10 & 0.1031 \(\) 0.0076 & 0.0087 \(\) 0.0018 \\ F-Deep-ens & **96.70 \(\) 0.04** & **0.1031 \(\) 0.0016** & **0.0057 \(\) 0.0031** & **97.11 \(\) 0.10** & **0.0851 \(\) 0.0011** & **0.0059 \(\) 0.0012** \\  
**Markov chain Monte Carlo** & & & & & & \\ SGLD & 94.79 \(\) 0.10 & 0.2089 \(\) 0.0021 & 0.0711 \(\) 0.0061 & 95.87 \(\) 0.08 & 0.1573 \(\) 0.0190 & 0.0463 \(\) 0.0050 \\ F-SGLD & **95.04 \(\) 0.06** & **0.1912 \(\) 0.0080** & **0.0601 \(\) 0.0002** & **96.43 \(\) 0.05** & **0.1336 \(\) 0.004** & **0.0385 \(\) 0.0003** \\  
**Sample** & & & & & & \\ SWAG-Diag & 96.03 \(\) 0.10 & 0.1251 \(\) 0.0029 & 0.0082 \(\) 0.0008 & 96.41 \(\) 0.05 & 0.1077 \(\) 0.0009 & 0.0047 \(\) 0.0013 \\ F-SWAG-Diag & **96.23 \(\) 0.01** & **0.1108 \(\) 0.0013** & **0.0043 \(\) 0.0005** & **97.05 \(\) 0.08** & **0.0888 \(\) 0.0052** & **0.0043 \(\) 0.0004** \\  SWAG & 96.03 \(\) 0.02 & 0.1232 \(\) 0.0022 & **0.0053 \(\) 0.0004** & 96.32 \(\) 0.08 & 0.1122 \(\) 0.0009 & 0.0088 \(\) 0.0006 \\ F-SWAG & **96.25 \(\) 0.03** & **0.11062 \(\) 0.0014** & 0.0056 \(\) 0.0002 & **97.09 \(\) 0.14** & **0.0883 \(\) 0.0004** & **0.0036 \(\) 0.0008** \\   

Table 2: Classification score on CIFAR-10 dataset.Each experiment is repeated three times with different random seeds and reports the mean and standard deviation.

    &  &  \\ Method & ACC \(\) & NLL \(\) & ECE \(\) & ACC \(\) & NLL \(\) & ECE \(\) \\  
**Variational inference** & & & & & \\ MC-Dropout & 96.18 \(\) 0.02 & 0.1270 \(\) 0.0030 & 0.0162 \(\) 0.0007 & 96.39 \(\) 0.09 & 0.1094 \(\) 0.0021 & **0.0094 \(\) 0.0044** \\ F-MC-Dropout & **96.39 \(\) 0.18** & **0.1137 \(\) 0.0024** & **0.0118 \(\) 0.0006** & **97.10 \(\) 0.12** & **0.0966 \(\) 0.0047** & 0.0095 \(\) 0.0008 \\  Deep-ens & 96.39 \(\) 0.09 & 0.1277 \(\) 0.0030 & 0.0108 \(\) 0.0015 & 96.96 \(\) 0.10 & 0.1031 \(\) 0.0076 & 0.0087 \(\) 0.0018 \\ F-Deep-ens & **96.70 \(\) 0.04** & **0.1031 \(\) 0.0016** & **0.0057 \(\) 0.0031** & **97.11 \(\) 0.10** & **0.0851 \(\) 0.0011** & **0.0059 \(\) 0.0012** \\  
**Markov chain Monte Carlo** & & & & & \\ SGLD & 94.79 \(\) 0.10 & 0.2089 \(\) 0.0021 & 0.0711 \(\) 0.0061 & 95.87 \(\) 0.08 & 0.1573 \(\) 0.0190 & 0.0463 \(\) 0.0050 \\ F-SGLD & **95.04 \(\) 0.06** & **0.1912 \(\) 0.0080** & **0.0601 \(\) 0.0002** & **96.43 \(\) 0.05** & **0.1336 \(\) 0.004** & **0.0385 \(\) 0.0003** \\  
**Sample** & & & & & \\ SWAG-Diag & 96.03 \(\) 0.10 & 0.1251 \(\) 0.0029 & 0.0082 \(\) 0.0008 & 96.41 \(\) 0.05 & 0.1077 \(\) 0.0009 & 0.0047 \(\) 0.0013 \\ F-SWAG-Diag & **96.23 \(\) 0.01** & **0.1108 \(\) 0.0013** & **0.0043 \(\) 0.0005** & **97.05 \(\) 0.08** & **0.0888 \(\) 0.0052** & **0.0043 \(\) 0.0004** \\  SWAG & 96.03 \(\) 0.02 & 0.1232 \(\) 0.0022 & **0.0053 \(\)

### Experimental results

#### 4.1.1 Predictive performance

Our experimental results, presented in Tables 1, 2, 3 for CIFAR-100 and CIFAR-10 dataset, and Table 4 for the ImageNet dataset, indicate a notable improvement across all experiments. It is worth noting that there is a trade-off between accuracy, negative log-likelihood, and expected calibration error. Nonetheless, our approach obtains a fine balance between these factors compared to the overall improvement.

### Effectiveness of sharpness-aware posterior

**Calibration of uncertainty estimates:** We evaluate the ECE of each setting and compare it to baselines in Tables 1, 2, and 4. This score measures the maximum discrepancy between the accuracy

    &  &  \\ Model & ACC \(\) & NLL \(\) & ECE \(\) & ACC \(\) & NLL \(\) & ECE \(\) \\   SWAG-Diag & 78.59 & 0.8559 & 0.0459 & 78.96 & 0.8584 & 0.0566 \\ F-SWAG-Diag & **78.71** & **0.8267** & **0.0194** & **79.20** & **0.8065** & **0.0199** \\  SWAG & 78.59 & 0.8303 & 0.0204 & 79.08 & 0.8205 & 0.0279 \\ F-SWAG & **78.70** & **0.8262** & **0.0185** & **79.17** & **0.8078** & **0.0208** \\  SGLD & 78.50 & 0.8317 & **0.0157** & 79.00 & 0.8165 & 0.0220 \\ F-SGLD & **78.64** & **0.8236** & 0.0166 & **79.16** & **0.8050** & **0.0167** \\   

Table 4: Classification score on ImageNet dataset

Figure 1: Comparing loss landscape of PreResNet-164 on CIFAR-100 dataset training with SWAG and F-SWAG method. For visualization purposes, we sample two models for each SWAG and F-SWAG and then plot the loss landscapes. It can be observed that the loss landscapes of our F-SWAG are flatter, supporting our argument for the flatter sampled models.

    &  &  \\ Method & ACC \(\) & NLL \(\) & ECE \(\) & ACC \(\) & NLL \(\) & ECE \(\) \\    \\ SGVB-LRT & 61.75 \(\) 0.75 & 1.534 \(\) 0.03 & 0.0676 \(\) 0.01 & 68.95 \(\) 1.20 & 1.140 \(\) 0.21 & 0.063 \(\) 0.04 \\ F-SGVB-LRT & 62.25 \(\) 0.57 & 1.4001 \(\) 0.04 & 0.0642 \(\) 0.01 & 70.00 \(\) 1.42 & 1.127 \(\) 0.25 & **0.022 \(\) 0.05** \\ + Geometry & **62.54 \(\) 0.67** & **1.3704 \(\) 0.01** & **0.0301 \(\) 0.03** & **70.12 \(\) 1.02** & **1.121 \(\) 0.23** & 0.036 \(\) 0.06 \\  SGVB & 54.40 \(\) 0.98 & 1.968 \(\) 0.05 & 0.214 \(\) 0.00 & 60.91 \(\) 2.31 & 1.746 \(\) 0.15 & 0.246 \(\) 0.03 \\ F-SGVB & 54.53 \(\) 0.33 & 1.967 \(\) 0.00 & 0.212 \(\) 0.00 & 61.54 \(\) 2.23 & 1.695 \(\) 0.15 & 0.242 \(\) 0.03 \\ + Geometry & **55.53 \(\) 0.65** & **1.906 \(\) 0.02** & **0.207 \(\) 0.00** & **62.58 \(\) 0.53** & **1.612 \(\) 0.03** & **0.224 \(\) 0.00** \\    \\ SGVB-LRT & 84.98 \(\) 1.87 & 0.422 \(\) 0.10 & 0.043 \(\) 0.04 & 89.10 \(\) 1.32 & 0.344 \(\) 0.02 & 0.033 \(\) 0.02 \\ F-SGVB-LRT & 86.32 \(\) 1.34 & 0.409 \(\) 0.03 & **0.017 \(\) 0.06** & 90.00 \(\) 1.10 & 0.291 \(\) 0.02 & 0.019 \(\) 0.01 \\ + Geometry & **86.44 \(\) 1.12** & **0.403 \(\) 0.06** & 0.025 \(\) 0.03 & **90.31 \(\) 1.11** & **0.262 \(\) 0.01** & **0.014 \(\) 0.02** \\  SGVB & 80.52 \(\) 2.10 & 0.781 \(\) 0.23 & 0.237 \(\) 0.06 & 86.74 \(\) 1.25 & 0.541 \(\) 0.01 & 0.181 \(\) 0.02 \\ F-SGVB & 80.60 \(\) 1.88 & 0.776 \(\) 0.13 & 0.223 \(\) 0.05 & **87.01 \(\) 0.91** & 0.534 \(\) 0.01 & 0.183 \(\) 0.01 \\ + Geometry & **82.05 \(\) 0.47** & **0.704 \(\) 0.01** & **0.206 \(\) 0.00** & 86.80 \(\) 1.30 & **0.531 \(\) 0.01** & **0.175 \(\) 0.01** \\   

Table 3: Classification scores of approximate the Gaussian posterior on the CIFAR datasets. Each experiment is repeated three times with different random seeds and reports the mean and standard deviation.

and confidence of the model. To further clarify it, we display the Reliability Diagrams of PreResNet-164 on CIFAR-100 to understand how well the model predicts according to the confidence threshold in Figure 2. The experiments is detailed in the supplementary material.

**Out-of-distribution prediction:** The effectiveness of the sharpness-aware Bayesian neural network (BNN) is demonstrated in the above experiments, particularly in comparison to non-flat methods. In this section, we extend the evaluation to an out-of-distribution setting. Specifically, we utilize the BNN models trained on the CIFAR-10 dataset to assess their performance on the CIFAR-10-C dataset. This is an extension of the CIFAR-10 designed to evaluate the robustness of machine learning models against common corruptions and perturbations in the input data. The corruptions include various forms of noise, blur, weather conditions, and digital distortions. We conduct an ensemble of 30 models sampled from the flat-posterior distribution and compared them with non-flat ones. We present the average result of each corruption group and the average result on the whole dataset in Table 5, the detailed result of each corruption form is displayed in the supplementary material. Remarkably, the flat BNN models consistently surpass their non-flat counterparts with respect to average ECE and accuracy metrics. This finding is additional evidence of the generalization ability of the sharpness-aware posterior.

### Ablation studies

In Figure 1, we plot the loss-landscape of the models sampled from our proposal of sharpness-aware posterior against the non-sharpness-aware one. Particularly, we compare two methods F-SWAG and SWAG by selecting four random models sampled from the posterior distribution of each method under the same hyper-parameter settings. As observed, our method not only improves the generalization of ensemble inference, demonstrated by classification results in Section 4.1 and sharpness in Section 4.2, but also the individual sampled model is flatter itself.

We measure and visualize the sharpness of the models. To this end, we sample five models from the approximate posteriors and then take the average of the sharpness of these models. For a model \(\), the sharpness is evaluated as \(\ _{}(+ )-_{}()\) to measure the change of loss value around \(\). We calculate the sharpness score of PreResNet-164 network for SWAG, and F-SWAG training on CIFAR-100 dataset and visualize them in the supplementary material. As shown there, the sharpness-aware versions produce smaller _sharpness_ scores compared to the corresponding baselines, indicating that our models get into flatter regions.

Figure 2: Reliability diagrams for PreResNet164 on CIFAR-100. The confidence is split into 20 bins and plots the gap between confidence and accuracy in each bin. The best case is the black dashed line when this gap is zeros. The plots of F-SWAG get closer to the zero lines, implying our F-SWAG can calibrate the uncertainty better.

    &  &  \\ Corruption & SWAG-D & F-SWAG-D & SWAG & F-SWAG & SWAG-D & F-SWAG-D & SWAG & F-SWAG \\   Noise & 0.0729 & 0.0701 & 0.0958 & 0.0078 & 74.26 & 75.59 & 74.02 & 75.08 \\ Blur & 0.0121 & 0.0090 & 0.0202 & 0.0273 & 91.13 & 90.55 & 91.03 & 90.93 \\ Weather & 0.018 & 0.0142 & 0.0722 & 0.0240 & 89.47 & 89.18 & 89.42 & 89.11 \\ Digital and others & 0.0277 & 0.0229 & 0.0384 & 0.0209 & 87.03 & 86.94 & 86.93 & 87.19 \\  Average & 0.0328 & **0.0290** & 0.0454 & **0.0200** & 85.47 & **85.56** & 85.35 & **85.58** \\   

Table 5: Classification score on CIFAR-10-C on PreResNet-164 model when training with CIFAR-10. The full result on each type of corruption is displayed in the supplementary material.

Conclusion

In this paper, we introduce theories in the Bayesian setting and discuss variational inference for the sharpness-aware posterior in the context of Bayesian Neural Networks (BNNs). The sharpness-aware posterior results in models that are less sensitive to noise and have a better generalization ability, as it enables the models sampled from it and the optimal approximate posterior estimates to have a higher flatness. We conducted extensive experiments that leveraged the sharpness-aware posterior with state-of-the-art Bayesian Neural Networks. Our main results show that the models sampled from the proposed posterior outperform their baselines in terms of ensemble accuracy, expected calibration error (ECE), and negative log-likelihood (NLL). This indicates that the flat-seeking counterparts are better at capturing the true distribution of weights in neural networks and providing accurate probabilistic predictions. Furthermore, we performed ablation studies to showcase the effectiveness of the flat posterior distribution on various factors such as uncertainty estimation, loss landscape, and out-of-distribution prediction. Overall, the sharpness-aware posterior presents a promising approach for improving the generalization performance of Bayesian neural networks.

Acknowledgements.This work was partly supported by ARC DP23 grant DP230101176 and by the Air Force Office of Scientific Research under award number FA2386-23-1-4044.