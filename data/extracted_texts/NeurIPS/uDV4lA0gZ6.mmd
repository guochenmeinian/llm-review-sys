# Efficient Robust Bayesian Optimization

for Arbitrary Uncertain inputs

 Lin Yang

Huawei Noah's Ark Lab

China

yanglin33@huawei.com

&Junlong Lyu

Huawei Noah's Ark Lab

Hong Kong SAR, China

lyujunlong@huawei.com

&Wenlong Lyu

Huawei Noah's Ark Lab

China

lvwenlong2@huawei.com

&Zhitang Chen

Huawei Noah's Ark Lab

Hong Kong SAR, China

chenzhitang2@huawei.com

###### Abstract

Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic functions and real problems demonstrate that our approach can handle various input uncertainties and achieve a state-of-the-art performance.

## 1 Introduction

Bayesian Optimization (BO) is a powerful sequential decision-making algorithm for high-cost black-box optimization. Owing to its remarkable sample efficiency and capacity to balance exploration and exploitation, BO has been successfully applied in diverse domains, including neural architecture search , hyper-parameter tuning , and robotic control , among others. Nevertheless, in some real-world problems, the stochastic nature of the optimization process, such as machining error during manufacturing, execution noise of control, or variability in contextual factor, inevitably introduces input randomness, rendering the design parameter \(x\) to deviate to \(x^{}\) before evaluation. This deviation produces a fluctuation of function value \(y\) and eventually leads to a performance instability of the outcome. In general, the input randomness is determined by the application scenario and can be of arbitrary distribution, even quite complex ones. Moreover, in some cases, we cannot observe the exact deviated input \(x^{}\) but a rough estimation for the input uncertainty. This is quite common for robotics and process controls. For example, consider a robot control task shown in Figure 0(a), a drone is sent to a target location \(x\) to perform a measurement task. However, due to the execution noise caused by the fuzzy control or a sudden wind, the drone ends up at location \(x^{} P(x)\) and gets a noisy measurement \(y=f(x^{})+\). Instead of observing the exact value of\(x^{}\), we only have a coarse estimation of the input uncertainty \(P(x)\). The goal is to identify a robust location that gives the maximal expected measurement under the process randomness.

To find a robust optimum, it is crucial to account for input uncertainty during the optimization process. Existing works [24; 3; 7; 10] along this direction assume that the exact input value, _i.e._, \(x^{}\) in Figure 0(b), is observable and construct a surrogate model using these exact inputs. Different techniques are then employed to identify the robust optimum: Nogueira et al. utilize the unscented transform to propagate input uncertainty to the acquisition function , while Beland and Nair integrate over the exact GP model to obtain the posterior with input uncertainty . Meanwhile,  designs a robust confidence-bounded acquisition and applies min-max optimization to identify the robust optimum. Similarly,  constructs an adversarial surrogate with samples from the exact surrogate. These methods work quite well but are constrained by their dependence on observable input values, which may not always be practical.

An alternative approach involves directly modeling the uncertain inputs. A pioneering work by Moreno _et al._ assumes Gaussian input distribution and employs a symmetric Kullback-Leibler divergence (SKL) to measure the distance of input variables. Dallaire _et al._ implement a Gaussian process model with an expected kernel and derive a closed-form solution by restricting the kernel to linear, quadratic, or squared exponential kernels and assuming Gaussian inputs. Nonetheless, the applicability of these methods is limited due to their restrictive Gaussian input distribution assumption and kernel choice. To surmount these limitations, Oliveira _et al._ propose a robust Gaussian process model that incorporates input distribution by computing an integral kernel. Although this kernel can be applied to various distributions and offers a rigorous regret bound, its posterior inference requires a large sampling and can be time-consuming.

In this work, we propose an Arbitrary Input uncertainty Robust Bayesian Optimization algorithm (AIRBO). This algorithm can directly model the uncertain input of arbitrary distribution and propagate the input uncertainty into the surrogate posterior, which can then be used to guide the search for robust optimum. To achieve this, we employ Gaussian Process (GP) as the surrogate and empower its kernel design with the Maximum Mean Discrepancy (MMD), which allows us to comprehensively compare the uncertain inputs in Reproducing Kernel Hilbert Space (RKHS) and accurately quantify the target function under various input uncertainties(Sec. 3.1). Moreover, to stabilize the MMD estimation and accelerate the posterior inference, we utilize Nystrom approximation to reduce the space complexity of MMD estimation from \(O(m^{2})\) to \(O(mh)\), where \(h m\) (Sec. 3.2). This can substantially improve the parallelization of posterior inference and a rigorous theoretical regret bound is also established under the approximation error (Sec. 4). Comprehensive evaluations on synthetic functions and real problems in Sec.5 demonstrate that our algorithm can efficiently identify robust optimum under complex input uncertainty and achieve state-of-the-art performance.

## 2 Problem Formulation

In this section, we first formalize the robust optimization problem under input uncertainty then briefly review the intuition behind Bayesian Optimization and Gaussian Processes.

### Optimization with Input Uncertainty

As illustrated in Figure 0(b), we consider an optimization of expensive black-box function: \(f(x)\), where \(x\) is the _design parameter_ to be tuned. At each iteration \(n\), we select a new query point

Figure 1: Robust Bayesian optimization problem.

according to the optimization heuristics. However, due to the stochastic nature of the process, such as machining error or execution noise, the query point is perturbed to \(x_{n}^{}\) before the function evaluation. Moreover, we cannot observe the exact value of \(x_{n}^{}\) and only have a vague probability estimation of its value: \(P_{x_{n}}\). After the function evaluation, we get a noisy measurement \(y=f(x_{n}^{})+_{n}\), where \(_{n}\) is homogeneous measurement noise sampled from \((0,^{2})\). The goal is to find an optimal design parameter \(x^{*}\) that maximizes the expected function value under input uncertainty:

\[x^{*}=*{arg\,max}_{x}_{x^{} P_{x}}f(x^{})dx^{ }=*{arg\,max}_{x}_{P_{x}}[f]\] (1)

Depending on the specific problem and randomness source, the input distribution \(P_{x}\) can be arbitrary in general and even become quite complex sometimes. Here we do not place any additional assumption on them, except assuming we can sample from these input distributions, which can be easily done by approximating it with Bayesian methods and learning a parametric probabilistic model . Additionally, we assume the exact values of \(x^{}\) are inaccessible, which is quite common in some real-world applications, particularly in robotics and process control .

### Bayesian Optimization

In this paper, we focus on finding the robust optimum with BO. Each iteration of BO involves two key steps: I) fitting a surrogate model and II) maximizing an acquisition function.

**Gaussian Process Surrogate:** To build a sample-efficient surrogate, we choose Gaussian Process (GP) as the surrogate model in this paper. Following , GP can be interpreted from a weight-space view: given a set of \(n\) observations, \(_{n}=\{(x_{i},y_{i})|i=1,...,n\}\). Denote all the inputs as \(X^{D n}\) and all the output vector as \(y^{n 1}\). We first consider a linear surrogate:

\[f(x)=x^{T}w,\ y=f(x)+,\ (0,^{2}),\] (2)

where \(w\) is the model parameters and \(\) is the observation noise. This model's capacity is limited due to its linear form. To obtain a more powerful surrogate, we can extend it by projecting the input \(x\) into a feature space \((x)\). By taking a Bayesian treatment and placing a zero mean Gaussian prior on the weight vector: \(w(0,_{p})\), its predictive distribution can be derived as follows (see Section2.1 of  for detailed derivation):

\[ f_{*}|x_{*},X,y^{T}(x_{* })_{p}(X)(A+_{n}^{2}I)^{-1}y,\\ ^{T}(x_{*})_{p}(x_{*})-^{T}(x_{*})_{p} (X)(A+_{n}^{2}I)^{-1}^{T}(X)_{p}(x_{*}),\] (3)

where \(A=^{T}(X)_{p}(X)\) and \(I\) is a identity matrix. Note the predictive distribution is also a Gaussian and the feature mappings are always in the form of inner product with respect to \(_{p}\). This implies we are comparing inputs in a feature space and enables us to apply kernel trick. Therefore, instead of exactly defining a feature mapping \(()\), we can define a kernel: \(k(x,x^{})=(x)^{T}_{p}(x^{})=(x)(x^{ })\). Substituting it into Eq. 3 gives the vanilla GP posterior:

\[& f_{*}|X,y,X_{*}(_{*},_{*}), _{*}=K(X_{*},X)[K(X,X)+_{n}^{2}I]^{-1}y,\\ &_{*}=K(X_{*},X_{*})-K(X_{*},X)[K(X,X)+_{n}^{2}I]^{-1 }K(X,X_{*}).\] (4)

From this interpretation of GP, we note that its core idea is to project the input \(x\) to a (possibly infinite) feature space \((x)\) and compare them in the Reproducing Kernel Hilbert Space (RKHS) defined by kernel.

**Acquisition Function Optimization:** Given the posterior of GP surrogate model, the next step is to decide a query point \(x_{n}\). The exploitation and exploration balance is achieved by designing an acquisition function \((x|D_{n})\). Through numerous acquisition functions exist , we follow [25; 7] and adopt the Upper Confidence Bound (UCB) acquisition:

\[(x|_{n})=_{*}(x)+_{*}(x),\] (5)

where \(\) is a hyper-parameter to control the level of exploration.

## 3 Proposed Method

To cope with randomness during the optimization process, we aim to build a robust surrogate that can directly accept the uncertain inputs of arbitrary distributions and propagate the input uncertainty into the posterior. Inspired by the weight-space interpretation of GP, we empower GP kernel with MMD to compare the uncertain inputs in RKHS. In this way, the input randomness is considered during the covariance computation and naturally reflected in the resulting posterior, which then can be used to guide the search for a robust optimum(Sec. 3.1). To further accelerate the posterior inference, we employ Nystrom approximation to stabilize the MMD estimation and reduce its space complexity (Sec. 3.2).

### Modeling the Uncertain Inputs

Assume \(P_{x}_{}\) are a set of distribution densities over \(^{d}\), representing the distributions of the uncertain inputs. We are interested in building a GP surrogate over the probability space \(\), which requires to measure the difference between the uncertain inputs.

To do so, we turn to the Integral Probabilistic Metric (IPM) . The basic idea behind IPM is to define a distance measure between two distributions \(P\) and \(Q\) as the supremum over a class of functions \(\) of the absolute expectation difference:

\[d(P,Q)=_{g}|_{u P}g(u)-_{v Q}g( v)|,\] (6)

where \(\) is a class of functions that satisfies certain conditions. Different choices of \(\) lead to various IPMs. For example, if we restrict the function class to be uniformly bounded in RKHS we can get the MMD , while a Lipschitz-continuous \(\) realizes the Wasserstein distance .

In this work, we choose MMD as the distance measurement for the uncertain inputs because of its intrinsic connection with distance measurement in RKHS. Given a characteristic kernel \(k:^{d}^{d}\) and associate RKHS \(_{k}\), define the mean map \(:_{k}\) such that \((P),g=_{P}[g], g_{k}\). The MMD between \(P,Q\) is defined as:

\[(P,Q)=_{||g||_{k} 1}[_{u P}g(u)-_{v  Q}g(v)]=||_{P}-_{Q}||,\] (7)

Without any additional assumption on the input distributions, except we can get \(m\) samples \(\{u_{i}\}_{i=1}^{m},\{v_{i}\}_{i=1}^{m}\) from \(P,Q\) respectively, MMD can be empirically estimated as follows :

\[^{2}(P,Q)_{1 i,j m,i j}( k(u_{i},u_{j})+k(v_{i},v_{j}))-}_{1 i,j m}k(u_{i},v _{j}),\] (8)

To integrate MMD into the GP surrogate, we design an MMD-based kernel over \(\) as follows:

\[(P,Q)=(-^{2}(P,Q)),\] (9)

with a learnable scaling parameter \(\). This is a valid kernel, and universal w.r.t. \(C()\) under mild conditions (see Theorem 2.2, ). Also, it is worth to mention that, to compute the GP posterior, we only need to sample \(m\) points from the input distributions, but do not require their corresponding function values.

With the MMD kernel, our surrogate model places a prior \((0,(P_{x},P_{x^{}}))\) and obtain a dataset \(_{n}=\{(_{i},y_{i})|_{i} P_{x_{i}},i=1,2,...,n\}\). The posterior is Gaussian with mean and variance:

\[_{n}(P_{*}) =}_{n}(P_{*})^{T}(}_{n}+^{2 })^{-1}_{n}\] (10) \[_{n}^{2}(P_{*}) =(P_{*},P_{*})-}_{n}(P_{*})^{T}(}_{n}+^{2})^{-1}}_{n}(P_{*}),\] (11)

where \(_{n}:=[y_{1},,y_{n}]^{T}\), \(}_{n}(P_{*}):=[(P_{*},P_{x_{1}}),,(P_{*},P_ {x_{n}})]^{T}\) and \([}_{n}]_{ij}=(P_{x_{i}},P_{x_{j}})\).

### Boosting posterior inference with Nystrom Approximation

To derive the posterior distribution of our robust GP surrogate, it requires estimating the MMD between each pair of inputs. Gretton _et al._ prove the empirical estimator in Eq. 8 approximates MMD in a bounded and asymptotic way . However, the sampling size \(m\) used for estimation greatly affects the approximation error and insufficient sampling leads to a high estimation variance(ref. Figure 2(a)).

Such an MMD estimation variance causes numerical instability of the covariance matrix and propagates into the posterior distribution and acquisition function, rendering the search for optimal query point a challenging task. Figure 2(b) gives an example of MMD-GP posterior with insufficient samples, which produces a noisy acquisition function and impedes the search of optima. Increasing the sampling size can help alleviate this issue. However, the computation and space complexities of the empirical MMD estimator scale quadratically with the sampling size \(m\). This leaves us with a dilemma that insufficient sampling results in a highly-varied posterior while a larger sample size can occupy significant GPU memory and reduce the ability for parallel computation.

To reduce the space and computation complexity while retaining a stable MMD estimation, we resort to the Nystrom approximation . This method alleviates the computational cost of kernel matrix by randomly selecting \(h\) subsamples from the \(m\) samples(\(h m\)) and computes an approximated matrix via \(=K_{mh}K_{h}^{+}K_{mh}^{T}\). Combining this with the MMD definition gives its Nystrom estimator:

\[^{2}(P,Q) =_{u,u^{} P} P[k(u,u^{})]+ _{v,v^{} Q} Q[k(v,v^{})]-2_{u,v P } Q[k(u,v)]\] \[}_{m}^{T}U_{m}+}_{m}^{T}V_{m}-}_{m}^{T}W _{m}\] \[}_{m}^{T}U_{mh}U_{h}^{+}U_{mh}^{T }_{n}+}_{m}^{T}V_{mh}V_{h}^{+}V_{mh}^{T} _{m}-}_{m}^{T}W_{mh}W_{h}^{+}W_{mh}^{T} _{m}\] (12)

where \(U=K(,^{})\), \(V=K(,^{})\), \(W=K(,)\) are the kernel matrices, \(_{m}\) represents a m-by-1 vector of ones, \(m\) defines the sampling size and \(h\) controls the sub-sampling size. Note that this Nystrom estimator reduces the space complexity of posterior inference from \(O(MNm^{2})\) to \(O(MNmh)\), where \(M\) and \(N\) are the numbers of training and testing samples, \(m\) is the sampling size for MMD estimation while \(h m\) is the sub-sampling size. This can significantly boost the posterior inference of robust GP by allowing more inference to run in parallel on GPU.

## 4 Theoretical Analysis

Assume \(x^{d}\), and \(P_{x}_{}\) are a set of distribution densities over \(^{d}\), representing the distribution of the noisy input. Given a characteristic kernel \(k:^{d}^{d}\) and associate RKHS \(_{k}\), we define the mean map \(:_{k}\) such that \((P),g=_{P}[g], g_{k}\).

We consider a more general case. Choosing any suitable functional \(L\) such that \((P,P^{}):=L(_{P},_{P^{}})\) is a positive-definite kernel over \(\), for example the linear kernel \(_{P},_{P^{}}_{k}\) and radial kernels \((-\|_{P}-_{P^{}}\|_{k}^{2})\) using the MMD distance as a metric. Such a kernel \(\) is associated with a RKHS \(_{}\) containing functions over the space of probability measures \(\).

One important theoretical guarantee to conduct \(\) model is that our object function can be approximated by functions in \(_{}\), which relies on the universality of \(\). Let \(C()\) be the class of continuous functions over \(\) endowed with the topology of weak convergence and the associated Borel \(\)-algebra, and we define \( C()\) such that

\[(P):=_{P}[f], P,\]

which is just our object function, For \(\) be radial kernels, it has been shown that \(\) is universal w.r.t \(C()\) given that \(\) is compact and the mean map \(\) is injective [11; 22]. For \(\) be linear kernel which is not universal, it has been shown in Lemma 1,  that \(_{}\) if and only if \(f\) and further \(\|\|_{}=\|f\|_{k}\). Thus, in the remain of this chapter, we may simply assume \(_{}\).

Suppose we have an approximation kernel function \((P,Q)\) near to the exact kernel function \((P,Q)\). The mean \(_{n}(p_{*})\) and variance \(_{n}^{2}(p_{*})\) are approximated by

\[_{n}(P_{*}) =}_{n}(P_{*})^{T}(}_{n}+ ^{2})^{-1}_{n}\] (13) \[_{n}^{2}(P_{*}) =(P_{*},P_{*})-}_{n}(P_{*})^{T}( {}_{n}+^{2})^{-1}}_{n}(P_{*}),\] (14)

where \(_{n}:=[y_{1},,y_{n}]^{T}\), \(}_{n}(P_{*}):=[(P_{*},P_{1}),,(P_{*},P_{n})]^{T}\) and \([}_{n}]_{ij}=(P_{i},P_{j})\).

The maximum information gain corresponding to the kernel \(\) is denoted as

\[_{n}:=_{_{}:||=n} (_{n};}_{n}|)=( +^{-2}}_{n}),\]

Denote \(e(P,Q)=(P,Q)-(P,Q)\) as the error function when estimating the kernel \(\). We suppose \(e(P,Q)\) has an upper bound with high probability:

**Assumption 1**.: _For any \(>0\), \(P,Q_{}\), we may choose an estimated \((P,Q)\) such that the error function \(e(P,Q)\) can be upper-bounded by \(e_{}\) with probability at least \(1-\), that is, \((|e(P,Q)| e_{})>1-\)._

**Remark.** Note that this assumption is standard in our case: we may assume \(_{x}\|\|_{k}\), where \(\) is the feature map corresponding to the \(k\). Then when using empirical estimator, the error between \(_{}\) and MMD is controlled by \(4}\) with probability at least \(1-\) according to Lemma E.1, . When using the Nystrom estimator, the error has a similar form as the empirical one, and under mild conditions, when \(h=O((m))\), we get the error of the order \(O(m^{-1/2}(1/))\) with probability at least \(1-\). One can check more details in Lemma 1.

Now we restrict our Gaussian process in the subspace \(_{}=\{P_{x},x\}\). We assume the observation \(y_{i}=f(x_{i})+_{i}\) with the noise \(_{i}\). The input-induced noise is defined as \( f_{p_{x_{i}}}:=f(x_{i})-_{P_{x_{i}}}[f]=f(x_{i})-(P_{x _{i}})\). Then the total noise is \(y_{i}-_{P_{x_{i}}}[f]=_{i}+ f_{p_{x_{j}}}\). We can state our main result, which gives a cumulative regret bound under inexact kernel calculations.

**Theorem 1**.: _Let \(>0,f_{k},\) and the corresponding \(\|\|_{k} b,_{x}|f(x)|=M\). Suppose the observation noise \(_{i}=y_{i}-f(x_{i})\) is \(_{}\)-sub-Gaussian, and thus with high probability \(|_{i}|<A\) for some \(A>0\). Assume that both \(k\) and \(P_{x}\) satisfy the conditions for \( f_{P_{x}}\) to be \(_{E}\)-sub-Gaussian, for a given \(_{E}>0\). Then, under Assumption 1 with \(>0\) and corresponding \(e_{}\), setting \(^{2}=1+\), running Gaussian Process with acquisition function_

\[(x|_{n})=_{n}(P_{x})+_{n}_{n}(P_{x})\] (15)

_where \(_{n}=\)\((b+^{2}+_{}^{2}}_{n}+1- )}),\)_

_we have that the uncertain-inputs cumulative regret satisfies:_

\[_{n} O(_{n}(_{n}-)}+ n^{2}_{n}-)e_{}}+n^{3}e_{})\] (16)

_with probability at least \(1--n\). Here \(_{n}=_{t=1}^{n}_{t}\), and \(_{t}=_{x}_{P_{x}}[f]-_{P_{x_{t} }}[f]\)_

The proof of our main theorem 1 can be found in appendix B.3.

The assumption that \(_{i}\) is \(_{}\)-sub-Gaussian is standard in \(\) fields. The assumption that \( f_{P_{x}}\) is \(_{E}\)-sub-Gaussian can be met when \(P_{x}\) is uniformly bounded or Gaussian, as stated in Proposition 3, . Readers may check the definition of sub-Gaussian in appendix, Definition 1.

To achieve an regret of order \(_{n} O(_{n})\), the same order as the exact Improved \(\) regret (23), and ensure this with high probability, we need to take \(=O(/n)\), \(e_{}=O(n^{-}_{n}(_{n}^{-2} n ^{-}))\), and this requires a sample size \(m\) of order \(O(n^{5}_{n}^{-2}(_{n}^{4} n)(n))\) for MCMC approximation, or with a same sample size \(m\) and a subsample size \(h\) of order \(O(n^{+}_{n}^{-1-}(_{n}^{2} n^{ }))\) for Nystrom approximation with some \(>0\). Note that (16) only offers an upper bound for cumulative regret, in real applications the calculated regret may be much smaller than this bound, as the approximation error \(e_{}\) can be fairly small even with a few samples when the input noise is relatively weak.

To analysis the exact order of \(_{n}\) could be difficult, as it is influenced by the specific choice of embedding kernel \(k\) and input uncertainty distributions \(P_{x_{i}},x_{i}\). Nevertheless, we can deduce the following result for a wide range of cases, showing that cumulative regret is sub-linear under mild conditions. One can check the proof in appendix B.4.

**Theorem 2** (Bounding the Maximum information gain).: _Suppose \(k\) is \(r\)-th differentiable with bounded derivatives and translation invariant, i.e., \(k(x,y)=k(x-y,0)\). Suppose the input uncertainty is i.i.d., that is, the noised input density satisfies \(P_{x_{i}}(x)=P_{0}(x-x_{i}), x_{i}\). Then if the space \(\) is compact in \(^{d}\), the maximum information gain \(_{n}\) satisfies_

\[_{n}=O(n^{}(n)).\]

_Thus, when \(r>d(d+1)\), the accumulate regret is sub-linear respect to \(n\), with sufficiently small \(e_{}\)._

## 5 Evaluation

In this section, we first experimentally demonstrate AIRBO's ability to model uncertain inputs of arbitrary distributions, then validate the Nystrom-based inference acceleration for GP posterior, followed by experiments on robust optimization of synthetic functions and real-world benchmark.

### Robust Surrogate

**Modeling arbitrary uncertain inputs**: We demonstrate MMDGP's capabilities by employing an RKHS function as the black-box function and randomly selecting 10 samples from its input domain. Various types of input randomness are introduced into the observation and produce training datasets of \(=\{(x_{i},f(x_{i}+_{i}))|_{i} P_{x_{i}}\}_{i=1}^{10}\) with different \(P_{x}\) configurations. Figure 1(a) and 1(b) compare the modeling results of a conventional GP and MMDGP under a Gaussian input uncertainty \(P_{x}=(0,0.01^{2})\). We observe that the GP model appears to overfit the observed samples without recognizing the input uncertainty, whereas MMDGP properly incorporates the input randomness into its posterior.

To further examine our model's ability under complex input uncertainty, we design the input distribution to follow a beta distribution with input-dependent variance: \(P_{x}=beta(=0.5,=0.5,=0.9( 4 x+1))\). The MMDGP posterior is shown in Figure 1(c). As the input variance \(\) changes along \(x\), inputs from the left and right around a given location \(x_{i}\) yield different MMD distances, resulting in an asymmetric posterior (_e.g._, around \(x=0.05\) and \(x=0.42\)). This suggests that MMDGP can precisely model the multimodality and asymmetry of the input uncertainty.

Moreover, we evaluated MMDGP using a step-changing Chi-squared distribution \(P_{x}=^{2}(g(x),=0.01)\), where \(g(x)=0.5\) if \(x[0,0.6]\), and \(g(x)=7.0\) otherwise. This abrupt change in \(g(x)\) significantly alters the input distribution from a sharply peaked distribution to a flat one with a long tail. Figure 1(d) illustrates that our model can accurately capture this distribution shape variation, as evidenced by the sudden posterior change around \(x=0.6\). This demonstrates our model can thoroughly quantify the characteristics of complex input uncertainties.

**Comparing with the other surrogate models:** We also compare our model with the other surrogate models under the step-changing Chi-squared input distribution. The results are reported in Figure 7 and they demonstrate our model outperforms obviously under such a complex input uncertainty (see Appendix D.1 for more details)

### Accelerating the Posterior Inference

**Estimation variance of MMD:** We first examine the variance of MMD estimation by employing two beta distributions \(P=beta(=0.4,=0.2,=0.1)\) and \(Q=beta(=0.4,=0.2,=0.1)+c\), where \(c\) is an offset value. Figure 2(a) shows the empirical MMDs computed via Eq. 8 with varying sampling sizes as \(Q\) moves away from \(P\). We find that a sampling size of 20 is inadequate, leading to high estimation variance, and increasing the sampling size to 100 stabilizes the estimation.

We further utilize this beta distribution \(P\) as the input distribution and derive the MMDGP posterior via empirical estimator in Figure 2(b). Note that the MMD instability caused by inadequate sampling subsequently engenders a fluctuating posterior and culminates in a noisy acquisition function, which prevents the acquisition optimizer (_e.g._, L-BFGS-B in this experiment) from identifying the optima. Although Figure 2(c) shows that this issue can be mitigated by using more samples during empirical

Figure 2: Modeling results under different types of input uncertainties.

MMD estimation, it is crucial to note that a larger sampling size significantly increases GPU memory usage because of its quadratic space complexity of \(O(MNm^{2})\) (\(M\) and \(N\) are the sample number of training and testing, \(m\) is the sampling size for MMD estimation). This limitation severely hinders parallel inference for multiple samples and slows the overall speed of posterior computation.

Table 1 summarizes the **inference time** of MMDGP posteriors at 512 samples with different sampling sizes. We find that, for beta distribution defined in this experiment, the Nystrom MMD estimator with a sampling size of 100 and sub-sampling size of 10 already delivers a comparable result to the empirical estimator with 100 samples (as seen in the acquisition plot of Figure (d)d). Also, the inference time is reduced from 8.117 to 0.78 seconds by enabling parallel computation for more samples. For the cases that require much more samples for MMD estimation (_e.g._, the input distribution is quite complex or high-dimensional), this Nystrom-based acceleration can have a more pronounced impact.

**Effect of Nystrom estimator on optimization:** To investigate the effect of Nystrom estimator on optimization, we also perform an ablation study in Appendix D.2, the results in Figure 8 suggest that Nystrom estimator slightly degrades the optimization performance but greatly improves the inference efficiency.

### Robust Optimization

**Experiment setup:** To experimentally validate AIRBO's performance, we implement our algorithm 1 based on BoTorch  and employ a linear combination of multiple rational quadratic kernels  to compute the MMD as Eq. 9. We compare our algorithm with several baselines: 1) **uGP-UCB** is a closely related work that employs an integral kernel to model the various input distributions. It has a quadratic inference complexity of \(O(MNm^{2})\), where \(M\) and \(N\) are the sample numbers of the training and testing set, and \(m\) indicates the sampling size of the integral kernel. 3)**GP-UCB** is the standard GP with UCB acquisition, which represents a broad range of existing methods that

  
**Method** & Sampling Size & Sub-sampling Size & **Inference Time (seconds)** & **Batch Size (samples)** \\  Empirical & 20 & - & 1.143 \(\) 0.083 & 512 \\ Empirical & 100 & - & 8.117 \(\) 0.040 & 128 \\ Empirical & 1000 & - & 840.715 \(\) 2.182 & 1 \\ Nystrom & 100 & 10 & 0.780 \(\) 0.001 & 512 \\ Nystrom & 1000 & 100 & 21.473 \(\) 0.984 & 128 \\   

Table 1: Performance of Posterior inference for 512 samples.

Figure 3: The posterior derived from the empirical and Nyström MMD approximators with varying sampling sizes.

focus on non-robust optimization. 3) **SKL-UCB** employs symmetric Kullback-Leibler divergence to measure the distance between the uncertain inputs . Its closed-form solution only exists if the input distributions are the Gaussians. 4) **ERBF-UCB** is the robust GP with the expected Radial Basis Function kernel proposed in . It computes the expected kernel under input distribution using the Gaussian integrals. Assuming the input distributions are sub-Gaussians, this method can efficiently find the robust optimum. Since all the methods use UCB acquisition, we simply distinguish them by their surrogate names in the following tests.

At the end of the optimization, each algorithm needs to decide a final _outcome_\(x_{n}^{r}\), perceived to be the robust optimum under input uncertainty at step \(n\). For a fair comparison, we employ the same outcome policy across all the algorithms: \(x_{n}^{r}=_{x_{n}}_{*}(x)\), where \(_{*}(x)\) is the posterior mean of robust surrogate at \(x\) and \(_{n}=\{(x_{i},f(x_{i}+_{i}))|_{i} P_{x_{i}}\}\) are the observations so far. The optimization performance is measured in terms of _robust regret_ as follows:

\[r(x_{n}^{r})=_{ P_{x^{*}}}[f(x^{*}+)]-_{  P_{x_{n}^{r}}}[f(x_{n}^{r}+)],\] (17)

where \(x^{*}\) is the global robust optimum and \(x_{n}^{r}\) represents the outcome point at step \(n\). For each algorithm, we repeat the optimization process 12 times and compare the average robust regret.

**1D RKHS function:** We begin the optimization evaluation with an RKHS function that is widely used in previous BO works . Figure 3(a) shows its exact global optimum resides at \(x=0.892\) while the robust optimum is around \(x=0.08\) when the inputs follow a Gaussian distribution \((0,0.01^{2})\). According to Figure 3(b), all the robust BO methods work well with Gaussian uncertain inputs and efficiently identify the robust optimum, but the GP-UCB stagnates at a local optimum due to its neglect of input uncertainty. Also, we notice the regret of our method decrease slightly slower than uGP works in this low-dimensional and Gaussian-input case, but later cases with higher dimension and more complex distribution show our method is more stable and efficient.

**1D double-peak function:** To test with more complex input uncertainty, we design a blackbox function with double peaks and set the input distribution to be a multi-modal distribution \(P_{x}=beta(=0.4,=0.2,=0.1)\). Figure 3(c) shows the blackbox function (black solid line) and the corresponding function expectations estimated numerically via sampling from the input distribution (_i.e._, the colored lines). Note the true robust optimum is around \(x=0.251\) under the beta distribution, but an erroneous location at \(x=0.352\) may be determined if the input uncertainty is incorrectly presumed to be Gaussian. This explains the results in Figure 3(d): the performance of SKL-UCB and ERBF-UCB are sub-optimal due to their misidentification of inputs as Gaussian variables, while our method accurately quantifies the input uncertainty and outperforms the others.

**10D bumped-bowl function:** we also extend our evaluation to a 10D bumped-bowl function  under a concatenated circular distribution. Figure 9 demonstrates AIRBO scales efficiently to high dimension and outperforms the others under complex input uncertainty(see Appendix D.3).

**Robust robot pushing:** To evaluate AIRBO in a real-world problem, we employ a robust robot pushing benchmark from , in which a ball is placed at the origin point of a 2D space and a robot learns to push it to a predefined target location \((g_{x},g_{y})\). This benchmark takes a 3-dimensional input \((r_{x},r_{y},r_{t})\), where \(r_{x},r_{y}[-5,+5]\) are the 2D coordinates of the initial robot location and \(r_{t}\) controls the push duration. We set four targets in separate quadrants, _i.e._, \(g1=(-3,-3),g_{2}=(-3,3),g_{3}=(4.3,4.3)\), and a "twin" target at \(g_{3}^{}=(5.1,3.0)\), and describe the input uncertainty via a two-component Gaussian Mixture Model (defined in Appendix D.4). Following , this blackbox benchmark outputs the minimum distance to these 4 targets under squared and linear distances: \(loss=(d^{2}(g_{1},l),d(g_{2},l),d(g_{3},l),d(g_{3}^{},l))\), where \(d(g_{i},l)\) is the Euclidean distance between the ball's ending location \(l\) and the \(i\)-th target. This produces a loss landscape as

Figure 4: Robust optimization results on synthetic functions.

shown in Figure 4(a). Note that \(g_{2}\) is a more robust target than \(g_{1}\) because of its linear-form distance while pushing the ball to quadrant I is the best choice as the targets, \(g_{3}\) and \(g_{3}^{}\), match the dual-mode pattern of the input uncertainty. According to Figure 4(b), our method obviously outperforms the others because it efficiently quantifies the multimodal input uncertainty. This can be further evidenced by the push configurations found by different algorithms in Figure 6, in which each dot represents the robot's initial location and its color represents the push duration. We find that AIRBO successfully recognizes the targets in quadrant I as an optimal choice and frequently pushes from quadrant III to quadrant I. Moreover, the pushes started close to the origin can easily go far away under input variation, so our method learns to push the ball from a corner with a long push duration, which is more robust in this case.

## 6 Discussion and Conclusion

In this work, we generalize robust Bayesian Optimization to an uncertain input setting. The weight-space interpretation of GP inspires us to empower the GP kernel with MMD and build a robust surrogate for uncertain inputs of arbitrary distributions. We also employ the Nystrom approximation to boost the posterior inference and provide theoretical regret bound under approximation error. The experiments on synthetic blackbox function and benchmarks demonstrate our method can handle various input uncertainty and achieve state-of-the-art optimization performance.

There are several interesting directions that worth to explore: though we come to current MMD-based kernel from the weight-space interpretation of GP and the RKHS realization of MMD, our kernel design exhibits a deep connection with existing works on kernel over probability measures [22; 11]. Along this direction, as our theoretic regret analysis in Section 4 does not assume any particular form of kernel and the Nystrom acceleration can also be extended to the other kernel computation, it is possible that AIRBO can be further generalized to a more rich family of kernels. Moreover, the MMD used in our kernel is by no means limited to its RKHS realization. In fact, any function class \(\) that comes with uniform convergence guarantees and is sufficiently rich can be used, which renders different realizations of MMD. With proper choice of function class \(\), MMD can be expressed as the Kolmogorov metric or other Earth-mover distances . It is also interesting to extend AIRBO with the other IPMs.

## 7 Acknowledgements

We sincerely thank Yanbin Zhu and Ke Ma for their help on formulating the problem. Also, a heartfelt appreciation goes to Lu Kang for her constant encouragement and support throughout this work.

Figure 5: Robust optimization of the robot push problem.

Figure 6: The robot’s initial locations and push times found by different algorithms