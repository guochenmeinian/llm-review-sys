# Universal Rates for Active Learning

Steve Hanneke

Purdue University

steve.hanneke@gmail.com

&Amin Karbasi

Yale University

amin.karbasi@yale.edu

&Shay Moran

Technion, Google Research

smoran@technion.ac.il

&Grigoris Velegkas

Yale University

grigoris.velegkas@yale.edu

###### Abstract

In this work we study the problem of _actively_ learning binary classifiers from a given concept class, i.e., learning by utilizing _unlabeled_ data and submitting targeted _queries_ about their labels to a domain expert. We evaluate the quality of our solutions by considering the _learning curves_ they induce, i.e., the rate of decrease of the misclassification probability as the number of label queries increases. The majority of the literature on active learning has focused on obtaining _uniform_ guarantees on the error rate which are only able to explain the upper envelope of the learning curves over families of different data-generating distributions. We diverge from this line of work and we focus on the _distribution-dependent_ framework of universal learning whose goal is to obtain guarantees that hold for any fixed distribution, but do not apply uniformly over all the distributions. We provide a complete characterization of the optimal learning rates that are achievable by algorithms that have to specify the number of _unlabeled_ examples they use ahead of their execution. Moreover, we identify combinatorial complexity measures that give rise to each case of our tetrachotomic characterization. This resolves an open question that was posed by Balcan et al. (2010). As a byproduct of our main result, we develop an active learning algorithm for _partial_ concept classes that achieves exponential learning rates in the uniform setting.

## 1 Introduction

The most prototypical type of learning is that of _supervised_ learning, where an algorithm is given as input \(n\)_labeled_ data points sampled i.i.d. from some unknown distribution and the goal is to output a function that has low probability of misclassifying new data from the same distribution. One caveat with this passive model of learning is that it fails to capture the settings in which _unlabeled_ data is easily accessible, but obtaining their labels is costly. A natural example that fits this description is that of webpage classification. It is easy for any web crawler to collect information about billions of different webpages in a very short amount of time, however understanding which category a webpage belongs to usually requires human feedback. Perhaps the most commonly used way to model this problem is through the _active_ learning framework in which the learner is given access to a large stream of unlabeled data and a budget of \(n\) queries that it can submit to a domain expert in order to obtain the label of some datapoint. The learner's goal is to submit queries for the labels of the most informative examples, and, as a result, eliminate some redundancy in the information content of labeled data.

In this paper we study the optimal learning rates that are achievable by an active learning algorithm. In the passive learning setting, it is common to measure the quality of an algorithm by its _learning curve_, i.e., plotting the decay of its error rate as the number of training examples increases. In contrast, in theactive learning setting, the resource we are interested in is the number of label queries the algorithm requests, so it is natural to consider the rate of decay of the misclassification probability as the number of queries \(n\) increases. Most of the prior works on active learning have focused on obtaining _uniform_ guarantees on the error rate, i.e., guarantees that hold uniformly over the data-generating distributions. In this work we follow a different path and we view the problem through the lens of _universal_ rates that was recently introduced by Bousquet et al. (2021). In this framework we are aiming for guarantees that hold for all distributions, but they do not hold uniformly over them. In other words, we allow for _distribution-dependent_ constants in the error rate. To make the distinction between uniform and universal rates clear, we first recall what uniform learnability of a hypothesis class \(\) means. We say that \(\) is uniformly learnable at rate \(R(n)\) if there exists a learning rule \(_{n}\) such that

\[ C,c>0() [_{}(_{n})] C R(c  n), n\,.\]

The above expression states that there exists a learning rule \(_{n}\) and _distribution-independent_ constants such that for all realizable distributions the expected error rate of the classifier is at most \(C R(c n)\). The difference in the definition of universal learnability is that we swap the order of the quantifiers. To be more precise, we say that a class \(\) is universally learnable at rate \(R(n)\) if there exists a learning rule \(_{n}\) such that

\[() C,c> 0[_{}(_{n})] C R(c n),  n\,.\]

Note that in the above definition the constants \(c,C\) are _distribution-dependent_. As is evident from our main result and from prior results in universal learning (Bousquet et al., 2021; Hanneke et al., 2022; Kalavasis et al., 2022; Bousquet et al., 2022; Hanneke et al., 2023) this change in the definition affects the landscape of the optimal learning rates significantly.

### Related Work

Active Learning.There has been a very long line of work deriving theoretical guarantees for active learning, both in the realizable and the agnostic setting (Cohn et al., 1994; Dasgupta, 2005; Balcan et al., 2006; Hanneke, 2007b, a; Dasgupta et al., 2007; Hanneke, 2009; Balcan et al., 2009, 2010; Hanneke, 2012, 2014; Wiener et al., 2015; Hanneke and Yang, 2015; Beygelzimer et al., 2016). As we alluded to before, most of these works focus on obtaining _minmax_ guarantees, i.e., the bounds they provide hold in the worst case over a family of distributions. To be more precise, while many of these results have distribution-dependent guarantees, they are typically expressed in a way that aims to match a lower bound on the minmax performance over a family o distributions, with respect to some parameter, like the disagreement coefficient. For these reasons the results in these works do not capture the full spectrum of universal rates. We also remark that there are a few works that do study universal rates, e.g. Balcan et al. (2010); Hanneke (2012); Yang and Hanneke (2013), but none of them have derived a complete characterization of the optimal rates.

Universal Rates.The study of universal learning rates was put forth in the seminal work of Bousquet et al. (2021) who derived a complete characterization of the optimal rates in the supervised learning setting. Later, Kalavasis et al. (2022) extended these result to the multiclass setting, with a bounded number of classes, and Hanneke et al. (2023) improved upon this result by characterizing multiclass classification with an infinite number of labels. Subsequently, the work of Bousquet et al. (2022) derived more fine-grained results for binary classification compared to Bousquet et al. (2021). The work that is most closely related to ours is Hanneke et al. (2022) which derives a complete characterization of the optimal learning rates in a very general interactive learning setting. In that setting, the learner is allowed to submit arbitrary binary valued queries about the unlabeled data. We provide a detailed comparison between our results and theirs in Section 1.5. Very recently, Attias et al. (2024) studied universal rates in the context of regression.

Partial Concept Classes.The vast majority of the literature in learning theory has focused on _total_ concept classes, i.e., classes that consist of functions that are defined everywhere on the instance domain. Recently, Alon et al. (2021) proposed a learning theory of _partial_ concept classes, i.e., classes that consist of functions that can be _undefined_ on some parts of the instance domain. Later, Kalavasis et al. (2022) extended some of the results to the multiclass setting, with a finite number of labels. Recently, Cheung et al. (2023) studied partial concept classes in the context of online learning and they showed that there are such classes that are online learnable but none of their "extensions" to total concept classes is online learnable. The advantage of partial concepts is that they provide a convenient way to express _data-dependent_ constraints. En route of obtaining our main result, we design active learning algorithms for partial concept classes. For a more detailed discussion about partial concepts we refer the reader to Appendix A.2.

### Formal Setting

Learning Model.We now present formally the learning setting that we consider in this work. There is a _domain_\(\), which we assume to be a Polish space, and a concept class \(\{0,1\}^{}\), which satisfies standard measurability assumptions (see Definition A.1). We define a _classifier_\(h:\{0,1\}\) to be a universally measurable function and its _error rate_ is defined as \(_{}(h):=[(x,y):h(x) y]\), where \(\) is the data-generating distribution over \(\{0,1\}\). When \(\) is clear from the context we might drop the subscript \(\) in \(_{}(h)\). We call \(\)_realizable_ with respect to the hypothesis class \(\) if \(_{h}_{}(h)=0\). We denote by \(_{}\) be the marginal distribution of \(\) on \(\).

Active Learning Model.We define an _active learning algorithm_ to be a sequence of universally measurable functions which, given access to a stream of _unlabeled_ data points from \(\) that are drawn i.i.d. from \(_{}\) and a label query budget \(n\), output a classifier \(_{n}:\{0,1\}\). In this work we consider a _non-adaptive_ active learning model, with respect to the _unlabeled_ data. In particular, the learning algorithm needs to specify a function \(u:\) so that \(u(n)\) is the number of _unlabeled_ points it observes and \(n\) is the number of points for which it can request the label. The number \(u(n)\) is specified _before_ the execution of the algorithm and cannot be modified based on the realization of the unlabeled sequence or the answers that it gets for the labels of the points it queries. We place no bound whatsoever on the function \(u()\). Also, the algorithm can only request the labels of points it has observed and not arbitrary points from \(\). We emphasize that the label requests that the algorithm makes can be adaptive, and can depend on answers to previous label queries. To the best of our knowledge, the active learning algorithms that have been proposed in the literature either fit into this model or they can be modified to satisfy the non-adaptivity restriction with negligible performance loss.

Learning Rates.We now define formally what it means for an algorithm to achieve a learning rate \(R(n)\) in the _universal learning_ model. We adopt the definition of Bousquet et al. (2021).

**Definition 1.1** (Learning Rates (Bousquet et al., 2021)).: _Fix a concept class \(\), and let \(R:,R(n)}{{}}0\) be a rate function, where \(n\) is the label query budget of the learner._

* \(\) _is learnable at rate_ \(R\) _if there is a learning algorithm_ \(_{n}\) _such that for every realizable distribution_ \(\)_, there exist_ \(c,C\) _for which_ \([(_{n})] CR(cn), n\)_._
* \(\) _is not learnable at rate faster than_ \(R\) _if for all learning algorithms_ \(_{n}\) _there exists a realizable distribution_ \(\) _and_ \(c,C\) _for which_ \([(_{n})] CR(cn)\)_, for infinitely many_ \(n\)_._
* \(\) _is learnable with optimal rate_ \(R\) _if it is learnable at rate_ \(R\) _and it is not learnable at rate faster than_ \(R\)_._
* \(\) _admits arbitrarily fast rates if for all rate functions_ \(R\)_, it is learnable at rate_ \(R\)_._
* \(\) _requires arbitrarily slow rates if for all rate functions_ \(R\)_, it is not learnable at rate faster than_ \(R\)_._

Combinatorial Measures.We now define some combinatorial complexity measures that our characterization relies on. To make the presentation easier to follow, we provide informal definitions. For the formal ones, we refer the reader to Appendix A.3. We first describe the _Littlestone tree_ that was introduced by Bousquet et al. (2021).

**Definition 1.2** (Littlestone Tree, Informal (see Definition A.8) (Bousquet et al., 2021)).: _A Littlestone tree for \(\{0,1\}^{}\) is a complete binary tree of depth \(d\) whose nodes are labeled by elements of \(\) and the edges to the left, right child are labeled by \(0,1\). We require that for every level \(0 n<d\)and every path from the root to a node at level \(n\) there is some \(h\) that realizes this path. We say that \(\) has an infinite Littlestone tree if it has a Littlestone tree of depth \(d=\)._

We underline that this notion can be thought of as an infinite extension of the _Littlestone dimension_(Littlestone, 1988) of \(\). Recall that the Littlestone dimension is defined to be the largest \(d\) for which \(\) has a Littlestone tree of such depth and it is \(\) if one can construct Littlestone trees of arbitrary depth. Crucially, this is not the same as having a _single_ tree whose depth is infinite, so one can see that infinite Littlestone dimension is _not_ the same as having an infinite Littlestone tree.

We next give the definition of the _Vapnik-Chervonenkis-Littlestone tree_ (VCL) that was introduced by Bousquet et al. (2021).

**Definition 1.3** (VCL Tree, Informal (see Definition A.10)(Bousquet et al., 2021)).: _A VCL tree for \(\{0,1\}^{}\) is a complete tree of depth \(d\) such that every level \(0 n<d\) has nodes that are labeled by \(^{n+1}\) with branching factor \(2^{n+1}\) and whose \(2^{n+1}\) edges connecting a node to its children are labeled by the elements of \(\{0,1\}^{n+1}\). We require that for every node at any level \(0 n<d,\) the path from the root to this node is realized by some \(h\). We say that \(\) has an infinite VCL tree if it has a VCL tree of depth \(d=\)._

Intuitively, the VCL tree combines the notions of the Littlestone tree and the VC dimension (Vapnik and Chervonenkis, 1971; Blumer et al., 1989). The differences between the Littlestone tree and the VCL tree are that in the latter the size of the nodes increases linearly with the level and the branching factor increases exponentially, whereas in the former all the nodes are singletons and the branching factor is always two.

We are now ready to introduce a new combinatorial measure which we call the _star tree_.

**Definition 1.4** (Star Tree, Informal (see Definition A.9)).: _A star tree for \(\{0,1\}^{}\) is a complete tree of depth \(d\) such that every level \(0 n<d\) has nodes that are labeled by \((\{0,1\})^{n+1}\) with branching factor \(n+1\) and whose \(n+1\) edges connecting a node to its children are labeled by \(\{0,,n\}.\) The label of the edge indicates the element of the node whose label along the path is flipped. We require that for every node at level \(0 n<d\), the path from the root to this node is realized by \(.\) We say that \(\) has an infinite star star tree if it has a star tree of depth \(d=\)._

Essentially, this definition combines the structure of a Littlestone tree with the notion of the _star number_(Hanneke and Yang, 2015). Every node at level \(n\) consists of \(n+1\)_labeled_ points and there are \(n+1\) edges attached to it. Each edge indicates which of the \(n+1\) points of the labeled node has its label flipped along every path that this edge is part of.

### Main Results

We are now ready to state the main results of this work. Our first main result is a complete characterization of the optimal learning rates that a class \(\) admits in the active learning setting.

**Theorem 1.5**.: _For every concept class \(\) exactly one of the following cases holds._

* \(\) _is actively learnable at arbitrarily fast rates._
* \(\) _is actively learnable at an optimal rate_ \(e^{-n}.\)__
* \(\) _is actively learnable at_ \(o(1/n)\) _rates, but requires rates arbitrarily close to_ \(1/n.\)__
* \(\) _requires arbitrarily slow rates for active learning._

Our next result characterizes exactly when these rates occur by specifying combinatorial complexity measures of \(\) that determine which case of the tetrachtotomy it falls into.

**Theorem 1.6**.: _For every concept class \(\) the following hold._

* _If_ \(\) _does not have an infinite Littlestone tree, then it is learnable at arbitrarily fast rates._
* _If_ \(\) _has an infinite Littlestone tree but does not have an infinite star tree, then it is learnable at optimal rate_ \(e^{-n}.\)__
* _If_ \(\) _has an infinite star tree but does not have an infinite VCL tree, then it is learnable at optimal rate_ \(o(1/n),\) _but requires rates arbitrarily close to_ \(1/n.\)__* _If_ \(\) _has an infinite VCL tree, then it requires arbitrarily slow rates._

We remark that the landscape of the optimal rates looks significantly different compared to the passive setting (Bousquet et al., 2021) and the general interactive learning setting (Hanneke et al., 2022). Our main result answers an open question that was posed in Balcan et al. (2010), which asks for necessary and sufficient conditions for learnability at an exponential rate in the active learning setting.

### Examples

We now present examples of classes that witness each case of our tetrachotomic characterization.

Arbitrarily-fast rates: Bousquet et al. (2021) give examples with no infinite Littlestone tree (e.g., thresholds on the integers, and positive halfspaces on \(^{d}\)), hence learnable at arbitrarily fast rates.

Exponential rates: Famously, threshold classifiers \([a,)\) over \(\) have an infinite Littlestone tree and are actively learnable at exponential rate (even uniformly). A more interesting example is the class of interval classifiers \([a,b]\) on \(\), which (also famously) has uniform rate \(1/n\) for active learning (it has infinite star number), and has an infinite Littlestone tree, but it _has no infinite star tree_: for any choice of \(x\) in the root node, the edge labeling \(x\) as 1 has a version space with star number equal 4 (it is effectively 2 disjoint threshold problems), so the depth of that subtree is bounded. Therefore, by our theory, it is actively learnable at \(e^{-n}\) universal rate (in stark contrast to the uniform rate \(1/n\)).

Sublinear rates: Halfspaces on \(^{d}\) have an infinite star tree but no infinite VCL tree. To construct that star tree, the key observation is that any set in convex position is a star set (Balcan et al., 2010).

Arbitrarily slow rates: Bousquet et al. (2021) provide examples of classes with an infinite VCL tree, such as the class of all clarfisifiers, so these require arbitrarily slow rates in our setting as well.

### Comparison to Supervised Learning and General Interactive Learning Setting

We now compare our characterization to the results of Bousquet et al. (2021) that prove an analogous result in the supervised learning setting. Let us first recall their main result which shows that in this learning model a class is universally learnable at:

* Exponential rate \(e^{-n}\) if and only if it does not have an infinite Littlestone tree.
* Linear rate \(1/n\) if and only if it has an infinite Littlestone tree but does not have an infinite VCL tree.
* Arbitrarily slow rates if and only if it has an infinite VCL tree.

As one can see, our results illustrate the advantage that active learning algorithms have over their supervised counterparts. We underline that the only case where active learning does not offer an improvement compared to the passive setting is when \(\) has an infinite VCL tree.

Let us now discuss the interactive learning model that was considered by Hanneke et al. (2022). In this general model of interaction, the learner is allowed to ask _arbitrary binary queries_ about any subset of the unlabeled data. In particular, these queries include, but are not limited to, label queries, comparison queries, and general membership queries. They show that the optimal rates that any class \(\) admits are the following:

* Arbitrarily fast if and only if it does not have an infinite Littlestone tree.
* Exponential if and only if it has an infinite Littlestone tree but not an infinite VCL tree.
* Arbitrarily slow if and only if it has an infinite VCL tree.

We underline that the algorithm by Hanneke et al. (2022) that achieves arbitrarily fast rates uses only label queries and the number of unlabeled data \(u(n)\) that it uses can be chosen statically prior to the execution of the algorithm. Therefore, this result applies to the setting we consider in our work. Moreover, the lower bounds they provide also apply to our setting since (i) the queries that Hanneke et al. (2022) consider are more general, and (ii) their lower bounds hold even when the learner knows the marginal distribution \(_{}\). As is evident from our main result, the active learning setting provides a richer landscape of optimal rates compared to the general interactive learning setting of Hanneke et al. (2022). In particular, just the absence of an infinite VCL tree for \(\) does not necessarily imply that we can achieve (at least) exponential rates. To get this result, Hanneke et al. (2022) make strong use of these general queries in order to provide an algorithm that has a binary-search flavor and can learn _partial_ concept classes with finite VC dimension at an exponential rate. Our main result shows that such guarantees are not achievable by using only label queries.

### Technical Challenges

The most technically innovative part of our work is the \(o(1/n)\) algorithm. Let us set up some terminology to facilitate our discussion. The _version space_ of a concept class, given a labeled dataset \(S\), is the set of concepts that classify all the elements of \(S\) correctly. Moreover, the _VCL game_ is a Gale-Stewart game defined by Bousquet et al. (2021) that was used in their passive learning algorithm that achieves \(1/n\) universal rate. The original (passive) learner from Bousquet et al. (2021) partitions a portion of the data into some number \(B(n)\) of batches, from which they construct partial concept classes of finite VC dimension by using the batches to play the VCL game against the player's winning strategy, and for each resulting partial concept class they run a separate learner on another portion of data and return a majority vote of their resulting classifiers. The latter part of this strategy _could never work_ in the active learning setting, since the number of batches \(B(n)\) must be an increasing function of \(n\), and applying an active learner for each partial concept class separately would require each to use (nearly) \((n)\) queries (to get the \(o(1/n)\) guarantee there), so the total number of queries would be (nearly) \((B(n)n) n\), violating the label budget \(n\). To resolve this, we ended up completely re-imagining how to use these partial concept classes. Rather than running a separate algorithm for each class, we run a _single_ active learning algorithm, where individual decisions of whether to query involve voting over the partial concept classes. We first extend an algorithm of Hanneke (2012) (for total concepts) to achieve \(o(1/n)\) rate for partial concept VC classes (this required completely re-formulating Hanneke's analysis). The resulting algorithm involves estimating the probability that a random \(k\)-tuple is VC shattered by certain constrained version spaces. We replace this with an estimated average (over a select subset of partial concept classes) of this shattering probability, which we show composes appropriately with the analysis of the algorithm to obtain the \(o(1/n)\) rate. Comparing our work to the general interactive learning setting considered by Hanneke et al. (2022), the main differences are (i) we design a new algorithm that uses only label queries and achieves exponential rates when \(\) does not have an infinite star tree, a combinatorial measure we introduce in our work, (ii) we prove a \(o(1/n)\) lower bound in the setting where \(\) has an infinite star tree, and (iii) we propose a novel active learning algorithm that achieves sublinear rates when \(\) does not have an infinite VCL tree.

## 2 Arbitrarily Fast Rates

As we explained before, the first case of the tetrachotomy in our characterization is a direct implication of the results by Hanneke et al. (2022). To be more precise, they design an algorithm which achieves arbitrarily fast rates using only label queries. In order to do that, they need the number of _unlabeled_ points \(u(n)\) to be an arbitrarily fast increasing function, that, nevertheless, can be specified in a non-adaptive manner prior to the execution of the algorithm. The result is summarized in Theorem 2.1.

**Theorem 2.1** (Hanneke et al. (2022)).: _If \(\) does not have an infinite Littlestone tree it is actively learnable with arbitrarily fast rates._

For completeness, we present their algorithm in Figure 1.

Similarly with the upper bound, the lower bound is an immediate consequence of a result from Hanneke et al. (2022), since the learner can submit more informative queries in their model.

**Theorem 2.2** (Hanneke et al. (2022)).: _If \(\) has an infinite Littlestone tree, then \(\) is not actively learnable at rate faster than exponential \(e^{-n}\). This holds even if \(_{}\) is known to the learner._

## 3 Exponentially Fast Rates

In this section, we prove the second case in the tetrachotomy we have stated, i.e., that \(\) is learnable at an exponential rate if and only if it has an infinite Littlestone tree and it does not have an infinite star tree. Our proof consists of two parts. First, we show that if \(\) does not have an infinite star tree it is learnable at an exponentially fast rate. Then, we show that whenever \(\) has an infinite star tree, the best achievable rate cannot exceed \(o(1/n)\). The omitted details can be found in Appendix C.

### Exponential Rates Algorithm: High-Level Overview

The high-level approach to get the exponential rates algorithm follows the same spirit of the approaches from Bousquet et al. (2021); Hanneke et al. (2022). First, we design an appropriate Gale-Stewart game (cf. Appendix A.2), i.e., a game between a learner and an adversary, that is associated with \(\) in which the learner has a winning strategy if and only if \(\) does not have an infinite star tree. The next step is to show that, in the limit, the winning strategy of the learner gives rise to a _partial_ concept class \(\) that has _finite_ star number (see Definition A.7). Since this result is asymptotic, our approach is to consider several instances of this game, execute them for a finite number of steps, and obtain a partial concept class from each one. Then, we aggregate these classes into a _majority_ class. The intuition is that, with high probability, most of the games will have induced classes whose star number is bounded by a distribution-dependent constant, so then we can show that the majority class will also have bounded star number, and this bound is distribution-dependent. Thus, our task boils down to actively learning a partial concept class whose star number is finite. In order to do that, we extend the approach that Hanneke and Yang (2015) used for total concept classes to the regime of partial classes. We believe that this result could be of independent interest.

### The Star Tree Game

We first outline the Gale-Stewart game we use. Recall that every node of a star tree at depth \(n\) consists of \(n+1\) points along with their labels. There are \(n+1\) edges that connect the node with its children and the label of every edge indicates the point whose label is flipped along any path that uses this edge. Let us now describe the game \(\) that we use in this setting. In every round \( 1\) we have the following interaction between the learner \(_{}\) and the adversary \(_{}\):

* Player \(_{}\) chooses points \((_{},_{})=(_{}^{0},,_{}^{- 1},_{}^{0},,_{}^{-1})^{} \{0,1\}^{}\).
* Player \(_{}\) chooses \(_{}\{0,,-1\}\).
* Player \(_{}\) wins the game in round \(\) if \[_{_{1},_{1},_{1},,_{}, _{},_{}}:=\{h:h( _{s}^{i})=_{s}^{i},&_{s} i\\ h(_{s}^{i})=1-_{s}^{i},&_{s}=i,1 s ,0 i<s\}=.\] (1)

It is easy to see that the winning condition for \(_{}\) is finitely decidable (cf. Appendix A.2), hence \(\) is a Gale-Stewart game. Recall that this means exactly one player between the adversary and the learner has a winning strategy. Using a result regarding the measurability of winning strategies in Gale-Stewart games that was shown by Bousquet et al. (2021) (see Theorem A.3) we can prove the following connection between \(\) and the existence of infinite star trees ( see Appendix C.1 for the proof).

**Lemma 3.1**.: _The class \(\) does not have an infinite star tree if and only if \(_{}\) has a universally measurable winning strategy in \(\)._

The first step in our approach, is to make use of some \((n)\) label queries in order to obtain the labels of \((n)\) many points. The idea these labeled points in order to simulate the Gale-Stewart game we described above (see Appendix C.3 for the details). The main technical issue we need to handle is that we have no control over the number of rounds the game needs in order to terminate. Using ideas that have appeared in the universal learning literature, we use a portion of these labeled points to estimate some number \(_{n}\) so that, with at least some constant probability over the dataset, the game will terminate within \(_{n}\) many rounds. Then, we split the remaining of the labeled dataset into batches of size \(_{n}\) and we run the game on each batch. The outcome of each game gives us a _pattern-avoidance_ function, i.e., a function that takes an input tuples of arbitrarily _labeled_ points and changes the label of one of them so that the resulting labeled tuple is not consistent with the data-generating distribution \(\). In other words, the output of this function could not have been generated by the \(\). A technical complication we need to handle is that we obtain multiple such pattern avoidance functions, some of which are incorrect, but to make the presentation cleaner we explain the idea using a single pattern avoidance function \(_{t^{*}}\) that produces inconsistent labels. The formal setting is handled in Appendix C.4. One way to think about this function is that it provides _data-dependent_ constraints. Thus, it is natural to express such a constraint through a _partial_ concept class. We define

\[=\{f:\{0,1,\}:(x_{1},f(x_{1})),(x_{2 },f(x_{2})),,(x_{t^{*}},f(x_{t^{*}}))(_ {t^{*}}), x_{1},,x_{t^{*}}^{t^{*}}\}.\]Notice that the constraint we have placed on \(\) is satisfied if \(f(x_{i})=\), for some \(i[t^{*}]\). We consider the natural extension of the notion of star sets to the case of partial concept classes, i.e., we say that a labeled set \(S\) with labels in \(\{0,1\}\) is a star set if \(S\) and its adjacent sets \(S^{}\), whose labels are still restricted to be in \(\{0,1\}\), are obtainable using functions from \(\) (see Definition A.7). A key observation is that the star number of \(\) is bounded by \(t^{*}-1\). Another difficulty we need to overcome is that we do not know \(t^{*}\), since it is a random variable that depends on the realized sequence and its distribution might have heavy tails. To make our approach easier to follow, let us first assume that we do know \(t^{*}\)1. Then, our task boils down to actively learning a partial concept class.

### Active Learning of Partial Concept Classes with Finite Star Number

We now present an algorithm that achieves exponential rates when actively learning a partial concept class \(\) that star number \(<\). The idea of our approach is to reduce the problem of actively learning a partial concept to the well-studied problem of actively learning a total concept class. The algorithm is presented in Figure 2. Let us explain the high-level ideas of the algorithm. First, we consider a large enough set of unlabeled data. Our goal is to find their labels using _logarithmically_ many queries. To do that, we consider the uniform distribution over these unlabeled examples. Then, we use an algorithm from Hanneke and Yang (2015) (see Theorem C.1) which guarantees exponential rates when applied to a class with finite star number. Because the underlying distribution on the sample is uniform, with high probability, the algorithm will find the correct labels of all the points. Finally, we feed these labeled examples to the one-inclusion graph algorithm (Theorem A.5) to get the desired result. We are now ready to state our theorem. The proof is postponed to Appendix C.2.

**Theorem 3.2**.: _There exists an active learning algorithm \(\) for a partial concept class \(\) which given a label budget \(n\) and access to unlabeled samples from a realizable distribution \(^{*}\) returns a classifier \(_{n}\) such that \(_{^{*}}[(_{n})] c_{1}e^{- c_{2}n/}\), where \(c_{1},c_{2}\) are absolute numerical constants, and \(,\) is the star number, VC dimension of \(\)._

### Slower than Exponential is Sublinear

The next step in the characterization is to show that if \(\) has an infinite star tree, then it does not admit rates faster than sublinear. The proof starts by picking a random path on the infinite star tree. The target distribution is supported only on nodes of the selected path. Then, given some algorithm \(_{n}\), we distribute the mass of the target probability distribution across the path, potentially skipping some nodes of it, in a way that creates an infinite sequence \(n_{i_{1}},n_{i_{2}},\), so that when the learner has label budget \(n_{i_{j}}\), with some constant probability, it will only observe unlabeled points up to level \(k_{i_{j}}\). Moreover, with at least some constant probability, it will not query the point of that level whose label is flipped along the target path. On that event, it makes a mistake with probability at least \(C p_{i_{j}}/k_{i_{j}}\), where \(C\) is some absolute constant. Our choice of \(p_{i_{j}},k_{i_{j}}\) guarantees that \(R(n_{j})>p_{i_{j}}/k_{i_{j}},\) where \(R()\) is the target sublinear rate function. Finally, we apply Fatou's lemma to get the desired result. For the full proof and the formal theorem statement, we refer the reader to Appendix C.5

## 4 Sublinear Rates

Our approach to achieve sublinear rates in the setting where \(\) does not have an infinite VCL tree shares some high-level ideas with the one in Section 3, but many technical challenges make it significantly more involved. The main obstacle is that there is no active learning algorithm that achieves sublinear rates for VC classes _uniformly_ over all realizable distributions. Recall that in the exponential rates setting, such an algorithm does exist (Hanneke and Yang, 2015). Instead, the sublinear rates algorithm for VC classes from Hanneke (2012) depends on distribution-dependent constants in the sample complexity. The omitted details from this section can be found in Appendix D.

Instead of the star tree Gale-Stewart game that was used to get the exponential rates guarantee, we use the VCL Gale-Stewart game Bousquet et al. (2021) (cf. Figure 6). To be more precise, we use \( n/5\) of the label budget to get the labels of \( n/5\) unlabeled points that come i.i.d. from \(_{}\). Then, we execute the VCL game on \(()\) different batches of size \(()\). Each of these games induces a _partial_ concept class. We show how to obtain a \(\)-dependent bound on the VC dimension that holds for most of these classes. Moreover, we show that for most of these classes the data-generating distribution \(\) is _realizable_. Finally, we design a single active learning algorithm that combines information from all these classes and achieves sublinear learning rates. This algorithm builds upon Hanneke (2012) but is modified to work with partial concept classes instead of total concept classes. This requires a very different analysis and is the most technically involved part of our work.

Let us now explain the main ideas of this algorithm and the challenges behind it. As we mentioned before, the number of queries that the algorithm from Hanneke (2012) needs to achieve the sublinear error rate depends on the underlying data-generating distribution. Thus, we cannot just get a large enough number of unlabeled samples, consider the uniform distribution over them and use the algorithm on this distribution. This is because the learning rate for \(\) would depend on the uniform distribution \(U_{S}\) over the sample \(S\) and not on the data-generating distribution \(\). To illustrate the ideas of the algorithm, we consider five different streams of i.i.d. (unlabeled) data \(S_{1},S_{2},S_{3},S_{4},S_{5}\). For the purposes of the subsequent discussion, we can imagine that these streams have infinite size, but as explained in description of the algorithm, we only need \((n)\) unlabeled points. Let us first explain the use of \(S_{5}\). We use \(n/5\) of our query budget to obtain the labels of the first \(n/5\) points and then we use them to train a _supervised_ learning algorithm from Bousquet et al. (2021) that achieves linear rate \(O(1/n)\). This is used for technical reasons in our analysis and in order to ensure that the classifier we output has, at most, linear error rate no matter how the active learning component of our algorithm behaves. Next, we use \(n/5\) of the query budget to obtain the labels of the first \(n/5\) points from \(S_{1}\). Then, we run the VCL game on these labeled datasets of size \(/5\) and obtain \(\) different pattern avoidance functions \(_{/5}^{i}\) that take as input \(_{/5}^{i}\) points (cf. Appendix D.2), where \(i[]\). Let

\[_{/5}^{i}:=\{f:\{0,1,\}:(f(x_{1}), ,f(x_{_{/5}^{i}}))_{/5}^{i}(x_{1}, ,x_{_{/5}^{i}})\},i[]\,.\]

First, we show that for a \((1-o(1))\)-fraction of these partial concept classes \(\) is a realizable distribution. Intuitively, this means that the partial concept class we obtain by running the VCL game on \(\) many points is the same as the class we would have obtained if we were to run the game on infinitely many points (cf. Lemma D.4). Next, we need to estimate some number \(}_{n}\) which, as \(n\), converges to the \(9/10\)-quantile \(^{*}\) of the distribution of the VC dimension of the partial concept classes that are obtained by running the VCL game on _infinitely_ many samples. We let

\[}_{n}:=_{d}\{ i_{1},i_{2}, ,i_{9/10}[]:i_{1}<i_{2}<<i_{9/10 {n}},(_{/5}^{i_{j}}) d, j [9/10]\}\,,\]

where \(()\) denotes the VC dimension of class \(\). Lemma D.5 shows that, for large enough \(n\), \(}_{n}=^{*}\), with high probability, where \(^{*}\) is such that with probability at least \(9/10\) over the random draw2 of the partial class, its VC dimension is at most \(^{*}\). One technical complication we need to handle is that the concept classes we have obtained are estimated from a game on \(\) many points instead of infinitely many points, so a \(o(1)\)-fraction of them do not correspond to samples from the correct distribution. To do that we use a robust version of the well-known Dvoretzky-Kiefer-Wolfowitz (DKW) inequality (cf. Theorem D.1) for estimating the CDF.

Next, we use another \(n/5\) of the query budget to obtain the labels of the first \(n/5\) points of \(S_{2}\). We will make two distinctions regarding this stream. For the purposes of the analysis, we consider a fixed stream of infinitely many i.i.d. samples from \(\) and we denote it by \(S_{2}^{}\), but in the actual algorithm we use a dataset of size \((n)\) and we denote it by \(S_{2}^{n}\). We define

\[V_{n/5}^{i}:=\{f_{}^{i}:f(x)=y^{}$}\}\,,\]

to be the version space of \(_{}^{i}\) defined on the first \(n/5\) examples of \(S_{2}^{}\). Moreover, we let \(V_{^{*},n/5}\) be a random version space that is sampled from the following process: we run the VCL game on an infinite stream of labeled data from \(\) to get a pattern avoidance function \(\) and then we define the partial concept class \(}\) in the same way as before. If the VC dimension of this class is greater than \(^{*}\) we discard it and restart the process. Otherwise, we let \(V_{^{*},n/5}\) be the version space of \(}\) on the first \(n/5\) labeled points of \(S_{2}^{}\). We take \(^{*}\) to be the \(9/10-\)quantile of \(}\) as described before (cf. Lemma D.5). Given some \(k\), let \(p_{n,k}:=[^{k}(x_{1},,x_{k}V_{^{*},n/5})|S_{2}^{}]\) where the expectation is over the draw of \(V_{^{*},n/5}\), given the fixed \(S_{2}^{}\). Let \(k^{*}\) be the largest number such that \(_{n}p_{n,k^{*}} 0.\) Notice that since, by definition, the VC dimension is bounded by \(^{*}\) such a number \(k^{*}\) exists. From here on, we will only consider the version spaces \(V^{i}_{n/5}\) that are obtained from some partial class with VC dimension at most \(}_{n}.\) Let \(p_{n,k,i}:=^{k}(x_{1},,x_{k}\) VC shattered by \(V^{i}_{n/5}).\) Notice that for every \(k}_{n}\) and every \(i[]\) we can estimate this quantity to arbitrary precision using only _unlabeled_ examples. We denote by \(_{n,k,i}\) these estimates.

We now consider the first \(n^{2}\) unlabeled points of the third data stream \(S_{3}.\) For each such point \(X\), let \(p^{X}_{n,k}:=[^{k}(x_{1},,x_{k},XV_{^{*},n/5})|S_{2}^{},X].\) Moreover, for each \(y\{0,1\}\) let

\[V^{(X,y)}_{^{*},n/5}:=\{f V_{^{*},n/5}:f(X)=y\},\;\;p^{(X,y)}_{n,k}:=[^{k}(x_{1},,x_{k}V^{(X,y)}_{^{*},n/5})|S_{2}^{},X],y\{0,1\}\,.\]

We define the quantities \(p^{X}_{n,k,i},p^{(X,y)}_{n,k,i}\) in the same way for the realized version spaces. Again, by Hoeffding's bound, we can estimate these quantities to arbitrary precision using unlabeled data. Similarly as before, we denote these estimates by \(^{X}_{n,k,i},^{(X,y)}_{n,k,i}.\) The idea is to make use of Lemma D.4 and show that the classes which have been obtained by a VCL game that has not converged will only affect our estimates by some \(o(1)\). This is formalized in Proposition D.6. Thus, we can use \(_{n,k,i},^{X}_{n,k,i},^{(X,y)}_{n,k,i},\) in order to estimate \(p_{n,k,},p^{X}_{n,k},p^{(X,y)}_{n,k}.\) We denote these estimates by \(_{n,k,},^{X}_{n,k},\)\(^{(X,y)}_{n,k}.\) These are the key quantities we use to _infer_ the labels of unlabeled points.

Our algorithm tries to infer the label of each unlabeled point \(X S_{3}\) (cf. Figure 7) in the following way: if \(^{X}_{n,k}_{n,k}}{2}\) then we query the label of \(X,\) otherwise we infer the label to be \(_{y\{0,1\}}^{(X,y)}_{n,k}.\) Lemma D.7 shows that the inferences are correct, when \(n\) is large enough.

The main ingredient of the proof that remains to be handled is to show that the number of label queries we submit is _sublinear_ in \(n.\) For that, it is sufficient to show that the probability that we query the label of a point is \(o(1).\) Lemma D.8 shows that when \(k=k^{*},\) this is indeed the case.

Finally, since we do not know the true value of \(k^{*},\) we run the algorithm for every \(k}_{n}.\) The active learning component of the algorithm gives us \(}_{n}+1\) different labeled datasets, which we use to train \(}_{n}+1\) instances of a supervised learning algorithm, such as the one from Bousquet et al. (2021). Our analysis so far has shown that for sufficiently large \(n,\) at least one of these datasets will be correctly labeled with size \((n).\) Thus, since the supervised learning algorithm has error linear in the size of its training set, at least one of these executions will give a classifier that has error \(o(1/n).\) The last step is to run a tournament among the \(_{n}+2\) different classifiers3 to choose the best one. This is handled by Lemma D.9(Hanneke, 2012). The main result of this section (cf. Theorem D.10), follows as a corollary of the results we have discussed. All the steps are summarized in Figure 7.

Lastly, a lower bound from Hanneke et al. (2022) completes our characterization (cf. Theorem D.11).

## 5 Conclusion

In this work we have provided a complete characterization of the optimal learning rates in active learning. It is an open question if it also holds when the learner knows the distribution \(_{}.\)