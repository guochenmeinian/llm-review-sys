# Classifier Clustering and Feature Alignment for Federated Learning under Distributed Concept Drift

Junbao Chen

Beijing Institute of Technology

junbaochen@bit.edu.cn

&Jingfeng Xue

Beijing Institute of Technology

xuejf@bit.edu.cn

&Yong Wang

Beijing Institute of Technology

wangyong@bit.edu.cn

&Zhenyan Liu

Beijing Institute of Technology

zhenyanliu@bit.edu.cn

&Lu Huang

Beijing Institute of Technology

luhuang@bit.edu.cn

Corresponding author.

###### Abstract

Data heterogeneity is one of the key challenges in federated learning, and many efforts have been devoted to tackling this problem. However, distributed concept drift with data heterogeneity, where clients may additionally experience different concept drifts, is a largely unexplored area. In this work, we focus on real drift, where the conditional distribution \(P(|)\) changes. We first study how distributed concept drift affects the model training and find that local classifier plays a critical role in drift adaptation. Moreover, to address data heterogeneity, we study the feature alignment under distributed concept drift, and find two factors that are crucial for feature alignment: the conditional distribution \(P(|)\) and the degree of data heterogeneity. Motivated by the above findings, we propose FedCCFA, a federated learning framework with classifier clustering and feature alignment. To enhance collaboration under distributed concept drift, FedCCFA clusters local classifiers at class-level and generates clustered feature anchors according to the clustering results. Assisted by these anchors, FedCCFA adaptively aligns clients' feature spaces based on the entropy of label distribution \(P()\), alleviating the inconsistency in feature space. Our results demonstrate that FedCCFA significantly outperforms existing methods under various concept drift settings. Code is available at https://github.com/Chen-Junbao/FedCCFA.

## 1 Introduction

Federated Learning (FL)  is an emerging privacy-preserving machine learning paradigm that allows multiple clients to collaboratively train a global model without sharing their raw data. In FL, clients train the models on their local data and send the updated models to the server for aggregation. Driven by the growing need for privacy protection, FL has been widely applied in various real-world scenarios .

One significant challenge in FL is data heterogeneity, which denotes the discrepancies in the data distributions across clients. Such discrepancies can hinder the convergence of the global model.

However, existing works neglect a real-world setting where _data heterogeneity_ and _distributed concept drift_ simultaneously exist. Unlike conventional concept drift in centralized machine learning , distributed concept drift  involves multiple clients experiencing different concept drifts at different times. For example, for the same medical image, diagnoses can vary among doctors (i.e., concept drift across clients), and even a doctor may offer different diagnoses at different times (i.e., concept drift across times). Moreover, the distribution of medical images varies across hospitals (i.e., data heterogeneity). This setting significantly degrades the performance of most FL methods, especially those using a single global model, because the model cannot provide different outputs for the same input. A similar research problem is multistream classification , where a sampling bias may exist between the distributions represented by source stream and target stream. Different from this problem, distributed concept drift focuses on the changing conditional distribution \(P(|)\) across clients and over time. For each client at any round, training and test data distribution are assumed to be similar.

Several recent works have recognized the concept drift problem in FL. However, as discussed above, these single-model solutions  are ill-suited for distributed concept drift. FedDrift  considers distributed concept drift and employs multiple models to address this problem. However, FedDrift significantly increases the computation overhead for its distance measure and the storage overhead for multiple entire models. In addition, since the data heterogeneity can affect the loss estimation, FedDrift may fail to merge the models under the same concept. Experimental details are provided in Appendix C.7.

To tackle distributed concept drift, we analyze how it affects the model training in FL. In this work, we focus on _real drift_ in concept drift, where the conditional distribution \(P(|)\) changes. When \(P(|)\) varies across clients, the representation should not be affected, as the marginal distribution \(P()\) is invariant. However, as shown in Figure 1, when vanilla FedAvg is adopted and distributed concept drift occurs at round 100, the Frobenius norm of representation update increases drastically, suggesting that the drift leads to large gradients in the representation. Furthermore, the accuracy of vanilla FedAvg drops rapidly and cannot recover to the accuracy before the drift, indicating the unsuitability of the single-model solution.

Motivated by the observations and analyses above, we decouple the network into an extractor and a classifier, and first train the classifier while fixing the extractor. After the classifier learns new conditional distribution, small gradients will be back-propagated to the extractor, and then we train the extractor. This decoupled method can effectively adapt to distributed concept drift, demonstrated by the much higher accuracy than FedAvg in Figure 1. The small gradient norm of representation at drift round also indicates the small gradients back-propagated from classifier. However, some clients may share similar \(P(|)\), and pure decoupled methods neglect the fine-grained collaboration between local classifiers. This will make each client's local classifier overfit to its local data. To enhance generalization performance, we develop a class-level classifier clustering method. Our clustering method separates the classifier for each class (referred to as class classifier), and then aggregates clients' class classifiers trained under the same conditional distribution \(P(|)\). The clients under the same conditional distribution share the aggregated class classifiers. This aggregation reduces the bias introduced by any single client's data, contributing to improved generalization performance. As shown in Figure 1, with the benefit of classifier clustering, the generalization performance is further improved, demonstrated by higher accuracy and smaller gradient norm. To remedy the data heterogeneity under distributed concept drift, we propose an adaptive feature alignment method, which aligns the feature spaces of the clients with the same conditional distribution \(P(|)\) and adjusts the alignment weight according to the entropy of label distribution.

To summarize our contributions:

Figure 1: The impact of distributed concept drift on model training. Distributed concept drift occurs at round 100. Decoupled: classifier-then-extractor learning method. Decoupled-Clustering: Decoupled method with classifier clustering.

1. We explore the impact of distributed concept drift on FL training and propose a class-level classifier clustering approach that not only adapts to this drift but also enhances generalization performance (Section 4.1).

2. We propose clustered feature anchors to achieve feature alignment under distributed concept drift and propose an adaptive alignment weight to prevent severe data heterogeneity from impeding main task learning (Section 4.2).

3. We propose FedCCFA, a federated learning framework with classifier clustering and feature alignment (see Section 4.3). In Section 5, we conduct extensive experiments and empirical results demonstrate that FedCCFA can effectively adapt to distributed concept drift under data heterogeneity and significantly outperforms existing methods.

## 2 Related work

Concept drift in FL.Concept drift has been extensively studied in centralized machine learning [11; 12; 25; 26; 38]. Several recent works have recognized the concept drift problem in FL and proposed methods to tackle this issue, including regularization , continual learning [3; 14] and adaptive learning rate [2; 32]. These works assume that the conditional distributions \(P(|)\) of all clients' dataset are the same, so only a single global model is trained. However, as proposed in  and discussed in Section 1, distributed concept drift may exist in FL setting and the single-model solution fails to adapt to this drift. To address this problem, FedDrift  creates new models based on drift detection and adaptively merges models by hierarchical clustering. However, FedDrift still faces some challenges: 1) incorrect model merging caused by data heterogeneity; 2) high computation and communication overhead for measuring cluster distance; 3) high storage cost for maintaining multiple global models.

Data heterogeneity in FL.Data heterogeneity hinders fast convergence when using vanilla FedAvg . In this work, we focus on the heterogeneity of label distributions (referred to as label distribution skew). To alleviate this issue, previous works either focus on local training [1; 20; 22; 24; 29] or global aggregation [17; 18; 33; 39; 40; 41]. To further study how data heterogeneity affects FL, several recent works have focused on the representation of model, such as dimensional collapse  and inconsistent feature spaces [45; 48; 43; 50]. To align clients' feature spaces, FedFA  and FedPAC  regularize the \(_{2}\) distance between local features and global anchors. To promote more precise alignment, FedFM  uses a contrastive-guiding method to further maximize the distance between the feature and non-corresponding anchors. However, severe data heterogeneity may significantly increase the loss of feature alignment, hindering the model convergence.

Clustered FL and personalized FL.Some clustered FL methods group clients with the same data distribution into a cluster, which can also adapt to distributed concept drift. To group clients, several works measure the similarity based on gradient information [9; 10; 35] or training loss [13; 27]. However, these methods face the following challenges: 1) unknown number of clusters; 2) large computation and communication overhead for estimating the training loss; 3) considerable storage cost for multiple global models. Personalized FL methods [6; 23; 31; 37; 43; 49] are also robust to distributed concept drift, since each client trains a local model for its local data distribution. However, most personalized FL methods neglect the classifier collaboration among the clients with similar data distributions, limiting the performance of models. Different from personalized FL approaches, this work focuses on generalized FL, aiming to enhance generalization performance.

## 3 Problem formulation

We consider a FL setting where there are \(K\) clients and a central server. The \(k\)-th client has a local dataset \(D_{k}\) with data distribution \(P_{k}(,)\), where \(\) is the input space and \(\) is the label space with \(C\) classes. Let \((;,y)\) be the task-specific loss function associated with model \(\) and data sample \((,y)\). The global objective of FL can be formulated as:

\[_{^{d}}\{F():=_{k=1}^{K}p_{k}F_{k}( )\}\] (1)where \(p_{k}\) is the aggregation weight of the \(k\)-th client and \(F_{k}():=_{(,y) D_{k}}[_{k}(; ,y)]\) is the local objective.

To distinguish different types of concept drift, we decompose the joint distribution \(P(,)\) as: \(P(,)=P()P(|)=P()P(|)\). In this work, we focus on the _real drift_ in concept drift. Real drift means that the conditional distribution at round \(t\) may be different from that at the previous round, i.e., \(P^{(t)}(|) P^{(t-1)}(|)\). In addition, under distributed concept drift, this conditional distribution may vary across clients, i.e., \(P^{(t)}_{i}(|) P^{(t)}_{j}(|)\).

To address distributed concept drift, we decouple the model parameterized by \(=\{,\}\) into a feature extractor \(f_{}\) parameterized by \(\) and a classifier \(f_{}\) parameterized by \(\). Given a sample \((,y)\), the feature extractor \(f_{}:\) maps the input \(\) into a feature vector \(=f_{}()\) in the feature space \(\), and then the classifier \(f_{}:\) maps the feature vector \(\) to the label space \(\). All clients share the feature extractor and each client maintains its local classifier. To align clients' feature spaces, we introduce a regularization term \(G_{k}(;_{k})\) into the local objective function. Here, \(_{k}\) represents a form of global information that client \(k\) uses to align its feature space. Let \(=\{_{1},_{2},, _{k}\}\) denote the set of all clients' local classifier parameters and \(\) denote the parameters of shared feature extractor. The global objective can be reformulated as:

\[_{,}\{F(, ):=_{k=1}^{K}p_{k}[F_{k}(,_{k})+ G_{k}(;_{k})]\}\] (2)

where \(\) is the weight of feature alignment.

## 4 Methodology

FedCCFA decouples the network into a feature extractor \(f_{}\) and a classifier \(f_{}\). In FedCCFA, the classifier is the last layer of the model (i.e., a linear classifier), and the feature extractor is composed of the remaining layers. In this section, we first present two methods used in FedCCFA and then describe the design of FedCCFA.

### Classifier clustering

For better classifier collaboration, we introduce a new method for client clustering. Specifically, all clients share the same extractor and train their personal classifiers. Given the identical dimension reduction \(=f_{}()\), the personal classifier learns the local data distribution. Therefore, the linear classifiers with similar weights exhibit similar data distributions, especially the conditional distribution \(P(|)\). Different from existing clustered FL methods, _FedCCFA directly uses the classifier weights for clustering_, which significantly reduces the computation and communication cost.

However, if using the weights of local classifiers, clustering may be disturbed by two factors: (1) variation in the classifier weights before training, and (2) class imbalance. For the first one, since clients' classifiers are different before local training, the classifiers trained under the same conditional distribution may differ significantly, which can lead to wrong clustering results. For the second one, the classifier can be easily biased towards head classes with massive training data, so the classifiers trained under the similar marginal distributions \(P()\) may be grouped, although their conditional distributions \(P(|)\) are different.

Balanced classifier training.To address the above two problems, before local classifier training, FedCCFA trains a balanced classifier and uses it for classifier clustering. Specifically, to ensure that the classifier weights before training are identical, each selected client \(k^{(t)}\) updates its classifier \(_{k}^{(t)}\) by the initial global classifier \(^{(0)}\). Then, to address class imbalance, client \(k\) samples a balanced batch \(b_{k}^{(t)}\) from \(D_{k}^{(t)}\) to train its classifier \(_{k}^{(t)}\) while fixing its extractor \(_{k}^{(t)}\):

\[_{k}^{(t)}_{k}^{(t)}-_{ }_{}F_{k}(_{k}^{(t) },_{k}^{(t)})\] (3)

where \(_{}\) denotes the learning rate for classifier.

After \(s\) training iterations, client \(k\) saves the balanced classifier \(}_{k}^{(t)}\) and sends it to the server after local training. Note that, to reduce additional computation cost, we randomly select 5 samples for each class \(c[C]\) (i.e., the balanced batch size \(|b_{k}^{(t)}|\) is \(5*C\)), and set training iterations \(s\) to a small value.

Class-level clustering.Unlike FedPAC  that uses _entire_ classifier for collaboration, FedCCFA conducts classifier clustering at _class-level_. Specifically, after receiving all balanced classifiers \(\{}_{k}^{(t)}\}\), the server separates these classifiers for each class (referred to as class classifier). Then, for each class \(c\), the server measures the class-level distance \(_{c}(i,j)\) between client \(i\) and client \(j\) by their class classifiers \(}_{i,c}^{(t)}\) and \(}_{j,c}^{(t)}\), where \(i,j^{(t)}\). To effectively measure distance between high-dimensional vectors, we exploit MADD  and realize a measure based on cosine distance:

\[_{c}(i,j)=^{(t)}|-2}_{q^{(t )}\{i,j\}}|Cos(}_{i,c}^{(t)},}_{q,c} ^{(t)})-Cos(}_{j,c}^{(t)},}_{q,c}^{(t)})|,  i,j^{(t)}\] (4)

where \(Cos(,)\) denotes the cosine distance between vector \(\) and \(\).

After getting the distance matrix \(_{c}\), DBSCAN clustering algorithm is used to get the class-level clusters \(_{c}^{(t)}\). For each cluster \(_{m,c}^{(t)}_{c}^{(t)}\), clustered class classifier is aggregated as:

\[}_{m,c}^{(t)}=_{m,c}^{(t)}|}_{k _{m,c}^{(t)}}_{k,c}^{(t)},_{m,c}^{ (t)}_{c}^{(t)}\] (5)

where \(|_{m,c}^{(t)}|\) denotes the number of clients in cluster \(_{m,c}^{(t)}\). Each client \(k_{m,c}^{(t)}\) updates its local class classifier \(_{k,c}^{(t)}\) by \(}_{m,c}^{(t)}\). Here we use uniform aggregation considering privacy concerns. More details about aggregation method are shown in Appendix C.6.

### Adaptive feature alignment

To alleviate the inconsistency in feature spaces , we introduce a regularization term into the local objective function to align clients' feature spaces. Compared to existing alignment methods [43; 45; 50], our method is robust to two challenges: concept drift and the degree of data heterogeneity.

Clustered feature anchors.Existing feature alignment methods suppose that all clients' conditional distributions \(P(|)\) are identical. Based on this, global feature anchors [45; 50] (also known as feature centroids ) are leveraged to align clients' feature spaces. However, under distributed concept drift scenario, the conditional distribution \(P(|)\) may vary across clients, which can result in the differences in feature anchors. Therefore, clients require the global anchors that match their conditional distributions; otherwise, incorrect global anchors can mislead feature alignment. Motivated by this, we propose a feature alignment method using clustered feature anchors. Specifically, at round \(t\), each client uses its feature extractor \(_{k}^{(t)}\) to compute the local feature anchor \(a_{k,c}^{(t)}\) for each class \(c\):

\[a_{k,c}^{(t)}=^{(t)}|}_{(,c) D_{k,c}^{(t)}}f _{_{k}^{(t)}}(), c[C]\] (6)

Then, with the help of our class-level clustering, we compute the global feature anchor \(_{m,c}^{(t)}\) of class \(c\) for each cluster \(_{m,c}^{(t)}\):

\[_{m,c}^{(t)}=_{m,c}^{(t)}|}_{k _{m,c}^{(t)}}a_{k,c}^{(t)},_{m,c}^{(t)} _{c}^{(t)}\] (7)

Finally, each client \(k_{m,c}^{(t)}\) uses its global anchors \(_{k}^{(t)}=\{_{m,c}^{(t)}\}_{c=1}^{C}\) to align its feature space during local training. FedCCFA leverages the contrastive-guiding loss proposed in FedFM , but uses clustered feature anchors. Let \(sim(,)\) denote the cosine similarity between \(\) and \(\). Then the alignment loss function for a sample \((,c)\) with label \(c\) is defined as:

\[G_{k}(_{k}^{(t)};_{k}^{(t)})=-_{k}^{(t)}}(),_{k,c}^{(t)})/)}{_{i=1}^{C} (sim(f_{_{k}^{(t)}}(),_{k,i}^{(t)})/)}\] (8)

where \(f_{_{k}^{(t)}}()\) is the representation vector of input \(\) and \(\) denotes a temperature parameter.

Adaptive alignment weight.In existing feature alignment methods [43; 45; 50], the alignment weight is fixed and all clients use the same weight. However, severe data heterogeneity will significantly increase the gradients of alignment term, impeding the main task learning. Experimental results are presented in Table 5. To balance the main task learning and feature alignment, it is essential to reduce the alignment weight under severe data heterogeneity. Note that, in this work, we focus on the label distribution skew and the degree of this heterogeneity can be reflected by the marginal distribution \(P_{k}^{(t)}()\). Based on this intuition, we leverage the entropy of marginal distribution \(P_{k}^{(t)}()\), denoted as \((P_{k}^{(t)}())\), to adaptively determine the alignment weight:

\[_{k}^{(t)}_{k}^{(t)}-_{} _{}[F_{k}(_{k}^{(t)},_{k}^{(t)})+(P_{k}^{(t)}())}{}G_{k}(_{k}^{(t)}; _{k}^{(t)})]\] (9)

where \(_{}\) denotes the learning rate for extractor and \(\) is the scaling factor. For the round \(T_{s}\) to start feature alignment, we use the empirical value \(T_{s}=20\) proposed in FedFM .

### FedCCFA

We now present FedCCFA, a federated learning framework to adapt to distributed concept drift under data heterogeneity. The pipeline of FedCCFA is shown in Figure 2. The procedure of FedCCFA is formally presented in Algorithm 1 in Appendix A.

Local training.At each round \(t\), each selected client \(k^{(t)}\) updates its extractor \(_{k}^{(t)}\) by the global extractor \(^{(t)}\), and then starts local training procedure. Specifically, each client trains a balanced classifier (Equation 3) for client clustering. Then, it fixes its feature extractor and trains local classifier to adapt to concept drift. Finally, it trains its feature extractor (Equation 9). Since the classifier \(_{k}^{(t)}\) learns the conditional distribution \(P_{k}^{(t)}(|)\), concept drift will not lead to larges gradients in the representation. After local training, each client generates its local anchors for each class (Equation 6).

Global aggregation.After receiving the local parameters and local anchors, the server starts the aggregation procedure. Specifically, the server performs client clustering with the help of balanced classifiers. Then, the server aggregates all feature extractors:

Figure 2: An overview of the proposed FedCCFA. Clients train balanced classifiers and local models, and then generate local anchors. The server performs client clustering with the help of balanced classifiers, and then aggregates local models and local anchors.

\[^{(t+1)}=^{t}}|D_{k}^{(t)}|}_{k ^{t}}|D_{k}^{(t)}|_{k}^{(t)}\] (10)

Finally, according to the clustering results, the server aggregates local classifiers and local anchors for each cluster.

## 5 Experiments

### Experimental setup

Datasets and models.We conduct experiments on three datasets, namely Fashion-MNIST , CIFAR-10  and CINIC-10 . We construct two different CNN models for Fashion-MNIST and CIFAR-10/CINIC-10, respectively. Details of datasets and models are provided in Appendix B.1.

Baselines.We compare FedCCFA against the methods falling under the following categories: (1) single-model methods without drift adaptation: FedAvg , FedProx , SCAFFOLD  and FedFM ; (2) single-model methods with drift adaptation: Adaptive-FedAvg (shortened to AdapFedAvg)  and Flash ; (3) personalized FL methods: pFedMe , Ditto , FedRep , FedBABU  and FedPAC ; (4) clustered FL methods: IFCA  and FedDrift .

Federated learning settings.We consider two FL scenarios: 20 clients with full participation and 100 clients with 20% participation. We use a widely considered non-IID setting : for each class \(c[C]\), we sample a probability vector \(_{c}=(p_{c,1},p_{c,2},,p_{c,K}) Dir_{K}()\) and allocate a \(p_{c,k}\) proportion of instances of class \(c\) to client \(k[K]\), where \(Dir_{K}()\) denotes the Dirichlet distribution with concentration parameter \(\); smaller \(\) means more unbalanced partition. To evaluate the adaptability to concept drift, each client's training set contains at least 5 samples per class.

Concept drift settings.In this work, we focus on the distributed concept drift proposed in , where the conditional distribution \(P(|)\) varies over time and across clients. We use three label swapping settings to simulate the conditional distribution changes across clients: for client \(k[K]\), (1) class 1 and class 2 are swapped if \(k\%10<3\); (2) class 3 and class 4 are swapped if \(3<=k\%10<=5\); (3) class 5 and class 6 are swapped if \(k\%10>5\). We simulate three patterns of conditional distribution changes over time: (1) **Sudden Drift.** All label swapping settings occur at round 100; (2) **Incremental Drift.** Label swapping settings (1), (2) and (3) occur at round 100, 110 and 120, respectively; (3) **Reoccurring Drift.** All label swapping settings occur at round 100, and these settings occur again at round 150.

Implementation details.We run 200 communication rounds for all experiments. To comprehensively evaluate the generalized performance and drift adaptability, for each client, we report the generalized accuracy of its model on _the whole test set_. In particular, the conditional distributions \(P(|)\) of each client's training set and test set are the same at every round. For clustered and single-model methods, each client evaluates its global model; for the other methods, each client evaluates its personal model (or the combination of global extractor and personal classifier). Finally, we report the average accuracy across clients at the last round. For local training, we use SGD optimizer. The weight decay is 0.00001 and the SGD momentum is 0.9. For all datasets, we set local epochs \(E=5\). For the decoupled methods, extractor learning rate is 0.01 and classifier learning rate is 0.1; for the other methods, local learning rate is 0.01. For FedCCFA, scaling factor \(\) is 20.0, iterations of balanced training \(s\) is 5 and balanced batch size is \(5*C\) (5 samples per class). For classifier clustering, maximum distance \(\) and minimum samples used in DBSCAN algorithm are 0.1 and 1, respectively. More details of hyperparameters are provided in Appendix B.2.

### Experimental results

We focus on three points in our experiments: (1) the generalization performance of FedCCFA; (2) the adaptability to distributed concept drift compared to existing methods; (3) the effects of our classifier clustering and adaptive alignment weight. Full experimental results are provided in Appendix C.

Performance without concept drift.First, we evaluate all methods under the no drift setting, and these results are the base performance compared against various concept drift settings. For each method, we run three trials and report the mean and standard deviation. Table 1 presents the generalized accuracy under \(Dir(0.5)\). We observe that FedCCFA outperforms all decoupled methods (FedRep, FedBABU and FedPAC) and personalized FL methods (pFedMe and Ditto), indicating that FedCCFA enhances the generalization performance of local classifiers. Besides, the performance of IFCA under 20 clients with 100% participation is worse than the performance under 100 clients with 20% participation. This is because multiple global models are trained under similar data distribution (i.e., each global model is trained with much less data). In contrast, with the help of our classifier clustering, clients with similar data distribution will share the same classifier. Compared with single-model methods, FedCCFA achieves lower accuracy, which is attributed to decoupled training. Specifically, for decoupled methods (e.g., FedPAC, FedRep and our FedCCFA), training the classifier first might cause it to fit the initial features, resulting in gradient attenuation during backpropagation. This will restrict the subsequent extractor's training process and prevent it from optimally learning

    &  &  &  \\   & 20 clients & 100 clients & 20 clients & 100 clients & 20 clients & 100 clients \\  FedAvg & 90.57\(\)0.18 & 90.22\(\)0.33 & 78.56\(\)0.20 & 74.05\(\)0.72 & 62.23\(\)0.28 & 58.28\(\)0.21 \\ FedProx & 90.29\(\)0.17 & 90.22\(\)0.02 & 78.49\(\)0.20 & 73.50\(\)0.61 & 62.17\(\)0.35 & 58.40\(\)0.86 \\ SCAFFOLD & 90.33\(\)0.04 & 87.72\(\)0.19 & 75.84\(\)0.71 & 59.01\(\)0.74 & 58.92\(\)0.12 & 47.69\(\)0.35 \\ FedFM & 90.03\(\)0.26 & 90.20\(\)0.35 & 78.97\(\)0.43 & 74.89\(\)0.42 & 62.96\(\)0.27 & 58.66\(\)0.13 \\  AdapFedAvg & 90.42\(\)0.25 & 90.39\(\)0.11 & 78.28\(\)0.38 & 73.91\(\)0.69 & 61.96\(\)0.30 & 58.80\(\)0.42 \\ Flash & 90.19\(\)0.05 & 89.94\(\)0.30 & 78.01\(\)0.61 & 75.13\(\)0.23 & 61.11\(\)0.43 & 60.30\(\)0.25 \\  pFedMe & 85.06\(\)0.32 & 84.81\(\)0.31 & 63.08\(\)1.28 & 51.49\(\)0.08 & 43.75\(\)0.07 & 41.80\(\)0.49 \\ Ditto & 90.33\(\)0.15 & 89.73\(\)0.19 & 77.03\(\)0.39 & 72.26\(\)0.44 & 59.30\(\)0.25 & 56.33\(\)0.10 \\ FedRep & 81.70\(\)0.10 & 80.39\(\)0.30 & 64.08\(\)0.30 & 52.19\(\)1.50 & 43.63\(\)0.38 & 38.48\(\)0.12 \\ FedBABU & 76.83\(\)1.66 & 80.69\(\)0.54 & 58.99\(\)0.25 & 55.42\(\)0.21 & 40.74\(\)0.21 & 41.43\(\)0.26 \\ FedPAC & 85.01\(\)0.39 & 87.61\(\)0.26 & 67.96\(\)0.40 & 67.77\(\)0.36 & 43.83\(\)0.69 & 47.50\(\)0.38 \\  IFCA & 86.99\(\)1.17 & 88.61\(\)0.51 & 64.10\(\)0.75 & 72.53\(\)0.30 & 48.43\(\)1.48 & 57.84\(\)0.18 \\ FedDrift & 90.38\(\)0.36 & 90.33\(\)0.16 & 78.59\(\)0.35 & 73.70\(\)0.76 & 62.12\(\)0.23 & 58.48\(\)0.72 \\  FedCCFA & 89.81\(\)0.36 & 89.74\(\)0.18 & 78.38\(\)0.56 & 74.44\(\)0.26 & 61.13\(\)0.25 & 58.70\(\)0.33 \\   

Table 1: Generalized accuracy under \(Dir(0.5)\). The sample ratio is 100% and 20% for 20 clients and 100 clients, respectively. All results are averaged over 3 runs (mean \(\) std).

    &  &  &  \\   & 20 clients & 100 clients & 20 clients & 100 clients & 20 clients & 100 clients \\  FedAvg & 67.81\(\)1.12 & 68.15\(\)1.98 & 60.96\(\)0.37 & 58.15\(\)0.23 & 49.69\(\)0.16 & 46.18\(\)0.39 \\ FedProx & 69.25\(\)0.60 & 68.47\(\)0.19 & 61.25\(\)0.20 & 57.68\(\)0.11 & 49.45\(\)0.40 & 46.11\(\)0.59 \\ SCAFFOLD & 69.92\(\)1.24 & 69.66\(\)0.24 & 58.67\(\)0.39 & 45.87\(\)1.29 & 46.34\(\)0.70 & 37.94\(\)1.43 \\ FedFM & 68.48\(\)0.79 & 69.12\(\)0.34 & 60.61\(\)0.27 & 57.51\(\)0.35 & 50.25\(\)0.11 & 46.23\(\)0.81 \\  AdapFedAvg & 69.30\(\)1.06 & 68.86\(\)0.53 & 60.92\(\)0.20 & 58.23\(\)0.30 & 49.86\(\)0.36 & 46.34\(\)0.19 \\ Flash & 10.00\(\)0.00 & 71.16\(\)0.28 & 59.84\(\)0.75 & 60.49\(\)0.27 & 49.44\(\)0.41 & 49.28\(\)0.40 \\  pFedMe & 82.37\(\)0.09 & 77.66\(\)0.17 & 58.92\(\)1.64 & 44.15\(\)1.08 & 41.34\(\)0.22 & 37.76\(\)0.78 \\ Ditto & 78.51\(\)0.82 & 79.62\(\)0.31 & 67.45\(\)0.01 & 63.35\(\)0.67 & 51.06\(\)0.26 & 48.40\(\)0.34 \\ FedRep & 81.99\(\)0.37 & 81.07\(\)0.29 & 64.51\(\)0.86 & 53.30\(\)1.51 & 44.00\(\)0.26 & 38.15\(\)0.14 \\ FedBABU & 79.83\(\)0.18 & 81.68\(\)0.10 & 58.87\(\)0.50 & 55.29\(\)0.61 & 41.24\(\)0.90 & 40.49\(\)0.30 \\ FedPAC & 84.00\(\)0.47 & 87.24\(\)0.16 & 66.47\(\)0.30 & 64.73\(\)1.22 & 44.38\(\)0.18 & 46.22\(\)0.47 \\  IFCA & 87.02\(\)0.06 & 88.25\(\)0.21 & 61.

[MISSING_PAGE_FAIL:9]

scaling factor \(\{20,50,100\}\). We see that our adaptive alignment weight is robust to the degree of data heterogeneity and the performance is not sensitive to the scaling factor.

## 6 Conclusion

In this work, we take a further step towards distributed concept drift in federated learning. We have shown that FedCCFA can effectively adapt to distributed concept drift, and outperforms existing methods under various concept drift settings. Further experiments suggest that our classifier clustering method significantly enhances the generalization performance for decoupled FL methods. Besides, our clustered feature anchors can enhance the precision of feature alignment and our adaptive alignment weight can stabilize the training process when using feature alignment under severe heterogeneity. We hope that FedCCFA can inspire more works on classifier collaboration and other types of concept drift in federated learning.

Limitations.FedCCFA takes some steps to train balanced classifiers, which increases computation cost. Although we reduce it by setting small iteration and batch size, it is preferable to remove these steps. We will investigate other efficient methods in the future. Besides, feature alignment, used in FedCCFA, FedFM and FedPAC, could impede main task learning under severe data heterogeneity. Therefore, research on the feature alignment under severe heterogeneity is also of interest.