# Adaptive Linear Estimating Equations

Mufang Ying

Department of Statistics

Rutgers University - New Brunswick

my426@scarletmail.rutgers.edu &Koulik Khamaru

Department of Statistics

Rutgers University - New Brunswick

k1241@stat.rutgers.edu &Cun-Hui Zhang

Department of Statistics

Rutgers University - New Brunswick

czhang@stat.rutgers.edu

###### Abstract

Sequential data collection has emerged as a widely adopted technique for enhancing the efficiency of data gathering processes. Despite its advantages, such data collection mechanism often introduces complexities to the statistical inference procedure. For instance, the ordinary least squares (OLS) estimator in an adaptive linear regression model can exhibit non-normal asymptotic behavior, posing challenges for accurate inference and interpretation. In this paper, we propose a general method for constructing debiased estimator which remedies this issue. It makes use of the idea of adaptive linear estimating equations, and we establish theoretical guarantees of asymptotic normality, supplemented by discussions on achieving near-optimal asymptotic variance. A salient feature of our estimator is that in the context of multi-armed bandits, our estimator retains the non-asymptotic performance of the least squares estimator while obtaining asymptotic normality property. Consequently, this work helps connect two fruitful paradigms of adaptive inference: a) non-asymptotic inference using concentration inequalities and b) asymptotic inference via asymptotic normality.

## 1 Introduction

Adaptive data collection arises as a common practice in various scenarios, with a notable example being the use of (contextual) bandit algorithms. Algorithms like these aid in striking a balance between exploration and exploitation trade-offs within decision-making processes, encompassing domains such as personalized healthcare and web-based services [35; 24; 3; 22]. For instance, in personalized healthcare, the primary objective is to choose the most effective treatment for each patient based on their individual characteristics, such as medical history, genetic profile, and living environment. Bandit algorithms can be used to allocate treatments based on observed response, and the algorithm updates its probability distribution to incorporate new information as patients receive treatment and their response is observed. Over time, the algorithm can learn which treatments are the most effective for different types of patients.

Although the adaptivity in data collection improves the quality of data, the sequential nature (non-iid) of the data makes the inference procedure quite challenging [34; 26; 5; 28; 27; 10; 30; 29]. There is a lengthy literature on the problem of parameter estimation in the adaptive design setting. In a series of work [15; 19; 17], the authors studied the consistency of the least squares estimator for an adaptivelinear model. In a later work, Lai  studied the consistency of the least squares estimator in a nonlinear regression model. The collective wisdom of these papers is that, for adaptive data collection methods, standard estimators are consistent under a mild condition on the maximum and minimum eigenvalues of the covariance matrix [19; 14]. In a more recent line of work [1; 2], the authors provide a high probability upper bound on the \(_{2}\)-error of the least squares estimator for a linear model. We point out that, while the high probability bounds provide a quantitative understanding of OLS, these results assume a stronger sub-Gaussian assumption on the noise variables.

The problem of inference, i.e. constructing valid confidence intervals, with adaptively collected data is much more delicate. Lai and Wei  demonstrated that for a unit root autoregressive model, which is an example of adaptive linear regression models, the least squares estimator doesn't achieve asymptotic normality. Furthermore, the authors showed that for a linear regression model, the least squares estimator is asymptotically normal when the data collection procedure satisfies a stability condition. Concretely, letting \(_{i}\) denote the covariate associated with \(i\)-th sample, the authors require

\[_{n}^{-1}_{n}}{{}} \] (1)

where \(_{n}=_{i=1}^{n}_{i}_{i}^{}\) and \(\{_{n}\}_{n 1}\) is a sequence of _non-random_ positive definite matrices. Unfortunately, in many scenarios, the stability condition (1) is violated [38; 19]. Moreover, in practice, it might be difficult to verify whether the stability condition (1) holds or not. In another line of research [10; 36; 37; 4; 9; 28; 31; 25; 38], the authors assume knowledge of the underlying data collection algorithm and provide asymptotically valid confidence intervals. While this approach offers intervals under a much weaker assumption on the underlying model, full knowledge of the data collection algorithm is often unavailable in practice.

Online debiasing based methods:In order to produce valid statistical inference when the stability condition (1) does not hold, some authors [8; 7; 13] utilize the idea of online debiasing. At a high level, the online debiased estimator reduces bias from an initial estimate (usually the least squares estimate) by adding some correction terms, and the online debiasing procedure does not require the knowledge of the data generating process. Although this procedure guarantees asymptotic reduction of bias to zero, the bias term's convergence rate can be quite slow.

In this work, we consider estimating the unknown parameter in an adaptive linear model by using a set of adaptive linear estimating equations (ALEE). We show that our proposed ALEE estimator achieves asymptotic normality without knowing the exact data collection algorithm while addressing the slowly decaying bias problem in online debiasing procedure.

## 2 Background and problem set-up

In this section, we provide the background for our problem and set up a few notations. We begin by defining the adaptive data collection mechanism for linear models.

### Adaptive linear model

Suppose a scalar response variable \(y_{t}\) is linked to a covariate vector \(_{t}^{d}\) at time \(t\) via the linear model:

\[y_{t}=_{t}^{}^{*}+_{t}t[n],\] (2)

where \(^{*}^{d}\) is the unknown parameter of interest.

In an adaptive linear model, the regressor \(_{t}\) at time \(t\) is assumed to be a (unknown) function of the prior data point \(\{_{1},y_{1},,_{t-1},y_{t-1}\}\) as well as additional source of randomness that may be present in the data collection process. Formally, we assume there is an increasing sequence of \(\)-fields \(\{_{t}\}_{t 0}\) such that

\[(_{1},y_{1},,_{t-1},y_{t-1},_{t}) _{t-1}t[n].\]

For the noise variables \(\{_{t}\}_{t 1}\) appearing in equation (2), we impose the following conditions

\[[_{t}|_{t-1}]=0,[_{t}^{2} |_{t-1}]=^{2},_{t 1}[| _{t}/|^{2+}|_{t-1}]<,\] (3)

for some \(>0\). The above condition is relatively mild compared to a sub-Gaussian condition.

Examples of adaptive linear model arise in various problems, including multi-armed and contextual bandit problems, dynamical input-output systems, adaptive approximation schemes and time series models. For instance, in the context of the multi-armed bandit problem, the design vector \(_{t}\) is one of the basis vectors \(\{_{k}\}_{k[d]}\), representing an arm being pulled, while \(^{*},y_{t}\) represent the true mean reward vector and reward at time \(t\), respectively.

### Adaptive linear estimating equations

As we mentioned earlier, the OLS estimator can fail to achieve asymptotic normality due to the instability of the covariance matrix with adaptively collected data. To get around this issue, we consider a different approach ALEE (adaptive linear estimating equations). Namely, we obtain an estimate by solving a system of linear estimating equations with adaptive weights,

\[_{t=1}^{n}_{t}(y_{t}-_{t}^{} }_{})=.\] (4)

Here the weight \(_{t}^{d}\) is chosen in a way that \(_{t}_{t-1}\) for \(t[n]\). Let us now try to gain some intuition behind the construction of ALEE. Rewriting equation (4), we have

\[\{_{t=1}^{n}_{t}_{t}\}(}_{}-^{*})=_{t=1}^{n}_{t}_{t}.\] (5)

Notably, the choice of \(_{t}_{t-1}\) makes \(_{t=1}^{n}_{t}_{t}\) the sum of a martingale difference sequence. Our first theorem postulates conditions on the weight vectors \(\{_{t}\}_{t 1}\) such that the right-hand side of (5) converges to normal distribution asymptotically. Throughout the paper, we use the shorthand \(_{t}=(_{1},,_{t})^{}^{t d}\), \(_{t}=(_{1},,_{t})^{}^{t d}\).

**Proposition 2.1**.: _Suppose condition (3) holds and the predictable sequence \(\{_{t}\}_{1 t n}\) satisfies_

\[_{1 t n}\|_{t}\|_{2}=o_{p}(1) _{d}-_{n}^{}_{n}_{}=o_{p}( 1).\] (6)

_Let \(_{w}=_{w}_{w}^{}_{n}\) with \(_{n}=_{w}_{w}_{w}^{}\) being the SVD of \(_{n}\). Then,_

\[_{w}(}_{}-^{*})/ {}}{{}} ,_{d},\] (7)

_where \(\) is any consistent estimator for \(\)._

**Proof.** Invoking the second part of the condition (6), we have that \(_{w}\) is invertible for large \(n\), and \(\|_{w}_{w}^{-1}_{w}^{}-_{d} \|_{}=o_{p}(1)\). Utilizing the expression (5), we have

\[_{w}(}_{}-^{*})/= _{w}_{w}^{-1}_{w}^{}_{n}^{ }_{n}(}_{}-^{*})/ =_{w}_{w}^{-1}_{w}^{}_{t=1}^ {n}_{t}_{t}/.\]

Invoking the stability condition on the weights \(\{_{t}\}\) and using the fact that \(_{t=1}^{n}_{t}_{t}\) is a martingale difference sequence, we conclude from martingale central limit theorem [11, Theorem 2.1] that

\[_{t=1}^{n}_{t}_{t}/}{{ }},_{d}.\]

Combining the last equation with \(\|_{w}_{w}^{-1}_{w}^{}-_{d} \|_{}=o_{p}(1)\) and using Slutsky's theorem yield

\[_{w}(}_{}-^{*})/ }{{}}, _{d}.\]

The claim of Proposition 2.1 now follows from Slutsky's theorem.

A few comments regarding the Proposition 2.1 are in order. Straightforward calculation shows

\[_{w}^{}_{w}=_{n}^{}_{w} _{n}_{n},_{w}= _{n}(_{n}^{}_{n})^{-1}_{n}^{}.\] (8)

In words, the volume of the confidence region based on (7) is always larger than the confidence region generated by the least squares estimate. Therefore, the ALEE-based inference, which is consistently valid, exhibits a reduced efficiency in cases where both types of confidence regions are valid. Compared with the confidence regions based on OLS, the advantage of the ALEE approach is to provide flexibility in the choice of weights to guarantee the validity of the CLT conditions (6).

Next, note that the matrix \(_{w}\) is asymptotically equivalent to the matrix \(_{n}^{}_{n}\) (see equation (5)) under the stability condition (6). The benefit of this reformulation is that it helps us better understand efficiency of ALEE compared with the OLS. This has led us to define a notion of _affinity_ between the weights \(\{_{t}\}_{t 1}\) and covariates \(\{_{t}\}_{t 1}\) for better understanding of the efficiency of ALEE and ways to design nearly optimal weights, as it will be clear in the next section.

Finally, it is straightforward to obtain a consistent estimate for \(\). For instance, assuming \((_{}(_{n}^{}_{n}))/n}{{ }}0\) and the noise condition (3), we have

\[^{2}:=_{t=1}^{n}(y_{t}-_{t}^{} }_{})^{2}}{{ }}^{2}.\] (9)

Here, \(}_{}\) refers to the least squares estimate. See [19, Lemma 3] for a detailed proof of equation (9).

## 3 Main results

In this section, we propose methods to construct weights \(\{_{t}\}_{t 1}\) which satisfy the stability property (6), and study the resulting ALEE. Section 3.1 is devoted to the multi-armed bandit case, Section 3.2 to an autoregressive model, and Section 3.3 to the contextual bandit case. Before delving into details, let us try to understand intuitively how to construct weights that have desirable properties.

The expression (8) reveals that the efficiency of ALEE depends on the projection of the data matrix \(_{n}\) on \(_{n}\). Thus, the efficiency of the ALEE approach can be measured by the principal angles between the random projections \(_{w}\) in (8) and \(_{x}=_{n}_{n}^{-1}_{n}^{}\). Accordingly, we define the _affinity_\((_{n},_{n})\) of the weights \(\{_{t}\}_{t 1}\) as the cosine of the largest principle angle, or equivalently

\[(_{n},_{n})=_{d}(_{w}_{x})=_{d}_{w}^{}_{n}_{n}^{-1 /2}\] (10)

as the \(d\)-th largest singular value of \(_{w}_{x}\). Formally, the above definition captures the cosine of the angle between the two subspaces spanned by the columns of \(_{n}\) and \(_{n}\), respectively . Good weights \(\{_{t}\}_{t 1}\) are those with relatively large affinity or

\[_{w}_{n}_{n}^{-1/2}.\] (11)

### Multi-armed bandits

In the context of the \(K\)-arm bandit problem, the Gram matrix has a diagonal structure, which means that we can focus on constructing weights \(\{_{t}\}_{t 1}\) for each coordinate independently. For an arm \(k[K]\) and round \(t 1\), define

\[s_{t,k}=s_{0}+_{i=1}^{t}x_{i,k}^{2}_{0}$}.\] (12)

Define the \(k\)-th coordinate of the weight \(_{t}\) as

\[w_{t,k}=f}{s_{0}}}{ }} f(x)=x) ((e^{2}x))^{2}}}.\] (13)

The intuition behind the above construction is as follows. The discussion at near equation (11) indicates that the \(k\)-th coordinate of \(_{t}\) should be proportional to \(x_{t,k}/(_{i n}x_{i,k}^{2})^{1/2}\). However, the weight \(_{t}\) is required to be predictable, which can only depend on the data points 1 up to time \(t\). Consequently, we approximate the sum \(_{i n}x_{i,k}^{2}\) by the partial sum \(s_{t,k}\) in (12). Finally, note that

\[w_{t,k}=f}{s_{0}}}{ }}}{}}.\] (14)

The logarithmic factors in (13) ensure that the stability conditions (6) hold. In the following theorem, we generalize the above method as a general strategy for constructing weights \(\{_{t}\}_{t 1}\) satisfying the stability condition (6).

#### 3.1.1 Stable weight construction strategy

Consider a positive decreasing function \(f(x)\) on the interval \([1,)\) with an increasing derivative \(f^{}(x)\). Let \(f\) satisfy the conditions: \(f^{}/f\) is increasing,

\[_{1}^{}f^{2}(x)dx=1,_{1}^{}f(x)dx=.\] (15)

With \(s_{0}_{0}\), we define weight \(w_{t,k}\) as

\[w_{t,k}=f}{s_{0}}}{}}  s_{t,k}=s_{0}+_{i=1}^{t}x_{i,k}^{2}.\] (16)

A key condition that ensures the weights \(\{w_{t,k}\}_{t 1}\) satisfy the desirable stability property (6) is

\[_{1 t n}f^{2}}{s_{0}}^{2}} {s_{0}}+_{1 t n}(1-/s_{0})}{f(s_{t-1,k}/s_{0} )})+_{s_{n,k}/s_{0}}^{}f^{2}(x)dx=o_{p}(1).\] (17)

For multi-armed bandits, this condition is automatically satisfied when both quantities \(1/s_{0}\) and \(s_{0}/s_{n,k}\) converge to zero in probability. Putting together the pieces, we have the following result for multi-armed bandits.

**Theorem 3.1**.: _Suppose condition (3) holds and \(1/s_{0}+s_{0}/s_{n,k}=o_{p}(1)\) for some \(k[K]\). Then, the \(k\)-th coordinate \(_{,k}\), obtained using weights from equation (16), satisfies_

\[(_{,k}-_{k}^{*})_{1}^{s_{n,k}/s_{ 0}}}}{}f(x)dx}{{ }}(0,1),\] (18)

_where \(\) is a consistent estimate of \(\). Equivalently,_

\[_{,k}-_{k}^{*})}{ w_{t,k}^{2}}}_{t=1}^{n}w_{t,k}x_{t, k}}{{}}(0,1).\] (19)

The proof of Theorem 3.1 can be found in Section A.1 of the Appendix. A few comments regarding Theorem 3.1 are in order.

First, the above theorem enables us to construct valid CI in the estimation of the mean \(_{k}^{*}\) for a sub-optimal arm \(k\) when employing an asymptotically optimal allocation rule to achieve the optimal regret in  with sample size \(_{t n}x_{t,k} n\), or when using a sub-optimal rule to achieve \((n)\). On the other hand, the classical martingale CLT is applicable to the optimal arm (if unique) under such asymptotically optimal or sub-optimal allocation rules. Consequently, one may obtain a valid CI for the optimal arm from the standard OLS estimate . However, it is important to note that such CIs are not guaranteed for sub-optimal arms.

Figure 1: Empirical distribution of the standardized estimation errors from OLS and ALEE approach. Results are obtained with a dataset of size \(n=1000\) and \(3000\) independent replications. Left: AR\((1)\) model \(y_{t}=y_{t-1}+_{t}\) with independent errors \(_{t}(0,1)\). Right: Two-armed bandit problem with equal arm mean \(_{1}^{*}=_{2}^{*}=0.3\) and independent noise \(_{t}(0,1)\). Figure 4 in Section C.3 considers the same setting with centered Poisson noise, which is not sub-Gaussian.

Next, while Theorem 3.1 holds for any \(s_{0}\) diverging to infinity but of smaller order than \(s_{n,k}\) ( which may depend on \(k\)), the convergence rate of \(_{1 t n}w_{t,k}_{t}\) to normality is enhanced by choosing a large value for \(s_{0}\). In practical terms, it is advisable to choose an \(s_{0}\) that is slightly smaller than the best-known lower bound for \(s_{n,k}\).

Finally, the choice of function \(f\) determines the efficiency of ALEE estimator. For instance, taking function \(f(x)=1/x\), we obtain an estimator with asymptotic variance of order \(1/\{s_{0}^{2}(s_{n,k}/s_{0})\}\), which is only better than what one would get using stopping time results by a logarithmic factor. In the next Corollary, an improved choice of \(f\) yields near optimal variance up to logarithmic terms.

**Corollary 3.2**.: _Consider the same set of assumptions as stated in Theorem 3.1. The ALEE estimator \(_{,k}\), obtained by using \(f(x)=(^{}2)^{1/2}\{x( e^{2}x)( e^{2}x)^{1+}\}^ {-1/2}\) for any \(>0\) satisfies_

\[}{(s_{n,k}/s_{0})\{(s_{n,k}/s_{0}) \}^{1+}}}}(_{,k}- _{k}^{*})}{}}{{ }}(0,1).\]

The proof of this corollary follows directly from Theorem 3.1. For \(s_{0}= n/ n\) in multi-armed bandits with asymptotically optimal allocations, \((s_{n,k}/s_{0})=(1+o(1)) s_{n,k}\).

#### 3.1.2 Finite sample bounds for ALEE estimators

One may also construct finite sample confidence intervals for each arm via applying concentration bounds. Indeed, for any arm \(k K\), we have

\[\{_{t=1}^{n}w_{t,k}x_{t,k}\}(_{,k}- _{k}^{*})=_{t=1}^{n}w_{t,k}_{t}.\] (20)

Following the construction of \(w_{t,k}_{t-1}\), the term \(_{t=1}^{n}w_{t,k}_{t}\) is amenable to concentration inequalities if we assume that the noise \(_{t}\) is sub-Gaussian conditioned on \(_{t-1}\), i.e.

\[[e^{_{t}} _{t-1}] e^{_{}^{2}^{2}/2}.\] (21)

**Corollary 3.3** (Theorem 1 in ).: _Suppose the sub-Gaussian noise condition (21) is in force. Then for any \(>0\) and \(_{0}>0\), the following bound holds with probability at least \(1-\)_

\[|_{t=1}^{n}w_{t,k}x_{t,k}||_{,k}-_{k}^{*}|_{}+_{t=1}^{n}w_{t,k }^{2})(+_{t=1}^{n}w_{t,k}^{2}}{^{2} _{0}})}.\] (22)

**Remark 3.4**.: _In the context of multi-armed bandit, by considering the function \(f\) in Corollary 3.2 with \(=1\) and Corollary 3.3 with \(_{0}=1\), we derive that with probability at least \(1-\)_

\[|_{,k}-_{k}^{*}|_{g})}/s_{0})}\{2+(s_{n,k}/s_{0})\}} {}-}}\] (23)

_provided \(s_{0}>1\). See Section A.2 of the Appendix for a proof of this argument. Recall that \(}=(s_{0}+_{i n}x_{i,k}^{2})^{1/2}\), the bound is in the same spirit as existing finite sample bounds for the OLS estimator for arm means . In simple terms, the ALEE estimator behaves similarly to the OLS estimator in a non-asymptotic setting while still maintaining asymptotic normality._

### Autoregressive time series

Next, we focus on an autoregressive time series model

\[y_{t}=^{*}y_{t-1}+_{t}t[n],\] (24)

where \(y_{0}=0\). Note that the above model is a special case of the adaptive linear model (2). It is well-known that when \(^{*}(-1,1)\), the time series model (24) satisfies a stability assumption (1). Consequently, one might use the OLS estimate based confidence intervals  for \(^{*}\). However, when \(^{*}=1\) -- also known as the _unit root_ case -- stability condition (1) does not hold, and the least squares estimator is not asymptotically normal . In other words, when \(^{*}=1\), the least squares based intervals do not provide correct coverage.

In this section, we apply ALEE-based approach to construct confidence intervals that are valid for \(^{*}[-1,1]\). Similar to previous sections, let \(s_{0}_{0}\) and denote \(s_{t}=s_{0}+_{1 i t}y_{i-1}^{2}\). Following a construction similar to the last section, we have the following corollary.

**Corollary 3.5**.: _Assume the noise variables \(\{_{t}\}_{t}\) are i.i.d with mean zero, variance \(^{2}\) and sub-Gaussian parameter \(_{g}^{2}\). Then, for any \(^{*}[-1,1]\), the ALEE estimator, obtained using \(w_{t}=f(s_{t}/s_{0})y_{t-1}/}\) with function \(f\) from Corollary 3.2 and \(s_{0}=n/(n)\), satisfies_

\[}{(s_{n}/s_{0})\{(s_{n}/s_{0 })\}^{1+}}}}(_{}- ^{*})}{}}{{}} (0,1).\] (25)

The proof of Corollary 3.5 can be found in Section A.3 of the Appendix.

### Contextual bandits

In contextual bandit problems, the task of defining adaptive weights that satisfy the stability condition (6) while maintaining a large affinity is challenging. Without loss of generality, we assume that \(\|_{t}\|_{2} 1\). Following the discussion around (11) and using \(_{t}\) as an approximation of \(_{n}\), we see that a good choice for the weight is \(_{t}_{t}^{-}_{t}\). However, it is not all clear at the moment why the above choice produces \(d-\)dimensional weights \(_{t}\) satisfying the stability condition (6). It turns out that the success of our construction is based on the variability of certain matrix \(_{t}\). For a \(_{0}\)-measurable \(d d\) symmetric matrix \(_{0}_{d}\) and \(t[n]\), we define

\[_{t}=_{0}+_{i=1}^{t}_{i}_{i }^{}_{t}=_{t-1}^{-}_{t}.\] (26)

For \(t[n]\), we define the variability matrix \(_{t}\) as

\[_{t}=(_{d}+_{i=1}^{t}_{i}_{i}^{})^{-1}.\] (27)

The variability matrix \(_{t}\) comes up frequently in finite sample analysis of the least squares estimator [16; 19; 2], the generalized linear models with adaptive data , and in online optimization ; see comments after Theorem 3.6 for a more detailed discussion on the matrix \(_{t}\). Now, we define weights \(\{_{t}\}_{t 1}\) as

\[_{t}=_{t}^{}_{t-1}_{t}} _{t}_{t}.\] (28)

**Theorem 3.6**.: _Suppose condition (3) holds and \(\|_{0}^{-1}\|_{}+\|_{n}\|_{}=o_{p}(1)\). Then, the ALEE estimator \(}_{}\), obtained using the weights \(\{_{t}\}_{1 t n}\) from (28), satisfies_

\[(_{t=1}^{n}_{t}_{t})(}_{}-^{*})}{{ }},^{2}_{d}.\]

The proof of Theorem 3.6 can be found in Section A.4 of the Appendix. In Theorem B.4 in the appendix, we establish the asymptotic normality of a modified version of the ALEE estimator, which has the same asymptotic variance as the one in Theorem 3.6 under the assumption \(\|_{0}^{-1}\|_{}=o_{p}(1)\). In other words, the modified theorem B.4 does not assume any condition on the \(\|_{n}\|_{}\).

To better convey the idea of our construction, we provide a lemma that may be of independent interest. This lemma applies to weights \(_{t}\) generated by (27) and (28) with general \(_{t}\).

**Lemma 3.7**.: _Let \(_{t}\) be as in (28) with the variability matrix \(_{t}\) in (27). Then,_

\[_{t=1}^{n}_{t}_{t}^{}=_{d}-_{n},_{1 t n}\|_{t}\|_{2}=_{1 t n}\| _{t-1}_{t}\|_{2}/(1+_{t}^{}_{t-1}_{ t})^{1/2}.\] (29)

_For \(_{t}_{t-1}\), the stability condition (6) holds when \(_{1 t n}_{t}^{}_{t}_{t}+\|_{n}\|_ {}=o_{p}(1)\)._Proof.For any \(t 1\), \(_{t}=_{t-1}-_{t-1}_{t}_{ t}^{}_{t-1}/(1+_{t}^{}_{t-1} _{t})\). It follows that \(_{t}_{t}=_{t-1}_{t}/(1+ _{t}^{}_{t-1}_{t})\) and \(_{t=1}^{n}_{t}_{t}^{}=_{t=1}^{n} _{t-1}(_{t}^{-1}-_{t-1}^{-1})_{t}= _{d}-_{n}\).

Comments on Theorem 3.6 conditions:It is instructive to compare the conditions of Theorem 3.1 and Theorem 3.6. The condition \(\|_{0}^{-1}\|_{}=o_{p}(1)\) is an analogue of the condition \(1/s_{0}=o_{p}(1)\). The condition \(\|_{n}\|_{}=o_{p}(1)\) is a bit more subtle. This condition is an analogue of the condition \(s_{0}/s_{n,k}=o_{p}(1)\). Indeed, applying elliptical potential lemma [2, Lemma 4] yields

\[_{0}+_{n}))}{(( _{0}))}(_{n}^{-1})-d=_{t=1}^{ n}_{t}^{}_{t-1}^{-1}_{t}  2_{0}+_{n}))}{(( _{0}))}\] (30)

where \(_{n}=_{i=1}^{n}_{i}_{i}^{}\) is the Gram matrix. We see that for \(\|_{n}\|_{}=o_{p}(1)\), it is necessary that the eigenvalues of \(_{n}\) grow to infinity at a faster rate than the eigenvalues of \(_{0}\). Moreover, in the case of dimension \(d=1\), the condition \(\|_{n}\|_{}=o_{p}(1)\) is equivalent to \(s_{0}/s_{n,k}=o_{p}(1)\).

## 4 Numerical experiments

In this section, we consider three settings: two-armed bandit setting, first order auto-regressive model setting and contextual bandit setting. In two-armed bandit setting, the rewards are generated with same arm mean \((_{1}^{*},_{2}^{*})=(0.3,0.3)\), and noise is generated from a normal distribution with mean \(0\) and variance \(1\). To collect two-armed bandit data, we use \(\)-Greedy algorithm with decaying exploration rate \(\). The rate is designed to make sure the number of times each armed is pulled has order greater than \((n)\) up to time \(n\). In the second setting, we consider the time series model,

\[y_{t}=^{*}y_{t-1}+_{t},\] (31)

where \(^{*}=1\) and noise \(_{t}\) is drawn from a normal distribution with mean \(0\) and variance \(1\). In the contextual bandit setting, we consider the true parameter \(^{*}\) to be \(0.3\) times the all-one vector. In the initial iterations, a random context \(_{t}\) is generated from a uniform distribution in \(^{d-1}\). Then, we apply \(\)-Greedy algorithm to these pre-selected contexts with decaying exploration rate \(^{2}(t)/t\). For all of the above three settings, we run \(1000\) independent replications.

To analyze the data we collect for these settings, we apply ALEE approach with weights specified in Corollary 3.2, 3.5 and Theorem B.4, respectively. More specifically, in the first two settings, we consider \(=1\) in Corollary 3.2. For two-armed bandit example, we set \(s_{0}=e^{2}(n)\), which is known to be a lower bound for \(s_{n,1}\). For AR(1) model, we consider \(s_{0}=e^{2}n/(n)\). For the contextual bandit example, we consider \(_{0}=(n)_{d}\). In the simulations, we also compare ALEE approach to the normality based confidence interval for OLS estimator  (which may be incorrect), the concentration bounds for the OLS estimator based on self-normalized martingale sequence , and W-decorrelation . Detailed implementations about these methods can be found in Appendix C.1.

In Figure 2, we display results for two-armed bandit example, providing the empirical coverage plots for the first arm mean \(_{1}^{*}\) as well as average width for two-sided CIs. We observe that CIs based on

Figure 2: Two-armed bandit problem with equal arm mean \(_{1}^{*}=_{2}^{*}=0.3\). Error bars plotted are \(\) standard errors.

OLS undercover \(_{1}^{*}\) while other methods provide satisfactory coverage. Notably, from the average CI width plot, we can see that W-decorrelation and concentration methods have relatively large CI widths. On the contrary, ALEE-based CIs achieve target coverage while keeping the width of CIs relatively small.

For AR(1) model, we display the results in Figure 3. For the context bandit example, we consider \(d=20\) and summarize the empirical coverage probability and the logarithm of the volume of the confidence regions in Table 1, along with corresponding standard deviations. See Appendix C.2 for experiments with dimension \(d=10\) and \(d=50\).

## 5 Discussion

In this paper, we study the parameter estimation problem in an adaptive linear model. We propose to use ALEE (adaptive linear estimation equations) to obtain point and interval estimates. Our main contribution is to propose an estimator which is asymptotically normal without requiring any stability condition on the sample covariance matrix. Unlike the concentration based confidence regions, our proposed confidence regions allow for heavy tailed noise variables. We demonstrate the utiltity of our method by comparing our method with existing methods.

Our work leaves several questions open for future research. For example, it would be interesting to characterize the variance of the ALEE estimator compared to the best possible variance[13; 20] for \(d>1\). It would also be interesting to know if such results can be extended to non-linear adaptive models, e.g., to an adaptive generalized linear model . Furthermore, our paper assumes a fixed dimension \(d\) for the problem while letting \(n\). It would be interesting to explore whether we can allow the dimension to grow with the number of samples at a specific rate.

   Method &  \\   & 0.8 &  &  \\   & Avg. Coverage & Avg. Log(Volume) & Avg. Coverage & Avg. Log(Volume) & Avg. Coverage & Avg. log(Volume) \\ ALEE & 0.805 (\(\) 0.396) & 6.541 (\(\) 0.528) & 0.861 (\(\) 0.346) & 7.108 (\(\) 0.528) & 0.910 (\(\) 0.286) & 7.806 (\(\) 0.528) \\ OLS & 0.776 (\(\) 0.417) & -2.079 (\(\) 0.525) & 0.830 (\(\) 0.376) & -1.513 (\(\) 0.525) & 0.881 (\(\) 0.324) & -0.815 (\(\) 0.525) \\ W-Decorrelation & 0.777 (\(\) 0.416) & 25.727 (\(\) 0.518) & 0.829 (\(\) 0.377) & 26.294 (\(\) 0.518) & 0.870 (\(\) 0.336) & 26.992 (\(\) 0.518) \\ Concentration & 1.000 (\(\) 0.000) & 17.374 (\(\) 0.506) & 1.000 (\(\) 0.000) & 17.408(\(\) 0.506) & 1.000 (\(\) 0.000) & 17.455 (\(\) 0.506) \\   

Table 1: Contextual bandit: d = 20

Figure 3: AR(1) with model coefficient \(^{*}=1\) and \(s_{0}=e^{2}n/(n)\). Error bars plotted are \(\) standard errors.