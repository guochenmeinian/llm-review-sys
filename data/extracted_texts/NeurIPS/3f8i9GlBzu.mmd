# Can Transformers Smell Like Humans?

Farzaneh Taleb

Department of Intelligent Systems

KTH Royal Institute of Technology

Stockholm, Sweden

farzantn@kth.se Miguel Vasco

Department of Intelligent Systems

KTH Royal Institute of Technology

Stockholm, Sweden

miguelsv@kth.se Antonio H. Ribeiro

Department of Information Technology

Uppsala University

Uppsala, Sweden

antonio.horta.ribeiro@it.uu.se Marten Bjorkman

Department of Intelligent Systems

KTH Royal Institute of Technology

Stockholm, Sweden

celle@kth.se Danica Kragic

Department of Intelligent Systems

KTH Royal Institute of Technology

Stockholm, Sweden

dani@kth.se

###### Abstract

The human brain encodes stimuli from the environment into representations that form a sensory perception of the world. Despite recent advances in understanding visual and auditory perception, olfactory perception remains an under-explored topic in the machine learning community due to the lack of large-scale datasets annotated with labels of human olfactory perception. In this work, we ask the question of whether pre-trained transformer models of chemical structures encode representations that are aligned with human olfactory perception, i.e., _can transformers smell like humans_? We demonstrate that representations encoded from transformers pre-trained on general chemical structures are highly aligned with human olfactory perception. We use multiple datasets and different types of perceptual representations to show that the representations encoded by transformer models are able to predict: (i) labels associated with odorants provided by experts; (ii) continuous ratings provided by human participants with respect to pre-defined descriptors; and (iii) similarity ratings between odorants provided by human participants. Finally, we evaluate the extent to which this alignment is associated with physicochemical features of odorants known to be relevant for olfactory decoding.

## 1 Introduction

The human brain receives sensory input from the environment and encodes it into a high-dimensional representation space, forming a perception of the world . Recent studies have significantly improved our understanding of the underlying mechanisms of visual, linguistic, and auditory perception . Indeed, there is a significant level of alignment between human response (from neuron to behavior) and activations of deep neural networks when provided with the same stimuli .

Despite these recent advances, human olfactory perception remains an under-explored topic. There is no single organizing principle that determines the dimensions of odor space, making the characterization of odor perception and its relation to chemical compounds an open and complex problem . A lack of universally accepted methods to describe odorants either quantitatively or qualitatively makes this problem even more challenging. There are very few studies that have explored the mapping of chemical structures to olfactory perception [16; 17; 18; 19]. In addition, processing chemical olfactory stimuli using deep neural networks has not been extensively investigated. Nevertheless, training the existing supervised models usually requires an extensive effort by experts to label data.

Transformer-based models [20; 21] are a breakthrough in machine learning, surpassing the need for extensive labeling by utilizing implicit supervision without the necessity for direct labels. These models have demonstrated impressive performance in various tasks such as image , video , and natural language processing . More recently, they have also shown promising results in encoding chemical structures .

In this work, we ask the question of whether representations of odorant chemical structures extracted from transformers pre-trained on chemical structures align with human olfactory perception or, in other words, _can transformers smell like humans_? We employ MoLformer , a state-of-the-art transformer, which is pre-trained on chemical structures and we show that representations of odorants extracted from this model:

* can predict _labels assigned to odorants_ by experts (Section 4.1);
* can predict _continuous perceptual ratings_ provided by human participants (Section 4.2);
* present a high correlation index with _human perceptual similarity ratings_ (Section 4.3);
* present a high correlation index with _physicochemical descriptors_ known to be relevant for olfactory perception (Section 4.4).

Surprisingly these results hold for models that _were not explicitly trained for the purpose of predicting the human olfactory experience_. To the best of our knowledge, we provide the first empirical study on evaluating the alignment between odorant representations encoded by transformers and human olfactory perception.

## 2 Related Work

The availability of larger datasets, together with advances in predictive methods, has led to an increasing interest in the prediction of olfactory perception from molecular structures.

**Olfactory perception prediction.** Learning predictive models of olfactory from molecular structures has been addressed mostly by the neuroscience community. Several works used standard chemoinformatic representations of molecules to model olfactory perception [17; 19; 18]. Specifically, Snitz et al.  proposed a computational framework and algorithm based on structural features of molecules to predict perceptual similarities between odorant pairs. This algorithm leverages feature engineering to identify the most relevant subset of features among 1433 physicochemical descriptors to predict pair-wise odorant perceptual similarities.

Figure 1: **Evaluating representational alignment** between human and pre-trained transformers. Human participants are stimulated with two odorant substances and asked to rate the perceptual similarity between them (Left). We encode representations of the same pair of odorants using MoLFormer and compute the similarity between pairs of representations (Right). Finally, we measure the alignment between the two systems.

Later, Ravia et al.  extended this model to also include the perceived intensity of molecular components. They employed 21 physicochemical descriptors discovered in previous works and proposed a weighting approach for multicomponent odorants (MC-odorants) based on their perceived intensity. They reported a higher correlation when employing the weighting approach compared to using the same model without it. However, the representation and generalization capabilities of these models are quite limited and unexplored.

**Deep neural networks for odorants.** Recently, Lee et al.  proposed a novel representation learning model of odorants, based on a message-passing graph neural network , which they refer to as Principal Odor Map (POM). To train this model, they curated and merged data from Leffingwell  and GoodScent  databases to compile a dataset of about 5000 molecules with 138 expert-labeled odor descriptors. This model outperforms the baselines in multiple odor prediction tasks and shows a relatively high alignment with human ratings in describing odorants. Nevertheless, training this model requires labeled data, relying on subjective evaluations of numerous odorants by experts. Besides being time-consuming and laborious, this process can introduce subjective biases into the model, a concern magnified by our incomplete understanding of the foundational factors of olfactory perception.

**Large-scale molecular models.** Large-scale pre-trained models, often known as foundation models , have been recently explored to perform diverse tasks by leveraging large amounts of unlabeled data. MoLFormer  model has been proposed in the context of chemical prediction tasks, able to extract rich representations from chemical structures. MoLFormer consists of a transformer-based architecture, with linear attention and relative positional encodings. This model is trained using a self-supervised approach, on multiple datasets (e.g., the PubChem  and ZINC  datasets) on a masked token prediction loss.

## 3 Method

In this section, we provide a detailed description of the datasets utilized in this study and outline the methodology for extracting both odorant (machine) and perceptual (human) representations. Additionally, we present the main model and baseline methods employed, along with the evaluation metrics used to assess their performance. Our experiments do not require significant computational resources: we mostly train linear models that do not involve GPU usage or models that can be trained on a single commercially available GPU under one hour. All computational code to reproduce our results is available at [https://github.com/Farzaneh-Taleb/transformer-olfactory-alignment](https://github.com/Farzaneh-Taleb/transformer-olfactory-alignment)

### Datasets

We use the publicly available version of the following datasets provided by Pyrfume repository .

**Leffingwell-Goodscent (GS-LF) [27; 28].** We employ a curated and merged version of the Goodscents  and Leffingwell  datasets, provided by , following the procedure introduced by Lee et al. . This dataset contains 4983 molecules with 138 expert-labeled descriptors (e.g. creamy, grassy), where each odorant may be linked to multiple descriptors.

**Sagar .** This dataset contains the rating of 160 odorants by 3 human participants, with respect to 15+3 perceptual descriptors. In addition to 15 common descriptors among participants, there are 3 more descriptors that vary among them. We excluded these variable descriptors and focused solely on the common descriptors among the participants. The provided ratings were already normalized within the range of [-1, 1] and the mean ratings across all the subjects are computed for subsequent analysis.

**Keller .** This dataset contains ratings of 480 structurally and perceptually diverse molecules by 55 human participants, evaluating 23 descriptors. Participants were instructed to adjust a slider to rate odorants according to individual descriptors, with the slider position subsequently translated into a scale ranging from 0 to 100. Ratings were then averaged across all participants for further analysis.

**Ravia .** This dataset contains similarity ratings of 195 unique pairs of MC-odorants and mono-molecules by 94 participants. The similarity values were averaged across all the participants. In this work, we disregarded the factor of odorant intensity and averaged similarity ratings based on the unique pairs of odorants.

**Snitz .** This dataset includes similarity ratings from 139 participants and 359 unique pairs of odorants. In each trial, participants were presented with two distinct odorants and asked to rate the degree of similarity in their smells. These ratings were then averaged across all participants.

### Odorant representations

Odorants can be described as a single molecule or a mixture of molecules, which we denote as multicomponent odorants (MC-odorants). In this section we describe the method to extract odorant representations from the main pre-trained model (MoLFormer) and our baseline models (DAM and Open-POM).

**MoLFormer.** We employ MoLFormer  to encode SMILES strings associated with a single molecule and extract a 768-dimensional vector from the last layer of the model. SMILES (simplified molecular-input line-entry system) is a string-based representation that encodes relevant chemical information such as the type of atoms, their bonds, and the substructures present in the molecule. For MC-odorants, we average the extracted representations across all available mono-molecule components within that MC-odorant. The odorant representation for each dataset is a matrix of \(X_{i}^{n 768}\) where \(n\) is the number of unique odorants.

**Open-POM.** The principal odor map (POM) is a supervised-learning model, based on a message-passing graph neural network , which is trained on the GS-LF datasets to predict odorant perceptual labels. We employ a publicly available version of this model, which we denote by Open-POM . We train Open-POM for 150 epochs, using 30 different train-test splits, and we extract representations from the penultimate layer of this model. The odorant representation for each dataset is a matrix of \(X_{i}^{n 256}\) where \(n\) is the number of unique odorants. For MC-odorants, we average the representations extracted for each individual molecule within the mixture.

**Distance Angle Model (DAM).** Snitz et al.  proposed a distance angle model (DAM) that uses 21 physicochemical descriptors to predict the similarities between pairs of odorants. We extract these 21 descriptors for each odorant using AlvaDesc  and discard 6 of them due to NaN values produced by this software. We use the remaining subset of 15 physicochemical descriptors out of 21 to measure similarity between odorants or train a linear mapping from them to the perceptual representation space. The odorant representation for each dataset is a matrix of \(X_{i}^{n 15}\) where \(n\) is the number of unique odorants. As suggested by Ravia et al. , we average the representations extracted for each individual molecule within the mixture to compute representations for MC-odorants.

### Perceptual representations

Perceptual representations of odorants are provided by human participants when exposed to odorant stimuli. Perceptual olfactory data were collected in one of the following ways:

1. Experts label the odorants, where each odorant may be linked to multiple labels (e.g., [27; 28]). The perceptual representation is a matrix of \(y_{i}\{0,1\}^{n d}\) where \(n\) is the number of unique odorants and \(d\) is the number of classes.
2. Non-expert participants provided ratings with regards to a set of predefined descriptors (e.g., [33; 34].) In this case, the averaged perceptual representations over participants and replicas form a matrix of \(y_{i}[a,b]^{n d}\), where \(n\) is the number of unique odorants, \(d\) is the number of descriptors, and \(a\) and \(b\) denote the minimum and maximum values participants can use to describe the odorants with respect to these descriptors.
3. Participants evaluated the perceived similarity between pairs of odorants (e.g., [18; 17]). In this case, the averaged perceptual representations over participants and replicas are a vector of \(y_{i}[a,b]^{n 1}\) where \(n\) is the number of unique "pair of odorants" and \(a\) and \(b\) indicate the range of values participants can use to rate the odorants' similarity with respect to the descriptors.

### Alignment between perceptual and odorants representations

We measure the similarity between two representation spaces directly when it is possible (Section 4.3), otherwise we train a linear model to predict perceptual representations for each odorant (Section 4.1, 4.2). We use nested 5-fold cross-validation to tune the hyper-parameters of the linear modelsand assess evaluation metrics on the test set that was held out during the training phase using an 80%-20% train-test split. This process is repeated 30 times using 30 different train-test splits.

### Evaluation metrics

In this section, we introduce the main evaluation metrics to measure the alignment in this paper.

**Micro-averaged ROC-AUC score.** The micro-averaged ROC-AUC score was computed to assess the performance of each model for the multi-label classification task. The micro-averaged ROC-AUC score is computed by aggregating true positive, false positive, true negative, and false negative values across all classes.

**Normalized Root Mean Squared Error (NRMSE).** The root mean squared error (RMSE) is the difference between the observed values and predicted ones for the regression task. Here, we normalize it by the range of true observations - i.e., \(=/((y)-(y))\).

**Pearson Correlation Coefficient (CC).** We report the Pearson correlation coefficient between predicted results and real values. It measures the linear correlation between two sets of data and is the ratio between the covariance of two variables and the product of their standard deviations.

## 4 Results

In this section, we evaluate whether the representations encoded by pre-trained models of chemical data can predict the human olfactory experience _despite not being explicitly trained for this purpose_. First, we focus on a subset of experiments aimed at predicting expert-assigned labels from odorants through linear mapping from representations to perceptual descriptors (Section 4.1). Subsequently, we aim to predict continuous scores provided by human participants (Section 4.2). Finally, we seek to predict the direct similarity scores from the representations extracted from odorants (Section 4.3). Additionally, we provide insights into the potential reasons underlying the observed alignments (Section 4.4).

### Expert-assigned labels classification

To assess the performance of MoLFormer in predicting expert-assigned labels for odorants, we implemented a linear mapping from the representations extracted by MoLFormer to the odorant representations extracted from GS-LF dataset. First, the dimensionality of the extracted representations is reduced to 20 using PCA, followed by z-scoring of each feature. Then, we train individual logistic regression models for each descriptor. This process was repeated 30 times, each with a different train-test split, to quantify the uncertainty of the results.

Figure 2: **ROC curve for linear classifiers trained on GS-LF representations extracted from three different models. Each curve corresponds to a separate test split, with the thicker curve representing the average performance across all splits. We highlight that MoLFormer outperforms DAM, despite not being trained to predict perceptual labels but does not achieve the performance level of Open-POM, which demonstrates the highest performance. The chance level is shown with red dashed line.**

We apply the same procedure without dimensionality reduction to DAM model representations. For the Open-POM model, which is already trained end-to-end and supervised on the same dataset, we directly extracted the predictions for the test set without retraining the model. As shown in Figure 2 the MoLFormer model achieves high ROC-AUC scores in odorant classification, outperforming the DAM model, which is trained using 15 physicochemical descriptors. However, the performance of MoLFormer is lower than that of Open-POM, which is trained end-to-end with supervision on the same dataset.

An additional experiment is conducted to understand the degree of perceptual details captured in the odorant representation space of MoLFormer by comparing odorant representations encoded by this model with the representations encoded by Open-POM. In Figure 3 we depict the first two principal components of the representations. We highlight the similarity between the representations encoded by both Open-POM and MoLFormer and observe that the latter is able to capture the perceptual relationship between different odorants despite not using any perceptual labels during training (unlike the supervised Open-POM Model).

### Continues perceptual rating prediction

To evaluate the capabilities of the MoLFormer model to predict continuous rating scores with respect to pre-defined descriptors, provided by human participants, we train separate linear regression models with regularization applied using the Lasso penalty for each descriptor. Once again, the dimensionality of the extracted representations is reduced to 20 using PCA (for MoLFormer and Open-POM), followed by z-scoring of each feature. This procedure is repeated using 30 different train-test splits.

The results of these experiments are shown in Table 1 and Figure 4. Table 1 shows the average Pearson correlation coefficient and NRMSE across all descriptors, while Figure 4 presents the results for each individual descriptor. As shown in Table 1, overall, none of the models exhibit a high correlation. Nevertheless, MoLFormer slightly underperforms compared to Open-POM in both datasets. However, it performs better than DAM for the Keller dataset but worse than DAM for the Sagar dataset, where DAM even outperforms Open-POM.

Figure 3: **Visualization of odorant representations** encoded by different models on the GS-LF dataset using the figure layout suggested by . We plot the first and second principal components (PCs) of the representation spaces. Areas dense with molecules that have broad category labels (floral, meaty, or ethereal) are shaded, while areas dense with narrow category labels are outlined. MoLFormer captures the perceptual relationship between different odorants in its representation space, despite not being explicitly trained for this purpose.

According to Figure 4 MoLFormer model performs on par with the Open-POM and DAM models, which are trained with supervision in predicting the rating for each descriptor. In summary, although, on average, MoLFormer performs slightly worse than Open-POM, it still demonstrates a similar degree of alignment, especially despite the absence of supervision in its training process.

### Representational similarity analysis

In order to evaluate the direct alignment between the odorant similarities encoded by MoLFormer and those obtained from human participants, we separately encode each odorant by MoLFormer (and the baseline models) and compute the cosine similarity between the extracted representations. Subsequently, we compute the Pearson correlation between the similarity scores computed by the models and those provided by human participants in the Ravia and Snitz datasets. The results are presented in Figure 4(a).

These results show that the MoLFormer is able to extract representations that encode information related to the human olfactory perception, despite not having access to that information during model training. We highlight a significant high correlation between perceptual and odorant representation for the Snitz (\(r=0.64\), \(p<0.0001\)) and Ravia datasets (\(r=0.66\), \(p<0.0001\)).

    &  &  \\   & MoLFormer & Open-POM & DAM & MoLFormer & Open-POM & DAM \\  CC (\(\)) & \(0.20 0.00\) & \(0.22 0.01\) & \(0.17 0.00\) & \(0.25 0.01\) & \(0.29 0.01\) & \(0.35 0.01\) \\ NRMSE (\(\)) & \(0.15 0.00\) & \(0.15 0.00\) & \(0.15 0.00\) & \(0.19 0.00\) & \(0.18 0.00\) & \(0.17 0.00\) \\   

Table 1: **Performance of the models to predict continuous ratings averaged across all perceptual descriptors.** We compute the average Pearson correlation coefficient (CC) and normalized root mean squared error (NRMSE) across all descriptors. MoLFormer shows slightly worse performance than Open-POM but better than DAM for the Keller dataset and worse than DAM for the Sagar dataset, where DAM outperforms Open-POM.

Figure 4: **Performance of the models to predict continuous ratings per descriptor.** We computed Correlation and NRMSE between predicted and actual ratings per perceptual descriptor. Despite not being trained to predict human olfactory labels, the MoLFormer model performs on par with the Open-POM and DAM models.

The comparison with the baseline models indicates that it performs on par with the Open-POM model and significantly outperforms the DAM model. These results suggest that, despite being trained with some form of supervision, these models may struggle to effectively extract similarities between odorants. Additionally, the findings demonstrate that MoLFormer is more proficient at identifying similarities between pairs of odorants than mapping them to a set of predefined descriptors. This superior performance may be due to the model's ability to capture a measure of similarity, as perceived by humans, rather than introducing subjective language bias associated with pre-defined descriptors.

Finally, we aim to evaluate whether the depth of the layer in the MoLFormer model, from which we extract the odorant representations, affects the representational alignment. To assess this, we repeat the described procedure in this section for each layer separately. As shown in Figure 4(b), representational alignment improves with increasing layer depth, indicating that deeper layers of the transformer are more aligned with high-level perceptual representations.

### Decoding relevant physicochemical features from pre-trained representations

To evaluate whether MoLformer effectively extracts features from chemical structures relevant to olfactory perception, we evaluate the alignment of MoLFormer with physicochemical descriptors that are used in the DAM model. To do so, we train 15 linear regression models, each one to predict a single physicochemical descriptor from the extracted representations of the MoLFormer. We subsequently evaluate the correlation between the predicted and true values. As shown in Figure 6, MoLformer demonstrates a high degree of alignment in predicting these values. Out of the 15 physiochemical descriptors, MoLformer successfully predicts the values for 13 descriptors as well as or better than the Open-POM model.

Next, we evaluate whether this alignment changes across the layers of MoLformer. Therefore, we repeat the same procedure for each layer separately. As illustrated in Figure 7, the alignment with the identified chemical features decreases with increasing layer depth. However, as demonstrated in Figure 4(b), the alignment with perception improves. These results collectively are consistent with well-known principles in vision models, where the lower layers typically capture low-level, localized features like edges and textures, while deeper layers gradually shift toward higher-level, abstract representations, such as shapes and objects. Nonetheless, additional investigation is required to fully reveal and comprehend this potential hierarchical structure.

Figure 5: **Representational similarity analysis** for Snitz and Ravia datasets: a) Correlation coefficients between similarity scores provided by human participants and computed using representations encoded by the different models ; b) Correlation coefficients considering odorant representations extracted from different layers of the MoLFormer model.

## 5 Discussion

In this study, we investigated the alignment between odorant representations encoded by the MoL-Former, a self-supervised transformer model pre-trained on chemical structures, and human olfactory perception. We evaluated the alignment between these representations by analyzing the similarity between them or finding a linear mapping between the representations. Additionally, we offered insights into the potential reasons behind the observed alignments by exploring relevant chemical features extracted by the model.

Figure 6: **Performance of the models to predict relevant physicochemical descriptors.** We computed Correlation and NRMSE between the predicted and actual values of descriptors. MoLFormer is able to predict 13 out of 15 physicochemical descriptors related to smell as well as or better than the Open-POM model, demonstrating high alignment with physicochemical descriptors.

Figure 7: **Correlation between the actual and predicted value of physicochemical descriptors** diminishes as the layer depth increases.

**Perceptual prediction from pretrained models**. We demonstrate for the first time that representations extracted from pre-trained large models, solely trained on chemical structures, align closely with the perceptual representations of odorants. This finding suggests that odorant perception can be accurately predicted from chemical structures. Furthermore, we show that this model can predict a subset of physicochemical descriptors known to be relevant to olfactory perception. Together, these results offer valuable predictions for chemists and neuroscientists to explore in future research.

**Evaluating alignment across multiple datasets.** To evaluate alignment from various perspectives, we designed three different experiments. First, we leveraged a dataset with expert-provided labels for odorants, assessing the model's ability to independently predict multi-target binary labels for each odorant. This task did not involve variability from human participants or continuous odorant ratings. MoLFormer exhibited relatively high performance in predicting these binarized labels. Second, we used datasets containing average continuous ratings from human participants, which inherently present more challenges due to variability among non-expert participants' ratings. Our evaluation revealed that while all models performed poorly on this task, MoLFormer performed comparably to supervised models. Lastly, we evaluated direct similarity scores between odorants from two datasets, examining the alignment between human-provided similarity scores and those computed from the representations encoded by models. MoLFormer showed a high alignment, highlighting its ability to predict similarity between odorants rather than relying on human-made descriptors. This suggests that pre-defined descriptors for describing odorants may need to be more carefully chosen, and models trained with these descriptors might not accurately reflect the true similarity between odorants.

**Reduction in alignment with physicochemical descriptors across layers of the models.** We conducted a complementary analysis to identify potential reasons underlying the observed perceptual alignment. Our focus was on the subset of features previously identified as significant for decoding olfactory perception from chemical structures. Our findings indicate that MoLFormer representations exhibit a high degree of alignment with these features. While most features show strong alignment, a few demonstrate less alignment (such as nRCOSR). These results collectively suggest that while these features are important, their significance varies. Additionally, our analysis of the predictability of these features across the different layers of the model shows that as we go through the layers, we observe a decrease in alignment with physicochemical descriptors despite an increase in alignment with perception. This observation aligns well with established principles in vision models, where lower layers have been shown to capture low-level, local features such as edges and textures, while progressively transitioning to align with higher-level, abstract representations, such as shapes and objects, in deeper layers . However, further exploration is needed to fully uncover and understand this potential hierarchy.

**Limitations.** Our work is perhaps best understood in the context of its limitations. We do not directly take into consideration the intensity or concentration of each individual molecule within a mixture during the encoding of odorants. Incorporating these intensity factors in future work could potentially improve the alignment. Additionally, our research was constrained by the available datasets, which typically lack sufficient variations in different odorants, particularly for continuous rating regression tasks. Furthermore, we only considered the average rating scores and did not evaluate the alignment on a per-subject basis.

**Future Work.** We aim to leverage these findings to develop improved models of olfactory perception. Specifically, we plan to utilize unsupervised models trained exclusively on chemical structures to identify which chemical features are crucial for predicting perception, thereby avoiding the introduction of biases from human subjective perception. Additionally, we intend to investigate the mechanisms underlying olfactory perceptions decoded from chemical features. The observed alignment trends across different layers of the model may provide key insights into this process. Finally, evaluating representational alignment between the extracted representations from transformers trained on chemical structures and fMRI data from the brain can provide deeper insights into the underlying mechanisms of olfactory perception.