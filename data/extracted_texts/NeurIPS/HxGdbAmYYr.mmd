# Mixture of Adversarial LoRAs: Boosting Robust Generalization in Meta-Tuning

Xu Yang\({}^{1}\)  Chen Liu\({}^{1}\)  Ying Wei\({}^{2}\)

\({}^{1}\) City University of Hong Kong \({}^{2}\) Zhejiang University

xyang337-c@my.cityu.edu.hk  chen.liu@cityu.edu.hk  ying.wei@zju.edu.cn

Corresponding authors.

###### Abstract

This paper introduces AMT, an **A**dversarial **M**eta-**T**uning methodology, to boost the robust generalization of pre-trained models in the out-of-domain (OOD) few-shot learning. To address the challenge of transferring knowledge from source domains to unseen target domains, we construct the robust LoRAPool by meta-tuning LoRAs with dual perturbations applied to not only the inputs but also singular values and vectors of the weight matrices at various robustness levels. On top of that, we introduce a simple yet effective test-time merging mechanism to dynamically merge discriminative LoRAs for test-time task customization. Extensive evaluations demonstrate that AMT yields significant improvements, up to 12.92% in clean generalization and up to 49.72% in adversarial generalization, over previous state-of-the-art methods across a diverse range of OOD few-shot image classification tasks on three benchmarks, confirming the effectiveness of our approach to boost the robust generalization of pre-trained models. Our code is available at https://github.com/xyang583/AMT.

## 1 Introduction

Few-shot learning (FSL) has recently been revolutionized by large-scale pre-trained vision transformer models . Their generalization capability can be further enhanced with a few annotated examples, achieving impressive performance across a broad spectrum of downstream tasks . Building on this foundation, meta-tuning emerges as a powerful strategy that integrates the broad generalization capabilities of pre-trained prior knowledge with the adaptive flexibility of meta-learning, allowing models to quickly adapt to new tasks in few-shot scenarios .

Despite its success, the robust generalization of meta-tuning to defend against adversarial attacks  and adapt to out-of-distribution (OOD) downstream tasks  remains an ongoing challenge. However, it is crucial for various real-world applications such as medical imaging diagnostics and autonomous driving to simultaneously achieve competitive performance on adversarial examples or out-of-distribution data. Deployed models often encounter novel environments with distribution shifts between training and test data, including variations in hospital equipment and protocols  or diverse urban road scenarios . Moreover, these models are vulnerable to adversarial attacks leading to harmful diagnoses or unsafe driving decisions. For instance, adversaries can perturb sensor signals to deceive 2D or 3D medical imaging models , manipulate traffic signs with malicious stickers , or fool the autopilot into following unsafe trajectories .

In this paper, we delve into leveraging adversarial training and meta-tuning to enhance robust generalization of pre-trained vision transformers across different domains. Compared with previous meta-tuning approaches, this involves two unique aspects. Firstly, when incorporating adversarialexamples, the model should learn to adapt to the worst-case tasks while preserving its inherent generalization capabilities. Inspired by the observation that the singular values distribution of weight parameters undergoes significant changes during fine-tuning , we aim to explicitly strengthen the principal components of pre-trained model weight matrices during meta-tuning. To this end, we inject perturbations on both input and principal singular values and vectors via the incremental meta-update of the Low-rank Adapter (LoRA) [25; 26] on top of frozen pre-trained parameters. Secondly, the adversarial perturbation needs to simulate wide distribution variations from the training environment, and care must be taken to avoid interference when training with multiple perturbation types [27; 28]. Thus, we introduce an adaptive robust LoRAPool constructed by meta-tuning different LoRAs in parallel for different attack strengths. To adapt to novel tasks from unseen distributions, we view the robust LoRAPool as the basis and integrate meta-updated principal components into the pre-trained model through a test-time merging mechanism for downstream task customization.

Our main contributions are summarized as follows:

* We propose AMT, a novel adversarial meta-tuning approach for enhancing the robust generalization of pre-trained vision transformers across diverse domains.
* By injecting the adversarial perturbations on the inputs, singular values and vectors of the weight matrices, the core components of pre-trained model weights are consolidated for worst-case tasks. We further enhance this approach with the adaptive robust LoRAPool meta-tuned under varying perturbation budgets, without compromising the pre-trained model's inherent capabilities.
* We integrate discriminative principle components into the pre-trained model via a simple yet effective test-time merging mechanism for customizing task-specific feature extractors, which is compatible with other test-time fine-tuning methods.
* We experimentally evaluate our method on challenging large-scale out-of-domain few-shot image classification benchmarks, including Meta-Dataset  that consists of 9 OOD datasets, as well as BSCD-FSL  and fine-grained datasets  comprising another 8 OOD datasets. Our method achieves impressive few-shot performance across domains, significantly outperforming previous state-of-the-art methods in clean generalization by up to 12.92% and in adversarial generalization by up to 49.72%.

## 2 Related work

**Out-of-Domain Few-shot Learning and Meta-Learning.** Out-of-Domain Few-Shot Learning (OOD-FSL) aims to transfer prior knowledge learned on source domains to unseen target domains to address the few-shot learning problem [16; 17; 18; 29; 31; 32; 33; 34; 35; 36]. Meta-learning relies on episodic training to learn parameter initialization [37; 38; 39], optimization rule [40; 41; 42] or a transferable metric space [43; 44; 45; 46; 47] as prior knowledge for quick adaptation to new tasks. To tackle distribution shifts, many methods are proposed by building a universal feature representation with multiple feature extractors [32; 31], conditioning batch normalization parameters [48; 30; 33], or test-time gradient-based fine-tuning . Most related to our work is FLUTE , which jointly trains the feature extractor with multiple sets of Feature-wise Linear Modulation (FiLM)  parameters on multiple training datasets and combines them as the initialization for gradient descent at test time. Our method AMT stands in the single source domain setting and differs from previous works in that our adversarial meta-tuning does not compromise the pre-trained model, and the adaptive merging mechanism of the robust LoRAPool performs task customization in a non-parametric manner without the requirement of gradient descent, ensuring scalability with newly added components to the pool.

**Vision Transformers in Few-shot Learning.** Vision Transformers (ViTs) have gained prominence as the foundation model due to their ability to capture long-range dependencies in data [50; 51; 52]. Self-supervised pre-training effectively endows vision transformer with data-driven and well-generalized prior [1; 2; 53; 54], especially for the few-shot learning task. In the spirit of transfer learning, one line of works leverages self-distillation framework to seek universal feature representations without meta-training [55; 56; 57] and directly learns auxiliary visual prompts  and attention scaling matrices  on the support set through gradient descent during meta-testing. Another important research direction is developing meta-learning techniques to enhance pre-trained models with input-conditioned prompts  and task-specific masks . PMF  contributes a strong baseline by meta-tuning the full model. In this work, we also ground our method on pre-trained vision transformers and show that adversarial meta-tuning can further boost their robust generalization across downstream tasks. Also, our contribution is orthogonal to other existing test-time fine-tuning methods and provides a better starting point to improve their performance at test time.

**Adversarial Training for Out-of-Distribution Generalization.** Adversarial training  is one of the most effective defense techniques to improve the model adversarial robustness by minimizing a locally maximized loss function via adversarial perturbation on inputs [13; 60; 61; 62; 63; 64; 65] and model parameters . Despite widely recognized trade-offs between adversarial robustness and clean accuracy [67; 68], and between in-distribution (ID) and out-of-distribution (OOD) generalization [63; 69], there exist strategies to achieve better balances among these trade-offs. These strategies include modified adversarial training regime , dual sets of parameters [70; 71; 72], model ensemble , multi-scale patch perturbations , or partial fine-tuning strategy . Furthermore, since adversarially perturbed input data can be viewed as a special type of OOD data , recent studies [77; 78; 79] have demonstrated that adversarial pre-training can enhance generalization performance on downstream datasets and improve robustness against distribution shifts. Compared with sample-wise adversarial attacks, where all samples in each domain share the universal perturbation, the distributional attacks in a low-rank structure show the capability of making the models resistant against adversarial perturbations of higher magnitude [80; 81] Inspired yet different from the previous attack methods, our method utilizes a mixture of adversarial low-rank adaptors customized for meta-tuning to enhance the robust generalization of clean pre-trained models.

**Adversarial Meta-Learning.** There is a series of works that leverage adversarial training to enhance the few-shot learner's adversarial robustness [14; 15; 82; 83]. However, compared with standard few-shot learning, the adversarially trained model has degraded clean accuracy . Adversarial training is also utilized to improve the cross-domain few-shot learning performance by attacking individual image pixels  and features [85; 86]. For example, StyleAdv  perturbs each sample style in a task through attacking statistical information of AdaIN  and updating all parameters. Our approach diverges from these existing methods, aiming to further enhance the generalization performance of large-scaled pre-trained models. To achieve this, we propose to inject double perturbations on inputs as well as singular values and vectors over the entire query set as a whole during meta-tuning, while keeping all pre-trained parameters frozen to preserve prior knowledge.

**Parameter-Efficient Few-Shot Learning.** To reduce the computational cost associated with full-model fine-tuning, various parameter-efficient fine-tuning (PEFT) methods have been proposed that only update a small set of parameters, including inserting soft prompts [88; 89], adding adapter modules [90; 91; 92], and introducing low-rank matrices [25; 93; 94]. Recent works have shown that PEFT achieves comparable or superior performance than standard fine-tuning in the few-shot setting for large language models . In this work, we explore crafting the small parameter sets via meta-tuning to boost robust generalization of pre-trained vision transformers. Concretely, we leverage LoRA  as the core parameter-efficient component for constructing the adaptive robust pool, as it enables low-rank updates to be merged into network weights without additional computational or memory costs incurred during inference.

## 3 Problem Formulation

In this work, we focus on out-of-domain few-shot image classification where our goal is to find parameters \(\) that generalize well on unseen target domains with the single-source training domain. In this context, the model not only needs to learn novel concepts from limited data but also to generalize well across diverse domains. For each domain, there exists a dataset collected from that environment. During training, we only have access to the single source training dataset \(_{tr}^{}\), from which each task \(=(,)\) is randomly sampled as the input. The support set \(\) contains \(K\) annotated images for each of the \(N\) categories: \(=\{x_{s},y_{s}\}_{s=1}^{NK}\), while the query set \(\) contains \(M\) images \(=\{x_{q},y_{q}\}_{q=1}^{M}\). At evaluation time, the aim is to tackle tasks with novel classes sampled from previously unseen datasets \(_{test}^{}\).

## 4 Methods

We introduce our approach in this section. The overall framework of our AMT is illustrated in Figure 1. It contains two components: (i) adversarial singular value and vector perturbation, which explicitly perturbs the singular values and vectors to highlight the principal components in the worst-case tasks; (ii) Adaptive robust LoRAPool, which consists of several adversarially meta-tuned LoRA modules and test-time merging mechanism to adaptively merge them for task customization.

### Preliminaries

**Adversarial Meta-Tuning**. We ground our method on a large-scale pre-trained Vision Transformer  and then meta-tune the model in an episodic manner , following PMF . To robustify the learned meta-knowledge, adversarial meta-tuning adopts the worst-case optimization by injecting the adversarial perturbation \(\) to the query image \(x_{q}\) through the minimax strategy [14; 15]. The intuition here is to make the meta-tuned model have the same prediction in the worst-case task.

We consider the \(l_{}\) norm bounded perturbations in this work, so the corresponding optimization problem can be formulated as \(_{}_{\|\|_{}} (f_{}(,x_{q}+),y_{q})\) where \(f_{}\) denotes predicted logits of a query example with the model parameters \(\), and \(\) is the meta-task loss, which is usually the cross-entropy loss for image classification. The inner maximization problem can be efficiently solved by gradient-based methods. In practice, Projected Gradient Descent (PGD)  is the most popular method to generate adversarial perturbations \(\). Specifically, when the step size is \(\), PGD optimizes \(\) by running the following update rule for multiple iterations. Here, \(\) is the projection operator to clip \(\) so that \(\|\|_{}\).

\[_{}(+ (_{}(f_{}(,x_{q}+),y _{q}))).\] (1)

**Low Rank Adaptation**. LoRA  is one of the popular parameter-efficient fine-tuning approaches for transformer models. Given a pre-trained weight matrix \(W^{d_{i_{n}} d_{out}}\), LoRA approximates incremental updates to the parameter matrix with a low-rank decomposition \( W=AB\), where \(A^{d_{in} r}\) and \(B^{r d_{out}}\), and the rank \(r(d_{in},d_{out})\). The LoRA approach can be applied to all the linear layers in the vision transformer. For an input \(x\) and a hidden state \(h=Wx\), LoRA modifies forward process as \(h=(W+ W)x=Wx+ABx\). When fine-tuning, \(W\) is frozen while \(A\) and \(B\) are trainable. In addition, \(A\) is randomly initialized via Gaussian initialization while \(B\) is initialized to zero, resulting in the incremental update \(AB=0\) at the beginning.

### Adversarial Singular Value and Vector Perturbation

Drawing inspiration from the insight that the distribution of singular values undergoes significant changes during fine-tuning , we aim to explicitly strengthen the principal components of pre-trained model weight matrices to enhance the model's generalization capability across diverse

Figure 1: **Overview of our method. Adversarial perturbations, bounded by different budgets \(\), are incorporated into the clean query set. To construct the robust LoRAPool, the LoRA modules initialized with SVD results are meta-tuned on the adversarial examples, upon which adversarial perturbations are injected into singular values and vectors. The discriminative incremental updates of principal components are adaptively merged into the pre-trained weights for test-time task customization.**target domains. Using the on-the-fly generated adversarial query samples, we inject the worst-case perturbation on singular values and vectors over the entire query set. However, meta-tuning the full model and performing multiple singular value decomposition (SVD) during training are computationally expensive. To this end, we adopt the LoRA formulation to update model parameters during meta-tuning and initialize the incremental updates of LoRA with the result of SVD of weight matrices for the multi-head self-attention (MHA) layer and feed-forward network (FFN) layer in the vision transformer .

Formally, for a weight matrix \(W^{d_{in} d_{out}}\) and its singular value decomposition \(W=U(S)V^{T}\), where \(U^{d_{in}(d_{in},d_{out})}\), \(V^{d_{out}(d_{in},d_{out})}\) and \(S^{(d_{in},d_{out})}\) represent the left/right singular vectors and the singular values in descending order, respectively. In the LoRA formulation \( W=AB\) with the rank \(r\), the top \(r\) singular values and corresponding vectors are utilized to initialize \(A^{d_{in} r}\) and \(B^{r d_{out}}\), while the residual singular values and vectors are used to calculate the residual matrix \(W^{res}^{d_{in} d_{out}}\) for error correction:

\[ A&=U_{[r]}(S _{[r]}^{1/2})^{d_{in} r}\\ B&=(S_{[r]}^{1/2})V_ {[r]}^{T}^{r d_{out}}\\ W^{res}&=U_{[r]}(S_{[r]} )V_{[r]}^{T}^{d_{in} d_{out}}\] (2)

In Equation (2), we have \(W=W^{res}+AB\). During training, \(W^{res}\) is kept frozen, so the updates of \(A\) and \(B\) in the subspace approximate the modification of principle singular value and vectors.

To boost the generalization performance of the model, we utilize the sharpness-aware minimization (SAM)  to update \(A\) and \(B\). Specifically, we find the worst-case perturbation \(_{A}\) and \(_{B}\) in the neighborhood of \(A\) and \(B\) by gradient ascent. \(_{A}\) is calculated by the following equation where \(M\) is the size of query set and \(_{1}\) depicts the size of the neighbourhood. \(_{B}\) can be calculated similarly.

\[_{A}=_{1}_{q=1}^{M}_{A}(f_{W^{ res}+AB}(,x_{q}^{adv}),y_{q}))\] (3)

Here, we omit other parameters in \(\) for notation simplicity. We then use the gradient based on the worst-case neighborhood to update \(A\) and \(B\). Given the learning rate \(_{2}\), the update rule for \(A\) is as follows. \(B\) is updated similarly using the same learning rate.

\[A A-_{2}_{q=1}^{M}_{A}(f_{ W^{res}+(A+_{A})B}(,x_{q}^{adv}),y_{q}))\] (4)

Different from prior adversarial meta-learning works [14; 15], this paper focuses on improving both the clean accuracy and cross-domain robustness for few-shot learning . The meta-objective function of AMT is the combination of both aspects:

\[=_{CE}(f_{W^{res}+AB}(,x_{q} ),y_{q})+_{adv}D_{}(f_{W^{res}+AB}( ,x_{q}^{adv})\|f_{W^{res}+AB}(,x_{q}))\] (5)

where \(_{CE}\) is the original cross-entropy loss, \(D_{}\) is the Kullback-Leibler divergence and \(_{adv}\) is the trade-off coefficient. Note that here we use few-shot task loss instead of global classification loss in StyleAdv  to generate the adversarial attacks, by which we leverage label randomness to avoid the potential performance degradation caused by true label leaking effect .

### Adaptive Robust LoRAPool Construction

To simulate various distributional shifts for the unseen tasks, we adversarially meta-tune \(P\) LoRA modules in parallel by Equation (4), each corresponding to a different robustness level controlled by the size of the adversarial budget, i.e., \(\) in Equation 1. Therefore, we will obtain a robust LoRAPool composed of \(P\) LoRA modules \(=[A_{1}B_{1},,A_{P}B_{P}]\). Algorithm 1 shows our adversarial meta-tuning pipeline.

**Test-time Merging**. Given several LoRA modules, the challenge in the evaluation time is to adaptively merge these modules in robust LoRAPool into the pre-trained model to fit the new tasks. It is commonly assumed in domain generalization that unseen distributions fall within the convex hull of the training environments [97; 98], so we consider the LoRAs in the pool as the bases and learn a convex combination adapted to the task at hand.

To estimate the coefficient of this combination, we propose blending intra-class compactness and inter-class divergence on the support set as the criterion to extract the most discriminative features for classification. To reduce the computational cost of calculating pair-wise similarity between all support samples, we leverage the class prototype to approximate the cluster center of each class and calculate sample-prototype distances. Formally, for the \(i\)-th LoRA in the pool and the \(c\)-th class out of the total \(N\) classes, we denote the class prototype as the average of per-class support features \(_{i,c}=_{y_{s}=c}_{W^{res}+A_{i}B_{i}}(x_{s})\). The intra-class compactness \(C_{i}\) and the inter-class divergence \(V_{i}\) are then respectively defined as,

\[C_{i}=_{s=1}^{NK}(_{W^{res}+A_{i}B_{i}} (x_{s}),_{i,y_{s}}), V_{i}=_{s =1}^{K}_{c=1\\ c y_{s}}^{N}(_{W^{res}+A_{i}B_{i}} (x_{s}),_{i,c})\] (6)

where \((,)\) denotes the cosine similarity between two feature vectors. After calculating the intra-class compactness and inter-class divergence for each LoRA, the merging coefficient \(_{i}\) for each LoRA module can be estimated as

\[_{i}=_{k}((-(1-( C-(1- V ))))_{i}.}{_{i=1}^{k}_{k}((-(1- ( C-(1-)V)))_{i}.}\] (7)

where \(\) and \(\) stand for smooth and balance factors, respectively. The operation \(_{k}\) before softmax refers to selecting the top \(k\) LoRA modules with the largest score and the rest LoRAs are deactivated for the current task. The merged weight matrix is then calculated as \(W^{}=W^{res}+_{i=1}^{P}_{i}A_{i}B_{i}\). To address the issue of interference stemming from redundant components during merging , we introduce singular value trimming, retaining only the largest top-\(\%\) singular values and resetting the rest to zero to obtain the final task-specific weight \(\):

\[=(W^{})\] (8)

This design provides high expressiveness and flexibility by specifying suitable LoRAs for novel tasks, significantly enhancing the model's adaptation ability to generalize across unseen domains. Algorithm 2 in the Appendix A shows our test-time merging algorithm pipeline.

```
1:Input: Source training domain \(_{tr}^{seen}\); pre-trained weight residual matrix \(W^{res}\); \(P\) sets of attack configuration candidates;
2:Output: Adversarially meta-trained LoRAPool;
3:Initialize adversarial LoRAPool: \(=\{\}\)
4:for\(i=1\)to\(P\) (in parallel)do
5: Sample the \(i\)-th set of \(_{i}\), \(_{i}\) from attack configuration candidates.
6: Initialize the LoRA parameter \(AB\) via Eq. (2);
7:while not converged do
8: Sample a task \(=\{,\}_{tr}^{seen}\).
9: Generate adversarial query set \(_{adv}=\{x_{q}^{adv},y_{q}\}_{q=1}^{M}\) with \(_{i}\), \(_{i}\) via Eq. (1)
10:\(//\) Perturb singular value and vectors
11:\(_{A}=_{1}_{q=1}^{M}_{A}(f_{W^{ res}+AB}(,x_{q}^{adv}),y_{q}))\)
12:\(_{B}=_{1}_{q=1}^{M}_{B}(f_{W^{ res}+AB}(,x_{q}^{adv}),y_{q}))\)
13:\(//\) Update \(AB\) via SGD
14:\(A A-_{2}_{q=1}^{M}_{A}(f_{W^{ res}+(A+_{A})B}(,x_{q}^{adv}),y_{q}))\)
15:\(B B-_{2}_{q=1}^{M}_{B}(f_{W^{ res}+A(B+_{B})}(,x_{q}^{adv}),y_{q}))\)
16:endwhile
17:\(= AB\)
18:endfor ```

**Algorithm 1** Robust LoRAPools

**Network Inference**. After obtaining the task-specific feature extractor through test-time merging, we can employ it directly for inference and perform the nearest-centroid classification . To further improve the few-shot performance in each novel task, our AMT is compatible with other cutting-edge test-time fine-tuning approaches, and thus we introduce a variant AMT-FT, which allows for additional full  or efficient  fine-tuning.

Experiments

We evaluate the effectiveness of the proposed AMT on three cross-domain few-shot image classification benchmarks in Section 5.1. Additionally, we present ablation studies in Section 5.2, conduct a broader analysis in Section 5.3, and compare our approach with other PEFT methods in Section 5.4.

**Experimental setup**. We evaluate AMT using the large-scale cross-domain few-shot classification benchmarks Meta-Dataset , BSCD-FSL  and fine-grained datasets .Note that, in the main experiments, all methods utilize a single model trained on the source domain ImageNet to analyze the trade-offs between robustness and generalization. The details of each benchmark are described in Appendix B.1. And training and evaluation details are included in Appendix B.2. We conduct a comprehensive hyperparameter study in Appendix H.

**Baselines**. We adopt the state-of-the-art PMF  as the meta-tuning baseline method and use ATTNSCALE  as the baseline for an efficient test-time fine-tuning approach. To evaluate our approach against previous adversarial few-shot learning methods, we choose StyleAdv  as the representative. All methods employ a Vision Transformer  which is DINO-pretrained  on ImageNet-1K in our main experiments.

### Comparison with State-Of-The-Art Methods

**Clean OOD-FSL**. In Table 1, we evaluate AMT on Meta-Dataset to investigate its generalization performance on OOD few-shot learning problem in both the \(5\)-way \(1\)-shot and \(5\)-shot settings. We group approaches in two settings. The tuning-free setting does not involve additional training on the support set. We adaptively merge meta-tuned LoRA into pre-trained models via our non-parametric test-time merging mechanism and perform prototype-based classification. Aside from this, the test-time fine-tuning setting allows for training on the support set according to different fine-tuning methods, such as fine-tuning full parameters  or partial parameters . Our proposed method AMT consistently achieves superior performance across all domains in the tuning-free setting, up to **12.92%** on Omniglot, compared with previous state-of-the-art methods. Moreover, thanks to the flexible design of LoRAPool and the meta-learned well-generalized initialization for pre-trained models, AMT demonstrates strong compatibility with advanced fine-tuning approaches, further boosting few-shot learning performance, with the improvements of **3.92%** and **4.3%** over PMF  and ATTNSCALE , respectively. Notably, unlike previous StyleAdv , our robust generalization improvement does not sacrifice the in-domain clean accuracy. We attribute this to our adaptive robust LoRAPool design, which completely inherits the pre-trained knowledge and performs customization by injecting discriminative information for unseen tasks. We take a further comparative analysis on BSCD-FSL  and fine-grained dataset  in Table 2 and under the variable-way-variable-shot setting in Table 18 of Appendix K. The overall performance improvement demonstrates the effectiveness of our method.

**Adversarial OOD-FSL**. We evaluate adversarial robustness under distribution shifts for previous state-of-the-art methods using the PGD-10 attack  in Table 3. We observe that the naturally trained meta-tuning method PM  is not adversarially robust. The style adversarial attack method StyleAdv  is also highly vulnerable to adversarial attacks in most domains and sacrifices nearly seven percentage points in-domain performance. In contrast, our method AMT consistently outperforms previous state-of-the-art methods by a wide margin in terms of both in-domain and out-of-domain robust accuracy, achieving up to **49.72%** on Omniglot. Additionally, our method AMT-FT exhibits synergy with the adversarial test-time fine-tuning strategy, further boosting the in-domain and out-of-domain few-shot adversarial robustness. To take a step further, we measure adversarial robustness against AutoAttack  and unseen attacks under distribution shifts in Table 19 and Table 20 of Appendix M, respectively. The results indicate that AMT consistently boosts adversarial generalization across domains. Intriguingly, as shown in Figure 4 of Appendix L, AMT can also handle natural corruptions under distribution shifts. As a whole, AMT improves the trade-offs between adversarial robustness and clean accuracy [68; 63], as well as between ID and OOD generalization .

### Ablation Study

**Component Analysis**. In Table 4, we demonstrate the effectiveness of various components in our method: adversarial perturbation on query images and singular values and vectors, robust LoRAPool, test-time merging, and singular value trimming. For the method incorporating adversarial perturbation 

[MISSING_PAGE_FAIL:8]

without in-domain compromise. Furthermore, we compare with SAM  and the original LoRA initialization  in Table 9 and Table 10 of Appendix G, where the superior performance validates the efficacy of our adversarial singular value and vector perturbations in boosting the model's generalization capability. See Appendix G for more details. Moreover, in Table 16 of Appendix I, we observe that the simple pixel-level adversarial attacks can effectively simulate larger domain shifts than static data augmentation  and achieve comparable or superior generalization improvements compared to the learnable adversarial transformation method .

### More Analysis

**Alternative Test-time Merging Strategies**. Before finalizing our test-time merging mechanism, we experimented with various design choices. The first idea involves employing a parametric linear classifier to evaluate the compatibility of LoRAs with novel tasks, similar to FLUTE . To train the classifier, we input a batch of adversarial samples, each generated by attacking a different robust LoRA within the pool, to estimate which LoRA generated it. The classifier's mean output on the support set serves as the merging coefficients for a novel task. Additionally, we explored simply averaging LoRA weights or logits, similar to model soups . Appendix E Table 6 compares these alternative strategies using the robust LoRAPool. We see that our AMT, with the introduced intra-class compactness and inter-class divergence criteria, achieves superior overall generalization. In contrast, the linear classifier may not accurately indicate the robustness level of adversarial perturbations based on semantic characteristics. Though logit averaging demonstrates comparable performance, it requires storing all LoRA parameters for extracting query features on each task. Our method merges the LoRAPool into the pre-trained model for adaptation on the support set, maintaining the same amount of parameters for query feature extraction as the baselines [12; 59].

**Compatibility with Other Pre-training Methods**. We evaluate the effectiveness of our AMT across different pre-training regimes on the Meta-Dataset. Previous state-of-the-art methods [12; 58; 59] employ DINO  pre-training on ImageNet, which utilizes the class token for self-distillation learning. We choose iBOT  as the representative approach using patch reconstruction as a proxy task for

    &  &  &  &  &  &  &  \\   & & & & & & & & & & & & & & & & \\  ✗ & ✗ & ✗ & ✗ & ✗ & 65.07 & 59.03 & 38.13 & 76.18 & 61.56 & 57.29 & 56.03 & 80.41 & 55.17 & 54.42 & 60.35 \\ ✓ & ✗ & ✗ & ✗ & ✗ & 64.57 & 62.47 & 38.53 & 76.23 & 60.47 & 57.97 & 56.22 & 81.72 & 57.04 & 53.96 & 60.92 \\ ✓ & ✗ & ✓ & ✓ & ✗ & 65.56 & 63.92 & 39.74 & 76.06 & 61.73 & 58.64 & 55.99 & 80.93 & 56.96 & 54.28 & 61.38 \\ ✓ & ✗ & ✓ & ✓ & ✓ & 64.95 & 70.80 & 40.55 & 75.19 & 60.73 & **59.66** & 56.92 & 83.63 & 57.66 & 56.04 & 62.61 \\ ✓ & ✓ & ✓ & ✗ & ✗ & 67.95 & 62.16 & 39.13 & 79.27 & 61.77 & 58.75 & 56.59 & 79.74 & 55.45 & 54.63 & 61.54 \\ ✓ & ✓ & ✓ & ✓ & ✗ & 68.46 & 65.75 & 42.63 & 79.43 & **63.10** & 58.23 & 55.69 & 78.93 & 63.67 & 56.28 & 63.22 \\  ✓ & ✓ & ✓ & ✓ & ✓ & **68.80** & **71.95** & **42.90** & **79.95** & 62.99 & 59.62 & **59.06** & **85.37** & **63.78** & **57.14** & **65.16** \\   

Table 4: **Component ablation studies on Meta-Dataset in the \(5\)-way \(1\)-shot setting. APQ: adversarial perturbation on query set, APSV: adversarial perturbation on singular values and vectors, RLP: Robust LoRAPool, TTM: test-time merging, STr: singular value trimming.**

    &  &  &  &  \\   & &  &  &  &  &  &  &  &  &  &  &  \\  PM  & - & 23.22 & 7.74 & 5.37 & 22.38 & 25.39 & 1.11 & 12.79 & 24.99 & 2.23 & 10.20 & 13.54 \\ StyleAdv  & - & 16.76 & 15.25 & 5.95 & 17.70 & 25.75 & 1.43 & 14.78 & 30.75 & 3.07 & 9.63 & 14.11 \\ AMT & - & **33.70** & **42.19** & **11.72** & **32.05** & **32.47** & **27.45** & **19.74** & **41.12** & **22.79** & **17.67** & **28.09** \\  PM  & Y & 23.22 & 31.77 & 18.35 & 22.65 & 25.39 & 30.99 & 23.20 & 38.93 & 25.86 & 23.69 & 26.41 \\ AMT-FT & Y & **33.70** & **42.19** & **20.40** & **34.92** & **32.47** & **37.49** & **20.10** & **41.12** & **32.75** & **22.70** & **31.78** \\    &  &  &  &  \\   & &  &  &  &  &  &  &  &  &  &  &  \\  PM  & - & 36.12 & 15.29 & 8.22 & 41.93 & 40.56 & 2.53 & 23.14 & 45.27 & 4.32 & 17.75 & 23.51 \\ StyleAdv  & - & 29.76 & 25.35 & 8.91 & 34.06 & 40.22 & 1.98 & 23.99 & 50.66 & 5.03 & 15.89 & 23.59 \\ AMT & - & **44.69** & **65.01** & **25.10** & **58.51** & **47.82** & **41.72** & **37.70** & **68.54** & **33.41** & **29.84** & **45.23** \\  PM  & Y & 36.12 & 38.43 & 21.07 & 41.93 & 40.56 & 36.51 & 26.72 & 49.83 & 29.89 & 26.47 & 34.75 \\ AMT-FT & Y & **49.62** & **68.62** & **27.26** & **59.37** & **47.82** & **60.62** & **37.70** & **72.06** & **52.70** & **37.44** & **51.32** \\   

Table 3: **Few-shot classification adversarial robust accuracy on Meta-Dataset in the \(5\)-way \(1\)-shot and \(5\)-shot settings. Adv. TTF: adversarial test-time fine-tuning.**self-supervised pre-training, DeIT  for supervised pre-training with strong regularizations and AdvPre  for adversarial pre-training. As shown in Table 7 of Appendix F, AMT achieves average performance improvements of 5.97%, 4.58%, 6.41% and 6.36% over DINO, iBOT, DeIT and AdvPre, respectively, demonstrating its effectiveness across supervised, self-supervised and robust pre-training methods. Intriguingly, we find that AMT significantly enhances the compromised in-domain clean accuracy for the adversarially robust model , even outperforming clean pre-trained models.

### Comparison with Other Parameter-Efficient Fine-Tuning Methods

We compare AMT with other parameter-efficient fine-tuning methods in Table 17 of Appendix J. We observe that single Adapter-based and LoRA-based methods achieve comparable performance in adversarial meta-tuning and outperform full-model and FiLM-based meta-tuning. Besides, the superiority of the FiLM/Adapter Pool over the FiLM/Adapter signifies that our adversarial pool design contributes to the OOD performance without compromising in-domain accuracy. Also, our approach, which incorporates additional perturbation in singular values/vectors and non-parametric test-time merging mechanism utilizing the criteria (i.e., Algorithm 2) that adaptively integrates the LoRAPool into pre-trained weights, enjoys significant performance improvement over FiLM/Adapter Pool. Moreover, unlike the FLUTE-style test-time fine-tuning strategy that requires further tuning of pool components, our framework shows better compatibility with different test-time fine-tuning approaches, including LoRA tuning, full fine-tuning , and attention scaling . More details are included in Appendix J.

## 6 Conclusions and Limitations

This paper introduces AMT employing adversarial meta-tuning to augment the robust generalization for pre-trained vision transformers. Upon generated adversarial query images at various robustness levels, we perturb the singular values and vectors to explicitly reinforce the principal components and maintain a robust LoRAPool containing perturbation-specific low-rank updates. The discriminative meta-updated components in the pool are adaptively selected and merged for customizing the model to adapt to novel tasks through a non-parametric test-time merging mechanism. Extensive experiments have demonstrated that AMT with substantial improvements in robust generalization sets new benchmarks in out-of-domain few-shot image classification tasks. Our analysis also contributes to the deeper understanding of adversarial training advancement in the few-shot setting.

Although LoRAPool has demonstrated effectiveness across different datasets and tasks, one limitation is the need for _manual_ setting of the adversarial budget, particularly the size \(\), for each module. Furthermore, our exploration has been limited to adversarial budgets containing \(l_{}\) bounded perturbations, potentially restricting the ability of our method to model various types of distributional shifts. In our future work, we aim to address these limitations by expanding our exploration to include different types of adversarial perturbations and enhancing the adaptability of our method based on the specific dataset used in meta-tuning.

Figure 2: **Effectiveness of the adversarial perturbation on singular values and vectors. The accuracy on Meta-Dataset in the \(5\)-way \(1\)-shot is reported.**