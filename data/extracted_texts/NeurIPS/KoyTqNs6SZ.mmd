# Learning to Price Homogeneous Data

Keran Chen

UW-Madison

kchen429@wisc.edu

&Joon Suk Huh

UW-Madison

jhuh23@wisc.edu

&Kirthevasan Kandasamy

UW-Madison

kandasamy@cs.wisc.edu

###### Abstract

We study a data pricing problem, where a seller has access to \(N\) homogeneous data points (e.g. drawn i.i.d. from some distribution). There are \(m\) types of buyers in the market, where buyers of the same type \(i\) have the same valuation curve \(v_{i}:[N]\), where \(v_{i}(n)\) is the value for having \(n\) data points. _A priori_, the seller is unaware of the distribution of buyers, but can repeat the market for \(T\) rounds so as to learn the revenue-optimal pricing curve \(p:[N]\). To solve this online learning problem, we first develop novel discretization schemes to approximate any pricing curve. When compared to prior work, the size of our discretization schemes scales gracefully with the approximation parameter, which translates to better regret in online learning. Under assumptions like smoothness and diminishing returns which are satisfied by data, the discretization size can be reduced further. We then turn to the online learning problem, both in the stochastic and adversarial settings. On each round, the seller chooses an _anonymous_ pricing curve \(p_{t}\). A new buyer appears and may choose to purchase some amount of data. She then reveals her type _only if_ she makes a purchase. Our online algorithms build on classical algorithms such as UCB and FTPL, but require novel ideas to account for the asymmetric nature of this feedback and to deal with the vastness of the space of pricing curves. Our algorithms achieve \(}(m)\) regret in the stochastic setting and \(}(m^{}{{2}}})\) regret in the adversarial setting.

## 1 Introduction

Due to the rise in popularity of machine learning, there is an increased demand for data. However, not all users of data have the wherewithal to collect data on their own, and have to rely on data marketplaces to acquire the data they need. For example, a materials data platform (e.g. ), may have collected vast amounts of data from various proprietary sources. Materials scientists in smaller organizations and academia, who do not have large experimental apparatuses, may wish to purchase this data to aid in their research. Similarly, small businesses may wish to purchase customer data for advertising and product recommendations , while small technology companies may wish to purchase data about cloud operations to optimize their computing infrastructure .

**Model.** Motivated by the emergence of such data marketplaces, we study the following online data pricing problem. A seller has access to \(N\) homogeneous data points, (e.g. drawn i.i.d. from some distribution). He wishes to sell the data to a sequence of distinct buyers over \(T\) rounds, and intends to achieve large revenue. There are \(m\) types of buyers in the data marketplace, with all buyers in type \(i\) having the same valuation curve \(v_{i}:[N]\) for the data, where \(v_{i}(n)\) represents the buyer's value for having \(n\) points. As data is homogeneous, we can treat an agent's value as a function of the _amount of data_\(n\) (we will illustrate this in the sequel). Valuation curves are monotone non-decreasing, as more data is better. At each round \(t\), the seller chooses a price curve \(p_{t}:[N]\), where \(p_{t}(n)\) is the price for purchasing \(n\) data points. Then, a buyer with type \(i_{t}\) arrives and purchases an amount of data that maximizes her utility (value minus price), provided that she can achieve non-negative utility. A buyer will reveal her type to the seller _only if_ she makes a purchase, and _only after_ shemakes the purchase. The seller has knowledge of valuation curves of the \(m\) types, but does not know the distribution \(q\) over types (stochastic setting), or the buyer sequence (adversarial setting). Moreover, he cannot practice non-anonymous (discriminatory) pricing, as he needs to choose the pricing curve \(p_{t}\) without knowledge of the buyer's type on that round.

While there is extensive research on _revenue-optimal pricing_ and _learning to price_, data marketplaces merit special attention, both due to their recent emergence and the unique characteristics of data. Typically the number of data \(N\) (number of goods) is very large, but data usually satisfies additional properties such as smoothness (an agent's value does not increase significantly with a small amount of additional data) and diminishing returns (additional data is more valuable when a buyer has less data). To illustrate further, note that two steps are essential to develop an effective online learning solution for data pricing. _(1)_ First, we need to solve the _planning problem_, i.e. find a revenue-optimal pricing curve when the type distribution \(q\) is known. _(2)_ Second, when \(q\) is unknown, we need to combine the algorithm in step (1) with estimates for \(q\) to maximize long-term revenue.

Methods in the existing literature fall short in both steps. _(1)_ When the type distribution \(q\) is known, the data pricing problem resembles an _ordered item pricing_ problem, which is known to be NP-hard . Hence, prior work has aimed at approximating the optimal pricing curves via discretization schemes. Unfortunately, existing discretization schemes have poor, often exponential, dependence on the approximation parameter \(\). However, achieving sublinear regret in online learning requires choosing \(\) that vanishes with longer time horizons, i.e. \( 0\) as \(T\). Therefore, directly using existing discretization schemes in an online setting leads to poor statistical _and_ computational properties of the associated online algorithm. This requires us to leverage the above properties of data to design discretization schemes with better dependence on \(\). _(2)_ While there is prior work on learning optimal prices , these techniques either fall short of addressing the complexities in our setting, or fail to account for the properties of data, and hence do not scale gracefully when the amount of data \(N\) is very large. Moreover, in our online learning setup, the seller faces a trade-off between setting high prices to maximize instantaneous revenue versus setting low prices so as to guarantee a purchase, which results in the buyer revealing their type, which in turn can be helpful in future rounds. Prior work has studied this asymmetric feedback model _only in single-item markets_ which is significantly simpler, and _only in the stochastic setting_.

### Summary of our contributions

Our contributions in this work are threefold: _(1)_ First, in SS3, we develop discretization schemes for revenue-optimal data pricing under a variety of assumptions, which we will use later in our online learning schemes. _(2)_ In SS4, we study learning a revenue-optimal price in a stochastic setting, where the customer types on each round are drawn from a fixed but unknown distribution \(q\). _(3)_ Finally, in SS5, we study online learning when the buyer types are chosen by an oblivious adversary.

**1. Discretization (approximation) schemes for revenue-optimal data pricing.** Assuming only monotonicity, we show that there is a discretization of size \(}((N/)^{m})\) which is an \(()\) additive approximation to any pricing curve. When compared to prior work , our discretization scheme has smaller dependence on \(^{-1}\) when the number of types \(m\) is small (see Table 1). This will be useful, both statistically and computationally, when we study the online setting, as we need to choose \( 0\) as \(T\) to achieve sublinear regret. This is still quite large in real-world data marketplaces, where \(N\) may be very large. Hence, we also study two other assumptions. First, when valuations are smooth, satisfying an \(L\)-Lipschitz-like condition, we construct a discretization of size \(}((L/^{2})^{m})\), which has no dependence on \(N\). Next, under a diminishing returns condition, we construct a discretization of size \((J^{m}^{-3m}^{m}(N))\), which only has polylogarithmic dependence on \(N\).

_Key insights._ We first show that when there are only \(m\) types, for any price function \(p:[N]\), there exists an "\(m\)-step" price function \(p^{}\) whose revenue is at least as much as that of \(p\) on any type distribution \(q\). An \(m\)-step function is non-decreasing and changes values at most \(m\) times, allowing us to focus on this restricted class and thereby reduce the search space when \(m N\). We then consider discretizations of the data space \([N]\) and valuations \(\) which allow us to obtain an \(()\)-approximation to any pricing curve, and then apply this insight to construct our discretizations. Finally, we show that with monotonicity and diminishing returns, similarly accurate approximations are attainable with substantially coarser discretizations.

**2. Learning to price in the stochastic setting.** Next, we turn to the online learning problem described in the beginning in a stochastic setting. On each round, our algorithm computes an upper confidence bound (UCB) [8; 38] on the revenue for each price curve in the discretization previously developed; we then choose the price curve with the highest UCB. As summarized in Table 2, this algorithm achieves a \(}(m)\) bound on the regret for _any_ discretization scheme, including those from prior work. In the stochastic setting, the key advantage of our discretization schemes is computational.

_Key insights._ Both the design and the anlaysis of an algorithm is challenging in this setting due to two reasons: _(i)_ the large size of the discretization and _(i)_ the asymmetric nature of feedback. First, naively maintaining UCBs for each price leads to large confidence intervals, and hence large regret as the size of the discretization is large; instead, we construct confidence intervals on estimates of the type distribution, and translate them to UCBs for the revenue. Second, the asymmetric nature of the feedback places us between bandit and full-information settings. Treating this like a bandit setting would lead to poor, exponential dependence on \(m\) in the regret. However, we are unable to treat this as full information since the type distribution is revealed only if there is a purchase. Handling this asymmetry requires a delicate construction of the UCB.

**3. Learning to price in the adversarial setting.** We study learning in an adversarial setting where the types on each round may be chosen adversarially. Table 2 shows the regret and time complexity of our method when paired with various discretization schemes. In the adversarial setting, our discretization schemes offer both computational and statistical advantages compared to prior work.

_Key insights._ Our algorithm builds on the Follow-the-Perturbed-Leader (FTPL) , originally designed for full-information settings and not directly applicable here. To handle asymmetric feedback, we use the information we have about the valuation curves to keep track of which customers would not have made a purchase given a price curve. If a purchase is made and we observe feedback, we use the usual FTPL update, but if not, we reward each pricing curve with the sum of revenue of all types that would not purchase in that current round.

### Related work

**Dynamic pricing**. The online posted-price mechanism, also known as dynamic pricing, is a central research area in algorithmic market design [19; 33]. In the most classical setting , the seller sets a price for an item in each round, and a buyer purchases the item only if their valuation exceeds the posted price. While several extensions of this setting have been explored for both parametric [12; 20; 28; 29; 32; 46] and non-parametric [11; 17; 39; 40; 44] demands, most focus on single-parameter demands, i.e., selling a single item to buyers. Our data pricing problem is multi-parameter, as demands are parameterized by multiple outcomes, i.e. the number of data points.

**Bayesian unit-demand pricing problem**. Formally, our data pricing problem is a variant of the Bayesian Unit-demand Pricing Problem (BUPP) . BUPP addresses the problem of (offline) revenue maximization over a known distribution of unit-demand buyers, meaning they want to buy at

  Algorithm & Assumptions & Size of discretization & Reference \\  Hartline and Koltun  & – & \(}(2^{N}^{-N})\) & – \\  Chawla et al.  & **M** & \(N^{(^{-2}^{-1})}\) & – \\  Algorithm 1 (ours) & **M, F** & \(}(N^{m}^{-m})\) & Theorem 3.1 \\  Algorithm 5 (ours) & **M, F, S** & \(}(L^{m}^{-2m})\) & Theorem 3.2 \\  Algorithm 2 (ours) & **M, F, D** & \(}(J^{m}^{-3m}^{m}N)\) & Theorem 3.3 \\  

Table 1: Comparison of discretization (approximation) schemes of prior work and our methods under various assumptions. All methods achieve a \(()\) additive approximation to any pricing curve. Here, **M** means **M**onotonicity, **F** means that there are a **F**inite (\(m\)) number of types, **S** means that the valuation curves satisfy a \(L\)-Lipschitz-like **S**moothness condition (Assumption 1), and **D** means that they satisfy a **D**iminishing returns condition (Assumption 2). The \(}\) notation suppresses log dependencies when there is already a polynomial dependence on a parameter. Prior work has exponential dependence in either \(N\) or \(^{-1}\). We wish to do better since _(i)_ typically, the number of data \(N\) is very large and _(ii)_ we need \( 0\) as \(T\) to achieve sublinear regret.

most one item from the inventory. In BUPP, a seller has \(N\) distinct items to sell to a unit-demand buyer whose valuations are \(v=(v_{1},,v_{N})\), where \(v_{i}\) is the value of the \(i\)th item. Given prices \(p_{i},\ i[N]\), the unit-demand buyer purchases a single item \(i[N]\) that maximizes their utility: \(v_{i}-p_{i}\). Assuming the valuation profile \(v\) follows a known distribution \(D\), the goal of BUPP is to find the best prices \(\{p_{i}\}_{i[N]}\) that maximize the seller's expected revenue.

Our data pricing problem is a variant of BUPP in two ways: _(1)_ We study the sequential setting where type distributions are _unknown_, while valuation profiles for each type are known, and _(2)_ We assume monotonic values \(v_{1} v_{N}\), which is natural in data pricing. Unfortunately, BUPP is a computationally intractable problem, as is ours. BUPP is known to be \(\)-hard even when \(D\) is a product distribution . Moreover, even assuming that values are monotonic (i.e., \(v_{1} v_{N}\)), the problem remains (strongly) \(\)-hard . Therefore, we aim to provide a reasonably efficient no-regret algorithm for our problem, especially when the number of types \(m\) is a fixed constant.

The previous works most relevant to our paper are Hartline and Koltun  and Chawla et al. , which study offline revenue maximization for unit-demand buyers. Buyers in our problem are also unit-demand, as each amount of data points can be seen as an individual item. Revenue maximization for unit-demand buyers is known to be computationally intractable , even with ordered (monotonic) buyer values , leading these works to focus on approximation algorithms. Hartline and Koltun  proposed an approximation algorithm with near-linear runtime in the number of buyers, given a fixed number of items. Chawla et al.  introduced a polynomial-time approximation scheme (PTAS) for unit-demand buyers with monotonic values. In this work, we extend the framework to the online setting with partial feedback, which has more practical implications.

In addition, Balcan and Beyhaghi  provide new guarantees for learning revenue-maximizing menus of lotteries and two-part tariffs, demonstrating that their discretization technique yields efficient solutions for specific pricing models. Similar discretization methods could be investigated in future work to potentially improve our approach in more complex data pricing scenarios.

**Market design for data-sharing**. In recent years, there has been a plethora of work devoted to algorithmic market design for data sharing . These works provide ingenious solutions to challenges unique to the data market, such as free replicability and the difficulty of valuation due to the combinatorial nature of data. Except for Agarwal et al. , the above-cited solutions are inherently _offline or single-shot_. While we focus on a simplified yet relevant setting where data comes from a single source, resulting in monotonic valuations, in this work, we tackle the problem in a sequential, dynamic setting, which has practical importance. In contrast to our approach, Agarwal et al.  considered the price to be a constant (i.e., a scalar rather than a price vector) to address the inherent computational intractability of multi-dimensional pricing. Instead, we maintain the price

  Setting & Assumptions & Regret bound & Complexity per iteration & Reference \\   & \(\) & }(m)\)} & \(}(()^{m}T^{}{{2} }})\) &  \\   & \(\) & & & \\   & \(\) & & & \\   & \(\) & }(m^{}{{2}}})\)} & \(}(()^{m}T^{}{{2} }})\) &  \\   & \(\) & & & \\    & \(\) & & & \\   Discretization method & Assumptions & Complexity per iteration & Regret (Adversarial) \\  Hartline and Koltun  & \(\) & \(}(2^{N}^{-N})\) & \(}(m)\) \\  Chawla et al.  & \(\) & \(N^{(^{-2}^{-1})}\) & \(}(mT^{}{{4}}})\) \\  

Table 2: Comparison of regret and time complexity of _our_ online learning methods when paired with our discretization schemes and schemes from prior work. See Table 1 for a description of the assumptions. All methods, including  achieve \((m)\) regret in the stochastic setting.

as a vector (i.e., a price function) but focus on cases where the valuation function satisfies natural properties such as monotonicity, smoothness, and diminishing returns.

## 2 Problem setting, assumptions, and challenges

A seller has \(N\) homogeneous data points. There are \(m\) types of buyers who wish to purchase this data. A buyer of type \(i[m]\) has a valuation curve \(v_{i}:[N]\), where \(v_{i}(n)\) is her value for \(n\) data points. We will assume \(v_{i}(n)\) is non-decreasing as more data is valuable, and further that \(v_{i}(0)=0\).

**Example 1**.: To motivate this model, consider a seller with \(N\) ordered data points \(\{x_{1},,x_{N}\}\), drawn i.i.d. from a distribution \(D\). If a buyer purchases \(n\) points, she receives the first \(n\) points, \(X_{n}=\{x_{1},,x_{n}\}\). Her _ex-post_ value \(_{i}(X_{n})\) may represent the accuracy of her ML model trained with \(X_{n}\). However, as the buyer has not seen the data before the purchase, she does not know which specific points she will receive, and hence her (_ex-ante_) value \(v_{i}(n)=_{X_{n}}[_{i}(X_{n})]\) is the expected model accuracy when \(n\) i.i.d points are drawn from \(D\). The different types could be buyers who use the data for different tasks or models. For instance, with ImageNet's , \(N 1.4\) million data points, different types of buyers could perform different learning tasks such as object detection, identification, and segmentation, and/or train different models such as AlexNet , ResNet , and GoogLeNet . Both empirically and theoretically, for many learning tasks, \(v_{i}(n)\) is non-decreasing, and satisfies additional characteristics such as smoothness and/or diminishing returns.

**Pricing curves, buyer utility, and buyer purchase model.** Let \(p:[N]\) be a pricing curve chosen by the seller. Let \(}{{=}}\{p:[N]:\ p(0)=0\}\) denote the set of all pricing curves. If a buyer purchases \(n\) points, her utility is \(u_{i}(n)=v_{i}(n)-p(n)\). If a buyer can achieve non-negative utility, i.e. \(v_{i}(n) p(n)\) for some \(n[N]\), she will purchase an amount of data to maximize her utility. To fully specify the buyer's purchase model, we will assume that when there are multiple \(n\) which maximizes her utility, she will choose the largest such \(n\). Formally, for a given pricing curve \(p\), a buyer of type \(i\) will purchase \(n_{i,p}\) points where,

\[n_{i,p}}{{=}}\{0& {if $v_{i}(n)<p(n)$ for all $n[N]$,}\\ \{\,_{n[N]}(v_{i}(n)-p(n))\,\} &.\] (1)

_Optimal revenue._ It follows that the revenue from a buyer of type is \(p(n_{i,p})\). Let \(q=(q_{1},,q_{m})\) be the distribution of the buyers. Under this distribution \(q\), the expected revenue \((p)\) for a price curve \(p\), the optimal price \(p^{}\), and the optimal revenue \(\) as follows:

\[(p)}{{=}}_{i=1}^{m}q_{i}  p(n_{i,p}), 28.452756ptp^{}}{{=}}_{p}(p),  28.452756pt}{{=}} (p^{}).\] (2)

We have omitted the dependence on \(q\) in \(\), \(p^{}\), and \(\). There is no closed-form solution to finding the optimal pricing curve, even when \(q\) is known. Therefore, in SS3, we explore discretization methods to approximate \(p^{}\), which will then be used in SS4 and SS5 to develop online learning algorithms. Unfortunately, the size of this discretization can be very large in \(N\) and \(m\) without further assumptions. Therefore, we also consider two additional commonly satisfied conditions by data.

Our first such assumption states that buyer valuation curves satisfy a Lipschitz-like smoothness condition with Lipschitz constant \(L/N\). We use \(L/N\) instead of \(L\) since the number of data has a range \([0,N]\), while the valuations only have a range \(\). This condition states that a buyer's valuation does not change significantly if she only purchases a few additional points.

**Assumption 1** (Smoothness, **S**).: _For all \(n,n^{}[N]\), we have \(v_{i}(n+n^{})-v_{i}(n)n^{}\)._

Our second condition is based on the fact that data typically exhibits diminishing returns . This means that an additional data point is more valuable when there is less data, i.e. \(v_{i}(n+1)-v_{i}(n)\) is decreasing with \(n\). We will in fact make a stronger assumption, and justify it below.

**Assumption 2** (Diminishing returns, **D**).: _There exists some \(J>0\) such that, for all types \(i[m]\), and for all \(n[N]\), we have \(v_{i}(n+1)-v_{i}(n)\)._

Assumption 2 quantifies the rate of decrease of diminishing returns. Following Example 1, the valuation (accuracy) curves for many learning problems take the form \(v_{i}(n)=- n^{-}\); for instance, for binary classification in a VC class \(\), \(\) may be the best accuracy in \(\), \((}})\) where \(d_{}\) is the VC dimension, and \(=1/2\); similarly, for nonparametric regression of a twice differentiable function, \(\) and \(\) are constants while \(=2/5\). In such cases, Assumption 2 is satisfied with \(J=\). Note that neither assumption subsumes the other: a non-concave Lipschitz function will not satisfy Assumption 2, while a suitable \(L\) for a function which satisfies Assumption 2 may need to be very large for Assumption 1 to hold for small \(n\).

### Learning to price in online settings

In this work, we will also study how a seller may learn to maximize revenue. In our learning problem, the seller is aware of the valuation curves \(\{v_{i}\}_{i}\) of each type, but does not know the distribution of types (stochastic setting) or there may be no such distribution (adversarial setting).

**Setup.** The seller repeats the data market for \(T\) rounds. At the beginning of each round, he chooses some price curve \(p_{t}\). _After_ the seller has chosen \(p_{t}\), a new buyer of type \(i_{t}[m]\) appears and purchases \(n_{t}=n_{i_{t},p_{t}}\) amount of data (see (1)). The buyer is aware of her own valuation curve. If she makes a purchase, that is if \(n_{t}>0\), she pays \(p_{t}(n_{t})\) to the seller and reveals her type \(i_{t}\). Otherwise, the buyer will make no payment and not reveal her type.

We have assumed that _a priori_, the seller is aware of the buyer valuation curves \(\{v_{i}\}_{i[m]}\), and that buyers are aware of their own valuation curves. In Example 1, a seller can profile how different machine learning models perform with different amounts of data and publish them ahead of time. The buyers can also gauge their value from these curves, even though they do not have access to the data. Next, we have also assumed that buyers will reveal their type after the purchase. In modern machine learning as a service platforms , buyers directly run their jobs in the seller's computing platform, so the seller can observe the buyers job _type_ directly. Even if this is not the case, sellers can elicit this information via questionnaires and reviews from customers who have made a purchase .

**Challenges.** Despite these assumptions, the learning problem remains challenging for two main reasons. First, the space of price curves is vast: discretizing the valuations in \(\) into \(K\) bins, still leaves \((K^{N})\) possible price curves, which is both statistically and computationally intractable, especially for large \(N\). Second, in addition to the exploration-exploitation trade-off usually encountered in sequential decision-making, the seller faces a tension between high instantaneous revenue and information acquisition: setting high prices can yield high immediate revenue if a purchase occurs, but it also increases the risk of no purchase, resulting in no revenue and crucially no feedback about the buyer type which could help him in future rounds. This trade-off was recently studied for single-item markets in a stochastic setting , but is more complex in our multi-item problem. Moreover, to our knowledge, no existing work addresses this asymmetric feedback model in an adversarial setting, even for single-item markets. Next, we describe the buyer arrival model and define the regret for the learning problem in both stochastic and adversarial settings.

**Stochastic setting.** Here, there is some fixed but unknown distribution of types \(q\). On each round, a buyer of type \(i_{t} q\) is drawn independently. The optimal expected revenue \(\) under type distribution \(q\) is as defined in (2). The regret \(R_{T}\) is as defined below. We wish to design algorithms which have small expected regret \([R_{T}]\), where the expectation accounts for both the sampling of types \(i_{t} q\) and any randomness in the algorithm. We have,

\[R_{T}\ }{{=}}\ T\,-\,_{t=1}^ {T}p_{t}(n_{t})\ =\ T\,-\,_{t=1}^{T}p_{t}(n_{i_{t},p_{t}}).\] (3)

**Adversarial setting.** Here, the types on each round \(\{i_{t}\}_{t=1}^{T}\) are chosen arbitrarily, possibly by an oblivious adversary, ahead of time. The type on round \(t\) is revealed to the seller only at the end of the round, and only if there is a purchase. In the adversarial setting, we define our regret \(R_{T}\) with respect to the single best price in \(\) in hindsight. We wish to design algorithms with small expected regret \([R_{T}]\), where the expectation is with respect to any randomness in the algorithm. We have,

\[R_{T}\ }{{=}}\ _{p}_{t=1}^ {T}p(n_{i_{t},p})\,-\,_{t=1}^{T}p_{t}(n_{i_{t},p_{t}}).\] (4)

**Given:** Approximation parameter \(>0\).

Let \(W\) be discretization of the valuation space \(\) defined as follows,

\[Z_{i} }{{=}}\{(1+)^{i}; \ i\{0,1,,_{1+}\}\},\] \[W_{i} }{{=}}\{Z_{i-1}+Z_{i-1} ;\ \ \ k\{1,2,...,(2+)m\}, W}{{=}}_{i=1}^{_{1+ }}W_{i}.\]

Set \(}\) to be the class of all "\(m\)-step" functions mapping \([N]\) to \(W\).

**Algorithm 1** Price discretization scheme under monotonicity

## 3 Efficient discretization of price curves with small errors

We first study the revenue maximization problem in the offline setting, where the seller knows both the valuation curves \(v_{i},i[m]\), and the type distribution \(q\). Our goal is to design a discretization so as to achieve revenue within a gap of \(()\) from \(\). Before discussing our discretization algorithms, we first show that the optimal pricing curve is "simple" when there are at most \(m\) types.

**Lemma 3.1**.: _Assume there are \(m\) types with non-decreasing value curves \(\{v_{i}\}_{i[m]}\). For any non-decreasing price curve \(p\), there exists an "\(m\)-step" price curve \(\) that yields expected revenue at least that of \(p\) with respect to any distribution over the \(m\) types. Here, \(m\)-step refers to non-decreasing functions \(f:[N]\) where \(f(n+1)-f(n)>0\) in at most \(m\) points (i.e., at most \(m\) jumps)._

Lemma 3.1, proven in Appendix A.1, will be an important tool in all three discretization algorithms of this section. It will allow us to reduce the space of pricing curves as we only need to focus on \(m\)-step price curves. Next, we present our first discretization procedure in Algorithm 1, which only assumes the monotonicity of the valuation curves.

**Discretization scheme under monotonic valuations.** Our discretization procedure, outlined in Algorithm 1, adapts the method in Hartline and Koltun  using Lemma 3.1. For this, we will first construct a discretization \(W\) of the valuation space as follows. Let \(Z_{i}=(1+)^{i}\), \(i=0,1,,_{1+}\) be the powers of \((1+)\) on price space \([,1]\). For each \(i\), we let \(W_{i}\) be a uniform discretization of the interval \([Z_{i-1},Z_{i+1})\) uniformly with gap \(Z_{i-1}\). Finally, let \(W\) be the union of all such \(W_{i}\). According to Lemma 3.1, every price function in \(\) has the same revenue as an \(m\)-step function. We set \(}\) to be all choices of non-decreasing \(m\)-step functions that take value in \(W\). We have the following theorem about Algorithm 1 which we prove in Appendix A.2.

**Theorem 3.1**.: _Consider the discretization \(}\) as constructed in Algorithm 1. For any type distribution, there exists \(p}\) such that \((p)-()\). Moreover, we have \(|}|()^{m}(e (2+)_{1+} )^{m}}(( )^{m})\)._

**Discretization scheme for smooth monotonic valuations.** Due to space constraints, we present our algorithm, under Assumption 1 in Appendix A.4. We have the following theorem about Algorithm 5.

**Theorem 3.2**.: _Consider the discretization \(}\) as constructed in Algorithm 5. Under Assumption 1, for any type distribution, there exists \(p}\) such that \((p)-()\). Moreover, \(|}|(_{1+}^{m} (1/)(L/)^{m})}((})^{m})\)._

**Discretization scheme for monotone valuations under diminishing returns.** Finally, we study discretization schemes under the diminishing returns condition. Our procedure, outlined in Algorithm 2 proceeds as follows. We use the same discretization \(W\) of the valuation space from Algorithm 1. Next, we will discretize the dataspace \([N]\). To exploit the structure in the diminishing returns condition, we will need to do so more densely when \(n\) is small. For this, let \(Y_{i}=}(1+^{2})^{i}\), \(i=0,,_{1+^{2}}}{2Jm}\) be the powers of \((1+^{2})\) on data space \([},N]\). For each \(i\), the set \(Q_{i}\) further partitions the interval \([Y_{i},Y_{i+1})\) uniformly with gap \(Y_{i}}{2Jm}\). For \(n\) smaller than \(}\), we do not discretize it as the valuations may change rapidly when \(n\) is small. Let \(N_{}\) be the union of\(\{1,2,,}\}\) and all the set \(Q_{i}\). Therefore, \(N_{}\) has a size of at most \(}+2Jm_{1+^{2}}}{2Jm}\). We have the following theorem about Algorithm 2 which we prove in Appendix A.5.

**Theorem 3.3**.: _Consider the discretization \(}\) as constructed in Algorithm 2. Under Assumption 2, for any type distribution, there exists \(p}\) such that \((p)-()\). Moreover,_

\[|}|((} )^{m}^{m}(}{Jm})(_{1+ }^{m}1/))}(( })^{m}).\]

Proof outline.: By Lemma 3.1, we may assume the optimal price curve \(p^{}=\{(n_{i}^{},p_{i}^{})\}_{i=1}^{m}\) is an \(m\)-step function, where \(p_{i}^{}\) denote the value of \(p\) on step \(i\). We generate an \(m\)-step price curve \(p=\{(n_{i},p_{i})\}_{i=1}^{m}\) on space \(N_{} W\) such that \(n_{i}\) is obtained by rounding down \(n_{i}^{}\) to the closest value in \(N_{}\), and \(p_{i} p_{i}^{}/(1+)\). We then show that if a buyer purchases at step \(i\) under price \(p^{}\), she will not purchase at step \(j<i\) under new price \(p\). Therefore, the revenue from this buyer is at least \(p_{i} p_{i}^{}/(1+)=p_{i}^{}-()\), which ensures that \((p)-()\).

## 4 Online learning in the stochastic setting

We now study the online learning problem outlined in SS2.1 in the stochastic setting. Our Algorithm, outlined in Algorithm 3 is based on the classical upper confidence bound (UCB) algorithm for stochastic bandits [8; 38]. It takes a discretization \(}\) of the pricing curves as input, and on each round chooses a \(p_{t}}\) which has the largest UCB on the revenue.

The key challenge lies in constructing an UCB. As \(}\) is large, naively constructing UCB over prices in \(}\) will lead to a \(}|T T}\) upper bound, leading to poor, exponential dependence on \(m\). This is the bound if we only observe the reward for the prices that are actually pulled, but do not observe the types after purchase. Therefore, naively applying UCB is like bandit feedback. On the other extreme, had we been in an alternative setting where we observe the type regardless of purchase, this is like a full information feedback because once observe the type, we know the revenue for all prices. Then UCB gives us \(}|)T T}\) upper bound. We are in an intermediate regime between bandit feedback and full information: The challenge in constructing the UCB arises because we only observe types upon purchase. As the key unknown is the type distribution, we maintain UCBs for it and translate them to UCBs for the revenue. In particular, our UCB depends on how many times a buyer _could_ have purchased at a given round, which is a random quantity depending on the algorithm itself.

Construction of UCB.We will now show how to construct the upper confidence bound \(}_{t}\) at the end of round \(t\), which will be used in computing \(p_{t+1}\). For \( t\), let \(S_{}\), defined below in (5), be the set of types who would have purchased in round \(\) at price \(p_{}\) had they appeared in that round. Then, for any type \(i[m]\), we define \(T_{i,t}\) to be the number of times that type \(i\) appears in set \(S_{}\) for \(\{1,,t\}\). That is, \(T_{i,t}\) measures the number of times a buyer of type \(i\) would have purchased during the first \(t\) rounds. We have,

\[S_{}}{{=}}i[m]: n[N],v_ {i}(n)-p_{}(n) 0}, T_{i,t}}{{=}} _{=1}^{t}(i S_{}).\] (5)

Note that as we use the \(0\) price function on round 1, i.e. \(p_{1}()=0\), we have \(T_{i,t}>0\) for all \(t>1\). Next, we estimate \(q_{i}\) via the fraction of times that type \(i\) has appeared in the past \(t\) rounds, provided that \(i S_{}\) for \(\{1,,t\}\). We have defined this quantity, \(_{i,t}\) below in (6). Via a standard application of Hoeffding's inequality, we can show that \(q_{i}-_{i,t}}\) with high probability. Using this, we can construct an upper confidence bound \(_{i,t}\) as follows,

\[_{i,t}}{{=}}} _{=1}^{t}(i S_{},i_{}=i),_{i, t}}{{=}}_{i,t}+}}.\] (6)

We now translate the UCBs on \(q\) to the UCBs on the revenue. Recall from (1) that a buyer of type \(i\) will purchase \(n_{i,p}\) points at price \(p\) and the revenue from this buyer will be \(p(n_{i,p})\). Note that as the seller has access to the valuation curves, he can compute \(n_{i,p}\) for any \(i\) and price curve \(p\). Since \((p)=_{i q}[p(n_{i,p})]\), we have the following natural UCB for \((p)\) on round \(t\):

\[}_{t}(p)\ }{{=}}\ _{i=1}^{m}_{i,t} p(n_{i,p}).\] (7)

This completes the description of our construction. The following theorem bounds the regret for Algorithm 3 when paired with any of the discretization schemes in SS3. While the computational complexity of our method depends on \(||\), there is no dependence on the regret because of the above construction of the UCB. The proof is given in Appendix C.

**Theorem 4.1**.: _Suppose in Algorithm 3 we use a discretization \(}\) which is a \((1/)\) additive approximation to any price curve. Then, the regret of Algorithm 3 satisfies \([R_{T}]}(m)\)._

Proof challenges.: When bounding the regret, we first observe that the subsets \(S[m]\) induces a partitioning of the price curves, where \(p\) belongs to the partition of \(S\), if all types in \(S\) would make a purchase at price \(p\), and all types in \(S^{c}\) would not make a purchase at price \(p\). With this insight, we can view the action of a seller as not just choosing a price curve, but also choosing a set \(S_{t}[n]\). That is, \(S_{t}\) can be viewed as a super-arm in a combinatorial semi-bandit problem .

## 5 Online learning in the adversarial setting

We now study the adversarial setting. Similar to the stochastic setting, our algorithm will use a discretization of the price curves from SS3. We will control regret by bounding both the discretization error and the algorithm's regret relative to the best pricing curve in the discretization.

Before proceeding, let us first contextualize our feedback model against prior work. If the buyers do not reveal their types, this becomes an adversarial bandit problem with \(|}|\) arms (pricing curves) . Using an algorithm such as EXP-3  results in large \(}(T^{}{{2}}}|}|^{ }{{2}}})\) regret, which is not ideal due to \(|}|\)'s exponential dependence in \(m\). Conversely, if buyers reveal their types regardless of purchase,this is equivalent to full information feedback, where algorithms such as Hedge or Follow-the-perturbed-leader (FTPL)  yield \((T^{}{{2}}}^{}{{2}}}|} |)\) regret, translating to \(}((mT)^{}{{2}}})\) with our discretization schemes in SS3. In our intermediate regime, where feedback is only revealed upon purchase, we aim for a middle ground. We show our algorithm, outlined in Algorithm4, achieves \(}(m^{3/2}T^{}{{2}}})\) regret, which is worse than full information, but still depends polynomially on \(m\).

Our algorithm takes a discretization \(}\) and a perturbation parameter \(\) as input. First, it samples a random perturbation \(_{p}\) from an exponential distribution with pdf \( e^{- x}\) for each pricing curve \(p\) in \(}\). It maintains rewards \(\{r_{t}(p)\}_{t,p}\) for each round \(t\) and price curve \(p\). On each round, it chooses the price curve that maximizes the perturbed cumulative reward \(_{=1}^{t}r_{}(p)+_{p}\).

This scheme is similar to FTPL, but the key difference is in how we design the rewards \(\{r_{t}(p)\}_{t,p}\). To describe this, let \(S_{t}\), defined exactly as in (5), be the set of agents who would have purchased in round \(t\) at price \(p_{t}\). At the end of the round, if there was a purchase, for all prices \(p}\), we set the reward to be \(r_{t}(p)=p(n_{i_{t},p})\), i.e. the payment we would have received from the buyer at that round, had the price been \(p\) (see (1)). If there was no purchase, we know that \(i_{t} S_{t}\), in which case we set \(r_{t}(p)=_{i S_{t}^{c}}p(n_{i,p})\). In this case, \(r_{t}(p)\) is an upper bound on \(p(n_{i_{t},p})\), and this upper bound is tight around prices similar to the chosen price \(p_{t}\); in fact, \(r_{t}(p_{t})=0\) if there was no purchase. Intuitively, \(r_{t}(p)\) deals with the uncertainty of not knowing the type on round \(t\) by providing a large reward (as we are taking the sum) to prices that _could have_ resulted in a purchase, which encourages exploration of such prices in future rounds. This intuition will help us bound the regret.

Theorem5.1 provides a bound on the regret for Algorithm4. Its proof is given in AppendixB. Combining this with the size of \(}\) under the various assumptions in SS3, we obtain \(}(m^{}{{2}}})\) regret.

**Theorem 5.1**.: _Suppose in Algorithm4 we use a discretization \(}\) which is a \((1/)\) additive approximation to any price curve. Let \(R_{T}\) be as defined in (4). Then, for Algorithm4, we have \([R_{T}]\ \ (m^{2} T+^{-1}(1+ |}|))\). Setting \(=}|}{m^{2}T}}\), we have \([R_{T}]\ \ m}|}\)._

## 6 Conclusion and Discussion

We designed revenue-optimal learning algorithms for pricing data. First, we leveraged properties like smoothness and diminishing returns to create novel discretization schemes for approximating any pricing curve. These schemes were then used in our learning algorithms to improve their statistical and computational properties. Our algorithms build on classical methods like UCB and FTPL but required significant adaptations to handle the vast space of pricing curves and the asymmetric feedback. An interesting future direction would be to relax the assumption that the seller knows the valuation curves \(v_{i}\).

Computational complexity.Our algorithm is designed to achieve polynomial computational complexity with respect to the number of data points when the number of types is fixed, making it suitable for practical data pricing scenarios where the type count is typically small or bounded. While the overall computational cost grows exponentially with the number of types due to the problem's strong NP-hardness (see ), this design choice ensures computational feasibility in settings with large datasets and a limited number of types.