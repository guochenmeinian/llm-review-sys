# Equivariant flow matching

Leon Klein

Freie Universitat Berlin

leon.klein@fu-berlin.de &Andreas Kramer

Freie Universitat Berlin

andreas.kraemer@fu-berlin.de &Frank Noe

Microsoft Research AI4Science

Freie Universitat Berlin

Rice University

franknoe@microsoft.com

###### Abstract

Normalizing flows are a class of deep generative models that are especially interesting for modeling probability distributions in physics, where the exact likelihood of flows allows reweighting to known target energy functions and computing unbiased observables. For instance, Boltzmann generators tackle the long-standing sampling problem in statistical physics by training flows to produce equilibrium samples of many-body systems such as small molecules and proteins. To build effective models for such systems, it is crucial to incorporate the symmetries of the target energy into the model, which can be achieved by equivariant continuous normalizing flows (CNFs). However, CNFs can be computationally expensive to train and generate samples from, which has hampered their scalability and practical application. In this paper, we introduce equivariant flow matching, a new training objective for equivariant CNFs that is based on the recently proposed optimal transport flow matching. Equivariant flow matching exploits the physical symmetries of the target energy for efficient, simulation-free training of equivariant CNFs. We demonstrate the effectiveness of flow matching on rotation and permutation invariant many-particle systems and a small molecule, alanine dipeptide, where for the first time we obtain a Boltzmann generator with significant sampling efficiency without relying on tailored internal coordinate featurization. Our results show that the equivariant flow matching objective yields flows with shorter integration paths, improved sampling efficiency, and higher scalability compared to existing methods.

## 1 Introduction

Generative models have achieved remarkable success across various domains, including images , language , and applications in the physical sciences . Among the rapidly growing subfields in generative modeling, normalizing flows have garnered significant interest. Normalizing flows  are powerful exact-likelihood generative neural networks that transform samples from a simple prior distribution into samples that follow a desired target probability distribution. Previous studies  have emphasized the importance of incorporating symmetries of the target system into the flow model. In this work, we focus specifically on many-body systems characterized by configurations \(x^{N D}\) of \(N\) particles in \(D\) spatial dimensions. The symmetries of such systems arise from the invariances of the potential energy function \(U(x)\). Theassociated probability distribution, known as the Boltzmann distribution, is given by

\[(x)T})}, \]

where \(k_{B}\) represents the Boltzmann constant and \(T\) denotes the temperature.

Generating equilibrium samples from the Boltzmann distribution is a long-standing problem in statistical physics, typically addressed using iterative methods like Markov Chain Monte Carlo or Molecular Dynamics (MD). In contrast, Boltzmann generators (BGs)  utilize normalizing flows to directly generate independent samples from the Boltzmann distribution. Moreover, they allow the reweighting of the generated density to match the unbiased target Boltzmann distribution \(\). When dealing with symmetric densities, which are ubiquitous in physical systems, BGs employ two main approaches: (i) describing the system using internal coordinates [8; 20] or (ii) describing the system in Cartesian coordinates while incorporating the symmetries into the flow through equivariant models . In this work, we focus on the latter approach, which appears more promising as such architectures can in principle generalize across different molecules and do not rely on tailored system-specific featurizations. However, current equivariant Boltzmann generators based on continuous normalizing flows (CNFs) face limitations in scalability due to their high computational cost during both training and inference. Recently, flow matching  has emerged as a fast, simulation-free method for training CNFs. A most recent extension, optimal transport (OT) flow matching , enables learning optimal transport maps, which facilitates fast inference through simple integration paths. In this work, we apply OT flow matching to train flows for highly symmetric densities and find that the required batch size to approximate the OT map adequately can become prohibitively large (Figure 1c). Thus, the learned flow paths will deviate strongly from the OT paths (Figure 1d), which increases computational cost and numerical errors. We tackle this problem by proposing a novel _equivariant_ OT flow matching objective for training equivariant flows on invariant densities, resulting in optimal paths for faster inference (see Figure 1e,f).

Our main contributions in this work are as follows:

1. We propose a novel flow matching objective designed for invariant densities, yielding nearly optimal integration paths. Concurrent work of  proposes nearly the same objective with the same approximation method, which they also call equivariant flow matching.

Figure 1: Results for the 13 particle Lennard-Jones system (LJ13) for different flow matching training methods. (a, b) Sample pairs generated with the different flow matching objectives during training. (c) Mean transport cost (squared distance) for training batches. (d, e) Integration paths per particle for samples generated by models trained with OT flow matching and equivariant OT flow matching, respectively. (f) Integration path length, i.e. arc length between prior and output sample, distribution compared with the OT path length between the prior and push-forward distribution of the flows.

2. We compare different flow matching objectives to train equivariant continuous normalizing flows. Through our evaluation, we demonstrate that only our proposed equivariant flow matching objective enables close approximations to the optimal transport paths for invariant densities. However, our proposed method is most effective for larger highly symmetric systems, while achieving sometimes inferior results for the smaller systems compared to optimal transport flow matching.
3. We introduce a new invariant dataset of alanine dipeptide and a large Lennard-Jones cluster. These datasets serve as valuable resources for evaluating the performance of flow models on invariant systems.
4. We present the first Boltzmann Generator capable of producing samples from the equilibrium Boltzmann distribution of a molecule in Cartesian coordinates. Additionally, we demonstrate the reliability of our generator by accurately estimating the free energy difference, in close agreement with the results obtained from umbrella sampling. Concurrent work of  also introduce a Boltzmann Generator, based on coupling flows instead of CNFs, in Cartesian coordinates for alanine dipeptide. However, they investigate alanine dipeptide at \(T=800K\) instead of room temperature.

## 2 Related work

Normalizing flows and Boltzmann generators  have been applied to molecular sampling and free energy estimation [25; 20; 26; 27; 28]. Previous flows for molecules only achieved significant sampling efficiency when employing either system-specific featurization such as internal coordinates [8; 29; 25; 20; 30; 31] or prior distributions close to the target distribution [32; 31; 33]. Notably, our equivariant OT flow matching method could also be applied in such scenarios, where the prior distribution is sampled by MD at a different thermodynamic state (e.g., higher temperature or lower level of theory). A flow model for molecules in Cartesian coordinates has been developed in  where a transferable coupling flow is used to sample small peptide conformations by proposing iteratively large time steps instead of sampling from the target distribution directly. Equivariant diffusion models [35; 36] learn a score-based model to generate molecular conformations. The score-based model is parameterized by an equivariant function similar to the vector field used in equivariant CNFs. However, they do not target the Boltzmann distribution. As an exception,  propose a diffusion model in torsion space and use the underlying probability flow ODE as a Boltzmann generator. Moreover,  use score-based models to learn the transition probability for multiple time-resolutions, accurately capturing the dynamics.

To help speed up CNF training and inference, various authors [39; 40; 41] have proposed incorporating regularization terms into the likelihood training objective for CNFs to learn an optimal transport (OT) map. While this approach can yield flows similar to OT flow matching, the training process itself is computationally expensive, posing limitations on its scalability. The general idea underlying flow matching was independently conceived by different groups [21; 42; 43] and soon extended to incorporate OT [22; 44]. OT maps with invariances have been studied previously to map between learned representations , but have not yet been applied to generative models. Finally, we clarify that we use the term flow matching exclusively to refer to the training method for flows introduced by Lipman et al.  rather than the flow-matching method for training energy-based coarse-grained models from flows introduced at the same time .

## 3 Method

In this section, we describe the key methodologies used in our study, highlighting important prior work.

### Normalizing flows

Normalizing flows [14; 47] provide a powerful framework for learning complex probability densities \((x)\) by leveraging the concept of invertible transformations. These transformations, denoted as \(f_{}:^{n}^{n}\), map samples from a simple prior distribution \(q(x_{0})=(x_{0}|0,I)\) to samples from a more complicated output distribution. This resulting distribution \(p(x_{1})\), known as the _push-forward_

[MISSING_PAGE_FAIL:4]

where \(p(z)\) is some arbitrary conditioning distribution independent of \(x\) and \(t\). For a derivation see  and . There are different ways to efficiently parametrize \(u_{t}(x|z)\) and \(p_{t}(x|z)\). We here focus on a parametrization that gives rise to the optimal transport path, as introduced in 

\[z =(x_{0},x_{1}) p(z)=(x_{0},x_{1}) \] \[u_{t}(x|z) =x_{1}-x_{0} p_{t}(x|z)=(x|t x _{1}+(1-t) x_{0},^{2}), \]

where the conditioning distribution is given by the 2-Wasserstein optimal transport map \((x_{0},x_{1})\) between the prior \(q(x_{0})\) and the target \((x_{1})\). The 2-Wasserstein optimal transport map is defined by the 2-Wasserstein distance

\[W_{2}^{2}=_{} c(x_{0},x_{1})(dx_{0},dx_{1}), \]

where \(\) is the set of couplings as usual and \(c(x_{0},x_{1})=||x_{0}-x_{1}||_{2}^{2}\) is the squared Euclidean distance in our case. Following , we approximate \((x_{0},x_{1})\) by only considering a batch of prior and target samples. Hence, for each batch we generate samples from \(p(z)\) as follows:

1. sample batches of points \((x_{0}^{1},,x_{0}^{B}) q\) and \((x_{1}^{1},,x_{1}^{B})\),
2. compute the cost matrix \(M\) for the batch, i.e. \(M_{ij}=||x_{0}^{i}-x_{1}^{j}||_{2}^{2}\),
3. solve the discrete OT problem defined by \(M,\)
4. generate training pairs \(z^{i}=(x_{0}^{i},x_{1}^{i})\) according to the OT solution.

We will refer to this training procedure as _OT flow matching_.

### Equivariant flows

Symmetries can be described in terms of a _group_\(G\) acting on a finite-dimensional vector space \(V\) via a matrix representation \((g);g G\). A map \(I:V V^{}\) is called \(G\)-invariant if \(I((g)x)=I(x)\) for all \(g G\) and \(x V\). Similarly, a map \(f:V V\) is called \(G\)-equivariant if \(f((g)x)=(g)f(x)\) for all \(g G\) and \(x V\).

In this work, we focus on systems with energies \(U(x)\) that exhibit invariance under the following symmetries: (i) _Permutations_ of interchangeable particles, described by the symmetric group \(S(N^{})\) for each interchangeable particle group. (ii) _Global rotations and reflections_, described by the orthogonal group \(O(D)\) (iii) _Global translations_, described by the translation group \(\). These symmetries are commonly observed in many particle systems, such as molecules or materials.

In , it is shown that equivariant CNFs can be constructed using an equivariant vector field \(v_{}\) (Theorem 2). Moreover, [17; 50] show that the push-forward distribution \((x_{1})\) of a \(G\)-equivariant flow with a \(G\)-invariant prior density is also \(G\)-invariant (Theorem 1). Note that this is only valid for orthogonal maps, and hence not for translations. However, translation invariance can easily be achieved by assuming mean-free systems as proposed in . An additional advantage of mean-free systems is that global rotations are constrained to occur around the origin. By ensuring that the flow does not modify the geometric center and the prior distribution is mean-free, the resulting push-forward distribution will also be mean-free.

Although equivariant flows can be successfully trained with the OT flow matching objective, the trained flows display highly curved vector fields (Figure 1d) that do not match the linear OT paths. Fortunately, the OT training objective can be modified so that it yields better approximations to the OT solution for finite batch sizes.

## 4 Equivariant optimal transport flow matching

Prior studies [51; 22] indicate that medium to small batch sizes are often sufficient for effective OT flow matching. However, when dealing with highly symmetric densities, accurately approximating the OT map may require a prohibitively large batch size. This is particularly evident in cases involving permutations, where even for small system sizes, it is unlikely for any pair of target-prior samples \((x_{0},x_{1})\) to share the exact same permutation. This is because the number of possible permutations scales with the number of interchangeable particles as \(N!\), while the number of combinations of the sample pairs scales only with squared batch size (Figure 1). To address this challenge, we propose using a cost function

\[(x_{0},x_{1})=_{g G}||x_{0}-(g)x_{1}||_{2}^{2}, \]that accurately accounts for the underlying symmetries of the problem in the OT flow matching algorithm. Hence, instead of solely reordering the batch, we instead also align samples along their orbits.

We summarize or main theoretical findings in the following theorem.

**Theorem 1**.: _Let \(G\) be a compact group that acts on an Euclidean \(n\)-space by isometries. Let \(T x y\) be an OT map between \(G\)-invariant measures \(_{1}\) and \(_{2}\), using the cost function \(c\). Then_

1. \(T\) _is_ \(G\)_-equivariant and the corresponding OT plan_ \((_{1},_{2})\) _is_ \(G\)_-invariant._
2. _For all pairs_ \((x,T(x))\) _and_ \(y G T(x):\)__ \[c(x,T(x))=_{G}c(g x,g T(x))d(g)=_{g G}c(x,g y)\] (14)
3. \(T\) _is also an OT map for the cost function_ \(\)_._

Refer to Appendix B.1 for an extensive derivation and discussion. The key insights can be summarized as follows: (i) Given the \(G\)-equivariance of the target OT map \(T\), it is natural to employ an \(G\)-equivariant flow model for its learning. (ii) From 2. and 3., we can follow that our proposed cost function \(\), effectively aligns pairs of samples in a manner consistent with how they are aligned under the \(G\)-equivariant OT map \(T\).

In this work we focus on \(O(D)\)- and \(S(N)\)-invariant distributions, which are common for molecules and multi-particle systems. The minimal squared distance for a pair of points \((x_{0},x_{1})\), taking into account these symmetries, can be obtained by minimizing the squared Euclidean distance over all possible combinations of rotations, reflections, and permutations

\[(x_{0},x_{1})=_{r O(D),s S(N)}||x_{0}-(rs)x_{1}||_{2}^{ 2}. \]

However, computing the exact minimal squared distance is computationally infeasible in practice due to the need to search over all possible combinations of rotations and permutations. Therefore, we approximate the minimizer by performing a sequential search

\[(x_{0},x_{1})=_{r SO(D)}||x_{0}-(r)x_{1}||_{2}^{ 2},=*{arg\,min}_{s S(N)}||x_{0}-(s)x_{1}||_{ 2}^{2}. \]

We demonstrate in Section 6 that this approximation results in nearly OT integration paths for equivariant flows, even for small batch sizes. While we also tested other approximation strategies in Appendix A.9, they did not yield significant changes in our results, but come at with additional computational overhead. We hence alter the OT flow matching procedure as follows: For each element of the cost matrix \(M\), we first compute the optimal permutation with the Hungarian algorithm  and then align the two samples through rotation with the Kabsch algorithm . The other steps of the OT flow matching algorithm remain unchanged. We will refer to this loss as _Equivariant OT flow matching_. Although aligning samples in that way comes with a significant computational overhead, this reordering can be done in parallel before or during training (see Appendix C.4). It is worth noting that in the limit of infinite batch sizes, the Euclidean cost will still yield the correct OT map for invariant densities.

## 5 Architecture

The vector field \(v_{}(t,x)\) is parametrized by an \(O(D)\)- and \(S(N)\)-equivariant graph neural network, similar to the one used in  and introduced in . The graph neural network consists of \(L\) consecutive layers. The update for the \(i\)-th particle is computed as follows

\[h_{i}^{0} =(t,a_{i}), m_{ij}^{l}=_{e}(h_{i}^{l},h_{j}^{l},d_{j }^{2}), \] \[x_{i}^{l+1} =x_{i}^{l}+_{j i}^{l}-x_{j}^{l})}{ d_{ij}+1}_{d}(m_{ij}^{l}),\] (18) \[h_{i}^{l+1} =_{h}(h_{i}^{l},m_{i}^{l}), m_{i}^{l}=_{ j i}_{m}(m_{ij}^{l})m_{ij}^{l},\] (19) \[v_{}(t,x^{0})_{i} =x_{i}^{L}-x_{i}^{0}, \]where \(_{}\) are neural networks, \(d_{ij}\) is the Euclidean distance between particle \(i\) and \(j\), and \(a_{i}\) is an embedding for the particle type. Notably, the update conserves the geometric center if all particles are of the same type (see Appendix B.2), otherwise we subtract the geometric center after the last layer. This ensures that the resulting equivariant vector field \(v_{}(t,x)\) conserves the geometric center. When combined with a symmetric mean-free prior distribution, the push-forward distribution of the CNF will be \(O(D)\)- and \(S(N)\)-invariant.

## 6 Experiments

In this section, we demonstrate the advantages of equivariant OT flow matching over existing training methods using four datasets characterized by invariant energies. We explore three different training objectives: (i) likelihood-based training, (ii) OT flow matching, and (iii) equivariant OT flow matching. For a comprehensive overview of experimental details, including dataset parameters, error bars, learning rate schedules, computing infrastructure, and additional experiments, please refer to Appendix A and Appendix C in the supplementary material. For all experiments, we employ a mean-free Gaussian prior distribution. The number of layers and parameters in the equivariant CNF vary across datasets while remaining consistent within each dataset (see Appendix C). We provide naive flow matching as an additional baseline in Appendix A.11. However, the results are very similar to the ones obtained with OT flow matching, although the integration paths are generally slightly longer.

### DW4 and LJ13

We first evaluate the different loss functions on two many-particle systems, DW4 and LJ13, that were specifically designed for benchmarking equivariant flows as described in . These systems feature pair-wise double-well and Lennard-Jones interactions with \(4\) and \(13\) particles, respectively (see Appendix C.2 for more details). While state-of-the-art results have been reported in , their evaluations were performed on very small test sets and were biased for the LJ13 system. To provide a fair comparison, we retrain their model using likelihood-based training as well as the two flow matching losses on resampled training and test sets for both systems. Additionally, we demonstrate improved likelihood performance of flow matching on their biased test set in Appendix A.3. The results, presented in Table 1, show that the two flow matching objectives outperform likelihood-based training while being computationally more efficient. The effective sample sizes (ESS) and negative log likelihood (NLL) are comparable for the flow matching runs. However, for the LJ13 system, the equivariant OT flow matching objective significantly reduces the integration path length compared

  
**Training type** & **NLL** (\(\)) & **ESS** (\(\)) & **Path length** (\(\)) \\   & & DW4 & \\  Likelihood  & \(1.72 0.01\) & \(86.87 0.19\%\) & \(3.11 0.04\) \\ OT flow matching & \(1.70 0.02\) & \(\%\) & \(2.94 0.02\) \\ Equivariant OT flow matching & \(1.68 0.01\) & \(88.71 0.40\%\) & \(2.92 0.01\) \\   & & LJ13 & \\  Likelihood  & \(-15.83 0.07\) & \(39.78 6.19\%\) & \(5.08 0.22\) \\ OT flow matching & \(-16.09 0.03\) & \(54.36 5.43\%\) & \(2.84 0.01\) \\ Equivariant OT flow matching & \(-16.07 0.02\) & \(\%\) & \(\) \\   & & LJ55 & \\  OT flow matching & \(-88.45 0.04\) & \(3.74 1.06\%\) & \(7.53 0.02\) \\ Equivariant OT flow matching & \(-\) & \(\%\) & \(\) \\   & & Alanine dipeptide & \\  OT flow matching & \(-\) & \(\%\) & \(10.19 0.03\) \\ Equivariant OT flow matching & \(-106.78 0.02\) & \(0.69 0.05\%\) & \(\) \\   

Table 1: Comparison of flows trained with different training objectives. Errors are computed over three runs.

to other methods due to the large number of possible permutations (refer to Figure 1 for a visual illustration).

### LJ55

The effectiveness of equivariant OT flow matching becomes even more pronounced when training on larger systems, where likelihood training is infeasible (see Appendix A.2). To this end, we investigate a large Lennard-Jones cluster with 55 particles (_LJ55_).

We observe that the mean batch transport cost of training pairs is about \(10\) times larger for OT flow matching compared to equivariant OT flow matching (Figure 2b), resulting in curved and twice as long integration paths during inference (Figure 2a,c). However, the integration paths for OT flow matching are shorter than those seen during training, see Appendix A.1 for a more detailed discussion. We compare the integration error caused by using a fixed step integrator (rk4) instead of an adaptive solver (dropi5 ). As the integration paths follow nearly straight lines for the equivariant OT flow matching, the so resulting integration error is minimal, while the error is significantly larger for OT flow matching (Figure 2d). Hence, we can use a fixed step integrator, with e.g. \(20\) steps, for sampling for equivariant OT flow matching, resulting in a three times speed-up over OT flow matching (Figure 2e), emphasizing the importance of accounting for symmetries in the loss for large, highly symmetric systems. Moreover, the equivariant OT flow matching objective outperforms OT flow matching on all evaluation metrics (Table 1). To ensure that the flow samples all states, we compute the energy distribution (Figure 2f) and perform deterministic structure minimization of the samples, similar to , in Appendix A.7.

### Alanine dipeptide

In our final experiment, we focus on the small molecule alanine dipeptide (Figure 3a) in Cartesian coordinates. The objective is to train a Boltzmann Generator capable of sampling from the equilibrium Boltzmann distribution defined by the semi-empirical _GFN2-xTB_ force-field . This semi-empirical potential energy is invariant under permutations of atoms of the same chemical element and global rotations and reflections. However, here we consider the five backbone atoms defining the \(\) and \(\) dihedral angles as distinguishable to facilitate analysis. Since running MD simulations with semi-empirical force-fields is computationally expensive, we employ a surrogate training set, further challenging the learning task.

Figure 2: Results for the LJ55 system (a) Integration paths per particle for OT flow matching (left) and equivariant OT flow matching (right). (b) Mean transport cost (squared distance) for training batches. (c) Integration path length distribution. (d) Integration error for a fixed step size integrator (rk4) with respect to a reference solution generated by an adaptive solver (dropi5). (e) Effective samples vs number of function evaluations, i.e. evaluations of the vector field, for a sampling batch size of \(1000\). (f) Energy histograms for a flow trained with equivariant OT flow matching.

Alanine dipeptide data set generationThe alanine dipeptide training data set is generated through two steps: (i) Firstly, we perform an MD simulation using the classical _Amber ff99SBildn_ force-field for a duration of \(1\) ms . (ii) Secondly, we relax \(10^{5}\) randomly selected states from the MD simulation using the semi-empirical _GFN2-xTB_ force-field for \(100\) fs each. For more detailed information, refer to Appendix C.2 in the supplementary material. This training data generation is significantly cheaper than performing a long MD simulation with the semi-empirical force field.

Although the Boltzmann generator is trained on a biased training set, we can generate asymptotically unbiased samples from the semi-empirical target distribution by employing reweighting (Appendix B.3) as demonstrated in Figure 3e. In this experiment, OT flow matching outperforms equivariant OT flow matching in terms of effective sample size (ESS) and negative log likelihood (NLL) as shown in Table 1. However, the integration path lengths are still longer for OT flow matching compared to equivariant OT flow matching, as depicted in Figure 3c. Since the energy of alanine dipeptide is invariant under global reflections, the flow generates samples for both chiral states. While the presence of the mirror state reflects the symmetries of the energy, in practical scenarios, molecules typically do not change their chirality spontaneously. Therefore, it may be undesirable to have samples from both chiral states. However, it is straightforward to identify samples of the undesired chirality and apply a mirroring operation to correct them. Alternatively, one may use a SO(3) equivariant flow without reflection equivariance  to prevent the generation of mirror states.

Alanine dipeptide - free energy differenceThe computation of free energy differences is a common challenge in statistical physics as it determines the relative stability of metastable states. In the specific case of alanine dipeptide, the transition between negative and positive \(\) dihedral angle is the slowest process (Figure 3d), and equilibrating the free energy difference between these two states from MD simulation requires simulating numerous transitions, i.e. millions of consecutive MD steps, which is expensive for the semi-empirical force field. In contrast, we can train a Boltzmann generator from data that is not in global equilibrium, i.e. using our biased training data, which is significantly cheaper to generate. Moreover, as the positive \(\) state is much less likely, we can even bias our training data to have nearly equal density in both states, which helps compute a more precise free energy estimate (see Appendix C.5). The equivariant Boltzmann generator is trained using the OT flow matching loss, which exhibited slightly better performance for alanine dipeptide. We obtain similar results for the equivariant OT flow matching loss (see Appendix A.4). To obtain an accurate estimation of the free energy difference, five umbrella sampling simulations are conducted along the \(\) dihedral angle using the semi-empirical force-field (see Appendix C.2). The free energy difference estimated by the Boltzmann generator demonstrates good agreement with the results

Figure 3: Results for the alanine dipeptide system (a) Alanine dipeptide molecule. (b) Mean transport cost (squared distance) for training batches. (c) Integration path length distribution. (d) Ramachandran plot depicting the generated joint marginal distribution over the backbone dihedral angles \(\) and \(\) after filtering out samples with right-handed chirality and high energies. (e) Energy histograms for samples generated by a flow trained with OT flow matching. (f) Free energy distribution along the slowest transition (\(\) dihedral angle) computed with umbrella sampling and the equivariant flow.

of these simulations (Table 2 and Figure 2(f)), whereas both the relaxed training data and classical Molecular Dynamics simulation overestimate the free energy difference.

## 7 Discussion

We have introduced a novel flow matching objective for training equivariant continuous normalizing flows on invariant densities, leading to optimal transport integration paths even for small training batch sizes. By leveraging flow matching objectives, we successfully extended the applicability of equivariant flows to significantly larger systems, including the large Lennard-Jones cluster (LJ55). We conducted experiments comparing different training objectives on four symmetric datasets, and our results demonstrate that as the system size increases, the importance of accounting for symmetries within the flow matching objective becomes more pronounced. This highlights the critical role of our proposed flow matching objective in scaling equivariant CNFs to even larger systems.

Another notable contribution of this work is the first successful application of a Boltzmann generator to model alanine dipeptide in Cartesian coordinates. By accurately estimating free energy differences using a semi-empirical force-field, our approach of applying OT flow matching and equivariant OT flow matching to equivariant flows demonstrates its potential for reliable simulations of complex molecular systems.

## 8 Limitations / Future work

While we did not conduct experiments to demonstrate the transferability of our approach, the architecture and proposed loss function can potentially be used to train transferable models. We leave this for future research. Although training with flow matching is faster and computationally cheaper than likelihood training for CNFs, the inference process still requires the complete integration of the vector field, which can be computationally expensive. However, if the model is trained with the equivariant OT flow matching objective, faster fixed-step integrators can be employed during inference. Our suggested approximation of Equation (15) includes the Hungarian algorithm, which has a computational complexity of \((N^{3})\). To improve efficiency, this step could be replaced by heuristics relying on approximations to the Hungarian algorithm . Moreover, flow matching does not allow for energy based training, as this requires integration similar to NLL training. A potential alternative approach is to initially train a CNF using flow matching with a small set of samples. Subsequent sample generation through the CNF, followed by reweighting to the target distribution, allows these samples to be added iteratively to the training set, similarly as in [27; 37]. Notably, in our experiments, we exclusively examined Gaussian prior distributions. However, flow matching allows to transform arbitrary distributions. Therefore, our equivariant OT flow matching method holds promise for application in scenarios where the prior distribution is sampled through MD at a distinct thermodynamic state, such as a higher temperature or a different level of theory [32; 33]. In these cases, where both the prior and target distributions are close, with samples alignable through rotations and permutations, we expect that the advantages of equivariant OT flow matching will become even more pronounced than what we observed in our experiments.

Building upon the success of training equivariant CNFs for larger systems using our flow matching objective, future work should explore different architectures for the vector field. Promising candidates, such as [58; 59; 60; 61; 62], could be investigated to improve the modeling capabilities of equivariant CNFs. While our focus in this work has been on symmetric physical systems, it is worth noting that equivariant flows have applications in other domains that also exhibit symmetries, such as traffic data generation , point cloud and set modeling [64; 65], as well as invariant distributions on arbitrary manifolds . Our equivariant OT flow matching approach can be readily applied to these areas of application without modification.

    & MD & relaxed MD & Umbrella sampling & Boltzmann generator \\ Free energy difference / \(k_{B}T\) & \(5.31\) & \(5.00\) & \(4.10 0.26\) & \(4.10 0.08\) \\   

Table 2: Dimensionless free energy differences for the slowest transition of alanine dipeptide estimated from various methods. Umbrella sampling yields a converged reference solution. Errors over five runs.