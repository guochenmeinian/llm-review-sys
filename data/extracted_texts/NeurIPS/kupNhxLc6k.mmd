# Computing Optimal Nash Equilibria in Multiplayer Games

Youzhi Zhang

Centre for Artificial Intelligence and Robotics

Hong Kong Institute of Science & Innovation

Chinese Academy of Sciences

youzhi.zhang@cair-cas.org.hk

&Bo An

School of Computer Science and Engineering

Nanyang Technological University

Singapore

boan@ntu.edu.sg

&V. S. Subrahmanian

Department of Computer Science

Northwestern University

Evanston, USA

vss@northwestern.edu

###### Abstract

Designing efficient algorithms to compute a Nash Equilibrium (NE) in multiplayer games is still an open challenge. In this paper, we focus on computing an NE that optimizes a given objective function. For example, when there is a team of players independently playing against an adversary in a game (e.g., several groups in a forest trying to interdict illegal loggers in green security games), these team members may need to find an NE minimizing the adversary's utility. Finding an optimal NE in multiplayer games can be formulated as a mixed-integer bilinear program by introducing auxiliary variables to represent bilinear terms, leading to a huge number of bilinear terms, making it hard to solve. To overcome this challenge, we first propose a general framework for this formulation based on a set of correlation plans. We then develop a novel algorithm called **CRM** based on this framework, which uses **C**orrelation plans with their **R**elations to restrict the feasible solution space after the convex relaxation of bilinear terms while **M**inimizing the number of correlation plans to reduce the number of bilinear terms. We show that our techniques can significantly reduce the time complexity, and CRM can be several orders of magnitude faster than the state-of-the-art baseline.

## 1 Introduction

One of the important problems in artificial intelligence is the design of algorithms for agents to make decisions in interactive environments . To this day, many results have been achieved in two-player non-cooperative environments, for example, security games , the game of Go , and poker games . One of the most important solution concepts behind these results is the well-known Nash Equilibrium (NE) . Indeed, there are many efficient algorithms, e.g., algorithms based on linear programs  or counterfactual regret minimization , to compute Nash equilibria (NEs) in two-player zero-sum games. However, there are fewer results on efficient algorithms for NEs with theoretical guarantees in multiplayer games (see the discussion in ), and most of these results are for games with particular structures (e.g., polymatrix games ). The main reason is that finding NEs in multiplayer games is hard -- it is PPAD-complete even for zero-sum three-player games . Designing efficient algorithms to compute NEs in multiplayer games is thus still an open challenge.

In this paper, we focus on computing an optimal NE that optimizes a specific objective over the space of NEs. In the real world, we may need to optimize our objective over the space of NEs . Possible objectives  could be maximizing social welfare (the sum of the players' expected utilities), maximizing the expected utilities of one player or several players, maximizing the minimum utility among players, minimizing the support sizes of the NE strategies, and so on. In addition, when there is a team of players in a game, team members need to consider finding an equilibrium that optimizes some objective [45; 12]. For example, in green security games where several heterogeneous groups (e.g., local police, the Madagascar National Parks, NGOs, and community volunteers) try to protect forests from illegal logging , the groups involved may need to find an NE that minimizes the adversary's utility1.

Unfortunately, the problems mentioned above are NP-hard [14; 9]. In two-player games, finding an optimal NE can be formulated as a mixed-integer linear program . In this formulation, finding an optimal solution means optimizing an objective over the space of NEs, and this space is modeled as the feasible solution space of the mixed-integer linear program. We can directly extend this two-player formulation to find an optimal NE in multiplayer games by representing the space of NEs as the feasible solution space of a mixed-integer bilinear program transformed from a multilinear program by using auxiliary variables to represent bilinear terms. Then finding an optimal NE requires solving a non-convex program. Unfortunately, such a formulation is not efficient because there are exponentially many bilinear terms in the program. There are other approaches (e.g., ) that guarantee finding an NE in multiplayer games. However, these approaches need to enumerate all NEs to find an optimal NE, which is very inefficient  (see our experimental results) because there can be exponentially many NEs .

To tackle this challenge, we first propose a general framework for transforming a multilinear program for computing optimal NEs into a bilinear program based on a set of correlation plans, where each correlation plan (i.e., a probability distribution over joint actions) corresponds to a set of auxiliary variables representing a set of bilinear terms. We then develop a novel algorithm called **CRM** based on this framework, which uses **C**orrelation plans with their **R**elations to strictly reduce the feasible solution space after the convex relaxation of bilinear terms while **M**inimizing the number of correlation plans to reduce the number of bilinear terms. We show that our techniques can significantly reduce the time complexity, and CRM can be several orders of magnitude faster than the state-of-the-art baseline. To our best knowledge, CRM is the first algorithm to use a minimum set of correlation plans to reformulate the program for computing optimal NEs in multiplayer games.

## 2 Preliminaries

Consider a normal-form game2\(G=(N,A,u)\). We denote the set of players as \(N=\{1,,n\}\); the set of all players' joint actions is \(A=_{i N}A_{i}\), where \(A_{i}\) is the finite set of player \(i\)'s pure strategies (actions) with \(a_{i} A_{i}\); and the set of all players' payoff functions is \(u=(u_{1},,u_{n})\), where \(u_{i}:A\) is player \(i\)'s payoff function. Let \(U_{max}=_{i N}_{a A}u_{i}(a)\), and \(U_{min}=_{i N}_{a A}u_{i}(a)\). In addition, the set of (joint) mixed strategy profiles \(X=_{i N}X_{i}\), where \(X_{i}=(A_{i})\) (i.e., the set of probability distributions over \(A_{i}\)) is the set of mixed strategies of player \(i\), and \(x_{i}(a_{i})\) is the probability that any action \(a_{i} A_{i}\) is played. Let \(-i\) be the set of all players excluding player \(i\), i.e., \(-i=N\{i\}\), and \(A_{-i}\) be \(_{j N\{i\}}A_{j}\). Generally, given \(N^{} N\), \(a_{N^{}} A_{N^{}}=_{i N^{}}A_{i}\), \(a_{N^{}}(i)\) is the action of player \(i N^{}\) in the joint action \(a_{N^{}}\). For example, if \(a_{N^{}}=(a_{1},a_{3},a_{5})\) with \(N^{}=\{1,3,5\}\), \(a_{N^{}}(3)=a_{3}\). If \(N^{}=N\), we ignore the subscript, i.e., \(a=a_{N}\) and \(A=A_{N}\). For each \(x X\), player \(i\)'s expected payoff is:

\[u_{i}(x)=_{a A}u_{i}(a)_{j N}x_{j}(a(j)),\]

and, if player \(i\) plays \(a_{i}\):

\[u_{i}(a_{i},x_{-i})=_{a_{-i} A_{-i}}u_{i}(a_{i},a_{-i})_{j-i}x _{j}(a_{-i}(j)).\]In this paper, we consider multiplayer games, i.e., \(n>2\).

A Nash Equilibrium (NE, and NEs for Nash Equilibria)  is a stable strategy profile in which no player has an incentive to change her strategy given other players' strategies and always exists. Formally, a strategy profile \(x^{*}\) is an NE if, for each player \(i\), \(x^{*}_{i}\) is a best response to \(x^{*}_{-i}\), i.e., \(u_{i}(x^{*}_{i},x^{*}_{-i}) u_{i}(x_{i},x^{*}_{-i}), x_{i} X_{i}\), which is equivalent to \(u_{i}(x^{*}_{i},x^{*}_{-i}) u_{i}(a_{i},x^{*}_{-i}), a_{i} A_{i}\).

With the above condition of NEs, we could use a multilinear program to represent the space of NEs, but it will involve the product of strategies in \(u_{i}(x)\), whose degree is \(n\) and is higher than the product of strategies in \(u_{i}(a_{i},x_{-i})\). To reduce the degree of the program representing the space of NEs from \(n\) to \(n-1\) (i.e., only the product of strategies in \(u_{i}(a_{i},x_{-i})\) is required), in two-player games, the previous work  exploited the following NE's property, which can be used in multiplayer games as well. For each strategy profile \(x X\), the regret of an action \(a_{i}\) is the difference in player \(i\)'s expected utility between playing \(x_{i}\) in \(x\) and playing \(a_{i}\), i.e., \(u_{i}(x)-u_{i}(a_{i},x_{-i})\). Obviously, a strategy profile \(x X\) is an NE if and only if every action either has the regret 0, or is played with the probability 0 in \(x\). Then the space of NEs of a game can be formulated as the feasible solution space of a mixed-integer program by using a binary variable \(b_{a_{i}}\) to represent that any action \(a_{i}\) either has the regret 0, or is played with the probability 0:

\[u_{i}(a_{i},x_{-i})=_{a_{-i} A_{-i}}u_{i}(a_{i},a_{-i}) _{j-i}x_{j}(a_{-i}(j)) i,a_{i} A_{i}\] (1a) \[_{a_{i} A_{i}}x_{i}(a_{i})=1 i N\] (1b) \[1-b_{a_{i}} x_{i}(a_{i}) i N,a_{i} A_{i}\] (1c) \[u_{i}(x) u_{i}(a_{i},x_{-i}) i N,a_{i} A_{i}\] (1d) \[u_{i}(x)-u_{i}(a_{i},x_{-i}) b_{a_{i}}(U_{max}-U_{min})  i N,a_{i} A_{i},\] (1e) \[u_{i}(a_{i},x_{-i})[U_{min},U_{max}],u_{i}(x)[U_{min},U_{max }] i N,a_{i} A_{i},\] (1f) \[x_{i}(a_{i}),b_{a_{i}}\{0,1\}, i N,a_ {i} A_{i},\] (1g)

where we use the notations of utility functions \(u_{i}(x)\) and \(u_{i}(a_{i},x_{-i})\) to represent the corresponding variables in the program. Eq.(1c) ensures that binary variable \(b_{a_{i}}\) is set to 0 when \(x_{i}(a_{i})>0\) and can be set to 1 only when \(x_{i}(a_{i})=0\); and Eq.(1e) ensures that the regret of action \(a_{i}\) equals 0 (i.e., \(u_{i}(x)=u_{i}(a_{i},x_{-i})\)), unless \(b_{a_{i}}=1\) where the constraint \(u_{i}(x)-u_{i}(a_{i},x_{-i})(U_{max}-U_{min})\) always holds.

An optimal NE is an NE optimizing an objective function \(g(x)\) over the space of NEs, where \(g(x)\) is a linear objective function3 and could be maximizing social welfare, maximizing the expected utilities of one player or several players, maximizing the minimum utility among players, minimizing the support sizes of the NE strategies, and so on. Unfortunately, finding an optimal NE optimizing the above objectives is NP-hard .

## 3 Computing Optimal Nash Equilibria

The problem of finding an optimal NE in multiplayer games requires optimizing an objective over the space of NEs. This space is represented by Eq.(1), which involves nonlinear terms in Eq.(1a) to represent the strategies of players in \(-i\), which is bilinear when \(n=3\) and is multilinear when \(n 4\). The multilinear program is usually transformed into a bilinear program to make the program solvable using global optimization solvers, e.g., Gurobi . Here, we propose a general framework for this transformation based on a set of correlation plans for any binary collection of subsets of players, where each set in this collection is divided into two disjoint sets, and each correlation plan corresponds to a set of auxiliary variables representing a set of bilinear terms. However, there are two challenges for solving this bilinear program: 1) this bilinear program usually involves a large number of bilinear terms, and 2) an important step used by state-of-the-art algorithms to solve such bilinear programs is to use convex relaxation to replace each bilinear term in the program [15; 18], which significantly enlarges the feasible solution space. To overcome these challenges, we develop a novel algorithm called **CRM** that uses **C**orrelation plans with their **R**elations to strictly reduce the feasible solution space after the convex relaxation while **M**inimizing the number of correlation plans to reduce the number of bilinear terms. Section 3.4 shows that our techniques can significantly reduce the time complexity. The procedure of CRM is shown in Algorithm 2, which is illustrated in Appendix A.

### A General Transformation Framework

A correlation plan is a probability distribution over the joint action space of a subset of players, and we focus on correlation plans for certain special collections of subsets of players, which can be used to transform a multilinear program for computing optimal NEs into a bilinear program.

**Definition 1**.: _A collection \(\) of subsets of players is a **binary collection** if:_

1. \(\{-i i N\}\)_;_
2. _for each_ \(N^{}\)_,_ \(N^{} N\) _with_ \(|N^{}| 2\)_; and_
3. _for each_ \(N^{}\)_, there are two disjoint children_ \(N^{}_{l}\) _and_ \(N^{}_{r}\) _in_ \(\{\{i\} i N\}\) _such that_ \(N^{}_{l} N^{}_{r}=\) _and_ \(N^{}=N^{}_{l} N^{}_{r^{}}\)_, i.e.,_ \(N^{}\) _is divided into two disjoint sets._

_Let \(N^{}_{l}\) and \(N^{}_{r}\) be the left child and the right child of \(N^{}\), respectively. For each \(N^{}\) in any binary collection \(\), a **correlation plan** of \(N^{}\) is a probability distribution \(x_{N^{}}\) over \(A_{N^{}}\): given \(x_{N^{}}(a_{N^{}})\) (\( a_{N^{}} A_{N^{}},N^{}\)),_

\[_{a_{N^{}} A_{N^{}}}x_{N^{}}(a_{N^{}})=1  N^{}.\] (2)

For simplification, let \(i\) be equivalent to \(\{i\}\) for each \(i N\). That is, \(x_{i}\) is a special correlation plan \(x_{\{i\}}\) (i.e., \(x_{i}=x_{\{i\}}\)), \(a_{i} A_{i}\) is a special joint action \(a_{\{i_{j}\}} A_{\{i\}}\) (i.e., \(a_{i}=a_{\{i_{1}\}}\)). Each element \(N^{}\) in a binary collection \(\) has the binary division, i.e., it is divided into two disjoint sets \(N^{}_{l}\) and \(N^{}_{r^{}}\). Based on this binary division, any joint action \(a_{N^{}} A_{N^{}}\) can be divided into two sub-joint actions \(a_{N^{}_{l}} A_{N^{}_{l}}\) and \(a_{N^{}_{r}} A_{N^{}_{r}}\) such that \(a_{N^{}_{l}}=(a_{N^{}_{l}},a_{N^{}_{r}})\). Then we can use this binary division to ensure that \(_{j N^{}}x_{j}(a_{N^{}}(j))=x_{N^{}}(a_{N^{}})\) for the correlation plan \(x_{N^{}}\), as shown in Example 1.

**Example 1**.: \(\{\{1,2,3\},\{1,2,4\},\{1,3,4\},\{2,3,4\},\{1,2\},\{1,3\},\{2,3\},\{1,4\},\{3,4 \},\{2,4\}\}\) _is a binary collection for a four-player game. For \(N^{}=\{1,2,3\}\) in this collection with \(N^{}_{l}=\{1,2\}\) (having two children \(\{1\}\) and \(\{2\}\)) and \(N^{}_{r}=\{3\}\), we have \(a_{N^{}}=(a_{1},a_{2},a_{3})=(a_{\{1,2\}},a_{3}) A_{N^{}}\) and \(a_{\{1,2\}}=(a_{1},a_{2}) A_{\{1,2\}}\). Then we can have a chain of bilinear constraints (equalities): \(x_{N^{}}(a_{N^{}})=x_{\{1,2\}}(a_{\{1,2\}})x_{3}(a_{3})\) and \(x_{\{1,2\}}(a_{\{1,2\}})=x_{1}(a_{1})x_{2}(a_{2})\), which guarantees that \(x_{N^{}}(a_{N^{}})=x_{1}(a_{1})x_{2}(a_{2})x_{3}(a_{3})\). In other words, we use \(x_{\{1,2\}}(a_{\{1,2\}})\) and \(x_{N^{}}(a_{N^{}})\) as the auxiliary variables to represent bilinear terms \(x_{1}(a_{1})x_{2}(a_{2})\) and \(x_{\{1,2\}}(a_{\{1,2\}})x_{3}(a_{3})\), respectively._

This property of correlation plans of a binary collection \(\) can be used to transform the multilinear Program (1) into a bilinear program. First, we use the binary division of each element \(N^{}\) in \(\) to connect correlation plans, i.e., for any \(N^{}\) with its children \(N^{}_{l}\) and \(N^{}_{r}\):

\[x_{N^{}}(a_{N^{}})\!=\!x_{N^{}_{l}}(a_{N^{ }_{l}})x_{N^{}_{r}}(a_{N^{}_{r}}) a_{N^{}}\! =\!(a_{N^{}_{l}},a_{N^{}_{r}})\!\!A_{N^{}}\] (3a) \[x_{N^{}}(a_{N^{}}) a_{N^{}}  A_{N^{}}.\] (3b)

Second, we replace \(_{j-i}x_{j}(a_{-i}(j))\) in Eq.(1a) with \(x_{-i}(a_{-i})\):

\[u_{i}(a_{i},x_{-i})\!=\!_{a_{-i} A_{-i}}\!\!u_{i}(a_{i},a_{-i})x_{-i}(a_{ -i}) i N,a_{i} A_{i}.\] (4)

In the above transformation, each correlation plan corresponds to a set of auxiliary variables (e.g., \(x_{N^{}}(a_{N^{}})\)) representing a set of bilinear terms (e.g., \(x_{N^{}_{l}}(a_{N^{}_{l}})x_{N^{}_{r}}(a_{N^{}_{r}})\)). Eq.(3) guarantees that \(_{j N^{}}x_{j}(a_{N^{}}(j))=x_{N^{}}(a_{N^{}})\), and then the feasible solution space of Eqs.(1b)-(1g), (3), and (4) represents the space of NEs.

**Theorem 1**.: _The feasible solution space of mixed strategies (i.e., \(x_{i}(a_{i})\) for each \(i N\), \(a_{i} A_{i}\)) in Eqs.(1b)-(1g), (3), and (4) is the space of NEs. (Proofs are in Appendix B.)_We can then compute an optimal NE by solving the following mixed-integer bilinear program according to any binary collection \(\):

\[_{x}g(x)\] (5a) \[(1b)-(1g),(3),(4).\] (5b)

It is straightforward to solve Program (5) by using the **vanilla binary collection**\(}\) that includes all non-singleton proper subsets of \(N\), i.e., \(}=\{N^{} N^{} N,|N^{}| 2\}\), where, for each \(N^{}}\), \(N^{}_{l}\) is \(N^{}\{j\}\) and \(N^{}_{r}\) is \(\{j=_{i N^{}}i\}\). Example 1 provides an example of \(}\).

### Exploit Correlation Plans with Their Relations

In this section, we use correlation plans with their relations to restrict the feasible solution space after the convex relaxation. The common convex relaxation technique [27; 35; 18] before searching for the optimal solution is: each bilinear term \(x_{N^{}}(a_{N^{}})=y_{1}y_{2}\) with \(y_{1},y_{2}\) is represented by the following constraints including four linear constraints:

\[\{0,y_{1}+y_{2}-1\} x_{N^{}}(a_{N^{}}) \{y_{1},y_{2}\},\] (6)

which significantly enlarges the feasible solution space. We now show the motivation to use correlation plans with their relations to reduce this feasible solution space.

**Example 2**.: _Given \(N^{}=\{2,4\} N\) with two actions for each player (i.e., \(A_{i}=\{a_{i},a^{}_{i}\}\)) in a game \(G\), by Eq.(6), bilinear terms (e.g., \(x_{N^{}}(a_{2},a_{4})=x_{2}(a_{2})x_{4}(a_{4})\)) are relaxed according to Eq.(6), e.g., \(\{0,x_{2}(a_{2})+x_{4}(a_{4})-1\} x_{N^{}}(a_{2},a_{4}) \{x_{2}(a_{2}),x_{4}(a_{4})\}\). With additional constraints by Eq.(1b) (e.g., \(x_{4}(a_{4})+x_{4}(a^{}_{4})=1\)), the following assignment could be a feasible solution:_

\[x_{N^{}}(a_{2},a_{4})=x_{N^{}}(a^{}_{2},a_{4}) =x_{N^{}}(a_{2},a^{}_{4})=x_{N^{}}(a^{}_{2},a^{ }_{4})\] (7) \[= x_{2}(a_{2})=x_{2}(a^{}_{2})=x_{4}(a_{4})=x_{4}(a^{ }_{4})=0.5.\]

_Obviously, in Eq.(7), \(x_{N^{}}(a_{2},a_{4})\) is not equal to \(x_{2}(a_{2})x_{4}(a_{4})\). In fact, based on Eq.(2), we have:_

\[x_{N^{}}(a_{2},a_{4})+x_{N^{}}(a^{}_{2},a_{4}) +x_{N^{}}(a_{2},a^{}_{4})+x_{N^{}}(a^{}_{2},a^{ }_{4})=1,\] (8)

_which will make the solution in Eq.(7) infeasible. Moreover, the following assignment is a feasible solution after the relaxation and satisfies Eq.(8):_

\[x_{N^{}}(a_{2},a_{4})=x_{N^{}}(a^{}_{2},a_{4}) =x_{N^{}}(a_{2},a^{}_{4})=0.2,\] (9) \[x_{N^{}}(a^{}_{2},a^{}_{4}) =0.4,x_{2}(a_{2})=x_{4}(a_{4})=0.5.\]

_However, in Eq.(9), \(x_{N^{}}(a_{2},a_{4})\) is still not equal to \(x_{2}(a_{2})x_{4}(a_{4})\). Actually, we have:_

\[x_{N^{}}(a_{2},a_{4})+x_{N^{}}(a^{}_{2},a_{4}) =x_{4}(a_{4}),\] (10) \[x_{N^{}}(a_{2},a^{}_{4})+x_{N^{}}(a^{}_{ 2},a^{}_{4}) =x_{4}(a^{}_{4}),\]

_which will make the solution in Eq.(9) infeasible._

This above example shows that we can use the definition of a correlation plan (i.e., Eq.(2)) and the relation of correlation plans to reduce the feasible solution space after the relaxation.

Each element \(N^{}\) in any binary collection \(\) is defined by \(N^{}_{l}\) and \(N^{}_{r}\), which actually defines relations between correlation plans for elements in \(\{\{i\} i N\}\). In Example 2, Eq.(10) actually represents a relation between the correlation plan \(x_{N^{}}\) and the mixed strategy \(x_{4}\) (i.e., the special correlation plan \(x_{\{4\}}\)). Formally, for any \(N^{}\) and \(i N^{}\):

\[_{a_{N^{}} A_{N^{}},a_{N^{}}(i)=a_{i}}x_{N^{}}(a _{N^{}})\!=x_{i}(a_{i}) a_{i} A_{i},\] (11)

where \(a_{N^{}}(i)\) is the action of player \(i N^{}\) in the joint action \(a_{N^{}}\). Similarly, let \(a_{N^{}}(N^{})\) be the sub-joint action of player \(N^{} N^{}\) in the joint action \(a_{N^{}}\). Then, for any \(N^{}\) with its children \(N^{}_{l}\) and \(N^{}_{r}\), and \(N^{}\{N^{}_{l},N^{}_{r}\}\):

\[_{a_{N^{}} A_{N^{}},a_{N^{}}(N^{})=a_{ N^{}}}x_{N^{}}(a_{N^{}})\!=x_{N^{}}(a_{N^{ }}) a_{N^{}}\!\!A_{N^{}}\] (12)

[MISSING_PAGE_EMPTY:6]

To overcome this challenge, we propose building a minimum-height binary tree for each element in \(\{-i i N\}\) and ensuring that the number of internal nodes in these binary trees is the minimum. The binary division for each element in a binary collection \(\) creates a binary tree for each element in \(\{-i i N\}\). For example, Figure 1(a) is a binary tree for \(-5=\{1,2,3,4\}\), and Figure 1(b) is a binary tree for \(-3=\{1,2,5,4\}\) in five-player games. Each binary tree for \(-i\) is a full binary tree, i.e., each internal node has two children, with \(n-2\) internal nodes and \(n-1\) leaf nodes, where the height is the number of internal nodes on the longest path from the root to a leaf (e.g., the height in Figure 1(a) is 2). Details for these binary trees are shown in Appendix D. We can then build a full binary tree \(T_{-n}\) with the minimum height \(_{2}(n-1)\) for \(-n\) and then replace \(i\) with \(n\) in the nodes of \(T_{-n}\) to obtain \(T_{-i}\) for each \(i-n=\{1,,n-1\}\). That creates \(n\) full binary trees for \(\{-i i N\}\). This procedure is shown in Algorithm 1 (details are shown in Appendix D), generating our **minimum binary collection**\(\) including all internal nodes in these trees. For example, Figure 1(a) builds a binary tree \(T_{-5}\), and Figure 1(b) obtains \(T_{-3}\) by replacing \(3\) with \(5\) in \(T_{-5}\). Generally, we only need to create at most \(_{2}(n-1)\) new internal nodes to build a minimum-height binary tree for each \(-i\) with \(i-n\). Then \(|}|\) is at most \(n-2+(n-1)_{2}(n-1)\), i.e., \(O(n n)\).

**Theorem 4**.: \(\) _generated by Algorithm 1 is a binary collection, and \(O(n n)\) for the size of \(}\) is the minimum size of all binary collections of a game \(G\). (Proofs are in Appendix B.)_

\(|}|\) only grows sub-quadratically with \(n\) and is much smaller than \(|}|=2^{n}-(n+2)\) for \(}\). Then \(}\) requires fewer bilinear terms than \(}\) when \(n>3\). For example, in a seven-player game with two actions for each player, by using \(}\) with \(|}|=21\) correlation plans, the number of bilinear terms is 564, which is much smaller than 2044 by using \(}\) with \(|}|=119\) correlation plans. Table 3 of Appendix G shows more examples. Note that Algorithm 1 cannot reduce the number of internal nodes when \(n=3\) because each element in \(\{-i i N\}\) includes only two players in three-player games. Our algorithm, CRM, is solving Program (13) based on \(}\), which is shown in Algorithm 2 and is illustrated in Appendix A.

### Complexity

The problem of finding an optimal NE is NP-hard , and our algorithm, CRM, i.e., Program (13) based on \(}\) generated by Algorithm 1, is a mixed-integer bilinear program, whose scalability is mainly affected by the number of bilinear terms and integer variables. Generally, the problem of solving a linear integer program is NP-hard, and the time complexity is \(O(I^{2}(EC^{2})^{2E+3})\), where \(I\) is the number of integer variables, \(E\) is the number of constraints containing integer variables, and \(C\) is the maximum value among constants and the range of integer variables in these constraints. Theoretically, each bilinear term can be represented by a mixed-integer linear program by introducing a new set of constraints and binary integer variables . Suppose each bilinear term introduces \(I^{}\) integer variables and \(E^{}\) constraints, and each player has \(m\) actions. Program (5) based on \(}\) has \(mn\) binary integer variables with \(mn\) constraints and the following number of bilinear terms:

\[_{N^{}}_{i N^{}}|A_{i}|(2^{n}-n-2)m ^{n-1} 2^{n}m^{n-1}.\]

Then the time complexity for solving the Program (5) based on \(}\) is \(O(I_{1}^{2}(E_{1}C^{2})^{2E_{1}+3})\) where \(I_{1}=2^{n}m^{n-1}I^{}+mn\) and \(E_{1}=2^{n}m^{n-1}E^{}+mn\). Program (13) based on \(}\) has \(mn\) binary

Figure 1: Binary trees for \(-5\) and \(-3\)

integer variables with \(mn\) constraints and the following number of bilinear terms:

\[_{N^{}}_{i N^{}}|A_{i}|| |m^{n-1},\]

i.e., \(O((n n)m^{n-1})\) bilinear terms (this size is the minimum because \(O(n n)\) is the minimum size of binary collections by Theorem 4) and. Then the time complexity for solving Program (13) based on \(\)\(\) is \(O(I_{2}^{2}(E_{2}C^{2})^{2E_{2}+3})\) where \(I_{2}=(n n)m^{n-1}I^{}+mn\) and \(E_{2}=(n n)m^{n-1}E^{}+mn\), and thus \(O(n n)\) of Algorithm 1 can be ignored. Therefore, CRM dramatically reduces the time complexity (i.e., the term \(2^{n}\) in \(I_{1}\) and \(E_{1}\) is changed to the term \(n n\) in \(I_{2}\) and \(E_{2}\)).

## 4 Experiments

Following prior work for NEs [34; 4; 13], we evaluate our approach on two sets of games: randomly generated games (i.e., \((n,m)\) with \(n\) players and \(m\) actions for each player) and six-player three-action games that are generated by GAMUT . Payoffs are generated from the interval between 0 and 100 (other ranges (e.g., \(\)) do not affect the result). Details are shown in Appendix F. We show the game size in terms of the number of bilinear terms and integer variables in Appendix G, e.g., the number of bilinear terms in the game \((9,2)\) is 19152 based on \(\)\(\) but is 2512 based on \(\)\(\).

**Baselines:** We compare our CRM4 shown in Algorithm 2, i.e., solving Program (13) based on \(\)\(\), to the state-of-the-art algorithms: i) **MIBP**[34; 13]: the equivalent of solving Program (5) based on \(\)\(\); ii) **EXCLUSION**: the first implemented algorithm guarantees to converge to an NE by using a tree-search based method by splitting the continuous probability space of the solution; and iii) **ENUMPOLY**: an algorithm in the well-known game-solving package Gambit which

   &  \\  Vary & \((n,m)\) & CRM & MIBP & ENUMPOLY & EXCLUSION \\   & (3, 2) & **0.01**\(\)**0 & 0.02 \(\) 0 & 0.03 \(\) 0.01 & 31 \(\) 4 (gap:15\%) \\  & (5, 2) & **0.2**\(\)**0.1 & 0.5 \(\) 0.4 & 11 \(\) 4 & 753 \(\) 148 (73\%) (gap:64\%) \\  & (7, 2) & **25**\(\)**17 & 429 \(\) 131 (20\%) & 1000 \(\) 0 (97\%) & 835 \(\) 119 (80\%) (gap:53\%) \\   & (3, 5) & **0.2**\(\)**0.03 & 0.3 \(\)0.1 & 1000 \(\) 0 (100\%) & 1000 \(\) 0 (100\%) (gap:67\%) \\  & (3, 8) & **4**\(\)**3 & 247 \(\) 140 (17\%) & 1000 \(\) 0 (100\%) & 1000 \(\) 0 (100\%) (gap:oc) \\   & (3, 10) & **9**\(\)**9 & 334 \(\) 167 (30\%) & 1000 \(\) 0 (100\%) & 1000 \(\) 0 (100\%) (gap:oc) \\   & (3, 13) & **38**\(\)**21 & 342 \(\) 151 (27\%) & 1000 \(\) 0 (100\%) & 1000 \(\) 0 (100\%) (gap:oc) \\  GAMUT Game & CRM & MIBP & ENUMPOLY & EXCLUSION \\  Random LEG & **2**\(\)**1 & 1000 \(\) 0 (100\%) & 1000 \(\) 0 (100\%) & 986 \(\) 27 (97\%) (gap:11\%) \\ Random graphical & **0.1**\(\)**0.1 & 803 \(\) 140 (83\%) & 50 \(\) 30 & 971 \(\) 55 (97\%) (gap:32\%) \\ Uniform LEG & **2.2**\(\)**1 & 1000 \(\) 0 (100\%) & 1000 \(\) 0 (100\%) & 986 \(\) 26 (97\%) (gap:11\%) \\  

Table 1: Part of experimental results (more results are in Tables 4 and 5 of Appendix H). The format is: Average Runtime \(\) 95% Confidence Interval (Percentage of Games not Solved within the Time Limit) (Utility Gap). Note that the unit of the runtime is second, the case that all games have been solved with the time limit should be (\(0\%\)) and is omitted, we only need to care about the utility gap (a larger gap means losing more) for EXCLUSION, and the utility gap \(\) represents EXCLUSION cannot return a solution within the time limit.

  Game &  \\  (8, 2) & **156\(\) 83 (3\%)** & 612\(\) 129 (33\%) & 190 \(\) 102 (7\%) & 763 \(\) 120 (60\%) & 1000 \(\) 0 (100\%) \\ (7, 2) & **25**\(\)**17 & 89 \(\) 51 & 36 \(\) 28 & 408 \(\) 157 (30\%) & 488 \(\) 111 (10\%) \\ (3, 15) & **167\(\) 86 (3\%)** & 167 \(\) 86 (3\%) & 317 \(\) 137 (17\%) & 317 \(\) 137 (17\%) & 558 \(\) 150 (40\%) \\ (3, 17) & **231\(\)122 (10\%)** & 231 \(\)122 (10\%) & 326 \(\) 134 (20\%) & 326 \(\) 134 (20\%) & 784 \(\) 102 (53\%) \\ Random graphical & **0.1**\(\)**0.1 & 0.4 \(\) 0.1 & 0.2 \(\) 0.1 & 0.6 \(\) 0.4 & 814 \(\) 134 (80\%) \\ Uniform LEG & **2.2**\(\)**1 & 5 \(\) 4 & 2.5 \(\) 2 & 5 \(\) 5 & 999 \(\) 2 (97\%) \\  

Table 2: Ablation study (more results are in Table 6 of Appendix H). Note that \(\)\(\) (in CR and C) and \(\)\(\) (in CRM, CM, and M) result in the same bilinear terms in three-player games because each element in \(\{-i i\{1,2,3\}\}\) includes only two players such that Algorithm 1 cannot reduce the number of internal nodes to reduce the number of bilinear terms, and then CR and CRM (or C and CM) have the same performance. The unit of the runtime is second.

tries to find all NEs by enumerating all the supports which could be the support of an NE and then searching for an equilibrium on that support. They represent approaches to solving a nonlinear program, finding an NE, and enumerating all Nash equilibria, respectively. There are some other algorithms in Gambit  for finding an NE in a multiplayer game, including: i) **GNM**: a global Newton method approach; ii) **IPA**: an iterated polymatrix approximation approach; iii) **LIAP**: a function minimization approach; iv) **SIMPDIV**: a simplicial subdivision approach; and v) **LOGIT**[29; 40]: a quantal response method. However, they cannot guarantee finding an NE . Therefore, they are not suitable for finding an optimal NE. In fact, we show in Appendix I that all of them fail to solve many games and even run significantly slower than CRM in many games. Note that these Gambit algorithms only achieve some NE if the game is solved, which may not be optimal.

**Algorithm Setting and Metric:** We set a time limit of 1000 seconds for each case unless stated otherwise. Our optimality gap for EXCLUSION is significantly smaller than 0.001 in  (we verified that, with the same optimality gap, our result for EXCLUSION is almost the same as the one in ). We mainly use the runtime and the percentage of games that are not solved within the time limit to measure the performance of our approach. Details are shown in Appendix F (also caption of Table 1).

**Result:** Part of results are shown in Table 1, and more results are in Tables 4 and 5 of Appendix H. They show that the runtime of our CRM steadily increases with the game size. Note that the runtime of CRM includes the runtime for our Algorithm 1, which is extremely small (see Appendix E). Moreover, CRM is significantly faster than the baselines and is two or three orders of magnitude faster than the state-of-art baselines MIBP, ENUMPOLY, and EXCLUSION in most games. The reasons are that: 1) MIBP with too many bilinear terms and large feasible solution space after the relaxation cannot perform well without CRM's novel techniques in Section 3, where each of these techniques significantly boosts the performance (see the ablation study); and 2) the exponentially many NEs and the large search space caused by splitting the continuous probability space make ENUMPOLY and EXCLUSION, respectively, hard to scale up. EXCLUSION always has large utility gaps, which means that we will lose large utilities if we use EXCLUSION for our problem. The result that CRM runs significantly faster than EXCLUSION means that CRM is a faster algorithm not only for computing an optimal NE but also for just computing an NE. Furthermore, the gap between CRM and any of the baselines increases with the number of players or actions. In games with a large gap between CRM and baselines, the real gap should be larger because these baselines have not solved all of them within the time limit, while CRM solved all of them. Overall, CRM significantly overcomes the limitation of baselines.

**Ablation Study**: We evaluate each component of CRM by using the following variants: i) **CR**: solving Program (13) based on \(}\); ii) **CM**: solving Program (13) based on \(}\) without the relation constraints Eqs.(11) and (12); iii) **C**: solving Program (13) based on \(}\) without the relation constraints Eqs.(11) and (12); and iv) **M**: solving Program (5) based on \(}\). Part of results are in Table 2, and more results are in Table 6 of Appendix H. We can see that each component of our approach significantly boosts its performance.

## 5 Related Work

Existing works define a correlation plan as a probability distribution over the joint action space of all players, and use it to formulate constraints for a correlated equilibrium [37; 1]. However, the constraints for the space of correlated equilibria cannot be used in our program due to the following two reasons. First, there are no correlation plans for coordinating all players in our program after the convex relaxation because our formulation based on  has reduced the degree of the multilinear program for the space of NEs in order to significantly reduce the number of bilinear terms. Second, our correlation plans are different from the correlation plan for correlated equilibria because our correlation plans are only for subsets of the players. Recently, the correlation plan  based on a decomposition of the extensive-form game into public states has been used to compute correlated equilibria. However, their approach is not suitable for our problem because our game is not extensive-form and then does not have the property of their problem. Then our approach exploiting the relations of correlation plans and minimizing the number of correlation plans is novel.

Several recent efforts have developed relatively efficient algorithms to find an NE that maximizes the utility of a team of players in zero-sum games [45; 50; 51; 52; 11; 24; 53]. However, these algorithms cannot be used in games where team members have different utility functions. Existingworks transforming multilinear terms into bilinear terms only focus on special cases. For example, the transformation in  is equivalent to our transformation based on \(}\), which is only a special case of our transformation framework. They  then directly solves the bilinear program based on this special transformation for finding an NE, which is equivalent to our baseline MIBP. Experiments show that our approach with novel techniques in Section 3 significantly outperforms . Similar to the formulation in , there are other formulations [2; 3] for finding an optimal NE for two players under the problem of computing a leader-follower (Stackelberg) equilibrium for a single leader and two followers after a mixed strategy is committed by the leader. These formulations are different from ours because of the difference between the NE and the Stackelberg equilibrium. For example, the leader will commit a strategy to the followers in a Stackelberg equilibrium, i.e., the followers know the leader's strategy, but this cannot happen in an NE as all players move simultaneously. Moreover, after dropping the dependences of the followers to the leader's strategies in these bilinear programming formulations, the problem boils down to computing an optimal NE in two-player games because they only consider two followers in their formulations, which results in the same two-player formulation of .

For the existing general optimization techniques, e.g., Reformulation-Linearization Technique (RLT) [35; 25; 36], they add linear constraints by multiplying linear constraints with a single variable to reduce the feasible solution space of the convex relaxation and the number of bilinear terms if they can be represented by linear constraints (i.e., variants of original linear constraints). However, these operations are not very effective for our problem because the bilinear terms cannot be represented by those linear constraints (i.e., variants of original linear constraints), and simply multiplying linear constraints with a single variable cannot effectively represent the relation between auxiliary variables and nonlinear terms. Indeed, RLT is implemented in Gurobi [18; 19], but its performance (see MIBP in Table 1) is not good enough for large games in experiments. Moreover, our approach significantly outperforms the state-of-the-art optimization solver Gurobi (see results for CRM versus MIBP in Table 1) in experiments.

## 6 Limitations

Similarly to the previous literature [34; 4; 13], to efficiently evaluate the algorithms, we set a time limit of 1000 seconds for each case unless stated otherwise. It means that we may need 30,000 seconds (almost 8 hours) to run an algorithm for each game setting (e.g., the game \((6,3)\)) with 30 cases. We totally run 13 algorithms for 21 different game settings, whose total runtime is more than 2,000 hours if each algorithm needs 30,000 seconds for each game setting. A higher time limit means more runtime. For example, if the time limit is 10,000s, we may need 20, 000 hours (more than 800 days), which is not reasonable for a personal computer. Increasing the game size will cause a similar problem as well. Our goal is only to show that our proposed algorithm runs faster than baselines. Therefore, as a proof of concept, our time limit and game size are reasonable and practical.

Our algorithm CRM is significantly faster than the state-of-the-art baseline, and it can solve many real-world games: e.g., (1) multiplayer hand games using only the hands of the players (https://en.m.wikipedia.org/wiki/Hand_game), including the rock-paper-scissors games, Morra games, and their variants; and (2) the matching pennies game with several players and only two actions for each player. However, we cannot handle extremely large games now because we are handling a very hard problem, and then it is unrealistic to expect that our exact algorithm CRM could run very fast in large games. Our algorithm is an attempt to make this computation of optimal NEs feasible, and our algorithm framework can be built on by further innovative heuristics to improve the computation of optimal NEs. That is, for games with more players or actions, we can exploit the auxiliary speed-up techniques: the multiagent learning framework--Policy-Spaced Response Oracles (PSRO) [22; 54; 55; 51; 46; 23], the abstraction techniques , or only considering approximate NEs. Specifically, our algorithm CRM could be used as the meta-solver in PSRO.

## 7 Conclusion

This paper proposes a novel algorithm (CRM) for computing optimal NEs based on our transformation framework. CRM uses correlation plans with their relations to strictly reduce the feasible solution space after the convex relaxation while minimizing the number of correlation plans to significantly reduce the number of bilinear terms. Experiments show that CRM significantly outperforms baselines.