# BALLAST: Bayesian Active Learning with Look-ahead Amendment for Sea-drifter Trajectories

Rui-Yang Zhang

Lancaster University

r.zhang26@lancaster.ac.uk

&Henry B. Moss

Lancaster University

henry.moss@lancaster.ac.uk

&Lachlan C. Astfalck

The University of Western Australia

lachlan.astfalck@uwa.edu.au

&Edward J. Cripps

The University of Western Australia

edward.cripps@uwa.edu.au

&David S. Leslie

Lancaster University

d.leslie@lancaster.ac.uk

###### Abstract

We introduce a formal experimental design methodology for guiding the placement of drifters to infer ocean currents. The majority of drifter placement campaigns either follow standard'space-filling' designs or relatively ad-hoc expert opinions, which could be significantly improved on by appealing to statistical experimental design. Drifter observations follow a Lagrangian structure as drifters are advected through the Eulerian vector field. It is, therefore, important to consider the likely future trajectories of placed drifters to compute the utility of candidate measurement locations. We present BALLAST: Bayesian Active Learning with Look-ahead Amendment for Sea-drifter Trajectories, a novel light-weight, nonmyopic policy amendment for drifter trajectory data that can be appended to any myopic policy. Our numerical studies suggest benefits in incorporating BALLAST into the sequential placement strategies of drifters.

## 1 Introduction

Understanding and predicting ocean currents are of vital importance to mapping the flow of heat, nutrients, pollutants and sediments in the ocean . Ocean currents are inferred from a plurality of measurement devices, such as fixed-location buoys, satellites and free-floating buoys, known as drifters . Free-floating drifters are being increasingly used due to their ability to sample both spatial and temporal flow properties and remain relatively affordable as compared to other measurement devices .

Standard experiment designs consider measurement devices that operate at a single location at a single time. Drifters are different: advected by the background vector field, drifters proceed to move following the Lagrangian flow of the ocean currents and collect data at multiple locations at multiple times (see the orange observation trajectories and the extended red observations in Figure 1). Drifter measurements thus require nontrivial policies for experiment designs and sequential experiment designs (SED) where observations are made incrementally -- allowing efficient dynamic experimentation by adapting to the results of previous measurements. However, the majority of existing drifter placement campaigns either follow standard'space-filling' designs  or relativelyad-hoc expert opinions . To the best of our knowledge, methodology for a formal statistical design of drifter allocation strategies does not exist.

Standard (S)ED policies only consider the observation made immediately at the selected observation point, making them _myopic_[4; 16] and are likely insufficient to guide the temporally extended Lagrangian observations associated with drifter placement designs. Policies that take into account potential future observations, often called _nonmyopic_ policies, exist in the literature [8; 7; 23], but they focus on solving or approximating the Bellman equation considering the next several observations actively selected by the decision-maker (see  for a discussion). A practical sequential placement strategy for drifters should incorporate potential future trajectories while remaining computationally light-weight.

In this work, we introduce an experimental design strategy for drifters -- Bayesian Active Learning with Look-ahead Amendment for Sea-drifter Trajectories (BALLAST) -- that offers a _light-weight_, _nonmyopic_ policy amendment by leveraging a vector-output Gaussian process model and the drifters' Lagrangian trajectory structure. We make three primary contributions: (i) we introduce sequential experimental design concepts to the problem of drifter placement, (ii) we propose a novel light-weight, nonmyopic SED policy amendment that can be easily appended to most existing myopic SED policies like maximum variance and maximum integrated variance , and (iii) we present the results of numerical simulations that showcase improved performance of our proposed policy over common alternatives.

## 2 Background

Gaussian ProcessesA vector-output Gaussian process model is used here to model the 2-dimensional, stationary vector field that represents the ocean currents over a region. A vector-output Gaussian process (GP) \(\{(x)\}_{x}\) with input space \(\), output space \(^{D}\) with \(D>1\), \(^{D}\)-valued mean function \(\) and \(^{D D}\)-valued covariance function \(k\) is a continuous stochastic process fully denoted as \(()((),k(,))\) such that every finite collection of random variables in \(\{(x)\}_{x X}\) has a multivariate normal distribution [22; 1]. Normally, the mean function \(\) is set to be a constant-zero function, which will be the case here too. Details about regressions and predictions with a vector-output GP can be found in Appendix A.

Experimental DesignExperimental design considers the problem of choosing the optimal measurement \(x^{*}\) given some existing data \(\) and a model \(g\) according to some utility function \(U\) that calculates the expected quality of each possible measurement \(x\) within the measurement set \(R\) under the belief of our latest model \(g\). Mathematically, this is given by \(x^{*}=*{argmax}_{x R}_{g}[U(x,g,)]\). When we wish to make measurements _sequentially_, or adaptively, we will find an optimal measurement \(x^{*}_{n+1}\) for each time \(n\) based on existing data \(_{n}\) and latest model \(g_{n}\) according to \(x^{*}_{n+1}=*{argmax}_{x R}_{g_{n}}[U(x,g_{n}, _{n})]\).

Figure 1: An example run with Max Var BALLASTs method with 10 sampled look-aheads. (Left) The ground truth field. (Mid) The estimated field using three placed drifters with the predictive standard deviation as the heat map. Trajectories of the three currently placed drifters are in orange. The three stars indicate three candidate locations for the next placement, with purple arrows indicating the 10 look-ahead trajectories sampled from our current model of the underlying flow. The blue star is the selected location for the next placement. (Right) The estimated field using four placed drifters with new observations in red.

In this work, we will use a Gaussian process as our model due to its expressibility, conjugacy with data updates and inherent uncertainty quantification. The choice of utility functions is central to the effectiveness of an (S)ED. Two common choices of utility functions are the variance of our latest model \(g_{n}\) at the candidate decision \(x\) (yielding the _maximum variance policy_), and the total variance of the posterior distribution of our model after being updated by the candidate decision \(x\) and its outcome \(y\) (yielding the _maximum integrated variance policy_). See [6; 18] for comprehensive introductions to these designs.

## 3 Sequential Drifter Placement and BALLAST

The problem of sequential drifter placement can be formulated as follows. Consider a fixed region \(R^{2}\) of the ocean that we wish to understand its currents. Let \(\) denote the true stationary vector field of the region \(R\). We will place drifters sequentially into the region and use the observations to infer the true field \(\), and the goal is to maximally reduce our uncertainty about \(\) using a minimum number of drifters.

Assuming \(n\) drifters are currently deployed, we have existing data \(_{n}\) and latest model \(g_{n}\). With a utility function choice \(U\), the myopic allocation policy is to only consider the initial placement point from \(R\), selected by

\[x^{*}=*{argmax}_{x R}_{g_{n}}[U(x,g_{n},_{n})].\] (1)

Recall that drifters are free-floating and will keep collecting data at different locations once placed. A myopic policy does not take into account the future trajectory of a drifter placed at \(x\) and could favour locations that are apparently more promising yet uninformative overall -- say the placed drifter leaves \(R\) immediately or is stuck in a convergent region and so is, in effect, stationary. With myopic policies, the Lagrangian structure of the drifter observations is completely ignored.

### Ballast

We propose the BALLAST method, a nonmyopic policy amendment with look-aheads of drifter trajectories that is computationally expedient. While still considering only the initial placement point \(x R\), we construct the look-ahead of a drifter placed at \(x\) via a projection of \(T\) steps with step size \(\) using a vector field \(}\), denoted by \(P_{}^{T}(x,}) R^{T+1}\). Given \(n\) existing drifters with data \(_{n}\) and model \(g_{n}\), the **BALLAST** method determines the next placement location by

\[x^{*}=*{argmax}_{x R}_{g_{n}}[U(P_{}^{T} (x,}),g_{n},_{n})].\] (2)

We will denote the conversion from Equation (1) to Equation (2) as the **BALLAST amendment** to the base myopic policy. Various design choices of this amendment are discussed below.

Look-ahead ProjectionThe trajectory of a drifter at \(x\) inside the vector field \(}\) can be approximated using numerical ordinary differential equation solvers. The simplest choice is the Euler method, which iteratively updates each step by \(x_{(m+1)}=x_{m}+}(x_{m})\) for \(m^{ 0}\) where \(}(x)\) denotes the value of the field \(}\) at \(x\). Other solvers such as the implicit Euler method can also be used .

Step Size and NumberCaution is required when setting the step size \(\) and the step number \(T\) to balance the trade-off between practicality and accuracy. A tiny step size \(\) may induce unwanted computational costs, yet too large a step size will produce poor approximations of the drifter dynamics and yield inaccurate predictions. For step number \(T\), a small value will make the policy more myopic, which we wish to avoid, yet a large value will incur additional computational costs. Furthermore, the look-ahead is based on an estimated vector field \(}\), which could be erroneous, so too long of a look-ahead might be misleading.

Estimated Vector FieldChoice of the estimated vector field reflects our latest understanding of currents in the region \(R\). As alluded to previously, the quality of the estimated vector field strongly influences the projection quality. Here, we propose two ways to construct the estimated field which induce two versions of BALLAST. The first way is to choose, naively, the predictive mean \(_{_{n}}\) of the latest GP model \(g_{n}\), that leads to the policy

\[x^{*}=*{argmax}_{x R}_{g_{n}}[U(P_{}^{T}(x,_{_{n}}),g_{n},_{n})]\] (3)

which we call **BALLASTn**. The second way is to draw \(K\) independent sample fields \(\{}_{k}\}_{k=1}^{K}\) from the predictive distribution of the latest model \(g_{n}\) and estimate the utility using the sample averages. Denote this second method by **BALLASTs**, with \(}_{k} g_{n}\) for \(k=1,2,,K\), we have

\[x^{*}=*{argmax}_{x R}_{k=1}^{K}_{g_{ n}}[U(P_{}^{T}(x,}_{k}),g_{n},_{n})].\] (4)

One should note that BALLASTs and BALLASTn are different. For BALLASTs, when we take the limit \(k\), we get

\[_{k=1}^{K}U(P_{}^{T}(x,}_{k}),g_{n},_{n})_{} g_{n}}[U(P_{}^{T}(x,} ),g_{n},_{n})]\]

whereas for BALLASTn we have

\[U(P_{}^{T}(x,_{} g_{n}}[}]),g_{n}, _{n})\]

instead. Since \(U P_{}^{T}\) is not a linear function in the field choice, the two quantities are not identical, showing that BALLASTs and BALLASTn are indeed different.

Utility FunctionIt is obvious from the formulation that the BALLAST methods are compatible with any utility function \(U\). With the look-ahead amendment provided by BALLAST methods, we have observed noticeable improvements from utility choices such as maximum variance and maximum integrated variance, as supported by the simulations in the following section.

## 4 Simulation Results

We generate a ground truth vector field \(\) from a vector-valued GP parameterised by the Helmholtz kernel of  with prespecified hyperparameters. A total of 8 drifters are sequentially placed with \(T=5 0.03\) unit time apart, and the observations provided by the drifters follow the ground truth field \(\) with small additive observation noise. When a drifter leaves the region \(R\), we terminate its motion. Eight placement policies are considered: uniform sampling, Sobol sequence , maximum variance, maximum variance with BALLASTn, maximum variance with BALLASTs using 100 sampled look-aheads, maximum integrated variance, maximum integrated variance with BALLASTn, and maximum integrated variance with BALLASTs using 100 sampled look-aheads. As demonstrated in Figure 1, we update the model and compute the mean squared error (MSE) of the predictive mean with each placement. Further details of the experiment are found in Appendix B.

Figure 2 shows experimental results over 100 random starting seeds and indicates improvements, regardless of the base utility functions, of the BALLAST amendments. The improvement is more significant as more drifters are placed. Furthermore, a simple policy like maximum variance after BALLAST amendments displays comparable performance to a more complicated myopic policy, the maximum integrated variance.

We have not carried out a thorough computational cost comparison, but for indicative timings using a standard laptop, one full run of the simulation with the maximum variance policy takes 15 seconds, while that with the BALLASTn takes around 20 seconds and that with the BALLASTs using 100 sampled look-aheads under simple parallelization of the samples takes around 1 minute 15 seconds. For operational drifter placement, these computational costs are likely to be insignificant.

## 5 Conclusion

In this paper, we introduce a formal experimental design of the sequential placement of drifters for ocean currents inference. Our numerical results showed that SED-based policies noticeably outperformed common ad-hoc or space-filling drifter allocation strategies, which are further outperformedby our proposed light-weight and nonmyopic BALLAST extensions. Potential further work includes considering time-varying ocean flows, for which more efficient sampling methods will be investigated , establishing theoretical guarantees for the non-myopic benefits of BALLAST, and incorporating BALLAST into a wider risk-averse  framework or incorporating information-theoretic framework for batch  or multi-fidelity designs .