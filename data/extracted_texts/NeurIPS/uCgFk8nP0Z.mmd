# DU-Shapley: A Shapley Value Proxy for

Efficient Dataset Valuation

 Felipe Garrido-Lucero*

Inria, Fairplay joint team

Palaiseau, France

felipe.garrido-lucero@irit.fr

* Equal contribution

Benjamin Heymann*

Criteo AI Lab

Paris, France

b.heymann@criteo.com

* Equal contribution

Maxime Vono*

Criteo AI Lab

Paris, France

m.vono@criteo.com

* Equal contribution

Patrick Loiseau

Inria, Fairplay joint team

Palaiseau, France

patrick.loiseau@inria.fr

Vianney Perchet

ENSAE, FairPlay joint team

Palaiseau, France

vianney@ensae.fr

###### Abstract

We consider the _dataset valuation problem_, that is, the problem of quantifying the incremental gain, to some relevant pre-defined utility of a machine learning task, of aggregating an individual dataset to others. The Shapley value is a natural tool to perform dataset valuation due to its formal axiomatic justification, which can be combined with Monte Carlo integration to overcome the computational tractability challenges. Such generic approximation methods, however, remain expensive in some cases. In this paper, we exploit the knowledge about the structure of the dataset valuation problem to devise more efficient Shapley value estimators. We propose a novel approximation, referred to as discrete uniform Shapley, which is expressed as an expectation under a discrete uniform distribution with support of reasonable size. We justify the relevancy of the proposed framework via asymptotic and non-asymptotic theoretical guarantees and illustrate its benefits via an extensive set of numerical experiments.

## 1 Introduction

One of the main challenges for training machine learning (ML) models with enough generalization capabilities is to access a sufficiently large set of labeled training data. These data often exist but are commonly spread across many parties, impairing their usage in a direct and simple way. Real world examples range from the advertising industry, where different retailers hold sets of observations with either similar or complementary features from consented data about browsing and shopping habits of individual users; to the medical sector where hospitals may improve their diagnostics accuracy by sharing their data. By collaborating with each other and pooling their individual datasets together, these _dataset owners_ could learn better ML models for their applications. Naturally, many questions raise from such collaborations. Federated learning [8; 9], for example, addresses the issues related to the practical ways that dataset owners can share their data. We consider a complementary problem to the one in federated learning: measuring the additional value each party would obtain by participating in the joint ML effort. In order to compute or estimate compensating rewards allowing to incentivize parties to share their data, a first stage that is commonly considered in the literature is to perform so-called _dataset valuation_[1; 42; 44].

Motivated by natural properties expected for fair valuation, different solution concepts from cooperative game theory  have been considered, the Shapley value  being arguably the most broadlystudied valuation scheme in ML due to its axiomatic justification. Agarwal et al.  designed a data marketplace and used the Shapley value to allocate the data among buyers. Tay et al.  considered a cooperative environment where agents can jointly train a generative model, from which synthetic data are drawn and distributed to the parties according to their Shapley values. Sim et al.  rewarded parties based on the Shapley value and information gain on model parameters. The critical challenge when using the Shapley value is its well-known computational intractability. To cope with it, [1; 44] considered Monte Carlo (MC) approximations, while  worked with a small set of three players. This approximation methods, however, remain expensive whenever computing the marginal contributions involve retraining. Moreover, they are generic and do not use the specific structure of the dataset valuation problem at stake, leaving open the possibility to find more adapted approximations for that problem.

The Shapley value was also used in the related problem of _data valuation_. Data valuation measures the contribution of a single data point within a dataset in the training of a given prediction model. Several solution concepts based on the Shapley value have been proposed for the data valuation problem including Data Shapley[10; 16], DShapley[11; 24], Beta Shapley or CS-Shapley, together with different MC variants to cope with the computational intractability issue. For the data valuation problem, the structure was exploited to give easier-to-compute solutions in certain cases, in particular for the \(k\)-nearest neighbor problem [12; 15; 25; 26; 35; 41; 46]. Unlike data valuation, however, dataset valuation aims at quantifying the marginal contribution of a _whole dataset_ to a given ML task with respect to (w.r.t.) the datasets brought by other dataset owners. Although data and dataset valuation are related problems, they are different and the techniques developed for data valuation cannot be used for the dataset valuation problem that we study (we further develop this point in Section 2.3).

**Contributions.** We consider the dataset valuation problem. Following the ML literature, we model it as a cooperative game whose value function relates to the considered ML task, and aim at estimating the Shapley value to measure the dataset owners contribution. We propose a new way to address the computational intractability issue of the Shapley value. Instead of relying on generic MC approximation schemes, our approximation method leverages the structure of the dataset valuation problem as well as a convergence result for a key random variable of the problem. Our approximation behaves well in many cases, both theoretically and empirically. More specifically, our main contributions can be summarized as follows:

1. [leftmargin=*]
2. We propose DU-Shapley (Definition 3), a novel Shapley value approximation that exponentially reduces the number of utility function valuations required for the computation. This is the first dataset valuation approach leveraging the specific structure of the utility function.
3. Based on three different use-cases, we establish asymptotic and non-asymptotic theoretical guarantees for DU-Shapley, showing notably that it converges almost surely to the Shapley value as the number of dataset owners grows.
4. We assess the benefits of the proposed methodology using extensive numerical experiments on both Shapley value approximation and dataset valuation use-cases. We show, in particular, that DU-Shapley outperforms all considered MC approximations of the Shapley value.

**Additional Related Work.** Cooperative game theory has been applied to solve multi-agents ML problems beyond data and dataset valuation [6; 18; 29; 47]. In particular, the Shapley value has been used to solve several problems including variable selection , feature importance [7; 27; 28], or model interpretation . In these problems, similarly to the data and dataset valuation problems, the computational intractability issue of the Shapley value is usually addressed via MC [2; 31; 32].

## 2 Problem Formulation and Main Concepts Involved

This section presents the dataset valuation problem we aim to solve, along with preliminaries including the definition and classical approximations of the Shapley value. For \(n\) and \(A\), we denote \([n]:=\{1,..,n\}\) and \((A)\) the uniform distribution with support on \(A\).

### Generic Model

We consider a collaborative ML setting involving a set \(\) of \(I=||^{*}\) dataset owners, also referred to as players in the sequel, who are willing to cooperate in order to solve a common ML problem. Each player \(i\) is assumed to possess an individual dataset \(_{i}=\{(x_{i}^{(j)},y_{i}^{(j)})\}_{j[n_{i}]}\)where \(x_{i}^{(j)}^{d}\) stands for a feature vector, \(y_{i}^{(j)}\) is a label, \(n_{i}=|_{i}|\) refers to the number of data points in \(_{i}\), and samples are drawn independently from a player-dependent distribution \(p_{i}\), i.e., \((x_{i}^{(j)},y_{i}^{(j)}) p_{i}\), for all \(j[n_{i}]\) and \(i\).

Our basic motivation is to quantify the incremental contribution that a given player \(i\) brings by sharing her dataset \(_{i}\) with other players towards solving some ML task. Hence, we are interested in scenarios in which, even though the data distribution might differ across players, they face a similar ML task, for instance the minimization of the expectation (with respect to \(p_{i}\)) of some loss function \((,Y)\), where \(\) denotes a prediction of \(Y\). In such cases, players can usually learn from others' datasets, in the sense that given some \(X\), the optimal prediction \(\) that minimizes \([(,Y)|X]\) is the same for all player. This holds, _e.g._, if the conditional distributions (or, in many cases, simply the conditional expectation) of \(y^{(j)}\) given \(x^{(j)}\) are the same but the marginal distributions of \(x^{(j)}\) differ.

To model this problem with full generality, we assume that the players \(i\) collaborate in solving an ML task whose success is measured through some abstract metric \(u\) that maps any dataset to a real number (say, the prediction accuracy in a classification problem). With a slight abuse of notation, for any coalition of players \(\), we define \(u()=u(_{})\), where \(_{}:=_{i}_{i}\). Hence, \(u:2^{}\) can be seen as a game-theoretical utility function that quantifies how well coalitions of players can solve the considered ML task based on the union of their datasets.

The following subsections provide three theoretical use-cases that instantiate the generic model and give specific utility functions \(u\) to illustrate the dataset valuation problem. Using different tools and techniques, Section 3 provides theoretical guarantees in each of them. These theoretical results are then complemented in Section 4 by numerical evidence of our proposed approach in more intricate practical problems on real data.

#### 2.1.1 Theoretical use-case 1: Non-parametric Regression

The first use case we shall investigate is quite generic and consists in non-parametric regression. We assume the existence of a function \(f^{*}\) such that \(y_{i}^{(j)}=f^{*}(x_{i}^{(j)})+_{i}^{(j)}\) with \(_{i}^{(j)}\) i.i.d., and a quadratic loss function. Without regularity assumption on \(f^{*}()\), learning can be arbitrarily slow; hence it is usually assumed that this mapping is Lipschitz (or at least \(\)-Holder [13; 45]).

The standard estimation method of \(f^{*}\) we shall consider is called the _regressogram_ or binning (also applied in  to study local differential privacy within regression) and consists in learning optimal piece-wise constant functions. More precisely, given some parameter \(B\)--chosen exogeneously as a function of the function regularity \(\), the ambient dimension \(d\) and the total number \(n\) of datapoints, typically \(B n^{}{{(d+2)}}}\)--, the feature space \(\) is partitioned into \(B\) cubic bins. The excess risk of learning \(f^{*}\) can then be decomposed into

\[((x)-f^{*}(x))^{2}=((x )-(x))^{2}+((x)-f^{*}(x))^{2},\] (1)

where \(\) is the estimator of \(f^{*}\), \((x):=_{b[B]}_{b}\{x b\}\), and \(_{b}\) is any value that \(f^{*}\) can take on the bin \(b\). The second term in (1) being agnostic to the players' datasets, the problem of measuring the contributions of the players to estimating \(f^{*}\) can be decomposed into measuring their contributions to estimating each \(_{b}\). In particular, the utility \(u()\) of a coalition \(\) can be defined, and split into the sum of \(B\) sub-utilities \(u_{b}()\) functions, as follows

\[u():=-(_{}(x)-(x))^{2} =_{b[B]}-(_{,b}- {f}_{b})^{2}(x b)=:_{b[B]}u_{b}()(x b),\]

where \(_{}\) is the estimator of \(\) when using the datasets of all players in \(\) and \(_{,b}\) is the estimator \(_{b}\) when using, for all players in \(\), the datasets of points in the bin \(b\). Interestingly, after this reduction, the problem is decomposed into \(B\) independent sub-problems--one per bin--, where the utility is a sole function of the number of data points used to estimate \(_{b}\), i.e., we can write \(u_{b}()=w_{b}(_{i}n_{i,b})\) for some function \(w_{b}:\), where \(n_{i,b}\) is the number of data points that player \(i\) has in the bin \(b\). This last property motivates our second theoretical use-case.

#### 2.1.2 Theoretical use-case 2: Homogeneous case

The second theoretical setting considers a general learning problem (not necessarily restricted to regression) and supposes that all players have the same sampling distribution, i.e., it takes \(p_{i}=p\)for all \(i\). This homogeneity on the players allows to reduce the problem of measuring the contribution of the players to just counting the number of data points contributed by each of them. Formally, and similarly to the previous use-case, we suppose the existence of a function \(w:\) such that \(u()=w(_{i}n_{i})\).

#### 2.1.3 Theoretical use-case 3: Heterogeneous Linear Regression - Local Differential Privacy

The third theoretical setting we consider is linear regression with random design and different variance of the features and labels per player. Although the setting is more general, one of the motivations behind it is standard linear regression with homogeneous data between players, but where players can purposely add noise when sharing their dataset (in order to provide Local Differential Privacy, for instance). Formally, for any \(i\), we consider the following linear model that generates the dataset \(_{i}\) of size \(n_{i}\):

\[y_{i}^{(j)}=x_{i}^{(j)}+_{i}^{(j)}\,,_{i}^{(j)} (0,_{i}^{2})\,,x_{i}^{(j)}(0_{d}, _{i}^{2}_{d})\,,j[n_{i}],\] (2)

with \(^{d}\) a ground-truth parameter, \(_{i}\) positive and known, and \(_{i}\) the differential privacy level chosen by player \(i\). Under the linear regression framework defined in (2), and following , the utility function of a set \(\) of players is defined by the negative expected mean square error over a hold-out dataset, i.e.,

\[u()=-x^{}_{}-x^{ }^{2}\,,\] (3)

where the expectation is taken over the distribution \(p_{}\) of a hold-out testing datum \(x^{d}\), the sampling distributions \((0,_{i}^{2}_{d})\) for all \(i\), and the linear regression error distributions \((0,_{i}^{2}), i,j[n_{i}]\), and \(_{}\) stands for the generalized least square estimator defined by \(_{}=(X_{}^{}_{}^{-1}X_ {})^{-1}X_{}^{}_{}^{-1}Y_{},\) where \(_{}=((_{i}^{2})_{i}) ^{||||}.\) The notations \(X_{}\) and \(Y_{}\) refer to the concatenation of \(\{X_{i}\}_{i}\) and \(\{Y_{i}\}_{i}\), respectively, and \(X_{i}^{n_{i} d}\) is defined by \(X_{i}=([x_{i}^{(1)}]^{},,[x_{i}^{(n_{i})}]^{})^{}\) while \(Y_{i}^{n_{i}}\) is defined by \(Y_{i}=(y_{i}^{(1)},,y_{i}^{(n_{i})})^{}\).

The following result provides a close-form expression for the utility function in this case:

**Proposition 1**.: _Let \(\) be a coalition of players and consider the value function as above. It follows,_

\[u()=xx^{} }{q()-d-1},q():=\,_{i} }}{{_{i}}}n_{i}^{2}}{_{i }}}{{_{i}}}^{2}n _{i}}\,\,,q()=0.\]

_In particular, considering \(p_{}=(0,_{d})\), we get \(u()=)}\)._

Proposition 1 shows that, in this use-case, the utility function can be written as a function \(w(q())\) of a scalar quantity \(q()\) that captures the datasets heterogeneity. Notice that in this use-case, if we add the homogeneity assumption that \(_{i}/_{i}=/\), for all \(i\), then the term \(q()\) becomes \(_{i}n_{i}\) and, as a consequence, we get

\[u()=w(q())=w(_{i}n_{i} )=}n_{i}}.\]

Recall that, in the non-parametric regression use-case, it holds \(u()=_{b[B]}(x b)w_{b}(q_{b}())\) where \(q_{b}()=_{i}n_{i,b}\). Therefore, in our three uses-cases, the utility of a coalition can be summarized as the function of some scalar quantity of interest. This observation will be useful to state later our theoretical results.

### Shapley Value

The Shapley value  is a classical solution concept in cooperative game theory to fairly allocate the total gains generated by a coalition of players. Given a utility function \(u\), the Shapley value of a player \(i\) is defined as the average marginal contribution of her dataset \(_{i}\) to all possible subsets of \(\{_{j}\}_{j\{i\}}\), built by aggregating the datasets of the other players. Formally, the Shapley value \(_{i}\) of player \(i\) writes

\[_{i}(u)=)|}_{()}[u(_{i}^{}\{i\})-u(_{i}^{})]\,,\] (4)where \(()\) refers to the set of permutations over \(\) and \(_{i}^{}\) to the set of predecessors of player \(i\) in permutation \(()\). The Shapley value of player \(i\) is equivalently expressed as

\[_{i}(u)=_{ \{i\}}(I-1\\ ||)^{-1}[u(\{i\})-u( )].\] (5)

The Shapley value has been commonly used in ML and cooperative game theory as it uniquely satisfies the following set of desirable properties.

1. _Efficiency._\(_{i=1}^{I}_{i}(u)=u()\), i.e, the sum of all Shapley values is equal to the value of \(\).
2. _Symmetry._ If, for any \(\{i_{1},i_{2}\}\), \(u(\{i_{1}\})=u(\{i_{2}\})\), then \(_{i_{1}}(u)=_{i_{2}}(u)\), i.e., whenever two players have the same marginal contributions, their Shapley values coincide.
3. _Dummy._ If, for any \(\{i\}\), \(u(\{i\})=u()\), then \(_{i}(u)=0\), i.e., whenever a player has null marginal contributions, her Shapley value is zero.
4. _Linearity._\(_{i}(u_{1}+u_{2})=_{i}(u_{1})+_{i}(u_{2})\), i.e., the Shapley value of sums of games is the sum of the Shapley values of the respective games.

**MC approximation of the Shapley Value.** Evaluating the Shapley value is unfortunately computationally expensive in general. As a consequence, many MC approximations have been considered by sampling with replacement \(T\) terms from the sum of either (4) or (5). Regarding (4), this boils down to considering the estimator

\[_{i}(u)=_{t=1}^{T}[u(_{i }^{_{t}}\{i\})-u(_{i}^{_{t}})],_{t} (()).\] (6)

### Data valuation vs Dataset valuation

A tentative, but naive, approach to solve the dataset valuation problem could be to run an auxiliary data-valuation algorithm on all the data and to assign to each dataset the sum of the values of its datapoints. We highlight the cons of this idea on a very simple, yet insightful example. Consider two datapoints \(x_{1}\) and \(x_{2}\), three datasets \(_{1}=\{x_{1}\}\), \(_{2}=\{x_{2}\}\), \(_{3}=\{x_{2},x_{2}\}\), and the following toy utility function \(u()=\{x_{1},x_{2}\}\). In data valuation, any point \(x_{2}\) shall have the same value, as they are identical. In particular, a naive summation would value \(_{3}\) twice the value of \(_{2}\). In dataset valuation, and for this toy problem at hand, it is quite clear that both datasets should have the same value. Moreover, the Shapley values are \(1/6\) for \(_{2}\) and \(_{3}\) versus \(2/3\) for \(_{1}\).

The message here is twofold. Data valuation and dataset valuation are two fundamentally different concepts and one cannot directly reduce the latter to the former. This is actually true, and this is the second message, because the utility function \(u\) is highly non-linear (even for the regression task).

## 3 Discrete Uniform Shapley Value

This section introduces and studies our approximation scheme for the Shapley value. Section 3.1 shows an asymptotic property that gives the general intuition behind our approximation. The result holds for the three use-cases of Sections 2.1.1 to 2.1.3. Section 3.2 presents a general approximation methodology for dataset valuation and shows its almost surely convergence as the number of players grows for our three uses-cases. Section 3.3 studies the rate of convergence, first for the homogeneous setting (Section 2.1.2), and then leverages this result to obtain a similar one for the non-parametric regression setting (Section 2.1.1). All proofs are postponed to the supplementary material.

### Insights behind \(\)-Shapley

The Shapley value, by re-arranging the coalitions \(\{i\}\) by their cardinality in the sum in (5), can be equivalently expressed as

\[_{i}(u)=_{K(\{0,,I-1\})}_{ (2^{\{i\}}_{K})}[u( \{i\})-u()]\,,\] (7)

where \(2^{\{i\}}_{K}\) denotes the subsets of \(\{i\}\) of cardinality \(K\). In our three uses-cases, it follows that

\[_{i}(u)=_{i}(w)=_{K(\{0,,I-1\})} _{(2^{\{i\}}_{K} )}[w(q(\{i\}))-w(q())]\,,\] (8)where \(w:_{+}\) is such that \(u()=w(q())\) for any \(\), and \(q()\) is the scalar quantity of interest identified in Sections 2.1.1 to 2.1.3 for each use-case:

\[q():=}_{i}n_{i} )^{2}}{_{i}_{i}^{2}n_{i}},i,_{i}=\{1&,\\ _{i}/_{i}&,.\] (9)

and for the first use-case, \(q_{b}()\) is analogously defined at every bin, with \(_{i}^{b}=1\) for all players and all bins. We remark that the definition of \(q()\) in the first and second use-cases is not restricted to linear regression. Equation (8) explicitly reveals a key random variable, namely \(q()\). Interestingly, Figure 1 suggests that \(q()\) converges in distribution to a uniform random variable as the number of players increases (with i.i.d. datasets sizes). Theorem 2 proves this result formally for any \((_{i})_{i}\).

**Theorem 2**.: _Let \(\{n_{i},_{i}\}_{i[I]}\) be two sequences of positive numbers such that the following limits_

\[_{I}_{i[I]}n_{i}_{i }=_{A},_{I}_{i[I]}(n_{i} _{i}-_{A})^{2}=_{A}^{2},\] \[_{I}_{i[I]}n_{i}_{i }^{2}=_{B},_{I}_{i[I]}(n_{i} _{i}^{2}-_{B})^{2}=_{B}^{2}\,,\]

_all exist, for some constants \(_{A},_{B},_{A},_{B}>0\). Let \(K(\{0,,I\})\), \(_{K}([2^{}_{K}])\). Then, almost surely, \(_{K})}{q()}([ 0,1])\)._

### Discrete Uniform Shapley value

The Shapley value re-arrangement in (7) exposes the main tool behind our approximation: it is enough to approximate the distribution of the random variable \(_{}\) that takes values on the subsets of \(_{-i}:=_{j\{i\}}_{j}\) (recall that \(u()=u(_{})\)). Theorem 2, taking the example of the second use-case for intuition, indicates that these datasets have uniformly distributed numbers of points in the limit. Generalizing this intuition, we propose to approximate \(_{}\) by taking \(I\) samples of increasing size from the pool \(_{-i}\) by sampling data points uniformly. This leads to the following definition of DU-Shapley for our generic model:

**Definition 3**.: _[DU-Shapley] For any \(i\), the discrete uniform Shapley value (DU-Shapley) of the \(i\)-th player, denoted by \(_{i}\), is given by_

\[_{i}(u):=_{k=0}^{I-1}u(^{(k)} _{i})-u(^{(k)}),\]

_where \(^{(k)}\) is a set of data points uniformly sampled without replacement from \(_{-i}\) of size \(k_{-i}\), with \(_{-i}=|_{-i}|\)._

Compared to the Shapley value defined in (5), which involves \(2^{I}\) terms to compute, note that DU-Shapley only involves \(I\) terms and hence it presents an exponential reduction of the number of utility function evaluations. Of course, these computational savings come at the cost of some bias. The latter is precisely quantified in Section 3.3 for our first two use-cases.

By definition, DU-Shapley is a random variable which depends on the sampled data points. However, whenever \(u()=w(q())\), with \(q()\) some scalar quantify of interest, as in our use-cases, we

Figure 1: Distribution of \(q()/q()\) when \(\) is sampled as in (8) (i.e., first sample a size \(K\) uniformly, then sample a coalition \(\) of size \(K\) uniformly). (left) \(I=10\), (middle) \(I=50\), (right) \(I=500\). We considered \(10^{4}\) samples for each random variable, and the third use-case with \(n_{i}()\) and \(_{i}/_{i}()\) for each \(i\).

can get rid of the stochastic nature of DU-Shapley by considering \(I\) real values from well chosen intervals. In particular, in our uses-cases, DU-Shapley boils down to:

\[_{i}(w)=_{k=0}^{I-1}w(_{i}^{k})-w(_{-i }^{k}),\] (10)

where

\[_{i}^{k}:=n_{i}+_{j \{i\}}_{j}n_{j})^{2}}{_{i}^{2}n_{i}+_{j\{i\}}_{j}^{2}n_{j}}_{-i}^{k}:=\{i\}}_{j}n_{j})^{2}}{_{j \{i\}}_{j}^{2}n_{j}}.\]

We remark the notation abuse as we should write \((w q)\). For simplicity, we omit the composition and only write \((w)\). Equation (10) coincides exactly with Definition 3 in the first two use-cases, i.e., when \(_{j}=\) for all \(j\). Indeed, as the random datasets \(^{(k)}\) have a fixed size and the value function only looks at the number of data points within the coalition, we obtain,

\[_{i}(u) =_{k=0}^{I-1}u(^{(k)}_{i}) -u(^{(k)})=_{k=0}^{I-1}w(|^{(k)} _{i}|)-w(|^{(k)}|)\] \[=_{k=0}^{I-1}w(k_{-i}+n_{i})-w(k_{-i})=_ {i}(w).\]

For the third use-case, Equation (10) is an approximation that comes from assuming that, for any \(j\{i\}\), \(|_{j}^{(k)}|=k}{I-1}\), which holds with high probability for large values of \(I\), since

\[q(^{(k)}_{i})=n_{ i}+_{j\{i\}}_{j}|_{j} ^{(k)}|)^{2}}{_{i}^{2}n_{i}+_{j \{i\}}_{j}^{2}|_{j}^{(k)}|}.\]

Theorem 2 implies the following result.

**Corollary 4**.: _Let \(_{i}\) and \(_{i}\) be, respectively, the Shapley value (5) and the DU-Shapley (10) of player \(i\). Then, in our three uses-cases, it holds, \(_{I}|_{i}-_{i}|=0\) almost surely._

While our theoretical results are based on Equation (10) for the cases where \(u()=w(q())\), we will see through numerical experiments that Definition 3 gives good results in more general cases.

### Non-Asymptotic Theoretical Guarantees

Corollary 4 states asymptotic guarantees for DU-Shapley. In this section, we show non-asymptotic results that give the convergence rate for the first two uses-cases.1 Recall that in non-parametric estimation, the utility writes as \(u()=_{b[B]}u_{b}()(x b)\), and therefore, by the linearity axiom of the Shapley value, for any \(i,_{i}(u)=_{b[B]}_{i}(u_{b})(x  b)\). As a consequence, in order to estimate \(_{i}(u)\), it is enough to compute each \(_{i}(u_{b})\). In particular, the Shapley value approximation error over the whole feature space becomes a simple aggregation of the Shapley value approximation errors over the bins. We focus firstly on bounding the bias of our method in the homogeneous use-case to then extend it to the non-parametric regression case.

As in the homogeneous use-case the utility function writes as \(u()=w(_{i}n_{i})\), we consider the following regularity assumptions on \(w\).

**H1**.: _The function \(w:_{+}\) is increasing, twice continuously differentiable, and such that \(_{n}n^{2}|w^{(2)}(n)|<\) (where \(w^{(2)}\) represents the second derivative)._

Monotonicity is a natural assumption in our framework as, the more data, the more precise the ML prediction is expected to be. The condition over the limit aims at controlling the growth behavior of the utility function and it is automatically satisfied whenever \(w\) is bounded and \(w^{(2)}\) is monotone, by the mean value theorem. Theorem 5 bounds the bias of DU-Shapley for the homogeneous use-case.

**Theorem 5**.: _Under Assumption **H1**, there exists a constant \(>0\), such that, for any \(i\), it holds,_

\[_{i}-_{i}^{2}}( _{-i}^{2}(1+(I-1))+_{-i}),\]_where \(_{i}\) and \(_{i}\) are respectively the Shapley value and the DU-Shapley of player \(i\), \(_{-i}=|_{-i}|\) is the average dataset size of all players but \(i\), \(^{2}_{-i}=_{j\{i\}}(n_{j}-_{- i})^{2}\) their empirical variance, and \(_{-i}\) measures the variability of the dataset sizes across players. Formally, it is defined as \(_{-i}:=R_{-i}^{2}_{-i}^{2}/4n_{-i}^{}\) where \(R_{-i}:=_{j\{i\}}|n_{j}-_{-i}|\), \(n_{-i}^{}:=_{j\{i\}}n_{j}\), and \(_{-i}:=n_{-i}^{}/_{j\{i\}}n_{j}\)._

The full proof of Theorem 5 is included in Appendix C.3 and it relies on controlling the absolute value of \([w(_{-i}K)-w(_{j}n_{j})]\), where \(K(\{0,...,I-1\})\) and \(\) is the random variable in (7). Using a second order Taylor expansion, the problem is reduced to controlling the term related to the second derivative of \(w\) by using the regularity assumptions in **H**1.

As advertised before, Theorem 5 can be directly generalized to the non-parametric use-case, since,

\[u()=_{b[B]}w_{b}_{i }n_{i,b}(x b),\ \ \ n_{i,b}=|\{(x,y)_{j},x b\}|.\]

**Corollary 6**.: _Under Assumption **H**1 for all functions \(w_{b}\), there exist constants \(_{b}>0\), such that, for any \(i\), it holds that_

\[_{i}-_{i}_{b[B]}(x b)}{(I-1)_{-i,b}^{2}}(_{-i,b}^{2}(1+(I-1))+2 _{-i,b}),\] (11)

_where \(_{i}\) and \(_{i}\) are respectively the Shapley value and the DU-Shapley of player \(i\), and all terms are equivalently defined to Theorem 5 at each bin \(b[B]\)._

The upper bound in (11) depends on natural quantities related to the dataset valuation problem described in Section 2.1 at each bin, such as the first two moments \(_{-i,b}\) and \(_{-i,b}\) of the datasets' size distribution. More precisely, the error increases when there are some outlier players with a very small or large dataset size. This behavior is expected since, in this particular setting, the random variable inside of the Shapley value differs from a uniform random variable. As showcased in Theorem 2, the error vanishes when the number of players \(I\) tends towards infinity.

## 4 Numerical Experiments

We illustrate the benefits of DU-Shapley by measuring numerically three properties: (1) how well DU-Shapley approximates the Shapley value in real data, (2) how many (theoretical) iterations need other methods to achieve the same accuracy level than DU-Shapley, and (3) how well DU-Shapley performs in classical dataset valuation tasks with real data. Appendix A.1 complements the results by a complexity comparison between our method and SVARM and Appendix A.2 by experiments on synthetic data. The experiments strongly suggest that DU-Shapley performs well in all tasks.

### Approximating the Shapley Value in Real-World Data

We consider the real-world datasets in Mitchell et al. , whose details are provided in Table 3 in the appendix. To tackle these problems we consider logistic regression models and gradient-boosted decision trees (GBDT). For classification tasks, the utility function has been taken as the expected accuracy of the trained logistic regression model over a hold-out testing set while for regression tasks, the utility function corresponds to the averaged MSE over a hold-out testing set. In both cases we took a hold-out testing set with 10% of the size of the training dataset. For each dataset, we considered two worst-case scenarios for our method, namely \(I=10\) players and \(I=20\) players.

Starting from the datasets in Table 3, we heterogeneously allocate datasets to the players. We compare ourselves with two approaches, referred to as MC-Shapley, for the standard MC approximation defined in (6), and MC-anti-Shapley that considers, in addition, antithetic sampling . We compute the averaged MSE across all players between the true Shapley value and each estimator.

Since computing the marginal contributions in this experiment requires re-training, which is clearly not feasible for a large number of epochs, we chose to restrict ourselves to 20 steps of stochastic gradient descent for logistic regression and 20 boosting iterations for GBDTs. For MC-based approaches, we considered \(I\) samples to compare those approximations with the proposed methodology on a fair basis, i.e., associated to the same computational budget.

Table 1 depicts the results. We clearly see that, even in the worst-case scenario where the number of players is small and far from the theoretical assumptions from Section 3.3, DU-Shapley competes favorably with the MC-based methods.

### Complexity of Computing the Shapley Values of all Players

We have looked at the number of iterations that DataShapley and the _Improved Group Testing-Based_ method  (IGTB) require to achieve DU-Shapley's accumulated bias, formally given by

\[(I):=_{i}^{2}(1+(I-1))+_{-i}}{(_{-i})^{4}} ^{1/2}.\]

To do so, we have replaced \(=(I)\), respectively, in the formula in Section 4.1 in  and Equation 5 in , with a value function motivated from our third use-case under the homogeneity assumption \(_{i}/_{i}=/\) for all \(i\). The results are illustrated in Figure 2. Remark DU-Shapley requires \(I^{2}\) iterations to compute all Shapley values. We observe that in all tested instances, both methods require a higher number of iterations to achieve the same error than DU-Shapley.

### Applying DU-Shapley to dataset valuation problems

We considered non-tabular datasets used in , namely bbc-embedding, IMDB-embedding, both text datasets, and CIFAR10-embedding, an image dataset. Feature embedding have been generated

   Dataset &  &  &  &  \\  Players & 10 & 20 & 10 & 20 & 10 & 20 & 10 & 20 \\  DU-Shapley & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) \\ MC-Shapley & \(1.10^{-2}\) & \(4.10^{-3}\) & \(3.10^{-2}\) & \(1.10^{-3}\) & \(9.10^{-2}\) & \(6.10^{-2}\) & \(5.10^{-2}\) & \(2.10^{-2}\) \\ MC-anti-Shapley & \(8.10^{-3}\) & \(2.10^{-3}\) & \(1.10^{-2}\) & \(8.10^{-4}\) & \(8.10^{-2}\) & \(4.10^{-2}\) & \(3.10^{-2}\) & \(1.10^{-2}\) \\    &  &  \\  Players & 10 & 20 & 10 & 20 & \\  DU-Shapley & \(}\) & \(}\) & \(}\) & \(}\) \\ MC-Shapley & \(4.10^{-1}\) & \(3.10^{-1}\) & \(5.10^{-3}\) & \(1.10^{-3}\) \\ MC-anti-Shapley & \(4.10^{-1}\) & \(2.10^{-1}\) & \(5.10^{-3}\) & \(1.10^{-3}\) \\   

Table 1: Worst-case comparison between DU-Shapley and competitors, for real-world datasets considered in Table 3. We report the averaged MSE across all players w.r.t. the exact Shapley value.

Figure 2: Iterations required by DataShapley and the Improved Group Testing-Based method to achieve DU-Shapley’s accumulated bias with function \(w(n_{S})=1-)}}{10^{k()}+n_{S}}\), where \(n_{S}\) is the number of data points of the coalition \(S\), and \(k():=(_{i}n_{i})-1\) is a normalization factor. (top) \(=0.01\), (bottom) \(=0.1\), (left) \(n_{}=10\), (middle) \(n_{}=50\), (right) \(n_{}=100\).

using pretrained DistilBERT and ResNet50 models, respectively. In addition we have adapted three baselines from data valuation to our setting: Leave-One-Out (LOO), DataShapley, and KNN-Shapley. Appendix B.2 gives the implementations details. For these datasets associated to classification problems, we used a multi-layer perceptron classifier as prediction model.

We have considered three dataset valuation problems, none of them needing the real Shapley values, which allows us to increase the number of players w.r.t. the experiments in Section 4.1. We investigated noisy label detection (NLD), dataset removal (DR), and dataset addition (DA) . For NLD, we used as a metric the F1-score (the larger the better). For DR, we used the testing accuracy (the lesser the better). For DA, we used the testing accuracy (the lesser the better).

We considered splitting the dataset across \(I=100\) players. The results are summarized in Table 2. We observe that DU-Shapley has competitive results compared to classical baselines despite of the fact that none of the considered cases verifies the structural assumptions from Section 3.3. In addition, we can see that DU-Shapley tends to have similar and even better results as DataShapley (which is a MC based method). This is in line with our theory as, for larger number of players, DU-Shapley tends to better estimate the true Shapley value.

## 5 Conclusion

We model the dataset valuation problem as a cooperative game and design a Shapley value approximation, named DU-Shapley, that exploits the underlying structure of the utility function and exponentially reduces the number of functions valuations required for the computation. In three different uses-cases, DU-Shapley is proved to almost surely converge to the real Shapley value as the number of players grows. Moreover, we find the rate of convergence, which depends only on natural parameters of dataset valuation. Numerical experiments showcase that DU-Shapley performs well in approximating the Shapley value and performing dataset valuation tasks, even when the assumptions needed for the theoretical guarantees do not hold, and it has a good complexity when computing the Shapley values of all players.

**Limitations of our method**. Our non-asymptotic bound for the non-parametric regression setting in Corollary 6 indicates that DU-Shapley works better when agents' datasets are _regular_ in the sense that they have similar sizes. Hence, a limitation of our approximation is that it may work poorly in settings where some players have large datasets compared to others, as the distribution of the random variable within the Shapley value drives apart from being uniform. Moreover, our convergence result in Theorem 2 (for all use-cases) assume the existence of limits, which roughly requires that heterogeneity between players--in terms of both dataset size and variance--can be bounded. This also indicates that convergence may be not be guaranteed if the heterogeneity is arbitrarily high.

   Dataset &  &  \\   &  &  &  &  &  &  \\  & 5\% & 15\% & 5\% & 15\% & 5\% & 15\% & 5\% & 15\% & 5\% & 15\% & 5\% & 15\% \\  Random & 0.11 & 0.19 & 0.61 & 0.60 & 0.25 & 0.41 & 0.11 & 0.19 & 0.90 & 0.88 & 0.68 & 0.81 \\ LOO & 0.13 & 0.18 & 0.62 & 0.60 & 0.15 & 0.32 & 0.11 & 0.17 & 0.90 & 0.88 & 0.61 & 0.77 \\ DataShapley & 0.13 & 0.25 & 0.61 & 0.59 & 0.12 & 0.18 & 0.12 & 0.20 & 0.89 & 0.87 & 0.08 & 0.12 \\ KNN-Shapley & **0.14** & 0.28 & **0.60** & 0.57 & 0.12 & 0.15 & **0.19** & 0.29 & **0.88** & 0.86 & 0.13 & 0.12 \\ DU-Shapley & **0.14** & **0.30** & 0.61 & **0.55** & **0.11** & **0.14** & 0.18 & **0.34** & 0.89 & **0.85** & **0.07** & **0.11** \\    &  \\   &  &  &  \\  & 5\% & 15\% & 5\% & 15\% & 5\% & 5\% & 15\% \\  Random & 0.10 & 0.16 & 0.77 & 0.75 & 0.62 & 0.68 \\ LOO & 0.11 & 0.18 & 0.77 & 0.74 & 0.53 & 0.59 \\ DataShapley & 0.17 & 0.28 & **0.75** & 0.69 & 0.36 & **0.33** \\ KNN-Shapley & **0.18** & 0.29 & 0.76 & 0.68 & 0.41 & 0.37 \\ DU-Shapley & **0.18** & **0.32** & 0.76 & **0.66** & **0.33** & 0.34 \\   

Table 2: Comparison between DU-Shapley and competitors for real-world datasets considered in  in Noisy label detection, Dataset Removal and Dataset Addition.