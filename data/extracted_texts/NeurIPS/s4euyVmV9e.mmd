# GLEAM-AI: Neural Surrogate for Accelerated Epidemic Analytics and Forecasting

Mohammadmehdi (Mehdi) Zahedi

Network Science Institute

Northeastern University

Boston, MA 02115, The Roux Institute

Northeastern University

Portland, ME 04101,

zahedi.m@northeastern.edu

&Dongxia Wu

University of California, San Diego

La Jolla, CA 92093

dowu@ucsd.edu

Jessica T. Davis

Network Science Institute

Northeastern University

Boston, MA 02115,

jes.davis@northeastern.edu

&Yi-An Ma

University of California, San Diego

La Jolla, CA 92093

yianma@ucsd.edu

&Alessandro Vespignani

Network Science Institute

Northeastern University

Boston, MA 02115

A.Vespignani@northeastern.edu

&Rose Yu

University of California, San Diego

La Jolla, CA 92093

roseyu@ucsd.edu

Matteo Chinazzi

Network Science Institute

Northeastern University

Boston, MA 02115,

The Roux Institute

Northeastern University

Portland, ME 04101

m.chinazzi@northeastern.edu

###### Abstract

Large-scale stochastic mechanistic models are more and more used in recent years to model global epidemic outbreaks and are useful tool for policy and decision makers to project, forecast, and asses the impact of epidemics. However, these models are incredibly demanding from a computational standpoint and time-consuming to run. Here, we present GLEAM-AI, a spatio-temporal probabilistic neural surrogate model to replicate the insights and results of large-scale mechanistic epidemic models and to accelerate stochastic simulations. We show how a surrogate model can efficiently be trained with less than \(5.3\) thousand simulations from the mechanistic model by utilizing a Bayesian active learning approach. We demonstrate its performance in efficiently replicating the mechanistic dynamics, providing approximately a \(200\) times speed-up with respect to the original model.

Workshop on Bayesian Decision-making and Uncertainty, 38th Conference on Neural Information Processing Systems (NeurIPS 2024).

Introduction

Large-scale, stochastic, age-structured, meta-population epidemic models are computationally expensive to run, especially when a lot of uncertainty exists on the characteristics of the outbreak under investigation and a large portion of the model's parameter space has to be explored to provide accurate forecasts or scenario analysis projections. In this context, utilizing a deep surrogate model in lieu of a mechanistic model can help accelerate stochastic simulations and reduce the computational cost and time needed to model complex disease dynamics, calibrate large-scale models, or simply provide timely insights on the evolution of an epidemic [1; 2; 3; 4]. In this work, we extend a stochastic neural surrogate modeling approach based on spatio-temporal neural processes (STNP)  to reproduce the dynamics of the Global Epidemic and Mobility model (GLEAM) [5; 6; 7; 8], a data-driven, stochastic, spatial, age-structured, multi-strain, meta-population epidemic model that incorporates high resolution population density data, mobility data, and disease dynamics into a unified framework. In particular, we focus our experiments on replicating the dynamics of a model tailored to reproduce the evolution of seasonal flu outbreaks in the United States. Our preliminary results show that GLEAM-AI can be efficiently trained to reproduce GLEAM model's dynamics using only about 5.3 thousands simulations.

## 2 Method

Disease dynamics are modeled using a traditional compartmental modeling framework. In particular, in GLEAM, seasonal flu disease dynamics are simulated using a compartmental model that divides the population into: susceptible, latent, infectious, hospitalized, and recovered, where the infectious population is further subdivided into asymptomatic, infectious traveling (e.g. mild cases of the disease), and symptomatic non-traveling (e.g. severe cases). Lastly, all individuals can be either vaccinated or unvaccinated. The details of the compartmental model used are reported in Fig.3, Appendix B. The surrogate model, GLEAM-AI, aims at reproducing the dynamics of two of these compartments, latent and hospitalized. I.e., number of infected individuals and number of hospitalized individuals over time, respectively. Details about the compartmental model and GLEAM are presented in Appendix A.

The proposed surrogate model is based on spatio-temporal neural process (STNP) , a generalization of neural process [9; 10; 11; 12]. GLEAM-AI comprises of an encoder-decoder architecture, as illustrated in Fig.1. The input to both the encoder and decoder is a mobility graph of the United States where each node represents a state and weighted edges describe long-range traveling patterns across the country. State level node features comprise: basic reproduction number, initial disease prevalence, residual immunity, population, the starting date of the outbreak, expressed as the number of days from January 1st of the corresponding year, and a seasonality forcing factor. The basic reproduction number \(R_{0}\) measures how many new cases one infected person is expected to cause in a fully susceptible population. Initial prevalence indicates the initial size of the population in that compartment that has those attributes; for instance, latent prevalence are the number of individuals that are in latent compartment at the start of the simulation. Residual immunity represents the remaining protection against the disease after previous exposure or vaccination. The encoder processes the input graph using a Diffusion Convolutional Recurrent Neural Network (DCRNN) . The resulting graph embeddings are concatenated with the latent prevalence time series and its lagged version, following the approach in neural processes , and then fed into a GRU to generate the time-dependent latent variable. The latent prevalence time series in the encoder is normalized using z-score normalization. The decoder uses the temporal graph embedding from DCRNN and latent variable from encoder to generate the samples. The DCRNN, used in both the encoder and decoder, has an input channel of 51 and an output dimension of 256. The latent variable has a dimension of 100. The compartmental decoders are separate structures, each consisting of GRU layers followed by fully connected layers, designed to learn the parameters for each compartment. Fig. 0(c) shows the compartmental decoder parameterized by a negative binomial distribution. In our experiment, we used a single-layer GRU for each compartmental decoder. The decoder's output has as many heads as there are compartments being generated. For flu, for example, we generate latent incidence, latent prevalence, hospitalized incidence, and hospitalized prevalence, meaning the decoder has four heads.

GLEAM-AI extends STNP  original framework along several dimensions. First, we redesigned the encoder to improve efficiency by using only the latent prevalence time series, i.e. the number of currently infected individuals at a given time \(t\), to learn the latent embedding space, as that is sufficient, conditional on knowing the initial condition of the model, to learn the disease dynamics encoded in GLEAM. Second, the decoder has been redesigned to map the output to generate all the compartments of interest, such as latent prevalence, latent incidence (i.e. new daily infections), hospitalized prevalence, and hospitalized incidence (i.e. new daily hospital admissions). Third, we designed the decoder to learn the initial states \(h_{0}\) of the gated recurrent units (GRUs). In GLEAM, only initial values for prevalence are known at the onset of the simulation, i.e. number of people currently members of each specific compartment, while initial values for incidence compartments are not known a priori. By learning initial states of GRU we give the model enough flexibility to capture dynamic of compartments not used by the encoder. Fourth, we explicitly provide as a time-varying node parameters, a temporal embedding describing the physics of the seasonal forcing dynamics that modulate disease transmission during the year by rescaling the effective reproductive number, \(R(t)\). Here, we adopted the same functional form for the seasonality forcing factor as used in GLEAM (see Eq. 1). Lastly, we experimented with different parametric distributions to parameterize the decoder, including the Gaussian distribution and the negative binomial distribution. Since the time series of each output compartment consists of count data, the negative binomial distribution is a natural choice as it can capture both the mean and dispersion simultaneously. So instead of point estimates, the decoder outputs distribution \(p(_{t}|_{\{t-1\}:1},z_{(t-1):1})\), where \(_{t}\) is any parameter of the distribution conditioned on their past values and the latent variables.

We employ Bayesian active learning [15; 16; 17; 1] to train GLEAM-AI in a sample-efficient way. Define \(S^{(i)}\) as train dataset at iteration \(i\). First, we generate 120 random simulations based on random inputs to serve as the initial training dataset \(S^{(1)}\), followed by alternating between acquiring new samples and training the model for 120 epochs. At every training phase, we use early stopping based on train loss to terminate the training. To select the input parameters for generating additional simulations, we predict \(_{1:T}\) on a predefined range of input parameters and using the acquisition function \(r(.)\) to compute the expected score \(E_{p(x_{1:T}|z_{1:T},)}[r(_{1:T}|z_{1:T},)]\) for each input. Based on these scores, we query the simulator \(F(^{(i+1)};)\), where \(\) represents the internal states of the simulator, to generate new samples. For the acquisition function, we used the maximum mean standard deviation  and query 60 samples from simulator at each acquisition phase. The loss function used in the model, derived from variational inference principles , is composed of the reconstruction loss and KL divergence, with the negative binomial likelihood used as the reconstruction loss. The algorithm is shown in Appendix C.

## 3 Experiments

Here, we present some preliminary results validating the model by comparing the distributions generated by GLEAM and GLEAM-AI. In Fig. 2, we compare the ensembles of more than 13,000

Figure 1: GLEAM-AI architecture. (a) encoder, (b) decoder, (c) compartmental decoder. The input to both the encoder and decoder is a mobility graph of the United States where each node represents a state and weighted edges describe long-range traveling patterns across the country. State-level node features comprise: basic reproduction number, initial disease prevalence, residual immunity, population, the starting date of the outbreak, and a seasonality forcing factor.

stochastic realizations for different ranges of parameters for a sample of representative states. Despite some discrepancies in distribution for some parameter ranges, the speed gains in generating samples outweighs the drawbacks. Generating a synthetic epidemic outbreak from GLEAM-AI is approximately 200 times faster than generating the same simulation in GLEAM. As a reference, running 100 replicates of the compartmental model used here takes approximately 3 hours using GLEAM and less than a minute using GLEAM-AI. This increased efficiency in generating data samples constitutes an advantage during real-world applications that typically involve running a large number (e.g. hundreds of thousands) of computationally expensive simulations to then select those that best match observational data. Indeed, thanks to the speed of execution of GLEAM-AI, we can use Approximate Bayesian Computation coupled with Sequential Monte Carlo (ABC-SMC) to efficiently calibrate the surrogate model to observed surveillance data, rather than a simpler ABC approach, and therefore estimate the posterior distribution of the inputs parameters.

## 4 Conclusion

In this work, we introduced GLEAM-AI, a spatio-temporal neural surrogate model designed to accelerate simulation of large-scale epidemic models. Our approach utilizes a probabilistic framework that integrates spatio-temporal neural process and Bayesian active learning to reduce the computation cost and number of queries from a mechanistic model. Our results demonstrate that GLEAM-AI is a viable model for real-time forecasting and pandemic response.

Figure 2: GLEAM vs GLEAM-AI: ensembles of the number of new daily flu hospital admissions (\(y\)-axis) over time for Alaska (AK), Florida (FA), Georgia (GA), Massachusetts (MA), North Carolina (NC), South Carolina (SC), Virginia (VA), Wyoming (WY) and United States (US). The solid lines are median, dark shades are \(50\%\) and light shades are \(95\%\) CI, respectively. The value of \(R_{0}\) for the first column is \([1.75,2.0]\), second column is \([2.25,2.5]\), third column \([2.75,3.0]\). The ranges for the other parameters are kept fixed across experiments and they are: seasonality forcing in \([0.8,0.85]\), initial disease prevalence is \(140/1000000\), starting dates of the outbreak in [2022-09-28, 2022-10-02], and residual immunity between 25%-30%. KS-test color-coded p-values comparing GLEAM and GLEAM-AI added at the bottom of each subfigure.