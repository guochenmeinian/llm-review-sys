# Virtual Scanning: Unsupervised Non-line-of-sight Imaging from Irregularly Undersampled Transients

Xingyu Cui\({}^{1}\) Huanjing Yue\({}^{1}\) Song Li\({}^{2,3}\) Xiangjun Yin\({}^{1}\)

**Yusen Hou\({}^{1}\) Yun Meng\({}^{2,3}\) Kai Zou\({}^{2,3}\) Xiaolong Hu\({}^{2,3}\) Jingyu Yang\({}^{1,}\)\({}^{*}\)**

\({}^{1}\)School of Electrical and Information Engineering, Tianjin University, China

\({}^{2}\)School of Precision Instrument and Optoelectronic Engineering, Tianjin University, China

\({}^{3}\)Key Lab. of Optoelectronic Information Science and Technology, Ministry of Education, China

Corresponding author: yjy@tju.edu.cn.

###### Abstract

Non-line-of-sight (NLOS) imaging allows for seeing hidden scenes around corners through active sensing. Most previous algorithms for NLOS reconstruction require dense transients acquired through regular scans over a large relay surface, which limits their applicability in realistic scenarios with irregular relay surfaces. In this paper, we propose an unsupervised learning-based framework for NLOS imaging from irregularly undersampled transients (IUT). Our method learns implicit priors from noisy irregularly undersampled transients without requiring paired data, which is difficult and expensive to acquire and align. To overcome the ambiguity of the measurement consistency constraint in inferring the albedo volume, we design a virtual scanning process that enables the network to learn within both range space and null space for high-quality reconstruction. We devise a physics-guided SURE-based denoiser to enhance robustness to ubiquitous noise in low-photon imaging conditions. Extensive experiments on both simulated and real-world data validate the performance and generalization of our method. Compared with the state-of-the-art (SOTA) method, our method achieves higher fidelity, greater robustness, and remarkably faster inference times by orders of magnitude. The code and model are available at https://github.com/XingyuCuii/Virtual-Scanning-NLOS.

## 1 Introduction

Non-line-of-sight (NLOS) imaging aims to reconstruct hidden scenes beyond the direct line of sight of the detector, garnering interest across various fields such as robot vision, autonomous driving, rescue operations, remote sensing, and medical imaging . In a typical active confocal NLOS imaging system, as depicted in Fig. 1, a laser source and a detector are both focused on the same point on a relay surface. Pulses emitted by the laser reflect off the surface to illuminate the hidden scene. The detector captures photons bouncing back from the scene toward the relay surface, referred to as transients, from which the hidden scene can be recovered using elaborately designed algorithms.

While existing works have achieved remarkable breakthroughs, they also face significant limitations that hinder their practical applicability. These methods assume dense and regular scanning of a large relay surface, which may not be feasible in realistic scenarios with irregular relay surfaces such as latticed windows or fences. Transients obtained through irregular undersampling can result in severe ill-posedness, leading to artifacts or reconstruction failure. This raises the challenging task of _NLOS imaging from irregularly undersampled transients (IUT)_. To address this, Liu et al.  proposed introducing manually designed strong regularization terms under a functional optimization framework. However, this approach is hindered by the need for lengthy numerical iterative computations. Recentlearning-based NLOS imaging methods [7; 8; 9; 10] enable quick inference, but they require supervision from a large amount of paired data, including well-aligned ground-truth albedos, which are difficult and expensive to acquire. Therefore, exploring NLOS imaging under unsupervised learning is worthwhile to eliminate the heavy reliance on paired data.

In this paper, we propose a novel unsupervised framework capable of learning implicit priors from noisy IUT. This framework comprises two components: a virtual scanning reconstruction network (VSRnet) that learns high-quality measurement-to-albedo mapping beyond the range space induced by the measurement consistency, and a SURE-based denoiser that enhances our method's robustness to measurement noise by incorporating the physics model of the low-photon time-resolved detector. We conduct extensive experiments on simulated data, publicly available real data, and data acquired from our self-built NLOS system. Our method outperforms existing algorithms, particularly in providing robustness for real data and diverse irregular relay surfaces.

Our main contributions are summarized as follows:

\(\) We propose an unsupervised NLOS imaging framework capable of learning implicit priors from noisy IUT, effectively overcoming the dependency on paired data that is difficult to acquire and align.

\(\) We introduce a virtual scanning process that enables the network to learn within both range and null spaces for high-quality reconstruction from IUT, extending NLOS imaging to realistic scenarios with irregular relay surfaces.

\(\) We propose a SURE-based denoiser, an unsupervised physics-guided module that incorporates the low-photon time-resolved detector's physics model, to enhance our method's robustness to noise.

\(\) We evaluate our method on simulated, publicly available, and self-captured real data, demonstrating its superior reconstruction quality and significantly faster inference compared to the SOTA method.

## 2 Related work

### Model-based NLOS reconstruction

Model-based NLOS algorithms have achieved significant advances in recent years. Direct reconstruction algorithms [11; 12; 13; 14; 15] offer rapid implementations for NLOS imaging, while iterative algorithms [16; 17; 18; 5] leverage more accurate physical models for higher reconstruction quality. Recent efforts aim to extend NLOS imaging to challenging real-world scenarios. For instance, Manna et al.  and Gu et al.  addressed NLOS imaging with dynamic and non-planar relay surfaces, respectively. However, these methods still rely on large relay surfaces and dense measurements. Another set of algorithms [21; 22; 23; 24; 25] aims to achieve high spatial resolution reconstruction using sparse sampling measurements to significantly reduce acquisition time. Yet, they are constrained to specific scanning patterns, such as regular or Hadamard patterns. To address NLOS imaging from irregularly undersampled transients, Liu et al.  introduced a reconstruction model using Confocal Complemented Signal-Object Collaborative Regularization (CC-SOCR). Despite its effectiveness, CC-SOCR suffers from long inference times due to its iterative nature.

Figure 1: Illustration of the active confocal NLOS imaging with an irregular relay surface. Yellow points indicate scannable points, while blue points indicate non-scannable points.

### Learning-based NLOS reconstruction

Recently, deep learning has gained attention for NLOS imaging due to its learning capabilities and fast inference. Chopite et al.  first employed deep learning for NLOS reconstruction, but their method fell short compared to model-based approaches due to the lack of physical guidance. Physics-guided methods [8; 26; 9; 10] have since emerged to enhance reconstruction quality, particularly for real-world data. Recent works focus on NLOS imaging from regularly undersampled transients [27; 28], but they require large datasets of paired data and fail to reconstruct from IUT. Furthermore, these supervised algorithms still have significant room for improvement in robustness on real data due to the gap between simulated datasets used for training and real-world data.

## 3 Problem formulation and motivation

### NLOS Imaging from IUT

Fig. 1 illustrates confocal NLOS imaging with time-resolved systems. By scanning a set of points \(P=\{(x_{i},y_{i},0) i=1,2,,s,\ x_{i},y_{i}\}\) on the relay surface, the forward model of NLOS imaging can be modeled as

\[(p,t)=_{Q}}(2\|p-q\|-tc)dq\] (1)

where \(\) is the spatial-temporal measurement, \(p=(x,y,0)\) denotes the scanning point, \((q)\) denotes the albedo value at point \(q\) in the 3D hidden scene \(Q\), \(c\) is the speed of light. The distance \(\|p-q\|\) is related to the time of flight \(t\) through the Dirac delta function \(()\). For compact presentation and analysis, we employed a discretized version of the above forward model. Let \(u^{st}\) and \(^{l^{2}z}\) represent the vectorized measurements and albedos of the hidden object, respectively, where \(l\) denotes the size of the vertical and horizontal dimensions, and \(z\) denotes the depth dimension. We denote the forward operator, also known as the light transport matrix, by \(H^{st l^{2}z}\). The forward processing can be described by the following linear model:

\[u=H.\] (2)

Notably, the forward operator \(H\) is related not only to the optical-electronic characteristics of the NLOS system but also to the scannable region on the relay surface.

### Motivation

Deep learning-based algorithms have demonstrated significant potential to enhance NLOS imaging performance compared to model-based approaches. Most prior work has adopted a supervised paradigm, which requires substantial amounts of high-quality paired data. However, it is prohibitively expensive or even infeasible to acquire ground-truth 3D albedo volumes precisely aligned with the spatio-temporal measurements. This limitation motivates us to develop an unsupervised NLOS reconstruction framework that avoids this dependency and further enhances the generalization of learning-based methods to real-world data.

The standard approach in unsupervised learning is to train the reconstruction mapping \(f_{}\) by minimizing the measurement consistency (MC) loss:

\[_{u}\|Hf_{}(u)-u\|_{2}^{2}.\] (3)

Nevertheless, solely enforcing the MC loss without ground truth supervision does not guarantee high-quality reconstruction. This can be analyzed from the perspective of the range-null decomposition . Let \(_{H}=\{v^{l^{2}z} Hv=0\}\) be the null space of the operator \(H\). Its complementary space is the range space of \(H^{}\), denoted by \(_{H}=\{H^{}u,u^{st}\}\), such that \(^{l^{2}z}=_{H}_{H}\).

Any albedo volume \(\) can be decomposed into a range-space component and a null-space component.

\[=H}_{}+H)}_{}\] (4)where \(H^{}^{l^{2}z st}\) is the pseudo-inverse of \(H\) satisfying \(HH^{}H=H\). The operator \(H^{}H\) projects the sample \(\) into the range space \(_{H}\): \(_{r}()=H^{}H\), whereas its complementary operator \((I-H^{}H)\) projects \(\) into the null-space \(_{H}\): \(_{n}()=(I-H^{}H)\). As long as the trained network \(f_{}\) reconstructs from input \(u\) as \(f_{}(u)=_{r}()+v_{n}\) for \(\;\;v_{n}_{H}\), the reconstructed volume \(f_{}(u)\) would fully meet the MC requirement: \(H(_{r}()+v_{n})=HH^{}H+Hv_{n}=u\) since we have \(HH^{}H=u\) and \(Hv_{n}=0\). This suggests that the MC constraint only locates the albedo volume in a broad subspace surrounding the range-space projection \(_{r}()\), and the inference of the component \(_{H}\) is ad-hoc without guidance.

This necessitates an unsupervised framework capable of learning beyond the range space. We note that model-based algorithms [18; 6; 25; 23] manually design regularization terms to learn beyond range space, but suffer from long inference times. In other computational imaging tasks, supervised methods [30; 31; 29; 32] and unsupervised methods [33; 34; 35; 36; 37] have been proposed to recover null-space components of the reconstructions. Along this avenue, we propose an effective unsupervised framework capable of learning in both range-null spaces for NLOS imaging from IUT.

## 4 Method

### Unsupervised framework

Fig. 2 shows the proposed unsupervised framework via virtual scanning for NLOS imaging from IUT. The framework consists of two components: 1) a virtual scanning reconstruction network (VSRnet) to recover the 3D albedo volume from both range and null space, and 2) a SURE-based denoiser to enhance the robustness to ubiquitous noise in transients. Given a set of \(G\) noisy irregularly undersampled transients \(=\{_{g}^{st}|\;g=1,,G\}\) and the set of their corresponding forward operators \(=\{H_{g}^{st l^{2}z}|\;g=1,,G\}\), our goal is to train a deep neural mapping without labeled supervision to reconstruct the 3D albedo volume \(\) from the noisy IUT \(\). As discussed in

Figure 2: The pipeline of our unsupervised framework: (a) The SURE-based denoiser, which consists of an encoder-decoder network designed for IUT and is trained by minimizing SURE loss in the first stage; (b) The virtual scanning reconstruction network (VSRnet), which consists of a Unet-like network and is trained by MC loss and VS loss in the second stage; (c) Relay surfaces used for training (yellow indicates scanning areas, and their corresponding 3D binary masks are used in implementation); (d) The virtual scanning process, which involves virtually observing \(^{(1)}\) with a relay surface \(M_{k}\) that is distinct from \(M_{g}\) and enforcing consistency between \(^{(1)}\) and \(^{(2)}\).

Sec. 3.1, due to the one-to-one correspondence between the forward operator and the relay surface, we will loosely use \(H_{g}\) to refer to different relay surfaces without ambiguity in the following sections.

We first briefly sketch the workflow of the inference stage, as shown in Fig. 2(a) and 2(b). The noisy IUT \(_{g}\), observed through an irregular relay surface \(H_{g}\), is first zero-padded to \(_{gr}\) on a full scanning grid. This is then passed through the SURE-based denoiser \(F_{}\) to remove noise. Subsequently, the albedo volume \(\) is reconstructed using VSRnet \(f_{}\), which incorporates the physical prior of NLOS imaging (LCT ) and a learned reconstruction mapping \(F_{}\). During the training stage, the denoiser is regularized by the SURE loss, while the reconstruction network is regularized by the MC loss. Additionally, we introduce the virtual scanning process (Fig. 2(d)) to capture the measurement details within the null space of observation operators. In this process, the reconstructed \(^{(1)}\) is projected into the measurement space as \(u_{kr}\) by virtually scanning with a different relay surface \(H_{k}\), which is distinct from \(H_{g}\). The virtual scanned measurement \(u_{kr}\) is then projected back into the reconstruction space as \(^{(2)}\) by the reconstruction network. We impose a virtual scanning (VS) loss between the two reconstructed volumes, \(^{(1)}\) and \(^{(2)}\), to promote null-space learning (Sec. 4.2). The modules of our framework and the loss functions utilized for training are detailed in the following subsections. The structures of \(F_{}\) and \(F_{}\) are detailed in the Supplementary Material (SM).

### Virtual Scanning

StrategyThe training strategy of VSRnet is depicted in Fig. 2(b) and 2(d). Specifically, at the reconstruction module (Fig. 2(b)), the denoised sample \(_{gr}\) is initially transformed to the albedo domain using the inverse operator of LCT \(H_{r}^{}\). The resulting \(H_{r}^{}_{gr}\) is then mapped to the albedo volume \(^{(1)}\) by the reconstruction network \(F_{}\) with a global residual connection. At the virtual scanning module, the reconstructed albedo volume \(^{(1)}\) is projected into a virtual undersampled measurement \(u_{kr}\) using another forward operator \(H_{k}\) (\(H_{k} H_{g}\)). To achieve efficient implementation of forward operators, we decouple \(H_{k}\) into \(M_{k} H_{r}\), which can be efficiently computed using Hadamard product and the fast Fourier transform. In practice, \(M_{k}^{l l z}\) is the 3D binary mask associated with the relay surface, constructed by repeating the 2D sampling pattern \(t\) times along the time dimension. \(H_{r}\) represents the forward operator of LCT. Following the same reconstruction pipeline, an albedo volume, denoted by \(^{(2)}\), is obtained from the virtual measurement \(u_{kr}\). The processes of obtaining \(^{(1)}\) and \(^{(2)}\) can be formalized as:

\[^{(1)}&=f_{}(F_{}((_{g}),M_{g}) M_{g}),\\ ^{(2)}&=f_{}(H_{r}^{(1)} M_{k}). \] (5)

The two reconstructed albedos, \(^{(1)}\) and \(^{(2)}\), should be identical if the learned mapping \(F_{}\) enables perfect reconstruction. This motivates us to impose a proximity constraint between \(^{(1)}\) and \(^{(2)}\) in the albedo domain, named the virtual scanning loss. The virtual scanning process in the training pipeline facilitates the learning of the null-space component, thereby providing a promising prior that complements the range space, as analyzed below.

AnalysisFig. 3 provides a more intuitive understanding of how the proposed virtual scanning facilitates the network in learning the null-space component. Let \(H_{1}\) and \(H_{2}\) be two observation

Figure 3: Toy visualization of NLOS reconstruction from the perspective of range-null space decomposition (RNSD). (a) illustrates the RNSD of \(\) observed by \(H_{1}\). (b) illustrates that \(\) cannot be accurately recovered with only the measurement consistency loss. (c) shows that the proposed virtual scanning promotes the acquisition of null-space components.

operators associated with two different relay surfaces. We observe \(\) using the forward operator \(H_{1}\), obtaining the measurement \(u_{1}\). As illustrated in Fig. 3(a), \(\) is projected into the range-space \(_{H_{1}}\) of \(H_{1}\). When we only impose the MC constraint, the resulting output \(^{(1)}\) will belong to the following set \(_{H_{1}}\):

\[_{H_{1}}=\{v\ |\ H_{1}^{}H_{1}v=_{r}(), _{r}()_{H_{1}}\}.\] (6)

As depicted by the blue dashed line in Fig. 3(b), there exist multiple outputs that satisfy the measurement consistency. If, for instance, we obtain inaccurate estimated results denoted as \(^{(1)}\) through \(^{(1)}=_{r}()+F_{}(_{r}())\), we then utilize \(H_{2}\) to virtually scan \(^{(1)}\) and project it into the range space \(_{H_{2}}\). Subject to the constraint \(^{(1)}=^{(2)}\), \(F_{}(_{r}(^{(1)}))\) converges to \(_{n}(^{(1)})\) due to the relationship \(^{(1)}=_{r}(^{(1)})+_{n}(^{(1)})\). Following this iteration, the network can learn within \(_{H_{1}}\) and \(_{H_{2}}\). The entire process is illustrated in Fig. 3(c). Similarly, by altering the order of operators \(H_{1}\) and \(H_{2}\), \(F_{}\) will also observe within \(_{H_{2}}\) and \(_{H_{1}}\). In practice, a set of operators \(\) is provided to enhance the network's generalization across various operators with different relay surfaces.

### SURE-based denoiser

NLOS imaging inherently operates under photon-limited conditions, and noise in transient measurements can lead to severe background artifacts in the albedo space. This hinders the network's ability to learn implicit priors from noisy IUT, especially in unsupervised learning. Inspired by previous studies [38; 39; 40; 41; 42], we introduce a physics-guided unsupervised denoiser to suppress measurement noise. Specifically, we leverage Stein's Unbiased Risk Estimator (SURE)  to derive an unsupervised learning loss function that considers the physical model of the time-resolved detector in NLOS imaging systems, which can be modeled as

\[ (u+b),\] (7) \[u =H,\]

where \(b\) represents the dark counts of the detector along with the background photons. The parameterized denoiser \(F_{}\) learns to map the noisy measurement \(\) to its clean version \(u\) via minimization of the SURE loss function given in Eq. (8).

### Loss function

Given a measurement set \(\{_{i,g},i=1,2,,I,g=1,2,,G\}\) collected by observing \(I\) hidden scenes, each with \(G\) relay surfaces, the training of our framework involves three loss functions: the SURE loss \(_{}\), the MC loss \(_{}\), and the VS loss \(_{}\). The SURE loss is an unbiased estimation of the mean squared error (MSE) under the Poisson noise model taking dark count consideration:

\[&_{}=_{\{i,g\}} \|_{i,g}-F_{}(_{i,g})\|_{2}^{2}- (+b)^{}_{i,g}\\ &+b^{}F_{}(_{i,g})+(e _{i,g}_{i,g})^{}F_{}(_{i,g}+ e _{i,g})-F_{}(_{i,g})}\] (8)

where \(\) is a positive number, \(e_{i,g}\{-1,1\}^{st}\) is a binary vector, whose elements follow a Bernoulli distribution with equal probability , and \(\) denotes element-wise multiplication. Detailed derivation of the SURE loss is given in supp. material.

We adopted the mean squared error for \(_{}\) and \(_{}\):

\[_{}&=_{\{ i,g\}}\|_{i,g}-H_{g}(f_{}(_{i,g}))\|_{2}^{2},\\ _{}&=_{\{i,g\}}\|f_{ }(_{i,g})-f_{}(H_{k}(f_{}(_{i,g}))\|_{2}^{2}. \] (9)

We first trained the denoiser \(F_{}\) using the SURE loss. Next, we froze the SURE-based denoiser and trained the network \(F_{}\) with a combined loss function, \(()=_{MC}()+_{VS}()\), where \(\) is a trade-off parameter (see SM for training details).

## 5 Experiment

### Experiment setup

DatasetWe generated 8,000 transients using the transient rasterizer from  with default parameters. The transients have a spatial-temporal resolution of \(128 128 512\) with a bin width of 33 ps. The dataset contains 111 objects from the alphanumerics dataset , covering lowercase and uppercase letters from the English and Greek alphabets, and numerals from 0 to 9. We also rendered a sample "bunny" for quantitative comparison. To assess our method's generalization, we tested it on real-world data acquired by three different systems  and a self-built system (see SM for system details). The hidden scenes feature various reflective materials, depth ranges, and geometric shapes, and were acquired under different conditions including scanned areas, spatial resolutions, bin widths, and integration times. For a fair comparison with CC-SOCR  within a manageable time frame, we resized the full-sampled transients  to \(128 128 256\) and the full-sampled transients  to \(64 64 256\). We used these resized transients for all methods.

Relay surfaceTo simulate the irregularly undersampled process, we extracted signals from the full-sampled transients according to various irregular relay surfaces. For training, we sampled five horizontal shutter patterns with intervals of  and 40 uniform rotations from 0 to 180 degrees, resulting in 200 sampling patterns (see Fig. 2(c)). For testing, we included more realistic irregular relay surfaces to evaluate our method's generalization capability in real-world scenarios.

Compared methodsWe compare our method with three traditional direct reconstruction algorithms (LCT , FK , RSD ), two learning-based algorithms (Unsupervised NeTF , Supervised USM ), and one iterative algorithm (CC-SOCR ). Since LCT, FK, RSD, and USM are designed for raster scanning, we use zero-padded versions of the IUT as input, similar to our method. NeTF and CC-SOCR accept irregularly undersampled transients. For a fair comparison, we also applied our SURE-based denoiser to pre-denoise the transients for all compared methods. However, we did not apply the pre-denoising step for CC-SOCR, as the results reconstructed by CC-SOCR did not show significant improvements. This is because the strong CC-SOCR regularization inherently performs some level of denoising. We compute the peak signal-to-noise ratio (PSNR) to quantitatively evaluate the reconstruction results on the simulated dataset for all methods.

### Results

Simulated dataFig. 4 shows comparison results on the "bunny". LCT, FK, NeTF, CC-SOCR, and our method can recover the main body. However, FK and CC-SOCR lose structures around the ear, while LCT and RSD exhibit aliasing artifacts due to irregular undersampling. Among the learning-based methods, NeTF produces a blurry object with diffused artifacts and loss of structures around the ear. USM struggles to adapt to irregularly undersampled transients and fails to reconstruct the hidden object. In contrast, our method successfully recovers most geometric structures of the bunny without aliasing artifacts, achieving the best quantitative results.

Real-world dataWe first tested our method on publicly available real datasets  (Fig.5), and then on self-captured real-world data (Fig.6). Without proper regularization, the direct reconstruction methods, _i. e._, LCT and RSD, exhibit severe aliasing artifacts due to undersampling. FK is depth-sensitive and fails to recover far-end structures in the hidden scene. NeTF tends to produce blurry shapes due to its struggle with utilizing limited information in IUT. USM produces results that are nearly overwhelmed by aliasing artifacts in irregularly undersampled cases, but can achieve acceptable results in regularly undersampled cases (Fig.6). CC-SOCR can recover main objects for

Figure 4: Reconstruction results of the “bunny” with different relay surfaces. The intensity images are normalized to the range of 0 to 1 through maximum value normalization. PSNR (dB) for each intensity image is displayed in the top right corner.

Figure 5: Reconstruction results of publicly available real-world dataset [10; 11; 12] with different relay surfaces.

all the test cases, but loses fine structures at distant depth layers ("Man Deer", "Letter", "Deer" and "Teaser") and underperforms on glossy ("Dragon") or retroreflective ("SU") objects. Our method achieves the best quality for various objects and sampling patterns. Our method generates stable results on real-world data with diverse attributes and relay surfaces despite being trained only on a simple alphanumeric dataset and shutter-like relay surfaces. It notably outperforms the range-space solver LCT, successfully removing aliasing artifacts while preserving structure. The promising generalization highlights the effectiveness of our method in learning beyond the range space.

### Inference time

We compare the inference time of various methods. The values in the table represent the average inference CPU with 32 cores and an NVIDIA 3090 GPU, respectively. The inference times of NeTF and CC-SOCR vary with different IUT. Therefore, we average the inference times across 16 IUT shown in Fig. 5 and Fig. 6 each with a size of \(128 128 256\). As shown in Tab. 1, the direct reconstruction methods, LCT, FK, and RSD, are faster than the other methods. Unlike these one-step approaches, CC-SOCR iteratively solves the functional model by a series of alternative sub-problems, requiring nearly eight hours to reconstruct an albedo. NeTF stands on the per-scene rendering framework and thus requires significantly longer inference times than the other two learning-based methods, USM, and our method. Note that both our method and CC-SOCR achieve more accurate reconstructions than the other methods. However, our method is 12,000\(\) faster than CC-SOCR in CPU mode.

### Ablation study

We validate the effectiveness of the two core components of our method: the virtual scanning process (VS) and the SURE-based denoiser. For quantitative evaluation, we simulated a dataset of 1,000 transients by rendering objects with complex geometries, such as chairs, clocks, guitars, sofas, and motorcycles. Our method and its two variants were tested on the simulated transients sampling with 15 different relay surfaces. For qualitative evaluation, we assess the two components using real-world datasets, "Teaser" and "Dragon". "Teaser" features complex structures, which helps evaluate VS's ability to recover details. "Dragon", with its glossy material, exhibits a lower signal-to-noise ratio in its acquired transient, which helps validate the SURE-based denoiser's effectiveness.

   Method & LCT & FK & RSD & NeTF & USM & CC-SOCR & Ours \\  Runtime (CPU) & 0.81 s & 1.52 s & 0.94 s & N/A & 2.34 s & 7.73 h & 2.24 s \\ Runtime (GPU) & 0.09 s & 0.15 s & 0.12 s & 0.69 h & 0.24 s & N/A & 0.18 s \\   

Table 1: Inference time of various methods. The values in the table represent the average inference time across 16 IUT with size of \(128 128 256\).

Figure 6: Reconstruction results of self-captured real-world dataset with different relay surfaces.

Virtual ScanningAs shown in Tab. 2, the virtual scanning process resulted in an average improvement of 0.89 dB. Fig. 7 demonstrates that without the VS component, our method can only recover a limited portion of the scene structure, which is impaired by aliasing artifacts. In contrast, our full model reconstructs more detailed and cleaner structures, confirming the effectiveness of VS component in recovering null-space components.

SURE-based denoiserAs evident from the quantitative results, the SURE-denoiser achieved an average performance improvement of 1.83 dB, which is more significant than that of VS. This result aligns with expectations because background noise affects the entire reconstruction volume, while aliasing artifacts caused by irregular undersampling disrupt the main structure. For both LCT and our method, as illustrated in Fig. 7(b), the denoiser effectively suppresses noise artifacts. In Sec. 5.2, we apply the denoiser to competing methods to enhance their robustness to noise for a fair comparison. This demonstrates the versatility of the denoiser as a plug-and-play module in other NLOS algorithms.

Additional ablation studies on the hyperparameters within the loss functions and the relay surfaces used for training are provided in the supplementary materials.

## 6 Conclusion and limitations

ConclusionIn this paper, we propose an unsupervised learning-based framework for NLOS imaging from irregularly undersampled transients (IUT). By introducing a virtual scanning process and a SURE-based denoiser, our framework achieves high-quality and fast NLOS reconstructions from IUT. Furthermore, it can be trained solely from noisy IUT, enabling future work on direct learning from real-world datasets to bridge the gap between simulated and real datasets. Our method outperforms the state-of-the-art method on both simulated and real-world data with various relay surfaces. In future work, we will extend our method to non-confocal imaging systems for more practical applications.

LimitationsOur method faces two main limitations. Firstly, it is constrained to the confocal system due to the lack of a high-speed, low-memory non-confocal forward operator for deep learning training. However, the framework is theoretically extendable to general forward operators, indicating future research on new forward operators in NLOS imaging may not require special consideration for irregular undersampling. Secondly, while our method is entirely unsupervised, we only present the results of our method which is trained using simulated transients due to the time-consuming nature of collecting real transient datasets. Nonetheless, this approach partially mitigates the data gap introduced by simulated ground truth, and the results demonstrate excellent performance. Transitioning to deep learning that exclusively uses real transients is one of our future goals.