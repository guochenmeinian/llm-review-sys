# PFDiff: Training-free Acceleration of Diffusion Models through the Gradient Guidance of Past and Future

PFDiff: Training-free Acceleration of Diffusion Models through the Gradient Guidance of Past and Future

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Diffusion Probabilistic Models (DPMs) have shown remarkable potential in image generation, but their sampling efficiency is hindered by the need for numerous denoising steps. Most existing solutions accelerate the sampling process by proposing fast ODE solvers. However, the inevitable discretization errors of the ODE solvers are significantly magnified when the number of function evaluations (NFE) is fewer. In this work, we propose _PFDiff_, a novel _training-free_ and _orthogonal_ timestep-skipping strategy, which enables existing fast ODE solvers to operate with fewer NFE. Based on two key observations: a significant similarity in the model's outputs at time step size that is not excessively large during the denoising process of existing ODE solvers, and a high resemblance between the denoising process and SGD. PFDiff, by employing gradient replacement from past time steps and foresight updates inspired by Nesterov momentum, rapidly updates intermediate states, thereby reducing unnecessary NFE while correcting for discretization errors inherent in first-order ODE solvers. Experimental results demonstrate that PFDiff exhibits flexible applicability across various pre-trained DPMs, particularly excelling in conditional DPMs and surpassing previous state-of-the-art training-free methods. For instance, using DDIM as a baseline, we achieved 16.46 FID (4 NFE) compared to 138.81 FID with DDIM on ImageNet 64x64 with classifier guidance, and 13.06 FID (10 NFE) on Stable Diffusion with 7.5 guidance scale.

## 1 Introduction

In recent years, Diffusion Probabilistic Models (DPMs) [1; 2; 3; 4] have demonstrated exceptional modeling capabilities across various domains including image generation [5; 6; 7], video generation , text-to-image generation [9; 10], speech synthesis , and text-to-3D generation [12; 13]. They have become a key driving force advancing deep generative models. DPMs initiate with a forward process that introduces noise onto images, followed by utilizing a neural network to learn a backward process that incrementally removes noise, thereby generating images [2; 4]. Compared to other generative methods such as Generative Adversarial Networks (GANs)  and Variational Autoencoders (VAEs) , DPMs not only possess a simpler optimization target but also are capable of producing higher quality samples . However, the generation of high-quality samples via DPMs requires hundreds or thousands of denoising steps, significantly lowering their sampling efficiency and becoming a major barrier to their widespread application.

Existing techniques for rapid sampling in DPMs primarily fall into two categories. First, training-based methods [16; 17; 18; 19], which can significantly compress sampling steps, even achieving single-step sampling . However, this compression often comes with a considerable additional training cost, and these methods are challenging to apply to large pre-trained models. Second, training-free samplers [20; 21; 22; 23; 24; 25; 26; 27; 28; 29; 30], which typically employ implicit or analytical solutions to Stochastic Differential Equations(SDE)/Ordinary Differential Equations (ODE) for lower-error sampling processes. For instance, Lu et al. [21; 22], by analyzing the semi-linear structure of the ODE solvers for DPMs, have sought to analytically derive optimally the solutions for DPMs' ODE solvers. These training-free sampling strategies can often be used in a plug-and-play fashion, compatible with existing pre-trained DPMs. However, when the NFE is below 10, the discretization error of these training-free methods will be significantly amplified, leading to convergence issues [21; 22], which can still be time-consuming.

To further enhance the sampling speed of DPMs, we have analyzed the potential for improvement in existing training-free accelerated methods. Initially, we observed a notably high similarity in the model's outputs for the existing ODE solvers of DPMs when time step size \( t\) is not extremely large, as illustrated in Fig. 1(a). This observation led us to utilize the gradients that have been computed from past time steps to approximate current gradients, thereby reducing unnecessary estimation of noise network. Furthermore, due to the similarities between the sampling process of DPMs and Stochastic Gradient Descent (SGD)  as noted in Remark 1, we incorporated a _foresight_ update mechanism using Nesterov momentum , known for accelerating SGD training. Specifically, we ingeniously employ prior observation to predict future gradients, then utilize the future gradients as a "_springboard_" to facilitate larger update step size \( t\), as shown in Fig. 1(b).

Motivated by these insights, we propose _PFDiff_, a timestep-skipping sampling algorithm that rapidly updates the current intermediate state through the gradient guidance of past and future. Notably, PFDiff is _training-free_ and _orthogonal_ to existing DPMs sampling algorithms, providing a new orthogonal axis for DPMs sampling. Unlike previous orthogonal sampling algorithms that compromise

Figure 1: Sampling by conditional pre-trained DPMs [5; 9] using DDIM  and our method PFDiff (dashed box) with DDIM as a baseline, varying the number of function evaluations (NFE).

sampling quality for speed , we prove that PFDiff corrects for errors in the sampling trajectories of first-order ODE solvers. This improves sampling quality while reducing unnecessary NFE in existing ODE solvers, as illustrated in Fig. 1(b). To validate the orthogonality and effectiveness of PFDiff, extensive experiments were conducted on both unconditional [2; 4; 20] and conditional [5; 9] pre-trained DPMs, with the visualization experiment of conditional DPMs depicted in Fig. 1. The results indicate that PFDiff significantly enhances the sampling performance of existing ODE solvers. Particularly in conditional DPMs, PFDiff, using only DDIM as the baseline, surpasses the previous state-of-the-art training-free sampling algorithms.

## 2 Background

### Diffusion SDEs

Diffusion Probabilistic Models (DPMs) [1; 2; 3; 4] aim to generate \(D\)-dimensional random variables \(x_{0}^{D}\) that follow a data distribution \(q(x_{0})\). Taking Denoising Diffusion Probabilistic Models (DDPM)  as an example, these models introduce noise to the data distribution through a forward process defined over discrete time steps, gradually transforming it into a standard Gaussian distribution \(x_{T}(,)\). The forward process's latent variables \(\{x_{t}\}_{t[0,T]}\) are defined as follows:

\[q(x_{t} x_{0})=(x_{t}_{t}x_{0},_{t}^{2}), \]

where \(_{t}\) is a scalar function related to the time step \(t\), with \(_{t}^{2}+_{t}^{2}=1\). In the model's reverse process, DDPM utilizes a neural network model \(p_{}(x_{t-1} x_{t})\) to approximate the transition probability \(q(x_{t-1} x_{t},x_{0})\),

\[p_{}(x_{t-1} x_{t})=(x_{t-1}_{}(x_{t},t), _{}^{2}(t)), \]

where \(_{}^{2}(t)\) is defined as a scalar function related to the time step \(t\). By sampling from a standard Gaussian distribution and utilizing the trained neural network, samples following the data distribution \(p_{}(x_{0})=_{t=1}^{T}p_{}(x_{t-1} x_{t})\) can be generated.

Furthermore, Song et al.  introduced SDE to model DPMs over continuous time steps, where the forward process is defined as:

\[x_{t}=f(t)x_{t}t+g(t)w_{t}, x_{0} q(x_{ 0}), \]

where \(w_{t}\) represents a standard Wiener process, and \(f\) and \(g\) are scalar functions of the time step \(t\). It's noteworthy that the forward process in Eq. (1) is a discrete form of Eq. (3), where \(f(t)=_{t}}{t}\) and \(g^{2}(t)=_{t}^{2}}{t}-2 _{t}}{t}_{t}^{2}\). Song et al.  further demonstrated that there exists an equivalent reverse process from time step \(T\) to \(0\) for the forward process in Eq. (3):

\[x_{t}=[f(t)x_{t}-g^{2}(t)_{x} q_{t}(x_{t})] t+g(t)_{t}, x_{T} q(x_{T}), \]

Figure 2: (a) The trend of the MSE of the noise network output \(_{}(x_{t},t)\) over time step size \( t\), where \(\) in DDPM  comes from \(_{t}\) in Eq. (6). Solid lines: ODE solvers, dashed lines: SDE solvers. (b) Comparison of partial sampling trajectories between PFDiff-1 and a first-order ODE solver, where the update directions are guided by the tangent direction of the sampling trajectories.

where \(\) denotes a standard Wiener process. In this reverse process, the only unknown is the _score function_\(_{x} q_{t}(x_{t})\), which can be approximated through neural networks.

### Diffusion ODEs

In DPMs based on SDE, the discretization of the sampling process often requires a significant number of time steps to converge, such as the \(T=1000\) time steps used in DDPM . This requirement primarily stems from the randomness introduced at each time step by the SDE. To achieve a more efficient sampling process, Song et al.  utilized the Fokker-Planck equation  to derive a _probability flow ODE_ related to the SDE, which possesses the same marginal distribution at any given time \(t\) as the SDE. Specifically, the reverse process ODE derived from Eq. (3) can be expressed as:

\[x_{t}=[f(t)x_{t}-g^{2}(t)_{x} q_{t}(x_{t}) ]t, x_{T} q(x_{T}). \]

Unlike SDE, ODE avoids the introduction of randomness, thereby allowing convergence to the data distribution in fewer time steps. Song et al.  employed a high-order RK45 ODE solver , achieving sample quality comparable to SDE at 1000 NFE with only 60 NFE. Furthermore, research such as DDIM  and DPM-Solver  explored discrete ODE forms capable of converging in fewer NFE. For DDIM, it breaks the Markov chain constraint on the basis of DDPM, deriving a new sampling formula expressed as follows:

\[x_{t-1}=}(-}_{ }(x_{t},t)}{}})+- _{t}^{2}}_{}(x_{t},t)+_{t}_{t}, \]

where \(_{t}=)/(1-_{t} )}/_{t-1}}\), and \(_{t}\) corresponds to \(_{t}^{2}\) in Eq. (1). When \(=1\), Eq. (6) becomes a form of DDPM ; when \(=0\), it degenerates into an ODE, the form adopted by DDIM , which can obtain high-quality samples in fewer time steps.

**Remark 1**.: _In this paper, we regard the gradient \(_{t}\), the noise network output \(_{}(x_{t},t)\), and the score function \(_{x} q_{t}(x_{t})\) as expressing equivalent concepts. This is because Song et al.  demonstrated that \(_{}(x_{t},t)=-_{t}_{x} q_{t}(x_{t})\). Moreover, we have discovered that any first-order solver of DPMs can be parameterized as \(x_{t-1}=_{t}-_{t}_{t}+_{t}\). Taking DDIM  as an example, where \(_{t}=}{_{t}}}x_{t}\), \(_{t}=}{_{t}}-_{t-1}}-}\), \(_{t}=_{}(x_{t},t)\), and \(=0\). This indicates the similarity between SGD and the sampling process of DPMs, a discovery also implicitly suggested in the research of Xue et al.  and Wang et al. ._

## 3 Method

### Solving for reverse process diffusion ODEs

By substituting \(_{}(x_{t},t)=-_{t}_{x} q_{t}(x_{t})\), Eq. (5) can be rewritten as:

\[x_{t}}{t}=s(_{}(x_{t},t),x_{t},t):=f(t )x_{t}+(t)}{2_{t}}_{}(x_{t},t), x_{T}  q(x_{T}). \]

Given an initial value \(x_{T}\), we define the time steps \(\{t_{i}\}_{i=0}^{T}\) to progressively decrease from \(t_{0}=T\) to \(t_{T}=0\). Let \(_{t_{0}}=x_{T}\) be the initial value. Using \(T\) steps of iteration, we compute the sequence \(\{_{t_{i}}\}_{i=0}^{T}\) to obtain the solution of this ODE. By integrating both sides of Eq. (7), we can obtain the exact solution of this sampling ODE.

\[_{t_{i}}=_{t_{i-1}}+_{t_{i-1}}^{t_{i}}s(_{ }(x_{t},t),x_{t},t)t. \]

For any \(p\)-order ODE solver, Eq. (8) can be discretely represented as:

\[_{t_{i-1} t_{i}}_{t_{i-1}}+_{n=0}^{p-1}h( _{}(_{t_{n}},_{n}),_{_{n}}, _{n}), i[1,,T], \]

where \(_{0}=t_{i-1}\), \(_{p}=t_{i}\), and \(=_{n+1}-_{n}\) denote the time step size. The function \(h\) represents the different solution methodologies applied by various \(p\)-order ODE solvers to the function \(s\). For the Euler-Maruyama solver , \(h\) is the identity mapping of \(s\). Further, we define \((Q,_{t_{i-1}},t_{i-1},t_{i}):=_{t_{i-1}}+_{n=0}^{p-1}h( _{}(_{_{n}},_{n}),_{_{n}}, _{n})\). Here, \(\) is any \(p\)-order ODE solver, and buffer \(Q=(\{_{}(_{_{n}},_{n})\}_{ n=0}^{p-1},t_{i-1},t_{i})\), where \(_{0}=t_{i-1}\) and \(_{p}=t_{i}\).

When using the ODE solver defined in Eq. (9) for sampling, the choice of \(T=1000\) leads to significant inefficiencies in DPMs. The study on DDIM  first revealed that by constructing a new forward sub-state sequence of length \(M+1\) (\(M T\)), \(\{_{t_{i}}\}_{i=0}^{M}\), from a subsequence of time steps \([0,,T]\) and reversing this sub-state sequence, it is possible to converge to the data distribution in fewer time steps. However, as illustrated in Fig. 2a, for ODE solvers, as the time step \( t=t_{i}-t_{i-1}\) increases, the gradient direction changes slowly initially, but undergoes abrupt changes as \( t T\). This phenomenon indicates that under minimal NFE (i.e., maximal time step size \( t\)) conditions, the discretization error in Eq. (9) is significantly amplified. Consequently, existing ODE solvers, when sampling under minimal NFE, must sacrifice sampling quality to gain speed, making it an extremely challenging task to reduce NFE to below 10 [21; 22]. Given this, we aim to develop an efficient timestep-skipping sampling algorithm, which reduces NFE while correcting discretization errors, thereby ensuring that sampling quality is not compromised, and may even be improved.

### Sampling guided by past gradients

For any \(p\)-order timestep-skipping sampling algorithm for DPMs, the sampling process can be reformulated according to Eq. (9) as follows:

\[_{t_{i}}(Q,_{t_{i-1}},t_{i-1},t_{i}), i[1,,M], \]

where buffer \(Q=(\{_{}(_{_{n}},_{n})\}_{ n=0}^{p-1},t_{i-1},t_{i})\) and \([1,,M]\) is an increasing subsequence of \([1,,T]\). As illustrated in Fig. 2a, when the time step size \( t\) (i.e., \(t_{i}-t_{i-1}\)) is not excessively large, the MSE of the noise network, defined as \(_{t=0}^{T- t-1}\|_{}(x_{t},t)- _{}(x_{t+ t},t+ t)\|^{2}\), is remarkably similar. This phenomenon is especially pronounced in ODE-based sampling algorithms, such as DDIM  and DPM-Solver . This observation suggests that there are many unnecessary time steps in ODE-based sampling methods during the complete sampling process (e.g., when \(T=1000\)), which is one of the reasons these methods can generate samples in fewer steps. Based on this, we propose replacing the noise network of the current timestep with the output from a previous timestep to reduce unnecessary NFE without compromising the quality of the final generated samples. Initially, we store the output of the previous timestep's noise network in a _buffer_ as follows:

\[Q}(\{_{}(_{_{ n}},_{n})\}_{n=0}^{p-1},t_{i-1},t_{i}),_{0}=t_{i-1},_{p}=t_{i}. \]

Then, in the current timestep, we directly use the noise network output saved in the buffer from the previous timestep to replace the current timestep's noise network output, thereby updating the intermediate states to the next timestep, as detailed below:

\[_{t_{i+1}}(Q,_{t_{i}},t_{i},t_{i+1}),Q=(\{_{}(_{_{n}},_{n})\}_{n=0}^{p-1 },t_{i-1},t_{i}). \]

By using this approach, we can effectively accelerate the sampling process, reduce unnecessary NFE, and ensure the quality of the samples is not affected. The convergence proof is in Appendix B.1.

### Sampling guided by future gradients

As stated in Remark 1, considering the similarities between the sampling process of DPMs and SGD , we introduce a _foresight_ update mechanism of Nesterov momentum, utilizing future gradient information as a "_springboard_" to assist the current intermediate state in achieving more efficient leapfrog updates. Specifically, for the intermediate state \(_{t_{i+1}}\) predicted using past gradients as discussed in Sec. 3.2, we first estimate the future gradient and _update_ the current _buffer_ as follows:

\[Q}(\{_{}(_{_{ n}},_{n})\}_{n=0}^{p-1},t_{i+1},t_{i+2}),_{0}=t_{i+1},_{p}=t_{i+2}. \]

Subsequently, leveraging the concept of foresight updates, we predict a further future intermediate state \(_{t_{i+2}}\) using the current intermediate state \(_{t_{i}}\) along with the future gradient information corresponding to \(_{t_{i+1}}\), as shown below:

\[_{t_{i+2}}(Q,_{t_{i}},t_{i},t_{i+2}),Q=(\{_{}(_{_{n}},_{n})\}_{n=0}^{p-1},t_{i+1},t_{i+2} ). \]Furthermore, Zhou et al.  performed a Principal Component Analysis (PCA) on the sampling trajectories generated by ODE solvers for DPMs and discovered they almost lie in a two-dimensional plane embedded within a high-dimensional space. This implies that the _Mean Value Theorem_ approximately holds during the sampling process using ODE solvers. Specifically, updating the current intermediate state \(_{t_{i}}\) at an optimal time point \(s\) with the corresponding gradient information, _ground truth_\(_{}(_{t_{s}},t_{s})\), results in the smallest update error, where \(s\) is between time points \(i\) and \(i+2\). Further, we can reason that for any _first-order_ ODE solver, under the same time step, the use of future gradient information \(_{}(_{t_{i+1}},t_{i+1})\) from Eq. (13) to update the current intermediate state \(_{t_{i}}\) results in a smaller sampling error compared to using the gradient information at the current time point \(_{}(_{t_{i}},t_{i})\). A detailed proof is provided in Appendix B.2. However, for higher-order ODE solvers, the solving process implicitly utilizes future gradients as mentioned in Sec. 3.5, and the additional explicit introduction of future gradients increases sampling error. Therefore, when using higher-order ODE solvers as a baseline, the sampling process is accelerated by only using past gradients. It is only necessary to modify Eq. (14) to \(_{t_{i+2}}(Q,_{t_{i+1}},t_{i+1},t_{i+2})\) while keeping \(Q\) constant. Ablation experiments can be found in Sec. 4.3.

### PFDiff: sampling guided by past and future gradients

Combining Sec. 3.2 and Sec. 3.3, the intermediate state \(_{t_{i+1}}\) obtained through Eq. (12) is used to update the buffer \(Q\) in Eq. (13). In this way, we achieve our proposed efficient timestep-skipping algorithm, which we name PFDiff, as shown in Algorithm 1. For higher-order ODE solvers (\(p>1\)), PFDiff only utilizes past gradient information, while for first-order ODE solvers (\(p=1\)), it uses both past and future gradient information to predict further future intermediate states. Notably, during the iteration from intermediate state \(_{t_{i}}\) to \(_{t_{i+2}}\), we only perform a single batch computation (NFE = \(p\)) of the noise network in Eq. (13). Furthermore, we propose that in a single iteration process, \(_{t_{i+2}}\) in Eq. (14) can be modified to \(_{t_{i+(k+1)}}\), achieving a \(k\)-step skip to sample more distant future intermediate states. Additionally, when \(k 1\), the buffer \(Q\), which acts as an intermediate "springboard" from Eq. (13), has various computational origins. This can be accomplished by modifying \(_{t_{i+1}}\) in Eq. (12) to \(_{t_{i+l}}\). We collectively refer to this multi-step skipping and different "springboard" selection strategy as PFDiff-\(k\_l\) (\(l k\)). Further algorithmic details can be found in Appendix C. Finally, through the comparison of sampling trajectories between PFDiff-1 and a first-order ODE sampler, as shown in Fig. 2b, PFDiff-1 showcases its capability to correct the sampling trajectory of the first-order ODE sampler while reducing the NFE.

**Proposition 3.1**.: _For any given DPM first-order ODE solver \(\), the PFDiff-\(k\_l\) algorithm can describe the sampling process within an iteration cycle through the following formula:_

\[_{t_{i+(k+1)}}(_{}((_{}( _{t_{i-(k-l+1)}},t_{i-(k-l+1)}),_{t_{i}},t_{i},t_{i+l}),t_{ i+l}),_{t_{i}},t_{i},t_{i+(k+1)}), \]

```
1: initial value \(x_{T}\), NFE \(N\), model \(_{}\), any \(p\)-order solver \(\)
2: Define time steps \(\{t_{i}\}_{i=0}^{M}\) with \(M=2N-1p\)
3:\(_{t_{0}} x_{T}\)
4:\(Q}(\{_{}(_{t_{i}}, _{n})\}_{n=0}^{p-1},t_{0},t_{1})\), where \(_{0}=t_{0},_{p}=t_{1}\)\(\) Initialize buffer
5:\(_{t_{1}}=(Q,_{t_{0}},t_{0},t_{1})\)
6:for\(i 1\) to \(-2\)do
7:if\((i-1) 2=0\)then
8:\(_{t_{i+1}}=(Q,_{t_{i}},t_{i},t_{i+1})\)\(\) Updating guided by past gradients
9:\(Q}(\{_{}(_{t_{i}}, _{n})\}_{n=0}^{p-1},t_{i+1},t_{i+2})\)\(\) Update buffer (overwrite)
10:if\(p=1\)then
11:\(_{t_{i+2}}=(Q,_{t_{i}},t_{i},t_{i+2})\)\(\) Anticipatory updating guided by future gradients
12:elseif\(p>1\)then
13:\(_{t_{i+2}}=(Q,_{t_{i+1}},t_{i+1},t_{i+2})\)\(\) The higher-order solver uses only past gradients
14:endif
15:endfor
16:return\(_{t_{M}}\)
```

**Algorithm 1** PFDiff-1_where the value of \(_{}(_{t_{i-(k-l+1)}},t_{i-(k-l+1)})\) can be directly obtained from the buffer \(Q\), without the need for additional computations. The iterative process defined by Eq. (15) ensures that the sampling outcomes converge to the data distribution consistent with the solver \(\), while effectively correcting errors in the sampling process (Proof in Appendix B)._

It is noteworthy that, although the PFDiff is conceptually orthogonal to the SDE/ODE solvers of DPMs, even when the time size \( t\) is relatively small, the MSE of the noise network in the SDE solver exhibits significant differences, as shown in Fig. 1(a). Consequently, PFDiff shows marked improvements on the ODE solver, and our experiments are almost exclusively based on ODE solvers, with exploratory experiments on SDE solvers referred to Sec. 4.1.

### Connection with other samplers

Relationship with \(p\)-order solver [21; 22; 27].According to Eq. (10), a single iteration of the \(p\)-order solver can be represented as:

\[_{t_{i+1}}-((\{_{ }(_{_{n}},_{n})\}_{n=0}^{p-1},t_{i},t_{i+1 }),_{t_{i}},t_{i},t_{i+1}), i[0,,M-1]. \]

A single iteration of the \(p\)-order solver uses \(p\) NFE to predict the next intermediate state. The intermediate step gradients obtained during this process can be considered as an approximation of future gradients. This approximation is implicitly contained within the sampling guided by future gradients that we propose. Furthermore, as shown in Eq. (15), a single iteration update of PFDiff based on a first-order solver can be seen as using a 2-order solver with only one NFE.

## 4 Experiments

In this section, we validate the effectiveness of PFDiff as an _orthogonal_ and _training-free_ sampler through a series of extensive experiments. This sampler can be integrated with any order of ODE solvers, thereby significantly enhancing the sampling efficiency of various types of pre-trained DPMs. To systematically showcase the performance of PFDiff, we categorize the pre-trained DPMs into two main types: conditional and unconditional. Unconditional DPMs are further subdivided into discrete and continuous, while conditional DPMs are subdivided into classifier guidance and classifier-free guidance. In choosing ODE solvers, we utilized the widely recognized first-order DDIM , Analytic-DDIM , and the higher-order DPM-Solver  as baselines. For each experiment, we use the Frechet Inception Distance (FID\(\))  as the primary evaluation metric, and provide the experimental results of the Inception Score (IS\(\))  in the Appendix D.7 for reference. Lastly, apart from the ablation studies on parameters \(k\) and \(l\) discussed in Sec. 4.3, we showcase the optimal results of PFDiff-\(k\_l\) (where \(k=1,2,3\) and \(l k\)) across six configurations as a performance demonstration of PFDiff. As described in Appendix C, this does not increase the computational burden in practical applications. All experiments were conducted on an NVIDIA RTX 3090 GPU.

### Unconditional sampling

For unconditional DPMs, we selected discrete DDPM  and DDIM , as well as pre-trained models from continuous ScoreSDE , to assess the effectiveness of PFDiff. For these pre-trained models, all experiments sampled 50k instances to compute evaluation metrics.

For unconditional discrete DPMs, we first select first-order ODE solvers DDIM  and Analytic-DDIM  as baselines, while implementing SDE-based DDPM  and Analytic-DDPM  methods for comparison, where \(=1.0\) is from \(_{t}\) in Eq. (6). We conduct experiments on the CIFAR10  and CelebA 64x64  datasets using the quadratic time steps employed by DDIM. By varying the NFE from 6 to 20, the evaluation metric FID\(\) is shown in Figs. 2(a) and 2(b). Additionally, experiments with uniform time steps are conducted on the CelebA 64x64, LSUN-bedroom 256x256 , and LSUN-church 256x256  datasets, with more results available in Appendix D.2. Our experimental results demonstrate that PFDiff, based on pre-trained models of discrete unconditional DPMs, significantly improves the sampling efficiency of DDIM and Analytic-DDIM samplers across multiple datasets. For instance, on the CIFAR10 dataset, PFDiff combined with DDIM achieves a FID of 4.10 with only 15 NFE, comparable to DDIM's performance of 4.04 FID with 1000 NFE. This is something other time-step skipping algorithms [23; 28] that sacrifice sampling quality for speed cannot achieve. Furthermore, in Appendix D.2, by varying \(\) from 1.0 to 0.0 in Eq. (6) to control the scale of noise introduced by SDE, we observe that as \(\) decreases (reducing noise introduction), the performance of PFDiff gradually improves. This once again validates our assumption proposed in Sec. 3.2, based on Fig. 1(a), that there is a significant similarity in the model's outputs at the time step size that is not excessively large for the existing ODE solvers.

For unconditional continuous DPMs, we choose the DPM-Solver-1, -2 and -3  as the baseline to verify the effectiveness of PFDiff as an orthogonal timestep-skipping algorithm on the first and higher-order ODE solvers. We conducted experiments on the CIFAR10  using quadratic time steps, varying the NFE. The experimental results using FID\(\) as the evaluation metric are shown in Fig. 1(c). More experimental details can be found in Appendix D.3. We observe that PFDiff consistently improves the sampling performance over the baseline with fewer NFE settings, particularly in cases where higher-order ODE solvers fail to converge with a small NFE (below 10) .

### Conditional sampling

For conditional DPMs, we selected the pre-trained models of the widely recognized classifier guidance paradigm, ADM-G , and the classifier-free guidance paradigm, Stable-Diffusion , to validate the effectiveness of PFDiff. We employed uniform time steps setting and the DDIM  ODE solver as a baseline across all datasets. Evaluation metrics were computed by sampling 50k samples on the ImageNet 64x64  dataset for ADM-G and 10k samples on other datasets, including ImageNet 256x256  in ADM-G and MS-COCO2014  in Stable-Diffusion.

For conditional DPMs employing the classifier guidance paradigm, we conducted experiments on the ImageNet 64x64 dataset  with a guidance scale (\(s\)) set to 1.0. For comparison, we implemented DPM-Solver-2 and -3 , and DPM-Solver++(2M) , which exhibit the best performance on conditional DPMs. Additionally, we introduced the AutoDiffusion method  using DDIM as a

Figure 4: Conditional sampling results. We report the FID\(\) for different methods by varying the NFE. Evaluated: ImageNet 64x64 with 50k, others with 10k samples. \({}^{*}\)AutoDiffusion  method requires additional search costs. \({}^{}\)We borrow the results reported in DPM-Solver-v3  directly.

Figure 3: Unconditional sampling results. We report the FID\(\) for different methods by varying the number of function evaluations (NFE), evaluated on 50k samples.

baseline for comparison, noting that this method incurs additional search costs. We compared FID\(\) scores by varying the NFE as depicted in Fig. 4a, with corresponding visual comparisons shown in Fig. 1b. We observed that PFDiff reduced the FID from 138.81 with 4 NFE in DDIM to 16.46, achieving an 88.14% improvement in quality. The visual results in Fig. 1b further demonstrate that, at the same NFE setting, PFDiff achieves higher-quality sampling. Furthermore, we evaluated PFDiff's sampling performance based on DDIM on the large-scale ImageNet 256x256 dataset . Detailed results are provided in Appendix D.4.

For conditional, classifier-free guidance paradigms of DPMs, we employed the sd-v1-4 checkpoint and computed the FID\(\) scores on the validation set of MS-COCO2014 . We conducted experiments with a guidance scale (\(s\)) set to 7.5 and 1.5. For comparison, we implemented DPM-Solver-2 and -3 , and DPM-Solver++(2M)  methods. At \(s=7.5\), we introduced the state-of-the-art method reported in DPM-Solver-v3  for comparison, along with DPM-Solver++(2M) , UniPC , and DPM-Solver-v3(2M) . The FID\(\) metrics by varying the NFE are presented in Figs. 4b and 4c, with additional visual results illustrated in Fig. 1a. We observed that PFDiff, solely based on DDIM, achieved state-of-the-art results during the sampling process of Stable-Diffusion, thus demonstrating the efficacy of PFDiff. Further experimental details can be found in Appendix D.5.

### Ablation study

We conducted ablation experiments on the six different algorithm configurations of PFDiff mentioned in Appendix C, with \(k=1,2,3\) (\(l k\)). Specifically, we evaluated the FID\(\) scores on the unconditional and conditional pre-trained DPMs  by varying the NFE. Detailed experimental setups and results can be found in Appendix D.6.1. The experimental results indicate that for various pre-trained DPMs, the choice of parameters \(k\) and \(l\) is not critical, as most combinations of \(k\) and \(l\) within PFDiff can enhance the sampling efficiency over the baseline. Moreover, with \(k=1\) fixed, PFDiff-1 can significantly improve the baseline's sampling quality within the range of 8\(\)20 NFE. For even better sampling quality, one can sample a small subset of examples (e.g., 5k) to compute evaluation metrics or directly conduct visual analysis, easily identifying the most effective \(k\) and \(l\) combinations.

To validate the PFDiff algorithm as mentioned in Sec. 3.3, which necessitates the joint guidance of past and future gradients for first-order ODE solvers, and only past gradients for higher-order ODE solvers, offering a more effective means of accelerating baseline sampling. This study employs the first-order ODE solver DDIM  as the baseline, isolating the effects of both past and future gradients, and uses the higher-order ODE solver DPM-Solver  as the baseline, removing the influence of future gradients for ablation experiments. Specific experimental configurations and results are shown in Appendix D.6.2. The results indicate that, as described by the PFDiff algorithm in Sec. 3.3, it is possible to further enhance the sampling efficiency of ODE solvers of any order.

## 5 Conclusion

In this paper, based on the recognition that the ODE solvers of DPMs exhibit significant similarity in model outputs when the time step size is not excessively large, and with the aid of a foresight update mechanism, we propose PFDiff, a novel method that leverages the gradient guidance from both past and future to rapidly update the current intermediate state. This approach effectively reduces the unnecessary number of function evaluations (NFE) in the ODE solvers and significantly corrects the errors of first-order ODE solvers during the sampling process. Extensive experiments demonstrate the orthogonality and efficacy of PFDiff on both unconditional and conditional pre-trained DPMs, especially in conditional pre-trained DPMs where PFDiff outperforms previous state-of-the-art training-free sampling methods.

Limitations and broader impactAlthough PFDiff can effectively accelerate the sampling speed of existing ODE solvers, it still lags behind the sampling speed of training-based acceleration methods and one-step generation paradigms such as GANs. Moreover, there is no universal setting for the optimal combination of parameters \(k\) and \(l\) in PFDiff; adjustments are required according to different pre-trained DPMs and NFE. It is noteworthy that PFDiff may be utilized to accelerate the generation of malicious content, thereby having a detrimental impact on society.