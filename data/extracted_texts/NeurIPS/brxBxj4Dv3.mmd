# NoisyGL: A Comprehensive Benchmark for Graph Neural Networks under Label Noise

Zhonghao Wang\({}^{1}\), Danyu Sun\({}^{1}\), Sheng Zhou\({}^{1}\)1, Haobo Wang\({}^{1}\),

**Jiapei Fan\({}^{2}\), Longtao Huang\({}^{2}\), Jiajun Bu\({}^{1}\)**

\({}^{1}\)Zhejiang Key Laboratory of Accessible Perception and Intelligent Systems,

Collage of Computer Science, Zhejiang University \({}^{2}\)Alibaba Group

{wangzhonghao, zhousheng_zju, wanghaobo, bjj}@zju.edu.cn,

danyu.21@intl.zju.edu.cn,

{jiapei.fjp, kaiyang.hlt}@alibaba-inc.com

Sheng Zhou is the Corresponding Author

###### Abstract

Graph Neural Networks (GNNs) exhibit strong potential in node classification tasks through a message-passing mechanism. However, their performance often hinges on high-quality node labels, which are challenging to obtain in real-world scenarios due to unreliable sources or adversarial attacks. Consequently, _label noise_ is common in real-world graph data, negatively impacting GNNs by propagating incorrect information during training. To address this issue, the study of Graph Neural Networks under Label Noise (GLN) has recently gained traction. However, due to variations in dataset selection, data splitting, and preprocessing techniques, the community currently lacks a comprehensive benchmark, which impedes deeper understanding and further development of GLN. To fill this gap, we introduce NoisyGL in this paper, the first comprehensive benchmark for graph neural networks under label noise. NoisyGL enables fair comparisons and detailed analyses of GLN methods on noisy labeled graph data across various datasets, with unified experimental settings and interface. Our benchmark has uncovered several important insights missed in previous research, and we believe these findings will be highly beneficial for future studies. We hope our open-source benchmark library will foster further advancements in this field. The code of the benchmark can be found in https://github.com/eaglelab-zju/NoisyGL.

## 1 Introduction

Many complex real-world systems can be represented as graph-structured data, including the citation network , biological networks , traffic networks , and social networks . Graph Neural Networks (GNNs) have demonstrated substantial effectiveness in modeling graph data through a message-passing process that aggregates information from neighboring nodes . Among the numerous applications of GNNs, node classification is the most thoroughly studied task, where GNNs are trained with the explicit assistance of semi-supervised node labels .

Although GNNs have achieved success, their performance in semi-supervised graph learning tasks is highly dependent on precise node labels, which are difficult to obtain in real-world scenarios . For instance, in online social networks, the process of manually labeling millions of users is costly, and the labels often depend on unreliable user input . Furthermore, graph data is vulnerable to adversarial label-flipping attacks . Consequently, label noise is widespread in graph data. Research has demonstrated that label noise can significantly reduce the generalizability of machine learning models on computer vision and natural language processing scenarios . In GNNs, themessage-passing mechanism can further exacerbate this negative impact by propagating incorrect supervision from mislabeled nodes throughout the graph, leading to substantial results .

To address this challenge, an intuitive solution is to draw on the success of previous Learning with Label Noise (LLN) strategies and apply them to GNNs. However, these approaches are not always applicable to graph learning tasks due to the non-i.i.d nature, sparse labeling of graph data, and message-passing mechanism of GNNs. All these factors make GNNs vulnerable to label noise and hinder traditional LLN methods from being directly applied to graph learning tasks.

In recent years, researchers have developed a series of Graph Neural Networks under Label Noise (GLN) methods to achieve robust graph learning in the presence of label noise. These methods succeeded greatly by adopting Loss regularization [14; 31; 11; 2], Robust training strategy , Graph structure augmentation [1; 18; 32], and contrastive learning [30; 10]. Despite the researcher's claim of the robustness of their proposed GLN methods, the comprehensive benchmark for evaluating these methods remains absent, bringing out the following problems: _1) Existing works utilize different datasets, noise types, rates, data splitting, and processing strategies, which makes it challenging to achieve a fair comparison. 2) Existing work lacks an empirical understanding regarding the impact of the graph structure itself on label noise--a critical distinction between LLN and GLN. 3) No existing work has thoroughly examined the applicability of traditional LLN methods to graph learning problems._ These problems hinder us from gaining a comprehensive understanding of the progress in this field.

In this research, we present NoisyGL -- the first comprehensive benchmark for graph neural networks under label noise. Our benchmark includes seventeen representative methods: ten GLN methods to assess their effectiveness and robustness on graphs with noisy labels, and seven LLN methods to evaluate their applicability in graph learning tasks. We employ standardized backbones and APIs, consistent data splitting, and processing strategies to ensure a fair comparison and allow users to construct their models or datasets with minimal effort easily. Besides performance and robustness evaluations, our benchmark supports multidimensional analysis, enabling researchers to explore the time efficiency of different methods and understand the influence of graph structure on the handling of label noise.

Through extensive experiments, we have the following key findings: 1) Simply applying LLN methods can't significantly improve GNNs' robustness to label noise. 2) Existing GLN methods can alleviate label noise in their applicable scenarios. 3) Pair noise is the most harmful label noise due to its misleading impact. 4) Negative effects of label noise can spread through the graph structure, especially in sparse graphs. 5) GLN methods involving graph structure augmentation effectively mitigate the spread effect of label noise. Our contributions can be summarized as follows:

* **Perform an in-depth review of the current research challenge.** In our study, we revisited and scrutinized the entire progression of GLN. We discovered that the lack of a thorough benchmark in this domain significantly hinders a deeper understanding.
* **Provide a comprehensive and user-friendly benchmark.** We present NoisyGL, the first comprehensive benchmark for GLN. In this benchmark, we have selected and implemented a variety of LLN and GLN methods and evaluated them across eight commonly used datasets under uniform experimental settings. Our benchmark library is available to the public on GitHub, intending to aid future research efforts.
* **Highlight the key findings and future opportunities.** Our study has resulted in several crucial findings that have the potential to greatly advance this field.

## 2 Formulations and Background

**Notations.** Consider a graph denoted by \(=\{,\}\), where \(\) is the set of \(N\) nodes and \(\) is the set of edges. \(^{N N}\) is the adjacency matrix and \(=[_{1},_{2},_{N}]^ {N d}\) denotes node features matrix with dimension \(d\). Each node has a ground truth label, the set of which is denoted by \(=\{y_{1}^{*},y_{2}^{*},,y_{N}^{*}\}\). We focus on the semi-supervised node classification problem, where only a small set of nodes \(_{L}\) has assigned labels for training procedure, denoted as \(_{L}=\{y_{1}^{*},y_{2}^{*},,y_{l}^{*}\}\), where \(l\) is the number of labeled nodes. The rest of them are unlabeled nodes, denoted as \(_{U}=-_{L}\). Given \(\) and \(\), the goal of node classification is to train a classifier \(f_{}:(,)}^{N c}=\{ }_{1},}_{2},,}_{N}\}\) by minimizing \((f_{}(,),_{L})\), where \(c\) is the number of classes, \(\) is a loss function that measures the difference between the predicted labels and the ground truth labels. Typically \(f_{}\) is a well-designed Graph Neural Network(GNN). In this way, according to the Empirical Risk Minimization (ERM) principle, the well-trained classifier \(f_{^{*}}\) can generalize on unseen data \(_{U}\).

However, the accessible labels \(_{L}\) can be corrupted by label noise in the real world, reducing the generalization ability of \(f_{^{*}}\). We denote the observed noisy labels as \(_{N}=\{_{1},_{2},_{l}\}\) and \(_{L}\) is their corresponding true labels. Typically, we consider two types of label noise, and here are their definitions:

**Uniform noise ** or symmetric noise assumes that the true label has a probability of \((0,1)\) to be uniformly flipped to another class. Formally, for \(_{j i}\), we have \(p(=j|y^{*}=i)=\), where \(c\) represents the number of classes.

**Pair noise ** or pair flipping. Assumes that the true label can only be flipped to its corresponding pair class with a probability \(\). Formally, we have \(p(=y_{p}|y^{*}=y_{c})=\) and \(_{j y_{p},y_{c}}p(=j|y^{*}=y_{c})=0\), where \(y_{p}\) is the corresponding pair class of \(y_{c}\).

The transition patterns of pair noise and uniform noise are illustrated in the Appendix. B.1. It is important to note that these noise types assume that the transition probability depends only on the observed and true labels, and is independent of instances. In real-world scenarios, label noise can be much more complex. We focus on the most frequently used noise types, leaving the investigation of the other noise types for future studies.

## 3 Benchmark Design

### Datasets and Implementations

**Datasets.** We selected 8 node classification datasets widely used among different studies on graph label noise. These selected datasets come from different domains and exhibit different characteristics, enabling us to evaluate the generalizability of existing methods across a range of scenarios. Specifically, we use three classic citation datasets , namely Cora, Citeseer, Pubmed, and one author collaboration network DBLP , as well as two representative product co-purchase network datasets Amazon-Computers and Amazon-Photo . Additionally, to analyze the model performance on heterophilous graphs, we include two representative social media network datasets BlogCatalog and Flickr . We present detailed introductions to these datasets in Appendix C.1.

The splitting methods for training, validation, and test sets of the same dataset in different tasks are not always consistent. This necessitates a unified dataset splitting in our work to achieve fair comparisons. For three citation datasets, i.e. Cora Citeseer and Pubmed, we follow the most commonly used split in [31; 24; 11; 8]. For the author collaboration network DBLP, we follow the split as [1; 10]. For two co-purchase datasets Amazon-Computers and Amazon-Photo, we follow the split as . For the social network datasets BlogCatalog and Flickr, we use the same split as . In this study, we assume that the labels of both the training set and validation set have been affected by label noise. A clean test set is used to evaluate the model's performance.

**Label Corruption.** In each experiment, we first generate a label transition probability matrix based on the given noise rate and the definition of noise. Then, for each clean label in the training and validation set, we draw a noisy label from a categorical distribution according to its corresponding transition probability. These noisy labels are used in the subsequent training procedure.

**Implementations** We consider a collection of state-of-the-art GLN algorithms, including NRGNN , RTGNN , CP , D-GNN , RCNGLN , CLNode , PIGNN , UnionNET , CGNN , and CRGNN ; and a set of well-designed LLN methods, including two loss correction methods Forward and Backward correction , two robust loss functions APL  and SCE , two multi-network learning methods Coteaching  and JoCoR , and one noise adaptation layer method S-model . We have rigorously reproduced all methods according to their papers and source code. More details about these algorithms and implementations can be found in the Appendix C.2.

### Research Questions

In this study, we aim to answer the following research questions:

**RQ1: Can LLN methods be applied directly to graph learning tasks?**

**Motivation.** While recent studies have suggested that applying traditional Learning with Label Noise (LLN) methods directly to graph learning tasks may not yield the best results , a comprehensive analysis of this issue is still lacking. We aim to investigate the suitability of existing LLN methods for graph learning and understand the underlying reasons. By tackling this question, we can gain a clearer insight into the unique challenges posed by graph label noise and identify which LLN techniques remain effective in graph learning contexts.

**Experiment Design.** To investigate this question, we select various LLN methods referenced in the Section 3.1 and implement them on the GCN backbone using unified hyper-parameters. We then perform node classification experiments on the most frequently used datasets, evaluating their effectiveness under various types and levels of label noise. For each method and dataset, we record the mean accuracy metrics and standard deviations over 10 runs. Data splitting is performed randomly with a consistent ratio. By comparing the performance of these LLN methods with GCN, we determine whether they enhance the robustness of the backbone.

**RQ2: How much progress has been made by existing GLN methods?**

**Motivation.** While numerous GLN methods have been introduced in the literature, previous studies have used varied datasets, data splits, and preprocessing techniques, complicating the fair comparison of these methods' performance. Furthermore, we notice that the majority of existing approaches have been tested on homophily graphs, leading to concerns about their relevance to heterophily graphs, which are also commonly encountered in practice. By investigating this issue, we seek to determine if current GLN methods effectively address graph label noise and to identify their shortcomings.

**Experiment Design.** To address this question, we select and implement many advanced GLN methods as described in Section 3.1. We then assess the performance of these methods using uniform datasets and experimental settings. For each method and dataset, we record the mean test accuracy and the standard deviation across 10 runs. Since many of these GLN methods use GCN as their foundation, we compare their performance with GCN to evaluate their robustness to label noise.

**RQ3: Are existing GLN methods computationally efficient?**

**Motivation.** The efficiency of GNNs in terms of computation is crucial for their use in real-world applications, and considering label noise can lead to higher computational expenses. While previous research has deeply investigated the accuracy, generalization, and robustness of the GLN method, it has failed to address the computational efficiency of these approaches. Therefore, it is important to evaluate the computational efficiency of different methods.

**Experiment design.** To answer this question, we recorded the runtime and test accuracy of various methods on different datasets under \(30\%\) uniform noise. Specifically, for each method, we conducted 10 experiments for each method on each dataset. In each experiment, we measured the time when the model achieved the best accuracy on the validation set, considering it as the total runtime for that method. Through these experiments, we can assess whether the GLN methods strike a balance between computational efficiency and test accuracy.

**RQ4: Are existing GLN methods sensitive to noise rate?**

**Motivation.** Previous studies utilize different noise rates, making it difficult to fairly compare the performance of various methods. Therefore, it is essential to assess different methods using a consistent set of noise rates and to verify if existing GLN methods maintain stable performance across different noise levels.

**Experiment Design.** To investigate this question, we assess the performance of several GLN methods over varying noise levels using the same datasets and noise types. Specifically, we introduce label contamination with pair noise and uniform noise at rates of \(10\%\), \(20\%\), \(30\%\), \(40\%\), and \(50\%\), while using clean labels as a baseline. We then train the GLN methods on these datasets following the experimental settings described in RQ2 and record the mean test accuracy and standard deviation from 10 runs. This evaluation allows us to determine the robustness of each method.

**RQ5: Are existing GLN methods robust to different types of label noise?**

[MISSING_PAGE_FAIL:5]

[MISSING_PAGE_FAIL:6]

GCN on the Cora dataset and an astounding 2945.8 times longer on the DBLP dataset. Moreover, RNCGLN runs out of memory on the PubMed dataset, underscoring its inefficiency in memory usage. On the other hand, while the NRGNN method also consumes more time than GCN, it achieves a reasonable trade-off between performance and computational efficiency across both datasets. Detailed experimental results can be found in Appendix A.

#### 4 (RQ4) Most GLN methods can't ensure a high performance under severe noise.

Figure 2 depicts the performance of different GLN methods on the DBLP dataset under various types and levels of label noise. We observe that, in general, as the noise level increases, the test accuracy of each method decreases. This decrease is most pronounced for pair noise, where the test accuracy of all methods almost halves at \(50\%\) pair noise. Additionally, we noticed that RTGNN maintains relatively stable performance under uniform noise. Moreover, two methods, NRGNN and PIGNN, show better results than the baseline GNN over different noise levels and types on the DBLP dataset. Detailed experimental results are provided in Appendix A.

#### 5 (RQ5) Pair noise is more harmful to graph learning.

In our experiments, we consistently observed that pair noise poses the most significant threat to the generalization ability of models. We have an explanation for this finding: Recall the definition provided in Section 2. For uniform noise, the true label has a chance to flip to any other class, incorrect parameter updates caused by mislabeled instances can be partially compensated by other mislabeled instances. Pair noise, however, restricts the flipping class to a specific pair class. For classifiers, this type of pair flipping can be more misleading. After being fully trained, the classifier is more likely to over-fit the pair class. This becomes particularly harmful when node features propagate through message-passing mechanisms, which can lead to a more similar embedding within local neighbors and thus make them have a similar probability of being misclassified to their corresponding pair class. To validate our hypothesis, we conducted an empirical study. Specifically, we recorded the misleading train accuracy of five methods (including 1 GCN baseline, 2 LLN and 2 GLN) on four datasets under \(50\%\) pair and uniform noise. Here the misleading train accuracy represents the model's accuracy in making incorrect predictions to the misclassified classes. The experimental results (shown in Table 1) demonstrate that pair noise has the greatest impact, leading the model to overfit predict the mislabeled classes across different methods and datasets. Detailed experimental results are available in Appendix A.

   Dataset (Avg. \# Degree) & Noise type & GCN & JCoRoR & APL & NRGNN & CLNode \\   & \(50\%\) **Uniform noise** & \(78.49 9.87\) & \(70.82 3.87\) & \(77.29 12.35\) & \(16.16 7.00\) & \(68.46 17.64\) \\  & \(50\%\) **Pair Noise** & \(94.53 5.51\) & \(84.90 3.49\) & \(92.93 6.46\) & \(64.05 12.02\) & \(88.03 6.22\) \\  & \(50\%\) **Uniform noise** & \(98.78 1.15\) & \(82.64 5.51\) & \(93.21 5.13\) & \(32.74 6.88\) & \(79.54 15.19\) \\  & \(50\%\) **Pair Noise** & \(98.54 2.46\) & \(87.54 5.49\) & \(96.19 3.85\) & \(60.74 12.91\) & \(82.23 8.78\) \\
**A-Computers (35.76)** & \(50\%\) **Uniform noise** & \(19.68 6.59\) & \(19.02 5.02\) & \(23.49 6.44\) & \(13.36 2.89\) & \(15.27 5.00\) \\  & \(50\%\) **Pair Noise** & \(75.30 7.91\) & \(66.85 5.91\) & \(72.42 9.90\) & \(45.17 8.59\) & \(64.34 11.66\) \\
**Blogcatalog (66.11)** & \(50\%\) **Uniform noise** & \(29.13 9.95\) & \(27.73 13.31\) & \(24.23 16.14\) & \(7.93 2.97\) & \(31.67 9.33\) \\  & \(50\%\) **Pair Noise** & \(72.50 15.54\) & \(64.25 7.95\) & \(73.39 13.65\) & \(56.92 10.29\) & \(64.70 11.64\) \\   

Table 1: Misleading train accuracy of different methods under pair and uniform noise (10 Runs)

Figure 4: Time consumption and Test accuracy of different GLN methods on Cora and DBLP under \(30\%\) uniform noise (10 Runs).

(RQ6) Graph structure can amplify the negative effect of label noise.From the experimental results in Table 2, we observed that in the sparse graph (Cora), AUIS and AUU exhibit a significant decrease compared to AUCS. Taking the performance of GCN on the Cora dataset as an example, this decrease is \(36.17\%\) and \(10.85\%\), respectively. These results highlight the importance of proper supervision of neighboring nodes with correct annotations. Proper supervision of neighboring nodes with correct annotations significantly improves the classification accuracy of unlabeled nodes, while incorrect supervision of neighboring nodes severely reduces the classification accuracy of these nodes, even worse than when no neighborhood supervision is applied. Besides, our investigation also highlights the effectiveness of graph structure augmentation methods in mitigating the spread effect of label noise. According to Table 2, three methods, i.e. NRGNN, RTGNN, and RNCGLN, exhibit the smallest decrease in AUIS compared to AUCS and AUU among all methods. This indicates that they can effectively mitigate the spread effect of label noise. This phenomenon is even more pronounced in sparse graphs like Cora. One possible explanation can be easily drawn from the previous findings: The additional graph structure learning measures they adopted can lead to a denser graph structure used for predictions during the up-sampling process. Consequently, the classifier can rely on more references from the neighborhood, reducing its dependence on a small number of incorrectly labeled samples. Detailed experimental results are available in Appendix A.

(RQ6) Sparse graphs are more vulnerable to the spread effect of label noise.From Table 2 we see that the propagation effect of label noise can be very severe on sparse graphs with a relatively low average degree, like Cora, Citeseer, Pubmed, and DBLP, but not on dense graphs such as Amazon-Computers, Amazon-Photos, Blogcatalog and Flickr. The explanation for this observation is that unlabeled nodes on sparse graphs usually have only a limited number of annotated nodes in their neighborhood available for training. The prediction results of unlabeled nodes rely heavily on the annotated nodes in their neighborhood. However, if these nodes are incorrectly labeled, it will lead to erroneous learning of the embedding for the unlabeled nodes. In contrast, for dense graphs, the neighborhood of unlabeled nodes contains many annotated nodes that can serve as references. As a result, the classifier model is more likely to find correct supervision from these annotated nodes. This hypothesis is further supported by empirical evidence from Table 1, where we observe that compared to sparse graphs (such as Cora, Citeseer, and Pubmed), GCN is less susceptible to misleading on dense graphs like Blogcatalog and Amazon-Computers with a high average degree. Detailed experimental results are available in Appendix A.

## 5 Future directions

Based on the experimental results and analysis, we present several potential directions for the further development of the GLN.

**Designing widely applicable GLN approaches.** Our observations in finding (r) reveal that most existing GLN methods cannot ensure consistently high performance across all scenarios. To address this problem, we need to explore three key questions: 1) What are the common properties of different graph datasets? 2) How can these common properties be utilized to enhance the robustness of GNNs against label noise? Our finding (r) indicated that enhancing graph structures can reduce the spread of label noise in graphs with varying densities, leading to the third question: 3) If identifying common properties is challenging, can we unify these features through data augmentation?

**Designing GLN approaches for various graph learning tasks.** Previous studies on GLN have predominantly focused on node classification tasks. However, the field of graph learning includes

  
**Dataset (Avg. \# Degree)** & Records & GCN & NRGNN & RTGNN & CP & CLNode & RNCGLN \\   & **AUCS** & \(80.76 2.95\) & \(83.11 3.16\) & \(75.53 4.80\) & \(80.85 3.46\) & \(76.77 3.30\) & \(77.06 3.30\) \\  & **AUU** & \(71.99 3.44\) & \(81.33 2.25\) & \(73.44 4.95\) & \(72.32 4.45\) & \(67.11 5.11\) & \(75.36 3.33\) \\  & **AUUS** & \(51.55 6.53\) & \(78.81 5.94\) & \(69.50 8.06\) & \(51.46 12.99\) & \(43.86 7.48\) & \(72.92 4.66\) \\   & **AUCS** & \(92.21 2.44\) & \(85.62 2.96\) & \(89.98 2.10\) & \(90.74 2.98\) & \(93.08 1.97\) & \(75.71 6.59\) \\   & **AUU** & \(89.76 2.84\) & \(84.29 2.79\) & \(89.19 2.13\) & \(88.85 3.20\) & \(91.15 2.33\) & \(74.40 6.73\) \\   & **AUIS** & \(87.01 4.72\) & \(82.46 5.86\) & \(88.84 4.76\) & \(86.34 3.99\) & \(88.71 3.40\) & \(71.08 7.89\) \\   

Table 2: AUCS, AUU, AUIS of different methods on Cora and Amazon-Photos under \(30\%\) uniform noise (10 Runs)other important tasks such as link prediction, edge property prediction, and graph classification. However, there is limited work on graph classification  and graph transfer learning  in the presence of label noise. Overall, research in other areas of graph learning, beyond node classification, is still in its early stages, and warrants further attention and exploration.

**Considering other types of label noise in graph learning.** Previous studies of GLN have mainly focused on pair noise and uniform noise. These noise types are instance-independent, assuming that the label corruption process is conditionally independent of node features when the true labels are given . However, there exists another type of label noise--instance-dependent label noise--that is more realistic. In this case, the corruption probability depends on both the node features and the observed labels. However, none of the previous GLN studies have investigated this problem. Furthermore, unlike traditional machine learning tasks, graph learning involves additional graph structure, so the label noise model on graphs may also depend on graph topology. These issues are worth investigating, as they are more likely to occur in real-world scenarios.

## 6 Conclusions and Future work

In this research, we present NoisyGL, the first comprehensive benchmark designed for Graph Neural Networks under Label Noise (GLN) conditions. NoisyGL includes 7 prominent LLN and 10 GLN methods, allowing the community to fairly evaluate their effectiveness and robustness across various datasets. By using standardized backbones and APIs, consistent data splitting, and processing strategies, NoisyGL ensures a fair comparison and allows users to easily construct their own models or datasets with minimal effort. From this benchmark, we extract several key insights that are highly promising for the progression of this evolving field: Firstly, we point out that simply applying LLN methods cannot significantly improve the robustness of GNNs to label noise. Secondly, we found that existing GLN methods can alleviate label noise in their own applicable scenarios. In particular, pair noise emerges as the most harmful label noise due to its misleading effects. Finally, we discovered that negative effects of label noise can spread through the graph structure, especially in sparse graphs, and graph structure augmentation proves to be effective in mitigating the spread effect of label noise.

**Border Impacts and Limitations.** As NoisyGL provides a comprehensive benchmark for GNNs under label noise, we aim to attract more attention on the quality of graph data from the graph learning community, including the topology, node attributes and labels. However, NoisyGL also has some limitations that we aim to address in future work. Firstly, we aim to include a broader range of datasets to evaluate methods in different scenarios. While our current datasets are predominantly homogeneous graphs, we recognize that most GLN methods struggle with heterogeneous graphs, such as the Flickr network. Secondly, we hope to implement more GLN methods to gain a deeper understanding of the progress in the field. We will continuously update our repository to keep track of the latest advances in the field. We are also open to any suggestions and contributions that will improve the usability and effectiveness of our benchmark.

## 7 Acknowledgement

This work is supported by the National Natural Science Foundation of China (62106221, 62372408), Zhejiang Provincial Natural Science Foundation of China (Grant No: LTGG23F030005), Ningbo Natural Science Foundation (Grant No: 2022J183).