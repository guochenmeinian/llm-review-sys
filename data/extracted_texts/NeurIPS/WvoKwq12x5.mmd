# PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications

Dingkang Yang\({}^{1,3}\)\({}^{@paragraphsign}\) Jinjie Wei\({}^{1,3}\)\({}^{}\) Dongling Xiao\({}^{2}\)\({}^{}\) Shunli Wang\({}^{1}\)\({}^{@sectionsign}\) Tong Wu\({}^{2}\)\({}^{@sectionsign}\) Gang Li\({}^{2}\)\({}^{@sectionsign}\) Mingcheng Li\({}^{1}\)\({}^{@sectionsign}\) Shuaibing Wang\({}^{1}\)\({}^{@sectionsign}\) Jiawei Chen\({}^{1}\)\({}^{@sectionsign}\) Yue Jiang\({}^{1}\)

Qingyao Xu\({}^{1}\)\({}^{@sectionsign}\) Ke Li\({}^{2}\)\({}^{@sectionsign}\) Peng Zhai\({}^{1,3}\)\({}^{*}\) Lihua Zhang\({}^{1,3,4,5}\)

\({}^{1}\)Academy for Engineering and Technology, Fudan University, Shanghai, China

\({}^{2}\)Tencent Youtu Lab, Shanghai, China

\({}^{3}\)Cognition and Intelligent Technology Laboratory, Shanghai, China

\({}^{4}\)Engineering Research Center of AI and Robotics, Ministry of Education, Shanghai, China

\({}^{5}\)AI and Unmanned Systems Engineering Research Center of Jilin Province, Changchun, China

{dkyang20, pzhai, lihuazhang}@fudan.edu.cn

jjwei23@m.fudan.edu.cn, xdluestc@outlook.com

tristanli@tencent.com

Equal first contributions. Equal second contributions. Corresponding authors. Project lead.

###### Abstract

Developing intelligent pediatric consultation systems offers promising prospects for improving diagnostic efficiency, especially in China, where healthcare resources are scarce. Despite recent advances in Large Language Models (LLMs) for Chinese medicine, their performance is sub-optimal in pediatric applications due to inadequate instruction data and vulnerable training procedures. To address the above issues, this paper builds PedCorpus, a high-quality dataset of over 300,000 multi-task instructions from pediatric textbooks, guidelines, and knowledge graph resources to fulfil diverse diagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the first Chinese pediatric LLM assistant built on a systematic and robust training pipeline. In the continuous pre-training phase, we introduce a hybrid instruction pre-training mechanism to mitigate the internal-injected knowledge inconsistency of LLMs for medical domain adaptation. Immediately, the full-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the general medical knowledge schema into the models. After that, we devise a direct following preference optimization to enhance the generation of pediatric-like humanistic responses. In the parameter-efficient secondary SFT phase, a mixture of universal-specific experts strategy is presented to resolve the competency conflict between medical generalist and pediatric expertise mastery. Extensive results based on the metrics, GPT-4, and doctor evaluations on distinct downstream tasks show that PediatricsGPT consistently outperforms previous Chinese medical LLMs. The project and data will be released at https://github.com/ydk122024/PediatricsGPT.

## 1 Introduction

As an essential component of medicine, pediatrics plays an indispensable role in ensuring children's health growth . The unbalanced distribution of healthcare resources  has resulted in a massive shortage of pediatricians, especially in populous countries led by China . With therapid advances in LLMs exemplified by ChatGPT , developing intelligent pediatric consultation systems provides promise for enriching medical services. Although Chinese LLMs [18; 59; 2; 57; 20] have exhibited progress in general language understanding, they are incompetent in the pediatric medical field due to the lack of domain-specific discipline and specialized expertise injection.

To fulfil the interactive demands of Chinese medicine, preliminary efforts [8; 45; 50; 15] have enhanced LLMs' healthcare mastery through Supervised Fine-Tuning (SFT) training and medically relevant corpus collection. Despite improvements, challenges remain due to unavoidable dilemmas, including inadequate instruction data and vulnerable training procedures. Specifically, (i) existing instruction data typically involve vanilla rephrasing of the general medical corpus  or aggregation of doctor-like dialogues , which loses the specialization and focus in pediatric applications. More importantly, the current straightforward different round instruction construction paradigms [58; 15] fail to accommodate multi-task healthcare services in real-world scenarios, limiting the model generalization and inducing response hallucination. (ii) Furthermore, prior methods mostly relied on SFT to compensate for medical instruction following capabilities, ignoring the discrepancies between inherent and externally absorbed knowledge within the models. This single pattern causes secondary LLMs to lapse into excessive role-playing rather than understanding . Despite a few attempts in the pre-training and Reinforcement Learning from Human Feedback (RLHF) phases [7; 34], their performance is restricted by actor-critic instability  and online sampling bias .

Motivated by these observations, we construct PedCorpus, a high-quality dataset with over 300,000 instructions across single-turn and multi-turn medical conversations. Besides containing generalist healthcare data, PedCorpus incorporates multi-dimensional corpora from pediatric textbooks, guidelines, and knowledge graphs to ensure medical knowledge's accuracy. Vanilla instructions can also be readily extended to seed instructions for generating specialized corpora to serve different training phases. Furthermore, we integrate the well-presented GPT-4-distilled data with authentic doctor-patient dialogue data to standardize the fluency and faithfulness of instruction information.

Among our PedCorpus, we propose PediatricGPT, the first Chinese pediatric LLM assistant with pediatric expertise and medical generalist. PediatricGPT is developed on a systematic training pipeline that includes Continuous Pre-Training (CPT), full-parameter SFT, human preference alignment, and parameter-efficient secondary SFT. In this case, we introduce a hybrid instruction pre-training mechanism in CPT to bridge the capability weakening due to corpus format discrepancies between the internal and injected medical knowledge of foundation models, facilitating knowledge accumulation and extension. Meanwhile, a Direct Following Preference Optimization (DFPO) in human preference alignment is devised to enhance response robustness and align human preferences. Additionally, we present a mixture of universal-specific experts strategy to tackle the competency conflict between medical generalist and pediatric expertise in secondary SFT via Low-Rank Adaptation (LoRA) , which strengthens the model's adaptability to distinct downstream tasks. We conduct three pragmatic pediatric tasks to evaluate the different capabilities of existing models. Extensive experiments on pediatric and public benchmarks show that our PediatricsGPT outperforms open-source Chinese medical LLMs and baselines, yielding competitive performance compared to GPT-3.5-turbo.

## 2 Related Work

**Chinese Large Language Model Evolution.** The emergence of Large Language Models (LLMs) dominated by ChatGPT  and GPT-4  has revolutionized the paradigm for novel human-machine interaction. Driven by learning-oriented technologies [11; 12; 13; 53; 54; 48], pragmatic instruction [32; 47] and preference optimization [7; 34] strategies enable LLMs to address complex generation tasks with aligned human intentions. Despite improvements, large-scale resources for training general LLMs [28; 43; 44] are anchored in the English corpora, limiting their abilities to respond reliably in extensive Chinese application scenarios. Recently, researchers [18; 59] have attempted to enhance the comprehension and execution of Chinese instructions in open-source LLMs by augmenting Chinese vocabulary and data (_e.g.,_ Chinese LLaMA and Alpaca ). To facilitate Chinese-specific demands, several LLMs trained from scratch exhibit remarkable Chinese proficiency due to multilingual data resources, such as the Baichuan [2; 52], General Language Model (GLM) [20; 57], and Qwen  families. In this work, the Baichuan2-Base series is utilized as the foundation model for our PediatricsGPT, given its comprehensive potential among similar contenders.

**LLMs in Medical Applications.** Current LLMs provide unprecedented opportunities to develop resource-efficient and diagnostic-comprehensive intelligent healthcare systems. Despite universal models [5; 33] equipped with certain internal knowledge regarding biomedicine, they are incompetent in real-world medical applications due to the absence of domain-specific disciplines. In this context, several efforts [45; 50; 15; 30] attempt to construct medically tailored LLMs from multiple perspectives. For instance, ChatDoctor  uses patient-doctor conversation data based on LLaMA  to enhance the language model's accuracy in healthcare. DoctorGLM  proves that a healthcare-purpose LLM can be implemented with affordable overhead by fine-tuning ChatGLM-6B . After that, more Chinese medical LLMs [51; 8; 58; 14; 56] are progressively presented to generate doctor-like robust responses, such as HuatuoGPT , DISC-MedLLM , and Zhongqing . Despite advances in general medical knowledge, current models are suboptimal for pressing pediatric applications. In comparison, our sophisticated training procedure and high-quality instruction datasets inject new insights and prospects for developing specialized LLMs with pediatric expertise.

## 3 Methodology

This section describes the proposed PedCorpus dataset and the sequential pipeline for developing PediatricsGPT. Figure 1 illustrates the comprehensive method workflow.

### PedCorpus: Multi-task Medical Instruction Dataset

To endow the model with versatile diagnostic proficiency, PedCorpus is constructed through the multi-dimensional corpus across three application-oriented medical tasks, including Knowledge Question-Answer (MedKQ&A), Evidence-based Diagnosis (EviDiag), and Treatment Recommendation (TreRecom). Table 1 shows the detailed statistical information from different data sources. We explain the three patterns of PedCorpus construction below.

**Specialized Pediatric Data.** Extracting pediatric data from textbooks, guidelines, and knowledge graphs ensures knowledge professionalism. Specifically, we automatically extract standard medical definitions and descriptions from physical textbooks covering 131 disease types in 11 broad categories. Over 500 corresponding disease guidelines are collected, including diagnostic protocols and treatment consensus. Additionally, extensive knowledge entities are sampled from ternary instances in the knowledge graphs. Based on these resources, we introduce a role-playing-driven instruction building rule via GPT-4 API that produces well-organized instructions to enable **accurate** and **humanistic** model responses. The detailed building procedure is shown in Appendix A.1.

**Real Doctor-patient Conversations.** To avoid the model collapse dilemma , we incorporate authentic doctor-patient dialogues from online treatment platforms and voice transcriptions during medical consultations. The single-/multi-turn instructions are jointly considered to equip the model with healthcare interrogation and contextual understanding. Original responses from real doctors are usually terse and noisy, potentially worsening the generation quality . To this end, we craft 100 high-quality examples to guide the advanced language model by the in-context learning to regularize vanilla conversations in the self-instruct pattern [17; 46]. This approach ensures **doctor-like** and **patient-friendly** model responses. More regularization details are shown in Appendix A.2.

**Distilled Medical Datasets.** Integrating general medical knowledge from existing datasets [29; 26; 60] is a common practice in previous efforts [15; 50; 51; 8]. However, we find numerous unclear and incomplete representations in the instruction instances from public benchmarks due to the absence of careful calibration, potentially triggering hallucinated outputs. Consequently, we manually sample

    &  &  &  &  &  \\   & & & Preference & & MedKQ\&A & EviDiag & TreeRecom \\   & Pediatric Textbooks & Pediatrics & 37,284 & ✔ & ✔ & – & ✔ \\  & Pediatric Guidelines & Pediatrics & 63,129 & ✔ & ✔ & – & ✔ \\  & Pediatric KG & Pediatrics & 46,320 & ✔ & ✔ & – & ✔ \\  & Real Doctor-Patient Conversations & Multiple & 46,385 & ✔ & – & ✔ & ✔ \\  & Distilled Medical Datasets & Multiple & 107,177 & – & ✔ & ✔ & ✔ \\   & Plain Textbooks, Guidelines, KG & Multiple & – & ✔ & ✔ & ✔ \\  & Filtered Chinese Wikipedia & Multiple & 975.8MB & – & – & – & – \\  & Extended data from PedCorpus & Multiple & – & – & – & – \\  PedCorpus-DFPO & Pediatrics data from PedCorpus & Pediatrics & 15,556 & ✔ & ✔ & ✔ & ✔ \\   

Table 1: Statistical information on the proposed dataset. PedCorpus is well extensible and adaptable by incorporating general domain data and as seed instructions to generate specialized corpora (_i.e.,_ PedCorpus-CPT and PedCorpus-DFPO). “KG” means the Knowledge Graphs.

107,177 knowledge-intensive instructions from three mainstream benchmarks (_i.e.,_ Huatuo-26M , MedDialog , and CMeKG ), adhering to the philosophy of quality over quantity . After that, a progressive instruction reconstruction rule is proposed to distill the sampled instructions to ensure **informative** and **logical** model responses. The rule process can be found in Appendix A.3.

### Hybrid Instruction Pre-training in CPT

Continuous Pre-Training (CPT) is essential in developing domain-specific models [14; 49; 56] since it can break the scaling law  to a certain extent. For this purpose, we introduce the PedCorpus-CPT dataset to ensure a high-quality pre-training corpus. From Table 1, PedCorpus-CPT consists of three-part data components. (i) We integrate plain texts from vanilla pediatric textbooks, guidelines, and knowledge graphs. (ii) The filtered Chinese Wikipedia  is also considered to achieve the model's trade-off for medical-general knowledge memory capacity. (iii) In practice, we observe that CPT leads to catastrophic forgetting of the models at follow-up due to different data distribution and format discrepancies compared to the original pre-training and SFT. Thus, we introduce a hybrid instruction pre-training mechanism to bridge these discrepancies. The core philosophy is to assemble instruction data from PedCorpus with Input-Output forms into Completion forms, which are then assimilated into plain texts to provide multi-task and complementary information. This mechanism effectively mitigates inconsistencies between the internal-injected medical knowledge of the foundation model while reinforcing medical domain adaptation. Moreover, we take PedCorpus as the seed instructions to improve multiple-department corpus density and breadth via knowledge-enhanced prompts. The prompt template is shown in Appendix B.

We pre-train the foundation model to follow the causal language modelling paradigm. Given any input token sequence \(=(t_{0},t_{1},t_{2},...)_{cpt}\) from the above multi-channel corpus \(_{cpt}\), the next token \(t_{i}\) is autoregressively predicted by minimizing the negative log-likelihood:

\[_{}(,_{cpt})=_{ _{cpt}}[-_{i}^{||}\! p(t_{i} t _{0},t_{1},...,t_{i-1};)],\] (1)

where \(\) is the model parameter and the input context consists of \(t_{0},t_{1},...,t_{i-1}\).

### Full-parameter Supervised Fine-tuning

During this phase, we activate the model's ability to follow medical instructions by the Full-parameter Supervised Fine-tuning (FSFT). The full-parameter pattern enables a fuller invocation of the intensive knowledge in CPT and promotes comprehension and logical reasoning about diverse structured instructions. The training data at this phase is composed of the following three aspects. (i) We utilize the multi-department medical data in the PedCorpus dataset to develop the medical generalist. (ii)

Figure 1: The sequential pipeline for developing PediatricsGPT. We begin by injecting intensive medical and world knowledge into the foundation model through the hybrid instruction mechanism in CPT phase. Then, full-parameter SFT is implemented to improve the model’s instruction-following capabilities regarding medical generalists. After that, we introduce the direct following preference optimization to control the model behaviour to align with human preference. In the parameter-efficient SFT phase, the LoRA-based mixture of universal-specific experts is devised to mitigate conflicts across downstream tasks and competition between pediatric expertise and general mastery.

Chinese instruction data (_i.e.,_ Alpaca dataset  and ShareGPT ) from general domains are selectively integrated to avoid the potential overfitting risk. (iii) Providing safety measures is vital for LLM assistants yet overlooked by prior methods . In contrast, we write 200 training instructions with some degree of maliciousness, hallucinations, and counterfactuals. Correspondingly, the refusal responses with detailed explanations for disobedience are carefully crafted. We also include 300 examples related to self-cognition content. These data significantly improve the robustness and security of the model against unfriendly commands.

Given any input instruction \(=(x_{0},x_{1},x_{2},...)_{fsft}\) and corresponding target response \(=(y_{0},y_{1},y_{2},...)_{fsft}\) from the above-integrated fine-tuning dataset \(_{fsft}\), the optimization objective can be formulated as follows:

\[_{}(,_{fsft})=_{(, )_{fsft}}[-|}{}_{i=1}^{||} \,p(y_{i},y_{<i};)].\] (2)

### Direct Following Preference Optimization

Aligning human intention preferences facilitates the model to generate harmless responses. To this end, we introduce PedCorpus-DFPO \(_{dfpo}\), a preference dataset to guide the model in learning human preference behaviours. PedCorpus-DFPO contains the input instruction set \(=(x_{0},x_{1},x_{2},...)_{dfpo}\), which is selectively sampled from vanilla PedCorpus. On the one hand, we perform a humanistic stylistic rephrasing of the outputs to generate preferred responses \(^{w}=(y_{0}^{w},y_{1}^{w},y_{2}^{w},...)_{dfpo}\). On the other hand, the corresponding low responses \(^{l}=(y_{0}^{l},y_{1}^{l},y_{2}^{l},...)_{dfpo}\) are generated from the feedback of a low-capability medical assistant  to maintain domain consistency.

Despite impressive improvements achieved by RLHF-based approaches [56; 58], challenges remain due to unstable reward modelling and significant computational costs [41; 61]. Inspired by single-stage preference learning , we propose a stable and lightweight method for domain-specific LLMs called Direct Following Preference Optimization (DFPO). DFPO utilizes variable changes to formulate the preference loss as a policy function that efficiently optimizes the policy with a simple binary cross-entropy objective. Meanwhile, our method directly regularizes model behaviour boundaries in an instruction-following paradigm on medical demonstrations of preferred responses, facilitating robustness and smoothing of the preference learning.

Theoretically, the observed probability of a particular preference pair usually follows the Bradley-Terry model , and \(^{w}\) is preferred over \(^{l}\) (denoted \(^{w}^{l}\)):

\[p(^{w}^{l})=((,^{w})-(, ^{l})),\] (3)

where \((,^{w/l})\) means the parameterized reward function and \(()\) is the sigmoid activation. In this case, the overall optimization objective is expressed as:

\[_{}(,_{dfpo})=-_{(, ^{w},^{l})_{dfpo}}[\,( \,(^{w})}{_{r}(^{w })}-\,(^{l})}{ _{r}(^{l})})]+(,^{w}),\] (4)

where \(_{}\) and \(_{r}\) are the desired optimal policy and the reference policy, respectively. \(\) is the control parameter reflecting the deviation from the basic \(_{r}\). For the fine-tuning regularization term \((,^{w})\) with the scaling coefficient \(\), the implementation process is equivalent to maximizing the log probability \(p(^{w})\) regarding the preferred responses \(^{w}\) given the input instructions \(\):

\[(,^{w})=_{(,^{w})_{dfpo}} [-^{w}|}{}_{i=1}^{|^{w}|}\,p(y_{i} ^{w},y_{<i}^{w};)].\] (5)

### Mixture of Universal-specific Experts in Parameter-efficient SFT

This phase aims to reinforce the model performance for various pediatric applications through the LoRA-based Parameter-efficient SFT (PSFT). The used dataset \(_{psft}\) is derived from the pediatric department in PedCorpus and partial general medical/world data. In practice, we observe that competition across different pediatric tasks and the conflicts between medical generalization and specialized knowledge deteriorate instruction-following abilities. Accordingly, we propose a mixture of universal-specific experts strategy to address these challenges. Formally, LoRA adapters  act as experts to replace the linear layers in the Feed-Forward Neural (FFN) networks of LLMs, providing trainable parameters. Several specific experts \(\{E_{j}^{s}\}_{j=1}^{T}\) are assigned adaptive activations to master distinct pediatric expertise through soft routing. The routing gating is defined as follows:

\[G()=(_{g}+((_{n} )).\] (6)

\(_{g}\) and \(_{n}\) are the learnable weights. \(((_{n})\) is the noise term for regularizing the expert utilization balance, where \(()\) and \(()\) represent the Standard Normal distribution sampling and Softplus function, respectively. Moreover, we consistently activate a universal expert \(E^{u}\) across all training data to prevent general knowledge forgetting and mitigate competency conflict. The parameterized output \(\) of all the experts in the forward process can be mathematized as follows:

\[=(_{j=1}^{T}\!G()_{j}E_{j}^{s}()+E^{u}( )),\] (7)

where \(r\) is the rank value and \(\) is a hyper-parameter for approximating the learning rate.

## 4 Experiments

### Datasets and Implementation Details

Extensive experiments are conducted on three application-oriented benchmarks to assess the model's pediatric medical abilities, including Knowledge Question-Answer (**MedKQ&A**), Evidence-based Diagnosis (**EviDiag**), and Treatment Recommendation (**TreRecom**). Each benchmark contains 300 held-out samples to reject data leakage during training. In addition, we select two publicly available Chinese medical benchmarks to validate the model's generalizability in general healthcare. Specifically, we sample 50 challenging instances of diagnostic queries from each department from the **webMedQA** and **CMD** benchmarks, respectively, leading to testing sets with 300 samples.

Our PediatricsGPT is developed upon the Baichuan2-Base  models in two versions with 7 and 13 billion parameters. The model training is accomplished through the PyTorch platform with Accelerate

   Benchmark & Model & ROUGE-1 & ROUGE-2 & ROUGE-L & BLEU-1 & BLEU-2 & BLEU-3 & BLEU-4 & BLEU & Distinct-1 & Distinct-2 \\   &  & 19.44 & 21.50 & 26.77 & 20.00 & 17.30 & 14.86 & 24.88 & 20.14 & 39.95 \\  & Baichuan2-13B & 46.96 & 22.85 & 22.54 & 29.02 & 22.56 & 22.63 & 19.31 & 27.97 & 21.45 & 42.53 \\  & HuatuoGPT & 48.82 & 23.44 & 25.13 & 43.00 & 41.25 & 36.91 & 29.82 & 34.60 & 20.42 & 41.27 \\  & DSC-MedLMM & 53.83 & 25.98 & 27.71 & 47.91 & 44.57 & 37.65 & 30.07 & 37.11 & 26.63 & 51.98 \\  & Zhongjing & 53.97 & 26.03 & 29.56 & 51.11 & 45.04 & 39.13 & 33.59 & 42.61 & **26.75** & **52.66** \\  & HuatuoGPT-II & 55.27 & 26.59 & 27.95 & 59.07 & 51.49 & 45.38 & 38.70 & 39.18 & 20.97 & 41.34 \\  & Meditron-7B & 55.63 & 26.19 & 30.37 & 58.43 & 53.45 & 56.07 & 38.77 & 42.23 & 22.34 & 45.17 \\  & Llama1-31-8B & 53.18 & 24.74 & 28.26 & 45.07 & 42.45 & 36.57 & 29.73 & 35.63 & 22.74 & 46.52 \\  & ChaqPT & 56.92 & 27.87 & 29.05 & 61.58 & 54.37 & 47.97 & 40.77 & 45.15 & 20.76 & 40.19 \\  & GPT-4 & 58.79 & 33.56 & 32.15 & **62.53** & 59.14 & 55.26 & 52.39 & 53.72 & 21.79 & 43.26 \\  & PediatricsGPT-TB & 58.08 & 31.78 & 31.11 & 59.41 & 56.88 & 57.47 & 55.34 & 54.41 & 24.33 & 47.41 \\  & PediatricsGPT-13B & **60.88** & **36.56** & **35.64** & 61.65 & **63.17** & **58.96** & **59.34** & **57.22** & 24.24 & 46.23 \\   & Baichuan2-7B & 26.81 & 7.75 & 11.22 & 15.18 & 11.51 & 9.19 & 6.73 & 13.44 & 23.65 & 46.93 \\  & Baichuan2-13B & 39.14 & 12.06 & 12.44 & 47.65 & 36.02 & 28.82 & 21.19 & 28.28 & 25.45 & 50.43 \\  & HuatuoGPT & 35.12 & 10.77 & 15.04 & 46.22 & 33.10 & 25.44 & 21.22 & 25.54 & 22.30 & 45.73 \\  & DISC-MedLMM & 33.55 & 11.67 & 15.32 & 15.91 & 21.46 & 10.27 & 7.96 & 16.77 & **35.89** & **69.36** \\  & Zhongjing & 40.92 & 14.26 & 17.41 & 48.64 & 37.52 & 30.17 & 22.44 & 27.03 & 33.40 & 65.89 \\  & HuatuoGPT-II & 39.52 & 12.14 & 16.38 & 49.58 & 37.62 & 30.66 & 23.34 & 28.98 & 21.97 & 43.62 \\  & Meditron-7B & 42.63 & 15.12 & 18.94 & 52.36 & 39.24 & 37.78 & 27.15 & 31.25 & 22.07 & 45.13 \\  & Llama3-1.88 & 37.25 & 13.07 & 16.23 & 44.54 & 32.29 & 37.72 & 20.12 & 23.57 & 24.43 & 45.67 \\  & ChaqPT & 40.88 & 13.42 & 16.97 & 48.84 & 37.69 & 30.55 & 23.17 & 29.02 & 43.49 & 46.54 \\  & GPT-4 & **48.48** & 16.74 & 21.51 & 57.59 & 44.78 & 37.94 & 30.56 & 36.79 & 25.69 & 50.13 \\  & PediatricsGPT-TP & 45.83 & 16.60 & 19.91 & 54.37 & 41.99 & 37.59 & 29.03 & 33.42 & 23.49 & 46.61 \\  & PediatricsGPT-13B & 47.32 & **17.63** & **21.87** & **58.21** & **45.72** & 39.74 & **31.25** & **37.15** & 23.34 & 46.34 \\   & Baichuan2-7B & 48.39 & 23.07 & 26.35 & 47.94 & 40.91 & 35.54 & 29.69 & 35.06 & 21.90 & 43.57 \\  & Baichuan2-13B & 48.87 & 23.41 & 26.42 & 49.96 & 46.24 & 42.84 & 35.04 & 35.63 & 22.36 & 45.12 \\   & HuatuoGPT & 53.48 & 25.41 & 27.08 & 58.14 & 49.64 & 42.93 & 35.16 & 41.63 & 23.26 & 46.21 \\   & Disco-MedLMM & 52.77 & 24.26 & 28.89 & 58.73 & 50.05 & 42.96 & 35.59 & 42.44 & 24.30 & 51.95 \\   & Zhongjing & 54.92 & 26.63 & 29.68 & 60.12 & 53.31 & 44.25 & 38.76 & 40.38 & 26.18 & 53.94 \\   & HuatuoGPT-II & 58.44 & 30.47 & 32.02 & 59.91 & 54.26 & 45.73 & 38.92 & 42.28 & 28.88 & 57.15 \\   & Meditron-7B & 58.56 & 32and DeepSpeed packages using eight Nvidia A800 GPUs. The ZeRO strategy  is employed to alleviate the memory overhead during full parameter training. The AdamW optimizer  is adopted for network optimization, and the bf16 data accuracy is chosen. More detailed hyper-parameter configurations for different stages are shown in Appendix C.

### Model Zoo

We compare a series of LLMs for comprehensive evaluations. Concretely, **Baichuan2-7B/13B (Chat)** models  are trained on 2.6 trillion tokens as the baselines, which have excellent abilities in different domains. **Meditron-7B** is a 7 billion parameters model adapted to the medical domain from Llama2-7B through continued pre-training on a comprehensively curated medical corpus. **Llama3.1-8B** is a robust multilingual large language model through systematic training. For reproducible Chinese medical works, **DISC-MedLLM (13B)** is fine-tuned through reconstructed medical dialogues and behavioural preference instructions. **HuatuoGPT (13B)** performs SFT based on mixed instruction data and introduce human feedback in RLHF. **HuatuoGPT-II (13B)** enhances the medical-specific domain adaptation of LLMs through one-stage unified training. **Zhongjing (13B)** implements a complete pipeline based on Ziya-LLaMA-13B to enhance the model's multi-turn medical conversation abilities. **ChatGPT** and **GPT-4** have impressive performance in general medical fields as closed-source models developed by OpenAI.

### Comparison with State-of-the-art Methods

**Metrics-based Evaluation.** In Table 2, we present the comparison results of different models on three pediatric benchmarks through multifaceted metrics, including ROUGE-1/2/L, BLEU-1/2/3/4, GLEU, and Distinct-1/2. The key observations are listed below. (i) PediatricsGPT-13B significantly outperforms the baselines and SOTA medical models on the vast majority of metrics across all benchmarks, demonstrating excellent pediatric expertise. (ii) Our 7B version also achieves competitive results compared to the 13B models. For instance, PediatricsGPT-7B yields absolute improvements of 3.53% and 4.44% on metrics ROUGE-L and GLEU in the EviDiag task compared to HuatuoGPT-II, respectively, generating more accurate and informative content. (iii) By contrast to Zhongjing and HuatuoGPT-II with massive training corpora, our method confirms that the training data quality outweighs quantity for performance gains. (iv) The worst results at baselines emphasize that target-oriented fine-tuning is an effective strategy for improving domain-specific abilities.

**Automated GPT-4 Evaluation.** Measuring model performance from multiple aspects is essential in the pediatric medical domain. To this end, we consider four dimensions to holistically assess response quality, including _usefulness_, _correctness_, _consistency_, and _smoothness_. Advanced GPT-4  is prompted to select the winning response between pairwise models based on these dimensions. The

Figure 3: Response comparisons of PediatricsGPT-13B with other baselines via Doctor evaluation.

Figure 2: Response comparisons of PediatricsGPT-13B with other baselines via GPT-4 evaluation.

dimension explanations and the prompt template for GPT-4 can be found in Appendix D. (i) As Figure 2 shows, PediatricsGPT-13B wins all LLMs by large margins in the MedKQ&A task, implying the necessity of implementing the knowledge-intensive CPT. (ii) The favourable win rates on the TreRecom and EviDiag tasks compared to medical LLMs show the superiority of our model in both single-turn treatment recommendations and multi-turn medical diagnostics. For example, our model beats Zhongjing via the 59% win rate on the EviDiag, which specializes in multi-round consultations.

**Manual Doctor Evaluation.** Doctor approval of LLM assistants is a vital step toward realistic applications. We invite three doctors (each paid $300) to determine the winner of pairwise models by the majority voting rule. The evaluation requires simultaneous consideration of the responses' _professionalism_, _factuality_, and _safety_. (i) Excluding ChatGPT, the dominance of our model in Figure 3 shows the effectiveness of considering safety measure data while incorporating specialized pediatric knowledge. (ii) The proposed direct following preference optimization makes PediatricsGPT-13B more favoured by human preferences compared to other behavioural alignment efforts [8; 56; 58]. (iii) The competitive performance of ChatGPT when human judgments indicate that the scaling law still holds, stemming from the high agreement between its behaviours and human intentions.

**Generalization Ability Evaluation.** We show the GLEU metric-based scores of different models on the Chinese medical benchmarks in Figure 4 for CMD and Figure 5 for webMedQA. (i) PediatricsGPT-13B achieves impressive results across diverse medical departments (including pediatrics), exhibiting medical generalist and pediatric competency mastery. (ii) The 7B counterpart similarly outperforms most 13B Chinese medical LLMs and exceeds ChatGPT in some departments. For instance, PediatricsGPT-7B brings relative gains of 18.8% and 7.1% compared to ChatGPT in the Gynecology and Oncology tasks on the CMD benchmark. These findings confirm the robust generalization of our model and its ability to capture the multifaceted medical dialogue distributions.

### Ablation Studies

We perform thorough ablation studies on five medical benchmarks to investigate the effects of different modelling components. Following , we compare the responses from each of the proposed model variants with ChatGPT, and then calculate the win rate (%) of our model in pairwise responses by GPT-4 and doctor evaluations. Table 3 shows the following observations.

**Importance of Continuous Pre-training.** Firstly, we remove the complete continuous pre-training phase to observe performance variations. (i) The significantly deteriorated win rates reveal that

Figure 4: Comparison results of different models on the CMD benchmark.

Figure 5: Comparison results of different models on the webMedQA benchmark.

injecting specialized knowledge into medical LLMs through rich corpora is indispensable. (ii) Meanwhile, our hybrid instruction pre-training mechanism provides valuable gains to the model.

**Necessity of Supervised Fine-tuning.**

(i) We observe consistent performance gaps when removing the Full-parameter SFT (FSFT) and Parameter-efficient SFT (PSFT) phases, respectively. This makes sense since SFTs are necessary to activate the model's healthcare instruction-following capabilities. (ii) Moreover, PSFT is more critical for three pediatric applications because it facilitates pediatric-related knowledge accumulation, while FSFT focuses on consolidating general medical semantic representations. (iii) Then, we replace the proposed Mixture of Universal-specific Experts (MUE) version with the vanilla single LoRA. The reduced performance on pediatric EviDiag and TreRecom benchmarks verifies that it is essential to introduce multiple LoRAs that act as specific experts on different tasks. A reasonable explanation is that the single-LoRA model suffers from the task competition between learning the knowledge question-answer and mastering the diagnostic recommendation abilities. (iv) Furthermore, we find that the universal LoRA expert significantly improves the results on the general medical benchmarks (_i.e._, CMD and webMedQA), proving that it mitigates the competency conflict between general medical and pediatric knowledge.

**Effectiveness of Preference Alignment.** (i) When the Direct Following Preference Optimization (DFPO) phase is removed, the model exhibits significant performance drops in doctor evaluations compared to the full version. This observation proves that DFPO effectively helps the model to align human preferences, reducing harmful content while generating doctor-like output. (ii) As two candidates, the vanilla DPO and RLHF methods are inferior to the proposed DFPO, suggesting that our strategy can more safely control model behaviour, leading to more favoured humanistic responses.

### Qualitative Analysis of LoRA Experts

**Effect of Specific Expert Numbers.** As a complement to the ablation of LoRA experts, Figure 6(a) explores the gain effects of varying the number of specific experts while maintaining the universal expert. (i) Noticeably, our MCE strategy with three specific experts achieves a reasonable performance trade-off across the three tasks with only 0.95% trainable parameters. (ii) Conversely, excessively introducing LoRA experts does not result in appreciable gains but increases the training overhead.

    &  & EviDiag & TreRecom &  &  \\   & GPT-4 & Doctor & GPT-4 & Doctor & GPT-4 & Doctor & GPT-4 & Doctor & GPT-4 & Doctor \\ 
**Full Model** & **68\%** & **56\%** & **54\%** & **44\%** & **58\%** & **38\%** & **46\%** & **40\%** & **53\%** & **45\%** \\   \\  w/o Continuous Pre-training & 61\% & 50\% & 46\% & 39\% & 51\% & 31\% & 39\% & 33\% & 47\% & 38\% \\ w/o Hybrid Instruction Pre-training & 67\% & 54\% & 52\% & 43\% & 57\% & 36\% & 44\% & 38\% & 52\% & 43\% \\   \\  w/o Full-parameter SFT & 65\% & 53\% & 50\% & 42\% & 55\% & 36\% & 42\% & 36\% & 49\% & 41\% \\ w/o Parameter-efficient SFT & 63\% & 51\% & 49\% & 40\% & 53\% & 34\% & 45\% & 39\% & 51\% & 43\% \\ w/o MUE Strategy & 67\% & **57\%** & 52\% & 43\% & 56\% & 36\% & 43\% & 37\% & 50\% & 42\% \\ w/o Universal Expert & 67\% & **56\%** & 53\% & **44\%** & 57\% & 37\% & 44\% & 38\% & 51\% & 42\% \\   \\  w/o DFPO & 67\% & 53\% & 52\% & 41\% & 57\% & 36\% & 45\% & 38\% & 51\% & 41\% \\ w/ Vanilla DPO & 66\% & 55\% & 53\% & 42\% & 57\% & 36\% & 44\% & 38\% & 52\% & 42\% \\ w/ RLHF & 67\% & 55\% & **54\%** & 43\% & 57\% & 37\% & 45\% & 39\% & 52\% & 44\% \\   

Table 3: Ablation study results on five medical benchmarks. “w/” and “w/o” are short for with and without, respectively. “MUE” means the Mixture of Universal-specific Experts strategy.

Figure 6: (a) and (b) show the effect of specific expert numbers on model performance and specific expert utilization in different task data, respectively.

**Analysis of Expert Utilization.** To confirm the duties of specific LoRA experts in the routing process, we visualize the normalized weights assigned by the routing gating when encountering data from different downstream tasks. CMD and webMedQA data are merged to compose general healthcare data. From Figure 6(b), (i) Experts 2 and 3 are emphatically activated on the TreRecom and MedKQ&A tasks, respectively, implying their focal ability to tackle medical knowledge interpretations and treatment recommendations. (ii) In contrast, Expert 1 is more proficient at learning multi-turn diagnosis semantics in the EviDiag task, which is different from the other tasks of instruction content. (iii) Additionally, there is no clear difference in the specific expert utilization on general healthcare, implying that the general task is handled by the consistently universal expert. The above observations demonstrate the effectiveness and necessity of the proposed MCE strategy.

### Visualization Analysis of Model Responses

To intuitively compare the output quality of medical LLMs, we show the responses of different models for each of the three types of medical inquiries in Figures 13&14&15 from Appendix E. From the results, Zhongjing offers insufficient information due to limited output content. Although HautoGPT-II gives well-organized responses, it lacks accuracy and informativeness. In comparison, our model can provide more specialized and detailed medical knowledge and diagnostic guidance in extended response contexts, confirming its application potential in diverse healthcare services.

## 5 Conclusion and Discussion

This paper presents PediatricsGPT, a Chinese medical LLM assistant with medical generalist and pediatric expertise capabilities. Based on the well-designed PedCorpus dataset, PediatricsGPT undergoes a systematic and robust procedure ranging from continuous pre-training and supervised fine-tuning to human preference optimization, leading to competence in different pediatric and general healthcare service scenarios. Extensive experimental results under multi-dimensional evaluation patterns demonstrate that our model outperforms currently available Chinese medical LLMs, providing a potential solution for promoting reliable and intelligent interactive diagnosis and treatment.

**Broader Impacts.** (i) Our model has made meaningful contributions to pediatric medicine by integrating extensive medical data and emerging research. This integration facilitates more accurate and expedited diagnosis of complex pediatric conditions and aids in predicting treatment outcomes, enabling highly personalized and effective treatment strategies for young patients. (ii) The proposed PediatricsGPT provides crucial decision support for medical professionals, giving evidence-based recommendations and specialized medical insights. Additionally, it democratizes access to expert medical suggestions and accurate medical knowledge, empowering parents and caregivers with accurate health information, which is especially crucial in underserved areas. (iii) The training pipeline of PediatricsGPT showcases exemplary generalizability, designed to be applicable across various medical and non-medical domains. This adaptability broadens the model's applicability and pioneers the development of future AI solutions in healthcare and other fields.

**Limitations.** (i) When deployed online, the proposed PediatricsGPT model, like other Large Language Models (LLMs), faces significant security risks, particularly from attacks aimed at manipulating its outputs. These attacks can be strategically designed to exploit the model's response mechanisms, allowing attackers to induce the model to generate unsafe, biased, or otherwise inappropriate content. (ii) Currently, our PediatricsGPT model does not support all languages. This linguistic barrier can prevent the model from reaching a global audience, particularly in diverse linguistic landscapes where localized medical information is crucial.

**Ethical Issues.** We fully recognize the critical importance of privacy and data protection. All data used has been meticulously de-identified, with all sensitive information removed, and this process has been verified by the partnering medical institutions. For the public databases, we strictly follow specific license agreements for use and adaptation. For the constructed corpus, we underwent an internal ethical review by the ethical review board of the partnering medical institutions with license and approval. We will release relevant resources to the extent that they are controlled and permitted.

We provide more discussions of the future work in Appendix F.

**Acknowledgment.** This work is supported in part by the National Key R&D Program of China under Grant 2021ZD0113502, in part by the Shanghai Municipal Science and Technology Major Project under Grant 2021SHZDZX0103.