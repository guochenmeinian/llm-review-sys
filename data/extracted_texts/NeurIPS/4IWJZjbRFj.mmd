# Removing Hidden Confounding in Recommendation:

A Unified Multi-Task Learning Approach

 Haoxuan Li\({}^{1}\), Kunhan Wu\({}^{2}\), Chunyuan Zheng\({}^{3}\), Yanghao Xiao\({}^{4}\),

**Hao Wang\({}^{5}\), Zhi Geng\({}^{6}\), Fuli Feng\({}^{7}\), Xiangnan He\({}^{7}\), Peng Wu\({}^{6,}\)**

\({}^{1}\)Peking University \({}^{2}\)Carnegie Mellon University \({}^{3}\)University of California, San Diego

\({}^{4}\)University of Chinese Academy of Sciences \({}^{5}\)Zhejiang University

\({}^{6}\)Beijing Technology and Business University \({}^{7}\)University of Science and Technology of China

Corresponding author: pengwu@bitbu.edu.cn.

###### Abstract

In recommender systems, the collected data used for training is always subject to selection bias, which poses a great challenge for unbiased learning. Previous studies proposed various debiasing methods based on observed user and item features, but ignored the effect of hidden confounding. To address this problem, recent works suggest the use of sensitivity analysis for worst-case control of the unknown true propensity, but only valid when the true propensity is near to the nominal propensity within a finite bound. In this paper, we first perform theoretical analysis to reveal the possible failure of previous approaches, including propensity-based, multi-task learning, and bi-level optimization methods, in achieving unbiased learning when hidden confounding is present. Then, we propose a unified multi-task learning approach to remove hidden confounding, which uses a few unbiased ratings to calibrate the learned nominal propensities and nominal error imputations from biased data. We conduct extensive experiments on three publicly available benchmark datasets containing a fully exposed large-scale industrial dataset, validating the effectiveness of the proposed methods in removing hidden confounding.

## 1 Introduction

Recommender systems (RS) play a key role in information retrieval by filtering out items that may be of interest to users [16; 24]. In general, the training process of recommendation uses historical user interaction data. However, a challenge in using interactions to make predictions is selection bias [3; 32; 40; 57], i.e., users always choose preferred items to interact [5; 51], resulting in a difference in the distribution between data with and without interactions [14; 45; 46; 47; 48; 54; 56; 60], which poses a great challenge for unbiased evaluation and learning of the prediction models.

Many methods have been proposed to tackle the selection bias problem, such as the error imputation-based (EIB) , inverse propensity scoring (IPS) [33; 41; 42], and doubly robust (DR) methods [7; 27; 28; 29; 52]. Based on these, recent works further incorporate multi-task learning to alleviate the data sparsity issue, such as entire space multi-task model (ESMM) , multi-task IPS and multi-task DR (Multi-IPS and Multi-DR) , and entire space counterfactual multi-task models (ESCM\({}^{2}\)) .

However, these studies only consider the selection bias induced by measured confounders, but ignore the presence of hidden (or unmeasured) confounders, which considerably influences the application of these advanced methods in real-world recommendation scenarios. Hidden confounders are ubiquitous and inevitable in RS due to information limitations (e.g., friend useful suggestions) or privacy restrictions (e.g., user salary) [8; 31; 35; 50]. In this paper, we perform theoretical analysisfor the existing propensity-based and multi-task learning methods, showing that all of them will lead to biased evaluation and learning in the presence of hidden confounding.

To remove hidden confounding, previous causal inference literature suggested the use of instrumental variables  or front door adjustment . However, in real-world application scenarios, these approaches require strong assumptions that are difficult to verify in practice. On the other hand, a recent recommendation study proposed robust deconfounder (RD) to adopt sensitivity analysis using a min-max optimization for worst-case control of the unknown true propensity . Nevertheless, they assume the true propensity is near to the nominal one within a bound, which is decided by the strength of the unmeasured confounder, posing another challenge in case these assumptions are violated.

In contrast, unbiased datasets are regarded as the gold standard for unbiased evaluations and can be collected from A/B tests or randomized controlled trials [10; 13; 21; 55]. This provides an alternative solution to remove hidden confounding [15; 20; 26; 58]. Nevertheless, training recommendation models directly on unbiased datasets can suffer from severe overfitting due to the limited sample size restricted by the collection cost of random exposure . Despite few works leverage the unbiased data to combat selection bias [4; 53] by adopting the bi-level optimization, this paper shows that they still lead to biased learning, due to the biased hypothesis space of the prediction model.

To tackle the above problems, we propose a unified multi-task learning approach to remove hidden confounding by leveraging a few unbiased ratings. Interestingly, we show that the unbiased data can help calibrate the learned nominal propensities and nominal error imputations, which differs from RD using sensitivity analysis for nominal propensities only . Specifically, the proposed multi-task learning builds residual networks for learned propensities and imputed errors from biased data, respectively. Next, a consistency loss of IPS (or DR) estimation on the biased dataset and empirical average prediction errors on the unbiased dataset are developed to help the training of the two residual networks, for calibrating the learned nominal propensities and nominal error imputations, respectively. The prediction model is then trained with the calibrated IPS (or calibrated DR) loss and unbiased data to achieve unbiased learning in the presence of hidden confounding.

The main contributions of this paper are summarized as follows:

* We theoretically reveal limitations of the existing multi-task learning and bi-level optimization methods for achieving the unbiasedness in the presence of hidden confounding.
* We provide a unified multi-task learning approach to remove hidden confounding by combining a few unbiased ratings, in which the learned nominal propensities and nominal error imputations can be calibrated by the residual networks with the proposed consistency loss.
* We conduct extensive experiments on three publicly available benchmark datasets, including a large-scale industrial dataset, to validate the effectiveness of the proposed methods.

## 2 Problem Setup

We formulate the selection bias in RS using post-click conversion rate (pCVR) prediction task for illustration purpose, which can be naturally generalized to other recommendation tasks with explicit feedback, e.g., rating prediction. Suppose that the entire space has \(m\) users and \(n\) items, let \(\) be the set of all user-item pairs. Denote \(\{0,1\}^{m n}\) as the true post-click conversion label matrix of user-item pairs, where each entry \(r_{u,i}\) indicates whether a conversion occurs after user \(u\) clicks on item \(i\). Let \(x_{u,i}\) be the feature of user-item pair \((u,i)\), and \(}^{m n}\) be the prediction matrix for pCVR, where \(_{u,i}=f(x_{u,i},_{})\) is the predicted pCVR obtained by a model \(f\) with parameter \(_{}\). In RS, users always select the preferred items to click on, leading to a significant difference in the distribution between clicked and unclicked events thus causing selection bias.

If \(\) is fully observed, then a pCVR model \(f(x_{u,i};_{})\) can be trained by minimizing the ideal loss

\[_{}(_{})=|}_{ (u,i)}_{u,i},\]

where \(_{u,i}(r_{u,i},_{u,i})\) and \((,)\) is a pre-specified loss, e.g., the cross-entropy loss, \((r_{u,i},_{u,i})=-r_{u,i}_{u,i}-(1-r_{u,i})(1 -_{u,i})\). However, the post-click conversion feedback of a user-item pair \((u,i)\) can be observed only when user \(u\) clicks on item \(i\), making the ideal loss not computable. Let \(o_{u,i}\) be the indicator of user \(u\) clicking on item \(i\), and \(=\{(u,i)(u,i),o_{u,i}=1\}\) be the set of clicked events, where \(\) means that the clicked events is a biased sample of the entire space \(\). In this paper, we further consider the presence of hidden confounding. Without loss of generality, we assume that all confounders consist of a measured part \(x_{u,i}\) and a hidden (unmeasured) part \(h_{u,i}\), where the latter arises from issues such as information limitations (e.g., friend suggestions) and privacy restrictions (e.g., user salary), which cannot be observed explicitly and used for training.

## 3 Previous Methods Lead to Biased Learning under Hidden Confounding

### Multi-Task Learning

The pCVR prediction task is closely related to click-through rate (CTR) and post-view click-through & conversion rate (CTCVR) prediction tasks, as the formula \(=*\) holds, where the CTR is \(p_{u,i}(o_{u,i}=1|x_{u,i})\), also known as propensity score in the causal inference literature, represents the probability of a user \(u\) clicking on an item \(i\). The CTCVR is \((r_{u,i}=1,o_{u,i}=1|x_{u,i})\), means the probability that item \(i\) is clicked and converted by user \(u\).

Let \(_{u,i}_{u,i}(x_{u,i},_{})\) be CTR prediction model with parameter \(_{}\). The ESMM method  learns pCVR by joint-training CTR and CTCVR losses

\[_{}(_{})=|}_{( u,i)}(o_{u,i},_{u,i}),_{ }(_{},_{})= |}_{(u,i)}(o_{u,i}r_{u,i},_{u,i}_{ u,i}).\]

However, the ESMM loss \(_{}(_{})+_{}( _{},_{})\) is a biased estimator of the ideal loss . To achieve unbiased learning, the MTL-IPS and MTL-DR methods  use the losses

\[_{}(_{},_{})=|}_{(u,i)}_{u,i}}{_{u,i }},\;_{}(_{},_{},_{ })=|}_{(u,i)}_{u,i}+(_{u,i}-_{u,i})}{_{u,i}} ,\]

where \(_{u,i}_{u,i}(x_{u,i},_{})\) is the imputation model that predicts \(_{u,i}\) using \(x_{u,i}\), i.e., it estimates \(g_{u,i}[_{u,i}|x_{u,i}]\). Without hidden confounders, \(_{}\) is an unbiased estimator of the ideal loss when the learned propensities are accurate, i.e., \(_{u,i}=p_{u,i}\)[41; 42], and \(_{}\) is unbiased if either \(_{u,i}=p_{u,i}\) or \(_{u,i}=g_{u,i}\)[39; 52]. However, both IPS and DR are biased under hidden confounders.

**Lemma 1** (Theorem 3.1 in ).: _In the presence of hidden confounders \(h_{u,i}\), both \(_{}\) and \(_{}\) are biased estimators of the ideal loss, even if \(_{u,i}=p_{u,i}\) and \(_{u,i}=g_{u,i}\)._

The above result also holds in the follow-up DR studies [23; 25; 43], and can be naturally extended to conclude that the MTL-IPS and MTL-DR  are biased under hidden confounding. Recently, ESCM\({}^{2}\)-IPS and ESCM\({}^{2}\)-DR showed state-of-the-art performance in pCVR prediction by incorporating the ESMM loss \(_{}\) as the global risk of CTCVR, and MTL-IPS and MTL-DR losses \(_{}^{}\) as counterfactual risk of pCVR . Formally, the ESCM\({}^{2}\) loss is

\[_{^{2}}=_{}+_{1}_ {}+_{2}_{}^{}+_{3} _{},\]

where \(_{t}\) for \(t=1,2,3\) are hyper-parameters, \(_{}^{}\) is either \(_{}\) or \(_{}\). The imputation loss is

\[_{}(_{},_{},_{ })=|}_{(u,i)}-_{u,i})^{2}}{_{u,i}}.\]

However, since both \(_{}\) and \(_{}^{}\) are biased under hidden confounding, ESCM\({}^{2}\) is also biased.

### Debiasing with a Few Unbiased Ratings

Instead of only using the biased dataset \(\), many methods are proposed to improve the debiasing performance by combining a small unbiased dataset \(\) and a large biased dataset \(\), such as bi-level optimization approaches, including learning to debias (LTD)  and AutoDebias , causal embedding method (CausE) , knowledge distillation framework for counterfactual recommendation via uniform data (KDCRec) [30; 32], and causal balancing methods .

Specifically, learning to debias (LTD)  and AutoDebias  adopt bi-level optimization [17; 37] to learn a CTR model \(_{u,i}(x_{u,i},_{})\) such that the pCVR prediction model \(_{u,i}=f(x_{u,i},_{})\) performs well on the small unbiased dataset \(\). Formally, the bi-level optimization in LTD is

\[_{}^{*} =\;_{_{}}_{ }^{}(_{}^{*}(_{ {TR}})),\] \[\;_{}^{*}(_{ {TR}}) =\;_{_{}}_{}^{ }(_{},_{}),\]

where the upper loss is as an average of prediction errors on the unbiased dataset

\[_{}^{}(_{}^{*}( _{}))=|}_{(u,i)}(r_{u,i},_{u,i}(_{}^{*}(_{ }))),\]

and AutoDebias further develop a solution for universal debiasing. However, despite the use of unbiased ratings, we show that they still lead to biased estimates under hidden confounding.

**Proposition 1**.: _In the presence of hidden confounders, both LTD and AutoDebias are biased._

Proof.: Let \(_{}=\{_{u,i}(x_{u,i},_{}):_{}_{}\}\) be the hypothesis space of propensity model. Then \(_{}^{*}\) defined above is the parameter in \(_{}\) such that the pCVR prediction model performs optimally on \(\). The bi-level optimization takes \(_{}^{}\) to estimate the ideal loss using a selected propensity \(_{u,i}(x_{u,i},_{}^{*})_{}\), however, \(_{}^{}\) could be a biased estimator of the ideal loss for all \(_{u,i}_{}\) (due to \(_{u,i}\) could deviates from the true one by an arbitrary distance, as formally stated in Theorem 2), therefore both LTD and AutoDebias using bi-level optimization are biased. 

Proposition 1 formally reveals the limitations of directly adopting bi-level optimization for addressing hidden confounding. Both LTD and AutoDebias essentially use unbiased data for _model selection_ among all possible IPS or DR losses, but in fact, without _correcting_ the IPS or DR estimators themselves for predicting the ideal loss, those IPS or DR-based methods will not be able to tackle unobserved confounding, because of the intrinsic biasedness of the estimators to the ideal loss.

An alternative class of methods that use unbiased data for tuning is the causal embedding method (CausE)  and KDCRec [30; 32]. Specifically, they both consider building a connection between a model trained with biased data and another model trained with unbiased data. CausE  designs an alignment term as the pairwise difference between the parameters of the two models, which is then included in the object function to be minimized. KDCRec [30; 32] proposes a general knowledge distillation framework for counterfactual recommendation via uniform data, including label-based, feature-based, sample-based, and model structure-based distillations. The above methods empirically shown impressive performance by distilling the shared information on both biased and unbiased data. However, theoretical guarantees under hidden confounding are lacking, and it would be interesting to investigate the conditions under which these methods can achieve unbiased learning.

### Mitigating Hidden Confounding with Sensitivity Analysis

To tackle the problem of hidden confounding, robust deconfounder (RD)  proposes to adopt sensitivity analysis from the causal inference literature [6; 38] to minimize the worst-case prediction loss. Formally, the unknown **true propensity**\(_{u,i}(o_{u,i}=1|x_{u,i},h_{u,i})\) is assumed to near the **nominal propensity**\(p_{u,i}=(o_{u,i}=1|x_{u,i})\) within a bound that

\[)_{u,i}}{p_{u,i}(1- _{u,i})} 1+(1/p_{u,i}-1)/  a_{u,i} w_{u,i} b_{u,i} 1+(1/p_{u,i}-1 ),\]

where hyper-parameter \(\) corresponds to the strength of unmeasured confounding, \(w_{u,i}=1/_{u,i}\) is the inverse of the true propensity, and \(a_{u,i}\) and \(b_{u,i}\) are the lower and upper bounds of \(w_{u,i}\), respectively. Let \(=[_{1,1},_{1,1}][_{m,n}, _{m,n}]\) be the possible inverse propensities on all user-item pairs, where \(_{u,i}\) and \(_{u,i}\) are the estimates of \(a_{u,i}\) and \(b_{u,i}\), respectively, then RD-IPS method trains the prediction model by minimizing the worst-case IPS loss

\[_{}(_{},_{ })=_{W}|}_{(u,i)}o_{u,i }_{u,i}w_{u,i},\]

and the RD-DR method can be developed by a similar argument controlling the worst-case DR loss.

To summarize, the RD methods first obtains the bounds of true propensities around the nominal propensities, then minimize the upper bound of the IPS (or DR) loss to control the worst-case caused by unmeasured confounders. However, on the one hand, it is not clear how to set \(\) correctly since both the true propensities and the strength of hidden confounding are unknown. On the other hand, the effectiveness of sensitivity analysis for controlling the hidden confounding requires that the true propensity is around the nominal propensity for all user-item pairs, but such (strong) assumptions cannot be verified from the data and raises another concern in case the assumptions are violated.

## 4 Debiasing Residual Networks under Hidden Confounding

### Methodology Overview

Different from the previous methods that use sensitivity analysis to control the worst-case IPS or DR loss caused by hidden confounding, we propose a unified multi-task learning approach with residual networks as in Figure 1, with the motivation of using a small unbiased data to calibrate the learned propensities and imputed errors in IPS or DR loss for training the unbiased prediction model.

Following causal inference literature [18; 19], we define the **true propensity** and **true imputation** as \(_{u,i}(o_{u,i}=1|x_{u,i},h_{u,i}),\;_{u,i} (_{u,i}|x_{u,i},h_{u,i})\), both of them are functions of \((x_{u,i},h_{u,i})\), with \(_{u,i}\) and \(_{u,i}\) as their estimates. To distinguish, we call \(p_{u,i}=(o_{u,i}=1|x_{u,i})\) and \(g_{u,i}=[_{u,i}|x_{u,i}]\) the **nominal propensity** and **nominal imputation**, with \(_{u,i}\) and \(_{u,i}\) as their estimates.

Next, we show the necessity of calibrations on both \(_{u,i}\) and \(_{u,i}\) estimated from the baised data \(\).

**Theorem 2** (Necessity of Calibration).: _Suppose the partial derivative of \(_{u,i}\) and \(_{u,i}\) with respect to hidden confounders \(h_{u,i}\) are not always equal to 0, and \(_{u,i}\) and \(_{u,i}\) are consistent estimators of \(p_{u,i}\) and \(g_{u,i}\), then there exists \(>0\), such that_

\[_{||}(|_{u,i}-_{u,i}|>)>0, _{||}(|_{u,i}-_{u,i} |>)>0.\]

Proof.: Given the partial derivative of \(_{u,i}\) with respect to hidden confounders \(h_{u,i}\) is not always equal to 0, that is, \(h_{u,i}\) has a non-zero effect on \(o_{u,i}\), so we have \(_{u,i} p_{u,i}\) according to their definitions. Thus, for some \(>0\), there exist positive constants \(_{},N_{1}()>0\), such that for all \(||>N_{1}()\),

\[(|_{u,i}-p_{u,i}|>)>_{}>0.\]

Since \(_{u,i}\) is a consistent estimator of \(p_{u,i}\), there exists some \(N_{2}()>0\), such that for all \(||>N_{2}()\),

\[(|_{u,i}-p_{u,i}|/2)<}{4}.\]

Thus, if \(||>\{N_{1}(),N_{2}()\}\), we have

\[(|_{u,i}-p_{u,i}|>,|_{u,i}-p_{u,i }|</2)\] \[=(|_{u,i}-p_{u,i}|>)-(|_{u,i}-p_{u,i}|>,|_{u,i}-p_{u,i}|)\] \[>_{}-_{}/4=3_{}/4.\]

Let \(=/2\) and note that \(\{|_{u,i}-p_{u,i}|>,|_{u,i}-p_{u,i}|</2\} \{|_{u,i}-_{u,i}|>\}\), we have

\[(|_{u,i}-_{u,i}|>)(|_{u,i}-p_{ u,i}|>,|_{u,i}-p_{u,i}|</2)>3_{}/4>0,\]

which leads to \(_{||}(|_{u,i}-_{u,i}|>)>0\). Similarly, it can be shown that \(_{||}(|_{u,i}-_{u,i}|> )>0\). 

Theorem 2 shows that in the presence of hidden confounding, the estimated nominal propensities and nominal imputed errors deviate from the true one, even with the infinite sample size. To address this problem, as shown in Figure 1, we propose a novel consistency loss that utilizes unbiased data to calibrate the learned nominal propensities and imputed errors from the biased data.

Specifically, we define the **calibrated propensity model**\(=(_{},_{})\) and the **calibrated imputation model**\(=(_{},_{})\) as follows

\[_{u,i} =(^{-1}(_{u,i}(_{}))+ ^{-1}( p_{u,i}(_{}))),\] \[_{u,i} =(^{-1}(_{u,i}(_{} ))+^{-1}(_{u,i}(_{}))),\]

where \(\) is the sigmoid function, and the transformations are designed for numerical stability, e.g., to control range from 0 to 1. Compared with \(_{u,i}\) and \(_{u,i}\) adopted in the previous multi-task learning approaches [34; 44; 59], the residual terms \( p_{u,i}\) and \(_{u,i}\) are further added to \(_{u,i}\) and \(_{u,i}\) to capture the effect of hidden confounding. The loss function of the proposed approach is defined as

\[_{}=_{}()+ _{}()}_{}+_{}^{}(,)+_{}^{}()+_{ }^{})}_{}+ _{}^{}( ,,,)}_{},\]

where \(\), \(\) and \(\) are hyper-parameters for trade-off. The following states for each loss.

### Nominal Propensities and Imputations Initialization

Similar to the previous IPS and DR methods [39; 41; 42; 52], as well as the multi-task learning approaches [34; 44; 59], we use the losses \(_{}\) and \(_{}\) in Section 3.1 for training the estimated nominal propensities \(_{u,i}\) and nominal imputed errors \(_{u,i}\) from the biased dataset. However, since \(_{u,i}\) and \(_{u,i}\) can only capture the effect of _measured_ confounding, we do not directly use them for training the prediction model under _hidden_ confounding. Instead, we train the prediction model using the calibrated propensities and imputed errors as illustrated in Section 4.3.

### Debiased Prediction Model Training

**Training on Biased Data.** To train an unbiased prediction model, the losses need to be unbiased with respect to the ideal loss, thus the direct use of nominal \(_{u,i}\) and \(_{u,i}\) under hidden confounding would lead to biased predictions. In contrast to previous studies, we propose to use both the initialized \(_{u,i}\) and \(_{u,i}\) in Section 4.2, and the corresponding residual terms \( p_{u,i}\) and \(_{u,i}\) (see Section 4.4 for more details) using IPS (or DR, CTCVR loss) to achieve unbiased prediction model learning.

Specifically, using the calibrated propensity model, the proposed residual-IPS (Res-IPS) loss is

\[_{}^{}(_{}_{u,i}( _{}), p_{u,i}(_{}))=|}_{(u,i)}_{u,i}}{_{u,i}}.\]

Figure 1: Proposed debiasing residual networks for removing hidden confounding.

Similarly, using both the calibrated propensity model and the calibrated imputation model, the proposed residual-DR (Res-DR) loss is

\[_{}^{}(_{}_{u,i}( _{}), p_{u,i}(_{}),_{u,i}( _{}),_{u,i}(_{}))=|}_{(u,i)}_{u,i}+(_{u,i}-_{u,i})}{_{u,i}}.\]

Although CTCVR loss is not unbiased to the ideal loss , as previous studies have shown, using both IPS (or DR) loss and CTCVR loss empirically can lead to better debiasing performance by mitigating the data sparsity issue . Similarly, using the calibrated propensity model, the proposed calibrated CTCVR loss is

\[_{}(_{}_{u,i}(_{ }), p_{u,i}(_{}))=|}_{ (u,i)}(o_{u,i}r_{u,i},_{u,i}_{u,i} ).\]

Empirically, one can choose from the three calibrated losses for training a debiased prediction model.

**Training on Unbiased Data.** Since the unbiased data do not encounter any confounding problems, it provides a golden standard to evaluate and train the pCVR prediction model. The unbiased loss is

\[_{}^{}(_{})=|}_{(u,i)}(r_{u,i},_{u,i}( _{})).\]

Different from the previous studies , in which \(_{}^{}\) is used to select the optimal propensity or imputation models, our approach is not necessary for training the prediction model using the unbiased loss (since one can use the aforementioned calibrated losses). In addition, the direct use of the unbiased loss can lead to severe overfitting, which once again demonstrates the importance of calibrating the propensity and imputation models in the IPS or DR loss.

### Residual Networks Training

Collected through a carefully designed experiment, the unbiased data can be regarded as a representative sample of the entire space . Thus, we always have \(_{}^{}_{}( _{})\), regardless of hidden confounding in biased data, which motivates us to propose a consistency loss

\[_{}^{}(_{},_{},_{},_{},_{})=( _{}^{},_{}^{ }),\]

which measures the discrepancy between \(_{}^{}\) and \(_{}^{}\), which equivalently provides us with _an optimization direction for removing hidden confounding_.

**Proposition 3**.: _If \(_{}^{}=0\), then \(_{}^{}\) is an unbiased estimator of the ideal loss, regardless of whether hidden confounders exist or not._

Essentially, the consistency loss uses unbiased data to calibrate the debiasing loss \(_{}^{}\) based on the biased data, thereby guaranteeing the debiasing ability of the proposed methods in the presence of hidden confounding. As discussed in Sections 4.1-4.3, we utilize the two residual terms \( p_{u,i}\) and \(_{u,i}\) to capture the effect of hidden confounding, which are trained by minimizing \(_{}^{}\).

## 5 Real-World Experiments

**Dataset and Pre-processing.** Following the previous studies , we use three real-world datasets: Coat2, Yahoo! R3, and KuaiRec4, for evaluating the debiasing performance of the proposed methods, where KuaiRec is a public large-scale industrial dataset. Coat contains 6,960 biased ratings from 290 users to 300 items, where each user picks 24 items to rate based on their personal preferences. Meanwhile, it also contains 4,640 unbiased ratings, where each user is asked to rate 16 randomly selected items. Yahoo! R3 contains 311,704 biased ratings and 54,000 unbiased ratings, where the unbiased ratings are from the first 5,400 users for 10 random selected items. We binarize ratings less than four to 0 and other ratings to 1 for the above two five-scaledatasets. KuaiRec is a fully exposed dataset containing 4,676,570 video watching ratio records from 1,411 users for 3,327 videos. The records less than two are binarized to 0 and other records to 1.

**Baselines.** In our experiment, we take the widely-used **Matrix Factorization (MF)** as the base model. We compare our methods with the debiasing methods: **IPS**, **DR**, **RD-IPS**, **RD-DR**, and multi-task learning approaches: **ESMM**, **Multi-IPS**, **Multi-DR**, **ESCM\({}^{2}\)-IPS** and **ESCM\({}^{2}\)-DR**. We also compared the methods using both biased data and unbiased data: **CausE**, **KD-Label**, **KD-Feature** and **AutoDebias**.

**Experimental Protocols and Details.** We adopt three widely-used evaluation metrics: AUC, Recall@K (R@K), and NDCG@K (N@K) for debiasing performance evaluation. We set K = 5 for Coat and Yahoo! R3, and K = 50 for KuaiRec. All the experiments are implemented on Pytorch with Adam as the optimizer. We tune learning rate in \(\{0.0001,0.0005,0.001,0.005,0.01,0.05\}\), weight decay in \(\{0,1e-6,,1e-1,1\}\). For our methods, we tune \(\) in \(\{0.1,0.5,1\}\), \(\) in \(\{0.1,0.5,1,5,10\}\), and \(\) in \(\{0.001,0.005,0.01,0.05,0.1\}\). In addition, we randomly split 5% of unbiased data from the test set to train models for all methods that require unbiased data5.

**Performance Comparison.** Table 1 shows the real-world debiasing performance for varying methods on three datasets. First, most debiasing methods outperform the base model, i.e., MF (bias), demonstrating the necessity for debiasing in the presence of selection bias. Second, methods using both biased and unbiased data outperform the methods using only one of them, which indicates that there exists some non-overlap information that can benefit for debiasing between both biased and

    &  &  &  \\  Method & AUC & N@5 & R@5 & AUC & N@5 & R@5 & AUC & N@50 & R@50 \\  MF  (Bias) & 0.747 & 0.500 & 0.546 & 0.721 & 0.553 & 0.716 & 0.820 & 0.561 & 0.816 \\ MF  (Uniform) & 0.580 & 0.363 & 0.386 & 0.574 & 0.455 & 0.611 & 0.664 & 0.491 & 0.816 \\ MF  (Combine) & 0.751 & 0.504 & 0.546 & 0.724 & 0.558 & 0.717 & 0.822 & 0.566 & 0.812 \\ CausE  & 0.763 & 0.512 & 0.575 & 0.730 & 0.555 & 0.736 & 0.819 & 0.581 & 0.856 \\ ESMM  & 0.745 & 0.506 & 0.525 & 0.708 & 0.545 & 0.693 & 0.823 & 0.563 & 0.852 \\ KD-Label  & 0.760 & 0.509 & 0.562 & 0.726 & 0.583 & 0.752 & 0.815 & 0.570 & 0.858 \\ AutoDebias  & 0.762 & 0.540 & 0.580 & 0.735 & 0.632 & **0.785** & 0.818 & 0.584 & 0.866 \\ KD-Feature  & 0.766 & 0.522 & 0.584 & 0.717 & 0.557 & 0.736 & 0.809 & 0.588 & 0.873 \\  IPS  & 0.761 & 0.513 & 0.566 & 0.722 & 0.555 & 0.733 & 0.826 & 0.574 & 0.849 \\ Multi-IPS  & 0.758 & 0.514 & 0.531 & 0.719 & 0.546 & 0.710 & 0.810 & 0.554 & 0.875 \\ ESCM\({}^{2}\)-IPS  & 0.757 & 0.514 & 0.558 & 0.729 & 0.559 & 0.714 & 0.815 & 0.577 & 0.860 \\ RD-IPS  & 0.764 & 0.514 & 0.566 & 0.730 & 0.571 & 0.735 & 0.832 & 0.585 & 0.873 \\ BRD-IPS  & 0.763 & 0.511 & 0.564 & 0.735 & 0.582 & 0.743 & 0.834 & 0.588 & 0.877 \\ Res-IPS (ours) & **0.777** & **0.575** & **0.601** & **0.759** & **0.639** & **0.785** & **0.849** & **0.601** & **0.885** \\  DR  & 0.766 & 0.525 & 0.552 & 0.725 & 0.553 & 0.727 & 0.824 & 0.567 & 0.838 \\ Multi-DR  & 0.759 & 0.527 & 0.565 & 0.719 & 0.553 & 0.712 & 0.829 & 0.562 & 0.859 \\ ESCM\({}^{2}\)-DR  & 0.760 & 0.553 & 0.568 & 0.715 & 0.566 & 0.722 & 0.827 & 0.569 & 0.830 \\ RD-DR  & 0.768 & 0.539 & 0.571 & 0.732 & 0.569 & 0.738 & 0.833 & 0.585 & **0.884** \\ BRD-DR  & 0.770 & 0.546 & 0.577 & 0.735 & 0.576 & 0.737 & 0.831 & 0.585 & 0.883 \\ Res-DR (ours) & **0.793** & **0.588** & **0.607** & **0.750** & **0.654** & **0.803** & **0.854** & **0.595** & 0.860 \\   

Table 1: Performance in terms of AUC, NDCG@K, and Recall@K on the unbiased dataset of Coat, Yahoo! R3 and KuaiRec. The best two results are bolded, and the best baseline is underlined.

    &  &  \\  Unbiased data ratio & 2\% & 4\% & 6\% & 8\% & 10\% & 2\% & 4\% & 6\% & 8\% & 10\% \\  CausE & 0.818 & 0.818 & 0.819 & 0.819 & 0.819 & 0.579 & 0.580 & 0.584 & 0.586 & 0.587 \\ KD-Label & 0.815 & 0.815 & 0.815 & 0.816 & 0.816 & 0.582 & 0.584 & 0.588 & 0.588 \\ AutoDebias & 0.810 & 0.815 & 0.818 & 0.826 & 0.832 & 0.569 & 0.580 & 0.587 & 0.589 \\ Res-IPS (ours) & **0.845** & **0.848** & **0.850** & **0.850** & **0.852** & **0.595** & **0.596** & **0.602** & **0.603** \\ Res-DR (ours) & **0.850** & **0.851** & **0.854** & **0.855** & **0.855** & **0.592** & **0.593** & **0.597** & **0.605** & **0.606** \\   

Table 2: Effects of varying unbiased data ratio on KuaiRec in terms of AUC and NDCG@50. The best two results are bolded, and the best baseline is underlined.

unbiased data, and highlights the importance of leveraging both kinds of data. Meanwhile, the direct use of multi-task learning approaches to IPS and DR estimators cannot benefit the debiasing performance under hidden confounding. The proposed Res-IPS and Res-DR methods stably outperform previous methods on all three datasets, which provides empirical evidence of the existence of hidden confounding in the real-world recommendations, as well as the effectiveness of our methods for removing hidden confounding. Table 2 shows the results of AUC and NDCG@50 on KualRec with varying unbiased data ratios. The performance of all methods improves with increasing unbiased data ratio, and our method stably outperforms the baseline methods by a large margin.

**Ablation Studies.** The two losses \(_{}^{}\) and \(_{}^{}\) as well as the two residual terms \(\) and \( p\) are crucial in the proposed multi-task learning approach. We further conduct ablation studies with respect to the residual networks and the training loss components, respectively. From Table 3, Res-DR using either the propensity residual network or the imputation residual network can stably outperform ESCM\({}^{2}\)-DR, and Res-DR achieves the best performance when two residual networks are adopted together. When both propensity and imputation residual networks are removed, although Res-DR includes \(_{}^{}\) and \(_{}^{}\) losses, it has similar performance to ESCM\({}^{2}\)-DR, which further indicates that the performance improvement of Res-DR can be attributed to the effectiveness of the residual networks. From Table 4, both Res-IPS and Res-DR methods without \(_{}^{}\) loss or without \(_{}^{}\) loss outperform ESCM\({}^{2}\)-IPS and ESCM\({}^{2}\)-DR. Similarly, our methods achieve the best performance when both two losses are preserved. Note that the model with \(_{}^{}\) loss performs better than the model with \(_{}^{}\) loss, which is attributed to \(_{}^{}\) corrects for biased learned propensities and biased imputed errors under the presence of hidden confounding. In addition, unbiased data does not significantly improve the debiasing performance when it is directly used to train the prediction model through \(_{}^{}\), due to the overfitting problem caused by the limited unbiased data size, which is consistent to the poor performance of MF (uniform) in Table 1. Meanwhile, minimizing \(_{}^{}\) does not provide any residual information for biased learned propensities and biased imputed errors.

**In-Depth Analysis.** The proposed methods contain the prediction model, imputation model, propensity model, and residual models, thus it is meaningful to investigate the effect of different optimization algorithms among these models on the debiasing performance. Specifically, we implement the following learning approaches on the Res-DR: (1) Joint Learning (JL) , which joint optimizes the prediction model and the imputation model. (2) Double Learning (DL) , which adds a parameter

    &  &  &  &  \\  Method & \(_{}^{}\) & \(_{}^{}\) & AUC & N@5 & R@5 & AUC & N@5 & R@5 & AUC & N@50 & R@50 \\  ESCM\({}^{2}\)-IPS & \(\) & \(\) & 0.757 & 0.514 & 0.558 & 0.729 & 0.559 & 0.714 & 0.815 & 0.577 & 0.860 \\ Res-IPS-None & \(\) & \(\) & 0.755 & 0.522 & 0.546 & 0.722 & 0.552 & 0.707 & 0.825 & 0.580 & 0.853 \\ Res-IPS-U & \(\) & \(\) & 0.770 & 0.562 & 0.570 & 0.718 & 0.587 & 0.741 & 0.833 & 0.583 & 0.849 \\ Res-IPS-B\&U & \(\) & \(\) & **0.784** & 0.573 & 0.592 & 0.756 & 0.635 & 0.778 & 0.845 & 0.592 & 0.880 \\ Res-IPS & \(\) & \(\) & 0.777 & **0.575** & **0.601** & **0.759** & **0.639** & **0.785** & **0.849** & **0.601** & **0.885** \\  ESCM\({}^{2}\)-DR & \(\) & \(\) & 0.760 & 0.553 & 0.568 & 0.715 & 0.566 & 0.722 & 0.827 & 0.569 & 0.830 \\ Res-DR-None & \(\) & \(\) & 0.765 & 0.544 & 0.550 & 0.714 & 0.575 & 0.735 & 0.824 & 0.562 & 0.823 \\ Res-DR-U & \(\) & \(\) & 0.770 & 0.565 & 0.577 & 0.722 & 0.604 & 0.756 & 0.836 & 0.562 & 0.842 \\ Res-DR-B\&U & \(\) & \(\) & 0.790 & 0.574 & 0.601 & 0.744 & 0.640 & 0.782 & 0.848 & 0.586 & 0.848 \\ Res-DR & \(\) & \(\) & **0.793** & **0.588** & **0.607** & **0.750** & **0.654** & **0.803** & **0.854** & **0.595** & **0.860** \\   

Table 4: Ablation study on **loss components** in Res-IPS and Res-DR methods, with AUC, NDCG@K and Recall@K as evaluation metrics. The best result is bolded and the second is underlined.

    &  &  &  &  \\  Method & \(\) & \( p\) & AUC & R@5 & N@5 & AUC & N@5 & R@5 & AUC & N@50 & R@50 \\  ESCM\({}^{2}\)-DR & \(\) & \(\) & 0.760 & 0.553 & 0.568 & 0.715 & 0.566 & 0.722 & 0.827 & 0.569 & 0.830 \\ Res-DR w/o \( p\) & \(\) & \(\) & 0.763 & 0.544 & 0.568 & 0.716 & 0.560 & 0.715 & 0.831 & 0.570 & 0.836 \\ Res-DR w/o \( p\) & \(\) & \(\) & 0.783 & 0.561 & 0.573 & 0.734 & 0.630 & 0.781 & 0.833 & 0.570 & 0.849 \\ Res-DR w/o \(\) & \(\) & \(\) & 0.768 & 0.555 & 0.581 & 0.721 & 0.645 & 0.791 & 0.841 & 0.579 & 0.836 \\ Res-DR & \(\) & \(\) & **0.793** & **0.588** & **0.607** & **0.750** & **0.654** & **0.803** & **0.854** & **0.595** & **0.860** \\   

Table 3: Ablation study on **residual networks** in Res-DR method, with AUC, NDCG@K and Recall@K as evaluation metrics. The best result is bolded and the second is underlined.

sharing mechanism between the prediction model and the imputation model based on JL. (3) Multi-Task Learning (MTL) adopted in our methods. Figure 2 shows the experiment results. Remarkably, MTL significantly outperforms JL and DL, whereas in Table 1 DR and MTL-based ESCM\({}^{2}\)-DR perform similarly. This is because DR only has three training models (namely the prediction model, imputation model, and propensity model), whereas the proposed Res-DR has two additional residual models. As the number of models increases, JL can no longer bridge the models efficiently, which leads to a slow convergence and limited performance. Instead, DL increases the connection between models via timely parameter sharing. Finally, MTL trade-offs the different tasks in Res-DR to train all the models, leading to the optimal debiasing performance.

**Sensitivity Analysis.** We perform the sensitivity analysis of \(\) on Res-IPS and Res-DR, as shown in Figure 3. Our methods achieve the optimal performance when \(\) is moderate (0.005-0.01). This is because when \(\) is too large, it hurts the performance of other tasks (e.g., CVR model training), and when \(\) is too small, it makes the consistency loss be paid with less attention, so that the hidden confounding cannot be effectively removed. Res-IPS and Res-DR stably outperform ESCM\({}^{2}\)-IPS and ESCM\({}^{2}\)-DR under varying \(\). This further illustrates the effectiveness the consistency loss.

## 6 Conclusion

This paper investigates the use of a few unbiased ratings to calibrate the learned propensities and imputed errors for removing hidden confounding. First, we theoretically reveal the biasedness of previous debiasing methods in the presence of hidden confounding. Next, we propose a multi-task debiasing residual networks learning approach for training the debiased prediction model. By building residual networks and calibrating the biased learned propensities and biased imputed errors, the prediction model is trained on both the calibrated IPS or DR losses and the unbiased dataset to ensure the unbiasedness. Extensive experiments on two benchmark datasets and a large-scale industrial dataset validate the effectiveness of our proposal. A limitation of this work is the use of slightly more model parameters due to the need to address hidden confounding with residual networks.