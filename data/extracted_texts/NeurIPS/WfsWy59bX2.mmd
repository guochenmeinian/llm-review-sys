# Anonymous Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization

Adel Javanmard

University of Southern California, Google Research

ajavanma@usc.edu

&Vahab Mirrokni

Google Research

mirrokni@google.com

###### Abstract

While personalized recommendations systems have become increasingly popular, ensuring user data protection remains a top concern in the development of these learning systems. A common approach to enhancing privacy involves training models using anonymous data rather than individual data. In this paper, we explore a natural technique called _look-alike clustering_, which involves replacing sensitive features of individuals with the cluster's average values. We provide a precise analysis of how training models using anonymous cluster centers affects their generalization capabilities. We focus on an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT) and allows us to theoretically understand the role of different model components on the generalization error. In addition, we demonstrate that in certain high-dimensional regimes, training over anonymous cluster centers acts as a regularization and improves generalization error of the trained models. Finally, we corroborate our asymptotic theory with finite-sample numerical experiments where we observe a perfect match when the sample size is only of order of a few hundreds.

## 1 Introduction

Look-alike modeling in machine learning encompasses a range of techniques that focus on identifying users who possess similar characteristics, behaviors, or preferences to a specific target individual. This approach primarily relies on the principle that individuals with shared attributes are likely to exhibit comparable interests and behaviors. By analyzing the behavior of these look-alike users, look-alike modeling enables accurate predictions for the target user. This technique has been widely used in various domains, including targeted marketing and personalized recommendations, where it plays a crucial role in enhancing user experiences and driving tailored outcomes [26; 19; 18; 21].

In this paper, we use look-alike clustering for a different purpose, namely to anonymize sensitive information of users. Consider a supervised regression setup where the training set contains \(n\) pairs \((_{i},_{i})\), for \(i[n]\), with \(y_{i}\) denoting the response and \(_{i}^{d}\) representing a high-dimensional vector of features. We consider two groups of features: sensitive features, which contain some personal information about users and should be protected from the leaner, and the non-sensitive features. We assume that that the learner has access to a clustering structure on users, which is non-private information (e.g. based on non-sensitive features or other non-sensitive data set on users).

We propose a look-alike clustering approach, where we anonymize the individuals' sensitive features by replacing them with the cluster's average values. Only the anonymized dataset will be shared with the learner who then uses it to train a model. We refer to Figure 1 for an illustration of this approach. Note that the learner never gets access to the individuals' sensitive features and so this approach is safe from re-identification attacks where the learner is given access to the pool of individuals' sensitive information (up to permutation) and may use the non-sensitive features to re-identify theusers. Also note that since a common representation (average sensitive features) is used for all the users in a cluster, this approach offers \(m\)-anonymity provided that each cluster is of size at least \(m\) (minimum size clustering).

Minimum size clustering has received an increased attention mainly as a tool for anonymization and when privacy considerations are in place [7; 2; 3]. A particular application is for providing anonymity for user targeting in online advertising with the goal of replacing the use of third-party cookies with a more privacy-respecting entity . There are a variety of approximation algorithms for clustering with minimum size constraint [23; 9; 1; 24], as well as parallel and dynamic implementation .

In this paper, we focus on linear regression and derive a precise characterization of model generalization1 using the look-alike clustering approach, in the so-called _proportional regime_ where the size of training set grows in proportion to the number of parameters (which for the linear regression is equal to the number of features). The proportional regime has attracted a significant attention as overparametrized models have become greatly prevalent. It allows to understand the effect under/overparametrization in feature-rich models, providing insights to several intriguing phenomena, including double-descent behavior in the generalization error [22; 8; 14].

Our precise asymptotic theory allows us to demystify the effect of different factors on the model generalization under look-alike clustering, such as the role of cluster size, number of clusters, signal-to-noise ratio of the model as well as the strength of sensitive and non-sensitive features. A key tool in our analysis is a powerful extension of Gordon's Gaussian process inequality  known as the Convex Gaussian Minimax Theorem (CGMT), which was developed in  and has been used for studying different learning problems; see e.g, [29; 8; 15; 14; 16].

Initially, it might be presumed that look-alike clustering would hinder model generalization by suppressing sensitive features of individuals, suggesting a possible tradeoff between anonymity (privacy) and model performance. However, our analysis uncovers scenarios in which look-alike clustering actually enhances model generalization! We will develop further insights on these results by arguing that the proposed look-alike clustering can serve as a form of regularization, mitigating model overfitting and consequently improving the model generalization.

Before summarizing our key contributions in this paper, we conclude this section by discussing some of the recent work on the tradeoff between privacy and model generalization at large. An approach to study such potential tradeoff is via the lens of memorization. Modern deep neural networks, with remarkable generalization property, operate in the overparametrized regime where there are more tunable parameters than the number of training samples. Such overparametrized models tend to interpolate the training data and are known to fit well even random labels [34; 33]. Similar phenomenon has been observed in other models, such as random forest , Adaboost [25; 32], and kernel methods [5; 17]. Beyond label memorization,  studies setting where learning algorithms with near-optimal generalization must encode most of the information about the entire high-dimensional (and high-entropy) covariates of the training examples. Clearly, memorization of training data imposes significant privacy risks when this data contains sensitive personal information, and therefore these results hint to a potential trade-off between privacy protection and model generalization [27; 12; 20]. Lastly,  studies settings where data is sampled from a mixture of subpopulations, and shows that label memorization is _necessary_ for achieving near-optimal generalization error, whenever the

Figure 1: Schematic illustration of look-alike clustering on features data. Within each cluster, the sensitive features of users are replaced by a common look-alike representation (center of the cluster). In this example, \(_{1}\), \(_{2}\), \(_{3}\) represent the average of the sensitive features vectors for users in cluster 1, 2, 3.

distribution of subpopulation frequencies is long-tailed. Intuitively, this corresponds to datasets with many small distinct subpopulations. In order to predict more accurately on a subpopulation from which only a very few examples are observed, the algorithm needs to memorize their labels.

### Summary of contributions

We consider a linear regression setting for response variable \(y\) given feature \(\), and posit a Gaussian Mixture Model on the features to model the clustering structure on the samples. We focus on the high-dimensional asymptotic regime where the number of training samples \(n\), the dimension of sensitive features (\(p\)), and the dimension of non-sensitive features (\(d-p\)) grow in proportion (\(p/n_{p}\) and \(d/n_{d}\), for some constants \(0<_{p}_{d}\)). Asymptotic analysis in this particular regime, characterized by a fixed sample size to feature size ratio, has recently garnered significant attention due to its relevance to the regime where modern neural networks operate. This analysis allows for the study of various intriguing phenomena related to both statistical properties (such as double-descent) and the tractability of optimizing the learning process in such networks , where the population analysis \(n/d\) fails to capture. Let \(^{n}=\{(_{i},y_{i}),i[n]\}\) denote the (unanonymized) training set and \(^{n}_{L}\) be the set obtained after replacing the sensitive features with the look-alike representations of clusters. We denote by \(}\) and \(}_{L}\) the min-norm estimators fit to \(^{n}\) and \(^{n}_{L}\), respectively. Under this asymptotic setting:

* We provide a precise characterization of the generalization error of \(}\) and \(}_{L}\). Despite the randomness in data generating model, we show that in the high-dimensional asymptotic, the generalization errors of these estimators converge in probability to deterministic limits for which we provide explicit expressions.
* Our characterizations reveal several interesting facts about the generalization of the estimators: 1. For the min-norm estimator \(}\) we observe significantly different behavior in the underparametrized regime (\(_{d} 1\)) than in the overparametrized regime (\(_{d}>1\)). Note that in the underparametrized regime, the min-norm estimator coincides with the standard least squares estimator. For the look-alike estimator \(}_{L}\) our analysis identifies the underparametrized regime as \(_{d}-_{p} 1\) and the overparametrized regime as \(_{d}-_{p}>1\). 2. In the underparametrized regime, our analysis shows that, somewhat surprisingly, the generalization error (for both estimators) does not depend on the number or size of the clusters, nor the scaling of the cluster centers. 3. In the overparametrized regime, our analysis provides a precise understanding of the role of different factors, including the number of clusters, energy of cluster centers, and the alignment of the model with the constellation of cluster centers, on the generalization error.
* Using our characterizations, we discuss settings where the look-alike estimator \(}_{L}\) has better generalization than its non-private counterpart \(}\). A relevant quantity that shows up in our analysis is the ratio of the norm of the model component on the sensitive features over the noise in the response, which we refer to as signal-to-noise ratio (SNR). Using our theory, we show that if SNR is below a certain threshold, then look-alike estimator \(}_{L}\) has lower generalization error than \(}\). This demonstrates scenarios where anonymizing sensitive features via look-alike clustering does 'not' hinder model generalization. We give an interpretation for this result, after Theorem 5.1, by arguing that at low-SNR, look-alike clustering acts as a regularization and mitigates overfitting, which consequently improves model generalization.
* In our analysis in the previous parts, we assume that the learner has access to the exact underlying clustering structure on the users, to disentangle the clustering estimation error from look-alike modeling. However, in practice the learner needs to estimate the clustering structure from data. In Section 3.2, we combine our analysis with a perturbation analysis to extend our results to the case of imperfect clustering estimation.

Due to space constraint, we refer to the supplementary material for an overview of our proof techniques as well as proof of theorems and technical lemmas.

Model

We consider a linear regression setting, where we are given \(n\) i.i.d pairs \((_{i},y_{i})\), where the response \(y_{i}\) is given by

\[y_{i}=_{i},_{0}+_{i}, _{i}(0,^{2}).\] (2.1)

We assume that there is a clustering structure on features \(_{i}\), \(i[n]\), independent from the responses. We model this structure via Gaussian-Mixture model.

**Gaussian-Mixture Model (GMM) on features.** Each example \(\) belong to cluster \([k]\), with probability \(_{}\). We let \(=[,_{2},,_{k}]^{k}\) with \( 0\) and \(^{}=1\). The cluster conditional distribution of an example \(\) in cluster \(\) follows an isotropic Gaussian with mean \(_{}^{d}\), namely

\[=_{}+,(, ^{2}).\] (2.2)

By scaling the model (2.1), without loss of generality we assume \(=1\). Writing in the matrix form, we let

\[=_{1}|_{2}||_{n} ^{d n},=(y_{1},,y_{n})^{n}, =_{1}|_{2}||_{k} ^{d k}\,.\] (2.3)

It is also convenient to encode the cluster membership as one-hot encoded vectors \(_{i}^{k}\), where \(_{i}\) is one at entry \(\) (with \(\) being the cluster of example \(_{i}\)) and zero everywhere else. The GMM can then be written as

\[=+\,,\] (2.4)

with \(^{d n}\) is a Gaussian matrix with i.i.d \((0,1)\) entries, and \(^{k n}\) is the matrix obtained by stacking vectors \(_{i}\) as its column.

**Sensitive and non-sensitive features.** We assume that some of the features are sensitive for which we have some reservation to share with the learner and some non-sensitive features. Without loss of generality, we write it as \(=(_{},_{})\), where \(_{}^{p}\) representing the sensitive features and \(_{}^{d-p}\) representing the non-sensitive features. We also decompose the model \(_{0}\) (2.1) as \(_{0}=(_{0,},_{0,})\) with \(_{0,}^{p}\) and \(_{0,}^{d-p}\). Likewise, the cluster mean vector \(\) is decomposed as \(=(_{},_{})\). The idea of look-alike clustering is to replace the sensitive features of an example \(_{}\) with the center of its cluster \(_{}\). This way, if each cluster is of size at least \(m\), then look-alike clustering offers \(m\)-anonymity.

Our goal in this paper is to precisely characterize the effect of look-alike clustering on model generalization. We focus on the high-dimensional asymptotic regime, where the number of training data \(n\), and features sizes \(d,p\) grow in proportion.

We formalize the high-dimensional asymptotic setting in the assumption below:

**Assumption 1**: _We assume that the number of clusters \(k\) is fixed and focus on the asymptotic regime where \(n,d,p\) at a fixed ratio \(d/n_{d}\) and \(p/n_{p}\)._

To study the generalization of a model \(\) (performance on unseen data) via the _out-of-sample prediction risk_ defined as \(():=(y-^{} )^{2}\), where \((y,)\) is generated according to (2.1). Our next lemma characterizes the risk when the feature \(\) is drawn from GMM.

**Lemma 2.1**: _Under the linear response model (2.1) and a GMM for features \(\), the out-of-sample prediction risk of a model \(\) is given by_

\[()=^{2}+\|_{0}-\|_{_{2}}^{2}+(_{0}-)^{ }()^{}(_{0}- )\,.\]

The proof of Lemma 2.1 is deferred to the supplementary.

## 3 Main results

Consider the minimum \(_{2}\) norm (min-norm) least squares regression estimator of \(\) on \(\) defined by

\[}=(^{})^{}\,,\] (3.1)where \((^{})^{}\) denotes the Moore-Penrose pseudoinverse of \(^{}\). This estimator can also be formulated as

\[}}=\{\| \|_{_{2}}:\,\|-^{} \|_{_{2}}\}\,.\]

We also define the "look-alike estimator" denoted by \(}_{L}\), where the sensitive features are first anonymized via look-like modeling, and then the min-norm estimator is computed based on the resulting features. Specifically the sensitive feature \(_{}\) of each sample is replaced by the center of its cluster. In our notation, writing \(^{}=[_{}^{},_{}^{ }]\), we define \(_{L}^{}=[(_{})^{},_{}^{}]\) the features matrix obtained after look-alike modeling on the sensitive features. The look-alike estimator is then given by

\[}_{L}=(_{L}_{L}^{})^{}_ {L}\,,\] (3.2)

Our main result is to provide a precise characterization of the risk of look-alike estimator \(}_{L}\) as well as \(}\) (non-look-alike) in the asymptotic regime, as described in Assumption 1. We then discuss regimes where look-alike clustering offers better generalization.

As our analysis shows there are two majorly different setting in the behavior of the look-alike estimator: \((i)\)\(_{d}-_{p} 1\), i.e., the sample size \(n\) is asymptotically larger than \(d-p\), the number of non-sensitive features (referred to as _underparametrized_ asymptotics); \((ii)\)\(_{d}-_{p} 1\), which is referred to as _overparametrized_ asymptotics.

Our first theorem is on the risk of look-alike estimator in the underparametrized setting. To present our result, we consider the following singular value decomposition for \(_{}\), the matrix of cluster centers restricted to sensitive features:

\[_{}=_{}_{}_{}^{ },_{}^{p r},_{ {s}}^{r r},_{}^{k r}\,, r=(_{}) k.\]

**Theorem 3.1**: _(**Look-alike estimator, underparametrized regime**) Consider the linear response model (2.1), where the features are coming from the GMM (2.4). Also assume that \(\|_{0,}\|=r_{}\) and \(\|_{}^{}_{0,}\|=r_{}\), for all \(n,p\). Under Assumption 1 with \(_{d}-_{p} 1\), the out-of-sample prediction risk of look-alike estimator \(}_{L}\), defined by (3.2), converges in probability,_

\[(}_{L})}+r_{}^{2}}{1-(_{d}-_{p})}- r_{}^{2}\,.\]

There are several intriguing observations about this result. In the underparametrized regime:

1. The risk depends on \(_{0,}\) (model component on the sensitive features), only through the norms \(\|_{0,}\|=r_{}\) and \(\|_{}^{}_{0,}\|=r_{}\). Note that \(\|_{}^{}_{0,}\|\) measures the alignment of the model with the left singular vectors of the cluster centers.
2. The cluster structure on the non-sensitive features plays no role in the risk, nor does \(_{0,}\) the model component corresponding to the non-sensitive features.
3. The cluster prior probabilities \(\) does not impact the risk.

We next proceed to the overparametrized setting. For technical convenience, we make some simplifying assumption, however, we believe a similar derivation can be obtained for the general case, albeit with a more involved analysis.

**Assumption 2**: _Suppose that there is no cluster structure on the non-sensitive features (\(_{}=\)). Also, assume orthogonal, equal energy centers for the clusters on the sensitive features (\(_{}=_{}\) with \(_{}^{}_{}=_{}\))._

Our next theorem characterizes the risk of look-alike estimator in the underparametrized regime.

**Theorem 3.2**: _(**Look-alike estimator, overparametrized regime**) Consider the linear response model (2.1), where the features are coming from the GMM (2.4). Also assume that \(\|_{0,}\|=r_{}\), \(\|_{0,}\|=r_{}\) and \(\|_{}^{}_{0,}\|=r_{}\) for all \(n,p,d\). Under Assumption 1 with \(_{d}-_{p} 1\), and Assumption 2, the out-of-sample prediction risk of look-alike estimator \(}_{L}\), defined by (3.2), converges in probability,_

\[(}_{L})}^{ 2}+(1-)r_{}^{2}+_{0}^{2}+^{}(+ ^{2}())\,,\] (3.3)_where \(=(_{1},,_{k})\) encodes the cluster priors and \(_{0}\) and \(^{k}\) are given by the following relations:_

\[ = (+()}{_{d}-_{p} -1})^{-1}_{}^{}_{0,}\,,\] \[_{0}^{2} = -_{p}-1}(^{2}+r_{}^{2}+ ^{2}^{}())+(1- -_{p}})r_{}^{2}\,.\]

As discussed in the introduction, one of the focal interest in this work is to understand cases where look-alike modeling improves generalization. In Section 5 we discuss this by comparing the look-alike estimator \(}_{L}\) with the min-norm estimator \(}\), given by (3.1) which utilizes the full information on the sensitive features. In order to do that, we next derive a precise characterization of the risk of \(}\) in the asymptotic setting.

**Theorem 3.3**: _(_**min-norm estimator with no look-alike clustering**_) Consider the linear response model (2.1), where the features are coming from the GMM (2.4). Under Assumption 1, the followings hold for the min-norm estimator \(}\) given by (3.1):_

1. _(underparametrized setting) If_ \(_{d} 1\)_, we have_ \[(})}{}}{1-_{d}}\,.\]
2. _(overparametrized setting) If_ \(_{d} 1\)_, under Assumption_ 2_, the prediction risk of_ \(}\) _converges in probability_ \[(})}{}^ {2}+_{0}^{2}+}^{}(+^{2} ())}\,,\] (3.4) _where_ \(_{0}\) _and_ \(}\) _are given by the following relations:_ \[} = (++^{2}()}{_{d} -1})^{-1}_{}^{}_{0,}\,,\] \[_{0}^{2} = -1}(^{2}+}^{ }(+^{2}())})+ (1-})((1-)r_{}^{2}+r_{ }^{2}).\]

**Example 3.1**: _(Balanced clusters) In the case of equal cluster prior (\(_{1}==_{k}=1/k\)), the risk characterization (3.3) depends on \(\) only through \(||_{_{2}}\) (and likewise, the risk (3.4) depends on \(}\) only through its norm). This significantly simplifies these characterizations._

### Extension to imperfect clustering estimation

In our previous results, we assumed that the underlying cluster memberships of users are known to the learner, so we could concentrate our analysis on the impact of training using anonymous cluster centers. However, in practice, clusters should be estimated from the features and thus includes an estimation error. In our next result, we combine our previous result with a perturbation analysis to bound the risk of the look-alike estimator based on estimated clusters.

Recall matrix \(^{d k}\) from (2.3), whose columns are the cluster centers. Also, recall the matrix \(^{k n}\) whose columns are the one-hot encoding of the cluster memberships. We let \(}\) and \(}\) indicate the estimated matrices, with the cluster estimation error rate \(_{n}:=}\|_{s}-}_{s} }\|_{2}\), where \(\|\|_{2}\) indicates spectral norm. Note that only the cluster estimation error with respect to the sensitive features matters because in the look-alike modeling only those features are anonymized (replaced by the cluster centers).

**Proposition 3.4**: _Let \(}^{}:=[(}_{s}})^{},_{}^{}]\) be the feature matrix after replacing the sensitive features with the estimated cluster centers of users. We also let \(}_{L}=(}_{L}}_{L}^{ })^{}}_{L}\) be the look-alike estimator based on \(}_{L}\). Note that \(}_{L}\) is the counterpart of \(}_{L}\) given by (3.2). Define the cluster estimation error rate \(_{n}:=}\|}_{s}-}_{s}}\|_{2}\), and suppose that either of the following conditions hold:_* _(i)_ \(_{d}-_{p}<0.5\) _and_ \(<-_{p})}--_{p}}\)_._
* _(ii)_ \(_{d}-_{p}>2\) _and_ \(<-_{p}-1}-1\)_._

_Then,_

\[(}_{L})(}_{L})+C\,,\]

_for some constant \(C\) depending on the problem parameters._

## 4 Numerical experiments

In this section, we validate our theory with numerical experiments. We consider GMM with \(k\) clusters, where the centers of clusters are given by \(_{}\), for \([k]\), where \(_{}^{d}\) are of unit \(_{2}\)-norm. Also the vectors \(_{}\) are non-zero only on the first \(p\) entries, and their restriction to these entries form a random orthogonal constellation. Therefore, defining \(=[_{1},,_{k}]\), we have \(=[_{}\\ ]\), with \(_{}^{}_{}=_{k}\). In this setting there is no cluster structure on the non-sensitive features and the cluster centers on the sensitive features are orthogonal and of same norm.

Recall the decomposition of the model \(_{0}=(_{0,},_{0,})\), with \(_{0}\) the true underlying model (2.1) and \(_{0,}\), \(_{0,}\) the components corresponding to sensitive and non-sensitive features. We generate \(_{0,}^{d-p}\) to have i.i.d standard normal entries and then normalize it to have \(|_{0,}|_{_{2}}=r_{}\). For \(_{0,}\), we generate \(_{1},_{2}(_{p},_{p})\), independently and let

\[_{0,}=r_{}\ _{_{ }}_{1}}{|_{_{}}_{1} |_{_{2}}}+r_{}\ -_{_{ }})_{2}}{|(-_{_{}})_ {2}|_{_{2}}}\,,\]

where \(_{_{}}:=_{}_{}^{ }\) is the projection onto column space of \(_{}\). Therefore, \(|_{0,}|_{_{2}}=r_{}\) and \(\|_{}^{}_{0,}\|_{ _{2}}=r_{}\). Note that \(\) quantifies the alignment of the model with the cluster centers, confined to the sensitive features.)

We will vary the values of \(r_{}\) and \(r_{}\) in our experiments. We also consider the case of balanced clusters, so the cluster prior probabilities are all equal, \(_{}=1/k\), for \([k]\). We set the number of

Figure 2: Validation of theoretical characterizations of the risks. Curves correspond to (asymptotic) analytical predictions, and dots to numerical simulations (averaged over 20 realizations). In all the plots, \(d=500\), \(p=200\), \(=5\), \(k=3\), \(=0.3\). Left panel corresponds to the risk of \(}_{L}\) and right panel corresponds to the risk of \(}\).

cluster \(k=3\), dimension of sensitive features \(p=200\) and the dimension of entire features vector \(d=500\). We also set \(=5\) and \(=0.3\). In our experiments, we vary the sample size \(n\) and plot the risk of \(}_{L}\) and \(}\) versus \(_{d}-_{p}=(d-p)/n\). We consider different settings, where we vary \(r_{}\), \(r_{}\) and \(\) (noise variance in model (2.1)). In Figure 2, we report the results. Curves correspond to our asymptotic theory and dots to the numerical simulations. (Each dot is obtained by averaging over 20 realizations of that configuration.) As we observe, in all scenarios our theoretical predictions are a perfect match to the empirical performance.

## 5 When does look-alike clustering improve generalization?

In Section 3, we provided a precise characterization of the risk of look-alike estimator \(}_{L}\) and its counterpart, the min-norm estimator \(}\) which utilizes the full information on the sensitive features. By virtue of these characterizations, we would like to understand regimes where the look-alike clustering helps with the model generalization, and the role of different problem parameters in achieving this improvement. Notably, since the look-alike estimator offers \(m\)-anonymity on the sensitive features (with \(m\) the minimum size of clusters), our discussion here points out instances where data anonymization and model generalization are not in-conflict.

We define the gain of look-alike estimator as \(:=(})/(}_{L})\) to indicate the gain obtained in generalization via look-alike clustering. For ease in presentation, we focus on the case of balanced clusters (equal priors \(_{1}==_{k}=1/k\)), and consider three cases:

\(\)**Case 1 (\(_{d} 1\)):** In this case, both \(}_{L}\) and \(}\) are in the underparametrized regime and Theorems 3.1 and 3.3 (a) provide simple closed-form characterization of the risks of \(}_{L}\) and \(}\), by which we obtain

\[}}{{}})^{-1}}{(1 +r_{}^{2}/^{2})(1-_{d}+_{p})^{-1}- r_{}^{2}/ ^{2}}\,.\]

Define the signal-to-noise ratio \(=r_{}/\). Since \( 1\), it is easy to see that \(\) is decreasing in the SNR. In particular, as SNR\( 0\), we have \((1-_{d}+_{p})/(1-_{d})>1\), which means the look-alike estimator \(}_{L}\) achieves lower risk compared to \(}\). In Figure 2(a) we plot \(()\) versus SNR, for several values of \(_{p}\). Here we set \(_{d}=0.9\) and \(=0.3\). As we observe in low SNR, the look-alike estimator has lower risk. Specifically, for each curve there is a threshold for the SNR, below which \(()>0\). Furthermore, this threshold increases with \(_{p}\), covering a larger range of SNR where \(}_{L}\) has better generalization.

In Figure 2(b) we report similar curves, where this time \(_{p}=0.5\) and we consider several values of \(\). As we observe, at fixed SNR the gain \(\) is increasing in \(\). This is expected since \(\) measures the alignment of the underlying model \(_{0}\) with the (left eigenvectors of) cluster centers and so higher \(\) is to advantage of the look-alike estimator which uses the cluster centers instead of individuals' sensitive features.

\(\) **Case 2 (\(_{d} 1,_{d}-_{p} 1\)):** In this case, the look-alike estimator \(}_{L}\) is in the underparametrized regime, while the min-norm \(}\) is in the overparametrized regime. The following theorem uses the characterizations in Theorem 3.1 and and 3.3 (b), and shows that in the low SNR\(=r_{ s}/\), the look-alike estimator \(}_{L}\) has a positive gain. It further shows the monotonicity of the gain with respect to different problem parameters.

**Theorem 5.1**: _Suppose that \(_{d} 1\) and \(_{d}-_{p} 1\), and consider the case of equal cluster priors. The gain \(\) is increasing in \(r_{ ns}\) and \(\), and is decreasing in \(^{2}/k\). Furthermore, under the following condition_

\[{ SNR}^{2}:=(}{})^{2}-1)^{-1}-(1-_{d}+_{p})^{-1}}{(1-_{d }+_{p})^{-1}+_{d}^{-1}-1}\,,\] (5.1)

_we have \( 1\), for all values of other parameters (\(,k,,r_{ ns}\))._

**An interpretation based on regularization:** We next provide an argument to build further insight on the result of Theorem 5.1. Recall the data model (2.1), where substituting from (2.2) and decomposing over sensitive and non-sensitive features we arrive at

\[y =_{ s},_{ s}+_{  ns},_{ ns}+\] \[=_{ s},_{ s}+ _{ s},_{ s}+_{ ns},_{ ns }+\,.\]

Note that \(_{ s},_{ s}(0,_{ s}^{2})\). At low SNR, this term is of order of the noise term \((0,^{2})\). Recall that the look-alike clustering approach replaces the sensitive feature \(_{ s}\) by the cluster center \(_{ s}\), and therefore drops the term \(_{ s},_{ s}\) from the model during the training process. In other words, look-alike clustering acts as a form of regularization which prevents overfitting to the noisy component \(_{ s},_{ s}\), and this will help with the model generalization, together with anonymizing the sensitive features.

In Figure 3(a) we plot \(()\) versus \(\) for several values of \(r_{ ns}\). Here, \(_{d}=2\), \(_{p}=1.7\), \(=1\), \(r_{ s}=0.5\) and so condition (5.1) holds. As we observe \(()\) is positive, decreasing in \(\) and also at any fixed \(\), it is increasing in \(r_{ ns}\), all of which are consistent with the Theorem 5.1. In Figure 3(b), we plot similar curves where this time \(r_{ ns}=0.2\) and we try several values of \(\). As we see the look-alike estimator has larger gain \(\) at larger values of \(\).

\(\) **Case 3 (\(_{d}-_{p} 1\)):** In this case, both \(}_{L}\) and \(}\) are in the overparametrized regime. Let us first focus on \(r_{ ns}\), the energy of the model on the non-sensitive features. Invoking the equations (3.3) and (3.4) and hiding the terms that do not depend on \(r_{ ns}\) in constants \(C_{1}\), \(C_{2}\) we arrive at

\[)}}{{}}+(1-})r_{ ns}^{2}}{C_{2}+(1--_{p}})r_{ ns}^{2}}\,.\]

Therefore, \(_{r_{ ns}}=(1-_{d}^{-1})/(1-(_{d}-_{p})^{-1} )>1\), indicating a gain for the look-alike estimator over \(}\). In Figure 4(a), we plot \(()\) versus \(r_{ ns}\) for several values of \(_{p}\). As we observe, when \(r_{ ns}\) is large enough we always have a gain, which is increasing in \(_{p}\).

We next consider the effect of SNR = \(r_{}/\). In Figure 4(b) we \(()\) versus SNR, for several values of \(_{p}\). Similar to the underparametrized regime, we observe that in low SNR, the look-alike estimator has better generalization \((()>0)\).

## 6 Beyond linear models

In previous section, we used our theory for linear models to show that at low SNR, look-alike modeling improves model generalization. We also provided an insight for this phenomenon by arguing that look-alike modeling acts as a form of regularization and avoids over-fitting at low SNR regime. In this section we show empirically that this phenomenon also extends to non-linear models.

Consider the following data generative model:

\[y(N,p_{}), p_{}=,_{0})+)}\,,\]

where \((0,^{2})\). We construct the model \(_{0}=(_{0,},_{0,})\) similar to the setup in Section 4. We set \(n=200\), \(d=180\), \(k=3\), \(=5\), \(=1\), \(=0.3\), \(r_{}=2\) and \(N=1000\) (number of trials in Binomial distribution). We vary SNR by changing \(r_{}\) in the set \(\{0.1,0.3,,1.9\}\). The estimators \(}\) and \(}_{L}\) are obtained by fitting a GLM with logit link function and binomial distribution. We compute the risks of \(}\) and \(}_{L}\) by averaging over a test set of size \(50K\). In Figure 6, we plot the gain \(()\) versus \(r_{}\) where each data point is by averaging over \(50\) different realizations of data. As we observe at low SNR, \(()>0\) indicating that the look-alike estimator \(}_{L}\) obtains a lower risk than the min-norm estimator.

Figure 6: Behavior of gain \(\) versus SNR for the nonlinear model described in Section 6. At small SNR, we observe a positive gain (lower risk of look-alike estimator \(}_{L}\) compared to \(}\)).