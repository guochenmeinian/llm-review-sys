# PageRank Bandits for Link Prediction

Yikun Ban\({}^{1}\)1, Jiaru Zou\({}^{1}\)1, Zihao Li\({}^{1}\), Yunzhe Qi\({}^{1}\), Dongqi Fu\({}^{2}\), Jian Kang\({}^{3}\),

**Hanghang Tong\({}^{1}\), Jingrui He\({}^{1}\)**

\({}^{1}\)University of Illinois Urbana-Champaign, \({}^{2}\)Meta AI, \({}^{3}\)University of Rochester

\({}^{1}\){yikunb2, jiaruz2, ziahoali5, yuzheq2, htong, jingrui}@illinois.edu

\({}^{2}\)dongqifu@meta.com, \({}^{3}\)jian.kang@rochester.edu

Equal contribution.

###### Abstract

Link prediction is a critical problem in graph learning with broad applications such as recommender systems and knowledge graph completion. Numerous research efforts have been directed at solving this problem, including approaches based on similarity metrics and Graph Neural Networks (GNN). However, most existing solutions are still rooted in conventional supervised learning, which makes it challenging to adapt over time to changing customer interests and to address the inherent dilemma of exploitation versus exploration in link prediction. To tackle these challenges, this paper reformulates link prediction as a sequential decision-making process, where each link prediction interaction occurs sequentially. We propose a novel fusion algorithm, PRB (PageRank Bandits), which is the first to combine contextual bandits with PageRank for collaborative exploitation and exploration. We also introduce a new reward formulation and provide a theoretical performance guarantee for PRB. Finally, we extensively evaluate PRB in both online and offline settings, comparing it with bandit-based and graph-based methods. The empirical success of PRB demonstrates the value of the proposed fusion approach. Our code is released at https://github.com/jiaruzouu/PRB

## 1 Introduction

Link prediction is an essential problem in graph machine learning, focusing on predicting whether a link will exist between two nodes. Given the ubiquitous graph data in real-world applications, link prediction has become a powerful tool in domains such as recommender systems  and knowledge graph completion [49; 41]. Considerable research efforts have been dedicated to solving this problem. One type of classic research approaches is heuristic-based methods, which infer the likelihood of links based on node similarity metrics [43; 46]. Graph Neural Networks (GNNs) have been widely utilized for link prediction. For example, Graph Autoencoders leverage Message Passing Neural Network (MPNN) representations to predict links . Recently, MPNNs have been combined with structural features to better explore pairwise relations between target nodes [73; 70; 18; 61].

Existing supervised-learning-based methods for link prediction are designed for either the static [73; 70; 18; 61] or relatively dynamic environment [64; 55; 62; 58; 69; 19; 27; 26; 75], they (chronologically) split the dataset into training and testing sets. Due to the dynamic and evolving nature of many real-world graphs, ideal link prediction methods should adapt over time to consistently meet the contexts and goals of the serving nodes. For instance, in short-video recommender systems, both video content and user preferences change dynamically over time . Another significant challenge is the dilemma of exploitation and exploration in link prediction. The learner must not only exploit past collected data to predict links with high likelihood but also explore lower-confidence target nodes to acquire new knowledge for long-term benefits. For example, in social recommendations, itis necessary to prioritize popular users by 'exploiting' knowledge gained from previous interactions, while also'exploring' potential value from new or under-explored users to seek long-term benefits . Furthermore, while existing works often analyze time and space complexity, they generally lack theoretical guarantees regarding the performance of link prediction. To address these challenges, in this paper, we make the following contributions:

**Problem Formulation and Algorithm**. We formulate the task of link prediction as sequential decision-making under the framework of contextual bandits, where each interaction of link prediction is regarded as one round of decision-making. We introduce a pseudo-regret metric to evaluate the performance of this decision process. More specifically, we propose a fusion algorithm named PRB (PageRank Bandits), which combines the exploitation and exploration balance of contextual bandits with the graph structure utilization of PageRank [59; 42]. Compared to contextual bandit approaches, PRB leverages graph connectivity for an aggregated representation. In contrast to PageRank, it incorporates the principles of exploitation and exploration from contextual bandits to achieve a collaborative trade-off. Additionally, we extend PRB to node classification by introducing a novel transformation from node classification to link prediction, thereby broadening the applicability of PRB.

**Theoretical Analysis**. We introduce a new formulation of the reward function to represent the mapping from both node contexts and graph connectivity to the reward. We provide one theoretical guarantee for the link prediction performance of the proposed algorithm, demonstrating that the cumulative regret induced by PRB can grow sub-linearly with respect to the number of rounds. This regret upper bound also provides insights into the relationship between the reward and damping factor, as well as the required realization complexity of the neural function class.

**Empirical Evaluation**. We extensively evaluate PRB in two mainstream settings. (1) Online Link Prediction. In this setting, each link prediction is made sequentially. In each round, given a serving node, the model is required to choose one target node that has the highest likelihood of forming a link with the serving node. The model then observes feedback and performs corresponding optimizations. The goal is to minimize regret over \(T\) rounds (e.g., \(T=10,000\)). We compare PRB with state-of-the-art (SOTA) bandit-based approaches (e.g., [76; 12]), which are designed for sequential decision-making. PRB significantly outperforms these bandit-based baselines, demonstrating the success of fusing contextual bandits with PageRank for collaborative exploitation and exploration. (2) Offline Link Prediction. In this setting, both training and testing data are provided, following the typical supervised learning process. Although PRB is designed for online learning, it can be directly applied to offline learning on the training data. We then use the trained model to perform link prediction on the testing data, comparing it with SOTA GNNs-based methods (e.g., [18; 61]). The superior performance of PRB indicates that principled exploitation and exploration can break the performance bottleneck in link prediction. Additionally, we conduct ablation and sensitivity studies for a comprehensive evaluation of PRB.

## 2 Related Work

**Contextual Bandits**. The first line of works studies the linear reward assumption, typically calculated using ridge regression [39; 8; 1; 60; 21; 53]. Linear UCB-based bandit algorithms [1; 9; 40] and linear Thompson Sampling [4; 2] can achieve satisfactory performance and a near-optimal regret bound of \(}()\). To learn general reward functions, deep neural networks have been adapted to bandits in various ways [10; 11]. [54; 47] develop \(L\)-layer DNNs to learn arm embeddings and apply Thompson Sampling on the final layer for exploration.  introduced the first provable neural-based contextual bandit algorithm with a UCB exploration strategy, and  later extended to the TS framework.  provides sharper regret upper bound for neural bandits with neural online regression. Their regret analysis builds on recent advances in the convergence theory of over-parameterized neural networks [24; 5] and uses the Neural Tangent Kernel [34; 6] to establish connections with linear contextual bandits . [12; 13] retains the powerful representation ability of neural networks to learn the reward function while using another neural network for exploration. [52; 51] integrates exploitation-exploration neural networks into the graph neural networks for fine-grained exploration and exploration. Recently, neural bandits have been adapted to solve other learning problems, such as active learning[14; 7], meta learning.

**Link Prediction Models.** Three primary approaches have been identified for link prediction models. Node embedding methods, as described by previous work [50; 30; 57; 23; 44; 45; 25], focus on mapping each node to an embedding vector and leveraging these embeddings to predict connections. Another approach involves link prediction heuristics, as explored by [43; 15; 3; 77], which utilize crafted structural features and network topology to estimate the likelihood of connections between nodes in a network. The third category employs GNNs for predicting link existence; notable is the Graph Autoencoder (GAE) , which learns low-dimensional representations of graph-structured data through an unsupervised learning process. GAE utilizes the inner product of MPNN representations of target nodes to forecast links but might not capture pairwise relations between nodes effectively. More sophisticated GNN models that combine MPNN with additional structural features, such as those by [71; 70; 18], have demonstrated superior performance by integrating both node and structural attributes. One such combined architecture is SF-then-MPNN, as adopted by [71; 78]. In this approach, the input graph is first enriched with structural features (SF) and then processed by the MPNN to enhance its expressivity. However, since structural features change with each target link, the MPNN must be re-run for each link, reducing scalability. For instance, the SEAL model  first enhances node features by incorporating the shortest path distances and extracting k-hop subgraphs, then applies MPNN across these subgraphs to generate more comprehensive link representations. Another combined architecture is SF-and-MPNN. Models like Neo-GNN  and BUDDY  apply MPNN to the entire graph and concatenate features such as common neighbor counts to enhance representational fidelity. In addition,  has developed the Neural Common Neighbor with Completion (NCNC) which utilizes the MPNN-then-SF architecture to achieve higher expressivity and address the graph incompleteness.

Recently, representation learning on temporal graphs for link prediction has also been widely studied to exploit patterns in historical sequences, particularly with GNN-based methods [58; 69; 19; 64; 62; 55]. However, these approaches are still conventional supervised-learning-based methods that chronologically split the dataset into training and testing sets. Specifically, these methods train a GNN-based model on the temporal training data and then employ the trained model to predict links in the test data. In contrast, we formulate link predictions as sequential decision-making, where each link prediction is made sequentially. Node classification[16; 67; 66] is also a prominent direction in graph learning, but it is not the main focus of this paper.

## 3 Problem Definition

Let \(G_{0}=(V,E_{0})\) be an undirected graph at initialization, where \(V\) is the set of \(n\) nodes, \(|V|=n\), and \(E_{0} V V\) represents the set of edges. \(E_{0}\) can be an empty set in the cold-start setting or include some existing edges with a warm start. Each node \(v_{i} V\) is associated with a context vector \(x_{0,i}^{d}\). Then, we formulate link prediction as the problem of sequential decision-making under the framework of contextual bandits. Suppose the learner is required to finish a total of \(T\) link predictions. We adapt the above notation to all the evolving \(T\) graphs \(\{G_{t}=(V,E_{t})\}_{t=0}^{T-1}\) and let \([T]=\{1,,T\}\). In a round of link prediction \(t[T]\), given \(G_{t-1}=(V,E_{t-1})\), the learner is presented with a serving node \(v_{t} V\) and a set of \(k\) candidate nodes \(_{t}=\{v_{t,1},,v_{t,k}\} V\), where \(_{t}\) is associated with the corresponding \(k\) contexts \(_{t}=\{x_{t,1},,x_{t,k}\}\) and \(|_{t}|=k\). In the scenario of social recommendation, \(v_{t}\) can be considered as the user that the platform (learner) intends to recommend potential friends to, and the other candidate users will be represented by \(_{t}\). \(_{t}\) can be set as the remaining nodes \(_{t}=V_{t}/v_{t}\) or formed by some pre-selection algorithm \(_{t} V_{t}\).

The goal of the learner is to predict which node in \(_{t}\) will generate a link or edge with \(v_{t}\). Therefore, we can consider each node in \(_{t}\) as an arm, and aim to select the arm with the maximal reward or the arm with the maximal probability of generating an edge with \(v_{t}\). For simplicity, we define the reward of link prediction as the binary reward. Let \(v_{t,}_{t}\) be the node selected by the learner. Then, the corresponding reward is defined as \(r_{t,}=1\) if the link \([v_{t},v_{t,}]\) is really generated; otherwise, \(r_{t,}=0\). After observing the reward \(r_{t,}\), we update \(E_{t-1}\) to obtain the new edge set \(E_{t}\), and thus new \(G_{t}\).

For any node \(v_{t,i}_{t}\), denote by \(_{|x_{t,}}\) the conditional distribution of the random reward \(r_{t,i}\) with respect to \(x_{t,i}\), where \(=\{1,0\}\). Then, inspired by the literature of contextual bandits, we define the following _pseudo_ regret:

\[_{T}=_{t=1}^{T}(_{r_{t,} _{|x_{t,}}}[r_{t,}^{*}]-_{r_{t, }_{|x_{t,}}}[r_{t,}])= (r_{t,}=1|x_{t,})\] (3.1)

[MISSING_PAGE_FAIL:4]

the updated parameters of \(f_{2}\) for the next round of link prediction. The reasons for setting \((x_{t,i})\) as the input of \(f_{2}\) are as follows: (1) it incorporates the information of both \(x_{t,i}\) and discriminative ability of \(f_{1}(;^{1}_{t-1})\); (2) the statistical form of the confidence interval for reward estimation can be regarded as the mapping function from \((x_{t,i})\) to the potential gain, and \(f_{2}\) is to learn the unknown mapping .

The previous steps demonstrate the exploitation and exploration of node contexts to facilitate decision-making in link prediction. Since graph connectivity is also crucial, we next introduce our method of integrating the bandit principle with PageRank to enable collaborative exploitation and exploration. PageRank calculates the stationary distribution of the random walker starting from some node, iteratively moving to a random neighbor with probability \(\) (damping factor) or returning to its original position with probability \(1-\). Let \(_{t}\) be the stationary distribution vector calculated based on the graph \(G_{t}\). Then, \(_{t}\) satisfies:

\[_{t}=_{t}_{t}+(1-)\,_{t}\] (4.1)

where \(_{t}^{n n}\) is the transition matrix built on \(G_{t-1}\) and \(_{t}\) is typically regarded as a position vector to mark the starting node. \(_{t}\) is computed as \(_{t-1}^{-1}_{t-1}\), where \(_{t-1}^{n n}\) is the degree matrix of \(G_{t-1}\) and \(_{t-1}^{n n}\) is the adjacency matrix of \(G_{t-1}\).

Here we propose to use \(_{t}\) to include the starting exploitation and exploration scores of candidate nodes, defined as:

\[i_{t},_{t}[i]=f_{1}(x_{t,i};^{1}_{t-1})+f_{2}(x _{t,i};^{2}_{t-1}),\,i V/_{t},_{t}[i]=0.\] (4.2)

Therefore, \(_{t}\) is the vector for the final decision-making based on collaborative exploitation and exploration. Some research efforts have been devoted to accelerating the calculation of Eq.4.1 in the evolving graph, e.g., , which can be integrated into PRB (Line 9 in Algorithm 1) to boost its efficiency and scalability.

**PRB for Node Classification**. We also extend PRB to solve the problem of node classification as illustrated in Figure 1. Consider a \(k\)-class classification problem. We add \(k\) super nodes \(\{_{1},_{2},,_{k}\}\) to the graph, which represents \(k\) classes, respectively. Then, we transform the node classification problem into the link prediction problem, aiming to predict the link between the serving node and the \(k\) super nodes. To be specific, in round \(t[T]\), the learner is presented with the serving node \(v_{t}\) and the \(k\) candidate (super) nodes \(_{t}=\{_{1},_{2},,_{k}\}\) associated with \(k\) corresponding contexts \(_{t}=\{x_{t,1},x_{t,2},,x_{t,k}\}\). Recall \(x_{t}\) is the context associated with \(v_{t}\). Then, we define the contexts of super nodes as \(x_{t,1}=[x_{t}^{},,,]^{},x_{t,2}=[,x_{t}^{},,]^{},,x_{t,k}=[,,,x_{t}]^{}\), \(x_{t,i}^{kd},i[k]\). This context definition is adopted from neural contextual bandits . Then, the learner is required to select one node from \(_{t}\). Let \(_{i_{k}}\) be the selected node and \(_{i_{t}^{*}}\) be ground-truth node (\(i_{t}^{*}\) is the index of ground-truth class of node \(v_{t}\)). Then, after observing the reward \(r_{t,i_{t}}\), one edge \([v_{t},_{i_{t}}]\) is added to the graph \(G_{t-1}\), if \(v_{t}\) belongs to the class \(i_{t}\), i.e., \(i_{t}=i_{t}^{*}\) and reward \(r_{t,i_{t}}=1\). Otherwise, \(r_{t,i_{t}}=0\) and the edge \([v_{t},_{i_{t}^{*}}]\) is added to \(G_{t-1}\). Then, we can naturally apply PRB to this problem. We detail our extended algorithm for node classification in Algorithm 2.

Figure 1: **Transforming Node Classification to Link Prediction**. Consider a binary node classification problem. In the left figure, given a graph, the learner tries to classify node 4 into one of two classes. First, we add two supernodes to the graph, each representing one of the classes. The node classification problem is then transformed into predicting links between node 4 and the two supernodes in the right figure. Suppose the learner predicts that a link will exist between node 4 and supernode 0. If node 4 belongs to Class 0, the reward is 1, and an edge is added between node 4 and supernode 0; otherwise, the reward is 0, and an edge is added between node 4 and supernode 1.

**PRB Greedy.** We also introduce a greedy version of PRB which integrates PageRank solely with contextual bandit exploitation, as outlined in Algorithm 3. We will compare each variant of algorithms in our experiment section.

## 5 Regret Analysis

In this section, we provide the theoretical analysis of PRB by bounding the regret defined in Eq.3.1. One important step is the definition of the reward function, as this problem is different from the standard bandit setting that focuses on the arm (node) contexts and does not take into account the graph connectivity. First, we define the following general function to represent the mapping from the node contexts to the reward. Given the serving node \(v_{t}\) and an arm node \(v_{t,i} V_{t}\) associated with the context \(x_{t,i}\), the reward conditioned on \(v_{t}\) and \(v_{t,i}\) is assumed to be governed by the function:

\[[_{t,i}|v_{t},v_{t,i}]=y(x_{t,i})\] (5.1)

where \(y\) is an unknown but bounded function that can be either linear or non-linear. Next, we provide the formulation of the final reward function. In round \(t[T]\), let \(_{t}\) be the vector to represent the expected rewards of all candidate arms \(_{t}=[y(x_{t,i}):v_{t,i} V_{t}]\). Given the graph \(G_{t-1}\), its normalized adjacency matrix \(_{t}\), and the damping factor \(\), inspired by PageRank, the optimizing problem is defined as: \(_{t}^{*}=_{}^{}(- _{t})+(1-)\|-_{t}\|_{2}^{2}/2\). Then, its optimal solution is

\[_{t}^{*}=_{t}_{t}^{*}+(1-)\, _{t}.\] (5.2)

For any candidate node \(v_{t,i}_{t}\), we define its expected reward as \(_{r_{t,i}_{Y|v_{t,i}}}[r_{t,i}]=_{t}^{*}[i]\). \(_{t}^{*}\) is a flexible reward function that reflects the mapping relation of both node contexts and graph connectivity. \(\) is a hyper-parameter to trade-off between the leading role of graph connectivity and node contexts. When \(=0\), \(_{t}^{*}\) turns into the reward function in contextual bandits [76; 12]; when \(=1\), \(_{t}^{*}\) is the optimal solution solely for graph connectivity. Here, we assume \(\) is a prior knowledge. Finally, the pseudo-regret is defined as

\[_{T}=_{t=1}^{T}(_{t}^{*}[i^{*}]-_{t}^{* }[]).\] (5.3)

where \(i^{*}=_{v_{t,i}_{t}}_{t}^{*}[i]\) and \(\) is the index of the selected node. The regret analysis is associated with the Neural Tangent Kernel (NTK) matrix as follows:

**Definition 5.1** (Ntz [34; 63]).: _Let \(\) denote the normal distribution. Given all data instances \(\{x_{t}\}_{t=1}^{Tk}\), for \(i,j[Tk]\), define_

\[_{i,j}^{0}=_{i,j}^{0}= x_{i},x_{j}, \ \ _{i,j}^{l}=_{i,i}^{l}&_{i,j}^{l}\\ _{j,i}^{l}&_{j,j}^{l}\] \[_{i,j}^{l}=2_{a,b(, _{i,j}^{l-1}]}[(a)(b)],\] \[_{i,j}^{l}=2_{i,j}^{l-1}_{a,b (,_{i,j}^{l-1}]}[^{}(a)^{ }(b)]+_{i,j}^{l}.\]

_Then, the NTK matrix is defined as \(=(^{L}+^{L})/2\)._

**Assumption 5.1**.: There exists \(_{0}>0\), such that \(_{0}\).

The assumption 5.1 is generally made in the literature of neural bandits [76; 74; 20; 35; 12; 10; 65] to ensure the existence of a solution for NTK regression.

As the standard setting in contextual bandits, all node contexts are normalized to the unit length. Given \(x_{t,i}^{d}\) with \(\|x_{t,i}\|_{2}=1\), \(t[T],i[k]\), without loss of generality, we define a fully-connected network with depth \(L 2\) and width \(m\):

\[f(x_{t,i};)=_{L}(_{L-1}(_{L-2 }(_{1}x_{t,i})))\] (5.4)

where \(\) is the ReLU activation function, \(_{1}^{m d}\), \(_{l}^{m m}\), for \(2 l L-1\), \(^{L}^{1 m}\), and \(=[(_{1})^{},(_{2})^{}, ,(_{L})^{}]^{}^{p}\). Note that our analysis can also be readily generalized to other neural architectures such as CNNs and ResNet [5; 24]. We employ the following initialization  for \(\): For \(l[L-1]\), each entry of \(_{l}\) is drawn from the normal distribution \((0,2/m)\); each entry of \(_{L}\) is drawn from the normal distribution \((0,1/m)\). The network \(f_{1}\) and \(f_{2}\) follows the structure of \(f\). Define \(=[y(x_{t,i}):t[T],i[k]]\). Finally, we provide the performance guarantee as stated in the following Theorem.

**Theorem 5.1**.: _Given the number of rounds \(T\), for any \(,(0,1)\), suppose \(m((T,L) k(1/))\), \(_{1}=_{2}=}{}\) and set \(_{t,i}=r_{t,i},t[T],i[k]\). Then, with probability at least \(1-\) over the initialization, Algorithm 1 achieves the following regret upper bound:_

\[_{T}}(kT}),S^{2})}\] (5.5)

_where \(=+)}{(1+T)}\) and \(S=^{}^{-1}}\)._

Theorem 5.1 provides a regret upper bound for PRB with the complexity of \(}()\) (see proofs in Appendix E). Instead, the graph-based methods (e.g., [18; 61]) lack an upper bound in terms of their performance. Theorem 5.1 provides insightful results in terms of PRB's performance. First, PRB's regret can grow sub-linearly with respective to \(T\). Second, PRB's performance is affected by the number of nodes \(k\). This indicates the larger the graph is, the more difficult the link prediction problem is. Third, \(\) and \(S\) in the regret upper bound reflect the complexity of the required neural function class to realize the underlying reward function \(_{t}^{*}\), i.e., the difficulty of learning \(_{t}^{*}\). \(\) is the effective dimension, which measures the actual underlying dimension in the RKHS space spanned by NTK. \(S\) is to provide an upper bound on the optimal parameters in the context of NTK regression. Both \(\) and \(S\) are two complexity terms that commonly exist in the literature of neural contextual bandits[76; 74]. In the general case when \(1>>0\), learning \(_{t}^{*}\) proportionally turns into a bandit optimization problem and the upper bound provided in Theorem 5.1 matches the SOTA results in neural bandits [76; 74]. In fact, the regret upper bound is closely related to the graph structure of \(G_{t}\). In the special case when \(=1\), learning \(_{t}^{*}\) turns into a simple convex optimization problem (Eq. (4.1)) and PRB can really find the optimal solution, which leads to zero regrets. When \(=0\), the problem turns into a complete bandit optimization problem with the same regret upper bound as Theorem 5.1.

## 6 Experiments

In this section, we begin by conducting a comprehensive evaluation of our proposed method, PRB, compared with both bandit-based and graph-based baselines across online and offline link prediction settings. Then, we analyze the computational costs associated with each experiment and present additional ablation studies related to PRB. In the implementation of PRB, we adapt the efficient PageRank algorithm  to solve Eq. (4.1).

### Online Link Prediction

    & MovieLens & AmazonFashion & Facebook & GrQc \\   & Mean \(\) Std & Mean \(\) Std & Mean \(\) Std \\  EE-Net & 1638 \(\) 15.3 & 1698 \(\) 19.3 & 2274 \(\) 27.1 & 3419 \(\) 16.5 \\ NeuGreedy & 1955 \(\) 17.3 & 1952 \(\) 27.4 & 2601 \(\) 14.2 & 3629 \(\) 18.2 \\ NeuralUCB & 1737 \(\) 16.8 & 1913 \(\) 18.6 & 2190 \(\) 16.3 & 3719 \(\) 16.4 \\ NeuralTS & 1683 \(\) 14.7 & 2055 \(\) 21.9 & 2251 \(\) 19.5 & 3814 \(\) 23.3 \\ 
**PRB** & **1555 \(\) 21.7** & **1455 \(\) 18.4** & **1929 \(\) 17.0** & **3236 \(\) 18.5** \\   

Table 1: Cumulative regret of bandit-based methods on **online** link prediction.

Figure 2: Regret comparison of bandit-based methods on **online** link prediction datasets (average of 10 runs with standard deviation in shadow, detailed in Table 1).

In this sub-section, we evaluate PRB on the setting of online link prediction and node classification as described in Sec. 3, compared with bandit-based baselines.

**Datasets and Setups.** We use three categories of real-world datasets to compare PRB with bandit-based baselines. The details and experiment settings are as follows.

(1) Recommendation datasets: Movielens  and Amazon Fashion  (Bipartite Graph). Given the user set \(U\) and item set \(I\), let \(G_{0}\) be the graph with no edges, \(G_{0}=(V=U+I,E_{0}=)\). In round \(t[T]\), we randomly select a user \(v_{t} U\), and then randomly pick 100 items (arms) from \(I\), including \(v_{t}\)'s 10 purchased items, forming \(_{t}\). PRB runs based on \(G_{t-1}\) and selects an arm (node) \(v_{t,}_{t}\). If the selected arm \(v_{t,}\) is the purchased item by \(u_{t}\), the regret is \(0\) (or reward is \(1\)) and we add the edge \([v_{t},v_{t,}]\) to \(G_{t-1}\), to form the new graph \(G_{t}\); otherwise, the regret is \(1\) (or reward is \(0\)) and \(G_{t}=G_{t-1}\).

(2) Social network datasets: Facebook  and GR-QC . Given the user set \(V\), we have \(G_{0}=(V,E_{0}=)\). In a round \(t[T]\), we randomly select a source node \(v_{t}\) that can be thought of as the serving user. Then, we randomly choose 100 nodes, including \(v_{t}\)'s 10 connected nodes but their edges are removed, which form the arm pool \(_{t}\) associated with the context set \(_{t}\). Then, PRB will select one arm \(v_{t,}_{t}\). If \(v_{t}\) and \(v_{t,}\) are connected in the original graph, the regret is \(0\) and add the edge \([v_{t},v_{t,}]\) to \(G_{t-1}\); otherwise, the regret is \(1\) and \(G_{t}=G_{t-1}\).

(3) Node classification datasets: Cora, Citeseer, and Pubmed from the Planetoid citation networks . Recall the problem setting described in Sec. 4. Consider a \(k\)-class node classification problem. Given a graph \(G(V,E_{0}=)\), we randomly select a node \(v_{t} V\) to predict its belonging class, in a round \(t[T]\). Then, PRB select one super node \(_{i_{t}}\). If \(v_{t}\) belongs to class \(i_{t}\), the regret is \(0\) and add \([v_{t},_{i_{t}}]\) to \(G_{t-1}\). Otherwise, the regret is \(1\) and \(G_{t}=G_{t-1}\).

**Baselines.** For bandit-based methods, we apply Neural Greedy  that leverages the greedy exploration strategy on the exploitation network, NeuralUCB  that uses the exploitation network to learn the reward function along with an UCB-based exploration strategy, NeuralTS  that adopts the exploitation network to learn the reward function along with the Thompson Sampling exploration strategy, and EE-net  that utilizes the exploitation-exploration network to learn the reward function. Following [76; 12], for all methods, we train each network every 50 rounds for the first 2000 rounds and then every 100 rounds for the remaining rounds. See Appendix A.1 for additional experimental setups.

**Online Link Prediction**. We use Figure 2 to depict the regret trajectories over 10,000 rounds, and Table 1 to detail the cumulative regret after 10,000 rounds for all methods, where the lower is better. Based on the regret comparison, PRB consistently outperforms all other baselines across all datasets. For example, the cumulative regret at 10,000 rounds for PRB on MovieLens is considerably lower than the best-performing baseline, EE-Net. Similarly, in the AmazonFashion dataset, PRB achieved the lowest regret, surpassing the strongest baseline EE-Net over 14%. This trend is consistent across the Facebook and GrQc datasets, where PRB maintains its lead with the lowest regrets respectively. The consistency in PRB's performance across various datasets suggests the importance of utilizing the graph structure formed by previous link predictions.

**Online Node classification**. Figure 3 and Table 2 show the regret comparison on online node classification. PRB consistently demonstrates the lowest cumulative regret by outperforming other

    & Cora & Citeseer & Pubmed \\   & Mean \(\) Std & Mean \(\) Std & Mean \(\) Std \\  EE-Net & 1990 \(\) 13.8 & 2299 \(\) 33.4 & 1659 \(\) 11.3 \\ NeuGreedy & 2826 \(\) 21.4 & 2543 \(\) 24.6 & 1693 \(\) 13.5 \\ NeuralUCB & 2713 \(\) 21.7 & 3101 \(\) 22.0 & 1672 \(\) 14.3 \\ NeuralTS & 1998 \(\) 15.6 & 3419 \(\) 39.5 & 1647 \(\) 11.3 \\ 
**PRB** & **1874 \(\) 25.6** & **2168 \(\) 35.7** & **1577 \(\) 10.7** \\   

Table 2: Cumulative regret of bandit-based methods on **online** node classification.

bandit methods at round 10,000, respectively. Overall, PRB decreases regrets by 3.0%, 1.2%, and 3.5% compared to one of the best baselines, NeuralTS. This experiment demonstrates that PRB is versatile enough for applications beyond online link prediction, extending to other real-world tasks such as online node classification. This highlights PRB's advantage of fusing contextual bandits with PageRank for collaborative exploitation and exploration.

### Offline Link Prediction

In this subsection, we evaluate PRB in the setting of offline link prediction compared with graph-based baselines, where training and testing datasets are provided, following the same evaluation process of [18; 61]. Here, we train PRB on the training dataset using the same sequential optimization method Sec. 6.1. Then, we run the trained PRB on the testing dataset. Notice that PRB never sees the test data in the training process as other baselines.

**Datasets**. In this study, we use real-world link-prediction datasets to compare PRB with graph-based baselines. Specifically, we apply Cora, Citeseer, and Pubmed from Planetoid citation networks ; ogbl-collab, ogbl-ppa, and ogbl-ddi from Open Graph Benchmark . (See dataset statistics in Appendix C.)

**Setting:** We strictly follow the experimental setup in  and use the Hits@k metric for evaluation. Please also refer to A.1 for additional setups.

**Baselines**. For graph-based methods, we choose traditional link-prediction heuristics including CN , RA , AA  and common GNNs including GCN  and SAGE . Then, we employ SF-then-MPNN models, including SEAL  and NBFNet , as well as SF-and-MPNN models like Neo-GNN  and BUDDY. Additionally, we also select the MPNN-then-SF model NCN  and NCNC . The results of the baselines are sourced from Table 2 of .

**Comparison with Graph-based Baselines.** We present the experimental results in Table 3 for all methods. The results demonstrate that PRB consistently outperforms other baselines across all six datasets. Specifically, compared to the most recent method, NCNC, PRB achieves a minimum improvement of 0.68% on the Collab dataset, a maximum of 4.2%, and an average of 2.42% across

    & Cora & Citeseer & Pubmed & Collab & PPA & DDI \\  Methods & HR@100 \(\) Std & HR@100 \(\) Std & HR@100 \(\) Std & HR@50 \(\) Std & HR@100 \(\) Std & HR@20 \(\) Std \\  CN & 33.92 \(\) 0.46 & 29.79 \(\) 0.90 & 23.13 \(\) 0.15 & 56.44 \(\) 0.00 & 27.65 \(\) 0.00 & 17.73 \(\) 0.00 \\ AA & 39.85 \(\) 1.34 & 35.19 \(\) 1.33 & 27.38 \(\) 0.11 & 64.35 \(\) 0.00 & 32.45 \(\) 0.00 & 18.61 \(\) 0.00 \\ RA & 41.07 \(\) 0.48 & 33.56 \(\) 0.17 & 27.03 \(\) 0.35 & 64.00 \(\) 0.00 & 49.33 \(\) 0.00 & 27.60 \(\) 0.00 \\  GCN & 66.79 \(\) 1.65 & 67.08 \(\) 2.94 & 53.02 \(\) 1.39 & 44.75 \(\) 1.07 & 18.67 \(\) 1.32 & 37.07 \(\) 5.07 \\ SAGE & 55.02 \(\) 4.03 & 57.01 \(\) 3.74 & 39.66 \(\) 0.72 & 48.10 \(\) 0.81 & 16.55 \(\) 2.40 & 53.90 \(\) 4.74 \\  SEAL & 81.71 \(\) 1.30 & 83.89 \(\) 2.15 & 75.54 \(\) 1.32 & 64.74 \(\) 0.43 & 48.80 \(\) 3.16 & 30.56 \(\) 3.86 \\ NBFNet & 71.65 \(\) 2.27 & 74.07 \(\) 1.75 & 58.73 \(\) 1.99 & OOM & OOM & 4.00 \(\) 0.58 \\  Neo-GNN & 80.42 \(\) 1.31 & 84.67 \(\) 2.16 & 73.93 \(\) 1.19 & 57.52 \(\) 0.37 & 49.13 \(\) 0.60 & 63.57 \(\) 3.52 \\ BUDDY & 88.00 \(\) 0.44 & 92.93 \(\) 0.27 & 74.10 \(\) 0.78 & 65.94 \(\) 0.58 & 49.85 \(\) 0.20 & 78.51 \(\) 1.36 \\  NCN & 89.05 \(\) 0.96 & 91.56 \(\) 1.43 & 79.05 \(\) 1.16 & 64.76 \(\) 0.87 & 61.19 \(\) 0.85 & 82.32 \(\) 6.10 \\ NCNC & 89.65 \(\) 1.36 & 93.47 \(\) 0.95 & 81.29 \(\) 0.95 & 66.61 \(\) 0.71 & 61.42 \(\) 0.73 & 84.11 \(\) 3.67 \\ 
**PRB** & **92.33 \(\) 0.57** & **95.13 \(\) 1.28** & **84.54 \(\) 0.86** & **67.29 \(\) 0.31** & **63.47 \(\) 1.75** & **88.31 \(\) 4.36** \\   

Table 3: Results on **offline** link prediction benchmarks. OOM means out of GPU memory.

Figure 3: Regret comparison of bandit-based methods on **online** node classification datasets (average of 10 runs with standard deviation in shadow, detailed in Table 2.

all datasets. Given that all baselines lack the perspective of exploration, the results demonstrate that fusing the exploitation and exploration in contextual bandits along with learning graph connectivity through PageRank does significantly enhance accuracy for link prediction.

### Ablation and Sensitivity Studies

Table 4 presents the performance of different variants of PRB, including PRB-greedy that only use the exploitation network and PRB-(10%-G) that has the warm start with addition 10% edges in \(G_{0}\). The results show that exploration is crucial to the final performance and the additional graph knowledge can boost the performance.

Due to the space limit, we move all other experiment sections to Appendix A, including computational cost analysis on PRB and additional ablation & sensitivity studies.

## 7 Conclusion

This paper introduces a fusion algorithm for link prediction, which integrates the power of contextual bandits in balancing exploitation and exploration with propagation on graph structure by PageRank. We further provide the theoretical performance analysis for PRB, showing the regret of the proposed algorithm can grow sublinearly. We conduct extensive experiments in link prediction to evaluate PRB's effectiveness, compared with both bandit-based and graph-based baselines.