# A Computation and Communication Efficient Method for Distributed Nonconvex Problems

in the Partial Participation Setting

Alexander Tyurin

KAUST

Saudi Arabia

alexandertiurin@gmail.com

&Peter Richtarik

KAUST

Saudi Arabia

richtarik@gmail.com

###### Abstract

We present a new method that includes three key components of distributed optimization and federated learning: variance reduction of stochastic gradients, partial participation, and compressed communication. We prove that the new method has optimal oracle complexity and state-of-the-art communication complexity in the partial participation setting. Regardless of the communication compression feature, our method successfully combines variance reduction and partial participation: we get the optimal oracle complexity, never need the participation of all nodes, and do not require the bounded gradients (dissimilarity) assumption.

## 1 Introduction

Federated and distributed learning have become very popular in recent years (Konecny et al., 2016; McMahan et al., 2017). The current optimization tasks require much computational resources and machines. Such requirements emerge in machine learning, where massive datasets and computations are distributed between cluster nodes (Lin et al., 2017; Ramesh et al., 2021). In federated learning, nodes, represented by mobile phones, laptops, and desktops, do not send their data to a server due to privacy and their huge number (Ramaswamy et al., 2019), and the server remotely orchestrates the nodes and communicates with them to solve an optimization problem.

As in classical optimization tasks, one of the main current challenges is to find **computationally efficient** optimization algorithms. However, the nature of distributed problems induces many other (Kairouz et al., 2021), including i) **partial participation** of nodes in algorithm steps: due to stragglers (Li et al., 2020) or communication delays (Vogels et al., 2021), ii) **communication bottleneck**: even if a node participates, it can be costly to transmit information to a server or other nodes (Alistarh et al., 2017; Ramesh et al., 2021; Kairouz et al., 2021; Sapio et al., 2019; Narayanan et al., 2019). It is necessary to develop a method that considers these problems.

## 2 Optimization Problem

Let us consider the nonconvex distributed optimization problem

\[_{x^{d}}\{f(x):=_{i=1}^{n}f_{i}(x)\},\] (1)

where \(f_{i}\ :\ ^{d}\) is a smooth nonconvex function for all \(i[n]:=\{1,,n\}\). The full information about function \(f_{i}\) is stored on \(i^{}\) node. The communication between nodes is maintained in the parameters server fashion (Kairouz et al., 2021): we have a server that receives compressedinformation from nodes, updates a state, and broadcasts an updated model.1 Since we work in the nonconvex world, our goal is to find an \(\)-solution (\(\)-stationary point) of (1): a (possibly random) point \(^{d}\), such that \(\![.\| f()\|^{2}. ]\).

We consider three settings:

1. **Gradient Setting.** The \(i^{}\) node has only access to the gradient \( f_{i}\,:\,^{d}^{d}\) of function \(f_{i}\). Moreover, the following assumptions for the functions \(f_{i}\) hold.

**Assumption 1**.: _There exists \(f^{*}\) such that \(f(x) f^{*}\) for all \(x\)._

**Assumption 2**.: _The function \(f\) is \(L\)-smooth, i.e., \(\| f(x)- f(y)\| L\|x-y\|\) for all \(x,y^{d}\)._

**Assumption 3**.: _The functions \(f_{i}\) are \(L_{i}\)-smooth for all \(i[n]\). Let us define \(^{2}:=_{i=1}^{n}L_{i}^{2}\).2_

2. **Finite-Sum Setting.** The functions \(\{f_{i}\}_{i=1}^{n}\) have the finite-sum form

\[f_{i}(x)=_{j=1}^{m}f_{ij}(x), i[n],\] (2)

where \(f_{ij}:^{d}\) is a smooth nonconvex function for all \(j[m]\).

We assume that Assumptions 1, 2 and 3 hold and the following assumption.

**Assumption 4**.: _The function \(f_{ij}\) is \(L_{ij}\)-smooth for all \(i[n],j[m].\) Let \(L_{}:=_{i[n],j[m]}L_{ij}.\)_

3. **Stochastic Setting.** The function \(f_{i}\) is an expectation of a stochastic function,

\[f_{i}(x)=_{}[f_{i}(x;)], i[ n],\] (3)

where \(f_{i}:^{d}_{}\). For a fixed \(x\), \(f_{i}(x;)\) is a random variable over some distribution \(_{i}\), and, for a fixed \(_{},\,f_{i}(x;)\) is a smooth nonconvex function. The \(i^{}\) node has only access to a stochastic gradients \( f_{i}(;_{ij})\) of the function \(f_{i}\) through the distribution \(_{i},\) where \(_{ij}\) is a sample from \(_{i}.\) We assume that Assumptions 1, 2 and 3 hold and the following assumptions.

**Assumption 5**.: _For all \(i[n]\) and for all \(x^{d},\) the stochastic gradient \( f_{i}(x;)\) is unbiased and has bounded variance, i.e., \(_{}[ f_{i}(x;)]= f_{i}(x),\) and \(_{}[\| f_{i}(x;)- f_{i}(x) \|^{2}]^{2},\) where \(^{2} 0.\)_

**Assumption 6**.: _For all \(i[n]\) and for all \(x,y,\) the stochastic gradient \( f_{i}(x;)\) satisfies the mean-squared smoothness property, i.e., \(_{}[\| f_{i}(x;)- f_{i}(y;) \|^{2}] L_{}^{2}\|x-y\|^{2}.\)_

We compare algorithms using _the oracle complexity_, i.e., the number of (stochastic) gradients that each node has to calculate to get \(\)-solution, and _the communication complexity_, i.e., the number of bits that each node has to send to the server to get \(\)-solution.

### Unbiased Compressors

We use the concept of unbiased compressors to alleviate the communication bottleneck. The unbiased compressors quantize and/or sparsify vectors that the nodes send to the server.

**Definition 1**.: A stochastic mapping \(\,:\,^{d}^{d}\) is an _unbiased compressor_ if there exists \(\)

\[[(x)]=x [\|(x)-x\|^{2}]\|x \|^{2} x^{d}.\] (4)

We denote a set of stochastic mappings that satisfy Definition 1 as \(().\) In our methods, the nodes make use of unbiased compressors \(\{_{i}\}_{i=1}^{n}\). The community developed a large number of unbiassed compressors, including \(K\) (see Definition 5) (Beznosikov et al., 2020; Stich et al., 2018), Adaptive sparsification (Wangni et al., 2018) and Natural compression and dithering (Horvath et al., 2019). We are aware of correlated compressors by Szlendak et al. (2021) and quantizers by Suresh et al. (2022) that help in the homogeneous regimes, but in this work, we are mainly concentrated on generic heterogeneous regimes, though, for simplicity, assume the independence of the compressors.

**Assumption 7**.: \(_{i}()\) _for all \(i[n]\), and the compressors are statistically independent._

### Nodes Partial Participation Assumptions

We now try to formalize the notion of partial participation. Let us assume that we have \(n\) events \(\{i^{}\}\) with the following properties.

**Assumption 8**.: _The partial participation of nodes has the following distribution: exists constants \(p_{}(0,1]\) and \(p_{},\) such that_

1. \[(i^{})=p_{ } i[n],\]
2. \[(i^{}j^{})=p_{ } i j[n].\]
3. \[p_{} p_{}^{2},\] (5)

_and these events from different communication rounds are independent._

We are not fighting for the full generality and believe that more complex sampling strategies can be considered in the analysis. For simplicity, we settle upon Assumption 8. Standard partial participation strategies, including \(s\)-nice sampling, where the server chooses uniformly \(s\) nodes without replacement (\(p_{}=}{{n}}\) and \(p_{}~{}=~{}s(s-1)}{{n}(n-1)}\)), and independent participation, where eachnode independently participates with probability \(p_{}\) (due to independence, we have \(p_{}=p_{}^{2}\)), satisfy Assumption 8. In the literature, \(s-\)nice sampling is one of the most popular strategies (Zhao et al., 2021; Richtarik et al., 2021; Reddi et al., 2020; Konecny et al., 2016).

## 3 Motivation and Related Work

The main goal of our paper is to develop a method for the nonconvex distributed optimization that will include three key features: variance reduction of stochastic gradients, compressed communication, and partial participation. We now provide an overview of the literature (see also Table 1 and Table 2).

**1. Variance reduction of stochastic gradients**

It is important to consider finite-sum (2) and stochastic (3) settings because, in machine learning tasks, either the number of local functions \(m\) is huge or the functions \(f_{i}\) is an expectation of a stochastic function due to the batch normalization (Ioffe and Szegedy, 2015) or random augmentation (Goodfellow et al., 2016), and it is infeasible to calculate the full gradients analytically. Let us recall the results from the nondistributed optimization. In the gradient setting, the optimal oracle complexity is \((}{{}})\), achieved by the vanilla gradient descent (GD) (Carmon et al., 2020; Nesterov, 2018). In the finite-sum setting and stochastic settings, the optimal oracle complexities are \((m+}{})\) and \((}{}+}{{2}}}})\)(Fang et al., 2018; Li et al., 2021; Arjevani et al., 2019), accordingly, achieved by methods SPIDER, SARAH, PAGE, and STORM from (Fang et al., 2018; Nguyen et al., 2017; Li et al., 2021; Cutkosky and Orabona, 2019).

**2. Compressed communication**

In distributed optimization (Ramesh et al., 2021; Xu et al., 2021), lossy communication compression can be a powerful tool to increase the communication speed between the nodes and the server. Different types of compressors are considered in the literature, including unbiased compressors (Alistarh et al., 2017; Beznosikov et al., 2020; Szlendak et al., 2021), contractive (biased) compressors (Richtarik et al., 2021), 3PC compressors (Richtarik et al., 2022). We will focus on unbiased compressors because methods DASHA and MARINA (Tyurin and Richtarik, 2023; Szlendak et al., 2021; Gorbunov et al., 2021) that employ unbiased compressors provide the current theoretical state-of-the-art (SOTA) communication complexities.

Many methods analyzed optimization methods with the unbiased compressors (Alistarh et al., 2017; Mishchenko et al., 2019; Horvath et al., 2019; Gorbunov et al., 2021; Tyurin and Richtarik, 2023). In the gradient setting, the methods MARINA and DASHA by Gorbunov et al. (2021) and Tyurin and Richtarik (2023) establish the current SOTA communication complexity, each method needs \(}{{}}}{}\) communication rounds to get an \(-\)solution. In the finite-sum and stochastic settings, the current

   Method & \(VR\) & \(PP\) & \(CC\) & Limitations \\   SPIDER, PAGE & & & & \\ (Fang et al., 2018; Li et al., 2021) & ✓ & ✗ & ✗ & — \\  MARINA & & & & & \\ (Gorbunov et al., 2021) & ✓ & ✗\({}^{(a)}\) & ✓\({}^{(b)}\) & & (see (Tyurin and Richtarik, 2023)). \\  ZeroSARAH & & & & & \\ (Li et al., 2021) & ✓ & ✓ & ✗ & Only homogeneous regime, i.e., the functions \(f_{i}\) are equal. \\  FedPAGE & & & & \\ (Zhao et al., 2021) & ✗ & ✗\({}^{(a)}\) & ✗ & & Suboptimal oracle complexity \(()\). \\  DASHA & & & & \\ (Tyurin and Richtarik, 2023) & ✓ & ✗ & ✓ & & — \\  DASH-PP & & & & & \\ (new) & ✓ & ✓ & ✓ & & — \\   

Table 2: Summary of methods that solve the problem (1) in the finite-sum setting (2). Abbr.: _VR_ (Variance Reduction) = Does a method have the optimal oracle complexity \((m+}{})\)? _PP_ and _CC_ are defined in Table 1.

SOTA communication complexity is attained by the DASHA method, while maintaining the optimal oracle complexities \((m+}{})\) and \((}{ n}+n})\) per node.

**3. Partial participation**

From the beginning of federated learning era, the partial participation has been considered to be the essential feature of distributed optimization methods McMahan et al. (2017); Konechny et al. (2016); Kairouz et al. (2021). However, previously proposed methods have limitations: i) methods \(\) and \(\) from Gorbunov et al. (2021); Zhao et al. (2021) still require synchronization of all nodes with a small probability. ii) in the stochastic settings, methods \(\), \(\), and \(\) with the partial participation mechanism McMahan et al. (2017); Karimireddy et al. (2020); Zhao et al. (2021) provide results without variance reduction techniques from Fang et al. (2018); Li et al. (2021); Cutkosky and Orabona (2019) and, therefore, get suboptimal oracle complexities. Note that \(\) and \(\) reduce the variance _only from compressors_ (in the partial participation and stochastic setting). iii) in the finite-sum setting, the \(\) method by Li et al. (2021) focuses on the homogeneous regime only (the functions \(f_{i}\) are equal). iv) The \(\) method by Karimireddy et al. (2020) and the \(\) method (for Partial Participation) by the concurrent paper Patel et al. (2022) consider the online version of the problem (1). Therefore, \(\) and \(\) (for Partial Participation) require stricter assumptions, including the bounded inter-client gradient variance assumption. In the finite-sum setting (2), \(\) and \(\) obtain a suboptimal oracle complexity \((}{{^{3/2}}})\) while, in the full participation setting, it is possible to get the complexity \((}{{}})\).

## 4 Contributions

We propose a new method \(\) for the nonconvex distributed optimization.

\(\) As far as we know, this is the first method that includes three key ingredients of federated learning methods: _variance reduction of stochastic gradients, compressed communication, and partial participation._

\(\) Moreover, this is the first method that combines _variance reduction of stochastic gradients and partial participation_ flawlessly: i) it gets the optimal oracle complexity ii) does not require the participation of all nodes iii) does not require the bounded gradients assumption of the functions \(f_{i}\).

\(\) We prove convergence rates and show that this method has _the optimal oracle complexity and the state-of-the-art communication complexity in the partial participation setting_. Moreover, in our work, we observe a nontrivial side-effect from mixing the variance reduction of stochastic gradients and partial participation. It is a general problem not related to our methods or analysis that we discuss in Section C.

\(\) In Section A, we present experiments where we validate our theory and compare our new methods to previous ones.

## 5 Algorithm Description and Main Challenges Towards Partial Participation

We now present \(\) (see Algorithm 1), a family of methods to solve the optimization problem (1). When we started investigating the problem, we took \(\) as a baseline method for two reasons: the family of algorithms \(\) provides the current state-of-the-art communication complexities in the _non-partial participation_ setting, and, unlike \(\), it does not send non-compressed gradients and does not synchronize all nodes. Let us briefly discuss the main idea of \(\), its problem in the _partial participation_ setting, and why the refinement of \(\) is not an exercise.

In fact, the original \(\) method supports the partial participation of nodes _in the gradient setting_. Since the nodes only do the following steps (see full algorithm in Algorithm 6):

\[g_{i}^{t+1}=g_{i}^{t}+_{i}( f_{i}(x^{t+1})-(1-a) f _{i}(x^{t})-ag_{i}^{t}).\] (6)```
1:Input: starting point \(x^{0}^{d}\), stepsize \(>0\), momentum \(a(0,1]\), momentum \(b(0,1]\), probability \(p_{}(0,1]\) (only in DASHA-PP-PAGE), batch size \(B\) (only in DASHA-PP-PAGE, DASHA-PP-PAGE, DASHA-PP-P-MVR), probability \(p_{}(0,1]\) that a node is _participating_(a), number of iterations \(T 1\)
2:Initialize \(g_{0}^{0}^{d}\), \(h_{i}^{0}^{d}\) on the nodes and \(g^{0}=_{i=1}^{n}g_{i}^{0}\) on the server
3:Initialize \(h_{ij}^{0}^{d}\) on the nodes and take \(h_{i}^{0}=_{j=1}^{m}h_{ij}^{0}\) (only in DASHA-PP-FINITE-MVR)
4:for\(t=0,1,,T-1\)do
5:\(x^{t+1}=x^{t}- g^{t}\)
6: Broadcast \(x^{t+1},x^{t}\) to all _participating_(a) nodes
7:for\(i=1,,n\) in parallel do
8:if\(i\)th node is participating(a)then
9: Calculate \(k_{i}^{t+1}\) using Algorithm 2, 3, 4 or 5
10:\(h_{i}^{t+1}=h_{i}^{t}+}k_{i}^{t+1}\)
11:\(m_{i}^{t+1}=_{i}(}k_{i}^{t+1}-} (g_{i}^{t}-h_{i}^{t}))\)
12:\(g_{i}^{t+1}=g_{i}^{t}+m_{i}^{t+1}\)
13: Send \(m_{i}^{t+1}\) to the server
14:else
15:\(h_{ij}^{t+1}=h_{ij}^{t}\) (only in DASHA-PP-FINITE-MVR)
16:\(h_{i}^{t+1}=h_{i}^{t}, g_{i}^{t+1}=g_{i}^{t}, m_{i}^{t+1}=0\)
17:endif
18:endfor
19:\(g^{t+1}=g^{t}+_{i=1}^{n}m_{i}^{t+1}\)
20:endfor
21:Output:\(^{T}\) chosen uniformly at random from \(\{x^{t}\}_{k=0}^{T-1}\) (a): For the formal description see Section 2.2. ```

**Algorithm 2** Calculate \(k_{i}^{t+1}\) for DASHA-PP in the gradient setting. See line 9 in Alg. 1

```
1:\(k_{i}^{t+1}= f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f _{i}(x^{t}))\) ```

**Algorithm 3** Calculate \(k_{i}^{t+1}\) for DASHA-PP-PAGE in the finite-sum setting. See line 9 in Alg. 1

```
1:Generate a random set \(I_{i}^{t}\) of size \(B\) from \([m]\)_with replacement_
2:\(k_{i}^{t+1}= f_{i}(x^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t})),\\ }$ on all {participating} nodes},\\ _{j I_{i}^{t}}( f_{ij}(x^{t+1})- f_{ij}(x^{ t})),\\ }$ on all {participating} nodes}\) ```

**Algorithm 4** Calc. \(k_{i}^{t+1}\) for DASHA-PP-FINITE-MVR in the finite-sum setting. See line 9 in Alg. 1

```
1:Generate a random set \(I_{i}^{t}\) of size \(B\) from \([m]\)_without replacement_
2:\(k_{i}^{t+1}=( f_{ij}(x^{t+1})- f_{ij} (x^{t})-b(h_{ij}^{t}- f_{ij}(x^{t}))),&j I_{i}^{t},\\ 0,&j I_{i}^{t}\)
3:\(h_{ij}^{t+1}=h_{ij}^{t}+}k_{ij}^{t+1}\)
4:\(k_{i}^{t+1}=_{j=1}^{m}k_{ij}^{t+1}\) ```

**Algorithm 5** Calculate \(k_{i}^{t+1}\) for DASHA-PP-MVR in the stochastic setting. See line 9 in Alg. 1

```
1:Generate i.i.d. samples \(\{_{ij}^{t+1}\}_{j=1}^{B}\) of size \(B\) from \(_{i}\).
2:\(k_{i}^{t+1}=_{j=1}^{B} f_{i}(x^{t+1};_{ij}^{t+1})-_{j=1}^{B} f_{i}(x^{t};_{ij}^{t+1})-b(h_{i}^{t}-_{j=1}^{B} f_{i}(x^{t};_{ij}^{t+1}))\) ```

**Algorithm 5** Calculate \(k_{i}^{t+1}\) for DASHA-PP-MVR in the stochastic setting. See line 9 in Alg. 1

[MISSING_PAGE_EMPTY:7]

[MISSING_PAGE_FAIL:8]

optimal oracle complexity and SOTA communication complexity. Indeed, comparing the following result with (Tyurin and Richtarik, 2023, Corollary 6.6), one can see that we get the degeneration up to \(}{{p_{}}}\) factor, which is expected in the partial participation setting. Note that the complexities improve with the number of workers \(n\).

**Corollary 2**.: _Suppose that assumptions of Corollary 1 hold, \(B\{}}},}^{ 2}}{1}}L^{2}}\}^{6}\), and we use the unbiased compressor \(K\) with \(K=(}{{}}).\) Then the communication complexity of Algorithm 1 is \((d+}_{0}d}{p_{} }),\) and the expected number of gradient calculations per node equals \((m+}_{0}}{p_{} }).\)_

The convergence rate of DASHA-PP-FINITE-MVR is provided in Section E.5.

### Stochastic Setting

We define \(h^{t}:=_{i=1}^{n}h_{i}^{t}\).

**Theorem 4**.: _Suppose that Assumptions 1, 2, 3, 5, 6, 7 and 8 hold. Let us take \(a=}}{2+1}\), \(b(0,}}{2-p_{}}]\), \((L+[}^{2}}( ^{2}+L_{}^{2}}{B})+}}((1-}}{p_{}}) ^{2}+L_{}^{2}}{B})]^{1/2})^ {-1}\), and \(g_{i}^{0}=h_{i}^{0}\) for all \(i[n]\) in Algorithm 1 (DashA-PP-MVR). Then_

\[[\| f(^{T})\|^{2}] }[}{}+\| h^{0}- f(x^{0})\|^{2}+(} ^{2}}+}}{p_{}})}{np_{} })(_{i=1}^{n}\|h_{i}^{0}- f_{i}(x^{0}) \|^{2})]\] \[+((2+1)}{p_{}^{2}}+}})}{nB}.\]

In the next corollary, we choose momentum \(b\) and initialize vectors \(h_{i}^{0}\) to get \(\)-solution.

**Corollary 3**.: _Suppose that assumptions from Theorem 4 hold, momentum \(b=(\{}}{}}},}neB}{^{2}}\}),\)\(}{n B} 1,\) and \(h_{i}^{0}=}}_{k=1}^{B_{}} f_{i}(x^{0} ;_{ik}^{0})\) for all \(i[n],\) and batch size \(B_{}=(}}B}{b}),\) then Algorithm 1 (DashA-PP-MVR) needs_

\[T:=}{}L+}}(+}{})+}}(}} {L}}{}+}{B})+}{}}n B}\]

_communication rounds to get an \(\)-solution and the number of stochastic gradient calculations per node equals \((B_{}+BT).\)_

The convergence rate of the DASHA-SYNC-MVR, the state-of-the-art method without partial participation, equals \((}{}[L+} (+}{})+}}{B}]+}{n B }).\) Similar to Section 6.2, we see that in the regimes when \( L_{}\) the third term w.r.t. \(}{{^{3/2}}}\) can degenerate up to \(}}{{p_{}}}.\) However, if we take \(B=(}}{{^{2}}}),\) then the degeneration of the third term will be up to \(}{{p_{}}}.\) This effect we analyze in Section C. The fact that the degeneration is up to \(}{{p_{}}}\) we check numerically in Section A.

In the following corollary, we consider \(K\) compressors (see Definition 5) and show that with the particular choice of parameters, up to the Lipschitz constants factors, DASHA-PP-MVR gets the optimal oracle complexity and SOTA communication complexity of DASHA-SYNC-MVR method. Indeed, comparing the following result with (Tyurin and Richtarik, 2023, Corollary 6.9), one can see that we get the degeneration up to \(}{{p_{}}}\) factor, which is expected in the partial participation setting. Note that the complexities improve with the number of workers \(n\).

**Corollary 4**.: _Suppose that assumptions of Corollary 3 hold, batch size \(B\{}},}^{2}}{1}}L^{2}}\},\) we take \(K\) compressors with \(K=(}{}).\) Then the communication complexity equals \(K\) compressors with \(K=(}{}).\)_

[MISSING_PAGE_FAIL:10]

Karimireddy, S. P., Jaggi, M., Kale, S., Mohri, M., Reddi, S. J., Stich, S. U., and Suresh, A. T. (2020a). Mime: Mimicking centralized stochastic algorithms in federated learning. _arXiv preprint arXiv:2008.03606_.
* Karimireddy et al. (2020b) Karimireddy, S. P., Kale, S., Mohri, M., Reddi, S., Stich, S., and Suresh, A. T. (2020b). Scaffold: Stochastic controlled averaging for federated learning. In _International Conference on Machine Learning_, pages 5132-5143. PMLR.
* Konecny et al. (2016) Konecny, J., McMahan, H. B., Yu, F. X., Richtarik, P., Suresh, A. T., and Bacon, D. (2016). Federated learning: Strategies for improving communication efficiency. _arXiv preprint arXiv:1610.05492_.
* Li et al. (2020) Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith, V. (2020). Federated optimization in heterogeneous networks. _Proceedings of Machine Learning and Systems_, 2:429-450.
* Li et al. (2021a) Li, Z., Bao, H., Zhang, X., and Richtarik, P. (2021a). PAGE: A simple and optimal probabilistic gradient estimator for nonconvex optimization. In _International Conference on Machine Learning_, pages 6286-6295. PMLR.
* Li et al. (2021b) Li, Z., Hanzely, S., and Richtarik, P. (2021b). ZeroSARAH: Efficient nonconvex finite-sum optimization with zero full gradient computation. _arXiv preprint arXiv:2103.01447_.
* Lin et al. (2017) Lin, Y., Han, S., Mao, H., Wang, Y., and Dally, W. J. (2017). Deep gradient compression: Reducing the communication bandwidth for distributed training. _arXiv preprint arXiv:1712.01887_.
* McMahan et al. (2017) McMahan, B., Moore, E., Ramage, D., Hampson, S., and y Arcas, B. A. (2017). Communication-efficient learning of deep networks from decentralized data. In _Artificial intelligence and statistics_, pages 1273-1282. PMLR.
* Mishchenko et al. (2019) Mishchenko, K., Gorbunov, E., Takac, M., and Richtarik, P. (2019). Distributed learning with compressed gradient differences. _arXiv preprint arXiv:1901.09269_.
* Narayanan et al. (2019) Narayanan, D., Harlap, A., Phanishayee, A., Seshadri, V., Devanur, N. R., Ganger, G. R., Gibbons, P. B., and Zaharia, M. (2019). PipeDream: generalized pipeline parallelism for dnn training. In _Proceedings of the 27th ACM Symposium on Operating Systems Principles_, pages 1-15.
* Nesterov (2018) Nesterov, Y. (2018). _Lectures on convex optimization_, volume 137. Springer.
* Nguyen et al. (2017) Nguyen, L., Liu, J., Scheinberg, K., and Takac, M. (2017). SARAH: A novel method for machine learning problems using stochastic recursive gradient. In _The 34th International Conference on Machine Learning_.
* Paszke et al. (2019) Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al. (2019). Pytorch: An imperative style, high-performance deep learning library. In _Advances in Neural Information Processing Systems (NeurIPS)_.
* Patel et al. (2022) Patel, K. K., Wang, L., Woodworth, B., Bullins, B., and Srebro, N. (2022). Towards optimal communication complexity in distributed non-convex optimization. In _Advances in Neural Information Processing Systems_.
* Ramaswamy et al. (2019) Ramaswamy, S., Mathews, R., Rao, K., and Beaufays, F. (2019). Federated learning for emoji prediction in a mobile keyboard. _arXiv preprint arXiv:1906.04329_.
* Ramesh et al. (2021) Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I. (2021). Zero-shot text-to-image generation. _arXiv preprint arXiv:2102.12092_.
* Reddi et al. (2020) Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K., Konecny, J., Kumar, S., and McMahan, H. B. (2020). Adaptive federated optimization. _arXiv preprint arXiv:2003.00295_.
* Richtarik et al. (2021) Richtarik, P., Sokolov, I., and Fatkhullin, I. (2021). EF21: A new, simpler, theoretically better, and practically faster error feedback. _In Neural Information Processing Systems, 2021_.
* Richtarik et al. (2022) Richtarik, P., Sokolov, I., Fatkhullin, I., Gasanov, E., Li, Z., and Gorbunov, E. (2022). 3PC: Three point compressors for communication-efficient distributed training and a better theory for lazy aggregation. _arXiv preprint arXiv:2202.00998_.
* Raghavan et al. (2019)Sapio, A., Canini, M., Ho, C.-Y., Nelson, J., Kalnis, P., Kim, C., Krishnamurthy, A., Moshref, M., Ports, D. R., and Richtarik, P. (2019). Scaling distributed machine learning with in-network aggregation. _arXiv preprint arXiv:1903.06701_.
* Stich et al. (2018) Stich, S. U., Cordonnier, J.-B., and Jaggi, M. (2018). Sparsified SGD with memory. _Advances in Neural Information Processing Systems_, 31.
* Suresh et al. (2022) Suresh, A. T., Sun, Z., Ro, J. H., and Yu, F. (2022). Correlated quantization for distributed mean estimation and optimization. _arXiv preprint arXiv:2203.04925_.
* Szlendak et al. (2021) Szlendak, R., Tyurin, A., and Richtarik, P. (2021). Permutation compressors for provably faster distributed nonconvex optimization. _arXiv preprint arXiv:2110.03300_.
* Tyurin and Richtarik (2023) Tyurin, A. and Richtarik, P. (2023). DASHA: Distributed nonconvex optimization with communication compression and optimal oracle complexity. _International Conference on Learning Representations (ICLR)_.
* Vogels et al. (2021) Vogels, T., He, L., Koloskova, A., Karimireddy, S. P., Lin, T., Stich, S. U., and Jaggi, M. (2021). RelaySum for decentralized deep learning on heterogeneous data. _Advances in Neural Information Processing Systems_, 34.
* Wangni et al. (2018) Wangni, J., Wang, J., Liu, J., and Zhang, T. (2018). Gradient sparsification for communication-efficient distributed optimization. _Advances in Neural Information Processing Systems_, 31.
* Xu et al. (2021) Xu, H., Ho, C.-Y., Abdelmoniem, A. M., Dutta, A., Bergou, E. H., Karatsenidis, K., Canini, M., and Kalnis, P. (2021). Grace: A compressed communication framework for distributed machine learning. In _2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS)_, pages 561-572. IEEE.
* Zhao et al. (2021a) Zhao, H., Burlachenko, K., Li, Z., and Richtarik, P. (2021a). Faster rates for compressed federated learning with client-variance reduction. _arXiv preprint arXiv:2112.13097_.
* Zhao et al. (2021b) Zhao, H., Li, Z., and Richtarik, P. (2021b). FedPAGE: A fast local stochastic gradient method for communication-efficient federated learning. _arXiv preprint arXiv:2108.04755_.

###### Contents

* 1 Introduction
* 2 Optimization Problem
	* 2.1 Unbiased Compressors
	* 2.2 Nodes Partial Participation Assumptions
* 3 Motivation and Related Work
* 4 Contributions
* 5 Algorithm Description and Main Challenges Towards Partial Participation
* 6 Theorems
	* 6.1 Gradient Setting
	* 6.2 Finite-Sum Setting
	* 6.3 Stochastic Setting
* A Numerical Verification of Theoretical Dependencies
* A.1 Experiments in Partial Participation Setting
* B Original DASHA and DASHA-MVR Methods
* C Problem of Estimating the Mean in the Partial Participation Setting
* D Auxiliary facts
* D.1 Sampling Lemma
* D.2 Compressors Facts
* E Proofs of Theorems
* E.1 Standard Lemmas in the Nonconvex Setting
* E.2 Generic Lemmas
* E.3 Proof for DASHA-PP
* E.4 Proof for DASHA-PP-PAGE
* E.5 Proof for DASHA-PP-FINITE-MVR
* E.6 Proof for DASHA-PP-MVR
* F Analysis of DASHA-PP under Polyak-Lojasiewicz Condition
* F.1 Gradient Setting
* F.2 Finite-Sum Setting
* F.3 Stochastic Setting
* F.4 Proofs of Theorems
* F.4.1 Standard Lemma under Polyak-Lojasiewicz Condition

F.4.2 Generic Lemma F.4.3 Proof for DASHA-PP under PL-condition F.4.4 Proof for DASHA-PP-PAGE under PL-condition F.4.5 Proof for DASHA-PP-MVR under PL-condition G Description of DASHA-PP-SYNC-MVR G.1 Proof for DASHA-PP-SYNC-MVR

## Appendix A Numerical Verification of Theoretical Dependencies

Our main goal is to verify the dependeces from the theory. We compare DASHA-PP with DASHA. Clearly, DASHA-PP can not generally perform better than DASHA. In different settings, we verify that the bigger \(p_{}\), the closer DASHA-PP is to DASHA, i.e., DASHA-PP converges no slower than \(}{{p_{}}}\) times.

In all experiments, we take the _real-sim_ dataset with dimension \(d=20{,}958\) and the number of samples equals \(72{,}309\) from LIBSVM datasets (Chang and Lin, 2011) (under the 3-clause BSD license), and randomly split the dataset between \(n=100\) nodes equally, ignoring residual samples. In the finite-sum setting, we solve a classification problem with functions

\[f_{i}(x):=_{j=1}^{m}(1-a_{ij}^{}x )})^{2},\] (11)

where \(a_{ij}^{d}\) is the feature vector of a sample on the \(i^{}\) node, \(y_{ij}\{-1,1\}\) is the corresponding label, and \(m\) is the number of samples on the \(i^{}\) node for all \(i[n]\). In the stochastic setting, we consider functions

\[f_{i}(x_{1},x_{2}):=_{j[m]}-(^{}x_{y_{ij}})}{_{y\{1,2\}}(a_{ij}^{}x_{y} )})+_{y\{1,2\}}_{k=1}^{d}\}_{k}^{2 }}{1+\{x_{y}\}_{k}^{2}},\] (12)

where \(x_{1},x_{2}^{d}\), \(\{\}_{k}\) is an indexing operation, \(a_{ij}^{d}\) is a feature of a sample on the \(i^{}\) node, \(y_{ij}\{1,2\}\) is a corresponding label, \(m\) is the number of samples located on the \(i^{}\) node, constant \(=0.001\) for all \(i[n]\).

The code was written in Python 3.6.8 using PyTorch 1.9 (Paszke et al., 2019). A distributed environment was emulated on a machine with Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz and 64 cores.

We use the standard setting in experiments7 where all parameters except step sizes are taken as suggested in theory. Step sizes are finetuned from a set \(\{2^{i}\,|\,i[-10,10]\}\). We emulate the partial participation setting using \(s\)-nice sampling with the number of nodes \(n=100\). We consider the Rand\(K\) compressor and take the batch size \(B=1\). We plot the relation between communication rounds and values of the norm of gradients at each communication round.

In the finite-sum (Figure 0(a)) and in the stochastic setting (Figure 0(b)), we see that the bigger probability \(p_{}=}{{n}}\) to \(1\), the closer DASHA-PP to DASHA. Moreover, DASHA-PP with \(s=10\) and \(s=1\) converges approximately \( 10\) (\(=}{{p_{}}}\)) and \( 100\) (\(=}{{p_{}}}\)) times slower, accordingly. Our theory predicts such behavior.

Figure 1: Classification task with the _real-sim_ dataset.

[MISSING_PAGE_FAIL:16]

[MISSING_PAGE_EMPTY:17]

Problem of Estimating the Mean in the Partial Participation Setting

We now provide the example to explain why the only choice of \(B=(\{}}},}^{2}}{1_{p_{}}L^{2}}\})\) and \(B=(\{}n}, }^{2}}{1_{p_{}}L^{2}}\})\) in DASHA-PP-PAGE and DASHA-PP-MVR, accordingly, guarantees the degeneration up to \(}{{p_{}}}\). This is surprising, because in methods with the variance reduction of stochastic gradients (Li et al., 2021; Tyurin and Richtarik, 2023) we can take the size of batch size \(B=(})\) and \(B=(n})\) and guarantee the optimality. Note that the smaller the batch size \(B\), the more the server and the nodes have to communicate to get \(\)-solution.

Let us consider the task of estimating the mean of vectors in the distributed setting. Suppose that we have \(n\) nodes, and each of them contains \(m\) vectors \(\{x_{ij}\}_{j=1}^{m}\), where \(x_{ij}^{d}\) for all \(i[n],j[m]\). First, let us consider that each node samples a mini-batch \(I^{i}\) of size \(B\) with replacement and sends it to the server. Then the server calculates the mean of the mini-batches from nodes. One can easily show that the variance of the estimator is

\[[\|_{i=1}^{n}_{j I^{i }}x_{ij}-_{i=1}^{n}_{j=1}^{m}x_{ij}\|^{2}]\] (13) \[=_{i=1}^{n}_{j=1}^{m}\|x_{ij }-_{j=1}^{m}x_{ij}\|^{2}.\]

Next, we consider the same task in the partial participation setting with \(s\)-nice sampling, i.e., we sample a random set \(S[n]\) of \(s[n]\) nodes without replacement and receive the mini-batches only from the sampled nodes. Such sampling of nodes satisfy Assumption 8 with \(p_{}=}{{n}}\) and \(p_{}=}{{n(n-1)}}\). In this case, the variance of the estimator (See Lemma 1 with \(r_{i}=0\) and \(s_{i}=_{j I^{i}}x_{ij}\)) is

\[[\|_{i S}_{j I^{i} }x_{ij}-_{i=1}^{n}_{j=1}^{m}x_{ij}\|^{2}]\] (14) \[=_{i=1}^{n}_{j=1}^{m} \|x_{ij}-_{j=1}^{m}x_{ij}\|^{2}}_{_{ {max}}^{2}}\] \[+_{i=1}^{n} \|_{j=1}^{m}x_{ij}-_{i=1}^{n}_{j=1}^{m }x_{ij}\|^{2}}_{}^{2}}.\]

Let us assume that \(s}{{2}}\). Note that (13) scales with any \(B 1,\) while (14) only scales when \(B=(_{}^{2}}}{{^{2}}} ).\) In other words, for large enough \(B,\) the variance in (14) does not significantly improves with the growth of \(B\) due to the term \(}^{2}\). In our proof, due to partial participation, the variance from (14) naturally appears, and we get the same effect. As was mentioned in Sections 6.2 and 6.3, it can be seen in our convergence rate bounds.

Auxiliary facts

We list auxiliary facts that we use in our proofs:

1. For all \(x,y^{d},\) we have \[\|x+y\|^{2} 2\|x\|^{2}+2\|y\|^{2}\] (15)
2. Let us take a _random vector_\(^{d},\) then \[[\|\|^{2}]=[\|- []\|^{2}]+\|[ ]\|^{2}.\] (16)

### Sampling Lemma

This section provides a lemma that we regularly use in our proofs, and it is useful for samplings that satisfy Assumption 8.

**Lemma 1**.: _Suppose that a set \(S\) is a random subset of a set \([n]\) such that_

1. \[(i S)=p_{}, i[n],\]
2. \[(i S,j S)=p_{}, i j [n],\]
3. \[p_{} p_{}^{2},\]

_where \(p_{}(0,1]\) and \(p_{}.\) Let us take random independent vectors \(s_{i}^{d}\) for all \(i[n],\) nonrandom vector \(r_{i}^{d}\) for all \(i[n],\) and random vectors_

\[v_{i}=r_{i}+}}s_{i},i S,\\ r_{i},i S,\]

_then_

\[[\|_{i=1}^{n}v_{i}- [_{i=1}^{n}v_{i}]\|^{2}]\] \[=p_{}}_{i=1}^{n}[ \|s_{i}-[s_{i}]\|^{2}]+}-p_{}}{n^{2}p_{}^{2}}_{i=1}^{n}\| [s_{i}]\|^{2}+}-p_{}^{2}}{p_{ }^{2}}\|_{i=1}^{n}[s_{i}]\|\] \[p_{}}_{i=1}^{n}[ \|s_{i}-[s_{i}]\|^{2}]+}-p_{}}{n^{2}p_{}^{2}}_{i=1}^{n}\| [s_{i}]\|^{2}.\]

Proof.: Let us define additional constants \(p_{}\) and \(p_{}\), such that

1. \[(i S,j S)=p_{},  i j[n],\]
2. \[(i S,j S)=p_{},  i j[n].\]

Note, that

\[p_{}=p_{}+p_{}\] (17)

and

\[p_{}=1-p_{}-2p_{}.\] (18)

Using the law of total expectation and

\[[v_{i}]=p_{}(r_{i}+[}}s_{i}])+(1-p_{})r_{i}=r_{i}+ [s_{i}],\]we have

\[[\|_{i=1}^{n}v_{i}- [_{i=1}^{n}v_{i}]\|^{2}]\] \[=}_{i=1}^{n}[\|v_{i}-( r_{i}+[s_{i}])\|^{2}]\] \[+}}{n^{2}}_{i=1}^{n}\|r_{i}- (r_{i}+[s_{i}])\|^{2}\] \[+}}{n^{2}}_{i j}^{n} [ r_{i}+}}s_{i}-(r_{i}+ [s_{i}]),r_{j}+}}s_{j}-(r_{j}+ [s_{j}])]\] \[+}}{n^{2}}_{i j}^{n} [ r_{i}+}}s_{i}-(r_{i}+ [s_{i}]),r_{j}-(r_{j}+[s_{j}]) ]\] \[+}}{n^{2}}_{i j}^{n} r _{i}-(r_{i}+[s_{i}]),r_{j}-(r_{j}+ [s_{j}]).\]

From the independence of random vectors \(s_{i}\), we obtain

\[[\|_{i=1}^{n}v_{i}- [_{i=1}^{n}v_{i}]\|^{2}]\] \[=}}{n^{2}}_{i=1}^{n}[\| }}s_{i}-[s_{i}]\|^{2}]\] \[+}}{n^{2}}_{i=1}^{n}\| [s_{i}]\|^{2}\] \[+}(1-p_{})^{2}}{n^{2}p_{ }^{2}}_{i j}^{n}[s_{i}], [s_{j}]\] \[+}(p_{}-1)}{n^{2}p_{ }}_{i j}^{n}[s_{i}], [s_{j}]\] \[+}}{n^{2}}_{i j}^{n} [s_{i}],[s_{j}].\]

Using (17) and (18), we have

\[[\|_{i=1}^{n}v_{i}- [_{i=1}^{n}v_{i}]\|^{2}]\] \[=}}{n^{2}}_{i=1}^{n}[\| }}s_{i}-[s_{i}]\|^{2}]\] \[+}}{n^{2}}_{i=1}^{n}\|[s_{i}]\|^{2}\]

[MISSING_PAGE_EMPTY:21]

### Standard Lemmas in the Nonconvex Setting

We start the proof of theorems by providing standard lemmas from the nonconvex optimization.

**Lemma 2**.: _Suppose that Assumption 2 holds and let \(x^{t+1}=x^{t}- g^{t}\). Then for any \(g^{t}^{d}\) and \(>0\), we have_

\[f(x^{t+1}) f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|g^{t}- f(x^{t})\|^{2}.\] (19)

Proof.: Using \(L-\)smoothness, we have

\[f(x^{t+1})  f(x^{t})+ f(x^{t}),x^{t+1}-x^{t} +\|x^{t+1}-x^{t}\|^{2}\] \[=f(x^{t})- f(x^{t}),g^{t}+ \|x^{t+1}-x^{t}\|^{2}.\]

Next, due to \(- x,y=\|x-y\|^{2}- \|x\|^{2}-\|y\|^{2},\) we obtain

\[f(x^{t+1}) f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|g^{t}- f(x^{t})\|^{2}.\]

**Lemma 3**.: _Suppose that Assumption 1 holds and_

\[[f(x^{t+1})]+^{t+1} [f(x^{t})]-[\| f(x^{t}) \|^{2}]+^{t}+ C,\] (20)

_where \(^{t}\) is a sequence of numbers, \(^{t} 0\) for all \(t[T]\), constant \(C 0\), and constant \(>0\). Then_

\[[\| f(^{T})\|^{2} ]}{ T}+}{T}+2C,\] (21)

_where a point \(^{T}\) is chosen uniformly from a set of points \(\{x^{t}\}_{t=0}^{T-1}\)._

Proof.: By unrolling (20) for \(t\) from \(0\) to \(T-1\), we obtain

\[_{t=0}^{T-1}[\| f( x^{t})\|^{2}]+[f(x^{T})]+^{T} f(x^{0})+ ^{0}+ TC.\]

We subtract \(f^{*}\), divide inequality by \(,\) and take into account that \(f(x) f^{*}\) for all \(x\), and \(^{t} 0\) for all \(t[T],\) to get the following inequality:

\[_{t=0}^{T-1}[\| f(x^{t}) \|^{2}]}{ T}+}{T}+2C.\]

It is left to consider the choice of a point \(^{T}\) to complete the proof of the lemma. 

**Lemma 4**.: _If \(0<(L+)^{-1}\), \(L>0\), and \(A 0,\) then_

\[-- 0.\]

The lemma can be easily checked with the direct calculation.

### Generic Lemmas

**Lemma 5**.: _Suppose that Assumptions 7 and 8 hold and let us consider sequences \(g_{i}^{t+1}\), \(h_{i}^{t+1},\) and \(k_{i}^{t+1}\) from Algorithm 1, then_

\[_{}[_{p_{}}[ \|g^{t+1}-h^{t+1}\|^{2}]]\] \[p_{}}_{i=1}^{n}\|k_{i} ^{t+1}\|^{2}+((2+1)\,p_{}-p_{ })}{n^{2}p_{}^{2}}_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}+(1-a)^{2}\|g^{t}-h^{t}\|^{2},\] (22)

_and_

\[_{}[_{p_{}}[ \|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]]\] \[}}\|k_{i}^{t+1}\|^{2}+ ((2+1-p_{})}{p_{}}+(1-a)^{2}) \|g_{i}^{t}-h_{i}^{t}\|^{2} i[n].\] (23)

Proof.: First, we estimate \(_{}[_{p_{}}[\|g^{t+1} -h^{t+1}\|^{2}]]\):

\[_{}[_{p_{}}[ \|g^{t+1}-h^{t+1}\|^{2}]]\] \[=_{}[_{p_{}}[ \|g^{t+1}-h^{t+1}-_{}[_{p_{ }}[g^{t+1}-h^{t+1}]]\|^{2}]]+\| _{}[_{p_{}}[g^{t+1}-h^{t+1 }]]\|^{2},\]

where we used (16). Due to Assumption 8, we have

\[_{}[_{p_{}}[g_ {i}^{t+1}]]\] \[=p_{}_{}[g_{i}^{t}+_{i}}}k_{i}^{t+1}-}} (g_{i}^{t}-h_{i}^{t})]+(1-p_{})g_{i}^{t}\] \[=g_{i}^{t}+p_{}_{}[_{i}}}k_{i}^{t+1}-}} (g_{i}^{t}-h_{i}^{t})]\] \[=g_{i}^{t}+k_{i}^{t+1}-a(g_{i}^{t}-h_{i}^{t}),\]

and

\[_{}[_{p_{}}[h_{i}^{t+1} ]]=p_{}_{}[h_{i}^{t}+ {p_{}}k_{i}^{t+1}]+(1-p_{})h_{i}^{t}=h_{i}^{t}+k_{i} ^{t+1}.\]

Thus, we can get

\[_{}[_{p_{}}[ \|g^{t+1}-h^{t+1}\|^{2}]]\] \[=_{}[_{p_{}}[ \|g^{t+1}-h^{t+1}-_{}[_{p_{ }}[g^{t+1}-h^{t+1}]]\|^{2}]]+(1-a)^{2} \|g^{t}-h^{t}\|^{2}.\]

Due to the independence of compressors, we can use Lemma 1 with \(r_{i}=g_{i}^{t}-h_{i}^{t}\) and \(s_{i}=p_{}_{i}}}k_{i}^{t+1} -}}(g_{i}^{t}-h_{i}^{t})-k_{i}^{t+1},\) and obtain

\[_{}[_{p_{}}[ \|g^{t+1}-h^{t+1}\|^{2}]]\] \[p_{}}_{i=1}^{n}_{ }[\|p_{}_{i}}}k_{i}^{t+1}-}}(g_{i}^{t}-h_{i}^{t} )-k_{i}^{t+1}-_{}[p_{} _{i}}}k_{i}^{t+1}-}}(g_{i}^{t}-h_{i}^{t})-k_{i}^{t+1}]\|^{2}\] \[+}-p_{}}{n^{2}p_{}^{2 }}_{i=1}^{n}\|_{}[p_{}_{i }}}k_{i}^{t+1}-}}(g_{ i}^{t}-h_{i}^{t})-k_{i}^{t+1}]\|^{2}\]\[\] \[+}}[\|g^{t }-h^{t}\|^{2}]+}-p_{})}{ np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]+}^{2}}[_{i=1}^{n}\|k_{i}^{t+1}\|^{2}].\]Proof.: Due to Lemma 2 and the update step from Line 5 in Algorithm 1, we have

\[_{t+1}[f(x^{t+1})]\] \[_{t+1}[f(x^{t})-\| f( x^{t})\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+(\|g^{t}-h^{t}\|^{2}+\|h^{t}- f( x^{t})\|^{2}]).\]

Let us fix some constants \(,[0,)\) that we will define later. Combining the last inequality, bounds (22), (23) and using the law of total expectation, we get

\[[f(x^{t+1})]\] \[=[_{t+1}[f(x^{t+1})]]\] \[[f(x^{t})-\| f(x^{ t})\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+(\|g^{t}-h^{t}\|^{2}+\|h^{t}- f (x^{t})\|^{2})]\] \[+[p_{}} _{i=1}^{n}\|k_{i}^{t+1}\|^{2}+((2+1)\,p_{ }-p_{})}{n^{2}p_{}^{2}}_{i=1}^{n}\|g_{i} ^{t}-h_{i}^{t}\|^{2}+(1-a)^{2}\|g^{t}-h^{t}\|^{2}]\] \[+[}}_{i= 1}^{n}\|k_{i}^{t+1}\|^{2}+((2+1-p_{} )}{p_{}}+(1-a)^{2})_{i=1}^{n}\|g_{i}^{t}-h _{i}^{t}\|^{2}]\] \[=[f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+(+(1-a)^{2}) [\|g^{t}-h^{t}\|^{2}]\] \[+(((2+1)\,p_{}-p_{ })}{np_{}^{2}}+((2+1-p_{})}{p_{}}+(1-a)^{2}))[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+(}}+}})[_{i=1}^{n}\|k _{i}^{t+1}\|^{2}].\]

Now, by taking \(=\), we can see that \(+(1-a)^{2},\) and thus

\[[f(x^{t+1})]\] \[[f(x^{t})-\| f(x^{ t})\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+[\|g^{t}-h^{t}\|^ {2}]\] \[+(}-p_{ })}{np_{}^{2}}+((2+1-p_{})}{p_{}}+(1-a)^{2}))[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+(}}+}})[_{i=1}^{n}\|k _{i}^{t+1}\|^{2}].\]Next, by taking \(=}-p_{})}{np_{}^{2}}\) and considering the choice of \(a\), one can show that \((}-p_{} )}{np_{}^{2}}+((2+1-p_{} )}{p_{}}+(1-a)^{2}))\). Thus

\[[f(x^{t+1})]\] \[+}}[\| g^{t+1}-h^{t+1}\|^{2}]+} -p_{})}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+}}[\| g^{t}-h^{t}\|^{2}]+} -p_{})}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+(}^{2}}+ }-p_{})}{np_{ }^{3}})[_{i=1}^{n}\|k_{i}^{t+1} \|^{2}].\]

Considering that \(p_{} 0\), we can simplify the last term and get

\[[f(x^{t+1})]\] \[+}}[\| g^{t+1}-h^{t+1}\|^{2}]+} -p_{})}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+}^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}].\]

### Proof for Dasha-Pp

**Lemma 7**.: _Suppose that Assumptions 3 and 8 hold. For \(h_{i}^{t+1}\) and \(k_{i}^{t+1}\) from Algorithm 1 (Dasha-Pp) we have_

1. \[_{p_{}}[\|h^{t+1}- f(x^{t+1})\| ^{2}]\] \[}-p_{}) ^{2}}{np_{}^{2}}\|x^{t+1}-x^{t}\|^{2}+(p_{ }-p_{})}{n^{2}p_{}^{2}}_{i=1}^{n}\|h_{ i}^{t}- f_{i}(x^{t})\|^{2}+(1-b)^{2}\|h^{t}- f (x^{t})\|^{2}.\]
2. \[_{p_{}}[\|h_{i}^{t+1}- f_{i}(x^{t+1})\| ^{2}]\] \[})}{p_{}}L_{i}^{2}\|x^ {t+1}-x^{t}\|^{2}+((1-p_{})}{p_{}}+ (1-b)^{2})\|h_{i}^{t}- f_{i}(x^{t})\|^{2},  i[n].\]
3. \[\|k_{i}^{t+1}\|^{2} 2L_{i}^{2}\|x^{t+1}-x^{t}\|^{2}+2b^ {2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}, i[n].\]

Proof.: First, let us proof the bound for \(_{k}[_{p_{}}[\|h^{t+1}- f(x^{t+1} )\|^{2}]]\):

\[_{p_{}}[\|h^{t+1}- f(x^{t+1})\|^{2}]\]\[=_{p_{}}[\|h^{t+1}-_{p_{ }}[h^{t+1}]\|^{2}]+\|_{p_{ }}[h^{t+1}]- f(x^{t+1})\|^{2}.\]

Using

\[_{p_{}}[h^{t+1}_{i}]=h^{t}_{i}+  f_{i}(x^{t+1})- f_{i}(x^{t})-b(h^{t}_{i}- f_{i}(x^{t}))\]

and (16), we have

\[_{p_{}}[\|h^{t+1}- f(x^{t+1}) \|^{2}]\] \[=_{p_{}}[\|h^{t+1}-_{p_{ }}[h^{t+1}]\|^{2}]+(1-b)^{2} \|h^{t}- f(x^{t})\|^{2}.\]

We can use Lemma 1 with \(r_{i}=h^{t}_{i}\) and \(s_{i}=k^{t+1}_{i}\) to obtain

\[_{p_{}}[\|h^{t+1}- f(x^{t+1}) \|^{2}]\] \[p_{}}_{i=1}^{n}\|k^{t+1}_{i} -k^{t+1}_{i}\|^{2}+}-p_{}}{n^{2}p_{}^{2}}_{i=1}^{n}\|k^{t+1}_{i}\|^{2}+(1-b)^{2} \|h^{t}- f(x^{t})\|^{2}\] \[=}-p_{}}{n^{2}p_{}^{2}} _{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h^{t}_{i }- f_{i}(x^{t}))\|^{2}+(1-b)^{2}\|h^{t}-  f(x^{t})\|^{2}\] \[}{}}-p_{ })}{np_{}^{2}}_{i=1}^{n}\| f_{i}(x^{t+ 1})- f_{i}(x^{t})\|^{2}+(p_{}-p_{ })}{n^{2}p_{}^{2}}_{i=1}^{n}\|h^{t}_{i}-  f_{i}(x^{t})\|^{2}+(1-b)^{2}\|h^{t}- f(x^{t })\|^{2}\] \[}-p_{})^ {2}}{np_{}^{2}}\|x^{t+1}-x^{t}\|^{2}+(p_{ }-p_{})}{n^{2}p_{}^{2}}_{i=1}^{n}\| h^{t}_{i}- f_{i}(x^{t})\|^{2}+(1-b)^{2}\|h^{t}- f (x^{t})\|^{2}.\]

In the last in inequality, we used Assumption 3. Now, we prove the second inequality:

\[_{p_{}}[\|h^{t+1}_{i}- f_{i}( x^{t+1})\|^{2}]\] \[=_{p_{}}[\|h^{t+1}_{i}-_{ p_{}}[h^{t+1}_{i}]\|^{2}]+\|_{p_{ }}[h^{t+1}_{i}]- f_{i}(x^{t+1})\|^{2}\] \[=_{p_{}}[\|h^{t+1}_{i}-(h^{t}_ {i}+ f_{i}(x^{t+1})- f_{i}(x^{t})-b(h^{t}_{i}- f_{i}(x^{t})) )\|^{2}]+(1-b)^{2}\|h^{t}_{i}- f_{i}(x^ {t})\|^{2}\] \[=})^{2}}{p_{}}\|  f_{i}(x^{t+1})- f_{i}(x^{t})-b(h^{t}_{i}- f_{i}(x^{t})) \|^{2}+(1-b)^{2}\|h^{t}_{i}- f_{i}(x^{t})\|^ {2}\] \[})}{p_{}}L^{2}_{i}\|x^{t +1}-x^{t}\|^{2}+((1-p_{})}{p_{}}+ (1-b)^{2})\|h^{t}_{i}- f_{i}(x^{t})\|^{2}.\]

Finally, the third inequality of the theorem follows from (15) and Assumption 3. 

**Theorem 2**.: _Suppose that Assumptions 1, 2, 3, 7 and 8 hold. Let us take \(a=}}{2+1},\,b=}}{2-p_{}},\)_

\[(L+[}^{2}}+}^{2}}(1-}}{p_ {}})]^{1/2})^{-1},\]

_and \(g^{0}_{i}=h^{0}_{i}= f_{i}(x^{0})\) for all \(i[n]\) in Algorithm 1_(DASHA-PP)_, then \([\| f(^{T})\|^{2}]}{ T}.\)_

Proof.: Let us fix constants \(,[0,)\) that we will define later. Considering Lemma 6, Lemma 7, and the law of total expectation, we obtain

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g^{t+1}_{i}-h^{t+1}_{i}\|^ {2}]\]\[+}{ E}[\|g^{t}-h^{t} \|^{2}]+-p_{ aa})}{np_{ a}^{ 2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2 }]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t+1}- f_{i}(x^{ t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-..\] \[..+}{ E}[ \|h^{t+1}- f(x^{t+1})\|^{2}]+[_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\] \[..+}{ E}[ \|g^{t}-h^{t}\|^{2}]+-p_{  aa})}{np_{ a}^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t }-h_{i}^{t}\|^{2}].\]

After rearranging the terms, we get

\[{ E}[f(x^{t+1})]+ }{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{ n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f_ {i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[-(--^{2}}{np_{ a}^{2}}--p_{ aa}) \,^{2}}{np_{ a}^{2}}-)^{2}}{p _{ a}}){ E}[\|x^{t+1}-x^{t}\|^{2}]\] \[+(+(1-b)^{2}){ E}[\|h^{t}- f (x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ \,(p_{ a}-p_{ aa})}{np_{ a}^{2}}+((1- p_{ a})}{p_{ a}}+(1-b)^{2})){ E}[_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

By taking \(=\), one can show that \((+(1-b)^{2})\), and

\[{ E}[f(x^{t+1})]+ }{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{ n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+[_{i=1}^{n}\|h_{i}^{t +1}- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\]\[-(--^{2}}{np_{ a}^{2}}--p_{  aa})^{2}}{bnp_{ a}^{2}}-) ^{2}}{p_{ a}}){ E}[\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ -p_{ aa})}{np_{ a}^{2}}+( (1-p_{ a})}{p_{ a}}+(1-b)^{2})){ E}[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2} ].\]

Note that \(b=}{2-p_{i}}\), thus

\[((2+1)}{np_{ a}^{2}}+-p_{ aa})}{np_{ a}^{2}}+((1-p_{ a})}{p_{ a}}+(1-b)^{2}))\] \[((2+1)}{np_{ a}^{2}}+ -p_{ aa})}{np_{ a}^{2}}+(1- b)).\]

And if we take \(=^{2}}+-p_{ aa})}{np_{ a}^{2}}\), then

\[((2+1)}{np_{ a}^{2}}+-p_{ aa})}{np_{ a}^{2}}+(1-b)) ,\]

and

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(^{2}}+ -p_{ aa})}{np_{ a}^{2}}){ E} [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\| ^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{ np_{ a}^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[-(--^{2}}{np_{ a}^{2}}--p_ { aa})^{2}}{bnp_{ a}^{2}}.\] \[.-) ^{2}}{np_{ a}^{3}}--p_{ aa} )(1-p_{ a})^{2}}{np_{ a}^{3}}){ E}[ \|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(^{2}}+ -p_{ aa})}{np_{ a}^{2}}){ E} [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2} ].\]

Let us simplify the last inequality. First, note that

\[)^{2}}{np_{ a}^{3}} ^{2}}{np_{ a}^{2}},\]

due to \(b p_{ a}\). Second,

\[-p_{ aa})^{2}}{bnp_{ a}^{2}} -p_{ aa})^{2}}{np_{ a}^{3}},\]

due to \(b}{2}\). All in all, we have

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(^{2}}+ -p_{ aa})}{np_{ a}^{2}}){ E} [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1}) \|^{2}]\]\[ [f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}}[\|g^ {t}-h^{t}\|^{2}]+ }-p_{})}{np_{}^{2}}[_{i=1}^{ n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[-(--^{2}}{np_{}^{2}}-}-p_{})^{2}}{np_{}^{3}}) [\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2 }}+}-p_{})}{np_{}^{ 2}})[_{i=1}^{n}\|h_{i}^{t}- f_{ i}(x^{t})\|^{2}].\]

Using Lemma 4 and the assumption about \(\), we get

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^ {2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2 }}+}-p_{})}{np_{}^{ 2}})[_{i=1}^{n}\|h_{i}^{t+1}- f_{ i}(x^{t})\|^{2}]\] \[+}}[\|g ^{t}-h^{t}\|^{2}]+ }-p_{})}{np_{}^{2}}[_{i=1}^{ n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2 }}+}-p_{})}{np_{}^ {2}})[_{i=1}^{n}\|h_{i}^{t}- f_ {i}(x^{t})\|^{2}].\]

It is left to apply Lemma 3 with

\[^{t} = }}[\|g^{t}-h^ {t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{ n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+ [\|h^{t}- f(x^{t})\|^{2 }]+(}^{2}}+}-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2 }]\]

to conclude the proof. 

### Proof for \(\)-\(\)-Page

Let us denote

\[k_{i,1}^{t+1} := f_{i}(x^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t})),\] \[k_{i,2}^{t+1} :=_{j I_{i}^{}}( f_{ij}(x^{t+1 })- f_{ij}(x^{t})),\] \[h_{i,1}^{t+1} :=h_{i}^{t}+}}k_{i,1}^{t+1},& ,\\ h_{i}^{t},&,\] \[h_{i,2}^{t+1} :=h_{i}^{t}+}}k_{i,2}^{t+1},& ,\\ h_{i}^{t},&,\]

\(h_{1}^{t+1}:=_{i=1}^{n}h_{i,1}^{t+1}\), and \(h_{2}^{t+1}:=_{i=1}^{n}h_{i,2}^{t+1}\). Note, that

\[h^{t+1}=h_{1}^{t+1},&}$},\\ h_{2}^{t+1},&}$}.\]

[MISSING_PAGE_FAIL:31]

\[+p_{}\|_{_{}}[h_{1} ^{t+1}-_{_{}}[h_{1}^{t+1}]]^{2}+ (1-p_{})\|_{B}[_{_ {}}[h_{2}^{t+1}]]- f(x^{t+1})\|^{2}\] \[=p_{}_{_{}}[\|h _{1}^{t+1}-_{_{}}[h_{1}^{t+1}] \|^{2}]+(1-p_{})_{B}[_{_{}}[\|h_{2}^{t+1}]\|^{2}]\] \[+(p_{}(1-}} )^{2}+(1-p_{}))\|h^{t}- f(x^{t}) \|^{2}.\] (24)

Next, we consider \(_{_{}}[\|h_{1}^{t+1}-_{ _{}}[h_{1}^{t+1}]\|^{2}]\). We can use Lemma 1 with \(r_{i}=h_{i}^{t}\) and \(s_{i}=k_{i,1}^{t+1}\) to obtain

\[_{_{}}[\|h_{1}^{t+1}- _{_{}}[h_{1}^{t+1}]\|^{2}]\] \[p_{}}_{i=1}^{n}\|k_{i,1}^{t +1}-k_{i,1}^{t+1}\|^{2}+}-p_{}}{n^{2}p_{ }^{2}}_{i=1}^{n}\|k_{i,1}^{t+1}\|^{2}\] \[=}-p_{}}{n^{2}p_{}^{2}} _{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[}{}}-p_{ {aa}})}{n^{2}p_{}^{2}}_{i=1}^{n}\| f_{i}(x^{t+1 })- f_{i}(x^{t})\|^{2}+}-p_{} )b^{2}}{n^{2}p_{}^{2}p_{}^{2}}_{i=1}^{n}\|h _{i}^{t}- f_{i}(x^{t})\|^{2}.\]

From Assumption 3, we have

\[_{_{}}[\|h_{1}^{t+1}- _{_{}}[h_{1}^{t+1}]\|^{2}]\] \[}-p_{})^{ 2}}{np_{}^{2}}\|x^{t+1}-x^{t}\|^{2}+}-p_{})b^{2}}{n^{2}p_{}^{2}p_{}^ {2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}.\] (25)

Now, we prove the bound for \(_{B}[_{_{}}[\|h_{2}^{t +1}-_{B}[_{_{}}[h_{2}^{t+1} ]]\|^{2}]].\) Considering that mini-batches in the algorithm are independent, we can use Lemma 1 with \(r_{i}=h_{i}^{t}\) and \(s_{i}=k_{i,2}^{t+1}\) to obtain

\[_{B}[_{_{}}[ \|h_{2}^{t+1}-_{B}[_{p_{}}[h_{2}^{ t+1}]]\|^{2}]]\] \[p_{}}_{i=1}^{n}_{B} [\|k_{i,2}^{t+1}-_{B}[k_{i,2}^{t+1}]\|^{2} ]+}-p_{}}{n^{2}p_{}^{2}}_{i=1}^ {n}\|_{B}[k_{i,2}^{t+1}]\|^{2}\] \[=p_{}}_{i=1}^{n}_{B}[ \|_{j I_{i}^{t}}( f_{ij}(x^{t+1})- f_{ ij}(x^{t}))-( f_{i}(x^{t+1})- f_{i}(x^{t})) \|^{2}]\] \[+}-p_{}}{n^{2}p_{}^{2}} _{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}\] \[=p_{}Bm}_{i=1}^{n}_{j=1}^{m} \|( f_{ij}(x^{t+1})- f_{ij}(x^{t}))-( f_ {i}(x^{t+1})- f_{i}(x^{t}))\|^{2}\] \[+}-p_{}}{n^{2}p_{}^{2}} _{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}\] \[=p_{}Bm}_{i=1}^{n}_{j=1}^{m}\| ( f_{ij}(x^{t+1})- f_{ij}(x^{t}))-( f_{i}(x^{ t+1})- f_{i}(x^{t}))\|^{2}\] \[+}-p_{}}{n^{2}p_{}^{2}} _{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}\] \[p_{}Bm}_{i=1}^{n}_{j=1}^{m} \| f_{ij}(x^{t+1})- f_{ij}(x^{t})\|^{2}+}-p_{}}{n^{2}p_{}^{2}}_{i=1}^{n}\| f _{i}(x^{t+1})- f_{i}(x^{t})\|^{2}.\]Next, we use Assumptions 3 and 4 to get

\[_{B}[_{p_{}}[\|h_{2}^{t+1}-_ {B}[_{p_{}}[h_{2}^{t+1}]]\|^{2} ]](}^{2}}{np_{}B}+}-p_{})^{2}}{np_{}^{2 }})\|x^{t+1}-x^{t}\|^{2}.\] (26)

Applying (25) and (26) into (24), we get

\[_{B}[_{p_{}}[\|h^{t+ 1}- f(x^{t+1})\|^{2}]]\] \[ p_{}(}-p_{})^{2}}{np_{}^{2}}\|x^{t+1}-x^{t}\|^{2}+ }-p_{})b^{2}}{n^{2}p_{}^{ 2}p_{}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\| ^{2})+\] \[+(1-p_{})(}^ {2}}{np_{}B}+}-p_{}) ^{2}}{np_{}^{2}})\|x^{t+1}-x^{t}\|^{2}\] \[+(p_{}(1-}} )^{2}+(1-p_{}))\|h^{t}- f(x^{t}) \|^{2}\] \[(}-p_{}) ^{2}}{np_{}^{2}}+})L_{ }^{2}}{np_{}B})\|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n^ {2}p_{}^{2}p_{}}_{i=1}^{n}\|h_{i}^{t}- f_{ i}(x^{t})\|^{2}+(p_{}(1-}} )^{2}+(1-p_{}))\|h^{t}- f(x^{t}) \|^{2}.\]

The proof of the second inequality almost repeats the previous one:

\[_{B}[_{p_{}}[\|h_{i }^{t+1}- f_{i}(x^{t+1})\|^{2}]]]\] \[=p_{}_{B}[_{p_{}} [\|h_{i,1}^{t+1}- f_{i}(x^{t+1})\|^{2}]]+(1- p_{})_{B}[_{p_{}}[\|h_{i,2}^{t+ 1}- f_{i}(x^{t+1})\|^{2}]]\] \[+p_{}\|_{B}[_{p_{ }}[h_{i,1}^{t+1}]]- f_{i}(x^{t+1})\|^{2} +(1-p_{})\|_{B}[_{p_{ }}[h_{i,2}^{t+1}]]- f_{i}(x^{t+1})\|^{2}\] \[=p_{}_{B}[_{p_{}} [\|h_{i,1}^{t+1}-_{B}[_{p_{}} [h_{i,1}^{t+1}]]\|^{2}]]+(1-p_{}) _{B}[_{p_{}}[\|h_{i,2}^{t+1}- _{B}[_{p_{}}[h_{i,2}^{t+1}] ]\|^{2}]]\] \[+(p_{}(1-}} )^{2}+(1-p_{}))\|h_{i}^{t}- f_{i}(x ^{t})\|^{2}.\] (27)

Let us consider \(_{B}[_{p_{}}[\|h_{i,1}^{t+1}- _{B}[_{p_{}}[h_{i,1}^{t+1}]] \|^{2}]]\):

\[_{B}[_{p_{}}[\|h_{i, 1}^{t+1}-_{B}[_{p_{}}[h_{i,1}^{t+1} ]]\|^{2}]]\] \[=_{p_{}}[\|h_{i,1}^{t+1}-_{B}[_{p_{}}[h_{i,1}^{t+1}]]\| ^{2}]\] \[=p_{}\|h_{i}^{t}+}}k_{i,1}^{t +1}-(h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t})))\|^{2}\] \[+(1-p_{})\|h_{i}^{t}-(h_{i}^ {t}+ f_{i}(x^{t+1})- f_{i}(x^{t})-}}(h_{i }^{t}- f_{i}(x^{t})))\|^{2}\] \[=})^{2}}{p_{}}\| f_{i}(x ^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{ i}(x^{t}))\|^{2}\] \[+(1-p_{})\| f_{i}(x^{t+1})-  f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t}) )\|^{2}\] \[=}}{p_{}}\| f_{i}(x^{t+1 })- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t}) )\|^{2}.\]Considering (15) and Assumption 3, we obtain

\[_{B}[_{p_{}}[\|h_{i,1}^{ t+1}-_{B}[_{p_{}}[h_{i,1}^{t+1}] ]\|]]\] \[})L_{i}^{2}}{p_{}} \|x^{t+1}-x^{t}\|^{2}+})b^{2}}{p_ {}p_{}^{2}}\|h_{i}^{t}- f_{i}(x^{t})\|^ {2}.\] (28)

Next, we obtain the bound for \(_{B}[_{p_{}}[\|h_{i,2}^{t+1}- _{B}[_{p_{}}[h_{i,2}^{t+1}] ]\|^{2}]]\):

\[_{B}[_{p_{}}[\|h_{i, 2}^{t+1}-_{B}[_{p_{}}[h_{i,2}^{t+1} ]]\|^{2}]]\] \[=p_{}_{B}[\|h_{i}^{t}+}}k_{i,2}^{t+1}-(h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x ^{t}))\|^{2}]\] \[+(1-p_{})_{B}[\|h_{i}^{t}- (h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[=p_{}_{B}[\|}} k_{i,2}^{t+1}-( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[+(1-p_{})\| f_{i}(x^{t+1})- f_{i} (x^{t})\|^{2}\] \[+(1-p_{})\| f_{i}(x^{t+1})- f_{i} (x^{t})\|^{2}\] \[=}}_{B}[\|k_{i,2}^{t+1} -( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]+ }}{p_{}}\| f_{i}(x^{t+1})- f_{ i}(x^{t})\|^{2}\] \[}}_{B}[\|k_{i,2}^{t +1}-( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]+ })\,L_{i}^{2}}{p_{}}\|x^{t+1}-x^{t} \|^{2},\] (29)

where we used Assumption 3. By plugging (28) and (29) into (27), we get

\[_{B}[_{p_{}}[_ {p_{}}[\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2} ]]]\] \[ p_{}(})L _{i}^{2}}{p_{}}\|x^{t+1}-x^{t}\|^{2}+})b^{2}}{p_{}p_{}^{2}}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2})\] \[+(1-p_{})(}}_{B}[\|k_{i,2}^{t+1}-( f_{i}(x^{t+1})- f_{i}(x^{t}) )\|^{2}]+})\,L_{i}^{2}}{p_{ }}\|x^{t+1}-x^{t}\|^{2})\] \[+(p_{}(1-}} )^{2}+(1-p_{}))\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}\] \[})L_{i}^{2}}{p_{ }}\|x^{t+1}-x^{t}\|^{2}+}}{p_{}} _{B}[\|k_{i,2}^{t+1}-( f_{i}(x^{t+1})- f _{i}(x^{t}))\|^{2}]\] \[+(})b^{2}}{p_{ }p_{}}+p_{}(1-}})^{2}+(1-p_{}))\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}.\]

From the independence of elements in the mini-batch, we obtain

\[_{B}[_{p_{}}[\|h_{i} ^{t+1}- f_{i}(x^{t+1})\|^{2}]]]\] \[})L_{i}^{2}}{p_{ }}\|x^{t+1}-x^{t}\|^{2}+}}{p_{}} _{B}[\|_{j I_{i}^{t}}( f_{ij}(x^{ t+1})- f_{ij}(x^{t}))-( f_{i}(x^{t+1})- f_{i}(x^{t}) )\|^{2}]\] \[+(})b^{2}}{p_{ }p_{}}+p_{}(1-}} )^{2}+(1-p_{}))\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}\]\[=})L_{i}^{2}}{p_{}}\|x^{ t+1}-x^{t}\|^{2}+}}{p_{}B^{2}}_{B} [_{j I_{i}^{t}}\|( f_{ij}(x^{t+1})- f_{ij}(x^{ t}))-( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[+(})b^{2}}{p_{} p_{}}+p_{}(1-}})^{2}+ (1-p_{}))\|h_{i}^{t}- f_{i}(x^{t})\| ^{2}\] \[=})L_{i}^{2}}{p_{}}\| x^{t+1}-x^{t}\|^{2}+}}{mp_{}B}_{j=1}^{m} \|( f_{ij}(x^{t+1})- f_{ij}(x^{t}))-( f _{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}\] \[+(})b^{2}}{p_{} p_{}}+p_{}(1-}})^{2}+ (1-p_{}))\|h_{i}^{t}- f_{i}(x^{t})\| ^{2}\] \[})L_{i}^{2}}{p_{}} \|x^{t+1}-x^{t}\|^{2}+}}{mp_{}B}_ {j=1}^{m}\| f_{ij}(x^{t+1})- f_{ij}(x^{t})\|^{2}\] \[+(})b^{2}}{p_{} p_{}}+p_{}(1-}})^{2}+ (1-p_{}))\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}\] \[(})L_{i}^{2}}{p_{}}+})L_{}^{2}}{p_{}B}) \|x^{t+1}-x^{t}\|^{2}\] \[+(})b^{2}}{p_{} p_{}}+p_{}(1-}})^{2}+ (1-p_{}))\|h_{i}^{t}- f_{i}(x^{t}) \|^{2},\]

where we used Assumption 4. Finally, we prove the last inequality:

\[_{B}[_{p_{}}[\|k_{i}^{t+ 1}\|^{2}]]\] \[=p_{}\| f_{i}(x^{t+1})- f_{i}(x^{t}) -}}(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-p_{})_{B}[\|_ {j I_{i}^{t}}( f_{ij}(x^{t+1})- f_{ij}(x^{t}))\| ^{2}]\] \[}{=}p_{}\| f_{i}( x^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t}) )\|^{2}\] \[+(1-p_{})_{B}[\| _{j I_{i}^{t}}( f_{ij}(x^{t+1})- f_{ij}(x^{t}))- ( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[}{}2p_{}\| f_{i} (x^{t+1})- f_{i}(x^{t})\|^{2}+}{p_{}}\|h _{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+(1-p_{})_{B}[\| _{j I_{i}^{t}}( f_{ij}(x^{t+1})- f_{ij}(x^{t}))- ( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[+(1-p_{})\| f_{i}(x^{t+1})- f_{i }(x^{t})\|^{2}\] \[ 2\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}+ }{p_{}}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\]\[+(1-p_{})_{B}[\|_{j I _{i}^{t}}( f_{ij}(x^{t+1})- f_{ij}(x^{t}))-( f _{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}].\]

Using the independence of elements in the mini-batch, we have

\[_{B}[_{p_{}}[\|k_{i}^{t+1 }\|^{2}]]\] \[ 2\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2 }+}{p_{}}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+}}{B^{2}}_{B}[_{j I _{i}^{t}}\|( f_{ij}(x^{t+1})- f_{ij}(x^{t}))- ( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[=2\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}+ }{p_{}}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+}}{Bm}_{j=1}^{m}\|(  f_{ij}(x^{t+1})- f_{ij}(x^{t}))-( f_{i}(x^{t+1}) - f_{i}(x^{t}))\|^{2}\] \[ 2\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2 }+}{p_{}}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+}}{Bm}_{j=1}^{m}\| f_{ ij}(x^{t+1})- f_{ij}(x^{t})\|^{2}\]

It it left to consider Assumptions 3 and 4 to get

\[_{B}[_{p_{}}[\|k_{i}^{t+ 1}\|^{2}]]\] \[(2L_{i}^{2}+})L_{}^{2}} {B})\|x^{t+1}-x^{t}\|^{2}+}{p_{}} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}.\]

**Theorem 3**.: _Suppose that Assumptions 1, 2, 3, 4, 7, and 8 hold. Let us take \(a=}}{2+1},\,b=}p_{}}{2-p_{ }},\) probability \(p_{}(0,1]\),_

\[(L+[}^{2}}( ^{2}+})L_{}^{2}}{B})+}^{2}p_{}}((1-}}{p_{}})^{2}+})L_{}^{2}}{B} )]^{1/2})^{-1}\]

_and \(g_{i}^{0}=h_{i}^{0}= f_{i}(x^{0})\) for all \(i[n]\) in Algorithm 1_(DASHA-PP-PAGE) _then \([\| f(^{T})\|^{2}]}{ T^{2}}.\)_

Proof.: Let us fix constants \(,[0,)\) that we will define later. Considering Lemma 6, Lemma 8, and the law of total expectation, we obtain

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2 }]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}}[\| g^{t}-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n}\|g_ {i}^{t}-h_{i}^{t}\|^{2}]\]\[+^{2}}{ E}[_{i=1}^{n}\|k_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f_ {i}(x^{t+1})\|^{2}]\] \[={ E}[f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^ {t}\|^{2}]+-p_{ a})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\] \[+^{2}}{ E}[{  E}_{B}[{ E}_{p_{ pair}}[_{i=1}^{n}\|k_ {i}^{t+1}\|^{2}]]]\] \[+[{ E}_{B}[{ E}_{p_{ pair}}[ \|h^{t+1}- f(x^{t+1})\|^{2}]]]\] \[+[{ E}_{B}[{ E}_{p_{ pair}}[ _{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2} ]]]\] \[[f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^ {t}\|^{2}]+-p_{ a})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\] \[+^{2}}{ E}[ (2^{2}+)L_{ max}^{2}}{B})\|x^ {t+1}-x^{t}\|^{2}+}{p_{ page}}_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(-p_{ a}) ^{2}}{np_{ a}^{2}}+)L_{ max}^{2}}{np_{ a }B})\|x^{t+1}-x^{t}\|^{2}\] \[+-p_{ a})b^{2}}{n^{2}p_{ a}^{2 }p_{ page}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+ (p_{ page}(1-})^{2}+(1-p_{ page}) )\|h^{t}- f(x^{t})\|^{2}\] \[+() ^{2}}{p_{ a}}+)L_{ max}^{2}}{p_{ a}B })\|x^{t+1}-x^{t}\|^{2}\] \[+()b^{2}}{p_{ a}p_{ page} }+p_{ page}(1-})^{2}+(1-p_{ page})) _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\]

After rearranging the terms, we get

\[{ E}[f(x^{t+1})]+ }{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ a})}{np_{ a}^{2}}{ E}[_{i=1}^{n} \|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f_ {i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^ {t}\|^{2}]+-p_{ a})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\] \[-(--^{2}}(2^{2}+)L_{ max}^{2}}{B }).\]\[-(}-p_{})^{2}}{ np_{}^{2}}+})L_{}^{2}}{np_{ }B})-(})^{2}}{ p_{}}+})L_{}^{2}}{p_{}B} )[\|x^{t+1}-x^{t}\|^{2}]\] \[+(+(p_{}(1-}})^{2}+(1-p_{})))[\|h^{t}-  f(x^{t})\|^{2}]\] \[+((2+1)}{np_{}^{2}p_{ }}+}-p_{})b^{2}}{np_{ }^{2}p_{}}.\] \[+(})b^{2}}{p_{ }p_{}}+p_{}(1-}} )^{2}+(1-p_{})))[ {n}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

Due to \(b=}p_{}}{2-p_{}} p_{}\), one can show that \((p_{}(1-}})^{2}+(1-p_{ })) 1-b\). Thus, if we take \(=\), then

\[(+(p_{}(1-}})^ {2}+(1-p_{})))+(1-b)=,\]

therefore

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}}[ {n}_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}}[\|g^{t }-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n}\|g _{i}^{t}-h_{i}^{t}\|^{2}]\] \[-(--}^{2}}(2^{2}+})L_{ }^{2}}{B}).\] \[-(}-p_{})^{2}}{np_{}^{2}}+})L_{ }^{2}}{np_{}B})-(} )^{2}}{p_{}}+})L_{ }^{2}}{p_{}B}))[\|x^{t+1}-x^{t }\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]\] \[+((2+1)}{np_{}^{2}p_{ }}+}-p_{})b}{np_{}^{2}p_{}}.\] \[+(})b^{2}}{p_{ }p_{}}+p_{}(1-}} )^{2}+(1-p_{})))[ {n}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

Next, with the choice of \(b=}p_{}}{2-p_{}}\), we ensure that

\[(})b^{2}}{p_{}p_{}}+p_{ }(1-}})^{2}+(1-p_{})) 1-b.\]

If we take \(=}^{2}p_{}^{2}}+ }-p_{})}{np_{}^{2}p_{}},\) then

therefore

\[[f(x^{t+1})]+}} [\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}}[ {n}_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\]\[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(}^{2}p_ {}}+}-p_{})}{np_{ }^{2}p_{}})[_{i=1}^{n }\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+}}[\|g ^{t}-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[-(--}^{2}}(2^{2}+})L_{}^{2}}{B}).\] \[.-}}(2(1-}}{p_{}})^{2}+})L_{}^{2}}{B}).\] \[.-(}^{3}p_{}}+}}{p_{ }^{2}})}{np_{}^{2}p_{}})(2 (1-p_{})^{2}+})L_{ }^{2}}{B}))\![\|x^{t+1}-x^{t} \|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2} p_{}}+}-p_{})}{np_{ }^{2}p_{}})[_{i=1}^{n }\|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

Let us simplify the inequality. First, due to \(b}p_{}}{2}\), we have

\[}}(2(1-}}{p_{ }})^{2}+})L_{} ^{2}}{B})}^{2}p_{}}( (1-}}{p_{}})^{2}+})L_{}^{2}}{B}).\]

Second, due to \(b p_{}p_{}\) and \(p_{} p_{}^{2}\), we get

\[(}^{3}p_{ }}+}}{p_{}} )}{np_{}^{2}p_{}})(2(1-p_{})^{2}+})L_{}^{2}}{B})\] \[(}^{2}}+ }}{p_{}})}{np_{ }^{2}p_{}})(2(1-}}{p _{}})^{2}+})L_{ }^{2}}{B})\] \[}^{2}}( (1-}}{p_{}})^{2}+})L_{}^{2}}{B})\] \[+}}{p_{} })}{np_{}^{2}p_{}}((1-}}{p_{}})^{2}+})L_{}^{2}}{B})\] \[}^{2}}( ^{2}+})L_{}^{2}}{B})\] \[+}^{2}p_{}}( (1-}}{p_{}})^{2}+})L_{}^{2}}{B}).\]

Combining all bounds together, we obtain the following simplified inequality:

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2 }]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+}}[ \|g^{t}-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\]\[-(--^{2}p_{ pa}}(^{2}+)L_{ max }^{2}}{B}).\] \[-^{2}p_{ page}}((1- }{p_{ a}})^{2}+)L_{  max}^{2}}{B})[\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]+(^{2}p_{ page} }+-p_{ aa})}{np_{ a}^{2}p_{ page}} ){ E}[_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{ t})\|^{2}].\]

Using Lemma 4 and the assumption about \(\), we get

\[{ E}[f(x^{t+1})]+ }{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{ n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(^{2}p_{  page}}+-p_{ aa})}{np_{ a}^{2}p_{ page }}){ E}[_{i=1}^{n}\|h_{i}^{t+1}- f_{i}( x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{t }\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]+(^{2}p_{ page} }+-p_{ aa})}{np_{ a}^{2}p_{ page}} ){ E}[_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{ t})\|^{2}].\]

It is left to apply Lemma 3 with

\[^{t} = }{ E}[\|g^{t}-h^{t} \|^{2}]+-p_{ aa})}{np_{  a}^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+[\|h^{t}- f(x^{t})\|^{2} ]+(^{2}p_{ page}}+-p_{ aa})}{np_{ a}^{2}p_{ page}}){ E} [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\]

to conclude the proof. 

**Corollary 1**.: _Let the assumptions from Theorem 3 hold and \(p_{ page}=}{{(m+B)}}\). Then_ DASHA-PP-PAGE _needs_

\[T:=}{}L+ }(+}{} )+}}(} }{}+}{B})\] (10)

_communication rounds to get an \(\)-solution and the expected number of gradient calculations per node equals \((m+BT).\)_

Proof.: In the view of Theorem 3, it is enough to do

\[T:=(}{}[L+}{np_{ a}^{2}}(^{2}+)L_{  max}^{2}}{B})+^{2}p_{ page}}((1-}{p_{ a}})^{2}+)L_{ max}^{2}}{B} )]})\]

steps to get \(\)-solution. Using the choice of \(p_{ mega}\) and the definition of \(_{p_{ a}}\), we can get (10).

Note that the expected number of gradients calculations at each communication round equals \(p_{ mega}m+(1-p_{ mega})B= 2B\). 

**Corollary 2**.: _Suppose that assumptions of Corollary 1 hold, \(B\{}},^{2}}{1_{p _{ a}}L^{2}}\}\)8, and we use the unbiased compressor \(K\) with \(K=(}{{}}).\) Then the communication complexity of _Algorithm 1 is \((d+_{0}d}{p_{}} ),\) and the expected number of gradient calculations per node equals \((m+_{0}}{p_{} }).\)_

Proof.: The communication complexity equals

\[(d+KT) = (d+}{}[KL+K}}(+}{} )+K}}}( }}}{}+}{B})]).\]

Since \(B^{2}}{1_{p_{}}^{2}L^{2}},\) we have \(}}}{}+}{B}}{B}\) and

\[(d+KT) = (d+}{}[KL+K}}(+}{} )+K}}}}{B}] ).\]

Note that \(K=(})=(}})\) and \(+1=\) due to Theorem 6, thus

\[(d+KT) = (d+}{}[}}L+}}(+ }{})+}}L_{} ])\] \[= (d+_{0}d}{p_{} }).\]

Using the same reasoning, the expected number of gradient calculations per node equals

\[(m+BT) = (m+}{}[BL+B}}(+}{} )+B}}}(}}}{}+}{B})])\] \[= (m+}{}[BL+B}}(+}{} )+B}}}}{B}])\] \[= (m+}{}[}}}L+}{p_{}} (+}{})+}} }L_{}])\] \[= (m+_{0}}{p_{}}).\]

### Proof for Dasha-Pp-Finite-Mvr

**Lemma 9**.: _Suppose that Assumptions 3, 4, and 8 hold. For \(h_{i}^{t+1}\), \(h_{ij}^{t+1}\) and \(k_{i}^{t+1}\) from Algorithm 1 (DASHA-PP-Finite-Mvr) we have_

1. \[_{B}[_{p_{}}[\|h^{t+ 1}- f(x^{t+1})\|^{2}]]\] \[(^{2}}{np_{}B}+}-p_{})^{2}}{np_{}^{2}}) \|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n^{2 }p_{}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\| ^{2}+}{n^{2}p_{}Bm}_{i=1}^{n}_{j=1}^{m}\|h_ {ij}^{t}- f_{ij}(x^{t})\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}.\]
2. \[_{B}[_{p_{}}[\|h_{i} ^{t+1}- f_{i}(x^{t+1})\|^{2}]]\] \[(^{2}}{p_{}B}+})L_{i}^{2}}{p_{}})\|x^{t+1}-x^{t}\|^{2}\] \[+}{p_{}Bm}_{j=1}^{m}\|h_{ij}^ {t}- f_{ij}(x^{t})\|^{2}+(})b ^{2}}{p_{}}+(1-b)^{2})\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}, i[n].\]3. \[_{B}[_{_{}}[\|h _{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]]\] \[}B}{m})L_{}^{2}}{}B}{m}}\|x^{t+1}-x^{t}\|^{2}\] \[+(}B}{m})b^{2}} {}B}{m}}+(1-b)^{2})\|h_{ij}^{t}- f_{ij}(x ^{t})\|^{2}, i[n], j[m].\]
4. \[_{B}[\|k_{i}^{t+1}\|^{2}]\] \[(}^{2}}{B}+2L_{i}^{2}) \|x^{t+1}-x^{t}\|^{2}\] \[+}{Bm}_{j=1}^{m}\|h_{ij}^{t}- f_{ ij}(x^{t})\|^{2}+2b^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2},  i[n].\]

Proof.: We start by proving the first inequality. Note that

\[_{B}[_{_{}}[h_{ i}^{t+1}]]\] \[=h_{i}^{t}+_{j=1}^{m} ( f_{ij}(x^{t+1})- f_{ij}(x^{t})-b(h_{ij}^{t}- f_{ ij}(x^{t})))+(1-) 0\] \[= f_{i}(x^{t+1})+(1-b)(h_{i}^{t}- f_{i}(x^{t}) ),\]

thus

\[_{B}[_{_{}}[ \|h^{t+1}- f(x^{t+1})\|^{2}]]\] \[}{=}_{B}[_{ _{}}[\|h^{t+1}-_{B}[_{ _{}}[h^{t+1}]]\|^{2}]]+(1 -b)^{2}\|h^{t}- f(x^{t})\|^{2}.\]

We can use Lemma 1 with \(r_{i}=h_{i}^{t}\) and \(s_{i}=k_{i}^{t+1}\) to obtain

\[_{B}[_{_{}}[ \|h^{t+1}- f(x^{t+1})\|^{2}]]\] \[p_{}}_{i=1}^{n}_{B} [\|k_{i}^{t+1}-_{B}[k_{i}^{t+1}]\|^{2} ]+}-p_{}}{n^{2}p_{}^{2}}_{i=1 }^{n}\|_{B}[k_{i}^{t+1}]\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}\] \[=p_{}}_{i=1}^{n}_{B}[ \|_{j=1}^{m}k_{ij}^{t+1}-( f_{i}(x^{t+1})-  f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t})))\| ^{2}]\] \[+}-p_{}}{n^{2}p_{}^{2} }_{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{ t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}.\]

Next, we again use Lemma 1 with \(r_{i}=0\), \(s_{i}= f_{ij}(x^{t+1})- f_{ij}(x^{t})-b(h_{ij}^{t}- f_{ ij}(x^{t})),\)\(p_{}=,\) and \(p_{}=.\)

[MISSING_PAGE_EMPTY:43]

\[}}(_{j=1}^{m} \| f_{ij}(x^{t+1})- f_{ij}(x^{t})-b(h_{ij}^{t}- f_{ ij}(x^{t}))\|^{2})\] \[+}}{p_{}}\| f_{i}(x^{t +1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[}Bm}_{j=1}^{m}\| f_{ij}(x^ {t+1})- f_{ij}(x^{t})-b(h_{ij}^{t}- f_{ij}(x^{t})) \|^{2}\] \[+}}{p_{}}\| f_{i}(x^{t +1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[}}{{}}}B}{m})}{}B}{m}}\| f_{ij}(x ^{t+1})- f_{ij}(x^{t})\|^{2}+(} )b^{2}}{p_{}}+(1-b)^{2})\|h_{ij}^{t}- f_{ij}(x^ {t})\|^{2}.\]It is left to consider Assumption 4:

\[_{B}[_{p_{}}[\|h_{ij}^{t+ 1}- f_{ij}(x^{t+1})\|^{2}]]\] \[}B}{m})L_{ }^{2}}{}B}{m}}\|x^{t+1}-x^{t}\|^{2}+(}B}{m})b^{2}}{}B}{m}}+(1- b)^{2})\|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}.\]

Finally, we obtain the bound for the last inequality of the lemma:

\[_{B}[\|k_{i}^{t+1}\|^{2}]\] \[}}{{=}}_{B} [\|k_{i}^{t+1}-_{B}[k_{i}^{t+1}]\|^{2}]\] \[+\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{ t}- f_{i}(x^{t}))\|^{2}.\]

Using Lemma 1, we get

\[_{B}[\|k_{i}^{t+1}\|^{2}]\] \[_{j=1}^{m}\| f_{ij}(x^{t+1}) - f_{ij}(x^{t})-b(h_{ij}^{t}- f_{ij}(x^{t}))\|^{2}\] \[+\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{ t}- f_{i}(x^{t}))\|^{2}\] \[_{j=1}^{m}\| f_{ij}(x^{t+1})-  f_{ij}(x^{t})-b(h_{ij}^{t}- f_{ij}(x^{t}))\|^{2}\] \[+\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{ t}- f_{i}(x^{t}))\|^{2}\] \[}}{{}}_ {j=1}^{m}\| f_{ij}(x^{t+1})- f_{ij}(x^{t})\|^{2}+2 \| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}\] \[+}{Bm}_{j=1}^{m}\|h_{ij}^{t}- f_{ ij}(x^{t})\|^{2}+2b^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2},\]

where we used Assumptions 3 and 4. 

**Theorem 7**.: _Suppose that Assumptions 1, 2, 3, 4, 7, and 8 hold. Let us take \(a=}}{2+1}\), \(b=}B}{m}}{2-}\), \(g_{i}^{0}=h_{i}^{0}= f_{i}(x^{0})\) for all \(i[n]\) and \(h_{ij}^{0}= f_{ij}(x^{0})\) for all \(i[n]\), \(j[m]\) in Algorithm 1 (DASHA-PP-FINITE-MVR) then \([\| f(^{T})\|^{2}]}{^{T}}\)._

Proof.: Let us fix constants \(,,[0,)\) that we will define later. Considering Lemma 6, Lemma 9, and the law of total expectation, we obtain

\[[f(x^{t+1})]+}} [\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\]\[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\] \[+[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]\] \[[f(x^{t})-\| f(x^{ t})\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}}[\| g^{t}-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+}^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\] \[+[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]\] \[=[f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}}[\| g^{t}-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+}^{2}} [_{B}[_{i=1}^{n}\|k_{i}^{t+1}\|^ {2}]]\] \[+[_{B}[_{p_{ }}[\|h^{t+1}- f(x^{t+1})\|^{2}]]]\] \[+[_{B}[_{p_{ }}[_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1}) \|^{2}]]]\] \[+[_{B}[_{p_{}}[_{i=1}^{n}_{j=1}^{m}\|h_{ij}^{t+1}- f_{ij}(x^{t+1}) \|^{2}]]]\] \[[f(x^{t})-\| f(x^{t} )\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}}[\| g^{t}-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+}^{2}} [(}^{2}}{B}+2^{2})\|x^{t+1 }-x^{t}\|^{2}+}{Bmn}_{i=1}^{n}_{j=1}^{m}\|h_{ ij}^{t}- f_{ij}(x^{t})\|^{2}+}{n}_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(}^{2}}{np_{ }B}+}-p_{})^{2}}{ np_{}^{2}})\|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n^{2}p_{ }^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+ }{n^{2}p_{}Bm}_{i=1}^{n}_{j=1}^{m}\|h_{ij}^{t} - f_{ij}(x^{t})\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}\]\[+(}^{2}}{p_{}B}+ })^{2}}{p_{}})\|x^{t+1}-x^{t }\|^{2}\] \[+}{p_{}Bnm}_{i=1}^{n}_{j=1}^{m}\| h_{ij}^{t}- f_{ij}(x^{t})\|^{2}+(} )b^{2}}{p_{}}+(1-b)^{2})_{i=1}^{n}\|h_ {i}^{t}- f_{i}(x^{t})\|^{2}\] \[+}B}{m} )L_{}^{2}}{}B}{m}}\|x^{t+1}-x^{t}\| ^{2}\] \[+(}B}{m})b^{2}}{ {p_{}B}{m}}+(1-b)^{2})_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}.\]

Due to \(b=}B}{2-}B}{m}}}}{2-p_ {}}\), we have

\[(}B}{m})b^{2}}{}B }{m}}+(1-b)^{2}) 1-b\]

and

\[(})b^{2}}{p_{}}+(1-b)^{2})  1-b.\]

Moreover, we consider that \(1-}B}{m} 1,\) therefore

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\] \[+[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]\] \[[f(x^{t})-\| f(x^{t} )\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}}[\|g^{t }-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n}\|g_ {i}^{t}-h_{i}^{t}\|^{2}]\] \[+}^{2}}[ (}^{2}}{B}+2^{2})\|x^{t+1}-x^{t }\|^{2}+}{Bmn}_{i=1}^{n}_{j=1}^{m}\|h_{ij}^{t}-  f_{ij}(x^{t})\|^{2}+}{n}_{i=1}^{n}\|h_{i}^{ t}- f_{i}(x^{t})\|^{2}]\] \[+(}^{2}}{np_{}B}+}-p_{})^{2}}{np_{}^{2}} )\|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n^{2}p_{ {a}}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+}{n^{2}p_{}Bm}_{i=1}^{n}_{j=1}^{m}\|h_{ij}^{t}- f _{ij}(x^{t})\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}\] \[+(}^{2}}{p_{}B}+})^{2}}{p_{}})\|x^{t+1}-x^{t} \|^{2}\]\[+}{p_{}Bnm}_{i=1}^{n}_{j=1}^{m}\|h _{ij}^{t}- f_{ij}(x^{t})\|^{2}+(1-b)\,_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+}^{2}}{p_{}B} \|x^{t+1}-x^{t}\|^{2}+(1-b)\,_{i=1}^{n}_{j=1}^ {m}\|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}.\]

After rearranging the terms, we get

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\] \[+[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+}}[\|g^{t }-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}- h_{i}^{t}\|^{2}]\] \[-(--}^{2}}(}^{2}}{B}+2^{2}).\] \[.-(}^{2}}{np_{}B} +}-p_{})^{2}}{np_{ }^{2}})-(}^{2}}{p_{}B}+})^{2}}{p_{}})- }^{2}}{p_{}B})[\|x^{t+1}-x^{t}\|^{2}]\] \[+(+(1-b)^{2})[\| h^{t}- f(x^{t})\|^{2}]\] \[+((2+1)}{np_{}^{2}}+ }-p_{})b^{2}}{np_{}^{2}}+ (1-b))[_{i=1}^{n}\|h_{i} ^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{}^{2}B}+ }{np_{}B}+}{p_{}B}+ (1-b))[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}].\]

Thus, if we take \(=\), then \(+(1-b)^{2}\) and

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}}[ {1}{n}_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}}[\|g^{t }-h^{t}\|^{2}]+}-p_{ })}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}- h_{i}^{t}\|^{2}]\] \[-(--}^{2}}(}^{2}}{B}+2^{2})\]\[-(^{2}}{bnp_{ a}B}+-p_{ aa})^{2}}{bnp_{ a}^{2}})- (^{2}}{p_{ a}B}+)^{2} }{p_{ a}})-^{2}}{p_{ a}B} [\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ -p_{ aa})b}{np_{ a}^{2}}+(1-b )){ E}[_{i=1}^{n}\|h_{i}^{t}- f _{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}B}+ B}+}{p_{ a}B}+(1-b )){ E}[_{i=1}^{n}_{j=1}^{m}\|h_{ ij}^{t}- f_{ij}(x^{t})\|^{2}].\]

Next, if we take \(=^{2}}+-p_{ aa})b}{np_{ a}^{2}}\), then

\[((2+1)}{np_{ a}^{2}}+-p_{ aa})b}{np_{ a}^{2}}+(1-b) )=,\]

therefore

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(^{2}}+ -p_{ aa})}{np_{ a}^{2}}){ E} [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\| ^{2}]\] \[+[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^ {t}\|^{2}]+-p_{ aa} )}{np_{ a}^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i} ^{t}\|^{2}]\] \[-(--^{2}}(^{2}}{B}+2^{2})\] \[-(^{2}}{bp_{ a}B}+-p_{ aa})^{2}}{bnp_{ a}^{2}})- (^{2}}+-p_{ aa})}{np_{ a}^{2}})(^{2}}{p_{  a}B}+)^{2}}{p_{ a}})\] \[-^{2}}{p_{ a}B} [\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]\] \[+(^{2}}+-p_{ aa})}{np_{ a}^{2}}){ E}[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}B}+ B}+(2+1)}{np_{ a}^{ 3}B}+(p_{ a}-p_{ aa})}{nBp_{ a}^{3}}+ (1-b)){ E}[_{i=1}^{n}_{j=1}^{m }\|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}].\]

Due to \(b p_{ a}\) and \(-p_{ aa}}{p_{ a}} 1\), we have

\[(2+1)}{np_{ a}^{2}B}+B}+(2+1)}{np_{ a}^{3}B}+ (p_{ a}-p_{ aa})}{nBp_{ a}^{3}}\] \[(2+1)}{np_{ a}^{2}B}+B}+(2+1)}{np_{ a}^{2}B}+ B}\]\[=(2+1)}{np_{ a}^{2}B}+B}.\]

Let us take \(=^{2}B}+B}.\) Thus

\[((2+1)}{np_{ a}^{2}B}+B}+(2+1)}{np_{ a}^{3}B}+ (p_{ a}-p_{ aa})}{nBp_{ a}^{3}}+(1-b ))\]

and

\[&[f(x^{t+1})]+}[\|g^{t+1}-h^{t+1}\|^{2}]+ -p_{ a})}{np_{ a}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\| ^{2}]\\ &+[\|h^{t+1}- f( x^{t+1})\|^{2}]+(^{2}}+ -p_{ a})}{np_{ a}^{2}})[_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\| ^{2}]\\ &+(^{2}B}+ B})[_{i=1}^{n} _{j=1}^{m}\|h_{ij}^{t+1}- f_{ij}(x^{t+1})\|^{2}]\\ &[f(x^{t})]- [\| f(x^{t})\|^{2}]\\ &+}[\| g^{t}-h^{t}\|^{2}]+-p_{  a})}{np_{ a}^{2}}[_{i=1}^{n}\|g_{i}^ {t}-h_{i}^{t}\|^{2}]\\ &-(--^{2}}(^{2}}{B}+2^{2} ).\\ &-(^{2}}{bnp_{ a}B}+ -p_{ a})^{2}}{bnp_{ a}^{2}} )-(^{2}}+-p_{ a})}{np_{ a}^{2}})(^{2}}{p_{ a}B}+)^{2}}{p_{ a}})\\ &.-(^{2 }B}+B})^{2}}{p_{ a}B} )\![\|x^{t+1}-x^{t}\|^{2}]\\ &+[\|h^{t}- f(x^{t })\|^{2}]\\ &+(^{2}}+ -p_{ a})}{np_{ a}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2 }]\\ &+(^{2}B}+ B})[_{i=1}^{n} _{j=1}^{m}\|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}].\]

Let us simplify the term near \([\|x^{t+1}-x^{t}\|^{2}].\) Due to \(b p_{ a}\), \(-p_{ a}}{p_{ a}} 1,\) and \(1-p_{ a} 1,\) we have

\[&^{2}} (^{2}}{B}+2^{2})\\ &+(^{2}}{bnp_{ a}B}+-p_{ a})^{2}}{bnp_{ a}^{2}}) \\ &+(^{2}}+ -p_{ a})}{np_{ a}^{2}})( ^{2}}{p_{ a}B}+)^{2}}{p_{  a}})\\ &+(^{2}B}+ B})^{2}}{p_{ a}B}\\ &^{2}}(^{2}}{B}+2^{2})\]\[+(^{2}}{bnp_{ a}B}+-p_{ aa})^{2}}{bnp_{ a}^{2}})\] \[+(^{2}B}+B})^{2}}{p_{ a}B}\]

Considering that \(bB}{m}\) and \(bB}{2m}\), we obtain

\[^{2}}(^{2}}{B}+2^{2})\] \[+(^{2}}{bnp_{ a}B}+-p_{ aa})^{2}}{bnp_{ a}^{2}})\] \[+(^{2}}+-p_{ aa})}{np_{ a}^{2}})(^{2}}{p_{ a}B}+)^{2}}{p_{ a}})\] \[+(^{2}B}+B})^{2}}{p_{ a}B}\] \[^{2}}(^{2}}{B}+2^{2})+(^{2}}{ bnp_{ a}B}+-p_{ aa})^{2}}{ bnp_{ a}^{2}})\] \[^{2}}(^{2}}{B}+2^{2})+(^{2}}{ np_{ a}^{2}B^{2}}+-p_{ aa})^{2}}{Bnp_{  a}^{3}}).\]

All in all, we have

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+}{ E}[\|g^{t}-h^ {t}\|^{2}]+-p_{ aa })}{np_{ a}^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i} ^{t}\|^{2}]\] \[-(--^{2}}(^{2}}{B}+2^{2} )-(^{2}}{np_{ a}^{2}B^{2}}+-p_{ aa})^{2}}{Bnp_{ a}^{3}} )){ E}[\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]\] \[+(^{2}}+-p_{ aa})}{np_{ a}^{2}}){ E}[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(^{2}B}+B}){ E}[_{i=1}^{n}_{j=1}^{m }\|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}].\]

Using Lemma 4 and the assumption about \(\), we get

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\]\[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(}^{2}}+ }-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+ 1})\|^{2}]\] \[+(}^{2}B}+ }B})[_{i=1}^{n} _{j=1}^{m}\|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1} )\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]\] \[+(}^{2}}+ }-p_{})}{np_{}^{2}} )[_{i=1}^{n}\|h_{i}^{t}- f_{i}( x^{t})\|^{2}]\] \[+(}^{2}B}+ }B})[_{i=1}^{n} _{j=1}^{m}\|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}].\]

It is left to apply Lemma 3 with

\[^{t} = }}[\|g^{t}-h^{t} \|^{2}]+}-p_{} )}{np_{}^{2}}[_{i=1}^{n}\|g_ {i}^{t}-h_{i}^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]\] \[+(}^{2}}+}-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(}^{2}B}+}B})[_{i=1}^{n}_{j=1}^{m} \|h_{ij}^{t}- f_{ij}(x^{t})\|^{2}]\]

to conclude the proof. 

### Proof for \(\)

Let us denote \( f_{i}(x^{t+1};_{i}^{t+1}):=_{j=1}^{B} f_{i}(x^ {t+1};_{ij}^{t+1})\).

**Lemma 10**.: _Suppose that Assumptions 3, 5, 6 and 8 hold. For \(h_{i}^{t+1}\) and \(k_{i}^{t+1}\) from Algorithm 1 (\(\)) we have_

1. \[_{k}[._{p_{}}[\|h^ {t+1}- f(x^{t+1})\|^{2}]]\] \[^{2}}{np_{}B}+( L_{}^{2}}{np_{}B}+}-p_{} )^{2}}{np_{}^{2}})\|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n^{2}p _{}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2} +(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}.\]
2. \[_{k}[_{p_{}}[\|h_{i}^{t +1}- f_{i}(x^{t+1})\|^{2}]]\] \[^{2}}{p_{}B}+( L_{}^{2}}{p_{}B}+})L_{i}^{2}}{p_{}} )\|x^{t+1}-x^{t}\|^{2}\] \[+(})b^{2}}{p_{}}+(1-b)^{2 })\|h_{i}^{t}- f_{i}(x^{t})\|^{2}, i[n].\]3. \[_{k}[\|k_{i}^{t+1}\|^{2}] ^{2}}{B}+(L_{}^{2}}{B}+2L_{i}^{2}) \|x^{t+1}-x^{t}\|^{2}+2b^{2}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}, i[n].\]

Proof.: First, let us proof the bound for \(_{k}[_{p_{k}}[\|h^{t+1}- f(x^{t+1}) \|^{2}]]\):

\[=_{k}[_{p_{k}}[\|h^{t+1}- _{k}[_{p_{k}}[h^{t+1}]]\|^{2 }]]+\|_{k}[_{p_{k}}[h^{t+1} ]]- f(x^{t+1})\|^{2}.\]

Using

\[_{k}[_{p_{k}}[h_{i}^{t+1}] ]=h_{i}^{t}+_{k}[k_{i}^{t+1}]=h_{i}^{t}+ f_{ i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\]

and (16), we have

\[_{k}[_{p_{k}}[\|h^{t+1}- f (x^{t+1})\|^{2}]]\] \[=_{k}[_{p_{k}}[\|h^{t+1}- _{k}[_{p_{k}}[h^{t+1}]]\|^{2 }]+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}.\]

We can use Lemma 1 with \(r_{i}=h_{i}^{t}\) and \(s_{i}=k_{i}^{t+1}\) to obtain

\[_{k}[_{p_{k}}[\|h^{t+1}- f (x^{t+1})\|^{2}]]\] \[p_{k}}_{i=1}^{n}_{k}[\| k_{i}^{t+1}-_{k}[k_{i}^{t+1}]\|^{2}]+}-p_{}}{n^{2}p_{}^{2}}_{i=1}^{n}\| _{k}[k_{i}^{t+1}]\|^{2}+(1-b)^{2}\|h^{t}- f (x^{t})\|^{2}\] \[=p_{}}_{i=1}^{n}_{k}[ \| f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t};_{i}^{t+1})-b (h_{i}^{t}- f_{i}(x^{t};_{i}^{t+1}))..\] \[-( f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{ i}^{t}- f_{i}(x^{t})))\|^{2}]\] \[+}-p_{}}{n^{2}p_{}^ {2}}_{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i} ^{t}- f_{i}(x^{t}))\|^{2}\] \[+}-p_{}}{n^{2}p_{}^ {2}}_{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t }- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}\] \[=}{n^{2}p_{}}_{i=1}^{n}_{k} [\| f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t};_{i}^{ t+1})-( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[+}{n^{2}p_{}}_{i=1}^{n} \| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t }))\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}\] \[=}{n^{2}p_{}}_{i=1}^{n}_{k} [\| f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t+1})\| ^{2}]\] \[+}{n^{2}p_{}}_{i=1}^{n} _{k}[\| f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^ {t};_{i}^{t+1})-( f_{i}(x^{t+1})- f_{i}(x^{t})) \|^{2}]\] \[+}-p_{}}{n^{2}p_{}^ {2}}_{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t }- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}.\]

[MISSING_PAGE_EMPTY:54]

Now, we prove the second inequality:

\[_{k}[_{p_{k}}[\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]]\] \[=_{k}[_{p_{k}}[\|h_{i}^{t+1}- _{k}[_{p_{k}}[h_{i}^{t+1}]]\|^ {2}]]\] \[+\|_{k}[_{p_{k}}[h_{i}^{ t+1}]]- f_{i}(x^{t+1})\|^{2}\] \[=_{k}[_{p_{k}}[\|h_{i}^{t+1}- (h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f _{i}(x^{t})))\|^{2}]]\] \[+\|h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{t})- b(h_{i}^{t}- f_{i}(x^{t}))- f_{i}(x^{t+1})\|^{2}\] \[=_{k}[_{p_{k}}[\|h_{i}^{t+1}- (h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f _{i}(x^{t})))\|^{2}]]\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[=p_{}_{k}[\|h_{i}^{t}+}}k_{i}^{t+1}-(h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{ t})-b(h_{i}^{t}- f_{i}(x^{t})))\|^{2}]\] \[+(1-p_{})\|h_{i}^{t}-(h_{i}^{t}+ f _{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t})))\| ^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+})^{2}}{p_{}}\| f _{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-p_{})\| f_{i}(x^{t+1})- f_{i} (x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[=}}_{k}[\| f_{i} (x^{t+1};_{i}^{t+1})- f_{i}(x^{t};_{i}^{t+1})-b(h_{i}^{t}-  f_{i}(x^{t};_{i}^{t+1}))-( f_{i}(x^{t+1})- f _{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t})))\|^{2}]\] \[+}}{p_{}}\| f_{i} (x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[=}}_{k}[\|b( f _{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t};_{i}^{t+1}))+(1-b) ( f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t};_{i}^{t+1})- ( f_{i}(x^{t+1})- f_{i}(x^{t})))\|^{2}]\] \[+}}{p_{}}\| f_{i} (x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\] \[}{}}{p_{}} _{k}[\| f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^ {t+1})\|^{2}]\] \[+}{p_{}}_{k}[\|  f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t};_{i}^{t+1})-(  f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[+}}{p_{}}\| f_{i}(x^ {t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}.\]Considering the independence of elements in the mini-batch, we obtain

\[_{k}[_{p_{}}[\|h_{i}^{t+1 }- f_{i}(x^{t+1})\|^{2}]]\] \[=}{p_{}B^{2}}_{j=1}^{B}_{k} [\| f_{i}(x^{t+1};_{ij}^{t+1})- f_{i}(x^{t+1})\| ^{2}]\] \[+}{p_{}B^{2}}_{j=1}^{B} _{k}[\| f_{i}(x^{t+1};_{ij}^{t+1})- f_{i}(x ^{t};_{ij}^{t+1})-( f_{i}(x^{t+1})- f_{i}(x^{t})) \|^{2}]\] \[+}}{p_{}}\| f_{i}( x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t}))\|^{2}\] \[+(1-b)^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}.\] \[}{}}{p_{}B^{2} }_{j=1}^{B}_{k}[\| f_{i}(x^{t+1};_{ij}^{t+1})-  f_{i}(x^{t+1})\|^{2}]\] \[+}{p_{}B^{2}}_{j=1}^{B} _{k}[\| f_{i}(x^{t+1};_{ij}^{t+1})- f_{i}( x^{t};_{ij}^{t+1})-( f_{i}(x^{t+1})- f_{i}(x^{t})) \|^{2}]\] \[+})}{p_{}}\| f_{ i}(x^{t+1})- f_{i}(x^{t})\|^{2}+(})b^{2}}{p_ {}}+(1-b)^{2})\|h_{i}^{t}- f_{i}(x^{t})\|^{2}\]

Next, we use Assumptions 3, 6, 5, to get

\[_{k}[\|h_{i}^{t+1}- f_{i}(x^{t+1}) \|^{2}]]\] \[^{2}}{p_{}B}+(L_{}^{2}}{p_{}B}+})L_{i}^{2}}{p_{ }})\|x^{t+1}-x^{t}\|^{2}\] \[+(})b^{2}}{p_{}}+(1-b) ^{2})\|h_{i}^{t}- f_{i}(x^{t})\|^{2}.\]

It is left to prove the bound for \(_{k}[\|k_{i}^{t+1}\|^{2}]\):

\[_{k}[\|k_{i}^{t+1}\|^{2}]\] \[=_{k}[\| f_{i}(x^{t+1};_{i}^{t+1})-  f_{i}(x^{t};_{i}^{t+1})-b(h_{i}^{t}- f_{i}(x^{t};_{i}^{ t+1}))\|^{2}]\] \[}{=}_{k}[\| f_{ i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t};_{i}^{t+1})-b(h_{i}^{t}-  f_{i}(x^{t};_{i}^{t+1}))-( f_{i}(x^{t+1})- f_ {i}(x^{t})-b(h_{i}^{t}- f_{i}(x^{t})))\|^{2}]\] \[+\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{t }- f_{i}(x^{t}))\|^{2}\] \[+\| f_{i}(x^{t+1})- f_{i}(x^{t})-b(h_{i}^{ t}- f_{i}(x^{t}))\|^{2}\] \[}{}2b^{2}_{k}[\|  f_{i}(x^{t+1};_{i}^{t+1})- f_{i}(x^{t+1})\|^{2}]\] \[+2(1-b)^{2}_{k}[\| f_{i}(x^{t+1}; _{i}^{t+1})- f_{i}(x^{t};_{i}^{t+1})-( f_{i}(x^{t+1})-  f_{i}(x^{t}))\|^{2}]\] \[+2\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^ {2}+2b^{2}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}.\]

Using Assumptions 3, 6, 5 and the independence of elements in the mini-batch, we get

\[_{k}[\|k_{i}^{t+1}\|^{2}]\]\[^{2}}{B}+(L_{}^{2}}{ B}+2L_{i}^{2})\|x^{t+1}-x^{t}\|^{2}+2b^{2}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2}.\]

**Theorem 4**.: _Suppose that Assumptions 1, 2, 3, 5, 6, 7 and 8 hold. Let us take \(a=}{2+1}\), \(b(0,}{2-p_{ a}}]\), \((L+[(2+1)}{np_{ a}^{2}}( ^{2}+L_{}^{2}}{B})+} ((1-}{p_{ a}})^{2}+L _{}^{2}}{B})]^{1/2})^{-1}\), and \(g_{i}^{0}=h_{i}^{0}\) for all \(i[n]\) in Algorithm 1 (DASHA-PP-MVR). Then_

\[[\| f(^{T})\|^{2}] [}{}+\|h^{0}-  f(x^{0})\|^{2}+(^{2}}+ }{p_{ a}})}{np_{ a}})( _{i=1}^{n}\|h_{i}^{0}- f_{i}(x^{0})\|^{2} )]\] \[+((2+1)}{p_{ a}^{2}}+})}{nB}.\]

Proof.: Let us fix constants \(,[0,)\) that we will define later. Considering Lemma 6, Lemma 10, and the law of total expectation, we obtain

\[[f(x^{t+1})]+}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ a})}{np_{ a}^{2}}[ {n}_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[[f(x^{t})-\| f(x^{t })\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}[\|g ^{t}-h^{t}\|^{2}]+-p_{  a})}{np_{ a}^{2}}[_{i=1}^{n}\|g_{i}^{ t}-h_{i}^{t}\|^{2}]\] \[+^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}]\] \[=[f(x^{t})-\| f(x^{t}) \|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}[\|g ^{t}-h^{t}\|^{2}]+-p_{  a})}{np_{ a}^{2}}[_{i=1}^{n}\|g_{i}^{ t}-h_{i}^{t}\|^{2}]\] \[+^{2}} [_{k}[_{i=1}^{n}\|k_{i}^{t+1}\|^{ 2}]]\] \[+^{2}}[ \|g^{t}-h^{t}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}[_{i=1}^{n}\|g _{i}^{t}-h_{i}^{t}\|^{2}]\] \[[f(x^{t})-\| f(x^{t })\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}[\|g ^{t}-h^{t}\|^{2}]+-p_{  aa})}{np_{ a}^{2}}[_{i=1}^{n}\|g_{i}^{ t}-h_{i}^{t}\|^{2}]\] \[+^{2}} [^{2}}{B}+(L_{}^{2}}{B}+2 ^{2})\|x^{t+1}-x^{t}\|^{2}+2b^{2}_{i=1 }^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\]\[+\!(^{2}}{np_{ a}B}+(L_{}^{2}}{np_{ a}B}+-p_{ aa}) {L}^{2}}{np_{ a}^{2}})\|x^{t+1}-x^{t}\|^{2}\] \[+-p_{ aa})b^{2}}{n^{2}p_{ a}^{2} }_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+(1-b )^{2}\|h^{t}- f(x^{t})\|^{2}\] \[+\!(^{2}}{p_{ a}B}+( L_{}^{2}}{p_{ a}B}+)^{ 2}}{p_{ a}})\|x^{t+1}-x^{t}\|^{2}.\] \[+()b^{2}}{p_{ a}}+(1-b)^{2}) _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2} .\]

After rearranging the terms, we get

\[{ E}[f(x^{t+1})]+ }{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{n }\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[-(--^{2}}(L_{}^{2}}{B}+2^{2}).\] \[.-(L_{}^{2}}{np_{ a}B }+-p_{ aa})^{2}}{np_{ a}^{2}} )-(L_{}^{2}}{p_{ a}B}+)^{2}}{p_{ a}})[\|x^{t+1}-x^{t} \|^{2}]\] \[+(+(1-b)^{2}){ E}[\|h^ {t}- f(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+-p_{ aa})b^{2}}{np_{ a}^{2}}+()b^{2}}{p_{ a}}+(1-b)^{2})){ E}[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ }{np_{ a}}+}{p_{ a}})}{B}.\]

By taking \(=\), one can show that \(+(1-b)^{2}\), and

\[{ E}[f(x^{t+1})]+}{  E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{n} \|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+[_{i=1}^{n}\|h_{i}^{t+ 1}- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[-(--^{2}}(L_{}^{2}}{B}+2^{2}).\] \[-(L_{}^{2}}{np_{  a}B}+-p_{ aa})^{2}}{np_{ a}^{2}} )-(L_{}^{2}}{p_{ a}B}+)^{2}}{p_{ a}})[\|x^{t+1}-x^{t} \|^{2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]\]\[+((2+1)}{np_{ a}^{2}}+-p_{ aa})b}{np_{ a}^{2}}+()b^{2}}{p_{ a}}+(1-b)^{2}))\!{ E}[_ {i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ }+}{p_{ a}})}{B}.\]

Note that \(b}{2-p_{ a}}\), thus

\[((2+1)}{np_{ a}^{2}}+-p_{ aa})b}{np_{ a}^{2}}+()b^{2}}{p_{ a}}+(1-b)^{2}))\] \[((2+1)}{np_{ a}^{2}}+ -p_{ aa})b}{np_{ a}^{2}}+(1-b ))\!.\]

And if we take \(=^{2}}+-p_{ aa})b}{np_{ a}^{2}},\) then

\[((2+1)}{np_{ a}^{2}}+-p_{ aa})b}{np_{ a}^{2}}+(1-b) ),\]

and

\[{ E}[f(x^{t+1})]+}{  E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{n} \|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(^{2}}+ -p_{ aa})}{np_{ a}^{2}}){ E} [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\| ^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}{ E}[\|g^{t}-h^{ t}\|^{2}]+-p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[-(--^{2}}(L_{}^{2}}{B}+2^{2} )..\] \[..-b}(L_{}^{2}}{B}+2(1-}{p_{ a}})^{2 }).\] \[.-(^{3}}+}{p_{ a}})}{np_{ a}^{2}} )(L_{}^{2}}{B}+2(1-p_{ a})^{2} )){ E}[\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t})\| ^{2}]+(^{2}}+-p_{ aa})}{np_{ a}^{2}}){ E}[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+}+(^{2}}+ -p_{ aa})}{np_{ a}^{2}})}{p_{ a}})}{B}.\]

Let us simplify the inequality. First, due to \(b p_{ a}\) and \((1-p_{ a})(1-}{p_{ a}}),\) we have

\[(^{3}}+}{p_{ a}})}{np_{ a}^{2}}) (L_{}^{2}}{B}+2(1-p_{ a})^{2})\] \[=^{3}}(L_{}^{2}}{B}+2(1-p_{ a})^{2})\] \[+}{p_{ a}})}{np_{  a}^{2}}(L_{}^{2}}{B}+2(1-p_{ a})^{2})\]\[^{2}}(L_{ }^{2}}{B}+2^{2})\]

therefore

\[^{2}}(L_{ }^{2}}{B}+2^{2})\]

therefore

\[[f(x^{t})]-[\|  f(x^{t})\|^{2}]\]

\[+}[\|h^{t}-h^{t}\|^{2} ]+-p_{ aa})}{np_{ a}^{2 }}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t+1}\| ^{2}]\]

\[+[\|h^{t+1}- f(x^{t})\|^{2} ]+(^{2}}+-p_{ aa})}{np_{ a}^{2}})[ _{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\]

\[[f(x^{t})]-[\|  f(x^{t})\|^{2}]\]

\[+}[\|g^{t}-h^{t}\| ^{2}]+-p_{ aa})}{np_{ a }^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\]

\[-(--^{2}}(L_{}^{2}}{B}+2^{2}).\]

\[.-b}(L_{}^{2}}{ B}+2(1-}{p_{ a}})^{2})) [\|x^{t+1}-x^{t}\|^{2}]\]

\[+[\|h^{t}- f(x^{t}) \|^{2}]+(^{2}}+ -p_{ aa})}{np_{ a}^{2}})[_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\]

\[+}[\|g^{t}-h^{t}\| ^{2}]+-p_{ aa})}{np_{ a }^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\]

\[-(--^{2}}(L_{}^{2}}{B}+^{2}).\]

\[-b}(L_{c}^{2}}{B}+(1-}{p_{ a}})^{2})[\|x^{t+1}-x^{t} \|^{2}]\]

\[+[\|h^{t}- f(x^{t})\|^{2} ]+(^{2}}+-p_{ aa})}{np_{ a}^{2}})[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\]

\[+((2+1)}{np_{ a}^{2}}+}+(^{2}}+-p_{ aa})}{np_{ a}^{2}})}{p_{ a }})}{B}.\]

Also, we can simplify the last term:

\[(^{2}}+-p_{ aa})}{np_{ a}^{2}})}{p_{  a}}\] \[=(2+1)}{np_{ a}^{3}}+(1-}{p_{ a}})}{np_{ a}^{2}}\] \[(2+1)}{np_{ a}^{2}}+},\]

thus

\[[f(x^{t+1})]+} [\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}[_{i=1 }^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\]\[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+(}^{2}}+ }-p_{})}{np_{}^{2}} )[_{i=1}^{n}\|h_{i}^{t+1}- f_{i }(x^{t+1})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2} }+}-p_{})}{np_{}^{2 }})[_{i=1}^{n}\|h_{i}^{t}- f_{i }(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2} }+}-p_{})}{np_{}^{ 2}})[_{i=1}^{n}\|h_{i}^{t}- f_{ i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2} }+}-p_{})}{np_{}^{ 2}})[_{i=1}^{n}\|h_{i}^{t}- f_{ i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2 }}+}-p_{})}{np_{}^{ 2}})[_{i=1}^{n}\|h_{i}^{t+1}- f_{ i}(x^{t+1})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+(}^{2 }}+}-p_{})}{np_{}^{ 2}})[_{i=1}^{n}\|h_{i}^{t}- f_{ i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{}^{2} }+}})}{B}.\]

It is left to apply Lemma 3 with

\[^{t} = }}[\|g^{t}-h^ {t}\|^{2}]+}-p_{})}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+ [\|h^{t}- f(x^{t})\|^{2 }]+(}^{2}}+}-p_{})}{np_{}^{2}})[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\]

and \(C=((2+1)}{p_{}^{2}}+}})}{nB}\) to conclude the proof. 

**Corollary 3**.: _Suppose that assumptions from Theorem 4 hold, momentum \(b=(\{}}{} }},}neB}{^{2}} \}),\ }{neB} 1,\) and \(h_{i}^{0}=}}_{k=1}^{B_{}} f_{i}(x ^{0};_{ik}^{0})\) for all \(i[n],\) and batch size \(B_{}=(}}B}{b}),\) then Algorithm 1 (DASHA-PP-MVR) needs_

\[T:=\!(}{}\![L+}}(+}{})+ {}{p_{}n}(_{p_{ }}}{}+}{B})+}{ }}neB})\]

_communication rounds to get an \(\)-solution and the number of stochastic gradient calculations per node equals \((B_{}+BT).\)_Proof.: Using the result from Theorem 4, we have

\[[\| f(^{T})\|^{2}]\] \[2_{0}(L+}^{2}}(^{2}+L_{}^ {2}}{B})+}b}((1-}}{ p_{}})^{2}+L_{}^{2}}{B})})\] \[+\|h^{0}- f(x^{0})\|^{2}+( }^{2}}+}}{p_{}})}{np_{}})( _{i=1}^{n}\|h_{i}^{0}- f_{i}(x^{0})\|^{2})\] \[+((2+1)}{p_{}^{2}}+ }})}{nB}\]

We choose \(b\) to ensure \(((2+1)}{p_{}^{2}}+}})}{nB}=().\) Note that \(=(\{}}}{neB}},}{p_{}neB}\}) (\{}{p_{}},}{p_{ }neB}\}),\) thus

\[[\| f(^{T})\|^{2}]\] \[=_{0}(L+}}(+}{} )+}{p_{}^{2} n^{2}B}}( _{p_{}}+}{}))\] \[+\|h^{0}- f(x^{0})\|^{2}+( }{np_{}^{2}}+}}) (_{i=1}^{n}\|h_{i}^{0}- f_{i}(x^{0})\|^{2 })+,\]

where \(_{p_{}}=}}{p_{}}}.\) It enough to take the following \(T\) to get \(\)-solution.

\[T=_{0} (L+}}(+ }{})+}{p_{}^{2} n^{2} B}}(_{p_{}}+}{} ))\] \[+\|h^{0}- f(x^{0})\|^{2}+( }{np_{}^{2}}+}})( _{i=1}^{n}\|h_{i}^{0}- f_{i}(x^{0})\|^{2} ).\]

Let us bound the norms:

\[[\|h^{0}- f(x^{0})\|^{2}] = [\|_{i=1}^{n}}}_{k=1}^{B_{}} f_{i}(x^{0};_{ik}^{0})-  f(x^{0})\|^{2}]\] \[= B_{}^{2}}_{i=1}^{n}_{k=1}^{B_ {}}[\| f_{i}(x^{0};_{ik}^{0})-  f_{i}(x^{0})\|^{2}]\] \[ }{nB_{}}.\]

Using the same reasoning, one cat get \(_{i=1}^{n}[\|h_{i}^{0}- f_{i}(x^{0}) \|^{2}]}{B_{}}.\) Combining all inequalities, we have \[T =\!(\![_{0}(L+ }}(+}{})+}{p_{}^{2} n^{2}B}}( _{p_{}}+}{}) ).\] \[+}{bnB_{}}+ ^{2}}{np_{}^{2}B_{}}+}{np_{}B_{}}].\]

Using the choice of \(B_{}\) and \(b,\) we obtain

\[T =\!(\![_{0}( L+}}(+}{ })+}{p_{}^{2} n^{2}B }}(_{p_{}}+}{} )).\] \[+}{}}nB}+ ^{2}^{2}}{np_{}^{5/2}B}+}{p_{}^{3/2}nB}\] \[=\!(\![_{0}( L+}}(+}{ })+}{p_{}^{2} n^{2}B }}(_{p_{}}+}{} )).\] \[+}{}}nB}+}}}\] \[=\!(}{}\![L+}}(+}{} )+}{p_{}^{2} n^{2}B}}( _{p_{}}+}{}) ]+}{}}n B}+}}})\!.\]

Using \(}{neB} 1,\) we can conclude the proof of the inequality. The number of stochastic gradients that each node calculates equals \(B_{}+2BT=(B_{}+BT).\) 

**Corollary 4**.: _Suppose that assumptions of Corollary 3 hold, batch size \(B\{}},^{2}}{1_{p_{}}^{2}^{2}}\},\) we take Rand\(K\) compressors with \(K=(}{}).\) Then the communication complexity equals \((}}}+ _{0}d}{p_{}}),\) and the expected number of stochastic gradient calculations per node equals \((}{}}n}+_{0}}{p_{}^{3/2}n}).\)_

Proof.: The communication complexity equals

\[(d+KT) = (d+}{}\![KL+K {}{p_{}}(+}{} )+K}{p_{}^{2} n^{2}B}}( _{p_{}}+}{}) ]+K}{}}n B}).\]Due to \(B^{2}}{1_{p_{a}}^{2}^{2}},\) we have \(_{p_{a}}+}{}} {}\) and

\[(d+KT) = (d+}{}[KL+K}}(+}{} )+K}{p_{}^{2} n^{2}B}}}{}]+K}{}}n  B}).\]

From Theorem 6, we have \(+1=.\) Since \(K=(}{})=( }}),\) the communication complexity equals

\[(d+KT) = (d+}{}[ {p_{}}L+}}(+ }{})+}}L_{ }]+}}})\] \[= (}}}+_{0}d}{p_{}})\]

And the expected number of stochastic gradient calculations per node equals

\((B_{}+BT)\)

\[=(}{}}n }+}}}}{n  B}}+}{}[BL+B}}(+}{})+B }{p_{}^{2} n^{2}B}}(_{p_{}}+}{})]+B }{}}n B})\] \[=(}{}}n }+}}}}{n  B}}+}{}[BL+B}}(+}{})+B}{p_{}^{2} n^{2}B}}}{} ]+}{}}n})\] \[=(}{}}n }+}{}}n}+ }{}[}}L+}}( +}{})+} }L_{}])\] \[=(}{}}n }+_{0}}{p_{}^{ }{{2}}}n}).\]Analysis of Dasha-Pp under Polyak-Lojasiewicz Condition

In this section, we provide the theoretical convergence rates of Dasha-Pp under Polyak-Lojasiewicz Condition.

**Assumption 9**.: _The function \(f\) satisfy (Polyak-Lojasiewicz) PL-condition:_

\[\| f(x)\|^{2} 2(f(x)-f^{*}), x,\] (30)

_where \(f^{*}=_{x^{d}}f(x)>-\)._

Under Polyak-Lojasiewicz condition, a (random) point \(\) is \(\)-solution, if \([f()]-f^{*}\).

We now provide the convergence rates of Dasha-Pp under PL-condition.

### Gradient Setting

**Theorem 8**.: _Suppose that Assumption 1, 2, 3, 7, 8 and 9 hold. Let us take \(a=}}{2+1},\,b=}}{2-p_{}},\)_

\[\{(L+}^{2}}+}^{2}}(1-}}{ p_{}})})^{-1},\},\]

_and \(h_{i}^{0}=g_{i}^{0}= f_{i}(x^{0})\) for all \(i[n]\) in Algorithm 1_(Dasha-Pp)_, then \([f(x^{T})]-f^{*}(1-)^{T}_{0}.\)_

Let us provide bounds up to logarithmic factors and use \(}()\) notation. The provided theorem states that to get \(\)-solution Dasha-Pp have to run

\[}(}}++ }{p_{}}+}{p_{ }}),\]

communication rounds. The method Dasha from (Tyurin and Richtarik, 2023), have to run

\[}(++}{ }),\]

communication rounds to get \(\)-solution. The difference is the same as in the general nonconvex case (see Section 6.1). Up to Lipschitz constants factors, we get the degeneration up to \(}{{p_{}}}\) factor due to the partial participation.

### Finite-Sum Setting

**Theorem 9**.: _Suppose that Assumption 1, 2, 3, 7, 4, 8, and 9 hold. Let us take \(a=}}{2+1},\) probability \(p_{}=,\,b=}p_{}}{2-p_{ }},\)_

\[\{(L+ }^{2}}(^{2}+})L_{}^{2}}{B} )+}^{2}p_{}}((1-}}{p_{}})^{2}+})L_ {}^{2}}{B}))^{-1}}, \}.\]

_and \(h_{i}^{0}=g_{i}^{0}= f_{i}(x^{0})\) for all \(i[n]\) in Algorithm 1_(Dasha-Pp-PAGE)_, then \([f(x^{T})]-f^{*}(1-)^{T}_{0}.\)_

The provided theorem states that to get \(\)-solution Dasha-Pp have to run

\[}(}}+}B}++}}( +}}{})+}{p_{ }}(+}}{} )),\]

communication rounds. The method Dasha-Page from (Tyurin and Richtarik, 2023), have to run

\[}(+++}(+}}{})+}{}(}}{})),\]

communication rounds to get \(\)-solution. We can guarantee the degeneration up to \(}{{p_{}}}\) factor due to the partial participation only if \(B=(}^{2}}{^{2}})\). The same conclusion we have in Section 6.2.

### Stochastic Setting

**Theorem 10**.: _Suppose that Assumption 1, 2, 3, 7, 5, 6, 8 and 9 hold. Let us take \(a=}}{2+1}\), \(b(0,}}{2-p_{}}],\)_

\[\{(L+}^ {2}}(L_{}^{2}}{B}+^{2})+}b}(L_{}^{2}}{B}+(1-}}{p_{ }})^{2}))^{-1}}\,,,\},\]

_and \(h_{i}^{0}=g_{i}^{0}\) for all \(i[n]\) in Algorithm 1_(DASHA-PP-MVR)_, then_

\[[f(x^{T})-f^{*}]\] \[+((2+1)}{p_{ }^{2}}+}})}{nB}.\]

The provided theorems states that to get \(\)-solution DASHA-PP have to run

\[}(}}+}}}{ n B}}}_{ _{2}}+}{p_{} n B}++}}(+}{})+_{n^{}{ 2}}}(+}{}) )\] (31)

communication rounds. We take \(b=(\{}}{} }},\,}\})(\{ }}{^{2}},\,}\}).\)

The method DASHA-SYNC-MVR from (Tyurin and Richtarik, 2023), have to run

\[}(+}{ n  B}++}(+ }{})+}{2}} }(}{}))\] (32)

communication rounds to get \(\)-solution9.

In the stochastic setting, the comparison is a little bit more complicated. As in the finite-sum setting, we have to take \(B=(}{L^{2}})\) to guarantee the degeneration up to \(}{{p_{}}}\) of the term \(_{1}\) from (31). However, DASHA-PP-MVR has also suboptimal term \(_{2}\). This suboptimality is tightly connected with the suboptimality of \(B_{}\) in the general nonconvex case, which we discuss in Section 6.3, and it also appears in the analysis of DASHA-MVR(Tyurin and Richtarik, 2023). Let us provide the counterpart of Corollary 4. The corollary reveals that we can escape regimes when \(_{2}\) is the bottleneck by choosing the parameters of the compressors.

**Corollary 5**.: _Suppose that assumptions of Theorem 10 hold, batch size \(B\{}},}{L^{2}}\},\) we take Rand\(K\) compressors with \(K=(}{}).\) Then the communication complexity equals_

\[}(}}+}{p_{}}),\]

_and the expected number of stochastic gradient calculations per node equals_

\[}(}{p_{} n }+}{p_{}n^{}{2}} }).\]

Up to Lipschitz constants, DASHA-PP-MVR has the state-of-the-art oracle complexity under PL-condition (see (Li et al., 2021a)). Moreover, DASHA-PP-MVR has the state-of-the-art communication complexity of DASHA for a small enough \(\).

### Proofs of Theorems

The following proofs almost repeat the proofs from Section E. And one of the main changes is that instead of Lemma 3, we use the following lemma.

#### f.4.1 Standard Lemma under Polyak-Lojasiewicz Condition

**Lemma 11**.: _Suppose that Assumptions 1 and 9 hold and_

\[[f(x^{t+1})]+^{t+1}[f(x^{t}) ]-[\| f(x^{t})\|^{2} ]+(1-)^{t}+ C,\]

_where \(^{t}\) is a sequence of numbers, \(^{t} 0\) for all \(t[T]\), constant \(C 0,\) constant \(>0,\) and constant \((0,1/).\) Then_

\[[f(x^{T})-f^{*}](1-)^{T}((f(x^{0} )-f^{*})+^{0})+.\] (33)

Proof.: We subtract \(f^{*}\) and use PL-condition (30) to get

\[[f(x^{t+1})-f^{*}]+^{t+1}  [f(x^{t})-f^{*}]- [\| f(x^{t})\|^{2}]+^{t}+ C\] \[ (1-)[f(x^{t})-f^{*}]+(1- )^{t}+ C\] \[= (1-)([f(x^{t})-f^{*}]+ ^{t})+ C.\]

Unrolling the inequality, we have

\[[f(x^{t+1})-f^{*}]+^{t+1}  (1-)^{t+1}((f(x^{0})-f^{*})+^{ 0})+ C_{i=0}^{t}(1-)^{i}\] \[ (1-)^{t+1}((f(x^{0})-f^{*})+^ {0})+.\]

It is left to note that \(^{t} 0\) for all \(t[T]\). 

#### f.4.2 Generic Lemma

We now provide the counterpart of Lemma 6.

**Lemma 12**.: _Suppose that Assumptions 2, 7, 8 and 9 hold and let us take \(a=}}{2+1},\) then_

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^ {2}]\] \[[f(x^{t})-\| f(x^{ t})\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+(1-)\,}} [\|g^{t}-h^{t}\|^{2}]+(1-)\,}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[+}^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}].\]

Proof.: Let us fix some constants \(,[0,)\) that we will define later. Using the same reasoning as in Lemma 6, we can get

\[[f(x^{t+1})]\] \[+[\|g^{t+1}-h^{t+1}\|^{2} ]+[_{i=1}^{n}\|g_{i}^{t+1}-h_{i} ^{t+1}\|^{2}]\] \[[f(x^{t})-\| f(x^ {t})\|^{2}-(-)\|x^{t+1}-x^{t }\|^{2}+\|h^{t}- f(x^{t})\|^{2}]\]\[+(+(1-a)^{2})[\| g^{t}-h^{t}\|^{2}]\] \[+(((2+1)p_{}-p_{ })}{np_{}^{2}}+((2+1-p_{})}{p_{}}+(1-a)^{2}))[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+(}}+}})[_{i=1}^{n}\|k_{i}^{t+ 1}\|^{2}].\]

Let us take \(=\). One can show that \(+(1-a)^{2}(1-)\), and thus

\[[f(x^{t+1})]\] \[[f(x^{t})-\| f(x^{t })\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+(1-)[ \|g^{t}-h^{t}\|^{2}]\] \[+(}-p_{ })}{np_{}^{2}}+((2+1-p_{ })}{p_{}}+(1-a)^{2}))[_{i =1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+(}}+}})[_{i=1}^{n}\|k_{i}^{t+ 1}\|^{2}].\]

Considering the choice of \(a\), one can show that \(((2+1-p_{})}{p_{}}+(1-a)^{2})  1-a\). If we take \(=}-p_{})}{np_{} ^{2}}\), then \((}-p_{})}{np _{}^{2}}+((2+1-p_{})}{p_{}}+(1-a)^{2}))(1-)\) and

\[[f(x^{t+1})]\] \[[f(x^{t})-\| f(x^{t })\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[[f(x^{t})-\| f(x^{t })\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[[f(x^{t})-\| f(x^{t })\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+(1-)}}[\|g^{t}-h^{t}\|^{2}]+(1- )}-p_{})}{np_ {}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{ i}^{t}\|^{2}]\] \[+}^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}].\]

It it left to consider that \(\), and therefore \(1- 1-\)

#### f.4.3 Proof for \(PP}\) under PL-condition

**Theorem 8**.: _Suppose that Assumption 1, 2, 3, 7, 8 and 9 hold. Let us take \(a=}}}{2+1}\), \(b=}}}{2-p_{}}}\),_

\[\{(L+}}^{2}}+}}^{2}}(1-}}}{p_{}}})})^{-1},\},\]

_and \(h_{i}^{0}=g_{i}^{0}= f_{i}(x^{0})\) for all \(i[n]\) in Algorithm 1 (\(PP}\)), then \([f(x^{T})]-f^{*}(1-)^{T}_{0}\)._

Proof.: Let us fix constants \(,[0,)\) that we will define later. Considering Lemma 12, Lemma 7, and the law of total expectation, we obtain

\[[f(x^{t+1})]+ {p_{}}}[\|g^{t+1}-h^{t+1}\|^{2}] +}}-p_{} })}{np_{}}^{2}}[_{i=1}^{n}\| g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})-\| f (x^{t})\|^{2}-(-)\|x^{t+1}- x^{t}\|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}}^{2} }[2^{2}\|x^{t+1}-x^{t}\|^{2}+2b^{2} {1}{n}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+[}}-p_{ }})}{np_{}}^{2}}\|x^{t+1}-x^{t}\| ^{2}+(p_{}}-p_{}})}{np_{ }}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}+(1-b)^{2}\|h^{t}- f(x^{t})\|^{2}]\] \[+[}})}{p_{ }}}^{2}\|x^{t+1}-x^{t}\|^{2}+((1-p_{}})}{p_{}}}+(1-b)^{2}) _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

After rearranging the terms, we get

\[[f(x^{t+1})]+ {p_{}}}[\|g^{t+1}-h^{t+1}\|^{2}] +}}-p_{} })}{np_{}}^{2}}[_{i=1}^{n}\| g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^ {2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-)}}}[\|g^{t}-h^{t}\|^{2}]+(1- )}}-p_{ }})}{np_{}}^{2}}[_{ i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[-(--^{2}}{np_{}}^{2}}-}}-p_{}})}{np_{}}^{2 }}^{2}-}})^{2}}{p_{}}})[\|x^{t+1}-x^{t}\|^{2}]\] \[+(+(1-b)^{2})[\|h^{ t}- f(x^{t})\|^{2}]\] \[+((2+1)}{np_{}}^{2}}+(p_{}}-p_{}} )}{np_{}}^{2}}+((1-p_{}})}{p _{}}}+(1-b)^{2}))[_{i=1 }^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

By taking \(=\), one can show that \((+(1-b)^{2})(1-)\), and

\[[f(x^{t+1})]+}}}[\|g^{t+1}-h^{t+1}\|^{2}]+}}-p_{}})}{np_{ }}^{2}}[_{i=1}^{n}\|g_{i}^{t+1}- h_{i}^{t+1}\|^{2}]\]\[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+[_{i=1}^{n}\|h_{i}^ {t+1}- f_{i}(x^{t+1})\|^{2}]\] \[ [f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+(1-) }}[\|g^{t}-h^{t}\|^{2}]+(1- )}-p_{})}{ np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[-(--^{2}}{np_{}^{2}}-}-p_{})^{2}}{bpn_{}^{2}}- })^{2}}{p_{}}) [\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]\] \[+((2+1)}{np_{}^{2} }+}-p_{})}{np_{}^ {2}}+((1-p_{})}{p_{}}+(1-b)^{2} ))[_{i=1}^{n}\|h_{i}^{t}- f _{i}(x^{t})\|^{2}].\]

Note that \(b=}}{2-p_{}}\), thus

\[((2+1)}{np_{}^{2}} +}-p_{})}{np_{}^ {2}}+((1-p_{})}{p_{}}+(1-b)^{2} ))\] \[((2+1)}{np_{}^{ 2}}+}-p_{})}{np_{}^{2}}+(1-b)).\]

And if we take \(=}^{2}}+}-p_{})}{np_{}^{2}}\), then

\[((2+1)}{np_{}^{2}}+}-p_{})}{np_{}^{2}}+ (1-b))(1-),\]

and

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[ [f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1-) }-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i} ^{t}\|^{2}]\] \[-(--^{2}}{np_{}^{2}}-}-p_{})^{2}}{bpn_{}^{2}}.\] \[.-}) ^{2}}{np_{}^{3}}-}-p_{ })(1-p_{})^{2}}{np_{}^{3}} )[\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]+(1-) (}^{2}}+}-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}].\]

Due to \(}}{2} b p_{}\), we have

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^ {2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1} )\|^{2}]+(}^ {2}}+}-p_{})}{np_{}^ {2}})[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\]\[ [f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1- )}-p_{})}{ np_{}^{2}}[_{i=1}^{n}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2}]\] \[-(--^{2}}{np_{}^{2}}-}-p_{})^{2}}{np_{}^{2}} )[\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]+(1-) (}^{2}}+}-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}].\]

Using Lemma 4 and the assumption about \(\), we get

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1 })\|^{2}]+(}^ {2}}+}-p_{})}{np_{}^ {2}})[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\] \[ [f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1-) }-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i }^{t+1}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]+(1-) (}^{2}}+}-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}].\]

Note that \(}}{4}\), thus \(1- 1-\) and

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1 })\|^{2}]+( }^{2}}+}-p_{})}{np_{}^{2}})[_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1 })\|^{2}]\] \[ [f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1- )}-p_{})}{ np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i }^{t}\|^{2}]\] \[+(1-)[\|h ^{t}- f(x^{t})\|^{2}]+(1-)(}^{2}}+}- p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}].\]

In the view of Lemma 11 with

\[^{t} = }}[\|g^{t}-h^{ t}\|^{2}]+}-p_{})}{ np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i }^{t}\|^{2}]\] \[+ [\|h^{t}- f(x^{t})\|^{2} ]+(}^{2}}+}-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}],\]

we can conclude the proof of the theorem. \(\)

#### f.4.4 Proof for \(\)-\(\)-\(\) under \(\)-condition

**Theorem 9**.: _Suppose that Assumption 1, 2, 3, 7, 4, 8, and 9 hold. Let us take \(a=}}{2+1}\), probability \(p_{}=,b=}up_{}}{2-p_{ }},\)__and \(h_{i}^{0}=g_{i}^{0}= f_{i}(x^{0})\) for all \(i[n]\) in Algorithm 1 (DASHA-PP-PAGE), then \([f(x^{T})]-f^{*}(1-)^{T}_{0}\)._

Proof.: Let us fix constants \(,[0,)\) that we will define later. Considering Lemma 12, Lemma 8, and the law of total expectation, we obtain

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\| ^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[+}^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})-\| f(x^{ t})\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+}^{2}} [(2^{2}+})L_{}^{2}}{B})\|x^{t+1}-x^{t}\|^{2}+}{p_{}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(}-p_{ })^{2}}{np_{}^{2}}+})L_{}^{2}}{np_{}B})\|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n ^{2}p_{}^{2}p_{}}_{i=1}^{n}\|h_{i}^{t}- f _{i}(x^{t})\|^{2}+(p_{}(1-}})^{2}+(1-p_{}))\|h^{t}- f(x^{t}) \|^{2}\] \[+(} )^{2}}{p_{}}+})L_{}^{2}}{p_{}B})\|x^{t+1}-x^{t}\|^{2}\] \[+(})b^{2}}{p_{ }p_{}}+p_{}(1-}})^{2}+(1-p_{}))_{i=1}^{n}\|h_{i }^{t}- f_{i}(x^{t})\|^{2}.\]

After rearranging the terms, we get

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-)}}[\|g^{t}-h^{t}\|^{2}]+(1- )}-p_{})}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\]\[-(--^{2}}(2^{2}+)L_{ max }^{2}}{B}).\] \[.-(-p_{ a}) ^{2}}{np_{ a}^{2}}+)L_{ max}^ {2}}{np_{ a}B})-()^ {2}}{p_{ a}}+)L_{ max}^{2}}{p_{ a}B} ))[\|x^{t+1}-x^{t}\|^{2}]\] \[+(+(p_{ page}(1-} )^{2}+(1-p_{ page})))[\|h^ {t}- f(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}p_{  page}}+-p_{ aa})b^{2}}{np_{ a}^{2}p_{  page}}.\] \[.+()b^{2}}{p_{  a}p_{ page}}+p_{ page}(1-})^{2}+( 1-p_{ page})))[_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

Due to \(b=p_{ a}}{2-p_{ a}} p_{ page}\), one can show that \((p_{ page}(1-})^{2}+(1-p_{ page })) 1-b\). Thus, if we take \(=\), then

\[(+(p_{ page}(1-})^{2}+ (1-p_{ page})))+(1-b)=(1-),\]

therefore

\[[f(x^{t+1})]+}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-) }[\|g^{t}-h^{t}\|^{2}]+(1- )-p_{ aa})}{np_{ a}^{2 }}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[-(--^{2}}(2^{2}+ )L_{ max}^{2}}{B}).\] \[.-}(2(1-}{p_{ a}})^{2}+)L_{  max}^{2}}{B})-()^ {2}}{p_{ a}}+)L_{ max}^{2}}{p_{ a}B} ))[\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}p_ { page}}+-p_{ aa})b}{np_{ a}^{2}p_{  page}}.\] \[.+()b^{2}}{p_{  a}p_{ page}}+p_{ page}(1-})^{2}+ (1-p_{ page})))[_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}].\]

Next, with the choice of \(b=p_{ a}}{2-p_{ a}}\), we ensure that

\[()b^{2}}{p_{ a}p_{ page}}+p_{ page} (1-})^{2}+(1-p_{ page})) 1 -b.\]

If we take \(=^{2}p_{ page}}+ -p_{ aa})b}{np_{ a}^{2}p_{ page}},\) then

\[((2+1)}{np_{ a}^{2}p_{ page}}+-p_{ aa})b}{np_{ a}^{2}p_{ page}}+ ()b^{2}}{p_{ a}p_{ page}}+p_{ page} (1-})^{2}+(1-p_{ page})) )(1-),\]therefore

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-)\,}} [\|g^{t}-h^{t}\|^{2}]+(1-)\,}-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[-(--}^{2}}(2^{2}+})L_{}^{2}}{B}).\] \[-}}(2(1-}}{p_{}})^{2}+})L_{}^{2}}{B})\] \[-(}^{ 3}p_{}}+}}{p_{ }})}{np_{}^{2}p_{}})(2(1-p_{ })^{2}+})L_{}^ {2}}{B})[\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]+(1-) (}^{2}p_{}} +}-p_{})}{np_{}^{2} p_{}})[_{i=1}^{n}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2}].\]

Let us simplify the inequality. First, due to \(b}P_{}}{p_{}}\), we have

\[}}(2(1-}}{p_{ }})^{2}+})L_{}^ {2}}{B})}^{2}p_{}}( (1-}}{p_{}})^{2}+})L_{}^{2}}{B}).\]

Second, due to \(b p_{}p_{}\) and \(p_{} p_{}^{2}\), we get

\[(}^{3}p_{ }}+}}{p_{}} )}{np_{}^{2}p_{}})(2(1-p_{})^{2}+})L_{}^{2}}{B})\] \[(}^{2}}+ }}{p_{}})}{np_{}^{2}p_{}})(2(1-}}{p_{}} )^{2}+})L_{}^{2}}{B})\] \[}^{2}}( (1-}}{p_{}})^{2}+})L_{}^{2}}{B})\] \[+}^{2}p_{}^{2}} ((1-}}{p_{}})^{2}+ })L_{}^{2}}{B}).\]

Combining all bounds together, we obtain the following inequality:

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t+1}- f(x^ {t+1})\|^{2}]+(}^{2}p_{}}+}-p_{} )}{np_{}^{2}p_{}})[ _{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\]\[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1-) }-p_{})}{np_{}^ {2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1-) }-p_{})}{np_{}^ {2}p_{}}[_{i=1}^{n}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2}]\] \[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1-) }-p_{})}{np_{}^ {2}p_{}}[_{i=1}^{n}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2}]\] \[+(1-)[\| h^{t}- f(x^{t})\|^{2}]+(1-)}^{2}p_{}}+}- p_{})}{np_{}^{2}p_{}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2 }].\]

Note that \(\), thus \(1- 1-\) and

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\| ^{2}]\] \[+[\|h^{t+1}- f(x^{t+1} )\|^{2}]+(}^{2 }p_{}}+}-p_{})}{np_{ }^{2}p_{}})[_{i=1}^{n} \|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-)}} [\|g^{t}-h^{t}\|^{2}]+(1-) }-p_{})}{np_{} ^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+(1-)[\|h^ {t}- f(x^{t})\|^{2}]+(1-)(}^{2}p_{}}+}-p_{})}{np_{}^{2}p_{}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}].\]

It is left to apply Lemma 11 with

\[^{t} =}}[\|g^{t}-h^{t }\|^{2}]+}-p_{})}{ np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+[\|h^{t}- f(x^{t})\|^ {2}]+(}^{2}p_{}}+ }-p_{})}{np_{}^{2}p_{}} )[_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^ {t})\|^{2}]\]

to conclude the proof. \(\)

#### e.4.5 Proof for Dastha-Pp-Mvr under Pel-condition

**Theorem 10**.: _Suppose that Assumption 1, 2, 3, 7, 5, 6, 8 and 9 hold. Let us take \(a=}}{2+1}\), \(b(0,}}{2-p_{}}],\)_

\[\{(L+ }^{2}}(L_{}^{2}}{B}+^{2})+}b}(L_{}^{2}}{B}+(1-}}{p_{}})^{2}))^{-1}}\,,,\},\]

_and \(h_{i}^{0}=g_{i}^{0}\) for all \(i[n]\) in Algorithm 1_(Dastha-Pp-MvR)_, then_

\[[f(x^{T})-f^{*}]\] \[(1-)^{T}(_{0}+\|h^{0}- f(x^{0})\|^{2}+(}^{2}}+}-p_{})}{np_{}^{2}})_{i=1}^{n}\|h_{i}^{0}-  f_{i}(x^{0})\|^{2})\] \[+((2+1)}{p_{ }^{2}}+}})}{nB}.\]

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^ {2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[[f(x^{t})-\| f(x^{ t})\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+(1-)}}[\|g^{t}-h^{t}\|^{2}]+(1- )}-p_{})}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+}^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}].\]

Proof.: Let us fix constants \(,[0,)\) that we will define later. Considering Lemma 12, Lemma 10, and the law of total expectation, we obtain

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{}^ {2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[+}^{2}} [_{i=1}^{n}\|k_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})-\| f(x^ {t})\|^{2}-(-)\|x^{t+1}-x^{ t}\|^{2}+\|h^{t}- f(x^{t})\|^{2}]\] \[+(1-)}}[\|g^{t}-h^{t}\|^{2}]+(1- )}-p_{})}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\]\[+^{2}}{ E}[ ^{2}}{B}+(L_{}^{2}}{B}+2^{2}) \|x^{t+1}-x^{t}\|^{2}+2b^{2}_{i=1}^{n}\|h_{i}^{ t}- f_{i}(x^{t})\|^{2}]\] \[+^{2}}{np_{ a}B}+( L_{}^{2}}{np_{ a}B}+-p_{ aa} )^{2}}{np_{ a}^{2}})\|x^{t+1}-x^{t}\|^{2}\] \[+-p_{ aa})b^{2}}{n^{2}p_{ a}^{2 }}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+(1-b)^{2} \|h^{t}- f(x^{t})\|^{2}\] \[+^{2}}{p_{ a}B}+( L_{}^{2}}{p_{ a}B}+)^{ 2}}{p_{ a}})\|x^{t+1}-x^{t}\|^{2}\] \[+()b^{2}}{p_{ a}}+(1-b)^{2}) _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2} .\]

After rearranging the terms, we get

\[{ E}[f(x^{t+1})]+(1-)\,}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+(1 -)\,-p_{ aa})}{np_{ a}^{2}} { E}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{ 2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f_ {i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+(1-)\,}{ E}[ \|g^{t}-h^{t}\|^{2}]+(1-)\,-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[-(--^{2}}(L_{}^{2}}{B}+2^{2}).\] \[.-(L_{}^{2}}{np_{ a}B }+-p_{ aa})^{2}}{np_{ a}^{2}} )-(L_{}^{2}}{p_{ a}B}+)^{2}}{p_{ a}})[\|x^{t+1}- x^{t}\|^{2}]\] \[+(+(1-b)^{2}){ E}[\|h ^{t}- f(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ {2(p_{ a}-p_{ aa})b^{2}}{np_{ a}^{2}}+()b^{2}}{p_{ a}}+(1-b)^{2})[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ }{np_{ a}}+}{p_{ a}})}{B}.\]

By taking \(=\), one can show that \((+(1-b)^{2})(1-)\), and

\[{ E}[f(x^{t+1})]+(1-)\,}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+(1- )\,-p_{ aa})}{np_{ a}^{2}}{ E }[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+[_{i=1}^{n}\|h_{i}^{t+1 }- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+(1-)\,}{ E}[ \|g^{t}-h^{t}\|^{2}]+(1-)\,-p_{ aa})}{np_{ a}^{2}}{ E}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[-(--^{2}}(L_{}^{2}}{B}+2^{2})\]

[MISSING_PAGE_EMPTY:78]

\[=^{3}}(L_{}^{2}}{B}+2(1-p_{ a})^{2})\] \[+}{p_{ a}})} {np_{ a}^{2}}(L_{}^{2}}{B}+2(1-p_{ a}) ^{2})\] \[^{2}}(L_{}^{2}}{B}+2^{2})\] \[+b}(L_{ }^{2}}{B}+2(1-}{p_{ a}})^{2} ),\]

therefore

\[[f(x^{t+1})]+(1-)\,}[\|g^{t+1}-h^{t+1}\|^{2}] +(1-)\,-p_{ a})}{np_{ a}^ {2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+[\|h^{t+1}- f(x ^{t+1})\|^{2}]+(^ {2}}+-p_{ a})}{np_{ a}^{2}}) [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1 })\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-)\,} [\|g^{t}-h^{t}\|^{2}]+(1-)\,-p_{ a})}{np_{ a}^{2}}[ _{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[-(--^{2}}(L_{}^{2}}{B}+2^{2}).\] \[-b}(L_{ }^{2}}{B}+2(1-}{p_{ a}})^{2} )[\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]+(1-) (^{2}}+-p_{ a})}{np_{ a}^{2}})[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}} +}+(^{2}}+-p_{ a})}{np_{ a}^{2}}) }{p_{ a}})}{B}\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-)}[\|g^{t}-h^{t}\|^{2}]+(1- )-p_{ a})}{np_{ a}^{2}} [_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2 }]\] \[-(--^{2}}(L_{}^{2}}{B}+^{ 2}).\] \[-b}(L_{ }^{2}}{B}+(1-}{p_{ a}})^{2} )[\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]+(1-) (^{2}}+-p_{ a})}{np_{ a}^{2}})[_{i= 1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2}}+ }+(^{2 }}+-p_{ a})}{np_{ a}^{2}})}{p_{ a}})}{B}.\]

Also, we can simplify the last term:

\[(^{2}}+-p_{ a})}{np_{ a}^{2}})}{p_{  a}}\] \[=(2+1)}{np_{ a}^{3}}+(1-}{p_{ a}})}{np_{ a}^{2}}\]\[(2+1)}{np_{ a}^{2}}+},\]

thus

\[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-) }[\|g^{t}-h^{t}\|^{2}]+(1- )-p_{ aa})}{np_{ a}^ {2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1} \|^{2}]\] \[+(1-) }[\|g^{t}-h^{t}\|^{2}]+(1- )-p_{ aa})}{np_{ a}^ {2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\] \[-(--^{2}}(L_{}^{2}}{B}+^ {2}).\] \[-b}(L_{ }^{2}}{B}+(1-}{p_{ a}})^{2} )[\|x^{t+1}-x^{t}\|^{2}]\] \[+(1-) [\|h^{t}- f(x^{t})\|^{2}]+(1- )(^{2}}+-p_{ aa})}{np_{ a}^{2}})[ {1}{n}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2 }}+})}{B}.\]

Using Lemma 4 and the assumption about \(\), we get

\[[f(x^{t+1})]+(1-)}[\|g^{t+1}-h^{t+1}\|^{2} ]+(1-) -p_{ aa})}{np_{ a}^{2}}[_{i=1}^{n}\|g_ {i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x ^{t+1})\|^{2}]+(^ {2}}+-p_{ aa})}{np_{ a}^{2}}) [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t +1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-) }[\|g^{t}-h^{t}\|^{2}]+(1- )-p_{ aa})}{np_{ a}^ {2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\] \[+(1-)[ \|h^{t}- f(x^{t})\|^{2}]+(1-) (^{2}}+-p_{ aa})}{np_{ a}^{2}})[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{ a}^{2 }}+})}{B}.\]

Note that \(\), thus \(1- 1-\) and

\[[f(x^{t+1})]+(1-)}[\|g^{t+1}-h^{t+1}\|^{2} ]+(1-)-p _{ aa})}{np_{ a}^{2}}[_{i=1}^{n}\|g_{i} ^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x ^{t+1})\|^{2}]+(^ {2}}+-p_{ aa})}{np_{ a}^{2}}) [_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t +1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[+(1-)} [\|g^{t}-h^{t}\|^{2}]+(1- )-p_{ aa})}{np_{ a}^ {2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\]\[+(1-)\,[\|h^{t}-  f(x^{t})\|^{2}]+(1-)(}^{2}}+}-p_{})}{np_{}^{2}})[_{i=1}^{n }\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+((2+1)}{np_{}^{2} }+}})}{B}.\]

It is left to apply Lemma 11 with

\[^{t} = }}[\|b^{t}-h ^{t}\|^{2}]+}-p_{})}{ np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+ [\|h^{t}- f(x^{t})\| ^{2}]+(}^{2}}+}-p_{})}{np_{}^{2}}) [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}]\]

and \(C=((2+1)}{p_{}^{2}}+}})}{nB}\) to conclude the proof. 

**Corollary 5**.: _Suppose that assumptions of Theorem 10 hold, batch size \(B\{}},^{2}}{L^{2}}\},\) we take \(K\) compressors with \(K=(}{}).\) Then the communication complexity equals_

\[}(}}+}{p_{}}),\]

_and the expected number of stochastic gradient calculations per node equals_

\[}(}{p_{} n }+}{p_{}n^{}{{2}}}}).\]

Proof.: In the view of Theorem 10, DASHA-PP have to run

\[}(}}+}}}{ n B}}+}{p_{ } n B}++} }(+}{})+}n^{}{{2}}}}(+ }{}))\]

communication rounds in the stochastic settings to get \(\)-solution. Note that \(K=(}}).\) Moreover, we can skip the initialization procedure and initialize \(h_{i}^{0}\) and \(g_{i}^{0}\), for instance, with zeros because the initialization error is under a logarithm. Considering Theorem 6, the communication complexity equals

\[}(K}}+K }}}{ n B}}+K }{p_{} n B}+K+K}}(+}{})+K}n^{}{{2}}}}(+}{}))\] \[=}(K}}+K }}}{ n B}}+K }{p_{} n B}+K+K}}(+}{})+K}{p_{}n^{}{{2}}} })\] \[=}(}}+}}+} n  B}+}}+} }(+}{})+}{p_{}n^{}{{2}}}})\] \[=}(}}+}}+}}+}}+} }(+}{})+}{p_{}})\] \[=}(}}+}{p_{}}).\]

The expected number of stochastic gradient calculations per node equals

\[}(B}}+B}}}{ n B}}+B}{p_{ } n B}+B+B} }(+}{})+B}n^{}{{2}}}}(+ }{}))\]\[=}(B}}+B}}}{ n B}}+B}{p_{} n B}+B+B}}(+}{})+B }n^{}{{2}}}} (}{}))\] \[=}(}}+}}}{ n B}}+}{p_{} n}+B+} }(+}{})+}{p_{}n^{}{{2}}}})\] \[=}(}}+}{p_{} n}+ }{p_{} n}+}^{}{{2}}}n}+}^{ }{{2}}}n}(+}{ })+}{p_{}n^{}{{2 }}}})\] \[=}(}{p_{} n }+}{p_{}n^{}{{2}}} }).\]Description of DASHA-PP-SYNC-Mvr

By analogy to (Tyurin and Richtarik, 2023), we provide a "synchronized" version of the algorithm. With a small probability, participating nodes calculate and send a mega batch without compression. This helps us to resolve the suboptimality of DASHA-PP-MVR w.r.t. \(\). Note that this suboptimality is not a problem. We show in Corollary 4 that DASHA-PP-MVR can have the optimal oracle complexity and SOTA communication complexity with the particular choices of parameters of the compressors.

```
1:Input: starting point \(x^{0}^{d}\), stepsize \(>0\), momentum \(a(0,1]\), momentum \(b(0,1]\), probability \(p_{}(0,1]\), batch size \(B^{}\) and \(B\), probability \(p_{}(0,1]\) that a node is _participating_(a), number of iterations \(T 1\).
2:Initialize \(g_{i}^{0}\), \(h_{i}^{0}\) on the nodes and \(g^{0}=_{i=1}^{n}g_{i}^{0}\) on the server
3:for\(t=0,1,,T-1\)do
4:\(x^{t+1}=x^{t}- g^{t}\)
5:\(c^{t+1}=1,p_{},\\ 0,1-p_{}\)
6: Broadcast \(x^{t+1},x^{t}\) to all _participating_(a) nodes
7:for\(i=1,,n\) in parallel do
8:if\(i^{}\) node is _participating_(a) then
9:if\(c^{t+1}=1\)then
10: Generate i.i.d. samples \(\{_{ik}^{t+1}\}_{k=1}^{B^{}}\) of size \(B^{}\) from \(_{i}\).
11:\(k_{i}^{t+1}=}_{k=1}^{B^{}} f_{i}(x^{t+1}; _{ik}^{t+1})-}_{k=1}^{B^{}} f_{i}(x^{t}; _{ik}^{t+1})-}}(h_{i}^{t}-} _{k=1}^{B^{}} f_{i}(x^{t};_{ik}^{t+1}))\)
12:\(m_{i}^{t+1}=}}k_{i}^{t+1}-}}(g_{i }^{t}-h_{i}^{t})\)
13:else
14: Generate i.i.d. samples \(\{_{ij}^{t+1}\}_{j=1}^{B}\) of size \(B\) from \(_{i}\).
15:\(k_{i}^{t+1}=_{j=1}^{B} f_{i}(x^{t+1};_{ij}^{t+1})- _{j=1}^{B} f_{i}(x^{t};_{ij}^{t+1})\)
16:\(m_{i}^{t+1}=_{i}(}}k_{i}^{t+1}-}}(g_{i}^{t}-h_{i}^{t}))\)
17:endif
18:\(h_{i}^{t+1}=h_{i}^{t}+}}k_{i}^{t+1}\)
19:\(g_{i}^{t+1}=g_{i}^{t}+m_{i}^{t+1}\)
20: Send \(m_{i}^{t+1}\) to the server
21:else
22:\(h_{i}^{t+1}=h_{i}^{t}\)
23:\(m_{i}^{t+1}=0\)
24:\(g_{i}^{t+1}=g_{i}^{t}\)
25:endif
26:endfor
27:\(g^{t+1}=g^{t}+_{i=1}^{n}m_{i}^{t+1}\)
28:endfor
29:Output:\(^{T}\) chosen uniformly at random from \(\{x^{t}\}_{k=0}^{T-1}\) (a): For the formal description see Section 2.2. ```

**Algorithm 8**DashA-PP-SYNC-Mvr

In the following theorem, we provide the convergence rate of DASHA-PP-SYNC-MVR.

**Theorem 11**.: _Suppose that Assumptions 1, 2, 3, 5, 6, 7 and 8 hold. Let us take \(a=}}{2+1}\), \(b=}p_{}}{2-p_{}}\), probability \(p_{}(0,1],\) batch size \(B^{} B 1\)_

\[(L+}^{2} }(^{2}+^{2}}{B})+}p_{ }^{2}}((1-}}{p_{}})^{2}+^{2}}{B}))^{-1}},\]_and \(h_{i}^{0}=g_{i}^{0}\) for all \(i[n]\) in Algorithm 8. Then_

\[[\| f(^{T})\|^{2}] [}{}+}p_{}}\|h^{0}- f(x^{0})\|^{2}+}}{p_{i}})}{np_{}p_{}}_{i=1}^{n }\|h_{i}^{0}- f_{i}(x^{0})\|^{2}]\] \[+}{nB^{}}.\]

First, we introduce the expected density of compressors (Gorbunov et al., 2021; Tyurin and Richtarik, 2023).

**Definition 12**.: The expected density of the compressor \(_{i}\) is \(_{_{i}}:=_{x^{d}}[\| _{i}(x)\|_{0}]\), where \(\|x\|_{0}\) is the number of nonzero components of \(x^{d}\). Let \(_{}=_{i[n]}_{_{i}}\).

Note that \(_{}\) is finite and \(_{} d\).

In the next corollary, we choose particular algorithm parameters to reveal the communication and oracle complexity.

**Corollary 6**.: _Suppose that assumptions from Theorem 11 hold, probability \(p_{}=\{\ }}{d},}\},\) batch size \(B^{}=(}{n}),\) and \(h_{i}^{0}=g_{i}^{0}=}}}_{k=1}^{B_{ }}} f_{i}(x^{0};_{ik}^{0})\) for all \(i[n],\) initial batch size \(B_{}}=(}}}}})=(\{}}_{ }},}{}}n}\} ),\) then \(\)-\(\)-\(\)-\(\) needs_

\[T:=(}{}\![L+(}}+}^{2}_{}n}})(+}{})+}n}(}{}+}{B})]+}{}}n B }).\]

_communication rounds to get an \(\)-solution, the expected communication complexity is equal to \((d+_{}T),\) and the expected number of stochastic gradient calculations per node equals \((B_{}}+BT),\) where \(_{}\) is the expected density from Definition 12._

The main improvement of Corollary 6 over Corollary 3 is the size of the initial batch size \(B_{}}\). However, Corollary 4 reveals that we can avoid regimes when \(\)-\(\)-\(\) is suboptimal.

We also provide a theorem under \(\)-condition (see Assumption 9).

**Theorem 13**.: _Suppose that Assumptions 1, 2, 3, 5, 6, 7, 8 and 9 hold. Let us take \(a=}}p_{}}}{2-p_{}}}\), probability \(p_{}(0,1],\) batch size \(B^{} B 1,\)_

\[\{(L+}^{2}}(^{2}}{B}+^{2})+( ^{2}}{np_{}p_{}^{2}B}+}}{p_{}}})^{2}}{np_{}p_{ }^{2}}))^{-1}},,\},\]

_and \(h_{i}^{0}=g_{i}^{0}\) for all \(i[n]\) in Algorithm 8. Then_

\[[f(x^{T})-f^{*}]\] \[(1-)^{T}(_{0}+\|h^ {0}- f(x^{0})\|^{2}+}-p_{}})}{np_{}^{2}p_{}}_{i=1}^{n}\|h_{i}^{0}-  f_{i}(x^{0})\|^{2})+}{ nB^{}}.\]

Let us provide bounds up to logarithmic factors and use \(}()\) notation.

**Corollary 7**.: _Suppose that assumptions from Theorem 13 hold, probability \(p_{}=\{\ }}{d},}\},\) batch size \(B^{}=(}{ n})\) then \(\)-\(\)-\(\)-\(\) needs_

\[T:=}(}_{}}+ }{p_{} n B}++}}(}{}+)+ (}{p_{}}n}}+}n^{}{{2}}}})(}{}+)).\]communication rounds to get an \(\)-solution, the expected communication complexity is equal to \(}(_{}T),\) and the expected number of stochastic gradient calculations per node equals \(}(BT),\) where \(_{}\) is the expected density from Definition 12._

The proof of this corollary almost repeats the proof of Corollary 6. Note that we can skip the initialization procedure and initialize \(h_{i}^{0}\) and \(g_{i}^{0}\), for instance, with zeros because the initialization error is under a logarithm.

Let us assume that \(}}=()\) (holds for the Rand\(K\) compressor), then the convergence rate of DASHA-PP-SYNC-MVR is

\[}(}}+} {p_{} B}++} }(}{}+)+}^{3/2}}(}{}+ )).\] (34)

Comparing (34) with the rate of DASHA-PP-MVR (31), one can see that DASHA-PP-SYNC-MVR improves the suboptimal term \(_{2}\) from (31). However, Corollary 5 reveals that we can escape these suboptimal regimes by choosing the parameter \(K\) of Rand\(K\) compressors in a particular way.

### Proof for Dasha-PP-SYNC-MVR

In this section, we provide the proof of the convergence rate for DASHA-PP-SYNC-MVR. There are four different sources of randomness in Algorithm 8: the first one from random samples \(_{i}^{t+1}\), the second one from compressors \(\{_{i}\}_{i=1}^{n}\), the third one from availability of nodes, and the fourth one from \(c^{t+1}\). We define \(_{k}[]\), \(_{}[]\), \(_{p_{}}[]\) and \(_{p_{}}[]\) to be conditional expectations w.r.t. \(_{i}^{t+1}\), \(\{_{i}\}_{i=1}^{n}\), availability, and \(c^{t+1}\), accordingly, conditioned on all previous randomness. Moreover, we define \(_{t+1}[]\) to be a conditional expectation w.r.t. all randomness in iteration \(t+1\) conditioned on all previous randomness.

Let us denote

\[k_{i,1}^{t+1} :=}_{k=1}^{B^{}} f_{i}(x^{t+1} ;_{ik}^{t+1})-}_{k=1}^{B^{}} f_{i}(x^{t };_{ik}^{t+1})-}}(h_{i}^{t}-}_{k=1}^{B^{}} f_{i}(x^{t};_{ik}^{t+1})),\] \[k_{i,2}^{t+1} :=_{j=1}^{B} f_{i}(x^{t+1};_{ij}^{t+1})- _{j=1}^{B} f_{i}(x^{t};_{ij}^{t+1}),\] \[h_{i,1}^{t+1} :=h_{i}^{t}+}k_{i,1}^{t+1},&i^{}},\\ h_{i}^{t},&,\] \[h_{i,2}^{t+1} :=h_{i}^{t}+}k_{i,2}^{t+1},&i^{}},\\ h_{i}^{t},&,\] \[g_{i,1}^{t+1} :=g_{i}^{t}+}k_{i,1}^{t+1}-}}(g_{i}^{t}-h_{i}^{t}),&i^{}},\\ g_{i}^{t},&,\] \[g_{i,2}^{t+1} :=g_{i}^{t}+_{i}(}k_{ i,2}^{t+1}-}}(g_{i}^{t}-h_{i}^{t})),&i^{ }},\\ g_{i}^{t},&,\]

\(h_{1}^{t+1}:=_{i=1}^{n}h_{i,1}^{t+1}\), \(h_{2}^{t+1}:=_{i=1}^{n}h_{i,2}^{t+1}\), \(g_{1}^{t+1}:=_{i=1}^{n}g_{i,1}^{t+1}\), and \(g_{2}^{t+1}:=_{i=1}^{n}g_{i,2}^{t+1}\). Note, that

\[h^{t+1}=h_{1}^{t+1},&c^{t+1}=1,\\ h_{2}^{t+1},&c^{t+1}=0,\]

and

\[g^{t+1}=g_{1}^{t+1},&c^{t+1}=1,\\ g_{2}^{t+1},&c^{t+1}=0\]

First, we will prove two lemmas.

**Lemma 13**.: _Suppose that Assumptions 3, 5, 7 and 8 hold and let us consider sequences \(\{g_{i}^{t+1}\}_{i=1}^{n}\) and \(\{h_{i}^{t+1}\}_{i=1}^{n}\) from Algorithm 8, then_

\[}}[_{ }}}[_{_{_{ }}}}}[\|g^{t+1}-h^{t+1}\|^{2}]]]\] \[})}{n^{2}p_{ }}_{i=1}^{n}\|k_{i,2}^{t+1}\|^{2}+(}-p_{})a^{2}}{n^{2}p_{}^{2}}+})a^{2}}{n^{2}p_{}})_ {i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}\] \[+(1-a)^{2}\|g^{t}-h^{t}\|^{2},\]

_and_

\[}}[_{_{}}}}[\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2 }]]]\] \[})}{p_{ }}\|k_{i,2}^{t+1}\|^{2}+(})a ^{2}}{p_{}}+})a^{2}}{p_{ }})\|g_{i}^{t}-h_{i}^{t}\|^{2}\] \[+(1-a)^{2}\|g_{i}^{t}-h_{i}^{t}\|^{2}, i[n].\]

Proof.: First, we get the bound for \(+1}}[\|g^{t+1}-h^{t+1}\|^{2}]\):

\[}}[_{_{}}}}[\|g^{t+1}-h^{t+1}\|^{2}] ]]\] \[=p_{}_{}}} [\|g_{1}^{t+1}-h_{1}^{t+1}\|^{2}]+(1-p_{})}}[_{ _{_{}}}}}[\|g_{2}^{t+1}-h_{2}^{t+1} \|^{2}]].\]

Using

\[_{_{_{_{_{ }_{_{}_{_{}_{_{ }_{_{}_{_{}_{_{ }_{_{}_{_{}_{_{ }_{_{}_{_{}_{_{ }_{_{}_{_{}_{_{ }_{_{}_{_{}_{_{ }_{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\,\,\,\,\,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\[+(1-p_{})(}}{n^{2}} _{i=1}^{n}_{}[\|_{i}(}}k_{i,2}^{t+1}-}}(g_{i}^{t}-h_{i}^{t} ))-(}}k_{i,2}^{t+1}- }}(g_{i}^{t}-h_{i}^{t}))\|^{2}])\] \[+(1-a)^{2}\|g^{t}-h^{t}\|^{2}.\]

In the last inequality, we use Assumption 7. Next, using (15), we have

\[})}{n^{2}p_{} }_{i=1}^{n}\|k_{i,2}^{t+1}\|^{2}+( }-p_{})a^{2}}{n^{2}p_{}^{2}}+}) a^{2}}{n^{2}p_{}})_{i=1}^{n}\|g_{i}^{t} -h_{i}^{t}\|^{2}\] \[+(1-a)^{2}\|g^{t}-h^{t}\|^{2}.\]

The second inequality can be proved almost in the same way:

\[=p_{}_{p_{}}[\|g_{i,1}^{t+1 }-h_{i,1}^{t+1}\|^{2}]+(1-p_{})_{ }[_{p_{}}[\|g_{i,2}^{t+1}-h_{i,2}^ {t+1}\|^{2}]]\] \[}{=}p_{}_{p_{ }}[\|g_{i,1}^{t+1}-h_{i,1}^{t+1}-(1-a)(g_{i} ^{t}-h_{i}^{t})\|^{2}]+(1-p_{}) _{}[_{p_{}}[\|g_{i,2}^{ t+1}-h_{i,2}^{t+1}\|^{2}]]\] \[+p_{}(1-a)^{2}\|g_{i}^{t}-h_{i}^{t}\|^{2}\] \[=}(1-p_{})a^{2}}{p_{}}\| g_{i}^{t}-h_{i}^{t}\|^{2}\] \[+(1-a)^{2}\|g_{i}^{t}-h_{i}^{t}\|^{2}\] \[=}(1-p_{})a^{2}}{p_{}}\| g_{i}^{t}-h_{i}^{t}\|^{2}\] \[+(1-p_{})p_{}_{}[\|g_{i}^{t}+_{i}(}}k_{i,2}^{ t+1}-}}(g_{i}^{t}-h_{i}^{t}))-(h_{i}^{t}+ }}k_{i,2}^{t+1})-(1-a)(g_{i}^{t}-h_{ i}^{t})\|^{2}]\] \[+(1-p_{})(1-p_{}) \|g_{i}^{t}-h_{i}^{t}-(1-a)(g_{i}^{t}-h_{i}^{t})\|^{2}\] \[+(1-a)^{2}\|g_{i}^{t}-h_{i}^{t}\|^{2}\] \[=}(1-p_{})a^{2}}{p_{}}\| g_{i}^{t}-h_{i}^{t}\|^{2}\] \[+(1-p_{})p_{}_{}[\|_{i}(}}k_{i,2}^{t+1}- {a}{p_{}}(g_{i}^{t}-h_{i}^{t}))-(}}k_{i,2}^{t+1}-a(g_{i}^{t}-h_{i}^{t}))\|^{2}]\]\[^{2}}{np_{}p_{}p_{} B^{}}+(}L_{}^{2}}{np_{}B^{}} (1-}})^{2}+} )L_{}^{2}}{np_{}B}+}-p_{} )^{2}}{np_{}^{2}})\|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n^{2} p_{}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+ (p_{}(1-}})^{2}+(1-p_{ }))\|h_{i}^{t}- f_{i}(x^{t})\|^{2},  i[n],\]

_and_

\[_{k}[\|k_{i,2}^{t+1}\|^{2}](^{2}}{B}+L_{i}^{2})\|x^{t+1}-x^{t}\|^{2}, i [n],\]

Proof.: First, we prove the bound for \(_{k}[_{p_{}}[\|h^{t+1}- f(x^{t+ 1})\|^{2}]]\). Using

\[_{k}[_{p_{}}[h_{i,1}^{t+1}]]\]\[=h_{i}^{t}+_{k}[}_{k=1}^{B^{ }} f_{i}(x^{t+1};_{ik}^{t+1})-}_{k=1}^{B^{ }} f_{i}(x^{t};_{ik}^{t+1})-\,}}(h_{i }^{t}-}_{k=1}^{B^{}} f_{i}(x^{t};_{ik}^{ t+1}))]\] \[=h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t}))\]

and

\[_{k}[_{p_{t}}[h_{i,2}^{t+1}]]\] \[=h_{i}^{t}+_{k}[_{j=1}^{B} f _{i}(x^{t+1};_{ij}^{t+1})-_{j=1}^{B} f_{i}(x^{t};_ {ij}^{t+1})]\] \[=h_{i}^{t}+ f_{i}(x^{t+1})- f_{i}(x^{t}),\]

we have

\[_{k}[_{p_{t}}[\|h^{t+1}- f (x^{t+1})\|^{2}]]]\] \[=p_{}_{k}[_{p_{t}}[\| h_{1}^{t+1}- f(x^{t+1})\|^{2}]]+(1-p_{})_{k} [_{p_{t}}[\|h_{2}^{t+1}- f(x^{t+1})\|^{2 }]]\] \[}{=}p_{}_{k} [_{p_{t}}[\|h_{1}^{t+1}-_{k}[_{p_{t}}[h_{1}^{t+1}]]\|^{2}]]+(1-p_{ {mega}})_{k}[_{p_{t}}[\|h_{2}^{t+1}-_{k}[_{p_{t}}[h_{2}^{t+1}]]\|^{2}]]\] \[+(p_{}(1-}} )^{2}+(1-p_{}))\|h^{t}- f(x^{t})\|^{2}.\]

We can use Lemma 1 two times with i) \(r_{i}=h_{i}^{t}\) and \(s_{i}=k_{i,1}^{t+1}\) and ii) \(r_{i}=h_{i}^{t}\) and \(s_{i}=k_{i,2}^{t+1}\), to obtain

\[_{k}[_{p_{t}}[\|h^{t+1}- f (x^{t+1})\|^{2}]]]\] \[ p_{}(p_{}}_{i=1}^{ n}_{k}[\|k_{i,1}^{t+1}-_{k}[k_{i,1}^{t+1} ]\|^{2}]+}-p_{}}{n^{2}p_{ }^{2}}_{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})-}}(h_{i}^{t}- f_{i}(x^{t}))\|^{2})\] \[+(1-p_{})(p_{}}_{ i=1}^{n}_{k}[\|k_{i,2}^{t+1}-_{k}[k_{i,2}^{t+1} ]\|^{2}]+}-p_{}}{n^{2}p_{ }^{2}}_{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}\] \[+}-p_{})b^{2}}{n^{2}p_ {}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+ (p_{}(1-}})^{2}+(1-p_{ }))\|h^{t}- f(x^{t})\|^{2}.\] (35)

Let us consider \(_{k}[\|k_{i,1}^{t+1}-_{k}[k_{i,1}^{t+1} ]\|^{2}]\).

\[_{k}[\|k_{i,1}^{t+1}-_{k}[k_{i,1 }^{t+1}]\|^{2}]\] \[=_{k}[\|}_{k=1}^{B^{ }} f_{i}(x^{t+1};_{ik}^{t+1})-}_{k=1}^{B^ {}} f_{i}(x^{t};_{ik}^{t+1})-\,}}(h_ {i}^{t}-}_{k=1}^{B^{}} f_{i}(x^{t};_{ik}^{ t+1})).\]\[-\,( f_{i}(x^{t+1})- f_{i}(x^{t})-}} (h_{i}^{t}- f_{i}(x^{t})))\|^{2}\] \[=_{k}[\|}_{k=1}^{B^{ }} f_{i}(x^{t+1};_{ik}^{t+1})-}_{k=1}^{B ^{}} f_{i}(x^{t};_{ik}^{t+1})+}}( }_{k=1}^{B^{}} f_{i}(x^{t};_{ik}^{t+1})).\] \[-\,.( f_{i}(x^{t+1})- f_{i}(x^{t})+}}( f_{i}(x^{t})))\|^{2}]\] \[=}_{k=1}^{B^{}}_{k}[ \|}}( f_{i}(x^{t+1};_{ik}^{t+1})-  f_{i}(x^{t+1}))..\] \[+\,...(1-}}) ( f_{i}(x^{t+1};_{ik}^{t+1})- f_{i}(x^{t};_{ik}^{t+1})- ( f_{i}(x^{t+1})- f_{i}(x^{t})))\|^{2} ],\]

where we used independence of the mini-batch samples. Using (15), we get

\[_{k}[\|k_{i,1}^{t+1}-_{k}[k_{i,1}^ {t+1}]\|^{2}]\] \[}{B^{ 2}p_{}^{2}}_{k=1}^{B^{ }}_{k}[\| f_{i}(x^{t+1};_{ik}^{t+1})- f _{i}(x^{t+1})\|^{2}]\] \[+}(1-}})^{2} _{k=1}^{B^{}}_{k}[\| f_{i}(x^{t+1};_{ik}^ {t+1})- f_{i}(x^{t};_{ik}^{t+1})-( f_{i}(x^{t+1})- f _{i}(x^{t}))\|^{2}].\]

Due to Assumptions 5 and 6, we have

\[_{k}[\|k_{i,1}^{t+1}-_{k}[k_{i,1}^ {t+1}]\|^{2}]^{2}}{B^{}p_{ }^{2}}+^{2}}{B^{}}(1-}} )^{2}\|x^{t+1}-x^{t}\|^{2}.\] (36)

Next, we estimate the bound for \(_{k}[\|k_{i,2}^{t+1}-_{k}[k_{i,2}^{t+1}] \|^{2}].\)

\[_{k}[\|k_{i,2}^{t+1}-_{k}[k_{i,2}^ {t+1}]\|^{2}]\] \[=_{k}[\|_{j=1}^{B} f_{i}(x ^{t+1};_{ij}^{t+1})-_{j=1}^{B} f_{i}(x^{t};_{ij}^{t+ 1})-( f_{i}(x^{t+1})- f_{i}(x^{t}))\|^{2}]\] \[=}_{j=1}^{B}_{k}[\| f_{ i}(x^{t+1};_{ij}^{t+1})- f_{i}(x^{t};_{ij}^{t+1})-( f_{i}(x^{ t+1})- f_{i}(x^{t}))\|^{2}].\]

Due to Assumptions 6, we have

\[_{k}[\|k_{i,2}^{t+1}-_{k}[k_{i,2}^{t+1}] \|^{2}]^{2}}{B}\|x^{t+1}-x^{t}\|^{2}.\] (37)

Plugging (36) and (37) into (35), we obtain

\[_{k}[_{p_{}}[\|h^{t+1}-  f(x^{t+1})\|^{2}]]]\] \[}}{np_{}}( ^{2}}{B^{}p_{}^{2}}+^{2}}{B^{}} (1-}})^{2}\|x^{t+1}-x^{t}\|^{2})\] \[+})\,L_{}^{2}}{np_{}B} \|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})}{n^{2}p_{}^{2}} _{i=1}^{n}\| f_{i}(x^{t+1})- f_{i}(x^{t})\|^{2}\]

[MISSING_PAGE_EMPTY:91]

[MISSING_PAGE_EMPTY:92]

\[+\!(^{2}}{p_{}p_{ }B^{}}+(}L_{}^{2}}{p_{}B^{}}(1-}})^{2}+})L_{}^{2}}{p_{}B}+}) {L}^{2}}{p_{}})\|x^{t+1}-x^{t}\|^{2}\]\[+})b^{2}}{np_{}p_{}}_{i=1}^ {n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}+(p_{} (1-}})^{2}+(1-p_{}) )_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{ 2}.\]

Let us simplify the last inequality. Since \(B^{} B\) and \(b=}p_{}}{2-p_{}} p_{}\), we have \(1-p_{} 1\),

\[}L_{}^{2}}{p_{}B^{}}(1-}})^{2}}L_{}^{2}}{p_{ }B},\]

\[(p_{}(1-}})^{2}+(1-p_ {})) 1-b,\]

and

\[(})b^{2}}{p_{}p_{}}+ p_{}(1-}})^{2}+(1-p_{} )) 1-b.\]

Thus

\[[f(x^{t})-\| f(x^{t} )\|^{2}-(-)\|x^{t+1}-x^{t} \|^{2}+(\|g^{t}-h^{t}\|^{2}+\|h^{t}- f (x^{t})\|^{2})]\] \[+}}(^{2}}{B}+^{2})\|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{} )a^{2}}{n^{2}p_{}^{2}}_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}+(1-a)^{2}\|g^{t}-h^{t}\|^{2}\] \[+}}(^{2}}{B}+^{2})\|x^{t+1}-x^{t}\|^{2}\] \[+})a^{2}}{p_{}} _{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}+(1-a )^{2}\|g_{i}^{t}-h_{i}^{t}\|^{2}\] \[+^{2}}{np_{}p_{ }B^{}}+^{2}}{np_{}B}+}-p_{})^{2}}{np_{}^{2}} \|x^{t+1}-x^{t}\|^{2}\] \[+}-p_{})b^{2}}{n^{2}p_{ }^{2}p_{}^{2}}_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^ {t})\|^{2}+(1-b)\|h^{t}- f(x^{t})\|^{2}\] \[+^{2}}{p_{}p_{ }B^{}}+^{2}}{p_{}B}+})^{2}}{p_{}}\|x^{t+ 1}-x^{t}\|^{2}\] \[+(1-b)_{i=1}^{n}\|h_{i}^{t}- f _{i}(x^{t})\|^{2}.\]

After rearranging the terms, we get

\[[f(x^{t+1})]+[\|g^{t+1} -h^{t+1}\|^{2}]+[_{i=1}^{n} \|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\]\[ [f(x^{t})]-[\|  f(x^{t})\|^{2}]\] \[-(--}}(^{2}}{B}+^{2})-}}(^{2}}{B}+^{2}).\] \[.-(^{2}}{np_{}B}+ }-p_{})^{2}}{np_{ }^{2}})-(^{2}}{p_{}B}+ })^{2}}{p_{}})) [\|x^{t+1}-x^{t}\|^{2}]\] \[+(+(1-a)^{2})[ \|g^{t}-h^{t}\|^{2}]\] \[+(}-p_ {})a^{2}}{np_{}^{2}}+(})a^{2}}{p_{}}+(1-a)^{2}))[ _{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+(+(1-b))[\|h^ {t}- f(x^{t})\|^{2}]\] \[+(}-p_{})b^{2} }{np_{}^{2}p_{}}+(1-b))[_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(}{np_{}p_{}}+}{p_{}p_{}})}{B^{ }}.\]

Let us take \(=\), thus \(+(1-a)^{2}\) and

\[[f(x^{t+1})]+ [\|g^{t+1}-h^{t+1}\|^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[ [f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[-(--}}(^{2}}{B}+^{2})-}}(^{2}}{B}+^{2}).\] \[.-(^{2}}{np_{}B}+ }-p_{})^{2}}{np_{ }^{2}})-(^{2}}{p_{}B}+ })^{2}}{p_{}})) [\|x^{t+1}-x^{t}\|^{2}]\] \[+[\|g^{t}-h^{t}\|^{2}]\] \[+(}-p_ {})a}{np_{}^{2}}+(})a^{2}}{p_{}}+(1-a)^{2}))[ {1}{n}_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+(+(1-b))[\|h^ {t}- f(x^{t})\|^{2}]\] \[+(}-p_{})b^{2} }{np_{}^{2}p_{}}+(1-b))[_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(}{np_{}p_{}}+}{p_{}p_{}})}{B^{}}.\]

Next, since \(a=}}{2+1}\), we have \((})a^{2}}{p_{}}+(1-a)^{2})  1-a\). We the choice \(=}-p_{})}{np_{ }^{2}}\), we guarantee \(}-p_{})a}{np_{ }^{2}}+(})a^{2}}{p_{}}+(1-a)^{2})\) and

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2} ]+}-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i }^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\|^{2} ]+[_{i=1}^{n}\|h_{i}^{t+1}- f _{i}(x^{t+1})\|^{2}]\]\[ [f(x^{t})]-[\|  f(x^{t})\|^{2}]\] \[-(--}^{2}}(^{2}}{B}+^ {2})-}-p_{})}{np_{}^{3}}(^{2}}{B}+ ^{2}).\] \[.-(^{2}}{np_{}B}+ }-p_{})^{2}}{ np_{}^{2}})-(^{2}}{p_{}B}+ })^{2}}{p_{}})) [\|x^{t+1}-x^{t}\|^{2}]\] \[+}} [\|g^{t}-h^{t}\|^{2}]+}-p_{})}{np_{}^{2}} [_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{ 2}]\] \[+(+(1-b))[\|h^ {t}- f(x^{t})\|^{2}]\] \[+(}-p_{} )b^{2}}{np_{}^{2}p_{}}+(1-b))\![_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{ 2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]\]\[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{})b^{2 }}{np_{}^{2}p_{}}[_{i=1}^{n }\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1} )\|^{2}]+}-p_{})b ^{2}}{np_{}^{2}p_{}}[_{i=1 }^{n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1} )\|^{2}]+}-p_{}) }{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{}) }{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{}) }{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{}) b^{2}}{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{}) b^{2}}{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{}) b^{2}}{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1} )\|^{2}]+}-p_{}) b^{2}}{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1} )\|^{2}]+}-p_{}) b^{2}}{np_{}^{2}p_{}}[_{i=1}^{ n}\|h_{i}^{t}- f_{i}(x^{t+1})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{})}{ np_{}^{2}p_{}}[_{i=1}^{n}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{})}{ np_{}^{2}p_{}}[_{i=1}^{n}\|h_{i}^{t}-  f_{i}(x^{t})\|^{2}]\] \[+}{nB^{}}\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\]\[-(--}^{2}}(^{2}}{B}+^{2} )-(^{2}}{np_{}^{2}p_{}^{2} B}+}}{p_{}})^{2}}{ np_{}p_{}^{2}}))[\|x^{t+1}-x^{t} \|^{2}]\] \[+}}[ \|g^{t}-h^{t}\|^{2}]+}-p_{})}{np_{}^{2}}[ _{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{})}{np_{ }^{2}p_{}}[_{i=1}^{n}\|h_{ i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+}{nB^{}}.\]

Using Lemma 4 and the assumption about \(,\) we get

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_{ }^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{ t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+}-p_{})}{np_{ }^{2}p_{}}[_{i=1}^{n}\|h_{ i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[+}}[ \|g^{t}-h^{t}\|^{2}]+}-p_{})}{np_{}^{2}}[ _{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+[\|h^{t}- f(x^{t}) \|^{2}]+}-p_{})}{ np_{}^{2}p_{}}[_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+}{nB^{}}.\]

It is left to apply Lemma 3 with

\[^{t} = }}[\|g ^{t}-h^{t}\|^{2}]+}-p _{})}{np_{}^{2}}[_{i=1}^{n} \|g_{i}^{t}-h_{i}^{t}\|^{2}]\] \[+ [\|h^{t}- f(x^{t})\|^{2} ]+}}{p_{}})}{np_{}p _{}}[_{i=1}^{n}\|h_{i}^{t}- f _{i}(x^{t})\|^{2}]\]

and \(C=}{nB^{}}\) to conclude the proof. 

**Corollary 6**.: _Suppose that assumptions from Theorem 11 hold, probability \(p_{}=\{\ }}{d},}\},\) batch size \(B^{}=(}{n}),\) and \(h_{i}^{0}=g_{i}^{0}=}}_{k=1}^{B_{}} f _{i}(x^{0};_{ik}^{0})\) for all \(i[n],\) initial batch size \(B_{}=(}}}})= (\{}_{}}},}{}n}}\}),\) then \(\) needs_

\[T:=(}{}[L+(}}+}^{2}_{}n}}) (+}{})+} n}(}{}+}{B} )]+}{}n B}}).\]

_communication rounds to get an \(\)-solution, the expected communication complexity is equal to \((d+_{}T),\) and the expected number of stochastic gradient calculations per node equals \((B_{}+BT),\) where \(_{}\) is the expected density from Definition 12._Proof.: Due to the choice of \(B^{}\), we have

\[[\| f(^{T})\|^{2}] 2_{0}(L+}^{2}}(^{2}+^{2} }{B})+}p_{}^{2}}((1-}}{p_{}})^{2}+^{2}}{B} )})\] \[+}p_{}}\|h^{0}- f (x^{0})\|^{2}+}}{p_{}} )}{np_{}p_{}}_{i=1}^{n}\|h_{i}^{ 0}- f_{i}(x^{0})\|^{2}\] \[+.\]

Using

\[[\|h^{0}- f(x^{0})\|^{2}]= [\|_{i=1}^{n}}}_{k=1}^{B_{ }} f_{i}(x^{0};_{ik}^{0})- f(x^{0})\|^{2} ]}{nB_{}}\]

and

\[}_{i=1}^{n}[\|h_{i}^{0}- f_{i}(x^{ 0})\|^{2}]=}_{i=1}^{n}[\| }}_{k=1}^{B_{}} f_{i}(x^{0};_{ ik}^{0})- f_{i}(x^{0})\|^{2}]}{nB_{}},\]

we have

\[[\| f(^{T})\|^{2}] 2_{0}(L+}^{2}}(^{2}+^{2}}{B})+}p_{}^{2}}( (1-}}{p_{}})^{2}+^{2}}{B})})\] \[+}{nB_{}p_{}B_{}}\] \[+.\]

Therefore, we can take the following \(T\) to get \(\)-solution.

\[T=([_{0}(L+}{np_{}^{2}}(^{2}+^{2}}{B} )+}p_{}^{2}}(^{2}+ ^{2}}{B})})+}{np_{}p_{ }B_{}}])\]

Considering the choice of \(p_{}\) and \(B_{}\), we obtain

\[T =([_{0}(L+ (}}+}^{2} _{}n}})(+}{} )+}n}(}{}+}{B}))+}{np_{}p_{ }B_{}}])\] \[=(}{}[L+( }}+}^{2}_ {}n}})(+}{})+ }n}(}{}+}{B})]+}{}}n  B}).\]

The expected communication complexity equals \((d+p_{}d+(1-p_{})_{} )=(d+_{})\) and the expected number of stochastic gradient calculations per node equals \((B_{}+p_{}B^{}+(1-p_{})B )=(B_{}+B).\)

**Theorem 13**.: _Suppose that Assumptions 1, 2, 3, 5, 6, 7, 8 and 9 hold. Let us take \(a=}}p_{}}}{2-p_{}}}\), probability \(p_{}}(0,1],\) batch size \(B^{} B 1,\)_

\[\{(L+}}^{2}}(^{2}}{B}+^{2})+ (^{2}}{np_{}}p_{}}^{2} B}+}}}{p_{}}}) ^{2}}{np_{}}p_{}}^{2}}) )^{-1}}.,,\},\]

_and \(h_{i}^{0}=g_{i}^{0}\) for all \(i[n]\) in Algorithm 8. Then_

\[[f(x^{T})-f^{*}]\] \[(1-)^{T}(_{0}+\|h^ {0}- f(x^{0})\|^{2}+}}-p_{ }})}{np_{}}^{2}p_{}}} _{i=1}^{n}\|h_{i}^{0}- f_{i}(x^{0})\|^{2} )+}{ nB^{}}.\]

Proof.: Let us fix constants \(,,,[0,)\) that we will define later. As in the proof of Theorem 11, we can get

\[[f(x^{t+1})]+[\|g ^{t+1}-h^{t+1}\|^{2}]+[_{i=1}^{ n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[-(--}}}(^{2}}{B}+^{2})- }}}(^{2}}{B}+ {L}^{2}).\] \[-(^{2}}{np_{}}B}+}}-p_{}}) {L}^{2}}{np_{}}^{2}})-(^{2}}{p _{}}B}+}})^{2}}{p_{ {}}})[\|x^{t+1}-x^{t}\|^{2} ]\] \[+(+(1-a)^{2}) [\|g^{t}-h^{t}\|^{2}]\] \[+(}}-p_{ }})a^{2}}{np_{}}^{2}}+(}})a^{2}}{p_{}}}+(1-a)^{2}) )[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+(+(1-b))[ \|h^{t}- f(x^{t})\|^{2}]\] \[+(}}-p_{}})b^{2}}{np_{}}^{2}p_{}}}+(1-b))\! [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t}) \|^{2}]\] \[+(}{np_{}}p_{}}}+}{p_{}}p_{}}} )}{B^{}}.\]

Let us take \(=\), thus \(+(1-a)^{2}(1-)\) and

\[[f(x^{t+1})]+ [\|g^{t+1}-h^{t+1}\|^{2}]+[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1})\| ^{2}]+[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\] \[-(--}}}(^{2}}{B}+^{2})- }}}(^{2}}{B}+ ^{2}).\]\[+(+(1-b))[\|h^{t}-  f(x^{t})\|^{2}]\] \[+(}-p_{})b^{2} }{np_{}^{2}p_{}}+(1-b))\![_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(}{np_{}p_{}}+}{p_{}p_{}})}{B^{}},\]

where simplified the term using \(p_{} 0\). Let us take \(=\) to obtain

\[[f(x^{t+1})]+}}[\|g^{t+1}-h^{t+1}\|^{2}]+}-p_{})}{np_ {}^{2}}[_{i=1}^{n}\|g_{i}^{t+1}-h_ {i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1 })\|^{2}]+[_{i=1}^{n}\|h_{ i}^{t+1}- f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]- [\| f(x^{t})\|^{2}]\]\[-(--^{2}}(^{2}}{B}+^{2}).\] \[.-(^{2}}{bnp_{ a}B}+ -p_{ aa})^{2}}{bnp_{ a}^{2}} )-(^{2}}{p_{ a}B}+) ^{2}}{p_{ a}}))\!{ E}[\|x^{t+1}-x^{t} \|^{2}]\] \[+(1-)}{  E}[\|g^{t}-h^{t}\|^{2}]+(1-) -p_{ a})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\] \[+(1-)[\| h^{t}- f(x^{t})\|^{2}]\] \[+(-p_{ a})b}{np_{ a }^{2}p_{ mega}}+(1-b))\!{ E}[_{i=1}^{n} \|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(p_{ a}}+ }{p_{ a}p_{ mega}})}{B^{}},\]

Next, we take \(=-p_{ a})}{np_{ a}^{2}p_{ mega }}\), thus

\[{ E}[f(x^{t+1})]+}{  E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E}[ _{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+-p_{ aa})}{np_{ a}^ {2}p_{ mega}}{ E}[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[-(--^{2}}(^{2}}{B}+^{2}).\] \[.-(^{2}}{bnp_{ a}B}+ -p_{ aa})^{2}}{bnp_{ a}^{2}} )-(-p_{ aa})}{np_{ a}^{2}p_ { mega}})(^{2}}{p_{ a}B}+) ^{2}}{p_{ a}}))\!{ E}[\|x^{t+1}-x^{t} \|^{2}]\] \[+(1-)}{  E}[\|g^{t}-h^{t}\|^{2}]+(1-) -p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\| ^{2}]\] \[+(1-)[\| h^{t}- f(x^{t})\|^{2}]+(1-)-p_{ aa})}{np_{ a}^{2}p_{ mega}}{ E}[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+(p_{ a}}+-p_{ aa})b^{2}}{np_{ a}^{3}p_{ mega}^{2}}) }{B^{}},\]

Since \(p_{ a}}{2} b p_{ mega}p_{ a}\) and \(1-p_{ a} 1-}{p_{ a}} 1\), we get

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+-p_{ aa})}{np_{ a }^{2}p_{ mega}}{ E}[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[[f(x^{t})]-[ \| f(x^{t})\|^{2}]\] \[-(--^{2}}(^{2}}{B}+^{2}).\]\[+(1-)}{ E }[\|g^{t}-h^{t}\|^{2}]+(1-)-p_{ aa})}{np_{ a}^{2}p _{ mega}}{ E}[_{i=1}^{n}\|h_{i}^{t}- f_{i}( x^{t})\|^{2}]\] \[+(1-)[\|h^ {t}- f(x^{t})\|^{2}]+(1-)-p_{ aa})}{np_{ a}^{2}p_{ mega}}{ E} [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{ 2}]\] \[+}{nB^{}}\] \[ { E}[f(x^{t})]-[\|  f(x^{t})\|^{2}]\] \[-(--^{2}}(^{2}}{B}+^{2} )-(^{2}}{np_{ a}^{2}p_{ a}^{2}B}+ }{p_{ a}})^{2}}{np_{  mega}p_{ a}^{2}})){ E}[\|x^{t+1}-x^{t}\|^ {2}]\] \[+(1-)}{  E}[\|g^{t}-h^{t}\|^{2}]+(1-) -p_{ aa})}{np_{ a }^{2}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t}\|^ {2}]\] \[+(1-)[\|h ^{t}- f(x^{t})\|^{2}]+(1-)-p_{ aa})}{np_{ a}^{2}p_{ mega}}{ E} [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{ 2}]\] \[+}{nB^{}}.\]

Using Lemma 4 and the assumption about \(\), we get

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}}{ E} [_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+-p_{ aa})}{np_{ a }^{2}p_{ mega}}{ E}[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[ { E}[f(x^{t})]-[\|  f(x^{t})\|^{2}]\] \[+(1-)[\|h^ {t}- f(x^{t})\|^{2}]+(1-)-p_{ aa})}{np_{ a}^{2}p_{ mega}}{ E} [_{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{ 2}]\] \[+}{nB^{}}.\]

Due to \(\) and \(\), we have

\[{ E}[f(x^{t+1})]+}{ E}[\|g^{t+1}-h^{t+1}\|^{2}]+-p_{ aa})}{np_{ a}^{2}p_{ mega}}{  E}[_{i=1}^{n}\|g_{i}^{t+1}-h_{i}^{t+1}\|^{2}]\] \[+[\|h^{t+1}- f(x^{t+1}) \|^{2}]+-p_{ aa})}{np_{ a }^{2}p_{ mega}}{ E}[_{i=1}^{n}\|h_{i}^{t+1}-  f_{i}(x^{t+1})\|^{2}]\] \[ { E}[f(x^{t})]-[\|  f(x^{t})\|^{2}]\] \[+(1-)}{ E }[\|g^{t}-h^{t}\|^{2}]+(1-)-p_{ aa})}{np_{ a}^{2}p _{ mega}}{ E}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^{t} \|^{2}]\] \[+(1-)[\|h^ {t}- f(x^{t})\|^{2}]+(1-)-p_{ aa})}{np_{ a}^{2}p_{ mega}}{ E}[ _{i=1}^{n}\|h_{i}^{t}- f_{i}(x^{t})\|^{2}]\] \[+}{nB^{}}.\]It is left to apply Lemma 11 with

\[^{t} = }}[\|g^{t}-h^{t} \|^{2}]+}-p_{})}{np_{}^{2}}[_{i=1}^{n}\|g_{i}^{t}-h_{i}^ {t}\|^{2}]\] \[+ [\|h^{t}- f(x^{t})\|^ {2}]+}-p_{})}{np_{}^{2}p_{ }}[_{i=1}^{n}\|h_{i}^{t}- f_{ i}(x^{t})\|^{2}]\]

and \(C=}{nB^{}}\) to conclude the proof.