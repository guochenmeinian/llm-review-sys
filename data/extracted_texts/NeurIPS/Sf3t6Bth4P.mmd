# Enhancing Sharpness-Aware Optimization Through Variance Suppression

Bingcong Li

Georgios B. Giannakis

University of Minnesota - Twin Cities

Minneapolis, MN, USA

{lixx5599, georgios}@umn.edu

###### Abstract

Sharpness-aware minimization (SAM) has well documented merits in enhancing generalization of deep neural networks, even without sizable data augmentation. Embracing the geometry of the loss function, where neighborhoods of 'flat minima' heighten generalization ability, SAM seeks 'flat valleys' by minimizing the maximum loss caused by an _adversary_ perturbing parameters within the neighborhood. Although critical to account for sharpness of the loss function, such an '_over-friendly_ adversary' can curtail the outmost level of generalization. The novel approach of this contribution fosters stabilization of adversaries through _variance suppression_ (VaSSO) to avoid such friendliness. VaSSO's _provable_ stability safeguards its numerical improvement over SAM in model-agnostic tasks, including image classification and machine translation. In addition, experiments confirm that VaSSO endows SAM with robustness against high levels of label noise. Code is available at https://github.com/BingcongLi/VaSSO.

## 1 Introduction

Despite deep neural networks (DNNs) have advanced the concept of "learning from data," and markedly improved performance across several applications in vision and language (Devlin et al., 2018; Tom et al., 2020), their overparametrized nature renders the tendency to overfit on training data (Zhang et al., 2021). This has led to concerns in generalization, which is a practically underscored perspective yet typically suffers from a gap relative to the training performance.

Improving generalizability is challenging. Common approaches include (model) regularization and data augmentation (Srivastava et al., 2014). While it is the default choice to integrate regularization such as weight decay and dropout into training, these methods are often insufficient for DNNs especially when coping with complicated network architectures (Chen et al., 2022). Another line of effort resorts to suitable optimization schemes attempting to find a generalizable local minimum. For example, SGD is more preferable than Adam on certain overparameterized problems since it converges to maximum margin solutions (Wilson et al., 2017). Decoupling weight decay from Adam also empirically facilitates generalizability (Loshchilov and Hutter, 2017). Unfortunately, the underlying mechanism remains unclear, and whether the generalization merits carry over to other intricate learning tasks calls for additional theoretical elaboration.

Our main focus, sharpness aware minimization/optimization (SAM), is a highly compelling optimization approach that facilitates state-of-the-art generalizability by exploiting sharpness of loss landscape (Foret et al., 2021; Chen et al., 2022). A high-level interpretation of sharpness is how violently the loss fluctuates within a neighborhood. It has been shown through large-scale empirical studies that sharpness-based measures highly correlate with generalization (Jiang et al., 2019). Several workshave successfully explored sharpness for generalization advances. For example, Keskar et al. (2016) suggests that the batchsize of SGD impresses solution flatness. Entropy SGD leverages local entropy in search of a flat valley (Chaudhari et al., 2017). Different from prior works, SAM induces flatness by explicitly minimizing the _adversarially_ perturbed loss, defined as the maximum loss of a neighboring area. Thanks to such a formulation, SAM has elevated generalization merits among various tasks in vision and language domains (Chen et al., 2022; Zhang et al., 2022). The mechanism fertilizing SAM's success is also theoretically investigated based on arguments of implicit regularization; see e.g., (Andriushchenko and Flammarion, 2022; Wen et al., 2023; Bartlett et al., 2022).

The adversary perturbation, or _adversary_ for short, is central to SAM's heightened generalization because it effectively measures sharpness through the loss difference with original model (Foret et al., 2021; Zhuang et al., 2022; Kim et al., 2022). In practice however, this awareness on sharpness is undermined by what we termed _friendly adversary_. Confined by the stochastic linearization for computational efficiency, SAM's adversary only captures the sharpness for a particular minibatch of data, and can become a friend on other data samples. Because the global sharpness is not approached accurately, the friendly adversary precludes SAM from attaining its utmost generalizability. The present work advocates variance suppressed sharpness aware optimization (VaSSO1) to alleviate 'friendliness' by stabilizing adversaries. With its _provable_ stabilized adversary, VaSSO showcases favorable numerical performance on various deep learning tasks.

All in all, our contribution is summarized as follows.

* it can completely wipe out the generalization merits.
* A novel approach, VaSSO, is proposed to tackle this issue. VaSSO is equipped with what we termed _variance suppression_ to streamline a principled means for stabilizing adversaries. The theoretically guaranteed stability promotes refined global sharpness estimates, thereby alleviating the issue of friendly adversary.
* A side result is tighter convergence analyses for VaSSO and SAM that i) remove the bounded gradient assumption; and ii) deliver a more flexible choice for hyperparameters.
* Numerical experiments confirm the merits of stabilized adversary in VaSSO. It is demonstrated on image classification and neural machine translation tasks that VaSSO is capable of i) improving generalizability over SAM model-agnostically; and ii) nontrivially robustifying neural networks under the appearance of large label noise.

**Notation**. Bold lowercase (capital) letters denote column vectors (matrices); \(\|\|\) stands for \(_{2}\) norm of vector \(\); and \(,\) is the inner product of \(\) and \(\). \(_{}()\) denotes the surface of a ball with radius \(\) centered at \(\), i.e., \(_{}():=\{+\|\|=1\}\).

## 2 The known, the good, and the challenge of SAM

This section starts with a brief recap of SAM (i.e., the known), followed with refined analyses and positive results regarding its convergence (i.e., the good). Lastly, the _friendly adversary_ issue is explained in detail and numerically illustrated.

### The known

Targeting at a minimum in flat basin, SAM enforces small loss around the entire neighborhood in the parameter space (Foret et al., 2021). This idea is formalized by a minimax problem

\[_{}_{\|\|}f+ \] (1)

where \(\) is the radius of considered neighborhood, and the nonconvex objective is defined as \(f():=_{}[f_{}()]\). Here, \(\) is the neural network parameter, and \(\) is a random batch of data. The merits of such a formulation resides in its implicit sharpness measure \(_{\|\|}f+-f()\), which effectively drives the optimization trajectory towards the desirable flat valley (Kim et al., 2022).

The inner maximization of (1) has a natural interpretation as finding an _adversary_. Critical as it is, obtaining an adversary calls for _stochastic linearization_ to alleviate computational concerns, i.e.,

\[_{t}=*{arg\,max}_{\|\|}f(_{t}+)}{{}}*{arg\,max}_{\| \|}f(_{t})+ f(_{t}),}{{}}*{arg\, max}_{\|\|}f(_{t})+_{t}(_{t}),\] (2)

where linearization \((a)\) relies on the first order Taylor expansion of \(f(_{t}+)\). This is typically accurate given the choice of a small \(\). A stochastic gradient \(_{t}(_{t})\) then substitutes \( f(_{t})\) in \((b)\) to downgrade the computational burden of a full gradient. Catalyzed by the stochastic linearization in (2), it is possible to calculate SAM's adversary in closed-form

\[_{t}=_{t}(_ {t})}{\|_{t}(_{t})\|}.}\] (3)

SAM then adopts the stochastic gradient of adversary \(_{t}(_{t}+_{t})\) to update \(_{t}\) in a SGD fashion. A step-by-step implementation is summarized in Alg. 1, where the means to find an adversary in line 4 is presented in a generic form in order to unify the algorithmic framework with later sections.

### The good

To provide a comprehensive understanding about SAM, this subsection focuses on Alg. 1, and establishes its convergence for (1). Some necessary assumptions are listed below, all of which are common for nonconvex stochastic optimization problems (Ghadimi and Lan, 2013; Bottou et al., 2016; Mi et al., 2022; Zhuang et al., 2022).

**Assumption 1** (lower bounded loss).: \(f()\) _is lower bounded, i.e., \(f() f^{*},\)._

**Assumption 2** (smoothness).: _The stochastic gradient \(()\) is \(L\)-Lipschitz, i.e., \(\|()-()\| L\|- \|,,\)._

**Assumption 3** (bounded variance).: _The stochastic gradient \(()\) is unbiased with bounded variance, that is, \([()|]= f()\) and \([\|()- f()\|^{2}|]= ^{2}\) for some \(>0\)._

The constraint of (1) is never violated since \(\|_{t}\|=\) holds for each \(t\); see line 4 in Alg. 1. Hence, the convergence of SAM pertains to the behavior of objective, where a tight result is given below.

**Theorem 1** (SAM convergence).: _Suppose that Assumptions 1 - 3 hold. Let \(_{t}=}{}\), and \(=}{}\). Then with \(c_{0}=1-\) (clearly \(0<c_{0}<1\)), Alg. 1 guarantees that_

\[_{t=0}^{T-1}\| f(_{t})\|^{2} }{}_{t=0}^{T-1}\| f( _{t}+_{t})\|^{2}}{}.\]

The convergence rate of SAM is the same as SGD up to constant factors, where the detailed expression hidden under big \(\) notation can be found in Appendix D. Our results eliminate the need for the bounded gradient assumption compared to existing analyses in (Mi et al., 2022; Zhuang et al., 2022). Moreover, Theorem 1 enables a much larger choice of \(=(T^{-1/2})\) relative to (Andriushchenko and Flamm, 2022), where the latter only supports \(=(T^{-1/4})\).

A message from Theorem 1 is that _any_ adversary satisfying \(_{t}_{}()\) ensures converge. Because the surface \(_{}()\) is a gigantic space, it challenges the plausible optimality of the adversary and poses a natural question - _is it possible to find a more powerful adversary for generalization advances?_

### The challenge: friendly adversary

**Adversary to one minibatch is a friend of others.** SAM's adversary is'malicious' for minibatch \(_{t}\) but not necessarily for other data because it only safeguards \(f_{_{t}}(_{t}+_{t})-f_{_{t}}( _{t}) 0\) for a small \(\). In fact, it can be shown that \(f_{}(_{t}+_{t})-f_{}(_ {t}) 0\) whenever the stochastic gradients do not align well, i.e., \((_{t}(_{t}),_{}(_{t})) 0\). Note that such misalignment is common because of the variance in massive training datasets. This issue is referred to as _friendly adversary_, and it implies that the adversary \(_{t}\) cannot accurately depict the global sharpness of \(_{t}\). Note that the 'friendly adversary' also has a more involved interpretation, that is, \(_{t}(_{t})\) falls outside the column space of Hessian at convergence; see more discussions after (Wen et al., 2023, Definition 4.3). This misalignment of higher order derivatives undermines the inductive bias of SAM, thereby worsening generalization.

To numerically visualize the catastrophic impact of the friendly adversary, we manually introduce one by replacing line 4 of Alg. 1 as \(}_{t}=}_{t}(_{t})/\| }_{t}(_{t})\|\), where \(}_{t}\) denotes the gradient on \(}_{t}\), a randomly sampled batch of the same size as \(_{t}\). This modified approach is denoted as SAM-db, and its performance for i) ResNet-18 on CIFAR10 and ii) ResNet-34 on CIFAR1002 can be found in Fig. 1(a). Note that the test accuracy is normalized relative to SGD for the ease of visualization. It is evident that the friendly \(}_{t}\) in SAM-db almost erases the generalization benefits entirely.

**Source of friendly adversary.** The major cause to the friendly adversary attributes to the gradient variance, which equivalently translates to the lack of stability in SAM's stochastic linearization \((2b)\). An illustrative three dimensional example is shown in Fig. 2, where we plot the adversary \(_{t}\) obtained from different \(_{t}\) realization in \((2b)\). The minibatch gradient is simulated by adding Gaussian noise to the true gradient. When the signal to noise ration (SNR) is similar to a practical scenario (ResNet-18 on CIFAR10 shown in Fig. 2 (e)), it can be seen in Fig. 2 (c) and (d) that the adversaries _almost uniformly_ spread over the norm ball, which strongly indicates the deficiency for sharpness evaluation.

**Friendly adversary in the lens of Frank Wolfe.** An additional evidence in supportive to SAM's friendly adversary resides in its connection to stochastic Frank Wolfe (SFW) that also heavily relies on stochastic linearization (Reddi et al., 2016). The stability of SFW is known to be vulnerable - its convergence cannot be guaranteed without a sufficient large batchsize. As thoroughly discussed in Appendix A, the means to obtain adversary in SAM is tantamount to one-step SFW with a _constant_ batchsize. This symbolizes the possible instability of SAM's stochastic linearization.

### A detailed look at friendly adversaries

The gradient variance is major cause to SAM's friendly adversary and unstable stochastic linearization, however this at first glance seems to conflict with an _empirical_ note termed \(m\)-sharpness, stating that the benefit of SAM is clearer when \(_{t}\) is found using subsampled \(_{t}\) of size \(m\) (i.e., larger variance).

Since \(m\)-sharpness highly hinges upon the loss curvature, it is unlikely to hold universally. For example, a transformer is trained on IWSLT-14 dataset, where the test performance (BLEU) decreases with smaller \(m\) even if we have tuned \(\) carefully; see Fig. 1(c). On the theoretical side, an example is provided in (Andriushchenko and Flammarion, 2022, Sec. 3) to suggest that \(m\)-sharpness is not

Figure 1: (a) A friendly adversary erases the generalization merits of SAM; (b) \(m\)-sharpness may _not_ directly correlate with variance since noisy gradient degrades generalization; and (c) \(m\)-sharpness may not hold universally. Note that test accuracies in (a) and (b) are normalized to SGD.

necessarily related with sharpness or generalization. Moreover, there also exists specific choice for \(m\) such that the \(m\)-sharpness formulation is ill-posed. We will expand on this in Appendix B.

Even in the regime where \(m\)-sharpness is empirically observed such as ResNet-18 on CIFAR10 and ResNet-34 on CIFAR100, we show through experiments that \(m\)-sharpness is _not_ a consequence of gradient variance, thus not contradicting with the friendly adversary issue tackled in this work.

**Observation 1**.: **Same variance, different generalization.** Let \(m=128\) and batchsize \(b=128\). Recall the SAM-db experiment in Fig. 1(a). If \(m\)-sharpness is a direct result of gradient variance, it is logical to expect SAM-db has comparable performance to SAM simply because their batchzises (hence variance) for finding adversary are the same. Unfortunately, SAM-db degrades accuracy. We further increase the variance of \(}_{t}(_{t})\) by setting \(m=64\). The resultant algorithm is denoted as SAM-db-m/2. It does not catch with SAM and performs even worse than SAM-db. These experiments validate that variance/stability correlates with friendly adversary instead of \(m\)-sharpness.

**Observation 2**.: **Enlarged variance degrades generalization.** We explicitly increase variance when finding adversary by adding Gaussian noise \(\) to \(_{t}(_{t})\), i.e., \(}_{t}=_{t}(_{t})}{\| _{t}(_{t})\|}}{\|_{t}(_{t})\|}\). After tuning the best \(\) to compensate the variance of \(\), the test performance is plotted in Fig. 1(b). It can be seen that the generalization merits clearly decrease with larger variance on both ResNet-18 and ResNet-34. This again illustrates that the plausible benefit of \(m\)-sharpness does not stem from increased variance.

In sum, observations 1 and 2 jointly suggest that gradient variance correlates with friendly adversary rather than \(m\)-sharpness, where understanding the latter is beyond the scope of current work.

## 3 Variance-supressed sharpness-aware optimization (VaSSO)

This section advocates variance suppression to handle the friendly adversary. We start with the design of VaSSO, then establish its stability. We also touch upon implementation and possible extensions.

### Algorithm design and stability analysis

A straightforward attempt towards stability is to equip SAM's stochastic linearization with variance reduced gradients such as SVRG and SARAH (Johnson and Zhang, 2013; Nguyen et al., 2017; Li et al., 2019). However, the requirement to compute a full gradient every a few iterations is infeasible and hardly scales well for tasks such as training DNNs.

The proposed variance suppression (VaSSO) overcomes this computational burden through a novel yet simple stochastic linearization. For a prescribed \((0,1)\), VaSSO is summarized below

\[:}_{t}=(1-)_{t-1}+ _{t}(_{t})\] (4a) \[_{t}=*{arg\,max}_{\|\| }f(_{t})+_{t},=_{t}}{\|_{t}\|}.\] (4b)

Compared with (2) of SAM, the key difference is that VaSSO relies on slope \(_{t}\) for a more stable stochastic linearization as shown in (4b). The slope \(_{t}\) is an exponentially moving average (EMA) of \(\{_{t}(_{t})\}_{t}\) such that the change over consecutive iterations is smoothed. Noticing that \(_{t}\) and \(_{t}\) share the same direction, the relatively smoothed \(\{_{t}\}_{t}\) thus imply the stability of \(\{_{t}\}_{t}\) in VaSSO. Moreover, as \(_{t}\) processes information of different minibatch data, the global sharpness can be captured in a principled manner to alleviate the friendly adversary challenge.

Figure 2: (a) - (d) SAMâ€™s adversaries spread over the surface; (e) SNR is in \([0.01,0.1]\) when training a ResNet-18 on CIFAR10, where the SNR is calculated at the first iteration of every epoch.

To theoretically characterize the effectiveness of VaSSO, our first result considers \(_{t}\) as a qualified strategy to estimate \( f(_{t})\), and delves into its mean square error (MSE).

**Theorem 2** (Variance suppression).: _Suppose that Assumptions 1 - 3 hold. Let Alg. 1 equip with i) \(_{t}\) obtained by (4) with \((0,1)\); and, ii) \(_{t}\) and \(\) selected the same as Theorem 1. VaSSO guarantees that the MSE of \(_{t}\) is bounded by_

\[\|_{t}- f(_{t})\|^{2} ^{2}+^{2}}{^{2} }.\] (5)

Because SAM's gradient estimate has a looser bound on MSE (or variance), that is, \([\|_{t}- f(_{t})\|^{2}]^{2}\), the shrunk MSE in Theorem 2 justifies the name of variance suppression.

Next, we quantify the stability invoked with the suppressed variance. It is convenient to start with necessary notation. Define the _quality_ of a stochastic linearization at \(_{t}\) with slope \(\) as \(_{t}():=_{\|\|}f(_{t} )+,\). For example, \(_{t}(_{t})\) and \(_{t}_{t}(_{t})\) are quality of VaSSO and SAM, respectively. Another critical case of concern is \(_{t} f(_{t})\). It is shown in (Zhuang et al., 2022) that \(_{t} f(_{t})_{\|\|}f(_{t}+)\) given a small \(\). Moreover, \(_{t} f(_{t})-f(_{t})\) is also an accurate approximation to the sharpness (Zhuang et al., 2022). These observations safeguard \(_{t}( f(_{t}))\) as the anchor when analyzing the stability of SAM and VaSSO.

**Definition 1** (\(\)-stability).: _A stochastic linearization with slope \(\) is said to be \(\)-stable if its quality satisfies \(|_{t}()-_{t}( f( _{t}))|\)._

A larger \(\) implies a more friendly adversary, hence is less preferable. We are now well-prepared for our main results on adversary's stability.

**Theorem 3** (Adversaries of VaSSO is more stable than SAM.).: _Suppose that Assumptions 1 - 3 hold. Under the same hyperparameter choices as Theorem 2, the stochastic linearization is \(+(})\)-stable for VaSSO, while \(\)-stable in SAM._

Theorem 3 demonstrates that VaSSO alleviates the friendly adversary problem by promoting stability. Qualitatively, VaSSO is roughly \((0,1)\) times more stable relative to SAM, since the term in big \(\) notation is negligible given a sufficiently large \(T\). Theorem 3 also guides the choice of \(\) - preferably small but not too small, otherwise the term in big \(\) is inversely amplified.

### Additional perspectives of VaSSO

Having discussed about the stability, this subsection proceeds with other aspects of VaSSO for a thorough characterization.

**Convergence.** Summarized in the following corollary, the convergence of VaSSO can be pursued as a direct consequence of Theorem 1. The reason is that \(_{t}_{}()\) is satisfied by (4).

**Corollary 1** (VaSSO convergence).: _Suppose that Assumptions 1 - 3 hold. Choosing \(_{t}\) and \(\) the same as Theorem 1, then for any \((0,1)\), VaSSO ensures that_

\[_{t=0}^{T-1}\| f(_{t})\|^{2} }{}_{t=0}^{T-1}\| f( _{t}+_{t})\|^{2}}{}.\]

**VaSSO better reflects sharpness around optimum.** Consider a near optimal region where \(\| f(_{t})\| 0\). Suppose that we are in a big data regime where \(_{t}(_{t})= f(_{t})+\) for some Gaussian random variable \(\). The covariance matrix of \(\) is assumed to be \(^{2}\) for simplicity, but our discussion can be extended to more general scenarios using arguments from von Mises-Fisher statistics (Mardia and Jupp, 2000). SAM has difficulty to estimate the flatness in this case, since \(_{t}/\|\|\) uniformly distributes over \(_{}()\) regardless of whether the neighboring region is sharp. On the other hand, VaSSO has \(_{t}=_{t}/\|_{t}\|\). Because \(\{_{}(_{})\}_{}\) on sharper valley tend to have larger magnitude, their EMA \(_{t}\) is helpful for distinguishing sharp with flat valleys.

**Memory efficient implementation.** Although at first glance VaSSO has to keep both \(_{t}\) and \(_{t}\) in memory, it can be implemented in a much more memory efficient manner. It is sufficient to store \(_{t}\) together with a scaler \(\|_{t}\|\) so that \(_{t}\) can be recovered on demand through normalization; see (4b). Hence, VaSSO has the same memory consumption as SAM.

**Extensions.** VaSSO has the potential to boost the performance of other SAM family approaches by stabilizing their stochastic linearization through variance suppression. For example, adaptive SAM methods (Kwon et al., 2021; Kim et al., 2022) ensure scale invariance for SAM, and GSAM (Zhuang et al., 2022) jointly minimizes a surrogated gap with (1). Nevertheless, these SAM variants leverage stochastic linearization in (2). It is thus envisioned that VaSSO can also alleviate the possible friendly adversary issues therein. Confined by computational resources, we only integrate VaSSO with GSAM in our experiments, and additional evaluation has been added into our research agenda.

## 4 Numerical tests

To support our theoretical findings and validate the powerfulness of variance suppression, this section assesses generalization performance of VaSSO via various learning tasks across vision and language domains. All experiments are run on NVIDIA V100 GPUs.

### Image classification

**Benchmarks.** Building on top of the selected base optimizer such as SGD and AdamW (Kingma and Ba, 2014; Loshchilov and Hutter, 2017), the test accuracy of VaSSO is compared with SAM and two adaptive approaches, ASAM and FisherSAM (Foret et al., 2021; Kwon et al., 2021; Kim et al., 2022).

**CIFAR10.** Neural networks including VGG-11, ResNet-18, WRN-28-10 and PyramidNet-110 are trained on CIFAR10. Standard implementation including random crop, random horizontal flip, normalization and cutout (Devries and Taylor, 2017) are leveraged for data augmentation. The first three models are trained for \(200\) epochs with a batchsize of \(128\), and PyramidNet-110 is trained for \(300\) epochs using batchsize \(256\). Cosine learning rate schedule is applied in all settings. The first three models use initial learning rate \(0.05\), and PyramidNet adopts \(0.1\). Weight decay is chosen as \(0.001\) for SAM, ASAM, FisherSAM and VaSSO following (Du et al., 2022; Mi et al., 2022), but \(0.0005\) for SGD. We tune \(\) from \(\{0.01,0.05,0.1,0.2,0.5\}\) for SAM and find that \(=0.1\) gives the best results for ResNet and WRN, \(=0.05\) and \(=0.2\) suit best for and VGG and PyramidNet, respectively. ASAM and VaSSO adopt the same \(\) as SAM. FisherSAM uses the recommended \(=0.1\)(Kim et al., 2022). For VaSSO, we tune \(=\{0.4,0.9\}\) and report the best accuracy although VaSSO with both parameters outperforms SAM. We find that \(=0.4\) works the best for ResNet-18 and WRN-28-10 while \(=0.9\) achieves the best accuracy in other cases.

It is shown in Table 1 that VaSSO offers \(0.2\) to \(0.3\) accuracy improvement over SAM in all tested scenarios except for PyramidNet-110, where the improvement is about \(0.1\). These results illustrate that suppressed variance and the induced stabilized adversary are indeed beneficial for generalizability.

**CIFAR100.** The training setups on this dataset are the same as those on CIFAR10, except for the best choice for \(\) of SAM is \(0.2\). The numerical results are listed in Table 2. It can be seen that SAM has significant generalization gain over SGD, and this gain is further amplified by VaSSO. On all tested models, VaSSO improves the test accuracy of SAM by \(0.2\) to \(0.3\). These experiments once again corroborate the generalization merits of VaSSO as a blessing of the stabilized adversary.

**ImageNet.** Next, we investigate the performance of VaSSO on larger scale experiments by training ResNet-50 and ViT-S/32 on ImageNet (Deng et al., 2009). Implementation details are deferred to Appendix C. Note that the baseline optimizer is SGD for ResNet and AdamW for ViT. VaSSO is also integrated with GSAM (V+G) to demonstrate that the variance suppression also benefits other SAM type approaches (Zhuang et al., 2022). For ResNet-50, it can be observed that vanilla VaSSO

   CIFAR10 & SGD & SAM & ASAM & FisherSAM & VaSSO \\ 
**VGG-11-BN** & 93.20\({}_{ 0.05}\) & 93.82\({}_{ 0.05}\) & 93.47\({}_{ 0.04}\) & 93.60\({}_{ 0.09}\) & **94.10\({}_{ 0.07}\)** \\
**ResNet-18** & 96.25\({}_{ 0.06}\) & 96.58\({}_{ 0.10}\) & 96.33\({}_{ 0.09}\) & 96.72\({}_{ 0.03}\) & **96.77\({}_{ 0.09}\)** \\
**WRN-28-10** & 97.08\({}_{ 0.16}\) & 97.32\({}_{ 0.11}\) & 97.15\({}_{ 0.05}\) & 97.46\({}_{ 0.18}\) & **97.54\({}_{ 0.12}\)** \\
**PyramidNet-110** & 97.39\({}_{ 0.09}\) & 97.85\({}_{ 0.14}\) & 97.56\({}_{ 0.11}\) & 97.84\({}_{ 0.18}\) & **97.93\({}_{ 0.08}\)** \\   

Table 1: Test accuracy (%) of VaSSO on various neural networks trained on CIFAR10.

outperforms other SAM variants, and offers a gain of \(0.26\) over SAM. V+G showcases the best performance with a gain of \(0.28\) on top of GSAM. VaSSO and V+G also exhibit the best test accuracy on ViT-S/32, where VaSSO improves SAM by 0.56 and V+G outperforms GSAM by 0.19. These numerical improvement demonstrates that stability of adversaries is indeed desirable.

### Neural machine translation

Having demonstrated the benefits of a suppressed variance on vision tasks, we then test VaSSO on German to English translation using a Transformer (Vaswani et al., 2017) trained on IWSLT-14 dataset (Cettolo et al., 2014). The fairseq implementation is adopted. AdamW is chosen as base optimizer in SAM and VaSSO because of its improved performance over SGD. The learning rate of AdamW is initialized to \(5 10^{-4}\) and then follows an inverse square root schedule. For momentum, we choose \(_{1}=0.9\) and \(_{2}=0.98\). Label smoothing is also applied with a rate of \(0.1\). Hyperparameter \(\) is tuned for SAM from \(\{0.01,0.05,0.1,0.2\}\), and \(=0.1\) performs the best. The same \(\) is picked for ASAM and VaSSO as well.

The validation perplexity and test BLEU scores are shown in Table 4. It can be seen that both SAM and ASAM have better performance on validation perplexity and BLEU relative to AdamW. Although VaSSO with \(=0.9\) has slightly higher validation perplexity, its BLEU score outperforms SAM and ASAM. VaSSO with \(=0.4\) showcases the best generalization performance on this task, providing a \(0.22\) improvement on BLEU score relative to AdamW. This aligns with Theorems 2 and 3, which suggest that a small \(\) is more beneficial to the stability of adversary.

### Additional tests

Additional experiments are conducted to corroborate the merits of suppressed variance and stabilized adversary in VaSSO. In particular, this subsection evaluates several flatness related metrics after training a ResNet-18 on CIFAR10 for \(200\) epochs, utilizing the same hyperparameters as those in Section 4.1.

**Hessian spectrum.** We first assess Hessian eigenvalues of a ResNet-18 trained with SAM and VaSSO. We focus on the largest eigenvalue \(_{1}\) and the ratio of largest to the fifth largest eigenvalue \(_{1}/_{5}\). These measurements are also adopted in (Foret et al., 2021; Jastrzebski et al., 2020) to reflect the flatness of the solution, where smaller numbers are more preferable. Because exact calculation for Hessian spectrum is too expensive provided the size of ResNet-18, we instead leverage Lanczos algorithm for approximation (Ghorbani et al., 2019). The results can be found in Table 5. It can be seen that SAM indeed converges to a much flatter solution compared with SGD, and VaSSO further improves upon SAM. This confirms that the friendly adversary issue is indeed alleviated by

   CIFAR100 & SGD & SAM & ASAM & FisherSAM & VaSSO \\ 
**ResNet-18** & 77.90\({}_{ 0.07}\) & 80.96\({}_{ 0.12}\) & 79.91\({}_{ 0.04}\) & 80.99\({}_{ 0.13}\) & **81.30\({}_{ 0.13}\)** \\
**WRN-28-10** & 81.71\({}_{ 0.13}\) & 84.88\({}_{ 0.10}\) & 83.54\({}_{ 0.14}\) & 84.91\({}_{ 0.07}\) & **85.06\({}_{ 0.05}\)** \\
**PyramidNet-110** & 83.50\({}_{ 0.12}\) & 85.60\({}_{ 0.11}\) & 83.72\({}_{ 0.09}\) & 85.55\({}_{ 0.14}\) & **85.85\({}_{ 0.09}\)** \\   

Table 2: Test accuracy (%) of VaSSO on various neural networks trained on CIFAR100.

   ImageNet & vanilla & SAM & ASAM & GSAM & VaSSO & V+G \\ 
**ResNet-50** & 76.62\({}_{ 0.12}\) & 77.16\({}_{ 0.14}\) & 77.10\({}_{ 0.16}\) & 77.20\({}_{ 0.13}\) & **77.42\({}_{ 0.13}\)** & **77.48\({}_{ 0.04}\)** \\
**ViT-S/32** & 68.12\({}_{ 0.05}\) & 68.98\({}_{ 0.08}\) & 68.74\({}_{ 0.11}\) & 69.42\({}_{ 0.18}\) & **69.54\({}_{ 0.15}\)** & **69.61\({}_{ 0.11}\)** \\   

Table 3: Test accuracy (%) of VaSSO on ImageNet, where V+G is short for VaSSO + GSAM.

    & SGD & SAM & VaSSO \\  \(_{1}\) & 82.52 & 26.40 & **23.32** \\ \(_{1}/_{5}\) & 16.63 & 2.12 & **1.86** \\   

Table 5: Hessian spectrum of a ResNet-18 trained on CIFAR10.

the suppressed variance in VaSSO, which in turn boosts the generalizability of ResNet-18 as shown earlier in Section 4.1.

**Label noise.** It is known that SAM holds great potential to harness robustness to neural networks under the appearance of label noise in training data (Foret et al., 2021). As the training loss landscape is largely perturbed by the label noise, this is a setting where the suppressed variance and stabilized adversaries are expected to be advantageous. In our experiments, we measure the performance VaSSO in the scenarios where certain fraction of the training labels are randomly flipped. Considering \(=\{0.9,0.4,0.2\}\), the corresponding test accuracies are summarized in Table 6.

Our first observation is that VaSSO outperforms SAM at different levels of label noise. VaSSO elevates higher generalization improvement as the ratio of label noise grows. In the case of \(75\%\) label noise, VaSSO with \(=0.4\) nontrivially outperforms SAM with an absolute improvement more than \(5\), while VaSSO with \(=0.2\) markedly improves SAM by roughly \(10\). In all scenarios, \(=0.2\) showcases the best performance and \(=0.9\) exhibits the worst generalization when comparing among VaSSO. In addition, when fixing the choice to \(\), e.g., \(=0.2\), it is found that VaSSO has larger absolute accuracy improvement over SAM under higher level of label noise. These observations coincide with Theorem 3, which predicts that VaSSO is suitable for settings with larger label noise due to enhanced stability especially when \(\) is chosen small (but not too small).

## 5 Other related works

This section discusses additional related work on generalizability of DNNs. The possibility of blending VaSSO with other approaches is also entailed to broaden the scope of this work.

**Sharpness and generalization.** Since the study of Keskar et al. (2016), the relation between sharpness and generalization has been intensively investigated. It is observed that sharpness is closely correlated with the ratio between learning rate and batchsize in SGD (Jastrzebski et al., 2017). Theoretical understandings on the generalization error using sharpness-related measures can be found in e.g., (Dziugaite and Roy, 2017; Neyshabur et al., 2017; Wang and Mao, 2022). These works justify the goal of seeking for a flatter valley to enhance generalizability. Targeting at a flatter minimum, approaches other than SAM are also developed. For example, Izmailov et al. (2018) proposes stochastic weight averaging for DNNs. Wu et al. (2020) studies a similar algorithm as SAM while putting more emphases on the robustness of adversarial training.

**Other SAM type approaches.** Besides the discussed ones such as GSAM and ASAM, (Zhao et al., 2022) proposes a variant of SAM by penalizing the gradient norm based on the observation where sharper valley tends to have gradient with larger norm. Barrett and Dherin (2021) arrive at a similar conclusion by analyzing the gradient flow. Exploiting multiple (ascent) steps to find an adversary is systematically studied in (Kim et al., 2023). SAM has also been extended to tackle the challenges in

    & SAM &  VaSSO \\ (\(=0.9\)) \\  &  VaSSO \\ (\(=0.4\)) \\  & 
 VaSSO \\ (\(=0.2\)) \\  \\ 
**25\% label noise** & 96.39\({}_{ 0.12}\) & 96.36\({}_{ 0.11}\) & 96.42\({}_{ 0.12}\) & **96.48\({}_{ 0.09}\)** \\
**50\% label noise** & 93.93\({}_{ 0.21}\) & 94.00\({}_{ 0.24}\) & 94.63\({}_{ 0.21}\) & **94.93\({}_{ 0.16}\)** \\
**75\% label noise** & 75.36\({}_{ 0.42}\) & 77.40\({}_{ 0.37}\) & 80.94\({}_{ 0.40}\) & **85.02\({}_{ 0.39}\)** \\   

Table 6: Test accuracy (%) of VaSSO on CIFAR10 under different levels of label noise.

domain adaptation (Wang et al., 2023). However, these works overlook the friendly adversary issue, and the proposed VaSSO provides algorithmic possibilities for generalization benefits by stabilizing their adversaries. Since the desirable confluence with VaSSO can be intricate, we leave an in-depth investigation for future work.

**Limitation of VaSSO and possible solutions.** The drastically improved generalization of VaSSO comes at the cost of additional computation. Similar to SAM, VaSSO requires to backpropagate twice per iteration. Various works have tackled this issue and developed lightweight SAM. LookSAM computes the extra stochastic gradient once every a few iterations and reuses it in a fine-grained manner to approximate the additional gradient (Liu et al., 2022). ESAM obtains its adversary based on stochastic weight perturbation, and further saves computation by selecting a subset of the minibatch data for gradient computation (Du et al., 2022). The computational burden of SAM can be compressed by switching between SAM and SGD following a predesigned schedule (Zhao et al., 2022), or in an adaptive fashion (Jiang et al., 2023). SAF connects SAM with distillation for computational merits (Du et al., 2022). It should be pointed out that most of these works follow the stochastic linearization of SAM, hence can also encounter the issue of friendly adversary. This opens the door of merging VaSSO with these approaches for generalization merits while respecting computational overhead simultaneously. This has been included in our research agenda.

## 6 Concluding remarks

This contribution demonstrates that stabilizing adversary through variance suppression consolidates the generalization merits of sharpness aware optimization. The proposed approach, VaSSO, provably facilitates stability over SAM. The theoretical merit of VaSSO reveals itself in numerical experiments, and catalyzes model-agnostic improvement over SAM among various vision and language tasks. Moreover, VaSSO nontrivially enhances model robustness against high levels of label noise. Our results corroborate VaSSO as a competitive alternative of SAM.