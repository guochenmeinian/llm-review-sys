# Learning to Group Auxiliary Datasets for Molecule

Tinglin Huang\({}^{1}\)&Ziniu Hu\({}^{2}\)&Rex Ying\({}^{1}\)

\({}^{1}\)Yale University, \({}^{2}\)University of California, Los Angeles

###### Abstract

The limited availability of annotations in small molecule datasets presents a challenge to machine learning models. To address this, one common strategy is to collaborate with additional auxiliary datasets. However, having more data does not always guarantee improvements. Negative transfer can occur when the knowledge in the target dataset differs or contradicts that of the auxiliary molecule datasets. In light of this, identifying the auxiliary molecule datasets that can benefit the target dataset when jointly trained remains a critical and unresolved problem. Through an empirical analysis, we observe that combining graph structure similarity and task similarity can serve as a more reliable indicator for identifying high-affinity auxiliary datasets. Motivated by this insight, we propose _MolGroup_1, which separates the dataset affinity into task and structure affinity to predict the potential benefits of each auxiliary molecule dataset. MolGroup achieves this by utilizing a _routing mechanism_ optimized through a _bi-level optimization framework_. Empowered by the meta gradient, the routing mechanism is optimized toward maximizing the target dataset's performance and quantifies the affinity as the gating score. As a result, MolGroup is capable of predicting the optimal combination of auxiliary datasets for each target dataset. Our extensive experiments demonstrate the efficiency and effectiveness of MolGroup, showing an average improvement of 4.41%/3.47% for GIN/Graphormer trained with the group of molecule datasets selected by MolGroup on 11 target molecule datasets.

## 1 Introduction

Predicting and understanding molecular properties is a fundamental task in biomedical and chemical fields [51; 14; 23; 55], such as evaluating the toxicity of new clinical drugs, characterizing the binding results for the inhibitors of human \(\)-secretase, and predicting the thermodynamic property of organic molecules. In recent years, machine learning-based methods have shown promise in this domain [19; 57; 30; 63; 50]. However, labeling molecules requires expensive real-world clinical trials and expert knowledge, making it difficult to collect a large and diverse labeled dataset for training. This limited availability of labeled data poses a challenge for traditional machine learning methods, which struggle to effectively generalize on small

Figure 1: Relative improvement of using the combination of target dataset and auxiliary dataset over only using target dataset: \(((a,b)-(a))/(a)\), where \(a\) is target dataset and \(b\) is auxiliary dataset.

datasets. To alleviate this, many methods resort to incorporating additional sources of data to the learning process , such as augmenting the current drug data with other known drugs of toxicity. This approach can significantly improve performance by introducing useful out-of-distribution knowledge  and emphasizing attention on relevant features .

Unfortunately, negative transfer can occur when the included data competes for model capacity or when the model fails to learn a shared representation . This phenomenon is also evident in our empirical study, as illustrated in Figure 1. We pair each target dataset with every other dataset and measure the relative improvement achieved by the combination2. The results demonstrate how auxiliary datasets positively or negatively affect the target dataset. For instance, ToxCast greatly improves the performance of ClinTox, while FreeSolv consistently degrades all other datasets' performance. These findings highlight the presence of underlying affinity between different datasets, where auxiliary datasets with high affinity yield greater benefits3. In light of this, _how can we measure the affinity of auxiliary datasets to a target dataset?_

**Measured by both structure and task similarity** -- a clear answer is well supported by our preliminary analysis (Section 3). We compare the similarity between molecule datasets based on task and graph structure separately and examine their correlation with the relative improvement. Our results confirm that combining both task and structure similarity leads to a stronger correlation with relative improvement. However, existing works on task grouping  primarily model task similarities. They rely on exhaustively searching or examining the effect of one task on another. Without further incorporating structure affinity, these methods fail to achieve better performance.

Present work.In this paper, we focus on designing a dataset grouping method for molecules. Here we propose MolGroup, a routing-based molecule grouping method. As shown in Fig. 2, MolGroup involves calculating the affinity scores of each auxiliary dataset based on the graph structure and task information, and selecting the auxiliary datasets with high affinity. The selected datasets are then combined and fed into the downstream model. The key idea is to adopt a _routing mechanism_ in the network and learn to route between auxiliary-specific or target-specific parameters through a _bi-level optimization framework_. The routing mechanism is optimized toward maximizing the target dataset's performance, and its learned gating score serves as the affinity score. This score is calculated by measuring and combining the task and structure affinity between datasets. Our main contributions can be summarized below:

* We provide an empirical study to investigate how different molecule datasets affect each other's learning, considering both task and structure aspects.
* We propose MolGroup, a molecule dataset grouping method, which outperforms other methods on 11 molecule datasets and achieves an average improvement of 4.41%/3.47% for GIN/Graphormer.

Figure 2: Overview of our proposed MolGroup to identify the auxiliary datasets with high affinity. (1) Measure the affinity between the given new molecule dataset and the existing molecule datasets in terms of task and structure. (2) Rank the auxiliary datasets and filter them according to a predetermined threshold. (3) Train the model with the combination of the selected auxiliary datasets and the target dataset.

Related Work

Molecule representation pretraining.Recently, the pretrain-finetune paradigm has been extensively applied to learn the representation of molecules [57; 19; 16; 37; 52; 55]. These methods involve pretraining a graph neural network on a large-scale molecule dataset through contrastive [35; 19; 47; 49; 56; 49] or generative [16; 19; 63] proxy tasks, and finetuning the model on specific downstream task. In our experiments, we demonstrate that incorporating high-affinity auxiliary datasets can significantly improve the performance of pretrained models on downstream target datasets. In addition, our proposed MolGroup can seamlessly integrate with the pretrained models, and the grouping results obtained by the lightweight surrogate model can effectively generalize.

Task grouping.Many applications use multi-task learning [29; 8; 59; 28; 41; 20] to reduce the inference time required to conduct multiple tasks individually or enhance the performance of the tasks with limited labels. To avoid negative transfer, previous methods have been proposed to separate tasks with high affinity. Early studies [60; 45; 22] formulate this as an integer program problem and solve it through optimization. Recent works [12; 44] learn the underlying affinity between different tasks by quantifying the effect of the task's gradient or active learning strategy. In this paper, we focus on grouping the auxiliary molecule datasets that can maximize the performance of the target dataset. By incorporating both structure and task information, our method can achieve better performance.

While MolGroup and MTG-Net  are both related to meta-learning approaches for solving grouping problems, the specific objectives differ. MTG-Net formulates the grouping problem as a meta-learning problem and learns the relationship between tasks with a few meta-training instances, while our approach uses the meta gradient to optimize the routing mechanism instead of applying the meta-learning paradigm.

Conditional computation.A plethora of studies applies conditional computation for scaling up model capacity or adapting computation to input [4; 39; 15; 26; 42; 62; 3]. For instance, Mixture-of-Experts layer [42; 26; 36] introduces the routing mechanism to route each token of a sequence to a subset of experts, which increases the number of parameters without incurring too much computational cost. Some methods apply conditional computation to limit the attention operation for speeding up the inference [10; 3; 62; 46]. Another line of work in multilingual modeling  includes the routing mechanism in each layer to enforce the model to learn language-specific behavior, which can be considered as a simplified neural architecture search framework. Different from these existing works, the routing mechanism in MolGroup aims to endow the model with the ability to determine the fusion significance of two datasets' parameters, which is used as the affinity score.

## 3 Understanding Relationship between Molecule Datasets

Molecule datasets comprise two critical aspects of information: the structural characteristics of the molecules and the associated predictive tasks. Using this insight, we analyze the relationship between molecule datasets by dividing them into these two dimensions. We conduct an empirical study that links the discrepancies in structure and task between datasets to changes in performance when they train together. Molecule structure and predictive task are quantified as the distribution of fingerprint [5; 7] and task embedding :

* **Fingerprint distribution**: Fingerprint is a multi-hop vector used to character a molecule's structure, with each bit representing a certain chemical substructure. We first convert all the instances into MACC  fingerprint, then obtain the fingerprint distribution of the dataset by computing the occurrence frequency of each bit.
* **Task embedding**: We apply Task2vec  to quantify task representation which uses Fisher Information Matrix associated with a pretrained probe network. GIN  is applied as the probe network with extracted atom and bond features as input , and the Monte Carlo algorithm is employed to approximate the Fisher Information Matrix, following the suggested implementation.

Considering the asymmetric nature of the impact between molecule datasets, we use asymmetric KL divergence as the similarity metric [9; 25]. Structural similarity between datasets is measured by fingerprint distribution similarity, while task similarity is measured by task embedding similarity. We plot the regression curve and calculate the Pearson correlation between relative improvement and structural/task similarity over all the combination pairs in Fig.3(a). Additionally, we compute the structural and task similarity between each target dataset and the other 14 datasets individually. We then calculate the Pearson correlation between the similarity scores and the corresponding relative improvement for each target dataset, as shown in Fig.3(b) and (c).

Combination of task and structure leads to better performance.We combine the structure similarity and task similarity for each dataset pair by adding them together, and calculate the Pearson coefficient between the combined similarity and relative improvement in Fig.3(a). This combined similarity demonstrates a stronger correlation with the performance compared to using the two similarities separately, demonstrating the effectiveness of incorporating both structure and task information. Despite this, the existing methods of multi-task grouping primarily focus on leveraging the underlying interdependence among tasks, without explicitly incorporating the structure feature.

Structure and task are compensatory.Based on Fig.3(b) and (c), we can observe that the structure and task correlation exhibit a compensatory relationship. For instance, a dataset may present a low structural correlation but a high correlation in task similarity, as observed in Tox21, where the structural correlation is 0.04, while the task correlation is 0.66. This suggests that these two sources of information contribute to the performance gain in a complementary manner, such that the inadequacy of one source does not preclude performance improvement facilitated by the other. This observation also demonstrates that the affinity of an auxiliary dataset to a target dataset should be determined by the discrepancies in both structure and task.

Both similar and dissimilar structures and tasks can benefit target dataset.According to Fig.3(b) and (c), 8 out of 11 cases in the structural analysis and 7 out of 11 cases in the task analysis show a positive correlation, indicating that the auxiliary datasets with similar structures and predicted tasks can effectively augment the target dataset and improve its performance.

There are also negatively related cases, such as SIDER in Fig.3(b) and BACE in Fig.3(c), indicating that larger discrepancies in graph structure and task can potentially lead to greater improvement. This observation aligns with prior studies on out-of-distribution generalization [58; 54] which demonstrate that dissimilar graph structures and tasks can improve the performance in small datasets with limited annotations. These findings confirm that the additional information required from the other sources of data varies across different target datasets, and both similar and dissimilar structures and tasks from the auxiliary datasets can potentially benefit the target dataset.

Based on the above observations, we argue that an ideal criterion for selecting auxiliary datasets should incorporate measures of both structure and task similarity to the target dataset, and balance these two features. In this study, we propose MolGroup, a routing-based grouping method that allows us to capture the task and graph structure affinity between two molecule datasets.

## 4 Grouping Molecule Datasets with MolGroup

In this section, we introduce MolGroup, a molecule dataset grouping method. MolGroup includes two modules: (1) **routing mechanism** used to quantify the affinity between two datasets, and (2)

Figure 3: **(a) Regression curves between relative improvement and the measures of structure similarity, task similarity, and their mixing. (b,c) Pearson correlation between relative improvement and similarity of fingerprint distribution/task embedding of each molecule dataset individually.**

**bi-level optimization framework** used to update the routing mechanism through meta gradient. Unlike previous methods, the proposed routing function can comprehensively measure the affinity from two perspectives: task and graph structure. We formally define these two modules in Section 4.1 and Section 4.2, and explain our selection process in Section 4.3. More details can be found in Appendix B.

### Routing Mechanism

The objective of MolGroup is to determine the affinity between a target dataset \(_{T}\) and a set of auxiliary datasets \(\{_{Aux}\}_{M}\). To this end, we propose to use the routing mechanism that dynamically allocates the impact of each auxiliary dataset on the target dataset across the network's sub-layers. Intuitively, this routing mechanism allows us to control the contribution of the auxiliary datasets to the final predictions, ensuring the incorporation of the high-affinity auxiliary datasets while mitigating any interference. We first formulate the graph convolution process of a GNN at \(l\)-th layer as:

\[^{(l+1)}=f^{(l)}_{}(^{(l)}),\] (1)

where \(^{(l+1)}\) is the representation of the input batch at \(l\)-th layer, and \(f^{(l)}_{}()\) denotes the convolution function with parameter \(\) at \(l\)-th layer. As illustrated in Fig. 4, in MolGroup, every dataset is assigned a specific parameter \(_{T},_{1},,_{M}\), and we apply the routing mechanism to the auxiliary dataset's convolution process while keeping the convolution process of the target dataset unchanged. Specifically, given an input batch of the target dataset \(_{T}\) and \(m\)-th auxiliary dataset \(_{m}\), the convolution with routing mechanism for \(m\)-th auxiliary dataset at \(l\)-th layer is calculated as:

\[^{(l+1)}_{m}=_{m}f^{(l)}_{_{T}}(^ {(l)}_{m})+(1-_{m})f^{(l)}_{_{m}}(^{(l)}_{m}),\] (2) \[_{m}=g_{m}(_{T},_{m}),\] (3)

where \(^{(l)}_{m}\) is the representation of \(m\)-th auxiliary dataset at \(l\)-th layer, and \(_{m}\) is the gating score generated by the routing function \(g_{m}()\). The routing function endows the model with the capability of determining the impact of the auxiliary dataset on the target dataset's parameter. A closed gate suggests that the backward gradient has a minor impact on \(_{T}\), particularly when \(_{m}=0\), indicating no interaction between the auxiliary dataset and the target dataset. Conversely, an open gate encourages the gradient from the auxiliary dataset to operate on \(_{T}\), particularly when \(_{m}=1\), indicating a hard-parameter sharing architecture.

The calculation of \(g()\) is parameterized using two modules to capture task affinity and structure affinity. For task affinity, we assign learnable embeddings \(^{}_{T}\) and \(^{}_{m}\) for the target dataset and auxiliary dataset respectively, which updated through optimization. For structure affinity, we first extract the fingerprint feature \(x^{}\) for each molecule instance in the input batch. Then, we embed it using a weight matrix and apply Set2Set  to obtain a single embedding \(^{}\):

\[^{}=(\{x^{}\}_{ n}),\] (4)

where \(\) is a learnable weight matrix, and \(n\) is the number of the instance in the batch. Task affinity score and structure affinity score are computed as the cosine similarity and fused as the dataset affinity

Figure 4: Overview of routing mechanism and bi-level optimization framework.

score, which can be formulated as:

\[_{m}=g_{m}(_{T},_{m})=(_{ T}^{}_{m}^{}+(1-)_{T}^{ }_{m}^{}),\] (5)

where \(()\) is the logistic-sigmoid function, and \(\) is a hyperparameter used to balance these two affinity scores. It can be found that the task affinity score is determined globally during training, while the structure affinity score is computed at a per-step level of granularity. To ensure stable learning, a high value for \(\) is suggested. Further analysis can be found in Appendix E. We average the dataset affinity score over a continuous subset of training steps to obtain a final affinity score.

### Bi-level Optimization Framework

The learning of the routing mechanism depends on how the auxiliary dataset's gradient affects the target dataset's performance. However, optimizing this routing mechanism in a target dataset-aware way is challenging since it is only used during the forward pass of the auxiliary dataset. To address this, we propose to use a bi-level  optimization framework to incorporate the guidance of the target dataset. The framework utilizes the target dataset's performance, using the parameters updated by the auxiliary dataset, as a signal to guide the learning of the routing mechanism.

Equipped with the routing mechanism, the overall optimization can be formulated as:

\[_{_{T}}L_{T}(_{T};_{T}),\] (6) \[_{_{T},_{m}}L_{m}(_{m};_{T}, _{m},_{m}),\] (7)where \(L_{T}\) and \(L_{m}\) denote the loss function of the target dataset and auxiliary dataset. It can be found that the optimization of \(_{T}\) is closely linked to the auxiliary task and its relevance is determined by the routing function. We explicitly represent such dependency as \(_{T}(_{m})\). With the goal of obtaining an optimal gating score \(_{m}\) parameterized by \(g_{m}()\), given \(M\) auxiliary datasets, we further formulate the optimization as a bi-level framework:

\[_{_{1},,_{M}}L_{T}(_{T};_{ T}(\{_{m}\}_{M})),\] (8) \[_{T}(\{_{m}\}_{M})=*{ arg\,min}_{_{T}}_{m}^{M}L_{m}(_{m};_{T},_{m}, _{m}),\] (9)

As illustrated in Fig.4, the update process of the routing function is split into two steps: first, the model parameters except the routing function are updated using the gradient from the auxiliary tasks; second, we reuse this computation graph and calculate the meta gradient of the routing mechanism.

### Iterative Filtering and Selection

We adopt an iterative filtering process to perform the selection of auxiliary datasets. Initially, all datasets are trained together in a model equipped with the routing mechanism for several epochs. At the final epoch, we average the generated affinity score across all training steps and take it as the final dataset affinity. Datasets with an affinity score below the predefined threshold are then filtered out. This process is repeated for \(t\) iterations, and in the last round of filtering, the top-\(k\) remaining auxiliary datasets are selected based on their affinity scores. Finally, these selected datasets are combined with the target dataset and used for training the model. The pseudo-code is presented in Algo.1.

Complexity.Given \(M\) candidate auxiliary datasets, we combine them with the target dataset and use MolGroup for grouping. At each training step, we sample data from each dataset with equal probability to form a mini-batch, ensuring that each dataset contributes equally to the training process. The total number of training instances is set as \(N M\) to cover all instances in the target dataset, where \(N\) is the target dataset size. Therefore, the training complexity of each round is \(O(NM)\). This approach is efficient as the number of auxiliary datasets is typically filtered, and further analysis is provided in Section 5.2.

## 5 Experiments

To show the effectiveness of MolGroup, we apply it to 15 molecule datasets with varying sizes and compare it with 8 baseline models. Moreover, we conduct some further studies including an ablation study and efficiency comparison, and conclude some findings regarding the grouping results. The statistics of the involved datasets are summarized in Appendix A, the experimental setting is detailed in Appendix C, and the extensive experimental results can be found in Appendix D.

### Dataset Grouping Evaluation

Baselines.We compare MolGroup with three classes of approaches: 1) search-based methods, 2) grouping-based methods, and 3) the methods that train on all the datasets. Regarding the search-based methods, we apply beam search [32; 13] and consider two kinds of criteria, i.e., the target dataset's performance on the validation set (P), and the combination of the performance and the difference of fingerprint distribution (P+S). We select the candidates with the highest criterion value and train the model for a few epochs at each selection step to speed up the search process. As for the grouping-based methods, we apply TAG  and Task2vec , which calculates the pairwise affinity using the gradient-based strategy. For the last class of methods, we consider Unweighted Averages(UA), Gradnorm , and MTDNN , where MTDNN selects a subset of datasets through the task discriminator. Furthermore, we present the results of Pretrain-Finetune strategy [19; 57], where the model is first trained on PCQM4Mv2  and then finetuned on the downstream dataset.

Dataset.Our study utilizes 15 molecule datasets of varying sizes obtained from MoleculeNet [51; 18] and ChemBL , which can be categorized into three groups: medication, quantum mechanics, and chemical analysis. Our focus is solely on the small molecule datasets that have less than 10,000instances in their training sets, totaling 11 target datasets. We follow the original split setting, where qm8 and qm9 are randomly split, and scaffold splitting is used for the others.

Architectures.All the model architectures include a standard encoder-decoder, where GIN  is used as the encoder in MolGroup and other baseline methods that explicitly group datasets. We evaluate the selected auxiliary datasets using GIN and the SOTA model Graphormer . To accommodate the different tasks, we use a different decoder for each one. The overall training loss is calculated as the unweighted mean of the losses for all included tasks.

Due to the space limit, here we present the comparison results of 6 datasets in Table 1. Our results show that MolGroup outperforms all the baseline methods and consistently improves the performance of the backbone model, with an average relative improvement of 6.47% across all datasets. We observed that MolGroup assigned low-affinity scores to all candidate auxiliary datasets for qm8 and qm9, resulting in no selection of auxiliary datasets for those two target datasets. We attribute this phenomenon to the significant difference between quantum chemistry and other domains. We also observe that UA, Gradnorm, and Pretrain-Finetune methods perform even worse than the model trained only on the target dataset due to the significant distribution shift among these datasets. In addition, the search-based methods' performance is constrained by the limited exploration space, and task grouping methods neglect the data structure difference, leading to suboptimal performance.

Additionally, we apply the resulting groups to evaluate the impact of dataset combination using Graphormer as the encoder . We first pretrain Graphormer on PCQM4Mv2 , which is the largest graph-level prediction dataset, and then finetune it on the specific downstream datasets with the selected auxiliary datasets. As shown in Table 2, the extensive parameter space and pretraining offer a significant improvement to Graphormer, consistent with the previous studies [57; 43]. Moreover, the dataset combinations found by MolGroup outperform all the baseline methods and provide an average relative improvement of 3.35% across all the target datasets, demonstrating the generalizability of the auxiliary dataset groupings exploited by the lightweight surrogate model GIN.

   Method & BBBP(\(\)) & ClinTox(\(\)) & Tox21(\(\)) & BACE(\(\)) & FreeSolv(\(\)) & qm8(\(\)) \\  Only-target & \(66.62_{0.028}\) & \(56.45_{0.023}\) & \(74.23_{0.005}\) & \(75.02_{0.026}\) & \(3.842_{1.579}\) & \(0.0385_{0.001}\) \\  Beam search(P) & \(66.02_{0.015}\) & \(57.86_{0.068}\) & \(74.71_{0.004}\) & \(67.34_{0.039}\) & \(3.271_{0.479}\) & \(0.0553_{0.002}\) \\ Beam search(P+S) & \(67.69_{0.034}\) & \(57.63_{0.036}\) & \(74.36_{0.003}\) & \(69.74_{0.056}\) & \(3.331_{0.287}\) & \(0.0494_{0.000}\) \\ TAG & \(60.66_{0.014}\) & \(57.98_{0.028}\) & \(70.32_{0.006}\) & \(70.02_{0.076}\) & \(3.922_{0.748}\) & \(0.0637_{0.001}\) \\ Task2vec & \(68.18_{0.011}\) & \(47.30_{0.031}\) & \(68.00_{0.005}\) & \(74.71_{0.032}\) & \(3.383_{0.766}\) & \(0.0635_{0.001}\) \\ MTDNN & \(66.56_{0.021}\) & \(52.90_{0.039}\) & \(71.87_{0.003}\) & \(69.91_{0.026}\) & \(3.428_{0.733}\) & \(0.0523_{0.002}\) \\ UA & \(60.41_{0.008}\) & \(51.99_{0.078}\) & \(68.16_{0.004}\) & \(61.75_{0.018}\) & \(4.095_{0.334}\) & \(0.0625_{0.001}\) \\ Gradnorm & \(61.21_{0.007}\) & \(53.08_{0.070}\) & \(59.40_{0.041}\) & \(64.83_{0.028}\) & \(4.356_{0.589}\) & \(0.0657_{0.006}\) \\ Pretrain-Finetune & \(56.59_{0.026}\) & \(56.00_{0.037}\) & \(50.64_{0.015}\) & \(64.80_{0.052}\) & \(4.391_{0.043}\) & \(0.0637_{0.001}\) \\  MolGroup & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) \\   

Table 1: Performance comparison of GIN on target molecule datasets, with \(\) indicating higher is better and \(\) indicating lower is better.

   Method & BBBP(\(\)) & ClinTox(\(\)) & Tox21(\(\)) & BACE(\(\)) & FreeSolv(\(\)) & qm8(\(\)) \\  Only-target & \(66.40_{0.019}\) & \(77.59_{0.028}\) & \(75.97_{0.009}\) & \(78.91_{0.023}\) & \(2.004_{0.088}\) & \(0.0372_{0.002}\) \\  Beam search(P) & \(67.53_{0.010}\) & \(76.77_{0.117}\) & \(76.61_{0.008}\) & \(81.58_{0.038}\) & \(2.129_{0.215}\) & \(0.0473_{0.001}\) \\ Beam search(P+S) & \(67.15_{0.030}\) & \(77.70_{0.076}\) & \(76.83_{0.007}\) & \(80.68_{0.024}\) & \(2.312_{0.191}\) & \(0.0458_{0.001}\) \\ TAG & \(69.62_{0.008}\) & \(78.08_{0.036}\) & \(76.57_{0.006}\) & \(80.10_{0.016}\) & \(2.038_{0.178}\) & \(0.0537_{0.001}\) \\ Task2vec & \(66.93_{0.022}\) & \(72.92_{0.049}\) & \(75.15_{0.007}\) & \(80.84_{0.017}\) & \(1.941_{0.123}\) & \(0.0530_{0.001}\) \\ MTDNN & \(66.71_{0.039}\) & \(71.97_{0.078}\) & \(76.84_{0.008}\) & \(79.79_{0.001}\) & \(2.173_{0.321}\) & \(0.0512_{0.001}\) \\ UW & \(65.37_{0.000}\) & \(80.52_{0.027}\) & \(72.16_{0.009}\) & \(75.64_{0.000}\) & \(2.405_{0.415}\) & \(0.0569_{0.000}\) \\ Gradnorm & \(60.40_{0.045}\) & \(43.46_{0.083}\) & \(55.06_{0.002}\) & \(48.00_{0.005}\) & \(2.552_{0.595}\) & \(0.1694_{0.014}\) \\  MolGroup & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) \\   

Table 2: Performance comparison using Graphormer on target molecule datasets.

### Further Analysis

Overall selected results.In Fig. 6, we visualize the auxiliary datasets with top-3 affinity scores to the target dataset measured by MolGroup. PCBA is selected by most of the datasets due to their diverse structure or useful out-of-distribution information. This phenomenon is supported by Fig. 1, where PCBA demonstrates significant benefits across datasets. We also observe that Tox21 benefits ClinTox and ToxCast, particularly for toxicity-related tasks. Additionally, despite belonging to distinct domains, some datasets exhibit a great affinity to the target dataset, such as qm8 for BBBP and ESOL for Lipo. These findings demonstrate that MolGroup can effectively reveal the underlying affinity between molecule datasets.

Ablation study.We conduct an ablation study to verify the impact of the bi-level optimization framework. Specifically, the routing mechanism is solely updated by the auxiliary dataset's task without the guidance of the target dataset. We pick BBBP as the target dataset, and average the gating scores \(_{m}\) every epoch, which is illustrated in Fig. 5(a). The routing mechanism tends to assign a low weight to the auxiliary-specific parameters (<0.15 in most cases) to increase the dataset-specific capacity, failing to differentiate the affinity of the auxiliary dataset to the target dataset. Conversely, the meta gradient can optimize the routing mechanism toward maximizing the performance of the target dataset, which learns a distinguishable affinity score distribution. Similar phenomena can be found in the other datasets.

Efficiency Comparison.We compare the wall-clock time performance of MolGroup with the other grouping methods using the same running environment (see Appendix D). We pick BBBP and Tox21 as the target datasets, and the results are presented in Fig. 5(b). Beam search explores combinations in a greedy manner, but its computational complexity increases exponentially as the search space grows. TAG efficiently computes inter-task affinity by averaging the lookahead loss proposed during training. MTDNN includes all auxiliary datasets and utilizes a task discriminator to select instances, which limits its computational performance based on the number of training instances used. Although we initially input all candidate auxiliary datasets to MolGroup, we only train for a few epochs at each round, and the majority of them are filtered out after the first or second round of training. Specifically, only 6 and 5 out of 14 candidates remain after the first round of filtering for BBBP and Tox21 respectively.

Comparison with Task2vec: similar task\(\)benefit.In Section 3, we conclude that task similarity measured by task embedding is correlated with relative improvement. But Task2vec  fails to achieve better performance in our experiments since it doesn't incorporate structure information. It is likely that the datasets with similar tasks can serve as data augmentation and are able to benefit each other during training. We choose Tox21, ToxCast, and ClinTox as examples since they share similar tasks of predicting the absence of toxicity or qualitative toxicity measurement. We combine them pairwise and observe that half of the cases result in negative transfers. To delve deeper into this phenomenon, we average the structure affinity score measured by MolGroup over every epoch and plot the results for positive and negative transfer cases in Fig. 7(a) and (b) respectively.

Figure 5: **(a) Comparison between MolGroup with and without meta gradient on BBBP. (b) Efficiency comparison between MolGroup and the other grouping methods.**

Figure 6: Selected grouping for each target dataset.

Our result reveals that the structure affinity consistently converged to a low score during training on negative transfer cases, suggesting a fundamental mismatch between the target task and the auxiliary dataset. The results also demonstrate that the combination of task and structure affinity can lead to a more comprehensive measurement, which is consistent with the insights presented in Sec. 3.

Comparison with TAG: differential affinity scores perform better.TAG  is the SOTA method in task grouping; however, it fails to select high-affinity auxiliary datasets in our cases. Here we plot the inter-task affinity scores measured by TAG for BBBP in Fig. 7(c). Compared with MolGroup's results shown in Fig. 3(a), we observe that most datasets' affinity scores produced by TAG are homogeneous, centered around 0. Even the dataset with the highest affinity score (FreeSolv) is the negative auxiliary dataset to BBBP, as demonstrated in Fig. 1. One reason is that the lookahead loss of every dataset pair used in TAG can be easily influenced by the other dataset when they are trained together in a shared architecture. In contrast, the specific parameters assigned to each dataset in MolGroup can alleviate this issue and result in more stable training.

PCBA is an effective booster. One interesting finding is that dataset PCBA  can boost the performance of most of the small molecule datasets, as shown in Table 3. This dataset offers both a diverse range of chemical compounds with unique scaffold structures, comprising over 350,000 training instances, and an extensive collection of 128 bioassay annotations that represent a broad range of biological activities, making it a potent booster for small molecule property prediction tasks that can benefit from both structure and task.

## 6 Conclusion

A common strategy to improve the performance of small molecule datasets is to incorporate additional data during training. In this paper, we conduct an empirical study to investigate the relationship between molecule datasets and conclude that an ideal criterion should combine graph structure and task discrepancies. Motivated by this, we propose MolGroup which quantifies the affinity between datasets by a routing mechanism that is optimized by the bi-level optimization framework. We evaluate our method on 15 molecule datasets and compare it with 8 baseline models, and the results demonstrate the effectiveness of MolGroup.

**Limitation.** MolGroup operates at the dataset level and does not consider subdataset-level information. As a result, it cannot fully exploit the potential benefits obtained from specific subdatasets within a large dataset. This limitation could impact the performance of MolGroup on certain datasets, such as qm8 and qm9, where MolGroup fails to group high-affinity auxiliary datasets.

    & BBBP(\(\)) & ClinTox(\(\)) & ToxCast(\(\)) & Tox21(\(\)) & ESOL(\(\)) & FreeSolv(\(\)) & Lipo(\(\)) \\  Only-target & \(66.62_{0.028}\) & \(56.45_{0.023}\) & \(60.69_{0.010}\) & \(74.23_{0.005}\) & \(1.563_{0.040}\) & \(3.842_{1.579}\) & \(0.8063_{0.015}\) \\ +PCBA & \(67.11_{0.023}\) & \(57.77_{0.028}\) & \(62.05_{0.007}\) & \(74.81_{0.006}\) & \(1.463_{0.020}\) & \(3.563_{0.989}\) & \(0.8021_{0.009}\) \\   

Table 3: Cases whose performance is improved by PCBA.

Figure 7: **(a,b)** Structure affinity score of positive and negative cases measured by MolGroup. **(c)** Inter-task affinity score measured by TAG on BBBP.