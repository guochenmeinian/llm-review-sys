# Model Merging by Gradient Matching

Nico Daehim\({}^{1}\), Thomas Mollenhoff\({}^{2}\),

**Edoardo M. Ponti\({}^{3}\), Iryna Gurevych\({}^{1}\), Mohammad Emtiyaz Khan\({}^{2}\)**

\({}^{1}\)Ubiquitous Knowledge Processing Lab (UKP Lab)

Department of Computer Science and Hessian Center for AI (hessian.AI)

Technical University of Darmstadt

\({}^{2}\)RIKEN Center for Advanced Intelligence Project, Tokyo, Japan

\({}^{3}\)University of Edinburgh

www.ukp.tu-darmstadt.de

###### Abstract

Models trained on different datasets can be merged by a weighted-averaging of their parameters, but why does it work and when can it fail? Here, we connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a new uncertainty-based scheme to improve the performance by reducing the mismatch. The connection also reveals implicit assumptions in other schemes such as averaging, task arithmetic, and Fisher-weighted averaging.

## 1 Introduction

Merging models through a weighted averaging of their parameters has recently found many applications in deep learning. For example, averaging checkpoints generated during various training runs can improve out-of-distribution generalization (Izmailov et al., 2018; Wortsman et al., 2022b, _inter alia_), while averaging models trained on different datasets can borrow knowledge from "donor tasks" (Matena & Raffel, 2022) and enforce specific fine-grained behaviors in models (Ilharco et al., 2023).

The reasons behind the effectiveness of these methods are not well understood, and many schemes have been proposed, including arithmetic mean (Wortsman et al., 2022b, a), linear interpolation (Ilharco et al., 2023; Ortiz-Jimenez et al., 2023; Yadav et al., 2023), or individual parameter weighing (Matena & Raffel, 2022; Daehim et al., 2023). A prominent hypothesis, 'linear mode connectivity', is that when the models land in relatively few low-loss basins their interpolation again lies in them (Frankle et al., 2020; Neyshabur et al., 2020; Wortsman et al., 2022a; Ainsworth et al., 2023), but it does not tell us why one merging scheme should be preferred over the others or how to improve them.

In this abstract, we make two contributions: we first connect the inaccuracy of weighted-averaging to mismatches in the gradients and then improve its performance by reducing the mismatch with a second-order approximation; see an illustration in Fig. 1.

## 2 Model Merging by Parameter Averaging

We consider merging \(T>1\) models \(_{t}^{d}\) with the same architecture that are trained on different datasets, for example, by fine-tuning a large pretrained model, such as \(_{}\). We focus on the following weighted-averaging scheme: \(}=_{0}\,_{}+ _{t=1}^{T}_{t}\,_{t}\), with scaling matrices \(_{t}^{d d}\). Since \(d\) is often large, simple choices of \(_{t}\) are used in practice, for example, scalars \(_{t}>0\)(Wortsman et al., 2022b, a), often tuned on held-out data. For large models, different parameters have different scaling and it is better to take this into account, for example, by using the Fisher \(_{t}\) in 'Fisher Averaging': \(}_{}=_{t=1}^{T}_{t}_{t},_{t}=_{t}}^{-1}}_{t}\) with \(}=_{t=1}^{T}_{t}_{t},t 1\) In practice, to reduce the computation cost, we may only use the diagonal of the Fisher estimated inan online fashion (Matena & Raffel, 2022). However, it is unclear how FA takes care of the commonalities of the \(_{t}\) and \(_{}\). A recent work by Jin et al. (2023) uses insights from linear models to justify some choices, but may not hold for nonlinear models. Ilharco et al. (2023) proposed to subtract \(_{}\) with 'task arithmetic': \(}_{}=_{}+_{ t=1}^{T}_{t}(_{t}-_{})\), which reduces double-counting the information by using \(_{t}-_{}\), but it is unclear how to combine it with Fisher-style scaling.

We investigate the following: (1) how to choose scaling matrices; (2) what is the effect of these choices on the merged models' accuracy; and (3) how to obtain a new method that reduces inaccuracies.

## 3 Model Merging and Connections to Gradient Mismatches

To understand the inaccuracies of parameter averaging, we introduce the idea of a _target model_: it is the model that model merging methods want to estimate. Consider two models \(_{1}\) and \(_{2}\) trained on two datasets \(_{1}\) and \(_{2}\), respectively, for example, as follows,

\[_{1}=*{arg\,min}_{}\ \ _{1}( )+\|\|^{2}, _{2}=*{arg\,min}_{}\ \ _{2}( )+\|\|^{2}.\] (1)

Here, the loss functions on \(_{1}\) and \(_{2}\) are denoted by \(_{1}()\) and \(_{2}()\) respectively and the regularizer is an \(L_{2}\) regularizer (what follows also holds for other explicit regularizers, also implicit ones). The target model in this case could be a model \(_{1+2}\) that is trained jointly on the two datasets:

\[_{1+2}=*{arg\,min}_{}\ \ _{1}_{1}( )+_{2}_{2}(_{1})+ \|\|^{2}.\] (2)

We will now connect gradient mismatch to the error between the target \(_{1+2}\) and a parameter-average \(_{1}_{1}+_{2}_{2}\), but the approach is general and applies to different types of targets and averages.

We start with the first-order stationarity conditions of the models in Eqs. 1 and 2,

\[_{1}=-_{1}(_{1}), _{2}=-_{2}(_{2}), _{1+2}=-_{1}_{1}(_ {1+2})-_{2}_{2}(_{1+2}).\] (3)

Using these, we can express \(_{1+2}\) in terms of \(_{1}_{1}+_{2}_{2}\) and quantify the error made. To do so, we multiply the first and second equations above by \(_{1}\) and \(_{2}\) respectively, and add them together. Then, we subtract the resultant from the third equation to get the following expression:

\[_{1+2}-(_{1}_{1}+ _{2}_{2})}_{=,}=-_{1}_{1}(_{1+2})- _{1}(_{1})]}_{_{1}_{1}}- _{2}_{2}(_{1+2})- _{2}(_{2})]}_{_{2}_{2}}.\] (4)

The left-hand side is the error \(=_{1+2}-(_{1}_{1}+_{2} _{2})\) which is equal to the weighted-sum of the two gradient-mismatch terms on the individual losses \(_{1}(_{1})\) and \(_{2}(_{2})\). It shows that if the individual models are already close to the target model, parameter averaging should be reasonably accurate. It also shows us room for improvement and mismatch reduction may lead to better schemes.

Figure 1: The left panel illustrates our approach. We connect the error \(\) of the merged model \(_{}\) to the gradient mismatch over losses \(_{t}\) and propose a new method that reduces the mismatch by using the Hessian \(_{t}\) and error \(_{t}\) of the individual models \(_{t}\). The right panel shows an example of adding datasets to RoBERTa trained on IMDB. We clearly see that reducing mismatch also reduces test error of task arithmetic. We consider 5 datasets, each indicated by a number on the markers.

The method is generic and can be used to analyze errors of generic parameter-averaging schemes, for example, data removal (cf. Appendix). Test accuracy can also be analyzed. For example, given test loss \(_{}()\) and weighted-average \(}\), we have: \(_{}(_{1+2})-_{}(})_{}(})^{}(_{1+2}-})\). Large gradient mismatch therefore is expected to correlate with large differences in test performance.

Sources of errors can be analyzed, too. For example, when the test data is more correlated to \(_{1}\), then model merging would be effective if gradient mismatch due to \(_{1}\) is also small. This is similar to linear mode connectivity: when both the target and merged models lie in low-loss basins, we expect gradient mismatch to be low due to flatness. However, gradient-mismatch does not require this and is more general and constructive by allowing us to improve models by actively reducing the mismatch.

### Analyzing the Inaccuracy of Task Arithmetic on Large Language Models

We will demonstrate the use of the gradient-mismatch principle to analyze the inaccuracy of 'task arithmetic' (Ilharco et al., 2023) for \(_{}\) trained on a large dataset \(_{}\).

\[_{}=*{arg\,min}_{}~{}_{}()+\|\|^{2},~{}_{}()=_{i_{}}_{i}( ).\] (5)

Here, \(_{i}()\) denotes the loss on the \(i\)'th example. For simplicity, we use an \(L_{2}\) regularization with parameter \(>0\) but the choice is not crucial. The loss function can also be normalized. Our goal is to merge models \(_{t}\) that are finetuned on different datasets \(_{t}\) for \(t=1,2,,T\) using:

\[_{t}=*{arg\,min}_{}~{}_{t}()+\|-_{}\|_{_{0} }^{2},\] (6)

where \(\|\|_{_{0}}^{2}=^{}_{0}\) is the Mahalanobis distance with a scaling matrix \(_{0}\) which controls how different \(\) is from \(_{}\). We will discuss how to set \(_{0}\) later. _The derivation can be easily adopted to other fine-tuning procedures_ as long as we can express the dependence on \(_{}\) explicitly.

Task arithmetic (TA) uses \(}_{}=_{}+_{t}_{t}( _{t}-_{})\) to merge models. There are two natural questions: what is the target model that such a scheme is trying to approximate and what are the errors made by TA in approximating it? As before, a reasonable choice of the target model is the one obtained by fine-tuning using a similar procedure as Eq. 6 but on all \(_{t}\) at once,

\[_{1:T}=*{arg\,min}_{}~{}_{t=1}^{T} _{t}_{t}()+\|-_{ {LLM}}\|_{_{0}}^{2}.\] (7)

Following the same derivation as Eq. 4, we can quantify the error between \(_{1:T}\) and \(}_{}\) (a full derivation is given in Appendix):

\[_{1:T}=_{}+_{t=1}^{T}_ {t}(_{t}-_{})}_{=_{}}- _{t=1}^{T}_{t}_{0}^{-1}_ {t}(_{1:T})-_{t}(_{t})]}_{_{t}_{t}}.\] (8)

The derivation can be used to understand the implicit assumptions made in task arithmetic. The increments \(_{t}-_{}\) arise above due to the quadratic regularizer \(\|-_{}\|^{2}\) used in Eqs. 6 and 7 and avoid double counting. More importantly, the error between \(_{1:T}\) and \(}_{}\) is attributed to gradient mismatch between \(_{t}\) and \(_{1:T}\). The expression suggests that by reducing the mismatch we could improve task arithmetic. We will now show that a simple method that uses Taylor's approximation to reduce the gradient mismatch justifies combining TA with a Fisher-like weighting schemes.

Figure 2: Our method is more robust to scaling than TA for task addition in CV (left) and NLP (right).

### A New Method to Reduce the Gradient Mismatch

We now derive a new parameter-averaging method by reducing the gradient mismatch in Eq. 8. Explicit minimization of the mismatch is non-trivial because \(_{t}(_{1:T})\) depends non-linearly on \(_{1:T}\) but we can get rid of the term by using a first-order Taylor approximation,

\[_{t}()_{t}(_{t})+ _{t}(-_{t})\] (9)

where \(_{t}=^{2}_{t}(_{t})\) is the Hessian of the loss \(_{t}\) at \(_{t}\). Using this in Eq. 8 and after some rearrangement, we get the following merging scheme (a full derivation is given in Appendix),

\[}_{1:T}=_{}+_{t=1}^{T}_{t}( }^{-1}_{0+t})(_{t}-_{ }),\] (10)

where \(}=_{0}+_{t=1}^{T}_{t}_{t}\) and \(_{0+t}=_{0}+_{t}\) is the Hessian plus a regularization matrix. The new merging scheme adds preconditioners \(}^{-1}_{0+t}\) to task arithmetic. The preconditioners depend on the Hessians \(_{t}\), which is similar to Fisher averaging, but here the choice naturally emerges as a consequence of the gradient-mismatch reduction. Nevertheless, replacing \(_{t}\) by the diagonal Fisher \(_{t}\) of \(_{t}\) is often easier to compute and easier numerically because positive-definiteness is ensured. The matrix \(_{0}\) can be set in a similar way, for example, to the Hessian/Fisher of Eq. 5 at \(_{}\).

Choosing different setting of \(_{t}\), \(_{0}\), and \(_{t}\), can recover many existing schemes as special cases of Eq. 10. This helps us to understand not only their inaccuracies but also their implicit assumptions. AM and TA can be seen as special cases where the preconditioner \(_{t}=\). This implies that the gradient mismatch term in Eq. 8 is left as is and the error will be high when there gradient mismatch is high. In contrast, Fisher averaging can be seen as a special cases where \(_{0}=\) which implies that the quadratic regularizer in Eqs. 6 and 7 vanishes, ignoring the dependence of \(_{t}\) on \(_{}\).

## 4 Experiments & Results

We use a pretrained ViT (Dosovitskiy et al., 2021) for image classification and add eight datasets to it: Cars (Krause et al., 2013), DTD (Cimpoi et al., 2014), EuroSAT (Helber et al., 2018), GTSRB (Houben et al., 2013), MNIST (LeCun, 1998), RESISC45 (Cheng et al., 2017), SUN397 (Xiao et al., 2010), and SVHN (Yuval, 2011), replicating Ilharco et al. (2023). We use identity to approximate the Hessian of the ViT and all task models are trained by fine-tuning it. The results are outlined in the leftmost panel of Fig. 2. Our proposed merging function is much more robust to the choice of scaling factors. For larger factors, task arithmetic even falls below the zero-shot baseline.

We repeat a similar experiment with RoBERTa (Liu et al., 2019) for sentiment classification, which we first train on IMDB (Maas et al., 2011) (arbitrarily chosen). We approximate \(_{0}\) using squared gradients on the training data. We then use this model to initialize all \(_{t}\) which we train on Amazon (Zhang et al., 2015), RottenTomatoes (Pang and Lee, 2005), SST2 (Socher et al., 2013), and Yelp (Zhang et al., 2015). Table 1 shows that our new method gets closer to the "all-data" target model than other merging functions, indicating that reducing gradient mismatch is crucial, as outlined also in Fig. 1. Furthermore, it improves over TA even when we tune scaling factors on the test set for TA and not at all for our method. Fig. 2 (right) shows a plot over scaling factors where our method dominates TA which also falls below the zero-shot baseline of the IMDB model.

  & IMDB & Yelp & RT & SST2 & Amazon & Avg. \\  All-data & 94.8 & 97.6 & 91.2 & 94.7 & 96.9 & 95.0 \\  Averaging & 94.4 & 97.0 & 89.1 & 93.6 & 96.2 & 94.1 \\ Fisher Averaging & **94.8** & 97.2 & 89.9 & 93.1 & 96.6 & 94.3 \\ Task Arithmetic (tuned \(_{1}\))\({}^{}\) & 94.3 & 97.2 & 89.6 & **94.5** & 96.4 & 94.4 \\ Ours & 94.7 (10.4) & **97.3 (10.1)** & **90.2 (70.6)** & 93.7 (0.8) & **96.7 (10.3)** & **94.5 (70.1)** \\  

Table 1: We merge four tasks with RoBERTa trained on IMDB. Our merging function shows that reducing gradient mismatch improves performance over previously proposed functions.

Conclusion

We have connected the error of the merged model to the gradient mismatch between the individual models that are merged and the 'target model' that merging aims to recover. We have used this to reveal implicit assumptions in related methods and propose an improved merging scheme that is more robust in terms of scaling factors and improves downstream performance.