# DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework

Hua Wang

Department of Statistics and Data Science

University of Pennsylvania

Philadelphia, PA 19104

wanghua@wharton.upenn.edu

&Sheng Gao

Department of Statistics and Data Science

University of Pennsylvania

Philadelphia, PA 19104

shenggao@wharton.upenn.edu

&Huanyu Zhang

Meta Platforms, Inc.

New York, NY 10003

huanyuzhang@meta.com

&Weijie J. Su

Department of Statistics and Data Science

University of Pennsylvania

Philadelphia, PA 19104

suw@wharton.upenn.edu

&Milan Shen

Meta Platforms, Inc.

Menlo Park, CA 94025

milanshen@gmail.com

###### Abstract

Hyperparameter optimization, also known as hyperparameter tuning, is a widely recognized technique for improving model performance. Regrettably, when training private ML models, many practitioners often overlook the privacy risks associated with hyperparameter optimization, which could potentially expose sensitive information about the underlying dataset. Currently, the sole existing approach to allow privacy-preserving hyperparameter optimization is to uniformly and randomly select hyperparameters for a number of runs, subsequently reporting the best-performing hyperparameter. In contrast, in non-private settings, practitioners commonly utilize "adaptive" hyperparameter optimization methods such as Gaussian process-based optimization, which select the next candidate based on information gathered from previous outputs. This substantial contrast between private and non-private hyperparameter optimization underscores a critical concern. In our paper, we introduce DP-HyPO, a pioneering framework for "adaptive" private hyperparameter optimization, aiming to bridge the gap between private and non-private hyperparameter optimization. To accomplish this, we provide a comprehensive differential privacy analysis of our framework. Furthermore, we empirically demonstrate the effectiveness of DP-HyPO on a diverse set of real-world datasets.

## 1 Introduction

In recent decades, modern deep learning has demonstrated remarkable advancements in various applications. Nonetheless, numerous training tasks involve the utilization of sensitive information pertaining to individuals, giving rise to substantial concerns regarding privacy . To address these concerns, the concept of differential privacy (DP) was introduced by . DP provides a mathematically rigorous framework for quantifying privacy leakage, and it has gained widespreadacceptance as the most reliable approach for formally evaluating the privacy guarantees of machine learning algorithms.

When training deep learning models, the most popular method to ensure privacy is noisy (stochastic) gradient descent (DP-SGD) . DP-SGD typically resembles non-private gradient-based methods; however, it incorporates gradient clipping and noise injection. More specifically, each individual gradient is clipped to ensure a bounded \(_{2}\) norm. Gaussian noise is then added to the average gradient which is utilized to update the model parameters. These adjustments guarantee a bounded sensitivity of each update, thereby enforcing DP through the introduction of additional noise.

In both non-private and private settings, hyperparameter optimization (HPO) plays a crucial role in achieving optimal model performance. Commonly used methods for HPO include grid search (GS), random search (RS), and Bayesian optimization (BO). GS and RS approaches are typically non-adaptive, as they select the best hyperparameter from a predetermined or randomly selected set. While these methods are straightforward to implement, they can be computationally expensive and inefficient when dealing with large search spaces. As the dimensionality of hyperparameters increases, the number of potential trials may grow exponentially. To address this challenge, adaptive HPO methods such as Bayesian optimization have been introduced . BO leverages a probabilistic model that maps hyperparameters to objective metrics, striking a balance between exploration and exploitation. BO quickly emerged as the default method for complex HPO tasks, offering improved efficiency and effectiveness compared to non-adaptive methods.

While HPO is a well-studied problem, the integration of a DP constraint into HPO has received little attention. Previous works on DP machine learning often neglect to account for the privacy cost associated with HPO . These works either assume that the best parameters are known in advance or rely on a supplementary public dataset that closely resembles the private dataset distribution, which is not feasible in most real-world scenarios.

Only recently have researchers turned to the important concept of honest HPO , where the privacy cost during HPO cannot be overlooked. Private HPO poses greater challenges compared to the non-private case for two primary reasons. First, learning with DP-SGD introduces additional hyperparameters (e.g., clipping norm, the noise scale, and stopping time), which hugely adds complexity to the search for optimal hyperparameters. Second, DP-SGD is more sensitive to the selection of hyperparameter combinations, with its performance largely influenced by this choice .

To tackle this challenging question, previous studies such as  propose running the base algorithm with different hyperparameters a random number of times. They demonstrate that this approach significantly benefits privacy accounting, contrary to the traditional scaling of privacy guarantees with the square root of the number of runs (based on the composition properties from ). While these papers make valuable contributions, their approaches only allow for uniformly random subsampling from a finite and pre-fixed set of candidate hyperparameters at each run. As a result, any advanced technique from HPO literature that requires adaptivity is either prohibited or necessitates a considerable privacy cost (polynomially dependent on the number of runs), creating a substantial gap between non-private and private HPO methods.

Given these considerations, a natural question arises: _Can private hyperparameter optimization be adaptive, without a huge privacy cost?_ In this paper, we provide an affirmative answer to this question.

### Our Contributions

* **We introduce the pioneering adaptive private hyperparameter optimization framework, DP-HyPO,** which enables practitioners to adapt to previous runs and focus on potentially superior hyperparameters. DP-HyPO permits the flexible use of non-DP adaptive hyperparameter optimization methods, such as Gaussian process, for enhanced efficiency, while avoiding the substantial privacy costs due to composition. In contrast to the non-adaptive methods presented in , our adaptive framework, DP-HyPO, effectively bridges the gap between private and non-private hyperparameter optimization. Importantly, our framework not only encompasses the aforementioned non-adaptive methods as special cases, but also seamlessly integrates virtually all conceivable adaptive methods into the framework.

* **We provide sharp DP guarantees for the adaptive private hyperparameter optimization.** Specifically, when the training procedure is executed multiple times, with each iteration being DP on its own, outputting the best repetition is DP ensured by the composition property. However, applying composition results in excessively loose privacy guarantees. Prior work in [24; 32] presents bounds that are either independent of the number of repetitions or depend logarithmically on it. Nevertheless, these results require that the hyperparameter selection for each iteration follows a uniform sampling distribution. In contrast, DP-HyPO allows arbitrary adaptive sampling distributions based on previous runs. Utilizing the Renyi DP framework, we offer a strict generalization of those uniform results by providing an accurate characterization of the Renyi divergence between the adaptive sampling distributions of neighboring datasets, without any stability assumptions.
* **Empirically, we observe that the Gaussian process-based DP-HyPO algorithm outperforms its uniform counterpart across several practical scenarios.** Generally, practitioners can integrate any non-private adaptive HPO methods into the DP-HyPO framework, opening up a vast range of adaptive private HPO algorithm possibilities. Furthermore, DP-HyPO grants practitioners the flexibility to determine the privacy budget allocation for adaptivity, empowering them to balance between the adaptivity and privacy loss when confronting various hyperparameter optimization challenges.

## 2 Preliminaries

### Differential Privacy and Hyperparameter Optimization

Differential Privacy is a mathematically rigorous framework for quantifying privacy leakage. A DP algorithm promises that an adversary with perfect information about the entire private dataset in use - except for a single individual - would find it hard to distinguish between its presence or absence based on the output of the algorithm . Formally, for \(>0\), and \(0<1\), we consider a (randomized) algorithm \(M:^{n}\) that takes as input a dataset.

**Definition 2.1** (Differential privacy).: A randomized algorithm \(M\) is \((,)\)-DP if for any neighboring dataset \(D,D^{}^{n}\) differing by an arbitrary sample, and for any event \(E\), we have

\[[M(D) E]^{}[M (D^{}) E]+.\]

Here, \(\) and \(\) are privacy parameters that characterize the privacy guarantee of algorithm \(M\). One of the fundamental properties of DP is composition. When multiple DP algorithms are sequentially composed, the resulting algorithm remains private. The total privacy cost of the composition scales approximately with the square root of the number of compositions .

We now formalize the problem of hyperparameter optimization with DP guarantees, which builds upon the finite-candidate framework presented in [24; 32]. Specifically, we consider a set of base DP algorithms \(M_{}:^{n}\), where \(\) represents a set of hyperparameters of interest, \(^{n}\) is the domain of datasets, and \(\) denotes the range of the algorithms. This set \(\) may be any infinite set, e.g., the cross product of the learning rate \(\) and clipping norm \(R\) in DP-SGD. We require that the set \(\) is a measure space with an associated measure \(\). Common choices for \(\) include the counting measure or Lebesgue measure. We make a mild assumption that \(()<\).

Based on the previous research , we make two simplifying assumptions. First, we assume that there is a total ordering on the range \(\), which allows us to compare two selected models based on their "performance measure", denoted by \(q\). Second, we assume that, for hyperparameter optimization purposes, we output the trained model, the hyperparameter, and the performance measure. Specifically, for any input dataset \(D\) and hyperparameter \(\), the return value of \(M_{}\) is \((x,q) M_{}(D)\), where \(x\) represents the combination of the model parameters and the hyperparameter \(\), and \(q\) is the (noisy) performance measure of the model.

### Related Work

In this section, we focus on related work concerning private HPO, while deferring the discussion on non-private HPO to Appendix F.

Historically, research in DP machine learning has neglected the privacy cost associated with HPO . It is only recently that researchers have begun to consider the honest HPO setting , in which the cost is taken into account.

A direct approach to addressing this issue involves composition-based analysis. If each training run of a hyperparameter satisfies DP, the entire HPO procedure also complies with DP through composition across all attempted hyperparameter values. However, the challenge with this method is that the privacy guarantee derived from accounting can be excessively loose, scaling polynomially with the number of runs.

Chaudhuri et al.  were the first to enhance the DP bounds for HPO by introducing additional stability assumptions on the learning algorithms.  made significant progress in enhancing DP bounds for HPO without relying on any stability properties of the learning algorithms. They proposed a simple procedure where a hyperparameter was randomly selected from a uniform distribution for each training run. This selection process was repeated a random number of times according to a geometric distribution, and the best model obtained from these runs was outputted. They showed that this procedure satisfied \((3,0)\)-DP as long as each training run of a hyperparameter was \((,0)\)-DP. Building upon this,  extended the procedure to accommodate negative binomial or Poisson distributions for the repeated uniform selection. They also offered more precise Renyi DP guarantees for this extended procedure. Furthermore,  explored a generalization of the procedure for top-\(k\) selection, considering \((,)\)-DP guarantees.

In a related context,  explored a setting that appeared superficially similar to ours, as their title mentioned "adaptivity." However, their primary focus was on improving adaptive optimizers such as DP-Adam, which aimed to reduce the necessity of hyperparameter tuning, rather than the adaptive HPO discussed in this paper. Notably, in terms of privacy accounting, their approach only involved composing the privacy cost of each run without proposing any new method.

Another relevant area of research is DP selection, which encompasses well-known methods such as the exponential mechanism  and the sparse vector technique , along with subsequent studies. However, this line of research always assumes the existence of a low-sensitivity score function for each candidate, which is an unrealistic assumption for hyperparameter optimization.

## 3 DP-HyPO: General Framework for Private Hyperparameter Optimization

The obvious approach to the problem of differentially private hyperparameter optimization would be to run each base algorithm and simply return the best one. However, running such an algorithm on large hyperparameter space is not feasible due to the privacy cost growing linearly in the worst case.

While  have successfully reduced the privacy cost for hyperparameter optimization from linear to constant, there are still two major drawbacks. First, none of the previous methods considers the case when the potential number of hyperparameter candidates is infinite, which is common in most hyperparameter optimization scenarios. In fact, we typically start with a range of hyperparameters that we are interested in, rather than a discrete set of candidates. Furthermore, prior methods are limited to the uniform sampling scheme over the hyperparameter domain \(\). In practice, this setting is unrealistic since we want to "adapt" the selection based on previous results. For instance, one could use Gaussian process to adaptively choose the next hyperparameter for evaluation, based on all the previous outputs. However, no adaptive hyperparameter optimization method has been proposed or analyzed under the DP constraint. In this paper, we bridge this gap by introducing the first DP adaptive hyperparameter optimization framework.

### DP-HyPO Framework

To achieve adaptive hyperparameter optimization with differential privacy, we propose the DP-HyPO framework. Our approach keeps an adaptive sampling distribution \(\) at each iteration that reflects accumulated information.

Let \(Q(D,)\) be the procedure that randomly draws a hyperparameter \(\) from the distribution1\(()\), and then returns the output from \(M_{}(D)\). We allow the sampling distribution to depend on both the dataset and previous outputs, and we denote as \(^{(j)}\) the sampling distribution at the \(j\)-thiteration on dataset \(D\). Similarly, the sampling distribution at the \(j\)-th iteration on the neighborhood dataset \(D^{}\) is denoted as \(^{(j)}\).

We now present the DP-HyPO framework, denoted as \((D,^{(0)},,C,c)\), in Framework 1. The algorithm takes a prior distribution \(^{(0)}()\) as input, which reflects arbitrary prior knowledge about the hyperparameter space. Another input is the distribution \(\) of the total repetitions of training runs. Importantly, we require it to be a random variable rather than a fixed number to preserve privacy. The last two inputs are \(C\) and \(c\), which are upper and lower bounds of the density of any posterior sampling distributions. A finite \(C\) and a positive \(c\) are required to bound the privacy cost of the entire framework.

```
Initialize \(^{(0)}\), a prior distribution over \(\). Initialize the result set \(A=\{\}\) Draw \(T\) for\(j=0\) to \(T-1\)do \((x,q) Q(D,^{(j)})\) \(A=A\{(x,q)\}\) Update \(^{(j+1)}\) based on \(A\) according to any adaptive algorithm such that for all \(\), \[c()}{^{(0)}()} C\] endfor Output \((x,q)\) from \(A\) with the highest \(q\)
```

**Framework 1** DP-HyPO \((D,^{(0)},,C,c)\)

Notice that we intentionally leave the update rule for \(^{(j+1)}\) unspecified in Framework 1 to reflect the fact that any adaptive update rule that leverages information from previous runs can be used. However, for a non-private adaptive HPO update rule, the requirement of bounded adaptive density \(c()}{^{(0)}()} C\) may be easily violated. In Section 3.2, We provide a simple projection technique to privatize any non-private update rules. In Section 4, we provide an instantiation of DP-HyPO using Gaussian process.

We now state our main privacy results for this framework in terms of Renyi Differential Privacy (RDP) . RDP is a privacy measure that is more general than the commonly used \((,)\)-DP and provides tighter privacy bounds for composition. We defer its exact definition to Definition A.2 in the appendix.

We note that different distributions of the number of selections (iterations), \(\), result in very different privacy guarantees. Here, we showcase the key idea for deriving the privacy guarantee of DP-HyPO framework by considering a special case when \(\) follows a truncated negative binomial distribution2\((,)\) (the same assumption as in ). In fact, as we show in the proof of Theorem 1 in Appendix A, the privacy bounds only depend on \(\) directly through its probability generating function, and therefore one can adapt the proof to obtain the corresponding privacy guarantees for other probability families, for example, the Possion distribution considered in . From here and on, unless otherwise specified, we will stick with \(=(,)\) for simplicity. We also assume for simplicity that the prior distribution \(^{(0)}\) is a uniform distribution over \(\). We provide more detailed discussion of handling informed prior other than uniform distribution in Appendix D.

**Theorem 1**.: _Suppose that \(T\) follows truncated negative Binomial distribution \(T(,)\). Let \((-1,)\), \((0,1)\), and \(0<c C\). Suppose for all \(M_{}:^{n}\) over \(\), the base algorithms satisfy \((,)\)-RDP and \((,)\)-RDP for some \(, 0,(1,)\), and \([1,)\). Then the DP-HyPO algorithm \((D,^{(0)},(,),C,c)\) satisfies \((,^{})\)-RDP where_

\[^{}=+(1+)(1-})+(+1+) +}+[T]}{-1}.\]To prove Theorem 1, one of our main technical contributions is Lemma A.4, which quantifies the Renyi divergence of the sampling distribution at each iteration between the neighboring datasets. We then leverage this crucial result and the probability generating function of \(\) to bound the Renyi divergence in the output of \(\). We defer the detailed proof to Appendix A.

Next, we present the case with pure DP guarantees. Recall the fact that \((,0)\)-DP is equivalent to \((,)\)-RDP . When both \(\) and \(\) tend towards infinity, we easily obtain the following theorem in terms of \((,0)\)-DP.

**Theorem 2**.: _Suppose that \(T\) follows truncated negative Binomial distribution \(T(,)\). Let \((-1,)\) and \((0,1)\). If all the base algorithms \(M_{}\) satisfies \((,0)\)-DP then the DP-HyPO algorithm \((D,^{(0)},(,),C,c)\) satisfies \(((2+)(+),0)\)-DP._

Theorem 1 and Theorem 2 provide practitioners the freedom to trade off between allocating more DP budget to enhance the base algorithm or to improve adaptivity. In particular, a higher value of \(\) signifies greater adaptivity, while a larger \(\) improves the performance of base algorithms.

#### 3.1.1 Uniform Optimization Method as a Special Case

We present the uniform hyperparameter optimization method  in Algorithm 2, which is a special case of our general DP-HyPO Framework with \(C=c=1\). Essentially, this algorithm never updates the sampling distribution \(\).

```
Let \(=(\{1,...,||\})\), and \(A=\{\}\)  Draw \(T(,)\) for\(j=0\) to \(T-1\)do \((x,q) Q(D,)\) \(A=A\{(x,q)\}\) endfor  Output \((x,q)\) from \(A\) with the highest \(q\)
```

**Algorithm 2** Uniform Hyperparameter Optimization \((D,,,)\)

Our results in Theorem 1 and Theorem 2 generalize the main technical results of . Specifically, when \(C=c=1\) and \(\) is a finite discrete set, our Theorem 1 precisely recovers Theorem 2 in . Furthermore, when we set \(=1\), the truncated negative binomial distribution reduces to the geometric distribution, and our Theorem 2 recovers Theorem 3.2 in .

### Practical Recipe to Privatize HPO Algorithms

In the DP-HyPO framework, we begin with a prior and adaptively update it based on the accumulated information. However, for privacy purposes, we require the density \(^{(j)}\) to be bounded by some constants \(c\) and \(C\), which is due to the potential privacy leakage when updating \(^{(j)}\) based on the history. It is crucial to note that this distribution \(^{(j)}\) can be significantly different from the distribution \(^{(j)}\) if we were given a different input dataset \(D^{}\). Therefore, we require the probability mass/density function to satisfy \(^{(j)}()\) for all \(\) to control the privacy loss due to adaptivity.

This requirement is not automatically satisfied and typically necessitates modifications to current non-private HPO methods. To address this challenge, we propose a general recipe to modify any non-private method. The idea is quite straightforward: throughout the algorithm, we maintain a non-private version of the distribution density \(^{(j)}\). When sampling from the space \(\), we perform a projection from \(^{(j)}\) to the space consisting of bounded densities. Specifically, we define the space of essentially bounded density functions by \(S_{C,c}=\{f^{^{+}}:f,f,_{}f()=1\}\). For such a space to be non-empty, we require that \(c 1 C,\) where \(\) is the measure on \(\). This condition is well-defined as we assume \(()<\).

To privatize \(^{(j)}\) at the \(j\)-th iteration, we project it into the space \(S_{C,c}\), by solving the following convex functional programming problem:

\[_{f} \ \ \|f-^{(j)}\|_{2},\] (3.1) s.t. \[\ f S_{C,c}.\]

Note that this is a convex program since \(S_{C,c}\) is convex and closed. We denote the output from this optimization problem by \(_{S_{C,c}}(^{(j)})\). Theoretically, problem (3.1) allows the hyperparameter space \(\) to be general measurable space with arbitrary topological structure. However, empirically, practitioners need to discretize \(\) to some extent to make the convex optimization computationally feasible. Compared to the previous work, our formulation provides the most general characterization of the problem and allows pratitioners to _adaptively_ and _iteratively_ choose a proper discretization as needed. Framework 1 tolerates a much finer level of discretization than the previous method, as the performance of latter degrades fast when the number of candidates increases. We also provide examples using CVX to solve this problem in Section 4.2. In Appendix C, we discuss about its practical implementation, and the connection to information projection.

## 4 Application: DP-HyPO with Gaussian Process

In this section, we provide an instantiation of DP-HyPO using Gaussian process (GP) . GPs are popular non-parametric Bayesian models frequently employed for hyperparameter optimization. At the meta-level, GPs are trained to generate surrogate models by establishing a probability distribution over the performance measure \(q\). While traditional GP implementations are not private, we leverage the approach introduced in Section 3.2 to design a private version that adheres to the bounded density contraint.

We provide the algorithmic description in Section 4.1 and the empircal evaluation in Section 4.2.

### Algorithm Description

The following Algorithm (\(\)) is a private version of Gaussian process for hyperparameter tuning. In Algorithm 3, we utilize GP to construct a surrogate model that generates probability distributions for the performance measure \(q\). By estimating the mean and variance, we assign a "score" to each hyperparameter \(\), known as the estimated upper confidence bound (UCB). The weight factor \(\) controls the balance between exploration and exploitation, where larger weights prioritize exploration by assigning higher scores to hyperparameters with greater uncertainty.

To transform these scores into a sampling distribution, we apply the softmax function across all hyperparameters, incorporating the parameter \(\) as the inverse temperature. A higher value of \(\) signifies increased confidence in the learned scores for each hyperparameter.

### Empirical Evaluations

We now evaluate the performance of our GP-based DP-HyPO (referred to as "GP") in various settings. Since DP-HyPO is the first adaptive private hyperparameter optimization method of its kind, we compare it to the special case of Uniform DP-HyPO (Algorithm 2), referred to as "Uniform", as proposed in . In this demonstration, we consider two pragmatic privacy configurations: the white-box setting and the black-box setting, contingent on whether adaptive HPO algorithms incur extra privacy cost. In the white-box scenario (Section 4.2.1 and 4.2.2), we conduct experiments involving training deep learning models on both the MNIST dataset and CIFAR-10 dataset. Conversely, when considering the black-box setting (Section 4.2.3), our attention shifts to a real-world Federated Learning (FL) task from the industry. These scenarios provide meaningful insights into the effectiveness and applicability of our GP-based DP-HyPO approach.

#### 4.2.1 MNIST Simulation

We begin with the white-box scenario, in which the data curator aims to provide overall protection to the published model. In this context, to accommodate adaptive HPO algorithms, it becomes necessary to reduce the budget allocated to the base algorithm.

In this section, we consider the MNIST dataset, where we employ DP-SGD to train a standard CNN. The base algorithms in this case are different DP-SGD models with varying hyperparameters, and we evaluate each base algorithm based on its accuracy. Our objective is to identify the best hyperparameters that produce the most optimal model within a given total privacy budget.

Specifically, we consider two variable hyperparameters: the learning rate \(\) and clipping norm \(R\), while keeping the other parameters fixed. We ensure that both the GP algorithm and the Uniform algorithm operate under the same total privacy budget, guaranteeing a fair comparison.

Due to constraints on computational resources, we conduct a semi-real simulation using the MNIST dataset. For both base algorithms (with different noise multipliers), we cache the mean accuracy of \(5\) independently trained models for each discretized hyperparameter and treat that as a proxy for the "actual accuracy" of the hyperparameter. Each time we sample the accuracy of a hyperparameter, we add a Gaussian noise with a standard deviation of \(0.1\) to the cached mean. We evaluate the performance of the output model based on the "actual accuracy" corresponding to the selected hyperparameter. Further details on the simulation and parameter configuration can be found in Appendix E.1.

In the left panel of Figure 1, we demonstrated the comparison of performance of the Uniform and GP methods with total privacy budget \(=15\)3 and \(=1e-5\). The accuracy reported is the actual accuracy of the output hyperparameter. From the figure, we see that when \(T\) is very small (\(T<8\)), GP method is slightly worse than Uniform method as GP spends \((C/c)\) budget less than Uniform method for each base algorithm (the cost of adaptivity). However, we see that after a short period of exploration, GP consistently outperform Uniform, mostly due to the power of being adaptive. The superiority of GP is further demonstrated in Table 1, aggregating over geometric distribution.

#### 4.2.2 CIFAR-10 Simulation

When examining the results from MNIST, a legitimate critique arises: our DP-Hypo exhibits only marginal superiority over its uniform counterpart, which questions the assertion that adaptivity holds significant value. Our conjecture is that the hyperparameter landscape of MNIST is relatively uncomplicated, which limits the potential benefits of adaptive algorithms.

To test the hypothesis, we conduct experiments on the CIFAR-10 dataset, with a setup closely mirroring the previous experiment: we employ the same CNN model for training, and optimize the same set of hyperparameters, which are the learning rate \(\) and clipping norm \(R\). The primary difference lies in how we generate the hyperparameter landscape. Given that a single run on CIFAR-10 is considerably more time-consuming than on MNIST, conducting multiple runs for every hyperparameter combination is unfeasible. To address this challenge, we leverage BoTorch ,an open-sourced library for HPO, to generate the landscape. Since we operate in the white-box setting, where the base algorithms have distinct privacy budgets for the uniform and adaptive scenarios, we execute 50 runs and generate the landscape for each case, including the mean (\(_{}\)) and standard error (\(_{}\)) of accuracy for each hyperparameter combination \(\). When the algorithm (GP or Uniform) visits a specific \(\), our oracle returns a noisy score \(q()\) drawn from a normal distribution of \(N(_{},_{})\). A more detailed description of our landscapes and parameter configuration can be found in Appendix E.2.

In the middle of Figure 1, we showcase a performance comparison between the Uniform and GP methods with a total privacy budget of \(=12\) and \(=1e-5\). Clearly, GP consistently outperforms the Uniform method, with the largest performance gap occurring when the number of runs is around 10.

#### 4.2.3 Federated Learning

In this section, we move to the black-box setting, where the privacy budget allocated to the base algorithm remains fixed, while we allow extra privacy budget for HPO. That being said, the adaptivity can be achieved without compromising the utility of the base algorithm.

We explore another real-world scenario: a Federated Learning (FL) task conducted on a proprietary dataset 4 from industry. Our aim is to determine the optimal learning rates for the central server (using AdaGrad) and the individual users (using SGD). To simulate this scenario, we once again rely on the landscape generated by BoTorch , as shown in Figure 3 in Appendix E.3.

Under the assumption that base algorithms are black-box models with fixed privacy costs, we proceed with HPO while varying the degree of adaptivity. The experiment results are visualized in the right panel of Figure 1, and Table 2 presents the aggregated performance data.

We consistently observe that GP outperforms Uniform in the black-box setting. Furthermore, our findings suggest that allocating a larger privacy budget to the GP method facilitates the acquisition of adaptive information, resulting in improved performance in HPO. This highlights the flexibility of GP in utilizing privacy resources effectively.

  Geometric(\(\)) & 0.001 & 0.002 & 0.003 & 0.005 & 0.01 & 0.02 & 0.025 & 0.03 \\   GP & 0.946 & 0.948 & 0.948 & 0.947 & 0.943 & 0.937 & 0.934 & 0.932 \\  Uniform & 0.943 & 0.945 & 0.945 & 0.944 & 0.940 & 0.935 & 0.932 & 0.929 \\  

Table 1: Accuracy of MNIST using Geometric Distribution with various different values of \(\) for Uniform and GP methods. Each number is the mean of \(200\) runs.

Figure 1: Left: The accuracy of the output hyperparameter in MNIST semi-real simulation, with \(=15\), \(=0.00001\). Middle: The accuracy of the output hyperparameter in CIFAR-10, with \(=12\), \(=0.00001\). Right: The loss of the output hyperparameter in FL. Error bars stands for \(95\%\) confidence. Curves for GP are calculated by averaging \(400\) independent runs, and curves for Uniform are calculated by averaging \(10000\) independent runs. For a clearer demonstration, we compare the performance for each fixed value of \(T\), and recognize that the actual performance is a weighted average across different values of \(T\).

## 5 Conclusion

In conclusion, this paper presents a novel framework, DP-HyPO. As the first adaptive HPO framework with sharp DP guarantees, DP-HyPO effectively bridges the gap between private and non-private HPO. Our work encompasses the random search method by [24; 32] as a special case, while also granting practitioners the ability to adaptively learn better sampling distributions based on previous runs. Importantly, DP-HyPO enables the conversion of any non-private adaptive HPO algorithm into a private one. Our framework proves to be a powerful tool for professionals seeking optimal model performance and robust DP guarantees.

The DP-HyPO framework presents two interesting future directions. One prospect involves an alternative HPO specification which is practically more favorable. Considering the extensive literature on HPO, there is a significant potential to improve the empirical performance by leveraging more advanced HPO methods. Secondly, there is an interest in establishing a theoretical utility guarantee for DP-HyPO. By leveraging similar proof methodologies to those in Theorem 3.3 in , it is feasible to provide basic utility guarantees for the general DP-HyPO, or for some specific configurations within DP-HyPO.

## 6 Acknowledgements

The authors would like to thank Max Balandat for his thoughtful comments and insights that helped us improve the paper.