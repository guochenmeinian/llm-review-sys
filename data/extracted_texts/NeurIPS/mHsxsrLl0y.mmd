# Theoretically Guaranteed Bidirectional Data Rectification for Robust Sequential Recommendation

Yatong Sun\({}^{1,2}\), Xiaochun Yang\({}^{1}\), Zhu Sun\({}^{3*}\), Bin Wang\({}^{1}\), Yan Wang\({}^{2}\)

\({}^{1}\)School of Computer Science and Engineering, Northeastern University, China

\({}^{2}\)School of Computing, Macquarie University, Australia

\({}^{3}\)Center for Frontier AI Research, Institute of High Performance Computing, A*STAR, Singapore

yatong@stumail.neu.edu.cn, yangxc@mail.neu.edu.cn, sunzhuntu@gmail.com, binwang@mail.neu.edu.cn, yan.wang@mq.edu.au

denotes the corresponding authors

###### Abstract

Sequential recommender systems (SRSs) are typically trained to predict the next item as the _target_ given its preceding (and succeeding) items as the _input_. Such a paradigm assumes that every input-target pair is reliable for training. However, users can be induced to click on items that are inconsistent with their true preferences, resulting in unreliable instances, i.e., mismatched input-target pairs. Current studies on mitigating this issue suffer from two limitations: (i) they discriminate instance reliability according to models trained with unreliable data, yet without theoretical guarantees that such a seemingly contradictory solution can be effective; and (ii) most methods can only tackle either unreliable input or targets but fail to handle both simultaneously. To fill the gap, we theoretically unveil the relationship between SRS predictions and instance reliability, whereby two error-bounded strategies are proposed to rectify unreliable targets and input, respectively. On this basis, we devise a model-agnostic **B**idirectional **D**ata **R**ectification (**B**irD**Rec**) framework, which can be flexibly implemented with most existing SRSs for robust training against unreliable data. Additionally, a rectification sampling strategy is devised and a self-ensemble mechanism is adopted to reduce the (time and space) complexity of BirDRec. Extensive experiments on four real-world datasets verify the generality, effectiveness, and efficiency of our proposed BirDRec.

## 1 Introduction

Recently, the study on sequential recommender systems (SRSs) [1; 2; 3; 4; 5] has garnered much attention as users' preferences are inherently dynamic and evolving in real-world scenarios. The goal of SRSs is learning to predict the next item a user interacts with given the preceding (and succeeding) items. Therefore, a training instance for SRSs is typically composed of an _input_ item sequence and its next item as the _target_. However, distractions in daily lives (e.g. recommendations from friends, account sharing, and accidental clicks) can induce users to click on items that are inconsistent with their true preferences, resulting in unreliable training instances with mismatched input-target pairs. The mismatch can be categorized into _Complete Mismatch_ and _Partial Mismatch_ when the item caused by distractions acts as an unreliable target and unreliable input of an instance, respectively. To illustrate, the romantic film 'La La Land', in the first instance of Figure 1, serves as an unreliable target, which is recommended by friends and completely mismatched with the previous superhero movies. By contrast, in the second instance, 'La La Land' acts as an unreliable input item which renders the input sequence partially mismatched with the target superhero film. Bothtypes of mismatch would cause unreliable training instances that mislead SRSs to learn sequential relationships between irrelevant items and eventually undermine the recommendation accuracy.

Although there are a number of studies aiming to combat such unreliable data for more robust SRSs, they suffer from two core limitations. (i) They discriminate instance reliability based on the intermediate or final output of a model (either the SRS itself [6; 7; 8; 9] or an additional corrector ) that is trained with unreliable data. However, there is no theoretical guarantee that such seemingly contradictory solutions can be trustworthy for detecting and correcting unreliable instances. (ii) Most prior studies only focus on tackling either unreliable input [6; 7; 11; 12; 13] or targets , but fail to handle both simultaneously. Only one recently proposed method  attempts to address this issue, but it relies on a corrector trained with unreliable data, yet without any theoretical guarantees.

As such, we, _for the first time_, theoretically unveil the relationship between the SRS predictions and instance reliability, proving that a target with consistently low prediction scores is unlikely to be reliable, assuming that the randomness of user behavior is limited. It then inspires us to devise two error-bounded rectification strategies to (1) detect consistently low-scored targets (i.e., unreliable targets) and replace them with steadily high-scored items and (2) detect and delete consistently low-scored items within the input (i.e., unreliable input), where the score is estimated by a backward SRS. Note that the unreliable input items, as the interruptions in the input, are not replaced but directly removed to bridge the preceding and succeeding items. Based on these strategies, we propose a model-agnostic **B**idirectional **D**ata **R**ectification (**BirDRec**) framework which contains two SRSs in opposite directions for tackling both unreliable targets and input. In addition, to reduce the time complexity, a rectification sampling strategy is devised to efficiently obtain consistently high-scored items; to reduce space complexity, a self-ensemble mechanism  is adopted to approximate the weighted average prediction scores across different training epochs.

**Contributions. (1)** We are the first to provide theoretically guaranteed data rectification strategies based on SRS predictions to tackle both unreliable input and targets for more robust SRSs. **(2)** We devise a model-agnostic bidirectional data rectification framework that can be flexibly implemented with most existing SRSs for robust training against unreliable data. **(3)** We devise a rectification sampling strategy and adopt a self-ensemble mechanism to ensure better scalability of BirDRec. **(4)** Extensive experiments with SRSs based on representative backbones and datasets across various domains validate the generality, effectiveness, and efficiency of BirDRec.

## 2 Related Works

Early SRSs [15; 16] adopt Markov Chains to encode users' interaction sequences, assuming users' latest interactions affect the future behavior linearly and independently. Later, powerful deep learning backbones such as recurrent neural networks (RNNs) [17; 18; 19], convolution neural networks (CNNs) [20; 21; 22], graph neural networks (GNNs) [23; 24; 25; 26; 27], and Transformers [28; 29] are employed to extract complex non-linear patterns within users' sequences . They posit each training instance is a definitely matched input-target pair and thus cannot handle unreliable data.

To resist unreliable data, existing robust SRSs can be categorized into three types. The _first type_ focuses on handling the complete mismatch by identifying and eliminating instances with unreliable targets. For example, BERD  empirically finds that instances with high training loss and low uncertainty tend to have unreliable targets. This idea is relevant to studies on clean label selection [31; 32; 33; 34; 35] and label correction [36; 37; 38]. The _second type_ concentrates on addressing partial mismatch by reducing the importance of unreliable input when formulating users' dynamic preference representations. Accordingly, various advanced mechanisms are integrated into SRSs, such as memory networks , gating networks [39; 40; 41], autoencoders , reinforcement learning ,

Figure 1: Examples of two types of mismatch caused by external distractions.

uncertainty modelling [11; 42], and Fast Fourier Transform . To the best of our knowledge, there is only one recently proposed method STEAM  falling into the _third type_ which attempts to tackle both unreliable targets and input with an additional corrector producing reliable data. Nonetheless, existing robust SRSs all rely on models (either SRSs or additional correctors) trained with unreliable data, yet without theoretical proof that such seemingly contradictory solutions can be effective.

## 3 Theoretical Guarantees for Rectifying Unreliable Data

This section presents theoretical guarantees for rectifying unreliable data via SRS predictions for more robust SRSs. In particular, Section 3.1 introduces important preliminaries. Subsequently, Section 3.2 unveils the relationship between the prediction score of SRSs and the reliability of a target, inspiring us to propose an error-bounded strategy for handling unreliable targets; and Section 3.3 provides the error-bounded strategy for dealing with unreliable input.

### Preliminaries

**Problem Statement of SRSs**. Let \(\) and \(\) be the sets of users and items, respectively. Each user \(u\) chronologically interacts with a sequence of items \(^{u}=[_{1}^{u},_{2}^{u},...,_{ ^{u}}^{u}]\), where \(_{t}^{u}\) is the \(t\)-th item user \(u\) interacts with and \(|^{u}|\) is the length of sequence \(^{u}\). The goal of SRSs is to predict the target item \(_{t}^{u}\) given the input \(}_{t}^{u}=\{u,[_{t-L}^{u},...,_{t-2} ^{u},_{t-1}^{u}]\}\), where \(L\) is the length of \(}_{t}^{u}\). Thus, the training instance of SRSs can be represented as an input-target pair \((}_{t}^{u},_{t}^{u})\). Note that we use '-' to denote the observed data that may be unreliable due to external distractions.

**Core Assumptions**. Ideally, each user-item interaction should be drawn from users' true preference distribution \(\) without any distractions, where \(_{v_{i}}(_{t}^{u})=(v_{t}^{u}=v_{i}|_{t}^{u})\). We define \(p_{1}\) to be the true item for recommendation, i.e, the top-\(1\) item according to \(\),

\[_{v_{i}}[_{p_{1}}(_{t}^{u} )_{v_{i}}(_{t}^{u})]=||,\] (1)

where \([]\) is an indicator function that equals \(1\) if the condition is true; otherwise 0. Meanwhile, we define \(p_{2}\) to be the middle-ranked item (ranked \(||/2\)-th) according to \(\), namely,

\[_{v_{i}}[_{p_{2}}(_{t}^{u })_{v_{i}}(_{t}^{u})]=||/2.\] (2)

In general, SRSs are built upon the hypothesis that users usually select items with a tendency rather than randomly. In other words, the randomness of users' true preferences is restricted, i.e., the probability gap between the top-\(1\) and middle-ranked items regarding \(\) is unlikely to be small. This assumption can be formally defined as follows.

**Assumption 1**.: _The users' true preference distribution \(\) fulfills the relaxed Multiclass Tsybakov Condition  with constants \(C>0\), \(>0\), and \(_{0}(0,1]\), such that for all \((0,_{0}]\),_

\[_{p_{1}}(_{t}^{u})-_{p_{2}}(_{t} ^{u}) C^{}.\] (3)

The feasibility of Assumption 1 relies on small \(C\) and large \(\), which are satisfied on public (observed) datasets based on our empirical analysis in the Appendix with \(C(0.55,0.70)\) and \((1.37,4.01)\).

**Connecting \(\) with SRS Predictions**. Obviously, \(\) is the ideal corrector to rectify unreliable data, however, due to its unavailability, many existing methods [8; 10] leverage SRS predictions as the substitution with no theoretical guarantees. This urges us to explore the connection between \(\) and SRS predictions. To achieve this goal, we first investigate the relationship between \(\) and users' observed preference distribution \(\), since SRSs are trained with the observed data that may be distorted by external distractions. Formally, \(_{v_{i}}(}_{t}^{u})=(_{t}^{u}= v_{i}|}_{t}^{u})\), where \(_{t}^{u}\) is the observed target that may be unreliable. We then define a transition probability \(_{v_{i}v_{i}}(}_{t}^{u})=(_{t}^{u}=v_ {i}|v_{t}^{u}=v_{j},}_{t}^{u})\) as the chance that a true target \(v_{t}^{u}\) is flipped from item \(v_{j}\) to item \(v_{i}\) owing to external distractions. Thus, for any pair \((v_{i},v_{j})\), there is a linear relationship between \(\) and \(\):

\[_{v_{i}}(}_{t}^{u})=_{v_{j} }(_{t}^{u}=v_{i}|v_{t}^{u}=v_{j},}_{t}^{u})(v_{t}^{u}=v_{j}|}_{t}^{u})= _{v_{j}}_{v_{j}v_{i}}(}_{t}^{u}) _{v_{j}}(}_{t}^{u}).\] (4)

To bridge \(\) and SRS predictions via \(\), we then study the relationship between \(\) and SRS predictions. Let \(f^{h}\) be an SRS at the \(h\)-th training epoch, and the prediction of \(f^{h}\) be \(\)-close to \(\),

\[=_{}_{t}^{h},v_{i}}|_{v_{i}}(}_{t}^{u})-f_{v_{i}}^{h}(}_{t}^{u})|,\] (5)where \(f_{v}^{h}(}_{t}^{u})\) is the predicted probability (score) of the target being \(v_{i}\) given the input \(}_{t}^{u}\) at the \(h\)-th training epoch. Eqs. (4-5) indicate that there is indeed a connection between \(\) and SRS predictions, laying the foundation for the proposed strategies to rectify unreliable data as what follows.

### Theorems for Rectifying Unreliable Targets

We now explore how to properly use SRS predictions for rectifying unreliable targets. Prior works empirically find that unreliable targets tend to possess consistently low prediction scores at different epochs . Yet, there is no guarantee that such prediction scores given by an SRS trained with unreliable data can be trustworthy for detecting unreliable targets. This prompts us to theoretically unveil the relationship between target reliability and SRS predictions at different epochs. Specifically, Theorem 1 proves that a reliable target is unlikely to keep low prediction scores during training.

**Theorem 1**.: _Given Assumption 1, let \(\{w_{h} 1 h H,0 w_{h} 1,_{h=1}^{H}w_{h}=1\}\) be the weights1 for averaging prediction scores of different epochs. \(\{}_{t}^{u},_{t}^{u}\}\), assume \(_{_{t}^{u}_{t}^{u}}(}_ {t}^{u})\). Let \(=_{_{t}^{u}_{t}^{u}}(}_{t}^{u}) _{p_{2}}(}_{t}^{u})+_{v_{j}_{t}^{u}} _{v_{j}_{t}^{u}}(}_{t}^{u})_{v_{j}}(}_{t}^{u})\). We have: \(p_{1}=_{t}^{u};_{h=1}^{H}[w_{h}f_{_ {t}^{u}}^{h}(}_{t}^{u})] C( ())^{}\)._

Proof.: \[p_{1}=_{t}^{u},_{h=1}^{H}[w_{h }f_{_{t}^{u}}^{h}(}_{t}^{u})]\] \[ p_{1}=_{t}^{u},_{h=1}^{H}w_{h} _{_{t}^{u}}(}_{t}^{u})- \] \[= p_{1}=_{t}^{u},_{_{t}^{u} }(}_{t}^{u})_{p_{2}}(}_{t}^{u}), _{h=1}^{H}w_{h}_{v_{j}}_{v_{j}_{t}^{ u}}_{v_{j}}(}_{t}^{u})-\] (6) \[ p_{1}=_{t}^{u},_{v_{1}^{u}}( }_{t}^{u})_{p_{2}}(}_{t}^{u}), _{_{t}^{u}_{t}^{u}}(}_{t}^{u})_{v_{j} }(}_{t}^{u})_{v_{j}}(}_{t}^{u}) +\] \[= p_{1}=_{t}^{u},_{p_{2}}(}_{t}^{u})_{v_{1}^{u}}(}_{t}^{u}) {+-_{v_{j}_{t}^{u}}_{v_{j}_{t}^{u} }(}_{t}^{u})_{v_{j}}(}_{t}^{u})}{_{ v_{k}^{u}_{t}^{u}}(}_{t}^{u})}.\]

By replacing \(\) with \(_{_{t}^{u}_{t}^{u}}(}_{t}^{u})_{p_{ 2}}(}_{t}^{u})+_{v_{j}_{t}^{u}}_{v_{j} _{j}_{t}^{u}}(}_{t}^{u})_{v_{j}}( }_{t}^{u})\), we obtain:

\[p_{1}=_{t}^{u},_{h=1}^{H}[w_{h}f_{_{t}^{u}}^{h}(}_{t}^{u})] _{p_{2}}(}_{t}^{u})_{p_{1}}( }_{t}^{u})_{p_{2}}(}_{t}^{u})+ _{t}^{u}_{t}^{u}}(}_{t }^{u})}.\] (7)

Recall that \(_{_{t}_{t}^{u}}(}_{t}^{u})\), which indicates \(_{t}^{u}_{t}^{u}}(}_{t }^{u})}_{0}\). Hence, the relaxed Multiclass Tsybakov Condition holds and the probability is bounded by \(C_{t}^{u}_{t}^{u}}(}_{t}^{u})}^{}\), namely, \(C()^{}\). 

Note that a small \(\) relies on large observed data and a powerful \(f\), so that (i) the observed data can accurately approximate \(\), and (ii) \(f\) can closely fit the observed data. Both requirements can be satisfied thanks to the large-scale datasets and deep learning advancements in recommendation.

Theorem 1 indicates that the probability of a reliable target (\(p_{1}=_{t}^{u}\)) keeping low prediction scores across different epochs (\(_{h=1}^{H}[w_{h}f_{_{t}^{u}}^{h}(}_{t}^{u}) ]\)) is bounded to be low, i.e., no more than \(C()^{}\). This inspires us to rectify unreliable targets by replacing consistently low-scored targets with steadily high-scored items as the following strategy.

**DRUT: Detecting and Replacing Unreliable Targets**. Given an SRS \(f\) that is \(\)-close to \(\), an instance \(}_{t}^{u},_{t}^{u}\), the consistently high-scored item \(v_{m}=_{v_{i}_{t}^{u}}_{h=1}^{H}[w_{h}f_{v_{i}}^{h}( }_{t}^{u})]\), and \((0,1]\), we stipulate that if \(_{h=1}^{H}[w_{h}f_{_{t}^{u}}^{h}(}_{t}^{u}) ]/_{h=1}^{H}[w_{h}f_{v_{m}}^{h}(}_{t}^{u}) ]<\), i.e., the target \(_{t}^{u}\) is consistently lower-scored than \(v_{m}\) to some extent, then \(_{t}^{u}\) should be replaced by \(v_{m}\) in the \(H\)-th epoch. We denote the output instance of DRUT as \(}_{t}^{u},_{t}^{u}\).

Different from existing methods, DRUT is theoretically error-bounded. Specifically, the error of DRUT, denoted as \(_{}\), comes from three cases: (**Case-1**) the true target \(p_{1}\) is \(_{t}^{u}\) but is replaced

[MISSING_PAGE_EMPTY:5]

**Theorem 3** (The Upper Bound of \(_{}\)).: _Given Assumption 1 and the set of weights \(\{w_{h}\ |\ 1 h H,0 w_{h} 1,_{h=1}^{H}w_{h}=1\}\), \(\ }_{t}^{u},}_{t-t}^{u}\), let \(_{1}^{}=[}_{t-1}}^{}(}_{t}^{u}-(}_{t}^{u})_{}_{t}^{ }}^{}(}_{t}^{u})+_{v_{j} v_{l-1}^{}} _{v_{j}}^{}}_{t-t}^{u}_{v_{j}}^{}(}_{t}^{u})}{_{h=1}^{H}[w_{h}}_{t}^{u}(}_{t}^{u})]}]\), \(_{2}^{}=[^{H}[w_{h}}_{t-1}^{h}( _{t}^{u})]}{_{}_{t}m_{}}}^{ }(}_{t}^{u})_{}_{t}^{}}^{}(}_{t}^{u})}]\), \(_{1}^{}=|^{}-_{1}^{}|\), \(_{2}^{}=|^{}-_{2}^{}|\). Assume \(_{2}^{}<_{2}^{}\), \(^{}[_{}_{t-1}^{} }_{t}^{u}}-}_{t}^{},_{}_{t}^{u}}-}_{t}^{}]\), \(}_{t}^{u}}}{_{2}^{}(}_{t}^{u})^{2}(}_{t}^{u})^{2}-_{2}^{} }{_{2}^{}(}_{t}^{u})^{2}(}_{t}^{u})^ {2}-_{2}^{}}[_{v_{1}^{}}_{t}^{u}}^{}(}_{t}^{u})-_{v_{1}^{}}_{m}}^{}(}_{t}^{u})][_{0}+_{p_{2}^{ }}^{}(}_{t}^{u})]-_{v_{j} p_{1}^{}}[ _{v_{j}}_{m}}^{}(}_{t}^{u})-_{v_{j }}_{t}^{}}^{}(}_{t}^{u})]_{v_{j} }^{}(}_{t}^{u})\). We have: \(_{} C(^{}+_{1}^{ })^{}+C(^{}+_{2}^{ })^{}+C(^{})^{ }\)._

## 4 The Proposed BirDRec Framework

By integrating DRUT and DDUI into existing SRSs, we introduce BirDRec, a model-agnostic bidirectional data rectification framework, which can rectify both unreliable targets and input with theoretical guarantees for more robust SRSs. Yet, the complexity of BirDRec is prohibitively high due to the calculation and storage of prediction scores for each instance across different epochs in DRUT and DDUI. To ease this issue, we devise a rectification sampling strategy that avoids prediction on the full item set to replace unreliable targets or delete unreliable input, thereby reducing the time complexity of BirDRec. Meanwhile, we adopt the self-ensemble mechanism  to approximate the weighted average prediction scores of different epochs, thus avoiding preserving scores of all epochs and reducing the space complexity.

**Framework Overview**. Accordingly, the efficiency-improved BirDRec is depicted in Fig. 2. Specifically, BirDRec first leverages the self-ensembled forward SRS to rectify the target of an instance via DRUT, and then the input is rectified by the self-ensembled backward SRS via DDUI. Thereafter, the rectified instance and its \(L\) backward instances are respectively used to train the forward and backward SRSs, which are finally employed to update the corresponding self-ensembled SRSs.

### Reducing Time Complexity via Rectification Sampling

The time complexity of BirDRec is primarily attributed to the search for consistently high-scored items (\(v_{m}\) and \(_{m}\)), which requires the calculation of prediction scores between every instance and all items. Concretely, the per-epoch time complexity of BirDRec is \(N(||+L)\), where \(N\) denotes the number of instances. To mitigate this substantial computational burden, we propose a rectification sampling strategy that circumvents the need to search the entire item set.

**Rectification Sampling**. Each instance \(}_{t}^{u},_{t}^{u}\) is assigned two rectification pools \(_{t}^{u}\) and \(}_{t}^{u}\) to rectify the target and input, respectively. At first, \(_{t}^{u}\) is initialized by the \(K\) succeeding items of \(_{t}^{u}\), i.e., \([_{t+1}^{u},...,_{t+K}^{u}]\), which are potentially better substitutions for \(_{t}^{u}\). Similarly, \(}_{t}^{u}\) is initialized with the \(K\) preceding items of \(_{t-1}^{u}\). Next, in each epoch, the items in \(_{t}^{u}\), together with \(K\) additional items that are randomly sampled from \(\), are ranked in descending order w.r.t. their weighted average prediction scores over different epochs (i.e., \(_{h=1}^{H}[w_{h}f_{v,i}^{h}(}_{t}^{u})]\)). Then the top-\(1\) item, denoted as \(_{m}\), is adopted as the approximation of \(v_{m}\) in DRUT, while the top-\(K\) items are retained to update \(_{t}^{u}\) for the next epoch. The rationale behind approximating \(v_{m}\) with \(_{m}\) is supported by Theorem 4, which indicates that the relative rank of an item over a list of randomly sampled items can approximate this item's relative rank over the full item set. That is, the top-\(1\) item \(_{m}\) tends to be ranked highly over

Figure 2: The overall architecture of the proposed BirDRec framework.

\(\). The updating rules of \(^{u}_{t}\) for DDUI is defined similarly as \(^{u}_{t}\). As a result, the per-epoch time complexity of BirDRec is reduced from \(N(||+L)\) to \(N(K+L)\).

**Theorem 4**.: _Let \(\) be a list of \(K\) items randomly sampled from \(\) with replacement, \((0,1)\), \(r_{H}(^{u}_{t},v_{i})=_{v_{j}} _{h=1}^{h}[w_{h}f^{h}_{v_{j}}(^{u}_{t})]\) be the rank of item \(v_{i}\) over the entire item set at the \(H\)-th epoch, and \(_{H}(^{u}_{t},v_{i})=_{v_{j}} _{h=1}^{h}[w_{h}f^{h}_{v_{j}}(^{u}_{t})]>_{h=1}^{H}[w_{h}f^{ h}_{v_{i}}(^{u}_{t})]\) be the rank of \(v_{i}\) over \(\) at the \(H\)-th epoch. We have: \([_{H}(^{u}_{t},v_{i})}{K}-( ^{u}_{t},v_{i})}{||}|](-2K^{2})\)._

### Reducing Space Complexity via Self-ensemble Mechanism

The huge space cost of BirDRec is caused by the storage of prediction scores between each instance and all items in every epoch, for the sake of calculating the weighted average prediction scores.

Specifically, at the \(H\)-th epoch, the space complexity of preserving all prediction scores is \((N|| H)\). To save space, we thus approximate the weighted average scores with the self-ensemble mechanism , thereby avoiding storing prediction scores of different epochs. Formally, let \(f^{H}\) be an SRS parameterized by \(_{H}\), and \(^{H}\) be a self-ensembled SRS parameterized by \(}_{H}=_{h=1}^{H}w_{h}_{h}\). It has proven that  the difference between the weighted average prediction scores (\(_{h=1}^{H}w_{h}f^{h}_{v_{i}}(^{u}_{t})\)) and the prediction of the self-ensembled SRS (\(^{H}_{v_{i}}(^{u}_{t})\)) is of the second order of smallness, if and only if \(w_{h}=^{H-h}(1-)^{1-(h-1)}\), where \((0,1)\) denotes the exponential decay rate for ensembling; and \(()\) is the unit impulse function, i.e., \((0)=1\), otherwise \(0\). With such self-ensemble, there is no need to store SRSs of each epoch, as \(}_{H}\) can be efficiently derived from \(}_{H-1}\) and \(_{H}\) with the exponential moving average as follows:

\[}_{H}=_{h=1}^{H}^{H-h}(1-)^ {1-(h-1)}_{h}=}_{H -1}+(1-)_{H}.\] (9)

By doing so, the burden of retaining prediction scores of different epochs is reduced to maintaining an extra self-ensembled SRS. As the parameters of an SRS mainly consist of the user and item embeddings, the per-epoch space complexity of BirDRec is reduced from \((||+||) d+(L+|| H ) N\) to \((||+||) d+(L+K) N\), where \(d\) represents the embedding size. Furthermore, to reduce the number of parameters and mitigate overfitting, the (self-ensembled) forward and backward SRSs in BirDRec share the same user and item embeddings.

## 5 Experiments and Results

### Experimental Settings

**Datasets.** We adopt four real-world datasets with varying domains, sizes, sparsity, and average sequence lengths shown in Table 1. Specifically, ML-1M (ML) is a popular movie recommendation benchmark. Beauty (Be)  is the product review dataset collected from Amazon.com. Yelp (Ye)  is a business recommendation dataset released by Yelp.com. QK-Video (QK)  is a video recommendation dataset crawled from Tencent.com. Following [3; 8; 9], we preprocess all datasets by removing users and items whose interactions are less than 5.

**Baselines.** To verify the generality of BirDRec, we implement it with _vanilla SRSs_ based on representative backbones. In particular, FPMC is based on Markov Chain. GRU4Rec, Caser, and MAGNN are built on RNN, CNN, and GNN, respectively. SASRec and BERT4Rec are based on Transformer. Meanwhile, to validate its effectiveness and efficiency, we compare BirDRec with state-of-the-art _robust SRSs_ including BERD, FMLP-Rec, and STEAM, which aim to tackle unreliable targets, unreliable input, and both, respectively.

**Evaluation Protocol.** Following [9; 48; 49], three widely-used metrics are adopted to evaluate the ranking quality, namely, HR, NDCG, and MRR. For all these metrics, higher metric values suggest

  
**Dataset** & \# Users & \# Items & \# Interactions & Avg. Length & Sparsity \\  ML-1M (ML) & 6,040 & 3,417 & 999,611 & 165.5 & 95.16\% \\ Beauty (Be) & 22,362 & 12,102 & 198,502 & 8.9 & 99.93\% \\ Yelp (Ye) & 22,844 & 16,552 & 236,999 & 10.4 & 99.94\% \\ QK-VoidQK (QK) & 30,704 & 41,534 & 2,268,935 & 73.9 & 99.82\% \\   

Table 1: Statistics of the datasets.

[MISSING_PAGE_FAIL:8]

BirDRec framework. We can note that all the baselines are boosted significantly on all datasets with the aid of BirDRec, which demonstrates the _generality_ of BirDRec.

Table 3 compares BirDRec with state-of-the-art robust SRSs. Considering BERD and STEAM are both built upon Transformer, we also adopt a transformer-based SRS, SASRec, as the default backbone of BirDRec in the following experiments to ensure fair comparisons. The results show that BirDRec dramatically outperforms existing robust SRSs, confirming the _effectiveness_ of our error-bounded rectification strategies in comparison to existing methods that lack theoretical guarantees.

Fig. 3 compares the time and storage cost of BirDRec and STEAM, both of which aim to handle unreliable input and targets simultaneously. In particular, Figs. 3(a) and (b) show that BirDRec executes \(4.28\) times faster than STEAM in each epoch and converges with fewer epochs. Meanwhile, Figs. 3(c) and (d) show that BirDRec incurs only half the storage cost of STEAM on most datasets. These results highlight the _efficiency_ of our sampling strategy and the self-ensemble mechanism. The storage cost of BirDRec is marginally higher than STEAM's on ML-1M. This is because the advantage of our rectification sampling strategy is less obvious on datasets with small item sets (see Table 1), indicating the superior scalability of our BirDRec on large-scale item sets.

**Ablation Study**. To check the efficacy of essential strategies of BirDRec (DRUT, DDUI, and the self-ensemble), we add these strategies incrementally to a plain representative SRS - SASRec. Note that without self-ensemble, DRUT and DDUI only consider the prediction scores at the latest epoch for data rectification. The results are presented in Fig. 4 and similar trends can be noted with the rest SRSs on the other metrics. First, adding either DRUT or DDUI to SASRec brings dramatic improvements, implying the effectiveness of DRUT and DDUI in rectifying unreliable targets and input, respectively. Second, using DRUT and DDUI together is better than leveraging each of them solely, indicating the necessity of rectifying both unreliable targets and input for more robust SRSs. Moreover, adding the self-ensemble mechanism can further boost the accuracy, which confirms the efficacy of considering prediction scores of different epochs for data rectification. Overall, the performance gain of separately adding DRUT, DDUI, and self-ensemble is \(45.7\%\), \(43.3\%\), and \(3.1\%\), respectively. That is, DRUT and DDUI contribute more than the self-ensemble to our BirDRec.

**Hyper-parameter Analysis.** We analyze the impact of key hyper-parameters, i.e., the rectification thresholds \(\), \(^{}\), the size \(K\) of the rectification pool, and the exponential decay rate \(\). The results are presented in Fig. 5 with several major findings (similar trends can be noted with the other metrics on the rest datasets). (i) The best choice for \(\) and \(^{}\) is \(0.1\), showing that small thresholds tend to maintain unreliable instances while large ones may mistakenly rectify reliable data. (ii) \(K 10\) is sufficient to gain better accuracy. (iii) \( 0.5\) yields better performance, that is, it is beneficial to consider predictions in earlier epochs. (iv) Even if the hyper-parameters of BirDRec are not optimally set, BirDRec still dramatically outperforms the best baseline (BERD) on ML-1M.

   Datasets &  \\  Metrics & HR@5 & HR@10 & NDCG@5 & NDCG@10 & MRR & HR@5 & HR@10 & NDCG@5 & NDCG@10 & MRR \\  BERD & 0.1922* & 0.2814* & 0.1267* & 0.1554* & 0.1335* & 0.0507* & 0.0745 & 0.0332 & 0.0406 & 0.0364 \\ FGMLP-Rec & 0.1789 & 0.2685 & 0.1207 & 0.1492 & 0.1299 & 0.0501 & 0.0743 & 0.0384* & 0.0448* & 0.0404* \\ STEAM & 0.1198 & 0.1950 & 0.0765 & 0.1006 & 0.0874 & 0.0495 & 0.0765* & 0.0324 & 0.0414 & 0.0371 \\ BiDRec & **2.3259** & **0.1631** & **0.1915** & **0.1647** & **0.0653** & **0.0903** & **0.0459** & **0.0537** & **0.0822** \\ _Improv._ & 22.379 & 15.815 & 28.737 & 23.232 & 23.373 & 30.347 & 18.044 & 19.535 & 19.878 & 19.31\% \\   Datasets &  \\  BERD & 0.0423 & 0.0636 & 0.0304 & 0.0360 & 0.0351 & 0.0548 & 0.0958 & 0.0352 & 0.0496 & 0.0461 \\ FGMLP-Rec & 0.0489 & 0.0702 & 0.0374 & 0.0433 & 0.0422 & 0.0604* & 0.0991 & 0.0951 & 0.0481* & 0.0480* \\ STEAM & 0.0556* & 0.0822* & 0.0387* & 0.0473* & 0.0448* & 0.0597 & 0.1021* & 0.0371 & 0.0507 & 0.0465 \\ BirDRec & **0.0771** & **0.0965** & **0.0626** & **0.0687** & **0.0663** & **0.0815** & **0.1306** & **0.0523** & **0.0882** & **0.0616** \\ _Improv._ & 38.675 & 17.400 & 61.76 & 45.246 & 47.99 & 34.93\% & 27.91\% & 33.76\% & 32.68\% & 28.33\% \\   

Table 3: Performance comparison with existing robust SRSs, where the best performance is boldfaced and the runner up is marked by ‘\(*\)’. _Improv._ means the relative improvement of BirDRec over the runner up. The significance of the improvement is determined by a paired t-test with \(p 0.001\).

Figure 4: Ablation study on different variants of BirDRec.

**Case Study.** Fig. 6 presents a real instance that is rectified by BirDRec on ML-1M. Specifically, in the DRUT module, the target movie 'Schindler's List' consistently gets lower scores than the movie 'Terminator 2' in the rectification pool, and is then replaced by 'Terminator 2'. This is reasonable, given that 'Terminator 2' aligns more closely with the input Sci-fi movies than 'Schindler's List'. Subsequently, in the DDUI module, the input movie 'American Beauty' is consistently lower-scored than the movie 'Star Wars IV' in the rectification pool and is thus deleted. This decision is justifiable, considering that the rectified target, 'Terminator 2', generally lacks relevance to the input 'American Beauty' across various aspects, including genres, actors, directors, tags, etc.

**Limitations of BirDRec.** Although BirDRec exhibits its superiority through our extensive experiments, its limitations are two-fold. Firstly, the improvement of BirDRec on storage cost is limited for smaller item sets. This is primarily because the rectification sampling strategy with self-ensemble has less apparent advantages on datasets with smaller item sets. To be specific, the storage cost reduction for calculating weighted average prediction scores is from \(O(|V|*H)\) to \(O(K)\) for each instance. Thus if \(|V|\) is small, the benefit of this reduction will be less obvious. Secondly, although BirDRec is significantly faster than the latest robust SRS (STEAM), it is worth noting that BirDRec is 1.6 times on average slower than its backbone model (as depicted in Fig. 3) in each training epoch. This increased training time could be a practical concern in systems with extremely large-scale datasets and real-time recommendation demands.

## 6 Conclusion

This work, _for the first time_, provides theoretically guaranteed data rectification strategies to tackle both unreliable input and targets for more robust SRSs. The proposed strategies are further integrated into a model-agnostic bidirectional data rectification framework, BirDRec, that can be flexibly implemented with most existing SRSs, for robust training against unreliable data. Additionally, we devise a rectification sampling strategy to reduce the computational cost of BirDRec; meanwhile, a self-ensemble mechanism is adopted to reduce the space complexity. Extensive experiments verify the generality, effectiveness, and efficiency of the proposed BirDRec.