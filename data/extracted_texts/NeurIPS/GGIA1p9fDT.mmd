# CORNN: Convex optimization of recurrent neural networks for rapid inference of neural dynamics

Fatih Dinc

Department of Applied Physics

Stanford University

Stanford, CA 94305

&Adam Shai

CNC Program

Stanford University

Stanford, CA 94305

&Mark J. Schnitzer

Howard Hughes Medical Institute

CNC Program

Stanford University

Stanford, CA 94305

&Hidenori Tanaka

Physics & Informatics Laboratories, NTT Research, Inc.

Sunnyvale, CA 94085

Center for Brain Science, Harvard University

Cambridge, MA 02138

These authors contributed equally to this work.These authors co-supervised this work.

###### Abstract

Advances in optical and electrophysiological recording technologies have made it possible to record the dynamics of thousands of neurons, opening up new possibilities for interpreting and controlling large neural populations in behaving animals. A promising way to extract computational principles from these large datasets is to train data-constrained recurrent neural networks (dRNNs). Performing this training in real-time could open doors for research techniques and medical applications to model and control interventions at single-cell resolution and drive desired forms of animal behavior. However, existing training algorithms for dRNNs are inefficient and have limited scalability, making it a challenge to analyze large neural recordings even in offline scenarios. To address these issues, we introduce a training method termed Convex Optimization of Recurrent Neural Networks (CORNN)1. In studies of simulated recordings, CORNN attained training speeds \(\)100-fold faster than traditional optimization approaches while maintaining or enhancing modeling accuracy. We further validated CORNN on simulations with thousands of cells that performed simple computations such as those of a 3-bit flip-flop or the execution of a timed response. Finally, we showed that CORNN can robustly reproduce network dynamics and underlying attractor structures despite mismatches between generator and inference models, severe subsampling of observed neurons, or mismatches in neural time-scales. Overall, by training dRNNs with millions of parameters in subminute processing times on a standard computer, CORNN constitutes a first step towards real-time network reproduction constrained on large-scale neural recordings and a powerful computational tool for advancing the understanding of neural computation.

## 1 Introduction

Understanding the relationship between neural dynamics and computational function is fundamental to neuroscience research . To infer computational structure from neural population dynamics,neuroscientists regularly collect and analyze large-scale neural recordings using electrophysiological or optical imaging recording methods. Both recording modalities have undergone rapid progress in recent years, yielding a steady increase in the numbers of cells that can be recorded and manipulated . Owing to this progress, an urgent need has emerged for developing and refining theoretical and computational tools suited for the analysis of large recording datasets.

Data-driven modeling of neural network dynamics, in which recordings of neural activity are transformed into a computational model through network reconstruction, provides a promising way of bridging experiments and theory . This approach not only complements recent experimental breakthroughs in targeted stimulation of individual neurons () for hypothesis testing and brain-machine interfaces but also facilitates the distillation of fundamental computational principles from large amounts of experimental data . Historically, especially for recordings of individual or small numbers of cells, hand-crafted network models were used . While valuable, traditional hand-crafted models often struggle to handle the large datasets generated in contemporary neuroscience.

To bridge the gap, a new approach has recently emerged in which artificial networks are trained on tasks mimicking those performed in the laboratory by animal models . However, this approach lacks the ability to transform observed patterns of neural activity into data-driven, mechanistic computational models. A promising solution to these issues, which retains the advantages of neural network-based modeling, is the training of dRNNs . These models, part of a broader suite of computational strategies , align the dynamics of the neural units within the RNN to the activities of recorded neurons. This data-constrained methodology for RNN training has the potential to modernize estimations of functional connectivity --still a mainstay in systems neuroscience --and provides a viable path to distill underlying computations by extracting the state-space representations of the learned dRNNs . Additionally, dRNNs may open the door to computational control for causal experimentation , serving as a valuable computational adjunct to widely used techniques like optogenetics .

Despite recent advances in the dRNN framework, how to perform fast and scalable reconstructions of neural activity traces from large-scale empirical recordings has remained unclear. Notably, the slowness of existing dRNN optimization algorithms may often necessitate the use of high-performance clusters and several days of computation in large-scale experiments. These limitations might have been a barrier to the widespread adoption of dRNN approaches. Moreover, to fully harness the potential of dRNNs, it is essential to extend their range of applicability from offline analyses to on-the-fly applications within individual recording sessions. An approach to training dRNNs in a nearly immediate manner would be a key advancement that would enable novel experimental approaches, such as theory-driven real-time interventions targeting individual cells with specific computational or functional roles (Fig. 1). However, realizing these benefits requires having an optimization routine that is fast, robust, and scalable to large networks.

In this work, we present CORNN, a convex solver designed for fast and scalable network reproduction. We demonstrate its accuracy and efficiency compared to alternative network training methods such as FORCE  and back-propagation through time (BPTT), which have been employed in previous seminal works utilizing dRNNs . Our main contributions include the development of CORNN (Fig. 2), the introduction of an initialization strategy to accelerate convergence (Figs. 2, S4, and S6), and the demonstration of CORNN's scalable speed (Figs. 3, 5, S2, S3, S5, S8, and S9), which enables rapid training on the activity patterns of thousands of neurons (Figs. 4, 5, S7, S8, S9, S10, and S11). CORNN's performance can be further enhanced by 1-2 orders of magnitude through the use of a standard graphical processing units (GPU) on a desktop computer (Figs. S5 and S8). Unlike BPTT and FORCE, CORNN does not require fine-tuning (Figs. S1, S6), making it a user-friendly technology for biologists. Lastly, we highlight CORNN's robustness against non-idealities such as mismatches in the assumed dynamical system equations (Figs. 4, 5, S10, and S11), subsampling of neural populations (Fig. 5), differences in dynamical time-scales (Fig. S10), and existence of non-Gaussian (Fig. S3) or correlated noise (Fig. S11).

By enabling user-friendly, subminute training on standard computers, CORNN represents a first necessary step in transforming data-constrained recurrent neural networks from a theoretical concept into an experimental/computational technology. While this work focuses on introducing and validating the fast solver on simulated benchmarks, future work with CORNN should focus on addressing the challenges that arise when analyzing large-scale neural recordings from experimental neuroscience.

## 2 Approach

### Experimental setup for real-time interventions using dRNNs

Previous work suggested the use of dRNNs for real-time feedback between experimental and computational research . To date, however, the use of dRNNs has remained offline. Past studies extracted computational principles from neural recordings by fitting dRNNs _after_ data collection [24; 25; 26; 27; 28; 29]. Moreover, the use of dRNNs has generally required the expertise of computational neuroscientists, likely due to the complications associated with the optimization and training of neural network models. However, with the advent of large-scale recordings and data-driven approaches, real-time brain-machine interface research is likely a forthcoming application [36; 37; 38]. In such use cases, neurobiologists might wish to train dRNNs via a user-friendly approach. Hence, a fast and straightforward dRNN training procedure would enable a new breed of interventional experiments to dissect the brain's microcircuitry.

To appreciate the advantages of fast data-driven reconstruction of neural dynamics, consider a hypothetical scenario in which dRNNs, facilitated by CORNN, enable real-time interventions at the single-cell level (Fig. 1). In this scenario, neural activities from mice performing behavioral tasks are captured and extracted in real-time using advanced imaging or electrophysiological technologies and pre-processing algorithms [39; 40; 2; 3; 7; 3]. As the experiment progresses, neural activity traces from each mouse are reproduced by training dRNNs, which are then reverse-engineered to reveal underlying attractor structures. Rapid dRNN training allows for a tight feedback loop between incoming measured data and optimal experimental design, in order to refine the inferred model. Techniques similar to adversarial attacks  might be used to devise optimal cell targeting strategies from these dRNNs , allowing one to test hypotheses about the computational roles of individual neurons or to identify optimal neurons for use within brain-machine interfaces. Once a perturbation strategy is determined, it can be tested on subsequent trials of the experiment, using the same animal whose recorded neural dynamics led to the trained dRNN. Thus, a fast dRNN training algorithm could allow for better fitting of a dynamical system model to the experimental data and provide a natural testbed to probe hypotheses about the computational structure of the biological neural circuitry.

Motivated by the goals described above, our paper focuses on training dRNNs accurately and as fast as possible. However, experimental concerns and the need for biological interpretability lead to several constraints. Firstly, to ensure real-time communication with the experimental apparatus, we require that the training process takes place on standard lab computers, not clusters. Secondly, given the computational complexity of real-time processing in large scale recordings, especially with thousands of neurons, we expect that at least one of the GPUs is reserved for extracting neural activities

Figure 1: **Using data-constrained recurrent neural networks for the interpretation and manipulation of brain dynamics within a potential experimental pipeline.** This approach centers around online modeling of network dynamics, which can enhance hypothesis testing at the single-cell level and support advancements in brain-machine interface research. The training process is motivated by three objectives: (i) predicting the patterns of neural populations, (ii) revealing inherent attractor structures, and (iii) formulating optimal control strategies for subsequent interventions.

from brain-imaging movies  (though see  for a promising development in smaller scale experiments), or spikes from electrophysiological recordings , leaving the central processing unit (CPU), or perhaps a second GPU, for training dRNNs. Finally, maintaining biological interpretability via 1-1 matching of observed and modeled neurons is crucial, as arbitrariness brought by hidden units can explain away existing functional connectivity and/or contributions of observed neurons to underlying attractor structures. These concerns make many traditional machine learning architectures and optimization routines, typically trained on large clusters with billions of parameters, unsuitable for our purposes. This includes recent work on the dynamical system reconstruction paradigm , which chiefly aims to maximize reconstruction accuracy of dynamical systems without regard to biological interpretability, training speed, and scalability.

### Inference model and estimator family of interest

Recurrent neural networks are universal approximators for dynamical systems, whose internal computations can be reverse engineered and interpreted . Thus, we choose leaky firing-rate RNNs as the inference models of CORNN, which follow the dynamical system equations :

\[r_{i}}{t}=-r_{i}+(z_{i})+_{i}^{ }, z_{i}=_{j=1}^{N_{}}W_{ij}^{}r_ {j}+_{j=1}^{N_{}}W_{ij}^{}u_{j}+_{i}^{ },\] (1)

where \(\) is the neural decay time, \(z_{i}\) is the total input to the recurrent unit \(i\), \(r_{i}\) is the firing rate of the unit \(i\), and \((.)\) is the pre-defined non-linearity, \(W_{ij}^{}\) is the weight matrix for the recurrent connections, \(W_{ij}^{}\) is the weight matrix from the input to the recurrent units, \(u_{j}\) is the input vector, and \(_{i}^{}\) is the input noise to the recurrent units. Unlike previous literature, given our goal of reconstruction, we also consider the existence of a conversion noise \(_{i}^{}\) that accounts for errors and mismatches in the non-linearity. Additionally, the inference model has the constraint \(W_{ii}^{}=0\) preventing any self-excitation of neurons.

Suitable estimators for reconstructing such a model can be obtained (recursively) by discretizing the differential equation:

\[_{t+1,i}=(1-)_{t,i}+ f(_{t,i}),\] (2)

where we define the time scale parameter \(=\). Here, the model parameters influence \(_{i,t}\) explicitly linearly, and implicitly through previous time activities, such that \(_{t,i}=_{j}_{t,j}_{ji}\). We define the short-hand notations \(x=[r;u]\) and \(=[W^{};W^{}]^{T}\) as concatenated matrices. The goal of the estimation problem is to find \(\) minimizing a loss function.

Figure 2: **CORNN: Convex and scalable solver for dRNNs via ADMM .** The CORNN algorithm optimizes the parameters of a recurrent neural network so that activity in hidden units align with activities measured from a ground-truth system, we refer to as a generator. The choice of objective function results in a convex loss landscape. The algorithm starts by finding a fixed point for initialization, where the Hessians of all subproblems are aligned to the correlation matrix of neural activities, which can be pre-computed and pre-inverted. The optimization loop then iterates through predicting the neural activities, computing the prediction error, updating the parameter values, and checking for convergence. The final output is the set of optimized parameters, which represents the functional connections between the neurons in the data-constrained recurrent neural network.

A reasonable choice for the loss function of this regression problem is the traditional \(_{2}\) loss:

\[_{2}()=_{i=1}^{n_{}}_{t=1}^{T}(_{t,i}-r_{t,i})^{2}.\] (3)

However, due to the time recurrent definition of the general estimator \(_{t,i}\), this minimization problem would require backpropagation through time (BPTT). It is not apriori clear if BPTT is the right optimization method for network reproduction, for which one has access to high information content regarding the internal dynamics of the network. We discuss this in the results below.

Instead of using BPTT, we consider a smaller subset of estimators during training where \(_{t,i}\) is teacher-forced to \(r_{t,i}\) when computing \(_{t+1,i}\). This turns the potentially infinite time problem into a single time-step one, which we call "single step prediction error paradigm." Under this condition, the \(_{2}\) loss function transforms to a simpler form:

\[_{2}()=^{2}_{i=1}^{n_{}}_{t= 1}^{T}(_{t,i}-d_{t,i})^{2},\] (4)

where we define \(d_{t,i}=-(1-)r_{t,i}}{}\) and correspondingly \(_{t,i}=(_{t,i})\) becomes an estimator consisting of a linear term through a single non-linearity. However, this simplified version of the loss is not convex and leads to a counter-intuitive global loss function with vanishing gradients (Fig. 2).

### Convexification of the loss function

Rather than minimizing the naive \(_{2}\) loss function, we observe that \(_{t,i}}{2}\) follows a linear + sigmoid form. As a result, we replace the \(_{2}\) loss function with a cross-entropy loss function that is well known to be convex under this estimator. In fact, in the limit of \(d_{t,i} 1\), the problem reduces to logistic regression. Instead of a naive replacement, we use a weighted loss of the form:

\[_{}()=_{i=1}^{n_{}} _{t=1}^{T}c_{t,i}(_{t,i}}{2}, }{2}).\] (5)

Here, we use CE to denote the cross-entropy loss function and \(c_{t,i}\) are non-negative weighting factors chosen as \(c_{t,i}=[1-d_{t,i}^{2}]^{-1}\) for the CORNN solver. The specific choice of \(c_{t,i}\), which resembles (but is not) preconditioning , is motivated from a theoretical view in Supplementary Section S1.3. The reader can verify that the Hessian of this loss, derived in Eq. (S4), is positive semi-definite. For now, we write down the regularized loss function for CORNN as:

\[_{}()=_{}()+||||_{F}^{2},\] (6)

where \(||||_{F}\) is the Frobenius norm of \(\) and \(\) is the regularization parameter.

Fundamental principle of CORNN: Subproblem Hessians align to the correlation matrix of neural activity traces

Having convexified the loss function, we next observe that the loss function itself is perfectly separable such that \(_{}()=_{i}_{i}(_{,i})\), where \(_{,i}\) denotes the \(i\)th column of the parameter matrix \(\) (See Eq. S1). This means that the original problem can be divided into \(n_{}\) sub-problems and solved independently. However, inspired by the fact that solving least-squares for a vector or a matrix target has the same complexity, we can devise a faster method. Specifically, the choice of the specific weighting factors, \(c_{t,i}=[1-d_{t,i}^{2}]^{-1}\), leads to a shared (approximate) Hessian for all subproblems (See Eq. (S4)):

\[HX^{T}X+ I,\] (7)

where \(X\) stands for \(x_{t,i}\) in the matrix form, \(I\) is the identity matrix, and \(\) is the regularization parameter. We note that the approximation is exact in the limit \(_{t,i}=d_{t,i}\). In other words, we _align the Hessian of each subproblem to the correlation matrix of neural activities_. Unlike for least-squares minimization, this is a local, not global, Hessian; but as long as we can initialize the network sufficiently close to the optimal solution, we expect that the descent direction with the approximate Hessian converges quickly. In this sense, the approximation in Eq. (7) shows similarities with quasi-Newton methods  but is distinct in the pre-computed nature of the Hessian.

Following straightforward algebra, we obtain the gradient as

\[_{}_{}()=-X^ {T}E+,\] (8)

where we define the prediction error matrix \(E_{t,i}=-_{t,i}|}{1-d_{t,i}^{2}}\). It is worth noting that each column of the gradient matrix contains the gradient for the scalar subproblem corresponding to the \(i\)th output. Then, defining the inverse (fixed-point) Hessian matrix as

\[A^{+}=[X^{T}X+T I]^{-1}.\] (9)

we obtain the following update rule (See Eq. (S20))

\[^{k+1}=A^{+}X^{T}X^{k}+A^{+}X^{T}E^{k},\] (10)

where we highlight all quantities that can be pre-computed with blue. In essence, the update rule, which we call "Hessian aligned prediction error (HAPE) update," consists of computing the prediction error followed by matrix multiplications; thus is well suited to be accelerated on a GPU if available, but still can be efficiently computed on CPU cores.

The alignment of subproblem Hessians relies on the assumption that we can find a "close-enough" starting position, called the fixed-point, for the initial parameters \(^{(0)}\). As we show in Supplementary Section S1.2, a suitable candidate is the approximate least-squares solution:

\[_{}:=A^{+}X^{T}Z.\] (11)

Then, the initial set of predictions becomes \(_{t,i}:=(_{j}x_{t,j}(_{})_{j,i})\), which is subsequently refined through the HAPE iterations. This step is computationally negligible, as the blue colored matrix is already pre-computed for the iterations that follow.

In this section, we focused on the leaky firing rate RNNs as described in Eq. (1). However, CORNN can be applied to the other widely used variant of RNNs, _i.e._, the leaky current RNN described in Eq. (S28) and regularly employed in neuroscience literature [52; 12; 26]. The reproduction of the leaky current RNNs can be made convex by observing the direct link between the firing rates, \(r\), and the currents, \(z\), via a linear plus non-linear relationship, _i.e._, \(r=(z)\) and subsequently replacing \(d_{t,i}\) with \(r_{t,i}\) in Hessian and gradient calculations. To prevent introducing unnecessary complexity, we focus on leaky firing rate RNNs in this work.

## 3 Results

### CORNN as a versatile base model

While Hessian alignment, and subsequent HAPE updates, are the core principles driving the fast solver of CORNN, a versatile base model should be able to incorporate various regularization schemes and sparsity constraints. For example, the addition of constraints \(W_{ii}^{}=0\) or a potential low-rank regularization would prevent the Hessian alignment and subsequently the use of fast HAPE updates. However, these constraints could be biologically relevant and perhaps vital to eliminate overfitting in the reproduced network. In fact, for the inference model given in Eq. (1), \(r_{t,i} r_{t+1,i}\) for small \(\); making the unconstrained problem ill-posed since self excitation would explain a good amount of the activity of each neuron. Thus, to incorporate the equality constraint and many others, we developed a solver using the alternating direction method of multipliers (ADMM)  (summarized in Fig. 2).

In the ADMM solver, the primary problem is divided into two subproblems that are solved individually during subsequent iterations, yet linked through a consensus variable that ensures agreement between the solutions of both subproblems upon convergence. In this framework, the first subproblem solves the unconstrained optimization problem, whereas the second one enforces the constraints/regularization (See Supplementary Section S1 for derivations). This division allows the use of fast HAPE updates in the computationally extensive first subproblem, where Hessians can be aligned.

While we only considered the equality constraint in this work, the ADMM framework can be used to add additional L1 and/or nuclear norm regularizations to the learned connectivity matrix [51; 54], and utilize biological priors for further inductive biases. Finally, we note that given the highly irregular nature of the prediction error when \(d_{t,i} 1\), we supplied the fast solver with a simple automated outlier detection step explained in Supplementary Section S1.5.

### Backpropagation through time on the \(_{2}\) loss is suboptimal

In a traditional setting, in which neural activations are hidden and need to be learned through training to provide a correct output, backpropagation through time (BPTT) is necessary to learn long-term dependencies in the data. However, in the network reproduction where neural activations are no longer hidden, it is not clear whether BPTT would be beneficial for the learning, since long-term dependencies are inherently present in the state space of the dynamical system, whose equations are given in Eq. (1). Specifically, given that Eq. (1) has only a single time derivative, the time evolution is performed in a Markovian manner, _i.e._, given the current state, the next state can be computed without need for additional information (up to a corruption by random noise).

To test whether BPTT is a suitable training algorithm for network reproduction, we examined randomly connected chaotic recurrent neural networks as a synthetic ground-truth benchmark (See Section S3.1 for details). As shown in Fig. S1, contrary to expectation, teacher-forcing enhanced the convergence speed of the BPTT. Moreover, we also observed higher reproduction accuracy with the cross-entropy loss compared to the traditional \(_{2}\) loss, inline with our observation from Fig. 2 that \(_{2}\) loss leads to vanishing gradients in large error regime. As expected, BPTT took around a minute even in the toy example of Fig. S1 with \(100\) time points and \(100\) neurons, approximately two orders of magnitude smaller than a standard calcium imaging session in both dimensions.

### CORNN decreases training times several orders of magnitude

Having shown that teacher-forcing can speed-up convergence in chaotic networks, we next validated that chaotic dynamics can be reconstructed via a single step prediction error paradigm that CORNN utilizes. Specifically, we initialized randomly connected recurrent neural networks as generators, extracted neural activities for a fixed duration of length \(T\), and trained the dRNNs using CORNN, Newton's solver, gradient descent, and FORCE on varying number of iterations to benchmark their speed and accuracy (See Supplementary Sections S2 and S3.1 for details). All algorithms were able to train, some achieving near perfect accuracies in reproducing the internal connectivity of the generator network (See Figs. 3, S2, and S3). However, FORCE, the current default method in neuroscience literature for dRNN training [24; 25; 28; 29], was 4 orders of magnitude slower (Fig. 3) and needed fine-tuned hyperparameters to barely outperform the fixed-point initialization (Fig. S4).

Whether minimizing the weighted or logistic loss led to more accurate reconstruction depended on the underlying noise distribution (we tested two noise distributions: \(()\) and \((,)\)) of the data as shown in Figs. 3, S2, and S3. However, CORNN outperformed all other algorithms in speed in both cases with several orders of magnitude and converged

Figure 3: **CORNN reduces training times by several orders of magnitude.** The plots illustrate the relationship between reconstruction accuracy (Pearson’s correlation coefficient between ground truth and inferred weights) and training time, measured in seconds on a log scale. The FORCE approach (here, on firing rates) is the default method in neuroscience literature for dRNN training [24; 25; 28; 29]. Parameters: \(=0.1\), \(n_{}=5000\), \(T=30000\). No input. \(^{}(10^{-3})\), \(^{}(0,10^{-4})\). Lines: median. Error bars: s.d. over 7 networks.

in sub-second times even with the CPU implementation, whereas others took up to several days for training (Fig. 3). We also observed increased efficiency for CORNN on a GPU (Fig. S5) and that fixed-point initialization could stabilize other algorithms (Figs. S4 and S6).

### CORNN runtimes scale linearly with data size and polynomially with the network size

To this point, we provided validity evidence for the speed and accuracy of CORNN, or single-step prediction error paradigm in general, via the randomly connected chaotic RNN generators. Next, we focused on RNNs with more structured connectivity matrices. Specifically, we trained a model RNN using BPTT to perform a 3-bit flip flop task following  as shown in Fig. S7 (See Supplementary Section S3.2 for details). Fig. S7A shows the output of an example test trial, not used for the generator RNN training or the CORNN reproduction, with \(200\) time points followed by \(100\) time points of inter trial interval. We observed that CORNN reproduced network performed the task the same way the original network did; potentially making similar mistakes. Thus, as a first step, we confirmed that CORNN can learn to output the same outputs as the original network.

Next, we looked at underlying neural activities of an example (original) generator and reproduced (CORNN learned) network in Fig. S7B. The reproduction matched not only the output of the network, but also the internal firing dynamics of individual units. Yet, as shown in Fig. S7C, the synaptic connections were not perfectly learned even in such a simple scenario with matching models, which required more trials and potentially interventional data . Thus, we next tested whether increasing the number of trials could lead to better reproduction of the original network and whether CORNN can scale well to fit the increased data and network size.

Fig. S8 shows that accurately reproducing the large networks required significantly more trials. Moreover, the data size requirement for the estimation process increased with the number of units in the generator network, which emphasizes the importance of an optimization algorithm that can scale well to multiple day recordings . Fortunately, CORNN had a near-linear scaling of training times _vs._ the increasing number of trials and hence can handle large datasets (See Fig. S8). In the other direction, we observed that the training times scaled polynomially (Fig. S9), following \(n_{}^{}\)

Figure 4: **CORNN can reproduce underlying neural dynamics and attractor structures despite several non-idealities in the timed-response task.****A.** To assess the robustness of CORNN against time-scale mismatches, assumed inference models, and unobserved influences from subsampled neural populations, we trained 10 networks using a different generator model than CORNN for the timed-response task. **B.** We conducted a set of novel test trials to evaluate the reproduction accuracy of CORNN when the network was disturbed by a small distractor, which was not present during the learning of the timed-response task. **C.** Despite observing only 500 out of 5000 neurons and with an average 10% mismatch between \(_{G}\) and \(_{I}\), the CORNN-learned network reproduced both the neural dynamics and the output. **D.** When reproducing the original network without subsampling or time-scale mismatches but with generator-inference mismatches, the learned weights exhibited imperfect, but non-zero, correlation with the ground truth. **E.** Similar to **D**, we reproduced the network shown in **C** with subsampling and time-scale mismatches. Parameters: \(n_{G}=5000\), \(^{}(0,10^{-2})\) for \(100\) training trials, one example network, \(_{G}=}=0.1\), and \( t=1ms\). **B, D**: \(n_{O}=5000\), \(_{I}=0.1\). **C, E**: \(n_{O}=500\), \(_{I}(0.1,10^{-4})\).

with \([1.3,2.2]\), _vs._ the increasing number of neurons. Bringing both observations together, we concluded that there is an \(O(n_{}^{}T)\) scaling of the empirical training times.

### CORNN is robust to a diverse set of non-ideal conditions

To this point, we had considered ideal scenarios in which the generator network shared the same dynamical system equations as the inference network, all neurons were observed, and the time-scales of the generator and inference RNN units matched perfectly. Next, we considered cases in which these assumptions are violated (See Fig. 4A). Specifically, we trained a generator RNN with different governing equations (See Supplementary Section S3.3) to perform a timed-response task (See Fig. 4B), which put the network in a limit-cycle like dynamical attractor state initiated by an input. We tested the existence of the underlying attractor through a novel distractor input, which was not present during the training of the task (See Fig. 4B, C). If CORNN was able to learn the underlying state-space geometry, the reproduced network activities should be able to return to their attractive trajectory under novel perturbations.

When we subsampled the generator networks by 10% and introduced jitter in the time scales, we observed that the inference model reproduced the neural dynamics in the observed population in a novel perturbation trial (See Fig. 4C), even though the sub-connectivity matrix was not well reproduced (See Fig. 4D, E). On the one hand, this observation reinforces the findings of previous literature that the connectivity matrices learned by dRNNs should be interpreted as functional connections, accounting for the behavior of networks at the level of neural dynamics, and not synaptic connections [15; 25]. On the other hand, the ability of the mismatched network to reproduce neural activities in a novel perturbation trial provided evidence that the effects of the underlying attractor structures can be robustly reproduced with CORNN despite severe experimental non-idealities. We quantified these robustness aspects in Figs. 5A,B (subsampling), S10 (time-scale mismatch), and S11 (correlated noise). Moreover, we observed the \(n_{}^{}\) scaling for the training times with increased number of network size (Fig. 5C), inline with the results of Fig. S9.

## 4 Discussion

To place in perspective the experimental paradigm enabled by CORNN introduced in this work, we now return to the experimental scenario in Fig. 1. Imagine an experiment in which mice perform a predefined task several times, _e.g._, for an half hour, with imaging of 3000-4000 neurons. This experimental scenario yields roughly ten million parameters to be trained in the dRNN. The current study showcased CORNN's efficacy in training networks of thousands of neurons, requiring just \(O(10)\) iterations, each comparable in complexity to gradient computation and taking seconds. Consequently, training such a network from the initial imaging session would take less than a minute. Once trained, the network can enable real-time planning of experimental interventions, testing

Figure 5: **CORNN runtimes scale polynomially with increasing number of neurons, whereas reconstruction accuracies remain robust to subsampling.** We use the timed-response task as a testbed for quantifying the robustness of CORNN to unobserved influences due to subsampling in neural populations. **A** Reconstruction accuracy of input weights are plotted as a function of subsampling ratio (fraction of observed neurons), **B** reconstruction accuracy of neural activities, measured as the R\({}^{2}\) between the ground truth and predicted activations, and **C** the linear scaling of the training times with asymptotic slopes \([1.2,1.3]\) vs increasing number of neurons on a log-log plot, hinting at polynomial scaling. The different colors in the plot correspond to different number of training trials. Parameters: \(=0.1\), \(^{}(0,10^{-2})\) for the training trials. See Supplementary Section S3.3 for further details. Data points: mean, error bars: s.e.m. over 10 networks.

multiple scenarios in parallel to identify several optimal targeting strategies, a template of potential interventions, for neuron combinations driving desired animal behavior. Moreover, with CORNN's rapid convergence and typical inter-trial intervals of a few seconds in behavioral experiments, the network and the interventional strategy can be refined between trials with incoming data streams, facilitating real-time learning.

To understand the timescales for real-time inference with a dRNN for within-trial intervention experiments using calcium imaging, we can look at typical values. Acquiring each image frame takes about 30 ms . While new frames continue to be acquired, motion correction and neural activity extraction can happen in \(\)5 ms per frame . In addition to these ongoing imaging steps, the simulation and decision-making with the CORNN-fitted dRNN needs to be performed. The dRNN starts with the current observed activity and can quickly simulate multiple future responses under different input scenarios, _i.e._, potential interventions. Since the simulation involves only iterative matrix multiplications and point-wise nonlinearities, it finishes very quickly--in just a few ms. For instance, running a 1000neuron RNN forward for 10 timesteps (\(\) a second), for 100 different initial conditions, takes \(<6\) ms on a GPU, and \(<25\) ms on a CPU, in our hands. Once a desired intervention is identified from the simulations, the phase mask on a spatial light modulator can be updated in \(\)10 ms to optically stimulate the chosen neurons . Putting all the steps together, in under 100 ms one could capture brain activity, simulate future responses, decide on an intervention, and update the optical stimulation parameters. This is fast enough for real-time closed-loop applications. By streamlining network training, CORNN provides dRNNs for these types of experiments.

An important final point in considering the use of CORNN in experimental settings comes from the fact that neural networks are, in general, non-identifiable . That is, for any given settings of the parameters, there are other settings which give the same input-output function. This means that CORNN does not aim to infer the true underlying synaptic connectivity matrix from a neural activity dataset. Instead, the main use of CORNN is to infer an RNN model which recapitulates the dynamical trajectories in a neural population. CORNN may also capture the underlying attractor structure of a system. However, we caution that any claim having to do with attractor structures must be experimentally validated with perturbation experiments that directly test for attractors. In our work, we simulated such experimental validation (Figs. 4 and 5) and found that in the setting tested, CORNN was able to predict the dynamical effects of perturbations on the neural population.

## 5 Conclusion

In this work, we introduced a fast and scalable convex solver (CORNN) for rapid training of data-constrained recurrent neural networks. We showed that CORNN is as accurate yet faster than existing approaches by orders of magnitude and can easily scale to the large datasets of today, training in seconds to a few minutes depending on the data, network size and the availability of a GPU. CORNN, as a base model, lays the groundwork for future developments and can be improved by integrating experimentally relevant assumptions and regularizations within the ADMM framework.

When applied to simulated data from structured networks, CORNN picked up the underlying attractor structure despite non-idealities (Figs. 4, 5, S10, and S11). Inspired by this observation, further development of data-constrained RNNs can support systems neuroscience research aiming to understand inter-area interactions and can complement or augment studies of canonical or pairwise correlations toward characterizations of functional connectivity . Moreover, reverse engineering the learned network may provide a deeper understanding of how neuronal populations contribute to emergent computation, cognition, and memory [12; 30]. Finally, with the advent of interventional methods such as single-cell targeted optogenetics , dRNNs can be trained to test causal connections computationally and supply theoretical predictions at a scale previously unachievable for single-cell targeted experimentation .

This work constitutes a first step towards the application of CORNN to experimental data. However, several steps remain to apply dRNNs in real-time to interventional experiments. Some example steps may include the transformation of calcium traces or spike trains into traces of firing rates normalized within \([-1,1]\), applying the CORNN solver developed in this work into first offline and then online experimental scenarios, estimation of neuronal time-scales from the experimental data instead of tuning them as hyperparameters, and perhaps implementing a low-rank regularization approach that opens the door to interpreting the observed dynamics in terms of latent variables [26; 52].