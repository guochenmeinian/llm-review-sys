# Streaming Factor Trajectory Learning for Temporal Tensor Decomposition

Shikai Fang

Kahlert School of Computing

The University of Utah

shikai.fang@utah.edu

&Xin Yu

Kahlert School of Computing

The University of Utah

yuxwind@gmail.com

&Shibo Li

Kahlert School of Computing

The University of Utah

shiboli.cs@gmail.com

&Zheng Wang

Kahlert School of Computing

The University of Utah

ul208847@utah.edu

&Robert M. Kirby

Kahlert School of Computing

The University of Utah

kirby@cs.utah.edu

&Shandian Zhe

Kahlert School of Computing

The University of Utah

zhe@cs.utah.edu

Corresponding author.

###### Abstract

Practical tensor data is often along with time information. Most existing temporal decomposition approaches estimate a set of fixed factors for the objects in each tensor mode, and hence cannot capture the temporal evolution of the objects' representation. More important, we lack an effective approach to capture such evolution from streaming data, which is common in real-world applications. To address these issues, we propose Streaming Factor Trajectory Learning (SFTL) for temporal tensor decomposition. We use Gaussian processes (GPs) to model the trajectory of factors so as to flexibly estimate their temporal evolution. To address the computational challenges in handling streaming data, we convert the GPs into a state-space prior by constructing an equivalent stochastic differential equation (SDE). We develop an efficient online filtering algorithm to estimate a decoupled running posterior of the involved factor states upon receiving new data. The decoupled estimation enables us to conduct standard Rauch-Tung-Striebel smoothing to compute the full posterior of all the trajectories in parallel, without the need for revisiting any previous data. We have shown the advantage of SFTL in both synthetic tasks and real-world applications. The code is available at https://github.com/xuangu-fang/Streaming-Factor-Trajectory-Learning.

## 1 Introduction

Tensor data is common in real-world applications. For example, one can extract a three-mode tensor _(patient, drug, clinic)_ from medical service records and a four-mode tensor _(customer, commodity, seller, web-page)_ from the database of an online shopping platform. Tensor decomposition is a fundamental tool for tensor data analysis. It introduces a set of factors to represent the objects in each mode, and estimate these factors by reconstructing the observed entry values. These factors can be viewed as the underlying properties of the objects. We can use them to search for interesting structures within the objects (_e.g.,_ communities and outliers) or as discriminate features for predictive tasks, such as personalized treatment or recommendation.

Real-world tensor data is often accompanied with time information, namely the timestamps at which the objects of different modes interact to produce the entry values. Underlying the timestamps can be rich, valuable temporal patterns. While many temporal decomposition methods are available,most of them estimate a set of static factors for each object -- they either introduce a discrete time mode (Xiong et al., 2010; Zhe et al., 2016a) or inject the timestamp into the decomposition model (Zhang et al., 2021; Fang et al., 2022; Li et al., 2022). Hence, these methods cannot learn the temporal variation of the factors. Accordingly, they can miss important evolution of the objects' inner properties, such as health and income. In addition, practical applications produce data streams at a rapid pace (Du et al., 2018). Due to the resource limit, it is often prohibitively expensive to decompose the entire tensor from scratch whenever we receive new data. Many privacy-protecting applications (_e.g.,_ SnapChat) even forbid us to preserve or re-access the previous data. Therefore, not only do we need a more powerful decomposition model that can estimate the factor evolution, we also need an effective method to capture such evolution from fast data streams.

To address these issues, we propose SFTL, a Bayesian streaming factor trajectory learning approach for temporal tensor decomposition. Our method can efficiently handle data streams, with which to estimate a posterior distribution of the factor trajectory to uncover the temporal evolution of the objects' representation. Our method never needs to keep or re-visit previous data. The contribution of our work is summarized as follows.

* First, we use a Gaussian process (GP) prior to sample the factor trajectory of each object as a function of time. As a nonparametric function prior, GPs are flexible enough to capture a variety of complex temporal dynamics. The trajectories are combined through a CANDECOMP/PARAFAC (CP) (Harshman, 1970) or Tucker decomposition (Tucker, 1966) form to sample the tensor entry values at any time point.
* Second, to sidestep the expensive covariance matrix computation in the GP, which further causes challenges in streaming inference, we use spectral analysis to convert the GP into a linear time invariant (LTI) stochastic differential equation (SDE). Then we convert the SDE into an equivalent state-space prior over the factor (trajectory) states at the observed timestamps. As a result, the posterior inference becomes easier and computationally efficient.
* Third, we take advantage of the chain structure of the state-space prior and use the recent conditional expectation propagation framework (Wang and Zhe, 2019) to develop an efficient online filtering algorithm. Whenever a collection of entries at a new timestamp arrives, our method can efficiently estimate a decoupled running posterior of the involved factor states, with a Gaussian product form. The decoupled Gaussian estimate enables us to run standard RTS smoothing (Sarkka, 2013) to compute the full posterior of each factor trajectory independently and in parallel, without revisiting any previous data. Our method at worst has a linear scalability with respect to the number of observed timestamps.

We first evaluated our method in a simulation study. On synthetic datasets, SFTL successfully recovered several nonlinear factor trajectories, and provided reasonable uncertainty estimation. We then tested our method on four real-world temporal tensor datasets for missing value prediction. In both online and final predictive performance, SFTL consistently outperforms the state-of-the-art streaming CP and Tucker decomposition algorithms by a large margin. In most cases, the prediction accuracy of SFTL is even higher than the recent static decomposition methods, which have to pass through the dataset many times. Finally, we investigated the learned factor trajectories from a real-world dataset. The trajectories exhibit interesting temporal evolution.

## 2 Preliminaries

**Tensor Decomposition.** We denote an \(M\)-mode tensor by \(^{d_{1} d_{M}}\), where each mode \(m\) has \(d_{m}\) dimensions, corresponding to \(d_{m}\) objects. Each tensor entry is indexed by a tuple \(=(_{1},,_{M})\), and the value is denoted by \(y_{}\). For decomposition, we introduce a set of latent factors \(_{j}^{m}^{R_{m}}\) to represent each object \(j\) in mode \(m\) (\(1 m M\)). One most popular tensor decomposition model is the CANDECOMP/PARAFAC (CP) decomposition (Harshman, 1970), which sets \(R_{1}==R_{M}=R\), and uses the following element-wise form, \(y_{}^{}(_{_{1}}^{1} _{_{M}}^{M})=_{r=1}^{R}_{m=1}^{M}u_{_{m}, r}^{m}\), where \(\) is the element-wise product. Another commonly used model is Tucker decomposition (Tucker, 1966), \(y_{}()^{}(_ {_{1}}^{1}_{_{M}}^{M})=_{r_{ 1}=1}^{R_{1}}_{r_{M}=1}^{R_{M}}[w_{}_{m =1}^{M}u_{_{m},r_{m}}^{m}]\), where \(^{R_{1} R_{M}}\) is the tensor-core parameter, \(()\) is the vectorization, \(\) is the Kronecker product, and \(=(r_{1},,r_{M})\).

**Gaussian Process (GP)**s are nonparametric function priors. For a function \(f()\), if we place a GP prior, \(f(0,(,^{}))\), it means \(f()\) is sampled as a realization of the GP with covariance function \(\), which is often chosen as a kernel function. The GP prior only models the correlation between the function values, namely, \((f(),f(^{}))=(,^{})\), and does not assume any parametric form of the function. Hence, GPs are flexible enough to estimate various complex functions from data, _e.g._, from multilinear to highly nonlinear. The finite projection of the GP is a Gaussian distribution. That is, given an arbitrary collection of inputs \(\{_{1},,_{N}\}\), the corresponding function values \(=[f(_{1}),,f(_{N})]^{}\) follow a multi-variate Gaussian prior distribution, \(p()=(|,)\) where \(\) is the covariance matrix and each \([]_{mn}=(_{m},_{n})\).

## 3 Bayesian Temporal Tensor Decomposition with Factor Trajectories

In real-world applications, tensor data is often associated with time information, namely, the timestamps at which the objects of different modes interact to generate the entry values. To capture the potential evolution of the objects' inner properties, we propose a Bayesian temporal tensor decomposition model that can estimate a trajectory of the factor representation. Specifically, for each object \(j\) in mode \(m\), we model the factors as a function of time, \(_{j}^{m}:[0,]^{R}\). To flexibly capture a variety of temporal evolution, we assign a GP prior over each element of \(_{j}^{m}(t)=[u_{j,1}^{m}(t),,u_{j,R}^{m}(t)]^{}\), _i.e._, \(u_{j,r}^{m}(t)(0,(t,t^{}))\) (\(1 r R\)). Given the factor trajectories, we then use the CP or Tucker form to sample the entry values at different time points. For the CP form, we have

\[p(y_{}(t)|(t))=(y_{}(t )|^{}(_{t_{1}}^{1}(t)_{ _{M}}^{M}(t)),^{-1}),\] (1)

where \((t)=\{_{j}^{m}(t)\}\) includes all the factor trajectories, and \(\) is the inverse noise variance, for which we assign a Gamma prior, \(p()=(|_{0},_{1})\). For the Tucker form, we have \(p(y_{}(t)|(t),)=(y_{ }(t)|()^{}(_{t_{1}}^{1}(t )_{_{M}}^{M}(t)),^{-1})\) where we place a standard normal prior over the tensor-core, \(p(())=(()|, )\). In this work, we focus on continuous observations. It is straightforward to extend our method for other types of observations.

Suppose we have a collection of observed entry values and timestamps, \(=\{(_{1},y_{1},t_{1}),,(_ {N},y_{N},t_{N})\}\) where \(t_{1} t_{N}\). We denote the sequence of timestamps when a particular object \(j\) of mode \(m\) participated in the observed entries by \(s_{j,1}^{m}<<s_{j,c_{j}^{m}}^{m}\), where \(c_{j}^{m}\) is the participation count of the object. Note that it is a sub-sequence of \(\{t_{n}\}\). From the GP prior, the values of each \(u_{j,r}^{m}(t)\) at these timestamps follow a multi-variate Gaussian distribution, \(p(_{j,r}^{m})=(_{j,r}^{m}|, _{j}^{m})\) where \(_{j,r}^{m}=[u_{j,r}^{m}(s_{j,1}^{m}),,u_{j,r}^{m}(s_{j,c_{j}^{ m}}^{m})]^{ 2}\) and \(_{j}^{m}\) is the covariance/kernel matrix computed at these timestamps. The joint probability with the CP form is

\[p(\{_{j,r}^{m}\},,)=_{m=1}^ {M}_{j=1}^{d_{m}}_{r=1}^{R}(_ {j,r}^{m}|,_{j}^{m})(|_{0}, _{1})\] \[_{n=1}^{N}(y_{n}|^{ }(_{_{n1}}^{1}(t_{n})_{_{nM}}^{M}(t _{n})),^{-1}).\] (2)

The joint probability with the Tucker form is the same except that we use the Tucker likelihood instead and multiply with the prior of tensor-core \(p()\).

While this formulation is straightforward, it can introduce computational challenges. There are many multi-variate Gaussian distributions in the joint distribution (2), _i.e._, \(\{(_{j,r}^{m}|,_{j}^{m})\}\). The time and space complexity to compute each \((_{j,r}^{m}|,_{j}^{m})\) is \(((c_{j}^{m})^{3})\) and \(((c_{j}^{m})^{2})\), respectively. With the increase of \(N\), the appearance count \(c_{j}^{m}\) for many objects can grow as well, making the computation cost very expensive or even infeasible. The issue is particularly severe when we handle streaming data -- the number of timestamps grows rapidly when new data keeps coming in, so does the size of each covariance matrix.

### Equivalent Modeling with State-Space Priors

To sidestep expensive covariance matrix computation and ease the inference with streaming data, we follow (Hartikainen and Sarkka, 2010) to convert the GP prior into an SDE via spectral analysis.

We use a Matem kernel \(_{}(t,t^{})=a}}{( )^{2}})^{}}{()^{2-1}}K_{}(}{})\) where \(()\) is the Gamma function, \(=|t-t^{}|\), \(a>0\), \(>0\), \(K_{}\) is the modified Bessel function of the second kind, and \(=p+\) (\(p\{0,1,2,\}\)) as the GP covariance. Via the analysis of the power spectrum of \(_{}\), we can show that if \(f(t)(0,_{}(t,t^{}))\), it can be characterized by a linear time-invariant (LTI) SDE, with state \(=(f,f^{(1)},,f^{(p)})^{}\) where \(f^{(k)}}{{=}}^{k}f/t^{k}\),

\[}{t}=+(t),\] (3)

where \((t)\) is a white noise process with diffusion \(^{2}\),

\[=(0&1&&&\\ &&&\\ &&0&1\\ -c_{0}&&-c_{p-1}&-c_{p}),=( 0\\ \\ 0\\ 1).\]

Both \(^{2}\) and \(\) are obtained from the parameters in \(_{}\). Due to the space limit, we leave the detailed derivation in Appendix (Section A). The LTI-SDE is particularly useful in that its finite set of states follow a Gauss-Markov chain, _i.e.,_ the state-space prior. Given arbitrary \(t_{1}<<t_{L}\), we have

\[p((t_{1}),,(t_{L}))=p((t_{1}))_{k=1 }^{L-1}p((t_{k+1})|(t_{k})),\]

where \(p((t_{1}))=((t_{1})|,_{})\), \(p((t_{k+1})|(t_{k}))=((t_{k+1})| _{k}(t_{k}),_{k})\), \(_{}\) is the stationary covariance matrix computed by solving the matrix Riccati equation [Lancaster and Rodman, 1995], \(_{n}=(_{k})\) where \(_{k}=t_{k+1}-t_{k}\), and \(_{k}=_{}-_{k}_{}_{k}^{}\). Therefore, we do not need the full covariance matrix as in the standard GP prior, and the computation is much more efficient. The chain structure is also convenient to handle streaming data as we will explain later.

We therefore convert the GP prior over each factor trajectory \(u_{j,r}^{m}(t)\) into an LTI-SDE. We denote the corresponding state by \(_{j,r}^{m}(t)\). For example, if we choose \(p=1\), then \(_{j,r}^{m}(t)=[u_{j,r}^{m}(t);u_{j,r}^{m}(t)/t]\). For each object \(j\) in mode \(m\), we concatenate all its trajectory states into one, \(_{j}^{m}(t)=[_{j,1}^{m}(t);;_{j,R}^{m}(t)]\). Then on all of its timestamps \(s_{j,1}^{m}<<s_{j,c_{j}^{m}}^{m}\), we obtain a state-space prior

\[p(_{j,1}^{m})=(_{j,1}^{m}|, }_{}),\;\;p(_{j,k+1}^{m}|_{j,k}^ {m})=(_{j,k+1}^{m}|}_{j,k}^{m} _{j,k}^{m},}_{j,k}^{m}),\] (4)

where \(_{j,k}^{m}}{{=}}_{j}^{m}(s_ {j,k}^{m})\), \(}_{}=(_{},, _{})\), \(}_{j,k}^{m}=(_{j,k}^{m}, ,_{j,k}^{m})\), \(_{j,k}^{m}=e^{(s_{j,k+1}^{m}-s_{j,k}^{m})},}_{j,k}^{m}=(_{j,k}^{m},, _{j,k}^{m})\), and \(_{j,k}^{m}=_{}-_{j,k}^{m}_{ }(_{j,k}^{m})^{}\).

The joint probability of our model with the CP form now becomes

\[p(\{_{j,k}^{m}\},,)=p()_{m=1}^ {M}_{j=1}^{d_{m}}p(_{j,1}^{m})_{k=1}^{c_{j}^{ m}-1}p(_{j,k+1}^{m}|_{j,k}^{m})\] \[_{n=1}^{N}(y_{n}|^{}(_{t_{n1}}^{1}(t_{n})_{t_{nM}}^{M}(t_{n})),^{-1}).\] (5)

Note that in the likelihood, each \(_{t_{nm}}^{m}(t_{n})(1 j M)\) is contained in a corresponding state vector \(_{t_{nm},k}^{m}\) such that \(s_{t_{nm},k}^{m}=t_{n}\) (by definition, we then have \(_{t_{nm},k}^{m}=_{t_{nm}}^{m}(t_{n})\)). The joint probability with the Tucker form is similar, which we omit to save the space.

## 4 Trajectory Inference from Streaming Data

In this section, we develop an efficient, scalable algorithm for factor trajectory estimation from streaming data. In general, we assume that we receive a sequence of (small) batches of observed tensor entries, \(\{_{1},_{2},\}\), generated at different timestamps, \(\{t_{1},t_{2},\}\). Each batch \(_{n}\) is generated at timestamp \(t_{n}\) and \(t_{n}<t_{n+1}\). Denote by \(_{t_{n}}\) all the data up to timestamp \(t_{n}\), _i.e.,_\(_{t_{n}}=_{1}_{n}\). Upon receiving \(_{n+1}\), we intend to update our model without revisitingto provide the trajectory posterior estimate, \(\{p(_{j}^{m}(t)|_{t_{n+1}})| t 0,1 m M,1  j d_{m}\}\), where \(_{t_{n+1}}=_{t_{n}}_{n+1}\).

To this end, we first observe that the standard state-space model with a Gaussian likelihood has already provided a highly efficient streaming inference framework. Denote by \(_{n}\) and \(_{n}\) the state and observation at each step \(n\), respectively. To handle streaming observations \(\{_{1},_{2},\}\), we only need to compute and track the running posterior \(p(_{n}|_{1:n})\) upon receiving each \(_{n}\), where \(_{1:n}\) denotes the total data up to step \(n\). This is called Kalman filtering , which only depends on the running posterior at step \(n-1\), _i.e.,_\(p(_{n-1}|_{1:n-1})\), and is highly efficient. After all the data is processed (suppose it stops at step \(N\)), we can use Rauch-Tung-Striebel (RTS) smoother  to efficiently compute the full posterior of each state, \(p(_{n}|_{1:N})\), from backward, which does not need to re-access any previous observations (see Section B in Appendix).

However, one cannot apply the above framework outright to our model, since the tensor decomposition likelihood of each observed entry couples the states of multiple factor trajectories, see (1) -- which correspond to the participated objects at different modes. That means, the factor-state chains of different objects are dynamically intertwined through the received data. The multiplicative form of these states in the likelihood render the running posterior of each trajectory intractable to compute, not to mention running RTS smoother. To address this challenge, we take advantage of the chain structure and use the recent conditional Expectation propagation (CEP) framework  to develop an efficient online filtering algorithm, which approximates the running posterior of the involved factor states as a product of Gaussian. Thereby, we can decouple the involved factor state chains, and conduct standard RTS smoothing for each chain independently.

Specifically, denote the sequence of timestamps when each object \(j\) of mode \(m\) has showed up in the data stream up to \(t_{n}\), by \(s_{j,1}^{m}<s_{j,2}^{m}<<s_{j,c_{j,n}^{m}}^{m}\) where \(c_{j,n}^{m}\) is the object's appearance count up to \(t_{n}\). Denote by \(_{n}^{m}\) the indexes of all the objects of mode \(m\) appearing in \(_{n}\). Hence, for every object \(j_{n}^{m}\), we have \(s_{j,c_{j,n}^{m}}^{m}=t_{n},\) and \(_{j,c_{j,n}^{m}}^{m}}{{=}} _{j}^{m}(t_{n})\) is the factor state of the object at \(t_{n}\). Upon receiving each \(_{n}\), we intend to approximate the running posterior of all the involved factor states and noise inverse variance \(\) with the following decoupled form,

\[p(,\{_{j,c_{j,n}^{m}}^{m}|j_{n}^{m}\}_{1 m M }|_{t_{n}}) q(|_{n})_{m=1}^{M}_{j _{n}^{m}}q(_{j,c_{j,n}^{m}}^{m}|_{t_{n}}),\] (6)

where \(q(|_{t_{n}})=(|a_{n},b_{n})\), and \(q(_{j,c_{j,n}^{m}}^{m}|_{t_{n}})=(_ {j,c_{j,n}^{m}}^{m}|}_{j,c_{j,n}^{m}}^{m},}_{j,c _{j,n}^{m}}^{m})\). To this end, let us consider given the approximation at \(t_{n}\), how to obtain the new approximation at \(t_{n+1}\) (_i.e.,_ upon receiving \(_{n+1}\)) in the same form of (6). To simplify the notation, let us define the preceding states of the involved factors by \(_{n}=\{_{j,c_{j,n+1}^{m}}^{m}|j_{n+1}^{m}\}_{m}\), and the current states by \(_{n+1}=\{_{j,c_{j,n+1}^{m}}^{m}|j_{n+1}^{m}\}_{m}\). First, due to the chain structure of the prior over each \(\{_{j,c_{j,n}^{m}}^{m}|k=0,1,2,\}\), we can see that conditioned on \(\{_{n},\}\), the current states \(_{n+1}\) and the new observations \(_{n+1}\) are independent of \(_{t_{n}}\). This is because in the graphical model representation, \(\{_{n},\}\) have blocked all the paths from the old observations \(_{t_{n}}\) to the new state and observations (Bishop, 2007); see Fig. 1 for an illustration. Then, we can derive that

\[p(_{n+1},_{n},|_{t_{n+1}}) p( _{n+1},_{n},,_{n+1}|_{t_{n}})=p(_ {n},|_{t_{n}})p(_{n+1},_{n+1}|_{n},,_{t_{n}})\] \[=p(_{n},|_{t_{n}})p(_{n+1}|_{n} )p(_{n+1}|_{n+1},),\] (7)

where \(p(_{n},|_{t_{n}})\) is the running posterior at \(t_{n}\),

\[p(_{n+1}|_{n})=_{m=1}^{M}_{j_{n+1}^{m}}p( _{j,c_{j,n+1}^{m}}^{m}|_{j,c_{j,n}^{m}}^{m}),\]

each \(p(_{j,c_{j,n+1}^{m}}^{m}|_{j,c_{j,n}^{m}}^{m})\) is a conditional Gaussian distribution defined in (4), and \(p(_{n+1}|_{n+1},)=_{(,y) _{n+1}}(y|^{}(_{_{ 1}}^{1}(t_{n+1})_{_{M}}^{M}(t_{n+1})), ^{-1})\). Since \(p(_{n},|_{t_{n}})\) takes the form of (6), we can analytically marginalize out each \(_{j,c_{j,n}^{m}}^{m}_{n}\), and obtain

\[p(_{n+1},|_{t_{n+1}}) (|a_{n},b_{n})_{m=1}^{M}_{j_{n +1}^{m}}(_{j,c_{j,n+1}^{m}}^{m}|}_{j,c_{j,n+1}^{m}}^{m},}_{j,c_{j,n+1}^{m}}^{m})\] (8) \[_{(,y)_{n+1}} (y|^{}(_{_{1}}^{1}(t_{n+1}) _{_{M}}^{M}(t_{n+1})),^{-1}).\]

If we view the R.H.S of (8) as a joint distribution with \(_{n+1}\), then our task amounts to estimating the posterior distribution, _i.e.,_ the L.H.S of (8). The product in the CP likelihood (and also Tucker likelihood) renders exact posterior computation infeasible, and we henceforth approximate

\[(y|^{}(_{_{1}}^{1}(t_{n+1}) _{_{M}}^{M}(t_{n+1}))) _{m=1}^{M}(_{_{m}}^{m}(t_{n+1})|_{_{m}}^{m},_{_{m}}^{m})(| _{},_{})\] (9)

where \(\) means approximately proportional to. To optimize these approximation terms, we use the recent conditional Expectation propagation (CEP) framework (Wang and Zhe, 2019) to develop an efficient inference algorithm. It uses conditional moment matching to update each approximation in parallel and conducts fixed point iterations, and hence can converge fast. We leave the details in the Appendix (Section C). Once it is done, we substitute the approximation (9) into (8). Then the R.H.S of (8) becomes a product of Gaussian and Gamma terms over each state and \(\). We can then immediately obtain a closed-form estimation in the form as (6). At the beginning, when estimating \(p(_{1},|_{t_{1}})\), since the preceding states \(_{0}=\), we have \(a_{n}=_{0}\), \(b_{n}=_{1}\), \(}_{j,c_{j,n+1}^{m}}^{m}=\), and \(}_{j,c_{j,n+1}^{m}}^{m}=}_{}\) in (8), which is the prior of each \(_{j,c_{j,n}^{m}}^{m}\) and \(\) (see (4)).

In this way, we can continuously filter the incoming batches \(\{_{1},_{2},\}\). As a result, for the factor state chain of every object \(j\) in every mode \(m\), along with each timestamp \(s_{j,k}^{m}\), we can online estimate and track a running posterior approximation \(\{q(_{j,k}^{m}|_{t_{j,k}^{m}})|k=1,2,\}\), which is a Gaussian distribution. Hence, we can run the standard RTS smoother, to compute the full posterior of every factor state, with which we can compute the posterior of the trajectory at any time point \(t\)(Bishop, 2006). Our method is summarized in Algorithm 1.

**Algorithm Complexity.** The time complexity of our algorithm processing a batch \(_{n}\) is \((|_{n}|R^{3})\) where \(||\) is the size. The time complexity of RTS smoother for a particular object \(j\) in mode \(m\) is \((R^{3}c_{j,N}^{m})\), where \(N\) is the total number of timestamps. The space complexity of our algorithm is \((_{m=1}^{M}_{j=1}^{d_{m}}c_{j,N}^{m}R^{2})\), which is to track the running posterior of the factor state at each appearing timestamp for every object. Since \(c_{j,N}^{m} N\), the complexity of our algorithm is at worst linear in \(N\).

## 5 Related Work

Many tensor decomposition methods have been developed, such as (Yang and Dunson, 2013; Rai et al., 2014; Zhe et al., 2015, 2016, 2016, 2020; Tillinghast et al., 2020; Pan et al., 2020; Fang et al., 2021, 2021, 2020; Zhang et al., 2021, 2020; Zhang et al., 2021, 2020; Zhang et al., 2021, 2021).

Tillinghast and Zhe, 2021, Tillinghast et al., 2022, Fang et al., 2022, Zhe and Du, 2018, Pan et al., 2020, Wang et al., 2020, Pan et al., 2021, Wang et al., 2022]. For temporal decomposition, most existing methods augment the tensor with a discrete time mode to estimate additional factors for time steps, _e.g.,_[Xiong et al., 2010, Rogers et al., 2013, Song et al., 2017, Du et al., 2018, Ahn et al., 2021]. The most recent works have conducted continuous-time decomposition. Zhang et al.  used polynomial splines to model a time function as the CP coefficients. Li et al.  used neuralODE [Chen et al., 2018] to model the entry value as a function of latent factors and time point. Fang et al.  performed continuous-time Tucker decomposition, and modeled the tensor-core as a time function. To our knowledge, [Wang et al., 2022] is the first work to estimate factor trajectories. It places a GP prior in the frequency domain, and samples the factor trajectories via inverse Fourier transform. It then uses another GP to sample the entry values. While successful, this method cannot handle streaming data, and the black-box GP decomposition lacks interpretability.

Current Bayesian streaming tensor decomposition methods include [Du et al., 2018, Fang et al., 2021, Pan et al., 2020, Fang et al., 2021b], which are based on streaming variational Bayes [Broderick et al., 2013] or assumed density filtering (ADF) [Boyen and Koller, 1998]. ADF can be viewed as an instance of Expectation Propagation (EP) [Minka, 2001] for streaming data. EP approximates complex terms in the probability distribution with exponential-family members, and uses moment matching to iteratively update the approximations, which essentially is a fixed point iteration. To address the challenge of intractable moment matching, Wang and Zhe  proposed conditional EP (CEP), which uses conditional moment matching and Taylor expansion to compute the moments for factorized approximations. The theoretical guarantees and error bound analysis for EP and ADF have been studied for a long time, such as [Boyen and Koller, 1998, Dehaene and Barthelme, 2015, 2018]. The most recent work [Fang et al., 2022] also uses SDEs to represent GPs and CEP framework for inference, but their GP prior is placed on the tensor-core, not for learning factor trajectories, and their method is only for static decomposition, and cannot handle streaming data.

## 6 Experiment

### Simulation Study

We first conducted a simulation study, for which we simulated a two-mode tensor, with two nodes per mode. Each node is represented by a time-varying factor: \(u_{1}^{1}(t)=-^{3}(2 t)\), \(u_{2}^{1}(t)=(1-^{3}( t))^{3}(3 t)\), \(u_{1}^{2}(t)=(2 t)\), and \(u_{2}^{2}(t)=-^{3}(3 t)(3 t)(2 t)\). Giventhese factors, an entry value at time \(t\) is generated via \(y_{(i,j)}(t)(u_{i}^{1}(t)u_{j}^{2}(t),0.05)\). We randomly sampled \(500\) (irregular) timestamps from \(\). For each timestamp, we randomly picked two entries, and sampled their values accordingly. Overall, we sampled 1,000 observed tensor entry values.

We implemented SFTL with PyTorch (Paszke et al., 2019). We used \(=\) and \(a==0.3\) for the Matern kernel. We streamed the sampled entries according to their timestamps, and ran our streaming factor trajectory inference based on the CP form. The estimated trajectories are shown in Fig. 2. As we can see, SFTL recovers the ground-truth pretty accurately, showing that SFTL has successfully captured the temporal evolution of the factor representation for every node. It is interesting to observe that when \(t\) is around 0, \(0.5\) and \(1\), the posterior standard deviation (the shaded region) increases significantly. This is reasonable: the ground-truth trajectories overlap at these time points, making it more difficult to differentiate/estimate their values at these time points. Accordingly, the uncertainty of the estimation increases. In Section D of Appendix, we further provide the root-mean-square error (RMSE) in recovering the four trajectories, and sensitivity analysis of the kernel parameters.

    & RMSE & _FitRecord_ & _ServerRoom_ & _BeijingAir-2_ & _BeijingAir-3_ \\   & PTucker & \(0.656 0.147\) & \(0.458 0.039\) & \(0.401 0.01\) & \(0.535 0.062\) \\  & Tucker-ALS & \(0.846 0.005\) & \(0.985 0.014\) & \(0.559 0.021\) & \(0.838 0.026\) \\  & CP-ALS & \(0.882 0.017\) & \(0.994 0.015\) & \(0.801 0.082\) & \(0.875 0.028\) \\  & CT-CP & \(0.664 0.007\) & \(0.384 0.009\) & \(0.64 0.007\) & \(0.815 0.018\) \\  & CT-GP & \(0.604 0.004\) & \(0.223 0.035\) & \(0.759 0.02\) & \(0.892 0.026\) \\  & BCTT & \(0.518 0.007\) & \(0.185 0.013\) & \(0.396 0.022\) & \(0.801 0.02\) \\  & NONFAT & \(0.503 0.002\) & \(\) & \(0.395 0.007\) & \(0.882 0.014\) \\  & THIS-ODE & \(0.526 0.004\) & \(0.132 0.003\) & \(0.54 0.014\) & \(0.877 0.026\) \\   & POST & \(0.696 0.019\) & \(0.64 0.028\) & \(0.516 0.028\) & \(0.658 0.103\) \\  & ADF-CP & \(0.648 0.008\) & \(0.654 0.008\) & \(0.548 0.015\) & \(0.551 0.043\) \\  & BASS-Tucker & \(0.976 0.024\) & \(1.000 0.016\) & \(1.049 0.037\) & \(0.991 0.039\) \\  & SFTL-CP & \(\) & \(0.161 0.014\) & \(\) & \(0.473 0.013\) \\  & SFTL-Tucker & \(0.430 0.010\) & \(0.331 0.056\) & \(0.303 0.041\) & \(\) \\   & & & & \\   & PTucker & \(0.369 0.009\) & \(0.259 0.008\) & \(0.26 0.006\) & \(0.263 0.02\) \\  & Tucker-ALS & \(0.615 0.006\) & \(0.739 0.008\) & \(0.388 0.008\) & \(0.631 0.017\) \\  & CP-ALS & \(0.642 0.012\) & \(0.746 0.009\) & \(0.586 0.056\) & \(0.655 0.018\) \\  & CT-GP & \(0.46 0.004\) & \(0.269 0.003\) & \(0.489 0.006\) & \(0.626 0.01\) \\  & CT-GP & \(0.414 0.001\) & \(0.165 0.034\) & \(0.55 0.012\) & \(0.626 0.011\) \\  & BCTT & \(0.355 0.005\) & \(0.141 0.011\) & \(0.254 0.007\) & \(0.578 0.009\) \\  & NONFAT & \(0.341 0.001\) & \(\) & \(0.256 0.004\) & \(0.626 0.007\) \\  & THIS-ODE & \(0.363 0.004\) & \(0.083 0.002\) & \(0.345 0.004\) & \(0.605 0.013\) \\   & POST & \(0.478 0.014\) & \(0.476 0.023\) & \(0.352 0.022\) & \(0.486 0.095\) \\  & ADF-CP & \(0.449 0.006\) & \(0.496 0.007\) & \(0.385 0.012\) & \(0.409 0.029\) \\   & BASS & \(0.772 0.031\) & \(0.749 0.01\) & \(0.934 0.037\) & \(0.731 0.02\) \\   & SFTL-CP & \(\) & \(0.108 0.008\) & \(\) & \(0.318 0.008\) \\   & SFTL-Tucker & \(0.246 0.001\) & \(0.216 0.034\) & \(0.185 0.029\) & \(\) \\   

Table 1: Final prediction error with \(R=5\). The results were averaged from five runs.

Figure 2: The learned factor trajectories from the synthetic data. The shaded region indicates the posterior standard deviation.

### Real-World Applications

Next, we examined SFTL in four real-world datasets: _FitRecord_, _ServerRoom_, _BeijingAir-2_, and _BeijingAir-3_. We tested 11 competing approaches. We compared with state-of-the-art streaming tensor decomposition methods based on the CP or Tucker model, including (1) POST [Du et al., 2018], (2) BASS-Tucker [Fang et al., 2021a] and (3) ADF-CP [Wang and Zhe, 2019], the state-of-the-art static decomposition algorithms, including (4) P-Tucker [Oh et al., 2018], (5) CP-ALS and (6) Tucker-ALS [Bader and Kolda, 2008]. For those methods, we augment the tensor with a time mode, and convert the ordered, unique timestamps into increasing time steps. We also compared with the most recent continuous-time decomposition methods. (7) CT-CP [Zhang et al., 2021], (8) CT-GP, (9) BCTT [Fang et al., 2022], (10) THIS-ODE [Li et al., 2022], and (11) NONFAT [Wang et al., 2022], nonparametric factor trajectory learning, the only existing work that also estimates factor trajectories for temporal tensor decomposition. Note that the methods 4-11 cannot handle data streams. They have to iteratively access the data to update the model parameters and factor estimates. The details about the competing methods and datasets are provided in Appendix (Section E).

For all the competing methods, we used the publicly released implementations of the original authors. The hyper-parameter setting and turning follows the original papers. For SFTL, we chose \(\) from \(\{,\}\), \(a\) from [0.5, 1] and \(\) from [0.1, 0.5]. For our online filtering, the maximum number of CEP iterations was set to \(50\) and the tolerance level to \(10^{-4}\). For numerical stability, we re-scaled the timestamps to \(\). We examined the number of factors (or factor trajectories) \(R\{2,3,5,7\}\).

**Final Prediction Accuracy.** We first examined the final prediction accuracy with our learned factor trajectories. To this end, we followed [Xu et al., 2012, Kang et al., 2012], and randomly sampled \(80\%\) observed entry values and their timestamps for streaming inference and then tested the prediction error on the remaining entries. We also compared with the static decomposition methods, which need to repeatedly access the training entries. We repeated the experiment five times, and computed the average root mean-square-error (RMSE), average mean-absolute-error (MAE), and their standard deviations. We ran our method based on both the CP and Tucker forms, denoted by SFTL-CP and SFTL-Tucker, respectively. We report the results for \(R=5\) in Table 1. Due to the space limit, we leave the other results in the Appendix (Table 4,5, and 6). As we can see, SFTL outperforms all the streaming approaches by a large margin. SFTL even obtains significantly better prediction accuracy than all the static decomposition approaches, except that on _Server Room_, SFTL is second to THIS-ODE and NONFAT. Note that SFTL only went through the training entries for once. Although NONFAT can also estimate the factor trajectories, it uses GPs to perform black-box nonlinear decomposition and hence loses the interpretability. Note that NONFAT in most case also outperforms the other static decomposition methods that only estimate time-invariant factors. The superior performance of SFTL and NONFAT shows the importance of capturing factor evolution.

**Online Predictive Performance.** Next, we evaluated the online predictive performance of SFTL. Whenever a batch of entries at a new timestamp has been processed, we examined the prediction accuracy on the test set, with our current estimate of the factor trajectories. We repeated the evaluation for five times, and examine how the average prediction error varies along with the number of processed entries. We show the results for \(R=5\) in Fig. 3, and the others in Appendix (Fig. 5, 6, and 7). It is clear that SFTL in most cases outperforms the competing streaming decomposition algorithms by a large margin throughout the course of running. Note that the online behavior of BASS-Tucker was quite unstable and so we excluded it in the figures. It confirms the advantage of our streaming trajectory learning approach -- even in the streaming scenario, incrementally capturing the time-variation of the factors can perform better than updating fixed, static factors. To confirm the advantage of SFTL in computational efficiency, we report the running time in Section G of Appendix.

Figure 3: Online prediction error with the number of processed entries (\(R=5\)).

**Investigation of Learning Results.** Finally, we investigated our learned factor trajectories. We set \(R=3\) and ran SFTL-CP on _ServerRoom_. In Fig. 4, we visualize the trajectory for the 1st air conditioning mode, the 2rd power usage level, and the 3rd location. The shaded region indicates the standard deviation, and the red dashed line the biggest timestamp in the data. First, we can see that the posterior variance of all the trajectories grow quickly when moving to the right of the red line. This is reasonable because it is getting far away from the training region. Second, for each object, the first and second trajectories (1st and 2nd column in Fig. 4) exhibit quite different time-varying patterns, _e.g.,_ the local periodicity in \(u^{1}_{1,2}(t)\) and \(u^{2}_{2,2}(t)\), the gradual decreasing and increasing trends in \(u^{3}_{3,1}(t)\) and \(u^{3}_{3,2}(t)\), respectively, which imply different inner properties of the object. Third, it is particularly interesting to see that the third trajectory for all the objects appear to be close to zero, with relatively large posterior variance all the time. This might imply that two factor trajectories have been sufficient to represent each object. Requesting for a third trajectory is redundant. More important, our model is empirically able to detect such redundancy and returns a zero-valued trajectory.

## 7 Conclusion

We have presented SFTL, a probabilistic temporal tensor decomposition approach. SFTL can efficiently handle streaming data, and estimate time-varying factor representations. On four real-world applications, SFTL achieves superior online and final prediction accuracy.