# Dis-inhibitory neuronal circuits can control the sign of synaptic plasticity

Julian Rossbroich\({}^{1,2}\)

Friedemann Zenke\({}^{1,2}\)

{firstname.lastname}@fmi.ch

\({}^{1}\) Friedrich Miescher Institute for Biomedical Research, Basel, Switzerland

\({}^{2}\) Faculty of Science, University of Basel, Basel, Switzerland

###### Abstract

How neuronal circuits achieve credit assignment remains a central unsolved question in systems neuroscience. Various studies have suggested plausible solutions for back-propagating error signals through multi-layer networks. These purely functionally motivated models assume distinct neuronal compartments to represent local error signals that determine the sign of synaptic plasticity. However, this explicit error modulation is inconsistent with phenomenological plasticity models in which the sign depends primarily on postsynaptic activity. Here we show how a plausible microcircuit model and Hebbian learning rule derived within an adaptive control theory framework can resolve this discrepancy. Assuming errors are encoded in top-down dis-inhibitory synaptic afferents, we show that error-modulated learning emerges naturally at the circuit level when recurrent inhibition explicitly influences Hebbian plasticity. The same learning rule accounts for experimentally observed plasticity in the absence of inhibition and performs comparably to back-propagation of error (BP) on several non-linearly separable benchmarks. Our findings bridge the gap between functional and experimentally observed plasticity rules and make concrete predictions on inhibitory modulation of excitatory plasticity.

## 1 Introduction

How do neurons far away from the sensory periphery and motor output system update their connections to contribute to network computation meaningfully? This question, formally known as the "credit assignment problem," is one of the outstanding questions in systems neuroscience. Classic learning theories assume synaptic plasticity in the brain is mainly Hebbian, i.e., changes in a synapse's efficacy depend merely on the pre- and postsynaptic activity of the neurons it connects . A plethora of experiments in different brain areas support the notion of Hebbian plasticity [2; 3] and diverse phenomenological plasticity models quantitatively capture observed synaptic plasticity dynamics [4; 5; 6; 7; 8]. Theories of reinforcement learning suggested further extensions of Hebbian learning to three-factor rules that account for reward modulation, whereby a global modulatory factor, e.g., dopamine, explicitly influences the sign of plasticity [9; 10]. Again, there is ample experimental evidence for the role of neuromodulators in gating plasticity in various brain areas [11; 12]. Yet, recent work argues that global neuromodulation is insufficient to learn complex function mappings in large networks [13; 14] and that more fine-grained control over the sign of plasticity is required, as in the BP algorithm used in deep learning [15; 16; 17; 18]. This realization motivated several modeling studies on how biological networks could approximate BP [19; 20; 21; 22; 23; 24; 25]. One central assumption in virtually all of these models is that the sign of plasticity is explicitly modulated by a neuron-specific local error signal akin to the gradient-based update used in BP . However, learning rules with explicit errormodulation are inconsistent with phenomenological models of Hebbian plasticity (Fig. 1), raising the question of how theories of bio-plausible credit assignment tie into the phenomenology of Hebbian learning.

Here, we address this question using a normative control theory approach. We set out from a plausible dis-inhibitory circuit motif ubiquitously found in the brain [27; 28] and derive a Hebbian learning rule with an explicit inhibitory current dependence. We demonstrate that this learning rule accounts for key experimental observations _and_ allows for control over the sign of plasticity through top-down synaptic input to specific interneurons. Our work suggests that error signals could naturally be encoded in top-down inputs to inhibitory neurons and bridges the gap between normative theories of gradient-based learning and phenomenological models of Hebbian plasticity. Our main contributions are:

* We extend Deep Feedback Control (DFC), a recent adaptive control theory framework for error-based learning , to a biologically plausible dis-inhibitory microcircuit motif.
* We show how a Hebbian plasticity rule with an explicit inhibition dependence can naturally decode credit signals from this microcircuit.
* We demonstrate that this rule enables error-based learning in hierarchical networks, naturally stabilizes runaway Hebbian plasticity, and resembles phenomenological plasticity rules under simulated experimental conditions.
* Finally, we demonstrate that our learning rule performs comparable to BP in deep neural networks trained on computer vision benchmarks.

## 2 Background and previous work

In this article we strive to reconcile phenomenological plasticity models constrained by experiments and models of biologically plausible credit assignment based on normative theories of gradient-based learning. In the following we review essential literature of both approaches.

Figure 1: Explicit error modulation of the sign of plasticity is inconsistent with phenomenological plasticity models. **(a)** In neuronal circuits, top-down feedback connections target excitatory neurons, as well as inhibitory and dis-inhibitory circuits that have been implicated in gating of plasticity. In phenomenological plasticity models, the sign of plasticity is typically determined by postsynaptic quantities such as the membrane voltage , firing rate , or calcium concentration  without explicit error modulation. **(b)** In normative models, the sign of plasticity is typically subject to a hypothetical, explicit error modulation with little experimental evidence. Explicit error modulation makes specific predictions of the shape of the learning rule, (Supplementary Fig. S1; see Appendix A), at odds with experimentally observed plasticity (see Panel (a)). **(b)** Theories of bio-plausible gradient-based learning typically focus on approximating direct error-modulation as in BP, but differ in how errors are computed and relayed. Existing models suggest separate temporal phases, e.g. equilibrium propagation (EP) , putative compartments to represent error signals locally, e.g., dendritic error coding [22; 30], or burst-multiplexing [23; 31]. Still, there is little evidence for an explicit error signal that alters the sign of plasticity  and is consistent with phenomenological plasticity models.

### Phenomenological synaptic plasticity models

There is widespread experimental support for the notion of Hebbian synaptic plasticity in the brain, captured in the form of classical long-term potentiation (LTP) and long-term depression (LTD)  or spike-timing-dependent plasticity (STDP) . An extensive mathematical model catalog captures the phenomenology of these findings [4; 5; 6; 7; 8]. Common to most of the above models is that postsynaptic quantities define a plasticity threshold which separates LTD from LTP induction, which effectively determines the sign of the synaptic weight change [32; 33; 34] (Fig. 1a). A plethora of phenomenological plasticity models exist that capture such dependence on firing rate , voltage , and postsynaptic calcium concentration [5; 8]. For isolated neurons, classic work has demonstrated that Hebbian plasticity can extract principal components from structured data  or capture receptive field formation observed experimentally . However, these models do not extend to deep hierarchical networks, nor can they account for the modulation of plasticity through local error signals required for solving the credit assignment problem. Thus, the mechanisms by which synaptic plasticity observed under experimental conditions could give rise to coordinated learning at the circuit- and network level remain elusive.

### Models of biologically plausible credit assignment

The above models are contrasted by normative rules derived from gradient-based learning principles, which often aim at approximating BP  (Fig. 1b-c). A crucial aspect of BP is the separation of forward- and backward signaling, which algorithmically separates credit signaling from neuronal activity . This separation presents a significant challenge for biologically plausible implementations, as it presumes a distinct separation through either learning phases or separate pathways.

Equilibrium propagation (EP) offers one possible, if only partial, solution to this dilemma. EP posits that local errors are derived as variations in neuronal activity at a network equilibrium state . Yet, classic EP still requires separate processing phases for each input, inconsistent with neurobiology. However, recent work suggests possible ways of alleviating the requirement for distinct phases through neural oscillations .

An alternative to separate phases for forward and backward passes is to separate them spatially. Predictive coding models [19; 25; 39] exemplify this idea, whereby errors are computed in dedicated neuron-specific error units by comparing each neuron's activity to a top-down prediction. Recent work has suggested that the electrotonically segregated apical dendrites of cortical pyramidal neurons [37; 40] could represent local errors in learning [21; 22].

However, to approximate BP, a common theme across these models is their dependence on explicit error-modulation of plasticity  (Fig. 1b-c). While error-modulated learning rules prove functionally useful and, in some cases, can match the performance of BP, experimental evidence for their existence is inconclusive. In particular, they fall short of capturing established properties of experimentally observed plasticity, such as a threshold between LTD and LTP that is governed by postsynaptic activity [32; 33; 34; 41].

Finally, Payeur et al.  proposed a unique multiplexing approach by encoding forward and feedback signals in the event and burst rate of output spike trains. Such burst-dependent plasticity rules capture essential facets of phenomenological plasticity  (Supplementary Fig. S1; see Appendix A). However, the model primarily applies to cortical Layer 5 pyramidal cells with electrically segregated dendritic trees. In contrast, it may not work for layer 2/3 neurons or other brain areas without segregated dendrites.

Since most of the above models focused on approximating BP, they face another potential issue: they usually require weak feedback, which causes only a slight perturbation, or nudge, of the input-driven equilibrium. This requirement contrasts significantly with a wealth of experimental literature suggesting that feedback connections in the brain substantially influence neuronal activity [42; 43; 44]. Rather than striving to find biologically plausible separations between forward and backward signaling, recent modeling studies used an approach grounded in adaptive control theory [45; 46; 47; 25; 48]. These models leverage strong feedback signals to steer neuronal activity to align with a given target output. While strong feedback aligns more closely with neurobiological observations, these models are also dependent on explicitly error-modulated learning rules, wherein the error is computed from either the difference between the controlled and uncontrolled states of neuronal activity similar to EP or the difference between activity in segregated neuronal compartments, as in dendritic error coding.

Still, it remains to be seen how such learning could be implemented at the circuit level with plasticity rules that capture experimental findings. In this article, we propose a putative circuit-level solution to this issue by mapping the notion of feedback control onto a known dis-inhibitory circuit motif and combining it with an inhibition-modulated Hebbian plasticity rule.

## 3 Model

To study whether biological microcircuits could naturally interpret dis-inhibitory feedback signals as local errors to control the sign of synaptic plasticity, we consider a continuous time dynamic multi-layer network comprised of excitatory and inhibitory neurons in each layer with dis-inhibitory feedback connections.

### Neuronal dynamics

The membrane potential dynamics of the excitatory and inhibitory neurons in layer \(i\) are described by the following ordinary differential equations (ODEs):

\[_{}_{i}^{} = -_{i}^{}(t)+_{i}_{i-1}^{ }(t)-_{i}^{}(t)\] (1) \[_{}_{i}^{} = -_{i}^{}(t)+_{i}^{}(t)- _{i}(t)\] (2)

with \(_{i}\) the afferent synaptic weights from the previous layer and \(_{i}=(_{i})\) a smooth, monotonically increasing nonlinear activation function. Note that here we made the simplifying assumption that each excitatory neuron has an associated inhibitory neuron and that both are connected locally within a microcircuit. For all simulations, we use the soft rectifying nonlinearity \((u)=(1+(u-))\), in which \(\) and \(\) are parameters controlling the scale and shift of the activation function, respectively. Dis-inhibitory feedback is mediated through top-down control signals \((t)\) relayed to each layer \(i\) through an associated feedback weight matrix \(_{i}\) (Fig. 2). The input layer \(_{0}(t)\) is data-dependent and not influenced by top-down feedback. For a constant input current \(_{0}\), the network dynamics settle to the equilibrium state

\[}{}_{i}^{}=_{i}_{i-1}^ {}-}{}_{i}^{}, }{}_{i}^{}=_{i}^{}- _{i}}{}.\] (3)

### Feedback control

As in previous work on DFC [24; 47], our model uses feedback control to drive the output activity of the network towards the target activity \(_{L}^{}\) by minimizing the magnitude of the output error:

\[(t)=-.(_{L},_{L}^ {})}{_{L}}|_{_{L}=_{L}( t)}^{T}\] (4)

where \((_{L},_{L}^{})\) is a label-dependent supervised loss function defined on the network's output activity. For a simple mean squared error (MSE) loss, \(=}{{n}}_{n}}{{2}}\|_{L}^{ }(n)-_{L}(n)\|_{2}^{2}\), the error for each datapoint \(n\) is directly related to the difference between the network's output and the target, specifically \((t)=_{L}^{}-_{L}(t)\).

Leaky proportional-integral controller.In our model, we use a leaky proportional-integral controller to compute the feedback control signals \((t)\):

\[(t)=k_{}(t)+k_{}^{} ,_{c}^{}=(t)-^{}(t)\] (5)

where \(k_{}\) and \(k_{}\) are the proportional and integral control constants, respectively.

Figure 2: Illustration of a multi-layer network with dis-inhibitory control microcircuits (left). Each network unit consists of an excitatory and inhibitory neuron that are recurrently connected (right). The top-down control signal to each layer \(_{i}(t)\) is relayed through dis-inhibitory afferents (orange).

Dis-inhibitory feedback connectivity.Next, we have to connect the controller to the controlled quantities. In the context of our model, we assume that control signals are relayed via inhibitory interneurons. We thus have to specify the feedback weights connecting the control signals to the local microcircuits defined in the previous section. While we make no claims about how suitable control feedback is generated in neurobiology, in this article we merely assume that suitable control signals exist and that they are mediated via inhibitory interneurons. To that end, the feedback weights \(_{i}\) need to be chosen such that the output loss \((_{L},_{L}^{})\) is minimized at the controlled equilibrium state. To fulfill this requirement, the column space of the concatenated feedback weights of the network, \(Q[_{1}^{T},,_{L}^{T}]^{T}\), must be equal to the row space of the network Jacobian \(J\) at steady-state . This Jacobian characterizes how infinitesimal perturbations of each controlled quantity, e.g., a neuronal activation, relates to changes in the network's output \(_{L}\). In contrast to previous models relying on top-down control, our network consists of recurrently connected excitatory and inhibitory units whilst top-down input is targeting the inhibitory population exclusively. Since we want to model control through dis-inhibitory circuits, we assume that the Jacobian for the controller is defined with respect to the inhibitory membrane potential at each layer:

\[J[_{1},,_{L}]=[_{L}}{_{1}^{}},,_{L}}{_{L}^{}}]\] (6)

where we use \(_{L}}{_{i}^{}}=_{ _{i}^{}}_{L}\) to denote the Jacobian matrix of partial derivatives of the vector \(_{L}\) with respect to the vector \(_{i}^{}\). It has been shown that a wide range of possible feedback weights \(Q\) can match the row space of \(J\) in the DFC framework. One simple way of ensuring this condition is met is to set the feedback weights at each layer proportional to the transposed Jacobian, i.e., \(-_{i}=_{i}^{T}\). However, the Jacobian depends on the input and the neuronal activity. It is thus changing over time until an equilibrium state is reached. To avoid changing feedback weights over time for a given input, we compute them based on the network Jacobian at the uncontrolled equilibrium state with \(=0\)

\[-_{i}=}_{i}^{T}=.(_{L}}{_{i}^{}})^{T}|_{_{i}^{ }=}_{i}^{}}\] (7)

with \(}_{i}^{}\) corresponding to the inhibitory membrane potentials in Layer \(i\) at the uncontrolled equilibrium state.

Learning as minimization of control in dis-inhibitory neuronal circuits.Given suitable feedback weights and a strong influence on the network activity by the controller, neuronal activity can change considerably compared to the uncontrolled steady-state. Tracing the steps of , learning rules can be derived from a _minimization of control_ objective

\[=_{n}\|Q}(n)\|_{2}^{2}\] (8)

where \(}(n)\) is the steady-state feedback control signal for datapoint \(n\). Formally, it can be shown that minimizing the above surrogate loss \(\) also minimizes the output loss \(\) (see Appendix B.1). We start with the following learning rule which minimizes \(\):

\[_{w}}{t}i=[}_{i}^{}-}_{i}^{})}_{ }(}_{i}^{ })}_{}]}_{i-1}^{})^{T}}_{}\] (9)

where \(^{}()\) is the derivative of the activation function and \(\) denotes element-wise multiplication. The sign of the weight change is determined by the error projected onto each neuron by the feedback controller at the equilibrium, which following Eq. (3) is encoded as \(_{i}}=}_{i}^{}-}_{i}^{}\). While Eq. (9) minimizes \(\) when provided with sensible feedback signals, it does not constitute a local learning rule because it explicitly depends on the inhibitory membrane potentials \(}_{i}^{}\), which excitatory neurons cannot access directly (cf. Fig. 1).

### A Hebbian learning rule for error-modulated learning through dis-inhibitory control

We were wondering whether excitatory neurons could compute an effective local approximation of Eq. (9) by estimating the inhibitory membrane potentials from locally available quantities. To that end, we first re-write Eq. (9) as

\[_{W}}{t}_{i}=[(}}_{i}^{}-^{-1}(}}_{i}^{ }))^{}(}}_{i}^ {})](}}_{i-1}^{} )^{T},\] (10)

where we substituted the inhibitory membrane potentials \(}}_{i}^{}\) with the inverse activation function \(^{-1}(}}_{i}^{})\). Mathematically, Eqs. (9) and (10) are equivalent, but conceptually, it re-frames the problem of non-locality since it would require an excitatory neuron to compute the inverse activation function from the recurrent inhibitory current, which is locally available. While it is hard to imagine how neurons would invert the activation function of other neurons exactly, we assume that they could conceivably compute a linear approximation, leading to a learning rule of the following general form:

\[_{W}}{t}_{i}=[(}}_{i}^{}-_{i}-_{i}}}_ {i}^{})^{}(}}_{i}^ {})](}}_{i-1}^{} )^{T}.\] (11)

Here the parameter \(_{i}\) takes the role of a postsynaptic plasticity threshold, common to many phenomenological plasticity models [6; 7; 8], while \(_{i}\) adds an inhibitory current dependence to this threshold. In practice, we obtain \(_{i}\) and \(_{i}\) through a first-order Taylor expansion of the inverse activation function around a given linearization point \(\) (see Appendix B). In the next sections, we will see that, depending on the inhibitory activation function and the linearization parameters, the model reconciles aspects of phenomenological plasticity with an effective error-modulation mechanism as demanded by normative theories of gradient-based learning.

## 4 Learning with dis-inhibitory control accounts for key plasticity experiments

Most experiments on synaptic plasticity are performed _in vitro_ under highly controlled conditions, in which pairs of connected neurons are isolated. This enables researchers to investigate the plasticity at single synapses in the absence of interfering activity from the local microcircuit or long-range synaptic afferent connections. Such experimental conditions would likely interfere with any putative error-modulation of synaptic plasticity since long-range synaptic afferents are either severed during sample preparation or do not transmit plausible activity levels. To account for such possible experimental confounding factors and to compare experimentally observed Hebbian plasticity, we probe our error-modulated learning rule in three different settings: full microcircuit with "closed-loop feedback", intact "microcircuit without feedback", and isolated neurons resembling in-vivo experimental conditions with "direct control of inhibition" (Fig. 3). In each setting, we vary the excitatory input to the excitatory neuron and calculate the resulting weight change as a function of the postsynaptic firing rate using Eq. (11). For a qualitative comparison to previously suggested error-driven plasticity rules, we evaluated learning rules using dendritic error coding [22; 24; 30] or burst-dependent plasticity [23; 31] in comparable settings (Supplementary Fig. S1; see Appendix A).

Dis-inhibition controls the sign of plasticity in the intact microcircuit.We first considered a simplified version of the intact microcircuit with top-down dis-inhibitory feedback, for which our learning rule was derived. In this circuit, top-down control drives neuronal activity towards a target value \(r^{}\). We computed the weight updates dictated by our learning rule for two different targets as a function of the neuronal firing rate. In this setting, the learning rule exhibits two stable fixed points separated by an unstable one (Fig. 3a). Importantly, a stable fixed point exists at the the target firing rate, i.e. \(r^{}=r^{}\) (Fig. 3a). At this fixed point, the sign of plasticity is determined by the top-down controller through the error decoded by the learning rule (11). This behavior is in line with the behavior of learning rules with explicit error-modulation in this simplified setting (cf. Fig. 1b, Supplementary Fig. S1).

Moreover, in contrast to purely error-modulated plasticity rules, our rule exhibits an LTD region flanked by a stable fixed point in neuronal firing rates at zero and an unstable fixed point at intermediate firing rates. The existence of this LTD regime is a direct consequence of the local approximation used in its derivation (cf. Eq. (11)) and depends on the chosen parameters of the linearization (Supplementary Fig. S2; see Appendix B). For proper error-modulated learning in our framework, we have to ensure that each neuron's activity does not exclusively stay in this region over time and across different inputs. In neurobiology, this activity regime could, for instance, be attained through homeostatic plasticity . Thus our learning rule exhibits error-modulated plasticity at the upper fixed point when embedded in an intact microcircuit with top-down feedback.

Plasticity in an isolated microcircuit is self-stabilizing.To examine how our learning rule behaves in the absence of top-down control signals, we investigated plasticity dynamics in an isolated microcircuit without control feedback, while local circuit connectivity between excitatory and inhibitory neurons was left intact. In this setting, the inhibitory membrane potential does not encode an error signal that can be decoded by the learning rule. While explicitly error-modulated learning rules would not exhibit any synaptic weight change in this setting, our Hebbian learning rule predicts weight changes due to the imperfect approximation of the inverse function. Fig. 3b depicts the resulting plasticity dynamics for two different linear approximations. Embedded in a local microcircuit, the plasticity rule still exhibits both an LTD and LTP regime and a stable fixed point that depends on the learning rule parameters. Notably, the plasticity rule embedded in an isolated, but intact microcircuit is self-stabilizing through recurrent inhibition. Interestingly, the necessity of such a stable fixed point at higher activity levels for stable learning has been postulated previously in theoretical work . As before, the presence and location of the stable fixed point depend on the choice of plasticity parameters (Supplementary Fig. S2).

Plasticity induction changes under direct control of inhibition.Experiments on excitatory plasticity _in vitro_ are commonly performed under conditions designed to minimize the interference of inhibitory activity, for example by applying GABA antagonists . To study plasticity induction in our model under such simulated experimental conditions, we blocked recurrent connections from excitatory to inhibitory neurons, so that inhibitory activity is independent of excitatory activity. Additionally, we controlled inhibitory activity, as could be achieved, for instance, through current injection or optogenetic manipulations in experiments. In the absence of any inhibitory activity, i.e. \(r^{}=0\), our learning rule reduces to the form \( w r_{}(r_{}-)^{ }(r_{})\) and loses its stable fixed point (Fig. 3c). Thus, in the absence of inhibition, the weight update prescribed by our plasticity model resembles Hebbian plasticity rules commonly observed under experimental conditions (Fig. 3d). However, our model predicts that direct control over inhibitory inputs to the excitatory neuron should shift the postsynaptic plasticity threshold to larger values.

In summary, dis-inhibitory control accounts for key plasticity experiments while also supporting error-driven learning in top-down controlled microcircuits. Additionally, its self-stabilizing capabilities provide a possible explanation as to why _in vitro_ experiments have failed to uncover a

Figure 3: A Hebbian learning rule for error-modulated learning through dis-inhibitory control resembles plasticity observed in single-neuron electrophysiology experiments. **(a)** Weight change \( W\) of a a single synapse as a function of postsynaptic firing rate \(r_{}\). Different colored lines indicate two different postsynaptic firing rate targets \(r^{}\) indicated by colored arrows. The top-down feedback onto the interneuron is proportional to the error \(r^{}-r^{}\). In the intact microcircuit with closed-loop feedback, our learning rule naturally leads to error-modulated learning. **(b)** Same as (a), but with top-down connections ablated. The two shades of green represent two different linear approximations of the inverse inhibitory activation function (see inset; inverse activation function in black). The plasticity rule resembles a multi-stable Hebbian plasticity rule . **(c)** Same as before, but for an isolated neuron without microcircuit. Different shades of blue correspond to different amounts of inhibitory current. Different levels of injected inhibitory current lead to different values for the plasticity threshold, but the stable fixed point disappears in the absence of recurrent inhibition. **(d)** Experimentally observed plasticity with activity-dependent LTD and LTP redrawn from . The data qualitatively resembles our learning rule in the open-loop setting (cf. panel (c)).

stabilizing mechanism for excitatory synaptic plasticity. Next, we test whether our learning rule allows hierarchical networks to solve nonlinear function approximation problems.

## 5 Dis-inhibitory control orchestrates learning in multi-layer networks

To explore our model's ability to train multi-layer networks, we first designed a simple continuous-time low-dimensional student-teacher learning task (Fig. 4a; see Appendix C for details). In this task, a randomly initialized teacher network with fixed parameters \(f((t))\) is given a set of 20 sine wave inputs with randomly chosen amplitudes, frequencies, and phases \((t)\). An architecturally identical student network but with different initial weights receives the same input \((t)\) and is tasked to reproduce the teacher's output, i.e. \(r_{L}^{}(t)=f((t))\), evaluated through an MSE loss function. A dis-inhibitory feedback controller as described in the previous section is continually driving the student network's activity towards lower loss in real time. We trained the student network with either the exact non-linear inhibitory threshold rule Eq. (10) or the Hebbian learning rule with a linear inhibitory threshold Eq. (11). Neuronal and weight dynamics were simulated in continuous time using an explicit \(5^{}\) order Runge-Kutta method. To make sure that the feedback controller is aligned with the changing Jacobian during learning, the feedback weights were plastic and continuously evolving towards the average network Jacobian (see Appendix C).

Before learning, the student network did not follow the target closely in the open-loop setting, i.e., when the control signal was turned off. However, as soon as dis-inhibitory control was activated, the output activity closely followed the target (Fig. 4b). We then trained the student network for a total of 300 seconds of continuous sine wave inputs using either Eq. (10) or Eq. (11). After learning, the student network output closely followed the target in the open-loop setting, accompanied by a substantial reduction of the open-loop MSE loss (\(c(t)=0\)) and the surrogate loss \(\) over the course of training (Fig. 4c). Finally, we observed that the linear threshold learning rule resulted in comparable performance to the exact inverse learning rule. Thus, an inhibitory modulated Hebbian learning rule is capable of solving a nonlinear learning task when credit is relayed through local dis-inhibitory microcircuits acting as feedback controller.

### Training multi-layer networks on classification tasks through dis-inhibitory control

Having confirmed that our learning rule is capable of error-driven learning through minimization of control on a simple continuous-time learning task, we wondered whether we could train a multi-layer perceptron (MLP) on standard image classification tasks. To that end, we implemented a MLP with excitatory-inhibitory microcircuit units. Networks were comprised of either one or three hidden layers

Figure 4: Online learning using dis-inhibitory control of Hebbian plasticity in a student-teacher task. **(a)** A teacher network (left) of size 30-20-2 implements a nonlinear mapping from an array of input sine waves \((t)\) (bottom) to an output target \(f((t))\). A student network (right) of the same size learns to approximate the teacher function by minimizing the control signal \(_{i}(t)\) of a dis-inhibitory feedback controller at each layer. **(b)** One example teacher output neuron (black) and the corresponding student neuron (teal) before and after learning. The yellow bar indicates when feedback control is active. **(c)** MSE loss \(\) and least control loss \(\) over time for student networks trained with the exact update rule derived in Eq. (10) and the linear threshold rule (Eq. (11)).

and used a parameterized soft rectifier activation function for all units. Numerical integration was performed using a fifth-order Runge-Kutta method with an adaptive step size to allow the network to reach an equilibrium state for each input (see Appendix C for details). Networks were trained either with the exact inverse rule in Eq. (10), or the linear threshold rule (Eq. (11)). To make training more robust and less dependent on initialization, the linear approximation of the inverse function was obtained through first-order Taylor expansion around a neuron-specific parameter \(}_{i}\) which tracked the average inhibitory firing rate across each batch (see Appendix C). With these settings we trained the networks on MNIST  and Fashion-MNIST . For comparison, we also trained conventional MLPs with the same neuron numbers but strictly feed-forward connectivity using BP.

We observed that networks trained using dis-inhibitory control with the exact inverse learning rule performed almost on par with standard BP on both datasets (Table 1). Using the linear threshold rule led to a slight drop in accuracy in all cases. It is possible that this gap could be narrowed further by choosing different linearization parameters \(}_{i}\) since the performance of the exact inverse rule suggests that improving the approximation of the error translates to higher accuracy.

In above simulations, the Jacobian used for calculating the feedback signals is input-dependent and feedback weights are thus different for each stimulus. In neurobiology, feedback would presumably be relayed via synaptic connections that do not change this rapidly. To test whether successful learning is possible with more slowly varying feedback weights we repeated the above simulations with feedback weights that slowly tracked the average Jacobian (see Appendix C). This change did not compromise learning, although it resulted in a small but noticeable drop in accuracy compared to the ideal data-dependent Jacobian (Table 1). In summary, the combination of dis-inhibitory control with a Hebbian learning rule with an inhibition-dependent threshold allows training MLPs on vision datasets such as MNIST and Fashion-MNIST to accuracy values close to networks trained with BP.

## 6 Discussion

In this article, we introduced a Hebbian learning rule with an inhibition-dependent threshold, which, through dis-inhibitory microcircuit dynamics, allows top-down feedback to control the sign of plasticity. Notably, the learning rule captures essential aspects of classic phenomenological Hebbian plasticity models under simulated experimental conditions disrupting recurrent inhibition in the local microcircuit. In contrast to standard Hebbian plasticity models, our model is stable when recurrent inhibition is intact without requiring additional homeostatic or compensatory mechanisms. Finally, we show how dis-inhibitory control is sufficient to train MLPs on vision tasks with performance levels close to classical BP.

**Dis-inhibitory control reconciles error-based learning with classic Hebbian plasticity models.** The learning rule we put forward in this article has a postsynaptic plasticity threshold \(\) (cf. Eq. (11)), a neuron-specific parameter potentially subject to its own temporal dynamics. This threshold makes it reminiscent of the BCM rule . Moreover, our model extends classic plasticity models by an explicit dependence on inhibition, which adds a dynamic, rapidly evolving component to the plasticity threshold. We derived this dual-threshold mechanism within a normative minimization-of-control objective. Its functional role is to decode a credit signal, relayed through dis-inhibitory afferents, from changes in the inhibitory current. Notably, the inhibitory threshold in our model confers an additional helpful property in that it induces a rapid compensatory plasticity mechanism that prevents

    & &  &  \\  Number of hidden layers & 1 & 3 & 1 & 3 \\   Backprop & & \(98.1 0.2\) & \(98.3 0.1\) & \(89.3 0.3\) & \(89.4 0.2\) \\  Dis-inhibitory control &  Exact inverse \\ Linear threshold \\  & \(97.7 0.2\) & \(98.0 0.2\) & \(89.1 0.2\) & \(89.1 0.2\) \\   &  Exact inverse \\ Linear threshold \\  & \(97.1 0.1\) & \(96.5 0.1\) & \(87.6 0.4\) & \(86.8 0.2\) \\   & 
 Exact inverse (Avg \(\)) \\ Linear threshold \\  & \(97.8 0.1\) & \(97.0 1.5\) & \(88.7 1.8\) & \(88.2 0.5\) \\   

Table 1: Test accuracy in % for networks trained with BP or dis-inhibitory feedback control. Reported values are mean \(\)stdev (\(n=10\)). For validation accuracy see Appendix C.

pathological runaway LTP, usually associated with Hebbian plasticity, through recurrent inhibition and in the absence of top-down control signals or any additional homeostatic mechanisms. Theoretical studies have argued that such a stabilizing mechanism for high firing rates should exist to counteract the runaway potentiation of Hebbian plasticity .

Experimentally testable predictions.Our model puts forth several testable predictions. First, we anticipate a direct modulation of plasticity induction through inhibitory currents in conventional excitatory long-term plasticity induction protocols. We predict that postsynaptic plasticity thresholds  should be influenced by inhibitory current injection, even when the postsynaptic activity is kept constant in experiments. Most plasticity experiments proceed in the presence of GABA antagonists or sodium channel blockers, which may obscure the direct impact of inhibition on the plasticity threshold. Nevertheless, abundant experimental evidence supports the idea that inhibition influences classic induction protocols at excitatory synapses  and that GABAergic afferents can switch the sign of plasticity . Second, our model suggests that blocking dis-inhibitory circuits during an error-based learning paradigm should block or influence learning. Consistent with this hypothesis, dis-inhibitory microcircuits have been implicated with the gating of plasticity and behaviorally relevant learning in the Amygdala , Hippocamp , and sensory cortices  (for a review, see ). Conversely, activating the same circuitry should affect or trigger learning during specific tasks.

Limitations.Several limitations should be considered when interpreting this study's results. First, while our learning rule minimizes the loss, it does not necessarily follow the negative gradient. This difference could lead to sub-optimal learning dynamics and we will explore its impact in future work.

Moreover, our circuit model requires specific one-to-one connectivity between excitatory and inhibitory interneurons that is inconsistent with circuit motifs observed in the brain. In biological microcircuits, excitatory neurons usually exceed the number of inhibitory neurons , and inhibitory interneurons typically provide inputs to many local excitatory cells and vice versa. Nevertheless, it may be possible to consider our model's inhibitory threshold (cf. Eq. (11)) as a local inhibitory current derived from multiple presynaptic targets. In this scenario, the challenge for excitatory neurons is to estimate their respective contribution to the inhibitory current they receive. In future work, we will explore the possibility of learning an estimate of the expected inhibitory current by implementing inhibitory plasticity to achieve an excitatory-inhibitory balanced state  and its co-dependence with excitatory plasticity . Inhibitory plasticity and its interactions with excitatory plasticity is supported by experiments  and has been the focus of recent computational models . However, neither of these studies explored the functional relevance of co-dependent plasticity for credit assignment and circuit-level learning.

Finally, the present model does not adhere to Dale's law in synaptic connections between hidden layers or the feedback pathway. Instead, we integrated the local population of dis-inhibitory interneurons into the dynamics of a top-down controller that modifies inhibitory activity bidirectionally. Biologically, this could be achieved through high baseline firing rates of dis-inhibitory interneurons or top-down feedback connections that target inhibitory interneurons directly . In future work, we will explore detailed cortical architectures for dis-inhibitory feedback controllers that allow bi-directional modulation.

In summary, we made the first step to reconcile realistic circuit models and phenomenological plasticity rules with normative theories relying on error-modulated plasticity to solve the credit assignment problem. Specifically, we showed how top-down feedback signals targeting specific interneurons could efficiently modulate neuronal activity _and_ plasticity. Our results highlight the potential of learning algorithms beyond BP, showcase their ability to incorporate diverse plasticity phenomena observed in neurobiology, and open the door for exciting future research.