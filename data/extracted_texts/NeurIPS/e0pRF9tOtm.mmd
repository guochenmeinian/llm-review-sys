# Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks

Private (Stochastic) Non-Convex Optimization Revisited: Second-Order Stationary Points and Excess Risks

 Arun Ganesh

Google Research

arunganesh@google.com

&Daogao Liu

University of Washington

dgliu@uw.edu

&Sewoong Oh

University of Washington and Google Research

sewoong@cs.washington.edu

&Abhradeep Thakurta

Google DeepMind

athakurta@google.com

Most of this work was done while the author was an intern at Google.

###### Abstract

We reconsider the challenge of non-convex optimization under differential privacy constraint. Building upon the previous variance-reduced algorithm SpiderBoost, we propose a novel framework that employs two types of gradient oracles: one that estimates the gradient at a single point and a more cost-effective option that calculates the gradient difference between two points. Our framework can ensure continuous accuracy of gradient estimations and subsequently enhances the rates of identifying second-order stationary points. Additionally, we consider a more challenging task by attempting to locate the global minima of a non-convex objective via the exponential mechanism without almost any assumptions. Our preliminary results suggest that the regularized exponential mechanism can effectively emulate previous empirical and population risk bounds, negating the need for smoothness assumptions for algorithms with polynomial running time. Furthermore, with running time factors excluded, the exponential mechanism demonstrates promising population risk bound performance, and we provide a nearly matching lower bound.

## 1 Introduction

Differential privacy  is a standard privacy guarantee for training machine learning models. Given a randomized algorithm \(:P^{*} R\), where \(P\) is a data domain and \(R\) is a range of outputs, we say \(\) is \((,)\)-differentially private (DP) for some \( 0\) and \(\) if for any neighboring datasets \(,^{} P^{*}\) that differ in at most one element and any \( R\), the distribution of the outcome of the algorithm, e.g., pair of models trained on the respective datasets, are similar:

\[_{x()}[x] e^{ }_{x(^{})}[x ]+.\]

Smaller \(\) and \(\) imply the distributions are closer; hence, an adversary accessing the trained model cannot tell with high confidence whether an example \(x\) was in the training dateset. Given this measure of privacy, we consider the problem of optimizing a non-convex loss while ensuring a desired level of privacy. In particular, suppose we are given a dataset \(=\{z_{1},,z_{n}\}\) drawn i.i.d. from underlying distribution \(\). Each loss function \(f(;z):\) is \(G\)-Lipschitz over the convex set \(^{d}\) of diameter \(D\). Let the population risk function be \(F_{}(x):=_{z}[f(x;z)]\) and the empirical risk function be \(F_{}(x):=_{z}f(x;z)\). We also denote \(F_{S}(x):=_{z S}f(x;z)\) for \(S\).

Our focus is in minimizing non-convex (empirical and population) risk functions, which may have multiple local minima. Since finding the global optimum of a non-convex function can be challenging, an alternative goal in the field is to find stationary points: A first-order stationary point is a point with a small gradient of the function, and a second-order stationary point is a first-order stationary point where additionally the function has a positive or nearly positive semi-definite Hessian. As first order stationary points can be saddle points or even a local maximum, we focus on the problem of finding a second order stationary point, i.e., a local minimum, privately. Existing works in finding approximate SOSP privately only give guarantees for the empirical function \(F_{}\). We improve upon the state-of-the-art result for empirical risk minimization and give the first guarantee for the population function \(F_{}\). This requires standard assumptions on bounded Lipschitzness, smoothness, and Hessian Lipschitzness, which we make precise in Section 2 and in Assumption 3.1.

Compared to finding a local minimum, finding a global minimum can be extremely challenging. We also present two methods, polynomial and exponential time, that outperform existing guarantees measured in excess risks for respective computational complexities. Our primary results are succinctly summarized in Table 1.

Related Work.We propose a novel and simple framework based on SpiderBoost , and its private version  that achieves the current best rate for finding the first order stationary point privately. We discuss the primary difference between our framework and theirs, that is their algorithms only promise small gradient estimation errors on average, but our framework can ensure small estimation errors consistently throughout all the iterations, and the motivation behind this briefly.

In SGD and its variants, the typical approach involves obtaining an estimation \(_{t}\) of the gradient \( f(x_{t})\). In the stochastic variance-reduced algorithm SpiderBoost , it queries the gradient \(_{1}(x_{t}) f(x_{t})\) directly every \(q\) steps with some oracle \(_{1}\), and for the other \(q-1\) steps within each period, it queries the gradient difference between two steps, that is \(_{2}(x_{t},x_{t-1}) f(x_{t})- f(x_{t-1})\), and maintain \(_{t}=_{t-1}+_{2}(x_{t},x_{t-1})\). The contrast between these two types of oracles can be perceived as \(_{1}\) being more accurate but also more costly, in terms of computation or privacy budget, although our framework does not strictly necessitate this assumption.

As SpiderBoost queries \(_{1}\) every \(q\) steps, the error on the estimation may accumulate and \(\|_{t}- f(x_{t})\|\) can become large. Despite this, as demonstrated in , these estimations can, on average, suffice to find a private FOSP. However, such large deviations pose a challenge when scrutinizing behavior near a saddle point. For instance, when the current point is a saddle point, but the current estimation is unsatisfactory, it becomes uncertain whether the algorithm can escape the saddle point. It could be argued that average good estimations could achieve a SOSP, but to the best of our knowledge, there is no existing result addressing this concern.

A plausible solution to this challenge is to maintain high-quality gradient estimations throughout all iterations, a feat accomplished by our framework. We believe this feature holds promise for improving the outcomes of various other optimization problems, thus enhancing the overall appeal and significance of our work.

### Main Results

Sosp.One of our main contributions is a refined optimization framework (Algorithm 1), predicated on the variance-reduced SpiderBoost , which guarantees consistently accurate gradient estimations. By integrating this framework with private gradient oracles, we achieve improved error rates for privately identifying SOSP of both empirical and population risks.

Advances in private non-convex optimization have focused on finding a first-order stationary point (FOSP), whose performance is measured in (\(i\)) the norm of the empirical gradient at the solution \(x\), i.e., \(\| F_{}(x)\|\), and (\(ii\)) the norm of the population gradient, i.e., \(\| F_{}(x)\|\). We survey the recent progress in the appendix in detail.

**Definition 1.1** (First-order stationary point).: _We say \(x^{d}\) is a First-Order Stationary Point (FOSP) of \(g:^{d}\) iff \( g(x)=0\). \(x\) is an \(\)-FOSP of g, if \(\| g(x)\|_{2}\)._

Since FOSP can be a saddle point or a local maxima, finding a second-order stationary point is desired. Exact second-order stationary points can be extremely challenging to find . Instead, progress is commonly measured in terms of how well the solution approximates an SOSP.

**Definition 1.2** (Second-order stationary point, ).: _We say a point \(x^{d}\) is a Second-Order Stationary Point (SOSP) of a twice differentiable function \(g:^{d}\) iff \(\| g(x)\|_{2}=0\) and \(^{2}g(x) 0\). We say \(x^{d}\) is an \(\)-SOSP for \(\)-Hessian Lipschitz function \(g\), if \(\| g(x)\|_{2}\ \ ^{2}g(x)-I\)._

On the empirical risk \(F_{}\), the SOTA on privately finding \(\)-SOSP is by , which achieves \(=(\{(/n)^{1/2},(d/n)^{4/7}\})\). In Theorem 4.2, we show that applying the proposed Algorithm 1 achieves a rate bounded by \(=((/n)^{2/3})\), which improves over the SOTA in all regime.2 There remains a factor \((/n)^{-1/6}\) gap to a known lower bound of \(=(/n)\) that holds even if finding only an \(\)-FOSP . On the population risk \(F_{}\), applying Algorithm 1 with appropriate private gradient oracles is the first private algorithm to guarantee finding an \(\)-SOSP with \(=(n^{-1/3}+(/n)^{3/7})\) in Theorem 4.6. There is a gap to a known lower bound of \(=(1/+/n)\) that holds even if finding only an \(\)-FOSP .

Minimizing Excess Risk.In addition to the optimization framework, we present sampling-based algorithms designed to identify a private solution \(x^{priv}^{d}\) that minimizes both the excess empirical risk: \([F_{}(x^{priv})]-_{x}F_{}(x)\), and the excess population risk: \([F_{}(x^{priv})]-_{x}F_{}(x)\). Here, the expectation is over the randomness of the solution \(x^{priv}\) and the drawing of the training date over \(\). Our method is different from , which Gradient Langevin Dynamics and achieves in polynomial time a bound of \(O(d/(^{2} n))\) for both excess empirical and population risks with a need for the smoothness assumption. In Table 1 we omit excess empirical risk, as the bounds align with those of the population risk. We introduce a sampling-based algorithm from the exponential mechanism, which runs in polynomial time and achieves excess empirical and population risks bounded by \(O(d/((nd)))\) with improved dependence on \(\) (Theorem 5.6). Crucially, it achieves these results without the need for the smoothness assumption required by .

In the case of permitting an exponential running time,  demonstrated \((d/( n))\) upper bound for non-convex excess empirical risks alongside a nearly matching lower bound. However, establishing a tight bound for the excess population risk remained an unresolved problem. We address this open question by providing nearly matching upper and lower bounds of \((d/( n)+)\) for the excess population risk (Theorem 5.8).

### Our Techniques

Stationary Points.In our framework, we deviate from the traditional approach of querying \(_{1}\) once every \(q\) steps. Instead, we introduce a novel but simple method of monitoring the total drift we make, that is \(_{t}=_{i=_{t}}^{t}\|x_{i}-x_{i-1}\|_{2}^{2}\), where \(_{t}\) represents the last timestamp when we employed \(_{1}\). As we are considering smooth functions, the maximum error to estimate \( f(x_{t})- f(x_{t-1})\)

   &  &  \\  & empirical & population & poly-time & exp-time \\  SOTA & \((}}{n^{}^{}},}}{n^{}^{}})\) & N/A & \( n}\) & N/A \\ Ours & \(}}{n^{}^{}}\) & \(}}+(}{n})^{ {3}}\) & \(\) & \(+}\) \\ LB & \(}{n}\) & \(}+}{n}\) & \(+}\) & \(+}\) \\  

Table 1: SOTA refers to the best previously known bounds on \(\) for \(\)-SOSP by  and on the excess population risk by . We introduce algorithm 1 that finds an \(\)-SOSP (columns \(2\)–\(3\)) with an improved rate. We show exponential mechanism can minimize the excess risk in polynomial time and exponential time, respectively (columns \(4\) and \(5\)). \(\) requires extra assumption on bounded smoothness. The lower bounds for SOSP are from , and the lower bound on excess population risk is from Theorem 5.11. We omit logarithmic factors in \(n\) and \(d\) except the upper bounds for excess population risk with polynomial time.

is proportional to \(\|x_{t}-x_{t-1}\|_{2}\). If the value \(_{t}\) is small, we know the current estimation should still be good enough, eliminating the need for an expensive fresh estimation from \(_{1}\). Conversely, when \(_{t}\) is large, the gradient estimation error may be substantial, necessitating a query to \(_{1}\) and thus obtaining \(_{t}=_{1}(x_{t})\). To effectively manage the total cost, it is crucial to set an appropriate threshold to decide when the drift is significant. A smaller threshold would ensure more accurate estimations but might incur higher costs due to more frequent queries to \(_{1}\).

Our aim is to bound the total occurrences of the event that \(_{t}\) is large, which leads to querying \(_{1}\). A crucial observation is that, if \(_{t}\) increases rapidly, then the gradient norms are large and hence function values decrease quickly, which we know does not happen frequently under the standard assumption that the function is bounded.

In our framework, we assume \(_{1}(x)\) is an unbiased estimation of \( f(x)\), and \(_{1}(x)- f(x)\) is Norm-SubGaussian (Definition 2.2), and similarly \(_{2}(x,y)\) is an unbiased estimation of \( f(x)- f(y)\) whose error is also Norm-SubGaussian. In the empirical case, we can simply add Gaussian noises with appropriately chosen variances to the gradients of the empirical function \( F_{}\) for simplicity, and one can choose a smaller batch size to reduce the computational complexity. In the population case, we draw samples from the dataset without replacement to avoid dependence issues, and add the Gaussian noises to the sampled gradients. Hence we only need the gradient oracle complexity to be linear in the size of dataset for the population case.

Minimizing Excess Risk.Our polynomial time approach harnesses the power of the Log-Sobolev Inequality (LSI) and the classic Stroock perturbation lemma. The previous work of  shows that if the density \(- F_{}(x)-r(x)\) satisfies the LSI for some regularizer \(r\), then sampling a model \(x\) from this density is DP with an appropriate \((,)\). If \(r\) is a \(\) strongly convex function, then the density proportional to \((-r)\) satisfies LSI with constant \(1/\), and \((- F_{}(x)-r(x))\) satisfies LSI with constant \((_{x,y}|F_{}(x)-F_{}(y)|)/\) by the Stroock perturbation lemma. Our bound on the empirical risk follows from choosing the appropriate inverse temperature \(\) and regularizer \(r\) to satisfy \((,)\)-DP. The final bound on the population risk also follows from LSI, which bounds the stability of the sample drawn from the respective distribution.

When running time is not a priority, we employ an exponential mechanism over a discretization of \(\) to establish the upper bound. The empirical risk bound derives from , and we leverage the concentration of sums of bounded random variables to bound the maximum difference over the discretizations between the empirical and population risk. We show this is nearly tight by reductions from selection to non-convex Lipschitz optimization of .

### Organization

In Section 2, we present necessary definitions and backgrounds for our work. In Section 3, we construct the optimization framework, with guarantees on finding the SOSP with two different kinds of SubGaussian gradient oracles. It's crucial to note that this framework focuses solely on optimization and does not pertain to privacy. Section 4 explores the pursuits of finding the SOSP privately by constructing private SubGaussian gradient oracles and seamlessly integrating them into the existing framework. We bound the private excess bounds in Section 5. For other preliminaries, all omitted proofs and some further discussions on related work can be found in the Appendix.

## 2 Preliminaries

Throughout the paper, if not stated explicitly, the norm \(\|\|\) means the \(_{2}\) norm.

**Definition 2.1** (Lipschitz, Smoothness and Hessian Lipschitz).: _Given a function \(f:\), we say \(f\) is \(G\)-Lipschitz, if for all \(x_{1},x_{2}\), \(|f(x_{1})-f(x_{2})| G\|x_{1}-x_{2}\|\), we say a function \(f\) is \(M\)-smooth, if for all \(x_{1},x_{2}\), \(\| f(x_{1})- f(x_{2})\| M\|x_{1}-x_{2}\|\), and we say the function \(f\) is \(\)-Hessian Lipschitz, if for all \(x_{1},x_{2}\), we have \(\|^{2}f(x_{1})-^{2}f(x_{2})\|\|x_{1}-x_{2}\|\)._

**Definition 2.2** (SubGaussian, and Norm-SubGaussian).: _A random vector \(x^{d}\) is SubGaussian (\(()\)) if there exists a positive constant \(\) such that \(\,e^{ v,x-\,x} e^{\|v\|^{2}^{2}/2}, \;\; v^{d}.\;x^{d}\) is norm-SubGaussian (\(()\)) if there exists \(\) such that \([\|x-\,x\| t] 2e^{-}{2^{2}}}, t \)._

**Fact 2.3**.: _For a Gaussian \((0,^{2}I_{d})\), \(\) is \(()\) and \(()\)._

**Lemma 2.4** (Hoeffding type inequality for norm-subGaussian, ).: _Let \(x_{1},,x_{k}^{d}\) be random vectors, and for each \(i[k]\), \(x_{i}_{i-1}\) is zero-mean \((_{i})\) where \(_{i}\) is the corresponding filtration. Then there exists an absolute constant \(c\) such that for any \(>0\), with probability at least \(1-\), \(\|_{i=1}^{k}x_{i}\| c^{k}_{i}^{2}(2d/ )}\), which means \(_{i=1}^{k}x_{i}\) is \((\,_{i=1}^{k}_{i}^{2})\)._

## 3 Convergence to Stationary Points: Framework

We present the optimization framework for finding SOSP in this section. It's important to emphasize that this framework is dedicated exclusively to optimization concerns, with privacy considerations being outside of its purview. The results about SOSP throughout the paper follows the assumptions of .

**Assumption 3.1**.: _Any function drawn from \(\) is \(G\)-Lipschitz, \(\)-Hessian Lipschitz, and \(M\)-smooth, almost surely, and the risk is upper bounded by \(B\)._

As discussed before, we define two different kinds of gradient oracles, one for estimating the gradient at one point and the other for estimating the gradient difference at two points.

**Definition 3.2** (SubGaussian gradient oracles).: _For a \(G\)-Lipschitz and \(M\)-smooth function \(F\):_

\((1)\) _We say \(_{1}\) is a first kind of \(_{1}\) norm-subGaussian Gradient oracle if given \(x^{d}\), \((x)\) satisfies \(\,_{1}(x)= F(x)\) and \(_{1}(x)- F(x)\) is \((_{1})\)._

\((2)\) _We say \(_{2}\) is a second kind of \(_{2}\) norm-subGaussian stochastic Gradient oracle if given \(x,y^{d}\), \(_{2}(x,y)\) satisfies that \(\,_{2}(x,y)= F(x)- F(y)\) and \(_{2}(x,y)-( F(x)- F(y))\) is \((_{2}\|x-y\|)\)._

Note that we should assume \(M\) to make finding a second-order stationary point strictly more challenging than finding a first-order stationary point. We use \(()\) to denote the smallest eigenvalue of a matrix.

```
1:Input: Objective function \(F\), Gradient Oracle \(_{1},_{2}\) with SubGaussian parameters \(_{1}\) and \(_{2}\), parameters of objective function \(B,M,G\), \(\), parameter \(\), failure probability \(\)
2: Set \(=^{2}+4_{1}^{2})(BMd/)}, =)}{}\)
3: Set \(=1/M,t=0,T=BM^{4}()/^{2}\)
4: Set \(_{0}=,=1,_{-1}=0\)
5:while\(t T\)do
6:if\(\|_{t-1}\|^{3}(BMd/)_{t-1} 0\)then
7:\(_{t}=,_{t}=0\)
8:\(_{t}=_{1}(x_{t})+g_{t}\), where \(g_{t}(0,^{2}}{d}I_{d})\)
9:elseif\(_{t-1}\)then
10:\(_{t}=_{1}(x_{t})\), \(_{t}=0\), \(_{t}=_{t-1}-1\)
11:else
12:\(_{t}=_{2}(x_{t},x_{t-1})\), \(_{t}=_{t-1}+_{t}\), \(_{t}=_{t-1}-1\)
13:endif
14:\(x_{t+1}=x_{t}-_{t},_{t+1}=_{t}+^{2} \|_{t}\|_{2}^{2}\), \(t=t+1\)
15:endwhile
16:Return:\(\{x_{1},,x_{T}\}\) ```

**Algorithm 1** Stochastic Spider

Inspired by  who adapted the SpiderBoost algorithm for finding private FOSPs, we give a framework based on the SpiderBoost in Algorithm 1. Our analysis of Algorithm 1 hinges on three key properties we establish in this section: (\(i\)) \(_{t}\) remains consistently close to the true gradient \( F(x_{t})\) with high probability; (\(ii\)) the algorithm is capable of escaping the saddle point with high probability, and (\(iii\)) a large \(\) implies significant decrease in the function value, which enables us to limit the number of queries to the more accurate but costlier first kind of gradient oracle \(_{1}\).

**Lemma 3.3**.: _For any \(0 t T\) and letting \(_{t} t\) be the largest integer such that \(_{_{t}}\) is set to be 0, with probability at least \(1-/T\), for some universal constant \(C>0\), we have_

\[\|_{t}- F(x_{t})\|^{2}_{2}^{2}_{i=_{t }+1}^{t}\|x_{i}-x_{i-1}\|^{2}+4_{1}^{2} C(Td/).\] (1)

_Hence with probability at least \(1-\), we know for each \(t T\), \(\|_{t}- F(x_{t})\|^{2}^{2}/16\), where \(^{2}:=16C(_{2}^{2}+4_{1}^{2})(Td/)\) and \(\) is a parameter we can choose in the algorithm._

As shown in Lemma 3.3, the error on the gradient estimation for each step is bounded with high probability. Then by adding the Gaussian noise in Line 8, we can show the algorithm can escape the saddle point efficiently based on previous results.

**Lemma 3.4** (Essentially from ).: _Under Assumption 3.1, run SGD iterations \(x_{t+1}=x_{t}-_{v}\), with step size \(=1/M\). Suppose \(x_{0}\) is a saddle point satisfying \(\| F(x_{0})\|\) and \(}(^{2}F(x_{0}))-\), \(=^{3}(dBM/)\). If \(_{0}= F(x_{0})+_{1}+_{2}\) where \(\|_{1}\|\), \(_{2}(0,}{d(d/)}I_{d})\), and \(\|_{t}- F(x_{t})\|\) for all \(t[]\), with probability at least \(1-(1/)\), one has \(F(x_{})-F(x_{0})-}{^{ 3}()},\) where \(=)}{}\)._

We discuss this lemma in the Appendix in more details. The next lemma is standard, showing how large the function values can decrease in each step.

**Lemma 3.5**.: _By setting \(=1/M\), we have \(F(x_{t+1}) F(x_{t})+\|_{t}\|\| F(x_{t})-_{t}\| -\|_{t}\|^{2}\). Moreover, with probability at least \(1-\), for each \(t T\) such that \(\| F(x_{t})\|\), we have_

\[F(x_{t+1})-F(x_{t})-\|_{t}\|^{2}/6-^{2}/6.\]

With the algorithm designed to control the \(\) term, the guarantee for Stochastic Spider to find the second order stationary point is stated below:

**Lemma 3.6**.: _Suppose \(_{1}\) and \(_{2}\) are \(_{1}\) and \(_{2}\) norm-subGaussian respectively. If one sets \(=O(1)^{2}+4_{1}^{2})(Td/)}\), with probability at least \(1-\), at least one point in the output set \(\{x_{1},,x_{T}\}\) of Algorithm 1 is \(\)-SOSP, where_

\[=^{3}(BMd/)=^{2}+4 _{1}^{2})(^{2}+_{1}^{2}}) ^{3}(^{2}+_{1}^{2})})}.\]

As mentioned before, we can bound the number of occurrences where the \(\) gets large and hence bound the total time we query the oracle of the first kind.

**Lemma 3.7**.: _Under the event that \(\|_{t}- F(x_{t})\|/4\) for all \(t[T]\) and our parameter settings, letting \(K=\{t[T]:_{t}\}\) be the set of iterations where the drift is large, we know \(|K| O+T^{2}^{2}/=O B^{4}()/.\)_

## 4 Private SOSP

We adopt the framework before and get our main results on finding SOSP privately by constructing private gradient oracles in this section. Finding SOSP for empirical risk function \(F_{}\) and for population risk function \(F_{}\) are discussed in Subsection 4.1 and Subsection 4.2 respectively.

### Convergence to the SOSP of the Empirical Risk

We use Stochastic Spider to improve the convergence to \(\)-SOSP of the empirical risk, and aim at getting \(=(d^{1/3}/n^{2/3})\). We use the full-batch size for simplicity, and use the gradient oracles

\[_{1}(x):= F_{}(x)+g_{1},_{2}(x,y):= F_{}(x)- F_{ }(y)+g_{2},\] (2)

where \(g_{1}(0,_{1}^{2}I_{d})\) and \(g_{2}(0,_{2}^{2}\|x-y\|_{2}^{2}I_{d})\) are added to ensure privacy by Gaussian mechanism (in Appendix).

[MISSING_PAGE_FAIL:7]

**Lemma 4.5**.: _Fix a point \(x^{d}\). Given a set \(S\) of \(m\) samples drawn i.i.d. from the distribution \(\), then we know with probability at least \(1-\), we have_

\[\| F_{S}(x)- F_{}(x)\|_{2} O}\|^{2}F_{S}(x)-^{2}F_{}(x)\|_{op} O}.\]

By choosing the appropriate noise scales \(_{1}\) and \(_{2}\) to ensure the privacy guarantee, we can bound the population bound similar to the empirical bound with these tools.

**Theorem 4.6** (Population).: _Divide the dataset \(\) into two disjoint datasets \(_{1}\) and \(_{2}\) of size \( n/2\) and \( n/2\) respectively. Set \(b_{1}=,b_{2}=^{2}}{BM},_{1}= {G}{b_{1}},_{2}=}\) and \(=(B^{1/3}^{1/3}d}{M^{5/3}}n^{-1/3},( }{M^{5/3}})^{6/7}(}{n})^{4/7})\) in Equation (3) and use them as gradient oracles. Running Algorithm 1 with \(_{1}\), and outputting the set \(\{x_{i}\}_{i[T]}\) if the total time to query \(_{1}\) is bounded by \(O(B^{4}()/)\), otherwise outputting a set of \(T\) arbitrary points, is \((/2)\)-zCDP, and with probability at least \(1-\), at least one point in the output is \(_{1}\)-SOSP of \(F_{}\) with_

\[_{1}=O(BGM d)^{1/3}}+(G^{1/7}B^{ 3/7}M^{3/7})(}{n})^{3/7}^{3}(nBMd/ ).\]

_Moreover, if we run Algorithm 2 with inputs \(\{x_{i}\}_{i[T]},_{2},B,M,G,,_{1}\), \(=\) with probability at least \(1-\), Algorithm 2 can output an \(_{2}\)-SOSP of \(F_{}\) with \(_{2}=O(_{1}+(n ,n^{1/2})}}+G(}+})).\) The whole procedure is \(\)-zCDP._

## 5 Bounding the Private Excess Risk

In this section, we shift our focus from "second-order" guarantees to "zeroth-order" guarantees, and consider the problem of getting good private risk bounds without convexity.

### Polynomial Time Approach

If we want the algorithm to be efficient and implementable in polynomial time, to our knowledge the only known bound is \(O( n})\) in  for smooth functions.  used Gradient Langevin Dynamics, a popular variant of SGD to solve this problem, and prove the privacy by advanced composition . We generalize the exponential mechanism to the non-convex case and implement it without a smoothness assumption.

First recall the Log-Sobolev inequality: We say a probability distribution \(\) satisfies LSI with constant \(C_{ LSI}\) if for all \(f:^{d}\), \(_{}[f^{2} f^{2}]-_{}[f^{2}]_{}[ f^{2}] 2C_{ LSI}\,_{}\,\| f\|_{2}^{2}\). A well-known result () says if \(f\) is \(\)-strongly convex, then the distribution proportional to \((-f)\) satisfies LSI with constant \(1/\). Recall the results from previous results  about LSI and DP:

**Theorem 5.1** ().: _Sampling from \((- F(x;)-r(x))\) for some public regularizer \(r\) is \((,)\)-DP, where \( 2\,},\) and \(C_{ LSI}\) is the worst LSI constant._

We can apply the classic perturbation lemma to get the new LSI constant in the non-convex case. Suppose we add a regularizer \(\|x\|^{2}\), and try to sample from \((-(F(x;)+\|x\|^{2}))\).

**Lemma 5.2** (Stroock perturbation).: _Suppose \(\) satisfies LSI with constant \(C_{ LSI}()\). If \(0<c^{}}{} C\), then \(C_{ LSI}(^{})C_{ LSI}()\)._

Lemma 5.3 is a more general version of Theorem 3.4 in  and can be used to bound the empirical risk.

**Lemma 5.3**.: _Let \((x)(-(F_{}(x)+\|x\|_{2}^{2}))\). Then for \( GD>d\), we know_

\[}_{x}(F_{}(x)+\|x\|_{2}^{2})- _{x^{*}}(F_{}(x^{*})+\|x^{*}\|_{2}^{2} )( GD/d)\]

We now turn to bound the generalization error, and use the notion of uniform stability:

**Lemma 5.4** (Stability and Generalization ).: _Given a dataset \(=\{s_{i}\}_{i[n]}\) drawn i.i.d. from some underlying distribution \(\), and given any algorithm \(\), suppose we randomly replace a sample \(s\) in \(\) by an independent fresh one \(s^{}\) from \(\) and get the neighboring dataset \(^{}\), then \(_{,}[F_{}(() )-F_{}(())]=_{,s^{ },}[f(();s^{}))-f(( ^{});s^{}))],\) where \(()\) is the output of \(\) with input \(\)._

As each function \(f(;s^{})\) is \(G\)-Lipschitz, it suffices to bound the \(W_{2}\) distance of \(()\) and \((^{})\). If \(\) is sampling from the exponential mechanism, letting \(_{}(-(F_{}(x)+\|x\|^{2}))\) and \(_{^{}}(-(F_{^{}}(x)+ \|x\|^{2}))\), it suffices to bound the \(W_{2}\) distance between \(_{}\) and \(_{^{}}\). The following lemma can bound the generalization risk of the exponential mechanism under LSI:

**Lemma 5.5** (Generalization error bound).: _Let \(_{}(-(F_{}(x)+\|x\|_{2}^ {2}))\). Then we have \(_{,_{}}[F_{}(x)-F_{ }(x)] O(( GD)}{n})\)._

We get the following results:

**Theorem 5.6** (Risk bound).: _We are given \(,(0,1/2)\). Sampling from \((-(F_{}(x)+\|x\|_{2}^{2}))\) with \(=O(}),=}\) is \((,)\)-DP. The empirical risk and population risk are bounded by \(O(GD}{(nd)})\)._

ImplementationThere are multiple existing algorithms that can sample efficiently from density with LSI, under mild assumptions. For example, when the functions are smooth or weakly smooth, one can turn to the Langevin Monte Carlo , and . The algorithm in  also requires mild smoothness assumptions. We discuss the implementation of non-smooth functions in bit more details, which is more challenging.

We can adopt the rejection sampler in , which is based on the alternating sampling algorithm in . Both  and  are written in the language of log-concave and strongly log-concave densities, but their results hold as long as LSI holds. By combining them together, we can get the following risk bounds. The details of the implementation can be found in Appendix D.3.

**Theorem 5.7** (Implementation, risk bound).: _For \(,(0,1/2)\), there is an \((,2)\)-DP efficient sampler that can achieve the empirical and population risks \(O(GD}{(nd)})\). Moreover, in expectation, the sampler takes \((n^{3}^{3}(d)/(GD))\) function values query and some Gaussian random variables restricted to the convex set \(\) in total._

### Exponential Time Approach

In , it is shown that sampling from \((-F_{}(x))\) is \(\)-DP, and a nearly tight empirical risk bound of \(()\) is achieved for convex functions. It is open what is the bound we can get for non-convex DP-SO.

Upper BoundGiven exponential time we can use a discrete exponential mechanism as considered in . We recap the argument and extend it to DP-SO. The proof is based on a simple packing argument, and can be found in the Appendix.

**Theorem 5.8**.: _There exists an \(\)-DP differentially private algorithm that achieves a population risk of \(O(GD(d( n/d)/( n)+/()))\)._

Lower BoundResults in  imply that the first term of \((GDd/ n)\) is tight, even if we relax to approximate DP with \(>0\). A reduction from private selection problem shows the \(()\) generalization term is also nearly-tight (Theorem 5.11). In the selection problem, we have \(k\) coins, each with an unknown probability \(p_{i}\). Each coin is flipped \(n\) times such that \(\{x_{i,j}\}_{j[n]}\), each \(x_{i,j}\) i.i.d. sampled from \((p_{i})\), and we want to choose a coin \(i\) with the smallest \(p_{i}\). The risk of choosing \(i\) is \(p_{i}-_{i^{*}}p_{i^{*}}\).

**Theorem 5.9**.: _Any algorithm for the selection problem has excess population risk \((})\)._This follows from a folklore result on the selection problem (see e.g. ). We can combine this with the following reduction from selection to non-convex optimization:

**Theorem 5.10** (Restatement of results in ).: _If any \((,)\)-DP algorithm for selection has risk \(R(k)\), where \(R(k)\) is a function with \(k\) as variables, then any \((,)\)-DP algorithm for minimizing 1-Lipschitz losses over \(B_{d}(0,1)\) (the \(d\)-dimensional unit ball) has risk \(R(2^{(d)})\)._

From this and the aforementioned lower bounds in empirical non-convex optimization we get the following:

**Theorem 5.11**.: _For \( 1,[2^{-(n)},1/n^{1+(1)}]\), any \((,)\)-DP algorithm for minimizing \(1\)-Lipschitz losses over \(B_{d}(0,1)\) has excess population risk \(\{(d(1/)/( n)),()\}\)._

## 6 Discussion

In this paper, we gave improved bounds for finding SOSPs under differential privacy, as well as points with low population risk. We discuss some potential follow-up questions here.

First, there is still a gap between our upper bounds and the lower bounds of . Closing this gap is an interesting question and may lead to novel technical insights about private optimization. To obtain upper bounds for finding SOSP, both our work and the work of  uses the oracle of the second kind defined in Definition 3.2. Second, in typical private optimization work, only oracles of the first kind are used. It is possible that the oracle of the second kind is useful in private optimization problems besides finding stationary points, either in theory or practice. In particular, since this oracle has lower sensitivity, it may allow us to tolerate a higher noise level / lower privacy budget across multiple iterations. Third, we privatize the SpiderBoost in the work, and there are other versions of variance-reduced algorithms like Spiker and SARAH. It is interesting if our ideas can be used to privatize those algorithms, and compare their practical performance. Lastly, our polynomial-time excess population risk bounds have a \(O(1/ n)\) dependence on the dataset size, whereas for convex losses standard results have a \(\{1/,1/ n\}\) dependence. The stronger dependence is achievable under LSI, but the practical settings in which LSI holds without convexity holding seems limited. It remains an open question to find a practical assumption weaker than convexity that allows us to achieve better dependence on \(n\).

## 7 Acknowledgement

DG would like to thank Ruoqi Shen and Kevin Tian for several discussions.