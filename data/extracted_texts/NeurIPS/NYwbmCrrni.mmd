# Disambiguated Attention Embedding for

Multi-Instance Partial-Label Learning

 Wei Tang\({}^{1,2}\), Weijia Zhang\({}^{3}\), Min-Ling Zhang\({}^{1,2}\)

\({}^{1}\) School of Computer Science and Engineering, Southeast University, Nanjing 210096, China

\({}^{2}\) Key Laboratory of Computer Network and Information Integration (Southeast University),

Ministry of Education, China

\({}^{3}\) School of Information and Physical Sciences, The University of Newcastle,

Callaghan, NSW 2308, Australia

tangw@seu.edu.cn, weijia.zhang@newcastle.edu.au, zhangml@seu.edu.cn

Corresponding author

###### Abstract

In many real-world tasks, the concerned objects can be represented as a multi-instance bag associated with a candidate label set, which consists of one ground-truth label and several false positive labels. Multi-instance partial-label learning (MIPL) is a learning paradigm to deal with such tasks and has achieved favorable performances. Existing MIPL approach follows the instance-space paradigm by assigning augmented candidate label sets of bags to each instance and aggregating bag-level labels from instance-level labels. However, this scheme may be suboptimal as global bag-level information is ignored and the predicted labels of bags are sensitive to predictions of negative instances. In this paper, we study an alternative scheme where a multi-instance bag is embedded into a single vector representation. Accordingly, an intuitive algorithm named DeMipl, i.e., _Disambiguated attention Embedding for Multi-Instance Partial-Label learning_, is proposed. DeMipl employs a disambiguation attention mechanism to aggregate a multi-instance bag into a single vector representation, followed by a momentum-based disambiguation strategy to identify the ground-truth label from the candidate label set. Furthermore, we introduce a real-world MIPL dataset for colorectal cancer classification. Experimental results on benchmark and real-world datasets validate the superiority of DeMipl against the compared MIPL and partial-label learning approaches.

## 1 Introduction

Significant advancements in supervised machine learning algorithms have been achieved by utilizing large amounts of labeled training data. However, in numerous tasks, training data is weakly-supervised due to the substantial costs associated with data labeling . Weak supervision can be broadly categorized into three types: incomplete, inexact, and inaccurate supervision . Multi-instance learning (MIL) and partial-label learning (PLL) are typical weakly-supervised learning frameworks based on inexact supervision. In MIL, samples are represented by collections of features called bags, where each bag contains multiple instances . Only bag-level labels are accessible during training, while instance-level labels are unknown. Consequently, the instance space in MIL contains inexact supervision, signifying that the number and location of positive instances within a positive bag remain undetermined. PLL associates each instance with a candidate label set that contains one ground-truth label and several false positive labels . As a result, the label space in PLL embodies inexact supervision, indicating that the ground-truth label of an instance is uncertain.

However, inexact supervision can exist in instance and label space simultaneously, i.e., dual inexact supervision . This phenomenon can be observed in histopathological image classification, where an image is typically partitioned into a multi-instance bag [37; 38; 39; 40], and labeling ground-truth labels incurs high costs due to the need for specialized expertise. Consequently, utilizing crowd-sourced candidate label sets will significantly reduce the labeling cost . For this purpose, a learning paradigm called multi-instance partial-label learning (MIPL) has been proposed to work with dual inexact supervision. In MIPL, a training sample is represented as a multi-instance bag associated with a bag-level candidate label set, which comprises a ground-truth label along with several false positive labels. It is noteworthy that the multi-instance bag includes at least one instance that is affiliated with the ground-truth label, while none of the instances belong to any of the false positive labels.

Due to the difficulty in handling dual inexact supervision, to the best of our knowledge, MiplGp is the only viable MIPL approach. MiplGp learns from MIPL data at the instance-level by utilizing a label augmentation strategy to assign an augmented candidate label set to each instance, and integrating a Dirichlet disambiguation strategy with the Gaussian processes regression model . Consequently, the learned features of MiplGp primarily capture local instance-level information, neglecting global bag-level information. This characteristic renders MiplGp susceptible to negative instance predictions when aggregating bag-level labels from instance-level labels. As illustrated in Figure 1(a), identical or similar negative instances can simultaneously occur in multiple multi-instance bags with diverse candidate label sets, thereby intensifying the challenge of disambiguation.

In this paper, we overcome the limitations of MiplGp by introducing a novel algorithm, named DeMipl, i.e., _Disambiguated attention Embedding for Multi-Instance Partial-Label learning_, based on the embedded-space paradigm. Figure 1(b) illustrates that DeMipl aggregates each multi-instance bag into a single vector representation, encompassing all instance-level features within the bag. Furthermore, DeMipl effectively identifies the ground-truth label from the candidate label set.

Our contributions can be summarized as follows: First, we propose a disambiguation attention mechanism for learning attention scores in multi-instance bags. This is in contrast to existing attention-based MIL approaches that are limited to handling classifications with exact bag-level labels [13; 14; 43]. Second, we propose an attention loss function that encourages the attention scores of positive instances to approach one, and those of negative instances to approach zero, ensuring consistency between attention scores and unknown instance-level labels. Third, we leverage the multi-class attention scores to map the multi-instance bags into an embedded space, and propose a momentum-based disambiguation strategy to identify the ground-truth labels of the multi-instance bags from the candidate label sets. In addition, we introduce a real-world MIPL dataset for colorectal cancer classification comprising \(7000\) images distributed across seven categories. The candidate labels of this dataset are provided by trained crowdsourcing workers.

Experiments are conducted on the benchmark as well as real-world datasets. The experimental results demonstrate that: (a) DeMipl achieves higher classification accuracy on both benchmark and real-world datasets. (b) The attention loss effectively enhances the disambiguation attention mechanism, accurately discerning the significance of positive and negative instances. (c) The momentum-based disambiguation strategy successfully identifies the ground-truth labels from candidate label sets, especially in scenarios with an increasing number of false positive labels.

The remainder of the paper is structured as follows. First, we introduce DeMipl in Section 2 and present the experimental results in Section 3. Finally, we conclude the paper in Section 4.

Figure 1: A brief illustration of DeMipl, where \(\) and \(\) are candidate label sets and predicted labels, respectively. The ground-truth labels are shown in red.

## 2 Methodology

### Notations and Framework of DeMipl

Let \(=^{d}\) represent the instance space, and let \(=\{l_{1},l_{2},,l_{k}\}\) represent the label space containing \(k\) class labels. The objective of MIPL is to derive a classifier \(f:2^{}\). \(=\{(_{i},_{i}) 1 i m\}\) is a training dataset that consists of \(m\) bags and their associated candidate label sets. Particularly, \((_{i},_{i})\) is the \(i\)-th multi-instance partial-label sample, where \(_{i}=\{_{i,1},_{i,2},,_{i,n_{i}}\}\) constitutes a bag with \(n_{i}\) instances, and each instance \(_{i,j}\) for \( j\{1,2,,n_{i}\}\). \(_{i}\) is the candidate label set that conceals the ground-truth label \(Y_{i}\), i.e., \(Y_{i}_{i}\). It is worth noting that the ground-truth label is unknown during the training process. Assume the latent instance-level labels within \(_{i}\) is \(_{i}=\{y_{i,1},y_{i,2},,y_{i,n_{i}}\}\), then \( y_{i,j}=Y_{i}\) and \( y_{i,j}\{Y_{i}\}\) hold. In the context of MIPL, an instance is considered a positive instance if its label is identical to the ground-truth label of the bag; otherwise, it is deemed a negative instance. Moreover, the class labels of negative instances do not belong to the label space.

The framework of the proposed DeMipl is illustrated in Figure 2. It consists of three main steps. First, we extract instances in the multi-instance bag \(_{i}\) and obtain instance-level feature \(_{i}\). Next, we employ the disambiguation attention mechanism to integrate the multi-instance bag into a single feature vector \(_{i}\). Finally, we use a classifier to predict the classification confidences \(_{i}\) of the multi-instance bag. To enhance classification performance, we introduce two loss functions for model training: the attention loss \(_{a}\) and the momentum-based disambiguation loss \(_{m}\). During the training process, the attention mechanism and the classifier work collaboratively.

### Disambiguation Attention Mechanism

Based on the embedded-space paradigm, a key component of DeMipl is the disambiguation attention mechanism. The attention mechanisms are common models [44; 45; 46], which can calculate attention scores to determine the contribution of each instance to the multi-instance bag [13; 14]. The attention scores are then utilized to aggregate the instance-level features into a single vector representation.

For a multi-instance bag \(_{i}=\{_{i,1},_{i,2},,_{i,n_{i}}\}\), we employ a neural network-based function parameterized by \(h\) to extract its feature information:

\[_{i}=h(_{i})=\{_{i,1},_{i,2},,_{i,n_{i}}\},\] (1)

where \(_{i,j}=h(_{i,j})^{d^{}}\) is the feature of the \(j\)-th instance within \(i\)-th bag. For the MIPL problems, we propose a multi-class attention mechanism. First, we calculate the relevance of each instance to all classes, and then transform the relevance into the contribution of each instance to the bag-level feature by a learnable linear model. The attention score \(a_{i,j}\) of \(_{i,j}\) is calculated as follows:

\[a_{i,j}=^{}((_{v}^ {}_{i,j}+_{v})(_{u}^{} _{i,j}+_{u}))\}},\] (2)

Figure 2: The framework of DeMipl, where \(_{a}\) and \(_{m}\) are the attention loss and momentum-based disambiguation loss, respectively.

where \(^{}^{1 k}\), \(^{}_{v},~{}^{}_{u}^{k d^{}}\), and \(_{v},~{}_{u}^{k}\) are parameters of the attention mechanism. tanh\(()\) and sigm\(()\) are the hyperbolic tangent and sigmoid functions to generate non-linear outputs for the models, respectively. \(\) represents an element-wise multiplication. Consequently, the bag-level feature is aggregated by weighted sums of instance-level features:

\[_{i}=^{n_{i}}a_{i,j}}_{j=1}^{n_{i}}a_{i,j}_{i,j},\] (3)

where \(_{i}\) is the bag-level feature of \(_{i}\). To ensure that the aggregated features accurately represent the multi-instance bag, it is necessary to maintain the consistency between attention scores and instance-level labels, that is, the attention scores of positive instances should be significantly higher than those of negative instances. To achieve this, the proposed attention loss is shown below:

\[_{a}=-_{i=1}^{m}_{j=1}^{n_{i}}a_{i,j} a_{i, j}.\] (4)

Different from existing attention-based MIL approaches where most of them can only handle binary classification, DeMipl produces multi-class attention scores using Equation (2). Furthermore, unlike loss-based attention  that extends binary attention score to multi-class using a naive softmax function, DeMipl utilizes a learnable model with the attention loss to encourage attention scores of negative and positive instances to approach \(0\) and \(1\), respectively. The ambiguity in attention scores is reduced since the differences in attention scores between positive and negative instances are amplified. As a result, the disambiguated attention scores can make bag-level vector representations discriminative, thereby enabling the classifier to accurately identify ground-truth labels.

### Momentum-based Disambiguation Strategy

After obtaining the bag-level feature, the goal is to accurately identify the ground-truth label from the candidate label set. Therefore, we propose a novel disambiguation strategy, namely using the momentum-based disambiguation loss to compute the weighted sum of losses for each category. Specifically, the proposed momentum-based disambiguation loss is defined as follows:

\[_{m}=_{i=1}^{m}_{c=1}^{k}w_{i,c}^{(t)}( f_{c}^{(t)}(_{i}^{(t)}),_{i}),\] (5)

where \((t)\) refers to the \(t\)-th epoch. \(_{i}^{(t)}\) is the bag-level feature of multi-instance bag \(_{i}\) and \(f_{c}^{(t)}()\) is the model output on the \(c\)-th class at the \(t\)-th epoch. \(()\) is the cross-entropy loss, and \(w_{i,c}^{(t)}\) weights the loss value on the \(c\)-th class at the \(t\)-th epoch.

Following the principle of the identification-based disambiguation strategy , the label with the minimal loss value on the candidate label set can be considered the ground-truth label. We aim to assign a weight of \(1\) to the single ground-truth label and a weight of \(0\) to the rest of the candidate labels. However, the ground-truth label is unknown during the training process. To overcome this issue, we allocate weights based on the magnitude of class probabilities, ensuring that larger class probabilities are associated with higher weights. Specifically, we initialize the weights by:

\[w_{i,c}^{(0)}=\{_{i}|}&Y_{i,c}_{i},\\ 0&,.\] (6)

where \(_{i}|}\) is the cardinality of the candidate label set \(_{i}\). The weights are updated as follows:

\[w_{i,c}^{(t)}=\{^{(t)}w_{i,c}^{(t-1)}+(1- ^{(t)})^{(t)}(_{j}^{(t)})}{_{j_{i}}f _{j}^{(t)}(_{j}^{(t)})}&Y_{i,c}_{i},\\ 0&,.\] (7)

where the momentum parameter \(^{(t)}=\) is a trade-off between the weights at the last epoch and the outputs at the current epoch. \(T\) is the maximum training epoch.

It is worth noting that the momentum-based disambiguation strategy is a general form of the progressive disambiguation strategy. Specifically, when \(^{(t)}=0\), the momentum-based disambiguation strategy degenerates into the progressive disambiguation strategy . When \(^{(t)}=1\), the momentum-based disambiguation strategy degenerates into the averaging-based disambiguation strategy , which equally treats every candidate label.

### Synergy between Attention Mechanism and Disambiguation Strategy

Combining the attention loss and disambiguation loss, the full loss function is derived as follows:

\[=_{m}+_{a}_{a},\] (8)

where \(_{a}\) serves as a constant weight for the attention loss. In each iteration, the disambiguation attention mechanism aggregates a discriminative vector representation for each multi-instance bag. Subsequently, the momentum-based disambiguation strategy takes that feature as input and yields the disambiguated candidate label set, i.e., class probabilities. Meanwhile, the attention mechanism relies on the disambiguated candidate label set to derive attention scores. Thus, the disambiguation attention mechanism and the momentum-based disambiguation strategy work collaboratively.

## 3 Experiments

### Experimental Setup

Benchmark DatasetsWe utilize four benchmark MIPL datasets stemming from MiplGp literature , i.e., MNIST-mipl, FMNIST-mipl, Birdsong-mipl, and SIVAL-mipl from domains of image and biology [48; 49; 50; 51]. Table 1 summarizes the characteristics of both the benchmark and real-world datasets. We use _#bags_, _#ins_, _#dim_, _avg_. _#ins_, _#class_, and _avg_. _#CLs_ to denote the number of bags, number of instances, dimension of each instance, average number of instances in all bags, number of class labels, and the average size of candidate label set in each dataset.

Real-World DatasetWe introduce CRC-mipl, the first real-world MIPL dataset for colorectal cancer classification (CRC). It comprises \(7000\) hematoxylin and eosin (H&E) staining images taken from colorectal cancer and normal tissues. Each image has dimensions of \(224 224\) pixels and is categorized into one of the seven classes based on the tissue cell types. CRC-mipl is derived from a larger dataset used for colorectal cancer classification, which originally contains \(100000\) images with nine classes . The adipose and background classes exhibit significant dissimilarities compared to the other categories. Therefore, we choose the remaining seven classes to sample \(1000\) images per class. These classes include debris, lymphocytes, mucus, smooth muscle, normal colon mucosa, cancer-associated stroma, and colorectal adenocarcinoma epithelium.

We employ four image bag generators : Row , single blob with neighbors (SBN) , k-means segmentation (KMeansSeg) , and scale-invariant feature transform (SIFT) , to obtain a bag of instances from each image, respectively. The candidate label sets of CRC-mipl are provided by three crowdsourcing workers without expert pathologists. Each of the workers annotates all \(7000\) images, and each worker assigned candidate labels with non-zero probabilities to form a label set per image. A higher probability indicates a higher likelihood of being the ground-truth label, while a probability of zero implies the label is a non-candidate label. After obtaining three label sets for each image, we distill a final candidate label set as follows. A label present in two or three label sets is selected as a member of the final candidate label set. If the final candidate label set consists of only one or no label, we pick the labels corresponding to the highest probability in each label set. The average length of the final candidate label set per image is \(2.08\). More detailed information on the MIPL datasets can be found in the Appendix.

Compared AlgorithmsFor comparative studies, we consider one MIPL algorithm MiplGp  and four PLL algorithms, containing one feature-aware disambiguation algorithm Pl-aggd and three deep learning-based algorithms, namely Proden, Rc, and Lws.

   Dataset & \#bags & \#ins & \#dim & avg. \#ins & \#class & avg. \#CLs & domain \\  MNIST-MIPL & 500 & 20664 & 784 & 41.33 & 5 & \(2,3,4\) & image \\ FMNIST-MIPL & 500 & 20810 & 784 & 41.62 & 5 & \(2,3,4\) & image \\ Birdsong-MIPL & 1300 & 48425 & 38 & 37.25 & 13 & \(2,3,4,5,6,7\) & biology \\ SIVAL-MIPL & 1500 & 47414 & 30 & 31.61 & 25 & \(2,3,4\) & image \\  CRC-MIPL-Row & 7000 & 50000 & 9 & 8 & 7 & \(2.08\) & image \\ CRC-MIPL-SBN & 7000 & 63000 & 15 & 9 & 7 & \(2.08\) & image \\ CRC-MIPL-KMeansSeg & 7000 & 30178 & 6 & 4.311 & 7 & \(2.08\) & image \\ CRC-MIPL-SIFT & 7000 & 175000 & 128 & 25 & 7 & \(2.08\) & image \\   

Table 1: Characteristics of the Benchmark and Real-World MIPL Datasets.

ImplementationDeMipl is implemented using PyTorch  on a single Nvidia Tesla V100 GPU. We employ the stochastic gradient descent (SGD) optimizer with a momentum of \(0.9\) and weight decay of \(0.0001\). The initial learning rate is chosen from a set of \(\{0.01,0.05\}\) and is decayed using a cosine annealing method . The number of epochs is set to \(200\) for the SIVAL-mipl and CRC-mipl datasets, and \(100\) for the remaining three datasets. The value of \(_{a}\) is selected from a set of \(\{0.0001,0.001\}\). For the MNIST-mipl and FMNIST-mipl datasets, we utilize a two-layer CNN in work of Ilse et al.  as a feature extraction network, whereas for the remaining datasets, no feature extraction network is employed. To ensure the reliability of the results, we conduct ten runs of random train/test splits with a ratio of \(7:3\) for all datasets. The mean accuracies and standard deviations are recorded for each algorithm. Subsequently, we perform pairwise t-test at a significance level of \(0.05\).

To map MIPL data into PLL data, we employ the Mean strategy and the MaxMin strategy as described in the MiplGp literature . The Mean strategy calculates the average values of each feature dimension for all instances within a multi-instance bag to yield a bag-level vector representation. The MaxMin strategy involves computing the maximum and minimum values of each feature dimension for all instances within a multi-instance bag and concatenating them to construct bag-level features. In the subsequent section, we report the results of Proden, Rc, and Lws using linear models, while the results with multi-layer perceptrons are provided in the Appendix.

### Experimental Results on the Benchmark Datasets

Table 2 presents the classification results achieved by DeMipl and the compared algorithms on the benchmark datasets with varying numbers of false positive labels \(r\). Compared to MiplGp, DeMipl demonstrates superior performance in \(8\) out of \(12\) cases, with no significant difference observed in the remaining \(1\) out of \(12\) cases. MiplGp performs better than DeMipl on the SIVAL-mipl dataset, primarily due to the unique characteristics of the SIVAL-mipl dataset. The dataset encompasses \(25\) highly diverse categories, such as apples, medals, books, and shoes, resulting in distinctive and discriminative features within multi-instance bags. Each instance's feature includes color and texture information derived from the instance itself as well as its four cardinal neighbors, which enhances the distinctiveness of instance-level features. This suggests that instances with similar features are rarely found across different multi-instance bags. Therefore, by following the instance-space paradigm, MiplGp effectively leverages these distinctive attributes of the dataset.

Compared to PLL algorithms, DeMipl outperforms them on all benchmark datasets. This superiority can be attributed to two main factors. First, PLL algorithms cannot directly handle multi-instance bags, whereas the original multi-instance features possess better discriminative power than the degenerated features obtained through the Mean and MaxMin strategies. Second, the proposed momentum-based disambiguation strategy is more robust than the disambiguation strategies of the compared algorithms. It should be noted that although these PLL algorithms achieve satisfactory results in PLL tasks, their performance in addressing MIPL problems is inferior to dedicated MIPL algorithms, namely DeMipl and MiplGp. This observation emphasizes the greater challenges posed by MIPL problems, which involve increased ambiguity in supervision compared to PLL problems, and highlights the necessity of developing specialized algorithms for MIPL.

Additionally, we experiment with another extension of applying PLL algorithms to MIPL data by directly assigning a bag-level candidate label set as the candidate label set for each instance within the bag. However, all of them perform worse than MIPL. Moreover, the majority of the compared PLL algorithms fail to produce satisfactory results. This is likely caused by the fact that the ground-truth labels for most instances are absent from their respective candidate label sets. Consequently, the absences of ground-truth labels impede the disambiguation ability of MIPL algorithms.

### Experimental Results on the Real-World Dataset

The classification accuracy of DeMipl and the compared algorithms on the CRC-mipl dataset is presented in Table 3, where the symbol - indicates that MiplGp encounters memory overflow issues on our V100 GPUs. DeMipl demonstrates superior performance compared to MiplGp on the CRC-mipl-sbn and CRC-mipl-KMeansSeg datasets, while only falling behind MiplGp on the CRC-mipl-Row dataset. When compared to the PLL algorithms, DeMipl achieves better results in \(28\) out of \(32\) cases, and only underperforms against Pl-aggd in \(2\) cases on CRC-mipl-Row and CRC-mipl-sbn.

[MISSING_PAGE_FAIL:7]

instances in CRC-MIPL-Row and CRC-MIPL-SBN exhibit similar feature representations, and possess limited discriminative power when distinguishing positive and negative instances. With more powerful bag generators such as CRC-MIPL-KMeansSeg and CRC-MIPL-Sift, which generate content-aware features that are more informative and discriminative, the disambiguation power of DeMipL can be fully utilized as demonstrated by the significant performance advantages against all compared baselines.

Furthermore, the CRC-MIPL dataset exhibits distinct differences between tissue cells and the background in each image. The Mean strategy diminishes the disparities and discriminations, leading to superior outcomes for the Maxmin strategy in most cases when compared to the Mean strategy.

### Further Analysis

Effectiveness of the Attention LossTo validate the effectiveness of the attention loss, we introduce a degenerated variant named DeMipL-MD, which excludes the attention loss from DeMipL. Table 4 verifies that DeMipL achieves superior accuracy compared to DeMipL-MD on both the FMNIST-MIPL and SIVAL-MIPL datasets. Notably, the difference is more pronounced on the FMNIST-MIPL dataset than that on the SIVAL-MIPL dataset. This can be attributed to the fact that the feature representation of each instance in the FMNIST-MIPL dataset solely comprises self-contained information, enabling clear differentiation between positive and negative instances. Conversely, the feature representation of each instance in the SIVAL-MIPL dataset encompasses both self and neighboring information, leading to couplings between the feature information of positive instances and negative instances.

To further investigate the scores learned by the attention loss, we visualize the frequency distribution of attention scores throughout the training process. As illuminated in Figure 3, the top row corresponds to DeMipL-MD, while the bottom row corresponds to DeMipL. At epoch=\(10\), attention scores generated by DeMipL show higher dispersion, suggesting that DeMipL trains faster than DeMipL-MD. At epoch=\(50\) and \(100\), attention scores computed by DeMipL tend to converge towards two extremes: attention scores for negative instances gravitate towards zero, while attention scores for positive instances approach one. In conclusion, the attention loss is conducive to calculating appropriate attention scores for positive and negative instances, thereby improving accuracy.

Effectiveness of the Momentum-based Disambiguation StrategyTo further investigate the momentum-based disambiguation strategy, the performance of DeMipL is compared with its two degenerated versions denoted as DeMipL-Pr and DeMipL-Av. DeMipL-Pr is obtained by setting the momentum parameter \(^{(t)}=0\) in Equation (7), which corresponds to progressively updating the weights based on the current output of the classifier. In contrast, DeMipL-Av is obtained by setting the momentum parameter \(^{(t)}=1\), resulting in uniform weights throughout the training process.

Figure 4 illustrates the performance comparison among DeMipL, DeMipL-Pr, and DeMipL-Av on the MNIST-MIPL, FMNIST-MIPL, and Birdsong-MIPL datasets. When the number of false positive labels is small, DeMipL-Pr and DeMipL-Av demonstrate similar performance to DeMipL. However,

    &  &  \\   & \(r=1\) & \(r=2\) & \(r=3\) & \(r=1\) & \(r=2\) & \(r=3\) \\  DeMipL-MD & 0.744\(\)0.273 & 0.784\(\)0.018 & 0.586\(\)0.101 & 0.607\(\)0.024 & 0.530\(\)0.021 & 0.499\(\)0.035 \\ DeMipL & 0.881\(\)0.021 & 0.823\(\)0.028 & 0.657\(\)0.025 & 0.635\(\)0.041 & 0.554\(\)0.051 & 0.503\(\)0.018 \\   

Table 4: Classification accuracy (mean\(\)std) of DeMipL-MD and DeMipL.

Figure 3: The frequency distribution of attention scores on MNIST-MIPL dataset (\(r=1\)).

as the number of false positive labels increases, DeMipl consistently outperforms DeMipl-Pr and DeMipl-Av by a significant margin. This observation suggests that the momentum-based disambiguation strategy is more robust in handling higher levels of disambiguation complexity. Furthermore, it can be observed that DeMipl-Pr generally outperforms DeMipl-Av across various scenarios. However, when \(r=3\) in the MNIST-mipl and FMNIST-mipl datasets, DeMipl-Av surpasses DeMipl-Pr. We believe this can be attributed to the following reason: having three false positive labels within the context of five classifications represents an extreme case. DeMipl-Pr likely assigns higher weights to false positive labels, whereas DeMipl-Av uniformly assigns weights to each candidate label, adopting a more conservative approach to avoid assigning excessive weights to false positive labels. In a nutshell, the proposed momentum-based disambiguation strategy demonstrates superior robustness compared to existing methods for disambiguation.

Parameter Sensitivity AnalysisThe weight \(_{a}\) in Equation (8) is the primary hyperparameter in DeMipl. Figure 5 illustrates the sensitivity analysis of the weight \(_{a}\) on the MNIST-mipl and CRC-mipl-sift datasets. The learning rates on the MNIST-mipl dataset are set to \(0.01\), \(0.01\), \(0.05\) for \(r=1\), \(2\), \(3\), respectively, while on the CRC-mipl-sift dataset, the learning rate is set to \(0.01\). As illuminated in Figure 5, DeMipl demonstrates insensitivity to changes in the weight \(_{a}\). In the experiments involving DeMipl and its variants, the weight \(_{a}\) is chosen from a set of \(\{0.0001,0.001\}\).

## 4 Conclusion

In this paper, we propose DeMipl, the first deep learning-based algorithm for multi-instance parallel-label learning, accompanied by a real-world dataset. Specifically, DeMipl utilizes the disambiguation attention mechanism to aggregate each multi-instance bag into a single vector representation, which is further used in conjunction with the momentum-based disambiguation strategy to determine the ground-truth label from the candidate label set. The disambiguation attention mechanism and momentum-based strategy synergistically facilitate disambiguation in both the instance space and label space. Extensive experimental results indicate that DeMipl outperforms the compared algorithms in \(96.3\%\) of cases on benchmark datasets and \(85.7\%\) of cases on the real-world dataset.

Despite DeMipl's superior performance compared to the well-established MIPL and PLL approaches, it exhibits certain limitations and there are several unexplored research avenues. For example, DeMipl assumes independence among instances within each bag. A promising avenue for future research involves considering dependencies between instances. Moreover, akin to MIL algorithms grounded in the embedded-space paradigm , accurately predicting instance-level labels poses a challenging endeavor. One possible approach entails the introduction of an instance-level classifier.

Figure 4: Classification accuracy of DeMipl, DeMipl-Pr, and DeMipl-Av with varying \(r\).

Figure 5: Performance of DeMipl with varying weight \(_{a}\).