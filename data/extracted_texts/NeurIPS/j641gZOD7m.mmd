# Understanding Learning Dynamics of Neural Representations via Feature Visualization at Scale

Chandana Kuntala \({}^{1}\)\({}^{2}\)  Carlos R. Ponce \({}^{1}\)  Deepak Kumar Sharma \({}^{2}\)  Binku Wang \({}^{1}\)

\({}^{1}\) Department of Neurobiology, Harvard Medical School, Boston, MA

\({}^{2}\) Department of Information Technology, Indira Gandhi Technical University for Women, New Delhi, India

\({}^{3}\) Kempner Institute for the Study of Natural and Artificial Intelligence, Harvard University, Allston, MA

{chandana007btit20, deepaksharma}@igdtuw.ac.in

{carlos, binxu_wang}@hms.harvard.edu

Corresponding author: Binku Wang (binku_wang@hms.harvard.edu)

###### Abstract

How does feature learning happen during the training of a neural network? We developed an accelerated pipeline to synthesize maximally activating images ("prototypes") for hidden units in a parallel fashion. Through this, we were able to perform feature visualization at scale and to track the emergence and development of visual features across the training of neural networks. Using this technique, we studied the "developmental" process of features in a convolutional neural network trained from scratch using SimCLR with or without color jittering augmentation. After creating over one million prototypes with our method, tracking and comparing these visual signatures showed that the training with color-jitter augmentation led to constantly diversifying high-level features, while no color-jittering led to more diverse low-level features but less development of high-level features. These results illustrate how feature visualization can be used to understand hidden learning dynamics under different training objectives and data distribution.

Figure 1: **A. Dual perspectives on neural representation. Left, neural vector space view of representation; Right, image space tuning landscape view of representation. B. Visual summary of our approach.**Introduction

In the biological and artificial neural systems, the neural representation of images is often analyzed in a multi-dimensional vector space [4; 17; 7; 20], formed by the activation of neurons. For example, in this vector space, the representations of different object categories form "object manifolds" which allows classification and few-shot learning [4; 6; 28]. An alternative perspective is to think about neural representation in their domain i.e. on the image manifold [35; 31]. From this perspective, the tuning of each neuron is a function (i.e. landscapes) on the manifold, with peaks and troughs. The peaks of the landscape correspond to images that highly activate these neurons. Note that, the axes of the neural vector space are the tuning functions of these neurons, thus the highly activating images could be regarded as the meaning of these axes. Through this paper, we call the activation maximizing images for each neuron a "prototype" . Thus, obtaining the prototypes for all units in a neural network could provide a full basis set for understanding the representation of this network.

Feature visualization has been a prominent technique for finding and synthesizing prototypes in deep artificial neural networks [22; 23; 10], and the biological brain [26; 34; 12]. But normally, these methods were applied to one unit at a time, hard for application at scale.

In this work, we developed an accelerated pipeline to extract "prototypes" in a parallel fashion. Through this, we were able to apply feature visualization on a large scale, tracking the emergence and change of "prototypes" across the whole training process of neural networks - creating a visual signature for each network checkpoint. We leveraged this method to study the "development" of features in a convolutional neural network trained from scratch via self-supervised learning. The preliminary results illustrate how different training objectives and data distribution led to different "development" dynamics inside a computational visual hierarchy.

## 2 Methods

### Feature Visualization at Scale

Our method is based on [21; 33; 30], where feature visualization is performed within the latent space of a pretrained generative adversarial network (GAN) . This GAN can be regarded as the natural image prior or the regularizer for the optimization, which counteracts the adversarial artifacts . For each target unit, we optimize its activation using a hybrid of Covariance Matrix Adaptation Evolutionary Strategy (CMA-ES)  and gradient optimization: we performed 10s of CMA steps to search for an initialization vector that evoked non-zero activation in the unit, then we performed 100s of gradient ascent steps to optimize the vector to a peak to visualize the features. We implemented both CMA and Adam optimization in a more paralleled fashion, which enables feature visualization for each and every channel in a layer in a single run. This method increased our overall throughput by 33-fold (details in Sec. 6.2).

Figure 2: Example prototypes for networks trained with color jittering (clrjit) and without (keepclr)

### Experiment Setup for Self-Supervised Learning

SimCLR  is a popular self-supervised learning algorithm for learning visual representation from a data distribution. This algorithm trains a neural network to associate different augmented views of the same image as similar representations, and those of different images as dissimilar ones. One key component of this method is the augmentation pipeline, which determines what type of transformation should the neural network be invariant to. It's well-known that with the same SimCLR objective, different augmentation pipelines led to dramatically different final performances . The network mechanism underlying this difference is not well understood. Thus, we treated this as an example problem and dissected the feature learning dynamics through the lens of the prototype distribution.

Here, we had two training conditions with different augmentation pipelines and tested their effect on the development process of prototypes. 1) **Color jitter** (abbreviated as _clrjit_), the default augmentation pipeline of SimCLR; 2) **Keep Color** (_keepclr_), the same pipeline with color jittering and random grayscale augmentation disabled, which keeps the original color of the image. As the two conditions exposed the neural networks to different image statistics and pushed them with different objectives, we'd like to see if we can understand these differences better through the lens of prototype distribution.

For all our experiments, we used ResNet18  as our neural network architecture and trained it with SimCLR on STL10  dataset for 100 epochs.

Specifically, we completed three training runs of ResNet18 from scratch with random seeds 1,2,3 with color jittering and keep color augmentations; resulting in 6 training sequences of 101 epochs neural network checkpoints. For each checkpoint, we performed prototype extraction twice for each channel of every major layer (details in Sec. 6.1). Thus, all these prototypes can be indexed by [training condition, run number, evolution repeat, epoch number, layer, channel].

We evaluated the quality of their representations using the linear probe protocol (see Sec.6.1), namely fitting a linear classifier to see how well it classifies the test set images. The models trained with color jittering augmentation have far higher classification accuracy (\(70.0 0.3\)%) than the models without (\(49.8 0.3\)%) (Fig.5). This is consistent with the original observations of the importance of color augmentation in SimCLR (Fig.5 in ). From this perspective, the _clrjit_ models have better feature representations for object classification. The focus of our analysis is to dissect the difference in representation quality and link it back to the development of prototypes.

## 3 Results

### Visual difference of the prototypes between conditions

How do the learned features differ between the two training conditions? We first visually inspected the distribution of prototypes in each layer for the two conditions (Fig.2).

For the color jittering condition (Fig.2a), in layer 1, the prototypes masked with their respective receptive fields primarily captured patterns like black stripes on a white background (a1-1,1-32), and solid colors like Prussian blue (a1-2), white/off-white, black, and partial cyan, red, and green shades. In the second layer, more square-circle figures like squircles (a2-1,2-3) were observed along with intricate patterns like thick lines and irregular line figures that somewhat resembled a cracked earth texture or an abstract glass painting texture (a2-2,2-4). In layer 3, the features became finer, as

Figure 3: **Dynamics of prototypes diversity during training**.

high-frequency textures were observed (a3-1), along with black and white squircles (a3-2), rectangles (a3-3), and grids (a3-4). In layer 4, high-frequency textures (a4-1) were observed as well as distorted grid-like structures (a4-2). Few prototypes showed a gradient of colors resembling fur-like (a4-3) and watercolor textures (a4-4).

In contrast, in the keep color condition (Fig.2 b), in layer 1, a vibrant array of colors were observed including magenta / pink (b1-1), green (b1-2), red, blues, cyan, and yellow along with colorful stripes (b1-4). In layer 2, high-frequency textures (b2-4) were present along with colored gemstone-like shapes embedded in high-frequency textures (b2-1,b2-2,b2-3). In higher layers (layer 3 and layer 4), there were a significant number of high-frequency textures present mainly in the warm hues like oranges and reds (row3,4). These texture patterns are perceptually more similar to each other than the ones in color-jittering conditions.

### Developmental process of prototypes during training

So how do the neural networks arrive at these features? We visualized the prototypes of each training epochs as a row. For instance, for these example units in layer3 of a clrjit network (Fig.4, see Fig.9 for keepclr condition), each of these units goes through an initial stage of rapid erratic change, and then settles down to a primitive version of the final feature at around epoch 30, then elaborate this primitive form until the end. The latter half of epochs have more similarities between each other for each unit than the initial epochs however each of these individual units keeps diversifying with respect to each other throughout the training process as seen in Fig. 3.

### Distance structure between prototypes

Next, we quantified our perception by computing the distance structure between prototypes to understand their distribution and dynamics during training. We computed the Mean Squared Error (MSE) and Cosine distance in both pixel space and the embedding space of some pre-trained networks (detail in Sec.6.4). Further, we computed the prototype similarity with the images masked by their functional receptive field mask (Sec.6.3) to focus on the central feature.

We quantified the **diversity of prototypes** during training: for each epoch, we computed the pairwise distance matrix between prototypes of all channels, and then computed the mean distance between prototype pairs (Fig. 3). We found salient differences between the two training conditions (color jitter, keep color), and consistencies between repeated training runs and prototype evolutions. Here we showed results with ResNet50 as our embedding model and MSE as the distance metric. For layer 1, the diversity dropped drastically in the first few epochs, and then grew to a stable level. In the end, keepclr condition led to more diverse prototypes than clrjit. For layer 2, after the initial drop of diversity, the prototypes diversify again, and keepclr condition led to slightly higher diversity. However, for layers 3 and 4, the keepclr condition increased prototype diversity early on and then they plateaued; in contrast, the clrjit condition led to a constant increase in prototype diversity without plateau. When the cosine distance is used instead of MSE (Fig.6), a shift is observed in the dynamics, albeit the diverging trend between conditions remained similar to the MSE result. The consistency of the color-jittering networks being at the top tends to demonstrate how these networks develop more

Figure 4: Development of prototypes through training for color jittering (clrjit) condition, layer 3. Columns denote 0,10,20,... to 90 epoch; Rows denote Units 1, 2, 12, and 98 (0-based index).

diverse prototypes through their evolutions. Further observations about the rate of change and the stability of prototype across re-evolution are noted in Sec. 7.2

This observation is intriguing. We interpreted it as follows, the color jittering augmentation constantly drives the network to find higher-level visual features to solve the instance classification task; while without color jittering, slightly more diverse lower-level features (layer1,2) suffice to solve the task. Intuitively, when SimCLR training doesn't randomly augment the color (keepclr), one simple way to find views of the same image is to look for similar color palettes. Thus, it's intuitive that the keepclr network needs to be more sensitive to image colors (Fig. 2). In comparison, with color jittering, the network cannot rely on color matching as a reliable strategy, and it needs to discover higher-level form consistencies, which may drive the diversification and learning of deeper layer features.

## 4 Related Work

Understanding self-supervised representationSelf-supervised learning (SSL) has been a popular feature learning paradigm in vision. In this paradigm, pre-training uses different objectives to learn features, which are used in the downstream tasks, with minor fine-tunings. But what is a good feature representation? Usually, these features were evaluated based on the performance of the downstream task. One open question is to understand and evaluate representations by themselves without using a downstream task. Many works analyzed the representation similarity of SSL networks and supervised networks .  understand the success of contrastive learning through the alignment of positive pairs and the uniformity of representation on the hypersphere. More recently,  and  found certain intrinsic measures of representation e.g. effective dimensionality, intrinsic dimensionality, and cluster learnability, predict the in-distribution task performance well. On the other front,  used generative models to understand the "interpretation" of the same image by pre-trained networks to show their different biases, creating a more visual and intuitive explanation.

## 5 Discussion

It has been noticed that the randomly initialized neural networks have lower dimensional representations, i.e. the activations of hidden units are more correlated across populations; and supervised training increased the dimensionality of the representation, and the increase is more prominent in deeper layers (Fig. H.1A, ). In the other perspective, the units become less correlated to each other during training, which is consistent with our finding that the prototypes of the units become more and more diverse during training.

Prototype diversity seems like a promising proxy for the richness of neural representation, however, it may not be the full story, these prototypes need to be related to the training and testing distribution of images in a meaningful way to be useful. Thus, one deep and open question is to elucidate the relationship between these prototypes and the training distribution of the network. Classic work of efficient coding  relates Gabor-like V1 receptive field (i.e. prototypes) to the natural image distribution and the sparse coding objective. Future works of similar flavor may be able to illuminate the relationship between the collection of prototypes of deeper layers and the training distribution of the network.