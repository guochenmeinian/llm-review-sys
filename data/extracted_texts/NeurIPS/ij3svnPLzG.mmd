# Semi-Supervised Contrastive Learning for Deep Regression with Ordinal Rankings from Spectral Seriation

Semi-Supervised Contrastive Learning for Deep Regression with Ordinal Rankings from Spectral Seriation

Weihang Dai\({}^{1}\), Yao Du\({}^{1}\), Hanru Bai\({}^{3}\), Kwang-Ting Cheng\({}^{1}\), Xiaomeng Li\({}^{1,2}\)

\({}^{1}\)The Hong Kong University of Science and Technology

\({}^{2}\)HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen

\({}^{3}\)Fudan University

eexmli@ust.hk

Corresponding author

###### Abstract

Contrastive learning methods can be applied to deep regression by enforcing label distance relationships in feature space. However, these methods are limited to labeled data only unlike for classification, where unlabeled data can be used for contrastive pretraining. In this work, we extend contrastive regression methods to allow unlabeled data to be used in a semi-supervised setting, thereby reducing the reliance on manual annotations. We observe that the feature similarity matrix between unlabeled samples still reflect inter-sample relationships, and that an accurate ordinal relationship can be recovered through spectral seriation algorithms if the level of error is within certain bounds. By using the recovered ordinal relationship for contrastive learning on unlabeled samples, we can allow more data to be used for feature representation learning, thereby achieve more robust results. The ordinal rankings can also be used to supervise predictions on unlabeled samples, which can serve as an additional training signal. We provide theoretical guarantees and empirical support through experiments on different datasets, demonstrating that our method can surpass existing state-of-the-art semi-supervised deep regression methods. To the best of our knowledge, this work is the first to explore using unlabeled data to perform contrastive learning for regression. Code is available at https://github.com/xmed-lab/CLSS.

## 1 Introduction

Contrastive learning is an effective technique for improving feature representations in deep neural networks (DNNs) [3; 4; 19; 33; 10]. These methods involve identifying positive and negative sample pairs based on feature similarity, where positive pairs are usually defined as augmented samples from the same input or samples from the same class. Early works such as SimCLR , MoCo , and SupCon , showed that pretraining DNNs through contrastive learning can lead to state-of-the-art classification results due to improved feature representations. These techniques have since been extended to segmentation [33; 43], video recognition , multi-modality learning , as well as deep regression [8; 42; 37] to great effect.

It is possible to perform contrastive learning for classification in an unsupervised manner, which allows large amounts of unlabeled data to be used [3; 4; 28]. Unsupervised contrastive learning is not possible for deep regression tasks however, because in order for feature representations to be effective for regression, they must reflect label distance relationships in feature space [8; 42; 37]. Contrastive regression loss functions ensure that sample pairs with smaller label distances have features that are more similar, compared to those with greater label distance. Because of this, _existing methods can only be used on fully labeled datasets_, which can be a limiting factor when annotations are costly to obtain. This is especially true for medical imaging analysis, where deep regression is important for estimating real-number medical indicators but often require expert knowledge for manual annotation [8; 20; 40].

In this work, we extend contrastive learning for deep regression _such that unlabeled data can also be used_. We consider a semi-supervised setting where only a small portion of the training dataset is labeled, and the majority of samples are unlabeled. We observe that by enforcing supervised contrastive learning on labeled samples, the feature similarity matrix of unlabeled samples will also learn to reflect label distance . Although the unlabeled feature similarity matrix will be inaccurate and noise corrupted, _it is still possible to infer the relative ordering of samples if errors are within certain bounds_. To give an intuitive example, it is easy to infer the relative ranking of an unlabeled sample based on its pair-wise feature similarity against labeled samples, assuming that features are well-trained (see Fig. 1a). Even in the presence of noisy features, it is still possible to infer the correct ranking if most of the similarity values are reliable (Fig. 1b). Similarly, given a feature similarity matrix for a batch of unlabeled samples, it is still possible to infer their relative ordering even with some degree of noise present (Fig. 1c).

To this end, we propose a novel semi-supervised contrastive regression method by making use of ordinal rankings recovered from the unlabeled feature similarity matrix. We make use of the spectral seriation algorithm proposed by Atkins _et al_.  for ranking recovery, which can then be used to construct a distance matrix for supervising contrastive learning on the unlabeled samples. The spectral seriation algorithm is based on an error-minimization approach and allows for some degree of error correction when extracting rankings from the feature similarity matrix. Thus, the ordinal rankings can also be used to supervise predictions on unlabeled samples, which we demonstrate leads to further improvements for semi-supervised regression. We term our method Contrastive Learning with Spectral Seriation (CLSS). Fig. 2 illustrates our overall framework.

We provide theoretical proofs and empirically show that our method can achieve state-of-the-art performance on multiple datasets. Our method is highly beneficial for critical applications such as medical imaging analysis, where annotations can be expensive to obtain. To the best of our knowledge, CLSS is _the first to extend contrastive learning for deep regression to unlabeled data_. To summarize, our main contributions are: (1) we propose CLSS, a novel semi-supervised contrastive learning method that is the first to use unlabeled data for contrastive regression; (2) we demonstrate that spectral seriation can be used to extract robust rankings from the feature similarity matrix of

Figure 1: Obtaining rankings from feature similarity. (a) Given labeled samples with well trained features, the ranking of an unlabeled sample can be easily inferred to be between the two with the highest similarity values. (b) The correct ranking can still be inferred with noisy features, as long as the noise levels are within certain thresholds. (c) Given a feature similarity matrix of unlabeled samples, the correct ranking can still be obtained if noise levels are within certain bounds.

unlabeled samples for supervision; (3) we demonstrate that our method can outperform existing state-of-the-art alternatives on different deep regression tasks using multiple datasets.

## 2 Related Work

### Contrastive Learning

Contrastive learning for classification involves identifying positive and negative sample pairs based on feature similarity, which allows similar samples to be grouped closer together in feature space [3; 19; 15]. These methods can be performed supervised or unsupervised depending on how positive pairs are defined. SimCLR  and MoCo  defines positive pairs as augmented samples from the same input data, which means labels are not required. Supervised methods such as SupCon  define positive pairs as samples belonging to the same class.

Contrastive learning for deep regression requires features to reflect label distance relationships in feature space. Dai _et al_. propose AdaCon, which uses adaptive margins in the SupCon loss function to encourage similarity values to reflect pair-wise label distance . Xue _et al_.  find that determining positive and negative pairs based on distance thresholds can be effective for regression tasks. Zhang _et al_. introduce ordinal entropy, which also encourages features to be spread out depending on their pair-wise label distance . Results from these methods show that improving feature learning is a highly effective way to improve deep regression model performance. Because label information is required for these existing contrastive regression loss functions, _they cannot be used with unlabeled data_ however. Our method, CLSS, is the first to extend contrastive learning for regression to allow unlabeled data to also be used for training.

### Semi-Supervised Regression

Semi-supervised learning allows unlabeled data to be used with labeled data for model training. It is an effective way of reducing reliance on manual annotations and is particularly valuable for applications where labeled data is costly to obtain [9; 22; 23; 39; 21]. Semi-supervised classification methods are well studied [29; 41], but semi-supervised deep regression problems receive significantly less attention . Early works such as COREG  propose using co-trained KNN neural networks to enforce consistency between two models. Consistency based methods have also been explored in [36; 34]. Iterative approaches for generating pseudo-labels , deep kernel learning methods [25; 35; 18], and graph based methods  have been proposed for semi-supervised learning in more recent works. A major limitation of these methods is that they are primarily designed for structured tabular data however, and cannot be trained end-to-end with a deep feature extractor for unstructured inputs.

Dai _et al_. proposed UCVME , which enforces consistent uncertainty predictions between co-trained models, and can be used for unstructured inputs such as images and videos. Although this

Figure 2: Framework for Contrastive Learning with Spectral Seritation (CLSS). Unlike existing works for contrastive learning that are only able to use labeled data, we make use of spectral seriation to obtain ordinal rankings for unlabeled samples. This can then be used for constrative learning and ranking supervision for unlabeled samples.

method achieves good performance, it ignores potential improvements that can be made on the feature level, which is critical to the performance of deep regression models [8; 42]. In this work, _we are the first_ to address the challenge of performing contrastive learning for deep regression by making use of unlabeled data.

## 3 Method

### Overview

Our novel method allows contrastive learning to be performed with _unlabeled data_ under a semi-supervised framework. We denote \(\{(x_{i},y_{i})\}_{i=1}^{N}\) as the labeled dataset consisting of \(N\) samples, where \(x_{i}\) is the input data and \(y_{i}\) is its corresponding label in \(\). We denote \(^{}\{x_{i^{}}^{}\}_{i^{}=1}^{N^{ }}\) as the unlabeled dataset consisting of input data only. We denote the feature extractor as \(f()\) and the feature vector as \(z\) for labeled data, such that \(z_{i}=f(x_{i})\). Similarly, we denote features for unlabeled data as \(z_{i}^{}\). Contrastive learning is performed on the L2 normalized feature vector, with some methods also performing feature projection onto a lower dimension [8; 42; 3]. We denote the transformed, normalized feature vector for labeled data as \(\) such that \(_{i}=}{||z_{i}||_{2}}\). We use \(^{}\) for unlabeled data. The feature similarity matrix for labeled and unlabeled samples are denoted as \(\) and \(^{}\) respectively. We denote the regression head as \(g()\). The overall deep regression model can be expressed as:

\[Y=g(f(X))+\;;\;\;N(0,^{2})\,.\] (1)

The model can be trained through supervised regression by minimizing mean squared error (MSE) loss, which we denote as \(^{SR}\):

\[^{SR}=_{i=1}^{N}(y_{i}-_{i})^{2}\;.\] (2)

Supervised contrastive learning can be performed on the normalized feature vectors for labeled samples \(\) using different contrastive regression losses, which we denote as \(^{SC}\). Spectral seriation can then be used to extract the ordinal rankings \(R^{}\) from \(^{}\) for supervising contrastive learning and predictions on labeled samples. We describe our method in detail below.

### Using ordinal ranking from spectral seriation for supervision

#### 3.2.1 Spectral seriation for retrieving ordinal ranking from similarity matrix

Contrastive learning for deep regression aims to ensure that feature representations reflect label distance relationships in feature space [8; 42; 37]. If \(y_{i}\) and \(y_{j}\) are closer together than \(y_{i}\) and \(y_{k}\), than the distance between features \(z_{i}\) and \(z_{j}\) should be closer together than \(z_{i}\) and \(z_{k}\). Thus:

\[||_{i}-_{j}||_{2}<||_{i}-_{k}||_{2}\;\; \;|y_{i}-y_{j}|<|y_{i}-y_{k}|.\] (3)

Alternatively, because we use L2 normalized feature vectors,

\[(_{i},_{j})>(_{i},_{k})\;\; \;|y_{i}-y_{j}|<|y_{i}-y_{k}|,\] (4)

where \(\) is the cosine similarity function, and \((_{i},_{j})\) and \((_{i},_{k})\) correspond to entries in similarity matrix \(\). By performing supervised contrastive learning on labeled samples, we can also expect entries in \(^{}\) to also approximate Eq. 4 with noise, as they have been trained to reflect distance relationships in feature space.

To retrieve the ordinal ranking \(R^{}\) of samples in an unlabeled batch, we can make use of the spectral seriation algorithm originally proposed by Atkins _et al_. . The algorithm is designed to recover an ordinal ranking given a correlation matrix, where higher correlation values indicate closer proximity in ranking. The algorithm is especially useful for when it is easy to determine the similarity between sample pairs but difficult to obtain a direct ordering. Cosine similarity is equivalent to correlation after L2 normalization. Therefore spectral seriation can also be used to recover \(R^{}\) from \(^{}\).

The seriation problem can be formulated as a loss minimizing function:

\[*{arg\,min}_{R^{}}_{i,j}^{}_{i,j}(R^{ }_{i}-R^{}_{j})^{2}\;,\] (5)where \(^{}_{i,j}=(_{i},_{j})\). Since sample pairs closer together in ranking have higher correlation values, minimizing this loss encourages these samples to have \(R_{i}\) and \(R_{j}\) that are closer together. As per spectral seriation, the solution to \(R^{}\) can be derived from the Fiedler vector, as stated in Theorem 1.

**Theorem 1**: _Given similarity matrix \(^{}\) such that \(^{}_{i,j}>^{}_{i,k}\) for \(|y_{i}-y_{j}|<|y_{i}-y_{k}|\), the ordinal ranking that best satisfies observed \(^{}\) is the ranking of the values in the Fiedler vector of \(\), where \(\) is the Laplacian of \(^{}_{i,j}\)._

Intuitively, the proof of this theorem can be obtained by approximating discrete rankings \(R^{}\) with real-number values \(r^{}\) and expressing Eq. 5 in the form of:

\[_{r^{}e=0,r^{^{}}r^{}=1}r^{ }r^{}\;.\] (6)

\(r^{}\) can be solved by computing the Fiedler vector, which is the eigenvector corresponding with the smallest non-zero eigenvalue. The relative rankings of \(r^{}\) then give us \(R^{}\). We refer interested readers to  for detailed derivations.

#### 3.2.2 Unlabeled contrastive learning with seriation rankings

Spectral seriation gives us rank \(R^{}\) of unlabeled samples within a batch. From this, we can obtain rankings on the distances between sample pairs for some anchor sample \(i\). The distance ranking can be used to supervise contrastive learning on unlabeled samples by ensuring that the feature similarity values are consistent with the rankings. We define the unlabeled contrastive learning loss with respect to some subset \(\) as:

\[^{UC}=_{i=1}^{||}\,((^{ }_{[i,]}),\,(-|R^{}-R^{}_{[i]}|);),\] (7)

where \([i,:]\) denotes the \(i\)th row in the matrix, \([i]\) denotes the \(i\)th value of a vector, \(\) denotes the ranking operator, and \(\) is the ranking similarity function. This loss function ensures that the ranking of the feature similarity values with anchor sample \(i\) are consistent with that of the distances between derived rankings obtained from seriation. For the differentiable ranking similarity loss function \(\), we directly use the differential combinatorial solver proposed in , which takes an additional parameter \(\). On a high level, the function makes use of interpolation methods to allow combinatorial inputs to be differentiable, although detailed explanations can be found in the original work.

#### 3.2.3 Ranking supervision of unlabeled predictions with seriation rankings

Given \(R^{}\) for unlabeled samples, we can also perform supervision on the prediction output \(\). The spectral seriation algorithm is inherently robust to error, which we show in section 3.3, which means pair-wise distance rankings from seriation are likely to be more accurate than the predicted output. We define the unlabeled prediction ranking loss with respect to some subset \(\) as:

\[^{UR}=_{i=1}^{||}\,((-|^{ }-^{}_{[i]}|),\,(-|R^{}-R^{}_{[i]}|) ;),\] (8)

where \([i]\) denotes the \(i\)th value of a vector. This serves as an additional supervision for unlabeled data.

#### 3.2.4 Overall framework

The total loss function \(\) of our method is:

\[=^{SR}+w_{SC}^{SC}+w_{UC}^{UC}+w_{ UR}^{UR}\;,\] (9)

where \(^{SR}\), \(^{SC}\), \(^{UC}\), and \(^{UR}\) represent the loss values of supervised regression, supervised contrastive loss, unsupervised contrastive loss, and unsupervised ranking loss. \(w_{SC}\), \(w_{UC}\), and \(w_{UR}\) are the corresponding loss weights. \(^{UC}\) and \(^{UR}\) are calculated using unlabeled data with the ordinal rankings recovered through spectral seriation. Fig. 2 shows the overall framework.

### Robustness analysis of spectral seriation

Because spectral seriation is based on a loss minimization approach, the algorithm itself is robust to noisy inputs. In this section, we provide theoretical proofs to formally show that spectral seriation is robust to two different types of noise: noisy similarity matrices, and noisy feature representations. We derive approximate bounds to analytically demonstrate that spectral seriation can be a reliable method for recovering ordinal rankings from noisy similarity values of unlabeled samples. Additional derivations are also included in the supplementary materials for more technical readers.

#### 3.3.1 Robustness to noise in the similarity matrix

We make use of matrix perturbation theory to show that spectral seriation ranking is robust to noisy values in similarity matrix \(^{}\). We give an upper bound for the noisy entries of the similarity matrix, and show that when the errors of the similarity matrix are bounded, our spectral ranking algorithm recovers the true ranking, thereby demonstrating the error correcting nature of spectral seriation.

The main result is presented in Theorem 2. We first present two related lemmas to assist with the proof, where Lemma 1 provides the perturbation bounds for eigenvalues of symmetric matrices, and Lemma 2 provides the upper bound of the Fiedler value.

**Lemma 1**: _Let \(,^{n n}\) be Hermitian matrices, \(()=\{_{i}\},()=\{_ {i}\},_{1}_{2}_{n},_{1} _{2}_{n}\), then:_

\[|_{i}-_{i}|\|-\|_{2}.\]

**Lemma 2**: \(\) _is the Fiedler value of the Laplacian matrix \(\) of the similarity matrix \(^{}\), then:_

\[_{1 i n}\{_{ii}\}.\]

**Theorem 2**: _For a similarity matrix \(^{}\), suppose the error matrix of it is \(^{}\). When \(2||^{}||_{F} 1-\{_{  i}|^{}_{ii}|\}}{n-1}\), the seriation obtained by the spectral ranking algorithm using \(^{}\) is the same as that obtained by the spectral ranking algorithm using \(^{}+^{}\)._

The proof of Theorem 2 relies mainly on the definition of the Fielder vector, Lemma 1 and Lemma 2. First order approximation is used to approximate changes in the Fielder vector after adding noise to the similarity matrix, thus allowing us to obtain upper bounds for the noise level. Detailed derivations are included in the supplementary materials.

#### 3.3.2 Robustness to noise in feature representations

We next consider the case where the feature representation for some given sample \(^{}_{i}\) is noisy. The direct consequence of this is that all entries in rows \(i\) and column \(j\) of \(^{}\) will be noisy. We can also use a similar approach to show that the spectral seriation algorithm can recover the correct ranking as long as the error values are within an upper bound.

**Theorem 3**: _For a similarity matrix \(^{}\), suppose rows \(i\) and column \(i\) are corrupted due to inadequate feature representations being learnt for sample \(i\). When \(||^{}_{[i,:]}||_{2}-||^{}_{[i,: ]}||_{1}+_{1 j n}|^{}_{ij}| 1- \{_{ i}|^{}_{ii}| \}}{n-1}\), the seriation obtained by the spectral ranking algorithm using \(^{}\) is the same as that obtained by the spectral ranking algorithm using \(^{}+^{}\)._

The proof for Theorem 3 can be obtained following a similar approach to Theorem 2. We include detailed derivations in the supplementary materials.

## 4 Experiments

We evaluate our proposed method using three different types of datasets to demonstrate its effectiveness as a general approach for semi-supervised deep regression. We use a synthetic non-linear dataset for operator learning, a medical imaging dataset for brain age estimation from MRI scans, and a natural image dataset for age estimation from photographs.

### Synthetic dataset for non-linear operator learning

We use the non-linear synthetic dataset generated by Lu _et al_. in problem 6 of  and train a neural network to estimate the operator function. The target is the stochastic partial differential equation:

\[-(e^{b(x;w)} u(x;w))=f(x)\;,\] (10)

where \(w\) is stochastic, \(x(0,1)\), and \(e^{b(x;w)}\) is a diffusion coefficient where \(b(x;w)\) follows a random Gaussian process. The Dirichlet boundary conditions are \(u(0)=u(1)=0\), and \(f(x)=10\). The input data \(\{x\}_{i=1}^{N}\) are outputs generated by \((x;w)\) and the target label \(\{y\}_{i=1}^{N}\) is the solution of \(u(x;w)\). More details of the data generation process can be found in problem 6 of .

We use the same architecture and training scheme following , which consists of a two-layer fully connected neural network with 100 hidden units. We perform 10 separate training runs on 1,000 samples each and test our model on a set of 100,000 samples. Mean and standard deviation of the 10 runs are reported. We use ordinal entropy  as the contrastive loss function \(^{SC}\), which is imposed on the feature layer after L2 normalization. Training is performed with a learning rate of \(1 10^{-3}\). We use the entire dataset as an input batch and train for 100,000 epochs. Smaller batches of 10 samples are used to calculate \(^{SC}\), \(^{UC}\), and \(^{UR}\) to reduce computation time due to the quadratic scaling of the feature similarity matrix. We set \(w_{SC}\),\(w_{UC}\), and \(w_{UR}\) to \(1 10^{-3}\) and \(\) to 2. Implementation is done in PyTorch and training is performed on a single V100 Nvidia GPU.

#### 4.1.1 Comparison with state-of-the-art alternatives

We compare with state-of-the-art semi-supervised deep regression methods to demonstrate the effectiveness of our method, CLSS. We adapt conventional mean-teacher  (_Mean-teacher_) and cross psuedo-label  supervision (_CPS_) semi-supervised learning methods for deep regression using a single output value as the regression prediction. We also compare with the state-of-the-art method, UCVME, proposed in . For reference, we show results using a supervised naive regression method using only labeled data. We show in Table 1 results for different settings, where 1/5, 1/4, 1/3, and 1/2 of available labels are used, and the remaining samples are treated as unlabeled data. Additional implementation details are provided in the supplementary materials section.

We can see that semi-supervised methods generally outperform naive supervised regression. Our proposed method, CLSS, convincingly outperforms alternative methods however and consistently improves \(^{2}\) by 3-4% over the next best alternative across all settings. Computational and memory costs for each method are also provided in Section S3.1.5 of the supplementary materials for reference.

#### 4.1.2 Ablation Study

To analyse the effect of different components in our methodology, namely the use of \(^{SC}\), \(^{UC}\), and \(^{UR}\), we perform training with the loss functions added separately to study their impact. We plot the results in Fig. 3 for easier visualization. We can see that each individual component leads to

  \\  Type & Method & 1/5 labels & 1/4 labels & 1/3 labels & 1/2 labels \\  _Supervised_ & Regression & 0.098 \(\) 0.095 & 0.056 \(\) 0.016 & 0.041 \(\) 0.015 & 0.032 \(\) 0.009 \\   & Mean-teacher  & 0.080 \(\) 0.089 & 0.047 \(\) 0.021 & 0.043 \(\) 0.019 & 0.029 \(\) 0.011 \\  & CPS  & 0.057 \(\) 0.012 & 0.045 \(\) 0.016 & 0.041 \(\) 0.015 & 0.028 \(\) 0.007 \\  & UCVME  & 0.040 \(\) 0.008 & 0.033 \(\) 0.008 & 0.027 \(\) 0.007 & 0.028 \(\) 0.021 \\  & CLSS (Ours) & **0.033 \(\) 0.008** & **0.027 \(\) 0.009** & **0.020 \(\) 0.007** & **0.016 \(\) 0.007** \\  ^{2}\)\(\)} \\  Type & Method & 1/5 labels & 1/4 labels & 1/3 labels & 1/2 labels \\  _Supervised_ & Regression & 66.9\% \(\) 39.4 & 83.8\% \(\) 7.7 & 88.5\% \(\) 8.0 & 90.9\% \(\) 5.1 \\   & Mean-teacher  & 69.4\% \(\) 40.1 & 86.9\% \(\) 8.4 & 90.7\% \(\) 7.6 & 92.5\% \(\) 7.2 \\  & CPS  & 84.5\% \(\) 8.8 & 88.8\% \(\) 8.5 & 88.5\% \(\) 8.0 & 93.3\% \(\) 5.3 \\   & UCVME  & 92.2\% \(\) 3.6 & 94.2\% \(\) 2.8 & 95.0\% \(\) 3.0 & 95.6\% \(\) 4.3 \\   & CLSS (Ours) & **96.4\% \(\) 1.7** & **97.3\% \(\) 2.4** & **98.4\% \(\) 1.3** & **99.3\% \(\) 0.5** \\  

Table 1: Comparison with state-of-the-art methods on synthetic non-linear dataset.

significant contributions in improved performance across all settings. This provides further empirical support of the effectiveness of CLSS.

#### 4.1.3 Quality of ordinal rankings from spectral seriation

CLSS uses the ordinal rankings recovered from \(^{}\) to supervise predictions on unlabeled samples. This is based on the observation that the spectral seriation algorithm is robust to errors and more likely to provide accurate supervision. To validate this, we compare with results using rankings derived from predictions \(\) instead of from spectral seriation. We formulate a new loss \(^{UCP}\):

\[^{UCP}=_{i=1}^{||}(( ^{}_{[i,:]}),\;(-|^{}-^{}_{[i]}|) )\,,\] (11)

and train the model using loss function \(=^{SR}+w_{SC}^{SC}+w_{UCP}^{UCP}\). We do not include \(^{UR}\) since predictions \(\) are already used to derive the ranking. Results are shown in Table 2.

We can see that CLSS consistently performs better than using rankings derived from predictions \(^{}\). This validates the observation that rankings obtained through spectral seriation are more robust, leading to better supervision on unlabeled samples.

### Validation on Brain Age estimation from MRI Scans

Semi-supervised deep regression problems are particularly valuable for medical applications, as real-number medical indicators are common for disease tracking [8; 26; 17], and labeled data are usually costly to obtain [20; 21; 9]. We validate CLSS on the IXI brain MRI dataset for brain age estimation . Brain age estimation involves training a model to learn relevant phenotypes from MRI scans associated with brain health and has important applications in detection of diseases such as Alzheimer's [6; 14]. Typically, a model is trained using brain MRIs from healthy patients to predict _chronological_ age, and then used to make predictions for unhealthy patients to estimate their _biological_ brain age for disease screening . This process assumes that patients used for training have similar chronological and biological ages however, which requires data from healthy individuals to be used. By making use of unlabeled data, we can make training more robust since chronological age is not strictly enforced as the ground truth for these samples. This also reduces the reliance on healthy patients for training.

The IXI dataset consists of 588 MRI brain scans with corresponding ages between 20 and 86 . Out of these, we use 88 samples as the test set and 80 samples as the validation set. A 3D ResNet-18  is used as our model. We use a learning rate of \(1 10^{-3}\) with 0.1 decay every 10 epochs and

   & ^{2}\)} \\   & 1/5 labels & 1/4 labels & 1/3 labels & 1/2 labels \\  Regression+\(^{SC}\)+\(^{UCP}\) & 0.039 / 92.4\% & 0.030 / 95.8\% & 0.024 / 96.8\% & 0.016 / 98.5\% \\ CLSS (Ours) & **0.033 / 96.4\%** & **0.027 / 97.3\%** & **0.020 / 98.4\%** & **0.016 / 99.3\%** \\  

Table 2: Results using different rankings for supervision

Figure 3: Ablation results from adding \(^{SC}\), \(^{UC}\) and \(^{UR}\) separately. Using \(^{UC}\) and \(^{UR}\) to supervise unlabeled samples consistently leads to better predictions.

train for a total of 30 epochs. We use a batch size of 16 for labeled samples and a batch size of 8 for unlabeled samples. We set \(w_{SC}=1\), \(w_{UC}=0.05\), \(w_{UR}=0.01\), and \(=2\), which were chosen based on the validation set. To account for unstable training, all experiments were run separately 10 times using different random seeds. Mean and standard deviation of the 10 runs are reported. We use PyTorch for implementation and train on a single V100 Nvidia GPU.

#### 4.2.1 Comparison with state-of-the-art alternatives and ablation studies

We compare results from using CLSS with alternative state-of-the-art semi-supervised methods and show results in Table 3. We use settings where 1/5, 1/4, 1/3, and 1/2 of the dataset is treated as labeled data and remaining samples are treated as unlabeled data.

We can see from the results that our method, CLSS, performs the best under all semi-supervised settings except 1/3 labels. CLSS therefore can be used as an effective way of reducing reliance on labeled data for medical imaging analysis applications. Additional ablation experiments are included in the supplementary materials and demonstrate the importance of each component in CLSS.

### Validation on Age-Estimation from photographs

We also validate our method on a natural image dataset to provide further empirical support. We use the AgeDB-DIR dataset  for performing age-estimation from photographs, a common benchmark task for deep regression. Although photographs of people can easily be obtained online, accurate age labels are not always available due to privacy issues. This challenge can be addressed through semi-supervised deep regression methods to reduce reliance on labeled data. AgeDB-DIR consists of 16,488 images of people with ages ranging between 1 and 101. The dataset has fewer tail samples to reflect real-world label imbalance settings. We use the same data splits provided by the dataset for training, validation, and testing.

We use a ResNet50 network  pretrained on ImageNet  as our deep regression model. We use a learning rate of \(5 10^{-4}\) with decay of 0.1 every 10 epochs and train for 30 epochs. We use a batch size of 32 for labeled samples and a batch size of 8 for unlabeled samples. We set \(w_{SC}=1\), \(w_{UC}=0.05\), \(w_{UR}=0.01\), and \(=2\), which were chosen based on the validation set. To account for unstable training, all experiments were run separately 10 times using different random seeds. Mean and standard deviation of the 10 runs are reported. We use PyTorch for implementation and train on a single V100 Nvidia GPU.

#### 4.3.1 Comparison with state-of-the-art alternatives and ablation studies

We compare results from using CLSS with alternative state-of-the-art semi-supervised methods and show results in Table 4. We use settings where 1/30, 1/25, 1/20, and 1/15 of the dataset is treated as labeled data and remaining samples are treated as unlabeled data.

We can see from the results that CLSS outperforms alternative methods for all settings. Overall, the experiments demonstrate that CLSS can also be applied effectively to natural image datasets. We also include ablation experiments in the supplementary materials to highlight the effect of different components.

  Type & Method & 1/5 labels & 1/4 labels & 1/3 labels & 1/2 labels \\  _Supervised_ & Regression & 9.95 \(\) 1.41 & 11.93 \(\) 1.40 & 11.76 \(\) 1.75 & 10.93 \(\) 1.60 \\   & Mean-teacher  & 11.23 \(\) 2.31 & 10.27 \(\) 1.57 & 10.52 \(\) 3.12 & 12.01 \(\) 2.03 \\  & CPS  & 10.23 \(\) 1.41 & 10.27 \(\) 1.19 & **9.64 \(\) 1.27** & 9.69 \(\) 1.01 \\   & UCVME  & 9.83 \(\) 1.32 & 10.86 \(\) 1.67 & 9.65 \(\) 1.31 & 10.06 \(\) 1.19 \\   & CLSS (Ours) & **9.58 \(\) 1.48** & **9.68 \(\) 1.22** & 9.72 \(\) 1.29 & **9.37 \(\) 1.17** \\  

Table 3: Comparison with state-of-the-art methods on IXI brain age dataset.

## 5 Conclusion

In this work, we propose a novel approach, CLSS, that allows unlabeled data to be used for contrastive learning on deep regression tasks. We make use of the observation that the feature similarity matrix of unlabeled samples also reflect label distance between samples, and that a robust ordinal ranking can be extracted from the matrix using spectral seriation. We derive theoretical bounds for error values in the similarity matrix for which the derived ordinal ranking remains correct, thereby demonstrating the robustness of our method. We validate our method empirically on a synthetic dataset and two real-world datasets and show that our method can outperform alternative state-of-the-art semi-supervised deep regression methods. Overall, CLSS is a useful technique for improving the performance of semi-supervised deep regression models.

## 6 Acknowledgements

This research is supported by grants from the National Natural Science Foundation of China/HKSAR Research Grants Council Joint Research Scheme under Grant N_HKUST627/20, by the Project of Hetao Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone (HZQB-KCZYB-2020083), by the Hong Kong Innovation and Technology Commission (Project no. ITS/030/21 & Project no. PRP/041/22FX), and by Foshan HKUST Projects under FSUST21-HKUST10E and FSUST21-HKUST11E.