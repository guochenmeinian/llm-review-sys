# Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging

Jiamian Wang\({}^{1*}\), Zongliang Wu\({}^{2,3}\), Yulun Zhang\({}^{4}\), Xin Yuan\({}^{2}\), Tao Lin\({}^{2}\), Zhiqiang Tao\({}^{1}\)

\({}^{1}\)Rochester Institute of Technology, \({}^{2}\)Westlake University,

\({}^{3}\)Zhejiang University, \({}^{4}\)Shanghai Jiao Tong University

Corresponding authors: Jiamian Wang (jw4905@rit.edu) and Zhiqiang Tao (zhiqiang.tao@rit.edu)

###### Abstract

Existing reconstruction models in snapshot compressive imaging systems (SCI) are trained with a single well-calibrated hardware instance, making their performance vulnerable to hardware shifts and limited in adapting to multiple hardware configurations. To facilitate cross-hardware learning, previous efforts attempt to directly collect multi-hardware data and perform centralized training, which is impractical due to severe user data privacy concerns and hardware heterogeneity across different platforms/institutions. In this study, we explicitly consider data privacy and heterogeneity in cooperatively optimizing SCI systems by proposing a Federated Hardware-Prompt learning (FedHP) framework. Rather than mitigating the client drift by rectifying the gradients, which only takes effect on the learning manifold but fails to solve the heterogeneity rooted in the input data space, FedHP learns a hardware-conditioned promter to align inconsistent data distribution across clients, serving as an indicator of the data inconsistency among different hardware (e.g., coded apertures). Extensive experimental results demonstrate that the proposed FedHP coordinates the pre-trained model to multiple hardware configurations, outperforming prevalent FL frameworks for \(0.35\)dB under challenging heterogeneous settings. Moreover, a Snapshot Spectral Heterogeneous Dataset has been built upon multiple practical SCI systems. Data and code are available at https://github.com/Jiamian-Wang/FedHP-Snapshot-Compressive-Imaging.git

## 1 Introduction

The technology of snapshot compressive imaging (SCI) (Yuan et al., 2021) has gained prominence in the realm of computational imaging. Taking an example of hyperspectral image reconstruction, the spectral SCI (Gehm et al., 2007) can fast capture and compress 3D hyperspectral signals as 2D measurements through optical hardware, and then restore the original signals with high fidelity by training deep neural networks (Meng et al., 2020; Miao et al., 2019). Despite the remarkable performance (Cai et al., 2022, 2022; Liu et al., 2022; Huang et al., 2021; Hu et al., 2022), existing deep SCI methods are generally trained with a specific hardware configuration, _e.g._, a well-calibrated coded aperture (physical mask). The resulting model is vulnerable to hardware shift/perturbation and limited in adapting to multiple hardware configurations. However, directly learning a reconstruction model cooperatively from multi-hardware seems to be infeasible due to data proprietary constraint. It is also non-trivial to coordinate heterogeneous hardware instances with a unified model.

To elaborate, we first recap previous research efforts of centralized learning solutions. A naive solution is to _jointly train_ a single reconstruction model with data collected from different hardware configurations, _i.e._, coded apertures. As shown in Fig. 1_right_, this solution enhances the ability of reconstruction (\(0.5\)dB\(+\)) by comparison to a single hardware training scenario. However, theperformance on inconsistent coded apertures is still non-guaranteed since the model only learns to fit coded apertures in a purely data-driven manner. Followed by, _self-tuning_(Wang et al., 2022) advances the learning by approximating the posterior distribution of coded apertures in a variational Bayesian framework. Despite the significant performance boost, it is only compatible with the coded apertures drawing from _homogeneous_ hardware (same distribution) yet cannot handle _heterogeneous_ hardware. Nevertheless, centralized learning presumes that hardware instances and hyperspectral data are always publicly available, which hardly holds in practice - both the optical systems (with different confidential configurations, _e.g._, coded apertures) and data samples (_i.e._, measurements captured from non-overlapping scenes) are generally proprietary assets across institutions, adhering to the strict privacy policy constraints (Vergara-Laurens et al., 2016; Li et al., 2021), while considering the multi-hardware cooperative training confining to this concern remains unexplored.

In this work, we leverage federated learning (FL) (Kairouz et al., 2021; Li et al., 2020; Wang et al., 2021) for cross-platform/silo multi-hardware reconstruction modeling without sharing the hardware configurations and local training data. Firstly, the FL benchmark, FedAvg (McMahan et al., 2017), is adopted and brings performance boost (compared by \(3\) and \(4\) in Fig. 1_right_). However, FedAvg has been proven to be limited in solving heterogeneous data (Hsu et al., 2019; Karimireddy et al., 2020) - the heterogeneity in SCI substantially stems from the hardware, which is usually absorbed into the compressed data and governs the network training. Thus, different configurations, _e.g._, coded apertures, yield different data distributions. Besides, we consider a more practical scenario by extending the sample-wise hardware difference into distribution-wise, _i.e._, not only the different coded apertures yield heterogeneity, but also coded apertures from different clients may follow different distributions (see \(P_{1} P_{3}\) in Fig. 1).

To adress the heterogeneity issue, this work proposes a Federated Hardware-Prompt (FedHP) framework to achieve multi-hardware cooperative learning with privacy piratically preserved. Prevalent FL methods handle the heterogeneity by regularizing the global/local gradients (Karimireddy et al., 2020; Li et al., 2020), which only take effect on the learning manifold but fail to solve the heterogeneity rooted in the input data space. Differently, FedHP traces back to the source of the data heterogeneity of this application, _i.e._, inconsistent hardware configurations, and devises a prompt network to solve the client drift issue in input data space. By taking the coded aperture as input, the prompter better accounts for the underlying inconsistency and closes the gap between input data distributions across clients. Besides, the prompter explicitly models the correlation between the software and hardware, empowering the learning by following the spirit of the co-optimization (Goudreault et al., 2023; Zheng et al., 2021; Robidoux et al., 2021) in computational imaging. In addition, FedHP directly operates on pre-trained reconstruction backbones with locally well-trained models and keeps them frozen throughout the learning, which improves the training efficiency than directly optimizing the reconstruction backbones in FL from scratch. We summarize the contributions as follows.

* We introduce and tackle an unexplored problem of hardware cooperative learning in SCI, under the presence of data privacy constraints and heterogeneous configurations. To our best knowledge, the proposed FedHP first integrates federated learning into spectral SCI.

Figure 1: Comparison of hyperspectral reconstruction learning strategies. (1) The model trained with the single hardware (_Prevalent treatment_) hardly handles other hardware. Both (2) _Jointly train_ and (3) _Self-tuning_(Wang et al., 2022) are centralized training solutions. Both (4) FedAvg and the proposed (5) FedHP adopt the same data split setting. We compare the performance gain of different methods over (1). All results are evaluated by unseen masks (non-overlapping) sampled from the practical mask distributions \(\{P_{1},P_{2},P_{3}\}\). FedHP learns a prompt network \(()\) for cooperation.

* We uncover the data heterogeneity of SCI that stems from distinct hardware configurations. A hardware prompt module is developed to solve the distribution shift across clients and empower the hardware-software co-optimization in computational imaging. The proposed method provides an orthogonal perspective in handling the heterogeneity of the existing FL practices.
* We build a new Snapshot Spectral Heterogeneous Dataset (SSHD) from multiple practical spectral snapshot imaging systems. Extensive experiments demonstrate that FedHP outperforms both centralized learning methods and classic federated learning frameworks. The proposed method can inspire future work in this novel research direction of hardware collaboration in SCI.

## 2 Method

### Preliminary Knowledge

We study the cooperative learning problem by taking the representative setup of coded aperture snapshot spectral imaging system for hyperspectral imaging as an example, due to its recent advances (Cai et al., 2022, 2022, 2022). Given the real-world hyperspectral signal \(^{H W N_{}}\), where \(N_{}\) denotes the number of spectral channels, the hardware performs the compression with the physical coded aptertrure \(\) of the size \(H W\), _i.e._, \(_{hw}\). Accordingly, the encoding process produces a 2D measurement \(^{}^{H(W+)}\), where \(\) denotes the shifting

\[^{}=_{n_{}=1}^{N_{}}^{} (:,:,n_{})+,\] (1)

\[^{}(h,w,n_{})=(h,w+d(-^{*}),n_{ }),\]

where \(\) denotes the pixel-wise multiplication and \(\) presents the measurement noise. For each spectral wavelength \(\), the corresponding signal \((:,:,n_{})\) is shifted according to the function \(d(-^{*})\) by referring to the pre-defined anchor wavelength \(^{*}\), such that \(=d(N_{}-1)\). Following the optical encoder, recent practices train a deep reconstruction network \(f()\) to retrieve the hyperspectral data \(}^{H W N_{}}\) by taking the 2D measurement \(^{}\) as input. We define the initial training dataset as \(\) and the corresponding dataset for the reconstruction as \(^{^{*}}\)

\[=\{_{i}\}_{i=1}^{i=N},\ \ ^{^{*}}=\{ _{i}^{^{*}},_{i}\}_{i=1}^{i=N},\] (2)

where \(_{i}\) is the ground truth and \(_{i}^{^{*}}\) is governed by a specific coded aperture \(^{*}\). The reconstruction model finds the local optimum by minimizing the mean squared loss

\[=*{arg\,min}_{}_{i=1}^{N}|| f(;_{i}^{^{*}})-_{i}||_{2}^{2},\] (3)

where \(\) expresses all learnable parameters in the reconstruction model. \(}_{i}=f(;_{i}^{^{*}})\) is the prediction. Pre-trained reconstruction models (Cai et al., 2022, Huang et al., 2021) demonstrates promising performance when is compatible with a single encoder set-up, where the measurement in training and testing phases are produced by the same hardware using a fixed coded aperture of \(^{*}\).

**Motivation**. Previous work (Wang et al., 2022) uncovered that most existing reconstruction models experience large performance descent (_e.g._, \(>2\)dB in terms of PSNR) when handling the data encoded by a different coded aperture \(^{}\) from training, _i.e._, \(^{}^{*}\) as mask determines the data distribution and also takes effect in learning as (3). Thus, a well-trained reconstruction model can be highly sensitive to a specific hardware configuration of coded aperture and is hardly compatible with the other optical systems in the testing phase. A simple solution of adapting the reconstruction network to a different coded aperture \(^{}\) is to retrain the model with corresponding dataset \(^{^{}}=\{_{i}^{^{}}, _{i}\}_{i=1}^{i=N}\)and then test upon \(^{}\) accordingly. However, this solution does not broaden the adaptability of reconstruction models to multi-hardware and can introduce drastic computation overhead. In this work, we tackle this challenge by learning a reconstruction model cooperatively from multiple hardware with inconsistent configurations.

### Centralized Learning in SCI

**Jointly Train**. To solve the above problem, _Jointly train_ (Fig. 1 part \(2\)) serves as a naive solution to train a model with data jointly collected upon a series of hardware. Assuming there are total number of \(K\) hardware with different coded apertures, _i.e._, \(_{1},_{2},...,_{K}\). Each hardware produces a training dataset upon \(\) as \(^{_{k}}=\{_{i}^{_{k}},_{i} \}_{i=1}^{i=N}\). The joint training dataset for reconstruction is

\[^{_{1 K}}=^{_{1}}^{_{2}}...^{_{K}},\] (4)

where different coded apertures can be regarded as hardware-driven data augmentation treatments toward the hyperspectral data. The reconstruction model will be trained with the same mean squared loss provided in (3) upon \(^{_{1 K}}\). [Wang et al., 2022] demonstrated that jointly learning brings performance boost compared with single mask training (Fig. 1_right_). However, this method adopts a single well-trained model to handle coded apertures, failing to adaptively cope with the underlying discrepancies and thus, leading to compromised performances for different hardware.

**Self-tuning**. Following _Jointly train_, recent work of _Self-tuning_[Wang et al., 2022] recognizes the coded aperture that plays the role of hyperparameter of the reconstruction network, and develops a hyper-net to explicitly model the posterior distribution of the coded aperture by observing \(^{_{1 K}}\). Specifically, the hyper-net \(h(;_{k})\) approximates \(P(|^{_{1 K}})\) by minimizing the Kullback-Leibler divergence between this posterior and a variational distribution \(Q()\) parameterized by \(\). Compared with _Jointly train_, _Self-tuning_ learns to adapt to different coded apertures and appropriately calibrates the reconstruction network during training, even if there are unseen coded apertures. However, the variational Bayesian learning poses a strict distribution constraint to the sampled coded apertures, which limits the scope of _Self-tuning_ under the practical setting.

To sum up, both of the _Jointly train_ and _Self-tuning_ are representative solutions of centralized learning, where the dataset \(\) and hardware instances with \(_{1},...,_{K}\) from different sources are presumed to be publicly available. Such a setting has two-fold limitations. (1) Centralized learning does not take the privacy concern into consideration. Hardware configuration and data information sharing across institutions is subject to the rigorous policy constraint. (2) Existing centralized learning methods mainly consider the scenario where coded apertures are sampled from the same distribution, _i.e._, hardware origin from the same source, which is problematic when it comes to the coded aperture distribution inconsistency especially in the cross-silo case. Bearing the above challenges, in the following, we resort to the federated learning (FL) methods to solve the cooperative learning of reconstruction considering the privacy and hardware configuration inconsistency.

### Federated Learning in SCI

**FedAvg**. We firstly tailor FedAvg [McMahan et al., 2017], into SCI. Specifically, we exploit a practical setting of cross-silo learning in snapshot compressive imaging. Suppose there are \(C\) clients, where each client is packaged with a group of hardware following a specific distribution of \(P_{c}\)

\[_{k}^{c} P_{c},\] (5)

where \(_{k}^{c}\) represents \(k\)-th sampled coded aperture in \(c\)-th client. For simplicity, we use \(^{c}\) to denote arbitrary coded aperture sample in \(c\)-th client as shown in Eq. (5). Based on the hardware, each client computes a paired dataset \(^{^{c}}\) from the local hyperspectral dataset \(_{c}\)

\[_{c}=\{_{i}\}_{i=1}^{i=N_{c}},\ \ ^{ ^{c}}=\{_{i}^{^{c}},_{i}\}_{i=1}^{i=N_ {c}},\] (6)

where \(N_{c}\) represents the number of hyperspectral data in \(_{c}\). The local learning objective is

\[_{c}()=_{i=1}^{N}||}_{i}-_{i}||_{2}^{2},\] (7)

where \(}_{i}=f(;_{i}^{^{c}}), \ ^{c} P_{c}\), we use \(\) to denote the learnable parameters of reconstruction model at a client. FedAvg learns a global model \(_{G}\) without sharing the hyperspectral signal dataset \(_{c}\), \(^{^{c}}\), and \(^{c}\) across different clients. Specifically, the global learning objective \(_{G}()\) is

\[_{G}()=_{c=1}^{C^{}}_{c}_{c}(),\] (8)

where \(C^{}\) denotes the number of clients that participate in the current global round and \(_{c}\) represents the aggregation weight. Compared with the centralized learning solutions, FedAvg not only bridges the local hyperspectral data without sharing sensitive information, but also collaborates multi-hardware with a unified reconstruction model for a better performance (Fig. 1_right_ comparison between \(3\) and \(4\)). However, FedAvg shows limitations in two-folds. (1) It has been shown that FedAvg is hard to handle the heterogeneous data (Karimireddy et al., 2020; Khaled et al., 2020; Hsu et al., 2019). (2) Directly training the reconstruction backbones from scratch would introduce prohibitive computation. Next, we firstly introduce the hardware-induced data heterogeneity in SCI. Then we develop a Federated Hardware-Prompt (FedHP) method to achieve cooperative learning without optimizing the client backbones.

**Data Heterogeneity**. We firstly consider the data heterogeneity stems from the _different coded apertures samples, i.e._, hardware instances. According to Section 2.1, the optical hardware samples the hyperspectral signal \(_{i}\) from \(=\{_{i}\}_{i=1}^{i=N}\) and encodes it into a 2D measurement \(_{i}^{}\), which constitutes \(^{}\) and further serves as the input data for the reconstruction model. To this end, the modality of \(\{_{i}^{}\}_{i=N}^{i=1}\) is vulnerable to the coded aperture variation. A single coded aperture \(\) defines a unique input data distribution for the reconstruction, _i.e._, \(_{i}^{} P_{}(_{i}^{})\). For arbitrary distinct coded apertures, we have \(P_{^{*}}(_{i}^{^{*}}) P_{^{ }}(_{i}^{^{}})\) if \(^{*}^{}\). In federated learning, data heterogeneity persistently assincle there is no identical coded aperture across different clients. Such a heterogeneous scenario, _i.e._, sampling _non-overlapping masks_ from the same mask distribution, can be caused by lightning distortion or optical platform fluttering.

We take a step further to consider the other type of data heterogeneity stemming from the _distinct distributions of coded apertures_2. As formulated in (6), each client collects a coded aperture assemble following the distribution \(P_{c}\) for \(c\)-th client. We have \(P_{c}\) differs from one another, _i.e._, \(P_{c1} P_{c2}\) for \(c1 c2\), \(c1,c2\{1,...,C\}\). Hardware instances from different clients are produced by distinct manufacturing agencies, so that the distribution \(P_{c1}\) and \(P_{c2}\) drastically differs as demonstrated in Fig. 1. This is a more challenging scenario than previous case. As presented in Section 3.2, classic federated learning methods, _e.g._, FedProx (Li et al., 2020) and SCAFFOLD (Karimireddy et al., 2020) hardly converge while the proposed method enables an obvious performance boost.

### FedHP: Federated Hardware-Prompt Learning

**Hardware-Prompt Learning**. Bearing the heterogeneous issue, previous efforts (Li et al., 2020; Karimireddy et al., 2020) mainly focus on rectifying the global/local gradients upon training, which only _takes effect on the learning manifold_ but fail to _solve the heterogeneity_ rooted in the input data space, whose effectiveness in this low-level vision task may be limited. Since we uncover two types of the heterogeneity in snapshot compressive imaging stemming from the hardware inconsistency (Section. 2.3), this work opts to tackling the client drift issue by directly operating in the input data space. This can be achieved by collaboratively learning the input data alignment given different coded apertures. In light of the visual prompt tuning in large models (Liu et al., 2023; Bahng et al., 2022), we devise a hardware-conditioned prompt network in the following.

As shown in the _Step 2_ of Fig. 2, given the input data \(\{_{i}^{}\}_{i=1}^{i=N}\) of the reconstruction, the prompt network aligns the input samples, _i.e._, measurements \(^{_{i}}\), by adding a prompter conditioned on the hardware configuration. Let \((;)\) denote the prompt network (_e.g._, attention block) parameterized

Figure 2: Learning process of FedHP. We take one global round as an example, which consists of (1) _Initialize_, (2) _Local Update (Prompt)_, (3) _Local Update (Adaptor)_, and (4) _Aggregation_. For each client, the reconstruction backbone \((_{c}^{p})\), is initialized as pre-trained model upon local training dataset \(_{c}\) and kept as frozen throughout the training. The prompt net upon hardware configuration, _i.e._, coded aperture, takes effect on the input data of reconstruction, _i.e._, \(^{}\). Adaptors are introduced to enhance the learning, where \(_{c}\) denotes the parameters of all adaptors.

by \(\) and \(_{i}^{}\) is produced upon coded aperture \(\). Then, the resulting input sample is aligned as

\[_{i}^{}=_{i}^{}+(;).\] (9)

In the proposed method, the prompt network collaborates different clients with inconsistent hardware configurations. It takes effect by implicitly observing and collecting diverse coded aperture samples of all clients, and jointly learns to react to different hardware settings. The promoter regularizes the input data space and achieves the goal of coping with heterogeneity sourcing from hardware.

**Training**. As shown in Fig. 2, we demonstrate the training process of proposed FedHP by taking one global round as an example3. Since the prompt learning takes effect on pre-trained models, we initialize the \(c\)-th backbone parameters with the pre-trained model \(_{c}^{p}\) on local data \(^{^{c}}\) with (7). The global prompt network \(_{G}\) is randomly initialized and distributed to the \(c\)-th client

\[_{c}_{G},\ c=1,...,C^{},\] (10)

where \(_{c}\) is the local prompt network, and \(C^{}\) denotes the number of clients participated in the current global round. To enable better response of the pre-trained backbone toward the aligned input data space, we also introduce the adaptors into the transformer backbone. As shown in Fig. 2_Step 3_, we show the architecture of the proposed adaptor, which is a _CONV-GELU-CONV_ structure governed by a residual connection. We insert the adaptors behind the _LN_ layers.

We perform local updates in each global round. It is composed of two stages. Firstly, we update the local prompt network \(_{c}\) for \(S_{p}\) iterations, and fix all the other learnable parameters. The loss is

\[_{c}=_{i=1}^{N}||f(_{c}^{p},_{c};_{ i}^{^{c}}+(^{c}))-_{i}||_{2}^{2},\] (11)

where we use \(_{c}\) to represent learnable parameters of all adaptors for \(c\)-th client. Secondly, we tune the adaptors for another \(S_{b}\) iterations. Both of the pre-trained backbone and prompt network are frozen. The loss of \(c\)-th client shares the same formulation as (11). After the local update, FedHP uploads and aggregates the learnable parameters \(_{c}\), \(c=1,...,C\) of the prompt network. Since the proposed method does not require to optimize and communicate the reconstruction backbones, the underlying cost is drastically reduced considering the marginal model size of prompt network and adaptors compared with the backbone, which potentially serves as a supplied benefit of FedHP.

Compared with FedAvg, FedHP adopts the hardware prompt to explicitly align the input data representation and handle the distribution shift attributing to the coded aperture inconsistency or coded aperture distribution discrepancy.

## 3 Experiments

### Implementation details

**Dataset**. Following existing practices (Cai et al., 2022; Lin et al., 2022; Hu et al., 2022; Huang et al., 2021), we adopt the benchmark training dataset of CAVE (Yasuma et al., 2010), which is composed of \(32\) hyperspectral images with the spatial size as \(512 512\). Data augmentation techniques of rotation, flipping are employed, producing \(205\) different training scenes. For the federated learning, we equally split the training dataset according to the number of clients \(C\). The local training dataset are kept and accessed confidentially across clients. Note that one specific coded aperture determines a unique dataset according to (2), the resulting data samples for each client can be much more than \(205/C\). We employ the widely-used simulation testing dataset for the quantitative evaluation, which consists of ten \(256 256 28\) hyperspectral images collected from KAIST (Choi et al., 2017). Besides, we use the real testing data with spatial size of \(660 660\) collected by a SD-CASSI system (Meng et al., 2020) for the perceptual evaluation considering the real-world perturbations.

**Hardware**. We collect and will release the first Snapshot Spectral Heterogeneous Dataset (SSHD) containing a series of practical SCI systems, from three agencies, each of which offers a series of coded apertures that correspond to a unique distribution4 as presented by federated settings in Fig. 2. No identical coded apertures exists among all systems. For the case of inconsistent mask distributions,we directly assign hardware systems from one source to form a client. We simulate the scenario of non-overlapping masks by distributing coded apertures from one source to different clients.

**Implementation details**. We adopt MST-S  as the reconstruction backbone. The prompt network is instantiated by a SwinIR  block. Limited by the computational resource, we set the number of clients as \(3\) in main comparison. We empirically find that collaborate such amount of clients can be problematic for popular federated learning methods under the very challenging scenario of data heterogeneity (see Section 3.2). For FL methods, we update all clients throughout the training, _i.e._, \(C^{}=C=3\). For the proposed method, we pre-train the client backbones from scratch for \(4 10^{4}\) iterations on their local data. Notably, the total training iterations of different methods are kept as \(1.25 10^{5}\) for a fair comparison. The batch is set as \(12\). We set the initial learning rate for both of the prompt network and adaptor as \(_{p}=_{b}=1 10^{-4}\) with step schedulers, _i.e._, half annealing every 2\(\)10\({}^{4}\) iterations. We train the model with an Adam  optimizer (\(_{1}=0.9,_{2}=0.999\)). We use PyTorch  on an NVIDIA A100 GPU.

**Compared Methods**. We compare FedHP with mainstream FL methods, including FedAvg , FedProx , and SCAFFOLD . Besides, GST  paves the way for the robustness of the reconstruction toward multiple hardware. Thereby, we integrate this method into the FL framework, dubbed as FedGST. All methods require to train and aggregate the entire client backbones. By comparison, FedHP updates and shares the prompt network, outperforming the others with smaller amount of parameters being optimized and communicated. We adopt PSNR and SSIM  for the quantitative evaluation.

### Performance

**Simulation Results**. We quantitatively compare different methods in Table 1 by considering the data heterogeneity stems from non-overlapping masks. FedHP performs better than the classic federated

    &  &  &  &  &  \\   & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM \\ 
1 & 31.98\(\)0.19 & 0.893\(\)0.0025 & 31.85\(\)0.023 & 0.890\(\)0.0038 & 31.78\(\)0.26 & 0.888\(\)0.0025 & 32.02\(\)0.14 & 0.891\(\)0.0048 & **32.31\(\)0.10** & **90.026\(\)0.0020** \\
2 & 34.09\(\)0.01 & 0.862\(\)0.011 & 29.85\(\)0.022 & 0.851\(\)0.027 & 29.81\(\)0.0247 & 0.847\(\)0.013 & 31.19\(\)0.02 & 0.851\(\)0.0043 & **30.78\(\)0.0038** \\
3 & 31.78\(\)0.02 & 0.008\(\)0.0038 & 30.80\(\)0.0037 & 0.908\(\)0.017 & 0.907\(\)0.01 & 0.906\(\)0.014 & 31.19\(\)0.02 & 0.851\(\)0.0043 & **31.26\(\)0.00** & **31.099\(\)0.018** \\
4 & 33.99\(\)0.20 & 0.959\(\)0.0037 & 34.10\(\)0.02 & 0.960\(\)0.0031 & 39.32\(\)0.26 & 0.956\(\)0.0013 & 38.99\(\)0.27 & 0.951\(\)0.0043 & **39.78\(\)0.0037** & **39.76\(\)0.0038** \\
5 & 28.39\(\)0.20 & 0.852\(\)0.0014 & 0.852\(\)0.0014 & 0.876\(\)0.0013 & 0.874\(\)0.0012 & 28.51\(\)0.0012 & 0.874\(\)0.0013 & **38.52\(\)0.0017** \\
6 & 30.53\(\)0.00 & 0.906\(\)0.0015 & 30.04\(\)0.02 & 0.905\(\)0.0042 & 29.87\(\)0.0014 & 0.901\(\)0.0019 & 30.29\(\)0.02 & 0.849\(\)0.0012 & **30.77\(\)0.012** \\
7 & 30.01\(\)0.20 & 0.831\(\)0.0027 & 27.60\(\)0.02 & 0.871\(\)0.0025 & 26.53\(\)0.0017 & 0.830\(\)0.0027 & 32.95\(\)0.0018 & **30.78\(\)0.0016** & **30.46\(\)0.0016** & **30.88\(\)0.0012** \\
8 & 28.60\(\)0.01 & 0.888\(\)0.0038 & 27.59\(\)0.0023 & 0.884\(\)0.0025 & 27.74\(\)0.01 & 0.880\(\)0.0018 & 28.35\(\)0.0018 & **28.36\(\)0.0018** & **32.54\(\)0.0018** \\
9 & 31.45\(\)0.01 & 0.901\(\)0.0013 & 31.29\(\)0.0141 & 0.986\(\)0.0013 & 31.22\(\)0.012 & 0.892\(\)0.0013 & 30.00\(\)0.0180 & 0.885\(\)0.0001 & **31.34\(\)0.01** & **30.043\(\)0.013** \\
10 & 29.94\(\)0.01 & 0.875\(\)0.012 & 20.84\(\)0.013 & 0.867\(\)0.0023 & 23.96\(\)0.0026 & 28.51\(\)0.0028 & 28.51\(\)0.013 & 0.857\(\)0.0004 & **29.12\(\)0.013** & **0.835\(\)0.012** \\ 
4vg. & 31.21\(\)0.10 & 0.8959\(\)0.0017 & 30.76\(\)0.00 & 0.8900\(\)0.0046 & 30.71\(\)0.00 & 0.8872\(\)0.0013 & 30.85\(\)0.011 & 0.8855\(\)0.0017 & **31.35\(\)0.01** & **0.9033\(\)0.011** \\   

Table 1: PSNR(dB)/SSIM performance comparison. For different clients, we sample non-overlapping masks from the same mask distribution to train the model and use unseen masks randomly sampled from all clients for testing. We report _mean\(\)std_ among 100 trials for all the samples.

Figure 3: Reconstruction results on simulation data. The density curves compare the spectral consistency of different methods to the ground truth. We use the same coded aperture for all methods.

learning methods. By comparison, FedProx and SCAFFOLD only allows sub-optimal performance, which uncovers the limitations of rectifying the gradient directions in this challenging task. Besides, FedGST works inferior than FedHP, since FedGST approximates the posterior and expects coded apertures strictly follows the identical distribution, which can not be guaranteed in practice. In Fig. 3, we visualize the reconstruction results with sampled wavelengths. FedHP not only enables a more granular retrieval on unseen coded aperture, but also maintains a promising spectral consistency as shown by randomly cropped patches (_e.g._, a, b in Fig. 3).

**Challenging Scenario of Heterogeneity** We consider a more challenging scenario where the data heterogeneity is caused the _distinct coded aperture distributions of different clients_. We compare different methods in Table 2. All methods experience large performance degradation, among which FedProx and SCAFFOLD becomes ineffective. Intuitively, it is hard to concur the clients under the large distribution gap, while directly adjusting the input data space better tackles the problem.

**Real Results**. In Fig. 4, we visually compare the FedAvg with FedHP on the real data. Specifically, both methods are evaluated under an unseen hardware configuration, _i.e._, coded aperture from an uncertain distribution. The proposed method introduces less distortions among different wavelengths. Such an observation endorses FedHP a great potential in collaborating hardware systems practically.

### Model Discussion

We conduct model discussion in Table 3. Specifically, we accumulate the total cost (_e.g._, number of parameters, GMACs, and training time) of all clients in a federated system.

**Ablation Study**. We firstly consider a scenario that trains three clients independently without FL (_FedHP w/o FL_). For a fair comparison, each client pre-trains the backbone by using the same procedure as FedHP and are then enhanced with a prompt network and adaptors for efficient fine-tuning. By comparison, FedHP enables an obvious improvement (\(0.6\)dB) by implicitly sharing the hardware and data. We then investigate the effectiveness of the promper and adaptor to the reconstruction, respectively. By observation, directly removing the adaptor leads to limited performance descent. Using prompt network brings significant performance boost. The hardware promper aligns the input data distributions, potentially solving the heterogeneity rooted in the input data space, considering fact that learning manifold is highly correlated with the coded apertures.

**Discussion of the client number**. In Table 3(a), we discuss the power of FedHP with more real clients under the scenario of _Hardware shaking_. The performance gap between FedHP and FedAvg consistently remains with the client number increasing, which demonstrates the practicability of the FedHP for the cross-silo spectral system cooperative learning, _e.g._, \(3 5\) clients/institutions.

    &  &  &  &  &  &  \\   & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM & PSNR & SSIM \\ 
1 & 29.15\({}_{0.00}\) & 0.8392\({}_{0.0042}\) & 23.01\({}_{0.011}\) & 0.5540\({}_{0.0002}\) & 229.9\({}_{0.13}\) & 0.5535\({}_{0.0006}\) & 29.46\({}_{0.01}\) & 0.8344\({}_{0.0007}\) & **30.37\({}_{0.70}\)** & **0.5628\({}_{0.0004}\)** \\
2 & 28.28\({}_{0.010}\) & 0.8102\({}_{0.0023}\) & 20.91\({}_{0.00}\) & 0.4486\({}_{0.0002}\) & 20.98\({}_{0.94}\) & 0.4474\({}_{0.0003}\) & 27.93\({}_{0.30}\) & 0.7733\({}_{0.70}\) & **28.67\({}_{0.0002}\)** \\
3 & 28.42\({}_{0.011}\) & 0.5464\({}_{0.0004}\) & 17.57\({}_{0.0004}\) & 0.4626\({}_{0.0002}\) & 17.58\({}_{0.0003}\) & 20.4608\({}_{0.0003}\) & 28.45\({}_{0.0003}\) & 0.8633\({}_{0.0003}\) & **29.51\({}_{0.0003}\)** & **0.8577\({}_{0.0005}\)** \\
4 & 36.93\({}_{0.007}\) & 0.9596\({}_{0.0003}\) & 20.08\({}_{0.0003}\) & 23.02\({}_{0.0000}\) & 0.4881\({}_{0.0003}\) & 16.21\({}_{0.0003}\) & 0.9188\({}_{0.0003}\) & **37.37\({}_{0.0003}\)** & **0.9395\({}_{0.0003}\)** \\
5 & 25.84\({}_{0.0007}\) & 0.8037\({}_{0.0003}\) & 0.8037\({}_{0.0003}\) & 0.4136\({}_{0.0003}\) & 20.98\({}_{0.0003}\) & 20.189\({}_{0.0003}\) & 26.21\({}_{0.0003}\) & 0.7988\({}_{0.0003}\) & **27.47\({}_{0.0003}\)** & **0.8577\({}_{0.0003}\)** \\
6 & 27.28\({}_{0.000}\) & **0.8656\({}_{0.0004}\)** & 19.10\({}_{0.0004}\) & 0.4077\({}_{0.0004}\) & 19.19\({}_{0.0004}\) & 0.4063\({}_{0.0003}\) & 27.52\({}_{0.0004}\) & 0.8386\({}_{0.0004}\) & **28.31\({}_{0.0004}\)** & **28.31\({}_{0.0004}\)** & 0.5699\({}_{0.0003}\) \\
7 & 26.10\({}_{0.000}\) & 0.8032\({}_{0.0004}\) & 19.05\({}_{0.0003}\) & 0.4936\({}_{0.0003}\) & 19.426\({}_{0.0003}\) & 19.45\({}_{0.0003}\) & 26.25\({}_{0.0003}\) & 0.872\({}_{0.0004}\) & **28.325\({}_{0.0004}\)** & **0.8259\({}_{0.0003}\)** \\
8 & 25.77\({}_{0.000}\) & **0.8473\({}_{0.0000}\)** & 19.84\({}_{0.0001}\) & 19.89\({}_{0.0004}\) & 0.4026\({}_{0.0003}\) & 26.22\({}_{0.0004}\) & 0.8206\({}_{0.0002}\) & **26.45\({}_{0.0003}\)** & **0.8547\({}_{0.0004}\)** \\
9 & 28.30\({}_{0.000}\) & **0.8541\({}_{0.0004}\)** & 18.33\({}_{0.0004}\) & 0.4285\({}_{0.0004}\) & 18.30\({}_{0.0004}\) & 0.4269\({}_{0.0003}\) & 27.41\({}_{0.0003}\) & 0.8199\({}_{0.0004}\) & **29.36\({}_{0.0004}\)** & 0.8536\({}_{0.0004}\) \\
10 & 26.04\({}_{0.010}\) & 0.3075\({}_{0.0005}\) & 20.0020 & 0.3046\({}_{0.0002}\) & 20.036\({}_{0.0004}\) & 20.03\({}_{0.0003}\) & 0.3451\({}_{0.0002}\) & 22.72\({}_{0.0002}\) & 0.7433\({}_{0.0004}\) & **27.76\({}_{0.0004}\)** & **0.8211\({}_{0.0004}\)** \\   

Table 2: PSNR(dB)/SSIM performance comparison. Mass from each client are sampled from a _specific_ distribution for training. We randomly sample non-overlapping masks (unseen to training) from all distributions for testing. We report _mean\({}_{ 4}\)_ among 100 trials for all methods.

Figure 4: Visualization of reconstruction results on real data. Six representative wavelengths are selected. We use the same unseen coded aperture for both FedAvg and FedHP.

**Comparison with a deep unfolding method**. We also compare the proposed FedHP with a representative deep unfolding method of GAP-Net (Meng et al., 2023) as deep unfolding methods can be adaptable to various hardware configurations. Specifically, we use three clients and keep training and testing settings of GAP-Net the same as FedHP. As shown in Table 3(b), FedHP improves by \(0.28\)dB with only \(7\%\) model size. In fact, despite the adaptability, deep unfolding still shows limitations in solving hardware perturbation/replacement for a given system (Wang et al., 2022).

## 4 Related Work

**Hyperspectral Image Reconstruction**. In hyperspectral image reconstruction (HSI), learning deep reconstruction models (Cai et al., 2022a,b, Lin et al., 2022; Huang et al., 2021; Meng et al., 2020; Hu et al., 2022; Miao et al., 2019) has been the forefront among recent efforts due to high-fidelity reconstruction and high-efficiency. Among them, MST (Cai et al., 2022a) devises the first transformer backbone by computing spectral attention. Existing reconstruction learning strategies mainly considers the compatibility toward a single hardware instance. The learned model can be highly sensitive to the variation of hardware. To tackle this practical challenge, GST (Wang et al., 2022) paves the way by proposing a variational Bayesian learning treatment.

**Federated Learning**. Federated learning (Kairouz et al., 2021; Li et al., 2020; Wang et al., 2021) collaborates client models without sharing the privacy-sensitive assets. However, FL learning suffers from client drift across clients attributing to the data heterogeneity issue. One mainstream (Karimireddy et al., 2020; Li et al., 2020; Xu et al., 2021; Jhunjhunwala et al., 2023; Reddi et al., 2021) mainly focus on regularizing the global/local gradients. As another direction, personalized FL methods (Collins et al., 2021; Chen and Chao, 2022; Fallah et al., 2020; T Dinh et al., 2020; Jiang and Lin, 2023) propose to fine-tune the global model for better adaptability on clients. However, customizing the global model on client data sacrifices the underlying robustness upon data distribution shift (Wu et al., 2022; Jiang and Lin, 2023), which contradicts with our goal of emphasizing the generality across hardware and thus is not considered. In this work, we propose a federated learning framework to solve the multi-hardware cooperative learning considering the data privacy and heterogeneity, which to the best knowledge, is the first attempt of empowering spectral SCI with FL. Besides, the principle underlying this method can be potentially extended to broad computational imaging applications (Zheng et al., 2021; Liu et al., 2023; Goudreault et al., 2023; Robidoux et al., 2021)

## 5 Conclusion

In this work, we observed an unexplored research scenario of multiple hardware cooperative learning in spectral SCI, considering two practical challenges of privacy constraint and the heterogeneity stemming from inconsistent hardware configurations. We developed a Federated Hardware-Prompt (FedHP) learning framework to solve the distribution shift across clients and empower the hardware-software co-optimization. The proposed method serves as a first attempt to exploit the power of FL in spectral SCI. Besides, we have collected a Snapshot Spectral Heterogeneous Dataset (SSHD) from multiple real spectral SCI systems. Future works may theoretically derive the convergence of FedHP and exploit the behavior of FedHP under a large number of clients. We hope this study will inspire broad explorations in this novel direction of hardware collaboration in SCI.

Table 4: Model discussions of the proposed FedHP.

Table 3: Ablation study and complexity analysis under the non-overlapping masks. The PSNR (dB)/SSIM are computed among 100 testing trials. We report the model complexity and the accumulative training time of all clients (_e.g._, \(C=3\)).