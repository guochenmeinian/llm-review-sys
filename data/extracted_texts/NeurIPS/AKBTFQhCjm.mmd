# DEFT: Efficient Fine-Tuning of Diffusion Models by Learning the Generalised \(h\)-transform

Alexander Denker

University College London

a.denker@ucl.ac.uk

&Francisco Vargas*

University of Cambridge

fav25@cam.ac.uk

&Shreyas Padhy*

University of Cambridge

sp2058@cam.ac.uk

&Kieran Didi*

University of Cambridge

ked48@cam.ac.uk

&Simon Mathis*

University of Cambridge

svm34@cam.ac.uk

&Vincent Dutordoir

University of Cambridge

vd309@cam.ac.uk

&Riccardo Barbano

Atinary Technologies

rbarbano@atinary.com

&Emile Mathieu

University of Cambridge

ebm32@cam.ac.uk

&Urszula Julia Komorowska

University of Cambridge

ujk21@cam.ac.uk

&Pietro Lio

University of Cambridge

pl219@cam.ac.uk

equal contributions

###### Abstract

Generative modelling paradigms based on denoising diffusion processes have emerged as a leading candidate for _conditional_ sampling in inverse problems. In many real-world applications, we often have access to large, expensively trained unconditional diffusion models, which we aim to exploit for improving conditional sampling. Most recent approaches are motivated heuristically and lack a unifying framework, obscuring connections between them. Further, they often suffer from issues such as being very sensitive to hyperparameters, being expensive to train or needing access to weights hidden behind a closed API. In this work, we unify conditional training and sampling using the mathematically well-understood _Doob's h-transform_. This new perspective allows us to unify many existing methods under a common umbrella. Under this framework, we propose DEFT _(Doob's h-transform Efficient FineTuning)_, a new approach for conditional generation that simply fine-tunes a very small network to quickly learn the conditional \(h\)-transform, while keeping the larger unconditional network unchanged. DEFT is much faster than existing baselines while achieving state-of-the-art performance across a variety of linear and non-linear benchmarks. On _image reconstruction_ tasks, we achieve speedups of up to 1.6\(\), while having the best perceptual quality on natural images and reconstruction performance on medical images. Further, we also provide initial experiments on protein motif scaffolding and outperform reconstruction guidance methods.

## 1 Introduction

Denoising diffusion models are a powerful class of generative models where noise is gradually added to data samples until they converge to pure noise. The time reversal of this noising process thenallows noise to be transformed into samples. This process has been widely successful in generating high-quality images  and has more recently shown promise in designing protein backbones that have been validated in experimental protein design workflows . Recently, there has been much interest in _conditioning_ the time reversal process, in order to generate samples that are subject to an observed condition. Conditional sampling requires the posterior score \(_{} p_{t}(|=)\), given some observation \(\). As diffusion models typically approximate the score of the underlying distribution, i.e., \(s_{t}^{^{*}}()_{} p_{t}()\), a pre-trained diffusion model can be leveraged using Bayes' theorem

\[_{} p_{t}(|=) s_{t}^{ ^{*}}()+_{} p_{t}(=|),\] (1)

to approximate the posterior score. The time-dependent likelihood \(_{} p_{t}(=|)\) is often termed _guidance_ due to its interpretation to guide the reverse process to the conditioned inputs, and is unfortunately analytically intractable. To tackle this problem, several approximations for the _guidance_ have been proposed; see, for example, [12; 22; 29; 56; 65; 69] and further discussion in Appendix B. Instead of relying on the decomposition (1), another line of work aims to learn the posterior score directly [5; 27], which requires expensive training for new conditional sampling tasks, and access to large amounts of paired data points.

In the setting of conditional generation with diffusion models, our primary goal is to leverage large pre-trained foundation models which are prevalent in applications, but which typical front-end users are not able to backpropagate through, making approaches like [12; 22] infeasible. This might be due to their prohibitive computation times or because they lie behind an API preventing the usage of autodiff frameworks.

In this work, we propose a unified framework for conditional generation using Doob's \(h\)-transform, a well-known result in the stochastic differential equations (SDE) literature [14; 55; 61; 78]. Under this framework, we propose DEFT _(Doob's \(h\)-transform Efficient FineTuning)_, an algorithm that estimates the time-dependent likelihood directly from data, i.e., \(h^{*}=_{} p_{t}(=|)\), while being able to leverage an existing pre-trained unconditional model. We learn the guidance term (\(h\)-transform) efficiently using 1) smaller networks, and 2) a small training dataset of paired data points and corresponding observations. Furthermore, through connections to stochastic control, we propose a novel network architecture for general-purpose fine-tuning, which, in conjunction with our

Figure 1: DEFT reverse diffusion setup. The pre-trained unconditional diffusion model \(s_{t}^{}\) and the fine-tuned \(h\)-transform \(h_{t}^{}\) are combined at every sampling step. We propose a special network to parametrise the \(h\)-transform including the guidance term \(_{}_{0}} p(|}_{0})\) as part of the architecture. Here \(}_{0}\) denotes the unconditional denoised estimate given \(s_{t}^{}(_{t})\). During training, we only need to fine-tune \(h_{t}^{}\) (usually \(4\)-\(9\%\) the size of \(s_{t}^{}\)) using a small dataset of paired measurements, keeping \(s_{}^{t}\) fixed. During sampling, we do not need to backpropagate through either model, resulting in speed-ups during evaluation.

proposed loss, achieves competitive results across a series of inverse problems in imaging and protein design, while having a much lower computational cost.

## 2 Conditioning diffusions via the \(h\)-transform

In this section, we explore the formal mechanism to condition the boundary points of an SDE mathematically, and connect it to existing methodologies for conditioning diffusions in generative modelling. For a more rigorous background to denoising diffusion models, see Appendix A. Let us first recap the score-based generative modelling framework of ; we start with a forward SDE, which progressively transforms the target distribution \(_{0}\) (e.g. \(_{0}=p_{}\))

\[_{t}=f_{t}(_{t})\,t+_{t}}_{t},_{0}_{0},\] (2)

with drift \(f_{t}\) and diffusion \(_{t}\). Under some regular assumptions, there exists a corresponding reverse SDE with corresponding drift \(_{t}\), that allows us to take samples from \(_{T}\) (typically \((0,)\)) and denoise them to generate samples from \(_{0}\),

\[_{t}=(f_{t}(_{t})-_{t}^{2}_{_{t} } p_{t}(_{t}))\,t+_{t} }_{t},_{T}_{T},\] (3)

where the time flows backwards, and \(_{t}=f_{t}(_{t})-_{t}^{2}_{_{t}} p_{t}(_{t})\). The goal of conditional sampling is to condition the reverse SDE on a particular observation, i.e., to produce samples that satisfy constraints. For example, we might want to use (3) to generate samples where we already know some dimensions of the sample (e.g. knowing some pixels of the image a-priori in image inpainting). Doob's \(h\)-transform [55; 14] provides a formal mechanism for conditioning an SDE to hit an event at a given time. We will show that existing methods for conditional generative modelling arise as approximate instances of this proposed framework. Formally, we have:

**Proposition 2.1**.: _(Doob's \(h\)-transform ) Consider the reverse SDE in Eqn. (3). The conditioned process \(_{t}|_{0} B\) is a solution of_

\[_{t}=(_{t}(_{t})-_{t}^{2}_{t}}_{0|t}(_{0} B|_{t})})\, t+_{t}}_{t},_{T} _{T},\] (4)

_with a backward drift \(_{t}(_{t})=f_{t}(_{t})-_{t}^{2}_{_{t}} p _{t}(_{t})\), such that \((_{s}|_{t})=_{s|t,0}(_{s}|_{t},_{0} B)\) and \((_{0} B)=1\)._

Note, that we will refer to the conditional process with \(_{t}\) and to the unconditional process with \(_{t}\). Doob's \(h\)-transform shows that by conditioning a diffusion process to hit a particular event \(_{0} B\) at a boundary time, the resulting conditional process is itself an SDE with an _additional drift term_ (shown in the blue box above). Furthermore, the resulting SDE will hit the specified event within a finite time \(T\). The function \(h(t,_{t})_{0|t}(_{0} B_{t})\) is referred to as the \(h\)_-transform_[55; 14]. See also Appendix C.3 for a discussion about the connection to reconstruction guidance methods.

Rather than conditioning an SDE on a deterministic event, one is often interested in a posterior arising from noisy observations (e.g. noisy inverse problems)

\[=((_{0})),\ _{0} p_{},\] (5)

where \(\) is a forward operator, "noisy" describes a noise process and unlike the classical \(h\)-transform, we are not enforcing a deterministic condition such as \((_{0})=\). We typically assume we can evaluate and sample from the likelihood \(p(|=_{0})\). Our goal is to sample from the posterior \(p(_{0}|=)=p(|_{0})p_{}(_{0})/ p()\). Sampling from the posterior \(p(_{0}|=)\) can be achieved by a generalisation of the \(h\)-transform that build on results in , given as follows:

**Proposition 2.2**.: _(Generalised \(h\)-transform) Given the following backwards SDE with marginals \(p_{t}\)_

\[_{t}=_{t}(_{t})\,t+_{t}\  }_{t},_{T}_{T},\] (6)

_then it follows that the backward SDE_

\[_{T}  Q_{T}^{f_{t}}[p(_{0}|)]=_{T|0}( |_{0})p(_{0}|)_{0}\] \[_{t} =(_{t}(_{t})-_{t}^{2}\,_{_{t}}  p_{y|t}(=|_{t})\,)\,t+_{t}\ }_{t},\] (7)_satisfies \((_{0})=p(_{0}|=)\) with \(p_{y|t}(=|)\) and \( p(=|_{0})_{0|t}(_{0}|) _{0}\). We recover guidance based diffusions via \(_{t}(_{t})=f_{t}(_{t})-_{t}^{2}_{_{t}} p _{t}(_{t})\)._

Here \(Q_{T}^{f_{t}}[(_{0})]=_{T|0}(|_{0})( _{0})_{0}\) is the transition operator of the forward process. Note, that the initial distribution \(Q_{T}^{f_{t}}[p(_{0}|)]\) of the controlled SDE differs from the unconditional SDE. However, in Proposition G.2 we show that for the VP-SDE the difference between them gets exponentially small for increasing \(T\). To summarise, the above result gives a generalisation of the \(h\)-transform that allows sampling from posteriors; notice that it recovers the traditional \(h\)-transform in the no-noise setting. Whilst this more general formulation of the \(h\)-transform has been explored in unconditional generative modelling , this is the first work to cast conditional generative modelling in this light. We refer to the term in blue as the _generalised \(h\)-transform_ henceforth.

Proposition 2.2 provides theoretical backing to methodologies such as DPS  or IIGDM , in which the reverse SDE (7) is used to solve noisy inverse problems. For a careful derivation of Proposition 2.2 see Appendix D. While prior works have explored using Bayes' rule to decompose the conditional score, we provide rigorous arguments for intermediate steps, and carefully formalise the connection between conditional generative modelling and the \(h\)-transform, providing a concise result. This framework is flexible enough to also encompass prior work on conditional score matching, see e.g., [5; 27], and the discussion Appendix H.

## 3 Learning the generalised \(h\)-transform

Prior works either learn the posterior score from scratch, see e.g. [5; 27], or use approximations to the generalised \(h\)-transform, see e.g. [12; 32]. Instead, we propose a method to learn the generalised \(h\)-transform. We refer to this process as fine-tuning, as the pre-trained unconditional network remains unchanged and only the approximation to the generalised \(h\)-transform is learned. Our main result is given in the following theorem, where we give several representations of the generalised \(h\)-transform.

**Theorem 3.1**.: _(Representations of conditional SDE sampling) For a given \(((_{0}))\), let \(\) be the path measure of the conditional SDE_

\[_{t}=(f_{t}(_{t})-_{t}^{2}(_{_{t}} p_{t}(_{t})+h_{t}(_{t})))t+ _{t}\;}_{t},\] (8)

_where \(_{T} Q_{T}^{f_{t}}[p(_{0}|)]\). The generalised \(h\)-transforms admits the following representations:_

1. _The path measure induced by the_ \(h\)_-transformed SDE satisfies_ \(^{*}=^{p(_{0}| )}{_{0}}}\)_, where_ \(\) _is the path measure of the unconditioned SDE and_ \(_{0}\) _is it's time_ \(0\) _marginal._
2. _The_ \(h\)_-transform admits a denoising score matching representation_ \[h_{t}^{*}=*{arg\,min}_{_{t}}_{}^{}(h_{t})\] \[_{}^{}(h_{t})*{ }_{_{0} p(_{0}|)\\ t(0,T),_{t} p_{t|0}(_{t}|_{0})}[ \|(h_{t}(_{t})+_{_{t}} p_{t}(_{t}))-_{ _{t}}_{t|0}(_{t}|_{0})\|^{2}]\]
3. _The_ \(h\)_-transform admits the following_ **stochastic control** _formulation_ \[h_{t}^{*}=*{arg\,min}_{_{t}}\{_{}^{}(h_{t})_{}[_{0}^{T}_{t}^{2}||h_{t}(_{t})||^{2} t]-_{_{0}_{0}}[ p(| _{0})]\},\] _where_ \(\) _is the path measure for the conditional SDE being controlled._
4. _The path measure induced by the_ \(h\)_-transformed SDE solves the a Schrodinger bridge problem with boundary conditions_ \(_{0}=Q_{T}^{f_{t}}[p(_{0}|)](0,I)\)_,_ \(_{T}=p(_{0}|)\) _and with the unconditional process_ \(\) _as its reference._

Here, 4) and 1) follow directly from [7; 73]. For the proof 2) see Appendix D.2 and for 3) see Appendix G. Under appropriate conditions on the likelihood, the space of admissible controlscan be taken to be the set of \(C_{1}\)-vector fields with linear growth in space; see . In the following sections, we will discuss the representations in 2) and 3) in more detail.

### DEFT: Fine-tuning by score matching

The score matching objective in Theorem 3.12) offers a simulation-free loss function to estimate the generalised \(h\)-transform. While the theorem's formulation focuses on learning the \(h\)-transform for a specific measurement \(\), this loss function can naturally be extended and amortized over the full range of measurements, i.e.,

\[_{h}_{}[_{}^{ }(h)],\] (9)

to obtain \(h_{t}^{*}(,)=_{} p_{t}(|)\). Further, for settings where the operator may vary, we can additionally amortise over the forward operator \( p\) and learn \(h_{t}^{*}(,,)=_{} p_{t}(|, )\). We exploit this to amortise over inpainting masks, see Section 4.1, and motif scaffolding, see Section 4.3. For the DDPM  discretisation of the SDE and a pre-trained epsilon matching model \(_{t}^{^{*}}\), the fine-tuning objective (9) reduces to

\[_{}_{(_{0},),,t}[\|(h_{t}^{ }(_{t},)+_{t}^{^{*}}(_{t}))-\| ^{2}],\] (10)

with \(_{t}=_{t}}_{0}+_{t}}\), \((_{0},) p(_{0},),(0,)\), where \(h_{t}^{}\) represents the neural network used to approximate the generalised \(h\)-transform. Note that the loss function (10) only requires evaluation of the pre-trained model, without needing to backpropagate through the weights \(^{*}\), which is often quite expensive and sometimes impossible in closed APIs. Training under the DDPM discretisation can be performed according to Algorithm 5. Sampling with DEFT is further explained in Algorithm 6, and pictorially represented in Figure 1. As an additional insight into the behaviour of the \(h\)-transform that makes it more flexible and capable of modelling non-linear tasks than standard reconstruction guidance methods, we show that the \(h\)-transform can be interpreted as a correction term for the Tweedie estimate . We can express the conditional Tweedie's estimate as

\[[_{0}|_{t},] }_{0}(_{t},)\] (11) \[=_{t}-_{t}}(h_{t}^{^{*} }(_{t},)+_{t}^{^{*}}(_{t}))}{_{t}}}=}_{0}(_{t})-_{t}}}{ _{t}}}h_{t}^{^{*}}(_{t},),\]

where \(}_{0}(_{t})\) is the unconditional Tweedie estimate. Equation (11) highlights that the \(h\)-transform can also be interpreted as a correction factor to the unconditional denoised estimate, similar to [52; 80].

### Connections to variational inference and stochastic control

A limitation to the fine-tuning objective with DEFT is that it requires a small dataset of paired datapoints and measurements. In this section, we propose an alternative approach by expressing the solution to the conditional sampling problem as a stochastic optimal control objective, which is highlighted in Theorem 3.13). This allows us to learn the \(h\)-transform by optimising a variational inference-type problem. Importantly, this stochastic control objective only requires the availability of a single noisy observation \(\) instead of a paired fine-tuning dataset. Further, the stochastic control objective can even be used in other conditional sampling tasks, for example in reward tilted distributions, i.e. where the goal is to sample from \(() e^{r()}p_{}()\). Here \(e^{r()}\) serves the same purpose as the likelihood, but there is no explicit measurement \(\).

However, the stochastic control objective is not directly applicable for high-dimensional training, as the complete chain \(\{_{t}\}_{t}\) must be kept in memory and backpropagated through or adjoint methods have to be used . In Appendix G.3, we discuss several alternatives and present experiments for scaling up the above objective, e.g., methods like VarGrad  and Trajectory Balance . VarGrad allows to detach the trajectory from the gradient computation, drastically reducing the memory footprint. We discuss concurrent work in G.1 and G.2. Further, we show initial experiments for conditional sampling in G.4. The stochastic control objective serves as a conceptual bridge between sampling from unnormalised densities using diffusion models [74; 75; 81] and conditional score-based generative modelling.

### Likelihood-informed inductive bias

If the likelihood is differentiable, we can impose an inductive bias on the \(h\)-transform approximation. Specifically, the generalized \(h\)-transform can be expressed as an expectation, and we can apply the DPS approximation  as follows

\[_{_{t}} p_{y|t}(|_{t})=_{_{t} }_{_{0} p(_{0}|_{t})}[p(|_{0})] _{_{t}} p(|[}_{0} |_{t}])\] \[_{_{t}} p(|}_{0}(_{t })),\]

where we use Tweedie's estimate based on the pre-trained unconditional diffusion model in the last step. The DPS approximation has been validated in many different conditional sampling tasks, so it would make for a good initialisation of the learned \(h\)-transform. However, the DPS approximation requires the Jacobian of the unconditional model, which is expensive to compute and known to be poorly conditioned. Further, in applications where we only have access to the forward pass of the unconditional model, the Jacobian is infeasible to compute. Similar to , we found that omitting this term still leads to an expressive architecture, while greatly reducing the computational cost. Thus, we propose the following network architecture

\[h_{t}^{}(_{t},)=_{1}^{}(_{t}, }_{0}(_{t}),_{}_{0}} p(| }_{0}(_{t})),t)+_{2}^{}(t)_{}_{0}} p( |}_{0}(_{t})),\] (12)

to parametrise the \(h\)-transform, where the last layer of \(_{1}^{}\) is initialised with \(\) and \(_{2}^{}\) is initialised to output \(1\). This initialisation provides a computationally efficient approximation to the \(h\)-transform, which still guides the sampling.

This type of network architecture has been proposed within the sampling community to apply diffusion models to normalising constant estimation [49; 74; 81]. The theoretical connection to stochastic control in Section 3.2, motivates us further to adapt the architectures from the sampling field to the conditional generative modelling setting. We ablate the different components of our proposed architecture in Appendix F.1 and find that the additional components greatly improve performance empirically.

## 4 Experiments

We evaluate the DEFT framework from Section 3.1 on both linear and non-linear natural and medical image reconstruction tasks, as well as the motif scaffolding problem in protein design. Further, in Appendix H.2 we provide a comparison of the conditional training framework with DEFT on the Flowers image dataset. We provide our code https://github.com/alexdenker/DEFT.

### Image reconstruction

We test a wide variety of both linear and non-linear image reconstruction tasks on the \(256 256\)px ImageNet dataset . We make use of a pre-trained unconditional diffusion model with \( 500\)M parameters 2. We perform all our evaluations on a \(1k\) subset of the validation set3. For all inverse problems under consideration, the \(h\)-transform was trained on a separate \(1\)k subset of the validation set. For linear inverse problems, we compare against IIGDM , DDRM , DPS  and RED-diff . Additionally, we evaluate I\({}^{2}\)SB . The performance of I\({}^{2}\)SB can be seen as an upper-bound to DEFT, as it is a conditional diffusion trained on the complete ImageNet dataset. For non-linear tasks, we only compare against DPS and RED-diff as both IIGDM and DDRM are not directly applicable to non-linear forward operators. For DEFT we make use of the DDIM sampling scheme with \(100\) time steps . For the comparison methods we used the same hyperparameters as in  without further tuning, including the number of sampling steps (1000 for DPS and RED-Diff, 20 for DDRM and 100 for IIGDM).

We compute PSNR and SSIM, which are commonly used distortion measures, along with perceptual metrics such as Learned Perceptual Image Patch Similarity (LPIPS) , Kernel Inception Distance (KID) , and top-1 classifier accuracy of a pre-trained ResNet50 model . There is a well-known tradeoff between optimising distortion metrics versus perceptual quality, and depending on the task, one may wish for better performance along one axis at the cost of the other. For natural image tasksinvolving in-painting and super-resolution, it is common to prefer "natural"-looking images, which score better on perceptual similarity, whereas for tasks involving (medical) image reconstruction it is standard to prefer a lower distortion metric . Further, we calculate the total time (including training for DEFT) for evaluation \(1\)k validation images in the "Time (hrs)" row. Furthermore, we report the effective time taken to sample a single image in the "Time per sample (s)" row. This time is calculated by fitting the largest batch size of validation images that fit on a single A100 GPU and dividing the time taken for the batch by the batch size.

InpaintingFirst, we evaluate DEFT on the linear inverse problem of image inpainting. We make use of the inpainting masks for the 1k subset used by \({}^{2}\), which includes masks that obscure \(20\%-30\%\) of the image. Results are shown in Table 1, including the computational time for sampling all \(1000\) validation images. For DEFT, this computational time additionally includes the \(3.9\) hrs of training time of the \(h\)-transform additionally with the \(1.2\) hrs of evaluation. Even with the added training time, we reduce the overall computational time for DEFT, compared to DPS and RED-diff. A visual comparison is provided in Figure 2. Further, in Figure 8 in the Appendix, we show the diversity of samples using different initial seeds. Even though IIGDM and DDRM are faster methods, they perform significantly worse, and are only applicable for linear inverse problems. Inpainting is a task that prefers "natural"-looking image samples, and DEFT outperforms all other methods on perceptual metrics such as LPIPS and KID, being a close second on top-1 accuracy.

Super-resolutionFor another linear inverse problem, we evaluate \(4\)x noiseless super-resolution. Here, the forward operator is given by a bicubic downsampling. The results are presented in Table 1. While DEFT has a lower PSNR compared to the baseline methods, we see significant improvement on perceptual quality metrics (KID, LPIPS, and top-1 accuracy). We show visual results in Figure 9.

High dynamic rangeFor the first non-linear tasks, we make use of the high dynamic range (HDR) task described in . Here, the forward operator is given by \(()=(2;-1,1)\), where \(\) denotes the RGB image scaled to the range \([-1,1]\). The results are presented in Table 2. We observe

    & &  &  \\  & DPS & IIGDM & DDRM & RED-diff & DEFT & \(\) & DPS & IGDM & DDRM & RED-diff & DEFT & \(\) \\  PSNR (\(\)) & 21.27 & 20.30 & 20.72 & **23.29** & 22.18 & 23.26 & 24.83 & 25.25 & 25.32 & **25.95** & 24.92 & **23.95** \\ SSIM (\(\)) & 0.67 & 0.82 & 0.83 & **0.87** & 0.85 & 0.86 & 0.71 & 0.73 & 0.72 & **0.75** & 0.71 & 0.64 \\ KID (\(\)) & 15.28 & 4.50 & 2.50 & 0.86 & **0.29** & 0.238 & 10.01 & 10.9 & 14.0 & 10.0 & **1.78** & 0.004 \\ LPIPS (\(\)) & 0.26 & 0.12 & 0.14 & 0.10 & **0.09** & 0.068 & 0.16 & 0.15 & 0.23 & 0.25 & **0.12** & 0.11 \\ top-1 (\(\)) & 58.2 & 67.8 & 68.6 & **72.0** & 71.7 & 74.5 & 71.5 & 71.02 & 63.9 & 66.7 & **71.9** & 71.6 \\  Time (hrs) (\(\)) & 30.72 & 2.83 & **0.33** & 7.86 & 5.2 & **N/A** & 30.72 & 2.83 & **0.33** & 7.86 & 5.2 & **N/A** \\ Time per sample (s) (\(\)) & 100.6 & 10.2 & 1.22 & 28.3 & 4.36 & **N/A** & 100.6 & 10.2 & 1.22 & 28.3 & 4.36 & **N/A** \\   

Table 1: Results on inpainting and 4x super-resolution. Best values are shown in **bold**, second best values are underlined. We report both the total time to sample \(1\)k images, and the time per sample in seconds. The time to sample includes the training time for DEFT. These tasks aim to generate “natural”-looking images and therefore perceptual similarity metrics (KID, LPIPS and top-1) are more relevant. I\({}^{2}\)SB (grey column) can be considered an upper bound on performance.

Figure 2: Results for inpainting. We show the ground truth with the inpainting mask superimposed.

that DPS struggles with this specific non-linear tasks, while DEFT achieves good results. We show a visual comparison in the Appendix, see Figure 10.

Phase retrievalThe goal in phase retrieval is to recover the image from intensity measurements only, i.e., the forward operator is given by \(()=||\), with \(\) as the Fourier transform. We study the same 2x oversampling setting as in . Phase retrieval is a challenging non-linear inverse problem, as the forward operator is invariant to translations, global phase shifts and complex conjugation. In Figure 7 in the appendix, we show samples for different initial seeds and observe a wide variety of image quality. We also observe this behaviour for the baseline methods. However, DEFT is able to achieve better performance compared to RED-diff and DPS, see also Table 2. However, there is room for further improvement to achieve good reconstructions on a consistent basis.

Non-linear deblurringThe non-linear deblurring task was originally proposed by . Here, the forward operator is defined by a trained neural network , resulting in a highly non-linear blur. Quantitative results are presented in Table 2. This non-linear reconstruction task was also evaluated for RED-diff in . However, we found that the forward operator of the original implementation4 leads to a nearly trivial reconstruction task. In Appendix F.2, we show results with the code from , while Table 2 shows the results with our implementation of the forward operator. Further, in Figure 3 we provide a visual comparison, where DEFT is able to recover the ground truth quite faithfully.

Ablation: Size of fine-tuning datasetAs DEFT requires a dataset for fine-tuning, we ablate the number of training samples. We trained DEFT on a subset of 10, 100 and 200 ImageNet images for Inpainting. We see improvements of all metrics, when training on a larger dataset. The results are presented in Table 3. For the KID, we outperform RED-diff (KID: 0.86) even when trained on only 200 images. However, even with 10 images, we perform quite competitively, showcasing that our method is very sample-efficient when it comes to learning a conditional transform.

    &  &  &  \\  & DPS & RED-diff & DEFT & DPS & RED-diff & DEFT & DPS & RED-diff & DEFT \\  PSNR (\(\)) & \(7.94\) & \(25.23\) & \(\) & \(9.99\) & \(10.53\) & \(\) & \(17.57\) & \(21.21\) & \(\) \\ SSIM (\(\)) & \(0.21\) & \(0.79\) & \(\) & \(0.12\) & \(0.17\) & \(\) & \(0.39\) & \(0.53\) & \(\) \\ KID (\(\)) & \(272.5\) & \(1.2\) & \(\) & \(93.2\) & \(114.0\) & \(\) & \(12.89\) & \(66.8\) & \(\) \\ LPIPS (\(\)) & \(0.72\) & \(0.1\) & \(\) & \(0.66\) & \(\) & \(\) & \(0.42\) & \(0.42\) & \(\) \\ top-1 (\(\)) & \(4.0\) & \(68.5\) & \(\) & \(1.5\) & \(7.2\) & \(\) & \(30.2\) & \(23.5\) & \(\) \\  Time (hrs) (\(\)) & \(30.7\) & \(7.9\) & \(\) & \(30.7\) & \(7.9\) & \(\) & \(30.9\) & \(8.1\) & \(\) \\ Time per sample (s) (\(\)) & \(100.4\) & \(28.3\) & \(\) & \(100.6\) & \(28.4\) & \(\) & \(101.2\) & \(30.4\) & \(\) \\   

Table 2: Results on different non-linear image reconstruction tasks. Best values are shown in **bold**, second best values are underlined.

Figure 3: Results for non-linear deblurring. We show both the ground truth, the measurements and samples for DPS, RED-diff and DEFT. DEFT is able to reconstruct high-quality images.

### Computed tomography

We are evaluating DEFT both on the 2016 American Association of Physicists in Medicine (AAPM) grand challenge dataset , and the LoDoPab-CT dataset , for details see Appendix E.1. For the unconditional models we make use of the attention U-Net architecture . For the model trained on AAPM, we use exactly the same architecture (\( 374\) params.) as in , while for LoDoPab-CT we use a smaller model (\( 133\)M params.). For the forward operator, we use a parallel-beam radon transform with \(60\) angles and add Gaussian noise with \(_{y}=1.0\), which corresponds to approx. \(3.5\%\) relative noise. We compare against DPS  and RED-diff , where the parameters were obtained using a grid search on a subset of the validation set to maximise the PSNR. In Table 4 we present PSNR and SSIM, in addition to the sampling time, and provide a visual comparison Figure 4. For both datasets, we choose the same DEFT architecture with about \(23\)M parameters.In the Appendix F, we perform an ablation regarding the parametrisation of DEFT, see Table 6. In particular, these results show the necessity of providing the unconditional Tweedie estimate \(}_{0}\) as input to the \(h\)-transform in (12). We observe almost a \(8\)dB difference in PSNR for models without the Tweedie estimate and the log-likelihood term.

### Conditional protein design: motif scaffolding

We evaluate DEFT on the contiguous motifs of the RFDiffusion benchmark . In this motif scaffolding task, we sample protein \(C_{}\) atom coordinates \(^{d}\) such that the generated backbone contains a targeted motif, i.e. a subset of \(C_{}\) coordinates \(^{n}\), similar to an image outpainting task. The forward operator is therefore given by \(=()=\), where \(\{0,1\}^{n d}\) denotes a masking matrix which only selects the \(n\) observed \(C_{}\) coordinates.

We leverage the pretrained Genie diffusion model which is an unconditional model for protein backbone generation . To apply DEFT to it, we use a downsized version of the unconditional base model as our \(h\)-transform model which only uses 200k instead of the original 4.1M parameters. To adopt this model to the DEFT algorithm, we modify the SE(3)-invariant encoder by adding additional conditional pair feature networks for the motif coordinates as well as the unconditional Tweedie estimate \(}_{0}\), similar to the setting in the previous experiments. As per Section 3.3, we add a time-dependent likelihood approximation term to the \(h\)-transform network. We train the \(h\)-transform

    &  &  \\  & DPS & RED-diff & DEFT & DPS & RED-diff & DEFT \\  PSNR & \(33.11\) & \(\) & \(34.73\) & \(34.16\) & \(34.95\) & \(\) \\ SSM & \(0.855\) & \(0.865\) & \(\) & \(0.846\) & \(0.849\) & \(\) \\ Time (s) & \(208.9\) & \(83.4\) & \(\) & \(156.8\) & \(70.1\) & \(\) \\   

Table 4: Results for CT on AAPM and LoDoPab-CT and sampling time per image on a single GeForce RTX 3090. Best values are shown in **bold**, second best values are underlined. For DEFT we use \(100\) DDIM steps, while RED-diff and DPS use \(1000\) time steps.

Figure 4: Reconstructions for computed tomography on LoDoPab-CT

    \\ Number of images & 10 & 100 & 200 & 1000 \\  PSNR \(()\) & \(20.87\) & \(20.99\) & \(22.11\) & \(22.18\) \\ SSIM \(()\) & \(0.83\) & \(0.84\) & \(0.847\) & \(0.85\) \\ KID \(()\) & \(1.85\) & \(0.978\) & \(0.401\) & \(0.29\) \\ LPIPS \(()\) & \(0.123\) & \(0.112\) & \(0.096\) & \(0.09\) \\ top-1 \(()\) & \(68.8\) & \(69.6\) & \(70.6\) & \(71.7\) \\   

Table 3: Varying the size of the fine-tuning dataset for DEFT for Inpainting on ImageNet.

network on the same SCOPe dataset as in . More details on the training details can be found in App. E.2. We compare DEFT against DPS  and a previously published version of Genie that was trained in an amortised fashion . The guidance parameter of DPS was tuned over 5 different experiment runs. The amortised model serves here as an upper limit of how well DEFT can perform with Genie as a base model.

The overall in-silico success, defined by scRNA\(<2\)A and motifRMSD\(<1\)A, is provided in Figure 5. In the Appendix, we provide a detailed breakdown of these results, see Figure 13. Further, in Figure 13 and Figure 15 we provide a comparison of the task 1YCR for the different methods. We observe that DEFT outperforms DPS, solving 10 out of the 12 tasks compared to only 5 tasks for DPS. While it has lower success rates than the amortised model, it still solves all but two tasks in that benchmark with only 9% of the parameter count and significantly shorter training time compared to the amortised model (\(800\) epochs for DEFT vs \(2100\) epochs for amortised). The low performance of DPS indicates that the base Genie model is limiting the performance here and may partly explain the performance difference between DEFT and amortised training. Exploring DEFT with a more capable base model is therefore another promising avenue for research. Excitingly, the lower training time and data requirements of DEFT enable fine-tuning a model on specific protein families for particular applications, a task that is left for future work.

## 5 Conclusion

We presented a unified mathematical framework, based on Doob's \(h\)-transform, to better understand and classify different conditional diffusion methods. Under this framework, we proposed DEFT, a novel parameter-efficient conditional fine-tuning method that does not require backpropagation through large pre-trained score networks, resulting in efficient sampling. We evaluated DEFT on several image reconstruction tasks and showed that it reliably outperformed standard methods, both in time, reconstruction quality and perceptual similarity metrics. While DEFT requires additional training on a small dataset of paired measurements, we find that it is still faster than many existing baselines due to being able to use fewer sampling steps during evaluation, and not needing to backpropagate during evaluation.

Limitations and future workThe DEFT framework uses a (small) fine-tuning dataset, in contrast to zero-shot conditional sampling approaches, e.g., DPS  or IIGDM . Fine-tuning on small datasets may have the risk of overfitting to biases inherent in the data. In contrast to zero-shot conditional sampling, DEFT assumes no knowledge of the forward operator. However, the forward operator can be incorporated as an inductive bias within the network architecture to improve performance. We also proposed a zero-shot approach through the optimal control loss in Section 3.2, which only needs a single observation \(\) to learn the \(h\)-transform. Though we show promising results scaling this approach to the MNIST dataset in Appendix H, the computational burden of simulating the full SDE at each iteration is still high, which might make this optimal control loss infeasible for high-dimensional data. However, there is promising recent work on partial trajectory optimisation , which may reduce the computational burden of the stochastic control objective, making it competitive with existing methods.

Figure 5: Comparison of DPS, DEFT and amortised training for motif scaffolding for 12 contiguous targets. 4% and 9% are the relative sizes of the h-transform compared to the unconditional model.