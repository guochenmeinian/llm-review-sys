# Relating Representational Geometry to

Cortical Geometry in the Visual Cortex

Francisco Acosta

Department of Physics

UC Santa Barbara

facosta@ucsb.edu

&Colin Conwell

Department of Cognitive Science

Johns Hopkins University

&Sophia Sanborn

Electrical & Computer Engineering

UC Santa Barbara

&David Klindt

SLAC

Stanford University

&Nina Miolane

Electrical & Computer Engineering

UC Santa Barbara

###### Abstract

A fundamental principle of neural representation is to _minimize wiring length_ by spatially organizing neurons according to the frequency of their communication (Sterling and Laughlin, 2015). A consequence is that nearby regions of the brain tend to represent similar content. This has been explored in the context of the visual cortex in recent works (Doshi and Konkle, 2023; Tong et al., 2023). Here, we use the notion of _cortical distance_ as a baseline to ground, evaluate, and interpret measures of _representational distance_. We compare several popular methods--both second-order methods (Representational Similarity Analysis, Centered Kernel Alignment) and first-order methods (Shape Metrics)--and calculate how well the representational distance reflects 2D anatomical distance along the visual cortex (the _anatomical stress score_). We evaluate these metrics on a large-scale fMRI dataset of human ventral visual cortex (Allen et al., 2022), and observe that the 3 types of Shape Metrics produce representational-anatomical stress scores with the smallest variance across subjects, (Z score = -1.5), which suggests that first-order representational scores quantify the relationship between representational and cortical geometry in a way that is more invariant across different subjects. Our work establishes a criterion with which to compare methods for quantifying representational similarity with implications for studying the anatomical organization of high-level ventral visual cortex.

## 1 Introduction

A neural representation comprises the collective activity of a population of neural units, such as the firing frequencies of individual neurons, haemodynamic responses of fMRI voxels, or the activations of nodes in an artificial neural network (ANN); a representation can therefore be viewed as a set of vectors in a high-dimensional neural state space. There is much interest in investigating representations through the lens of geometry. _Representational geometry_(Chung and Abbott, 2021) offers a framework to quantify the operational dissimilarities between different neural systems performing related tasks. The central idea is to compare across brain networks or computational models of brain function like ANNs by comparing the geometry of their neural representations. Indeep learning there is much interest in understanding what makes a good representation in ANNs (Higgins et al., 2022, 2018). In the biological domain, information is encoded in a population of neurons as patterns of electrical activity. The ability to compare different representations in the brain may yield insights into phenomena like _representational drift_(Schoonver et al., 2021; Driscoll et al., 2022) and allow researchers to quantify how representations form and change during learning (Guo et al., 2020). It is also widely hypothesized that ANNs and biological neural networks form similar representations from data in order to solve similar problems (Schrimpf et al., 2018; Conwell et al., ), or that making them more similar could help in building more robust artificial systems (McClure and Kriegeskorte, 2016; Li et al., 2019). Moreover, comparing representations and finding the common core has also been linked to disentanglement Duan et al. (2019). This motivates the development of methods to compare between representations in AI models and in the brain.

A line of recent work lends credence to the idea that there is a direct correspondence between the geometry of a neural representation and the structure of the task variables it encodes (Chaudhuri et al., 2019; Gardner et al., 2022; Nieh et al., 2021)--what has been called a first-order isomorphism between task variables and their representations. Alternatively, we may seek to find a "second-order isomorphism" between the task variables and their representations, i.e. a correspondence between the relations among task variables and the relations among their representations Shepard and Chipman (1970). Kriegeskorte (2008) operationalize this idea by introducing Representational Similarity Analysis (RSA). Kornblith et al. (2019) introduced Centered Kernel Alignment (CKA), a related method that also exploits the second-order isomorphism idea to quantify dissimilarity between neural network representations. On the other hand, Williams et al. (2021) introduced Generalized Shape Metrics (GSM), which quantify the distance between representations based on their shape in neural state space, and can therefore be related to the first-order isomorphism approach.

In this paper, we evaluate these three methods for quantifying dissimilarities ("distance") between neural representations across several functionally-defined regions of interest (ROIs) in human visual cortex, in a large-scale human fMRI dataset Allen et al. (2022). Here, we use 2D anatomical _cortical distance_ as a ground-truth measure of representational distance, under the hypothesis that the cortex is spatially organized such that similar information is represented in nearby brain regions (Sterling and Laughlin, 2015; Doshi and Konkle, 2023). Our approach provides a method for grounding, evaluating, and interpreting different metrics of representational distance. Although anatomical distance provides only a very coarse measure of expected representational distance, we propose it can nonetheless provide insight into the differences between approaches.

## 2 Background: Approaches in Representational Geometry

Consider a population of \(n\) neural units in a neural network and a set of \(m\) stimuli: for example, a group of fMRI voxels in a region of the human visual cortex and a set of \(m\) natural images. The \(i^{}\) stimulus elicits a neural population response \(x_{i}^{n}\), which can be viewed as a point in the \(n\)-dimensional _neural state space_. The neural representation of a task in a network is the collection of responses elicited by all possible task-relevant stimuli across all neural units.

### Neural Representations

Neural Representation Matrix \(X\)In practice we are restricted to sampling a finite subset of possible stimuli and record from a limited number of neural units in a population. Without making any assumptions about an underlying manifold, we can simply consider the set of points in neural state space and organize the \(m\) neural response vectors \(x_{1},,x_{m}\) as rows of a neural representation matrix \(X^{m n}\). We call methods that directly use the neural representation matrix to measure representational similarity _first-order_ methods, because they compare representations \(a\) and \(b\) by directly comparing \(X^{(a)}\) and \(X^{(b)}\). These methods are therefore sensitive to more fine-grained details of the geometric structure of neural responses in the neural state space. Williams et al. (2021) is one such first-order method that compares representations based on their _shape_ as described in section 2.2.3.

The Gramian \(G\)There are other representational similarity methods like RSA and CKA (described in sections 2.2.1 and 2.2.2 respectively) that instead can be classified as _second-order_ methods. These methods compare representations \(a\) and \(b\) by comparing second-order matrices built from the representation matrices. One such object is the _Gramian_ normalized by number of neural units \(n\), hereinafter simply the Gramian \(G\), computed as:

\[G=XX^{T}.\]

Second-order methods compare representations \(a\) and \(b\) by comparing \(G^{(a)}\) and \(G^{(b)}\).

### Methods for Dissimilarity between Neural Representation

#### 2.2.1 Representational Similarity Analysis (RSA)

RSA is a broad framework to compare representations, and a large number of dissimilarity scores have been proposed Kriegeskorte (2008); Kriegeskorte and Kievit (2013); Diedrichsen and Kriegeskorte (2017); Diedrichsen et al. (2021); Schutt et al. (2023). All variants of RSA can be broken down into 2 steps: (1) Construction of Representational Dissimilarity Matrices (RDMs), and (2) Comparison of RDMs. Several types of RDMs can be derived directly from the Gramian \(G\). For example, we can compute a Pearson RDM whose \(ij\) entry is one minus the Pearson correlation \(\) between \(x_{i},x_{j}\) from \(G\):

\[^{}_{ij}=1-(x_{i},x_{j})=1-(x_{i},x_{j})}{(x_{i})(x_{j})}=1-}{G_{ jj}}}.\]

Once we have computed \(^{(a)}\) and \(^{(b)}\) for two networks \(a\) and \(b\), the remaining step is to quantify how different their RDMs are. Because RDMs are symmetric and their diagonals are zero (assuming the neural activity vectors are centered), they are often compared by computing the Pearson correlation or the Spearman rank correlation between their vectorized upper triangular entries. Thus, when one chooses to compare the Pearson RDMs for \(a\) and \(b\) using Pearson correlation, the dissimilarity score is computed as

\[d^{}_{ab}=1-((^{ ,(a)}),(^{(b),})),\]

where \(()\) returns the vectorized upper triangular of each matrix.

#### 2.2.2 Centered Kernel Alignment (CKA)

Kornblith et al. (2019) propose to use centered kernel alignment (CKA), another second-order method to measure dissimilarity between neural representations. It is based on the Hilbert-Schmidt Independence Criterion (HSIC) (Gretton et al., 2005). Consider representations \(X^{(a)}\) and \(X^{(b)}\). Let \(H=-^{T}\) be the \(m m\) centering matrix, \(k^{(a)}\) and \(k^{(b)}\) be kernels, and \(K^{(a)}_{ij}=k^{(a)}(x^{(a)}_{i},x^{(a)}_{j})\). HSIC is given by \((K^{(a)},K^{(b)})=}(K^{(a)}HK^{(b)}H)\). CKA is computed from HSIC as

\[d^{}_{ab}=(K^{(a)},K^{(b)})}{(K^{ (a)},K^{(a)})(K^{(b)},K^{(b)})}}.\]

#### 2.2.3 Generalized Shape Metrics (GSM)

Williams et al. (2021) introduce a family of metrics based on the _shape_ of representations in neural state space that can be used to compare representations while explicitly accounting for desired symmetries, such as permutation invariance across neurons. This framework defines a _metric space_ over neural representation matrices. Crucially, unlike RSA and CKA, the shape metrics are proper metrics and are therefore guaranteed to satisfy the triangle inequality, which ensures the performance of several geometric analyses like k-means clustering(Yianilos, 1970). Given a symmetry group \(\) and a "preprocessing function" \(\), the distance between networks \(a\) and \(b\) is given by

\[d^{}_{ab}=_{T}^{a}(X^{(a)})-^{b}(X^ {(b)})T_{F}.\]

One shortcoming with this approach is that it requires all networks being compared to have the same dimensionality. Williams et al. (2021) deal with this by performing PCA projections of all networks to a common dimension.

## 3 Methods & Results: Comparing Approaches to Representational Geometry

### Natural Scenes Dataset

The Natural Scenes Dataset  is a large-scale, high-resolution fMRI dataset (7T field strength, 1.6-s TR, \(1.8mm^{3}\) voxel size) that measures the brain responses of 8 subjects to a large sampling of stimuli from the Microsoft Common Objects in Context (COCO) dataset  across 40 scanning sessions. Subjects in the scanner were tasked only to judge whether or not they had seen the presented images before. In this analysis, we focus on the brain responses to a 1000-image subset of this dataset (the NSD 'Shared1000') that each of 4 subjects (subjects 01, 02, 05, 07) saw for all 3 of the experimental design's intended repetitions. The 3 image repetitions were averaged to yield single voxel-level response values for each stimuli.

### Comparing Representational Geometry to Anatomical Geometry

We implement 14 variants of RSA, where each variant is specified by the choice of one of Euclidean distance, Pearson correlation, Spearman correlation, Mahalanobis distance, and Concordance correlation to construct the RDM and the choice of one of Pearson, Spearman, and Concordance to compare the RDMs.We implement 2 variants of CKA (linear and kernel). For GSM, we implement 3 different metrics corresponding to 3 \(\) values (0,0.5,1). For every selected variant of RSA, CKA, and Shape Metrics we obtain a pairwise representational dissimilarity matrix among 11 ROIs: EBA, OPA, FFA-1, FFA-2, FBA-1, FBA-2, VWFA-1, VWFA-2, OFA, OWFA, and PPA. This matrix encapsulates the "geometry" of these ROIs based on their neural representations. We then seek to compare the result of each method to the anatomical geometry of these ROIs, encapsulated by a pairwise anatomical distance matrix. This approach is summarized in Fig. 1

#### 3.2.1 Anatomical Geometry of Human Visual Cortex

For each subject, we have the 3D coordinates associated with every voxel, which we project to the cortical surface using the Python package pycortex. In this setup, the cortical surface is modeled as a 2D mesh composed of _vertices_; all voxels are projected to corresponding vertices. Because the human cortex is highly folded and curved, with intricate patterns of gyri (ridges) and sulci (grooves), computing distances between different vertices on the cortex is non-trivial. We

Figure 1: **Methods Overview.****(1)** In one subject, we obtain the \(K\) neural representations corresponding to \(K\) ROIs in the visual cortex. Within a ROI, a stimulus image elicits a particular response in every fMRI voxel; the representation of \(m\) stimulus images can be seen as \(m\) points in a high dimensional vector space, where each voxel specifies a dimension. **(2)** We compute the representational dissimilarity between every pair of ROIs using the various metrics (RSA, CKA, GSM). This yields a pairwise distance matrix \(d_{ab}\) for each metric. **(3)** We compute the geodesic distance along the cortical surface between the centroids of each pair of ROIs, to obtain the anatomical pairwise distance matrix \(_{ab}\). **(4)** We calculate the representational-anatomical stress score for each representational metric, which quantifies how well the metric captures the cortical geometry of the visual cortex.

must compute distances _along_ the cortical surface, which can be modeled as 2-dimensional curved manifold in \(^{3}\), and therefore requires finding geodesics between vertices.

#### 3.2.2 Frechet mean of ROI vertices

To find the distances between ROIs we must first find the centroid of each ROI which, as a notion of the average of points on a curved manifold, is given by the Frechet mean of all the vertices in the ROI. Take the cortical surface to be a curved manifold \(\) embedded in \(^{3}\); the Frechet mean of a set of vertices \(p_{1},p_{2},...,p_{N}\) is the point \(\) such that

\[=*{arg\,min}_{p}_{i=1}^{N}d^{2}(p,p_{i})\] (1)

where \(d^{2}(p,p_{i})\) is the squared geodesic distance between \(p\) and \(p_{i}\). Once we have found the Frechet mean or centroid of every functional ROI, we compute the pairwise geodesic distance between all 11 ROI centroids, to obtain a \(11 11\) anatomical pairwise distance matrix.

#### 3.2.3 Stress score

We can now calculate a measure of "stress" between each representational geometry pairwise-dissimilarity matrix and the "ground-truth" anatomical geometry pairwise-distance matrix:

\[=(d_{ab}-_{ab})^{2}}{_{a<b}_{ab}^{2}}}.\]

We observe in Fig. 2 that the 3 types of Shape Metrics produce representational-anatomical stress scores with the smallest variance across subjects, (Z score = -1.5), which suggests that first-order representational scores quantify the relationship between representational and cortical geometry in a way that is more invariant across different subjects. Our preliminary results motivate more extensive analysis to understand the relationship between neural representations and the cortical organization of the visual stream, as well as the development of further benchmarks to evaluate the performance of different representational metrics. Understanding the unique advantages of different representational metrics will yield insights into the role of representational geometry in computations in the brain.

Figure 2: **Anatomical geometry stress scores for various representational dissimilarity metrics.** We implement 14 variants of RSA (defined by the choice of RDM construction and RDM comparison), 2 variants of CKA (linear and kernel), and 3 variants of GSM (3 different values for \(\), which parameterizes a transformation on the raw representations).