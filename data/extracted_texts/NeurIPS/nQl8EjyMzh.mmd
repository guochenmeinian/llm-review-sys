# On conditional diffusion models for PDE simulations

Aliaksandra Shysheya

University of Cambridge

as2975@cam.ac.uk

&Cristiana Diaconu

University of Cambridge

cdd43@cam.ac.uk

&Federico Bergamin

Technical University of Denmark

fedbe@dtu.dk

Paris Perdikaris

Microsoft Research AI4Science

paperdikaris@microsoft.com

&Jose Miguel Hernandez-Lobato

University of Cambridge

jmh233@cam.ac.uk

Richard E. Turner

University of Cambridge

Microsoft Research AI4Science

The Alan Turing Institute

ret23@cam.ac.uk

Equal contribution.

###### Abstract

Modelling partial differential equations (PDEs) is of crucial importance in science and engineering, and it includes tasks ranging from forecasting to inverse problems, such as data assimilation. However, most previous numerical and machine learning approaches that target forecasting cannot be applied out-of-the-box for data assimilation. Recently, diffusion models have emerged as a powerful tool for conditional generation, being able to flexibly incorporate observations without retraining. In this work, we perform a comparative study of score-based diffusion models for forecasting and assimilation of sparse observations. In particular, we focus on diffusion models that are either trained in a conditional manner, or conditioned after unconditional training. We address the shortcomings of existing models by proposing 1) an autoregressive sampling approach, that significantly improves performance in forecasting, 2) a new training strategy for conditional score-based models that achieves stable performance over a range of history lengths, and 3) a hybrid model which employs flexible pre-training conditioning on initial conditions and flexible post-training conditioning to handle data assimilation. We empirically show that these modifications are crucial for successfully tackling the combination of forecasting and data assimilation, a task commonly encountered in real-world scenarios.

## 1 Introduction

Partial differential equations (PDEs) are ubiquitous as they are a powerful mathematical framework for modelling physical phenomena, ranging from the motion of fluids to acoustics and thermodynamics. Applications are as varied as weather forecasting , train aerodynamics profiling , and concert hall design . PDEs can either be solved through numerical methods like finite element methods , or, alternatively, there has been a rising interest in leveraging deep learning to learn neural approximations of PDE solutions . These approaches have shown promise for generating accurate solutions in fields such as fluid dynamics and weather prediction .

Some of the most common tasks within PDE modelling are 1) _forecasting_, where the goal is to generate accurate and long rollouts based on some initial observations, and 2) _inverse problems_,which aim to reconstruct a certain aspect of the PDE (i.e. coefficient, initial condition, full trajectory, etc.) given some partial observations of the solution to the PDE. Data assimilation (DA) refers to a particular class of inverse problems , with a goal to predict or refine a trajectory given some partial and potentially noisy observations. While in general these tasks are addressed separately, there are cases in which a model that could jointly tackle both tasks would be beneficial. For example, in weather prediction, a common task is to forecast future states, as well as update them after more observations from weather stations and satellites are available . Currently, traditional numerical weather prediction systems tackle this in a two-stage process (a forecast model followed by a data assimilation system), both with a similarly high computational cost. A simpler option would be to have a model that is flexible enough to both produce accurate forecasts as well as condition on any incoming noisy observations.

In this work, we investigate how a probabilistic treatment of PDE dynamics [9; 81] can achieve this goal, with a focus on score-based diffusion models [64; 68; 26] as they have shown remarkable performance in other challenging applications, ranging from image and video [27; 58] to protein generation [72; 78; 79]. We perform a comparative study between the diffusion model approaches in Tab. 1, and evaluate their performance on forecasting and DA in PDE modelling. The unconditionally-trained model that is conditioned post-training through reconstruction guidance  is referred to as the _joint model_, while the _amortised model_ directly fits a conditional score during training.

The main contribution of this work is that we propose extensions to the joint and amortised models to make them successfully applicable to tasks that combine forecasting and DA:

**Joint model.** We propose an autoregressive (AR) sampling strategy to overcome the limitations of the sampling approach proposed in , which samples full PDE trajectories all-at-once (AAO). We provide theoretical justification for why AR outperforms AAO, and empirically show, through extensive experiments, that AR outperforms or performs on par with AAO on DA, and drastically improves upon AAO in forecasting, where the latter fails.

**Amortised model.** We introduce a novel training procedure for amortised models for PDEs, that, unlike previous work , allows their performance to remain stable over a variety of history lengths. Moreover, we propose a hybrid model that combines amortisation with reconstruction guidance that is especially well-suited to mixed tasks, that involve both a forecasting and DA component.

Finally, this work provides, to the best of our knowledge, the first quantitative comparison between joint and amortised models for PDE modelling, with all other factors such as training dataset and model architecture carefully controlled.

## 2 Background

Continuous-time diffusion models.In this section we recall the main concepts underlying continuous diffusion models, and refer to Song et al.  for a thorough presentation. We consider a forward noising process \((x(t))_{t 0}\) associated with the following stochastic differential equation (SDE)

\[x(t)=-x(t)t+w(t),\ x(0) p_{0},\] (1)

with \(w(t)\) an isotropic Wiener process, and \(p_{0}\) the data distribution. The process defined by (1) is the well-known Ornstein-Uhlenbeck process, which geometrically converges to the standard Gaussian distribution \((0,)\). Additionally, for any \(t 0\), the noising kernel of (1) admits the following form \(p_{t|0}(x(t)|x(0))=(x(t)|_{t}x(0),_{t}^{2})\), with \(_{t}=e^{-t/2}\) and \(_{t}^{2}=1-e^{-t}\). Importantly, under mild assumptions on \(p_{0}\), the time-reversal process \(((t))_{t 0}\) also satisfies an SDE [10; 24] which is

   Model & SCORE & rollout & conditioning \\  Joint AAO  & \(_{}(t,x_{1:L}(t))\) & AAO & Guidance \\ Joint AR (ours) & \(_{}(t,x_{1:L}(t))\) & AR & Guidance \\ Universal amortised (ours) & \(_{}(t,x_{1:L}(t),y)\) & AR & Architecture/Guidance \\   

Table 1: Score-based methods considered in this work. Each method can be classified in terms of the score network (joint or conditional), the rollout strategy at sampling time, and the conditioning mechanism at inference time.

given by

\[(t)=\{-(t)-  p_{t}((t))\}t+w(t),\] (2)

where \(p_{t}\) denotes the density of \(x(t)\). In practice, the score \( p_{t}\) is unavailable, and is approximated by a neural network \(_{}(t,) p_{t}\), referred to as the _score network_. The parameters \(\) are learnt by minimising the denoising score matching (DSM) loss [30; 68; 73]

\[()=[\|_{}(t,x(t))- p_{t}( x(t)|x(0))\|^{2}],\] (3)

where the expectation is taken over the joint distribution of \(t()\), \(x(0) p_{0}\) and \(x(t) p_{t|0}(|x(0))\) from the noising kernel. Sampling involves discretising and solving (2). Optionally, to avoid errors accumulating along the denoising discretisation, each denoising step (predictor) can be followed by a small number of Langevin Monte Carlo (corrector) steps .

Conditioning with diffusion models.The methodology introduced above allows for (approximately) sampling from \(x(0) p_{0}\). However, in many settings, one is actually interested in sampling from the conditional \(p(x(0)|y)\) given some observations \(y\) with likelihood \(p(y|(x))\) and \(:\) being _a measurement_ operator. The conditional is given by Bayes' rule \(p(x(0)|y)=p(y|x(0))p(x(0))/p(y)\), yet it is not available in closed form. An alternative is to simulate the _conditional_ denoising process [13; 15; 68]

\[(t)=\{-(t)-  p_{t}((t)|y)\}t+w(t).\] (4)

In the following, we describe the two main ways to sample from this process.

Amortising over observations.The simplest approach directly learns the conditional score \( p_{t}((t)|y)\)[26; 68]. This can be achieved by additionally feeding \(y\) to the score network \(_{}\), i.e. \(_{}(t,x(t),y)\), and optimising its parameters by minimising a loss akin to (3).

Reconstruction guidance.Alternatively, one can leverage Bayes' rule, which allows to express the conditional score w.r.t. \(x(t)\) as the sum of the following two gradients

\[ p(x(t)|y)=_{}+ _{},\] (5)

where \( p(x(t))\) can be approximated by a score network \(_{}(t,x(t)) p(x(t))\) trained on the prior data--with no information about the observation \(y\). The conditioning comes into play via the \( p(y|x(t))\) term which is referred to as _reconstruction guidance_[11; 13; 27; 48; 65; 80]. Assuming a Gaussian likelihood \(p(y|x(0))=(y|x(0),_{y}^{2})\) with linear measurement \((x)=x\), we have:

\[p(y|x(t)) = p(y|x(0))p(x(0)|x(t))\;x(0) (y|x(0),^{2})q(x(0)|x(t))\;x(0)\] \[=(y|(x(t)),(_{y}^{2}+r_{ t}^{2}))\] (6)

where \(p(x(0)|x(t))\) is not available in closed form and is approximated by a Gaussian \(q(x(0)|x(t))(x(0)|(x(t)),r_{t}^{2})\) with mean given by Tweedie's formula [18; 57]\((x(t))[x(0)|x(t)]=(x(t)+_{t}^{2} p _{t}(x(t)))/_{t}\) and variance \([x(0)|x(t)] r_{t}^{2}\), where \(r_{t}\) is the guidance schedule and is chosen as a monotonically increasing function [19; 53; 65; 60].

## 3 PDE surrogates for forecasting and data assimilation

In this section, we discuss the design space of diffusion models, outlined in Tab. 1, for tackling forecasting and DA in the context of PDE modelling.

Problem setting.We denote by \(:\) a differential operator taking functions \(u:_{+}\) as input. Along with some initial \(u(0,)=u_{0}\) and boundary \(u(,)=f\) conditions, these define a partial differential equation (PDE) \(_{}u=(u;)=(_{z}u, _{z}^{2}u,;)\) with coefficients \(\) and where \(_{}u\) is a shorthand for the partial derivative \( u/\), and \(_{z}u,_{z}^{2}u\) denote the partial derivatives \( u/ z,^{2}u/ z^{2}\), respectively. We assume access to some accurate numerical solutions from conventional solvers, which are discretised both in space and time. Let's denote such trajectories by \(x_{1:L}=(x_{1},,x_{L})^{D L} p_{0}\) with \(D\) and \(L\) being the size of the discretised space and time domains, respectively.

We are generally interested in the problem of generating realistic PDE trajectories given observations, i.e. sampling from conditionals \(p(x_{1:L}|y)\). Specifically, we consider tasks that involve conditioning on initial states, as well as on sparse space-time observations, reflective of some real-life scenarios such as weather prediction. Thus, we focus on two types of problems, and the combination thereof: (a) _forecasting_, which involves predicting future states \(x_{H:L}\) given a length-\(H\) past history \(x_{1:H-1}\), i.e. sampling from \(p(x_{H:L}|x_{1:H-1})\); (b) _data assimilation_ (DA), which is concerned with inferring the ground state of a dynamical system given some sparse observed states \(x_{o}\), i.e. sampling from \(p(x_{1:L}|x_{o})\). Then, the goal is to learn a flexible PDE surrogate, i.e. a machine learning model, that, unlike most numerical solvers , is able to solve the underlying PDE while accounting for various initial conditions and sparse observations.

### Learning the score

Learning a diffusion model over the full joint distribution \(p(x_{1:L}(t))\) can become prohibitively expensive for long trajectories, as it requires a score network taking the full sequence as input--\(_{}(t,x_{1:L}(t))\), with memory footprint scaling linearly with the length \(L\) of the sequence.

One approach to alleviate this, as suggested by Rozet and Louppe , is to assume a Markov structure of order \(k\) such that the joint over data trajectories can be factorised into a series of conditionals \(p(x_{1:L})=p(x_{1})p(x_{2}|x_{1}) p(x_{k+1}|x_{1:k})_{i=k+2}^{L}p(x _{i}|x_{i-k:i-1})\). Here we are omitting the time dependency \(x_{1:L}=x_{1:L}(0)\) for clarity's sake. The score w.r.t. \(x_{i}\) can be written as

\[_{x_{i}} p(x_{1:L}) =_{x_{i}} p(x_{i}|x_{i-k:i-1})+_{j=i+1}^{i+k}_ {x_{i}} p(x_{j}|x_{j-k:j-1})\] \[=_{x_{i}} p(x_{i},x_{i+1:i+k}|x_{i-k:i-1})=_{x_{i }} p(x_{i-k:i+k})\] (7)

with \(k+1 i L-k-1\), whilst formulas for \(i k\) and \(i L-k\) can be found in App. B.1. In the case of modelling the conditional \(p(x_{1:L}|y)\), we use the same Markov assumption, such that learning \(_{x_{i}} p(x_{1:L}|y)\) reduces to learning a local score \(_{x_{i}} p(x_{i-k:i+k}|y)\). The rest of Sec. 3.1 describes learning the local score of the joint distribution, but the same reasoning can easily be applied to fitting the local score of the conditional distribution.

When noising the sequence with the SDE (1), there is no guarantee that \(x_{1:L}(t)\) will still be \(k\)-order Markov. However, we still assume that \(x_{1:L}(t)\) is Markov but with a larger order \(k^{}>k\), as motivated in Rozet and Louppe [60, Sec 3.1]. To simplify notations we use \(k^{}=k\) in the rest of the paper. Consequently, instead of learning the entire joint score at once \(_{x_{1:L}(t)} p(x_{1:L}(t))\), we only need to learn the _local_ scores \(_{}(t,x_{i-k:i+k}(t))_{x_{i-k:i+k}(t)} p(x_{ i-k:i+k}(t))\) with a window size of \(2k+1\). The main benefit is that the network only takes as input sequences of size \(2k+1\) instead of \(L\), with \(k<<L\). The local score network \(_{}\) is trained by minimising the following DSM loss \(()\):

\[_{}(t,x_{i-k:i+k}(t))- p_{t|0}(x_ {i-k:i+k}(t)|x_{i-k:i+k})\|^{2}\]

where the expectation is taken over the joint \(i([k+1,L-k])\), \(t()\), \(x_{i-k:i+k} p_{0}\) and \(x_{i-k:i+k}(t) p_{t|0}(|x_{i-k:i+k})\) given by the noising process.

### Conditioning

Reconstruction guidance.We now describe how to tackle forecasting and DA by sampling from conditionals \(p(x_{1:L}|x_{o})\)--instead of the prior \(p(x_{1:L})\)--with the trained joint local score \(_{}(t,x_{i-k:i+k}(t))\) described in Sec. 3.1. For both tasks, the conditioning information \(y=x_{o}^{O}\) is a measurement of a subset of variables in the space-time domain, i.e. \(x_{o}=(x)=(x)+\) with \((x)^{N}\) the space-time vectorised trajectory, \((0,_{y}^{2})\) and a masking matrix \(=\{0,1\}^{O N}\) where rows indicate observed variables with \(1\). Plugging this in (6) and computing the score we get the following reconstruction guidance term

\[ p(x_{o}|x(t))^{2}+_{y}^{2}}(y- (x(t)))^{}(x(t))}{ x(t)}.\] (8)Summing up this guidance with the trained score over the prior as in (5), we get an approximation of the conditional score \( p(x_{1:L}(t)|x_{o})\) and can thus generate conditional trajectories by simulating the conditional denoising process.

Conditioning via architecture.Alternatively, instead of learning a score for the joint distribution and conditioning a posteriori, one can directly learn an approximation to the conditional score. Such a score network \(_{}(t,x_{i:t+P}(t)|x_{i-C:i})\) is trained to fit the conditional score given the states \(x_{i-C:i}\) by minimising a DSM loss akin to (3). Here, we denote the number of observed states by \(C\), while \(P\) stands for the length of the predictive horizon. Most of the existing works  propose models, which we refer to as _amortised_ models, where the number of conditioning frames \(C\) is fixed and set before training. Thus, a separate model for each combination of \(P\) and \(C\) needs to be trained. To overcome this issue, similarly to , we propose a _universal amortised_ model, which allows to use any \(P\) and \(C\), such that \(P+C=2k+1\), during sampling. In particular, during training, instead of determining \(C\) beforehand, we sample \(C(\{0,,2k\})\) for each batch and train the model to fit the conditional score \(_{}(t,x_{i-C:i+P}(t)|x_{i-C:i})\), thus amortising over \(C\) as well.

The conditioning on the previous states is achieved by feeding them to the score network as separate input channels. The conditioning dimension is fixed to the chosen window size of \(2k+1\). To indicate whether a particular channel is present we add binary masks of size \(2k+1\). Even though we condition on \(x_{i-C:i}\), the score for the whole window size \(x_{i-C:i+P}(t)\) is predicted. In our experiments, we found that this training scheme works well for our tasks, although another parameterization as in , where the score is only predicted for the masked variables, could be used.

Architecture conditioning and reconstruction guidance.In the universal amortised model, conditioning on previous states happens naturally via the model architecture. However, this strategy is not practical for conditioning on partial observations (e.g. sparse space-time observations as in DA), as a new model needs to be trained every time new conditioning variables are introduced. To avoid this, we propose to simultaneously use reconstruction guidance (as estimated in (8)) to condition on other variables, as well as keep the conditioning on previous states through model architecture.

### Rollout strategies

In this section, we describe sampling approaches that can be used to generate PDE rollouts, depending on the choice of local score and conditioning. We provide in App. K pseudocode for each rollout strategy.

All-at-once (AAO).With a trained joint score \(_{}(t,x_{i-k:i+k}(t))\) we can generate entire trajectories \(x_{1:L}\) in one go, as in Rozet and Louppe . The full score \(_{}(t,x_{1:L}(t)) p_{t}(x_{1:L}(t))\) is reconstructed from the local scores, as shown in App. B.1 and summarised in Rozet and Louppe [60, Alg 2.]. The \(\)th component is given by \(_{i}=_{}(t,x_{i-k:i+k}(t))[k+1]\) which is the central output of the score network, except for the start and the end of the sequence for which the score is given by \(_{1:k}=_{}(t,x_{1:2k+1}(t))[:k+1]\) and \(_{L-k:L}=_{}(t,x_{L-2k:L}(t))[k+1:]\), respectively. If we observe some values \(x_{o}(|x_{1:L},_{y}^{2}|)\), the conditional sampling is done by summing the full score \(_{}(t,x_{1:L}(t))\) with the guidance term \( p(x_{o}|x_{1:L}(t))\) estimated with (8).

Autoregressive (AR).Let us assume that we want to sample \(x_{C+1:L}\) given \(x_{1:C}\) initial states. An alternative approach to AAO is to factor the forecasting prediction problem as \(p(x_{1:L}|x_{1:C})=_{i}p(x_{i}|x_{i-C:i-1})\) with \(C k\). As suggested in Ho et al. , it then follows that we can sample the full trajectory via ancestor sampling by iteratively sampling each conditional diffusion process. More generally, instead of sampling one state at a time, we can autoregressively generate \(P\) states, conditioning on the previous \(C\) ones, such that \(P+C=2k+1\). This procedure can be used both by the joint and the amortised conditional score. DA can similarly be tackled by further conditioning on additional observations appearing within the predictive horizon \(P\) at each AR step of the rollout.

Scalability.Both sampling approaches involve a different number of neural function evaluations (NFEs). Assuming \(p\) predictor steps and \(c\) corrector steps to simulate (4), AAO sampling requires \((1+c)p\) NFEs. In contrast, the AR scheme is more computationally intensive as each autoregressive step also costs \((1+c)p\) NFEs but with \((1+)\) AR steps. We stress, though, that this is assuming the full score network evaluation \(_{1:L}=_{}(t,x_{1:L}(t))\) is parallelised. In practice, due to memory constraints, the full score in AAO would have to be sequentially computed. Assuming only one local score evaluation fits in memory, it would require as many NFEs as AR steps. What's more, as discussed in the next paragraph, AAO in practice typically requires more corrector steps. See App. F.1 for further discussion on scalability.

Modelling capacity of the joint score.As highlighted in Tab. 1, when using a joint score, both AAO and AR rollout strategies can be used. We hypothesise there are two main reasons why AR outperforms AAO. First, for the same score network with an input window size of \(2k+1\), the AAO model has a Markov order \(k\) whilst the AR model has an effective order of \(2k\). Indeed, as shown in (7), a process of Markov order \(k\) yields a score for which each component depends on \(2k+1\) inputs. Yet parameterising a score network taking \(2k+1\) inputs, means that the AR model would condition on the previous \(2k\) states at each step. This twice greater Markov order implies that the AR approach is able to model a strictly larger class of data processes than the AAO sampling. See App. B.1 for further discussion on this.

Second, with AAO sampling the denoising process must ensure the start of the generated sequence agrees with the end of the sequence. This requires information to be propagated between the two ends of the sequence, but at each step of denoising, the score network has a limited receptive field of \(2k+1\), limiting information propagation. Langevin corrector steps allow extra information flow, but come with additional computational cost. In contrast, in AR sampling, there is no limit in information flowing forward due to the nature of the autoregressive scheme.

## 4 Related work

In the following, we present works on diffusion models for PDE modelling since these are the models we focus on in this paper. We present an extended related work section in App. C, where we broadly discuss ML-based and classical solver-based techniques for tackling PDE modelling.

Diffusion models for PDEs.Recently, several works have leveraged diffusion models for solving PDEs, with a particular focus on fluid dynamics. Amortising the score network on the initial state, Kohl et al.  introduced an autoregressive scheme, whilst Yang and Sommer  suggested to directly predict future states. Recently, Cachay et al.  proposed to unify the denoising time and the physical time to improve scalability. Lippe et al.  built upon neural operators with an iterative denoising refinement, particularly effective to better capture higher frequencies and enabling long rollouts. In contrast to the above-mentioned work, others have tackled DA and super-resolution tasks. Shu et al.  and Jacobsen et al.  suggested using the underlying PDE to enforce adherence to physical laws. Huang et al.  used an amortised model and inpainting techniques  for conditioning at inference time to perform DA on weather data. Rozet and Louppe  decomposed the score of long trajectory into a series of local scores over short segments to be able to work with flexible lengths and to dramatically improve scalability w.r.t. memory use. Concurrently to our work, Qu et al.  extended this approach to latent diffusion models to perform DA on ERA5 weather data . In this work, we show that such a trained score network can alternatively be sampled autoregressively, which is guaranteed to lead to a higher Markov order, and empirically produce accurate long-range forecasts. Concurrently, Ruhe et al.  proposed to use a local score, not justified by any Markov assumption, together with a frame-dependent noising process for video and fluid dynamics generation. Diffusion models for PDE modelling are indeed closely related to other sequence modelling tasks, such as video generation and indeed our universal amortised approach is influenced by Hoppe et al. , Voleti et al. .

## 5 Experimental results

We study the performance of the diffusion-based models proposed in Tab. 1 on three different described in more detail below. The code to reproduce the experiments is publicly available at https://github.com/cambridge-mlg/pdediff.

Data.In this work, we consider the 1D Kuramoto-Sivashinsky (KS) and the 2D Kolmogorov flow equations, with the latter being a variant of the incompressible Navier-Stokes flow. KS is a fourth-order nonlinear 1D PDE describing flame fronts and solidification dynamics. The position of the flame \(u\) evolves as \(_{}u+u_{x}u+_{x}^{2}u+_{x}^{4}u=0\) where \(>0\) is the viscosity. The equation is solved on a periodic domain with \(256\) points for the space discretisation and timestep \(=0.2\). Training trajectories are of length \(140\), while the length of validation and testing ones is set to \(640\). The Kolmogorov flow is a 2D PDE that describes the dynamics of an incompressible fluid. The evolution of the PDE is given by \(_{}+-^{2}+ p-f=0\) and \(=0\), where \(\) represents the velocity field, \(\) the viscosity, \(\) the fluid density, \(p\) the pressure, and \(f\) is the external forcing. The considered trajectories have \(64\) states with \(64 64\) resolution and \(=0.2\). The evaluation metrics are measured with respect to the scalar vorticity field \(=_{x}u_{y}-_{y}u_{x}\). We focus on these since their dynamics are challenging, and have been investigated in prior work [17; 42]. We refer to App. D for more details on the data generation. In addition, in App. F.1 we present results for the simpler 1D Burgers' equation.

Models.For forecasting and DA, we train a single local score network on contiguous segments randomly sampled from training trajectories. We use a window 9 model for KS and a window 5 model for Kolmogorov, as these settings give a good trade-off between performance and memory requirements. We show in F.3 that increasing the window size in KS does lead to improved performance in forecasting, but the gains are relatively small. We parameterise the score network \(_{}\) with a modern U-Net architecture [22; 59] with residual connections and layer normalization. For sampling, we use the DPM solver  with \(128\) evenly spaced discretisation steps. As a final step, we return the posterior mean over the noise free data via Tweedie's formula. For the guidance schedule we set \(r_{t}^{2}=_{t}^{2}/_{t}^{2}\) and tune \(\) via grid search. We refer to App. D.4 for more details.

Evaluation metrics.We compute two per time step metrics--mean squared error \(_{1:L}=[(x_{1:L}-_{1:L})^{2}]\) and Pearson correlation \(_{1:L}=(x_{1:L},_{1:L})}{(x_{1:L}) (_{1:L})}\) between model samples \(_{1:L} p_{}\) and ground truth trajectories \(x_{1:L} p_{0}\). We measure example accuracy through \(=_{l=1}^{L}_{l}}\) and high correlation time \(t_{}=l_{} t\) with \(l_{}=_{l 1:L}\{_{l}>0.8\}\).

### Forecasting

As mentioned in Sec. 3, forecasting is a crucial component of the combined task we consider, so we investigate the ability of trained diffusion models to sample long rollouts. The models are evaluated on \(128\) and \(50\) test trajectories for KS and Kolmogorov, respectively. To understand the current state of score-based models for PDE forecasting we benchmark them against other ML-based models, including the state-of-the-art PDE-Refiner  and a MSE-trained U-Net and Fourier Neural Operator (FNO) . We follow the setup in  for the architectures and training settings of the baselines. For the diffusion models and the MSE-trained U-Net baseline, we experiment with both an architecture inspired from  and one inspired from  and report the best results. The performance of both neural network architectures considered can be found in Tab. 5. More details about the different architectures can be found in App. D.4.

Fig. 1 shows the performance of the joint, amortised and universal amortised models for different conditioning scenarios \(P C\), with \(P\) the number of states generated, and \(C\) the number of states conditioned upon at each iteration. For the KS dataset, the universal amortised model outperforms the plain amortised one across all \(P C\); for Kolmogorov their performance is comparable (i.e. within

Figure 1: High correlation time (\(\)) on the KS (left) and Kolmogorov (right) datasets for different \(P C\) conditioning scenarios of the joint, amortised and universal amortised models, where \(P\) indicates the number of generated states and \(C\) the number of states conditioned upon. We show mean \( 3\) standard errors, as computed on the test trajectories.

standard errors). For both datasets, the best (plain and universal) amortised models outperform the best joint AR model, with the exact best high correlation times shown in Fig. 2.

Stability over history length.The most interesting comparison between the models lies in how they leverage past history in the context of forecasting. Previous work notes that longer history generally degrades the performance of amortised models . We find that this behaviour is dataset-dependent--the observation holds for KS, whereas for Kolmogorov the plain amortised models with longer history (i.e. \(1 4\) and \(2 3\)) tend to outperform the ones with shorter history (i.e. \(3 2\) and \(4 1\)). Due to our novel training procedure for the universal amortised model (i.e. training over a variety of tasks), we obtain stable performance over all conditioning scenarios for the KS dataset. For Kolmogorov, the universal amortised model benefits from longer history, similarly to the plain amortised one. However, note that, unlike the plain amortised model, where a different model needs to be trained for each conditioning scenario, the universal amortised can tackle any scenario, allowing for a trade-off between accuracy and computational speed at sampling time. The joint model generally benefits from longer conditioning trajectories, but is also fairly stable for the majority of \(P C\) settings. We show more results in App. F.3.

For a complete comparison between the models in Tab. 1, we also perform AAO sampling for the joint model. However, as shown in App. F.1, the predicted samples rapidly diverge from the ground truth. Thus, the AR method of querying the joint model is crucial for forecasting.

Benchmarks.In Fig. 2, we report the comparison against popular methods for forecasting. The universal amortised model performs similarly to the MSE-trained U-Net on both datasets, while the joint model is comparable to the MSE-trained FNO, performing on par with it for KS and slightly outperforming it for Kolmogorov. However, we stress that, unlike these benchmarks, which can only be straight-forwardly applied to forecasting, our models are significantly more flexible--they manage to achieve competitive performance with some of the MSE-trained benchmarks, yet can be applied to a wider variety of tasks (e.g. forecasting combined with DA).

Additional results.For a more thorough understanding of the models' behaviour, we perform further analysis on the frequency spectra of the generated trajectories in App. I. We show that, as noted in previous work , the generated KS samples tend to approximate the low-frequency components well, but fail to capture the higher-frequency components, while the Kolmogorov samples generally show good agreement with the ground truth spectrum. We also investigate the long-term behaviour of our proposed models in App. J. Even when generating trajectories that are significantly longer than those used during training, the models are capable of generating physically-plausible states.

### Offline data assimilation

In offline DA, we assume we have access to some sparse observations. The experimental setting goes as follows. We first choose a number of observed variables, and then uniformly sample the associated indices. We assume to always observe some full initial states. More details can be found in App. G. We repeat this for different numbers of values observed, varying the sparsity of observations, from approximately a third of all data to almost exclusively conditioning on the initial states. We compute the RMSD of the generated trajectories for six values of the proportion of observed data, evenly spaced on a log scale from \(10^{-3}\) to \(10^{-0.5}\). We show results for the joint AR model, joint AAO with \(0\) and \(1\) corrections (indicated between brackets), and the universal amortised model. To provide

Figure 2: The best joint and amortised models compared against standard ML-based benchmarks for forecasting on the KS (left) and Kolmogorov (right) datasets. High correlation time (\(\)) is reported, showing the mean \(\) 3 standard errors, as computed on the test trajectories. We show in Tab. 5 the configurations for the best models.

a consistent comparison with the AAO approach from , all models use the U-Net architecture inspired by . We tune the guidance strength \(\), and for AR we only report the \(P C\) setting that gives the best trade-off between performance and computation time (see Fig. 28 for a comprehensive summary of performance depending on \(\) and \(P C\)). We show the results on 50 test trajectories for both KS and Kolmogorov. More results can be found in App. G.

More efficient sampling.We observe in Fig. 3 that AR sampling outperforms AAO in the sparse observation regimes, and performs on par with it in the dense observation regimes, provided corrections are used. However, Fig. 3 shows that corrections significantly increase the associated computational cost. We believe the difference in performance is mostly due to the limiting information propagation in the AAO scheme, combined with the lower effective Markov order of AAO vs AR (\(k\) vs \(2k\) for a local score network with a window of \(2k+1\)), as discussed in Sec. 3.3. To further investigate this hypothesis, in App. G.2.1 we compare the results for a window \(5\) (\(k=2\)) AR model with a window \(9\) (\(k=4\)) AAO model for KS. These should, in theory, have the same effective Markov order. We observe that for the sparsest observation regime, there is still a gap between AR (\(k=2\)) and AAO (\(k=4\)), potentially because the high sparsity of observations make the information flow in the AAO scheme inefficient. In fact, this is consistent with the findings from forecasting, where we observe that the AAO strategy is unable to produce coherent trajectories if it does not have access to enough future observations. In contrast, for the other sparsity scenarios the performance of the two schemes becomes similar provided corrections are used. However, this comes with a significant increase in computational cost.

Reconstruction guidance for universal amortised model.As outlined in Sec. 3.2, we can combine the universal amortised model with reconstruction guidance for conditioning on sparse observations. Amortised models do not straight-forwardly handle DA -- this can be seen in Fig. 29a, where we show that conditioning just through the architecture gives poor results in DA. In KS, the universal amortised model achieves lower RMSD for the very sparse observation scenarios (\(10^{-3}\) proportion observed), and for the very dense ones (\(10^{0.5}\) proportion observed). However, the joint model outperforms it in the middle ranges. In Kolmogorov, the universal amortised model slightly outperforms the joint for all sparsity settings, with the results being within error bars. These findings indicate that they are both viable choices for offline DA, with the best performing choice depending on the application.

Interpolation baseline.In App. G.3 we also provide a quantitative and qualitative comparison to a simple interpolation baseline, proving that the studied models manage to capture the underlying physical behaviour better than such simple baselines.

### Online DA: combining forecasting and data assimilation

Inspired by real-life applications such as weather prediction, we compare the models in the online DA setting, which represents the combination of forecasting and DA. We assume that some sparse

Figure 3: RMSD (mean \(\) 3 standard errors) for KS (left) and Kolmogorov (right) on the offline DA setting for varying sparsity levels (top), and the computational cost associated with each setting (bottom). The latter is the same for all sparsity settings for AAO, but differs for AR since it depends on the \(P C\) setting that was used. The \(c\) in AAO (\(c\)) refers to the number of corrector steps used.

and noisy variables are observed once every \(s\) states (in blocks of length \(s\)), and whenever new observations arrive (i.e. at each DA step), we forecast the next \(f\) states. At the first step, we perform forecasting assuming we have access to some randomly sampled indices, accounting for \(10\%\) of the first \(s\)-length trajectory. At the second step (after \(s\) time-steps), we refine this forecast with the newly observed set of variables. This repeats until we have the forecast for the entire length of the test trajectories. The performance is measured in terms of the mean RMSD between the forecasts and the ground truth (averaged over all the DA steps, each outputting a trajectory of length \(f\)). We set \(s=20\) and \(f=400\) for KS, and \(s=5\) and \(f=40\) for Kolmogorov, resulting in \(13\), and \(6\) DA steps, respectively. The setup is visualised in App. H, and the key findings from the results in Tab. 2 are

* AAO is unsuitable for tasks involving forecasting -- As opposed to the offline setting, AAO fails at online DA, leading to a significantly higher RMSD on both datasets.
* The universal amortised model shows the best performance out of all the models, which is in line with the findings from the previous sections -- it outperforms joint AR in forecasting and performs on par with it in DA.

## 6 Discussion

In this work, we explore different ways to condition and sample diffusion models for forecasting and DA. In particular, we empirically demonstrate that diffusion models achieve comparable performance with MSE-trained models in forecasting, yet are significantly more flexible as they can effectively also tackle DA. We theoretically justify and empirically demonstrate the effectiveness of AR sampling for joint models, which is crucial for any task that contains a forecasting component. Moreover, we enhance the flexibility and robustness of amortised models by proposing a new training strategy which also amortises over the history length, and by combining them with reconstruction guidance.

Limitations and future work.Although achieving competitive results with MSE-trained baselines in forecasting, the models still lack state-of-the-art performance. Thus, they are most practical in settings where flexible conditioning is needed, rather than a standard forecasting task. Although we have explored different solvers and number of discretisation steps, the autoregressive sampling strategy requires simulating a denoising process at each step, which is computationally intensive. We believe that this can be further improved, perhaps by reusing previous sampled states. Additionally, the guided sampling strategy requires tuning the guidance strength, yet we believe there exist some simple heuristics that are able to decrease the sensitivity of this hyperparameter. Finally, we are interested in investigating how the PDE characteristics (i.e. spatial / time discretisation, data volume, frequency spectrum, etc.) influence the behaviour of the diffusion-based models.