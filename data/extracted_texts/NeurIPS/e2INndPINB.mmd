# Rethinking Reconstruction-based Graph-Level Anomaly Detection: Limitations and a Simple Remedy

Sunwoo Kim\({}^{1}\), Soo Yong Lee\({}^{1}\), Fanchen Bu\({}^{2}\), Shinhwan Kang\({}^{1}\),

Kyungho Kim\({}^{1}\), Jaemin Yoo\({}^{2}\), Kijung Shin\({}^{1,2}\)

\({}^{1}\)Kim Jaechul Graduate School of AI, \({}^{2}\)School of Electrical Engineering

Korea Advanced Institute of Science and Technology (KAIST)

{kswoo97, syleetolow, boqvezen97, shinhwan.kang,

kkyungho, jaemin, kijungs}@kaist.ac.kr

###### Abstract

Graph autoencoders (Graph-AEs) learn representations of given graphs by aiming to accurately reconstruct them. A notable application of Graph-AEs is graph-level anomaly detection (GLAD), whose objective is to identify graphs with anomalous topological structures and/or node features compared to the majority of the graph population. Graph-AEs for GLAD regard a graph with a high mean reconstruction error (i.e. mean of errors from all node pairs and/or nodes) as anomalies. Namely, the methods rest on the assumption that they would better reconstruct graphs with similar characteristics to the majority. We, however, report non-trivial counter-examples, a phenomenon we call _reconstruction flip_, and highlight the limitations of the existing Graph-AE-based GLAD methods. Specifically, we empirically and theoretically investigate when this assumption holds and when it fails. Through our analyses, we further argue that, while the reconstruction errors for a given graph are effective features for GLAD, leveraging the multifaceted summaries of the reconstruction errors, beyond just mean, can further strengthen the features. Thus, we propose a novel and simple GLAD method, named MuSE. The key innovation of MuSE involves taking multifaceted summaries of reconstruction errors as graph features for GLAD. This surprisingly simple method obtains SOTA performance in GLAD, performing best overall among 14 methods across 10 datasets.

## 1 Introduction

Graph autoencoders (Graph-AEs) are a family of graph neural networks (GNNs) that learn latent representations of given graphs by aiming to accurately reconstruct them. Representative examples of Graph-AEs include GAE  and GraphMAE , which respectively aim to accurately reconstruct graph structure and node features. Graph-AEs have a broad spectrum of applications, such as anomaly detection  and link prediction .

Graph-AEs are trained to capture the structural information of graphs used for training (i.e., training graphs). Thus, intuitively, Graph-AEs are expected to better reconstruct graphs that are similar to the training graphs. However, to our surprise, this expectation is not always true. Given Graph-AEs trained to reconstruct the graphs in Figure 1(a), which share common structural characteristics, one would expect that the Graph-AEs would reconstruct the training graphs with smaller reconstruction errors than a dissimilar counterpart (e.g., in Figure 1 (b)). We, however, report the opposite. The reconstruction error is lower for the graph in Figure 1(b) than the training graphs. While similar observations were reported in computer vision application , which we elaborate on in Section 2.1, the existing literature does not clearly explain the aforementioned phenomenon.

This counterintuitive phenomenon guides our analysis, implication, and the proposed method. First, we aim to understand this counterintuitive phenomenon, which we refer to as the _reconstruction flip_.

We argue that the phenomenon can occur when (1) the training graphs and unseen graphs share a primary structural pattern and (2) the pattern is more pronounced in unseen graphs than in training graphs. We corroborate our claim with our theoretical and empirical analysis.

Second, our finding has strong implications for graph-level anomaly detection (GLAD). GLAD aims to identify graphs of different characteristics (e.g., structures and/or features) from the majority [38; 33; 39; 32]. Many existing GLAD methods leverage Graph-AEs [33; 38]. They regard a graph with a high mean reconstruction error (i.e. mean of errors from all node pairs and/or nodes) as anomalies, assuming trained Graph-AEs would struggle to reconstruct the graphs with structural patterns (and/or node attributes) that deviate from most training graphs. However, our finding suggests that this assumption does not always hold. Specifically, anomalous graphs with structural characteristics distinct from the training graphs may exhibit similar or even lower mean reconstruction errors. In such cases, the existing methods would struggle to detect anomalous graphs. We argue that this issue arises from how the existing methods leverage reconstruction errors, yet these errors remain valuable graph features for GLAD. We propose using multifaceted summaries of the reconstruction errors, rather than relying solely on their mean, to further enhance the features.

Third, based on the analysis and implication, we propose a simple and novel GLAD method, **MuSE** (**Mu**ltifacted **S**ummarization of **R**econstruction **E**rrors). **MuSE**, like other Graph-AE-based GLAD methods, reconstructs given graphs. However, **MuSE** employs a new way of using reconstruction errors: representing a graph with multifaceted summaries (e.g., mean, standard deviation, etc.) of the graph's reconstruction errors for GLAD. This simple innovation allows **MuSE** to obtain SOTA performance in the GLAD tasks. Through our extensive experiments including 13 baseline methods and 10 benchmark datasets, **MuSE** performs overall best, achieving up to 28.1% performance gain (in terms of AUROC) compared to the best competitor. We summarize our contribution as follows:

* **Analysis (Section 3) with implications (Section 4):** We investigate the reconstruction flip phenomenon both theoretically and empirically, yielding practical implications for GLAD.
* **Effective method (Section 5):** Motivated by our analysis, we propose **MuSE**, a simple yet effective GLAD method that represents a graph as multifaceted summaries of its reconstruction errors.
* **Extensive experiments (Section 6):** Our experiments on \(10\) datasets demonstrate the superiority of **MuSE** over prior GLAD methods. Our code and datasets are available at https://github.com/kswoo97/GLAD_MUSE.

## 2 Related Work and Preliminaries

In this section, we provide a brief literature review on graph-level anomaly detection (GLAD) and peculiar observations in GLAD. We then present the preliminaries of our work.

### Related work

**Graph-level anomaly detection.** Graph-level anomaly detection (GLAD) aims to identify graphs whose characteristics deviate from those of the majority of the graph population [38; 33; 39; 32]. GLAD has various applications, including brain diagnosis  and drug discovery . While several GLAD methods require anomaly label supervision to train a detector [54; 35], we focus on the methods that do not require anomaly labels [38; 33; 39; 32], since anomaly labels are often not available in real-world scenarios. A GLAD method typically trains a model to perform certain pretext tasks on given graphs, and the graphs are regarded as anomalies if the trained model shows poor pretext task

Figure 1: The training graphs in (a) and the unseen graph in (b) exhibit different structural characteristics, but a Graph-AE model reconstructs the graph in (b) more accurately than those in (a).

performance on them. Notable pretext tasks include graph reconstruction [38; 33], graph embedding hypersphere minimization [39; 57], and cross-view mutual information maximization [34; 32].

**Peculiar observations in graph-level anomaly detection.** The most relevant literature with our work is a study of Zhao and Akoglu . In graph classification datasets, they regarded graphs belonging to a particular class as normal graphs and otherwise as anomalies to benchmark several GLAD methods. In this setting, they observed that several GLAD methods, especially kernel-based ones, occasionally perform worse than random guessing. However, their analysis focused on graph kernels [37; 41], without covering graph autoencoders, which are our focus. In computer vision, Liu et al.  suggested that certain anomalous images can be easier to reconstruct than normal ones, presenting a method that can overcome these undesirable circumstances. However, neither their analysis nor the method can be trivially extended to the graph domain, as elaborated in Appendix F.1.

### Preliminary

**Graphs.** A graph \(=(,)\) is defined by a node set \(=\{v_{1},,v_{||}\}\) and an edge set \(=\{e_{1},,e_{||}\}\), where each edge \(e_{i}\) is defined by a node pair. We assume that each node \(v_{i}\) is equipped with a feature vector \(_{i}^{d}\), which forms a node feature matrix \(^{|| d}\) where each \(i\)-th row \(_{i,:}=_{i}\). Moreover, \(\) can be represented by an adjacency matrix \(\{0,1\}^{||||}\), where \(_{i,j}=1\) if and only if \(\{v_{i},v_{j}\}\). Therefore, the graph can also be defined as \(=(,)\).

**Graph neural networks.** Graph neural networks (GNNs) are a category of neural networks designed for processing graph data. GNNs primarily leverage message passing schemes [49; 14; 45; 11; 28; 30]. In this work, we consider GNNs as parameterized functions \(f_{}\) that generate node embeddings \(=f_{}(,)^{||  d^{}}\) for each graph \(=(,)\). 1

**Graph autoencoders.** Graph autoencoders (Graph-AEs) are a family of GNNs that learn graph latent representations by graph reconstruction. Specifically, Graph-AEs reconstruct a given graph's structure [22; 43] and/or node features [15; 16]. For example, GAE  reconstructs the adjacency matrix of a given graph. Specifically, GAE first uses an encoder GNN \(f_{}\) to generate node embeddings \(=f_{}(,)\) of a given graph \(=(,)\). Then, GAE obtains a reconstructed adjacency matrix \(}^{||||}\) through the inner-product of node embeddings and entry-wise sigmoid activation \(\) (i.e., \(}=(^{T})\)). Lastly, it minimizes the difference between \(\) and \(}\), for which one can use the binary cross-entropy (BCE) loss \(_{}( f_{})-_{i,j=1}^{ ||}(_{i,j}}_{i,j}+(1-_ {i,j})(1-}_{i,j}))\) or the squared Frobenius-norm loss \(_{}( f_{})\|- }\|_{F}^{2}=_{i,j=1}^{||}(_{i,j} -}_{i,j})^{2}.\) Given a set of training graphs \(=\{_{1},_{2},,_{||}\}\), GAE is trained (i.e., the encoder parameter \(\) is updated) to minimize \(_{}( f_{})\) (or equivalently, \(_{}( f_{})\)), where \(\) is \(_{}\) or \(_{}\).

In our analysis below, we focus on methods that reconstruct graph structures, while we describe and investigate node-feature-reconstruction methods in Appendix E.1.

## 3 Analysis of Graph Autoencoders

In this section, we explore _reconstruction flip_ phenomena (e.g., the phenomenon described in Figure 1), where graph autoencoders (Graph-AEs) reconstruct some unseen graphs that are dissimilar to training graphs better than training graphs.

Our analysis focuses on evidencing the claims below. We assume GAE  trained on graphs sharing a primary pattern \(\) of strength \(\).

[topsep=0pt,leftmargin=*]

* _Reconstruction flip **tends to occur** when unseen (test) graphs have the same primary pattern \(\) but with a greater strength \(^{}>\).
* _Reconstruction flip **tends not to occur** when unseen (test) graphs have a different primary pattern \(^{}\)._

### Synthetic graphs

To elaborate on the concepts of a primary pattern \(\) and a pattern strength \(\), we employ two types of synthetic graphs: (1) graphs with community structures and (2) graphs with cycles.

**Community type.** Syn-Com graphs have community structures, a pervasive pattern in real-world graphs , as the primary pattern \(\). Graphs in Figure 1 are instances of such graphs. We control the strength \(S\) of community structures through a parameter \(\). The \(10\) nodes in each graph are evenly divided into two communities. Each intra- and inter-community edge is formed with probability \((1+)/2\) and \((1-)/2\), respectively. In our empirical analysis, we consider two graph classes with different \(\)'s. Graphs in one class \(_{=0.4}^{com}\) are generated with \(=0.4\) (weaker community structure; the graphs in Figure 1(a)) and those in the other class \(_{=0.8}^{com}\) are generated with \(=0.8\) (stronger community structure; the graph in Figure 1(b)).

**Cycle type.** Syn-Cycle graphs contain a cycle of nodes (i.e., a closed chain of nodes), which is commonly observed in real-world graphs . In Syn-Cycle, the primary pattern \(\) corresponds to the node cycle. Graphs in Figure 4 are instances of Syn-Cycle. In Syn-Cycle graphs, the pattern strength \(\) is stronger in the clean-cycle graph consisting only of a cycle with \(n\) nodes (the left graph in Figure 4), and it is weaker in noisy-cycle graphs, where a node within the cycle of (\(n-1\)) nodes is linked to an extra node (the right graph in Figure 4). The number of nodes \(n\) is fixed to \(10\).

We provide detailed descriptions of both graph types in Appendix C.

### Empirical analysis

**Setting.** We consider two scenarios. In Scenario 1, we aim to validate our first claim. To this end, we leverage (1) the Com-Com dataset, where the training graphs are sampled from \(_{=0.4}^{com}\) and the unseen graphs are sampled from \(_{=0.8}^{com}\), and (2) the Cycle-Cycle dataset, where the training graphs are sampled from the noisy-cycle graphs and the unseen graph is the clean-cycle graph.

Figure 4: A clean-cycle graph and a noisy-cycle graph.

Figure 3: **Reconstruction flip does NOT occur.** When Graph-AEs are trained on graphs sharing a primary pattern, the trained Graph-AEs exhibit higher reconstruction errors for graphs with a different pattern (red lines) than those with the same pattern (blue lines).

Figure 2: **Reconstruction flip occurs.** When Graph-AEs are trained on graphs sharing a primary pattern of weak strength, the trained Graph-AEs exhibit lower reconstruction errors for graphs with the same pattern but with higher strength (red lines) than those with weaker strength (blue lines).

In Scenario 2, we aim to validate our second claim. To this end, we leverage (3) the Com-Cycle dataset, where the training graphs are sampled from \(_{=0,4}^{com}\) and the unseen graphs are sampled from the noisy-cycle graphs, and (4) the Cycle-Com dataset, where the training graphs are sampled from the noisy-cycle graphs and the unseen graphs are sampled from \(_{=0,4}^{com}\).

For each dataset, we train GAE  equipped with GIN  as the graph encoder. We use either the (1) binary cross-entropy (BCE) loss or the (2) squared Frobenius-norm (Frobenius) loss, which are formalized in Section 2.2, for the reconstruction loss. We compare the reconstruction losses for the training graphs and unseen graphs. Further details are provided in Appendix D.2.

_Note. While we focus on adjacency reconstruction in this section, we provide an analysis of feature-reconstruction methods in Appendix E.1, where the results are consistent with those below._

**Empirical results.** In Scenario 1, for both Com-Com and Cycle-Cycle datasets, reconstruction losses are lower for the graphs with stronger pattern strengths, which are unseen graphs (see Figure 2). That is, all graphs share a primary pattern \(\) (either node community or cycle) with two different strengths \(<^{}\), and GAE trained on graphs of pattern strength \(\) reconstructs those of pattern strength \(^{}\) with lower losses, demonstrating our first claim. In Scenario 2, for both Com-Cycle and Cycle-Com datasets, reconstruction losses become lower for the training graphs after some training epochs (see Figure 3). That is, given training graphs with a primary pattern \(\) (either node communities or a cycle), the trained GAE reconstructs graphs with the same pattern \(\) with lower losses than those with a different pattern \(^{}\), demonstrating our second claim.

### Theoretical analysis

In this subsection, we theoretically analyze the empirical observations in Section 3.2, focusing on the occurrence of reconstruction flip. Informally speaking, we shall show that when GAE is trained on graphs with a primary pattern \(\) of strength \(\), the following holds:

1. [label=(**A0**),leftmargin=*,noitemsep]
2. Reconstruction losses decrease for graphs with the same \(\) of various strengths.
3. Reconstruction losses decrease more rapidly for graphs with the same \(\) of greater strengths.

**Setting.** For theoretical analysis, we use a single-layer linear GAE. Formally, for a given graph \(=(,)\), the linear GAE reconstructs the given graph's adjacency matrix as follows: \(}=()^{T}\), where \(^{n n}\) is a learnable weight matrix and \(n\) is the number of nodes. We use the squared Frobenius norm as the reconstruction loss \((,)=\|-}\|_{F}^{2}\). We consider Syn-Com graphs \(_{}^{com}\) (Section 3.1). To formalize the training of linear GAE, we define the expected gradient descent update of \(\) as follows:

\[(,,)=-_{} [(,)}{} ]^{n n},\] (1)

where \(>0\) is a learning rate and \(_{}[|]\) takes the expectation over all the graphs \(_{}^{com}\). We assume graphs of strength \(_{1}\) are used as the training graphs and graphs of strength \(_{2}\) are used as the unseen (test) graphs.

**Theoretical results.** We now present our theoretical results, with proof of each theorem in Appendix A. We first demonstrate that 1 holds by expectation.

**Theorem 1** (Generalization across \(\)).: _For any \(n 12\) and \(0<_{1} 1\), there exists \(>0\) such that for any \(0<\) and any \(0<_{2} 1\) (recall that \(0\) and \(1\) are the lower and upper bounds of \(\), respectively) with the initial weight matrix \(^{(0)}=_{n}\),_

\[_{}[(,(_{ 1},^{(0)},))|_{2}]}_{$ after update}}<_{}[ (,^{(0)})|_{2}]}_{$ before update}}.\]

Roughly, Theorem 1 states that regardless of the values of \(_{1}\) and \(_{2}\), updating \(\) with graphs of strength \(_{1}\) reduces the reconstruction losses for graphs of strength \(_{2}\). Intuitively, this suggests that GAE learns the primary pattern \(\), regardless of the strength \(\) (here, \(_{1}\)) of the training graphs.

Now, we demonstrate that 2 holds by expectation.

**Theorem 2** (Correlation with \(\)).: _For any \(n 34\) and \(0<_{1} 0.98\), there exists \(>0\) such that for any \(0<\) and any \(_{1}+0.02_{2} 1\) with the initial weight \(^{(0)}=_{n}\),_

\[_{}[(,^{ (0)})-(,(_{1},^{(0)},)) _{1}]}_{$ (training graphs)}}<_{}[( ,^{(0)})-(,(_{1}, ^{(0)},))_{2}]}_{$ ( unseen graphs)}}.\]

Roughly, Theorem 2 states that updating \(\) using graphs of pattern strength \(_{1}\) results in a greater reduction of reconstruction losses for graphs of higher strength \(_{2}>_{1}\) than for the graphs used in \(\) update (i.e., graphs of strength \(_{1}\)). Intuitively, this result suggests that even if GAE is trained on graphs with a primary pattern \(\) of strength \(\) (here, \(_{1}\)), the trained GAE tends to reconstruct graphs of a greater strength \(^{}\) (here, \(_{2}\)) with smaller losses.

## 4 Implications in Graph-Level Anomaly Detection

In this section, we investigate the practical implications of our analysis in Section 3 for graph-level anomaly detection (GLAD). Specifically, we discuss the limitations of existing graph-autoencoder-based GLAD methods and propose an improved approach to using graph reconstruction errors.

### Limitations of existing Graph-AEs in GLAD

**Anomalous graphs may have low mean reconstruction errors.** As outlined in Section 2.1, many methods for graph-level anomaly detection (GLAD) use graph autoencoders (Graph-AEs), aiming to identify graphs whose characteristics deviate from the majority. Typically, such GLAD methods [33; 38] consider graphs with higher reconstruction losses (i.e. mean (or sum) of reconstruction errors from all node pairs and/or nodes) as anomalies. This is based on the intuition that Graph-AEs would struggle to reconstruct anomalous graphs that are dissimilar to the majority of training graphs. However, our empirical (Section 3.2) and theoretical (Section 3.3) analyses reveal that Graph-AEs can exhibit lower mean reconstruction errors for graphs that are less similar to training graphs. In the context of GLAD, when anomalous graphs have the same primary pattern as training graphs but have stronger strengths, Graph-AEs tend to exhibit lower mean reconstruction errors, compared to the training graphs. Thus, such anomalies tend not to be detected by existing Graph-AE-based GLAD methods, revealing their severe limitations.

**Mean is not all you need.** In addition in practice, we find that in some cases, dissimilar graphs can have similar mean reconstruction errors. As shown in Figure 5, although the graph \(_{1}\) in (a) and the graph \(_{2}\) in (b) have significantly different numbers of edges, their mean reconstruction errors are similar, making it difficult to distinguish between the two graphs (refer to the caption of Figure 5). On the other hand, Figure 5(c) shows that the reconstruction error distributions over individual node pairs 2 of \(_{1}\) (blue distribution) and \(_{2}\) (red distribution) differ significantly in shape. Other descriptive statistics, such as standard deviation, can effectively distinguish the two graphs in such cases. Thus, incorporating additional statistical measures beyond the mean is beneficial for Graph-AEs in GLAD.

Figure 5: A case of Graph-AEs (specifically, GAE ) having similar mean reconstruction errors for two dissimilar graphs (specifically, \(_{1}\)**has 0.6622** and \(_{2}\)**has 0.6627**), while their error distributions differ significantly.

### Enhancing the use of reconstruction errors

Based on the implications discussed in Section 4.1, we argue that _a graph's reconstruction errors aggregated in various ways_ can provide features that effectively distinguish anomalous graphs from normal graphs. We provide detailed descriptions of this claim below.

**Reconstruction errors serve as good features for GLAD.** Consider the following scenarios where Graph-AEs are trained on graphs sharing a pattern \(\) of strength \(\). First, for an unseen graph of a pattern \(\) with higher strength \(^{}>\), Graph-AEs tend to return lower mean reconstruction errors compared to those of the training graphs (Figure 2). Second, for an unseen graph of a different pattern \(^{}\), Graph-AEs tend to give higher mean reconstruction error than those of the training graphs (Figure 3). In both cases, the error distributions of anomalous graphs differ from those of normal graphs, serving as effective features for distinguishing them.

**Using multifaceted summaries of errors is important for GLAD.** In practice, we need a fixed-size representation of the error distribution to be used with anomaly classifiers, which generally require a fixed-size input vector. To achieve this, we propose using various summary statistics (e.g., mean and standard deviation) to represent the given error distribution. Specifically, rather than relying on a single statistic, we use multifaceted summaries that capture various aspects of the error distributions. This is because distinct error distributions may share certain similar summary statistics, as shown in Figure 5. Therefore, multifaceted summaries of the error distribution can act as an effective feature vector for distinguishing anomalous graphs from normal graphs.

## 5 Proposed Method: MuSE

Based on the discussions provided in Section 4.2, we present **MuSE** (**M**ultifacted **S**ummarization of Reconstruction **E**rrors), a simple yet effective graph-level anomaly detection (GLAD) method. MuSE aggregates a graph's reconstruction errors into multiple summary statistics and uses a vector of these aggregated errors as the graph's representation for GLAD. We describe how we train the reconstruction model in Section 5.1 and how we obtain the error representation (i.e., a multifaceted summary of reconstruction errors) in Section 5.2.

### Step 1: Training a reconstruction model

We first train MuSE to reconstruct graphs in training data. Step 1 is composed of three parts: (1) augmentation, (2) encoding/decoding, and (3) reconstruction loss minimization. For an input graph \(=(,)\), MuSE first augments the input graph by randomly dropping some edges, mitigating potential overfitting problems. Specifically, MuSE randomly samples \( p||\) edges from \(\) for some \(0 p<1\). Let \(^{}\) denote the set of sampled edges. We mask the corresponding entries in \(\) by setting them to zero to generate the augmented adjacency matrix \(^{}\{0,1\}^{||||}\) (i.e., \(^{}_{i,j}=0\) if \(\{v_{i},v_{j}\}^{}\), otherwise \(^{}_{i,j}=_{i,j,}, i,j[||]\)).

MuSE then encodes the augmented graph \(^{}=(,^{})\) to obtain node embeddings \(^{|| d^{}}\) by using a graph neural network (GNN) encoder \(f_{}\) (i.e., \(=f_{}(,^{})\)). Subsequently, MuSE decodes the node embeddings \(\) to obtain reconstructed node features \(}^{|| d}\) and reconstructed adjacency matrix \(}(0,1)^{||||}\). For node feature reconstruction, MuSE uses a node feature decoder \(g_{}:^{d^{}}^{d}\) (i.e., \(}=g_{}()\)). Similarly, for adjacency matrix reconstruction, MuSE uses an adjacency matrix decoder \(h_{}:^{d^{}}^{d^{}}\) and the inner product of its output (i.e., \(}=(^{}^{})\), where \(\) is a sigmoid function and \(^{}=h_{}()\)).

Lastly, for training, we leverage reconstruction losses regarding the node features and the adjacency matrix. For node feature reconstruction, we use the cosine-similarity loss as in GraphMAE . Formally, the loss is defined as follows:

\[_{}()=|}_{i=1}^{| |}(1-_{i,:}^{T}}_{i,:}}{\| _{i,:}\|_{2}\|}_{i,:}\|_{2}}),\|\|_{2}_{2}.\] (2)

For adjacency-matrix reconstruction, we use the binary cross-entropy (BCE) loss as in GAE . Since real-world graphs are often sparse (i.e., the adjacency matrix contains significantly more zeroentries than ones), we weight the loss terms associated with non-zero entries to stabilize model training in the presence of this imbalance. Formally, the loss is defined as follows:

\[_{}()=-(|})^{2} _{i=1}^{||}_{j=1}^{||}(_{i,j }}_{i,j}+(1-_{i,j})(1-}_{ i,j})),\] (3)

where \(=(|^{2}}{_{i=1}^{||}_{j=1}^{| |}_{i,j}}-1)^{}\) and \(\) is a scale hyperparameter. Then, the total reconstruction loss \(()\) is defined as the mean of \(_{}()\) (Eq. (2)) and \(_{}()\) (Eq. (3)) (i.e., \(()=(_{}()+_ {}())/2\)). For a set of training graphs \(=\{_{1},,_{K}\}\), we update the parameters (i.e., \(,,\) and \(\)) by using gradient descent aiming to minimize \(_{t[K]}(_{t})\).

### Step 2: Generating error representation

After training the reconstruction model, we represent each graph using its reconstruction errors, specifically those from all node pairs and/or nodes. Consider obtaining the reconstruction errors for a graph \(=(,)\) with the trained reconstruction model (i.e., \(f_{},g_{},\) and \(h_{}\)). To this end, we first obtain reconstructed features \(}\) and a reconstructed adjacency matrix \(}\) by using the encoding and decoding scheme described in Section 5.1. Note that we do not perform augmentation for Step 2 (i.e., the original graph \((,)\) is the input of the encoder \(f_{}\)).

After that, we obtain node-feature reconstruction errors \(_{}( f_{},g_{},h_{})\) on each node and adjacency-matrix reconstruction errors \(_{}( f_{},g_{},h_{})\) on each node pair. Formally,

\[_{}()=_{}( f _{},g_{},h_{})[1-_{i,:}^{T}}_{i,:}}{\|_{i,:}\|_{2}\|_{i,:}\|_{2}} ]_{i[||]}^{||},\] (4)

\[_{}()=_{}( f _{},g_{},h_{})[_{i,j}}_{i,j}+(1-_{i,j})(1-}_{i,j})]_ {i,j[||]}^{||^{2}}.\] (5)

Lastly, based on the motivation described in Section 4, we aggregate reconstruction errors (i.e., "_summarize_" vectors into scalars) using \(T\) different aggregation functions \(_{t}\)'s as follows:

\[()_{1}( _{}()),,_{T}(_{ }())]}_{_{}()}, _{1}(_{}()),, _{T}(_{}())}_{_{}()}] ^{2T}.\] (6)

Any aggregation functions that provides a representative summary of \(_{}()\) and \(_{}()\) are applicable, such as mean and standard deviation. As a result, we represent a graph \(\) as a \(2T\)-dimensional vector \(()\) (Eq. (6)), which we refer to as the final _error representation_ of \(\). We present a time complexity analysis of MuSE in Appendix F.3.

After obtaining error representations of graphs, we leverage one-class classifiers on these representations to finally perform anomaly detection. Note that Steps 1 and 2 are decoupled from the application of one-class classifiers (i.e., one-class classifier is trained after completing Steps 1 and 2).

## 6 Experiments

In this section, we evaluate the effectiveness of MuSE in graph-level anomaly detection (GLAD) by addressing four key research questions.

* **RQ1.** How accurately does MuSE detect anomalous graphs?
* **RQ2.** How robust is MuSE against contamination of the training set?
* **RQ3.** Can the error representations of MuSE distinguish anomalies from normal graphs in the representation space?
* **RQ4.** Are the key components of MuSE essential for its performance?

### Experimental settings

**Datasets.** Given the absence of benchmark datasets with ground-truth graph-level anomalies, following existing GLAD studies [39; 32; 33; 55; 34; 38], we use graph classification benchmark datasetsfor evaluation. Specifically, we use 10 datasets from diverse tuning, such as chemical molecules, bioinformatics, and social networks. Detailed descriptions of the datasets are in Appendix B.

**Training and evaluation.** Following Qiu et al. , for a dataset with \(C\) graph classes, we use \(C\) experimental configurations. In each configuration, graphs with one class are treated as normal, while graphs with the other classes are considered anomalies. For each configuration, the normal graphs are split into training, validation, and test sets in an 80%/10%/10% ratio. Additionally, 5% of anomalies are sampled for the validation set (only for hyperparameter tuning) and 5% for the test set. We conduct five trials for each configuration, with each trial using different data splits and model initializations. Each model's performance on each dataset is evaluated by averaging the test mean AUROC across all configurations.

**Baseline methods and MuSE.** We compare MuSE against 13 baseline methods, including 7 GLAD methods [39; 32; 33; 55; 34; 38; 6] and 6 graph self-supervised learning (SSL) methods [15; 22; 53]. Among SSL methods, those with '-1' in their names are one-stage SSL methods that use SSL losses as anomaly scores. Those with '-2' are two-stage SSL methods that (1) obtain graph embeddings the models learn via SSL and (2) employ a one-class classifier. For aggregation functions of MuSE (Eq. (6)), we use two aggregation functions: mean and standard deviation. Therefore, we represent each graph with a \(4\)-dimensional vector, which is formalized in Appendix D.4. All methods use GIN  as a graph encoder. All two-stage approaches use an MLP autoencoder as a one-class classifier. Details of two-stage methods and the MLP autoencoder are in Appendix D.3. In addition, we provide further experimental details, including hyperparameter configurations, in Appendix D.

### RQ1. Performance in graph-level anomaly detection

As shown in Table 1, MuSE outperforms all baseline methods in terms of average ranking. Two points stand out. First, in 8 out of 10 datasets, MuSE outperforms all other GLAD methods. Compared to the second-best GLAD method (OCGTL), MuSE achieves up to 16.2% performance gain (in the NCI1 dataset). Second, in 8 out of 10 datasets, MuSE outperforms all the SSL-based two-stage baselines (GraphCL-2, GAE-2, and GraphMAE-2). Given that they use the same one-class classifier with MuSE, this result demonstrates the effectiveness of the proposed error representation (Eq. (6)).

### RQ2. Robustness against the training set contamination

In real-world scenarios, training data may also contain anomalous graphs, making the robustness of GLAD methods against training set contamination crucial for their practical effectiveness. To assess this robustness, we inject anomalous graphs into the training set at rates of 10%, 20%, and 30%. 3 As shown in Figure 6, MuSE exhibits the least performance drop, among the three strongest GLAD methods, demonstrating its robustness.

   &  &  & NCI1 & AIDS & Reddit & IMDB & MUTAG & DIFER & B2R & ER & AR \\    & DOMINAT-G  & 64.3 (4.4) & 55.9 (0.7) & 65.5 (1.0) & 80.6 (4.0) & 58.6 (3.6) & 68.0 (8.7) & 65.0 (4.2) & 56.6 (0.2) & 76.2 (0.2) & 58.7 (5.5) & 10.7 \\  & OGGTL  & 74.5 (5.1) & 71.0 (8.7) & 61.2 (1.5) & 95.3 (3.7) & 69.0 (4.0) & 65.8 (3.6) & 64.9 (3.6) & 66.9 (3.9) & 71.3 (1.7) & 63.0 (0.6) & 6.9 \\  & GLocalKD  & 47.8 (8.9) & 50.7 (8.5) & 51.6 (5.1) & 51.2 (2.4) & 49.2 (5.8) & 58.5 (6.7) & 55.1 (4.4) & 51.1 (8.5) & 58.6 (17.6) & 54.4 (4.4) & 17.0 \\  & GLADC  & 52.1 (5.2) & 50.7 (5.6) & 51.4 (3.6) & 51.4 (1.0) & 52.2 (2.6) & 57.7 (5.2) & 53.3 (4.5) & 55.8 (4.1) & 59.0 (1.4) & 52.8 (4.2) & 16.8 \\  & GLAD  & 61.6 (5.6) & 63.0 (5.8) & 58.1 (9.3) & 59.6 (2.6) & 75.6 (6.0) & 65.1 (3.6) & 63.0 (2.0) & 57.2 (7.2) & 76.8 (9.5) & 55.2 (2.9) & 9.8 \\  & HIMNET  & 52.1 (3.7) & 56.9 (5.8) & 53.6 (4.6) & 64.3 (3.2) & 67.2 (4.1) & 64.3 (4.3) & 57.5 (2.9) & 63.6 (7.0) & 69.5 (7.2) & 68.5 (2.8) & 12.3 \\  & SIGNET  & 64.2 (9.3) & 56.4 (8.4) & 63.1 (9.0) & 97.2 (1.6) & **70.4** (4.0) & 48.2 (4.8) & 67.5 (1.6) & 40.2 (5.8) & 66.6 (9.5) & 56.2 (4.3) & 10.4 \\   & GraphCL-1  & 64.5 (3.9) & 60.7 (4.2) & 55.8 (1.1) & 71.2 (6.5) & 57.7 (5.5) & 54.2 (5.6) & 52.6 (3.2) & 57.8 (6.7) & 60.5 (9.3) & 55.5 (4.1) & 14.2 \\  & GAE-1  & 64.7 (5.6) & 63.1 (7.3) & 62.5 (2.2) & 86.2 (1.4) & 74.8 (2.3) & 63.8 (7.4) & 63.2 (3.3) & 56.5 (6.8) & 68.5 (1.3) & 60.0 (9.9) & 10.3 \\  & GraphDAE-1  & 56.7 (3.3) & 60.5 (4.9) & 53.2 (9.1) & 98.3 (7.2) & 73.2 (7.7) & 67.0 (5.0) & 62.3 (2.6) & 62.2 (6.2) & 69.6 (7.1) & 70.1 (7.6) & 52.2 (2.0) & 10.6 \\   & GraphCL-2  & 66.1 (3.0) & 59.1 (5.2) & 60.3 (4.0) & 91.8 (5.5) & 73.1 (4.1) & 66.3 (5.6) & 67.4 (3.5) & 59.1 (4.6) & 71.9 (1.0) & 67.3 (3.6) & 7.2 \\  & GAE-2  & 67.2 (3.4) & 62.3 (5.0) & 62.4 (3.9) & 85.8 (6.7) & 75.3 (7.6) & 66.7 (6.3) & 67.3 (3.6) & 60.8 (5.6) & 72.0 (8.5) & 65.7 (2.0) & 7.0 \\  & GraphMAE-2  & 68.0 (4.3) & 61.2 (4.0) & 68.3 (2.3) & 69.0 (3.6) & 75.8 (4.6) & 66.7 (3.8) & 63.8 (3.1) & 61.4 (6.0) & 72.8 (6.9) & 66.2 (4.6) & 54.1 \\   & MuSE w/o \(\)\(\)2.8 & **79.4**(3) & **75.6**(2) & **69.2** & **79.9**(6) & **79.6**(8) & 72.2 (6.9) & 65.8 (5.7) & 63.0 (4.0) & 66.6 (9.6) & 63.3 (6.8) & 5.8 \\  & MuSE w/o La & 61.8 (6.6) & 64.7 (7.1) & 63.1 (3.1) & 89.3 (2.8) & 72.0 (4.8) & 56.9 (7.1) & 57.0 (3.5) & 58.1 (1.0) & 68.7 (1.2) & 67.0 (4.0) & 11.0 \\   & MuSE w/o AVG & 78.6 (4.0) & 68.1 (5.8) & 68.0 (2.0) & 95.0 (2.6) & 73.2 (6.6) & 66.2 (6.5) & 60.9 (3.9) & 60.1 (2.4) & 66.3 (13.0) & 62.0 (3.5) & 7.7 \\   & MuSE w/o STD & 74.3 (5.4) & 74.4 (5.2) & 65.2 (6.9) & 98.7 (5.7) & 70.5 (4.3) & 70.7 (6.2) & 62.0 (2.4) & 62.9 (6.4) & 71.3 (11.9) & 66.7 (7.2) & 5.6 \\  _{}\) and \(_{}\), and (2) multiple aggregation functions (specifically, mean and standard deviation). To this end, we leverage the following four variants of MuSE:

1. MuSE w/o \(_{}\): A variant that only leverages adjacency matrix reconstruction,
2. MuSE w/o \(_{}\): A variant that only leverages node feature reconstruction,
3. MuSE w/o STD: A variant that only leverages mean aggregation,
4. MuSE w/o AVG: A variant that only leverages standard-deviation aggregation.

As shown in Table 1, MuSE with all components outperforms all of its variants in 8 out of 10 datasets, justifying the design choice of MuSE.

## 7 Discussions

In this work, we report and analyze an intriguing phenomenon, _reconstruction flip_ of graph autoencoders (Graph-AEs). We investigate the phenomenon theoretically and empirically (Section 3) and further claim their implication in graph-level anomaly detection (GLAD; Section 4). Based on our analysis, we propose a novel GLAD method, MuSE (Section 5), and report its superior performance in GLAD via extensive experiments (Section 6). Below, we conclude the paper by discussing some potential limitations of our research, which could be addressed in future work.

**More diverse and general primary patterns.** In our analysis, we focus on the two patterns: _community structures_ and _a node cycle_ (Section 3). Although our claims hold for these patterns, a wide range of graph patterns remains unexplored in this work. Furthermore, a unified framework that can incorporate various graph patterns into a single pattern may exist. Further investigation into these patterns may improve our analysis, leading to new potential applications.

**Scalability improvement.** Since MuSE reconstructs the entire adjacency matrix of a graph (Eq. (3)), its time complexity for reconstruction is \(O(n^{2})\), where \(n\) is the number of nodes in the graph. While this complexity is manageable for many real-world graph-level datasets (refer to Table 2), leveraging MuSE for large-scale graphs can be challenging. A simple technique that reconstructs only a sampled subset of an adjacency matrix results in a performance drop (refer to Appendix E.5). Therefore, improving the scalability of MuSE while preserving its detection performance is a non-trivial task, making it a promising direction for future research.

Figure 6: Comparison of the three strongest GLAD methods’ robustness against training set contamination. MuSE undergoes the least performance drop among the three methods.

Figure 7: PCA visualization of MuSE’s error representations of graphs. Graphs belonging to different classes are well-separated in the representation space.

**Acknowledgements.** This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. RS-2024-00406985) (90%). This work was supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. RS-2019-II190075, Artificial Intelligence Graduate School Program (KAIST)) (10%).