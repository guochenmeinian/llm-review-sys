# Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness

Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness

Yiquan Li\({}^{1}\)1 Zhongzhu Chen\({}^{2}\)1 Kun Jin\({}^{2*}\) Jiongxiao Wang\({}^{1}\)1 Jiachen Lei\({}^{3}\)

Bo Li\({}^{4}\) Chaowei Xiao\({}^{1}\)

\({}^{1}\)University of Wisconsin-Madison; \({}^{2}\) University of Michigan-Ann Arbor;

\({}^{3}\)California Institute of Technology ;\({}^{4}\)University of Illinois Urbana-Champaign

###### Abstract

Diffusion Purification, purifying noised images with diffusion models, has been widely used for enhancing certified robustness via randomized smoothing. However, existing frameworks often grapple with the balance between efficiency and effectiveness. While the Denoising Diffusion Probabilistic Model (DDPM) offers an efficient single-step purification, it falls short in ensuring purified images reside on the data manifold. Conversely, the Stochastic Diffusion Model effectively places purified images on the data manifold but demands solving cumbersome stochastic differential equations, while its derivative, the Probability Flow Ordinary Differential Equation (PF-ODE), though solving simpler ordinary differential equations, still requires multiple computational steps. In this work, we demonstrated that an ideal purification pipeline should generate the purified images on the data manifold that are as much semantically aligned to the original images for effectiveness in one step for efficiency. Therefore, we introduced Consistency Purification, an efficiency-effectiveness Pareto superior purifier compared to the previous work. Consistency Purification employs the consistency model, a one-step generative model distilled from PF-ODE, thus can generate on-manifold purified images with a single network evaluation. However, the consistency model is designed not for purification thus it does not inherently ensure semantic alignment between purified and original images. To resolve this issue, we further refine it through Consistency Fine-tuning with LPIPS loss, which enables more aligned semantic meaning while keeping the purified images on data manifold. Our comprehensive experiments demonstrate that our Consistency Purification framework achieves state-of-the-art certified robustness and efficiency compared to baseline methods.

## 1 Introduction

Diffusion models were first proposed for high-quality image generation [1; 2; 3; 4; 5] and have been extended to generative tasks across various modalities, including audio [6; 7; 8], video [9; 10], and 3D object [11; 12; 13]. A diffusion model for image generation typically involves two key processes: (1) a forward diffusion process, which transforms the source image into an isotropic Gaussian by gradually adding Gaussian noise, and (2) the reverse diffusion process, which uses a Deep Neural Network (DNN) to perform iterative denoising starting from random Gaussian noise.

Due to the inherent denoising capability of diffusion models, there have been widely applied to improve the robustness of DNNs. This enhancement is achieved by Diffusion Purification [14; 15; 16; 17; 18], which purifies the network inputs to reduce the effects of various types of unforeseen corruptions or adversarial attacks. Among these, one particularly suitable and effective scenario of purification is to improve certified robustness through randomized smoothing  for image classification tasks. This method guarantees a tight robustness in the \(_{2}\) norm with a smoothed classifier. However, many previous works [19; 20; 21; 22; 23; 24] have shown that it still requires retraining with Gaussian augmented examples for each noise level to optimize the smoothed classifier. Diffusion models, capable of purifying Gaussian perturbed images before classification, can be seamlessly integrated with any base classifier to produce a smoothed classifier for arbitrary noise levels. This integration has been demonstrated to effectively enhance certified robustness, as supported by numerous studies [18; 25; 26; 27].

However, current diffusion purification for certified robustness via randomized smoothing still faces significant trade-offs between _efficiency_ and _effectiveness_. Although Denoising Diffusion Probabilistic Model (DDPM)  only requires one single network evaluation in the purification process , it generates the mean of the posterior data distribution conditioned the noisy sample, which does not necessarily locate on the data manifold and may exhibit ambiguity during classification. To further improve diffusion purification, various methods such as DensePure , Local Smoothing  and Noised Diffusion Classifiers  are applied. However, these methods are considerably less efficient as they require multiple times of the computational costs compared to one-step DDPM. Another promising approach involves using the Probability Flow Ordinary Differential Equation (PF-ODE) . It has offered a method to accelerate the sampling process  and achieved a closer distribution to the original data, well balancing efficiency and effectiveness. However, several computational steps are still needed to solve the ODE numerically.

To find a Pareto superior solution in terms of efficiency and effectiveness, we introduce a new framework, **Consistency Purification**, which integrating consistency models into diffusion purification with **Consistency Fine-tuning**. The consistency model is a novel category of diffusion models that learns the trajectory of the PF-ODE that transits the data distribution to the noisy distribution. It is trained to map any point along this trajectory back to its starting point. This property is desirable for diffusion purification, as it allows images with any scale of Gaussian noise to be directly purified to the clean images. Distilled from a pre-trained diffusion model by simulating the PF-ODE trajectory, the consistency model can generate high-quality in-distribution images in a single step, thereby ensuring both efficiency and effectiveness. However, since consistency models are primarily trained for image generation, it may not suffice to guarantee that the purified image that maintains the same semantic meaning as the original image. To address this issue, we propose adding a Consistency Fine-tuning step into the purification framework, which further fine-tunes the consistency model using Learned Perceptual Image Patch Similarity (LPIPS)  loss, aiming to minimize the perceptual differences between the purified and original images, thereby ensuring better semantic alignment, while at the same time, ensuring the purified images still lie on the data manifold.

We show that Consistency Purification is Pareto superior compared to baselines from two aspects. First of all, compared with effective methods like DensePure , Local Smoothing  and Noised Diffusion Classifiers , Consistency Purification is much more efficient since it enables single-step purification. Secondly, compared with efficient method like onestep-DDPM , we provide both

Figure 1: An illustration of Consistency Purification framework.

theoretical analysis and experiment results to support the effectiveness improvement of Consistency Purification. In Example 3.1, we show an one-dimensional example demonstrating that consistency model can generate on-manifold purified samples while onestep-DDPM does not have this property.

In Theorem 3.3, we show an important theoretical result that given a purifier, the lower the transport from the original distribution to the purified distribution (a measure of distance between probability distributions, see ), the higher the probability that the purified sample is sufficiently close to the original sample, and thus the better purification outcomes. Our experiment results verify that both the integration of consistency model in Consistency Purification and the further Consistency Fine-tuning decreases such transport and achieves better semantic alignment between purified samples and original samples.

Beyond the validation of our theory, we conduct comprehensive experiments to demonstrate the empirical improvements of Consistency Purification. Compared to various baseline settings, our approach has shown significant improvements, achieving an average 5% gain in performance over the previous onestep-DDPM under the same cost with single-step purification. These observations underscore our success in finding a Pareto superior diffusion purification framework in both efficiency and effectiveness for certified robustness.

## 2 Backgrounds

**Randomized Smoothing .** Randomized smoothing is designed to certify the robustness of a given classifier under \(_{2}\) norm perturbations. Given a base classifier \(f\) and an input \(\), randomized smoothing first defines the smoothed classifier by \(g()=*{arg\,max}_{c}_{(,^{2})}(f(+)=c),\) where \(\) is the noise level, which controls the trade-off between robustness and accuracy.  shows that \(g()\) induces the certifiable robustness for \(\) under the \(_{2}\) norm with radius \(R\), where \(R=(^{-1}(p_{A})-^{-1}(p_{B})),\) where \(p_{A}\) and \(p_{B}\) are the probability of the most probable class and "runner-up" class respectively; \(\) is the inverse of the standard Gaussian CDF. The \(p_{A}\) and \(p_{B}\) can be estimated with arbitrarily high confidence via the Monte Carlo method.

**Continuous-Time Diffusion Model .** The diffusion model has two components: the _diffusion process_ followed by the _reverse process_. Given an input random variable \(_{0} p\), the diffusion process adds isotropic Gaussian noises to the data so that the diffused random variable at time \(t\) is \(_{t}=}(_{0}+_{t})\), s.t., \(_{t}(,_{t}^{2})\), and \(_{t}^{2}=(1-_{t})/_{t}\), and we denote \(_{t} p_{t}\). The forward diffusion process can also be defined by the stochastic differential equation

\[=D(,t)t+G(t),\] (SDE)

where \(_{0} p\), \(D:^{d}^{d}\) is the drift coefficient and typically has the form \(D(,t)=D(t)\). \(G:\) is the diffusion coefficient, \(t\) is an infinitesimal time step, and \((t)^{n}\) is the standard Wiener process.

The reverse process exists and removes the added noise by solving the reverse-time SDE 

\[=[D(t)-G(t)^{2}_{} p_{t}() ]t+G(t)},\] (reverse-SDE)

where \(p_{t}()\) denotes the marginal distribution at time \(t\), and \(}(t)\) is a reverse-time standard Wiener process.  defined the probability flow ODE (PF ODE) which has the same marginal distribution as reverse-SDE but can be solved much faster

\[=[D(t)-G(t)^{2}_{} p_{t }()]t.\] (PF-ODE)

As shown in , the perturbation kernel of SDE has the general form

\[p_{0t}((t)(0))=((t);s(t)(0),s(t)^ {2}(t)^{2})\] (perturbation-kernel)

where \(s(t)=(_{0}^{t}f())\) and \((t)=^{t}}{s()^{2}}\ }\). Under this formulation, PF-ODE can written as

\[=[-s(t)^{2}(t)( t)_{} p(}{s(t)};(t))]t\]

where \(\) denotes the time derivative and \(p(}{s(t)};(t))\) denotes the marginal distribution at time \(t\). In our context, we use the _EDM_ parameter  where \(s(t)=1\) and \((t)=t\) which gives us a probability flow ODE

\[=-t_{} p_{t}()t.\] (EDM-ODE)We use \(\{_{t}\}_{t}\) and \(\{}_{t}\}_{t}\) to denote the diffusion process and the reverse process generated by SDE and reverse-SDE respectively, which follow the same distribution. We also use \(\{}_{t}\}_{t}\) to denote the reverse process generated by PF-ODE, which has the same marginal distribution as \(\{_{t}\}_{t}\) and \(\{}_{t}\}_{t}\) given \(t\).

**Discrete-Time Diffusion Model (DDPM ).** DDPM constructs a discrete Markov chain \(\{_{0},_{1},,_{i},,_{N}\}\) as the forward process for the training data \(_{0} p\), such that \((_{i}|_{i-1})=(_{i};} _{i-1},_{i}I)\), where \(0<_{1}<_{2}<<_{N}<1\) are predefined noise scales such that \(_{N}\) approximates the Gaussian white noise. Denote \(_{i}=_{i=1}^{N}(1-_{i})\), we have \((_{i}|_{0})=(_{i};_{i}}_{0},(1-_{i}))\), i.e., \(_{t}(_{0},)=_{i}}_{0}+(1- _{i}),(,)\). The reverse process of DDPM learns a reverse direction variational Markov chain \(p_{}(_{i-1}|_{i})=(_{i-1};_{ }(_{i},i),_{}(_{i},i))\).  defines \(}\) as a function approximator to predict \(\) from \(_{i}\) such that \(}(_{i},i)=}}(_{i}- }{_{i}}}}( _{i},i))\). Then the reverse time samples are generated by \(}_{i-1}=}}(}_{i}-}{_{i}}}}(} _{i},i))+},(,I)\), and the optimal parameters \(^{*}\) are obtained by solving \(^{*}:=_{_{0},}[\| -}(_{i}}_{0}+( 1-_{i}),i)\|_{2}^{2}]\).  also provided a one-step approximate reconstruction of \(_{0}\) from any \(_{t}\),

\[_{0}}_{0}=(_{t}-_ {t}}_{}(_{t}))/_{t}}.\] (onestep-DDPM)

**Consistency Model **. Given a solution trajectory of PF-ODE, the consistency model is defined as \(D:(_{t},t)_{t}\). The model exhibits the property of self-consistency, ensuring that its outputs are consistent for arbitrary pairs of \((_{t},t)\) from the same PF-ODE trajectory; specifically, \(D(_{t},t)=D(_{t^{}},t^{})\) for all \(t,t^{}[,T]\). As shown by the definition, consistency models are suitable for one-shot denoising, allowing for the recovery of \(_{t}\) from any noisy input \(_{t}\) in one network evaluation. Two distinct training strategies can be employed for training the consistency models: distillation mode and isolation mode. The primary distinction lies in whether the models distill the knowledge from pre-trained diffusion models or train from initial parameters. According to the experiments reported in , consistency models trained in the distillation mode have been shown to outperform those trained in isolation mode for generating high-quality images. Consequently, our paper only considers consistency models trained in the distillation mode.

## 3 Theoretical Analysis

In this section, we provide theoretical explanations on the advantages of Consistency Purification, with a focus on its purification performance improvement in terms of certified robustness over .

As demonstrated in , PF-ODE maintains the marginal distribution of reverse-SDE, thereby establishing a deterministic mapping between the noisy distribution \(_{t}\) and the data distribution \(_{0}\). In other words, PF-ODE guarantees that the purified sample lies on the data manifold, unlike onestep-DDPM, which lacks this assurance. We present here a simple one dimensional example for illustration.

**Example 3.1**.: _Consider a one-dimensional space with a data set consisting of two samples \(\{_{1},_{2}\}\), where \(_{1}=1\) and \(_{2}=-1\). The distribution can be represented as a mixture of Dirac delta distributions: \(p_{}()=((-_{1})+(-_{2}))\). By setting \(s(t)=1\) and \((t)=t\) in perturbation-kernel, the distribution at time \(t\) becomes: \(p_{t}()=}e^{-(-1 }{t})^{2}}+e^{-(+1}{t})^{2}}\). Then_

\[ p_{t}()}{} =-1}{t})e^{-(-1}{t})^{2}}-+1)}{2tp_{t}()}e^{-(+1}{t})^{2}}}{2tp_{t}( {x})}\] \[= -}{t^{2}}+(-1}{t })^{2}}-e^{-(+1}{t})^{2}}}{e^{-(-1}{t})^{2}}+e^{-(+1}{t })^{2}}}.\]

_From the derivative formula \( p_{t}()}{}\), it's evident that \(=0\) is an equilibrium point, and the right-hand side expression is Lipschitz continuous around \(=0\) by L'Hopital's rule. Thus, according to the Picard-Lindelof theorem, any trajectory starting on either side of \(=0\) will not cross this point. As PF-ODE drives \(p_{t}()\) closer to the Dirac delta distribution \(p_{}()\) as \(t\) approaches zero, any initial point on positive/negative side of \(=0\) will eventually approach \(1\) or \(-1\), i.e., the data manifold. Furthermore, in this example, PF-ODE generates not only a purified sample on the data manifold but also closest to the noisy sample. This property is desirable as it establishes a relatively large "robust" neighborhood around each true data point, which implies high certified robustness and a significant certified radius, which will be further discussed later. With the consistency model, we do not need to solve the ODE but rather directly map the noisy sample to either \(1/-1\) depending on its location relative to \(=0\)._

_For comparison, given any \(\) and \(t\), the onestep-DDPM will output a posterior mean that is_

\[(-1}{t})^{2}}-e^{- (+1}{t})^{2}}}{e^{-(-1}{t} )^{2}}+e^{-(+1}{t})^{2}}}=}{2}}-1}{e^{}{2}}+1}.\]

_The posterior mean will be near \(1\) or \(-1\) only when \(t\) is sufficiently small compared to \(\|\|\). Otherwise, it deviates from the data manifold. In the case when \(t\) is large, the posterior mean will be close to zero, locating in an ambiguous classification region. In adversarial purification , we typically select \(t\) based on the variance of the noise added to the data sample rather than using an very small \(t\). This practice helps avoid significant deviations in the posterior mean estimation due to the imperfect estimation of score/noise. With a very small \(t\), even a slight bias in score/noise estimation can lead to a substantial deviation, resulting in a denoised sample even farther from the data manifold represented by \(p_{}()\)._

Additionally, PF-ODE is deterministic, eliminating the overhead of majority voting required when using reverse-SDE as a purifier . The consistency model, which reduces ODE solving to a one-step mapping, further ensures purification has the same efficiency as onestep-DDPM while keeping the in-distribution property.

Though the consistency model enjoys both in-distribution property and one-step efficiency, it does not guarantee that the purified sample has the same semantic meaning as the original sample. This is because the derivation of PF-ODE only guarantees a mapping between noisy distribution and data distribution, which is sufficient for generation, but not enough for denoising purposes.

To address this concern, we first delineate the desired characteristics of the purifier. As evidenced in prior works , an ideal purifier should yield a purified output situated within a proximate vicinity of the original input. It is generally presumed that such purified outputs retain the semantic meaning of the original inputs with a high probability. The disparity in semantic consistency between the noisy input and the purified output generated by PF-ODE arises due to the proximity of the purified output to other samples. In this regard, we propose quantifying this disparity through the notion of transport between the data distribution and the purified distribution, derived by introducing Gaussian perturbations to the data distribution and subsequently applying denoising via PF-ODE. Given an original sample \(\), Gaussian noise \(\), and purifier \(d\), the mapping in the transport process is defined as \(T: d(+)\), which is probabilistic. We aim to demonstrate that a diminished transport between the data distribution and the purified distribution is conducive to a higher likelihood of the purified output being situated in proximity to the original sample, thereby preserving its semantic meaning.

We will leverage the following definition.

**Definition 3.2**.: Given the data distribution \(p\), Gaussian noise \(\), timestep \(t\), and a purifier \(d\), we define \(_{t}: d(+t)\) and the "transport" under \(g_{t}\) between the data distribution and purified distribution as \(T_{_{t}}(p):=\|-_{t}()\| p()d\).

Intuitively, transport measures the distance between the original and purified samples, which should be small by an effective purifier. Below, we quantify this intuition and present our main theorem. See the detailed proof in Appendix B.

**Theorem 3.3**.: _Given the transport \(T_{_{t}}(p)\) between the data distribution \(p\) and the corresponding purified distribution under \(g_{t}\), then for any \(r>0\), the probability that the distance between the original sample \(\) and purified sample \(}=_{t}()\) is larger than \(r\) is upper bounded by \(}(p)}{r}\)._

_Remark 3.4_.: By Theorem 3.3, the efficacy of the purifier hinges on two crucial factors: the transport \(T_{_{t}}(p)\) and the radius \(r\). A theoretically perfect purifier would yield zero transport; however, this is unattainable due to the inherent randomness of \(g_{t}\). Typically, we can optimize the parameter \(t\) to minimize the transport, denoted as \(T^{*}=_{t}}(p)}{r}\). In the context of classification tasks, the selection of \(r\) also depends on the robustness of the classifier; a more robust classifier allows a larger \(r\) to be chosen, thereby guarantee better purification efficacy.

For ensuring consistency in semantic meaning between the original and purified samples, it is insufficient merely to minimize their distance; it is also necessary that the purified sample resides on the data manifold, which is the in-distribution property we previously mentioned. To concurrently achieve both objectives, rather than solely focusing on minimizing the Euclidean distance between the original and purified samples, we opt to minimize the Learned Perceptual Image Patch Similarity (LPIPS) loss between them. This strategy aids in mitigating the risk of the purified sample deviating from the data manifold, thereby preserving semantic meaning. In Table 1, we show that using LPIPS is better than \(_{1}\) and \(_{2}\) loss for Consistency Fine-tuning when we want to guarantee the generated images are in-distribution, where lower FID scores indicate better in-distribution properties.

Figure 2 validates the effectiveness of Consistency Purification based on our results in Theorem 3.3, it shows that both the integration of consistency model in Consistency Purification and the further Consistency Fine-tuning can decrease the transport from the original distribution to the purified distribution. Specifically, we can see that Consistency Purification achieves a lower average distance from the purified sample to the original sample compared with onestep-DDPM, and Consistency Fine-tuning further decreases this average distance, indicating both components result in a lower transport and thus a better semantic alignment between purified samples and original samples.

## 4 Method

We propose our framework, Consistency Purification, with a further improved version using Consistency Fine-tuning.

### Consistency Purification

We introduce Consistency Purification, directly applying consistency model as a purifier to integrate with a base classifier into smoothed classifier for randomized smoothing.

Following Diffusion Denoised Smoothing outlined in , it is necessary to establish a mapping between Gaussian noise augmented images required by randomized smoothing and the noised image in the ODE trajectory of consistency model. For a given consistency model purifier \(D_{}\), any noisy input \(_{t}(,t^{2})\) can be recovered to the trajectory's start \(_{e}\) by directly passing it through the model with time \(t\): \(_{e}=D_{}(_{t},t)\).

When comparing this to the image augmented with additive Gaussian noise \(_{rs}(,^{2})\), which is required by randomized smoothing, we observe that \(_{rs}\) and \(_{t}\) share the same formula when \(t=\). However, since the variances \(\{_{i}\}_{i=1}^{m}\) may not be used during the training of the consistency model, we empirically select the nearest time step \(t\) from the discrete time steps used in training for each \(\).

For the entire time horizon \([,T]\) with \(N-1\) sub-interval boundaries \(t_{1}=<t_{2}<<t_{N}=T\), the time steps used in training are computed by: \(t_{i}=(^{1/}+(T^{1/}-^{1/}))^{ },\) where \(=7\).

    &  \\  Loss & 0.25 & 0.5 & 1.0 \\  - & 60.3 & 155.3 & 350.3 \\ \(_{1}\) & 96.8 & 205.7 & 383.6 \\ \(_{2}\) & 102.1 & 214.8 & 375.4 \\ LPIPS & **20.5** & **100.9** & **338.1** \\   

Table 1: FID between purified and clean images on CIFAR-10 test set using different types of fine-tuning loss functions with noise level \(\{0.25,0.5,1.0\}\).

Figure 2: Transport between purified images and clean images with noise level \(\{0.25,0.5,0.75,1.0\}\).

Given the variance \(\) of Gaussian noise used in randomized smoothing, we select the corresponding time step \(t_{}^{*}\) for Consistency Purified Smoothing by \(t_{}^{*}=\{t_{i}|(+t_{i}}{2},+t_{i+1}}{2} ]\}\).

### Consistency Fine-tuning

To optimize the consistency model for aligning semantic meanings during purification, we fine-tune the purifier \(D_{}\) by minimizing the following loss function: \(_{}=\|-D_{}(_{},t_{} ^{*})\|_{}\), where the expectation is taken with \( p_{data}\), \(\{_{i}\}_{i=1}^{m}\), \(_{}(,^{2})\). Here LPIPS denotes the distance computed by the Learned Perceptual Image Patch Similarity . \(p_{data}\) represents the distribution of the training data, from which clean images \(\) are sampled. \(\{_{i}\}_{i=1}^{m}\) denotes the uniform distribution over \(m\) different noise scales \(_{i}\) used for randomized smoothing. Typically, we select the scale set \(_{i}\{0.25,0.5,1.0\}\), which is commonly used to compute the certified radius via randomized smoothing.

After obtaining the fine-tuned consistency model purifier \(D_{^{*}}\),it can replace the original model used in Consistency Purified Smoothing to purify any noised image \(_{rs}\) with Gaussian variance \(_{i}\), resulting in the final purified image \(_{p}\) by \(_{p}=D_{^{*}}(_{rs},t_{_{i}}^{*})\).

We present the detailed algorithm of our Consistency Purification in Appendix A.

## 5 Experiments

In this section, we begin by detailing the experimental settings, followed by our main results. Additionally, we conduct ablation studies to further demonstrate the effectiveness of our framework. All experiments are conducted with 1\(\)NVIDIA RTX A5000 24GB GPU.

### Experimental Settings.

**Dataset.** We evaluate the Consistency Purification framework on both CIFAR-10  and ImageNet-64 . CIFAR-10 contains \(32 32\) pixel images across 10 different categories while ImageNet-64 includes \(64 64\) pixel images across 1000 categories. Due to limited computational resources, we select 500 test images for CIFAR-10 from the 10,000 CIFAR-10 test set, choosing every 20th example in sequence (e.g., the 1st, 21st, 41st, etc.). Similarly, for the ImageNet-64 dataset, we sample 500 test examples from its 50,000 test examples using a fixed interval of 100.

**Consistency Purification.** For CIFAR-10, to demonstrate the effectiveness of Consistency Purification, we first perform purification with a public unconditional consistency model . After that, to further improve the performance, we fine-tune the model with noise levels \(\) sampling from \(\{0.25,0.5,1.0\}\), shown as the (**+ Consistency Fine-tuning**). However, currently there is no publicly available unconditional consistency model checkpoint for the ImageNet dataset that can be used directly for purification purposes. The only available model is the conditional consistency model on ImageNet-64. Thus, here we trained an unconditional consistency model on ImageNet-64, initializing it with the existing conditional consistency model checkpoint. Details of the training process are included in Appendix C. Additionally, we also conduct Consistency Fine-tuning on ImageNet-64 model with noise levels \(\{0.05,0.15,0.25\}\).

**Baselines.** For comparative analysis of CIFAR-10, we conduct baseline experiments under various settings. The first baseline involves onestep-DDPM, where we employ the 50-M unconditional improved diffusion models from  utilizing the one-shot denoising method  for purification. Given that our consistency model is distilled from an EDM model , we include EDM as our baselines, applying both one-shot denoising (onestep-EDM) and ODE solver (PF-ODE EDM) for purification. Additionally, we include the recent advancement in diffusion purification methods, Diffusion Calibration, as a baseline following , which fine-tunes the diffusion model with the guidance of classifier WideResNet28-10 to improve the purification accuracy under the specific classifier. While for ImageNet-64, due to the lack of public unconditional EDM model, we only include the comparison baseline with onestep-DDPM.

**Randomized Smoothing Settings.** We set \(N=10000\) for both CIFAR-10 and ImageNet as the number of sampling times used in randomized smoothing. We compute the certified radius for each test example at three different noise levels \(\{0.25,0.5,1.0\}\) for CIFAR-10 and \(\{0.05,0.15,0.25\}\) for ImageNet-64. Then we calculate the proportion of test examples whose radius exceeds a specific threshold \(\). The highest accuracy among these noise levels is reported as the certified accuracy at \(\).

**Classifiers.** For the classifier used after purification for CIFAR-10, we employ ViT-B/16 model , which is pretrained on ImageNet-21k  and finetuned on CIFAR-10 dataset. In our ablation studies, we also use ResNet  and WideResNet  trained on CIFAR-10. For ImageNet-64, we make up-sampling on the 64\(\)64 images and directly apply ViT-B/16 as the classifier.

### Main Results.

We present the certified accuracy of Consistency Purification for both CIFAR-10 and ImageNet-64 dataset, with the results presented in Table 2. We also include the purification steps which decide whether the purifier needs multiple evaluation times through the networks (Multi Steps) other than a single network evaluation (One Step). As observed from Table 2, Consistency Purification significantly outperforms onestep-DDPM for both CIFAR-10 and ImageNet-64 with even higher certified accuracy with Consistency Fine-tuning. Besides, for CIFAR-10, the results also suggest the effectiveness of Consistency Purification with Consistency Fine-tuning when compared with more baseline methods such as onestep-EDM, PF-ODE EDM and Diffusion Calibration. For the detailed certified accuracy evaluation of fine-grained \(\) at different noise levels \(\), we present the results in Figure 3 compared with the onestep-DDPM setting. All results have demonstrated that Consistency Purification is able to certify robustness with both efficiency and effectiveness.

    &  \\  Method & Purification Steps & 0.0 & 0.25 & 0.5 & 0.75 & 1.0 \\  onestep-DDPM & One Step & 87.6 & 73.6 & 55.6 & 39.2 & 29.6 \\ onestep-EDM & One Step & 87.4 & 76.2 & 58.8 & 40.8 & 32.4 \\ PF-ODE EDM & Multi Steps & 89.6 & 77.0 & 60.4 & 42.6 & 34.0 \\ Diffusion Calibration & One Step & 90.2 & 76.4 & 57.2 & 42.6 & 32.4 \\  Consistency Purification & One Step & **90.4** & 77.2 & 59.8 & 42.8 & 33.2 \\ **+ Consistency Fine-tuning** & One Step & 90.2 & **79.4** & **62.4** & **43.8** & **35.4** \\    &  \\  Method & Purification Steps & 0.0 & 0.05 & 0.15 & 0.25 & 0.35 \\  onestep-DDPM  & One Step & 55.2 & 44.8 & 33.4 & 15.2 & 8.8 \\ Consistency Purification & One Step & 62.4 & 54.2 & 35.2 & 19.8 & 13.0 \\ **+ Consistency Fine-tuning** & One Step & **68.6** & **58.0** & **37.4** & **23.4** & **17.4** \\   

Table 2: Certified Accuracy of Consistency Purification for CIFAR-10 and ImageNet-64.

Figure 3: Certified Accuracy of Consistency Purification with fine-grained radius \(\). The left figure shows results on CIFAR-10, the right figure shows results on ImageNet-64. The lines demonstrate the certified accuracy of various radius \(\) under different Gaussian noise levels \(\).

To better illustrate the significant improvement in certified robustness brought by Consistency Purification, we present visualizations of images after diffusion purification in Figure 4 for CIFAR-10 at a noise level of \(=0.5\), compared with the onestep-DDPM approach. As shown, our method produces significantly higher-quality purified images than onestep-DDPM. Furthermore, these purified images achieve a notably higher classification accuracy when evaluated by the same classifier. Additional visualization examples for ImageNet-64 are included in Appendix D.

### Ablation Studies.

We conduct various ablation studies to evaluate the effectiveness of our proposed method.

**Comparison with Non-Diffusion-based Baselines.** To compare Consistency Purification with various non-diffusion-based approaches, we conducted additional experiments to compute the certified accuracy under three non-diffusion-based methods [19; 22; 42].  first proposed training a classifier with noisy images to ensure certified robustness. Subsequent works [42; 22] build on 's methodology, attempting to enhance the smoothed classifier by adding prediction consistency regularization, or incorporating per-sample bias. The experimental results presented in Tabel 3 show that our method surpasses all previous non-diffusion-based methods in achieving higher certified accuracy, particularly with a significantly high clean performance at \(=0.0\). Furthermore, in contrast to non-diffusion-based methods, which incur significant costs by requiring additional fine-tuning of robust classifiers for each specific noise level, our method can be applied directly to any off-the-shelf classifiers, significantly broadening its practical applications.

**Fine-tuning Loss Functions.** To further demonstrate that LPIPS loss is the best choice considering both on-manifold purification and semantic meaning alignment, we assess the certified accuracy of Consistency Purification using different loss functions during Consistency Fine-tuning. Instead of LPIPS distance between the clean and purified images as the loss function, we experiment with \(_{1}\) and \(_{2}\) distances. Results in Table 4 indicate that Consistency Purification with LPIPS loss achieves the highest Certified Accuracy. In contrast, fine-tuning with \(_{1}\) and \(_{2}\) distances compromises the purification performance for certification. This demonstrates that fine-tuning with LPIPS loss function effectively aligns semantic meanings, whereas \(_{1}\) or \(_{2}\) distances may hurt them.

**Noise Levels Sampling Schedules during Consistency Fine-tuning.** In our experiments of Consistency Fine-tuning, we simply select the same sampling schedules of noise levels \(\{0.25,0.5,1.0\}\), uniformly sampling \(\) used in randomized smoothing. To empirically demonstrate its effectiveness, we compare this approach with continuous sampling schedules where \(\). Results presented in Table 5 show that our discrete sampling schedule achieves higher certified accuracy. This indicates that fine-tuning with a discrete scale, aligned with the noise levels used in randomized smoothing, enhances certified robustness.

Figure 4: Visualization of purified images after the diffusion purification by applying onestep-DDPM and Consistency Purification on CIFAR-10 with \(=0.5\) noise level. Identical noise patterns are applied to images at corresponding locations. A green border indicates that the purified image is correctly classified, while a red border denotes misclassification by the classifier.

    &  \\  Methods & 0.0 & 0.25 & 0.5 & 0.75 & 1.0 \\  Randomized Smoothing  & 74.8 & 59.2 & 42.0 & 31.8 & 22.0 \\ Consistency Regularization  & 74.4 & 66.0 & 56.2 & 41.4 & 32.8 \\ Aces  & 74.6 & 66.4 & 57.0 & 43.6 & 32.8 \\ Consistency Purification & **90.4** & 77.2 & 59.8 & 42.8 & 33.2 \\
**+ Consistency Fine-tuning** & 90.2 & **79.4** & **62.4** & **43.8** & **35.4** \\   

Table 3: Certified Accuracy of Consistency Purification compared with non-diffusion-based baseline methods.

**Generalizability with Different Classifiers.** We compute certified accuracy with various classifiers to test if our framework maintains its effectiveness with arbitrary classifiers. The results, presented in Table 6, compare Consistency Fine-tuning with Diffusion Calibration, an alternative method to fine-tune diffusion models for improving the certified robustness. When evaluated across different classifiers, including ViT-B/16, ResNet56, and WideNet28-10, our method outperforms Diffusion Calibration except certified accuracy at \(=0.0\) on WRN28-10 model. It is worth noting that the Diffusion Calibration, which requires a specific classifier for guidance during fine-tuning, exhibits limitations, only achieving comparable performance with the guidance classifier WRN28-10. This demonstrates the advantages of Consistency Fine-tuning in generalizing across different classifiers.

**Fine-tuning Classifier vs. Fine-tuning Diffusion Model.** A potential concern with Consistency Fine-tuning is the higher certified accuracy and lower training cost associated with Fine-tuning the Classifier (CLS-FT) compared to our approach of Fine-tuning the Diffusion Model (DM-FT). However, our experiments, as shown in Table 7, indicate that DM-FT does not conflict with CLS-FT; rather, combining these two methods achieves even higher certified accuracy. On another hand, although CLS-FT yield slightly higher certified accuracy than DM-FT, its requirement for fine-tuning a specific classifier compromises the natural property of diffusion purification frameworks with arbitrary off-the-shelf classifiers, thus limiting the practical applicability.

## 6 Conclusion

In this paper, we introduced Consistency Purification, a novel framework proposed to enhance certified robustness via randomized smoothing. By incorporating consistency models into diffusion purification approach and further refining them through Consistency Fine-tuning, our empirical experiments have demonstrate the framework's ability to achieve high certified robustness efficiently with one single network evaluation for purification.

**Limitations.** A notable limitation of our study is that our empirical results do not include computing certified robustness of high-resolution images such as ImageNet 256\(\)256. This constraint is due to the absence of publicly available checkpoints for the consistency model at this resolution. Additionally, training a consistency model for ImageNet 256\(\)256 would require huge computing resources, which are currently beyond our affordability. However, our framework is designed for adaptability and could be easily extended to ImageNet 256\(\)256 once these checkpoints become available. As a result, our empirical evaluations in this paper are limited to the CIFAR-10 and ImageNet 64\(\)64 datasets.

    &  \\  Method & Classifier & 0.0 & 0.25 & 0.5 & 0.75 & 1.0 \\   & VIT-B/16 & 90.2 & 76.4 & 57.2 & 42.6 & 32.4 \\  & WRN28-10 & **88.2** & 76.4 & 59.2 & 42.0 & 31.8 \\  & ResNet56 & 86.0 & 72.8 & 52.6 & 35.2 & 25.8 \\   & VIT-B/16 & 90.2 & **79.4** & **62.4** & **43.8** & **35.4** \\  & WRN28-10 & 88.0 & **76.4** & **59.8** & **42.2** & **33.0** \\  & ResNet56 & **87.2** & **74.8** & **57.6** & **38.2** & **30.2** \\   

Table 6: Certified Accuracy of Consistency Fine-tuning with different classifiers on CIFAR-10. The guidance classifier used in Diffusion Calibration is WideResNet28-10.