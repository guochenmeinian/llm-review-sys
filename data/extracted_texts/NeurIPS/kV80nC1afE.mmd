# Adaptive Passive-Aggressive Framework for Online Regression with Side Information

Runhao Shi, Jiaxi Ying, Daniel P. Palomar

The Hong Kong University of Science and Technology

{rshiaf, jx.ying}@connect.ust.hk, palomar@ust.hk

###### Abstract

The Passive-Aggressive (PA) method is widely used in online regression problems for handling large-scale streaming data, typically updating model parameters in a passive-aggressive manner based on whether the error exceeds a predefined threshold. However, this approach struggles with determining optimal thresholds and adapting to complex scenarios with side information, where tracking accuracy is not the sole metric in the regression model. To address these challenges, we introduce a novel adaptive framework that allows finer adjustments to the weight vector in PA using side information. This framework adaptively selects the threshold parameter in PA, theoretically ensuring convergence to the optimal setting. Additionally, we present an efficient implementation of our algorithm that significantly reduces computational complexity. Numerical experiments show that our model achieves outstanding performance associated with the side information while maintaining low tracking error, demonstrating marked improvements over traditional PA methods across various scenarios.

## 1 Introduction

Online learning techniques, initially introduced by Zinkevich (2003), have gained significant popularity due to their robustness in adversarial environments and efficiency in processing large streaming data (Shalev-Shwartz et al., 2012; Orabona, 2019; Hazan, 2022). In the online learning framework, an online player continuously makes decisions and receives corresponding losses, aiming to minimize regret. Regret, in this context, refers to the worst-case discrepancy in performance compared to the best-fixed decision in hindsight, measuring the overhead of identifying the best-fixed decision.

These techniques have found widespread application in modeling regression problems for streaming data, enabling practical applications across various fields (Herbster, 2001; Crammer et al., 2006; Shalev-Shwartz and Ben-David, 2014). They are extensively applied in diverse domains such as portfolio selection (Li et al., 2012; Li and Hoi, 2012), malicious URL detection (Ma et al., 2009; Zhao and Hoi, 2013), and time series prediction (Anava et al., 2013, 2015; Hazan et al., 2018; Lale et al., 2020; Tsiamis and Pappas, 2022; Zhang et al., 2024). Without relying on strong assumptions, online regression models demonstrate robustness with regret guarantees in challenging scenarios. Furthermore, their incremental learning schemes make them highly adaptable to streaming data, eliminating the need to retrain the entire dataset and resulting in significant efficiency advantages.

One well-known online regression method is the Passive-Aggressive (PA) algorithm (Crammer et al., 2006). PA employs a passive-aggressive updating scheme to learn a weight vector for linear regression problems. It passively maintains the previous weight below a certain threshold and aggressively updates the weight when the loss exceeds the threshold. However, determining an appropriate threshold can be challenging. A small threshold prioritizes real-time tracking accuracy but may lead to overfitting and sensitivity to noise, compromising long-term tracking accuracy. Additionally, the selected weight may impact factors beyond accuracy in practical model performance. Whenadditional metrics and side information are available for evaluating performance, PA may struggle to achieve a more nuanced weight selection.

To address the aforementioned challenges, we propose an Adaptive Passive-Aggressive online regression framework with Side information (APAS) to achieve the following objectives:

* **Novel APAS framework:** We introduce a novel APAS framework that integrates side information into PA to enhance weight evaluation and selection. This framework adaptively selects the threshold parameter in PA, enabling it to achieve outstanding performance associated with the side information while maintaining a low tracking error.
* **Efficient algorithm:** We develop an efficient algorithm using the successive convex approximation (SCA, Scutari et al., 2013) to accelerate the computation of APAS. This algorithm rapidly converges to the optimal point, allowing flexibility in selecting measurements to integrate side information.
* **Regret bound:** We derive an \(O()\) regret bound for our APAS framework for non-convex loss functions, ensuring the robustness and effectiveness of APAS theoretically. This regret bound matches the optimal regret bound for non-convex loss functions.
* **Extensive experiments:** We conduct an enhanced index tracking task on both synthetic and real financial datasets to validate the effectiveness and efficiency of APAS, which demonstrates the impressive performance of APAS in achieving high returns while maintaining small tracking errors.

**Notation:** Matrices and vectors are represented by bold letters. \([T]\) denotes the set \(\{1,2,,T\}\). The weight vector at time \(t\) is denoted by \(_{t}\). The instance and target in an online regression problem are denoted by \(_{t}^{N}\) and \(y_{t}\), respectively. The proximal operator and Moreau envelope associated with \( h\) are denoted as \(_{ h}\) and \(M_{ h}\), respectively. The Euclidean projection of vector \(^{N}\) onto the set \(\) is denoted by \(_{}()=_{}\| -\|_{2}^{2}\). For a continuous function \(f(x)\), the set of subderivatives at point \(a\) is denoted as \( f(a)\). The left derivative at \(a\) is denoted by \(_{-}f(a)=_{x a^{-}}\). The derivative at point \(a\), if it exists, is denoted as \(f^{}(a)\).

## 2 Preliminaries

### Online Learning

Online learning is a mathematical framework designed to address optimization problems where objective functions change over time. In this context, an online learner sequentially makes decisions \(b_{t}\) based on historical loss and receives a new loss \(f_{t}(b_{t})\) after making the decision. The performance of an online learning algorithm is evaluated using the concept of regret \(R_{T}\), which quantifies the discrepancy between the algorithm's performance and that of an optimal static parameter setting:

\[R_{T}=_{t=1}^{T}f_{t}(b_{t})-_{b}(_{t=1}^{T}f_ {t}(b)),\]

where \(\) denotes the feasible set. An online learning strategy converges to the optimal static parameter setting if \(R_{T}=o(T)\), indicating the average performance gap diminishes as the number of iterations \(T\) approaches infinity. In the case of convex loss functions, different regularization functions can be employed to achieve various optimal regret bounds, depending on the assumptions about the curve of the loss function (Zinkevich, 2003; Hazan et al., 2007; Hazan and Seshadhri, 2007, 2009). Adaptive regularization methods, which select the regularization term dynamically, have also been proposed and widely adopted in various domains (Duchi et al., 2010, 2011; Van Erven and Koolen, 2016).

### Passive-Aggressive Method

The Passive-Aggressive (PA) method is a popular online algorithm utilized for regression problems involving streaming data (Crammer et al., 2006). In an online regression problem, we receive an instance \(_{t}^{N}\) and predict the target value \(_{t}^{}_{t}\) using the incrementally learned vector \(_{t}\), where the ground truth is \(y_{t}\). PA predicts the next weight vector by solving the following optimization problem:

\[}_{t+1}=^{N}}{}\ \|-_{t}\|_{2}^{2}_{}(;(_{t},y_{t}))=0,\] (1)where \(_{}\) is the \(\)-insensitive hinge loss function defined as follows:

\[_{}(;(,y))=0&| ^{}-y|,\\ |^{}-y|-&.\]

Intuitively, PA performs an aggressive update when the discrepancy between the predicted value and the ground truth exceeds the threshold \(\), and passively maintains the previous weight when the discrepancy is within the threshold \(\). A smaller threshold may prioritize real-time tracking accuracy but could result in overfitting and compromise long-term performance. Therefore, the selection of the threshold \(\) significantly influences the performance. Additionally, relying solely on tracking accuracy without considering side information may limit the method's potential performance.

## 3 Proposed Method

In this section, we present a novel framework that incorporates the side information into PA for evaluating and selecting weight vector \(_{t+1}\) and threshold \(\). This framework adaptively selects select \(\) by balancing real-time tracking accuracy and side performance, achieving performance comparable to the optimal parameter setting, supported by theoretical regret guarantees. Additionally, we propose an efficient method based on the successive convex approximation technique, which significantly reduces time complexity and accelerates computation.

### PAS Framework

In this section, we present a novel Passive-Aggressive with Side information (PAS) framework that considers the trade-off between real-time tracking accuracy and side performance. PAS builds upon two variations of PA, each providing closed-form solutions for a given value of \(\), without imposing any constraints as follows:

\[}_{t+1}()=_{t}&| _{t}^{}_{t}-y_{t}|,\\ _{t}+[y_{t}-_{t}^{}_{ t}]_{t}_{t}&,\] (2)

where

\[_{t}=(|_{t}^{}_{t}-y_ {t}|-)/\|_{t}\|_{2}^{2}&\\ (|_{t}^{}_{t}-y_{t}|- )/(\|_{t}\|_{2}^{2}+)&, \] (3)

and PA-II refers to a robust PA method with an aggressiveness constant \(C\). For the regression problem with constraints, the final weight is determined by performing a projection onto the feasible set \(\):

\[_{t+1}()=}{}\|-}_{t+1}()\|_{2}^{2}.\] (4)

Although Crammer et al. (2006) does not include a projection operation, we demonstrate in Appendix D that PA with lazy projection still achieves a comparable bound to Crammer et al. (2006).

Suppose that at each round \(t\), we have a lower semi-continuous convex function \(h_{t}()\) that quantifies the performance associated with the side information. To leverage this information and enhance the performance of the weight selection, we integrate \(h_{t}()\) into the projection step of the PA method and propose the PAS framework for selecting the next weight vector:

\[_{t+1}()=}{}\,(h_{t}()+\|-}_{t+1} ()\|_{2}^{2})=_{ h_{t}}(}_{t+1}()),\] (5)

where \(_{ h_{t}}\) denotes the proximal operator. In PAS, \(\) serves as the trade-off parameter that quantifies the preference between tracking accuracy and side performance. When \(h_{t}()\) is set as a constant, the PAS model essentially simplifies to the original PA method with lazy projection, as shown in Equation (4). By leveraging the proximal operator, we can explicitly integrate side performance into the weight selection process by modifying \(h_{t}()\).

From another perspective, \(\|-}_{t+1}()\|_{2}^{2}\) can be viewed as a regularization term that passively aligns with the trend of the ground truth. In contrast, \(h_{t}()\) serves as the primary loss measurement, acting as the main driver for aggressively updating the weight vector. To understand how the weight vector \(_{t+1}()\) is selected, we discuss the following two scenarios:* If \(|_{t}^{}_{t}-y_{t}|\), we have \(_{t+1}()=_{}(h_ {t}()+\|-_{t}\|_{2}^{2})\). This implies that we aim to passively maintain the same weight setting as the previous round while aggressively updating the weight to improve side performance for small real-time tracking errors.
* If \(|_{t}^{}_{t}-y_{t}|>\), we have \(_{t+1}()=_{}(h _{t}()+\|-_{t}\|_{2}^{2}- ^{}[y_{t}-_{t }^{}_{t}]_{t}_{t}+)\). This implies that we aim to passively maintain the same weight setting as the previous round while aggressively updating the weight to improve real-time tracking accuracy and side performance for large real-time tracking errors.

This framework ensures that while the selected weight passively follows the general trend of the data through the \(_{2}\)-norm, it actively seeks to improve performance based on the side information, thus achieving a balance between stability and adaptability. Consequently, \(_{t+1}()\) corresponds to the point that defines the infimum of the trade-off between side performance \(h_{t}\) and real-time tracking accuracy. The infimum is essentially the Moreau Envelope (Parikh et al., 2014), which we define as the loss function with respect to \(\):

\[f_{t}()=_{}[h_{t}()+ \|-}_{t+1}()\|_{2}^ {2}]=M_{ h_{t}}(}_{t+1}() ).\] (6)

Here, \(M_{ h_{t}}\) represents the Moreau Envelope of \( h_{t}\) with respect to \(}_{t+1}()\). In this way, we establish a connection between the determined weight vector \(_{t+1}()\) and loss function \(f_{t}()\) with \(\).

### Adaptive PAS

The parameter \(\) is a crucial component in PAS, as it determines the weight selection \(_{t+1}()\) and the performance evaluation \(f_{t}()\). While the trade-off parameter \(\) has an intuitive interpretation, the process of setting \(\) is less straightforward. A smaller threshold \(\) may prioritize real-time tracking accuracy but could lead to overfitting, affecting long-term accuracy and compromising side performance. Conversely, a larger \(\) might stabilize performance but result in underfitting. Hence, our objective is to develop an adaptive algorithm that can dynamically choose the value of \(\) based on the designed loss function \(f_{t}()\). To facilitate the dynamic selection of \(\), we introduce the following assumptions:

**Assumption 1**.: _The feasible domain \(\) of the parameter \(\) is bounded with \(=[,D]\) and \(>0\)._

**Assumption 2**.: _The subderivatives of \(f_{t}()\) is bounded, such that \(_{,t[T]}| f_{t}()| G\)._

Our proposed adaptive parameter updating scheme for \(_{t+1}\) and \(_{t+1}\) is as follows: At each round \(t\), we receive information up to time \(t\) and use it to select the next weight vector \(_{t+1}(_{t})\) with \(_{t}\). Subsequently, we update \(_{t+1}\) based on the loss \(f_{t}(_{t})\). The overall procedure is illustrated in Figure 1. Under Assumptions 1 and 2, the updating rule for \(_{t+1}\) is formulated as follows:

\[_{t+1}=_{}[_{t}-_{t}_{t} (_{t})],\] (7)

Figure 1: Adaptive learning scheme of APAS.

where \(_{}[]=\{\{,\},D\}\), \(_{t}=}{G}\), and \(_{t}=_{}[|_{t}^{}_{t}-y_ {t}|]\). Here, \(_{t}()\) is a modified derivative of \(f_{t}()\), which is defined as follows:

\[_{t}()f_{t}^{}()& <_{t},\\ \{0,_{-}f_{t}(_{t})\}&\] (8)

Since \(}_{t+1}()\) is a continuous piecewise function with respect to \(\), being affine on \(<_{t}\) and constant otherwise, and \(M_{ h_{t}}(}_{t+1}())\) is a strongly convex function, their composition \(f_{t}()\) becomes a piecewise-convex function. Thus, \(f_{t}()\) is differentiable and strongly convex for \(<_{t}\), and constant otherwise. The derivative of \(f_{t}()\) for \(<_{t}\) can be calculated using the chain rule:

\[f_{t}^{}()=}(}_{t+1}())}{}=}(}_{t+1}())}{ }_{t+1}()}}_{t+1}()}{}.\] (9)

The derivative of the Moreau Envelope \(M_{ h_{t}}\) with respect to \(}_{t+1}()\) can be calculated as follows:

\[}(}_{t+1}() )}{}_{t+1}()}= (}_{t+1}()-_{ h_{t}} (}_{t+1}())).\] (10)

To summarize, the overall updating scheme for \(_{t+1}\) and weight vector \(_{t+1}\) is outlined in Algorithm 1. This adaptive mechanism enables the framework to adjust dynamically to changing environments, eliminating the need for a manually set static threshold. Intuitively, the update process for \(\) works as follows: If the real-time tracking error is lower than \(_{t}\) (i.e., \(_{t}_{t}\)), then according to Equation (8), the derivative \(_{t}(_{t}) 0\). Based on the update rule in Equation (7), this suggests that \(_{t}\) is reduced to avoid underestimating the tracking accuracy. Conversely, when the real-time tracking error exceeds \(_{t}\), the update mechanism adjusts \(_{t}\) to strike a balance between minimizing side loss and maintaining tracking accuracy.

```
1:Input: trade-off parameter \(\).
2:Initialize\(_{1}\) and \(_{1}\).
3:for\(t=1,2,,T\)do
4: Calculate \(}_{t+1}(_{t})\) according to Equation (2);
5: Update \(_{t+1}(_{t})=_{ h_{t}}(}_{t+1}(_{t}))\);
6: Update \(_{t+1}\) according to Equation (7);
7:endfor
8:Output:\(_{T+1}(_{T})\). ```

**Algorithm 1** Adaptive Passive-Aggressive Framework with Side Information (APAS)

### Efficient Algorithm

Algorithm 1 requires the calculation of the proximal operator at each iteration (see Line 5), which can be computationally expensive. While this problem can be addressed directly using the Interior Point Method (IPM) with an off-the-shelf solver (Nemirovski, 2004), it generally incurs a high-order time complexity of \(O(N^{3.5})\), making it inefficient for large-scale problems.

To improve efficiency, we propose an algorithm that utilizes the Successive Convex Approximation (SCA) framework to accelerate computation (Scutari et al., 2013). SCA reduces time complexity by iteratively optimizing a more manageable surrogate function in place of the original objective function until convergence is reached (Sun et al., 2016; Scutari and Sun, 2018). We denote the objective function of Problem (5) as \(u_{t}()=h_{t}()+\|-}_{t+1}()\|_{2}^{2}\). To apply SCA, the surrogate function, denoted as \(_{t}(^{k})\), should be strongly convex and satisfy the condition that \(_{t}(^{k}^{k})= u_{t}( ^{k})\), ensuring the gradients match at \(^{k}\).

We employ the first-order Taylor expansion to approximate \(h_{t}()\), defining the surrogate function \(_{t}(^{k})\) as follows:

\[_{t}(^{k})=^{ }-(}_{t+1}( )- h_{t}(^{k}))^{}+\]By simplifying the formulation, we iteratively optimize the following surrogate problem instead:

\[^{N}}{}\|-^{k}\|_{2}^{2},\] (11)

where \(^{k}=}_{t+1}()- h_{t}( ^{k})\). When the feasible set \(\) exhibits special geometric properties, such as being a probability simplex or a hyperplane, the optimization problem in Equation (11) admits a closed-form solution, as provided in Appendix C (Palomar and Fonollosa, 2005; Duchi et al., 2008).

```
1:Input:\(}_{t+1}()\), \(\), and \( h_{t}\).
2:Initialize\(k=1\), \(^{1}\) and \(\{^{k}\}\).
3:repeat:
4: Solve (11) with \(^{k}=}_{t+1}()- h_{t}( ^{k})\) and set the optimal point as \(}^{k+1}\);
5: Compute \(^{k+1}=^{k}+^{k}(}^{k+1}- ^{k})\);
6:\(k k+1\);
7:until convergence
8:Output:\(_{t+1}()=^{k+1}\). ```

**Algorithm 2** Efficient Algorithm for (5)

The overall procedure for efficiently calculating (5) is encapsulated in Algorithm 2. Empirically, this method converges very quickly, reaching the optimal point within only a few iterations. Additionally, it does not require calculating the objective value of \(h_{t}()\), making it more flexible for incorporating side information. By setting \(^{k+1}=^{k}(1-^{k})\) with \((0,1)\) and \(^{0}<1/\), Algorithm 2 guarantees convergence to the optimal point of Problem (5). This convergence behavior is analyzed in Proposition 1, with the proof provided in Appendix B.

**Proposition 1**.: _With \(^{k}(0,1]\), \(^{k} 0\) and \(_{k}^{k}=+\), Algorithm 2 converges in a finite number of iterations to an optimal solution of (5) or every limit point of the sequence \(\{^{k}\}_{k=1}^{}\) (at least one such point exists) is an optimal solution of (5)._

### Regret Analysis

The loss function \(f_{t}()\) in the APAS framework is piecewise convex, leading to a scenario where it is generally non-convex and non-smooth. In general convex online learning settings, optimal regret bounds are well-established, typically \(O()\) for \(T\) iterations. However, achieving these optimal regret bounds in non-convex online learning scenarios poses significant challenges due to the inherent difficulties in optimizing non-convex functions. Strategies to address these challenges often involve either working with a restricted class of loss functions or focusing on a computationally feasible notion of regret (Hazan et al., 2017; Gao et al., 2018). Additionally, some approaches dealing with general non-convex losses rely on access to sampling oracles, which are impractical in many real-world applications (Maillard and Munos, 2010; Krichene et al., 2015; Agarwal et al., 2019; Suggala and Netrapalli, 2020). Despite recent advances, obtaining optimal regret bounds in non-convex settings remains an open and active area of research.

In our work, we demonstrate that Algorithm 1 can achieve the optimal \(O()\) regret bound. Our approach is novel in that it does not rely on restrictive assumptions or oracles. Instead, it leverages the properties of the function curve and quasi-convexity, as detailed in Proposition 3 and Proposition 4 in Appendix A. Although \(f_{t}()\) is non-convex and non-smooth, its behavior along the function curve enables us to derive favorable regret bounds, achieved by carefully designing the learning rate \(_{t}\) and the updating rule for \(_{t+1}\). The following theorem formalizes the regret bound of our approach:

**Theorem 2**.: _Under Assumptions 1 and 2, Algorithm 1 achieves the following regret bound for \(T 1\):_

\[R_{T}=_{t=1}^{T}f_{t}(_{t})-_{} _{t=1}^{T}f_{t}() 2G^{2}}{}}=O( ),\] (12)

_where \(D\), \(\), and \(G\) are constants defined in Assumptions 1 and 2._

The proof of Theorem 2 is provided in Appendix A. Theorem 2 ensures that Algorithm 1 achieves performance that is comparable to the optimal parameter setting over the long term. Crucially, our approach does not depend on restrictive assumptions or external oracles. Instead, it dynamically adjusts the parameter \(\) by responding to real-time changes, allowing for optimal performance in both stable and volatile environments.

Experiments

To demonstrate the performance of our proposed methods, we conduct experiments using stock lists from S&P 500 and NASDAQ 100 from Yahoo! FinanceTM for an enhanced index-tracking task. Enhanced index tracking is a passive portfolio selection strategy that aims to enhance returns by incorporating tactical tilts towards specific styles, while still maintaining a portfolio that closely mirrors an index (Dose and Cincotti, 2005; Benidis et al., 2017, 2018; Xu et al., 2022).

In our experiments, the instance \(_{t}\) represents the stock return at time \(t\), where \(x_{t,i}=(p_{t,i}-p_{t-1,i})/p_{t-1,i}\) with \(p_{t,i}\) denoting the price of asset \(i\) at time \(t\). The target value \(y_{t}\) is the index return at time \(t\). In the enhanced index tracking task, we sequentially select the portfolio weight \(_{t}\) at each iteration to mimic the trend of the index \(y_{t}\), where the feasible set is the probability simplex \(=\{^{N}^{}=1, 0\}\). To achieve a higher return, rather than merely tracking the index, we define the side information as the negative log return, i.e., \(h_{t}()=-(1+_{t}^{})\).

We measure the performance of different methods using tracking error and excess cumulative return. The tracking error is quantified by the magnitude of the daily tracking error (MDTE), computed by:

\[=^{T}_{t}^{ }_{t}-y_{t}^{2}}.\] (13)

The excess cumulative return is used to assess the performance relative to the tracking index, which represents the discrepancy between the logarithmic cumulative return of the strategy and the index:

\[=_{t=1}^{T}1+_{t}^{ }_{t}-_{t=1}^{T}(1+y_{t}).\] (14)

_Benchmark:_ In addition to the base model PA, we compare the performance with two versions of SLAIT: SLAIT-ETE and SLAIT-DR (Benidis et al., 2017). SLAIT-ETE focuses on tracking accuracy, while SLAIT-DR aims to replicate the index while avoiding excessively large drawdowns.

### Synthetic Data Experiments

We generate synthetic data by sampling \(_{t}(,)\), where \(^{N}\) and \(^{N N}\) are the sample mean and sample covariance matrix calculated from the real market data from the S&P 500. The corresponding index value is generated by:

\[y_{t}=_{t}^{}^{}+,\]

where \((0,^{2})\) represents Gaussian noise, and \(^{}\) is the true weight of the index components. We generate 50 datasets to test the average performance of different methods, with each dataset containing \(T=200\) observations and \(N=100\) dimensions. The training set consists of 50% of the data, while the test set contains the remaining 50%. Both SLAIT-ETE and SLAIT-DR use a rolling training window of 100-day observations, rebalanced every 3 days.

Figure 2 presents the performance comparison and ablation experiments of the proposed APAS framework against benchmarks on the synthetic dataset. Specifically, Figure 1(a) illustrates the comparison of excess return and tracking error for APAS and the benchmarks, where the curve for APAS is generated by varying the trade-off parameter \(\). For small \(\), APAS exhibits relatively low tracking error, while for large \(\), APAS achieves higher returns with a slight sacrifice in accuracy. Compared to the benchmarks, APAS demonstrates higher excess cumulative return for the same level of tracking error and lower tracking error for the same level of excess cumulative return.

Figure 1(a) also shows how varying the trade-off parameter \(\) affects the balance between side performance (measured as excess cumulative return) and tracking error. Generally, \(\) can be selected based on the specific problem's considerations, such as the magnitude of side information and the desired balance between minimizing tracking error and maximizing side performance. In practice, \(\) can be determined using domain knowledge and cross-validation. For example, if a specific range of tracking error is desired, the bisection method can be employed during cross-validation to identify the value of \(\) that maximizes side performance while meeting the tracking error requirement.

Figure 1(b) compares the performance of the fixed parameter setting with the adaptive one, where PAS refers to the non-adaptive version of APAS with fixed \(\). The closer the curve is to the top left, the

better the performance. Even without knowing the optimal parameter setting for \(\), the adaptive \(\) updating scheme in APAS ensures relatively good performance.

We also compare the trends of tracking error and excess cumulative return over time \(T\) in Figure 3. This figure shows that both the PA method and the proposed APAS method exhibit relatively low tracking error. Although the PA method has the minimum tracking error, it achieves the lowest excess cumulative return among all methods. In comparison, the APAS method maintains a comparably low tracking error but with a significantly higher excess cumulative return.

It is widely acknowledged that heavy-tailed distributions offer a more realistic model for data-generating processes in financial markets compared to Gaussian distributions (Cardoso et al., 2021, 2022). To further evaluate the performance of APAS in highly volatile and noisy environments, we include a detailed comparison of our proposed methods under various data and noise distributions, available in Appendix E.

### Real Market Data Experiments

We conduct simulations on two well-known indices using real market data from Yahoo! FinanceTM: the S&P 500 Index and the NASDAQ 100 Index. For the S&P 500 Index, we collect data from 2021-01-01 to 2023-01-01, totaling \(T=503\) daily observations with \(N=453\) stocks. For the NASDAQ 100 Index, we collect data from 2019-01-01 to 2021-01-01, also totaling \(T=503\) daily observations with \(N=101\) stocks. For the PA and APAS methods, 50% of the data is used for training, with weights updated adaptively each day based on the latest data. For the SLAIT-ETE and SLAIT-DR methods, the training lookback period is 50% of the data, with rebalancing occurring every 10 days.

Figure 3: Tracking error and excess cumulative return over time \(T\) for different methods on the synthetic dataset.

Figure 2: Comparison of tracking error and excess cumulative return on the synthetic dataset.

Figures 4 and 5 show the performance comparison on the S&P 500 and NASDAQ 100 datasets, respectively. As observed, with a small \(\) setting, APAS has a comparable tracking error to PA while yielding a better excess cumulative return. With a large \(\) setting, APAS exhibits a higher tracking error but achieves the best excess cumulative return among all methods. The real market comparisons across different datasets demonstrate that the proposed APAS model provides a superior trade-off between tracking error and excess cumulative return compared to the benchmarks.

### Speed Comparison of Acceleration Schemes

This section evaluates the computational efficiency of our proposed method (Algorithm 2) in Section 3.3 across different problem dimensions \(N\). The benchmarks include the widely-used convex problem solver CVXR Fu et al. (2020), Projected Gradient Descent (PGD), and Alternating Direction Method of Multipliers (ADMM, Boyd et al., 2011).

We assess the performance of the proposed method over 100 randomized trials, comparing the convergence speed and CPU time (in seconds), as shown in Figure 6. The left panel of Figure 6 illustrates the average convergence gap versus the number of iterations on a dataset with \(N=1000\) dimensions, comparing the proposed method with PGD and ADMM. The right panel displays the average CPU time for each method across different problem dimensions \(N\). The results demonstrate that our method converges rapidly to the optimal point, being nearly 100 times faster than CVXR and ADMM and 10 times faster than PGD for high-dimensional data.

To further assess whether time complexity is affected by including different types of side information, we conduct additional experiments using various forms of side information beyond the log return \(h_{t}()=-(1+_{t}^{})\), such as:

Figure 4: Tracking error and excess cumulative return over time \(T\) for different methods on S&P 500 dataset.

Figure 5: Tracking error and excess cumulative return over time \(T\) for different methods on NASDAQ 100 dataset.

* Switching cost: \(h_{t}()=||-_{t}||_{1}\);
* Weighted \(_{1}\) norm: \(h_{t}()=_{i=1}^{N}_{i}|w_{i}|\);
* Group Lasso: \(h_{t}()=_{i=1}^{m}_{i}||w_{|_{i}}||_{2}\), where \(_{i},,_{m}\) are \(m\) disjoint groups.

We evaluate the performance of the proposed efficient method with different types of side information functions over \(100\) randomized trials, comparing the average CPU time (in seconds) in Table 1. From Table 1, it appears that group Lasso incurs higher CPU times, especially for larger dimensions \(N\), due to the added complexity of calculating norms for disjoint groups. In general, while the type of side information can impact the computational time, the APAS framework maintains efficiency across different scenarios.

## 5 Conclusions

In this paper, we addressed the limitations of the Passive-Aggressive (PA) algorithm in online regression, particularly in determining the appropriate threshold and integrating side information for weight selection. To tackle these issues, we proposed the APAS framework, which incorporates side information into PA. Our APAS framework adaptively selects the threshold parameter, enabling it to leverage side information for improved performance while maintaining a low tracking error. We demonstrated the robustness and effectiveness of APAS through an \(O()\) regret bound, even with non-convex loss functions. Additionally, we developed an efficient algorithm that significantly reduced computational complexity without compromising theoretical performance guarantees. Comprehensive experiments on synthetic and real market datasets validated the effectiveness and efficiency of APAS, highlighting its practical applicability across various scenarios.