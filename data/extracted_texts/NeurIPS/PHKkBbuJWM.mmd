# An Iterative Self-Learning Framework for Medical Domain Generalization

Zhenbang Wu 1  Huaxiu Yao 2  David M Liebovitz 3  Jimeng Sun 1

1 University of Illinois Urbana-Champaign, {zw12, jimeng}@illinois.edu

2 University of North Carolina at Chapel Hill, huaxiu@cs.unc.edu

3 Northwestern University, david.liebovitz@nm.org

###### Abstract

Deep learning models have been widely used to assist doctors with clinical decision-making. However, these models often encounter a significant performance drop when applied to data that differs from the distribution they were trained on. This challenge is known as the domain shift problem. Existing domain generalization algorithms attempt to address this problem by assuming the availability of domain IDs and training a single model to handle all domains. However, in healthcare settings, patients can be classified into numerous latent domains, where the actual domain categorizations are unknown. Furthermore, each patient domain exhibits distinct clinical characteristics, making it sub-optimal to train a single model for all domains. To overcome these limitations, we propose SLDG, a self-learning framework that iteratively discovers decoupled domains and trains personalized classifiers for each decoupled domain. We evaluate the generalizability of SLDG across spatial and temporal data distribution shifts on two real-world public EHR datasets: eICU and MIMIC-IV. Our results show that SLDG achieves up to 11% improvement in the AUPRC score over the best baseline.

## 1 Introduction

Deep learning techniques have been increasingly popular in clinical predictive modeling with electronic health records (EHRs) [12; 11; 47; 58; 2]. However, these models typically assume that the training (source) data and testing (target) data share the same underlying data distribution (i.e., domain). This assumption can become problematic when models are applied to new domains, such as data from different hospitals or future time points [17; 59; 20; 37]. In these situations, domain shifts caused by variations in patient cohorts, clinical standards, and terminology adoption can significantly degrade the model's performance.

This paper aims to develop a clinical predictive model on the source data that effectively handles potential domain shifts when applied to the target data. Domain generalization (DG)  methods have been widely utilized to address such problems, including techniques like domain alignment [32; 24; 25; 45; 31; 51; 62], meta-learning [23; 27; 26; 5; 22; 29], and ensemble learning [9; 42; 43; 61]. However, when applied in healthcare settings, these methods encounter the following limitations:

* **Reliance on domain IDs.** Most DG methods depend on the presence of domain IDs, which indicate the domain to which each sample belongs, to guide the model training [24; 16; 4; 9; 42]. However, as shown in Fig. 1, patients can be divided into numerous latent domains based on features such as age, medical history, treatment, and symptoms. The actual categorization of these latent domains can be difficult to obtain and vary across different tasks [1; 49]. Consequently, existing DG methods often resort to broad domain categorizations, such as hospital or timestamp, which provide limited information [59; 17].

* **Attempt to train a single model.** While some recent DG methods have attempted to alleviate the reliance on domain labels [62; 29], they try to train a single model that generalizes across all domains. However, patients from different domains possess distinct characteristics and require different treatment approaches [2; 58]. For example, as shown in Fig. 1, fever is considered a normal symptom for patients with viral infections as it helps stimulate the immune system. On the other hand, it can be a bad signal for patients with cardiovascular disease, leading to complications. Thus, training a single model for all domains is challenging and can lead to sub-optimal performance.

To overcome these limitations, we propose SLDG, a self-learning framework for domain generalization that iteratively discovers decoupled domains and trains customized classifiers for each discovered domain. Specifically, SLDG consists of the following iterative steps:

* **Decoupled domain discovery.** While domain labels are not initially available, we posit that they can be recovered by clustering the learned latent representations. However, identifying all fine-grained domains across various clinical features (e.g., demographics, diagnosis, and treatments) can be challenging. Instead, we propose to decouple these clinical features and discover the clusters separately for each type of feature. To achieve this, we maintain a distinct latent space for each type of features using a feature-specific patient encoder. Within each latent space, we perform hierarchical clustering independently to discover the domain categorizations. By adopting this approach, we effectively reduce the number of domains from exponential to linear to the number of feature types.
* **Domain-specific model customization.** To account for the unique characteristics of patients in different domains, our approach involves training customized classifiers for each domain. To ensure parameter efficiency, we extract domain representations from the learned clusters and utilize them to parameterize the domain-specific classifiers. For a given patient, we determine the closest domain by comparing the patient's representations with the domain representations, and subsequently select the corresponding classifier for accurate inference.

To assess the generalizability of SLDG across spatial and temporal shifts, we conduct experiments on two publicly available EHR datasets: eICU  and MIMIC-IV . Our results demonstrate that SLDG outperforms the best baseline by up to 11% in terms of AUPRC score. We also conduct detailed analyses and ablation studies to investigate the factors contributing to the performance gain achieved by SLDG.

Figure 1: Conventional domain generalization methods typically rely on domain IDs and shared characteristics across domains to train a single generalized model. However, in the medical field, patients can be classified into numerous latent domains that are not directly observable. Additionally, each patient domain exhibits unique clinical characteristics, making it sub-optimal to train a single model for all domains.

## 2 Preliminaries

In EHR data, a patient's hospital visit is represented by a sequence of events, denoted as \(x=[e_{1},e_{2},,e_{m}]\), where \(m\) is the total number of events in the visit. Each event \(e\) characterizes features of a certain type \(t\), such as diagnosis, prescription, and lab tests. This mapping is denoted by a function \(T(e):\), where \(\) and \(\) denote the sets of all events and types, respectively. For example, a patient visit can be [Acute embolism (I82. 40), Atrial fibrillation (I48.91), Ultrasound (76700), CT scan (G0296), ECG (93042), Heparin IV (5224)]. And each event corresponds to a specific type (e.g., diagnosis, procedure, medication). The main objective of clinical predictive modeling is to predict the occurrence of future events, such as 15-day hospital readmission and 90-day mortality, denoted as \(y\{+,-\}\), based on the patient's current visit \(x\).

Existing clinical prediction works typically train a model \(f_{}()\) with parameter \(\) by minimizing a loss function \(l()\) on source training data sampled from distribution \(P_{tr}\), as in Eq. (1),

\[_{}_{(x,y) P_{tr}}[l(f_{}(x),y)],\] (1)

with the hope that the trained model can perform well on the target test data distributed according to \(P_{te}\). However, in real-world settings, the source and target distributions can differ due to spatial and temporal shifts, i.e., \(P_{tr} P_{te}\). Consequently, the model trained on source data may experience a drop in performance when applied to the target data.

## 3 The Sldg Approach

In this paper, our goal is to train a model \(f_{}()\) on source data \(P_{tr}\) that can generalize to target data \(P_{te}\) despite potential domain shifts. Existing DG algorithms face limitations due to their reliance on domain IDs and attempts to train a single model for all domains. To overcome these limitations, we propose to iteratively discover latent domains and train customized classifiers for each domain. However, we face the challenge of dealing with a large number of latent domains, which not only makes domain discovery difficult but also results in an exponential increase in the number of model parameters with respect to the number of feature types. In the following sections, we will describe how our method SLDG addresses this challenge through decoupled domain discovery and domain-specific model customization. Additionally, we will introduce the training and inference strategy. Fig. 2 illustrates the SLDG framework.

### Decoupled Domain Discovery

Although domain labels are not initially available, we hypothesize that the domain information is encoded in the learned latent representations and can be recovered with the clustering technique. How

Figure 2: An illustration of the SLDG framework. The feature-specific patient encoder maps each patient into multiple latent spaces, with each space capturing patient characteristics from a specific perspective. Next, SLDG iteratively performs decoupled clustering to identify latent domains and learns domain-specific classifiers customized for each domain.

ever, patients can be categorized into thousands of latent domains, determined by various features such as age, medical history, treatment, and symptoms. For instance, a patient can fall into the fine-grained domain of _older male patients with a history of smoking and a diagnosis of type 2 diabetes_. Identifying all such fine-grained domains can be challenging, as clustering methods may either overlook smaller domains or result in an excessive number of domains that would inflate the number of parameters in subsequent steps. To address this, we propose decoupling these clinical features and independently discovering clusters for each feature type. For example, the patient above can simultaneously belong to the decoupled domains of _older, male, history of smoking_, and _diagnosis of type 2 diabetes_. This approach effectively reduces the number of domains from exponential to linear with respect to the number of feature types.

Concretely, we maintain a distinct latent space for each type of feature. When given an input patient visit \(x\), \(\) maps it to the latent space corresponding to the feature type \(t\) using a feature-specific patient encoder \(E_{t}()\), as in Eq. (2),

\[_{t} E_{t}(x),\ \ _{t}^{h},\] (2)

where \(h\) denotes the hidden dimension. Next, within each latent space of type \(t\), \(\) gathers all patient representations \(\{_{t}^{(i)}\}_{i=1}^{N_{tr}}\), where \(N_{tr}\) is the number of source training data, and performs clustering to discover the domain categorizations, as in Eq. (3),

\[_{t}(\{_{t}^{(i)}\}_{i=1}^{N_{tr}}),\ \ _{t}\{0,1\}^{N_{tr} K_{t}},\] (3)

where \(K_{t}\) represents the number of discovered domains in the latent space of type \(t\). \(_{t}\) denotes the learned domain assignment, where \(_{t}[i,k]\) is equal to one if and only if (i.f.f.) the patient \(x^{(i)}\) is assigned to the \(k\)-th domain. We will describe this procedure in detail in the following.

Feature-Specific Patient Encoding.This module is responsible for mapping each patient into multiple latent spaces, each capturing the patient's health status of a specific feature type. This enables subsequent modules to decouple the representations of different feature types. For a patient's hospital visit \(x\) with a list of events \([e_{1},,e_{m}]\), \(\) computes the contextualized representation for each event by applying the embedding function \(E()\), as in Eq. (4),

\[[_{1},,_{m}]=E([e_{1},,e_{m}]),\ \ _{j} ^{h},\] (4)

where \(_{j}\) is the contextualized representation for event \(e_{j}\) with dimension \(h\). We model \(E()\) using a three-layer Transformer  framework. To ensure that there are no unseen events in the target data, we initialize the event embedding look-up table with ClinicalBERT  embeddings of the event name and then project it down to our hidden dimension of size \(h\). The embedding look-up table is fixed during training.

Next, \(\) aggregates the contextualized event representations \([_{1},,_{m}]\) based on their types, such as family history, diagnosis, and treatments. For each type \(t\), the type-specific representation \(_{t}\) is computed by averaging the representations of all events of that type, as in Eq. (5),

\[_{t}=(\{_{j} T(e_{j})=t\}_{j=1}^{m}),\ \ _{t}^{h},\] (5)

where \(T(e_{i})\) indicates the type of event \(e_{i}\). If no events belong to a certain type, the pooled sequence representation is used as a substitute. Consequently, each patient's hospital visit is represented by a set of vectors \(\{_{t}\}_{t}\), with each vector capturing the patient's health status from a specific type of events. These decoupled patient representations are then utilized to perform per-feature-type domain clustering, described next.

Hierarchical Domain Clustering.This module is responsible for clustering patient representations in each latent space to discover latent domains, enabling subsequent modules to customize the classifier for each domain. In the previous step, we obtain a set of patient representations \(\{_{t}^{(i)}\}_{i=1}^{N_{tr}}\) for each latent space of type \(t\). To perform clustering, standard clustering techniques such as k-Means and Gaussian Mixture Model (GMM) require specifying the number of clusters, which is less ideal as the number of clusters can be difficult to choose and may vary across latent spaces. Inspired by GEORGE , we adopt a fully automated hierarchical clustering technique by monitoring the Silouette score .

Specifically, in each latent space, SLDG first applies UMAP  for dimensionality reduction. Then, it runs k-Means with \(k\{2,,10\}\) to identify the optimal number of clusters based on the highest Silhouette score. Subsequently, SLDG further split each cluster into five sub-clusters. However, only sub-clusters surpassing the Silhouette score of the original cluster and containing at least 500 patients are retained. The final number of clusters in the latent space of type \(t\) is denoted as \(K_{t}\). The cluster assignment is represented by a binary matrix \(_{t}\) of size \(N_{tr} K_{t}\), where \(_{t}[i,k]\) is set to one i.f.f. the patient \(x^{(i)}\) is assigned to the \(k\)-th cluster. This automated approach allows us to effectively select the number of clusters in each latent space, balancing between discovering overly coarse or fine-grained clusters.

### Domain-Specific Model Customization

To accommodate the unique characteristics of patients in different domains, we propose to train customized classifiers for each decoupled domain. Given an input patient visit \(x\) and its multi-vector representations \(\{_{t}\}_{t}\), SLDG computes the predicted probability \(o\) of a specific event occurring by employing a weighted combination of domain-specific classifiers in each latent space \(t\), as in Eq. (6),

\[o|}_{t} _{k=1}^{K_{t}}(_{t})}_{} (_{t})}_{},\ \ o,\] (6)

where \(C_{t,k}()\) refers to the customized classifier for the discovered domain \(k\) in the latent space of type \(t\), while \(G_{t,k}()\) corresponds to the gating function. In the following, we will elaborate on how SLDG leverages the clustering results to efficiently parameterize the domain-specific classifier and effectively determine the gating weights.

To efficiently parameterize the domain-specific classifier \(C_{t,k}()\) for the \(k\)-th discovered domain in the latent space of type \(t\), we define two learnable weight vectors of size \(h\): \(_{t,k}^{+}\) and \(_{t,k}^{-}\), which represent the prototypes of the positive and negative classes, respectively. The predicted probability of a specific event occurring is computed based on the relative distance between the patient representation \(_{t}\) and the positive and negative prototypical weights, as in Eq. (7),

\[C_{t,k}(_{t})=_{t,k}^{+},_{t}))}{ _{*\{+,-\}}(-d(_{t,k}^{*},_{t}))},\ \ C_{t,k}(_{t}),\] (7)

where \(d(,)\) is the Euclidean distance. To facilitate efficient learning, we initialize the two prototypical weight vectors \(_{t,k}^{+}\) and \(_{t,k}^{-}\), with the average representations of patients from the corresponding classes, as in Eq. (8),

\[(_{t,k}^{*})=(\{_{t}^{(i)}(M _{t}[i,k]=1)(y^{(i)}=*)\}_{i=1}^{N_{tr}}),\ \ *\{+,-\},\] (8)

where \(M_{t}[i,k]=1\) includes only patients assigned to the \(k\)-th domain in the latent space of type \(t\).

We adopt a similar approach to the gating function \(G_{t}()\). For each discovered domain \(k\) in the latent space of type \(t\), we introduce a learnable prototypical weight vector \(_{t,k}^{h}\). The gating weights are determined based on the distance between the patient representation \(_{t}\) and the corresponding prototypical weights, as in Eq. (9),

\[G_{t}(_{t})=(\{-d(_{t,k},_{t})\}_ {k=1}^{K_{t}}),\ \ G_{t}(_{t})^{K_{t}},\] (9)

where the prototypical weight vectors \(\{_{t,k}\}_{k=1}^{K_{t}}\) are initialized as the average representations of patients in that domain, as in Eq. (10),

\[(_{t,k})=(\{_{t}^{(i)} M_{t} [i,k]=1\}_{i=1}^{N_{tr}}),\ \ k=1,,K_{t}.\] (10)

### Training and Inference

To train SLDG, we begin by utilizing a pre-trained patient encoder 1 for decoupled domain discovery. Then, we iteratively update the model weights and re-generate the clusters every 20 epochs. In each iteration, we re-initialize the classifier and gating parameters. This iterative process is repeated three times to enhance the model's performance. During training, we minimize the binary cross-entropy loss. For inferencing, given a target patient visit, \(\) first maps it to multiple decoupled latent spaces with the feature-specific patient encoders \(E_{t}()\). Subsequently, in each latent space of type \(t\), the gating function \(G_{t}()\) determines the weight combinations used to aggregate the predictions from domain-specific classifiers \(\{C_{t,k}()\}_{k=1}^{K_{t}}\). The final prediction is obtained by averaging the predictions from all latent domains. The pseudocode of \(\) can be found in Appx. A.

## 4 Experiments

### Experimental Setup

**Datasets.** We evaluate \(\) on two publicly available real-world EHR datasets: eICU  and MIMIC-IV , which are described as follows:

* **eICU** covers over 200K visits for 139K patients admitted to the intensive care unit (ICU) in one of the 208 hospitals across the United States. The data was collected between 2014 and 2015. The 208 hospitals can be further categorized into four groups based on their location (Midwest, Northeast, West, and South). We use age, gender, and ethnicity as patient demographic information, and leverage the diagnosis, treatment, medication, and lab tables to gather patient visit information.
* **MIMIC-IV** covers over 431K visits for 180K patients admitted to the ICU in the Beth Israel Deaconess Medical Center. The data was collected between 2008 to 2019. The approximate actual year of each admission is revealed as one of the four-year groups (2008-2010, 2011-2013, 2014-2016, and 2017-2019). We use age, gender, and ethnicity as patient demographic information, and leverage diagnoses, procedures, and prescriptions to gather patient admission information.

We elaborate on the cohort selection process and provide comprehensive dataset statistics in Appx. B.1. In the end, we extract 149227 visits from 116075 patients in the eICU dataset, and 353238 visits from 156549 patients in the MIMIC-IV dataset.

**Clinical Predictive Tasks.** We focus on two common clinical predictive tasks: (1) Readmission prediction, which aims to determine whether a patient will be readmitted within the next 15 days following discharge. (2) Mortality prediction, which aims to predict whether a patient will pass away upon discharge in the eICU setting, or within 90 days after discharge in the MIMIC-IV setting. A detailed explanation of this setting can be found in Appx. B.2.

**Data Split.** We evaluate the performance of our model across spatial gaps using the eICU dataset. For this purpose, we select the target testing data as the group (Midwest) that demonstrated the largest performance gap in a pilot study. The remaining groups (Northeast, West, and South) are used as the source training data. To assess the model's performance across temporal gaps, we utilize the MIMIC-IV dataset. Patients admitted after 2014 are used as the target testing data, while all preceding patients are included in the source training data. We elaborate more on the data split in Appx. B.3.

**Baselines.** We compare \(\) against three categories of baselines. (1) The first category consists of naive baselines, including **Oracle**, trained directly on the target data, and **Base**, trained solely on the source data. (2) The second category comprises DG methods that require domain IDs. These include **DANN** and **MLDG**, which use coarse regional and temporal groups as the domain definition, and **ManyDG**, which treats each patient as a unique domain. (3) The last category consists of DG methods that do not rely on domain IDs, including **IRM**, **MMLD**, and **DRA**. A detailed explanation of all the baselines can be found in Appx. B.4.

**Evaluation Metrics.** Both readmission prediction and mortality prediction are binary classification tasks. To evaluate the performance of the models, we calculate the Area Under the Precision-Recall Curve (AUPRC) and the Area Under the Receiver Operating Characteristic Curve (AUROC) scores. For each metric, we report the average scores and standard deviation by performing bootstrapping1000 times. Additionally, we conduct independent two-sample t-tests to assess whether SLDG achieves a significant improvement over the baseline methods.

**Implementation Details.** For all baselines, we use the same Transformer  architecture as the backbone encoder. Patient demographics features (age, gender, and ethnicity) are embedded with an embedding look-up table. We also embed the timestamps with sinusoidal positional encoding. The medical, patient demographics, and temporal embeddings are added together to form the overall sequence embedding. All models are trained for 100 epochs, and the best model is selected based on the AUPRC score monitored on the source validation set. For SLDG, UMAP  from UMAP-learn  is used with 2 components, 10 neighbors, and 0 minimum distance; and k-Means from Scikit-learn  is used with the default hyper-parameter. Further information regarding the detailed implementations can be found in Appx. B.5.

### Main Results

Table 1 presents the domain generalization results on the eICU  and MIMIC-IV  datasets. Firstly, we observe a significant performance gap between the Oracle and Base methods, indicating the presence of substantial spatial and temporal domain gaps. This supports the use of the DG setting. Notably, the readmission tasks exhibit larger domain gaps, which is reasonable since hospitals across different locations and timestamps may have varying criteria for patient readmission. Secondly, we note that the two DG methods, DANN  and MLDG , utilizing coarse domain partitions such as region and timestamp, achieve minimal or no improvements. This outcome is expected because the domain partitions are too coarse, making it challenging to identify consistent domain features. In comparison, ManyDG  achieves better performance by considering each individual patient as a unique domain. Among the remaining three baseline methods that do not rely on domain IDs, IRM  demonstrates the slightest improvement. DRA  performs better due to the usage of multi-head networks, which share a similar intuition as SLDG. MMLD  attains the highest performance among all baselines, showcasing the advantages of explicit domain discovery. Lastly, SLDG outperforms baselines for all tasks. Specifically, in terms of the AUPRC score, SLDG achieves an 11% relative improvement in eICU readmission prediction, 3% in eICU mortality prediction, 10% in MIMIC-IV readmission prediction, and 6% in MIMIC-IV mortality prediction.

### Quantitative Analysis

This section provides quantitative analyses to elucidate the performance enhancements achieved by SLDG. The analyses encompass the evaluation of clustering results, ablation studies on the clustering algorithm, the impact of the number of clusters and iterations, and a runtime comparison.

    &  &  \\  &  &  &  &  \\  &  & **AUROC** & **AUPRC** & **AUROC** & **AUROC** & **AUROC** & **AUROC** \\  Oracle & 0.219 (0.01) & 0.677 (0.01) & 0.271 (0.01) & 0.839 (0.01) & 0.282 (0.01) & 0.693 (0.00) & 0.428 (0.00) & 0.898 (0.01) \\  Base & 0.104 (0.02) & 0.510 (0.01) & 0.230 (0.01) & 0.803 (0.01) & 0.237 (0.01) & 0.665 (0.01) & 0.374 (0.01) & 0.861 (0.00) \\ DANN & 0.135 (0.01) & 0.538 (0.01) & 0.245 (0.01) & 0.808 (0.01) & 0.247 (0.01) & 0.673 (0.01) & 0.380 (0.02) & 0.873 (0.02) \\ MLDG & 0.104 (0.01) & 0.525 (0.01) & 0.224 (0.01) & 0.797 (0.01) & 0.205 (0.01) & 0.657 (0.02) & 0.360 (0.01) & 0.857 (0.01) \\ ManyDG & 0.155 (0.01) & 0.549 (0.01) & 0.259 (0.01) & 0.814 (0.01) & 0.249 (0.01) & 0.676 (0.01) & 0.388 (0.01) & 0.880 (0.01) \\ IRM & 0.136 (0.01) & 0.538 (0.01) & 0.252 (0.02) & 0.811 (0.01) & 0.242 (0.00) & 0.668 (0.01) & 0.387 (0.01) & 0.876 (0.01) \\ MMLD & 0.167 (0.01) & 0.578 (0.00) & 0.256 (0.01) & 0.818 (0.01) & 0.250 (0.02) & 0.679 (0.01) & 0.393 (0.01) & 0.887 (0.01) \\ DRA & 0.148 (0.01) & 0.551 (0.01) & 0.249 (0.01) & 0.810 (0.01) & 0.246 (0.01) & 0.670 (0.01) & 0.387 (0.01) & 0.875 (0.01) \\  SLDG & **0.186 (0.01)** & **0.623 (0.01)** & **0.268 (0.01)** & **0.824 (0.01)** & **0.274 (0.01)** & **0.690 (0.01)** & **0.416 (0.00)** & **0.899 (0.01)** \\   

Table 1: Results of domain generalization on the eICU and MIMIC-IV datasets. An asterisk (*) indicates that SLDG achieves a significant improvement over the best baseline method, with a p-value smaller than 0.05. The experimental results demonstrate that SLDG exhibits robustness against spatial (eICU) and temporal (MIMIC-IV) domain shifts.

**Evaluation of clustering results.** First, we evaluate the domain recovery ability of DG methods that do not rely on domain IDs, namely MMLD , DRA , and the proposed SLDG. Since the actual latent domain categorizations are unavailable, we assess the separability of the learned clustering results with the Silhouette score . Note that the reported Silhouette score is calculated on the testing set, while the hyper-parameters are chosen based on the Silhouette score on the training set. As depicted in Fig. 3, DRA achieves the lowest score, which aligns with expectations as it solely learns latent domain categorizations through multi-head networks without explicit clustering. In contrast, MMLD generates more distinct clusters due to its iterative clustering and training setup. However, it still necessitates manual specification of the number of clusters. In comparison, SLDG obtains the highest score using an automated hierarchical clustering technique.

**Influence of the clustering algorithm.** Next, we assess the influence of different clustering algorithms. Naive k-Means and GMM require manual specification of the number of clusters, which we set to the same value as SLDG's. The results can be found in Tab. 2. We observe that naive k-Means and GMM achieve similar perform similarly to the best baseline methods in Tab. 1. This outcome is reasonable since the success of SLDG relies on both the accurate discovery of latent domains and customized models for each domain. Naive clustering techniques often fail to identify subtle yet important latent domains. In contrast, SLDG, utilizing the automatic hierarchical clustering technique, achieves the highest score.

**Influence of the number of clusters and iterations.** Next, we analyze the impact of the number of clusters and iterations on the eICU readmission prediction task. We also compare our results with the best-performing baseline, MMLD . The results can be found in Fig. 4. The upper panel of the figure shows that the model's performance initially improves with an increasing number of clusters. This improvement can be attributed to the finer granularity of clustering, which enables better identification of domains and customization of experts. However, as the number of clusters continues to increase, the model's performance starts to decline. This decline is caused by the growing number of model parameters, making training more challenging and leading to overfitting on suspicious samples. Similarly, the trend observed in the lower panel of the figure for the number of iterations aligns with the number of clusters. The performance initially improves as

    &  &  \\  &  &  &  &  \\  & **AUPRC** & **AUROC** & **AUPRC** & **AUROC** & **AUPRC** & **AUROC** & **AUPRC** & **AUROC** \\  SLDG + k-Means & 0.148 (0.01) & 0.553 (0.01) & 0.249 (0.01) & 0.814 (0.00) & 0.250 (0.01) & 0.670 (0.01) & 0.388 (0.01) & 0.886 (0.01) \\ SLDG + GMM & 0.143 (0.01) & 0.549 (0.01) & 0.240 (0.01) & 0.808 (0.01) & 0.250 (0.01) & 0.688 (0.01) & 0.390 (0.00) & 0.888 (0.00) \\  SLDG & **0.186 (0.01)** & **0.623 (0.01)** & **0.268 (0.01)** & **0.824 (0.01)** & **0.274 (0.01)** & **0.699 (0.01)** & **0.416 (0.01)** & **0.899 (0.01)** \\   

Table 2: Ablation study on the influence of the clustering algorithm.

Figure 4: Results on the influence of the number of clusters and iterations.

Figure 3: Performance of latent domain clustering. A higher Silhouette score indicates improved cluster separability.

the number of iterations increases, allowing the model to learn more from the data. However, after a certain point, the model starts overfitting on specific clusters, leading to decreased performance.

**Runtime comparison.** Lastly, we compare the training time of SLDG with the naive Base baseline. All runtimes are measured on a single NVIDIA A6000 GPU. The results can be found in Tab. 3. The use of the UMAP  dimensionality reduction technique enables SLDG to perform clustering quickly. As a result, the training time overhead of SLDG is reasonably low overall (18% on eICU and 20% on MIMIC-IV) compared to the significant performance improvement achieved (up to 79% relative improvement on AUPRC score on eICU and up to 15% on MIMIC-IV).

### Case Study

For the case study, we first examine the recovered domains within each latent space. The results are presented in the left panel of Fig. 5. It is evident that the common events identified within the same domains are consistent. For instance, _propofol_, _lorazepam_, and _fentanyl_ is frequently used together, serving the purpose of anesthesia (pre-surgery), sedation (in-surgery), and pain management (post-surgery). Furthermore, the right panel of Figure 5 illustrates a visualization of the learned domain similarity, i.e., the distances between the domain prototypical weights \(\{_{t,k}\}_{k=1}^{K_{t}}\). Notably, our method (SLDG) successfully captures meaningful relationships among the latent domains. For instance, a strong relationship is learned between _pneumonia_ and _sepsis_. In clinical practice, when pneumonia is severe or if the infection spreads beyond the lungs, it can enter the bloodstream and trigger a systemic response, leading to sepsis . Another example is the observed strong association between _cardiac arrest_ and _infarction_. In practice, if a significant portion of the heart muscle is damaged, it can disrupt the heart's electrical system, potentially leading to cardiac arrest .

## 5 Related Work

**Domain Generalization** The goal of DG is to learn a model using data from multiple source domains in order to achieve effective generalization to a distinct target domain . To achieve this, domain alignment approaches try to match the feature distributions among multiple source domains with techniques such as moments minimization [32; 25], contrastive learning , adversarial learning [25; 45], regularizers [4; 24], and augmentation [62; 50; 44; 60]. Meta-learning frameworks have also been utilized to simulate new domain scenarios during training [23; 27; 26; 5; 22; 29]. Additionally, domain-specific model ensemble techniques have been employed [9; 42; 43; 61]. However, these conventional DG methods assume the availability of domain IDs, which may not be feasible in healthcare settings where patients can belong to numerous unobserved domains.

Recent advancements in DG have attempted to alleviate the reliance on domain IDs [29; 62; 14; 10; 33]. MMLD  is the most relevant prior work to ours. It simultaneously discovers latent domains and learns domain-invariant features through adversarial learning. However, it focuses on training a

Figure 5: Left: Common clinical events observed in two largest domains identified from each latent space. Right: Learned similarity among the identified domains within the diagnostic latent space.

  
**Latent Space** & **Frequent Clinical Events from the Top-2 Clusters** \\  Diagnosis & Sepsis, Infection, Kidney failure \\   & Cardiac Arrest, Congestive Heart Failure \\  Treatment & Heart valve procedures, Cardiovascular monitoring \\   & Ventilation, Respiratory intubation \\  Medication & Propofol, Lorazepam, Fentanyl \\   & Amiodarone, Noradrenaline \\   

Table 3: Runtime comparison.

single model that generalizes across all domains. Given that patients from different domains exhibit distinct characteristics and require different treatment approaches [2; 58], training a single model for all domains poses challenges and can result in sub-optimal performance.

**Clinical Predictive Modeling.** The main objective of clinical predictive modeling is to predict the occurrence of future events, such as 15-day hospital readmission and 90-day mortality, based on existing patient information. Deep learning models have been widely used in clinical predictive modeling with EHR data [55; 57]. These models are designed to capture temporal patterns in patient data [11; 36; 6; 28], model structural information in medical codes [13; 52], augment the model using pre-training , or leverage patient similarities for better decision making [58; 2]. However, these models typically assume an unchanged test domain and may suffer from degraded performance with domain shift. To address this issue, AutoMap  solves the feature space shift issue by learning an auto-mapping function without considering any distribution shift. MedLink  aggregates de-identified patient data from different sites to enable joint training. ManyDG  tackles patient covariate shift by treating each patient as a unique domain and disentangling domain variant and invariant features. However, maintaining a large number of domains is unnecessary, as similar patients often exhibit similar clinical behavior and can share a common domain.

## 6 Conclusion

Clinical predictive models often exhibit degraded performance when applied to data from new regions or future periods due to distribution shifts. To address this, we propose SLDG, a self-learning framework that iteratively identifies decoupled domains and trains customized classifiers for each domain. We evaluate SLDG on two medical datasets, and our results show that it outperforms all baseline methods. In addition, we provide detailed qualitative analyses and case studies to support our findings.