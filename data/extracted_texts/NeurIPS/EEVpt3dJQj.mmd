# Auditing Fairness by Betting

Ben Chugg\({}^{1}\), Santiago Cortes-Gomez\({}^{1}\), Bryan Wilder\({}^{1}\), Aaditya Ramdas\({}^{1,2}\)

Departments of Machine Learning\({}^{1}\) and Statistics\({}^{2}\)

Carnegie Mellon University

{benchugg, scortesg, builder, aramdas}@cmu.edu

###### Abstract

We provide practical, efficient, and nonparametric methods for auditing the fairness of deployed classification and regression models. Whereas previous work relies on a fixed-sample size, our methods are sequential and allow for the continuous monitoring of incoming data, making them highly amenable to tracking the fairness of real-world systems. We also allow the data to be collected by a probabilistic policy as opposed to sampled uniformly from the population. This enables auditing to be conducted on data gathered for another purpose. Moreover, this policy may change over time and different policies may be used on different subpopulations. Finally, our methods can handle distribution shift resulting from either changes to the model or changes in the underlying population. Our approach is based on recent progress in anytime-valid inference and game-theoretic statistics--the "testing by betting" framework in particular. These connections ensure that our methods are interpretable, fast, and easy to implement. We demonstrate the efficacy of our approach on three benchmark fairness datasets.

## 1 Introduction

As algorithmic decision-making continues to increase in prevalence across both the private and public sectors [1; 2], there has been an increasing push to scrutinize the fairness of these systems. This has lead to an explosion of interest in so-called "algorithmic fairness", and a significant body of work has focused on both defining fairness and training models in fair ways (e.g., [3; 4; 5]). However, preventing and redressing harms in real systems also requires the ability to _audit_ models in order to assess their impact; such algorithmic audits are an increasing area of focus for researchers and practitioners [6; 7; 8; 9]. Auditing may begin during model development , but as model behavior often changes over time throughout real-world deployment in response to distribution shift or model updates [11; 12], it is often necessary to repeatedly audit the performance of algorithmic systems over time [13; 8]. Detecting whether deployed models continue to meet various fairness criteria is of paramount importance to deciding whether an automated decision-making system continues to act reliably and whether intervention is necessary.

In this work, we consider the perspective of an auditor or auditing agency tasked with determining if a model deployed "in the wild" is fair or not. Data concerning the system's decisions are gathered over time (perhaps with the purpose of testing fairness but perhaps for another purpose) and our goal is to determine if there is sufficient evidence to conclude that the system is unfair. If a system is in fact unfair, we want to determine so as early as possible, both in order to avert harms to users and because auditing may require expensive investment to collect or label samples [13; 8]. Following the recent work of Taskesen et al.  and Si et al. , a natural statistical framework for thinking about this problem is hypothesis testing. Informally, consider the null and alternative hypotheses, \(H_{0}\) and \(H_{1}\), defined respectively as

\[H_{0}:, H_{1}:.\]Unfortunately, traditional hypothesis testing requires stringent assumptions on the data; a fixed number of iid data points, for example. Such assumptions are unrealistic in our setting. We should, for instance, be able to continually test a system as we receive more information, i.e., perform _sequential_ hypothesis testing. Moreover, we would like to be able stop collecting additional samples at arbitrary data-dependent stopping times if we have sufficient evidence against the null. This is not allowed in traditional statistical frameworks, where it is known as "peeking" or "p-hacking."

To overcome these challenges, we take advantage of recent progress in safe, anytime-valid inference (SAVI) to construct sequential procedures for determining whether an existing decision-making system is fair. SAVI is part of _sequential analysis_, a branch of statistics concerned--as the name suggests--with analyzing data sequentially while maintaining statistical validity. This subfield traces origins back to Wald, Lai, Robbins, and several others beginning in the 1940s . More recently, the power of sequential analysis to enable inference under continuous monitoring of data and data-dependent stopping rules (hence _safe_ and _anytime-valid_) has led to an explosion of work in the area . A further exciting development has been the connection between such methods and so-called "game-theoretic probability"  which is consistent with modern measure theoretic probability1 but provides an alternative foundation based on repeated games. Importantly for our purposes, this renders many of the tools of SAVI interpretable as well as statistically powerful. We refer the interested reader to the recent survey by Ramdas et al.  for further detail on the relationship between sequential analysis, SAVI, and game-theoretic statistics.

**Contributions.** We develop tools to sequentially audit both classifiers and regressors. In particular:

1. We formulate the problem of auditing the fairness of classification and regression models in terms of sequential hypothesis testing. The focus on _sequential_ testing is distinct from other work, and highlights various desiderata that are important in practice--specifically, (i) being able to continuously monitor the data and (ii) a focus on rejecting the null as early as possible (i.e., reducing the number of costly samples needed to detect unfairness).
2. Next, we design nonparametric sequential hypothesis tests which hold under various definitions of group fairness. We treat auditing as sequential two-sample testing and adapt the recent work of Shekhar and Ramdas  on two-sample testing by betting to the fairness setting. We also provide novel bounds on the expected stopping time of our tests under the alternative, and demonstrate how to handle distribution drift (due to either model changes or changes in the underlying population), time-varying data collection policies, and composite nulls which more accurately reflect practical demands.
3. Finally, we demonstrate the real world applicability of our methods on three datasets: credit default data, US census data, and insurance data. We show that our method is robust to distribution shift resulting from model retraining and to various randomized data-collection policies whose densities deviate significantly from the underlying population. All code is publicly available at https://github.com/bchugg/auditing-fairness.

In order to provide a preview of our methodology, we suggest the following thought experiment. Imagine a fictitious better who is skeptical that a machine learning system is fair. She sets up an iterated game wherein she bets on the results of the audit as it is conducted. Her bets are structured such that, if the system is unfair, her expected payoff will be large. Conversely, if the system is fair, her expected payoff is small. Thus, if her wealth increases over time, it is evidence that the system is unfair. Our sequential test thus rejects the null if her wealth crosses some predetermined threshold. Of course, the trick is to design her bets in such a way the above conditions are satisfied, and that under the alternative, her wealth grows as quickly as possible. Mathematically, the above is made rigorous via nonnegative (super)martingales and results concerning their behavior over time .

**Additional Related Work.** This work sits at the intersection of several fields. On the fairness side, the closest work to ours is that of Taskesen et al.  and Si et al. , both of which study fairness through the lens of (fixed-time) hypothesis testing, based on a batch of \(n\) iid observations. Given iid data \(Z_{t}\), they formulate the null as \(H_{0}:\), where \(\) is the set of all "fair" distributions and derive a test statistic based on projecting the empirical distribution onto \(\) (minimizing a Wasserstein distance). They work with classifiers only. On the more technical side, we view our work as a continuation and application of the testing by betting framework  and more specifically of nonparametric two sample testing by betting . We will deploy similar "betting strategies" (to be defined later) as , but provide novel analyses which are particular to our setting, and consider several extensions. Relatedly, but slightly further removed from our setting, Duan et al.  also employ game-theoretic ideas to construct interactive rank tests. The idea of a auditing a system to verify its veracity extends well beyond the domain of algorithmic fairness. Statistical procedures have been developed, for instance, to audit election results  and recently several SAVI inspired methods have been developed for several such scenarios [33; 34]. More broadly and outside the scope of this paper, betting techniques have been deployed with great success in optimization, online learning, and statistics [35; 36; 37; 38; 26].

## 2 Preliminaries

Consider a feature space \(\) and model \(:\). Depending on the application, \((x)\) might be a risk score for an individual with covariates \(x\), a classification decision, or the probability that some action is taken. Each \(x\) is associated with some "sensitive attribute" \(A=A_{x}\{0,1,,J\}\) (indicating, e.g., the result of a private health test, whether they went to college, their income strata, etc). We will often refer to \(A\) as group membership. The classifier may or may not observe \(A\). For the sake of exposition, we will assume that \(A\{0,1\}\), i.e, there are two groups. However, our methods extend straightforwardly to more than two groups. The details are provided in Appendix B. Before formally stating the problem, let us discuss the notion of fairness we will employ in this work.

**Fairness.** We focus on the concept of "group" fairness. Roughly speaking, this involves ensuring that groups of individuals sharing various attributes are treated similarly. There have been multiple notions of group fairness proposed in the literature. We introduce the following generalized notion of group fairness, which can be instantiated to recapture various others.

**Definition 1**.: Let \(\{_{j}(A,X,Y)\}_{j\{0,,J\}}\) denote a family of conditions on the attributes \(A\), covariates \(X\), and outcomes \(Y\). We say a predictive model \(:\) is fair with respect to \(\{_{j}\}\) and a distribution \(\) over \(\) if, for all \(i,j[J]\), \(_{X}[(X)|_{i}(A,X,Y)]=_{X}[ (X)|_{j}(A,X,Y)]\).

As was mentioned above, unless otherwise stated we will assume that there are only two conditions \(_{0}\), \(_{1}\). For our purposes, the important feature of Definition 1 is that it posits the equality of means. Indeed, letting \(_{b}=_{X}[(X)|_{b}]\) for \(b\{0,1\}\) we can write our null as \(H_{0}:_{0}=_{1}\) and alternative as \(H_{1}:_{0}_{1}\). Different choices of conditions \(_{j}\) lead to various fairness notions in the literature. For instance, if \(\) is a classification model, then:

1. Taking \(_{0}=\{A=0,Y=1\}\) and \(_{1}=\{A=1,Y=1\}\) results in _equality of opportunity_. _Predictive equality_ is similar, corresponding to switching \(Y=1\) with \(Y=0\).
2. Taking \(_{0}=\{A=0\}\), \(_{1}=\{A=1\}\) results in _statistical parity_.
3. Taking \(_{j}=\{A=j,(X)\}\) for some projection mapping \(: F\) onto "legimitate factors" results in _conditional statistical parity_[42; 41].

**Problem Formulation.** We consider an _auditor_ who is receiving two streams of predictions \(Z^{0}=((X^{0}_{t}))_{t T_{0}}\) and \(Z^{1}=((X^{1}_{t}))_{t T_{1}}\), where \(X^{b}_{t}\) obeys condition \(_{b}\) (i.e., is drawn from some distribution over \(|_{b}\)). For brevity, we will let \(^{b}_{t}=(X^{b}_{t})\), \(b\{0,1\}\). The index sets \(T_{0},T_{1}\{\}\) denote the times at which the predictions are received. We let the index differ between groups as it may not be feasible to receive a prediction from each group each timestep. We refer to this entire process as an _audit_ of the model \(\).

For \(b\{0,1\}\), let \(T_{b}[t]=T_{b}[t]\) be the set of times at which we receive predictions from group \(b\) up until time \(t\). The auditor is tasked with constructing a _sequential hypothesis test_\((_{t})_{t 1}\) where \(_{t}=_{t}((_{t T_{0}[t]}Z^{0}_{t})(_{t T_{1}[t]}Z^{ 1}_{t}))\{0,1\}\) is a function of all predictions received until time \(t\). We interpret \(_{t}=1\) as "reject \(H_{0}\)", and \(_{t}=0\) as "fail to reject \(H_{0}\)." Once we reject the null, we stop gathering data. That is, our stopping time is \(=_{t}\{_{t}=1\}\). We say that \(\) is a _level-\(\)_ sequential test if

\[_{P H_{0}}P( t 1:_{t}=1),\ \ \ \ _{P H_{0}}P(<).\] (1)

In words, the test should have small false positive rate (type I error) _simultaneously across all time steps_. (Note that a fixed-time level-\(\) test would simply drop the quantifier \( t 1\) and concern itself with some fixed time \(t=n\).) We also wish to design tests with high power. Formally, we say that \(\) has _asymptotic power_\(1-\) if \(_{P H_{1}}P( t 1:_{t}=0)\), or equivalently \(_{P H_{1}}P(=)\). That is, in all worlds in which the alternative is true, we fail to reject with probability at most \(\) (type II error). Typically the type-II error \(_{n}\) decreases with the sample size \(n\). In this work we will develop asymptotic power one tests, meaning that \(_{n} 0\) as \(n\).

**Martingales and filtrations.** Our techniques rely on the machinery of nonnegative (super)martingales and results concerning their behavior over time. We introduce some of the technicalities here. A (forward) filtration \((_{t})_{t 0}\) is an increasing sequence of \(\)-fields \(_{t}_{t+1}\). Throughout this paper, we will consider the "canonical filtration" \(_{t}=(Z_{1},,Z_{t})\) which can heuristically (but very usefully) be thought of as all the information known at time \(t\). We say that a stochastic process \(S=(S_{t})_{t 1}\) is _adapted_ to \((_{t})\) if \(S_{t}\) is \(_{t}\) measurable for all \(t 1\), and _predictable_ if \(S_{t}\) is \(_{t-1}\) measurable for all \(t 1\). A \(P\)_-martingale_ is an adapted stochastic process \(M=(M_{t})_{t 1}\) such that \(_{P}[M_{t+1}|_{t}]=M_{t}\) for all \(t 1\). If the equality is replaced with \(\), then \(M\) is a \(P\)_-supermartingale_. A particularly useful result in sequential analysis is _Ville's inequality_, which states that if \(M\) is a nonnegative \(P\)-supermartingale, then for all \(>0\), \(P( t 0:M_{t} 1/)_{P}[M_{0}]\). We will also employ the following randomized improvement to Ville's inequality [43, Corollary 4.1.1]: For \(M\) as above and any \(\)-stopping time \(\), \(P( t:M_{t} 1/\) or \(M_{} U/)\), where \(U\) is a uniform random variable on \(\)_which is independent of_\(M\) and \(\).

## 3 Methods

We begin by introducing the methodology in the setting where the predictions are received uniformly at random from the population. We will then progressively generalize the setting: Sections 3.2 and 3.3 will enable time-varying data collection policies, Section 3.4 will allow the means \(_{0}\) and \(_{1}\) to change with time, and Section 3.5 will consider composite nulls of the form \(|_{0}-_{1}|\).

To ease the presentation, let us make the assumption that we receive an audit from both groups each timestep, so that \(T_{0}=T_{1}=\). This is without loss of generality; one can simply wait until multiple audits from each group are available. However, Appendix A provides a more detailed discussion on how to modify our framework and theorems if this condition is unmet.

### Testing by betting

Returning to the intuition for a moment, recall the fictitious bettor discussed in the introduction. She attempts to prove that the system is unfair by betting on the results of the audits before they are revealed. If the system _is_ unfair, then the average difference between \(^{0}_{t}\) and \(^{1}_{t}\) (i.e., the model's outputs across different groups) will be non-zero. The skeptic's bets are therefore structured such that if \(_{0}=^{0}_{t}^{1}_{t}=_{1}\), then her expected wealth will increase over time. More formally, at time \(t\), the skeptic designs a _payoff function_\(S_{t}:_{ 0}\) which is \(_{t-1}\) measurable and \(_{P}[S_{t}(^{0}_{t},^{1}_{t})|_{t- 1}] 1\) if \(P H_{0}\) (i.e, \(_{0}=_{1}\)). Next, the skeptic receives the model predictions \(^{0}_{t}=(X^{0}_{t})\) and \(^{1}_{t}=(X^{1}_{t})\). We assume the skeptic starts with wealth of \(_{0}=1\). At each time \(t\), she reinves all her wealth \(_{t-1}\) on the outcome and her payoff is \(_{t}=S_{t}(^{0}_{t},^{1}_{t}) _{t-1}=_{i=1}^{t}S_{t}(^{0}_{t},^{1}_{t})\). We call \((_{t})_{t 0}\) the skeptic's _wealth process_. The wealth process is a supermartingale starting at \(1\) under the null, due to the constraint on the payoff function. Thus, by Ville's inequality, the probability that \(_{t}\) ever exceeds \(1/\) is at most \(\) when the model is fair. The skeptic's goal, as it were, is to design payoff functions such that the wealth process grows quickly under the alternative, and thus rejection occurs sooner rather than later.

Inspired by a common idea in game-theoretic statistics (cf. ), let us consider the following payoff function:

\[S_{t}(^{0}_{t},^{1}_{t})=1+_{t}(^{0}_{t }-^{1}_{t}),\] (2)

where \(_{t}\) is predictable and lies in \([-1,1]\) to ensure that \(S_{t}(^{0}_{t},^{1}_{t}) 0\). Note that for \(P H_{0}\), \(_{P}[_{t}|_{t-1}]=_{t-1}_ {P}[1+_{t}(^{0}_{t}-^{1}_{t})|_{t-1}] =_{t-1}\), so \((_{t})_{t 1}\) is a nonnegative \(P\)-martingale. Rejecting when \(_{t}>1/\) thus gives to a valid level-\(\) sequential test as described above. We will select \(_{t}\) using Online Newton Step (ONS) , which ensures exponential growth of the wealth process under the alternative. Figure 1 illustrates the behavior of the wealth process under various hypotheses when using ONS to choose \(_{t}\). As the difference between the meansincreases, the wealth grows more quickly which leads to faster rejection of the null. To define ONS, let \(g_{t}=_{t}^{0}-_{t}^{1}\) and initialize \(_{1}=0\). For all \(t 1\), recursively define

\[_{t}=}{1+_{i=1}^{t-1 }z_{i}^{2}}-_{t-1} 1/2-1/2,\ \ \ \ z_{i}=}{1-_{i}g_{i}}.\] (3)

The machinery just introduced is sufficient to define a level-\(\) sequential test. However, we add a final ingredient to increase the power of this procedure. Motivated by the _randomized_ Ville's inequality mentioned in Section 2, we introduce one final step: If we stop the procedure at some stopping time \(\) but have not yet rejected the null (because, for instance, our budget ran out), we can check if \(_{} U/\), where \(U\) is uniform on  and _drawn independently from everything observed so far_. We emphasize that the final step can only be performed once. Thus, if it is possible that more data will be collected in the future, we advise waiting. We summarize the process in Algorithm 1.

``` Input:\((0,1)\) \(_{0} 1\) for\(t=1,2,,\)do #\(\) may not be known in advance  Perhaps receive audits \(_{t}^{0}\) and \(_{t}^{1}\)  Construct payoff \(S_{t}\) (e.g., (2), (16), or (7))  Update \(_{t}_{t-1} S_{t}\)  If \(_{t} 1/\) then stop and reject the null endfor if the null has not been rejected then  Draw \(U(0,1)\), reject if \(_{} U/\) endif ```

**Algorithm 1** Testing group fairness by betting

The following proposition gives a bound on the expected stopping time of this sequential test under the alternative. We note that Shekhar and Ramdas  also provide a bound on the expected stopping time of a multivariate betting-style sequential test. However, due to the generality of their setting, their result is defined in terms of quantities which are difficult to analyze. We thus provide a more direct analysis specific to the difference of univariate means. The proof may be found in Appendix C.1.

**Proposition 1**.: _Algorithm 1 with input \((0,1)\) and betting strategy (2) is a level-\(\) sequential test with asymptotic power one. Moreover, letting \(=|_{0}-_{1}|\), under the alternative the expected stopping time \(\) obeys_

\[[]} }.\] (4)

It is possible to demonstrate a lower bound of \([]^{2}(1/)/^{2}\) where \(^{2}=[(^{0}-^{1})^{2}]\)[28, Prop. 2]. Since \(^{2} 1\) in the worst case, our result is optimal up to a factor of \((1/^{2})\).

### Time-varying data collection policies

Here we extend the setting to allow for time-dependent data collection policies. This is motivated by the fact that organizations are often collecting data for various purposes and must therefore evaluate fairness on data which is not necessarily representative of the population at large. We also allow the data collection policies to differ by group. Mathematically, for \(b\{0,1\}\) let \(_{t}^{b}()=_{t}(|_{b})\) denote the randomized policies which determine the probability with which a set of covariates are

Figure 1: **Left:** Description of main algorithm. **Right:** The wealth process \((_{t})\) under different conditions on the means. Observations follow a Bernoulli distribution for a given mean. As \(=|_{0}-_{1}|\) increases, the wealth grows more quickly. If a test rejects, the procedure ends, hence the plateauing of the blue and purple lines. For \(=0\), the wealth fluctuates around 1 and the test never rejects. Shaded regions indicated the standard deviation after 100 trials.

selected from the population. Let \(^{b}\) be the density of \(X|_{b}\). Following standard propensity weighting techniques [46; 47], introduce the weighted estimates

\[_{t}^{b}(x):=(x)}{_{t}^{b}(x)}.\] (5)

We may write simply \(_{t}^{b}\) when \(x\) is understood from context. The policy \(_{t}^{b}\) (and hence the weight \(_{t}^{b}\)) need not be deterministic, only \(_{t-1}\) measurable (so it can be considered a deterministic quantity at time \(t\)). This is motivated by various practical applications of sequential decision-making, in which the policy used to collect data often changes over time in response to either learning or policy [48; 49]. In many applications, \(_{t}^{b}\) is a function of a select few covariates only--for instance, income, education level, or career. In some settings it is reasonable to assume knowledge of \(^{b}\) (by means of a census, for instance). However, this is not always the case. Section 3.3 will therefore discuss strategies which do not require precise knowledge of the density. We will assume that for all \(x,t\) and \(b,_{t}^{b}(x)<\). In this case, (5) enables an unbiased estimate of \(_{b}=_{}[(X)|_{b}]\) when \(X_{t}\) is sampled according to \(_{t}^{b}\):

\[_{X_{t}^{b}}[_{t}^{b}_{t}^{b}(X)| _{t-1},_{b}]=_{}(x)_{t}^{b}(x)_{t}^{b}(x) x=_{}(x)^{b}(x)x=_{b}.\] (6)

Our payoff function is similar to the previous section, but reweights the samples by \(_{t}^{b}(=_{t}^{b}(X_{t}^{b}))\), and then adds a corrective factor to ensure that the payoff is nonnegative:

\[S_{t}(_{t}^{0},_{t}^{1})=1+_{t}L_{t}(_{t}^{0}_{t}^{0}-_{t}^{1}_{t}^{1}),\ \ \ \ L_{t}:=_{b\{0,1\}}}{}^{b}(x)},\] (7)

and \(_{t}\) is once again selected via ONS. Multiplication by \(L_{t}\) is required to ensure that the values \(L_{t}(_{t}^{0}_{t}^{0}-_{t}^{1}_{t}^{1})\) lie in \([-1,1]\) in order to be compatible with ONS. Here "ess inf" is the essential infimum, which is the infimum over events with nonzero measure. For most practical applications one can simply replace this with a minimum. For such a strategy, we obtain the following guarantee.

**Proposition 2**.: _Algorithm 1 with input \((0,1)\) and betting strategy (7) is a level-\(\) sequential test with asymptotic power one. Moreover, suppose that \(0<L_{}:=_{t 1}L_{t}\) and let \(= L_{}\) and \(=|_{0}-_{1}|\). Then, treating log-log factors as constant, under the alternative the expected stopping time \(\) obeys_

\[[]} }.\] (8)

Thus we see that we pay the price of allowing randomized data collection policies by a factor of roughly \(1/L_{}\). Note that the payoff function (7) does not require knowledge of \(L_{}\). Indeed, this strategy remains valid even if \(L_{}=0\) as long as \(L_{t}\) is nonzero for each \(t\). It is only the analysis that requires \(L_{}\) to be finite and known. The proof of Proposition 2 is provided in Appendix C.2.

### Time-varying policies for unknown densities

A reasonable objection to the discussion in the previous section is that the densities \(^{b}\) may not always be known. In this case we cannot compute the propensity weights in (5). Here we provide an alternative payoff function which uses an estimate of the density, \(^{b}\). We assume we know upper and lower bounds on the multiplicative error of our estimate: \(^{}_{b}_{x}\{^{b}(x)/^{b}(x)\}\), and \(^{}_{b}_{x}\{^{b}(x)/^{b}(x)\}\). We assume that \(^{}>0\).

Let \(_{t}^{b}\) be the propensity weights at time \(t\) using the estimated density, i.e., \(_{t}^{b}(x)=^{b}(x)/_{t}^{b}(x)\). Notice that \(_{X_{t}^{b}}[_{t}^{b}(X)(X)| _{t-1}]=_{}(x)^{b}(x)x =_{}(x)(^{b}(x)/^{b}(x))^{b}(x) x^{}_{b}.\) Similarly, \(_{X_{t}^{b}}[^{b}(X)(X)|_ {t-1},_{b}]^{}_{b}\). Recall that \(_{t}^{b}=(X_{t}^{b})\). Consider the payoff function

\[S_{t}(_{t}^{0},_{t}^{1})=1+_{t}B_{t} _{t}^{0}_{t}^{0}}{^{}}-_{t}^{1}_{t}^{1}}{^{}},\] (9)

where \(B_{t}\) is \(_{t-1}\) measurable. Then

\[[S_{t}|_{t-1}]=1+_{t}B_{t} _{_{t}^{b}}[_{t}^{0}_{t}^{0}|_{t-1}]} {^{}}-_{_{t}^{b}}[_{t}^{1} {Y}_{t}^{1}|_{t-1}]}{^{}} 1+_{t}B_{t}(_{0}-_{1}).\]Under the null, \(_{0}-_{1}=0\), implying that \([S_{t}|_{t-1}] 1\). We select \(B_{t}\) so that \(S_{t}\) is nonnegative (thus ensuring that the capital process is a nonnegative supermartingale) and is compatible with ONS. The following condition on \(B_{t}\) suffices: \(B_{t}^{}_{b}_{x}(2_{t}^{b}(x))^{-1}\). Note that if we know the true densities then we can take \(^{}=^{}=1\) and we recover (7).

### Handling distribution shift

Until this point we've assumed that the means \(_{b}\) remain constant over time. A deployed model, however, is susceptible to distribution shift due to changes in the underlying population, changes in the model (retraining, active learning, etc), or both. Here we demonstrate that our framework handles both kinds of drift. In fact, we need not modify our strategy (we still deploy Algorithm 1), but we must reformulate our null and alternative hypotheses and our analysis will change. Before introducing the mathematical formalities, we draw the reader's attention to Figure 2 which illustrates two cases of distribution shift and the response of our sequential test to each. The left panel is a case of "smooth" drift in which case \(_{0}(t)=_{1}(t)\) are equal for some number of timesteps after which \(_{1}(t)\) begins to drift upward. The right panel exemplifies a situation in which both means change each timestep (the weekly prevalence of disease in a population, for instance), but \(_{1}(t)\) has a marked drift upward over time. In both cases, the wealth process is sensitive to the drift and grows over time.

To handle changes in the underlying population we let \(_{t}\) denote the population distribution over \(\) at time \(t\). Likewise, to handle changes to the model, we let \(_{t}:\) be the model at time \(t\). In order to define our hypotheses, let \(_{t}:=|_{0}(t)-_{1}(t)|\) where \(_{b}(t)=_{X_{t}}[_{t}(X)|_{b},_{t- 1}]\), \(b\{0,1\}\). Then, we write the null and alternative hypothesis as

\[H_{0}:_{t}=0\ \  t 1, H_{1}:\,T \ \ \ _{t}>0\ \  t T.\] (10)

Of course, \(H_{0}\) and \(H_{1}\) do not cover the space of possibilities. In particular, neither contains the event that \(_{1}(t)_{0}(t)\) for some finite interval \(t[a,b]\) and are otherwise equal. However, we believe (10) strikes a desirable balance between analytical tractability and practical utility; defining \(H_{1}\) such that we will reject the null for each finite window \([a,b]\) places too extreme a burden on the growth of the wealth process. Moreover, as illustrated by Figure 2, if \(_{t}>0\) for a large enough window, then our sequential tests will reject the null.

If we are working with randomized data collection policies per Section 3.2, then one should change the definition of the weights in Equation (5) to incorporate the time-varying distribution \(_{t}\). That is, \(_{t}^{b}(x)=_{t}^{b}(x)/_{t}^{b}(x)\). Otherwise, all procedures detailed in the previous sections remain the same, and we can provide the following guarantee on their performance.

**Proposition 3**.: _Algorithm 1 with input \((0,1)\) and letting strategies (2) and (7) is a level-\(\) sequential test for problem (10). It has power one under the alternative if \(_{}:=_{t n}_{t}>0\) where \(n\) is some time at which drift begins. Moreover, under the alternative the expected stopping

Figure 2: Two illustrations of our sequential test adapting to distribution shift. In both settings, the observations at time \(t\) are Bernoulli with bias determined by the respective mean at that time. Shaded areas in the bottom plots represent the standard deviation across 100 trials. **Left:** For the first 100 time steps, we have \(_{0}(t)=_{1}(t)=0.3\). At time \(100\), \(_{1}(t)\) begins to smoothly slope upward. **Right:** Here we assume that both means are non-stationary and non-smooth. Both are sinusoidal with Gaussian noise but \(_{1}(t)\) drifts slowly upwards over time.

time \(\) obeys_

\[[] n+^{2}} ^{2}}.\] (11)

_Furthermore, if the data are gathered by randomized policies \(_{t}^{b}\) and \(L_{}>0\) for \(L_{}\) as in Proposition 2, then the expected stopping time follows by replacing \(_{}\) in (14) with \(_{}L_{}\)._

Let us make two remarks about this result. First, the condition \(_{}>0\) ensures that, after some point, the means \(_{0}(t)\) and \(_{1}(t)\) remain separated. If they diverge only to later reconverge, there is no guarantee that the test will reject (though, in practice, it will if they are separated for sufficiently long). Second, the reader may have guessed that the expected stopping time under drift beginning at time \(n\) follows from Propositions 1 and 2 after simply adding \(n\). However, it is a priori feasible that the reliance of ONS on past predictions would result in slower convergence under distribution shift. Proposition 3 verifies that this is not the case, and that the rate is the same up to constants.

### Composite Nulls

In practice, it may be unreasonable to require that the means between two groups are precisely zero. Instead, we may only be interested in detecting differences greater than \(\) for some \(0< 1\). In this case we may write the null and alternative as

\[H_{0}:|_{0}-_{1}|\ \ \ H_{1}:|_{0}-_{1}|>.\] (12)

To formulate our test, we introduce two pairs of auxiliary hypotheses: \(H_{0}^{}:_{0}-_{1}\) vs \(H_{1}^{}:_{0}-_{1}>\) and \(H_{0}^{}:_{1}-_{0}\) vs \(H_{1}^{}:_{1}-_{0}>\). Observe that if either \(H_{0}^{}\) or \(H_{0}^{}\) is false, then the alternative \(H_{1}\) is true. Our approach will therefore entail testing both \(H_{0}^{}\) vs \(H_{1}^{}\) and \(H_{0}^{}\) vs \(H_{1}^{}\). Let \(_{0}^{Q}\) denote the sequential test for the former, and \(_{t}^{R}\) for the latter. The test given by \(_{t}=\{_{t}^{Q},_{t}^{R}\}\) (i.e., rejecting \(H_{0}\) if _either_\(H_{0}^{}\) or \(H_{0}^{}\) is rejected) is then a test for (12). Game-theoretically, this can be interpreted as splitting our initial capital in half and playing two games simultaneously. To test \(H_{0}^{}\) and \(H_{0}^{}\) consider the two payoff functions

\[Q_{t}(_{t}^{0},_{t}^{1})=1+_{t}( _{t}^{0}-_{t}^{1}-),\ \ \ \ R_{t}(_{t}^{0},_{t}^{1})=1+_{t}( _{t}^{1}-_{t}^{0}-).\] (13)

If \(_{t}[,]\) then both \(Q_{t}\) and \(R_{t}\) are nonnegative. We thus select \(_{t}\) via ONS as usual. The wealth processes \((_{t}^{Q})\) and \((_{t}^{R})\) defined by \(Q_{t}\) and \(R_{t}\) (i.e., \(_{t}^{Q}=_{i t}Q_{i}(_{i}^{0},_{i}^{1})\) and \(_{t}^{R}=_{i t}R_{i}(_{i}^{0},_{i}^{1})\)) are then nonnegative supermartingales under \(H_{0}^{}\) and \(H_{0}^{}\), respectively. We reject \(H_{0}\) if either \(_{t}^{R} 2/\) or \(_{t}^{Q} 2/\) which results in an overall level-\(\) sequential test.

**Proposition 4**.: _Algorithm 1 with input \(/2(0,1)\) with betting strategy \(Q_{t}\) (resp., \(R_{t}\)) is a level-\(/2\) sequential test for \(H_{0}^{}\) vs \(H_{1}^{}\) (resp., \(H_{0}^{}\) vs \(H_{1}^{}\)). Rejecting \(H_{0}\) if either \(H_{0}^{}\) or \(H_{0}^{}\) is rejected results in a level-\(\) sequential test with asymptotic lower one for problem (12). Let \(=|_{0}-_{1}|\). Then, under the alternative the expected stopping time \(\) obeys_

\[[]} }.\] (14)

Figure 3: Comparisons of false positives rates (FPRs) and stopping times on credit loan data and US census data. The left two columns plot \(\) under \(H_{1}\) versus the FPR as \(\) is varied from 0.1 to 0.01. The FPR is grossly inflated when under method M1, as illustrated the first and third columns. Betting is a Pareto improvement over the permutation tests.

We note that under the alternative, \(<\), so \(0<-<\). Proposition 4 states that the expected stopping time depends on the interplay of \(\) and \(\), and will increase as they approach each other. This is intuitive. For a fixed \(\) one would expect that the problem becomes harder as \(\).

## 4 Experiments

Here we provide several sets of experiments to demonstrate the benefits of our sequential test compared to fixed-time tests.2 First we need to consider how fixed-time tests might be applied in practice to deal with sequential settings. We consider two such methods.

**M1.** For some prespecified \(k\), wait until we have collected \(k\) audits, then perform the test. If the test does not reject, collect another \(k\) audits and repeat. We emphasize that if one does not adjust the significance level over time, then _this is not a valid level-\(\) test_. However, it may be used unwittingly in practice, so we study it as one baseline.

**M2.** We batch and test in the same way as above, but we apply a Bonferroni-like correction in order to ensure it is level \(\). More precisely, for the \(j\)th-batch, \(j 1\), we set the significance level to \(/2^{j}\). The union bound then ensures that the FPR is at most \(\) over all batches.

We run experiments on three real world datasets: a credit default dataset , US census data , and health insurance data . All can be made to violate equality of opportunity if trained with naive models; we provide the details in Appendix D. Suffice it to say here that the absolute difference in means, \(\), is \(\) 0.03 for the credit default dataset, \(\) 1.1 for the census data, and \( 0.06\) for the insurance data. We employ various distinct models to test our methods, from forest-based models to logistic regression. We use a permutation test as our baseline fixed-time test because of its ubiquity in practice, exact type-I error control under exchangeability, and minimax optimality in various scenarios .

Figure 3 compares the results of Algorithm 1 (betting strategy (2)) with the permutation test baselines M1 and M2. The left two columns plot the empirical false positive rate (FPR) against the stopping time under the alternative. Values concentrated in the lower left corner are therefore preferable. We plot values for each test as \(\) is varied from 0.01 to 0.1. The betting test typically Pareto-dominates the (stopping time, FPR) values achievable by the baselines. In a small number of cases, M1 (baseline without Bonferroni correction) achieves a faster stopping time; however, this is only possible with a very high FPR (> 0.5). This inflated FPR is verified by the final column, which shows that M1 does not respect the desired type-I error rate. This encourages the use of the Bonferroni-style correction of M2. However, doing so results in an overly conservative test which is slower to reject than betting, as seen in the center column of Figure 3. Betting, meanwhile, respects the desired FPR over all \(\), and almost always has the fastest stopping time at any given FPR. We note that while it may appear that the permutation tests improve as \(k\) gets larger, this trend does not hold for large \(k\). Indeed, \(k\) is

Figure 4: Response of the tests to distribution shift on the census data. We use a fair model for 400 timesteps, after which we switch to an unfair model with \( 1.0\). The leftmost plot uses permutation tests under M1, resulting in inflated type-I error. Values are plotted as \(\) ranges from 0.01 to 0.1.

also the minimum rejection time for the permutation test. Increasing \(k\) to 1,500 on the credit default dataset, for instance, would result in vertical line at \(=1,500\).

The robustness of betting to distribution shift is illustrated by Figure 4. Here we use a fair model for the first 400 timesteps, after which we switch to a random forest classifier which is unfair (\( 1.1\)). The rejection time for all tests suffers accordingly, but betting remains a Pareto improvement over the permutation tests using M2. As before, using M1 results in an enormous FPR. Interestingly, we see that M2 also results in FPR higher than 0.1 (the maximum value of \(\)) a nontrivial percentage of the time. Indeed, under distribution shift, the the permutation test using M2 is no longer level-\(\) since the data are not exchangeable. Betting, on the other hand, maintains its coverage guarantee.

Finally, Figure 5 illustrates the performance of various algorithms when audits are not conducted on predictions received uniformly at random from the population (discussed in Section 3.2). Instead, predictions were received based on an individual's region. We test three distinct strategies, \(_{1}\), \(_{2}\) and \(_{3}\), each of which deviates from the population distribution to varying degrees (LHS of Figure 5). As expected, the rejection time of our strategy suffers compared to when the predictions are received uniformly from the population (denoted by the red crosses). The desired level-\(\) guarantee is still met, however, and betting continues to outperform permutation tests in all cases.

## 5 Summary

We have argued that practitioners in the field of algorithmic fairness should consider adopting sequential hypothesis tests in lieu of fixed-time tests. The former enjoy two desirable properties absent in the latter: (i) the ability to continually monitor incoming data, and (ii) the ability to reject at data-dependent stopping times. Both (i) and (ii) are useful for high-stakes and/or time-sensitive applications in which fixing the budget beforehand and waiting for more data to arrive may be unsatisfactory, such as auditing the fairness of healthcare models  or resource allocation strategies during a public health crisis [55; 56]. We provided a sequential test with asymptotic power one for group fairness (Algorithm 1) inspired by the paradigm of game-theoretic probability and statistics [25; 21; 28]. It is fast, easy to implement, and can handle time-varying data collection policies, distribution shift, and composite nulls, all of which are common in practice. We also provided bounds on the expected stopping time of the test. We hope that the simplicity of our methods combined with their strong theoretical guarantees prove useful for practitioners in the field.

**Limitations and societal impact.** Auditing is a complex socio-technical problem which involves a range of questions: choosing appropriate audit targets, gaining access to data, ensuring the credibility and independence of external auditors, creating accountability based on audit results, and more . Indeed, poorly designed audits may certify that a system is "fair" while masking harder to verify issues such as data provenance. Our work addresses only one portion of the overall auditing task: providing statistically sound methods for the sequential testing of a specific criteria. This is complementary to, and does not substitute for, careful overall design of an auditing framework.

Figure 5: Illustration of our betting method when using various data collection strategies, \(_{1}\), \(_{2}\), and \(_{3}\), which were based on each individualâ€™s region (NE, NW, SE, SW). Operationally, \(_{i}\) samples an individual by first sampling a region with the given probability, and then sampling an individual uniformly at random from that region. We compare results against our method with data sampled uniformly from the population (red crosses), and to permutation tests (M2), also with uniformly sampled data. Even with randomized policies, we continue to outperform permutation tests.

**Acknowledgements.** We thank Jing Yu Koh and Shubhanshu Shekhar for helpful conversations. We also thank the anonymous referees for helpful feedback which improved the paper. BC and AR acknowledge support from NSF grants IIS-2229881 and DMS-2310718. BC was supported in part by the NSERC PGS D program, grant no. 567944. BW and SCG were supported in part by the AI2050 program at Schmidt Futures, grant no. G-22-64474.