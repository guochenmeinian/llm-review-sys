# Not so griddy: Internal representations of RNNs path integrating more than one agent

William T. Redman

Intelligent Systems Center

Johns Hopkins Applied Physics Laboratory

&Francisco Acosta

Department of Physics

University of California, Santa Barbara

&Santiago Acosta\(-\)Mendoza

Dynamical Neuroscience

University of California, Santa Barbara

&Nina Miolane

Department of Electrical & Computer Engineering

University of California, Santa Barbara

will.redman@jhuapl.edu

###### Abstract

Success in collaborative and competitive environments, where agents must work with or against each other, requires individuals to encode the position and trajectory of themselves and others. Decades of neurophysiological experiments have shed light on how brain regions [e.g., medial entorhinal cortex (MEC), hippocampus] encode the self's position and trajectory. However, it has only recently been discovered that MEC and hippocampus are modulated by the positions and trajectories of others. To understand how encoding spatial information of multiple agents shapes neural representations, we train a recurrent neural network (RNN) model that captures properties of MEC to path integrate trajectories of two agents simultaneously navigating the same environment. We find significant differences between these RNNs and those trained to path integrate only a single agent. At the individual unit level, RNNs trained to path integrate more than one agent develop weaker grid responses, stronger border responses, and tuning for the _relative_ position of the two agents. At the population level, they develop more distributed and robust representations, with changes in network dynamics and manifold topology. Our results provide testable predictions and open new directions with which to study the neural computations supporting spatial navigation.

## 1 Introduction

When navigating real-world environments, individual agents (e.g., animals) must adjust their trajectories based on the observed trajectories of others . This becomes especially important in competitive and collaborative settings, where the positions, movement directions, and speeds of others contain information necessary for goal-based decision making. For example, an agent competing with others for food must keep track of where "opponent" agents are and where they are headed, in order to effectively update its strategy. While decades of research has shed fundamental light on the neural circuitry involved in spatial navigation in the absence of others ("single agent" navigation), little is known about how the brain enables spatial navigation in the more general "multi-agent" scenario.

A core component of spatial navigation is _path integration_, the ability to update an estimate of position in an environment from a sequence of movement directions and speeds (Fig. 1A). Medial entorhinal cortex (MEC) is believed to play a critical role in supporting path integration via functional classes of neurons , such as grid cells , border cells , and band cells . Recent research has shown that MEC is activated when human subjects observe others navigateenvironments [9; 10], suggesting that it may additionally be involved in computations supporting multi-agent path integration. That neural activity in MEC could be shaped by trajectories of others is further supported by recent work demonstrating that populations of cells in hippocampus and anterior cingulate cortex, brain regions interconnected with MEC, encode spatial information related to the positions of other agents [11; 12; 13; 14; 15; 16; 17]. However, what representations exist in MEC to support multi-agent path integration and how they differ from the representations that have been found in single agent environments, remains largely unexplored. This is of additional importance as it is unclear whether continuous attractor networks (CANs) [18; 19; 20], which are believed to underlie the grid code in MEC [21; 22; 23; 24; 25], can simultaneously support the encoding of multiple individuals [26; 27].

To begin to investigate this open research direction, we train a recurrent neural network (RNN) model to perform path integration of two agents ("dual agent" path integration2) and interrogate the representations that emerge. These RNN models [28; 29], when trained on single agent path integration, have been shown to develop properties analogous to MEC. In particular, they exhibit units with grid, border, and band responses [28; 29; 30] and population dynamics consistent with continuous toroidal attractors [31; 32].

While their biological plausibility remains unclear [33; 34], we choose to analyze these RNN models for four reasons. First, they contain inter-connectivity between "hippocampus"\(-\)like and "MEC"\(-\)like layers, enabling us to model aspects of the experimentally reported multi-agent hippocampal responses [11; 12; 13; 14; 16; 17]. Second, the lack of neural data from MEC in multi-agent settings makes the outputs of these RNN models unbiased predictions that can be used to further assess their validity. Third, these RNN models have been shown to have response properties beyond grid, border, and band cells that are similar to those in MEC recordings , suggesting that the RNNs learn solutions more broadly representative of MEC. And fourth, beyond their connection to neuroscience, these RNN models represent legitimate machine learning systems that exhibit improved goal-based navigation when paired with reinforcement learning . As autonomous agents becoming increasingly deployed in everyday environments, their ability to navigate in multi-agent settings becomes increasingly important  and understanding how the representations learned by RNN models trained on single and dual agent path integration compare can provide new insight into how to improve this capability.

We find that, with only a few modifications, we can train existing RNN models [28; 29] to achieve good performance on dual agent path integration ("dual agent RNNs"\(-\)Sec. 2). These dual agent RNNs are flexible enough to generalize to single agent path integration, whereas RNNs trained on single agent path integration ("single agent RNNs") are not capable of performing dual agent path integration (Sec. 3.1), demonstrating how representations that are optimal in the single agent setting need not be in the dual agent setting. Investigating the learned representations, at the individual unit level, we find that the need to path integrate more than one agent leads to the emergence of stronger border representations and weaker grid representations (Sec. 3.2), a result consistent with recent human neurophysiological experiments [9; 10]. Measuring the representations in a reference frame that captures the joint position of both agents, we find that units in dual agent RNNs develop tuning for "relative space" (Sec. 3.3). Collectively, these results provide insight into how the dual agent RNN is able to efficiently solve its task. Utilizing topological and dynamical tools, we characterize differences between single and dual agent RNNs at the population level (Sec. 3.4), finding no evidence for continuous toroidal attractors underlying the activity of dual agent RNNs which further emphasizes their distinct computational mechanisms. These results question how our existing understanding of MEC can be extended to the ethologically relevant multi-agent setting, and we hope our that they will motivate future experimental and theoretical exploration.

**Contributions.** We study, _for the first time_, how representations that emerge in RNNs trained on dual agent path integration differ, at the individual unit and population level, from the representations of single agent RNNs. Our results are consistent with recent neurophysiological experiments [9; 10] and provide testable predictions that can guide future experimental design.

## 2 RNN model

Prior work has considered the setting where a single agent traverses a square environment through finite length paths [28; 29; 30]. The agent starts a given path at position \((0)=[x(0),y(0)]^{}[-/2] [-/2]\) and subsequently moves to positions \((0)(1)...(T)\). This path can alternatively be defined by \((0)\) and a sequence of movement directions, \((t)[-,]\), and speeds, \(v(t)[0,)\), such that \((t+1)=(t)+v(t) t[(t),\, (t)]^{}\), for small \( t^{+}\) (Fig. 1A). The accurate updating of \((t+1)\) from only \((t)=[(t),\,v(t)]^{}\) is formally what is meant by **path integration**.

To learn an RNN model that can perform single agent path integration, prior work has utilized the following architecture (Fig. 1B). The inputs \((t)\) are projected, via weights \(^{}^{n_{G} 2}\), into a recurrent layer of \(n_{G}\) units. This recurrent layer has connectivity defined by weights \(^{}^{n_{G} n_{G}}\). The units in the recurrent layer are used to drive the activation of \(n_{P}\) output units, via weights \(^{}^{n_{P} n_{G}}\). More explicitly, the RNN model evolves via the dynamics

\[(t+1)=[^{}(t)+^{ }(t)],\] (1)

\[}(t+1)=^{}(t+1),\] (2)

where \((t)^{n_{G}}\) and \(}(t)^{n_{P}}\) are the activations of the recurrent and output units at time \(t\), and \(()\) is an activation function.

The RNN model, defined by Eqs. 1\(-\)2, is trained by comparing the output layer activations, \(}(t)\), with "ground truth" activations, \((t)\), using the cross entropy loss,

\[(t)=-}(t)(t)-||^{ }||_{2}.\] (3)

The second term, \(||^{}||_{2}\), is a weight decay regularization term that penalizes the \(L_{2}\) norm of the recurrent weights, by strength \(^{+}\). This was found to be beneficial for generalization . The form \((t)\) takes has been shown to determine properties of the representations learned by the single agent RNNs . We follow Sorscher et al. (2019) and set the ground truth activations to be "place cell"\(-\)like , with the place fields having a difference of Gaussian (DoG) structure  (Fig. 1C),

\[p_{i}(t)=[(t),\,_{i}]=-||(t )-_{i}||_{2}^{2}/2_{1}^{2}--||(t) -_{i}||_{2}^{2}/2_{2}^{2},\] (4)

where \(p_{i}(t)\) is the ground truth activation of unit \(i\) at time \(t\), \(_{i}[-/2,\,/2][-/2,\,/2]\) is the center of its place field, and \(_{1}<_{2}\) define the place field's size. The initial activation in the recurrent layer is set using the ground truth place cell activations, \((0)=^{}(0)\), where \(^{}^{n_{G} n_{P}}\) is a learnable set of weights.

To assess the RNN model's performance in single agent path integration, the position of the agent is decoded from the activations of the output layer. Prior work has used a simple top-\(n_{d}\) decoder, where the predicted location of the agent is found by averaging the place field centers, \(_{i}\), corresponding

Figure 1: **Overview of RNNs trained to perform single agent path integration.** (A) Illustration of path integration task. The agent starts at known position \(x(0)\) and \(y(0)\) and makes a sequence of movements through space given by the movement directions \((t)\) and speeds \(v(t)\). From this, \(x(t+1)\) and \(y(t+1)\) must be estimated. (B) Schematic of single agent RNN model architecture [28; 29], which takes input \(v(t)\) and \((t)\), recurrently processes it, and drives activations of an output layer. (C) Example ground truth place cell (PC) activations used as targets for the RNN output units.

to the \(n_{d}\) units in the output layer with the highest activations. That is, \(}(t)=}_{i=1}^{n_{d}}_{_{i}}(t)\), where the \(_{i}\) correspond to the ranked order of the output layer activations [i.e., \(_{_{1}}(t)>_{_{2}}(t)>...>_{_{n_{p}}}(t)\)]. The decoding error is then defined as \(||(t)-}(t)||_{2}\).

To enable the RNN model to perform dual agent path integration, we make four modifications (see Appendix B and Table S1, for more details):

* **Additional inputs:** We set \((t)=[_{1}(t)\), \(v_{1}(t)\), \(_{2}(t)\), \(v_{2}]^{}\), where \(_{i}(t)\) and \(v_{i}(t)\) correspond to the \(i^{}\) agent's movement direction and speed at time \(t\).
* **Summed place cell activations:** We set the ground truth place cell responses to be the sum of their responses to the location of each agent independently. That is, if \(_{i}(t)\) corresponds to the position of the \(i^{}\) agent at time \(t\), then \(p_{i}(t)=[_{1}(t),\,_{i}]\) + \([_{2}(t),\,_{i}]\). This choice, inspired by "social" place cells [11; 12; 13; 14; 16; 17], is an important one and we provide our rationale in choosing it in Appendix B.1.
* \(k\)**-means clustering for decoding:** We use \(k\)-means clustering to separate the place field centers corresponding to the \(2n_{d}\) output layer units with the highest activations into \(k=2\) groups. The predicted positions of the two agents, \(}_{1}(t)\) and \(}_{2}(t)\), are estimated by the center of each cluster.
* **Reduced weight decay regularization:** We reduce the weight regularization strength, \(\), in the loss function (Eq. 3), as we expect the added complexity of dual agent path integration to require more of \(^{}\)'s capacity.

Training this modified RNN on dual agent path integration, we show\(-\)for the _first time\(-\)_that it is possible to learn a network that achieves high performance (Figs. 2, S1). While the decoding error of dual agent path integration is greater for dual agent RNNs than the decoding error of single agent path integration is for single agent RNNs (Fig. 2A, B), we find that nearly \(50\%\) of all \(5000\) dual agent trajectories sampled have an error below \(0.10\) m, which was previously used as a threshold to determine success  (Fig. 2B). In addition, visualizing the RNN's prediction on individual dual agent trajectories shows qualitatively similar behavior to the true trajectories, even when decoding error is \(>0.10\) m. (Fig. 2C). Examining the trajectories where the two agents are closest to each other (Fig. S2), we find the dual agent RNN is able to maintain its performance. As hypothesized, reducing the strength of weight decay, from \(=10^{-4}\) to \(=10^{-6}\), enables an increase in performance on dual agent path integration (Fig. 2A\(-\)compare pink solid and dashed lines).

## 3 Results

### Representations in single agent RNNs are not optimal for dual agent path integration

The discovery that recurrent units in RNNs trained on single agent path integration (Sec. 2) develop responses like those found in MEC [28; 29; 30; 35] has been interpreted as a normative demonstration of the optimality of these representations. Are these same representations also optimal for dual agent path integration?

To test this, we apply trained single agent RNNs to the dual agent setting (Appendix C). These networks have a decoding error of \( 1.0\) m. (Fig. 3A\(-\)red dot), nearly a \(10\) increase in error relative to the trained dual agent RNNs (Fig. 3A\(-\)pink solid line). To determine whether this high decoding error is due to poor generalization or to the RNN being sensitive to the precise value of the network weights, we "fine-tune" all the trained single agent RNN weights (\(^{}\), \(^{}\), \(^{}\), \(^{}\)) for 10 epochs on the dual agent path integration task (Appendix C). We find that this leads to an improvement in performance on dual agent path integration, although the end decoding error remains higher than the decoding error of the trained dual agent RNN (Fig. 3A\(-\)compare solid red and pink solid lines). However, this improvement is dependent on updating the trained weights in the recurrent layer, as freezing \(^{}\) and fine-tuning the other weights again leads to high decoding error (Fig. 3A\(-\)red dashed line). Taken together, these results demonstrate that the representations learned by the recurrent units in trained single agent RNNs are not optimal for dual agent path integration.

In contrast, trained dual agent RNNs can perform single agent path integration with decoding error \(<0.10\) m. (Fig. 3B\(-\)green dot). Fine-tuning the weights on single agent path integration further improves performance, even when \(^{}\) is frozen (Fig. 3B\(-\)green dashed line). This is aligned with recent experimental and computational work showing that fixed MEC connectivity and slow time-scale plasticity between MEC and hippocampus enables generalizable representations of new environments . These results (which exhibit a similar trend when comparing the training loss instead of the decoding error\(-\)Fig. S3) demonstrate that dual agent RNNs have internal representations that are flexible enough to enable generalization to single agent path integration.

### Single and dual agent RNNs develop different representations at the individual unit level

To begin dissecting the representations that emerge in dual agent RNNs, we examine the functional properties of individual units in the recurrent layer. Previous work has found that single agent RNNs develop responses analogous to three functional classes of neurons in MEC: grid cells [5; 6], border cells , and band cells . The distribution of these properties can be quantified by computing scores

Figure 3: **Dual agent RNNs can generalize to single agent path integration, but not vice versa.** (A) Decoding error of RNNs trained on single agent path integration and tested on dual agent path integration with (red lines) and without (red dot) fine-tuning (FT) on dual agent path integration. Converged performance and performance from random initialization of dual agent RNNs (dashed and solid pink lines, respectively) are shown for comparison. (B) Same as (A), but for RNNs trained on dual agent path integration and tested on single agent path integration. (A)\(-\)(B) Lines denote mean and shaded area denotes maximum and minimum, across 5 independently trained RNNs.

Figure 2: **RNNs can be trained to successfully perform dual agent path integration.** (A) Decoding error, as a function of training epoch, for RNNs trained and tested on single and dual agent path integration. Solid line is mean across 5 independently trained networks and shaded area is maximum and minimum of all 5 networks. (B) Distribution of median decoding error, across 5000 trajectories (1000 per network), for single and dual agent RNNs. (C) Example ground truth and decoded dual agent trajectories. Trajectories were chosen as those closest to the \(0^{}\), \(25^{}\), \(50^{}\), and \(75^{}\) percentile of the decoding error distribution.

for each unit (Appendix D.2). While grid and border scores are standard metrics, to our knowledge no band score exists. We therefore developed a metric to quantify "banded\(-\)ness" (Appendix D.2).

We find statistically significant differences in the distribution of these functional properties between single and dual agent RNNs (Fig. 4A, B). In particular, we find dual agent RNNs develop units with lower grid scores, but higher border and band scores (Fig. 4A). Visualizing rate maps associated with the dual agent RNN units that have the highest grid scores, we find that many have responses that are not solely constrained to vertices of triangular lattices, but are instead "honeycomb"\(-\)like (Fig. 4B). This suggests that dual agent path integration leads to a weaker grid code. In contrast, dual agent RNN units with high border and band scores have more "ideal" responses, as compared to units of single agent RNNs, which have additional grid structure (Fig. 4B). This demonstrates that dual agent path integration leads to a strengthened border and band code. These results are consistently observed across all 5 independently trained RNNs (Fig. S4).

Figure 4: **Single and dual agent RNNs differ in their distribution of functional properties.** (A) Distribution of grid, border, and band scores, computed for all units of single and dual agent RNNs. Distribution includes 5 independently trained RNNs. Kolmogorov-Smirnov (KS) test used to compare distributions (\(**:p<0.01\)). (B) Visualization of rate maps (Appendix D.1) for units, from individual RNNs, with highest grid, border, and band scores. (C) Decoding error of trained RNNs with the units corresponding to the highest grid, border, and band score ablated (solid line: mean across 5 independently trained RNNs), compared to trained RNNs with random units ablated (dashed lines: mean across 10 randomly sampled choices of ablated units for each independently trained RNN; shaded area: \(\) standard deviation) (Appendix D.3). Mann-Whitney test is used to compare distributions (\(*:p<0.05\) and \(**:p<0.01-\)see Table S2 for \(p\)-values).

Prior work has found all three of these classes to be important for single agent path integration [28; 30; 31; 32; 39; 40]. To understand their importance in dual agent path integration, we perform targeted ablations, removing units with the highest grid, border, and band scores (Appendix D.3). We compare the decoding error of these RNNs to RNNs with randomly removed units, as this has been found to be a strong baseline [31; 35]. Unlike single agent RNNs, which have a significant increase in decoding error relative to the random baseline with the ablation of all functional classes, dual agent RNNs are less sensitive to the ablation of any one functional class (Fig. 4C). This suggests that dual agent RNNs develop a more distributed and robust representation. We note that the greater (albeit, small) sensitivity of the dual agent RNNs to ablations of border and band cells are consistent with work arguing their driving role in path integration [30; 31; 39; 40].

To determine the extent to which our results are due to the nature of dual agent path integration, as opposed to specific choices of RNN architecture and hyper-parameters, we perform several control experiments. First, we consider the possibility that, by having twice as many agents to track, dual agent RNNs have half the effective size of single agent RNNs. In such a case, we might expect a smaller single agent RNN to generate responses similar to those of dual agent RNNs. However, half-sized single agent RNNs have representations that are distinct from the full-sized dual agent RNNs (Fig. S5A). Second, dual agent rate maps are computed using the position of only one of the two agents (the other agent being "averaged out"--Appendix D.1). We re-compute the rate maps of dual agent RNNs, removing one of the agents completely. Thus, while the network was trained in the dual agent setting, the rate maps are only affected by a single agent. We find this to have little effect on the representations (Fig. S5B). Third, we vary the agent whose position is being used to construct the rate map. We find that the rate maps are nearly identical (Fig. S6). Given that there is nothing in the loss function (Eq. 3) that distinguishes the two agents, it is not surprising that the dual agent RNN treats them the same. Finally, we measure the distribution of grid, border, and band scores for the RNNs trained with greater weight decay regularization (Fig. 2A--dashed lines). We find that the overall trend of dual agent path integration leading to lower grid scores and higher border scores, relative to single agent path integration, holds (Fig. S7).

Taken together, these results demonstrate that the addition of another dynamic variable (i.e., a second agent) leads to differences in the distribution of functional properties, at the individual unit level, between single and dual agent RNNs.

### Dual agent RNNs develop tuning in relative space

Recent neural recordings have demonstrated that, when mice are trained to navigate to reward sites that move in physical space, grid cells perform path integration in reference frames that are anchored to the locations of these rewards . These results highlight the fact that hippocampus and MEC can perform computations in different coordinate systems . Inspired by these results, we examine whether dual agent RNNs develop grid responses in another reference frame. One candidate coordinate system is defined by the relative positions of the two agents ("relative space"--Fig. 5A, Appendix E). We do not find evidence for units having grid responses in relative space (Fig. 5B, C), demonstrating that dual agent RNNs are not simply using the same representations as in the single agent setting, but in a different reference frame. However, we find that units classified as border and band cells in the absolute (i.e., allocentric) reference frame have strong tuning in relative space (Fig. S8A). Units with high border score have greatest activations when both agents are near borders (Fig. S8A, B) and units with high band score have greatest activations when both agents are positioned at periodic distances, along parallel lines (Fig. S8A, B). The latter could enable easy representation of parallel movement, where the agents are naturally separated. In contrast, units with high grid score have activations that are largely invariant to relative space (Fig. S8A, B).

To further characterize the extent to which dual agent RNNs encode relative position, we compute the spatial information  of all recurrent units relative space rate maps (Appendix E.2). We find that, while most units contain little spatial information in relative space (corresponding to spatial information \( 0\)), the distribution is heavy tailed (Fig. 5D). Visualizing the relative space rate maps with the highest spatial information, we find that many are localized, with greatest activation when the two agents are near each other (Fig. 5E\(-\)center pixels). We hypothesize that, because accurate dual agent path integration becomes more challenging as the two agents get closer together, ablating units with high spatial information in the relative space reference frame would lead to an increase in decoding error. In-line with this hypothesis, we find that removing the units with the highest relative space spatial information leads to a statistically significant decrease in decoding performance, relative to the random ablation baseline (Fig. 5F, Appendix E.3). That this ablation leads to stronger deficits than the ablation of grid, border, and band cells (Fig. 4C), emphasizes of their importance in supporting dual agent path integration. Further, it demonstrates that the dual agent RNN utilizes an efficient representation (encoding the _relative_ position) to achieve dual agent path integration.

### Single and dual agent RNNs learn different representations at the population level

Our comparison of the representations that emerge in single and dual agent RNNs has thus far been focused on the activations of individual recurrent units. Our findings that dual agent RNNs develop different distributions of functional classes than single agent RNNs, and that dual agent RNNs encode relative space spatial information, are suggestive that the network structure underlying single and dual agent RNNs are distinct. To further explore this hypothesis, we analyze the recurrent unit activations at the population level.

Topological data analysis (TDA)  has become a widely used tool for studying neural population activity [25; 45; 46; 47; 48; 49; 50]. A core technique in TDA is persistent homology (Appendix F.1), which can be used to estimate the topology of the underlying neural manifold. Applying persistent homology, we find evidence that the population activations of single agent RNNs are constrained to a manifold having topology consistent with a two-dimensional torus (Fig. 6A, left\(-\)black arrows), consistent with prior characterizations [31; 32]. When performing the same analysis on the population activations of dual agent RNNs, we find differences in the persistent homology. In particular, the topological signatures of a two-dimensional torus are not clearly present in the persistence diagram (Fig. 6A, right). We see similar patterns in the persistence diagrams across different independently trained single and dual agent RNNs (Fig. S9). This difference in topology can further be seen by the fact that the persistence diagrams corresponding to single agent RNNs are closer (with respect to an appropriate metric ) to the persistence diagrams of an idealized torus, than the persistence diagrams corresponding to the dual agent RNN are (Fig. S10). This suggests that dual agent RNNs **do not** have the same continuous attractor structure that single agent RNNs have [31; 32].

Figure 5: **Dual agent RNNs develop tuning to “relative space”.** (A) Schematic illustration of a transformation from the allocentric reference frame to the relative space reference frame. (B) Distribution of grid scores (across 5 independently trained RNNs), computed on the relative space rate maps (Appendix E.1). (C) Visualization of relative space rate maps, from an individual dual agent RNN, with the highest relative space grid scores. (D) Distribution of spatial information, computed on the relative space rate maps. Distribution includes 5 independently trained RNNs. (E) Visualization of relative space rate maps, from an individual dual agent RNN, with the highest relative space spatial information. (F) Decoding error of dual agent RNNs with units having the highest relative space spatial information ablated. Dashed line and shaded area same as Fig. 4C. Mann-Whitney test is used to compute \(p\)-values (\(**:p<0.01-\)see Table S3 for statistics).

The topology and geometry of neural manifolds do not capture all properties of the underlying neural circuit. Indeed, RNNs with the same dynamical properties (e.g., existence of fixed point attractors, limit cycles) can be constructed to have different population activation geometries . Similarly, RNNs with the same population activation geometries can be constructed to have different dynamics . Recent work has developed a data-driven dynamical systems framework [dynamic similarity analysis (DSA)] for computing compact representations of RNN dynamics . Therefore, we complemented our TDA results by applying DSA (Appendix F.2) to the population activations of single and dual agent RNNs. We find that independently trained single agent RNNs are dynamically more similar to each other than they are to independently trained dual agent RNNs, and vice versa (Fig. 6B). Therefore, at both the topological and dynamical level, the representations learned by the single and dual agent RNN are different, suggesting that the addition of a second agent fundamentally changes the network structure that emerges.

## 4 Discussion

Inspired by recent work demonstrating that brain regions believed to encode the self's position and trajectory (e.g., MEC, hippocampus) are modulated by the position and trajectories of others [9; 10; 11; 12; 13; 14; 16], we trained a class of RNN models [28; 29] to path integrate two agents and investigated the representations that emerged. Given that these RNN models, when trained to path integrate single agents, develop properties that are similar to those found in MEC at the individual unit (e.g., grid, border, and band responses) and population (e.g., network structure with signatures of continuous toroidal attractors) level, this is a natural point for starting to address the larger question of how the MEC supports representation of multiple dynamic variables.

We find that the representations that emerge in dual agent RNNs significantly differ from those of single agent RNNs. Dual agent path integration leads to weaker grid codes and stronger border codes (Fig. 4). This is consistent with electrophysiological recordings that have found MEC encodes distance of others to boundaries  and fMRI recordings that have observed a negative correlation between grid cell strength and performance on multi-agent tasks . Functional class ablations and TDA revealed a distributed and robust representation, with no evidence for the population activity being constrained to a two-dimensional torus (Fig. 6). Despite this, dual agent RNNs are able to generalize to perform single agent path integration, even when the weights in their recurrent layer are frozen (Fig. 3B). This demonstrates the flexibility of their representations  and is in-line with work finding that neural networks trained to perform multiple tasks develop abstract and distributed tuning [54; 55; 56; 57]. Finally, we found that RNNs trained on dual agent path integration develop tuning in the coordinate system defined by the relative position of the two agents (Figs. 5, S8). This is consistent with the tuning of neurons in anterior cingulate cortex to relative position between agents , as well as is aligned with neurophysiological experiments that have uncovered neurons in MEC that encode distance and orientation of self to objects .

Figure 6: **Population level activations of single and dual agent RNNs differ in their topology and dynamics.** (A) Persistence diagrams (Appendix F.1) of the population activations of example single and dual agent RNNs. \(H_{1}\) bars of high filtration value correspond to existence of loops and \(H_{2}\) bars correspond to existence of two-dimensional cavities. Black arrows denote features of the single agent persistence diagram that are consistent with a two-dimensional toroidal attractor. (B) DSA (Appendix F.2) applied to the activations of independently trained single and dual agent RNNs. Color denotes Procrustes analysis over vector fields metric.

**Limitations.** The biological plausibility of the RNN models investigated in this work  have been questioned  (although, see response by Sorscher et al. (2022) ). While our dual agent ground truth place cells were motivated by experimental work measuring hippocampal responses in environments with multiple animals , it represents only one possible choice (as discussed in Appendix B). Additionally, it has been found that the RNN model develops weaker modularization in grid properties , a feature that is believed to be critical for encoding local spatial information  (although see work suggesting individual grid modules contain more spatial information than previously thought ). Recent use of loss functions that incorporate more than just path integration have found stronger grid responses and modularization . Future work should investigate the properties that emerge in these models when tasked with dual agent path integration. In our experiments, we did not account for noise in velocity inputs, which have been found to play a dominant role in human path integration error , and are presumably higher for the assessment of others' velocities (given the lack of vestibular and proprioceptive feedback). We hypothesize that, as noise is added to the estimate of one agent's position and velocity, dual agent RNNs will develop representations more similar to single agent RNNs, suggesting a trade-off that should be explored.

**Predictions.** Recent advances in experimental paradigms, where rodents must update their goal-based planning given the trajectories of others , offer the possibility of comparing the _in vivo_ representations of MEC with those generated by the dual agent RNN. Our results make several testable predictions about what responses might be found in MEC. First, we expect grid responses to be weakened, with the cells that do have high grid score exhibiting deviations from standard grid cells ("honeycomb"\(-\)like responses\(-\)Fig. 4). Second, we expect strengthened boundary and border responses (Fig. 4), with border cells responding most strongly when both agents are near borders (Fig. S8). Finally, we expect that the relative position between agents will be encoded in the a subpopulation of MEC neurons (Fig. 5) that is disjoint from cells with high grid scores (Fig. S8). Testing these predictions will provide insight into the validity of the RNN model, as well as our assumption that MEC can perform simultaneous path integration of two agents.

**Future directions.** There are several impactful directions that our work can be extended. First, analyzing the emergent properties of RNNs trained to path integrate more than two agents can lead to a better understanding of how the MEC performs computations in the multi-agent setting. Second, reinforcement learning can be used to probe how the dual agent RNN representations might support higher order behavior  (such as shortcut taking in dynamic chasing ). Third, theoretical work, showing\(-\)from first principles\(-\)what representations are necessary for single agent path integration  can be extended to the dual agent path integration setting. This will provide a thorough treatment of how the complexity of multi-agent environments changes the computations needed to be performed by MEC. Finally, foundational work on MEC has found that grid cells encode abstract relationships beyond purely spatial variables . These include social hierarchies , sound frequencies , list ordering distances , and elapsed time . Our work has implications for how the MEC may simultaneously integrate information across these different cognitive axes.

**Outlook.** Continuous attractor networks (CANs) for the grid code  are one of the few canonical models in computational neuroscience. That we find RNNs trained to perform dual agent path integration develop structure distinct from CANs is noteworthy. There are several possibilities for reconciling our results with their differences to CANs, two of which we discuss below. First, the relative space encoding that we find could be coupled with a CAN so that the resulting network path integrates the other agent by first path integrating the self and then updating the other's position estimate by using the relative spacing encoding. This kind of egocentric framework is consistent with the presence of object vector cells in MEC . Second, the grid code could be one of several codes that enables path integration, and scenarios (such as the presence of another) could lead to the reduction of the grid code for another, more suitable code. This is in-line with the negative correlation between strength of grid responses and success in a multi-agent task .

We hope that our work inspires new experiments to uncover the representations used by the brain to enable success in multi-agent environments.