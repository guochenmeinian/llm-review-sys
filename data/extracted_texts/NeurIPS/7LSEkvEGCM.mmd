# Representation Equivalent Neural Operators:

a Framework for Alias-free Operator Learning

 Francesca Bartolucci\({}^{1}\) Emmanuel de Bezenac\({}^{2}\) Bogdan Raonic\({}^{2,3}\)

Roberto Molinaro\({}^{2}\) Siddhartha Mishra\({}^{2,3}\) Rima Alaifari\({}^{2,3}\)

\(1\) Delft University of Technology, Netherlands

\(2\) Seminar for Applied Mathematics, ETH, Zurich, Switzerland

\(3\) ETH AI Center, Zurich, Switzerland

###### Abstract

Recently, _operator learning_, or learning mappings between infinite-dimensional function spaces, has garnered significant attention, notably in relation to learning partial differential equations from data. Conceptually clear when outlined on paper, neural operators necessitate discretization in the transition to computer implementations. This step can compromise their integrity, often causing them to deviate from the underlying operators. This research offers a fresh take on neural operators with a framework _Representation equivalent Neural Operators (ReNO)_ designed to address these issues. At its core is the concept of operator aliasing, which measures inconsistency between neural operators and their discrete representations. We explore this for widely-used operator learning techniques. Our findings detail how aliasing introduces errors when handling different discretizations and grids and loss of crucial continuous structures. More generally, this framework not only sheds light on existing challenges but, given its constructive and broad nature, also potentially offers tools for developing new neural operators.

## 1 Introduction

Operators are mappings between infinite-dimensional function spaces. Prominent examples are _solution operators_ for ordinary and partial differential equations (PDEs)  which map function space inputs such as initial and boundary data to the function space valued PDE solution. They are also the natural mathematical framework for inverse problems, both in the context of PDEs  and in (medical) imaging , where the object of interest is the _inverse operator_ which maps observables to the underlying material property/image that needs to be inferred or reconstructed.

Given the prohibitive cost of traditional physics based algorithms for approximating operators, particularly those associated with PDEs, increasing attention is being paid in recent years to machine-learning based _operator approximation_. Such techniques for learning operators from data fall under the genre of _operator learning_. A (by no means comprehensive) list of examples for operator learning architectures include operator networks , DeepONets , Graph neural operators , multipole neural operators , PCA-Nets , Fourier neural operators (FNO) , VIDON , spectral neural operators , LOCA , NOMAD , Continuous Generative Neural Networks  and transformer based operator learning models .

However, there is still a lack of clarity on what constitutes _operator learning?_ Clearly, an operator learning framework, or a _neural operator_ in the nomenclature of , should be able to _process functions as inputs and outputs_. On the other hand, functions are continuous objects and in practice,one may not have access to functions either at the input or output level. Instead, one can only access functions and perform computations with them on digital computers through their _discrete representations_ such as point values on a grid, cell averages or in general, coefficients of an underlying basis. Hence, in practice, neural operators have to map discrete inputs to discrete outputs. This leads to a dichotomy, i.e., neural operators are designed to process functions as inputs/outputs but only have access to their discrete representations. Consequently, at any finite resolution, possible mismatches between the discretizations and the continuous versions of neural operators can lead to inconsistencies in the underlying function spaces. These inconsistency errors can propagate through the networks and may mar the performance of these algorithms. Moreover, important structural properties of the underlying operator, such as symmetries and conservation laws, hold at the continuous level. Inconsistent discretizations may not preserve these structural properties of the operator, leading to symmetry breaking etc. with attendant adverse consequences for operator approximation.

Addressing this possible inconsistency between neural operators and their discretizations is the central point of this article. To this end, we revisit and adapt existing notions of the relationship between continuous and discrete representations in signal processing, applied harmonic analysis and numerical analysis, with respect to the questions of sampling and interpolation. Roughly speaking, we aim to find a mathematical framework in which the continuous objects (functions) can be completely (uniquely and stably) recovered from their discrete representations (point evaluations, basis coefficients, etc.) at _any_ resolution. Consequently, working with discrete values is tantamount to accessing the underlying continuous object. This equivalence between the continuous and the discrete is leveraged to define _a class of neural operators_, for which the discrete input-output representations or their continuous function space realizations are _equivalent_. On the other hand, lack of this equivalence leads to _aliasing errors_, which can propagate through the neural operator layers to adversely affect operator approximation. More concretely, our contributions are

* We provide a novel, very general unifying mathematical formalism to characterize a class of neural operators such that there is an equivalence between their continuous and discrete representations. These neural operators are termed as _Representation equivalent Neural Operators_ or ReNOs. Our definition results in an automatically consistent function space formulation for ReNOs.
* To define ReNOs, we provide a novel and precise quantification of the notion of _aliasing error for operators_. Consequently, ReNOs are neural operators with zero aliasing error.
* We analyze existing operator learning architectures to find whether they are ReNOs or not.
* Synthetic numerical experiments are presented to illustrate ReNOs learn operators without aliasing and to also point out the practical consequences of aliasing errors particularly, with respect to evaluations of the neural operators on different grid resolutions.

## 2 A short background on Frame Theory and Aliasing

We start with a short discussion, revisiting concepts on the relationship between functions and their discrete representations. This is the very essence of _frame theory,_ widely used in signal processing and applied harmonic analysis. We refer to SM D for a detailed introduction to frame theory.

Equivalence between functions and their point samples.For simplicity of exposition, we start with univariate functions \(f L^{2}()\) and the following question: Can a function be uniquely and stably recovered from its values, _sampled_ from equispaced grid points \(\{f(nT)\}_{n}\)? The classical _Whittaker-Shannon-Kotel'nikov (WSK) sampling theorem_, which lies at the heart of digital-to-analog conversion, answers this question in the affirmative when the underlying function \(f_{}\), i.e., it belongs to the _Paley-Wiener space_ of _band-limited functions_\(_{}=\{f L^{2}():[- ,]\},\) for some \(>0\), \(\) the Fourier transform of \(f\) and _sampling rate_\(1/T 2\), with \(2\) termed as the _Nyquist rate_. The corresponding reconstruction formula is,

\[f(x)=2T_{n}f(nT)(2(x-nT)),(x)=( x)/( x).\] (2.1)We note that the sequence of functions \(\{_{n}(x)=(2 x-n)\}_{n}\) constitutes an _orthonormal basis_ for \(_{}\) and denote by \(_{_{}}\,L^{2}()_{}\) the _orthogonal projection operator_ onto \(_{}\),

\[_{_{}}f=_{n} f,_{n} _{n}=_{n}f()_{n},\] (2.2)

where the last equality is a consequence of \(_{}\) being a reproducing kernel Hilbert space with kernel \(_{}(x,y)=(2(x-y))\). Hence, \(_{_{}}f\) corresponds to the right-hand side of (2.1) for \(T=1/2\) and formula (2.1) is exact if and only if \(f_{}\), i.e., \(f=_{_{}}f f_{}\).

What happens when we sample a function at a sampling rate below the Nyquist rate, i.e. when \(1/T<2\)? Alternatively, what is the effect of approximating a function \(f_{}\) by \(_{_{}}f\)? Again, sampling theory provides an answer in the form of the _aliasing error:_

**Definition 2.1**.: _Aliasing for bandlimited functions[2, SS5] The aliasing error function \((f)\) and the corresponding aliasing error of \(f L^{2}()\) for sampling at the rate \(2\) are given by_

\[(f)=f-_{_{}}f, \|(f)\|_{2}=\|f-_{_{}}f\|_{2}.\]

_If the aliasing error \((f)\) is zero, i.e. if \(f_{}\), we say that there is a continuous-discrete equivalence (CDE) between \(f\) and its samples \(\{f(n/2)\}_{n}\)._

Continuous-Discrete Equivalence in Hilbert spaces.Next, we generalize the above described concept of continuous-discrete equivalence to any separable Hilbert space \(\), with inner product \(,\) and norm \(\|\|\). A countable sequence of vectors \(\{f_{i}\}_{i I}\) in \(\) is a _frame_ for \(\) if there exist constants \(A,B>0\) such that for all \(f\)

\[A\|f\|^{2}_{i I}| f,f_{i}|^{2} B\|f\|^{2}.\] (2.3)

Clearly, an orthonormal basis for \(\) is an example of a frame with \(A=B=1\). We will now define maps that will allow us to make the link between functions and their discrete representations, which we will extensively use in the following sections. The bounded operator \(T\,^{2}(I), T(\{c_{i}\}_{i I})=_{i I}c_ {i}f_{i},\) is called _synthesis operator_ and its adjoint \(T^{*}^{2}(I), T^{*}f=\{ f,f_{i}\}_ {i I}\), which discretizes the function by extracting its frame coefficients, is called _analysis operator_. By composing \(T\) and \(T^{*}\), we obtain the _frame operator_\(S:=TT^{*}\), which is an invertible, self-adjoint and positive operator. Furthermore, the pseudo-inverse of the synthesis operator is given by \(T^{}\,^{2}(I), T^{}f=\{ f,S ^{-1}f_{i}\}_{i I}\), which will be used in the following to reconstruct the function from its discrete representation, i.e. its frame coefficients.

With these concepts, one can introduce the most prominent result in frame theory , the _frame decomposition theorem_, which states that every element in \(\) can be _uniquely and stably_ reconstructed from its frame coefficients by means of the reconstruction formula

\[f=TT^{}f=_{i I} f,S^{-1}f_{i} f_{i}=_{i I}  f,f_{i} S^{-1}f_{i},\] (2.4)

where the series converge unconditionally. Formula (2.4) is clearly a generalization of reconstruction formula (2.1). However, it is worth pointing out that, in general, the coefficients in (2.4) are not necessarily point samples of the underlying function \(f\), but more general frame coefficients.

In general, it may not be possible to access all the frame coefficients to reconstruct a function in a Hilbert space. Instead, just like in the case of reconstructing functions from point samples, one will need to consider approximations to this idealized situation. This is best encapsulated by the notion of a _frame sequence_, i.e., a countable sequence \(\{v_{i}\}_{i I}\) which is a frame for its closed linear span, i.e. for \(}\{v_{i}:i I\}\). With this notion, we are in a position to generalize aliasing errors and the CDE, to arbitrary Hilbert spaces. Let \(\) be a separable Hilbert space and let \(\{v_{i}\}_{i I}\) be a frame sequence for \(\) with \(=}\{v_{i}:i I\}\) and frame operator \(S\). Then, the orthogonal projection of \(\) onto \(\) is given by \(_{}f=_{i I} f,v_{i} S^{-1}v_{i}.\) Thus, formula (2.4) holds and the function \(f\) can be uniquely and stably recovered from its frame coefficients if and only if \(f\). If \(f\), reconstructing \(f\) from the corresponding frame coefficients results in an _aliasing error:_

**Definition 2.2**.: _Aliasing for functions in arbitrary separable Hilbert spaces. The aliasing error function \((f)\) and the resulting aliasing error \(\|(f)\|\) of \(f\) for the frame sequence \(\{v_{i}\}_{i I}\) are given by_

\[(f)=f-_{}f,\|(f)\|=\|f- _{}f\|.\]If the aliasing error \((f)\) is zero, i.e. if \(f,\) we say that there is a _continuous-discrete equivalence (CDE)_ between \(f\) and its frame coefficients \(\{ f,v_{i}\}_{i I}\).

## 3 Alias-Free Framework for Operator Learning

In this section, we will extend the concept of aliasing of functions to operators. We demonstrate that this notion of _operator aliasing is fundamental to understanding how the neural operator performs across various discretizations_, thereby addressing the shortcomings of possible lack of _continuous-discrete equivalence._ We will then define Representation equivalent Neural operators (ReNOs), whose discrete representations are equivalent across discretizations.

Assume we posit a (neural) operator \(U\), mapping between infinite-dimensional function spaces. As mentioned before, this operator is never computed in practice, instead a discrete mapping \(u\) is used. The difficulty in formalizing this is that we should be able to compute this discrete mapping for any discretizations of the input and output function. We formalize this notion below in a practical manner.

Setting.Let \(UU\) be an operator between two separable Hilbert spaces, and let \(=\{_{i}\}_{i I}\) and \(=\{_{k}\}_{k K}\) be frame sequences for \(\) and \(\), respectively, with synthesis operators \(T_{}\) and \(T_{}\). We denote their closed linear spans by \(_{}:=}\{_{i}:i I\}\) and \(_{}:=}\{_{k}:k K\}\). We note that by classical frame theory , the pseudo-inverses \(T_{}^{}\) and \(T_{}^{}\), initially defined on \(_{}\) and \(_{},\) respectively, can in fact be extended to the entire Hilbert spaces, i.e. \(T_{}^{}:^{2}(I)\) and \(T_{}^{}:^{2}(K)\).

### Operator Aliasing and Representation Equivalence

Once the discretization is chosen - determined by input and output frame sequences \((,)\) - connecting the continuous operator \(U\) with its discrete counterpart \(u\) is the notion of operator aliasing. Given any mapping \(u^{2}(I)^{2}(K)\), we can build the operator \(T_{} u T_{}^{}\), whose definition clearly depends on the choices of the frame sequences that we make on the continuous level. In other words, any mapping \(u\) can be interpreted as a discrete representation of an underlying continuous operator, which in general, may differ from the operator \(U\), that is of interest here. Hence, in analogy to Definitions 2.1 and 2.2, we can define the aliasing error of \(U\) relative to the discrete representation \(u\) as,

**Definition 3.1**.: _Operator aliasing. The aliasing error operator \((U,u,,)U \) is given by_

\[(U,u,,)=U-T_{} u T_{}^{},\]

_and the corresponding scalar error is \(\|(U,u,,)\|\), with \(\|\|\) denoting the operator norm._

An aliasing error of zero implies that the operator \(U\) can be perfectly represented by first discretizing the function with \(T_{}^{}\), applying \(u\), and then reconstructing with \(T_{}\), or equivalently, that the diagram in Figure 0(a) commutes, i.e. the black and the blue directed paths in the diagram lead to the same result. If the aliasing error is zero, we say that \((U,u,,)\) satisfies a _continuous-discrete equivalence

Figure 1: Alias-free framework. \(U\) is the underlying operator, \(u\) its discrete implementation. The synthesis operators and their pseudo-inverses make the link between function and discrete space.

_(CDE)_, implying that accessing the discrete representation \(u\) is exactly the same as accessing the underlying continuous operator \(U\).

**Example 3.2**.: _Aliasing with the magnitude squared operator._ Consider the operator \(U(f)=|f|^{2}\) as an operator from \(_{}\) into \(_{2}\). The choice to discretize inputs and outputs on the same grid \(\{\}_{n}\) corresponds to choosing \(==\{(2 x-n)\}_{n}\), and to defining the discrete mapping \(u^{2}()^{2}()\) by \(u(v)=T_{}^{} U T_{}(v)=v\), where \(\) denotes the entrywise product. Then, for every \(f_{}\) such that \(U(f)_{2}_{}\), we have

\[(U,u,,)(f)=U(f)-T_{} T_{}^{}(U(f))=U(f )-_{_{}}(U(f)) 0,\]

and we encounter aliasing. This occurs because \(U\) introduces new frequencies that exceed the bandwidth \(\). However, we can rectify this by sampling the output functions on a grid with twice the resolution of the input grid. This corresponds to choosing \(=\{(4 x-n)\}_{n}\) and to defining \(u=T_{}^{} U T_{}\), which simply maps samples from grid points \(\{\}_{n}\) into squared samples from the double resolution grid \(\{\}_{n}\). This effectively removes aliasing since the equality \(U=T_{} u T_{}^{}\) is satisfied. Furthermore, sampling the input and output functions with arbitrarily higher sampling rate, i.e. representing the functions with respect to the system \(\{(2x-n)\}_{n}\) with \(>2\), yields no aliasing error since \(\{(2x-n)\}_{n}\) constitutes a frame for \(_{2}_{}\).

In practice, the discrete representation \(u\) of the operator \(U\) depends on the choice of the frame sequences. This means that - as mentioned at the beginning of the section - there is one map for every input/output frame sequence \(,\). The consistency between operations \(u,u^{}\) with respect to different frame sequences can be evaluated using the following error.

**Definition 3.3**.: _Representation equivalence error. Suppose that \(u,u^{}\) are discrete maps with associated frame sequences \(,\) and \(^{},^{}\), respectively. Then, the representation equivalence error is given by the function \((u,u^{}):^{2}(I)^{2}(K)\), defined as:_

\[(u,u^{})=u-T_{}^{} T_{^{}} u^{ } T_{^{}}^{} T_{}\]

_and the corresponding scalar error is \(\|(u,u^{})\|\)._

Intuitively, this amounts to computing each mapping on their given discretization, and comparing them by expressing \(u^{}\) in the frames associated to \(u\). In the following section we leverage the notion of operator aliasing in the context of operator learning, as well as explore its practical implications with respect to representation equivalence at the discrete level.

### Representation equivalent Neural Operators (ReNO)

Equipped with the above notion of continuous-discrete equivalence, we can now introduce the concept of _Representation equivalent Neural Operator (ReNO)_. To this end, for any pair \((,)\) of frame sequences for \(\) and \(\), we consider a mapping at the discrete level \(u(,)T_{}^{}T _{}^{}\), which handles discrete representations of the functions. Notice how this map is indexed by the frame sequences: this is normal as when the discretization changes, the definition of the function should also change. In order to alleviate the notation, when this is clear from the context, we will refer to \(u(,)\) simply as \(u\). See **SM** D.1 for an explanation of the condition \(u(,)T_{}^{}T _{}^{}\).

**Definition 3.4**.: _Representation equivalent Neural Operators (ReNO). We say that \((U,u)\) is a ReNO if for every pair \((,)\) of frame sequences that satisfy \(U_{}\) and \(U_{}\) there is no aliasing, i.e. the aliasing error operator is identical to zero:_

\[(U,u,,)=0.\] (3.1)

_We will write this property in short as \((U,u)=0\)._

In other words, the diagram in Figure 0(a) commutes for every considered pair \((,)\). In this case, the discrete representations \(u(,)\) are all equivalent, meaning that they uniquely determine the same underlying operator \(U\), whenever a continuous-discrete equivalence property holds at the level of the function spaces. The domain and range conditions in Definition 3.4 simply imply that the frames can adequately represent input and output functions of \(U\).

**Remark 3.5**.: If the aliasing error \((U,u,,)\) is zero (as required in Definition 3.4), then the assumption that \(u(,)\) maps \(T^{}_{}^{2}(I)\) into \(T^{}_{}^{2}(K)\) implies that

\[u(,)=T^{}_{} U T_{}.\] (3.2)

We observe that this definition of \(u(,)\) is such that the diagram in Figure 0(b) commutes. In other words, once we fix the discrete representations \(,\) associated to the input and output functions, there exists a unique way to define a discretization \(u(,)\) that is consistent with the continuous operator \(U\) and this is given by (3.2). In practice, we may have access to different discrete representations of the input and output functions, which in the theory amounts to a change of reference systems in the function spaces. Note that to avoid any aliasing error, the discrete representation of \(U\)_has to_ depend on the chosen frame sequences, i.e. inevitably, \(u\) must depend on \(\) and \(\), and hence, must be discretization dependent. See A.2 for the proof of Remark 3.5.

In particular, Remark 3.5 directly implies a formula to go from one discrete representation to another, as

\[u(^{},^{})=T^{}_{^{}} T_{}  u(,) T^{}_{} T_{^{}},\] (3.3)

whenever the pairs of frame sequences \((,)\) and \((^{},^{})\) satisfy the conditions in Definition 3.4. In other words, the diagram in 0(c) commutes.

Formula (3.3) immediately implies Proposition 3.6, which establishes a link between aliasing and representation equivalence. This highlights the contrast to _discretization invariance_, discussed at length in : while this concept establishes an asymptotic consistency, representation equivalence includes the direct comparison between any two given discretizations and guarantees their equivalence.

**Proposition 3.6**.: _Equivalence of ReNO discrete representations. Let \((U,u)\) be a ReNO. For any two frame sequence pairs \((,)\) and \((^{},^{})\) satisfying conditions in Definition 3.4, we have that_

\[(u,u^{})=0,\]

_where, by a slight abuse of notation, \(u^{}\) denotes \(u(^{},^{})\)._

Hence, under the assumption that the discrete map at each discretization is consistent with the underlying continuous operator, we have a unique way to express the operator at each discretization. Moreover, formula (3.3) closely resembles analogous formulas presented in [17; 15; 23] when evaluating _single shot super resolution_. However, in Section 5, we offer a nuanced perspective, indicating variability across different scenarios.

### Layer-wise Instantiation

As shown in Remark 3.5, we can compute the outputs of the ReNO on the computer by first discretizing the continuous operator \(U\). Typically, if \(U\) is a neural operator composed of multiple layers, as we will show in this section, it is possible to discretize each layer, while remaining consistent with the underlying operator.

Consider a neural operator \(U\) with \(L\) layers, each a mapping between separable Hilbert spaces:

\[U=U_{L} U_{L-1} U_{1}, U_{}_{}_{+1},=1, ,L,\] (3.4)

we denote by \(_{}\) a _frame sequence_ for \(_{}\). The choice of frame sequences for each \(_{}\) corresponds to the choice of accessible discrete representations of functions in the underlying function space \(_{}\).

**Proposition 3.7**.: _Stability of ReNO under composition. Consider the composition \(U=U_{L} U_{1}\) as in eq. 3.4, as well as a discrete mapping \(u=u_{L} u_{1}\). If each layer \((U_{},u_{})\) is a ReNO, the composition \((U,u)\) also is a ReNO._

As the proof of Proposition 3.7, presented in **SM** A.1, also shows, if each hidden layer in the operator (3.4) has an aliasing error (2.2), then these errors may propagate through the network and increase with increasing number of layers.

### \(-\)ReNOs

In practice, we may not need to set the aliasing error to zero. But it is essential to be able to control it and make it as small as desired. The notion of ReNOs, Definition 3.4, can very simply be extended to the case where we allow for a small, controlled amount of aliasing. Indeed we can introduce \(-\)ReNOs, which satisfy \(\|(U,u)\|\) (for every pair of admissible frame sequences) instead of \((U,u)=0\).

**Proposition 3.8**.: _Let \((U,u)\) be an \(-\)ReNO. For any two frame sequence pairs \((,)\) and \((^{},^{})\) satisfying conditions in Definition 3.4 and such that \(_{^{}}_{}\), we have_

\[\|(u,u^{})\|}}{}},\]

_where, by a slight abuse of notation, \(u^{}\) denotes \(u(^{},^{})\)._

## 4 Examples

Equipped with our definition of Representation equivalent Neural Operators (ReNOs), we analyze some existing operator learning architectures to ascertain whether they are neural operators or not.

Convolutional Neural Networks (CNN).Classical convolutional neural networks are based on the convolutional layer \(k\), involving a discrete kernel \(f^{2s+1}\) and a discrete input \(c\):

\[k(c)[m]=(f*c)[m]=_{i=-s}^{s}c[m-i]f[i].\]

We can then analyze this layer using our framework to ask whether this operation can be associated to some underlying continuous operator. Intuitively, if this is the case, the computations conducted on different discretizations effectively representing the input should be consistent; in the contrary case, no associated continuous operator exists and the convolutional operation is not a ReNO.

Consider the case where the discrete input \(c\) corresponds to pointwise evaluation on a grid of some underlying bandlimited function \(f_{}\), for example \(c[n]=f(),n\) with associated orthonormal basis \(=\{(2 x-n)\}_{n}\). Consider now an alternate representation of \(f\), point samples of a grid twice as fine: \(d[n]=f()\), with \(^{}=\{(4 x-n)\}_{n}\) as basis. Clearly, even though discrete inputs agree, i.e. \(c[n]=d[2n]\), this is no longer true for the outputs, \((k*c)[n](k*d)[2n]\). This in turn implies that there exist frame sequences \(,^{}\) such that:

\[T_{} k_{}(c) T_{}^{} T_{^{}} k _{^{}}(d) T_{^{}}^{}\] (4.1)

thereby defying the representation equivalence property of ReNOs, in the sense of Definition 3.4. This fact is also corroborated with the experimental analysis, Section 5.

Fourier Neural Operators (FNO).FNOs are defined in  in terms of layers, which are either lifting or projection layers or _Fourier layers_. As lifting and projection layers do not change the underlying spatial structure of the input function, but only act on the channel width, these linear layers will satisfy Definition 3.4 of ReNO here. Hence, we focus on the Fourier layer of the form,

\[v_{+1}(x)=(A_{}v_{}(x)+B_{}(x)+v_{} (x)),\] (4.2)

with the Fourier operator given by

\[v=^{-1}(R)(v).\]

Here, \(,^{-1}\) are the Fourier and Inverse Fourier transforms.

For simplicity of exposition, we set \(A_{}=B_{} 0\) and focus on investigating whether the Fourier layer (4.2) satisfies the requirements of a ReNO. Following , the discrete form of the Fourier layer is given by \((kv)\), with \(kv=F^{-1}(R F(v)),\) where \(F,F^{-1}\) denote the discrete Fourier transform (DFT) and its inverse.

In **SM** B.1, we show that the convolution in Fourier space operation for the FNO layer (4.2) satisfies the requirements of a ReNO. However the pointwise activation function \((f)\), applied to a bandlimited input \(f_{}\) will not necessarily respect the bandlimits, i.e., \((f)_{}\). In fact, with popular choices of activation functions such as ReLU, \((f)_{}\), for any \(>0\) (see **SM** C for numerical illustrations). Thus, the Fourier layer operator (4.2) may not respect the continuous-discrete equivalence and can lead to aliasing errors, a fact already identified in . Hence, FNO _may not be a ReNO in the sense of Definition 3.4._

Convolutional Neural Operators (CNO).Introduced in , the layers of a convolutional neural operator consist of three elementary operations

\[v_{l+1}=_{l}_{l}_{l}(v_{l}), 0 l  L-1,\] (4.3)

where \(_{l}\) is a convolution operator, \(_{l}\) is a non-linear operator whose definition depends on the choice of an activation function \(\), and \(_{l}\) is a projection operator. We show in **SM** B.2 that CNO layers respect equation (3.2) and consequently CNOs are Representation equivalent Neural Operators (ReNOs) in the sense of Definition 3.4. This is the result of the fact that the activation layer is defined in a way to respect the band-limits of the underlying function space.

## 5 Empirical Analysis

### Assessing Representation Equivalence

In the previous section, we have studied existing neural operator architectures from a theoretical perspective. In this section, for the same architectures, we corroborate these findings from an empirical viewpoint. Aliasing is a quantity that cannot be computed in practice, as we cannot access the underlying operator \(U\) on a computer, we can nonetheless compute representation equivalent errors introduced in Definition 3.3, which is related to aliasing by Propositions 3.7 and 3.8 (as well as being a quantity of interest in itself).

Experimental Setting.We wish to learn an unknown target operator \(Q\) using a neural operator. In this experiment, all neural operators (CNN, FNO and SNO) take as input pointwise evaluations on the grid, and are able to deal with varying input resolutions. A simple way of constructing the target operator \(Q:H H\), where \(H\) is the space of periodic and \(K=30\)-bandlimited functions, is by sampling input and output pairs in a random fashion. Sampling of a function in \(H\) can be realized as follows: As we know that \(_{K}:=\{d_{K}(.-x_{k})\}_{k=-K,,K}\) constitutes a frame for \(H\), \(d_{K}\) being the Dirichlet kernel of order \(K\) and \(x_{k}=\), any function \(f H\) can be written as \(f(x)=_{k=-K}^{K}f(x_{k})d_{K}(x-x_{k})\). Thus, the discrete representation of \(f\) simply corresponds to its \(2K+1=61\) point-wise evaluations on a grid, i.e. \(\{f(x_{k})\}_{k=-K,,K}\). Note that for simplicity we have used and will use the same frame sequences for both input and output spaces, as these are the same.

Training and Evaluation.Once the data is generated, we train neural operators \(u(_{K},_{K})\) on discretizations associated to the frame sequences, which are simply the point-wise evaluations of the input-target functions in the data. In other words, we regress to the frame coefficients of the target function, with coefficients of the input function as input. Once training is over, we evaluate how the different neural operators behave when dealing with changing input and output frame sequences. The frame sequences here are \(_{M}\) for different testing frames, with associated \(2M+1\) sized grids, with associated operator \(u_{M}:^{2M+1}^{2M+1}\).

The results of this experiment are presented in Figure 2; we also provide results for additional architectures in Figure 4. The results in Figure 2 clearly show that as predicted by our theory, neither CNN nor FNO are representation equivalent, in the sense of Definition 3.4 and changing the resolution, which amounts to a change of frame, does not keep the operator invariant, causing aliasing errors that materialize themselves as representation equivalence errors (as in Definition 3.3) here. On the other hand, as predicted by the theory, CNO is more likely to be a ReNO - as long as the frames selected satisfy conditions of Definition 3.4 (i.e. "Representation Equivalence" zone). When these conditions no longer hold ("No Equivalence" zone), CNO also generates aliasing errors. Thus, this experiment clearly demonstrates the practical implications of the ReNO framework. In contrast, the discretization invariance_ condition only ensures that in the infinite resolution limit, the neural operator converges, while not making any predictions about the behavior of the neural operator at finite resolutions.

Minimizing representation equivalence error.Instead of directly tackling aliasing errors from a theoretical perspective as is done in the previous sections, we select an architecture that may have aliasing, i.e. FNO, and we try to minimize the representation equivalence error during training. We observe and detail our findings in **SM** C.3.

### Assessing Structure Preservation

Our methodology aims to maintain the structure of the underlying operator, as defined at the continuous level. Fundamental structural characteristics of the underlying operator, like symmetries and conservation principles, are maintained at the discrete level. Discretizations that are not aligned may fail to uphold these intrinsic properties of the operator, resulting in deviations like symmetry breaking which can negatively influence the results.

As an example of this, we consider FNO. Similarly to what is done in , the primary structure we aim to uphold is translation equivariance, as defined at the operator level. We look at different trained FNOs - all of which have a different representation equivalence error - and assess whether they are translation equivariant or not. More specifically, these FNOs are trained by minimizing both the regression loss and the representation equivalence error simultaneously, introducing a more or less large multiplier \(\) on the latter, just like in **SM** C.3.

As we vary the parameter \(\), we observe in Table 1, there is a distinct relationship between the Discrete Aliasing Error (DAE) and the Translation Equivariance Error. Both errors show a similar trend with a nearly perfect positive linear association.

   Representation Equivalence Error (\%) & 10.38 & 20.24 & 42.97 & 98.55 \\ Translation Equivariance Error (\%) & 10.54 & 20.54 & 45.79 & 104.44 \\   

Table 1: Representation equivalence error vs translation equivariance error. We observe a direct link between aliasing and preserving continuous structures.

Figure 2: Representation equivalence is computed for three classical architectures, CNN, FNO and CNO trained on a resolution of \(61\) (yellow dot). The “Resolution Equivalence” zone, located on the right-hand side, denotes the region where discrete representations have an associated frame, while the left-hand side represents the area where this is no longer the case (loss of input/output information). As predicted by the theory, CNN and FNO are not representation equivalent, while CNO is error-free in the equivalence region, but failing to do so outside of it.

Discussion

Summary.Although a variety of architectures for operator learning are available since the last couple of years, there is still a lack of clarity about what exactly constitutes _operator learning_. Everyone would agree that an operator learning architecture should have functions as inputs and outputs. However, in practice, one does not necessarily have access to functions, either at the input or output level. Rather the access is limited to some form of _discrete representations_ of the underlying functions, for instance, point values, cell averages, coefficients with respect to a basis etc. Moreover, one can only perform computations with discrete objects on digital computers. Hence, given the necessity of having to work with discrete representations of functions, it is essential to enforce some relationship between the continuous and discrete representations of the underlying functions or in other words, demand consistency in function space.

Unlike in , where the authors advanced a form of _asymptotic consistency_ in terms of discretization parameters, we go further to require a stronger form of structure-preserving equivalence of the continuous and discrete representations of operators. To this end, we leverage the equivalence between continuous and discrete representations of functions in Hilbert spaces in terms of frame theory. The main point about this equivalence is the fact that functions, belonging to suitable function spaces, can be uniquely and stably reconstructed, from their frame coefficients. A failure to enforce this equivalence results in the so-called aliasing errors that quantitatively measure function space inconsistencies.

We extend this notion of aliasing error to operators here and use it to define _Representation equivalent Neural Operators (ReNOs)_, see Definition 3.4. Our framework automatically implies consistency in function spaces and provides a recipe for deriving ReNOs in terms of changing the underlying frames. We also employ our framework to analyze whether or not existing operator learning architectures are ReNOs and also corroborate our results through experiments.

Related Work.Our current paper relies heavily on structure preservation from classical numerical analysis,  and references therein, as well as concepts from signal processing and applied harmonic analysis  and references therein. Among the emerging literature on operator learning,  was one of the first papers to attempt a unifying framework that encompasses many operator learning architectures and codify them through a particular definition of neural operators. We take an analogous route here but with our main point of departure from  being that unlike their notion of asymptotic consistency, we require _systematic consistency in function space_ by enforcing the representation equivalence for the underlying operator at each layer. Another relevant work is  where the authors flag the issue of possible aliasing errors with specific operator learning architectures. We significantly expand on the approach of  by providing a rigorous and very general definition for aliasing errors. Finally, our definition of Representation equivalent Neural Operators, relying on aliasing errors for operators, is analogous to a similar approach for _computing with functions_, rather than discrete representations, which is the cornerstone of the _Chebfun_ project  and references therein.

Limitations and Extensions.Our aim in this paper was to tackle a fundamental question of what defines a _neural operator?_ We have addressed this question here and shown that enforcing some form of equivalence between continuous and discrete representations is needed for the architecture to genuinely learn the underlying operator rather than just a discrete representation of it. What we have not addressed here are quantitative measures of the error associated with a _Representation equivalent Neural Operator,_ introduced in Definition 3.4, in approximating the underlying operator. This is a much broader question than what is addressed here, since sources of error, other than aliasing errors, such as _approximation, training and generalization_ errors also contribute to the total error (see ).

One interesting direction for further analysis would involve exploring operators and their discretized counterparts that form \(\)-ReNOs and also enforce the ReNO property approximately. Characterizing the implications of this concept within operator learning is a topic for future work.