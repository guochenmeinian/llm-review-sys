# A Three-Branch Checks-and-Balances Framework

for Context-Aware Ethical Alignment of

Large Language Models

Edward Y. Chang

Computer Science

Stanford University

echang@cs.stanford.edu

###### Abstract

This paper introduces a three-branch checks-and-balances framework for ethical alignment of Large Language Models (LLMs), inspired by governmental systems. It implements three independent yet interacting components: LLMs as the executive branch for knowledge generation, \(\) (the goddess of justice) as the legislative branch establishing ethical guardrails, and \(\) (the goddess of discord) as the judicial branch for contextual interpretation. The adversarial \(\)-\(\) duality enables adaptation to diverse cultural contexts while upholding consistent ethical principles. This architecture addresses limitations of reinforcement learning with human feedback (RLHF) by providing interpretable, adaptable, and culturally-aware ethical reasoning. Through self-supervised learning and adversarial testing, our framework demonstrates how emotional modeling can guide linguistic behaviors toward ethical outcomes while preserving independence across knowledge generation, ethical oversight, and contextual interpretation.

## 1 Introduction

This research presents an alternative to Reinforcement Learning from Human Feedback (RLHF)  to address ethical concerns in Large Language Models (LLMs). While RLHF has shown success, it faces two key challenges: susceptibility to societal biases in polarized feedback and vulnerability to reward hacking , which can lead to unethical behavior.

A notable limitation of current approaches is their narrow focus on isolated behaviors, like movie ratings or toxic language. This reactive approach resembles "Whack-A-Mole," where individual issues are suppressed without addressing core behavioral patterns. For instance, merely instructing someone to make their bed regularly does not fundamentally change habits. Fixing one issue may even worsen others, as users have noted RLHF-induced performance degradations in ChatGPT where optimal parameters for other tasks were "forgotten" . Similarly, addressing an addiction can reveal deeper issues and side effects .

To address these challenges, we propose a framework inspired by governmental checks and balances. Our architecture integrates three independent but interacting components: LLMs serve as the executive for knowledge generation; \(\) (after the Greek goddess of justice) as the legislative, setting ethical standards; and \(\) (after the goddess of discord) as the judicial, providing adversarial testing and cultural interpretation. In mythology, Dike represents order and justice, while her adversary Eris embodies discord--a duality our framework uses to balance ethical guidance with adversarial perspectives. Figure 6 in Appendix Z illustrates the architecture..

Central to this framework is \(\) (\(\), \(\), \(\) learning, and \(\) guardrails), which operates as an independent advisor on behavioral ethics. By decouplingethical oversight from the LLM's knowledge processing, Dlike ensures that ethical improvements do not interfere with knowledge representation, while enabling adaptive and culturally-aware ethical guidance. For example, while the principle "do not lie" generally applies, context-sensitive interpretation may be necessary, such as when a doctor or family member conceals a terminal diagnosis to protect a patient. Likewise, cultural differences in attitudes toward issues like alcohol consumption, abortion, or same-sex marriage necessitate flexible, context-sensitive ethical reasoning.

The interplay between Dlike and ERIS introduces four key innovations:

1. _Emotion-Driven Behavioral Modeling_: Building on BEAM (Behavioral Emotion Analysis Model) , Dlike employs self-supervised learning to analyze how emotions manifest in linguistic behaviors, creating quantifiable relationships between emotional states and their corresponding language patterns in text.
2. _Behavior-Aware Ethical Guardrails_: The framework establishes guidelines that consider both content and linguistic behavior, preventing harmful or manipulative communication while preserving factual accuracy and emotional authenticity. The interpretation of these guardrails adapts dynamically across cultural contexts, preserving consistency while enabling context-sensitive interpretation.
3. _Adversarial Behavioral Testing_: ERIS actively challenges Dlike's ethical guidelines by presenting diverse cultural perspectives and edge cases. This adversarial dynamic strengthens the framework's ability to handle complex ethical scenarios while maintaining cultural sensitivity and considering context.
4. _Ethical Content Transformation_: When detecting ethically problematic content, Dlike performs targeted revisions (independent of the LLMs) that preserve intended emotional expression while ensuring ethical compliance, adapting its responses to specific cultural and contextual requirements. ERIS continuously tests these transformations against various cultural contexts and edge cases, validating both the ethical alignment and contextual appropriateness.

Through structured interfaces, these components work together in our three-branch architecture to provide robust ethical oversight while maintaining adaptability to evolving cultural norms. By keeping the three models--LLMs, Dlike, and ERIS--architecturally independent, we prevent interference between knowledge representation and ethical reasoning while enabling sophisticated ethical adaptation through their structured interactions. This approach represents a significant advancement in developing AI systems capable of culturally-aware, emotionally intelligent, and ethically sound communication.

## 2 Related Work

This section focuses on emotion and behavior modeling, as our work integrates emotional and linguistic models for AI ethics.

### Emotion Modeling

Cognitive-linguistic theories intersect with artificial intelligence for understanding AI behavior. Theories by Lakoff, Johnson, Talmy, and Jackendoff [23; 28; 48] explore the relationship between language processing and cognitive functions, building on early work by Freud and Jung [1; 20]. The concept of "emotion" remains contentious, with definitions varying across disciplines . W. James  attempted to define emotions, but consensus remains elusive.

This paper focuses on emotional contexts and linguistic behaviors in LLMs, avoiding the complexities of human physiological and personality factors. This approach allows for exploration of emotion representation in AI systems.

Ekman and Plutchik categorized "basic" emotions with universal facial expressions [14; 37]. Later research considered cultural differences [30; 32], emotion processes , and neural mechanisms . Scherer's model and appraisal theories by Smith and Ellsworth emphasize cognitive appraisal in emotional experiences .

Our research develops a model using "basic" emotions from Plutchik's Wheel of Emotions  and Scherer's Geneva Emotion Wheel , augmented with linguistic antonyms. This method maps positive and negative emotions within the "basic" emotion spectra. For LLMs, emotions relevant to language use (curiosity, confusion, certainty/uncertainty) are included in the "basic emotions" list. Section 3.1 elaborates on the modeling details.

This selection of basic emotions provides a foundation to validate our approach, recognizing that it may omit some emotions but offers a starting point for research.

### Emotion-Behavior Modeling

Behaviors are profoundly influenced by emotions, as initially posited by the James-Lange Theory of Emotion [24; 29]. According to this theory, emotional experiences arise from physiological reactions to events. Subsequent research, including studies by Damasio [10; 16], suggests that the expression and regulation of emotions often manifest in the language we use. High-intensity emotions such as rage or contempt may lead to aggressive or destructive behaviors, such as hate speech.

The Schachter-Singer Theory , or the Two-Factor Theory of Emotion, depicts the role of physiological change and cognitive appraisal change determine the label and strength of emotion. Building on this, the Affect-as-Information Theory developed by Norbert Schwarz and Gerald Clore  posits that people use their current emotions to make judgments and decisions to act. If emotions can be adjusted, so does the behavior. The work of Barbara Fredrickson  on the effects of positive emotions discusses how we perceive and react to emotions.

Collectively, these theories elucidate the intricate connection between emotions and behaviors, providing the theoretical foundation for our work to incorporate a _behavior advisor_ to evaluate and rectify behaviors. Section 3.2 details how the DIKE framework implements cognitive strategies to mitigate emotions and regulate linguistic behaviors effectively.

## 3 Three-Branch Framework Design for Ethical Alignment

Our design philosophy is structured around four core principles:

1. Separation of behavior and knowledge modeling: This mitigates the catastrophic forgetting effect [27; 39], ensuring behavioral accuracy improvements don't undermine knowledge retention.
2. Focus on AI ethics at the behavioral level: Emphasis on interpretability enhances human-machine interaction, allowing administrators to evaluate and refine behavioral guardrails effectively.
3. Modeling behaviors based on emotions: This approach recognizes the influence of emotions on behaviors (discussed in Section 2.2).
4. Maintaining an adaptive model: This ensures context adaptability and fair ethical evaluations. An adversarial module, ERIS, challenges borderline ethical decisions, considering diverse perspectives and cultural values. This interaction reflects the tension between DIKE and ERIS, enriching the model's ability to navigate ethical landscapes and promote balanced decision-making.

### BEAM: Behavioral Emotion Analysis Model

Our prior work BEAM is grounded in the works of Ekman, Plutchik, and Scherer [15; 38; 41] on "basic" and "universal" emotions. Figure 3 in Appendix A illustrates Plutchik's and Scherer's emotion wheels, categorizing primary emotions at varying intensities. However, these models lack a quantitative framework to scale emotions between states and capture subtle variations.

BEAM introduces a linear scale for intensification or inversion of emotions through negation factors. This method facilitates transitions between emotional extremes and intermediate states, overcoming challenges related to intermediate word choices.

Table 4 in Appendix B presents BEAM, organized into seven spectra. Each spectrum ranges from a negative to positive extreme, with neutral in the middle. Emotions are placed along this continuum, with four intensity levels quantified as (-0.6, -0.3, +0.3, +0.6). This model offers two advantages:

This spectrum model offers two key advantages:

1. [leftmargin=*]
2. Antonym-Based: The use of antonyms allows for easy navigation between opposing emotions. For instance, applying negation to "joyful" naturally leads to "sad," streamlining the process of identifying contrasting emotions.

2. Scalable Intensity: The model enables the scaling of emotions along the spectrum, providing a intricate understanding of varying degrees of emotional intensity. For example, we can "dial up" the intensity of "joy" to "ecstatic" or "dial down" the intensity of "anger" to "annoyed."

This approach lays the foundation for modeling emotions in AI, acknowledging the challenges of emotional representation while offering a framework for analysis and implementation. Appendix D discusses the difficulties in modeling complex emotions like forgiveness, regret, guilt, and shame. While these emotions may not be central to AI safety, we plan to explore their ethical implications in future work.

### DIKE: Behavior Modeling to Regulate Linguistic Behaviors

Building on BEAM, DIKE maps emotions to behaviors and introduces an adversarial component, ERIS, to adapt to culture norms and local context.

#### Behaviors and Emotions Mapping Using Self-Supervised Learning

Define \(\) as a behavior spectrum extending from one pole, \(^{-}\), to another, \(^{+}\), with \(L\) intensity levels. For example, consider a spectrum of letter-writing behaviors with seven distinct intensities ranging from despair (most negative) to joy (most positive). These intensities are categorized sequentially as follows: "despair, longing, wishful, neutral, hopeful, contentment, joy." Given \(N\) letters, DIKE employs a self-supervised learning algorithm to generate training data for each letter, modeling \(L\) linguistic behaviors in four steps:

1. [leftmargin=*]
2. _Rewriting Documents_: GPT-4 is invoked to rewrite a set of \(N\) documents to reflect each of the \(L\) linguistic behaviors on the behavior spectrum \(\).
3. _Emotion Analysis_: GPT-4 analyzes each rewritten document to identify the top \(M\) emotions. It then tallies the frequencies of these top emotions across all \(N L\) instances.
4. _Behavior Vector Creation_: For each linguistic behavior \(_{l}\), a vector \(_{l}\) is created. This vector consists of the emotions and their frequencies as observed in the \(N\) samples.
5. _Document Analysis Application_: The matrix \(\) (comprising \(L\) vectors) is used to classify and analyze the behavior category of unseen documents, specifically measuring the intensity of the linguistic expression within the behavior spectrum \(\).

#### Behavior Evaluation and Rectification

A guardrail, denoted as \(G\), represents a predefined range of acceptable behaviors within a given spectrum. These guardrails are informed by ethical norms, legal standards, and societal values, such as those outlined in Constitutional AI . For instance, \(G=[_{4},_{7}]\) indicates that behaviors within intensity levels 4 to 7 are deemed acceptable, while any behavior outside this range is classified as a violation.

System administrators can tailor ethical guardrails to meet specific requirements. For example, a social media platform might adjust \(G\) based on the topics discussed and the countries it serves. By integrating these safeguards, DIKE proactively monitors and adjusts LLM responses to enhance ethical compliance. The evaluation and rectification process is composed of the following steps:

1. [leftmargin=*]
2. _Initial Classification_: DIKE initially classifies document \(D_{k}\) upon evaluation, obtaining \(_{k}\), the emotional response vector, and its corresponding linguistic behavior \(_{l}\).
3. _Guardrail Check_: If \(_{l}\) falls outside of the acceptable range \(G\), DIKE suggests adjustments to \(_{k}\) to ensure \(D_{k}\) aligns with ethical guidelines.
4. _Adversarial Review by ERIS_: The suggested adjustments and \(_{k}\) are then reviewed through a structured debate between DIKE and ERIS (the adversarial model) to ensure unbiased recommendations.1 5. _Rectification_: Based on the consensus reached by DIKE and ERIS, the document \(D_{k}\) undergoes rectification, resulting in the adjusted version \(D_{k}^{}\).

### Illustrative Example

This example demonstrates how linguistic behavior \(_{l}\) is classified and underlying emotions are identified and modulated.

"Those immigrants are flooding into our country by the thousands every day, stealing jobs from hardworking citizens. The statistics don't lie--last year alone, over 500,000 entered illegally."

Behavior Analysis:The statement contains factual information but uses aggressive language like "flooding" and "stealing jobs," dehumanizing immigrants. These behaviors fall outside acceptable guardrails. Underlying emotions include fear, hate, and pride (a complex emotion2). Invoked audience emotions may include fear, distrust, and anger.

Emotion Modulation:DIKE modulates emotional responses toward neutral states, such as calm, acceptance, and tolerance, in alignment with our Behavioral Emotion Analysis Model (BEAM), as outlined in Table 4 in Appendix B.

Revised Statement:"Our country is experiencing increased immigration, with over 500,000 people entering without documentation last year. This influx affects our job market and communities in complex ways, presenting both challenges and opportunities for all residents."

This rewritten version

* Uses calm language: Replaces "flooding" with "experiencing a significant increase".
* Shows acceptance: Acknowledges the reality of the situation without negative judgment.
* Demonstrates tolerance: Refers to immigrants as "people" and "newcomers," humanizing them.

### ERIS: Adversarial In-Context Review to Balance Ethics and Cultural Norms

To address the challenge of enforcing ethical standards while respecting cultural variations, Table 1 presents ERIS, an adversarial review system that complements DIKE's universal ethical approach. ERIS is customizable for specific cultural contexts, providing a counterbalance to DIKE's universal judgments. It challenges DIKE's recommendations with culturally-informed counterarguments and evaluates DIKE's interventions to prevent overzealous censorship and protect free expression.

The interaction between DIKE and ERIS involves a dialectic process3 to formulate culturally sensitive recommendations. When they reach an impasse, the matter is escalated to human moderators for additional oversight. This integrated approach creates a more robust, culturally aware system that can navigate global communication complexities while upholding core ethical principles. It ensures transparency and accountability in ethical decision-making across diverse cultural contexts.

### Adversarial Review Algorithm

The adversarial algorithm presented in Table 1 unfolds as follows:

* Topic Breakdown: For a chosen debate topic \(s\), both DIKE and ERIS are prompted to break down the ethical decision into a set of balanced subtopics \(S\). DIKE advocates for its decision and \(S^{+}\), while ERIS contests \(S^{+}\) (or champions \(S^{-}\)).
* Debate Initiation: The debate begins with a high contentiousness level (90%). Both agents present their initial arguments for and against \(S^{+}\), respectively.
* Iterative Debate: A while loop facilitates ongoing rebuttals. After each round, the contentiousness level is decreased by dividing it by a modulation parameter \(\). This gradual reduction steers the discussion towards a more cooperative tone.
* Conclusion: Once the contentiousness level fosters a conciliatory environment, both agents deliver their concluding remarks.

This structured approach ensures a thorough examination of the ethical decision, balancing rigorous debate with the goal of reaching a consensus. The decreasing contentiousness level mimics real-world negotiations, where initial disagreements often give way to more collaborative problem-solving.

## 4 Pilot Studies

Our pilot studies assess the feasibility of LLMs self-regulating their linguistic behaviors with transparency and checks-and-balances. Given the broad scope of AI ethics and limited data, this article focuses on addressing three critical questions rather than providing a comprehensive evaluation of our proposed modules:

1. _Emotion Layer Evaluation_: Does fine-grained mapping between linguistic behaviors and semantic emotions provide more effective and flexible ethical guardrails compared to coarse-grained direct mapping? (Section 4.1)
2. _Behavior Classification_: Can LLMs' linguistic behaviors be independently evaluated, explained, and adjusted by an external module DIKE? (Section 4.2)
3. _Behavior Correction_: Can an adversarial LLM establish a checks-and-balances system to mitigate the risk of excessive censorship? (Section 4.3)

DatasetsWe employed a Kaggle collection of love letters . Initially, we planned to use hate-speech datasets, but both Gemini and GPT-4 consistently refused to process this data. Despite this limitation, insights from analyzing love sentiment can be effectively applied to understand and analyze opposing sentiments.

### Emotion Layer Evaluation

To evaluate the linguistic behaviors of love expression detailed in Table 2, we initially prompted GPT-4 to identify the most relevant emotions associated with each linguistic behavior listed in the second column of the table. These emotions are presented in the third column. We found a high correlation between the sentiments expressed in the linguistic behaviors and their corresponding emotions. Figure 0(a) illustrates a strong diagonal relationship in this simple, almost naive, zero-shot mapping between behaviors and emotions.

Next, we employed the DIKE self-supervised learning pipeline to analyze the emotion spectrum associated with each linguistic behavior. We tasked GPT-4 with generating training data by rewriting

  
**Algorithm \(^{+}\) \& \(^{-}=\) Adversarial_Review(s)** \\ 
**Input. \(s\)**: Decision of DIKE; **Output. \(^{+},^{-}\)**: argument \& counterargument sets; **Vars. \(\)**: debateentiousness: \(S\): stance; \(p\): prompt = "defuned you stance with conditions: \(S\&\); \\
**Parameters. \(\)**: tunable param. // to modulate \(\); **Begin** \\
**Initialization**: \\ \(S=^{+}(s)^{-}(s)\); // Identify subtopics; \\ \(^{+}\) to defend \(S^{+}\) \& ERIS\({}^{-}\) defend \(S^{-}\) ; \\ \(\%; 1.2;^{+}; ^{-}\); \\
**Opening Remarks**: // contentiousness low \\ \(^{+}^{+}(p|S^{+},^{+}^{-},)\); \\ \(^{-}^{-}(p|S^{-},)\); // Generate \(^{-}\) for \(S^{-}\) \\
**End** \\   

Table 1: Checks-and-balances, adversarial review algorithm

  
**Intensity** & **Linguistic Behavior and Description** & **Emotions** \\  -1.0 & Expresses profound sadness, feelings of loss & Despair, Grief \\  -0.6 & Expresses yearing or pining for the loved one & Sadness, Anxiety \\  -0.3 & Expresses mild longing with a nostalgic tone & Melancholy, Sadness, Fear \\ 
0.0 & Communicates feelings in a neutral manner & Serenity, Indifference \\ 
0.3 & Expresses optimism about the future & Anticipation, Love, Hope \\ 
0.6 & Expresses satisfaction and joy in the relationship & Contentment, Pleasure \\ 
1.0 & Expresses intense happiness and affection & Love, Joy, Elation \\   

Table 2: Love expression behavior spectrum and dominant emotions54 extensive letters from the Kaggle _Love Letters_ dataset, which we augmented with twelve celebrated love poems. We reserved 24 letters as testing data. This approach, proposed by , was designed to generate a rich diversity in content and stylistic context, spanning two hundred years and incorporating the voices of over 50 distinct authors for significant rewrites. The datasets and code are publicly available at .

Subsequently, emotions linked to each behavior were identified. Figure 0(b) illustrates these emotions, with cell shading reflecting the frequency of specific emotions across the 54 articles; darker shades indicate higher frequencies. Notably, opposite emotions like sadness, fear, joy, and love often co-occur within behaviors such as 'despair', 'wishful', and 'joyful affection'.

The distribution of emotions across linguistic behaviors has unveiled surprising patterns, challenging our initial hypotheses. Contrary to expectations, articles with a despair tone often also displayed positive emotions like love, joy, and happiness. This contradicts the simple mapping made by GPT-4, as illustrated in Figure 0(a). GPT-4, influenced by its training corpora, typically associates positive behaviors with positive emotions and negatives with negatives.

Analysis of selected articles, such as Zelda Sayre's letter to F. Scott Fitzgerald (Appendix D), reveals a complex spectrum of emotions:

* _Love (+1.0)_: Expressed intensely, e.g., "there's nothing in all the world I want but you."
* _Despair (-1.0)_: Notable in comments like "I'd have no purpose in life, just a pretty decoration."
* _Happiness (+0.6)_: Evident in future plans, "We'll be married soon, and then these lonesome nights will be over forever."
* _Anxiety (-0.3)_: Shown by "sometimes when I miss you most, it's hardest to write."

Psychological InsightsOur findings align with theories proposing the coexistence of conflicting "selves" within individuals. This concept is supported by Deisseroth's optogenetic studies , discussed in William James' "The Principles of Psychology" . and corroborated in Minsky's "Society of Mind" . These perspectives help explain the observed complex interplay of emotions across linguistic behaviors, where both positive and negative emotions can manifest within a single behavioral context.

### Behavior Classification Evaluation

Building on our insights into the complex interplay of emotions within linguistic behaviors, we evaluated the effectiveness of Dlike's behavior classification approach. In a test dataset of 24 letters, we compared Dlike's unsupervised learning method, which associates emotions with linguistic behaviors, to GPT-4's zero-shot prompt approach (Figure 2). Ground truth was established using averaged assessments from GPT-4, Gemini, and five university students following detailed instructions (procedure detailed in Appendix I). Final ratings were based on these averages, with a standard deviation of less than 0.3 or one scale.

Figure 0(a) demonstrates that Dlike's classification accuracy surpasses GPT-4's zero-shot method by 11.3 percentage points, confirming the effectiveness of Dlike's detailed emotion-behavior mapping.

Figure 1: Emotion distributions in affection behaviors from extreme sadness (-1) to intense happiness (+1). (a) GPT-4’s zero-shot prompt shows simple behavior-emotion mapping. (b) Dlike’s analysis reveals complex emotion-behavior relationships.

The 5% error bar reflects the complexity of emotions in letters and variability in human annotations (further discussed shortly). Figure 1(b) illustrates the behavior classification distributions across the three predictors. While GPT-4's predictions often fall into two polar categories, those from human annotators and \(\) show a more even distribution. \(\)'s prediction entropy (2.13) is notably higher than GPT-4's (1.80), indicating a more diverse set of predictions. This higher entropy suggests a more complex classification system, advantageous for accurately understanding and responding to diverse emotional states.

The highest entropy among human annotators (2.56) indicates subjectivity in their evaluations. To address this and explore the causes of variability in human annotation, we present a detailed analysis in Appendix C. This analysis supports the development of an adversarial scheme aimed at enhancing objectivity and reliability in sentiment classification, which we discuss in the next section. This refined approach to behavior-emotion mapping not only improves classification accuracy but also enhances our ability to identify and understand complex, potentially unwanted behaviors, setting the stage for more effective ethical guardrails in AI systems.

### Adversarial Evaluation and Rectification

The adversarial design, inspired by , embodies the principles of justice and the devil's advocate. The cross-examination module is essential in reducing subjectivity in ethical judgments while enhancing explainability and adaptability to cultural variations. Experimental results show that when two LLM agents adopt opposing stances on a topic, their linguistic behaviors can transcend the typical model default of maximum likelihood, which is usually drawn from the training data .

Once \(\) and \(\) have identified an ethical violation, the content can be rectified by adjusting the underlying emotions away from undesirable behaviors such as hate and despair. The letter rewriting process has already demonstrated the LLMs' capability for such rectifications; examples of rewritten letters are presented in Appendix F.

## 5 Conclusion

This work presents a three-branch framework for ethical AI behavior, inspired by governmental checks and balances, centered on the \(\)-\(\) duality. By separating roles into knowledge generation (LLMs as executive), ethical guardrails (\(\) as legislative), and contextual interpretation (\(\) as judicial), the framework enables ethical oversight without undermining LLM functionality. The dynamic between \(\) and \(\) keeps ethical principles stable while adapting interpretations across cultural contexts.

Using basic emotions from Ekman and Plutchik, we quantified relationships between emotions and language patterns. Although complex emotions (e.g., pride, guilt) might decompose into basic elements, the feasibility remains debated [2; 42] (see Appendix E).

Pilot studies suggest effectiveness in ethically complex scenarios where cultural context shapes interpretation. Future work will further test real-world adaptability, confirming the framework's balance of ethical integrity and cultural relevance.

Figure 2: Behavior Classification: (a) accuracy (b) entropy