# Boundary Decomposition for

Nadir Objective Vector Estimation

 Ruihao Zheng Zhenkun Wang

School of System Design and Intelligent Manufacturing,

Southern University of Science and Technology

12132686@mail.sustech.edu.cn, wangzhenkun90@gmail.com

Corresponding author

###### Abstract

The nadir objective vector plays a key role in solving multi-objective optimization problems (MOPs), where it is often used to normalize the objective space and guide the search. The current methods for estimating the nadir objective vector perform effectively only on specific MOPs. This paper reveals the limitations of these methods: exact methods can only work on discrete MOPs, while heuristic methods cannot deal with the MOP with a complicated feasible objective region. To fill this gap, we propose a general and rigorous method, namely boundary decomposition for nadir objective vector estimation (BDNE). BDNE scalarizes the MOP into a set of boundary subproblems. By utilizing bilevel optimization, boundary subproblems are optimized and adjusted alternately, thereby refining their optimal solutions to align with the nadir objective vector. We prove that the bilevel optimization identifies the nadir objective vector under mild conditions. We compare BDNE with existing methods on various black-box MOPs. The results conform to the theoretical analysis and show the significant potential of BDNE for real-world application.

## 1 Introduction

The multi-objective optimization problem (MOP) can be written as

\[&()=(f_ {1}(),,f_{m}())^{},\\ &,\] (1)

where \(=(x_{1},,x_{n})^{}\) is the decision vector (also called solution), and \(^{n}\) denotes the feasible region. \(:^{n}^{m}\) is composed of \(m\) objective functions, and \(()\) is the objective vector corresponding to \(\).

**Definition 1**.: _Given two vectors \(,^{m}\), \(\) is said to_ **dominate**_\(\) (denoted as \(\)), if and only if \(u_{i} v_{i}\) for every \(i\{1,,m\}\) and \(u_{j}<v_{j}\) for at least one \(j\{1,,m\}\)._

**Definition 2**.: _A decision vector \(^{*}\) and the corresponding objective vector \((^{*})\) are_ **Pareto-optimal**_, if there is no \(\) such that \(()\) dominates \((^{*})\) according to Definition 1._

**Definition 3**.: _A decision vector \(^{*}\) and the corresponding objective vector \((^{*})\) are_ **weakly Pareto-optimal**_, if there does not exist another decision vector \(\) such that \(f_{i}()<f_{i}(^{*})\) for all \(i=1,,m\)._

**Definition 4**.: _The set of all Pareto-optimal solutions is called the_ **Pareto set**_(denoted as \(PS\)), and the set of all Pareto-optimal objective vectors is called the_ **Pareto front**_(denoted as \(PF\))._

**Definition 5**.: _The relative complement of the \(PF\) in the set of all weakly Pareto-optimal objective vectors is called the_ **weakly Pareto-optimal boundary**_(denoted as \(WPB\))._

**Definition 6**.: _The_ **ideal objective vector \(^{ide}\)** _is composed of the lower bounds of the \(PF\), i.e., \(z_{i}^{ide}=_{ PS}f_{i}()\) for \(i=1,,m\). The_ **nadir objective vector \(^{nad}\)** _consists of the upper bounds of the \(PF\), i.e., \(z_{i}^{nad}=_{ PS}f_{i}()\) for \(i=1,,m\)._

**Definition 7**.: _For the \(i\)-th objective function \(f_{i}\) with \(i\{1,,m\}\), an objective vector \(^{(i)^{c}}\) is called the_ **critical point**_of \(f_{i}\) if it is Pareto-optimal and has the worst \(f_{i}\) value, i.e., \(^{(i)^{c}}\{()|=_{ PS}f_{i}()\}\). The nadir objective vector is often determined by obtaining the critical point on each objective, since \(z_{i}^{nad}=z_{i}^{(i)^{c}}\) for each \(i\{1,,m\}\)._

The nadir objective vector is a fundamental concept of multi-objective optimization and has been widely applied to real-world problems [1; 2; 3]. Specifically, numerous optimization methods' operations involve the nadir objective vector. Firstly, the nadir objective vector is often used to guide the search in various tasks, including both continuous MOPs [4; 5] and discrete MOPs [6; 7]. An inaccurate estimation of the nadir objective vector degrades the performance of exact algorithms , evolutionary algorithms , and multi-objective learning . Secondly, the nadir objective vector offers a comprehensive view of the \(PF\) for decision-makers, which can facilitate the application of preference-based algorithms [11; 12; 2]. For example, an accurate nadir objective vector is the assumption of many interactive algorithms. A poor approximation may cause biased decisions. In addition, the nadir objective vector and the ideal objective vector are widely used to normalize the objective space . Normalization with an inappropriately estimated nadir objective vector can cause performance deterioration of the optimization algorithm [14; 15].

The ideal objective vector can be acquired by minimizing each objective separately. Unfortunately, obtaining the nadir objective vector is much more complicated [16; 17]. Existing exact methods are developed for discrete MOPs, posing significant challenges for their extension to other MOPs. The remaining methods are heuristic, showing satisfactory performance on simple MOPs. For example, DTLZ1 has an equilateral-triangle-shaped \(PF\), and its nadir objective vector can be easily estimated using several heuristic methods . However, when the MOP possesses a complicated feasible objective region (_e.g._, an irregular \(PF\) and the \(WPB\)), all heuristic methods fail to approximate the nadir objective vector accurately.

In this paper, we first demonstrate the shortcomings of existing methods in detail. After that, we propose a general method with theoretical guarantees called boundary decomposition for nadir objective vector estimation (BDNE). We implement BDNE for black-box MOPs and use 28 black-box problems to validate its performance. The results indicate that BDNE remarkably outperforms the existing methods. The major contributions of BDNE are summarized as follows:

* Scalarization method for boundary decomposition. We define the boundary subproblem that converts an objective vector into a scalar via boundary weight vectors. We prove that the critical point of each objective can be found by optimizing a particular boundary subproblem under mild conditions (_i.e._, the critical point satisfies proper Pareto optimality). We also prove that the optimal solution to any boundary subproblem is Pareto-optimal, thereby facilitating the search of the particular boundary subproblems.
* Bilevel optimization based on boundary decomposition. We formulate a bilevel optimization problem for each objective, aiming to identify the particular boundary subproblem by comparing the optimal solutions of boundary subproblems. The upper-level optimization seeks each objective's boundary weight vector that maximizes the objective function value; the lower-level optimization searches for the optimal solutions of given boundary subproblems. Besides, the trade-off of decision-makers can be involved in finding a satisfactory nadir objective vector.

## 2 Related Works

Existing nadir objective vector estimation methods can be divided into two categories: 1) exact methods and 2) heuristic methods.

**Exact Method.** Exact methods are all designed for discrete MOPs and cannot be applied to other problems. For example, the methods in [18; 19] assume that the objective function values are integers, limiting their applicability to continuous problems. Moreover, some exact methods are exclusively designed for multi-objective integer linear programming . \(m\) bilevel optimization problems areformulated in  and guarantee that their optimal solutions construct the nadir objective vector. The bilevel optimization is implemented solely for the discrete search space where an exhaustive search is available. However, the exact solver is often unavailable for many problems such as non-linear continuous ones, leading to uncertain optimality gaps. As a result, the pay-off table, which this method relies heavily on, may be tough to obtain. In addition, its lower-level optimization, including two stages, may exhibit significant unreliability and high computational costs. Another significant limitation of exact methods is their inability to solve beyond small-scale problems within reasonable runtimes, thus posing substantial challenges to their real-world applicability.

**Heuristic Method.** Heuristic methods readily apply to diverse MOPs yet lack theoretical guarantees. Generally, the heuristic method estimates the nadir objective vector as follows

\[_{i}^{nad}=_{ S}f_{i}()i=1,,m,\] (2)

where \(S\) is an iteratively improved solution set. \(S\) can be specified as the population of the multi-objective evolutionary algorithm (MOEA)  (denoted as SF1). When the population is the \(PS\), Eq. (2) becomes the definition of the nadir objective vector. That is, SF1 can achieve the nadir objective vector under the ideal situation where the population is the \(PS\). However, this is almost impossible because retaining inferior solutions, such as weakly Pareto-optimal or dominance-resistant ones, in the population is often inevitable . In case the population contains these inferior solutions, the SF1-based algorithm may be severely misled and fail to estimate the nadir objective vector, as shown in Figure 1(b) and Figure 1(f) (see Section 4). Several methods are proposed to mitigate the impact of inferior solutions by selecting a subset from the population [24; 25; 26]. Additionally, \(S\) can be obtained by identifying extreme points in the population. In [27; 28; 29], the extreme points are determined by finding the objective vector with minimum values on each objective function. This method is also known as the pay-off table method, which can overestimate or underestimate the nadir objective vector [30; 20]. Some methods identify the objective vectors that are closest to axis vectors as extreme points. The distance between the objective vector and the axis vector can be measured by the Minkowski distance (_e.g._, \(L_{2}\) and \(L_{}\)), the perpendicular distance , and the cosine similarity . In , each objective is associated with a single-objective optimization subproblem to determine \(m\) extreme points. In Appendix A, we use an example to illustrate the deficiencies of heuristic methods in estimating the nadir objective vector. We can observe from Figure 4 and Table 4 that all methods incorrectly estimate the critical points as well as the nadir objective vector.

## 3 Methodology

To address the limited applicability of exact methods and the unreliability of heuristic methods, we propose a method with general applicability to any MOP and theoretical guarantees in this section. Specifically, our method does not necessitate the objective function value to be an integer as opposed to [18; 19] and involves simpler optimization tasks compared to . Our method also enables finding the nadir objective vector, unlike heuristic methods. Furthermore, our method supports using a user-defined trade-off. In the following, we begin by introducing boundary decomposition and establishing its theoretical foundations. After that, we develop a bilevel optimization method based on boundary decomposition to achieve alignment with the nadir objective vector. This method is then implemented for the black-box MOP, and its effectiveness is evaluated in the subsequent section.

### Boundary Subproblem

We define a boundary subproblem for the \(i\)-th objective as

\[g_{i}^{bd}(|^{i},^{r},)=_{1 j m }\{w_{j}^{i}((1-)f_{j}()+_{k=1} ^{m}f_{k}()-z_{j}^{r})\},\] (3)

where \(^{i}\) is called the boundary weight vector of the \(i\)-th objective, \(^{r}\) is a reference point, and \(0<<1\). \(^{i}\) satisfies three conditions: 1) \(w_{i}^{i}=0\); 2) \( j\{1,,m\},w_{j}^{i} 0\); 3) \(\ j\{1,,m\},w_{j}^{i}>0\). The definition of the boundary subproblem is inspired by the modified weighted Tchebycheff metric . The contour surface of the boundary subproblem is illustrated in Figure 1. Additionally, several examples are presented to demonstrate the optimal objective vector of the boundary subproblem. In the following, we provide the theoretical foundations. Claims are followed by corresponding explanations. All proofs are presented in Appendix F.

**Definition 8** (From ).: _Let \(}\) be the image of an objective vector \(\), where_

\[_{i}=(1-)z_{i}+_{j=1}^{m}z_{j}\;\; \;\;i=1,,m\;\;(0<<1).\] (4)

_Given a value of \(\) and two objective vectors \(\) and \(\), \(\) is said to_ **cone-dominate \(\)** _(denoted as \(^{c}\)) if and only if \(}}\)._

**Definition 9**.: _Given a value of \(\), an objective vector is cone-optimal if no objective vector can cone-dominate it._

**Theorem 1**.: _The optimal objective vector to the boundary subproblem with \(^{i}\) (denoted as \(^{*}\)) must be Pareto-optimal, if and only if \( j\{1,,m\}\{i\}\) such that \(z_{j}^{r}_{j}^{*}\)._

**Theorem 2**.: _Let \(z_{j}^{r}_{j}^{(i)^{c}}\) for every \(j\{1,,m\}\{i\}\). \(^{(i)^{c}}\) uniquely solves the boundary subproblem with_

\[w_{j}^{i}=0,&j=i,\\ _{j}^{(i)^{c}}-z_{j}^{r}},&j i,\] (5)

_if and only if \(^{(i)^{c}}\) is cone-optimal._

**Corollary 1**.: _To ensure the validity of Theorem 2 without further information, it is necessary to satisfy the condition \(z_{j}^{r}_{j}^{(i)^{c}}\) for every \(j\{1,,m\}\{i\}\)._

Firstly, we reveal the connection between the boundary subproblem and the nadir objective vector. The boundary subproblem involves two steps: transforming the given objective vector and scalarizing the transformed objective vector with the boundary weight vector. The transformation implies cone domination, which defines a strict partial order (see Appendix F.1 for details) and belongs to the family of generalized Pareto domination . We assume that the critical points are cone-optimal and a set of objective vectors is obtained by optimizing infinitely sampling boundary subproblems. According to Theorems 1 and 2, this set is a subset of the \(PF\) and the critical points are included in it. Finally, the nadir objective vector can be identified by Eq. (2) where \(S\) is specified as the obtained set.

**Definition 10** (From ).: _A decision vector \(^{*}\) and the corresponding objective vector \((^{*})\) are_ **properly Pareto-optimal** _if they are Pareto-optimal and if there exists a finite number \(M>0\) such that, for each \(i\) and any \(\), we have_

\[(^{*})-f_{i}()}{f_{j}()-f_{j}( ^{*})} M,\] (6)

_where \(j\) satisfies \(f_{j}(^{*})<f_{j}()\)._

**Theorem 3**.: _An objective vector is cone-optimal, if and only if the objective vector is Pareto-optimal and the value of \(\) satisfies_

\[.\] (7)

**Corollary 2**.: _A cone-optimal objective vector is also properly Pareto-optimal._

Figure 1: The contour surfaces of boundary subproblems.

The following question arises: under what conditions can a solution be considered cone-optimal? Let \(=(0,1,1)^{}\) and \(=(0.2,0.5,0.5)^{}\) be a critical point and Pareto-optimal objective vector, respectively. If \(=0.5\), then \(^{}\) (since \(}=(1,2,2)^{}\) and \(}=(0.8,1.1,1.1)^{}\)); If \(=0.1\), then \(^{}\) and \(^{}\) (since \(}=(0.2,1.2,1.2)^{}\) and \(}=(0.32,0.62,0.62)^{}\)). The critical point is cone-dominated if an excessive \(\) value is used. We should know how to set an appropriate \(\) to preserve the specific Pareto-optimal objective vectors. We find that cone domination is related to proper Pareto optimality. The idea of proper Pareto optimality is to divide the \(PS\) into proper and improper ones. The definition of proper Pareto optimality is shown in Definition 10. That is, a solution can be considered properly Pareto-optimal when at least one pair of objectives satisfies: a finite decrement in one objective requires a reasonable increment in the other objective. We also can infer that different proper Pareto-optimal solutions may necessitate distinct minimum values of \(M\). Then we derive that \(\) is bounded by \(M\) as shown in Theorem 3. Corollary 2 is established accordingly. We can let \(\) be a sufficiently small value such that the critical points are cone-optimal.

**Theorem 4**.: _Let \(^{*}\) be an objective vector satisfying \(z_{j}^{r}_{j}^{*}\) for every \(j\{1,,m\}\{i\}\). If an objective vector \(^{}\) does not cone-dominate \(^{*}\) and \(z_{i}^{*} z_{i}^{}\), then \(^{*}\) has a lower function value than \(^{}\) with respect to some boundary subproblem of the \(i\)-th objective._

**Corollary 3**.: _Let \(^{e}\) consist of the optimal values of \(m\) BLOPs and \(\{|^{e}\}\) be the promising region. Any Pareto-optimal objective vector outside the promising region fails to address the trade-off of decision-makers, namely, \(M>\)._

The remaining issue is that \(M\) is not known in advance, making it difficult to set \(\) according to \(M\). We introduce a user-defined parameter \(\) (\(>0\)) and let \(=\). \(\) represents the upper bound of the trade-off between the \(k\)-th and \(l\)-th objectives, where \(k=_{1 j m}f_{j}(^{*})-f_{j}()\) and \(l=_{1 j m}f_{j}()-f_{j}(^{*})\). In other words, \(\) is the amount of increment in the value of one objective function that the decision-maker is willing to tolerate in exchange for a one-unit decrement in another objective function. If the preference of decision-makers about \(\) is available, we have the guarantee shown in Corollary 3 derived from Theorems 3 and 4. Corollary 3 can guarantee to obtain a satisfactory nadir objective vector. When the preference is not provided, \(\) can take a sufficiently large value. On the one hand, if a finite trade-off \(M\) exists for the critical point, then \(\) can take an appropriate value from \([M,)\) to obtain the nadir objective vector. On the other hand, \(M\) results in \( 0\), which means the corresponding objective vector is not properly Pareto-optimal. In practical terms, a Pareto-optimal solution with a very large value of \(M\) does not essentially differ from an inferior solution for decision-makers. If the critical points are improper, using a generally agreeable value of \(\) is reasonable.

**Theorem 5**.: _The optimal objective vector to the boundary subproblem with \(^{i}\) (denoted as \(^{*}\)) must be cone-optimal (or properly Pareto-optimal), if \( j\{1,,m\}\{i\}\) such that \(z_{j}^{r}<_{j}^{*}\)._

**Theorem 6**.: _Let \(z_{j}^{r}<_{j}^{*}\) for every \(j\{1,,m\}\{i\}\). If an objective vector \(^{*}\) is optimal for the boundary subproblem with \(^{i}\), \(^{*}\) must be an optimal objective vector to the boundary subproblem with_

\[w_{j}^{*}=0,&j=i,\\ _{j}^{*}-z_{j}^{r}},&j i.\] (8)

Moreover, we can make minor modifications to Theorem 1, resulting in Theorem 5. Theorem 6 can be deduced using Theorem 5. Theorem 6 reveals the relationship between the boundary subproblem's optimal solution and the boundary weight vector, which is useful for designing the algorithm in Section 3.3.

### Nadir Objective Vector Estimation via Bilevel Optimization

Practically, we cannot have infinite boundary subproblems. In this subsection, an optimization problem is defined to obtain the nadir objective vector. Its two goals are: 1) converging to Pareto-optimal objective vectors and 2) identifying critical points from Pareto-optimal ones. In the 2-objective case, both goals can be achieved through a single optimization procedure. Specifically, the critical points can be obtained by optimizing boundary subproblems using \((1,0)^{}\) and \((0,1)^{}\) as the weight vectors. This is because solving the boundary subproblem with \(^{i}\) is equivalent to solving that with \(^{i}\) where \(>0\) is a constant. Unfortunately, the critical points cannot be obtained by a fixed boundary subproblem when the MOP involves three or more objectives. That is, both goals cannot be achieved simultaneously. This motivates the formulation of a bilevel optimization problem (BLOP) for each objective to achieve the two goals: the lower-level optimization problem (LLOP) corresponds to the first goal while the upper-level optimization problem (ULOP) is for the second goal. The BLOP is formulated below, based on the boundary subproblem.

Firstly, \(M\) is affected by different value ranges of objective functions, which might lead to algorithm performance deterioration . The objective space should be normalized properly. We let \(z_{j}^{r}=0\) for \(j=1,,m\) in Eq. (3) and introduce two reference points \(^{r1}\) and \(^{r2}\) (\(z_{j}^{r2}>z_{j}^{r1}\) for \(j=1,,m\)) for normalization. Then, the boundary subproblem with normalization can be written as

\[g_{i}^{bdn}(|^{i},^{r1},^{r2},) =_{1 j m}\{w_{j}^{i}((1-)f_{j}^{}( )+_{k=1}^{m}f_{k}^{}()) \},\] (9)

where \(f_{k}^{}()=(f_{k}()-z_{k}^{r1})/(z_ {k}^{r2}-z_{k}^{r1})\) for \(k=1,,m\). In this formulation, \(^{r1}\) should be set according to Theorem 1 and Corollary 1. For example, it is reasonable to set \(^{r1}\) to \(^{ide}\) since \(z_{j}^{ide} f_{j}()\) for \(j=1,,m\) such that \((1-)f_{j}^{}()+_{k=1}^{m}f_{k}^{ }() 0\). Furthermore, \(^{r2}\) should be set according to . Secondly, several boundary subproblems might have the same optimal solution. On the one hand, solving the boundary subproblem with \(^{i}\) is equivalent to solving that with \(^{i}\) where \(>0\) is a constant. We can let \(_{j=1 j i}^{m}w_{j}^{i}=1\). On the other hand, Theorem 6 indicates that the optimal objective vectors to some boundary subproblems may not align with the corresponding boundary weight vectors. For example, this scenario is common on discrete MOPs. We can penalize the flat landscape of the ULOP according to the distance between the boundary weight vector and its optimal objective vector. Let \(^{}\) be the optimal solution of the boundary subproblem with \(^{i}\). In this paper, we calculate the distance as \(d(^{i},^{})=^{m}( w_{j}^{i}-u_{j}/_{k=1}^{m}u_{k})^{2}}\) where

\[u_{j}=0,&j=i,\\ ^{}()+_{k=1}^{m}f_ {k}^{}()},&j i.\] (10)

Let \(\) be a sufficiently small constant, \(l\{1,,m\}\{i\}\), and \(I=\{1,,m\}\{i,l\}\). Finally, the BLOP with respect to the \(i\)-th objective for \(i=1,,m\) has the ULOP formulated as

max. \[f_{i}^{u}(^{i})=f_{i}(^{})- d( ^{i},^{}),\] s.t. \[w_{i}^{i}=0, w_{l}^{i}=1-_{j I}w_{j}^{i},_ {j I}w_{j}^{i} 1,\] (11) \[0 w_{j}^{i} 1j I,\]

where \(^{}\) is the optimal decision vector to the LLOP of the following form

min. \[f_{i}^{l}()=g_{i}^{bdn}(|^{i}, ^{r1},^{r2},),\] (12) s.t. \[.\]

The search is performed on the original decision space in the LLOP, while the search space of the ULOP can be viewed as \(^{m-2}\) (_i.e._, \((m-2)\)-dimensional Euclidean space). For the \(i\)-th objective, the ULOP uses a boundary weight vector \(^{i}\) as a solution and requires maximizing the \(i\)-th penalized objective function value of the Pareto-optimal solution obtained by the LLOP. In other words, a feasible solution of the ULOP requires an optimal solution of the LLOP. We propose an algorithm framework called BDNE for estimating the nadir objective vector on the MOP with more than two objectives. Specifically, BDNE aims to solve these \(m\) BLOPs. The steps of BDNE are given in Algorithm 1, where \(\) is the user-defined upper bound of the trade-off (see Section 3.1 for details). Three following issues should be specified: determine the reference points \(^{r1}\) and \(^{ 2}\), choose suitable single-objective optimizers, and set the stopping criteria.

### Algorihm for Black-Box Multi-Objective Optimization Problems

To evaluate the viability of BDNE, we implement it for black-box MOPs. We adopt evolutionary algorithms as the solvers in BDNE. Each ULOP uses CMA-ES  to search the eligible boundary weight vector(s). We utilize CMA-ES to optimize the ULOP for two reasons. First, CMA-ES is a state-of-the-art algorithm for single-objective black-box optimization. Second, optimal solutions to the LLOPs are not always available; instead, approximate solutions are often obtained. Consequently, the function values of the approximate solutions may exhibit noise. CMA-ES is suitable for this task as it demonstrates strong robustness in optimizing noisy functions . In each iteration, \(m\) ULOPs generate the pending LLOPs simultaneously. Then all LLOPs are solved collaboratively by the MOEA instead of optimizing each LLOP separately. This is because the superiority of MOEAs is demonstrated empirically and theoretically in solving multi-objective black-box optimization problems .

**Stopping Criteria and Reference Points.** The maximal number of iterations is employed as the stopping criterion for the ULOP as well as the LLOP. We use \(_{u}\) and \(_{l}\) to denote the maximum number of iterations for the ULOP and the LLOP respectively. \(^{r^{1}}\) is set to the current best objective function values. \(^{r^{2}}\) is constructed by the current best objective function values of \(m\) ULOPs. Initially, EC-NSGA-II  runs for \(_{l}\) iterations. The minimum and maximum objective function values of its final population determine the settings of \(^{r^{1}}\) and \(^{r^{2}}\). Then \(^{r^{1}}\) is updated once a new solution is generated. \(^{r^{2}}\) is only renewed when the parameters of CMA-ES update. During the optimization process, \(^{r^{1}}\) and \(^{r^{2}}\) iteratively approximate \(^{ide}\) and \(^{nad}\) respectively.

**Upper-Level Optimization.**\(m\) ULOPs represents \(m\) CMA-ES procedures. Let \(=-1\). The population size of each CMA-ES procedure is \(\). That is, \((N-m)\) boundary weight vectors are used to align with the eligible ones and evenly assigned to \(m\) objectives. Let \(\{^{i,j},j=1,,\}\) denote the set of adjustable boundary weight vectors for the \(i\)-th objective. Initially, most of them are sampled from the initial distribution of the CMA-ES procedure. The sampled points may need to be repaired to satisfy the constraints in the ULOP. For each objective, one boundary weight vector is initialized to the vector with \((m-1)\) elements being \(\) (_e.g._, \((0,,)^{}\)). The remaining \(m\) ones, which are \(m\) different unit vectors, are fixed throughout the optimization of \(m\) BLOPs. The LLOPs with these \(m\) boundary weight vectors can motivate the search of \(^{ide}\). Besides, they enhance population diversity when the adjustable boundary subproblems become similar. When LLOPs are stopped, the parameters of each CMA-ES procedure are updated first according to the \(\) boundary weight vectors. Let \(^{i,j} A\) be the best solution so far for the subproblem with \(^{i,j}\), and then the fitness of \(^{i,j}\) is defined as \((f_{i}(^{i,j})- d(^{i,j}, ^{i,j}))\). Note that some boundary weight vectors, such as repaired ones, might not be directly generated from the current distribution of the CMA-ES procedure. These injected solutions should obey the injection rule . Subsequently, the boundary weight vectors of the \(i\)-th objective are updated as follows:

1. [label=**Step 0**]
2. \(W\{^{i,j},j=1,,\}\) and then delete \(\) the worst boundary weight vector in \(W\).
3. Transform the best one in \(W\) according to Eq. (10).

   Symbol & Description \\  \(_{u}(_{l})\) & Maximum number of iterations for each CMA-ES procedure (the MOEA solving LLOPs). \\ \(N\) & \(\); number of generated LLOPs in each iteration of \(m\) ULOPs. \\ \(P\) & \(||=N\); population of the MOEA for solving \(N\) LLOPs. \\ \(A\) & \(|A|=N\); elite archive preserved the current best solutions for \(N\) LLOPs. \\ \(^{i,j}\) & The \(j\)-th boundary weight vector of the \(i\)-th objective. \\   

Table 1: Notation used in Section 3.3.

**Step 3** Create \(\) new ones via the \(i\)-th CMA-ES procedure and integrate them into \(W\).

The updated \(^{r^{2}}\) may substantially alter the normalized space in Eq. (9), potentially changing the optimal solution to the LLOP. As Theorem 6 reports, Step 2 can effectively preserve the best solution for the LLOP, irrespective of changes in the normalized space. Particularly, in the last iteration of the ULOP (_i.e._, the \(_{u}\)-th iteration), \(^{i,1},,^{i,t}\) are all changed to the boundary weight vector with the best fitness for \(i=1,,m\). More computational resources are allocated to the \(i\)-th objective's current best LLOP in the final iteration. It helps to obtain a better approximation for these \(m\) LLOPs.

**Lower-Level Optimization.**\(N\) LLOPs are optimized by an MOEA with population size \(N\). An evolutionary algorithm executes solution reproduction and environmental selection iteratively. The reproduction procedure of the proposed MOEA includes two steps:

* Use binary tournament selection based on \(\) to obtain the mating pool from \(P\).
* Apply reproduction operators to create an offspring set of size \(N\) (denoted as \(O\)).

\(\) is a utility vector including utility values of solutions in \(P\). A solution with a lower utility value is more likely to enter the mating pool. The selection procedure is performed as follows:

* Calculate \(=r_{1},,r_{|P O|}^{}\) for \(P O\).
* Select the smallest \(N\) elements of \(\) and their corresponding solutions for the new \(\) and the new generation of \(P\), respectively.
* Identify the best solutions for the \(N\) subproblems from \(P O\) for the new generation of \(A\).

Given a decision vector \(^{k} P O\), we let \(R^{k}_{i,j}\) be the ascending rank of \(g^{bdn}_{i}(^{k}|^{i,j},^{r1},^{r2},)\) within \(g^{bdn}_{i}(|^{i,j},^{r1},^{ r2},) P O}\). \(r_{k}\) is formulated as \(r_{k}=_{(i,j) I}\{R^{k}_{i,j}\}\) where \(I=\{(i,j)|i=1,m,j=1,,\}\). \(^{k}\) with a smaller \(r_{k}\) implies a higher quality.

## 4 Experimental Studies

### Experimental Setup

**Instances.** We proposed 4 scalable test problems denoted as TN1-TN4. The feasible objective regions of TN1 and TN2 are shown in Figure 1(a) and Figure 1(e). The \(PF\) of TN1 is a \((m-1)\)-dimensional simplex. TN2 has a concave \(PF\) constructed by two \((m-1)\)-dimensional simplices. TN3 and TN4 are the modified versions of TN1 and TN2 respectively. Their objective functions have different value ranges. Details of TN1-TN4 are available in Appendix B. Moreover, we select problems with different shapes of feasible objective regions, including 6 existing test problems [46; 47; 48; 49] (DTLZ3, mDTLZ3, MaF2, DTLZ5, IMOP4, and IMOP6) and 4 real-world problems [50; 51; 52] (MP-DMP, ML-DMP, RE3-4-7, and RE5-3-1). We consider test problems with 3, 5, and 8 objectives, which accordingly have 8, 12, and 16 variables. The \(PF\)s of RE3-4-7 and RE5-3-1 are unknown and represented by their current best solution sets.

**Comparison Algorithms2**. BDNE is compared with 2 representative heuristic algorithms for black-box MOPs: ECR-NSGA-II  (based on SF1) and DNPE  (based on EP6). ECR-NSGA-II is parameter-free. DNPE is configured according to the corresponding reference (_i.e._, \(=100\)). For BDNE, we set \(=100\) and \(_{l}=200\). Then \(_{u}=14\) according to the setting of \(_{l}\) and \(FE_{max}\). The general algorithm settings are summarized in Table 2, where \(FE_{max}\) means maximum number of function evaluations. Each algorithm is executed 30 times on each instance. Additionally, the computer resources and algorithm runtimes can be found in Appendix C.

**Performance Metric.** The estimated nadir objective vector is extracted by Eq. (2) where \(S\) is the final population. Let \(^{ind}_{i}\) be the estimated nadir objective vector. The error metric value is computed by \(E=^{m}(z^{ind}_{i}-^{nad}_{i})/(z^{ind}_{i}-z^{ idc}_{i})^{2}}\). The result table records the mean metric value

   \(m\) & \(N\) & \(FE_{max}\) & Operator \\ 
3 & 60 & 180,000 & \\
5 & 100 & 300,000 & SBX+PM \\
8 & 160 & 480,000 &  \\   

Table 2: General algorithm settings.

and the standard deviation across all runs for each instance. The performance rank on each instance is inside parentheses. "+", "=" or "-" denotes that the performance of the corresponding algorithm is statistically better than, similar to, or worse than that of BDNE based on Wilcoxon's rank sum test at 0.05 significant level. "\(\)" indicates the gap between the mean metric value of the corresponding algorithm and that of BDNE. The best mean metric values are also emphasized.

### Results

Table 3 shows the statistical results on 28 instances. Across most instances, BDNE outperforms the other algorithms and has mean metric values below \(5\%\). In Figure 2, we can see that BDNE accurately approximates at least one critical point for each objective, consistent with our theoretical analysis. DNPE ranks second. DNPE has competitive results on MaF2, DTLZ5, DTLZ2, mDTLZ2, IMOP6, 3-objective ML-DMP, and CRE5-3-1. We can infer that the extreme points determined by DNPE are very close to the critical points of these MOPs. Nevertheless, the performance of DNPE deteriorates on other instances. Besides, comparing the results between TN1 and TN3, value ranges of objective functions significantly impact DNPE but hardly affect BDNE. ECR-NSGA-II achieves the worst overall performance. Moreover, it has large standard deviations on many instances, which indicates its highly unstable performance. This is because ECR-NSGA-II suffers from dominance-resistant

   Problem & \(m\) & ECR-NSGA-II & \(\) & DNPE & \(\) & BDNE \\   & 3 & 2.23\({}_{ 1.36}\)(3)- & -2.23 & 0.203\({}_{ 1.58e-07}\)(2)- & -0.203 & 3.14e-16\({}_{ 6.65e-16}\)(1) \\  & 5 & 5.28\({}_{ 2.11}\)(3)- & -5.28 & 0.171\({}_{ 1.12e-06}\)(2)- & -0.171 & 0.000273\({}_{ 0.00741}\)(1) \\  & 8 & 12.7\({}_{ 1.05}\)(3)- & -12.7 & 0.168\({}_{ 4.15e-06}\)(2)- & -0.146 & 0.00221\({}_{ 0.00331}\)(1) \\   & 3 & 1.46\({}_{ 0.949}\)(3)- & -1.46 & 0.223\({}_{ 3.54e-07}\)(2)- & -0.223 & 0.0000172\({}_{ 0.000535}\)(1) \\  & 5 & 4.77\({}_{ 1.91}\)(3)- & -4.77 & 0.333\({}_{ 4.86e-10}\)(2)- & -0.325 & 0.00803\({}_{ 0.00233}\)(1) \\  & 8 & 12.2\({}_{ 0.843}\)(3)- & -12.2 & 0.333\({}_{ 3.96e-10}\)(2)- & -0.315 & 0.01854\({}_{ 0.00294}\)(1) \\   & 3 & 2.15\({}_{ 1.43}\)(3)- & -2.15 & 0.263\({}_{ 4.02e-08}\)(2)- & -0.263 & 2.39e-16\({}_{ 2.32e-16}\)(1) \\  & 5 & 4.7\({}_{ 1.77}\)(3)- & -4.69 & 0.263\({}_{ 1.85e-08}\)(2)- & -0.262 & 0.000669\({}_{ 0.00203}\)(1) \\  & 8 & 12.7\({}_{ 0.718}\)(3)- & -12.7 & 0.263\({}_{ 1.20e-08}\)(2)- & -0.243 & 0.0195\({}_{ 0.00203}\)(1) \\   & 3 & 1.35\({}_{ 0.88}\)(3)- & -1.35 & 0.337\({}_{ 4.04e-08}\)(2)- & -0.337 & 4.92e-05\({}_{ 5.99e-05}\)(1) \\  & 5 & 5.34\({}_{ 2.17}\)(3)- & -5.34 & 0.337\({}_{ 1.90e-08}\)(2)- & -0.335 & 0.00208\({}_{ 0.00422}\)(1) \\  & 8 & 12.3\({}_{ 0.951}\)(3)- & -12.3 & 0.337\({}_{ 1.42e-08}\)(2)- & -0.31 & 0.0268\({}_{ 0.031}\)(1) \\   & 3 & 0.00268\({}_{ 0.00277}\)(3)- & -0.00268 & 4.29e-10\({}_{ 3.33e-10}\)(2)- & -2.48e-10 & 1.81e-10\({}_{ 2.82e-10}\)(1) \\  & 5 & 0.0269\({}_{ 0.0171}\)(3)- & -0.0269 & 6.04e-10\({}_{ 5.2e-10}\)(2)- & -4.36e-10 & 1.68e-10\({}_{ 1.86e-10}\)(1) \\  & 8 & 0.233\({}_{ 0.167}\)(3)- & -0.233 & 5.91e-10\({}_{ 3.86e-10}\)(2)- & -2.04e-10 & 3.87e-10\({}_{ 5.31e-10}\)(1) \\   & 3 & 0.171\({}_{ 0.0995}\)(3)- & -0.164 & 0.0209\({}_{ 6.14e-06}\)(2)- & -0.0143 & 0.00658\({}_{ 0.00105}\)(1) \\  & 5 & 0.581\({}_{ 0.116}\)(3)- & -0.576 & 0.0112\({}_{ 9.19e-06}\)(2)- & -0.00648 & 0.0047\({}_{ 0.000487}\)(1) \\  & 8 & 0.826\({}_{ 0.00972}\)(3)- & -0.823 & 0.00859\({}_{ 1.25e-05}\)(2)- & -0.005 & 0.00358\({solutions. For example, ECR-NSGA-II retains solutions close to the \(WPB\) in Figure 1(b) and Figure 1(f). Each of these solutions has at least one inferior objective function value.

In general, the two algorithms have huge performance gaps compared with BDNE. The effectiveness and superiority of BDNE are demonstrated. More experiments are presented in Appendix E.

## 5 Conclusion, Limitation, and Future Work

**Conclusion**. In this paper, we have revealed the deficiency of existing methods in estimating the nadir objective vector. Specifically, exact methods suffer from limited applicability and high computational costs, while the irregular \(PF\) and the \(WPB\) can cause significant challenges for heuristic methods. We have proposed a new scalarization method, which can define specific boundary subproblems to find the nadir objective vector under mild conditions. We have formulated \(m\) BLOPs using boundary subproblems and designed a corresponding algorithm framework called BDNE. We have also conducted experimental studies to validate the effectiveness of BDNE. In experiments, BDNE adopts evolutionary algorithms and effectively approximates the nadir objective vectors of various black-box MOPs.

**Limitation and Future Work.** The estimated nadir objective vector can be obtained beforehand or improved with the optimization process. In the paper, we present BDNE as an independent algorithm (_i.e._, estimate the nadir objective vector beforehand). In the future, we will investigate how to integrate BDNE into the iteration of an algorithm to enhance its overall performance (see Appendix E.4 for some pilot studies). Furthermore, BDNE has been implemented in a general manner. We plan to refine BDNE for specific applications, including multi-objective discrete optimization problems. Potential societal impacts can be found in Appendix D.