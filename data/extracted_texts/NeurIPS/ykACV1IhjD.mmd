# Controlling Continuous Relaxation for

Combinatorial Optimization

Yuma Ichikawa

Fujitsu Limited, Kanagawa, Japan

Department of Basic Science, University of Tokyo

###### Abstract

Unsupervised learning (UL)-based solvers for combinatorial optimization (CO) train a neural network that generates a soft solution by directly optimizing the CO objective using a continuous relaxation strategy. These solvers offer several advantages over traditional methods and other learning-based methods, particularly for large-scale CO problems. However, UL-based solvers face two practical issues: **(I)** an optimization issue, where UL-based solvers are easily trapped at local optima, and **(II)** a rounding issue, where UL-based solvers require artificial post-learning rounding from the continuous space back to the original discrete space, undermining the robustness of the results. This study proposes a Continuous Relaxation **a**nnealing1 (**CRA**) strategy, an effective rounding-free learning method for UL-based solvers. CRA introduces a penalty term that dynamically shifts from prioritizing continuous solutions, effectively smoothing the non-convexity of the objective function, to enforcing discreteness, eliminating artificial rounding. Experimental results demonstrate that CRA significantly enhances the performance of UL-based solvers, outperforming existing UL-based solvers and greedy algorithms in complex CO problems. Additionally, CRA effectively eliminates artificial rounding and accelerates the learning process.

## 1 Introduction

The objective of combinatorial optimization (CO) problems is to find the optimal solution from a discrete space, and these problems are fundamental in many real-world applications (Papadimitriou and Steiglitz, 1998). Most CO problems are NP-hard or NP-complete; making it challenging to solve large-scale problems within feasible computational time. Traditional methods frequently depend on heuristics to find approximate solutions, but they require considerable insights into the specific problems. Alternatively, CO problems can be formulated as integer linear programming (ILP) and solved using ILP solvers. However, ILP solvers lacks scalability for large-scaled problems.

Recently, several studies have used machine learning methods to handle CO problems by learning heuristics. Most of these studies focus on supervised learning (SL)-based solvers (Hudson et al., 2021; Joshi et al., 2019; Gasse et al., 2019; Selsam et al., 2018; Khalil et al., 2016), which require optimal solutions to CO problems as supervision during training. However, obtaining optimal solutions is challenging in practice, and SL-based solvers often fail to generalize well (Yehuda et al., 2020). Reinforcement learning (RL)-based solvers (Yao et al., 2019; Chen and Tian, 2019; Yolcu and Poczos, 2019; Nazari et al., 2018; Khalil et al., 2017; Bello et al., 2016) avoid the need for optimal solutions but often suffer from notoriously unstable training due to poor gradient estimation and hard explorations (Mnih et al., 2015; Tang et al., 2017; Espeholt et al., 2018). Unsupervised learning (UL)-based solvers (Schuetz et al., 2022; Karalias and Loukas, 2020; Amizadeh et al., 2018) haverecently attracted much attention. UL-based solvers follow a continuous relaxation approach, training a UL model to output a _soft solution_ to the relaxed CO problem by directly optimizing a differentiable objective function, offering significantly stable and fast training even for large-scale CO problems. Notably, the physics-inspired GNN (PI-GNN) solver (Schuetz et al., 2022a) employs graph neural networks (GNN) to automatically learn instance-specific heuristics and performs on par with or outperforms existing solvers for CO problems with millions of variables without optimal solutions.

While these offer some advantages over traditional and other machine learning-based solvers, they face two practical issues. The first issue is an optimization issues where UL-based solvers are easily trapped at local optima. Due to this issue, Angelini and Ricci-Tersenghi (2023) demonstrated that the PI-GNN solver (Schuetz et al., 2022a) could not achieve results comparable to those of the degree-based greedy algorithm (DGA) (Angelini and Ricci-Tersenghi, 2019) on maximum independent set (MIS) problems in random regular graphs (RRG). Wang and Li (2023) also pointed out the importance of using dataset or history, and initializing the GNN with outputs from greedy solvers to help the PI-GNN solver overcome optimization challenges. This issue is a crucial bottleneck to the applicability of this method across various real-world applications. The second issue relates to the inherent ambiguity of the continuous relaxation approach. This approach necessitates artificial rounding from the soft solution, which may include continuous values, back to the original discrete solution, potentially undermining the robustness of the results. While linear relaxation can provide an optimal solution for original discrete problems on bipartite graphs (Hoffman and Kruskal, 2010), it typically leads to solutions with \(1/2\) values, which is known to half-integrality (Nemhauser and Trotter Jr, 1974), in which existing rounding methods (Schuetz et al., 2022b; Wang et al., 2022) completely lose their robustness. For NP-hard problems with graph structures, such as the MIS and MaxCut, semidefinite programming (SDP) relaxations have been proposed as effective approximation methods (Lovasz, 1979; Goemans and Williamson, 1995). However, these approaches rely on rounding techniques, such as spectral clustering (Von Luxburg, 2007), to transform relaxed solutions into feasible ones, which often fails to obtain optimal solutions.

To address these issues, we propose the **C**ontinuous **R**elaxation **A**nnealing (**CRA**). CRA introduces a penalty term to control the continuity and discreteness of the relaxed variables, with a parameter \(\) to regulate the intensity of this penalty term. When the parameter \(\) is small, the relaxed variable tends to favor continuous solutions, whereas a large \(\) biases them toward discrete values. This penalty term also effectively eliminates local optimum. Moreover, a small \(\) forces the loss function to approach a simple convex function, encouraging active exploration within the continuous space. CRA also includes an annealing process, where \(\) is gradually increased until the relaxed variables approach discrete values, eliminating the artificial rounding from the continuous to the original discrete space after learning. In this study, the solver that applies the CRA to the PI-GNN solver is referred to as the CRA-PI-GNN solver. We also demonstrate the benefits of the CRA through experiments on benchmark CO problems, including MIS, maximum cut (MaxCut), and diverse bipartite matching (DBM) problems across graphs of varying sizes and degrees. The experimental results show that the CRA significantly enhances the performance of the PI-GNN solver, outperforming the original PI-GNN solver, other state-of-the-art learning-based baselines, and greedy algorithms. This improvement is achieved by directly optimizing each instance without any history, e.g., previous optimal solutions and the information of other instances. Additionally, these experiments indicate that the CRA accelerates the learning process of the PI-GNN solver. Notably, these results overcome the limitations pointed out by Angelini and Ricci-Tersenghi (2023); Wang and Li (2023), highlighting the further potential of UL-based solvers.

Notation.We use the shorthand expression \([N]=\{1,2,,N\}\), where \(N\). \(I_{N}^{N N}\) denotes an \(N N\) identity matrix, \(_{N}\) denotes the vector \((1,,1)^{}^{N}\), and \(_{N}\) denotes the vector \((0,,0)^{}^{N}\). \(G(V,E)\) represents an undirected graph, where \(V\) is the set of nodes with cardinality \(|V|=N\), and \(E V V\) denotes the set of edges. For a graph \(G(V,E)\), \(A_{ij}\) denotes the adjacency matrix, where \(A_{ij}=0\) if an edge \((i,j)\) does not exist and \(A_{ij}>0\) if the edge is present.

## 2 Background

Combinatorial optimization.The goal of this study is to solve the following CO problem.

\[_{\{0,1\}^{N}}f(;C)\ \ \ \ (C),\]where \(C\) denotes instance-specific parameters, such as a graph \(G=(V,E)\), and \(\) represents the set of all possible instances. \(f:\) denotes the cost function. Additionally, \(=(x_{i})_{1 i N}\{0,1\}^{N}\) is a binary vector to be optimized, and \((C)\{0,1\}^{N}\) denotes the feasible solution space, typically defined by the following equality and inequality constraints.

\[(C)=\{\{0,1\}^{N} i[I],\;g_{i}(;C) 0,\; j[J],\;h_{j}(;C)=0\},\;\;I,J,\]

where, for \(i[I]\), \(g_{i}:\{0,1\}^{N}\) denotes the inequality constraint, and for \(j[J]\), \(h_{j}:\{0,1\}^{N}\) denotes the equality constraint. Following UL-based solvers (Wang et al., 2022; Schuetz et al., 2022; Karalias and Loukas, 2020), we reformulate the constrained problem into an equivalent unconstrained form using the penalty method (Smith et al., 1997):

\[_{}l(;C,),\;\;l(;C,) f (;C)+_{i=1}^{I+J}_{i}v_{i}(;C).\]

where, for all \(i[I+J]\), \(v:\{0,1\}^{N}\) is the penalty term, which increases when the constraints are violated. For example, the penalty term is defined as follows:

\[ i[I],j[J],\;v_{i}(;C)=(0,g_{i}(;C)),\;\; j [J],\;v_{j}(;C)=(h_{j}(;C))^{2},\]

and \(=(_{i})_{1 i I+J}^{I+J}\) denotes the penalty parameters that control the trade-off between constraint satisfaction and cost optimization. Note that, as \(\) increases, the penalty for constraint violations becomes more significant. In the following, we provide an example of this formulation.

Example: MIS problem.The MIS problem is a fundamental NP-hard problem (Karp, 2010), defined as follows. Given an undirected graph \(G(V,E)\), an independent set (IS) is a subset of nodes \( V\) where any two nodes are not adjacent. The MIS problem aims to find the largest IS, denoted as \(^{*}\). In this study, \(\) denotes the IS density, defined as \(=||/|V|\). Following Schuetz et al. (2022), a binary variable \(x_{i}\) is assigned to each node \(i V\). The MIS problem can be formulated as follows:

\[f(;G,)=-_{i V}x_{i}+_{(i,j) E}x_{i}x_{j},\]

where the first term maximizes the number of nodes assigned a value of \(1\), and the second term penalizes adjacent nodes assigned \(1\) according to the penalty parameter \(\).

### Unsupervised learning based solvers

Learning for CO problems involves training an algorithm \(_{}():\{0,1\}^{N}\) parameterized by a neural network (NN), where \(\) denotes the parameters. For a given instance \(C\), this algorithm generates a valid solution \(}=_{}(C)(C)\) and aims to minimize \(f(};C)\). Several approaches have been proposed to train \(_{}\). This study focuses on UL-based solvers, which do not use a labeled solution \(^{*}*{argmin}_{(C)}f(;C)\) during training (Wang et al., 2022; Schuetz et al., 2022; Karalias and Loukas, 2020; Amizadeh et al., 2018). In the following, we outline the details of the UL-based solvers.

The UL-based solvers employ a continuous relaxation strategy to train NN. This continuous relaxation strategy reformulates a CO problem into a continuous optimization problem by converting discrete variables into continuous ones. A typical example of continuous relaxation is expressed as follows:

\[_{}(;C,),\;\;(;C,) (;C)+_{i=1}^{m+p}_{i}_{i}(;C),\]

where \(=(p_{i})_{1 i N}^{N}\) represents a set of relaxed continuous variables, where each binary variable \(x_{i}\{0,1\}\) is relaxed to a continuous counterpart \(p_{i}\), and \(:^{N}\) denotes the relaxed form of \(f\) such that \((;C)=f(;C)\) for \(\{0,1\}^{N}\). The relation between each constraint \(v_{i}\) and its relaxation \(_{i}\) is similar for \(i[I+J]\), meaning that \( i[I+J]\), \(_{i}(;C)=v_{i}(;C)\) for \(\{0,1\}^{N}\). Wang et al. (2022) and Schuetz et al. (2022) formulated \(_{}(C)\) as the relaxed continuous variables, defined as \(_{}():^{n}\). In the following discussions, we denote \(_{}\) as \(_{}\) to make the parametrization of the relaxed variables explicit. Then, \(_{}\) is optimized by directly minimizing the following label-independent function:

\[(;C,)(_{}(C);C)+ _{i=1}^{I+J}_{i}_{i}(_{}(C);C).\]

After training, the relaxed solution \(_{}\) is converted into discrete variables using artificial rounding \(_{}\), where \( i[N],\ x_{i}=(p_{,i}(C))\) based on a threshold (Schuetz et al., 2022), or alternatively, a greedy method (Wang et al., 2022). Two types of schemes for UL-based solvers have been developed based on this formulation.

(Type I) Learning generalized heuristics from history/data.One approach, proposed by Karalias and Loukas (2020), aims to automatically learn effective heuristics from historical dataset instances \(=\{C_{}\}_{=1}^{P}\) and then apply these learned heuristics to a new instance \(C^{*}\), through inference. Note that this method assumes that either the training dataset is easily obtainable or that meaningful data augmentation is feasible. Specifically, given a set of training instances \(=(C_{})\), sampled independently and identically from a distribution \(P(C)\), the goal is to minimize the average loss function \(_{}_{=1}^{P}l(;C_{},)\). However, this method does not guarantee quality for a test instance, \(C^{*}\). Even if the training instances \(\) are extensive and the test instance \(C\) follows \(P(C)\), low average performance \(_{C P(C)}[(;C)]\) may not guarantee a low \(l(;C)\) for on a specific \(C\). To address this issue, Wang and Li (2023) introduced a meta-learning approach where NNs aim to provide good initialization for future instances rather than direct solutions.

(Type II) Learning effective heuristics on a specific single instance.Another approach, known as the PI-GNN solver (Schuetz et al., 2022, 2022), automatically learns instance-specific heuristics for a single instance using the instance parameter \(C\) by directly applying Eq. (2.1). This approach addresses CO problems on graphs, where \(C=G(V,E)\), and employs GNNs for the relaxed variables \(p_{}(G)\). Here, an \(L\)-layered GNN is trained to directly minimize \((;C,)\), taking as input a graph \(G\) and the embedding vectors on its nodes, and outputting the relaxed solution \(_{}(G)^{N}\). A detailed description of GNNs is provided in Appendix E.2. Note that this setting is applicable even when the training dataset \(\) is difficult to obtain. The overparameterization of relaxed variables is expected to smooth the objective function by introducing additional parameters to the optimization problem, similar to the kernel method. However, minimizing Eq. 2.1 for a single instance can be time-consuming compared to the inference process. Nonetheless, for large-scale CO problems, this approach has been reported to outperform other solvers in terms of both computational time and solution quality (Schuetz et al., 2022, 2022).

Note that, while both UL-based solvers for multiple instances (Type I) and individual instances (Type II) are valuable, this study focuses on advancing the latter: a UL-based solver for a single instance. Both types of solvers are applicable to cost functions that meet a particular requirement due to their reliance on a gradient-based algorithm to minimize Eq (2.1).

**Assumption 2.1** (Differentiable cost function).: The relaxed loss function \((;C,)\) and its partial derivative \(;C,)}}{{}}\) are accessible during the optimization process.

These requirements encompass a nonlinear cost function and interactions involving many-body interactions, extending beyond simple two-body interactions.

## 3 Continuous relaxation annealing for UL-based solvers

In this section, we discuss the practical issues associated with UL-based solvers and then introduce continuous relaxation annealing (CRA) as a proposed solution.

### Motivation: practical issues of UL-based solvers

UL-based solvers (Type II) (Schuetz et al., 2022, 2022) are effective in addressing large-scale CO problems. However, these solvers present following two practical issues, highlighted in several recent studies (Wang and Li, 2023; Angelini and Ricci-Tersenghi, 2023). Additionally, we numerically validate these issues; see Appendix F.1 for detailed results.

(I) Ambiguity in rounding method after learning.UL-based solvers employ a continuous relaxation strategy to train NNs and then convert the relaxed continuous variables into discrete binary values through artificial rounding as discussed in Section 2.1. This inherent ambiguity in continuous relaxation strategy often results in potential discrepancies between the optimal solutions of the original discrete CO problem and those of the relaxed continuous one. Continuous relaxation expands the solution space, often producing continuous values that lower the cost compared to an optimal binary value. Indeed, while linear relaxation can provide an optimal solution for discrete problems on bipartite graphs (Hoffman and Kruskal, 2010), it typically results in solutions with \(}{{2}}\) values, which is known to half-integrality (Nemhauser and Trotter Jr, 1974). Existing rounding methods (Schuetz et al., 2022b; Wang et al., 2022) often lose robustness in these scenarios. In practice, PI-GNN solver often outputs values near \(}{{2}}\), underscoring the limitations of current rounding techniques for UL-based solvers.

(II) Difficulty in optimizing NNs.Recently, Angelini and Ricci-Tersenghi (2023) demonstrated that PI-GNN solver falls short of achieving results comparable to those of the degree-based greedy algorithm (DGA) (Angelini and Ricci-Tersenghi, 2019) when solving the MIS problems on RRGs. Angelini and Ricci-Tersenghi (2023) further emphasized the importance of evaluating UL-based solvers on complex CO problems, where greedy algorithms typically perform worse. A representative example is the MIS problems on RRGs with a constant degree \(d>16\), where a clustering transition in the solution space creates barriers that impede optimization. Moreover, Wang and Li (2023) emphasized the importance of using training/historical datasets, \(=\{C_{}\}_{1 P}\), which contain various graphs and initialization using outputs from greedy solvers, such as DGA and RGA for MIS problems. Their numerical analysis indicated that PI-GNN solver tends to get trapped in local optima when directly optimized directly for a single instance without leveraging a training dataset \(\). However, in a practical setting, systematic methods for generating or collecting training datasets \(\) to effectively avoid local optima remains unclear. Additionally, training on instances that do not contribute to escaping local optima is time-consuming. Therefore, it is crucial to develop an effective UL-based solver that can operate on a single instance without relying on training data, \(\). Our numerical experiments, detailed in Appendix F.1, also confirmed this optimization issue. They demonstrated that as problem complexity increases, the PI-GNN solver is often drawn into trivial local optima, \(}=_{N}\), in certain problems. This entrapment results in prolonged plateaus that significantly slow down the learning process and, in especially challenging cases, can render learning entirely infeasible. Our numerical experiments, detailed in Appendix F.1, also validated this optimization issue, demonstrating that as the problem complexity increases, PI-GNN solver tends to be absorbed into the trivial local optima \(}=_{N}\) in some problems, resulting in prolonged plateaus which significantly decelerates the learning process and, in particularly challenging cases, can render learning entirely infeasible.

### Continuous relaxation annealing

Penalty term to control discreteness and continuity.To address these issues, we propose a penalty term to control the balance between discreteness and continuity in the relaxed variables, formulated as follows:

\[(;C,,)=(;C,)+ (),\ \ ()_{i=1}^{N}(1-(2p_{i}-1)^{}),\ \ \{2n\ |\ n_{+}\},\]

where \(\) is a penalty parameter, and the even number \(\) denote a curve rate. When \(\) is negative, i.e., \(<0\), the relaxed variables tend to favor the continuous space, smoothing the non-convexity of the objective function \((;C,)\) due to the convexity of the penalty term \(()\). In contrast, when \(\) is positive, i.e., \(>0\), the relaxed variables tend to favor discrete space, smoothing out the continuous solution into discrete solution. Formally, the following theorem holds as \(\) approaches \(\).

**Theorem 3.1**.: _Assuming the objective function \((;C)\) is bounded within the domain \(^{N}\), as \(+\), the relaxed solutions \(^{*}*{argmin}_{}(;C,,)\) converge to the original solutions \(^{*}*{argmin}_{}\{l(;C,)\}\). Moreover, as \(-\), the loss function \((;C,,)\) becomes convex, and the relaxed solution \(}{{N}}/2=*{argmin}_{}(,C,,)\) is unique._

For the detailed proof, refer to Appendix B.1. Theorem 3.1 can be generalized for any convex function \((;C)\) that has a unique maximum at \(}{{}}/2\) and achieves a global minimum for all \(\{0,1\}^{N}\); an example is binary cross entropy \(_{}()=_{i=1}^{N}(p_{i} p_{i}+(1-p_{i})(1-p_{i}))\), introduced by Sun et al. (2022); Sanokowski et al. (2024) for the UL-based solvers (Type I). Additionally, the penalty term eliminates the stationary point \(^{}=_{N}\) described in Section 3.1, preventing convergence to a plateau. For UL-based solvers, the penalty term is expressed as follows:

\[(;C,,)=(;C,) +(;C),\]

where \((;C)(_{}(C))\). According to Theorem 3.1, setting a sufficiently large \(\) value cases the relaxed variables to approach nearly discrete values. We can also generalize this penalty term \((;C)\), to Potts variables optimization, including coloring problems (Schuetz et al., 2022), and mixed-integer optimization; refer to Appendix C.1.

Annealing penalty term.We propose an annealing strategy that gradually anneals the penalty parameter \(\) in Eq. (3.2). Initially, a negative gamma value, i.e., \(<0\), is chosen to leverage the properties, facilitating broad exploration by smoothing the non-convexity of \((;C,)\) and eliminating the stationary point \(^{}=_{N}\) to avoid the plateau, as discussed in Section 3.1. Subsequently, the penalty parameter \(\) is gradually increased to a positive value, \(>0\), with each update of the trainable parameters (one epoch), until the penalty term approaches zero, i.e., \((,C) 0\), to automatically round the relaxed variables by smoothing out suboptimal continuous solutions oscillating between \(1\) or \(0\). A conceptual diagram of this annealing process is shown in Fig. 1.

Note that employing the binary cross-entropy \(_{}()\) is infeasible for UL-based solvers when \(>0\), as the gradient \(}()}}{{ p_{i}}}\) diverges to \(\) at \(0\) or \(1\). In deed, when \(=0\), most relaxed variables typically approach binary values, with a relatively small number of variables oscillating between \(0\) and \(1\). This gradient divergence issue in \(_{}()\) makes the learning infeasible without additional techniques, such as gradient clipping. In contrast, the gradient of the penalty term in Eq. 3.2, \()}}{{ p_{i}}}\), is bounded within \([-2,2]\) for any \(\), preventing the gradient divergence issue seen in \(_{}()\). Additionally, by increasing \(\), the absolute value of the gradient near \(}{{2}}\) becomes smaller, allowing for control over the smoothing strength toward a discrete solution near \(}{{2}}\).

We also propose an early stopping strategy that monitors both the loss function and the penalty term, halting the annealing and learning processes when the penalty term approaches zero, i.e., \((;C) 0\). Various annealing schedules can be considered; in this study, we employ the following scheduling: \((+1)()+\), where the scheduling rate \(_{+}\) is a small constant, and \(\) denotes the update iterations of the trainable parameters. We refer to the PI-GNN solver with this continuous relaxation annealing as CRA-PI-GNN solver. Here, two additional hyperparameters are introduced: the initial scheduling value \((0)\) and the scheduling rate \(\). Numerical experiments suggest that better solutions are obtained when \((0)\) is set to a small negative value and \(\) is kept low. The ablation study are presented in Appendix F.5.

## 4 Related Work

Previous works on UL-based solvers have addressed various problems, such as MaxCut problems (Yao et al., 2019) and traveling salesman problems (Hudson et al., 2021), using carefully tailored problem-specific objectives. Some studies have also explored constraint satisfaction problems (Amizadeh et al., 2018; Toenshoff et al., 2019), but applying these approaches to broader CO problems often requires problem-specific reductions. Karalias and Loukas (2020) proposed Erdos Goes Neural (EGN) solver, an UL-based solver for general CO problems based on Erdos' probabilistic method. This solver

Figure 1: Annealing strategy. When \(<0\), it facilitates exploration by reducing the non-convexity of the objective function. As \(\) increases, it promotes optimal discrete solutions by smoothing away suboptimal continuous ones.

generate solutions through an inference process using training instances. Subsequently, Wang et al. (2022) proposed an entry-wise concave continuous relaxation, broadening the EGN solver to a wide range of CO problems. In contrast, Schuetz et al. (2022, 2022) proposed PI-GNN solver, an UL-based solver for a single CO problems that automatically learns problem-specific heuristics during the training process. However, Angelini and Ricci-Tersenghi (2023); Boettcher (2023) pointed out the optimization difficulties where PI-GNN solver failed to achieve results comparable to those of greedy algorithms. Wang and Li (2023) also claimed optimization issues with PI-GNN solver, emphasizing the importance of learning from training data and history to overcome local optima. They then proposed Meta-EGN solvers, a meta-learning approach that updates NN network parameters for individual CO problem instances. Furthermore, to address these optimization issue, Lin et al. (2023); Sun et al. (2022); Sanokowski et al. (2024) proposed annealing strategy similar to simulated annealing (Kirkpatrick et al., 1983).

## 5 Experiments

We begin by evaluating the performance of CRA-PI-GNN solver on the MIS and the MaxCut benchmark problems across multiple graphs of varying sizes, demonstrating that CRA effectively overcomes optimization challenges without relying on data/history \(\). We then extend the evaluation to the DBM problems, showing the applicability to more practical CO problems. For the objective functions and the detailed explanations, refer to Appendix E.1.

### Experimental settings

Baseline methods.In all experiments, the baseline methods include the PI-GNN solver (Schuetz et al., 2022) as the direct baseline of a UL-based solver for a single instance. For the MIS problems, we also consider the random greedy algorithm (RGA) and DGA (Angelini and Ricci-Tersenghi, 2019) as heuristic baselines. For the MaxCut problems, RUN-CSP solver (Toenshoff et al., 2019) is considered as an additional baseline, and a standard greedy algorithm and SDP based approximation algorithm (Goemans and Williamson, 1995) are considered as an additional classical baseline. The parameters for the Goemans-Williamson (GW) approximation are all set according to the settings in Schuetz et al. (2022). The implementation used the open-source CVXOPT solver with CVXPY 2 as the modeling interface. Note that we do not consider UL-based solvers for learning generalized heuristics (Karalias and Loukas, 2020; Wang et al., 2022; Wang and Li, 2023), which rely on training instances \(=\{C_{}\}_{=1}^{P}\). The primary objective of this study is to evaluate whether CRA-PI-GNN solver can surpass the performance of both PI-GNN solver and greedy algorithms. However, for the MIS problem, EGN solver (Karalias and Loukas, 2020) and Meta-EGN solver (Wang and Li, 2023) are considered to confirm that CRA can overcome the optimization issues without training instances.

Implementation.The objective of the numerical experiments is to compare the CRA-PI-GNN solver with the PI-GNN solver. Thus, we follow the same experimental configuration described as the experiments in Schuetz et al. (2022), employing a simple two-layer GCV and GraphSAGE(Hamilton et al., 2017) implemented by the Deep Graph Library (Wang et al., 2019); Refer to Appendix D.1 for the detailed architectures. We use the AdamW (Kingma and Ba, 2014) optimizer with a learning rate of \(=10^{-4}\) and weight decay of \(10^{-2}\). The GNNs are trained for up to \(5 10^{4}\) epochs with early stopping, which monitors the summarized loss function \(_{s=1}^{S}(P_{:,s})\) and the entropy term \((P;,)\) with tolerance \(10^{-5}\) and patience \(10^{3}\) epochs; Further details are provided in Appendix D.2. We set the initial scheduling value to \((0)=-20\) for the MIS and matching problems, and we set \((0)=-6\) for the MaxCut problems with the scheduling rate \(=10^{-3}\) and curve rate \(=2\) in Eq. (3.2). These values are not necessarily optimal, and refining these parameters can lead to better solutions; Refer to Appendix F.5 and Appendix F.6 for an ablation study of these parameters. Once the training process is complete, we apply projection heuristics to map the obtained soft solutions back to discrete solutions using simple projection, where for all \(i[N]\), we map \(p_{,i}\) into \(0\) if \(p_{,i} 0.5\) and \(p_{,i}\) into \(1\) if \(p_{,i}>0.5\). However, due to the early stopping in Section 3.2, the CRA-PI-GNN solver ensures that for all benchmark CO problems, the soft solution at the end of the training process became 0 or 1 within the 32-bit Floating Point range in Pytorch GPU; thus, it is robust against a given threshold, which we set to \(0.5\) in our experiments. Additionally, no violations

[MISSING_PAGE_FAIL:8]

discussed in Section 3.1, Angelini and Ricci-Tersenghi (2023); Wang and Li (2023) have posted the optimization concerns on UL-based solvers. However, we call these claim into question by substantially outperforming heuristics DGA and RGA for the MIS on graphs with \(d=20,100\), without training/historical instances \(=\{G^{}\}_{=1}^{n}\), as shown in Table 1. See Appendix 6 for the results of solving all other Gsets, where consistently, CRA-PI-GNN provides better results as well. A comparison of the sampling-based solvers, RL-based solvers, SL-based solvers, Gurobi, and MIS-specific solvers is presented in Appendix F.2.

Acceleration of learning speed.We also compared the learning curve between PI-GNN and CRA-PI-GNN solver to confirmed that the CRA-PI-GNN solver does not become trapped in the plateau, \(_{N}=_{N}\), as discussed in Section 3.1. Fig. 5 shows the dynamics of the cost functions for the MIS problems with \(N=10{,}000\) across \(d=3,5,20,100\). Across all degrees, CRA-PI-GNN solver achieves a better solution with fewer epochs than PI-GNN solver. Specifically, PI-GNN solver becomes significantly slower due to getting trapped in the plateau even for graphs with low degrees, such as \(d=3,5\). In contrast, CRA-PI-GNN solver can effectively escape from plateaus through the smoothing and automatic rounding of the penalty term when the negative parameter \(>0\).

Computational scaling.We next evaluate the computational scaling of the CRA-PI-GNN solver for MIS problems with large-scale RRGs with a node degree of \(100\) in Fig. 4, following previous studies (Schuetz et al., 2022; Wang and Li, 2023). Fig. 4 demonstrated a moderate super-linear scaling of the total computational time, approximately \( N^{1.4}\) for GCN and \( N^{1.7}\) for GraphSage. This performance is nearly identical to that of the PI-GNN solver (Schuetz et al., 2022) for problems on RRGs with lower degrees. It is important note that the runtimes of CRA-PI-GNN solver heavily depend on the optimizer for GNNs and annealing rate \(\); thus this scaling remains largely unchanged for problems other than the MIS on \(100\) RRG. Additionally, CRA demonstrate that the runtime remains nearly constant as graph order and density increase, indicating effective scalability with denser graphs which is presented in Appendix F.2.

### MaxCut problem

Degree dependency of solutions.We first compare the performances of PI-GNN and CRA-PI-GNN solvers with GCV, following Schuetz et al. (2022). Fig. 3 shows the cut ratio \(_{d}\) as a function of the degree \(d\) compared to the theoretical upper bound (Parisi, 1980; Dembo et al., 2017). Across all degrees \(d\), CRA-PI-GNN solver also outperforms PI-GNN solver, approaching the theoretical upper bound. In contrast, PI-GNN solver fails to find valid solutions for \(d>20\) as with the case of the MIS problems in Section 5.2.

Standard MaxCut benchmark test.Following Schuetz et al. (2022), we next conducted additional experiments on standard MaxCut benchmark instances based on the publicly available Gset dataset (Ye, 2003), which is commonly used to evaluate MaxCut algorithms. Here, we provide benchmark results for seven distinct graphs with thousands of nodes, including Erdos-Renyi graphs with uniform edge probability, graphs in which the connectivity decays gradually from node \(1\) to \(N\), \(4\)-regular toroidal graphs, and a very large Gset instance with \(N=10{,}000\) nodes. Table 2 shows, across all problems, CRA-PI-GNN solver outperforms both the PI-GNN, RUN-CSP solvers and other greedy algorithm.

Figure 5: The dynamics of cost function for MIS problems on RRGs with \(N=10{,}000\) nodes varying degrees \(d\) as a function of the number of parameters updates \(N_{}\).

Figure 6: ApR on DBM problems.

See Appendix 6 for the results of solving all other Gsets, where CRA-PI-GNN consistently provides better results as well.

### Diverse bipartite matching

To evaluate the applicability of the CRA-PI-GNN solver to more practical problems not on graphs, we conducted experiments on DBM problems (Ferber et al., 2020; Mulamba et al., 2020; Mandi et al., 2022); refer to Appendix E.1 for details. This problems consists of \(27\) distinct instances with varying properties, and each instance comprises \(100\) nodes representing scientific publications, divided into two groups of \(50\) nodes \(N_{1}\) and \(N_{2}\). The optimization is formulated as follows:

\[l(;C,M,)=-_{ij}C_{ij}x_{ij}+_{1}_{i}_{j}x_{ij}-1+_{2}_{j} _{i}x_{ij}-1\]

where \(C^{N_{1} N_{2}}\) represents the likelihood of a link between each pair of nodes, an indicator \(M_{ij}\) is set to \(0\) if article \(i\) and \(j\) share the same subject field (\(1\) otherwise) \( i N_{1}\), and \(j N_{2}\). The parameters \(p,q\) represent the probability of pairs sharing their field and of unrelated pairs, respectively. As in Mandi et al. (2022), we explore two variations of this problem, with \(p=q=\) being \(25\)% and \(5\)%, respectively, and these variations are referred to as Matching-1 and Matching-2, respectively. In this experiment, we set \(_{1}=_{2}=10\) and \(_{3}=_{4}=25\). Fig 6 shows that the CRA-PI-GNN solver can find better solutions across all instances.

## 6 Conclusion

This study proposes CRA strategy to address the both optimization and rounding issue in UL-based solvers. CRA strategy introduces a penalty term that dynamically shifts from prioritizing continuous solutions, where the non-convexity of the objective function is effectively smoothed, to enforcing discreteness, thereby eliminating artificial rounding. Experimental results demonstrate that CRA-PI-GNN solver significantly outperforms PI-GNN solver and greedy algorithms across various complex CO problems, including MIS, MaxCut, and DBM problems. CRA approach not only enhances solution quality but also accelerates the learning process.

Limitation.In these numerical experiments, most hyperparameters were fixed to their default values, as outlined in Section 5.1, with minimal tuning. However, tuning may be necessary for specific problems or to further enhance performance.