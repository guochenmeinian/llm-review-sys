# Trust Your \(\nabla\): Gradient-based Intervention Targeting for Causal Discovery

# Trust Your \(\): Gradient-based Intervention Targeting for Causal Discovery

Mateusz Olko\({}^{1,2,}\)1 Michal Zajac\({}^{3,}\)1 Aleksandra Nowak\({}^{2,3,4,}\)1

**Nino Scherrer\({}^{5}\) Yashas Annadani\({}^{6}\) Stefan Bauer\({}^{6}\)**

**Lukasz Kucinski\({}^{2,7}\) Piotr Milos\({}^{2,8,7}\)2**

\({}^{1}\)Warsaw University, \({}^{2}\)IDEAS NCBR,

\({}^{3}\)Jagiellonian Univeristy, Faculty of Mathematics and Computer Science,

\({}^{4}\)Jagiellonian University, Doctoral School of Exact and Natural Sciences,

\({}^{5}\)ETH Zurich, \({}^{6}\)Helmholtz, TU Munich, \({}^{7}\)deepsense.ai,

\({}^{8}\)Institute of Mathematics, Polish Academy of Sciences

###### Abstract

Inferring causal structure from data is a challenging task of fundamental importance in science. Often, observational data alone is not enough to uniquely identify a system's causal structure. The use of interventional data can address this issue, however, acquiring these samples typically demands a considerable investment of time and physical or financial resources. In this work, we are concerned with the acquisition of interventional data in a targeted manner to minimize the number of required experiments. We propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention targeting function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime.

## 1 Introduction

Estimating causal structure from data, commonly known as causal discovery, is central to the progress of science . Real-world systems can often be explained as a composition of smaller parts connected by causal relationships. Understanding this underlying structure is essential for making accurate predictions about the system's behavior after a perturbation or treatment has been applied . Causal discovery methods have been successfully deployed in various fields, such as biology , medicine , earth system science , or neuroscience . In machine learning, causal decomposition has been shown to enable sample-efficient learning and fast adaptation to distribution shifts by only updating a subset of parameters .

_Observational data_, that is the data obtained directly from the unperturbed system, are, in general, insufficient to identify a system's causal structure and only allow to determine the structure up to the so-called Markov Equivalence Class . To overcome this limited identifiability problem, causal discovery algorithms commonly leverage _interventional_ data , which are acquired by gathering data from an experiment perturbing a part of the system . The field of _experimental design_, Tong and Koller,  is concerned with theacquisition of interventional data in a targeted manner to minimize the number of required experiments, which often requires spending a significant amount of time and physical or financial resources.

In this work, we introduce a simple and effective experimental design algorithm called Gradient-based Intervention Targeting, or GIT for short, see Figure 1. GIT can be easily combined with various gradient-based causal discovery frameworks to provide an efficient active selection of intervention targets. Our method, which is grounded in the ideas from active and curriculum learning (Settles et al., 2007; Graves et al., 2017; Ash et al., 2020), collects interventional data that induce the biggest gradient on parameters of causal structure. GIT leverages the gradient-based nature of the underlying causal discovery framework and achieves better performance than the contemporary baselines.

Our contributions include:

* We introduce GIT, which is to our knowledge, the first gradient-based intervention targeting method. Due to it's plug-and-play nature, our method can be easily combined with various gradient-based causal discovery frameworks.
* Our extensive experiments on synthetic and real-world graphs demonstrate that GIT effectively reduces the amount of interventional data needed to discover the causal structure, and performs well in the low-data regime. This makes GIT a compelling option when access to interventional data is limited.
* We provide a theoretical justification of GIT and a suite of analyses introspecting its behavior and performance.

## 2 Related Work

**Experimental Design / Intervention Design.** There are two major classes of methods for selecting optimal interventions for causal discovery. One class of approaches is based on graph-theoretical properties. Typically, a completed partially directed acyclic graph (CPDAG), describing an equivalence class of DAGs, is first specified. Then, either substructures, such as cliques or trees, are investigated and used to inform decisions (He and Geng, 2008; Eberhardt, 2008; Squires et al., 2020; Greenewald et al., 2019), or edges of a proposed graph are iteratively refined until reaching a prescribed budget (Ghassami et al., 2018, 2019; Kocaoglu et al., 2017; Lindgren et al., 2018). One limitation of graph-theoretical approaches is that misspecification of the CPDAG at the beginning of the process can deteriorate the final solution. Another class of methods is based on Bayesian Optimal Experiment Design (Lindley, 1956), which aims to select interventions with the highest mutual information (MI) between the observations and model parameters. MI is approximated in different ways: AIT (Scherrer et al., 2021) uses F-score inspired metric to implicitly approximate MI; CBED (Tigas et al., 2022) incorporates BALD-like estimator (Houlsby et al., 2011); ABCD (Agrawal et al., 2019) uses estimator based on weighted importance sampling. Although theoretically principled, computing mutual information suffers from approximation errors and model mismatches. Therefore, in this work, we explore using scores based on different principles.

**Gradient-based Causal Structure Learning.** The appealing properties of neural networks have sparked a flurry of gradient-based causal structure learning methods. The most prevalent approaches are self-supervised formulations that optimize a data-dependent scoring metric (for instance, penalized log-likelihood) to find the best causal graph \(G\). Existing self-supervised methods that are capable (or can be extended) of incorporating interventional data can be categorized based on

Figure 1: Overview of GIT’s usage in a gradient-based causal discovery framework. The framework infers a posterior distribution over graphs from observational and interventional data (denoted as \(_{obs}\) and \(_{int}\)) through gradient-based optimization. The distribution over graphs and the gradient estimator \(()\) are then used by GIT in order to score the intervention targets based on the magnitude of the estimated gradients. The intervention target with the highest score is then selected, upon which the intervention is performed. New interventional data \(^{new}_{int}\) are then collected and the procedure is repeated.

the underlying optimization formulation into: (i) frameworks with a joint optimization objective (Brouillard et al., 2020; Lorch et al., 2021; Cundy et al., 2021; Annadani et al., 2021; Geffner et al., 2022; Deleu et al., 2022) and (ii) frameworks with alternating phases of optimization (Bengio et al., 2020; Ke et al., 2019; Lippe et al., 2022). While structural and functional parameters are optimized under a joint objective in the former, the latter splits the optimization into two phases with separate objectives. All the aforementioned methods allow evaluation of gradient with respect to the structural and functional parameters with a batch of (real or hypothesized) interventional samples and can serve as a base framework for our proposed _gradient-based_ intervention acquisition strategy.

**Gradients in Active and Curriculum Learning.** Gradients have been successfully used as a criterion to select data to process in previous work. Settles et al. (2007) introduce Expected Gradient Length (EGL), computed under the current belief, as a criterion for active learning. A batch active learning method introduced in Ash et al. (2020) also targets data points with high gradient magnitude, including uncertainty and diversity in the decision. In the area of curriculum learning, Graves et al. (2017) considers Gradient Prediction Gain (GPG), which is defined as the gradient's magnitude and is meant to be a proxy for expected learning progress. We take inspiration from those approaches to propose a novel usage of the gradient criterion in the field of causal discovery.

## 3 Preliminaries

### Structural Causal Models and Causal Structure Discovery

Causal relationships can be formalized using structural causal models (SCM) (Peters et al., 2017). Each of the endogenous variables \(X=(X_{1},,X_{n})\) is expressed as a function \(X_{i}=f_{i}(PA_{i},U_{i})\) of its direct causes \(PA_{i} X\) and an external independent noise \(U_{i}\). It is assumed that the assignments are acyclic and thus associated with a directed acyclic graph \(G=(V,E)\). The nodes \(V=\{1,,n\}\) represent the random variables and the edges correspond to the direct causes, that is \((i,j) E\) if and only if \(X_{i} PA_{j}\). The joint distribution factorizes according to

\[(X_{1},,X_{n})=_{i=1}^{n}(X_{i}|PA_{i}).\] (1)

Causal structure discovery aims to recover the ground truth graph \(G\). The solution to this problem is not uniquely defined when having access only to observational data from the ground truth distribution \(\). Formally, it can be determined solely up to a Markov Equivalence Class (MEC) (Spirites et al., 2000; Peters et al., 2017) without additional restrictive assumptions. To achieve identifiability, data from additional experiments, called interventions, need to be gathered.

A single-node intervention on \(X_{i}\) replaces the conditional distribution \((X_{i}|PA_{i})\) with a new distribution denoted as \(}(X_{i}|PA_{i})\), yielding a so-called interventional distribution:

\[_{i}(X)}(X_{i}|PA_{i})_{j i }(X_{j}|PA_{j}).\] (2)

The node \(i V\) is called the _intervention target_. An intervention that removes the dependency of a variable \(X_{i}\) on its parents, yielding \(}(X_{i}|PA_{i})=}(X_{i})\), is called hard. In this paper, we use data gathered by performing single-node interventions.

### Online Causal Discovery and Targeting Methods

In this work, we consider an _online_ causal discovery procedure outlined in Algorithm 1. Given a causal discovery Algorithm \(\), the graph model \(_{0}\) is fitted using observational data \(_{obs}\). Following that, batches of interventional samples are acquired iteratively and are used by the algorithm to improve the belief about the causal structure (line 7). Intervention targets are chosen by _intervention targetting method_\(\) to optimize the overall performance, taking into account the current belief about the graph structure encoded in \(_{i-1}\). Below we discuss two popular choices for the method \(\) (with more details deferred to Appendix D).

causal discovery is approximating the posterior distribution over the possible causal DAGs. This allows using the framework of Bayesian Optimal Experimental Design to select the most informative intervention (experiment). The score of a new experiment is given by the mutual information (MI) between the interventional data due to the experiment and the current belief about the graph structure. Hence, such an approach requires estimating MI. For instance, Causal Bayesian Experimental Design (CBED) (Tigas et al., 2022) uses a BALD-like estimator (Houlsby et al., 2011) to sample batches of interventional targets.

## 4 Git method

In this work, we present a new _intervention targeting_ method GIT. GIT chooses intervention targets that induce the largest update of the parameters modeling the causal structure. Inspired by _hallucinated gradients_ exploited by (Ash et al., 2020) we calculate gradients on imaginary data generated by the causal model, to score possible interventions for real data acquisition.

To formally introduce our method, we first describe the requirements that need to be fulfilled by a causal algorithm \(\) in order to use it with GIT. We then explain how GIT works and follow up with a discussion about causal assumptions and theoretical justification of our approach. Finally, in Section 4.1, we present a practical implementation of our method with a causal discovery algorithm \(\), using a popular ENCO algorithm as an example.

Requirements for causal discovery algorithm \(\).The intervention targeting method GIT can be coupled with any gradient-based causal discovery algorithm \(\) (see Algorithm 1) that fulfills the following conditions:

1. \(\) models a distribution over the causal DAGs, denoted by a family of probability measures \(_{}(G)\) parameterized by \(\), that allows sampling.
2. For each causal graph \(G\), \(\) maintains a corresponding family of conditional distributions, \(_{G,}(X_{i}|PA_{(i,G)})\), parametrized by \(\), which induces the joint distribution \(_{G,}\): \[_{G,}(X)_{i}_{G,}(X_{i}|PA_{ (i,G)}).\] (3) If \(G\) corresponds to the ground truth graph, \(_{G,}\) approximates the ground truth distribution over \(X\).
3. \(\) gives access to its loss function \(\) and gradient of the loss function \(_{}\) with respect to \(\).

These requirements are mildly restrictive and they are fulfilled by many gradient-based discovery methods (for instance, ENCO (Lippe et al., 2022), SDI (Ke et al., 2019), DiBS (Lorch et al., 2021), DCDI (Brouillard et al., 2020) or DECI (Geffner et al., 2022)).

Method.GIT scores each possible intervention target by calculating the expected magnitude of the gradient using imaginary interventional data generated by the causal model. Gradient magnitude serves as a proxy for the size of the update that can be induced on the parameters of the causal model.

The method picks intervention that has the highest score. Formally, for a given intervention \(i V\) we define its score \(s_{i}\) as follows:

\[s_{i}_{X_{,,i}}\|_{}(X)\|.\] (4)

Note that the expected value is computed with the interventional distribution coming from the model, instead of ground truth, defined as:

\[_{,,i}(X)_{G}_{}(G)_{G,,i}(X).\] (5)

The summation in equation 5 is taken over all DAGs and \(_{G,,i}\) corresponds to the joint distribution from the model for graph \(G\):

\[_{G,,i}(X)}(X_{i}|PA_{i})_{ j i}_{G,}(X_{j}|PA_{(j,G)}).\] (6)

The computational procedure of GIT's intervention target selection is listed in Algorithm 2. The expected value in \(s_{i}\) is approximated using the Monte-Carlo method, see line 4 of Algorithm 2. We also use a version of Algorithm 2 where real interventional data are used in line 3 (instead of the imaginary ones from the model) and call it GIT-privileged. GIT-privileged serves as a soft upper bound in our analysis. Note however, that it is not practically useful, as collecting real interventional data would require intervention on every node in the first place.

```
0: parameters \(\) of distribution over graphs, functional parameters \(\), loss function \(\), graph nodes \(V\)
0: batch of intervention targets to execute: \(I\)
1:\(\) sample a set of DAGs according to \(_{}(G)\)
2:for intervention target \(i V\)do
3:\(_{G,i}\) sample batch of data according to \(_{G,,i}\)
4:\(s_{i}|}_{G}_{G,i}|}_{X_{G,i}}\|_{}(X)\|\)
5:endfor
6:\(I\) select a batch of targets with highest scores \(s_{i}\) ```

**Algorithm 2**GIT's Intervention target selection

Assumptions of GIT.From the causal perspective, GIT relies exclusively on the Markov property assumption, which allows factorization of joined distribution (see Equation 1). However, GIT as a plug-and-play extension for causal discovery algorithms \(\) inherits their assumptions. This may include, for instance, causal sufficiency or faithfulness. Our method does not require any additional assumptions on the variables \(X_{i}\) and allows for both discrete and continuous setups.

Theoretical justification of GIT.We show the convergence of GIT in two contexts. First, we prove that the main setup of this paper, i.e., GIT with ENCO (Lippe et al., 2022), described in Section 4.1, converges. The detailed result can be found in Appendix B, but the gist of the argument is that vertices for which the model structure is not aligned with the ground truth will have non-trivial gradients and hence will be queried by GIT, allowing the model to improve. Moreover, we show empirically that GIT gradients are well correlated with the principled GPG signal of GIT-privileged, see Appendix F.6. Second, we show that given any convergent causal discovery algorithm, GIT converges if we allow a uniform sampling of intervention with small probability \(>0\), see Appendix A. We call this approach \(\)-greedy GIT. Importantly, on a finite sample with small enough \(\), GIT and \(\)-greedy GIT are statistically indistinguishable.

### Applicability to ENCO

We choose to use ENCO as the gradient-based causal discovery framework \(\) in our main experiments (recall Algorithm 1) due to its strong empirical results and good computational performance on GPUs. ENCO maintains a parameterized distribution over graph structures, with the so-called structural parameters \(\{_{i,j}\}_{i,j}\) representing the adjacency matrix and a set of parameters modeling the functional dependencies, \(\). The structural parameters, \(_{i,j}\), are factorized into an edge existence parameter, \(_{i,j}\), and an edge orientation parameter, \(_{i,j}=-_{j,i}\).

The parameters are updated by iteratively alternating between two optimization phases. The goal of the first phase is to learn functions \(f_{_{i}}(x_{i}|PA_{(i,G)})\), which model the conditional density of \((X_{i}|PA_{(i,G)})\). The training objective is the log-likelihood loss. The second phase aims to update the parametrized edge probabilities \(_{i,j}\)'s. To this end, ENCO collects a data sample from a mixture of interventional distributions denoted by \(_{I}\). The graph parameters are optimized by minimizing \(_{X_{I}}L_{}(X)\) where:

\[L_{}(X)_{G P_{,}}_{ i=1}^{n}L_{G}(X_{i}), L_{G}(x_{i})- f_{_{i}}(x_{i}|PA _{(i,G)}),\] (7)

For a detailed description of the method, distributions, and the estimators see Appendix C.1.

Git with ENCO details.The loss function \(\) utilized by Git is denoted \(L_{}\). We incorporate information from both structural parameters and use \(\|_{}L_{}(X)\|^{2}+\|_{}L_{}( X)\|^{2}\) to compute the score for the intervention \(i\) in line 4 of Algorithm 2. In order to sample DAGs from the current graph distribution (line 1 of Algorithm 2), we use a two-phase sampling procedure proposed in (Scherrer et al., 2021, Section 3.2) as it is scalable and guarantees DAG-ness by construction opposed to Gibbs sampling or rejection sampling techniques.

## 5 Experiments

We compare Git against the following baselines: AIT, CBED, Random, and Git-privileged. AIT and CBED are competitive intervention acquisition methods for gradient-based causal discovery (which we discussed in Section 3.2). The Random method selects interventions uniformly in a round-robin fashion2. The last approach, Git-privileged, is the oracle method described in Section 4.

Our main result is that Git brings substantial improvement in the low data regime, being the best among benchmarked methods for all considered synthetic graph classes and half of the considered real graphs in terms of the AUSHD metric (see Equation 9). On the remaining real graphs, our approach performs similarly to the baseline methods. Notably, in most cases, Git surpasses MI-based approaches: CBED and AIT. We present the summary in Table 1. This result is accompanied by an in-depth analysis of the relationships between different strategies and the distributions of the selected intervention targets. Additional results in the DiBS framework (Lorch et al., 2021) with continuous data are presented in Appendix F.1.

### Experimental Setup

We evaluate the different intervention targeting methods in online causal discovery, see Algorithm 1. We utilize an observational dataset of size \(5000\). We use \(T=100\) rounds, in each one acquiring an interventional batch of \(32\) samples. We distinguish two regimes: regular, with all \(100\) rounds (\(N=3200\) interventional samples), and low, with \(33\) rounds (\(N=1056\) interventional samples). We use \(||=50\) graphs and \(|_{G,i}|=128\) data samples from each graph for the Monte-Carlo approximation of the Git score. We tested different sizes of the Monte-Carlo sample and found that it does not have a major impact on performance, see Appendix F.4. For all experiments in this section we assume, following the approach of Lippe et al. (2022), that all interventions are single-node, hard, and change the conditional distribution of the intervened node to uniform.

DatasetsWe use synthetic and real-world datasets. The synthetic dataset consists of bidiag, chain, collider, jungle, fulldag and random DAGs, each with \(25\) nodes. The variable distributions are categorical, with \(10\) categories3. The real-world dataset consists of alarm, asia, cancer, child,

    & AIT & CBED & Random & Git (ours) & Git-privileged \\  mean AUSHD & \(6\) (\(2+4\)) & \(6\) (\(4+2\)) & \(12\) (\(5+7\)) & \(18\) (\(11+7\)) & \(24\) (\(12+12\)) \\ mean SHD & \(10\) (\(4+6\)) & \(7\) (\(4+3\)) & \(22\) (\(12+10\)) & \(17\) (\(10+7\)) & \(24\) (\(12+12\)) \\   

Table 1: We count the number of setups (24), where a given method was best or comparable to the other methods (AIT, CBED, Random, and Git; Git-privileged was not compared against), based on 90% confidence intervals for SHD and AUSHD. Each entry shows the total count, broken down into two data regimes, \(N=1056\) and \(N=3200\), respectively, presented in parentheses.

earthquake, and sachs graphs, taken from the BnLearn repository (Scutari, 2010). Both synthetic and real-world graphs are commonly used as benchmarking datasets (Ke et al., 2019; Lippe et al., 2022; Scherrer et al., 2021).

MetricsWe use the Structural Hamming Distance (SHD) (Tsamardinos et al., 2006) between the predicted and the ground truth graph as the main metric. SHD between two directed graphs is defined as the number of edges that need to be added, removed, or reversed in order to transform one graph into the other. More precisely, for two DAGs represented as adjacency matrices \(c\) and \(c^{}\),

\[(c,c^{}):=_{i>j}(c_{ij}+c_{ji} c^{}_{ ij}+c^{}_{ji}c_{ij} c^{}_{ij}).\] (8)

In the experiments, we always compute SHD between the predicted and the ground truth graph. In order to aggregate SHD values over different data regimes, we introduce the area under the SHD curve (AUSHD):

\[_{m}^{T}:=_{t=1}^{T}_{m}^{t},_{m}^{t}:=(c_{gt},c_{m,t})\] (9)

where \(m\) is the used method, \(T\) is the number of interventional data batches, \(c_{gt}\) is the ground truth graph, and \(c_{m,t}\) is the graph fitted by the method \(m\) using \(t\) interventional data batches. Intuitively, for small to moderate values of \(T\), AUSHD captures a method's speed of convergence: the faster the SHD converges to 0, the smaller the area. For large values of \(T\), AUSHD measures the asymptotic convergence. Smaller values indicate a better method. For visualizations, we use surplus of AUSHD over Random method (SAUSHD), which compares method \(m\) the the Random baseline. Precisely,

\[_{m}^{T}:=_{m}^{T}-[_{Random }^{T}],\] (10)

where the expectation averages all randomness sources (e.g. stemming from the initialization). Again, smaller values indicate a better method.

### Main Result: Git's Empirical Performance

Git's Overall Strong PerformanceWe evaluate GIT on 24 training setups: twelve graphs (synthetic and real-world, six in each category) and two data regimes. GIT is the best or comparable to the baseline methods (excluding GIT-privileged) in 18 cases according to mean AUSHD, and 17 cases according to mean SHD, see Table 1. Additionally, GIT is stable, as the distribution of its AUSHD has most frequently the smallest variation among non-privileged methods (\(11\) out of \(24\) cases), see Table 8 and Table 9 in Appendix F.2.2. In terms of pairwise comparison with other methods, GIT is better in 45 cases and comparable in 35 cases, out of a total of 96 (\(=24\) setups \( 4\)

Figure 2: The distribution of SAUSHD (see equation 10), calculated using 25 seeds, for synthetic graphs (lower is better). The intense color (left-hand side of each violin plot) indicates the low data regime (\(N=1056\) samples). The faded color (right-hand side of each violin plot) represents a higher amount of data (\(N=3200\) samples). Note that even though the solution quality is improved when more samples are available, typically, SAUSHD is smaller in the low data regime. This is because it measures relative improvement over the random baseline, which is most visible for the small number of samples in most methods.

[MISSING_PAGE_FAIL:8]

We perform an additional experiment in a modified regime, where each intervention yields \(1024\) data points instead of the previous \(32\). Such a regime is relevant in scenarios where setting up an intervention with a new target is costly but obtaining the individual samples is relatively cheap. We run the experiment on synthetic graphs with \(25\) nodes and we run for \(25\) acquisition rounds. We present the AUSHD values in Table 2 and full SHD curves in Appendix F.3. In this setting, GIT outperforms all the standard baselines and is on par with GIT-privileged. Importantly, GIT reaches the SHD value of \(0\) for all graphs. Additionally, we found that GIT selects each intervention target exactly once, except for the chain graph, for which the discovery process converges already after only 15 rounds.

### Investigating GIT's intervention target distributions

In order to gain a qualitative understanding of the GIT's behavior, we analyze the node distributions generated by respective methods on the BnLearn graphs in Figure 4. We observe that GIT often selects nodes with high out-degree, as visible in the sachs and child graphs. Intuitively, interventions on such nodes bring much information, as they affect multiple other nodes. In addition, the most frequently selected nodes in the sachs, child, and asia graphs are also adjacent to the edges for which there exists a graph in the MEC that has the corresponding connection reversed (as indicated by the green color in Figure 4). Note that in general, establishing the directionality of such an edge \((v,w)\) requires performing interventions on nodes \(v,w\) (recall Section 3.1). 4

We further explore the interventional targets and verify that GIT is able to target the most uncertain regions of the graph. In the considered setup, we select a node \(v\) in the graph. Let \(E_{v}\) be edges adjacent to \(v\). We set the structural parameters corresponding to edges \(e E_{v}\) to the ground truth values and initialize in the standard way the parameters for \(e E_{v}\). Such a model is only unsure

    & AIT & CRED & Random & GIT(ours) & GIT-privileged \\  hiding & 22.6 & 17.6 & 20.4 & **16.8** & 15.4 \\ chain & 11.4 & 8.2 & 10.2 & **8.0** & 7.7 \\ collider & 11.2 & 11.4 & 9.9 & **5.0** & 4.8 \\ fill & 120.1 & 116.0 & 101.1 & **100.9** & 93.2 \\ jungle & 22.3 & 16.7 & 19.9 & **11.4** & 10.6 \\ random & 38.4 & 36.2 & 32.4 & **29.9** & 28.3 \\   

Table 2: Average AUSHD values (from 5 seeds) for experiments with interventional batch size equal 1024.

Figure 4: The interventional target distributions obtained by different strategies on real-world data. The probability is represented by the intensity of the node’s color. The green color represents the edges for which there exists a graph in the Markov Equivalence Class that has the corresponding connection reversed. The number below each graph denotes the entropy of the distribution.

Figure 5: Histograms of intervention targets chosen by GIT. In this experiment, a node \(v\) was chosen (denoted by a red color; \(v\)’s parents are indicated by green). Parameters were initialized so that the model is only unsure about the neighborhood of \(v\). The solid lines denote known edges and dashed ones are to be discovered.

about the connectivity around \(v\), while the rest of the solution is given. We then run the ENCO framework with GIT and report the intervention target distributions in Figure 5.

The interventions concentrate on \(v\) (red color) and its parents (green color). This indicates the efficiency of our approach, as these are most relevant to discovering the graph structure. Indeed, to recover the solution, only the parameters for \(e E_{v}\) need to be found. Intervening on \(v\) changes the distributions of its descendants, providing information on the existence of edges between these variables.

## 6 Limitations and future work

* The theoretical grounding of the method involves multiple assumptions. Further work that simplifies or relaxes the assumptions and identifies fail cases would benefit the community.
* We provide proof that epsilon-greedy GIT converges with any causal discovery framework. As for pure GIT, we show its convergence only with the ENCO framework. The development of a more general theory that solidifies the approach is a promising future work direction.
* Our method can be applied in the soft-intervention case, and providing appropriate experimental evaluation would be an interesting follow-up to this work.
* Our method may need more interventions than the minimal number required to identify the causal structure. For example, GIT can be biased towards high-degree nodes, as interventions on them tend to affect a larger amount of structural parameters and result in larger gradients, which might cause suboptimal choices.
* Intervention acquisition methods (including GIT) seem to be less effective in a continuous setting. We believe investigating this area would benefit the community.

## 7 Conclusions

In this paper, we consider the problem of experimental design for causal discovery. We introduce a novel Gradient-based Intervention Targeting (GIT) method, which leverages the gradients of gradient-based causal discovery objectives to score intervention targets. We demonstrate that the method is particularly effective in the low-data regime, outperforming competitive baselines. We also provide a theoretical justification for the method and perform several analyses, confirming that GIT typically selects informative targets.