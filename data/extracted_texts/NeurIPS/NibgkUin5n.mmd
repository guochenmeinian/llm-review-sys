# Towards Generic Semi-Supervised Framework for

Volumetric Medical Image Segmentation

 Haonan Wang\({}^{1}\), Xiaomeng Li\({}^{1,2}\)

\({}^{1}\)The Hong Kong University of Science and Technology

\({}^{2}\)HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen

hwanggr@connect.ust.hk, eexmli@ust.hk

Corresponding author.

###### Abstract

Volume-wise labeling in 3D medical images is a time-consuming task that requires expertise. As a result, there is growing interest in using semi-supervised learning (SSL) techniques to train models with limited labeled data. However, the challenges and practical applications extend beyond SSL to settings such as unsupervised domain adaptation (UDA) and semi-supervised domain generalization (SemiDG). This work aims to develop a generic SSL framework that can handle all three settings. We identify two main obstacles to achieving this goal in the existing SSL framework: 1) the weakness of capturing distribution-invariant features; and 2) the tendency for unlabeled data to be overwhelmed by labeled data, leading to over-fitting to the labeled data during training. To address these issues, we propose an **Aggregating & Decoupling** framework. The aggregating part consists of a Diffusion encoder that constructs a _common knowledge set_ by extracting distribution-invariant features from aggregated information from multiple distributions/domains. The decoupling part consists of three decoders that decouple the training process with labeled and unlabeled data, thus avoiding over-fitting to labeled data, specific domains and classes. We evaluate our proposed framework on four benchmark datasets for SSL, Class-imbalanced SSL, UDA and SemiDG. The results showcase notable improvements compared to state-of-the-art methods across all four settings, indicating the potential of our framework to tackle more challenging SSL scenarios. Code and models are available at: https://github.com/xmed-lab/GenericSSL.

## 1 Introduction

Labeling volumetric medical images requires expertise and is a time-consuming process. Therefore, the use of semi-supervised learning (SSL) is highly desirable for training models with limited labeled data. Various SSL techniques  have been proposed, particularly in the field of semi-supervised volumetric medical image segmentation (SSVMIS), to leverage both labeled and unlabeled data. However, current SSVMIS methods  assume that the labeled and unlabeled data are from the same domain, implying they share the same distribution. In practice, medical images are often collected from different clinical centers using various scanners, resulting in significant domain shifts. These shifts arise due to differences in patient populations, scanners, and scan acquisition settings. As a consequence, these SSVMIS methods have limitations in real-world application scenarios and frequently encounter overfitting issues, leading to suboptimal results.

To address this limitation, researchers have increasingly focused on Unsupervised Domain Adaptation (UDA) techniques. These techniques leverage both labeled (source domain) and unlabeled data (targetdomain) for training, but the data originate from different domains. Furthermore, Semi-supervised Domain Generalization (SemiDG), a more stringent scenario, has garnered significant interest. SemiDG utilizes labeled and unlabeled data from multiple domains during training and is evaluated on an unseen domain. Currently, methods for these three scenarios are optimized separately, and there is no existing approach that addresses all three scenarios within a unified framework. However, given that all training stages involve labeled and unlabeled data, it is intuitive to explore a **generic SSL-based framework** that can handle all settings and eliminate the need for complex task-specific designs. Therefore, this paper aims to develop a generic framework that can handle existing challenges in real-world scenarios, including:

* _Scenario 1: SSL (Figure 1(a)): The sample data used for both training and testing are from the same domain, representing the standard SSL setting._
* _Scenario 2: UDA (Figure 1(b)): The sampled data originate from two domains, with the labels of the target domain being inaccessible, representing the UDA setting._
* _Scenario 3: SemiDG (Figure 1(c)): The sampled data encompasses multiple domains, with only a limited number of them being labeled, representing the SemiDG setting._

Potential similarities can be found and summarized as follows: (1) in the training stage, both labeled data and unlabeled data are used; (2) in the scenario of the real-world application domain, whether the distribution shifts in SSL or the domain shifts in UDA and SemiDG can all be regarded as _sampling bias_, _i.e._, the main difference is how we sample the data in Figure 1.

Now we wonder whether the existing SSVMIS methods are powerful enough to handle this general task. Experimental results show that the existing SSL methods do not work well on UDA and SemiDG settings, as shown in Table 3 & 4, and vice versa (Table 2). _One of the main obstacles lies in the severe over-fitting of these models, which is caused by the dominance of labeled data during training_. Specifically, the state-of-the-art SSVMIS methods are mainly based on two frameworks: (1) Teacher-student framework , where a student model is first trained with the labeled data, and a teacher model obtained from the EMA of the student model generates the pseudo label to re-train the student model with labeled data, see Figure 2(a); (2) CPS (Cross Pseudo Supervision)  framework, which leverages the consistency between two perturbed models and the pseudo label generated by one of the networks will be used to train the other network, see Figure 2(b). The predicting modules in these two main frameworks are trained with both labeled and unlabeled data; however, the labeled data, with precise ground truths as supervision, converges more rapidly compared with the unlabeled data. **Thus, the training process will easily get overwhelmed by the supervised training task**, as shown in Figure 3. Another challenge lies in the fact that existing SSVMIS methods fail to address the issue of distribution shifts, let alone domain shifts, resulting in a limitation in capturing features that are invariant to changes in distribution.

Figure 1: From (a), (b) to (c): generalizing SSL to UDA and SemiDG settings by sampling more diverse data to form the training and testing sets.

Based on the similarities and the main weaknesses of the mainstream SSVMIS methods, we argue that a generic framework is possible if we can solve the over-fitting issue and design a powerful methods to capture the distribution-invariant features. To tackle the above issues and design a generic SSVMIS methods for the real-world application scenarios, this work proposes a novel Aggregating & Decoupling (A&D) framework. Specifically, A&D consists of an Aggregating stage and a Decoupling stage. In the Aggregating stage, based on the recent success of the diffusion model [19; 20], we propose a Diff-VNet to aggregate the multi-domain features into one shared encoder to construct a _common knowledge set_ to improve the capacity of capturing the distribution-invariant features. To solve the over-fitting issue, in the Decoupling stage, we decouple the decoding process to (1) a labeled data training flow which mainly updates a Diff-VNet decoder and a difficulty-aware V-Net decoder to generate high-quality pseudo labels; (2) an unlabeled data training flow which mainly updates another vanilla V-Net decoder with the supervision of the pseudo labels. The denoising process of the Diff-VNet decoder provides the domain-unbiased pseudo labels while the difficulty-aware V-Net decoder class-unbiased pseudo labels. We also propose a re-parameterizing & smoothing combination strategy to further improve the quality of the pseudo labels.

The key contributions of our work can be summarized as follows: (1) we unify the SSL, Class Imbalanced SSL, UDA, and SemiDG for volumetric medical image segmentation with one generic framework; (2) we state the over-fitting issues of the current SSL methods and propose to solve it by an efficient data augmentation strategy and decoupling the decoders for labeled data and unlabeled, respectively; (3) we introduce the Diffusion V-Net to learn the underlying feature distribution from different domains to generalize the SSL methods to more realistic application scenarios; (4) The proposed Aggregating & Decoupling framework achieves state-of-the-art on representative datasets of SSL, class-imbalance SSL, UDA, and SemiDG tasks. Notably, our method achieves significant improvements on the Synapse dataset (12.3 in Dice) and the MMWHS dataset in the MR to CT setting (8.5 in Dice). Extensive ablation studies are conducted to validate the effectiveness of the proposed methods.

## 2 Related Work

### Semi-supervised Segmentation & the Class Imbalance Issue

Semi-supervised segmentation aims to explore tremendous unlabeled data with supervision from limited labeled data. Recently, self-training-based methods [3; 4; 21] have become the mainstreamof this domain. Approaches with consistency regularization strategies [22; 3; 21] achieved good performance by encouraging high similarity between the predictions of two perturbed networks for the same input image, which highly improved the generalization ability. In the medical image domain, the data limitation issue is more natural and serious. Existing approaches [23; 24; 10; 14; 13; 17; 16; 25] to combat the limited data have achieved great success but are bottlenecked by the application scenarios and cannot handle more challenging but practical settings such as UDA and SemiDG.

Class Imbalance IssueClass imbalance issue is a significant problem to extend the existing SSL-based methods to more practical setting, since medical datasets have some classes with notably higher instances in training samples than others. In natural image domain, different means are proposed to solve this issue, including leveraging unlabeled data [26; 27; 28; 29; 30], re-balancing data distributions in loss [31; 30; 32], debiased learning [6; 5]_etc._ In medical image domain, this issue is more severe but only few work [15; 33; 25] noticed this problem. Incorporating the class-imbalance awareness is crucial for the generalization of the SSL methods.

### Unsupervised Domain Adaptation & Semi-supervised Domain Generalization

Domain adaptation (DA) aims to solve the domain shifts by jointly training the model with source domain data and target domain data. Unsupervised Domain Adaptation (UDA) [34; 35; 36; 37] is the most challenging and practical setting among all the DA setting, since no target labels are required. In this context, UDA is becoming increasingly important in the medical image segmentation field, and as a result, a myriad of UDA approaches have been developed for cross-domain medical image segmentation by leveraging: generative adversarial-based methods [38; 39; 40; 41; 42; 43; 44; 45; 46], semi-supervised learning techniques [47; 48; 49], and self-training as well as contrastive learning techniques [50; 51], _etc_. Though with promising adaptation results, these methods highly rely on the unlabeled target domain information, which hinders the generalizability.

Domain generalization (DG) is a more strict setting, where the difference with DA is that the model does not use any information from the target domain. Unlike unsupervised domain adaptation, semi-supervised domain generalization (SemiDG) does not assume access to labeled data from the target domains. Existing SemiDG methods [52; 53] leverage various unusual strategies to solve the domain shifts, _e.g._, meta-learning , Fourier Transformation , compositionality _etc._, which are not general and have unsatisfactory performance on the tasks such as UDA and SSL.

Compared to these prior works, our work is the first to unify SSL, Imbalanced SSL, UDA, and SemiDG settings. This extension not only amplifies the scope and versatility of SSL-based frameworks in medical image segmentation but also stands in stark contrast to earlier approaches that remained confined to singular domains such as SSL or UDA.

### Diffusion Model

Denoising diffusion models [56; 19; 57; 58] have shown significant success in various generative tasks [59; 60; 61; 62; 63], due to the powerful ability of modeling the underlying distribution of the data, conceptually having a greater capacity to handle challenging tasks. Noticing this property, there has been a rise in interest to incorporate them into segmentation tasks, including both natural image segmentation [64; 65; 66], and medical image segmentation [67; 68; 20] Given the notable achievements of diffusion models in these respective domains, leveraging such models to develop generation-based perceptual models would prove to be a highly promising avenue to push the boundaries of perceptual tasks to newer heights.

## 3 Method

### Overview of the Aggregating & Decoupling Framework

In this section, we will introduce our **Aggregating & Decoupling (A&D)** framework, as shown in Figure 4, which consists of an Aggregating stage and a Decoupling stage. The training pipeline is illustrated in Algorithm 1.

The **Aggregating stage** aims to construct a _common knowledge set_ across domains based on the idea that all data share common underlying high-level knowledge, such as texture information.

By aggregating information from multiple domains and jointly trained, the encoder can capture the underlying domain-invariant features. To achieve this, we introduce a powerful yet efficient Sampling-based Volumetric Data Augmentation (SVDA) strategy to enlarge the distribution diversity and leverage the diffusion model to capture the invariant features of the diversified data.

In the decoding of the existing SSL methods, the decoders are simultaneously trained with both labeled and unlabeled data, which leads to coupling and over-fitting issues and further hinder the extending to the general SSL. The **Decoupling stage** aims to solve these issues by decoupling the labeled and unlabeled data training flows. Concretely, for the labeled data flow, (1) a diffusion decoder is mainly used to guide the diffusion encoder to learn the distribution-invariant representations through the diffusion backward process, and thus produces the _domain-unbiased pseudo labels_; (2) a vanilla V-Net decoder with the proposed difficulty-aware re-weighting strategy is mainly to avoid the model over-fit to the easy and majority classes, and thus produces the _class-unbiased pseudo labels_. Then, for the unlabeled data flow, the domain- and class-unbiased pseudo labels are ensembled through a proposed Reparameterize & Smooth (RS) strategy to generate high quality pseudo labels. Finally, the pseudo labels are used to supervise the training of an additional V-Net decoder for prediction only.

### Aggregating Stage

Assume that the entire dataset comprises of \(N_{L}\) labeled samples \(\{(x_{i}^{l},y_{i})\}_{i=1}^{N_{L}}\) and \(N_{U}\) unlabeled samples \(\{x_{i}^{u}\}_{i=1}^{N_{U}}\), where \(x_{i}^{D H W}\) is the input volume and \(y_{i}^{K D H W}\) is the ground-truth annotation with \(K\) classes. The goal of the aggregating stage is to augment the data with SVDA and encode the labeled \((x^{l},y)\) and unlabeled data \(x^{u}\) to high-level distribution-invariant features for denoising labeled data flow \(h^{l;}\) difficulty-aware labeled data flow \(h^{l;}\), and unlabeled data flow \(h^{u}\).

Sampling-based Volumetric Data Augmentation (SVDA)Instead of the time-consuming traditional data augmentation used in  which cascaded all the augmentations, SVDA build upon an augmentation set and \(N_{aug}\) operations are randomly sampled to apply to both the labeled and unlabeled data. The augmentation set consists of 3D spatial-wise transforms (random crop, random rotation, random scaling) and voxel-wise transforms (Gaussian blur, brightness, contrast, gamma). \(N_{aug}\) is empirically set to 3.

Figure 4: Overview of the proposed **Aggregating & Decoupling** framework. Blue and orange regions denote the training process with labeled data and unlabeled data, respectively. We separate the training of the decoders using labeled data and unlabeled data, and only use the decoder trained with unlabeled data for prediction.

**Diffusion for Capturing Invariant Features** We follow Diff-UNet  to use diffusion model for perception but modify it to a V-Net version and remove the additional image encoder. Given the labeled volume data \(x^{l}^{D W H}\) and its label \(y^{D W H}\), we first convert the label to the one-hot format \(y_{0}^{K D W H}\) and add successive \(t\) step noise \(\) to obtain the noisy label \(y_{t}^{K D W H}\), which is the diffusion forward process:

\[y_{t}=_{t}}y_{0}+_{t}}, (0,1)\] (1)

Then, the noisy label is concatenated with the image \(x^{l}\) as the input of the Diff-VNet. Concretely, the high-level features are different for different data flows. For the denoising flow, _i.e._, \(D(x^{l};)\) as decoder, the diffusion encoder takes concatenation \(([y_{t},x^{l}])\) and time step \(t\) as input to generate the time-step-embedded multi-scale features \(h_{i}^{l;}^{i F} }}\) where \(i\) is the stage and \(F\) is the basic feature size. \(h_{i}^{l;}\) are further used by \(D(x^{l};)\) to predict the clear label \(y_{0}\). For the difficulty-aware training flow and the unlabeled data flow, _i.e._, \(D(x^{l};)\) and \(D(x^{u};)\) as decoders, the encoder only takes \(x_{l}\) and \(x_{u}\) as input to obtain the multi-scale features \(h_{i}^{l;}\), \(h_{i}^{u}\), respectively. Note that \(h_{i}^{l;}\), \(h_{i}^{u}\) are with same shapes with \(h_{i}^{l;}\).

### Decoupling Stage

The decoupling stage consists of four steps: supervised denoising training to generate domain-unbiased pseudo labels, supervised difficulty-aware training to generate class-unbiased pseudo labels, pseudo labeling to ensemble the two pseudo labels and unsupervised training to get the final predictor.

Supervised Denoising Training with the Diffusion Decoder \(D(x^{l};)\)Taking \(h_{i}^{l;}\) as inputs, \(D(x^{l};)\) decodes the features to predict the clear label \(y_{0}\) as domain-unbiased pseudo label. The objective function is defined as follow:

\[_{deno}=}_{i=0}^{N_{L}}_{DiceCE}(p_{i} ^{l;},y_{i})\] (2)

where \(_{DiceCE}(x,y)=[_{CE}(x,y)+_{Dice} (x,y)]\) is the combined dice and cross entropy loss.

Supervised Difficulty-aware Training with \(D(x^{l};)\)To alleviate the common class imbalance issue in SSVMIS, we design a Difficulty-aware Re-weighting Strategy (DRS) to force the model to focus on the most difficult classes (_i.e._ the classes learned slower and with worse performances). The difficulty is modeled in two ways with the probability map \(p^{l;}\) produced by diffusion decoder \(D(x^{l};)\): learning speed and performance. We use Population Stability Index  to measure thelearning speed of each class after the \(e^{th}\) iteration:

\[du_{k,e}=_{e-}^{e}(,0)(}{ _{k,e-1}}), dl_{k,e}=_{e-}^{e}(,0)( }{_{k,e-1}})\] (3)

where \(_{k}\) denotes the Dice score of \(p^{l;}\) of \(k^{th}\) class in \(e^{th}\) iteration and \(=_{k,e}-_{k,e-1}\). \(du_{k,e}\) and \(dl_{k,e}\) denote classes not learned and learned after \(e^{th}\) iteration. \(\) is the number accumulation iterations and set to 50 empirically. Then, we define the difficulty of \(k^{th}\) class after \(e^{th}\) iteration as:

\[d_{k,e}=}{dl_{k,e}}\] (4)

where the classes learned faster have smaller \(d_{k,e}\), the corresponding weights in the loss function will be smaller to slow down the learn speed. We also accumulate \(1-_{k,e}\) for \(\) iterations to obtain the reversed dice weight \(w_{_{k,e}}\) and weight \(d_{k,e}\). In this case, classes with lower dice scores will have larger weights in the loss function, which forces the model to pay more attention to these classes. The overall difficulty-aware weight of \(k^{th}\) class is defined as:

\[w_{k}^{diff}=w_{_{k,e}}(d_{k,e})^{}\] (5)

where \(\) is empirically set to \(\) in the experiments to alleviate outliers. The objective function of the supervised difficulty-aware training is defined as follow:

\[_{diff}=}_{i=0}^{N_{L}}_{k=0}^{K}w _{k}^{diff}_{DiceCE}(p_{i,k}^{l;},y_{i,k})\] (6)

Pseudo Labeling with Reparameterize & Smooth (RS) StrategyThe domain-unbiased \(p^{u;}\) probability map is generated by iterating the diffusion model (\(E(x^{l},x^{u};)\)+\(D(x^{l};)\)) \(t\) times with the Denoising Diffusion Implicit Models (DDIM) method . The class-unbiased \(p^{u;}\) probability map can be obtained by \(D(x^{l};)\) with stopped gradient forward pass. We ensemble \(p^{u;}\) and \(p^{u;}\) to generate high-quality pseudo labels. However, when combining these two maps, we found that the denoised probability map \(p^{u;}\) is too sparse, _i.e._, with very high confidence of each class. This property is benefit for the fully-supervised tasks, but in this situation, it will suppress \(p^{u;}\) and is not robust to noise and error. Thus, we re-parameterize \(p^{u;}\) with the Gumbel-Softmax to add some randomness and using Gaussian blur kernel to remove the noise brought by this operation. The final pseudo label is:

\[y^{,}=((p^{u;})+(p^{u;}))\] (7)

Unsupervised Training with \(D(x^{u};)\)Finally, we can use the pseudo label \(y^{,}\) to train \(D(x^{u};)\) in an unsupervised manner. The objective function of the unsupervised training is defined as:

\[_{u}=}_{i=0}^{N_{U}}_{DiceCE}(p_{i}^{u; },y^{,})\] (8)

To better leverage the domain- and class-unbiased features, we also transmit with knowledge distillation strategy: \(=w_{ema}+(1-w_{ema})(+)/2,w_{ema}=0.99\). The overall training function of the A&G framework is:

\[=_{deno}+_{diff}+_{u}\] (9)

where \(\) is empirically set as \(10\) and follow  to use the epoch-dependent Gaussian ramp-up strategy to gradually enlarge the ratio of unsupervised loss. In the inference stage, only the diffusion encoder \(E(x^{l},x^{u};)\) and \(D(x^{u};)\) are used to generate the predictions.

## 4 Experiments

### Datasets and Implementation Details

We evaluate our proposed A&D framework on four datasets for four tasks, _i.e._, LASeg dataset  for SSL, Synapse dataset  for class imbalanced SSL, MMWHS dataset  for UDA, and M&Ms

[MISSING_PAGE_FAIL:8]

significant improvements over the existing state-of-the-art approach on the Synapse dataset with 20% labeled data and the MMWHS dataset in the MR to CT setting, demonstrating a substantial increase of 12.3 in Dice score for the Synapse dataset and 8.5 for the MMWHS dataset.

### Analyses

Architecture AnalysisAs shown in Figure 5, we test different architectures for the framework, the corresponding results are in Table 5. When using three separate networks (a)(b), the performance drop significantly, the reason is that this structure can not learn the domain-invariant features. Using pure V-Net (c) or diffusion-based networks (d) also leads to inferior results, especially for the pure diffusion model, it is hard to train due to the limited labeled data, high-quality pseudo labels are hard to obtain, which further hinder the training of the unsupervised branch.

Ablation on the componentsWe analyze the effectiveness of different components in our method. According to the results in Table 6, on MMWHS MR to CT setting (UDA), when removing the diffusion model, performance decreases the most, which indicated the importance ability of the diffusion model for capturing the distribution-invariant features. The result of removing the SVDA also indicates that when the data is not diverse enough, the diffusion model cannot capture effective underlying features. On Synapse dataset for IBSSL, the results are slightly different with those in the UDA setting, the DRS plays more important role than the Diffusion. In 5% M&Ms dataset for SemiDG, the results are quite aligned with results in the UDA setting.

Hyper-parameter SelectionWe evaluate the performance of our method under different time step \(t\) of the diffusion model and the number of sampled augmentations, as shown in Table 7.

   Arch. & a & b & c & d & e \\  Dice & 76.14 & 50.53 & 82.19 & 45.63 & 90.14 \\   

Table 6: Ablation study of the components in our framework on 20% labeled Synapse setting (IBSSL), MMWHS MR to CT setting (UDA) and 2% labeled 2% labeled M&Ms setting (SemiDG).

    &  &  \\  & Domain A & Domain B & Domain C & Domain D & Average & Domain A & Domain B & Domain C & Domain D & Average \\  nnUNet  & 52.87 & 64.63 & 72.97 & 73.27 & 65.94 & 65.30 & 79.73 & 78.06 & 81.25 & 76.09 \\ SDNet+Aug  & 54.48 & 67.81 & 76.46 & 74.35 & 68.28 & 71.21 & 77.31 & 81.40 & 79.95 & 77.47 \\ LDDG  & 59.47 & 56.16 & 68.21 & 68.56 & 63.16 & 66.22 & 69.49 & 73.40 & 75.66 & 71.29 \\ SAML  & 56.31 & 56.32 & 75.70 & 69.94 & 64.57 & 67.11 & 76.35 & 77.43 & 78.64 & 74.88 \\ BCP \({}^{*}\) & 71.57 & 76.20 & 76.87 & 77.94 & 75.65 & 73.66 & 79.04 & 77.01 & 78.49 & 77.05 \\ DGNet  & 66.01 & 72.72 & 77.54 & 75.14 & 72.85 & 72.40 & 80.30 & 82.51 & 83.77 & 79.75 \\ vMFNet  & 73.13 & 77.01 & **81.57** & 82.02 & 78.43 & 77.06 & 82.29 & **84.01** & **85.13** & 82.12 \\ \(}\)**(ours)** & **79.62** & **82.26** & 80.03 & **83.31** & **81.31** & **81.71** & **85.44** & 82.18 & 83.9 & **83.31** \\   ^{*}\) SOTA method on semi-supervised segmentation.} \\ 

Table 4: Results on two settings of M&Ms dataset for **SemiDG** task.

Figure 5: Ablation study on different architectures. (e) is the final framework

   Methods & A\&D & w/o SVDA & w/o Diffusion & w/o DRS & w/o RS \\  IBSSL & 60.9 & 55.3 & 56.7 & 52.0 & 58.7 \\ UDA & 90.1 & 84.6 & 79.2 & 85.8 & 87.0 \\ SemDG & 80.6 & 77.9 & 74.9 & 78.2 & 78.6 \\   

Table 7: Ablation study of the noise step \(t\) and the number of sampled augmentations on MMWHS CT to MR setting.

VisualizationWe also present the visualization results to further analyze our method. As shown in Figure 6, for the UDA task, our framework can generate smoother volumetric objects. Our framework also has detect minority classes, as can be seen in Appendix, which indicates the effectiveness of incorporating the class-imbalance awareness with the proposed difficulty-aware re-weighing strategy.

LimitationsThe diffusion process introduces additional training costs; however, the inference efficiency remains unaffected as only the decoder trained using unlabeled data is utilized during inference. Moreover, the failure cases are mainly in the M&Ms dataset for SemiDG setting. Specifically, our method usually fails on the first and the last slices along the depth axis. Due to the restricted depth dimension (less than 10), the 2D slices and the corresponding masks vary significantly. In such a case, it is hard for our volumetric framework to capture depth-wise information for the first or last slice with only one neighboring slice as a reference, and thus leads to false positive results.

## 5 Conclusion

In this paper, we propose a generic framework for semi-supervised learning in volumetric medical image segmentation, called Aggregating & Decoupling. This framework addresses four related settings, namely SSL, class imbalanced SSL, UDA, and SemiDG. Specifically, the aggregating part of our framework utilizes a Diffusion encoder to construct a "common knowledge set" by extracting distribution-invariant features from aggregated information across multiple distributions/domains. On the other hand, the decoupling part involves three decoders that facilitate the training process by decoupling labeled and unlabeled data, thus mitigating overfitting to labeled data, specific domains, and classes. Experimental results validate the effectiveness of our proposed method under four settings.

The significance of this work lies in its ability to encourage semi-supervised medical image segmentation methods to address more complex real-world application scenarios, rather than just developing frameworks in ideal experimental environments. Furthermore, we have consolidated all four settings within a single codebase, enabling the execution of any task using a single bash file by merely adjusting the arguments. We believe that this consolidated codebase will be convenient for further research and beneficial for the community.