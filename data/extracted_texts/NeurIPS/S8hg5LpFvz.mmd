# \(p\)-Poisson surface reconstruction

in curl-free flow from point clouds

Yesom Park\({}^{1}\)1, Taekyung Lee\({}^{2}\)2, Jooyoung Hahn\({}^{3}\), Myungjoo Kang\({}^{1}\)

\({}^{1}\) Department of Mathematical Sciences, Seoul National University

\({}^{2}\) Interdisciplinary Program in Artificial Intelligence, Seoul National University

\({}^{3}\) Department of Mathematics and Descriptive Geometry,

Slovak University of Technology in Bratislava

{yeisom, d1xorud1231, mkang}@snu.ac.kr

jooyoung.hahn@stuba.sk

Equal contribution authors. Correspondence to: <mkang@snu.ac.kr>.

###### Abstract

The aim of this paper is the reconstruction of a smooth surface from an unorganized point cloud sampled by a closed surface, with the preservation of geometric shapes, without any further information other than the point cloud. Implicit neural representations (INRs) have recently emerged as a promising approach to surface reconstruction. However, the reconstruction quality of existing methods relies on ground truth implicit function values or surface normal vectors. In this paper, we show that proper supervision of partial differential equations and fundamental properties of differential vector fields are sufficient to robustly reconstruct high-quality surfaces. We cast the \(p\)-Poisson equation to learn a signed distance function (SDF) and the reconstructed surface is implicitly represented by the zero-level set of the SDF. For efficient training, we develop a variable splitting structure by introducing a gradient of the SDF as an auxiliary variable and impose the \(p\)-Poisson equation directly on the auxiliary variable as a hard constraint. Based on the curl-free property of the gradient field, we impose a curl-free constraint on the auxiliary variable, which leads to a more faithful reconstruction. Experiments on standard benchmark datasets show that the proposed INR provides a superior and robust reconstruction. The code is available at https://github.com/Yebbi/PINC.

## 1 Introduction

Surface reconstruction from an unorganized point cloud has been extensively studied for more than two decades  due to its many downstream applications in computer vision and computer graphics. Classical point cloud or mesh-based representations are efficient but they do not guarantee a watertight surface and are usually limited to fixed geometries. Implicit function-based representations of the surface  as a level set \(=\{^{3} u()=c\}\) of a continuous implicit function \(u:^{3}\), such as signed distance functions (SDFs) or occupancy functions, have received considerable attention for providing watertight results and great flexibility

Figure 1: Comparison of reconstruction using an eikonal equation (9), the \(p\)-Poisson equation (8), and the proposed \(p\)-Poisson equation with the curl-free condition (11).

in representing different topologies. In recent years, with the rise of deep learning, a stream of work called _implicit neural representations_ (INRs) [2; 44; 16; 61; 19; 55; 53; 50] has revisited them by parameterizing the implicit function \(u\) with neural networks. INRs have shown promising results by offering efficient training and expressive surface reconstruction.

Early INRs [44; 42; 16] treat the points-to-surface problem as a supervised regression problem with ground-truth distance values, which are difficult to use in many situations. To overcome this limitation, some research efforts have used partial differential equations (PDEs), typically the eikonal equation, as a means to relax the 3D supervision [23; 37; 48]. While these efforts have been successful in reconstructing various geometries, they encounter an issue of non-unique solutions in the eikonal equation and rely heavily on the oriented normal vector at each point. They often fail to capture fine details or reconstruct plausible surfaces without normal vectors. A raw point cloud usually lacks normal vectors or numerically estimated normal vectors [1; 18] contain approximation errors. Moreover, the prior works are vulnerable to noisy observations and outliers.

The goal of this work is to propose an implicit representation of surfaces that not only provides smooth reconstruction but also recovers high-frequency features only from a raw point cloud. To this end, we provide a novel approach that expresses an approximated SDF as the unique solution to the \(p\)-Poisson equation. In contrast to previous studies that only describe the SDF as a network, we define the gradient of the SDF as an auxiliary variable, motivated by variable splitting methods [47; 60; 22; 12] in the optimization literature. We then parameterize the auxiliary output to automatically satisfy the \(p\)-Poisson equation by reformulating the equation in a divergence-free form. The divergence-free splitting representation contributes to efficient training by avoiding deeply nested gradient chains and allows the use of sufficiently large \(p\), which permits an accurate approximation of the SDF. In addition, we impose a curl-free constraint  because the auxiliary variable should be learned as a conservative vector field which has vanishing curl. The curl-free constraint serves to achieve a faithful reconstruction. We carefully evaluate the proposed model on widely used benchmarks and robustness to noise. The results demonstrate the superiority of our model without a priori knowledge of the surface normal at the data points.

## 2 Background and related works

Implicit neural representationsIn recent years, implicit neural representations (INRs) [41; 16; 3; 55; 54], which define a surface as zero level-sets of neural networks, have been extensively studied. Early work requires the ground-truth signed implicit function [44; 16; 41], which is difficult to obtain in real-world scenarios. Considerable research [3; 4] is devoted to removing 3D supervision and relaxing it with a ground truth normal vector at each point. In particular, several efforts use PDEs to remove supervision and learn implicit functions only from raw point clouds. Recently, IGR  revisits a conventional numerical approach  that accesses the SDF by incorporating the eikonal equation into a variational problem by using modern computational tools of deep learning. Without the normal vector, however, IGR misses fine details. To alleviate this problem, FFN  and SIREN  put the high frequencies directly into the network. Other approaches exploit additional loss terms to regulate the divergence  or the Hessian . The vanishing viscosity method, which perturbs the eikonal equation with a small diffusion term, is also considered [37; 49] to mitigate the drawback that the eikonal loss has unreliable minima. The classical Poisson reconstruction , which recovers the implicit function by integration over the normal vector field, has also been revisited to accelerate the model inference time , but supervision of the normal vector field is required. Neural-Pull  constructs a new loss function by borrowing the geometrical property that the SDF and its gradient define the shortest path to the surface.

\(p\)-Poisson equationThe SDF is described by a solution of various PDEs. The existing work [23; 55; 6] uses the eikonal equation, whose viscosity solution describes the SDF. However, the use of the residual of the eikonal equation as a loss function raises concerns about the convergence to the SDF due to non-unique solutions of the eikonal equation. Recent works [55; 6] utilize the notion of vanishing viscosity to circumvent the issue of non-unique solutions. In this paper, we use the \(p\)-Poisson equation to approximate the SDF, which is a nonlinear generalization of the Poisson equation (\(p=2\)):

\[-_{p}u=-(\| u\|^{p-2}  u)=1\\ u=0,\] (1)where \(p 2\), the computation domain \(^{3}\) is bounded, and \(\) is embedded in \(\).

The main advantage of using the \(p\)-Poisson equation is that the solution to (1) is unique in Sobolev space \(W^{1,p}()\). The unique solution with \(p 2\) brings a viscosity solution of the eikonal equation in the limit \(p\), which is the SDF, and it eventually prevents finding non-viscosity solutions of the eikonal equation; see a further discussion with an example in Appendix C.1. Moreover, in contrast to the eikonal equation, it is possible to describe a solution of (1) as a variational problem and compute an accurate approximation [5; 20]:

\[_{u}_{}}{p}d-_{ }ud.\] (2)

As \(p\), it has been shown [11; 30] that the solution \(u\) of (1) converges to the SDF whose zero level set is \(\). As a result, increasing \(p\) gives a better approximation of the SDF, which is definitely helpful for surface reconstruction. However, it is still difficult to use a fairly large \(p\) in numerical computations and in this paper we will explain one of the possible solutions to the mentioned problem.

## 3 Method

In this section, we propose a \(p\)-Poisson equation based **I**mplicit **N**eural representation with **C**url-free constraint (**PINC**). From an unorganized point cloud \(=\{_{i}:i=1,2,,N\}\) sampled by a closed surface \(\), a SDF \(u:^{3}\) whose zero level set is the surface \(=\{^{3} u()=0\}\) is reconstructed by the proposed INR. There are two key elements in the proposed method: First, using a variable-splitting representation  of the network, an auxiliary output is used to learn the gradient of the SDF that satisfies the \(p\)-Poisson equation (1). Second, a curl-free constraint is enforced on an auxiliary variable to ensure that the differentiable vector identity is satisfied.

### \(p\)-Poisson equation

A loss function in the physics-informed framework  of the existing INRs for the \(p\)-Poisson equation (1) can be directly written:

\[_{u}_{}|u|d+_{0}_{}| (\| u\|^{p-2} u)+1|d ,\] (3)

where \(_{0}>0\) is a regularization constant. To reduce the learning complexity of the second integrand, we propose an augmented network structure that separately parameterizes the gradient of the SDF as an auxiliary variable that satisfies the \(p\)-Poisson equation (1).

Variable-splitting strategyUnlike existing studies [23; 37; 6] that use neural networks with only one output \(u\) for the SDF, we introduce a separate auxiliary network output \(G\) for the gradient of the SDF; see that the same principle is used in . In the optimization literature, it is called the variable splitting method [47; 60; 22; 12] and it has the advantage of decomposing a complex minimization into a sequence of relatively simple sub-problems. With the auxiliary variable \(G= u\) and the penalty method , the variational problem (3) is converted into an unconstrained problem:

\[_{u,G}_{}|u|d+_{0}_{} |(\|G\|^{p-2}G)+1|d+ _{1}_{}\| u-G\|^{2}d,\] (4)

where \(_{1}>0\) is a penalty parameter representing the relative importance of the loss terms.

\(p\)-Poisson as a hard constraintLooking more closely at the minimization (4), if \(G\) is already a gradient to satisfy (1), then the second term in (4) is no longer needed and it brings the simplicity of one less parameter. Now, for a function \(F:^{3}\) such that \( F=1\), for example \(F()=\), the \(p\)-Poisson equation (1) is reformulated by the divergence-free form:

\[(\| u\|^{p-2} u+F)=0.\] (5)

Then, there exists a vector potential \(:^{3}^{3}\) satisfying

\[\|G\|^{p-2}G+F=,\] (6)

[MISSING_PAGE_FAIL:4]

Note that the optimal \(\) should have a unit norm according to the eikonal equation. To facilitate training, we relax this nonconvex equality condition into a convex constraint \(\|\ \ \| 1\). To this end, we parameterize the second network auxiliary output \(\) and define \(\) by

\[=()}{ \{1,\|\ \ \|\}},\] (12)

where \(\) is the projection operator to the three-dimensional unit ball. Appendix A provides further discussion on the importance of the curl-free term to learn a conservative vector field.

Figure 2 illustrates the proposed network architecture. The primary and the auxiliary variables are trained in a single network, instead of being trained separately in individual networks. The number of network parameters remains almost the same since only the output dimension of the last layer is increased by six, while all hidden layers are shared.

### Proposed loss function

In the case of a real point cloud to estimate a closed surface by range scanners, it is inevitable to have occluded parts of the surface where the surface has a concave part depending on possible angles of the measurement . It ends up having relatively large holes in the measured point cloud. Since there are no points in the middle of the hole, it is necessary to have a certain criterion for how to fill in the hole. In order to focus to check the quality of \(_{}\) (11) in this paper, we choose a simple rule to minimize the area of zero level set of \(u\):

\[_{}=_{}+_{4}_{} _{}(u)\| u\|\,d,\] (13)

where \(_{4}>0\) and \(_{}(x)=1-^{2}()\) is a smeared Dirac delta function with \(>0\). The minimization of the area is used in [21; 49] and the advanced models [15; 27; 63] on missing parts of the point cloud to provide better performance of the reconstruction.

## 4 Experimental results

In this section, we evaluate the performance of the proposed model to reconstruct 3D surfaces from point clouds. We study the following questions: **(i)** How does the proposed model perform compared to existing INRs? **(ii)** Is it stable from noise? **(iii)** What is the role of the parts that make up the model and the loss? Each is elaborated in order in the following sections.

ImplementationAs in previous studies [44; 23; 37], we use an 8-layer network with 512 neurons and a skip connection to the middle layer, but only the output dimension of the last layer is increased by six due to the auxiliary variables. For (13), we empirically set the loss coefficients to \(_{1}=0.1\), \(_{2}=0.0001\). \(_{3}=0.0005\), and \(_{4}=0.1\) and use \(p=\) in (7) for numerical simplicity. We implement all numerical experiments on a single NVIDIA RTX 3090 GPU. In all experiments, we use the Adam optimizer  with learning rate \(10^{-3}\) decayed by \(0.99\) every \(2000\) iterations.

Figure 2: The visualization of the augmented network structure with two auxiliary variables.

DatasetsWe leverage two widely used benchmark datasets to evaluate the proposed model for surface reconstruction: Surface Reconstruction Benchmark (SRB)  and Thingi10K . The geometries in the mentioned datasets are challenging because of their complex topologies and incomplete observations. Following the prior works, we adopt five objects per dataset. We normalize the input data to center at zero and have a maximum norm of one.

BaselinesWe compare the proposed model with the following baselines: IGR , SIREN , SAL , PHASE , and DiGS . All models are evaluated from only raw point cloud data without surface normal vectors. A comparison with models that leverage surface normals as supervision is included in Appendix C.

MetricsTo estimate the quantitative accuracy of the reconstructed surface, we measure Chamfer (\(d_{C}\)) and Hausdorff (\(d_{H}\)) distances between the ground-truth point clouds and the reconstructed surfaces. Moreover, we report one-sided distances \(d_{}}\) and \(d_{}\) between the noisy data and the reconstructed surfaces. Please see Appendix B.2 for precise definitions.

### Surface reconstruction

We validate the performance of the proposed PINC (13) in surface reconstruction in comparison to other INR baselines. For a fair comparison, we consider the baseline models that were trained without a normal prior. Table 1 summarizes the numerical comparison on SRB in terms of metrics. We report the results of baselines from . The results show that the reconstruction quality obtained is on par with the leading INRs, and we achieved state-or-the-art performance for Chamfer distances.

Figure 3: 3D Reconstruction results for SRB and Thingi10K datasets.

[MISSING_PAGE_FAIL:7]

shows that the variable splitting method, which satisfies the \(p\)-Poisson equation as a hard constraint (without the curl-free condition), recovers a fairly decent surface, but it generates oversmoothed surfaces and details are lost. However, as we can see from the qualitative result reconstructed with the curl-free constraint, this constraint allows us to capture the details that PINC without the curl-free condition cannot recover. The metric values presented in Table 3 also provide clear evidence of the need for the curl-free term. To further examine the necessity of another auxiliary variable \(\), we conduct an additional experiment by applying the curl-free loss term directly on \(G\) without the use of \(\). The results are presented in the second row of the Table 3. The results indicate that taking curl on \(G\), which is constructed by taking curl on \(\) in (7), leads to a suboptimal reconstruction. This is likely due to a challenging optimization landscape that is difficult to optimize as a result of consecutive automatic differentiation . The results provide numerical evidences of the necessity of introducing \(\).

Effect of minimal area criterionWe study the effect of the minimal area criterion suggested in Section 3.3. In real scenarios, there are defected regions where the surface has not been measured. To fill this part of the hole, the minimum surface area is considered. Figure 6 clearly shows this effect. Some parts in the daratech of SRB have a hole in the back. Probably because of this hole, parts that are not manifolds are spread out as manifolds as shown in the left figure without considering the minimal area. However, we can see that adding a minimal area loss term alleviates this problem. We would like to note that, except for daratech, we did not encounter this problem because other data are point clouds sampled from a closed surface and also are not related to hole filling. Indeed, we

Figure 4: Reconstruction results from noisy observations. Two levels of additive Gaussian noise with standard deviations \(=0.005\) (low) and \(0.01\) (high) are considered.

Figure 5: Comparison of surface reconstruction without (left) and with (right) curl-free constraint.

    &  &  \\ Model & \(d_{C}\) & \(d_{H}\) & \(d_{}\) & \(d_{}\) \\  wo/ curl free & 0.20 & 4.96 & 0.12 & 2.98 \\ w/ curl free on \(G\) & 4.17 & 52.26 & 0.48 & 6.03 \\ w/ curl free on \(\) & 0.16 & 4.78 & 0.05 & 0.80 \\   

Table 3: Quantitative results on the ablation study of the curl-free term.

empirically observe that the results are quite similar with and without the minimal area term for all data other than charatech.

Effect of large \(p\)The \(p\)-Poisson equation (1) draws the SDF as \(p\) becomes infinitely large. Therefore, it is natural to think that it would be good to use a large \(p\). Here, we conducted experiments on the effect of \(p\). We define \(G\) with various \(p=2,10\), and \(100\) and learn the SDF with it. Figure 7 shows surfaces that were recovered from the Gargoyle data in the SRB with different \(p\) values. When \(p\) is as small as 2, it is obvious that it is difficult to reconstruct a compact surface from points. When \(p\) is 10, a much better surface is constructed than that of \(p=2\), but the by-products still remain on the small holes. Furthermore, a large value of \(p=100\) provides a quite proper reconstruction. This experimental result demonstrates that a more accurate approximation can be obtained by the use of a large \(p\), which is consistent with the theory. This once again highlights the advantage of the variable splitting method we have proposed, which allows an arbitrarily large \(p\) to be used. This highlights the advantage of the variable splitting method (7) we have proposed in Section 3.1, which allows an arbitrarily large \(p\) to be used. Note that the previous approaches have not been able to use large \(p\) because the numeric value of \(p\)-power easily exceeds the limit of floating precision. On the other hand, the proposed method is amenable to large \(p\) and hence the reconstruction becomes closer to the point cloud.

## 5 Conclusion and limitations

We presented a \(p\)-Poisson equation-based shape representation learning, termed PINC, that reconstructs high-fidelity surfaces using only the locations of given points. We introduced the gradient of the SDF as an auxiliary network output and incorporated the \(p\)-Poisson equation into the auxiliary variable as a hard constraint. The curl-free constraint was also used to provide a more accurate representation. Furthermore, the minimal surface area regularization was considered to provide a compact surface and overcome the ill-posedness of the surface reconstruction problem caused by unobserved points. The proposed PINC successively achieved a faithful surface with intricate details and was robust to noisy observations.

The minimization of the surface area is used to reconstruct missing parts of points under the assumption that a point cloud is measured by a closed surface. Regarding the hole-filling strategy, it still needs further discussion and investigation of various constraints such as mean curvature or total variation of the gradient. At present, the proposed PDE-based framework is limited to closed surfaces and is inadequate to reconstruct open surfaces. We leave the development to open surface reconstruction as future work. Establishing a neural network initialization that favors the auxiliary gradient of the SDF would be an interesting venue. Furthermore, the computational cost of convergence would differ when using and not using auxiliary variables. Analyzing the convergence speed or computational cost of utilizing auxiliary variables versus not utilizing them is a worthwhile direction for future research.

## 6 Societal Impacts

The proposed PINC allows high-quality representation of 3D shapes only from raw unoriented 3D point cloud. It has many potential downstream applications, including product design, security, medical imaging, robotics, and the film industry. We are aware that accurate 3D surface reconstruction

Figure 6: Comparison of surface recovery without (a) and with (b) minimum area criterion.

can be used in malicious environments such as unauthorized reproduction of machines without consent and digital impersonation. However, it is not a work to develop a technique to go to abuse, and we hope and encourage users of the proposed model to concenter on the positive impact of this work.

## 7 Acknowledgements

This work was supported by the NRF grant [2012R1A2C3010887] and the MSIT/IITP (, [2021-0-00077], [No. 2021-0-01343, Artificial Intelligence Graduate School Program(SNU)]). Also, this project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 945478.