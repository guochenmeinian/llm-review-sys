# Flexible task abstractions emerge in linear networks

with fast and bounded units

Kai Sandbrink

Exp. Psychology, Oxford

Brain Mind Institute, EPFL

&Jan P. Bauer

ELSC, HebrewU

Gatsby Unit, UCL

&Alexandra M. Proca

Department of Computing

Imperial College London

&Andrew M. Saxe

Gatsby Unit, UCL

&Christopher Summerfield

Exp. Psychology, Oxford

&Ali Hummos

Brain and Cognitive Sciences

MIT

Equal contribution, randomized orderCorresponding author, ahummos@MIT.edu

###### Abstract

Animals survive in dynamic environments changing at arbitrary timescales, but such data distribution shifts are a challenge to neural networks. To adapt to change, neural systems may change a large number of parameters, which is a slow process involving _forgetting_ past information. In contrast, animals leverage distribution changes to segment their stream of experience into tasks and associate them with internal task abstractions. Animals can then respond _flexibly_ by selecting the appropriate task abstraction. However, how such flexible task abstractions may arise in neural systems remains unknown. Here, we analyze a linear gated network where the weights and gates are jointly optimized via gradient descent, but with neuron-like constraints on the gates including a faster timescale, nonnegativity, and bounded activity. We observe that the weights self-organize into modules specialized for tasks or sub-tasks encountered, while the gates layer forms unique representations that switch the appropriate weight modules (task abstractions). We analytically reduce the learning dynamics to an effective eigenspace, revealing a virtuous cycle: fast adapting gates drive weight specialization by protecting previous knowledge, while weight specialization in turn increases the update rate of the gating layer. Task switching in the gating layer accelerates as a function of curriculum block size and task training, mirroring key findings in cognitive neuroscience. We show that the discovered task abstractions support generalization through both task and subtask composition, and we extend our findings to a nonlinear network switching between two tasks. Overall, our work offers a theory of cognitive flexibility in animals as arising from joint gradient descent on synaptic and neural gating in a neural network architecture.

## 1 Introduction

Humans and other animals show a remarkable capacity for flexible and adaptive behavior in the face of changes in the environment. Brains leverage change to discover latent factors underlying their sensory experience : they segment the computations to be learned into discrete units or 'tasks'. After learning multiple tasks, low-dimensional task representations emerge that are abstract (represent the task invariant to the current input)  and compositional . The discovery of theseuseful task abstractions relies on the temporal experience of change, and in fact, brains struggle when trained on randomly shuffled interleaved data (Flesch et al., 2018; Beukers et al., 2024).

In contrast, while artificial neural networks have become important models of cognition, they perform well in environments with large, shuffled datasets but struggle with temporally correlated data and distribution shifts. To adapt to changing data distributions (or 'tasks'), neural networks rely on updating their high-dimensional parameter space, even when revisiting previously learned tasks - leading to catastrophic forgetting (McCloskey and Cohen, 1989; Hadsell et al., 2020). One way to limit this forgetting is through task abstractions, either provided to the models (Hummos et al., 2024) or discovered from data (Hummos, 2023). In addition, adapting a model entirely by updating its weights is data-intensive due to high dimensionality. Task abstractions simplify this process by allowing updates to a low-dimensional set of parameters, which can be switched rapidly between known tasks, and recomposed for new ones. However, despite the advantages of task abstractions, simple algorithms for segmenting tasks from a stream of data in neural systems remain an open challenge.

This paper examines a novel setting where task abstractions emerge in a linear gated network model with several neural pathways, each gated by a corresponding gating variable. We jointly optimize the weight layer and gating layer through gradient descent, but impose faster timescale, nonnegativity, and bounded activity on the gating layer units, making them conceptually closer to biological neurons. We find two discrete learning regimes for such networks based on hyperparameters, a _flexible_ learning regime in which knowledge is preserved and task structure is integrated flexibly, and a _forgetful_ learning regime in which knowledge is overwritten in each successive task. In the flexible regime, the gating layer units align to represent tasks and subtasks encountered while the weights separate into modules that align with the computations required. Later on, gradient descent dynamics in the gating layer neurons can retrieve or combine existing representations to switch between previous tasks or solve new ones. Such flexible gating-based adaptation offers a parsimonious mechanism for continual learning and compositional generalization (Butz et al., 2019; Hummos, 2023; Qihong Lu et al., 2024; Schug et al., 2024). Our key contributions thus are as follows:

* We **describe flexible and forgetful modes of task-switching** in neural networks and **analytically identify the effective dynamics** that induce the flexible regime.
* The model, to our knowledge, is **the first simple neural network model that benefits from data distribution shifts and longer task blocks rather than interleaved training**(Flesch et al., 2018; Beukers et al., 2024). We also provide a direct comparison to human behavior where task switching accelerates with further task practice (Steyvers et al., 2019).
* We **generalize our findings to fully-connected deep linear networks**. We find that differential learning rates and regularization on the second layer weights are necessary and sufficient for earlier layers to form task-relevant modules and later layers to implement a gating-based solution that selects the relevant modules for each task.
* We **extend our findings to non-linear networks**. As a limited proof of concept, we embed such a layer in a non-linear convolutional network learning two-digit classification tasks.

## 2 Related work

Cognitive flexibility allows brains to adapt behavior in response to change (Miller and Cohen, 2001; Egner, 2023; Sandbrink and Summerfield, 2024). Neural network models of cognitive flexibility frequently represent knowledge for different tasks in distinct neural populations, or modules, which then need to be additionally gated or combined (Musslick and Cohen, 2021; Yang et al., 2019). Several models assumed access to ground truth task identifiers and used them to provide information about the current task demands to the network (Kirkpatrick et al., 2017; Masse et al., 2018; Yang et al., 2019; Wang and Zhang, 2022; Driscoll et al., 2024; Hummos et al., 2024). Indeed having access to task identifiers facilitates learning, decreases forgetting, and enables compositional generalization (Yang et al., 2019; Masse et al., 2022; Hummos et al., 2024). Such works sidestep the problem of discovering these task representations from the data stream.

Other models train modular neural structures end-to-end, such as mixture-of-experts (Jacobs et al., 1991; Jordan and Jacobs, 1994; Tsuda et al., 2020), or modular networks (Andreas et al., 2016; Kirsch et al., 2018; Goyal et al., 2019). A fundamental issue is the 'identification problem' where different assignments of experts to tasks do not significantly influence how well the model can fit the data, making identification of useful sub-computations via specialized experts difficult (Geweke, 2007). Practically, this results in a lack of modularity with tasks learned across many experts (Mittal et al., 2020) or expert collapse, where few experts are utilized (Krishnamurthy et al., 2023). Recent work used a surprise signal to allow temporal experience to adapt learning (Barry and Gerstner, 2022). Our model proposes simple dynamics that benefit from the temporal structure to assign sub-tasks to modules.

Our work builds on the theoretical study of _linear_ networks which exhibit complex learning dynamics, but are analytically tractable (Saxe et al., 2013, 2019). Prior work examined how gating alleviates interference (Saxe et al., 2022), but gating was static and provided as data to the network. We generalize this line of work by showing how appropriate gating emerges dynamically. More recently, Shi et al. (2022) analyzed specialization of a linear network with multiple paths when tasks are presented without blocking and gates, and Lee et al. (2024) studied the effects of a pretraining period. We consider continual learning with a blocked curriculum. Schug et al. (2024) proved that learning a linear number of (connected) task module combinations is sufficient for compositional generalization to an exponential number of module combinations in a modular architecture similar to ours. Instead, we explicitly study the interaction between task learning and gating variable update dynamics.

## 3 Approach

### Setting

We formulate a dynamic learning problem consisting of \(M\) distinct tasks. At each time step \(t\) the network is presented with an input and output pair \(((t),^{ m}((t)))\) sampled from the current task \(m\). Tasks are presented in blocks lasting a period of time \(_{B}\) before switching to another task sequentially (Fig. 1A). Models are never given the task identity \(m\) or task boundaries.

Specifically, we consider a multitask teacher-student setup in which each task is defined by a teacher \(^{ m}\), which generates a ground truth label \(^{ m}=^{ m}\) with a Gaussian i.i.d. input \(\) at every point in time. We randomly generate the teachers to produce orthogonal responses to the same input. While orthogonal tasks simplify theoretical analysis, we generalize to non-orthogonal tasks in Appendix A.9.

### Model

We study the ability of linear gated neural networks (Saxe et al., 2013, 2022) to adapt to teachers sequentially. We use a one-layer linear gated network with \(P\) student weight matrices \(^{p}^{d_{} d_{}}\), together with \(P\) scalar variables \(c^{p}\) which gate a cluster of neurons in the hidden layer (Fig. 1B). The model output \(^{d_{}}\) reads

\[=_{p=1}^{P}c^{p}^{p}.\] (1, NTA)

Since the \(c^{p}\) variables will learn to reflect which task is currently active, we refer to their activation patterns as _task abstractions_. We refer to a student weight matrix together with its corresponding gating variable as a _path_.

We refer to this architecture as the Neural Task Abstractions (NTA) model when the following two conditions are met during training: first, we update both the weights \(^{p}\) and the gating variables \(c^{p}\) via gradient descent, but on a regularized loss function \(=_{}+_{}\). Second, we impose a shorter timescale for the gates \(_{c}\) than for the weights \(_{w}\), i.e. \(_{c}<_{w}\) (although this condition becomes unnecessary if the task is sufficiently high-dimensional, see Appendix A.2).

Figure 1: The open-ended learning setting and the modeling approach. A. Example of the blocked curriculum with two tasks. B. Neural Task Abstraction (NTA) model updates \(^{p}\) through gradient descent, but also the gating variables \(c^{p}\), leading to task abstractions emerging in the gating layer.

The task loss is a mean-squared error \(_{}=}{{2}}_{i}^{d_{}}((y_{i}^{*m}-y _{i})^{2})\) where the average is taken over a batch of samples. The regularization loss contains two components \(_{}=_{}_{}+ _{}_{}\) weighted by coefficients \(_{},_{}\). The normalization term bounds gate activity, \(_{}=}{{2}}(||||_{k}-1)^{2}\), where we consider \(k=1,2\). The nonnegativity term favors positive gates \(_{}=_{p=1}^{p}(0,-c^{p})\). Together, these regularizers incentivize the model to function as an approximate mixture model by driving solutions towards any convex combination of students without favoring specialization and reflect constraints of biological neurons (see Appendix B.3 for details).

Assuming small learning rates (_gradient flow_), this approach implies updates of

\[_{c}}{{dt}}\,c^{p}=-\,_{c^{p}}\,, _{w}}{{dt}}\,^{p}=-\,_{^{p}}\, \]

where \(_{c}\) and \(_{w}\) are time constants of the model parameters. We initialize \(^{p}\) as i.i.d. Gaussian with small variance \(^{2}/d_{}\), \(=0.01\) and \(c^{p}=}{{2}}\).

Code for model and simulations at: [https://github.com/aproca/neural_task_abstraction](https://github.com/aproca/neural_task_abstraction)

## 4 Task abstractions emerge through joint gradient descent

We train the model with fast and bounded gates on \(M=2\) alternating tasks (Fig. 1A) and use \(P=2\) paths for simplicity (for the \(P M\) case, see Fig. 3 and Appendix A.3). As a baseline, we compare to the same model but without gate regularization and timescales difference.

Both models reach low loss in early blocks, but only flexible NTA starts to adapt to task switches increasingly fast after several block changes (Fig. 2A,F). Analyzing the model components reveals what underlies this accelerated adaptation (Fig. 2C,D): in early blocks of training, zero loss is reached through re-aligning both students \(^{p}\) to the active teacher \(^{*m}\) in every block, while the gates \(c^{p}\) are mostly drifting (Fig. 2B). Reaching low loss is furthermore only achieved towards the end of a block. Later, the weights stabilize to each align with one of the teachers (Fig. 2C,D), and the appropriate student is selected via gate changes (Fig. 2B), reducing loss quickly. The rate at which gates change correlates with the alignment and magnitude \(||^{p}||\) of the learned weights (Fig. 2C,E). Overall, this points towards a transition between two learning regimes: first, learning happens by aligning student weight matrices with the current teacher, which we call _forgetful_ because it overwrites previous weight changes. Later, as the weights specialize, the learned representations \(^{p}\) can be rapidly selected by the gates according to the task at hand, reflecting adaptation that is _flexible_. Only

Figure 2: **Joint gradient descent on gates and weights enables fast adaptation through gradual specialization. Learning on the blocked curriculum from Fig. 1 with \(_{c}=0.03\), \(_{w}=1.3\), and block length \(_{B}=1.0\). \(x\)-axis indicates time as multiples of \(_{B}\). (_Black_) Flexible NTA model Eq. (1, NTA), (_gray_) forgetful NTA model with \(_{c}=_{w}\) and \(_{}=_{}=0\). Simulation averaged over 10 random seeds with standard error indicated. A. Loss of both models over time. B. Gate activity of flexible NTA. C. Student-teacher weight alignment \(^{*m}^{p}\), normalized and averaged over rows (cosine similarity) for each student-teacher pair. D., E. Norm of updates to \(^{p}\) and c. _Dashed_: norm of students correlating with update size of \(\). F. Time to \(_{}=0.1\) for both models over blocks.**

the model equipped with fast and bounded gates (flexible NTA) is able to enter this flexible regime (Fig. 2A,F).

Next, we verify that the task abstractions in the gating variables are general, in the sense that they support compositional generalization. We consider two settings that begin by training a model with three paths on three teachers A, B, and C in alternating blocks, and then training on novel conditions. In _task composition_, the novel conditions are the teachers' additive compositions A+B, A+C, B+C (Fig. 3A), we see that the flexible NTA model trains on these combinations much faster (Fig. 3C). In _subtask composition_, the novel conditions are combinations of the rows of different teachers, i.e. we break the teachers A, B, C into rows and select from these rows to compose new tasks. (Fig. 3B). In the subtask composition case, we use a more expressive form of the gates in the model that can control each row of the student matrices \(^{p}\) individually. We find that, in the flexible regime, the model quickly adapts to the introduction of compositional tasks, while the forgetful model with regularization removed does not (Fig. 3C,D). For more details and extended analysis, see Appendix A.8.

We devote the next section to identifying what factors support the flexible regime of learning.

## 5 Mechanisms of learning flexible task abstractions

We observed in Fig. 2 that simultaneous gradient descent on weights and gates converges to a flexible regime capable of rapid adaptation to task changes. But what mechanisms facilitate this solution? We here leverage the linearity of the model to identify the effective dynamics in the SVD space of the teachers, in which we describe the emergence and functioning of the flexible regime.

### Reduction to effective 2D model dynamics

For simplicity, we consider the case with only \(M=P=2\) teachers and students. We take a similar approach to Saxe et al. (2013), and project the student weights into the singular value space of the teachers for each mode \(\) individually, yielding a scalar \(w^{p}_{2^{m}}^{ m}^{p}^{ m} _{}\). Each pair of components \(\) thus reduces to a 2D state vector \(=c^{1}^{1}+c^{2}^{2}^{2}\), where we stack \(w^{p}_{m}\) along the index \(m\) and omit \(\) in the following for readability (Fig. 4A). A similar projection is possible in terms of the row vectors of both teachers (Appendix A.1.1).

The essential learning dynamics of the system can therefore be described as

\[_{w}\,}{t}^{p}=c^{p}(^{ m} -), \] \[_{c}\,}{t}^{p}=^{p }(^{ m}-)-\,_{c^{p}}_{}. \]

where \(^{ m}\) describes the output of the currently-active teacher \(m\). In Appendix A.1, we show analytically and through simulations that this reduction is exact when gradients are calculated over many samples.

Figure 3: **Flexible model generalizes to compositional tasks.****A.** Task composition consists of new tasks that sum sets of teachers previously encountered. **B.** Subtask composition consists of new tasks that concatenate alternating rows of sets of teachers previously encountered. Loss of models trained on generalization to task composition (**C.**) and subtask composition (**D.**) for the flexible (_black_) and forgetful (_gray_) NTA. ‘New tasks’ indicates the start of the generalization phase when the task curriculum is changed to cycle through the compositional tasks.

### Specialization emerges due to self-reinforcing feedback loops

The flexible regime is characterized by students that are each attuned to a single teacher (Fig. 4B), whereas in the forgetful regime, both students track the active teacher together (Fig. 4C). We can describe this difference by studying the specialization of the students. We define this by considering the difference in how represented the teachers are in the two paths: for teacher 1, \(_{1} w_{m=1}^{p=1}-w_{m=1}^{p=2}\) and, for teacher 2, \(_{2} w_{m=2}^{p=2}-w_{m=2}^{p=1}\). Similarly, a hallmark of the flexible regime are separated gates. Together, this defines the specialization subspace

\[(_{1}+_{2}), \] \[ c^{1}-c^{2} \]

The system is in the flexible regime when absolute values of \(\) and \(\) are high (approaching 1), and in the forgetful regime when they are low (around 0). In this section, we study the emergence of the flexible regime through self-reinforcing feedback loops, with specialized students and normalizing regularization leading to more separated gates, and separated gates in turn leading to more specialized students. In each subsection, we first describe the effect of the feedback loops on the paths individually, before considering the combined effect on specialization. Without loss of generality, we consider cases where the student \(p\) specializes to teacher \(m=p\).

#### 5.2.1 Specialized students and regularization encourage fast and separated gates

We first investigate the influence of \(^{p}\) on \(}{t}c^{p}\). From the gate update in Eq. (2), we get

\[_{c}}{t}c^{p}=_{1}\,^{p }^{ 1}\;+\;_{2}\,^{p}^{ 2}\; \;\;\;-\;\;\;\;\;_{c^{p}}_{}, \]

where we decomposed the error \(^{ m}-\) into the teacher basis as coefficients \(_{m}^{}^{ m}\). The feedback between students and gates enters here in two terms, as can be seen by expressing \(^{p}^{ m}=||^{p}||\,||^{ m}||\, ((^{p},^{ m}))\), where \(\) denotes the angle between two vectors. As observed in Fig. 2, both the _alignment_ between students and teachers \(((^{p},^{ m}))\) and the _magnitude_ of the students \(||^{p}||\) control the gate switching speed.

Figure 4: **Mechanism of gradual task specialization in effective 2D subspace.****A.** Sketch of the reduced model and dynamic feedback. Out-of-subspace students gradually align to teacher axes. **B.** Trajectories of student weight matrices (_blue, orange_) in the teacher subspace during complete adaptation following a context switch from teacher 1 to teacher 2 in the flexible regime. _Gray stripes_ indicate associated gate activation. The student weight matrices move little. **C.** Like (**B**), but for the forgetful regime. Student weight matrices entirely remap and gates do not turn off. **D.** Gradient of the task loss on \(c^{p}\) as a function of the weight alignment. **E.** Trajectories in the specialization subspace as a function of gate timescale for values \(_{c}=0.1,0.18,0.32,0.56,1.00\) comparing (_color_) simulations and (_dashed black_) analytical predictions from exact solutions under symmetry in the flexible regime. Simulations begin from initial conditions of complete specialization and separation \(w_{m}^{p}=_{pm}\), \(c^{p}=_{p1}\) and follow a complete adaptation from teacher 1 to teacher 2 over the course of a block, reaching \(_{}<10^{-2}\) for all \(_{c}\).

As the vectors \(^{p}\) are formed from the students' singular values, they scale proportionally to the bare matrix entries \(W^{p}_{ij}\) for random initialization (Marcenko-Pastur distribution). Early in learning, the small initialization will therefore attenuate gate changes by prolonging their effective timescale \(_{c}/||^{p}||\) (or equivalently, lower their learning rate).

As we demonstrate in Fig. 4D, these effects apply to both activation and inactivation of the gates, depending on the direction of the current error \(^{}^{ m} 0\).

The regularization in the system introduces a feedback loop between \(c^{1}\) and \(c^{2}\). In practice, the system quickly reaches a regime where both gates \(c^{p}\) are positive. In this case, the regularization term using the \(L^{1}\)-norm becomes \(_{c^{p}}_{}_{p^{}}c^{p^{}}-1\), reaching a minimum along the line \(_{p^{}}c^{p^{}}=1\). In order to minimize the regularization loss, the upscaling of one gate \(c^{p}\) past \(0.5\) will result in the downscaling of the other gate \(c^{p^{}}\), and vice versa. We note that this regularization term does not favor specialization by itself since the network can also attain zero loss in the unspecified forgetful solution with, for instance, \(c^{1}=c^{2}=0.5\).

The above dynamics mean that differences in student alignment separate the gates, as described by

\[_{c}}{t}=_{1}\,_{1}- _{2}\,_{2} \]

We therefore see that the differences in gate activation are driven by the difference in specialization in the two components \(_{1}\) and \(_{2}\) and corresponding error components \(_{1}\) and \(_{2}\). Since the error components are of opposite sign following a context switch, \(}{t}\) is maximized when the students are maximally specialized.

#### 5.2.2 Flexible gates protect learned specialization

We now study the influence of \(c^{p}\) on \(}{t}^{p}\). The gates allow for a switching mechanism that does not require a change in the weights. When continuing gradient descent on all parameters, however, Eq. (1) will also entail a finite update to the wrong student.

If we Taylor-expand to second order, this update reads

\[_{w}}{t}^{p}\;\;c^{p}\;+\;((}{t}c^{p})+c^{p}(}{t}) )\,dt. \]

The first summand of the second term reflects the protection that arises from changes in gating \(}{t}c^{p}=^{p}\): a task switch to \(^{ m}=(0,1)^{}\) incurs an error \((-1,1)^{}\). For a specialized, but now incorrect student \(^{p}(1,\,0)^{}\), this term becomes \(}{t}c^{p}=^{p}<0\) for the incorrect student. Together with the decreasing error in the last term \(}{t}\), this reduces the student update from the leading-order first term \(c^{p}\). Importantly, this protection effect grows over training as the student's contribution to the error \(^{p}\) increases.

Alongside protection, flexible gates also accelerate specialization, as can be seen by considering \(\) in specialization space,

\[_{w}}{t}=( _{1}-_{2}) \]

This equation shows that the students specialize through two factors: the difference in error between the two components \(_{1}-_{2}\), and the difference in gate activation \(=c^{1}-c^{2}\).

Exact solutions to the learning dynamics describe protection and adaptation under symmetry in the flexible regime

In this section, we study exact solutions to the learning dynamics in Eq. (6) and Eq. (8) to describe the behavior of the model as it switches between tasks when it is already in the flexible regime. To solve the differential equations, we require the condition of symmetry where \(=_{1}=_{2}\). This condition is approximately true for specialized states in the flexible regime (see Fig. A.10), and its persistence follows as long as \(_{1}=-_{2}\) holds or in the limit of strong \(L^{1}\) regularization.

We use the method presented in Shi et al. (2022) to solve the resulting dynamics of the ratio between the expressions for \(}{t}\) and \(}{t}\)

\[}{_{w}}}{}=2\,(_{1}-_{2})}{( _{1}-_{2})} \]

which is a separable differential equation that can be solved up to an integration constant (see Appendix A.7.2). Plugging in initial conditions that correspond to complete specialization in the flexible regime \((0)=(0)=1\), we obtain the exact dynamics of \(\) as a function of \(\) over the course of a block,

\[=}{_{w}}(1-^{2})}. \]

This analytical solution accurately describes adaptation in the flexible regime (Fig. 4E). The relationship highlights the role of a shorter gate timescale \(_{c}\) in protecting the student's knowledge. Learning that comes from both students specializing towards the current teacher occurs outside of this specialization space and becomes more important for low \(_{c}\) (see Appendix A.7.3).

Quantifying the range of the flexible regime across block length, regularization strength, and gate speed

To assess the roles of block length, regularization, and fast gate timescale (inverse gate learning rate) in establishing the flexible regime, we run two grid searches over the gate learning rate/regularization strength and block length each task is trained on, keeping the total time trained constant (such that models trained on shorter block lengths are trained over more block switches but equal amounts of data). For each set of hyperparameters we compute the total alignment (cosine similarity) between the entire concatenated set of teachers and students as a single overall measure of specialization in the network weights at the end of learning. We identify the boundaries of the flexible regime where specialization emerges in our model, dependent on block length, gate timescale, and regularization strength (Fig. 5). A priori, the block length dependence is surprising, as one might expect additional time spent in a block to be reversed by the equally-long subsequent block. However, we show in Appendix A.6 that gating breaks this time-reversal symmetry, and specialization grows with block length \(_{B}\) for fixed overall learning time \(t\).

## 7 Inducing the flexible regime in a deep fully-connected neural network

Our NTA model uses a low-dimensional gating layer that gates computations from student networks. We sought to understand the necessity and role of this structure by considering a more general form of the model in a deep linear network with no architectural assumptions. Based on the analysis and results so far (Fig. 4D,5), we impose regularization and faster learning rates on the second layer of a 2-layer fully-connected network. Behaviorally, this network also shows the signatures of the flexible regime with adaptation accelerating with each task switch experienced (Fig. A.4A).

Figure 5: Model specialization emerges as a function of block length, gate learning rate, and regularization strength. The colorbar indicates total alignment (cosine similarity) between all sets of students and teachers considered collectively.

To quantify specialization and gating behavior, we compute the cosine similarity between each row of the first hidden layer and the teachers and use this to sort the network into two students that align to the teachers they match best. We also permute the second layer columns to match the sorting of the first layer. We then visualize the specialization of the sorted first hidden layer using the same measures as in the original NTA model. We also take the mean of each sorted student's second hidden layer to be its corresponding gate. Using this analysis, we find emergent gating in the second layer (Fig. A.4B) and specialization in the first (Fig. A.4C). Adaptation to later task switches takes place primarily in the second layer (Fig. A.4E).

By visualizing the sorted second hidden layer of the fully-connected network at the last timestep of two different task blocks, we indeed observe distinct gating behavior along the diagonal, specialized for each task (Fig. 6 for one seed). We compare this to the same fully-connected network trained without regularization which remains in the forgetful learning regime. We include visualizations of the unsorted second hidden layer for fully-connected networks arriving at both the gating and non-gating solutions (Fig. A.5 for ten seeds), as well as the sorted second hidden layer (Fig. A.6 for ten seeds) as supplement. Appendix A.4.2 discusses the potential for multiplicative gates to emerge in fully-connected architectures.

## 8 Flexible remapping of representations in nonlinear networks in two MNIST tasks

We next study whether NTA also works in larger, nonlinear systems. As a proof of concept, we investigate whether NTA can help a neural network switch between two nonlinearly-transformed versions of the MNIST dataset . The first task is the conventional MNIST task. The second is a permuted version of MNIST where the image of a digit is sorted based on its parity according to the function \(y y/2+5(y\%2)\), where \(\%\) is the modulo operation (see Fig. 7A). We

Figure 6: Task-specialized gating emerges in the second layer of a 2-layer network with faster second-layer learning rate and regularization. The sorted second layer weights at the last timestep of two different task blocks (one seed).

Figure 7: Learning flexible neural task abstractions in a nonlinear character recognition setting.**A. We formulate two tasks, the original and a permuted version of MNIST. **B.** We embed the NTA system into a larger pretrained convolutional neural network architecture. **C.** Accuracy reached on the MNIST test set as a function of time for both (_black_) the NTA network and (_gray_) the original CNN. The two tasks are presented sequentially in blocks for both (_blue shading_) MNIST and (_orange shading_) the permuted version. **D.** The activation of the two gating units as a function of time. We show mean and standard error with 10 seeds.

pre-train a convolutional neural network (CNN) on MNIST to learn useful representations, achieving about 90% accuracy on the test set. We then train an NTA system beginning from the final hidden layer representations that feeds into the same sigmoid nonlinearity (see Fig. 7B). We again induce the flexible regime using regularization and fast timescales, and contrast performance with a forgetful model (see Appendix B.7). We find that the flexible model learns to recover its original accuracy quickly after the first task switches whereas the forgetful one needs to continuously re-learn the task, as evaluated on the MNIST test set (Fig. 7C). The activity in the gating units reflects selective activity (Fig. 7D). To further test the range of NTA, we examine how much these results depend on the orthogonality of the task space by formulating two tasks based on real-world groupings of clothing in fashionMNIST  that have different amounts of shared structure. We find that rapid task switching occurs in both settings at a similar speed (Fig. A.15).

## 9 Relations to multi-task learning in humans

Our model captures several aspects of human learning. Humans update task knowledge in proportion to how well each probable task explains current experience . Analogously in our model, weight updates are gated with the corresponding gating variable, whose activity in turn reflects how well the weights behind it capture the target computation.

Humans show faster task switching with more practice on the tasks involved. In our model, we saw that the gates change faster as weights specialize to the tasks, which facilitated faster adaptation after block switches. NTA shows a qualitative fit (Fig. 8) to humans trained on alternating tasks . In contrast, a forgetful model shows a deceleration, possibly due to being far from optimal initialization  after task switches.

## 10 Conclusions and future work

This study demonstrates how task abstraction and cognitive flexibility can emerge in neural networks trained through joint gradient descent on weights and gating variables. Simple constraints on the gating variables induce gradient descent dynamics that lead to the _flexible regime_. In this regime, the weights self-organize into task-specialized modules, with gating variables facilitating rapid task switching. Analytical reductions revealed a virtuous cycle: specialized weights enable faster gating, while flexible gating protects and accelerates weight specialization. This contrasts with the _forgetful regime_ in which knowledge is continually forgotten and re-learned after task switches. The constraints necessary for reaching the flexible regime are appropriate regularization, differential learning rates, and sufficient task block length. These mirror properties of biological neurons and beneficial learning settings identified in cognitive science.

The mechanistic understanding of how task abstraction arises in neural systems might bridge artificial neural networks and biological cognition, offering a foundation for future exploration of adaptive and compositional generalization in dynamic environments. While this study focuses on simple two-layer networks, the framework is applicable to other non-linear architectures such as recurrent networks or Transformer architectures. We see future work providing additional architectures and real-world applications of the framework.

Figure 8: **Comparing performance after a task switch in humans and NTA model.****A.**Steyvers et al.  report performance of humans learning two alternating tasks (CC BY-NC-ND 4.0 license). **B.** After a block switch, loss comparison between the flexible (_left_) and the forgetful (_right_) NTA model shows opposite trends with further training on switching speed. Bars are standard error with 10 seeds.

## Author contributions

All authors contributed to manuscript writing and conceptualization of the work. AP conceptualized and implemented the experiments, and contributed to the idea, the theory, and the model simulator. JB conceptualized and developed the theory, developed the model simulator, and contributed to the idea and experiments. KS conceptualized and developed the theory, conceived of the idea and the link to cognitive flexibility, and contributed to experiments. AH directed the project, contributed to the idea and the experiments, and provided feedback on the theory.