# Improved learning rates in multi-unit uniform price auctions

Marius Potfer\({}^{*}\)\({}^{1,2}\) Dorian Baudry\({}^{3}\) Hugo Richard\({}^{1}\) Vianney Perchet\({}^{1}\)

&Cheng Wan\({}^{2}\)

\({}^{1}\) Joint team Fairplay, ENSAE, and Criteo AI LAB

\({}^{2}\) EDF R&D

\({}^{3}\) Department of Statistics, University of Oxford

marius.potfer@ensae.fr

###### Abstract

Motivated by the strategic participation of electricity producers in electricity day-ahead market, we study the problem of online learning in repeated multi-unit uniform price auctions focusing on the adversarial opposing bid setting. The main contribution of this paper is the introduction of a new modeling of the bid space. Indeed, we prove that a learning algorithm leveraging the structure of this problem achieves a regret of \((K^{4/3}T^{2/3})\) under bandit feedback, improving over the bound of \((K^{7/4}T^{3/4})\) previously obtained in the literature. This improved regret rate is tight up to logarithmic terms. Inspired by electricity reserve markets, we further introduce a different feedback model under which all winning bids are revealed. This feedback interpolates between the full-information and bandit scenarios depending on the auctions' results. We prove that, under this feedback, the algorithm that we propose achieves regret \((K^{5/2})\).

## 1 Introduction

The short-term electricity market, based on a wholesale market, is organized as an auction that determines the quantity each electricity producer needs to produce and the price at which electricity is sold. They participate, in this market by submitting prices for each kilowatt-hour they can produce. They have the opportunity to participate strategically, submitting prices that can deviate from their actual production cost. While several regulatory and practical constraints apply, this market is essentially a multi-unit auction of identical items (Willems & Yu, 2022). These auctions are extensively studied and utilized for resource allocation. Several pricing rules can be applied, the most common being discriminatory pricing, uniform pricing (Ausubel et al., 2014), and Vickrey-Clarke-Groves (VCG) auctions (Sessa et al., 2017). Although the VCG auction is known for its truthful bidding property, it is seldom implemented due to its complexity. Instead, uniform or discriminatory pricing are often preferred, particularly in treasury auctions (Khezr & Cumpston, 2022) and their procurement variations in electricity reserve markets (Viehmann et al., 2021).

The wholesale electricity market is held every day and, structurally, the electricity producers who participate in the mechanism remain the same for multiple years. This represents an opportunity to study how producers can be strategic in the way they adapt to other's bidding strategies. We therefore focus on the problem of online bidding in a repeated multi-unit auction. This setting allows us to model how an agent participating multiple times to an auction with the same other participants can leverage the information he has obtained during past auctions. This family of settings, of which a review is available in (Nedelec et al., 2022), was first investigated for learning from the point of view of the auctioneer and was then applied to bidders learning how to bid optimally.

Online learning in multi-unit auctions with uniform pricing (every object is sold at the same price independently of the winner) is studied in (Branzei et al., 2024) while the case of discriminatory pricing is studied in Galgana and Golrezaei, 2023. When the bids of all bidders are revealed after each auction (full-information), known regret rates for uniform and discriminatory pricing are of the same order \(()\)(Branzei et al., 2024; Galgana & Golrezaei, 2023) where \(T\) is the time horizon. When bidders only observe the number of items they win and the price (bandit feedback) the regret upper bounds given in Galgana and Golrezaei, 2023 and Branzei et al., 2024 are of order \(}(T^{2/3})\) (for discriminatory pricing) and \(}(T^{3/4})\) (for uniform pricing) suggesting that bidding multi-unit auctions with uniform pricing is strictly harder than with discriminatory pricing. Our study shows that this is not the case as we present an algorithm achieving regret \(}(T^{2/3})\) with uniform pricing therefore closing the gap between the two settings.

Auction rulesA decision-maker (i.e., _the bidder_) repeatedly bids in a uniform pricing \(K\)-unit auction. The single-shot version of the auction, from the perspective of any participant \(i\) whose value of obtaining a \(^{}\)-item is denoted by \(v_{i,k}\), proceeds as follows.

1. Each participant submits a bid profile \((b_{i,k})_{k[K]} B\), where \[B=\{(b_{k})_{k[K]},1 b_{1} b_{2} b _{K} 0\}.\] We call \(B\) the action space and we denote by \(_{-i}\) the bids from other participants.
2. The price per item \(p(_{i},_{-i})\) is set either as * the \(K^{}\) highest bid (Last Accepted Bid (LAB) pricing rule), * the \((K+1)^{}\) highest bid (First Rejected Bid (FRB) pricing rule).
3. The participant receives the items they won and pays \(p(_{i},_{-i})\) for each item. Since items are identical, we call allocation \(x_{i}[K]:=\{1,2,...,K\}\) the number of items participant \(i\) receives, formally defined as follows: \[x_{i}(_{i},_{-i}):=|\{k[K] b_{i,k} p(_{i},_{-i})\}|\\ |\{k[K]b_{i,k}>p(_{i},_{-i})\}| .\] (1)

The focus is to design efficient learning algorithms for the decision-maker, i.e., one specific participant \(i\); we can therefore aggregate bids from other participants as the bid of a single _adversary_\(:=_{-i}\) and omit the index \(i\) of the learner denoting \(:=_{i}\). This setup gives rise to the quasi-linear utility \(u(,)=_{l=1}^{x(,)}[v_{l}-p( ,)]\).

In the remainder of this paper, we adopt the LAB pricing rule. The techniques and theoretical proofs can be adapted from one setup to the other with little change. In the absence of specific mention of a pricing rule, our results can be applied to both auction types..

Repeated settingAs mentioned above, this auction is not played just once, but repeated many times (say, each day). We shall then denote a time horizon \(T\), and assume a different auction is run at each time step \(t[T]\) and the objective of the bidder is to maximize their cumulative utility. Quite naturally, the bidder should adjust their bids to the adversary's behavior, learned from the outcomes of the previous iterations. On the other hand, we assume that the bidder does not need to learn their own values, i.e., the valuations \((v_{k})_{k[K]}\) are known to the bidder and do not change over time.

We denote by \((^{t})_{t[T]}\) and \((^{t})_{t[T]}\) respectively the sequences of bids of the player and of the adversary, and by \(p^{t}:=p(^{t},^{t})\) and \(x^{t}:=x(^{t},^{t})\) the price and allocation at time \(t\). The utility of the bidder after the auction \(t[T]\) is then defined as \(u(^{t},^{t})=_{l=1}^{x^{t}}(v_{l}-p^{t})\). As standard in online learning, we evaluate the performance of a learning (bidding) strategy through its _regret_, defined as follows

\[R_{T}=_{ B}_{t=1}^{T}u(,^{t})-[_{t=1}^{T}u(^{t},^{t})]\,\] (2)

where the expectation is taken over the randomness of the algorithm generating the bids \(^{t}\). Maximizing the utility of the bidder is equivalent to minimizing the regret.

FeedbackThe bidders can improve their strategy using the information they receive after each iteration of the auction. The type of _feedback_ they receive represents their knowledge about the bids of the adversary. In the literature, two common types of feedback are considered (Cesa-Bianchi et al., 2023),

1. the _bandit_ feedback where the bidder's allocation \(x_{t}\) is revealed and the price \(p_{t}\) is only revealed if \(x_{t}>0\), and
2. the _full information_ feedback where all the bids emitted by all participants are revealed.

Inspired by the terms of commodity electricity markets in several European countries _including Germany and France_, similarly to Karaca et al., 2020, we shall introduce and study a third partial feedback specific to multi-unit auctions,

1. the _all-winner feedback_: the allocation, the price, and all the winning bids are revealed to the bidder.

**Remark 1**.: _With a uniform discretization of the bidding space \(B\), learning to bid in multi-unit uniform auctions can be recast as a special instance of a combinatorial bandit problem. In the latter, the decision maker sequentially selects multiple arms out of \(N\) available, i.e., picking at each stage an action in some admissible subset of \(\{0,1\}^{N}\). Using off-the-shelf combinatorial bandit algorithms, that do not leverage the relevant structure of repeated auctions, would end up in a highly inefficient and sub-optimal procedure (see Section 2). Our approach is different; in essence, we reduce the complex combinatorial problem by expressing the utility objective as a polynomial (in \(K\) and \(T\)) sum of simpler functions._

Related WorkMultiple-unit auctions of indivisible identical items have been extensively studied in their static settings. In particular, how the pricing rules (discriminatory, uniform, VCG) influence revenue (Ausubel et al., 2014), social welfare (Birmpas et al., 2019; De Keijzer et al., 2013), or price stability (Anderson and Holmberg, 2018). Their use in the context of electricity markets is common and similar questions are being studied with this specific application in mind (Akbari-Dibavar et al., 2020; Cramton and Stoft, 2006; Fabra et al., 2006; Son et al., 2004)

The repeated setting of auctions, and specifically the use of online learning procedure inspired by Multi Armed Bandits has received lots of attention in the last decade. First studied from the point of view of the auctioneer: Blum et al., 2004 studied maximizing auction revenue, Cesa-Bianchi et al., 2014 and Kanoria and Nazerzadeh, 2014 specifically focused on learning reserve prices. Learning to bid, the bidder's problem, was considered later on, initially in single-item auctions. Second price auctions facing either adversarial or stochastic highest opposing bids were studied in Weed et al., 2016, and in a contextual, budget-constrained setting by Flajolet and Jaillet, 2017. Balseiro et al., 2019 considered the first price auction with adversarial opposing bids leading to optimal regret rates of \(}(T^{2/3})\) in the known valuation and contextual setting.

First mentioned in Feng et al., 2018 for unit demand, multiple unit auctions as online learning problems only recently started to be considered as their own topic of interest. Discriminatory pricing and uniform pricing respectively studied in Galgana and Golrezaei, 2023 and Branzei et al., 2024 can be learned with \(}()\) in the full-information setting. Under bandit feedback, the former achieves \(}(KT^{2/3})\) regret rates in discriminatory pricing and the latter \(}(K^{7/4}T^{3/4})\) regret rates with uniform pricing. Compared to single unit auctions, the combinatorial nature of the action space in \(K\)-unit auctions makes it a harder learning problem. Branzei et al., 2024 makes use of a cautiously designed equivalent action space represented as a Directed Acyclic Graph (DAG) to address the combinatorial limitation and to design an algorithm guaranteeing the aforementioned regret bounds.

The effects of specific feedback on the ability to achieve lower regret rates have also raised some interest. Feng et al., 2018 studied the effects of "Win Only" feedback in a more general auction setting. More recently, Cesa-Bianchi et al., 2023 focused on feedback transparency. They characterize gaps in the regret rates that can be achieved depending on the amount of feedback received, getting three separate rates \(O()\), \(O(T^{2/3})\) and \((T)\) depending on the feedback considered. The work of Karaca et al., 2020, similarly to the all-winner feedback, studied partial feedback, which lie in between bandit and full-information, motivated by electricity market auctions.

ContributionWe introduce a novel representation of the action space that overcomes the combinatorial complexity introduced by the multiplicity of the bids in \(K\)-unit auction. Inspired by the properties of the equivalent action space used by Branzei et al., 2024, we introduce bid-gaps, to further decompose the utility into a sum of independent functions. This decomposition leads to improved regret rates of \(}(K^{4/3}T^{2/3})\) under bandit feedback, compared to the known upper bound of \(}(K^{7/4}T^{3/4})\). These improved bounds match, in terms of \(T\), the rates \(}(KT^{2/3})\) achievable in discriminatory pricing. We notice a reduction to simpler auctions which bear an \((T^{2/3})\) lower bound on the regret, answering the open question of the optimal rates dependency in \(T\) in the bandit setting. Motivated by the terms of bid revelation in electricity reserve markets in several European countries _including Germany and France_, a novel feedback structure is considered, which lies in between bandit feedback and full information. This feedback, which we call all-winner, reveals all the winning bids of the action. We propose an algorithm that achieves a \(}(K^{5/2})\) regret, almost matching the regret rates under full information up to a factor \(K\), while the lower bound of \((K)\) proved by Branzei et al., 2024 for the full-information feedback, naturally extend to this setting. We summarize our results in Table 1 below.

## 2 Action space

We first motivate the new cautiously designed action space, and provide intuitions on how it is constructed and its main properties. We then formalize its definition.

Motivation for an alternative representationUsual techniques such as uniform discretization of the action space as in (Feng et al., 2018) might lead to consider the subset of non-increasing sequences on this discretization, denoted by \(B_{}0,,2,...,(-1),}^{K}\). Without loss of generality, we shall assume in the following that \(1/\) is an integer. The main downside of this representation is that the size of \(B_{}\) is exponential and thus, without any further properties of the problem leveraged, this would lead to arbitrarily bad regret rates \(}(T^{})\) in bandit setting. Even though we can restrict the available action to _reasonable ones_ (ie undominated strategies 6) this isn't enough to achieve improved rates in general.

Branzei et al., 2024 proposed a Directed Acyclic Graph (DAG) equivalent of the action space \(B_{}\) to overcome this combinatorial limitation. They use the decomposition of the utility into a sum of independent functions, depending only on pairs of consecutive bids (the edges in their graphs), to reduce the combinatorial complexity to only 2 (instead of \(K\)), and thus achieved an \((K^{7/4}T^{3/4})\) regret bound under bandit feedback. Motivated by the breakthrough enabled by such a representation of the action space, we consider a new equivalent action space \(H_{}\), introduced in Equation 5. This new action space allows to leverage more precisely the regularity of the utility with respect to the bidder's choice of bids, which in turn leads to improved regret bounds under bandit feedback, presented in Theorem 1.

### Action space tailored to the outcomes

We now provide intuitions on the utility regularity that will be leveraged. We start by observing that, for a given auction, the price is either set by one of the bidder's bid or by a bid from the adversary.

Assume that the bidder bids \((b_{1},...,b_{K}) B_{}\), and that the price is \(b_{k}\) for some \(k[K]\). Then, we claim that many bid profiles would have led to the same outcome. Indeed, any bid profile (from the bidder) with the same \(k^{}\) bid \(b_{k}\), leads to the same outcome. In the alternative case, where the adversary sets the price, if the bidder wins \(k\) items (i.e., the \(K-k\) adversary's bid \(^{t}_{K-k}\) sets the price), then any bid profile satisfying \(b_{k}^{t}_{K-k} b_{k+1}\) leads to the same outcome.

   Feedback & Literature & This work & Lower bound \\  Full information & \(}(K^{3/2})\) & \(}(K^{3/2})\) & \((K)\) \\ All winner & & \(}(K^{5/2})\) & \((K)\) \\ Bandit & \(}(K^{7/4}T^{3/4})\) & \(}(K^{4/3}T^{2/3})\) & \((T^{2/3})^{*}\) \\   

Table 1: Regret Rates in multi-unit uniform price auction. \({}^{*}\) holds in the LAB pricing rule setting Notice that in the two aforementioned cases of regularities of the utility, all bids \( B_{}\) which would lead to the same outcome share one of the following properties: for a specific \(k\) and \(j\),

* in the first case : \(b_{k}=j\),
* in the second case : \(b_{k}(j+1)_{K-k}^{t} j b_{k+1}\).

For simplicity, we shall assume that the bids of the decision-maker belong to the \(\)-discretization, i.e., \((b_{1},...,b_{K}) B_{}\) while the bids of the adversary do not belong to it, in order to avoid ties2. We denote this set \(B_{}\), the set of non-increasing sequences of \(^{K}\) without values in \([]\).

We, introduce an alternative description of the bidding space \(B_{}\) whose structure closely matches the aforementioned regularities' in order to improve the bidder's strategy. It leverages new binary variables indicating which of the aforementioned properties a bid \( B_{}\) has, they are defined as follows: for any \(k[K]\) and \(j[]\),

\[h_{k,j}() =\{b_{k}=j\}\] (3) \[h_{k+,j}() =\{b_{k}(j+1)>j b_{k+1} \}.\] (4)

Let \(=\{1,,2,...,K-1,,K\}\) and \(_{}=[]\). For any \( B_{}\), we define the pseudo-bid \(}\) to be the list of these binary variable \(h_{k,j}\) with \(k,j\), such that \(h_{k,j}()=1\), ordered in lexicographic order, increasingly in \(k\) and decreasingly in \(j\). We naturally define \(H_{}\) the pseudo-bid space generated by the bid space \(B_{}\) :

\[H_{}=\{}| B_{}\}\] (5)

**Lemma 1**.: _For each pseudo-bid \( H_{}\), there exists a unique \( B_{}\) such that \(=}\). This therefore defines a bijective mapping between \(H_{}\) and \(B_{}\)._

Proof.: From the expression of \(H_{}\) in (5), it is clear that the mapping \(}\), is surjective.

Let \( H_{}\), there exists \(=\{b_{1},...,b_{K}\} B_{}\) such that \(=}\). Let \(j_{k}_{}\) such that \(b_{k}=j_{k}\), for all \(k[K]\), we have \(h_{k,j_{k}}\). If there exists another bid \(}=\{_{1},...,_{K}\} B_{}\) such that \(=}}\), for all \(k[K],h_{k,j_{k}}(})=1\).Therefore (3) yields \(_{k}=j_{k}=b_{k}\) for all \(k[K]\). This proves unicity and therefore that the mapping is bijective. 

The following characterization of the pseudo-bid space directly follows from Lemma 1.

**Corollary 1**.: _Given a bid \(=(b_{i})_{i[K]} B_{}\) and the pseudo-bid \(} H_{}\), we have the following: for all \(k,j[K]_{}\),_

\[b_{k} =j h_{k,j}}\] (6) \[b_{k} (j+1)>j b_{k+1} h_{k+,j} }\] (7)

To provide further intuition, Figure 0(a) and Figure 0(b) show how two corresponding bids might be represented in \(B_{}\) and \(H_{}\). The bids (6) are represented by circles, while the bid-gaps (7) are ellipses.

### Utility decomposition

Leveraging the new action space, we define the utility, price, and allocation function on \(H_{}\) resulting from the bijective map with \(B_{}\). Let \( H_{}\) and \( B_{}\) the unique element of \(B_{}\) such that \(=}\). For all \( B_{}\), we define the utility as \(u_{H}(},):=u(,)\), the price \(x_{H}(},):=x(,)\) and the allocation \(p_{H}(},):=p(,)\)

The following additional set notation, which matches a binary variable \(h_{k,j}\) to its corresponding price range, allows for unified descriptions :

\[_{}(h_{k,j}):=\{j\}&\\ (j,(j+1))&,\] (8)

We now explicitly show how the pseudo-bid space is _well suited_ to capture the regularity of the outcomes of the auction (and therefore of the utility) mentioned above. To be more precise, the following Lemma 2 states that within a pseudo-bid profile \(\), a pseudo-bid \(h_{k,j}\) can be _credited_ for the outcome: any other pseudo-bid profile containing this pseudo bid would have lead to the same outcome.

**Lemma 2**.: _Let \( B_{}\) and \((k,j)_{}\). There exists \(C\{0,1\}\), such that for all \( H_{}\) with \(h_{k,j}\),_

\[\{p_{H}(,)_{}(h_{k,j})\} \{x_{H}(,)= k\}=C\] (9)

_and if \(C=1\), \(p_{H}(,)\) is also constant on \(\{ H_{}:h_{k,j}\}\)_

Proof.: Let \( B_{}\) such that \(h_{k,j}}\). If \(k\) is integer, then Corollary 1 yields \(b_{k}=j\), hence we get \(\{p_{H}(,)=j\}\{x_{H}(, )=k\}=\{_{K-k}>j=b_{k}>_{K-k+1}\}\) which only depends on \(k,j\) and \(\). If \(k\) is half-integer, then Corollary 1 yields \(b_{k+1}<j<(j+1)<b_{k}\), hence we get \(\{p_{H}(,)=_{}(h_{k,j})\} \{x_{H}(,)=k\}=\{j<_{K-k}<(j+1)\}\) which also only depends on \(k,j\) and \(\). It is straightforward to see that when the indicator function takes value one, the price is constant with value \(j\) for the integer case and \(_{K-k}\) in the half integer case. 

Lemma 2 allows us to exhibit a key property of the utility on the pseudo-bid space: it can be decomposed into a sum of sub-utilities (defined in Equation 11), each of which only depends on one of the components of \(\).

**Lemma 3**.: _Let \( H_{}\) and \( B_{}\). The utility of the bidder rewrites as a sum of sub-utilities:_

\[u_{H}(,)=_{h_{k,j}}w(h_{k,j},),\] (10)

\[w(h_{k,j},):=\{\{p_{H}(,) _{}(h_{k,j})\}\{x_{H}(,)= k \}\}_{l=1}^{ k}(v_{l}-p_{H}(,)).\] (11)

Proof of Lemma 3.: \(x(,)=0\) implies that \(u\) as defined in Equation (10) is zero, as expected. For the case where \(x(,)>0\), we use that the indicator functions in Equation 11 correspond to disjoint events. Thus, there exists a unique pair \((k,j)_{}\) such that \(w(h_{k,j},)>0\), furthermore, this sub-utility \(w(h_{k,j},)\) matches the utility \(u(,)\). This concludes the proof. 

While the expression of these indicators in Equation (11) involves the full action \(\), Lemma 2 shows that they only depend either on the associated bid \(h_{k,j}\). Furthermore, notice that within a given \( H_{}\), the events corresponding to each \(h_{k,j}\) are disjoints and therefore only one can be realized. As a result there is at most one \(h\) with positive sub-utility, we denote it \(h_{}(,)\).

Figure 1: Graph representation of action spaces \(B_{}\)(Branzei et al., 2024) and \(B(_{})\) (this paper)

[MISSING_PAGE_FAIL:7]

The combination of Algorithm 1 and Algorithm 2 leads to the following probabilities, typical of an exponential weight algorithm, on \(H_{}\). For \( H_{}\),

\[^{}()=^{t} u_{H}^{n}( ))}{_{ H_{}}(_{n=0}^{t}  u_{H}^{n}())}\] (17)

as shown in Appendix B, in Equation 29.

EstimatorsWith partial feedback (either bandits or all-winner), the bidder does not gather enough information to compute all of the sub-utilities, and it can only do it for a subset of pseudo-bids.They must therefore resort, as it is standard in multi-armed bandit literature, to estimators that should leverage all the information available. Under bandit feedback, only sub-utilities of binary variables which belong to the action played at time \(t\) can be computed.- On the other hand, under all-winner feedback, the richer feedback allows to compute sub-utilities for a bigger set of binary variables \(h\), we denote it \(A\) and define it in Lemma 4.

**Lemma 4**.: _With the all-winner feedback, the bidder can compute from its feedback the sub-utilities of any pseudo bid in \(A(^{t},^{t})\), defined as:_

\[A(^{t},^{t}):=\{h_{k,j},(k,j) _{}\{k>x^{t}\}\{k=x^{t}j p^{t}\}\}\] (18)

_Where \(x^{t}:=x_{H}(^{t},^{t})\) and \(p^{t}=p_{H}(^{t},^{t})\)._

The formal proof of Lemma 4 is in Appendix C.

As noted above, within a given pseudo-bid \(\), only one sub-utility can be non-zero. We therefore also define the set of binary variables with non-zero sub-utilities \(A_{}(^{t},^{t}):=\{h_{k,j} A(^{ t},^{t})|w(h_{k,j},^{t})>0\}\).

We can now formally introduce the estimators used by the no-regret procedure.

**Definition 3.1** (Estimators).: _Let \(^{t} H_{}\) be the action played by the learner, and \(^{t} B_{}\) the bids of the adversary at time \(t\),. For any bid or bid-gap \(h\), we define the sub-utility estimators:_

\[^{t}(h)=(h=h_{}^{t}) (h)-K}{^{t}(h)},\] (19)

\[^{t}(h)=(h A_{}^{t}( ^{t}))(h)-K}{^{t} B^{t}}{ }(h A_{}^{t}(^{t}))}\] (20)_where \(h_{*}^{t}:=h_{*}(^{t},^{t})\) is the sub/pseudo-bid played at time \(t\) that has non-zero sub-utility, \(^{t}\) is the probability distribution on \(H_{}\) as in (17) and \(^{t}(h):=_{ H_{}:h}^ {t}()\)_

Naturally, estimation of the utility of any action \( H_{}\) is done with a simple summation, over \(h\), of these estimates.

### Regret Analysis

Combining Algorithm 1 and the sampling Algorithm 2, we recover the regret guarantees obtained by (Branzei et al., 2024, Theorem 2) in the same setting for the full-information feedback. We provide a formal statement and proof of this result in the Appendix B, in Theorem 3. We now analyze the performance of the learning procedure for the two other types of feedback.

**Theorem 1**.: _In the repeated \(K\)-unit auction with uniform pricing guarantees and under bandit feedback, Algorithm 1 incurs a regret of at most \((K^{4/3}T^{2/3}(T))\) For any time horizon \(T\), with the choices of \(=()^{1/3}\) and \(=K^{-1/3}T^{-2/3})/3}\)._

Proof sketch.: The aforementioned regret bounds are proved by using a similar analysis as the one in Lattimore and Szepesvari, 2020 to obtain regret bounds of EXP3 algorithm in the adversarial bandits case. We apply this analysis to the discretized action space \(H_{}\) and bound the additional cost of using a discretization separately. Then we choose a discretization size \(\) to minimize the total regret.

The improvement over known regret bounds in Branzei et al., 2024 results from the decomposition of the utility into sub-utilities. Since these sub-utilities only depend on one bid or bid-gap, the _variance_ of the estimators (cf Lemma 9) only depend on the possible number of bids or bid-gaps ( of order \(\)) not the number of bid profiles ( of order \(}\)). This is akin to why combinatorial bandits under semi-bandit feedback (Audibert et al., 2014) achieve better regret than under bandit-feedback. 

**Theorem 2**.: _For any time horizon \(T\), using Algorithm 1 in the repeated \(K\)-unit auction with uniform pricing guarantees, under all-winner feedback, a regret of at most \((K^{5/2}(T))\) with \(=K^{-1}T^{-1/2}\) and \(=K^{3/2}T^{1/2}\)._

Proof sketch.: The proof of these bounds in the all-winner feedback follows closely the analysis used for the bandit feedback. Better bounds are achieved in comparison to the bandit's feedback thanks to the lower _variance_ of the estimator defined in (10), proved in Lemma 10. Intuitively, this comes from the ability to observe the realized utility more often, allowed by the richer feedback. We exhibit this by using tools used in bandits with graph feedback (Alon et al., 2017). 

Regret lower boundWe provide a matching lower bound on the regret of any online learning algorithm (Lemma 5), in the bandit feedback setting, by extending a result from (Balseiro et al., 2019) in the context of single price auctions. This partially answers an open question raised by Branzei et al., 2024 regarding the achievable learning rate in the bandit setting for the problem that we consider.

**Lemma 5**.: _Any online learning procedure must incur \((T^{2/3})\) regret in multi-unit uniform auction with the Last Accepted Bid rule under bandit feedback Bid pricing rule._

This stems from the fact that against an adversary that only plays bids with value 1 except for its last bid, the auction is essentially a first-price auction.

Proof.: We extend the lower bound on the regret of the first price auction in Balseiro et al., 2019. At time \(t\), let \(^{t}=\{1,1,...,1,h^{t}\}\) be the bid of the adversary, let the valuation of the learner be \(v=(1,0,..,0)\) and denote \(^{t}=(b_{1}^{t},...,b_{k}^{t}) B\) the learner's bid. We only consider sensible bids, such that \(b_{i}^{t}>0 i=1\), because they are dominating strategies. The learner's utility is \(u(,)=\{b_{1}^{t}>h^{t}\}(1-b_{1}^{t})\), and the bandits feedback, (\(x^{t},\{x^{t}>0\}p^{t}\)) is : \((\{b_{1}^{t}>h^{t}\},\{b_{1}^{t}>h^{t} \}b_{1}^{t})\) which coincides with both the utility and the bandits feedback of the first price auction with value 1.

This specific instance of the repeated \(K\)-unit auction therefore coincides with the repeated first price auction with opposing bid \(h^{t}\) at time \(t\), which can be any instance of the first price auction. Thereforeif no learning algorithm can guarantee better regret than \((T^{2/3})\) in the latter problem, no algorithm can guarantee better regret than \((T^{2/3})\) in the former.

## 4 Conclusion

We provided the first no-regret algorithm achieving optimal rates in \(T\) for the \(K\)-unit uniform auction under bandit, full information, and all winner feedback. The techniques and theoretical tools presented can be applied to obtain similar regret guarantees in the adversarial bid setting with random valuation, under the assumption that the valuation and opposing bids are independent. An interesting open question is whether similar rates can be achieved in a contextual setting (when valuations changing at each round are observed before each play). The obtained regret rates match the ones obtained in the discriminatory price auction, a commonly compared auction mechanism, up to a factor \((K^{})\). This raises the question of whether this gap can be closed or if a lower bound showing a separation in achievable regret rates exists.