# Functional Gradient Flows for Constrained Sampling

Shiyue Zhang

School of Mathematical Sciences

Peking University

zhangshiyue@stu.pku.edu.cn &Longlin Yu

School of Mathematical Sciences

Peking University

llyu@pku.edu.cn &Ziheng Cheng

Department of Industrial Engineering and Operations Research

University of California, Berkeley

ziheng_cheng@berkeley.edu &Cheng Zhang

School of Mathematical Sciences and Center for Statistical Science

Peking University

chengzhang@math.pku.edu.cn

Equal contribution.Corresponding author.

###### Abstract

Recently, through a unified gradient flow perspective of Markov chain Monte Carlo (MCMC) and variational inference (VI), particle-based variational inference methods (ParVIs) have been proposed that tend to combine the best of both worlds. While typical ParVIs such as Stein Variational Gradient Descent (SVGD) approximate the gradient flow within a reproducing kernel Hilbert space (RKHS), many attempts have been made recently to replace RKHS with more expressive function spaces, such as neural networks. While successful, these methods are mainly designed for sampling from unconstrained domains. In this paper, we offer a general solution to constrained sampling by introducing a boundary condition for the gradient flow which would confine the particles within the specific domain. This allows us to propose a new functional gradient ParVI method for constrained sampling, called _constrained functional gradient flow_ (CFG), with provable continuous-time convergence in total variation (TV). We also present novel numerical strategies to handle the boundary integral term arising from the domain constraints. Our theory and experiments demonstrate the effectiveness of the proposed framework.

## 1 Introduction

Efficiently approximating and sampling from unnormalized distributions is a fundamental and challenging task in probabilistic machine learning, especially in Bayesian inference. Various methods, including Markov Chain Monte Carlo (MCMC) and Variational Inference (VI), have been developed to address the intractability of the target distribution. In VI, the inference problem is reformulated as an optimization task that aims to find an approximation within a specific distribution family that minimizes the Kullback-Leibler (KL) divergence to the posterior (Jordan et al., 1999; Wainwright and Jordan, 2008; Blei et al., 2016). Leveraging efficient optimization algorithms, VI is often fast during training and more scalable to large datasets. However, its approximation power may be limited depending on the chosen family of variational distributions. In contrast, MCMC methods generatesamples from the posterior through a Markov chain that satisfies the detailed balance condition (Duane et al., 1987; Robert and Stramer, 2002; Neal, 2011; Welling and Teh, 2011; Chen et al., 2014). While MCMC is asymptotically unbiased, it may be slow to converge, and assessing convergence can be challenging.

Recently, there has been a growing interest in the gradient flow formulation of both MCMC and VI, leading to the development of particle based variational inference methods (ParVIs) that tend to combine the best of both worlds (Liu and Wang, 2016; Chen et al., 2018; Liu et al., 2019; di Langosco et al., 2021; Fan et al., 2022; Alvarez-Melis et al., 2022). From the variational perspective, ParVIs take a non-parametric approach where the approximating distribution is represented as a set of particles. These particles are iteratively updated towards the steepest direction to reduce the KL divergence to the posterior, following the gradient flow in the space of distributions with certain geometries. This non-parametric nature of ParVIs significantly enhances its flexibility compared to classical parametric VIs, and the interaction between particles also makes ParVIs more particle-efficient than MCMCs.

One prominent particle-based variational inference technique is Stein Variational Gradient Descent (SVGD) (Liu and Wang, 2016). It calculates the update directions for particles by approximating the gradient flows of the Kullback-Leibler (KL) divergence within a reproducing kernel Hilbert space (RKHS), where the approximation takes a tractable form (Liu, 2017; Chewi et al., 2020). However, the performance of SVGD heavily depends on the choice of the kernel function and the quadratic computational complexity of the kernel matrix also makes it impractical to use a large number of particles. As kernel methods are known to have limited expressive power, many attempts have been made recently to expand the function class for gradient flow approximation (Hu et al., 2018; Grathwohl et al., 2020; di Langosco et al., 2021; Dong et al., 2023; Cheng et al., 2023). By embracing a more expressive set of functions, such as neural networks, these functional gradient approaches have shown improved performance over vanilla SVGD while not requiring expensive kernel computation.

While MCMC and VI methods have shown great success in sampling from unconstrained domains, they often struggle when dealing with target distributions supported on constrained domains. Sampling from constrained domains is an important and challenging problem that appears in various fields, such as topic modeling (Blei et al., 2003), computational statistics and biology (Morris, 2002; Lewis et al., 2012; Thiele et al., 2013). Recently, several attempts have been made to extend classical sampling methods like Hamiltonian Monte Carlo (HMC) or SVGD to constrained domains (Brubaker et al., 2012; Byrne and Girolami, 2013; Liu and Zhu, 2018; Shi et al., 2022). However, these extensions either involve computationally expensive numerical subroutines such as solving nonlinear systems of equations, or rely on intricate implicit and symplectic schemes or mirror maps that require a case-by-case design effort tailored to specific constraint domains.

In this paper, we propose a functional gradient ParVI method for sampling from probability distributions subject to constrained domains with general shapes. We demonstrate that functional gradient approaches for ParVIs can be seamlessly adapted to constrained domains by learning the gradient flows with a vector field that adheres to a boundary condition. Intuitively, this boundary condition would confine particles within the specified domain, and it is indeed a sufficient condition for gradient flows of probability measures confined to this domain. Following previous works (di Langosco et al., 2021; Dong et al., 2023; Cheng et al., 2023), we employ the regularized Stein discrepancy objective for functional gradient estimation where we directly incorporate the boundary condition for the vector field into the design of its neural network approximation. Due to the domain constraints, integration by parts now would lead to an additional boundary integral term in the training objective. We, therefore, derived an effective approach for properly evaluating this term for general boundaries. Extensive numerical experiments across different constrained machine learning problems are conducted to demonstrate the effectiveness and efficiency of our method.

## 2 Related Work

To better capture the gradient flow, a number of functional gradient methods for ParVIs have been proposed recently that employ a larger and more expressive class of functions than reproducing kernel Hilbert spaces (RKHS). In particular, di Langosco et al. (2021) used neural networks to learn the Stein Discrepancy with an \(L_{2}\) regularization term, and updated the particles based on the learned witness functions. Dong et al. (2023) and Cheng et al. (2023) provided extensions that accommodates a broader class of regularizers.

Sampling from constrained domains is generally more challenging compared to the unconstrained ones. Brubaker et al. (2012) proposed a constrained version of HMC for sampling on implicit manifolds by applying Lagrangian mechanics to Hamiltonian dynamics, which requires solving a nonlinear system of equations for each numerical integration step. Lan et al. (2014) focused on constraints that can be transformed into hyper-spheres, which can be viewed a special case of Brubaker et al. (2012) that has close-form update formulas. Zhang et al. (2020); Ahn and Chewi (2021); Shi et al. (2022) extended Langevin algorithms and SVGD to constrained domains via mirror maps. However, these methods require explicit forms of transformations (e.g., spherical augmentation and mirror maps) that capture the constraints, which would limit their applications to simple domains. Bubeck et al. (2018); Brosse et al. (2017); Salim and Richtarik (2020) considered projected Langevin algorithms through projection oracle, which is of high computational cost for complex constrained domains. Zhang et al. (2022) proposed an orthogonal-space gradient flow approach for sampling in manifold domains with equality constraints, which employed a similar strategy to ours. Our method is different from theirs in that it is designed for domains with inequality constraints using ParVIs with neural network gradient flow approximations, and we also proposed novel numerical strategies to address boundary-related challenges.

## 3 Background

NotationsWe use \(x\) to denote particles in \(^{d}\) and \(=\{x|g(x) 0\}\) to denote the constrained domain. Notation \(_{}\) is the indicator function of \(\). Let \(\|\|\) denote the standard Euclidean norm of a vector. Let \((^{d})\) denote the set of probability distributions on \(^{d}\) that are absolute continuous with respect to the Lebesgue measure, and we do not distinguish the probability measure with its density function. Let \(D_{}\) be the Kullback-Leibler divergence and TV be the total variation distance. We use \((,)\) to denote the space of continuous mappings from \(\) to \(\), and use the shorthand \(()\) for \((,)\).

### Particle-based Variational Inference

Let \(p^{*}(^{d})\) be the target distribution we wish to sample from. We can frame the problem of sampling into a KL divergence minimization problem

\[:=_{p}D_{}(p\|p^{*}),\] (1)

where \((^{d})\) is the space of probability measures. Particle-based variational inference methods (ParVIs) can be described within this framework where \(Q\) is represented as a set of particles. Starting from an initial distribution \(p_{0}\) and an initial particle \(x_{0} p_{0}\), we update the particle \(x_{t}\) following \(dx_{t}=v_{t}(x_{t})dt\) where \(v_{t}:^{d}^{d}\) is the velocity field at time \(t\). The density \(p_{t}\) of \(x_{t}\) follows the continuity equation \(dp_{t}/dt=-(v_{t}p_{t})\), and the KL divergence decreases with the following rate:

\[D_{}(p_{t}\|p^{*})=-_{p_{t}} }{p_{t}},v_{t}.\] (2)

ParVIs aim to find the optimal velocity field \(v_{t}\) that minimizes (2) in a Hilbert space \(\) with the squared norm regularizer as follows

\[_{v_{t}}-_{p_{t}}}{p_ {t}},v_{t}+\|v_{t}\|_{}^{2}.\] (3)

### Functional Wasserstein Gradient

Different choices of the space \(\) in (3) lead to different gradient flow algorithms. SVGD Liu and Wang (2016) chooses \(\) to be a Reproducing Kernel Hilbert Space with kernel \(k(,)\). This way, the optimal velocity field has a close form solution

\[v_{t}^{*}()=_{p_{t}}[k(,x) p^{*}(x)+_{x}k (,x)],\] (4)

albeit the design of kernels can be restrictive for the flexibility of the method.

When \(=^{2}(p_{t})\), then \(v_{t}^{*}=}{p_{t}}\) is also known as the Wasserstein gradient of KL divergence (Jordan et al., 1998). Since the score function of particle distribution \( p_{t}\) is generally inaccessible,recent works propose to parameterize \(v_{t}\) as a neural network and train it through (3) di Langosco et al. (2021); Dong et al. (2023); Cheng et al. (2023). Due to Stein's identity, (3) has a tractable form

\[v_{t}^{*}=_{v}_{p_{t}}[-  p^{*},v- v+\|v\|^{2}],\] (5)

where \(\) is the neural network family. This method is called functional Wasserstein gradient in contrast to the kernelized version.

## 4 Main Method

Consider sampling from a target distribution \(p^{*}(x)\) supported on \(=\{g(x) 0\}\), where \(g:^{d}\) is a continuously differentiable function. Throughout the work, we assume that \(p^{*}\) admits differentiable positive density function on \(\).

We first reformulate the problem into a constrained optimization in the space of probability measures:

\[_{p(^{d})}D_{}(p\|p^{*}),\ \ \ \ \ \ p()=1.\] (6)

However, note that \(p^{*}\) is only supported on \(\), the problem is ill-posed if \(p()<1\), since in this case \(p\) will not be absolute continuous with respect to \(p^{*}\) and \(D_{}(p\|p^{*})\) cannot be defined. Besides, note that the initial particle distribution \(p_{0}\) is generally assumed to be fully supported on \(^{d}\) and thus does not meet the constraint.

To fix this issue, a natural idea is to drive the particle distribution \(p_{t}\) towards \(\) to satisfy \(p_{t}()=1\) and train the functional gradient flow on constrained domains by minimizing the regularized Stein discrepancy (RSD)

\[_{v}\ _{}=_{}p_{t}(- }{p_{t}},v+\|v\|^{2} )x.\] (7)

These stringent requirements make the construction of velocity field for constrained sampling far more volatile than conventional functional gradient for unconstrained domains.

In the rest of this section, we first present the idea of velocity design in Section 4.1 and then derive the tractable training objective in Section 4.2. The practical algorithm is proposed in Section 4.3.

### Necessity of Piece-wise Velocity Field

We first show that a globally continuous velocity field may fail to achieve the exact minimum of RSD under the constraint. To ensure that particles inside \(\) will never escape, the velocity should satisfy the boundary condition

\[v_{t}} 0,\ \ .\] (8)

In fact, if (8) holds, by Stoke's formula and the continuity equation \(p_{t}(x)=-(p_{t}(x)v_{t}(x))\), we have

\[}{t}p_{t}()=}{t} _{p_{t}}_{}=_{}p_{t}(x)x=-_{}(p_{t}(x)v_{t}(x))x=- _{}p_{t}(x)v_{t}(x)}S.\] (9)

Thus we can conclude

**Proposition 4.1**.: _If \(v_{t}} 0\) on \(\), then \(p_{t}()\) will not decrease._

However, it is possible that there does not exist an optimal solution of (7) that meets the boundary condition (8) and is continuous on \(\), as illustrated in the following 1D-example.

**Example 4.2**.: _Let \(p^{*}(-}{2})_{\{x^{2} 1\}}\) and \(p(-)^{2}}{2})\). We have \(}{p}=-\) in \(\) and \(_{}=_{-1}^{1}p|v(x)+|^{2} x-\). The constraint on boundary is \(v(1) 0,v(-1) 0\). Hence there is no optimal \(v\) in \(()\)._Therefore, it is necessary to design velocities for particles inside and outside separately. For particles located outside \(\) (contributing to the probability \(p(g(x)>0)\)), it is prudent to make the velocity drive the particles into the domain. On the other hand, for those already inside \(\), the velocity field should be able to fit the target distribution. Overall, it is reasonable to use the following piece-wise construction:

\[v_{t}=h_{net}_{\{g<0\}}- _{\{g 0\}}.\] (10)

Here \(>0\) is a constant. The gradient direction \( g\) will push the particles into \(\). And \(h_{net}\) is a continuous neural net to learn the optimal direction in \(\). We observed that the magnitudes of the gradients of different particles vary significantly in the numerical experiments and thus use the normalized gradient \(\) instead.

### Training Objective

Based on the velocity design in (10), we are now ready to derive a tractable training objective for \(h_{net}\) to learn the optimal direction in \(\) through (7).

Note that in principle, \(h_{net}\) should be trained after \(p_{t}()=1\). However, in order to enhance efficiency in practice, we use inner particles to minimize RSD before all the particles are driven in the constrained domain. At this phase, we replace \(p_{t}\) in (7) with the conditional measure \(_{t}:=p_{t}(|)\).

For any \(v(,^{d})\), expand (7) and we get

\[_{}&=_{ }-_{t}v^{T}}{_{t}}x+_{}_{t}\|v\|^{2}x\\ &=_{}-_{t}[v^{T} p^{*}+ v] x+_{}_{t}\|v\|^{2}x+_{ }_{t}v}S.\] (11)

Substitute \(v\) with the continuous extension of \(h_{net}\) on \(\) and we obtain the training objective for \(h_{net}\).

Note that the first two terms in (11) are aligned with (5) by substituting in the integration domain, while the last term is a boundary integral specific to inequality constraints. This is one of the essential differences between training functional gradients on constrained and unconstrained domains.

### Estimation of the Boundary Integral

The boundary integral \(_{}pv}S\) is computationally intractable in general. Inspired by the _co-area formula_(Federer, 2014), we can estimate it using a heuristic band-wise approximation as follows

\[_{}pv}S_{_{h}}pv}x=_{ _{h}}(x)v(x)}( x)}x=_{h})}{h}_{_{h}}(x)v(x) }x,\] (12)

where \((x) p(x)\) such that \(_{_{h}}(x)x=1\), and \(_{h}:=\{x:d(x,) h\}\) is a band-like area near the boundary with a small bandwidth \(h>0\), which further has a proxy as

\[g(x) 0, g(x+h) 0.\] (13)

Please refer to Appendix A for more explanations. This way, we can use the particles in the band-like area to obtain a Monte Carlo estimate of the boundary integral. Suppose there are \(m\) particles in \(\), of which \(\{x_{j}\}_{j=1}^{n}\) are in the band-like area. Then \(p(x_{h})\), and thus

\[_{}pv}S_{j=1}^{n}v(x_{j})^{T} g(x_{j})/\| g(x_{j})\|.\] (14)

We summarize all the techniques above and propose the Constrained Functional Gradient (CFG) in Algorithm 1. We use the neural network structure designed as in Appendix D for \(h_{net}\).

```
0: Unnormalized target distribution \(p^{*}\), initial particles \(\{x_{0}^{i}\}_{i=1}^{N}\), initial neural network parameters \(w_{0}=\{_{0},_{0}\}\), weight parameter \(\), iteration number \(L,L\), particle step size \(\), parameter step size \(\), bandwidth \(h\) for\(k=0,,L-1\)do  Assign \(w_{k}^{0}=w_{k}\)  Identify \(\{x_{k}^{i_{j}}\}_{j=1}^{n}:=\{x_{k}^{i}|x_{k}^{i}_{h}\}\), \(\{x_{k}^{l_{r}}\}_{r=1}^{m}:=\{x_{k}^{l}|x_{k}^{l}\}\) for\(t=0,,L^{}-1\)do  Set \(h_{w_{k}^{l}}=f_{_{k}^{l}}-z_{_{k}^{l}}^{2} g\)  Compute \[}_{RSD}(w) =_{r=1}^{m}[-}{(x_{k}^{l_{r}})}^{T }h_{w}(x_{k}^{l_{r}})- h_{w}(x_{k}^{l_{r}})\] \[+\|h_{w}(x_{k}^{l_{r}})\|^{2}]+_{j=1}^{ n}(x_{k}^{i_{j}})^{T} g(x_{k}^{i_{j}})}{\| g(x_{k}^{i_{j}})\|}\]  Update \(w_{k}^{t+1}=w_{k}^{t}-_{w}}_{RSD}(w_{k}^{t})\) endfor  Assign \(w_{k+1}=w_{k}^{L^{}}\)  Compute \(v_{w_{k+1}}=(f_{_{k+1}}-z_{_{k+1}}^{2} g)_{ \{g<0\}}-_{\{g 0\}}\)  Update particles \(x_{k+1}^{i}=x_{k}^{i}+ v_{w_{k+1}}(x_{k}^{i})\) for \(i=1,,N\) endfor return Particles \(\{x_{L}^{i}\}_{i=1}^{N}\) ```

**Algorithm 1** CFG: Constrained Functional Gradient

## 5 Theoretical Analysis

In this section, we present the convergence guarantee of CFG in terms of TV distance. Consider the continuous dynamic \(x_{t}=v_{t}(x_{t})t\) where \(v_{t}\) is defined in (10). Let \(p_{t}\) be the law of \(x_{t}\). We first investigate when particles can get into the domain.

**Assumption 5.1**.: \(\| g(x)\| C>0\) _for \(x^{c}\) and \(M_{0}=\{g(x_{0}):x_{0}(p_{0})\}<\)._

For simplicity, we do not delve into the case that the particles outside \(\) may get stuck at local extremal point of \(g\) before getting in \(\). Based on this assumption, the particles will enter the constrained domain in finite time:

**Theorem 5.2**.: _There exists a finite \(t_{0}}{ C}\), such that \(g(x_{t}) 0, t t_{0}\)._

The proof is deferred to Appendix B.1. Since domains with inequality constraints do not necessarily require the velocity field to gradually decay near the boundary as in Zhang et al. (2022), directly using \(_{\{g 0\}}\) allows for a swift penetration of the particles into the constrained domain.

Once the particles are in the constrained domain, an important technique is to extend the target distribution to be non-trivially supported on the whole space by convolution with a Gaussian kernel and use it as a proxy. Denote the convolution of the target distribution and the Gaussian distribution as \(^{*}=p^{*}*(0,^{2}I)\), where \(>0\) can be arbitrarily small. Now the KL divergence \(D_{}(p_{t}\|^{*})\) is well defined on \(^{d}\). Moreover, by the convolution properties, \((^{*}\|p^{*}) 0\) as \( 0\)(Stein & Shakarchi, 2005).

**Assumption 5.3** (Poincare inequality).: _The target distribution \(p^{*}\) satisfies \(_{p^{*}}[f]_{p^{*}}[\| f\|^{2}]\) for any smooth function \(f\)._

This is a common assumption in convergence analysis that describes the degree of convexity of the target distribution (Chewi et al., 2022). In contrast to Zhang et al. (2022), our approach relies solely on the Poincare property of the original target distribution, rather than requiring it for the conditional measure on a zero measure set. Following Cheng et al. (2023), we make the following assumption on the approximation error of neural networks.

**Assumption 5.4**.: _For any \(t>t_{0}\). \(_{}p_{t}\|h_{net}(t)-}{p_{t}}\|^{2}x\)._

Now, we are ready to present the main result.

**Proposition 5.5**.: _Suppose that \(p^{*}\) satisfies \(\)-PI and the data distribution \(p_{t}\) is smooth. Denote_

\[F(p_{t},^{*}):=_{}p_{t}\|^{*}}{p_{t}}\|^ {2}x,\]

_then the following bound holds for any \(t>t_{0}\)_

\[(p_{t}\|^{*}))(F(p_{t},^{* }))}+()\] (15)

Relating the gradient of KL divergence and the Fisher information and letting \( 0\), we have

**Theorem 5.6**.: _Under assumption 5.4 and the assumptions in Proposition 5.5, suppose also that the KL divergence \(D_{}(p_{t_{0}}\|p^{*})<\). The following bound holds_

\[_{t T}(p_{t}\|p^{*})(T^{-}+ ^{}).\] (16)

Please refer to Appendix B.2 and B.3 for detailed proofs.

## 6 Experiments

In this section, we compare CFG to other baseline methods for constrained domain sampling, including MSVGD (Shi et al., 2022), MIED (Li et al., 2022), Spherical HMC (Lan et al., 2014), PD-SVGD and Control SVGD (Liu et al., 2021). Throughout the section, we use neural networks with 2 hidden layers and initialize our particles with Gaussian distributions unless otherwise stated. We use the neural network structure designed as in Appendix D. All the experiments were implemented with Pytorch. More details can be found in Appendix D. The code is available at https://github.com/ShiyueZhang66/Constrained-Functional-Gradient-Flow.

### Toy Experiments

We first conduct 2-D experiments to test the effectiveness of CFG on sampling from truncated Gaussian distributions within various constrained domains, including ring-shaped, cardioid-shaped and double-moon-shaped domains. We covered non-convex domains, including unconnected domains. We use 1000 particles for all domains. From the left of Figure 1 we can see that the particles quickly converge to the target distribution without escaping the constrained domain. Comparison to MIED (via various distributional metrics) on the first three domains are deferred to Appendix D.1, where CFG provides better approximation in most cases.

To compare with MSVGD and MIED, we additionally conduct the experiment of sampling from truncated gaussian mixture distribution within the block-shaped domain. The initial distribution is the uniform distribution. The right of Figure 1 shows that our method outperformed MSVGD and achieved comparable results to MIED in terms of Wasserstein-2 distance and energy distance.

### Bayesian Lasso

The Lasso method is broadly used in model selection to avoid overfitting by imposing a penalty term on model parameters. Park and Casella (2008) introduced a Bayesian alternative, named Bayesian Lasso, that replaces the plenty term with the double exponential prior distribution \(p_{}()(-\|\|_{1})\). Lan et al. (2014) then proposed Spherical HMC method, which introduced more flexibility in choosing priors with explicit \(_{q}\)-norm constraints: \(p_{}() p()_{\{\|\|_{q} r\}}\). For \(q=1\), it corresponds to the Lasso method. For more general case when \(q>1\), it is called Bayesian Bridge regression.

Following Lan et al. (2014), we choose the prior to be the truncated Gaussian distribution, where \(p()=(0,^{2})\). This leads to the Bayesian regularized linear regression model (Lan et al., 2014):

\[y|X,,^{2}(X,^{2}),| ^{2}(0,^{2})(\|\|_{q} r)\] (17)The posterior distribution for \(\) is \(|y,X,^{2}(^{*},^{2}(X^{T}X+)^{- 1})(\|\|_{q} r)\), where \(^{*}=(X^{T}X+)^{-1}X^{T}y\). This posterior has an inequality constraint and our method can apply.

#### 6.2.1 Synthetic Dataset

We first generate a 20-dimensional dataset \((X,y)\), where \(X^{1000 20}\), \(y^{1000}\) and \(y=X_{true}+\), where \((0,25)\). We set the true regression coefficients to be \(_{true}=(10,,10,0,,0)\), where the first half of components is tens and the second half is zeros. Let \(^{OLS}\) denote the estimates obtained by ordinary least squares (OLS) regression. We follow Park & Casella (2008) and set \(r=\|^{OLS}\|_{1}\).

We compare our method on Wasserstein-2 distance and energy distance with Spherical HMC and MIED using different number of particles. The ground truth is obtained via rejection sampling using 100,000 posterior samples. We use the \(h_{0}(dN)^{-}\) scheme to adapt the bandwidth to the number of particles \(N\) (see Appendix C), where we choose \(h_{0}d^{-}=0.1\). From Figure 2, we see that CFG performs the best in both metrics when \(N\) is small. This indicates the sample efficiency of particle-based variational inference for constrained sampling, which aligns with the findings in Liu & Wang (2016) for unconstrained sampling. All methods provide similar results when \(N\) is large.

It is worth noting that as a kernel-based method, the time complexity of MIED scales quadratically as \(N\) increases, while functional gradient methods like CFG scale linearly. Meanwhile, we observed in our experiments that MIED tends to require more iterations to converge when the number of particles increases. These issues add to the overall time cost for MIED to achieve accurate approximation, especially when a large \(N\) is used (see Figure 9 in Appendix D.2). Similar issues of SVGD are also stated in Dong et al. (2023). Please refer to Appendix D.2 for detailed information.

#### 6.2.2 Real Dataset

Following Lan et al. (2014), we also evaluate our method using the diabetes dataset discussed in Park & Casella (2008). We compare the posterior median estimates given by Spherical HMC, CFG and MIED for the Lasso regression model (\(q=1\)) and the Bridge regression model (\(q=1.2\)), as the shrinkage factor \(s:=r/\|^{OLS}\|_{1}\) varies from 0 to 1. We use 5000 particles for CFG and MIED.

Figure 1: **Left**: CFG sampled particles at different numbers of iterations on constrained domains (ring, cardioid, double-moon, block). **Right**: The convergence curves of MSVGD, CFG and MIED on the block constraint.

From Figure 3 we can see that our method aligns well with Spherical HMC and MIED, which shows the effectiveness of our method.

### Monotonic Bayesian Neural Network

We use the COMPAS dataset following the setting in Liu et al. (2021). Given a Bayesian neural network \((,)\), define the constraint function \(g()=_{}()-\) with \(_{}()=_{x}[\|(-_{x_{ }}(x;))_{+}\|_{1}]\). Here, \(x_{}\) denotes the subset of features to which the output should be monotonic. Note that in Liu et al. (2021), the constraint is only in the sense of expectation, i.e., \(_{p}[g()] 0\). In the context of monotonic neural network (Karpf, 1991; Liu et al., 2020), however, the monotonicity constraint is \(g() 0\), which defines a domain with inequality constraints and thus our method can be applied.

We use two-layer ReLU neural network with \(50\) hidden units. With different threshold \(\{0.005,0.01,0.05\}\), we compare our CFG with MIED and two SVGD variants in Liu et al. (2021): PD SVGD and Control SVGD (C-SVGD). The number of particles is \(200\) and the results are shown in Table 1. We observe that in all the tasks, our method outperforms the other two baselines in terms of both test accuracy and test likelihood. "Ratio Out" denotes the proportion of particles outside \(=\{g() 0\}\) to the total number of particles. All methods can successfully force almost all the particles into the domain. We further plot in the right of Figure 3 the averaged test monotonic loss \(_{}\) against test accuracy during the training process for \(=0.01\). For MIED, the test accuracy is higher when more particles are outside the domain, while lower when forcing the particles into the

Figure 3: **Left**: Bayesian Lasso (\(q=1\)) using Spherical HMC (upper left), CFG (upper middle) and MIED (upper right). Bayesian Bridge Regression (\(q=1.2\)) using Spherical HMC (lower left) CFG (upper middle) and MIED (upper right). **Right**: Results of monotonic Bayesian neural network with \(=0.01\). Only the portion below \(0.02\) is shown on the y-axis to better display the performance of models satisfying constraint.

Figure 2: **Left**: Wasserstein-2 distance of SPH, CFG and MIED versus the number of particles, **Right**: Energy distance of SPH, CFG and MIED versus the number of particles. Both on a synthetic dataset.

domain during training. Notably, Vanilla SVGD exhibits lower accuracy and higher monotonic loss, indicating the importance of constraint-sampling methods.

Furthermore, our method can scale up to even higher dimensional real problems. We experimented on the COMPAS dataset using larger monotonic BNNs and on the 276-dimensional larger dataset Blog Feedback Liu et al. (2020). Please refer to Appendix D.3 for detailed information.

## 7 Conclusion

We proposed a new functional gradient ParVI method for constrained domain sampling, named CFG, which uses neural networks to design a piece-wise velocity field that satisfies a non-escaping boundary condition. We presented novel numerical strategies to deal with boundary integrals arising from the domain constraints. We showed that our method has TV distance convergence guarantee. Empirically, we demonstrated the effectiveness of our method on various machine learning tasks with inequality constraints.