# A hierarchical decomposition for explaining ML performance discrepancies

Harvineet Singh\({}^{1}\)  Fan Xia\({}^{1}\)  Adarsh Subbaswamy\({}^{2}\)  Alexej Gossmann\({}^{2}\)  Jean Feng\({}^{1}\)

\({}^{1}\)University of California, San Francisco

\({}^{2}\)U.S. Food and Drug Administration, Center for Devices and Radiological Health

Corresponding author: jean.feng@ucsf.edu

###### Abstract

Machine learning (ML) algorithms can often differ in performance across domains. Understanding _why_ their performance differs is crucial for determining what types of interventions (e.g., algorithmic or operational) are most effective at closing the performance gaps. _Aggregate decompositions_ express the total performance gap as the gap due to a shift in the feature distribution \(p(X)\) plus the gap due to a shift in the outcome's conditional distribution \(p(Y|X)\). While this coarse explanation is helpful for guiding root cause analyses, it provides limited details and can only suggest coarse fixes involving **all variables** in an ML system. _Detailed decompositions_ quantify the importance of **each variable** to each term in the aggregate decomposition, which can provide a deeper understanding and suggest more targeted interventions. Although parametric methods exist for conducting a full hierarchical decomposition of an algorithm's performance gap at the aggregate and detailed levels, current nonparametric methods only cover parts of the hierarchy; many also require knowledge of the entire causal graph. We introduce a nonparametric hierarchical framework for explaining why the performance of an ML algorithm differs across domains, without requiring causal knowledge. Furthermore, we derive debiased, computationally-efficient estimators and statistical inference procedures to construct confidence intervals for the explanations.

## 1 Introduction

The performance of an ML algorithm can differ across domains due to shifts in the data distribution. Understanding what contributed to this performance gap can help teams choose the most effective corrective action(s), ranging from algorithmic modifications (e.g. model retraining) to operational fixes (e.g. updating data pipelines). Prior works have focused primarily on _aggregate_ decompositions, which decompose the performance gap into that due to a shift in the marginal distribution of the input features \(p(X)\) (covariate shift ) and that due to a shift in the conditional distribution of the outcome \(p(Y|X)\) (concept shift or conditional outcome shift) . However, coarse decompositions can only suggest coarse corrective actions, such as investigating data pipelines for all features. The goal of this work is to provide a hierarchical nonparametric framework that first decomposes a performance gap into aggregate terms and then each aggregate term into detailed terms. This helps narrow down the features to investigate and understand how they affect the gap.

If one is willing to make the strong assumption that the expected loss of a model is a linear function of some feature set \(X\), the problem of obtaining _aggregate_ and _detailed_ decompositions drastically simplifies. This is the key assumption underlying the Oaxaca-Blinder (OB) decomposition, one of the most widely used frameworks in the (income and health) disparities literature . Given an MLmodel with average loss \(_{D}[]\) in domains \(D=0\) and \(1\) and assuming the linear loss relationship \(_{D}[|X]=_{D}^{}X\), the OB framework decomposes the performance gap at the _aggregate_ level into that due to a covariate shift (\(_{0}^{}(_{1}[X]-_{0}[X])\)) and that due to a conditional outcome shift (\((_{1}-_{0})^{}_{1}[X]\)). That is, the former is due to a shift in the feature means and the latter is due to a shift in the coefficients. At the _detailed_ level, the aggregate terms corresponding to covariate and conditional outcome shifts are further broken down into the contributions from each feature, i.e. \(_{0,j}(_{1}[X_{j}]-_{0}[X_{j}])\) and \((_{1,j}-_{0,j})_{1}[X_{j}]\), respectively. Although the highly intuitive nature of the OB framework has led to its widespread popularity, the terms are difficult to interpret under model misspecification. As such, this work aims to define a similar hierarchical decomposition framework for explaining ML performance disparities, _without making strong parametric assumptions_.

There is currently no unified, nonparametric framework that obtains aggregate and detailed decompositions. Instead, solutions have been proposed for parts of the hierarchy (see Table 1): nonparametric methods exist for the aggregate decomposition [5; 30; 48] and, assuming the causal graph is known, detailed decompositions of the covariate shift [40; 44; 50; 38; 4; 23]. However, the causal graph is unlikely to be known in high-dimensional settings and, more importantly, there are no methods for simultaneously obtaining a detailed decomposition of the conditional outcome shift. There are also methods that do not decompose the performance gap and instead describe distribution shifts in the variables  or model explanations [12; 31; 23]. However, such approaches do not quantify how such shifts ultimately contribute to an ML performance gap. We make the following contributions.

* We introduce a **unified hierarchical nonparametric framework** for decomposing the performance gap of an ML algorithm (Fig 1 left). Using the concept of _partial_ distribution shifts, we generalize shifts with respect to variable subgroups to encompass not only covariate shifts but also conditional outcome shifts. We then introduce a unified scoring rule for (candidate) partial shifts, which can be used even when the causal graph is not known.
* We derive novel debiased and asymptotically normal estimators for terms in the decomposition, which allow us to construct **confidence intervals (CIs) with asymptotically valid coverage rates**.
* We demonstrate the utility of our framework in **real-world examples** of prediction models for hospital readmission and insurance coverage. Code for reproducing experiments is available at https://github.com/jjfeng/HDPD.

## 2 A unifying framework for explaining performance gaps

**Notation.** Consider a prediction algorithm \(f:^{m}\) for binary outcomes \(Y\) across source and target domains, denoted by \(D=0\) and \(D=1\), respectively. Let the performance of \(f\) be quantified in terms of a loss function \(:\{0,1\}\), such as the 0-1 misclassification loss \(\{f(X) Y\}\). Suppose variables \(X\) can be partitioned into disjoint sets \(W^{m_{1}}\) and \(Z=X W^{m_{2}}\), where \(m=m_{1}+m_{2}\). Although our framework does not require knowing the causal ordering between variables, the interpretation is more intuitive when \(W\) is causally upstream

Figure 1: **(left)** Proposed framework called Hierarchical Decomposition of Performance Differences (namely, HDPD) helps to understand performance gaps of an ML algorithm between two domains. It decomposes the overall gap (say, in classification accuracy) into gaps due to shifts in the covariate versus outcome distribution (Aggregate). Then, it quantifies the importance of each feature to the two components (Detailed). **(right)** In terms of directed acyclic graphs, aggregate decompositions describe the effect of shift interventions, for instance, on the outcome \(Y\) distribution while keeping all else fixed between domains. Detailed decompositions quantify how well can we explain those shift interventions by more targeted shifts with respect to feature subsets \(Z_{s}\) alone.

[MISSING_PAGE_FAIL:3]

\(s\{1,,m\}\), the attribution to variable \(j\) is the average gain in value when additionally shifting with respect to \(j\), i.e.

\[_{j}:=\ _{s\{1,,m\} j}^{ -1}\{v(s j)-v(s)\}.\] (2)

**Interpretation.** Such VI values can help ML teams identify the underlying cause(s) for a performance gap and design targeted operational and/or algorithmic interventions. For instance, a variable with high importance to the conditional covariate shift term \(_{}\) may indicate differences in the variable's missingness rates, prevalence, or selection bias across domains. If instead the variable is highly important to the conditional outcome shift term \(_{}\), it may indicate inherent differences in the conditional distribution (i.e. effect modification), differences in measurement error or the way outcome is defined between domains, or omission of variables predictive of the outcome. Finally, note that variable importances should be viewed as _relative_ to the variables included in the framework rather than absolute importances, as one cannot include all possible explanatory variables.

To define VI values, **the key question is how to define a value function \(v\) that is applicable to different types of \(s\)-partial shifts, even when the causal graph is not known.** It turns out that the answer is far from straightforward. The next section discusses how the value function and candidate \(s\)-partial shifts must be defined with care.

### Value of partial distribution shifts

When the true causal graph is known, prior works define an \(s\)-partial covariate shift as the substitution of nodes \(s\) with mechanisms from the target domain and its value \(v(s)\) as the difference in the average loss, e.g. \(_{1}[]-_{100}[]\)[50; 38]. However, this has a number of limitations: (i) knowing the entire causal graph is often impractical, (ii) in the absence of such a graph, this value function is not a proper scoring rule and can assign high values to partial shifts that contradict the true causal graph (see Example E.1 for details), and (iii) \(v(s)\) can be high even if the shift does not induce similar shifts in the loss as the aggregate shift.

Instead, we propose to evaluate candidate \(s\)-partial shifts by how closely they approximate aggregate shifts, using a nonparametric extension of the traditional \(R^{2}\) measure. In the case of conditional covariate shifts, an aggregate shift induces a performance difference of \(_{ 10}(W)\) in strata \(W\) while a candidate \(s\)-partial shift induces a performance difference of \(_{ 80}(W)=_{ 80}[|W]-_{ 00}[ |W]\). The value of this \(s\)-partial shift is then the percent variation of \(_{ 10}\) explained by \(_{ 80}\), i.e.

\[v_{}(s):=1-_{1}[(_{ 8 0}(W)-_{ 10}(W))^{2}]}{_{1} [_{ 10}^{2}(W)]}.\] (3)

Likewise, for conditional outcome shifts, an aggregate shift induces a performance difference of \(_{ 1}(W,Z)\) in strata \((W,Z)\) while a candidate \(s\)-partial shift induces a performance difference of \(_{ s}(W,Z)=_{ s}[|W,Z]-_{ 0}[ |W,Z]\). The value of this \(s\)-partial conditional outcome shift is then defined as the percent variation of \(_{ 1}\) explained by \(_{ s}\), i.e.

\[v_{}(s):=1-_{11}[(_{ s}(W, Z)-_{ 1}(W,Z))^{2}]}{_{11}[_{  1}^{2}(W,Z)]}.\] (4)

This formulation of the value function in terms of \(R^{2}\) provides a unified way to score partial conditional covariate and outcome shifts, does not require knowledge of the true causal graph, and is a strictly proper scoring rule under certain conditions (see Appendix E). In general, we expect the highest scoring candidate \(s\)-partial shifts to be those that are close to the true causal graph _and_ induce large shifts in the ML algorithm's loss. Finally, we acknowledge one caveat with this framework: because some variables must be held out to define the \(R^{2}\) measure, we cannot score partial shifts in the baseline variables \(W\). We hope to close this gap in future work.

### Candidate partial distribution shifts

We now present the set of candidate partial shifts considered in this work. High-level illustrations for the candidate partial shifts are given in Fig 1 right top; more detailed illustrations are given in Fig 4 of the Appendix. We emphasize that these are _candidates_, as the true causal graph is not known. While there are certainly other partial shifts that one may consider, many have various disadvantages. As such, we leave the investigation of other partial shifts to future work.

\(s\)**-partial conditional covariate shift**: Suppose \(Z_{-s}\) is downstream of \(Z_{s}\). Then \(p_{s}(z|w):=p_{1}(z_{s}|w)p_{0}(z_{-s}|z_{s},w)\). Wu et al.  considered a similar proposal.

\(s\)**-partial conditional outcome shift**: Shifting the conditional distribution of \(Y\) only with respect to a variable subset \(Z_{s}\) but not \(Z_{-s}\) requires care. We cannot simply define \(p_{s}(Y|W,Z)\) as a function of only \(W\) and \(Z_{s}\). Such a definition would imply that an \(s\)-partial shift has a non-zero effect, even in settings with no shift in the conditional outcome distribution (i.e. \(p_{1}(Y|W,Z) p_{0}(Y|W,Z)\)).

Instead, we define an \(s\)-partial outcome shift based on models commonly used in model recalibration/revision [42; 34], where the modified risk (conditional probability of \(Y\)) is a function of the risk in the source domain \(Q:=q(W,Z):=p_{0}(Y=1|W,Z)\), \(W\), and \(Z_{s}\). That is, we define the shift as

\[p_{s}(y|z,r,w):=p_{1}(y|z_{s},r,w)= p_{1}(y|_{-s},z_{s},w)p_{1}( _{-s}|z_{s},q(w,z_{s},_{-s})=r,w)d_{-s}\] (5)

By defining the shifted outcome distribution solely as a function of \(Q,W\), and \(Z_{s}\), any direct effect from \(Z_{-s}\) to \(Y\) is eliminated and \(p_{s}\) has the desired behavior in the setting where there is no conditional outcome shift.

## 3 Estimation and statistical inference

Here we discuss estimation and statistical inference for the aggregate terms (\(_{},_{}\), and \(_{}\)), the value functions \(v_{}(s)\) and \(v_{}(s)\), and the Shapley-based detailed terms \(_{,j}\) and \(_{,j}\) for \(j(0,,m_{2})\). One approach is to rely on _plug-in_ estimators, which plug in estimates of conditional means (also called outcome models) or density ratios , which we collectively refer to as nuisance parameters. For instance, one can estimate the conditional means \(_{ 10}(w)=_{ 10}[|W]\) and \(_{ 00}(w)=_{ 00}[|W]\) using ML and take the empirical mean of \(_{ 10}-_{ 00}\) with respect to the target domain to get a plug-in estimator for \(_{}=_{ 1}[_{ 10}-_{ 00}]\). However, because estimation of the true nuisance parameters using ML typically converge at a rate slower than \(n^{-1/2}\), plug-in estimators generally fail to be consistent at a rate of \(n^{-1/2}\) and cannot be used to construct CIs .

To this end, we use the method of one-step correction from semiparametric inference to derive _debiased_ ML estimators [45; 7]. The core idea is to subtract the first-order bias of a plug-in estimator, which requires characterizing the canonical gradient (or efficient influence function) of the estimand . The primary technical contribution in this section is the derivation of debiased estimators for the detailed decompositions. (Estimation and inference for the aggregate decomposition is well-studied, as the aggregate terms can be formulated as average causal effects.) Due to space limitations, this section only presents estimators for the detailed decomposition of the conditional outcome shift. This estimand is particularly interesting, as its unique structure is not amenable to standard techniques for debiasing ML estimators. We refer the reader to the Appendix for derivations, pseudocode, and proofs for all the estimators.

**Notation.** Let \(_{D}\) denote the expectation with respect to domain \(D\). For ease of exposition, suppose the number of IID observations from each domain is the same, denoted by \(n\). We present split-sample estimators, though the results can be readily extended using cross-fitting [7; 25]. Let the data be randomly split into "training" and "evaluation" partitions. Let \(_{D,n}\) denote the empirical average in the evaluation partition for domain \(D\). All estimated quantities are denoted using hat notation.

### Value of \(s\)-partial conditional outcome shifts

Here we describe the high-level steps for deriving a debiased estimator for \(v_{}(s)\), the value of a candidate \(s\)-partial conditional outcome shift. The following section describes a computationally efficient procedure for combining such estimates to obtain Shapley values.

Standard recipes for deriving asymptotically normal, nonparametric-efficient estimators rely on _pathwise_ differentiability of the estimand and analyzing its efficient influence function . However, \(v_{}(s)\) is not pathwise differentiable because it is a function of (5), which conditions on the source risk \(q(w,z)\) equalling some value \(r\). Taking the pathwise derivative of \(v_{}(s)\) requires taking a derivative of the indicator function \(\{q(w,z)=r\}\), which generally does not exist. Given the difficulties in deriving an asymptotically normal estimator for \(v_{}(s)\), we propose estimating a close alternative that _is_ pathwise differentiable.

The idea is to replace \(q\) in (5) with its binned variant \(q_{}(w,z)= q(w,z)B+\) for some \(B^{+}\), which discretizes outputs from \(q\) into \(B\) disjoint bins. As long as \(B\) is sufficiently high, the binned version of the estimand, denoted \(v_{,}(s)\), is a close approximation to \(v_{}(s)\). (We use \(B=20\) in the empirical analyses, which we believe to be sufficient in practice.) The benefit of this binned variant is that the derivative of the indicator function \(\{q_{}(w,z){=}r\}\) is zero almost everywhere as long as observations with source risks exactly equal to a bin edge have measure zero. More formally, we require the following:

**Condition 3.1**.: _Let \(\) be the set of \((W,Z)\) such that \(q(W,Z)\) falls precisely on some bin edge and is not equal to zero or one. The set \(\) is measure zero._

Under this condition, \(v_{,}(s)\) is pathwise differentiable and, using one-step correction, we derive a debiased ML estimator that has the unique form of a V-statistic (this follows from the integration over "phantom" \(_{-s}\) in (5)). We represent V-statistics using the operator \(_{1,n}}_{1,n}\), which takes the average over all pairs of observations \(O_{i}\) with replacement, i.e. \(}_{i=1}^{n}_{j=1}^{n}g(O_{i},O_{j})\) for some function \(g\). Calculation of this estimator and its theoretical properties are as follows.

**Estimation.** Using the training partition, estimate the outcome models \(_{_{D}}(W,Z)=_{_{D}}[|W,Z]\) for \(D=0,1\), the shifted outcome model \(_{_{S}}(W,Z)=_{_{s}}[|W,Z]\); and the density ratio models \(_{110}(W,Z)=p_{1}(W,Z)/p_{0}(W,Z)\) and \((W,Z_{s},Z_{-s},Q_{})=p_{1}(Z_{-s}|W,Z_{s},q_{}(W,Z )=Q_{})/p_{1}(Z_{-s})\). The outcome and density ratio models can be fit using ML-based regression models and probabilistic classifiers , respectively (see Section H for details). The estimator for \(v_{,}(s)\) is the ratio \(_{,}(s)=_{,n}^{}(s) /_{,n}^{}\), where the numerator and denominator are estimated using the evaluation partition as

\[_{,n}^{}(s) =_{1,n}_{s}(W,Z)^{2}+2\ _{1,n}_{s}(W,Z)(-_{_{1}}(W,Z))\] \[-2\ _{1,n}}_{1,n}_{s}(W,Z_{s },_{-s})(W,Z_{s},_{-s},Y)(W,Z_{s},_{- s},Q_{})\] \[+2\ _{1,n}}_{1,n}_{s}(W,Z_{s },_{-s})_{}(W,Z_{s},_{-s})(W,Z_{ s},_{-s},Q_{})\] (6) \[_{,n}^{} =_{1,n}(_{_{1}}(W,Z)-_{ _{0}}(W,Z))^{2}+2\ _{1,n}(_{_{1}}(W,Z)-_{_{0 }}(W,Z))(-_{_{1}}(W,Z))\] \[-2\ _{0,n}(_{_{1}}(W,Z)-_{ _{0}}(W,Z))(-_{_{0}}(W,Z))_{110 }(W,Z),\] (7)

where \(_{s}(W,Z)=_{_{1}}(W,Z)-_{_{s}}( W,Z)\). Note that the first terms in (6) and (7) are the plug-in estimates, followed by additional terms that correct its bias.

**Inference.** This estimator is asymptotically normal assuming the estimators for the nuisance parameters converge at a fast enough rate, per the following theorem.

**Theorem 3.2**.: _Suppose Condition 3.1 holds. For variable subset \(s\), suppose the density ratios \((W,Z_{s},Z_{-s},Q_{})\) and \(_{110}(W,Z)\) are bounded; denominator in case of no shift \(v_{}^{}()>0\); estimator \(\) is consistent; estimators \(_{_{0}},_{_{1}}\) and \(_{_{s}}\) converge at an \(o_{p}(n^{-1/4})\) rate, and_

\[_{1}(_{}-q_{})^{2} =o_{p}(n^{-1})\] (8) \[_{1}(_{_{s}}-_{_{s}})( -) =o_{p}(n^{-1/2}),_{0}(_{_{0}}-_{ _{0}})(_{110}-_{110})=o_{p}(n^{-1/2})\] (9)

_Then the estimator \(_{,}(s)\) is asymptotically normal centered at the estimand \(v_{,}(s)\)._

Note that the product terms in (9) mean that the estimator converges to normal at \(n^{-1/2}\)-rate even if one of the nuisance parameters is estimated at a rate slower than \(n^{-1/2}\). Hence, it is _multiply-robust_ to nuisance model misspecification. A convergence rate of \(o_{p}(n^{-1/4})\) can be achieved by ML estimators in a wide variety of conditions, and such assumptions are commonly used to construct debiased ML estimators. The additional requirement in (8) that \(_{}\) converges at a \(o_{p}(n^{-1})\) rate is new, but fast or even super-fast convergence rates of _binned_ risks is achievable under suitable margin conditions  such as Condition G.7 in the Appendix.

### Shapley values

Calculating the exact Shapley value is computationally intractable as it involves an exponential number of terms. However, Williamson and Feng  showed that calculating the exact Shapleyvalue is unnecessary for the purposes of statistical inference. Because there is inherent uncertainty in estimates of the value functions \(v(s)\), one only needs to sample and estimate the values for enough variable subsets such that the uncertainty due to estimation dominates that due to subset sampling. This leads to a drastic reduction in computation time: Williamson and Feng  proves that the number of subsets one needs to sample only needs to be linear or super-linear in the total number of observations \(n\). Using this result, Algorithm 4 outlines a computationally efficient procedure for estimation and inference of the detailed decomposition.

## 4 Simulation

We now present simulations to show that the proposed procedure achieves the desired coverage rates (Section 4.1) and illustrate how the HDPD framework provides more intuitive explanations of performance gaps (Section 4.2). In all empirical analyses, performance of the ML algorithm is quantified in terms of 0-1 accuracy. Below, we briefly describe the simulation settings; full details are provided in Section I in the Appendix.

### Verifying theoretical properties

We first verify that the inference procedures for the decomposition terms have CIs with coverage close to their nominal rate. We check the coverage of the aggregate decomposition as well as the value of \(s\)-partial conditional covariate and partial conditional outcome shifts for \(s=\{Z_{1}\},\{Z_{2}\},\{Z_{3}\}\). \((W,Z_{1},Z_{2},Z_{3})\) are sampled from independent normal distributions with different means in source and target, while \(Y\) is simulated from logistic regression models with different coefficients. CIs for the debiased ML estimator converge to the nominal 90% coverage rate with increasing sample size, whereas those for the naive plug-in estimator do not (Fig 1(a) and Fig 6).

### Comparing explanations

We now compare the proposed definitions for the detailed decomposition with existing methods. For the detailed decomposition due to conditional covariate shift, the comparators are:

* MeanChange Tests for a difference in means for each feature. Defines importance as \(1-\) p-value.
* Oaxaca-Blinder: Fits a linear model of the logit-transformed expected loss with respect to \(Z\) in the source domain. Defines importance of \(Z_{i}\) as its coefficient multiplied by the difference in the means of \(Z_{i}\).
* WuShift: Defines importance of subset \(s\) as change in _overall_ performance due to \(s\)-partial conditional covariate shifts. Applies Shapley framework to obtain VIs.

Figure 2: (a) Coverage rates of 90% CIs for value of \(s\)-partial shifts for the conditional covariate (first column) and outcome shifts (second column) across dataset sizes \(n\). Dashed horizontal line indicates 90% coverage rate. (b) Comparison of variable importance reported by proposed method HDPD (debiased) versus existing methods for conditional covariate and outcome shift terms.

For the detailed decomposition due to conditional outcome shifts, we compare against:

* ParametricChange: Fits a logistic model for \(Y\) with interaction terms between domain and \(Z\). Defines importance of \(Z_{i}\) as the coefficient of its interaction term.
* ParametricAcc: Same as ParametricChange but models the 0-1 loss rather than \(Y\).
* RandomForestAcc: Compares VI of random forest models trained on data from both domains with input features \(D\), \(Z\), and \(W\) to predict the 0-1 loss.
* Oaxaca-Blinder: Fits linear models for the logit-transformed expected loss in each domain. Defines importance of \(Z_{i}\) as its mean in the target domain multiplied by the difference in its coefficients across domains.

Although the proposed method may agree with these other methods on the top features in certain data settings, we highlight important situations where the methods differ.

**Conditional covariate.** (Fig 2b(i)) We simulate \((W,Z_{1})\) from a standard normal distribution, \(Z_{2}\) from a mixture of two Gaussians whose means depend on the value of \(Z_{1}\) (i.e. \(Z_{1} Z_{2}\)), and \(Y\) from a logistic regression model depending on \((W,Z_{1},Z_{2})\). We induce a shift from the source domain to the target domain by shifting only the distribution of \(Z_{1}\), so that \(p_{1}(Z|W)=p_{0}(Z_{2}|Z_{1},W)p_{1}(Z_{1}|W)\). Only the proposed estimator correctly recovers that \(Z_{1}\) is more important than \(Z_{2}\), as the \(\{1\}\)-partial conditional covariate shift explains all the variation in performance gaps across strata \(W\) (i.e. the corresponding \(R^{2}\)-based value function \(v_{2}(\{1\})\) is equal to 1). The other methods incorrectly assign higher importance to \(Z_{2}\). MeanChange only measures shifts but not loss due to shifts, Oaxaca-Blinder uses a misspecified linear model, and WuShift estimates the performance change due to hypothesized \(s\)-partial shifts but does not check if the partial shifts are good explanations in the first place.

**Conditional outcome.** (Fig 2b(ii)) \(W\) and \(Z^{4}\) are simulated from the same distribution in both domains. \(Y\) is generated from a logistic regression model with coefficients for \((W,Z_{1},,Z_{4})\) as \((0.5,0.5,1,0.3,0.3)\) in the source and \((0.5,0.3,1,1.3,-0.1)\) in the target. Interestingly, none of the methods have the same ranking of the features. ParametricChange identifies \(Z_{1}\) as having the largest shift on the logit scale, but this does not mean that it is the most important explanation for changes in the _loss_. According to our decomposition framework, \(Z_{3}\) is actually the most important for explaining changes in model performance due to outcome shifts. Oaxaca-Blinder, ParametricAcc, and RandomForestAcc have odd behavior. Oaxaca-Blinder assigns \(Z_{3}\) second to the lowest importance and ParametricAcc assigns \(Z_{2}\) the highest importance), likely because they misspecify the outcome models. RandomForestAcc likely ranks \(Z_{2}\) highly because its VI values quantify which variables are good predictors of performance, not performance shift.

A more objective evaluation is to compare the performance of fixes based on the different explanations. To this end, we re-fit the ML algorithm in the target domain with respect to input features \(Q,W\), and the top variables \(Z_{s}\) from each explanation. We find that model revisions based on the proposed method achieve the highest performance gain (Table 3 in Appendix).

Figure 3: Aggregate and detailed decompositions for performance gaps of (a) a model predicting readmission risk across patient populations and (b) a model predicting insurance coverage across US states. A subset of VI estimates is shown; see full list in Section J in the Appendix.

Real-world data case studies

We now demonstrate applicability of the framework on two datasets with naturally-occurring shifts.

**Hospital readmission.** Using electronic health record data from the Zuckerberg San Francisco General Hospital, we analyzed performance of a Gradient Boosted Tree (GBT) trained on the general patient population (source) to predict 30-day readmission risk but applied to patients diagnosed with heart failure (HF, target). Features include 4 demographic variables (\(W\)) and 16 diagnosis codes (\(Z\)). Each domain supplied \(n=3750\) observations from which we keep 20% in the evaluation partition.

Model accuracy drops from 70% to 53% in HF population. From the aggregate decompositions (Fig (a)a), we observe that the drop is mainly due to covariate shift. If one performed the standard check to see which variables significantly changed in their mean value (MeanChange), then one would find a significant shift in nearly _every_ variable. Little support is offered to identify main drivers of the performance drop. In contrast, the detailed decomposition from the proposed framework estimates diagnoses "Drug-induced or toxic-related condition" and "Mental & substance use disorder in remission" as having the highest estimated contributions to the conditional covariate shift, and most other variables having little to no contribution. Upon discussion with clinicians from this hospital, differences in the top two diagnoses may be explained by (i) substance use being a major cause of HF at this hospital, with over eightly percent of its HF patients reporting current or prior substance use, and (ii) substance use and mental health disorders often occurring simultaneously in this HF patient population. Based on these findings, closing the performance gap may require a mixture of both operational (e.g. care programs centered around substance use) and algorithmic interventions (e.g. reweighting data with respect to the top two features). Finally, CIs from the debiased ML procedure provide valuable information on the uncertainty of the estimates and highlight, for instance, that more data is necessary to determine the true ordering between the top two features. In contrast, existing methods do not provide (asymptotically valid) CIs.

**ACS Public Coverage.** We analyze a neural network trained to predict whether a person has public health insurance using data from Nebraska in the American Community Survey (source, \(n=3000\)), applied to data from Louisiana (target, \(n=6000\)). Baseline variables include 3 demographics (sex, age, race), and covariates \(Z\) include 31 variables related to health conditions, employment, marital status, citizenship status, and education.

Model accuracy drops from 84% to 66% across the two states. The main driver is the shift in the outcome distribution per the aggregate decomposition (Fig (b)b) and the most important contributor to the outcome shift is annual income, perhaps due to differences in cost of living across the two states. Income is significantly more important than all the other variables; the ranking between the remaining variables is unclear. In comparing the performance of targeted model revisions, we find that revising the model based on top variables identified by the proposed procedure leads to AUCs that are better or as good as those based on RandomForestAcc (Table 4 in the Appendix).

## 6 Prior work

**Describing distribution shifts.** This line of work focuses on detecting and localizing which distributions shift between datasets [29; 39]. Budhatoki et al.  identify the main variables contributing to a distribution shift via a Shapley framework, Kulinski and Inouye  fits interpretable optimal transport maps, and Liu et al.  finds the region with the largest shift in the conditional outcome distribution. However, these works do not quantify how these shifts contribute to _changes in performance_, the metric of practical importance.

**Explaining loss differences across subpopulations.** Understanding differences in model performance across subpopulations in a single dataset is similar to understanding differences in model performance across datasets, but the focus is typically to _find_ subpopulations with poor performance rather than to explain how distribution shifts contributed to the performance change. Existing approaches include slice discovery methods [35; 22; 10; 13] and structured representations of the subpopulation using e.g. Euclidean balls .

**Attributing performance changes.** Prior works have described similar aggregate decompositions of the performance change into covariate and conditional outcome shift components [5; 36]. To provide more granular explanations of performance shifts, existing works on causal attribution [50; 38] and mediation analysis  quantify the importance of shifts in each variable assuming the causal graph is correctly specified; covariate shifts restricted to variable subsets assuming that the partial shifts follow a particular structure ; and conditional shifts in each variable assuming a parametric model . However, the strong assumptions made by these methods make them difficult to apply in practice, and model misspecification can lead to unintuitive interpretations. Furthermore, such methods do not provide hierarchical decompositions, i.e. VIs for each type of shift. Decomposition methods such as Oaxaca-Blinder similarly make strong parametric assumptions , which is inappropriate for the complex data settings in ML. In addition, there is no unifying nonparametric framework for decomposing both covariate and outcome shifts, and many methods do not output CIs, which is important when the amount of labeled data from a given domain is limited. A summary of how the proposed framework compares against prior works is shown in Table 1.

## 7 Discussion

ML algorithms regularly encounter distribution shifts in practice, leading to drops in performance. We present a novel framework that helps ML developers and deployment teams build a more nuanced understanding of the shifts. Compared to past work, the approach provides a nonparametric hierarchical framework for decomposing both conditional covariate and outcome shifts, does not require fine-grained knowledge of the causal relationship between variables, and quantifies the uncertainty of the estimates by constructing confidence intervals. We present real-world case studies to demonstrate how this framework can help diagnose performance drops and guide corrective actions. This framework requires overlapping support of the covariates, which may not always be applicable in practice. In such cases, one solution is to restrict to the common support .

Important extensions of this work include decompositions of more complex measures of model performance such as AUC and analyzing other factorizations of the data distribution (e.g. label/prior shifts ). For unstructured data (e.g. image and text), the current framework can be applied to low-dimensional embeddings or by extracting interpretable concepts ; more work is needed to directly analyze unstructured data. Finally, while the focus of this work is to interpret performance gaps, future work may take this work one step further to design optimal interventions for closing the performance gap.