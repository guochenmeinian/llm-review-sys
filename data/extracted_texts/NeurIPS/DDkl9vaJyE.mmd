# Brant: Foundation Model for

Intracranial Neural Signal

 Daoze Zhang

Zhejiang University

zhangdz@zju.edu.cn

&Zhizhang Yuan1

Zhejiang University

zhizhangyuan@zju.edu.cn

&Yang Yang2

Zhejiang University

yangya@zju.edu.cn

&Junru Chen

Zhejiang University

jrchen_cali@zju.edu.cn

&Jingjing Wang

Zhejiang University

wjjxjj@zju.edu.cn

&Yafeng Li

Nuozhu Technology Co., Ltd.

yafeng.li@neurox.cn

Equal contribution.Corresponding author.

###### Abstract

We propose a foundation model named Brant for modeling intracranial recordings, which learns powerful representations of intracranial neural signals by pre-training, providing a large-scale, off-the-shelf model for medicine. Brant is the largest model in the field of brain signals and is pre-trained on a large corpus of intracranial data collected by us. The design of Brant is to capture long-term temporal dependency and spatial correlation from neural signals, combining the information in both time and frequency domains. As a foundation model, Brant achieves SOTA performance on various downstream tasks (i.e. neural signal forecasting, frequency-phase forecasting, imputation and seizure detection), showing the generalization ability to a broad range of tasks. The low-resource label analysis and representation visualization further illustrate the effectiveness of our pre-training strategy. In addition, we explore the effect of model size to show that a larger model with a higher capacity can lead to performance improvements on our dataset. The source code and pre-trained weights are available at: https://zju-brainnet.github.io/Brant.github.io/.

## 1 Introduction

Brain signals are electrical impulses that are generated by brain neurons and transmit through neural networks. These signals provide important information about brain activity and can usually be monitored in two ways, namely scalp electroencephalography (EEG) and intracranial electroencephalography (iEEG). The former records the electrical brain activity through electrodes placed on the scalp, while the latter implants intracranial electrodes into brain tissue directly to derive neural recordings. Compared with EEG, iEEG manifests significant advantages by providing more abundant, stereotactic and detailed information about brain wave patterns from deeper brain structures, which has been the mainstream method to obtain deep brain information, and is essential in the therapies for some brain diseases (e.g., Parkinson's disease , epileptic seizure ).

Modeling intracranial recordings has drawn much research attention, but several issues still remain unresolved. Currently, studies for modeling intracranial recordings are mainly divided into two research lines, namely handcrafted feature based methods  and deep learning based methods . Handcrafted feature engineering requires lots of domain knowledge and may only work on specific tasks. And most deep learning based methods are fully supervised, which relies heavily onlabeled data. However, labeling data at scale in medical experiments is often infeasible or expensive, which underscores the importance of maximizing the label efficiency. To overcome these limitations, the paradigm of self-supervised pre-training followed by fine-tuning with few samples can greatly reduce the reliance on labels and enable the model to generalize to various downstream tasks.

Moreover, modeling intracranial recordings requires careful consideration of several key factors. (1) Long-term dependency. Since intracranial neural signals are time series and gradual changes in brain activity may only be captured by the long-period analysis , long-term temporal dependency is crucial in modeling intracranial data. (2) Spatial correlation. The electrodes implanted in the brain contain many contacts (also called channels), which are distributed across various brain regions. Due to the fact that brain waves propagate through different brain regions , signals recorded from different channels can be spatially correlated, reflecting the underlying neural activity. (3) Time and frequency domains. For neural recordings, the time domain provides information about the amplitude and duration while the frequency domain can reveal underlying oscillatory patterns and rhythms . Therefore, modeling neural signals in both domains can provide information more consistent with the neurophysiological mechanisms . To the best of our knowledge, no existing work on intracranial recordings considers all the three key factors simultaneously.

In view of the unresolved issues above, we propose a foundation model for intracranial neural signal named **Brain**Neural **T**ransformer (Brant). The design of our model takes all the three key factors (i.e., long-term dependency, spatial correlation, time and frequency domains) for intracranial signal modeling into account. Moreover, Brant contains more than 500M parameters and is pre-trained on a large intracranial dataset with 1.01 TB data, which can be adapted to accomplish various downstream tasks. Compared to other existing methods for modeling brain signals, Brant can achieve better performance with far fewer labeled samples, showing the great benefit of our work in medical scenarios. As an off-the-shelf model along with the code and weights, Brant can participate in other medical research and experiments, which alleviates the issue of sample and label efficiency.

To sum up, the main contributions of our work comprise:

* We propose a foundation model for intracranial neural signals named Brant, which is the largest model on brain signals (shown in Fig. 1) and pre-trained on a large intracranial dataset collected by us, providing a large-scale and off-the-shelf model for medicine.
* To our knowledge, Brant is the first to date that attends long-term dependency and captures spatial correlation across channels, while combining the information from both time and frequency domains.
* Extensive experiments show that Brant generalizes well to various downstream tasks, showing the great potential in neural recordings modeling. Further analysis illustrates the effectiveness of large-scale pre-trained model, demonstrating the medical value of our work.

## 2 Method

Model overview.As previously mentioned, we propose Brant to capture long-term dependency and spatial correlation from intracranial recordings, while combining the information from both time and frequency domains. Our model mainly consists of two Transformer encoders, namely, temporal encoder and spatial encoder (shown in Fig. 2). The temporal encoder encodes a sequence of \(L\) consecutive patches which focus on the temporal dependency, and the spatial encoder encodes \(C\) patches with the same time indices from all channels to capture their underlying spatial correlation.

Figure 1: The model scale of existing brain signal models, including RP , TS , CPC , BENDR , MVTS , BrainBERT , LGGNet , EEG-GCNN , BrainNet , SICR , SEEG-Net , and two works from Banville et al.  and Tang et al. .

During pre-training, we randomly mask the input signals recorded from the implanted electrodes, then linearly map the original signals to the latent space and add positional and frequency information through input encoding. Then the input encoding is encoded to latent representations and a linear projection head is added on the top of the spatial encoder which maps the representations to reconstruct the original signals. The details of our model and pre-training task are described as below.

**Patching.** Since neural recordings are electrical signals with high sampling rates, we aggregate timestamps into patches to (1) enhance the locality and extract semantic information; (2) reduce computation and memory usage; and (3) attend a longer temporal dependency . Specifically, given a neural signal \(^{N C}\), where \(N\) is the number of timestamps and \(C\) is the number of electrode channels, we divide \(\) with length \(M\) and stride \(S\) to generate a set of patches \(^{N_{p} C M}\), where \(N_{p}=\) is the number of patches in each channel.

**Frequency encoding.** We propose frequency encoding to explicitly inject the information on frequency domain to the observed data. The frequency encoding is mainly based on power spectral density (PSD) which describes the distribution of a signal's total average power over frequency (details about PSD are in App. A). To be specific, we split the frequency domain into several bands according to the standard description for rhythmic activity : (1) \(\) (4-8Hz), (2) \(\) (8-13Hz), (3) \(\) (13-30Hz), (4) \( 1\) (30-50Hz), (5) \( 2\) (50-70Hz), (6) \( 3\) (70-90Hz), (7) \( 4\) (90-110Hz), (8) \( 5\) (110-128Hz). For the \(i\)-th frequency band, a learnable encoding \(_{i}\) is set as its representation which is shared across all the patches. Then we compute the absolute spectral power of each patch \(p_{j,c},j=1,...,N_{p};c=1,...,C\) in the \(i\)-th frequency band:

\[P_{j,c}(i)=_{(i)}PSD_{p_{j,c}}(),\ \ i\{1,2,,8\},\] (1)

which acts as the weight of \(_{i}\). The frequency encoding \(_{j,c}^{D}\) of patch \(p_{j,c}\) is obtained as the weighted sum of the learnable encodings \(_{i}\):

\[_{j,c}=_{i=1}^{8}(i))}{_{i^{ }=1}^{8}(P_{j,c}(i^{}))}_{i}.\] (2)

**Encoding process.** It contains several steps to encode the input signal to latent representations. Specifically, the input \(_{j:j+L-1}^{L C M}\) contains \(L C\) patches and \(_{j:j+L-1,c}^{L M}\)

Figure 2: The pre-training framework of Brant. The collected intracranial neural recordings are first processed to a set of patches \(^{N_{p} C M}\) as the input. Then each time we mask a subset of patches \(_{j:j+L-1}\) and map the input patches to the hidden space while adding positional and frequency information to derive the input encoding \(}_{j:j+L-1}\). The temporal encoder encodes the input encoding in each channel to derive the temporal representations \(_{j:j+L-1}\). The spatial encoder encodes the temporal representations with the same time indices from all channels to obtain the final representations \(_{j:j+L-1}\). Then a linear head is used to obtain the reconstructed patches \(}_{j:j+L-1}\) from the final representations.

denotes the patches in \(c\)-th channel. We first map each sequence of patches \(_{j:j+L-1,c},c=1,...,C\) to the latent space of dimension \(D\) by a linear projection \(_{}^{D M}\), and the projected input will be added with a learnable positional encoding \(_{}^{L D}\) which monitors the temporal order of patches and the frequency encoding:

\[}_{j:j+L-1,c}=(_{}_{j:j+L-1,c}^{ {T}})^{}+_{}+_{j:j+L-1,c},\] (3)

where \(}_{j:j+L-1,c}^{L D}\) denotes the input encoding of the original signals \(_{j:j+L-1,c}\). The input encoding will be fed into the temporal encoder to obtain temporal hidden representations \(_{j:j+L-1,c}^{L D}\) and we denote the temporal representations of the whole input as \(_{j:j+L-1}^{L C D}\). The spatial encoder further captures the spatial correlation across channels, which takes each of the temporal representations \(_{k}^{C D},k=j,...,j+L-1\) as the input and outputs the final representations \(_{k}^{C D},k=j,...,j+L-1\). Overall, given the input signal \(_{j:j+L-1}\), the encoding process returns the corresponding latent representations \(_{j:j+L-1}^{L C D}\).

**Self-supervised pre-training.** Self-supervised representation learning is a powerful approach to extract high level abstract representation from unlabelled data. Among those methods to learn representation via self-supervised pre-training, masked autoencoder (MAE) has been proved to be a simple but effective way in many fields [27; 29; 30]. We apply this technique to our self-supervised pre-training, in which the model is trained to reconstruct the whole input given its partial observation.

Given the input patches \(_{j:j+L-1}\), we mask a subset of patches uniformly at random and encode the masked patches to the latent representations \(_{j:j+L-1}\). During the pre-training stage, the representations will be fed into a flatten layer with linear head \(_{}^{M D}\) to reconstruct the original patches. Finally we utilize an MSE loss to measure the discrepancy between the reconstructed patches \(}_{j:j+L-1}\) and the original patches \(_{j:j+L-1}\).

## 3 Experimental Setup

### Dataset

Pre-training dataset.Brant is pre-trained on 1.01 TB neural data, a large clinical intracranial neural signal dataset recorded by stereo-electroencephalography (SEEG) technique from a first-class hospital. The subjects undergo a surgical procedure to implant 4 to 11 invasive electrodes, each with 52 to 153 channels, in their brain. The dataset contains 2528 hours of 1000Hz recordings with more than 1 trillion timestamps. More details are in App. E. We down sample the original signals to 250Hz and generate a set of patches of 6s (1500 timestamps).

**Downstream dataset.** Another neural dataset collected by us with seizure labels is used to fine-tune and evaluate our model. It contains 29.39 GB data with 43 hours of 1000Hz intracranial recordings and we do the same preprocessing (i.e. down sampling and patching) to it as the pre-training dataset. Professional neurosurgeons participate in the labeling of epileptic seizures and the labels consist of two categories, namely, seizure and normal samples. More details are in App. E. For each downstream task, we sample a small subset from the downstream dataset for fine-tuning and evaluation.

### Pre-training

For the model configurations, the temporal encoder contains a 12-layer Transformer encoder with model dimension 2048, inner dimension (FFN) 3072 and 16 attention heads, and the spatial encoder contains a 5-layer Transformer encoder with model dimension 2048, inner dimension 3072 and 16 attention heads. During the pre-training, 40% patches in each input sample are masked with zero values uniformly at random. We take 16 input samples as a minibatch and each minibatch contains an average of 24k patches. The model is pre-trained on a Linux system with 2 CPUs (AMD EPYC 9654 96-Core Processor) and 4 GPUs (NVIDIA Tesla A100 80G) for about 2.8 days.

We optimize with Adam , updating the model parameters every 4 steps, and the model trains for 750k updates in total. A cyclic scheduler that adopts a basic triangular cycle without amplitude scaling is utilized to adjust learning rate during pre-training. Specifically, we set the basic learning rate as \(3 10^{-6}\) and the maximum learning rate as \(1 10^{-5}\), then the learning rate steps up (down)for every 8k updates. We apply mixed precision training with FP32 and BF16 to reduce the memory usage in GPUs for acceleration.

### Downstream tasks

As Brant is a foundation model for intracranial recordings, we conduct extensive experiments on several downstream tasks, including short- and long-term signal forecasting, frequency-phase forecasting, imputation and seizure detection, to verify the high capacity of our model in modeling intracranial recordings. We conduct each downstream task for Brant on two settings: (1) fine-tune the model with a learning rate of \(1 10^{-7}\); (2) freeze the pre-trained weights. Five random runs were performed to obtain the mean and standard deviation. The detailed setups of these downstream tasks are as follows:

Short- and long-term signal forecasting.Predictive observation of the neural signal values is beneficial for the development of warning systems for patients in need of precautionary measures [32; 33]. Therefore, we adopt short- and long-term signal forecasting, in which the learned representations are fine-tuned to predict future signals with different lengths given a past sequence. The past sequence length is set as 15 patches (90s) and the prediction lengths are set as 2 patches (12s) and 20 patches (120s) in short- and long-term forecasting, respectively. We sample 400 minutes of recordings from the downstream dataset, then randomly split into 320 minutes for fine-tuning and 80 minutes for evaluation. A linear prediction head is used to predict the future signals. We adopt MAE and MSE as the performance metrics.

Frequency-phase forecasting.In medicine, it is essential to predict the physical features like frequency and phase of brain signals to provide guidance for some treatments. For example, in a therapy that modulates brain activity called _transcranial alternating current stimulation_ (tACS), the stimulation control heavily depends on these knowledge about the target brain activity . Therefore, we set up the frequency-phase forecasting task in order for these therapies like tACS to be most effectively used in the treatment of brain disorders .

Given a past sequence, this task is to predict the _dominant frequency_ and _phase_ information (see details in App. B) of intracranial signals in the future. The past and prediction lengths are set as 15 patches (90s) and 5 patches (30s), respectively. We use the same sampling and split strategy as that in the short- and long-term signal forecasting to generate the data for the frequency-phase forecasting task. A linear layer is adopted to predict the dominant frequency and phase of the future signals. As for the metrics, following the work by Mansouri et al. , we use MAE for dominant frequency forecasting, and phase locking value (PLV) for phase forecasting. The PLV is a value between 0 and 1 calculated by the equation:

\[PLV=_{t=1}^{T}(i((t)-(t))),\] (4)

where \(\) and \(\) are the original signals and the forecasted signals, respectively.

**Imputation.** During brain signal recordings, measurement problems such as artifact contamination or electrode impairment are not easily corrected, thus the neural recordings will be incomplete. Imputation can fill in these contaminated signals so that other medical devices can keep operating under missing values, making use of available data . For the imputation task, we randomly mask the timestamps in each patch with the ratio of 40% and fine-tune the model to predict the missing values. We adopt the same sampling and split strategy to obtain the imputation data as in the short- and long-term signal forecasting. We add a linear head to make predictions, then apply MAE and MSE as the evaluation metrics to measure the discrepancy between the masked and predicted values.

Seizure detection.As one of the most important applications of intracranial recordings, seizure detection task is to evaluate the model ability to distinguish between epileptic seizures and normal waveforms. We sample 250 minutes of recordings from the downstream dataset with about 10% positive (seizure) samples, where 200 minutes are randomly selected for fine-tuning and the remaining 50 minutes for evaluation. An MLP is adopted to classify the pre-trained representations. The evaluation metrics we use are accuracy, precision, recall, \(F_{1}\) and \(F_{2}\) scores. The F-measure is a metric defined as the weighted harmonic mean of precision and recall, with the following equation \(F_{}=) precision recall}{^{2} precision +recall}\).

[MISSING_PAGE_FAIL:6]

but the results of Brant-Freeze are also better than most baselines. Especially on long-term forecasting, Brant-Freeze defeats all the baseline methods, showing the ability to capture long-term dependency of our model. Among the baselines, PatchTST  performs well compared to other methods, mainly because it also adopts a patching strategy to attend longer temporal dependency.

**Frequency-phase forecasting.** Forecasting physical features like frequency and phase of neural signal is essential in some medical techniques (see Sec. 3.3). The results of frequency-phase forecasting are shown on the right of Tab. 1, which shows that our model outperforms all the methods, demonstrating that Brant facilitates effective implementation of therapies for some brain disorders.

**Imputation.** As a mitigation for measurement problems, imputation can fill in the incomplete neural signals, allowing other medical devices to continue operating even when data is missing (see Sec. 3.3). From Tab. 2, Brant and Brant-Freeze achieve the best and the second best results among all the methods, which demonstrates the ability of our model in capturing underlying temporal patterns with partially observed neural recordings to imputate the contaminated neural signals.

**Seizure detection.** As seizure detection is an important medical application of intracranial recordings, we not only compare our model with the pre-training based baselines, but also further select 4 supervised method designed for seizure detection. From Tab. 3, Brant outperforms all the other methods and Brant-Freeze achieves second best on most of the metrics. BrainBERT  achieves the best accuracy, precision and F2 score among all the baseline methods, primarily due to it provides contextualized neural embeddings and combines the information from time and frequency domains like our model. However, Brant still improves the F2 score by 29.59% over BrainBERT, because our temporal encoder obtains a wider receptive field and the spatial encoder captures the spatial correlation across channels, which are both critical in modeling intracranial recordings.

   ModelTask &  \\  Model & MAE & MSE \\  RP  & 0.5953\(\)0.0008 & 0.9158\(\)0.0038 \\ TS  & 0.5225\(\)0.0008 & 0.7476\(\)0.0032 \\ CPC  & 0.5663\(\)0.0006 & 0.8271\(\)0.0034 \\ BENDR  & 0.4849\(\)0.0008 & 0.6492\(\)0.0031 \\ MVTS  & 0.5946\(\)0.0009 & 0.8903\(\)0.0032 \\ BrainBERT  & 0.6083\(\)0.0008 & 0.9790\(\)0.0026 \\  PatchTST  & 0.4282\(\)0.0007 & 0.5506\(\)0.0012 \\ TS-TCC  & 0.6144\(\)0.0008 & 1.0558\(\)0.0029 \\ TF-C  & 1.1876\(\)0.0014 & 3.0179\(\)0.0042 \\ CoST  & *0.2652\(\)0.0005 & *0.1638\(\)0.0007 \\  Brant-Freeze & 0.1963\(\)0.0005 & 0.0865\(\)0.0004 \\ Brant & **0.1912\(\)0.0003** & **0.0814\(\)0.0002** \\   

Table 2: Performance on the imputation task.

   ModelTask &  \\  Model & Accuracy & Precision & Recall & F1 & F2 \\  Spectral Power  & 89.01\(\)0.12 & 72.77\(\)1.98 & 36.07\(\)1.23 & 48.23\(\)0.57 & 40.12\(\)1.02 \\ Rhythmicity Spectrogram  & 88.58\(\)0.16 & 70.31\(\)2.09 & 37.07\(\)1.39 & 48.55\(\)0.60 & 39.10\(\)1.09 \\ Amplitude-integrated EEG  & 88.82\(\)0.19 & 71.21\(\)2.01 & 35.73\(\)1.50 & 47.58\(\)0.61 & 39.68\(\)1.12 \\ SEEG-Net & 88.97\(\)0.14 & 70.45\(\)2.20 & 38.44\(\)1.47 & *49.74\(\)0.60 & 42.28\(\)1.10 \\  RP  & 67.65\(\)1.21 & 18.62\(\)2.45 & 34.71\(\)2.11 & 24.24\(\)1.87 & 29.59\(\)1.97 \\ TS  & 85.90\(\)0.36 & 54.68\(\)3.65 & 31.66\(\)1.97 & 40.10\(\)0.81 & 34.57\(\)1.66 \\ CPC  & 84.72\(\)0.40 & 48.31\(\)2.80 & 36.03\(\)0.92 & 41.28\(\)0.66 & 37.96\(\)1.42 \\ BENDR  & 88.14\(\)0.68 & 71.49\(\)3.42 & 29.83\(\)2.03 & 42.10\(\)1.84 & 33.77\(\)1.81 \\ MVTS  & 88.35\(\)0.22 & 69.43\(\)3.19 & 32.03\(\)2.08 & 43.84\(\)1.96 & 35.90\(\)1.94 \\ BrainBERT  & *89.59\(\)0.12 & 77.86\(\)3.10 & 39.28\(\)0.88 & 52.21\(\)0.39 & *43.60\(\)0.98 \\  PatchTST  & 81.13\(\)0.22 & 38.71\(\)3.64 & 21.16\(\)2.21 & 27.37\(\)0.42 & 23.27\(\)1.26 \\ TS-TCC  & 88.13\(\)0.29 & 89.61\(\)2.08 & 23.81\(\)1.50 & 37.62\(\)0.40 & 27.91\(\)1.19 \\ TF-C  & 75.05\(\)0.61 & 18.75\(\)2.41 & 10.09\(\)2.02 & 18.92\(\)0.41 & 19.02\(\)1.24 \\ CoST  & 81.05\(\)0.15 & 30.98\(\)2.59 & *43.19\(\)1.88 & 36.08\(\)0.79 & 40.03\(\)1.88 \\  Brant-Freeze & 90.53\(\)0.33 & *77.26\(\)3.16 & 48.92\(\)0.72 & 59.87\(\)0.62 & 52.87\(\)0.47 \\ Brant & **91.17\(\)0.15** & **79.25\(\)2.32** & **52.74\(\)1.43** & **63.29\(\)0.37** & **56.50\(\)1.08** \\   

Table 3: Performance on the seizure detection task.

### Model Analysis.

Low-resource labeled data evaluation.In medical scenarios, collecting labeled data for even small experiments is a huge investment. To demonstrate the practical value of our work, we evaluate Brant on seizure detection where the amount of labeled data is limited. Specifically, the pre-trained model is fine-tuned on 200 minutes, 60 minutes and 20 minutes of labeled data that sampled from the downstream dataset (Sec. 3.1), respectively. After fine-tuning, models are evaluated on the same 50 minutes of labeled data which is also sampled from the downstream dataset but non-overlapped with the fine-tuning data.

From Tab. 4, the performances of supervised methods decrease rapidly compared to the self-supervised or unsupervised methods, showing that the representations learned on unlabeled data can improve low-resource settings. Among the pre-training works, our model maintains the most stable performance on 20-minute labeled data. Note that the F2 score of our model on 20-minute labeled data (51.03%) is even higher than the F2 score of the best baseline on 200-minute labeled data (43.60%), demonstrating that Brant fully captures the patterns and semantic information from the intracranial data during pre-training and adapts to downstream tasks more easily.

Representation analysis.As classification task can verify the model capacity in high-level representation learning , we visualize the pre-trained representations of Brant and 3 best pre-training based methods on seizure detection task using t-SNE (shown in Fig. 4). Compared to other methods, the representations of seizure and normal signals learned from Brant are separated more clearly during pre-training, which intuitively illustrates our SOTA performance on low-resource label settings. Furthermore, the results explain the good performance of Brant-Freeze on seizure detection.

    & 200 minutes &  &  \\   & F2 & F2 & Decrease & F2 & Decrease \\  Spectral Power  & 40.12\(\)1.02 & 25.95\(\)1.92 & 35.32\% & 5.06\(\)1.67 & 87.39\% \\ Rhythmicity Spectrogram  & 39.10\(\)1.09 & 21.87\(\)2.33 & 44.07\% & 2.81\(\)0.87 & 92.81\% \\ Amplitude-integrated EEG  & 39.68\(\)1.12 & 18.42\(\)2.34 & 53.58\% & 2.05\(\)0.95 & 94.84\% \\ SEEG-Net  & *42.28\(\)1.10 & 35.54\(\)1.90 & 15.94\% & 12.76\(\)2.13 & 69.82\% \\  RP  & 29.59\(\)1.97 & 27.62\(\)2.03 & *6.66\% & 25.05\(\)1.98 & 15.34\% \\ TS  & 34.57\(\)1.66 & 30.15\(\)3.05 & 12.79\% & 29.61\(\)3.34 & *14.35\% \\ CPC  & 37.96\(\)1.42 & 30.55\(\)3.01 & 19.52\% & 29.57\(\)3.74 & 22.10\% \\ BENDR  & 33.77\(\)1.81 & 25.37\(\)3.12 & 24.87\% & 22.18\(\)0.98 & 34.32\% \\ MVTS  & 35.90\(\)1.94 & 26.62\(\)1.11 & 25.58\% & 24.39\(\)1.01 & 32.06\% \\ BrainBERT  & 43.60\(\)0.98 & 41.93\(\)2.09 & 3.84\% & 36.35\(\)3.23 & 16.63\% \\  PatchTST  & 23.27\(\)1.26 & 18.02\(\)2.23 & 22.55\% & 17.07\(\)2.11 & 26.64\% \\ TS-TCC  & 27.91\(\)1.19 & 25.35\(\)2.07 & 9.17\% & 20.36\(\)1.90 & 27.05\% \\ TF-C  & 19.02\(\)1.34 & 15.97\(\)1.23 & 16.04\% & 13.66\(\)1.10 & 28.18\% \\ CoST  & 40.03\(\)1.88 & *39.18\(\)3.02 & **2.12**\% & 36.10\(\)4.12 & 9.82\% \\  Brant & **56.50\(\)1.08** & **52.30\(\)2.04** & 7.43\% & **51.03\(\)2.74** & **9.68**\% \\   

Table 4: Low-resource labeled data evaluation on the seizure detection task and the relative decrease of the F2 score on 60-minute and 20-minute labeled data versus 200-minute labeled data.

Figure 4: Pre-trained representation visualization of Brant and 3 best baselines on seizure detection task. The representations of seizure and normal samples are plotted in red (\(\)) and yellow (\(\)).

[MISSING_PAGE_FAIL:9]

Generalization ability analysis.To further verify the generalization ability of Brant on more subjects with more heterogeneity, we evaluated the model on data of 31 unseen subjects from two public datasets named MAYO and FNUSA . More details about this study are shown in App. G.

## 5 Related Work

Intracranial recordings modeling.With the development of iEEG technique to obtain deep brain information from both cortical and subcortical structures, modeling intracranial recordings has attracted the attention of many researchers. Wang et al.  extract time domain features of iEEG signals from multiple receptive fields by utilizing multiscale CNN and LSTM. Guo et al.  introduce a hypergraph learning approach to model iEEG signals by detecting high frequency oscillations. Yu and Hu  propose EDANN to learn domain-invariant representations of iEEG data from multiple subjects by domain adversarial training. Jiang et al.  develop a novel method using short-time resting-state connectivity to identify the seizure onset zone (SOZ) from intercital EEG signals. Wang et al.  conduct cross-subject iEEG seizure detection based on adaptive feature fusion of brain network features and single-channel features. However, these works are all supervised that relies heavily on labeled data, which is often difficult and expensive to obtain at scale. Furthermore, most works for intracranial data modeling process each channel independently, ignoring the spatial correlation. Although Chen et al.  propose BrainNet which contains a graph diffusion component which measures the brain wave diffusion among channels, their work only focus on the information in time domain and is limited to an individual subject.

Pre-training on brain signals.Pre-training on time series [37; 38; 27; 39] has shown good performance in many scenarios (e.g., weather, traffic flow, exchange rates), including some works designed for brain signals. Banville et al.  learn representations from EEG signals by a self-supervised temporal context prediction task, revealing clear latent structures related to physiological and clinical phenomena. Kostas et al.  address the problem of limited labeled data on EEG by using a contrastive self-supervised learning task to pre-train a model named BENDR, which is then fine-tuned for downstream tasks. Potter et al.  propose an unsupervised approach to model EEG signals using a transformer-based model with a signal reconstruction task. Cai et al.  propose to study the self-supervised learning framework for brain signals that can be applied to pre-train either scalp or intracranial EEG data. Wang et al.  propose a pre-training work named BrainBERT for intracranial recordings and conduct experiments on iEEG data. They adopt time-frequency representations but ignore the spatial correlation between channels, which is critial in modeling intracranial recordings (additional commentary on differences between our work and BrainBERT is in App. D).

## 6 Conclusion

We propose a task-agnostic foundation model, Brant, which learns powerful representations of intracranial recordings. Brant is the largest pre-training model on brain signals, whose design (1) attends a long temporal dependency; (2) captures the spatial correlation between channels; and (3) extracts information from both time and frequency domains. Experimentally, Brant achieves consistent SOTA performance on various downstream tasks w.r.t. medical scenarios. Further analysis shows the effectiveness and benefit of a large-scale pre-trained model in the field of medicine. Brant is an off-the-shelf model with its code and weights, which significantly alleviates the issue of sample and label efficiency and can directly participate in other medical research and treatment.

Limitations and future works.By pre-training on a large amount of intracranial data, Brant contains over 500M parameters, far more than other existing works on brain signals. However, compared to other fields such as CV and NLP in which the models can reach billions of parameters and achieve good performance on a variety of tasks by zero-shot learning, there is still potential for further improvement of our work. In the future, by scaling up our dataset, the scale of our model can be further expanded to capture higher-level semantic information from neural data, revealing more complicated brain activities and dynamics, to provide assistance for more healthcare applications.