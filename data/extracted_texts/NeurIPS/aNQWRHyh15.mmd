# In-and-Out: Algorithmic Diffusion for

Sampling Convex Bodies

 Yunbum Kook

School of Computer Science

Georgia Institute of Technology

yb.kook@gatech.edu

&Santosh S. Vempala

School of Computer Science

Georgia Institute of Technology

vempala@gatech.edu

&Matthew S. Zhang

Department of Computer Science,

University of Toronto,

matthew.zhang@mail.utoronto.ca

###### Abstract

We present a new random walk for uniformly sampling high-dimensional convex bodies. It achieves state-of-the-art runtime complexity with stronger guarantees on the output than previously known, namely in Renyi divergence (which implies TV, \(_{2}\), KL, \(^{2}\)). The proof departs from known approaches for polytime algorithms for the problem -- we utilize a stochastic diffusion perspective to show contraction to the target distribution with the rate of convergence determined by functional isoperimetric constants of the stationary density.

## 1 Introduction

Generating random samples from a high-dimensional convex body is a basic algorithmic problem with myriad connections and applications. The core of the celebrated result of , giving a randomized polynomial-time algorithm for computing the volume of a convex body, was the first polynomial-time algorithm for uniformly sampling convex bodies. In the decades since, the study of sampling has led to a long series of improvements in its algorithmic complexity , often based on uncovering new mathematical/geometric structure, establishing connections to other fields (e.g., functional analysis, matrix concentration) and developing new tools for proving isoperimetric inequalities and analyzing Markov chains. With the proliferation of data and the increasing importance of machine learning, sampling has also become an essential algorithmic tool, with applications needing samplers in very high dimension, e.g., scientific computing , systems biology , differential privacy  and machine learning .

Samplers for convex bodies are based on Markov chains (see SS5 for a summary). Their analysis is based on bounding the _conductance_ of the associated Markov chain, which in turn bounds the mixing rate. Analyzing the conductance requires combining delicate geometric arguments with (Cheeger) isoperimetric inequalities for convex bodies. An archetypal example of the latter is the following: for any measurable partition \(S_{1},S_{2},S_{3}\) of a convex body \(^{d}\), we have

\[(S_{3}),S_{2})}{C_{}}\{ (S_{1}),(S_{2})\}\,,\]

where \(d(,)\) is the (minimum) Euclidean distance, and \(C_{}\) is an isoperimetric constant of the uniform distribution over \(\). (The KLS conjecture posits that \(C_{}=(1)\) for any convex body \(\) in _isotropic position_, i.e., under the normalization that a random point from \(\) has identity covariance). The coefficient \(C_{}^{2}\) is bounded by the Poincare constant of the uniform distribution over \(\) (and they arein fact asymptotically equal). The classical proof of conductance uses geometric properties of the random walk at hand to reduce the analysis to a suitable isoperimetric inequality (see e.g., [3; 16]). The end result is a guarantee on the number of steps after which the total variation distance (TV distance) between the current distribution and the target is bounded by a desired error parameter. This framework has been widely used and effective in analyzing an array of candidate samplers, e.g., Ball walk , Hit-and-Run [17; 5], Riemannian Hamiltonian Monte Carlo  etc.

One successful approach, studied intensively over the past decade, is based on _diffusion_. The basic idea is to first analyze a continuous-time diffusion process, typically modeled by a _stochastic differential equation_ (SDE), and then show that a suitable time-discretization of the process, sometimes together with a Metropolis filter, converges to the desired distribution efficiently. A major success along this line is the Unadjusted Langevin Algorithm and its variants, studied first in . These algorithms have strong guarantees for sampling "nice" distributions [20; 21; 22; 23], such as ones that are strongly log-concave, or more generally distributions satisfying isoperimetric inequalities, while also obeying some smoothness conditions. The analysis of these algorithms is markedly different from the conductance approach, and typically yields guarantees in stronger metrics such as the \(\)-divergence.

Our starting point is the following question:

_Can diffusion-based approaches be used for the problem of sampling convex bodies?_

Despite remarkable progress, thus far, constrained sampling problems have evaded the diffusion approach, except as a high-level analogy (e.g., the Ball walk can be viewed as a discretization of Brownian motion, but this alone does not suggest a route for analysis) or with significantly worse convergence rates (e.g., [24; 25]).

Contributions.Our main finding is a simple diffusion-based algorithm that can be mapped to a stochastic process (and, importantly, to a pair of forward and backward processes), such that the rate of convergence is bounded directly by an appropriate functional inequality for the target distribution. As a consequence, for the first time, we obtain clean end-to-end guarantees in the Renyi divergence (which implies guarantees in other well known quantities such as \(_{2},,,^{2}\) etc.), while giving state-of-the-art runtime complexity for sampling convex bodies (e.g., Ball walk or Speedy walk [3; 4]). Besides being a stronger guarantee on the output, Renyi divergence is of particular interest for differential privacy . Perhaps most interesting is that our proof approach is completely different from prior work on convex body sampling. In summary,

* The guarantees hold for the \(q\)-Renyi divergences while matching the rates of previous work (prior work only had guarantees in the TV distance).
* The analysis is simple, modular, and easily extendable to several other settings.

Organization.In SS2, we provide some relevant notions for understanding our results. We then proceed to outline our algorithm in SS3. The algorithmic guarantees are provided in SS4, in which we also outline our proof and compare it with the analysis of Ball walk, Speedy walk. Lastly, we provide a detailed survey of the relevant literature in SS5 before concluding.

## 2 Preliminaries

Unless otherwise specified, we will use \(\|\|\) for the \(2\)-norm on \(^{d}\). We write \(a=(b)\), \(a b\) to mean that \(a cb\) for some universal constant \(c>0\). Similarly, \(a b\), \(a=(b)\) for \(a cb\), while \(a=(b)\) means \(a b,b a\) simultaneously. We will also use \(a=}(b)\) to denote \(a=(b(b))\). Lastly, we will use measure and density interchangeably when there is no confusion.

To quantify the convergence rate, we introduce some common divergences between distributions.

**Definition 1** (Distance and divergence).: For two measures \(,\) on \(^{d}\), the _total variation_ distance between them is defined by

\[\|-\|_{}:=_{B}|(B)-(B)|,\]

where \(\) is the collection of all measurable subsets of \(^{d}\). The _\(2\)-Wasserstein distance_ is given by

\[_{2}^{2}(,):=_{(,)}_{(X,Y )}[\|X-Y\|^{2}]\,,\]where \(\) is the set of all couplings between \(,\). Next, we define the _\(f\)-divergence_ of \(\) towards \(\) with \(\) (i.e., \(\) is absolutely continuous with respect to \(\)) as, for some convex function \(f:_{+}\) with \(f(1)=0\) and \(f^{}()=\),

\[D_{f}(\,\|\,):= f}{} \,\,.\]

The _\(\)-divergence_ arises when taking \(f(x)=x x\), the _\(^{q}\)-divergence_ when taking \(f(x)=x^{q}-1\), and the _\(q\)-Renyi divergence_ is given by

\[_{q}(\,\|\,):=^{q}(\,\|\, )+1\,.\]

**Definition 2**.: We say that a probability measure \(\) on \(^{d}\) satisfies a _Poincare inequality_ (PI) with parameter \(C_{}()\) if for all smooth functions \(f:^{d}\),

\[_{}f C_{}()\,_{}[\| f\|^ {2}]\,,\] (PI)

where \(_{}f_{}[|f-_{}f|^{2}]\).

The Poincare inequality is implied by the log-Sobolev inequality.

**Definition 3**.: We say that a probability measure \(\) on \(^{d}\) satisfies a _log-Sobolev inequality_ (LSI) with parameter \(C_{}()\) if for all smooth functions \(f:^{d}\),

\[_{}(f^{2}) 2C_{}()\,_{}[\|  f\|^{2}]\,,\] (LSI-I)

where \(_{}(f^{2}):=_{}[f^{2} f^{2}]-_{} [f^{2}](_{}[f^{2}])\). Equivalently, for any probability measure \(\) over \(^{d}\) with \(\),

\[2\,(\,\|\,) C_{}()\,(\,\|\, )\,,\] (LSI-II)

where \((\,\|\,):=_{}[\|} {}\|^{2}]\) is the _Fisher information_ of \(\) with respect to \(\).

## 3 Diffusion for uniform sampling

We propose the following \(\)-and-\(\)1 sampler for uniformly sampling from \(\). Each iteration consists of two steps, one that might leave the body and the second accepted only if it is (back) in \(\).

It might be illuminating for the reader to compare this algorithm to the well-studied Ball walk (Algorithm 2); each proposed step is a uniform random point in a fixed-radius ball around the current point, and is accepted only if the proposed point is in the body \(\). In contrast, each iteration of \(\)-and-\(\) is a two-step process, where the first step (Line 2) ignores the boundary of the body, and

Figure 1: Description of uniform samplers: (i) Ball walk: proposes a uniform random point \(z\) from \(B_{}(x_{1})\), but \(z\) so it stays at \(x_{1}=x_{2}\). (ii) Speedy walk: moves to \(x_{2}\) drawn uniformly at random from \( B_{}(x_{1})\). (iii) \(\)-and-\(\): first moves to \(y_{2}\) obtained by taking a Gaussian step from \(x_{1}\), and then to \(x_{2}\) obtained by sampling the truncated Gaussian \((y_{2},hI_{d})|_{}\).

the second step (Line 3) is accepted only if a proposal \(x_{i+1}\) is a feasible point in \(\). We will presently elaborate on the benefits of this variation.

Each successful iteration of the algorithm, i.e., one that is not declared "Failure", can be called a _proper_ step. We will see that the number of proper steps is directly bounded by isoperimetric constants (such as Poincare and log-Sobolev) of the target distribution. In fact, this holds quite generally without assuming the convexity of \(\). The implementation of an iteration is based on rejection sampling (Line 3), and our analysis of the efficiency of this step relies crucially on the convexity of \(\). This is reminiscent of the Speedy walk in the literature on convex body sampling (Algorithm 3), which is used as a tool to analyze proper steps of the Ball walk. We refer the reader to Appendix C for a brief survey on these and related walks.

This simple algorithm can be interpreted as a composition of "flows" in the space of measures. This view will allow us to use tools from stochastic analysis. In particular, we shall demonstrate how to interpret the two steps of one iteration of \(\)-and-\(\) as alternating _forward_ and _backward_ heat flows. We begin by defining an augmented probability measure on \(^{d}^{d}\) by

\[(x,y)-\|x-y\|^{2}\,_{ }(x)\,.\]

We denote by \(^{X},^{X|Y}(|y)\) the marginal distribution of its first component (resp. conditional distribution given the second component), and similarly denote by \(^{Y},^{Y|X}(|x)\) for the second component. In particular, the marginal in the first component \(^{X}\) is the uniform distribution over \(\). Sampling from such a joint distribution to obtain the marginal on \(X\) (say), can be more efficient than directly working only with \(^{X}\). This idea was utilized in Gaussian Cooling  and later as the restricted Gaussian Oracle (RGO) .

Under this notation, Algorithm 1 corresponds to a Gibbs sampling scheme from the two marginals of \((x,y)\). To be precise, Line 2 and Line 3 correspond to sampling from

\[y_{i+1}^{Y|X}(|x_{i})=(x_{i},hI_{d}) x_{i+1}^{X|Y}(|y_{i+1})=(y_{i+1},hI_{d})|_{ }\,.\]

We implement the latter step through rejection sampling; if the number of trials in Line 3 hits the threshold \(N\), then we halt and declare _failure_ of the algorithm. It is well known that such a Gibbs sampling procedure will ensure the desired stationarity of \((x,y)\). Note that, conditioned on the event that the algorithm does not fail, the resulting iterate will be an unbiased sample from the correct distribution.

Stochastic perspective: forward and backward heat flows.Our algorithm can be viewed through the lens of stochastic analysis, due to an improved analysis for the proximal sampling . This view provides an interpolation in continuous-time, which is simple and powerful. To make this concrete, we borrow an exposition from [28, SS8.3]. We denote the successive laws of \(x_{i}\) and \(y_{i}\) by \(_{i}^{X}\) and \(_{i}^{Y}\), respectively. Recall that the first step of sampling from \(^{Y|X}(|x_{i})\) (Line 2) yields \(_{i+1}^{Y}=^{Y|X=x}\,_{i}^{X}(x)\). This is the result of evolving a probability measure under _(forward) heat flow_ of \(_{i}^{X}\) for some time \(h\), given by the following stochastic differential equation: for \(Z_{0}_{i}^{X}\),

\[Z_{t}=B_{t}\] (FH)

where \(B_{t}\) is the standard Brownian process. We write \((Z_{t})=_{i}^{X}P_{t}\). In particular, \(Z_{h}=Z_{0}+_{i}^{X}*(0,hI_{d})=_{i+1}^{Y}\) for \((0,hI_{d})\). When \(_{i}^{X}=^{X}\), the first step of Algorithm 1 gives

\[^{Y}(y)=[^{X}*(0,hI_{d})](y)=( )\,(2 h)^{d/2}}_{}-\|y-x \|^{2}\,x\,.\] (3.1)The second step of sampling from \(^{X|Y}(|y_{i+1})\) can be represented by \(^{X}_{i+1}=^{X|Y=y}\,^{Y}_{i+1}(y)\) (Line 3). The continuous-time process corresponding to this step might not be obvious. However, let us consider (FH) with \(Z_{0}^{X}\). Then, \(Z_{h}^{Y}\), so the joint distribution of \((Z_{0},Z_{h})\) is simply \(\). This implies that \((Z_{0}|Z_{h}=y)^{X|Y=y}\). Imagine there is an SDE _reversing_ the forward heat flow in a sense that if we are initialized deterministically at \(Z_{h}_{y}\) at time \(0\), then the law of the SDE at time \(h\) would be \((Z_{0}|Z_{h}=y)=^{X|Y=y}\). Then, this SDE would serve as a continuous-time interpolation of the second step.

Such a _time reversal_ SDE is indeed possible! The following SDE on \((Z_{t}^{})_{t[0,h]}\) initialized at \(Z_{0}^{}^{Y}=^{X}P_{h}\) ensures \(Z_{h-t}(Z_{t}^{})=^{X}P_{h-t}\):

\[Z_{t}^{}=(^{X}P_{h-t})(Z_{t}^{}) \,t+B_{t}t[0,h]\,.\] (BH)

Although this is designed to reverse (FH) **initialized by \(Z_{0}^{X}\)** (so \(Z_{h}=Z_{0}^{}^{Y}\)), its construction also ensures that if \(Z_{0}^{}_{y}\), a point mass, then \(Z_{h}^{}(Z_{0}|Z_{h}=y)=^{X|Y=y}\). Thus, if we initialize (BH) with \(Z_{0}^{}^{Y}_{i+1}\), then the law of \(Z_{h}^{}\) corresponds to \(^{X|Y=y}\,^{Y}_{i+1}(y)=^{X}_{i+1}\).

_Remark 1_.: We note that \(\)-and-Out is exactly the _proximal_ sampling scheme  for uniform distributions. The proximal sampler with a target density proportional to \((-V(x))\) considers an augmented distribution \((x,y)(-V(x)-\|x-y\|^{2})\) and then repeats the following two steps: (1) \(y_{i+1}^{Y|X=x_{i}}=(x_{i},hI_{d})\) and then (2) \(x_{i+1}^{X|Y=y_{i+1}}\). Naively, the proximal sampler is implemented by performing rejection sampling, with the Gaussian centered at the minimizer of \(^{|Y=y_{i+1}}\) as the proposal. Realizing this would require a projection oracle (to \(\)), which is only known to be implementable with \((d^{2})\) membership queries. \(\)-and-Out completely avoids the need for a projection oracle.

## 4 Results

Our computational model is the classical general model for convex bodies . We assume \(()>0\) throughout this paper. Below, \(B_{r}(x)\) denotes the \(d\)-dimensional ball of radius \(r\) centered at \(x\).

**Definition 4** (Convex body oracle).: A _well-defined membership oracle_ for a convex body \(^{d}\) is given by a point \(x_{0}\), a number \(D>0\), with the guarantee that \(B_{1}(x_{0}) B_{D}(x_{0})\), and an oracle that correctly answers _YES_ or _NO_ to any query of the form "\(x\)?"

**Definition 5** (Warmness).: A distribution \(\) is _\(M\)-warm_ with respect to another distribution \(\) if for every \(x\) in the support of \(\), we have \((x) M\,(x)\).

We now summarize our main result, which is further elaborated in Appendix B.4 (Theorem 5). Below, \(^{}\) is the uniform distribution over \(\), and \(_{q}\) is the Renyi-divergence of order \(q\) (see Definition 1).

**Theorem 1** (Informal version of Theorem 5).: _For any given \(,(0,1)\), \(q 1\), and any convex body \(\) given by a well-defined membership oracle, there exist choices of parameters \(h,N\) such that \(\)-and-\(\), starting from an \(M\)-warm distribution, with probability at least \(1-\), returns \(X\) such that \(_{q}(\,\|\,^{})\). The number of proper steps is \(}(qd^{2}^{2})\), and the expected total number of membership queries is \(}(qMd^{2}^{6})\), where \(\) is the largest eigenvalue of the covariance of \(^{}\)._

_Remark 2_.: Despite our guarantee being in the much stronger "metric" of \(_{q}\) compared to the \(\) guarantees of Ball walk, we do not have to incur any additional asymptotic complexity.

To obtain this result, one should choose the following values for the parameters: \(h^{-1}=(d^{2})\), \(N=(^{5}(1/)}{})\). See Lemma 3 for more details.

    & Forward flow & Backward flow \\   SDE & \(Z_{t}=B_{t}\) & \(Z_{t}^{}=(^{X}P_{h-t})(Z_{t}^{})\, t+B_{t}\) \\  Fokker-Planck & \(_{t}_{t}=_{t}\) & \(_{t}_{t}^{}=-_{t}^{} (^{X}P_{h-t})+_{t}^{}\) \\   

Table 1: The Fokker-Planck equations for the forward and backward heat flow describe how the laws of \(Z_{t}\) and \(Z_{t}^{}\) in (FH) and (BH) evolve over time. See Appendix B.2 for details.

Finally, while the assumption of warmness for the initialization may seem strong at the outset, for well-rounded convex bodies (\(_{X}[\|X\|^{2}] C^{2}d\) for some constant \(C\)), it is possible to generate an \((1)\) warm-start with complexity \(}(d^{3})\). See  for details.

We note that for \(X^{}\),

\[\|(^{})\|_{}(( ^{}))=[\|X-X\|^{2}] D^{2}\,.\]

The above guarantee in the Renyi divergence immediately provides \(_{2},,\), and \(^{2}\) guarantees as special cases. For two distributions \(\) and \(\), we have

1. \((\,\|\,)=_{q 1}_{q}(\|\,) _{q}(\|\,)_{q^{}}(\|\,) _{}(\|\,)=}{}\), \(1<q q^{}\).
2. \(2\,\|-\|_{}^{2}(\,\|\,)(^{2 }(\,\|\,)+1)=_{2}(\,\|\,)\).
3. \(_{2}^{2}(,) 2C_{}()\,(\,\|\,)\) (Talagrand's \(_{2}\)-inequality) and \(C_{}(^{}) D^{2}\).
4. \(_{2}^{2}(,) 2C_{}()\,^{2}(\,\|\,)\) and \(C_{}(^{})\|(^{})\|_ {} d\).

The query complexity is better if the convex body is (near-)_isotropic_, i.e., the uniform distribution over the body has (near-)identity covariance. This relies on recent estimates of the worst-case Poincare constant for isotropic log-concave distributions . The condition that the convex body is isotropic can be achieved in practice through a _rounding_ procedure . See SS5 for more details.

**Corollary 1**.: _Assume that \(^{}\) is near-isotropic, i.e. the operator norm of its covariance is \((1)\). Under the same setting as above, \(\)-and-\(\) succeeds with probability \(1-\), returning \(X\) such that \(_{q}(\,\|\,^{})\). The number of proper steps is \(}(qd^{2}^{2})\), and the expected total number of membership queries is \(}(qMd^{2}^{6})\)._

Our analysis will in fact show that the bound on the number of proper steps holds for general _non-convex bodies_ and _any feasible start_ in \(\). This is deduced under an \(M\)-warm start in Corollaries 2 and 3. We remark that such a bound for non-convex uniform sampling is not known for the Ball walk or the Speedy walk.

**Theorem 2**.: _For any given \((0,1)\) and set \( B_{D}(0)\) with \(()>0\), \(\)-and-\(\) with variance \(h\) and \(M\)-warm initial distribution achieves \(_{q}(_{m}^{X}\,\|\,^{X})\) after the following number of iterations:_

\[m=qh^{-1}C_{}(^{X})&q 2\,,\\ qh^{-1}C_{}(^{X})&q 1\,.\]

We have two different convergence results above under (LSI-l) and (Pl). Under (LSI-l) we have a _doubly-logarithmic_ dependence on the warmness parameter \(M\). On the other hand, using (Pl), which is weaker than (LSI-l) (in general, \(C_{} C_{}\)), the dependence on \(M\) is logarithmic. We discuss implications of our results further in SS4.2.

### Outline of analysis.

We first record two fundamental lemmas, which introduce the mathematical formalism for our analysis. The first is the existence of forward and backward heat flows (Lemma 12), which will interpolate each line in Algorithm 1. These flow equations describe how the laws of \(Z_{t}\) and \(Z_{t}^{}\) in (FH) and (BH) evolve respectively over time. All proofs are deferred to Appendix B.

**Lemma 1**.: _The forward heat flow equation with initial distribution \(_{0}\) is given by_

\[_{t}_{t}=_{t}\,,\]

_and its backward heat flow equation is given by_

\[_{t}_{t}^{}=-\!(_{t}^{} (^{X}P_{h-t}))+_{t}^{} _{0}^{}=_{h}\,.\]

_These admit (weak) solutions on \([0,h]\) for any initial distribution \(_{0}\) with \(_{0}}{^{X}} M<\)._

One successful iteration of \(\)-and-\(\) is exactly the same as the composition of running the forward heat flow and then backward heat flow, both for time \(h\).

**Lemma 2**.: _Let \(_{k}^{X}\) be the law of the \(k\)-th iterate \(x_{k}\) of \(andOut}\). If (\(\)) is initialized with \((Z_{0})=_{k}^{X}\), then \((Z_{h})=_{k+1}^{Y}\). If (\(\)) is initialized with \((Z_{0}^{})=_{k+1}^{Y}\), then \((Z_{h}^{})=_{k+1}^{X}\)._

We summarize our proof strategy below, which requires us to demonstrate two facts: (i) The current distribution should converge to the uniform distribution, (ii) within each iteration of the algorithm, the failure probability and the expected number of rejections should be small enough. In this section we provide the main claims within each of these parts, and defer the remaining details to Appendix B.

While each individual component resembles pre-existing work in the literature, in their synthesis we will demonstrate how to interleave past developments in theoretical computer science, optimal transport, and functional analysis. The combination of these in this domain yields elegant and surprisingly simple proofs, as well as stronger results.

Part (i).Broadly speaking, we need to demonstrate that the corresponding Markov chain is rapidly mixing. Here, we use the heat flow perspective to derive mixing rates under any suitable divergence measure (such as \(\), \(^{2}\), or \(_{q}\)). This extends known results for the unconstrained setting . To summarize the proof, by considering instead the solutions after small time \(t\), we invoke known contraction results from  and then use a continuity argument to conclude the proof.

**Theorem 3**.: _Let \(_{k}^{X}\) be the law of the \(k\)-th output of \(andOut}\) with initial distribution \(_{0}^{X}\). Let \(C_{}\) be the (\(\)-) constant of the uniform distribution \(^{X}\) over \(\). Then, for any \(q 1\),_

\[_{q}(_{k}^{X}^{X})_{q}(_{0} ^{X}^{X})}{(1+h/C_{})^{2k/q}}\,.\]

_For \(C_{}\) the (\(\)) constant of \(^{X}\),_

\[^{2}(_{k}^{X}^{X})(_{0}^{X} ^{X})}{(1+h/C_{})^{2k}}\,.\]

_Furthermore, for any \(q 2\),_

\[_{q}(_{k}^{X}^{X})_{q}( _{0}^{X}^{X})-})}{q}&k_{q}(_{0}^{X}^{X})-1)}{2(1+h/C_{ })}\,,\\ (1+h/C_{})^{-2(k-k_{0})/q}&k k_{0}:=_{q}(_{0}^{X}^{X})-1)}{2(1+h/C_{})} .\]

The final result reduces the problem of obtaining a mixing guarantee to that of demonstrating a functional inequality on the target distribution. For this, it is not strictly necessary that \(\) be convex.

Part (ii).Convexity of \(\) is crucial this time unlike Part (i). We show in Appendix B.3 that the failure probability remains under control by taking a suitable variance \(h\) and threshold \(N\), and that the expected number of trials per iteration is of order \( N\), not \(N\). To do this, we apply a detailed argument involving local conductance and the convexity of \(\), which relies on techniques from .

**Lemma 3** (Per-iteration guarantees).: _Let \(\) be any convex body in \(^{d}\) presented by a well-defined membership oracle, \(^{X}\) the uniform distribution over \(\), and \(\) an \(M\)-warm initial distribution with respect to \(^{X}\). For any given \(m\) and \((0,1)\), set \(Z=( 9)\), \(h=}\) and \(N=Z^{4}Z=}()\). Then, the failure probability of one iteration of \(andOut}\) is at most \(/m\), and the expected membership queries per iteration is \(M^{4}\)._

### Discussion

No need to be lazy.Previous uniform samplers like \(\) are made _lazy_ (i.e., with probability \(1/2\), it does nothing), to ensure convergence to the target stationary distribution. However, our algorithm does not need this, as our sampler is shown to directly contract towards the target.

Unified framework.We remark that Theorem 2 places the previously known mixing guarantees for \(\), \(\) in a unified framework. Existing tight guarantees for \(\) are in TV distance and based on the log-Sobolev constant, assuming an oracle for implementing each step .

The known convergence guarantees of Ball walk (see Appendix C for details), namely the mixing time of \(}(Md^{2}D^{2})\) for TV distance, are for the composite algorithm [Speedy walk\(+\)rejection sampling]. Here Speedy walk records only the accepted steps of Ball walk, so its stationary distribution differs slightly from the uniform distribution (and can be corrected with a post-processing step). On the other hand, In-and-Out actually converges to \(^{}\) without any adjustments and achieves stronger Renyi divergence bounds in the same asymptotic complexity. Our analysis shows that the mixing guarantee is determined by isoperimetric constants of the target (Poincare or log-Sobolev).

Effective step size.The Ball walk's largest possible step size is of order \(1/\) (see Appendix C) to keep the rejection probability bounded by a constant. This bound could also be viewed as an "effective" step size of In-and-Out, since the \(_{2}\)-norm of the Gaussian \((0,hI)\) is concentrated around \(\) and we will set the variance \(h\) of In-and-Out to \(}(1/d^{2})\), so we have \( 1/\).

What has really changed?In-and-Out has clear similarities to both Ball walk and Speedy walk. What then are the changes that allow us to use continuous-time interpolation? One step of Ball walk is [random step (\(y B_{}(x)\)) + Metropolis-filter (accept if \(y\))]. This filtering is an abrupt discrete step, and it is unclear how to control contraction. It could be replaced by a step of Speedy walk (\(x(B_{}(y))\)). Then, each iteration of In-and-Out can be viewed as a Gaussian version of a Ball walk's proposal\(+\)Speedy walk algorithm.

How can we compare In-and-Out with Speedy walk? Iterating speedy steps leads to a biased distribution. As clarified in Remark 3, one step of (a Gaussian version of) Speedy walk can be understood as a step of backward heat flow. Therefore, if one can control the isoperimetric constants of the biased distribution along the trajectory of the backward flow, then contraction of Speedy walk toward the biased distribution will follow from the simultaneous backward analysis.

## 5 Related work

Sampling from constrained log-concave distributions is a fundamental task arising in many fields. Uniform sampling with convex constraints is its simplest manifestation, which was first studied as a core subroutine for a randomized volume-computation algorithm . Since then, this fundamental problem has been studied for over three decades [2; 3; 4; 38; 5; 25; 24]. We review these algorithms, grouping them under three categories -- geometric random walks, structured samplers, and diffusion-type samplers. Below, \(\) is convex.

Geometric random walk.We discuss two geometric random walks - Ball walk[3; 4] and Hit-and-Run [39; 17]. Ball walk is a simple metropolized random walk; it draws \(y\) uniformly at random from a ball of radius \(\) centered at a current point \(x\), and moves to \(y\) if \(y\) and stays at \(x\) otherwise. In the literature, Ball walk actually refers to a composite algorithm consisting of [Speedy walk\(+\) rejection sampling], where Speedy walk records only the accepted steps of Ball walk (see Appendix C for details). The step size \(\) should be set to \((d^{-1/2})\) to avoid stepping outside of \(\).  showed that Ball walk needs \(}(Md^{2}D^{2})\) membership queries to be \(\)-close to \(^{}\) in TV, where \(D\) is the diameter of \(\), and the warmness parameter \(M\) measures the closeness of the initial distribution to the target uniform distribution \(^{}\).

Hit-and-Run is another zeroth-order algorithm that needs _no step size_; it picks a uniform random line \(\) passing a current point, and move to a uniform random point on \(\).  shows that, if we define the second moment as \(R^{2}:=_{X^{}}[\|X-X\|^{2}]\), then Hit-and-Run requires \((d^{2}R^{2})\) queries. Notably, this algorithm has a poly-logarithmic dependence on \(M\) as opposed to Ball walk.

Both algorithm are affected by skewed shape of \(\) (i.e., large \(D\) or \(R\)), so these samplers are combined with pre-processing step called _rounding_. This procedure finds a linear transformation that makes the geometry of \(\) less skewed and so more amenable to sampling. In literature, there exists a randomized algorithm  that rounds \(\) and generates a good warm start (i.e., \(M=(1)\)), with Ball walk used as a core subroutine. This algorithm takes up \(}(d^{3.5})\) queries in total, and in such position with the good warm start, Ball walk only needs \(}(d^{2})\) queries to sample from \(^{}\).

Structured samplers.The aforementioned samplers based on geometric random walks require _only_ access to the membership oracle of the convex body _without_ any additional structural assumptions.

The alternate paradigm of _geometry-aware sampling_ attempts to exploit the _structure_ of convex constraints, with the aim of expediting the convergence of the resultant sampling schemes. One common assumption is to make available a _self-concordant barrier function_\(\) which has regularity on its high-order derivatives and blows up when approaching the boundary \(\). The Hessian of \(\) encodes the local geometry of the constraint, and the samplers often work directly with \(^{2}\).

The first canonical example of such a zeroth-order sampler is Dikin walk used when \(\) is given by \(m\) linear constraints ; it draws a uniform sample from an ellipsoid (characterized by \(^{2}\)) of fixed radius around a current point, and is often combined with a Metropolis adjustment.  shows that Dikin walk mixes in \((md)\) steps, although each iteration is slightly more expensive than one membership query. This algorithm requires no rounding, but still needs a good warm-start, which can be achieved by an annealing-type algorithm using \(}(md)\) iterations of Dikin walk .

Riemannian Hamiltonian Monte Carlo is a structured sampler that exploits the first-order information of the potential (i.e., \((1/)\)) ; its proposal is given as the solution to the Hamilton's ODE equation, followed by the Metropolis-filter. In the linear-constraint setting above, it requires \((md^{2/3})\) many iterations to achieve \(\)-close distance to \(^{}\). This sampler is further analyzed for practical ODE solvers  and for more sophisticated self-concordant barriers .

Similarly, Mirror Langevin  is a class of algorithms which converts the constrained problem into an unconstrained one obtained by considering the pushforward of the constrained space by \(\). The algorithm can also be metropolized . The best known rate for this algorithm is \(}(d)\) under some strong assumptions on \(\).

Diffusion-type samplers.Samplers based on discretizations of Ito diffusions, stochastic processes which rapidly mix to \(\) in continuous time, have long been used for sampling without constraints . While the underlying stochastic processes generalize easily to constrained settings, the discretization analysis relies crucially on the smoothness of the target distribution. This is clearly impossible to achieve in the constrained setting, so some techniques are required to circumvent this difficulty. These algorithms, however, generalize easily to the more general problem of sampling from distributions of the form \(^{X} e^{-7}_{}\), by incorporating first order information from \(f\).

The first approach for adapting diffusion-based samplers  iterates a two-step procedure. First, a random step is taken, with \(x_{k+1/2}(x_{k},2hI_{d})\) for some appropriately chosen step \(h\),2 and then project it to \(\), i.e., \(x_{k+1}=_{}(x_{k+1/2})\). The complexity is given in terms of queries to a _projection oracle_, each call to which can be implemented with a polynomial number of membership oracle queries; a total of \(}(d^{2D^{3}}/^{4})\) queries are needed to be \(\)-close in \(_{2}\) to \(^{X}\). Another approach, which uses an algorithmically designed "soft" penalty instead of a projection, was proposed in , and achieves a rate estimate of \(}(}{{^{10}}})\).

A second approach, suggested by , considers a different proximal scheme, which performs a "soft projection" onto \(\), by taking steps like \(((1-h^{-1})x_{k}+h_{}(x_{k}),2hI_{d})\). It is called Moreau-Yosida regularized Langevin, named after an analogous regularization scheme for constrained optimization. This scheme also relies on access to a projection oracle for \(\), and quantifies their query complexity accordingly. Their final rate estimate is \(}(d^{}{{}}}/^{}}{{}}})\) to be \(\)-close in \(\) distance to \(^{X}\).

Observing the prior work integrating diffusion-based sampling with convex constraints, the dependence on the key parameters \(d,\), while polynomial, are many orders worse than the rates for zeroth-order samplers such as Ball walk, Hit-and-Run. In contrast, our analysis not only recovers but in some sense surpasses the known rates for Ball walk, Hit-and-Run, while harmonizing well with the continuous-time perspective of diffusions.

Proximal schemes for sampling.The Gibbs sampling scheme used in this paper was inspired by the restricted Gaussian oracle introduced in  (in turn inspired by Gaussian Cooling ), which alternately iterates between a pure Gaussian step, and a "proximal" step (which we elaborate in our exposition). This scheme was given novel interpretations by , which showed that it interpolates the forward and backward heat flows, in the sense defined by . The backward heat flow itself is intimately related to stochastic localization schemes, invented and popularized in .

This formulation proved surprisingly powerful, allowing many existing rates in unconstrained sampling to be recovered from a relatively simple analysis. This was further extended by  to achieve the current state-of-the-art rate in unconstrained sampling. Finally,  suggest that this could be applied to tackle some constrained problems. However, the assumptions in this final mentioned work are not compatible with the uniform sampling problem on general convex bodies.

## 6 Conclusion

We propose \(\)-and-Out for uniform sampling on convex bodies, and show that it obtains guarantees in \(_{q}\) divergence from an \(M\)-warm start, substantially stronger than prior work, and without increasing the computational complexity. Notably, our proof technique is quite different and provides a direct reduction to isoperimetric constants of the target distribution.

While the current work focuses on uniform sampling of convex bodies, there are a number of natural extensions that may be considered. It may be possible to prove analogous results for general log-concave distributions, and on non-log-concave distributions satisfying isoperimetric inequalities, e.g., it is open to find a polytime algorithm for sampling a general distribution satisfying a Poincare inequality presented by a function oracle (with no smoothness assumptions).

Acknowledgements.We are deeply grateful to Andre Wibisono and Sinho Chewi for helpful comments and pointers to the literature for Lemma 10. This work was supported in part by NSF award 210644, NSERC through the CGS-D award, and a Simons Investigator award.