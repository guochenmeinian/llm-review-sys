# Zero-shot causal learning

Hamed Nilforoshan Michael Moor Yusuf Roohani Yining Chen1

Anja Surina Michihiro Yasunaga Sara Oblak Jure Leskovec

Equal contribution. Code is available at: [https://github.com/snap-stanford/caml/](https://github.com/snap-stanford/caml/)

Equal contribution. Code is available at: [https://github.com/snap-stanford/caml/](https://github.com/snap-stanford/caml/)

Equal contribution. Code is available at: [https://github.com/snap-stanford/caml/](https://github.com/snap-stanford/caml/)

###### Abstract

Predicting how different interventions will causally affect a specific individual is important in a variety of domains such as personalized medicine, public policy, and online marketing. There are a large number of methods to predict the effect of an existing intervention based on historical data from individuals who received it. However, in many settings it is important to predict the effects of novel interventions (e.g., a newly invented drug), which these methods do not address. Here, we consider zero-shot causal learning: predicting the personalized effects of a novel intervention. We propose CaML, a causal meta-learning framework which formulates the personalized prediction of each intervention's effect as a task. CaML trains a single meta-model across thousands of tasks, each constructed by sampling an intervention, its recipients, and its nonrecipients. By leveraging both intervention information (e.g., a drug's attributes) and individual features (e.g., a patient's history), CaML is able to predict the personalized effects of novel interventions that do not exist at the time of training. Experimental results on real world datasets in large-scale medical claims and cell-line perturbations demonstrate the effectiveness of our approach. Most strikingly, CaML's zero-shot predictions outperform even strong baselines trained directly on data from the test interventions.

## 1 Introduction

Personalized predictions about how an intervention will causally affect a specific individual are important across many high impact applications in the physical, life, and social sciences. For instance, consider a doctor deciding whether or not to prescribe a drug to a patient. Depending on the patient, the same drug could either (a) cure the disease, (b) have no effect, or (c) elicit a life-threatening adverse reaction. Predicting which effect the drug will have for each patient could revolutionize healthcare by enabling personalized treatments for each patient.

The causal inference literature formalizes this problem as conditional average treatment effects (CATE) estimation, in which the goal is to predict the effect of an intervention, conditioned on patient characteristics (\(X\)). When natural experiment data is available, consisting of individuals who already did and did not receive an intervention, a variety of CATE estimators exist to accomplish this task . These methods can then predict the effect of an _existing_ intervention (\(W\)) on a new individual (\(X^{}\)).

However, in many real-world applications natural experiment data is entirely unavailable, and yet CATE estimation is critical. For instance, when new drugs are discovered, or new government policiesare passed, it is important to know the effect of these novel interventions on individuals and subgroups in advance, i.e., before anybody is treated. There is thus a need for methods that can predict the effect of a _novel_ intervention (\(W^{}\)) on a new individual (\(X^{}\)) in a zero-shot fashion, i.e., without relying on _any_ historical data from individuals who received the intervention.

Generalizing to novel interventions is especially challenging because it requires generalizing across two dimensions simultaneously: to new interventions and new individuals. This entails efficiently "aligning" newly observed interventions to the ones previously observed in the training data.

**Present work.** Here, we first formulate the zero-shot CATE estimation problem. We then propose CaML (**C**ausal **M**eta-**I**earning), a general framework for training a single meta-model to estimate CATE across many interventions, including novel interventions that did not exist at the time of model training (Figure 1). Our key insight is to frame CATE estimation for each intervention as a separate meta-learning task. For each task observed during training, we sample a retrospective natural experiment consisting of both (a) individuals who did receive the intervention, and (b) individuals who did not receive the intervention. This natural experiment data is used to estimate the effect of the intervention for each individual (using any off-the-shelf CATE estimator), which serves as the training target for the task.

In order to achieve zero-shot generalization to new interventions, we include information (\(W\)) about the intervention (e.g., a drug's attributes), in the task. We then train a single meta-model which fuses intervention information with individual-level features (\(X\)) to predict the intervention's effect. Our approach allows us to predict the causal effect of novel interventions, i.e., interventions without sample-level training data, such as a newly discovered drug (Figure 1). We refer to this capability as _zero-shot causal learning_.

In our experiments, we evaluate our method on two real-world datasets--breaking convention with the CATE methods literature which typically relies on synthetic and semi-synthetic datasets. Our experiments show that CaML is both scalable and effective, including the application to a large-scale medical dataset featuring tens of millions of patients. Most strikingly, CaML's zero-shot performance exceeds even strong baselines that were trained directly on data from the test interventions. We further discover that CaML is capable of zero-shot generalization even under challenging conditions: when trained only on single interventions, at inference time it can accurately predict the effect of combinations of novel interventions. Finally, we explain these findings, by proving a zero-shot generalization bound.

## 2 Related work

We discuss recent work which is most closely related to zero-shot causal learning, and provide an extended discussion of other related work in Appendix B. Most CATE estimators do not address novel interventions, requiring that all considered interventions be observed during training. A notable exception is recent methods which estimate CATE for an intervention using structured information about its attributes [25; 35]. In principle, these methods can also be used for zero-shot predictions. These methods estimate CATE directly from the raw triplets \((W,X,Y)\), without considering natural experiments, by tailoring specific existing CATE estimators (the S-learner  and Robinson decomposition , respectively) to structured treatments. The main drawback of these approaches is that they are inflexible, i.e., they are restricted to using a single estimator and are unable to take advantage of the recent advances in the broader CATE estimation literature (e.g., recently developed binary treatment estimators [16; 21; 40]). This is a limitation because any single CATE estimator can be unstable across different settings . Notably, the estimators which these methods build on have already been shown to result in high bias in many domains [44; 37; 10; 16]. Likewise, we find that these methods struggle with zero-shot predictions (Section 6). CaML's key difference from prior work is that we construct a separate task for each training intervention by synthesizing natural experiments. This allows us to (a) flexibly wrap any existing CATE estimator to obtain labels for each task, and thus take advantage of the most recent CATE estimation methods and (b) leverage meta-learning, which requires task-structured data. Consequently, CaML is able to achieve strong zero-shot performance (Section 6).

## 3 Background: single-intervention CATE estimation

Each task in the CaML framework consists of estimating conditional average treatment effects (CATEs) for a single binary treatment. In this section, we first provide background on CATEestimation under this simple case of a single treatment (\(W\)) and outcome (\(Y\)), and subsequently generalize it to our zero-shot setting. Under a single intervention and outcome, we consider \(n\) independent observations \(P_{1},,P_{n}\) drawn from a distribution \(\). For unit \(i=1,...,n\), \(P_{i}=(W_{i},X_{i},Y_{i})\) collects: a binary or continuous outcome of interest \(Y_{i}\), instance features (i.e., pre-treatment covariates) \(X_{i}^{d}\), and a treatment-assignment indicator \(W_{i}\{0,1\}\). We use the Neyman-Rubin potential outcomes framework , in which \(Y_{i}(1),Y_{i}(0)\) reflect the outcome of interest either under treatment (\(W_{i}=1\)), or under control (\(W_{i}=0\)), respectively. In our running medical example, \(Y_{i}(1)\) is the health status if exposed to the drug, and \(Y_{i}(0)\) is the health status if not exposed to the drug. Notably, the _fundamental problem of causal inference_ is that we only observe one of the two potential outcomes, as \(Y_{i}=W_{i} Y_{i}(1)+(1-W_{i}) Y_{i}(0)\) (e.g., either health status with or without drug exposure can be observed for a specific individual, depending on whether they are prescribed the drug). However, it is possible to make personalized decisions by estimating treatment effects that are tailored to the attributes of individuals (based on features \(X\)). Thus, we focus on estimating \((x)\), known as the conditional average treatment effect (CATE):

\[=(x)=_{}Y(1)-Y(0) X=x \]

A variety of methods have been developed to estimate \((x)\) from observational data . These rely on standard assumptions of unconfoundedness, consistency, and overlap . _Unconfoundedness_: there are no unobserved confounders, i.e. \(Y_{i}(0),Y_{i}(1) W_{i} X_{i}\). _Consistency_: \(Y_{i}=Y_{i}(W_{i})\), i.e. treatment assignment determines whether \(Y_{i}(1)\) or \(Y_{i}(0)\) is observed. _Overlap_: Treatment assignment is nondeterministic, such that for all \(x\) in support of \(X\): \(0<P(W_{i}=1 X_{i}=x)<1\).

## 4 Zero-shot causal learning

In many real-world settings (_e.g._ drugs, online A/B tests) novel interventions are frequently introduced, for which no natural experiment data are available. These settings require zero-shot CATE estimates. The zero-shot CATE estimation problem extends the prior section, except the intervention variable \(W_{i}\) is no longer binary, but rather contains rich information about the intervention: \(W_{i}^{e}\) (e.g., a drug's chemistry), where \(W_{i}=0\) corresponds to a sample that did not receive any intervention. Thus, each intervention value \(w\) has its own CATE function that we seek to estimate:

\[_{w}=_{w}(x)=_{}Y(w)-Y(0) X=x , \]

During training, we observe \(n\) independent observations \(P_{1},,P_{n}\) drawn from a distribution \(\). Each \(P_{i}=(W_{i},X_{i},Y_{i})\). Let \(_{seen}\) be set of all interventions observed during training. The zero-shot CATE estimation task consists of estimating CATE for a novel intervention that was never observed during training:

_Problem 1_ (Zero-shot CATE estimation).: **Given**\(n\) training observations \((W_{1},X_{1},Y_{1}),,(W_{n},X_{n},Y_{n})\) drawn from \(\) containing intervention information, individual features, and outcomes... **estimate**\(_{w^{}}(x)\) for a novel intervention \(w^{}_{seen}\).

This problem formulation extends in a straightforward manner to combinations of interventions, by allowing a single intervention \(W_{i}\) to consist of a set of intervention vectors. CaML supports combinations of interventions, as we elaborate on in Section 4.1

Figure 1: Overview of the zero-shot causal learning problem. Each individual has features (\(X\)), an intervention with features (\(W\)), and an outcome (\(Y\)). Lightning bolts represent interventions (_e.g._ drugs). The personalized effect of an intervention (\(\)) is always unobserved. The goal is to predict the \(\) for a novel intervention (\(W^{}\)) and individual (\(X^{}\)) that did not exist during training.

**CaML overview.** We propose a novel framework for estimating CATE across multiple interventions, even including ones that were never encountered during training. Our framework consists of three key components (Figure 2). First, we formulate CATE estimation as a meta-learning problem in which each task corresponds to the CATE estimation for a unique intervention. A task dataset for a given intervention is constructed by sampling a natural experiment of all individuals who received the intervention, and a sample of individuals who did not. Tasks are augmented with intervention information (\(W\)). Synthesizing these natural experiments allows us to compute a noisy CATE label \(\) using any off-the-shelf estimator (\(\) is referred to as pseudo-outcomes by the causal inference literature ). Finally, we train a single meta-model to predict these labels using individual-level (\(X\)) and intervention-level (\(W\)) information, such that it is able to generalize to novel tasks, i.e., estimating CATE for novel interventions.

The CaML framework incorporates three important design considerations: _(1) Single meta-model_. In domains such as electronic health records and online marketing, we observe that large-scale datasets contain thousands of interventions with rich feature information (\(W\)). Instead of training a separate model for each intervention, CaML trains a single meta-model that can estimate CATE across all interventions. This approach lets us leverage shared structure across tasks and generalize to novel interventions that were not present during training. _(2) Pseudo-outcomes_. Instead of directly modeling the response surfaces \([Y(w) X=x]\) and \([Y(0) X=x]\), we use pseudo-outcomes for each intervention to train our model. This approach is informed by recent studies indicating bias in estimating CATE from direct predictions of observed outcomes . CaML outperforms strong baselines that meta-learn \(Y(w)\) and \(Y(0)\) directly, as demonstrated in our experiments (see Tables 2 and 3, rows S-learner and T-learner with meta-learning). _(3) Discrete tasks from continuous interventions_. CaML takes advantage of the extensive literature on CATE estimation for single, binary interventions. By creating a natural experiment for each intervention, CaML taps into this literature and benefits from the high performance of recently developed nonparametric CATE estimators .

CaML identifies CATE for novel interventions under the assumptions that: (1) for each observed intervention \(w\), \(_{w}(x)\) is identifiable under the binary treatment assumptions (unconfoundedness, consistency, and overlap) in Section 3. This allows for valid training labels for each task. (2) \(_{w}(x)=(w,x)\), i.e., a global function \((w,x)\) unifies all intervention-specific CATE functions, (3) \((w,x)\) is continuous in \(w\). This allows the model to smoothly extrapolate the treatment effect to new interventions that are close to observed interventions in the intervention space. Lastly, (4) \(W\) follows a continuous distribution.

### Meta-dataset

We formulate CATE estimation as a meta-learning problem. For this, each task refers to CATE estimation for a distinct intervention. Interventions as well as tasks in our meta-dataset are jointly indexed by \(j\) with \(1 j K\), such that we can refer to the \(j\)-th intervention information with \(w^{(j)}\).

Figure 2: Visual illustration of the CaML (causal meta-learning) framework. (1) We sample a task (i.e., an intervention) and a natural experiment from the training data consisting of individuals who either received the intervention (W={\(|\)}), or did not (W={\(\}\)). Each individual has features (\(X\)) and an outcome (\(Y\)), and the intervention also has information (\(W\)) (e.g., a drug’s attributes). (2) For each individual we estimate the effect of the intervention on the outcome (pseudo-outcomes \(\)). (3) We predict an individual’s pseudo-outcomes \(\) using a model that fuses \(X\) and \(W\). CaML is trained by repeating this procedure across many tasks and corresponding natural experiments.

We then construct a meta-dataset \(D\) in the following way:

\[D =D^{(j)}_{} D^{(j)}_{ },w^{(j)}}_{j=1}^{K}, \] \[D^{(j)}_{} =\{(X_{i},Y_{i}) W_{i}=w^{(j)}\}D^{(j)}_{}=\{(X_{i},Y_{i}) W_{i}=0)\}. \]

\(D^{(j)}\) denotes the natural experiment dataset for task \(j\), composed of a treated group (instances which received the intervention, i.e. \(W_{i}=w^{(j)}\)) and control group (instances which did not receive any intervention, i.e. \(W_{i}=0\)). Each sample \(i\) represents an individual, for which the quantities \((X_{i},Y_{i})\) are collected as introduced in Section 3. In practice, we down-sample both groups (i.e. to 1 million samples for the treated and control groups) in our large-scale experiments.

We augment each task dataset \(D^{(j)}\) with intervention information, \(w^{(j)}^{e}\), for zero-shot generalization to new interventions [35; 18; 87; 39]. The form of \(w^{(j)}\) varies with the problem domain -- for text interventions, it could be a language model's text embedding [79; 84; 58], while biomedical treatments can be represented as nodes in a knowledge graph [8; 49]. Additionally, domain-specific features, like treatment categories from an ontology, may be included in \(w^{(j)}\). To handle combinations of interventions (e.g., pairs of drugs), we aggregate the \(w\) for each intervention using an order-invariant pooling operation (we used the sum operator), and sample a separate natural experiment for individuals who received the full combination.

### Estimating pseudo-outcomes

We next estimate the training targets for each task (i.e. intervention) in the meta-dataset. The training target (\(^{(j)}\)) is an unbiased, but noisy, estimate of CATE. More formally, for each task \(j\) (which points to the natural experiment dataset for intervention \(w^{(j)}\)), we estimate \(^{(j)}\), where \(_{}[^{(j)}|X=x]=_{w^{(j)}}(x)\). Thus, \(^{(j)}_{i}\) denotes the target for the \(i\)-th sample in the \(j\)-th task (indexing will be omitted when it is clear from context). We refer to these targets as pseudo-outcomes, following prior literature . For prior work on pseudo-outcomes, refer to Appendix B. In Appendix E we demonstrate why these pseudo-outcomes provide an unbiased training objective. For a detailed explanation on the necessity of using pseudo-outcomes instead of directly modeling \(Y(w)\) and \(Y(0)\), please see [44; 16; 10].

CaML is agnostic to the specific choice of pseudo-outcome estimator. Thus, we assume a function \((D^{(j)})\) which takes as input a task dataset \(D^{(j)} D\) and returns a vector containing the pseudo-outcomes \(\) for each sample in the task. We extend each task dataset \(D^{(j)}\) with the pseudo-outcomes, such that a sample holds the elements \((X_{i},Y_{i},_{i})\). Our key insight is that by collecting these pseudo-outcomes across multiple tasks, and predicting them using a combination of intervention and individual information (\(W,X\)) we can develop a CATE estimator which generalizes to novel interventions. In practice, we use the RA-learner  and treat pseudo-outcome estimation as a data pre-processing step (Appendix C.6).

### Meta-model training

Given \(m\) target outcomes \(Y_{1},...,Y_{m}\) (e.g., different drug side effects), our goal is then to learn a model \(_{}^{e}^{d}^{m}\) that for parameters \(\) minimizes

\[^{*}=*{argmin}_{}\ _{j U(D)}\ _{W,X, D^{(j)}}[L(_{})], \]

where \(U(D)\) denotes the discrete uniform distribution over the tasks of the meta-dataset \(D\), and where \(L(f)\) refers to a standard loss function between the pseudo-outcomes and the model output, i.e., \(L(f)=(-f(w,x))^{2}\). To assess whether the model generalizes to novel tasks, we partition our meta-dataset by task, into non-overlapping subsets \(D=D_{} D_{} D_{}\). During training, \(_{}\) is optimized on training tasks \(D_{}\). We validate and test this model on \(D_{}\) and \(D_{}\), which are thus unseen during training tasks. While the CaML framework is agnostic to a specific training strategy, we based our approach (Algorithm 1) on the Reptile meta-learning algorithm  which we find performs better compared to straightforward empirical risk minimization (_c.f._ Section 6). For this, the objective is slightly modified to

\[^{*}=*{argmin}_{}\ _{j U(D)}\ [L(A^{k}_{D^{j}}(_{}))], \]where \(A_{D}^{k}\) represents the operator that updates a model \(f\) using data sampled from the dataset \(D\) for \(k\) gradient steps. This operator is defined in more detail as the ADAPT routine in Algorithm 1. Note that depending on the choice of CATE estimator, this routine iterates only over treated samples of a task dataset \(D^{(j)}\) (as in our experiments), or over all samples, including untreated ones.

```
0: meta-dataset \(D\), meta-model \(_{}\) with initialized parameters \(\), hyperparameter \(k\). for iteration \(=1,2,,L\)do \(j\) \(D_{}^{(j)},D_{}^{(j)}\)\(\)QueryTaskData(\(j\)) \(^{(j)}\)\(\)EstimatePseudoOutcomes(\(D_{}^{(j)},D_{}^{(j)}\)) \(^{}((D_{}^{(j)},D_{}^{ (j)}),^{(j)},w^{(j)},_{},k)\) \(g-^{}\) {Reptile gradient} \(- g\) {Gradient step for meta-model \(_{}\)} endfor return\(_{}\)
```

**Algorithm 1** The CaML algorithm

### CaML architecture

To parameterize \(_{}\), we propose a simple but effective model architecture (see Section 6):

\[_{}(w,x)=_{1}([;]), =_{2}(x)= _{3}(w), \]

where \([\,;]\) denotes concatenation. Equation 7 shows that the intervention information \(w\) and individual features \(x\) are encoded separately into dense vectors \(\) and \(\), respectively. Our MLPs consist of layers of the form \(g(z)=z+((z))\).

## 5 Theoretical analysis

We now consider zero-shot causal learning from a theoretical perspective. Under simplified assumptions, we bound the prediction error in the zero-shot setting.

We formulate the setting as a supervised learning problem with noisy labels (pseudo-outcomes) where we learn a smooth function \(f=(w,x)\) among a family \(\). We focus on \(\), and assume \(\) without loss of generality, since we can normalize \(\) to this range. The training dataset has \(n\) interventions with \(m\) samples each, i.e. first _n.i.d._ draws from \(P_{W}\): \(w^{(1)},,w^{(n)}\) and then for each \(w^{(j)}\), _m i.i.d._ draws from \(P_{X}\): \(x_{1}^{(j)},,x_{m}^{(j)}\).

The main theorem quantifies the rate that combining information across different interventions helps with zero-shot performance. We prove a finite-sample generalization bound for the ERM variant of CaML. The ERM is a special case of Adapt with \(k=1\) that is more conducive to rigorous analysis. The advantage of Reptile over ERM is orthogonal and we refer the readers to the original discussion . We assume the estimated pseudo-outcomes \(\) during training satisfy \(=+\) where \(\) is an independent zero-mean noise with \(||\) almost surely for some \( 0\),

\[=_{f}(f)=_{f}_{j=1}^{n} _{i=1}^{m}(f(w^{(j)},x_{i}^{(j)})-_{i}^{(j)})^{2}.\]

The test error is \(L(f)=_{W,X,}[(f(w,x)-)^{2}]\). Let \(f^{*}=_{f}L(f)\). We bound the excess loss \(L()-L(f^{*})\). Our key assumption is that interventions with similar features \(W\) have similar effects in expectation. We assume that all functions in our family are smooth with respect to \(W\), i.e., \( f,_{W,X}[\| f/ W \|_{2}^{2}]^{2}\).

**Theorem 1**.: _Under our assumptions, with probability \(1-\),_

\[L() L(f^{*})+8(1+)R_{nm}()+8()(1/)}{n}}++\] \[(1+)+2(1+)^{2}/m) (1/)}{n}}\]

where \(R_{nm}\) is a novel notion of zero-shot Rademacher complexity defined in equation (9); \(C\) is a Poincare constant that only depends on the distribution of \(W\). For large \(n,m\), the leading terms are the function complexity \(R_{nm}()\), and an \(O()\) term with a numerator that scales with \(\) and \((1+)^{2}/m\). This validates our intuition that when the intervention information \(W\) is more informative of the true treatment effects (smaller \(\)), and when the estimation of \(\) in the training dataset is more accurate, the performance is better on novel interventions. Please refer to Section A for the full proof. Compared to standard generalization bound which usually has a \(\) term, our main technical innovation involves bounding the variance by the smoothness of the function class plus Poincare-type inequalities. When \(\) is much smaller than \(1\) we achieve a tighter bound.

## 6 Experiments

We explore to what extent zero-shot generalization is practical when predicting the effects of interventions. We thus design two novel evaluation settings using real-world data in domains where zero-shot CATE estimation will be highly impactful: (1) Health Insurance Claims: predicting the effect of a drug on a patient, and (2) LINCS: predicting the effect of a perturbation on a cell. We use new datasets because existing causal inference benchmarks  focus on a single intervention. By contrast, zero-shot causal learning must be conceptualized in a multi-intervention setting.

**Zero-shot Evaluation**. Each task corresponds to estimating CATE for a single intervention, across many individual samples (e.g. patients). We split all tasks into meta-training/meta-validation, and a hold-out meta-testing set for evaluating zero-shot predictions (Table 2, unseen drugs for Claims and Table 3, unseen molecular perturbations in LINCS). For the Claims dataset, we also consider the challenging setting of combinations of unseen drugs (Table 5).

Each meta-validation and meta-testing task contains a natural experiment of many samples (e.g., patients) who received the unseen intervention, and many control samples who did not receive the intervention. The same patient (Claims) or cell-line (LINCS) can appear in multiple tasks (if they received different interventions at different times). Thus, to ensure a fair zero-shot evaluation, we exclude all samples who have ever received a meta-testing intervention from meta-val/meta-train. Similarly, we exclude all meta-validation patients from meta-train. Details on holdout selection are provided in Appendix C.2.

Table 1 gives an overview of both benchmarks. In the Claims dataset, we compare zero-shot predictions with strong single-intervention baselines which cannot generalize to unseen interventions. To do so, we further split each task in meta-validation and meta-testing into a train/test (50/50) split of samples. These baselines are trained on a task's train split, and all methods are evaluated on the test split of the meta-testing tasks. On the LINCS dataset, as each task consists of \(<100\) cells, single-intervention baselines performed weakly and are excluded from analysis.

**Baselines.** We compare the zero-shot performance of CaML to two distinct categories of baselines. (1) _Trained directly on test interventions_. These are strong CATE estimators from prior work and

 p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt}} Dataset & Samples & Features (\(X\)) & Outcome (\(Y\)) & Intervention type & Intervention information (\(W\)) \\  Claims & Patients & Patient history (binned couts) & Pancytopenia onset & Drug intake (prescription) & Drug embedding (knowledge graph) \\ LINCS & Cell lines & Cancer cell encyclopedia & Expression of landmark genes (DEG) & Perturbation (small molecule) & Molecular embeddings (RDKit) \\  

Table 1: High-level overview of our two experimental settings. Details in Appendix C.1.

can only be trained on a single intervention. Thus, we train a single model on each meta-testing task's train split, and evaluate performance on its test split. This category includes T-learner , X-learner , RA-learner , R-learner , DragonNet , TARNet , and FlexTENet .

(2) _Zero-shot_ baselines are trained across all meta-training tasks and are able to incorporate intervention information (\(W\)). These methods are thus, in principle, capable of generalizing to unseen interventions. We use GraphITE  and Structured Intervention Networks (SIN) . We also introduce two strong baselines which learn to directly estimate \(Y(w)\) and \(Y(0)\) by meta-learning across all training interventions, without using pseudo-outcomes: S-learner and T-learner with meta-learning. These extend the S-learner and T-learner from prior work  to incorporate intervention information (\(W\)) in their predictions. We elaborate on implementation details of baselines in Appendix C.7. For details on hyperparameter search and fair comparison, see Appendix C.1.

**Ablations.** In our first ablation experiment (w/o meta-learning), we trained the CaML model without meta-learning, instead using the standard empirical risk minimization (ERM) technique . Our second ablation (w/o RA-learner) assesses the sensitivity of CaML's performance to different pseudo-outcome estimation strategies. For further details on how these ablation studies were implemented, see Appendix C.3. We discuss the key findings from these ablations in Section 6.3.

### Setting 1: Personalized drug side effect prediction from large-scale medical claims

Our first setting (Claims) is to predict the increased likelihood of a life-threatening side effect caused by a drug prescription. We leverage a large-scale insurance claims dataset of over 3.5 billion claims across 30.6 million patients in the United States2. Each datestamped insurance claim contains a set of diagnoses (ICD-10 codes), drug prescriptions (DrugBank ID), procedures (ICD-10 codes), and laboratory results (LOINC codes). Laboratory results were categorized by whether the result was high, low, normal, abnormal (for non-continuous labs), or unknown.

Interventions are administration of one drug (\(n=745\)), or two drugs (\(n=22,\!883\)) prescribed in combination. Time of intervention corresponds to the _first_ day of exposure. Intervention information (\(W\)) was generated from pre-trained drug embeddings from a large-scale biomedical knowledge graph  (Appendix C). We compute drug combination embeddings as the sum of the embeddings of the constituent drugs. We focus on the binary outcome (\(Y\)) of the occurrence of the side effect pancytopenia within 90 days of intervention exposure. Pancytopenia is a deficiency across all three blood cell lines (red blood cells, white blood cells, and platelets). Pancytopenia is life-threatening, with a 10-20% mortality rate [38; 43], and is a rare side effect of many common medications  (_e.g._ arthritis and cancer drugs), which in turn require intensive monitoring of the blood work. Following prior work , patient medical history features (\(X\)) were constructed by time-binned counts of each unique medical code (diagnosis, procedure, lab result, drug prescription) at seven different time scales before the drug was prescribed, resulting in a total of 443,940 features. For more details, refer to Appendix C.1.

**Metrics** We rely on best practices for evaluating CATE estimators in observational data, as established by recent work [86; 11], which recommend to assess treatment rules by comparing subgroups across different quantiles of estimated CATE. We follow the high vs. others RATE (rank-weighted average treatment effect) approach from Yadlowsky et. al , which computes the difference in average treatment effect (ATE) of the top \(u\) percent of individuals (ranked by predicted CATE), versus all individuals (for more details, see Appendix C.1). For instance, RATE @ 0.99 is the difference between the top 1% of the samples (by estimated CATE) vs. the average treatment effect (ATE) across all samples, which we would expect to be high if the CATE estimator is accurate. Note that estimates of RATE can be negative if model predictions are inversely associated with CATE. We elaborate on the RATE computation in Appendix C.1.

The real-world use case of our model is preventing drug prescription for a small subset of high-risk individuals. Thus, more specifically, for each task \(j\), intervention \(w_{j}\) in the meta-dataset, and meta-model \(_{}\), we compute \(RATE\@u\) for each \(u\) in \([0.999,0.998,0.995,0.99]\) across individuals who received the intervention. We use a narrow range for \(u\) because pancytopenia is a very rare event occurring in less than 0.3% of the patients in our dataset. Hence, in a real-world deployment scenario, it is necessary to isolate the small subset of high-risk patients from the vast majority of patients for whom there is no risk of pancytopenia onset.

[MISSING_PAGE_FAIL:9]

there are only a small number of instances (cell lines) per intervention3. CaML outperforms both single-intervention and multi-intervention learners by drawing from both of their strengths--it allows us to use strong CATE estimation methods (i.e. the RA-learner) which previously were restricted to single interventions, while sharing information across multiple interventions.

_CaML learns to generalize from single interventions to combinations of unseen interventions (drug pairs)._ We evaluate CaML's performance in the challenging setting of predicting the personalized effects of combinations of two drugs which are both unseen during training, while only training on interventions consisting of single drugs. CaML achieves strong performance results (see Appendix Table 5), surpassing the best baseline trained on the test tasks, and outperforms all zero-shot baselines, across all 12 metrics.

_Understanding CaML's performance results._ Our ablation studies explain that CaML's performance gains are due to (1) our meta-learning formulation and algorithm (in contrast to the w/o meta-learning row, in which ERM is used to train the model), and (2) the flexible CATE estimation strategy, allowing to take advantage of recently developed CATE estimators previously restricted to single interventions (in contrast to the w/o RA-learner row, in which an alternative pseudo-outcome estimator is used). Lastly, (3) comparison to existing binary intervention CATE estimators trained separately on each meta-testing intervention (Table 2, grey rows) shows that we gain from learning from thousands interventions. See Appendix C.3 for details on ablations.

## 7 Conclusion

We introduce a novel approach to predict the effects of novel interventions. CaML consistently outperforms state-of-the-art baselines, by unlocking zero-shot capability for many recently developed CATE estimation methods which were previously restricted to studying single interventions in isolation. While our study is limited to retrospective data, we plan to prospectively validate our findings. Future work includes designing new model architectures and CATE estimators which learn well under the CaML framework, developing new metrics to evaluate zero-shot CATE estimators, as well as more generally exploring novel learning strategies that enable zero-shot causal learning.

**Societal impacts**. In high-stakes decision-making inaccurate predictions can lead to severe consequences. It is important not to overly rely on model predictions and proactively involve domain experts, such as doctors, in the decision-making process. Additionally, it is crucial to ensure that underserved communities are not disadvantaged by errors in treatment effect estimates due to underrepresentation in the training data. Important avenues for achieving equitable CATE estimation in future work include process-oriented approaches (i.e., evaluating model errors for underserved demographics), and outcome-oriented methods (i.e., gauging model impacts on demographic utility) [12; 57; 69; 2]. Furthermore, the deployment of CATE models could raise privacy concerns. These models typically require access to individual patient data to estimate personalized treatment effects accurately. Ensuring the privacy and security of this sensitive information is crucial to avoid potential data breaches or unauthorized access, which could harm patients and erode public trust in healthcare systems.

    & PHEE 50 DEGs (\(\)) & PHEE 20 DEGs (\(\)) \\   Mean. & 3.78 & 4.11 \\  GraphITE & 3.58 \(\) 0.023 & 3.82 \(\) 0.011 \\ SIN & 3.78 \(\) 0.001 & 4.06 \(\) 0.001 \\ S-learner w/ meta-learning & 3.63 \(\) 0.004 & 3.90 \(\) 0.004 \\ T-learner w/ meta-learning & 3.61 \(\) 0.007 & 3.85 \(\) 0.006 \\  CaML - w/o meta-learning & 3.57 \(\) 0.006 & 3.79 \(\) 0.004 \\ CaML - w/o RA-learner & 4.28 \(\) 0.517 & 4.60 \(\) 0.413 \\ CaML (ours) & **3.56**\(\) 0.001 & **3.78**\(\) 0.005 \\   

Table 3: Performance results for the LINCS dataset (predicting the effect of an unseen perturbation on the gene expression of an unseen cell-line). CaML outperforms all baselines. Improvement is largest for the 20 most differentially expressed genes, where most signal is expected.