# Fearless Stochasticity in Expectation Propagation

Jonathan So

University of Cambridge

js2488@cam.ac.uk &Richard E. Turner

University of Cambridge

The Alan Turing Institute

###### Abstract

Expectation propagation (EP) is a family of algorithms for performing approximate inference in probabilistic models. The updates of EP involve the evaluation of moments--expectations of certain functions--which can be estimated from Monte Carlo (MC) samples. However, the updates are not robust to MC noise when performed naively, and various prior works have attempted to address this issue in different ways. In this work, we provide a novel perspective on the moment-matching updates of EP; namely, that they perform natural-gradient-based optimisation of a variational objective. We use this insight to motivate two new EP variants, with updates that are particularly well-suited to MC estimation. They remain stable and are most sample-efficient when estimated with just a single sample. These new variants combine the benefits of their predecessors and address key weaknesses. In particular, they are easier to tune, offer an improved speed-accuracy trade-off, and do not rely on the use of debiasing estimators. We demonstrate their efficacy on a variety of probabilistic inference tasks.

## 1 Introduction

Expectation propagation (EP)  is a family of algorithms that is primarily used for performing approximate inference in probabilistic models , although it can be used more generally for approximating certain kinds of functions and their integrals .

EP involves the evaluation of moments--expectations of certain functions--under distributions that are derived from the model of interest. EP is usually applied to models for which these moments have convenient closed-form expressions or can be accurately estimated using deterministic methods. Moments can also be estimated using Monte Carlo (MC) samples, significantly expanding the set of models EP can be applied to. However, the updates of EP are not robust to MC noise when performed naively, and various prior works have attempted to address this issue in different ways .

In this work we provide a novel perspective on the moment-matching updates of EP; namely, that they perform natural-gradient-based optimization of a variational objective (Section 3). We use this insight to motivate two new EP variants, EP-\(\) (Section 3.2) and EP-\(\) (Section 3.3), with updates that are particularly well-suited to MC estimation, remaining stable and being most sample-efficient when estimated with just a single sample. These new variants combine the benefits of their predecessors and address key weaknesses. In particular, they are easier to tune, offer an improved speed-accuracy trade-off, and do not rely on the use of debiasing estimators. We demonstrate their efficacy on a variety of probabilistic inference tasks (Section 4).

## 2 Background

In this section, we first introduce the problem setting. We then give an overview of EP, followed by a discussion of issues related to sampled estimation of EP updates.

Let \(\) be the tractable, minimal exponential family of distributions (see Appendix A), defined by the statistic function \(s(.)\) with respect to base measure \((.)\). Let \(\), \(\), \(A(.)\) denote the natural domain, mean domain and log-partition function of \(\), respectively, and \(A^{*}(.)\) the convex dual of \(A(.)\).

Let \(p_{0}\) be the member of \(\) with natural parameter \(_{0}\), so that \(p_{0}(z)=(_{0}^{}s(z)-A(_{0}))\)1, and assume that a distribution of interest \(p^{*}\), the _target distribution_, has a density of the form

\[p^{*}(z) p_{0}(z)_{i=1}^{m}_{i}(z). \]

In Bayesian inference settings, \(p^{*}\) would be the posterior distribution over parameters \(z\) given some observed data \(\), where \(p_{0}\) may correspond to a prior distribution, and \(\{_{i}(z)\}_{i}\) to log-likelihood terms given some partition of \(\).2 However, we consider the more general setting in which the target distribution is simply a product of factors. Note that we can assume form (1) without loss of generality if we allow \(p_{0}\) to be improper. The inference problem typically amounts to computing quantities derived from the normalised density \(p^{*}(z)\), such as samples, summary statistics, or expectations of given functions. In some special cases, these quantities can be computed exactly, but this is not feasible in general, and approximations must be employed.

### Expectation propagation (EP)

Given a target distribution density of form (1), EP aims to find an approximation \(p\) such that

\[p(z) p_{0}(z)_{i}_{i}^{}s(z)  p^{*}(z). \]

By assumption \(\) is tractable, and so provided that \((_{0}+_{i}_{i})\), \(p\) is a tractable member of \(\). Each factor \((_{i}^{}s(z))\) is known as a _site potential_, and can be roughly interpreted as a \(\)-approximation to the \(i\)-th _target factor_, \((_{i}(z))\).3\(_{i}\) is known as the \(i\)-th _site parameter_.

Variational problemEP, and several of its variants , can be viewed as solving a variational problem which we now introduce following the exposition of Hasenclever et al. .

Let the \(i\)-th _locally extended family_, denoted \(_{i}\), be the exponential family defined by the statistic function \(s_{i}(z)=(s(z),_{i}(z))\) with respect to base measure \((.)\). Let \(_{i},_{i}\) and \(A_{i}(.)\) denote the natural domain, mean domain, and log partition function of \(_{i}\), respectively. Note that a member of \(_{i}\) roughly corresponds to a distribution whose density is the (normalised) product of a member of \(\) with the \(i\)-th target factor raised to a power. Unlike \(\), we do not assume \(_{i}\) is minimal.

Fixed points of EP correspond to the solutions of the saddle-point problem

\[_{}_{\{_{i}\}_{i}}L(, _{1},,_{m}),\] \[L(,_{1},,_{m})=A_{0}+ _{i}_{i}+_{i}_{i}A_{i} (-_{i}^{-1}_{i},_{i}^{-1})-A(). \]

At a solution to (3), the EP approximation is given by (2). The hyperparameters \(\{_{i}\}_{i}\) control the characteristics of the approximation, and correspond to the power parameters of power EP.

EP updatesEP , power EP  and double-loop EP , can all be viewed as alternating between some number (\( 1\)) of _inner updates_ to decrease \(L\) with respect to \(\{_{i}\}_{i}\), with an _outer update_ to increase \(L\) with respect to \(\). EP is not typically presented in this way, but by doing so we will be able to present a unified algorithm that succinctly illustrates the relationship between the different variants. We show equivalence with the conventional presentation of EP in Appendix B. The inner and outer updates are given by

\[_{i}_{i}- _{0}+_{j}_{j}- A^{*}_{p_ {i}(z)}[s(z)], \] \[_{0}+ _{j}_{j}, \]where \(p_{i}_{i}\) denotes the \(i\)-th _tilted distribution_, with density

\[p_{i}(z)((-_{i}^{-1}_{i})^{}s(z)+_{i }^{-1}_{i}(z)). \]

The hyperparameter \(\) controls the level of damping, which is used to aid convergence. An undamped inner update (with \(=1\)) can be seen as performing _moment matching_ between \(p\) and \(p_{i}\). The expectation in (4) is most often computed analytically, or estimated using deterministic numerical methods. It can also be estimated by sampling from \(p_{i}\), however, we will later show that the resulting stochasticity can lead to a biased and unstable procedure. The inner updates can be performed either serially or in parallel (over \(i\)). In this work we assume they are applied in parallel, but the ideas presented can easily be extended to the serial case. Heskes and Zoeter  showed that (4) follows a decrease direction in \(L\) with respect to \(_{i}\), and so is guaranteed to decrease \(L\) when \(\) is small enough. See Appendix C for a derivation of the inner update. When \(\{_{i}\}_{i}\) are at a partial minimum of \(L\) (for fixed \(\)), the outer update performs an exact partial maximisation of the primal form of the variational problem - see Hasenclever et al.  for details. All of the EP variants considered in this paper differ only in their handling of the inner minimisation, and this is our focus.

Unified EP algorithmThe double-loop EP algorithm of Heskes and Zoeter  repeats the inner update to convergence before performing each outer update, which ensures convergence of the overall procedure. The usual presentation of EP combines (4) and (5) into a single update in \(_{i}\) (see Appendix B), however, Jylanki et al.  observed that it can also be viewed as performing double-loop EP with just a single inner update per outer update (which is not guaranteed to converge in general). By taking this view, we are we are able to present EP, power EP, and their double-loop counterparts as a single algorithm, presented in Algorithm 1. We do so primarily to illustrate how these variants are related to one another, and to the new variants of Section 3.

```
\(\), \(_{0}\), \(\{_{i}\}_{i}\), \(\{_{i}(z)\}_{i}\), \(\{_{i}\}_{i}\), \(n_{}\), \(\) while not converged do \(_{0}+_{j}_{j}\) \(_{0}+_{j}_{j}\) for\(1\) to \(n_{}\)do for\(i=1\) to \(m\) in paralleldo \(_{i}_{i}-(_{0}+_{j}_{j}- A^{ *}(_{p_{i}(z)}[s(z)]))\) return\(\{_{i}\}_{i}\)
```

**Algorithm 1** EP (\(_{i}\)=1,\(n_{}\)=1), power EP (\(_{i}\)\(\)1,\(n_{}\)=1), and their double-loop variants (\(n_{}\)>1)

Note that dependence on \(\{_{i}\}_{i}\) comes through the definition of \(p_{i}(.)\). We can think of "exact" double-loop EP as corresponding to \(n_{}=\), with the inner loop exiting once some convergence criterion has been satisfied. In practice, a truncated inner loop is often used by setting \(n_{}\) to some small number [17; 30]. Upon convergence of Algorithm 1, the approximation \(p(z) p^{*}(z)\) is given by (2). Going forwards we will refer to the family of algorithms encompassed by Algorithm 1 simply as EP.

Stochastic moment estimationEP is typically applied to models for which the updates either have closed-form expressions, or can be accurately estimated using deterministic numerical methods. However, as update (4) only depends on the target distribution through expectations under the tilted distributions, this suggests that updates could also be performed using _sampled_ estimates of those expectations. By using MC methods to estimate the tilted distribution moments, EP can be used in a black-box manner, dramatically expanding the set of models it can be applied to. Instead of performing a single large sampling task--as would be required by applying MC methods directly--EP can instead solve several simpler ones, gaining significant computational advantages [17; 48; 52]. Unfortunately, when performed naively, update (4) is not robust to MC noise. This is because the moment estimates are converted to the natural (site) parameter space by mapping through \( A^{*}(.)\), which is not linear in general, and so MC noise in the estimates leads to biased updates of \(_{i}\).

## 3 Fearlessly stochastic EP algorithms

In this section we show an equivalence between the moment-matching updates of EP and natural gradient descent (NGD). We use this view to motivate two new EP variants which have several advantages when updates are estimated using samples. We conclude with a review of related work.

### Natural gradient view of EP

Several EP variants--EP , power EP, double loop EP , stochastic natural gradient EP , and the new ones to follow--differ only in how they perform the _inner_ optimisation in (3) with respect to \(\{_{i}\}_{i}\). The optimisation can be viewed as one with respect to the \(m+1\) distributions \(p,p_{1},,p_{m}\), which are jointly parameterised by \(\{_{i}\}_{i}\). Natural gradient descent (NGD) , which involves preconditioning a gradient with the inverse Fisher information matrix (FIM) of a distribution, is an effective method for optimising parameters of probability distributions. It would therefore seem desirable to apply NGD to the inner optimisation, yet doing so is not straightforward. While the FIM can be naturally extended to the product of statistical manifolds that is the solution space, computing and inverting it will not generally be tractable, making (the natural extension of) NGD in this space infeasible.

Consider instead \(_{i}{}^{(t)}\) with natural parameter \(_{i}{}^{(t)}(_{i})=_{0}+_{j}_{j}{}^{(t)}+^{-1} (_{i}-_{i}{}^{(t)})\). The \(t\) superscript on the site parameters indicates that they are fixed for the current iteration, and so the distribution is fully parameterised by \(_{i}\). Note that when \(_{j}=_{j}{}^{(t)} j\), we have \(_{i}{}^{(t)}=p\). Proposition 1, which we prove in Appendix D, states that the moment-matching updates of EP can be viewed as performing NGD in \(L\) with respect to _mean parameters_ of \(_{i}{}^{(t)}\).

We will make use of the following properties: for an exponential family with log partition function \(A(.)\), the gradient \( A(.)\) provides the map from natural to mean parameters, and this mapping is one-to-one for minimal families, with the inverse given by \( A^{*}(.)\). See Appendix A for details.

**Proposition 1**.: _For \(>0\), the moment-matching update of EP (4) is equivalent to performing an NGD step in \(L\) with respect to the mean parameters of \(_{i}{}^{(t)}\) with step size \(^{-1}\). That is, for \(_{i}=_{_{i}{}^{(t)}(z)}[s(z)]\), and \(_{i}{}^{(t)}(_{i})\) the FIM of \(_{i}{}^{(t)}\) with respect to \(_{i}\), we have_

\[_{i}-^{-1}_{i}^{(t)}(_{i})^{-1}}= A_{i}^{(t)} _{i}-_{0}+_{j}_{j}- A^{*} _{p_{i}(z)}[s(z)]. \]

Note that the right hand side of (7) just maps update (4) to mean parameters of \(_{i}{}^{(t)}\). 4 We discussed in Section 2 that noise in the moment estimates results in bias in the update to \(_{i}\) of EP, due to the noise being passed through the nonlinear map \( A^{*}(.)\). This alone would not be a problem if the updates followed unbiased descent direction estimates in some other fixed parameterisation. Let \(_{i}= A^{*}(_{i})\), then, from the definition of \(L\) and \(_{i}\), we have

\[}=}{_{i}} }{_{i}} A_{0}+ _{j}_{j}-_{p_{i}(z)}[s(z)], \]

and so when \(_{p_{i}(z)}[s(z)]\) is estimated with unbiased samples, the NGD update (7) in \(_{i}\) is also unbiased. However, a _sequence_ of updates introduces bias. This is because the parameterisation changes from one update to the next, with the mean parameters of \(_{i}{}^{(t)}\) mapped to those of \(_{i}{}^{(t+1)}\) by

\[_{i}^{(t+1)}= A_{i}^{(t+1)}_{i}^{(t)} ^{-1} A^{*}_{i}^{(t)}, \]

where \((_{i}{}^{(t)})^{-1}(.)\) is the inverse of \(_{i}{}^{(t)}(.)\), and \(_{i}{}^{(t+1)}(.)\) is defined using the site parameters _after_ the update at time \(t\). This map is not linear in general, and so an unbiased, noisy update of \(_{i}\) at one time step, results in bias when mapped to the next. This bias can make the EP updates unstable in the presence of MC noise, leading previous work to use methods, specific to \(\), for obtaining approximately unbiased _natural_ parameter estimates from samples. However, even with these debiasing methods, a relatively large number of samples is still needed in practice . Here we have assumed parallel application of (4), but the bias at site \(i\) is induced whenever the parameters for other sites change from one update to the next, which occurs in both parallel and serial settings.

We now use the natural gradient interpretation of the EP updates to motivate two new variants that are far more robust to MC noise. In particular, they are stable, and most sample-efficient, when updates are estimated with just a single sample. Furthermore, unlike methods that rely on deibasing estimators, they do not require sample thinning (see Section 3.4). This largely eliminates two hyperparameters for the practitioner. While practical considerations, such as ensuring efficient use of parallel hardware, may justify using more than one sample per update, this can in principle be tuned _a priori_, much like the batch size hyperparameter of stochastic gradient descent.

### Ep-\(\)

We showed in the previous section that bias is introduced into the sequence of NGD updates due to a nonlinear map from one parameterisation to the next. If the map were affine, the sequence would remain unbiased. This can be achieved by performing NGD with respect to \(_{i}\), the _natural_ parameters of \(_{i}{}^{(t)}\). Then, the map from one parameterisation to the next (by equating \(_{i}\)) is given by \(_{i}{}^{(t+1)}(_{i}{}^{(t)})^{-1}\), which is linear. The NGD direction in \(L\) with respect to \(_{i}{}^{(t)}\) and \(_{i}\) is given by

\[-_{i}(_{i})^{-1}} =-}{_{i}} A_{0 }+_{j}_{j}-_{p_{i}(z)}[s(z)]. \]

See Appendix E for a derivation. Note that \(\) plays a similar role as the NGD step size in this parameterisation, but it also affects \(_{i}{}^{(t)}\), and so to obtain a more faithful NGD interpretation we fix \(=1\) and introduce an explicit NGD step size \(\) to decouple from the effect on \(_{i}{}^{(t)}\). The resulting update can be expressed directly as an update in \(_{i}\), by applying \((_{i}{}^{(t)})^{-1}\) to the updated \(_{i}\), giving

\[_{i}_{i}-}{_ {i}} A_{0}+_{j}_{j}- _{p_{i}(z)}[s(z)]. \]

We can use automatic differentiation to efficiently compute (11), by recognising the second term as a Jacobian-vector product (JVP) with respect to \(_{i}(_{i})= A^{*}(_{i})\).5 In summary, by performing NGD with respect to _natural_ parameters of \(_{i}{}^{(t)}\), instead of mean parameters, the resulting sequence of updates is unbiased in \(_{i}\). We call the resulting procedure--which is given in Algorithm 2--EP-\(\), to emphasise that we have simply changed the NGD parameterisation of EP. The unbiased updates of EP-\(\) allow it to be more sample-efficient than EP by using a smaller number of samples per iteration. The left panel of Figure 1 demonstrates this effect in a stochastic version of the clutter problem .

### Ep-\(\)

The bias introduced by the updates of EP cannot be mitigated by reducing \(\) (increasing the damping) without also proportionally sacrificing the amount of progress made by each update. More concretely, let the bias in dimension \(d\) of \(_{i}{}^{(t+1)}\), after an update at time \(t\), be defined as \([_{i}{}^{(t+1)}-_{i}{}^{(t+1)}]_{d}\), where \(_{i}{}^{(t+1)}\) is the value of \(_{i}{}^{(t+1)}\) after a _noise-free_ update, and expectation is taken over the sampling distributions of all parallel updates at time \(t\). Then, Proposition 2 below, which we prove in Appendix G, summarises the effect of decreasing \(\) on EP.

Figure 1: The effect of step size (\(\) or \(\)) and number of MC samples (\(n_{}\)) on different EP variants in a stochastic version of the clutter problem of Minka . EP (naive) uses maximum likelihood estimation for the updates, and EP (debiased) uses the estimator of Xu et al. . Step size corresponds to \(\) for EP, and \(\) for EP-\(\) and EP-\(\). Only EP-\(\) and EP-\(\) can perform \(1\)-sample updates, hence the other traces are not visible. The left panel shows the expected decrease in \(L\) after \(100/n_{}\) steps. Performing e.g. \(100\)\(1\)-sample steps, or \(10\)\(10\)-sample steps, achieves a much larger decrease in \(L\) than a single \(100\)-sample step. The right panel shows the magnitude of the bias in \(_{i}\) after a single parallel update, averaged over all sites and dimensions. The bias of EP-\(\) shrinks far faster as the step size decreases than that of EP. EP-\(\) is always unbiased and so is not visible.

**Proposition 2**.: _After update (4) is executed in parallel over \(i\), as \( 0^{+}\), both the expected decrease in \(L\), and the bias \([_{i}{}^{(t+1)}-_{i}{}^{(t+1)}]_{d}\), are \(O()\) for all \(d\)._

Proposition 1 at the beginning of this section states that update (4) can be viewed as performing an NGD step with respect to \(_{i}\) with a step size of \(^{-1}\). However, changing \(\) also has the effect of changing the definition of \(_{i}{}^{(t)}\). It is then natural to wonder what happens if we fix \(=1\) and introduce an explicit step size for NGD, \(\), resulting in the update

\[_{i}_{i}- A_{0}+_ {j}_{j}-_{p_{i}(z)}[s(z)]. \]

See Appendix F for a derivation. It turns out that in doing so, when we decrease \(\), the bias shrinks far faster than the expected decrease in \(L\).

**Proposition 3**.: _After update (12) is executed in parallel over \(i\), as \( 0^{+}\), the expected decrease in \(L\) is \(O()\), and the bias \([_{i}{}^{(t+1)}-_{i}{}^{(t+1)}]_{d}\) is \(O(^{2})\), for all \(d\)._

Proposition 3, which we prove in Appendix G, tells us that by using update (12), we can reduce the bias to arbitrarily small levels while still making progress in decreasing \(L\). Update (12) can also be expressed directly as an update in \(_{i}\) by applying \((^{(t)})^{-1} A^{*}\), giving

\[_{i} A^{*}(1-) A_{0}+ _{j}_{j}+_{p_{i}(z)}[s(z)] -_{0}-_{j i}_{j}, \]

which has the simple interpretation of performing EP, but with damping of the moments instead of the site (natural) parameters. In summary, if we perform NGD with respect to the same mean parameterisation as EP, but treat the NGD step size as a free parameter, \(\), we can obtain updates that are _approximately_ unbiased while still making progress. We call this variant EP-\(\), again to indicate that we are simply performing the NGD update of EP in the mean parameter space.6 The resulting procedure is also given by Algorithm 2.

```
\(\), \(_{0}\), \(\{_{i}\}\), \(\{_{i}(z)\}_{i}\), \(\{_{i}\}_{i}\), \(n_{}\), \(\) while not converged do \(_{0}+_{j}_{j}\) for\(1\) to \(n_{}\)do for\(i=1\) to \(m\) in paralleldo  update \(_{i}\) using (11) for EP-\(\), or (13) for EP-\(\) return\(\{_{i}\}_{i}\)
```

**Algorithm 2** EP-\(\) and EP-\(\) (differences with Algorithm 1 are highlighted in green)

The computational cost of EP-\(\) is lower than that of EP-\(\) because it does not require JVPs through \( A^{*}()\).7 The drawback is that the updates of EP-\(\) do still retain some bias, however, we find that the bias of EP-\(\) typically has negligible impact on its performance relative to EP-\(\). This is evident in the clutter problem of Minka , as demonstrated in the left panel of Figure 1, as well as in the larger scale experiments of Section 4. The right panel of Figure 1 illustrates how quickly the bias in \(_{i}\) shrinks as the step size of EP-\(\) is decreased. Note that the results of this subsection are stated in terms of bias in \(_{i}\), but it is straightforward to show that equivalent results also hold for \(_{i}\) using Taylor series arguments.

### Related work

The link between natural gradients and moment matching in an exponential family is well known , but the connection with EP shown here - which relies on identification of the distribution \(_{i}{}^{(t)}\) and parameterisation \(_{i}{}^{(t)}\) - is new, to the best of our knowledge. Bui et al.  showed that the updates of (power) EP are equivalent to performing NGD in a local variational free energy objective when taking the limit of the power parameter as \(_{i}\), and Wilkinson et al.  showed that this extends to the (global) variational free energy objective for models with a certain structure. Our result is different in that it relates to NGD of the EP variational objective, and applies for all values of \(_{i}\).

EP was combined with Markov chain Monte Carlo (MCMC) moment estimates by Xu et al.  in a method called _sampling via moment sharing_ (SMS), and later by Vehtari et al.  in the context of hierarchical models. In both works, when \(\) was multivariate normal (MVN) --arguably the most useful case--the authors used an estimator for the updates that is unbiased when \(_{i}\) is also MVN. Although this estimator is only _approximately_ unbiased in general, it can help to stabilise the updates significantly. Even so, it is necessary to use a relatively large number of samples for the updates, with several hundred or more being typical. Using many samples per update is inefficient, as the update direction can change from one iteration to the next. Furthermore, such estimators typically rely on a known number of _independent_ samples. Samples drawn using MCMC methods are generally autocorrelated, necessitating the use of sample thinning before the estimators can be applied. This adds another hyperparameter to the procedure--the thinning ratio--and it is also inefficient due to the discarding of samples. The practitioner is required to choose the number of samples, the thinning ratio, and the amount of damping, all of which affect the accuracy, stability, and computational efficiency of the procedure. There is no easy way to choose these _a priori_, forcing the practitioner to either set them conservatively (favouring accuracy and stability), or to find appropriate settings by trial and error, both of which are likely to expend time and computation unnecessarily.

The stochastic natural gradient EP (SNEP) method of Hasenclever et al. , which is closely related to our work, also optimises the EP variational objective using a form of NGD. The SNEP updates are unbiased in the presence of MC noise, allowing them to be performed with as little as one sample, without relying on \(\)-specific debiasing estimators, or the sample thinning that would entail. In SNEP, NGD is performed with respect to mean parameters of the _site potentials_, which are treated as bona fide distributions in \(\). In contrast, we showed that EP can already be viewed as performing NGD, but with respect to the distributions \(\{_{i}{}^{(t)}\}_{i}\), and our new variants, EP-\(\) and EP-\(\), are able to gain the same advantages as SNEP, but using the same distributions for NGD as EP. Hasenclever et al.  showed that in some settings, SNEP can obtain accurate point estimates fairly rapidly. However, we find that it typically converges far slower than both EP and our new variants, consistent with findings in Vehtari et al. . We argue that this is because the site potentials (when considered as distributions) bear little resemblance with the distributions that are ultimately being optimised, and so their geometry is largely irrelevant for the optimisation of \(L\). In contrast, the geometry of \(p_{i}{}^{(t)}\) is closely related to that of \(L\), as we show in Appendix H.

We note that Xu et al.  and Hasenclever et al.  also proposed methods for performing updates in an asynchronous fashion, significantly reducing the frequency and cost of communication between nodes in distributed settings. In principle, these methods could be combined with those presented in this paper, but we do not consider them further here.

## 4 Evaluation

In this section we demonstrate the efficacy of EP-\(\) and EP-\(\) on a variety of probabilistic inference tasks. In each experiment, the task was to perform approximate Bayesian inference of unobserved parameters \(z\), given some observed data \(\). All of the models in these experiments followed the same general structure, consisting of a minimal exponential family prior over \(z\), \(p_{0}\), and a partition of the data \(\{_{i}\}_{i}^{m}\), where each block \(_{i}\) depends on both \(z\) and an additional vector of _local_ latent variables \(w_{i}\) that also depend on \(z\). That is, the joint density has the form

\[p_{0}(z)_{i}p(w_{i} z)p(_{i} w_{i},z), \]

where \(p_{0}\). This structure is shown graphically in Appendix J. To perform approximate inference of \(z\), we first define \(_{i}(z)\) as the log likelihood of \(_{i}\) given \(z\), with \(w_{i}\) marginalised out. That is,

\[_{i}(z)= p(_{i},w_{i} z)w_{i}. \]

Then, given \(p_{0}(z)\) and \(\{_{i}(z)\}_{i}\), we define \(p^{*}(z)\) as (1), and proceed to find an approximation \(p(z) p^{*}(z)\) using the methods described in earlier sections. Note that sampling from the tilted distribution \(p_{i}(z)\) requires jointly sampling over \(z\) and \(w_{i}\) and taking the marginal. EP is a particularly appealing framework for performing inference in this setting, as the dimensionality of the sampled distributions is constant with respect to \(m\), mitigating the curse of dimensionality experienced by conventional MCMC approaches . In our experiments we used NUTS  to perform the sampling, consistent with prior work [48; 52]. In each experiment we compared EP-\(\) and EP-\(\) with EP, in the manner used by Xu et al.  and Vehtari et al. . When \(\) was MVN we also compared to SNEP . For the models with normal-inverse Wishart (NIW) \(\), we were unable to find an initialisation for SNEP that would allow us to perform a meaningful comparison. We discuss this point further in Appendix J.

To evaluate the performance of the different variants, we monitored KL divergence to an _estimate_ of the optimum, obtained by running EP with a large number of samples. We used 500 different hyperparameter settings for each variant, chosen using random search, and repeated each run 5 times using different random seeds for NUTS. All runs of EP-\(\) and EP-\(\) were performed with \(n_{}=1\) and \(n_{}=1\). The results of our evaluation are summarised by the Pareto frontiers in Figure 2.

We see that EP-\(\) and EP-\(\) can typically reach a given level of accuracy (distance from an estimate of the optimum) faster than EP, often significantly so. We stress that the frontiers for EP-\(\) and EP-\(\) are traced out with \(n_{}\) and \(n_{}\) each fixed to \(1\), with no sample thinning, varying only the step size hyperparameter \(\), with higher accuracy/cost regions of the frontier corresponding to lower values of \(\). In contrast, to trace out the frontier of EP we must jointly vary \(\), \(n_{}\), and the thinning ratio. See Appendix K for examples of this effect. The performances of EP-\(\) and EP-\(\) are very similar. We found SNEP to be significantly slower than the other methods, consistent with findings by Vehtari et al. . Pareto frontiers with respect to wall-clock time can be found in Appendix L. Code for these experiments can be found at [https://github.com/cambridge-mlg/fearless-ep](https://github.com/cambridge-mlg/fearless-ep). We now provide a brief overview of individual experiments, with further details given in Appendix J.

Hierarchical logistic regression with MVN priorHierarchical logistic regression (HLR) is used to perform binary classification in a number of groups when the extent to which data should be pooled across groups is unknown . We performed approximate Bayesian inference in a HLR model using a MVN prior over the group-level parameters. We applied this model to synthetic data, generated using the same procedure as Vehtari et al. , which was designed to be challenging for EP. In this experiment \(z^{8}\), \(w_{i}^{4}\)\(\)\(i\), and each of the \(m=16\) groups had \(n=20\) observations. In the upper-left panel of Figure 2 we see that EP-\(\) and EP-\(\) typically reach a given level of accuracy faster than EP and SNEP.

Figure 2: Pareto frontiers showing the number of NUTS steps (\(x\)-axis) against the KL divergence from \(p\) to an estimate of the optimum (\(y\)-axis). Each point on the plot marks the lowest average KL divergence attained by _any_ hyperparameter setting by that step count. Error bars mark the full range of values for the marked hyperparameter setting across 5 random seeds.

Hierarchical logistic regression with NIW priorWe also performed approximate Bayesian inference in a similar HLR model, but using a normal-inverse Wishart (NIW) prior over group-level parameters, allowing for correlation of regression coefficients within groups. We applied this model to political survey data, where each of \(m=50\) groups corresponded to responses from a particular US state, with \(7\) predictor variables corresponding to characteristics of a given survey respondent, so that \(w_{i}^{7}\)\(\)\(i\). There were \(n=97\) survey respondents per state. The data, taken from the 2018 Cooperative Congressional Election Study, related to support for allowing employers to decline coverage of abortions in insurance plans . The upper-right panel of Figure 2 shows that EP-\(\) and EP-\(\) consistently reach a given level of accuracy significantly faster than EP.

Cosmic radiation modelA hierarchical Bayesian model was used by Vehtari et al.  to capture the nonlinear relationship between diffuse galactic far ultraviolet radiation and 100-\(\)m infrared emission in various sectors of the observable universe, using data obtained from the Galaxy Evolution Explorer telescope. In this model each \(w_{i}^{9}\) parameterised a nonlinear regression model using data obtained from one of \(m\) sections of the observable universe. The \(m\) regression problems were related through hyperparameters \(z^{18}\), which parameterised the section-level parameter densities. The prior, \(p_{0}\), was MVN. The specifics of the nonlinear regression model are quite involved and we refer the reader to Vehtari et al.  for details. We were unable to obtain the dataset, and so we generated synthetic data using parameters that were tuned by hand to try and match the qualitative properties of the original data - see Appendix N for examples. We used a reduced number of \(m=36\) sites and \(n=200\) observations per site to allow us to perform a comprehensive hyperparameter search. The lower-left panel of Figure 2 shows once again that EP-\(\) and EP-\(\) consistently reach a given level of accuracy significantly faster than EP and SNEP.

Neural response modelA common task in neuroscience is to model the firing rates of neurons under various conditions. We performed inference in a hierarchical Bayesian neural response model, using recordings of V1 complex cells in an anesthesised adult cat . In this dataset, 10 neurons in a specific area of cat V1 were simultaneously recorded under the presentation of 18 different visual stimuli, each repeated 8 times, for a total of 144 trials. We modelled the observed spike counts of the 10 neurons in each trial as Poisson, with latent (log) intensities being MVN, with mean and covariance (collectively \(z^{65}\)) drawn from a NIW prior \(p_{0}\). Inference of \(z\) amounted to inferring the means, and inter-neuron covariances, of latent log firing rates across stimuli. We grouped the data into \(m=8\) batches of \(n=18\) trials each, so that the latent log firing rates for all trials in batch \(i\) were jointly captured by \(w_{i}^{180}\). The lower-right panel of Figure 2 shows that EP-\(\) and EP-\(\) either match or beat the speed of EP for reaching any given level of accuracy. For high levels of accuracy the performances of the methods appear to converge with one another, but note that the asymptote is not exactly zero because the optimal solution was estimated by running EP with a large (but finite) number of samples.

## 5 Limitations

In this work we have largely assumed that the drawing of MC samples is the dominant cost. In practice, other costs become relevant, which may shift the balance in favour of using more samples to estimate updates. We discuss this in Appendix I, along with strategies for reducing computational overheads. We note, however, that wall-clock time results for our evaluation experiments (in Appendix L) are in line with the results of Section 4, indicating that the drawing of MC samples was indeed the dominant cost.

When EP and its variants--including those introduced here--are combined with MC methods, the underlying samplers typically have hyperparameters of their own, which are often adapted using so-called warmup phases. While EP-\(\) and EP-\(\) significantly reduce the complexity of tuning hyperparameters specific to EP, they do not help with those of the underlying samplers. This means that the complexity of hyperparameter tuning (for all EP variants) is still greater than that for direct MC methods. We used comprehensive hyperparameter searches in our experiments in order to perform a meaningful comparison with baseline methods, necessarily limiting the scale of problems we could tackle.

Our focus has been on developing improved methods for performing EP when the updates must be estimated with noise, with the motivation for this kind of setting having been discussed by prior work [52; 17; 48]. EP and its variants are agnostic to the choice of sampling kernel, and as such we have not discussed issues relating to the performance of the underlying samplers. In the left panel of Figure 3 however, we highlight the relative inefficiency of using EP-\(\) with NUTS as the underlying sampler when compared to conjugate-computation variational inference (CVI), an efficient variational inference method . While EP-\(\) is able to obtain much more faithful posterior approximations than CVI, it is significantly slower when measured in wall-clock time, despite the gains made over its predecessors. However, this is due to the relative cost of drawing independent samples with NUTS, as the sample efficiency of EP-\(\) is roughly equivalent to that of CVI when an (illustrative) "oracle" sampling kernel is used, as demonstrated in the left-middle panel of Figure 3. Further discussion and details of the experiments behind Figure 3 can be found in Appendix M.

## 6 Future work

In Section 5, we demonstrated that the efficiency of EP variants is constrained by that of of the underlying samplers. There are several ways in which their performance could be improved by using knowledge of \(p\) to guide sampling from \(p_{i}\). One such improvement would be to use \(p\) to set MCMC hyperparameters directly, obviating the need to adapt them during warm-up phases, e.g. when \(p\) is MVN, its precision matrix could be used directly as the mass matrix in Hamiltonian Monte Carlo schemes. Another potential improvement is that samples from \(p\) could be used to re-initialise MCMC chains at each iteration, providing approximate independence between updates for a small additional cost. It would also be worthwhile considering how our methods can be efficiently implemented on modern compute hardware to better take advantage of the inherently parallel nature of EP, e.g. practical performance could be improved by using sampling kernels that are themselves designed for efficient parallel execution . Performance may be further improved in distributed settings by using asynchronous extensions of EP in order to minimise communication-related overheads and delays [17; 52]. We leave investigation of these ideas to future work.

## 7 Conclusion

In this work, we used a novel interpretation of the moment-matching updates of EP to motivate two new EP variants that are far more robust to MC noise. We demonstrated that these variants can offer an improved speed-accuracy trade-off compared to their predecessors, and are easier to tune.

Figure 3: Comparison of EP-\(\) with conjugate-computation variational inference (CVI) on a hierarchical logistic regression model. The two leftmost plots show forward (solid) and reverse (dashed) KL divergences between the approximation of each method and a MVN distribution estimated directly from MCMC samples. The left panel shows a comparison with respect to wall-clock time, when NUTS is used as the underlying sampling kernel for EP-\(\). The left-middle panel shows a similar comparison, but with respect to the number of samples drawn, and using an “oracle” sampling kernel for EP-\(\). Hyperparameters were tuned for each method and shaded regions show the range of trajectories across 5 random seeds. The right and right-middle panels show pairwise marginals of the various MVN approximations overlaid on contours of the true posterior. Coloured dots and ellipses correspond to means and 2-standard-deviation contours, respectively. See Section 5 for discussion of these results, and Appendix M for further details.

Acknowledgements

We would like to thank the anonymous reviewers for providing valuable feedback, and Jihao Andreas Lin for sharing his plotting expertise. Jonathan So is supported by the University of Cambridge Harding Distinguished Postgraduate Scholars Programme. Richard E. Turner is supported by Google, Amazon, ARM, Improbable, EPSRC grant EP/T005386/1, and the EPSRC Probabilistic AI Hub (ProbAI, EP/Y028783/1).