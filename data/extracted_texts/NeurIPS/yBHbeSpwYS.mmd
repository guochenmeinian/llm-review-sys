# In Pursuit of Causal Label Correlations for Multi-label Image Recognition

Zhao-Min Chen\({}^{1}\),  Xin Jin\({}^{2}\),  Yisu Ge\({}^{1,}\),  Sixian Chan\({}^{3}\)

\({}^{1}\)Key Laboratory of Intelligent Informatics for Safety \(\&\) Emergency of Zhejiang Province,

Wenzhou University

\({}^{2}\)Samsung Electronic (China) R\(\&\)D Centre, Samsung Electronic

\({}^{3}\)The College of Computer Science and Technology, Zhejiang University of Technology

chenzhaomin123@gmail.com, ysg@wzu.edu.cn

Corresponding author.

###### Abstract

Multi-label image recognition aims to predict all objects present in an input image. A common belief is that modeling the correlations between objects is beneficial for multi-label recognition. However, this belief has been recently challenged as label correlations may mislead the classifier in testing, due to the possible contextual bias in training. Accordingly, a few of recent works not only discarded label correlation modeling, but also advocated to remove contextual information for multi-label image recognition. This work explicitly explores label correlations for multi-label image recognition based on a principled causal intervention approach. With causal intervention, we pursue causal label correlations and suppress spurious label correlations, as the former tend to convey useful contextual cues while the later may mislead the classifier. Specifically, we decouple label-specific features with a Transformer decoder attached to the backbone network, and model the confounders which may give rise to spurious correlations by clustering spatial features of all training images. Based on label-specific features and confounders, we employ a cross-attention module to implement causal intervention, quantifying the causal correlations from all object categories to each predicted object category. Finally, we obtain image labels by combining the predictions from decoupled features and causal label correlations. Extensive experiments clearly validate the effectiveness of our approach for multi-label image recognition in both common and cross-dataset settings.

## 1 Introduction

Multi-label image recognition is a fundamental task in computer vision, aiming to predict all objects present in an image. It has widespread applications including object detection , medical imaging , and person re-identification . However, this task is challenging as the combinations of labels can be tremendous. Modelling label correlations to reduce the search space is believed to be essential for multi-label image recognition .

In the research of multi-label image recognition, an implicit yet common assumption is: the training and test sets follow independent and identically distributions (i.i.d.), and the label correlations are consistent. Under this setting, a deep backbone network can implicitly extract context-aware features that are beneficial for object recognition, and furthermore, explicit label correlation modeling can explore contextual cues more deeply to improve the recognition accuracy. Technically, graph structures  or attention mechanisms  have been successfully employed to model labelcorrelations. However, these methods may fall short when there exists contextual bias in the training set. As illustrated by Fig. 1, "Person", "Dog", and "Cat" co-occur frequently in the training set, but a test image may only contain "Person" and "Dog". Consequently, due to the learned label correlations, the multi-label recognition model predicts a high probability of "Cat", solely based on the presence of "Person" and "Dog".

Recently, a few researchers [14; 17] have uncovered the contextual bias issue, and discarded explicit label correlation modeling. Furthermore, they attempted to alleviate the effects of contextual bias by decorrelating the feature representations of a category from its co-occurring context , or removing the contextual bias in features with causal mechanisms . Despite improved accuracy, these methods neglect to model label correlations. In this paper, we ask: _is it possible to model label correlations for multi-label recognition, with the purpose of preserving good and suppressing bad contextual contents?_ This work attempts to answer this question, as well as quantifying the goodness of contexts (corresponding to all pre-defined categories in the dataset) for recognizing a certain semantic category from the perspective of causal theory .

In this paper, we explore label correlations with a principled causal intervention approach for multi-label image recognition. Causal intervention aims to measure the causal effect from one cause variable to another effect variable, by "physically" putting the effect variable at any context to remove the effects of confounders in current image. Our key motivation lies on the realization that the causal label correlations (in the probability-raising sense ) are stable in both training and testing, even when contextual bias does exist in the training set. We pursue causal correlations (_e.g._, from "Person" to "Clothes") to mine contextual cues for recognition, while suppressing spurious correlations (_e.g._, from "Person" to "Cat") which are associated by confounders (_e.g._, the overall scene) and may mislead the classifier in testing.

We design an end-to-end framework that carefully integrates causal intervention into multi-label recognition. Specifically, we decouple label-specific features with a Transformer decoder attached to the backbone network, and model the confounders (imaginary contextual contents) by clustering spatial features of all training images. Based on label-specific features and confounders, we employ a cross-attention module to implement causal intervention for all pre-defined categories, quantifying the causal label correlations from all object categories to each predicted object category. Finally, we combine the predictions from decoupled features and causal correlations for multi-label prediction.

In summary, our main contributions are as follows:

* We propose a conceptually simple, yet effective label correlation modeling approach based on causal intervention to tackle the issue of contextual bias for multi-label image recognition. It allows us to capture causal label correlations (good contextual contents) to improve recognition accuracy, while suppressing the effects of spurious correlations (possible bad contextual contents) that may mislead the classifier.
* We conduct comprehensive experiments with contextual bias to evaluate the effectiveness of the proposed method for multi-label image recognition. Under both common and cross-dataset settings, our method consistently demonstrates advantages over existing methods.

## 2 Related Work

Correlation modeling for multi-label image recognition.Modeling label correlations is crucial for multi-label image recognition. Early approaches achieved this by embedding label correlations using

Figure 1: Illustration of the concept and effect of contextual bias in training. It is common that “Person”, “Dog”, and “Cat” co-occur in training images (we only show one image), while the test image may only contain “Person” and “Dog”. Excessive reliance on the label co-occurrence in the training set may lead the recognition model to predict the “Cat” solely based on the presence of “Person” and “Dog”.

Recurrent Neural Networks (RNNs) [32; 21], but the performance is affected by the order in which the labels are predicted. To overcome the sequential issue, researchers attempted to capture label correlations with graph structures, enabling simultaneous prediction of the label sets [4; 28; 12; 25].

Besides graph structures, several other approaches have been developed to establish label correlations. DER  employs metric learning to pull related label-specific features closer and push unrelated label features apart. C-Tran  introduces a label mask training approach for general multi-label image classification, indirectly constructing label correlations by predicting masked labels. Q2L  employs Transformers to decompose label features and utilizes self-attention mechanisms to establish label correlations. SST  employs Transformers to simultaneously capture both spatial and semantic label correlations.

From a broader view of context modeling, label correlation modeling, arguably, can be understood as a strategy to enhance label-specific contextual cues. However, contextual information is a double-edged sword, and may mislead the classifier in presence of contextual bias in training.

Contextual bias and debiasing.While visual context is widely believed to be beneficial for object recognition, recent works show that contextual bias may hurt multi-label image recognition [14; 17]. Such bias happens when an object category frequently co-occurs with some other object categories. Strongly relying on context may mislead the classifier, when typical contextual patterns around an object are absent or an object are absent from its typical context.

Due to the contextual bias issue, some recent works have discarded label correlation modeling for multi-label image recognition, since the contextual priors encoded by learnt label correlations may mislead recognition. Furthermore, these works developed contextual debiasing techniques, by decorrelating feature representations of a category from its co-occurring context , or removing contextual bias in features with causal mechanisms . We argue that these methods may discard useful contextual cues, leading to inferior accuracy for common objects in common contexts.

Causal intervention in vision.Causal intervention measures the causal relationship between two random variables, by removing the confounders that may associate them . Recently, causal intervention has gained attention in the field of computer vision [17; 26; 33; 34; 27; 36; 37], with expectations to address the contextual bias or long-tailed distribution issues. For instance, VC-RCNN  employs causal intervention and proxy tasks to extract unbiased visual features, which can benefit downstream tasks like Image Captioning, Visual Question Answering, and Visual Commonsense Reasoning. Tang _et al_.  show that the SGD momentum is essentially a confounder in long-tailed classification, and propose to remove bad causal effects by intervention. Wang _et al_.  reveal that traditional attention module is biased in out-of-distribution setting, and propose causal attention for unbiased visual recognition.

For multi-label image recognition, Liu _et al_.  recently propose to remove the contextual bias in features with causal intervention. However, this approach does not consider label correlations, and may discard contextual evidences that are crucial for recognizing obscure instances.

## 3 Preliminaries and Motivation of Causal Correlations

Causal correlations in probability-raising sense.Humans can easily understand the causal correlation between the presence of two objects (_e.g._, "Person" is the cause of "Clothes"). Seeking

Figure 2: Illustration of causal label correlations and spurious correlations revealed by causal intervention, in a probability-raising sense that if \(P(Y|do(X))>P(Y)\), then a causal correlation exists from \(X\) (“Person”) to \(Y\) (categories in this figure).

for a calculable formal definition, we follow the statement in : if \(P(Y|do(X))>P(Y)\), then a causal correlation exists from \(X\) to \(Y\) in a probability-raising sense. Here \(do(X)\) is the \(do\)-operation, which pursues the causality between the cause \(X\) and the effect \(Y\) without the confounding effect.

As shown in Fig. 2, our implementation of causal intervention (which will be elaborated later) can reveal the causal correlations between objects in above probability-raising sense. For example, given the observation of "Person", the probabilities of "Clothes" and "Skis" raise. But on the other hand, although "Cat" often co-occurs with "Person", with causal intervention the probability of "Cat" even decreases when observing "Person".

Why pursuing causal correlations?Understanding this requires delving deep into the implication of causal intervention. Causal intervention is reminiscent of randomised controlled trials . Based on the presence of \(X\), causal intervention makes the prediction of \(Y\) goes beyond the limitation of the context of current test image. It measures the probability of \(Y\), by putting \(Y\) at randomised context (which can be simulated by confounder set \(C\)) with \(X\). Therefore, if \(X\) is the cause of \(Y\), it should be able to provide contextual cues to raise the probability of \(Y\), regardless of the contents (except \(X\) and \(Y\)) in current test image. If \(X\) is not the cause of \(Y\), it will not raise the probability of \(Y\) based on causal intervention, although they might co-occur frequently in the training set.

Formally, Fig. 3 shows a Structural Causal Model , where \(X\) and \(Y\) represent two labels, and \(C\) represents the confounder set. In causal theory, each directed edge denotes a possible causal relationship between two nodes. Fig. 3 (a) and (b) illustrate two extreme cases: the causal correlation between label \(X\) and \(Y\) which is not affected by the confounder \(C\), and the spurious correlation, where the co-occurrence of \(X\) and \(Y\) is caused by the confounder set \(C\).

Causal intervention by backdoor adjustment.As "physical" intervention that puts \(Y\) at any context is almost impossible, backdoor adjustment  is typically applied for "virtual" intervention:

\[P(Y|do(X))=_{c}P(Y|X,C=c)P(C=c)\,,\] (1)

Here the key idea is to cut off the link from confounder \(C\) to cause \(X\), and stratify \(C\) into pieces \(C=\{c\}\), making \(C\) no longer correlated with \(X\), and making \(X\) have a fair opportunity to incorporate every confounder \(c\) into the prediction of \(Y\), subject to a prior \(P(c)\).

## 4 Approach

### Overview of Proposed Pipeline

Building upon above analysis, we incorporate causal intervention into explicit label correlation modeling for multi-label image recognition, designing a pipeline of two complementary branches (Fig. 4): the branch of decoupled label-specific features, and the branch of causal label correlations. In particular, the causal correlation branch is built upon decoupled features.

Given an input image, a backbone network (_e.g._, ResNet-50 ) is firstly employed to extract the spatial feature. Then, a Transformer decoder is leveraged to decouple label-specific features from the spatial feature. This branch predicts image labels based on objects themselves, rather than the context or label correlations. To take into account the label correlations yet overcoming the effects of contextual bias, we construct a causal intervention branch, which explicitly models causal label correlations, and integrates them into prediction.

Formally, we denote the prediction confidence from the causal intervention branch as \(}_{causal}\), and the prediction from the decoupled feature branch as \(}_{decouple}\), then the final prediction confidence

Figure 3: (a): Causal correlation between label \(X\)’and \(Y\), which is not affected by confounder set \(C\). (b): Spurious correlation, where the co-occurence of \(X\) and \(Y\) is caused by confounder set \(C\).

scores \(}\) can be written as:

\[}=1/2}_{causal}+1/2}_{decouple} ^{N}\,,\] (2)

where \(N\) is the number of categories. We utilize standard multi-label recognition loss to train the model, which can be written as:

\[=_{gt}(})+(1-_{gt})(1-})\,,\] (3)

where \(_{gt}=\{0,1\}^{N}\) is ground truth label vector of the input image.

In the following, we will detail the designs of the decoupled feature branch and the causal intervention branch. We will also present explanations and discussions about causal correlations in context to facilitate understanding.

### Predicting by Decoupling Label-Specific Features

We firstly decouple label-specific features for input image with two purposes: (i) predicting image labels based on objects themselves; (ii) preparing for label correlation modeling by causal intervention.

For decoupling label-specific features, common approaches include Class Activation Mapping (CAM)  and Transformer . We employ a Transformer decoder for this purpose. Specifically, given input image \(\), we firstly use a CNN backbone to extract spatial feature \(\):

\[=f_{cnn}().\] (4)

Then, we employ a standard Transformer decoder to decouple label-specific features \(^{N D}\) from \(\):

\[=f_{decoder}(,).\] (5)

Here, \(^{N D}\) are learnable label embedding as queries, \(N\) and \(D\) are the number of categories and dimensionality of spatial features, respectively.

Finally, we obtain the prediction confidence \(}_{decouple}\) from decoupled features by:

\[}_{decouple}=(f_{fc1}())\,,\] (6)

where \(f_{fc1}()\) denotes the fully-connected layer, \(()\) is the sigmoid function. We apply multi-label loss to this branch for decoupled label-specific feature learning.

### Predicting by Summarizing Causal Label Correlations

With label-specific features, we can construct our intervention branch which _explicitly_ models causal label correlations for multi-label image recognition.

To estimate the probability of each category \(Y_{j}\) on this causal intervention branch, a straightforward approach is firstly calculating \(P(Y_{j}|do(X_{i}))\) for each category \(X_{i}\), and then merging them:

\[^{j}_{causal}=f_{merge}([P(Y_{j}|do(X_{1}),...,P(Y_{j}|do(X_{N})]).\] (7)

One might expect complex modeling of \(P(Y_{j}|do(X_{i}))\) and \(f_{merge}()\) for calculating Eq. 7. In this work, we introduce a simple yet effective implementation, using one cross-attention layer and one fully-connected layer.

Figure 4: The overall framework of our proposed method.

Causal intervention based on label-specific features.We hypothesize that whether \(X_{i}\) appears in the test image should be encoded by its label-specific feature \(x_{i}\). Given label-specific features \(x_{i}\) and \(y_{j}\) for label \(X_{i}\) and \(Y_{j}\), and one potential confounder feature \(c\), we model the conditional likelihood in Eq.1 as:

\[P(Y_{j}|X_{i},C=c)=(f_{y_{j}}(x_{i},c))\,,\] (8)

where \(()\) is the sigmoid function. \(f_{y_{j}}()\) calculates the logit for label \(Y_{j}\). Then, causal intervention can be calculated as:

\[P(Y_{j}|do(X_{i}))=_{c}[(f_{y_{j}}(x_{i},c))]\,.\] (9)

Due to the difficulty in directly computing Eq. 9, we apply the Normalized Weighted Geometric Mean (NWGM)  to approximate the above equation:

\[P(Y_{j}|do(X_{i})) =_{c}[(f_{y_{j}}(x_{i},c))]\] \[(_{c}[f_{y_{j}}(x_{i},c)])\] \[=(_{c}f_{y_{j}}(x_{i},c) P(c))\,.\] (10)

Here \(P(c)\) is the prior of confounder, which can be obtained from data.

Calculating Eq. 10 requires further modeling of \(f_{y_{j}}(x_{i},c)\). However, instead of hypothesizing a formulation of \(f_{y_{j}}(x_{i},c)\) which only intervenes one category \(X_{i}\) for \(Y_{j}\), we describe an efficient formulation based on cross attention to intervene all categories \(X_{i}\) for \(Y_{j}\) in one step. This allows us to circumvent the calculation of each \(f_{y_{j}}(x_{i},c)\), making the calculation of Eq. 7 more efficient.

Effective modeling for all \(f_{y_{j}}(x_{i},c)\) by cross-attention.Formally, following the notation in Eq. 5, let \(=[x_{1},...,x_{N}]^{N D}\) denote all label-specific features. To implement Eq. 7, we seek for a model to combine the information of all label-specific features \(x_{i}\) and one potential confounder feature \(c\) to predict the logit of label \(Y_{j}\). We employ cross-attention mechanism and fully-connected layer for this purpose:

\[_{c} =+c\,,\] \[^{j}_{causal} =f_{merge}([P(Y_{j}|do(X_{1}),...,P(Y_{j}|do(X_{N})])\] \[=f_{merge}([(_{c}f_{y_{j}}(x_{1},c) P(c)),..., (_{c}f_{y_{j}}(x_{N},c) P(c))])\] \[(_{c}f_{y_{j}}(,c) P(c))\] \[=(_{c}f_{fc2}(f_{cross\_atten}(y_{j},_{c},_ {c})) P(c))\,,\] (11)

where \(_{c}\) is the addition-based combination of all label-specific features \(\) and a confounder feature \(c\), and \(f_{fc2}\) is a fully-connected layer applied upon the cross-attention feature to obtain the logit. Algorithm 1 provides the pseudocode of causal intervention process.

Modeling the confoundersIt remains an open question about cofounder modeling for visual recognition tasks. In VC R-CNN , the authors treated objects as confounders, and extract object-level features based on bounding box annotations. However, on one hand, there is no bounding box annotation in the typical setting for multi-label image recognition. On the other hand, we argue that cofounders for recognizing certain object are often hard to define and enumerate - objects, scene, and even the texture of the environment are all potential confounders. For example, suppose that an image contains two objects: "Person" and "Surboard", with the scene being the "Beach". In VC R-CNN, the "Surboard" is considered the confounders for the "Person". However, in our opinion, the true confounder should the "Beach", although it does not have an associated image label.

Based on above analysis, to characterize these non-enumerable confounders, high-level spatial features of training images from pre-trained classification CNN provide a good choice, as semantic objects/regions are often activated in classification features. By clustering spatial features with K-means algorithm, we obtain a compact set of prototypes to represent potential confounders like objects, scenes and textures. We empirically show the effectiveness of this simple approach for modeling the confounders.

```
#X(NxD):Thelabel-specificfeatures
#C(MxD):Confounders
#P(M):Priors
#Nisthemumberofcategories
#Disthemimensionalityofspatialfeatures
#Misthenumberofconfounders Z=X.unsqueezeeze(1)+C.unsqueezeeze(0)#NxMxD y_j=X[j,:] y_causal_j=0 forcinrange(M): y_causal_j+=fc2(cross_atten(y_j,Z[:,c,:],Z[:,c,:]))*P[c] y_causal_j=y_causal_j.sigmoid() ```

**Algorithm 1** Pseudocode of Causal Intervention in a PyTorch-like style.

## 5 Experiments

### Experimental Settings and Implementation Details

Common Setting.The COCO-Stuff  and DeepFashion  datasets are experimented in common setting, where the training and test sets are from the same dataset. We strictly adhere to the evaluation setup employed in , and report the performance under two different test distributions: "_Exclusive_" denotes virtual co-occurrence where labels appearing simultaneously in the training set do not co-occur in the test set, and "_Co-occur_" represents the objects co-occurring in both the training and test sets. "_All_" is the average performance of all categories. We report top-3 recall for DeepFashion and mAP for COCO-Stuff.

Cross-dataset Setting.We consider a more challenging yet practical setting in real-world applications: the training and test sets are from different datasets, and may suffer from serious contextual bias issue. We simulate this setting by using MS-COCO  for training and NUS-WIDE  for testing, and vice versa. In particular, we select the same categories (14 common classes) from both the MS-COCO and NUS-WIDE datasets for experiments. We report the mean Average Precision (mAP) for all categories in this setting.

Implementation Details.To fair comparison with previous methods, we employ ResNet-50 and ResNet-101 as backbones for the common setting and real-world setting, respectively. We utilize the ImageNet  for model parameter initialization. For the cross-dataset setting, the input images are randomly cropped to a resolution of \(448 448\), while for the common setting, the resolution is set to \(224 224\). To extract label-specific features, we employ a 2-layer Transformer decoder with 4 attention heads. For modeling confounders, we first train a baseline model with standard multi-label loss, then extract spatial features from all the images in the training dataset, and employ \(K\)-means algorithm (default number of clusters is set to 80) to cluster all pixel-level spatial features. The Adam optimizer is chosen for model optimization, with a weight decay of \(2e-2\) and \((_{1},_{2})=(0.9,0.9999)\). The initial learning rate is set to \(1e-4\), and we employ a cyclic learning rate policy to train our model for 80 epochs. All of the experiments are run on a computer with an AMD EPYC 7542 32-Core processor, 256 GB main memory, and eight GTX-3090 GPUs.

### Comparing to the State-of-the-arts

Common Setting.In Table 1, we report the performance on COCO-Stuff and DeepFashion datasets, where the baseline is the vanilla Resnet-50 with standard multi-label loss. Comparing with the baseline, we observed a significant improvement (\(55.0\%\)_v.s._\(60.6\%\) on "_All_" mAP). Furthermore, our proposed method outperforms all state-of-the-arts on these two benchmarks. For example, it obtains a \(+1.5\%\) "_Exclusive_" and \(+3.6\%\) "_Co-occur_" improvements over the feature-split  on COCO-Stuff dataset.

We also observe that previous methods that directly build label correlations based on graph structures are affected by contextual bias in datasets. For example, ML-GCN  and SSGRL  both construct label graphs based on the training set and utilize the graph structure to capture correlations between labels. These two methods cannot achieve significant improvements over the baseline, and even exhibit noticeable performance degradation. We speculate that the graph structure constructed from the training set are not applicable to the test set in presence of contextual bias.

Cross-dataset Setting.Table 2 reports the results on the MS-COCO and NUS-WIDE datasets, where the baseline is the vanilla Resnet-101 with standard multi-label loss. Similar to the common setting, the performance of previous methods is affected by contextual bias, and our method outperforms all other state-of-the-art methods. However, compared to the baseline, the performance improvement of our method is not as significant as in the common setting. We speculate that, apart from contextual bias in training, the inconsistency in data distribution may also affect the performance. Even so, the cross-dataset results can indicate robustness and generalization capabilities of our method.

### Ablation Studies

In this section, we conduct ablation studies by using ResNet-50 as backbone on COCO-Stuff Dataset.

#### 5.3.1 Effectiveness of Different Modules

We investigate the impacts of key modules in our framework. Specifically, there are two essential modules, _i.e_., decoupling the label feature module (denoted as "Decouple") and causal intervention module (denoted as "Causal"). Table 3 shows the mAP performance by progressively integrating the above two modules. Solely applying "Decouple" on the backbone gives a \(+1.8\%\) "_All_" mAP, \(+0.2\%\) "_Exclusive_" mAP and \(+1.5\%\) "_Co-occur_" mAP improvement. Directly applying decoupling leads to improved "_Co-occur_" performance but fails to enhance "_Exclusive_" performance. We speculate

   &  &  \\   & Exclusive & Co-occur & All & Exclusive & Co-occur & All \\  Q2L  & 23.5 & 67.1 & 57.2 & 12.8 & 26.3 & 26.1 \\ ADD-GCN  & 20.6 & 64.8 & 55.2 & 8.2 & 22.6 & 23.5 \\ ML-GCN  & 18.6 & 67.1 & 55.1 & 10.3 & 23.7 & 24.0 \\ SSGRL  & 18.1 & 66.6 & 54.9 & 7.9 & 22.8 & 23.1 \\ C-Tran  & 22.4 & 65.1 & 55.4 & 11.4 & 24.6 & 24.8 \\ CCD  & 23.8 & 65.3 & 55.9 & 11.5 & 24.2 & 24.6 \\ TDRG  & 20.0 & 64.8 & 56.2 & 8.1 & 22.9 & 23.6 \\ IDA  & 25.2 & 64.9 & 57.0 & 11.3 & 25.1 & 25.4 \\ CAM-Based  & 26.4 & 64.9 & – & – & – & – \\ feature-split  & 28.8 & 66.0 & – & 9.2 & 20.1 & – \\  Baseline (R50) & 21.9 & 65.5 & 55.0 & 11.5 & 24.1 & 24.1 \\ Ours & **29.7** & **69.6** & **60.6** & **14.6** & **27.4** & **28.8** \\  

Table 1: Performance comparison in the common setting on the COCO-Stuff and DeepFashion datasets.

  Method & MS-COCO \(\) NUS-WIDE & NUS-WIDE \(\) MS-COCO \\  ADD-GCN  & 81.8 & 77.2 \\ ML-GCN  & 81.4 & 77.2 \\ SSGRL  & 80.2 & 76.1 \\ C-Tran  & 80.9 & 76.9 \\ CCD  & 81.9 & 78.3 \\ Q2L  & 82.1 & 78.6 \\ IDA  & 82.3 & 78.9 \\ CAM-Based  & 81.0 & 77.8 \\ feature-split  & 81.9 & 78.3 \\  Baseline (R101) & 81.1 & 77.1 \\ Ours & **83.2** & **80.2** \\  

Table 2: mAP Performance comparison in the cross-dataset setting on the MS-COCO and NUS-WIDE datasets.

that the cross-attention mechanism can capture the long-range dependencies, since it can implicitly model causal correlations but cannot eliminate spurious co-occurrence correlations. Then, the causal intervention module, which can remove spurious co-occurrence correlations and capture the causal correlations, bring another \(3.8\%\) "_All_" mAP. These results show the effectiveness of our approach in alleviating label correlations bias.

#### 5.3.2 Investigation of Confounders

Modeling confounders is a core step in our approach. In order to investigate the impact of different confounders, we designed comparative experiments at three aspects, _i.e._, the number of clustering centers, different clustering features, and different approaches for modeling confounders.

**The number of clustering centers.** In order to investigate the influence of the number of clustering centers, we conducted experiments with different numbers of cluster centers: 20, 40, 60, 80, and 100, respectively. The experimental results are presented in the Table 4. It can be observed that within a certain range, increasing the number of cluster centers does not significantly affect performance. However, a performance decline is noticeable when the number of clusters is reduced to 20. We speculate that the confounders correspond to many attributes including semantic, color, texture, and so on. A smaller number of cluster centers can only express very limited attributes, resulting in a decline in performance.

**Different backbones for clustering.** By default, we employ ResNet-50 as the backbone to extract features from all images in the training set on COCO-Stuff, and perform clustering to obtain confounders. In order to investigate the impact of different clustering features, we utilize distinct backbones for feature extraction. As shown in Table 5, the confounders obtained from different backbones have not significant influence on final performance. The role of the confounders is to identify label causal correlations and does not directly participate in recognition. Therefore, the features extracted by a weak backbone seems sufficient in identifying causal correlations, and the use of a strong backbone does not lead to performance improvement.

**Different approaches for modeling confounders.** In this paper, we utilize clustering centers to characterize confounders. We compare it with two additional modeling techniques. The experimental results as shown in the Table 6. "Random" means using random vectors to replace cluster centers as confounders. "Early" means fusing features from early epochs directly to obtain the confounder, which is adopted by . "Label" means directly using label-specific features as the confounder. Our modeling of confounders using \(K\)-means yields the best results. "Random" leads to significant performance degradation (measured by mAP), especially on the "Exclusive" subset. Since, we believe that confounders should be modeled at semantic level. The "Early" approach relies solely on simple feature fusion, which fails to effectively differentiate various attributes. The "Label" approach only employs object semantics as the confounder, leading to the omission of other attributes. By contrast,

  Method & Exclusive & Co-occur & All \\  Random & 22.1 & 66.3 & 56.1 \\ Early & 27.8 & 69.1 & 60.1 \\ Label & 28.0 & 69.3 & 60.3 \\ \(K\)-means & **29.7** & **69.6** & **60.6** \\  

Table 6: The impact of different modeling approaches for confounders.

  Decouple & Causal & Exclusive & Co-occur & All \\  & & 21.9 & 65.5 & 55.0 \\ \(\) & & 22.1 & 67.0 & 56.8 \\ \(\) & \(\) & **29.7** & **69.6** & **60.6** \\  

Table 3: The impacts of different modules.

  Number & Exclusive & Co-occur & All \\ 
20 & 26.9 & 68.9 & 59.6 \\
40 & 26.8 & 69.3 & 60.1 \\
60 & 29.3 & **69.8** & 60.2 \\
80 & **29.7** & 69.6 & **60.6** \\
100 & 29.5 & 69.4 & 60.5 \\  

Table 4: The impacts of clustering center number.

  Confounder Backbone & Exclusive & Co-occur & All \\  ResNet-50 & **29.7** & 69.6 & **60.6** \\ ResNet-101 & 29.6 & **69.9** & 60.5 \\ BEIT3-Large & 29.4 & 69.7 & 60.5 \\  

Table 5: The impact of backbones for clustering.

our approach incorporates both object-related information and other contextual information, offering a more expressive set of confounders.

#### 5.3.3 Different Implementations of Eq. 7

We investigate different implementations of Eq. 7. Following , we employ a simpler linear approach and average merge method to model Eq. 7. As shown in Table 7, we can observe that employing a linear modeling approach yields competitive results, but our method still outperforms it. We speculate that while linear modeling can implement Eq. 7, our approach utilizes cross-attention, which possesses the ability to model long-range dependencies, thereby efficiently capturing causal correlations and suppressing spurious correlations.

## 6 Conclusions

In this paper, we presented a principled approach to address the contextual bias issue for multi-label image recognition. Using causal intervention from causal theory, we pursued causal label correlations, and integrated them into multi-label prediction. We evaluate the effectiveness of our approach with both quantitative and qualitative assessments. In the future, we will investigate more advanced structural causal models for better describing the label correlations.