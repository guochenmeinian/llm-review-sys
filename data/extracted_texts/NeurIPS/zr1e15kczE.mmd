# Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT

Zhen Zhang, Bingqiao Luo, Shengliang Lu, Bingsheng He

National University of Singapore

zhen@nus.edu.sg,luo.bingqiao@u.nus.edu,lusl@nus.edu.sg,hebs@comp.nus.edu.sg

###### Abstract

Numerous studies have been conducted to investigate the properties of large-scale temporal graphs. Despite the ubiquity of these graphs in real-world scenarios, it's usually impractical for us to obtain the whole real-time graphs due to privacy concerns and technical limitations. In this paper, we introduce the concept of _Live Graph Lab_ for temporal graphs, which enables open, dynamic and real transaction graphs from blockchains. Among them, Non-fungible tokens (NFTs) have become one of the most prominent parts of blockchain over the past several years. With more than $40 billion market capitalization, this decentralized ecosystem produces massive, anonymous and real transaction activities, which naturally forms a complicated transaction network. However, there is limited understanding about the characteristics of this emerging NFT ecosystem from a temporal graph analysis perspective. To mitigate this gap, we instantiate a live graph with NFT transaction network and investigate its dynamics to provide new observations and insights. Specifically, through downloading and parsing the NFT transaction activities, we obtain a temporal graph with more than 4.5 million nodes and 124 million edges. Then, a series of measurements are presented to understand the properties of the NFT ecosystem. Through comparisons with social, citation, and web networks, our analyses give intriguing findings and point out potential directions for future exploration. Finally, we also study machine learning models in this live graph to enrich the current datasets and provide new opportunities for the graph community. The source codes and dataset are available at https://livegraphlab.github.io.

## 1 Introduction

Temporal graphs provide an accurate representation of real-world systems, including social networks, transaction networks and the Web , etc. By investigating temporal graphs, we can gain insights into the temporal dynamics and understand how these systems evolve and function . Notably, a growing number of graph mining algorithms  and graph systems  have been developed. However, with this continuously growing trend, several severe issues emerge, which limit the further development of graph community. In the current literature, studies are usually conducted on a set of outdated and incomplete graphs. The majority of the aforementioned graphs are either not easily available or their graph structures are incomplete since they cannot record all the interactions in graph. Moreover, even through all the interactions are recorded, they might not be shareable in a public and timely evolving manner, such as social networks in companies like Meta and Tencent. Thus, for meaningful temporal graph analysis and benchmarks, we need open graph datasets that evolve dynamically and are easily accessible in a timely manner.

To bridge this gap, we propose the concept of Live Graph Lab, which provides live graphs according to blockchain transactions. Specifically, we offer a set of tools for _downloading_, _parsing_, _cleaning_, and _analyzing_ blockchain transactions to empower the analyses of transaction graphs. It not only alleviatesthe researchers' burden of accessing massive raw transaction data, but also brings a considerable of opportunities to conduct experiments in the real-world scenario for temporal graph studies. Our introduced live graphs have several unique characters like _open availability_, _dynamic evolution_ and _real transactions_ due to the inherent characteristics of the decentralized blockchain. Therefore, it is of great importance to investigate the properties of these live graphs to provide new insights for graph algorithms and systems.

Today, as blockchain technology becomes more widespread, the token economy is gradually emerging. Non-fungible tokens (NFTs) have seen tremendous growth with its market capitalization reaching over $40 billion. Notably, one of the digital work named "Everdyays: The First 5000 Days" 1 by artist _Beeple_ was sold for $69 million, which makes NFTs become the center of attention. This phenomenon also leads to an increasing number of enthusiasts participating in this emerging concept. At the same times, it generates massive, anonymous and real transaction activities, which naturally forms a complex NFT transaction network. Although traditional networks like social networks and citation networks have been extensively studied, they are often outdated due to _their lack of constantly updating_. To enrich the current datasets and overcome their limitations, we instantiate a live graph with NFT transaction network by synchronizing a full Ethereum node, thus it continuously keeps up with the latest Ethereum block and includes all the transaction data. To investigate the characteristics of this live NFT transaction network, we present a temporal graph extracted from a specific time period spanning from 2017 to 2022, which comprises over 4.5 million nodes and 124 million edges. Then, comprehensive analyses are performed, and the results demonstrate that our presented live graph exhibits a variety of characteristics, offering exciting opportunities for the graph community. To summarize, the main contributions and findings are as follows:

* We introduce the concept of live graph lab, which focuses on open, dynamic and real graphs.
* We instantiate a live graph with NFT transaction network and provide a systemic analysis, which demonstrates interesting properties like fast-growing, highly-active, ect.
* Graph machine learning models are investigated in the live graph, and the experimental results indicate that live graphs pose new challenges and opportunities for the graph community.

## 2 Related Datasets

Graph has gained significant attention from both academic and industrial communities. A wide range of benchmark datasets have been proposed to facilitate the research in graph community. Among them, SNAP  and Network Data Repository  provide diverse types of graphs including social networks, web networks, etc. AMiner  offers comprehensive citation networks extracted from DBLP, ACM and Microsoft Academic Graph. Chartalist  presents a set of blockchain datasets to enable machine learning model development. Although these datasets are publicly available, they are not constantly updated in a nearly real-time manner. Take social network as an example, the ego-Twitter  in SNAP project was released more than 10 years ago. Thus, the graph properties presented in these benchmarks may no longer be suitable in the current context. Meanwhile, their graph structures are usually incomplete due to privacy policy constraints or technical limitations. However, these characters are important for various downstream applications. For instance, if the graph is incomplete or their characteristics have changed significantly, the learning outcomes could be ineffective and even misleading in the graph learning tasks. To enrich the current datasets and overcome their limitations, we propose the concept of Live Graph Lab, which supports various experiments for temporal graph algorithms. We provide a detailed comparison of these datasets in Table 1. Specifically, the proposed live graph lab has the following properties: (1) it is open and

   Categories & Datasets & Open & Timely Evolving & Complete Structure & Timestamp \\  Social Network & ego-Twitter  & ✓ & ✗ & ✗ \\ Citation Network & DBLP  & ✓ & ✗ & ✗ \\ The Web & web-Google  & ✓ & ✗ & ✗ \\ Blockchain & Live Graph Lab & ✓ & ✓ & ✓ \\   

Table 1: Comparisons among different types of graph datasets.

publicly available; (2) it is constantly evolving in a nearly real-time manner; (3) it is complete (i.e, all interactions are fully recorded); (4) it has realistic timestamp. Moreover, previous blockchain datasets mainly focus on fungible token transactions. However, Non-Fungible Tokens (NFTs), which are a vital component of the Ethereum, have been overlooked by existing works. Our work covers this gap by delving into this emerging NFT ecosystem.

## 3 Dataset Details

In this paper, we instantiate a live graph with NFT transaction network in the Ethereum blockchain. We first provide an overview of the blockchain background. Then, we give a comprehensive explanation of the graph construction process. Note that, our methodologies are applicable to other bolckchains like Solana and Polygon, etc.

### Background

**Blockchain and Ethereum.** Blockchain, a distributed ledger technology, has attracted continuous attention recent years and is made up of securely linked blocks with cryptography techniques , where each block contains information of the previous block (e.g., cryptographic hash). Ethereum is a decentralized, programmable blockchain, which means users can construct various decentralized applications on the blockchain. Ether (ETH) is the native cryptocurrency of Ethereum, and every transaction incurred in the Ethereum needs a specific fee paid in ETH.

**Smart Contract and Non-Fungible Token.** Smart contract is an important feature in the Ethereum blockchain , which is a computer program that runs on the Ethereum to automatically execute or control relevant events and actions according to its logic. Smart contracts have largely reduced the requirements for trusted intermediaries, fraud losses and arbitration costs, etc. Non-Fungible Token (NFT) is one of the most successful applications on Ethereum. NFTs are tokens that can be used to represent the ownership of any unique asset such as image, video and audio, etc. Different from fungible items where one dollar is exchangeable for another one dollar, NFTs are not interchangeable with each other, since they all have unique properties and are not divisible.

### Raw Data

The statistic information of our dataset is summarized in Table 2. To access the transaction information in Ethereum, Geth, a golang implementation of Ethereum client software, is launched to facilitate the synchronization of the ledger on Ethereum mainnet. When the client synchronizes to the latest block, we extract all the blocks before Aug 1st, 2022 (i.e., from block #0 to block #15,255,104). Then, we parse all the transaction data and log data via toolkit Ethereum ETL2. Thanks to the well-defined standards in NFT communities, it is convenient for us to extract the information we need. Specifically, according to the standard of EIP-721, every NFT smart contract must implement the standard interfaces including _transfer_, _approval_, _owner_f and _balanceOf_, etc. For those smart contract that do not strictly follow the EIP-721 standard, we remove those smart contracts and its relevant transactions from our data. For the remaining data, we filter out all the _transfer_ events triggered by its smart contracts to extract the NFT transactions. This is because the ownership change of any NFT will emit a _transfer_ event identified by the event topic Keccack256 hash _0xddf...3ef_. In the NFT _transfer_ event, it contains four key contents including the Keccack256 hash, the sender's address, the receiver's address, and the transferred NFT token ID. The time when the transaction occurs can be

  Descriptions & Statistics \\  Start date (mm-dd-yyyy, UTC) & 07-12-2017 13:49 \\ End date (mm-dd-yyyy, UTC) & 08-01-2022 06:50 \\ Number of NFT collections & 97,667 \\ Number of NFT tokens & 77,991,885 \\ Number of account addresses & 4,531,020 \\ Number of transactions & 124,660,813 \\  

Table 2: Statistics of the dataset.

retrieved from the block that the event was found. Once we have obtained all of these key information, we can know when and which NFTs are transferred among different wallet addresses and the prices they are sold.

By parsing the transfer events, we find out that there are 97,667 NFT collections with 77,991,885 NFT tokens, where each collection contains different number of NFT tokens (e.g., varying from thousands to millions). Meanwhile, 124,660,813 transactions are extracted, and among them 4,531,020 users (i.e., we regard each wallet address as a user) participate in the transactions. It is worthy noting that there are over 100,000 NFT collections according to Etherscan3. However, as we have mentioned, some of them are not standard NFT tokens (i.e., they do not strictly follow the EIP-721 standard), and we remove them from our data. Thus, our method almost extracts all the NFT collections.

### Graph Construction

We investigate the structure and dynamics of all these transactions by constructing a directed temporal graph \(=(,,)\), where \(\) and \(\) denote the node set and edge set, respectively. That's to say, we only count once for those addresses that have repetitive interactions. \(\) is a set of timestamps when the interactions happen. We use \(t(e)\) to denote the timestamp when edge \(e\) is formed, and \(t(u)\) represents when the node \(u\) is added into the graph. Thus, \(a_{t}(u)=t-t(u)\) reflects node \(u\)'s age at time \(t\). For any given time \(t\), graph \(_{t}\) consists of all the nodes as well as edges until time \(t\). Note that, since we have accurate timestamps for the arrival of each node and edge, our investigation of graph dynamics is at a much finer granularity compared with the majority of existing studies [5; 41].

## 4 Observations and Analyses

To have a better understanding of the instantiated live graph, we start the analyses from the following perspectives: (1) Structural properties, which investigate how its nodes and edges change as time goes on; (2) Dynamic behaviors, which are graph specific properties such as how hub-nodes and bi-directional edges are formed. More comprehensive analyses are given in the Appendix C and D.

### Structural Properties

To fully understand how active is the NFT transaction network, we measure the evolution of nodes and edges over the time. Specifically, we set the time granularity to a yearly yardstick. Since our data started from the July of 2017 and ended at the August of 2022, the statistical information for 2017 and 2022 only has a half year's data. Figure 0(a) and 0(b) show the annual growth of nodes and edges in a log-scale. As observed, there is a rapid increase in the number of nodes and edges, which become 28K and 165K times larger within the six years. It means the NFT transaction network is highly active and growing at a fast speed.

To further figure out what leads to the growth, we analyse the newly added nodes in each pair of consecutive years. New nodes could join the network through different ways (i.e., mint, buy or airdrop NFTs). Among them, mint is the most common and easy way to obtain NFTs, where only a small number of gas fee is needed to pay. Figure 0(a) presents the trend of newly added mint nodes and non-mint nodes. We notice that the number of mint nodes added into the network is approximately the same magnitude of the total nodes at that time. Therefore, mint NFTs dominates the growth of

Figure 1: Evolution of nodes and edges.

nodes in the network at present, meanwhile the number of non-mint nodes are also increasing at a high velocity. These two phenomena result in the expansion of nodes.

Figure 0(b) also shows the trend of added bidirectional edges and self-edges. We can see that the number of bidirectional edges only account for a small volume. Unlike social networks where the edges are highly mutual, the NFT market is an anonymous ecosystem and the probability of mutually interacting with each other is relatively low. These bidirectional edges might happen in the scenarios of swap or wash trading activities . We also notice that there exist a very few self-loops in the network, which means these addresses transact with themselves. This abnormal phenomenon might be caused by a mistake input for the received address or these transactions are executed for testing. Furthermore, to characterize how active are these addresses, we compute the percentage of edges in which new nodes have links from or to old nodes, and the percentage of edges which only contain links between new nodes. Here, we refer to new nodes as the nodes created in the current year, and old nodes indicate the nodes that have existed in the previous years. Figure 0(c) demonstrates that more than 50% percent of newly added edges are constituted by the connections between new nodes and old nodes, except for the year of 2021. This indicates that most of the addresses remain active as the NFT ecosystem become mature. It is also very interesting to note that the newly created addresses are highly active in 2021, and at the same time, the whole NFT market capitalization reaches over $40 billion USD dollars in this year.

For completeness, we also show the degree distribution of the NFT transaction network in Figure 0(d) with log-log scale. As expected, it follows a power-law distribution. We observe that some nodes have the degree of 1, which indicates they did not conduct any other transactions after the NFTs were minted or transferred. There also exist several high degree hubs that are extremely active and interacts with more than thousands of different addresses. Among them, a special Null address (i.e., _0x000...000_)4_ has the highest degree, since every NFT mint activity will create a link from the Null address to the mint address.

### Dynamic Behaviors

**Evolution of Hub Nodes.** The node degree shows a heavily long-tailed distribution (i.e., Figure 0(d)), and the assortativity raises year by year (i.e., Figure 3(a) in Appendix C). Both these two measurements are highly relevant to the evolving of hub nodes in the transaction network. Figure 1(a) and 1(b) illustrate the correlations between node degrees and its number of new connections in two consecutive years. We use blue color to present the node degree distribution in the previous year, and then red color indicates the number of connections from new nodes in the current year. As expected, we can find that if a node had high degree in the previous year, it would have high probability to get more new node connections in the current year. Moreover, this observation is also validated by measuring their Pearson Correlation Coefficients. We evaluate the correlation coefficients between node degrees and its number of new node connections (in year 2018-2019 and 2019-2020), which are 0.2266 and 0.5476, respectively. The results reveal that these two factors are positively relevant. Thus, we can draw the conclusion that the NFT transaction network follows preferential attachment growth model , i.e., "the rich gets richer".

Next, we analyze the distribution of the hub nodes. Specifically, we note that half of the top-100 largest hub nodes are smart contract addresses. This is understandable, since smart contracts play an important role in providing various services (e.g., NFT fractionalization and staking) to other users

Figure 2: Correlation between hub nodes, new connections and mutual edges.

in the network. Thus, they tend to have high degrees once they are frequently used by others. The transactions with such smart contracts result in the increase of assortativity. Furthermore, there also exist some hub nodes that are not smart contracts. For instance, we observe that address _ox8a0...7005_ is the fifth largest hub nodes with the degree of 69,458. After checking its transactions manually, we find that all its transactions are about HyperNFT tokens, and it holds more than 180,000 such kind of tokens. Since it is strange, we then check its transactions in details and discover that this address creates a transaction every a few minutes, where the ID of the transacted NFT token is in a continuous and increase order. According to these clues, it is very certain that this address is a bot, which makes frequent transactions to pretend it's very prosperous to attract more users to join in. The hub nodes are responsible for the spreading of information in the network, thus it is necessary to investigate the properties of hub nodes.

**Mutual Interaction Edges.** In the previous study, we find that the reciprocity of the transaction network is relatively low, which is around 0.1 in the end (i.e., Figure 3(c) in Appendix C). This is quite different from the property in the social networks, where the reciprocity is very high and the value is above 0.7 . One possible reason is that people are prone to mutually following and interacting with their friends in the social networks, since it does not cost anything. However, it becomes different in the NFT transaction network, because we do not know who we are actually interacting with and every action costs in the blockchain. To uncover the reciprocity's characteristics, we focus on the mutual interaction edges. Specifically, we are interested in if two nodes are mutually interacting with each other, i.e., reciprocal edges \( u,v_{t}\) and \( v,u_{}\), what their maximum time interval distribution \(|t-|\) looks like, i.e., the maximum delay in days of the reciprocity. Figure 3(c) shows that mutual interaction edges forming within one day account for the highest proportion, and the maximum time interval can reach to more than 1,000 days. According to Figure 3(d), we can observe that about 15% of the reciprocal edges are formed almost simultaneously among those bi-directional edges, and more than 70% of them are formed within 90 days. From these observations, we can conclude that the NFT transaction network can not be regarded as an undirected network due to its low reciprocity value, and the simultaneously formed bi-directional edges can be a good indicator to judge the abnormal activities. For instance, it may be caused by the token transfers among the accounts controlled by a same person.

To further investigate this phenomenon, we want to know how many address pairs are suspicious in these bi-directional links. We first conduct some statistics for all NFT transaction addresses, which involves the following two factors: the number of transactions (including from transactions and to transactions) and the number of distinctly interacted addresses. Then, if one address has very limited transactions and it only interacts with a specific address, it is highly possible that these two addresses are of same person's wallets. This is because this address is actually not active, but it responses promptly in the bi-directional links. Similarly, another situation is although one address has a lot of transactions, it interacts with one specific address frequently and the specific address accounts for a large ratio of the total transactions. They may also belong to same person's wallets. Based on these two observations, we define the following two rules to identify the suspicious address pairs: 1) one of them makes less than 5 transactions or 2) the transaction ratios between them is larger than 0.8. If they satisfy at least one of the rules, we then believe these two addresses are likely to be same person's wallets. According to these rules, we discover that 33.72% of those simultaneously formed bi-directional links have high probability of being suspicious. This observation provides a new perspective for detecting anomaly transactions.

## 5 Downstream Applications

The above analyses provide a general overview of this live graph's properties. Our results demonstrate that the transaction network is highly active and evolving at a fast speed. These properties put forward new challenges for various downstream tasks. Next, we investigate three widely studied tasks.

### Temporal Link Prediction

Link prediction lies at the core of graph analysis and mining. The link prediction's goal is to predict whether a pair of node would form a link, which has been extensively used in diverse real-world scenarios like recommendation [79; 7] and knowledge graph completion , just to name a few. Inthis section, we focus on temporal link prediction, i.e., we try to forecast future interactions based on the historical transactions. Specifically, we investigate the snapshot-based representation for temporal link prediction via graph neural networks . Since each edge \(e\) has a timestamp \(_{e}\), we utilize a sequence of graph to depict the temporal transaction network \(G=\{_{t}\}_{t=1}^{T}\), where each snapshot is a static graph \(_{t}=(_{t},_{t},_{t})\) with \(_{t}=\{e|_{e} t\}\). Through modeling the sequential information of different graph snapshots, we could leverage the information available up to time \(t\) to forecast possible edges at time \(t+1\). Although various approaches have been proposed for temporal link prediction, it is unclear whether they can achieve satisfied performance in this highly active and large-scale temporal transaction network.

**Graph Neural Networks.** GNNs have gained great success in numerous learning tasks on graphs including node classification , graph classification  and link prediction . The objective of GNN is to acquire effective node representations through iteratively aggregating messages from its local neighborhood. Specifically, the \(l\)-th layer of a GNN model can be formulated as follows:

\[_{v}^{l}=^{l}(\{^{l}(_ {u}^{l-1},_{v}^{l-1})|u(v)\},_{v}^{l -1})\]

where \(_{v}^{l}\) is the node representation for node \(v\) at layer \(l\) and \((v)\) represents node \(v\)'s neighborhood. \(()\) indicates the message-passing function, which propagates information from its neighbors. \(()\) is the aggregation function, which updates its representation with node's neighborhood representations. For a \(L\) layers GNN, it aggregates information from the \(L\)-hop neighborhood. Different GNN architectures can have different message-passing and aggregation functions. The original GNN model is designed for static graphs, thus it cannot capture the underlying temporal information within the graph. To incorporate the evolving property, existing works utilize RNNs  to aggregate information from different graph snapshots. Hence, the dynamic GNN models have much more parameters compared with the vanilla GNNs, which is more difficult to scale to large graphs due to the back propagation through time constraints.

**Models.** We compare a number of recent state-of-the-art dynamic GNN models. (1) Dyngraph2vec  captures the temporal transitions with a deep architecture with dense and recurrent layers. (2) TGCN  integrates GCN with GRU to learn complex spatial and temporal dependencies. (3) EvolveGCN  use a RNN to adapt the graph convolutional network parameters. (4) GCRN  generalize TGCN with either GRU or LSTM. Moreover, it uses ChebNet  to encode the graph structure information, and separate GNNs are applied to compute different gates of RNNs. (5) DynGEM  utilizes deep autoencoder to perform graph embedding, then local and global constraints are employed to keep node representations being stable over time. (6) Roland  is an efficient learning framework designed for temporal GNNs, which updates its parameters through a combination of incremental training and meta-learning strategies .

**Settings.** For dataset, we remove all the transactions associated with the Null address, which results in 3.13 million nodes and 23.13 million edges in the directed graph. We set node feature as 1 for all the nodes and utilize area under the curve (AUC) as well as mean reciprocal rank (MRR) as evaluation metrics. For every node \(u\) connected by a positive edge \((u,v)\) at time \(t\), we randomly select 100 negative edges originating from node \(u\). Subsequently, we determine the rank of the score for edge \((u,v)\) among all the sampled negative edges. AUC characterizes the probability of ranking positive node more highly than negative nodes. MRR denotes the average of reciprocal ranks computed across all nodes. Following the settings in Roland , we utilize two different train-test splits: fixed-split and live-update. Among them, _the fixed-split setting assesses the models using all the edges from the last \(20\%\) graph snapshots_. Although it is widely used in the existing works, the fixed-split might produce misleading results based on edges merely from the last few graph snapshots, since the graph structure could constantly evolve in the real world scenario. _To eliminate this bias, we also utilize live-update split to test the models, which evaluates their performance over all the available graph snapshots_. \(10\%\) of edges are used to determine the early-stop condition in this setting.

**Results.** We present the link prediction results in Table 3. Specifically, we use three different time granularities (i.e, days, weeks and months) to construct the graph snapshot sequences, which results in 1,657 graph snapshots, 253 graph snapshots and 60 graph snapshots, respectively. All the models' performance is evaluated under two different settings, i.e., fixed-split and live-update. We notice that as the time granularity becomes coarser, the models' performance drops. This is because the NFT transaction network is highly active, which is about 68 million transaction volume per day on average in 2021. Thus, it will be more difficult to predict all the possible links in a long time period. Meanwhile, we can observe very high AUC scores in a daily time granularity, which indicates the models have a better capability of distinguishing the positive and the negative edges in this short time scenarios. Also, the performance in live-update setting is a little lower than the fixed-split setting. This is caused by the pattern shifts in different graph snapshots, which implies the patterns indeed evolve over the time. Therefore, we can conclude that it is necessary to model the NFT transaction network in a finer time granularity, and at the meantime this will result in longer graph snapshot sequence, which puts forward more challenges to model the temporal information.

### Temporal Node Classification

Node classification plays a crucial role in understanding the attributes, behaviors, and relationships of nodes in temporal graphs, offering valuable insights in diverse applications. By predicting the label of nodes at a particular time \(t\), we gain a temporal perspective that deepens our understanding of how nodes evolve over time and their dynamic characteristics. Specifically, we focus on categorizing nodes according to their transaction behaviors. They can be generally classified into five distinct classes: daily traders, weekly traders, monthly traders, yearly traders and the remaining traders. We first filter out nodes that only have one transaction. Then, each node' maximum transaction interval is calculated. If the maximum interval is within one day, we call it daily trader. Likewise, if the maximum interval is within one week and larger than one day, we call it weekly trader, and so forth. This process results in a large-scale directed graph with about 1.80 million nodes and 21.83 million edges. Following the setting of EvolveGCN , we use the first 80% graph snapshots as training set, the following 10% graph snapshots as validation set and the last 10% graph snapshots as test set. Similar to temporal link prediction task, we use the same set of GNN models and add a multi-class classification layer. Furthermore, nodes' degrees are encoded as features. The number of transactions between two nodes and their latest interaction timestamp are transformed as edge features. Two commonly used metrics (i.e., accuracy and recall) are employed to assess the model's performance.

**Results.** The node classification results are illustrated in Table 4 and key observations are as follows. Three granularities, i.e., days, weeks and months, are utilized to generate the temporal graph snapshot sequences. In accordance with the temporal link prediction task, we can draw similar conclusions. Roland could consistently outperform other baselines, and its variant Roland-MA (moving-average) stands out due to its parameter-free design and remarkable capability to capture evolving patterns. On the other hand, TGCN fails to achieve satisfactory performance because of the gradient vanishing problem in longer sequences. GCRN-GRU and Roland-GRU address this issue by utilizing separate

    &  \\   &  &  &  \\   & AUC & MRR & AUC & MRR & AUC & MRR \\  Dyngraph2vec & OOM & OOM & OOM & OOM & OOM \\ TGCN & 53.64\(\)1.60 & 14.24\(\)2.60 & 61.55\(\)6.24 & 36.16\(\)6.60 & 74.87\(\)4.99 & 45.97\(\)4.46 \\ EvolveGCN & OOM & OOM & OOM & OOM & OOM & OOM \\ GCRN-GRU & 95.86\(\)0.03 & **71.48\(\)0.49** & 93.14\(\)0.18 & **68.44\(\)0.05** & **86.74\(\)0.80** & 58.23\(\)1.23 \\ GCRN-LSTM & 94.12\(\)0.92 & 68.51\(\)2.36 & 92.90\(\)0.43 & 67.66\(\)0.31 & 86.44\(\)0.92 & 58.71\(\)0.84 \\ DynGEM & OOM & OOM & OOM & OOM & OOM & OOM \\ Roland-MA & **95.93\(\)0.15** & 66.34\(\)0.23 & **93.53\(\)0.13** & 65.06\(\)0.43 & 86.23\(\)0.85 & 54.93\(\)1.42 \\ Roland-MLP & 65.46\(\)6.10 & 43.76\(\)5.94 & 73.34\(\)7.87 & 42.04\(\)16.8 & 85.88\(\)2.22 & 57.58\(\)4.12 \\ Roland-GRU & 73.33\(\)11.5 & 49.45\(\)8.91 & 91.48\(\)1.67 & 66.28\(\)1.86 & 86.59\(\)0.88 & **59.37\(\)1.54** \\   Dyngraph2vec & OOM & OOM & OOM & OOM & OOM & OOM \\ TGCN & 58.22\(\)5.76 & 17.77\(\)10.7 & 59.94\(\)8.44 & 22.67\(\)19.3 & 75.01\(\)2.66 & 43.16\(\)0.75 \\ EvolveGCN & OOM & OOM & OOM & OOM & OOM & OOM \\ GCRN-GRU & 80.95\(\)1.92 & 39.13\(\)0.39 & 85.34\(\)0.26 & 46.08\(\)1.43 & 81.40\(\)0.34 & 43.68\(\)0.39 \\ GCRN-LSTM & 79.12\(\)2.14 & 37.83\(\)1.16 & 84.73\(\)0.34 & 42.89\(\)3.34 & 81.24\(\)0.80 & 41.47\(\)3.00 \\ DynGEM & OOM & OOM & OOM & OOM & OOM & OOM \\ Roland-MA & **90.47\(\)0.66** & **49.79\(\)0.95** & **88.74\(\)0.37** & **50.77\(\)1.13** & 83.93\(\)0.95 & 47.11\(\)1.16 \\ Roland-MLP & 56.32\(\)8.06 & 22.16\(\)15.4 & 70.88\(\)10.5 & 40.91\(\)10.8 & 79.38\(\)4.47 & 46.51\(\)2.61 \\ Roland-GRU & 60.04\(\)5.08 & 27.29\(\)6.26 & 75.93\(\)19.2 & 48.66\(\)13.7 & **84.36\(\)0.46** & **50.75\(\)0.83** \\   

Table 3: Temporal link prediction performance in fixed split and live-update settings. We repeat experiments with three different seeds to report the mean as well as standard deviation of AUC and MRR. We also present the results under different time snapshot granularities, e.g., days, weeks and months. OOM means out-of-memory.

GNNs or leveraging previous and current snapshots. Furthermore, the scalability of several baselines is limited and they experience out-of-memory (OOM) issues. Among the three time granularities, the month granularity is generally the most difficult scenarios. This is because with a month granularity, the time period between snapshots is longer compared with the day and week granularities. As a result, it becomes more challenging to accurately predict the temporal patterns and changes in node behaviors. The longer time gap between snapshots increases the complexity of modeling the evolving dynamics of the network and introduces more uncertainty, leading to decreased performance in terms of classification accuracy and recall. Therefore, we can conclude that given the highly active NFT transaction network, it is essential for the model to use a finer time granularity. Nonetheless, this choice results in longer graph snapshot sequences, presenting additional difficulties in accurately capturing the temporal information.

### Continuous Subgraph Matching

Continuous Subgraph Matching (CSM) plays a vital role in numerous real-time graph applications. The goal of CSM is to identify and report the occurrences of a given query graph \(Q\) within a temporal graph stream \(G\). It can be utilized in various scenarios. For example, when setting the query graph \(Q\) as wash trading patterns in e-commerce, CSM could identify the anomaly transaction patterns in the graph via exactly matching . Similarly, representing query graph as rumor patterns in social network could help to detect and prevent the spread of rumors . In this subsection, we set the query graphs as the frequent wash trading patterns in the NFT transactions. According to the definition in [73; 47], wash trading is an activity where the seller is on the both sides of the trade. The goal of wash trading is to influence the price or create the illusion that the item is very popular, which produces artificial activities in the marketplace. Wash trading has been prohibited by many countries. However, due to the anonymous nature of the blockchain, wash trading has become a severe issue in the NFT market6, which accounts for a large volume in the whole NFT transactions. For instance, the CryptoPunk's \(9,998\)-th NFT was traded between two wallets for 124,457 ETH (about $534 million USD), in which the buyer paid to the seller, then the seller transferred the money back to the buyer. Thus, it is important to detect the wash trading transactions to uncover the anomaly behaviors and reduce the risks in the market. We resort to CSM to identify the wash trading transactions. Five most common wash trading patterns are shown in Figure 3. As can be seen, all of them contain at least one cycle. Here is a toy example that exemplifies Pattern 1: Address A (_0x744...282_) initiated the sale of Azuki token 1,215 to Address B (_0xd39...263_). Subsequently, Address B sold the token to Address

    &  &  &  \\   & Accuracy & Recall & Accuracy & Recall & Accuracy & Recall \\  Dyngraph2vec & OOM & OOM & OOM & OOM & OOM & OOM \\ TGCN & 18.48\(\)2.66 & 31.15\(\)3.16 & 43.97\(\)4.57 & 32.99\(\)2.34 & 47.45\(\)3.49 & **32.53\(\)2.95** \\ EvolveGCN & OOM & OOM & OOM & OOM & OOM & OOM \\ GCRN-GRU & 41.06\(\)3.30 & 34.75\(\)2.93 & 46.78\(\)0.72 & **34.79\(\)0.42** & 47.42\(\)2.16 & 28.97\(\)3.22 \\ GCRN-LSTM & 46.14\(\)3.29 & **35.19\(\)3.61** & 48.04\(\)2.37 & 31.58\(\)1.75 & 49.32\(\)2.01 & 35.39\(\)1.49 \\ DynGEM & OOM & OOM & OOM & OOM & OOM & OOM \\ Roland-MA & **51.02\(\)2.01** & 28.77\(\)3.23 & **50.39\(\)0.45** & 26.33\(\)3.95 & 47.96\(\)2.69 & 22.33\(\)3.07 \\ Roland-MLP & 48.46\(\)3.18 & 30.62\(\)3.94 & 47.59\(\)3.39 & 31.67\(\)3.62 & 45.74\(\)4.75 & 35.04\(\)3.47 \\ Roland-GRU & 49.88\(\)2.15 & 33.38\(\)3.91 & 46.63\(\)3.07 & 33.85\(\)1.48 & **50.04\(\)0.37** & 32.17\(\)2.72 \\   

Table 4: Node classification performance in fixed split setting. We repeat experiments with three different seeds to report the mean as well as standard deviation of Accuracy and Recall.

Figure 3: Five most common wash trading patterns.

C (_0xeaa...c0f_), and eventually, Address C sold it back to Address A. These transactions happened within half an hour, and interestingly, the token's price surged from 8.98 ETH to 11.99 ETH. Such activity can raise suspicions of wash trading. We will use them as query graphs in the experiments to simulate the wash trading detection procedure. More details are given in Appendix E.

**Results.** Table 5 shows the key results of continuous subgraph matching. As we can see, RapidFlow  is the most efficient algorithm, which demonstrates about 18-724x speedups compared with the remaining frameworks. This is because the query reduction technique can significantly expedite the query procedure through an optimized matching order. We also observe that no algorithm can dominate others in different query patterns except RapidFlow. Among them, SymBi  and Graphflow  perform quite worst on pattern 5, which need 10x more time to produce the results. SJ-Tree  and IEDyn [30; 31] cannot output the results within the time limit. The reason is that SJ-Tree encounters memory exhaustion in the majority of cases, and IEDyn's index update bears too much overhead because of the maintenance for constant-delay enumeration. Furthermore, the number of matched subgraphs increase from pattern 1 to pattern 5, however the query time does not have too much difference in almost all the frameworks. We can conclude that these four frameworks are applicable to large-scale graphs with dense structures. They can effectively serve as a bridge to generate ground truth for continuous subgraph matching, providing valuable support for the training of deep graph learning models.

## 6 Conclusion

In this paper, we propose the concept of Live Graph Lab, which includes blockchain based temporal graphs that are openly accessible, fully recorded, and dynamically evolving over time. Specifically, we instantiate a live graph using the NFT transaction network and investigate its dynamic properties in a temporal graph analysis perspective. Our findings reveal both similar and distinct characteristics when compared to traditional networks like social networks, citation networks, and the Web. Through comprehensive experiments on the live graph, we uncover numerous insightful discoveries. The proposed live graph overcomes the limitations of existing datasets and enhances the diversity in graph research. We believe that the live graph lab will become an indispensable resource for the graph community and open up new opportunities. There are also various other potential use cases, such as identifying whether an account holds a specific type of tokens or predicting the range of tokens that the account possesses, etc.

## 7 Border Impact and Limitation

The Live Graph Lab can facilitate researchers from graph community by offering comprehensive blockchain based graphs via an easily accessible manner. Insights from this research can be directly applied to improve the design, security, and user experience of NFT platforms, leading to sustainable growth of the ecosystem. Meanwhile, as the live graph constantly records all the NFT transactions in the Ethereum blockchain, the possibility of encountering malicious activities could become a concern, such as bot transactions or wash trading, etc. It might also cause potential negative societal impacts. Since the dataset consists of complete transactions associated with the wallet addresses, it could enable the tracking of each wallet's behaviors, habits, and financial activities. This kind of tracking could be exploited for targeted advertising, manipulation, or surveillance. The dataset could also make it possible for malicious actors to analyze the transaction patterns and manipulate the NFT market, which could lead to unfair practices, price manipulation, and market instability.

   Query Patterns &  \\  Queries & Counts & SymBi & Graphflow & TurboFlux & RapidFlow \\  _p1_ & 19,338 & 1.22\( 10^{4}\) & 1.11\( 10^{4}\) & 1.11\( 10^{4}\) & **5.93\( 10^{2}\)** \\ _p2_ & 2,243,232 & 1.19\( 10^{4}\) & 1.44\( 10^{4}\) & 1.51\( 10^{4}\) & **6.13\( 10^{2}\)** \\ _p3_ & 3,012,738 & 1.11\( 10^{4}\) & 1.13\( 10^{4}\) & 1.08\( 10^{4}\) & **5.83\( 10^{2}\)** \\ _p4_ & 9,472,960 & 1.24\( 10^{4}\) & 1.43\( 10^{4}\) & 6.06\( 10^{4}\) & **6.45\( 10^{2}\)** \\ _p5_ & 3,154,355,868 & 1.34\( 10^{5}\) & 4.24\( 10^{5}\) & 7.72\( 10^{4}\) & **5.84\( 10^{2}\)** \\   

Table 5: Comparison of different frameworks on query time.