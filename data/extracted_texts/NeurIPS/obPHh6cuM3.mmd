# Proving Olympiad Algebraic Inequalities without Human Demonstrations

Chenrui Wei\({}^{1}\)

chenruiu97@gmail.com

&Mengzhou Sun\({}^{2}\)

sunm07@u.nus.edu

&Wei Wang\({}^{1}\)

wangwei@bigai.ai

###### Abstract

Solving Olympiad-level mathematical problems represents a significant advancement in machine intelligence and automated reasoning. Current machine learning methods, however, struggle to solve Olympiad-level problems beyond Euclidean plane geometry due to a lack of large-scale, high-quality datasets. The challenge is even greater in algebraic systems, which involve infinite reasoning spaces within finite conditions. To address these issues, we propose _AIPS_, an _Algebraic Inequality Proving System_ capable of autonomously generating complex inequality theorems and effectively solving Olympiad-level inequality problems without requiring human demonstrations. During proof search in a mixed reasoning manner, a value curriculum learning strategy on generated datasets is implemented to improve proving performance, demonstrating strong mathematical intuitions. On a test set of 20 International Mathematical Olympiad-level inequality problems, AIPS successfully solved 10, outperforming state-of-the-art methods. Furthermore, AIPS automatically generated a vast array of non-trivial theorems without human intervention, some of which have been evaluated by professional contestants and deemed to reach the level of the International Mathematical Olympiad. Notably, one theorem was selected as a competition problem in a major city 2024 Mathematical Olympiad.

## 1 Introduction

One of the key milestones in the field of artificial intelligence is the capability to reason  and prove theorems . However, theorem proving often involves long reasoning chains, complex mathematical structures, intricate calculations, and infinite reasoning spaces. Consequently, developing AI capable of proving complex mathematical theorems requires sophisticated reasoning and the ability to navigate through an extensive search space to construct a valid proof. The complexity of these problems lies in the need for effective heuristics and strategies to manage the vast number of possible actions and the lengthy sequences of logical steps necessary to arrive at a solution.

Existing work on grade school and college admission math problems has achieved remarkable success, e.g., GSM8K  and SAT Math . However, research focused on solving International Mathematical Olympiad (IMO)-level problems remains relatively sparse. Notable efforts in this area include AlphaGeometry , and GPT-\(f\) on miniF2F , which have made progress in solving Euclidean plane geometry at the Olympiad level and various mathematical competition problems, respectively.

A significant challenge for learning-based methods in this domain is the scarcity of suitable datasets, which limits the ability to train models effectively and hampers progress in achieving human-levelperformance on these hard problems. AlphaGeometry (Trinh et al., 2024) addresses this issue by synthesizing millions of theorems and proofs across different levels of complexity to train a neural language model from scratch. Similarly, the INequality Theorem proving benchmark, INT (Wu et al., 2020), can synthesize a theoretically unlimited number of theorems and proofs in the domain of algebraic equalities and inequalities. However, INT focuses on testing a learning-assisted theorem proving agent's generalization ability rather than increasing the difficulty to competition level.

Another significant challenge in automated theorem proving is designing effective search strategies to navigate the vast space of possible proofs. Recent advancements have highlighted various approaches to enhance search efficiency and proof success rates. Some studies have shown that incorporating Monte Carlo Tree Search (MCTS) can significantly aid in proving new theorems (Wu et al., 2020). Inspired by the success of AlphaZero (Zhang and Yu, 2020), other research has explored HyperTree Proof Search (HTPS) (Lample et al., ), which learns from previous proof searches through online training, iteratively improving its strategy by learning which paths are more likely to lead to successful proofs. Another innovative approach starts the proof search from the root goal that needs to be proved (Polu and Sutskever, 2020), expanding a maintained proof tree by prioritizing open goals based on their cumulative log probability.

In this work, we introduce _AIPS_, an _Algebraic Inequality Proving System_, which can generate a large number of high-quality theorems and solve IMO-level algebraic problems. AIPS focuses on ternary and quaternary inequalities, excluding \(n\)-variable inequalities represented recursively in formal verification systems. Among the generated theorems, some have proven to be very challenging, with one selected for a major city's 2024 Mathematical Olympiad. We present novel and challenging inequality theorems discovered by AIPS in the supplementary material, which have been carefully evaluated by IMO-level professional contestants and found to be comparable to IMO inequalities from around the year 2000.

Additionally, AIPS incorporates a value network to evaluate newly generated inequalities, selecting subgoal candidates based on the top scores provided by the value network. The value network is trained on synthetic datasets with increasing difficulty in a curriculum manner. In our experiments, AIPS proved difficult theorems up to the IMO level and solve 10 out of 20 problems in an IMO-level inequality test, significantly surpassing the performance of previous Large Language Model-based theorem provers (Polu and Sutskever, 2020; Polu et al., 2022; Yang et al., 2024; Song et al., 2024).

The main contributions in this paper are summarized as follows:

* We propose a symbolic deductive engine capable of efficiently generating high-quality and solving high-difficulty algebraic inequality theorems. This engine addresses the bottleneck of lacking large-scale, high-quality data in this field.
* We demonstrate that a symbolic algebraic inequality prover can be significantly enhanced under the guidance of a value network, especially when the value network is trained in a curriculum manner.
* Our AIPS can generate challenging and elegant inequality theorems, with one theorem selected for a major city's Mathematical Olympiad. AIPS can prove 10 out of 20 IMO-level inequalities, outperforming state-of-the-art methods.

## 2 Algebraic Inequality Proving System

### Symbolic Deductive Engine for Algebra

Interactive theorem provers, such as Lean, can verify mathematical operations but lack the ability to perform automatic mathematical reasoning by combining computational rules. This challenge is amplified in the automatic proof of algebraic inequalities, which often involves numerous calculations, extensive transformation rules, and complex theorem matching. To address this, we designed a symbolic deductive engine that integrates with SymPy 1, supporting algebraic reasoning through theorem matching and applying transformation rules. Please refer to Appendix A for more details.

### Olympiad-Level Inequalities Proof Set

One of the main challenges in enabling learning-based models to solve complex mathematical problems is the scarcity of large-scale, high-quality datasets. To overcome this obstacle, we develop a theorem generator that effectively generates Olympiad-level inequality theorems by implementing a forward reasoning method.

We selected 10 synthetic problems and invited Olympiad medalists to evaluate their difficulty and elegance. Some generated theorems exceeded the difficulty of early IMO inequalities, with one theorem being used in a city's 2024 Mathematical Olympiad. Evaluation details are provided in Appendix C.

### Neural Algebraic Inequality Prover

By leveraging the capabilities of the deductive engine and the Best-First-search algorithm (Dechter and Pearl 1985), we train an inequality prover through value curriculum learning. This prover formulates the algebraic inequality proving as a sequential decision-making process by selecting theorems to generate highly human-readable proofs. As shown in Fig. 2, given a goal and related conditions, AIPS first generates a list of subgoals by applying a set of theorems at each iteration. A value neural network is then used to evaluate these newly generated subgoals along with the previous subgoals. The top-value subgoal is selected for the next step of reasoning. This iterative process continues until the proof is successfully completed. See Appendix A.5 for more details.

## 3 Experiments

We evaluate AIPS as well as 10 different baseline models on MO-INT-20, an Olympiad-level inequality problem test set, with each problem limited to 90 minutes of solving time, consistent with the standard problem-solving time in the IMO. It outperforms the state-of-the-art methods in terms of the number of solved problems, demonstrating the strong algebraic intuitions developed by the learned value network. The comparison results are shown in Table 1.

**Analysis.** Large language models (LLMs), formal theorem provers, and neural symbolic provers each demonstrate distinct strengths in the test. LLMs often make trivial logical or computational errors. Formal theorem provers, such as LeanCopilot, struggle with planning the proof for complex math problems. Neural provers with different search method and heuristics show different performance in the test. Please refer to Appendix B.5 for more details.

Figure 1: Example of generating synthetic theorems in AIPS.

Following a curriculum learning strategy on 1,000 inequality problems, AIPS achieves the best performance, solving 10 out of 20 problems. Among the 10 problems from the IMO or IMO shortlist, it successfully solves five, reaching the average level of IMO contestants. We also test the performances of AIPS after 200, 400, 600, and 800 loops of fine-tuning value network (see Appendix B.3). The results demonstrate that our value curriculum learning strategy is very effective, with the number of proof search steps significantly decreasing during the training process, and the number of solved problems increasing to 10 ultimately.

## 4 Conclusion

In conclusion, solving Olympiad-level mathematical problems is a significant milestone in machine intelligence and automated reasoning. The lack of large-scale, high-quality datasets presents a challenge, particularly in algebraic systems. To address this, we propose _AIPS_, an _Algebraic Inequality Proving System_, which autonomously generates complex inequality theorems and effectively solves Olympiad-level inequality problems without human input. Utilizing a value curriculum learning strategy, AIPS demonstrated strong mathematical intuition by solving 10 out of 20 International Mathematical Olympiad-level problems. One of these theorems was selected for a major city's 2024 Mathematical Olympiad.

 
**Model Category** & **Model** & **Problems Solved (20)** \\   & Gemini 1.5 Pro & 1 \\   & GPT-4 & 0 \\   & GPT-4 Turbo & 0 \\   & Llemma-7b & 0 \\  Interactive Theorem Provers & LeanCopilot (LeanDojo) & 0 \\   & DE + GPT-4 Turbo’s heuristics & 6 \\   & DE + BFS & 4 \\   & DE + MCTS & 5 \\   & DE + tree-depth heuristic function & 7 \\   & AIPS with pretrained value network & 7 \\   & AIPS & 10 \\  

Table 1: Model Performances on the MO-INT-20. **DE denotes our deductive engine**. BFS and MCTS are Breadth-First Search and Monte Carlo Tree Search, respectively.

Figure 2: Overview of AIPS proving process for an algebraic inequality.