# Atlas3D: Physically Constrained Self-Supporting Text-to-3D for Simulation and Fabrication

Yunuo Chen\({}^{1}\), Tianyi Xie\({}^{1}\), Zeshun Zong\({}^{1}\), Xuan Li\({}^{1}\),

**Feng Gao\({}^{2}\)** **Yin Yang\({}^{3}\), Ying Nian Wu\({}^{1}\), Chenfanfu Jiang\({}^{1}\)

\({}^{1}\)University of California, Los Angeles, \({}^{2}\) Amazon, \({}^{3}\) University of Utah

{yunuoch, tianyixie77, zeshunzong, xuanli1}@ucla.edu, fenggo@amazon.com,

yin.yang@utah.edu, ywu@stat.ucla.edu, cffjiang@ucla.edu

Equal contribution.This work is not related to F. Gao's position at Amazon.

###### Abstract

Existing diffusion-based text-to-3D generation methods primarily focus on producing visually realistic shapes and appearances, often neglecting the physical constraints necessary for downstream tasks. Generated models frequently fail to maintain balance when placed in physics-based simulations or 3D-printed. This balance is crucial for satisfying user design intentions in interactive gaming, embodied AI, and robotics, where stable models are needed for reliable interaction. Additionally, stable models ensure that 3D-printed objects, such as figurines for home decoration, can stand on their own without requiring additional support. To fill this gap, we introduce Atlas3D, an automatic and easy-to-implement method that enhances existing Score Distillation Sampling (SDS)-based text-to-3D tools. Atlas3D ensures the generation of self-supporting 3D models that adhere to physical laws of stability under gravity, contact, and friction. Our approach combines a novel differentiable simulation-based loss function with physically inspired regularization, serving as either a refinement or a post-processing module for existing frameworks. We verify Atlas3D's efficacy through extensive generation tasks and validate the resulting 3D models in both simulated and real-world environments.

## 1 Introduction

Generating high-quality 3D content is of great importance in modern visual computing. Realistic 3D models are highly sought after in computer graphics, while robust real 3D assets are gaining attention in training embodied AI. Nevertheless, the standability of 3D models - the ability to stand steadily without additional support - is often neglected. Real-world man-made objects such as action figures, toys, and furniture inherently possess some degree of geometric stability, allowing them to be safely placed on the ground. Although one usually takes such standability for granted, existing generative models fail to produce steady 3D assets due to their lack of physical perception; see Fig. 1.

Incorporating this stability expectation into 3D generation will significantly reduce the human effort required for tasks such as sorting out unqualified meshes, post-processing geometries, or adding external supports before actually using the 3D asset in any simulator or the real world. Furthermore, creating physically plausible 3D content will enhance the fidelity of simulations and policy training with these objects, potentially narrowing the sim-to-real gap and empowering embodied AI in robotic tasks. Towards this goal, we develop a 3D generation framework that can produce high-quality models adhering to basic physical laws, such as gravity, stability, and frictional contact.

Several attempts have been made to incorporate physical constraints into 3D generation. Yang et al. utilized the spatial and physical sense of LLM to design floor plans and furniture arrangements .

PhyScene introduced physical guidance, such as collision and reachability constraints, to diffusion models to generate furniture layouts . However, both works primarily consider straightforward spatial constraints, such as non-collision, and fail to incorporate more complex physics. Mezghanni et al. proposed a GAN-based network to generate physically-aware geometries by training a neural stability predictor using datasets labeled by Bullet . Another GAN-based work by Wang et al. employed CFD software to compute vehicle drag coefficients, guiding the generation of stream-lined vehicle meshes . Such indirect incorporation of physical simulations, however, results in suboptimal efficiency and accuracy. Furthermore, due to the low expressibility of the backbone latent representation, the versatility of the generated results is very limited compared to current state-of-the-art diffusion-based models, as the results are typically confined to specific categories (e.g., furniture and vehicles). Most recently, Ni et al. bridged differentiable physical simulation with differentiable rendering to obtain virtual 3D reconstructions from real-world images that are physically plausible in simulators. Their work primarily focused on simple four-leg-supported objects such as tables and chairs . Moreover, the evaluations of all aforementioned works are conducted in virtual simulators, leaving their performance in the real world untested. This limitation hinders potential downstream applications such as industrial manufacturing and robotic manipulation.

Since the pioneering work DreamFusion , Score Distillation Sampling (SDS) has demonstrated efficacy in elevating 2D content to 3D, inspiring numerous follow-up studies [8; 35; 46; 69; 88; 109]. These advancements have enhanced both the versatility of generated content and the quality of textures. However, none have addressed the crucial issue of physical stability. On the other hand, traditional computational fabrication has concentrated on employing topology and shape optimization to ensure that 3D printed objects can stand in a balanced state . Directly integrating these methods with 3D generative AI as a postprocessing module is suboptimal. Shape optimization disregards the original input conditions of diffusion models, while topology optimization produces internal structures that defy intuitive physics, rendering them unsuitable for training embodied AI systems designed to emulate human-like reasoning about physical objects.

Observing this gap, we introduce Atlas3D, a generation pipeline that produces physically plausible, self-supporting 3D models from text. Incorporating differentiable physics-based simulation into our process, we generate models that are both simulation- and fabrication-ready. That is, they can be directly utilized in physical simulators, or 3D-printed for real-world applications; see Fig. 1 and Fig. 2. As our method is orthogonal to previous SDS-based techniques, which focus on non-physical qualities, it can be seamlessly integrated into many existing generation frameworks, functioning either as part of the refinement stage in a multi-stage method or as a post-processing step in a single-stage method. We demonstrate the efficacy of Atlas3D by comparing the stability of our models with those

Figure 1: Simulation in ABD : (a) 3D models generated from our Atlas3D framework can stand steadily on the ground; (b) those generated from existing methods tend to fall over.

produced by existing methods. Validation examples reveal that our generated models can be deployed as virtual simulation assets. Their stability transfers directly to the real world, as evidenced by our 3D printed results, suggesting further applications in robot training.

## 2 Related Work

Diffusion-based 3D GenerationDue to the abundance of information encoded in large image latent diffusion models (LDMs) , extensive studies have used pre-trained LDMs to distill 3D content. One approach is to fine-tune LDMs to support novel view synthesis, with a separate multiview fusion step to produce 3D content [39; 68; 99; 38; 37; 89; 95; 42; 80; 25; 106; 41; 9; 83]. Another approach, which is more related to our paper, is using LDMs as likelihood discriminators. A differentiable renderer is connected to a 3D representation, and the LDMs guide the optimization of the representation parameters.  proposed Score Distillation Sampling (SDS). Efficiency has been improved by coarse-to-fine strategies [35; 60; 79; 8] and timestep scheduling [18; 100]. 3D priors are involved to improve multiview consistency [108; 66; 31; 1; 93; 36; 78]. Multiview diffusions can also be used to evaluate SDS [69; 87; 105; 94]. Other researchers have explored SDS variants or improvements [84; 77; 88; 24; 101; 16; 109; 96]. 3D LDMs that directly generate 3D representations are also explored, such as compositional scenes [17; 57], point clouds [43; 81; 51], SDFs [70; 107; 30], occupancy fields [15; 72; 45; 12] and NeRFs [3; 11; 52; 6; 55; 5; 75; 23].

Physics-aware 3D GenerationMost existing 3D generative models focus only on geometry or appearance modeling, with physics priors being underexplored. Time-independent physical constraints, such as penetrations, can be directly defined by penalties [97; 17; 82; 40; 102]. For time-dependent physical qualities, such as stability and comfort, data-driven quality checkers trained with offline simulators can be applied [10; 48; 4]. Offline simulators can also be used as validators to augment the training dataset  and update the design with reinforcement learning , and as dynamics generators for generated 3D assets [91; 21; 62]. Another direction is to utilize differentiable simulations, which have be widely used in tasks like robotic control [74; 19; 61; 34; 76] or inverse problems [33; 20; 103; 53; 32; 73; 104; 33]. They can also be applied in 3D content generation to define physics-based losses to aid per-instance generation [54; 92] or model training .

## 3 Background

### Score Distillation Sampling

SDS-based methods are shown to be effective in distilling 3D models from 2D images. They utilize a 3D representation such as implicit density field, implicit Signed Distance Field (SDF), or tetrahedral SDF , a differentiable renderer like NeRF , NeuS , or Nvdiffrast , and a pre-trained text-to-image model such as Stable Diffusion  serving as diffusion guidance. The generation process involves optimizing the parameters \(\) of the underlying 3D representation, where the 3D shape is differentiably rendered to 2D images \(=g()\) and compared against the real distribution from the diffusion model with text guidance \(y\):

\[_{}=_{t,}[w(t)\|_{}(_{t},y,t)-\|^{2}],\] (1)

where \(_{t}\) is the noisy image at noise level \(t\), \(w(t)\) is a weighting function, and \(_{}\) is the predicted noise. We refer readers to the Appendix for more technical details on SDS optimization.

### Rigid Body Dynamics

To incorporate physics into our framework, we propose predicting the dynamics of the generated 3D models using a differentiable simulator, where all objects are treated as rigid bodies. We follow the conventions in  to define the dynamical states of the simulation.

The kinematics of a rigid body are described by its mass \(M\) and body-space inertia tensor \(_{}\), which remains constant. Assuming the center of mass of the body initially lies at the origin, the physical state \(\) of the body at time \(t\) (not to be confused with the noise level in diffusion) includes position \((t)\) and orientation \((t)\) (spatial information), and its linear and angular momentum \((t)\) and \((t)\) (velocity information). The rigid body equations of motion are given by \[(t)=(t)\\ (t)\\ (t)\\ (t)=(t)\\ (t)*(t)\\ (t)\\ (t),\] (2)

where \((t)\) and \((t)\) are the total force and torque exerted on the body, \((t)=(t)}{M}\) is the linear velocity, \((t)=(t)^{-1}(t)\) is the angular velocity, \((t)=(t)_{}(t)^{T}\) is the world-space inertia tensor, and \(*\) denotes cross product of \(\) with the columns of \(\). The physical state at a later time can be derived via time integration: \((t)=(0)+_{0}^{t}(s)ds\), which can be solved by numerical methods. By optimizing the physical states together with the SDS loss, we can jointly refine both the 3D geometry and the physical attributes of the generated results.

## 4 Atlas3D Algorithm

We introduce Atlas3D, a plug-and-play algorithm for generating 3D models from text. Focusing on man-made objects such as action figures and toys, which generally do not deform, Atlas3D treats generated models as rigid bodies and incorporates physics-based guidance into the generation process.

### Physics Incorporation

As mentioned in SS 3.2, we predict the dynamic behavior of generated models by rigid body simulations. While various explicit or implicit representations of 3D shapes can be chosen in a generation network, we opt for triangular meshes in our framework as they facilitate frictional contact modeling and simplify kinematics computation. Given a triangle surface mesh representation \(()\), where \(\) is the implicit parameter, we integrate \(\) into a rigid body represented by the dynamic state \((t)=[(t),(t),(t),(t)]^{T}\), where the world-space location \(\) of any point \(\) on the body is \((t)=(t)+(t)\). Assuming the 3D model is initially placed upright3 on the ground with the bottom point touching the surface, we define standability as:

\[_{t}(t)=(0).\] (3)

Standardability intuitively indicates an equilibrium state where all external forces acting on the object are balanced, and the physical state remains unchanged over time. However, perfectly placing an object straight on the ground without initial velocity is impractical in the real world. For example, when manually placing a cube on a flat table, the bottom face is unlikely to be perfectly parallel to the table surface. A stable 3D model should recover its initial state under mild perturbations, such as minor shaking. This state is known as stable equilibrium. Motivated by this, we augment standability with stable equilibrium \((t)\) defined as

\[(t)=(0)+_{0}+_{0}^{t}(s)ds _{t}(t)=(0),\] (4)

where \(_{0}\) represents mild perturbations to the initial physical state. We first describe how to incorporate the standability criterion (Eq. 3) into the optimization process of 3D generation, and then explain how to further augment it with stable equilibrium (Eq. 4). Additionally, we introduce geometry regularization to enhance the smoothness of generated meshes.

#### 4.1.1 Standability through Differentiable Simulation

We utilize a differentiable rigid-body simulator to obtain the physical state \((t)\). Assuming that the 3D model will eventually reach its steady state, \( T\) large enough such that \( t>T,(t)=(T)\). Let \(\) denote a differentiable simulation function. We approximate \((T)\) via simulation:

\[(T)=((),(0),,T).\] (5)

Figure 2: 3D-printed figurines created with Atlas3D stand stably, while those without Atlas3D have fallen down.

Here \(T\) is the simulation end time, \(\) captures material parameters such as density and friction coefficient, as well as simulator parameters such as time step and damping. We adopt the semi-implicit Euler time-integrator in Warp  for simulation.

Assuming the initial translation, rotation, and velocity are all zero, the difference between \((T)\) and \((0)\) arises only from discrepancies in spatial location, as the velocity at the final steady state is also zero. Therefore, we propose a standability loss to penalize rotational deviation due to instability:

\[_{}=\|(T)-(0)\|_{2}^{2}=\|(T)-\|_{2}^{2},\] (6)

where \(^{3 3}\) represents the rotation matrix. We disregard the translation \(\), as real-world instability mostly leads to rotational deviation from the initial state, such as falling to one side, while most translations, like falling due to gravity, are irrelevant to standability.

With a differentiable simulator, the standability loss can be backpropagated to mesh vertex coordinates and then to the implicit parameter \(\) as \(_{}}{d}=_{}}{ d}}{d}\). In theory, any differentiable simulator is compatible with our framework.

#### 4.1.2 Stable Equilibrium

Although the standability loss directly penalizes the non-standability of a 3D object, it can be slow to compute, especially when \(T\) is large and many time steps are required, creating a huge computational graph. Consequently, both the simulation itself and the backpropagation of gradients through the simulation trajectory are time-consuming. Additionally, standability does not necessarily imply stable equilibrium, which is crucial for real-world 3D objects such as action figures and toys. Without this property, an object remains unstable even if standability is achieved, known as unstable equilibrium. Unstable equilibrium means that when a disturbance force is applied, the object moves away from its original position instead of recovering. Fig. 3 visualizes the difference between stable and unstable equilibrium. In the absence of perturbation, geometries like the upside-down triangle may remain standable in a simulator but are clearly unstable in the real world. Thus, we augment standability with stable equilibrium (Eq. 4). One straightforward way to incorporate this property is to introduce initial perturbation \(_{0}\) into the simulator. However, this would require many more simulations with various perturbations and subsequent loss backpropagation, which is extremely time-consuming.

Inspired by the concept of a potential well , we augment our optimization objective with a robust and efficient stable equilibrium loss \(_{}\). Specifically, for an object to be robustly standable, it needs to reside at a local minimum of potential energy--specifically, gravitational potential energy--so that if perturbed, gravity will act as a restoring force that returns the object to its original state. For a rigid body, gravitational potential energy is determined by the height of its center of mass. Thus, for any object in a stable equilibrium state, the center of mass would rise if it is slightly perturbed. This leads to our formulation of the stable equilibrium loss \(_{}\). Let \(_{}\) denote the position of the center of mass of the underlying geometry and \(H()\) denote the distance of the point \(\) to the ground, assuming the object's pivot point is at \(z=0\). The stable equilibrium loss is defined as:

\[_{}:=_{^{2},|| ||=1}[\{H(_{}(_{}^{ }))-H(_{}()),0\}],\] (7)

where \(_{}^{}\) represents the rotation of \(\) radian about axis \([^{T},0]^{T}\). Mathematically, a local minimum of gravitational potential energy is reached if \(_{0}\) such that \((0,_{0}),_{}=0\). In practice, we fix the perturbation scale \(\) and uniformly sample 20 perturbation directions \(\) in \(xy\)-plane.

### Additional Regularization

While standability loss \(_{}\) and stable equilibrium loss \(_{}\) provide a well-defined objective for robust standing, they may lead to distorted optimized meshes due to the high-dimensional searching

Figure 3: 2D illustration of stable equilibrium and unstable equilibrium. (a) A square is stable as a small perturbation of \(\) increases in \(H(_{})\);(b) An upside-down triangle is unstable as tilting decreases \(H(_{})\).

space of implicit parameter \(\) without constraint. To constrain the optimization space and obtain smooth meshes, we add a normal consistency term that favors smooth solutions:

\[_{}=|}_{(i,j)} (1-_{i}_{j}),\] (8)

where \(\) is the set of the triangle pairs sharing a common pair with \(_{i},_{j}\) being their normals respectively. This term maximizes the cosine similarity between neighboring surface triangle normals, leading to smoother meshes. Considering the bottom surfaces of most robust standing objects are flat, we apply the Laplacian loss to a subset \(\) of vertices with a height lower than a threshold \(h_{b}\):

\[_{}=|}_{i} _{i}_{2},\] (9)

where \(_{i}=()_{i}^{3}\) calculates the differential coordinates of vertex \(i\) with \(\) being the Laplacian matrix of the mesh graph and \(\) representing mesh vertices. Intuitively, this loss term attempts to minimize the distance between vertex \(i\) and the average position of adjacent vertices.

### Method Overview

With the physically-inspired loss terms derived above, we now describe how to incorporate them into the text-to-3D framework. SDS-based methods and their variants start optimization with a random initialization of the implicit parameters, which initially have no knowledge of the model's geometry. Adding physical constraints at this early stage would be ineffective. Therefore, we propose a two-stage training strategy: the coarse stage and the refine stage. In the coarse stage, we generate a rough shape of the model using a text prompt. We can adopt any SDS-based generation framework as our baseline model, offering various choices of implicit representation and differentiable renderers. In the refine stage, we optimize the geometry with our physical constraints included. For this, we use a tetrahedral SDF representation  and employ Deep Marching Tetrahedra (DmTet) to differentiably convert the coarse geometry from implicit density or SDF as necessary. We utilize Nvdiffrast  as the differentiable renderer and Stable Diffusion v2.1  for guidance. We propose the following loss function for the joint optimization of texture, geometry, and stability:

\[=_{}_{}+_{}_{}+_{}_{}+_{}_{}+_{}_{}\] (10)

In practice, we observe that adding standability loss once every 10 iterations is sufficient to ensure a significant reduction in loss without notably increasing computational overhead.

## 5 Experiments

In this section, we devise comprehensive experiments (both virtual and real-world) to demonstrate the efficacy of our method. We use a series of text prompts to generate 3D models that we expect to be self-supporting, and compare the generated results with baseline models. Our models are verified by simulation for stability and then fabricated using a 3D printer for real-world testing. We refer readers to the Appendix for more details about implementation, training, and experiment setup.

Figure 4: Comparison with Magic3D  includes zoom-in views that highlight the detailed changes in geometry. Our method enhances Magic3D with physics priors to generate self-supporting meshes.

### Simulation Verification

Qualitative ComparisonUsing the same text prompts, we compare our generated models with previous methods. The quality of the results is assessed by their stability, which is verified by a forward simulation: we simulate the generated models in an upright initial position close to the ground for a sufficiently long time and record whether they fall. Using Magic3D  as the baseline model, we visualize the initial state and a later state in Fig. 4. Our generated meshes remain stable throughout the simulation, while the baseline models fail under the same conditions due to a lack of consideration for physics.

We highlight the main changes in mesh topology that enable the models to stand (see Fig. 4). These changes include modifications to both the overall shape and specific local geometries. More specifically, our physical adjustments alter the contact surface to gain more support from the ground and shift the center of mass to be slightly lower and more centered above the contact surface. These macroscopic and microscopic optimizations jointly increase the support to the models, thus ensuring their stability. Note that our method slightly modifies the texture of the generated results as we are jointly optimizing our physical adjustments with the SDS loss.

Since we do not assume a specific baseline model in the first stage, we can vary the model used in the coarse stage to generate versatile, physically-aware 3D meshes based on different existing SDS generation models. We use MVDream  as another baseline model and compare the results side-by-side with ours in Fig. 5. Our method improves the geometry of the mesh and ensures stability in simulation. The quality of the texture and the main part of the shape is determined by the underlying model used in the coarse stage, while we focus on improving the physical stability in the refinement stage. More qualitative comparisons with previous methods are provided in the Appendix.

Ablation StudyWe perform ablation studies to demonstrate the necessity of our proposed losses. It can be observed in Fig. 6(b), that without standability loss \(L_{}\), the model fails to stand. While the model can still stand without stable equilibrium loss \(L_{}\), as demonstrated in Fig. 6(c), it is less stable under perturbation (see next section for details). The geometry regularization loss term \(L_{}\) helps smooth the geometry and avoid spiky artifacts on the surface as shown in Fig. 6(d). Additionally, we show that applying mesh regularization as a post-processing step, rather than integrating it with SDS loss in a joint optimization, can degrade text alignment as this neglects the semantics during the deformation process (see Fig. 6(e)).

Figure 5: Atlas3D is also compatible with MVDream , enhancing it with stable standability.

Figure 6: Ablation study of each loss term.

Stability under PerturbationIn the real world, placing an object on the ground always involves some noise, as both human and robot manipulation have imprecision in angles and directions. Hence, the standability of an object under small perturbations is crucial for improving the success rate of such tasks.

To mimic this uncertainty in our framework, we evaluate the stability of our generated models under a small initial rotation. With a given precision \(_{}\), we rotate the generated mesh at random angles \(_{y},_{x}(-_{},_{})\) in both the \(y\) and \(x\) axes, respectively (with the \(z\) axis being the up direction). The mesh is then placed close to the ground and tested in a simulation to see if it can still stand. We choose 13 different values of the maximum perturbation angle \(_{}\) and perform 100 random tests with each angle on 6 of our generated models. We report the success rate in Fig. 7. We define a successful test as: after a sufficiently long time period, the maximum height of the model stays within 3% of the initial maximum height.

Due to the presence of physical constraints, our generated models can withstand small initial perturbations, while the baseline models fail to stand when placed straight up (without rotation), let alone with perturbations. Furthermore, introducing the stable equilibrium loss consistently increases the success rate of standing under different scales of perturbations, as shown in Table. 1.

Standability on Different PlatformsOur pipeline can be generalized to learn standability on various platforms, not just flat ground, by incorporating them as boundary conditions in the simulator. To demonstrate this, we use a 10-degree inclined plane and a sphere, then train our 3D model separately to stand still on each. Modeling frictional contact is crucial for achieving stability in such scenarios. As shown in Figure Fig. 8, our optimized mesh stands stably on both the incline and the sphere with the help of static friction, whereas the baseline model fails as expected.

Simulator Cross-validationWhile we base our method on a differentiable rigid-body simulator with a semi-implicit Euler time-integrator, our pipeline is compatible with any other physics-based simulator as the backbone, with differentiability required for the training stage. To verify the reliability of models generated with our simulator, we include an external simulator in the testing stage to verify the correctness of the simulated dynamics. We choose the Incremental Potential Contact (IPC) method [27; 29], which has been proven accurate for frictional contact. We validate the correctness of every single generated model and visualize the simulation results in Fig. 1.

  Perturbation Angle \(_{}\) & 0 & 0.01 & 0.02 & 0.04 & 0.08 \\  w/ stability loss & 1 & 1 & 0.99 & 0.69 & 0.4 \\  w/o stability loss & 1 & 0.97 & 0.71 & 0.62 & 0.23 \\  

Table 1: Comparison of success rate under perturbation (goose).

Figure 8: Standability evaluation on uneven surfaces.

Figure 7: Success rate of models standing under perturbation.

our method. We randomly select 150 prompts from  and manually exclude 43 prompts deemed unfeasible (for instance, it does not make sense to require "a swan and its cygnets swimming in a pond" to be standable), leaving a total of 107 prompts. We use the two-stage Magic3D  as the baseline model and compare our optimized mesh with the results from the refine stage of the baseline under the same settings (e.g., iterations, loss weights).

To evaluate the standability of the baseline method and our method, we run the rigid body simulation in Warp with simulation end time \(T=2.0\) at which almost all objects have reached the steady state. We propose Time-Averaged Rotation Deviation Loss (TRD) defined as

\[=_{0}^{T}||(t)}-( 0)}||_{2}t\] (11)

to assess the standability, as a representation of the average tilting of the upward direction \(}\) (of the object) over time. We approximate the integral (Eq. 11) with discrete quadrature \( t=0.02\). Results are plotted in Fig. 94. The mean TRD score is reduced by more than six times compared with the baseline method. As shown in Table. 2, we calculate the average CLIP score  of 107 generated shapes for both our proposed method and baseline. Furthermore, Elo (GPT-4o)  scores are presented. Both metrics illustrate that our method not only implements physics-based stability but also maintains the fidelity of the generated 3D shapes in terms of content alignment and overall shape quality. More details are provided in the Appendix.

### Real-world Validation

One major advantage of incorporating physics-based simulation into the optimization pipeline is that it bridges the gap between the generated model and the real world. Our method ensures the direct usability of the model for fabrication, with success primarily dependent on the accuracy of both the simulator and the manufacturing machine.

3D Printing and User StudiesWe test the readiness of our generated meshes for real-world application by producing eight figures using a 3D-printing device (Zortrax M200 with Z-ABS filament material). For reference, we also print the corresponding baseline meshes generated without physical constraints. Our physically constrained figures can steadily support themselves when gently placed on an even surface, while the baseline figures either fail to stand at all, or require extensive adjustments and fall easily with little perturbation (see Fig. 2).

We conduct user studies with these printed figures to assess their stability under different types of human manipulation. Ten users were asked to place the figures upright on a table, with five trials for each figure, resulting in a total of 800 trials. Fabricated figures generated from the baseline has a success rate of 7%, while figures generated from our method has an overall success rate of 92.25%.

   Metrics & Ours & Magic3D \\  TRD \(\) & 0.060 & 0.389 \\ CLIP \(\) & 25.356 & 25.781 \\ Elo (GPT-4o) \(\) & 970.774 & 1029.226 \\   

Table 2: Quantitative Evaluation

Figure 10: Standability test using a robotic arm. More results are shown in the Appendix.

Figure 9: TRD results from 107 prompts using the Magic3D baseline and our method.

Itemized results are provided in the Appendix. Our method significantly increases the physical stability of the models under varying human efforts.

Validation with a Robot ArmTo showcase the compatibility of our framework with robotic applications, we test our fabricated figures with a teleoperated LewanSoul LeArm robot arm outfitted with a two-finger parallel gripper (see Fig. 10). The gripper is set to initially grasp a figure above the ground. It slowly moves downward, and is then gently released to place the figure on the ground. Four trials were performed for each figure, yielding 64 trials in total. For the baseline method, 6.25% trials resulted in successful standing figures, while ours has a success rate of 90.6%. Experimental data are provided in the Appendix and supplemental video.

## 6 Conclusion

We present Atlas3D, a physically constrained SDS-based framework that generates self-supporting 3D models from text prompts. Our framework can learn standability through a differentiable physics-based simulator and other physics-inspired loss functions. The generated 3D models can be directly imported into a physics simulator and are ready to be manufactured and deployed in the real world. Our method has wide potential for generation tasks, as it can be easily integrated into many existing pipelines and improve the physical plausibility of their generated results.

Limitations and Future WorkOur physical adjustments are optimized over all mesh vertices, resulting in a large degree of freedom in optimization. This may lead to undesired distorted meshes . Future works may consider adding a latent embedding or skeleton rigging to limit the variety of mesh deformation. Our framework focuses on SDS-based methods as a backbone. It would be interesting to further generalize our physical constraints to other non-SDS or non-diffusion based methods [22; 49; 28]. Finally, we only consider text-to-3D tasks in this work. An exciting extension is to generalize our work to image-to-3D tasks [60; 39].