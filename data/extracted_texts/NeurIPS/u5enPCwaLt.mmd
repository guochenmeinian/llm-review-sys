# Towards Estimating Bounds on the Effect of Policies under Unobserved Confounding

Alexis Bellot*  Silvia Chiappa

Google DeepMind

London, UK

Correspondence to Alexis Bellot: abellot@google.com

###### Abstract

As many practical fields transition to provide personalized decisions, data is increasingly relevant to support the evaluation of candidate plans and policies (_e.g._, guidelines for the treatment of disease, government directives, etc.). In the machine learning literature, significant efforts have been put into developing machinery to predict the effectiveness of policies efficiently. The challenge is that, in practice, the effectiveness of a candidate policy is not always identifiable, _i.e._, not uniquely estimable from the combination of the available data and assumptions about the domain at hand (_e.g._, encoded in a causal graph). In this paper, we develop graphical characterizations and estimation tools to bound the effect of policies given a causal graph and observational data collected in non-identifiable settings. Specifically, our contributions are two-fold: (1) we derive analytical bounds for general probabilistic and conditional policies that are tighter than existing results, (2) we develop an estimation framework to estimate bounds from finite samples, applicable in higher-dimensional spaces and continuously-valued data. We further show that the resulting estimators have favourable statistical properties such as fast convergence and robustness to model misspecification.

## 1 Introduction

Understanding how to act upon the world around us requires humans and artificial systems to thoughtfully evaluate the effect of different plans, policies, and interventions one might consider. Data and methods that facilitate this process are increasingly relevant for high-stakes decision-making, notably in medical care with the rise of precision medicine , but also in education , law enforcement , public policy , and economics . The interventions that a practitioner might consider, could consist of complex policies where a variable is set to follow a conditional or stochastic relationship depending on other variables in the system. For example, policy-makers might contemplate higher taxes on processed foods and stronger campaigns on its health risks targeted to overweight individuals. A sensible question in this context could be "what is the effect of a policy that reduces the consumption of processed foods by \(50\%\) in people with a body mass index above 30?". Contrary to atomic (also called hard) interventions that force a particular value, this policy suggests a _softer_ intervention.

The identifiability and estimation of policies from data is a widely studied problem in the reinforcement learning [37; 39] and causal inference [2; 12; 15; 31; 32; 40] literatures. Despite the generality entailed by many common approaches in these fields, they often rely on an impractical condition: the assumption that the effectiveness of the policy is uniquely computable from the observed data and

[MISSING_PAGE_FAIL:2]

For a sample set \(:=\{^{(i)}\}_{i=1,,n} P\), we use \(_{}[f()]:=(1/n)_{i=1}^{n}f(^{(i)})\). We use \(\|f\|_{P}:=_{P}[\{f()\}^{2}]}\). \(-f=o_{P}(r_{n})\) denotes that a function \(\) is a consistent estimator of \(f\) at a rate \(r_{n}\), \(-f=O_{P}(r_{n})\) denotes that it is bounded in probability at rate \(r_{n}\).

## 2 Partial Identification of the Effect of Policies

A policy \(\) over a subset \(\) is a sequence of decision rules or plans \(:=\{_{X}\}_{X}\) for determining the assignment of variables \(\). In its most general form, every \(_{X}:_{X}_{_{X}}\) is a probability mapping from domain of \(_{X}\) to the domain of \(X\).

Qualitatively different types of interventions may be modelled with \(_{X}\). Specifically, a deterministic intervention setting \(X:=g(_{X})\) based on the values of \(_{X}\) can be encoded as \(_{X}(x_{X}):=_{g(_{X})}(x)\) while a probabilistic intervention may be written \(_{X}(x_{X}):=P_{_{X}}(X=x_{x})\). The intervened model \(_{}\) represents a different regime in which the assignment \(\{f_{X}\}_{X}\) is replaced with the assignment induced by \(\). For an outcome \(Y\), the interventional distribution \(P_{_{}}(Y)\), equivalently \(P_{}(Y)\), is defined as the distribution over \(Y\) in \(_{}\). It will be useful to adopt the notation \(}:=_{X}_{X}(x_{X})\) to denote the product of policy assignments on individual variables subject to intervention in \(\).

**Example 1** (Illustration of policies).: In the context of a public health program, let \(X\) be a measure of an individual's weekly physical exercise routine, \(C\) an individual's family history of metabolic diseases, and \(Y\) hospital admissions related to heart disease. Consider the causal diagram Fig. 0(a); currently, an individuals exercise voluntarily, which depends on unobserved factors that could be associated with risk of heart disease. The government is considering an incentive plan aimed at increasing the frequency of exercise depending individual's family history of metabolic diseases (with some probability). The proposed intervention can be encoded as \(=\{_{X}\}\) and sets the new assignment \(_{X}\) such that the variable \(X\) follows the pre-specified distribution. Graphically, this policy is represented by Fig. 0(b) (with the new edge corresponding to the implementation of the policy highlighted in blue) and may be evaluated with the following quantity,

\[_{P_{}}[Y]=_{x,c}_{P_{}}[Y x,c] _{X}(x c)P_{}(c).\] (1)

The inferential challenge is that this quantity is not uniquely computable from \(P(x,y,c)\) and \(\), requiring more complex and nuanced notions of policy evaluation.

Formally, we are interested in the evaluation of the effectiveness of a plan or policy \(\), acting on a (potentially multivariate) discrete action \(\) based on values of observed covariates \(^{d}\), on an outcome of interest \(Y\)2.

**Definition 1** (Average treatment effect).: _The effectiveness of a policy \(\) on \(Y\) is \(_{P_{}}[Y]\)._

From the investigator's perspective, only the causal diagram \(\) of the environment \(\) is available. No assumptions about the form or shape of \(P()\) and \(\) are made, but for the structural knowledge encoded in \(\). In general, there might exist multiple SCMs \(\) that induce the same causal diagram \(\) and entail \(P()\) but result in different values of \(_{P_{}}[Y]\). The identification of a _set_ of possible solutions that contain the true value of \(_{P_{}}[Y]\) leads to the notion of _partial identification_.

**Definition 2** (Partial Identification).: _The effectiveness of a policy \(\) is said to be partially identifiable from \(\) and \(P()\) if_

\[^{}(P)_{P_{_{}}}[Y]^{u}(P), $ such that }_{}=,P_{}()=P(),\] (2)

_where \((^{},^{u})\) are functionals of \(P\) that are bounded away from \(0\) and \(1\), respectively._

The earliest bound on the effect of policies, the so-called _natural bounds_, were developed considering discrete atomic interventions, i.e. of the form \(_{X}=_{x}(X),X\{1,,d_{X}\}\).

Figure 1: Graphs for Example 1.

**Proposition 1** (Natural Bounds).: _For any \(\), \(_{P}[Y_{}()]_{P_{}}[Y] _{P}[(Y-1)_{}()]+1.\)_

Remarkably, these inequalities hold irrespective of the causal graph of the system \(\); a result that dates back to [27; 33]. Similarly, we could adapt the underlying proof strategy to derive functionals of \(P\) that bound the effect of more general probabilistic or conditional policies \(\), given as follows.

**Proposition 2** (Natural Policy Bounds (NPB)).: _For any \(\), \(_{P}[Y}]_{P_{}}[Y] _{P}[(Y-1)}]+1.\)_

These inequalities also hold irrespective of the causal graph of the system. The natural bounds from [27; 33] are a special case of the natural policy bounds (NPBs) by setting \(:=\{_{X}\}_{X}\) where \(_{X}:=_{x}(X)\), and therefore \(}=_{}()\). We could show that the NPBs are tight in some cases. For example, in Example 1, provably, no better bounds for \(_{P_{}}[Y]\) than those defined by Prop. 2 could be derived (a result given in Prop. 10 in Appendix B). For other systems that involve variables that are "separated" in \(\), however, better bounds may be derived by exploiting the implications of the causal graph and definition of the policy on the induced observational and interventional distributions. Consider the following example as a first illustration of this idea.

**Example 2** (Tighter bounds with causal diagram).: We are interested in evaluating the effect of a policy \(:=\{_{X_{1}}(x_{1} c),_{x_{2}}(X_{2})\}\) from \(P(x_{1},c,x_{2},y)\) and \(\) in Fig. 1(a). In particular, this problem involves a stochastic conditional intervention on \(X_{1}\) given \(C\) and a deterministic intervention on \(X_{2}\); both variables having differing dependencies onto the rest of the system. We could show that,

\[_{P_{}}[Y]=_{P_{_{X_{1}}}}[Y] _{P}[Y_{X_{1}}]=^{}(P).\] (3)

The inequality gives an expression for the bound in terms of \(P\) that exploits the fact that intervening on \(X_{2}\) does not influence \(Y\), and is tighter that the natural policy lower bound as \(^{}(P)_{P}[Y_{X_{1}}]P(X_{2}=x_{2})=_{ P}[Y_{X_{1}}_{x_{2}}(X_{2})]\)\((=)\). For the upper bound we could similarly establish that,

\[_{P_{}}[Y]_{P}[(Y-1)_{X_{1}} ]+1=^{u}(P).\] (4)

which is smaller than the natural policy bound as \(^{u}(P)_{P}[(Y-1)_{X_{1}}_{x_{2}}(X_{2}) ]+1\)\((=)\).

This example, although relatively straightforward, serves to illustrate the potential of causal diagrams (and the constraints they imply on the effect of policies) for defining tighter bounds.

## 3 Graphical Criteria for Partial Identification

This section aims to consider more general separation statements between variables encoded in a causal diagram and the decomposition they imply to provide a systematic algorithm to bound the effectiveness of policies. We start by introducing the notion of _partial adjustment sets_ (Def. 3) that is applicable with multiple intervention variables.

**Definition 3** (Partial adjustment set).: _Let \(:=\{_{_{1}},_{_{2}}\}\) be a policy on \(\{_{1},_{2}\}\) with a conditioning set \(\). A set \((_{1}_{2})\) is said to be a partial adjustment set for \(_{_{2}}\) in \(\) if \((Y_{d}_{2},,_{1})_{_{_{_{1}}}_{2}}\)._

**Proposition 3**.: _Let \(:=\{_{_{1}},_{_{2}}\}\) be a policy mapping a set of covariates \(\) to a set of treatment variables \(\{_{1},_{2}\}\). Let \(\) be a partial adjustment set for \(_{_{2}}\) in \(\). Then,_

\[_{P}[Y}]_{P_{}}[Y] _{P}[(Y-1)}]+1,\] (5)

_where \(:=(,,)=1/P(_{2},)\)._

In words, partial adjustment sets are designed to exploit the unconfounded status of some intervention variables with respect to the outcome, and could be leveraged to derive tighter bounds when available.

Figure 2: Graphs used in Sec. 2 and 3.

**Example 3** (Tighter bounds with partial adjustment sets).: Consider the problem of evaluating the effect of a policy \(:=\{_{X_{1}}(x_{1} c),_{X_{2}}(x_{2} c)\}\) from \(P(x_{1},c,x_{2},w,y)\) and \(\) in Fig. 1(b). Following Def. 3, we could establish that \(=\) is a valid partial adjustment set for \(_{X_{2}}\) since we can verify that \((Y}_{d}X_{2} C,X_{2}) _{_{_{X_{1}}}X_{2}}\). Prop. 3 then gives us a valid expression for bounding the effect of the policy,

\[_{P_{}}[Y]_{P}[Y}/P(X_{2}  C)] (_{P}[Y}],).\] (6)

For the upper bound we similarly find that,

\[_{P_{}}[Y]_{P}[(Y-1)}/P(X_{2}  C)]+1 (_{P}[(Y-1)}]+1,).\] (7)

Next, we define a second useful notion, so-called _partial conditional instrumental variables sets_, that can be exploited to evaluate bounds in \(\)-specific distributions \(P(_{}()/P())\) instead of in \(P\) as described in Prop. 4.

**Definition 4** (Partial conditional instrumental set).: _A set \(\) is said to be a partial instrumental set conditional on \(\) for a policy \(\) in \(\) if \((Y}_{d})_{_{}}\)._

For illustration, we give a simple criterion below to show how this subgroup structure could be exploited to derive tighter bounds.

**Proposition 4**.: _Let \(\) be an unconditional partial instrumental set with respect to a policy \(\), i.e. \((Y}_{d})_{_{}}\). Then,_

\[_{}_{P}[Y}_{}()/P( {Z})]_{P_{}}[Y]_{}_{P}[(Y-1) }_{}()/P()]+1.\] (8)

The following example shows that partial adjustment sets and partial conditional instrumental sets may be usefully combined to derive tighter bounds than would be available had each proposition (Props. 3 and 4) been applied in isolation.

**Example 4** (Tighter bounds with partial adjustment and instrumental sets).: For this example, consider the evaluation of an atomic intervention \(:=\{_{x_{1}}(X_{1}),_{x_{2}}(X_{2})\}\) in the causal diagram \(\) given in Fig. 1(c). Note that \(}=_{}()\). Following Def. 3, \(\{\}\) is a valid partial adjustment set for \(_{X_{1}}\) since we can verify that \((Y}_{d}X_{2} X_{1})_{ _{_{X_{1}}}X_{2}}\). Further, we could verify that \(\{Z\}\) is a partial instrumental set conditional on \(\{X_{2}\}\) with respect to \(_{X_{1}}\) since \((Y}_{d}Z X_{2})_{ _{_{X_{1}}}}\). These two separation statements in (manipulated versions of) \(\) could be leveraged to derive a tighter bound than previously considered:

\[_{z}_{P}[Y}_{z}(Z)/P(X_{2},Z)]_{P_{}}[Y]\] \[_{z}_{P}[(Y-1)}_{z}(Z) /P(X_{2},Z)]+1.\]

To derive bounds in a more systematic fashion, combining the notions developed so far, we present Alg. 1 that recursively seeks to find partial adjustment and partial instrumental sets in an efficient and automatic manner.

Intuitively, Alg. 1 seeks to recursively simplify the query. First by omitting the intervened variables that have no effect on the outcome; second by finding the set of intervened variables for which a partial adjustment set could be used to tighten the bound, and third by finding the set of variables that act as valid partial instrumental sets to evaluate bounds on the most favorable conditional distributions rather than on the joint distribution.

[MISSING_PAGE_FAIL:6]

Estimation of the Effect of Policies

This section aims to develop an estimation framework for the effect of a policy \(_{P_{}}[Y]\) given finite samples from \(P\) that partially identifies its value. The key observation of this section is that multiple characterizations for estimation could be derived for a given bound returned by lines 20-21 in Alg. 1.

In a first instance, parameterized by the probability ratio given in Alg. 1 defined by \(=(_{1},_{2})\),

\[T^{,}:=_{P}[_{2}Y]\ \ \ (=_{}^{}), _{2}:=_{}_{1},_{1}:=_{} _{}()/P(,,).\] (10)

In a second instance, parameterized by a collection of regression parameters \(=(_{0},_{1},_{1},_{2})\) where

\[_{2} :=_{2}(,,,)=_{P}[Y,,,],\] (11) \[_{1} :=_{1}(,,,)=_{} ()_{2}(,,,),\] (12) \[_{1} :=_{1}(,,,)=_{P}[_{1}(,,,),,,],\] (13) \[_{0} :=_{0}(,,)=_{}_{1}(,,,)_{}().\] (14)

\(T^{,}:=_{P}[_{0}(,,)]\) could be shown to equal \(_{}^{}\).

Both formulations define equivalent but different estimation targets for the lower bound3 and may be combined leveraging the double machine learning (DML) toolkit for more efficient and robust inferences .

The following procedure is the main contribution of this section. It defines a DML estimator for bounding the effectiveness \(_{P_{}}[Y]\) of a policy \(\).

**Definition 5** (DML Estimator).: _Given \(\) and \(\), let \(\{,,,,,Y\}\) be defined as in Alg. 1. Consider a finite sample of data \( P\), randomly split into \(K\) folds. The \(k\)'th partition of the sample is denoted \(^{(k)}\) and \(^{(-k)}:=^{(k)}\). For each \(k\), learn approximate nuisances \((}_{k},}_{k})\) with \(D^{(-k)}\). Then, define_

\[_{}\ ^{,}\,\ _{}\ ^{,u}\ \] (15)

_to be an estimate for the bounds on \(_{P_{}}[Y]\) where,_

\[^{,} :=_{k=1}^{K}_{^{(k)}}[_{2,k}\{Y-_{2,k}\}]+_{^{(k)}}[_{1,k}\{}_{1,k}-_{1,k}\}]+_{^{(k )}}[_{0,k}]\] \[^{,u} :=1+_{k=1}^{K}_{^{(k)}}[_{2,k}\{(Y-1)-_{2,k}\}]+_{^{(k)}}[_{1,k}\{}_{1,k}-_{1,k}\}]+_{^{(k)}}[_{0,k}].\]

To analyse the error of the DML estimator, we consider the case that nuisances can be estimated consistently. Thus requirement is relatively mild in practice as accurate probability estimation employing off-the-shelf classification and regression methods is feasible in general. Its error with respect to the true bounds is given by the following proposition.

**Proposition 8** (Error rates).: _Suppose the nuisance estimates \((},})\) are \(L_{2}\)-consistent and bounded. Then, the error of the DML estimator \(^{}\{^{,},^{,u}\}\) in Def. 5 is given as follows_

\[^{}-T^{}=_{k=1}^{K}R_{k}+O_{P} \|_{2,k}-_{2}\|_{2,k}-_{2}\|+O_{P} \|_{1,k}-_{1}\|_{1,k}-}}_{1,k} \|\]

_where \(R_{k}\) is a random variable that converges to zero at a rate \(_{P}(1/)\)._

In words, the DML estimator exhibits a robustness property since the error of \(^{}\) is bounded in probability at \(n^{-1/2}\) rate whenever the nuisances converge at a rate \(n^{-1/4}\). Note that the term \(\|}_{1,k}-_{1,k}\|\) quantifies the error in approximating the conditional expectation in Eq. (13) for a given \(_{1}\) estimated at that stage, and that the estimation error of \(_{2}\) and \(_{2}\) are equivalent since they are deterministic transformations of each other. The following proposition is a corollary that shows that the DML estimator is unbiased under misspecification.

**Proposition 9** (Bias under misspecification).: _Suppose either \(_{1}=_{1}\) or \(_{2}=_{2}\) and that either \(_{1}=_{1}\) or \(}}_{1}=_{1}\). Then, \(^{}\{^{,},^{,u}\}\) is an unbiased estimator of the corresponding bound defined in Alg. 1._

## 5 Experiments

This section evaluates the quality of policy effect estimation from finite samples. Our goal is to illustrate the computation of bounds and provide empirical evidence of the fast convergence and robustness to misspecification of estimators.

Finite sample bounds are estimated with gradient boosting classification and regression models (for conditional expectations) or by taking sample averages (for unconditional expectations). We truncated estimates of probability mass functions in the interval \([0.01,0.99]\) to ensure positivity. We assess the quality of an estimator \(\) by computing the absolute average error (AAE) with respect to (a proxy for) the true bounds (estimated in practice with larger sample sizes), _i.e._, AAE = \(|^{u}-_{z}_{}^{u}|+|^{}-_{} _{}^{}|\). Throughout, we report various statistics: 25th, 50th, 75th percentile, etc., across evaluation runs with ten different random seeds. Further details of the simulations are provided in Appendix C.

### Synthetic Simulations

The synthetic simulations consider 4 data generating mechanisms constructed according to the graphs in Fig. 4. They highlight the use of partial instrumental sets, partial adjustment sets, high-dimensional partial adjustment sets, and combinations of partial instrumental and adjustment sets of varying dimensionality. The task is to estimate bounds on the effectiveness of a policy \(:=\{_{X_{1}},_{X_{2}}\}\) defined as follows.

\[_{X_{1}}:=_{X_{1}}(X_{1}=1)=0.5,_{X_{2}}:=_{X_{2}}(X_{2}=1  c)=1/(1-\{-c\}).\] (16)

Figure 4: Experimental results on bounding the effectiveness of policies with the proposed estimators. Different rows highlight evaluations on different data generating mechanisms: the first row tests estimation with a partial instrumental set, the second row tests estimation with a partial adjustment set, the third row tests estimation with a high-dimensional partial adjustment set (\(^{100}\)), and the fourth row tests estimation with a combination of partial adjustment and instrumental sets.

That is the policy assigns \(X_{1}\{0,1\}\) randomly with probability \(0.5\), and assigns \(X_{2}\{0,1\}\) as a function of \(C\) with the probability of \(X_{2}=1\) increasing with the value of \(C\).

To estimate bounds on \(_{P_{}}[Y]\), we consider the proposed estimators, labelled: \(T^{}\), estimated with the nuisances in Eq. (10), \(T^{}\), estimated with the nuisances in Eq. (11), and \(T^{}\) estimated with the procedure in Def. 5. Our evaluations test performance across 4 different settings designed to highlight various properties.

* **Setting 1**: All nuisances estimated correctly. This setting aims to show that all estimators converge to the bound of interest.
* **Setting 2**: Nuisances \(}\) are sampled from a uniform distribution to induce misspecification in the estimation of \(\).
* **Setting 3**: Nuisances \(}\) are sampled from a uniform distribution to induce misspecification in the estimation of \(\). Settings 2 and 3 aim to demonstrate the doubly-robustness property of the DML estimator.
* **Setting 4**: Noise \(\) is introduced in the estimation of all nuisances \((,)\) to emphasize error due to finite sample variation. Specifically, noise \((n^{-},n^{-}),=1/4\), that induces a slower rate of convergence as a function of sample size, inspired by . This setting aims to show that the fast convergence behavior of the DML estimator compared to competing estimators.

The results are given in Fig. 44. We observe that across all data generating mechanisms, estimators improve with the size of the dataset and converge under no misspecification (Setting 1) to the underlying bounds. It is interesting to note also the differing accuracy of estimators in the small sample regime. \(T^{}\), based the estimation of a ratio of probabilities, can be unstable with low sample sizes if the ratio denominator is estimated to be close to zero while \(T^{}\), based on a sequence of regression tasks, tends to be better behaved. \(T^{}\) in contrast is constructed as a combination of elements of \(T^{}\) and \(T^{}\). In particular, note in Def. 5 the use of nuisances \(\) and \(\). As a result, \(T^{}\) has quite a different performance profile. Settings 2 and 3 in Fig. 4 show that the DML estimator \(T^{}\) is robust to misspecification in either the nuisances \(\) or \(\) that highlights the robustness property. Further, when decaying noise is introduced in the estimation of nuisances (Setting 4), the DML estimator outperforms in general with a faster convergence rate. We also observe that performance remains close to optimal with high-dimensional variables \(\), demonstrating that the DML estimator provides a practical toolkit for bounding in practice.

#### 5.1.1 Width of Bounds According to Different Graphical Criteria

This section evaluates the width of the bounds returned by exploiting the different graphical criteria provided in Sec. 3. The simulations are based on the data generating mechanism described by causal diagram illustrated in the fourth row of Fig. 4. We consider evaluating the policy in Eq. (16) and compute the bounds obtained by applying Prop. 2 (most conservative), Prop. 3 (using the partial adjustment set \(W\) only), Prop. 4 (using the partial instrumental set \(Z\) only), and finally Alg. 1 (that combines all propositions and is the proposed approach). Fig. 5 gives the results over 10 seeds of the data and across multiple data sizes, highlighting the gain achieved by exploiting the causal structure using the proposed approaches.

**Remark** (Actual width of bounds in practice). The majority of our empirical evaluations are spent on evaluating the accuracy of different methods at estimating bounds, without addressing whether the returned bounds are actually informative. In practice, the graph structure can play an important role in tightening bounds but the actual width of the bounds in a particular problem are primarily driven by the distribution of data. Here is an example to make this more concrete.

For a given policy \(\), Prop. 2 defines tight bounds (under some circumstances) on \(_{P_{}}[Y]\). The width of this bound is given by \(1-_{P}}\) that is ultimately driven by \(P(x)\). This term may therefore evaluate to anything between 0 and 1 depending on \(P(x)\) and \(\).

Figure 5: Width of bounds.

For more complex causal structures, the bounds proposed in Props. 3 and 4 (and Alg. 1) reduce the width of the interval above. Loosely written, from \(1-_{P}[}]\) to \(1-_{P}[}]\) for some \(\) that is a function of the joint distribution \(P\) and the structure of the graph. But again, the actual width of the interval is ultimately determined by the values of \(P\) and \(\) that may be large or small depending on the value probabilities involved.

### Evaluating Health Campaigns

This section illustrates the evaluation of lifestyle recommendations for the mitigation of obesity in individuals from Colombia, Peru and Mexico . The data was collected from anonymous users using a web platform, and includes reported obesity levels measured according to BMI \((Y)\), age \((A)\), smoking status \((S)\), frequency of consumption of high caloric food \((H)\), whether individuals monitored their calorie intake \((M)\), family history being overweight \((F)\), exercise frequency \((E)\), and time using technology devices \((T)\). Obesity is a multi-factored medical condition for which several causes have been acknowledged in the literature; causal diagrams relating the variables above have been curated in several related studies [1; 9]. We considered these findings to construct the causal diagram in Fig. 5(a) that we assumed for this example.

We aim to study the effect of a health campaign designed to lower the intake of high caloric food \((H)\) and increase the frequency of exercise \((E)\) on obesity levels \((Y)\). For instance, we could hypothesize that the campaign leads to an increase in the observed proportion of individuals rarely consuming of high caloric food (\(H\)) from \(0.12\) to \(0.5\) and that of individuals doing exercise (\(E\)) regularly from \(0.05\) to \(0.5\). These statements could be formulated as a stochastic policy \(^{}:=\{_{H}^{},_{E}^{}\}\) acting on \(H\) and \(E\), with new assignments,

\[_{H}^{}:=_{H}^{}(H=)=,_{E}^{ }:=_{E}^{}(E=)=.\] (17)

We consider the evaluation of expected BMI levels \(_{P_{^{}}}[Y]\) that range from \(12\) to \(50\) in the population, with a mean of \(29.3\). First note that this or other policies acting on \((H,E)\) are not identifiable due to the bi-directed edge \(\{HY\}\), but may nevertheless be bounded using Alg. 1. We find that

\[_{t}_{P}[Y]_{P_{^{}}}[Y ]_{t}_{P}[(Y-1)]+1,:=_{_ {}}_{t}(T)/P(E,T A,S,F).\] (18)

To illustrate the inference of. bounds with the DML estimator, we consider evaluating policies with \(=0.2,0.4,0.6,0.8\). Fig. 5(b) gives the results. The end-points of the intervals denote estimated lower and upper bounds. We see that policies that promote a healthier lifestyle (larger values of \(\)) are expected to reduce obesity levels on average but substantial uncertainty is still expected.

## 6 Conclusions

The evaluation of policies is arguably one of the critical ingredients enabling more personalized decision-making systems. When the effect of policies is not identifiable, bounds can provide an effective support for making informed decisions. In this paper we developed partial identification and estimation tools for bounding the effect of a (stochastic or conditional) policy given data and assumptions encoded in a causal graph. We introduced several graphical characterizations that induce tighter bounds, and developed an estimation framework that exhibit robustness to noise and fast convergence. The results of this paper were illustrated through synthetic simulations and a real-world health campaign example for the reduction of obesity levels.

Figure 6: Health campaign evaluations.