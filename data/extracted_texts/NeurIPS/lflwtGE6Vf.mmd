# (Fl)\({}^{2}\): Overcoming Few Labels in Federated Semi-Supervised Learning

Seungjoo Lee   Thanh-Long V. Le   Jaemin Shin   Sung-Ju Lee

KAIST

Republic of Korea

{seungjoo.lee,thanhlong0780,jaemin.shin,profsj}@kaist.ac.kr

###### Abstract

Federated Learning (FL) is a distributed machine learning framework that trains accurate global models while preserving clients' privacy-sensitive data. However, most FL approaches assume that clients possess labeled data, which is often not the case in practice. Federated Semi-Supervised Learning (FSSL) addresses this label deficiency problem, targeting situations where only the server has a small amount of labeled data while clients do not. However, a significant performance gap exists between Centralized Semi-Supervised Learning (SSL) and FSSL. This gap arises from confirmation bias, which is more pronounced in FSSL due to multiple local training epochs and the separation of labeled and unlabeled data. We propose _(FL)\({}^{2}\)_, a robust training method for unlabeled clients using _sharpness-aware consistency regularization_. We show that regularizing the original pseudo-labeling loss is suboptimal, and hence we carefully select unlabeled samples for regularization. We further introduce _client-specific adaptive thresholding_ and _learning status-aware aggregation_ to adjust the training process based on the learning progress of each client. Our experiments on three benchmark datasets demonstrate that our approach significantly improves performance and bridges the gap with SSL, particularly in scenarios with scarce labeled data. The source code is available at https://github.com/seungjoo-ai/FLFL-NeurIPS24

## 1 Introduction

Federated learning (FL)  is a distributed machine learning system that trains accurate global models while preserving clients' privacy-sensitive data. Each FL client trains its local model on their device using only their data, and the server aggregates these local models into a global model. As a result, clients' private data is protected as only the local models' weights are shared with the server.

Because of its privacy-preserving nature, FL has garnered recent attention, with efforts to make it reliable and efficient [2; 3; 4]. However, most previous FL studies assumed that clients have labeled data, which is unrealistic in practical settings for two reasons. First, clients are often reluctant or lack the motivation to label data. Second, certain data types require domain expertise during the labeling process [5; 6]. For example, labeling medical data demands specialized knowledge and expertise. Similarly, sensory data, which can have multiple dimensions, is difficult for most clients to interpret accurately. Therefore, we envision a _labels-at-server_ scenario as more realistic for FL, where a small amount of labeled data is available only at the server while the clients' data remains unlabeled.

Various Federated Semi-Supervised Learning (FSSL) approaches [8; 7; 9; 10; 11] have been developed for the _labels-at-server_ scenario. However, there is a substantial performance gap between FSSL and centralized Semi-Supervised Learning (SSL), particularly when labeled data is limited. Fig. 1 illustrates this issue across varying amounts of labeled data on the CIFAR10 dataset . When asufficient amount of labeled data is available, the performance difference between SSL and FSSL is minimal. However, this gap widens considerably as the quantity of labeled data decreases.

We point out _confirmation bias_ as the primary cause, where the model tends to overfit to easy-to-learn samples or incorrectly pseudo-labeled data . This issue is particularly pronounced in FSSL as the training process involves multiple local epochs on clients [8; 14; 15]. This extended training on localized data accelerates the overfitting process, making the model more susceptible to confirmation bias. Moreover, labeled and unlabeled data are kept separate in a _labels-at-server_ setting. Unlike in centralized SSL where labeled and unlabeled objectives could be jointly optimized, this separation in FSSL prevents effective co-optimization, further contributing to the performance gap.

We propose **F**ew-**L**abels **F**ederated semi-supervised **L**earning, abbreviated as _(FL)\({}^{2}\)_, to mitigate _confirmation bias_ in FSSL using (1) _client-specific adaptive thresholding_, (2) _sharpness-aware consistency regularization_, and (3) _learning status-aware aggregation_. Previous FSSL approaches [7; 8] use a fixed threshold to obtain high-confidence pseudo-labels but are prone to _confirmation bias_ as only a small portion of data is utilized in the early stages of training. Instead, we adaptively change the threshold according to the clients' learning status. In the early stages, we use a low threshold to include more data for training. As training progresses and the model becomes more confident, we increase the threshold to obtain more accurate pseudo-labels. We profile the learning status of each client and determine client-specific adaptive thresholds.

Recently, Sharpness-Aware Minimization (SAM) has demonstrated strong generalization capabilities across various tasks [16; 17; 18]. Inspired by this, we hypothesized that applying SAM could effectively mitigate _confirmation bias_ among clients. However, our findings revealed that naively applying SAM degrades performance. This issue occurs as SAM generalizes not only correctly pseudo-labeled samples, but also incorrectly pseudo-labeled ones. Generalization of incorrect data samples leads to the propagation of errors, thereby degrading the model's performance. Therefore, we apply consistency regularization to carefully selected data samples that are highly likely correct. We also uncover that the standard SAM objective (i.e., achieving flatter local minima) does not work well in FSSL. We thus propose a novel consistency regularization between the model outputs of adversarially perturbed and original weight parameters.

Finally, we propose a novel _learning status-aware aggregation_. In FSSL, the learning difficulty can vary across clients. Since the server can access only a small labeled dataset, clients whose data closely resembles the server's data will face lower learning difficulty. In comparison, those with more distinct data will encounter higher difficulty. Additionally, due to the non-iid data distribution of clients, the learning difficulty naturally differs among them. To account for different client learning difficulties, we assign higher aggregation weights to clients with higher learning difficulty, enabling the global model to learn more effectively from these clients. In contrast, previous FSSL approaches did not consider these variations in learning difficulty and relied on fixed aggregation weights.

Our main contributions are summarized as follows:

* We propose a _client-specific adaptive threshold_ that adjusts the pseudo-labeling threshold according to each client's learning status. By using a low threshold at the early stage of training, we effectively reduce confirmation bias by utilizing more data.

Figure 1: Comparison of SSL and FSSL algorithms on CIFAR-10 with varying numbers of labeled samples, where FreeMatch  represents SSL, and SemiFL , FedCon , and FedMatch  represent FSSL.

* We demonstrate that applying the SAM objective in FSSL is non-trivial and requires careful considerations. Minimizing the sharpness of incorrectly pseudo-labeled samples reduces the model performance. We also identify that the original SAM objective is ineffective in FSSL and propose a novel _sharpness-aware consistency regularization_ that regularizes consistency between original and perturbed model outputs.
* We propose _learning status-aware aggregation_ that adjusts the weight based on the client's learning status. Clients with lower learning status receive higher aggregation weights, ensuring their updates are well reflected in the global model.
* Our evaluation shows that our approach significantly outperforms existing methods across different settings, particularly when labeled data is scarce. _(FL)\({}^{2}\)_ improves the classification accuracy of up to 23.0% compared with existing FSSL methods.

## 2 Related work

Semi-supervised learning (SSL)Recent SSL methods primarily stem from two key ideas: pseudo-labeling  and consistency regularization . Pseudo-labeling artificially creates pseudo-labels and uses them as hard labels for supervised training. On the other hand, consistency regularization trains models by minimizing the variance between stochastic outputs, typically achieved through various weak or strong augmentations. FixMatch  generates high-quality pseudo labels via static probability thresholding and trains models to predict these labels from strongly augmented inputs. FlexMatch  enhances this approach by incorporating class-specific local thresholds alongside a fixed global threshold, adjusting based on the model's learning status. FreeMatch  dynamically adjusts the confidence threshold according to the model's learning status and introduces a self-adaptive class fairness regularization penalty to encourage diverse predictions during early training. FlatMatch  increases generalization by adopting sharpness-awareness minimization  into a cross-sharpness measure in SSL settings to ensure consistent learning performance between the labeled and unlabeled data.

Federated semi-supervised learning (FSSL)Federated Learning (FL) enables collaborative training of a global model while ensuring data remains on the client side, thereby preserving data privacy (further discussed in Appendix D). FSSL leverages FL in scenarios where labeled data is limited. FSSL research addresses two primary settings: _labels-at-clients_[26; 27; 7; 28; 29] and _labels-at-server_[9; 7; 8]. In the _labels-at-server_ scenario, FedMatch  encourages similar outputs from similar clients using inter-client consistency loss. It employs disjoint training between the server and clients to mitigate forgetting issues. FedCon  utilizes contrastive learning to assist clients' networks in learning embedding projections. SemiFL  achieves state-of-the-art results in the label-at-server setting by introducing _alternate training_, which finetunes the global model with labeled data after each communication round. It generates pseudo-labels with the global model at the start of every communication round, rather than the common per-batch generation.

Real-world _labels-at-server_ FL scenarios to have extremely limited labeled data as labeling data requires domain expertise and could be costly [5; 6]. However, existing FSSL approaches target scenarios with hundreds of labeled data points (> 250) on the server, and their accuracy significantly deteriorates when only tens of labeled data points are available (Section 5.2). In contrast, _(FL)\({}^{2}\)_ achieves high accuracy even in extremely label-scarce settings, such as when only 10 labeled data points are available on the server, demonstrating increased usability and practicality for real-world applications.

## 3 Preliminaries

### Federated learning

Federated Learning (FL) collaboratively trains a global model via coordinated communication with multiple clients. In communication round \(t\), the server selects \(K\) clients among available clients. The server transmits the current global model weights \(W_{g}^{t}\) to selected clients. The selected clients update the model weight \(W_{k}^{t}\) with the local dataset for \(E\) epochs, where \(k\) indicates the client index. Formally, \(W_{t}^{k}=W_{t}^{k}-_{W}_{}\), where \(_{}\) denotes the objective function of clients, e.g.,cross-entropy loss for the classification task. After local training, the server aggregates the trained model weights with \(^{k}\) as aggregation weight of each client, which is

\[W_{t+1}^{g}=_{k=1}^{K}^{k}W_{t}^{k}.\] (1)

### Federated semi-supervised learning

In Federated Semi-Supervised Learning (FSSL), especially in the _labels-at-server_ scenario, labeled dataset \(_{L}^{S}=\{(x_{b},y_{b}):b[N_{L}]\}\) is only available at the server, while clients have only unlabeled dataset \(_{U}^{k}=\{u_{b}:b[N_{U}^{k}]\}\), where \(N_{L}\) and \(N_{U}=_{k=1}^{K}N_{U}^{k}\) are the total number of labeled data and unlabeled data, respectively. In general, \(N_{L} N_{U}\). At each communication round \(t\), the server updates its model weight \(W_{t}^{S}\) with supervised loss \(_{}\) for \(E\) local epochs with

\[_{}=_{b=1}^{B}(y_{b},p_{W _{t}^{S}}(y|w(x_{b}))), W_{t}^{S}=W_{t}^{S}-_{W}_{ },\] (2)

where data batch \((x_{b},y_{b})\) is randomly drawn from \(_{L}^{S}\) with batch size \(B\). \((,)\) refers to the cross-entropy loss, \(()\) is the weak data augmentation (e.g., random horizontal flip and crop), and \(p_{W}()\) is the output probability from model \(W\). Clients update their model weight \(W_{t}^{k}\) using cross-entropy loss with pseudo-labeling, which can be expressed as

\[_{}=_{b=1}^{ B}( (q_{b})>)(_{b},Q_{b}), W_{t}^{k}=W_{t}^{k }-_{W}_{},\] (3)

where \(q_{b}\) and \(Q_{b}\) are the abbreviations of \(p_{W_{t}^{k}}(y|(u_{b}))\) and \(p_{W_{t}^{k}}(y|(u_{b}))\), respectively. Data batch \(u_{b}\) is randomly selected from \(_{U}^{k}\) with a batch size of \(B\). The one-hot label form of \(q_{b}\) is denoted as \(_{b}\), and the ratio of data with confidence above \(\) is represented by \(\). The indicator function \((>)\) is used for confidence-based thresholding. \(()\) represents strong augmentation (e.g., RandAugment ).

We adopt "fine-tune global model with labeled data" and "generate pseudo-labels with global model" strategies from SemiFL . In communication round \(t\), the server distributes the current global model \(W_{t}^{g}\) to \(K\) selected clients. Before training, clients generate pseudo-labels for a local dataset with a fixed global model \(W_{t}^{g}\). The changed local objective function is

\[_{}=_{b=1}^{ B}( (q_{b}^{g})>)(_{b}^{g},Q_{b}),\] (4)

where \(q_{b}^{g}\) stands for \(p_{W_{t}^{g}}(y|(u_{b}))\). Subsequently, the server aggregates trained local models with Eq 1. The server fine-tunes the aggregated model with \(_{}\), yielding a new global model \(W_{t+1}^{g}\).

### Sharpness-aware minimization

Sharpness-Aware Minimization (SAM) [25; 31] has been increasingly applied to various tasks [16; 17; 18] due to its ability to enhance generalization. SAM improves generalization by minimizing the sharpness of the loss landscape, which helps in finding flatter minima that generalize better across different tasks and datasets. Traditional optimization methods could lead to sharp minima, resulting in poor generalization to unseen data. SAM addresses this issue by incorporating weight perturbations into the optimization objective to find flatter minima. The core objective of SAM is defined as:

\[_{w}_{\|\|_{2}<}_{w+},\] (5)

where \(\) is a perturbation vector constrained within a \(\)-ball around the model weight \(w\). The inner maximization seeks to find the perturbation \(\) that maximizes the loss \(\) within the specified \(\)-ball.

To make this optimization feasible, SAM approximates the perturbation \(\) as:

\[^{*}=_{w}}{\|_{w}_{w}\| _{2}}.\] (6)This approximation simplifies the inner maximization by scaling the gradient direction to have a norm of \(\). The outer minimization updates the weights using the gradient evaluated at the perturbed weights \(w+^{*}\). Specifically, the gradient used for the weight update is \(_{w}_{w+^{*}}\).

## 4 Method

**F**ew-**L**abels **F**ederated semi-supervised **L**earning, abbreviated as _(FL)\({}^{2}\)_, has three key components: (1) _client-specific adaptive thresholding_, which leverages more unlabeled data by dynamically adjusting thresholds for pseudo-labeling, (2) _sharpness-aware consistency regularization_, which minimizes sharpness for carefully selected data to ensure better generalization, and (3) _learning status-aware aggregation_, which aggregates local models from clients while considering their learning progress. Fig. 2 overviews _(FL)\({}^{2}\)_ and Appendix A details the algorithm.

### Client-specific adaptive thresholding

We use an adaptive thresholding mechanism rather than a fixed threshold to incorporate more unlabeled data from the beginning of training. This approach is inspired by FreeMatch  that gradually increases the threshold according to the model learning status. At round \(t\), each client profiles its learning status during the pseudo-label generation stage using local unlabeled dataset \(_{U}^{k}\) with global model \(W_{}^{g}\). Adaptive threshold \(_{t}^{k}\) of client \(k\) at round \(t\) is

\[_{t}^{k}=_{U}^{k}|}_{b=1}^{|_{U}^{k}| }(q_{b}^{g}),\] (7)

Figure 2: Overview of _(FL)\({}^{2}\)_: (1) _client-specific adaptive thresholding_ adjusts the pseudo-labeling threshold according to each client’s learning status, (2) _sharpness-aware consistency regularization_ ensures consistency between the original model and the adversarially perturbed model with carefully selected high-confident pseudo labels, and (3) _learning status-aware aggregation_ aggregates client models considering each client’s learning progress.

where \(q_{b}^{g}\) is \(q_{b}\) calculated with global model \(W_{t}^{g}\). This approach sets a low initial threshold value, as the model exhibits lower confidence in the data at the beginning of training. The threshold gradually increases as training progresses, allowing the model to focus on high-confidence data. Additionally, we estimate the learning status specific to each class and apply different thresholds for each class. This is achieved by utilizing the output probabilities of the global model's predictions for each class, which can be expressed as

\[_{t}^{k}(c)=_{U}^{k}|}_{b=1}^{| _{U}^{k}|}q_{b}^{g}(c).\] (8)

We calculate client-specific adaptive thresholds for each class using \(_{t}^{k}\) and \(_{t}^{k}(c)\) as

\[_{t}^{k}(c)=(_{t}^{k}(c))_{ t}^{k}=_{t}^{k}(c)}{\{_{t}^{k}(c):c[C]\}} _{t}^{k}.\] (9)

The unsupervised training objective \(_{a}\) of client \(k\) with adaptive thresholding at each iteration is:

\[_{a}^{k}=_{b=1}^{ B}( (q_{b}^{g})>_{t}^{k}((q_{b}^{g}))( _{b}^{g},Q_{b}).\] (10)

### Sharpness-aware consistency regularization

While Sharpness-Aware Minimization (SAM) generalizes well in many tasks [16; 17; 18], it is not trivial to apply it to FSSL, as SAM generalizes not only correctly pseudo-labeled samples but also incorrect samples. This indiscriminate generalization results in the propagation of errors, thereby degrading the model's performance (Section 5.4). To tackle this issue, we apply consistency regularization to a carefully curated subset of data samples with a high confidence of correctness. While we use client-specific adaptive threshold (Section 4.1), we use a high fixed threshold to get high-confidence data samples. _(FL)\({}^{2}\)_ adversarially perturbs the weight parameters that maximize loss calculated with high-confidence data samples and regularizes consistency using the perturbed weight.

Adversarial weight perturbationWhen a client \(k\) trains its local model \(W^{k}\) with mini-batch, the model weight is perturbed with \(^{*}\) that increases \(_{p}^{k}\) the most, where \(^{*}\) and \(_{p}^{k}\) are defined as

\[_{p}^{k}=_{b=1}^{ B}( (q_{b}^{g})>_{f})(_{b}^{g},Q_{b}),\] (11)

\[_{p}^{*}=*{argmax}_{\|\|_{2}} _{p}^{k}}_{p}^{k}}{\| _{W^{k}}_{p}^{k}\|_{2}}, W^{k*}=W^{k}+_{p}^{*}.\] (12)

where \(\) stands for perturbation strength. We use a large fixed threshold \(_{f}\) to get a high-confidence pseudo-label.

Consistency regulationWith the perturbed weight \(W^{k*}\), we calculate \(Q_{b}^{*}\), which is the output probability of a strongly augmented sample for \(W^{k*}\). Unlike traditional SAM objective that takes \(_{W^{k*}}_{p}\), we measure the difference of model outputs between the original and the perturbed models (Section 5.5). Formally,

\[_{cs}^{k}=_{d}(Q_{b}^{*},Q_{b}),Q_{b}^{*}=p_{W^{k*}}(y| (u_{b})),\] (13)

in which \(_{d}(,)\) measures the distance (e.g., L2 distance or KL divergence). Finally, local training objective of client \(k\) with client-specific adaptive thresholding (Section 4.1) and sharpness-aware consistency regularization is

\[_{}^{k}=w_{a}_{a}^{k}+w_{cs} _{cs}^{k}\] (14)

with \(w_{a}\) and \(w_{cs}\) being the loss weights. _(FL)\({}^{2}\)_ effectively leverages both low-confidence data with _client-specific adaptive threshold_ and high-confidence data with _sharpness-aware consistency regularization_ to minimize the confirmation bias of clients.

### Learning status-aware aggregation

After the local training of the selected \(K\) clients, the server aggregates the trained local models using weights \(^{k}\), as shown in Eq. 1. While existing FSSL approaches use uniform weights (\(^{k}=1/K\)), we propose a _learning status-aware aggregation_ that adjusts the aggregation weight based on the client's learning status. For a client with a low learning status, indicated by a low adaptive threshold \(_{t}^{k}\), we increase the aggregation weight so that the local learning is better reflected in the global model. We calculate the aggregation weight as

\[_{t}^{k}=^{k}}{_{k=1}^{K}(1-_{t}^{k})}.\] (15)

Our aggregation method complements the client-specific adaptive thresholds (Section 4.1). In this scheme, we use lower thresholds for clients with a lower learning status to enable more extensive learning from their data. By extending this notion to the client level, clients with lower thresholds, which indicate more valuable learning updates, are given a greater influence on the global model. This ensures that the most informative updates are prioritized.

## 5 Experiments

### Setup

Data setupWe evaluate _(FL)\({}^{2}\)_ in three public datasets: CIFAR10, CIFAR100 , and SVHN . We test our method under balanced IID and unbalanced non-IID data distribution settings. Each client receives an equal amount of unlabeled data in the balanced IID setting. We sample data using a Dirichlet distribution \(()\) for the unbalanced non-IID setting. Each client receives a different number of data samples and samples per class. As \(\), the distribution approaches IID. We set \(=\{0.1,0.3\}\) in our experiments. The number of labeled data samples at the server (\(N_{L}\)) is set to \(\{10,40\}\) for CIFAR10, \(\{100,400\}\) for CIFAR100, and \(\{40,250\}\) for SVHN, following widely-used evaluation settings for SSL [19; 24].

Learning setupIn our experiments, we use 100 clients, with a participation ratio of 0.1 per communication round (\(K=10\)). We adopt the WideResNet  as our backbone, employing WideResNet28x2 for the CIFAR10 and SVHN datasets, and WideResNet28x8 for the CIFAR100 dataset. Both the server and clients optimize their local datasets for five local epochs, with 800 communication rounds. We employ the momentum SGD optimizer with a learning rate of 0.03, momentum of 0.9, and weight decay of 5e-4, following previous work . For sharpness-aware consistency regularization (Section 4.2), we use the KL-divergence loss function for \(_{d}(,)\). For adversarial weight perturbation (Eq. 12), we use ASAM , which implements scale invariance on standard SAM . Based on a grid search, the perturbation strength \(\) is set to 0.1 for the CIFAR10 and SVHN datasets and 1.0 for the CIFAR100 dataset. For strong data augmentation, we use RandAugment . We also adopt the static Batch Normalization (sBN)  strategy, as utilized in SemiFL. Further details on sBN are in Appendix E. We used RTX3090 GPUs throughout the experiment. Additional details are in Appendix C.

### Performance comparison with FSSL algorithms

We evaluate _(FL)\({}^{2}\)_ against existing FSSL methods: FedMatch , FedCon , and SemiFL . Table 1 shows that _(FL)\({}^{2}\)_ consistently delivers the best or nearly the best performance across all settings. For instance, although SemiFL performs the best in the non-IID-0.3 setting of CIFAR100 with 100 labels, it struggles to generalize to other scenarios. SemiFL achieves only around 10% accuracy in CIFAR10 with 10 labels and about 43% accuracy in SVHN with 250 labels. In contrast, _(FL)\({}^{2}\)_ consistently maintains high accuracy across all tasks. The performance gap compared with the best-performing algorithm (SemiFL) in non-IID-0.3/CIFAR100/100-labels is only 0.3%. Except for that, _(FL)\({}^{2}\)_ consistently outperforms the baseline methods across all other settings. Additionally, _(FL)\({}^{2}\)_ demonstrates a substantial improvement over existing methods, achieving **20.3%** higher performance in non-IID-0.3/SVHN/250-labels and **23.0%** higher performance in IID/SVHN/250-labels. These findings indicate that _(FL)\({}^{2}\)_ effectively mitigates _confirmation bias_ among clients, leading to robust generalization even with limited data across different settings.

We emphasize that _(FL)\({}^{2}\)_ significantly outperforms other methods when labeled data is extremely limited: by **22.2%** on the IID setting of CIFAR10 with 10 labels and by **21.9%** on the IID setting of SVHN with 40 labels. This substantial margin highlights _(FL)\({}^{2}\)_'s exceptional ability to leverage scarce labeled data, making it practical for real-world federated learning applications. Additional experiments are provided in Appendix B.

Significance of each component of _(FL)\({}^{2}\)_We assess the contribution of each component of _(FL)\({}^{2}\)_: Client-specific Adaptive Thresholding (CAT), Sharpness-Aware Consistency Regularization (SACR), and Learning Status-Aware Aggregation (LSAA) in Table 2. The accuracy improvements provided by each component are evaluated using the SVHN dataset with 40 labeled data points and a balanced IID setting. We use FixMatch + FedAvg as the baseline, where FixMatch  employs a fixed threshold for pseudo-labeling. Our results indicate that both SACR and CAT significantly enhance the performance over the baseline. Combining SACR and CAT yields further accuracy improvements. Finally, integrating LSAA for model aggregation, equivalent to _(FL)\({}^{2}\)_, achieves the highest accuracy. These findings demonstrate that each component of _(FL)\({}^{2}\)_ contributes uniquely and complementarily to the overall performance.

### Effect of _(FL)\({}^{2}\)_ on confirmation bias

Since incorrect pseudo-labels usually lead to confirmation bias , we evaluated pseudo-label accuracy, label ratio, correct label ratio, wrong label ratio, and C/W ratio in addition to test accuracy. We compared _(FL)\({}^{2}\)_ against baseline methods using the SVHN dataset with 40 labels in a balanced

    &  &  &  \\  \# of labeled data samples (\(N_{L}\)) & 10 & 40 & 40 & 250 & 100 & 400 \\   & FedCon & 16.0(2.3) & 25.6(2.2) & 20.7(2.7) & 70.1(2.2) & 6.3(0.3) & 10.0(1.8) \\  & FedCon & 16.6(2.1) & 25.4(2.3) & 20.5(1.4) & 73.1(2.0) & 4.0(0.4) & 8.2(0.6) \\  & SemiFL & 10.0(0.0) & 19.9(7.5) & 18.0(2.6) & 82.3(1.8) & 9.8(2.4) & 13.5(5.0) \\  & _(FL)\({}^{2}\)_ & **19.2(5.7)** & **36.4(1.4)** & **21.5(3.3)** & **88.0(1.0)** & **10.4(1.3)** & **23.5(1.2)** \\   & FedMatch & 15.3(1.3) & 25.2(3.5) & 22.3(0.7) & 72.3(3.0) & 5.5(1.5) & 9.8(1.1) \\  & FedCon & 16.9(2.4) & 26.5(2.1) & 21.6(1.7) & 68.7(2.7) & 5.8(0.6) & 13.3(0.9) \\   & SemiFL & 10.0(0.0) & 38.0(2.7) & 26.3(2.5) & 42.7(40.1) & **12.4(1.2)** & 18.9(9.7) \\   & _(FL)\({}^{2}\)_ & **24.3(4.5)** & **43.5(7.5)** & **31.0(4.2)** & **92.6(0.5)** & 12.1(1.1) & **25.4(1.0)** \\   & FedMatch & 16.2(1.9) & 25.4(2.8) & 18.4(4.7) & 66.2(0.8) & 6.4(0.6) & 10.0(1.7) \\  & FedCon & 16.7(2.0) & 23.3(6.2) & 20.3(1.0) & 71.6(1.5) & 5.7(0.6) & 12.4(1.6) \\   & SemiFL & 10.0(0.0) & 75.3(2.8) & 53.4(13.3) & 43.3(41.0) & 13.9(3.3) & 27.9(6.1) \\   & _(FL)\({}^{2}\)_ & **38.9(11.1)** & **81.5(7.4)** & **75.3(2.4)** & **94.6(1.1)** & **14.4(2.3)** & **28.1(2.2)** \\   

Table 1: Evaluation of _(FL)\({}^{2}\)_ compared with existing FSSL methods. We report the average accuracy(%) and standard deviation across three runs with different random seeds. _(FL)\({}^{2}\)_ shows significant performance improvements over existing methods across different settings. **Bold** indicates the best result and underline indicates the second-best result.

   Algorithm & Accuracy \\  FixMatch + FedAvg & 50.2 \\ 
**SACR** + FixMatch + FedAvg & 60.9 \\
**CAT** + FedAvg & 68.2 \\
**CAT** + **SACR** + FedAvg & 71.7 \\  _(FL)\({}^{2}\)_: **CAT** + **SACR** + **LSAA** & **73.2** \\   

Table 2: Contribution of each component of _(FL)\({}^{2}\)_ on the SVHN dataset (\(N_{L}=40\), balanced IID). By applying Client-specific Adaptive Thresholding (CAT) and Sharpness-Aware Consistency Regularization (SACR) to the baseline (FixMatch + FedAvg), performance is boosted. The combination of CAT and SACR further improves the accuracy. Incorporating Learning Status-Aware Aggregation (LSAA) leads to the best performance, finally achieving _(FL)\({}^{2}\)_. The result demonstrates the importance of each component in _(FL)\({}^{2}\)_.

IID setting, as reported in Fig. 3. A high pseudo-label accuracy indicates that the method produces reliable pseudo-labels. A high correct label ratio suggests that the method supplies the model with more accurate labels. Conversely, a low wrong label ratio indicates that the model encounters fewer incorrect labels, which is crucial for minimizing confirmation bias . Lastly, a high C/W ratio signifies that the model is exposed to more correct labels than incorrect ones, further helping to reduce confirmation bias.

We observed that _(FL)\({}^{2}\)_ consistently outperforms SemiFL across all metrics. While SemiFL generates more incorrect labels (C/W ratio < 1), _(FL)\({}^{2}\)_ produces twice as many correct labels than incorrect ones (Fig. 3f). Additionally, the wrong label ratio for _(FL)\({}^{2}\)_ is approximately 30%, significantly lower than SemiFL's 45% (Fig. 3e). These results suggest that _(FL)\({}^{2}\)_ effectively reduces incorrect pseudo-labels while increasing correct ones, thereby mitigating confirmation bias. Furthermore, we observe the effectiveness of each component of _(FL)\({}^{2}\)_, which are CAT, SACR, and LSAA. Using CAT and SACR alone delivers better performance than the baseline for all metrics. If we use CAT + SACR, pseudo label accuracy increases, correct label ratio increases, and wrong label ratio decreases, which means we reduce the confirmation bias. When LSAA is added, which is _(FL)\({}^{2}\)_, it achieves the best performance across all metrics. This suggests that the synergistic effect of CAT, SACR, and LSAA effectively reduces confirmation bias.

### Impact of incorrect pseudo-labels on sharpness-aware consistency regularization

We investigate the impact of incorrect pseudo-labeled data on Sharpness-Aware Consistency Regularization (SACR). We compare the performance of SACR in two scenarios: when applied only to correctly pseudo-labeled data assuming that we know the ground truth labels to assess the upper bound of SACR, and when applied to all pseudo-labeled data, including incorrectly pseudo-labeled samples. We examine when Client-specific Adaptive Thresholding (CAT) is used in both scenarios.

Fig. 4 reports the test accuracy and pseudo-label accuracy for the following cases: CAT alone, CAT+SACR (all data), and CAT+SACR (only correct pseudo-labels). CAT+SACR (only correct pseudo-labels) achieves high pseudo-label accuracy, indicating that SACR can effectively reduce

Figure 3: Comparison of SemiFL, _(FL)\({}^{2}\)_, and its variants on the SVHN dataset (\(N_{L}=40\), balanced IID). Pseudo-label accuracy measures the percentage of correct pseudo-labels. The label ratio is the proportion of pseudo-labeled samples among all unlabeled data. Correct and wrong label ratios indicate the percentages of correctly and incorrectly labeled samples, respectively. The C/W ratio shows the number of correct labels relative to wrong labels. All subgraphs share the legend of Fig. 3a.

confirmation bias_ when applied to correctly pseudo-labeled data. Conversely, when SACR is applied to all data, including wrongly pseudo-labeled samples, the performance significantly decreases and shows worse performance than using only CAT. This emphasizes the importance of applying SACR exclusively to carefully selected data samples that are highly likely to be correct.

### Comparison with the standard SAM objective

We compare the proposed Sharpness-aware Consistency Regularization (SACR) to the standard Sharpness-Aware Minimization (SAM) objective. Both SAM and SACR perturb the model to maximize the given loss function. However, in SACR, the distance between the model outputs of perturbed and original model weights is minimized, while SAM takes the gradient of the given loss function at the perturbed weights.

Fig. 4 shows the test and pseudo-label accuracy using the standard SAM objective versus SACR. We examine the effects of SAM and SACR when applied only to correctly labeled samples in conjunction with Client-specific Adaptive Thresholding (CAT). Although SAM improves the performance over standalone CAT, SACR outperforms the standard SAM in convergence speed and final accuracy. The effectiveness of SACR can be attributed to the fundamental differences between SAM and SACR. SAM _explores_ the given loss landscape in search of a flat local minima. In contrast, SACR _changes_ the loss landscape by explicitly incorporating an additional consistency regularization term.

## 6 Discussion and conclusion

We introduced a novel federated learning algorithm, **F**ew-**L**abels **F**ederated semi-supervised **L**earning, _(FL)\({}^{2}\)_, that addresses the challenge of few-labels settings in Federated Semi-Supervised Learning (FSSL) for unlabeled clients. _(FL)\({}^{2}\)_ effectively reduces the _confirmation bias_ through three key strategies: (1) _client-specific adaptive thresholding_, which adjusts the pseudo-labeling threshold based on each client's learning status; (2) _sharpness-aware consistency regularization_, which ensures consistency between the original and the adversarially perturbed models with carefully selected high-confidence pseudo labels; and (3) _learning status-aware aggregation_, which incorporates each client's learning progress into the aggregation of client models. _(FL)\({}^{2}\)_ closes the performance gap between SSL and FSSL, making FSSL an effective solution for practical scenarios.

Limitations and future workOur approach introduces additional computational demands on clients, as _client-specific adaptive thresholding_ generates more pseudo-labels than traditional fixed threshold methods. Furthermore, _sharpness-aware consistency regularization_ adds an extra inference step with a perturbed model, increasing the computational burden. While our study is grounded in empirical findings, a promising future direction is to theoretically analyze the impact of the proposed methods, particularly in understanding how the generalization of incorrectly pseudo-labeled data affects overall performance.

Figure 4: Test accuracy and pseudo-label accuracy on the CIFAR10 dataset with 40 labels, balanced IID setting. Client-specific Adaptive Thresholding (CAT) is used as the baseline. Applying Sharpness-aware Consistency Regularization (SACR) to all data, including wrongly pseudo-labeled data, degrades performance than using only CAT, while applying SACR to correctly labeled data improves performance. SACR also outperforms the standard SAM objective (CAT+SAM).