# CE-NAS: An End-to-End Carbon-Efficient Neural Architecture Search Framework

Yiyang Zhao

Worcester Polytechnic Institute

&Yunzhuo Liu

Shanghai Jiao Tong University

Bo Jiang

Shanghai Jiao Tong University

&Tian Guo

Worcester Polytechnic Institute

###### Abstract

This work presents a novel approach to neural architecture search (NAS) that aims to increase carbon efficiency for the model design process. The proposed framework CE-NAS addresses the key challenge of high carbon cost associated with NAS by exploring the carbon emission variations of energy and energy differences of different NAS algorithms. At the high level, CE-NAS leverages a reinforcement-learning agent to dynamically adjust GPU resources based on carbon intensity, predicted by a time-series transformer, to balance energy-efficient sampling and energy-intensive evaluation tasks. Furthermore, CE-NAS leverages a recently proposed multi-objective optimizer to effectively reduce the NAS search space. We demonstrate the efficacy of CE-NAS in lowering carbon emissions while achieving SOTA results for both NAS benchmarks and open-domain NAS tasks. For example, on the HW-NasBench, CE-NAS reduces carbon emissions by up to 7.22X while maintaining a search efficiency comparable to vanilla NAS. For open-domain NAS tasks, CE-NAS achieves SOTA results with 97.35% top-1 accuracy on CIFAR-10 with only 1.68M parameters and a carbon consumption of 38.53 lbs of \(CO_{2}\). On ImageNet, our searched model achieves 80.6% top-1 accuracy with a 0.78 ms TensorRT latency using FP16 on NVIDIA V100, consuming only 909.86 lbs of \(CO_{2}\), making it comparable to other one-shot-based NAS baselines. Our code is available at https://github.com/cake-lab/CE-NAS.

## 1 Introduction

Deep Learning (DL) has become an increasingly important field in computer science, with wide applications such as healthcare and finance . Neural architecture search (NAS) has emerged as a means to automate the design of DL models, which involves training _many DL models_ from a massive architecture design space with hundreds of millions to trillions of candidates . Consequently, NAS can be energy-intensive and significantly contributes to today's carbon emissions . Many NAS works have reported using thousands of GPU-hours . For example, Zoph et al.  used 800 GPUs for 28 days, resulting in 22,400 GPU-hours, to obtain the final architectures. Strubell et al.  found that a single NAS solution can emit as much carbon as five cars during its lifetime.

The environmental impact of NAS, if left untamed, can be substantial. While recent works have significantly improved the search efficiency of NAS , e.g., reducing the GPU-hours to tens of hours without sacrificing the architecture quality, there still lacks _conscious efforts in reducing carbon emissions_. As noted in a recent vision paper by Bashir et al. , energy efficiency can help reduce carbon emissions but is not equivalent to carbon efficiency. This paper aims tobridge the gap between carbon and energy efficiency with a new NAS framework designed to be carbon-aware from the outset.

The proposed framework, termed CE-NAS, tackles the high carbon emission problem from two main aspects. First, CE-NAS regulates the model design process by _deciding when to use different NAS evaluation strategies based on the carbon intensity_, which varies geographically and temporally with the mix of active generators as observed in . To elaborate, given a fixed amount of GPU resources, CE-NAS will allocate more resources to energy-efficient NAS evaluation strategies, e.g., one-shot NAS , during periods of high carbon intensity. Conversely, during periods of low carbon intensity, CE-NAS will shift the focus to running energy-intensive but more effective NAS evaluation strategies, e.g., vanilla NAS . We design and train a reinforcement learning (RL) agent (SS3.5) based on historical and predicted carbon emissions (SS3.5.2) and observed search results to make such allocation decisions. Second, the CE-NAS framework will support searching for DL models satisfying multiple metrics beyond the commonly used metric of inference accuracy. CE-NAS can consider more metrics such as inference latency, #PARAMs, #FLOPs, etc. For example, CE-NAS can search for models with high accuracy and low inference latency. Specifically, both the search and deployment efficiency are achieved by integrating a recent learning-based multi-objective optimizer LaMOO  to CE-NAS. Figure 1 depicts the overall workflow of CE-NAS.

To demonstrate CE-NAS's efficacy in addressing the energy and carbon issues, we conduct a comprehensive evaluation using both commonly used NAS benchmarks and real-world NAS tasks. For example, utilizing carbon emission data from ElectricityMap , CE-NAS achieves better performance with reduced carbon costs compared to existing methods on various NAS benchmarks, including HW-NASBench  and NasBench301 . In open-domain tasks, CE-NAS achieves the state-of-the-art (SOTA) top-1 accuracy of 97.35% with only 1.68M parameters on the CIFAR-10

Figure 1: An overview of CE-NAS. The sampling and evaluation tasks will be allocated different GPU resources based on carbon emission intensity during the neural architecture search. Specifically, when the \(CO_{2}\) intensity is low, we allocate more resources to energy-intensive evaluation, which focuses on assessing the performance of sampled architectures generated through energy-efficient sampling. Conversely, when \(CO_{2}\) intensity is high, more GPUs are dedicated to energy-efficient sampling, which utilizes various NAS algorithms to sample new architectures from a search space partitioned based on previously evaluated architectures. The specific GPU allocation strategy is learned through a reinforcement learning agent, as detailed in the middle section of the figure.

image classification task, with \(CO_{2}\) costs similar to those of one-shot-based NAS algorithms. For the ImageNet dataset, CE-NAS achieves the SOTA top-1 accuracy of 80.6% under the same inference latency of 0.78 ms with TensorRT on NVIDIA V100, while maintaining a carbon cost comparable to SOTA NAS methods . We also evaluate our carbon forecasting model and show that it outperforms existing models [11; 56; 55], including the SOTA method .

In summary, we make the following key contributions.

* We introduce a carbon-efficient NAS framework named CE-NAS that can dynamically allocate GPU resources among different NAS evaluation methods--namely, vanilla NAS and one/few-shot NAS--based on carbon emissions data and current search results. CE-NAS is an end-to-end framework that synergistically integrates an RL-based agent for GPU resource allocation, a time-series transformer  for carbon intensity prediction, and a multi-objective optimizer  for reduced search space.
* We implement and evaluate CE-NAS on different NAS benchmarks, including HW-NasBench  and Nasbench301 . We show that CE-NAS can achieve the best search performance compared to only using vanilla NAS, one-shot NAS, and a recently proposed heuristic GPU allocation strategy  given the same carbon budget.
* CE-NAS delivers SOTA architectural performance in open-domain NAS tasks while maintaining carbon costs comparable to one-shot NAS methods. For example, on CIFAR-10, CE-NAS achieves a top-1 accuracy of 97.35% with only 1.68M parameters and a carbon cost of 38.53 lbs \(CO_{2}\). On ImageNet, CE-NAS reaches a top-1 accuracy of 80.6% with a 0.78 ms TensorRT latency using FP16 on NVIDIA V100.

## 2 Related Work

_Efficient neural architecture search (NAS)_ often focuses on improving the evaluation phase, e.g., via weight-sharing (one-shot) [65; 46; 88; 18; 13], zero-shot proxy [41; 85; 3; 37; 73; 76; 95; 74; 50; 59; 44; 70; 16; 17], performance predictor [45; 13; 79; 93], low-fidelity NAS evaluation [102; 66; 79; 78; 46; 36], and gradient proxy NAS . A comparison of these methods can be found in Table 4 in Appendix. Weight-sharing leverages the accuracy estimated by a _supernet_ as a proxy for the true architecture performance, while gradient proxy NAS uses the gradient as a proxy. These proxy-based methods, although incurring smaller search costs in terms of energy, can have lower search efficiency because their estimated architecture accuracy may have poor rank correlation . Zero-shot proxy NAS eliminates the need for _supernet_ training entirely, serving as a fully training-free proxy for network evaluation. However, as noted in , mainstream zero-shot NAS methods still struggle to achieve high rank correlations between predicted and true accuracies, even when compared to weight-sharing-based NAS evaluation. Performance predictors provide a more accurate performance prediction than weight-sharing and gradient proxy NAS. Still, their accuracy heavily relies on the volume and quality of the training data, which can be very expensive to create [90; 93]. Low-fidelity evaluation still requires training each searched architecture, leading to limited energy savings. In practice, simply employing these methods without modification might not effectively balance carbon emissions and performance during the search process. CE-NAS successfully achieves good search efficiency, search quality, and carbon efficiency by integrating the weight-sharing NAS method into vanilla NAS. We also leverage the low-fidelity evaluation method in the open-domain NAS search.

_The high carbon emission of NAS_ is a pressing issue. A study by  found that a single NAS solution can emit as much carbon as five cars over its lifetime. For example, if we design a transformer-based model, training a base Transformer model can use 96 GPU hours on NVIDIA's P100 , while training a larger model can take 28 GPU days. A recent NAS work  on transformer revealed that their comprehensive architecture search used 979 million training steps, totaling 274,120 GPU hours and resulting in 626,155 pounds of \(CO_{2}\) emissions. Although several NAS studies [87; 13; 12] have attempted to address carbon issues during the search process, they often treat carbon emissions uniformly, regardless of time and location variances. These carbon-agnostic NAS methods therefore miss the opportunity to explore the inherent carbon variations . Concurrently, systems researchers have explored the temporal and spatial variations exhibited in electricity's carbon emission for popular data center applications like training [4; 9] and inference . This work targets a special form of training workload, i.e., NAS, by leveraging the domain knowledge to optimize the end-to-end NAS process to explore carbon variations. Specifically, we concentrate on implementing the temporal variations in carbon intensity rather than spatial variations, as managing the carbon costs associated with spatial shifts poses significant challenges. Transferring large volumes of data over the Internet can incur substantial carbon costs, and accurately estimating these costs is complex. Data often passes through numerous intermediate routers across large geographic regions, making it difficult to ensure that the benefits of a spatial shift outweigh its associated overhead.

## 3 The Design of a Carbon-Efficient NAS Framework

In this section, we present an overview of the proposed CE-NAS framework (SS3.1). We first introduce the initial setup of our CE-NAS in SS3.2. We then propose a sampling strategy based on the one-shot/few-shot NAS evaluation method in SS3.3. Finally, we discuss the architecture evaluation part in SS3.4, which is both time and computing resource-intensive. In SS3.5, we describe how to use an RL-based agent to automatically allocate GPU resources based on predicted hourly carbon intensity.

### Ce-NAS Overview

As observed in , grid carbon emissions vary geographically and temporally based on the mix of active generators. Consequently, systems can emit different amounts of carbon even when consuming the same electricity at different locations or times. Currently, neither one (few)-shot nor vanilla NAS methods account for these variations in carbon emissions, which can lead to inefficiencies in terms of NAS carbon usage. Furthermore, one (few)-shot and vanilla NAS exhibit different search and carbon efficiency trade-offs. Vanilla NAS is carbon-intensive but effective, while one (few)-shot NAS can be carbon-friendly but sample-inefficient.

CE-NAS is a NAS framework that directly addresses the high-carbon issues by balancing energy consumption across high-carbon and low-carbon periods. The primary objective of this framework is to efficiently search for optimal neural architectures while minimizing the carbon footprint associated with the NAS process. Specifically, CE-NAS decouples the two parts of a NAS search process--energy-efficient sampling and energy-intensive evaluation--and handles them independently across different carbon periods. For each carbon period, CE-NAS uses an RL-based agent to automatically allocate GPU resources for the NAS search process to achieve good carbon efficiency.

### Search Initialization

CE-NAS considers more than one search objective(e.g., accuracy, mAP, latency, #FLops, etc), so we formulate the search problem as a multi-objective optimization (MOO). Similar to other NAS and optimization problems [24; 77; 98; 66], CE-NAS initializes the search process by randomly selecting several architectures, \(\), from the search space, \(\), and evaluating their accuracy, \(E()\), and other deployment metrics (#Params, #FLops, inference latency, inference energy, etc) \(T()\). Compared to the accuracy \(E()\), \(T()\) can be quickly measured without much cost. The resulting samples are then added to the observed samples set, \(\).

We distinguish two types of methods for evaluating the accuracy of an architecture. One is actual training, which trains an architecture \(a\) from scratch until convergence and evaluates it to obtain its true accuracy, \(E(a)\). To optimize computing resources during this process, we implement the low-fidelity training strategy described in [102; 66; 46; 79; 36]. This strategy reduces computing costs by simplifying the parameters of neural architectures (e.g., #depth, #channels, #resolutions) or shortening the training process under controlled conditions. The other method is using _one-shot evaluation_[10; 65; 46], which leverages a trained _supernet_, or a zero-shot-based NAS evaluator [95; 74; 50; 59; 44; 70; 16; 17] as a performance proxy to estimate the accuracy of the architecture, denoted as \(E^{}(a)\). Note that obtaining \(E^{}(a)\) is very cheap and carbon-efficient; however, due to the co-adaption among operations , \(E^{}(a)\) is often not as accurate as \(E(a)\). We train all the sampled architectures in the initialization stage to obtain their true accuracy for further search.

### Energy-Efficient Architecture Sampling

Multi-objective search space partition.We leverage the recently proposed multi-objective optimizer called LaMOO  that learns to partition the search space from observed samples to focus on promising regions likely to contain the Pareto frontier. LaMOO is an optimizer for general black-box optimization problems; we can apply it to NAS as follows.

We utilize LaMOO  to partition the search space \(\) into several subspaces, and find the optimal subspace denoted by \(_{best}\). Next, we construct and train a supernet [10; 97], \(_{best}\), for \(_{best}\). We then use a NAS search algorithm to identify new architectures that will be used to refine the search space. In this work, we employ the state-of-the-art multi-objective Bayesian optimization algorithm qNEHVI . This algorithm will generate new architectures \(}\) from \(_{best}\), and estimate their approximate accuracy \(E^{}(})\) using \(_{best}\). At the same time, these architectures \(}\) are added to a ready-to-train set \(\), consisting of candidates for further actual training as described in SS3.4.

We define the maximum capacity of \(\) as \(Cap()\), hyperparameter in CE-NAS. Note that the architectures in \(\) are removed once they are actual trained as described in SS3.4. When the capacity is reached, i.e., when there are more architectures to train than we have resources for, the sampling process blocks until spaces free up in \(\). The accuracy of architectures estimated by \(_{best}\) will be fed back into the search algorithm as shown in Figure 1 to repeat the process described above.

As mentioned in SS3.2, obtaining estimated accuracy through supernet is energy-efficient because these architectures can be evaluated without the time-consuming training. Therefore, during high carbon emission periods, CE-NAS will try to perform this process to save energy and produce as little carbon as possible, as shown in the _energy-efficient sampling_ part of Fig.1.

### Energy-Intensive Architecture Evaluation

If we perform the entire NAS only using the process described in SS3.3, CE-NAS will be essentially performing one/few-shot NAS only within the subspace \(_{best}\). Although these methods are efficient, they typically underperform compared to vanilla NAS. As Zhao et al. showed, it is possible to improve LaMOO's space partition with more observed samples through actual training . This section describes the process to evolve \(_{best}\) during low carbon emission periods.

At the high level, we will pick new architectures from the ready-to-train set \(\) to train to convergence and use them to refine the search space partition. That is, the architecture \(\), with its true accuracy, \(E()\), will be added to the observed sample set \(\) to help identify a more advantageous subspace, \(_{best}\), for the architecture sampling process as described in . In this work, we sort the architectures in the ready-to-train set \(\) by their _dominance number_. The dominance number \(o()\) of an architecture \(\) is defined as the number of samples that dominate \(\) in search space \(\):

\[o():=_{_{i}}[_{i}_{f},\ _{i}]^{1},\] (1)

where \([]\) is the indicator function. With the decreasing of the \(o()\), \(\) would be approaching the Pareto frontier; \(o()=0\) when the sample architecture \(\) is located in the Pareto frontier. The use of dominance number allows us to rank an architecture by considering both the estimated accuracy \(E^{}()\) and other metrics \(T()\) at the same time. CE-NAS will first train the architectures with lower dominance number values when GPU resources are available. Once an architecture is trained, it is removed from \(\).

This process is depicted in the _energy-consuming evaluation_ component of Figure 1. Note that this process includes actual time-consuming DL model training, which is time-consuming and highly energy-intensive, leading to significant \(CO_{2}\) emissions. Hence, CE-NAS will try to prioritize this process during periods of low carbon intensity.

### Carbon-Efficient GPU Allocation

The carbon impact of the above two processes (i.e., SS3.3 and SS3.4) in a NAS search is materialized through the use of GPU resources. A key decision CE-NAS needs to make is _how_ to allocate GPUs among these two interdependent processes. Assigning too many GPUs to architecture sampling could impact the search efficiency, i.e., the searched architectures are far from the true Pareto frontier; assigning too many GPUs to architecture evaluation could significantly increase energy consumption and carbon emission. CE-NAS must consider these trade-offs under varying carbon intensity and re-evaluate the GPU allocation strategy. We design an RL-based strategy (SS3.5.1) to automatically allocate GPU resources based on predicted carbon intensity in every one hour (SS3.5.2).

#### 3.5.1 Design of RL-Based GPU Allocation Strategy

Although the heuristic-based strategy proposed by  can adjust the tendency for sampling and evaluation based on carbon intensity, it is still far from making the most carbon-efficient decision. It overlooks critical influencing factors such as the varying gains in accuracy from performing sampling and evaluation at different stages of the search. These factors are specific to the NAS algorithms and are challenging to model, which complicates its inclusion in heuristic strategy design. To address this issue, we introduce a method based on reinforcement learning that automatically accounts for these diverse factors to develop allocation strategies. We propose a Reinforcement Learning (RL)-based method to automatically customize a GPU allocation strategy for specific NAS algorithms. In this paper, we choose LaMOO  with qNEHVI .

The key to applying RL lies in the design of effective state inputs, actions, and rewards according to the specific task. Our CE-NAS focuses on tailoring these elements for carbon-efficient NAS tasks, with the guiding principle of simplifying the state and action spaces to expedite efficient and rapid training. Specifically, Our RL agent, which is a simple-structured neural network with only four fully connected layers, takes the remaining carbon budget, the number of already searched architectures and their hypervolume (The definition of the hypervolume refers to Appendix E.2.4.), as well as the future carbon traces predicted by the time transformer as input. Then it outputs the probabilities of different GPU allocation ratios for architecture evaluation as action. These possible allocation ratios are discretized to boost learning efficiency. After the action is executed, CE-NAS generates a reward based on the improvement of the performance of the already searched architectures and then uses the reward to refine the policies of the agent by updating its network parameters with the _actor-critic_ policy gradient algorithm. The specifics of our RL design can be found in Appendix C and the middle part of Fig. 1.

#### 3.5.2 Design of Transformer-Based Carbon Intensity Forecasting

We utilize a machine learning model to predict future carbon intensity, which serves as the input of the RL agent. We leverage a time series transformer-based model, as shown in the top left part of Fig. 1, to forecast future carbon intensity because of their efficacy . Specifically, we leverage the architecture design by employing a standard encoder-decoder Transformer for time series forecasting . This method incorporates temporal features that act as positional encodings within the Transformer's encoder/decoder framework. Past values are input into the encoders, and future values are input into the decoders in the training stage. For instance, as described in , if a time series data point corresponds to the 11th of August, the temporal feature vector would be \((11,8)\), where 11 denotes the day of the month, and 8 signifies the month of the year. We leverage the SOTA

Figure 2: An overview of CE-NAS. This carbon trace is based on the US-CAL-CISO data from 2021, specifically covering the period from 0:00, July 2, 2021, to 8:00, July 4, 2021. The blue trace is its actual carbon trace and the yellow trace is the prediction trace by our carbon predictor described in sec. 3.5.2

NAS algorithm LaMOO  to design the architecture of the time series transformer. The details of search space and founded architectures are in Appendix D.

## 4 Ce-NAS Experimental Evaluation

We develop a prototype of the CE-NAS framework as outlined in Section 3. This section analyzes CE-NAS's carbon efficiency and search efficacy through trace-driven simulations and emulation. We first demonstrate the performance of our designed time-series transformer for carbon forecasting in SS 4.1. We then assess CE-NAS across two distinct NAS scenarios: the first leveraging two commonly used NAS benchmarks, HW-NAS-Bench  and NasBench301 , and the second including real-world computer vision applications, such as image classification.

Our experiments utilize carbon trace data sourced from ElectricityMap , an independent carbon information service. We selected the CISO2 trace beginning on July 2, 2021, due to its variable carbon intensity, which provides an opportunity to evaluate CE-NAS's performance over time and its adaptability to fluctuating carbon levels. Figure 2 illustrates the initial 80 hours of the carbon trace, demonstrating the actual data against the forecasted trace predicted by our designed time series transformer, as detailed in Section 3.5.2. Throughout the CE-NAS search phase, predicted carbon intensity is utilized for GPU allocation, while the actual carbon trace informs the calculation of carbon costs in the evaluation phase.

We also conduct several ablation studies detailed in Appendix F. These studies include variations of hyperparameters in the RL agent settings, validation of LaMOO's effectiveness, and a comparison of search performance using predicted versus actual carbon traces, among others. Our findings reveal only a minimal difference in search performance between using predicted and actual carbon traces.

### Time-series Transformer for Carbon Forecasting

We assess the performance of our time series forecasting transformer across three distinct regions: CISO, DE3, and PJM4. We compare our approach against other SOTA models referenced in [11; 56;

Figure 3: Search progress over time. CE-NAS has the second lowest relative carbon emission while achieving the second best \(HV_{\_diff}\) on HW-NAS-Bench, and CE-NAS has the second lowest relative carbon emission while achieving the second best \(HV\) on NasBench301.

    &  &  &  \\   & **STCF ** & **DACF ** & **CC ** & **ours** & **STCF ** & **DACF ** & **CC ** & **ours** & **STCF ** & **DACF ** & **CC ** & **ours** \\ 
**CISO** & 10.71 & 6.45 & 8.08 & **5.26** & 18.99 & 12.26 & 11.19 & **8.69** & 25.24 & 16.02 & 12.93 & **10.83** \\ 
**DE** & 15.54 & 7.21 & 7.81 & **5.34** & 31.56 & 11.82 & 10.69 & **8.23** & 42.16 & 13.95 & 12.80 & **10.68** \\ 
**PJM** & 4.27 & 3.08 & 3.69 & **2.58** & 7.11 & 5.51 & 4.93 & **3.53** & 8.90 & 7.06 & 5.87 & **4.02** \\   

Table 1: Daywise MAPE comparison of our time-series transformer and other baseline methods.

55]. The studies in [11; 56] employ a Feed-Forward Neural Network (FFNN) for their forecasts, while  utilizes a combination of FFNN, Convolutional Neural Network, and Long Short-Term Memory networks for multi-day carbon intensity predictions. We use the Mean Absolute Percentage Error (MAPE) to evaluate forecasting accuracy. Table 1 demonstrates a day-to-day comparison of all methods, with the most effective technique in bold. Our model demonstrates the best performance for both single-day and multi-day carbon intensity forecasting scenarios. More experimental details can be found in Appendix E.1.

### NAS Benchmarks and Baselines

To date, there are three popular open-source NAS benchmarks, NasBench101 , HW-NAS-BENCH , and NasBench301 . For our evaluation, we focus on the latter two, as the network architectures within these benchmarks cover the entirety of the search space. In contrast, the NasBench101 benchmark comprises only a limited subset of potential architectures. Evaluating using NasBench101 is challenging because we will not have access to important information, such as accuracy, during the search for the architecture not in the NasBench101 benchmark. We choose three types of baselines according to different GPU allocation strategies and NAS evaluation algorithms, including _vanilla LaMOO_, _one-shot LaMOO_ and a heuristic GPU allocation strategy , which is the SOTA result so far. We also define a carbon budget as the termination condition. Once the NAS exceeds this \(CO_{2}\) budget, it will be stopped. More baseline details are in Appendix E.2.3.

#### 4.2.1 Simulation using HW-NAS-Bench

    &  &  &  & \) **(lbs)**} &  \\  & & & & (**GPU hours)\({}^{}\) & \\  PNAS  & 3.41\(\)0.09 & 3.2 & 5400 & 3836.62 & vanilla \\ NAO  & 3.14\(\)0.09 & 3.2 & 5400 & 3836.62 & vanilla \\ NASNet-A  & 2.65 & 3.3 & 48000 & 30534.78 & vanilla \\ LEMONADE  & 2.58 & 13.1 & 2160 & 1514.07 & vanilla \\ AlphaX  & 2.54\(\)0.06 & 2.83 & 24000 & 16196.72 & vanilla \\ AmoebaNet-B-small  & 2.50\(\)0.05 & 2.8 & 75600 & 43972.18 & vanilla \\  BayeNAS  & 2.81\(\)0.04 & 3.4 & 31.2 & 21.70 & one-shot \\ DARTS  & 2.76\(\)0.09 & 3.3 & 50.4 & 34.04 & one-shot \\ MergeNAS  & 2.68\(\)0.01 & 2.9 & 40.8 & 27.01 & one-shot \\ One-shot REA & 2.68\(\)0.03 & 3.5 & 44.4 & 29.33 & one-shot \\ CNAS  & 2.60\(\)0.06 & 3.7 & 33.6 & 23.19 & one-shot \\ PC-DARTS  & 2.57\(\)0.07 & 3.6 & 33.6 & 23.19 & one-shot \\ Fair-DARTS  & 2.54\(\)0.05 & 3.32 & 98.4 & 65.87 & one-shot \\ P-DARTS  & 2.50 & 3.4 & 33.6 & 23.19 & one-shot \\ 
**CE-Net-P1** & 2.65\(\)0.03 & **1.68** & 228.6 & 38.53 & hybrid \\
**CE-Net-P2** & **2.16\(\)0.06** & 3.30 & 228.6 & 38.53 & hybrid \\    \({}^{}\) The total cost includes both the NAS search duration and the training time for the architectures identified. When applying one-shot NAS to search architectures on CIFAR-10, we estimate that training these architectures from scratch until convergence requires approximately 26.4 GPU hours.

Table 2: Search Results on CIFAR-10 using the NasNet search space. The two optimization objectives we are searching for are #params and accuracy.

Figure 4: Search efficiency under carbon emission constraints. These results are based on HW-NAS-Bench with carbon trace showing in fig. 2, and we ran each method ten times.

We evaluate our experimental results using two metrics: _relative carbon emission_ and _log hypervolume difference_. Note that _log hypervolume difference_ measures the quality of the search result and the smaller the better. Detailed definitions of these metrics can be found in Appendix E.2.4. As depicted in Figure 3(a), as the search time progresses, vanilla LaMOO demonstrates the highest performance in terms of \(HV_{,}\). Vanilla LaMOO's superior performance can be attributed to its approach of _training all sampled architectures_ to obtain their true accuracy, which effectively steers the search direction. However, when considering the relative carbon emission, vanilla LaMOO consumes 3.24X-7.22X carbon compared to other approaches. This is expected because vanilla LaMOO is an energy-intensive approach and is not designed to be aware of carbon emissions.

We show that CE-NAS's search efficiency is only marginally lower than that of vanilla LaMOO while having the least relative carbon emission. Note that we are plotting the \(HV_{,}\) in the Y-axis of Figure 3(a); the actual \(HV\) values achieved by CE-NAS and Vanilla LaMOO are about 4100 and 4117, differing only by 0.034%, even though the two lines look far apart. This result also suggests that only relying on energy-efficient approaches (e.g., one-shot LaMOO in this case) is insufficient to achieve good search performance. CE-NAS only takes 15 hours to get the comparable \(HV\) results with the final results of One-shot LaMOO.

Figure 4 presents a comparative analysis of CE-NAS's performance against various baselines under differing carbon budgets. It is evident that CE-NAS surpasses all baselines in search efficiency under different \(CO_{2}\) budget constraints5. Below a consumption level of 10,000g \(CO_{2}\), Notably, the search outcomes associated with CE-NAS, as depicted in Figure 4(a), and those of vanilla/one-shot LaMOO, as shown in Figure 4(d), are comparable in terms of the median log hypervolume difference. This indicates that integrating CE-NAS with the NAS strategy can achieve a carbon cost saving of up to 5X compared to the conventional vanilla/one-shot NAS methodologies.

Figure 5: Search efficiency under carbon emission constraints. These results are based on NasBench301 with carbon trace showing in fig. 2, and we ran each method five times.

  
**Method** & **Top-1 Error(\%)** &  **TensorRT Latency** \\ **FP16 V100 (ms)** \\  & 
 **Search&Training Cost** \\ **(GPU Hours)\({}^{}\)** \\  & **CO2 (bs)** & **NAS Method** \\  NASNet-A  & 26.0 & 2.86 & 48300 & 30679.13 & vanilla \\ PNAS  & 25.8 & 2.79 & 5700 & 4063.14 & vanilla \\ MnasNet  & 24.8 & **0.53** & 40300 & 26487.44 & vanilla \\ AlphaX  & 24.5 & 2.52 & 3900 & 2768.21 & vanilla \\ AmoebaNet-C  & 24.3 & 2.63 & 7590 & 44177.38 & vanilla \\  AutoSlim \({}^{}\) & 25.8 & 1.64 & 480 & 321.89 & one-shot \\ ProxylessNAS \({}^{}\) & 25.4 & 0.98 & 500 & 332.07 & one-shot \\ SinglePathNAS \({}^{}\) & 25.3 & 1.13 & 686 & 455.99 & one-shot \\ PC-DAFR \({}^{}\) & 24.2 & 1.50 & 411 & 278.15 & one-shot \\ FBNet-C \({}^{}\) & 21.5 & 1.22 & 576 & 381.58 & one-shot \\ OFA-Net \({}^{}\) & 20.0 & 1.16 & 1315 & 888.85 & one-shot \\ 
**CE-Net-G1\({}^{}\)** & 21.0 & **0.56** & 2706 & 909.86 & hybrid \\
**CE-Net-G2\({}^{}\)** & **19.4** & 0.78 & 2706 & 909.86 & hybrid \\    \({}^{}\) The total cost includes both the NAS search duration and the training time for the architectures identified.

\({}^{}\) The architecture is searched on ImageNet directly, otherwise it is searched on CIFAR-10 by transfer setting.

Table 3: Search Results on ImageNet. The two optimization objectives we are searching for are TensorRT Latency with FP16 in NVIDIA V100 and accuracy.

#### 4.2.2 Simulation using NasBench301

On NasBench301, we use two metrics: _relative carbon emission_ and _hypervolume_(\(HV\)). Note that higher HV means better search results. Given the expansive nature of the NasBench301 search space, the maximal hypervolume remains undetermined. Consequently, rather than employing the hypervolume difference as a performance metric, we utilize the absolute hypervolume value to represent the efficacy of our search strategy. As depicted in Figure 3(b), our findings are consistent with those from HW-NasBench. One-shot LaMOO incurs the lowest carbon footprint but yields the least impressive performance in terms of hypervolume. Conversely, Vanilla LaMOO achieves the highest \(HV\) but at a carbon cost that exceeds CE-NAS by more than 3.76 times. CE-NAS markedly surpasses the SoTA heuristic GPU allocation strategy regarding \(HV\), while maintaining a comparable carbon expenditure. At equivalent levels of carbon cost, as illustrated in Figure 5, CE-NAS demonstrates significantly superior search performance compared to other baselines. Figures 5(a) and 5(d) show that architectures identified through CE-NAS not only yield better results but also do so with a carbon cost that is four times lower than that of one-shot and vanilla NAS methods. Within the NasBench301 framework, CE-NAS also substantially outperforms the heuristic GPU allocation approach for NAS.

### Open-Domain NAS Tasks

#### 4.3.1 Searching on CIFAR-10 Image Classification Task

Our CE-NAS framework is compared with other popular NAS baselines, including vanilla and one-shot methods. Table 2 presents the SOTA results using DARTS and NASNet search spaces on CIFAR-10. The first group in the table comprises models discovered using vanilla NAS, and the second group includes those found with one-shot NAS. The \(CO_{2}\) cost is calculated based on the duration of the search/training and the carbon intensity in the CISO region. For our CE-NAS, we select the optimal architectures from the Pareto frontier of the search results. Our CE-Net-P1 has only 1.68M parameters, significantly reducing parameter size compared to other baselines while maintaining a comparable top-1 accuracy (97.35%) with other SOTA models. Our CE-Net-P2 surpasses all baselines in top-1 accuracy (97.84%) while maintaining a similar parameter count of 3.26M. The performance discrepancy between the one-shot (second group) and vanilla NAS (first group) methods is attributed to the supernet's inaccurate accuracy prediction [31; 92]. Remarkably, our CE-NAS not only outperforms all vanilla-based NAS algorithms but also incurs a mere 38.53 lbs of \(CO_{2}\) for the NAS search, comparable to the cost of one-shot-based NAS methods. More details related to the search space, training/search setup in More details in Appendix E.3.1.

#### 4.3.2 Searching on ImageNet Image Classification Task

Table 3 demonstrates a comparison between our CE-NAS and other state-of-the-art (SOTA) baselines. We selected our searched models, designated as CE-Net-G1 and CE-Net-G2, from the Pareto frontier, based on the dual objectives of accuracy and TensorRT latency. Our searched architectures incur a slightly higher carbon cost (909.86 lbs) compared to one-shot-based SOTA baselines but significantly outperform these baselines in terms of top-1 accuracy and TensorRT latency. More details on search space, and training/search setup are demonstrated in Appendix E.3.2.

## 5 Conclusion

In this work, we described the design of a carbon-efficient NAS framework CE-NAS by leveraging the temporal variations in carbon intensity. To search for energy-efficient architectures, CE-NAS integrates a SOTA multi-objective optimizer, LaMOO , with the one/few-shot and vanilla NAS algorithms. These two NAS evaluation strategies have different energy requirements, which CE-NAS leverages an RL-based agent to schedule when to use each based on average carbon intensity. CE-NAS has demonstrated very promising results across various NAS tasks. For example, on CIFAR-10, CE-NAS successfully identified an architecture that achieves 97.35% top-1 accuracy with just 1.68M parameters and emitted only 38.53 lbs of \(CO_{2}\). These compelling results suggest the efficacy and potential of CE-NAS as an effective framework in carbon-aware NAS. Additionally, on ImageNet, CE-NAS discovered state-of-the-art models achieving a top-1 accuracy of 80.6% with a TensorRT latency of 0.78 ms using FP16 on NVIDIA V100, and a top-1 accuracy of 79.0% with a latency of 0.56 ms on the same hardware. The carbon cost for this search was only 909.86 lbs.

Acknowledgement

This work was supported in part by NSF Grants #2105564 and #2236987, a VMware grant, the Worcester Polytechnic Institute's Computer Science Department, and the National Natural Science Foundation of China under No. 62072302. This work also used Expanse at San Diego Supercomputer Center through allocation CIS230364 from the Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS) program, which is supported by National Science Foundation grants #2138259, #2138286, #2138307, #2137603, and #2138296.