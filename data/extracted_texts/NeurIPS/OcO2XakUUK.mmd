# Realizable \(\mathcal{H}\)-Consistent and Bayes-Consistent

# Realizable \(\)-Consistent and Bayes-Consistent

Loss Functions for Learning to Defer

 Anqi Mao

Courant Institute

New York, NY 10012

aqmao@cims.nyu.edu &Mehrvar Mohri

Google Research & CIMS

New York, NY 10011

mohri@google.com &Yutao Zhong

Courant Institute

New York, NY 10012

yutao@cims.nyu.edu

###### Abstract

We present a comprehensive study of surrogate loss functions for learning to defer. We introduce a broad family of surrogate losses, parameterized by a non-increasing function \(\), and establish their realizable \(\)-consistency under mild conditions. For cost functions based on classification error, we further show that these loss functions admit \(\)-consistency bounds when the hypothesis set is symmetric and complete, a property satisfied by common neural network and linear function hypothesis sets. Our results also resolve an open question raised in previous work  by proving the realizable \(\)-consistency and Bayes-consistency of a specific surrogate loss. Furthermore, we identify choices of \(\) that lead to \(\)-consistent surrogate losses for _any general cost function_, thus achieving Bayes-consistency, realizable \(\)-consistency, and \(\)-consistency bounds _simultaneously_. We also investigate the relationship between \(\)-consistency bounds and realizable \(\)-consistency in learning to defer, highlighting key differences from standard classification. Finally, we empirically evaluate our proposed surrogate losses and compare them with existing baselines.

## 1 Introduction

In many practical scenarios, combining expert insights with established models can yield significant enhancements. These experts can be human domain specialists or more complex, albeit resource-intensive, models. For example, modern language and dialogue models are prone to producing _hallucinations_ or inaccurate information. The quality of their responses can be significantly enhanced by delegating uncertain predictions to more specialized or advanced pre-trained models. This problem is particularly crucial for large language models (LLMs), as noted in . The same principle applies to other generative systems, like those for images or videos, and to learning models in diverse applications such as image classification, annotation, and speech recognition. Thus, the task of _learning to defer_ (L2D) with experts has become increasingly critical across a wide array of applications.

Directly optimizing the deferral loss function, which is the target loss in L2D, is computationally intractable for many choices of the hypothesis set. Therefore, a common approach is to optimize a surrogate loss that facilitates the optimization of the deferral loss function. Recent work in L2D has proposed several surrogate losses  and studied their consistency guarantees, including Bayes-consistency, realizable \(\)-consistency, and \(\)-consistency bounds (see definitions in Section 3.2). In particular, Mozannar and Sontag  proposed the first Bayes-consistent surrogate loss by generalizing the cross-entropy loss for L2D. Verma and Nalisnick  proposed an alternative Bayes-consistent surrogate loss by generalizing the one-versus-all loss for L2D. Mozannar et al.  showed that these surrogate losses are not realizable \(\)-consistent. They proposed an alternative surrogate lossthat is realizable \(\)-consistent, but they were unable to prove or disprove whether the proposed surrogate loss is Bayes-consistent. All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on classification error. Mao et al. (2024) generalized the surrogate loss in (Mozannar and Sontag, 2020) to incorporate general cost functions and any multi-class surrogate losses. They provided \(\)-consistency bounds for the novel family of surrogate losses, offering a stronger guarantee than Bayes-consistency.

However, none of these surrogate losses satisfies all these guarantees simultaneously. In particular, a recent AISTATS notable award paper by Mozannar et al. (2023) left open the problem of finding surrogate losses that are both Bayes-consistent and realizable \(\)-consistent when the cost function for the expert is its classification error. The problem becomes even more challenging when considering more general and realistic cost functions.

We present a comprehensive analysis of surrogate loss functions for L2D. Our contributions address the limitations of previous approaches and provide a unified framework for designing surrogate losses with strong theoretical guarantees. In Section 4, we first introduce a broad family of surrogate losses for L2D, derived from first principles (Section 4.1). This family is parameterized by a non-increasing function \(\), which provides some flexibility in tailoring the loss function to specific requirements. We establish that under mild conditions on \(\), these surrogate losses achieve realizable \(\)-consistency, a key guarantee for many applications (Section 4.2).

Next, for cost functions based on classification error, we further establish that our surrogate loss functions admit \(\)-consistency bounds when the hypothesis set is symmetric and complete (Section 4.3). This result holds for commonly used neural network and linear function hypothesis sets, further strengthening the applicability of our results. Additionally, our results resolve an open question raised by Mozannar et al. (2023) by proving the realizable \(\)-consistency and Bayes-consistency of their proposed surrogate loss, which the authors had left as an open question (Section 4.4).

In Section 4.3, we further identify specific choices of \(\), such as the one corresponding to the mean absolute error loss, that lead to \(\)-consistent surrogate losses for _any general cost function_. These loss functions are adapted to general cost functions and benefit from Bayes-consistency (Section 4.4), realizable \(\)-consistency, and \(\)-consistency bounds _simultaneously_.

In Section 5, we also study the relationship between \(\)-consistency bounds and realizable \(\)-consistency in the context of L2D, highlighting key distinctions from the standard classification setting. Finally, we further report the results of experiments with our new surrogate losses and their comparison with the baselines in different settings (Section 6).

We discuss the related work in Section 2 and then begin with the preliminaries in Section 3.

## 2 Related work

The approach of _single-stage learning to defer_, where a predictor and a deferral function are trained together, was pioneered by Cortes, DeSalvo, and Mohri (2016, 2016, 2023) and further developed in subsequent studies on abstention, where the cost is constant (Chaoenphakdee et al., 2021; Cao et al., 2022; Li et al., 2023; Cheng et al., 2023; Mao et al., 2024, 2024) and on deferral, where the cost can vary depending on the instance and the label (Mozannar and Sontag, 2020; Verma and Nalisnick, 2022; Mozannar et al., 2023; Verma et al., 2023; Cao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2024). In this approach, the deferral function determines whether to defer to an expert for each input. This approach has been shown to be superior to _confidence-based_ approaches, where the decision to abstain or defer is based solely on the magnitude of the predictor's value (Chow, 1957, 1970; Bartlett and Wegkamp, 2008; Yuan and Wegkamp, 2010, 2011; Ramaswamy et al., 2018; Ni et al., 2019; Jitkrittum et al., 2023); and to _selective classification_ approaches, where the selection rate is fixed and a cost function modeled by an expert cannot be taken into account (El-Yaniv et al., 2010; El-Yaniv and Wiener, 2012; Wiener and El-Yaniv, 2011, 2012, 2015; Geifman and El-Yaniv, 2017, 2019; Acar et al., 2020; Gangrade et al., 2021; Zaoui et al., 2020; Jiang et al., 2020; Shah et al., 2022).

Madras et al. (2018) initiated the _learning to defer_ (L2D) problem scenario, which integrates human expert decisions into the cost function. This approach has been further explored in subsequent studies (Raghu et al., 2019; Wilder et al., 2021; Pradier et al., 2021). Mozannar and Sontag (2020) introduced the first Bayes-consistent surrogate loss for L2D, which was further refined in (Raman and Yee, 2021; Liu et al., 2022). Verma and Nalisnick (2022) proposed an alternative Bayes-consistent surrogate loss,the one-versus-all loss, which was later examined within a broader family of loss functions (Charusaie et al., 2022). Cao et al. (2023) proposed an asymmetric softmax function, which can induce a valid probability estimator for learning to defer. Mozannar et al. (2023) showed that the surrogate losses in (Mozannar and Sontag, 2020, Verma and Nalisnick, 2022) are not realizable \(\)-consistent. They proposed an alternative surrogate loss that is realizable \(\)-consistent, but they were unable to prove or disprove whether the proposed surrogate loss is Bayes-consistent. All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on classification error. Mao et al. (2024) generalized the surrogate loss in (Mozannar and Sontag, 2020) to incorporate general cost functions and any multi-class surrogate losses. They provided \(\)-consistency bounds for the novel family of surrogate losses, offering a stronger guarantee than Bayes-consistency.

Additional studies have focused on post-hoc methods, with Okati et al. (2021) suggesting an alternative optimization technique between the predictor and rejector, and Narasimhan et al. (2022) offering corrections for underfitting surrogate losses (Liu et al., 2024), and Charusaie and Samadi (2024) providing a unifying post-processing framework for multi-objective L2D based on a generalization of the Neyman-Pearson Lemma (Neyman and Pearson, 1933). The L2D framework or variations thereof have found applications in diverse scenarios, spanning regression, reinforcement learning, and human-in-the-loop systems, among others (De et al., 2020, 2021, Straitouri et al., 2021, Zhao et al., 2021, Joshi et al., 2021, Gao et al., 2021, Mozannar et al., 2022, Hemmer et al., 2023, Chen et al., 2024, Palomba et al., 2024). More recently, the problem of _learning to defer with multiple experts_ has been analyzed in several publications (Hemmer et al., 2022, Keswani et al., 2021, Kerrigan et al., 2021, Straitouri et al., 2022, Benz and Rodriguez, 2022, Verma et al., 2023, Mao et al., 2023, 2024a,g, Tailor et al., 2024). Meanwhile, Mao et al. (2023) also proposed a _two-stage learning to defer_ framework. They introduced two-stage surrogate losses that are both Bayes-consistent and realizable \(\)-consistent with constant costs. However, realizable \(\)-consistency does not hold for cost functions based on classification error. As with (Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023), our work focuses on the single-stage and single-expert setting, and we plan to explore a similar approach in a multi-expert/two-stage setting in the future.

## 3 Preliminaries

We start with the definitions and notations used in the learning-to-defer scenario considered in this paper. We will then introduce consistency guarantees, including _Bayes consistency_, _Realizable \(\)-consistency_, and \(\)-_consistency bounds_. Finally, we will review existing consistent surrogate losses for L2D.

### Learning to defer: problem setup

Let \(\) be an input space and \(=[n]:=\{1,,n\}\) be the label space in the standard multi-class classification setting. We study the _learning to defer_ (L2D) scenario, where a learner can either predict a label from \(\) or defer to an expert.

To model this, we introduce an augmented label space \(}=\{1,,n,n+1\}\), where the label \(n+1\) corresponds to deferral. An expert is a fixed predictor \(g\). The goal of L2D is to select a predictor \(h\) out of a hypothesis set \(\) of functions mapping from \(}\) to \(\) with small expected _deferral loss_. Let \((x)\) denote the prediction of \(h\) on input \(x\), defined as \((x)=*{argmax}_{y}}h(x,y)\), that is the label in the augmented label space \(}\) with the highest score, with an arbitrary but fixed deterministic strategy for breaking ties. Then, the _deferral loss function_\(_{}\) is defined as follows:

\[(x,y),_{}(h,x,y)=_{(x)*y}_{(x)[n]}+c(x,y)_{(x)=n+1},\]

where \(c(x,y)\) is the the cost of deferring on input \(x\) with true label \(y\). If the deferral option is selected, that is \((x)=n+1\), the deferral cost \(c(x,y)\) is incurred. Otherwise, the prediction of \(h\) is within the standard label space, \((x)[n]\), and the loss incurred coincides with the standard zero-one classification loss, \(_{(x)*y}\).

The choice of the cost function \(c\) is flexible. For example, the cost can be defined as the expert's classification error: \(c(x,y)=_{(x)*y}\), as in previous work (Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023). Here, \((x)=*{argmax}_{y[n]}g(x,y)\) is the prediction made by the expert \(g\). More generally, it can incorporate the inference cost for the expert (Mao et al., 2024a): \(c(x,y)=_{(x) y}+\), with \(,>0\). We assume, without loss of generality, that the cost is bounded by 1: \(0 c(x,y) 1\), which can be achieved through normalization in practice.

### Consistency guarantees

Directly optimizing the deferral loss function, which is the target loss in L2D, is generally computationally intractable for complex hypothesis sets \(\). Therefore, a common approach is to optimize a surrogate loss that facilitates the optimization of the deferral loss function. A natural learning guarantee for such surrogate losses is _Bayes-consistency_(Zhang, 2004; Bartlett et al., 2006; Zhang, 2004b; Tewari and Bartlett, 2007; Steinwart, 2007):

**Definition 3.1** (Bayes-consistency).: A surrogate loss \(\) is Bayes-consistent with respect to \(_{}\), if minimizing the surrogate loss over the family of all measurable functions leads to the minimization of the deferral loss:

\[_{n+}_{}(h_{n})-_{}^{ }(_{})=0_{n+}_{ _{}}(h_{n})-_{_{}}^{ }(_{})=0.\]

Here, given a distribution \(\) over \(\) and a loss function \(\), we denote by \(_{}(h)\) the _generalization error_ of a hypothesis \(h\), \(_{}(h)=_{(x,y)}[(h,x,y)]\), and by \(_{}^{}()\) the _best-in-class generalization error_, \(_{}^{}()=_{h} _{}(h)\). Bayes-consistency assumes that the optimization occurs over the family of all measurable functions, \(_{}\). However, in practice, the hypothesis set of interest is typically a restricted one, such as a family of neural networks. Therefore, a hypothesis-dependent learning guarantee, such as \(\)_-consistency bounds_(Awasthi et al., 2022a,b)(see also (Awasthi et al., 2021a,b, 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2024; LeCun et al., 2024; LeCun et al., 2024)) and _realizable \(\)-consistency_(Long and Servedio, 2013; Zhang and Agarwal, 2020), is more informative and relevant. Realizable \(\)-consistency, defined as follows, requires that a minimizer of the surrogate loss over the given hypothesis set \(\) also minimizes the target loss, provided that the underlying distribution is realizable.

**Definition 3.2** (Realizable \(\)-consistency).: A surrogate loss \(\) is realizable \(\)-consistent with respect to \(_{}\), if for any distribution over which there exists a predictor \(h^{}\) achieving zero deferral loss, \(_{_{}}(h^{})=0\), minimizing the surrogate loss also leads to a zero-error solution:

\[*{argmin}_{h}_{}(h)_{_{}}()=0.\]

Note that realizable \(\)-consistency does not imply Bayes-consistency, even if we set \(=_{}\) in Definition 3.2, since Bayes-consistency requires that the relationship holds for all distributions, not just realizable ones. \(\)_-consistency bounds_, on the other hand, always imply Bayes-consistency. Given a hypothesis set \(\), a surrogate loss \(\) admits an _\(\)-consistency bound_, if for some non-decreasing concave function \(_{+}_{+}\) with \((0)=0\), a bound of the following form holds for any hypothesis \(h\) and any distribution:

\[_{_{}}(h)-_{_{}}^{}()+_{_{}}( )(_{}(h)-_{ }^{}()+_{}()),\] (1)

where \(_{}()\) is _the minimizability gap_, defined as the difference between the best-in-class generalization error and the expected pointwise infimum loss: \(_{}()=_{}^{}( )-_{x}_{h}_{y|x }[(h,x,y)]\). The minimizability gap can be upper-bounded by the approximation error and vanishes when \(=_{}\)(Awasthi et al., 2022a,b). Thus, an \(\)-consistency bound implies Bayes-consistency. The relationship between the two hypothesis-dependent learning guarantees--realizable \(\)-consistency and \(\)-consistency bounds--depends on the target loss adopted in the specific learning scenario. In Section 5, we will demonstrate that in the standard multi-class classification setting, an \(\)-consistency bound is a stronger notion than realizable \(\)-consistency. However, in L2D, these guarantees do not imply one another.

### Existing surrogate losses

Here, we will review several consistent surrogate losses used in L2D. For convenience, we use \((x,y)=_{(x) y}\) to denote the cost when it specifically represents the expert's classification error, and use \(c(x,y)\) when it represents a general cost function.

Mozannar and Sontag (2020) proposed the first Bayes-consistent surrogate loss by generalizing the cross-entropy loss for L2D, with cost functions based on classification error, which is defined as

\[_{}(h,x,y)=-\!(}{_{y^{} }e^{h(x,y^{})}})-(1-(x,y))\!( }{_{y^{}}e^{h(x,y^{})}} )\!.\]

Verma and Nalisnick (2022) proposed an alternative one-vs-all surrogates loss with cost functions based on expert's classification error, that is Bayes-consistent as well:

\[_{}(h,x,y)=(h(x,y))+_{y^{ }\\ y^{} y}(-h(x,y^{}))+(1-(x,y)) [(h(x,n+1))-(-h(x,n+1))],\]

where \(\) is a strictly proper binary composite loss (Reid and Williamson, 2010), such as the logistic loss \(t(1+e^{-t})\). \(_{}\) and \(_{}\) are not realizable \(\)-consistent. Instead, Mozannar et al. (2023) proposed the following loss function that is realizable \(\)-consistent when \(\) is closed under scaling:

\[_{}(h,x,y)=-2\!(+(1- {c}(x,y))e^{h(x,n+1)}}{_{y^{}}e^{h(x,y^{})}} )\!.\]

However, they were unable to prove or disprove whether the surrogate loss \(_{}\) is Bayes-consistent.

All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on the classification error: \((x,y)=1_{(x) y}\). Mao et al. (2024) generalized the surrogate loss \(_{}\) to incorporate general cost functions and any multi-class surrogate losses:

\[_{}(h,x,y)=(h,x,y)+(1-c(x,y))(h,x,n+1).\]

Here, \(\) is a Bayes-consistent surrogate loss for the multi-class zero-one loss over the augmented label set \(}\). In particular, \(\) can be chosen as a comp-sum loss (Mao et al., 2023), for example, the generalized cross entropy loss (see Section 4.1). As shown by Mao et al. (2024), \(_{}\) benefits from \(\)-consistency bounds, which implies its Bayes-consistency.

## 4 Novel surrogate losses

In this section, we introduce a new family of surrogate losses for L2D that benefit from Bayes-consistency, realizable \(\)-consistency and \(\)-consistency bounds, starting from first principles.

### Derivation from first principles

Observe that for any \((x,y)\), we have \(1_{(x)=n+1}=1_{(x) y}1_{(x)=n+1}\), since \((x)=n+1\) implies \((x) y\). Thus, using additionally \(1_{(x)[n]}=1_{(x) n+1}\), the deferral loss can be rewritten as follows for all \((x,y)\):

\[_{}(h,x,y) =1_{(x) y}1_{(x)[n]}+c(x,y)1_{(x)=n+1}\] \[=1_{(x) y}1_{(x) n+1}+c(x,y)1_{ (x) y}1_{(x)=n+1}\] \[=1_{(x) y}1_{(x) n+1}+c(x,y)1_{ (x) y}(1-1_{(x) n+1})\] \[=c(x,y)1_{(x) y}+(1-c(x,y))1_{(x) y (x) n+1}.\] (2)

Next, we will derive the new surrogate losses for L2D by replacing the indicator functions in (2) with smooth loss functions. The first indicator function \(1_{(x) y}\) is just the multi-class zero-one loss. Thus, a natural choice is to replace it with a surrogate loss in standard multi-class classification. We will specifically consider the family of comp-sum losses (Mao et al., 2023), defined as follows for any \((h,x,y)\):

\[_{}(h,x,y)=\!(}{_{y^{} }e^{h(x,y^{})}})\!,\]

where \(_{}\{+\}\) is a non-increasing function. For example, by taking \((t)=-(t)\), \((1-t^{q})\) with \(q(0,1)\), \(1-t\), we obtain the _logistic loss_(Verhulst, 1838, 1845; Berkson, 1944,1951], the _generalized cross entropy loss_[Zhang and Sabuncu, 2018], and the _mean absolute error loss_[Ghosh et al., 2017], respectively:

\[_{}(h,x,y)=- \![}{_{y^{}}e^{h(x,y^{}) }}]\] \[_{}(h,x,y)= \![1-[}{_{y^{}}e ^{h(x,y^{})}}]^{q}]\] \[_{}(h,x,y)= 1-}{_{y^{}}e^{h(x,y^{})}}.\]

For any \((h,x,y)}\), the confidence margin \(_{h}(x,y)\) is defined by \(_{h}(x,y)=h(x,y)-_{y^{},y^{} y}h(x,y^{ })\). Thus, the second indicator function \(1_{(x) y h(x) n+1}\) can be expressed as follows in terms of the confidence margin:

\[1_{(x) y h(x) n+1} =1_{(h(x,y)_{y^{},y^{}  y}h(x,y^{}))(h(x,n+1)_{y^{} ,y^{} n+1}h(x,y^{}))}\] \[=1_{(_{h}(x,y) 0)(_{h}(x,n+1) 0)}\] \[=1_{(_{h}(x,y),_{h}(x,n+1)) 0}.\]

Note that the first indicator function can also be written in terms of margin: \(1_{(x) y}=1_{_{h}(x,y) 0}\). Unlike the first indicator function, which presses \(h(x,y)\) to be the largest score among \(\), that is the margin \(_{h}(x,y)\) to be positive, the second indicator function only enforces \(h(x,y)\) or \(h(x,n+1)\) to be the largest score among \(}\), that is the maximum of two margins, \(\{_{h}(x,y),_{h}(x,n+1)\}\), to be positive. This condition can be further strengthened by requiring the sum of two margins, \(_{h}(x,y)+_{h}(x,n+1)\), to be positive. In view of this observation, we adopt the following modified comp-sum surrogate loss for the second indicator function:

\[_{}(h,x,y)=\!(+e^{h(x,n+ 1)}}{_{y^{}}e^{h(x,y^{})}})\!,\]

where \(_{+}\{+\}\) is a non-increasing function. In other words, \(_{}\) replaces the term \(e^{h(x,y)}\) in the softmax function in \(_{}\) with the sum \(e^{h(x,y)}+e^{h(x,n+1)}\). The effect is to encourage the sum of the two margins, \(_{h}(x,y)+_{h}(x,n+1)\), to be positive, rather than just the single margin \(_{h}(x,y)\). Following this principle, we derive the following expression for a new family of surrogate losses, \(_{}\), dubbed _realizable L2D_:

\[_{}(h,x,y)=c(x,y)_{}(h,x,y)+(1-c(x,y)) _{}(h,x,y).\] (3)

For the choices of \((t)=-(t)\), \((1-t^{q})\) with \(q(0,1)\) and \(1-t\), we obtain the new surrogate losses for L2D in Table 1. In the next sections, we will prove both realizable \(\)-consistency guarantees and \(\)-consistency bounds for this family of surrogate losses, which imply their excess error bounds and Bayes-consistency as well.

### Realizable \(\)-consistency

Here, we show that \(_{}\) is realizable \(\)-consistent with respect to \(_{}\). We say that a hypothesis set \(\) is _closed under scaling_ if, \(h h\) for any \(\).

   \((t)\) & \(_{}\) \\  \(-(t)\) & \(-c(x,y)\![}{_{y^{}}e^{h(x,y^{ })}}]-(1-c(x,y))\![+e^{h(x,n+1)}}{_{y^{ }}e^{h(x,y^{})}}]\) \\ \((1-t^{q})\) & \(\![1-[}{_{y^{} }e^{h(x,y^{})}}]^{q}]\!+\! [1-[+e^{h(x,n+1)}}{_{y^{}} e^{h(x,y^{})}}]^{q}]\!\) \\ \(1-t\) & \(c(x,y)\!(1-}{_{y^{}}e^{h(x,y^{ })}})+(1-c(x,y))\!(1-+e^{h(x,n+1)}}{_{y^{ }}e^{h(x,y^{})}})\) \\   

Table 1: A new family of surrogate losses \(_{}\) for L2D.

**Theorem 4.1**.: _Assume that \(\) is closed under scaling. Suppose that \(\) is non-increasing, \(>0\) and \(_{t 1}(t)=0\). Then, the surrogate loss \(_{}\) is realizable \(\)-consistent with respect to \(_{}\)._

The proof, detailed in Appendix A, begins by establishing an upper bound on the deferral loss in terms of the comp-sum loss: \(_{}_{}}{ }\). Letting \(\) be the minimizer of \(_{}\) and \(\) be any real number, we then show that \(_{_{}}() {2}{3}}_{_{}}( h^{*})\). The generalization error is then split by conditioning on whether \(h^{*}(x)\) is the deferral class \((n+1)\) or not. Finally, we demonstrate that each conditional term converges to zero as \(\) tends to \(+\), and apply the monotone convergence theorem to complete the proof.

### \(\)-Consistency bounds

Here, we show that \(_{}\) admits an \(\)-consistency bound with respect to \(_{}\), which implies its Bayes-consistency as well. We say that a hypothesis set is symmetric if there exists a family \(\) of functions \(f\) mapping from \(\) to \(\) such that \(\{[h(x,1),,h(x,n+1)] h\}=\{[f_{1}(x),,f_{n+1} (x)] f_{1},,f_{n+1}\}\), for any \(x\). We say that a hypothesis set \(\) is complete if for any \((x,y)\), the set of scores generated by it spans across the real numbers: \(\{h(x,y) h\}=\). Common neural network and linear function hypothesis sets are all symmetric and complete. We first consider the case where the cost is expert's classification error.

**Theorem 4.2**.: _Assume that \(\) is symmetric and complete and that \(c(x,y)=1_{(x)u_{y}}\). Then, for all \(h\) and any distribution, the following \(\)-consistency bound holds:_

\[_{_{}}(h)-_{_{}}()+_{_{}}() (_{_{}}(h)-_{_{ }}()+_{_{}}( )),\]

_where \((t)=\) when \((t)=-(t)\) and \((t)=t}\) when \((t)=(1-t^{q})\) with \(q(0,1)\)._

The proof, detailed in Appendix B.3 and B.4, establishes strong consistency guarantees for our new surrogate loss \(_{}\) (Theorem 4.2). We first introduce \(y_{}=*{argmax}_{y}p(x,y)\), the label with the highest conditional probability. We then show that for any hypothesis \(h\) and input \(x\), if \(y_{}\) is not the predicted label \(h_{}\), the conditional error of \(h\) is lower bounded by a modified hypothesis \(\) (obtained by swapping the scores of \(y_{}\) and \(h_{}\)). Next, for hypotheses where \(y_{}=h_{}\), we lower bound their conditional regret in terms of the conditional regret of the deferral loss using a new hypothesis \(h_{}\). This proof is novel and significantly different from existing approaches for establishing \(\)-consistency bounds in either the standard or deferral settings (Mao et al., 2023, 2024a).

The next result further shows that when \((t)=1-t\), our surrogate losses benefit from \(\)-consistency bounds for any general cost function.

**Theorem 4.3**.: _Assume that \(\) is symmetric and complete. Suppose that \((t)=1-t\). Then, for all \(h\) and any distribution, the following \(\)-consistency bounds hold:_

\[_{_{}}(h)-_{_{}}()+_{_{}}()(n+1)( _{_{}}(h)-_{_{}}()+_{_{}}()).\]

The proof is included in Appendix B.2. Theorem 4.2 provides stronger consistency guarantees for our new surrogate loss \(_{}\) with \((t)=1-t\) since it holds for any general cost function. The proof idea is similar to that of Theorem 4.2, albeit with more cases to analyze due to the general cost function. This occurs when lower bounding the conditional regret of a hypothesis \(h\), which satisfies \(y_{}=h_{}\), in terms of the conditional regret of the deferral loss by introducing a new hypothesis \(h_{}\). The additional cases necessitate a more stringent condition for the guarantee, such that the functions \((t)=-(t)\) and \((t)=(1-t^{q})\) do not apply.

### Excess error bounds and Bayes-consistency

For the family of all measurable functions \(=_{}\), the minimizability gaps vanish. In this case, Theorems 4.2 and 4.3 imply the following excess error bounds and Bayes-consistency guarantees.

**Corollary 4.4**.: _Suppose that \(c(x,y)=1_{(x)u_{y}}\). For all \(h_{}\) and any distribution, the following excess error bounds hold:_

\[_{_{}}(h)-_{_{}}(_{})(_{_{}}(h)-_{_{}}(_{})),\]_where \((t)=\) when \((t)=-(t)\) and \((t)=t}\) when \((t)=(1-t^{q})\) with \(q(0,1)\). Furthermore, the surrogate loss \(_{}\) is Bayes-consistent with respect to \(_{}\) in these cases._

**Corollary 4.5**.: _Suppose that \((t)=1-t\). For all \(h_{}\) and any distribution, the following excess error bounds hold:_

\[_{_{}}(h)-_{_{}}(_{})(n+1)(_{_{}}(h)-_{_{}}(_{})).\]

_Furthermore, the surrogate loss \(_{}\) is Bayes-consistent with respect to \(_{}\) in this case._

Therefore, Theorem 4.1 and Corollary 4.4 show that \(_{}\) is both realizable \(\)-consistent and Bayes-consistent with respect to \(_{}\). This solves the open problem raised by Mozannar et al. (2023).

In particular, for cost functions based on classification error, \(c(x,y)=1_{(x) y}\), our surrogate loss \(_{}\) with \((t)=-(t)\) coincides with the surrogate loss \(_{}\) in (Mozannar et al., 2023), modulo a constant. This affirmatively answers the question of whether their surrogate loss is Bayes-consistent when \(c(x,y)=1_{(x) y}\). However, their surrogate loss cannot be shown to be Bayes-consistent for a general cost function. In contrast, our surrogate losses \(_{}\) with \((t)=1-t\) are adaptable to general cost functions and benefit from both \(\)-consistency bounds and realizable \(\)-consistency guarantees. We also provide a more general family of comp-sum loss functions with \((t)=(1-t^{q})\) that benefit from both \(\)-consistency bounds and realizable \(\)-consistency when \(c(x,y)=1_{(x) y}\).

### Summary

Here, we summarize the consistency properties of existing surrogate losses and ours. As mentioned earlier, most surrogate losses proposed in previous work, except for \(_{}\), are analyzed under the condition \(c(x,y)=1_{(x) y}\). This naturally leads to a summary of these surrogate losses in this context, as presented in Table 1. Additionally, we provide analyses and the consistency properties of our surrogate loss, \(_{}\), with general cost functions.

More specifically, our surrogate losses \(_{}\) satisfying Theorem 4.1 perform better in realizable scenarios than the surrogate losses \(_{}\), \(_{}\), and \(_{}\) from prior work, as ours are realizable \(\)-consistent while theirs are not. This will be illustrated by our experiment results in the realizable case (Figure 0(a)). Our surrogate losses \(_{}\) satisfying Theorem 4.2 and Corollary 4.4 are comparable to the surrogate losses in prior work in non-realizable scenarios when the cost is the expert's classification error, as all of them are Bayes-consistent and supported by H-consistency bounds. This is demonstrated by our experiment in the non-realizable case with the cost function being the expert's classification error (Table 3). Our surrogate losses \(_{}\) satisfying Theorem 4.3 and Corollary 4.5 are superior to the surrogate loss \(_{}\) in non-realizable scenarios with general cost functions, as ours are supported by H-consistency bounds and Bayes-consistency while theirs are not. This is evidenced by our experiment in the non-realizable case with general cost functions (Figure 0(b)).

5 Relationship between \(\)-consistency bounds and realizable \(\)-consistency

Here, we discuss the relationship between \(\)-consistency bounds and realizable \(\)-consistency. First, realizable \(\)-consistency does not imply \(\)-consistency bounds, since \(\)-consistency bounds require that the relationship holds for all distributions, not just realizable ones. Moreover, \(\)-consistency bounds provide non-asymptotic guarantees, while realizable \(\)-consistency provides only asymptotic guarantees. Second, \(\)-consistency bounds imply realizable \(\)-consistency in the standard multi-class classification setting. This is because minimizability gaps vanish under the realizable assumption in standard case. In particular, for comp-sum losses, the following holds (see Appendix C for proof).

  Surrogate losses & Realizable H-consistency & Bayes-consistency & H-consistency bounds \\  \(_{}\) & no & yes & yes \\ \(_{}\) & no & yes & yes \\ \(_{}\) & no & yes & yes \\ \(_{}\) (\(_{}\) with \((t)=-(t)\)) & yes & yes (proved by us) & yes (proved by us) \\ \(_{}\) with \((t)=(1-t^{q}),q(0,1)\) & yes & yes & yes \\ \(_{}\) with \((t)=1-t\) & yes & yes & yes \\  

Table 2: Consistency properties of existing surrogate losses and ours in the case of \(c(x,y)=1_{(x) y}\).

**Theorem 5.1**.: _Assume that there exists a zero error solution \(h^{*}\) with \(_{_{0-1}}(h^{*})=0\) and \(\) is closed under scaling. Assume that \(_{t 1}(t)=0\). Then, the minimizability gap of comp-sum loss \(_{}\) vanishes: \(_{_{}}()=0\)._

However, in the deferral setting, this relationship no longer holds: \(\)-consistency bounds cannot imply realizable \(\)-consistency. In particular, Mao et al. (2023) showed that \(_{}\) benefits from \(\)-consistency bounds, while Mozannar et al. (2023) showed that it is not realizable \(\)-consistent. The loss function in (Madras et al., 2018) is not Bayes-consistent, and thus does not have \(\)-consistency bound guarantees, but is actually realizable \(\)-consistent (Mozannar et al., 2023).

## 6 Experiments

In this section, we empirically evaluate our proposed surrogate losses and compare them with existing baselines.

**Experimental settings.** We follow the setting of Mozannar et al. (2023) and conduct experiments on a synthetic dataset: Mixture-of-Gaussians (Mozannar et al., 2023), and three real-world datasets: CIFAR-10H (Battleday et al., 2020), HateSpeech (Davidson et al., 2017), and COMPASS (Dressel and Farid, 2018). For these three datasets, we adopt the same model class as that in (Mozannar et al., 2023, Table 1). Each dataset is randomly split into 70%, 10%, and 20% for training, validation, and testing, respectively. For the Mixture-of-Gaussians, we adopt the exact realizable setting from (Mozannar et al., 2023, Section 7.2), which is realizable by linear functions: there exists a linear hypothesis \(h^{*}\) achieving zero deferral loss, \(_{_{}}(h^{*})=0\).

As with (Mozannar et al., 2023), we choose the cost function to be the expert's classification error: \(c(x,y)=1_{(x)ay}\). We compare our surrogate to four baselines as described in Section 3.3: the cross-entropy surrogate \(_{}\) from (Mozannar and Sontag, 2020), the one-vs-all surrogate \(_{}\) from (Mozannar and Sontag, 2020), the realizable surrogate \(_{}\) from (Mozannar et al., 2023), and the general surrogate \(_{}\) from (Mao et al., 2024). For \(_{}\), we choose \(\) as the logistic loss, following (Verma and Nalisnick, 2022). For \(_{}\), we choose \(\) as the generalized cross entropy loss with \(q=0.7\), following (Mao et al., 2024). For our Realizable L2D surrogate \(_{}\), we consider two choices: \(\) as the generalized cross entropy loss with \(q=0.7\), following (Zhang and Sabuncu, 2018; Mao et al., 2024), and \(\) as the mean absolute error loss (\(q=1\)). Among these, \(_{}\), \(_{}\) and \(_{}\) are Bayes-consistent but not realizable \(\)-consistent; \(_{}\), \(_{}\) with \(q=0.7\) and \(_{}\) with \(q=1\) are both Bayes-consistent and realizable \(\)-consistent, as shown in Sections 4.2 and 4.4. Note that in this case, \(_{}\) is a special case of \(_{}\) when \(\) is chosen as \(t-(t)\). We use the same optimizer, learning rate, and number of epochs as chosen in (Mozannar et al., 2023), and we select the model that achieves the highest _system accuracy_, that is average \([1-_{}(h,x,y)]\), on a validation set.

 Method & Dataset & System Accuracy & Accepted Accuracy & Coverage \\  Mozannar and Sontag (2020) (\(_{}\)) & & \(91.60 0.15\) & \(94.61 0.67\) & \(44.55 1.68\) \\ Verma and Nalisnick (2022) (\(_{}\)) & & \(92.18 0.10\) & \(95.43 0.36\) & \(58.56 3.18\) \\ Mazannar et al. (2023) (\(_{}\)) & & \(91.83 0.63\) & \(95.37 0.72\) & \(54.78 3.70\) \\ Mao et al. (2024) (\(_{}\)) & HateSpeech & \(92.05 0.04\) & \(96.28 0.35\) & \(46.74 2.80\) \\ Realizable L2D (\(_{},q=0.7\)) & & \(92.20 0.54\) & \(96.06 0.39\) & \(57.85 0.76\) \\ Realizable L2D (\(_{},q=1\)) & & \(91.97 0.29\) & \(96.57 0.69\) & \(53.25 2.49\) \\  Mozannar and Sontag (2020) (\(_{}\)) & & \(66.33 0.47\) & \(73.65 1.83\) & \(55.17 9.51\) \\ Verma and Nalisnick (2022) (\(_{}\)) & & \(66.33 1.31\) & \(71.03 5.10\) & \(53.33 4.73\) \\ Mozannar et al. (2023) (\(_{}\)) & & \(66.00 2.27\) & \(63.20 4.23\) & \(69.50 10.8\) \\ Mao et al. (2024) (\(_{}\)) & & \(66.67 0.62\) & \(76.25 2.42\) & \(48.33 5.31\) \\ Realizable L2D (\(_{},q=0.7\)) & & \(66.17 0.21\) & \(69.33 0.30\) & \(55.67 5.95\) \\ Realizable L2D (\(_{},q=1\)) & & \(66.83 0.85\) & \(69.02 2.42\) & \(54.83 0.62\) \\  Mozannar and Sontag (2020) (\(_{}\)) & & \(96.27 0.51\) & \(98.77 0.71\) & \(64.33 6.13\) \\ Verma and Nalisnick (2022) (\(_{}\)) & & \(96.25 0.45\) & \(98.74 0.54\) & \(67.88 6.16\) \\ Mozannar et al. (2023) (\(_{}\)) & & \(96.63 0.18\) & \(98.23 0.78\) & \(66.63 1.80\) \\ Mao et al. (2024) (\(_{}\)) & & \(96.75 0.55\) & \(98.65 0.80\) & \(65.68 3.36\) \\ Realizable L2D (\(_{},q=0.7\)) & & \(96.80 0.25\) & \(98.37 0.20\) & \(76.77 3.63\) \\ Realizable L2D (\(_{},q=1\)) & & \(96.57 0.05\) & \(98.34 0.24\) & \(77.37 2.43\) \\  

Table 3: Comparison of system accuracy, accepted accuracy and coverage; mean \(\) standard deviation over three runs. Realizable L2D outperforms or is comparable to baselines in all the settings.

**Evaluation.** For the three real-world datasets, we report the _system accuracy_, that is average value of \([1-_{}(h,x,y)]\) on the test data. For completeness, we also include the _accepted accuracy_, that is the average value of \([1_{(x) y}1_{(x)[n]}]\). This metric considers only incorrect predictions (\((x) y\)) and measures the fraction of those where the system's output (\((x)\)) falls within the valid range of possible outputs (\([n]\)). We also report the _coverage_, that is the average value of \([1_{(x)[n]}]\) on the test set, or the fraction of test instances where the system's prediction falls within the valid range (\([n]\)). For each metric, we average results over three runs and report the mean accuracy along with the standard deviation for both our proposed methods and the baseline approaches. For the realizable Mixture-of-Gaussians, we plot the system accuracy of various methods on a held-out test dataset consisting of 5,000 points as we increase the size of the training data.

**Results.** Table 3 shows that for the real-world datasets, \(_{}\) with \(q=0.7\), and \(_{}\) with \(q=1\) either outperform or are comparable to the best baseline in terms of system accuracy on each dataset. This performance is supported by our \(\)-consistency bounds and Bayes-consistency results for our Realizable L2D surrogate with respect to the deferral loss \(_{}\), as shown in Sections 4.3 and 4.4. Table 3 also shows that \(_{}\) achieves reasonable coverage and acceptable accuracy. The system accuracy, coverage, and standard deviations of the baselines match those in (Mozannar et al., 2023). Moreover, \(_{}\), \(_{}\) with \(q=0.7\), and \(_{}\) with \(q=1\) perform differently across various datasets: \(_{}\) with \(q=0.7\) outperforms the others on HateSpeech and CIFAR-10H, while \(_{}\) with \(q=1\) outperforms the others on COMPASS. Note that in this case, \(_{}\) is a special case of \(_{}\) when \(\) is chosen as \(t-(t)\). These results show that Realizable L2D can benefit from the flexibility in the choice of \(\).

Figure 0(a) shows system accuracy versus training samples on the realizable Mixture-of-Gaussians distribution. Our surrogate loss \(_{}\) with \(q=0.7\) and \(q=1\) are realizable \(\)-consistent, while \(_{}\), \(_{}\) and \(_{}\) are not. This verifies our theory.

Figure 0(b) shows system accuracy versus coverage on the HateSpeech dataset by varying \(\) in the general cost functions \(c(x,y)=1_{(x) y}+\). As \(\) increases, deferral algorithms yield solutions with higher coverage and decreased system accuracy. This is because \(\) controls the trade-off between expert's inference cost and accuracy. \(_{}\) with \(q=1\) performs comparably to the surrogate loss \(_{}\), as both are supported by \(\)-consistency bounds and Bayes-consistency with general cost functions. Our surrogate loss \(_{}\) with \(q=1\) outperforms \(_{}\) because the latter does not benefit from Bayes-consistency with general cost functions.

## 7 Conclusion

We introduced a broad family of surrogate losses and algorithms for learning to defer, parameterized by a non-increasing function. We established their realizable \(\)-consistency properties under mild conditions and proved that several of these surrogate losses benefit from \(\)-consistency bounds for cost functions based on classification error and general cost functions, which also imply their Bayes-consistency. This research not only resolves an open question posed in previous work but also lays the groundwork for comparing various consistency notions in learning to defer and standard classification. Looking forward, our approach offers a promising avenue for analyzing multi-expert and two-stage settings.

Figure 1: Results for the realizable case and the non-realizable case with general cost functions.