# Robust Guided Diffusion for Offline Black-box Optimization

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Offline black-box optimization aims to maximize a black-box function using an offline dataset of designs and their measured properties. Two main approaches have emerged: the forward approach, which learns a mapping from input to its value, thereby acting as a proxy to guide optimization, and the inverse approach, which learns a mapping from value to input for conditional generation. (a) Although proxy-free (classifier-free) diffusion shows promise in robustly modeling the inverse mapping, it lacks explicit guidance from proxies, essential for generating high-performance samples beyond the training distribution. Therefore, we propose _proxy-enhanced sampling_ which utilizes the explicit guidance from a trained proxy to bolster proxy-free diffusion with enhanced sampling control. (b) Yet, the trained proxy is susceptible to out-of-distribution issues. To address this, we devise the module _diffusion-based proxy refinement_, which seamlessly integrates insights from proxy-free diffusion back into the proxy for refinement. To sum up, we propose _Robust **G**uided **D**iffusion for Offline Black-box **O**ptimization (**RGD**), combining the advantages of proxy (explicit guidance) and proxy-free diffusion (robustness) for effective conditional generation. RGD achieves state-of-the-art results on various design-bench tasks, underscoring its efficacy. Our code is here.

## 1 Introduction

Creating new objects to optimize specific properties is a ubiquitous challenge that spans a multitude of fields, including material science, robotic design, and genetic engineering. Traditional methods generally require interaction with a black-box function to generate new designs, a process that could be financially burdensome and potentially perilous [1; 2]. Addressing this, recent research endeavors have pivoted toward a more relevant and practical context, termed offline black-box optimization (BBO) [3; 4]. In this context, the goal is to maximize a black-box function exclusively utilizing an offline dataset of designs and their measured properties.

There are two main approaches for this task: the forward approach and the reverse approach. The forward approach entails training a deep neural network (DNN), parameterized as \(_{}()\), using the offline dataset. Once trained, the DNN acts as a proxy and provides explicit gradient guidance to enhance existing designs. However, this technique is susceptible to the out-of-distribution (OOD) issue, leading to potential overestimation of unseen designs and resulting in adversarial solutions .

The reverse approach aims to learn a mapping from property value to input. Inputing a high value into this mapping directly yields a high-performance design. For example, MINs  adopts GAN  to model this inverse mapping, and demonstrate some success. Recent works  have applied proxy-free diffusion1, parameterized by \(\), to model this mapping, which proves its efficacy overother generative models. Proxy-free diffusion employs a score predictor \(}_{}(,,)\). This represents a linear combination of conditional and unconditional scores, modulated by a strength parameter \(\) to balance condition and diversity in the sampling process. This guidance significantly diverges from proxy (classifier) diffusion that interprets scores as classifier gradients and thus generates adversarial solutions. Such a distinction grants proxy-free diffusion its inherent robustness in generating samples.

Nevertheless, proxy-free diffusion, initially designed for in-distribution generation, such as synthesizing specific image categories, faces limitations in offline BBO. Particularly, it struggles to generate high-performance samples that exceed the training distribution due to the lack of explicit guidance2. Consider, for example, the optimization of a two-dimensional variable (\(x_{d1},x_{d2}\)) to maximize the negative Rosenbrock function : \(y(x_{d1},x_{d2})=-(1-x_{d1})^{2}-100(x_{d2}-x_{d1}^{2})^{2}\), as depicted in Figure 1. The objective is to steer the initial points (indicated in pink) towards the high-performance region (highlighted in yellow). While proxy-free diffusion can nudge the initial points closer to this high-performance region, the generated points (depicted in blue) fail to reach the high-performance region due to its lack of explicit proxy guidance.

To address this challenge, we introduce a _proxy-enhanced sampling_ module as illustrated in Figure 2(a). It incorporates the explicit guidance from the proxy \(_{}()\) into proxy-free diffusion to enable enhanced control over the sampling process. This module hinges on the strategic optimization of the strength parameter \(\) to achieve a better balance between condition and diversity, per reverse diffusion step. This incorporation not only preserves the inherent robustness of proxy-free diffusion but also leverages the explicit proxy guidance, thereby enhancing the overall conditional generation efficacy. As illustrated in Figure 1, samples (depicted in red) generated via _proxy-enhanced sampling_ are more effectively guided towards, and often reach, the high-performance area (in yellow).

Yet, the trained proxy is susceptible to out-of-distribution (OOD) issues. To address this, we devise a module _diffusion-based proxy refinement_ as detailed in Figure 2(b). This module seamlessly integrates insights from proxy-free diffusion into the proxy \(_{}()\) for refinement. Specifically, we generate a diffusion distribution \(p_{}(y|})\) on adversarial samples \(}\), using the associated probability flow ODE 3. This distribution is derived independently of a proxy, thereby exhibiting greater robustness than the proxy distribution on adversarial samples. Subsequently, we calculate the Kullback-Leibler divergence between the two distributions on adversarial samples, and use this divergence minimization as a regularization strategy to fortify the proxy's robustness and reliability.

To sum up, we propose _Robust Guided Diffusion for Offline Black-box Optimization_ (**RGD**), a novel framework that combines the advantages of proxy (explicit guidance) and proxy-free diffusion (robustness) for effective conditional generation. Our contributions are three-fold:

* We propose a _proxy-enhanced sampling_ module which incorporates proxy guidance into proxy-free diffusion to enable enhanced sampling control.
* We further develop _diffusion-based proxy refinement_ which integrates insights from proxy-free diffusion back into the proxy for refinement.
* RGD delivers state-of-the-art performance on various design-bench tasks, emphasizing its efficacy.

Figure 1: Motivation of explicit proxy guidance.

Figure 2: Overall of RGD.

## 2 Preliminaries

### Offline Black-box Optimization

Offline black-box optimization (BBO) aims to maximize a black-box function with an offline dataset. Imagine a design space as \(=^{d}\), where \(d\) is the design dimension. The offline BBO  is:

\[^{*}=_{}J().\] (1)

In this equation, \(J()\) is the unknown objective function, and \(\) is a possible design. In this context, there is an offline dataset, \(\), that consists of pairs of designs and their measured properties. Specifically, each \(\) denotes a particular design, like the size of a robot, while \(y\) indicates its related metric, such as its speed.

A common approach _gradient ascent_ fits a proxy distribution \(p_{}(y|)=(J_{}(),_{}( ))\) to the offline dataset where \(\) denote the proxy parameters:

\[&_{}_{(,y) }[- p_{}(y|)].\\ &=_{}_{(,y)}( _{}())+}())^{2}}{2 _{}^{2}()}.\] (2)

For the sake of consistency with terminology used in the forthcoming subsection on guided diffusion, we will refer to \(p_{}(|)\) as the proxy distribution and \(J_{}()\) as the proxy. Subsequently, this approach performs gradient ascent with \(J_{}()\), leading to high-performance designs \(^{*}\):

\[_{+1}=_{}+_{}J_{}()|_{=_{}},[0,-1],\] (3)

converging to \(_{}\) after \(\) steps. However, this method suffers from the out-of-distribution issue where the proxy predicts values that are notably higher than the actual values.

### Diffusion Models

Diffusion models, a type of latent variable models, progressively introduce Gaussian noise to data in the forward process, while the reverse process aims to iteratively remove this noise through a learned score estimator. In this work, we utilize continuous time diffusion models governed by a stochastic differential equation (SDE), as presented in . The forward SDE is formulated as:

\[d=(,t)dt+g(t)d.\] (4)

where \((,t):^{d}^{d}\) represents the drift coefficient, \(g():\) denotes the diffusion coefficient and \(\) is the standard Wiener process. This SDE transforms data distribution into noise distribution. The reverse SDE is:

\[d=[(,t)-g(t)^{2}_{} p()]dt +g(t)d},\] (5)

with \(_{} p()\) representing the score of the marginal distribution at time \(t\), and \(}\) symbolizing the reverse Wiener process. The score function \(_{} p()\) is estimated using a time-dependent neural network \(}(_{t},t)\), enabling us to transform noise into samples. For simplicity, we will use \(}(_{t})\), implicitly including the time dependency \(t\).

### Guided Diffusion

Guided diffusion seeks to produce samples with specific desirable attributes, falling into two categories: _proxy diffusion_ and _proxy-free diffusion_. While these were initially termed _classifier diffusion_ and _classifier-free diffusion_ in classification tasks, we have renamed them to _proxy diffusion_ and _proxy-free diffusion_, respectively, to generalize to our regression context. Proxy diffusion combines the model's score estimate with the gradient from the proxy distribution, providing explicit guidance. However, it can be interpreted as a gradient-based adversarial attack.

Proxy-free guidance, not dependent on proxy gradients, enjoys an inherent robustness of the sampling process. Particularly, it models the score as a linear combination of an unconditional and a conditional score. A unified neural network \(}(_{t},y)\) parameterizes both score types. The score \(}(_{t},y)\)approximates the gradient of the log probability \(_{_{t}} p(_{t}|y)\), i.e., the conditional score, while \(_{}(_{t})\) estimates the gradient of the log probability \(_{_{t}} p(_{t})\), i.e., the unconditional score. The score function follows:

\[}_{}(_{t},y,)=(1+)_{}(_ {t},y)-_{}(_{t}).\] (6)

Within this context, the strength parameter \(\) specifies the generation's adherence to the condition \(y\), which is set to the maximum value \(y_{max}\) in the offline dataset following . Optimization of \(\) balances the condition and diversity. Lower \(\) values increase sample diversity at the expense of conformity to \(y\), and higher values do the opposite.

## 3 Method

In this section, we present our method RGD, melding the strengths of proxy and proxy-free diffusion for effective conditional generation. Firstly, we describe a newly developed module termed _proxy-enhanced sampling_. It integrates explicit proxy guidance into proxy-free diffusion to enable enhanced sampling control, as detailed in Section 3.1. Subsequently, we explore _diffusion-based proxy refinement_ which incorporates insights gleaned from proxy-free diffusion back into the proxy, further elaborated in Section 3.2. The overall algorithm is shown in Algorithm 1.

```
0: offline dataset \(\), # of diffusion steps \(T\).
1: Train proxy distribution \(p_{}(y|)\) on \(\) by Eq. (2).
2: Train proxy-free diffusion model \(_{}(_{t},y)\) on \(\).
3:/*Diffusion-based proxy refinement*/
4: Identify adversarial samples via grad ascent.
5: Compute diffusion distribution \(p_{}(y|})\) by Eq. (12).
6: Compute KL divergence loss as per Eq. (13).
7: Refine proxy distribution \(p_{}(y|)\) through Eq. (15).
8:/*Proxy-enhanced sampling*/
9: Begin with \(_{T}(,)\)
10:for\(t=T-1\) to \(0\)do
11: Derive the score \(}_{}(_{t+1},y,)\) from Eq. (6).
12: Update \(_{t+1}\) to \(_{t}()\) using \(\) as per Eq. (7).
13: Optimize \(\) to \(\) following Eq. (8).
14: Finalize the update of \(_{t}\) with \(\) via Eq. (9).
15:endfor
16: Return \(^{*}=_{0}\) ```

**Algorithm 1** Robust Guided Diffusion for Offline BBO

### Proxy-enhanced Sampling

As discussed in Section 2.3, proxy-free diffusion trains an unconditional model and conditional models. Although proxy-free diffusion can generate samples aligned with most conditions, it traditionally lacks control due to the absence of an explicit proxy. This is particularly significant in offline BBO where we aim to obtain samples beyond the training distribution. Therefore, we require explicit proxy guidance to achieve enhanced sampling control. This module is outlined in Algorithm 1, Line \(8\)- Line \(16\).

**Optimization of \(\).** Directly updating the design \(_{t}\) with proxy gradient suffers from the OOD issue and determining a proper condition \(y\) necessitates the manual adjustment of multiple hyperparameters . Thus, we propose to introduce proxy guidance by only optimizing the strength parameter \(\) within \(}_{}(_{t},y,)\) in Eq. (6). As discussed in Section 2.3, the parameter \(\) balances the condition and diversity, and an optimized \(\) could achieve a better balance in the sampling process, leading to more effective generation.

**Enhanced Sampling.** With the score function, the update of a noisy sample \(_{t+1}\) is computed as:

\[_{t}()=solver(_{t+1},}_{}(_{t+1},y, )),\] (7)

where the _solver_ is the second-order Heun solver , chosen for its enhanced accuracy through a predictor-corrector method. A proxy is then trained to predict the property of noise \(_{t}\) at time step \(t\), denoted as \(J_{}(_{t},t)\). By maximizing \(J_{}(_{t}(),t)\) with respect to \(\), we can incorporate the explicit proxy guidance into proxy-free diffusion to enable enhanced sampling control in the balance between condition and diversity. This maximization process is:

\[=+}(_{t}(),t)}{ }.\] (8)

where \(\) denotes the learning rate. We leverage the automatic differentiation capabilities of PyTorch  to efficiently compute the above derivatives within the context of the solver's operation. The optimized \(\) then updates the noisy sample \(_{t+1}\) through:

\[_{t}=solver(_{t+1},}_{}(_{t+1},y,)).\] (9)This process iteratively denoises \(_{t}\), utilizing it in successive steps to progressively approach \(_{0}\), which represents the final high-scoring design \(^{*}\).

**Proxy Training.** Notably, \(J_{}(_{t},t)\) can be directly derived from the proxy \(J_{}()\), the mean of the proxy distribution \(p_{}(|)\) in Eq. (2). This distribution is trained exclusively at the initial time step \(t=0\), eliminating the need for training across time steps. To achieve this derivation, we reverse the diffusion from \(_{t}\) back to \(_{0}\) using the formula:

\[_{0}=_{t}+s_{}(_{t})(t)^{2}}{ (t)},\] (10)

where \(s_{}(_{t})\) is the estimated unconditional score at time step \(t\), and \((t)^{2}\) and \((t)\) are the variance and mean functions of the perturbation kernel at time \(t\), as detailed in equations (32-33) in . Consequently, we express

\[J_{}(_{t},t)=J_{}(_{t}+s_{}(_{t})(t)^{2}}{(t)}).\] (11)

This formulation allows for the optimization of the strength parameter \(\) via Eq. (8). For simplicity, we will refer to \(J_{}()\) in subsequent discussions.

### Diffusion-based Proxy Refinement

In the _proxy-enhanced sampling_ module, the proxy \(J_{}()\) is employed to update the parameter \(\) to enable enhanced control. However, \(J_{}()\) may still be prone to the OOD issue, especially on adversarial samples . To address this, we refine the proxy by using insights from proxy-free diffusion. The procedure of this module is specified in Algorithm 1, Lines 3-7.

**Diffusion Distribution**. Adversarial samples are identified by gradient ascent on the proxy as per Eq. (3) to form the distribution \(q()\). Consequently, these samples are vulnerable to the proxy distribution. Conversely, the proxy-free diffusion, which functions without depending on a proxy, inherently offers greater resilience against these samples, thus producing a more robust distribution. For an adversarial sample \(} q()\), we compute \(p_{}(})\), \(p_{}(}|y)\) via the probability flow ODE, and \(p(y)\) through Gaussian kernel-density estimation. The diffusion distribution regarding \(y\) is derived as:

\[p_{}(y|})=}(}|y) p(y )}{p_{}(})},\] (12)

which demonstrates inherent robustness over the proxy distribution \(p_{}(y|})\). Yet, directly applying diffusion distribution to design optimization by gradient ascent is computationally intensive and potentially unstable due to the demands of reversing ODEs and scoring steps.

**Proxy Refinement.** We opt for a more feasible approach: refine the proxy distribution \(p_{}(y|})=(J_{}(}),_ {}(}))\) by minimizing its distance to the diffusion distribution \(p_{}(y|})\). The distance is quantified by the Kullback-Leibler (KL) divergence:

\[_{q}[(p_{}||p_{})]=_{q()} p_{}(y|})(}(y| })}{p_{}(y|})})dy.\] (13)

We avoid the parameterization trick for minimizing this divergence as it necessitates backpropagation through \(p_{}(y|})\), which is prohibitively expensive. Instead, for the sample \(}\), the gradient of the KL divergence \((p_{}||p_{})\) with respect to the proxy parameters \(\) is computed as:

\[_{p_{}(y|})}[}(y| })}{d}(1+}(y|})}{p_{ }(y|})})].\] (14)

Complete derivations are in Appendix A. The KL divergence then acts as regularization in our loss \(\):

\[(,)=_{}[- p_{}(y| )]+_{q()}[(p_{}||p_{})],\] (15)

where \(\) is the training dataset and \(\) is a hyperparameter. We propose to optimize \(\) based on the validation loss via bi-level optimization as detailed in Appendix B.

## 4 Experiments

In this section, we conduct comprehensive experiments to evaluate our method's performance.

### Benchmarks

**Tasks.** Our experiments encompass a variety of tasks, split into continuous and discrete categories.

The continuous category includes four tasks: **(1)** Superconductor (SuperC) 4: The objective here is to engineer a superconductor composed of \(86\) continuous elements. The goal is to enhance the critical temperature using \(17,010\) design samples. This task is based on the dataset from . **(2)** Ant Morphology (Ant): In this task, the focus is on developing a quadrupedal ant robot, comprising \(60\) continuous parts, to augment its crawling velocity. It uses \(10,004\) design instances from the dataset in [3; 14]. **(3)** D'Kitty Morphology (D'Kitty): Similar to Ant Morphology, this task involves the design of a quadrupedal D'Kitty robot with 56 components, aiming to improve its crawling speed with \(10,004\) designs, as described in [3; 15]. **(4)** Rosenbrock (Rosen): The aim of this task is to optimize a 60-dimension continuous vector to maximize the Rosenbrock black-box function. It uses \(50000\) designs from the low-scoring part .

For the discrete category, we explore three tasks: **(1)** TF Bind 8 (TF8): The goal is to identify an \(8\)-unit DNA sequence that maximizes binding activity. This task uses \(32,898\) designs and is detailed in . **(2)** TF Bind 10 (TF10): Similar to TF8, but with a \(10\)-unit DNA sequence and a larger pool of \(50,000\) samples, as described in . **(3)** Neural Architecture Search (NAS): This task focuses on discovering the optimal neural network architecture to improve test accuracy on the CIFAR-\(10\) dataset, using \(1,771\) designs .

**Evaluation.** In this study, we utilize the oracle evaluation from design-bench . Adhering to this established protocol, we analyze the top \(128\) promising designs from each method. The evaluation metric employed is the \(100^{th}\) percentile normalized ground-truth score, calculated using the formula \(y_{n}=}}{y_{}-y_{}}\), where \(y_{}\) and \(y_{}\) signify the lowest and highest scores respectively in the comprehensive, yet unobserved, dataset. In addition to these scores, we provide an overview of each method's effectiveness through the mean and median rankings across all evaluated tasks. Notably, the best design discovered in the offline dataset, designated as \(()\), is also included for reference. For further details on the \(50^{th}\) percentile (median) scores, please refer to Appendix C.

### Comparison Methods

Our approach is evaluated against two primary groups of baseline methods: forward and inverse approaches. Forward approaches enhance existing designs through gradient ascent. This includes: **(i)** Grad: utilizes simple gradient ascent on current designs for new creations; **(ii)** ROMA : implements smoothness regularization on proxies; **(iii)** COMs : applies regularization to assign lower scores to adversarial designs; **(iv)** NEMO : bridges the gap between proxy and actual functions using normalized maximum likelihood; **(v)** BDI : utilizes both forward and inverse mappings to transfer knowledge from offline datasets to the designs; **(vi)** IOM : ensures consistency between representations of training datasets and optimized designs.

Inverse approaches focus on learning a mapping from a design's property value back to its input. High property values are input into this inverse mapping to yield enhanced designs. This includes: **(i)** CbAS : CbAS employs a VAE model to implicitly implement the inverse mapping. It gradually tunes its distribution toward higher scores by raising the scoring threshold. This process can be interpreted as incrementally increasing the conditional score within the inverse mapping framework. **(ii)** Autofocused CbAS (Auto.CbAS) : adopts importance sampling for retraining a regression model based on CbAS. **(iii)** MIN : maps scores to designs via a GAN model and explore this mapping for optimal designs. **(iv)** BONET : introduces an autoregressive model for sampling high-scoring designs. **(v)** DDOM : utilizes proxy-free diffusion to model the inverse mapping.

Traditional methods as detailed in  are also considered: **(i)** CMA-ES : modifies the covariance matrix to progressively shift the distribution towards optimal designs; **(ii)** BO-qEI : implements Bayesian optimization to maximize the proxy and utilizes the quasi-Expected-Improvement acquisition function for design suggestion, labeling designs using the proxy; **(iii)** REINFORCE : enhances the input space distribution using the learned proxy model.

### Experimental Configuration

In alignment with the experimental protocols established in [3; 20], we have tailored our training methodologies for all approaches, except where specified otherwise. For methods such as BO-qEI, CMA-ES, REINFORCE, CbAS, and Auto.CbAS that do not utilize gradient ascent, we base our approach on the findings reported in . We adopted \(T=1000\) diffusion sampling steps, set the condition \(y\) to \(y_{max}\), and initial strength \(\) as \(2\) in line with . To ensure reliability and consistency in our comparative analysis, each experimental setting was replicated across \(8\) independent runs, unless stated otherwise, with the presentation of both mean values and standard errors. These experiments were conducted using a NVIDIA GeForce V\(100\) GPU. We've detailed the computational overhead of our approach in Appendix D to provide a comprehensive view of its practicality.

### Results and Analysis

In Tables 1 and 2, we showcase our experimental results for both continuous and discrete tasks. To clearly differentiate among the various approaches, distinct lines separate traditional, forward, and inverse approaches within the tables For every task, algorithms performing within a standard deviation of the highest score are emphasized by **bolding** following .

We make the following observations. (1) As highlighted in Table 2, RGD not only achieves the top rank but also demonstrates the best performance in six out of seven tasks, emphasizing the robustness and superiority of our method. (2) RGD outperforms the VAE-based CbAS, the GAN-based MIN

  Method & Superconductor & Ant Morphology & D’Kitty Morphology & Rosenbrock \\  \(()\) & \(0.399\) & \(0.565\) & \(0.884\) & \(0.518\) \\ BO-qEI & \(0.402 0.034\) & \(0.819 0.000\) & \(0.896 0.000\) & \(0.772 0.012\) \\ CMA-ES & \(0.465 0.024\) & \(\) & \(0.724 0.001\) & \(0.470 0.026\) \\ REINFORCE & \(0.481 0.013\) & \(0.266 0.032\) & \(0.562 0.196\) & \(0.558 0.013\) \\  Grad & \(0.490 0.009\) & \(0.932 0.015\) & \(0.930 0.002\) & \(0.701 0.092\) \\ COMs & \(\) & \(0.818 0.017\) & \(0.905 0.017\) & \(0.672 0.075\) \\ ROMA & \(\) & \(0.898 0.029\) & \(0.928 0.007\) & \(0.663 0.072\) \\ NEMO & \(0.499 0.003\) & \(0.956 0.013\) & \(\) & \(0.614 0.000\) \\ IOM & \(\) & \(0.929 0.037\) & \(0.936 0.008\) & \(0.712 0.068\) \\ BDI & \(\) & \(0.906 0.000\) & \(0.919 0.000\) & \(0.630 0.000\) \\  CbAS & \(\) & \(0.876 0.031\) & \(0.892 0.008\) & \(0.702 0.008\) \\ Auto.CbAS & \(0.421 0.045\) & \(0.882 0.045\) & \(0.906 0.006\) & \(0.721 0.007\) \\ MIN & \(0.499 0.017\) & \(0.445 0.080\) & \(0.892 0.011\) & \(0.702 0.074\) \\ BONET & \(0.422 0.019\) & \(0.925 0.010\) & \(0.941 0.001\) & \(0.780 0.009\) \\ DDMO & \(0.495 0.012\) & \(0.940 0.004\) & \(0.935 0.001\) & \(\) \\  _RGD_ & \(\) & \(\) & \(\) & \(\) \\  

Table 1: Results (maximum normalized score) on continuous tasks.

  Method & TF Band 8 & TF Band 10 & NAS & Rank Mean & Rank Median \\  \(()\) & \(0.439\) & \(0.467\) & \(0.436\) & & \\ BO-qEI & \(0.798 0.083\) & \(0.652 0.038\) & \(\) & \(9.1/15\) & \(11/15\) \\ CMA-ES & \(0.953 0.022\) & \(0.670 0.023\) & \(0.985 0.079\) & \(7.3/15\) & \(4/15\) \\ REINFORCE & \(0.948 0.028\) & \(0.663 0.034\) & \(-1.895 0.000\) & \(11.3/15\) & \(14/15\) \\  Grad & \(0.872 0.062\) & \(0.646 0.052\) & \(0.624 0.102\) & \(9.0/15\) & \(10/15\) \\ COMs & \(0.517 0.115\) & \(0.613 0.003\) & \(0.783 0.029\) & \(10.3/15\) & \(10/15\) \\ ROMA & \(0.927 0.033\) & \(0.676 0.029\) & \(0.927 0.071\) & \(6.1/15\) & \(6/15\) \\ NEMO & \(0.942 0.003\) & \(\) & \(0.737 0.010\) & \(5.3/15\) & \(5/15\) \\ IOM & \(0.823 0.130\) & \(0.650 0.042\) & \(0.559 0.081\) & \(7.4/15\) & \(6/15\) \\ BDI & \(0.870 0.000\) & \(0.605 0.000\) & \(0.722 0.000\) & \(9.6/15\) & \(9/15\) \\  CbAS & \(0.927 0.051\) & \(0.651 0.060\) & \(0.683 0.079\) & \(8.7/15\) & \(8/15\) \\ Auto.CbAS & \(0.910 0.044\) & \(0.630 0.045\) & \(0.506 0.074\) & \(10.3/15\) & \(10/15\) \\ MIN & \(0.905 0.052\) & \(0.616 0.021\) & \(0.717 0.046\) & \(10.4/15\) & \(10/15\) \\ BONET & \(0.913 0.008\) & \(0.621 0.030\) & \(0.724 0.008\) & \(7.7/15\) & \(8/15\) \\ DDOM & \(0.957 0.006\) & \(0.657 0.006\) & \(0.745 0.070\) & \(4.9/15\) & \(5/15\) \\  _RGD_ & \(\) & \(\) & \(0.825 0.063\) & **2.0/15** & **2/15** \\  

Table 2: Results (maximum normalized score) on discrete tasks & ranking on all tasks.

and the Transformer-based BONET. This result highlights the superiority of diffusion models in modeling inverse mappings compared to other generative approaches. (3) Upon examining TF Bird 8, we observe that the average rankings for forward and inverse methods stand at \(10.3\) and \(6.0\), respectively. In contrast, for TF Bird 10, both methods have the same average ranking of \(8.7\), indicating no advantage. This notable advantage of inverse methods in TF Bird 8 implies that the relatively smaller design space of TF Bird 8 (\(4^{8}\)) facilitates easier inverse mapping, as opposed to the more complex space in TF Bird 10 (\(4^{10}\)). (4) RGD's performance is less impressive on NAS, where designs are encoded as \(64\)-length sequences of \(5\)-category one-hot vectors. This may stem from the design-bench's encoding not fully capturing the sequential and hierarchical aspects of network architectures, affecting the efficacy of inverse mapping modeling.

### Ablation Studies

In this section, we present a series of ablation studies to scrutinize the individual contributions of distinct components in our methodology. We employ our proposed approach as a benchmark and methodically exclude key modules, such as the _proxy-enhanced sampling_ and _diffusion-based proxy refinement_, to assess their influence on performance. These variants are denoted as _w/o proxy-e_ and _w/o diffusion-b r_. Additionally, we explore the strategy of directly performing gradient ascent on the diffusion intermediate state, referred to as _direct grad update_. The results from these ablation experiments are detailed in Table 3.

Our analysis reveals that omitting either module results in a decrease in performance, thereby affirming the importance of each component. The _w/o diffusion-b r_ variant generally surpasses _w/o proxy-e_, highlighting the utility of the proxy-enhanced sampling even with a basic proxy setup. Conversely, _direct grad update_ tends to produce subpar results across tasks, likely attributable to the proxy's limitations in handling out-of-distribution samples, leading to suboptimal design optimizations.

To further dive into the proxy-enhanced sampling module, we visualize the strength ratio \(/_{0}\)--where \(_{0}\) represents the initial strength--across diffusion steps \(t\). This analysis is depicted in Figure 3 for two specific tasks: Ant and TF10. We observe a pattern of initial decrease followed by an increase in \(\) across both tasks. This pattern can be interpreted as follows: The decrease in \(\) facilitates the generation of a more diverse set of samples, enhancing exploratory capabilities. Subsequently, the increase in \(\) signifies a shift towards integrating high-performance features into the sample generation. Within this context, conditioning on the maximum \(y\) is not aimed at achieving the dataset's maximum but at enriching samples with high-scoring attributes. Overall, this adjustment of \(\) effectively balances between generating novel solutions and honing in on high-quality ones.

In addition, we visualize the proxy distribution alongside the diffusion distribution for a sample \(}\) from the Ant task in Figure 4, to substantiate the efficacy of diffusion-based proxy refinement. The proxy distribution significantly overestimates the ground truth, whereas the diffusion distribution closely aligns with it, demonstrating the robustness of diffusion distribution. For a more quantitative

  Task & D & RGD & w/o proxy-e & w/o diffusion-b r & direct grad update \\  SuperC & 86 & \(\) & \(0.495 0.012\) & \(0.502 0.005\) & \(0.456 0.002\) \\ Ant & 60 & \(\) & \(0.940 0.004\) & \(0.961 0.011\) & \(-0.006 0.003\) \\ D’Kitty & 56 & \(\) & \(0.935 0.001\) & \(0.939 0.003\) & \(0.714 0.001\) \\ Rosen & 60 & \(0.797 0.011\) & \(0.789 0.003\) & \(\) & \(0.241 0.283\) \\  TF8 & 8 & \(\) & \(0.957 0.007\) & \(0.960 0.006\) & \(0.905 0.000\) \\ TF10 & 10 & \(\) & \(0.657 0.006\) & \(0.667 0.009\) & \(0.672 0.018\) \\ NAS & 64 & \(\) & \(0.745 0.070\) & \(0.717 0.032\) & \(0.718 0.032\) \\  

Table 3: Ablation studies on RGD.

Figure 3: Dynamics of strength ratio \(/_{0}\).

analysis, we compute the expectation of both distributions and compare them with the ground truth. The mean of the diffusion distribution is calculated as \(_{p_{}(y|)}[y]=_{p_{}(y|)} [}(y|)}{p_{}(y|)}y]\). The MSE loss for the proxy distribution is \(2.88\), while for the diffusion distribution, it is \(0.13\) on the Ant task. Additionally, we evaluate this on the TFB10 task, where the MSE loss for the proxy distribution is \(323.63\) compared to \(0.82\) for the diffusion distribution. These results further corroborate the effectiveness of our proposed module.

Furthermore, we (1) investigate the impact of replacing our trained proxy model with alternative approaches, specifically ROMA and COMs, (2) analyze the performance with an optimized condition \(y\) and (3) explore a simple annealing approach of \(\). For a comprehensive discussion on these, readers are referred to Appendix E.

### Hyperparameter Sensitivity Analysis

This section investigates the sensitivity of _RGD_ to various hyperparameters. Specifically, we analyze the effects of (1) the number of diffusion sampling steps \(T\), (2) the condition \(y\), and (3) the learning rate \(\) of the proxy-enhanced sampling. These parameters are evaluated on two tasks: the continuous Ant task and the discrete TFB10 task. For a detailed discussion, see Appendix F.

## 5 Related Work

**Offline black-box optimization.** A recent surge in research has presented two predominant approaches for offline BBO. The forward approach deploys a DNN to fit the offline dataset, subsequently utilizing gradient ascent to enhance existing designs. Typically, these techniques, including COMs , ROMA , NEMO , BDI [20; 28], IOM  and Parallel-mentoring , are designed to embed prior knowledge within the surrogate model to alleviate the OOD issue. The reverse approach [6; 31] is dedicated to learning a mapping from property values back to inputs. Feeding a high value into this inverse mapping directly produces a design of elevated performance. Additionally, methods in [22; 23] progressively tailor a generative model towards the optimized design via a proxy function and BONET  introduces an autoregressive model trained on fixed-length trajectories to sample high-scoring designs. Recent investigations  have underscored the superiority of diffusion models in delineating the inverse mapping. However, research on specialized guided diffusion for offline BBO remains limited. This paper addresses this research gap.

**Guided diffusion.** Guided diffusion seeks to produce samples with specific desirable attributes. Contemporary research in guided diffusion primarily concentrates on enhancing the efficiency of its sampling process.  propose a method for distilling a classifier-free guided diffusion model into a more efficient single model that necessitates fewer steps in sampling.  introduce an operator splitting method to expedite classifier guidance by separating the update process into two key functions: the diffusion function and the conditioning function. Additionally,  presents an efficient and universal guidance mechanism that utilizes a readily available proxy to enable diffusion guidance across time steps. In this work, we explore the application of guided diffusion in offline BBO, with the goal of creating tailored algorithms to efficiently generate high-performance designs.

## 6 Conclusion

In conclusion, we propose _Robust **G**uided **D**iffusion for Offline Black-box Optimization_ (**RGD**). The _proxy-enhanced sampling_ module adeptly integrates proxy guidance to enable enhanced sampling control, while the _diffusion-based proxy refinement_ module leverages proxy-free diffusion insights for proxy improvement. Empirical evaluations on design-bench have showcased RGD's outstanding performance, further validated by ablation studies on the contributions of these novel components. We discuss the broader impact and limitation in Appendix G.

Figure 4: Proxy vs. diffusion distribution.