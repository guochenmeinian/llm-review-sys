# DOPPLER: Differentially Private Optimizers with Low-pass Filter for Privacy Noise Reduction

Xinwei Zhang

University of Southern California

&Zhiqi Bu

Amazon

&Mingyi Hong

University of Minnesota

&Meisam Razaviyayn

University of Southern California

xinweiz,razaviya@usc.edu, This work is not affiliated with Zhiqi Bu's position at Amazon.

###### Abstract

Privacy is a growing concern in modern deep-learning systems and applications. Differentially private (DP) training prevents the leakage of sensitive information in the collected training data from the trained machine learning models. DP optimizers, including DP stochastic gradient descent (DPSGD) and its variants, privatize the training procedure by gradient clipping and _DP noise_ injection. However, in practice, DP models trained using DPSGD and its variants often suffer from significant model performance degradation. Such degradation prevents the application of DP optimization in many key tasks, such as foundation model pre-training. In this paper, we provide a novel _signal processing perspective_ to the design and analysis of DP optimizers. We show that a "frequency domain" operation called _low-pass filtering_ can be used to effectively reduce the impact of DP noise. More specifically, by defining the "frequency domain" for both the gradient and differential privacy (DP) noise, we have developed a new component, called DOPPLER. This component is designed for DP algorithms and works by effectively amplifying the gradient while suppressing DP noise within this frequency domain. As a result, it maintains privacy guarantees and enhances the quality of the DP-protected model. Our experiments show that the proposed DP optimizers with a low-pass filter outperform their counterparts without the filter by \(3\%-10\%\) in test accuracy on various models and datasets. Both theoretical and practical evidence suggest that the DOPPLER is effective in closing the gap between DP and non-DP training.

## 1 Introduction

A rapidly growing number of modern machine learning applications in computer vision, natural language processing, and their mixtures rely on the development of large foundation models, whose performance heavily depends on the huge amounts of data collected from individual users. The leakage of potentially sensitive information in training data has become an increasingly critical issue when releasing and using machine learning models. Unfortunately, modern complex models have a strong ability to memorize the exact training data during the training processing Carlini et al. (2021); Pan et al. (2020). To alleviate the possible privacy leakage in the model training procedure, privacy-preserving optimization has attracted both researchers' and practitioners' interests.

Differential Privacy (DP) Dwork and Roth (2014) provides a strong theoretical guarantee with an easy and nearly plug-and-play mechanism, i.e., gradient clipping and noise injection, for existing optimization algorithms to guarantee the privacy of training procedures Abadi et al. (2016). By directly applying the DP mechanism to existing optimizers, DP optimizers have achieved decent in fine-tuning foundation models Yu et al. (2021); Bu et al. (2024) or training smallmodels (De et al., 2022). However, the performance of the pretraining tasks and training large foundation models using DP optimizers still remain unsatisfactory. This is because, as the DP theory suggests, the amount of injected DP noise is proportional to the number of model parameters and the total update steps (Abadi et al., 2016). Thus, the performance of large foundation models trained with DP optimizers degrades severely. To put it in perspective, pretraining a foundation model for an image classification task on the CIFAR dataset from randomly initialized weights takes around \(100\) epochs, with \(300K\) steps (Dosovitskiy et al., 2020); the pretraining of BERT for natural language processing task takes \(1M\) steps (Devlin et al., 2019), and pretraining LLAMA takes more than \(250K\) steps (Touvron et al., 2023). The number of trainable parameters is also huge for these tasks, ranging from \(300M\) to \(70B\). Therefore, the huge amount of injected DP noise severely degrades the performance of the final model trained with DP optimizers.

To improve the performance of DP optimizers, existing research takes two approaches: 1) designing models that are less sensitive to DP noise, e.g., using group normalization, weight standardization, weight smoothing, and smooth activation layers (De et al., 2022; Papernot et al., 2021; Wang et al., 2020), and 2) designing adaptive DP optimizers that inject _relatively_ smaller noise, e.g., adaptive clipping, sparse gradient, and dynamic privacy budget (Andrew et al., 2021; Yu et al., 2021; Luo et al., 2021; Hong et al., 2022). However, existing methods only work for certain models and tasks at the cost of consuming more privacy budget. Moreover, most of the methods only demonstrate empirical improvements and do not provide theoretical justification for improving DP optimization. Therefore, there is a strong need for an approach that improves the performance of DP optimizers, which has the following properties: 1) has a solid theoretical guarantee, 2) is easy to implement, and 3) is compatible with most existing DP optimization improving methods.

Motivated by the above needs, in this paper, we develop a module that can easily be integrated into the DP training optimizers. We provide both theoretical and empirical justification for our proposed module. Specifically, our **contributions** are as follows:

* **Frequency-domain analysis:** We introduce the notion of frequency domain analysis on (DP) optimizers. This analysis sheds light on how "noise" affects the "signal" part of the update directions viewed as a sequence of update steps, rather than independent update steps.
* **Low-pass filter approach:** Based on our frequency-domain analysis, we propose a low-pass filtering approach named DOPPLER, that post-processes the privatized gradient to reduce DP noise and improve DP optimizers' performance. Our low-pass filter reduces noise in the frequency domain, which is orthogonal to existing DP noise reduction approaches in the time domain and, therefore, can be easily combined with other existing techniques to further reduce noise.
* **Theoretical Analysis:** We provide a novel theoretical analysis for the proposed low-pass filtering approach. Specifically, by introducing certain frequency domain assumptions on the gradients, we provide the convergence and privacy guarantee for DPSGD with the low-pass filter. Unlike existing methods that involve trading off noise with bias (e.g., adaptive clipping), or based on approximation (e.g., low-rank decomposition), our proposed algorithm does not introduce extra bias, model modification, or extra privacy cost.
* **Numerical results:** Our extensive numerical experiments compare the performance of a variety of DP optimizers with and without the low-pass filter on different models and datasets. Our results show that DP optimizers equipped with the low-pass filter outperform the ones without the filter.

## 2 Preliminaries

In this section, we discuss notations, assumptions, and some related prior work on DP optimization:

### Notations & assumptions

In this paper, we aim to optimize the Empirical Risk Minimization (ERM) problem:

\[_{^{d}}F(),\ \ F():=_{i=1}^{N}f(;_{i}).\] (1)

Here, \(=\{_{i}\}_{i=1}^{N}\) is the training dataset with \(N\) samples. Further denote the lower bound of the problem as \(f^{}= f()\). Throughout the paper, we use \(()_{t}\) to denote the update steps, \((,^{2})\)to denote the Gaussian distribution with mean \(\) and variance \(^{2}\). We also assume the problem (1) satisfies the following assumptions.

**A 1 (Smoothness)**: \(F()\) _is_ \(L\)_-smooth, i.e.,_ \(\| F()- F()\| L\|-\|,\ ,^{d}\)_._
**A 2 (Bounded Variance)**: _The per-sample gradient has bounded variance, i.e.,_

\[_{}\| f(;)- F( )\|^{2}_{}^{2},\ ^{d}.\]
**A 3 (Bounded Gradient)**: _The per-sample gradient has a bounded norm, i.e.,_

\[\| f(;)\| G,\ ^{d}, .\]

Let us briefly comment on these assumptions: A1 and A2 are standard in non-convex optimization (Allen-Zhu and Hazan, 2016; Zaheer et al., 2018; Abadi et al., 2016); and A3 is commonly used in analyzing the convergence of DP algorithms (Abadi et al., 2016; Wang et al., 2020; Andrew et al., 2021) to avoid introducing the clipping bias. Since the impact of clipping is not the major focus of this paper, we follow the existing analyses and use A3 to simplify our theoretical analysis.

### Differential privacy (DP) and differentially private SGD (DPSGD)

Differential privacy is a gold standard of privacy to protect the privacy of individuals:

**Definition 1** (\((,)\)-DP (Dwork and Roth, 2014)): _A randomized mechanism \(\) is said to be \((,)\)-differentially private, if for any two neighboring datasets \(,^{}\)\((,^{}\) differ only by one sample) and for any measurable output set \(\), it holds that \([()]^{}[ (^{})]+\)._

A popular practical differentially private approach to finding an (approximate) solution to the ERM optimization problem (1) is Differentially Private Stochastic Gradient Descent (DPSGD) (Abadi et al., 2016) and its variants, including DP-Adam and DP-Lora (Yu et al., 2021). To protect DP, DPSGD considers applying the commonly used Gaussian mechanism (Dwork and Roth, 2014; Abadi et al., 2016) at each iteration of the stochastic gradient descent method. The Gaussian mechanism provides a DP guarantee by injecting additive noise into the algorithm output.

**Definition 2** (Gaussian Mechanism (Dwork and Roth, 2014; Zhao et al., 2019)): _Suppose an algorithm \(:^{d}\) has \(_{2}\) sensitivity \(_{}\), i.e., \(_{,^{}}\|()- (^{})\|_{}\). Then, for any \(>0\) and \( 0.05\), by adding random Gaussian noise to the output of the algorithm \(M(x)=(x)+,\ (0,_{}^{2}I_{d}),\) where \(_{}=}}{}+ }}{}\), the algorithm \(M\) is \((,)\)-DP._

The DPSGD algorithm, presented in Algorithm 1, first samples a mini-batch \(^{t}\) of size \(B\) and computes the per-sample gradient at each step \(t\). Then, it applies the Gaussian mechanism by clipping the per-sample gradient and injecting DP noise. The clipping operation bounds the sensitivity of the stochastic gradients to \(C\), e.g., \(( f,C)=\{1, \} f\) or \( f\). Finally, the algorithm updates the model parameter with the privatized mini-batch gradient. It has been shown that DPSGD guarantees \((,)\)-DP with sufficiently large injected noise (Abadi et al., 2016).

**Theorem 1** (Privacy Guarantee (Abadi et al., 2016)): _Given \(N,B,T\) and \(C\), there exist positive constants \(u,v\), such that for any \(<T}{N^{2}},>0\), by choosing \(_{}^{2} v^{T()}{N^{2}^{2}}}\), Algorithm 1 is guaranteed to be \((,)\)-DP._

### Related work

**Effective DP training:** Improving the performance of DP training has been widely studied. Adaptive gradient clipping (Andrew et al., 2021) estimates the size of the gradient privately and adaptively changes the clipping threshold to avoid injecting large DP noise; automatic clipping (Bu et al., 2024) replaces the clipping operation with normalization to avoid injecting large DP noise when the gradient becomes small; Hong et al. (2022) proposes using a time-varying privacy budget at each step which injects non-static DP noise based on the gradient to reduce the impact of the DP noise. As the injected DP noise variance scales with the model size, reducing the number of trainable parameters with adapters, low-rank weights, or quantized models has also been used to reduce the DP noise magnitude (Yu et al., 2021; Luo et al., 2021; Yu et al., 2021). De et al. (2022); Papernot et al. (2021); Wang et al. (2020) use special model structures that are less sensitive to DP noise, including group normalization, weight standardization, smoothed activation, and smoothed weights.

These methods aim to reduce the magnitude of the injected DP noise or make the model and/or the DP algorithm less sensitive to large DP noise. However, the improvement is either empirical or only works for specific model structures and is unable to be generalized to other DP training tasks.

**Signal processing for optimization:** A few existing works analyze the optimization procedure from the signal processing perspective. They mainly focus on optimizing strongly convex problems using deterministic algorithms (Hu and Lessard, 2017; An et al., 2018); Gannot (2022) provides stability and convergence analysis from the frequency domain for inexact gradient methods. However, the results are still restricted to non-DP optimization and to strongly convex problems.

## 3 A signal processing perspective

As discussed in Section 2.3, most of the existing works that aim to improve the performance of DP training are reducing the _per-iteration_ injected DP noise. These approaches treat the update directions in each step independently, omitting the underlying dynamics and correlations between the steps. However, the gradient directions typically change smoothly due to the smoothness of the machine-learning model; therefore, the update directions are not independent over time.

With the intuition that the gradients over iterations are not independent, we provide the _frequency-domain_ analysis of the stochastic gradients. Specifically, in the frequency domain, we treat the (stochastic) gradients from \(t=0\) to \(t=T\) as a time series and analyze the long-term correlation and dependencies across all gradients. In contrast, the time domain refers to the analyses that only focus on the gradient at step \(t\): for instance, Bu et al. (2024); Yang et al. (2022) leverage the \(L\)-Lipschitz smoothness or the second-order Taylor expansion to bound/approximate the objective function in step \(t\) after the update is performed. By analyzing the DP optimizers' updates in the frequency domain, we can make use of our prior knowledge of the correlation among the update directions.

To explain our motivation in a simplified manner, we temporarily ignore the per-sample gradient clipping and focus our narrative on the noise: suppose \(_{t+1}=_{t}-_{t}_{t}\) with \(_{t}= F(_{t})+_{t}\) and \(_{t}\) being the Gaussian noise. We will come back to the clipping in Section 3.2. In what follows, we decompose the sequence of stochastic gradients \(\{_{t}\}\) into two parts: 1) the gradient signal \(\{ F(_{t})\}\) and the noise \(\{_{t}- F(_{t})\}\). We employ the power spectral density (PSD) to characterize the distribution of power into frequency components of a continuous signal. Mathematically, the power spectral density (PSD) of a sequence \(\{s_{t}\}_{t=0,1,...}\) is \(P_{s}()=\{_{s}()\}\), where \(\) denotes the Fourier transform from time domain (\(\)) to frequency domain (\(\)) (Oppenheim et al., 1996), and \(\) is the auto-correlation coefficient as \(_{s}()= s_{t},s_{t-}.\)

On the one hand, the gradient sequence \(\{ F(_{t})\}_{t=0,1,...}\) can be treated as a low-frequency signal, where we apply the Cauchy Schwarz inequality to get

\[_{ f}() = F(_{t}), F(_{t-})=\,[\| F(_{t}) \|^{2}+\| F(_{t-})\|^{2}-\| F(_{t})-  F(_{t-})\|^{2}]\] \[\,[\| F(_{t})\|^{2 }+\| F(_{t-})\|^{2}-L^{2}^{2}_{i=1}^{}\| _{t-i}\|^{2}].\]

This indicates that as long as the _stepsize_\(\)_is small_, the auto-correlation coefficients decrease as \(\) increases (as illustrated in Figure 0(a), blue line). Therefore, the PSD also decreases as \(\) increases, i.e., \(\{ F(_{t})\}\) is a low-frequency signal (as illustrated in Figure 0(b), blue line).

On the other hand, the noise signal \(\{_{t}\}:=\{_{t}- F(_{t})\}\) is a white noise, where its auto-correlation is non-zero when \(=0\) and is zero otherwise (as illustrated in Figure 0(a), red line):

\[_{}()=_{t},_{t- } d_{}^{2}+}^{2}}{B},&=0\\ =0,&.\]

Therefore, \(P_{}()=d_{}^{2}+}^{2}}{B}, \) (as illustrated in Figure 0(b), red line).

### Low-pass filter and noise reduction

From the above discussion, we observed that although the gradient and the DP noise are not separable in each step \(t\) (time-domain), they are distinguishable in the _frequency domain_. In particular, _the noise power is equally distributed over all frequencies, while the gradient is concentrated around the lower frequencies._ Therefore, we can apply the classical signal processing tools, such as frequency domain low-pass filters, to help improve the performance of DP optimization.

A low-pass filter amplifies the low-frequency component of the signal and suppresses the high-frequency part. Figure 0(c) shows an ideal low-pass filter that keeps the frequencies where the gradient is larger (\([-0.6,0.6]\)) and blocks the frequencies where the noise is larger (\(<-0.6>0.6\)). Signal-to-Noise Ratio (SNR) is a useful measure to characterize the quality of a noisy signal, i.e., the privatized gradient \(\{_{t}\}\) in DP optimization. Given the PSD of the gradient and the noise, the SNR of the privatized gradient is \(P_{ f}()}{_{}P_{}()}\). As illustrated in Figure 1, when there is no low-pass filter (i.e., in Figure 0(b)), the SNR is small as the noise dominates in the high-frequency. In contrast, by applying the low-pass filter (i.e., in Figure 0(c)), most of the signals in the low-frequencies are kept, and the noise in the high frequencies is filtered, so the SNR increases. A linear low-pass filter on \(\{_{t}\}\) can be written as a recursive linear combination of the history signals:

\[_{t}=-_{=1}^{n_{a}}a_{}_{t-}+_{= 0}^{n_{b}}b_{}_{t-},\]

where the sequence \(\{_{t}\}\) is the filtered output, \(\{a_{}\},\{b_{}\}\) are the filter coefficients. Additinally, the "order" of the filter is defined as \(\{n_{a},n_{b}\}\). By carefully designing the coefficients, the low-pass filter can take different shapes and filter different frequencies.

In contrast to low-pass filters, the existing approaches improving the performance of DP optimization can be viewed as increasing the SNR in the time domain, i.e., reducing the magnitude of the noise injected in each step while preserving most of the gradient signal. Because the low-pass filter reduces noise in the frequency domain, and the existing noise reduction approaches lie in the time domain, the two approaches are orthogonal to each other. Therefore, the low-pass filter can be combined with existing approaches to further improve the DP optimizers' performance.

### The impact of per-sample gradient clipping

The above analysis assumes that the clipping operation is inactive by choosing a large enough clipping threshold \(C\). In practice, the clipping operation is usually active. By assuming the clipped

Figure 1: An illustration of the auto-correlation \(()\) and power spectrum density \(P()\) of \(\{ F(^{t})\}\) and \(^{t}\) where \(_{ f}\) decays proportional to \(^{2}\) and \(_{t}\) is a white noise. (c) illustrates how an ideal low-pass filters out the high-frequency noise and keeps the low-frequency signal.

gradient \( F_{C}()\) has zero curl, the DP optimizer optimizes an alternative problem:

\[_{^{d}}F_{C}(),F_{C}( )=_{0}^{1} F_{C}(z)^{}z, \  F_{C}()=_{}(  f(;),C).\] (2)

Then the signal of the DP optimizer becomes the gradient of the alternative problem \(\{ F_{C}(_{t})\}\) and the noise becomes \(\{_{t}\}=\{_{t}- F_{C}(_{t})\}\). As clipping is a non-expansive operator, i.e., \(\|(,C)-(,C )\|\|-\|,\) the alternative problem \(F_{C}()\) is also \(L^{}\)-smooth with \(L^{} L\). Therefore, a similar argument could be made on the gradient signal \(\{ F_{C}(_{t})\}\) and the noise \(\{_{t}\}\) when the clipping threshold is small and the clipping operation is active.

## 4 The proposed DOPPLER approach

Building on the discussions in Section 3, we proposed a universal approach to improve DP optimization performance: **DP OP**timizer with Low-**P**ass **fiL**ter for nois**E** Reduction (**DOPPLER**). Taking DPSGD as an example, by applying DOPPLER, the main steps of the modified DPSGD algorithm are illustrated in Algorithm 2. The key steps of the low-pass filter are described in Lines 6-8. Line 6 computes the filtered update direction \(_{t}\) as a recursive linear combination of the current gradient, past gradients, and past update directions. \(_{t}\) estimates the first moment of the privatized gradient and can be expanded as a moving average of \(_{t}\), i.e., \(_{t}=_{=0}^{t+n_{b}}_{}_{t-}\). However, as \(\{_{}\},\{_{}\}\) are initialized with zeros (Line 2), \(_{t}\) is biased towards zero, especially in the early steps. To correct the initialization bias, in Line 7, the optimizer computes the bias correction factor \(c_{a,t}\) that is used in Line 8 to guarantee the weights \(_{}\) in the moving average are summed to \(1\).

**Connection to momentum method:** The DOPPLER approach is a generalized version of the momentum method from a first-order filter to higher orders. The momentum method uses _one_ buffer \(_{t}\) to store the exponential moving average of \(_{t}\), while DOPPLER uses _multiple_ buffers \(\{_{t-}\}_{=0}^{n_{a}-1}\) to compute a more complex moving average of \(_{t}\).

**Compatibility:** Algorithm 2 demonstrates how DOPPLER can be combined with the DPSGD algorithm while it is not restricted to DPSGD. The DOPPLER approach is compatible with other advanced DP optimizers, e.g., Adam (Kingma and Ba, 2015; Tang et al., 2024) and GaLore (Zhao et al., 2024). It serves as a base component for DP optimizers to improve their performance.

## 5 Theoretical analysis

### Convergence analysis

In this section, we analyze the convergence of DPSGD with DOPPLER. First, we make the following assumption on the gradient auto-correlation coefficients.

**A 4** (Gradient auto-correlation): _For all \(t\{0,,T-1\}\), there exists sequences \(\{c_{}\},\{c_{-}\}\) such that the following condition holds:_

\[ F(_{t}), F(_{t-})  c_{}\| F(_{t})\|^{2}+c_{-}\|  F(_{t-})\|^{2}, 0,\] (3) \[c_{-} 0, 0.\] (4)

```
1:Input:\(_{0},,,C,_{}\), \(\{a_{}\}_{=1}^{n_{a}},\{b_{}\}_{=0}^{n_{b}}\)
2:Initialize: \(\{_{-}\}_{=1}^{n_{a}}=0,\{_{-}\}_{=1}^{n_{b} }=0,\{c_{a,-}\}_{=1}^{a_{n}}=0,\{c_{b,-}\}_{=0}^{b_{n}}=0\)
3:for\(t=0,,T-1\)do
4: Randomly draw minibatch \(_{t}\) from \(\)
5:\(_{t}=_{t}|}_{_ {t}}( f(;),C)+_{t}\)# Compute private gradient \(_{t}(0,_{}^{}_{d})\)
6:\(_{t}=-_{=1}^{n_{a}}a_{}_{t-}+_{=0}^ {n_{b}}b_{}_{t-}\)# Apply filter
7:\(c_{b,t}=1,c_{a,t}=-_{=1}^{n_{a}}a_{}c_{a,t-}+_{=0}^ {n_{b}}b_{}c_{b,t-}\)# Compute bias
8:\(}_{t}=_{t}/c_{a,t}\)# Correct initialization bias
9:\(_{t+1}=_{t}-}_{t}\)# Parameter update
10:endfor ```

**Algorithm 2** DPSGD with DOPPLERClearly, we have \(c_{0}=>0\). From the discussion in Section 3, we see that the above assumption can be satisfied as long as \(\) is small enough, i.e.,

\[)\| F(_{t-} )\|^{2}+(1-2c_{})\| F(_{t})\|^ {2}}}{L=1}^{} F(_{t-_{1}}) \|^{2}+(d_{}^{2}+_{}^{2}/B)}}=(}).\]

The pattern of the sequence \(\{c_{}\}\) characterizes the frequency of the gradients as discussed in Section 3. If \(c_{}\)'s are all positive and slowly decreasing, then \( F(_{t})\) and \( F(_{t-})\) are highly correlated, so \(\{ F(_{t})\}\) lies in lower frequencies. However, \(c_{}\) is not necessarily positive. When some of \(c_{}\)'s are negative, or \(c_{}\)'s are oscillating between positive and negative values, it means that \( F(_{t})\) and \( F(_{t-})\) are negatively correlated, and \(\{ F(_{t})\}\) may contain high-frequency signals.

Before we present the theorem, let us define the normalized SNR as

\[}=^{T-1}_{=0}^{t}c_{} _{}}{_{t=0}^{T-1}_{=0}^{t}_{}^{2}},\] (5)

and define the expanded coefficients \(_{}\) as

\[_{}=_{_{2}=0}^{\{n_{b},\}}b_{_{2}}_{_{1} =1}^{n_{a}}z_{a,_{1}}(p_{a,_{1}})^{-_{2}},_{=1}^{n_{a}}}{1-p_{a,}x}=^{n_{a}}a_{}x^{}},\] (6)

which satisfies \(m_{t}=-_{=1}^{n_{a}}a_{}m_{t-}+_{=0}^{n_{b}}b_{}g _{t-}=_{=0}^{t}_{}g_{t-}\). Note that \(p_{a,}\) might be complex, but \(_{}\) are guaranteed to be real. With A4, we have the following convergence result for Algorithm 2.

**Theorem 2** (Convergence): _Assume the problem satisfies A1-A4. By choosing \(C G\), \(\{}{L_{}}\}\), and running Algorithm 2 for \(T\) iterations, the algorithm satisfies:_

\[_{t P(t)}\| F(_{t})\|^{2}_{0})-F^{}}{ S_{T}}+ }}(d_{}^{2}+}^{2}}{B}),\] (7)

_where we define \(S_{T}=_{t=0}^{T-1}_{=0}^{t}c_{}_{}=(T);\) the expectation is taken over \(t=0,,T-1\), such that \(P(t)=^{t}c_{}_{}}{S_{T}}\)._

The proof of Theorem 2 is given in Appendix B. Compared with vanilla DPSGD (Abadi et al., 2016), by adopting DOPPLER the noise is scaled by a factor of \(}}\). Thus, as long as \(}>\), the noise is reduced. Next, we will use the above result to obtain privacy-utility tradeoff.

### Privacy guarantee

Our low-pass filter is post-processing on the privatized gradient. Since DP is immune to post-processing Dwork and Roth (2014), Algorithm 2 provides the same DP guarantee as DPSGD, satisfying Theorem 1. By directly combining Theorem 1 and Theorem 2, we can obtain the following privacy-utility trade-off for Algorithm 2.

**Theorem 3** (Privacy-utility trade-off): _Assume the problem satisfies A1-A4. By choosing \(C=G\), \(_{}^{2}=T(1/)}{N^{2}^{2}}\), \(\{}{L_{}}\}\), and running Algorithm 2 for \(T=(}(F(_{0 })-F^{})}}{C})\) iterations, the algorithm satisfies \((,)\)-DP and the expected gradient satisfies:_

\[_{t P(t)}\| F(_{t})\|^{2}= (_{0})-F^{})(1/)}}{}}N}),\]

_where \(P(t)=^{t}c_{}_{}}{_{t=0}^{t-1}_{=0}^ {t}c_{}_{}}\) and \(,}\) are defined in (6), (5), respectively._

Theorem 3 implies that DPSGD with DOPPLER shares the same convergence rate \((}{N})\) as the vanilla DPSGD (Abadi et al., 2016). However, by using the low-pass filter, the performance of DPSGD improves by a _constant factor_\(}}}\), which is discussed next.

### Impact of the low-pass filter

Here, we provide \(}\) value for some choices of the filter coefficients and discuss how to design low-pass filters.

* For SGD (no filter), we have \(_{0}=1,\) and \(_{}=0,\ >0\). Then, the normalized SNR is \(}=\). This recovers the convergence result for DPSGD in Abadi et al. (2016).
* Momentum-SGD Cutkosky and Mehta (2020) is a special case of the low-pass filter, with filter coefficients: \(a_{1}=-0.9,b_{0}=0.1.\) and \(_{}=0.1 0.9^{}\). Then, the normalized SNR is \(} 1.9(+_{=0}^{t-1}0. 9^{}c_{})\), which is larger than vanilla DPSGD. This indicates that DPSGD with momentum can reduce the impact of DP noise compared with DPSGD w/o momentum.
* We can further improve the SNR by optimizing the filter coefficients under a fixed order: \[_{\{a_{}\},\{b_{}\}}},_{=0}^{n_{b}}b_{}-_{=1}^{n_{a}}a_{}=1.\] (8) From (8), we observe that the pattern of the auto-correlation coefficients \(c_{}\) determines the choice of the filter coefficients. When \(_{} c_{}\), \(}\) is maximized. However, in general, finding the _optimal_ filter coefficients by optimizing (8) before training is difficult, as \(\{c_{}\}\) is determined by the problem and the DP optimizer's updates and can be time-varying.

**Optimal FIR filter:** When the filter takes the form of a finite impulse response (FIR) (i.e., \(a_{n}=0\)), we can estimate \(\{c_{}\}\) and optimize \(b_{}\)'s according to (8) during training. To estimate \(c_{}\), we have:

\[c_{} ( F(_{t}),  F(_{t-})-c_{-}\| F(_{t-})\|^{2})/\| F(_{t})\|^{2}\] \[[_{t}, _{t-}-c_{-}(\|_{t-} \|^{2}-d_{}^{2}-_{}^{2}/B)] /[\|_{t}\|^{2}-d_{}^{2}- _{}^{2}/B]\] \[[_{t},_{t- }-\{\|_{t-}\|^{2}-d _{}^{2},0\}]/[\{\|_{t} \|^{2}-d_{}^{2},_{1}\},]\]

where in the last approximation we set \(c_{-}=\) and assume \(d_{}^{2}\) dominates \(_{}^{2}/B\); the \(\) are taken as \(\|\|^{2} 0\) and we choose \(_{1}=10^{-3}\) as a small positive number for numerical stability. After obtaining \(c_{}^{}\)s, \(b_{}^{}\)s have a closed-form solution \(b_{}=}{_{=0}^{n_{b}}c_{}}\). This estimation only relies on the stored privatized gradients \(\{_{t-}\}_{=0}^{n_{b}}\), so it does not spend an extra privacy budget or memory. Therefore, it can also be implemented along with DOPPLER, as an adaptive approach to adjust the filter coefficients for an optimal performance.

## 6 Numerical experiments

In this section, we investigate how the low-pass filter affects the performance of various DP optimizers on different datasets, privacy budgets, and models. Due to the page limitation, detailed implementation and extra numerical results are given in Appendix C. The code for the experiments is available at https://anonymous.4open.science/r/Low-pass-SGD-C7A1.

### Experiment Settings

**Dataset:** We conduct experiments on computer vision datasets (MNIST, CIFAR-10, and CIFAR-100 (Krizhevsky et al., 2009)) and natural language processing datasets, GLUE (Wang et al., 2018).

**Model:** We conduct experiments on various models, including the 5-layer CNN described in De et al. (2022), the modified ResNet in Kolesnikov et al. (2019), EfficientNet with group normalization (Tan and Le, 2019), and ViT (Dosovitskiy et al., 2020) for the CV tasks and RoBERTa-base (Liu et al., 2019) for the GLUE dataset. If not specified, the models are initialized with random weights _without pretraining_.

**Algorithm:** We compared the impact of DOPPLER on several base algorithms, including the DP version of SGD, Adam, and GaLore. The updates of the algorithms are given in Algorithm 2 and Algorithm 3 in Appendix C.2. We use **LP-** to denote the DP optimizer with DOPPLER.

**Hyper-parameters choices:** The choices of the filter coefficients \(a_{i},b_{i}\) are empirical; specific choices used in the experiments are listed in Table 2 in Appendix C.1.

The learning rate, batch size, and number of training epochs are tuned for best testing accuracy using grid search. Detailed hyper-parameters and search grids are given in Appendix C.1. For all experiments, we fix the privacy parameter \(=1/N^{1.1}\) to obtain a reasonable privacy notion.

### Numerical results

**PSD of the stochastic gradient:** First, we record the stochastic gradients of SGD and SGD with DOPPLER training ResNet-50 for \(40\) epochs (\(T=4000\) steps) on the CIFAR-10 dataset. Then, we compute the PSD of the recorded stochastic gradients. The results are given in Figure 2. We can observe that the recorded PSD of \(_{t}\) is filling all frequencies, and \(_{t}\) is a low-frequency signal. After applying the low-pass filter, the PSD of the filtered gradient lies in the low-frequency domain, and the high-frequency signals (and noise) are suppressed.

**Results for different datasets.** The comparisons between LP-DPSGD and DPSGD on different datasets are given in Figure 3. We can observe that LP-DPSGD outperforms DPSGD on MNIST, CIFAR-10, and CIFAR-100 datasets under the same privacy budget \(=8\). The results on the GLUE dataset is in Appendix C.3.

**Results for different algorithms:** The comparisons between DP optimizers, including DPSGD, DPAdamBC Tang et al. (2024), and DPGaLore (an extension of GaLore Zhao et al. (2024)), with and without DOPPLERis shown in Figure 4. We can observe that all DP optimizers with DOPPLERoutperform the baseline under different levels of privacy budget \(^{}\)s.

Figure 4: Comparision between DP optimizers w and w/o low-pass filters for pre-training with different \(\)’s on CIFAR-10 dataset.

Figure 3: Comparision between DPSGD and LP-DPSGD for pre-training on different datasets.

Figure 2: The recorded PSD of Gaussian noise \(\{_{t}\}\), and the stochastic gradients of SGD and LP-SGD of ResNet-50 training on CIFAR-10 dataset.

Conclusion and discussion

In this paper, we introduce a signal processing perspective to understand and analyze DP optimizers. By identifying the difference between the gradient and noise signal in the frequency domain, we propose DOPPLER, a low-pass filter approach, to filter out the DP noise and improve the signal-to-noise ratio of the privatized gradient. Our proposed filtering method is compatible with existing DP optimizers, and extensive experiments have shown that the low-pass filter could improve DP optimizers' performance in the case when the DP noise is large, e.g., in the pertaining stage and for training large models.

**Limitations:** Designing higher-order filters requires hyper-parameter tuning or prior knowledge of the gradients' auto-correlation pattern; implementing a high-order low-pass filter is memory inefficient (requires storing \(n_{a}+n_{b}\) optimization states for each trainable parameter), which eliminates the usage of the proposed method when optimizing very large-scale foundation models with limited memory resource.