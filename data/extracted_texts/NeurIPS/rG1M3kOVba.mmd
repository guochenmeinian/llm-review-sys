# FLuID: Mitigating Stragglers in Federated Learning using Invariant Dropout

Irene Wang\({}^{1,3}\), Prashant J. Nair\({}^{1}\), Divya Mahajan\({}^{2,3}\)

University of British Columbia\({}^{1}\), Microsoft\({}^{2}\), Georgia Institute of Technology\({}^{3}\)

irene.wang@gatech.edu   prashanthair@ece.ubc.edu   divya.mahajan@gatech.edu

###### Abstract

Federated Learning (FL) allows machine learning models to train locally on individual mobile devices, synchronizing model updates via a shared server. This approach safeguards user privacy; however, it generates a heterogeneous training environment due to the varying performance capabilities of devices. As a result, "straggler" devices with lower performance often dictate the overall training time. In this work, we aim to alleviate this performance bottleneck due to stragglers by dynamically load balancing the training across the system. We introduce _Invariant Dropout_, a method that extracts a sub-model based on the weight update threshold, thereby minimizing potential impacts on accuracy. Building on this dropout technique, we develop an adaptive training framework, Federated Learning using Invariant Dropout (FLuID). FLuID offers a lightweight framework for sub-model extraction to regulate the computational intensity, thereby reducing the load on straggler devices without affecting model quality. Our method leverages neuron updates from non-straggler devices to construct a tailored sub-model for each straggler based on client performance profiling. Unlike prior work, FLuID can dynamically adapt to changes in stragglers as runtime conditions shift. We evaluate FLuID using five real-world mobile clients. The evaluations show that Invariant Dropout maintains baseline model efficiency while alleviating the performance bottleneck of stragglers through a dynamic and lightweight runtime approach. 1

## 1 Introduction

Federated Learning (FL) enables machine learning models to train on edge and mobile devices, synchronizing the model updates via a common server . This method ensures user privacy as local data remains on the device, minimizing the risk of data breaches, leaks, or unauthorized access to sensitive information in the cloud . However, FL introduces heterogeneity due to varying performance capabilities of the participating devices. Consequently, straggler devices with lower computational and network performance often dictate the overall training latency and throughput, as shown in Figure 1.

Previous research mitigates the impact of stragglers through asynchronous aggregation, where clients can communicate and update the server model independently and asynchronously . While this approach alleviates some of the detrimental effects of stragglers, it can introduce staleness into the global model. This occurs because the gradients used to update the server model may rely on outdated parameters, resulting in inaccuracies that have the potential to slow down convergence and reduce overall accuracy .

Other research proposes eliminating updates from slower devices entirely. . However, this approach can introduce training bias, as it effectively excludes certain clients and their respective data.

To ensure the contribution of all devices, recent works in this area employ a dropout technique where the stragglers only train a subset of the global model . The overall accuracy of the model is determined by the subset of neurons that are dropped from the global model. Thus, previous work alleviates the training load on stragglers by either incurring training bias, creating performance-centric sub-models, or entirely reconstructing the sub-model.

Our paper proposes a novel dropout technique called Invariant Dropout, which identifies "invariant" neurons--those that train quickly and show little variation during training. We observe that the training (computational load) and transfer (communication load) of these invariant neurons to and from the straggler devices contribute minimally to the efficiency of the global model. Thus, they can be dropped. We observe that after only 30% of the training iterations, 15%-30% of the neurons become invariant across CIFAR10 , and LEAF datasets FEMNIST, and Shakespeare . Building on this insight, we develop a dynamic framework called Federated Learning using Invariant Dropout (FLuID), which adjusts the sub-model size based on both the magnitude of neuron updates and the computational capabilities of the client devices. In addition to introducing a new dropout technique, FLuID, unlike prior work, periodically calibrates the sub-model size during runtime to account for changes in stragglers due to factors like low battery or network issues.

Overall, we face two challenges in building FLuID -- identifying invariant neurons and establishing a dynamic lightweight method for straggler identification and sub-model size determination at runtime. FLuID addresses the first challenge by leveraging the non-straggler clients, which typically outnumber stragglers and train on the entire model, to identify invariant neurons. The server is not used for this purpose as it receives updates from stragglers running a sub-model. For the second challenge, FLuID uses a drop-threshold, below which neurons are dropped, allowing dynamic sub-model determination for each straggler. By profiling client training times and identifying stragglers during the initial epochs of each calibration step, FLuID can incrementally adjust the drop-threshold until the number of selected neurons matches the target sub-model size for stragglers.

Our evaluation of FLuID on various models, datasets, and real-world mobile devices shows an up to 18% speedup in performance. Additionally, it improves training accuracy by a maximum of 1.4 percentage points over the state-of-the-art Ordered Dropout, all while mitigating the computational performance overheads caused by straggler devices.

## 2 Related Work

In the domain of heterogeneous client optimization, several prior work have tried to mitigate the effects of stragglers.

**Dropout techniques.** Federated Dropout  randomly drops portions of the global model, sending a sub-model to the slower devices. However, this can potentially impact accuracy. Subsequent work, Ordered Dropout , mitigates this accuracy loss by regulating which neurons are dropped, either from the left or right portions of the global model. Other methods, such as those outlined in , use a low-rank approximation to identify over-parameterized neurons and generate tailored sub-models. Despite these advancements, none of these works consider the individual contribution of each neuron while creating a sub-model. In contrast, our work not only introduces a novel dropout technique that takes into account the contribution of each neuron but also

Figure 1: Stragglerâ€™s impact on FL performance. In synchronous FL, all clients, including stragglers, participate in global model aggregation.

provides a framework capable of dynamically identifying slower devices and adjusting the dropout rate accordingly.

**Server offloading strategies using split learning.** The approach proposed by  employs split learning to offload part of the model to the server, while  transfers their knowledge to a larger server-side CNN.  focuses on device mobility during Federated Learning, offloading training to edge servers. Finally,  introduces a compression method for split learning. However, unlike these methods, Invariant Dropout does not require data transfer out of the device and into the server, instead conducts all training on client devices. Nonetheless, if data movement was a possibility, Invariant Dropout can be stacked on top of these techniques to determine which part of the model needs to be offloaded to the server.

**Communication Optimizations.** To reduce learning time,  proposes an online learning approach that reduces the communication overheads of Federated Learning by adaptively sparsifying gradients.  introduces a Federated Learning framework utilizing a probabilistic device selection method to improve FL convergence time.  proposes a framework incorporating overhead reduction techniques for efficient training on resource-limited edge devices, including pruning and quantization. Unlike these works, Invariant Dropout avoids both communication and computation overhead by dropping the least contributing "invariant" neurons, presenting a new insight compared to these prior works.

**Model Pruning.** PruneFL  introduces an approach to dynamically select model sizes during FL and reduce communication and computation overhead, thereby minimizing training time. Work in  prunes the global model for slower clients by excluding neurons with no or small activations. These approaches either generate a single sub-model for all clients, including non-stragglers, to train on or generate a static sub-model for the entire training process which can result in the stragglers permanently losing the opportunity to contribute to certain parts of the model. In contrast, Invariant Dropout enables the generation of multiple sub-models with various resource budgets and dynamically chooses a sub-model for each round based on current neuron contribution.

**Coded Federated Learning.** CodedPaddedFL and CodedSecAgg  utilize coding strategies to mitigate the impact of slower devices. By sharing an encoded version of their data with other clients, both schemes introduce redundancy in the client's local data. Therefore, during training, the computation of a subset of clients is sufficient to train the global model and the computations of straggling clients can be discarded without loss of information. While CodedPaddedFL combines one-time padding with gradient codes, codedSecAgg is based on Shamir's secret sharing. Unlike these methods, Invariant Dropout allows each client to keep their data local.

**Training a Global Family of Models.** SuperFed  proposes co-training of multiple models to reduce training costs. It achieves this by sending subnetworks of different sizes to all clients. In contrast, FLuID focuses on optimizing the performance of stragglers by mostly training clients on the full global model and a smaller percentage (stragglers) on sub-models tailored to their capabilities.

## 3 Background and Motivation

### Challenges in Federated Learning

In Federated learning's synchronous aggregation protocols, the server hosts a global model and regularly aggregates updates from clients, which are then redistributed to clients . Thus, system heterogeneity remains a significant challenge in FL . As shown in Figure 1(a), we observe significant differences in training times across five Android-based mobile phones, from 2018 to 2020, engaged in Federated Learning without any dropout mechanism in place. Depending on the dataset and machine learning model, training time can vary significantly, with differences of up to twofold across datasets such as CIFAR10, FEMNIST, and Shakespeare. The standard deviation between the training times of each client is 0.5, 22, and 21 seconds for FEMNIST, CIFAR10, and Shakespeare, respectively. This highlights the real-world challenge of system heterogeneity, where different devices, even if they are of a similar class (e.g., Android-based mobile phones) with just a few years' difference, can offer dramatically different computational performance. Furthermore, we find the performance of mobile devices can fluctuate over time due to varying network bandwidth and resource availability. In response to these observations, we develop FLuID, a system designed to dynamically identify stragglers and adjust the training load to balance performance with non-straggler devices.

### Dropout Techniques

Model dropout is a technique that involves sending a subset of the global model, known as a sub-model, to stragglers for load balancing. There are two state-of-the-art proposals in this space: Federated Dropout  and Ordered Dropout from FjORD . Federated Dropout randomly drops neurons, simplifying the selection of sub-models, but reducing the global model's accuracy. In contrast, Ordered Dropout systematically drops neurons by maintaining order within the sub-model. These works demonstrate that the sub-model's neuron selection is crucial for the global model's accuracy. In the context of this work, "neurons" refer to filters in convolutional (\(\)) layers, activations in fully-connected (\(\)) layers, and hidden units in Long Short-Term Memory (LSTM)  layers.

**Accuracy Implications with dropout:** Figure 1(b) compares the testing accuracy of a non-dropout vanilla Federated Learning (FL) implementation with Ordered Dropout. This comparison is performed using five mobile devices, one of which is a straggler, across three different datasets: CIFAR10 , FEMNIST, and Shakespeare . As the sub-model size decreases, we observe that across all three datasets and machine learning models, Ordered Dropout experiences up to a 2.5 percentage point drop in accuracy. We vary the sub-model size from 0.5 (representing 50% of the global model) to 1 (the entire model). The results with 50-100 clients and 20% of them being stragglers are provided in Section 6.1.

## 4 Invariant Dropout

Invariant Dropout enables stragglers to only train on a sub-model consisting of neurons that 'vary' over time and contribute to the global model. Invariant dropout achieves this by selecting a subset (\(i\)) of sub-models (\(s_{i}\)) from a total sub-model distribution (\(S\)), where each sub-model represents a different number of neurons and thus varies in compute and memory requirements. Appendix A.1 illustrates the temporal variation in the percentage of invariant neurons in the evaluated models. Note that all clients including the straggler still perform inference on the full model.

### Proposed dropout mechanism

Invariant Dropout selects a sub-model from a set of sub-models, \(S\), composed of \(m\) total sub-models, denoted as \(S\) = \(s_{1},s_{2},...,s_{m}\). Each sub-model \(s_{i}\) contains neuron layers \(a_{1},a_{2},...,a_{k}\). The size of the sub-model corresponds to a dropout rate \(r\) that is based on the drop-threshold \(th\) for the dropout mechanism. Given a change in neuron value, \(g= a\), we can select the sub-model \(s_{i}\) = {\(a_{1},a_{2},...,a_{k}\)} where the updates in neurons within the sub-model satisfy \(g th\)\(\)\(a_{j} s_{i}\) and \(1 j k\). FLuID, which we describe below, selects \(s_{i}\) such that the compute utilization and memory footprint can effectively mitigate the inefficiency of the straggler.

Figure 2: (a) Performance variation across mobile devices (in log scale), (b) accuracy implications of prior dropout (static) techniques.

Next, we assume that the system includes \(C\) clients with \(T\) stragglers and \(N\) non-stragglers. \(T\) and \(N\) are exclusive and independent subsets of \(C\), where \(T N\) = \(C\) and \(T N\) = \(\). Invariant Dropout maintains a dropout rate \(r(0,1]\) per layer across the \(T\) stragglers. However, the complexity of selecting \(a_{j}(t+1)\) will vary with each sub-model \(s_{i}\). To reduce the computational overhead of selecting the appropriate sub-model, ID leverages non-straggler clients to provide directions on the set of \(a_{j}(t+1)\). The server computes over a subset of potential sub-models \(s_{i}\) to select the one with the maximum updates to the neurons.

### Variance in Gradients with Invariant Dropout

Consider \(C\) clients participating in Federated Learning. The training data is represented as \(x_{c}c=1^{C}\), where \(c\) denotes one client, and each client has a corresponding loss function \(fc_{c=1}^{C}\). Learning minimizes the loss function using the following optimization: \(f(w):= c=1^{C}f_{c}(w)\), where \(w_{t+1}=w_{t}-_{t}(g(w_{t}))\).

Invariant Dropout can be viewed as a sparse stochastic gradient vector, where each gradient has a certain probability of being dropped. The gradient vector is denoted as \(G=[g_{1},g_{2},...,g_{k}]\) where \(g R\) and each gradient has a probability of being retained and transmitted across the network, represented as \([p_{1},p_{2},...,p_{k}]\). The sparse vector for the stragglers is represented as \(G_{s}\). The variance of the ID-based gradient vector can be represented as \(E(G_{s}^{2})=_{i=1}^{k}(g_{i}^{2}p_{i})\). The variance of the dropout vector is a small factor deviation from the non-dropout gradient vector represented as follows:

\[_{i=1}^{k}p_{i}:_{i=1}^{k}(g_{i}^{2}p_{i})=(1+)_{i=1}^ {k}g_{i}^{2}\] (1)

Invariant Dropout drops weights based on the \(g= a\) gradient across epochs. Thus, the probability of a gradient not getting dropped (\(p_{i}\)) is inversely proportional to the dropout rate \(r\). This implies if \(|g_{i}|>|g_{j}|\) then \(p_{i}>p_{j}\). Let's assume that the top-k magnitude of gradients are not dropped. Hence if \(G=[g_{1},g_{2},...,g_{m}]\) is sorted, then \(G=[g_{1},g_{2},...,g_{k}]\) has a \(p=1\), whereas \(G=[g_{k+1},g_{k+2},...,g_{d}]\) has a probability of \(p_{i}=|}{r}\). This modifies the optimization problem in Equation 1 to:

\[_{i=1}^{k}g_{i}^{2}+_{i=k+1}^{m}|}{r}-(1+)_{i =1}^{m}g_{i}^{2}=0,|}{r} 1\] (2)

Which implies that

\[r=^{m}|g_{i}|}{(1+)_{i=1}^{m}g_{i}^{2}-_{i= 1}^{k}g_{i}^{2}}\] (3)

As per the constraint \(|}{r} 1\):

\[|g_{i}|(_{i=k+1}^{m}|g_{i}|)(1+)_{i=1}^{m}g_{i}^{2}-_{ i=1}^{k}g_{i}^{2}\] (4)

Invariant Dropout retains the gradients with the greatest magnitude. As a result, the boundedness of the expected value from Equation 1 can be represented as follows:

\[_{i=1}^{m}p_{i}=_{i=1}^{k}p_{i}+_{i=k+1}^{m}p_{i}\] (5)

\[_{i=1}^{m}p_{i}=k+|g_{i}|_{i=k+1}^{m}(^{m}|g_{i}|}{ (1+)_{i=1}^{m}g_{i}^{2}-_{i=1}^{k}g_{i}^{2}})\] (6)

\[_{i=1}^{m}p_{i} k(1+)\] (7)

As such, the variance of the gradient in ID is bounded by Equation 7.

## 5 FLuID Framework

Figure 3 shows the workflow of Federated Learning using Invariant Dropout (FLuID). In FLuID, each calibration step includes straggler determination (\(T\)), discovering invariant neurons(\(IN\)) and drop threshold (\(th\)), and sub-model extraction(\(s_{i}\)). Currently, the calibration occurs per epoch, i.e., one training run over the complete client dataset. However, the frequency of calibration can be reduced if the invariant neurons and stragglers do not significantly change over steps.

Algorithm 1 outlines the FLuID framework. At the onset of training, FLuID identifies the stragglers. To achieve this, FLuID runs the global model on all clients, including stragglers, and measures the performance delay between the end-to-end training time of the slowest client (\(T_{straggler}\)) and the target time (\(T_{target}\)).End-to-end training includes upload/download latency and communication time.

\(T_{target}\) is the desired training time FLuID aims to achieve for stragglers. FLuID assigns \(T_{target}\) as the next slowest client's training time. This choice optimizes non-straggler idle time reduction. Note, FLuID can support any \(T_{target}\) value. Setting \(T_{target}\) lower than the next-slowest client's time offers no gain as non-stragglers cannot accelerate. Conversely, setting \(T_{target}\) above the next-slowest client's training time leads to longer idleness and suboptimal performance. The required speedup for stragglers is calculated as \(Speedup=}{T_{target}}\). The initial calibration is carried out in lines 6-9 and 18-22 of the algorithm. Note, it takes a few epochs to calibrate the initial threshold, stragglers, and submodel. In subsequent calibration steps, the global server continues to measure the training time of clients and thereby identifies if there is any change in the straggler cohort.

**Tuning the performance of stragglers.** The sub-model size is determined by calculating the dropout rate \(r\) as detailed in lines 18-21 of Algorithm 1. The value of \(r\) is selected to ensure that the updated straggler training time, denoted as \(T_{stragglernew}\), is close to the target training time (\(T_{target}\)). Figure 7 in Appendix A.3 demonstrates that across all evaluated datasets, the training time of all five mobile clients decreases linearly as the sub-model size decreases, and falls within 10% of the sub-model size. Using this insight, FLuID chooses an \(r\) that is closest to the inverse of the speedup.

**Determining the drop threshold at runtime.** Once FLuID has identified the stragglers and the dropout rate, it iteratively adjusts the threshold to drop as many invariant neurons as possible. The design of FLuID is inspired by the preliminary results regarding the characteristics of invariant neurons and their impact on the model accuracy. In Appendix A.2, we present results to quantify the impact of the threshold value on the number of invariant neurons during training. We observe that, in order to obtain the desired accuracy, it is critical to select a threshold that yields a number of invariant neurons as close as possible to the number of neurons to be dropped for the sub-model.

Lets assume \(w_{ijc}(t)\) represents the set of weights of the \(i\)th neuron in the \(j\)th layer for client \(c\) after the training epoch \(t\). The percent difference \(g\) of the neuron, for each client \(c\), is the minimum value of \(g\) as denoted by: \(g(t)-w_{ij}(t-1)}{w_{ij}(t-1)}\). Neurons that are potential candidates for dropping are those whose weight updates are within the threshold (\(th\)) compared to the previous calibration point. Unfortunately, determining the appropriate \(th\) poses a few challenges.

Figure 3: The workflow of FLuID. The non-stragglers are used to determine the neurons that are not updated within a set threshold. Thereafter, sub-models are dynamically created by dropping invariant neurons. These sub-models are sent to the straggler devices.

In order to identify neuron drop candidates, the global server cannot rely on updates from all clients since stragglers only train on and update the sub-model. Instead, the server takes advantage of the fact that non-stragglers train on the complete model and can identify neurons whose weight updates fall within the threshold (\(th\)) for each calibration step. FLuID prioritizes dropping neurons on stragglers whose weight updates fall within the threshold (\(th\)) for the majority of non-stragglers.

The initial threshold value (\(th\)) in the FLuID framework is set as the average of the minimum percent update of all neurons in the initial few training epochs. The threshold is incrementally increased after each epoch until the number of neurons below the threshold is greater than or equal to the number of neurons to be left out of the sub-model. FLuID can have a different drop threshold for each layer. The algorithm targets neurons for dropping whose gradients consistently fall below the threshold over multiple epochs, prioritizing the elimination of non-critical neurons.

This entire process is repeated to recalibrate the stragglers, the drop rate (\(r\)), and the threshold (\(th\)).

## 6 Evaluation Setup

**Models and datasets.** We evaluate FLuID on three models and datasets as used by the prior works in the federated learning space .

The FEMNIST datasets consist of images of numbers and letters, partitioned based on the writer of the character in non-IID setting. We train a CNN with two 5x5 CONV layers with 16 and 64 channels respectively, each of them followed with 2\(\)2 max-pooling. The model also includes a fully connected dense layer with 120 units and a softmax output layer. The model is trained using a batch size of 10 and a learning rate of 0.004.

The Shakespeare dataset partitions data based on roles in Shakespeare's plays in non-IID setting. We train a two-layer LSTM classifier containing 128 hidden units. We train the model with a batch size of 128 and a learning rate of 0.001.

The CIFAR10 dataset consists of images, partitioned using the same strategy as FjORD  and the IID partition provided by the Flower . For the real-world mobile devices, we train on the VGG-9 model due to its ability to fit within the resource constraints of all the mobile phones we tested. VGG-9  model architecture consists 6 3x3 CONV layers (the first 2 have 32 channels,followed by two 64-channel layers, and lastly two 128-channel layers), two FC dense layers with 512 and 256 units and a final softmax output layer. We train the model with a batch size of 20 and a learning rate of 0.01. We conduct scalability experiments using the ResNet-18 model, and the results are presented in section 6.1. All the baseline dropout methods and Invariant Dropout are evaluated using the same setup.

**System Configuration.** Table 1 provides the details of the phones used for the experiments. We evaluate five clients and identify one straggler per training epoch. We connect all our client devices and our server over the same network. All the clients run on Android mobile phones from the years 2018 to 2020.

FLuID is implemented on top of the Flower (v0.18.0) [BTM\({}^{+}\)20] framework and TensorFlow Lite [Goo] from TensorFlow v2.8.0 [ABC\({}^{+}\)16]. Models are defined using TensorFlow's Sequential API, and then converted into.tflite formats.

**Evaluation metrics and baselines.** We compare the average training performance (wall-clock time) and accuracy for all workloads and experiments. In each evaluation round, clients receive the global model and report their evaluation accuracy and loss on local data to the server. The server calculates the distributed accuracy and loss by performing a weighted average based on the number of testing examples for each client. We compare FLuID with two established baselines: 1) Random Federated Dropout [CKMT18] and 2) Ordered Dropout from FjORD [HLA\({}^{+}\)21].

### Results and Analysis

**Accuracy Evaluation** We compare accuracy of Invariant Dropout with two baselines, using different sub-model sizes. We trained the models for 100, 250, and 65 epochs for CIFAR10, FEMNIST, and Shakespeare datasets, respectively. Table 2 presents the average achieved accuracy (\(\)) along with the standard deviation (\(\)) for the three datasets. Specifically, Invariant Dropout outperforms Random Dropout across all three datasets. Compared to Random Dropout, our work achieves a maximum accuracy gain of 1.6% points and on average 0.7% point higher accuracy for FEMNIST, 0.6% point higher accuracy for CIFAR10, and 0.3% point higher accuracy for Shakespeare datasets.

Invariant Dropout also achieves a higher accuracy against Ordered Dropout across all three datasets, with a maximum increase in accuracy of 1.4% and an average increase of 0.3% for FEMNIST, 0.4%

  
**Device** & **Year** & **Android Version** & **CPU (Cores)** & & & & & \\  LG Velvet 5G & 2020 & 10 & 1\(\)2.4 GHz Kryo 475 Prime + 1\(\)2.2 GHz Kryo 475 Gold + 6\(\)1.8 GHz Kryo 475 Silver & & & & \\  Google Pixel 3 & 2018 & 9 & 4\(\)2.5 GHz Kryo 385 Gold + 4\(\)1.6 GHz Kryo 385 Silver & & & & & \\  Samsung Galaxy S9 & 2018 & 10 & 4\(\)2.8 GHz Kryo 385 Gold + 4\(\)1.7 GHz Kryo 385 Silver & & & & & \\  Samsung Galaxy S10 & 2019 & 11 & 2\(\)2.73 GHz Mongoosa M + 2\(\)2.31 GHz Cortex-A75 + 4\(\)1.95 GHz Cortex-A55 & & & & & \\  Google Pixel 4 & 2019 & 12 & 1\(\)2.84 GHz Kryo 485 + 3 \(\)2.42 GHz Kryo 485 + 4\(\)1.78 GHz Kryo 485 & & & & \\   

Table 1: Software-Hardware specifications of clients

   Dataset & Dropout Method & \(r=0.95\) & \(r=0.85\) & \(r=0.75\) & \(r=0.65\) & \(r=0.5\) & \\   & & Accuracy (\(\)) & \(\) & Accuracy (\(\)) & \(\) & Accuracy (\(\)) & \(\) & Accuracy (\(\)) & \(\) & Accuracy (\(\)) & \(\) \\  Shakespeare & Random & 43.3 & 0.1 & 42.5 & 0.1 & 42.4 & 0.1 & 41.8 & 0.2 & 41.3 & 0.1 \\   & Ordered & 42.9 & 0.1 & 42.3 & 0.1 & 42.2 & 0.2 & 41.9 & 0.1 & 41.4 & 0.1 \\   & **Invariant** & **43.6** & 0.1 & **42.5** & 0.1 & **42.6** & 0.2 & **42.2** & 0.2 & **41.7** & 0.1 \\  CIFAR10 & Random & 57.5 & 0.1 & 56.8 & 0.2 & 57.0 & 0.2 & 57.2 & 0.2 & 57.2 & 0.3 \\  (VGG-9) & Ordered & 57.7 & 0.1 & 57.0 & 0.2 & 57.6 & 0.2 & 57.3 & 0.1 & 57.1 & 0.1 \\   & **Invariant** & **58.2** & 0.1 & **58.4** & 0.3 & 57.1 & 0.1 & **57.5** & 0.2 & **57.4** & 0.2 \\  FEMNIST & Random & 80.6 & 0.1 & 80.5 & 0.2 & 80.3 & 0.2 & 79.3 & 0.5 & 79.2 & 0.3 \\   & Ordered & 80.6 & 0.2 & 80.5 & 0.2 & 80.4 & 0.2 & 80.3 & 0.1 & 79.7 & 0.3 \\   & **Invariant** & **81.1** & 0.3 & **80.9** & 0.1 & **80.8** & 0.2 & **80.3** & 0.4 & **80.1** & 0.3 \\  

Table 2: Accuracy comparison of Random Dropout, Ordered Dropout, and Invariant Dropout. The text in **bold** indicates instances when Invariant Dropout showcases the highest accuracy. (\(=\) mean, \(=\) standard deviation, and \(r=\) sub-model as a fraction of global model).

for CIFAR10, and 0.4% for Shakespeare. The accuracy improvements of Invariant Dropout are statistically significant (\(<0.05\)). Moreover, Invariant Dropout shows less variation in accuracy between runs of the same sub-model size and across all sub-model sizes. This is because invariant Dropout eliminates only invariant neurons, which have little impact on the final model efficiency.

**Computational Performance Evaluation** Figure 3(a) shows FLuID's capability to effectively select the sub-model, resulting in a significant reduction in the straggler's training time that almost matches the next slowest client. In the absence of FLuID, the straggler's training time is typically 10% to 32% longer than the target time. However, after applying FLuID, the straggler's training time is within 10% of the target time. Furthermore, it is observed that the overall accuracy of the global model tends to be higher when stragglers train with larger sub-models. Consequently, FLuID selects the largest possible sub-model size that minimizes training time variance across clients. Notably, the performance improvement, unlike accuracy, is influenced by the size of the sub-model and not the specific dropout technique employed. For a more detailed analysis of the impact of sub-model size on training time, please refer to Appendix A.3.

**Varying stragglers at runtime.** FLuID can recalibrate stragglers. During the experiments in Table 2, we observe that the performance of our mobile clients remained relatively stable, without significant changes in the straggler. However, to evaluate the impact of varying conditions at runtime, we randomly executed certain clients at different points in the training process (25%, 50%, and 75% marks). This was achieved by enabling a client to run the training program as a background process between the specified periods. We observed that FLuID successfully adapted to the variation in stragglers during runtime. Figure 3(b) demonstrates the overall training time for this experiment. On average, the FLuID framework achieved 18% to 26% faster training time compared to the baseline, and 14% to 18% faster training time compared to selecting a static straggler throughout the entire training process. All results include the overhead of FLuID, which, importantly, is not significant. We observe, FLuID calibration process takes significantly less time (less than 5%) compared to the actual training time. This is because the additional computations required for threshold and sub-model calibration are performed centrally on the server, rather than being distributed to edge devices.

**Scalability study.** To assess the scalability of FLuID, we conducted experiments using simulated clients ranging from 50 to 100. Each machine runs 10 to 20 clients in parallel. Among all clients, we identified the slowest 20% as stragglers. We further extend the experiment to run CIFAR10 with ResNet-18 as these are emulated clients on a server and can support relatively larger models than mobile devices. Figure 5 shows the accuracy performance across all three datasets. Overall, Invariant Dropout consistently outperforms Ordered and Random Dropout and maintains a better accuracy profile similar to Table 2. In addition, our dropout technique performs significantly better than completely excluding stragglers from the training process.

We further extended the experiment to assess the scalability of FLuID by 1) clustering stragglers into multiple sub-model sizes (Appendix A.4), 2) Exploring the impact of varying ratios of stragglers in the system (Appendix A.5), and 3) a scalability study with 1000 clients where client sampling is employed as we cannot check for stragglers across 1000 devices individually (Appendix A.6). We demonstrate that FLuID can scale to scenarios involving multiple stragglers with varying computational capabilities by tailoring sub-model sizes for each client. Moreover, when compared to state-of-the-art dropout techniques, Invariant Dropout achieves high accuracies, even as the percentage of stragglers in the system scales up.

Figure 4: Performance evaluation of FLuID

## 7 Limitations and Future Work

Although FLuID is able to mitigate some impact of the stragglers, it does incur minimal overhead to handle stragglers and maintain system performance. Our evaluation takes this into account but this overhead may increase if straggler performance constantly changes.

FLuID currently only uses pre-defined sub-model sizes mapped to straggler performance, which keeps the framework lightweight and avoids high overhead. However, for future works with varied edge devices, fine-grained sub-model determination may further enhance the work.

## 8 Conclusions

Due to rapid technological advancements and device variability in handheld devices, system heterogeneity is prevalent in federated learning. Straggler devices, which exhibit low computational performance, act as the bottleneck. In this paper, we address these issues by introducing a novel dropout technique called Invariant Dropout. Invariant Dropout dynamically creates customized sub-models that include only the neurons exhibiting significant changes above a certain threshold. We build a framework, FLuID, which adapts to changes in stragglers as runtime conditions shift. FLuID effectively mitigates the performance overheads caused by stragglers while also achieving a higher accuracy compared to state-of-the-art techniques.

## 9 Acknowledgements

We thank the anonymous reviewers for their insightful comments. This research was supported in part through computational resources provided by Advanced Research Computing at the University of British Columbia (UBC) [soc]. This work was partially supported by Gift from Google and the Natural Sciences and Engineering Research Council of Canada (NSERC) [funding reference number RGPIN-2019-05059]. The work, in part, was supported by Georgia Tech School of Electrical and Computer Engineering and School of Computer Science. The views and conclusions contained herein are those of the authors. They should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of Georgia Tech, Microsoft, and UBC.

Figure 5: The accuracy comparison of Invariant Dropout with Ordered and Random Dropout as we scale to 50-100 clients with 20% of the slowest clients being stragglers.