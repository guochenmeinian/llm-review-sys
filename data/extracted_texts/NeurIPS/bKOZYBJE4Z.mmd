# Causal Contrastive Learning

for Counterfactual Regression Over Time

Mouad El Bouchattaoui

mouad.el-bouchattaoui@centralesupelec.fr

Myriam Tami

Paris-Saclay University, CentraleSupelec, MICS Lab, Gif-sur-Yvette, France

Benoit Lepetit

Saint-Gobain, Paris, France

Paul-Henry Cournede

Paris-Saclay University, CentraleSupelec, MICS Lab, Gif-sur-Yvette, France

###### Abstract

Estimating treatment effects over time holds significance in various domains, including precision medicine, epidemiology, economy, and marketing. This paper introduces a unique approach to counterfactual regression over time, emphasizing long-term predictions. Distinguishing itself from existing models like Causal Transformer, our approach highlights the efficacy of employing RNNs for long-term forecasting, complemented by Contrastive Predictive Coding (CPC) and Information Maximization (InfoMax). Emphasizing efficiency, we avoid the need for computationally expensive transformers. Leveraging CPC, our method captures long-term dependencies in the presence of time-varying confounders. Notably, recent models have disregarded the importance of invertible representation, compromising identification assumptions. To remedy this, we employ the InfoMax principle, maximizing a lower bound of mutual information between sequence data and its representation. Our method achieves state-of-the-art counterfactual estimation results using both synthetic and real-world data, marking the pioneering incorporation of Contrastive Predictive Encoding in causal inference.

## 1 Introduction

It's vital in real-world applications to estimate potential responses, i.e., responses under hypothetical treatment strategies. Individuals show diverse responses to the same treatment, emphasizing the need to quantify individual response trajectories. This enables personalized interventions, enhancing decision-making efficacy. In medical contexts, precise response estimation enables tailored treatments for patients . This paper focuses on _counterfactual regression over time_, estimating responses under hypothetical treatment plans based on individual records, including past covariates, responses, and treatment sequences up to the current prediction time . In addressing the challenges of this time-varying setting, we tackle: (1) **Time-dependent confounding**: confounders influenced by past treatment, impacting subsequent treatments and responses. (2) **Selection bias:** imbalanced covariate distributions across treatment regimes in observational data, requiring time-aware handling beyond methods in static settings . (3) **Long-term dependencies**: enduring interdependencies among covariates, treatments, and responses, enabling long-range interactions .

Recent advancements in neural networks, such as Recurrent Marginal Structural Networks (RMSNs) , Counterfactual Recurrent Networks (CRN) , and G-Net , have tackled these causal inference challenges. However, their reliance on RNNs limits their ability to capture long-term dependencies. Recent studies  propose integrating transformers to better represent temporal dynamics. Rather than viewing this as a limitation of RNNs, we see it as an opportunity to emphasize their strengths. We design specific architectures for counterfactual regression over large horizons, avoiding complex, hard-to-interpret models like transformers. Our approach leveragesthe computational efficiency of RNNs, incorporating Contrastive Predictive Coding (CPC) [52; 29] for learning data history representations. This enhances model performance while maintaining efficiency, offering a compelling alternative to transformer-based approaches. Furthermore, we usually formulate identification assumptions of counterfactual responses over the original process history space (Appendix B.1). However, these assumptions may not hold in the representation space for arbitrary functions. Since identification often involves conditional independence, it applies when using an invertible representation function. Current models for time-varying settings [42; 7; 48] do not enforce representation invertibility. To address this, instead of adding complexity with a decoder, we _implicitly_ push the history process to be "reconstructable" from the encoded representation by maximizing Mutual Information (MI) between representation and input, following the InfoMax principle , akin to Deep InfoMax .

## 2 Contributions

Our approach is inspired by self-supervised learning using MI objectives . We aim to maximize MI between different views of the same input, introducing counterfactual regression over time through CPC to capture long-term dependencies. Additionally, we propose a tractable lower bound to the original InfoMax objectives for more efficient representations. This is challenging due to the sequential nature and high dimensionality, marking a novelty. We demonstrate the importance of regularization terms via an ablation study. Previous work leveraging contrastive learning for causal inference applies only to the static setting with no theoretical grounding . To our knowledge, we frame for the first time the representation balancing problem from an information-theoretic perspective and show that the suggested adversarial game (Theorem 5.4) yields theoretically balanced representations using the Contrastive Log-ratio Upper Bound (CLUB) of MI, computed efficiently. Key innovations of our Causal CPC model include: (1) We showcase the capability of leveraging CPC to capture long-term dependencies in the process history using InfoNCE [25; 26; 52], an unexplored area in counterfactual regression over time where its integration into process history modeling is not straightforward in causality. (2) We enforce input reconstruction from representation by contrasting the representation with its input. Such quality is generally overlooked in baselines, yet it ensures that confounding information is retained, preventing biased counterfactual estimation. (3) Applying InfoMax to process history while respecting its dynamic nature is challenging. We provide a tractable lower bound to the original InfoMax problem, also bringing theoretical insights on the bound's tightness. (4) We suggest minimizing an upper bound on MI between representation and treatment to make the representation non-predictive of the treatment, using the CLUB of MI . This novel information-theoretic perspective results in a theoretically balanced representation across all treatment regimes. (5) By using a simple Gated Recurrent Unit (GRU) layer  as the model backbone, we demonstrate that well-designed regularizations can outperform more complex models like transformers. Finally, our experiments on synthetic data (cancer simulation ) and semi-synthetic data based on real-world datasets (MIMIC-III ) show the superiority of Causal CPC at accurately estimating counterfactual responses.

## 3 Related Work

Models for Counterfactual Regression Through TimeTraditionally, causal inference addresses time-varying confounders using Marginal Structural Models (MSMs) , which rely on inverse probability of treatment weighting . However, MSMs can yield high variance estimates, especially with extreme values, and are limited to pooled logistic regression, impractical for high-dimensional, dynamic data. RMSNs  enhance MSMs by integrating RNNs for propensity and outcome modeling. CRN  employs adversarial domain training with a gradient reversal layer  to establish a treatment-invariant representation space, reducing bias induced by time-varying confounders. Similarly, G-Net  combines g-computation and RNNs to predict counterfactuals in dynamic treatment regimes. Causal Transformer (CT)  uses transformers to estimate counterfactuals over time and handles selection bias by learning a treatment-invariant representation via Counterfactual Domain Confusion loss (CDC) . These models, like ours, assume _sequential ignorability_, in contrast to a body of work which does not fully verify our assumptions [45; 73; 68; 60; 80; 79; 8; 28; 12; 38; 58; 69; 19; 10; 31; 34; 6; 11; 82; 22], which we discuss in detail in Appendix C.1.2. In contrast, we introduce a contrastive learning approach to capture long-term dependencies while maintaining a simple model and ensuring high computational efficiency in both training and prediction. This demonstrates that simple models with well-designed regularization terms can still achieve high prediction quality. Additionally, previous works [62; 64; 41; 39; 48] did not consider the role of invertible representation in improving counterfactual regression. Here, we introduce an InfoMax regularization term to make our encoder easier to invert. Appendix C.1 provides a detailed overview of counterfactual regression models.

InfoMax PrincipleThe InfoMax principle aims to learn a representation that maximizes MI with its input [43; 5]. Estimating MI for high-dimensional data is challenging, often addressed by maximizing a simple and tractable lower bound on MI [32; 56; 40]. Another approach involves maximizing MI between two lower-dimensional representations of different views of the same input [3; 29; 75; 77], offering a more practical solution. We adopt this strategy by dividing our process history into two views, past and future, and maximizing a tractable lower bound on MI between them. This encourages a "reconstructable" representation of the process history. To our knowledge, the only work applying an InfoMax approach to counterfactual regression, albeit in static settings, is . They propose maximizing MI between an individual's representation and a global representation, aggregating information from all individuals into a single vector. However, the global representation lacks clarity and interpretability, raising uncertainties about its theoretical underpinnings in capturing confounders. Furthermore, there's a lack of theoretical analysis on how minimizing MI between individual and treatment-predictive representations could yield a treatment-invariant representation. As a novelty, we extend the InfoMax principle to longitudinal data, providing a theoretical guarantee of learning balanced representations. Appendix C.2 discusses self-supervision and MI, with all proofs in Appendix G.

## 4 Problem Formulation

SetupIn the framework of Potential Outcomes (PO) , and following , we track a cohort of individuals (units) \(i\{1,2,,N\}\) over \(t_{max}\) time steps. At each time \(t\{1,2,,t_{max}\}\), we observe the following: (1) **Discrete treatment**\(W_{it}=\{0,1,,K-1\}\), e.g., in medical contexts, \(W_{it}\) may represent treatments like radiotherapy or chemotherapy. (2) **Outcome of interest**\(Y_{it}\), such as tumor volume. (3) **Time-varying context**\(_{it}^{d_{x}}\), containing information about the individual that may influence treatment decisions and outcomes. \(_{it}\) is a \(d_{x}\)-dimensional vector of confounders, such as health records or clinical measurements. (4) **Static confounders**\(^{d_{v}}\), such as gender, which remain constant over time. (5) **Partially observed potential outcomes**\(Y_{it}(_{i, t})\), representing the outcomes that _would have been_ observed for individual \(i\) at time \(t\) under treatment sequence \(_{i, t}=(_{i,1},,_{i,t})^{t}\). We define the history process up to time \(t+1\) as \(_{t+1}=[,_{ t+1},W_{ t},Y_{ t}]\), capturing all information prior to the assignment of treatment \(W_{t+1}\). This history is illustrated in the causal graph shown in Figure 1.

GoalGiven a training dataset \(\{_{i,t+1},i=1,,N\}\) sampled from the empirical distribution \(_{_{t+1}}\), we address the following causal inference problem: _Given a history process \(_{t+1}\), how can we efficiently estimate counterfactual responses up to time \(t+\) (where \( 1\) is the prediction horizon) for a potential treatment sequence \(_{t+1:t+}=(_{t+1},,_{t+})\)?_ The goal is to estimate the causal quantity: \((Y_{t+}(_{t+1:t+})_{t+1})\), i.e., the expected outcome at time \(t+\), given the history \(_{t+1}\) and a sequence of treatments \(_{t+1:t+}\). We identify this causal quantity from observational data using the assumption of sequential ignorability [62; 42; 39; 48], which is implicitly assumed in Figure 1 and explicitly discussed in Appendix B.1. This allows us to express the counterfactual as:

\[(Y_{t+}(_{t+1:t+})_{t+1})= (Y_{t+}_{t+1},W_{t+1:t+}=_{t+1:t+}).\]

## 5 Causal CPC

### Representation Learning

Contrastive Predictive CodingWe employ contrastive learning to efficiently represent the process history \(_{t}\). Causal forecasting over multiple time horizons requires representations that capture variability in \(_{t}\). For short-term predictions, local features and smooth signal variations are critical,

Figure 1: Causal graph over \(_{t+1}\)

[MISSING_PAGE_FAIL:4]

By considering the proposed variant of the InfoMax principle, we can compute a contrastive bound to \(I(_{t}^{h},_{t}^{f})\) more efficiently, as the random vectors reside in a low-dimensional space thanks to the encoding. We define a contrastive loss using InfoNCE similar to Eq. (1):

\[^{(InfoMax)}(_{1},_{2},)-_{ }[(_{t}^{f},_{t}^{h }))}{_{i=1}^{||}(T_{}(_{t,t}^{f},_{ t}^{h}))}].\] (7)

We use a non-linear discriminator \(T_{}\) parametrized by \(\) (detailed in Appendix I). The representation of the past subsequence \(_{t}^{h}\) is mapped to a prediction of the future subsequence \(}_{t}^{f} F_{}(_{t}^{h})\) and \(T_{}=_{t}^{f^{}}}_{t}^{f}\).

Theorem 5.2 and Proposition 5.1 justify using the loss in Eq. (7) by showing that our InfoMax simplification provides a valid lower bound. Thus, the contrastive loss in Eq. (7) is valid, as:

\[(||)-^{(InfoMax)} I(_{t}^{h},_{t}^{f}) I(_{t},(_{t}^{h},_{t}^{f})).\] (8)

The "mental model" behind our regularization term comes from the MI, \(I(_{t},(_{t}^{h},_{t}^{f}))=H(_{t})-H( _{t}(_{t}^{h},_{t}^{f}))\), which can be written using entropy. Since the entropy term is constant and parameter-free, minimizing the conditional entropy \(H(_{t}(_{t}^{h},_{t}^{f})) 0\) ensures that \(_{t}\) is almost surely a function of \((_{t}^{h},_{t}^{f})\) (Appendix G.4, Proposition G.2). When MI is maximized, the theoretical existence of such a function suggests that the learned context \(_{t}\) can decode and reconstruct \(_{t}\).

Beyond the idea of reconstruction, it was shown that the InfoNCE objective implicitly learns to invert the data's generative model under mild assumptions . Recent works [18; 44] extend this insight to multi-modal settings, which can reframe our InfoMax problem: \(_{t}^{h}\) and \(_{t}^{f}\) can be seen as two coupled modalities, allowing us to identify latent generative factors up to some mild indeterminacies (e.g rotations, affine mappings). We plan to extend multi-modal causal representation learning to the longitudinal setting, where we anticipate minimizing our InfoMax objective, in the limit of infinite data, will effectively invert the data generation process up to a class of indeterminacies that we conjecture to be broader and under weaker assumptions than those in current causal representation learning literature, given our focus is on causal inference rather than the identification of causal latent variables. We initiate a formal basis for this claim in Appendix G.5.

### Balanced representation learning

MotivationOur goal is counterfactual regression, specifically estimating \((Y_{t+}(_{t+1:t+})_{t+1})\). For simplicity, with \(=1\), we estimate the potential outcome for a given treatment \(W_{t+1}=_{t+1}\), where \(W_{t+1}\{0,1,,K-1\}\), expressed as \((Y_{t+1}(_{t+1})_{t+1})\), which under standard assumptions is identified as:

\[(Y_{t+1}(_{t+1})_{t+1})=(Y_{t+1} _{t+1},W_{t+1}=_{t+1}).\]

The RHS can be estimated from data as \((Y_{t+1}_{t+1},W_{t+1})=f(_{t+1},W_{t+1})\). Since only one treatment is observed per individual at each time step, \(W_{i,t+1}=_{i,t+1}\), our model \(\) generates counterfactual responses by switching treatments \((_{i,t+1},_{t+1}^{})\), where \(_{t+1}^{}_{t+1}\) (e.g., chemotherapy vs. radiotherapy). The challenge is that \(_{t+1}\) and \(W_{t+1}\) are not independent, introducing potential bias in counterfactual estimation , leading to covariate shift or selection bias. To address this, we learn a representation \((_{t+1})\) that enforces distributional balance during decoding.

SetupTo mitigate selection bias, we leverage the context representation \(_{t}\) of \(_{t}\) and introduce two sub-networks: one for response prediction and one for treatment prediction, both using a mapping of the context representation:

\[_{t}=((_{t}))=_{ _{R}}(_{t}),\]

where SELU represents the Scaled Exponential Linear Unit , and \(_{R}\) denotes all parameters of the representation learner, i.e., \(_{R}=[_{1},_{2}]\). Following [7; 48], our objective is to learn a representation that accurately predicts outcomes while remaining _distributionally balanced_ across all possible treatment choices \(W_{t}=0,1,,K-1\). To achieve this, we frame the problem as an adversarial game: one network learns to predict the next treatment from the representation, while a regularization term ensures that the representation is non-predictive of the treatment.

**Factual response prediction** Since we intend to predict counterfactual responses for \(\) steps ahead in time, we train a decoder to predict the factual responses \(Y_{t+1},,Y_{t+}\) given the sequence of treatments \((W_{t+1},,W_{t+})\). We minimize the negative conditional likelihood

\[_{Y}(_{R},_{Y}) =- p_{_{Y}}(y_{t+1:t+}_{t},_ {t+1:t+})\] \[=-_{j=1}^{} p_{_{Y}}(y_{t+j} y_{t+1:t+j-1},_{t},_{t+1:t+j}).\]

We denote \(_{t}^{j}[Y_{t+1:t+j-1},_{t},W_{t+1:t+j}]\) and assume a Gaussian distribution for the conditional responses \(Y_{t+j}_{t}^{j}(G_{Y}(_{t}^{j}), ^{2})\), where \(G_{Y}\) models the mean of the conditional response (see right side of Figure 2). We set \(=0.05\) throughout our experiments. The response sequence is estimated autoregressively using a GRU-based decoder without teacher forcing  to ensure model training's consistency with testing in real-world scenarios (Figure 2 and Algorithm 2 in Appendix H).

Treatment predictionWe learn a treatment prediction sub-network parameterized by \(_{W}\) that takes as input the representation \(_{t+1}\) and predicts a distribution \(q_{_{W}}(_{t+1}_{t+1})\) over the treatment \(W_{t+1}\) by minimizing the negative log-likelihood, \(_{W}=- q_{_{W}}(_{t+1}_{t+1})\). To assess the quality of the representation in predicting the treatment, the gradient from \(_{W}\) only updates the treatment network parameters \(_{W}\) and is not backpropagated through the response of the parameters for the representation \(_{t+1}\) (Algorithm 2, Appendix H).

Adversarial learningTo create an adversarial game, we update the representation learning parameters, and in the next step, the treatment network \(q_{_{W}}(_{t+1})\) with adverse losses such that the representation \(_{t+1}\) becomes invariant with respect to the assignment of \(W_{t+1}\). Different from SOTA models (as highlighted in related work) and in line with our information guidelines principles, learning a balanced representation \(_{t+1}\) amounts to ensuring \(_{t+1}\!\!\! W_{t+1}\), which is equivalent to \(I(_{t+1},W_{t+1})=0\). Hence, we minimize the MI as a way to confuse the treatment classifier. Specifically, we minimize an upper bound on \(I(_{t+1},W_{t+1})\), namely the CLUB of MI .

\[ I_{}((_{t}),W_{t+1};q_{ _{W}})&_{((_{t}),W_{t+1})}[ q_{_{W}}(W_{t+1}(_{t+1})) ]\\ &-_{_{_{t}}}_{_{W_{t +1}}}[ q_{_{W}}(W_{t+1}(_{t+1}))].\] (9)

We use the objective in Eq. (9) to update the representation learner \((.)\). This update aims to minimize the discrepancy between the conditional likelihood of treatments for units sampled from \(_{(_{t},W_{t+1})}\) and the conditional likelihood of treatments under the assumption of independent sampling from the product of marginals \(_{_{t+1}}_{W_{t+1}}\). In practice, we generate samples from the product of marginals by shuffling the treatment \(W_{t+1}\) across the batch dimension similar to . When minimizing \(_{W}\), \(q_{_{W}}(_{t+1}_{t+1})\) gets closer to the true conditional distribution \(p(_{t+1}_{t+1})\), and, in this case, the objective in Eq. (9) provides an upper bound of the MI between representation and treatment. We formalize the intuition by adapting the result of :

Figure 2: Causal CPC architecture: The left shows the encoder, which learns context \(_{t}\) from process history \(_{t}\), with CPC and InfoMax objectives used for pretraining. The right shows the decoder, which autoregressively predicts the future outcome sequence from \(_{t}\).

**Theorem 5.3**.: _[_13_]_ _Let \(q_{_{W}}(_{t+1},_{t+1}) q_{_{W}}(_{t+1}| _{t+1})p(_{t+1})\) be the joint distribution induced by \(q_{_{W}}(_{t+1}|_{t+1})\) over the representation space of \(_{t+1}\). If:_

\[D_{KL}(p(_{t+1},_{t+1})\|q_{_{W}}(_{t+1},_{ t+1})) D_{KL}(p(_{t+1})p(_{t+1})\|q_{_{W}}(_{t +1},_{t+1})),\]

_then \(I(_{t+1},W_{t+1}) I_{CLUB}(_{t+1},W_{t+1};q)\)._

Based on Theorem 5.3, our adversarial training is interpretable and can be explained as follows: the treatment classifier seeks to minimize \(_{_{(_{t},W_{t+1}]}}[_{W}]\), which is equivalent to minimizing Kullback-Leibler divergence \(D_{KL}(p(_{t+1},_{t+1})\|q_{_{W}}(_{t+1},_ {t+1}))\). Therefore, \(q_{_{W}}(_{t+1},_{t+1})\) could get closer to \(p(_{t+1},_{t+1})\) than, ultimately, to \(p(_{t+1})p(_{t+1})\), as we train the network to predict \(W_{t+1}\) from \(_{t+1}\). In such a case and by Theorem 5.3, \(I_{CLUB}\) provides an upper bound on the MI. Hence, in a subsequent step, we minimize \(I_{CLUB}\) w.r.t the representation parameters, minimizing the MI \(I(_{t+1},W_{t+1})\) and achieving balance. We theoretically formulate such behavior by proving in the following theorem that, at the Nash equilibrium of this adversarial game, the representation is exactly balanced across the different treatment regimes provided by \(W_{t+1}\).

**Theorem 5.4**.: _Let \(t\{1,2,,t_{max}\}\), \(=_{_{R}}\) and \(q=q_{_{W}}\) are, respectively, any representation and treatment network. Let \(_{(_{t})}\) be the probability distribution over the representation space and \(_{(_{t})|W_{t+1}}\) its conditional counterpart. Then, there exist \(^{*}\) and \(q^{*}\) such that:_

\[^{*} =_{}I_{}((_{t}),W_{t+1};q^{ *})\] (10) \[q^{*} =_{q}_{_{^{*}(_{t})}} [ q(W_{t+1}^{*}(_{t}))].\]

_Such an equilibrium holds if and only if \(_{(_{t})|W_{t+1}=0}\!=\!_{(_{t })|W_{t+1}=1}\!=\!\!=\!_{(_{t})|W_{t+1}=k-1}\)-almost surely._

Since we target multi-timestep forecasting, covariate balancing in the representation space extends beyond \(t+1\). For simplicity, we presented it for \(t+1\), but in practice, the adversarial game applies the balancing across all forecasting horizons (Algorithm 2). The theorem also holds for other horizons by replacing \((_{t})\) with \((_{t+j-1})\) and \(W_{t+1}\) with \(W_{t+j}\), for \(2 j\).

Causal CPC TrainingThe Causal CPC model is trained in two stages: (1) **Encoder pretraining:** We first learn an efficient representation of the process history by minimizing loss:

\[_{enc}=^{}}(_{1},_{2},\{ _{j}\}_{j=1}^{})+^{(InfoMax)}(_{1},_{2},).\]

(2) **Decoder training:** After pretraining, we fine-tune the encoder by optimizing the factual outcome and treatment networks in the adversarial game from Theorem 5.4. Formally:

\[_{_{R},_{Y}}_{dec}(_{R},_{Y },_{W})=_{Y}(_{R},_{Y})+I_{}(_{ _{R}}(_{t}),W_{t+1};q_{_{W}}),\] \[_{_{W}}_{W}(_{W},_{R})=-_{_{_{R}}(_{t})}[ q_{_{W}}(W_{t+1} _{_{R}}(_{t}))].\]

## 6 Experiments

We compare Causal CPC with SOTA baselines: MSMs , RMSN , CRN , G-Net , and CT . All models are fine-tuned via a grid search over hyperparameters, including architecture and optimizers. Model selection is based on mean squared error (MSE) on factual outcomes from a validation set, and the same criterion is used for early stopping. Further details on hyperparameters and training procedures are provided in Appendices J and D.

### Experiments with Synthetic Data

Tumor GrowthWe use the PharmacoKinetic-PharmacoDynamic (PK-PD) model  to simulate responses of non-small cell lung cancer patients, following previous works [41; 7; 48]. We evaluate our approach on simulated counterfactual trajectories, varying the confounding level via the parameter \(\) (Appendix E.1). Unlike , who used larger datasets (10,000 for training, 1,000 for testing), we use a smaller, more challenging dataset (1,000 for training, 500 for testing) to reflect real-world data limitations. For long-horizon forecasting, we set the prediction horizon to 10 and evaluate two training sequence lengths: 60 and 40, with covariates of dimension 4.

[MISSING_PAGE_EMPTY:8]

patient trajectories are high-dimensional and exhibit long-range dependencies. Similar to the cancer simulation, the training data consisted of relatively few sequences (500 for training, 100 for validation, and 400 for testing). Table 1 presents the mean and standard deviation of counterfactual predictions across multiple horizons (\(=10\)). We test two maximum sequence lengths, 100 and 60, to assess the models' robustness for long-horizon forecasting.

ResultsCausal CPC consistently outperformed the baselines, especially at larger horizons, both with a sequence length of 100 and a reduced length of 60 (Figures 1, 5). Its superior performance at longer horizons is likely due to the high number of covariates, making it well-suited to contrastive-based training. We also tested the models with 800/200/200 individuals for training/validation/testing, as in  (Appendix F.2.2), where Causal CPC achieved state-of-the-art (SOTA) results comparable to CT but with much shorter training and prediction times.

Computational Efficiency and Model ComplexityEfficient execution is crucial for practical deployment, especially with periodic retraining. Beyond training, challenges arise in evaluating multiple counterfactual trajectories per individual, which grow exponentially with the forecasting horizon as \(K^{}\), where \(K\) is the number of possible treatments. This is particularly relevant when generating multiple treatment plans, such as minimizing tumor volume. Table 2 shows the models' complexity (number of parameters) and running time, split between model fitting and prediction. Causal CPC is highly efficient during prediction due to its simple 1-layer GRU, similar to CRN (1-layer LSTM), while providing better ITEs estimation. In contrast, CT is less efficient due to its transformer architecture and teacher forcing, which requires recursive data loading during inference. G-Net also has longer prediction times due to Monte Carlo sampling. Overall, Causal CPC strikes a strong balance between accuracy and efficiency, making it well-suited under constrained resources.

Real MIMIC-III DataWe evaluated our model on real MIMIC-III data, where counterfactual trajectories cannot be assessed due to the absence of observed counterfactual responses. However, performance can still be measured by forecasting factual (observed) responses over time. Our model estimates responses for each individual based on their observed treatment trajectory. As shown in Figure 6, Causal CPC consistently outperforms all baselines, especially at larger horizons, demonstrating its robustness and effectiveness in real-world settings.

## 7 Discussion

Why does Causal CPC outperform SOTA at large horizons?Our context \(_{t}\) is designed to capture shared information across future representations, particularly covariates, by minimizing the

  Model & \(=1\) & \(=2\) & \(=3\) & \(=4\) & \(=5\) & \(=6\) & \(=7\) & \(=8\) & \(=9\) & \(=10\) \\ 
**Causal CPC (corr)** & 0.32\(\)0.04 & 0.54\(\)0.05 & 0.54\(\)0.06 & 0.61\(\)0.01 & 0.66\(\)0.10 & 0.66\(\)0.10 & **0.71\(\)0.11** & **0.71\(\)0.11** & **0.75\(\)0.05** & **0.75\(\)0.05** & **0.77\(\)0.10** \\ 
**CT** & 0.42\(\)0.03 & **0.40\(\)0.06** & **0.52\(\)0.08** & **0.66\(\)0.05** & 0.67\(\)0.10 & 0.72\(\)0.12 & 0.77\(\)0.13 & 0.61\(\)0.11 & 0.85\(\)0.10 & 0.80\(\)0.17 \\ 
**G-Net** & 0.54\(\)0.13 & 0.72\(\)0.14 & 0.58\(\)0.16 & 0.96\(\)0.17 & 0.58\(\)0.18 & 1.44\(\)0.18 & 1.33\(\)0.16 & 1.40\(\)0.16 & 1.49\(\)0.16 \\ 
**CRN** & 0.27\(\)**0.03** & 0.45\(\)0.05 & 0.58\(\)0.09 & 0.72\(\)0.11 & 0.82\(\)0.15 & 0.92\(\)0.20 & 1.00\(\)0.25 & 1.00\(\)0.25 & 1.12\(\)0.32 & 1.17\(\)0.35 \\ 
**RMSE** & 0.40 \(\)0.16 & 0.70 \(\)0.21 & 0.80\(\)0.19 & 0.38\(\)0.17 & 0.94\(\)0.16 & 1.00\(\)0.15 & 1.15\(\)0.14 & 1.10\(\)0.14 & 1.14\(\)0.13 & 1.18\(\)0.13 \\  

Table 1: Evolution of RMSEs for the semi-synthetic MIMIC III, sequence length 100.

  Model &  &  \\  Causal CPC (Full) & **1.05** & **0.62** \\ Causal CPC (w/o \(^{(1+N) 2 1}\)) & 1.07 & 0.68 \\ Causal CPC (w/o \(^{(1+N) 2 1}\)) & 1.13 & 0.74 \\ Causal CPC (w/o \(^{(1+N) 2 1}\)) & 1.07 & 0.73 \\ Causal CPC (w/o balancing) & 1.08 & 0.69 \\  

Table 3: Ablation study with NRMSE averaged across (\(1 10\)) for cancer simulation (\(=1\)) and MIMIC III.

Figure 5: Performance for MIMIC III semi-synthetic, sequence length 60.

Figure 6: Evolution of RMSEs, Real MIMIC III, sequence length 100.

InfoNCE loss over multiple time steps (Eq. 1). As shown in Eq. (5), minimizing \(^{CPC}\) maximizes shared information between the context and future components, helping capture the _global structure_ of the process. This is especially beneficial for counterfactual regression over long horizons, explaining the model's superior performance. However, it may not always outperform SOTA in shorter-term predictions due to its focus on long-term dependencies.

Short-term Counterfactual RegressionWhile our model is designed for long-term predictions, it may not consistently outperform SOTA for short-horizon tasks. However, the use of contrastive loss, particularly InfoNCE (Eq. 4), suggests potential adaptability to balance both short- and long-term predictions without retraining. A trade-off could be achieved by adjusting the contrastive term weights across time steps in Eq. (4), which we leave for future work.

Ablation studyWe examined the model's performance in various configurations--full model, without CPC, and without InfoMax. Table 3 and Figure 7 show that removing either term reduces counterfactual accuracy across all horizons, underscoring their significance. Additionally, replacing our ICLUB objective with CDC loss  or removing balancing increases errors. We also tested different MI lower bounds like NWJ  and MINE  for both CPC and InfoMax (Appendix C.2), finding that InfoNCE yielded the best results (Table 10). Full ablation results are in Appendices E.2.2 and F.2.1.

Falsifiability TestThis study assumes sequential ignorability, common in causal inference . To assess robustness, we performed a falsifiability test by omitting certain confounders during training, while they remained in MIMIC-III data construction. As seen in Table 4, violating sequential ignorability increased prediction errors for Causal CPC, CT, and CRN, though RMSN was less affected but underperformed at \( 2\). Despite this, Causal CPC maintained its lead at larger horizons, demonstrating strong encoding of long-term dependencies.

Tightness of MI Upper BoundsEstimating MI bounds for high-dimensional variables is challenging and expensive , often limited to low-dimensional inputs or Gaussian assumptions. In MI-constrained models, batch size is crucial. As shown in Eq. (3), increasing the batch size \(\) tightens the lower bound via \((||)\), and to balance memory and performance, we chose batch sizes of 256 for the encoder and 128 for the decoder. While these bounds may not be perfectly tight, mutual information and self-supervision biases significantly enhance performance (Appendix C.2), as confirmed by ablation studies. Other MI estimators like NWJ and MINE  did not improve performance; our initial setup consistently performed better (Appendix F.2.1).

Extending Causal CPC to Continuous TreatmentOur approach could be extended to continuous treatments by replacing the treatment classifier with a regressor. Since the method maximizes likelihood, the equilibrium in Theorem 5.4 remains valid. However, in practice, continuous treatments will be represented by a single dimension, unlike discrete treatments with \(K\)-dimensional one-hot encoding. This risks losing important treatment information in counterfactual predictions. A simpler adaptation to our model could involve discretizing continuous treatments.

ConclusionWe introduced a novel approach to long-term counterfactual regression, combining RNNs with CPC to achieve SOTA results without relying on complex transformer models. Prioritizing computational efficiency, we incorporated contrastive loss-based regularization guided by mutual information (MI). Our method consistently outperforms existing models on both synthetic and real-world datasets, marking the first application of CPC in causal inference. Future work could focus on improving interpretability by integrating Shapley values into the causal framework . Additionally, developing uncertainty-aware models tailored for longitudinal data is crucial for enhancing the reliability of predictions in our causal framework .

  Model & \(=1\) & \(=2\) & \(=3\) & \(=4\) & \(=5\) & \(=6\) & \(=7\) & \(=8\) & \(=9\) & \(=10\) \\  Causal CPC & 0.44\(\)0.04 & 0.56\(\)0.07 & 0.66\(\)0.07 & 0.73 \(\) 0.08 & 0.78\(\) 0.08 & 0.83\(\)0.06 & **0.36\(\)0.10** & **0.58\(\)0.08** & **0.01\(\)0.08** & **0.91\(\)0.08** & **0.95\(\)0.07** \\  Causal Transformer & **0.43\(\)0.07** & **0.48\(\)0.07** & **0.06\(\)0.07** & **0.68\(\)0.06** & **0.75\(\)0.06** & **0.06\(\)0.07** & **0.39\(\)0.11** & 0.95\(\)0.13 & 1.00\(\)0.15 \\  CRN & **0.42\(\)0.07** & 0.54\(\)0.07 & 0.90\(\)0.07 & 0.94\(\)0.09 & 0.97\(\)0.09 & 0.97\(\)0.09 & 0.13\(\)0.13 & 1.19\(\)0.16 & 1.26\(\)1.19 & 1.32\(\)0.12 \\  RMSN & 0.38\(\)0.08 & 0.67\(\)0.21 & 0.78\(\)0.16 & 0.84\(\)0.14 & 0.91\(\)0.14 & 0.98\(\)0.15 & 1.04\(\)0.16 & 1.09\(\)0.18 & 1.15\(\)0.19 & 1.20\(\)0.23 \\  

Table 4: Results on the MIMIC III when sequential ignorability is violated reported by RMSEs

Figure 7: Ablation study of Causal CPC on MIMIC III.