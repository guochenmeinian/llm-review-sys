# Promoting Fairness Among Dynamic Agents in Online-Matching Markets under Known Stationary Arrival Distributions

Promoting Fairness Among Dynamic Agents in Online-Matching Markets under Known Stationary Arrival Distributions

Will Ma

Graduate School of Business

Columbia University

New York, NY 10027

wm2428@gsb.columbia.edu

&Pan Xu

Department of Computer Science

New Jersey Institute of Technology

Newark, NJ 07102

pxu@njit.edu

###### Abstract

Online (bipartite) matching under known stationary arrivals is a fundamental model that has been studied extensively with the objective of maximizing the total number of customers served. We instead study the objective of _maximizing the minimum matching rate across all online types_, which is referred to as long-run (individual) fairness. For Online Matching under long-run Fairness (OM-LF) with a single offline agent, we show that the first-come-first-serve (FCFS) policy is \(1\)-competitive, _i.e._, matching any optimal clairvoyant. For the general case of OM-LF: We present a sampling algorithm (SAMP) and show that (1) SAMP is of competitiveness of at least \(1-1/e\) and (2) it is asymptotically optimal with competitiveness approaching one in different regimes when either all offline agents have a sufficiently large matching capacity, or all online types have a sufficiently large arrival rate, or highly imbalance between the total offline matching capacity and the number of online arrivals. To complement the competitive results, we show the following hardness results for OM-LF: (1) Any non-rejecting policy (matching every arriving online agent if possible) is no more than \(1/2\)-competitive; (2) Any (randomized) policy is no more than \((-1)\)-competitive; (3) SAMP can be no more than \((1-1/e)\)-competitive suggesting the tightness of competitive analysis for SAMP. We stress that all hardness results mentioned here are independent of any benchmarks. We also consider a few extensions of OM-LF by proposing a few variants of fairness metrics, including long-run group-level fairness and short-run fairness, and we devise related algorithms with provable competitive performance.

## 1 Introduction

In online (bipartite) matching problems, nodes on one side of a bipartite graph are given in advance, while nodes on the other side arrive one-by-one. We refer to the two sets of nodes as _offline_ and _online_ agents, respectively. The edges incident to an online agent, which indicate the offline agents eligible to serve it, are revealed upon its arrival. An online matching algorithm must immediately serve each arriving agent using up to one eligible and unmatched offline agent; matches once made cannot be rearranged. The performance of an algorithm is typically evaluated as the total number of matches made, taking expectations as necessary if there is randomness in the arrivals or the algorithm. In this paper, we study online matching problems where performance is instead determined by the _fairness_ in service provided to different online agent types.

**Online Matching under Long-Run Fairness** (\(\)). Suppose there is a bipartite graph \(G=(I,J,E)\), where \(I\) and \(J\) denote the sets of _types_ for offline and online agents, respectively. Here each online type is defined based on certain attributes, _e.g._, race and/or gender identity, which are observed upon arrival. For an offline agent (of type) \(i I\), let \(_{i} J\) denote the "neighboring" online types that \(i\) is eligible to serve. Similarly, for an online agent (of type) \(j J\), let \(_{j} I\) denote the offline agent types eligible to serve \(j\).1 Each offline type \(i I\) has an integer capacity \(b_{i} 1\) indicating the maximum number of online agents (with types in \(_{i}\)) that \(i\) can serve.2 (**Arriving Process**). Agents of each online type \(j J\) arrive according to an _independent_ Poisson process with _homogeneous_ rate \(_{j}>0\), over a time horizon scaled to be \(\).3 When an online agent arrives in the time horizon , its type \(j\) is revealed, and an online algorithm (or policy) \(\) must make an immediate and irreversible decision from two options: either reject \(j\) or serve \(j\) by assigning it to an offline agent \(i_{j}\) that still has available capacity. For the latter choice, \(i\)'s matching capacity will be reduced by one. **(Fairness Metric)**. For each online type \(j J\), let \(X_{j}\) be the number of agents \(j\) served by \(\) and \(A_{j}\) the number of \(j\)'s arrivals by the end of the time horizon. For any \(>0\), let \(()\) denote a Poisson random variable with mean \(\). By our assumption, \(A_{j}\) is distributionally identical to a \((_{j})\) for every \(j J\). Let \(=(A_{j})_{j J}\), which is referred to as the (random) _arrival vector_ with each \(A_{j}(_{j})\). We define a long-run fairness as follows.

\[\ ()=_{j J}_{,}[X_{j}]}{_{}[A_{j} ]}=_{j J}_{,}[X_{j}]}{_{j }}. \]

We aim to design an online algorithm \(\) such that the achieved fairness is maximized. Note that all the information mentioned earlier, such as the graph \(G=(I,J,E)\), the capacities of offline agents \(\{b_{i}|i I\}\), and the arrival rates of online agents \(\{_{j}|j J\}\), are accessible to the algorithm \(\) as part of the input. _We refer to our problem as Online Matching under Long-Run Fairness (among online types)_ (\(\)).

**Remarks on \(\)**. (1) Random variables \(\{X_{j}|j J\}\) are dependent on both the arrival vector \(\) and any random bits used in the algorithm \(\) itself. (2) For the long-run fairness \(\), the time horizon typically represents one single day, and the algorithm is audited for fairness over a large number of days. In this case, the total number of agents (of type) \(j\) served over all the days will be statistically close to \(T\) times the numerator in (1), while the total number of arrivals of type \(j\) over all the days will be statistically close to \(T\) times the denominator. As a result, the audited performance is the minimum of this fraction over all types \(j J\).

## 2 Preliminaries and Main Contributions

**Competitive Ratio**. Consider a given instance, characterized as

\(=G=(I,J,E),(b_{i})_{i I},(_{j})_{j J})\), an online algorithm \(\), and a given fairness metric. We overload notation and let \(()\) denote the expected performance of \(\) on \(\). Similarly, we use \(()\) to denote an optimal clairvoyant algorithm and its corresponding performance when the context is clear. Note that \(\) can set the values of \((X_{j})_{j}\) with advance knowledge of \(\). With a fixed objective in mind, an algorithm \(\) is said to be at least _\(c\)-competitive_ if \(() c()\) for any possible instance \(\). The maximum possible value over \(c 1\) for which the above holds is called the _competitiveness_ of \(\). The maximum possible competitiveness within a class of online algorithms is called the _competitive ratio_ for that class.

**Holistic Nature of an Optimal Clairvoyant Algorithm**. Consider the classical (edge-weighted) online bipartite matching under KIID where the goal is to maximize the total weight of all matches. In that case, an optimal clairvoyant algorithm \(\) will aim to optimize the objective on every realized instance and it can always find a deterministic strategy to do so. However, this may not be true in our problem. To see this, consider a simple example under \(\) where there is one single offline agent with \(b=1\) and two online types with \(_{1}=\) and \(_{2}=1\). For any realized arrival vector \(=(A_{1},A_{2})\) with \(A_{1} 1\) and \(A_{2} 1\), we can show that the strategy of \(\) on \(\) can be characterized as follows: serve \(j=1\) and \(j=2\) with respective probabilities \(p\) and \(1-p\), where \(p(-2)/(-1) 0.418\). This suggests that OPT has to resort to a randomized strategy on \(\), and it does not suffice to simply maximize the objective of \([X_{1}]/,[X_{2}]/1\) on every realization of \(\). _More detailed discussions and clarifications can be seen in Appendix A_.

**Benchmark Linear Program (LP).** To guide the choice between offline agents, we write the following LP with variables \(\{x_{ij}|(ij) E\}\) and \(s\), where the variable \(x_{ij}\) can be interpreted as the expected number of online type \(j\) served by offline agent \(i\) in an optimal clairvoyant algorithm (OPT), while \(s\) can be interpreted as the "scale" of demand that can be served.

\[ s \] \[_{j_{i}}x_{ij} b_{i} i I\] (3) \[_{i_{j}}x_{ij} s_{j}\ \  j J\] (4) \[s,x_{ij} 0(i,j) E \]

_Throughout this paper, we refer to the linear program described above as LP (2). We utilize the notation \(\) to denote both an optimal clairvoyant policy and its corresponding performance when the context is clear._

**Lemma 1**.: LP (2) _is a valid benchmark for \(\), i.e., the optimal value of \(\) (2), denoted by \(s^{*}\), is a valid upper bound for the performance of a clairvoyant algorithm. Therefore, \(\{s^{*},1\}\)._

Note that it is important in Lemma 1 that we also upper bound OPT by 1; this will allow us to later establish asymptotic optimality in \(s^{*}\).

Proof.: Consider any clairvoyant algorithm OPT. Let \(X_{ij}\) be the random variable for the number of times it uses \(i\) to serve \(j\), with \(X_{j}=_{i_{j}}X_{ij}\). Recall that \(=_{j J}[X_{j}]/_{j}\). It can be checked that setting \(x_{ij}=[X_{ij}],s=\) constitutes a feasible LP solution with objective value \(\). Therefore, \(\), and \(1\) holds by definition, completing the proof. 

**Remarks on \(\)** (2). Among existing studies of online matching under known distributions, all benchmark LPs are designed solely for outputting an upper bound on the performance of an optimal clairvoyant (OPT), which is then used to establish a lower bound on the resulting competitiveness by comparing the performance of an online algorithm against it. In contrast, the benchmark LP (2) proposed here serves dual purposes. The optimal value \(s^{*}\) of LP (2), not only offers an upper bound on OPT but also plays a crucial role in scaling online sampling distributions (_e.g.,_ in Algorithm SAMP of Theorem 1). This means that benchmark LP (2) actively participates in the online algorithm design, serving as a key component in shaping the online decision-making process of the algorithms.

### Main Contributions

In this paper, we introduce a fairness metric among online types, defined in (1), and propose a model, called _online matching under long-run fairness among online types_ (\(\)). Our contributions are summarized as follows.

#### 2.1.1 A Warm-Up for \(\) with a Single Offline Agent.

We observe that when there is a single offline agent, the optimal online algorithm is First-Come-First-Serve (\(\)), which assigns all incoming agents to the offline agent as long as capacity is available. We demonstrate that \(\) is \(1\)-competitive.

**Proposition 1**.: _For \(\) with one single offline agent, \(\) is \(1\)-competitive, making it optimal among all algorithms._

Proof.: Suppose that \(I\) consists of a single offline agent with capacity \(b\). Let \(A\) be the random variable for the total number of online arrivals, in which case \(\) serves the first \(\{A,b\}\) arrivals. Conditioned on any value \(A>0\), the distribution of online types served is proportional to the arrival rates \(_{j}\). That is, for any online type \(j J\), the expected number of type-\(j\) agents served is \(\{(_{j J}_{j}),b\} }{_{j J}_{j}}\). All in all, \(\) achieves a fairness of

\(\{(_{j J}_{j}),b\}/ _{j J}_{j}\), which cannot be beaten even by a clairvoyant algorithm since the total number of agents served cannot exceed \(\{(_{j J}_{j}),b\}\). This shows that \(\) is \(1\)-competitive and is also the optimal clairvoyant algorithm. 

#### 2.1.2 General Cases of \(\)-\(\).

We consider \(\)-\(\) with multiple offline agents, where each offline agent may have a different capacity.

**Theorem 1** (Section 4).: _There is an algorithm (\(\)) for \(\)-\(\), whose competitiveness is lower-bounded by \((b,s^{*})[((b/s^{*}),b)](s^{*},1)/b(1,1)=1-1/\), where \(b=_{i I}b_{i}\) and \(s^{*}(0,)\) is the optimal value to benchmark LP (2) that measures the inverse of the overall demand saturation in the system. Meanwhile, the competitiveness of \(\) approaches \(1\) when either \(b\) or \(s^{*} 0^{+}\) (demand dominates supply) or \(s^{*}\) (supply dominates demand)._

**Theorem 2** (Section 5).: _For \(\)-\(\), the following hardness results hold: (1) Any non-rejection algorithm (possibly randomized) that serves an incoming agent whenever possible is no more than \(1/2\)-competitive. (2) Any algorithm (possibly randomized) is no more than \((-1)\)-competitive. (3) The competitive analysis of \(\) is tight, as it cannot be more than \((1-1/)\)-competitive. All the hardness results mentioned in (1), (2), and (3) are independent of any benchmarks.4_

#### 2.1.3 Extension of \(\)-\(\) to Group-Level Fairness.

We consider an extension of \(\)-\(\) when each online type belongs to some pre-defined protected groups. Specifically, suppose there is a collection of protected groups \(\), where each group \(g\) is a subset of \(J\), indicating the online agent types that fall under group \(g\). We assume w.l.o.g. that every type \(j J\) is contained in at least one group (otherwise we could discard and never serve that type); note however that groups can overlap with each other. We generalize long-run fairness (\(\)-\(\)), as defined in Equation (1), to a group-level version with respect to groups of \(\) as follows:

\[()=_{g}_{,}[X(g)]}{_{j g}_{j}}, \]

where \(X(g)=_{j g}X_{j}\) denotes the (random) number of types in \(g\) served in an algorithm \(\).

**Comparison between (Individual) Long-Run Fairness \(\)-\(\) in (1) and Group-Level Long-Run Fairness in (6)**. The original long-run fairness \(\)-\(\), as defined in (1), can be considered a special case of group-level long-run fairness in (6) with respect to \(=\{g=\{j\}|j J\}\), where each group consists of a single online type. Therefore, \(\)-\(\) in (1) can be interpreted as _individual_ long-run fairness with respect to every single type, as opposed to group-level fairness with respect to a pre-defined set of groups \(\). We emphasize that overlaps among groups can potentially doom classical policies, such as first-come-first-serve (FCFS), even under very simple settings. Proposition 1 states that \(\) is \(1\)-competitive (i.e., matching the performance of a clairvoyant optimal) for individual long-run fairness when there is a single offline agent. In contrast, Example 1 (see below) demonstrates that _FCFS is zero-competitive for group-level long-run fairness, as defined in (6), under the same setting of a single offline agent_.

**Example 1** (FCFS is zero-competitive for group-level fairness).: _Consider the following example: There is a single server with unit capacity. There are \(n+1\) online types, indexed as \(j=0,1,2,,n\), each with an arrival rate of 1, and \(n\) groups such that each group \(k=1,2,,n\) consists of two types \((0,j)\) with \(j=k\). We can verify the following: (1) Any clairvoyant optimal (\(\)) can achieve a group-level (long-run) fairness of at least \((1-1/e)/2\). For any offline policy prioritizing serving arriving online types of \(j=0\), it achieves a group-level fairness of at least \((1-1/e)/2\). (2) FCFS achieves a group-level fairness of \(1/(n+1)\): Note that each group has one agent served by FCFSonly when the first arriving agent belongs to one of the two types in that group, which occurs with probability \(2/(n+1)\). Thus, we conclude that FCFS is zero-competitive for group-level fairness (when \(n\))._

**Theorem 3** (Appendix G).: _For \(\) with group-level long-run fairness: (1) There exists an algorithm (\(\)-\(\)) that achieves a competitive ratio of at least \(1-^{-b}b^{b}/b!\) with \(b=_{i I}b_{i}\), which is increasing over \(b\{1,2,\}\) and approaches 1 as \(b\); (2) There exists an algorithm (\(\)) that achieves a competitive ratio of at least \(1-^{-}^{}/!\) with \(=_{j J}_{j}\), which approaches 1 as \(\)._

**Remarks on Results in Theorems 1, 2, and 3**. (1) Ma et al.  considered both long-run individual and group-level fairness maximization, but their focus was on fairness among _offline agents_. This is in contrast to the emphasis on fairness among online types. Another difference is that the work of  assumed integral arrival rates among online types and utilized this assumption to propose a strengthened benchmark LP. Additionally, they claimed that each online type could be made to admit a unit arrival rate (\(_{j}=1\)) by creating multiple copies. In our paper, however, we do not make any assumptions regarding the arrival rates among online types: They can take any fractional or integer values, allowing for a more general analysis of fairness among online types. A more detailed discussion can be seen in Appendix B. (2) As noted before, our arrival setting is essentially equivalent to the _Know Identical Independent Distributions_ (KIID), which is a discrete arrival setting commonly assumed in the study of online matching under known distributions. For Online Matching under KIID (OM-KIID), the most commonly studied objective is the maximization of the total weight of all matches under different weight settings, including unweighted, vertex-weighted (offline-side), and edge-weighted scenarios. To date, there have been only two known hardness results for OM-KIID with general arrival rates: one is \(0.823\) for unweighted and vertex-weighted due to  and the other is \(0.703\) for edge-weighted due to . Our hardness result of \(-1 0.732\) contributes to this short list of hardness results for OM-KIID. Notably, our analysis focuses on the objective of maximizing long-run fairness among online types, which adds a new dimension to the study of OM-KIID and expands the understanding of the inherent challenges and limitations in achieving fairness in online matching scenarios.

#### 2.1.4 Another Fairness Metric: Short-Run Fairness.

We propose a second fairness metric, called _Short-Run Fairness_, which is defined as follows:

\[=_{}[_{j J:A_{j}>0}_{}[X_{j}|]}{A_{j}}], \]

where \(=(A_{j})_{j J}\) is the (random) arrival vector with \(A_{j}(_{j})\) being the number of arrivals of type \(j J\).5

**Remarks on \(\)**. (a) In the numerator of \(\), \(_{}[X_{j}|]\) is a conditional expectation taken over only the randomness in the algorithm ALG. (b) In \(\), types \(j\) with no realized arrivals (for which the denominator \(A_{j}=0\)) are ignored. Also, we assume that \(=1\) in case all \(A_{j}=0\), _i.e.,_ no online agents arrive. (c) No inherent relation can be imposed on \(\) and \(\). _There are examples supporting both possibilities that \(>\) and \(<\); see details in Appendix C._ (d) For the short-run fairness, the algorithm is audited for fairness based on the realized arrivals every single day. To avoid impossibility results, evaluation in the numerator of (7) is based on the _expected_ service over any randomness in the algorithm.6 Interpreted another way, when evaluating Short-Run Fairness, we are allowing for _fractional_ allocations to be made on a given day. The overall performance (7) then takes the expectation of the daily audit scores over a large number of days. (e) Note that the definitions of long-run and short-run fairness, as shown in equations (1) and (7) respectively, bear similarities to two other concepts known as _ex-ante_ and _ex-post_ fairness. These concepts have been extensively studied in the field of online resource allocation . Specifically, our notion of long-run fairness aligns more closely with the idea of ex-ante fairness, which focuses on the minimum expectation, while the short-run fairness aligns more closely with the concept of ex-post fairness, which emphasizes the expectation of the minimum outcome.

Unlike \(\)-L, online matching under \(\)-S is quite technically challenging, even for upper-bounding the performance of an optimal clairvoyant policy (OPT). So far, we have not found any appropriate linear program that can serve as a valid benchmark for OPT as we did for FAIR-L. That being said, we take an initial stab by focusing on a simple case when there is a _single_ offline agent with a service capacity of \(b\). Even in this special case, characterizing the optimal online algorithm that maximizes \(\)-S is technically challenging. This contrasts with Proposition 1, which states that \(\) is \(1\)-competitive under \(\)-L with a single offline agent.

**Theorem 4** (Appendix H).: _For online matching under \(\)-S with a single offline agent of capacity \(b\) and a total online arrival rate of \(:=_{j J}_{j}\): (1) \(\) is \(0.863\)-competitive when \( 1\); (2) No algorithm can achieve a competitive ratio greater than \(0.942\) when \(b==1\); (3) There exists an algorithm (_Prob-Rej_) that achieves a competitive ratio of at least \(1-o(1)\), where \(o(1)\) is a vanishing term as \(\)._

## 3 Other Related Work

**Online Bipartite Matching.** Online bipartite matching was pioneered by Karp et al.  and its variants have gained interest during the past two decades in the CS community. Based on the arrival setting of online agents, there are three major categories: (1) Adversarial, the arrival sequence is fully unknown but fixed, see, _e.g.,_; (2) Random arrival order, the full arrival sequence forms a random permutation over a set of unknown agents, see, _e.g.,_; (3) known/unknown distributions, the stochastic arrivals of online agents follow certain known/unknown distributions. A special case here is when online arrivals follow Known Independent and Identical Distributions (KIID), see, _e.g.,_. Our arrival setting shares the spirit of KIID, though we consider a continuous version instead of discrete. Huang and Shu  considered the same arrival setting as ours and show that under mild assumptions,7 the performance of an online algorithm is almost the same under the two arrival settings (_i.e.,_ KIID and independent Poisson process).

There is an interesting connection between our model under Long-Run fairness and the _online-side_ vertex-weighted online matching under KIID. So far, studies about vertex-weighted online matching all focus on the setting of the offline side, _i.e.,_ all edges incident to any given offline agent share a weight. Examples include  and  under KIID,  under random arrival order, and  under adversarial arrival order. By contrast, we believe that our analysis and results can be applied to the _online-side_ vertex-weighted online matching problem, which we leave as future work.

**Fair Operations**. Fairness in operations is a topic of increasing interest and we aim to provide a brief literature review. Classical works in this area include  and  which define the price of fairness and efficiency-fairness tradeoff, respectively, in an axiomatic fashion. Gig platforms have motivated many studies on balancing multiple objectives , including fair allocation on the rider side  and income equality on the driver side  in rideshare. Fair _pricing_ to the customer side has been more generally studied in , while fair allocation has been studied in transportation problems  and COVID-19 vaccine distributions . We note that in the application of , the authors justify prioritizing transportation for certain groups (e.g. seniors), instead of balancing fairness across all groups as we do.

More generally, online resource allocation frameworks that can capture fairness have been considered in . These papers all derive regret bounds which are sublinear in the number of arrivals, while we derive competitive ratio bounds which hold universally and establish asymptotic optimalityin regimes (involving the demand saturation) not previously captured. However, we should note that our techniques appear to be reliant on the \(\)-\(\) objective function, while these papers allow for more general functions.

## 4 Proof of Theorem 1: Online Matching Under Long-Run Fairness (\(\)-\(\))

### Algorithm \(\) and Intuitions

In this section, we present an LP-based sampling algorithm, denoted by \(\), which is \((1-1/)\)-competitive and asymptotically optimal in many parameter regimes. Let \(\{x^{*}_{ij},s^{*}\}\) be an optimal solution to the benchmark LP (2). For all \(j J\), WLOG assume that \(x^{*}_{j}_{i_{j}}x^{*}_{ij}=s^{*}_{j}\).8\(\) is formally stated in Algorithm 1.

```
1 Solve \(\) (2) to get an optimal solution \(\{x^{*}_{ij},s^{*}\}\).
2 Let an online agent (of type) \(j\) arrive at time \(t\).
3 Sample a neighbor \(i_{j}\) with probability \(x^{*}_{ij}/(s^{*}_{j})\). /* This is a valid distribution since \(_{i_{j}}x^{*}_{ij}/(s^{*}_{j})=x^{*}_{j}/(s^{*} _{j})=1\). */
4If \(i\) is safe, i.e., i has remaining capacity, then assign \(i\) to serve \(j\); otherwise, reject \(j\).
```

**ALGORITHM 1**An LP-based Sampling Algorithm (\(\))

SAMP does not re-sample an offline agent if the first one sampled is unavailable, so it does not share the property of \(\) that an incoming agent is served whenever possible. The property that \(\) sometimes "rejects" an incoming agent is imperative for it to surpass the barrier of \(1/2\), as suggested by Theorem 2.

### Proof of Theorem 1: Competitive Analysis of \(\)

First, we use two lemmas to analyze the number of times each online type is served by \(\).

**Lemma 2**.: _For each \(i I\) and \(t\), let \(_{it}\) indicate if offline agent \(i\) is safe at the instantaneous point in time \(t\) in algorithm \(\), i.e., i still has remaining capacity at \(t\). \([_{it}][(b_{i}t/s^{*})<b_{i}]\), for all \(i I\) and \(t\)._

Proof.: An offline agent \(i\) is safe at time \(t\) if and only if there have been fewer than \(b_{i}\) arrivals before \(t\) which sampled \(i\). Such arrivals are Poisson with total rate \(_{j_{i}}_{j}_{ij}}{s^{*} _{j}}\), which is at most \(b_{i}/s^{*}\) by LP constraints (3). Therefore, the number of such arrivals is Poisson with mean at most \(b_{i} t/s^{*}\), completing the proof. 

**Lemma 3**.: _Let \(X^{S}_{j}\) be the random number of times type \(j\) is serviced in \(\). Then for all \(j J\),_

\[[X^{S}_{j}]}{_{j}} s^{*}_{i I}[\{(b_{i}/s^{*}),b_{i}\}]}{b_{i}}. \]

Proof.: Consider any \(i,j\) for which an offline agent \(i\) is eligible to serve online type \(j\). Let \(X^{S}_{ij}\) be the random variable for the number of times \(\) uses \(i\) to serve \(j\). \(X^{S}_{ij}\) is incremented whenever: (1) type \(j\) arrives (occurring following Poisson process of rate \(_{j}\)); (2) \(i\) is sampled (occurring with probability \(x^{*}_{ij}/(s^{*}_{j})\)); and (3) \(i\) is safe (occurring with probability at least \([(b_{i}t/s^{*})<b_{i}]\), by Lemma 2). Since these events are mutually independent, we have

\[[X^{S}_{ij}] _{0}^{1}_{j}_{ij}}{s^{*} _{j}}[(b_{i} t/s^{*})<b_{i}]dt\] \[=_{ij}}{b_{i}}_{0}^{1}}{s^{*}} [(b_{i} t/s^{*})<b_{i}]dt=_{ij}}{b_{i}} [\{(b_{i}/s^{*}),b_{i}\}].\]The final equality holds because the integral "counts" an arrival from a Poisson process of rate \(b_{i}/s^{*}\) whenever the number of arrivals thus far is less than \(b_{i}\); this equals, in expectation, the number of arrivals from such a process truncated by \(b_{i}\).

Now, for any online type \(j J\), let \(X^{S}_{j}=_{i_{j}}X^{S}_{ij}\) be the random variable for the number of times \(\) serves \(j\). The previous derivation for \(X^{S}_{ij}\) implies that

\[[X^{S}_{j}]_{i_{j}}x^{*}_{ij}[\{(b_{i}/s^{*}),b_{i}\}]}{b_{i}} s^{*} _{j}_{i_{j}}[\{( b_{i}/s^{*}),b_{i}\}]}{b_{i}},\]

where the second inequality uses LP constraint (4). This completes the proof. 

Having derived the expression on the RHS of (8), we aim to lower bound it in terms of simpler expressions of \(b_{i}\) and \(s^{*}\). Recall that \((b,s)\{s,1\}[\{(b/s),b\} ]}{b}\) for any integer \(b 1\) and \(s>0\). For any \(>0\) and \(s>0\), define \((,s)=[(), s]}{ (s,1)}\), a related function we will later use in our analysis. We can verify that \((b,s)=(b/s,s)\) and \((,s)=( s,s)\). Below are a few properties of \((b,s)\).

**Lemma 4** (Appendix D).: _(1) For any fixed \(s>0\), \((b,s)\) is increasing over \(b\{1,2,\}\); (2) For any fixed integer \(b 1\), \((b,s)\) is minimized at \(s=1\); (3) For all integers \(b 1\) and \(s>0\), \((b,s)(1,1)=1-1/\); (4) When \(s>1\), \((b,s) 1--b s(1-o(1))\), where \(o(1)\) vanishes when \(s\); (5) When \(s=1\), \((b,1) 1-}\) with \(b>1\); (6) When \(0<s<1\), \((b,s) 1--(1-s)^{2}\)._

Proof of Theorem 1.: By Lemma 3, the fairness of \(\) under \(\)-\(\) is at least

\[[X^{S}_{j}]}{_{j}} s^{*}_{i I}[\{(b_{i}/s^{*}),b_{i}\}]}{b_{i}} s^{*} [\{(b/s^{*}),b\}]}{b},\]

where \(b=_{i}b_{i}\), and the last inequality follows from Part (1) of Lemma 4. By Lemma 1, \(\{s^{*},1\}\). Putting these statements together, we see that the competitive ratio is lower bounded by

\[}{\{s^{*},1\}}[\{(b/s^{*} ),b\}]}{b}=(b,s^{*}).\]

All of the properties about \((b,s^{*})\) follow directly from Lemma 4, with the asymptotic behavior when \(b\), \(s^{*} 0^{+}\), or \(s^{*}\) following from the bounds given in parts (4)-(6) of Lemma 4. 

## 5 Proof of Theorem 2

**Example 2** (Bad Example).: \(J\) _consists of a large number of "rare types" \(t=1,,n\) each with \(_{t}=1/n\) and a single "common type" \(0\) with \(_{0}=n-1\). \(I\) consists of \(n\) unit-capacity servers such that each rare type \(t=1,,n\) can only be served by a server \(t\), but all servers can serve the common type. The graph structure is shown in Figure 1._

_We can verify that the optimal clairvoyant algorithm gives priority to rare types, and uses each server \(t\{1,2,,n\}\) for which type \(t\) never arrived to serve the common type. The expected amount of each rare type \(t\) served is \(1-^{-1/n} 1/n-O(1/n^{2})\), while the expected number of the common type served is at least \(n-1-n(1-^{-1/n}) n-2\). Thus, we claim any optimal clairvoyant (\(\)) can achieve a long-run fairness of \(1-O(1/n)\) under \(\)-\(\)._

### Proof of Part (1) of Theorem 2: \(1/2\)-Upper Bound for Non-Rejecting

We first use Example 2 to show that non-rejecting algorithms cannot be better than 1/2-competitive.

**Lemma 5**.: _On Example 2, any non-rejecting online algorithm is no more than \(1/2\)-competitive relative to the best clairvoyant algorithm._Proof.: An online algorithm that serves incoming agents whenever possible must have a (randomized) order for available servers to use on the common type. The rare type which is in position \(P[n]\) in this order must have an arrival before the \(P\)'th arrival of the common type \(0\), to have any chance of being served. For a given rare type \(t\), let \(P_{t}\) denote the (randomized) position of type \(t\) in this order. For any position \([n]\), let \((P)\) denote the arrival time of the \(P\)'th arrival of the common type \(0\). By independence of the Poisson processes for the arrivals of different types, the probability of a rare type \(t\) being served is at most

\[[1-(-(P_{t})/n)][(P_{t})/n], \]

which in turn is at most \(([P_{t}]+1}{n})/n\) for sufficiently large \(n\).9 Recall that for each rare type \(t=1,2,,n\), \(P_{t}\{1,2,,n\}\) denotes the position of type \(t\) in a randomized order adopted by a non-rejecting policy. Thus, we claim that \(_{t=1}^{n}[P_{t}]=n(n+1)/2\). This implies that at least one rare type \(t\) must satisfy \([P_{t}](n+1)/2\). Therefore, the fairness of this online algorithm cannot exceed \(1/2+O(1/n)\). 

**Remarks**. In Appendix E, we present a proof of Lemma 6, which can be viewed as a stronger version of Lemma 5. The alternative proof, though more technically involved, provides a foundational framework for analyzing a much broader class of online policies and is more self-explanatory. Additionally, in Appendix F, we focus on the bad example (Example 2) to conduct a quantitative study on the tradeoff between competitiveness and the number of rejected agents.

### Proof of Part (2) of Theorem 2: \((-1)\)-Upper Bound for Any Randomized

Proof.: On Example 2, any online algorithm that is going to reject the common type is better off doing so sooner rather than later, since an earlier rejection allows more time to observe which rare types arrive, and give those types priority. For any \(\), suppose that the online algorithm, denoted by \(()\), starts accepting common types after time \(\).

The online algorithm must have some (possibly randomized) order of offline servers to use when it wants to serve the common type. The rare type whose corresponding offline server is in position \(P[n]\) in this order must have an arrival before the \(P\)'th arrival of the common type _after time_\(\), to have any hope of being served. Counting from time \(\), the \(P\)'th arrival of the common type will occur before \(+\) w.h.p. as \(n\). As a result, the probability of this rare type being served is at most

\[1-(-,1\}}{n}) {n},1\}}{n}.\]

As \(n\), the average value of the RHS expression over \(P=1,,n\) is

\[_{0}^{1}\{+z,1\}dz=(+-^{2}).\]

Figure 1: A bad example used to show hardness results for any randomized and non-rejecting algorithms and the tightness of competitive analysis for \(\).

Therefore, even using a randomized order, there must exist a rare type whose probability of being served is at most \((+-^{2})\). Meanwhile, for any \(\), the expected number of common types served can be at most \((n-1)(1-)\). Since the arrival rates for rare and common types are \(\) and \(n-1\) respectively, the fairness of the online algorithm cannot exceed \(\{+-^{2},1-\}\).

We can verify that the fairness of the online algorithm is maximized at \(=2-\), in which case it equals \(-1\). Meanwhile, for Example 2, a clairvoyant algorithm can achieve a fairness of 1. This completes the proof. 

### Proof of Part (3) of Theorem 2: Tightness of Competitive Analysis of \(\)

Proof.: For each \(t\{1,2,,n\}\) and \(\{0,1,2,,n\}\), let \(x^{*}_{t,}\) denote the value set by an optimal solution of LP (2) on the edge \((i_{t},j_{})\) in Example 2. We can verify that the optimal LP solution sets \(x^{*}_{t,t}=1/n\) and \(x^{*}_{t,0}=1-1/n\) for each \(t=1,,n\), and \(s^{*}=1\). As a result, each offline agent \(t[n]\) serves a demand with a total arrival rate of one. Thus, each offline agent \(t\) successfully serves a demand with probability \(1-1/\) since no demand arrives otherwise (which occurs with probability \(1/\)). Conditioned on offline agent \(t\) serving a demand, the probability of that demand being of rare type \(t\) (instead of the common type \(0\)) is \(1/n\). Therefore, for any rare type \(t[n]\), we have \([X_{t}]/_{t}=1-1/\), where \(X_{t}\) denotes the random number of times type \(t\) is serviced. Thus, and under \(\)-L, \(\) achieves a fairness of at most \(1-1/\). Meanwhile, in Example 2, we show that a clairvoyant algorithm can achieve a \(\)-L of \(1-O(1/n)\), completing the proof. 

## 6 Conclusion and Reservations

We propose algorithms for maintaining statistical parity in the service rates provided to different online types or groups when agents arrive dynamically. We believe this has the potential to make a positive impact on _e.g.,_ sharing economy platforms, where our algorithms will give priority to under-served groups when matching agents, thereby boosting their rates of service. However, we admit that our algorithms do not address any underlying discrimination issues of why those groups were less commonly served by hosts/drivers in the first place. Also, our algorithms are only "fair" with respect to the fairness metrics we defined: Our model does not necessarily guarantee fairness over all arriving individuals. Relatedly, our algorithms could have the negative consequence of causing "unfairness" by violating the first-come-first-serve principle, since sometimes earlier-arriving agents are rejected in order to preserve capacity for later-arriving agents who may belong to protected groups.

[MISSING_PAGE_FAIL:11]

- 7th International Workshop_, WINE '11, pages 170-181, 2011.
*  Zhiyi Huang and Xinkai Shu. Online stochastic matching, poisson arrivals, and the natural linear program. In _Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing_, pages 682-693, 2021.
*  Zhiyi Huang, Zhihao Gavin Tang, Xiaowei Wu, and Yuhao Zhang. Online vertex-weighted bipartite matching: Beating 1-1/e with random arrivals. In _45th International Colloquium on Automata, Languages, and Programming (ICALP 2018)_. Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2018.
*  Zhiyi Huang, Xinkai Shu, and Shuyi Yan. The power of multiple choices in online stochastic matching. In _Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing_, pages 91-103, 2022.
*  Patrick Jaillet and Xin Lu. Online stochastic matching: New algorithms with better bounds. _Mathematics of Operations Research_, 39(3):624-646, 2013.
*  Chinmay Karande, Aranyak Mehta, and Pushkar Tripathi. Online bipartite matching with unknown distributions. In _Proceedings of the forty-third annual ACM symposium on Theory of computing_, pages 587-596. ACM, 2011.
*  Richard M. Karp, Umesh V. Vazirani, and Vijay V. Vazirani. An optimal algorithm for online bipartite matching. In _Proceedings of the 22nd Annual ACM Symposium on Theory of Computing_, STOC '90, pages 352-358, 1990.
*  Xin Liu, Bin Li, Pengyi Shi, and Lei Ying. Pond: Pessimistic-optimistic online dispatch. _arXiv preprint arXiv:2010.09995_, 2020.
*  Guodong Lyu, Wang Chi Cheung, Chung-Piaw Teo, and Hai Wang. Multi-objective online ride-matching. _Available at SSRN 3356823_, 2019.
*  Will Ma, David Simchi-Levi, and Jinglong Zhao. Dynamic pricing (and assortment) under a static calendar. _Management Science_, 2020.
*  Will Ma, Pan Xu, and Yifan Xu. Fairness maximization among offline agents in online-matching markets. _ACM Transactions on Economics and Computation_, 10(4):1-27, 2023.
*  Mohammad Mahdian and Qiqi Yan. Online bipartite matching with random arrivals: an approach based on strongly factor-revealing lps. In _Proceedings of the forty-third annual ACM symposium on Theory of computing_, pages 597-606. ACM, 2011.
*  Vahideh Manshadi, Rad Niazadeh, and Scott Rodilitz. Fair dynamic rationing. In _Proceedings of the 22nd ACM Conference on Economics and Computation_, pages 694-695, 2021.
*  Vahideh H Manshadi, Shayan Oveis Gharan, and Amin Saberi. Online stochastic matching: Online actions based on offline statistics. _Mathematics of Operations Research_, 37(4):559-573, 2012.
*  Enrico Masina. Useful review on the exponential-integral special function. _arXiv preprint arXiv:1907.12373_, 2019.
*  Aranyak Mehta, Amin Saberi, Umesh Vazirani, and Vijay Vazirani. Adwords and generalized online matching. _Journal of the ACM (JACM)_, 54(5):22, 2007.
*  Vedant Nanda, Pan Xu, Karthik Abhinav Sankararaman, John Dickerson, and Aravind Srinivasan. Balancing the tradeoff between profit and fairness in rideshare platforms during high-demand hours. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 34, pages 2210-2217, 2020.
*  Anik Pramanik, Pan Xu, and Yifan Xu. Equity promotion in public transportation. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 37, pages 11890-11898, 2023.
*  GS Sankar, A Louis, M Nasre, and P Nimbhorkar. Matchings with group fairness constraints: Online and offline algorithms. In _IJCAI International Joint Conference on Artificial Intelligence_, pages 377-383. International Joint Conferences on Artificial Intelligence, 2021.
*  Pan Xu and Yifan Xu. Equity promotion in online resource allocation. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 9962-9970, 2022.

*  Yifan Xu and Pan Xu. Trade the system efficiency for the income equality of drivers in rideshare. In _Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020_, pages 4199-4205, 2020.

Further Discussions on the Holistic Nature of an Optimal Clairvoyant

We emphasize that in our problem, any clairvoyant optimal policy (OPT) needs to consider the entire input instance as a whole when optimizing its decisions for each specific arrival sequence of online agents. (Recall that any clairvoyant optimal policy has the advantage of optimizing its decisions after observing the full arrival sequence.) This stands in contrast to clairvoyant optimal policies for existing, well-studied online matching problems when the objectives are to maximize the (expected) total weight of all matches. In these cases, any clairvoyant optimal policy only needs to optimize its decisions for each specific arrival sequence of online agents _without_ considering any information or consequences of other possible arriving sequences.

Now, let us revisit the toy example of OM-LF, as mentioned before, where there is one single offline agent with \(b=1\) and two online types with \(_{1}=\) and \(_{2}=1\). According to the arrival setting, agents of \(j=1\) and \(2\) each arrive following an independent Poisson process of rate \(1\) and \(\), respectively. OPT expects the following four possible scenarios. Let \(A_{1}\) and \(A_{2}\) denote the numbers of arrivals of \(j=1,2\), respectively.

* Case 1: \(A_{1}=0,A_{2} 1\), which occurs with probability equal to \(^{-}(1-1/)\);
* Case 2: \(A_{1} 1,A_{2}=0\), which occurs with probability equal to \((1-^{-})(1/)\);
* Case 3: \(A_{1} 1,A_{2} 1\), which occurs with probability equal to \((1-^{-})(1-1/)\);
* Case 4: \(A_{1}=0,A_{2}=0\), which occurs with probability equal to \(^{--1}\).

Observe that since we have one single offline agent \(i\) with a unit capacity, OPT has one single choice in Cases 1, 2, and 4. For example, in Case 1, OPT will match one arrival of \(j=2\) with \(i\), and in Case 2, OPT will match any arrival of \(j=1\) with \(i\), and in Case 4, OPT can do nothing since no arrivals. The only tricky issue arises in Case 3 since OPT can choose to match the only offline agent with one arrival either from \(j=1\) or \(j=2\). Consider the following two strategies.

The first policy, denoted by **ALG-A**, which aims to maximize \(([X_{1}]/,[X_{2}]/1)\) on every arrival instance. Thus, in Case 3, **ALG-A** should match the only offline agent with one arrival of \(j=1\) and \(j=2\) with respective probabilities of \(/(1+)\) and \(1/(1+)\). Note that the expected number of matches of \(j=1\) by **ALG-A** should be

\[[X_{1}]=[] 1+[]=(1-^{-})(1/) 1+(1 -^{-})(1-1/).\]

This suggests that

\[[X_{1}]}{_{1}}=[X_{1}]}{} }\;\;( 0).\]

Similarly, the expected number of matches of \(j=2\) by **ALG-A** should be

\[[X_{2}]}{_{2}}=[X_{2}] 1-1/ \;\;( 0).\]

Thus, we claim that **ALG-A** above achieves a long-run fairness of \(([X_{1}]}{_{1}},[X_{2}]}{ _{2}})=1/\).

Now, we consider a second strategy, denoted by **ALG-B**, which in Case 3 matches the only offline agent with one arrival of \(j=1\) and \(j=2\) with respective probabilities of \(p\) and \(1-p\), respectively, with \(p(0,1)\) being a constant independent of \(\). Note that the expected number of matches of \(j=1\) by **ALG-B** should be

\[[X_{1}]=[] 1+[] p=(1- ^{-})(1/) 1+(1-^{-})(1-1/e)  p.\]

Thus,

\[[X_{1}]}{_{1}}=[X_{1}]}{} }+(1-1/) p\;\;( 0).\]

Similarly, we have

\[[X_{2}]}{_{2}}=[X_{2}] 1-1/ \;\;( 0).\]Thus, the long-run fairness achieved by **ALG-B** is equal to

\[[X_{1}]}{_{1}},[X_{2}]}{_ {2}}=1/+(1-1/) p,1-1/,\]

which is equal to \(1-1/\) when \(p(1-2/)/(1-1/) 0.418\). That is strictly better than **ALG-A**. We can verify that **ALG-B** with \(p(1-2/e)/(1-1/e)\) is a clairvoyant optimal policy.

## Appendix B A Detailed Comparison of Our Work and Ma et al. 

Let us detail the differences between the two studies in the following two aspects.

**Model**: As pointed out on lines 155 to 162, the model of  assumes integral arrival rates for all online types and then further assumes, without loss of generality, that each online type has a unit arrival rate. In contrast, we do not make that assumption. Importantly, the integral-arrival-rate assumption among online types allows them to propose a significantly stronger benchmark LP than ours. Specifically, the extra constraint \(_{j S}x_{ij} 1-^{-(S)}=1-^{-|S|}\) in the LP  is crucial for overcoming the \(1-1/\) barrier for algorithms in , where \((S)\) denotes the total arrival rates among all online types in \(S\). As acknowledged there, their algorithms cannot surpass \(1-1/\) without that constraint. In our case, while the constraint remains valid, it becomes ineffective compared to its role in , which is particularly evident when most online types are rare. For instance, when each online type in \(S\) has an arrival rate as small as \(1/n^{2}\), this constraint reduces to \(_{j S}x_{ij} 1-^{-|S|/n^{2}}\), where the right-hand side approaches one as \(n\) regardless of the size of \(S\).

**Techniques**. Inspired by the insights above, we can no longer exploit any extra constraint to surpass the \(1-1/\) barrier. Instead, we conduct a parameter-dependent competitive analysis for our sampling-based policies and explore various scenarios where our algorithm can exceed \(1-1/\) or even approach one. Specifically, we incorporate two parameters--the optimal LP value and the minimum offline serving capacity--into the analysis and the final competitive ratio. In contrast, Ma et al.  conducted a traditional parameter-free analysis, neglecting the potential impact of different parameters in the input instance on the final competitiveness.

Appendix C Examples Showing the Possibilities of \(>\) and \(<\)

Below are examples showing it is possible that \(>\) and \(<\).

**Example 3**.: _Consider a simple example where we have one single offline agent and one single online type with \(b==1\). Consider the algorithm \(\): serve the online agent whenever it arrives._

_Let \(A(1)\) be the number of arrivals of online agents. Observe that \(=[X]=[A 1]=1-1/\). Note that when \(A=0\), we have \(=1\). Thus, we can verify that_

\[ =[A=0]+_{k=1}^{}>^{-1}+ _{k=1}^{}^{-1}}{k!}\] \[=^{-1}1+_{k=2}^{}= ^{-1}1+-2=1-1/=\,.\]

Thus we claim that it is possible that \(>\).

**Example 4**.: _Consider a simple example where we have one single offline agent and one single online type with \(b=1\) and an online arrival rate of \(\). Consider such an algorithm featured by a threshold \(k\) as follows: serve the online agent only when it arrives for the \(k\)th time. In other words, ignore it for the first \(k-1\) arrivals. Let \(A()\) denote the number of online arrivals._

_Take \(=10\) and \(k=11\). We can verify that (1) \(=\); (2)_

\[=[A=0]+_{=k}^{}[A=]/<^{- }+[A k]/k<[A k]/=\,.\]

_Thus, we claim that it is possible that \(<\)._Proof of Lemma 4

Proof.: Part (1) follows from the fact (see _e.g._, ) that \(\{(b/s),b\}/b\) is increasing in \(b\). Part (2) is valid since: if \(s 1\), then \((b,s)=\{(b/s),b\}/b\) which is decreasing in \(s\); if \(s 1\), then \((b,s)=s(\{(b/s),b\}/b)\), which is increasing in \(s\). Furthermore, we can derive that

\[[\{(b/s),b\}]}{b}=1-[ \{b-(b/s),0\}]=1-_{k=0}^{b-1}^{-b/s}}{s^{k}k!}(b-k);\]

if \(s=1\) then this equals

\[[\{(b/s),b\}]}{b}=1-_{k=0}^{b-1}^{-b}}{k!}+_{k=1}^{b-1}^{-b}}{(k-1)!}=1 -^{-b}}{(b-1)!}=(b,1).\]

It can be verified that \((b,1)\) gets minimized at \(b=1\) with \((1,1)=1-1/\). For \(b>1\),

\[(b,1) 1-^{-b}}{}{ ^{b-1}}}=1-}(1+)^{b-1} {} 1-},\]

where we use Stirling's approximation in the first inequality. This establishes Part (3) and Part (5).

Now, we show Parts (4) and (6). Recall that \((,s)=[(), s]}{ (s,1)}\) and \((b,s)=(b/s,s)\). Consider the first case when \(s>1\). We see that

\[(,s) =[((), s)]}{ }_{k=1}^{ s}^{-} ^{k}k}{k!}=_{k=0}^{ s-1}^{-}^{k }}{k!}=1-[() s]\] \[ 1--}{s} (1-o(1)).\]

The last inequality is due to the upper tail bound of a Poisson random variable as shown by , where \(o(1)=(1/ s)\) is vanishing when \(s\). Thus, since \((b,s)=(b/s,s)\), we see \((b,s) 1-(-b s(1-1/s)^{2}(1-o(1)))\), completing Part (4).

Similarly, for \(s<1\), we have

\[(,s) =[((), s)]}{ s }_{k= s}^{}^{- }^{k}}{k!}=1-[()< s]\] \[ 1--}{2}.\]

The last inequality is due to . Thus, by replacing \(\) with \(b/s\), we establish Part (6). 

## Appendix E An Alternative Proof for a Stronger Version of Lemma 5

Consider Example 2. We present an alternative proof for a stronger version of Lemma 5 below.

**Lemma 6**.: _For Example 1, the optimal non-rejecting policy (Non-Rej) achieves a long-run fairness of \(1/2+o(1)\) and \(1-o(1)\) for the rare type and the common type, respectively, where \(o(1)\) is a vanishing term when \(n\)._

Since the clairvoyant optimal achieves a long-run fairness of \(1-O(1/n)\) for both common and rare types, the above lemma immediately implies that Non-Rej achieves a competitiveness of \(1/2+o(1)\).

We claim that Non-Rej above is an optimal non-rejecting algorithm for the bad example. This can be justified as follows: When a common type arrives, the best strategy is to sample an available offline neighbor (server) uniformly at random since each rare type has an equal chance of arriving subsequently.

Proof of Lemma 6.: For each \(k\) with \(0 k n\) and \(t\), let \(_{k}(t)\) be the probability that there are \(k\) available servers at time \(t\). By the nature of Non-Rej, the update on the number of available servers follows a pure death process: The system starts at state \(k=n\) at time \(t=0\), i.e., \(_{n}(0)=1\); given the system has \(1 k<n\) free servers at time \(t\), it leaves the state whenever either a common type arrives or any rare type uniquely served by any of the \(k\) free servers arrives, with a total arrival rate of \(n-1+k/n\). Thus,

\[_{k}(t)}{t} =-_{k}(t) n,_{k}(0)=1 k=n;\] \[_{k}(t)}{t} =-_{k}(t)n-1++_{k+1}(t) n-1+,_{k}(0)=0 1 k<n;\] \[_{0}(t) =1-_{k=1}^{n}_{k}(t).\]

From the above ordinary-differential-equation system, we can solve that

\[_{k}(t)=[(tn)=n-k](1+o(1)),&1 k  n;\\ [(tn) n](1+o(1)),&k=0.\]

Let \(X\) be the (random) numbers of rare type agents that arrive and get served in Non-Rej. Therefore,

\[[X]=_{0}^{1}_{k=1}^{n}_{k}(t)(k/n)t=_{ 0}^{1}_{k=1}^{n}[(tn)=n-k](1+o(1))(k/n) t\]

We can verify that \([X]=1/2+o(1)\), where \(o(1)\) vanishes as \(n\). By symmetry, the number of each rare type served equals \([X]/n\), leading to a long-run fairness of \(([X]/n)/(1/n)=[X]=1/2+o(1)\). Similarly, let \(Y\) be the number of common type agents that arrive and are served in Non-Rej. Thus, the long-run fairness achieved for the common type is

\[[Y]}{n-1} =_{0}^{1}_{k=1}^{n}_{k}(t)(n-1) t=_{0}^{1}_{k=1}^{n}[(tn)=n-k](1+o(1 ))t\] \[=_{0}^{1}[(tn) n-1]t+o(1)= {1}{n}_{0}^{1}[(tn) n-1] n\;t+o(1)\] \[=(n),n -o(1)=1-o(1).\]

Thus, we establish the claim. 

Appendix F A Quantitative Study on the Tradeoff between Competitiveness and the Number of Rejected Agents

We use the bad example (Example 2) to conduct a case study on the trade-off between competitiveness and the number of rejected arriving agents (when the serving capacity remains). We hope this case study can provide insights for a comprehensive study of this trade-off in general cases. The proof of Lemma 6 in Section E offers a foundational framework for analyzing a general class of online policies. Consider an updated version of Non-Rej, denoted by \(()\), where we reject each arriving common-type agent with a preset constant probability \(\). We expect the parameter \(\) to serve as a useful moderator in balancing competitiveness and the number of rejected common-type agents.

Note that: (1) When \(=1\), \(()\) reduces to \(\); (2) The expected number of arriving common-type agents rejected in \(()\) is at least \((1-)(n-1)\).

**Lemma 7**.: _The policy \(()\) achieves a long-run fairness of \(1-/2+o(1)\) and \(-o(1)\) for the rare and common types, respectively, where \(o(1)\) is a vanishing term as \(n\). Additionally, it rejects at least \((1-)(n-1)\) arriving common-type agents in expectation._

Proof.: For each \(k\) with \(0 k n\) and \(t\), let \(_{k}(t)\) be the probability that there are \(k\) available servers at time \(t\). Following the same analysis as in the proof of Lemma 6, we have

\[_{k}(t)=[(tn)=n-k](1+o(1)),&1  k n;\\ [(tn) n](1+o(1)),&k=0.\]

Let \(X\) be the (random) numbers of rare type agents that arrive and get served in \(()\). Therefore,

\[[X] =_{0}^{1}_{k=1}^{n}_{k}(t)(k/n)t=_{ 0}^{1}_{k=1}^{n}[(tn)=n-k](1+o(1)) (k/n)t\] \[=_{0}^{1}_{=0}^{n-1}[(tn)=] (1-/n)t+o(1)\] \[=_{0}^{1}_{=0}^{n-1}[(tn)=] t-_{0}^{1}_{=0}^{n-1}[(tn )=]t+o(1)\] \[=_{0}^{1}[(tn) n-1]t- _{0}^{1}(t)[(tn) n-2]t+o(1)\] \[=1-/2+o(1).\]

By symmetry, the number of each rare type served is equal to \([X]/n\), leading to a long-run fairness of \(([X]/n)/(1/n)=[X]=1-/2+o(1)\). Similarly, let \(Y\) be the number of common type agents that arrive and are served in \(()\). The long-run fairness achieved for the common type is

\[[Y]}{n-1} =_{0}^{1}_{k=1}^{n}_{k}(t)(n-1) \,t=_{0}^{1}_{k=1}^{n}[(tn )=n-k]t+o(1)\] \[=_{0}^{1}\,[(tn) n-1]t+o(1)=_{0}^{1}[(tn) n -1](n)\,t+o(1)\] \[= (n),n-o(1)=-o(1).\]

Thus, we establish the claim. 

## Appendix G Proof of Theorem 3: Extension of \(\) to Group-Level Fairness

In this section, we consider the extension of \(\) to group-level fairness. Recall that we have a collection of protected groups \(=\{g|g J\}\), where each group \(g\) is a subset of \(J\) that indicates the online agent types in group \(g\). The updated long-run fairness with respect to \(\) is defined as FAIR-L(\(\)) \(=_{g}_{A,A}(X(g)]}{_{j g} _{j}}\), as shown in (6). Below is an updated version of Benchmark LP for the long-run group-level fairness.

\[\ s \] \[_{j_{i}}x_{ij}  b_{i}  i I\] \[_{j g}_{i_{j}}x_{ij}  s_{j g}_{j}\ \  g\] (11) \[_{i_{j}}x_{ij} _{j}  j J\] (12) \[s,x_{ij}  0 (i,j) E\]

Note that we add a new set of constraints (12), which are clearly valid for any clairvoyant algorithm since the constraints hold on every sample path based on the realized number of arrivals and services. Therefore, \( s^{*}\), where \(s^{*}\) represents the optimal value of LP (10), following the same argument as presented in the proof of Lemma 1.

### Proof of Part (1) of Theorem 3: \(\)-\(\) and Competitive Analysis

The algorithm \(\)-\(\) for \(\)-\(\) under long-run group-level fairness is formally stated in Algorithm 4. Note that \(\)-\(\) will reject an online agent immediately with probability \(1-_{i_{j}}x_{ij}^{*}/_{j}\), and will also reject it if the first sampled offline agent has reached capacity.

```
1 Solve \(\) (10) to get an optimal solution \(\{x_{ij}^{*}\}\).
2 Let an online agent (of type \(j\)) arrive at time \(t\).
3 Sample a neighbor \(i_{j}\) with probability \(x_{ij}^{*}/_{j}\). /* This is a valid distribution due to Constraint (12). */
4If\(i\) is safe,, \(i\) has remaining capacity, then assign \(i\) to serve \(j\); otherwise, reject \(j\).
``` ```

**ALGORITHM 4**A Sampling Algorithm for \(\)-\(\) under Long-Run Group-Level Fairness (\(\)-\(\))

Proof of Part (1) of Theorem 3.: We provide a terse argument since detailed logic can be found in Lemmas 2-3. The incoming demand flow to an offline agent \(i I\) is Poisson with rate \(_{j_{i}}_{j}^{*}}{_{j}}\), which is at most \(b_{i}\) by LP feasibility. Therefore, the capacity of any offline agent \(i\) has not been reached at time \(t\) with probability at least \([(b_{i}t)<b_{i}]\). Using this fact, the expected number of times offline agent \(i\) serves online type \(j\) is at least

\[_{0}^{1}_{j}^{*}}{_{j}}[(b_{i}t)<b_{i}]dt =^{*}}{b_{i}}_{0}^{1}b_{i} (b_{i}t)<b_{i}dt\] \[=x_{ij}^{*}[\{(b_{i}),b_{i} \}]}{b_{i}}.\]

Applying Lemma 4 twice, the expected total number of times a group \(g\) is served is at least

\[_{j g}_{i_{j}}x_{ij}^{*}[\{(b_{i}),b_{i}\}]}{b_{i}} [\{(b),b\}]}{b}_{j  g}_{i_{j}}x_{ij}^{*}\] \[=(1-^{-b}}{b!})_{j g}_{i _{j}}x_{ij}^{*}.\]

The proof is completed by using the LP inequality that \(_{j g}_{i_{j}}x_{ij}^{*}/_{j g}_{j} s ^{*}\). 

**Remarks on the Missing Role Played by \(s^{*}\) in the Final Competitiveness.** Below are a few notes on why the competitiveness should no longer depend on \(s^{*}\). Recall that in Theorem 1, when the focus is the fairness among all possible online types, \(s^{*}\) was interpreted as the "scale" of demand that can be served, and the competitiveness approached \(1\) if \(s^{*}\) or \(s^{*} 0^{+}\). However, in the context of group-level fairness, \(s^{*}\) no longer has this interpretation, and the statements about asymptotic optimality no longer hold. To illustrate this, we provide two examples below.

First, \(s^{*}\) is no longer possible, because \(s^{*} 1\) is implied by Constraints (11) and (12). On the other hand, if we do not add these constraints, then the LP has an unbounded gap, as demonstrated by the following example. There is a single group consisting of \(n\) types with arrival rates \(1\). One type is connected to an offline agent with capacity \(n\); the other types are connected to no offline agents. Without constraints (12), the LP would be able to "overseve" the first type and achieve a fairness of \(1\); any actual algorithm would have a fairness at most \(1/n\). All in all, in the generalized model, it is no longer possible to allow an \(s\) which is greater than \(1\).

Second, if \(s^{*} 0^{+}\), it is no longer the case that online algorithms can achieve a fairness of \(s^{*}\), as demonstrated by the following example. There is a single group consisting of \(2\) types; one with arrival rate \(1\) and the other with arrival rate \(\). Each type is connected to its own offline agent with capacity \(1\). In this case \(s^{*}=2/(1+)\), which approaches \(0\). However, an online algorithm makes in expectation only \(1+(1-1/)\) services, achieving fairness \((2-1/)/(1+)\).

### Algorithm Reserve when All Online Types are Common

In this section we introduce another regime, in which algorithms are \(1\)-competitive--the regime where all online types are common, _i.e._, all have high arrival rates. However, this regime requires a different algorithm, which we now motivate using the following example.

**Example 5**.: \(J\) _consists of a single type \(a\) with \(_{a}=n\) and \(I\) consists of \(n\) separate servers each with unit capacity. Using \(\)-\(\), each server faces a separate demand according to a Poisson process of rate 1 and successfully serves demand with probability \(1-1/\). The total expected demand served is \(n(1-1/)\). However, an algorithm that adaptively chooses an available server and never rejects incoming demand as long as a server is available serves a total expected demand of \([\{(n),n\}]\). As \(n\), the \(\)-\(\) of the adaptive algorithm approaches 1, while the \(\)-\(\) of \(\)-\(\) is stuck at \(1-1/\)._

\(\)-\(\) did not improve on this example even when the arrival rate approached \(\) because it did not "pool" the servers in order to reduce the variance in demand served. Motivated by this example, we now introduce an algorithm \(\), which pre-assigns the capacity that will be used to serve each online type. In general, offline agents could be adjacent to many online types and may not be as straightforward to assign as in Example 5; however, we make use of the updated \(\) (10) along with the dependent rounding procedure  to generate a randomized assignment. We state \(\) in Algorithm 5 and leave the proof of Part (2) of Theorem 3 to Appendix.

```
1Split and re-index offline agents as necessary so that \(b_{i}=1\) for all \(i I\).
2Solve \(\) (10) to get an optimal solution \(\{x^{*}_{ij},s^{*}\}\), and define \(x^{*}_{j}=_{i_{j}}x^{*}_{ij}\) for all \(j J\). Note that \(x^{*}_{j}_{j}\) for all \(j J\), by Constraint (12).
3Apply dependent rounding  to the LP solution \(\{x^{*}_{ij}\}\), and let \(\{X^{R}_{ij}\}\) be the rounded binary vector such that \(_{j_{i}}X^{R}_{ij} 1\) for all \(i I\).
4For each online type \(j\), reserve the offline agents \(\{i:X^{R}_{ij}=1\}\) exclusively for serving \(j\), and match them to incoming type-\(j\) agents in a first-come-first-serve manner.
```

**ALGORITHM 5**Alternate Algorithm that Pre-reserves Capacities (\(\))

### Proof of Part (2) of Theorem 3

Proof.: For all \(j\), let \((j)\) denote the set \(\{i:X^{R}_{ij}=1\}\), which is generally randomized. By the work of , it is possible to do the rounding in Step 3 so that the sets \(\{(j):j J\}\) are always mutually disjoint, and \(|\,(j)|\{[x^{*}_{j}],[x^{*}_{j}]\}\) for all \(j\) with \([|\,(j)|]=x^{*}_{j}\). \((j)\) is fixed in advance, and hence independent of the number of arrivals of type \(j\), for any \(j J\). Therefore,

[MISSING_PAGE_FAIL:21]

### Proof of Part (2) of Theorem 4

Proof.: Let \(b\) be the serving capacity of the single offline agent and \(\) be the total arrival rate of online types. Consider an instance with \(b=1\), and assume all online types are rare. In other words, with probability one, every online type has at most one arrival. For each \(t\), let \((,t)\) be the fairness achieved by an optimal online algorithm under \(\) when the online process is restricted as Poisson process of rate \( t\). Thus, we care about the value \((,1)\), which is the fairness achieved by the online optimal.

Consider an infinitesimally small period \(\) during which at most one arrival can occur. Now we try to upper bound \((,t+)\). (Case 1) There is no arrival during \((t,t+]\) which occurs with probability \(^{-}\). In the case, we have \((,t+)=(,t)\). (Case 2) There is one arrival during \((t,t+]\) which occurs with probability \(1-^{-}\). In this case, we have \((,t+)((,t),1-(,t)+ ^{- t})\), which is shown as below.

Let \(_{t,k}\) be the fairness achieved by an online optimal when there are \(k\) arrivals during \([0,t]\). Observe that \(_{t,0}=1\) for all \(t\). Therefore, by definition, \((,t)=_{k=0}^{}_{t,k}[( t) =k]\). Assume there is one arrival during \((t,t+]\). Note that

\[(,t+) =_{k=0}^{}(_{t,k},1-k_{t,k})[ ( t)=k]\] \[_{k=0}^{}_{t,k}[( t)=k] =(,t),\] \[(,t+) _{k=0}^{}(1-k_{t,k})[(  t)=k]\] \[ 1-_{k=1}^{}_{t,k}[( t) =k]=1-((,t)-^{- t}).\]

Thus, we claim that \((,t+)((,t),1-(,t)+^{- t})\). Wrapping up all the above analysis, we have \((,t+)^{-}(,t)+(1- ^{-})((,t),1-(,t)+^{- t})\). This suggests that \((,t)/ t-(,t)+( (,t),1-(,t)+^{- t})\).

For each given \(\), let \(R_{}(t)\) be the unique function satisfying that \(dR_{}(t)/dt=- R_{}(t)+(R_{}(t),1-R_{ }(t)+^{- t})\) with \(R_{}(0)=1\). Thus, we claim that \((,1) R_{}(1)\). Recall that the offline optimal has a performance of \(^{-}(1+)+_{k=2}^{}^{- }}{k!k}\) under \(\). We can numerically verify that \(R_{}(1)/^{-}(1+)+_{k=2}^{} ^{-}}{k!k}\) gets its minimum value of \(0.942\) when \(=1\). Thus, we establish our result. 

Proof of Part (3) of Theorem 4: Asymptomatically Optimal Algorithm of \(\) for \(\) with a Single Offline Agent

Let \((b,)\) denote an instance of online matching under short-run fairness \(\) with a single offline agent of capacity \(b\) and a total online arrival rate of \( 1\).

**Lemma 8**.: _Consider an instance \((b,)\) with \(b/<1\). We have \((b/)1+1/+o(1/)\)._

Proof.: Let \(A=_{j J}A_{j}\) be the total number of online arrivals. Observe that the performance of an optimal clairvoyant under \(\) should satisfy (1) \((A)=1\) when \(A b\) and (2) \((A)=b/k\) when \(A=k>b\). Therefore,

\[ =_{A}[(A)]\] \[=[A b] 1+_{k>b}^{}[A=k]\] \[[A(1-(1-))]+b_{k=1}^{} ^{-}^{k}}{k!}\]\[-}{2}+b+}+o}= 1++o.\]

Note that the inequality on the last line is due to the lower tail bound of a Poisson random variable as shown by . Another trick involved is \(_{k=1}^{}}{k!}=( )--\) where \(_{n}_{k=1}^{n}1/k- n 0.577\) is a constant, and \(\) is the Exponential integral function. As shown by , \(()=(^{}/)(1+1/+o(1/ ))\) when \( 1\). Thus, we are done. 

Now, we formally present the algorithm \(\)-\(\) in Algorithm 6, which shares the spirit as RESERVE as shown in Section G.2. Part (3) of Theorem 4 shows that \(\)-\(\) is \(1\)-competitive as the total arrival rate \(\), even if the service capacity \(b\) is increasing at the same time. Depending on whether \(b/\) is greater than 1, the probabilistic rejection probabilities have to be chosen differently. Also, note that due to dependent rounding, \(\)-\(\) is less likely to reject an agent if other agents have already been rejected, distributing equal opportunity among the first \(K\) arrivals to be served. This dependent rounding makes it different from \(\), \(\)-\(\), and similar algorithms in the literature.

```
1Set \(=b/-1\) if \(b/>1\) and \(=\) otherwise. let \(K=[(1+)]\).
2Apply dependent rounding  to the vector \(=(b/K)\), which has \(K\) identical entries each equal \(b/K\). \((Y_{k})_{k}\{0,1\}^{K}\) be the random vector output.
3Suppose an online agent (of type) \(j\) arrives, and let it be the \(k\)th arrival among all online arrivals.
4If \(k K\) and \(Y_{k}=1\), then serve the incoming type-\(j\) agent if it is possible; otherwise, reject agent \(j\).
```

**ALGORITHM 6**Probabilistic-Rejection Algorithm for \(\)-\(\) with a Single Offline Agent (\(\)-\(\))

Proof of Part (3) of Theorem 4.: For notation convenience, we use \(\) to denote \((b,)\), which represents an instance under \(\)-\(\) with a single offline agent of capacity \(b\) and a total online arrival rate of \(\). Additionally, we use \(\) to refer to the probabilistic-rejection algorithm \(\)-\(\). By definition, we have \(()=_{}_{j:A_{j}>0} _{}[X_{j}]/A_{j}_{}[ ()]\). Consider a given arrival vector \(\) with \(A\) being the total number of online arrivals. By definition, we have \(()=1\) when \(A=0\). Now, we show that \(()=b/K\) when (1) \(0<A K\) and (2) \(b/K 1\). Note that by dependent rounding, we have (**P1**) \([Y_{j}=1]=b/K\) for all \(j[K]:=\{1,2,,K\}\) and (**P2**) \(_{j=1}^{K}Y_{j}_{j=1}^{K}b/K=b=1\). Focus on a given \(j J\) with \(A_{j}>0\). Consider a specific online arrival of type \(j\), which is counted as the \(k\)th arrival among all online arrivals. When \(A K\), we see that \(k K\) and the single offline agent will not reach the capacity upon arrival due to (**P2**). Thus, we claim that the type-\(j\) agent will be served with probability equal to \([Y_{k}=1]=b/K\) for each of its \(A_{j}\) arrivals. Thus, \([X_{j}]=A_{j} b/K\) and \(()=_{j:A_{j}>0}_{}[X_{j}]/A_{ j}=b/K\). Consider the following three cases. (Case 1) \(b>\). In this case, \(K=b\). If \(A=0\), \(()=1\) and if \(0<A K\), \(()=b/K=1\). Thus, we claim that \(()=1\) when \(A K\).

\[()=_{}[()] [A K]=1-[()>b] 1-- (b/-1)^{2}/(2b/).\]

Note that \(() 1\). Thus, \(()/()()\) and we are done. (Case 2) \(b=\). In this case, when \(A K\), \(() b/K 1/(1+)\). Thus,

\[()/()()=_{}[()]1--}{2(1+)} .\]

Since \(=\), we establish our claim. (Case 3) \(b<\). We have \(() b/K(b/)/(1+)\) when \(A K\). Thus,

\[()=_{}[()] [A K]1-- }{2(1+)}.\]By Lemma 8, we have that for any given instance \((b,)\) with \(b<\),

\[()}{()}1- -}{2(1+)}.\]

Since \(=\), we establish our claim.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification:

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [NA]  Justification:  Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA]  Justification:  Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA]  Justification:  Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. ** It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.